dword		;Source (reg)	Dest (*[di] = ST)
	dd	ScaleDouble		;single		single
	dd	ScaleDouble		;single		double
	dd	ScaleX			;single		zero
	dd	ScaleSpclDest		;single		special
	dd	ScaleDouble		;double		single
	dd	ScaleDouble		;double		double
	dd	ScaleX			;double		zero
	dd	ScaleSpclDest		;double		special
	dd	ScaleX			;zero		single
	dd	ScaleX			;zero		double
	dd	ScaleX			;zero		zero
	dd	ScaleSpclDest		;zero		special
	dd	ScaleSpclSource		;special	single
	dd	ScaleSpclSource		;special	double
	dd	ScaleSpclSource		;special	zero
	dd	TwoOpBothSpcl		;special	special
	dd	ScaleTwoInf		;Two infinites


;The unmasked response to overflow and underflow with FSCALE is complicated 
;by the extreme range it can generate.  Normally, the exponent is biased
;by 24,576 in the appropriate direction to bring it back into range.
;This may not be enough, however.  If it isn't, a result of infinity
;(with the correct sign) is returned for overflow, regardless of the 
;rounding mode.  For underflow, zero (with the correct sign) is returned,
;even if it could be represented as a denormal.  This may be the only 
;operation in which the unmasked response destroys the operands beyond 
;recovery.

BigScale:
;Scale factor is much too big.  Just shift mantissa right two bits to get
;MSB out of sign bit and ensure no overflow when we add.
	mov	cl,2			;Always shift 2 bits if it's big
	jmp	ScaleCont

ScaleDouble:
;ebx:esi = ST(1) mantissa
;ecx = ST(1) sign in bit 15, exponent in high half
;edi = pointer to ST(0)
	rol	ecx,16			;Bring exponent down, sign to top
	or	ch,ch			;Check sign of exponent
	js	ScaleX			;No work if less than zero
	cmp	cx,30			;Scale factor exceed 30 bits?
	jge	BigScale
	not	cl			;cl = amount to shift right (mod 32)
ScaleCont:
	shr	ebx,cl			;ebx = exponent adjustment for ST(0)
;Use two's complement if negative (complement and increment)
	mov     eax,ecx
	cdq				;Extend sign through edx
	xor	ebx,edx			;Complement if negative
	sub	ebx,edx			;Increment if negative
;Scale exponent
	movsx	eax,EMSEG:[edi].wExp		;Get exponent to adjust
	add	eax,ebx			;Can't overflow
	cmp	eax,IexpMax-IexpBias	;Within normal range?
	jge	ScaleOverflow
	cmp	eax,IexpMin-IexpBias
	jle	ScaleUnderflow
SaveScaledExp:
;Result fit withing normal range
	mov	EMSEG:[edi].wExp,ax		;Update exponent of ST(0)
ScaleX:
	ret

ScaleOverflow:
;eax = exponent that's too big
	mov	EMSEG:[CURerr],Overflow
	test	EMSEG:[CWmask],Overflow	;Is exception unmasked?
	jz	UnmaskedScaleOvfl
;Produce masked overflow response
	mov	al,EMSEG:[CWcntl]		;Get rounding control
	mov	ah,al
;Return max value if RCup bit = 1 and -, or RCdown bit = 1 and +
;i.e., RCup & sign OR RCdown & not sign
.erre	RCchop eq RCup + RCdown		;Always return max value
.erre	RCnear eq 0			;Never return max value
	sar	ch,7			;Expand sign through whole byte
.erre	(RCdown and bSign) eq 0		;Don't want to change real sign
	xor	ch,RCdown		;Flip sign for RCdown bit
	and	ah,ch			;RCup & sign  OR  RCdown & not sign
	jz	ScaleToInfinity		;Save Infinity
;Get max value
	sub	ecx,1 shl 16		;Drop exponent by 1
	xor	esi,esi
	dec	esi			;esi == -1
	mov	ebx,esi
SaveScaleMax:
	mov	EMSEG:[edi].lManLo,esi
	mov	EMSEG:[edi].lManHi,ebx
	mov	EMSEG:[edi].ExpSgn,ecx
	ret

UnmaskedScaleOvfl:
	sub	eax,UnderBias		;Unmasked response
	cmp	eax,IexpMax-IexpBias	;Within normal range now?
	jl	SaveScaledExp		;Use exponent biased by 24K
ScaleToInfinity:
	mov	ebx,1 shl 31
	xor	esi,esi
	mov	ecx,(IexpMax-IexpBias+TexpBias) shl 16 + bTAG_INF
	mov	ch,EMSEG:[edi].bSgn		;Give it same sign
	jmp	SaveScaleMax		;Use infinity

ScaleUnderflow:
;eax = exponent that's too big
	test	EMSEG:[CWmask],Underflow	;Is exception unmasked?
	jz	ScaleSetUnder
	cmp	eax,-32768		;Does exponent fit in 16 bits?
	jg	@F
	mov	ax,-32768		;Max value
@@:
;Set up for denormalizer
	mov	ebx,EMSEG:[edi].lManHi
	mov	esi,EMSEG:[edi].lManLo
	shrd	ecx,eax,16		;Move exponent to high end of ecx
	mov	ch,EMSEG:[edi].bSgn		;Keep sign
	xor	eax,eax			;No sticky bits
	mov	EMSEG:[Result],edi
	jmp	Denormalize		;In emround.asm

ScaleSetUnder:
;Underflow exception not masked.  Adjust exponent and try again.
	mov	EMSEG:[CURerr],Underflow
	add	eax,UnderBias		;Unmasked response
	cmp	eax,IexpMin-IexpBias	;Within normal range now?
	jg	SaveScaledExp		;Use exponent biased by 24K
	mov	EMSEG:[CURerr],Underflow
ScaleToZero:
	mov	ecx,bTAG_ZERO
	mov	ch,EMSEG:[edi].bSgn		;Give it same sign
	xor	ebx,ebx
	mov	esi,ebx
	jmp	SaveScaleMax		;Set to zero

;***
ScaleSpclDest:
	mov	al,EMSEG:[edi].bTag		;Pick up tag
	cmp	al,bTAG_INF		;Scaling infinity?
	jz	ScaleRet		;No change if so
	jmp	SpclDest		;In emarith.asm

ScaleRet:
	ret

;***
ScaleSpclSource:
	cmp	cl,bTAG_INF		;Scaling by infinity?
	jnz	SpclSource		;in emarith.asm
	or	ch,ch			;Scaling by -infinity?
	js	ScaleToZero
	cmp	EMSEG:[edi].bTag,bTAG_ZERO	;Zero scaled by +infinity?
	jnz	ScaleToInfinity
	jmp	ReturnIndefinite	;Invalid operation

;***
ScaleTwoInf:
	or	ch,ch			;Scaling by +infinity?
	jns	ScaleRet		;All done then
;Scaling infinity by -infinity
	jmp	ReturnIndefinite	;Invalid operation
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\base\ntdll\i386\ntnapntr.asm ===
;++
;
; Copyright (c) 1991  Microsoft Corporation
;
; Module Name:
;
;    ntnap.asm
;
; Abstract:
;
;    This module implements the system service dispatch procedure.
;    It also creates a "profile" of each service by counting and
;    timing calls.
;
; Author:
;
;    Russ Blake (russbl) 22-Apr-1991
;
; Environment:
;
;    User or kernel mode.
;
; Revision History:
;
;--

include ks386.inc
include callconv.inc                    ; calling convention macros
include mac386.inc
include ntnap.inc

.386

EXTRN           _NapDllInit:near
EXTRN           _NapRecordInfo:near

NapStart        equ     [ebp - 08h]
NapEnd          equ     [ebp - 010h]
NapServiceNum   equ     [ebp - 014h]

NapLocalSize    equ     4 * 5

NapCalSrvNum    equ     0FFFFFFFFh

;++
;
; Routine Description:
;
;    This routine is called to save registers during API profiling.
;    The objecttive is to preserve the caller's environment
;    while timing takes place and, once, while dll initialization
;    takes place.  This routine svaes registers on the stack to
;    permit recursivce calls.
;
;    There should be a matching call to NapRestoreRegs to restore
;    the registers.
;
; Arguments:
;
;    All registers.
;
; Return Value:
;
;    None.  All registers are preserved on the stack.
;
;--


.386p

_TEXT   SEGMENT DWORD USE32 PUBLIC 'CODE'
        ASSUME CS:FLAT, DS:FLAT, ES:FLAT, SS:NOTHING, FS:NOTHING, GS:NOTHING

cPublicProc _NapSaveRegs

    ;
    ; This is how the stack looks like upon entering this routine:
    ;
    ;    ---+----+----+----+----+----
    ;       |   Return Address  |
    ;    ---+----+----+----+----+----
    ;        esp+                esp+
    ;        0                   4
    ;
    ;
    ; -> popping makes esp go ->
    ; <- pushing makes esp go <-
    ;

        push    ebp
        mov     ebp,esp         ; Remember where we are during this stuff
                                ; ebp = Original esp - 4
        push    eax
        push    ebx
        push    ecx
        push    edx
        push    esi
        push    edi
        pushfd
        push    ds
        push    es
        push    ss
        push    fs
        push    gs

        mov     eax,[ebp+4]     ; Grab Return Address
        push    eax             ; Put Return Address on Stack
        mov     ebp,[ebp+0]     ; Restore original ebp

    ;
    ; This is how the stack looks like just before executing RET:
    ;
    ;
    ;    +----+----+----+----+----+----+----+----+----+----+----+----+
    ;    |  Return  Address  |        g s        |        f s        |
    ;    +----+----+----+----+----+----+----+----+----+----+----+----+
    ;     esp+
    ;     0
    ;
    ;    +----+----+----+----+----+----+----+----+----+----+----+----+
    ;    |        s s        |        e s        |        d s        |
    ;    +----+----+----+----+----+----+----+----+----+----+----+----+
    ;     esp+
    ;     c
    ;
    ;    +----+----+----+----+----+----+----+----+----+----+----+----+
    ;    |      eflags       |        edi        |        esi        |
    ;    +----+----+----+----+----+----+----+----+----+----+----+----+
    ;    +----+----+----+----+----+----+----+----+----+----+----+----+
    ;    |        edx        |        ecx        |        ebx        |
    ;    +----+----+----+----+----+----+----+----+----+----+----+----+
    ;    +----+----+----+----+----+----+----+----+----+----+----+----+----
    ;    |        eax        |   original  ebp   |   Return Address  |
    ;    +----+----+----+----+----+----+----+----+----+----+----+----+----
    ;                         was
    ;                         ebp+
    ;                         0
    ;

        stdRET    _NapSaveRegs

stdENDP _NapSaveRegs

cPublicProc _NapRestoreRegs,,near

    ;
    ; This is how the stack looks like upon entering this routine:
    ;
    ;
    ;    +----+----+----+----+----+----+----+----+----+----+----+----+
    ;    |  Return  Address  |        g s        |        f s        |
    ;    +----+----+----+----+----+----+----+----+----+----+----+----+
    ;     esp+
    ;     0
    ;
    ;    +----+----+----+----+----+----+----+----+----+----+----+----+
    ;    |        s s        |        e s        |        d s        |
    ;    +----+----+----+----+----+----+----+----+----+----+----+----+
    ;     esp+
    ;     c
    ;
    ;    +----+----+----+----+----+----+----+----+----+----+----+----+
    ;    |      eflags       |        edi        |        esi        |
    ;    +----+----+----+----+----+----+----+----+----+----+----+----+
    ;     esp+
    ;     18
    ;
    ;    +----+----+----+----+----+----+----+----+----+----+----+----+
    ;    |        edx        |        ecx        |        ebx        |
    ;    +----+----+----+----+----+----+----+----+----+----+----+----+
    ;     esp+
    ;     24
    ;
    ;    +----+----+----+----+----+----+----+----+----+----+----+----+----
    ;    |        eax        |   original  ebp   |   Return Address  |
    ;    +----+----+----+----+----+----+----+----+----+----+----+----+----
    ;     esp+                esp+                esp+
    ;     30                  34                  38
    ;
        pop     eax             ; Get Return Address
        push    ebp             ; Save a temporary copy of original BP
        mov     ebp,esp         ; BP = Original SP + 4

        mov     [ebp+038h],eax  ; Put Return Address on Stack
        pop     eax             ; Get Original BP
        mov     [ebp+034h],eax  ; Put it in the original BP place

        pop     gs
        pop     fs
        pop     ss
        pop     es
        pop     ds
        popfd
        pop     edi
        pop     esi
        pop     edx
        pop     ecx
        pop     ebx
        pop     eax
        pop     ebp

        stdRET    _NapRestoreRegs

stdENDP _NapRestoreRegs


;++
;
; Routine Description:
;
;    This routine is called by the initialization code in the
;    Nt Api Profiler to calibrate the cost of profiling.
;    It simulates the overhead of a profiled call to a system
;    service, but carefully avoids doing any of the normal
;    work associated with such a call.
;
;    NOTE:  This routine's code should exactly parallel that of
;           _NapDispatch, except for any operation normally
;           (i.e., when not profiling) executed to call a system service.
;           This amounts to an "int 2Eh" in the middle of the routine.
;
; Arguments:
;
;    eax - Service Number of the routine being called.  Must be -1
;          for all calls to this routine.  The routine
;          _NapRecordInfo notes this value and discards
;          the call.
;
;    edx - Pointer to the parameters to the Service; ignored by
;          this routine.
;
; Return Value:
;
;    None.
;
;--


cPublicProc _NapCalibrate   , ,near


        push    ebp                     ; Locals: the value of
        mov     ebp, esp                ; the perf counter before and
        sub     esp, NapLocalSize       ; after the API call

        mov     eax, NapCalSrvNum       ; special routine number
        mov     NapServicenum, eax      ; is used for calibration
                                        ; can't be passed in eax from
                                        ; C routine, so load it here
                                        ; save the service routine number


        stdCall    _NapSaveRegs           ; save register state so call to
                                        ; get counter does not destroy them

        stdCall    _NapDllInit            ; initialize dll if necessary

; Now call NtQueryPerformanceCounter to get the starting count;
; Store this locally

        push    0                       ; don't need frequency: pass 0
        lea     eax, NapStart           ; (eax) = pointer to counter
        push    eax                     ; pass pointer to counter
        mov     eax, NapCounterServiceNumber
        lea     edx, [esp]              ; (edx) -> arguments
        int     2Eh                     ; get the current counter value
        add     esp, 08h                ; remove counter parameters

; Restore caller's registers

        stdCall   _NapRestoreRegs

; We're just calibrating the overhead, so we don't call the system
; service here.

; Save regsiters so we can complete the profile accounting.

        stdCall   _NapSaveRegs

; Now get the ending counter.

        push    0                       ; don't need frequency: pass 0
        lea     eax, NapEnd             ; (eax) = pointer to counter
        push    eax                     ; pass pointer to counter
        mov     eax, NapCounterServiceNumber
        lea     edx, [esp]              ; (edx) -> arguments
        int     2Eh                     ; get the current counter value
        add     esp, 08h                ; remove counter parameters

; Compute the time for this call and increment the nukmber of calls.

        lea     eax, NapEnd             ; pointer to start/end counters
                                        ; ID of this routine
        stdCall   _NapRecordInfo, <NapServiceNum, eax>

        stdCall   _NapRestoreRegs
                                        ; restore caller's registers
        leave                           ; we needed this for pseudo locals
        stdRET    _NapCalibrate
stdENDP _NapCalibrate


;++
;
; Routine Description:
;
;    This routine is called by the USRSTUBS_ENTRY1 MACRO in the
;    services.prf to carry out profiling on an Nt system api call.
;
; Arguments:
;
;    eax - Service Number of the routine being called.  This number
;          is assigned by genprof.c from the table in services.tab.
;
;    edx - Pointer to the parameters to the Service.
;
; Return Value:
;
;    Whatever the system service returns.
;
;--



cPublicProc _NapProfileDispatch , ,near

        push    ebp                     ; Locals: the value of
        mov     ebp, esp                ; the perf counter before and
        sub     esp, NapLocalSize       ; after the API call

        mov     NapServicenum, eax
                                        ; save the service routine number

        stdCall   _NapSaveRegs            ; save register state so call to
                                        ; get counter does not destroy them

        stdCall   _NapDllInit             ; initialize dll if necessary

; Now call NtQueryPerformanceCounter to get the starting count;
; Store this locally

        push    0                       ; don't need frequency: pass 0
        lea     eax, NapStart           ; (eax) = pointer to counter
        push    eax                     ; pass pointer to counter
        mov     eax, NapCounterServiceNumber
        lea     edx, [esp]              ; (edx) -> arguments
        int     2Eh                     ; get the current counter value
        add     esp, 08h                ; remove counter parameters

; Restore caller's registers

        stdCall   _NapRestoreRegs

        INT     2Eh                     ; invoke system service

; Save regsiters so we can complete the profile accounting.

        stdCall   _NapSaveRegs

; Now get the ending counter.

        push    0                       ; don't need frequency: pass 0
        lea     eax, NapEnd             ; (eax) = pointer to counter
        push    eax                     ; pass pointer to counter
        mov     eax, NapCounterServiceNumber
        lea     edx, [esp]              ; (edx) -> arguments
        int     2Eh                     ; get the current counter value
        add     esp, 08h                ; remove counter parameters

; Compute the time for this call and increment the number of calls.

        lea     eax, NapEnd             ; pointer to start/end counters
                                        ; ID of this routine
        stdCall   _NapRecordInfo, <NapServiceNum, eax>

        stdCall   _NapRestoreRegs
                                        ; restore caller's registers
        leave                           ; we needed this for pseudo locals
        stdRET    _NapProfileDispatch
stdENDP _NapProfileDispatch

;++
;
; Routine Description:
;
;    This routine is claled to get the spin lock associated with
;    a particular api.  It prevents the simultaneous update
;    from multiple threads in this or other processors of the
;    profiling data for the api.
;
; Arguments:
;
;    SpinLockAddr - address of the spin lock within the data
;                   for the api being updated.
;
; Return Value:
;
;    None.
;
;--


cPublicProc _NapAcquireSpinLock      , ,near

        push    eax
        mov     eax, [esp+8]            ; get address of lock
WaitForLock:
        lock bts dword ptr [eax], 0     ; test and set the spinlock
        jc      SHORT WaitForLock       ; spinlock owned: go to SpinLabel
        pop     eax

        stdRET    _NapAcquireSpinLock

stdENDP _NapAcquireSpinLock


;++
;
; Routine Description:
;
;    This routine is called to release the spin lock associated with
;    a particular api.
;
; Arguments:
;
;    SpinLockAddr - address of the spin lock within the data
;                   for the api being updated.
;
; Return Value:
;
;    None.
;
;--


cPublicProc _NapReleaseSpinLock     , ,near

        push    eax
        mov     eax, [esp+8]            ; get address of lock
        lock btr dword ptr [eax], 0     ; release spinlock
        pop     eax
        stdRET    _NapReleaseSpinLock

stdENDP _NapReleaseSpinLock


_TEXT           ends

                end
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\base\ntdll\ia64\ldrctx.c ===
/*++

Copyright (c) 1998  Microsoft Corporation

Module Name:

    ldrctx.c

Abstract:

    This module contains support for relocating executables.

Author:

    Landy Wang (landyw) 8-Jul-1998

Environment:

    User Mode only

Revision History:

--*/

#include <ntos.h>
#include <ldrp.h>

VOID
LdrpRelocateStartContext (
    IN PCONTEXT Context,
    IN LONG_PTR Diff
    )
/*++

Routine Description:

   This routine relocates the start context to mesh with the
   executable that has just been relocated.

Arguments:

   Context - Supplies a context that needs editing.

   Diff - Supplies the difference from the based address to the relocated
          address.

Return Value:

   None.

--*/
{
    Context->IntS1 += (ULONGLONG)Diff;
}

VOID
LdrpCorReplaceStartContext (
    IN PCONTEXT Context
    )
/*++

Routine Description:

   This routine replaces the initial address to run by one in mscoree.dll.

Arguments:

   Context - Supplies a context that needs editing.

Return Value:

   None.

--*/
{
    Context->IntS1 = (ULONGLONG)CorExeMain;
}
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\base\ntdll\ia64\critsect.s ===
//++
//
// Copyright (c) 1989  Microsoft Corporation
//
// Module Name:
//
//     critsect.s
//
// Abstract:
//
//    This module implements functions to support user mode critical sections.
//
// Author:
//
//    William K. Cheung (wcheung) 18-Sep-95
//
// Revision History:
//
//    07-Jul-97  bl    Updated to EAS2.3
//
//    08-Feb-96        Updated to EAS2.1
//
//--

#include "ksia64.h"

        .file    "critsect.s"

        //
        // intra-module functions to be called.
        //

        PublicFunction(RtlpWaitForCriticalSection)
        PublicFunction(RtlpUnWaitCriticalSection)


//++
//
// NTSTATUS
// RtlEnterCriticalSection(
//     IN PRTL_CRITICAL_SECTION CriticalSection
//     )
//
// Routine Description:
//
//     This function enters a critical section.
//
// Arguments:
//
//     CriticalSection (a0) - supplies a pointer to a critical section.
//
// Return Value:
//
//     STATUS_SUCCESS or raises an exception if an error occured.
//
// Algorithm in C:
//
// NTSTATUS
// RtlEnterCriticalSection(
//     IN PRTL_CRITICAL_SECTION CriticalSection
//     )
// {
//     PTEB     Teb;
//     LONG     OriginalValue;
//     HANDLE   CurrentThreadId;
//     DWORD    SpinCount;
//
//     Teb = NtCurrentTeb();
//     CurrentThreadId = Teb->ClientId.UniqueThread;
//     SpinCount = CriticalSection->SpinCount;
//
//     if (SpinCount == 0) {
// nospin:
//           OriginalValue = AtomicIncrement(CriticalSection->LockCount);
//      
//           if (OriginalValue != -1) {
//               if (CriticalSection->OwningThread != CurrentThreadId) {
//                   RtlpWaitForCriticalSection(CriticalSection);
//                   CriticalSection->OwningThread = CurrentThreadId;
//                   CriticalSection->RecursionCount = 0;
//               } else {
//                   CriticalSection->RecursionCount++;
//               }
//           } else {
//               CriticalSection->OwningThread = CurrentThreadId;
//               CriticalSection->RecursionCount = 0;
//           }
//       
//           return STATUS_SUCCESS;
//
//     } else { /* spin count not 0 */
//
//           if (CriticalSection->OwningThread == CurrentThread) {
//               AtomicIncrement(CriticalSection->LockCount);
//               CriticalSection->RecursionCount++;
//               return STATUS_SUCCESS;
//           } else {
//             do {
//               if (!CmpXchg(CriticalSection->LockCount,0,-1)) {
//                  Lock acquired
//                  CriticalSection->OwningThread = CurrentThreadId;
//                  CriticalSection->RecursionCount = 0;
//                  return STATUS_SUCCESS;
//               }
//               if (CriticalSection->LockCount >= 1) goto nospin;
//
//               while (CriticalSection->LockCount == 0) {
//                  if (!--SpinCount) goto nospin;
//               }
//             } while (1) // CriticalSection->LockCount == -1,  not owned
//           }
//     } 
// }
//
//--



        NESTED_ENTRY(RtlEnterCriticalSection)

        //
        // register aliases
        //

        rpThreadId=t3
        rOldLockCount=t4
        rpLockCount=t5
        rRecursionCount=t6
        rOwnerId=t7
        rpSpinCount=t9
        rSpinCount=t10
        rT1=t11
        rT2=t12
        
        pSpin=pt0
        pNoSpin=pt1
        pNotOwn=pt2
        pNotAcq=pt3
        pFree=pt5
        pHeld=pt6
        pGo=pt7
        pWait=pt8

//
// alloc regs and save brp & pfs
//

        NESTED_SETUP(1,5,1,0)
        add         rpLockCount = CsLockCount, a0
        ;;

        //
        // more register aliases
        //

        rThreadId   = loc2
        rpOwner     = loc3
        rpCsRecursion = loc4

        PROLOGUE_END

//
// Swizzle pointers to address the RecursionCount and
// LockCount fields in the critical section structure.
//

        lfetch.nt1  [rpLockCount]
        nop.f       0
        add         rpSpinCount = CsSpinCount, a0

        add         rpCsRecursion = CsRecursionCount, a0
        nop.f       0
        add         rpThreadId = TeClientId+CidUniqueThread, teb
        ;;

//
// Load the id of the currently running thread, anticipating
// that it may be needed.
//

        ld8         rThreadId = [rpThreadId]
        ld4         rSpinCount = [rpSpinCount]
        add         rpOwner = CsOwningThread, a0
        ;;
        
//
// Branch out if spin count is non-zero
//      
        cmp4.ne     pSpin, pNoSpin = rSpinCount, zero
        mov         v0 = STATUS_SUCCESS
(pSpin) br.spnt     RecsSpin

//
// Atomically increment the lock count at location (rpLockCount)
// and put the old value in register "rOldLockCount".
// Swizzle a pointer to address the thread id field in teb structure.
//

RecsNoSpin:
        fetchadd4.acq rOldLockCount = [rpLockCount], 1
        ld4.nt1     rRecursionCount = [rpCsRecursion]
        ;;
        
//
// Check the original value of lock count to determine if the
// lock is free.  If the value is -1, it is free.
//

        cmp4.eq     pFree, pHeld = -1, rOldLockCount
        ;;

//
// if lock is not free, get the thread id of its current owner
// otherwise, save the currently running thread's id.
//

(pHeld) ld8         rOwnerId = [rpOwner]
(pFree) st8         [rpOwner] = rThreadId
(pFree) st4         [rpCsRecursion] = zero
(pFree) br.ret.sptk.clr brp                     // return
        ;;

//
// if lock is not free, compare the owner id of the critical section against 
// that of the thread to determine if this thread is the owner.
// otherwise, return to caller.
//

        cmp.eq      pGo, pWait = rThreadId, rOwnerId
        mov         out0 = a0
        add         rRecursionCount = 1, rRecursionCount
        ;;

//
// if the thread has already owned the lock, save the updated 
// recursion count and return.
// otherwise, wait for the critical section to be released.
//

(pGo)   st4         [rpCsRecursion] = rRecursionCount  
(pGo)   br.ret.sptk brp
(pWait) br.call.spnt.many brp = RtlpWaitForCriticalSection
        ;;

        st8.rel     [rpOwner] = rThreadId
        st4         [rpCsRecursion] = zero
        mov         v0 = STATUS_SUCCESS

        NESTED_RETURN

// A nonzero spin count is specified
//

RecsSpin:

        ld8         rOwnerId = [rpOwner]
        mov         rT1 = -1
        ;;
        zxt4        rT1 = rT1                   // zero extend for compare with
        ;;                                      // 4 byte lock value

        mov         ar.ccv = rT1                // compare value
        cmp.ne      pNotOwn = rOwnerId, rThreadId        
(pNotOwn) br.spnt   RecsNotOwn

//
// The critical section is owned by the current thread. Increment the lock
// count and the recursion count.
//
        
        ld4         rRecursionCount = [rpCsRecursion]
        fetchadd4.acq rOldLockCount = [rpLockCount], 1
        ;;
        add         rRecursionCount = 1, rRecursionCount
        ;;

        st4         [rpCsRecursion] = rRecursionCount
        br.ret.sptk.clr brp                     // return

//
// A nonzero spin count is specified and the current thread is not the owner.
//

RecsNotOwn:
        cmpxchg4.acq rT1 = [rpLockCount], zero  // try to acquire lock
        ;;
        
        cmp4.ne     pNotAcq = -1, rT1
(pNotAcq) br.spnt   RecsNotAcq

        
//
// The critical section has been acquired. Set the owning thread and the initial
// recursion count and return success.
//

        st8         [rpOwner] = rThreadId
        st4         [rpCsRecursion] = zero
        br.ret.sptk.clr brp                     // return

//
// The critical section is currently owned. Spin until it is either unowned
// or the spin count has reached zero. 
//
// If LockCount > 0, then there are waiters. Don't spin because
// the lock will not free.
//

RecsNotAcq:
        ld4         rOldLockCount = [rpLockCount]
        ;;

        cmp4.eq     pNotOwn = -1, rOldLockCount
        cmp4.gt     pNoSpin = rOldLockCount, zero
(pNoSpin) br.spnt   RecsNoSpin
(pNotOwn) br.spnt   RecsNotOwn

        add         rSpinCount = -1, rSpinCount
        ;;

        cmp4.eq     pNoSpin, pSpin = zero, rSpinCount
(pNoSpin) br.spnt   RecsNoSpin
(pSpin) br.sptk     RecsNotAcq
        ;;

        NESTED_EXIT(RtlEnterCriticalSection)

//++
//
// NTSTATUS
// RtlLeaveCriticalSection(
//    IN PRTL_CRITICAL_SECTION CriticalSection
//    )
//
// Routine Description:
//
//    This function enters a critical section.
//
//    N.B. This function is duplicated in the runtime library.
//
// Arguments:
//
//    CriticalSection (a0) - Supplies a pointer to a critical section.
//
// Return Value:
//
//    STATUS_SUCCESS is returned as the function value.
//
// Algorithm in C:
//
// NTSTATUS
// RtlLeaveCriticalSection(
//     IN PRTL_CRITICAL_SECTION CriticalSection
//     )
// {
//     LONG NewRecursionCount;
//     LONG OldLockCount;
//     BOOL ToRelease;
// 
//     ASSERT(CriticalSection->RecursionCount >= 0)
//
//     if (CriticalSection->RecursionCount != 0) {
//         CriticalSection->RecursionCount -= 1;
//         AtomicDecrement(CriticalSection->LockCount);
//         return STATUS_SUCCESS;
//     }
// 
//     CriticalSection->OwningThread = 0; 
//     OldLockCount = AtomicDecrement(CriticalSection->LockCount);
// 
//     if ( OldLockCount != 0 ) {
//         RtlpUnWaitCriticalSection(CriticalSection);
//     }
// 
//     return STATUS_SUCCESS;
// }
// 
//--

//
// register aliases
//


        NESTED_ENTRY(RtlLeaveCriticalSection)

        rpOwner=t0
        rOldLockCount=t1
        rRecursionCount=t2
        rpLockCount=t5
        rpCsRecursion=t9

        pHold=pt0
        pRel=pt1
        pGo=pt7
        pWait=pt8

        NESTED_SETUP(1,2,1,0)
        add         rpCsRecursion = CsRecursionCount, a0
        ;;

        PROLOGUE_END

//
// load recursion count
// swizzle pointers to address the LockCount and OwningThread
// fields in the critical section structure.
//

        ld4         rRecursionCount = [rpCsRecursion]
        add         rpOwner = CsOwningThread, a0
        add         rpLockCount = CsLockCount, a0
        ;;

//
// check if the original value of the recursion count to determine
// if the lock is to be released.
//
// decrement the register copy of recursion count by 1 and save
// the new value in temp register
//

        cmp.ne      pHold, pRel = zero, rRecursionCount
        add         rRecursionCount = -1, rRecursionCount
        add         v0 = STATUS_SUCCESS, zero   // return STATUS_SUCCESS
        ;;

//
// save the updated recursion count into the critical section structure.
//
// atomically decrement the lock count.
//
// if lock is still held, return to caller.
//
// Note: An atomic fetch & add with release form is used here
//       all previous memory accesses are visible at this point.
//
// Note: All updates to the Critical Section structure MUST be complete
//       prior to the lock count being decremented which releases the
//       lock.
//

(pHold) st4         [rpCsRecursion] = rRecursionCount
(pRel)  st8         [rpOwner] = zero            // clear the owner field
        ;;
        fetchadd4.rel rOldLockCount = [rpLockCount], -1
(pHold) br.ret.sptk.clr brp                     // return to caller
        ;;

//
// The lock is now free, check the original value of the lock count to
// determine if any other thread is waiting for this critical section.
// If no thread is waiting, return to caller immediately.
// 

        cmp4.ge     pGo, pWait = zero, rOldLockCount
  (pGo) br.ret.sptk.clr brp                     // return to caller

        mov         out0 = a0
(pWait) br.call.spnt.many brp = RtlpUnWaitCriticalSection
 
        mov         v0 = STATUS_SUCCESS         // return STATUS_SUCCESS

        NESTED_RETURN
        ;;

        NESTED_EXIT(RtlLeaveCriticalSection)


//++
//
// BOOL
// RtlTryEnterCriticalSection(
//    IN PRTL_CRITICAL_SECTION CriticalSection
//    )
//
// Routine Description:
//
//    This function attempts to enter a critical section without blocking.
//
// Arguments:
//
//    CriticalSection (a0) - Supplies a pointer to a critical section.
//
// Return Value:
//
//    If the critical section was successfully entered, then a value of TRUE
//    is returned as the function value. Otherwise, a value of FALSE is returned
//
//--

        LEAF_ENTRY(RtlTryEnterCriticalSection)

        //
        // register aliases
        //

        rT0=t0
        rT1=t1
        rpThreadId=t3
        rOldLockCount=t4
        rpLockCount=t5
        rRecursionCount=t6
        rOwnerId=t7
        rpCsRecursion=t8
        rThreadId=t9
        rpOwner=t10
 
        pFree=pt5
        pHeld=pt6
        pOwn=pt7
        pFail=pt8

        alloc       rT0 = ar.pfs, 1, 0, 0, 0
        movl        rT1 = 0xffffffff
        ;;

        mov         ar.ccv = rT1
        add         rpOwner = CsOwningThread, a0
        add         rpLockCount = CsLockCount, a0
        ;;

        cmpxchg4.acq rOldLockCount = [rpLockCount], r0, ar.ccv
        add         rpCsRecursion = CsRecursionCount, a0
        add         rpThreadId = TeClientId+CidUniqueThread, teb
        ;;
 
        ld8         rOwnerId = [rpOwner]
        cmp4.eq     pFree, pHeld = rT1, rOldLockCount
        ;;


        ld8.nt1     rThreadId = [rpThreadId]
(pHeld) ld4.nt1     rRecursionCount = [rpCsRecursion]
        mov         v0 = TRUE
        ;;

(pFree) st4         [rpCsRecursion] = zero
(pFree) st8         [rpOwner] = rThreadId
(pHeld) cmp.eq      pOwn, pFail = rThreadId, rOwnerId
(pFree) br.ret.sptk.clr brp
        ;;

(pOwn)  fetchadd4.acq rT0 = [rpLockCount], 1
(pOwn)  add         rRecursionCount = 1, rRecursionCount
        nop.i       0
        ;;

(pOwn)  st4.rel     [rpCsRecursion] = rRecursionCount  
(pFail) mov         v0 = FALSE
        br.ret.sptk.clr brp

        LEAF_EXIT(RtlTryEnterCriticalSection)
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\base\ntdll\i386\emstore.asm ===
subttl  emstore.asm - FST, FSTP, FIST, FISTP instructions
        page
;*******************************************************************************
;emstore.asm - FST, FSTP, FIST, FISTP instructions
;
;        Microsoft Confidential
;
;	 Copyright (c) Microsoft Corporation 1991
;        All Rights Reserved
;
;Purpose:
;       FST, FSTP, FIST, FISTP instructions
;Inputs:
;	edi = [CURstk]
;	dseg:esi = pointer to memory destination
;
;Revision History:
;
; []	09/05/91  TP	Initial 32-bit version.
;
;*******************************************************************************


;******
EM_ENTRY eFSTP
eFSTP:
;******
;	edi = [CURstk]
;	esi = pointer to st(i) from instruction field

	cmp	EMSEG:[edi].bTag,bTAG_EMPTY
        jz      short efstp_StackError
;UNDONE: temporary hack to preserve condition codes
        mov     ax,[esp+4].OldStatus
        mov     EMSEG:[StatusWord],ax
;UNDONE: end of hack

;A common use of this instruction is FSTP st(0) just to pop the stack.
;We check for this case and optimize it.
        cmp     esi,edi
        jz      short JustPop
;Copy the register
        mov     eax,EMSEG:[edi].ExpSgn
        mov     EMSEG:[esi].ExpSgn,eax
        mov     eax,EMSEG:[edi].lManHi
        mov     EMSEG:[esi].lManHi,eax
        mov     eax,EMSEG:[edi].lManLo
        mov     EMSEG:[esi].lManLo,eax
JustPop:
	POPSTret	edi

efstp_StackError:
	mov	EMSEG:[CURerr],Invalid+StackFlag
	ret


;******
EM_ENTRY eFST
eFST:
;******
;	edi = [CURstk]
;	esi = pointer to st(i) from instruction field

	cmp	EMSEG:[edi].bTag,bTAG_EMPTY
	jz	StackError		;In emarith.asm
;Copy the register
        mov     eax,EMSEG:[edi].ExpSgn
        mov     EMSEG:[esi].ExpSgn,eax
        mov     eax,EMSEG:[edi].lManHi
        mov     EMSEG:[esi].lManHi,eax
        mov     eax,EMSEG:[edi].lManLo
        mov     EMSEG:[esi].lManLo,eax
DontPop:
	ret


;Come here if the instruction wants to pop the stack

PopStackChk:
	jc	DontPop			;Get unmasked error?
PopStack:
	mov	edi,EMSEG:[CURstk]
	POPSTret	edi


StoreSpcl64:
	cmp	cl,bTAG_DEN
	jz	Denorm64
.erre	bTAG_NAN lt bTAG_EMPTY
.erre	bTAG_NAN gt bTAG_INF
	cmp	cl,bTAG_NAN
	mov	ecx,DexpMax shl 16	;Insert special exponent for NAN/Inf.
	jb	StoreIEEE64		;Go handle infinity
	ja	Empty64
;Have a NAN.
	test	ebx,1 shl 30		;Check for SNAN
	jnz	StoreIEEE64		;Go store QNAN
	or	ebx,1 shl 30		;Make SNAN into a QNAN
	mov	EMSEG:[CURerr],Invalid	;Flag the exception
	test	EMSEG:[CWmask],Invalid	;Is it masked?
	jnz	StoreIEEE64		;If so, update with masked response
	stc				;Don't pop stack
	ret

Empty64:
;It's empty--signal invalid operation
	mov	EMSEG:[CURerr],StackFlag+Invalid
	test	EMSEG:[CWmask],Invalid	;Is it masked?
	jz	DoNothing64		;No--leave memory unchanged
;Store Indefinite
;For FSTP, we go ahead and do the pop even though it's empty
	mov	dword ptr dseg:[esi],0
	mov	dword ptr dseg:[esi+4],0FFF80000H	;64-bit IEEE indefinite
	ret				;CY clear

Denorm64:
	mov	EMSEG:[CURerr],Denormal
	test	EMSEG:[CWmask],Denormal	;Is it masked?
	jnz	NormStore64		;If so, ignore denormalization
DoNothing64:
	stc				;Don't pop stack
	ret

;*****************
;Store Double Real
;*****************

EM_ENTRY eFSTP64
eFSTP64:
	push	offset PopStackChk	;Return here after store

EM_ENTRY eFST64
eFST64:
        mov     EMSEG:[PrevDataOff],esi       ;Save operand pointer
	mov	ebx,EMSEG:[edi].lManHi
	mov	ecx,EMSEG:[edi].ExpSgn
	mov	edi,EMSEG:[edi].lManLo
;mantissa in ebx:edi, exponent in high ecx, sign in ch bit 7, tag in cl
;memory destination is dseg:esi
	mov	al,ch			;Save sign bit
	cmp	cl,bTAG_ZERO
.erre	bTAG_VALID lt bTAG_ZERO
.erre	bTAG_SNGL lt bTAG_ZERO
        jz      short SignAndStore64    ;Just set sign and exit
        ja      StoreSpcl64
NormStore64:
;Note that we could have a denormal exception at this point.
;Thus any additional exceptions must OR into [CURerr], not MOV.
	xor	cx,cx
	add	ecx,(DexpBias-TexpBias) shl 16	;Correct bias
        jl      short Under64
        cmp     ecx,DexpMax shl 16      ;Exponent too big?
        jge     Over64
	test	edi,(1 shl 11) - 1	;Any bits to round?
        jz      short StoreIEEE64

Round64:
	or	EMSEG:[CURerr],Precision 	;Set flag on inexact result
	test	EMSEG:[CWcntl],RoundControl	;Check rounding control bits
.erre	RCnear eq 0
        jnz     NotNearest64            ;Not just round-to-nearest
	test	edi,1 shl 10		;Check rounding bit
        jz      short StoreIEEE64       ;If zero, don't round up
	test	edi,(3 shl 10)-1	;Test LSB and sticky bits
        jnz     RoundUp64b

StoreIEEE64:
        or      ecx, ecx                ;now that value is rounded,
        je      short Under64           ;check exponent for underflow

StoreIEEE64Continue:
	and	ebx,not (1 shl 31)	;Clear MSB--it's implied in IEEE64
	shrd	edi,ebx,11
	shr	ebx,11			;Move mantissa down
	shl	ecx,4			;Exponent up to position
	or	ebx,ecx			;Combine exponent
SignAndStore64:
	and	al,bSign		;Just sign bit
	shl	eax,24			;Sign to MSB
	or	ebx,eax			;Combine sign
	mov	dseg:[esi],edi
	mov	dseg:[esi+4],ebx
;CY clear indicate no error
	ret

SetUnderflow:
	or	EMSEG:[CURerr],Underflow	;Unmasked underflow--do nothing
DoNothing:
	stc				;Indicate nothing was done
	ret

Under64:
        dec     cl                      ; Is cx == 1?
        jz      short StoreIEEE64Continue   ; Yes, we've alread been here

	test	EMSEG:[CWmask],Underflow	;Is underflow masked?
	jz	SetUnderflow		;No, do nothing more
;Produce masked underflow response
;Note that the underflow exception does not occur if the number can be
;represented exactly as a denormal.

	sar	ecx,16			;Bring exponent down
	cmp	ecx,DexpMin-52	;Allow for shift down to rounding bit
	jl	BigUnder64		;Too small, just make it zero
.erre	DexpMin eq 0
	neg	ecx			;Use as shift count
	inc	ecx			;Shift by at least one
	xor	edx,edx			;Place for sticky bits
	cmp	cl,32			;Long shift?
	jb	ShortDenorm
	neg	edi			;CY set if non-zero
	sbb	edx,edx			;-1 if bits shifted off, else zero
	mov	edi,ebx
	xor	ebx,ebx			;32-bit right shift
ShortDenorm:
;Shift count is modulo-32
	shrd	edx,edi,cl
	shrd	edi,ebx,cl
	shr	ebx,cl
	cmp	edx,1			;CY set if zero, else clear
	sbb	edx,edx			;Zero if bits shifted off, else -1
	inc	edx			;1 if bits shifted off, else zero
	or	edi,edx			;Collapse sticky bits into edi

        mov     ecx, 1                  ;Biased exponent is zero, put 1 into CL (noticed by Under64)
	test	edi,(1 shl 11) - 1	;Any bits to round?
	jz	StoreIEEE64		;If not, no exception
	or	EMSEG:[CURerr],Underflow
	jmp	Round64

Over64:
	test	EMSEG:[CWmask],Overflow	;Is overflow masked?
	jz	SetOverflow		;No, do nothing more
;Produce masked overflow response
	or	EMSEG:[CURerr],Overflow+Precision
	mov	ebx,DexpMax shl 20
	xor	edi,edi			;ebx:edi = positive infinity
	mov	ah,EMSEG:[CWcntl]	;Get rounding control
;Return max value if RCup bit = 1 and -, or RCdown bit = 1 and +
;i.e., RCup & sign OR RCdown & not sign
.erre	RCchop eq RCup + RCdown		;Always return max value
.erre	RCnear eq 0			;Never return max value
	sar	al,7			;Expand sign through whole byte
.erre	(RCdown and bSign) eq 0		;Don't want to change real sign
	xor	al,RCdown		;Flip sign for RCdown bit
	and	ah,al			;RCup & sign  OR  RCdown & not sign
	test	ah,RoundControl		;Look only at RC bits
	jz	SignAndStore64		;Return infinity
	dec	ebx
	dec	edi			;Max value == infinity-1
	jmp	SignAndStore64

SetOverflow:
	or	EMSEG:[CURerr],Overflow
	stc				;Indicate nothing was done
	ret

BigUnder64:
	or	EMSEG:[CURerr],Underflow+Precision
	xor	ebx,ebx
	mov	edi,ebx			;Set it to zero
	mov	ecx,ebx			;Including exponent
NotNearest64:
;We want to increase the magnitude if RCup and +, or RCdown and -
	mov	ah,EMSEG:[CWcntl]		;Get rounding control
	sar	al,7			;Expand sign through whole byte
.erre	(not RCup and RoundControl) eq RCdown
	xor	ah,al			;Flip rounding bits if negative
	and	ah,RoundControl
	cmp	ah,RCup
        jnz     StoreIEEE64             ;No, chop it

RoundUp64b:
        mov     EMSEG:[SWcc],RoundUp
	add	edi,1 shl 11		;Round up
	adc	ebx,0
        jnc     StoreIEEE64

	add	ecx,1 shl 16		;Mantissa overflowed, bump exponent
        cmp     ecx,DexpMax shl 16      ;Exponent too big?
        jge     Over64
        jmp     StoreIEEE64

;*******************************************************************************

StoreSpcl32:
	cmp	cl,bTAG_DEN
	jz	Denorm32
.erre	bTAG_NAN lt bTAG_EMPTY
.erre	bTAG_NAN gt bTAG_INF
	cmp	cl,bTAG_NAN
	mov	ecx,SexpMax shl 16	;Insert special exponent
	jb	StoreIEEE32
	ja	Empty64
;Have a NAN.
	test	ebx,1 shl 30		;Check for SNAN
	jnz	StoreIEEE32		;Go store QNAN
	or	ebx,1 shl 30		;Make SNAN into a QNAN
	mov	EMSEG:[CURerr],Invalid	;Flag the exception
	test	EMSEG:[CWmask],Invalid	;Is it masked?
	jnz	StoreIEEE32		;If so, update with masked response
	stc				;Don't pop stack
	ret

Empty32:
;It's empty--signal invalid operation
	mov	EMSEG:[CURerr],StackFlag+Invalid
	test	EMSEG:[CWmask],Invalid	;Is it masked?
	jz	DoNothing32		;No--leave memory unchanged
;Store Indefinite
;For FSTP, we go ahead and do the pop even though it's empty
	mov	dword ptr dseg:[esi],0FFC00000H	;32-bit IEEE indefinite
	ret				;CY clear

Denorm32:
	mov	EMSEG:[CURerr],Denormal
	test	EMSEG:[CWmask],Denormal	;Is it masked?
	jnz	NormStore32		;If so, ignore denormalization
DoNothing32:
	stc				;Don't pop stack
	ret

;*****************
;Store Single Real
;*****************

EM_ENTRY eFSTP32
eFSTP32:
	push	offset PopStackChk	;Return here after store

EM_ENTRY eFST32
eFST32:
        mov     EMSEG:[PrevDataOff],esi       ;Save operand pointer
	mov	ebx,EMSEG:[edi].lManHi
	mov	ecx,EMSEG:[edi].ExpSgn
	mov	edi,EMSEG:[edi].lManLo
;mantissa in ebx:edi, exponent in high ecx, sign in ch bit 7, tag in cl
;memory destination is dseg:esi
	mov	al,ch			;Save sign bit
	cmp	cl,bTAG_ZERO
.erre	bTAG_VALID lt bTAG_ZERO
.erre	bTAG_SNGL lt bTAG_ZERO
	jz	SignAndStore32		;Just set sign and exit
	ja	StoreSpcl32
NormStore32:
;Note that we could have a denormal exception at this point.
;Thus any additional exceptions must OR into [CURerr], not MOV.
	xor	cx,cx
	add	ecx,(SexpBias-TexpBias) shl 16	;Correct bias
	jle	Under32
	cmp	ecx,SexpMax shl 16	;Exponent too big?
	jge	Over32
;See if we need to round
	mov	edx,ebx			;Get low bits
	and	edx,(1 shl 8) - 1	;Mask to last 8 bits
	or	edx,edi			;Throwing away any bits?
	jz	StoreIEEE32
;Result will not be exact--check rounding mode
Round32:
	or	EMSEG:[CURerr],Precision 	;Set flag on inexact result
	test	EMSEG:[CWcntl],RoundControl	;Check rounding control bits
.erre	RCnear eq 0
	jnz	NotNearest32		;Not just round-to-nearest
	test	bl,1 shl 7		;Round bit set?
	jz	StoreIEEE32
	mov	edx,ebx
	and	edx,(3 shl 7)-1		;Mask to LSB and sticky bits
	or	edx,edi			;Combine with remaining sticky bits
	jz	StoreIEEE32
	mov	EMSEG:[SWcc],RoundUp
	add	ebx,1 shl 8		;Round up
	jc	AddOneExp32
StoreIEEE32:
	and	ebx,not (1 shl 31)	;Clear MSB--it's implied in IEEE32
	shr	ebx,8			;Move mantissa down
	shl	ecx,7			;Exponent up to position
	or	ebx,ecx			;Combine exponent
SignAndStore32:
	and	al,bSign		;Just sign bit
	shl	eax,24			;Sign to MSB
	or	ebx,eax			;Combine sign
	mov	dseg:[esi],ebx
;CY clear indicate no error
	ret

Under32:
	test	EMSEG:[CWmask],Underflow	;Is underflow masked?
	jz	SetUnderflow		;No, do nothing more
;Produce masked underflow response
;Note that the underflow exception does not occur if the number can be
;represented exactly as a denormal.
	sar	ecx,16			;Bring exponent down
	cmp	ecx,SexpMin-23	;Allow for shift down to rounding bit
	jl	BigUnder32		;Too small, just make it zero
.erre	SexpMin eq 0
	neg	ecx			;Use as shift count
	inc	ecx			;Shift by at least one
	xor	edx,edx			;Place for sticky bits
	shrd	edx,ebx,cl
	shr	ebx,cl
	xor	ecx,ecx			;Biased exponent is zero
	or	edi,edx			;Combine sticky bits
	mov	edx,ebx			;Get low bits
	and	edx,(1 shl 8) - 1	;Mask to last 8 bits
	or	edx,edi			;Throwing away any bits?
	jz	StoreIEEE32
	or	EMSEG:[CURerr],Underflow
	jmp	Round32

AddOneExp32:
	add	ecx,1 shl 16		;Mantissa overflowed, bump exponent
	cmp	ecx,SexpMax shl 16	;Exponent too big?
	jl	StoreIEEE32
Over32:
	test	EMSEG:[CWmask],Overflow	;Is overflow masked?
	jz	SetOverflow		;No, do nothing more
;Produce masked overflow response
	or	EMSEG:[CURerr],Overflow+Precision
	mov	ebx,SexpMax shl 23
	mov	ah,EMSEG:[CWcntl]		;Get rounding control
;Return max value if RCup bit = 1 and -, or RCdown bit = 1 and +
;i.e., RCup & sign OR RCdown & not sign
.erre	RCchop eq RCup + RCdown		;Always return max value
.erre	RCnear eq 0			;Never return max value
	sar	al,7			;Expand sign through whole byte
.erre	(RCdown and bSign) eq 0		;Don't want to change real sign
	xor	al,RCdown		;Flip sign for RCdown bit
	and	ah,al			;RCup & sign  OR  RCdown & not sign
	test	ah,RoundControl		;Look only at RC bits
	jz	SignAndStore32		;Return infinity
	dec	ebx			;Max value == infinity-1
	jmp	SignAndStore32

BigUnder32:
	or	EMSEG:[CURerr],Underflow+Precision
	xor	ebx,ebx			;Set it to zero
	xor	ecx,ecx			;Exponent too
NotNearest32:
;We want to increase the magnitude if RCup and +, or RCdown and -
	mov	ah,EMSEG:[CWcntl]		;Get rounding control
	sar	al,7			;Expand sign through whole byte
.erre	(not RCup and RoundControl) eq RCdown
	xor	ah,al			;Flip rounding bits if negative
	and	ah,RoundControl
	cmp	ah,RCup
	jnz	StoreIEEE32		;No, chop it
	mov	EMSEG:[SWcc],RoundUp
	add	ebx,1 shl 8		;Round up
	jnc	StoreIEEE32
	jmp	AddOneExp32

;*******************************************************************************

StoreSpcl32Int:
	cmp	cl,bTAG_DEN
	jz	NormStore32Int		;Ignore denormal
	cmp	cl,bTAG_EMPTY
	jnz	Over32Int		;All other specials are invalid
	mov	EMSEG:[CURerr],StackFlag+Invalid
	jmp	Invalid32Int

DoNothing32Int:
	stc				;Don't pop stack
	ret

CheckMax32:
	ja	Over32Int
	test	al,bSign		;Is it negative?
	jnz	Store32Int		;If so, answer is OK
Over32Int:
;Overflow on integer store is invalid according to IEEE
	mov	EMSEG:[CURerr],Invalid	;Must remove precision exception
Invalid32Int:
	test	EMSEG:[CWmask],Invalid	;Is it masked?
	jz	DoNothing32Int		;No--leave memory unchanged
;Store Indefinite
;For FSTP, we go ahead and do the pop even though it's empty
	mov	dword ptr dseg:[esi],80000000H	;32-bit integer indefinite
	ret				;CY clear

;******************
;Store Long Integer
;******************

EM_ENTRY eFISTP32
eFISTP32:
	push	offset PopStackChk	;Return here after store

EM_ENTRY eFIST32
eFIST32:
        mov     EMSEG:[PrevDataOff],esi       ;Save operand pointer
	mov	ebx,EMSEG:[edi].lManHi
	mov	ecx,EMSEG:[edi].ExpSgn
	mov	edi,EMSEG:[edi].lManLo
;mantissa in ebx:edi, exponent in high ecx, sign in ch bit 7, tag in cl
;memory destination is dseg:esi
	mov	al,ch			;Save sign bit
	cmp	cl,bTAG_ZERO
.erre	bTAG_VALID lt bTAG_ZERO
.erre	bTAG_SNGL lt bTAG_ZERO
	jz	Store32Int		;Just store zero and exit
	ja	StoreSpcl32Int
NormStore32Int:
	xor	edx,edx
	sar	ecx,16			;Bring exponent down
	cmp	ecx,-1			;Is it less than 1?
	jle	Under32Int
	cmp	ecx,31
	jg	Over32Int
	sub	ecx,31
	neg	ecx			;cl = amount to shift right
	shrd	edx,edi,cl
	shrd	edi,ebx,cl		;Collect round and sticky bits
	shr	ebx,cl			;Align integer
;See if we need to round
	mov	ecx,edi
	or	ecx,edx			;Throwing away any bits?
	jz	StoreIEEE32Int
;Result will not be exact--check rounding mode
Round32Int:
	mov	EMSEG:[CURerr],Precision 	;Set flag on inexact result
	test	EMSEG:[CWcntl],RoundControl	;Check rounding control bits
.erre	RCnear eq 0
	jnz	NotNearest32Int		;Not just round-to-nearest

;To perform "round even" when the round bit is set and the sticky bits
;are zero, we treat the LSB as if it were a sticky bit.  Thus if the LSB
;is set, that will always force a round up (to even) if the round bit is
;set.  If the LSB is zero, then the sticky bits remain zero and we always
;round down.

	bt	ebx,0			;Look at LSB (for round even)
	adc	edx,-1			;CY set if sticky bits <>0
	adc	edi,(1 shl 31)-1	;CY set if round up
	jnc	StoreIEEE32Int
	mov	EMSEG:[SWcc],RoundUp
	inc	ebx
	jz	Over32Int
StoreIEEE32Int:
	cmp	ebx,1 shl 31		;Check for max value
	jae	CheckMax32
SignAndStore32Int:
	shl	eax,24			;Sign to MSB
	cdq				;Extend sign through edx
	xor	ebx,edx			;Complement
	sub	ebx,edx			;  and increment if negative
	clc
Store32Int:
	mov	dseg:[esi],ebx
;CY clear indicates no error
	ret

Under32Int:
;ZF set if exponent is -1
	xchg	edx,edi			;32-bit right shift
	xchg	edi,ebx			;ebx = 0 now
	jz	Round32Int		;If exponent was -1, ready to round
	mov	EMSEG:[CURerr],Precision 	;Set flag on inexact result
NotNearest32Int:
;We want to increase the magnitude if RCup and +, or RCdown and -
	mov	ah,EMSEG:[CWcntl]		;Get rounding control
	sar	al,7			;Expand sign through whole byte
.erre	(not RCup and RoundControl) eq RCdown
	xor	ah,al			;Flip rounding bits if negative
	and	ah,RoundControl
	cmp	ah,RCup			;Rounding up?
	jnz	StoreIEEE32Int		;No, chop it
	mov	EMSEG:[SWcc],RoundUp
	inc	ebx
	jnc	StoreIEEE32Int
	jmp	Over32Int

;*******************************************************************************

StoreSpcl16Int:
	cmp	cl,bTAG_DEN
	jz	NormStore16Int		;Ignore denormal
	cmp	cl,bTAG_EMPTY
	jnz	Over16Int		;All other specials are invalid
	mov	EMSEG:[CURerr],StackFlag+Invalid
	jmp	Invalid16Int

DoNothing16Int:
	stc				;Don't pop stack
	ret

CheckMax16:
	ja	Over16Int
	test	al,bSign		;Is it negative?
	jnz	Store16Int		;If so, answer is OK
Over16Int:
;Overflow on integer store is invalid according to IEEE
	mov	EMSEG:[CURerr],Invalid
Invalid16Int:
	test	EMSEG:[CWmask],Invalid	;Is it masked?
	jz	DoNothing16Int		;No--leave memory unchanged
;Store Indefinite
;For FSTP, we go ahead and do the pop even though it's empty
	mov	word ptr dseg:[esi],8000H	;16-bit integer indefinite
	ret				;CY clear

;*******************
;Store Short Integer
;*******************

EM_ENTRY eFISTP16
eFISTP16:
	push	offset PopStackChk	;Return here after store

EM_ENTRY eFIST16
eFIST16:
        mov     EMSEG:[PrevDataOff],esi       ;Save operand pointer
	mov	ebx,EMSEG:[edi].lManHi
	mov	ecx,EMSEG:[edi].ExpSgn
	mov	edi,EMSEG:[edi].lManLo
;mantissa in ebx:edi, exponent in high ecx, sign in ch bit 7, tag in cl
;memory destination is dseg:esi
	mov	al,ch			;Save sign bit
	cmp	cl,bTAG_ZERO
.erre	bTAG_VALID lt bTAG_ZERO
.erre	bTAG_SNGL lt bTAG_ZERO
	jz	Store16Int		;Just store zero and exit
	ja	StoreSpcl16Int
NormStore16Int:
	xor	edx,edx
	sar	ecx,16			;Bring exponent down
	cmp	ecx,-1			;Is it less than 1?
	jle	Under16Int
	cmp	ecx,15
	jg	Over16Int
	sub	ecx,31
	neg	ecx			;cl = amount to shift right
	shrd	edx,edi,cl
	shrd	edi,ebx,cl		;Collect round and sticky bits
	shr	ebx,cl			;Align integer
;See if we need to round
	mov	ecx,edi
	or	ecx,edx			;Throwing away any bits?
	jz	StoreIEEE16Int
;Result will not be exact--check rounding mode
Round16Int:
	mov	EMSEG:[CURerr],Precision 	;Set flag on inexact result
	test	EMSEG:[CWcntl],RoundControl	;Check rounding control bits
.erre	RCnear eq 0
	jnz	NotNearest16Int		;Not just round-to-nearest

;To perform "round even" when the round bit is set and the sticky bits
;are zero, we treat the LSB as if it were a sticky bit.  Thus if the LSB
;is set, that will always force a round up (to even) if the round bit is
;set.  If the LSB is zero, then the sticky bits remain zero and we always
;round down.

	bt	ebx,0			;Look at LSB (for round even)
	adc	edx,-1			;CY set if sticky bits <>0
	adc	edi,(1 shl 31)-1	;CY set if round up
	jnc	StoreIEEE16Int
	mov	EMSEG:[SWcc],RoundUp
	inc	ebx
StoreIEEE16Int:
	cmp	ebx,1 shl 15		;Check for max value
	jae	CheckMax16
SignAndStore16Int:
	shl	eax,24			;Sign to MSB
	cdq				;Extend sign through edx
	xor	ebx,edx			;Complement
	sub	ebx,edx			;  and increment if negative
	clc
Store16Int:
	mov	dseg:[esi],bx
;CY clear indicates no error
	ret

Under16Int:
;ZF set if exponent is -1
	xchg	edx,edi			;16-bit right shift
	xchg	edi,ebx			;ebx = 0 now
	jz	Round16Int		;If exponent was -1, ready to round
	mov	EMSEG:[CURerr],Precision 	;Set flag on inexact result
NotNearest16Int:
;We want to increase the magnitude if RCup and +, or RCdown and -
	mov	ah,EMSEG:[CWcntl]		;Get rounding control
	sar	al,7			;Expand sign through whole byte
.erre	(not RCup and RoundControl) eq RCdown
	xor	ah,al			;Flip rounding bits if negative
	and	ah,RoundControl
	cmp	ah,RCup			;Rounding up?
	jnz	StoreIEEE16Int		;No, chop it
	mov	EMSEG:[SWcc],RoundUp
	inc	ebx
	jnc	StoreIEEE16Int
	jmp	Over16Int

;*******************************************************************************

;******************
;Store Quad Integer
;******************

EM_ENTRY eFISTP64
eFISTP64:
        mov     EMSEG:[PrevDataOff],esi       ;Save operand pointer
	call	RoundToInteger
	jc	Invalid64Int
;Have integer in ebx:edi
;Sign in ch
	cmp	ebx,1 shl 31		;Check for max value
	jae	CheckMax64
	or	ch,ch			;Check sign
	jns	Store64Int
;64-bit negation
	not	ebx
	neg	edi
	sbb	ebx,-1
Store64Int:
	mov	dseg:[esi],edi
	mov	dseg:[esi+4],ebx
	jmp	PopStack

CheckMax64:
	ja	Over64Int
	test	al,bSign		;Is it negative?
	jnz	Store64Int		;If so, answer is OK
Over64Int:
;Overflow on integer store is invalid according to IEEE
	mov	EMSEG:[CURerr],Invalid
Invalid64Int:
	test	EMSEG:[CWmask],Invalid	;Is it masked?
	jz	DoNothing80		;No--leave memory unchanged
;Store Indefinite
;For FSTP, we go ahead and do the pop even though it's empty
	mov	dword ptr dseg:[esi],0
	mov	dword ptr dseg:[esi+4],80000000H	;64-bit integer indefinite
	jmp	PopStack

;*******************************************************************************

Empty80:
;It's empty--signal invalid operation
	mov	EMSEG:[CURerr],StackFlag+Invalid
	test	EMSEG:[CWmask],Invalid	;Is it masked?
	jz	DoNothing80		;No--leave memory unchanged
;Store Indefinite
;For FSTP, we go ahead and do the pop even though it's empty
	mov	dword ptr dseg:[esi],0
	mov	dword ptr dseg:[esi+4],0C0000000H
	mov	word ptr dseg:[esi+8],0FFFFH	;80-bit IEEE indefinite
	jmp	PopStack

DoNothing80:
	ret

;***************
;Store Temp Real
;***************

EM_ENTRY eFSTP80
eFSTP80:
        mov     EMSEG:[PrevDataOff],esi       ;Save operand pointer
	mov	eax,EMSEG:[edi].ExpSgn
	cmp	al,bTAG_EMPTY
	jz	Empty80

        push    offset PopStack

StoreTempReal:
	mov	ebx,EMSEG:[edi].lManHi
	mov	edi,EMSEG:[edi].lManLo
;mantissa in ebx:edi, exponent in high eax, sign in ah bit 7, tag in al
;memory destination is dseg:esi
	mov	ecx,eax			;get copy of sign and tag
	shr	ecx,16			;Bring exponent down
	cmp	al,bTAG_ZERO
	jz	StoreIEEE80		;Skip bias if zero
	add	ecx,IexpBias-TexpBias	;Correct bias
	cmp	al,bTAG_DEN
	jz	Denorm80
StoreIEEE80:
	and	eax,bSign shl 8
	or	ecx,eax			;Combine sign with exponent
	mov	dseg:[esi],edi
	mov	dseg:[esi+4],ebx
	mov	dseg:[esi+8],cx

;	jmp	PopStack
        ret

Denorm80:
;Must change it to a denormal
	dec	ecx
	neg	ecx			;Use as shift count
	cmp	cl,32			;Long shift?
	jae	LongDenorm
	shrd	edi,ebx,cl
	shr	ebx,cl
	xor	ecx,ecx			;Exponent is zero
	jmp	StoreIEEE80

LongDenorm:
;edi must be zero if we have 32 bits to shift
	xchg	ebx,edi			;32-bit right shift
	shr	edi,cl			;shift count is modulo-32
	xor	ecx,ecx			;Exponent is zero
	jmp	StoreIEEE80
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\base\ntdll\wow6432\makefile.inc ===
!if exist(..\$(TARGET_DIRECTORY).inc)
!include ..\$(TARGET_DIRECTORY).inc
!endif

TEMP_DIR=$(O)
SERVICES_DIR=$(O)
SERVICES_TAB=$(SERVICES_DIR)\services.tab
KESVC_TAB=$(O)\kesvc32.tab
NTDLL_XTR=$(O)\ntdll.xtr

clean:
    -del $(KESVC32_TAB)

$(SERVICES_TAB): ..\..\ntos\ke\services.tab
    @echo Creating $@ from $**
    $(C_PREPROCESSOR) $** > $@
    del $(SERVICES_DIR)\kesvc32.tab

# generate and binplace kesvc32.tab, which copywow64 uses to validate that
# the x86 and Win64 sides of the build process agree
$(KESVC_TAB): ..\..\ntos\ke\services.tab
    $(C_PREPROCESSOR) $** > $@
    binplace $@

$(O)\usrstubs.obj: \
    $(O)\usrstubs.$(ASM_SUFFIX) $(O)\ntdll.def

$(NTDLL_XTR): $(SERVICES_TAB)
    gensrv -f $(NTDLL_XTR) -s $(MAKEDIR) $(SERVICES_DIR)

$(O)\usrstubs.$(ASM_SUFFIX): $(SERVICES_TAB) ntwow64.tab
    copy $(SERVICES_TAB)+ntwow64.tab $(TEMP_DIR)\services.tab
    gensrv -d $(O) -e $(ASM_SUFFIX) $(TARGET_BRACES) -s $(MAKEDIR)\$(TARGET_DIRECTORY) $(TEMP_DIR)

$(O)\ntdll.def: ..\ntdlldef.src ..\$(TARGET_DIRECTORY)def.src $(NTDLL_XTR)
    copy ..\ntdlldef.src+..\$(TARGET_DIRECTORY)def.src+$(NTDLL_XTR) $(O)\ntdll.pp
    $(TARGET_CPP) /EP $(CDEFINES) $(O)\ntdll.pp > $(O)\ntdll.def
    -del $(O)\ntdll.pp

..\ntdll.rc: $(PROJECT_ROOT)\published\$(O)\ntstatus.rc $(PROJECT_ROOT)\published\$(O)\ntstatus_MSG00001.bin
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\base\ntos\ntoskrnl.inc ===
!if defined (BUILD_CHECKED_KERNEL)
NTDEBUG=ntsd
FREEBUILD=0
!endif

!if !$(FREEBUILD)
NT_UP=0
!endif

GPSIZE=32

VC7_SYMBOLS=1
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\base\ntdllsym\syminfo.c ===
/*++

Copyright (c) 2000  Microsoft Corporation

Module Name:

    syminfo.c

--*/


#include "ntos.h"
#include <nt.h>
#include <ntrtl.h>
#include <nturtl.h>
#include <heap.h>
#include "heappage.h"
#include "heappagi.h"
#include "stktrace.h"
#include <winsnmp.h>
#include <winsafer.h>

LDR_DATA_TABLE_ENTRY ldrentry;
PEB peb;
PEB_LDR_DATA ldrdata;
TEB teb;
HEAP heap;


// Make it build

int __cdecl main() { 
    return 0; 
}
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\base\ntdll\wow6432\wow64nt.c ===
/*++

Copyright (c) 2001  Microsoft Corporation

Module Name:

    wow64nt.c

Abstract:

    This module contains the Wow64 thunks to retreive information about the
    native system without actually thunking the values.

Author:

    Samer Arafeh (samera) 5-May-2001

Environment:

    User Mode only

Revision History:

--*/

#include "csrdll.h"
#include "ldrp.h"
#include "ntwow64.h"


NTSTATUS
RtlpWow64GetNativeSystemInformation(
    IN SYSTEM_INFORMATION_CLASS SystemInformationClass,
    IN PVOID NativeSystemInformation,
    IN ULONG InformationLength,
    OUT PULONG ReturnLength OPTIONAL
    )

/*++

Routine Description:

    This function queries information about the native system. This function has the same
    semantics as NtQuerySystemInformation.

Arguments:

    SystemInformationClass - The system information class about which
        to retrieve information.

    NativeSystemInformation - A pointer to a buffer which receives the specified
        information.  The format and content of the buffer depend on the
        specified system information class.
        
    SystemInformationLength - Specifies the length in bytes of the system
        information buffer.

    ReturnLength - An optional pointer which, if specified, receives the
        number of bytes placed in the system information buffer.
    
Return Value:

    NTSTATUS

--*/
{
    return NtWow64GetNativeSystemInformation(
        SystemInformationClass,
        NativeSystemInformation,
        InformationLength,
        ReturnLength
        );
}
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\base\ntdll\ia64\ldrthunk.s ===
//++
//
// Copyright (c) 1996  Intel Corporation
// Copyright (c) 1989  Microsoft Corporation
//
// Module Name:
//
//    ldrthunk.s
//
// Abstract:
//
//    This module implements the thunk for the LdrpInitialize APC routine.
//
// Author:
//
//    William K. Cheung (wcheung) 19-Sep-95
//
// Revision History:
//
//    08-Feb-96    Updated to EAS2.1
//
//--

#include "ksia64.h"

        .file    "ldrthunk.s"

        PublicFunction(LdrpInitialize)

//++
//
// VOID
// LdrInitializeThunk(
//    IN PVOID NormalContext,
//    IN PVOID SystemArgument1,
//    IN PVOID SystemArgument2
//    )
//
// Routine Description:
//
//    This function computes a pointer to the context record on the stack
//    and jumps to the LdrpInitialize function with that pointer as its
//    parameter.
//
// Arguments:
//
//    NormalContext (a0) - User Mode APC context parameter
//
//    SystemArgument1 (a1) - User Mode APC system argument 1
//
//    SystemArgument2 (a2) - User Mode APC system argument 2
//
// Return Value:
//
//    None.
//
//--

        NESTED_ENTRY(LdrInitializeThunk)

        NESTED_SETUP(3,2,3,0)
        mov         out2 = a2
        ;;

        PROLOGUE_END

//
// SP points at stack scratch area followed by context record.
//

        add         out0 = STACK_SCRATCH_AREA, sp       // pointer to context
        mov         out1 = a1                           // copy args
        br.call.sptk.many brp = LdrpInitialize

//
// S0 in the context record contains the PLabel.  Fix IIP/GP in the context
// record with the entry point and gp values pointed to by S0.
//

        add         t7 = CxIntGp+STACK_SCRATCH_AREA, sp     // -> global pointer
        add         t2 = CxIntS0+STACK_SCRATCH_AREA, sp     // -> PLabel pointer
        add         t11 = CxStIIP+STACK_SCRATCH_AREA, sp    // -> func pointer
        ;;

        ld8         t8 = [t2]                   // get the function pointer
        mov         brp = savedbrp              // restore brp
        mov         ar.pfs = savedpfs           // restore pfs
        ;;

        ld8         t5 = [t8], PlGlobalPointer-PlEntryPoint  // get entry point
        ;;
        ld8         t6 = [t8]                   // get gp
        nop.i       0
        ;;

        st8         [t11] = t5                  // set iip to entry point
        st8         [t7] = t6                   // set gp
        br.ret.sptk.clr brp

        NESTED_EXIT(LdrInitializeThunk)
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\base\ntdll\wow6432\wow64csr.c ===
/*++

Copyright (c) 1998  Microsoft Corporation

Module Name:

    wow64csr.c

Abstract:

    This module contains the WOW64 versions of the code for the Windows Client.
    See csr* files in ntos\dll for more function comments.

Author:

    Michael Zoran (mzoran) 2-JUN-1998

Environment:

    User Mode only

Revision History:

--*/

#include "csrdll.h"
#include "ldrp.h"
#include "ntwow64.h"

NTSTATUS
CsrClientConnectToServer(
    IN PWSTR ObjectDirectory,
    IN ULONG ServerDllIndex,
    IN PVOID ConnectionInformation,
    IN OUT PULONG ConnectionInformationLength OPTIONAL,
    OUT PBOOLEAN CalledFromServer OPTIONAL
    )

{
    return NtWow64CsrClientConnectToServer(ObjectDirectory,
                                           ServerDllIndex,
                                           ConnectionInformation,
                                           ConnectionInformationLength,
                                           CalledFromServer);
}

NTSTATUS
CsrNewThread(
    VOID
    )
{
    return NtWow64CsrNewThread();
}

NTSTATUS
CsrIdentifyAlertableThread( VOID )
{
    return NtWow64CsrIdentifyAlertableThread();
}

NTSTATUS
CsrSetPriorityClass(
    IN HANDLE ProcessHandle,
    IN OUT PULONG PriorityClass
    )
{

   return NtWow64CsrSetPriorityClass(ProcessHandle, PriorityClass);

}

NTSTATUS
CsrClientCallServer(
    IN OUT PCSR_API_MSG m,
    IN OUT PCSR_CAPTURE_HEADER CaptureBuffer OPTIONAL,
    IN CSR_API_NUMBER ApiNumber,
    IN ULONG ArgLength
    )
{

    return NtWow64CsrClientCallServer(m,CaptureBuffer,ApiNumber,ArgLength);
}


PCSR_CAPTURE_HEADER
CsrAllocateCaptureBuffer(
    IN ULONG CountMessagePointers,
    IN ULONG Sizecd
    )
{
   return NtWow64CsrAllocateCaptureBuffer(CountMessagePointers, Sizecd);
}


VOID
CsrFreeCaptureBuffer(
    IN PCSR_CAPTURE_HEADER CaptureBuffer
    )

{

    NtWow64CsrFreeCaptureBuffer(CaptureBuffer);
}


ULONG
CsrAllocateMessagePointer(
    IN OUT PCSR_CAPTURE_HEADER CaptureBuffer,
    IN ULONG Length,
    OUT PVOID *Pointer
    )
{

   return NtWow64CsrAllocateMessagePointer(CaptureBuffer, Length, Pointer);

}


VOID
CsrCaptureMessageBuffer(
    IN OUT PCSR_CAPTURE_HEADER CaptureBuffer,
    IN PVOID Buffer OPTIONAL,
    IN ULONG Length,
    OUT PVOID *CapturedBuffer
    )
{

   NtWow64CsrCaptureMessageBuffer(CaptureBuffer,Buffer,Length,CapturedBuffer);

}

VOID
CsrCaptureMessageString(
    IN OUT PCSR_CAPTURE_HEADER CaptureBuffer,
    IN PCSTR String OPTIONAL,
    IN ULONG Length,
    IN ULONG MaximumLength,
    OUT PSTRING CapturedString
    )

{

  NtWow64CsrCaptureMessageString(CaptureBuffer, String, Length, MaximumLength, CapturedString);

}



PLARGE_INTEGER
CsrCaptureTimeout(
    IN ULONG MilliSeconds,
    OUT PLARGE_INTEGER Timeout
    )
{
    if (MilliSeconds == -1) {
        return( NULL );
        }
    else {
        Timeout->QuadPart = Int32x32To64( MilliSeconds, -10000 );
        return( (PLARGE_INTEGER)Timeout );
        }
}

VOID
CsrProbeForWrite(
    IN PVOID Address,
    IN ULONG Length,
    IN ULONG Alignment
    )

/*++

Routine Description:

    This function probes a structure for read accessibility.
    If the structure is not accessible, then an exception is raised.

Arguments:

    Address - Supplies a pointer to the structure to be probed.

    Length - Supplies the length of the structure.

    Alignment - Supplies the required alignment of the structure expressed
        as the number of bytes in the primitive datatype (e.g., 1 for char,
        2 for short, 4 for long, and 8 for quad).

Return Value:

    None.

--*/

{
    volatile CHAR *StartAddress;
    volatile CHAR *EndAddress;
    CHAR Temp;

    //
    // If the structure has zero length, then do not probe the structure for
    // write accessibility or alignment.
    //

    if (Length != 0) {

        //
        // If the structure is not properly aligned, then raise a data
        // misalignment exception.
        //

        ASSERT((Alignment == 1) || (Alignment == 2) ||
               (Alignment == 4) || (Alignment == 8));
        StartAddress = (volatile CHAR *)Address;

        if (((ULONG_PTR)StartAddress & (Alignment - 1)) != 0) {
            RtlRaiseStatus(STATUS_DATATYPE_MISALIGNMENT);
        } else {
            //
            // BUG, BUG - this should not be necessary once the 386 kernel
            // makes system space inaccessable to user mode.
            //
            if ((ULONG_PTR)StartAddress > CsrNtSysInfo.MaximumUserModeAddress) {
                RtlRaiseStatus(STATUS_ACCESS_VIOLATION);
            }

            Temp = *StartAddress;
            *StartAddress = Temp;
            EndAddress = StartAddress + Length - 1;
            Temp = *EndAddress;
            *EndAddress = Temp;
        }
    }
}

VOID
CsrProbeForRead(
    IN PVOID Address,
    IN ULONG Length,
    IN ULONG Alignment
    )

/*++

Routine Description:

    This function probes a structure for read accessibility.
    If the structure is not accessible, then an exception is raised.

Arguments:

    Address - Supplies a pointer to the structure to be probed.

    Length - Supplies the length of the structure.

    Alignment - Supplies the required alignment of the structure expressed
        as the number of bytes in the primitive datatype (e.g., 1 for char,
        2 for short, 4 for long, and 8 for quad).

Return Value:

    None.

--*/

{
    volatile CHAR *StartAddress;
    volatile CHAR *EndAddress;
    CHAR Temp;

    //
    // If the structure has zero length, then do not probe the structure for
    // read accessibility or alignment.
    //

    if (Length != 0) {

        //
        // If the structure is not properly aligned, then raise a data
        // misalignment exception.
        //

        ASSERT((Alignment == 1) || (Alignment == 2) ||
               (Alignment == 4) || (Alignment == 8));
        StartAddress = (volatile CHAR *)Address;

        if (((ULONG_PTR)StartAddress & (Alignment - 1)) != 0) {
            RtlRaiseStatus(STATUS_DATATYPE_MISALIGNMENT);
        } else {
            Temp = *StartAddress;
            EndAddress = StartAddress + Length - 1;
            Temp = *EndAddress;
        }
    }
}

HANDLE
CsrGetProcessId(
    VOID
    )
{
    return NtWow64CsrGetProcessId ();
}


VOID
CsrCaptureMessageUnicodeStringInPlace(
    IN OUT PCSR_CAPTURE_HEADER CaptureBuffer,
    IN OUT PUNICODE_STRING     String
    )
/*++

Routine Description:

    This function captures an ASCII string into a counted string data
    structure located in an API request message.

Arguments:

    CaptureBuffer - Pointer to a capture buffer allocated by
        CsrAllocateCaptureBuffer.

    String - Optional pointer to the Unicode string.  If this parameter is
        not present, then the counted string data structure is set to
        the null string.

    Length - Length of the Unicode string in bytes, ignored if String is NULL.

    MaximumLength - Maximum length of the string.  Different for null
        terminated strings, where Length does not include the null and
        MaximumLength does. This is always how much space is allocated
        from the capture buffer.

    CaptureString - Pointer to the counted string data structure that will
        be filled in to point to the captured Unicode string.

Return Value:

    None, but if you don't trust the String parameter, use a __try block.

--*/
{
    ASSERT(String != NULL);

    CsrCaptureMessageString(
        CaptureBuffer,
        (PCSTR)String->Buffer,
        String->Length,
        String->MaximumLength,
        (PSTRING)String
        );

    // test > before substraction due to unsignedness
    if (String->MaximumLength > String->Length) {
        if ((String->MaximumLength - String->Length) >= sizeof(WCHAR)) {
            String->Buffer[ String->Length / sizeof(WCHAR) ] = 0;
            }
    }
}


NTSTATUS
CsrCaptureMessageMultiUnicodeStringsInPlace(
    IN OUT PCSR_CAPTURE_HEADER* InOutCaptureBuffer,
    IN ULONG                    NumberOfStringsToCapture,
    IN const PUNICODE_STRING*   StringsToCapture
    )
/*++

Routine Description:

    Capture multiple unicode strings.
    If the CaptureBuffer hasn't been allocated yet (passed as NULL), first
        allocate it.

Arguments:

    CaptureBuffer - Pointer to a capture buffer allocated by
        CsrAllocateCaptureBuffer, or NULL, in which case we call CsrAllocateCaptureBuffer
        for you; this is the case if you are only capturing these strings
        and nothing else.

    NumberOfStringsToCapture - 

    StringsToCapture - 

Return Value:

    NTSTATUS

--*/
{
    NTSTATUS Status = STATUS_SUCCESS;
    ULONG Length = 0;
    ULONG i = 0;
    PCSR_CAPTURE_HEADER CaptureBuffer = NULL;

    if (InOutCaptureBuffer == NULL) {
        Status = STATUS_INVALID_PARAMETER;
        goto Exit;
    }

    CaptureBuffer = *InOutCaptureBuffer;

    if (CaptureBuffer == NULL) {
        Length = 0;
        for (i = 0 ; i != NumberOfStringsToCapture ; ++i) {
            if (StringsToCapture[i] != NULL) {
                Length += StringsToCapture[i]->MaximumLength;
            }
        }
        CaptureBuffer = CsrAllocateCaptureBuffer(NumberOfStringsToCapture, Length);
        if (CaptureBuffer == NULL) {
            Status = STATUS_NO_MEMORY;
            goto Exit;
        }
        *InOutCaptureBuffer = CaptureBuffer;
    }
    for (i = 0 ; i != NumberOfStringsToCapture ; ++i) {
        if (StringsToCapture[i] != NULL) {
            CsrCaptureMessageUnicodeStringInPlace(
                CaptureBuffer,
                StringsToCapture[i]
                );
        } else {
        }
    }
    Status = STATUS_SUCCESS;
Exit:
    return Status;
}
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\base\ntdllsym\makefile.inc ===
$(O)\ntdll.c : syminfo.c
    $(CXX_COMPILER_NAME) @<<$(CL_RSP) /E $** > $@
$(CXX_COMPILER_FLAGS: =
)
<<NOKEEP
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\base\ntdll\wow6432\ntwow64.h ===
/*++

Copyright (c) 1998  Microsoft Corporation

Module Name:

    ntwow64.h

Abstract:

    This module contains headers for fake kernel entrypoints(wow64 BOPS) in ntdll.

Author:

    Michael Zoran (mzoran) 22-NOV-1998

Environment:

    User Mode only

Revision History:

    May 07, 2001   SamerA     Added NtWow64GetNativeSystemInformation()

--*/

NTSYSAPI
NTSTATUS
NTAPI
NtWow64CsrClientConnectToServer(
    IN PWSTR ObjectDirectory,
    IN ULONG ServerDllIndex,
    IN PVOID ConnectionInformation,
    IN OUT PULONG ConnectionInformationLength OPTIONAL,
    OUT PBOOLEAN CalledFromServer OPTIONAL
    );

NTSYSAPI
NTSTATUS
NTAPI
NtWow64CsrNewThread(
    VOID
    );

NTSYSAPI
NTSTATUS
NTAPI
NtWow64CsrIdentifyAlertableThread(
    VOID
    );

NTSYSAPI
NTSTATUS
NTAPI
NtWow64CsrClientCallServer(
    IN OUT PCSR_API_MSG m,
    IN OUT PCSR_CAPTURE_HEADER CaptureBuffer OPTIONAL,
    IN CSR_API_NUMBER ApiNumber,
    IN ULONG ArgLength
    );

NTSYSAPI
PCSR_CAPTURE_HEADER
NTAPI
NtWow64CsrAllocateCaptureBuffer(
    IN ULONG CountMessagePointers,
    IN ULONG Size
    );

NTSYSAPI
VOID
NTAPI
NtWow64CsrFreeCaptureBuffer(
    IN PCSR_CAPTURE_HEADER CaptureBuffer
    );

NTSYSAPI
ULONG
NTAPI
NtWow64CsrAllocateMessagePointer(
    IN OUT PCSR_CAPTURE_HEADER CaptureBuffer,
    IN ULONG Length,
    OUT PVOID *Pointer
    );

NTSYSAPI
VOID
NTAPI
NtWow64CsrCaptureMessageBuffer(
    IN OUT PCSR_CAPTURE_HEADER CaptureBuffer,
    IN PVOID Buffer OPTIONAL,
    IN ULONG Length,
    OUT PVOID *CapturedBuffer
    );

NTSYSAPI
VOID
NTAPI
NtWow64CsrCaptureMessageString(
    IN OUT PCSR_CAPTURE_HEADER CaptureBuffer,
    IN PCSTR String OPTIONAL,
    IN ULONG Length,
    IN ULONG MaximumLength,
    OUT PSTRING CapturedString
    );

NTSYSAPI
NTSTATUS
NTAPI
NtWow64CsrSetPriorityClass(
    IN HANDLE ProcessHandle,
    IN OUT PULONG PriorityClass
    );

NTSYSAPI
HANDLE
NTAPI
NtWow64CsrGetProcessId(
    VOID
    );

NTSYSAPI
NTSTATUS
NTAPI
NtDbgUiConnectToDbg( VOID );

NTSTATUS
NtDbgUiWaitStateChange (
    OUT PDBGUI_WAIT_STATE_CHANGE StateChange,
    IN PLARGE_INTEGER Timeout OPTIONAL
    );

NTSYSAPI
NTSTATUS
NTAPI
NtDbgUiContinue (
    IN PCLIENT_ID AppClientId,
    IN NTSTATUS ContinueStatus
    );

NTSYSAPI
NTSTATUS
NTAPI
NtDbgUiStopDebugging (
    IN HANDLE Process
    );

NTSYSAPI
NTSTATUS
NTAPI
NtDbgUiDebugActiveProcess (
    IN HANDLE Process
    );

NTSYSAPI
VOID
NTAPI
NtDbgUiRemoteBreakin (
    IN PVOID Context
    );

NTSYSAPI
HANDLE
NTAPI
NtDbgUiGetThreadDebugObject (
    VOID
    );



// This is used in place of INT 2D
NTSYSAPI
NTSTATUS
NtWow64DebuggerCall (
    IN ULONG ServiceClass,
    IN ULONG Arg1,
    IN ULONG Arg2,
    IN ULONG Arg3,
    IN ULONG Arg4
    );


NTSYSAPI
NTSTATUS
NtWow64GetNativeSystemInformation(
    IN SYSTEM_INFORMATION_CLASS SystemInformationClass,
    OUT PVOID NativeSystemInformation,
    IN ULONG InformationLength,
    OUT PULONG ReturnLength OPTIONAL
    );
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\base\ntos\arb\sources.inc ===
MAJORCOMP=ntos
MINORCOMP=arb

TARGETNAME=arb
TARGETTYPE=LIBRARY
TARGETPATH=obj

C_DEFINES=$(C_DEFINES) /DNTOS_KERNEL

INCLUDES=..\..\inc;$(DDK_INC_PATH)

SOURCES=..\arbiter.c \
        ..\debug.c
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\base\ntos\arb\arbp.h ===
#ifndef _ARBP_
#define _ARBP_

#ifndef FAR
#define FAR
#endif

#if DBG
#define ARB_DBG 1 // DBG
#endif

#if NTOS_KERNEL

//
// If we are in the kernel use the in-kernel headers so we get the efficient
// definitions of things
//

#include "ntos.h"
#include "zwapi.h"

#else

//
// If we are building the library for bus drivers to use make sure we use the 
// same definitions of things as them
//

#include "ntddk.h"

#endif

#include "arbiter.h"
#include <stdlib.h>     // for __min and __max


#if ARB_DBG

extern const CHAR* ArbpActionStrings[];
extern ULONG ArbStopOnError;
extern ULONG ArbReplayOnError;

VOID
ArbDumpArbiterInstance(
    LONG Level,
    PARBITER_INSTANCE Arbiter
    );

VOID
ArbDumpArbiterRange(
    LONG Level,
    PRTL_RANGE_LIST List,
    PUCHAR RangeText
    );

VOID
ArbDumpArbitrationList(
    LONG Level,
    PLIST_ENTRY ArbitrationList
    );

#endif // ARB_DBG

#endif _ARBP_
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\base\ntos\arb\debug.c ===
/*++

Copyright (c) 1997  Microsoft Corporation

Module Name:

    debug.c

Abstract:

    This module contains support routines for the Pnp resource arbiters.

Author:

    Andrew Thornton (andrewth) 19-June-1998


Environment:

    Kernel mode

Revision History:

--*/

#include "arbp.h"


//
// Debugging support
//

//
// Debug print level:
//    -1 = no messages
//     0 = vital messages only
//     1 = call trace
//     2 = verbose messages
//

//Present in retail builds
LONG ArbDebugLevel = -1;

#if ARB_DBG

//
// ArbStopOnError works just like a debug level variable except
// instead of controlling whether a message is printed, it controls
// whether we breakpoint on an error or not.  Likewise ArbReplayOnError
// controls if we replay fail arbitrations so we can debug them.
//

ULONG ArbStopOnError;
ULONG ArbReplayOnError;

const CHAR* ArbpActionStrings[] = {
    "ArbiterActionTestAllocation",
    "ArbiterActionRetestAllocation",
    "ArbiterActionCommitAllocation",
    "ArbiterActionRollbackAllocation",
    "ArbiterActionQueryAllocatedResources",
    "ArbiterActionWriteReservedResources",
    "ArbiterActionQueryConflict",
    "ArbiterActionQueryArbitrate",
    "ArbiterActionAddReserved",
    "ArbiterActionBootAllocation"
};

#ifdef ALLOC_PRAGMA
#pragma alloc_text(PAGE, ArbDumpArbiterRange)
#pragma alloc_text(PAGE, ArbDumpArbiterInstance)
#pragma alloc_text(PAGE, ArbDumpArbitrationList)
#endif

VOID
ArbDumpArbiterRange(
    LONG Level,
    PRTL_RANGE_LIST List,
    PUCHAR RangeText
    )

/*++

Routine Description:

    This dumps the contents of a range list to the debugger.

Parameters:

    Level     - The debug level at or above which the data should be displayed.
    List      - The range list to be displayed.
    RangeText - Informative text to go with the display.

Return Value:

    None

--*/

{
    PRTL_RANGE current;
    RTL_RANGE_LIST_ITERATOR iterator;
    BOOLEAN headerDisplayed = FALSE;

    PAGED_CODE();

    FOR_ALL_RANGES(List, &iterator, current) {

        if (headerDisplayed == FALSE) {
            headerDisplayed = TRUE;
            ARB_PRINT(Level, ("  %s:\n", RangeText));
        }

        ARB_PRINT(Level,
                    ("    %I64x-%I64x %s%s O=0x%08x U=0x%08x\n",
                    current->Start,
                    current->End,
                    current->Flags & RTL_RANGE_SHARED ? "S" : " ",
                    current->Flags & RTL_RANGE_CONFLICT ? "C" : " ",
                    current->Owner,
                    current->UserData
                   ));
    }
    if (headerDisplayed == FALSE) {
        ARB_PRINT(Level, ("  %s: <None>\n", RangeText));
    }
}

VOID
ArbDumpArbiterInstance(
    LONG Level,
    PARBITER_INSTANCE Arbiter
    )

/*++

Routine Description:

    This dumps the state of the arbiter to the debugger.

Parameters:

    Level - The debug level at or above which the data should be displayed.

    Arbiter - The arbiter instance to display

Return Value:

    None

--*/

{

    PAGED_CODE();

    ARB_PRINT(Level,
                ("---%S Arbiter State---\n",
                Arbiter->Name
                ));

    ArbDumpArbiterRange(
        Level,
        Arbiter->Allocation,
        "Allocation"
        );

    ArbDumpArbiterRange(
        Level,
        Arbiter->PossibleAllocation,
        "PossibleAllocation"
        );
}

VOID
ArbDumpArbitrationList(
    LONG Level,
    PLIST_ENTRY ArbitrationList
    )

/*++

Routine Description:

    Display the contents of an arbitration list.  That is, the
    set of resources (possibilities) we are trying to get.

Parameters:

    Level           - The debug level at or above which the data
                      should be displayed.
    ArbitrationList - The arbitration list to be displayed.

Return Value:

    None

--*/

{
    PARBITER_LIST_ENTRY current;
    PIO_RESOURCE_DESCRIPTOR alternative;
    PDEVICE_OBJECT previousOwner = NULL;
    UCHAR andOr = ' ';

    PAGED_CODE();

    ARB_PRINT(Level, ("Arbitration List\n"));

    FOR_ALL_IN_LIST(ARBITER_LIST_ENTRY, ArbitrationList, current) {

        if (previousOwner != current->PhysicalDeviceObject) {

            previousOwner = current->PhysicalDeviceObject;

            ARB_PRINT(
                Level,
                ("  Owning object 0x%08x\n",
                current->PhysicalDeviceObject
                ));
            ARB_PRINT(
                Level,
                ("    Length  Alignment   Minimum Address - Maximum Address\n"
                ));

        }

        FOR_ALL_IN_ARRAY(current->Alternatives,
                         current->AlternativeCount,
                         alternative) {

            ARB_PRINT(
                Level,
                ("%c %8x   %8x  %08x%08x - %08x%08x  %s\n",
                andOr,
                alternative->u.Generic.Length,
                alternative->u.Generic.Alignment,
                alternative->u.Generic.MinimumAddress.HighPart,
                alternative->u.Generic.MinimumAddress.LowPart,
                alternative->u.Generic.MaximumAddress.HighPart,
                alternative->u.Generic.MaximumAddress.LowPart,
                alternative->Type == CmResourceTypeMemory ?
                  "Memory"
                : "Port"
                ));
            andOr = '|';
        }
        andOr = '&';
    }
}

#endif // ARB_DBG
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\base\ntos\cache\cachedat.c ===
/*++

Copyright (c) 1990  Microsoft Corporation

Module Name:

    cachedat.c

Abstract:

    This module implements the Memory Management based cache management
    routines for the common Cache subsystem.

Author:

    Tom Miller      [TomM]      4-May-1990

Revision History:

--*/

#include "cc.h"

//
//  Global SharedCacheMap lists and resource to synchronize access to it.
//
//

// extern KSPIN_LOCK CcMasterSpinLock;
LIST_ENTRY CcCleanSharedCacheMapList;
SHARED_CACHE_MAP_LIST_CURSOR CcDirtySharedCacheMapList;
SHARED_CACHE_MAP_LIST_CURSOR CcLazyWriterCursor;

//
//  Worker thread structures:
//
//      A spinlock to synchronize all three lists.
//      A count of the number of worker threads Cc will use
//      A count of the number of worker threads Cc in use
//      A listhead for preinitialized executive work items for Cc use.
//      A listhead for an express queue of WORK_QUEUE_ENTRYs
//      A listhead for a regular queue of WORK_QUEUE_ENTRYs
//      A listhead for a post-tick queue of WORK_QUEUE_ENTRYs
//
//      A flag indicating if we are throttling the queue to a single thread
//

// extern KSPIN_LOCK CcWorkQueueSpinLock;
ULONG CcNumberWorkerThreads = 0;
ULONG CcNumberActiveWorkerThreads = 0;
LIST_ENTRY CcIdleWorkerThreadList;
LIST_ENTRY CcExpressWorkQueue;
LIST_ENTRY CcRegularWorkQueue;
LIST_ENTRY CcPostTickWorkQueue;

BOOLEAN CcQueueThrottle = FALSE;

//
//  Store the current idle delay and target time to clean all.  We must calculate
//  the idle delay in terms of clock ticks for the lazy writer timeout.
//

ULONG CcIdleDelayTick;
LARGE_INTEGER CcNoDelay;
LARGE_INTEGER CcFirstDelay = {(ULONG)-(3*LAZY_WRITER_IDLE_DELAY), -1};
LARGE_INTEGER CcIdleDelay = {(ULONG)-LAZY_WRITER_IDLE_DELAY, -1};
LARGE_INTEGER CcCollisionDelay = {(ULONG)-LAZY_WRITER_COLLISION_DELAY, -1};
LARGE_INTEGER CcTargetCleanDelay = {(ULONG)-(LONG)(LAZY_WRITER_IDLE_DELAY * (LAZY_WRITER_MAX_AGE_TARGET + 1)), -1};

//
//  Spinlock for controlling access to Vacb and related global structures,
//  and a counter indicating how many Vcbs are active.
//

// extern KSPIN_LOCK CcVacbSpinLock;
ULONG_PTR CcNumberVacbs;

//
//  Pointer to the global Vacb vector.
//

PVACB CcVacbs;
PVACB CcBeyondVacbs;
LIST_ENTRY CcVacbLru;
LIST_ENTRY CcVacbFreeList;
ULONG CcMaxVacbLevelsSeen = 1;
ULONG CcVacbLevelEntries = 0;
PVACB *CcVacbLevelFreeList = NULL;
ULONG CcVacbLevelWithBcbsEntries = 0;
PVACB *CcVacbLevelWithBcbsFreeList = NULL;

//
//  Deferred write list and respective Thresholds
//

extern KSPIN_LOCK CcDeferredWriteSpinLock;
LIST_ENTRY CcDeferredWrites;
ULONG CcDirtyPageThreshold;
ULONG CcDirtyPageTarget;
ULONG CcPagesYetToWrite;
ULONG CcPagesWrittenLastTime = 0;
ULONG CcDirtyPagesLastScan = 0;
ULONG CcAvailablePagesThreshold = 100;
ULONG CcTotalDirtyPages = 0;

//
//  Captured system size
//

MM_SYSTEMSIZE CcCapturedSystemSize;

//
//  Number of outstanding aggresive zeroers in the system.  Used
//  to throttle the activity.
//

LONG CcAggressiveZeroCount;
LONG CcAggressiveZeroThreshold;

//
//  Tuning options du Jour
//

ULONG CcTune = 0;

//
//  Global structure controlling lazy writer algorithms
//

LAZY_WRITER LazyWriter;

GENERAL_LOOKASIDE CcTwilightLookasideList;

#ifdef CCDBG

LONG CcDebugTraceLevel = 0;
LONG CcDebugTraceIndent = 0;

#ifdef CCDBG_LOCK
extern KSPIN_LOCK CcDebugTraceLock;
#endif //  def CCDBG_LOCK

#endif

//
//  Global list of pinned Bcbs which may be examined for debug purposes
//

#if DBG

ULONG CcBcbCount;
LIST_ENTRY CcBcbList;

#endif

//
//  Throw away miss counter.
//

ULONG CcThrowAway;

//
//  Performance Counters
//

ULONG CcFastReadNoWait;
ULONG CcFastReadWait;
ULONG CcFastReadResourceMiss;
ULONG CcFastReadNotPossible;

ULONG CcFastMdlReadNoWait;
ULONG CcFastMdlReadWait;
ULONG CcFastMdlReadResourceMiss;
ULONG CcFastMdlReadNotPossible;

ULONG CcMapDataNoWait;
ULONG CcMapDataWait;
ULONG CcMapDataNoWaitMiss;
ULONG CcMapDataWaitMiss;

ULONG CcPinMappedDataCount;

ULONG CcPinReadNoWait;
ULONG CcPinReadWait;
ULONG CcPinReadNoWaitMiss;
ULONG CcPinReadWaitMiss;

ULONG CcCopyReadNoWait;
ULONG CcCopyReadWait;
ULONG CcCopyReadNoWaitMiss;
ULONG CcCopyReadWaitMiss;

ULONG CcMdlReadNoWait;
ULONG CcMdlReadWait;
ULONG CcMdlReadNoWaitMiss;
ULONG CcMdlReadWaitMiss;

ULONG CcReadAheadIos;

ULONG CcLazyWriteHotSpots;
ULONG CcLazyWriteIos;
ULONG CcLazyWritePages;
ULONG CcDataFlushes;
ULONG CcDataPages;

ULONG CcLostDelayedWrites;

PULONG CcMissCounter = &CcThrowAway;
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\base\ntos\arb\arbiter.c ===
/*++

Copyright (c) 1997  Microsoft Corporation

Module Name:

    arbiter.c

Abstract:

    This module contains support routines for the Pnp resource arbiters.

Author:

    Andrew Thornton (andrewth) 1-April-1997


Environment:

    Kernel mode

Revision History:

--*/

#include "arbp.h"

#define REGSTR_KEY_ROOTENUM             L"ROOT"
//
// Conditional compilation constants
//

#define ALLOW_BOOT_ALLOC_CONFLICTS      1
#define PLUG_FEST_HACKS                 0

//
// Pool Tags
//

#define ARBITER_ALLOCATION_STATE_TAG    'AbrA'
#define ARBITER_ORDERING_LIST_TAG       'LbrA'
#define ARBITER_MISC_TAG                'MbrA'
#define ARBITER_RANGE_LIST_TAG          'RbrA'
#define ARBITER_CONFLICT_INFO_TAG       'CbrA'

//
// Constants
//

#define PATH_ARBITERS            L"\\Registry\\Machine\\System\\CurrentControlSet\\Control\\Arbiters"
#define KEY_ALLOCATIONORDER      L"AllocationOrder"
#define KEY_RESERVEDRESOURCES    L"ReservedResources"
#define ARBITER_ORDERING_GROW_SIZE  8


//
// Macros
//

//
// PVOID
// FULL_INFO_DATA(
//    IN PKEY_VALUE_FULL_INFORMATION k
// );
//
// This macro returns the pointer to the beginning of the data area of a
// KEY_VALUE_FULL_INFORMATION structure.
//

#define FULL_INFO_DATA(k) ((PCHAR)(k) + (k)->DataOffset)

//
// BOOLEAN
// DISJOINT(
//      IN ULONGLONG s1,
//      IN ULONGLONG e1,
//      IN ULONGLONG s2,
//      IN ULONGLONG e2
//      );
//
#define DISJOINT(s1,e1,s2,e2)                                           \
    ( ((s1) < (s2) && (e1) < (s2))                                      \
    ||((s2) < (s1) && (e2) < (s1)) )

//
// VOID
// ArbpWstrToUnicodeString(
//      IN PUNICODE_STRING u,
//      IN PWSTR p
//      );
//

#define ArbpWstrToUnicodeString(u, p)                                   \
    (u)->Length = ((u)->MaximumLength =                                 \
        (USHORT) (sizeof((p))) - sizeof(WCHAR));                        \
    (u)->Buffer = (p)

//
// ULONG
// INDEX_FROM_PRIORITY(
//     LONG Priority
// );
//

#define ORDERING_INDEX_FROM_PRIORITY(P)                                 \
    ( (ULONG) ( (P) > 0 ? (P) - 1 : ((P) * -1) - 1) )

//
// Prototypes
//

NTSTATUS
ArbpBuildAllocationStack(
    IN PARBITER_INSTANCE Arbiter,
    IN PLIST_ENTRY ArbitrationList,
    IN ULONG ArbitrationListCount
    );

NTSTATUS
ArbpGetRegistryValue(
    IN HANDLE KeyHandle,
    IN PWSTR  ValueName,
    OUT PKEY_VALUE_FULL_INFORMATION *Information
    );

NTSTATUS
ArbpBuildAlternative(
    IN PARBITER_INSTANCE Arbiter,
    IN PIO_RESOURCE_DESCRIPTOR Requirement,
    OUT PARBITER_ALTERNATIVE Alternative
    );

VOID
ArbpUpdatePriority(
    PARBITER_INSTANCE Arbiter,
    PARBITER_ALTERNATIVE Alternative
    );

BOOLEAN
ArbpQueryConflictCallback(
    IN PVOID Context,
    IN PRTL_RANGE Range
    );

BOOLEAN
ArbShareDriverExclusive(
    IN PARBITER_INSTANCE Arbiter,
    IN PARBITER_ALLOCATION_STATE State
    );

//
// Make everything pageable
//

#ifdef ALLOC_PRAGMA

VOID
ArbDereferenceArbiterInstance(
    IN PARBITER_INSTANCE Arbiter
    );

#pragma alloc_text(PAGE, ArbInitializeArbiterInstance)
#pragma alloc_text(PAGE, ArbDereferenceArbiterInstance)
#pragma alloc_text(PAGE, ArbDeleteArbiterInstance)
#pragma alloc_text(PAGE, ArbTestAllocation)
#pragma alloc_text(PAGE, ArbpBuildAlternative)
#pragma alloc_text(PAGE, ArbpBuildAllocationStack)
#pragma alloc_text(PAGE, ArbSortArbitrationList)
#pragma alloc_text(PAGE, ArbCommitAllocation)
#pragma alloc_text(PAGE, ArbRollbackAllocation)
#pragma alloc_text(PAGE, ArbRetestAllocation)
#pragma alloc_text(PAGE, ArbBootAllocation)
#pragma alloc_text(PAGE, ArbArbiterHandler)
#pragma alloc_text(PAGE, ArbBuildAssignmentOrdering)
#pragma alloc_text(PAGE, ArbFindSuitableRange)
#pragma alloc_text(PAGE, ArbAddAllocation)
#pragma alloc_text(PAGE, ArbBacktrackAllocation)
#pragma alloc_text(PAGE, ArbPreprocessEntry)
#pragma alloc_text(PAGE, ArbAllocateEntry)
#pragma alloc_text(PAGE, ArbGetNextAllocationRange)
#pragma alloc_text(PAGE, ArbpGetRegistryValue)
#pragma alloc_text(PAGE, ArbInitializeOrderingList)
#pragma alloc_text(PAGE, ArbCopyOrderingList)
#pragma alloc_text(PAGE, ArbAddOrdering)
#pragma alloc_text(PAGE, ArbPruneOrdering)
#pragma alloc_text(PAGE, ArbFreeOrderingList)
#pragma alloc_text(PAGE, ArbOverrideConflict)
#pragma alloc_text(PAGE, ArbpUpdatePriority)
#pragma alloc_text(PAGE, ArbAddReserved)
#pragma alloc_text(PAGE, ArbpQueryConflictCallback)
#pragma alloc_text(PAGE, ArbQueryConflict)
#pragma alloc_text(PAGE, ArbStartArbiter)
#pragma alloc_text(PAGE, ArbShareDriverExclusive)

#endif // ALLOC_PRAGMA

//
// Implementation
//


NTSTATUS
ArbInitializeArbiterInstance(
    OUT PARBITER_INSTANCE Arbiter,
    IN PDEVICE_OBJECT BusDeviceObject,
    IN CM_RESOURCE_TYPE ResourceType,
    IN PWSTR Name,
    IN PWSTR OrderingName,
    IN PARBITER_TRANSLATE_ALLOCATION_ORDER TranslateOrdering OPTIONAL
    )

/*++

Routine Description:

    This routine initializes an arbiter instance and fills in any optional NULL
    dispatch table entries with system default functions.

Parameters:

    Arbiter - A caller allocated arbiter instance structure.
        The UnpackRequirement, PackResource, UnpackResource and ScoreRequirement
        entries should be initialized with the appropriate routines as should
        any other entries if the default system routines are not sufficient.

    BusDeviceObject - The device object that exposes this arbiter - normally an
        FDO.

    ResourceType - The resource type this arbiter arbitrates.

    Name - A string used to identify the arbiter, used in debug messages and
        for registry storage

    OrderingName - The name of the preferred assignment ordering list under
        HKLM\System\CurrentControlSet\Control\SystemResources\AssignmentOrdering


    TranslateOrdering - Function that, if present, will be called to translate
        each descriptor from the ordering list

Return Value:

    Status code that indicates whether or not the function was successful.

Notes:


--*/

{
    NTSTATUS status;

    PAGED_CODE();

    ASSERT(Arbiter->UnpackRequirement);
    ASSERT(Arbiter->PackResource);
    ASSERT(Arbiter->UnpackResource);

    ARB_PRINT(2,("Initializing %S Arbiter...\n", Name));

    //
    // Initialize all pool allocation pointers to NULL so we can cleanup
    //

    ASSERT(Arbiter->MutexEvent == NULL
           && Arbiter->Allocation == NULL
           && Arbiter->PossibleAllocation == NULL
           && Arbiter->AllocationStack == NULL
           );

    //
    // We are an arbiter
    //

    Arbiter->Signature = ARBITER_INSTANCE_SIGNATURE;

    //
    // Remember the bus that produced us
    //

    Arbiter->BusDeviceObject = BusDeviceObject;

    //
    // Initialize state lock (KEVENT must be non-paged)
    //

    Arbiter->MutexEvent = ExAllocatePoolWithTag(NonPagedPool,
                                                sizeof(KEVENT),
                                                ARBITER_MISC_TAG
                                                );

    if (!Arbiter->MutexEvent) {
        status = STATUS_INSUFFICIENT_RESOURCES;
        goto cleanup;
    }

    KeInitializeEvent(Arbiter->MutexEvent, SynchronizationEvent, TRUE);

    //
    // Initialize the allocation stack to a reasonable size
    //

    Arbiter->AllocationStack = ExAllocatePoolWithTag(PagedPool,
                                                     INITIAL_ALLOCATION_STATE_SIZE,
                                                     ARBITER_ALLOCATION_STATE_TAG
                                                     );

    if (!Arbiter->AllocationStack) {
        status = STATUS_INSUFFICIENT_RESOURCES;
        goto cleanup;
    }

    Arbiter->AllocationStackMaxSize = INITIAL_ALLOCATION_STATE_SIZE;


    //
    // Allocate buffers to hold the range lists
    //

    Arbiter->Allocation = ExAllocatePoolWithTag(PagedPool,
                                                sizeof(RTL_RANGE_LIST),
                                                ARBITER_RANGE_LIST_TAG
                                                );

    if (!Arbiter->Allocation) {
        status = STATUS_INSUFFICIENT_RESOURCES;
        goto cleanup;
    }

    Arbiter->PossibleAllocation = ExAllocatePoolWithTag(PagedPool,
                                                        sizeof(RTL_RANGE_LIST),
                                                        ARBITER_RANGE_LIST_TAG
                                                        );

    if (!Arbiter->PossibleAllocation) {
        status = STATUS_INSUFFICIENT_RESOURCES;
        goto cleanup;
    }

    //
    // Initialize the range lists
    //

    RtlInitializeRangeList(Arbiter->Allocation);
    RtlInitializeRangeList(Arbiter->PossibleAllocation);

    //
    // Initialize the data fields
    //
    Arbiter->TransactionInProgress = FALSE;
    Arbiter->Name = Name;
    Arbiter->ResourceType = ResourceType;

    //
    // If the caller has not supplied the optional functions set them to the
    // defaults (If this were C++ we'd just inherit this loit but seeing as its
    // not we'll do it the old fashioned way...)
    //

    if (!Arbiter->TestAllocation) {
        Arbiter->TestAllocation = ArbTestAllocation;
    }

    if (!Arbiter->RetestAllocation) {
        Arbiter->RetestAllocation = ArbRetestAllocation;
    }

    if (!Arbiter->CommitAllocation) {
        Arbiter->CommitAllocation = ArbCommitAllocation;
    }

    if (!Arbiter->RollbackAllocation) {
        Arbiter->RollbackAllocation = ArbRollbackAllocation;
    }

    if (!Arbiter->AddReserved) {
        Arbiter->AddReserved = ArbAddReserved;
    }

    if (!Arbiter->PreprocessEntry) {
        Arbiter->PreprocessEntry = ArbPreprocessEntry;
    }

    if (!Arbiter->AllocateEntry) {
        Arbiter->AllocateEntry = ArbAllocateEntry;
    }

    if (!Arbiter->GetNextAllocationRange) {
        Arbiter->GetNextAllocationRange = ArbGetNextAllocationRange;
    }

    if (!Arbiter->FindSuitableRange) {
        Arbiter->FindSuitableRange = ArbFindSuitableRange;
    }

    if (!Arbiter->AddAllocation) {
        Arbiter->AddAllocation = ArbAddAllocation;
    }

    if (!Arbiter->BacktrackAllocation) {
        Arbiter->BacktrackAllocation = ArbBacktrackAllocation;
    }

    if (!Arbiter->OverrideConflict) {
        Arbiter->OverrideConflict = ArbOverrideConflict;
    }

    if (!Arbiter->BootAllocation) {
        Arbiter->BootAllocation = ArbBootAllocation;
    }

    if (!Arbiter->QueryConflict) {
        Arbiter->QueryConflict = ArbQueryConflict;
    }

    if (!Arbiter->StartArbiter) {
        Arbiter->StartArbiter = ArbStartArbiter;
    }

    //
    // Build the prefered assignment ordering - we assume that the reserved
    // ranges have the same name as the assignment ordering
    //

    status = ArbBuildAssignmentOrdering(Arbiter,
                                        OrderingName,
                                        OrderingName,
                                        TranslateOrdering
                                        );

    if (!NT_SUCCESS(status)) {
        goto cleanup;
    }

    return STATUS_SUCCESS;

cleanup:

    if (Arbiter->MutexEvent) {
        ExFreePool(Arbiter->MutexEvent);
    }

    if (Arbiter->Allocation) {
        ExFreePool(Arbiter->Allocation);
    }

    if (Arbiter->PossibleAllocation) {
        ExFreePool(Arbiter->PossibleAllocation);
    }

    if (Arbiter->AllocationStack) {
        ExFreePool(Arbiter->AllocationStack);
    }

    return status;

}

VOID
ArbReferenceArbiterInstance(
    IN PARBITER_INSTANCE Arbiter
    )
{
    InterlockedIncrement(&Arbiter->ReferenceCount);
}

VOID
ArbDereferenceArbiterInstance(
    IN PARBITER_INSTANCE Arbiter
    )
{
    PAGED_CODE();

    InterlockedDecrement(&Arbiter->ReferenceCount);

    if (Arbiter->ReferenceCount == 0) {
        ArbDeleteArbiterInstance(Arbiter);
    }
}

VOID
ArbDeleteArbiterInstance(
    IN PARBITER_INSTANCE Arbiter
    )
{

    PAGED_CODE();

    if (Arbiter->MutexEvent) {
        ExFreePool(Arbiter->MutexEvent);
    }

    if (Arbiter->Allocation) {
        RtlFreeRangeList(Arbiter->Allocation);
        ExFreePool(Arbiter->Allocation);
    }

    if (Arbiter->PossibleAllocation) {
        RtlFreeRangeList(Arbiter->PossibleAllocation);
        ExFreePool(Arbiter->PossibleAllocation);
    }

    if (Arbiter->AllocationStack) {
        ExFreePool(Arbiter->AllocationStack);
    }

    ArbFreeOrderingList(&Arbiter->OrderingList);
    ArbFreeOrderingList(&Arbiter->ReservedList);

#if ARB_DBG

    RtlFillMemory(Arbiter, sizeof(ARBITER_INSTANCE), 'A');

#endif

}

NTSTATUS
ArbTestAllocation(
    IN PARBITER_INSTANCE Arbiter,
    IN OUT PLIST_ENTRY ArbitrationList
    )

/*++

Routine Description:

    This is the default implementation of the arbiter Test Allocation action.
    It takes a list of requests for resources for particular devices and attempts
    to satisfy them.

Parameters:

    Arbiter - The instance of the arbiter being called.

    ArbitrationList - A list of ARBITER_LIST_ENTRY entries which contain the
        requirements and associated devices.

Return Value:

    Status code that indicates whether or not the function was successful.
    These include:

    STATUS_SUCCESSFUL - Arbitration suceeded and an allocation has been made for
        all the entries in the arbitration list.

    STATUS_UNSUCCESSFUL - Arbitration failed to find an allocation for all
        entries.

    STATUS_ARBITRATION_UNHANDLED - If returning this error the arbiter is
        partial (and therefore must have set the ARBITER_PARTIAL flag in its
        interface.)  This status indicates that this arbiter doesn't handle the
        resources requested and the next arbiter towards the root of the device
        tree should be asked instead.

--*/

{

    NTSTATUS status;
    PARBITER_LIST_ENTRY current;
    PIO_RESOURCE_DESCRIPTOR alternative;
    ULONG count;
    PDEVICE_OBJECT previousOwner;
    PDEVICE_OBJECT currentOwner;
    LONG score;
    BOOLEAN performScoring;

    PAGED_CODE();
    ASSERT(Arbiter);

    //
    // Copy the current allocation
    //

    ARB_PRINT(3, ("Copy current allocation\n"));
    status = RtlCopyRangeList(Arbiter->PossibleAllocation, Arbiter->Allocation);

    if (!NT_SUCCESS(status)) {
        goto cleanup;
    }

    //
    // Free all the resources currently allocated to all the devices we
    // are arbitrating for
    //

    count = 0;
    previousOwner = NULL;

    FOR_ALL_IN_LIST(ARBITER_LIST_ENTRY, ArbitrationList, current) {

        count++;

        currentOwner = current->PhysicalDeviceObject;

        if (previousOwner != currentOwner) {

            previousOwner = currentOwner;

            ARB_PRINT(3,
                        ("Delete 0x%08x's resources\n",
                        currentOwner
                        ));

            status = RtlDeleteOwnersRanges(Arbiter->PossibleAllocation,
                                           (PVOID)currentOwner
                                           );

            if (!NT_SUCCESS(status)) {
                goto cleanup;
            }
        }

        //
        // Score the entries in the arbitration list if a scoring function was
        // provided and this is not a legacy request (which is guaranteed to be
        // made of all fixed requests so sorting is pointless)
        //

        performScoring = Arbiter->ScoreRequirement != NULL;
        //
        // ISSUE-2000/03/06-andrewth
        // Ensure that in the start and enum cleanup the RequestSource is correctly passed in
        // so we can safely skip the unnecesary scoring and sorting
        // && !LEGACY_REQUEST(current);
        //
        current->WorkSpace = 0;

        if (performScoring) {

            FOR_ALL_IN_ARRAY(current->Alternatives,
                             current->AlternativeCount,
                             alternative) {

                ARB_PRINT(3,
                            ("Scoring entry %p\n",
                            currentOwner
                            ));



                score = Arbiter->ScoreRequirement(alternative);

                //
                // Ensure the score is valid
                //

                if (score < 0) {
                    status = STATUS_DEVICE_CONFIGURATION_ERROR;
                    goto cleanup;
                }

                current->WorkSpace += score;
            }
        }
    }

    status = ArbSortArbitrationList(ArbitrationList);

    if (!NT_SUCCESS(status)) {
        goto cleanup;
    }

    //
    // Build the arbitration stack
    //

    status = ArbpBuildAllocationStack(Arbiter,
                                     ArbitrationList,
                                     count
                                     );

    if (!NT_SUCCESS(status)) {
        goto cleanup;
    }

    //
    // Attempt allocation
    //

    status = Arbiter->AllocateEntry(Arbiter, Arbiter->AllocationStack);

    if (NT_SUCCESS(status)) {

        //
        // Success.
        //

        return status;
    }

cleanup:

    //
    // We didn't succeed so empty the possible allocation list...
    //

    RtlFreeRangeList(Arbiter->PossibleAllocation);

    return status;
}


NTSTATUS
ArbpBuildAlternative(
    IN PARBITER_INSTANCE Arbiter,
    IN PIO_RESOURCE_DESCRIPTOR Requirement,
    OUT PARBITER_ALTERNATIVE Alternative
    )

/*++

Routine Description:

    This routine initializes a arbiter alternative from a given resource
    requirement descriptor

Parameters:

    Arbiter - The arbiter instance data where the allocation stack should be
        placed.

    Requirement - The requirement descriptor describing this requirement

    Alternative - The alternative to be initialized

Return Value:

    Status code that indicates whether or not the function was successful.

--*/

{

    NTSTATUS status;

    PAGED_CODE();
    ASSERT(Alternative && Requirement);

    Alternative->Descriptor = Requirement;

    //
    // Unpack the requirement into the alternatives table
    //

    status = Arbiter->UnpackRequirement(Requirement,
                                        &Alternative->Minimum,
                                        &Alternative->Maximum,
                                        &Alternative->Length,
                                        &Alternative->Alignment
                                        );

    if (!NT_SUCCESS(status)) {
        goto cleanup;
    }

    //
    // Align the minimum if necessary
    //

    if (Alternative->Minimum % Alternative->Alignment != 0) {
        ALIGN_ADDRESS_UP(Alternative->Minimum,
                         Alternative->Alignment
                         );
    }

    Alternative->Flags = 0;

    //
    // Check if this alternative is shared
    //

    if(Requirement->ShareDisposition == CmResourceShareShared) {
        Alternative->Flags |= ARBITER_ALTERNATIVE_FLAG_SHARED;
    }

    //
    // Check if this alternative is fixed
    //

    if (Alternative->Maximum - Alternative->Minimum + 1 == Alternative->Length) {
        Alternative->Flags |= ARBITER_ALTERNATIVE_FLAG_FIXED;
    }

    //
    // Check for validity
    //

    if (Alternative->Maximum < Alternative->Minimum) {
        Alternative->Flags |= ARBITER_ALTERNATIVE_FLAG_INVALID;
    }

    return STATUS_SUCCESS;

cleanup:

    return status;
}


NTSTATUS
ArbpBuildAllocationStack(
    IN PARBITER_INSTANCE Arbiter,
    IN PLIST_ENTRY ArbitrationList,
    IN ULONG ArbitrationListCount
    )

/*++

Routine Description:

    This routine initializes the allocation stack for the requests in
    ArbitrationList.  It overwrites any previous allocation stack and allocates
    additional memory if more is required.  Arbiter->AllocationStack contains
    the initialized stack on success.

Parameters:

    Arbiter - The arbiter instance data where the allocation stack should be
        placed.

    ArbitrationList - A list of ARBITER_LIST_ENTRY entries which contain the
        requirements and associated devices.

    ArbitrationListCount - The number of entries in the ArbitrationList

Return Value:

    Status code that indicates whether or not the function was successful.

--*/

{
    NTSTATUS status;
    PARBITER_LIST_ENTRY currentEntry;
    PARBITER_ALLOCATION_STATE currentState;
    ULONG stackSize = 0, allocationCount = ArbitrationListCount + 1;
    PARBITER_ALTERNATIVE currentAlternative;
    PIO_RESOURCE_DESCRIPTOR currentDescriptor;

    PAGED_CODE();

    //
    // Calculate the size the stack needs to be and the
    //

    FOR_ALL_IN_LIST(ARBITER_LIST_ENTRY, ArbitrationList, currentEntry) {

        if (currentEntry->AlternativeCount > 0) {
            stackSize += currentEntry->AlternativeCount
                            * sizeof(ARBITER_ALTERNATIVE);
        } else {
            allocationCount--;
        }
    }

    stackSize += allocationCount * sizeof(ARBITER_ALLOCATION_STATE);

    //
    // Make sure the allocation stack is large enough
    //

    if (Arbiter->AllocationStackMaxSize < stackSize) {

        PARBITER_ALLOCATION_STATE temp;

        //
        // Enlarge the allocation stack
        //

        temp = ExAllocatePoolWithTag(PagedPool,
                                     stackSize,
                                     ARBITER_ALLOCATION_STATE_TAG
                                     );
        if (!temp) {
            return STATUS_INSUFFICIENT_RESOURCES;
        }

        ExFreePool(Arbiter->AllocationStack);
        Arbiter->AllocationStack = temp;
    }

    RtlZeroMemory(Arbiter->AllocationStack, stackSize);

    //
    // Fill in the locations
    //

    currentState = Arbiter->AllocationStack;
    currentAlternative = (PARBITER_ALTERNATIVE) (Arbiter->AllocationStack
        + ArbitrationListCount + 1);

    FOR_ALL_IN_LIST(ARBITER_LIST_ENTRY, ArbitrationList, currentEntry) {

        //
        // Do we need to allocate anything for this entry?
        //

        if (currentEntry->AlternativeCount > 0) {

            //
            // Initialize the stack location
            //

            currentState->Entry = currentEntry;
            currentState->AlternativeCount = currentEntry->AlternativeCount;
            currentState->Alternatives = currentAlternative;

            //
            // Initialize the start and end values to an invalid range so
            // that we don't skip the range 0-0 every time...
            //

            currentState->Start = 1;
            ASSERT(currentState->End == 0);  // From RtlZeroMemory

            //
            // Initialize the alternatives table
            //

            FOR_ALL_IN_ARRAY(currentEntry->Alternatives,
                             currentEntry->AlternativeCount,
                             currentDescriptor) {


                status = ArbpBuildAlternative(Arbiter,
                                            currentDescriptor,
                                            currentAlternative
                                            );

                if (!NT_SUCCESS(status)) {
                    goto cleanup;
                }

                //
                // Initialize the priority
                //

                currentAlternative->Priority = ARBITER_PRIORITY_NULL;

                //
                // Advance to the next alternative
                //

                currentAlternative++;

            }
        }
        currentState++;
    }

    //
    // Terminate the stack with NULL entry
    //

    currentState->Entry = NULL;

    return STATUS_SUCCESS;

cleanup:

    //
    // We don't need to free the buffer as it is attached to the arbiter and
    // will be used next time
    //

    return status;
}

NTSTATUS
ArbSortArbitrationList(
    IN OUT PLIST_ENTRY ArbitrationList
    )

/*++

Routine Description:

    This routine sorts the arbitration list in order of each entry's
    WorkSpace value.

Parameters:

    ArbitrationList - The list to be sorted.

Return Value:

    Status code that indicates whether or not the function was successful.

--*/

{
    BOOLEAN sorted = FALSE;
    PARBITER_LIST_ENTRY current, next;

    PAGED_CODE();

    ARB_PRINT(3, ("IoSortArbiterList(%p)\n", ArbitrationList));

    while (!sorted) {

        sorted = TRUE;

        for (current=(PARBITER_LIST_ENTRY) ArbitrationList->Flink,
               next=(PARBITER_LIST_ENTRY) current->ListEntry.Flink;

            (PLIST_ENTRY) current != ArbitrationList
               && (PLIST_ENTRY) next != ArbitrationList;

            current = (PARBITER_LIST_ENTRY) current->ListEntry.Flink,
                next = (PARBITER_LIST_ENTRY)current->ListEntry.Flink) {


            if (current->WorkSpace > next->WorkSpace) {

                PLIST_ENTRY before = current->ListEntry.Blink;
                PLIST_ENTRY after = next->ListEntry.Flink;

                //
                // Swap the locations of current and next
                //

                before->Flink = (PLIST_ENTRY) next;
                after->Blink = (PLIST_ENTRY) current;
                current->ListEntry.Flink = after;
                current->ListEntry.Blink = (PLIST_ENTRY) next;
                next->ListEntry.Flink = (PLIST_ENTRY) current;
                next->ListEntry.Blink = before;

                sorted = FALSE;
            }
        }
    }

    return STATUS_SUCCESS;
}

NTSTATUS
ArbCommitAllocation(
    PARBITER_INSTANCE Arbiter
    )

/*++

Routine Description:

    This provides the default implementation of the CommitAllocation action.
    It frees the old allocation and replaces it with the new allocation.

Parameters:

    Arbiter - The arbiter instance data for the arbiter being called.

Return Value:

    Status code that indicates whether or not the function was successful.

--*/

{
    PRTL_RANGE_LIST temp;

    PAGED_CODE();

    //
    // Free up the current allocation
    //

    RtlFreeRangeList(Arbiter->Allocation);

    //
    // Swap the allocated and duplicate lists
    //

    temp = Arbiter->Allocation;
    Arbiter->Allocation = Arbiter->PossibleAllocation;
    Arbiter->PossibleAllocation = temp;

    return STATUS_SUCCESS;
}

NTSTATUS
ArbRollbackAllocation(
    IN PARBITER_INSTANCE Arbiter
    )

/*++

Routine Description:

    This provides the default implementation of the RollbackAllocation action.
    It frees the possible allocation the last TestAllocation provided.

Parameters:

    Arbiter - The arbiter instance data for the arbiter being called.

Return Value:

    Status code that indicates whether or not the function was successful.

--*/

{

    PAGED_CODE();

    //
    // Free up the possible allocation
    //

    RtlFreeRangeList(Arbiter->PossibleAllocation);

    return STATUS_SUCCESS;
}

NTSTATUS
ArbRetestAllocation(
    IN PARBITER_INSTANCE Arbiter,
    IN OUT PLIST_ENTRY ArbitrationList
    )

/*++

Routine Description:

    This provides the default implementation of the RetestAllocation action.
    It walks the arbitration list and updates the possible allocation to reflect
    the allocation entries of the list.  For these entries to be valid
    TestAllocation must have been performed on this arbitration list.

Parameters:

    Arbiter - The arbiter instance data for the arbiter being called.

    ArbitrationList - A list of ARBITER_LIST_ENTRY entries which contain the
        requirements and associated devices.  TestAllocation for this arbiter
        should have been called on this list.

Return Value:

    Status code that indicates whether or not the function was successful.

--*/

{
    NTSTATUS status;
    PARBITER_LIST_ENTRY current;
    ARBITER_ALLOCATION_STATE state;
    ARBITER_ALTERNATIVE alternative;
    ULONG length;

    PAGED_CODE();

    //
    // Initialize the state
    //

    RtlZeroMemory(&state, sizeof(ARBITER_ALLOCATION_STATE));
    RtlZeroMemory(&alternative, sizeof(ARBITER_ALTERNATIVE));
    state.AlternativeCount = 1;
    state.Alternatives = &alternative;
    state.CurrentAlternative = &alternative;
    state.Flags = ARBITER_STATE_FLAG_RETEST;

    //
    // Copy the current allocation and reserved
    //

    ARB_PRINT(2, ("Retest: Copy current allocation\n"));
    status = RtlCopyRangeList(Arbiter->PossibleAllocation, Arbiter->Allocation);

    if (!NT_SUCCESS(status)) {
        goto cleanup;
    }

    //
    // Free all the resources currently allocated to all the devices we
    // are arbitrating for
    //

    FOR_ALL_IN_LIST(ARBITER_LIST_ENTRY, ArbitrationList, current) {

        ARB_PRINT(3,
                    ("Retest: Delete 0x%08x's resources\n",
                    current->PhysicalDeviceObject
                    ));

        status = RtlDeleteOwnersRanges(Arbiter->PossibleAllocation,
                                       (PVOID) current->PhysicalDeviceObject
                                       );

        if (!NT_SUCCESS(status)) {
            goto cleanup;
        }
    }

    //
    // Build an allocation state for the allocation and call AddAllocation to
    // update the range lists accordingly
    //

    FOR_ALL_IN_LIST(ARBITER_LIST_ENTRY, ArbitrationList, current) {

        ASSERT(current->Assignment && current->SelectedAlternative);

        state.WorkSpace = 0;
        state.Entry = current;

        //
        // Initialize the alternative
        //

        status = ArbpBuildAlternative(Arbiter,
                                    current->SelectedAlternative,
                                    &alternative
                                    );

        ASSERT(NT_SUCCESS(status));

        //
        // Update it with our allocation
        //

        status = Arbiter->UnpackResource(current->Assignment,
                                         &state.Start,
                                         &length
                                         );

        ASSERT(NT_SUCCESS(status));

        state.End = state.Start + length - 1;

        //
        // Do any preprocessing that is required
        //

        status = Arbiter->PreprocessEntry(Arbiter,&state);

        if (!NT_SUCCESS(status)) {
            goto cleanup;
        }

        //
        // If we had a requirement for length 0 then don't attemp to add the
        // range - it will fail!
        //

        if (length != 0) {

            Arbiter->AddAllocation(Arbiter, &state);

        }
    }

    return status;

cleanup:

    RtlFreeRangeList(Arbiter->PossibleAllocation);
    return status;
}

NTSTATUS
ArbBootAllocation(
    IN PARBITER_INSTANCE Arbiter,
    IN OUT PLIST_ENTRY ArbitrationList
    )
/*++

Routine Description:

    This provides the default implementation of the BootAllocation action.
    It walks the arbitration list and updates the allocation to reflect the fact
    that the allocation entries in the list are in use.

Parameters:

    Arbiter - The arbiter instance data for the arbiter being called.

    ArbitrationList - A list of ARBITER_LIST_ENTRY entries which contain the
        requirements and associated devices.  Each device should have one and
        only one requirement reflecting the resources it is currently consuming.

Return Value:

    Status code that indicates whether or not the function was successful.

--*/

{

    NTSTATUS status;
    PARBITER_LIST_ENTRY current;
    PRTL_RANGE_LIST temp;
    ARBITER_ALLOCATION_STATE state;
    ARBITER_ALTERNATIVE alternative;

    PAGED_CODE();

    //
    // Initialize the state
    //

    RtlZeroMemory(&state, sizeof(ARBITER_ALLOCATION_STATE));
    RtlZeroMemory(&alternative, sizeof(ARBITER_ALTERNATIVE));
    state.AlternativeCount = 1;
    state.Alternatives = &alternative;
    state.CurrentAlternative = &alternative;
    state.Flags = ARBITER_STATE_FLAG_BOOT;
    state.RangeAttributes = ARBITER_RANGE_BOOT_ALLOCATED;

    //
    // Work on the possible allocation list
    //

    status = RtlCopyRangeList(Arbiter->PossibleAllocation, Arbiter->Allocation);

    FOR_ALL_IN_LIST(ARBITER_LIST_ENTRY, ArbitrationList, current) {

        ASSERT(current->AlternativeCount == 1);
        ASSERT(current->PhysicalDeviceObject);

        //
        // Build an alternative and state structure for this allocation and
        // add it to the range list
        //

        state.Entry = current;

        //
        // Initialize the alternative
        //

        status = ArbpBuildAlternative(Arbiter,
                                    &current->Alternatives[0],
                                    &alternative
                                    );

        ASSERT(NT_SUCCESS(status));
        ASSERT(alternative.Flags &
               (ARBITER_ALTERNATIVE_FLAG_FIXED | ARBITER_ALTERNATIVE_FLAG_INVALID)
               );

        state.Start = alternative.Minimum;
        state.End = alternative.Maximum;

        //
        // Blow away the old workspace and masks
        //

        state.WorkSpace = 0;
        state.RangeAvailableAttributes = 0;

        //
        // Validate the requirement
        //

        if (alternative.Length == 0
        || alternative.Alignment == 0
        || state.End < state.Start
        || state.Start % alternative.Alignment != 0
        || LENGTH_OF(state.Start, state.End) != alternative.Length) {

            ARB_PRINT(1,
                        ("Skipping invalid boot allocation 0x%I64x-0x%I64x L 0x%x A 0x%x for 0x%08x\n",
                         state.Start,
                         state.End,
                         alternative.Length,
                         alternative.Alignment,
                         current->PhysicalDeviceObject
                         ));

            continue;
        }

#if PLUG_FEST_HACKS

        if (alternative.Flags & ARBITER_ALTERNATIVE_FLAG_SHARED) {

            ARB_PRINT(1,
                         ("Skipping shared boot allocation 0x%I64x-0x%I64x L 0x%x A 0x%x for 0x%08x\n",
                          state.Start,
                          state.End,
                          alternative.Length,
                          alternative.Alignment,
                          current->PhysicalDeviceObject
                          ));

            continue;
        }
#endif


        //
        // Do any preprocessing that is required
        //

        status = Arbiter->PreprocessEntry(Arbiter,&state);

        if (!NT_SUCCESS(status)) {
            goto cleanup;;
        }

        Arbiter->AddAllocation(Arbiter, &state);

    }

    //
    // Everything went OK so make this our allocated range
    //

    RtlFreeRangeList(Arbiter->Allocation);
    temp = Arbiter->Allocation;
    Arbiter->Allocation = Arbiter->PossibleAllocation;
    Arbiter->PossibleAllocation = temp;

    return STATUS_SUCCESS;

cleanup:

    RtlFreeRangeList(Arbiter->PossibleAllocation);
    return status;

}


NTSTATUS
ArbArbiterHandler(
    IN PVOID Context,
    IN ARBITER_ACTION Action,
    IN OUT PARBITER_PARAMETERS Params
    )

/*++

Routine Description:

    This provides the default entry point to an arbiter.

Parameters:

    Context - The context provided in the interface where this function was
        called from.  This is converted to an ARBITER_INSTANCE using the
        ARBITER_CONTEXT_TO_INSTANCE macro which should be defined.

    Action - The action the arbiter should perform.

    Params - The parameters for the action.

Return Value:

    Status code that indicates whether or not the function was successful.

Note:

    The routines which implement each action are determined from the dispatch
    table in the arbiter instance.

--*/

{

    NTSTATUS status;
    PARBITER_INSTANCE arbiter = Context;

    PAGED_CODE();
    ASSERT(Context);
    ASSERT(Action >= 0 && Action <= ArbiterActionBootAllocation);
    ASSERT(arbiter->Signature == ARBITER_INSTANCE_SIGNATURE);

    //
    // Acquire the state lock
    //

    ArbAcquireArbiterLock(arbiter);

    //
    // Announce ourselves
    //

    ARB_PRINT(2,
                ("%s %S\n",
                ArbpActionStrings[Action],
                arbiter->Name
                ));

    //
    // Check the transaction flag
    //

    if (Action == ArbiterActionTestAllocation
    ||  Action == ArbiterActionRetestAllocation
    ||  Action == ArbiterActionBootAllocation) {

        ASSERT(!arbiter->TransactionInProgress);

    } else if (Action == ArbiterActionCommitAllocation
           ||  Action == ArbiterActionRollbackAllocation) {

        ASSERT(arbiter->TransactionInProgress);
    }

#if ARB_DBG

replay:

#endif

    //
    // Do the appropriate thing
    //

    switch (Action) {

    case ArbiterActionTestAllocation:

        //
        // NTRAID #95564-2000/02/31-andrewth
        // Until we support rebalance we don't deal with AllocateFrom
        //

        ASSERT(Params->Parameters.TestAllocation.AllocateFromCount == 0);
        ASSERT(Params->Parameters.TestAllocation.AllocateFrom == NULL);

        status = arbiter->TestAllocation(
                     arbiter,
                     Params->Parameters.TestAllocation.ArbitrationList
                     );
        break;

    case ArbiterActionRetestAllocation:

        ASSERT(Params->Parameters.TestAllocation.AllocateFromCount == 0);
        ASSERT(Params->Parameters.TestAllocation.AllocateFrom == NULL);

        status = arbiter->RetestAllocation(
                     arbiter,
                     Params->Parameters.TestAllocation.ArbitrationList
                     );
        break;

    case ArbiterActionCommitAllocation:

        status = arbiter->CommitAllocation(arbiter);

        break;

    case ArbiterActionRollbackAllocation:

        status = arbiter->RollbackAllocation(arbiter);

        break;

    case ArbiterActionBootAllocation:

        status = arbiter->BootAllocation(
                    arbiter,
                    Params->Parameters.BootAllocation.ArbitrationList
                    );
        break;

    case ArbiterActionQueryConflict:

        status = arbiter->QueryConflict(
                    arbiter,
                    Params->Parameters.QueryConflict.PhysicalDeviceObject,
                    Params->Parameters.QueryConflict.ConflictingResource,
                    Params->Parameters.QueryConflict.ConflictCount,
                    Params->Parameters.QueryConflict.Conflicts
                    );
        break;

    case ArbiterActionQueryArbitrate:
    case ArbiterActionQueryAllocatedResources:
    case ArbiterActionWriteReservedResources:
    case ArbiterActionAddReserved:

        status = STATUS_NOT_IMPLEMENTED;
        break;

    default:
        status = STATUS_INVALID_PARAMETER;
        break;
    }

#if ARB_DBG

    //
    // Check if we failed and want to stop or replay on errors
    //

    if (!NT_SUCCESS(status)) {

        ARB_PRINT(1,
                 ("*** %s for %S FAILED status = %08x\n",
                  ArbpActionStrings[Action],
                  arbiter->Name,
                  status
                 ));

        if (ArbStopOnError) {
            DbgBreakPoint();
        }

        if (ArbReplayOnError) {
            goto replay;
        }
    }

#endif // ARB_DBG

    if (NT_SUCCESS(status)) {

        if (Action == ArbiterActionTestAllocation
        ||  Action == ArbiterActionRetestAllocation) {

            arbiter->TransactionInProgress = TRUE;

        } else if (Action == ArbiterActionCommitAllocation
               ||  Action == ArbiterActionRollbackAllocation) {

            arbiter->TransactionInProgress = FALSE;
        }
    }

    ArbReleaseArbiterLock(arbiter);

    return status;

}

NTSTATUS
ArbBuildAssignmentOrdering(
    IN OUT PARBITER_INSTANCE Arbiter,
    IN PWSTR AllocationOrderName,
    IN PWSTR ReservedResourcesName,
    IN PARBITER_TRANSLATE_ALLOCATION_ORDER Translate OPTIONAL
    )

/*++

Routine Description:

    This is called as part of arbiter initialization and extracts the allocation
    ordering and reserved information from the registry and combines them into
    an ordering list.  The reserved ranges are put in Arbiter->ReservedList
    and the initial ordering in Arbiter->OrderingList.

Parameters:

    Arbiter - The instance data of the arbiter to be initialized.

    AllocationOrderName - The name of the key under HKLM\System\
        CurrentControlSet\Control\Arbiters\AllocationOrder the ordering
        information should be taken from.

    ReservedResourcesName - The name of the key under HKLM\System\
        CurrentControlSet\Control\Arbiters\ReservedResources the reserved ranges
        information should be taken from.

    Translate - A function to be called for each range that will perform system
        dependant translations required for this system.

Return Value:

    Status code that indicates whether or not the function was successful.

--*/

{
    NTSTATUS status;
    HANDLE arbitersHandle = NULL, tempHandle = NULL;
    UNICODE_STRING unicodeString;
    PKEY_VALUE_FULL_INFORMATION info = NULL;
    ULONG dummy;
    PIO_RESOURCE_LIST resourceList;
    PIO_RESOURCE_DESCRIPTOR current;
    ULONGLONG start, end;
    OBJECT_ATTRIBUTES attributes;
    IO_RESOURCE_DESCRIPTOR translated;

    PAGED_CODE();

    ArbAcquireArbiterLock(Arbiter);

    //
    // If we are reinitializing the orderings free the old ones
    //

    ArbFreeOrderingList(&Arbiter->OrderingList);
    ArbFreeOrderingList(&Arbiter->ReservedList);

    //
    // Initialize the orderings
    //

    status = ArbInitializeOrderingList(&Arbiter->OrderingList);

    if (!NT_SUCCESS(status)) {
        goto cleanup;
    }

    status = ArbInitializeOrderingList(&Arbiter->ReservedList);

    if (!NT_SUCCESS(status)) {
        goto cleanup;
    }

    //
    // Open HKLM\System\CurrentControlSet\Control\Arbiters
    //

    ArbpWstrToUnicodeString(&unicodeString, PATH_ARBITERS);
    InitializeObjectAttributes(&attributes,
                               &unicodeString,
                               OBJ_CASE_INSENSITIVE,
                               NULL,
                               (PSECURITY_DESCRIPTOR) NULL
                               );


    status = ZwOpenKey(&arbitersHandle,
                       KEY_READ,
                       &attributes
                       );

    if (!NT_SUCCESS(status)) {
        goto cleanup;
    }

    //
    // Open AllocationOrder
    //

    ArbpWstrToUnicodeString(&unicodeString, KEY_ALLOCATIONORDER);
    InitializeObjectAttributes(&attributes,
                               &unicodeString,
                               OBJ_CASE_INSENSITIVE,
                               arbitersHandle,
                               (PSECURITY_DESCRIPTOR) NULL
                               );


    status = ZwOpenKey(&tempHandle,
                       KEY_READ,
                       &attributes
                       );

    if (!NT_SUCCESS(status)) {
        goto cleanup;
    }

    //
    // Extract the value the user asked for
    //

    status = ArbpGetRegistryValue(tempHandle,
                                  AllocationOrderName,
                                  &info
                                  );

    if (!NT_SUCCESS(status)) {
        goto cleanup;
    }

    //
    // Check if the value we retrieved was a string and if so then it was a
    // short cut to a value of that name - open it.
    //

    if (info->Type == REG_SZ) {

        PKEY_VALUE_FULL_INFORMATION tempInfo;
        PWSTR shortcut = (PWSTR) FULL_INFO_DATA(info);

        //
        // Check its NUL terminated
        // 
        
        if (shortcut[(info->DataLength/sizeof(WCHAR))-1] != UNICODE_NULL) {
            status = STATUS_INVALID_PARAMETER;
            goto cleanup;
        }
                
        status = ArbpGetRegistryValue(tempHandle,
                                      shortcut,
                                      &tempInfo
                                      );

        if (!NT_SUCCESS(status)) {
            goto cleanup;
        }

        ExFreePool(info);
        info = tempInfo;

    }

    ZwClose(tempHandle);

    //
    // We only support one level of short cuts so this should be a
    // REG_RESOURCE_REQUIREMENTS_LIST
    //

    if (info->Type != REG_RESOURCE_REQUIREMENTS_LIST) {
        status = STATUS_INVALID_PARAMETER;
        goto cleanup;
    }

    //
    // Extract the resource list
    //

    ASSERT(((PIO_RESOURCE_REQUIREMENTS_LIST) FULL_INFO_DATA(info))
             ->AlternativeLists == 1);

    resourceList = (PIO_RESOURCE_LIST) &((PIO_RESOURCE_REQUIREMENTS_LIST)
                       FULL_INFO_DATA(info))->List[0];

    //
    // Convert the resource list into an ordering list
    //

    FOR_ALL_IN_ARRAY(resourceList->Descriptors,
                     resourceList->Count,
                     current) {

        //
        // Perform any translation that is necessary on the resources
        //

        if (ARGUMENT_PRESENT(Translate)) {

            status = (Translate)(&translated, current);

            if (!NT_SUCCESS(status)) {
                goto cleanup;
            }
        } else {
            translated = *current;
        }

        if (translated.Type == Arbiter->ResourceType) {

            status = Arbiter->UnpackRequirement(&translated,
                                                &start,
                                                &end,
                                                &dummy,  //length
                                                &dummy   //alignment
                                               );

            if (!NT_SUCCESS(status)) {
                goto cleanup;
            }

            status = ArbAddOrdering(&Arbiter->OrderingList,
                                    start,
                                    end
                                    );

            if (!NT_SUCCESS(status)) {
                    goto cleanup;
            }
        }
    }

    //
    // We're finished with info...
    //

    ExFreePool(info);
    info = NULL;

    //
    // Open ReservedResources
    //

    ArbpWstrToUnicodeString(&unicodeString, KEY_RESERVEDRESOURCES);
    InitializeObjectAttributes(&attributes,
                               &unicodeString,
                               OBJ_CASE_INSENSITIVE,
                               arbitersHandle,
                               (PSECURITY_DESCRIPTOR) NULL
                               );


    status = ZwCreateKey(&tempHandle,
                         KEY_READ,
                         &attributes,
                         0,
                         (PUNICODE_STRING) NULL,
                         REG_OPTION_NON_VOLATILE,
                         NULL
                         );

    if (!NT_SUCCESS(status)) {
        goto cleanup;
    }

    //
    // Extract the arbiter's reserved resources
    //

    status = ArbpGetRegistryValue(tempHandle,
                                  ReservedResourcesName,
                                  &info
                                  );

    if (!NT_SUCCESS(status)) {
        goto cleanup;
    }

    //
    // Check if the value we retrieved was a string and if so then it was a
    // short cut to a value of that name - open it.
    //

    if (info->Type == REG_SZ) {

        PKEY_VALUE_FULL_INFORMATION tempInfo;
        PWSTR shortcut = (PWSTR) FULL_INFO_DATA(info);

        //
        // Check its NUL terminated
        // 
        
        if (shortcut[(info->DataLength/sizeof(WCHAR))-1] != UNICODE_NULL) {
            status = STATUS_INVALID_PARAMETER;
            goto cleanup;
        }
                
        status = ArbpGetRegistryValue(tempHandle,
                                      shortcut,
                                      &tempInfo
                                      );

        if (!NT_SUCCESS(status)) {
            goto cleanup;
        }

        ExFreePool(info);
        info = tempInfo;

    }

    ZwClose(tempHandle);

    if (NT_SUCCESS(status)) {

        ASSERT(((PIO_RESOURCE_REQUIREMENTS_LIST) FULL_INFO_DATA(info))
             ->AlternativeLists == 1);

        resourceList = (PIO_RESOURCE_LIST) &((PIO_RESOURCE_REQUIREMENTS_LIST)
                       FULL_INFO_DATA(info))->List[0];

        //
        // Apply the reserved ranges to the ordering
        //

        FOR_ALL_IN_ARRAY(resourceList->Descriptors,
                         resourceList->Count,
                         current) {

            //
            // Perform any translation that is necessary on the resources
            //

            if (ARGUMENT_PRESENT(Translate)) {

                status = (Translate)(&translated, current);

                if (!NT_SUCCESS(status)) {
                    goto cleanup;
                }
            } else {
                translated = *current;
            }

            if (translated.Type == Arbiter->ResourceType) {

                status = Arbiter->UnpackRequirement(&translated,
                                                    &start,
                                                    &end,
                                                    &dummy,  //length
                                                    &dummy   //alignment
                                                   );

                if (!NT_SUCCESS(status)) {
                    goto cleanup;
                }

                //
                // Add the reserved range to the reserved ordering
                //

                status = ArbAddOrdering(&Arbiter->ReservedList, start, end);

                if (!NT_SUCCESS(status)) {
                    goto cleanup;
                }

                //
                // Prune the reserved range from the current ordering
                //

                status = ArbPruneOrdering(&Arbiter->OrderingList, start, end);

                if (!NT_SUCCESS(status)) {
                    goto cleanup;
                }

            }
        }

        ExFreePool(info);
    }

    //
    // All done!
    //

    ZwClose(arbitersHandle);

#if ARB_DBG

    {
        PARBITER_ORDERING current;

        FOR_ALL_IN_ARRAY(Arbiter->OrderingList.Orderings,
                         Arbiter->OrderingList.Count,
                         current) {
            ARB_PRINT(2,
                        ("Ordering: 0x%I64x-0x%I64x\n",
                         current->Start,
                         current->End
                        ));
        }

        ARB_PRINT(2, ("\n"));

        FOR_ALL_IN_ARRAY(Arbiter->ReservedList.Orderings,
                     Arbiter->ReservedList.Count,
                     current) {
            ARB_PRINT(2,
                        ("Reserved: 0x%I64x-0x%I64x\n",
                         current->Start,
                         current->End
                        ));
        }

    }

#endif

    ArbReleaseArbiterLock(Arbiter);

    return STATUS_SUCCESS;

cleanup:

    if (arbitersHandle) {
        ZwClose(arbitersHandle);
    }

    if (tempHandle) {
        ZwClose(tempHandle);
    }

    if (info) {
        ExFreePool(info);
    }

    if (Arbiter->OrderingList.Orderings) {
        ExFreePool(Arbiter->OrderingList.Orderings);
        Arbiter->OrderingList.Count = 0;
        Arbiter->OrderingList.Maximum = 0;
    }

    if (Arbiter->ReservedList.Orderings) {
        ExFreePool(Arbiter->ReservedList.Orderings);
        Arbiter->ReservedList.Count = 0;
        Arbiter->ReservedList.Maximum = 0;
    }

    ArbReleaseArbiterLock(Arbiter);

    return status;
}

BOOLEAN
ArbFindSuitableRange(
    PARBITER_INSTANCE Arbiter,
    PARBITER_ALLOCATION_STATE State
    )

/*++

Routine Description:

    This routine is called from AllocateEntry once we have decided where we want
    to allocate from.  It tries to find a free range that matches the
    requirements in State while restricting its possible solutions to the range
    State->CurrentMinimum to State->CurrentMaximum.  On success State->Start and
    State->End represent this range.

Arguments:

    Arbiter - The instance data of the arbiter who was called.

    State - The state of the current arbitration.

Return Value:

    TRUE if we found a range, FALSE otherwise.

--*/

{

    NTSTATUS status;
    ULONG findRangeFlags = 0;

    PAGED_CODE();

    ASSERT(State->CurrentAlternative);

    //
    // Catch the case where we backtrack and advance past the maximum
    //

    if (State->CurrentMinimum > State->CurrentMaximum) {
        return FALSE;
    }

    //
    // If we are asking for zero ports then trivially succeed with the minimum
    // value and remember that backtracking this is a recipe for infinite loops
    //

    if (State->CurrentAlternative->Length == 0) {
        State->End = State->Start = State->CurrentMinimum;
        return TRUE;
    }

    //
    // For legacy requests from IoAssignResources (directly or by way of
    // HalAssignSlotResources) or IoReportResourceUsage we consider preallocated
    // resources to be available for backward compatibility reasons.
    //
    // If we are allocating a devices boot config then we consider all other
    // boot configs to be available.
    //

    if (State->Entry->RequestSource == ArbiterRequestLegacyReported
        || State->Entry->RequestSource == ArbiterRequestLegacyAssigned) {

        State->RangeAvailableAttributes |= ARBITER_RANGE_BOOT_ALLOCATED;
    }

    //
    // Check if null conflicts are OK...
    //

    if (State->Flags & ARBITER_STATE_FLAG_NULL_CONFLICT_OK) {
        findRangeFlags |= RTL_RANGE_LIST_NULL_CONFLICT_OK;
    }

    //
    // ...or we are shareable...
    //

    if (State->CurrentAlternative->Flags & ARBITER_ALTERNATIVE_FLAG_SHARED) {
        findRangeFlags |= RTL_RANGE_LIST_SHARED_OK;
    }

    //
    // Select the first free alternative from the current alternative
    //

    status = RtlFindRange(
                 Arbiter->PossibleAllocation,
                 State->CurrentMinimum,
                 State->CurrentMaximum,
                 State->CurrentAlternative->Length,
                 State->CurrentAlternative->Alignment,
                 findRangeFlags,
                 State->RangeAvailableAttributes,
                 Arbiter->ConflictCallbackContext,
                 Arbiter->ConflictCallback,
                 &State->Start
                 );


    if (NT_SUCCESS(status)) {

        //
        // We found a suitable range
        //
        State->End = State->Start + State->CurrentAlternative->Length - 1;

        return TRUE;

    } else {

        if (ArbShareDriverExclusive(Arbiter, State) == FALSE) {

            //
            // We couldn't find any range so check if we will allow this conflict
            // - if so don'd fail!
            //

            return Arbiter->OverrideConflict(Arbiter, State);
        }
        return TRUE;
    }
}

VOID
ArbAddAllocation(
     IN PARBITER_INSTANCE Arbiter,
     IN PARBITER_ALLOCATION_STATE State
     )

/*++

Routine Description:

    This routine is called from AllocateEntry once we have found a possible
    solution (State->Start - State->End).  It adds the ranges that will not be
    available if we commit to this solution to Arbiter->PossibleAllocation.

Arguments:

    Arbiter - The instance data of the arbiter who was called.

    State - The state of the current arbitration.

Return Value:

    None.

--*/

{

    NTSTATUS status;

    PAGED_CODE();

    status = RtlAddRange(
                 Arbiter->PossibleAllocation,
                 State->Start,
                 State->End,
                 State->RangeAttributes,
                 RTL_RANGE_LIST_ADD_IF_CONFLICT +
                    (State->CurrentAlternative->Flags & ARBITER_ALTERNATIVE_FLAG_SHARED
                        ? RTL_RANGE_LIST_ADD_SHARED : 0),
                 NULL,
                 State->Entry->PhysicalDeviceObject
                 );

    ASSERT(NT_SUCCESS(status));

}


VOID
ArbBacktrackAllocation(
     IN PARBITER_INSTANCE Arbiter,
     IN PARBITER_ALLOCATION_STATE State
     )

/*++

Routine Description:

    This routine is called from AllocateEntry if the possible solution
    (State->Start - State->End) does not allow us to allocate resources to
    the rest of the devices being considered.  It deletes the ranges that were
    added to Arbiter->PossibleAllocation by AddAllocation.

Arguments:

    Arbiter - The instance data of the arbiter who was called.

    State - The state of the current arbitration.

Return Value:

    None.

--*/


{
    NTSTATUS status;

    PAGED_CODE();

    //
    // We couldn't allocate for the rest of the ranges then
    // backtrack
    //

    status = RtlDeleteRange(
                 Arbiter->PossibleAllocation,
                 State->Start,
                 State->End,
                 State->Entry->PhysicalDeviceObject
                 );

    ASSERT(NT_SUCCESS(status));

    ARB_PRINT(2,
                ("\t\tBacktracking on 0x%I64x-0x%I64x for %p\n",
                State->Start,
                State->End,
                State->Entry->PhysicalDeviceObject
                ));

}


NTSTATUS
ArbPreprocessEntry(
    IN PARBITER_INSTANCE Arbiter,
    IN PARBITER_ALLOCATION_STATE State
    )
/*++

Routine Description:

    This routine is called from AllocateEntry to allow preprocessing of
    entries

Arguments:

    Arbiter - The instance data of the arbiter who was called.

    State - The state of the current arbitration.

Return Value:

    None.

--*/
{

    PAGED_CODE();

    return STATUS_SUCCESS;
}

NTSTATUS
ArbAllocateEntry(
    IN PARBITER_INSTANCE Arbiter,
    IN PARBITER_ALLOCATION_STATE State
    )
/*++

Routine Description:

    This is the core arbitration routine and is called from TestAllocation
    to allocate resources for all of the entries in the allocation stack.
    It calls off to various helper routines (described above) to perform this
    task.

Arguments:

    Arbiter - The instance data of the arbiter who was called.

    State - The state of the current arbitration.

Return Value:

    None.

--*/



{

    NTSTATUS status;
    PARBITER_ALLOCATION_STATE currentState = State;
    BOOLEAN backtracking = FALSE;

    PAGED_CODE();

    //
    // Have we reached the end of the list?  If so then we have a working
    // allocation.
    //

tryAllocation:

    while(currentState >= State && currentState->Entry != NULL) {

        //
        // Do any preprocessing that is required
        //

        status = Arbiter->PreprocessEntry(Arbiter,currentState);

        if (!NT_SUCCESS(status)) {
            return status;
        }

        //
        // If we need to backtrack do so!
        //

        if (backtracking) {

            ULONGLONG possibleCurrentMinimum;

            backtracking = FALSE;

            //
            // Clear the CurrentAlternative of the *next* alternative - this will
            // cause the priorities to be recalculated next time through so we
            // will attempt to explore the search space again
            //
            // The currentState+1 is guaranteed to be safe because the only way
            // we can get here is from where we currentState-- below.
            //

            (currentState + 1)->CurrentAlternative = NULL;

            //
            // We can't backtrack length 0 requests because there is nothing to
            // backtrack so we would get stuck in an inifinite loop...
            //

            if (currentState->CurrentAlternative->Length == 0) {
                goto failAllocation;
            }

            //
            // Backtrack
            //

            Arbiter->BacktrackAllocation(Arbiter, currentState);

            //
            // Reduce allocation window to not include the range we backtracked
            // and check that that doesn't underflow the minimum or wrap
            //

            possibleCurrentMinimum = currentState->Start - 1;

            if (possibleCurrentMinimum > currentState->CurrentMinimum // wrapped
            ||  possibleCurrentMinimum < currentState->CurrentAlternative->Minimum) {

                //
                // We have run out space in this alternative move on to the next
                //

                goto continueWithNextAllocationRange;

            } else {

                currentState->CurrentMaximum = possibleCurrentMinimum;

                //
                // Get back into arbitrating at the right point
                //

                goto continueWithNextSuitableRange;
            }
        }

        //
        // Try to allocate for this entry
        //

continueWithNextAllocationRange:

        while (Arbiter->GetNextAllocationRange(Arbiter, currentState)) {

            ARB_INDENT(2, (ULONG)(currentState - State));

            ARB_PRINT(2,
                        ("Testing 0x%I64x-0x%I64x %s\n",
                        currentState->CurrentMinimum,
                        currentState->CurrentMaximum,
                        currentState->CurrentAlternative->Flags & ARBITER_ALTERNATIVE_FLAG_SHARED ?
                            "shared" : "non-shared"
                        ));

continueWithNextSuitableRange:

            while (Arbiter->FindSuitableRange(Arbiter, currentState)) {

                //
                // We found a possible solution
                //

                ARB_INDENT(2, (ULONG)(currentState - State));

                if (currentState->CurrentAlternative->Length != 0) {

                    ARB_PRINT(2,
                        ("Possible solution for %p = 0x%I64x-0x%I64x, %s\n",
                        currentState->Entry->PhysicalDeviceObject,
                        currentState->Start,
                        currentState->End,
                        currentState->CurrentAlternative->Flags & ARBITER_ALTERNATIVE_FLAG_SHARED ?
                            "shared" : "non-shared"
                        ));

                    //
                    // Update the arbiter with the possible allocation
                    //

                    Arbiter->AddAllocation(Arbiter, currentState);

                } else {

                    ARB_PRINT(2,
                        ("Zero length solution solution for %p = 0x%I64x-0x%I64x, %s\n",
                        currentState->Entry->PhysicalDeviceObject,
                        currentState->Start,
                        currentState->End,
                        currentState->CurrentAlternative->Flags & ARBITER_ALTERNATIVE_FLAG_SHARED ?
                            "shared" : "non-shared"
                        ));

                    //
                    // Set the result in the arbiter appropriatley so that we
                    // don't try and translate this zero requirement - it won't!
                    //

                    currentState->Entry->Result = ArbiterResultNullRequest;
                }

                //
                // Move on to the next entry
                //

                currentState++;
                goto tryAllocation;
            }
        }

failAllocation:

        //
        // We couldn't allocate for this device
        //

        if (currentState == State) {

            //
            // We are at the top of the allocation stack to we can't backtrack -
            // *** GAME OVER ***
            //

            return STATUS_UNSUCCESSFUL;

        } else {

            //
            // Backtrack and try again
            //

            ARB_INDENT(2, (ULONG)(currentState - State));

            ARB_PRINT(2,
                ("Allocation failed for %p - backtracking\n",
                currentState->Entry->PhysicalDeviceObject
                ));

            backtracking = TRUE;

            //
            // Pop the last state off the stack and try a different path
            //

            currentState--;
            goto tryAllocation;
        }
    }

    //
    // We have successfully allocated for all ranges so fill in the allocation
    //

    currentState = State;

    while (currentState->Entry != NULL) {

        status = Arbiter->PackResource(
                    currentState->CurrentAlternative->Descriptor,
                    currentState->Start,
                    currentState->Entry->Assignment
                    );

        ASSERT(NT_SUCCESS(status));

        //
        // Remember the alternative we chose from so we can retrieve it during retest
        //

        currentState->Entry->SelectedAlternative
            = currentState->CurrentAlternative->Descriptor;

        ARB_PRINT(2,
                    ("Assigned - 0x%I64x-0x%I64x\n",
                    currentState->Start,
                    currentState->End
                    ));

        currentState++;
    }

    return STATUS_SUCCESS;

}

BOOLEAN
ArbGetNextAllocationRange(
    IN PARBITER_INSTANCE Arbiter,
    IN OUT PARBITER_ALLOCATION_STATE State
    )

/*++

Routine Description:

    This routine attempts to find the next range where allocation should be
    tried.  It updates State->CurrentMinimum, State->CurrentMaximum and
    State->CurrentAlternative to indicate this range.

Arguments:

    Arbiter - The instance data of the arbiter

    State - The state of the current arbitration

Return Value:

    TRUE if a range to attemp allocation in is found, FALSE otherwise

--*/

{

    PARBITER_ALTERNATIVE current, lowestAlternative;
    ULONGLONG min, max;
    PARBITER_ORDERING ordering;


    for (;;) {

        if (State->CurrentAlternative) {

            //
            // Update the priority of the alternative we selected last time
            //

            ArbpUpdatePriority(Arbiter, State->CurrentAlternative);

        } else {

            //
            // This is the first time we are looking at this alternative or a
            // backtrack - either way we need to update all the priorities
            //

            FOR_ALL_IN_ARRAY(State->Alternatives,
                             State->AlternativeCount,
                             current) {

                current->Priority = ARBITER_PRIORITY_NULL;
                ArbpUpdatePriority(Arbiter, current);

            }
        }

        //
        // Find the lowest priority of the alternatives
        //

        lowestAlternative = State->Alternatives;

        FOR_ALL_IN_ARRAY(State->Alternatives + 1,
                         State->AlternativeCount - 1,
                         current) {

            if (current->Priority < lowestAlternative->Priority) {
                lowestAlternative = current;
            }
        }

        ARB_INDENT(2, (ULONG)(State - Arbiter->AllocationStack));

        //
        // Check if we have run out of allocation ranges
        //

        if (lowestAlternative->Priority == ARBITER_PRIORITY_EXHAUSTED) {

            if (lowestAlternative->Flags & ARBITER_ALTERNATIVE_FLAG_FIXED) {

                ARB_PRINT(2,("Fixed alternative exhausted\n"));

            } else {

                ARB_PRINT(2,("Alternative exhausted\n"));
            }

            return FALSE;

        } else {

            ARB_PRINT(2,(
                "LowestAlternative: [%i] 0x%I64x-0x%I64x L=0x%08x A=0x%08x\n",
                lowestAlternative->Priority,
                lowestAlternative->Minimum,
                lowestAlternative->Maximum,
                lowestAlternative->Length,
                lowestAlternative->Alignment
                ));

        }

        //
        // Check if we are now allowing reserved ranges
        //

        if (lowestAlternative->Priority == ARBITER_PRIORITY_RESERVED
        ||  lowestAlternative->Priority == ARBITER_PRIORITY_PREFERRED_RESERVED) {

            //
            // Set min and max to be the Minimum and Maximum that the descriptor
            // specified ignoring any reservations or orderings - this is our
            // last chance
            //

            min = lowestAlternative->Minimum;
            max = lowestAlternative->Maximum;

            ARB_INDENT(2, (ULONG)(State - Arbiter->AllocationStack));

            ARB_PRINT(2,("Allowing reserved ranges\n"));

        } else {

            ASSERT(ORDERING_INDEX_FROM_PRIORITY(lowestAlternative->Priority) <
                     Arbiter->OrderingList.Count);

            //
            // Locate the ordering we match
            //

            ordering = &Arbiter->OrderingList.Orderings
                [ORDERING_INDEX_FROM_PRIORITY(lowestAlternative->Priority)];

            //
            // Make sure they overlap and are big enough - this is just paranoia
            //

            ASSERT(INTERSECT(lowestAlternative->Minimum,
                             lowestAlternative->Maximum,
                             ordering->Start,
                             ordering->End)
                && INTERSECT_SIZE(lowestAlternative->Minimum,
                                  lowestAlternative->Maximum,
                                  ordering->Start,
                                  ordering->End) >= lowestAlternative->Length);

            //
            // Calculate the allocation range
            //

            min = __max(lowestAlternative->Minimum, ordering->Start);

            max = __min(lowestAlternative->Maximum, ordering->End);

        }

        //
        // If this is a length 0 requirement then succeed now and avoid much
        // trauma later
        //

        if (lowestAlternative->Length == 0) {

            min = lowestAlternative->Minimum;
            max = lowestAlternative->Maximum;

        } else {

            //
            // Trim range to match alignment.
            //

            min += lowestAlternative->Alignment - 1;
            min -= min % lowestAlternative->Alignment;

            if ((lowestAlternative->Length - 1) > (max - min)) {

                ARB_INDENT(3, (ULONG)(State - Arbiter->AllocationStack));
                ARB_PRINT(3, ("Range cannot be aligned ... Skipping\n"));

                //
                // Set CurrentAlternative so we will update the priority of this
                // alternative
                //

                State->CurrentAlternative = lowestAlternative;
                continue;
            }

            max -= lowestAlternative->Length - 1;
            max -= max % lowestAlternative->Alignment;
            max += lowestAlternative->Length - 1;

        }

        //
        // Check if we handed back the same range last time, for the same
        // alternative, if so try to find another range
        //

        if (min == State->CurrentMinimum
        && max == State->CurrentMaximum
        && State->CurrentAlternative == lowestAlternative) {

            ARB_INDENT(2, (ULONG)(State - Arbiter->AllocationStack));

            ARB_PRINT(2,
                  ("Skipping identical allocation range\n"
            ));

            continue;
        }

        State->CurrentMinimum = min;
        State->CurrentMaximum = max;
        State->CurrentAlternative = lowestAlternative;

        ARB_INDENT(2, (ULONG)(State - Arbiter->AllocationStack));
        ARB_PRINT(1, ("AllocationRange: 0x%I64x-0x%I64x\n", min, max));

        return TRUE;

    }
}

NTSTATUS
ArbpGetRegistryValue(
    IN HANDLE KeyHandle,
    IN PWSTR  ValueName,
    OUT PKEY_VALUE_FULL_INFORMATION *Information
    )

/*++

Routine Description:

    This routine is invoked to retrieve the data for a registry key's value.
    This is done by querying the value of the key with a zero-length buffer
    to determine the size of the value, and then allocating a buffer and
    actually querying the value into the buffer.

    It is the responsibility of the caller to free the buffer.

Arguments:

    KeyHandle - Supplies the key handle whose value is to be queried

    ValueName - Supplies the null-terminated Unicode name of the value.

    Information - Returns a pointer to the allocated data buffer.

Return Value:

    The function value is the final status of the query operation.

Note:

    The same as IopGetRegistryValue - it allows us to share the arbiter
    code with pci.sys

--*/

{
    UNICODE_STRING unicodeString;
    NTSTATUS status;
    PKEY_VALUE_FULL_INFORMATION infoBuffer;
    ULONG keyValueLength;

    PAGED_CODE();

    RtlInitUnicodeString( &unicodeString, ValueName );

    //
    // Figure out how big the data value is so that a buffer of the
    // appropriate size can be allocated.
    //

    status = ZwQueryValueKey( KeyHandle,
                              &unicodeString,
                              KeyValueFullInformationAlign64,
                              (PVOID) NULL,
                              0,
                              &keyValueLength );
    if (status != STATUS_BUFFER_OVERFLOW &&
        status != STATUS_BUFFER_TOO_SMALL) {
        return status;
    }

    //
    // Allocate a buffer large enough to contain the entire key data value.
    //

    infoBuffer = ExAllocatePoolWithTag( PagedPool,
                                        keyValueLength,
                                        ARBITER_MISC_TAG
                                        );

    if (!infoBuffer) {
        return STATUS_INSUFFICIENT_RESOURCES;
    }

    //
    // Query the data for the key value.
    //

    status = ZwQueryValueKey( KeyHandle,
                              &unicodeString,
                              KeyValueFullInformationAlign64,
                              infoBuffer,
                              keyValueLength,
                              &keyValueLength );
    if (!NT_SUCCESS( status )) {
        ExFreePool( infoBuffer );
        return status;
    }

    //
    // Everything worked, so simply return the address of the allocated
    // buffer to the caller, who is now responsible for freeing it.
    //

    *Information = infoBuffer;
    return STATUS_SUCCESS;
}


#define ARBITER_ORDERING_LIST_INITIAL_SIZE      16

NTSTATUS
ArbInitializeOrderingList(
    IN OUT PARBITER_ORDERING_LIST List
    )

/*++

Routine Description:

    This routine inititialize an arbiter ordering list.

Arguments:

    List - The list to be initialized

Return Value:

    Status code that indicates whether or not the function was successful.

--*/

{
    PAGED_CODE();

    ASSERT(List);

    List->Orderings = ExAllocatePoolWithTag(PagedPool,
                                            ARBITER_ORDERING_LIST_INITIAL_SIZE *
                                                sizeof(ARBITER_ORDERING),
                                            ARBITER_ORDERING_LIST_TAG
                                            );

    if (!List->Orderings) {
        List->Maximum = 0;
        List->Count = 0;
        return STATUS_INSUFFICIENT_RESOURCES;
    }

    List->Count = 0;
    List->Maximum = ARBITER_ORDERING_LIST_INITIAL_SIZE;

    return STATUS_SUCCESS;
}

NTSTATUS
ArbCopyOrderingList(
    OUT PARBITER_ORDERING_LIST Destination,
    IN PARBITER_ORDERING_LIST Source
    )

/*++

Routine Description:

    This routine copies an arbiter ordering list.

Arguments:

    Destination - An uninitialized arbiter ordering list where the data
        should be copied from

    Source - Arbiter ordering list to be copied
Return Value:

    Status code that indicates whether or not the function was successful.

--*/


{

    PAGED_CODE()

    ASSERT(Source->Count <= Source->Maximum);
    ASSERT(Source->Maximum > 0);

    Destination->Orderings =
        ExAllocatePoolWithTag(PagedPool,
                              Source->Maximum * sizeof(ARBITER_ORDERING),
                              ARBITER_ORDERING_LIST_TAG
                              );

    if (Destination->Orderings == NULL) {
        return STATUS_INSUFFICIENT_RESOURCES;
    }

    Destination->Count = Source->Count;
    Destination->Maximum = Source->Maximum;

    if (Source->Count > 0) {

        RtlCopyMemory(Destination->Orderings,
                      Source->Orderings,
                      Source->Count * sizeof(ARBITER_ORDERING)
                      );
    }

    return STATUS_SUCCESS;
}


NTSTATUS
ArbAddOrdering(
    OUT PARBITER_ORDERING_LIST List,
    IN ULONGLONG Start,
    IN ULONGLONG End
    )

/*++

Routine Description:

    This routine adds the range Start-End to the end of the ordering list.  No
    checking for overlaps or pruning is done (see ArbpPruneOrdering)

Arguments:

    OrderingList - The list where the range should be added.

    Start - The start of the range to be added.

    End - The end of the range to be added.

Return Value:

    Status code that indicates whether or not the function was successful.

--*/

{

    PAGED_CODE()

    //
    // Validate parameters
    //

    if (End < Start) {
        return STATUS_INVALID_PARAMETER;
    }

    //
    // Check if the buffer is full
    //

    if (List->Count == List->Maximum) {

        PARBITER_ORDERING temp;

        //
        // Out of space - grow the buffer
        //

        temp = ExAllocatePoolWithTag(PagedPool,
                              (List->Count + ARBITER_ORDERING_GROW_SIZE) *
                                  sizeof(ARBITER_ORDERING),
                              ARBITER_ORDERING_LIST_TAG
                              );

        if (!temp) {
            return STATUS_INSUFFICIENT_RESOURCES;
        }

        //
        // If we had any orderings copy them
        //

        if (List->Orderings) {

            RtlCopyMemory(temp,
                          List->Orderings,
                          List->Count * sizeof(ARBITER_ORDERING)
                          );

            ExFreePool(List->Orderings);
        }

        List->Maximum += ARBITER_ORDERING_GROW_SIZE;
        List->Orderings = temp;

    }

    //
    // Add the entry to the list
    //

    List->Orderings[List->Count].Start = Start;
    List->Orderings[List->Count].End = End;
    List->Count++;

    ASSERT(List->Count <= List->Maximum);

    return STATUS_SUCCESS;
}

NTSTATUS
ArbPruneOrdering(
    IN OUT PARBITER_ORDERING_LIST OrderingList,
    IN ULONGLONG Start,
    IN ULONGLONG End
    )

/*++

Routine Description:

    This routine removes the range Start-End from all entries in the ordering
    list, splitting ranges into two or deleting them as necessary.

Arguments:

    OrderingList - The list to be pruned.

    Start - The start of the range to be deleted.

    End - The end of the range to be deleted.

Return Value:

    Status code that indicates whether or not the function was successful.

Note:

    In the comments below *** represents the range Start - End and --- the range
    current->Start - current->End.

--*/

{

    NTSTATUS status;
    PARBITER_ORDERING current, currentInsert, newOrdering = NULL, temp = NULL;
    USHORT count;

    PAGED_CODE()

    ASSERT(OrderingList);
    ASSERT(OrderingList->Orderings);

    //
    // Validate parameters
    //

    if (End < Start) {
        status = STATUS_INVALID_PARAMETER;
        goto cleanup;
    }

    //
    // Allocate a buffer big enough for all eventualities
    //

    newOrdering = ExAllocatePoolWithTag(PagedPool,
                                        (OrderingList->Count * 2 + 1) *
                                            sizeof(ARBITER_ORDERING),
                                        ARBITER_ORDERING_LIST_TAG
                                        );

    if (!newOrdering) {
        status = STATUS_INSUFFICIENT_RESOURCES;
        goto cleanup;
    }

    currentInsert = newOrdering;

    //
    // Do we have a current ordering?
    //

    if (OrderingList->Count > 0) {

        //
        // Iterate through the current ordering and prune accordingly
        //

        FOR_ALL_IN_ARRAY(OrderingList->Orderings, OrderingList->Count, current) {

            if (End < current->Start || Start > current->End) {

                //
                // ****      or      ****
                //      ----    ----
                //
                // We don't overlap so copy the range unchanged
                //

                *currentInsert++ = *current;

            } else if (Start > current->Start) {

                if (End < current->End) {

                    //
                    //   ****
                    // --------
                    //
                    // Split the range into two
                    //

                    currentInsert->Start = End + 1;
                    currentInsert->End = current->End;
                    currentInsert++;

                    currentInsert->Start = current->Start;
                    currentInsert->End = Start - 1;
                    currentInsert++;


                } else {

                    //
                    //       **** or     ****
                    // --------      --------
                    //
                    // Prune the end of the range
                    //

                    ASSERT(End >= current->End);

                    currentInsert->Start = current->Start;
                    currentInsert->End = Start - 1;
                    currentInsert++;
                }
            } else {

                ASSERT(Start <= current->Start);

                if (End < current->End) {

                    //
                    // ****       or ****
                    //   --------    --------
                    //
                    // Prune the start of the range
                    //

                    currentInsert->Start = End + 1;
                    currentInsert->End = current->End;
                    currentInsert++;

                } else {

                    ASSERT(End >= current->End);

                    //
                    // ******** or ********
                    //   ----      --------
                    //
                    // Don't copy the range (ie. Delete it)
                    //

                }
            }
        }
    }


    ASSERT(currentInsert - newOrdering >= 0);

    count = (USHORT)(currentInsert - newOrdering);

    //
    // Check if we have any orderings left
    //

    if (count > 0) {

        if (count > OrderingList->Maximum) {

            //
            // There isn't enough space so allocate a new buffer
            //

            temp =
                ExAllocatePoolWithTag(PagedPool,
                                      count * sizeof(ARBITER_ORDERING),
                                      ARBITER_ORDERING_LIST_TAG
                                      );

            if (!temp) {
                status = STATUS_INSUFFICIENT_RESOURCES;
                goto cleanup;
            }

            if (OrderingList->Orderings) {
                ExFreePool(OrderingList->Orderings);
            }

            OrderingList->Orderings = temp;
            OrderingList->Maximum = count;

        }


        //
        // Copy the new ordering
        //

        RtlCopyMemory(OrderingList->Orderings,
                      newOrdering,
                      count * sizeof(ARBITER_ORDERING)
                      );
    }

    //
    // Free our temporary buffer
    //

    ExFreePool(newOrdering);

    OrderingList->Count = count;

    return STATUS_SUCCESS;

cleanup:

    if (newOrdering) {
        ExFreePool(newOrdering);
    }

    if (temp) {
        ExFreePool(temp);
    }

    return status;

}
VOID
ArbFreeOrderingList(
    IN PARBITER_ORDERING_LIST List
    )
/*++

Routine Description:

    Frees storage associated with an ordering list.
    Reverses ArbInitializeOrderingList.

Arguments:

    List - The list to be fred

Return Value:

    None
--*/

{
    PAGED_CODE();

    if (List->Orderings) {
        ASSERT(List->Maximum);
        ExFreePool(List->Orderings);
    }

    List->Count = 0;
    List->Maximum = 0;
    List->Orderings = NULL;
}



BOOLEAN
ArbOverrideConflict(
    IN PARBITER_INSTANCE Arbiter,
    IN PARBITER_ALLOCATION_STATE State
    )

/*++

Routine Description:

    This is the default implementation of override conflict which

Arguments:

    Arbiter - The instance data of the arbiter who was called.

    State - The state of the current arbitration.

Return Value:

    TRUE if the conflict is allowable, false otherwise

--*/

{

    PRTL_RANGE current;
    RTL_RANGE_LIST_ITERATOR iterator;
    BOOLEAN ok = FALSE;

    PAGED_CODE();

    if (!(State->CurrentAlternative->Flags & ARBITER_ALTERNATIVE_FLAG_FIXED)) {
        return FALSE;
    }

    FOR_ALL_RANGES(Arbiter->PossibleAllocation, &iterator, current) {

        //
        // Only test the overlapping ones
        //

        if (INTERSECT(current->Start, current->End, State->CurrentMinimum, State->CurrentMaximum)) {


            //
            // Check if we should ignore the range because of its attributes
            //

            if (current->Attributes & State->RangeAvailableAttributes) {

                //
                // We DON'T set ok to true because we are just ignoring the range,
                // as RtlFindRange would have and thus it can't be the cause of
                // RtlFindRange failing, so ignoring it can't fix the conflict.
                //

                continue;
            }

            //
            // Check if we are conflicting with ourselves AND the conflicting range
            // is a fixed requirement
            //

            if (current->Owner == State->Entry->PhysicalDeviceObject
            && State->CurrentAlternative->Flags & ARBITER_ALTERNATIVE_FLAG_FIXED) {

                State->Start=State->CurrentMinimum;
                State->End=State->CurrentMaximum;

                ok = TRUE;
                continue;
            }

            //
            // The conflict is still valid
            //

            return FALSE;
        }
    }
    return ok;
}

VOID
ArbpUpdatePriority(
    PARBITER_INSTANCE Arbiter,
    PARBITER_ALTERNATIVE Alternative
    )

/*++

Routine Description:

    This routine updates the priority of an arbiter alternative.

Arguments:

    Arbiter - The arbiter we are operating on

    Alternative - The alternative currently being considered

Return Value:

    Status code that indicates whether or not the function was successful.

Note:

    The priorities are a LONG values organised as:

    <------Preferred priorities-----> <-----Ordinary Priorities----->

    MINLONG--------------------------0-----------------------------MAXLONG
                                     ^                               ^ ^ ^
                                     |                               | | |
                                    NULL            PREFERRED_RESERVED | |
                                                                RESERVED |
                                                                     EXHAUSTED

    An ordinary priority is calculated the (index + 1) of the next ordering it
    intersects with (and has enough space for an allocation).

    A preferred priority is the ordinary priority * - 1

    In this way by examining each of the alternatives in priority order (lowest
    first) we achieve the desired allocation order of:

    (1) Preferred alternative with non-reserved resources
    (2) Alternatives with non-reserved resources
    (3) Preferred reserved resources
    (4) Reserved Resources

    MAXLONG the worst priority indicates that there are no more allocation ranges
    left.

--*/

{

    PARBITER_ORDERING ordering;
    BOOLEAN preferred;
    LONG priority;

    PAGED_CODE();

    priority = Alternative->Priority;

    //
    // If we have already tried the reserved resources then we are out of luck!
    //

    if (priority == ARBITER_PRIORITY_RESERVED
    ||  priority == ARBITER_PRIORITY_PREFERRED_RESERVED) {

        Alternative->Priority = ARBITER_PRIORITY_EXHAUSTED;
        return;
    }

    //
    // Check if this is a preferred value - we treat them specially
    //

    preferred = Alternative->Descriptor->Option & IO_RESOURCE_PREFERRED;

    //
    // If priority is NULL then we haven't started calculating one so we
    // should start the search from the initial ordering
    //

    if (priority == ARBITER_PRIORITY_NULL) {

        ordering = Arbiter->OrderingList.Orderings;

    } else {

        //
        // If we are a fixed resource then there is no point
        // in trying to find another range - it will be the
        // same and thus still conflict.  Mark this alternative as
        // exhausted
        //

        if (Alternative->Flags & ARBITER_ALTERNATIVE_FLAG_FIXED) {

            Alternative->Priority = ARBITER_PRIORITY_EXHAUSTED;

            return;
        }

        ASSERT(ORDERING_INDEX_FROM_PRIORITY(Alternative->Priority) <
                 Arbiter->OrderingList.Count);

        ordering = &Arbiter->OrderingList.Orderings
            [ORDERING_INDEX_FROM_PRIORITY(Alternative->Priority) + 1];

    }

    //
    // Now find the first member of the assignent ordering for this arbiter
    // where we have an overlap big enough
    //

    FOR_REST_IN_ARRAY(Arbiter->OrderingList.Orderings,
                      Arbiter->OrderingList.Count,
                      ordering) {

        //
        // Is the ordering applicable?
        //

        if (INTERSECT(Alternative->Minimum, Alternative->Maximum,
                      ordering->Start, ordering->End)
        && INTERSECT_SIZE(Alternative->Minimum, Alternative->Maximum,
                          ordering->Start,ordering->End) >= Alternative->Length) {

            //
            // This is out guy, calculate his priority
            //

            Alternative->Priority = (LONG)(ordering - Arbiter->OrderingList.Orderings + 1);

            //
            // Preferred priorities are -ve
            //

            if (preferred) {
                Alternative->Priority *= -1;
            }

            return;
        }
    }

    //
    // We have runout of non-reserved resources so try the reserved ones
    //

    if (preferred) {
        Alternative->Priority = ARBITER_PRIORITY_PREFERRED_RESERVED;
    } else {
        Alternative->Priority = ARBITER_PRIORITY_RESERVED;
    }

}

NTSTATUS
ArbAddReserved(
    IN PARBITER_INSTANCE Arbiter,
    IN PIO_RESOURCE_DESCRIPTOR Requirement      OPTIONAL,
    IN PCM_PARTIAL_RESOURCE_DESCRIPTOR Resource OPTIONAL
    )
{
    PAGED_CODE();

    return STATUS_NOT_SUPPORTED;
}

BOOLEAN
ArbpQueryConflictCallback(
    IN PVOID Context,
    IN PRTL_RANGE Range
    )

/*++

Routine Description:

    This call back is called from FindSuitableRange (via RtlFindRange) when we
    encounter an conflicting range.

Arguments:

    Context - Actually a PRTL_RANGE * where we store the range we conflicted
        with.

    Range - The range we conflict with.

Return Value:

    FALSE

--*/

{
    PRTL_RANGE *conflictingRange = (PRTL_RANGE*)Context;

    PAGED_CODE();

    ARB_PRINT(2,("Possible conflict: (%p) 0x%I64x-0x%I64x Owner: %p",
                   Range,
                   Range->Start,
                   Range->End,
                   Range->Owner
                ));

    //
    // Remember the conflicting range
    //

    *conflictingRange = Range;

    //
    // We want to allow the rest of FindSuitableRange to determine if this really
    // is a conflict.
    //

    return FALSE;
}


NTSTATUS
ArbQueryConflict(
    IN PARBITER_INSTANCE Arbiter,
    IN PDEVICE_OBJECT PhysicalDeviceObject,
    IN PIO_RESOURCE_DESCRIPTOR ConflictingResource,
    OUT PULONG ConflictCount,
    OUT PARBITER_CONFLICT_INFO *Conflicts
    )

/*++

Routine Description:

    This routine examines the arbiter state and returns a list of devices that
    conflict with ConflictingResource

Arguments:

    Arbiter - The arbiter to examine conflicts in

    ConflictingResource - The resource we want to know the conflicts with

    ConflictCount - On success contains the number of conflicts detected

    ConflictList - On success contains a pointer to an array of conflicting
        devices

Return Value:

    Status code that indicates whether or not the function was successful.

--*/
{
    //
    // NTRAID #98568 - 2000/03/31 - andrewth
    // ArbQueryConflict needs to be redesigned
    //
    
    NTSTATUS status;
    RTL_RANGE_LIST backupAllocation;
    BOOLEAN backedUp = FALSE;
    ARBITER_LIST_ENTRY entry;
    ARBITER_ALLOCATION_STATE state;
    ARBITER_ALTERNATIVE alternative;
    ULONG count = 0, size = 10;
    PRTL_RANGE conflictingRange;
    PARBITER_CONFLICT_INFO conflictInfo = NULL;
    PVOID savedContext;
    PRTL_CONFLICT_RANGE_CALLBACK savedCallback;
    ULONG sz;

    PAGED_CODE();

    ASSERT(PhysicalDeviceObject);
    ASSERT(ConflictingResource);
    ASSERT(ConflictCount);
    ASSERT(Conflicts);
    //
    // Set up our conflict callback
    //
    savedCallback = Arbiter->ConflictCallback;
    savedContext = Arbiter->ConflictCallbackContext;
    Arbiter->ConflictCallback = ArbpQueryConflictCallback;
    Arbiter->ConflictCallbackContext = &conflictingRange;

    //
    // If there is a transaction in progress then we need to backup the
    // the possible allocation so we can restore it when we are done.
    //

    if (Arbiter->TransactionInProgress) {

        RtlInitializeRangeList(&backupAllocation);

        status = RtlCopyRangeList(&backupAllocation, Arbiter->PossibleAllocation);

        if (!NT_SUCCESS(status)) {
            goto cleanup;
        }

        RtlFreeRangeList(Arbiter->PossibleAllocation);

        backedUp = TRUE;
    }

    //
    // Fake up the allocation state
    //


    status = RtlCopyRangeList(Arbiter->PossibleAllocation, Arbiter->Allocation);

    if (!NT_SUCCESS(status)) {
        goto cleanup;
    }

    status = ArbpBuildAlternative(Arbiter, ConflictingResource, &alternative);

    if (!NT_SUCCESS(status)) {
        goto cleanup;
    }

    RtlZeroMemory(&state, sizeof(ARBITER_ALLOCATION_STATE));

    state.Start = alternative.Minimum;
    state.End = alternative.Maximum;
    state.CurrentMinimum = state.Start;
    state.CurrentMaximum = state.End;
    state.CurrentAlternative = &alternative;
    state.AlternativeCount = 1;
    state.Alternatives = &alternative;
    state.Flags = ARBITER_STATE_FLAG_CONFLICT;
    state.Entry = &entry;

    RtlZeroMemory(&entry, sizeof(ARBITER_LIST_ENTRY));
    entry.RequestSource = ArbiterRequestPnpEnumerated;
    entry.PhysicalDeviceObject = PhysicalDeviceObject;
    
    if (!NT_SUCCESS(IoGetDeviceProperty(PhysicalDeviceObject,DevicePropertyLegacyBusType,sizeof(entry.InterfaceType),&entry.InterfaceType,&sz))) {
        entry.InterfaceType = Isa; // not what I want to do! However this has the right effect - good enough for conflict detection
    }
    if (!NT_SUCCESS(IoGetDeviceProperty(PhysicalDeviceObject,DevicePropertyBusNumber,sizeof(entry.InterfaceType),&entry.BusNumber,&sz))) {
        entry.BusNumber = 0; // not what I want to do! However this has the right effect - good enough for conflict detection
    }

    //
    // Initialize the return buffers
    //

    conflictInfo = ExAllocatePoolWithTag(PagedPool,
                                         size * sizeof(ARBITER_CONFLICT_INFO),
                                         ARBITER_CONFLICT_INFO_TAG
                                         );

    if (!conflictInfo) {
        status = STATUS_INSUFFICIENT_RESOURCES;
        goto cleanup;
    }

    //
    // Perform any necessary preprocessing
    //

    status = Arbiter->PreprocessEntry(Arbiter, &state);

    if (!NT_SUCCESS(status)) {
        goto cleanup;
    }

    //
    // Remove self from list of possible allocations
    // status may be set, but can be ignored
    // we take ourself out of test completely, so that a user can
    // pick new values in context of rest of the world
    // if we decide to use RtlDeleteRange instead
    // make sure we do it for every alias formed in PreprocessEntry
    //

    status = RtlDeleteOwnersRanges(Arbiter->PossibleAllocation,
                            state.Entry->PhysicalDeviceObject
                            );

    //
    // Keep trying to find a suitable range and each time we fail remember why.
    //
    conflictingRange = NULL;
    state.CurrentMinimum = state.Start;
    state.CurrentMaximum = state.End;

    while (!Arbiter->FindSuitableRange(Arbiter, &state)) {

        if (count == size) {

            //
            // We need to resize the return buffer
            //

            PARBITER_CONFLICT_INFO temp = conflictInfo;

            size += 5;

            conflictInfo =
                ExAllocatePoolWithTag(PagedPool,
                                      size * sizeof(ARBITER_CONFLICT_INFO),
                                      ARBITER_CONFLICT_INFO_TAG
                                      );

            if (!conflictInfo) {
                status = STATUS_INSUFFICIENT_RESOURCES;
                conflictInfo = temp;
                goto cleanup;
            }

            RtlCopyMemory(conflictInfo,
                          temp,
                          count * sizeof(ARBITER_CONFLICT_INFO)
                          );

            ExFreePool(temp);

        }

        if (conflictingRange != NULL) {
            conflictInfo[count].OwningObject = conflictingRange->Owner;
            conflictInfo[count].Start = conflictingRange->Start;
            conflictInfo[count].End = conflictingRange->End;
            count++;

            //
            // Delete the range we conflicted with so we don't loop forever
            //
#if 0
            status = RtlDeleteRange(Arbiter->PossibleAllocation,
                                    conflictingRange->Start,
                                    conflictingRange->End,
                                    conflictingRange->Owner
                                    );
#endif
            status = RtlDeleteOwnersRanges(Arbiter->PossibleAllocation,
                                    conflictingRange->Owner
                                    );

            if (!NT_SUCCESS(status)) {
                goto cleanup;
            }

        } else {
            //
            // someone isn't playing by the rules (such as ACPI!)
            //
            ARB_PRINT(0,("Conflict detected - but someone hasn't set conflicting info\n"));

            conflictInfo[count].OwningObject = NULL;
            conflictInfo[count].Start = (ULONGLONG)0;
            conflictInfo[count].End = (ULONGLONG)(-1);
            count++;

            //
            // we daren't continue at risk of looping forever
            //
            break;
        }

        //
        // reset for next round
        //
        conflictingRange = NULL;
        state.CurrentMinimum = state.Start;
        state.CurrentMaximum = state.End;
    }

    RtlFreeRangeList(Arbiter->PossibleAllocation);

    if (Arbiter->TransactionInProgress) {

        status = RtlCopyRangeList(Arbiter->PossibleAllocation, &backupAllocation);

        if (!NT_SUCCESS(status)) {
            goto cleanup;
        }

        RtlFreeRangeList(&backupAllocation);
    }

    Arbiter->ConflictCallback = savedCallback;
    Arbiter->ConflictCallbackContext = savedContext;

    *Conflicts = conflictInfo;
    *ConflictCount = count;

    return STATUS_SUCCESS;

cleanup:

    if (conflictInfo) {
        ExFreePool(conflictInfo);
    }

    RtlFreeRangeList(Arbiter->PossibleAllocation);

    if (Arbiter->TransactionInProgress && backedUp) {
        status = RtlCopyRangeList(Arbiter->PossibleAllocation, &backupAllocation);
        RtlFreeRangeList(&backupAllocation);
    }

    Arbiter->ConflictCallback = savedCallback;
    Arbiter->ConflictCallbackContext = savedContext;

    *Conflicts = NULL;

    return status;
}


NTSTATUS
ArbStartArbiter(
    IN PARBITER_INSTANCE Arbiter,
    IN PCM_RESOURCE_LIST StartResources
    )

/*++

Routine Description:

    This function is called by the driver that implements the arbiter once
    it has been started and knowns what resources it can allocate to its
    children.

    It will eventually initialize the range lists correctly but for
    now it is just an overloadable place holder as that work is done elsewhere.

Parameters:

    Arbiter - The instance of the arbiter being called.


Return Value:

    Status code that indicates whether or not the function was successful.

--*/

{
    PAGED_CODE();

    return STATUS_SUCCESS;
}

BOOLEAN
ArbShareDriverExclusive(
    IN PARBITER_INSTANCE Arbiter,
    IN PARBITER_ALLOCATION_STATE State
    )

/*++

Routine Description:

    This routine implements support for CmResourceShareDriverExclusive disposition
    by overriding conflict if the owner and request share at least one common
    driver.

Arguments:

    Arbiter - The instance data of the arbiter who was called.

    State - The state of the current arbitration.

Return Value:

    TRUE if the conflict is allowable, false otherwise

--*/

{

    PRTL_RANGE current;
    RTL_RANGE_LIST_ITERATOR iterator;
    PDEVICE_OBJECT owner, other;
    ULONG enumeratorNameLength;
    WCHAR enumeratorName[sizeof(REGSTR_KEY_ROOTENUM) / sizeof(WCHAR)];
    NTSTATUS status;
    BOOLEAN isRootEnumerated;

    PAGED_CODE();

    isRootEnumerated = FALSE;
    status = IoGetDeviceProperty(
        State->Entry->PhysicalDeviceObject, 
        DevicePropertyEnumeratorName,
        sizeof(enumeratorName),
        enumeratorName,
        &enumeratorNameLength);
    if (NT_SUCCESS(status)) {

        if (_wcsicmp(enumeratorName, REGSTR_KEY_ROOTENUM) == 0) {

            isRootEnumerated = TRUE;
        }                
    }
    FOR_ALL_RANGES(Arbiter->PossibleAllocation, &iterator, current) {
        //
        // Only test the overlapping ones
        //
        if (INTERSECT(current->Start, current->End, State->CurrentMinimum, State->CurrentMaximum)) {
            //
            // Check if we should ignore the range because of its attributes
            //
            if (current->Attributes & State->RangeAvailableAttributes) {
                //
                // We DON'T set ok to true because we are just ignoring the range,
                // as RtlFindRange would have and thus it can't be the cause of
                // RtlFindRange failing, so ignoring it can't fix the conflict.
                //
                continue;
            }
            if (State->CurrentAlternative->Descriptor->ShareDisposition != CmResourceShareDriverExclusive &&
                !(current->Attributes & ARBITER_RANGE_SHARE_DRIVER_EXCLUSIVE)) {

                continue;
            }
            if (!current->Owner) {

                continue;
            }
            //
            // Special case ROOT enumerated devices.
            //
            if (isRootEnumerated) {

                status = IoGetDeviceProperty(
                    current->Owner, 
                    DevicePropertyEnumeratorName,
                    sizeof(enumeratorName),
                    enumeratorName,
                    &enumeratorNameLength);
                if (NT_SUCCESS(status)) {

                    if (_wcsicmp(enumeratorName, REGSTR_KEY_ROOTENUM) != 0) {

                        isRootEnumerated = FALSE;
                    }                
                }
            }
            //
            // If both devices are ROOT enumerated, override the conflict.
            //
            if (isRootEnumerated) {

                ARB_PRINT(2,
                            ("Overriding conflict on IRQ %04x for driver %wZ\n",
                            (ULONG)State->Start,
                            &owner->DriverObject->DriverName
                            ));
                State->Start=State->CurrentMinimum;
                State->End=State->CurrentMaximum;
                if (State->CurrentAlternative->Descriptor->ShareDisposition == CmResourceShareDriverExclusive) {

                    State->RangeAttributes |= ARBITER_RANGE_SHARE_DRIVER_EXCLUSIVE;
                }
                return TRUE;
            }
            //
            // Check if there is a common driver in the two stacks ignoring the 
            // one for the PDO.
            //
            owner = ((PDEVICE_OBJECT)(current->Owner))->AttachedDevice;
            while (owner) {

                other = (PDEVICE_OBJECT)(State->Entry->PhysicalDeviceObject)->AttachedDevice;
                while (other) {

                    if (owner->DriverObject == other->DriverObject) {

                        ARB_PRINT(2,
                                    ("Overriding conflict on IRQ %04x for driver %wZ\n",
                                    (ULONG)State->Start,
                                    &owner->DriverObject->DriverName
                                    ));
                        State->Start=State->CurrentMinimum;
                        State->End=State->CurrentMaximum;
                        if (State->CurrentAlternative->Descriptor->ShareDisposition == CmResourceShareDriverExclusive) {

                            State->RangeAttributes |= ARBITER_RANGE_SHARE_DRIVER_EXCLUSIVE;
                        }
                        return TRUE;
                    }
                    other = other->AttachedDevice;
                }
                owner = owner->AttachedDevice;
            }
        }
    }
    //
    // The conflict is still valid
    //
    return FALSE;
}

#if DBG
VOID
ArbpIndent(
    IN ULONG Count
    )
{
    UCHAR spaces[80];

    ASSERT(Count <= 80);

    RtlFillMemory(spaces, Count, '*');

    spaces[Count] = 0;

    DbgPrint("%s", spaces);

}
#endif
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\base\ntos\cache\ccperf.c ===
/*++

Copyright (c) 1989  Microsoft Corporation

Module Name:

   CcPerf.c

Abstract:

    This module contains the perf trace routines in Cc Component

Author:

    Stephen Hsiao (shsiao) 2-Feb-2001

Revision History:

--*/

#include "cc.h"

#ifdef ALLOC_PRAGMA
#pragma alloc_text(PAGEWMI, CcPerfFileRunDown)
#endif //ALLOC_PRAGMA

VOID
CcPerfFileRunDown(
    PPERFINFO_ENTRY_TABLE HashTable
    )
/*++

Routine Description:

    This routine walks the following lists:

    1. CcDirtySharedCacheMapList
    2. CcCleanSharedCacheMapList
    
    and returns a pointer to a pool allocation
    containing the referenced file object pointers.

Arguments:
 
    None.
 
Return Value:
 
    Returns a pointer to a NULL terminated pool allocation 
    containing the file object pointers from the two lists, 
    NULL if the memory could not be allocated.
     
    It is also the responsibility of the caller to dereference each
    file object in the list and then free the returned pool.

Environment:

    PASSIVE_LEVEL, arbitrary thread context.
--*/
{
    KIRQL OldIrql;
    PSHARED_CACHE_MAP SharedCacheMap;

    ASSERT (KeGetCurrentIrql () == PASSIVE_LEVEL);

    CcAcquireMasterLock( &OldIrql );

    //
    // Walk through CcDirtySharedCacheMapList
    //
    
    SharedCacheMap = CONTAINING_RECORD( CcDirtySharedCacheMapList.SharedCacheMapLinks.Flink,
                                        SHARED_CACHE_MAP,
                                        SharedCacheMapLinks );
    
    while (&SharedCacheMap->SharedCacheMapLinks != &CcDirtySharedCacheMapList.SharedCacheMapLinks) {
        //
        //  Skip over cursors
        //
        if (!FlagOn(SharedCacheMap->Flags, IS_CURSOR)) {
            PerfInfoAddToFileHash(HashTable, SharedCacheMap->FileObject);
        }
        SharedCacheMap = CONTAINING_RECORD( SharedCacheMap->SharedCacheMapLinks.Flink,
                                            SHARED_CACHE_MAP,
                                            SharedCacheMapLinks );
    }                   

    //
    // CcCleanSharedCacheMapList
    //
    SharedCacheMap = CONTAINING_RECORD( CcCleanSharedCacheMapList.Flink,
                                        SHARED_CACHE_MAP,
                                        SharedCacheMapLinks );

    while (&SharedCacheMap->SharedCacheMapLinks != &CcCleanSharedCacheMapList) {
        PerfInfoAddToFileHash(HashTable, SharedCacheMap->FileObject);

        SharedCacheMap = CONTAINING_RECORD( SharedCacheMap->SharedCacheMapLinks.Flink,
                                            SHARED_CACHE_MAP,
                                            SharedCacheMapLinks );

    }

    CcReleaseMasterLock( OldIrql );
    return;
}
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\base\ntos\cache\cc.h ===
/*++

Copyright (c) 1990  Microsoft Corporation

Module Name:

    cc.h

Abstract:

    This module is a header file for the Memory Management based cache
    management routines for the common Cache subsystem.

Author:

    Tom Miller      [TomM]      4-May-1990

Revision History:

--*/

#ifndef _CCh_
#define _CCh_

#pragma warning(disable:4214)   // bit field types other than int
#pragma warning(disable:4201)   // nameless struct/union
#pragma warning(disable:4127)   // condition expression is constant
#pragma warning(disable:4115)   // named type definition in parentheses

#include <ntos.h>
#include <NtIoLogc.h>

#ifdef MEMPRINT
#include <memprint.h>
#endif

//
// Define macros to acquire and release cache manager locks.
//

#define CcAcquireMasterLock( OldIrql ) \
    *( OldIrql ) = KeAcquireQueuedSpinLock( LockQueueMasterLock )

#define CcReleaseMasterLock( OldIrql ) \
    KeReleaseQueuedSpinLock( LockQueueMasterLock, OldIrql )

#define CcAcquireMasterLockAtDpcLevel() \
    KeAcquireQueuedSpinLockAtDpcLevel( &KeGetCurrentPrcb()->LockQueue[LockQueueMasterLock] )

#define CcReleaseMasterLockFromDpcLevel() \
    KeReleaseQueuedSpinLockFromDpcLevel( &KeGetCurrentPrcb()->LockQueue[LockQueueMasterLock] )

#define CcAcquireVacbLock( OldIrql ) \
    *( OldIrql ) = KeAcquireQueuedSpinLock( LockQueueVacbLock )

#define CcReleaseVacbLock( OldIrql ) \
    KeReleaseQueuedSpinLock( LockQueueVacbLock, OldIrql )

#define CcAcquireVacbLockAtDpcLevel() \
    KeAcquireQueuedSpinLockAtDpcLevel( &KeGetCurrentPrcb()->LockQueue[LockQueueVacbLock] )

#define CcReleaseVacbLockFromDpcLevel() \
    KeReleaseQueuedSpinLockFromDpcLevel( &KeGetCurrentPrcb()->LockQueue[LockQueueVacbLock] )

#define CcAcquireWorkQueueLock( OldIrql ) \
    *( OldIrql ) = KeAcquireQueuedSpinLock( LockQueueWorkQueueLock )

#define CcReleaseWorkQueueLock( OldIrql ) \
    KeReleaseQueuedSpinLock( LockQueueWorkQueueLock, OldIrql )

#define CcAcquireWorkQueueLockAtDpcLevel() \
    KeAcquireQueuedSpinLockAtDpcLevel( &KeGetCurrentPrcb()->LockQueue[LockQueueWorkQueueLock] )

#define CcReleaseWorkQueueLockFromDpcLevel() \
    KeReleaseQueuedSpinLockFromDpcLevel( &KeGetCurrentPrcb()->LockQueue[LockQueueWorkQueueLock] )

//
//  This turns on the Bcb list debugging in a debug system.  Set value
//  to 0 to turn off.
//
//  ****    Note it must currently be turned off because the routines in
//          pinsup.c that manipulate this list need to be changed to do the
//          right thing for Obcbs.  Right now they get messed up by inserting Obcbs
//          (which may not be large enough among other things) into the global
//          list.  Ideally each place gets some code to insert the underlying
//          Bcbs into the list if they are not already there.
//

#if DBG
#define LIST_DBG 0
#endif

#include <FsRtl.h>

//
//  Peek at number of available pages.
//

extern PFN_COUNT MmAvailablePages;

//
//  Define our node type codes.
//

#define CACHE_NTC_SHARED_CACHE_MAP       (0x2FF)
#define CACHE_NTC_PRIVATE_CACHE_MAP      (0x2FE)
#define CACHE_NTC_BCB                    (0x2FD)
#define CACHE_NTC_DEFERRED_WRITE         (0x2FC)
#define CACHE_NTC_MBCB                   (0x2FB)
#define CACHE_NTC_OBCB                   (0x2FA)
#define CACHE_NTC_MBCB_GRANDE            (0x2F9)

//
//  The following definitions are used to generate meaningful blue bugcheck
//  screens.  On a bugcheck the file system can output 4 ulongs of useful
//  information.  The first ulong will have encoded in it a source file id
//  (in the high word) and the line number of the bugcheck (in the low word).
//  The other values can be whatever the caller of the bugcheck routine deems
//  necessary.
//
//  Each individual file that calls bugcheck needs to have defined at the
//  start of the file a constant called BugCheckFileId with one of the
//  CACHE_BUG_CHECK_ values defined below and then use CcBugCheck to bugcheck
//  the system.
//

#define CACHE_BUG_CHECK_CACHEDAT           (0x00010000)
#define CACHE_BUG_CHECK_CACHESUB           (0x00020000)
#define CACHE_BUG_CHECK_COPYSUP            (0x00030000)
#define CACHE_BUG_CHECK_FSSUP              (0x00040000)
#define CACHE_BUG_CHECK_LAZYRITE           (0x00050000)
#define CACHE_BUG_CHECK_LOGSUP             (0x00060000)
#define CACHE_BUG_CHECK_MDLSUP             (0x00070000)
#define CACHE_BUG_CHECK_PINSUP             (0x00080000)
#define CACHE_BUG_CHECK_VACBSUP            (0x00090000)

#define CcBugCheck(A,B,C) { KeBugCheckEx(CACHE_MANAGER, BugCheckFileId | __LINE__, A, B, C ); }

//
//  Define maximum View Size (These constants are currently so chosen so
//  as to be exactly a page worth of PTEs.
//

#define DEFAULT_CREATE_MODULO            ((ULONG)(0x00100000))
#define DEFAULT_EXTEND_MODULO            ((ULONG)(0x00100000))

//
//  For non FO_RANDOM_ACCESS files, define how far we go before umapping
//  views.
//

#define SEQUENTIAL_MAP_LIMIT        ((ULONG)(0x00080000))

//
//  Define some constants to drive read ahead and write behind
//

//
//  Set max read ahead.  Even though some drivers, such as AT, break up transfers >= 128kb,
//  we need to permit enough readahead to satisfy plausible cached read operation while
//  preventing denial of service attacks.
//
//  This value used to be set to 64k.  When doing cached reads in larger units (128k), we
//  would never be bringing in enough data to keep the user from blocking. 8mb is
//  arbitrarily chosen to be greater than plausible RAID bandwidth and user operation size
//  by a factor of 3-4.
//

#define MAX_READ_AHEAD                   (8 * 1024 * 1024)

//
//  Set maximum write behind / lazy write (most drivers break up transfers >= 64kb)
//

#define MAX_WRITE_BEHIND                 (MM_MAXIMUM_DISK_IO_SIZE)

//
//  Set a throttle for charging a given write against the total number of dirty
//  pages in the system, for the purpose of seeing when we should invoke write
//  throttling.
//
//  This must be the same as the throttle used for seeing when we must flush
//  temporary files in the lazy writer.  On the back of the envelope, here
//  is why:
//
//      RDP = Regular File Dirty Pages
//      TDP = Temporary File Dirty Pages
//      CWT = Charged Write Throttle
//          -> the maximum we will charge a user with when we see if
//              he should be throttled
//      TWT = Temporary Write Throttle
//          -> if we can't write this many pages, we must write temp data
//      DPT = Dirty Page Threshold
//          -> the limit when write throttling kicks in
//
//      PTD = Pages To Dirty
//      CDP = Charged Dirty Pages
//
//      Now, CDP = Min( PTD, CWT).
//
//      Excluding other effects, we throttle when:
//          #0  (RDP + TDP) + CPD >= DPT
//
//      To write temporary data, we must cause:
//          #1  (RDP + TDP) + TWT >= DPT
//
//      To release the throttle, we must eventually cause:
//          #2  (RDP + TDP) + CDP < DPT
//
//      Now, imagine TDP >> RDP (perhaps RDP == 0) and CDP == CWT for a particular
//      throttled write.
//
//      If CWT > TWT, as we drive RDP to zero (we never defer writing regular
//      data except for hotspots or other very temporary conditions), it is clear
//      that we may never trigger the writing of temporary data (#1) but also
//      never release the throttle (#2).  Simply, we would be willing to charge
//      for more dirty pages than we would be willing to guarantee are available
//      to dirty.  Hence, potential deadlock.
//
//      CWT < TWT I leave aside for the moment.  This would mean we try not to
//      allow temporary data to accumulate to the point that writes throttle as
//      a result.  Perhaps this would even be better than CWT == TWT.
//
//  It is legitimate to ask if throttling temporary data writes should be relaxed
//  if we see a large amount of dirty temp data accumulate (and it would be very
//  easy to keep track of this).  I don't claim to know the best answer to this,
//  but for now the attempt to avoid temporary data writes at all costs still
//  fits the reasonable operation mix, and we will only penalize the outside
//  oddcase with a little more throttle/release.
//

#define WRITE_CHARGE_THRESHOLD          (64 * PAGE_SIZE)

//
//  Define constants to control zeroing of file data: one constant to control
//  how much data we will actually zero ahead in the cache, and another to
//  control what the maximum transfer size is that we will use to write zeros.
//

#define MAX_ZERO_TRANSFER               (PAGE_SIZE * 128)
#define MIN_ZERO_TRANSFER               (0x10000)
#define MAX_ZEROS_IN_CACHE              (0x10000)

//
//  Definitions for multi-level Vacb structure.  The primary definition is the
//  VACB_LEVEL_SHIFT.  In a multi-level Vacb structure, level in the tree of
//  pointers has 2 ** VACB_LEVEL_SHIFT pointers.
//
//  For test, this value may be set as low as 4 (no lower), a value of 10 corresponds
//  to a convenient block size of 4KB.  (If set to 2, CcExtendVacbArray will try to
//  "push" the Vacb array allocated within the SharedCacheMap, and later someone will
//  try to deallocate the middle of the SharedCacheMap.  At 3, the MBCB_BITMAP_BLOCK_SIZE
//  is larger than MBCB_BITMAP_BLOCK_SIZE)
//
//  There is a bit of a trick as we make the jump to the multilevel structure in that
//  we need a real fixed reference count.
//

#define VACB_LEVEL_SHIFT                  (7)

//
//  This is how many bytes of pointers are at each level.  This is the size for both
//  the Vacb array and (optional) Bcb listheads.  It does not include the reference
//  block.
//

#define VACB_LEVEL_BLOCK_SIZE             ((1 << VACB_LEVEL_SHIFT) * sizeof(PVOID))

//
//  This is the last index for a level.
//

#define VACB_LAST_INDEX_FOR_LEVEL         ((1 << VACB_LEVEL_SHIFT) - 1)

//
//  This is the size of file which can be handled in a single level.
//

#define VACB_SIZE_OF_FIRST_LEVEL         (1 << (VACB_OFFSET_SHIFT + VACB_LEVEL_SHIFT))

//
//  This is the maximum number of levels it takes to support 63-bits.  It is
//  used for routines that must remember a path.
//

#define VACB_NUMBER_OF_LEVELS            (((63 - VACB_OFFSET_SHIFT)/VACB_LEVEL_SHIFT) + 1)

//
//  Define the reference structure for multilevel Vacb trees.
//

typedef struct _VACB_LEVEL_REFERENCE {

    LONG Reference;
    LONG SpecialReference;

} VACB_LEVEL_REFERENCE, *PVACB_LEVEL_REFERENCE;

//
//  Define the size of a bitmap allocated for a bitmap range, in bytes.
//

#define MBCB_BITMAP_BLOCK_SIZE           (VACB_LEVEL_BLOCK_SIZE)

//
//  Define how many bytes of a file are covered by an Mbcb bitmap range,
//  at a bit for each page.
//

#define MBCB_BITMAP_RANGE                (MBCB_BITMAP_BLOCK_SIZE * 8 * PAGE_SIZE)

//
//  Define the initial size of the Mbcb bitmap that is self-contained in the Mbcb.
//

#define MBCB_BITMAP_INITIAL_SIZE         (2 * sizeof(BITMAP_RANGE))

//
//  Define constants controlling when the Bcb list is broken into a
//  pendaflex-style array of listheads, and how the correct listhead
//  is found.  Begin when file size exceeds 2MB, and cover 512KB per
//  listhead.  At 512KB per listhead, the BcbListArray is the same
//  size as the Vacb array, i.e., it doubles the size.
//
//  The code handling these Bcb lists in the Vacb package contains
//  assumptions that the size is the same as that of the Vacb pointers.
//  Future work could undo this, but until then the size and shift
//  below cannot change.  There really isn't a good reason to want to
//  anyway.
//
//  Note that by definition a flat vacb array cannot fail to find an
//  exact match when searching for the listhead - this is only a
//  complication of the sparse structure.
//


#define BEGIN_BCB_LIST_ARRAY             (0x200000)
#define SIZE_PER_BCB_LIST                (VACB_MAPPING_GRANULARITY * 2)
#define BCB_LIST_SHIFT                   (VACB_OFFSET_SHIFT + 1)

#define GetBcbListHead(SCM,OFF,FAILSUCC) (                                                         \
  (((SCM)->SectionSize.QuadPart > BEGIN_BCB_LIST_ARRAY) &&                                         \
   FlagOn((SCM)->Flags, MODIFIED_WRITE_DISABLED)) ?                                                \
   (((SCM)->SectionSize.QuadPart > VACB_SIZE_OF_FIRST_LEVEL) ?                                     \
    CcGetBcbListHeadLargeOffset((SCM),(OFF),(FAILSUCC)) :                                          \
    (((OFF) >= (SCM)->SectionSize.QuadPart) ? &(SCM)->BcbList :                                    \
     ((PLIST_ENTRY)((SCM)->Vacbs) + (((SCM)->SectionSize.QuadPart + (OFF)) >> BCB_LIST_SHIFT)))) : \
   &(SCM)->BcbList                                                                                 \
)

//
//  Macros to lock/unlock a Vacb level as Bcbs are inserted/deleted
//

#define CcLockVacbLevel(SCM,OFF) {                                                               \
    if (((SCM)->SectionSize.QuadPart > VACB_SIZE_OF_FIRST_LEVEL) &&                              \
        FlagOn(SharedCacheMap->Flags, MODIFIED_WRITE_DISABLED)) {                                \
    CcAdjustVacbLevelLockCount((SCM),(OFF), +1);}                                                \
}

#define CcUnlockVacbLevel(SCM,OFF) {                                                             \
    if (((SCM)->SectionSize.QuadPart > VACB_SIZE_OF_FIRST_LEVEL) &&                              \
        FlagOn(SharedCacheMap->Flags, MODIFIED_WRITE_DISABLED)) {                                \
    CcAdjustVacbLevelLockCount((SCM),(OFF), -1);}                                                \
}

//
//  NOISE_BITS defines how many bits are masked off when testing for
//  sequential reads.  This allows the reader to skip up to 7 bytes
//  for alignment purposes, and we still consider the next read to be
//  sequential.  Starting and ending addresses are masked by this pattern
//  before comparison.
//

#define NOISE_BITS                       (0x7)

//
//  Define some constants to drive the Lazy Writer
//

#define LAZY_WRITER_IDLE_DELAY           ((LONG)(10000000))
#define LAZY_WRITER_COLLISION_DELAY      ((LONG)(1000000))

//
//  The following target should best be a power of 2
//

#define LAZY_WRITER_MAX_AGE_TARGET       ((ULONG)(8))

//
//  Requeue information hint for the lazy writer.
//

#define CC_REQUEUE                       35422

//
//  The global Cache Manager debug level variable, its values are:
//
//      0x00000000      Always gets printed (used when about to bug check)
//
//      0x00000001      FsSup
//      0x00000002      CacheSub
//      0x00000004      CopySup
//      0x00000008      PinSup
//
//      0x00000010      MdlSup
//      0x00000020      LazyRite
//      0x00000040
//      0x00000080
//
//      0x00000100      Trace all Mm calls
//

#define mm (0x100)

//
//  Miscellaneous support macros.
//
//      ULONG
//      FlagOn (
//          IN ULONG Flags,
//          IN ULONG SingleFlag
//          );
//
//      BOOLEAN
//      BooleanFlagOn (
//          IN ULONG Flags,
//          IN ULONG SingleFlag
//          );
//
//      VOID
//      SetFlag (
//          IN ULONG Flags,
//          IN ULONG SingleFlag
//          );
//
//      VOID
//      ClearFlag (
//          IN ULONG Flags,
//          IN ULONG SingleFlag
//          );
//
//      ULONG
//      QuadAlign (
//          IN ULONG Pointer
//          );
//

#define FlagOn(F,SF) ( \
    (((F) & (SF)))     \
)

#define BooleanFlagOn(F,SF) (    \
    (BOOLEAN)(((F) & (SF)) != 0) \
)

#define SetFlag(F,SF) { \
    (F) |= (SF);        \
}

#define ClearFlag(F,SF) { \
    (F) &= ~(SF);         \
}

#define QuadAlign(P) (             \
    ((((P)) + 7) & (-8)) \
)

//
//  Turn on pseudo-asserts if CC_FREE_ASSERTS is defined.
//

#if (!DBG && defined( CC_FREE_ASSERTS ))
#undef ASSERT
#undef ASSERTMSG
#define ASSERT(exp)                                             \
    ((exp) ? TRUE :                                             \
             (DbgPrint( "%s:%d %s\n",__FILE__,__LINE__,#exp ),  \
              DbgBreakPoint(),                                  \
              TRUE))
#define ASSERTMSG(msg,exp)                                              \
    ((exp) ? TRUE :                                                     \
             (DbgPrint( "%s:%d %s %s\n",__FILE__,__LINE__,msg,#exp ),   \
              DbgBreakPoint(),                                          \
              TRUE))
#endif


//
//  Define the Virtual Address Control Block, which controls all mapping
//  performed by the Cache Manager.
//

//
//  First some constants
//

#define PREALLOCATED_VACBS               (4)

//
//  Virtual Address Control Block
//

typedef struct _VACB {

    //
    //  Base Address for this control block.
    //

    PVOID BaseAddress;

    //
    //  Pointer to the Shared Cache Map using this Vacb.
    //

    struct _SHARED_CACHE_MAP *SharedCacheMap;

    //
    //  Overlay for remembering mapped offset within the Shared Cache Map,
    //  and the count of the number of times this Vacb is in use.
    //

    union {

        //
        //  File Offset within Shared Cache Map
        //

        LARGE_INTEGER FileOffset;

        //
        //  Count of number of times this Vacb is in use.  The size of this
        //  count is calculated to be adequate, while never large enough to
        //  overwrite nonzero bits of the FileOffset, which is a multiple
        //  of VACB_MAPPING_GRANULARITY.
        //

        USHORT ActiveCount;

    } Overlay;

    //
    //  Entry for the VACB reuse list
    //

    LIST_ENTRY LruList;

} VACB, *PVACB;

//
//  These define special flag values that are overloaded as PVACB.  They cause
//  certain special behavior, currently only in the case of multilevel structures.
//

#define VACB_SPECIAL_REFERENCE           ((PVACB) ~0)
#define VACB_SPECIAL_DEREFERENCE         ((PVACB) ~1)

#define VACB_SPECIAL_FIRST_VALID         VACB_SPECIAL_DEREFERENCE



#define PRIVATE_CACHE_MAP_READ_AHEAD_ACTIVE     0x10000
#define PRIVATE_CACHE_MAP_READ_AHEAD_ENABLED    0x20000

typedef struct _PRIVATE_CACHE_MAP_FLAGS {
    ULONG DontUse : 16;                     // Overlaid with NodeTypeCode

    //
    //  This flag says read ahead is currently active, which means either
    //  a file system call to CcReadAhead is still determining if the
    //  desired data is already resident, or else a request to do read ahead
    //  has been queued to a worker thread.
    //

    ULONG ReadAheadActive : 1;

    //
    //  Flag to say whether read ahead is currently enabled for this
    //  FileObject/PrivateCacheMap.  On read misses it is enabled on
    //  read ahead hits it will be disabled.  Initially disabled.
    //

    ULONG ReadAheadEnabled : 1;

    ULONG Available : 14;
} PRIVATE_CACHE_MAP_FLAGS;

#define CC_SET_PRIVATE_CACHE_MAP(PrivateCacheMap, Flags) \
    RtlInterlockedSetBitsDiscardReturn (&PrivateCacheMap->UlongFlags, Flags);

#define CC_CLEAR_PRIVATE_CACHE_MAP(PrivateCacheMap, Feature) \
    RtlInterlockedAndBitsDiscardReturn (&PrivateCacheMap->UlongFlags, (ULONG)~Feature);

//
//  The Private Cache Map is a structure pointed to by the File Object, whenever
//  a file is opened with caching enabled (default).
//

typedef struct _PRIVATE_CACHE_MAP {

    //
    //  Type and size of this record
    //

    union {
        CSHORT NodeTypeCode;
        PRIVATE_CACHE_MAP_FLAGS Flags;
        ULONG UlongFlags;
    };

    //
    //  Read Ahead mask formed from Read Ahead granularity - 1.
    //  Private Cache Map ReadAheadSpinLock controls access to this field.
    //

    ULONG ReadAheadMask;

    //
    //  Pointer to FileObject for this PrivateCacheMap.
    //

    PFILE_OBJECT FileObject;

    //
    //  READ AHEAD CONTROL
    //
    //  Read ahead history for determining when read ahead might be
    //  beneficial.
    //

    LARGE_INTEGER FileOffset1;
    LARGE_INTEGER BeyondLastByte1;

    LARGE_INTEGER FileOffset2;
    LARGE_INTEGER BeyondLastByte2;

    //
    //  Current read ahead requirements.
    //
    //  Array element 0 is optionally used for recording remaining bytes
    //  required for satisfying a large Mdl read.
    //
    //  Array element 1 is used for predicted read ahead.
    //

    LARGE_INTEGER ReadAheadOffset[2];
    ULONG ReadAheadLength[2];

    //
    //  SpinLock controlling access to following fields
    //

    KSPIN_LOCK ReadAheadSpinLock;

    //
    // Links for list of all PrivateCacheMaps linked to the same
    // SharedCacheMap.
    //

    LIST_ENTRY PrivateLinks;

} PRIVATE_CACHE_MAP;

typedef PRIVATE_CACHE_MAP *PPRIVATE_CACHE_MAP;


//
//  The Shared Cache Map is a per-file structure pointed to indirectly by
//  each File Object.  The File Object points to a pointer in a single
//  FS-private structure for the file (Fcb).  The SharedCacheMap maps the
//  first part of the file for common access by all callers.
//

//
//  OpenCount log Reasons/Actions
//

#if OPEN_COUNT_LOG
typedef struct _CC_OPEN_COUNT_LOG_ENTRY {
    ULONG Action;
    ULONG Reason;
} CC_OPEN_COUNT_LOG_ENTRY;

typedef struct _CC_OPEN_COUNT_LOG {
    USHORT Next;
    USHORT Size;
    CC_OPEN_COUNT_LOG_ENTRY Log[48];
} CC_OPEN_COUNT_LOG;

#define CcAddOpenToLog( LOG, ACTION, REASON ) {             \
    (LOG)->Log[(LOG)->Next].Action = (ACTION);              \
    (LOG)->Log[(LOG)->Next].Reason = (REASON);              \
    (LOG)->Next += 1;                                       \
    if ((LOG)->Next == (LOG)->Size) {                       \
        (LOG)->Next = 0;                                    \
    }                                                       \
}
#else  // OPEN_COUNT_LOG
#define CcAddOpenToLog( LOG, ACTION, REASON )
#endif // OPEN_COUNT_LOG

#define CcIncrementOpenCount( SCM, REASON ) {               \
    (SCM)->OpenCount += 1;                                  \
    if (REASON != 0) {                                      \
        CcAddOpenToLog( &(SCM)->OpenCountLog, REASON, 1 );  \
    }                                                       \
}

#define CcDecrementOpenCount( SCM, REASON ) {               \
    (SCM)->OpenCount -= 1;                                  \
    if (REASON != 0) {                                      \
        CcAddOpenToLog( &(SCM)->OpenCountLog, REASON, -1 ); \
    }                                                       \
}

typedef struct _SHARED_CACHE_MAP {

    //
    //  Type and size of this record
    //

    CSHORT NodeTypeCode;
    CSHORT NodeByteSize;

    //
    //  Number of times this file has been opened cached.
    //

    ULONG OpenCount;

    //
    //  Actual size of file, primarily for restricting Read Ahead.  Initialized
    //  on creation and maintained by extend and truncate operations.
    //
    //  NOTE:   This field may never be moved, thanks to the late DavidGoe,
    //          who should have written this comment himself :-(   cache.h
    //          exports a macro which "knows" that FileSize is the second
    //          longword in the Cache Map!
    //

    LARGE_INTEGER FileSize;

    //
    //  Bcb Listhead.  The BcbList is ordered by descending
    //  FileOffsets, to optimize misses in the sequential I/O case.
    //  Synchronized by the BcbSpinLock.
    //

    LIST_ENTRY BcbList;

    //
    //  Size of section created.
    //

    LARGE_INTEGER SectionSize;

    //
    //  ValidDataLength for file, as currently stored by the file system.
    //  Synchronized by the BcbSpinLock or exclusive access by FileSystem.
    //

    LARGE_INTEGER ValidDataLength;

    //
    //  Goal for ValidDataLength, when current dirty data is written.
    //  Synchronized by the BcbSpinLock or exclusive access by FileSystem.
    //

    LARGE_INTEGER ValidDataGoal;

    //
    //  Pointer to a contiguous array of Vacb pointers which control mapping
    //  to this file, along with Vacbs (currently) for a 1MB file.
    //  Synchronized by CcVacbSpinLock.
    //

    PVACB InitialVacbs[PREALLOCATED_VACBS];
    PVACB * Vacbs;

    //
    //  Referenced pointer to original File Object on which the SharedCacheMap
    //  was created.
    //

    PFILE_OBJECT FileObject;

    //
    //  Describe Active Vacb and Page for copysup optimizations.
    //

    volatile PVACB ActiveVacb;

    //
    //  Virtual address needing zero to end of page
    //

    volatile PVOID NeedToZero;

    ULONG ActivePage;
    ULONG NeedToZeroPage;

    //
    //  Fields for synchronizing on active requests.
    //

    KSPIN_LOCK ActiveVacbSpinLock;
    ULONG VacbActiveCount;

    //
    //  Number of dirty pages in this SharedCacheMap.  Used to trigger
    //  write behind.  Synchronized by CcMasterSpinLock.
    //

    ULONG DirtyPages;

    //
    //  THE NEXT TWO FIELDS MUST BE ADJACENT, TO SUPPORT
    //  SHARED_CACHE_MAP_LIST_CURSOR!
    //
    //  Links for Global SharedCacheMap List
    //

    LIST_ENTRY SharedCacheMapLinks;

    //
    //  Shared Cache Map flags (defined below)
    //

    ULONG Flags;

    //
    //  Status variable set by creator of SharedCacheMap
    //

    NTSTATUS Status;

    //
    //  Mask Bcb for this SharedCacheMap, if there is one.
    //  Synchronized by the BcbSpinLock.
    //

    struct _MBCB *Mbcb;

    //
    //  Pointer to the common Section Object used by the file system.
    //

    PVOID Section;

    //
    //  This event pointer is used to handle creation collisions.
    //  If a second thread tries to call CcInitializeCacheMap for the
    //  same file, while BeingCreated (below) is TRUE, then that thread
    //  will allocate an event store it here (if not already allocated),
    //  and wait on it.  The first creator will set this event when it
    //  is done.  The event is not deleted until CcUninitializedCacheMap
    //  is called, to avoid possible race conditions.  (Note that normally
    //  the event never has to be allocated.
    //

    PKEVENT CreateEvent;

    //
    //  This points to an event used to wait for active count to go to zero
    //

    PKEVENT WaitOnActiveCount;

    //
    //  These two fields control the writing of large metadata
    //  streams.  The first field gives a target for the current
    //  flush interval, and the second field stores the end of
    //  the last flush that occurred on this file.
    //

    ULONG PagesToWrite;
    LONGLONG BeyondLastFlush;

    //
    //  Pointer to structure of routines used by the Lazy Writer to Acquire
    //  and Release the file for Lazy Write and Close, to avoid deadlocks,
    //  and the context to call them with.
    //

    PCACHE_MANAGER_CALLBACKS Callbacks;

    PVOID LazyWriteContext;

    //
    //  Listhead of all PrivateCacheMaps linked to this SharedCacheMap.
    //

    LIST_ENTRY PrivateList;

    //
    //  Log handle specified for this shared cache map, for support of routines
    //  in logsup.c
    //

    PVOID LogHandle;

    //
    //  Callback routine specified for flushing to Lsn.
    //

    PFLUSH_TO_LSN FlushToLsnRoutine;

    //
    //  Dirty Page Threshold for this stream
    //

    ULONG DirtyPageThreshold;

    //
    //  Lazy Writer pass count.  Used by the Lazy Writer for
    //  no modified write streams, which are not serviced on
    //  every pass in order to avoid contention with foreground
    //  activity.
    //

    ULONG LazyWritePassCount;

    //
    //  This event pointer is used to allow a file system to be notified when
    //  the deletion of a shared cache map.
    //
    //  This has to be provided here because the cache manager may decide to
    //  "Lazy Delete" the shared cache map, and some network file systems
    //  will want to know when the lazy delete completes.
    //

    PCACHE_UNINITIALIZE_EVENT UninitializeEvent;

    //
    //  This Vacb pointer is needed for keeping the NeedToZero virtual address
    //  valid.
    //

    PVACB NeedToZeroVacb;

    //
    //  Spinlock for synchronizing the Mbcb and Bcb lists - must be acquired
    //  before CcMasterSpinLock.  This spinlock also synchronizes ValidDataGoal
    //  and ValidDataLength, as described above.
    //

    KSPIN_LOCK BcbSpinLock;

    PVOID Reserved;

    //
    //  This is an event which may be used for the WaitOnActiveCount event.  We
    //  avoid overhead by only "activating" it when it is needed.
    //

    KEVENT Event;

    EX_PUSH_LOCK VacbPushLock;
    
    //
    //  Preallocate one PrivateCacheMap to reduce pool allocations.
    //

    PRIVATE_CACHE_MAP PrivateCacheMap;

#if OPEN_COUNT_LOG

    //
    //  Instrument reasons for OpenCount
    //

    CC_OPEN_COUNT_LOG OpenCountLog;

#endif

} SHARED_CACHE_MAP;

typedef SHARED_CACHE_MAP *PSHARED_CACHE_MAP;

//
//  Shared Cache Map Flags
//

//
//  Read ahead has been disabled on this file.
//

#define DISABLE_READ_AHEAD               0x0001

//
//  Write behind has been disabled on this file.
//

#define DISABLE_WRITE_BEHIND             0x0002

//
//  This flag indicates whether CcInitializeCacheMap was called with
//  PinAccess = TRUE.
//

#define PIN_ACCESS                       0x0004

//
//  This flag indicates that a truncate is required when OpenCount
//  goes to 0.
//

#define TRUNCATE_REQUIRED                0x0010

//
//  This flag indicates that a LazyWrite request is queued.
//

#define WRITE_QUEUED                     0x0020

//
//  This flag indicates that we have never seen anyone cache
//  the file except for with FO_SEQUENTIAL_ONLY, so we should
//  tell MM to quickly dump pages when we unmap.
//

#define ONLY_SEQUENTIAL_ONLY_SEEN        0x0040

//
//  Active Page is locked
//

#define ACTIVE_PAGE_IS_DIRTY             0x0080

//
//  Flag to say that a create is in progress.
//

#define BEING_CREATED                    0x0100

//
//  Flag to say that modified write was disabled on the section.
//

#define MODIFIED_WRITE_DISABLED          0x0200

//
//  Flag that indicates if a lazy write ever occurred on this file.
//

#define LAZY_WRITE_OCCURRED              0x0400

//
//  Flag that indicates this structure is only a cursor, only the
//  SharedCacheMapLinks and Flags are valid!
//

#define IS_CURSOR                        0x0800

//
//  Flag that indicates that we have seen someone cache this file
//  and specify FO_RANDOM_ACCESS.  This will deactivate our cache
//  working set trim assist.
//

#define RANDOM_ACCESS_SEEN               0x1000

//
//  Flag indicating that the stream is private write.  This disables
//  non-aware flush/purge.
//

#define PRIVATE_WRITE                    0x2000

//
//  Cursor structure for traversing the SharedCacheMap lists.  Anyone
//  scanning these lists must verify that the IS_CURSOR flag is clear
//  before looking at other SharedCacheMap fields.
//


typedef struct _SHARED_CACHE_MAP_LIST_CURSOR {

    //
    //  Links for Global SharedCacheMap List
    //

    LIST_ENTRY SharedCacheMapLinks;

    //
    //  Shared Cache Map flags, IS_CURSOR must be set.
    //

    ULONG Flags;

} SHARED_CACHE_MAP_LIST_CURSOR, *PSHARED_CACHE_MAP_LIST_CURSOR;



#ifndef KDEXT
//
//  Bitmap Range structure.  For small files there is just one embedded in the
//  Mbcb.  For large files there may be many of these linked to the Mbcb.
//

typedef struct _BITMAP_RANGE {

    //
    //  Links for the list of bitmap ranges off the Mbcb.
    //

    LIST_ENTRY Links;

    //
    //  Base page (FileOffset / PAGE_SIZE) represented by this range.
    //  (Size is a fixed maximum.)
    //

    LONGLONG BasePage;

    //
    //  First and Last dirty pages relative to the BasePage.
    //

    ULONG FirstDirtyPage;
    ULONG LastDirtyPage;

    //
    //  Number of dirty pages in this range.
    //

    ULONG DirtyPages;

    //
    //  Pointer to the bitmap for this range.
    //

    PULONG Bitmap;

} BITMAP_RANGE, *PBITMAP_RANGE;
#endif

//
//  This structure is a "mask" Bcb.  For fast simple write operations,
//  a mask Bcb is used so that we basically only have to set bits to remember
//  where the dirty data is.
//

typedef struct _MBCB {

    //
    //  Type and size of this record
    //

    CSHORT NodeTypeCode;
    CSHORT NodeIsInZone;

    //
    //  This field is used as a scratch area for the Lazy Writer to
    //  guide how much he will write each time he wakes up.
    //

    ULONG PagesToWrite;

    //
    //  Number of dirty pages (set bits) in the bitmap below.
    //

    ULONG DirtyPages;

    //
    //  Reserved for alignment.
    //

    ULONG Reserved;

    //
    //  ListHead of Bitmap ranges.
    //

    LIST_ENTRY BitmapRanges;

    //
    //  This is a hint on where to resume writing, since we will not
    //  always write all of the dirty data at once.
    //

    LONGLONG ResumeWritePage;

    //
    //  Initial three embedded Bitmap ranges.  For a file up to 2MB, only the
    //  first range is used, and the rest of the Mbcb contains bits for 2MB of
    //  dirty pages (4MB on Alpha).  For larger files, all three ranges may
    //  be used to describe external bitmaps.
    //

    BITMAP_RANGE BitmapRange1;
    BITMAP_RANGE BitmapRange2;
    BITMAP_RANGE BitmapRange3;

} MBCB;

typedef MBCB *PMBCB;


//
//  This is the Buffer Control Block structure for representing data which
//  is "pinned" in memory by one or more active requests and/or dirty.  This
//  structure is created the first time that a call to CcPinFileData specifies
//  a particular integral range of pages.  It is deallocated whenever the Pin
//  Count reaches 0 and the Bcb is not Dirty.
//
//  NOTE: The first four fields must be the same as the PUBLIC_BCB.
//

typedef struct _BCB {

    union {

        //
        // To ensure QuadAlign (sizeof (BCB)) >= QuadAlign (sizeof (MBCB))
        // so that they can share the same pool blocks.
        //

        MBCB Dummy;

        struct {

            //
            //  Type and size of this record
            //

            CSHORT NodeTypeCode;

            //
            //  Flags
            //

            BOOLEAN Dirty;
            BOOLEAN Reserved;

            //
            //  Byte FileOffset and and length of entire buffer
            //

            ULONG  ByteLength;
            LARGE_INTEGER FileOffset;

            //
            //  Links for BcbList in SharedCacheMap
            //

            LIST_ENTRY BcbLinks;

            //
            //  Byte FileOffset of last byte in buffer (used for searching)
            //

            LARGE_INTEGER BeyondLastByte;

            //
            //  Oldest Lsn (if specified) when this buffer was set dirty.
            //

            LARGE_INTEGER OldestLsn;

            //
            //  Most recent Lsn specified when this buffer was set dirty.
            //  The FlushToLsnRoutine is called with this Lsn.
            //

            LARGE_INTEGER NewestLsn;

            //
            //  Pointer to Vacb via which this Bcb is mapped.
            //

            PVACB Vacb;

#if LIST_DBG
            //
            //  Links and caller addresses for the global Bcb list (for debug only)
            //

            LIST_ENTRY CcBcbLinks;
            PVOID CallerAddress;
            PVOID CallersCallerAddress;
#endif

            //
            //  Count of threads actively using this Bcb to process a request.
            //  This must be manipulated under protection of the BcbListSpinLock
            //  in the SharedCacheMap.
            //

            ULONG PinCount;

            //
            //  Resource to synchronize buffer access.  Pinning Readers and all Writers
            //  of the described buffer take out shared access (synchronization of
            //  buffer modifications is strictly up to the caller).  Note that pinning
            //  readers do not declare if they are going to modify the buffer or not.
            //  Anyone writing to disk takes out exclusive access, to prevent the buffer
            //  from changing while it is being written out.
            //

            ERESOURCE Resource;

            //
            //  Pointer to SharedCacheMap for this Bcb.
            //

            PSHARED_CACHE_MAP SharedCacheMap;

            //
            //  This is the Base Address at which the buffer can be seen in
            //  system space.  All access to buffer data should go through this
            //  address.
            //

            PVOID BaseAddress;
        };
    };

} BCB;

#ifndef KDEXT
typedef BCB *PBCB;
#endif

//
//  This is the Overlap Buffer Control Block structure for representing data which
//  is "pinned" in memory and must be represented by multiple Bcbs due to overlaps.
//
//  NOTE: The first four fields must be the same as the PUBLIC_BCB.
//

typedef struct _OBCB {

    //
    //  Type and size of this record
    //

    CSHORT NodeTypeCode;
    CSHORT NodeByteSize;

    //
    //  Byte FileOffset and and length of entire buffer
    //

    ULONG  ByteLength;
    LARGE_INTEGER FileOffset;

    //
    //  Vector of Bcb pointers.
    //

    PBCB Bcbs[ANYSIZE_ARRAY];

} OBCB;

typedef OBCB *POBCB;


//
//  Struct for remembering deferred writes for later posting.
//

typedef struct _DEFERRED_WRITE {

    //
    //  Type and size of this record
    //

    CSHORT NodeTypeCode;
    CSHORT NodeByteSize;

    //
    //  The file to be written.
    //

    PFILE_OBJECT FileObject;

    //
    //  Number of bytes the caller intends to write
    //

    ULONG BytesToWrite;

    //
    //  Links for the deferred write queue.
    //

    LIST_ENTRY DeferredWriteLinks;

    //
    //  If this event pointer is not NULL, then this event will
    //  be signalled when the write is ok, rather than calling
    //  the PostRoutine below.
    //

    PKEVENT Event;

    //
    //  The posting routine and its parameters
    //

    PCC_POST_DEFERRED_WRITE PostRoutine;
    PVOID Context1;
    PVOID Context2;

    BOOLEAN LimitModifiedPages;

} DEFERRED_WRITE, *PDEFERRED_WRITE;


//
//  Struct controlling the Lazy Writer algorithms
//

typedef struct _LAZY_WRITER {

    //
    //  Work queue.
    //

    LIST_ENTRY WorkQueue;

    //
    //  Dpc and Timer Structures used for activating periodic scan when active.
    //

    KDPC ScanDpc;
    KTIMER ScanTimer;

    //
    //  Boolean to say whether Lazy Writer scan is active or not.
    //

    BOOLEAN ScanActive;

    //
    //  Boolean indicating if there is any other reason for Lazy Writer to
    //  wake up.
    //

    BOOLEAN OtherWork;

} LAZY_WRITER;


#ifndef KDEXT
//
//  Work queue entry for the worker threads, with an enumerated
//  function code.
//

typedef enum _WORKER_FUNCTION {
    Noop = 0,
    ReadAhead,
    WriteBehind,
    LazyWriteScan,
    EventSet
} WORKER_FUNCTION;
#endif

typedef struct _WORK_QUEUE_ENTRY {

    //
    //  List entry for our work queues.
    //

    LIST_ENTRY WorkQueueLinks;

    //
    //  Define a union to contain function-specific parameters.
    //

    union {

        //
        //  Read parameters (for read ahead)
        //

        struct {
            PFILE_OBJECT FileObject;
        } Read;

        //
        //  Write parameters (for write behind)
        //

        struct {
            PSHARED_CACHE_MAP SharedCacheMap;
        } Write;

        //
        //  Set event parameters (for queue checks)
        //

        struct {
            PKEVENT Event;
        } Event;

    } Parameters;

    //
    //  Function code for this entry:
    //

    UCHAR Function;

} WORK_QUEUE_ENTRY, *PWORK_QUEUE_ENTRY;

//
//  This is a structure apended to the end of an MDL
//

typedef struct _MDL_WRITE {

    //
    //  This field is for the use of the Server to stash anything interesting
    //

    PVOID ServerContext;

    //
    //  This is the resource to release when the write is complete.
    //

    PERESOURCE Resource;

    //
    //  This is thread caller's thread, and the thread that must release
    //  the resource.
    //

    ERESOURCE_THREAD Thread;

    //
    //  This links all the pending MDLs through the shared cache map.
    //

    LIST_ENTRY MdlLinks;

} MDL_WRITE, *PMDL_WRITE;


//
//  Common Private routine definitions for the Cache Manager
//

VOID
CcGetActiveVacb (
    IN PSHARED_CACHE_MAP SharedCacheMap,
    OUT PVACB *Vacb,
    OUT PULONG Page,
    OUT PULONG Dirty
    );

VOID
CcSetActiveVacb (
    IN PSHARED_CACHE_MAP SharedCacheMap,
    IN OUT PVACB *Vacb,
    IN ULONG Page,
    IN ULONG Dirty
    );

//
//  We trim out the previous macro-forms of Get/Set (nondpc) so that we can page
//  more cache manager code that otherwise does not acquire spinlocks.
//

#define GetActiveVacb(SCM,IRQ,V,P,D)     CcGetActiveVacb((SCM),&(V),&(P),&(D))
#define SetActiveVacb(SCM,IRQ,V,P,D)     CcSetActiveVacb((SCM),&(V),(P),(D))

#define GetActiveVacbAtDpcLevel(SCM,V,P,D) {                            \
    ExAcquireSpinLockAtDpcLevel(&(SCM)->ActiveVacbSpinLock);            \
    (V) = (SCM)->ActiveVacb;                                            \
    if ((V) != NULL) {                                                  \
        (P) = (SCM)->ActivePage;                                        \
        (SCM)->ActiveVacb = NULL;                                       \
        (D) = (SCM)->Flags & ACTIVE_PAGE_IS_DIRTY;                      \
    }                                                                   \
    ExReleaseSpinLockFromDpcLevel(&(SCM)->ActiveVacbSpinLock);          \
}

//
//  Gather the common work of charging and deducting dirty page counts.  When
//  write hysteresis was being considered during Windows XP, this also helped
//  gather up the activation of that throttle.
//

#define CcDeductDirtyPages( S, P )                                      \
        CcTotalDirtyPages -= (P);                                       \
        (S)->DirtyPages -= (P);
        
#define CcChargeMaskDirtyPages( S, M, B, P )                            \
        CcTotalDirtyPages += (P);                                       \
        (M)->DirtyPages += (P);                                         \
        (B)->DirtyPages += (P);                                         \
        (S)->DirtyPages += (P);

#define CcChargePinDirtyPages( S, P )                                   \
        CcTotalDirtyPages += (P);                                       \
        (S)->DirtyPages += (P);

VOID
CcPostDeferredWrites (
    );

BOOLEAN
CcPinFileData (
    IN PFILE_OBJECT FileObject,
    IN PLARGE_INTEGER FileOffset,
    IN ULONG Length,
    IN BOOLEAN ReadOnly,
    IN BOOLEAN WriteOnly,
    IN ULONG Flags,
    OUT PBCB *Bcb,
    OUT PVOID *BaseAddress,
    OUT PLARGE_INTEGER BeyondLastByte
    );

typedef enum {
    UNPIN,
    UNREF,
    SET_CLEAN
} UNMAP_ACTIONS;

VOID
FASTCALL
CcUnpinFileData (
    IN OUT PBCB Bcb,
    IN BOOLEAN ReadOnly,
    IN UNMAP_ACTIONS UnmapAction
    );

VOID
FASTCALL
CcDeallocateBcb (
    IN PBCB Bcb
    );

VOID
FASTCALL
CcPerformReadAhead (
    IN PFILE_OBJECT FileObject
    );

VOID
CcSetDirtyInMask (
    IN PSHARED_CACHE_MAP SharedCacheMap,
    IN PLARGE_INTEGER FileOffset,
    IN ULONG Length
    );

VOID
FASTCALL
CcWriteBehind (
    IN PSHARED_CACHE_MAP SharedCacheMap,
    IN PIO_STATUS_BLOCK IoStatus
    );

#define ZERO_FIRST_PAGE                  1
#define ZERO_MIDDLE_PAGES                2
#define ZERO_LAST_PAGE                   4

BOOLEAN
CcMapAndRead(
    IN PSHARED_CACHE_MAP SharedCacheMap,
    IN PLARGE_INTEGER FileOffset,
    IN ULONG Length,
    IN ULONG ZeroFlags,
    IN BOOLEAN Wait,
    IN PVOID BaseAddress
    );

VOID
CcFreeActiveVacb (
    IN PSHARED_CACHE_MAP SharedCacheMap,
    IN PVACB ActiveVacb OPTIONAL,
    IN ULONG ActivePage,
    IN ULONG PageIsDirty
    );

VOID
CcMapAndCopy(
    IN PSHARED_CACHE_MAP SharedCacheMap,
    IN PVOID UserBuffer,
    IN PLARGE_INTEGER FileOffset,
    IN ULONG Length,
    IN ULONG ZeroFlags,
    IN PFILE_OBJECT FileObject
    );

VOID
CcScanDpc (
    IN PKDPC Dpc,
    IN PVOID DeferredContext,
    IN PVOID SystemArgument1,
    IN PVOID SystemArgument2
    );

VOID
CcScheduleLazyWriteScan (
    IN BOOLEAN FastScan
    );

VOID
CcStartLazyWriter (
    IN PVOID NotUsed
    );

#define CcAllocateWorkQueueEntry() \
    (PWORK_QUEUE_ENTRY)ExAllocateFromPPLookasideList(LookasideTwilightList)

#define CcFreeWorkQueueEntry(_entry_)         \
    ExFreeToPPLookasideList(LookasideTwilightList, (_entry_))

VOID
FASTCALL
CcPostWorkQueue (
    IN PWORK_QUEUE_ENTRY WorkQueueEntry,
    IN PLIST_ENTRY WorkQueue
    );

VOID
CcWorkerThread (
    PVOID ExWorkQueueItem
    );

VOID
FASTCALL
CcDeleteSharedCacheMap (
    IN PSHARED_CACHE_MAP SharedCacheMap,
    IN KIRQL ListIrql,
    IN ULONG ReleaseFile
    );

//
//  This exception filter handles STATUS_IN_PAGE_ERROR correctly
//

LONG
CcCopyReadExceptionFilter(
    IN PEXCEPTION_POINTERS ExceptionPointer,
    IN PNTSTATUS ExceptionCode
    );

//
//  Exception filter for Worker Threads in lazyrite.c
//

LONG
CcExceptionFilter (
    IN NTSTATUS ExceptionCode
    );

#ifdef CCDBG
VOID
CcDump (
    IN PVOID Ptr
    );
#endif

//
//  Vacb routines
//

VOID
CcInitializeVacbs(
    );

PVOID
CcGetVirtualAddressIfMapped (
    IN PSHARED_CACHE_MAP SharedCacheMap,
    IN LONGLONG FileOffset,
    OUT PVACB *Vacb,
    OUT PULONG ReceivedLength
    );

PVOID
CcGetVirtualAddress (
    IN PSHARED_CACHE_MAP SharedCacheMap,
    IN LARGE_INTEGER FileOffset,
    OUT PVACB *Vacb,
    OUT PULONG ReceivedLength
    );

VOID
FASTCALL
CcFreeVirtualAddress (
    IN PVACB Vacb
    );

VOID
CcReferenceFileOffset (
    IN PSHARED_CACHE_MAP SharedCacheMap,
    IN LARGE_INTEGER FileOffset
    );

VOID
CcDereferenceFileOffset (
    IN PSHARED_CACHE_MAP SharedCacheMap,
    IN LARGE_INTEGER FileOffset
    );

VOID
CcWaitOnActiveCount (
    IN PSHARED_CACHE_MAP SharedCacheMap
    );

NTSTATUS
FASTCALL
CcCreateVacbArray (
    IN PSHARED_CACHE_MAP SharedCacheMap,
    IN LARGE_INTEGER NewSectionSize
    );

NTSTATUS
CcExtendVacbArray (
    IN PSHARED_CACHE_MAP SharedCacheMap,
    IN LARGE_INTEGER NewSectionSize
    );

BOOLEAN
FASTCALL
CcUnmapVacbArray (
    IN PSHARED_CACHE_MAP SharedCacheMap,
    IN PLARGE_INTEGER FileOffset OPTIONAL,
    IN ULONG Length,
    IN BOOLEAN UnmapBehind
    );

VOID
CcAdjustVacbLevelLockCount (
    IN PSHARED_CACHE_MAP SharedCacheMap,
    IN LONGLONG FileOffset,
    IN LONG Adjustment
    );

PLIST_ENTRY
CcGetBcbListHeadLargeOffset (
    IN PSHARED_CACHE_MAP SharedCacheMap,
    IN LONGLONG FileOffset,
    IN BOOLEAN FailToSuccessor
    );

ULONG
CcPrefillVacbLevelZone (
    IN ULONG NumberNeeded,
    OUT PKIRQL OldIrql,
    IN ULONG NeedBcbListHeads
    );

VOID
CcDrainVacbLevelZone (
    );

//
//  Define references to global data
//

extern KSPIN_LOCK CcBcbSpinLock;
extern LIST_ENTRY CcCleanSharedCacheMapList;
extern SHARED_CACHE_MAP_LIST_CURSOR CcDirtySharedCacheMapList;
extern SHARED_CACHE_MAP_LIST_CURSOR CcLazyWriterCursor;
extern GENERAL_LOOKASIDE CcTwilightLookasideList;
extern ULONG CcNumberWorkerThreads;
extern ULONG CcNumberActiveWorkerThreads;
extern LIST_ENTRY CcIdleWorkerThreadList;
extern LIST_ENTRY CcExpressWorkQueue;
extern LIST_ENTRY CcRegularWorkQueue;
extern LIST_ENTRY CcPostTickWorkQueue;
extern BOOLEAN CcQueueThrottle;
extern ULONG CcIdleDelayTick;
extern LARGE_INTEGER CcNoDelay;
extern LARGE_INTEGER CcFirstDelay;
extern LARGE_INTEGER CcIdleDelay;
extern LARGE_INTEGER CcCollisionDelay;
extern LARGE_INTEGER CcTargetCleanDelay;
extern LAZY_WRITER LazyWriter;
extern ULONG_PTR CcNumberVacbs;
extern PVACB CcVacbs;
extern PVACB CcBeyondVacbs;
extern LIST_ENTRY CcVacbLru;
extern LIST_ENTRY CcVacbFreeList;
extern KSPIN_LOCK CcDeferredWriteSpinLock;
extern LIST_ENTRY CcDeferredWrites;
extern ULONG CcDirtyPageThreshold;
extern ULONG CcDirtyPageTarget;
extern ULONG CcDirtyPagesLastScan;
extern ULONG CcPagesYetToWrite;
extern ULONG CcPagesWrittenLastTime;
extern ULONG CcThrottleLastTime;
extern ULONG CcDirtyPageHysteresisThreshold;
extern PSHARED_CACHE_MAP CcSingleDirtySourceDominant;
extern ULONG CcAvailablePagesThreshold;
extern ULONG CcTotalDirtyPages;
extern ULONG CcTune;
extern LONG CcAggressiveZeroCount;
extern LONG CcAggressiveZeroThreshold;
extern ULONG CcLazyWriteHotSpots;
extern MM_SYSTEMSIZE CcCapturedSystemSize;
extern ULONG CcMaxVacbLevelsSeen;
extern ULONG CcVacbLevelEntries;
extern PVACB *CcVacbLevelFreeList;
extern ULONG CcVacbLevelWithBcbsEntries;
extern PVACB *CcVacbLevelWithBcbsFreeList;

//
//  Macros for allocating and deallocating Vacb levels - CcVacbSpinLock must
//  be acquired.
//

_inline PVACB *CcAllocateVacbLevel (
    IN LOGICAL AllocatingBcbListHeads
    )

{
    PVACB *ReturnEntry;

    if (AllocatingBcbListHeads) {
        ReturnEntry = CcVacbLevelWithBcbsFreeList;
        CcVacbLevelWithBcbsFreeList = (PVACB *)*ReturnEntry;
        CcVacbLevelWithBcbsEntries -= 1;
    } else {
        ReturnEntry = CcVacbLevelFreeList;
        CcVacbLevelFreeList = (PVACB *)*ReturnEntry;
        CcVacbLevelEntries -= 1;
    }
    *ReturnEntry = NULL;
    ASSERT(RtlCompareMemory(ReturnEntry, ReturnEntry + 1, VACB_LEVEL_BLOCK_SIZE - sizeof(PVACB)) ==
                                                          (VACB_LEVEL_BLOCK_SIZE - sizeof(PVACB)));
    return ReturnEntry;
}

_inline VOID CcDeallocateVacbLevel (
    IN PVACB *Entry,
    IN LOGICAL DeallocatingBcbListHeads
    )

{
    if (DeallocatingBcbListHeads) {
        *Entry = (PVACB)CcVacbLevelWithBcbsFreeList;
        CcVacbLevelWithBcbsFreeList = Entry;
        CcVacbLevelWithBcbsEntries += 1;
    } else {
        *Entry = (PVACB)CcVacbLevelFreeList;
        CcVacbLevelFreeList = Entry;
        CcVacbLevelEntries += 1;
    }
}

//
//  Export the macros for inspecting the reference counts for
//  the multilevel Vacb array.
//

_inline
PVACB_LEVEL_REFERENCE
VacbLevelReference (
    IN PSHARED_CACHE_MAP SharedCacheMap,
    IN PVACB *VacbArray,
    IN ULONG Level
    )
{
    return (PVACB_LEVEL_REFERENCE)
           ((PCHAR)VacbArray +
            VACB_LEVEL_BLOCK_SIZE +
            (Level != 0?
             0 : (FlagOn( SharedCacheMap->Flags, MODIFIED_WRITE_DISABLED )?
                  VACB_LEVEL_BLOCK_SIZE : 0)));
}

_inline
ULONG
IsVacbLevelReferenced (
    IN PSHARED_CACHE_MAP SharedCacheMap,
    IN PVACB *VacbArray,
    IN ULONG Level
    )
{
    PVACB_LEVEL_REFERENCE VacbReference = VacbLevelReference( SharedCacheMap, VacbArray, Level );

    return VacbReference->Reference | VacbReference->SpecialReference;
}


//
//  Here is a page of macros stolen directly from Pinball...
//

//
//  The following macros are used to establish the semantics needed
//  to do a return from within a try-finally clause.  As a rule every
//  try clause must end with a label call try_exit.  For example,
//
//      try {
//              :
//              :
//
//      try_exit: NOTHING;
//      } finally {
//
//              :
//              :
//      }
//
//  Every return statement executed inside of a try clause should use the
//  try_return macro.  If the compiler fully supports the try-finally construct
//  then the macro should be
//
//      #define try_return(S)  { return(S); }
//
//  If the compiler does not support the try-finally construct then the macro
//  should be
//
//      #define try_return(S)  { S; goto try_exit; }
//

#define try_return(S) { S; goto try_exit; }

#ifdef CCDBG

extern LONG CcDebugTraceLevel;
extern LONG CcDebugTraceIndent;

#ifndef CCDBG_LOCK

#define DebugTrace(INDENT,LEVEL,X,Y) {                     \
    LONG _i;                                               \
    if (((LEVEL) == 0) || (CcDebugTraceLevel & (LEVEL))) { \
        _i = (ULONG)PsGetCurrentThread();                  \
        DbgPrint("%08lx:",_i);                             \
        if ((INDENT) < 0) {                                \
            CcDebugTraceIndent += (INDENT);                \
        }                                                  \
        if (CcDebugTraceIndent < 0) {                      \
            CcDebugTraceIndent = 0;                        \
        }                                                  \
        for (_i=0; _i<CcDebugTraceIndent; _i+=1) {         \
            DbgPrint(" ");                                 \
        }                                                  \
        DbgPrint(X,Y);                                     \
        if ((INDENT) > 0) {                                \
            CcDebugTraceIndent += (INDENT);                \
        }                                                  \
    }                                                      \
}

#define DebugTrace2(INDENT,LEVEL,X,Y,Z) {                  \
    LONG _i;                                               \
    if (((LEVEL) == 0) || (CcDebugTraceLevel & (LEVEL))) { \
        _i = (ULONG)PsGetCurrentThread();                  \
        DbgPrint("%08lx:",_i);                             \
        if ((INDENT) < 0) {                                \
            CcDebugTraceIndent += (INDENT);                \
        }                                                  \
        if (CcDebugTraceIndent < 0) {                      \
            CcDebugTraceIndent = 0;                        \
        }                                                  \
        for (_i=0; _i<CcDebugTraceIndent; _i+=1) {         \
            DbgPrint(" ");                                 \
        }                                                  \
        DbgPrint(X,Y,Z);                                   \
        if ((INDENT) > 0) {                                \
            CcDebugTraceIndent += (INDENT);                \
        }                                                  \
    }                                                      \
}

#define DebugDump(STR,LEVEL,PTR) {                         \
    LONG _i;                                               \
    VOID CcDump();                                         \
    if (((LEVEL) == 0) || (CcDebugTraceLevel & (LEVEL))) { \
        _i = (ULONG)PsGetCurrentThread();                  \
        DbgPrint("%08lx:",_i);                             \
        DbgPrint(STR);                                     \
        if (PTR != NULL) {CcDump(PTR);}                    \
        DbgBreakPoint();                                   \
    }                                                      \
}

#else //  ndef CCDBG_LOCK

extern KSPIN_LOCK CcDebugTraceLock;

#define DebugTrace(INDENT,LEVEL,X,Y) {                     \
    LONG _i;                                               \
    KIRQL _oldIrql;                                        \
    if (((LEVEL) == 0) || (CcDebugTraceLevel & (LEVEL))) { \
        _i = (ULONG)PsGetCurrentThread();                  \
        ExAcquireSpinLock( &CcDebugTraceLock, &_oldIrql ); \
        DbgPrint("%08lx:",_i);                             \
        if ((INDENT) < 0) {                                \
            CcDebugTraceIndent += (INDENT);                \
        }                                                  \
        if (CcDebugTraceIndent < 0) {                      \
            CcDebugTraceIndent = 0;                        \
        }                                                  \
        for (_i=0; _i<CcDebugTraceIndent; _i+=1) {         \
            DbgPrint(" ");                                 \
        }                                                  \
        DbgPrint(X,Y);                                     \
        if ((INDENT) > 0) {                                \
            CcDebugTraceIndent += (INDENT);                \
        }                                                  \
        ExReleaseSpinLock( &CcDebugTraceLock, _oldIrql );  \
    }                                                      \
}

#define DebugTrace2(INDENT,LEVEL,X,Y,Z) {                  \
    LONG _i;                                               \
    KIRQL _oldIrql;                                        \
    if (((LEVEL) == 0) || (CcDebugTraceLevel & (LEVEL))) { \
        _i = (ULONG)PsGetCurrentThread();                  \
        ExAcquireSpinLock( &CcDebugTraceLock, &_oldIrql ); \
        DbgPrint("%08lx:",_i);                             \
        if ((INDENT) < 0) {                                \
            CcDebugTraceIndent += (INDENT);                \
        }                                                  \
        if (CcDebugTraceIndent < 0) {                      \
            CcDebugTraceIndent = 0;                        \
        }                                                  \
        for (_i=0; _i<CcDebugTraceIndent; _i+=1) {         \
            DbgPrint(" ");                                 \
        }                                                  \
        DbgPrint(X,Y,Z);                                   \
        if ((INDENT) > 0) {                                \
            CcDebugTraceIndent += (INDENT);                \
        }                                                  \
      ExReleaseSpinLock( &CcDebugTraceLock, _oldIrql );  \
    }                                                      \
}

#define DebugDump(STR,LEVEL,PTR) {                         \
    LONG _i;                                               \
    KIRQL _oldIrql;                                        \
    VOID CcDump();                                         \
    if (((LEVEL) == 0) || (CcDebugTraceLevel & (LEVEL))) { \
        _i = (ULONG)PsGetCurrentThread();                  \
      ExAcquireSpinLock( &CcDebugTraceLock, &_oldIrql ); \
        DbgPrint("%08lx:",_i);                             \
        DbgPrint(STR);                                     \
        if (PTR != NULL) {CcDump(PTR);}                    \
        DbgBreakPoint();                                   \
      ExReleaseSpinLock( &CcDebugTraceLock, _oldIrql );  \
    }                                                      \
}

#endif //  else ndef CCDBG_LOCK

#else

#undef CCDBG_LOCK

#define DebugTrace(INDENT,LEVEL,X,Y) {NOTHING;}

#define DebugTrace2(INDENT,LEVEL,X,Y,Z) {NOTHING;}

#define DebugDump(STR,LEVEL,PTR) {NOTHING;}

#endif //  CCDBG

//
//  Global list of pinned Bcbs which may be examined for debug purposes
//

#if DBG

extern ULONG CcBcbCount;
extern LIST_ENTRY CcBcbList;

#endif

#endif  //  _CCh_
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\base\ntos\cache\cachesub.c ===
/*++

Copyright (c) 1990  Microsoft Corporation

Module Name:

    cachesub.c

Abstract:

    This module implements the common subroutines for the Cache subsystem.

Author:

    Tom Miller      [TomM]      4-May-1990

Revision History:

--*/

#include "cc.h"

//
//  The Bug check file id for this module
//

#define BugCheckFileId                   (CACHE_BUG_CHECK_CACHESUB)

//
//  Define our debug constant
//

#define me 0x00000002

//
//  Define those errors which should be retried
//

#define RetryError(STS) (((STS) == STATUS_VERIFY_REQUIRED) || ((STS) == STATUS_FILE_LOCK_CONFLICT))

ULONG CcMaxDirtyWrite = 0x10000;

//
//  Local support routines
//

BOOLEAN
CcFindBcb (
    IN PSHARED_CACHE_MAP SharedCacheMap,
    IN PLARGE_INTEGER FileOffset,
    IN OUT PLARGE_INTEGER BeyondLastByte,
    OUT PBCB *Bcb
    );

PBCB
CcAllocateInitializeBcb (
    IN OUT PSHARED_CACHE_MAP SharedCacheMap OPTIONAL,
    IN OUT PBCB AfterBcb,
    IN PLARGE_INTEGER FileOffset,
    IN PLARGE_INTEGER Length
    );

NTSTATUS
CcSetValidData (
    IN PFILE_OBJECT FileObject,
    IN PLARGE_INTEGER ValidDataLength
    );

BOOLEAN
CcAcquireByteRangeForWrite (
    IN PSHARED_CACHE_MAP SharedCacheMap,
    IN PLARGE_INTEGER TargetOffset OPTIONAL,
    IN ULONG TargetLength,
    OUT PLARGE_INTEGER FileOffset,
    OUT PULONG Length,
    OUT PBCB *FirstBcb
    );

VOID
CcReleaseByteRangeFromWrite (
    IN PSHARED_CACHE_MAP SharedCacheMap,
    IN PLARGE_INTEGER FileOffset,
    IN ULONG Length,
    IN PBCB FirstBcb,
    IN BOOLEAN VerifyRequired
    );

PBITMAP_RANGE
CcFindBitmapRangeToDirty (
    IN PMBCB Mbcb,
    IN LONGLONG Page,
    IN PULONG *FreePageForSetting
    );

PBITMAP_RANGE
CcFindBitmapRangeToClean (
    IN PMBCB Mbcb,
    IN LONGLONG Page
    );

BOOLEAN
CcLogError(
    IN PFILE_OBJECT FileObject,
    IN PUNICODE_STRING FileName,
    IN NTSTATUS Error,
    IN NTSTATUS DeviceError,
    IN UCHAR IrpMajorCode
    );



//
//  Internal support routine
//

BOOLEAN
CcPinFileData (
    IN PFILE_OBJECT FileObject,
    IN PLARGE_INTEGER FileOffset,
    IN ULONG Length,
    IN BOOLEAN ReadOnly,
    IN BOOLEAN WriteOnly,
    IN ULONG Flags,
    OUT PBCB *Bcb,
    OUT PVOID *BaseAddress,
    OUT PLARGE_INTEGER BeyondLastByte
    )

/*++

Routine Description:

    This routine locks the specified range of file data into memory.

    Note that the data desired by the caller (or the first part of it)
    may be in one of three states:

        No Bcb exists which describes the data

        A Bcb exists describing the data, but it is not mapped
        (BcbOut->BaseAddress == NULL)

        A Bcb exists describing the data, and it is mapped

    Given the above three states, and given that the caller may call
    with either Wait == FALSE or Wait == TRUE, this routine has basically
    six cases.  What has to be done, and the order in which things must be
    done varies quite a bit with each of these six cases.  The most
    straight-forward implementation of this routine, with the least amount
    of branching, is achieved by determining which of the six cases applies,
    and dispatching fairly directly to that case.  The handling of the
    cases is summarized in the following table:

                Wait == TRUE                Wait == FALSE
                ------------                -------------

    no Bcb      Case 1:                     Case 2:

                CcAllocateInitializeBcb     CcMapAndRead (exit if FALSE)
                Acquire Bcb Exclusive       CcAllocateInitializeBcb
                Release BcbList SpinLock    Acquire Bcb Shared if not ReadOnly
                CcMapAndRead w/ Wait        Release BcbList SpinLock
                Convert/Release Bcb Resource

    Bcb not     Case 3:                     Case 4:
    mapped
                Increment PinCount          Acquire Bcb Exclusive (exit if FALSE)
                Release BcbList SpinLock    CcMapAndRead (exit if FALSE)
                Acquire Bcb Excl. w/ Wait   Increment PinCount
                if still not mapped         Convert/Release Bcb Resource
                    CcMapAndRead w/ Wait    Release BcbList SpinLock
                Convert/Release Bcb Resource

    Bcb mapped  Case 5:                     Case 6:

                Increment PinCount          if not ReadOnly
                Release BcbList SpinLock        Acquire Bcb shared (exit if FALSE)
                if not ReadOnly             Increment PinCount
                    Acquire Bcb Shared      Release BcbList SpinLock

    It is important to note that most changes to this routine will affect
    multiple cases from above.

Arguments:

    FileObject - Pointer to File Object for file

    FileOffset - Offset in file at which map should begin

    Length - Length of desired map in bytes

    ReadOnly - Supplies TRUE if caller will only read the mapped data (i.e.,
               TRUE for CcCopyRead, CcMapData and CcMdlRead and FALSE for
               everyone else)

    WriteOnly - The specified range of bytes will only be written.

    Flags - (PIN_WAIT, PIN_EXCLUSIVE, PIN_NO_READ, etc. as defined in cache.h)

    Bcb - Returns a pointer to the Bcb representing the pinned data.

    BaseAddress - Returns base address of desired data

    BeyondLastByte - Returns the File Offset of the first byte beyond the
                     last accessible byte.

Return Value:

    FALSE - if PIN_WAIT was set, and it was impossible to lock all
            of the data without blocking
    TRUE - if the desired data, is being returned

Raises:

    STATUS_INSUFFICIENT_RESOURCES - If a pool allocation failure occurs.
        This can only occur if Wait was specified as TRUE.  (If Wait is
        specified as FALSE, and an allocation failure occurs, this
        routine simply returns FALSE.)

--*/

{
    PSHARED_CACHE_MAP SharedCacheMap;
    LARGE_INTEGER TrialBound;
    KLOCK_QUEUE_HANDLE LockHandle;
    PBCB BcbOut = NULL;
    ULONG ZeroFlags = 0;
    LOGICAL SpinLockAcquired = FALSE;
    BOOLEAN Result = FALSE;

    ULONG ReceivedLength;
    ULONG ActivePage;
    ULONG PageIsDirty;
    PVACB Vacb = NULL;

    DebugTrace(+1, me, "CcPinFileData:\n", 0 );
    DebugTrace( 0, me, "    FileObject = %08lx\n", FileObject );
    DebugTrace2(0, me, "    FileOffset = %08lx, %08lx\n", FileOffset->LowPart,
                                                          FileOffset->HighPart );
    DebugTrace( 0, me, "    Length = %08lx\n", Length );
    DebugTrace( 0, me, "    Flags = %02lx\n", Flags );

    //
    //  Get pointer to SharedCacheMap via File Object.
    //

    SharedCacheMap = *(PSHARED_CACHE_MAP *)((PCHAR)FileObject->SectionObjectPointer
                                            + sizeof(PVOID));

    //
    //  See if we have an active Vacb, that we need to free.
    //

    GetActiveVacb( SharedCacheMap, OldIrql, Vacb, ActivePage, PageIsDirty );

    //
    //  If there is an end of a page to be zeroed, then free that page now,
    //  so it does not cause our data to get zeroed.  If there is an active
    //  page, free it so we have the correct ValidDataGoal.
    //

    if ((Vacb != NULL) || (SharedCacheMap->NeedToZero != NULL)) {

        CcFreeActiveVacb( SharedCacheMap, Vacb, ActivePage, PageIsDirty );
        Vacb = NULL;
    }

    //
    //  Make sure the calling file system is not asking to map beyond the
    //  end of the section, for example, that it did not forget to do
    //  CcExtendCacheSection.
    //

    ASSERT( ( FileOffset->QuadPart + (LONGLONG)Length ) <=
                     SharedCacheMap->SectionSize.QuadPart );

    //
    //  Initially clear output
    //

    *Bcb = NULL;
    *BaseAddress = NULL;

    if (!FlagOn(Flags, PIN_NO_READ)) {

        *BaseAddress = CcGetVirtualAddress( SharedCacheMap,
                                            *FileOffset,
                                            &Vacb,
                                            &ReceivedLength );

    } else {

        //
        //  In the PIN_NO_READ case, we simply need to make sure that the
        //  sparse structure containing the Bcb listheads is expanded in the
        //  region of the file we are interested in.
        //
        //  Fake a ReceivedLength that matches the remaining bytes in the view.
        //

        ReceivedLength = VACB_MAPPING_GRANULARITY -
                         (ULONG)(FileOffset->QuadPart & (VACB_MAPPING_GRANULARITY - 1));

        //
        //  Now simply cause a reference that will expand a multilevel Vacb.
        //

        CcReferenceFileOffset( SharedCacheMap, *FileOffset );
    }

    //
    //  Acquire Bcb List Exclusive to look for Bcb
    //

    KeAcquireInStackQueuedSpinLock( &SharedCacheMap->BcbSpinLock, &LockHandle );
    SpinLockAcquired = TRUE;

    //
    //  Use try to guarantee cleanup on the way out.
    //

    try {

        LOGICAL Found;
        LARGE_INTEGER FOffset;
        LARGE_INTEGER TLength;

        //
        //  Search for Bcb describing the largest matching "prefix" byte range,
        //  or where to insert it.
        //

        TrialBound.QuadPart = FileOffset->QuadPart + (LONGLONG)Length;
        Found = CcFindBcb( SharedCacheMap, FileOffset, &TrialBound, &BcbOut );


        //
        //  Cases 1 and 2 - Bcb was not found.
        //
        //  First caculate data to pin down.
        //

        if (!Found) {

            //
            //  Get out if the user specified PIN_IF_BCB.
            //

            if (FlagOn(Flags, PIN_IF_BCB)) {

                //
                //  We need to zap BcbOut since this is a hint to the cleanup code
                //  to remove the Bcb if we are returning FALSE.
                //

                BcbOut = NULL;
                try_return( Result = FALSE );
            }

            //
            //  Not found, calculate data to pin down.
            //
            //  Round local copy of FileOffset down to page boundary, and
            //  round copies of size and minimum size up.  Also make sure that
            //  we keep the length from crossing the end of the SharedCacheMap.
            //

            FOffset = *FileOffset;
            TLength.QuadPart = TrialBound.QuadPart - FOffset.QuadPart;

            TLength.LowPart += FOffset.LowPart & (PAGE_SIZE - 1);
            ReceivedLength += FOffset.LowPart & (PAGE_SIZE - 1);

            //
            //  At this point we can calculate the ReadOnly flag for
            //  the purposes of whether to use the Bcb resource, and
            //  we can calculate the ZeroFlags.
            //

            if ((!ReadOnly  && !FlagOn(SharedCacheMap->Flags, PIN_ACCESS)) || WriteOnly) {

                //
                //  We can always zero middle pages, if any.
                //

                ZeroFlags = ZERO_MIDDLE_PAGES;

                if (((FOffset.LowPart & (PAGE_SIZE - 1)) == 0) &&
                    (Length >= PAGE_SIZE)) {
                    ZeroFlags |= ZERO_FIRST_PAGE;
                }

                if ((TLength.LowPart & (PAGE_SIZE - 1)) == 0) {
                    ZeroFlags |= ZERO_LAST_PAGE;
                }
            }

            //
            //  We treat Bcbs as ReadOnly (do not acquire resource) if they
            //  are in sections for which we have not disabled modified writing.
            //

            if (!FlagOn(SharedCacheMap->Flags, MODIFIED_WRITE_DISABLED)) {
                ReadOnly = TRUE;
            }

            TLength.LowPart = (ULONG) ROUND_TO_PAGES( TLength.LowPart );

            //
            //  Round BaseAddress and FOffset down to the bottom of a page.
            //

            *BaseAddress = ((PCHAR)*BaseAddress - (FileOffset->LowPart & (PAGE_SIZE - 1)));
            FOffset.LowPart &= ~(PAGE_SIZE - 1);

            //
            //  Even if we are readonly, we can still zero pages entirely
            //  beyond valid data length.
            //

            if (FOffset.QuadPart >= SharedCacheMap->ValidDataGoal.QuadPart) {

                ZeroFlags |= ZERO_FIRST_PAGE | ZERO_MIDDLE_PAGES | ZERO_LAST_PAGE;

            } else if ((FOffset.QuadPart + (LONGLONG)PAGE_SIZE) >=
                                SharedCacheMap->ValidDataGoal.QuadPart) {

                ZeroFlags |= ZERO_MIDDLE_PAGES | ZERO_LAST_PAGE;
            }

            //
            //  We will get into trouble if we try to read more than we
            //  can map by one Vacb.  So make sure that our lengths stay
            //  within a Vacb.
            //

            if (TLength.LowPart > ReceivedLength) {
                TLength.LowPart = ReceivedLength;
            }


            //
            //  Case 1 - Bcb was not found and Wait is TRUE.
            //
            //  Note that it is important to minimize the time that the Bcb
            //  List spin lock is held, as well as guarantee we do not take
            //  any faults while holding this lock.
            //
            //  If we can (and perhaps will) wait, then it is important to
            //  allocate the Bcb acquire it exclusive and free the Bcb List.
            //  We then procede to read in the data, and anyone else finding
            //  our Bcb will have to wait shared to insure that the data is
            //  in.
            //

            if (FlagOn(Flags, PIN_WAIT)) {

                BcbOut = CcAllocateInitializeBcb( SharedCacheMap,
                                                  BcbOut,
                                                  &FOffset,
                                                  &TLength );

                if (BcbOut == NULL) {
                    DebugTrace( 0, 0, "Bcb allocation failure\n", 0 );
                    KeReleaseInStackQueuedSpinLock( &LockHandle );
                    SpinLockAcquired = FALSE;
                    ExRaiseStatus( STATUS_INSUFFICIENT_RESOURCES );
                }

                //
                //  Now just acquire the newly-allocated Bcb shared, and
                //  release the spin lock.
                //

                if (!ReadOnly) {
                    if (FlagOn(Flags, PIN_EXCLUSIVE)) {
                        (VOID)ExAcquireResourceExclusiveLite( &BcbOut->Resource, TRUE );
                    } else {
                        (VOID)ExAcquireSharedStarveExclusive( &BcbOut->Resource, TRUE );
                    }
                }
                KeReleaseInStackQueuedSpinLock( &LockHandle );
                SpinLockAcquired = FALSE;

                //
                //  Now read in the data.
                //

                if (!FlagOn(Flags, PIN_NO_READ)) {

                    (VOID)CcMapAndRead( SharedCacheMap,
                                        &FOffset,
                                        TLength.LowPart,
                                        ZeroFlags,
                                        TRUE,
                                        *BaseAddress );

                    //
                    //  Now we have to reacquire the Bcb List spinlock to load
                    //  up the mapping if we are the first one, else we collided
                    //  with someone else who loaded the mapping first, and we
                    //  will just free our mapping.  It is guaranteed that the
                    //  data will be mapped to the same place.
                    //

                    KeAcquireInStackQueuedSpinLock( &SharedCacheMap->BcbSpinLock, &LockHandle );

                    if (BcbOut->BaseAddress == NULL) {

                        BcbOut->BaseAddress = *BaseAddress;
                        BcbOut->Vacb = Vacb;
                        Vacb = NULL;
                    }

                    KeReleaseInStackQueuedSpinLock( &LockHandle );

                    //
                    //  Calculate Base Address of the data we want.
                    //

                    *BaseAddress = (PCHAR)BcbOut->BaseAddress +
                                   (ULONG)( FileOffset->QuadPart - BcbOut->FileOffset.QuadPart );
                }

                //
                //  Success!
                //

                try_return( Result = TRUE );
            }


            //
            //  Case 2 - Bcb was not found and Wait is FALSE
            //
            //  If we cannot wait, then we go immediately see if the data is
            //  there (CcMapAndRead), and then only set up the Bcb and release
            //  the spin lock if the data is there.  Note here we call
            //  CcMapAndRead while holding the spin lock, because we know we
            //  will not fault and not block before returning.
            //

            else {

                //
                //  Now try to allocate and initialize the Bcb.  If we
                //  fail to allocate one, then return FALSE, since we know that
                //  Wait = FALSE.  The caller may get lucky if he calls
                //  us back with Wait = TRUE.
                //

                BcbOut = CcAllocateInitializeBcb( SharedCacheMap,
                                                  BcbOut,
                                                  &FOffset,
                                                  &TLength );

                if (BcbOut == NULL) {

                    try_return( Result = FALSE );
                }

                //
                //  If we are not ReadOnly, we must acquire the newly-allocated
                //  resource shared, and then we can free the spin lock.
                //

                if (!ReadOnly) {
                    ExAcquireSharedStarveExclusive( &BcbOut->Resource, TRUE );
                }
                KeReleaseInStackQueuedSpinLock( &LockHandle );
                SpinLockAcquired = FALSE;

                //
                //  Note that since this call has Wait = FALSE, it cannot
                //  get an exception (see procedure header).
                //

                ASSERT( !FlagOn(Flags, PIN_NO_READ) );
                if (!CcMapAndRead( SharedCacheMap,
                                   &FOffset,
                                   TLength.LowPart,
                                   ZeroFlags,
                                   FALSE,
                                   *BaseAddress )) {

                    try_return( Result = FALSE );
                }

                //
                //  Now we have to reacquire the Bcb List spinlock to load
                //  up the mapping if we are the first one, else we collided
                //  with someone else who loaded the mapping first, and we
                //  will just free our mapping.  It is guaranteed that the
                //  data will be mapped to the same place.
                //

                KeAcquireInStackQueuedSpinLock( &SharedCacheMap->BcbSpinLock, &LockHandle );

                if (BcbOut->BaseAddress == NULL) {

                    BcbOut->BaseAddress = *BaseAddress;
                    BcbOut->Vacb = Vacb;
                    Vacb = NULL;
                }

                KeReleaseInStackQueuedSpinLock( &LockHandle );

                //
                //  Calculate Base Address of the data we want.
                //

                *BaseAddress = (PCHAR)BcbOut->BaseAddress +
                               (ULONG)( FileOffset->QuadPart - BcbOut->FileOffset.QuadPart );

                //
                //  Success!
                //

                try_return( Result = TRUE );
            }

        } else {

            //
            //  We treat Bcbs as ReadOnly (do not acquire resource) if they
            //  are in sections for which we have not disabled modified writing.
            //

            if (!FlagOn(SharedCacheMap->Flags, MODIFIED_WRITE_DISABLED)) {
                ReadOnly = TRUE;
            }
        }


        //
        //  Cases 3 and 4 - Bcb is there but not mapped
        //

        if (BcbOut->BaseAddress == NULL) {

            //
            //  It is too complicated to attempt to calculate any ZeroFlags in this
            //  case, because we have to not only do the tests above, but also
            //  compare to the byte range in the Bcb since we will be passing
            //  those parameters to CcMapAndRead.  Also, the probability of hitting
            //  some window where zeroing is of any advantage is quite small.
            //

            //
            //  Set up to just reread the Bcb exactly as the data in it is
            //  described.
            //

            *BaseAddress = ((PCHAR)*BaseAddress - (FileOffset->LowPart - BcbOut->FileOffset.LowPart));
            FOffset = BcbOut->FileOffset;
            TLength.QuadPart = (LONGLONG)BcbOut->ByteLength;

            //
            //  Case 3 - Bcb is there but not mapped and Wait is TRUE
            //
            //  Increment the PinCount, and then release the BcbList
            //  SpinLock so that we can wait to acquire the Bcb exclusive.
            //  Once we have the Bcb exclusive, map and read it in if no
            //  one beats us to it.  Someone may have beat us to it since
            //  we had to release the SpinLock above.
            //

            if (FlagOn(Flags, PIN_WAIT)) {

                BcbOut->PinCount += 1;

                //
                //  Now we have to release the BcbList SpinLock in order to
                //  acquire the Bcb shared.
                //

                KeReleaseInStackQueuedSpinLock( &LockHandle );
                SpinLockAcquired = FALSE;
                if (!ReadOnly) {
                    if (FlagOn(Flags, PIN_EXCLUSIVE)) {
                        (VOID)ExAcquireResourceExclusiveLite( &BcbOut->Resource, TRUE );
                    } else {
                        (VOID)ExAcquireSharedStarveExclusive( &BcbOut->Resource, TRUE );
                    }
                }

                //
                //  Now procede to map and read the data in.
                //
                //  Now read in the data.
                //

                if (!FlagOn(Flags, PIN_NO_READ)) {

                    (VOID)CcMapAndRead( SharedCacheMap,
                                        &FOffset,
                                        TLength.LowPart,
                                        ZeroFlags,
                                        TRUE,
                                        *BaseAddress );

                    //
                    //  Now we have to reacquire the Bcb List spinlock to load
                    //  up the mapping if we are the first one, else we collided
                    //  with someone else who loaded the mapping first, and we
                    //  will just free our mapping.  It is guaranteed that the
                    //  data will be mapped to the same place.
                    //

                    KeAcquireInStackQueuedSpinLock( &SharedCacheMap->BcbSpinLock, &LockHandle );

                    if (BcbOut->BaseAddress == NULL) {

                        BcbOut->BaseAddress = *BaseAddress;
                        BcbOut->Vacb = Vacb;
                        Vacb = NULL;
                    }

                    KeReleaseInStackQueuedSpinLock( &LockHandle );

                    //
                    //
                    //  Calculate Base Address of the data we want.
                    //

                    *BaseAddress = (PCHAR)BcbOut->BaseAddress +
                                   (ULONG)( FileOffset->QuadPart - BcbOut->FileOffset.QuadPart );
                }

                //
                //  Success!
                //

                try_return( Result = TRUE );
            }


            //
            //  Case 4 - Bcb is there but not mapped, and Wait is FALSE
            //
            //  Since we cannot wait, we go immediately see if the data is
            //  there (CcMapAndRead), and then only set up the Bcb and release
            //  the spin lock if the data is there.  Note here we call
            //  CcMapAndRead while holding the spin lock, because we know we
            //  will not fault and not block before returning.
            //

            else {

                if (!ReadOnly && !ExAcquireSharedStarveExclusive( &BcbOut->Resource, FALSE )) {

                    //
                    //  If we cannot get the resource and have not incremented PinCount, then
                    //  suppress the unpin on cleanup.
                    //

                    BcbOut = NULL;
                    try_return( Result = FALSE );
                }

                BcbOut->PinCount += 1;

                KeReleaseInStackQueuedSpinLock( &LockHandle );
                SpinLockAcquired = FALSE;

                //
                //  Note that since this call has Wait = FALSE, it cannot
                //  get an exception (see procedure header).
                //

                ASSERT( !FlagOn(Flags, PIN_NO_READ) );
                if (!CcMapAndRead( SharedCacheMap,
                                   &BcbOut->FileOffset,
                                   BcbOut->ByteLength,
                                   ZeroFlags,
                                   FALSE,
                                   *BaseAddress )) {

                    try_return( Result = FALSE );
                }

                //
                //  Now we have to reacquire the Bcb List spinlock to load
                //  up the mapping if we are the first one, else we collided
                //  with someone else who loaded the mapping first, and we
                //  will just free our mapping.  It is guaranteed that the
                //  data will be mapped to the same place.
                //

                KeAcquireInStackQueuedSpinLock( &SharedCacheMap->BcbSpinLock, &LockHandle );

                if (BcbOut->BaseAddress == NULL) {

                    BcbOut->BaseAddress = *BaseAddress;
                    BcbOut->Vacb = Vacb;
                    Vacb = NULL;
                }

                KeReleaseInStackQueuedSpinLock( &LockHandle );

                //
                //  Calculate Base Address of the data we want.
                //

                *BaseAddress = (PCHAR)BcbOut->BaseAddress +
                               (ULONG)( FileOffset->QuadPart - BcbOut->FileOffset.QuadPart );

                //
                //  Success!
                //

                try_return( Result = TRUE );
            }
        }


        //
        //  Cases 5 and 6 - Bcb is there and it is mapped
        //

        else {

            //
            //  Case 5 - Bcb is there and mapped, and Wait is TRUE
            //
            //  We can just increment the PinCount, release the SpinLock
            //  and then acquire the Bcb Shared if we are not ReadOnly.
            //

            if (FlagOn(Flags, PIN_WAIT)) {

                BcbOut->PinCount += 1;
                KeReleaseInStackQueuedSpinLock( &LockHandle );
                SpinLockAcquired = FALSE;

                //
                //  Acquire Bcb Resource shared to insure that it is in memory.
                //

                if (!ReadOnly) {
                    if (FlagOn(Flags, PIN_EXCLUSIVE)) {
                        (VOID)ExAcquireResourceExclusiveLite( &BcbOut->Resource, TRUE );
                    } else {
                        (VOID)ExAcquireSharedStarveExclusive( &BcbOut->Resource, TRUE );
                    }
                }
            }

            //
            //  Case 6 - Bcb is there and mapped, and Wait is FALSE
            //
            //  If we are not ReadOnly, we have to first see if we can
            //  acquire the Bcb shared before incrmenting the PinCount,
            //  since we will have to return FALSE if we cannot acquire the
            //  resource.
            //

            else {

                //
                //  Acquire Bcb Resource shared to insure that it is in memory.
                //

                if (!ReadOnly && !ExAcquireSharedStarveExclusive( &BcbOut->Resource, FALSE )) {

                    //
                    //  If we cannot get the resource and have not incremented PinCount, then
                    //  suppress the unpin on cleanup.
                    //

                    BcbOut = NULL;
                    try_return( Result = FALSE );
                }

                BcbOut->PinCount += 1;
                KeReleaseInStackQueuedSpinLock( &LockHandle );
                SpinLockAcquired = FALSE;
            }

            //
            //  Calculate Base Address of the data we want.
            //

            *BaseAddress = (PCHAR)BcbOut->BaseAddress +
                           (ULONG)( FileOffset->QuadPart - BcbOut->FileOffset.QuadPart );

            //
            //  Success!
            //

            try_return( Result = TRUE );
        }


    try_exit: NOTHING;

        if (FlagOn(Flags, PIN_NO_READ) &&
            FlagOn(Flags, PIN_EXCLUSIVE) &&
            (BcbOut != NULL) &&
            (BcbOut->BaseAddress != NULL)) {

            //
            //  Unmap the Vacb and free the resource if the Bcb is still
            //  dirty.  We have to free the resource before dropping the
            //  spinlock, and we want to hold the resource until the
            //  virtual address is freed.
            //

            CcFreeVirtualAddress( BcbOut->Vacb );

            BcbOut->BaseAddress = NULL;
            BcbOut->Vacb = NULL;
        }

    } finally {

        //
        //  Release the spinlock if it is acquired.
        //

        if (SpinLockAcquired) {
            KeReleaseInStackQueuedSpinLock( &LockHandle );
        }

        //
        //  If the Vacb was not used for any reason (error or not needed), then free it here.
        //

        if (Vacb != NULL) {
            CcFreeVirtualAddress( Vacb );
        }

        //
        //  If we referenced a piece of a multilevel structure, release here.
        //

        if (FlagOn(Flags, PIN_NO_READ)) {

            CcDereferenceFileOffset( SharedCacheMap, *FileOffset );
        }

        if (Result) {

            *Bcb = BcbOut;
            *BeyondLastByte = BcbOut->BeyondLastByte;

        //
        //  An abnormal termination can occur on an allocation failure,
        //  or on a failure to map and read the buffer.
        //

        } else {

            *BaseAddress = NULL;
            if (BcbOut != NULL) {
                CcUnpinFileData( BcbOut, ReadOnly, UNPIN );
            }
        }

        DebugTrace( 0, me, "    <Bcb = %08lx\n", *Bcb );
        DebugTrace( 0, me, "    <BaseAddress = %08lx\n", *BaseAddress );
        DebugTrace(-1, me, "CcPinFileData -> %02lx\n", Result );
    }

    return Result;
}


//
//  Internal Support Routine
//

VOID
FASTCALL
CcUnpinFileData (
    IN OUT PBCB Bcb,
    IN BOOLEAN ReadOnly,
    IN UNMAP_ACTIONS UnmapAction
    )

/*++

Routine Description:

    This routine umaps and unlocks the specified buffer, which was previously
    locked and mapped by calling CcPinFileData.

Arguments:

    Bcb - Pointer previously returned from CcPinFileData.  As may be
          seen above, this pointer may be either a Bcb or a Vacb.

    ReadOnly - must specify same value as when data was mapped

    UnmapAction - UNPIN or SET_CLEAN

Return Value:

    None

--*/

{
    KLOCK_QUEUE_HANDLE LockHandle;
    PSHARED_CACHE_MAP SharedCacheMap;

    DebugTrace(+1, me, "CcUnpinFileData >Bcb = %08lx\n", Bcb );

    //
    //  Note, since we have to allocate so many Vacbs, we do not use
    //  a node type code.  However, the Vacb starts with a BaseAddress,
    //  so we assume that the low byte of the Bcb node type code has
    //  some bits set, which a page-aligned Base Address cannot.
    //

    ASSERT( (CACHE_NTC_BCB & 0xFF) != 0 );

    if (Bcb->NodeTypeCode != CACHE_NTC_BCB) {

        ASSERT(((PVACB)Bcb >= CcVacbs) && ((PVACB)Bcb < CcBeyondVacbs));
        ASSERT(((PVACB)Bcb)->SharedCacheMap->NodeTypeCode == CACHE_NTC_SHARED_CACHE_MAP);

        CcFreeVirtualAddress( (PVACB)Bcb );

        DebugTrace(-1, me, "CcUnpinFileData -> VOID (simple release)\n", 0 );

        return;
    }

    SharedCacheMap = Bcb->SharedCacheMap;

    //
    //  We treat Bcbs as ReadOnly (do not acquire resource) if they
    //  are in sections for which we have not disabled modified writing, or
    //  in this special case if this action is a dereferencing of the BCB.
    //

    if (!FlagOn(SharedCacheMap->Flags, MODIFIED_WRITE_DISABLED) ||
        UnmapAction == UNREF) {
        ReadOnly = TRUE;
    }

    //
    //  Synchronize
    //

    KeAcquireInStackQueuedSpinLock( &SharedCacheMap->BcbSpinLock, &LockHandle );

    switch (UnmapAction) {

    case UNPIN:
    case UNREF:

        ASSERT( Bcb->PinCount > 0 );

        Bcb->PinCount -= 1;
        break;

    case SET_CLEAN:

        if (Bcb->Dirty) {

            ULONG Pages = Bcb->ByteLength >> PAGE_SHIFT;

            //
            //  Reverse the rest of the actions taken when the Bcb was set dirty.
            //

            Bcb->Dirty = FALSE;

            CcAcquireMasterLockAtDpcLevel();
            CcDeductDirtyPages( SharedCacheMap, Pages );
            
            //
            //  Normally we need to reduce CcPagesYetToWrite appropriately.
            //

            if (CcPagesYetToWrite > Pages) {
                CcPagesYetToWrite -= Pages;
            } else {
                CcPagesYetToWrite = 0;
            }

            //
            //  Remove SharedCacheMap from dirty list if nothing more dirty,
            //  and someone still has the cache map opened.
            //

            if ((SharedCacheMap->DirtyPages == 0) &&
                (SharedCacheMap->OpenCount != 0)) {

                RemoveEntryList( &SharedCacheMap->SharedCacheMapLinks );
                InsertTailList( &CcCleanSharedCacheMapList,
                                &SharedCacheMap->SharedCacheMapLinks );
            }

            CcReleaseMasterLockFromDpcLevel();
        }

        break;

    default:
        CcBugCheck( UnmapAction, 0, 0 );
    }

    //
    //  If we brought it to 0, then we have to kill it.
    //

    if (Bcb->PinCount == 0) {

        //
        //  If the Bcb is Dirty, we only release the resource and unmap now.
        //

        if (Bcb->Dirty) {

            if (Bcb->BaseAddress != NULL) {

                //
                //  Unmap the Vacb and free the resource if the Bcb is still
                //  dirty.  We have to free the resource before dropping the
                //  spinlock, and we want to hold the resource until the
                //  virtual address is freed.
                //

                CcFreeVirtualAddress( Bcb->Vacb );

                Bcb->BaseAddress = NULL;
                Bcb->Vacb = NULL;
            }

            if (!ReadOnly) {
                ExReleaseResourceLite( &Bcb->Resource );
            }

            KeReleaseInStackQueuedSpinLock( &LockHandle );
        }

        //
        //  Otherwise, we also delete the Bcb.
        //

        else {

            //
            //  Since CcCalculateVacbLockCount has to be able to walk
            //  the BcbList with only the VacbSpinLock, we take that one
            //  out to change the list and decrement the level.
            //

            CcAcquireVacbLockAtDpcLevel();
            RemoveEntryList( &Bcb->BcbLinks );

            //
            //  For large metadata streams we unlock the Vacb level.
            //

            CcUnlockVacbLevel( SharedCacheMap, Bcb->FileOffset.QuadPart );
            CcReleaseVacbLockFromDpcLevel();

            //
            //  Debug routines used to remove Bcbs from the global list
            //

#if LIST_DBG

            KeAcquireQueuedSpinLockAtDpcLevel( KeQueuedSpinLockContext(LockQueueBcbLock) );

            if (Bcb->CcBcbLinks.Flink != NULL) {

                RemoveEntryList( &Bcb->CcBcbLinks );
                CcBcbCount -= 1;
            }

            KeReleaseQueuedSpinLockFromDpcLevel( KeQueuedSpinLockContext(LockQueueBcbLock) );

#endif

            if (Bcb->BaseAddress != NULL) {

                CcFreeVirtualAddress( Bcb->Vacb );
            }
#if DBG
            if (!ReadOnly) {
                ExReleaseResourceLite( &Bcb->Resource );
            }

            //
            //  ASSERT that the resource is unowned.
            //

            ASSERT( Bcb->Resource.ActiveCount == 0 );
#endif
            KeReleaseInStackQueuedSpinLock( &LockHandle );
            CcDeallocateBcb( Bcb );
        }
    }

    //
    //  Else we just have to release our Shared access, if we are not
    //  readonly.  We don't need to do this above, since we deallocate
    //  the entire Bcb there.
    //

    else {

        if (!ReadOnly) {
            ExReleaseResourceLite( &Bcb->Resource );
        }

        KeReleaseInStackQueuedSpinLock( &LockHandle );
    }

    DebugTrace(-1, me, "CcUnpinFileData -> VOID\n", 0 );

    return;
}


VOID
CcSetReadAheadGranularity (
    IN PFILE_OBJECT FileObject,
    IN ULONG Granularity
    )

/*++

Routine Description:

    This routine may be called to set the read ahead granularity used by
    the Cache Manager.  The default is PAGE_SIZE.  The number is decremented
    and stored as a mask.

Arguments:

    FileObject - File Object for which granularity shall be set

    Granularity - new granularity, which must be an even power of 2 and
                  >= PAGE_SIZE

Return Value:

    None
--*/

{
    ((PPRIVATE_CACHE_MAP)FileObject->PrivateCacheMap)->ReadAheadMask = Granularity - 1;
}


VOID
CcScheduleReadAhead (
    IN PFILE_OBJECT FileObject,
    IN PLARGE_INTEGER FileOffset,
    IN ULONG Length
    )

/*++

Routine Description:

    This routine is called by Copy Read and Mdl Read file system routines to
    perform common Read Ahead processing.  The input parameters describe
    the current read which has just been completed, or perhaps only started
    in the case of Mdl Reads.  Based on these parameters, an
    assessment is made on how much data should be read ahead, and whether
    that data has already been read ahead.

    The processing is divided into two parts:

        CALCULATE READ AHEAD REQUIREMENTS   (CcScheduleReadAhead)

        PERFORM READ AHEAD                  (CcPerformReadAhead)

    File systems should always call CcReadAhead, which will conditionally
    call CcScheduleReadAhead (if the read is large enough).  If such a call
    determines that there is read ahead work to do, and no read ahead is
    currently active, then it will set ReadAheadActive and schedule read
    ahead to be peformed by the Lazy Writer, who will call CcPeformReadAhead.

Arguments:

    FileObject - supplies pointer to FileObject on which readahead should be
                 considered.

    FileOffset - supplies the FileOffset at which the last read just occurred.

    Length - supplies the length of the last read.

Return Value:

    None
--*/

{
    LARGE_INTEGER NewOffset;
    LARGE_INTEGER NewBeyond;
    LARGE_INTEGER FileOffset1, FileOffset2;
    KIRQL OldIrql;
    PSHARED_CACHE_MAP SharedCacheMap;
    PPRIVATE_CACHE_MAP PrivateCacheMap;
    PWORK_QUEUE_ENTRY WorkQueueEntry;
    ULONG ReadAheadSize;
    LOGICAL Changed = FALSE;

    DebugTrace(+1, me, "CcScheduleReadAhead:\n", 0 );
    DebugTrace2(0, me, "    FileOffset = %08lx, %08lx\n", FileOffset->LowPart,
                                                          FileOffset->HighPart );
    DebugTrace( 0, me, "    Length = %08lx\n", Length );

    SharedCacheMap = *(PSHARED_CACHE_MAP *)((PCHAR)FileObject->SectionObjectPointer
                                            + sizeof(PVOID));
    PrivateCacheMap = FileObject->PrivateCacheMap;

    if ((PrivateCacheMap == NULL) ||
        (SharedCacheMap == NULL) ||
        FlagOn(SharedCacheMap->Flags, DISABLE_READ_AHEAD)) {

        DebugTrace(-1, me, "CcScheduleReadAhead -> VOID (Nooped)\n", 0 );

        return;
    }

    //
    //  Round boundaries of transfer up to some greater granularity, so that
    //  sequential reads will be recognized even if a few bytes are skipped
    //  between records.
    //

    NewOffset = *FileOffset;
    NewBeyond.QuadPart = FileOffset->QuadPart + (LONGLONG)Length;

    //
    //  Find the next read ahead boundary beyond the current read.
    //

    ReadAheadSize = (Length + PrivateCacheMap->ReadAheadMask) & ~PrivateCacheMap->ReadAheadMask;
    FileOffset2.QuadPart = NewBeyond.QuadPart + (LONGLONG)ReadAheadSize;
    FileOffset2.LowPart &= ~PrivateCacheMap->ReadAheadMask;

    //
    //  CALCULATE READ AHEAD REQUIREMENTS
    //

    //
    //  Take out the ReadAhead spinlock to synchronize our read ahead decision.
    //

    ExAcquireSpinLock( &PrivateCacheMap->ReadAheadSpinLock, &OldIrql );

    //
    //  Read Ahead Case 0.
    //
    //  Sequential-only hint in the file object.  For this case we will
    //  try and always keep two read ahead granularities read ahead from
    //  and including the end of the current transfer.  This case has the
    //  lowest overhead, and the code is completely immune to how the
    //  caller skips around.  Sequential files use ReadAheadOffset[1] in
    //  the PrivateCacheMap as their "high water mark".
    //

    if (FlagOn(FileObject->Flags, FO_SEQUENTIAL_ONLY)) {

        //
        //  If the next boundary is greater than or equal to the high-water mark,
        //  then read ahead.
        //

        if (FileOffset2.QuadPart >= PrivateCacheMap->ReadAheadOffset[1].QuadPart) {

            //
            //  On the first read if we are using a large read ahead granularity,
            //  and the read did not get it all, we will just get the rest of the
            //  first data we want.
            //

            if ((FileOffset->QuadPart == 0)

                    &&

                (PrivateCacheMap->ReadAheadMask > (PAGE_SIZE - 1))

                    &&

                ((Length + PAGE_SIZE - 1) <= PrivateCacheMap->ReadAheadMask)) {

                FileOffset1.QuadPart = (LONGLONG)( ROUND_TO_PAGES(Length) );
                PrivateCacheMap->ReadAheadLength[0] = ReadAheadSize - FileOffset1.LowPart;
                FileOffset2.QuadPart = (LONGLONG)ReadAheadSize;

            //
            //  Calculate the next read ahead boundary.
            //

            } else {

                FileOffset1.QuadPart = PrivateCacheMap->ReadAheadOffset[1].QuadPart +
                                       (LONGLONG)ReadAheadSize;

                //
                //  If the end of the current read is actually beyond where we would
                //  normally do our read ahead, then we have fallen behind, and we must
                //  advance to that spot.
                //

                if (FileOffset2.QuadPart > FileOffset1.QuadPart) {
                    FileOffset1 = FileOffset2;
                }
                PrivateCacheMap->ReadAheadLength[0] = ReadAheadSize;
                FileOffset2.QuadPart = FileOffset1.QuadPart + (LONGLONG)ReadAheadSize;
            }

            //
            //  Now issue the next two read aheads.
            //

            PrivateCacheMap->ReadAheadOffset[0] = FileOffset1;

            PrivateCacheMap->ReadAheadOffset[1] = FileOffset2;
            PrivateCacheMap->ReadAheadLength[1] = ReadAheadSize;

            Changed = TRUE;
        }

    //
    //  Read Ahead Case 1.
    //
    //  If this is the third of three sequential reads, then we will see if
    //  we can read ahead.  Note that if the first read to a file is to
    //  offset 0, it passes this test.
    //

    } else if ((NewOffset.HighPart == PrivateCacheMap->BeyondLastByte2.HighPart)

            &&

        ((NewOffset.LowPart & ~NOISE_BITS)
           == (PrivateCacheMap->BeyondLastByte2.LowPart & ~NOISE_BITS))

            &&

        (PrivateCacheMap->FileOffset2.HighPart
           == PrivateCacheMap->BeyondLastByte1.HighPart)

            &&

        ((PrivateCacheMap->FileOffset2.LowPart & ~NOISE_BITS)
           == (PrivateCacheMap->BeyondLastByte1.LowPart & ~NOISE_BITS))) {

        //
        //  On the first read if we are using a large read ahead granularity,
        //  and the read did not get it all, we will just get the rest of the
        //  first data we want.
        //

        if ((FileOffset->QuadPart == 0)

                &&

            (PrivateCacheMap->ReadAheadMask > (PAGE_SIZE - 1))

                &&

            ((Length + PAGE_SIZE - 1) <= PrivateCacheMap->ReadAheadMask)) {

            FileOffset2.QuadPart = (LONGLONG)( ROUND_TO_PAGES(Length) );
        }

        //
        //  Round read offset to next read ahead boundary.
        //

        else {
            FileOffset2.QuadPart = NewBeyond.QuadPart + (LONGLONG)ReadAheadSize;

            FileOffset2.LowPart &= ~PrivateCacheMap->ReadAheadMask;
        }

        //
        //  Set read ahead length to be the same as for the most recent read,
        //  up to our max.
        //

        if (FileOffset2.QuadPart != PrivateCacheMap->ReadAheadOffset[1].QuadPart) {

            ASSERT( FileOffset2.HighPart >= 0 );

            Changed = TRUE;
            PrivateCacheMap->ReadAheadOffset[1] = FileOffset2;
            PrivateCacheMap->ReadAheadLength[1] = ReadAheadSize;
        }
    }

    //
    //  Read Ahead Case 2.
    //
    //  If this is the third read following a particular stride, then we
    //  will see if we can read ahead.  One example of an application that
    //  might do this is a spreadsheet.  Note that this code even works
    //  for negative strides.
    //

    else if ( ( NewOffset.QuadPart -
                PrivateCacheMap->FileOffset2.QuadPart ) ==
              ( PrivateCacheMap->FileOffset2.QuadPart -
                PrivateCacheMap->FileOffset1.QuadPart )) {

        //
        //  According to the current stride, the next offset will be:
        //
        //      NewOffset + (NewOffset - FileOffset2)
        //
        //  which is the same as:
        //
        //      (NewOffset * 2) - FileOffset2
        //

        FileOffset2.QuadPart = ( NewOffset.QuadPart << 1 ) - PrivateCacheMap->FileOffset2.QuadPart;

        //
        //  If our stride is going backwards through the file, we
        //  have to detect the case where the next step would wrap.
        //

        if (FileOffset2.HighPart >= 0) {

            //
            //  The read ahead length must be extended by the same amount that
            //  we will round the PrivateCacheMap->ReadAheadOffset down.
            //

            Length += FileOffset2.LowPart & (PAGE_SIZE - 1);

            //
            //  Now round the PrivateCacheMap->ReadAheadOffset down.
            //

            FileOffset2.LowPart &= ~(PAGE_SIZE - 1);
            PrivateCacheMap->ReadAheadOffset[1] = FileOffset2;

            //
            //  Round to page boundary.
            //

            PrivateCacheMap->ReadAheadLength[1] = (ULONG) ROUND_TO_PAGES(Length);
            Changed = TRUE;
        }
    }

    //
    //  Get out if the ReadAhead requirements did not change.
    //

    if (!Changed || PrivateCacheMap->Flags.ReadAheadActive) {

        DebugTrace( 0, me, "Read ahead already in progress or no change\n", 0 );

        ExReleaseSpinLock( &PrivateCacheMap->ReadAheadSpinLock, OldIrql );
        return;
    }

    //
    //  Otherwise, we will proceed and try to schedule the read ahead
    //  ourselves.
    //

    CC_SET_PRIVATE_CACHE_MAP (PrivateCacheMap, PRIVATE_CACHE_MAP_READ_AHEAD_ACTIVE);

    //
    //  Release spin lock on way out
    //

    ExReleaseSpinLock( &PrivateCacheMap->ReadAheadSpinLock, OldIrql );

    //
    //  Queue the read ahead request to the Lazy Writer's work queue.
    //

    DebugTrace( 0, me, "Queueing read ahead to worker thread\n", 0 );

    WorkQueueEntry = CcAllocateWorkQueueEntry();

    //
    //  If we failed to allocate a work queue entry, then, we will
    //  quietly bag it.  Read ahead is only an optimization, and
    //  no one ever requires that it occur.
    //

    if (WorkQueueEntry != NULL) {

        //
        //  We must reference this file object so that it cannot go away
        //  until we finish Read Ahead processing in the Worker Thread.
        //

        ObReferenceObject ( FileObject );

        //
        //  Increment open count to make sure the SharedCacheMap stays around.
        //

        CcAcquireMasterLock( &OldIrql );
        CcIncrementOpenCount( SharedCacheMap, 'adRQ' );
        CcReleaseMasterLock( OldIrql );

        WorkQueueEntry->Function = (UCHAR)ReadAhead;
        WorkQueueEntry->Parameters.Read.FileObject = FileObject;

        CcPostWorkQueue( WorkQueueEntry, &CcExpressWorkQueue );
    }

    //
    //  If we failed to allocate a Work Queue Entry, or all of the pages
    //  are resident we must set the active flag false.
    //

    else {

        ExAcquireFastLock( &PrivateCacheMap->ReadAheadSpinLock, &OldIrql );
        CC_CLEAR_PRIVATE_CACHE_MAP (PrivateCacheMap, PRIVATE_CACHE_MAP_READ_AHEAD_ACTIVE);
        ExReleaseFastLock( &PrivateCacheMap->ReadAheadSpinLock, OldIrql );
    }

    DebugTrace(-1, me, "CcScheduleReadAhead -> VOID\n", 0 );

    return;
}


VOID
FASTCALL
CcPerformReadAhead (
    IN PFILE_OBJECT FileObject
    )

/*++

Routine Description:

    This routine is called by the Lazy Writer to perform read ahead which
    has been scheduled for this file by CcScheduleReadAhead.

Arguments:

    FileObject - supplies pointer to FileObject on which readahead should be
                 considered.

Return Value:

    None
--*/

{
    KIRQL OldIrql;
    PSHARED_CACHE_MAP SharedCacheMap;
    PPRIVATE_CACHE_MAP PrivateCacheMap;
    ULONG i;
    LARGE_INTEGER ReadAheadOffset[2];
    ULONG ReadAheadLength[2];
    PCACHE_MANAGER_CALLBACKS Callbacks;
    PVOID Context;
    ULONG SavedState;
    LOGICAL Done;
    LOGICAL HitEof = FALSE;
    LOGICAL ReadAheadPerformed = FALSE;
    ULONG FaultOccurred = 0;
    PETHREAD Thread = PsGetCurrentThread();
    PVACB Vacb = NULL;

    LOGICAL ResourceHeld = FALSE;

    DebugTrace(+1, me, "CcPerformReadAhead:\n", 0 );
    DebugTrace( 0, me, "    FileObject = %08lx\n", FileObject );

    MmSavePageFaultReadAhead( Thread, &SavedState );

    try {

        //
        //  Since we have the open count biased, we can safely access the
        //  SharedCacheMap.
        //

        SharedCacheMap = FileObject->SectionObjectPointer->SharedCacheMap;

        Callbacks = SharedCacheMap->Callbacks;
        Context = SharedCacheMap->LazyWriteContext;

        //
        //  After the first time, keep looping as long as there are new
        //  read ahead requirements.  (We will skip out below.)
        //

        while (TRUE) {

            //
            //  Get SharedCacheMap and PrivateCacheMap.  If either are now NULL, get
            //  out.
            //

            CcAcquireMasterLock( &OldIrql );

            PrivateCacheMap = FileObject->PrivateCacheMap;

            //
            //  Now capture the information that we need, so that we can drop the
            //  SharedList Resource.  This information is advisory only anyway, and
            //  the caller must guarantee that the FileObject is referenced.
            //

            if (PrivateCacheMap != NULL) {

                ExAcquireSpinLockAtDpcLevel( &PrivateCacheMap->ReadAheadSpinLock );

                //
                //  We are done when the lengths are 0
                //

                Done = ((PrivateCacheMap->ReadAheadLength[0] |
                         PrivateCacheMap->ReadAheadLength[1]) == 0);

                ReadAheadOffset[0] = PrivateCacheMap->ReadAheadOffset[0];
                ReadAheadOffset[1] = PrivateCacheMap->ReadAheadOffset[1];
                ReadAheadLength[0] = PrivateCacheMap->ReadAheadLength[0];
                ReadAheadLength[1] = PrivateCacheMap->ReadAheadLength[1];
                PrivateCacheMap->ReadAheadLength[0] = 0;
                PrivateCacheMap->ReadAheadLength[1] = 0;

                ExReleaseSpinLockFromDpcLevel( &PrivateCacheMap->ReadAheadSpinLock );
            }

            CcReleaseMasterLock( OldIrql );

            //
            //  Acquire the file shared.
            //

            ResourceHeld = (*Callbacks->AcquireForReadAhead)( Context, TRUE );

            if ((PrivateCacheMap == NULL) || Done || !ResourceHeld) {

                try_return( NOTHING );
            }

            //
            //  PERFORM READ AHEAD
            //
            //
            //  Now loop until everything is read in.  The Read ahead is accomplished
            //  by touching the pages with an appropriate ReadAhead parameter in MM.
            //

            i = 0;

            do {

                LARGE_INTEGER Offset, SavedOffset;
                ULONG Length, SavedLength;

                Offset = ReadAheadOffset[i];
                Length = ReadAheadLength[i];
                SavedOffset = Offset;
                SavedLength = Length;

                if ((Length != 0)

                        &&

                    ( Offset.QuadPart <= SharedCacheMap->FileSize.QuadPart )) {

                    ReadAheadPerformed = TRUE;

                    //
                    //  Keep length within file and MAX_READ_AHEAD
                    //

                    if ( ( Offset.QuadPart + (LONGLONG)Length ) >= SharedCacheMap->FileSize.QuadPart ) {

                        Length = (ULONG)( SharedCacheMap->FileSize.QuadPart - Offset.QuadPart );
                        HitEof = TRUE;

                    }
                    if (Length > MAX_READ_AHEAD) {
                        Length = MAX_READ_AHEAD;
                    }

                    //
                    //  Now loop to read all of the desired data in.  This loop
                    //  is more or less like the same loop to read data in
                    //  CcCopyRead, except that we do not copy anything, just
                    //  unmap as soon as it is in.
                    //

                    while (Length != 0) {

                        ULONG ReceivedLength;
                        PVOID CacheBuffer;
                        ULONG PagesToGo;

                        //
                        //  Call local routine to Map or Access the file data.
                        //  If we cannot map the data because of a Wait condition,
                        //  return FALSE.
                        //
                        //  Since this routine is intended to be called from
                        //  the finally handler from file system read modules,
                        //  it is imperative that it not raise any exceptions.
                        //  Therefore, if any expected exception is raised, we
                        //  will simply get out.
                        //

                        CacheBuffer = CcGetVirtualAddress( SharedCacheMap,
                                                           Offset,
                                                           &Vacb,
                                                           &ReceivedLength );

                        //
                        //  If we got more than we need, make sure to only transfer
                        //  the right amount.
                        //

                        if (ReceivedLength > Length) {
                            ReceivedLength = Length;
                        }

                        //
                        //  Now loop to touch all of the pages, calling MM to insure
                        //  that if we fault, we take in exactly the number of pages
                        //  we need.
                        //

                        PagesToGo = ADDRESS_AND_SIZE_TO_SPAN_PAGES( CacheBuffer,
                                                           ReceivedLength );

                        CcMissCounter = &CcReadAheadIos;

                        while (PagesToGo) {

                            MmSetPageFaultReadAhead( Thread, (PagesToGo - 1) );
                            FaultOccurred |= !MmCheckCachedPageState(CacheBuffer, FALSE);

                            CacheBuffer = (PCHAR)CacheBuffer + PAGE_SIZE;
                            PagesToGo -= 1;
                        }
                        CcMissCounter = &CcThrowAway;

                        //
                        //  Calculate how much data we have left to go.
                        //

                        Length -= ReceivedLength;

                        //
                        //  Assume we did not get all the data we wanted, and set
                        //  Offset to the end of the returned data.
                        //

                        Offset.QuadPart = Offset.QuadPart + (LONGLONG)ReceivedLength;

                        //
                        //  It was only a page, so we can just leave this loop
                        //  After freeing the address.
                        //

                        CcFreeVirtualAddress( Vacb );
                        Vacb = NULL;
                    }
                }
                i += 1;
            } while (i <= 1);

            //
            //  Release the file
            //

            (*Callbacks->ReleaseFromReadAhead)( Context );
            ResourceHeld = FALSE;
        }

    try_exit: NOTHING;
    }
    finally {

        MmResetPageFaultReadAhead(Thread, SavedState);
        CcMissCounter = &CcThrowAway;

        //
        //  If we got an error faulting a single page in, release the Vacb
        //  here.  It is important to free any mapping before dropping the
        //  resource to prevent purge problems.
        //

        if (Vacb != NULL) {
            CcFreeVirtualAddress( Vacb );
        }

        //
        //  Release the file
        //

        if (ResourceHeld) {
            (*Callbacks->ReleaseFromReadAhead)( Context );
        }

        //
        //  To show we are done, we must make sure the PrivateCacheMap is
        //  still there.
        //

        CcAcquireMasterLock( &OldIrql );

        PrivateCacheMap = FileObject->PrivateCacheMap;

        //
        //  Show readahead is going inactive.
        //

        if (PrivateCacheMap != NULL) {

            ExAcquireSpinLockAtDpcLevel( &PrivateCacheMap->ReadAheadSpinLock );
            CC_CLEAR_PRIVATE_CACHE_MAP (PrivateCacheMap, PRIVATE_CACHE_MAP_READ_AHEAD_ACTIVE);

            //
            //  If he said sequential only and we smashed into Eof, then
            //  let's reset the highwater mark in case he wants to read the
            //  file sequentially again.
            //

            if (HitEof && FlagOn(FileObject->Flags, FO_SEQUENTIAL_ONLY)) {
                PrivateCacheMap->ReadAheadOffset[1].LowPart =
                PrivateCacheMap->ReadAheadOffset[1].HighPart = 0;
            }

            //
            //  If no faults occurred, turn read ahead off.
            //

            if (ReadAheadPerformed && !FaultOccurred) {
                CC_CLEAR_PRIVATE_CACHE_MAP (PrivateCacheMap, PRIVATE_CACHE_MAP_READ_AHEAD_ENABLED);
            }

            ExReleaseSpinLockFromDpcLevel( &PrivateCacheMap->ReadAheadSpinLock );
        }

        //
        //  Free SharedCacheMap list
        //

        CcReleaseMasterLock( OldIrql );

        ObDereferenceObject( FileObject );

        //
        //  Serialize again to decrement the open count.
        //

        CcAcquireMasterLock( &OldIrql );

        CcDecrementOpenCount( SharedCacheMap, 'adRP' );

        if ((SharedCacheMap->OpenCount == 0) &&
            !FlagOn(SharedCacheMap->Flags, WRITE_QUEUED) &&
            (SharedCacheMap->DirtyPages == 0)) {

            //
            //  Move to the dirty list.
            //

            RemoveEntryList( &SharedCacheMap->SharedCacheMapLinks );
            InsertTailList( &CcDirtySharedCacheMapList.SharedCacheMapLinks,
                            &SharedCacheMap->SharedCacheMapLinks );

            //
            //  Make sure the Lazy Writer will wake up, because we
            //  want him to delete this SharedCacheMap.
            //

            LazyWriter.OtherWork = TRUE;
            if (!LazyWriter.ScanActive) {
                CcScheduleLazyWriteScan( FALSE );
            }
        }

        CcReleaseMasterLock( OldIrql );
    }

    DebugTrace(-1, me, "CcPerformReadAhead -> VOID\n", 0 );

    return;
}


PBITMAP_RANGE
CcFindBitmapRangeToDirty (
    IN PMBCB Mbcb,
    IN LONGLONG Page,
    IN PULONG *FreePageForSetting
    )

/*++

Routine Description:

    This routine looks for the bitmap range containing the specified page.
    If it is found it is returned so the caller can set some dirty bits.
    If it is not found, then an attempt is made to come up with a free range
    and set it up to describe the desired range.  To come up with a free range,
    first we attempt to recycle the lowest range that does not currently contain
    any dirty pages.  If there is no such range, then we allocate one.

Arguments:

    Mbcb - Supplies the Mbcb in which to find the range.

    Page - Supplies the page number for the first page to be set dirty.

    FreePageForSetting - Supplies a free bitmap page of zeros from the zone; the
                         caller's pointer is cleared on return if this page is used.

Return Value:

    The desired bitmap range, or NULL if one could not be allocated.

Environment:

    The BcbSpinLock must be held on entry.

--*/

{
    PBITMAP_RANGE BitmapRange, FreeRange;
    PLIST_ENTRY InsertPoint;
    LONGLONG BasePage;

    //
    //  Initialize FreeRange and InsertPoint for the case we have
    //  to initialize a range.
    //

    FreeRange = NULL;
    InsertPoint = &Mbcb->BitmapRanges;

    //
    //  Point to the first bitmap range.
    //

    BitmapRange = (PBITMAP_RANGE)InsertPoint->Flink;

    //
    //  Calculate the desired BasePage from the caller's page.
    //

    BasePage = (Page & ~(LONGLONG)((MBCB_BITMAP_BLOCK_SIZE * 8) - 1));

    //
    //  Loop through the list until we find the range or we have a free range
    //  and correct insertion point.
    //

    do {

        //
        //  If we get an exact match, then we must have hit a fully-initialized
        //  range which we can return.
        //

        if (BasePage == BitmapRange->BasePage) {
            return BitmapRange;

        //
        //  Otherwise, see if the range is free and we have not captured a
        //  free range yet.
        //

        } else if ((BitmapRange->DirtyPages == 0) && (FreeRange == NULL)) {
            FreeRange = BitmapRange;

        //
        //  If we did not capture a free range, see if we need to update our
        //  insertion point.
        //

        } else if (BasePage > BitmapRange->BasePage) {
            InsertPoint = &BitmapRange->Links;
        }

        //
        //  Advance to the next range (or possibly back to the listhead).
        //

        BitmapRange = (PBITMAP_RANGE)BitmapRange->Links.Flink;

    //
    //  Loop until we hit the end, or we know we are done updating both InsertPoint
    //  and FreeRange.
    //

    } while ((BitmapRange != (PBITMAP_RANGE)&Mbcb->BitmapRanges) &&
             ((BasePage >= BitmapRange->BasePage) ||
              (FreeRange == NULL)));

    //
    //  If we found a FreeRange we can use, then remove it from the list.
    //

    if (FreeRange != NULL) {
        RemoveEntryList( &FreeRange->Links );

    //
    //  Otherwise we have to allocate the small bitmap range structure.  We usually
    //  try to avoid calling the pool package while owning a spin lock, but note the
    //  following things which must be true if we hit this point:
    //
    //      The file is larger than 3 bitmap ranges (normally 384MB on Intel).
    //      Three ranges plus all previously allocated ranges are simultaneously dirty.
    //
    //  The second point is fairly unlikely, especially for a sequential writer.  It
    //  can occur for a random writer in a large file, but eventually we will allocate
    //  enough ranges to always describe how many ranges he can keep dirty at once!
    //

    } else {
        FreeRange = ExAllocatePoolWithTag( NonPagedPool, sizeof(BITMAP_RANGE), 'rBcC' );
        if (FreeRange == NULL) {
            return NULL;
        }
        RtlZeroMemory( FreeRange, sizeof(BITMAP_RANGE) );
    }

    //
    //  Insert and initialize.
    //

    InsertHeadList( InsertPoint, &FreeRange->Links );
    FreeRange->BasePage = BasePage;
    FreeRange->FirstDirtyPage = MAXULONG;
    FreeRange->LastDirtyPage = 0;

    //
    //  If the range does not have a bitmap yet, then consume the one we were passed
    //  in.
    //

    if (FreeRange->Bitmap == NULL) {
        ASSERT(*FreePageForSetting != NULL);
        FreeRange->Bitmap = *FreePageForSetting;
        *FreePageForSetting = NULL;
    }

    return FreeRange;
}


PBITMAP_RANGE
CcFindBitmapRangeToClean (
    IN PMBCB Mbcb,
    IN LONGLONG Page
    )

/*++

Routine Description:

    This routine starts from the specified page, and looks for a range with dirty
    pages.  The caller must guarantee that some range exists with dirty pages.  If
    the end of the ranges is hit before finding any dirty ranges, then this routine
    loops back to the start of the range list.

Arguments:

    Mbcb - Supplies the Mbcb in which to find the range.

    Page - Supplies the page number for the first page to scan from.

Return Value:

    The desired bitmap range with dirty pages.

Environment:

    The BcbSpinLock must be held on entry.

--*/

{
    PBITMAP_RANGE BitmapRange;

    //
    //  Point to the first bitmap range.
    //

    BitmapRange = (PBITMAP_RANGE)Mbcb->BitmapRanges.Flink;

    //
    //  Loop through the list until we find the range to return.
    //

    do {

        //
        //  If we hit the listhead, then wrap to find the first dirty range.
        //

        if (BitmapRange == (PBITMAP_RANGE)&Mbcb->BitmapRanges) {

            //
            //  If Page is already 0, we are in an infinite loop.
            //

            ASSERT(Page != 0);

            //
            //  Clear Page and fall through to advance to first range.
            //

            Page = 0;


        //
        //  Otherwise, if we are in range, return the first range
        //  with dirty pages.
        //

        } else if ((Page <= (BitmapRange->BasePage + BitmapRange->LastDirtyPage)) &&
            (BitmapRange->DirtyPages != 0)) {
            return BitmapRange;
        }

        //
        //  Advance to the next range (or possibly back to the listhead).
        //

        BitmapRange = (PBITMAP_RANGE)BitmapRange->Links.Flink;

    } while (TRUE);
}


VOID
CcSetDirtyInMask (
    IN PSHARED_CACHE_MAP SharedCacheMap,
    IN PLARGE_INTEGER FileOffset,
    IN ULONG Length
    )

/*++

Routine Description:

    This routine may be called to set a range of pages dirty in a user data
    file, by just setting the corresponding bits in the mask bcb.

    IMPORTANT NOTE:

        If this routine fails to set any bits due to an allocation failure,
        it just returns quietly without informing the caller.  (Note that this
        routine is never called for no modified write sections.)  The reason
        for this behavior is that this routine is sometimes called as part of
        error recovery (CcFreeActiveVacb, CcMdlWriteComplete, etc.) when it is
        essential to just keep on moving.  Note that if an allocation failure does
        occur, this only means that MM will have to flush the modified page in
        time, since the Lazy Writer will not do it.

Arguments:

    SharedCacheMap - SharedCacheMap where the pages are to be set dirty.

    FileOffset - FileOffset of first page to set dirty

    Length - Used in conjunction with FileOffset to determine how many pages
             to set dirty.

Return Value:

    None

--*/

{
    KLOCK_QUEUE_HANDLE LockHandle;
    PMBCB Mbcb;
    PBITMAP_RANGE BitmapRange;
    LONGLONG FirstPage;
    LONGLONG LastPage;
    PULONG MaskPtr;
    ULONG Mask = 0;
    PULONG Bitmap = NULL;

    //
    //  We assume no caller can cross a bitmap range boundary (currently not even
    //  a view boundary!), so we do not want to loop through bitmap ranges.
    //

    ASSERT((FileOffset->QuadPart / MBCB_BITMAP_RANGE) ==
           ((FileOffset->QuadPart + Length - 1) / MBCB_BITMAP_RANGE));

    //
    //  Initialize our locals.
    //

    FirstPage = FileOffset->QuadPart >> PAGE_SHIFT;
    LastPage = ((FileOffset->QuadPart + Length - 1) >> PAGE_SHIFT);

    //
    //  PREfix correctly notes that Mbcb grande promotion test and the one
    //  that decides to preallocate the bitmap buffer ever disagree, we will
    //  be able to have a NULL Bitmap and die.  This will not happen since we
    //  guarantee that section size >= filesize.  Assert this case, and we will
    //  also assert that Bitmap is never NULL when needed - this should convince
    //  PREfix we're OK.
    //

    ASSERT( (SharedCacheMap->SectionSize.QuadPart / PAGE_SIZE) > LastPage );

    //
    //  If we have to convert to an Mbcb grande, we will loop back here to
    //  preallocate another buffer.
    //

    do {

        //
        //  For large streams, we need to preallocate a block we use for
        //  we use for bitmaps.  We allocate one, then loop back in the rare
        //  case where we will need another.  We free it at the bottom if we
        //  don't need one.
        //

        if (SharedCacheMap->SectionSize.QuadPart > (MBCB_BITMAP_INITIAL_SIZE * 8 * PAGE_SIZE)) {

            //
            //  If we could not preallocate, break out into common cleanup code and
            //  return quietly.
            //

            if (!CcPrefillVacbLevelZone( 1, &LockHandle.OldIrql, FALSE )) {
                return;
            }

            Bitmap = (PULONG)CcAllocateVacbLevel( FALSE );
            CcReleaseVacbLock( LockHandle.OldIrql );
        }

        //
        //  Acquire the Mbcb spinlock.
        //

        KeAcquireInStackQueuedSpinLock( &SharedCacheMap->BcbSpinLock, &LockHandle );

        //
        //  If there is no Mbcb, we will have to allocate one.
        //

        Mbcb = SharedCacheMap->Mbcb;
        if (Mbcb == NULL) {

            //
            //  Since we use the Bcb zone, we must assume that Bcbs are big enough.
            //

            ASSERT(QuadAlign(sizeof(MBCB)) <= QuadAlign(sizeof(BCB)));

            //
            //  Allocate the Mbcb from the Bcb zone.
            //

            Mbcb = (PMBCB)CcAllocateInitializeBcb( NULL, NULL, NULL, NULL );

            //
            //  If we could not allocate an Mbcb, break out to clean up and return
            //

            if (Mbcb == NULL) {
                break;
            }

            //
            //  Set in the node type, and initialize the listhead of ranges.
            //

            Mbcb->NodeTypeCode = CACHE_NTC_MBCB;
            InitializeListHead( &Mbcb->BitmapRanges );

            //
            //  Insert and initialize the first range.
            //

            InsertTailList( &Mbcb->BitmapRanges, &Mbcb->BitmapRange1.Links );
            Mbcb->BitmapRange1.FirstDirtyPage = MAXULONG;

            //
            //  Use the rest of the Mbcb as the initial bitmap.
            //

            Mbcb->BitmapRange1.Bitmap = (PULONG)&Mbcb->BitmapRange2;

            //
            //  Now set to use our new Mbcb.
            //

            SharedCacheMap->Mbcb = Mbcb;
        }

        //
        //  Now see if we need to switch to the Mbcb grande format.
        //

        if ((LastPage >= (MBCB_BITMAP_INITIAL_SIZE * 8)) &&
            (Mbcb->NodeTypeCode != CACHE_NTC_MBCB_GRANDE)) {

            ASSERT( Bitmap != NULL );

            //
            //  If there are any dirty pages, copy the initial bitmap over, and zero
            //  out the original end of the Mbcb for reuse.
            //

            if (Mbcb->BitmapRange1.DirtyPages != 0) {
                RtlCopyMemory( Bitmap, Mbcb->BitmapRange1.Bitmap, MBCB_BITMAP_INITIAL_SIZE );
                RtlZeroMemory( Mbcb->BitmapRange1.Bitmap, MBCB_BITMAP_INITIAL_SIZE );
            }

            //
            //  Store the new bitmap pointer and show we have consumed this one.
            //

            Mbcb->BitmapRange1.Bitmap = Bitmap;
            Bitmap = NULL;

            //
            //  Insert and initialize the first range.
            //

            InsertTailList( &Mbcb->BitmapRanges, &Mbcb->BitmapRange2.Links );
            Mbcb->BitmapRange2.BasePage = MAXLONGLONG;
            Mbcb->BitmapRange2.FirstDirtyPage = MAXULONG;
            InsertTailList( &Mbcb->BitmapRanges, &Mbcb->BitmapRange3.Links );
            Mbcb->BitmapRange3.BasePage = MAXLONGLONG;
            Mbcb->BitmapRange3.FirstDirtyPage = MAXULONG;
            Mbcb->NodeTypeCode = CACHE_NTC_MBCB_GRANDE;

            //
            //  This is a one-time event - converting to the large Mbcb.  Continue back
            //  to preallocate another buffer for CcFindBitmapRangeToDirty.
            //

            KeReleaseInStackQueuedSpinLock( &LockHandle );
            continue;
        }

        //
        //  Now find the Bitmap range we are setting bits in.
        //

        BitmapRange = CcFindBitmapRangeToDirty( Mbcb, FirstPage, &Bitmap );

        //
        //  If we could not allocate this dinky structure, break out quietly.
        //

        if (BitmapRange == NULL) {
            break;
        }

        //
        //  Now update the first and last dirty page indices and the bitmap.
        //

        if (FirstPage < (BitmapRange->BasePage + BitmapRange->FirstDirtyPage)) {
            BitmapRange->FirstDirtyPage = (ULONG)(FirstPage - BitmapRange->BasePage);
        }

        if (LastPage > (BitmapRange->BasePage + BitmapRange->LastDirtyPage)) {
            BitmapRange->LastDirtyPage = (ULONG)(LastPage - BitmapRange->BasePage);
        }

        //
        //  We have to acquire the shared cache map list, because we
        //  may be changing lists.
        //

        CcAcquireMasterLockAtDpcLevel();

        //
        //  If this is the first dirty page for this cache map, there is some work
        //  to do.
        //

        if (SharedCacheMap->DirtyPages == 0) {

            //
            //  If the lazy write scan is not active, then start it.
            //

            if (!LazyWriter.ScanActive) {
                CcScheduleLazyWriteScan( FALSE );
            }

            //
            //  Move to the dirty list.
            //

            RemoveEntryList( &SharedCacheMap->SharedCacheMapLinks );
            InsertTailList( &CcDirtySharedCacheMapList.SharedCacheMapLinks,
                            &SharedCacheMap->SharedCacheMapLinks );

            Mbcb->ResumeWritePage = FirstPage;
        }

        MaskPtr = &BitmapRange->Bitmap[(ULONG)(FirstPage - BitmapRange->BasePage) / 32];
        Mask = 1 << ((ULONG)FirstPage % 32);

        //
        //  Loop to set all of the bits and adjust the DirtyPage totals.
        //

        for ( ; FirstPage <= LastPage; FirstPage++) {

            if ((*MaskPtr & Mask) == 0) {
                CcChargeMaskDirtyPages( SharedCacheMap, Mbcb, BitmapRange, 1 );
                *MaskPtr |= Mask;
            }

            Mask <<= 1;

            if (Mask == 0) {

                MaskPtr += 1;
                Mask = 1;
            }
        }

        //
        //  See if we need to advance our goal for ValidDataLength.
        //

        LastPage = FileOffset->QuadPart + Length;

        if (LastPage > SharedCacheMap->ValidDataGoal.QuadPart) {
            SharedCacheMap->ValidDataGoal.QuadPart = (LONGLONG)LastPage;
        }

        CcReleaseMasterLockFromDpcLevel();

    //
    //  Continue until we have actually set the bits (there is a continue
    //  which just wants to loop back and allocate another buffer).
    //

    } while (Mask == 0);

    //
    //  Now if we preallocated a bitmap buffer, free it on the way out.
    //

    if (Bitmap != NULL) {
        CcAcquireVacbLockAtDpcLevel();
        CcDeallocateVacbLevel( (PVACB *)Bitmap, FALSE );
        CcReleaseVacbLockFromDpcLevel();
    }
    KeReleaseInStackQueuedSpinLock( &LockHandle );
}


VOID
CcSetDirtyPinnedData (
    IN PVOID BcbVoid,
    IN PLARGE_INTEGER Lsn OPTIONAL
    )

/*++

Routine Description:

    This routine may be called to set a Bcb (returned by CcPinFileData)
    dirty, and a candidate for the Lazy Writer.  All Bcbs should be set
    dirty by calling this routine, even if they are to be flushed
    another way.

Arguments:

    Bcb - Supplies a pointer to a pinned (by CcPinFileData) Bcb, to
          be set dirty.

    Lsn - Lsn to be remembered with page.

Return Value:

    None

--*/

{
    PBCB Bcbs[2];
    PBCB *BcbPtrPtr;
    KLOCK_QUEUE_HANDLE LockHandle;
    PSHARED_CACHE_MAP SharedCacheMap;

    DebugTrace(+1, me, "CcSetDirtyPinnedData: Bcb = %08lx\n", BcbVoid );

    //
    //  Assume this is a normal Bcb, and set up for loop below.
    //

    Bcbs[0] = (PBCB)BcbVoid;
    Bcbs[1] = NULL;
    BcbPtrPtr = &Bcbs[0];

    //
    //  If it is an overlap Bcb, then point into the Bcb vector
    //  for the loop.
    //

    if (Bcbs[0]->NodeTypeCode == CACHE_NTC_OBCB) {
        BcbPtrPtr = &((POBCB)Bcbs[0])->Bcbs[0];
    }

    //
    //  Loop to set all Bcbs dirty
    //

    while (*BcbPtrPtr != NULL) {

        Bcbs[0] = *(BcbPtrPtr++);

        //
        //  Should be no ReadOnly Bcbs
        //

        ASSERT(((ULONG_PTR)Bcbs[0] & 1) != 1);

        SharedCacheMap = Bcbs[0]->SharedCacheMap;

        //
        //  We have to acquire the shared cache map list, because we
        //  may be changing lists.
        //

        KeAcquireInStackQueuedSpinLock( &SharedCacheMap->BcbSpinLock, &LockHandle );

        if (!Bcbs[0]->Dirty) {

            ULONG Pages = Bcbs[0]->ByteLength >> PAGE_SHIFT;

            //
            //  Set dirty to keep the Bcb from going away until
            //  it is set Undirty, and assign the next modification time stamp.
            //

            Bcbs[0]->Dirty = TRUE;

            //
            //  Initialize the OldestLsn field.
            //

            if (ARGUMENT_PRESENT(Lsn)) {
                Bcbs[0]->OldestLsn = *Lsn;
                Bcbs[0]->NewestLsn = *Lsn;
            }

            //
            //  Move it to the dirty list if these are the first dirty pages,
            //  and this is not disabled for write behind.
            //
            //  Increase the count of dirty bytes in the shared cache map.
            //

            CcAcquireMasterLockAtDpcLevel();
            if ((SharedCacheMap->DirtyPages == 0) &&
                !FlagOn(SharedCacheMap->Flags, DISABLE_WRITE_BEHIND)) {

                //
                //  If the lazy write scan is not active, then start it.
                //

                if (!LazyWriter.ScanActive) {
                    CcScheduleLazyWriteScan( FALSE );
                }

                RemoveEntryList( &SharedCacheMap->SharedCacheMapLinks );
                InsertTailList( &CcDirtySharedCacheMapList.SharedCacheMapLinks,
                                &SharedCacheMap->SharedCacheMapLinks );
            }
            
            CcChargePinDirtyPages( SharedCacheMap, Pages );
            CcReleaseMasterLockFromDpcLevel();
        }

        //
        //  If this Lsn happens to be older/newer than the ones we have stored, then
        //  change it.
        //

        if (ARGUMENT_PRESENT(Lsn)) {

            if ((Bcbs[0]->OldestLsn.QuadPart == 0) || (Lsn->QuadPart < Bcbs[0]->OldestLsn.QuadPart)) {
                Bcbs[0]->OldestLsn = *Lsn;
            }

            if (Lsn->QuadPart > Bcbs[0]->NewestLsn.QuadPart) {
                Bcbs[0]->NewestLsn = *Lsn;
            }
        }

        //
        //  See if we need to advance our goal for ValidDataLength.
        //

        if ( Bcbs[0]->BeyondLastByte.QuadPart > SharedCacheMap->ValidDataGoal.QuadPart ) {

            SharedCacheMap->ValidDataGoal = Bcbs[0]->BeyondLastByte;
        }

        KeReleaseInStackQueuedSpinLock( &LockHandle );
    }

    DebugTrace(-1, me, "CcSetDirtyPinnedData -> VOID\n", 0 );
}


NTSTATUS
CcSetValidData (
    IN PFILE_OBJECT FileObject,
    IN PLARGE_INTEGER ValidDataLength
    )

/*++

Routine Description:

    This routine is used to call the File System to update ValidDataLength
    for a file.

Arguments:

    FileObject - A pointer to a referenced file object describing which file
        the read should be performed from.

    ValidDataLength - Pointer to new ValidDataLength.

Return Value:

    Status of operation.

--*/

{
    PIO_STACK_LOCATION IrpSp;
    PDEVICE_OBJECT DeviceObject;
    NTSTATUS Status;
    FILE_END_OF_FILE_INFORMATION Buffer;
    IO_STATUS_BLOCK IoStatus;
    KEVENT Event;
    PIRP Irp;

    DebugTrace(+1, me, "CcSetValidData:\n", 0 );
    DebugTrace( 0, me, "    FileObject = %08lx\n", FileObject );
    DebugTrace2(0, me, "    ValidDataLength = %08lx, %08lx\n",
                ValidDataLength->LowPart, ValidDataLength->HighPart );

    //
    //  Copy ValidDataLength to our buffer.
    //

    Buffer.EndOfFile = *ValidDataLength;

    //
    //  Initialize the event.
    //

    KeInitializeEvent( &Event, NotificationEvent, FALSE );

    //
    //  Begin by getting a pointer to the device object that the file resides
    //  on.
    //

    DeviceObject = IoGetRelatedDeviceObject( FileObject );

    //
    //  Allocate an I/O Request Packet (IRP) for this in-page operation.
    //

    Irp = IoAllocateIrp( DeviceObject->StackSize, FALSE );
    if (Irp == NULL) {

        DebugTrace(-1, me, "CcSetValidData-> STATUS_INSUFFICIENT_RESOURCES\n", 0 );

        return STATUS_INSUFFICIENT_RESOURCES;
    }

    //
    //  Get a pointer to the first stack location in the packet.  This location
    //  will be used to pass the function codes and parameters to the first
    //  driver.
    //

    IrpSp = IoGetNextIrpStackLocation( Irp );

    //
    //  Fill in the IRP according to this request, setting the flags to
    //  just cause IO to set the event and deallocate the Irp.
    //

    Irp->Flags = IRP_PAGING_IO | IRP_SYNCHRONOUS_PAGING_IO;
    Irp->RequestorMode = KernelMode;
    Irp->UserIosb = &IoStatus;
    Irp->UserEvent = &Event;
    Irp->Tail.Overlay.OriginalFileObject = FileObject;
    Irp->Tail.Overlay.Thread = PsGetCurrentThread();
    Irp->AssociatedIrp.SystemBuffer = &Buffer;

    //
    //  Fill in the normal read parameters.
    //

    IrpSp->MajorFunction = IRP_MJ_SET_INFORMATION;
    IrpSp->FileObject = FileObject;
    IrpSp->DeviceObject = DeviceObject;
    IrpSp->Parameters.SetFile.Length = sizeof(FILE_END_OF_FILE_INFORMATION);
    IrpSp->Parameters.SetFile.FileInformationClass = FileEndOfFileInformation;
    IrpSp->Parameters.SetFile.FileObject = NULL;
    IrpSp->Parameters.SetFile.AdvanceOnly = TRUE;

    //
    //  Queue the packet to the appropriate driver based on whether or not there
    //  is a VPB associated with the device.  This routine should not raise.
    //

    Status = IoCallDriver( DeviceObject, Irp );

    //
    //  If pending is returned (which is a successful status),
    //  we must wait for the request to complete.
    //

    if (Status == STATUS_PENDING) {
        KeWaitForSingleObject( &Event,
                               Executive,
                               KernelMode,
                               FALSE,
                               (PLARGE_INTEGER)NULL);
    }

    //
    //  If we got an error back in Status, then the Iosb
    //  was not written, so we will just copy the status
    //  there, then test the final status after that.
    //

    if (!NT_SUCCESS(Status)) {
        IoStatus.Status = Status;
    }

    DebugTrace(-1, me, "CcSetValidData-> %08lx\n", IoStatus.Status );

    return IoStatus.Status;
}


//
//  Internal Support Routine
//

BOOLEAN
CcAcquireByteRangeForWrite (
    IN PSHARED_CACHE_MAP SharedCacheMap,
    IN PLARGE_INTEGER TargetOffset OPTIONAL,
    IN ULONG TargetLength,
    OUT PLARGE_INTEGER FileOffset,
    OUT PULONG Length,
    OUT PBCB *FirstBcb
    )

/*++

Routine Description:

    This routine is called by the Lazy Writer to try to find a contiguous
    range of bytes from the specified SharedCacheMap that are dirty and
    should be flushed.  After flushing, these bytes should be released
    by calling CcReleaseByteRangeFromWrite.

    Dirty ranges are returned in strictly increasing order.

Arguments:

    SharedCacheMap - for the file for which the dirty byte range is sought

    TargetOffset - If specified, then only the specified range is
                   to be flushed.

    TargetLength - If target offset specified, this completes the range.
                   In any case, this field is zero for the Lazy Writer,
                   and nonzero for explicit flush calls.

    FileOffset - Returns the offset for the beginning of the dirty byte
                 range to flush

    Length - Returns the length of bytes in the range.

    FirstBcb - Returns the first Bcb in the list for the range, to be used
               when calling CcReleaseByteRangeFromWrite, or NULL if dirty
               pages were found in the mask Bcb.

Return Value:

    FALSE - if no dirty byte range could be found to match the necessary
            criteria.

    TRUE - if a dirty byte range is being returned.

--*/

{
    KLOCK_QUEUE_HANDLE LockHandle;
    PMBCB Mbcb;
    PBCB Bcb;
    LARGE_INTEGER LsnToFlushTo = {0, 0};

    LOGICAL BcbLookasideCheck = FALSE;

    PBITMAP_RANGE BitmapRange;
    PULONG EndPtr;
    PULONG MaskPtr;
    ULONG Mask;
    LONGLONG FirstDirtyPage;
    ULONG OriginalFirstDirtyPage;
    LONGLONG LastDirtyPage = MAXLONGLONG;

    DebugTrace(+1, me, "CcAcquireByteRangeForWrite:\n", 0);
    DebugTrace( 0, me, "    SharedCacheMap = %08lx\n", SharedCacheMap);

    //
    //  Initially clear outputs.
    //

    FileOffset->QuadPart = 0;
    *Length = 0;

    //
    //  We must acquire the SharedCacheMap->BcbSpinLock.
    //

    KeAcquireInStackQueuedSpinLock( &SharedCacheMap->BcbSpinLock, &LockHandle );

    //
    //  See if there is a simple Mask Bcb, and if there is anything dirty in
    //  it.  If so we will simply handle that case here by processing the bitmap.
    //

    Mbcb = SharedCacheMap->Mbcb;

    if ((Mbcb != NULL) &&
        (Mbcb->DirtyPages != 0) &&
        ((Mbcb->PagesToWrite != 0) || (TargetLength != 0))) {

        //
        //  If a target range was specified (outside call to CcFlush for a range),
        //  then calculate FirstPage and EndPtr based on these inputs.
        //

        if (ARGUMENT_PRESENT(TargetOffset)) {

            FirstDirtyPage = TargetOffset->QuadPart >> PAGE_SHIFT;
            LastDirtyPage = (TargetOffset->QuadPart + TargetLength - 1) >> PAGE_SHIFT;

            //
            //  Find the bitmap range containing the first dirty page.
            //

            BitmapRange = CcFindBitmapRangeToClean( Mbcb, FirstDirtyPage );

            //
            //  If the target range is not dirty, get out.  We may have even
            //  gotten back a nonoverlapping bitmap range.
            //

            if ((LastDirtyPage < (BitmapRange->BasePage + BitmapRange->FirstDirtyPage)) ||
                (FirstDirtyPage > (BitmapRange->BasePage + BitmapRange->LastDirtyPage))) {

                goto Scan_Bcbs;
            }

            if (LastDirtyPage < (BitmapRange->BasePage + BitmapRange->LastDirtyPage)) {
                EndPtr = &BitmapRange->Bitmap[(ULONG)(LastDirtyPage - BitmapRange->BasePage) / 32];
            } else {
                EndPtr = &BitmapRange->Bitmap[BitmapRange->LastDirtyPage / 32];
            }


        //
        //  Otherwise, for the Lazy Writer pick up where we left off.
        //

        } else {

            //
            //  If a length was specified, then it is an explicit flush, and
            //  we want to start with the first dirty page, else the Lazy Writer
            //  starts from the ResumeWritePage.
            //

            FirstDirtyPage = 0;
            if (TargetLength == 0) {
                FirstDirtyPage = Mbcb->ResumeWritePage;
            }

            //
            //  Now find the next (cyclic) dirty page from this point.
            //

            BitmapRange = CcFindBitmapRangeToClean( Mbcb, FirstDirtyPage );

            //
            //  If the page we thought we were looking for is beyond the last dirty page
            //  of this range, then CcFindBitmapRangeToClean must have wrapped back to
            //  the start of the file, and we should resume on the first dirty page of
            //  this range.
            //

            if (FirstDirtyPage > (BitmapRange->BasePage + BitmapRange->LastDirtyPage)) {
                FirstDirtyPage = BitmapRange->BasePage + BitmapRange->FirstDirtyPage;
            }

            EndPtr = &BitmapRange->Bitmap[BitmapRange->LastDirtyPage / 32];
        }

        //
        //  Now we can skip over any clean pages.
        //

        if (FirstDirtyPage < (BitmapRange->BasePage + BitmapRange->FirstDirtyPage)) {
            FirstDirtyPage = BitmapRange->BasePage + BitmapRange->FirstDirtyPage;
        }

        //
        //  Form a few other inputs for our dirty page scan.
        //

        MaskPtr = &BitmapRange->Bitmap[(ULONG)(FirstDirtyPage - BitmapRange->BasePage) / 32];
        Mask = (ULONG)(-1 << (FirstDirtyPage % 32));
        OriginalFirstDirtyPage = (ULONG)(FirstDirtyPage - BitmapRange->BasePage);

        //
        //  Because of the possibility of getting stuck on a "hot spot" which gets
        //  modified over and over, we want to be very careful to resume exactly
        //  at the recorded resume point.  If there is nothing there, then we
        //  fall into the loop below to scan for nozero long words in the bitmap,
        //  starting at the next longword.
        //

        if ((*MaskPtr & Mask) == 0) {

            //
            //  Before entering loop, set all mask bits and insure we increment from
            //  an even Ulong boundary.
            //

            Mask = MAXULONG;
            FirstDirtyPage &= ~31;

            //
            //  To scan the bitmap faster, we scan for entire long words which are
            //  nonzero.
            //

            do {

                MaskPtr += 1;
                FirstDirtyPage += 32;

                //
                //  If we go beyond the end, then we must wrap back to the first
                //  dirty page.  We will just go back to the start of the first
                //  longword.
                //

                if (MaskPtr > EndPtr) {

                    //
                    //  We can backup the last dirty page hint to where we
                    //  started scanning, if we are the lazy writer.
                    //

                    if (TargetLength == 0) {
                        ASSERT(OriginalFirstDirtyPage >= BitmapRange->FirstDirtyPage);
                        BitmapRange->LastDirtyPage = OriginalFirstDirtyPage - 1;
                    }

                    //
                    //  We hit the end of our scan.  Let's assume we are supposed
                    //  to move on to the next range with dirty pages.
                    //

                    do {

                        //
                        //  Go to the next range.
                        //

                        BitmapRange = (PBITMAP_RANGE)BitmapRange->Links.Flink;

                        //
                        //  Did we hit the listhead?
                        //

                        if (BitmapRange == (PBITMAP_RANGE)&Mbcb->BitmapRanges) {

                            //
                            //  If this is an explicit flush, then it is time to
                            //  get out.
                            //

                            if (TargetLength != 0) {
                                goto Scan_Bcbs;
                            }

                            //
                            //  Otherwise, we must wrap back to the first range in the
                            //  Lazy Writer Scan.
                            //

                            BitmapRange = (PBITMAP_RANGE)BitmapRange->Links.Flink;
                        }

                    } while (BitmapRange->DirtyPages == 0);

                    //
                    //  Now we have a new range with dirty pages, but if this is
                    //  an explicit flush of a specified range, we may be done.
                    //

                    if ((LastDirtyPage < (BitmapRange->BasePage + BitmapRange->FirstDirtyPage)) ||
                        (FirstDirtyPage > (BitmapRange->BasePage + BitmapRange->LastDirtyPage))) {

                        goto Scan_Bcbs;
                    }

                    //
                    //  Otherwise, we need to set up our context to resume scanning in this
                    //  range.
                    //

                    MaskPtr = &BitmapRange->Bitmap[BitmapRange->FirstDirtyPage / 32];
                    EndPtr = &BitmapRange->Bitmap[BitmapRange->LastDirtyPage / 32];
                    FirstDirtyPage = BitmapRange->BasePage + (BitmapRange->FirstDirtyPage & ~31);
                    OriginalFirstDirtyPage = BitmapRange->FirstDirtyPage;
                }
            } while (*MaskPtr == 0);
        }

        //
        //  Calculate the first set bit in the mask that we hit on.
        //

        Mask = ~Mask + 1;

        //
        //  Now loop to find the first set bit.
        //

        while ((*MaskPtr & Mask) == 0) {

            Mask <<= 1;
            FirstDirtyPage += 1;
        }

        //
        //  If a TargetOffset was specified, then make sure we do not start
        //  beyond the specified range or a dirty Bcb in the range.
        //

        if (ARGUMENT_PRESENT(TargetOffset)) {

            if (FirstDirtyPage >= ((TargetOffset->QuadPart + TargetLength + PAGE_SIZE - 1) >> PAGE_SHIFT)) {

                goto Scan_Bcbs;
            }

            //
            //  If Bcbs are present on this file, we must go scan to see if they
            //  describe a range that must be written first.  If this is not the
            //  case, we'll hop back and continue building the range from the mask Bcb.
            //
            //  Note that this case will be very rare.  Bcbs are introduced into user
            //  files in limited situations (CcZero) and the reverse is never allowed
            //  to happen.
            //

            if (!IsListEmpty(&SharedCacheMap->BcbList)) {

                BcbLookasideCheck = TRUE;
                goto Scan_Bcbs;
            }
        }

Accept_Page:

        //
        //  Now loop to count the set bits at that point, clearing them as we
        //  go because we plan to write the corresponding pages.  Stop as soon
        //  as we find a clean page, or we reach our maximum write size.  Of
        //  course we want to ignore long word boundaries and keep trying to
        //  extend the write.  We do not check for wrapping around the end of
        //  the bitmap here, because we guarantee some zero bits at the end
        //  in CcSetDirtyInMask.
        //

        while (((*MaskPtr & Mask) != 0) && (*Length < (MAX_WRITE_BEHIND / PAGE_SIZE)) &&
               (!ARGUMENT_PRESENT(TargetOffset) || ((FirstDirtyPage + *Length) <
                                                    (ULONG)((TargetOffset->QuadPart + TargetLength + PAGE_SIZE - 1) >> PAGE_SHIFT)))) {

            ASSERT(MaskPtr <= (&BitmapRange->Bitmap[BitmapRange->LastDirtyPage / 32]));

            *MaskPtr -= Mask;
            *Length += 1;
            Mask <<= 1;

            if (Mask == 0) {

                MaskPtr += 1;
                Mask = 1;

                if (MaskPtr > EndPtr) {
                    break;
                }
            }
        }

        //
        //  Now reduce the count of pages we were supposed to write this time,
        //  possibly clearing this count.
        //

        if (*Length < Mbcb->PagesToWrite) {

            Mbcb->PagesToWrite -= *Length;

        } else {

            Mbcb->PagesToWrite = 0;
        }

        //
        //  Reduce the dirty page counts by the number of pages we just cleared.
        //

        ASSERT(Mbcb->DirtyPages >= *Length);
        Mbcb->DirtyPages -= *Length;
        BitmapRange->DirtyPages -= *Length;

        CcAcquireMasterLockAtDpcLevel();
        CcDeductDirtyPages( SharedCacheMap, *Length );

        //
        //  Normally we need to reduce CcPagesYetToWrite appropriately.
        //

        if (CcPagesYetToWrite > *Length) {
            CcPagesYetToWrite -= *Length;
        } else {
            CcPagesYetToWrite = 0;
        }

        //
        //  If we took out the last dirty page, then move the SharedCacheMap
        //  back to the clean list.
        //

        if (SharedCacheMap->DirtyPages == 0) {

            RemoveEntryList( &SharedCacheMap->SharedCacheMapLinks );
            InsertTailList( &CcCleanSharedCacheMapList,
                            &SharedCacheMap->SharedCacheMapLinks );
        }
        CcReleaseMasterLockFromDpcLevel();

        //
        //  If the number of dirty pages for the Mbcb went to zero, we can reset
        //  our hint fields now.
        //

        if (BitmapRange->DirtyPages == 0) {

            BitmapRange->FirstDirtyPage = MAXULONG;
            BitmapRange->LastDirtyPage = 0;

            //
            //  Assume this is a large file and that the resume point should
            //  be at the beginning of the next range.  In all cases if the resume
            //  point is set too high, the next resume will just wrap back to 0 anyway.
            //

            Mbcb->ResumeWritePage = BitmapRange->BasePage + (MBCB_BITMAP_BLOCK_SIZE * 8);

        //
        //  Otherwise we have to update the hint fields.
        //

        } else {

            //
            //  Advance the first dirty page hint if we can.
            //

            if (BitmapRange->FirstDirtyPage == OriginalFirstDirtyPage) {

                BitmapRange->FirstDirtyPage = (ULONG)(FirstDirtyPage - BitmapRange->BasePage) + *Length;
            }

            //
            //  Set to resume the next scan at the next bit for
            //  the Lazy Writer.
            //

            if (TargetLength == 0) {

                Mbcb->ResumeWritePage = FirstDirtyPage + *Length;
            }
        }

        //
        //  We can save a callback by letting our caller know when
        //  we have no more pages to write.
        //

        if (IsListEmpty(&SharedCacheMap->BcbList)) {
            SharedCacheMap->PagesToWrite = Mbcb->PagesToWrite;
        }

        KeReleaseInStackQueuedSpinLock( &LockHandle );

        //
        //  Now form all of our outputs.  We calculated *Length as a page count,
        //  but our caller wants it in bytes.
        //

        *Length <<= PAGE_SHIFT;
        FileOffset->QuadPart = (LONGLONG)FirstDirtyPage << PAGE_SHIFT;
        *FirstBcb = NULL;

        DebugTrace2(0, me, "    <FileOffset = %08lx, %08lx\n", FileOffset->LowPart,
                                                               FileOffset->HighPart );
        DebugTrace( 0, me, "    <Length = %08lx\n", *Length );
        DebugTrace(-1, me, "CcAcquireByteRangeForWrite -> TRUE\n", 0 );

        return TRUE;
    }

    //
    //  We get here if there is no Mbcb or no dirty pages in it.  Note that we
    //  wouldn't even be here if there were no dirty pages in this SharedCacheMap.
    //

    //
    //  Now point to last Bcb in List, and loop until we hit one of the
    //  breaks below or the beginning of the list.
    //

Scan_Bcbs:

    //
    //  Use while TRUE to handle case where the current target range wraps
    //  (escape is at the bottom).
    //

    while (TRUE) {

        Bcb = CONTAINING_RECORD( SharedCacheMap->BcbList.Blink, BCB, BcbLinks );

        //
        //  If we are to resume from a nonzero FileOffset, call CcFindBcb
        //  to get a quicker start.  This is only useful on files that make
        //  use of significant pinned access, of course.
        //

        if (FlagOn(SharedCacheMap->Flags, MODIFIED_WRITE_DISABLED)) {

            PLARGE_INTEGER StartingOffset;

            if (ARGUMENT_PRESENT(TargetOffset)) {
                StartingOffset = TargetOffset;
            } else {
                StartingOffset = (PLARGE_INTEGER)&SharedCacheMap->BeyondLastFlush;
            }

            if (StartingOffset->QuadPart != 0) {

                LARGE_INTEGER StartingOffsetBias;

                StartingOffsetBias.QuadPart = StartingOffset->QuadPart + PAGE_SIZE;

                //
                //  Position ourselves.  If we did not find a Bcb for the page, then
                //  a lower FileOffset was returned, so we want to move forward one.
                //

                if (!CcFindBcb( SharedCacheMap,
                                StartingOffset,
                                &StartingOffsetBias,
                                &Bcb )) {
                    Bcb = CONTAINING_RECORD( Bcb->BcbLinks.Blink, BCB, BcbLinks );
                }
            }
        }

        while (&Bcb->BcbLinks != &SharedCacheMap->BcbList) {

            //
            //  Skip over this item if it is a listhead.
            //

            if (Bcb->NodeTypeCode != CACHE_NTC_BCB) {

                Bcb = CONTAINING_RECORD( Bcb->BcbLinks.Blink, BCB, BcbLinks );
                continue;
            }

            //
            //  If we are doing a specified range, then get out if we hit a
            //  higher Bcb.
            //

            if (ARGUMENT_PRESENT(TargetOffset) &&
                ((TargetOffset->QuadPart + TargetLength) <= Bcb->FileOffset.QuadPart)) {

                break;
            }

            //
            //  If we have not started a run, then see if this Bcb is a candidate
            //  to start one.
            //

            if (*Length == 0) {

                //
                //  Else see if the Bcb is dirty, and is in our specified range, if
                //  there is one.
                //

                if (!Bcb->Dirty ||
                    (ARGUMENT_PRESENT(TargetOffset) && (TargetOffset->QuadPart >= Bcb->BeyondLastByte.QuadPart)) ||
                    (!ARGUMENT_PRESENT(TargetOffset) && (Bcb->FileOffset.QuadPart < SharedCacheMap->BeyondLastFlush))) {

                    Bcb = CONTAINING_RECORD( Bcb->BcbLinks.Blink, BCB, BcbLinks );
                    continue;

                }

                //
                //  If we have a candidate dirty page from the mask Bcb, see
                //  if it describes a prior range.  We must decide to return
                //  the first dirty range.
                //

                if (BcbLookasideCheck && FirstDirtyPage <= (ULONG)(Bcb->FileOffset.QuadPart >> PAGE_SHIFT)) {
                    goto Accept_Page;
                }
            }

            //
            //  Else, if we have started a run, then if this guy cannot be
            //  appended to the run, then break.  Note that we ignore the
            //  Bcb's modification time stamp here to simplify the test.
            //
            //  If the Bcb is currently pinned, then there is no sense in causing
            //  contention, so we will skip over this guy as well.
            //
            //  Finally, if the new Bcb is in the next Vacb level, we will skip it
            //  to avoid problems with Bcb listheads going away in the middle of
            //  CcReleaseByteRangeFromWrite.
            //

            else {
                if (!Bcb->Dirty || ( Bcb->FileOffset.QuadPart != ( FileOffset->QuadPart + (LONGLONG)*Length)) ||
                    (*Length + Bcb->ByteLength > MAX_WRITE_BEHIND) ||
                    (Bcb->PinCount != 0) ||
                    ((Bcb->FileOffset.QuadPart & (VACB_SIZE_OF_FIRST_LEVEL - 1)) == 0)) {

                    break;
                }
            }

            //
            //  Increment PinCount to prevent Bcb from going away once the
            //  SpinLock is released, or we set it clean for the case where
            //  modified write is allowed.
            //

            Bcb->PinCount += 1;

            //
            //  Release the SpinLock before waiting on the resource.
            //

            KeReleaseInStackQueuedSpinLock( &LockHandle );

            if (FlagOn(SharedCacheMap->Flags, MODIFIED_WRITE_DISABLED) &&
                !FlagOn(SharedCacheMap->Flags, DISABLE_WRITE_BEHIND)) {

                //
                //  Now acquire the Bcb exclusive, so that we know that nobody
                //  has it pinned and thus no one can be modifying the described
                //  buffer.  To acquire the first Bcb in a run, we can afford
                //  to wait, because we are not holding any resources.  However
                //  if we already have a Bcb, then we better not wait, because
                //  someone could have this Bcb pinned, and then wait for the
                //  Bcb we already have exclusive.
                //
                //  For streams for which we have not disabled modified page
                //  writing, we do not need to acquire this resource, and the
                //  foreground processing will not be acquiring the Bcb either.
                //

                if (!ExAcquireResourceExclusiveLite( &Bcb->Resource,
                                                 (BOOLEAN)(*Length == 0) )) {

                    DebugTrace( 0, me, "Could not acquire 2nd Bcb\n", 0 );

                    //
                    //  Release the Bcb count we took out above.  We say
                    //  ReadOnly = TRUE since we do not own the resource,
                    //  and SetClean = FALSE because we just want to decement
                    //  the count.
                    //

                    CcUnpinFileData( Bcb, TRUE, UNPIN );

                    //
                    //  When we leave the loop, we have to have the spin lock
                    //

                    KeAcquireInStackQueuedSpinLock( &SharedCacheMap->BcbSpinLock, &LockHandle );
                    break;
                }

                KeAcquireInStackQueuedSpinLock( &SharedCacheMap->BcbSpinLock, &LockHandle );

                //
                //  If someone has the file open WriteThrough, then the Bcb may no
                //  longer be dirty.  If so, call CcUnpinFileData to decrement the
                //  PinCount we incremented and free the resource.
                //

                if (!Bcb->Dirty) {

                    //
                    //  Release the spinlock so that we can call CcUnpinFileData
                    //

                    KeReleaseInStackQueuedSpinLock( &LockHandle );

                    CcUnpinFileData( Bcb, FALSE, UNPIN );

                    KeAcquireInStackQueuedSpinLock( &SharedCacheMap->BcbSpinLock, &LockHandle );

                    //
                    //  Now if we already have some data we can just break to return
                    //  it, otherwise we have to restart the scan, since our Bcb
                    //  may have gone away.
                    //

                    if (*Length != 0) {
                        break;
                    }
                    else {

                        Bcb = CONTAINING_RECORD( SharedCacheMap->BcbList.Blink, BCB, BcbLinks );
                        continue;
                    }
                }

            //
            //  If we are not in the disable modified write mode (normal user data)
            //  then we must set the buffer clean before doing the write, since we
            //  are unsynchronized with anyone producing dirty data.  That way if we,
            //  for example, are writing data out while it is actively being changed,
            //  at least the changer will mark the buffer dirty afterwards and cause
            //  us to write it again later.
            //

            } else {

                CcUnpinFileData( Bcb, TRUE, SET_CLEAN );

               KeAcquireInStackQueuedSpinLock( &SharedCacheMap->BcbSpinLock, &LockHandle );
            }

            DebugTrace( 0, me, "Adding Bcb = %08lx to run\n", Bcb );

            //
            //  No matter what, once we've reached this point we are returning
            //  a range from the Bcbs.
            //

            BcbLookasideCheck = FALSE;

            //
            //  Update all of our return values.  Note that FirstBcb refers to the
            //  FirstBcb in terms of how the Bcb list is ordered.  Since the Bcb list
            //  is ordered by descending file offsets, FirstBcb will actually return
            //  the Bcb with the highest FileOffset.
            //

            if (*Length == 0) {
                *FileOffset = Bcb->FileOffset;
            }
            *FirstBcb = Bcb;
            *Length += Bcb->ByteLength;

            //
            //  If there is a log file flush callback for this stream, then we must
            //  remember the largest Lsn we are about to flush.
            //

            if ((SharedCacheMap->FlushToLsnRoutine != NULL) &&
                (Bcb->NewestLsn.QuadPart > LsnToFlushTo.QuadPart)) {

                LsnToFlushTo = Bcb->NewestLsn;
            }

            Bcb = CONTAINING_RECORD( Bcb->BcbLinks.Blink, BCB, BcbLinks );
        }

        //
        //  If we have a candidate dirty page from the mask Bcb, accept it
        //  since no Bcb has been found.
        //

        if (BcbLookasideCheck) {

            ASSERT( *Length == 0 );
            goto Accept_Page;
        }

        //
        //  If we found something, update our last flush range and reduce
        //  PagesToWrite.
        //

        if (*Length != 0) {

            //
            //  If this is the Lazy Writer, then update BeyondLastFlush and
            //  the PagesToWrite target.
            //

            if (!ARGUMENT_PRESENT(TargetOffset)) {

                SharedCacheMap->BeyondLastFlush = FileOffset->QuadPart + *Length;

                if (SharedCacheMap->PagesToWrite > (*Length >> PAGE_SHIFT)) {
                    SharedCacheMap->PagesToWrite -= (*Length >> PAGE_SHIFT);
                } else {
                    SharedCacheMap->PagesToWrite = 0;
                }
            }

            break;

        //
        //  Else, if we scanned the entire file, get out - nothing to write now.
        //

        } else if ((SharedCacheMap->BeyondLastFlush == 0) || ARGUMENT_PRESENT(TargetOffset)) {
            break;
        }

        //
        //  Otherwise, we may have not found anything because there is nothing
        //  beyond the last flush.  In that case it is time to wrap back to 0
        //  and keep scanning.
        //

        SharedCacheMap->BeyondLastFlush = 0;
    }

    //
    //  Now release the spinlock file while we go off and do the I/O
    //

    KeReleaseInStackQueuedSpinLock( &LockHandle );

    //
    //  If we need to flush to some Lsn, this is the time to do it now
    //  that we have found the largest Lsn and freed the spin lock.
    //

    if (LsnToFlushTo.QuadPart != 0) {

        try {

            (*SharedCacheMap->FlushToLsnRoutine) ( SharedCacheMap->LogHandle,
                                                   LsnToFlushTo );
        } except( CcExceptionFilter( GetExceptionCode() )) {

            //
            //  If there was an error, it will be raised.  We cannot
            //  write anything until we successfully flush the log
            //  file, so we will release everything here and just
            //  return with 0 bytes.
            //

            LARGE_INTEGER LastOffset;
            PBCB NextBcb;

            //
            //  Now loop to free up all of the Bcbs.  Set the time
            //  stamps to 0, so that we are guaranteed to try to
            //  flush them again on the next sweep.
            //

            do {
                NextBcb = CONTAINING_RECORD( (*FirstBcb)->BcbLinks.Flink, BCB, BcbLinks );

                //
                //  Skip over any listheads.
                //

                if ((*FirstBcb)->NodeTypeCode == CACHE_NTC_BCB) {

                    LastOffset = (*FirstBcb)->FileOffset;

                    CcUnpinFileData( *FirstBcb,
                                     BooleanFlagOn(SharedCacheMap->Flags, DISABLE_WRITE_BEHIND),
                                     UNPIN );
                }

                *FirstBcb = NextBcb;
            } while (FileOffset->QuadPart != LastOffset.QuadPart);

            //
            //  Show we did not acquire anything.
            //

            *Length = 0;
        }
    }

    //
    //  If we got anything, return TRUE.
    //

    DebugTrace2(0, me, "    <FileOffset = %08lx, %08lx\n", FileOffset->LowPart,
                                                           FileOffset->HighPart );
    DebugTrace( 0, me, "    <Length = %08lx\n", *Length );
    DebugTrace(-1, me, "CcAcquireByteRangeForWrite -> %02lx\n", *Length != 0 );

    return ((BOOLEAN)(*Length != 0));
}


//
//  Internal Support Routine
//

VOID
CcReleaseByteRangeFromWrite (
    IN PSHARED_CACHE_MAP SharedCacheMap,
    IN PLARGE_INTEGER FileOffset,
    IN ULONG Length,
    IN PBCB FirstBcb,
    IN BOOLEAN VerifyRequired
    )

/*++

Routine Description:

    This routine is called by the Lazy Writer to free a range of bytes and
    clear all dirty bits, for a byte range returned by CcAcquireByteRangeForWrite.

Arguments:

    SharedCacheMap - As supplied to CcAcquireByteRangeForWrite

    FileOffset - As returned from CcAcquireByteRangeForWrite

    Length - As returned from CcAcquirebyteRangeForWrite

    FirstBcb - As returned from CcAcquireByteRangeForWrite

    VerifyRequired - supplied as TRUE if a verify required error was received.
                     In this case we must mark/leave the data dirty so that
                     we will try to write it again.

Return Value:

    None

--*/

{
    LARGE_INTEGER LastOffset;
    PBCB NextBcb;

    DebugTrace(+1, me, "CcReleaseByteRangeFromWrite:\n", 0);
    DebugTrace2(0, me, "    FileOffset = %08lx, %08lx\n", FileOffset->LowPart,
                                                          FileOffset->HighPart );

    //
    //  If it is a mask Mbcb we are getting, then we only have to check
    //  for VerifyRequired.
    //

    if (FirstBcb == NULL) {

        ASSERT(Length != 0);

        if (VerifyRequired) {
            CcSetDirtyInMask( SharedCacheMap, FileOffset, Length );
        }

        DebugTrace(-1, me, "CcReleaseByteRangeFromWrite -> VOID\n", 0);

        return;
    }

    //
    //  PREfix correctly notes that if the caller gives us a listhead to start with,
    //  we will not have filled in LastOffset by the time we do our first loop test.
    //  For PREfix's benefit (and ours), assert we really are starting with a Bcb.
    //

    ASSERT( FirstBcb->NodeTypeCode == CACHE_NTC_BCB );

    //
    //  Now loop to free up all of the Bcbs.  If modified writing is disabled
    //  for each Bcb, then we are to set it clean here, since we are synchronized
    //  with callers who set the data dirty.  Otherwise we only have the Bcb pinned
    //  so it will not go away, and we only unpin it here.
    //

    do {
        NextBcb = CONTAINING_RECORD( FirstBcb->BcbLinks.Flink, BCB, BcbLinks );

        //
        //  Skip over any listheads.
        //

        if (FirstBcb->NodeTypeCode == CACHE_NTC_BCB) {

            LastOffset = FirstBcb->FileOffset;

            //
            //  If this is file system metadata (we disabled modified writing),
            //  then this is the time to mark the buffer clean, so long as we
            //  did not get verify required.
            //

            if (FlagOn(SharedCacheMap->Flags, MODIFIED_WRITE_DISABLED)) {

                CcUnpinFileData( FirstBcb,
                                 BooleanFlagOn(SharedCacheMap->Flags, DISABLE_WRITE_BEHIND),
                                 SET_CLEAN );
            }

            //
            //  If we got verify required, we have to mark the buffer dirty again
            //  so we will try again later.  Note we have to make this call again
            //  to make sure the right thing happens with time stamps.
            //

            if (VerifyRequired) {
                CcSetDirtyPinnedData( FirstBcb, NULL );
            }

            //
            //  Finally remove a pin count left over from CcAcquireByteRangeForWrite.
            //

            CcUnpinFileData( FirstBcb, TRUE, UNPIN );
        }

        FirstBcb = NextBcb;
    } while (FileOffset->QuadPart != LastOffset.QuadPart);

    DebugTrace(-1, me, "CcReleaseByteRangeFromWrite -> VOID\n", 0);
}


//
//  Internal Support Routine
//

VOID
FASTCALL
CcWriteBehind (
    IN PSHARED_CACHE_MAP SharedCacheMap,
    IN PIO_STATUS_BLOCK IoStatus
    )

/*++

Routine Description:

    This routine may be called with Wait = FALSE to see if write behind
    is required, or with Wait = TRUE to perform write behind as required.

    The code is very similar to the the code that the Lazy Writer performs
    for each SharedCacheMap.  The main difference is in the call to
    CcAcquireByteRangeForWrite.  Write Behind does not care about time
    stamps (passing ULONG to accept all time stamps), but it will never
    dump the first (highest byte offset) buffer in the list if the last
    byte of that buffer is not yet written.  The Lazy Writer does exactly
    the opposite, in the sense that it is totally time-driven, and will
    even dump a partially modified buffer if it sits around long enough.

Arguments:

    SharedCacheMap - Pointer to SharedCacheMap to be written

Return Value:

    FALSE - if write behind is required, but the caller supplied
            Wait = FALSE

    TRUE - if write behind is complete or not required

--*/

{
    KLOCK_QUEUE_HANDLE LockHandle;
    ULONG ActivePage;
    ULONG PageIsDirty;
    PMBCB Mbcb;
    NTSTATUS Status;
    PVACB ActiveVacb = NULL;

    DebugTrace(+1, me, "CcWriteBehind\n", 0 );
    DebugTrace( 0, me, "    SharedCacheMap = %08lx\n", SharedCacheMap );

    //
    //  First we have to acquire the file for LazyWrite, to avoid
    //  deadlocking with writers to the file.  We do this via the
    //  CallBack procedure specified to CcInitializeCacheMap.
    //

    if (!(*SharedCacheMap->Callbacks->AcquireForLazyWrite)
                            ( SharedCacheMap->LazyWriteContext, TRUE )) {

        //
        //  The filesystem is hinting that it doesn't think that it can
        //  service the write without significant delay so we will defer
        //  and come back later.  Simply drop the queued flag ... note that
        //  we do not modify CcPagesYetToWrite, in the hope that we can make
        //  up the difference in some other cache map on this pass.
        //

        CcAcquireMasterLock( &LockHandle.OldIrql );
        ClearFlag(SharedCacheMap->Flags, WRITE_QUEUED);
        CcReleaseMasterLock( LockHandle.OldIrql );

        IoStatus->Status = STATUS_FILE_LOCK_CONFLICT;
        return;
    }

    //
    //  See if there is a previous active page to clean up, but only
    //  do so now if it is the last dirty page or no users have the
    //  file open.  We will free it below after dropping the spinlock.
    //

    KeAcquireInStackQueuedSpinLock( &SharedCacheMap->BcbSpinLock, &LockHandle );
    CcAcquireMasterLockAtDpcLevel();

    if ((SharedCacheMap->DirtyPages <= 1) || (SharedCacheMap->OpenCount == 0)) {
        GetActiveVacbAtDpcLevel( SharedCacheMap, ActiveVacb, ActivePage, PageIsDirty );
    }

    //
    //  Increment open count so that our caller's views stay available
    //  for CcGetVacbMiss.  We could be tying up all of the views, and
    //  still need to write file sizes.
    //

    CcIncrementOpenCount( SharedCacheMap, 'brWS' );

    //
    //  If there is a mask bcb, then we need to establish a target for
    //  it to flush.
    //

    if ((Mbcb = SharedCacheMap->Mbcb) != 0) {

        //
        //  Set a target of pages to write, assuming that any Active
        //  Vacb will increase the number.
        //

        Mbcb->PagesToWrite = Mbcb->DirtyPages + ((ActiveVacb != NULL) ? 1 : 0);

        if (Mbcb->PagesToWrite > CcPagesYetToWrite) {

            Mbcb->PagesToWrite = CcPagesYetToWrite;
        }
    }

    CcReleaseMasterLockFromDpcLevel();
    KeReleaseInStackQueuedSpinLock( &LockHandle );

    //
    //  Now free the active Vacb, if we found one.
    //

    if (ActiveVacb != NULL) {

        CcFreeActiveVacb( SharedCacheMap, ActiveVacb, ActivePage, PageIsDirty );
    }

    //
    //  Now perform the lazy writing for this file via a special call
    //  to CcFlushCache.  He recognizes us by the &CcNoDelay input to
    //  FileOffset, which signifies a Lazy Write, but is subsequently
    //  ignored.
    //

    CcFlushCache( SharedCacheMap->FileObject->SectionObjectPointer,
                  &CcNoDelay,
                  1,
                  IoStatus );

    //
    //  No need for the Lazy Write resource now.
    //

    (*SharedCacheMap->Callbacks->ReleaseFromLazyWrite)
                        ( SharedCacheMap->LazyWriteContext );

    //
    //  Check if we need to put up a popup.
    //

    if (!NT_SUCCESS(IoStatus->Status) && !RetryError(IoStatus->Status)) {

        //
        //  We lost writebehind data.  Bemoan our fate into the system event
        //  log and throw a popup with a meaningful name to the desktop.
        //

        POBJECT_NAME_INFORMATION FileNameInfo = NULL;
        NTSTATUS Status;

        //
        //  Increment the count of how many of these we've had.  This counter
        //  is useful in attempting to discriminate some corruption cases under
        //  test.
        //

        CcLostDelayedWrites += 1;
        
        Status = IoQueryFileDosDeviceName( SharedCacheMap->FileObject, &FileNameInfo );

        if ( Status == STATUS_SUCCESS ) {
            IoRaiseInformationalHardError( STATUS_LOST_WRITEBEHIND_DATA, &FileNameInfo->Name, NULL );

        } else {
            if ( SharedCacheMap->FileObject->FileName.Length &&
                 SharedCacheMap->FileObject->FileName.MaximumLength &&
                 SharedCacheMap->FileObject->FileName.Buffer ) {

                IoRaiseInformationalHardError( STATUS_LOST_WRITEBEHIND_DATA, &SharedCacheMap->FileObject->FileName, NULL );
            }
        }

        CcLogError( SharedCacheMap->FileObject,
                    ( Status == STATUS_SUCCESS ?
                      &FileNameInfo->Name :
                      &SharedCacheMap->FileObject->FileName ),
                    IO_LOST_DELAYED_WRITE,
                    IoStatus->Status,
                    IRP_MJ_WRITE );

        if (FileNameInfo) {
            ExFreePool(FileNameInfo);
        }

    //
    //  See if there is any deferred writes we can post.
    //

    } else if (!IsListEmpty(&CcDeferredWrites)) {
        CcPostDeferredWrites();
    }

    //
    //  Now acquire BcbSpinLock again to check for ValidData updates.
    //

    KeAcquireInStackQueuedSpinLock( &SharedCacheMap->BcbSpinLock, &LockHandle );

    //
    //  If the the current ValidDataGoal is greater (or equal) than ValidDataLength,
    //  then we must see if we have advanced beyond the current ValidDataLength.
    //
    //  If we have NEVER written anything out from this shared cache map, then
    //  there is no need to check anything associtated with valid data length
    //  here.  We will come by here again when, and if, anybody actually
    //  modifies the file and we lazy write some data.
    //

    Status = STATUS_SUCCESS;
    if (FlagOn(SharedCacheMap->Flags, LAZY_WRITE_OCCURRED) &&
        (SharedCacheMap->ValidDataGoal.QuadPart >= SharedCacheMap->ValidDataLength.QuadPart) &&
        (SharedCacheMap->ValidDataLength.QuadPart != MAXLONGLONG) &&
        (SharedCacheMap->FileSize.QuadPart != 0)) {

        LARGE_INTEGER NewValidDataLength;

        NewValidDataLength = CcGetFlushedValidData( SharedCacheMap->FileObject->SectionObjectPointer,
                                                    TRUE );

        //
        //  If New ValidDataLength has been written, then we have to
        //  call the file system back to update it.  We must temporarily
        //  drop our global list while we do this, which is safe to do since
        //  we have not cleared WRITE_QUEUED.
        //
        //  Note we keep calling any time we wrote the last page of the file,
        //  to solve the "famous" AFS Server problem.  The file system will
        //  truncate our valid data call to whatever is currently valid.  But
        //  then if he writes a little more, we do not want to stop calling
        //  back.
        //

        if ( NewValidDataLength.QuadPart >= SharedCacheMap->ValidDataLength.QuadPart ) {

            KeReleaseInStackQueuedSpinLock( &LockHandle );

            //
            //  Call file system to set new valid data.  We have no
            //  one to tell if this doesn't work.
            //

            Status = CcSetValidData( SharedCacheMap->FileObject,
                                     &NewValidDataLength );

            KeAcquireInStackQueuedSpinLock( &SharedCacheMap->BcbSpinLock, &LockHandle );
            if (NT_SUCCESS(Status)) {
                SharedCacheMap->ValidDataLength = NewValidDataLength;
#ifdef TOMM
            } else if ((Status != STATUS_INSUFFICIENT_RESOURCES) && !RetryError(Status)) {
                DbgPrint("Unexpected status from CcSetValidData: %08lx, FileObject: %08lx\n",
                         Status,
                         SharedCacheMap->FileObject);
                DbgBreakPoint();
#endif TOMM
            }
        }
    }

    KeReleaseInStackQueuedSpinLock( &LockHandle );

    //
    //  Show we are done.
    //

    CcAcquireMasterLock( &LockHandle.OldIrql );
    CcDecrementOpenCount( SharedCacheMap, 'brWF' );

    //
    //  Make an approximate guess about whether we will call CcDeleteSharedCacheMap or not
    //  to truncate the file.
    //
    //  Also do not delete the SharedCacheMap if we got an error on the ValidDataLength
    //  callback.  If we get a resource allocation failure or a retryable error (due to
    //  log file full?), we have no one to tell, so we must just loop back and try again.
    //  Of course all I/O errors are just too bad.
    //

    if ((SharedCacheMap->OpenCount == 0)

            &&

        (NT_SUCCESS(Status) || ((Status != STATUS_INSUFFICIENT_RESOURCES) && !RetryError(Status)))) {

        CcReleaseMasterLock( LockHandle.OldIrql );
        FsRtlAcquireFileExclusive( SharedCacheMap->FileObject );
        CcAcquireMasterLock( &LockHandle.OldIrql );

        //
        //  Now really see if we are to delete this SharedCacheMap. By having released
        //  first we avoid a deadlock with the file system when the FileObject is
        //  dereferenced.  Note that CcDeleteSharedCacheMap requires that the
        //  CcMasterSpinLock already be acquired, and it releases it.
        //
        //  Note that we must retest since we dropped and reacquired the master
        //  lock.
        //

        if ((SharedCacheMap->OpenCount == 0)

                &&

            ((SharedCacheMap->DirtyPages == 0) || ((SharedCacheMap->FileSize.QuadPart == 0) &&
                                                   !FlagOn(SharedCacheMap->Flags, PIN_ACCESS)))) {

            //
            //  Make sure to drop the requeue flag in case the write hit the timeout at
            //  the same time it finished everything up.
            //

            CcDeleteSharedCacheMap( SharedCacheMap, LockHandle.OldIrql, TRUE );
            IoStatus->Information = 0;
            SharedCacheMap = NULL;

        } else {

            CcReleaseMasterLock( LockHandle.OldIrql );
            FsRtlReleaseFile( SharedCacheMap->FileObject );
            CcAcquireMasterLock( &LockHandle.OldIrql );
        }
    }

    //
    //  In the normal case, we just clear the flag on the way out if
    //  we will not requeue the workitem.
    //

    if (SharedCacheMap != NULL) {

        if (IoStatus->Information != CC_REQUEUE) {
            ClearFlag(SharedCacheMap->Flags, WRITE_QUEUED);
        }
        CcReleaseMasterLock( LockHandle.OldIrql );
    }

    DebugTrace(-1, me, "CcWriteBehind->VOID\n", 0 );

    return;
}


LARGE_INTEGER
CcGetFlushedValidData (
    IN PSECTION_OBJECT_POINTERS SectionObjectPointer,
    IN BOOLEAN CcInternalCaller
    )

/*++

Routine Description:

    This routine may be called by a file system to find out how far the Cache Manager
    has flushed in the stream.  More accurately, this routine returns either the FileOffset
    of the lowest dirty page currently in the file.

    NOTE that even though the routine takes SectionObjectPointer, the caller must insure
    that the stream is cached and stays cached for the duration of this routine, much like
    for the copy routines, etc.

Arguments:

    SectionObjectPointer - A pointer to the Section Object Pointers
                           structure in the nonpaged Fcb.

    CcInternalCaller - must be TRUE if the caller is coming from Cc, FALSE otherwise.
        TRUE imples the need for self-synchronization.

Return Value:

    The derived number for flushed ValidData, or MAXLONGLONG in the quad part if
    the Section is not cached.  (Naturally the caller can guarantee that this case
    does not occur, and internal callers do.)

--*/

{
    PSHARED_CACHE_MAP SharedCacheMap;
    KLOCK_QUEUE_HANDLE LockHandle;
    LARGE_INTEGER NewValidDataLength;

    //
    //  External callers may be unsynchronized with this shared cache map
    //  perhaps going away underneath this call.  NTFS and his
    //  pair of streams for compression-on-the-wire is a good example of
    //  someone who may be synchronized in one stream but needs to peek at
    //  the other.
    //

    if (!CcInternalCaller) {

        CcAcquireMasterLock( &LockHandle.OldIrql );

        SharedCacheMap = SectionObjectPointer->SharedCacheMap;

        if (SharedCacheMap == NULL) {
            CcReleaseMasterLock( LockHandle.OldIrql );
            NewValidDataLength.QuadPart = MAXLONGLONG;
            return NewValidDataLength;
        }

        CcIncrementOpenCount( SharedCacheMap, 'dfGS' );
        CcReleaseMasterLock( LockHandle.OldIrql );
        KeAcquireInStackQueuedSpinLock( &SharedCacheMap->BcbSpinLock, &LockHandle );

    } else {

        SharedCacheMap = SectionObjectPointer->SharedCacheMap;
    }

    ASSERT( SharedCacheMap != NULL );

    //
    //  If the file is entirely clean, then we wish to return
    //  the new ValidDataLength as equal to ValidDataGoal.
    //

    NewValidDataLength = SharedCacheMap->ValidDataGoal;

    //
    //  If there may be dirty pages we will look at the last Bcb in the
    //  descending-order Bcb list, and see if it describes data beyond
    //  ValidDataGoal.
    //
    //  It is important to note that since we use DirtyPages as a faux
    //  reference count over some short windows (+1, -1) the simple
    //  fact it is nonzero does *not* mean the file is dirty.
    //
    //  (This test is logically too conservative.  For example, the last Bcb
    //  may not even be dirty (in which case we should look at its
    //  predecessor), or we may have earlier written valid data to this
    //  byte range (which also means if we knew this we could look at
    //  the predessor).  This simply means that the Lazy Writer may not
    //  successfully get ValidDataLength updated in a file being randomly
    //  accessed until the level of file access dies down, or at the latest
    //  until the file is closed.  However, security will never be
    //  compromised.)
    //

    if (SharedCacheMap->DirtyPages) {

        PBITMAP_RANGE BitmapRange;
        PBCB LastBcb;
        PMBCB Mbcb = SharedCacheMap->Mbcb;

        if ((Mbcb != NULL) && (Mbcb->DirtyPages != 0)) {

            BitmapRange = CcFindBitmapRangeToClean( Mbcb, 0 );

            ASSERT(BitmapRange->FirstDirtyPage != MAXULONG);

            NewValidDataLength.QuadPart = (BitmapRange->BasePage + BitmapRange->FirstDirtyPage)
                                            << PAGE_SHIFT;
        }

        LastBcb = CONTAINING_RECORD( SharedCacheMap->BcbList.Flink,
                                     BCB,
                                     BcbLinks );

        while (&LastBcb->BcbLinks != &SharedCacheMap->BcbList) {

            if ((LastBcb->NodeTypeCode == CACHE_NTC_BCB) && LastBcb->Dirty) {
                break;
            }

            LastBcb = CONTAINING_RECORD( LastBcb->BcbLinks.Flink,
                                         BCB,
                                         BcbLinks );
        }

        //
        //  Check the Base of the last entry.
        //

        if ((&LastBcb->BcbLinks != &SharedCacheMap->BcbList) &&
            (LastBcb->FileOffset.QuadPart < NewValidDataLength.QuadPart )) {

            NewValidDataLength = LastBcb->FileOffset;
        }
    }

    if (!CcInternalCaller) {

        //
        //  Remove our reference.
        //

        CcAcquireMasterLockAtDpcLevel();
        CcDecrementOpenCount( SharedCacheMap, 'dfGF' );

        if ((SharedCacheMap->OpenCount == 0) &&
            !FlagOn(SharedCacheMap->Flags, WRITE_QUEUED) &&
            (SharedCacheMap->DirtyPages == 0)) {

            //
            //  Move to the dirty list.
            //

            RemoveEntryList( &SharedCacheMap->SharedCacheMapLinks );
            InsertTailList( &CcDirtySharedCacheMapList.SharedCacheMapLinks,
                        &SharedCacheMap->SharedCacheMapLinks );

            //
            //  Make sure the Lazy Writer will wake up, because we
            //  want him to delete this SharedCacheMap.
            //

            LazyWriter.OtherWork = TRUE;
            if (!LazyWriter.ScanActive) {
                CcScheduleLazyWriteScan( FALSE );
            }
        }

        KeReleaseInStackQueuedSpinLockFromDpcLevel( &LockHandle );
        CcReleaseMasterLock( LockHandle.OldIrql );
    }

    return NewValidDataLength;
}


VOID
CcFlushCache (
    IN PSECTION_OBJECT_POINTERS SectionObjectPointer,
    IN PLARGE_INTEGER FileOffset OPTIONAL,
    IN ULONG Length,
    OUT PIO_STATUS_BLOCK IoStatus OPTIONAL
    )

/*++

Routine Description:

    This routine may be called to flush dirty data from the cache to the
    cached file on disk.  Any byte range within the file may be flushed,
    or the entire file may be flushed by omitting the FileOffset parameter.

    This routine does not take a Wait parameter; the caller should assume
    that it will always block.

Arguments:

    SectionObjectPointer - A pointer to the Section Object Pointers
                           structure in the nonpaged Fcb.

    FileOffset - If this parameter is supplied (not NULL), then only the
                 byte range specified by FileOffset and Length are flushed.
                 If &CcNoDelay is specified, then this signifies the call
                 from the Lazy Writer, and the lazy write scan should resume
                 as normal from the last spot where it left off in the file.

    Length - Defines the length of the byte range to flush, starting at
             FileOffset.  This parameter is ignored if FileOffset is
             specified as NULL.

    IoStatus - The I/O status resulting from the flush operation.

Return Value:

    None.

--*/

{
    LARGE_INTEGER NextFileOffset, TargetOffset;
    ULONG NextLength;
    PBCB FirstBcb;
    KIRQL OldIrql;
    PSHARED_CACHE_MAP SharedCacheMap;
    IO_STATUS_BLOCK TrashStatus;
    PVOID TempVa;
    ULONG RemainingLength, TempLength;
    NTSTATUS PopupStatus;
    LOGICAL HotSpot;
    ULONG BytesWritten = 0;
    LOGICAL PopupRequired = FALSE;
    LOGICAL VerifyRequired = FALSE;
    LOGICAL IsLazyWriter = FALSE;
    LOGICAL FreeActiveVacb = FALSE;
    PVACB ActiveVacb = NULL;
    NTSTATUS Status = STATUS_SUCCESS;
    LARGE_INTEGER EndTick, CurrentTick;

    DebugTrace(+1, me, "CcFlushCache:\n", 0 );
    DebugTrace( 0, mm, "    SectionObjectPointer = %08lx\n", SectionObjectPointer );
    DebugTrace2(0, me, "    FileOffset = %08lx, %08lx\n",
                            ARGUMENT_PRESENT(FileOffset) ? FileOffset->LowPart
                                                         : 0,
                            ARGUMENT_PRESENT(FileOffset) ? FileOffset->HighPart
                                                         : 0 );
    DebugTrace( 0, me, "    Length = %08lx\n", Length );

    //
    //  If IoStatus passed a Null pointer, set up to through status away.
    //

    if (!ARGUMENT_PRESENT(IoStatus)) {
        IoStatus = &TrashStatus;
    }
    IoStatus->Status = STATUS_SUCCESS;
    IoStatus->Information = 0;

    //
    //  See if this is the Lazy Writer.  Since he wants to use this common
    //  routine, which is also a public routine callable by file systems,
    //  the Lazy Writer shows his call by specifying CcNoDelay as the file offset!
    //
    //  Also, in case we do not write anything because we see only HotSpot(s),
    //  initialize the Status to indicate a retryable error, so CcWorkerThread
    //  knows we did not make any progress.  Of course any actual flush will
    //  overwrite this code.
    //

    if (FileOffset == &CcNoDelay) {
        IoStatus->Status = STATUS_VERIFY_REQUIRED;
        IsLazyWriter = TRUE;
        FileOffset = NULL;
    }

    CcAcquireMasterLock( &OldIrql );

    SharedCacheMap = SectionObjectPointer->SharedCacheMap;

    //
    //  Awareness is indicated by the lowbit of the FileOffset pointer.
    //  Non-awareness of a private write stream results in a no-op.
    //

    if ((SharedCacheMap != NULL) && FlagOn( SharedCacheMap->Flags, PRIVATE_WRITE )) {

        if (((ULONG_PTR)FileOffset & 1) == 0) {

            CcReleaseMasterLock( OldIrql );
            return;

        }

        FileOffset = (PLARGE_INTEGER)((ULONG_PTR)FileOffset ^ 1);

    }

    //
    //  If there is nothing to do, return here.
    //

    if (ARGUMENT_PRESENT(FileOffset) && (Length == 0)) {

        CcReleaseMasterLock( OldIrql );
        DebugTrace(-1, me, "CcFlushCache -> VOID\n", 0 );
        return;
    }

    //
    //  See if the file is cached.
    //

    if (SharedCacheMap != NULL) {

        //
        //  Increment the open count to keep it from going away.
        //

        CcIncrementOpenCount( SharedCacheMap, 'fcCS' );

        if ((SharedCacheMap->NeedToZero != NULL) || (SharedCacheMap->ActiveVacb != NULL)) {

            ULONG FirstPage = 0;
            ULONG LastPage = MAXULONG;

            if (ARGUMENT_PRESENT(FileOffset)) {

                FirstPage = (ULONG)(FileOffset->QuadPart >> PAGE_SHIFT);
                LastPage = (ULONG)((FileOffset->QuadPart + Length - 1) >> PAGE_SHIFT);
            }

            //
            //  Make sure we do not flush the active page without zeroing any
            //  uninitialized data.  Also, it is very important to free the active
            //  page if it is the one to be flushed, so that we get the dirty
            //  bit out to the Pfn.
            //

            if (((((LONGLONG)LastPage + 1) << PAGE_SHIFT) > SharedCacheMap->ValidDataGoal.QuadPart) ||

                ((SharedCacheMap->NeedToZero != NULL) &&
                 (FirstPage <= SharedCacheMap->NeedToZeroPage) &&
                 (LastPage >= SharedCacheMap->NeedToZeroPage)) ||

                ((SharedCacheMap->ActiveVacb != NULL) &&
                 (FirstPage <= SharedCacheMap->ActivePage) &&
                 (LastPage >= SharedCacheMap->ActivePage))) {

                GetActiveVacbAtDpcLevel( SharedCacheMap, ActiveVacb, RemainingLength, TempLength );
                FreeActiveVacb = TRUE;
            }
        }
    }

    CcReleaseMasterLock( OldIrql );

    if (FreeActiveVacb) {
        CcFreeActiveVacb( SharedCacheMap, ActiveVacb, RemainingLength, TempLength );
    }

    //
    //  If there is a user-mapped file, then we perform the "service" of
    //  flushing even data not written via the file system.  Note that this
    //  is pretty important for folks provoking the flush/purge of a coherency
    //  operation.
    //
    //  It is critical this happen before we examine our own hints.  In the course
    //  of this flush it is possible valid data length will be advanced by the
    //  underlying filesystem, with CcZero'ing behind - which will cause us to
    //  make some dirty zeroes in the cache.  Syscache bug!  Note how coherency
    //  flushing works ...
    //

    if ((SharedCacheMap == NULL)

            ||

        FlagOn(((PFSRTL_COMMON_FCB_HEADER)(SharedCacheMap->FileObject->FsContext))->Flags,
               FSRTL_FLAG_USER_MAPPED_FILE) && !IsLazyWriter) {

        //
        //  Call MM to flush the section through our view.
        //

        DebugTrace( 0, mm, "MmFlushSection:\n", 0 );
        DebugTrace( 0, mm, "    SectionObjectPointer = %08lx\n", SectionObjectPointer );
        DebugTrace2(0, me, "    FileOffset = %08lx, %08lx\n",
                                ARGUMENT_PRESENT(FileOffset) ? FileOffset->LowPart
                                                             : 0,
                                ARGUMENT_PRESENT(FileOffset) ? FileOffset->HighPart
                                                             : 0 );
        DebugTrace( 0, mm, "    RegionSize = %08lx\n", Length );

        Status = MmFlushSection( SectionObjectPointer,
                                 FileOffset,
                                 Length,
                                 IoStatus,
                                 TRUE );

        if ((!NT_SUCCESS(IoStatus->Status)) && !RetryError(IoStatus->Status)) {

            PopupRequired = TRUE;
            PopupStatus = IoStatus->Status;
        }

        DebugTrace2(0, mm, "    <IoStatus = %08lx, %08lx\n",
                    IoStatus->Status, IoStatus->Information );
    }

    //
    //  Scan for dirty pages if there is a shared cache map.
    //

    if (SharedCacheMap != NULL) {

        //
        //  If FileOffset was not specified then set to flush entire region
        //  and set valid data length to the goal so that we will not get
        //  any more call backs.
        //

        if (!IsLazyWriter && !ARGUMENT_PRESENT(FileOffset)) {

            SharedCacheMap->ValidDataLength = SharedCacheMap->ValidDataGoal;
        }

        //
        //  If this is an explicit flush, initialize our offset to scan for.
        //

        if (ARGUMENT_PRESENT(FileOffset)) {
            TargetOffset = *FileOffset;
        }

        //
        //  Assume we want to pass the explicit flush flag in Length.
        //  But overwrite it if a length really was specified.  On
        //  subsequent loops, NextLength will have some nonzero value.
        //

        NextLength = 1;
        if (Length != 0) {
            NextLength = Length;
        }

        //
        //  Now calculate the tick that will signal the expiration of a
        //  lazy writer tick interval.
        //

        if (IsLazyWriter) {

            KeQueryTickCount( &EndTick );
            EndTick.QuadPart += CcIdleDelayTick;
        }

        //
        //  Loop as long as we find buffers to flush for this
        //  SharedCacheMap, and we are not trying to delete the guy.
        //

        while (((SharedCacheMap->PagesToWrite != 0) || !IsLazyWriter)

                    &&
               ((SharedCacheMap->FileSize.QuadPart != 0) ||
                FlagOn(SharedCacheMap->Flags, PIN_ACCESS))

                    &&

               !VerifyRequired

                    &&

               CcAcquireByteRangeForWrite ( SharedCacheMap,
                                            IsLazyWriter ? NULL : (ARGUMENT_PRESENT(FileOffset) ?
                                                                    &TargetOffset : NULL),
                                            IsLazyWriter ? 0: NextLength,
                                            &NextFileOffset,
                                            &NextLength,
                                            &FirstBcb )) {

            //
            //  Assume this range is not a hot spot.
            //

            HotSpot = FALSE;

            //
            //  We defer calling Mm to set address range modified until here, to take
            //  overhead out of the main line path, and to reduce the number of TBIS
            //  on a multiprocessor.
            //

            RemainingLength = NextLength;

            do {

                //
                //  See if the next file offset is mapped.  (If not, the dirty bit
                //  was propagated on the unmap.)
                //

                if ((TempVa = CcGetVirtualAddressIfMapped( SharedCacheMap,
                                                           NextFileOffset.QuadPart + NextLength - RemainingLength,
                                                           &ActiveVacb,
                                                           &TempLength)) != NULL) {

                    //
                    //  Reduce TempLength to RemainingLength if necessary, and
                    //  call MM.
                    //

                    if (TempLength > RemainingLength) {
                        TempLength = RemainingLength;
                    }

                    //
                    //  Clear the Dirty bit (if set) in the PTE and set the
                    //  Pfn modified.  Assume if the Pte was dirty, that this may
                    //  be a hot spot.  Do not do hot spots for metadata, and unless
                    //  they are within ValidDataLength as reported to the file system
                    //  via CcSetValidData.
                    //

                    HotSpot = (BOOLEAN)(((MmSetAddressRangeModified(TempVa, TempLength) || HotSpot) &&
                                         ((NextFileOffset.QuadPart + NextLength) <
                                          (SharedCacheMap->ValidDataLength.QuadPart)) &&
                                         ((SharedCacheMap->LazyWritePassCount & 0xF) != 0) &&
                                         IsLazyWriter) &&
                                        !FlagOn(SharedCacheMap->Flags, MODIFIED_WRITE_DISABLED));

                    CcFreeVirtualAddress( ActiveVacb );

                } else {

                    //
                    //  Reduce TempLength to RemainingLength if necessary.
                    //

                    if (TempLength > RemainingLength) {
                        TempLength = RemainingLength;
                    }
                }

                //
                //  Reduce RemainingLength by what we processed.
                //

                RemainingLength -= TempLength;

            //
            //  Loop until done.
            //

            } while (RemainingLength != 0);

            CcLazyWriteHotSpots += HotSpot;

            //
            //  Now flush, now flush if we do not think it is a hot spot.
            //

            if (!HotSpot) {

                MmFlushSection( SharedCacheMap->FileObject->SectionObjectPointer,
                                &NextFileOffset,
                                NextLength,
                                IoStatus,
                                !IsLazyWriter );

                if (NT_SUCCESS(IoStatus->Status)) {

                    if (!FlagOn(SharedCacheMap->Flags, LAZY_WRITE_OCCURRED)) {

                        CcAcquireMasterLock( &OldIrql );
                        SetFlag(SharedCacheMap->Flags, LAZY_WRITE_OCCURRED);
                        CcReleaseMasterLock( OldIrql );
                    }

                    //
                    //  Increment performance counters
                    //

                    if (IsLazyWriter) {

                        CcLazyWriteIos += 1;
                        CcLazyWritePages += (NextLength + PAGE_SIZE - 1) >> PAGE_SHIFT;
                    }

                } else {

                    LARGE_INTEGER Offset = NextFileOffset;
                    ULONG RetryLength = NextLength;

                    DebugTrace2( 0, 0, "I/O Error on Cache Flush: %08lx, %08lx\n",
                                 IoStatus->Status, IoStatus->Information );

                    if (RetryError(IoStatus->Status)) {

                        VerifyRequired = TRUE;

                    //
                    //  Loop to write each page individually, starting with one
                    //  more try on the page that got the error, in case that page
                    //  or any page beyond it can be successfully written
                    //  individually.  Note that Offset and RetryLength are
                    //  guaranteed to be in integral pages, but the Information
                    //  field from the failed request is not.
                    //
                    //  We ignore errors now, and give it one last shot, before
                    //  setting the pages clean (see below).
                    //

                    } else {

                        do {

                            DebugTrace2( 0, 0, "Trying page at offset %08lx, %08lx\n",
                                         Offset.LowPart, Offset.HighPart );

                            MmFlushSection ( SharedCacheMap->FileObject->SectionObjectPointer,
                                             &Offset,
                                             PAGE_SIZE,
                                             IoStatus,
                                             !IsLazyWriter );

                            DebugTrace2( 0, 0, "I/O status = %08lx, %08lx\n",
                                         IoStatus->Status, IoStatus->Information );

                            if (NT_SUCCESS(IoStatus->Status)) {
                                CcAcquireMasterLock( &OldIrql );
                                SetFlag(SharedCacheMap->Flags, LAZY_WRITE_OCCURRED);
                                CcReleaseMasterLock( OldIrql );
                            }

                            if ((!NT_SUCCESS(IoStatus->Status)) && !RetryError(IoStatus->Status)) {

                                PopupRequired = TRUE;
                                PopupStatus = IoStatus->Status;
                            }

                            VerifyRequired = VerifyRequired || RetryError(IoStatus->Status);

                            Offset.QuadPart = Offset.QuadPart + (LONGLONG)PAGE_SIZE;
                            RetryLength -= PAGE_SIZE;

                        } while(RetryLength > 0);
                    }
                }
            }

            //
            //  Now release the Bcb resources and set them clean.  Note we do not check
            //  here for errors, and just returned in the I/O status.  Errors on writes
            //  are rare to begin with.  Nonetheless, our strategy is to rely on
            //  one or more of the following (depending on the file system) to prevent
            //  errors from getting to us.
            //
            //      - Retries and/or other forms of error recovery in the disk driver
            //      - Mirroring driver
            //      - Hot fixing in the noncached path of the file system
            //
            //  In the unexpected case that a write error does get through, we
            //  *currently* just set the Bcbs clean anyway, rather than let
            //  Bcbs and pages accumulate which cannot be written.  Note we did
            //  a popup above to at least notify the guy.
            //
            //  Set the pages dirty again if we either saw a HotSpot or got
            //  verify required.
            //

            CcReleaseByteRangeFromWrite ( SharedCacheMap,
                                          &NextFileOffset,
                                          NextLength,
                                          FirstBcb,
                                          (BOOLEAN)(HotSpot || VerifyRequired) );

            //
            //  See if there is any deferred writes we should post.
            //

            BytesWritten += NextLength;
            if ((BytesWritten >= 0x40000) && !IsListEmpty(&CcDeferredWrites)) {
                CcPostDeferredWrites();
                BytesWritten = 0;
            }

            //
            //  If we're the lazy writer and have spent more than the active tick
            //  length in this loop, break out for a requeue so we share the
            //  file resources.
            //

            if (IsLazyWriter) {

                KeQueryTickCount( &CurrentTick );

                if (CurrentTick.QuadPart > EndTick.QuadPart) {
                    IoStatus->Information = CC_REQUEUE;
                    break;
                }
            }

            //
            //  Now for explicit flushes, we should advance our range.
            //

            if (ARGUMENT_PRESENT(FileOffset)) {

                NextFileOffset.QuadPart += NextLength;

                //
                //  Done yet?
                //

                if ((FileOffset->QuadPart + Length) <= NextFileOffset.QuadPart) {
                    break;
                }

                //
                //  Calculate new target range
                //

                NextLength = (ULONG)((FileOffset->QuadPart + Length) - NextFileOffset.QuadPart);
                TargetOffset = NextFileOffset;
            }
        }
    }

    //
    //  See if there are any deferred writes we should post if
    //  we escaped the loop without checking after a series of
    //  flushes.
    //

    if (BytesWritten != 0 && !IsListEmpty(&CcDeferredWrites)) {

        CcPostDeferredWrites();
    }

    //
    //  Now we can get rid of the open count, and clean up as required.
    //

    if (SharedCacheMap != NULL) {

        //
        //  Serialize again to decrement the open count.
        //

        CcAcquireMasterLock( &OldIrql );

        CcDecrementOpenCount( SharedCacheMap, 'fcCF' );

        if ((SharedCacheMap->OpenCount == 0) &&
            !FlagOn(SharedCacheMap->Flags, WRITE_QUEUED) &&
            (SharedCacheMap->DirtyPages == 0)) {

            //
            //  Move to the dirty list.
            //

            RemoveEntryList( &SharedCacheMap->SharedCacheMapLinks );
            InsertTailList( &CcDirtySharedCacheMapList.SharedCacheMapLinks,
                            &SharedCacheMap->SharedCacheMapLinks );

            //
            //  Make sure the Lazy Writer will wake up, because we
            //  want him to delete this SharedCacheMap.
            //

            LazyWriter.OtherWork = TRUE;
            if (!LazyWriter.ScanActive) {
                CcScheduleLazyWriteScan( FALSE );
            }
        }

        CcReleaseMasterLock( OldIrql );
    }

    //
    //  Make sure and return the first error to our caller.  In the
    //  case of the Lazy Writer, a popup will be issued.
    //

    if (PopupRequired) {
        IoStatus->Status = PopupStatus;
    }

    DebugTrace(-1, me, "CcFlushCache -> VOID\n", 0 );

    return;
}


PVOID
CcRemapBcb (
    IN PVOID Bcb
    )

/*++

Routine Description:

    This routine may be called by a file system to map a Bcb an additional
    time in order to preserve it through several calls that perform additional
    maps and unpins.


Arguments:

    Bcb - Supplies a pointer to a previously returned Bcb.

Return Value:

    Bcb with read-only indicator.

--*/

{
    KIRQL OldIrql;
    PVACB Vacb;

    //
    //  Remove read-only bit
    //

    Bcb = (PVOID) ((ULONG_PTR)Bcb & ~1);

    if (((PBCB)Bcb)->NodeTypeCode == CACHE_NTC_OBCB) {

        //
        //  If this is an overlapped BCB, use the first Vacb in the
        //  array
        //

        Vacb = ((POBCB)Bcb)->Bcbs[0]->Vacb;

    } else if (((PBCB)Bcb)->NodeTypeCode == CACHE_NTC_BCB) {

        //
        //  If this is a BCB, extract the Vcb from it
        //

        Vacb = ((PBCB)Bcb)->Vacb;

    } else {

        //
        //  Otherwise, there is no signature to match. Assume
        //  it is a Vacb.
        //

        Vacb = (PVACB) Bcb;
    }

    ASSERT((Vacb >= CcVacbs) && (Vacb < CcBeyondVacbs));

    //
    //  Safely bump the active count
    //

    CcAcquireVacbLock( &OldIrql );

    Vacb->Overlay.ActiveCount += 1;

    CcReleaseVacbLock( OldIrql );

    return (PVOID) ((ULONG_PTR)Vacb | 1);
}


VOID
CcRepinBcb (
    IN PVOID Bcb
    )

/*++

Routine Description:

    This routine may be called by a file system to pin a Bcb an additional
    time in order to reserve it for Write Through or error recovery.
    Typically the file system would do this the first time that it sets a
    pinned buffer dirty while processing a WriteThrough request, or any
    time that it determines that a buffer will be required for WriteThrough.

    The call to this routine must be followed by a call to CcUnpinRepinnedBcb.
    CcUnpinRepinnedBcb should normally be called during request completion
    after all other resources have been released.  CcUnpinRepinnedBcb
    synchronously writes the buffer (for WriteThrough requests) and performs
    the matching unpin for this call.

Arguments:

    Bcb - Supplies a pointer to a previously pinned Bcb

Return Value:

    None.

--*/

{
    KLOCK_QUEUE_HANDLE LockHandle;

    KeAcquireInStackQueuedSpinLock( &((PBCB)Bcb)->SharedCacheMap->BcbSpinLock, &LockHandle );

    ((PBCB)Bcb)->PinCount += 1;

    KeReleaseInStackQueuedSpinLock( &LockHandle );
}


VOID
CcUnpinRepinnedBcb (
    IN PVOID Bcb,
    IN BOOLEAN WriteThrough,
    OUT PIO_STATUS_BLOCK IoStatus
    )

/*++

Routine Description:

    This routine may be called to Write a previously pinned buffer
    through to the file.  It must have been preceded by a call to
    CcRepinBcb.  As this routine must acquire the Bcb
    resource exclusive, the caller must be extremely careful to avoid
    deadlocks.  Ideally the caller owns no resources at all when it
    calls this routine, or else the caller should guarantee that it
    has nothing else pinned in this same file.  (The latter rule is
    the one used to avoid deadlocks in calls from CcCopyWrite and
    CcMdlWrite.)

Arguments:

    Bcb - Pointer to a Bcb which was previously specified in a call
          to CcRepinBcb.

    WriteThrough - TRUE if the Bcb should be written through.

    IoStatus - Returns the I/O status for the operation.

Return Value:

    None.

--*/

{
    PSHARED_CACHE_MAP SharedCacheMap = ((PBCB)Bcb)->SharedCacheMap;

    DebugTrace(+1, me, "CcUnpinRepinnedBcb\n", 0 );
    DebugTrace( 0, me, "    Bcb = %08lx\n", Bcb );
    DebugTrace( 0, me, "    WriteThrough = %02lx\n", WriteThrough );

    //
    //  Set status to success for non write through case.
    //

    IoStatus->Status = STATUS_SUCCESS;

    if (WriteThrough) {

        //
        //  Acquire Bcb exclusive to eliminate possible modifiers of the buffer,
        //  since we are about to write its buffer.
        //

        if (FlagOn(SharedCacheMap->Flags, MODIFIED_WRITE_DISABLED)) {
            ExAcquireResourceExclusiveLite( &((PBCB)Bcb)->Resource, TRUE );
        }

        //
        //  Now, there is a chance that the LazyWriter has already written
        //  it, since the resource was free.  We will only write it if it
        //  is still dirty.
        //

        if (((PBCB)Bcb)->Dirty) {

            //
            //  First we make sure that the dirty bit in the PFN database is set.
            //

            ASSERT( ((PBCB)Bcb)->BaseAddress != NULL );
            MmSetAddressRangeModified( ((PBCB)Bcb)->BaseAddress,
                                       ((PBCB)Bcb)->ByteLength );

            //
            //  Now release the Bcb resource and set it clean.  Note we do not check
            //  here for errors, and just return the I/O status.  Errors on writes
            //  are rare to begin with.  Nonetheless, our strategy is to rely on
            //  one or more of the following (depending on the file system) to prevent
            //  errors from getting to us.
            //
            //      - Retries and/or other forms of error recovery in the disk driver
            //      - Mirroring driver
            //      - Hot fixing in the noncached path of the file system
            //
            //  In the unexpected case that a write error does get through, we
            //  report it to our caller, but go ahead and set the Bcb clean.  There
            //  seems to be no point in letting Bcbs (and pages in physical memory)
            //  accumulate which can never go away because we get an unrecoverable I/O
            //  error.
            //

            //
            //  We specify TRUE here for ReadOnly so that we will keep the
            //  resource during the flush.
            //

            CcUnpinFileData( (PBCB)Bcb, TRUE, SET_CLEAN );

            //
            //  Write it out.
            //

            MmFlushSection( ((PBCB)Bcb)->SharedCacheMap->FileObject->SectionObjectPointer,
                            &((PBCB)Bcb)->FileOffset,
                            ((PBCB)Bcb)->ByteLength,
                            IoStatus,
                            TRUE );

            //
            //  If we got verify required, we have to mark the buffer dirty again
            //  so we will try again later.
            //

            if (RetryError(IoStatus->Status)) {
                CcSetDirtyPinnedData( (PBCB)Bcb, NULL );
            }

            //
            //  Now remove the final pin count now that we have set it clean.
            //

            CcUnpinFileData( (PBCB)Bcb, FALSE, UNPIN );

            //
            //  See if there is any deferred writes we can post.
            //

            if (!IsListEmpty(&CcDeferredWrites)) {
                CcPostDeferredWrites();
            }
        }
        else {

            //
            //  Lazy Writer got there first, just free the resource and unpin.
            //

            CcUnpinFileData( (PBCB)Bcb, FALSE, UNPIN );

        }

        DebugTrace2(0, me, "    <IoStatus = %08lx, %08lx\n", IoStatus->Status,
                                                             IoStatus->Information );
    }

    //
    //  Non-WriteThrough case
    //

    else {

        CcUnpinFileData( (PBCB)Bcb, TRUE, UNPIN );

        //
        //  Set status to success for non write through case.
        //

        IoStatus->Status = STATUS_SUCCESS;
    }

    DebugTrace(-1, me, "CcUnpinRepinnedBcb -> VOID\n", 0 );
}


//
//  Internal Support Routine
//

BOOLEAN
CcFindBcb (
    IN PSHARED_CACHE_MAP SharedCacheMap,
    IN PLARGE_INTEGER FileOffset,
    IN OUT PLARGE_INTEGER BeyondLastByte,
    OUT PBCB *Bcb
    )

/*++

Routine Description:

    This routine is called to find a Bcb describing the specified byte range
    of a file.  It returns TRUE if it could at least find a Bcb which describes
    the beginning of the specified byte range, or else FALSE if the first
    part of the byte range is not present.  In the latter case, the requested
    byte range (TrialLength) is truncated if there is currently a Bcb which
    describes bytes beyond the beginning of the byte range.

    The caller may see if the entire byte range is being returned by examining
    the Bcb, and the caller (or caller's caller) may then make subsequent
    calls if the data is not all returned.

    The BcbSpinLock must be currently acquired.

Arguments:

    SharedCacheMap - Supplies a pointer to the SharedCacheMap for the file
                     in which the byte range is desired.

    FileOffset - Supplies the file offset for the beginning of the desired
                 byte range.

    BeyondLastByte - Supplies the file offset of the ending of the desired
                  byte range + 1.  Note that this offset will be truncated
                  on return if the Bcb was not found, but bytes beyond the
                  beginning of the Bcb are contained in another Bcb.

    Bcb - returns a Bcb describing the beginning of the byte range if also
          returning TRUE, or else the point in the Bcb list to insert after.

Return Value:

    FALSE - if no Bcb describes the beginning of the desired byte range

    TRUE - if a Bcb is being returned describing at least an initial
           part of the byte range.

--*/

{
    PLIST_ENTRY BcbList;
    PBCB Bcbt;
    BOOLEAN Found = FALSE;

    DebugTrace(+1, me, "CcFindBcb:\n", 0 );
    DebugTrace( 0, me, "    SharedCacheMap = %08lx\n", SharedCacheMap );
    DebugTrace2(0, me, "    FileOffset = %08lx, %08lx\n", FileOffset->LowPart,
                                                          FileOffset->HighPart );
    DebugTrace2(0, me, "    TrialLength = %08lx, %08lx\n", TrialLength->LowPart,
                                                           TrialLength->HighPart );

    //
    //  We want to terminate scans by testing the NodeTypeCode field from the
    //  BcbLinks, so we want to see the SharedCacheMap signature from the same
    //  offset.
    //

    ASSERT(FIELD_OFFSET(SHARED_CACHE_MAP, BcbList) == FIELD_OFFSET(BCB, BcbLinks));

    //
    //  Similarly, when we hit one of the BcbListHeads in the array, small negative
    //  offsets are all structure pointers, so we are counting on the Bcb signature
    //  to have some non-Ulong address bits set.
    //

    ASSERT((CACHE_NTC_BCB & 3) != 0);

    //
    //  Get address of Bcb listhead that is *after* the Bcb we are looking for,
    //  for backwards scan.  It is important that we fail in the forward
    //  direction so that we are looking in the right segment of the Bcb list.
    //

    BcbList = GetBcbListHead( SharedCacheMap, FileOffset->QuadPart + SIZE_PER_BCB_LIST, TRUE );

    //
    //  Search for an entry that overlaps the specified range, or until we hit
    //  a listhead.
    //

    Bcbt = CONTAINING_RECORD(BcbList->Flink, BCB, BcbLinks);

    //
    //  First see if we really have to do Large arithmetic or not, and
    //  then use either a 32-bit loop or a 64-bit loop to search for
    //  the Bcb.
    //

    if (FileOffset->HighPart == 0 &&
        Bcbt->NodeTypeCode == CACHE_NTC_BCB &&
        Bcbt->BeyondLastByte.HighPart == 0) {

        //
        //  32-bit - loop until we get back to a listhead.
        //

        while (Bcbt->NodeTypeCode == CACHE_NTC_BCB) {

            //
            //  Since the Bcb list is in descending order, we first check
            //  if we are completely beyond the current entry, and if so
            //  get out.
            //

            if (FileOffset->LowPart >= Bcbt->BeyondLastByte.LowPart) {
                break;
            }

            //
            //  Next check if the first byte we are looking for is
            //  contained in the current Bcb.  If so, we either have
            //  a partial hit and must truncate to the exact amount
            //  we have found, or we may have a complete hit.  In
            //  either case we break with Found == TRUE.
            //

            if (FileOffset->LowPart >= Bcbt->FileOffset.LowPart) {
                Found = TRUE;
                break;
            }

            //
            //  Now we know we must loop back and keep looking, but we
            //  still must check for the case where the tail end of the
            //  bytes we are looking for are described by the current
            //  Bcb.  If so we must truncate what we are looking for,
            //  because this routine is only supposed to return bytes
            //  from the start of the desired range.
            //

            if (BeyondLastByte->LowPart >= Bcbt->FileOffset.LowPart) {
                BeyondLastByte->LowPart = Bcbt->FileOffset.LowPart;
            }

            //
            //  Advance to next entry in list (which is possibly back to
            //  the listhead) and loop back.
            //

            Bcbt = CONTAINING_RECORD( Bcbt->BcbLinks.Flink,
                                      BCB,
                                      BcbLinks );

        }

    } else {

        //
        //  64-bit - Loop until we get back to a listhead.
        //

        while (Bcbt->NodeTypeCode == CACHE_NTC_BCB) {

            //
            //  Since the Bcb list is in descending order, we first check
            //  if we are completely beyond the current entry, and if so
            //  get out.
            //

            if (FileOffset->QuadPart >= Bcbt->BeyondLastByte.QuadPart) {
                break;
            }

            //
            //  Next check if the first byte we are looking for is
            //  contained in the current Bcb.  If so, we either have
            //  a partial hit and must truncate to the exact amount
            //  we have found, or we may have a complete hit.  In
            //  either case we break with Found == TRUE.
            //

            if (FileOffset->QuadPart >= Bcbt->FileOffset.QuadPart) {
                Found = TRUE;
                break;
            }

            //
            //  Now we know we must loop back and keep looking, but we
            //  still must check for the case where the tail end of the
            //  bytes we are looking for are described by the current
            //  Bcb.  If so we must truncate what we are looking for,
            //  because this routine is only supposed to return bytes
            //  from the start of the desired range.
            //

            if (BeyondLastByte->QuadPart >= Bcbt->FileOffset.QuadPart) {
                BeyondLastByte->QuadPart = Bcbt->FileOffset.QuadPart;
            }

            //
            //  Advance to next entry in list (which is possibly back to
            //  the listhead) and loop back.
            //

            Bcbt = CONTAINING_RECORD( Bcbt->BcbLinks.Flink,
                                      BCB,
                                      BcbLinks );

        }
    }

    *Bcb = Bcbt;

    DebugTrace2(0, me, "    <TrialLength = %08lx, %08lx\n", TrialLength->LowPart,
                                                            TrialLength->HighPart );
    DebugTrace( 0, me, "    <Bcb = %08lx\n", *Bcb );
    DebugTrace(-1, me, "CcFindBcb -> %02lx\n", Found );

    return Found;
}


//
//  Internal Support Routine
//

PBCB
CcAllocateInitializeBcb (
    IN OUT PSHARED_CACHE_MAP SharedCacheMap OPTIONAL,
    IN OUT PBCB AfterBcb,
    IN PLARGE_INTEGER FileOffset,
    IN PLARGE_INTEGER TrialLength
    )

/*++

Routine Description:

    This routine allocates and initializes a Bcb to describe the specified
    byte range, and inserts it into the Bcb List of the specified Shared
    Cache Map.  The Bcb List spin lock must currently be acquired.

    BcbSpinLock must be acquired on entry.

Arguments:

    SharedCacheMap - Supplies the SharedCacheMap for the new Bcb.

    AfterBcb - Supplies where in the descending-order BcbList the new Bcb
               should be inserted: either the ListHead (masquerading as
               a Bcb) or a Bcb.

    FileOffset - Supplies File Offset for the desired data.

    TrialLength - Supplies length of desired data.

Return Value:

    Address of the allocated and initialized Bcb

--*/

{
    PBCB Bcb;
    ULONG RoundedBcbSize = (sizeof(BCB) + 7) & ~7;

    if ((Bcb = ExAllocatePoolWithTag( NonPagedPool, sizeof(BCB), 'cBcC')) == NULL) {
        
        return NULL;
    }

    //
    //  Initialize the newly allocated Bcb.  First zero it, then fill in
    //  nonzero fields.
    //

    RtlZeroMemory( Bcb, RoundedBcbSize );

    //
    //  For Mbcb's, SharedCacheMap is NULL, and the rest of this initialization
    //  is not desired.
    //

    if (SharedCacheMap != NULL) {

        Bcb->NodeTypeCode = CACHE_NTC_BCB;
        Bcb->FileOffset = *FileOffset;
        Bcb->ByteLength = TrialLength->LowPart;
        Bcb->BeyondLastByte.QuadPart = FileOffset->QuadPart + TrialLength->QuadPart;
        Bcb->PinCount += 1;
        ExInitializeResourceLite( &Bcb->Resource );
        Bcb->SharedCacheMap = SharedCacheMap;

        //
        //  Since CcCalculateVacbLockCount has to be able to walk
        //  the BcbList with only the VacbSpinLock, we take that one
        //  out to change the list and set the count.
        //

        CcAcquireVacbLockAtDpcLevel();
        InsertTailList( &AfterBcb->BcbLinks, &Bcb->BcbLinks );

        ASSERT( (SharedCacheMap->SectionSize.QuadPart < VACB_SIZE_OF_FIRST_LEVEL) ||
                (CcFindBcb(SharedCacheMap, FileOffset, &Bcb->BeyondLastByte, &AfterBcb) &&
                 (Bcb == AfterBcb)) );

        //
        //  Now for large metadata streams we lock the Vacb level.
        //

        CcLockVacbLevel( SharedCacheMap, FileOffset->QuadPart );
        CcReleaseVacbLockFromDpcLevel();

        //
        //  If this resource was no write behind, let Ex know that the
        //  resource will never be acquired exclusive.  Also disable
        //  boost (I know this is useless, but KenR said I had to do it).
        //

        if (SharedCacheMap &&
            FlagOn(SharedCacheMap->Flags, DISABLE_WRITE_BEHIND)) {
#if DBG
            SetFlag(Bcb->Resource.Flag, ResourceNeverExclusive);
#endif
            ExDisableResourceBoost( &Bcb->Resource );
        }
    }

    return Bcb;
}


//
//  Internal support routine
//

VOID
FASTCALL
CcDeallocateBcb (
    IN PBCB Bcb
    )

/*++

Routine Description:

    This routine deallocates a Bcb to the BcbZone.  It must
    already be removed from the BcbList.

Arguments:

    Bcb - the Bcb to deallocate

Return Value:

    None

--*/

{
    //
    //  Deallocate Resource structures
    //

    if (Bcb->NodeTypeCode == CACHE_NTC_BCB) {

        ExDeleteResourceLite( &Bcb->Resource );
    }

    ExFreePool(Bcb);
    return;
}


//
//  Internal Support Routine
//

BOOLEAN
CcMapAndRead(
    IN PSHARED_CACHE_MAP SharedCacheMap,
    IN PLARGE_INTEGER FileOffset,
    IN ULONG Length,
    IN ULONG ZeroFlags,
    IN BOOLEAN Wait,
    IN PVOID BaseAddress
    )

/*++

Routine Description:

    This routine may be called to insure that the specified data is mapped,
    read into memory and locked.  If TRUE is returned, then the
    correct I/O status for the transfer is also returned, along with
    a system-space address for the data.

Arguments:

    SharedCacheMap - Supplies the address of the SharedCacheMap for the
                     data.

    FileOffset - Supplies the file offset of the desired data.

    Length - Supplies the total amount of data desired.

    ZeroFlags - Defines which pages may be zeroed if not resident.

    Wait - Supplies FALSE if the caller is not willing to block for the
           data, or TRUE if the caller is willing to block.

    BaseAddress - Supplies the system base address at which the data may
                  be accessed.

Return Value:

    FALSE - if the caller supplied Wait = FALSE and the data could not
            be returned without blocking.

    TRUE - if the data is being returned.

    Note: this routine may raise an exception due to a map or read failure,
          however, this can only happen if Wait was specified as TRUE, since
          mapping and reading will not be performed if the caller cannot wait.

--*/

{
    ULONG ZeroCase;
    ULONG SavedState;
    BOOLEAN Result = FALSE;
    PETHREAD Thread = PsGetCurrentThread();

    UNREFERENCED_PARAMETER (SharedCacheMap);
    UNREFERENCED_PARAMETER (FileOffset);

    MmSavePageFaultReadAhead( Thread, &SavedState );

    //
    //  try around everything for cleanup.
    //

    try {

        ULONG PagesToGo;

        //
        //  Now loop to touch all of the pages, calling MM to insure
        //  that if we fault, we take in exactly the number of pages
        //  we need.
        //

        PagesToGo = ADDRESS_AND_SIZE_TO_SPAN_PAGES( BaseAddress, Length );

        //
        //  Loop to touch or zero the pages.
        //

        ZeroCase = ZERO_FIRST_PAGE;

        while (PagesToGo) {

            //
            //  If we cannot zero this page, or Mm failed to return
            //  a zeroed page, then just fault it in.
            //

            MmSetPageFaultReadAhead( Thread, (PagesToGo - 1) );

            if (!FlagOn(ZeroFlags, ZeroCase) ||
                !MmCheckCachedPageState(BaseAddress, TRUE)) {

                //
                //  If we get here, it is almost certainly due to the fact
                //  that we can not take a zero page.  MmCheckCachedPageState
                //  will so rarely return FALSE, that we will not worry
                //  about it.  We will only check if the page is there if
                //  Wait is FALSE, so that we can do the right thing.
                //

                if (!MmCheckCachedPageState(BaseAddress, FALSE) && !Wait) {
                    try_return( Result = FALSE );
                }
            }

            BaseAddress = (PCHAR)BaseAddress + PAGE_SIZE;
            PagesToGo -= 1;

            if (PagesToGo == 1) {
                ZeroCase = ZERO_LAST_PAGE;
            } else {
                ZeroCase = ZERO_MIDDLE_PAGES;
            }
        }

        try_return( Result = TRUE );

    try_exit: NOTHING;
    }

    //
    //  Cleanup on the way out.
    //

    finally {

        MmResetPageFaultReadAhead(Thread, SavedState);
    }

    return Result;
}


//
//  Internal Support Routine
//

VOID
CcFreeActiveVacb (
    IN PSHARED_CACHE_MAP SharedCacheMap,
    IN PVACB ActiveVacb OPTIONAL,
    IN ULONG ActivePage,
    IN ULONG PageIsDirty
    )

/*++

Routine Description:

    This routine may be called to zero the end of a locked page or
    free the ActiveVacb for a Shared Cache Map, if there is one.
    Note that some callers are not synchronized with foreground
    activity, and may therefore not have an ActiveVacb.  Examples
    of unsynchronized callers are CcZeroEndOfLastPage (which is
    called by MM) and any flushing done by CcWriteBehind.

Arguments:

    SharedCacheMap - SharedCacheMap to examine for page to be zeroed.

    ActiveVacb - Vacb to free

    ActivePage - Page that was used

    PageIsDirty - ACTIVE_PAGE_IS_DIRTY if the active page is dirty

Return Value:

    None

--*/

{
    LARGE_INTEGER ActiveOffset;
    PVOID ActiveAddress;
    ULONG BytesLeftInPage;
    KIRQL OldIrql;

    //
    //  If the page was locked, then unlock it.
    //

    if (SharedCacheMap->NeedToZero != NULL) {

        PVACB NeedToZeroVacb;

        //
        //  Zero the rest of the page under spinlock control,
        //  and then clear the address field.  This field makes
        //  zero->nonzero transitions only when the file is exclusive,
        //  but it can make nonzero->zero transitions any time the
        //  spinlock is not held.
        //

        ExAcquireFastLock( &SharedCacheMap->ActiveVacbSpinLock, &OldIrql );

        //
        //  The address could already be gone.
        //

        ActiveAddress = SharedCacheMap->NeedToZero;
        if (ActiveAddress != NULL) {

            BytesLeftInPage = PAGE_SIZE - ((((ULONG)((ULONG_PTR)ActiveAddress) - 1) & (PAGE_SIZE - 1)) + 1);

            RtlZeroBytes( ActiveAddress, BytesLeftInPage );
            NeedToZeroVacb = SharedCacheMap->NeedToZeroVacb;
            ASSERT( NeedToZeroVacb != NULL );
            SharedCacheMap->NeedToZero = NULL;

        }
        ExReleaseFastLock( &SharedCacheMap->ActiveVacbSpinLock, OldIrql );

        //
        //  Now call MM to unlock the address.  Note we will never store the
        //  address at the start of the page, but we can sometimes store
        //  the start of the next page when we have exactly filled the page.
        //

        if (ActiveAddress != NULL) {
            MmUnlockCachedPage( (PVOID)((PCHAR)ActiveAddress - 1) );
            CcFreeVirtualAddress( NeedToZeroVacb );
        }
    }

    //
    //  See if caller actually has an ActiveVacb
    //

    if (ActiveVacb != NULL) {

        //
        //  See if the page is dirty
        //

        if (PageIsDirty) {

            ActiveOffset.QuadPart = (LONGLONG)ActivePage << PAGE_SHIFT;
            ActiveAddress = (PVOID)((PCHAR)ActiveVacb->BaseAddress +
                                    (ActiveOffset.LowPart  & (VACB_MAPPING_GRANULARITY - 1)));

            //
            //  Tell the Lazy Writer to write the page.
            //

            CcSetDirtyInMask( SharedCacheMap, &ActiveOffset, PAGE_SIZE );

            //
            //  Now we need to clear the flag and decrement some counts if there is
            //  no other active Vacb which snuck in.
            //

            CcAcquireMasterLock( &OldIrql );
            ExAcquireSpinLockAtDpcLevel( &SharedCacheMap->ActiveVacbSpinLock );
            if ((SharedCacheMap->ActiveVacb == NULL) &&
                FlagOn(SharedCacheMap->Flags, ACTIVE_PAGE_IS_DIRTY)) {

                ClearFlag(SharedCacheMap->Flags, ACTIVE_PAGE_IS_DIRTY);
                CcDeductDirtyPages( SharedCacheMap, 1);
            }
            ExReleaseSpinLockFromDpcLevel( &SharedCacheMap->ActiveVacbSpinLock );
            CcReleaseMasterLock( OldIrql );
        }

        //
        //  Now free the Vacb.
        //

        CcFreeVirtualAddress( ActiveVacb );
    }
}


//
//  Internal Support Routine
//

VOID
CcMapAndCopy(
    IN PSHARED_CACHE_MAP SharedCacheMap,
    IN PVOID UserBuffer,
    IN PLARGE_INTEGER FileOffset,
    IN ULONG Length,
    IN ULONG ZeroFlags,
    IN PFILE_OBJECT FileObject
    )

/*++

Routine Description:

    This routine may be called to copy the specified user data to the
    cache via a special Mm routine which copies the data to uninitialized
    pages and returns.

Arguments:

    SharedCacheMap - Supplies the address of the SharedCacheMap for the
                     data.

    UserBuffer - unsafe buffer supplying the user's data to be written

    FileOffset - Supplies the file offset to be modified

    Length - Supplies the total amount of data

    ZeroFlags - Defines which pages may be zeroed if not resident.

    WriteThrough - Supplies the file object being written to

Return Value:

    None

--*/

{
    ULONG ReceivedLength;
    ULONG ZeroCase;
    PVOID CacheBuffer;
    PVOID SavedMappedBuffer;
    ULONG SavedMappedLength;
    ULONG ActivePage;
    KIRQL OldIrql;
    LARGE_INTEGER PFileOffset;
    IO_STATUS_BLOCK IoStatus;
    NTSTATUS Status;
    ULONG SavedState;
    LOGICAL MorePages;
    BOOLEAN WriteThrough = BooleanFlagOn( FileObject->Flags, FO_WRITE_THROUGH );
    ULONG SavedTotalLength = Length;
    LARGE_INTEGER LocalOffset;
    ULONG PageOffset = FileOffset->LowPart & (PAGE_SIZE - 1);
    PVACB Vacb = NULL;
    PETHREAD Thread = PsGetCurrentThread();

    //
    //  Initialize SavePage to TRUE to skip the finally clause on zero-length
    //  writes.
    //

    BOOLEAN SavePage = TRUE;

    //
    //  PREfix needs to see this explicitly, as opposed to a structure copy.
    //

    LocalOffset.QuadPart = FileOffset->QuadPart;

    DebugTrace(+1, me, "CcMapAndCopy:\n", 0 );
    DebugTrace( 0, me, "    SharedCacheMap = %08lx\n", SharedCacheMap );
    DebugTrace2(0, me, "    FileOffset = %08lx, %08lx\n", FileOffset->LowPart,
                                                          FileOffset->HighPart );
    DebugTrace( 0, me, "    Length = %08lx\n", Length );

    MmSavePageFaultReadAhead( Thread, &SavedState );

    //
    //  BUGBUG: re-enable this path when we can also generate a ccsetvaliddata call
    //  in all cases to fix corruption issue see 615074)
    // 

#if 0

    //
    //  See if we need to force write through.  If the file object is of remote origin,
    //  it has been exempted from throttling.  As a result, it is possible that too
    //  many pages will get dirty.  In order to prevent this, we force write through
    //  on these file objects if we would have throttled them in the first place.
    //

    if (!WriteThrough && IoIsFileOriginRemote(FileObject)

                &&

        !CcCanIWrite( FileObject,
                      Length,
                      FALSE,
                      MAXUCHAR - 2 )) {

        WriteThrough = TRUE;
    }

#endif

    //
    //  try around everything for cleanup.
    //

    try {

        while (Length != 0) {

            CacheBuffer = CcGetVirtualAddress( SharedCacheMap,
                                               LocalOffset,
                                               &Vacb,
                                               &ReceivedLength );

            //
            //  PREfix wants to know this cannot be NULL, otherwise it
            //  will complain.
            //

            ASSERT( CacheBuffer != NULL );

            //
            //  If we got more than we need, make sure to only use
            //  the right amount.
            //

            if (ReceivedLength > Length) {
                ReceivedLength = Length;
            }
            SavedMappedBuffer = CacheBuffer;
            SavedMappedLength = ReceivedLength;
            Length -= ReceivedLength;

            //
            //  Now loop to touch all of the pages, calling MM to insure
            //  that if we fault, we take in exactly the number of pages
            //  we need.
            //

            CacheBuffer = (PVOID)((PCHAR)CacheBuffer - PageOffset);
            ReceivedLength += PageOffset;

            //
            //  Loop to touch or zero the pages.
            //

            ZeroCase = ZERO_FIRST_PAGE;

            //
            //  Set up offset to page for use below.
            //

            PFileOffset = LocalOffset;
            PFileOffset.LowPart -= PageOffset;

            while (TRUE) {

                //
                //  Calculate whether we wish to save an active page
                //  or not.
                //

                SavePage = (BOOLEAN) ((Length == 0) &&
                            (ReceivedLength < PAGE_SIZE) &&
                            (SavedTotalLength <= (PAGE_SIZE / 2)) &&
                            !WriteThrough);

                MorePages = (ReceivedLength > PAGE_SIZE);

                //
                //  Copy the data to the user buffer.
                //

                try {

                    //
                    //  It is possible that there is a locked page
                    //  hanging around, and so we need to nuke it here.
                    //

                    if (SharedCacheMap->NeedToZero != NULL) {
                        CcFreeActiveVacb( SharedCacheMap, NULL, 0, 0 );
                    }

                    Status = STATUS_SUCCESS;
                    if (FlagOn(ZeroFlags, ZeroCase)) {

                        Status = MmCopyToCachedPage( CacheBuffer,
                                                     UserBuffer,
                                                     PageOffset,
                                                     MorePages ?
                                                       (PAGE_SIZE - PageOffset) :
                                                       (ReceivedLength - PageOffset),
                                                     SavePage );

                        if (!NT_SUCCESS(Status)) {

                            ExRaiseStatus( FsRtlNormalizeNtstatus( Status,
                                                                   STATUS_INVALID_USER_BUFFER ));
                        }

                    //
                    //  Otherwise, we have to actually copy the data ourselves.
                    //

                    } else {

                        MmSetPageFaultReadAhead( Thread,
                                                 (MorePages && FlagOn(ZeroFlags, ZERO_LAST_PAGE)) ? 1 : 0);

                        RtlCopyBytes( (PVOID)((PCHAR)CacheBuffer + PageOffset),
                                      UserBuffer,
                                      MorePages ?
                                        (PAGE_SIZE - PageOffset) :
                                        (ReceivedLength - PageOffset) );

                        MmResetPageFaultReadAhead( Thread, SavedState );

                    }

                } except( CcCopyReadExceptionFilter( GetExceptionInformation(),
                                                     &Status ) ) {

                    //
                    //  If we got an access violation, then the user buffer went
                    //  away.  Otherwise we must have gotten an I/O error trying
                    //  to bring the data in.
                    //

                    if (Status == STATUS_ACCESS_VIOLATION) {
                        ExRaiseStatus( STATUS_INVALID_USER_BUFFER );
                    }
                    else {
                        ExRaiseStatus( FsRtlNormalizeNtstatus( Status,
                                                               STATUS_UNEXPECTED_IO_ERROR ));
                    }
                }

                //
                //  Now get out quickly if it is a small write and we want
                //  to save the page.
                //

                if (SavePage) {

                    ActivePage = (ULONG)( Vacb->Overlay.FileOffset.QuadPart >> PAGE_SHIFT ) +
                                 (ULONG)(((PCHAR)CacheBuffer - (PCHAR)Vacb->BaseAddress) >>
                                   PAGE_SHIFT);

                    PFileOffset.LowPart += ReceivedLength;

                    //
                    //  If the cache page was not locked, then clear the address
                    //  to zero from.
                    //

                    if (Status == STATUS_CACHE_PAGE_LOCKED) {

                        //
                        //  We need to guarantee this Vacb for zeroing and calling
                        //  MmUnlockCachedPage, so we increment the active count here
                        //  and remember it for CcFreeActiveVacb.
                        //

                        CcAcquireVacbLock( &OldIrql );
                        Vacb->Overlay.ActiveCount += 1;

                        ExAcquireSpinLockAtDpcLevel( &SharedCacheMap->ActiveVacbSpinLock );

                        ASSERT(SharedCacheMap->NeedToZero == NULL);

                        SharedCacheMap->NeedToZero = (PVOID)((PCHAR)CacheBuffer +
                                                             (PFileOffset.LowPart & (PAGE_SIZE - 1)));
                        SharedCacheMap->NeedToZeroPage = ActivePage;
                        SharedCacheMap->NeedToZeroVacb = Vacb;

                        ExReleaseSpinLockFromDpcLevel( &SharedCacheMap->ActiveVacbSpinLock );
                        CcReleaseVacbLock( OldIrql );

                    }

                    SetActiveVacb( SharedCacheMap,
                                   OldIrql,
                                   Vacb,
                                   ActivePage,
                                   ACTIVE_PAGE_IS_DIRTY );

                    try_return( NOTHING );
                }

                //
                //  If it looks like we may save a page and exit on the next loop,
                //  then we must make sure to mark the current page dirty.  Note
                //  that Cc[Fast]CopyWrite will finish the last part of any page
                //  before allowing us to free the Active Vacb above, therefore
                //  this case only occurs for a small random write.
                //

                if ((SavedTotalLength <= (PAGE_SIZE / 2)) && !WriteThrough) {

                    CcSetDirtyInMask( SharedCacheMap, &PFileOffset, ReceivedLength );
                }

                UserBuffer = (PVOID)((PCHAR)UserBuffer + (PAGE_SIZE - PageOffset));
                PageOffset = 0;

                //
                //  If there is more than a page to go (including what we just
                //  copied), then adjust our buffer pointer and counts, and
                //  determine if we are to the last page yet.
                //

                if (MorePages) {

                    CacheBuffer = (PCHAR)CacheBuffer + PAGE_SIZE;
                    ReceivedLength -= PAGE_SIZE;

                    //
                    //  Update our offset to the page.  Note that 32-bit
                    //  add is ok since we cannot cross a Vacb boundary
                    //  and we reinitialize this offset before entering
                    //  this loop again.
                    //

                    PFileOffset.LowPart += PAGE_SIZE;

                    if (ReceivedLength > PAGE_SIZE) {
                        ZeroCase = ZERO_MIDDLE_PAGES;
                    } else {
                        ZeroCase = ZERO_LAST_PAGE;
                    }

                } else {

                    break;
                }
            }

            //
            //  If there is still more to write (ie. we are going to step
            //  onto the next vacb) AND we just dirtied more than 64K, then
            //  do a vicarious MmFlushSection here.  This prevents us from
            //  creating unlimited dirty pages while holding the file
            //  resource exclusive.  We also do not need to set the pages
            //  dirty in the mask in this case.
            //

            if (Length > CcMaxDirtyWrite) {

                MmSetAddressRangeModified( SavedMappedBuffer, SavedMappedLength );
                MmFlushSection( SharedCacheMap->FileObject->SectionObjectPointer,
                                &LocalOffset,
                                SavedMappedLength,
                                &IoStatus,
                                TRUE );

                if (!NT_SUCCESS(IoStatus.Status)) {
                    ExRaiseStatus( FsRtlNormalizeNtstatus( IoStatus.Status,
                                                           STATUS_UNEXPECTED_IO_ERROR ));
                }

            //
            //  For write through files, call Mm to propagate the dirty bits
            //  here while we have the view mapped, so we know the flush will
            //  work below.  Again - do not set dirty in the mask.
            //

            } else if (WriteThrough) {

                MmSetAddressRangeModified( SavedMappedBuffer, SavedMappedLength );

            //
            //  For the normal case, just set the pages dirty for the Lazy Writer
            //  now.
            //

            } else {

                CcSetDirtyInMask( SharedCacheMap, &LocalOffset, SavedMappedLength );
            }

            CcFreeVirtualAddress( Vacb );
            Vacb = NULL;

            //
            //  If we have to loop back to get at least a page, it will be ok to
            //  zero the first page.  If we are not getting at least a page, we
            //  must make sure we clear the ZeroFlags if we cannot zero the last
            //  page.
            //

            if (Length >= PAGE_SIZE) {
                ZeroFlags |= ZERO_FIRST_PAGE;
            } else if ((ZeroFlags & ZERO_LAST_PAGE) == 0) {
                ZeroFlags = 0;
            }

            //
            //  Note that if ReceivedLength (and therefore SavedMappedLength)
            //  was truncated to the transfer size then the new LocalOffset
            //  computed below is not correct.  This is not an issue since
            //  in that case (Length == 0) and we would never get here.
            //

            LocalOffset.QuadPart = LocalOffset.QuadPart + (LONGLONG)SavedMappedLength;
        }
    try_exit: NOTHING;
    }

    //
    //  Cleanup on the way out.
    //

    finally {

        MmResetPageFaultReadAhead( Thread, SavedState );

        //
        //  We have no work to do if we have squirreled away the Vacb.
        //

        if (!SavePage || AbnormalTermination()) {

            //
            //  Make sure we do not leave anything mapped or dirty in the PTE
            //  on the way out.
            //

            if (Vacb != NULL) {

                CcFreeVirtualAddress( Vacb );
            }

            //
            //  Either flush the whole range because of write through, or
            //  mark it dirty for the lazy writer.
            //

            if (WriteThrough) {

                MmFlushSection ( SharedCacheMap->FileObject->SectionObjectPointer,
                                 FileOffset,
                                 SavedTotalLength,
                                 &IoStatus,
                                 TRUE );

                if (!NT_SUCCESS(IoStatus.Status)) {
                    ExRaiseStatus( FsRtlNormalizeNtstatus( IoStatus.Status,
                                                           STATUS_UNEXPECTED_IO_ERROR ));
                }

                //
                //  Advance ValidDataGoal
                //

                LocalOffset.QuadPart = FileOffset->QuadPart + (LONGLONG)SavedTotalLength;
                if (LocalOffset.QuadPart > SharedCacheMap->ValidDataGoal.QuadPart) {
                    SharedCacheMap->ValidDataGoal = LocalOffset;
                }
            }
        }
    }

    DebugTrace(-1, me, "CcMapAndCopy -> %02lx\n", Result );

    return;
}


BOOLEAN
CcLogError(
    IN PFILE_OBJECT FileObject,
    IN PUNICODE_STRING FileName,
    IN NTSTATUS Error,
    IN NTSTATUS DeviceError,
    IN UCHAR IrpMajorCode
    )

/*++

Routine Description:

    This routine writes an eventlog entry to the eventlog.

Arguments:

    FileObject - The fileobject in whose context the error occured.

    FileName - The filename to use in logging the error (usually the DOS-side name)

    Error - The error to log in the eventlog record

    DeviceError - The actual error that occured in the device - will be logged
                  as user data

Return Value:

    True if successful, false if internal memory allocation failed

--*/

{
    UCHAR ErrorPacketLength;
    UCHAR BasePacketLength;
    ULONG StringLength;
    PIO_ERROR_LOG_PACKET ErrorLogEntry = NULL;
    BOOLEAN Result = FALSE;
    PWCHAR String;

    PAGED_CODE();

    //
    //  Get our error packet, holding the string and status code.  Note we log against the
    //  true filesystem if this is available.
    //
    //  The sizing of the packet is a bit slimy since the dumpdata is already grown by a
    //  ULONG onto the end of the packet.  Since NTSTATUS is ULONG, well, we just work in
    //  place.
    //

    BasePacketLength = sizeof(IO_ERROR_LOG_PACKET);
    if ((BasePacketLength + FileName->Length + sizeof(WCHAR)) <= ERROR_LOG_MAXIMUM_SIZE) {
        ErrorPacketLength = (UCHAR)(BasePacketLength + FileName->Length + sizeof(WCHAR));
    } else {
        ErrorPacketLength = ERROR_LOG_MAXIMUM_SIZE;
    }

    ErrorLogEntry = (PIO_ERROR_LOG_PACKET) IoAllocateErrorLogEntry( (FileObject->Vpb ?
                                                                     FileObject->Vpb->DeviceObject :
                                                                     FileObject->DeviceObject),
                                                                    ErrorPacketLength );
    if (ErrorLogEntry) {

        //
        //  Fill in the nonzero members of the packet.
        //

        ErrorLogEntry->MajorFunctionCode = IrpMajorCode;
        ErrorLogEntry->ErrorCode = Error;
        ErrorLogEntry->FinalStatus = DeviceError;

        ErrorLogEntry->DumpDataSize = sizeof(NTSTATUS);
        RtlCopyMemory( &ErrorLogEntry->DumpData, &DeviceError, sizeof(NTSTATUS) );

        //
        //  The filename string is appended to the end of the error log entry. We may
        //  have to smash the middle to fit it in the limited space.
        //

        StringLength = ErrorPacketLength - BasePacketLength - sizeof(WCHAR);

        ASSERT(!(StringLength % sizeof(WCHAR)));

        String = (PWCHAR) ((PUCHAR)ErrorLogEntry + BasePacketLength);
        ErrorLogEntry->NumberOfStrings = 1;
        ErrorLogEntry->StringOffset = BasePacketLength;

        //
        //  If the name does not fit in the packet, divide the name equally to the
        //  prefix and suffix, with an ellipsis " .. " (4 wide characters) to indicate
        //  the loss.
        //

        if (StringLength < FileName->Length) {

            //
            //  Remember, prefix + " .. " + suffix is the length.  Calculate by figuring
            //  the prefix and then get the suffix by whacking the ellipsis and prefix off
            //  the total.
            //
            
            ULONG NamePrefixSegmentLength = ((StringLength/sizeof(WCHAR))/2 - 2)*sizeof(WCHAR);
            ULONG NameSuffixSegmentLength = StringLength - 4*sizeof(WCHAR) - NamePrefixSegmentLength;

            ASSERT(!(NamePrefixSegmentLength % sizeof(WCHAR)));
            ASSERT(!(NameSuffixSegmentLength % sizeof(WCHAR)));

            RtlCopyMemory( String,
                           FileName->Buffer,
                           NamePrefixSegmentLength );
            String = (PWCHAR)((PCHAR)String + NamePrefixSegmentLength);

            RtlCopyMemory( String,
                           L" .. ",
                           4*sizeof(WCHAR) );
            String += 4;

            RtlCopyMemory( String,
                           (PUCHAR)FileName->Buffer +
                           FileName->Length - NameSuffixSegmentLength,
                           NameSuffixSegmentLength );
            String = (PWCHAR)((PCHAR)String + NameSuffixSegmentLength);

        } else {
            
            RtlCopyMemory( String,
                           FileName->Buffer,
                           FileName->Length );
            String += FileName->Length/sizeof(WCHAR);
        }

        //
        //  Null terminate the string and send the packet.
        //

        *String = L'\0';

        IoWriteErrorLogEntry( ErrorLogEntry );
        Result = TRUE;
    }

    return Result;
}


LOGICAL
CcHasInactiveViews (
    VOID
    )

/*++

Routine Description:

    This routine is called by Memory Management only to query if the system
    cache has any inactive views.  If so, Memory Management may issue a
    subsequent call to CcUnmapInactiveViews to discard these views in an
    attempt to reclaim the prototype PTE pool (and other resources tied to
    the section).

Arguments:

    None.

Return Value:

    TRUE if Cc has any views it can discard, FALSE if not.

Environment:

    Arbitrary thread context, generally APC_LEVEL or DISPATCH_LEVEL.  Various
    mutexes and/or spinlocks may be held by the caller.

--*/

{
    return FALSE;       // BUGBUG - add code to flesh out.
}


LOGICAL
CcUnmapInactiveViews (
    IN ULONG NumberOfViewsToUnmap
    )

/*++

Routine Description:

    This routine is called by Memory Management to request that the cache
    manager unmap a number of inactive views.  This call is generally made
    because the system is low on pool (paged or nonpaged).

    Discarding these views is done in an attempt to reclaim the prototype
    PTE pool (and other resources tied to the section).

Arguments:

    NumberOfViewsToUnmap - Supplies the desired number of views to unmap.

Return Value:

    TRUE if Cc discarded *ANY* views, FALSE if not.

Environment:

    Dereference segment thread context at PASSIVE_LEVEL.

--*/

{
    UNREFERENCED_PARAMETER (NumberOfViewsToUnmap);

    return FALSE;       // BUGBUG - add code to flesh out.
}

#ifdef CCDBG
VOID
CcDump (
    IN PVOID Ptr
    )

{
    PVOID Junk = Ptr;
}
#endif
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\base\ntos\cache\fssup.c ===
/*++

Copyright (c) 1990  Microsoft Corporation

Module Name:

    fssup.c

Abstract:

    This module implements the File System support routines for the
    Cache subsystem.

Author:

    Tom Miller      [TomM]      4-May-1990

Revision History:

--*/

#include "cc.h"

//
//  The Bug check file id for this module
//

#define BugCheckFileId                   (CACHE_BUG_CHECK_FSSUP)

//
//  Define our debug constant
//

#define me 0x00000001

//
//  For your debugging pleasure, if the flag doesn't move!  (Currently not used)
//

#define IsSyscacheFile(FO) (((FO) != NULL) &&                                               \
                            (*(PUSHORT)(FO)->FsContext == 0X705) &&                         \
                            FlagOn(*(PULONG)((PCHAR)(FO)->FsContext + 0x48), 0x80000000))

extern POBJECT_TYPE IoFileObjectType;
extern ULONG MmLargeSystemCache;

VOID
CcUnmapAndPurge(
    IN PSHARED_CACHE_MAP SharedCacheMap
    );

VOID
CcDeleteMbcb(
    IN PSHARED_CACHE_MAP SharedCacheMap
    );

VOID
CcDeleteBcbs (
    IN PSHARED_CACHE_MAP SharedCacheMap
    );

VOID
CcPurgeAndClearCacheSection (
    IN PSHARED_CACHE_MAP SharedCacheMap,
    IN PLARGE_INTEGER FileOffset
    );

#ifdef ALLOC_PRAGMA
#pragma alloc_text(INIT,CcInitializeCacheManager)
#pragma alloc_text(PAGE,CcZeroData)
#endif


BOOLEAN
CcInitializeCacheManager (
    )

/*++

Routine Description:

    This routine must be called during system initialization before the
    first call to any file system, to allow the Cache Manager to initialize
    its global data structures.  This routine has no dependencies on other
    system components being initialized.

Arguments:

    None

Return Value:

    TRUE if initialization was successful

--*/

{
    CLONG i;
    ULONG Index;
    PGENERAL_LOOKASIDE Lookaside;
    USHORT NumberOfItems;
    PKPRCB Prcb;
    PWORK_QUEUE_ITEM WorkItem;

#ifdef CCDBG_LOCK
    KeInitializeSpinLock( &CcDebugTraceLock );
#endif

#if DBG
    CcBcbCount = 0;
    InitializeListHead( &CcBcbList );
#endif

    //
    //  Figure out the timeout clock tick for the lazy writer.
    //

    CcIdleDelayTick = LAZY_WRITER_IDLE_DELAY / KeQueryTimeIncrement();

    //
    //  Initialize shared cache map list structures
    //

    InitializeListHead( &CcCleanSharedCacheMapList );
    InitializeListHead( &CcDirtySharedCacheMapList.SharedCacheMapLinks );
    CcDirtySharedCacheMapList.Flags = IS_CURSOR;
    InsertTailList( &CcDirtySharedCacheMapList.SharedCacheMapLinks,
                    &CcLazyWriterCursor.SharedCacheMapLinks );
    CcLazyWriterCursor.Flags = IS_CURSOR;

    //
    //  Initialize worker thread structures
    //

    InitializeListHead( &CcIdleWorkerThreadList );
    InitializeListHead( &CcExpressWorkQueue );
    InitializeListHead( &CcRegularWorkQueue );
    InitializeListHead( &CcPostTickWorkQueue );

    //
    //  Set the number of worker threads based on the system size.
    //

    CcCapturedSystemSize = MmQuerySystemSize();
    if (CcNumberWorkerThreads == 0) {

        switch (CcCapturedSystemSize) {
        case MmSmallSystem:
            CcNumberWorkerThreads = ExCriticalWorkerThreads - 1;
            CcDirtyPageThreshold = MmNumberOfPhysicalPages / 8;
            CcAggressiveZeroThreshold = 1;
            break;

        case MmMediumSystem:
            CcNumberWorkerThreads = ExCriticalWorkerThreads - 1;
            CcDirtyPageThreshold = MmNumberOfPhysicalPages / 4;
            CcAggressiveZeroThreshold = 2;
            break;

        case MmLargeSystem:
            CcNumberWorkerThreads = ExCriticalWorkerThreads - 2;
            CcDirtyPageThreshold = MmNumberOfPhysicalPages / 4 +
                                    MmNumberOfPhysicalPages / 8;
            CcAggressiveZeroThreshold = 4;
            break;

        default:
            CcNumberWorkerThreads = 1;
            CcDirtyPageThreshold = MmNumberOfPhysicalPages / 8;
        }

        if (MmSystemCacheWs.MaximumWorkingSetSize > ((4*1024*1024)/PAGE_SIZE)) {
            CcDirtyPageThreshold = (ULONG)(MmSystemCacheWs.MaximumWorkingSetSize -
                                                    ((2*1024*1024)/PAGE_SIZE));
        }

        CcDirtyPageTarget = CcDirtyPageThreshold / 2 +
                            CcDirtyPageThreshold / 4;
    }

    CcAggressiveZeroCount = 0;

    //
    //  Now allocate and initialize the above number of worker thread
    //  items.
    //

    for (i = 0; i < CcNumberWorkerThreads; i++) {

        WorkItem = ExAllocatePoolWithTag( NonPagedPool, sizeof(WORK_QUEUE_ITEM), 'qWcC' );

        if (WorkItem == NULL) {

            CcBugCheck( 0, 0, 0 );
        }

        //
        //  Initialize the work queue item and insert in our queue
        //  of potential worker threads.
        //

        ExInitializeWorkItem( WorkItem, CcWorkerThread, WorkItem );
        InsertTailList( &CcIdleWorkerThreadList, &WorkItem->List );
    }

    //
    //  Initialize the Lazy Writer thread structure, and start him up.
    //

    RtlZeroMemory( &LazyWriter, sizeof(LAZY_WRITER) );

    InitializeListHead( &LazyWriter.WorkQueue );

    //
    //  Initialize the Scan Dpc and Timer.
    //

    KeInitializeDpc( &LazyWriter.ScanDpc, &CcScanDpc, NULL );
    KeInitializeTimer( &LazyWriter.ScanTimer );

    //
    //  Now initialize the lookaside list for allocating Work Queue entries.
    //

    switch ( CcCapturedSystemSize ) {

        //
        // ~512 bytes
        //

    case MmSmallSystem :
        NumberOfItems = 32;
        break;

        //
        // ~1k bytes
        //

    case MmMediumSystem :
        NumberOfItems = 64;
        break;

        //
        // ~2k bytes
        //

    case MmLargeSystem :
        NumberOfItems = 128;
        if (MmIsThisAnNtAsSystem()) {
            NumberOfItems += 128;
        }

        break;
    }

    ExInitializeSystemLookasideList( &CcTwilightLookasideList,
                                     NonPagedPool,
                                     sizeof( WORK_QUEUE_ENTRY ),
                                     'kWcC',
                                     NumberOfItems,
                                     &ExSystemLookasideListHead );

    //
    // Initialize the per processor nonpaged lookaside lists and descriptors.
    //

    for (Index = 0; Index < (ULONG)KeNumberProcessors; Index += 1) {
        Prcb = KiProcessorBlock[Index];

        //
        // Initialize the large IRP per processor lookaside pointers.
        //

        Prcb->PPLookasideList[LookasideTwilightList].L = &CcTwilightLookasideList;
        Lookaside = ExAllocatePoolWithTag( NonPagedPool,
                                           sizeof(GENERAL_LOOKASIDE),
                                           'KWcC');

        if (Lookaside != NULL) {
            ExInitializeSystemLookasideList( Lookaside,
                                             NonPagedPool,
                                             sizeof( WORK_QUEUE_ENTRY ),
                                             'KWcC',
                                             NumberOfItems,
                                             &ExSystemLookasideListHead );

        } else {
            Lookaside = &CcTwilightLookasideList;
        }

        Prcb->PPLookasideList[LookasideTwilightList].P = Lookaside;
    }

    //
    //  Initialize the Deferred Write List.
    //

    KeInitializeSpinLock( &CcDeferredWriteSpinLock );
    InitializeListHead( &CcDeferredWrites );

    //
    //  Initialize the Vacbs.
    //

    CcInitializeVacbs();

    return TRUE;
}


VOID
CcInitializeCacheMap (
    IN PFILE_OBJECT FileObject,
    IN PCC_FILE_SIZES FileSizes,
    IN BOOLEAN PinAccess,
    IN PCACHE_MANAGER_CALLBACKS Callbacks,
    IN PVOID LazyWriteContext
    )

/*++

Routine Description:

    This routine is intended to be called by File Systems only.  It
    initializes the cache maps for data caching.  It should be called
    every time a file is opened or created, and NO_INTERMEDIATE_BUFFERING
    was specified as FALSE.

Arguments:

    FileObject - A pointer to the newly-created file object.

    FileSizes - A pointer to AllocationSize, FileSize and ValidDataLength
                for the file.  ValidDataLength should contain MAXLONGLONG if
                valid data length tracking and callbacks are not desired.

    PinAccess - FALSE if file will be used exclusively for Copy and Mdl
                access, or TRUE if file will be used for Pin access.
                (Files for Pin access are not limited in size as the caller
                must access multiple areas of the file at once.)

    Callbacks - Structure of callbacks used by the Lazy Writer

    LazyWriteContext - Parameter to be passed in to above routine.

Return Value:

    None.  If an error occurs, this routine will Raise the status.

--*/

{
    KIRQL OldIrql;
    PSHARED_CACHE_MAP SharedCacheMap;
    PVOID CacheMapToFree = NULL;
    CC_FILE_SIZES LocalSizes;
    LOGICAL WeSetBeingCreated = FALSE;
    LOGICAL SharedListOwned = FALSE;
    LOGICAL MustUninitialize = FALSE;
    LOGICAL WeCreated = FALSE;
    PPRIVATE_CACHE_MAP PrivateCacheMap;
    NTSTATUS Status = STATUS_SUCCESS;

    DebugTrace(+1, me, "CcInitializeCacheMap:\n", 0 );
    DebugTrace( 0, me, "    FileObject = %08lx\n", FileObject );
    DebugTrace( 0, me, "    FileSizes = %08lx\n", FileSizes );

    //
    //  Make a local copy of the passed in file sizes before acquiring
    //  the spin lock.
    //

    LocalSizes = *FileSizes;

    //
    //  If no FileSize was given, set to one byte before maximizing below.
    //

    if (LocalSizes.AllocationSize.QuadPart == 0) {
        LocalSizes.AllocationSize.LowPart += 1;
    }

    //
    //  If caller has Write access or will allow write, then round
    //  size to next create modulo.  (***Temp*** there may be too many
    //  apps that end up allowing shared write, thanks to our Dos heritage,
    //  to keep that part of the check in.)
    //

    if (FileObject->WriteAccess /*|| FileObject->SharedWrite */) {

        LocalSizes.AllocationSize.QuadPart = LocalSizes.AllocationSize.QuadPart + (LONGLONG)(DEFAULT_CREATE_MODULO - 1);
        LocalSizes.AllocationSize.LowPart &= ~(DEFAULT_CREATE_MODULO - 1);

    } else {

        LocalSizes.AllocationSize.QuadPart = LocalSizes.AllocationSize.QuadPart + (LONGLONG)(VACB_MAPPING_GRANULARITY - 1);
        LocalSizes.AllocationSize.LowPart &= ~(VACB_MAPPING_GRANULARITY - 1);
    }

    //
    //  Do the allocate of the SharedCacheMap, based on an unsafe test,
    //  while not holding a spinlock.  If the allocation fails, it's ok
    //  to fail the request even though the test was unsafe.
    //

    if (FileObject->SectionObjectPointer->SharedCacheMap == NULL) {

restart:

        ASSERT (CacheMapToFree == NULL);

        SharedCacheMap = ExAllocatePoolWithTag( NonPagedPool, sizeof(SHARED_CACHE_MAP), 'cScC' );

        if (SharedCacheMap == NULL) {
            DebugTrace( 0, 0, "Failed to allocate SharedCacheMap\n", 0 );
            ExRaiseStatus( STATUS_INSUFFICIENT_RESOURCES );
        }

        //
        //  Stash a copy of it so we can free it in the error path below.
        //

        CacheMapToFree = SharedCacheMap;

        //
        //  Zero the SharedCacheMap and fill in the nonzero portions later.
        //

        RtlZeroMemory( SharedCacheMap, sizeof(SHARED_CACHE_MAP) );

#if OPEN_COUNT_LOG
        SharedCacheMap->OpenCountLog.Size = sizeof(SharedCacheMap->OpenCountLog.Log)/sizeof(CC_OPEN_COUNT_LOG_ENTRY);
#endif

        //
        //  Now initialize the Shared Cache Map.
        //

        SharedCacheMap->NodeTypeCode = CACHE_NTC_SHARED_CACHE_MAP;
        SharedCacheMap->NodeByteSize = sizeof(SHARED_CACHE_MAP);
        SharedCacheMap->FileObject = FileObject;
        SharedCacheMap->FileSize = LocalSizes.FileSize;
        SharedCacheMap->ValidDataLength = LocalSizes.ValidDataLength;
        SharedCacheMap->ValidDataGoal = LocalSizes.ValidDataLength;
        //  SharedCacheMap->Section set below

        //
        //  Initialize the spin locks.
        //

        KeInitializeSpinLock( &SharedCacheMap->ActiveVacbSpinLock );
        KeInitializeSpinLock( &SharedCacheMap->BcbSpinLock );

        ExInitializePushLock( &SharedCacheMap->VacbPushLock );

        if (PinAccess) {
            SetFlag(SharedCacheMap->Flags, PIN_ACCESS);
        }

        //
        //  If this file has FO_SEQUENTIAL_ONLY set, then remember that
        //  in the SharedCacheMap.
        //

        if (FlagOn(FileObject->Flags, FO_SEQUENTIAL_ONLY)) {
            SetFlag(SharedCacheMap->Flags, ONLY_SEQUENTIAL_ONLY_SEEN);
        }

        //
        //  Do the round-robin allocation of the spinlock for the shared
        //  cache map.  Note the manipulation of the next
        //  counter is safe, since we have the CcMasterSpinLock
        //  exclusive.
        //

        InitializeListHead( &SharedCacheMap->BcbList );
        SharedCacheMap->Callbacks = Callbacks;
        SharedCacheMap->LazyWriteContext = LazyWriteContext;

        //
        //  Initialize listhead for all PrivateCacheMaps
        //

        InitializeListHead( &SharedCacheMap->PrivateList );
    }

    //
    //  Serialize Creation/Deletion of all Shared CacheMaps
    //

    SharedListOwned = TRUE;

    CcAcquireMasterLock( &OldIrql );

    //
    //  Check for second initialization of same file object
    //

    if (FileObject->PrivateCacheMap != NULL) {

        DebugTrace( 0, 0, "CacheMap already initialized\n", 0 );
        CcReleaseMasterLock( OldIrql );
        if (CacheMapToFree != NULL) {
            ExFreePool(CacheMapToFree);
        }
        DebugTrace(-1, me, "CcInitializeCacheMap -> VOID\n", 0 );
        return;
    }

    //
    //  Get current Shared Cache Map pointer indirectly off of the file object.
    //  (The actual pointer is typically in a file system data structure, such
    //  as an Fcb.)
    //

    SharedCacheMap = FileObject->SectionObjectPointer->SharedCacheMap;

    //
    //  If there is no SharedCacheMap, then we must create a section and
    //  the SharedCacheMap structure.
    //

    if (SharedCacheMap == NULL) {

        //
        //  Insert the new SharedCacheMap.
        //

        if (CacheMapToFree == NULL) {
            CcReleaseMasterLock( OldIrql );
            SharedListOwned = FALSE;
            goto restart;
        }

        SharedCacheMap = CacheMapToFree;
        CacheMapToFree = NULL;

        //
        //  Insert the new Shared Cache Map in the global list
        //

        InsertTailList( &CcCleanSharedCacheMapList,
                        &SharedCacheMap->SharedCacheMapLinks );

        WeCreated = TRUE;

        //
        //  Finally, store the pointer to the Shared Cache Map back
        //  via the indirect pointer in the File Object.
        //

        FileObject->SectionObjectPointer->SharedCacheMap = SharedCacheMap;

        //
        //  We must reference this file object so that it cannot go away
        //  until we do CcUninitializeCacheMap below.  Note we cannot
        //  find or rely on the FileObject that Memory Management has,
        //  although normally it will be this same one anyway.
        //

        ObReferenceObject ( FileObject );

    } else {

        //
        //  If this file has FO_SEQUENTIAL_ONLY clear, then remember that
        //  in the SharedCacheMap.
        //

        if (!FlagOn(FileObject->Flags, FO_SEQUENTIAL_ONLY)) {
            ClearFlag(SharedCacheMap->Flags, ONLY_SEQUENTIAL_ONLY_SEEN);
        }
    }

    //
    //  If this file is opened for random access, remember this in
    //  the SharedCacheMap.
    //

    if (FlagOn(FileObject->Flags, FO_RANDOM_ACCESS)) {
        SetFlag(SharedCacheMap->Flags, RANDOM_ACCESS_SEEN);
    }

    //
    //  Make sure that no one is trying to lazy delete it in the case
    //  that the Cache Map was already there.
    //

    ClearFlag(SharedCacheMap->Flags, TRUNCATE_REQUIRED);

    //
    //  In case there has been a CcUnmapAndPurge call, we check here if we
    //  if we need to recreate the section and map it.
    //

    if ((SharedCacheMap->Vacbs == NULL) &&
        !FlagOn(SharedCacheMap->Flags, BEING_CREATED)) {

        //
        //  Increment the OpenCount on the CacheMap.
        //

        CcIncrementOpenCount( SharedCacheMap, 'onnI' );

        //
        //  We still want anyone else to wait.
        //

        SetFlag(SharedCacheMap->Flags, BEING_CREATED);

        //
        //  If there is a create event, then this must be the path where we
        //  we were only unmapped.  We will just clear it here again in case
        //  someone needs to wait again this time too.
        //

        if (SharedCacheMap->CreateEvent != NULL) {

            KeInitializeEvent( SharedCacheMap->CreateEvent,
                               NotificationEvent,
                               FALSE );
        }

        //
        //  Release global resource
        //

        CcReleaseMasterLock( OldIrql );
        SharedListOwned = FALSE;

        //
        //  Signify we have incremented the open count.
        //

        MustUninitialize = TRUE;

        //
        //  Signify we have marked BEING_CREATED in the CacheMap flags.
        //

        WeSetBeingCreated = TRUE;

        //
        //  We have to test this, because the section may only be unmapped.
        //

        if (SharedCacheMap->Section == NULL) {

            //
            //  Call MM to create a section for this file, for the calculated
            //  section size.  Note that we have the choice in this service to
            //  pass in a FileHandle or a FileObject pointer, but not both.
            //  Use the pointer as it results in much faster performance.
            //

            DebugTrace( 0, mm, "MmCreateSection:\n", 0 );
            DebugTrace2(0, mm, "    MaximumSize = %08lx, %08lx\n",
                        LocalSizes.AllocationSize.LowPart,
                        LocalSizes.AllocationSize.HighPart );
            DebugTrace( 0, mm, "    FileObject = %08lx\n", FileObject );

            SharedCacheMap->Status = MmCreateSection( &SharedCacheMap->Section,
                                                      SECTION_MAP_READ
                                                        | SECTION_MAP_WRITE
                                                        | SECTION_QUERY,
                                                      NULL,
                                                      &LocalSizes.AllocationSize,
                                                      PAGE_READWRITE,
                                                      SEC_COMMIT,
                                                      NULL,
                                                      FileObject );

            DebugTrace( 0, mm, "    <Section = %08lx\n", SharedCacheMap->Section );

            if (!NT_SUCCESS( SharedCacheMap->Status )){
                DebugTrace( 0, 0, "Error from MmCreateSection = %08lx\n",
                            SharedCacheMap->Status );

                SharedCacheMap->Section = NULL;
                Status = FsRtlNormalizeNtstatus( SharedCacheMap->Status,
                                                 STATUS_UNEXPECTED_MM_CREATE_ERR );
                goto exitfinally;
            }

            ObDeleteCapturedInsertInfo(SharedCacheMap->Section);

            //
            //  If this is a stream file object, then no user can map it,
            //  and we should keep the modified page writer out of it.
            //

            if (!FlagOn(((PFSRTL_COMMON_FCB_HEADER)FileObject->FsContext)->Flags2,
                        FSRTL_FLAG2_DO_MODIFIED_WRITE) &&
                (FileObject->FsContext2 == NULL)) {

                MmDisableModifiedWriteOfSection( FileObject->SectionObjectPointer );
                CcAcquireMasterLock( &OldIrql );
                SetFlag(SharedCacheMap->Flags, MODIFIED_WRITE_DISABLED);
                CcReleaseMasterLock( OldIrql );
            }

            //
            //  Create the Vacb array.
            //

            Status = CcCreateVacbArray( SharedCacheMap, LocalSizes.AllocationSize );
            if (!NT_SUCCESS(Status)) {
                goto exitfinally;
            }
        }

        //
        //  If the section already exists, we still have to call MM to
        //  extend, in case it is not large enough.
        //

        else {

            if ( LocalSizes.AllocationSize.QuadPart > SharedCacheMap->SectionSize.QuadPart ) {

                DebugTrace( 0, mm, "MmExtendSection:\n", 0 );
                DebugTrace( 0, mm, "    Section = %08lx\n", SharedCacheMap->Section );
                DebugTrace2(0, mm, "    Size = %08lx, %08lx\n",
                            LocalSizes.AllocationSize.LowPart,
                            LocalSizes.AllocationSize.HighPart );

                Status = MmExtendSection( SharedCacheMap->Section,
                                          &LocalSizes.AllocationSize,
                                          TRUE );

                if (!NT_SUCCESS(Status)) {

                    DebugTrace( 0, 0, "Error from MmExtendSection, Status = %08lx\n",
                                Status );

                    Status = FsRtlNormalizeNtstatus( Status,
                                                     STATUS_UNEXPECTED_MM_EXTEND_ERR );
                    goto exitfinally;
                }
            }

            //
            //  Extend the Vacb array.
            //

            Status = CcExtendVacbArray( SharedCacheMap, LocalSizes.AllocationSize );
            if (!NT_SUCCESS(Status)) {
                goto exitfinally;
            }
        }

        //
        //  Now show that we are all done and resume any waiters.
        //

        CcAcquireMasterLock( &OldIrql );
        ClearFlag(SharedCacheMap->Flags, BEING_CREATED);
        if (SharedCacheMap->CreateEvent != NULL) {
            KeSetEvent( SharedCacheMap->CreateEvent, 0, FALSE );
        }
        CcReleaseMasterLock( OldIrql );
        WeSetBeingCreated = FALSE;
    }

    //
    //  Else if the section is already there, we make sure it is large
    //  enough by calling CcExtendCacheSection.
    //

    else {

        //
        //  If the SharedCacheMap is currently being created we have
        //  to optionally create and wait on an event for it.  Note that
        //  the only safe time to delete the event is in
        //  CcUninitializeCacheMap, because we otherwise have no way of
        //  knowing when everyone has reached the KeWaitForSingleObject.
        //

        if (FlagOn(SharedCacheMap->Flags, BEING_CREATED)) {

            if (SharedCacheMap->CreateEvent == NULL) {

                SharedCacheMap->CreateEvent = (PKEVENT)ExAllocatePoolWithTag( NonPagedPool,
                                                                              sizeof(KEVENT),
                                                                              'vEcC' );

                if (SharedCacheMap->CreateEvent == NULL) {
                    DebugTrace( 0, 0, "Failed to allocate CreateEvent\n", 0 );

                    CcReleaseMasterLock( OldIrql );
                    SharedListOwned = FALSE;

                    Status = STATUS_INSUFFICIENT_RESOURCES;
                    goto exitfinally;
                }

                KeInitializeEvent( SharedCacheMap->CreateEvent,
                                   NotificationEvent,
                                   FALSE );
            }

            //
            //  Increment the OpenCount on the CacheMap.
            //

            CcIncrementOpenCount( SharedCacheMap, 'ecnI' );

            //
            //  Release global resource before waiting
            //

            CcReleaseMasterLock( OldIrql );
            SharedListOwned = FALSE;

            MustUninitialize = TRUE;

            DebugTrace( 0, 0, "Waiting on CreateEvent\n", 0 );

            KeWaitForSingleObject( SharedCacheMap->CreateEvent,
                                   Executive,
                                   KernelMode,
                                   FALSE,
                                   (PLARGE_INTEGER)NULL);

            //
            //  If the real creator got an error, then we must bomb
            //  out too.
            //

            if (!NT_SUCCESS(SharedCacheMap->Status)) {
                Status = FsRtlNormalizeNtstatus( SharedCacheMap->Status,
                                                 STATUS_UNEXPECTED_MM_CREATE_ERR );
                goto exitfinally;
            }
        }
        else {

            PCACHE_UNINITIALIZE_EVENT CUEvent, EventNext;

            //
            //  Increment the OpenCount on the CacheMap.
            //

            CcIncrementOpenCount( SharedCacheMap, 'esnI' );

            //
            //  If there is a process waiting on an uninitialize on this
            //  cache map to complete, let the thread that is waiting go,
            //  since the uninitialize is now complete.
            //

            CUEvent = SharedCacheMap->UninitializeEvent;

            while (CUEvent != NULL) {
                EventNext = CUEvent->Next;
                KeSetEvent(&CUEvent->Event, 0, FALSE);
                CUEvent = EventNext;
            }

            SharedCacheMap->UninitializeEvent = NULL;

            //
            //  Release global resource
            //

            CcReleaseMasterLock( OldIrql );
            SharedListOwned = FALSE;
            MustUninitialize = TRUE;
        }
    }

    if (CacheMapToFree != NULL) {
        ExFreePool( CacheMapToFree );
        CacheMapToFree = NULL;
    }

    //
    //  Now allocate (if local one already in use) and initialize
    //  the Private Cache Map.
    //

    PrivateCacheMap = &SharedCacheMap->PrivateCacheMap;

    //
    //  See if we should allocate a PrivateCacheMap while not holding
    //  a spinlock.
    //

    if (PrivateCacheMap->NodeTypeCode != 0) {

restart2:

        CacheMapToFree = ExAllocatePoolWithTag( NonPagedPool, sizeof(PRIVATE_CACHE_MAP), 'cPcC' );

        if (CacheMapToFree == NULL) {
            DebugTrace( 0, 0, "Failed to allocate PrivateCacheMap\n", 0 );

            Status = STATUS_INSUFFICIENT_RESOURCES;
            goto exitfinally;
        }

    }

    //
    //  Insert the new PrivateCacheMap in the list off the SharedCacheMap.
    //

    SharedListOwned = TRUE;
    CcAcquireMasterLock( &OldIrql );

    //
    //  Now make sure there is still no PrivateCacheMap, and if so just get out.
    //

    if (FileObject->PrivateCacheMap == NULL) {

        //
        //  Is the local one already in use?
        //

        if (PrivateCacheMap->NodeTypeCode != 0) {

            //
            //  Use the one allocated above, if there is one, else go to pool now.
            //

            if (CacheMapToFree == NULL) {
                CcReleaseMasterLock( OldIrql );
                SharedListOwned = FALSE;

                goto restart2;
            }

            PrivateCacheMap = CacheMapToFree;
            CacheMapToFree = NULL;
        }

        RtlZeroMemory( PrivateCacheMap, sizeof(PRIVATE_CACHE_MAP) );

        PrivateCacheMap->NodeTypeCode = CACHE_NTC_PRIVATE_CACHE_MAP;
        PrivateCacheMap->FileObject = FileObject;
        PrivateCacheMap->ReadAheadMask = PAGE_SIZE - 1;

        //
        //  Initialize the spin lock.
        //

        KeInitializeSpinLock( &PrivateCacheMap->ReadAheadSpinLock );

        InsertTailList( &SharedCacheMap->PrivateList, &PrivateCacheMap->PrivateLinks );

        FileObject->PrivateCacheMap = PrivateCacheMap;

    } else {

        //
        //  We raced with another initializer for the same fileobject and must
        //  drop our (to this point speculative) opencount.
        //

        ASSERT( SharedCacheMap->OpenCount > 1 );

        CcDecrementOpenCount( SharedCacheMap, 'rpnI' );
        SharedCacheMap = NULL;
    }

    MustUninitialize = FALSE;

exitfinally:

    //
    //  See if we got an error and must uninitialize the SharedCacheMap
    //

    if (MustUninitialize) {

        if (!SharedListOwned) {
            CcAcquireMasterLock( &OldIrql );
        }
        if (WeSetBeingCreated) {
            if (SharedCacheMap->CreateEvent != NULL) {
                KeSetEvent( SharedCacheMap->CreateEvent, 0, FALSE );
            }
            ClearFlag(SharedCacheMap->Flags, BEING_CREATED);
        }

        //
        //  Now release our open count.
        //

        CcDecrementOpenCount( SharedCacheMap, 'umnI' );

        if ((SharedCacheMap->OpenCount == 0) &&
            !FlagOn(SharedCacheMap->Flags, WRITE_QUEUED) &&
            (SharedCacheMap->DirtyPages == 0)) {

            //
            //  It is neccesary to eliminate the structure now.  We should
            //  be guaranteed that our dereference will not result in close
            //  due to the caller's reference on the fileobject, unlike the
            //  comment in the original code, below, would indicate.
            //
            //  Not removing this structure can result in problems if the file
            //  is also mapped and the mapped page writer extends VDL. An FS
            //  will use CcSetFileSizes and cause us to issue a recursive flush
            //  of the same range, resulting in a self-colliding page flush and
            //  a deadlock.
            //
            //  We also think that file extension/truncation in the interim
            //  (if the section create failed) would result in an inconsistent
            //  "resurrected" cache map if we managed to use the one we have
            //  now.  Note CcSetFileSizes aborts if the section is NULL.
            //

            CcDeleteSharedCacheMap( SharedCacheMap, OldIrql, FALSE );

#if 0                
            //
            //  On PinAccess it is safe and necessary to eliminate
            //  the structure immediately.
            //

            if (PinAccess) {

                CcDeleteSharedCacheMap( SharedCacheMap, OldIrql, FALSE );

            //
            //  If it is not PinAccess, we must lazy delete, because
            //  we could get into a deadlock trying to acquire the
            //  stream exclusive when we dereference the file object.
            //

            } else {

                //
                //  Move it to the dirty list so the lazy write scan will
                //  see it.
                //

                RemoveEntryList( &SharedCacheMap->SharedCacheMapLinks );
                InsertTailList( &CcDirtySharedCacheMapList.SharedCacheMapLinks,
                                &SharedCacheMap->SharedCacheMapLinks );

                //
                //  Make sure the Lazy Writer will wake up, because we
                //  want him to delete this SharedCacheMap.
                //

                LazyWriter.OtherWork = TRUE;
                if (!LazyWriter.ScanActive) {
                    CcScheduleLazyWriteScan( FALSE );
                }

                CcReleaseMasterLock( OldIrql );
            }
#endif

        } else {

            CcReleaseMasterLock( OldIrql );
        }

        SharedListOwned = FALSE;

    //
    //  If we did not create this SharedCacheMap, then there is a
    //  possibility that it is in the dirty list.  Once we are sure
    //  we have the spinlock, just make sure it is in the clean list
    //  if there are no dirty bytes and the open count is nonzero.
    //  (The latter test is almost guaranteed, of course, but we check
    //  it to be safe.)
    //

    } else if (!WeCreated &&
               (SharedCacheMap != NULL)) {

        if (!SharedListOwned) {

            CcAcquireMasterLock( &OldIrql );
            SharedListOwned = TRUE;
        }

        if ((SharedCacheMap->DirtyPages == 0) &&
            (SharedCacheMap->OpenCount != 0)) {

            RemoveEntryList( &SharedCacheMap->SharedCacheMapLinks );
            InsertTailList( &CcCleanSharedCacheMapList,
                            &SharedCacheMap->SharedCacheMapLinks );
        }
    }

    //
    //  Release global resource
    //

    if (SharedListOwned) {
        CcReleaseMasterLock( OldIrql );
    }

    if (CacheMapToFree != NULL) {
        ExFreePool(CacheMapToFree);
    }

    if (!NT_SUCCESS(Status)) {
        DebugTrace(-1, me, "CcInitializeCacheMap -> RAISING EXCEPTION\n", 0 );
        ExRaiseStatus(Status);
    }

    DebugTrace(-1, me, "CcInitializeCacheMap -> VOID\n", 0 );

    return;
}


BOOLEAN
CcUninitializeCacheMap (
    IN PFILE_OBJECT FileObject,
    IN PLARGE_INTEGER TruncateSize OPTIONAL,
    IN PCACHE_UNINITIALIZE_EVENT UninitializeEvent OPTIONAL
    )

/*++

Routine Description:

    This routine uninitializes the previously initialized Shared and Private
    Cache Maps.  This routine is only intended to be called by File Systems.
    It should be called when the File System receives a cleanup call on the
    File Object.

    A File System which supports data caching must always call this routine
    whenever it closes a file, whether the caller opened the file with
    NO_INTERMEDIATE_BUFFERING as FALSE or not.  This is because the final
    cleanup of a file related to truncation or deletion of the file, can
    only occur on the last close, whether the last closer cached the file
    or not.  When CcUnitializeCacheMap is called on a file object for which
    CcInitializeCacheMap was never called, the call has a benign effect
    iff no one has truncated or deleted the file; otherwise the necessary
    cleanup relating to the truncate or close is performed.

    In summary, CcUnitializeCacheMap does the following:

        If the caller had Write or Delete access, the cache is flushed.
        (This could change with lazy writing.)

        If a Cache Map was initialized on this File Object, it is
        unitialized (unmap any views, delete section, and delete
        Cache Map structures).

        On the last Cleanup, if the file has been deleted, the
        Section is forced closed.  If the file has been truncated, then
        the truncated pages are purged from the cache.

Arguments:

    FileObject - File Object which was previously supplied to
                 CcInitializeCacheMap.

    TruncateSize - If specified, the file was truncated to the specified
                   size, and the cache should be purged accordingly.

    UninitializeEvent - If specified, then the provided event will be set
                        to the signalled state when the actual flush is
                        completed.  This is only of interest to file systems
                        that require that they be notified when a cache flush
                        operation has completed.  Due to network protocol
                        restrictions, it is critical that network file
                        systems know exactly when a cache flush operation
                        completes, by specifying this event, they can be
                        notified when the cache section is finally purged
                        if the section is "lazy-deleted".

ReturnValue:

    FALSE if Section was not closed.
    TRUE if Section was closed.

--*/

{
    KIRQL OldIrql;
    PSHARED_CACHE_MAP SharedCacheMap;
    ULONG ActivePage;
    ULONG PageIsDirty;
    PVACB ActiveVacb = NULL;
    BOOLEAN SectionClosed = FALSE;
    PPRIVATE_CACHE_MAP PrivateCacheMap;

    DebugTrace(+1, me, "CcUninitializeCacheMap:\n", 0 );
    DebugTrace( 0, me, "    FileObject = %08lx\n", FileObject );
    DebugTrace( 0, me, "    &TruncateSize = %08lx\n", TruncateSize );

    //
    //  Serialize Creation/Deletion of all Shared CacheMaps
    //

    CcAcquireMasterLock( &OldIrql );

    //
    //  Get pointer to SharedCacheMap via File Object.
    //

    SharedCacheMap = FileObject->SectionObjectPointer->SharedCacheMap;
    PrivateCacheMap = FileObject->PrivateCacheMap;

    //
    //  Decrement Open Count on SharedCacheMap, if we did a cached open.
    //  Also unmap PrivateCacheMap if it is mapped and deallocate it.
    //

    if (PrivateCacheMap != NULL) {

        ASSERT( PrivateCacheMap->FileObject == FileObject );

        CcDecrementOpenCount( SharedCacheMap, 'ninU' );

        //
        //  Remove PrivateCacheMap from list in SharedCacheMap.
        //

        RemoveEntryList( &PrivateCacheMap->PrivateLinks );

        //
        //  Free local or allocated PrivateCacheMap
        //

        if (PrivateCacheMap == &SharedCacheMap->PrivateCacheMap) {
            PrivateCacheMap->NodeTypeCode = 0;
            PrivateCacheMap = NULL;
        }

        FileObject->PrivateCacheMap = (PPRIVATE_CACHE_MAP)NULL;
    }

    //
    //  Now if we have a SharedCacheMap whose Open Count went to 0, we
    //  have some additional cleanup.
    //

    if (SharedCacheMap != NULL) {

        //
        //  If a Truncate Size was specified, then remember that we want to
        //  truncate the FileSize and purge the unneeded pages when OpenCount
        //  goes to 0.
        //

        if (ARGUMENT_PRESENT(TruncateSize)) {

            if ( (TruncateSize->QuadPart == 0) && (SharedCacheMap->FileSize.QuadPart != 0) ) {

                SetFlag(SharedCacheMap->Flags, TRUNCATE_REQUIRED);

            } else if (IsListEmpty(&SharedCacheMap->PrivateList)) {

                //
                //  If this is the last guy, I can drop the file size down
                //  now.
                //

                SharedCacheMap->FileSize = *TruncateSize;
            }
        }

        //
        //  If other file objects are still using this SharedCacheMap,
        //  then we are done now.
        //

        if (SharedCacheMap->OpenCount != 0) {

            DebugTrace(-1, me, "SharedCacheMap OpenCount != 0\n", 0);

            //
            //  If the caller specified an event to be set when
            //  the cache uninitialize is completed, set the event
            //  now, because the uninitialize is complete for this file.
            //  (Note, we make him wait if he is the last guy.)
            //

            if (ARGUMENT_PRESENT(UninitializeEvent)) {

                if (!IsListEmpty(&SharedCacheMap->PrivateList)) {
                    KeSetEvent(&UninitializeEvent->Event, 0, FALSE);
                } else {
                    UninitializeEvent->Next = SharedCacheMap->UninitializeEvent;
                    SharedCacheMap->UninitializeEvent = UninitializeEvent;
                }
            }

            CcReleaseMasterLock( OldIrql );

            //
            //  Free PrivateCacheMap now that we no longer have the spinlock.
            //

            if (PrivateCacheMap != NULL) {
                ExFreePool( PrivateCacheMap );
            }

            DebugTrace(-1, me, "CcUnitializeCacheMap -> %02lx\n", FALSE );
            return FALSE;
        }

        //
        //  Remove the private write flag synchronously.  Even though a
        //  private writer is also opening the file exclusively, the
        //  shared cache map is not going away synchronously and we
        //  cannot let a non private writer re-reference the scm in
        //  this state. Their data will never be written!
        //

        if (FlagOn(SharedCacheMap->Flags, PRIVATE_WRITE)) {

            ClearFlag(SharedCacheMap->Flags, PRIVATE_WRITE | DISABLE_WRITE_BEHIND);
            MmEnableModifiedWriteOfSection( FileObject->SectionObjectPointer );
        }

        //
        //  The private cache map list better be empty!
        //

        ASSERT(IsListEmpty(&SharedCacheMap->PrivateList));

        //
        //  Set the "uninitialize complete" in the shared cache map
        //  so that CcDeleteSharedCacheMap will delete it.
        //

        if (ARGUMENT_PRESENT(UninitializeEvent)) {
            UninitializeEvent->Next = SharedCacheMap->UninitializeEvent;
            SharedCacheMap->UninitializeEvent = UninitializeEvent;
        }

        //
        //  We are in the process of deleting this cache map.  If the
        //  Lazy Writer is active or the Bcb list is not empty or the Lazy
        //  Writer will hit this SharedCacheMap because we are purging
        //  the file to 0, then get out and let the Lazy Writer clean
        //  up.
        //

        if ((!FlagOn(SharedCacheMap->Flags, PIN_ACCESS) &&
             !ARGUMENT_PRESENT(UninitializeEvent))

                ||

            FlagOn(SharedCacheMap->Flags, WRITE_QUEUED)

                ||

            (SharedCacheMap->DirtyPages != 0)) {

            //
            //  Move it to the dirty list so the lazy write scan will
            //  see it.
            //

            if (!FlagOn(SharedCacheMap->Flags, WRITE_QUEUED)) {
                RemoveEntryList( &SharedCacheMap->SharedCacheMapLinks );
                InsertTailList( &CcDirtySharedCacheMapList.SharedCacheMapLinks,
                                &SharedCacheMap->SharedCacheMapLinks );
            }

            //
            //  Make sure the Lazy Writer will wake up, because we
            //  want him to delete this SharedCacheMap.
            //

            LazyWriter.OtherWork = TRUE;
            if (!LazyWriter.ScanActive) {
                CcScheduleLazyWriteScan( FALSE );
            }

            //
            //  Get the active Vacb if we are going to lazy delete, to
            //  free it for someone who can use it.
            //

            GetActiveVacbAtDpcLevel( SharedCacheMap, ActiveVacb, ActivePage, PageIsDirty );

            DebugTrace(-1, me, "SharedCacheMap has Bcbs and not purging to 0\n", 0);

            CcReleaseMasterLock( OldIrql );
            ASSERT (SectionClosed == FALSE);
        }
        else {

            //
            //  Now we can delete the SharedCacheMap.  If there are any Bcbs,
            //  then we must be truncating to 0, and they will also be deleted.
            //  On return the Shared Cache Map List Spinlock will be released.
            //

            CcDeleteSharedCacheMap( SharedCacheMap, OldIrql, FALSE );

            SectionClosed = TRUE;
        }
    }

    //
    //  No Shared Cache Map.  To make the file go away, we still need to
    //  purge the section, if one exists.  (And we still need to release
    //  our global list first to avoid deadlocks.)
    //

    else {
        if (ARGUMENT_PRESENT(TruncateSize) &&
            ( TruncateSize->QuadPart == 0 ) &&
            (*(PCHAR *)FileObject->SectionObjectPointer != NULL)) {

            CcReleaseMasterLock( OldIrql );

            DebugTrace( 0, mm, "MmPurgeSection:\n", 0 );
            DebugTrace( 0, mm, "    SectionObjectPointer = %08lx\n",
                        FileObject->SectionObjectPointer );
            DebugTrace2(0, mm, "    Offset = %08lx\n",
                        TruncateSize->LowPart,
                        TruncateSize->HighPart );

            //
            //  0 Length means to purge from the TruncateSize on.
            //

            CcPurgeCacheSection( FileObject->SectionObjectPointer,
                                 TruncateSize,
                                 0,
                                 FALSE );
        }
        else {
            CcReleaseMasterLock( OldIrql );
        }

        //
        //  If the caller specified an event to be set when
        //  the cache uninitialize is completed, set the event
        //  now, because the uninitialize is complete for this file.
        //

        if (ARGUMENT_PRESENT(UninitializeEvent)) {
            KeSetEvent(&UninitializeEvent->Event, 0, FALSE);
        }
    }

    //
    //  Free the active vacb, if we found one.
    //

    if (ActiveVacb != NULL) {

        CcFreeActiveVacb( ActiveVacb->SharedCacheMap, ActiveVacb, ActivePage, PageIsDirty );
    }

    //
    //  Free PrivateCacheMap now that we no longer have the spinlock.
    //

    if (PrivateCacheMap != NULL) {
        ExFreePool( PrivateCacheMap );
    }

    DebugTrace(-1, me, "CcUnitializeCacheMap -> %02lx\n", SectionClosed );

    return SectionClosed;
}


//
//  Internal support routine.
//

VOID
CcDeleteBcbs (
    IN PSHARED_CACHE_MAP SharedCacheMap
    )

/*++

Routine Description:

    This routine may be called to delete all Bcbs for a stream.
    
    External synchronization must be acquired to guarantee no
    active pin on any bcb.

Arguments:

    SharedCacheMap - Pointer to SharedCacheMap.

Return Value:

    None.

--*/

{
    KIRQL OldIrql;
    PLIST_ENTRY NextEntry;
    PBCB Bcb;

    //
    //  If there are Bcbs, then empty the list. None of them can be pinned now!
    //  Either the file is being truncated, in which case synchronization with
    //  the lazy writer must have been externally acheived, or the file is being
    //  closed down and nothing should be able to get a fresh reference on this
    //  shared cache map.
    //

    NextEntry = SharedCacheMap->BcbList.Flink;
    while (NextEntry != &SharedCacheMap->BcbList) {

        Bcb = (PBCB)CONTAINING_RECORD( NextEntry,
                                       BCB,
                                       BcbLinks );
        NextEntry = Bcb->BcbLinks.Flink;

        //
        //  Skip over the pendaflex entries, only removing true Bcbs
        //  so that level teardown doesn't need to special case unhooking
        //  the pendaflex.  This has the side benefit of dramatically
        //  reducing write traffic to memory on teardown of large files.
        //

        if (Bcb->NodeTypeCode == CACHE_NTC_BCB) {

            ASSERT( Bcb->PinCount == 0 );

            RemoveEntryList( &Bcb->BcbLinks );

            //
            //  For large metadata streams we unlock the Vacb level when
            //  removing.  We do not need spinlocks since no other thread
            //  can be accessing this list when we are deleting the
            //  SharedCacheMap.
            //

            CcUnlockVacbLevel( SharedCacheMap, Bcb->FileOffset.QuadPart );

            //
            //  There is a small window where the data could still be mapped
            //  if (for example) the Lazy Writer collides with a CcCopyWrite
            //  in the foreground, and then someone calls CcUninitializeCacheMap
            //  while the Lazy Writer is active.  This is because the Lazy
            //  Writer biases the pin count.  Deal with that here.
            //

            if (Bcb->BaseAddress != NULL) {
                CcFreeVirtualAddress( Bcb->Vacb );
            }

#if LIST_DBG
            //
            //  Debug routines used to remove Bcbs from the global list
            //

            OldIrql = KeAcquireQueuedSpinLock( LockQueueBcbLock );

            if (Bcb->CcBcbLinks.Flink != NULL) {

                RemoveEntryList( &Bcb->CcBcbLinks );
                CcBcbCount -= 1;
            }

            KeReleaseQueuedSpinLock( LockQueueBcbLock, OldIrql );
#endif

            //
            //  If the Bcb is dirty, we have to synchronize with the Lazy Writer
            //  and reduce the total number of dirty.
            //

            CcAcquireMasterLock( &OldIrql );
            if (Bcb->Dirty) {
                CcDeductDirtyPages( SharedCacheMap,  Bcb->ByteLength >> PAGE_SHIFT );
            }
            CcReleaseMasterLock( OldIrql );

            CcDeallocateBcb( Bcb );
        }
    }
}


//
//  Internal support routine.
//

VOID
FASTCALL
CcDeleteSharedCacheMap (
    IN PSHARED_CACHE_MAP SharedCacheMap,
    IN KIRQL ListIrql,
    IN ULONG ReleaseFile
    )

/*++

Routine Description:

    The specified SharedCacheMap is removed from the global list of
    SharedCacheMap's and deleted with all of its related structures.
    Other objects which were referenced in CcInitializeCacheMap are
    dereferenced here.

    NOTE:   The CcMasterSpinLock must already be acquired
            on entry.  It is released on return.

Arguments:

    SharedCacheMap - Pointer to Cache Map to delete

    ListIrql - priority to restore to when releasing shared cache map list

    ReleaseFile - Supplied as nonzero if file was acquired exclusive and
                  should be released.

ReturnValue:

    None.

--*/

{
    LIST_ENTRY LocalList;
    PFILE_OBJECT FileObject;
    PVACB ActiveVacb;
    ULONG ActivePage;
    ULONG PageIsDirty;

    DebugTrace(+1, me, "CcDeleteSharedCacheMap:\n", 0 );
    DebugTrace( 0, me, "    SharedCacheMap = %08lx\n", SharedCacheMap );

    //
    //  Remove it from the global list and clear the pointer to it via
    //  the File Object.
    //

    RemoveEntryList( &SharedCacheMap->SharedCacheMapLinks );

    //
    //  Zero pointer to SharedCacheMap.  Once we have cleared the pointer,
    //  we can/must release the global list to avoid deadlocks.
    //

    FileObject = SharedCacheMap->FileObject;

    FileObject->SectionObjectPointer->SharedCacheMap = (PSHARED_CACHE_MAP)NULL;
    SetFlag( SharedCacheMap->Flags, WRITE_QUEUED );

    //
    //  The OpenCount is 0, but we still need to flush out any dangling
    //  cache read or writes.
    //

    if ((SharedCacheMap->VacbActiveCount != 0) || (SharedCacheMap->NeedToZero != NULL)) {

        //
        //  We will put it in a local list and set a flag
        //  to keep the Lazy Writer away from it, so that we can rip it out
        //  below if someone manages to sneak in and set something dirty, etc.
        //  If the file system does not synchronize cleanup calls with an
        //  exclusive on the stream, then this case is possible.
        //

        InitializeListHead( &LocalList );
        InsertTailList( &LocalList, &SharedCacheMap->SharedCacheMapLinks );

        //
        //  If there is an active Vacb, then nuke it now (before waiting!).
        //

        GetActiveVacbAtDpcLevel( SharedCacheMap, ActiveVacb, ActivePage, PageIsDirty );

        CcReleaseMasterLock( ListIrql );

        //
        //  No point in saying the page is dirty (which can cause an allocation
        //  failure), since we are deleting this SharedCacheMap anyway.
        //

        CcFreeActiveVacb( SharedCacheMap, ActiveVacb, ActivePage, FALSE );

        while (SharedCacheMap->VacbActiveCount != 0) {
            CcWaitOnActiveCount( SharedCacheMap );
        }

        //
        //  Now in case we hit the rare path where someone moved the
        //  SharedCacheMap again, do a remove again now.  It may be
        //  from our local list or it may be from the dirty list,
        //  but who cares?  The important thing is to remove it in
        //  the case it was the dirty list, since we will delete it
        //  below.
        //

        CcAcquireMasterLock( &ListIrql );
        RemoveEntryList( &SharedCacheMap->SharedCacheMapLinks );
    }

    CcReleaseMasterLock( ListIrql );

    //
    //  If there are Bcbs, then empty the list.
    //
    //  I really wonder how often we have Bcbs at teardown.  This is
    //  a lot of work that could be avoided otherwise.
    //

    if (!IsListEmpty( &SharedCacheMap->BcbList )) {
        CcDeleteBcbs( SharedCacheMap );
    }

    //
    //  Call local routine to unmap, and purge if necessary.
    //

    CcUnmapAndPurge( SharedCacheMap );

    //
    //  Now release the file now that the purge is done.
    //

    if (ReleaseFile) {
        FsRtlReleaseFile( SharedCacheMap->FileObject );
    }

    //
    //  Dereference our pointer to the Section and FileObject
    //  (We have to test the Section pointer since CcInitializeCacheMap
    //  calls this routine for error recovery.  Release our global
    //  resource before dereferencing the FileObject to avoid deadlocks.
    //

    if (SharedCacheMap->Section != NULL) {
        ObDereferenceObject( SharedCacheMap->Section );
    }
    ObDereferenceObject( FileObject );

    //
    //  If there is an Mbcb, deduct any dirty pages and deallocate.
    //

    if (SharedCacheMap->Mbcb != NULL) {
        CcDeleteMbcb( SharedCacheMap );
    }

    //
    //  If there was an uninitialize event specified for this shared cache
    //  map, then set it to the signalled state, indicating that we are
    //  removing the section and deleting the shared cache map.
    //

    if (SharedCacheMap->UninitializeEvent != NULL) {
        PCACHE_UNINITIALIZE_EVENT CUEvent, EventNext;

        CUEvent = SharedCacheMap->UninitializeEvent;
        while (CUEvent != NULL) {
            EventNext = CUEvent->Next;
            KeSetEvent(&CUEvent->Event, 0, FALSE);
            CUEvent = EventNext;
        }
    }

    //
    //  Now delete the Vacb vector.
    //

    if ((SharedCacheMap->Vacbs != &SharedCacheMap->InitialVacbs[0])

            &&

        (SharedCacheMap->Vacbs != NULL)) {

        //
        //  If there are Vacb levels, then the Vacb Array better be in an empty state.
        //

        ASSERT((SharedCacheMap->SectionSize.QuadPart <= VACB_SIZE_OF_FIRST_LEVEL) ||
               !IsVacbLevelReferenced( SharedCacheMap, SharedCacheMap->Vacbs, 1 ));

        ExFreePool( SharedCacheMap->Vacbs );
    }

    //
    //  If an event had to be allocated for this SharedCacheMap,
    //  deallocate it.
    //

    if ((SharedCacheMap->CreateEvent != NULL) && (SharedCacheMap->CreateEvent != &SharedCacheMap->Event)) {
        ExFreePool( SharedCacheMap->CreateEvent );
    }

    if ((SharedCacheMap->WaitOnActiveCount != NULL) && (SharedCacheMap->WaitOnActiveCount != &SharedCacheMap->Event)) {
        ExFreePool( SharedCacheMap->WaitOnActiveCount );
    }

    //
    //  Deallocate the storeage for the SharedCacheMap.
    //

    ExFreePool( SharedCacheMap );

    DebugTrace(-1, me, "CcDeleteSharedCacheMap -> VOID\n", 0 );

    return;

}


VOID
CcSetFileSizes (
    IN PFILE_OBJECT FileObject,
    IN PCC_FILE_SIZES FileSizes
    )

/*++

Routine Description:

    This routine must be called whenever a file has been extended to reflect
    this extension in the cache maps and underlying section.  Calling this
    routine has a benign effect if the current size of the section is
    already greater than or equal to the new AllocationSize.

    This routine must also be called whenever the FileSize for a file changes
    to reflect these changes in the Cache Manager.

    This routine seems rather large, but in the normal case it only acquires
    a spinlock, updates some fields, and exits.  Less often it will either
    extend the section, or truncate/purge the file, but it would be unexpected
    to do both.  On the other hand, the idea of this routine is that it does
    "everything" required when AllocationSize or FileSize change.

Arguments:

    FileObject - A file object for which CcInitializeCacheMap has been
                 previously called.

    FileSizes - A pointer to AllocationSize, FileSize and ValidDataLength
                for the file.  AllocationSize is ignored if it is not larger
                than the current section size (i.e., it is ignored unless it
                has grown).  ValidDataLength is not used.


Return Value:

    None

--*/

{
    LARGE_INTEGER NewSectionSize;
    LARGE_INTEGER NewFileSize;
    LARGE_INTEGER NewValidDataLength;
    IO_STATUS_BLOCK IoStatus;
    PSHARED_CACHE_MAP SharedCacheMap;
    NTSTATUS Status;
    KIRQL OldIrql;
    PVACB ActiveVacb;
    ULONG ActivePage;
    ULONG PageIsDirty;

    DebugTrace(+1, me, "CcSetFileSizes:\n", 0 );
    DebugTrace( 0, me, "    FileObject = %08lx\n", FileObject );
    DebugTrace( 0, me, "    FileSizes = %08lx\n", FileSizes );

    //
    //  Make a local copy of the new file size and section size.
    //

    NewSectionSize = FileSizes->AllocationSize;
    NewFileSize = FileSizes->FileSize;
    NewValidDataLength = FileSizes->ValidDataLength;

    //
    //  Serialize Creation/Deletion of all Shared CacheMaps
    //

    CcAcquireMasterLock( &OldIrql );

    //
    //  Get pointer to SharedCacheMap via File Object.
    //

    SharedCacheMap = FileObject->SectionObjectPointer->SharedCacheMap;

    //
    //  If the file is not cached, just get out.
    //

    if ((SharedCacheMap == NULL) || (SharedCacheMap->Section == NULL)) {

        CcReleaseMasterLock( OldIrql );

        //
        //  Let's try to purge the file incase this is a truncate.  In the
        //  vast majority of cases when there is no shared cache map, there
        //  is no data section either, so this call will eventually be
        //  no-oped in Mm.
        //
        //  First flush the first page we are keeping, if it has data, before
        //  we throw it away.
        //

        if (NewFileSize.LowPart & (PAGE_SIZE - 1)) {
            MmFlushSection( FileObject->SectionObjectPointer, &NewFileSize, 1, &IoStatus, FALSE );
        }

        CcPurgeCacheSection( FileObject->SectionObjectPointer,
                             &NewFileSize,
                             0,
                             FALSE );

        DebugTrace(-1, me, "CcSetFileSizes -> VOID\n", 0 );

        return;
    }

    //
    //  Make call a Noop if file is not mapped, or section already big enough.
    //

    if ( NewSectionSize.QuadPart > SharedCacheMap->SectionSize.QuadPart ) {

        //
        //  Increment open count to make sure the SharedCacheMap stays around,
        //  then release the spinlock so that we can call Mm.
        //

        CcIncrementOpenCount( SharedCacheMap, '1fSS' );
        CcReleaseMasterLock( OldIrql );

        //
        //  Round new section size to pages.
        //

        NewSectionSize.QuadPart = NewSectionSize.QuadPart + (LONGLONG)(DEFAULT_EXTEND_MODULO - 1);
        NewSectionSize.LowPart &= ~(DEFAULT_EXTEND_MODULO - 1);

        //
        //  Call MM to extend the section.
        //

        DebugTrace( 0, mm, "MmExtendSection:\n", 0 );
        DebugTrace( 0, mm, "    Section = %08lx\n", SharedCacheMap->Section );
        DebugTrace2(0, mm, "    Size = %08lx, %08lx\n",
                    NewSectionSize.LowPart, NewSectionSize.HighPart );

        Status = MmExtendSection( SharedCacheMap->Section, &NewSectionSize, TRUE );

        if (NT_SUCCESS(Status)) {

            //
            //  Extend the Vacb array.
            //

            Status = CcExtendVacbArray( SharedCacheMap, NewSectionSize );
        }
        else {

            DebugTrace( 0, 0, "Error from MmExtendSection, Status = %08lx\n",
                        Status );

            Status = FsRtlNormalizeNtstatus( Status,
                                             STATUS_UNEXPECTED_MM_EXTEND_ERR );
        }

        //
        //  Serialize again to decrement the open count.
        //

        CcAcquireMasterLock( &OldIrql );

        CcDecrementOpenCount( SharedCacheMap, '1fSF' );

        if ((SharedCacheMap->OpenCount == 0) &&
            !FlagOn(SharedCacheMap->Flags, WRITE_QUEUED) &&
            (SharedCacheMap->DirtyPages == 0)) {

            //
            //  Move to the dirty list.
            //

            RemoveEntryList( &SharedCacheMap->SharedCacheMapLinks );
            InsertTailList( &CcDirtySharedCacheMapList.SharedCacheMapLinks,
                            &SharedCacheMap->SharedCacheMapLinks );

            //
            //  Make sure the Lazy Writer will wake up, because we
            //  want him to delete this SharedCacheMap.
            //

            LazyWriter.OtherWork = TRUE;
            if (!LazyWriter.ScanActive) {
                CcScheduleLazyWriteScan( FALSE );
            }
        }

        //
        //  If section or VACB extension failed, raise an
        //  exception to our caller.
        //

        if (!NT_SUCCESS(Status)) {
            CcReleaseMasterLock( OldIrql );
            ExRaiseStatus( Status );
        }

        //
        //  It is now very unlikely that we have any more work to do, but since
        //  the spinlock is already held, check again if we are cached.
        //

        //
        //  Get pointer to SharedCacheMap via File Object.
        //

        SharedCacheMap = FileObject->SectionObjectPointer->SharedCacheMap;

        //
        //  If the file is not cached, just get out.
        //

        if (SharedCacheMap == NULL) {

            CcReleaseMasterLock( OldIrql );

            DebugTrace(-1, me, "CcSetFileSizes -> VOID\n", 0 );

            return;
        }
    }

    //
    //  If we are shrinking either of these two sizes, then we must free the
    //  active page, since it may be locked.
    //

    CcIncrementOpenCount( SharedCacheMap, '2fSS' );

    if ( ( NewFileSize.QuadPart < SharedCacheMap->ValidDataGoal.QuadPart ) ||
         ( NewFileSize.QuadPart < SharedCacheMap->FileSize.QuadPart )) {

        GetActiveVacbAtDpcLevel( SharedCacheMap, ActiveVacb, ActivePage, PageIsDirty );

        if ((ActiveVacb != NULL) || (SharedCacheMap->NeedToZero != NULL)) {

            CcReleaseMasterLock( OldIrql );

            CcFreeActiveVacb( SharedCacheMap, ActiveVacb, ActivePage, PageIsDirty );

            //
            //  Serialize again to reduce ValidDataLength.  It cannot change
            //  because the caller must have the file exclusive.
            //

            CcAcquireMasterLock( &OldIrql );
        }
    }

    //
    //  If the section did not grow, see if the file system supports
    //  ValidDataLength, then update the valid data length in the file system.
    //

    if ( SharedCacheMap->ValidDataLength.QuadPart != MAXLONGLONG ) {

        if ( NewFileSize.QuadPart < SharedCacheMap->ValidDataLength.QuadPart ) {
            SharedCacheMap->ValidDataLength = NewFileSize;
        }

        //
        //  Update our notion of ValidDataGoal (how far the file has been
        //  written in the cache) with caller's ValidDataLength.  (Our
        //  ValidDataLength controls when we issue ValidDataLength callbacks.)
        //

        SharedCacheMap->ValidDataGoal = NewValidDataLength;
    }

    //
    //  On truncate, be nice guys and actually purge away user data from
    //  the cache.  However, the PinAccess check is important to avoid deadlocks
    //  in Ntfs.
    //
    //  It is also important to check the Vacb Active count.  The caller
    //  must have the file exclusive, therefore, no one else can be actively
    //  doing anything in the file.  Normally the Active count will be zero
    //  (like in a normal call from Set File Info), and we can go ahead and
    //  truncate.  However, if the active count is nonzero, chances are this
    //  very thread has something pinned or mapped, and we will deadlock if
    //  we try to purge and wait for the count to go zero.  A rare case of
    //  this which deadlocked DaveC on Christmas Day of 1992, is where Ntfs
    //  was trying to convert an attribute from resident to nonresident - which
    //  is a good example of a case where the purge was not needed.
    //

    if ( (NewFileSize.QuadPart < SharedCacheMap->FileSize.QuadPart ) &&
        !FlagOn(SharedCacheMap->Flags, PIN_ACCESS) &&
        (SharedCacheMap->VacbActiveCount == 0)) {

        //
        //  Release the spinlock so that we can call Mm.
        //

        CcReleaseMasterLock( OldIrql );

        //
        //  If we are actually truncating to zero (a size which has particular
        //  meaning to the Lazy Writer scan!) then we must reset the Mbcb/Bcbs,
        //  if there are any, so that we do not keep dirty pages around forever.
        //

        if (NewFileSize.QuadPart == 0) {
            if (SharedCacheMap->Mbcb != NULL) {
                CcDeleteMbcb( SharedCacheMap );
            }
            if (!IsListEmpty( &SharedCacheMap->BcbList )) {
                CcDeleteBcbs( SharedCacheMap );
            }
        }

        CcPurgeAndClearCacheSection( SharedCacheMap, &NewFileSize );

        //
        //  Serialize again to decrement the open count.
        //

        CcAcquireMasterLock( &OldIrql );
    }

    CcDecrementOpenCount( SharedCacheMap, '2fSF' );

    SharedCacheMap->FileSize = NewFileSize;

    if ((SharedCacheMap->OpenCount == 0) &&
        !FlagOn(SharedCacheMap->Flags, WRITE_QUEUED) &&
        (SharedCacheMap->DirtyPages == 0)) {

        //
        //  Move to the dirty list.
        //

        RemoveEntryList( &SharedCacheMap->SharedCacheMapLinks );
        InsertTailList( &CcDirtySharedCacheMapList.SharedCacheMapLinks,
                        &SharedCacheMap->SharedCacheMapLinks );

        //
        //  Make sure the Lazy Writer will wake up, because we
        //  want him to delete this SharedCacheMap.
        //

        LazyWriter.OtherWork = TRUE;
        if (!LazyWriter.ScanActive) {
            CcScheduleLazyWriteScan( FALSE );
        }
    }

    CcReleaseMasterLock( OldIrql );

    DebugTrace(-1, me, "CcSetFileSizes -> VOID\n", 0 );

    return;
}


VOID
CcPurgeAndClearCacheSection (
    IN PSHARED_CACHE_MAP SharedCacheMap,
    IN PLARGE_INTEGER FileOffset
    )

/*++

Routine Description:

    This routine calls CcPurgeCacheSection after zeroing the end any
    partial page at the start of the range.  If the file is not cached
    it flushes this page before the purge.

Arguments:

    SectionObjectPointer - A pointer to the Section Object Pointers
                           structure in the nonpaged Fcb.

    FileOffset - Offset from which file should be purged - rounded down
               to page boundary.  If NULL, purge the entire file.

ReturnValue:

    FALSE - if the section was not successfully purged
    TRUE - if the section was successfully purged

--*/

{
    ULONG TempLength, Length;
    LARGE_INTEGER LocalFileOffset;
    IO_STATUS_BLOCK IoStatus;
    PVOID TempVa;
    PVACB Vacb;

    //
    //  Awareness is indicated by the lowbit of the fileoffset pointer.
    //  Non-awareness of a private write stream results in a no-op.
    //

    if (FlagOn( SharedCacheMap->Flags, PRIVATE_WRITE )) {

        if (((ULONG_PTR)FileOffset & 1) == 0) {
            return;
        }

        FileOffset = (PLARGE_INTEGER)((ULONG_PTR)FileOffset ^ 1);
    }

    //
    //  If a range was specified, then we have to see if we need to
    //  save any user data before purging.
    //

    if ((FileOffset->LowPart & (PAGE_SIZE - 1)) != 0) {

        //
        //  Switch to LocalFileOffset.  We do it this way because we
        //  still pass it on as an optional parameter.
        //

        LocalFileOffset = *FileOffset;
        FileOffset = &LocalFileOffset;

        //
        //  If the file is cached, then we can actually zero the data to
        //  be purged in memory, and not purge those pages.  This is a huge
        //  savings, because sometimes the flushes in the other case cause
        //  us to kill lots of stack, time and I/O doing CcZeroData in especially
        //  large user-mapped files.
        //

        if ((SharedCacheMap->Section != NULL) &&
            (SharedCacheMap->Vacbs != NULL)) {

            //
            //  First zero the first page we are keeping, if it has data, and
            //  adjust FileOffset and Length to allow it to stay.
            //

            TempLength = PAGE_SIZE - (FileOffset->LowPart & (PAGE_SIZE - 1));

            TempVa = CcGetVirtualAddress( SharedCacheMap, *FileOffset, &Vacb, &Length );

            //
            //  Do not map and zero the page if we are not reducing our notion
            //  of Valid Data, because that does two bad things.  First
            //  CcSetDirtyInMask will arbitrarily smash up ValidDataGoal
            //  (causing a potential invalid CcSetValidData call).  Secondly,
            //  if the Lazy Writer writes the last page ahead of another flush
            //  through MM, then the file system will never see a write from
            //  MM, and will not include the last page in ValidDataLength on
            //  disk.
            //

            RtlZeroMemory( TempVa, TempLength );

            if (FileOffset->QuadPart <= SharedCacheMap->ValidDataGoal.QuadPart) {

                //
                //  Make sure the Lazy Writer writes it.
                //

                CcSetDirtyInMask( SharedCacheMap, FileOffset, TempLength );

            //
            //  Otherwise, we are mapped, so make sure at least that Mm
            //  knows the page is dirty since we zeroed it.
            //

            } else {

                MmSetAddressRangeModified( TempVa, 1 );
            }

            FileOffset->QuadPart += (LONGLONG)TempLength;

            //
            //  If we get any kind of error, like failing to read the page from
            //  the network, just charge on.  Note that we only read it in order
            //  to zero it and avoid the flush below, so if we cannot read it
            //  there is really no stale data problem.
            //

            CcFreeVirtualAddress( Vacb );

        } else {

            //
            //  First flush the first page we are keeping, if it has data, before
            //  we throw it away.
            //

            MmFlushSection( SharedCacheMap->FileObject->SectionObjectPointer, FileOffset, 1, &IoStatus, FALSE );
        }
    }

    CcPurgeCacheSection( SharedCacheMap->FileObject->SectionObjectPointer,
                         FileOffset,
                         0,
                         FALSE );
}


BOOLEAN
CcPurgeCacheSection (
    IN PSECTION_OBJECT_POINTERS SectionObjectPointer,
    IN PLARGE_INTEGER FileOffset,
    IN ULONG Length,
    IN BOOLEAN UninitializeCacheMaps
    )

/*++

Routine Description:

    This routine may be called to force a purge of the cache section,
    even if it is cached.  Note, if a user has the file mapped, then the purge
    will *not* take effect, and this must be considered part of normal application
    interaction.  The purpose of purge is to throw away potentially nonzero
    data, so that it will be read in again and presumably zeroed.  This is
    not really a security issue, but rather an effort to not confuse the
    application when it sees nonzero data.  We cannot help the fact that
    a user-mapped view forces us to hang on to stale data.

    This routine is intended to be called whenever previously written
    data is being truncated from the file, and the file is not being
    deleted.

    The file must be acquired exclusive in order to call this routine.

Arguments:

    SectionObjectPointer - A pointer to the Section Object Pointers
                           structure in the nonpaged Fcb.

    FileOffset - Offset from which file should be purged - rounded down
               to page boundary.  If NULL, purge the entire file.

    Length - Defines the length of the byte range to purge, starting at
             FileOffset.  This parameter is ignored if FileOffset is
             specified as NULL.  If FileOffset is specified and Length
             is 0, then purge from FileOffset to the end of the file.

    UninitializeCacheMaps - If TRUE, we should uninitialize all the private
                            cache maps before purging the data.

ReturnValue:

    FALSE - if the section was not successfully purged
    TRUE - if the section was successfully purged

--*/

{
    KIRQL OldIrql;
    PSHARED_CACHE_MAP SharedCacheMap;
    PPRIVATE_CACHE_MAP PrivateCacheMap;
    ULONG ActivePage;
    ULONG PageIsDirty;
    BOOLEAN PurgeWorked = TRUE;
    PVACB Vacb = NULL;

    DebugTrace(+1, me, "CcPurgeCacheSection:\n", 0 );
    DebugTrace( 0, mm, "    SectionObjectPointer = %08lx\n", SectionObjectPointer );
    DebugTrace2(0, me, "    FileOffset = %08lx, %08lx\n",
                            ARGUMENT_PRESENT(FileOffset) ? FileOffset->LowPart
                                                         : 0,
                            ARGUMENT_PRESENT(FileOffset) ? FileOffset->HighPart
                                                         : 0 );
    DebugTrace( 0, me, "    Length = %08lx\n", Length );


    //
    //  If you want us to uninitialize cache maps, the RtlZeroMemory paths
    //  below depend on actually having to purge something after zeroing.
    //

    ASSERT(!UninitializeCacheMaps || (Length == 0) || (Length >= PAGE_SIZE * 2));

    //
    //  Serialize Creation/Deletion of all Shared CacheMaps
    //

    CcAcquireMasterLock( &OldIrql );

    //
    //  Get pointer to SharedCacheMap via File Object.
    //

    SharedCacheMap = SectionObjectPointer->SharedCacheMap;

    //
    //  Increment open count to make sure the SharedCacheMap stays around,
    //  then release the spinlock so that we can call Mm.
    //

    if (SharedCacheMap != NULL) {

        //
        //  Awareness is indicated by the lowbit of the fileoffset pointer.
        //  Non-awareness of a private write stream results in a no-op.
        //

        if (FlagOn( SharedCacheMap->Flags, PRIVATE_WRITE )) {

            if (((ULONG_PTR)FileOffset & 1) == 0) {

                CcReleaseMasterLock( OldIrql );
                return TRUE;
            }

            FileOffset = (PLARGE_INTEGER)((ULONG_PTR)FileOffset ^ 1);
        }

        CcIncrementOpenCount( SharedCacheMap, 'scPS' );

        //
        //  If there is an active Vacb, then nuke it now (before waiting!).
        //

        GetActiveVacbAtDpcLevel( SharedCacheMap, Vacb, ActivePage, PageIsDirty );
    }

    CcReleaseMasterLock( OldIrql );

    if (Vacb != NULL) {

        CcFreeActiveVacb( SharedCacheMap, Vacb, ActivePage, PageIsDirty );
    }

    //
    //  Increment open count to make sure the SharedCacheMap stays around,
    //  then release the spinlock so that we can call Mm.
    //

    if (SharedCacheMap != NULL) {

        //
        // Now loop to make sure that no one is currently caching the file.
        //

        if (UninitializeCacheMaps) {

            while (!IsListEmpty( &SharedCacheMap->PrivateList )) {

                PrivateCacheMap = CONTAINING_RECORD( SharedCacheMap->PrivateList.Flink,
                                                     PRIVATE_CACHE_MAP,
                                                     PrivateLinks );

                CcUninitializeCacheMap( PrivateCacheMap->FileObject, NULL, NULL );
            }
        }

        //
        //  Now, let's unmap and purge here.
        //
        //  We still need to wait for any dangling cache read or writes.
        //
        //  In fact we have to loop and wait because the lazy writer can
        //  sneak in and do an CcGetVirtualAddressIfMapped, and we are not
        //  synchronized.
        //

        while ((SharedCacheMap->Vacbs != NULL) &&
               !CcUnmapVacbArray( SharedCacheMap, FileOffset, Length, FALSE )) {

            CcWaitOnActiveCount( SharedCacheMap );
        }
    }

    //
    //  Purge failures are extremely rare if there are no user mapped sections.
    //  However, it is possible that we will get one from our own mapping, if
    //  the file is being lazy deleted from a previous open.  For that case
    //  we wait here until the purge succeeds, so that we are not left with
    //  old user file data.  Although Length is actually invariant in this loop,
    //  we do need to keep checking that we are allowed to truncate in case a
    //  user maps the file during a delay.
    //

    while (!(PurgeWorked = MmPurgeSection(SectionObjectPointer,
                                          FileOffset,
                                          Length,
                                          (BOOLEAN)((SharedCacheMap !=NULL) &&
                                                    ARGUMENT_PRESENT(FileOffset)))) &&
           (Length == 0) &&
           MmCanFileBeTruncated(SectionObjectPointer, FileOffset)) {

        (VOID)KeDelayExecutionThread( KernelMode, FALSE, &CcCollisionDelay );
    }

    //
    //  Reduce the open count on the SharedCacheMap if there was one.
    //

    if (SharedCacheMap != NULL) {

        //
        //  Serialize again to decrement the open count.
        //

        CcAcquireMasterLock( &OldIrql );

        CcDecrementOpenCount( SharedCacheMap, 'scPF' );

        if ((SharedCacheMap->OpenCount == 0) &&
            !FlagOn(SharedCacheMap->Flags, WRITE_QUEUED) &&
            (SharedCacheMap->DirtyPages == 0)) {

            //
            //  Move to the dirty list.
            //

            RemoveEntryList( &SharedCacheMap->SharedCacheMapLinks );
            InsertTailList( &CcDirtySharedCacheMapList.SharedCacheMapLinks,
                            &SharedCacheMap->SharedCacheMapLinks );

            //
            //  Make sure the Lazy Writer will wake up, because we
            //  want him to delete this SharedCacheMap.
            //

            LazyWriter.OtherWork = TRUE;
            if (!LazyWriter.ScanActive) {
                CcScheduleLazyWriteScan( FALSE );
            }
        }

        CcReleaseMasterLock( OldIrql );
    }

    DebugTrace(-1, me, "CcPurgeCacheSection -> %02lx\n", PurgeWorked );

    return PurgeWorked;
}


//
//  Internal support routine.
//

VOID
CcUnmapAndPurge(
    IN PSHARED_CACHE_MAP SharedCacheMap
    )

/*++

Routine Description:

    This routine may be called to unmap and purge a section, causing Memory
    Management to throw the pages out and reset his notion of file size.

Arguments:

    SharedCacheMap - Pointer to SharedCacheMap of section to purge.

Return Value:

    None.

--*/

{
    PFILE_OBJECT FileObject;

    FileObject = SharedCacheMap->FileObject;

    //
    //  Unmap all Vacbs
    //

    if (SharedCacheMap->Vacbs != NULL) {
        (VOID)CcUnmapVacbArray( SharedCacheMap, NULL, 0, FALSE );
    }

    //
    //  Now that the file is unmapped, we can purge the truncated
    //  pages from memory, if TRUNCATE_REQUIRED.  Note that since the
    //  entire section is being purged (FileSize == NULL), the purge
    //  and subsequent delete  of the SharedCacheMap should drop
    //  all references on the section and file object clearing the
    //  way for the Close Call and actual file delete to occur
    //  immediately.
    //

    if (FlagOn(SharedCacheMap->Flags, TRUNCATE_REQUIRED)) {

        DebugTrace( 0, mm, "MmPurgeSection:\n", 0 );
        DebugTrace( 0, mm, "    SectionObjectPointer = %08lx\n",
                    FileObject->SectionObjectPointer );
        DebugTrace2(0, mm, "    Offset = %08lx\n",
                    SharedCacheMap->FileSize.LowPart,
                    SharedCacheMap->FileSize.HighPart );

        CcPurgeCacheSection( FileObject->SectionObjectPointer,
                             NULL,
                             0,
                             FALSE );
    }
}


VOID
CcDeleteMbcb(
    IN PSHARED_CACHE_MAP SharedCacheMap
    )

/*++

Routine Description:

    This routine may be called to reset the Mbcb for a stream to say
    there are no dirty pages, and free all auxillary allocation.

Arguments:

    SharedCacheMap - Pointer to SharedCacheMap.

Return Value:

    None.

--*/

{
    PMBCB Mbcb;
    PBITMAP_RANGE BitmapRange;
    KLOCK_QUEUE_HANDLE LockHandle;
    ULONG DoDrain = FALSE;
    PLIST_ENTRY NextEntry;
    LIST_ENTRY BitmapRangesToFree;

    InitializeListHead( &BitmapRangesToFree );

    KeAcquireInStackQueuedSpinLock( &SharedCacheMap->BcbSpinLock, &LockHandle );

    Mbcb = SharedCacheMap->Mbcb;

    //
    //  Is there an Mbcb?
    //

    if (Mbcb != NULL) {

        //
        //  First deduct the dirty pages we are getting rid of.
        //

        CcAcquireMasterLockAtDpcLevel();
        CcDeductDirtyPages( SharedCacheMap, Mbcb->DirtyPages );
        CcReleaseMasterLockFromDpcLevel();

        //
        //  Now loop through all of the ranges.
        //

        while (!IsListEmpty(&Mbcb->BitmapRanges)) {

            //
            //  Get next range and remove it from the list.
            //

            BitmapRange = (PBITMAP_RANGE)CONTAINING_RECORD( Mbcb->BitmapRanges.Flink,
                                                            BITMAP_RANGE,
                                                            Links );

            RemoveEntryList( &BitmapRange->Links );

            //
            //  If there is a bitmap, and it is not the initial embedded one, then
            //  delete it.
            //

            if ((BitmapRange->Bitmap != NULL) &&
                (BitmapRange->Bitmap != (PULONG)&Mbcb->BitmapRange2)) {

                DoDrain = TRUE;

                //
                //  Usually the bitmap is all zeros at this point, but it may not be.
                //

                if (BitmapRange->DirtyPages != 0) {
                    RtlZeroMemory( BitmapRange->Bitmap, MBCB_BITMAP_BLOCK_SIZE );
                }
                CcAcquireVacbLockAtDpcLevel();
                CcDeallocateVacbLevel( (PVACB *)BitmapRange->Bitmap, FALSE );
                CcReleaseVacbLockFromDpcLevel();
            }

            //
            //  If the range is not one of the initial embedded ranges, then delete it.
            //

            if ((BitmapRange < (PBITMAP_RANGE)Mbcb) &&
                (BitmapRange > (PBITMAP_RANGE)((PCHAR)Mbcb + sizeof(MBCB)))) {

                InsertTailList( &BitmapRangesToFree, &BitmapRange->Links );
            }
        }

        //
        //  Zero the pointer and get out.
        //

        SharedCacheMap->Mbcb = NULL;

        KeReleaseInStackQueuedSpinLock( &LockHandle );

        //
        // Free all the pool now that no locks are held.
        //

        while (!IsListEmpty(&BitmapRangesToFree)) {
            NextEntry = RemoveHeadList( &BitmapRangesToFree );

            BitmapRange = CONTAINING_RECORD ( NextEntry,
                                              BITMAP_RANGE,
                                              Links );

            ExFreePool( BitmapRange );
        }

        //
        //  Now delete the Mbcb.
        //

        CcDeallocateBcb( (PBCB)Mbcb );

    } else {

        KeReleaseInStackQueuedSpinLock( &LockHandle );
    }

    if (DoDrain) {
        CcDrainVacbLevelZone();
    }
}


VOID
CcSetDirtyPageThreshold (
    IN PFILE_OBJECT FileObject,
    IN ULONG DirtyPageThreshold
    )

/*++

Routine Description:

    This routine may be called to set a dirty page threshold for this
    stream.  The write throttling will kick in whenever the file system
    attempts to exceed the dirty page threshold for this file.

Arguments:

    FileObject - Supplies file object for the stream

    DirtyPageThreshold - Supplies the dirty page threshold for this stream,
                         or 0 for no threshold.

Return Value:

    None

Environment:

    The caller must guarantee exclusive access to the FsRtl header flags,
    for example, by calling this routine once during create of the structure
    containing the header.  Then it would call the routine again when actually
    caching the stream.

--*/

{
    PSHARED_CACHE_MAP SharedCacheMap = FileObject->SectionObjectPointer->SharedCacheMap;

    if (SharedCacheMap != NULL) {

        SharedCacheMap->DirtyPageThreshold = DirtyPageThreshold;
    }

    //
    //  Test the flag before setting, in case the caller is no longer properly
    //  synchronized.
    //

    if (!FlagOn(((PFSRTL_COMMON_FCB_HEADER)(FileObject->FsContext))->Flags,
                FSRTL_FLAG_LIMIT_MODIFIED_PAGES)) {

        SetFlag(((PFSRTL_COMMON_FCB_HEADER)(FileObject->FsContext))->Flags,
                FSRTL_FLAG_LIMIT_MODIFIED_PAGES);
    }
}


VOID
CcZeroEndOfLastPage (
    IN PFILE_OBJECT FileObject
    )

/*++

Routine Description:

    This routine is only called by Mm before mapping a user view to
    a section.  If there is an uninitialized page at the end of the
    file, we zero it by freeing that page.

Parameters:

    FileObject - File object for section to be mapped

Return Value:

    None
--*/

{
    PSHARED_CACHE_MAP SharedCacheMap;
    ULONG ActivePage;
    ULONG PageIsDirty;
    KIRQL OldIrql;
    PVOID NeedToZero = NULL;
    PVACB ActiveVacb = NULL;
    IO_STATUS_BLOCK Iosb;
    BOOLEAN PurgeResult;

    //
    //  See if we have an active Vacb, that we need to free.
    //

    FsRtlAcquireFileExclusive( FileObject );
    CcAcquireMasterLock( &OldIrql );
    SharedCacheMap = FileObject->SectionObjectPointer->SharedCacheMap;

    if (SharedCacheMap != NULL) {

        //
        //  See if there is an active vacb.
        //

        if ((SharedCacheMap->ActiveVacb != NULL) || ((NeedToZero = SharedCacheMap->NeedToZero) != NULL)) {

            CcIncrementOpenCount( SharedCacheMap, 'peZS' );
            GetActiveVacbAtDpcLevel( SharedCacheMap, ActiveVacb, ActivePage, PageIsDirty );
        }
    }

    CcReleaseMasterLock( OldIrql );

    //
    //  Remember in FsRtl header there is a user section.
    //  If this is an advanced header then also acquire the mutex to access
    //  this field.
    //

    if (FlagOn( ((PFSRTL_COMMON_FCB_HEADER)FileObject->FsContext)->Flags,
                FSRTL_FLAG_ADVANCED_HEADER )) {

        ExAcquireFastMutex( ((PFSRTL_ADVANCED_FCB_HEADER)FileObject->FsContext)->FastMutex );

        SetFlag( ((PFSRTL_COMMON_FCB_HEADER)FileObject->FsContext)->Flags,
                 FSRTL_FLAG_USER_MAPPED_FILE );

        ExReleaseFastMutex( ((PFSRTL_ADVANCED_FCB_HEADER)FileObject->FsContext)->FastMutex );

    } else {

        SetFlag( ((PFSRTL_COMMON_FCB_HEADER)FileObject->FsContext)->Flags,
                 FSRTL_FLAG_USER_MAPPED_FILE );
    }

    //
    //  Free the active vacb now so we don't deadlock if we have to purge
    //


    if ((ActiveVacb != NULL) || (NeedToZero != NULL)) {
        CcFreeActiveVacb( SharedCacheMap, ActiveVacb, ActivePage, PageIsDirty );
    }


    if (FlagOn( ((PFSRTL_COMMON_FCB_HEADER)FileObject->FsContext)->Flags2, FSRTL_FLAG2_PURGE_WHEN_MAPPED )) {

        if (FileObject->SectionObjectPointer->SharedCacheMap) {
            ASSERT( ((PSHARED_CACHE_MAP)(FileObject->SectionObjectPointer->SharedCacheMap))->VacbActiveCount == 0 );
        }

        CcFlushCache( FileObject->SectionObjectPointer, NULL, 0, &Iosb );
        PurgeResult = CcPurgeCacheSection( FileObject->SectionObjectPointer, NULL, 0, FALSE );

        if (FileObject->SectionObjectPointer->SharedCacheMap) {
            ASSERT( ((PSHARED_CACHE_MAP)(FileObject->SectionObjectPointer->SharedCacheMap))->VacbActiveCount == 0 );
        }
    }


    FsRtlReleaseFile( FileObject );

    //
    //  If the file is cached and we have a Vacb to free, we need to
    //  use the lazy writer callback to synchronize so no one will be
    //  extending valid data.
    //

    if ((ActiveVacb != NULL) || (NeedToZero != NULL)) {

        //
        //  Serialize again to decrement the open count.
        //

        CcAcquireMasterLock( &OldIrql );

        CcDecrementOpenCount( SharedCacheMap, 'peZF' );

        if ((SharedCacheMap->OpenCount == 0) &&
            !FlagOn(SharedCacheMap->Flags, WRITE_QUEUED) &&
            (SharedCacheMap->DirtyPages == 0)) {

            //
            //  Move to the dirty list.
            //

            RemoveEntryList( &SharedCacheMap->SharedCacheMapLinks );
            InsertTailList( &CcDirtySharedCacheMapList.SharedCacheMapLinks,
                            &SharedCacheMap->SharedCacheMapLinks );

            //
            //  Make sure the Lazy Writer will wake up, because we
            //  want him to delete this SharedCacheMap.
            //

            LazyWriter.OtherWork = TRUE;
            if (!LazyWriter.ScanActive) {
                CcScheduleLazyWriteScan( FALSE );
            }
        }

        CcReleaseMasterLock( OldIrql );
    }
}


BOOLEAN
CcZeroData (
    IN PFILE_OBJECT FileObject,
    IN PLARGE_INTEGER StartOffset,
    IN PLARGE_INTEGER EndOffset,
    IN BOOLEAN Wait
    )

/*++

Routine Description:

    This routine attempts to zero the specified file data and deliver the
    correct I/O status.

    If the caller does not want to block (such as for disk I/O), then
    Wait should be supplied as FALSE.  If Wait was supplied as FALSE and
    it is currently impossible to zero all of the requested data without
    blocking, then this routine will return FALSE.  However, if the
    required space is immediately accessible in the cache and no blocking is
    required, this routine zeros the data and returns TRUE.

    If the caller supplies Wait as TRUE, then this routine is guaranteed
    to zero the data and return TRUE.  If the correct space is immediately
    accessible in the cache, then no blocking will occur.  Otherwise,
    the necessary work will be initiated to read and/or free cache data,
    and the caller will be blocked until the data can be received.

    File system Fsd's should typically supply Wait = TRUE if they are
    processing a synchronous I/O requests, or Wait = FALSE if they are
    processing an asynchronous request.

    File system threads should supply Wait = TRUE.

    IMPORTANT NOTE: File systems which call this routine must be prepared
    to handle a special form of a write call where the Mdl is already
    supplied.  Namely, if Irp->MdlAddress is supplied, the file system
    must check the low order bit of Irp->MdlAddress->ByteOffset.  If it
    is set, that means that the Irp was generated in this routine and
    the file system must do two things:

        Decrement Irp->MdlAddress->ByteOffset and Irp->UserBuffer

        Clear Irp->MdlAddress immediately prior to completing the
        request, as this routine expects to reuse the Mdl and
        ultimately deallocate the Mdl itself.

Arguments:

    FileObject - pointer to the FileObject for which a range of bytes
                 is to be zeroed.  This FileObject may either be for
                 a cached file or a noncached file.  If the file is
                 not cached, then WriteThrough must be TRUE and
                 StartOffset and EndOffset must be on sector boundaries.

    StartOffset - Start offset in file to be zeroed.

    EndOffset - End offset in file to be zeroed.

    Wait - FALSE if caller may not block, TRUE otherwise (see description
           above)

Return Value:

    FALSE - if Wait was supplied as FALSE and the data was not zeroed.

    TRUE - if the data has been zeroed.

Raises:

    STATUS_INSUFFICIENT_RESOURCES - If a pool allocation failure occurs.
        This can only occur if Wait was specified as TRUE.  (If Wait is
        specified as FALSE, and an allocation failure occurs, this
        routine simply returns FALSE.)

--*/

{
    PSHARED_CACHE_MAP SharedCacheMap;
    PVOID CacheBuffer;
    LARGE_INTEGER FOffset;
    LARGE_INTEGER ToGo;
    ULONG ZeroBytes, ZeroTransfer;
    ULONG SectorMask;
    ULONG i;
    BOOLEAN WriteThrough;
    BOOLEAN AggressiveZero = FALSE;
    ULONG SavedState = 0;
    ULONG MaxZerosInCache = MAX_ZEROS_IN_CACHE;
    ULONG NumberOfColors = 1;

    PBCB Bcb = NULL;
    PCHAR Zeros = NULL;
    PMDL ZeroMdl = NULL;
    ULONG MaxBytesMappedInMdl = 0;
    BOOLEAN Result = TRUE;

    PPFN_NUMBER Page;
    ULONG SavedByteCount;
    LARGE_INTEGER SizeLeft;

    DebugTrace(+1, me, "CcZeroData\n", 0 );

    WriteThrough = (BOOLEAN)(((FileObject->Flags & FO_WRITE_THROUGH) != 0) ||
                   (FileObject->PrivateCacheMap == NULL));

    //
    //  If the caller specified Wait, but the FileObject is WriteThrough,
    //  then we need to just get out.
    //

    if (WriteThrough && !Wait) {

        DebugTrace(-1, me, "CcZeroData->FALSE (WriteThrough && !Wait)\n", 0 );

        return FALSE;
    }

    SharedCacheMap = FileObject->SectionObjectPointer->SharedCacheMap;

    SectorMask = IoGetRelatedDeviceObject(FileObject)->SectorSize - 1;

    FOffset = *StartOffset;

    //
    //  Calculate how much to zero this time.
    //

    ToGo.QuadPart = EndOffset->QuadPart - FOffset.QuadPart;

    //
    //  This magic number is what the fastpaths throttle on, and they will present
    //  non-sector aligned zeroing requests. As long as we will always handle them
    //  on the cached path, we are OK.
    //
    //  If we will not make the cached path, the request must be aligned.
    //

    ASSERT( ToGo.QuadPart <= 0x2000 ||
            ((ToGo.LowPart & SectorMask) == 0  &&
             (FOffset.LowPart & SectorMask) == 0));

    //
    //  We will only do zeroing in the cache if the caller is using a
    //  cached file object, and did not specify WriteThrough.  We are
    //  willing to zero some data in the cache if our total is not too
    //  much, or there is sufficient available pages.
    //

    if (((ToGo.QuadPart <= 0x2000) ||
         (MmAvailablePages >= ((MAX_ZEROS_IN_CACHE / PAGE_SIZE) * 4))) && !WriteThrough) {

        try {

            while (MaxZerosInCache != 0) {

                ULONG ReceivedLength;
                LARGE_INTEGER BeyondLastByte;

                if ( ToGo.QuadPart > (LONGLONG)MaxZerosInCache ) {

                    //
                    //  If Wait == FALSE, then there is no point in getting started,
                    //  because we would have to start all over again zeroing with
                    //  Wait == TRUE, since we would fall out of this loop and
                    //  start synchronously writing pages to disk.
                    //

                    if (!Wait) {

                        DebugTrace(-1, me, "CcZeroData -> FALSE\n", 0 );

                        try_return( Result = FALSE );
                    }
                }
                else {
                    MaxZerosInCache = ToGo.LowPart;
                }

                //
                //  Call local routine to Map or Access the file data, then zero the data,
                //  then call another local routine to free the data.  If we cannot map
                //  the data because of a Wait condition, return FALSE.
                //
                //  Note that this call may result in an exception, however, if it
                //  does no Bcb is returned and this routine has absolutely no
                //  cleanup to perform.  Therefore, we do not have a try-finally
                //  and we allow the possibility that we will simply be unwound
                //  without notice.
                //

                if (!CcPinFileData( FileObject,
                                    &FOffset,
                                    MaxZerosInCache,
                                    FALSE,
                                    TRUE,
                                    Wait,
                                    &Bcb,
                                    &CacheBuffer,
                                    &BeyondLastByte )) {

                    DebugTrace(-1, me, "CcZeroData -> FALSE\n", 0 );

                    try_return( Result = FALSE );
                }

                //
                //  Calculate how much data is described by Bcb starting at our desired
                //  file offset.  If it is more than we need, we will zero the whole thing
                //  anyway.
                //

                ReceivedLength = (ULONG)(BeyondLastByte.QuadPart - FOffset.QuadPart );

                //
                //  Now attempt to allocate an Mdl to describe the mapped data.
                //

                ZeroMdl = IoAllocateMdl( CacheBuffer,
                                         ReceivedLength,
                                         FALSE,
                                         FALSE,
                                         NULL );

                if (ZeroMdl == NULL) {

                    ExRaiseStatus( STATUS_INSUFFICIENT_RESOURCES );
                }

                //
                //  It is necessary to probe and lock the pages, or else
                //  the pages may not still be in memory when we do the
                //  MmSetAddressRangeModified for the dirty Bcb.
                //

                MmDisablePageFaultClustering(&SavedState);
                MmProbeAndLockPages( ZeroMdl, KernelMode, IoReadAccess );
                MmEnablePageFaultClustering(SavedState);
                SavedState = 0;

                //
                //  Assume we did not get all the data we wanted, and set FOffset
                //  to the end of the returned data, and advance buffer pointer.
                //

                FOffset = BeyondLastByte;

                //
                //  Figure out how many bytes we are allowed to zero in the cache.
                //  Note it is possible we have zeroed a little more than our maximum,
                //  because we hit an existing Bcb that extended beyond the range.
                //

                if (MaxZerosInCache <= ReceivedLength) {
                    MaxZerosInCache = 0;
                }
                else {
                    MaxZerosInCache -= ReceivedLength;
                }

                //
                //  Now set the Bcb dirty.  We have to explicitly set the address
                //  range modified here, because that work otherwise gets deferred
                //  to the Lazy Writer.
                //

                MmSetAddressRangeModified( CacheBuffer, ReceivedLength );
                CcSetDirtyPinnedData( Bcb, NULL );

                //
                //  Unmap the data now
                //

                CcUnpinFileData( Bcb, FALSE, UNPIN );
                Bcb = NULL;

                //
                //  Unlock and free the Mdl (we only loop back if we crossed
                //  a 256KB boundary.
                //

                MmUnlockPages( ZeroMdl );
                IoFreeMdl( ZeroMdl );
                ZeroMdl = NULL;
            }

        try_exit: NOTHING;
        } finally {

            if (SavedState != 0) {
                MmEnablePageFaultClustering(SavedState);
            }

            //
            //  Clean up only necessary in abnormal termination.
            //

            if (Bcb != NULL) {

                CcUnpinFileData( Bcb, FALSE, UNPIN );
            }

            //
            //  Since the last thing in the above loop which can
            //  fail is the MmProbeAndLockPages, we only need to
            //  free the Mdl here.
            //

            if (ZeroMdl != NULL) {

                IoFreeMdl( ZeroMdl );
            }
        }

        //
        //  If hit a wait condition above, return it now.
        //

        if (!Result) {
            return FALSE;
        }

        //
        //  If we finished, get out nbow.
        //

        if ( FOffset.QuadPart >= EndOffset->QuadPart ) {
            return TRUE;
        }
    }

    //
    //  We either get here because we decided above not to zero anything in
    //  the cache directly, or else we zeroed up to our maximum and still
    //  have some left to zero direct to the file on disk.  In either case,
    //  we will now zero from FOffset to *EndOffset, and then flush this
    //  range in case the file is cached/mapped, and there are modified
    //  changes in memory.
    //

    //
    //  Round FOffset and EndOffset up to sector boundaries, since
    //  we will be doing disk I/O, and calculate size left.
    //

    ASSERT( (FOffset.LowPart & SectorMask) == 0 );

    FOffset.QuadPart += (LONGLONG)SectorMask;
    FOffset.LowPart &= ~SectorMask;
    SizeLeft.QuadPart = EndOffset->QuadPart + (LONGLONG)SectorMask;
    SizeLeft.LowPart &= ~SectorMask;
    SizeLeft.QuadPart -= FOffset.QuadPart;

    ASSERT( (FOffset.LowPart & SectorMask) == 0 );
    ASSERT( (SizeLeft.LowPart & SectorMask) == 0 );

    if (SizeLeft.QuadPart == 0) {
        return TRUE;
    }

    //
    //  try-finally to guarantee cleanup.
    //

    try {

        //
        //  Allocate a page to hold the zeros we will write, and
        //  zero it.
        //

        ZeroBytes = NumberOfColors * PAGE_SIZE;

        if (SizeLeft.HighPart == 0 && SizeLeft.LowPart < ZeroBytes) {
            ZeroBytes = SizeLeft.LowPart;
        }

        Zeros = (PCHAR)ExAllocatePoolWithTag( NonPagedPoolCacheAligned, ZeroBytes, 'eZcC' );

        if (Zeros != NULL) {

            //
            //  Allocate and initialize an Mdl to describe the zeros
            //  we need to transfer.  Allocate to cover the maximum
            //  size required, and we will use and reuse it in the
            //  loop below, initialized correctly.
            //

            if (SizeLeft.HighPart == 0 && SizeLeft.LowPart < MAX_ZERO_TRANSFER) {

                ZeroTransfer = SizeLeft.LowPart;

            } else {

                //
                //  See how aggressive we can afford to be.
                //

                if (InterlockedIncrement( &CcAggressiveZeroCount ) <= CcAggressiveZeroThreshold) {
                    AggressiveZero = TRUE;
                    ZeroTransfer = MAX_ZERO_TRANSFER;
                } else {
                    InterlockedDecrement( &CcAggressiveZeroCount );
                    ZeroTransfer = MIN_ZERO_TRANSFER;
                }
            }

            //
            //  Since the maximum zero may start at a very aggresive level, fall back
            //  until we really have to give up.  Since filter drivers, filesystems and
            //  even storage drivers may need to map this Mdl, we have to pre-map it
            //  into system space so that we know enough PTEs are available.  We also
            //  need to throttle our consumption of virtual addresses based on the size
            //  of the system and the number of parallel instances of this work outstanding.
            //  This may be a bit of overkill, but since running out of PTEs is a fatal
            //  event for the rest of the system, try to help out while still being fast.
            //

            while (TRUE) {

                //
                //  Spin down trying to get an MDL which can describe our operation.
                //
                
                while (TRUE) {

                    ZeroMdl = IoAllocateMdl( Zeros, ZeroTransfer, FALSE, FALSE, NULL );
                
                    //
                    //  Throttle ourselves to what we've physically allocated.  Note that
                    //  we could have started with an odd multiple of this number.  If we
                    //  tried for exactly that size and failed, we're toast.
                    //

                    if (ZeroMdl || ZeroTransfer == ZeroBytes) {

                        break;
                    }
                
                    Fall_Back:
                
                    //
                    //  Fallback by half and round down to a sector multiple.
                    //
                        
                    ZeroTransfer /= 2;
                    ZeroTransfer &= ~SectorMask;
                    if (ZeroTransfer < ZeroBytes) {
                        ZeroTransfer = ZeroBytes;
                    }

                    ASSERT( (ZeroTransfer & SectorMask) == 0 && ZeroTransfer != 0);
                }

                if (ZeroMdl == NULL) {

                    ExRaiseStatus( STATUS_INSUFFICIENT_RESOURCES );
                }

                //
                //  If we have throttled all the way down, stop and just build a
                //  simple MDL describing our previous allocation.
                //

                if (ZeroTransfer == ZeroBytes) {

                    MmBuildMdlForNonPagedPool( ZeroMdl );
                    break;
                }

                //
                //  Now we will temporarily lock the allocated pages
                //  only, and then replicate the page frame numbers through
                //  the entire Mdl to keep writing the same pages of zeros.
                //
                //  It would be nice if Mm exported a way for us to not have
                //  to pull the Mdl apart and rebuild it ourselves, but this
                //  is so bizzare a purpose as to be tolerable.
                //

                SavedByteCount = ZeroMdl->ByteCount;
                ZeroMdl->ByteCount = ZeroBytes;
                MmBuildMdlForNonPagedPool( ZeroMdl );

                ZeroMdl->MdlFlags &= ~MDL_SOURCE_IS_NONPAGED_POOL;
                ZeroMdl->MdlFlags |= MDL_PAGES_LOCKED;
                ZeroMdl->MappedSystemVa = NULL;
                ZeroMdl->ByteCount = SavedByteCount;
                Page = MmGetMdlPfnArray( ZeroMdl );
                for (i = NumberOfColors;
                     i < (ADDRESS_AND_SIZE_TO_SPAN_PAGES( 0, SavedByteCount ));
                     i++) {

                    *(Page + i) = *(Page + i - NumberOfColors);
                }

                if (MmGetSystemAddressForMdlSafe( ZeroMdl, LowPagePriority ) == NULL) {

                    //
                    //  Blow away this Mdl and trim for the retry.  Since it didn't
                    //  get mapped, there is nothing fancy to do.
                    //

                    IoFreeMdl( ZeroMdl );
                    goto Fall_Back;
                }

                break;
            }

        //
        //  We failed to allocate the space we wanted, so we will go to
        //  half of a page and limp along.
        //

        } else {

            //
            //  Of course, if we have a device which has large sectors, that defines
            //  the lower limit of our attempt.
            //

            if (IoGetRelatedDeviceObject(FileObject)->SectorSize < PAGE_SIZE / 2) {
                
                ZeroBytes = PAGE_SIZE / 2;
                Zeros = (PCHAR)ExAllocatePoolWithTag( NonPagedPoolCacheAligned, ZeroBytes, 'eZcC' );
            }

            //
            //  If we cannot get even that much, then let's write a sector at a time.
            //

            if (Zeros == NULL) {

                ZeroBytes = IoGetRelatedDeviceObject(FileObject)->SectorSize;
                Zeros = (PCHAR)ExAllocatePoolWithTag( NonPagedPoolCacheAligned, ZeroBytes, 'eZcC' );

                //
                //  If we cannot get even the minimum, we have to give up.
                //

                if (Zeros == NULL) {
                    ExRaiseStatus( STATUS_INSUFFICIENT_RESOURCES );
                }
            }

            //
            //  Allocate and initialize an Mdl to describe the zeros
            //  we need to transfer.  Allocate to cover the maximum
            //  size required, and we will use and reuse it in the
            //  loop below, initialized correctly.
            //

            ZeroTransfer = ZeroBytes;
            ZeroMdl = IoAllocateMdl( Zeros, ZeroBytes, FALSE, FALSE, NULL );

            ASSERT( (ZeroTransfer & SectorMask) == 0 );

            if (ZeroMdl == NULL) {
                ExRaiseStatus( STATUS_INSUFFICIENT_RESOURCES );
            }

            //
            //  Now we will lock and map the allocated pages.
            //

            MmBuildMdlForNonPagedPool( ZeroMdl );

            ASSERT( ZeroMdl->MappedSystemVa == Zeros );
        }

        //
        //  Zero the buffer now.
        //

        RtlZeroMemory( Zeros, ZeroBytes );

        //
        //  We have a mapped and zeroed range back by an MDL to use.  Note the
        //  size we have for cleanup, since we will possibly wind this down
        //  over the operation.
        //

        ASSERT( MmGetSystemAddressForMdl(ZeroMdl) );
        MaxBytesMappedInMdl = ZeroMdl->ByteCount;

        //
        //  Now loop to write buffers full of zeros through to the file
        //  until we reach the starting Vbn for the transfer.
        //

        ASSERT( ZeroTransfer != 0 &&
                (ZeroTransfer & SectorMask) == 0 &&
                (SizeLeft.LowPart & SectorMask) == 0 );

        while ( SizeLeft.QuadPart != 0 ) {

            IO_STATUS_BLOCK IoStatus;
            NTSTATUS Status;
            KEVENT Event;

            //
            //  See if we really need to write that many zeros, and
            //  trim the size back if not.
            //

            if ( (LONGLONG)ZeroTransfer > SizeLeft.QuadPart ) {

                ZeroTransfer = SizeLeft.LowPart;
            }

            //
            //  (Re)initialize the kernel event to FALSE.
            //

            KeInitializeEvent( &Event, NotificationEvent, FALSE );

            //
            //  Initiate and wait for the synchronous transfer.
            //

            ZeroMdl->ByteCount = ZeroTransfer;

            Status = IoSynchronousPageWrite( FileObject,
                                             ZeroMdl,
                                             &FOffset,
                                             &Event,
                                             &IoStatus );

            //
            //  If pending is returned (which is a successful status),
            //  we must wait for the request to complete.
            //

            if (Status == STATUS_PENDING) {
                KeWaitForSingleObject( &Event,
                                       Executive,
                                       KernelMode,
                                       FALSE,
                                       (PLARGE_INTEGER)NULL);
            }


            //
            //  If we got an error back in Status, then the Iosb
            //  was not written, so we will just copy the status
            //  there, then test the final status after that.
            //

            if (!NT_SUCCESS(Status)) {
                ExRaiseStatus( Status );
            }

            if (!NT_SUCCESS(IoStatus.Status)) {
                ExRaiseStatus( IoStatus.Status );
            }

            //
            //  If we succeeded, then update where we are at by how much
            //  we wrote, and loop back to see if there is more.
            //

            FOffset.QuadPart = FOffset.QuadPart + (LONGLONG)ZeroTransfer;
            SizeLeft.QuadPart = SizeLeft.QuadPart - (LONGLONG)ZeroTransfer;
        }
    }
    finally{

        //
        //  Clean up anything from zeroing pages on a noncached
        //  write.
        //

        if (ZeroMdl != NULL) {

            if ((MaxBytesMappedInMdl != 0) &&
                !FlagOn(ZeroMdl->MdlFlags, MDL_SOURCE_IS_NONPAGED_POOL)) {
                ZeroMdl->ByteCount = MaxBytesMappedInMdl;
                MmUnmapLockedPages (ZeroMdl->MappedSystemVa, ZeroMdl);
            }

            IoFreeMdl( ZeroMdl );
        }

        if (AggressiveZero) {
            InterlockedDecrement( &CcAggressiveZeroCount );
        }

        if (Zeros != NULL) {
            ExFreePool( Zeros );
        }

        DebugTrace(-1, me, "CcZeroData -> TRUE\n", 0 );
    }

    return TRUE;
}


PFILE_OBJECT
CcGetFileObjectFromSectionPtrs (
    IN PSECTION_OBJECT_POINTERS SectionObjectPointer
    )

/*++

This routine may be used to retrieve a pointer to the FileObject that the
Cache Manager is using for a given file from the Section Object Pointers
in the nonpaged File System structure Fcb.  The use of this function is
intended for exceptional use unrelated to the processing of user requests,
when the File System would otherwise not have a FileObject at its disposal.
An example is for mount verification.

Note that the File System is responsible for insuring that the File
Object does not go away while in use.  It is impossible for the Cache
Manager to guarantee this.

Arguments:

    SectionObjectPointer - A pointer to the Section Object Pointers
                           structure in the nonpaged Fcb.

Return Value:

    Pointer to the File Object, or NULL if the file is not cached or no
    longer cached

--*/

{
    KIRQL OldIrql;
    PFILE_OBJECT FileObject = NULL;

    //
    //  Serialize with Creation/Deletion of all Shared CacheMaps
    //

    CcAcquireMasterLock( &OldIrql );

    if (SectionObjectPointer->SharedCacheMap != NULL) {

        FileObject = ((PSHARED_CACHE_MAP)SectionObjectPointer->SharedCacheMap)->FileObject;
    }

    CcReleaseMasterLock( OldIrql );

    return FileObject;
}


PFILE_OBJECT
CcGetFileObjectFromBcb (
    IN PVOID Bcb
    )

/*++

This routine may be used to retrieve a pointer to the FileObject that the
Cache Manager is using for a given file from a Bcb of that file.

Note that the File System is responsible for insuring that the File
Object does not go away while in use.  It is impossible for the Cache
Manager to guarantee this.

Arguments:

    Bcb - A pointer to the pinned Bcb.

Return Value:

    Pointer to the File Object, or NULL if the file is not cached or no
    longer cached

--*/

{
    return ((PBCB)Bcb)->SharedCacheMap->FileObject;
}
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\base\ntos\cache\copysup.c ===
/*++

Copyright (c) 1990  Microsoft Corporation

Module Name:

    copysup.c

Abstract:

    This module implements the copy support routines for the Cache subsystem.

Author:

    Tom Miller      [TomM]      4-May-1990

Revision History:

--*/

#include "cc.h"

//
//  Define our debug constant
//

#define me 0x00000004

#ifdef ALLOC_PRAGMA
#pragma alloc_text(PAGE,CcCopyRead)
#pragma alloc_text(PAGE,CcFastCopyRead)
#endif


BOOLEAN
CcCopyRead (
    IN PFILE_OBJECT FileObject,
    IN PLARGE_INTEGER FileOffset,
    IN ULONG Length,
    IN BOOLEAN Wait,
    OUT PVOID Buffer,
    OUT PIO_STATUS_BLOCK IoStatus
    )

/*++

Routine Description:

    This routine attempts to copy the specified file data from the cache
    into the output buffer, and deliver the correct I/O status.  It is *not*
    safe to call this routine from Dpc level.

    If the caller does not want to block (such as for disk I/O), then
    Wait should be supplied as FALSE.  If Wait was supplied as FALSE and
    it is currently impossible to supply all of the requested data without
    blocking, then this routine will return FALSE.  However, if the
    data is immediately accessible in the cache and no blocking is
    required, this routine copies the data and returns TRUE.

    If the caller supplies Wait as TRUE, then this routine is guaranteed
    to copy the data and return TRUE.  If the data is immediately
    accessible in the cache, then no blocking will occur.  Otherwise,
    the the data transfer from the file into the cache will be initiated,
    and the caller will be blocked until the data can be returned.

    File system Fsd's should typically supply Wait = TRUE if they are
    processing a synchronous I/O requests, or Wait = FALSE if they are
    processing an asynchronous request.

    File system or Server Fsp threads should supply Wait = TRUE.

Arguments:

    FileObject - Pointer to the file object for a file which was
                 opened with NO_INTERMEDIATE_BUFFERING clear, i.e., for
                 which CcInitializeCacheMap was called by the file system.

    FileOffset - Byte offset in file for desired data.

    Length - Length of desired data in bytes.

    Wait - FALSE if caller may not block, TRUE otherwise (see description
           above)

    Buffer - Pointer to output buffer to which data should be copied.

    IoStatus - Pointer to standard I/O status block to receive the status
               for the transfer.  (STATUS_SUCCESS guaranteed for cache
               hits, otherwise the actual I/O status is returned.)

               Note that even if FALSE is returned, the IoStatus.Information
               field will return the count of any bytes successfully
               transferred before a blocking condition occured.  The caller
               may either choose to ignore this information, or resume
               the copy later accounting for bytes transferred.

Return Value:

    FALSE - if Wait was supplied as FALSE and the data was not delivered

    TRUE - if the data is being delivered

--*/

{
    PSHARED_CACHE_MAP SharedCacheMap;
    PPRIVATE_CACHE_MAP PrivateCacheMap;
    PVOID CacheBuffer;
    LARGE_INTEGER FOffset;
    PVACB Vacb;
    PBCB Bcb;
    PVACB ActiveVacb;
    ULONG ActivePage;
    ULONG PageIsDirty;
    ULONG SavedState;
    ULONG PagesToGo;
    ULONG MoveLength;
    ULONG LengthToGo;
    NTSTATUS Status;
    ULONG OriginalLength = Length;
    PETHREAD Thread = PsGetCurrentThread();
    ULONG GotAMiss = 0;

    DebugTrace(+1, me, "CcCopyRead\n", 0 );

    MmSavePageFaultReadAhead( Thread, &SavedState );

    //
    //  Get pointer to shared and private cache maps
    //

    SharedCacheMap = FileObject->SectionObjectPointer->SharedCacheMap;
    PrivateCacheMap = FileObject->PrivateCacheMap;

    //
    //  Check for read past file size, the caller must filter this case out.
    //

    ASSERT( ( FileOffset->QuadPart + (LONGLONG)Length) <= SharedCacheMap->FileSize.QuadPart );

    //
    //  If read ahead is enabled, then do the read ahead here so it
    //  overlaps with the copy (otherwise we will do it below).
    //  Note that we are assuming that we will not get ahead of our
    //  current transfer - if read ahead is working it should either
    //  already be in memory or else underway.
    //

    if (PrivateCacheMap->Flags.ReadAheadEnabled && (PrivateCacheMap->ReadAheadLength[1] == 0)) {
        CcScheduleReadAhead( FileObject, FileOffset, Length );
    }

    FOffset = *FileOffset;

    //
    //  Increment performance counters
    //

    if (Wait) {
        HOT_STATISTIC(CcCopyReadWait) += 1;

        //
        //  This is not an exact solution, but when IoPageRead gets a miss,
        //  it cannot tell whether it was CcCopyRead or CcMdlRead, but since
        //  the miss should occur very soon, by loading the pointer here
        //  probably the right counter will get incremented, and in any case,
        //  we hope the errrors average out!
        //

        CcMissCounter = &CcCopyReadWaitMiss;

    } else {
        HOT_STATISTIC(CcCopyReadNoWait) += 1;
    }

    //
    //  See if we have an active Vacb, that we can just copy to.
    //

    GetActiveVacb( SharedCacheMap, OldIrql, ActiveVacb, ActivePage, PageIsDirty );

    if (ActiveVacb != NULL) {

        if ((ULONG)(FOffset.QuadPart >> VACB_OFFSET_SHIFT) == (ActivePage >> (VACB_OFFSET_SHIFT - PAGE_SHIFT))) {

            ULONG LengthToCopy = VACB_MAPPING_GRANULARITY - (FOffset.LowPart & (VACB_MAPPING_GRANULARITY - 1));

            if (SharedCacheMap->NeedToZero != NULL) {
                CcFreeActiveVacb( SharedCacheMap, NULL, 0, FALSE );
            }

            //
            //  Get the starting point in the view.
            //

            CacheBuffer = (PVOID)((PCHAR)ActiveVacb->BaseAddress +
                                          (FOffset.LowPart & (VACB_MAPPING_GRANULARITY - 1)));

            //
            //  Reduce LengthToCopy if it is greater than our caller's length.
            //

            if (LengthToCopy > Length) {
                LengthToCopy = Length;
            }

            //
            //  Like the logic for the normal case below, we want to spin around
            //  making sure Mm only reads the pages we will need.
            //
            
            PagesToGo = ADDRESS_AND_SIZE_TO_SPAN_PAGES( CacheBuffer,
                                               LengthToCopy ) - 1;

            //
            //  Copy the data to the user buffer.
            //

            try {

                if (PagesToGo != 0) {
    
                    LengthToGo = LengthToCopy;
    
                    while (LengthToGo != 0) {
    
                        MoveLength = (ULONG)((PCHAR)(ROUND_TO_PAGES(((PCHAR)CacheBuffer + 1))) -
                                     (PCHAR)CacheBuffer);
    
                        if (MoveLength > LengthToGo) {
                            MoveLength = LengthToGo;
                        }
    
                        //
                        //  Here's hoping that it is cheaper to call Mm to see if
                        //  the page is valid.  If not let Mm know how many pages
                        //  we are after before doing the move.
                        //
    
                        MmSetPageFaultReadAhead( Thread, PagesToGo );
                        GotAMiss |= !MmCheckCachedPageState( CacheBuffer, FALSE );
    
                        RtlCopyBytes( Buffer, CacheBuffer, MoveLength );
    
                        PagesToGo -= 1;
    
                        LengthToGo -= MoveLength;
                        Buffer = (PCHAR)Buffer + MoveLength;
                        CacheBuffer = (PCHAR)CacheBuffer + MoveLength;
                    }
    
                //
                //  Handle the read here that stays on a single page.
                //
    
                } else {
    
                    //
                    //  Here's hoping that it is cheaper to call Mm to see if
                    //  the page is valid.  If not let Mm know how many pages
                    //  we are after before doing the move.
                    //
    
                    MmSetPageFaultReadAhead( Thread, 0 );
                    GotAMiss |= !MmCheckCachedPageState( CacheBuffer, FALSE );
    
                    RtlCopyBytes( Buffer, CacheBuffer, LengthToCopy );
    
                    Buffer = (PCHAR)Buffer + LengthToCopy;
                }
                
            } except( CcCopyReadExceptionFilter( GetExceptionInformation(),
                                                 &Status ) ) {

                MmResetPageFaultReadAhead( Thread, SavedState );

                SetActiveVacb( SharedCacheMap, OldIrql, ActiveVacb, ActivePage, PageIsDirty );

                //
                //  If we got an access violation, then the user buffer went
                //  away.  Otherwise we must have gotten an I/O error trying
                //  to bring the data in.
                //

                if (Status == STATUS_ACCESS_VIOLATION) {
                    ExRaiseStatus( STATUS_INVALID_USER_BUFFER );
                }
                else {
                    ExRaiseStatus( FsRtlNormalizeNtstatus( Status,
                                                           STATUS_UNEXPECTED_IO_ERROR ));
                }
            }

            //
            //  Now adjust FOffset and Length by what we copied.
            //

            FOffset.QuadPart = FOffset.QuadPart + (LONGLONG)LengthToCopy;
            Length -= LengthToCopy;

        }

        //
        //  If that was all the data, then remember the Vacb
        //

        if (Length == 0) {

            SetActiveVacb( SharedCacheMap, OldIrql, ActiveVacb, ActivePage, PageIsDirty );

        //
        //  Otherwise we must free it because we will map other vacbs below.
        //

        } else {

            CcFreeActiveVacb( SharedCacheMap, ActiveVacb, ActivePage, PageIsDirty );
        }
    }

    //
    //  Not all of the transfer will come back at once, so we have to loop
    //  until the entire transfer is complete.
    //

    while (Length != 0) {

        ULONG ReceivedLength;
        LARGE_INTEGER BeyondLastByte;

        //
        //  Call local routine to Map or Access the file data, then move the data,
        //  then call another local routine to free the data.  If we cannot map
        //  the data because of a Wait condition, return FALSE.
        //
        //  Note that this call may result in an exception, however, if it
        //  does no Bcb is returned and this routine has absolutely no
        //  cleanup to perform.  Therefore, we do not have a try-finally
        //  and we allow the possibility that we will simply be unwound
        //  without notice.
        //

        if (Wait) {

            CacheBuffer = CcGetVirtualAddress( SharedCacheMap,
                                               FOffset,
                                               &Vacb,
                                               &ReceivedLength );

            BeyondLastByte.QuadPart = FOffset.QuadPart + (LONGLONG)ReceivedLength;

        } else if (!CcPinFileData( FileObject,
                                   &FOffset,
                                   Length,
                                   TRUE,
                                   FALSE,
                                   FALSE,
                                   &Bcb,
                                   &CacheBuffer,
                                   &BeyondLastByte )) {

            DebugTrace(-1, me, "CcCopyRead -> FALSE\n", 0 );

            HOT_STATISTIC(CcCopyReadNoWaitMiss) += 1;

            //
            //  Enable ReadAhead if we missed.
            //

            CC_SET_PRIVATE_CACHE_MAP (PrivateCacheMap, PRIVATE_CACHE_MAP_READ_AHEAD_ENABLED);

            return FALSE;

        } else {

            //
            //  Calculate how much data is described by Bcb starting at our desired
            //  file offset.
            //

            ReceivedLength = (ULONG)(BeyondLastByte.QuadPart - FOffset.QuadPart);
        }

        //
        //  If we got more than we need, make sure to only transfer
        //  the right amount.
        //

        if (ReceivedLength > Length) {
            ReceivedLength = Length;
        }

        //
        //  It is possible for the user buffer to become no longer accessible
        //  since it was last checked by the I/O system.  If we fail to access
        //  the buffer we must raise a status that the caller's exception
        //  filter considers as "expected".  Also we unmap the Bcb here, since
        //  we otherwise would have no other reason to put a try-finally around
        //  this loop.
        //

        try {

            PagesToGo = ADDRESS_AND_SIZE_TO_SPAN_PAGES( CacheBuffer,
                                               ReceivedLength ) - 1;

            //
            //  We know exactly how much we want to read here, and we do not
            //  want to read any more in case the caller is doing random access.
            //  Our read ahead logic takes care of detecting sequential reads,
            //  and tends to do large asynchronous read aheads.  So far we have
            //  only mapped the data and we have not forced any in.  What we
            //  do now is get into a loop where we copy a page at a time and
            //  just prior to each move, we tell MM how many additional pages
            //  we would like to have read in, in the event that we take a
            //  fault.  With this strategy, for cache hits we never make a single
            //  expensive call to MM to guarantee that the data is in, yet if we
            //  do take a fault, we are guaranteed to only take one fault because
            //  we will read all of the data in for the rest of the transfer.
            //
            //  We test first for the multiple page case, to keep the small
            //  reads faster.
            //

            if (PagesToGo != 0) {

                LengthToGo = ReceivedLength;

                while (LengthToGo != 0) {

                    MoveLength = (ULONG)((PCHAR)(ROUND_TO_PAGES(((PCHAR)CacheBuffer + 1))) -
                                 (PCHAR)CacheBuffer);

                    if (MoveLength > LengthToGo) {
                        MoveLength = LengthToGo;
                    }

                    //
                    //  Here's hoping that it is cheaper to call Mm to see if
                    //  the page is valid.  If not let Mm know how many pages
                    //  we are after before doing the move.
                    //

                    MmSetPageFaultReadAhead( Thread, PagesToGo );
                    GotAMiss |= !MmCheckCachedPageState( CacheBuffer, FALSE );

                    RtlCopyBytes( Buffer, CacheBuffer, MoveLength );

                    PagesToGo -= 1;

                    LengthToGo -= MoveLength;
                    Buffer = (PCHAR)Buffer + MoveLength;
                    CacheBuffer = (PCHAR)CacheBuffer + MoveLength;
                }

            //
            //  Handle the read here that stays on a single page.
            //

            } else {

                //
                //  Here's hoping that it is cheaper to call Mm to see if
                //  the page is valid.  If not let Mm know how many pages
                //  we are after before doing the move.
                //

                MmSetPageFaultReadAhead( Thread, 0 );
                GotAMiss |= !MmCheckCachedPageState( CacheBuffer, FALSE );

                RtlCopyBytes( Buffer, CacheBuffer, ReceivedLength );

                Buffer = (PCHAR)Buffer + ReceivedLength;
            }

        }
        except( CcCopyReadExceptionFilter( GetExceptionInformation(),
                                           &Status ) ) {

            CcMissCounter = &CcThrowAway;

            //
            //  If we get an exception, then we have to renable page fault
            //  clustering and unmap on the way out.
            //

            MmResetPageFaultReadAhead( Thread, SavedState );


            if (Wait) {
                CcFreeVirtualAddress( Vacb );
            } else {
                CcUnpinFileData( Bcb, TRUE, UNPIN );
            }

            //
            //  If we got an access violation, then the user buffer went
            //  away.  Otherwise we must have gotten an I/O error trying
            //  to bring the data in.
            //

            if (Status == STATUS_ACCESS_VIOLATION) {
                ExRaiseStatus( STATUS_INVALID_USER_BUFFER );
            }
            else {
                ExRaiseStatus( FsRtlNormalizeNtstatus( Status,
                                                       STATUS_UNEXPECTED_IO_ERROR ));
            }
        }

        //
        //  Update number of bytes transferred.
        //

        Length -= ReceivedLength;

        //
        //  Unmap the data now, and calculate length left to transfer.
        //

        if (Wait) {

            //
            //  If there is more to go, just free this vacb.
            //

            if (Length != 0) {

                CcFreeVirtualAddress( Vacb );

            //
            //  Otherwise save it for the next time through.
            //

            } else {

                SetActiveVacb( SharedCacheMap, OldIrql, Vacb, (ULONG)(FOffset.QuadPart >> PAGE_SHIFT), 0 );
                break;
            }

        } else {
            CcUnpinFileData( Bcb, TRUE, UNPIN );
        }

        //
        //  Assume we did not get all the data we wanted, and set FOffset
        //  to the end of the returned data.
        //

        FOffset = BeyondLastByte;
    }

    MmResetPageFaultReadAhead( Thread, SavedState );

    CcMissCounter = &CcThrowAway;

    //
    //  Now enable read ahead if it looks like we got any misses, and do
    //  the first one.
    //

    if (GotAMiss &&
        !FlagOn( FileObject->Flags, FO_RANDOM_ACCESS ) &&
        !PrivateCacheMap->Flags.ReadAheadEnabled) {

        CC_SET_PRIVATE_CACHE_MAP (PrivateCacheMap, PRIVATE_CACHE_MAP_READ_AHEAD_ENABLED);
        CcScheduleReadAhead( FileObject, FileOffset, OriginalLength );
    }

    //
    //  Now that we have described our desired read ahead, let's
    //  shift the read history down.
    //

    PrivateCacheMap->FileOffset1 = PrivateCacheMap->FileOffset2;
    PrivateCacheMap->BeyondLastByte1 = PrivateCacheMap->BeyondLastByte2;
    PrivateCacheMap->FileOffset2 = *FileOffset;
    PrivateCacheMap->BeyondLastByte2.QuadPart =
                                FileOffset->QuadPart + (LONGLONG)OriginalLength;

    IoStatus->Status = STATUS_SUCCESS;
    IoStatus->Information = OriginalLength;

    DebugTrace(-1, me, "CcCopyRead -> TRUE\n", 0 );

    return TRUE;
}


VOID
CcFastCopyRead (
    IN PFILE_OBJECT FileObject,
    IN ULONG FileOffset,
    IN ULONG Length,
    IN ULONG PageCount,
    OUT PVOID Buffer,
    OUT PIO_STATUS_BLOCK IoStatus
    )

/*++

Routine Description:

    This routine attempts to copy the specified file data from the cache
    into the output buffer, and deliver the correct I/O status.

    This is a faster version of CcCopyRead which only supports 32-bit file
    offsets and synchronicity (Wait = TRUE).

Arguments:

    FileObject - Pointer to the file object for a file which was
                 opened with NO_INTERMEDIATE_BUFFERING clear, i.e., for
                 which CcInitializeCacheMap was called by the file system.

    FileOffset - Byte offset in file for desired data.

    Length - Length of desired data in bytes.

    PageCount - Number of pages spanned by the read.

    Buffer - Pointer to output buffer to which data should be copied.

    IoStatus - Pointer to standard I/O status block to receive the status
               for the transfer.  (STATUS_SUCCESS guaranteed for cache
               hits, otherwise the actual I/O status is returned.)

               Note that even if FALSE is returned, the IoStatus.Information
               field will return the count of any bytes successfully
               transferred before a blocking condition occured.  The caller
               may either choose to ignore this information, or resume
               the copy later accounting for bytes transferred.

Return Value:

    None

--*/

{
    PSHARED_CACHE_MAP SharedCacheMap;
    PPRIVATE_CACHE_MAP PrivateCacheMap;
    PVOID CacheBuffer;
    LARGE_INTEGER FOffset;
    PVACB Vacb;
    PVACB ActiveVacb;
    ULONG ActivePage;
    ULONG PageIsDirty;
    ULONG SavedState;
    ULONG PagesToGo;
    ULONG MoveLength;
    ULONG LengthToGo;
    NTSTATUS Status;
    LARGE_INTEGER OriginalOffset;
    ULONG OriginalLength = Length;
    PETHREAD Thread = PsGetCurrentThread();
    ULONG GotAMiss = 0;

    UNREFERENCED_PARAMETER (PageCount);

    DebugTrace(+1, me, "CcFastCopyRead\n", 0 );

    MmSavePageFaultReadAhead( Thread, &SavedState );

    //
    //  Get pointer to shared and private cache maps
    //

    SharedCacheMap = FileObject->SectionObjectPointer->SharedCacheMap;
    PrivateCacheMap = FileObject->PrivateCacheMap;

    //
    //  Check for read past file size, the caller must filter this case out.
    //

    ASSERT( (FileOffset + Length) <= SharedCacheMap->FileSize.LowPart );

    //
    //  If read ahead is enabled, then do the read ahead here so it
    //  overlaps with the copy (otherwise we will do it below).
    //  Note that we are assuming that we will not get ahead of our
    //  current transfer - if read ahead is working it should either
    //  already be in memory or else underway.
    //

    OriginalOffset.LowPart = FileOffset;
    OriginalOffset.HighPart = 0;

    if (PrivateCacheMap->Flags.ReadAheadEnabled && (PrivateCacheMap->ReadAheadLength[1] == 0)) {
        CcScheduleReadAhead( FileObject, &OriginalOffset, Length );
    }

    //
    //  This is not an exact solution, but when IoPageRead gets a miss,
    //  it cannot tell whether it was CcCopyRead or CcMdlRead, but since
    //  the miss should occur very soon, by loading the pointer here
    //  probably the right counter will get incremented, and in any case,
    //  we hope the errrors average out!
    //

    CcMissCounter = &CcCopyReadWaitMiss;

    //
    //  Increment performance counters
    //

    HOT_STATISTIC(CcCopyReadWait) += 1;

    //
    //  See if we have an active Vacb, that we can just copy to.
    //

    GetActiveVacb( SharedCacheMap, OldIrql, ActiveVacb, ActivePage, PageIsDirty );

    if (ActiveVacb != NULL) {

        if ((FileOffset >> VACB_OFFSET_SHIFT) == (ActivePage >> (VACB_OFFSET_SHIFT - PAGE_SHIFT))) {

            ULONG LengthToCopy = VACB_MAPPING_GRANULARITY - (FileOffset & (VACB_MAPPING_GRANULARITY - 1));

            if (SharedCacheMap->NeedToZero != NULL) {
                CcFreeActiveVacb( SharedCacheMap, NULL, 0, FALSE );
            }

            //
            //  Get the starting point in the view.
            //

            CacheBuffer = (PVOID)((PCHAR)ActiveVacb->BaseAddress +
                                          (FileOffset & (VACB_MAPPING_GRANULARITY - 1)));

            //
            //  Reduce LengthToCopy if it is greater than our caller's length.
            //

            if (LengthToCopy > Length) {
                LengthToCopy = Length;
            }

            //
            //  Like the logic for the normal case below, we want to spin around
            //  making sure Mm only reads the pages we will need.
            //
            
            PagesToGo = ADDRESS_AND_SIZE_TO_SPAN_PAGES( CacheBuffer,
                                               LengthToCopy ) - 1;

            //
            //  Copy the data to the user buffer.
            //

            try {

                if (PagesToGo != 0) {
    
                    LengthToGo = LengthToCopy;
    
                    while (LengthToGo != 0) {
    
                        MoveLength = (ULONG)((PCHAR)(ROUND_TO_PAGES(((PCHAR)CacheBuffer + 1))) -
                                     (PCHAR)CacheBuffer);
    
                        if (MoveLength > LengthToGo) {
                            MoveLength = LengthToGo;
                        }
    
                        //
                        //  Here's hoping that it is cheaper to call Mm to see if
                        //  the page is valid.  If not let Mm know how many pages
                        //  we are after before doing the move.
                        //
    
                        MmSetPageFaultReadAhead( Thread, PagesToGo );
                        GotAMiss |= !MmCheckCachedPageState( CacheBuffer, FALSE );
    
                        RtlCopyBytes( Buffer, CacheBuffer, MoveLength );
    
                        PagesToGo -= 1;
    
                        LengthToGo -= MoveLength;
                        Buffer = (PCHAR)Buffer + MoveLength;
                        CacheBuffer = (PCHAR)CacheBuffer + MoveLength;
                    }
    
                //
                //  Handle the read here that stays on a single page.
                //
    
                } else {
    
                    //
                    //  Here's hoping that it is cheaper to call Mm to see if
                    //  the page is valid.  If not let Mm know how many pages
                    //  we are after before doing the move.
                    //
    
                    MmSetPageFaultReadAhead( Thread, 0 );
                    GotAMiss |= !MmCheckCachedPageState( CacheBuffer, FALSE );
    
                    RtlCopyBytes( Buffer, CacheBuffer, LengthToCopy );
    
                    Buffer = (PCHAR)Buffer + LengthToCopy;
                }
                
            } except( CcCopyReadExceptionFilter( GetExceptionInformation(),
                                                 &Status ) ) {

                MmResetPageFaultReadAhead( Thread, SavedState );


                SetActiveVacb( SharedCacheMap, OldIrql, ActiveVacb, ActivePage, PageIsDirty );

                //
                //  If we got an access violation, then the user buffer went
                //  away.  Otherwise we must have gotten an I/O error trying
                //  to bring the data in.
                //

                if (Status == STATUS_ACCESS_VIOLATION) {
                    ExRaiseStatus( STATUS_INVALID_USER_BUFFER );
                }
                else {
                    ExRaiseStatus( FsRtlNormalizeNtstatus( Status,
                                                           STATUS_UNEXPECTED_IO_ERROR ));
                }
            }

            //
            //  Now adjust FileOffset and Length by what we copied.
            //

            FileOffset += LengthToCopy;
            Length -= LengthToCopy;
        }

        //
        //  If that was all the data, then remember the Vacb
        //

        if (Length == 0) {

            SetActiveVacb( SharedCacheMap, OldIrql, ActiveVacb, ActivePage, PageIsDirty );

        //
        //  Otherwise we must free it because we will map other vacbs below.
        //

        } else {

            CcFreeActiveVacb( SharedCacheMap, ActiveVacb, ActivePage, PageIsDirty );
        }
    }

    //
    //  Not all of the transfer will come back at once, so we have to loop
    //  until the entire transfer is complete.
    //

    FOffset.HighPart = 0;
    FOffset.LowPart = FileOffset;

    while (Length != 0) {

        ULONG ReceivedLength;
        ULONG BeyondLastByte;

        //
        //  Call local routine to Map or Access the file data, then move the data,
        //  then call another local routine to free the data.  If we cannot map
        //  the data because of a Wait condition, return FALSE.
        //
        //  Note that this call may result in an exception, however, if it
        //  does no Bcb is returned and this routine has absolutely no
        //  cleanup to perform.  Therefore, we do not have a try-finally
        //  and we allow the possibility that we will simply be unwound
        //  without notice.
        //

        CacheBuffer = CcGetVirtualAddress( SharedCacheMap,
                                           FOffset,
                                           &Vacb,
                                           &ReceivedLength );

        BeyondLastByte = FOffset.LowPart + ReceivedLength;

        //
        //  If we got more than we need, make sure to only transfer
        //  the right amount.
        //

        if (ReceivedLength > Length) {
            ReceivedLength = Length;
        }

        //
        //  It is possible for the user buffer to become no longer accessible
        //  since it was last checked by the I/O system.  If we fail to access
        //  the buffer we must raise a status that the caller's exception
        //  filter considers as "expected".  Also we unmap the Bcb here, since
        //  we otherwise would have no other reason to put a try-finally around
        //  this loop.
        //

        try {

            PagesToGo = ADDRESS_AND_SIZE_TO_SPAN_PAGES( CacheBuffer,
                                               ReceivedLength ) - 1;

            //
            //  We know exactly how much we want to read here, and we do not
            //  want to read any more in case the caller is doing random access.
            //  Our read ahead logic takes care of detecting sequential reads,
            //  and tends to do large asynchronous read aheads.  So far we have
            //  only mapped the data and we have not forced any in.  What we
            //  do now is get into a loop where we copy a page at a time and
            //  just prior to each move, we tell MM how many additional pages
            //  we would like to have read in, in the event that we take a
            //  fault.  With this strategy, for cache hits we never make a single
            //  expensive call to MM to guarantee that the data is in, yet if we
            //  do take a fault, we are guaranteed to only take one fault because
            //  we will read all of the data in for the rest of the transfer.
            //
            //  We test first for the multiple page case, to keep the small
            //  reads faster.
            //

            if (PagesToGo != 0) {

                LengthToGo = ReceivedLength;

                while (LengthToGo != 0) {

                    MoveLength = (ULONG)((PCHAR)(ROUND_TO_PAGES(((PCHAR)CacheBuffer + 1))) -
                                 (PCHAR)CacheBuffer);

                    if (MoveLength > LengthToGo) {
                        MoveLength = LengthToGo;
                    }

                    //
                    //  Here's hoping that it is cheaper to call Mm to see if
                    //  the page is valid.  If not let Mm know how many pages
                    //  we are after before doing the move.
                    //

                    MmSetPageFaultReadAhead( Thread, PagesToGo );
                    GotAMiss |= !MmCheckCachedPageState( CacheBuffer, FALSE );

                    RtlCopyBytes( Buffer, CacheBuffer, MoveLength );

                    PagesToGo -= 1;

                    LengthToGo -= MoveLength;
                    Buffer = (PCHAR)Buffer + MoveLength;
                    CacheBuffer = (PCHAR)CacheBuffer + MoveLength;
                }

            //
            //  Handle the read here that stays on a single page.
            //

            } else {

                //
                //  Here's hoping that it is cheaper to call Mm to see if
                //  the page is valid.  If not let Mm know how many pages
                //  we are after before doing the move.
                //

                MmSetPageFaultReadAhead( Thread, 0 );
                GotAMiss |= !MmCheckCachedPageState( CacheBuffer, FALSE );

                RtlCopyBytes( Buffer, CacheBuffer, ReceivedLength );

                Buffer = (PCHAR)Buffer + ReceivedLength;
            }
        }
        except( CcCopyReadExceptionFilter( GetExceptionInformation(),
                                           &Status ) ) {

            CcMissCounter = &CcThrowAway;

            //
            //  If we get an exception, then we have to renable page fault
            //  clustering and unmap on the way out.
            //

            MmResetPageFaultReadAhead( Thread, SavedState );


            CcFreeVirtualAddress( Vacb );

            //
            //  If we got an access violation, then the user buffer went
            //  away.  Otherwise we must have gotten an I/O error trying
            //  to bring the data in.
            //

            if (Status == STATUS_ACCESS_VIOLATION) {
                ExRaiseStatus( STATUS_INVALID_USER_BUFFER );
            }
            else {
                ExRaiseStatus( FsRtlNormalizeNtstatus( Status,
                                                       STATUS_UNEXPECTED_IO_ERROR ));
            }
        }

        //
        //  Update number of bytes transferred.
        //

        Length -= ReceivedLength;

        //
        //  Unmap the data now, and calculate length left to transfer.
        //

        if (Length != 0) {

            //
            //  If there is more to go, just free this vacb.
            //

            CcFreeVirtualAddress( Vacb );

        } else {

            //
            //  Otherwise save it for the next time through.
            //

            SetActiveVacb( SharedCacheMap, OldIrql, Vacb, (FOffset.LowPart >> PAGE_SHIFT), 0 );
            break;
        }

        //
        //  Assume we did not get all the data we wanted, and set FOffset
        //  to the end of the returned data.
        //

        FOffset.LowPart = BeyondLastByte;
    }

    MmResetPageFaultReadAhead( Thread, SavedState );

    CcMissCounter = &CcThrowAway;

    //
    //  Now enable read ahead if it looks like we got any misses, and do
    //  the first one.
    //

    if (GotAMiss &&
        !FlagOn( FileObject->Flags, FO_RANDOM_ACCESS ) &&
        !PrivateCacheMap->Flags.ReadAheadEnabled) {

        CC_SET_PRIVATE_CACHE_MAP (PrivateCacheMap, PRIVATE_CACHE_MAP_READ_AHEAD_ENABLED);
        CcScheduleReadAhead( FileObject, &OriginalOffset, OriginalLength );
    }

    //
    //  Now that we have described our desired read ahead, let's
    //  shift the read history down.
    //

    PrivateCacheMap->FileOffset1.LowPart = PrivateCacheMap->FileOffset2.LowPart;
    PrivateCacheMap->BeyondLastByte1.LowPart = PrivateCacheMap->BeyondLastByte2.LowPart;
    PrivateCacheMap->FileOffset2.LowPart = OriginalOffset.LowPart;
    PrivateCacheMap->BeyondLastByte2.LowPart = OriginalOffset.LowPart + OriginalLength;

    IoStatus->Status = STATUS_SUCCESS;
    IoStatus->Information = OriginalLength;

    DebugTrace(-1, me, "CcFastCopyRead -> VOID\n", 0 );
}


BOOLEAN
CcCopyWrite (
    IN PFILE_OBJECT FileObject,
    IN PLARGE_INTEGER FileOffset,
    IN ULONG Length,
    IN BOOLEAN Wait,
    IN PVOID Buffer
    )

/*++

Routine Description:

    This routine attempts to copy the specified file data from the specified
    buffer into the Cache, and deliver the correct I/O status.  It is *not*
    safe to call this routine from Dpc level.

    If the caller does not want to block (such as for disk I/O), then
    Wait should be supplied as FALSE.  If Wait was supplied as FALSE and
    it is currently impossible to receive all of the requested data without
    blocking, then this routine will return FALSE.  However, if the
    correct space is immediately accessible in the cache and no blocking is
    required, this routine copies the data and returns TRUE.

    If the caller supplies Wait as TRUE, then this routine is guaranteed
    to copy the data and return TRUE.  If the correct space is immediately
    accessible in the cache, then no blocking will occur.  Otherwise,
    the necessary work will be initiated to read and/or free cache data,
    and the caller will be blocked until the data can be received.

    File system Fsd's should typically supply Wait = TRUE if they are
    processing a synchronous I/O requests, or Wait = FALSE if they are
    processing an asynchronous request.

    File system or Server Fsp threads should supply Wait = TRUE.

Arguments:

    FileObject - Pointer to the file object for a file which was
                 opened with NO_INTERMEDIATE_BUFFERING clear, i.e., for
                 which CcInitializeCacheMap was called by the file system.

    FileOffset - Byte offset in file to receive the data.

    Length - Length of data in bytes.

    Wait - FALSE if caller may not block, TRUE otherwise (see description
           above)

    Buffer - Pointer to input buffer from which data should be copied.

Return Value:

    FALSE - if Wait was supplied as FALSE and the data was not copied.

    TRUE - if the data has been copied.

Raises:

    STATUS_INSUFFICIENT_RESOURCES - If a pool allocation failure occurs.
        This can only occur if Wait was specified as TRUE.  (If Wait is
        specified as FALSE, and an allocation failure occurs, this
        routine simply returns FALSE.)

--*/

{
    PSHARED_CACHE_MAP SharedCacheMap;
    PFSRTL_ADVANCED_FCB_HEADER FcbHeader;
    PVACB ActiveVacb;
    ULONG ActivePage;
    PVOID ActiveAddress;
    ULONG PageIsDirty;
    KIRQL OldIrql;
    NTSTATUS Status;
    PVOID CacheBuffer;
    LARGE_INTEGER FOffset;
    PBCB Bcb;
    ULONG ZeroFlags;
    LARGE_INTEGER Temp;

    DebugTrace(+1, me, "CcCopyWrite\n", 0 );

    //
    //  If the caller specified Wait == FALSE, but the FileObject is WriteThrough,
    //  then we need to just get out.
    //

    if ((FileObject->Flags & FO_WRITE_THROUGH) && !Wait) {

        DebugTrace(-1, me, "CcCopyWrite->FALSE (WriteThrough && !Wait)\n", 0 );

        return FALSE;
    }

    //
    //  Get pointer to shared cache map
    //

    SharedCacheMap = FileObject->SectionObjectPointer->SharedCacheMap;
    FOffset = *FileOffset;

    //
    //  See if we have an active Vacb, that we can just copy to.
    //

    GetActiveVacb( SharedCacheMap, OldIrql, ActiveVacb, ActivePage, PageIsDirty );

    if (ActiveVacb != NULL) {

        //
        //  See if the request starts in the ActivePage.  WriteThrough requests must
        //  go the longer route through CcMapAndCopy, where WriteThrough flushes are
        //  implemented.
        //

        if (((ULONG)(FOffset.QuadPart >> PAGE_SHIFT) == ActivePage) && (Length != 0) &&
            !FlagOn( FileObject->Flags, FO_WRITE_THROUGH )) {

            ULONG LengthToCopy = PAGE_SIZE - (FOffset.LowPart & (PAGE_SIZE - 1));

            //
            //  Reduce LengthToCopy if it is greater than our caller's length.
            //

            if (LengthToCopy > Length) {
                LengthToCopy = Length;
            }

            //
            //  Copy the data to the user buffer.
            //

            try {

                //
                //  If we are copying to a page that is locked down, then
                //  we have to do it under our spinlock, and update the
                //  NeedToZero field.
                //

                OldIrql = 0xFF;

                CacheBuffer = (PVOID)((PCHAR)ActiveVacb->BaseAddress +
                                      (FOffset.LowPart & (VACB_MAPPING_GRANULARITY - 1)));

                if (SharedCacheMap->NeedToZero != NULL) {

                    //
                    //  The FastLock may not write our "flag".
                    //

                    OldIrql = 0;

                    ExAcquireFastLock( &SharedCacheMap->ActiveVacbSpinLock, &OldIrql );

                    //
                    //  Note that the NeedToZero could be cleared, since we
                    //  tested it without the spinlock.
                    //

                    ActiveAddress = SharedCacheMap->NeedToZero;
                    if ((ActiveAddress != NULL) &&
                        (ActiveVacb == SharedCacheMap->NeedToZeroVacb) &&
                        (((PCHAR)CacheBuffer + LengthToCopy) > (PCHAR)ActiveAddress)) {

                        //
                        //  If we are skipping some bytes in the page, then we need
                        //  to zero them.
                        //

                        if ((PCHAR)CacheBuffer > (PCHAR)ActiveAddress) {

                            RtlZeroMemory( ActiveAddress, (PCHAR)CacheBuffer - (PCHAR)ActiveAddress );
                        }
                        SharedCacheMap->NeedToZero = (PVOID)((PCHAR)CacheBuffer + LengthToCopy);
                    }

                    ExReleaseFastLock( &SharedCacheMap->ActiveVacbSpinLock, OldIrql );
                }

                RtlCopyBytes( CacheBuffer, Buffer, LengthToCopy );

            } except( CcCopyReadExceptionFilter( GetExceptionInformation(),
                                                 &Status ) ) {

                //
                //  If we failed to overwrite the uninitialized data,
                //  zero it now (we cannot safely restore NeedToZero).
                //

                if (OldIrql != 0xFF) {
                    RtlZeroBytes( CacheBuffer, LengthToCopy );
                }

                SetActiveVacb( SharedCacheMap, OldIrql, ActiveVacb, ActivePage, ACTIVE_PAGE_IS_DIRTY );

                //
                //  If we got an access violation, then the user buffer went
                //  away.  Otherwise we must have gotten an I/O error trying
                //  to bring the data in.
                //

                if (Status == STATUS_ACCESS_VIOLATION) {
                    ExRaiseStatus( STATUS_INVALID_USER_BUFFER );
                }
                else {
                    ExRaiseStatus( FsRtlNormalizeNtstatus( Status,
                                                           STATUS_UNEXPECTED_IO_ERROR ));
                }
            }

            //
            //  Now adjust FOffset and Length by what we copied.
            //

            Buffer = (PVOID)((PCHAR)Buffer + LengthToCopy);
            FOffset.QuadPart = FOffset.QuadPart + (LONGLONG)LengthToCopy;
            Length -= LengthToCopy;

            //
            //  If that was all the data, then get outski...
            //

            if (Length == 0) {

                SetActiveVacb( SharedCacheMap, OldIrql, ActiveVacb, ActivePage, ACTIVE_PAGE_IS_DIRTY );
                return TRUE;
            }

            //
            //  Remember that the page is dirty now.
            //

            PageIsDirty |= ACTIVE_PAGE_IS_DIRTY;
        }

        CcFreeActiveVacb( SharedCacheMap, ActiveVacb, ActivePage, PageIsDirty );

    //
    //  Else someone else could have the active page, and may want to zero
    //  the range we plan to write!
    //

    } else if (SharedCacheMap->NeedToZero != NULL) {

        CcFreeActiveVacb( SharedCacheMap, NULL, 0, FALSE );
    }

    //
    //  At this point we can calculate the ZeroFlags.
    //

    //
    //  We can always zero middle pages, if any.
    //

    ZeroFlags = ZERO_MIDDLE_PAGES;

    if (((FOffset.LowPart & (PAGE_SIZE - 1)) == 0) &&
        (Length >= PAGE_SIZE)) {
        ZeroFlags |= ZERO_FIRST_PAGE;
    }

    if (((FOffset.LowPart + Length) & (PAGE_SIZE - 1)) == 0) {
        ZeroFlags |= ZERO_LAST_PAGE;
    }

    Temp = FOffset;
    Temp.LowPart &= ~(PAGE_SIZE -1);

    //
    //  If there is an advanced header, then we can acquire the FastMutex to
    //  make capturing ValidDataLength atomic.  Currently our other file systems
    //  are either RO or do not really support 64-bits.
    //

    FcbHeader = (PFSRTL_ADVANCED_FCB_HEADER)FileObject->FsContext;
    if (FlagOn(FcbHeader->Flags, FSRTL_FLAG_ADVANCED_HEADER)) {
        ExAcquireFastMutex( FcbHeader->FastMutex );
        Temp.QuadPart = ((PFSRTL_COMMON_FCB_HEADER)FileObject->FsContext)->ValidDataLength.QuadPart -
                        Temp.QuadPart;
        ExReleaseFastMutex( FcbHeader->FastMutex );
    } else {
        Temp.QuadPart = ((PFSRTL_COMMON_FCB_HEADER)FileObject->FsContext)->ValidDataLength.QuadPart -
                        Temp.QuadPart;
    }

    if (Temp.QuadPart <= 0) {
        ZeroFlags |= ZERO_FIRST_PAGE | ZERO_MIDDLE_PAGES | ZERO_LAST_PAGE;
    } else if ((Temp.HighPart == 0) && (Temp.LowPart <= PAGE_SIZE)) {
        ZeroFlags |= ZERO_MIDDLE_PAGES | ZERO_LAST_PAGE;
    }

    //
    //  Call a routine to map and copy the data in Mm and get out.
    //

    if (Wait) {

        CcMapAndCopy( SharedCacheMap,
                      Buffer,
                      &FOffset,
                      Length,
                      ZeroFlags,
                      FileObject );

        return TRUE;
    }

    //
    //  The rest of this routine is the Wait == FALSE case.
    //
    //  Not all of the transfer will come back at once, so we have to loop
    //  until the entire transfer is complete.
    //

    while (Length != 0) {

        ULONG ReceivedLength;
        LARGE_INTEGER BeyondLastByte;

        if (!CcPinFileData( FileObject,
                            &FOffset,
                            Length,
                            FALSE,
                            TRUE,
                            FALSE,
                            &Bcb,
                            &CacheBuffer,
                            &BeyondLastByte )) {

            DebugTrace(-1, me, "CcCopyWrite -> FALSE\n", 0 );

            return FALSE;

        } else {

            //
            //  Calculate how much data is described by Bcb starting at our desired
            //  file offset.
            //

            ReceivedLength = (ULONG)(BeyondLastByte.QuadPart - FOffset.QuadPart);

            //
            //  If we got more than we need, make sure to only transfer
            //  the right amount.
            //

            if (ReceivedLength > Length) {
                ReceivedLength = Length;
            }
        }

        //
        //  It is possible for the user buffer to become no longer accessible
        //  since it was last checked by the I/O system.  If we fail to access
        //  the buffer we must raise a status that the caller's exception
        //  filter considers as "expected".  Also we unmap the Bcb here, since
        //  we otherwise would have no other reason to put a try-finally around
        //  this loop.
        //

        try {

            RtlCopyBytes( CacheBuffer, Buffer, ReceivedLength );

            CcSetDirtyPinnedData( Bcb, NULL );
            CcUnpinFileData( Bcb, FALSE, UNPIN );
        }
        except( CcCopyReadExceptionFilter( GetExceptionInformation(),
                                           &Status ) ) {

            CcUnpinFileData( Bcb, TRUE, UNPIN );

            //
            //  If we got an access violation, then the user buffer went
            //  away.  Otherwise we must have gotten an I/O error trying
            //  to bring the data in.
            //

            if (Status == STATUS_ACCESS_VIOLATION) {
                ExRaiseStatus( STATUS_INVALID_USER_BUFFER );
            }
            else {

                ExRaiseStatus(FsRtlNormalizeNtstatus( Status, STATUS_UNEXPECTED_IO_ERROR ));
            }
        }

        //
        //  Assume we did not get all the data we wanted, and set FOffset
        //  to the end of the returned data and adjust the Buffer and Length.
        //

        FOffset = BeyondLastByte;
        Buffer = (PCHAR)Buffer + ReceivedLength;
        Length -= ReceivedLength;
    }

    DebugTrace(-1, me, "CcCopyWrite -> TRUE\n", 0 );

    return TRUE;
}


VOID
CcFastCopyWrite (
    IN PFILE_OBJECT FileObject,
    IN ULONG FileOffset,
    IN ULONG Length,
    IN PVOID Buffer
    )

/*++

Routine Description:

    This routine attempts to copy the specified file data from the specified
    buffer into the Cache, and deliver the correct I/O status.

    This is a faster version of CcCopyWrite which only supports 32-bit file
    offsets and synchronicity (Wait = TRUE) and no Write Through.

Arguments:

    FileObject - Pointer to the file object for a file which was
                 opened with NO_INTERMEDIATE_BUFFERING clear, i.e., for
                 which CcInitializeCacheMap was called by the file system.

    FileOffset - Byte offset in file to receive the data.

    Length - Length of data in bytes.

    Buffer - Pointer to input buffer from which data should be copied.

Return Value:

    None

Raises:

    STATUS_INSUFFICIENT_RESOURCES - If a pool allocation failure occurs.
        This can only occur if Wait was specified as TRUE.  (If Wait is
        specified as FALSE, and an allocation failure occurs, this
        routine simply returns FALSE.)

--*/

{
    PSHARED_CACHE_MAP SharedCacheMap;
    PVOID CacheBuffer;
    PVACB ActiveVacb;
    ULONG ActivePage;
    PVOID ActiveAddress;
    ULONG PageIsDirty;
    KIRQL OldIrql;
    NTSTATUS Status;
    ULONG ZeroFlags;
    ULONG ValidDataLength;
    LARGE_INTEGER FOffset;

    DebugTrace(+1, me, "CcFastCopyWrite\n", 0 );

    //
    //  Get pointer to shared cache map and a copy of valid data length
    //

    SharedCacheMap = FileObject->SectionObjectPointer->SharedCacheMap;

    //
    //  See if we have an active Vacb, that we can just copy to.
    //

    GetActiveVacb( SharedCacheMap, OldIrql, ActiveVacb, ActivePage, PageIsDirty );

    if (ActiveVacb != NULL) {

        //
        //  See if the request starts in the ActivePage.  WriteThrough requests must
        //  go the longer route through CcMapAndCopy, where WriteThrough flushes are
        //  implemented.
        //

        if (((FileOffset >> PAGE_SHIFT) == ActivePage) && (Length != 0) &&
            !FlagOn( FileObject->Flags, FO_WRITE_THROUGH )) {

            ULONG LengthToCopy = PAGE_SIZE - (FileOffset & (PAGE_SIZE - 1));

            //
            //  Reduce LengthToCopy if it is greater than our caller's length.
            //

            if (LengthToCopy > Length) {
                LengthToCopy = Length;
            }

            //
            //  Copy the data to the user buffer.
            //

            try {

                //
                //  If we are copying to a page that is locked down, then
                //  we have to do it under our spinlock, and update the
                //  NeedToZero field.
                //

                OldIrql = 0xFF;

                CacheBuffer = (PVOID)((PCHAR)ActiveVacb->BaseAddress +
                                      (FileOffset & (VACB_MAPPING_GRANULARITY - 1)));

                if (SharedCacheMap->NeedToZero != NULL) {

                    //
                    //  The FastLock may not write our "flag".
                    //

                    OldIrql = 0;

                    ExAcquireFastLock( &SharedCacheMap->ActiveVacbSpinLock, &OldIrql );

                    //
                    //  Note that the NeedToZero could be cleared, since we
                    //  tested it without the spinlock.
                    //

                    ActiveAddress = SharedCacheMap->NeedToZero;
                    if ((ActiveAddress != NULL) &&
                        (ActiveVacb == SharedCacheMap->NeedToZeroVacb) &&
                        (((PCHAR)CacheBuffer + LengthToCopy) > (PCHAR)ActiveAddress)) {

                        //
                        //  If we are skipping some bytes in the page, then we need
                        //  to zero them.
                        //

                        if ((PCHAR)CacheBuffer > (PCHAR)ActiveAddress) {

                            RtlZeroMemory( ActiveAddress, (PCHAR)CacheBuffer - (PCHAR)ActiveAddress );
                        }
                        SharedCacheMap->NeedToZero = (PVOID)((PCHAR)CacheBuffer + LengthToCopy);
                    }

                    ExReleaseFastLock( &SharedCacheMap->ActiveVacbSpinLock, OldIrql );
                }

                RtlCopyBytes( CacheBuffer, Buffer, LengthToCopy );

            } except( CcCopyReadExceptionFilter( GetExceptionInformation(),
                                                 &Status ) ) {

                //
                //  If we failed to overwrite the uninitialized data,
                //  zero it now (we cannot safely restore NeedToZero).
                //

                if (OldIrql != 0xFF) {
                    RtlZeroBytes( CacheBuffer, LengthToCopy );
                }

                SetActiveVacb( SharedCacheMap, OldIrql, ActiveVacb, ActivePage, ACTIVE_PAGE_IS_DIRTY );

                //
                //  If we got an access violation, then the user buffer went
                //  away.  Otherwise we must have gotten an I/O error trying
                //  to bring the data in.
                //

                if (Status == STATUS_ACCESS_VIOLATION) {
                    ExRaiseStatus( STATUS_INVALID_USER_BUFFER );
                }
                else {
                    ExRaiseStatus( FsRtlNormalizeNtstatus( Status,
                                                           STATUS_UNEXPECTED_IO_ERROR ));
                }
            }

            //
            //  Now adjust FileOffset and Length by what we copied.
            //

            Buffer = (PVOID)((PCHAR)Buffer + LengthToCopy);
            FileOffset += LengthToCopy;
            Length -= LengthToCopy;

            //
            //  If that was all the data, then get outski...
            //

            if (Length == 0) {

                SetActiveVacb( SharedCacheMap, OldIrql, ActiveVacb, ActivePage, ACTIVE_PAGE_IS_DIRTY );
                return;
            }

            //
            //  Remember that the page is dirty now.
            //

            PageIsDirty |= ACTIVE_PAGE_IS_DIRTY;
        }

        CcFreeActiveVacb( SharedCacheMap, ActiveVacb, ActivePage, PageIsDirty );

    //
    //  Else someone else could have the active page, and may want to zero
    //  the range we plan to write!
    //

    } else if (SharedCacheMap->NeedToZero != NULL) {

        CcFreeActiveVacb( SharedCacheMap, NULL, 0, FALSE );
    }

    //
    //  Set up for call to CcMapAndCopy
    //

    FOffset.LowPart = FileOffset;
    FOffset.HighPart = 0;

    ValidDataLength = ((PFSRTL_COMMON_FCB_HEADER)FileObject->FsContext)->ValidDataLength.LowPart;

    ASSERT((ValidDataLength == MAXULONG) ||
           (((PFSRTL_COMMON_FCB_HEADER)FileObject->FsContext)->ValidDataLength.HighPart == 0));

    //
    //  At this point we can calculate the ReadOnly flag for
    //  the purposes of whether to use the Bcb resource, and
    //  we can calculate the ZeroFlags.
    //

    //
    //  We can always zero middle pages, if any.
    //

    ZeroFlags = ZERO_MIDDLE_PAGES;

    if (((FileOffset & (PAGE_SIZE - 1)) == 0) &&
        (Length >= PAGE_SIZE)) {
        ZeroFlags |= ZERO_FIRST_PAGE;
    }

    if (((FileOffset + Length) & (PAGE_SIZE - 1)) == 0) {
        ZeroFlags |= ZERO_LAST_PAGE;
    }

    if ((FileOffset & ~(PAGE_SIZE - 1)) >= ValidDataLength) {
        ZeroFlags |= ZERO_FIRST_PAGE | ZERO_MIDDLE_PAGES | ZERO_LAST_PAGE;
    } else if (((FileOffset & ~(PAGE_SIZE - 1)) + PAGE_SIZE) >= ValidDataLength) {
        ZeroFlags |= ZERO_MIDDLE_PAGES | ZERO_LAST_PAGE;
    }

    //
    //  Call a routine to map and copy the data in Mm and get out.
    //

    CcMapAndCopy( SharedCacheMap,
                  Buffer,
                  &FOffset,
                  Length,
                  ZeroFlags,
                  FileObject );

    DebugTrace(-1, me, "CcFastCopyWrite -> VOID\n", 0 );
}


LONG
CcCopyReadExceptionFilter(
    IN PEXCEPTION_POINTERS ExceptionPointer,
    IN PNTSTATUS ExceptionCode
    )

/*++

Routine Description:

    This routine serves as a exception filter and has the special job of
    extracting the "real" I/O error when Mm raises STATUS_IN_PAGE_ERROR
    beneath us.

Arguments:

    ExceptionPointer - A pointer to the exception record that contains
                       the real Io Status.

    ExceptionCode - A pointer to an NTSTATUS that is to receive the real
                    status.

Return Value:

    EXCEPTION_EXECUTE_HANDLER

--*/

{
    *ExceptionCode = ExceptionPointer->ExceptionRecord->ExceptionCode;

    if ( (*ExceptionCode == STATUS_IN_PAGE_ERROR) &&
         (ExceptionPointer->ExceptionRecord->NumberParameters >= 3) ) {

        *ExceptionCode = (NTSTATUS) ExceptionPointer->ExceptionRecord->ExceptionInformation[2];
    }

    ASSERT( !NT_SUCCESS(*ExceptionCode) );

    return EXCEPTION_EXECUTE_HANDLER;
}


BOOLEAN
CcCanIWrite (
    IN PFILE_OBJECT FileObject,
    IN ULONG BytesToWrite,
    IN BOOLEAN Wait,
    IN UCHAR Retrying
    )

/*++

Routine Description:

    This routine tests whether it is ok to do a write to the cache
    or not, according to the Thresholds of dirty bytes and available
    pages.  The first time this routine is called for a request (Retrying
    FALSE), we automatically make the new request queue if there are other
    requests in the queue.

    Note that the ListEmpty test is important to prevent small requests from sneaking
    in and starving large requests.

Arguments:

    FileObject - for the file to be written

    BytesToWrite - Number of bytes caller wishes to write to the Cache.

    Wait - TRUE if the caller owns no resources, and can block inside this routine
           until it is ok to write.

    Retrying - Specified as FALSE when the request is first received, and
               otherwise specified as TRUE if this write has already entered
               the queue.  Special non-zero value of MAXUCHAR indicates that
               we were called within the cache manager with a MasterSpinLock held,
               so do not attempt to acquire it here.  MAXUCHAR - 1 means we
               were called within the Cache Manager with some other spinlock
               held.  MAXUCHAR - 2 means we want to enforce throttling, even if
               the file object is flagged as being of remote origin.  For either
               of the first two special values, we do not touch the FsRtl header.

Return Value:

    TRUE if it is ok to write.
    FALSE if the caller should defer the write via a call to CcDeferWrite.

--*/

{
    PSHARED_CACHE_MAP SharedCacheMap;
    KEVENT Event;
    KIRQL OldIrql;
    ULONG PagesToWrite;
    BOOLEAN ExceededPerFileThreshold;
    DEFERRED_WRITE DeferredWrite;
    PSECTION_OBJECT_POINTERS SectionObjectPointers;

    //
    //  If this file is writethrough or of remote origin, exempt it from throttling
    //  and let it write.  We do this under the assumption that it has been throttled
    //  at the remote location and we do not want to block it here.  If we were called
    //  with Retrying set to MAXUCHAR - 2, enforce the throttle regardless of the
    //  file object origin (see above).
    //

    if (BooleanFlagOn( FileObject->Flags, FO_WRITE_THROUGH) || 
        (IoIsFileOriginRemote(FileObject) && (Retrying != MAXUCHAR - 2))) {

        return TRUE;
    } 
    
    //
    //  Do a special test here for file objects that keep track of dirty
    //  pages on a per-file basis.  This is used mainly for slow links.
    //

    ExceededPerFileThreshold = FALSE;

    PagesToWrite = ((BytesToWrite < WRITE_CHARGE_THRESHOLD ?
                     BytesToWrite : WRITE_CHARGE_THRESHOLD) + (PAGE_SIZE - 1)) / PAGE_SIZE;

    //
    //  Don't dereference the FsContext field if we were called while holding
    //  a spinlock.
    //

    if ((Retrying >= MAXUCHAR - 1) ||

        FlagOn(((PFSRTL_COMMON_FCB_HEADER)(FileObject->FsContext))->Flags,
               FSRTL_FLAG_LIMIT_MODIFIED_PAGES)) {

        if (Retrying != MAXUCHAR) {
            CcAcquireMasterLock( &OldIrql );
        }

        if (((SectionObjectPointers = FileObject->SectionObjectPointer) != NULL) &&
            ((SharedCacheMap = SectionObjectPointers->SharedCacheMap) != NULL) &&
            (SharedCacheMap->DirtyPageThreshold != 0) &&
            (SharedCacheMap->DirtyPages != 0) &&
            ((PagesToWrite + SharedCacheMap->DirtyPages) >
              SharedCacheMap->DirtyPageThreshold)) {

            ExceededPerFileThreshold = TRUE;
        }

        if (Retrying != MAXUCHAR) {
            CcReleaseMasterLock( OldIrql );
        }
    }

    //
    //  See if it is ok to do the write right now
    //

    if ((Retrying || IsListEmpty(&CcDeferredWrites))

                &&

        (CcTotalDirtyPages + PagesToWrite < CcDirtyPageThreshold)

                &&

        MmEnoughMemoryForWrite()

                &&

        !ExceededPerFileThreshold) {

        return TRUE;
    }

    //
    //  Otherwise, if our caller is synchronous, we will just wait here.
    //

    if (Wait) {

        if (IsListEmpty(&CcDeferredWrites) ) {

            //
            // Get a write scan to occur NOW
            //

            CcAcquireMasterLock( &OldIrql );
            CcScheduleLazyWriteScan( TRUE );
            CcReleaseMasterLock( OldIrql );
        }
    
        KeInitializeEvent( &Event, NotificationEvent, FALSE );

        //
        //  Fill in the block.  Note that we can access the Fsrtl Common Header
        //  even if it's paged because Wait will be FALSE if called from
        //  within the cache.
        //

        DeferredWrite.NodeTypeCode = CACHE_NTC_DEFERRED_WRITE;
        DeferredWrite.NodeByteSize = sizeof(DEFERRED_WRITE);
        DeferredWrite.FileObject = FileObject;
        DeferredWrite.BytesToWrite = BytesToWrite;
        DeferredWrite.Event = &Event;
        DeferredWrite.LimitModifiedPages = BooleanFlagOn(((PFSRTL_COMMON_FCB_HEADER)(FileObject->FsContext))->Flags,
                                                         FSRTL_FLAG_LIMIT_MODIFIED_PAGES);

        //
        //  Now insert at the appropriate end of the list
        //

        if (Retrying) {
            ExInterlockedInsertHeadList( &CcDeferredWrites,
                                         &DeferredWrite.DeferredWriteLinks,
                                         &CcDeferredWriteSpinLock );
        } else {
            ExInterlockedInsertTailList( &CcDeferredWrites,
                                         &DeferredWrite.DeferredWriteLinks,
                                         &CcDeferredWriteSpinLock );
        }

        while (TRUE) {

            //
            //  Now since we really didn't synchronize anything but the insertion,
            //  we call the post routine to make sure that in some wierd case we
            //  do not leave anyone hanging with no dirty bytes for the Lazy Writer.
            //

            CcPostDeferredWrites();

            //
            //  Finally wait until the event is signalled and we can write
            //  and return to tell the guy he can write.
            //

            if (KeWaitForSingleObject( &Event,
                                       Executive,
                                       KernelMode,
                                       FALSE,
                                       &CcIdleDelay ) == STATUS_SUCCESS) {


                return TRUE;
            }
        }

    } else {
        return FALSE;
    }
}


VOID
CcDeferWrite (
    IN PFILE_OBJECT FileObject,
    IN PCC_POST_DEFERRED_WRITE PostRoutine,
    IN PVOID Context1,
    IN PVOID Context2,
    IN ULONG BytesToWrite,
    IN BOOLEAN Retrying
    )

/*++

Routine Description:

    This routine may be called to have the Cache Manager defer posting
    of a write until the Lazy Writer makes some progress writing, or
    there are more available pages.  A file system would normally call
    this routine after receiving FALSE from CcCanIWrite, and preparing
    the request to be posted.

Arguments:

    FileObject - for the file to be written

    PostRoutine - Address of the PostRoutine that the Cache Manager can
                  call to post the request when conditions are right.  Note
                  that it is possible that this routine will be called
                  immediately from this routine.

    Context1 - First context parameter for the post routine.

    Context2 - Secont parameter for the post routine.

    BytesToWrite - Number of bytes that the request is trying to write
                   to the cache.

    Retrying - Supplied as FALSE if the request is being posted for the
               first time, TRUE otherwise.

Return Value:

    None

--*/

{
    PDEFERRED_WRITE DeferredWrite;
    KIRQL OldIrql;

    //
    //  Attempt to allocate a deferred write block, and if we do not get
    //  one, just post it immediately rather than gobbling up must succeed
    //  pool.
    //

    DeferredWrite = ExAllocatePoolWithTag( NonPagedPool, sizeof(DEFERRED_WRITE), 'wDcC' );

    if (DeferredWrite == NULL) {
        (*PostRoutine)( Context1, Context2 );
        return;
    }

    //
    //  Fill in the block.
    //

    DeferredWrite->NodeTypeCode = CACHE_NTC_DEFERRED_WRITE;
    DeferredWrite->NodeByteSize = sizeof(DEFERRED_WRITE);
    DeferredWrite->FileObject = FileObject;
    DeferredWrite->BytesToWrite = BytesToWrite;
    DeferredWrite->Event = NULL;
    DeferredWrite->PostRoutine = PostRoutine;
    DeferredWrite->Context1 = Context1;
    DeferredWrite->Context2 = Context2;
    DeferredWrite->LimitModifiedPages = BooleanFlagOn(((PFSRTL_COMMON_FCB_HEADER)(FileObject->FsContext))->Flags,
                                                      FSRTL_FLAG_LIMIT_MODIFIED_PAGES);

    //
    //  Now insert at the appropriate end of the list
    //

    if (Retrying) {
        ExInterlockedInsertHeadList( &CcDeferredWrites,
                                     &DeferredWrite->DeferredWriteLinks,
                                     &CcDeferredWriteSpinLock );
    } else {
        ExInterlockedInsertTailList( &CcDeferredWrites,
                                     &DeferredWrite->DeferredWriteLinks,
                                     &CcDeferredWriteSpinLock );
    }

    //
    //  Now since we really didn't synchronize anything but the insertion,
    //  we call the post routine to make sure that in some wierd case we
    //  do not leave anyone hanging with no dirty bytes for the Lazy Writer.
    //

    CcPostDeferredWrites();

    //
    //  Schedule the lazy writer in case the reason we're blocking
    //  is that we're waiting for Mm (or some other external flag)
    //  to lower and let this write happen.  He will be the one to
    //  keep coming back and checking if this can proceed, even if
    //  there are no cache manager pages to write.
    //
            
    CcAcquireMasterLock( &OldIrql);
            
    if (!LazyWriter.ScanActive) {
        CcScheduleLazyWriteScan( FALSE );
    }

    CcReleaseMasterLock( OldIrql);
}


VOID
CcPostDeferredWrites (
    )

/*++

Routine Description:

    This routine may be called to see if any deferred writes should be posted
    now, and to post them.  It should be called any time the status of the
    queue may have changed, such as when a new entry has been added, or the
    Lazy Writer has finished writing out buffers and set them clean.

Arguments:

    None

Return Value:

    None

--*/

{
    PDEFERRED_WRITE DeferredWrite;
    ULONG TotalBytesLetLoose = 0;
    KIRQL OldIrql;

    do {

        //
        //  Initially clear the deferred write structure pointer
        //  and syncrhronize.
        //

        DeferredWrite = NULL;

        ExAcquireSpinLock( &CcDeferredWriteSpinLock, &OldIrql );

        //
        //  If the list is empty we are done.
        //

        if (!IsListEmpty(&CcDeferredWrites)) {

            PLIST_ENTRY Entry;

            Entry = CcDeferredWrites.Flink;

            while (Entry != &CcDeferredWrites) {

                DeferredWrite = CONTAINING_RECORD( Entry,
                                                   DEFERRED_WRITE,
                                                   DeferredWriteLinks );

                //
                //  Check for a paranoid case here that TotalBytesLetLoose
                //  wraps.  We stop processing the list at this time.
                //

                TotalBytesLetLoose += DeferredWrite->BytesToWrite;

                if (TotalBytesLetLoose < DeferredWrite->BytesToWrite) {

                    DeferredWrite = NULL;
                    break;
                }

                //
                //  If it is now ok to post this write, remove him from
                //  the list.
                //

                if (CcCanIWrite( DeferredWrite->FileObject,
                                 TotalBytesLetLoose,
                                 FALSE,
                                 MAXUCHAR - 1 )) {

                    RemoveEntryList( &DeferredWrite->DeferredWriteLinks );
                    break;

                //
                //  Otherwise, it is time to stop processing the list, so
                //  we clear the pointer again unless we throttled this item
                //  because of a private dirty page limit.
                //

                } else {

                    //
                    //  If this was a private throttle, skip over it and
                    //  remove its byte count from the running total.
                    //

                    if (DeferredWrite->LimitModifiedPages) {

                        Entry = Entry->Flink;
                        TotalBytesLetLoose -= DeferredWrite->BytesToWrite;
                        DeferredWrite = NULL;
                        continue;

                    } else {

                        DeferredWrite = NULL;

                        break;
                    }
                }
            }
        }

        ExReleaseSpinLock( &CcDeferredWriteSpinLock, OldIrql );

        //
        //  If we got something, set the event or call the post routine
        //  and deallocate the structure.
        //

        if (DeferredWrite != NULL) {

            if (DeferredWrite->Event != NULL) {

                KeSetEvent( DeferredWrite->Event, 0, FALSE );

            } else {

                (*DeferredWrite->PostRoutine)( DeferredWrite->Context1,
                                               DeferredWrite->Context2 );
                ExFreePool( DeferredWrite );
            }
        }

    //
    //  Loop until we find no more work to do.
    //

    } while (DeferredWrite != NULL);
}
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\base\ntos\cache\lazyrite.c ===
/*++

Copyright (c) 1990  Microsoft Corporation

Module Name:

    lazyrite.c

Abstract:

    This module implements the lazy writer for the Cache subsystem.

Author:

    Tom Miller      [TomM]      22-July-1990

Revision History:

--*/

#include "cc.h"

//
//  The Bug check file id for this module
//

#define BugCheckFileId                   (CACHE_BUG_CHECK_LAZYRITE)

//
//  Define our debug constant
//

#define me 0x00000020

//
//  Local support routines
//

PWORK_QUEUE_ENTRY
CcReadWorkQueue (
    );

VOID
CcLazyWriteScan (
    );


VOID
CcScheduleLazyWriteScan (
    IN BOOLEAN FastScan
    )

/*++

Routine Description:

    This routine may be called to schedule the next lazy writer scan,
    during which lazy write and lazy close activity is posted to other
    worker threads.  Callers should acquire the lazy writer spin lock
    to see if the scan is currently active, and then call this routine
    still holding the spin lock if not.  One special call is used at
    the end of the lazy write scan to propagate lazy write active once
    we go active.  This call is "the" scan thread, and it can therefore
    safely schedule the next scan without taking out the spin lock.

Arguments:

    FastScan - if set, make the scan happen immediately

Return Value:

    None.

--*/

{
    //
    //  It is important to set the active flag TRUE first for the propagate
    //  case, because it is conceivable that once the timer is set, another
    //  thread could actually run and make the scan go idle before we then
    //  jam the flag TRUE.
    //
    //  When going from idle to active, we delay a little longer to let the
    //  app finish saving its file.
    //

    if (FastScan) {
        
        LazyWriter.ScanActive = TRUE;
        KeSetTimer( &LazyWriter.ScanTimer, CcNoDelay, &LazyWriter.ScanDpc );

    } else if (LazyWriter.ScanActive) {

        KeSetTimer( &LazyWriter.ScanTimer, CcIdleDelay, &LazyWriter.ScanDpc );
    
    } else {

        LazyWriter.ScanActive = TRUE;
        KeSetTimer( &LazyWriter.ScanTimer, CcFirstDelay, &LazyWriter.ScanDpc );
    }
}


VOID
CcScanDpc (
    IN PKDPC Dpc,
    IN PVOID DeferredContext,
    IN PVOID SystemArgument1,
    IN PVOID SystemArgument2
    )

/*++

Routine Description:

    This is the Dpc routine which runs when the scan timer goes off.  It
    simply posts an element for an Ex Worker thread to do the scan.

Arguments:

    (All are ignored)

Return Value:

    None.

--*/

{
    PWORK_QUEUE_ENTRY WorkQueueEntry;

    UNREFERENCED_PARAMETER(Dpc);
    UNREFERENCED_PARAMETER(DeferredContext);
    UNREFERENCED_PARAMETER(SystemArgument1);
    UNREFERENCED_PARAMETER(SystemArgument2);

    WorkQueueEntry = CcAllocateWorkQueueEntry();

    //
    //  If we failed to allocate a WorkQueueEntry, things must
    //  be in pretty bad shape.  However, all we have to do is
    //  say we are not active, and wait for another event to
    //  wake things up again.
    //

    if (WorkQueueEntry == NULL) {

        LazyWriter.ScanActive = FALSE;

    } else {

        //
        //  Otherwise post a work queue entry to do the scan.
        //

        WorkQueueEntry->Function = (UCHAR)LazyWriteScan;

        CcPostWorkQueue( WorkQueueEntry, &CcRegularWorkQueue );
    }
}


NTSTATUS
CcWaitForCurrentLazyWriterActivity (
    )

/*++

Routine Description:

    This routine allows a thread to receive notification when the current tick
    of lazy writer work has completed.  It must not be called within a lazy
    writer workitem!  The caller must not be holding synchronization that could
    block a Cc workitem!

    In particular, this lets a caller insure that all available lazy closes at
    the time of the call have completed.

Arguments:

    None.

Return Value:

    Final result of the wait.

--*/

{
    KIRQL OldIrql;
    KEVENT Event;
    PWORK_QUEUE_ENTRY WorkQueueEntry;

    WorkQueueEntry = CcAllocateWorkQueueEntry();

    if (WorkQueueEntry == NULL) {
        return STATUS_INSUFFICIENT_RESOURCES;
    }

    WorkQueueEntry->Function = (UCHAR)EventSet;
    KeInitializeEvent( &Event, NotificationEvent, FALSE );
    WorkQueueEntry->Parameters.Event.Event = &Event;

    //
    //  Add this to the post-tick work queue and wake the lazy writer for it.
    //  The lazy writer will add this to the end of the next batch of work
    //  he issues.
    //

    CcAcquireMasterLock( &OldIrql );

    InsertTailList( &CcPostTickWorkQueue, &WorkQueueEntry->WorkQueueLinks );

    LazyWriter.OtherWork = TRUE;
    if (!LazyWriter.ScanActive) {
        CcScheduleLazyWriteScan( TRUE );
    }

    CcReleaseMasterLock( OldIrql );

    return KeWaitForSingleObject( &Event, Executive, KernelMode, FALSE, NULL );
}



VOID
CcLazyWriteScan (
    )

/*++

Routine Description:

    This routine implements the Lazy Writer scan for dirty data to flush
    or any other work to do (lazy close).  This routine is scheduled by
    calling CcScheduleLazyWriteScan.

Arguments:

    None.

Return Value:

    None.

--*/

{
    ULONG PagesToWrite, ForegroundRate, EstimatedDirtyNextInterval;
    PSHARED_CACHE_MAP SharedCacheMap, FirstVisited;
    KIRQL OldIrql;
    ULONG LoopsWithLockHeld = 0;
    BOOLEAN AlreadyMoved = FALSE;

    LIST_ENTRY PostTickWorkQueue;

    //
    //  Top of Lazy Writer scan.
    //

    try {

        //
        //  If there is no work to do, then we will go inactive, and return.
        //

        CcAcquireMasterLock( &OldIrql );

        if ((CcTotalDirtyPages == 0) && !LazyWriter.OtherWork) {

            //
            //  Sleep if there are no deferred writes.  It is important to check
            //  proactively because writes may be blocked for reasons external
            //  to the cache manager.  The lazy writer must keep poking since it
            //  may have no bytes to write itself.
            //

            if (IsListEmpty(&CcDeferredWrites)) {

                LazyWriter.ScanActive = FALSE;
                CcReleaseMasterLock( OldIrql );

            } else {

                CcReleaseMasterLock( OldIrql );

                //
                //  Check for writes and schedule the next scan.
                //

                CcPostDeferredWrites();
                CcScheduleLazyWriteScan( FALSE );
            }

            return;
        }

        //
        //  Pull out the post tick workitems for this pass.  It is important that
        //  we are doing this at the top since more could be queued as we rummage
        //  for work to do.  Post tick workitems are guaranteed to occur after all
        //  work generated in a complete scan.
        //

        InitializeListHead( &PostTickWorkQueue );
        while (!IsListEmpty( &CcPostTickWorkQueue )) {

            PLIST_ENTRY Entry = RemoveHeadList( &CcPostTickWorkQueue );
            InsertTailList( &PostTickWorkQueue, Entry );
        }

        //
        //  Calculate the next sweep time stamp, then update all relevant fields for
        //  the next time around.  Also we can clear the OtherWork flag.
        //

        LazyWriter.OtherWork = FALSE;

        //
        //  Assume we will write our usual fraction of dirty pages.  Do not do the
        //  divide if there is not enough dirty pages, or else we will never write
        //  the last few pages.
        //

        PagesToWrite = CcTotalDirtyPages;
        if (PagesToWrite > LAZY_WRITER_MAX_AGE_TARGET) {
            PagesToWrite /= LAZY_WRITER_MAX_AGE_TARGET;
        }

        //
        //  Estimate the rate of dirty pages being produced in the foreground.
        //  This is the total number of dirty pages now plus the number of dirty
        //  pages we scheduled to write last time, minus the number of dirty
        //  pages we have now.  Throw out any cases which would not produce a
        //  positive rate.
        //

        ForegroundRate = 0;

        if ((CcTotalDirtyPages + CcPagesWrittenLastTime) > CcDirtyPagesLastScan) {
            ForegroundRate = (CcTotalDirtyPages + CcPagesWrittenLastTime) -
                             CcDirtyPagesLastScan;
        }

        //
        //  If we estimate that we will exceed our dirty page target by the end
        //  of this interval, then we must write more.  Try to arrive on target.
        //

        EstimatedDirtyNextInterval = CcTotalDirtyPages - PagesToWrite + ForegroundRate;

        if (EstimatedDirtyNextInterval > CcDirtyPageTarget) {

            PagesToWrite += EstimatedDirtyNextInterval - CcDirtyPageTarget;
        }

        //
        //  Now save away the number of dirty pages and the number of pages we
        //  just calculated to write.
        //

        CcDirtyPagesLastScan = CcTotalDirtyPages;
        CcPagesYetToWrite = CcPagesWrittenLastTime = PagesToWrite;

        //
        //  Loop to flush enough Shared Cache Maps to write the number of pages
        //  we just calculated.
        //

        SharedCacheMap = CONTAINING_RECORD( CcLazyWriterCursor.SharedCacheMapLinks.Flink,
                                            SHARED_CACHE_MAP,
                                            SharedCacheMapLinks );

        DebugTrace( 0, me, "Start of Lazy Writer Scan\n", 0 );

        //
        //  Normally we would just like to visit every Cache Map once on each scan,
        //  so the scan will terminate normally when we return to FirstVisited.  But
        //  in the off chance that FirstVisited gets deleted, we are guaranteed to stop
        //  when we get back to our own listhead.
        //

        FirstVisited = NULL;
        while ((SharedCacheMap != FirstVisited) &&
               (&SharedCacheMap->SharedCacheMapLinks != &CcLazyWriterCursor.SharedCacheMapLinks)) {

            if (FirstVisited == NULL) {
                FirstVisited = SharedCacheMap;
            }

            //
            //  Skip the SharedCacheMap if a write behind request is
            //  already queued, write behind has been disabled, or
            //  if there is no work to do (either dirty data to be written
            //  or a delete is required).
            //
            //  Note that for streams where modified writing is disabled, we
            //  need to take out Bcbs exclusive, which serializes with foreground
            //  activity.  Therefore we use a special counter in the SharedCacheMap
            //  to only service these once every n intervals.
            //
            //  Skip temporary files unless we currently could not write as many
            //  bytes as we might charge some hapless thread for throttling, unless
            //  it has been closed.  We assume that the "tick" of the lazy writer,
            //  delayed temporarily by the passcount check, will permit the common
            //  open/write/close/delete action on temporary files to sneak in and
            //  truncate the file before we really write the data, if the file was
            //  not opened delete-on-close to begin with.
            //
            //  Since we will write closed files with dirty pages as part of the
            //  regular pass (even temporary ones), only do lazy close on files
            //  with no dirty pages.
            //

            if (!FlagOn(SharedCacheMap->Flags, WRITE_QUEUED | IS_CURSOR)

                    &&

                (((PagesToWrite != 0) && (SharedCacheMap->DirtyPages != 0) &&
                  (((++SharedCacheMap->LazyWritePassCount & 0xF) == 0) ||
                   !FlagOn(SharedCacheMap->Flags, MODIFIED_WRITE_DISABLED) ||
                   (CcCapturedSystemSize == MmSmallSystem) ||
                   (SharedCacheMap->DirtyPages >= (4 * (MAX_WRITE_BEHIND / PAGE_SIZE)))) &&
                  (!FlagOn(SharedCacheMap->FileObject->Flags, FO_TEMPORARY_FILE) ||
                   (SharedCacheMap->OpenCount == 0) ||
                   !CcCanIWrite(SharedCacheMap->FileObject, WRITE_CHARGE_THRESHOLD, FALSE, MAXUCHAR)))

                    ||

                 ((SharedCacheMap->OpenCount == 0) &&
                  (SharedCacheMap->DirtyPages == 0) ||
                  (SharedCacheMap->FileSize.QuadPart == 0)))) {

                PWORK_QUEUE_ENTRY WorkQueueEntry;

                //
                //  If this is a metadata stream with at least 4 times
                //  the maximum write behind I/O size, then let's tell
                //  this guy to write 1/8 of his dirty data on this pass
                //  so it doesn't build up.
                //
                //  Else assume we can write everything (PagesToWrite only affects
                //  metadata streams - otherwise writing is controlled by the Mbcb -
                //  this throttle is engaged in CcWriteBehind).
                //

                SharedCacheMap->PagesToWrite = SharedCacheMap->DirtyPages;

                if (FlagOn(SharedCacheMap->Flags, MODIFIED_WRITE_DISABLED) &&
                    (SharedCacheMap->PagesToWrite >= (4 * (MAX_WRITE_BEHIND / PAGE_SIZE))) &&
                    (CcCapturedSystemSize != MmSmallSystem)) {

                    SharedCacheMap->PagesToWrite /= 8;
                }

                //
                //  If still searching for pages to write, adjust our targets.
                //

                if (!AlreadyMoved) {

                    //
                    //  See if he exhausts the number of pages to write.  (We
                    //  keep going in case there are any closes to do.)
                    //

                    if (SharedCacheMap->PagesToWrite >= PagesToWrite) {

                        //
                        //  Here is where we should move the cursor to.  Figure
                        //  out if we should resume on this stream or the next one.
                        //

                        RemoveEntryList( &CcLazyWriterCursor.SharedCacheMapLinks );

                        //
                        //  For Metadata streams, set up to resume on the next stream on the
                        //  next scan.  Also force a push forward every n intervals if all of
                        //  the pages came from this stream, so we don't get preoccupied with
                        //  one stream at the expense of others (which may be waiting for a
                        //  lazy close).  Normally we would like to avoid seek overhead and
                        //  take the common case of a large sequential series of writes.
                        //
                        //  This is similar to hotspot detection.
                        //

                        if (FlagOn(SharedCacheMap->Flags, MODIFIED_WRITE_DISABLED) ||
                            ((FirstVisited == SharedCacheMap) &&
                             ((SharedCacheMap->LazyWritePassCount & 0xF) == 0))) {
                            InsertHeadList( &SharedCacheMap->SharedCacheMapLinks, &CcLazyWriterCursor.SharedCacheMapLinks );

                            //
                            //  For other streams, set up to resume on the same stream on the
                            //  next scan.
                            //

                        } else {
                            InsertTailList( &SharedCacheMap->SharedCacheMapLinks, &CcLazyWriterCursor.SharedCacheMapLinks );
                        }

                        PagesToWrite = 0;
                        AlreadyMoved = TRUE;

                    } else {

                        PagesToWrite -= SharedCacheMap->PagesToWrite;
                    }
                }

                //
                //  Otherwise show we are actively writing, and keep it in the dirty
                //  list.
                //

                SetFlag(SharedCacheMap->Flags, WRITE_QUEUED);
                SharedCacheMap->DirtyPages += 1;

                CcReleaseMasterLock( OldIrql );

                //
                //  Queue the request to do the work to a worker thread.
                //

                WorkQueueEntry = CcAllocateWorkQueueEntry();

                //
                //  If we failed to allocate a WorkQueueEntry, things must
                //  be in pretty bad shape.  However, all we have to do is
                //  break out of our current loop, and try to go back and
                //  delay a while.  Even if the current guy should have gone
                //  away when we clear WRITE_QUEUED, we will find him again
                //  in the LW scan.
                //

                if (WorkQueueEntry == NULL) {

                    CcAcquireMasterLock( &OldIrql );
                    ClearFlag(SharedCacheMap->Flags, WRITE_QUEUED);
                    SharedCacheMap->DirtyPages -= 1;
                    break;
                }

                WorkQueueEntry->Function = (UCHAR)WriteBehind;
                WorkQueueEntry->Parameters.Write.SharedCacheMap = SharedCacheMap;

                //
                //  Post it to the regular work queue.
                //

                CcAcquireMasterLock( &OldIrql );
                SharedCacheMap->DirtyPages -= 1;
                CcPostWorkQueue( WorkQueueEntry, &CcRegularWorkQueue );

                LoopsWithLockHeld = 0;

            //
            //  Make sure we occasionally drop the lock.  Set WRITE_QUEUED
            //  to keep the guy from going away.
            //

            } else if ((++LoopsWithLockHeld >= 20) &&
                       !FlagOn(SharedCacheMap->Flags, WRITE_QUEUED | IS_CURSOR)) {

                SetFlag(SharedCacheMap->Flags, WRITE_QUEUED);
                SharedCacheMap->DirtyPages += 1;
                CcReleaseMasterLock( OldIrql );
                LoopsWithLockHeld = 0;
                CcAcquireMasterLock( &OldIrql );
                ClearFlag(SharedCacheMap->Flags, WRITE_QUEUED);
                SharedCacheMap->DirtyPages -= 1;
            }

            //
            //  Now loop back.
            //

            SharedCacheMap =
                CONTAINING_RECORD( SharedCacheMap->SharedCacheMapLinks.Flink,
                                   SHARED_CACHE_MAP,
                                   SharedCacheMapLinks );
        }

        DebugTrace( 0, me, "End of Lazy Writer Scan\n", 0 );

        //
        //  Queue up our  post tick workitems for this pass.
        //

        while (!IsListEmpty( &PostTickWorkQueue )) {

            PLIST_ENTRY Entry = RemoveHeadList( &PostTickWorkQueue );
            CcPostWorkQueue( CONTAINING_RECORD( Entry, WORK_QUEUE_ENTRY, WorkQueueLinks ),
                             &CcRegularWorkQueue );
        }

        //
        //  Now we can release the global list and loop back, per chance to sleep.
        //

        CcReleaseMasterLock( OldIrql );

        //
        //  Once again we need to give the deferred writes a poke.  We can have all dirty
        //  pages on disable_write_behind files but also have an external condition that
        //  caused the cached IO to be deferred. If so, this serves as our only chance to
        //  issue it when the condition clears.
        //
        //  Case hit on ForrestF's 5gb Alpha, 1/12/99.
        //

        if (!IsListEmpty(&CcDeferredWrites)) {

            CcPostDeferredWrites();
        }

        //
        //  Now go ahead and schedule the next scan.
        //

        CcScheduleLazyWriteScan( FALSE );

    //
    //  Basically, the Lazy Writer thread should never get an exception,
    //  so we put a try-except around it that bug checks one way or the other.
    //  Better we bug check here than worry about what happens if we let one
    //  get by.
    //

    } except( CcExceptionFilter( GetExceptionCode() )) {

        CcBugCheck( GetExceptionCode(), 0, 0 );
    }
}


//
//  Internal support routine
//

LONG
CcExceptionFilter (
    IN NTSTATUS ExceptionCode
    )

/*++

Routine Description:

    This is the standard exception filter for worker threads which simply
    calls an FsRtl routine to see if an expected status is being raised.
    If so, the exception is handled, else we bug check.

Arguments:

    ExceptionCode - the exception code which was raised.

Return Value:

    EXCEPTION_EXECUTE_HANDLER if expected, else a Bug Check occurs.

--*/

{
    DebugTrace(0, 0, "CcExceptionFilter %08lx\n", ExceptionCode);

    if (FsRtlIsNtstatusExpected( ExceptionCode )) {

        return EXCEPTION_EXECUTE_HANDLER;

    } else {

        return EXCEPTION_CONTINUE_SEARCH;
    }
}



//
//  Internal support routine
//

VOID
FASTCALL
CcPostWorkQueue (
    IN PWORK_QUEUE_ENTRY WorkQueueEntry,
    IN PLIST_ENTRY WorkQueue
    )

/*++

Routine Description:

    This routine queues a WorkQueueEntry, which has been allocated and
    initialized by the caller, to the WorkQueue for FIFO processing by
    the work threads.

Arguments:

    WorkQueueEntry - supplies a pointer to the entry to queue

Return Value:

    None

--*/

{
    KIRQL OldIrql;
    PLIST_ENTRY WorkerThreadEntry = NULL;

    ASSERT(FIELD_OFFSET(WORK_QUEUE_ITEM, List) == 0);

    DebugTrace(+1, me, "CcPostWorkQueue:\n", 0 );
    DebugTrace( 0, me, "    WorkQueueEntry = %08lx\n", WorkQueueEntry );

    //
    //  Queue the entry to the respective work queue.
    //

    CcAcquireWorkQueueLock( &OldIrql );
    InsertTailList( WorkQueue, &WorkQueueEntry->WorkQueueLinks );

    //
    //  Now, if we aren't throttled and have any more idle threads we can
    //  use, activate one.
    //

    if (!CcQueueThrottle && !IsListEmpty(&CcIdleWorkerThreadList)) {
        WorkerThreadEntry = RemoveHeadList( &CcIdleWorkerThreadList );
        CcNumberActiveWorkerThreads += 1;
    }
    CcReleaseWorkQueueLock( OldIrql );

    if (WorkerThreadEntry != NULL) {

        //
        //  I had to peak in the sources to verify that this routine
        //  is a noop if the Flink is not NULL.  Sheeeeit!
        //

        ((PWORK_QUEUE_ITEM)WorkerThreadEntry)->List.Flink = NULL;
        ExQueueWorkItem( (PWORK_QUEUE_ITEM)WorkerThreadEntry, CriticalWorkQueue );
    }

    //
    //  And return to our caller
    //

    DebugTrace(-1, me, "CcPostWorkQueue -> VOID\n", 0 );

    return;
}


//
//  Internal support routine
//

VOID
CcWorkerThread (
    PVOID ExWorkQueueItem
    )

/*++

Routine Description:

    This is worker thread routine for processing cache manager work queue
    entries.

Arguments:

    ExWorkQueueItem - The work item used for this thread

Return Value:

    None

--*/

{
    KIRQL OldIrql;
    PLIST_ENTRY WorkQueue;
    PWORK_QUEUE_ENTRY WorkQueueEntry;
    BOOLEAN RescanOk = FALSE;
    BOOLEAN DropThrottle = FALSE;
    IO_STATUS_BLOCK IoStatus;

    IoStatus.Status = STATUS_SUCCESS;
    IoStatus.Information = 0;

    ASSERT(FIELD_OFFSET(WORK_QUEUE_ENTRY, WorkQueueLinks) == 0);

    while (TRUE) {

        CcAcquireWorkQueueLock( &OldIrql );

        //
        //  If we just processed a throttled operation, drop the flag.
        //

        if (DropThrottle) {

            DropThrottle = CcQueueThrottle = FALSE;
        }

        //
        //  On requeue, push at end of the source queue and clear hint.
        //

        if (IoStatus.Information == CC_REQUEUE) {

            InsertTailList( WorkQueue, &WorkQueueEntry->WorkQueueLinks );
            IoStatus.Information = 0;
        }

        //
        //  First see if there is something in the express queue.
        //

        if (!IsListEmpty(&CcExpressWorkQueue)) {
            WorkQueue = &CcExpressWorkQueue;

        //
        //  If there was nothing there, then try the regular queue.
        //

        } else if (!IsListEmpty(&CcRegularWorkQueue)) {
            WorkQueue = &CcRegularWorkQueue;

        //
        //  Else we can break and go idle.
        //

        } else {

            break;
        }

        WorkQueueEntry = CONTAINING_RECORD( WorkQueue->Flink, WORK_QUEUE_ENTRY, WorkQueueLinks );

        //
        //  If this is an EventSet, throttle down to a single thread to be sure
        //  that this event fires after all preceeding workitems have completed.
        //

        if (WorkQueueEntry->Function == EventSet && CcNumberActiveWorkerThreads > 1) {

            CcQueueThrottle = TRUE;
            break;
        }

        //
        //  Pop the workitem off: we will execute it now.
        //

        RemoveHeadList( WorkQueue );

        CcReleaseWorkQueueLock( OldIrql );

        //
        //  Process the entry within a try-except clause, so that any errors
        //  will cause us to continue after the called routine has unwound.
        //

        try {

            switch (WorkQueueEntry->Function) {

            //
            //  Perform read ahead
            //

            case ReadAhead:

                DebugTrace( 0, me, "CcWorkerThread Read Ahead FileObject = %08lx\n",
                            WorkQueueEntry->Parameters.Read.FileObject );

                CcPerformReadAhead( WorkQueueEntry->Parameters.Read.FileObject );

                break;

            //
            //  Perform write behind
            //

            case WriteBehind:

                DebugTrace( 0, me, "CcWorkerThread WriteBehind SharedCacheMap = %08lx\n",
                            WorkQueueEntry->Parameters.Write.SharedCacheMap );

                CcWriteBehind( WorkQueueEntry->Parameters.Write.SharedCacheMap, &IoStatus );
                RescanOk = (BOOLEAN)NT_SUCCESS(IoStatus.Status);
                break;


            //
            //  Perform set event
            //
        
            case EventSet:

                DebugTrace( 0, me, "CcWorkerThread SetEvent Event = %08lx\n",
                            WorkQueueEntry->Parameters.Event.Event );

                KeSetEvent( WorkQueueEntry->Parameters.Event.Event, 0, FALSE );
                DropThrottle = TRUE;
                break;

            //
            //  Perform Lazy Write Scan
            //

            case LazyWriteScan:

                DebugTrace( 0, me, "CcWorkerThread Lazy Write Scan\n", 0 );

                CcLazyWriteScan();
                break;
            }

        }
        except( CcExceptionFilter( GetExceptionCode() )) {

            NOTHING;
        }

        //
        //  If not a requeue request, free the workitem.
        //

        if (IoStatus.Information != CC_REQUEUE) {

            CcFreeWorkQueueEntry( WorkQueueEntry );
        }
    }

    //
    //  No more work.  Requeue our worker thread entry and get out.
    //

    InsertTailList( &CcIdleWorkerThreadList,
                    &((PWORK_QUEUE_ITEM)ExWorkQueueItem)->List );
    CcNumberActiveWorkerThreads -= 1;

    CcReleaseWorkQueueLock( OldIrql );

    if (!IsListEmpty(&CcDeferredWrites) && (CcTotalDirtyPages >= 20) && RescanOk) {
        CcLazyWriteScan();
    }

    return;
}
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\base\ntos\cache\mdlsup.c ===
/*++

Copyright (c) 1990  Microsoft Corporation

Module Name:

    mdlsup.c

Abstract:

    This module implements the Mdl support routines for the Cache subsystem.

Author:

    Tom Miller      [TomM]      4-May-1990

Revision History:

--*/

#include "cc.h"

//
//  Debug Trace Level
//

#define me                               (0x00000010)

#ifdef ALLOC_PRAGMA
#pragma alloc_text(PAGE,CcMdlRead)
#pragma alloc_text(PAGE,CcMdlReadComplete)
#pragma alloc_text(PAGE,CcMdlReadComplete2)
#pragma alloc_text(PAGE,CcMdlWriteComplete)
#endif


VOID
CcMdlRead (
    IN PFILE_OBJECT FileObject,
    IN PLARGE_INTEGER FileOffset,
    IN ULONG Length,
    OUT PMDL *MdlChain,
    OUT PIO_STATUS_BLOCK IoStatus
    )

/*++

Routine Description:

    This routine attempts to lock the specified file data in the cache
    and return a description of it in an Mdl along with the correct
    I/O status.  It is *not* safe to call this routine from Dpc level.

    This routine is synchronous, and raises on errors.

    As each call returns, the pages described by the Mdl are
    locked in memory, but not mapped in system space.  If the caller
    needs the pages mapped in system space, then it must map them.

    Note that each call is a "single shot" which should be followed by
    a call to CcMdlReadComplete.  To resume an Mdl-based transfer, the
    caller must form one or more subsequent calls to CcMdlRead with
    appropriately adjusted parameters.

Arguments:

    FileObject - Pointer to the file object for a file which was
                 opened with NO_INTERMEDIATE_BUFFERING clear, i.e., for
                 which CcInitializeCacheMap was called by the file system.

    FileOffset - Byte offset in file for desired data.

    Length - Length of desired data in bytes.

    MdlChain - On output it returns a pointer to an Mdl chain describing
               the desired data.  Note that even if FALSE is returned,
               one or more Mdls may have been allocated, as may be ascertained
               by the IoStatus.Information field (see below).

    IoStatus - Pointer to standard I/O status block to receive the status
               for the transfer.  (STATUS_SUCCESS guaranteed for cache
               hits, otherwise the actual I/O status is returned.)  The
               I/O Information Field indicates how many bytes have been
               successfully locked down in the Mdl Chain.

Return Value:

    None

Raises:

    STATUS_INSUFFICIENT_RESOURCES - If a pool allocation failure occurs.

--*/

{
    PSHARED_CACHE_MAP SharedCacheMap;
    PPRIVATE_CACHE_MAP PrivateCacheMap;
    PVOID CacheBuffer;
    LARGE_INTEGER FOffset;
    PMDL Mdl = NULL;
    PMDL MdlTemp;
    PETHREAD Thread = PsGetCurrentThread();
    ULONG SavedState = 0;
    ULONG OriginalLength = Length;
    ULONG Information = 0;
    PVACB Vacb = NULL;
    ULONG SavedMissCounter = 0;

    ULONG ActivePage;
    ULONG PageIsDirty;
    PVACB ActiveVacb = NULL;

    DebugTrace(+1, me, "CcMdlRead\n", 0 );
    DebugTrace( 0, me, "    FileObject = %08lx\n", FileObject );
    DebugTrace2(0, me, "    FileOffset = %08lx, %08lx\n", FileOffset->LowPart,
                                                          FileOffset->HighPart );
    DebugTrace( 0, me, "    Length = %08lx\n", Length );

    //
    //  Save the current readahead hints.
    //

    MmSavePageFaultReadAhead( Thread, &SavedState );

    //
    //  Get pointer to SharedCacheMap.
    //

    SharedCacheMap = FileObject->SectionObjectPointer->SharedCacheMap;
    PrivateCacheMap = FileObject->PrivateCacheMap;

    //
    //  See if we have an active Vacb, that we need to free.
    //

    GetActiveVacb( SharedCacheMap, OldIrql, ActiveVacb, ActivePage, PageIsDirty );

    //
    //  If there is an end of a page to be zeroed, then free that page now,
    //  so we don't send Greg the uninitialized data...
    //

    if ((ActiveVacb != NULL) || (SharedCacheMap->NeedToZero != NULL)) {

        CcFreeActiveVacb( SharedCacheMap, ActiveVacb, ActivePage, PageIsDirty );
    }

    //
    //  If read ahead is enabled, then do the read ahead here so it
    //  overlaps with the copy (otherwise we will do it below).
    //  Note that we are assuming that we will not get ahead of our
    //  current transfer - if read ahead is working it should either
    //  already be in memory or else underway.
    //

    if (PrivateCacheMap->Flags.ReadAheadEnabled && (PrivateCacheMap->ReadAheadLength[1] == 0)) {
        CcScheduleReadAhead( FileObject, FileOffset, Length );
    }

    //
    //  Increment performance counters
    //

    CcMdlReadWait += 1;

    //
    //  This is not an exact solution, but when IoPageRead gets a miss,
    //  it cannot tell whether it was CcCopyRead or CcMdlRead, but since
    //  the miss should occur very soon, by loading the pointer here
    //  probably the right counter will get incremented, and in any case,
    //  we hope the errrors average out!
    //

    CcMissCounter = &CcMdlReadWaitMiss;

    FOffset = *FileOffset;

    //
    //  Check for read past file size, the caller must filter this case out.
    //

    ASSERT( ( FOffset.QuadPart + (LONGLONG)Length ) <= SharedCacheMap->FileSize.QuadPart );

    //
    //  Put try-finally around the loop to deal with any exceptions
    //

    try {

        //
        //  Not all of the transfer will come back at once, so we have to loop
        //  until the entire transfer is complete.
        //

        while (Length != 0) {

            ULONG ReceivedLength;
            LARGE_INTEGER BeyondLastByte;

            //
            //  Map the data and read it in (if necessary) with the
            //  MmProbeAndLockPages call below.
            //

            CacheBuffer = CcGetVirtualAddress( SharedCacheMap,
                                               FOffset,
                                               &Vacb,
                                               &ReceivedLength );

            if (ReceivedLength > Length) {
                ReceivedLength = Length;
            }

            BeyondLastByte.QuadPart = FOffset.QuadPart + (LONGLONG)ReceivedLength;

            //
            //  Now attempt to allocate an Mdl to describe the mapped data.
            //

            DebugTrace( 0, mm, "IoAllocateMdl:\n", 0 );
            DebugTrace( 0, mm, "    BaseAddress = %08lx\n", CacheBuffer );
            DebugTrace( 0, mm, "    Length = %08lx\n", ReceivedLength );

            Mdl = IoAllocateMdl( CacheBuffer,
                                 ReceivedLength,
                                 FALSE,
                                 FALSE,
                                 NULL );

            DebugTrace( 0, mm, "    <Mdl = %08lx\n", Mdl );

            if (Mdl == NULL) {
                DebugTrace( 0, 0, "Failed to allocate Mdl\n", 0 );

                ExRaiseStatus( STATUS_INSUFFICIENT_RESOURCES );
            }

            DebugTrace( 0, mm, "MmProbeAndLockPages:\n", 0 );
            DebugTrace( 0, mm, "    Mdl = %08lx\n", Mdl );

            //
            //  Set to see if the miss counter changes in order to
            //  detect when we should turn on read ahead.
            //

            SavedMissCounter += CcMdlReadWaitMiss;

            MmSetPageFaultReadAhead( Thread, ADDRESS_AND_SIZE_TO_SPAN_PAGES( CacheBuffer, ReceivedLength ) - 1);
            MmProbeAndLockPages( Mdl, KernelMode, IoReadAccess );

            SavedMissCounter -= CcMdlReadWaitMiss;

            //
            //  Unmap the data now, now that the pages are locked down.
            //

            CcFreeVirtualAddress( Vacb );
            Vacb = NULL;

            //
            //  Now link the Mdl into the caller's chain
            //

            if ( *MdlChain == NULL ) {
                *MdlChain = Mdl;
            } else {
                MdlTemp = CONTAINING_RECORD( *MdlChain, MDL, Next );
                while (MdlTemp->Next != NULL) {
                    MdlTemp = MdlTemp->Next;
                }
                MdlTemp->Next = Mdl;
            }
            Mdl = NULL;

            //
            //  Assume we did not get all the data we wanted, and set FOffset
            //  to the end of the returned data.
            //

            FOffset = BeyondLastByte;

            //
            //  Update number of bytes transferred.
            //

            Information += ReceivedLength;

            //
            //  Calculate length left to transfer.
            //

            Length -= ReceivedLength;
        }
    }
    finally {

        CcMissCounter = &CcThrowAway;

        //
        //  Restore the readahead hints.
        //

        MmResetPageFaultReadAhead( Thread, SavedState );

        if (AbnormalTermination()) {

            //
            //  We may have failed to allocate an Mdl while still having
            //  data mapped.
            //

            if (Vacb != NULL) {
                CcFreeVirtualAddress( Vacb );
            }

            if (Mdl != NULL) {
                IoFreeMdl( Mdl );
            }

            //
            //  Otherwise loop to deallocate the Mdls
            //

            while (*MdlChain != NULL) {
                MdlTemp = (*MdlChain)->Next;

                DebugTrace( 0, mm, "MmUnlockPages/IoFreeMdl:\n", 0 );
                DebugTrace( 0, mm, "    Mdl = %08lx\n", *MdlChain );

                MmUnlockPages( *MdlChain );
                IoFreeMdl( *MdlChain );

                *MdlChain = MdlTemp;
            }

            DebugTrace(-1, me, "CcMdlRead -> Unwinding\n", 0 );

        }
        else {

            //
            //  Now enable read ahead if it looks like we got any misses, and do
            //  the first one.
            //

            if (!FlagOn( FileObject->Flags, FO_RANDOM_ACCESS ) &&
                !PrivateCacheMap->Flags.ReadAheadEnabled &&
                (SavedMissCounter != 0)) {

                CC_CLEAR_PRIVATE_CACHE_MAP (PrivateCacheMap, PRIVATE_CACHE_MAP_READ_AHEAD_ENABLED);
                CcScheduleReadAhead( FileObject, FileOffset, OriginalLength );
            }

            //
            //  Now that we have described our desired read ahead, let's
            //  shift the read history down.
            //

            PrivateCacheMap->FileOffset1 = PrivateCacheMap->FileOffset2;
            PrivateCacheMap->BeyondLastByte1 = PrivateCacheMap->BeyondLastByte2;
            PrivateCacheMap->FileOffset2 = *FileOffset;
            PrivateCacheMap->BeyondLastByte2.QuadPart =
                                FileOffset->QuadPart + (LONGLONG)OriginalLength;

            IoStatus->Status = STATUS_SUCCESS;
            IoStatus->Information = Information;
        }
    }


    DebugTrace( 0, me, "    <MdlChain = %08lx\n", *MdlChain );
    DebugTrace2(0, me, "    <IoStatus = %08lx, %08lx\n", IoStatus->Status,
                                                         IoStatus->Information );
    DebugTrace(-1, me, "CcMdlRead -> VOID\n", 0 );

    return;
}


//
//  First we have the old routine which checks for an entry in the FastIo vector.
//  This routine becomes obsolete for every component that compiles with the new
//  definition of FsRtlMdlReadComplete in fsrtl.h.
//

VOID
CcMdlReadComplete (
    IN PFILE_OBJECT FileObject,
    IN PMDL MdlChain
    )

{
    PDEVICE_OBJECT DeviceObject;
    PFAST_IO_DISPATCH FastIoDispatch;

    DeviceObject = IoGetRelatedDeviceObject( FileObject );
    FastIoDispatch = DeviceObject->DriverObject->FastIoDispatch;

    if ((FastIoDispatch != NULL) &&
        (FastIoDispatch->SizeOfFastIoDispatch > FIELD_OFFSET(FAST_IO_DISPATCH, MdlWriteComplete)) &&
        (FastIoDispatch->MdlReadComplete != NULL) &&
        FastIoDispatch->MdlReadComplete( FileObject, MdlChain, DeviceObject )) {

        NOTHING;

    } else {
        CcMdlReadComplete2( FileObject, MdlChain );
    }
}

VOID
CcMdlReadComplete2 (
    IN PFILE_OBJECT FileObject,
    IN PMDL MdlChain
    )

/*++

Routine Description:

    This routine must be called at IPL0 after a call to CcMdlRead.  The
    caller must simply supply the address of the MdlChain returned in
    CcMdlRead.

    This call does the following:

        Deletes the MdlChain

Arguments:

    FileObject - Pointer to the file object for a file which was
                 opened with NO_INTERMEDIATE_BUFFERING clear, i.e., for
                 which CcInitializeCacheMap was called by the file system.

    MdlChain - same as returned from corresponding call to CcMdlRead.

Return Value:

    None.
--*/

{
    PMDL MdlNext;

    UNREFERENCED_PARAMETER (FileObject);

    DebugTrace(+1, me, "CcMdlReadComplete\n", 0 );
    DebugTrace( 0, me, "    FileObject = %08lx\n", FileObject );
    DebugTrace( 0, me, "    MdlChain = %08lx\n", MdlChain );

    //
    //  Deallocate the Mdls
    //

    while (MdlChain != NULL) {

        MdlNext = MdlChain->Next;

        DebugTrace( 0, mm, "MmUnlockPages/IoFreeMdl:\n", 0 );
        DebugTrace( 0, mm, "    Mdl = %08lx\n", MdlChain );

        MmUnlockPages( MdlChain );

        IoFreeMdl( MdlChain );

        MdlChain = MdlNext;
    }

    DebugTrace(-1, me, "CcMdlReadComplete -> VOID\n", 0 );
}


VOID
CcPrepareMdlWrite (
    IN PFILE_OBJECT FileObject,
    IN PLARGE_INTEGER FileOffset,
    IN ULONG Length,
    OUT PMDL *MdlChain,
    OUT PIO_STATUS_BLOCK IoStatus
    )

/*++

Routine Description:

    This routine attempts to lock the specified file data in the cache
    and return a description of it in an Mdl along with the correct
    I/O status.  Pages to be completely overwritten may be satisfied
    with emtpy pages.  It is *not* safe to call this routine from Dpc level.

    This call is synchronous and raises on error.

    When this call returns, the caller may immediately begin
    to transfer data into the buffers via the Mdl.

    When the call returns with TRUE, the pages described by the Mdl are
    locked in memory, but not mapped in system space.  If the caller
    needs the pages mapped in system space, then it must map them.
    On the subsequent call to CcMdlWriteComplete the pages will be
    unmapped if they were mapped, and in any case unlocked and the Mdl
    deallocated.

Arguments:

    FileObject - Pointer to the file object for a file which was
                 opened with NO_INTERMEDIATE_BUFFERING clear, i.e., for
                 which CcInitializeCacheMap was called by the file system.

    FileOffset - Byte offset in file for desired data.

    Length - Length of desired data in bytes.

    MdlChain - On output it returns a pointer to an Mdl chain describing
               the desired data.  Note that even if FALSE is returned,
               one or more Mdls may have been allocated, as may be ascertained
               by the IoStatus.Information field (see below).

    IoStatus - Pointer to standard I/O status block to receive the status
               for the in-transfer of the data.  (STATUS_SUCCESS guaranteed
               for cache hits, otherwise the actual I/O status is returned.)
               The I/O Information Field indicates how many bytes have been
               successfully locked down in the Mdl Chain.

Return Value:

    None

--*/

{
    PSHARED_CACHE_MAP SharedCacheMap;
    PVOID CacheBuffer;
    LARGE_INTEGER FOffset;
    PMDL Mdl = NULL;
    PMDL MdlTemp;
    LARGE_INTEGER Temp;
    ULONG SavedState = 0;
    ULONG ZeroFlags = 0;
    ULONG Information = 0;

    KLOCK_QUEUE_HANDLE LockHandle;
    ULONG ActivePage;
    ULONG PageIsDirty;
    PVACB Vacb = NULL;

    DebugTrace(+1, me, "CcPrepareMdlWrite\n", 0 );
    DebugTrace( 0, me, "    FileObject = %08lx\n", FileObject );
    DebugTrace2(0, me, "    FileOffset = %08lx, %08lx\n", FileOffset->LowPart,
                                                          FileOffset->HighPart );
    DebugTrace( 0, me, "    Length = %08lx\n", Length );

    //
    //  Get pointer to SharedCacheMap.
    //

    SharedCacheMap = FileObject->SectionObjectPointer->SharedCacheMap;

    //
    //  See if we have an active Vacb, that we need to free.
    //

    GetActiveVacb( SharedCacheMap, LockHandle.OldIrql, Vacb, ActivePage, PageIsDirty );

    //
    //  If there is an end of a page to be zeroed, then free that page now,
    //  so it does not cause our data to get zeroed.  If there is an active
    //  page, free it so we have the correct ValidDataGoal.
    //

    if ((Vacb != NULL) || (SharedCacheMap->NeedToZero != NULL)) {

        CcFreeActiveVacb( SharedCacheMap, Vacb, ActivePage, PageIsDirty );
        Vacb = NULL;
    }

    FOffset = *FileOffset;

    //
    //  Put try-finally around the loop to deal with exceptions
    //

    try {

        //
        //  Not all of the transfer will come back at once, so we have to loop
        //  until the entire transfer is complete.
        //

        while (Length != 0) {

            ULONG ReceivedLength;
            LARGE_INTEGER BeyondLastByte;

            //
            //  Map and see how much we could potentially access at this
            //  FileOffset, then cut it down if it is more than we need.
            //

            CacheBuffer = CcGetVirtualAddress( SharedCacheMap,
                                               FOffset,
                                               &Vacb,
                                               &ReceivedLength );

            if (ReceivedLength > Length) {
                ReceivedLength = Length;
            }

            BeyondLastByte.QuadPart = FOffset.QuadPart + (LONGLONG)ReceivedLength;

            //
            //  At this point we can calculate the ZeroFlags.
            //

            //
            //  We can always zero middle pages, if any.
            //

            ZeroFlags = ZERO_MIDDLE_PAGES;

            //
            //  See if we are completely overwriting the first or last page.
            //

            if (((FOffset.LowPart & (PAGE_SIZE - 1)) == 0) &&
                (ReceivedLength >= PAGE_SIZE)) {
                ZeroFlags |= ZERO_FIRST_PAGE;
            }

            if ((BeyondLastByte.LowPart & (PAGE_SIZE - 1)) == 0) {
                ZeroFlags |= ZERO_LAST_PAGE;
            }

            //
            //  See if the entire transfer is beyond valid data length,
            //  or at least starting from the second page.
            //

            Temp = FOffset;
            Temp.LowPart &= ~(PAGE_SIZE -1);
            KeAcquireInStackQueuedSpinLock( &SharedCacheMap->BcbSpinLock, &LockHandle );
            Temp.QuadPart = SharedCacheMap->ValidDataGoal.QuadPart - Temp.QuadPart;
            KeReleaseInStackQueuedSpinLock( &LockHandle );

            if (Temp.QuadPart <= 0) {
                ZeroFlags |= ZERO_FIRST_PAGE | ZERO_MIDDLE_PAGES | ZERO_LAST_PAGE;
            } else if ((Temp.HighPart == 0) && (Temp.LowPart <= PAGE_SIZE)) {
                ZeroFlags |= ZERO_MIDDLE_PAGES | ZERO_LAST_PAGE;
            }

            (VOID)CcMapAndRead( SharedCacheMap,
                                &FOffset,
                                ReceivedLength,
                                ZeroFlags,
                                TRUE,
                                CacheBuffer );

            //
            //  Now attempt to allocate an Mdl to describe the mapped data.
            //

            DebugTrace( 0, mm, "IoAllocateMdl:\n", 0 );
            DebugTrace( 0, mm, "    BaseAddress = %08lx\n", CacheBuffer );
            DebugTrace( 0, mm, "    Length = %08lx\n", ReceivedLength );

            Mdl = IoAllocateMdl( CacheBuffer,
                                 ReceivedLength,
                                 FALSE,
                                 FALSE,
                                 NULL );

            DebugTrace( 0, mm, "    <Mdl = %08lx\n", Mdl );

            if (Mdl == NULL) {
                DebugTrace( 0, 0, "Failed to allocate Mdl\n", 0 );

                ExRaiseStatus( STATUS_INSUFFICIENT_RESOURCES );
            }

            DebugTrace( 0, mm, "MmProbeAndLockPages:\n", 0 );
            DebugTrace( 0, mm, "    Mdl = %08lx\n", Mdl );

            MmDisablePageFaultClustering(&SavedState);
            MmProbeAndLockPages( Mdl, KernelMode, IoWriteAccess );
            MmEnablePageFaultClustering(SavedState);
            SavedState = 0;

            //
            //  Now that some data (maybe zeros) is locked in memory and
            //  set dirty, it is safe, and necessary for us to advance
            //  valid data goal, so that we will not subsequently ask
            //  for a zero page.  Note if we are extending valid data,
            //  our caller has the file exclusive.
            //

            KeAcquireInStackQueuedSpinLock( &SharedCacheMap->BcbSpinLock, &LockHandle );
            if (BeyondLastByte.QuadPart > SharedCacheMap->ValidDataGoal.QuadPart) {
                SharedCacheMap->ValidDataGoal = BeyondLastByte;
            }
            KeReleaseInStackQueuedSpinLock( &LockHandle );

            //
            //  Unmap the data now, now that the pages are locked down.
            //

            CcFreeVirtualAddress( Vacb );
            Vacb = NULL;

            //
            //  Now link the Mdl into the caller's chain
            //

            if ( *MdlChain == NULL ) {
                *MdlChain = Mdl;
            } else {
                MdlTemp = CONTAINING_RECORD( *MdlChain, MDL, Next );
                while (MdlTemp->Next != NULL) {
                    MdlTemp = MdlTemp->Next;
                }
                MdlTemp->Next = Mdl;
            }
            Mdl = NULL;

            //
            //  Assume we did not get all the data we wanted, and set FOffset
            //  to the end of the returned data.
            //

            FOffset = BeyondLastByte;

            //
            //  Update number of bytes transferred.
            //

            Information += ReceivedLength;

            //
            //  Calculate length left to transfer.
            //

            Length -= ReceivedLength;
        }
    }
    finally {

        if (AbnormalTermination()) {

            if (SavedState != 0) {
                MmEnablePageFaultClustering(SavedState);
            }

            if (Vacb != NULL) {
                CcFreeVirtualAddress( Vacb );
            }

            if (Mdl != NULL) {
                IoFreeMdl( Mdl );
            }

            //
            //  Otherwise loop to deallocate the Mdls
            //

            FOffset = *FileOffset;
            while (*MdlChain != NULL) {
                MdlTemp = (*MdlChain)->Next;

                DebugTrace( 0, mm, "MmUnlockPages/IoFreeMdl:\n", 0 );
                DebugTrace( 0, mm, "    Mdl = %08lx\n", *MdlChain );

                MmUnlockPages( *MdlChain );

                //
                //  Extract the File Offset for this part of the transfer, and
                //  tell the lazy writer to write these pages, since we have
                //  marked them dirty.  Ignore the only exception (allocation
                //  error), and console ourselves for having tried.
                //

                CcSetDirtyInMask( SharedCacheMap, &FOffset, (*MdlChain)->ByteCount );

                FOffset.QuadPart = FOffset.QuadPart + (LONGLONG)((*MdlChain)->ByteCount);

                IoFreeMdl( *MdlChain );

                *MdlChain = MdlTemp;
            }

            DebugTrace(-1, me, "CcPrepareMdlWrite -> Unwinding\n", 0 );
        }
        else {

            IoStatus->Status = STATUS_SUCCESS;
            IoStatus->Information = Information;

            //
            //  Make sure the SharedCacheMap does not go away while
            //  the Mdl write is in progress.  We decrment below.
            //

            CcAcquireMasterLock( &LockHandle.OldIrql );
            CcIncrementOpenCount( SharedCacheMap, 'ldmP' );
            CcReleaseMasterLock( LockHandle.OldIrql );
        }
    }

    DebugTrace( 0, me, "    <MdlChain = %08lx\n", *MdlChain );
    DebugTrace(-1, me, "CcPrepareMdlWrite -> VOID\n", 0 );

    return;
}


//
//  First we have the old routine which checks for an entry in the FastIo vector.
//  This routine becomes obsolete for every component that compiles with the new
//  definition of FsRtlMdlWriteComplete in fsrtl.h.
//

VOID
CcMdlWriteComplete (
    IN PFILE_OBJECT FileObject,
    IN PLARGE_INTEGER FileOffset,
    IN PMDL MdlChain
    )

{
    PDEVICE_OBJECT DeviceObject;
    PFAST_IO_DISPATCH FastIoDispatch;

    DeviceObject = IoGetRelatedDeviceObject( FileObject );
    FastIoDispatch = DeviceObject->DriverObject->FastIoDispatch;

    if ((FastIoDispatch != NULL) &&
        (FastIoDispatch->SizeOfFastIoDispatch > FIELD_OFFSET(FAST_IO_DISPATCH, MdlWriteComplete)) &&
        (FastIoDispatch->MdlWriteComplete != NULL) &&
        FastIoDispatch->MdlWriteComplete( FileObject, FileOffset, MdlChain, DeviceObject )) {

        NOTHING;

    } else {
        CcMdlWriteComplete2( FileObject, FileOffset, MdlChain );
    }
}

VOID
CcMdlWriteComplete2 (
    IN PFILE_OBJECT FileObject,
    IN PLARGE_INTEGER FileOffset,
    IN PMDL MdlChain
    )

/*++

Routine Description:

    This routine must be called at IPL0 after a call to CcPrepareMdlWrite.
    The caller supplies the ActualLength of data that it actually wrote
    into the buffer, which may be less than or equal to the Length specified
    in CcPrepareMdlWrite.

    This call does the following:

        Makes sure the data up to ActualLength eventually gets written.
        If WriteThrough is FALSE, the data will not be written immediately.
        If WriteThrough is TRUE, then the data is written synchronously.

        Unmaps the pages (if mapped), unlocks them and deletes the MdlChain

Arguments:

    FileObject - Pointer to the file object for a file which was
                 opened with NO_INTERMEDIATE_BUFFERING clear, i.e., for
                 which CcInitializeCacheMap was called by the file system.

    FileOffset - Original file offset read above.

    MdlChain - same as returned from corresponding call to CcPrepareMdlWrite.

Return Value:

    None

--*/

{
    PMDL MdlNext;
    PMDL Mdl;
    PSHARED_CACHE_MAP SharedCacheMap;
    LARGE_INTEGER FOffset;
    IO_STATUS_BLOCK IoStatus;
    KIRQL OldIrql;
    NTSTATUS StatusToRaise = STATUS_SUCCESS;
    BOOLEAN First = FALSE;

    DebugTrace(+1, me, "CcMdlWriteComplete\n", 0 );
    DebugTrace( 0, me, "    FileObject = %08lx\n", FileObject );
    DebugTrace( 0, me, "    MdlChain = %08lx\n", MdlChain );

    SharedCacheMap = FileObject->SectionObjectPointer->SharedCacheMap;

    //
    //  Deallocate the Mdls
    //

    FOffset.QuadPart = *(LONGLONG UNALIGNED *)FileOffset;
    Mdl = MdlChain;

    //
    //  If the MDL is unlocked, this is a retry.
    //
    
    if (FlagOn( MdlChain->MdlFlags, MDL_PAGES_LOCKED )) {
        First = TRUE;
    }
    
    while (Mdl != NULL) {

        MdlNext = Mdl->Next;

        DebugTrace( 0, mm, "MmUnlockPages/IoFreeMdl:\n", 0 );
        DebugTrace( 0, mm, "    Mdl = %08lx\n", Mdl );

        //
        //  Now clear the dirty bits in the Pte and set them in the
        //  Pfn.  The Mdls will not be locked on repeated completion
        //  attempts.
        //

        if (First) {
            MmUnlockPages( Mdl );
        }

        //
        //  Extract the File Offset for this part of the transfer.
        //

        if (FlagOn(FileObject->Flags, FO_WRITE_THROUGH)) {

            MmFlushSection ( FileObject->SectionObjectPointer,
                             &FOffset,
                             Mdl->ByteCount,
                             &IoStatus,
                             TRUE );

            //
            //  If we got an I/O error, remember it.
            //

            if (!NT_SUCCESS(IoStatus.Status)) {
                StatusToRaise = IoStatus.Status;
            }

        } else {

            //
            //  Ignore the only exception (allocation error), and console
            //  ourselves for having tried.
            //

            CcSetDirtyInMask( SharedCacheMap, &FOffset, Mdl->ByteCount );
        }

        FOffset.QuadPart = FOffset.QuadPart + (LONGLONG)(Mdl->ByteCount);

        Mdl = MdlNext;
    }

    //
    //  Remove our open count and check to see if this makes the shared cache
    //  map eligible for lazy close.
    //
    //  We do this now so, on failure, old filesystems which did not expect
    //  writethrough to raise continue to work.  They will be within exception
    //  handling with the Mdl still in the IRP.
    //
    //  Note that non-writethrough is the only one that needs the cache map,
    //  and it'll always work.  Removing the open count for writethrough
    //  could be a minor win.
    //
    
    if (First) {
        
        CcAcquireMasterLock( &OldIrql );

        CcDecrementOpenCount( SharedCacheMap, 'ldmC' );

        if ((SharedCacheMap->OpenCount == 0) &&
            !FlagOn(SharedCacheMap->Flags, WRITE_QUEUED) &&
            (SharedCacheMap->DirtyPages == 0)) {

            //
            //  Move to the dirty list.
            //

            RemoveEntryList( &SharedCacheMap->SharedCacheMapLinks );
            InsertTailList( &CcDirtySharedCacheMapList.SharedCacheMapLinks,
                            &SharedCacheMap->SharedCacheMapLinks );

            //
            //  Make sure the Lazy Writer will wake up, because we
            //  want him to delete this SharedCacheMap.
            //

            LazyWriter.OtherWork = TRUE;
            if (!LazyWriter.ScanActive) {
                CcScheduleLazyWriteScan( FALSE );
            }
        }

        CcReleaseMasterLock( OldIrql );
    }
    
    //
    //  If we got an I/O error, raise it now.  Note that we have not free'd the Mdl
    //  yet so the owning filesystem can retry the completion.
    //

    if (!NT_SUCCESS(StatusToRaise)) {
        ExRaiseStatus( FsRtlNormalizeNtstatus( StatusToRaise,
                                               STATUS_UNEXPECTED_IO_ERROR ));
    }

    //
    //  Otherwise, free the Mdl chain and clean everything up.
    //
    
    Mdl = MdlChain;
    while (Mdl != NULL) {

        MdlNext = Mdl->Next;
        IoFreeMdl( Mdl );
        Mdl = MdlNext;
    }

    DebugTrace(-1, me, "CcMdlWriteComplete -> TRUE\n", 0 );

    return;
}

VOID
CcMdlWriteAbort (
    IN PFILE_OBJECT FileObject,
    IN PMDL MdlChain
    )

/*++

Routine Description:

    This routine must be called at IPL0 after a call to CcPrepareMdlWrite.

    This call does the following:

        Unmaps the pages (if mapped), unlocks them and deletes the MdlChain
        unlike the CcMdlWriteComplete this is only used to do teardown in a non
        success case where we didn't actually write anything

Arguments:

    FileObject - Pointer to the file object for a file which was
                 opened with NO_INTERMEDIATE_BUFFERING clear, i.e., for
                 which CcInitializeCacheMap was called by the file system.

    MdlChain - same as returned from corresponding call to CcPrepareMdlWrite.

Return Value:

    None

--*/

{
    PMDL MdlNext;
    PSHARED_CACHE_MAP SharedCacheMap;
    KIRQL OldIrql;
    BOOLEAN First = FALSE;

    DebugTrace(+1, me, "CcMdlWriteAbort\n", 0 );
    DebugTrace( 0, me, "    FileObject = %08lx\n", FileObject );
    DebugTrace( 0, me, "    MdlChain = %08lx\n", MdlChain );

    SharedCacheMap = FileObject->SectionObjectPointer->SharedCacheMap;

    //
    //  If the MDL is unlocked, we went through completion.
    //
    
    if (FlagOn( MdlChain->MdlFlags, MDL_PAGES_LOCKED )) {
        First = TRUE;
    }
    
    //
    //  Deallocate the Mdls
    //

    while (MdlChain != NULL) {

        MdlNext = MdlChain->Next;

        DebugTrace( 0, mm, "MmUnlockPages/IoFreeMdl:\n", 0 );
        DebugTrace( 0, mm, "    Mdl = %08lx\n", MdlChain );

        if (First) {
            MmUnlockPages( MdlChain );
        }
        IoFreeMdl( MdlChain );
        MdlChain = MdlNext;
    }

    //
    //  Now release our open count.  If this already went through completion,
    //  the opencount is already dropped.
    //

    if (First) {
        
        CcAcquireMasterLock( &OldIrql );

        CcDecrementOpenCount( SharedCacheMap, 'AdmC' );

        //
        //  Check for a possible deletion, this Mdl write may have been the last
        //  reference.
        //

        if ((SharedCacheMap->OpenCount == 0) &&
            !FlagOn(SharedCacheMap->Flags, WRITE_QUEUED) &&
            (SharedCacheMap->DirtyPages == 0)) {

            //
            //  Move to the dirty list.
            //

            RemoveEntryList( &SharedCacheMap->SharedCacheMapLinks );
            InsertTailList( &CcDirtySharedCacheMapList.SharedCacheMapLinks,
                            &SharedCacheMap->SharedCacheMapLinks );

            //
            //  Make sure the Lazy Writer will wake up, because we
            //  want him to delete this SharedCacheMap.
            //

            LazyWriter.OtherWork = TRUE;
            if (!LazyWriter.ScanActive) {
                CcScheduleLazyWriteScan( FALSE );
            }
        }

        CcReleaseMasterLock( OldIrql );
    }

    return;
}
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\base\ntos\cache\logsup.c ===
/*++

Copyright (c) 1990  Microsoft Corporation

Module Name:

    logsup.c

Abstract:

    This module implements the special cache manager support for logging
    file systems.

Author:

    Tom Miller      [TomM]      30-Jul-1991

Revision History:

--*/

#include "cc.h"

//
//  Define our debug constant
//

#define me 0x0000040

#ifdef ALLOC_PRAGMA
#pragma alloc_text(PAGE,CcSetLogHandleForFile)
#endif


VOID
CcSetAdditionalCacheAttributes (
    IN PFILE_OBJECT FileObject,
    IN BOOLEAN DisableReadAhead,
    IN BOOLEAN DisableWriteBehind
    )

/*++

Routine Description:

    This routine supports the setting of disable read ahead or disable write
    behind flags to control Cache Manager operation.  This routine may be
    called any time after calling CcInitializeCacheMap.  Initially both
    read ahead and write behind are enabled.  Note that the state of both
    of these flags must be specified on each call to this routine.

Arguments:

    FileObject - File object for which the respective flags are to be set.

    DisableReadAhead - FALSE to enable read ahead, TRUE to disable it.

    DisableWriteBehind - FALSE to enable write behind, TRUE to disable it.

Return Value:

    None.

--*/

{
    PSHARED_CACHE_MAP SharedCacheMap;
    KIRQL OldIrql;

    //
    //  Get pointer to SharedCacheMap.
    //

    SharedCacheMap = FileObject->SectionObjectPointer->SharedCacheMap;

    //
    //  Now set the flags and return.
    //

    CcAcquireMasterLock( &OldIrql );
    if (DisableReadAhead) {
        SetFlag(SharedCacheMap->Flags, DISABLE_READ_AHEAD);
    } else {
        ClearFlag(SharedCacheMap->Flags, DISABLE_READ_AHEAD);
    }
    if (DisableWriteBehind) {
        SetFlag(SharedCacheMap->Flags, DISABLE_WRITE_BEHIND | MODIFIED_WRITE_DISABLED);
    } else {
        ClearFlag(SharedCacheMap->Flags, DISABLE_WRITE_BEHIND);
    }
    CcReleaseMasterLock( OldIrql );
}


NTKERNELAPI
BOOLEAN
CcSetPrivateWriteFile(
    PFILE_OBJECT FileObject
    )

/*++

Routine Description:

    This routine will instruct the cache manager to treat the file as
    a private-write stream, so that a caller can implement a private
    logging mechanism for it.  We will turn on both Mm's modify-no-write
    and our disable-write-behind, and disallow non-aware flush/purge for
    the file.

    Caching must already be initiated on the file.

    This routine is only exported to the kernel.

Arguments:

    FileObject - File to make private-write.

Return Value:

    None.

--*/

{
    PSHARED_CACHE_MAP SharedCacheMap;
    BOOLEAN Disabled;
    KIRQL OldIrql;
    PVACB Vacb;
    ULONG ActivePage;
    ULONG PageIsDirty;

    //
    //  Pick up the file exclusive to synchronize against readahead and
    //  other purge/map activity.
    //

    FsRtlAcquireFileExclusive( FileObject );

    //
    //  Get pointer to SharedCacheMap.
    //
    
    if( FileObject->SectionObjectPointer == NULL ) {
        return FALSE;
    }

    SharedCacheMap = FileObject->SectionObjectPointer->SharedCacheMap;

    if( !SharedCacheMap ) {
        return FALSE;
    }

    //
    //  Unmap all the views in preparation for making the disable mw call.
    //

    //
    //  We still need to wait for any dangling cache read or writes.
    //
    //  In fact we have to loop and wait because the lazy writer can
    //  sneak in and do an CcGetVirtualAddressIfMapped, and we are not
    //  synchronized.
    //
    //  This is the same bit of code that our purge will do.  We assume
    //  that a private writer has succesfully blocked out other activity.
    //

    //
    //  If there is an active Vacb, then nuke it now (before waiting!).
    //

    CcAcquireMasterLock( &OldIrql );
    GetActiveVacbAtDpcLevel( SharedCacheMap, Vacb, ActivePage, PageIsDirty );
    CcReleaseMasterLock( OldIrql );
    
    if (Vacb != NULL) {

        CcFreeActiveVacb( SharedCacheMap, Vacb, ActivePage, PageIsDirty );
    }

    while ((SharedCacheMap->Vacbs != NULL) &&
           !CcUnmapVacbArray( SharedCacheMap, NULL, 0, FALSE )) {

        CcWaitOnActiveCount( SharedCacheMap );
    }

    //
    //  Knock the file down.
    // 

    CcFlushCache( FileObject->SectionObjectPointer, NULL, 0, NULL );

    //
    //  Now the file is clean and unmapped. We can still have a racing
    //  lazy writer, though.
    //
    //  We just wait for the lazy writer queue to drain before disabling
    //  modified write.  There may be a better way to do this by having
    //  an event for the WRITE_QUEUED flag. ?  This would also let us
    //  dispense with the pagingio pick/drop in the FS cache coherency
    //  paths, but there could be reasons why CcFlushCache shouldn't
    //  always do such a block.  Investigate this.
    //
    //  This wait takes on the order of ~.5s avg. case.
    //

    CcAcquireMasterLock( &OldIrql );
    
    if (FlagOn( SharedCacheMap->Flags, WRITE_QUEUED )) {
        
        CcReleaseMasterLock( OldIrql );
        FsRtlReleaseFile( FileObject );
        CcWaitForCurrentLazyWriterActivity();
        FsRtlAcquireFileExclusive( FileObject );

    } else {

        CcReleaseMasterLock( OldIrql );
    }

    //
    //  Now set the flags and return.  We do not set our MODIFIED_WRITE_DISABLED
    //  since we don't want to fully promote this cache map.  Future?
    //

    Disabled = MmDisableModifiedWriteOfSection( FileObject->SectionObjectPointer );

    if (Disabled) {
        CcAcquireMasterLock( &OldIrql );
        SetFlag(SharedCacheMap->Flags, DISABLE_WRITE_BEHIND | PRIVATE_WRITE);
        CcReleaseMasterLock( OldIrql );
    }

    //
    //  Now release the file for regular operation.
    //

    FsRtlReleaseFile( FileObject );

    return Disabled;
}


VOID
CcSetLogHandleForFile (
    IN PFILE_OBJECT FileObject,
    IN PVOID LogHandle,
    IN PFLUSH_TO_LSN FlushToLsnRoutine
    )

/*++

Routine Description:

    This routine may be called to instruct the Cache Manager to store the
    specified log handle with the shared cache map for a file, to support
    subsequent calls to the other routines in this module which effectively
    perform an associative search for files by log handle.

Arguments:

    FileObject - File for which the log handle should be stored.

    LogHandle - Log Handle to store.

    FlushToLsnRoutine - A routine to call before flushing buffers for this
                        file, to insure a log file is flushed to the most
                        recent Lsn for any Bcb being flushed.

Return Value:

    None.

--*/

{
    PSHARED_CACHE_MAP SharedCacheMap;

    //
    //  Get pointer to SharedCacheMap.
    //

    SharedCacheMap = FileObject->SectionObjectPointer->SharedCacheMap;

    //
    //  Now set the log file handle and flush routine
    //

    SharedCacheMap->LogHandle = LogHandle;
    SharedCacheMap->FlushToLsnRoutine = FlushToLsnRoutine;
}


LARGE_INTEGER
CcGetDirtyPages (
    IN PVOID LogHandle,
    IN PDIRTY_PAGE_ROUTINE DirtyPageRoutine,
    IN PVOID Context1,
    IN PVOID Context2
    )

/*++

Routine Description:

    This routine may be called to return all of the dirty pages in all files
    for a given log handle.  Each page is returned by an individual call to
    the Dirty Page Routine.  The Dirty Page Routine is defined by a prototype
    in ntos\inc\cache.h.

Arguments:

    LogHandle - Log Handle which must match the log handle previously stored
                for all files which are to be returned.

    DirtyPageRoutine -- The routine to call as each dirty page for this log
                        handle is found.

    Context1 - First context parameter to be passed to the Dirty Page Routine.

    Context2 - First context parameter to be passed to the Dirty Page Routine.

Return Value:

    LARGE_INTEGER - Oldest Lsn found of all the dirty pages, or 0 if no dirty pages

--*/

{
    PSHARED_CACHE_MAP SharedCacheMap;
    PBCB Bcb, BcbToUnpin = NULL;
    KLOCK_QUEUE_HANDLE LockHandle;
    LARGE_INTEGER SavedFileOffset, SavedOldestLsn, SavedNewestLsn;
    ULONG SavedByteLength;
    LARGE_INTEGER OldestLsn = {0,0};

    //
    //  Synchronize with changes to the SharedCacheMap list.
    //

    CcAcquireMasterLock( &LockHandle.OldIrql );

    SharedCacheMap = CONTAINING_RECORD( CcDirtySharedCacheMapList.SharedCacheMapLinks.Flink,
                                        SHARED_CACHE_MAP,
                                        SharedCacheMapLinks );

    //
    //  Use try/finally for cleanup.  The only spot where we can raise is out of the
    //  filesystem callback, but we have the exception handler out here so we aren't
    //  constantly setting/unsetting it.
    //

    try {

        while (&SharedCacheMap->SharedCacheMapLinks != &CcDirtySharedCacheMapList.SharedCacheMapLinks) {

            //
            //  Skip over cursors, SharedCacheMaps for other LogHandles, and ones with
            //  no dirty pages
            //

            if (!FlagOn(SharedCacheMap->Flags, IS_CURSOR) && (SharedCacheMap->LogHandle == LogHandle) &&
                (SharedCacheMap->DirtyPages != 0)) {

                //
                //  This SharedCacheMap should stick around for a while in the dirty list.
                //

                CcIncrementOpenCount( SharedCacheMap, 'pdGS' );
                SharedCacheMap->DirtyPages += 1;
                CcReleaseMasterLock( LockHandle.OldIrql );

                //
                //  Set our initial resume point and point to first Bcb in List.
                //

                KeAcquireInStackQueuedSpinLock( &SharedCacheMap->BcbSpinLock, &LockHandle );
                Bcb = CONTAINING_RECORD( SharedCacheMap->BcbList.Flink, BCB, BcbLinks );

                //
                //  Scan to the end of the Bcb list.
                //

                while (&Bcb->BcbLinks != &SharedCacheMap->BcbList) {

                    //
                    //  If the Bcb is dirty, then capture the inputs for the
                    //  callback routine so we can call without holding a spinlock.
                    //

                    if ((Bcb->NodeTypeCode == CACHE_NTC_BCB) && Bcb->Dirty) {

                        SavedFileOffset = Bcb->FileOffset;
                        SavedByteLength = Bcb->ByteLength;
                        SavedOldestLsn = Bcb->OldestLsn;
                        SavedNewestLsn = Bcb->NewestLsn;

                        //
                        //  Increment PinCount so the Bcb sticks around
                        //

                        Bcb->PinCount += 1;

                        KeReleaseInStackQueuedSpinLock( &LockHandle );

                        //
                        //  Any Bcb to unref from a previous loop?
                        //

                        if (BcbToUnpin != NULL) {
                            CcUnpinFileData( BcbToUnpin, TRUE, UNREF );
                            BcbToUnpin = NULL;
                        }

                        //
                        //  Call the file system.  This callback may raise status.
                        //

                        (*DirtyPageRoutine)( SharedCacheMap->FileObject,
                                             &SavedFileOffset,
                                             SavedByteLength,
                                             &SavedOldestLsn,
                                             &SavedNewestLsn,
                                             Context1,
                                             Context2 );

                        //
                        //  Possibly update OldestLsn
                        //

                        if ((SavedOldestLsn.QuadPart != 0) &&
                            ((OldestLsn.QuadPart == 0) || (SavedOldestLsn.QuadPart < OldestLsn.QuadPart ))) {
                            OldestLsn = SavedOldestLsn;
                        }

                        //
                        //  Now reacquire the spinlock and scan from the resume point
                        //  point to the next Bcb to return in the descending list.
                        //

                        KeAcquireInStackQueuedSpinLock( &SharedCacheMap->BcbSpinLock, &LockHandle );

                        //
                        //  Normally the Bcb can stay around a while, but if not,
                        //  we will just remember it for the next time we do not
                        //  have the spin lock.  We cannot unpin it now, because
                        //  we would lose our place in the list.
                        //
                        //  This is cheating, but it works and is sane since we're
                        //  already traversing the bcb list - dropping the bcb count
                        //  is OK, as long as we don't hit zero.  Zero requires a 
                        //  slight bit more attention that shouldn't be replicated.
                        //  (unmapping the view)
                        //

                        if (Bcb->PinCount > 1) {
                            Bcb->PinCount -= 1;
                        } else {
                            BcbToUnpin = Bcb;
                        }
                    }

                    Bcb = CONTAINING_RECORD( Bcb->BcbLinks.Flink, BCB, BcbLinks );
                }
                KeReleaseInStackQueuedSpinLock( &LockHandle );

                //
                //  We need to unref any Bcb we are holding before moving on to
                //  the next SharedCacheMap, or else CcDeleteSharedCacheMap will
                //  also delete this Bcb.
                //

                if (BcbToUnpin != NULL) {

                    CcUnpinFileData( BcbToUnpin, TRUE, UNREF );
                    BcbToUnpin = NULL;
                }

                CcAcquireMasterLock( &LockHandle.OldIrql );

                //
                //  Now release the SharedCacheMap, leaving it in the dirty list.
                //

                CcDecrementOpenCount( SharedCacheMap, 'pdGF' );
                SharedCacheMap->DirtyPages -= 1;
            }

            //
            //  Now loop back for the next cache map.
            //

            SharedCacheMap =
                CONTAINING_RECORD( SharedCacheMap->SharedCacheMapLinks.Flink,
                                   SHARED_CACHE_MAP,
                                   SharedCacheMapLinks );
        }

        CcReleaseMasterLock( LockHandle.OldIrql );

    } finally {

        //
        //  Drop the Bcb if we are being ejected.  We are guaranteed that the
        //  only raise is from the callback, at which point we have an incremented
        //  pincount.
        //

        if (AbnormalTermination()) {

            CcUnpinFileData( Bcb, TRUE, UNPIN );
        }
    }

    return OldestLsn;
}


BOOLEAN
CcIsThereDirtyData (
    IN PVPB Vpb
    )

/*++

Routine Description:

    This routine returns TRUE if the specified Vcb has any unwritten dirty
    data in the cache.

Arguments:

    Vpb - specifies Vpb to check for

Return Value:

    FALSE - if the Vpb has no dirty data
    TRUE - if the Vpb has dirty data

--*/

{
    PSHARED_CACHE_MAP SharedCacheMap;
    KIRQL OldIrql;
    ULONG LoopsWithLockHeld = 0;

    //
    //  Synchronize with changes to the SharedCacheMap list.
    //

    CcAcquireMasterLock( &OldIrql );

    SharedCacheMap = CONTAINING_RECORD( CcDirtySharedCacheMapList.SharedCacheMapLinks.Flink,
                                        SHARED_CACHE_MAP,
                                        SharedCacheMapLinks );

    while (&SharedCacheMap->SharedCacheMapLinks != &CcDirtySharedCacheMapList.SharedCacheMapLinks) {

        //
        //  Look at this one if the Vpb matches and if there is dirty data.
        //  For what it's worth, don't worry about dirty data in temporary files,
        //  as that should not concern the caller if it wants to dismount.
        //

        if (!FlagOn(SharedCacheMap->Flags, IS_CURSOR) &&
            (SharedCacheMap->FileObject->Vpb == Vpb) &&
            (SharedCacheMap->DirtyPages != 0) &&
            !FlagOn(SharedCacheMap->FileObject->Flags, FO_TEMPORARY_FILE)) {

            CcReleaseMasterLock( OldIrql );
            return TRUE;
        }

        //
        //  Make sure we occasionally drop the lock.  Set WRITE_QUEUED
        //  to keep the guy from going away, and increment DirtyPages to
        //  keep it in this list.
        //

        if ((++LoopsWithLockHeld >= 20) &&
            !FlagOn(SharedCacheMap->Flags, WRITE_QUEUED | IS_CURSOR)) {

            SetFlag( *((ULONG volatile *)&SharedCacheMap->Flags), WRITE_QUEUED);
            *((ULONG volatile *)&SharedCacheMap->DirtyPages) += 1;
            CcReleaseMasterLock( OldIrql );
            LoopsWithLockHeld = 0;
            CcAcquireMasterLock( &OldIrql );
            ClearFlag( *((ULONG volatile *)&SharedCacheMap->Flags), WRITE_QUEUED);
            *((ULONG volatile *)&SharedCacheMap->DirtyPages) -= 1;
        }

        //
        //  Now loop back for the next cache map.
        //

        SharedCacheMap =
            CONTAINING_RECORD( SharedCacheMap->SharedCacheMapLinks.Flink,
                               SHARED_CACHE_MAP,
                               SharedCacheMapLinks );
    }

    CcReleaseMasterLock( OldIrql );

    return FALSE;
}

LARGE_INTEGER
CcGetLsnForFileObject(
    IN PFILE_OBJECT FileObject,
    OUT PLARGE_INTEGER OldestLsn OPTIONAL
    )

/*++

Routine Description:

    This routine returns the  oldest and newest LSNs for a file object.

Arguments:

    FileObject - File for which the log handle should be stored.

    OldestLsn - pointer to location to store oldest LSN for file object.

Return Value:

    The newest LSN for the file object.

--*/

{
    PBCB Bcb;
    KLOCK_QUEUE_HANDLE LockHandle;
    LARGE_INTEGER Oldest, Newest;
    PSHARED_CACHE_MAP SharedCacheMap = FileObject->SectionObjectPointer->SharedCacheMap;

    //
    // initialize lsn variables
    //

    Oldest.LowPart = 0;
    Oldest.HighPart = 0;
    Newest.LowPart = 0;
    Newest.HighPart = 0;

    if(SharedCacheMap == NULL) {
        return Oldest;
    }

    KeAcquireInStackQueuedSpinLock(&SharedCacheMap->BcbSpinLock, &LockHandle);

    //
    //  Now point to first Bcb in List, and loop through it.
    //

    Bcb = CONTAINING_RECORD( SharedCacheMap->BcbList.Flink, BCB, BcbLinks );

    while (&Bcb->BcbLinks != &SharedCacheMap->BcbList) {

        //
        //  If the Bcb is dirty then capture the oldest and newest lsn
        //


        if ((Bcb->NodeTypeCode == CACHE_NTC_BCB) && Bcb->Dirty) {

            LARGE_INTEGER BcbLsn, BcbNewest;

            BcbLsn = Bcb->OldestLsn;
            BcbNewest = Bcb->NewestLsn;

            if ((BcbLsn.QuadPart != 0) &&
                ((Oldest.QuadPart == 0) ||
                 (BcbLsn.QuadPart < Oldest.QuadPart))) {

                 Oldest = BcbLsn;
            }

            if ((BcbLsn.QuadPart != 0) && (BcbNewest.QuadPart > Newest.QuadPart)) {

                Newest = BcbNewest;
            }
        }


        Bcb = CONTAINING_RECORD( Bcb->BcbLinks.Flink, BCB, BcbLinks );
    }

    //
    //  Now release the spin lock for this Bcb list and generate a callback
    //  if we got something.
    //

    KeReleaseInStackQueuedSpinLock( &LockHandle );

    if (ARGUMENT_PRESENT(OldestLsn)) {

        *OldestLsn = Oldest;
    }

    return Newest;
}
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\base\ntos\cache\prefboot.c ===
/*++

Copyright (c) 1999 Microsoft Corporation

Module Name:

    prefboot.c

Abstract:

    This module contains the code for boot prefetching.

Author:

    Cenk Ergan (cenke)          15-Mar-2000

Revision History:

--*/

#include "cc.h"
#include "zwapi.h"
#include "prefetch.h"
#include "preftchp.h"
#include "stdio.h"

#ifdef ALLOC_PRAGMA
#pragma alloc_text(PAGE, CcPfBeginBootPhase)
#pragma alloc_text(PAGE, CcPfBootWorker)
#pragma alloc_text(PAGE, CcPfBootQueueEndTraceTimer)
#endif // ALLOC_PRAGMA

//
// Globals:
//

//
// Whether the system is currently prefetching for boot.
//

LOGICAL CcPfPrefetchingForBoot = FALSE;

//
// Current boot phase, only updated in begin boot phase routine.
//

PF_BOOT_PHASE_ID CcPfBootPhase = 0;

//
// Prefetcher globals.
//

extern CCPF_PREFETCHER_GLOBALS CcPfGlobals;

//
// Routines for boot prefetching.
//

NTSTATUS
CcPfBeginBootPhase(
    PF_BOOT_PHASE_ID Phase
    )

/*++

Routine Description:

    This routine is the control center for the boot prefetcher. 
    It is called to notify boot prefetcher of boot progress. 

Arguments:

    Phase - Boot phase the system is entering.

Return Value:

    Status.

Environment:

    Kernel mode. IRQL == PASSIVE_LEVEL.

--*/

{
    LARGE_INTEGER VideoInitEndTime;
    LARGE_INTEGER MaxWaitTime;
    LONGLONG VideoInitTimeIn100ns;
    HANDLE ThreadHandle;
    PETHREAD Thread;
    PERFINFO_BOOT_PHASE_START LogEntry;
    PF_BOOT_PHASE_ID OriginalPhase;
    PF_BOOT_PHASE_ID NewPhase;   
    ULONG VideoInitTime;
    NTSTATUS Status;

    //
    // This is the boot prefetcher. It is allocated and free'd in this routine.
    // It is passed to the spawned boot worker if boot prefetching is enabled.
    //

    static PCCPF_BOOT_PREFETCHER BootPrefetcher = NULL;

    //
    // This is the system time when we started initializing the video.
    //

    static LARGE_INTEGER VideoInitStartTime;

    DBGPR((CCPFID,PFTRC,"CCPF: BeginBootPhase(%d)\n", (ULONG)Phase));

    //
    // Make sure phase is valid.
    //

    if (Phase >= PfMaxBootPhaseId) {
        Status = STATUS_INVALID_PARAMETER;
        goto cleanup;
    } 

    //
    // Log phase to trace buffer.
    //

    if (PERFINFO_IS_GROUP_ON(PERF_LOADER)) {

        LogEntry.Phase = Phase;
        
        PerfInfoLogBytes(PERFINFO_LOG_TYPE_BOOT_PHASE_START,
                         &LogEntry,
                         sizeof(LogEntry));
    }

    //
    // Update the global current boot phase.
    //

    for (;;) {
    
        OriginalPhase = CcPfBootPhase;

        if (Phase <= OriginalPhase) {
            Status = STATUS_TOO_LATE;
            goto cleanup;
        }

        //
        // If CcPfBootPhase is still OriginalPhase, set it to Phase.
        //

        NewPhase = InterlockedCompareExchange(&(LONG)CcPfBootPhase, Phase, OriginalPhase);

        if (NewPhase == OriginalPhase) {

            //
            // CcPfBootPhase was still OriginalPhase, so now it is set to
            // Phase. We are done.
            //

            break;
        }
    }

    Status = STATUS_SUCCESS;

    //
    // Perform the work we have to do for this boot phase.
    //

    switch (Phase) {

    case PfSystemDriverInitPhase:

        //
        // Update whether prefetcher is enabled or not.
        //

        CcPfDetermineEnablePrefetcher();

        //
        // If boot prefetching is not enabled, we are done.
        //

        if (!CCPF_IS_PREFETCHER_ENABLED() ||
            CcPfGlobals.Parameters.Parameters.EnableStatus[PfSystemBootScenarioType] != PfSvEnabled) {
            Status = STATUS_NOT_SUPPORTED;
            break;
        }

        //
        // Allocate and initialize boot prefetcher.
        //

        BootPrefetcher = ExAllocatePoolWithTag(NonPagedPool,
                                               sizeof(*BootPrefetcher),
                                               CCPF_ALLOC_BOOTWRKR_TAG);

        if (!BootPrefetcher) {
            Status = STATUS_INSUFFICIENT_RESOURCES;
            break;
        }

        KeInitializeEvent(&BootPrefetcher->SystemDriversPrefetchingDone,
                          NotificationEvent,
                          FALSE);
        KeInitializeEvent(&BootPrefetcher->PreSmssPrefetchingDone,
                          NotificationEvent,
                          FALSE);
        KeInitializeEvent(&BootPrefetcher->VideoInitPrefetchingDone,
                          NotificationEvent,
                          FALSE);
        KeInitializeEvent(&BootPrefetcher->VideoInitStarted,
                          NotificationEvent,
                          FALSE);

        //
        // Kick off the boot worker in paralel.
        //
            
        Status = PsCreateSystemThread(&ThreadHandle,
                                      THREAD_ALL_ACCESS,
                                      NULL,
                                      NULL,
                                      NULL,
                                      CcPfBootWorker,
                                      BootPrefetcher);
            
        if (NT_SUCCESS(Status)) {

            //
            // Give boot worker some head start by bumping its
            // priority. This helps to make sure pages we will
            // prefetch are put into transition before boot gets
            // ahead of the prefetcher.
            //

            Status = ObReferenceObjectByHandle(ThreadHandle,
                                               THREAD_SET_INFORMATION,
                                               PsThreadType,
                                               KernelMode,
                                               &Thread,
                                               NULL);

            if (NT_SUCCESS(Status)) {
                KeSetPriorityThread(&Thread->Tcb, HIGH_PRIORITY - 1);
                ObDereferenceObject(Thread);
            }

            ZwClose(ThreadHandle);               

            //
            // Before returning to initialize system drivers, wait
            // for boot worker to make progress.
            //
                
            KeWaitForSingleObject(&BootPrefetcher->SystemDriversPrefetchingDone, 
                                  Executive, 
                                  KernelMode, 
                                  FALSE, 
                                  NULL);

        } else {

            //
            // Free the allocated boot prefetcher.
            //

            ExFreePool(BootPrefetcher);
            BootPrefetcher = NULL;
        }

        break;

    case PfSessionManagerInitPhase:

        //
        // Wait for boot worker to make enough progress before launching
        // session manager.
        //

        if (BootPrefetcher) {
            KeWaitForSingleObject(&BootPrefetcher->PreSmssPrefetchingDone, 
                                  Executive, 
                                  KernelMode, 
                                  FALSE, 
                                  NULL);
        }

        break;

    case PfVideoInitPhase:

        //
        // Note when video initialization started.
        //

        KeQuerySystemTime(&VideoInitStartTime);

        //
        // Signal boot prefetcher to start prefetching in parallel to video 
        // initialization.
        //

        if (BootPrefetcher) {
            KeSetEvent(&BootPrefetcher->VideoInitStarted, 
                       IO_NO_INCREMENT,
                       FALSE);
        }

        break;

    case PfPostVideoInitPhase:

        //
        // Note when we complete video initialization. Save how long video  
        // initialization took in the registry in milliseconds.
        //

        KeQuerySystemTime(&VideoInitEndTime);

        VideoInitTimeIn100ns = VideoInitEndTime.QuadPart - VideoInitStartTime.QuadPart;
        VideoInitTime = (ULONG) (VideoInitTimeIn100ns / (1i64 * 10 * 1000));

        KeEnterCriticalRegionThread(KeGetCurrentThread());
        ExAcquireResourceSharedLite(&CcPfGlobals.Parameters.ParametersLock, TRUE);

        Status = CcPfSetParameter(CcPfGlobals.Parameters.ParametersKey,
                                  CCPF_VIDEO_INIT_TIME_VALUE_NAME,
                                  REG_DWORD,
                                  &VideoInitTime,
                                  sizeof(VideoInitTime));

        ExReleaseResourceLite(&CcPfGlobals.Parameters.ParametersLock);
        KeLeaveCriticalRegionThread(KeGetCurrentThread());

        //
        // Wait for prefetching parallel to video initialization to complete.
        //

        if (BootPrefetcher) {
            KeWaitForSingleObject(&BootPrefetcher->VideoInitPrefetchingDone, 
                                  Executive, 
                                  KernelMode, 
                                  FALSE, 
                                  NULL);
        }

        break;

    case PfBootAcceptedRegistryInitPhase:

        //
        // Service Controller has accepted this boot as a valid boot.
        // Boot & system services have initialized successfully.
        //

        //
        // We are done with boot prefetching. No one else could be accessing
        // BootPrefetcher structure at this point. 
        //

        if (BootPrefetcher) {

            //
            // Cleanup the allocated boot prefetcher.
            //

            ExFreePool(BootPrefetcher);
            BootPrefetcher = NULL;

            //
            // Determine if the prefetcher is enabled now that boot
            // is over.
            //

            CcPfDetermineEnablePrefetcher();
        }

        //
        // The user may not log in after booting. 
        // Queue a timer to end boot trace.
        //

        MaxWaitTime.QuadPart =  -1i64 * 60 * 1000 * 1000 * 10; // 60 seconds.

        CcPfBootQueueEndTraceTimer(&MaxWaitTime);

        break;
        
    case PfUserShellReadyPhase:
        
        //
        // Explorer has started, but start menu items may still be launching.
        // Queue a timer to end boot trace.
        //

        MaxWaitTime.QuadPart =  -1i64 * 30 * 1000 * 1000 * 10; // 30 seconds.

        CcPfBootQueueEndTraceTimer(&MaxWaitTime);

        break;

    default:
        
        //
        // Ignored for now.
        //

        Status = STATUS_SUCCESS;
        
    }

    //
    // Fall through with status from switch statement.
    //
    
 cleanup:

    DBGPR((CCPFID,PFTRC,"CCPF: BeginBootPhase(%d)=%x\n", (ULONG)Phase, Status));

    return Status;
}

VOID
CcPfBootWorker(
    PCCPF_BOOT_PREFETCHER BootPrefetcher
    )

/*++

Routine Description:

    This routine is queued to prefetch and start tracing boot in parallel.

Arguments:

    BootPrefetcher - Pointer to boot prefetcher context.

Return Value:

    None.

Environment:

    Kernel mode. IRQL == PASSIVE_LEVEL.

--*/

{
    PF_SCENARIO_ID BootScenarioId;
    CCPF_PREFETCH_HEADER PrefetchHeader;
    CCPF_BASIC_SCENARIO_INFORMATION ScenarioInfo;
    CCPF_BOOT_SCENARIO_INFORMATION BootScenarioInfo;
    PERFINFO_BOOT_PREFETCH_INFORMATION LogEntry;
    ULONG NumPages;
    ULONG RequiredSize;
    ULONG NumPagesPrefetched;
    ULONG TotalPagesPrefetched;
    ULONG BootPrefetchAdjustment;
    ULONG AvailablePages;
    ULONG NumPagesToPrefetch;
    ULONG TotalPagesToPrefetch;
    ULONG RemainingDataPages;
    ULONG RemainingImagePages;
    ULONG VideoInitTime;
    ULONG VideoInitPagesPerSecond;
    ULONG VideoInitMaxPages;
    ULONG RemainingVideoInitPages;
    ULONG VideoInitDataPages;
    ULONG VideoInitImagePages;
    ULONG PrefetchPhaseIdx;
    ULONG LastPrefetchPhaseIdx;
    ULONG SystemDriverPrefetchingPhaseIdx;
    ULONG PreSmssPrefetchingPhaseIdx;
    ULONG VideoInitPrefetchingPhaseIdx;
    ULONG ValueSize;
    CCPF_BOOT_SCENARIO_PHASE BootPhaseIdx;
    NTSTATUS Status;
    BOOLEAN OutOfAvailablePages;

    //
    // First we will prefetch data pages, then image pages.
    //

    enum {
        DataCursor = 0,
        ImageCursor,
        MaxCursor
    } CursorIdx;

    CCPF_BOOT_PREFETCH_CURSOR Cursors[MaxCursor];
    PCCPF_BOOT_PREFETCH_CURSOR Cursor;

    //
    // Initialize locals.
    //

    CcPfInitializePrefetchHeader(&PrefetchHeader);
    TotalPagesPrefetched = 0;
    OutOfAvailablePages = FALSE;

    DBGPR((CCPFID,PFTRC,"CCPF: BootWorker()\n"));

    //
    // Initialize boot scenario ID.
    //

    wcsncpy(BootScenarioId.ScenName, 
            PF_BOOT_SCENARIO_NAME, 
            PF_SCEN_ID_MAX_CHARS);

    BootScenarioId.ScenName[PF_SCEN_ID_MAX_CHARS] = 0;
    BootScenarioId.HashId = PF_BOOT_SCENARIO_HASHID;

    //
    // Start boot prefetch tracing.
    //

    CcPfBeginTrace(&BootScenarioId, PfSystemBootScenarioType, PsInitialSystemProcess);

    //
    // If we try to prefetch more pages then what we have available, we will 
    // end up cannibalizing the pages we prefetched into the standby list.
    // To avoid cannibalizing, we check MmAvailablePages but leave some 
    // breathing room for metadata pages, allocations from the driver 
    // initialization phase etc.
    //

    BootPrefetchAdjustment = 512;

    //
    // We also know that right after we prefetch for boot, in smss when 
    // initializing the registry we'll use up 8-10MB of prefetched pages if we 
    // don't have anything left in the free list. So we leave some room for 
    // that too.
    //

    BootPrefetchAdjustment += 8 * 1024 * 1024 / PAGE_SIZE; 

    //
    // Get prefetch instructions.
    //
    
    Status = CcPfGetPrefetchInstructions(&BootScenarioId,
                                         PfSystemBootScenarioType,
                                         &PrefetchHeader.Scenario);

    if (!NT_SUCCESS(Status)) {
        goto cleanup;
    }     
    
    //
    // Query the total number of pages to be prefetched. 
    //

    Status = CcPfQueryScenarioInformation(PrefetchHeader.Scenario,
                                          CcPfBasicScenarioInformation,
                                          &ScenarioInfo,
                                          sizeof(ScenarioInfo),
                                          &RequiredSize);

    if (!NT_SUCCESS(Status)) {
        goto cleanup;
    }
    
    //
    // Query the number of pages we have to prefetch for boot phases.
    //


    Status = CcPfQueryScenarioInformation(PrefetchHeader.Scenario,
                                          CcPfBootScenarioInformation,
                                          &BootScenarioInfo,
                                          sizeof(BootScenarioInfo),
                                          &RequiredSize);

    if (!NT_SUCCESS(Status)) {
        goto cleanup;
    }                                                            

    //
    // Read how long it took to initialize video in the last boot.
    //

    KeEnterCriticalRegionThread(KeGetCurrentThread());
    ExAcquireResourceSharedLite(&CcPfGlobals.Parameters.ParametersLock, TRUE);

    ValueSize = sizeof(VideoInitTime);
    Status = CcPfGetParameter(CcPfGlobals.Parameters.ParametersKey,
                              CCPF_VIDEO_INIT_TIME_VALUE_NAME,
                              REG_DWORD,
                              &VideoInitTime,
                              &ValueSize);

    ExReleaseResourceLite(&CcPfGlobals.Parameters.ParametersLock);
    KeLeaveCriticalRegionThread(KeGetCurrentThread());

    if (!NT_SUCCESS(Status)) {

        //
        // Reset video init time, so we don't attempt to prefetch
        // in parallel to it.
        //

        VideoInitTime = 0;

    } else {

        //
        // Verify the value we read from registry.
        //

        if (VideoInitTime > CCPF_MAX_VIDEO_INIT_TIME) {
            VideoInitTime = 0;
        }
    }

    //
    // Read how many pages per second we should be trying to prefetching 
    // in parallel to video initialization.
    //

    KeEnterCriticalRegionThread(KeGetCurrentThread());
    ExAcquireResourceSharedLite(&CcPfGlobals.Parameters.ParametersLock, TRUE);

    ValueSize = sizeof(VideoInitPagesPerSecond);
    Status = CcPfGetParameter(CcPfGlobals.Parameters.ParametersKey,
                              CCPF_VIDEO_INIT_PAGES_PER_SECOND_VALUE_NAME,
                              REG_DWORD,
                              &VideoInitPagesPerSecond,
                              &ValueSize);

    ExReleaseResourceLite(&CcPfGlobals.Parameters.ParametersLock);
    KeLeaveCriticalRegionThread(KeGetCurrentThread());

    if (!NT_SUCCESS(Status)) {

        //
        // There was no valid value in the registry. Use the default.
        //

        VideoInitPagesPerSecond = CCPF_VIDEO_INIT_DEFAULT_PAGES_PER_SECOND;

    } else {

        //
        // Verify the value we read from registry.
        //

        if (VideoInitPagesPerSecond > CCPF_VIDEO_INIT_MAX_PAGES_PER_SECOND) {
            VideoInitPagesPerSecond = CCPF_VIDEO_INIT_MAX_PAGES_PER_SECOND;
        }
    }

    //
    // Determine how many pages max we can prefetch in parallel to video
    // initialization.
    //

    VideoInitMaxPages = (VideoInitTime / 1000) * VideoInitPagesPerSecond;

    //
    // We can only prefetch pages used after winlogon in parallel to video
    // initialization. Determine exactly how many pages we will prefetch
    // starting from the last boot phase.
    //

    RemainingVideoInitPages = VideoInitMaxPages;
    VideoInitDataPages = 0;
    VideoInitImagePages = 0;

    for (BootPhaseIdx = CcPfBootScenMaxPhase - 1;
         RemainingVideoInitPages && (BootPhaseIdx >= CcPfBootScenSystemProcInitPhase);
         BootPhaseIdx--) {

        NumPages = CCPF_MIN(RemainingVideoInitPages, BootScenarioInfo.NumImagePages[BootPhaseIdx]);
        VideoInitImagePages += NumPages;
        RemainingVideoInitPages -= NumPages;

        if (RemainingVideoInitPages) {
            NumPages = CCPF_MIN(RemainingVideoInitPages, BootScenarioInfo.NumDataPages[BootPhaseIdx]);
            VideoInitDataPages += NumPages;
            RemainingVideoInitPages -= NumPages;
        }
    }  

    //
    // Let MM know that we have started prefetching for boot.
    //

    CcPfPrefetchingForBoot = TRUE;

    //
    // Log that we are starting prefetch disk I/Os.
    //

    if (PERFINFO_IS_GROUP_ON(PERF_DISK_IO)) {

        LogEntry.Action = 0;
        LogEntry.Status = 0;
        LogEntry.Pages = ScenarioInfo.NumDataPages + ScenarioInfo.NumImagePages;
        
        PerfInfoLogBytes(PERFINFO_LOG_TYPE_BOOT_PREFETCH_INFORMATION,
                         &LogEntry,
                         sizeof(LogEntry));
    }

    //
    // Verify & open the volumes that we will prefetch from.
    //

    Status = CcPfOpenVolumesForPrefetch(&PrefetchHeader);

    if (!NT_SUCCESS(Status)) {
        goto cleanup;
    }

    //
    // Prefetch the metadata.
    //
     
    CcPfPrefetchMetadata(&PrefetchHeader);  

    //
    // Initialize the boot prefetch cursors for data and image.
    //

    RtlZeroMemory(Cursors, sizeof(Cursors));

    Cursors[DataCursor].PrefetchType = CcPfPrefetchPartOfDataPages;
    Cursors[ImageCursor].PrefetchType = CcPfPrefetchPartOfImagePages;

    PrefetchPhaseIdx = 0;
    RemainingDataPages = ScenarioInfo.NumDataPages;
    RemainingImagePages = ScenarioInfo.NumImagePages;

    //
    // Setup the cursors for phases in which we will prefetch for boot.
    // First we will prefetch for system drivers.
    //

    NumPages = BootScenarioInfo.NumDataPages[CcPfBootScenDriverInitPhase];
    Cursors[DataCursor].NumPagesForPhase[PrefetchPhaseIdx] = NumPages;
    RemainingDataPages -= NumPages;

    NumPages = BootScenarioInfo.NumImagePages[CcPfBootScenDriverInitPhase];
    Cursors[ImageCursor].NumPagesForPhase[PrefetchPhaseIdx] = NumPages;
    RemainingImagePages -= NumPages;

    SystemDriverPrefetchingPhaseIdx = PrefetchPhaseIdx;

    PrefetchPhaseIdx++;

    //
    // Account for the video init pages we will prefetch last.
    //

    RemainingDataPages -= VideoInitDataPages;
    RemainingImagePages -= VideoInitImagePages;

    //
    // If we have plenty of available memory, prefetch the rest of the pages
    // (i.e. left over after driver init pages) in one pass.
    //

    TotalPagesToPrefetch = ScenarioInfo.NumDataPages + ScenarioInfo.NumImagePages;

    if (MmAvailablePages > BootPrefetchAdjustment + TotalPagesToPrefetch) {
       
        Cursors[DataCursor].NumPagesForPhase[PrefetchPhaseIdx] = RemainingDataPages;
        RemainingDataPages = 0;
        
        Cursors[ImageCursor].NumPagesForPhase[PrefetchPhaseIdx] = RemainingImagePages;
        RemainingImagePages = 0;

        PrefetchPhaseIdx++;

    } else {

        //
        // We will be short on memory. Try to prefetch for as many phases of
        // boot as we can in parallel. Prefetching data & image pages per boot
        // phase, so we don't end up with data pages for all phase but no image
        // pages so we have to go to the disk in each phase. Prefetching in 
        // chunks also help that all the pages we need for the initial phases
        // of boot ending up at the end of the standby list, since when 
        // CcPfPrefetchingForBoot is set, prefetched pages will be inserted 
        // from the front of the standby list.
        //

        for (BootPhaseIdx = CcPfBootScenDriverInitPhase + 1; 
             BootPhaseIdx < CcPfBootScenMaxPhase; 
             BootPhaseIdx++) {

            //
            // If we don't have any type of pages left to prefetch, we are done.
            //

            if (!RemainingDataPages && !RemainingImagePages) {
                break;
            }

            NumPages = CCPF_MIN(RemainingDataPages, BootScenarioInfo.NumDataPages[BootPhaseIdx]);
            RemainingDataPages -= NumPages;
            Cursors[DataCursor].NumPagesForPhase[PrefetchPhaseIdx] = NumPages;

            NumPages = CCPF_MIN(RemainingImagePages, BootScenarioInfo.NumImagePages[BootPhaseIdx]);
            RemainingImagePages -= NumPages;
            Cursors[ImageCursor].NumPagesForPhase[PrefetchPhaseIdx] = NumPages;

            PrefetchPhaseIdx++;
        }
    }

    PreSmssPrefetchingPhaseIdx = PrefetchPhaseIdx - 1;

    //
    // If we'll be prefetching pages in parallel to video initialization, now
    // add the phase for it.
    //

    if (VideoInitDataPages || VideoInitImagePages) {

        Cursors[DataCursor].NumPagesForPhase[PrefetchPhaseIdx] = VideoInitDataPages;
        Cursors[ImageCursor].NumPagesForPhase[PrefetchPhaseIdx] = VideoInitImagePages;

        VideoInitPrefetchingPhaseIdx = PrefetchPhaseIdx;

        PrefetchPhaseIdx++;

    } else {

        //
        // We won't have a prefetching phase parallel to video initialization.
        //

        VideoInitPrefetchingPhaseIdx = CCPF_MAX_BOOT_PREFETCH_PHASES;
    }

    //
    // We should not end up with more prefetch phases than we have room for.
    //

    CCPF_ASSERT(PrefetchPhaseIdx < CCPF_MAX_BOOT_PREFETCH_PHASES);

    LastPrefetchPhaseIdx = PrefetchPhaseIdx;

    //
    // Prefetch the data and image pages for each boot prefetching phase,
    // waiting for & signaling the events matching those phases so boot
    // is synchronized with prefetching. (I.e. we prefetch pages for a boot
    // phase before we start that boot phase.)
    //

    for (PrefetchPhaseIdx = 0; PrefetchPhaseIdx < LastPrefetchPhaseIdx; PrefetchPhaseIdx++) {

        //
        // If this is the video init prefetching phase, wait for video 
        // initialization to begin.
        //

        if (PrefetchPhaseIdx == VideoInitPrefetchingPhaseIdx) {
            KeWaitForSingleObject(&BootPrefetcher->VideoInitStarted, 
                                  Executive, 
                                  KernelMode, 
                                  FALSE, 
                                  NULL);
        }

        for (CursorIdx = 0; CursorIdx < MaxCursor; CursorIdx++) {

            Cursor = &Cursors[CursorIdx];

            NumPagesToPrefetch = Cursor->NumPagesForPhase[PrefetchPhaseIdx];

            //
            // For prefetch phases before SMSS is launched keep an eye on
            // how much memory is still available to prefetch into so we
            // don't cannibalize ourselves. After SMSS our heuristics on
            // standby-list composition do not make sense.
            //

            if (PrefetchPhaseIdx <= PreSmssPrefetchingPhaseIdx) {          

                //
                // Check if we have available memory to prefetch more.
                //

                if (TotalPagesPrefetched + BootPrefetchAdjustment >= MmAvailablePages) {

                    OutOfAvailablePages = TRUE;

                    NumPagesToPrefetch = 0;

                } else {

                    //
                    // Check if we have to adjust NumPagesToPrefetch and prefetch
                    // one last chunk.
                    //

                    AvailablePages = MmAvailablePages;
                    AvailablePages -= (TotalPagesPrefetched + BootPrefetchAdjustment);

                    if (AvailablePages < NumPagesToPrefetch) {
                        NumPagesToPrefetch = AvailablePages;
                    }
                }
            }

            if (NumPagesToPrefetch) {

                Status = CcPfPrefetchSections(&PrefetchHeader, 
                                              Cursor->PrefetchType,  
                                              &Cursor->StartCursor,
                                              NumPagesToPrefetch,
                                              &NumPagesPrefetched,
                                              &Cursor->EndCursor);

                if (!NT_SUCCESS(Status)) {
                    goto cleanup;
                }

            } else {

                NumPagesPrefetched = 0;
            }

            //
            // Update our position.
            //
            
            Cursor->StartCursor = Cursor->EndCursor;

            TotalPagesPrefetched += NumPagesPrefetched;

        }

        //
        // Note that we are done with this prefetching phase and
        // system boot can continue.
        //

        if (PrefetchPhaseIdx == SystemDriverPrefetchingPhaseIdx) {
            KeSetEvent(&BootPrefetcher->SystemDriversPrefetchingDone,
                       IO_NO_INCREMENT,
                       FALSE);
        }

        if (PrefetchPhaseIdx == PreSmssPrefetchingPhaseIdx) {
            KeSetEvent(&BootPrefetcher->PreSmssPrefetchingDone,
                       IO_NO_INCREMENT,
                       FALSE);
        }

        if (PrefetchPhaseIdx == VideoInitPrefetchingPhaseIdx) {
            KeSetEvent(&BootPrefetcher->VideoInitPrefetchingDone,
                       IO_NO_INCREMENT,
                       FALSE);
        }
    }

    Status = STATUS_SUCCESS;

 cleanup:

    //
    // Log that we are done with boot prefetch disk I/Os.
    //

    if (PERFINFO_IS_GROUP_ON(PERF_DISK_IO)) {

        LogEntry.Action = 1;
        LogEntry.Status = Status;
        LogEntry.Pages = TotalPagesPrefetched;
        
        PerfInfoLogBytes(PERFINFO_LOG_TYPE_BOOT_PREFETCH_INFORMATION,
                         &LogEntry,
                         sizeof(LogEntry));
    }

    //
    // Make sure all the events system may wait for before proceeding with
    // boot are signaled.
    //

    KeSetEvent(&BootPrefetcher->SystemDriversPrefetchingDone,
               IO_NO_INCREMENT,
               FALSE);

    KeSetEvent(&BootPrefetcher->PreSmssPrefetchingDone,
               IO_NO_INCREMENT,
               FALSE);

    KeSetEvent(&BootPrefetcher->VideoInitPrefetchingDone,
               IO_NO_INCREMENT,
               FALSE);

    //
    // Let MM know that we are done prefetching for boot.
    //

    CcPfPrefetchingForBoot = FALSE;

    //
    // Cleanup prefetching context.
    //

    CcPfCleanupPrefetchHeader(&PrefetchHeader);

    if (PrefetchHeader.Scenario) {
        ExFreePool(PrefetchHeader.Scenario);
    }

    DBGPR((CCPFID,PFTRC,"CCPF: BootWorker()=%x,%d\n",Status,(ULONG)OutOfAvailablePages));
}

NTSTATUS
CcPfBootQueueEndTraceTimer (
    PLARGE_INTEGER Timeout
    )

/*++

Routine Description:

    This routine allocates and queues a timer that will attempt to end
    the boot trace when it fires.

Arguments:

    Timeout - Timeout for the timer.

Return Value:

    Status.

Environment:

    Kernel mode. IRQL <= PASSIVE_LEVEL.

--*/

{
    PVOID Allocation;
    PKTIMER Timer;
    PKDPC Dpc;
    ULONG AllocationSize;
    NTSTATUS Status;
    BOOLEAN TimerAlreadyQueued;

    //
    // Initialize locals.
    //

    Allocation = NULL;

    //
    // Make a single allocation for the timer and dpc.
    //

    AllocationSize = sizeof(KTIMER);
    AllocationSize += sizeof(KDPC);

    Allocation = ExAllocatePoolWithTag(NonPagedPool,
                                       AllocationSize,
                                       CCPF_ALLOC_BOOTWRKR_TAG);

    if (!Allocation) {
        Status = STATUS_INSUFFICIENT_RESOURCES;
        goto cleanup;
    }

    Timer = Allocation;
    Dpc = (PKDPC)(Timer + 1);

    //
    // Initialize the timer and DPC. We'll be passing the allocation to the 
    // queued DPC so it can be freed.
    //

    KeInitializeTimer(Timer);
    KeInitializeDpc(Dpc, CcPfEndBootTimerRoutine, Allocation);

    //
    // Queue the timer.
    //

    TimerAlreadyQueued = KeSetTimer(Timer, *Timeout, Dpc);

    CCPF_ASSERT(!TimerAlreadyQueued);

    Status = STATUS_SUCCESS;
    
  cleanup:

    if (!NT_SUCCESS(Status)) {
        if (Allocation) {
            ExFreePool(Allocation);
        }
    }

    return Status;
}

VOID
CcPfEndBootTimerRoutine(
    IN PKDPC Dpc,
    IN PVOID DeferredContext,
    IN PVOID SystemArgument1,
    IN PVOID SystemArgument2
    )

/*++

Routine Description:

    This routine is invoked as the DPC handler for a timer queued to
    mark the end of boot and end the boot trace if one is active.

Arguments:

    DeferredContext - Allocated memory for the timer & dpc that need
      to be freed.

Return Value:

    None.

Environment:

    Kernel mode. IRQL == DISPATCH_LEVEL.

--*/

    
{
    PCCPF_TRACE_HEADER BootTrace;
    PERFINFO_BOOT_PHASE_START LogEntry;

    UNREFERENCED_PARAMETER (Dpc);
    UNREFERENCED_PARAMETER (SystemArgument1);
    UNREFERENCED_PARAMETER (SystemArgument2);

    //
    // Initialize locals.
    //

    BootTrace = NULL;

    //
    // Is the boot trace still active?
    //

    BootTrace = CcPfReferenceProcessTrace(PsInitialSystemProcess);

    if (BootTrace && BootTrace->ScenarioType == PfSystemBootScenarioType) {

        //
        // Is somebody already ending the boot trace?
        //

        if (!InterlockedCompareExchange(&BootTrace->EndTraceCalled, 1, 0)) {
        
            //
            // We set EndTraceCalled from 0 to 1. Queue the
            // workitem to end the trace.
            //
            
            ExQueueWorkItem(&BootTrace->EndTraceWorkItem, DelayedWorkQueue);

            //
            // Log that we are ending the boot trace.
            //

            if (PERFINFO_IS_GROUP_ON(PERF_LOADER)) {

                LogEntry.Phase = PfMaxBootPhaseId;
                
                PerfInfoLogBytes(PERFINFO_LOG_TYPE_BOOT_PHASE_START,
                                 &LogEntry,
                                 sizeof(LogEntry));
            }
        }
    }

    //
    // Free the memory allocated for the timer and dpc.
    //

    CCPF_ASSERT(DeferredContext);   
    ExFreePool(DeferredContext);

    if (BootTrace) {
        CcPfDecRef(&BootTrace->RefCount);
    }

    return;
}
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\base\ntos\cache\pinsup.c ===
/*++

Copyright (c) 1990  Microsoft Corporation

Module Name:

    pinsup.c

Abstract:

    This module implements the pointer-based Pin support routines for the
    Cache subsystem.

Author:

    Tom Miller      [TomM]      4-June-1990

Revision History:

--*/

#include "cc.h"

//
//  Define our debug constant
//

#define me 0x00000008

#if LIST_DBG

#define SetCallersAddress(BCB) {                            \
    RtlGetCallersAddress( &(BCB)->CallerAddress,            \
                          &(BCB)->CallersCallerAddress );   \
}

#endif

//
//  Internal routines
//

POBCB
CcAllocateObcb (
    IN PLARGE_INTEGER FileOffset,
    IN ULONG Length,
    IN PBCB FirstBcb
    );

#ifdef ALLOC_PRAGMA
#if !LIST_DBG
#pragma alloc_text(PAGE,CcMapData)
#pragma alloc_text(PAGE,CcPinMappedData)
#pragma alloc_text(PAGE,CcPinRead)
#pragma alloc_text(PAGE,CcPreparePinWrite)
#endif
#pragma alloc_text(PAGE,CcUnpinData)
#pragma alloc_text(PAGE,CcSetBcbOwnerPointer)
#pragma alloc_text(PAGE,CcUnpinDataForThread)
#pragma alloc_text(PAGE,CcAllocateObcb)
#endif



BOOLEAN
CcMapData (
    IN PFILE_OBJECT FileObject,
    IN PLARGE_INTEGER FileOffset,
    IN ULONG Length,
    IN ULONG Flags,
    OUT PVOID *Bcb,
    OUT PVOID *Buffer
    )

/*++

Routine Description:

    This routine attempts to map the specified file data in the cache.
    A pointer is returned to the desired data in the cache.

    If the caller does not want to block on this call, then
    Wait should be supplied as FALSE.  If Wait was supplied as FALSE and
    it is currently impossible to supply the requested data without
    blocking, then this routine will return FALSE.  However, if the
    data is immediately accessible in the cache and no blocking is
    required, this routine returns TRUE with a pointer to the data.

    Note that a call to this routine with Wait supplied as TRUE is
    considerably faster than a call with Wait supplies as FALSE, because
    in the Wait TRUE case we only have to make sure the data is mapped
    in order to return.

    It is illegal to modify data that is only mapped, and can in fact lead
    to serious problems.  It is impossible to check for this in all cases,
    however CcSetDirtyPinnedData may implement some Assertions to check for
    this.  If the caller wishes to modify data that it has only mapped, then
    it must *first* call CcPinMappedData.

    In any case, the caller MUST subsequently call CcUnpinData.
    Naturally if CcPinRead or CcPreparePinWrite were called multiple
    times for the same data, CcUnpinData must be called the same number
    of times.

    The returned Buffer pointer is valid until the data is unpinned, at
    which point it is invalid to use the pointer further.  This buffer pointer
    will remain valid if CcPinMappedData is called.

    Note that under some circumstances (like Wait supplied as FALSE or more
    than a page is requested), this routine may actually pin the data, however
    it is not necessary, and in fact not correct, for the caller to be concerned
    about this.

Arguments:

    FileObject - Pointer to the file object for a file which was
                 opened with NO_INTERMEDIATE_BUFFERING clear, i.e., for
                 which CcInitializeCacheMap was called by the file system.

    FileOffset - Byte offset in file for desired data.

    Length - Length of desired data in bytes.

    Wait - FALSE if caller may not block, TRUE otherwise (see description
           above)

    Bcb - On the first call this returns a pointer to a Bcb
          parameter which must be supplied as input on all subsequent
          calls, for this buffer

    Buffer - Returns pointer to desired data, valid until the buffer is
             unpinned or freed.  This pointer will remain valid if CcPinMappedData
             is called.

Return Value:

    FALSE - if Wait was supplied as FALSE and the data was not delivered

    TRUE - if the data is being delivered

--*/

{
    PSHARED_CACHE_MAP SharedCacheMap;
    LARGE_INTEGER BeyondLastByte;
    ULONG ReceivedLength;
    ULONG SavedState;
    volatile UCHAR ch;
    PVOID TempBcb;
    ULONG PageCount = ADDRESS_AND_SIZE_TO_SPAN_PAGES((ULongToPtr(FileOffset->LowPart)), Length);
    PETHREAD Thread = PsGetCurrentThread();

    DebugTrace(+1, me, "CcMapData\n", 0 );

    MmSavePageFaultReadAhead( Thread, &SavedState );

    //
    //  Increment performance counters
    //

    if (FlagOn(Flags, MAP_WAIT)) {

        CcMapDataWait += 1;

        //
        //  Initialize the indirect pointer to our miss counter.
        //

        CcMissCounter = &CcMapDataWaitMiss;

    } else {
        CcMapDataNoWait += 1;
    }

    //
    //  Get pointer to SharedCacheMap.
    //

    SharedCacheMap = *(PSHARED_CACHE_MAP *)((PCHAR)FileObject->SectionObjectPointer
                                            + sizeof(PVOID));

    //
    //  Call local routine to Map or Access the file data.  If we cannot map
    //  the data because of a Wait condition, return FALSE.
    //

    if (FlagOn(Flags, MAP_WAIT)) {

        *Buffer = CcGetVirtualAddress( SharedCacheMap,
                                       *FileOffset,
                                       (PVACB *)&TempBcb,
                                       &ReceivedLength );

        ASSERT( ReceivedLength >= Length );

    } else if (!CcPinFileData( FileObject,
                               FileOffset,
                               Length,
                               TRUE,
                               FALSE,
                               Flags,
                               (PBCB *)&TempBcb,
                               Buffer,
                               &BeyondLastByte )) {

        DebugTrace(-1, me, "CcMapData -> FALSE\n", 0 );

        CcMapDataNoWaitMiss += 1;

        return FALSE;

    } else {

        ASSERT( (BeyondLastByte.QuadPart - FileOffset->QuadPart) >= Length );

#if LIST_DBG
        {
            KIRQL OldIrql;
            PBCB BcbTemp = (PBCB)*Bcb;

            OldIrql = KeAcquireQueuedSpinLock( LockQueueBcbLock );

            if (BcbTemp->CcBcbLinks.Flink == NULL) {

                InsertTailList( &CcBcbList, &BcbTemp->CcBcbLinks );
                CcBcbCount += 1;
                KeReleaseQueuedSpinLock( LockQueueBcbLock, OldIrql );
                SetCallersAddress( BcbTemp );

            } else {
                KeReleaseQueuedSpinLock( LockQueueBcbLock, OldIrql );
            }

        }
#endif

    }

    //
    //  Caller specifically requested he doesn't want data to be faulted in.
    //

    if (!FlagOn( Flags, MAP_NO_READ )) {

        //
        //  Now let's just sit here and take the miss(es) like a man (and count them).
        //

        try {

            //
            //  Loop to touch each page
            //

            BeyondLastByte.LowPart = 0;

            while (PageCount != 0) {

                MmSetPageFaultReadAhead( Thread, PageCount - 1 );

                ch = *((volatile UCHAR *)(*Buffer) + BeyondLastByte.LowPart);

                BeyondLastByte.LowPart += PAGE_SIZE;
                PageCount -= 1;
            }

        } finally {

            MmResetPageFaultReadAhead( Thread, SavedState );

            if (AbnormalTermination() && (TempBcb != NULL)) {
                CcUnpinFileData( (PBCB)TempBcb, TRUE, UNPIN );
            }
        }
    }

    CcMissCounter = &CcThrowAway;

    //
    //  Increment the pointer as a reminder that it is read only, and
    //  return it.  We pend this until now to avoid raising with a valid
    //  Bcb into caller's contexts.
    //

    *(PCHAR *)&TempBcb += 1;
    *Bcb = TempBcb;

    DebugTrace(-1, me, "CcMapData -> TRUE\n", 0 );

    return TRUE;
}


BOOLEAN
CcPinMappedData (
    IN PFILE_OBJECT FileObject,
    IN PLARGE_INTEGER FileOffset,
    IN ULONG Length,
    IN ULONG Flags,
    IN OUT PVOID *Bcb
    )

/*++

Routine Description:

    This routine attempts to pin data that was previously only mapped.
    If the routine determines that in fact it was necessary to actually
    pin the data when CcMapData was called, then this routine does not
    have to do anything.

    If the caller does not want to block on this call, then
    Wait should be supplied as FALSE.  If Wait was supplied as FALSE and
    it is currently impossible to supply the requested data without
    blocking, then this routine will return FALSE.  However, if the
    data is immediately accessible in the cache and no blocking is
    required, this routine returns TRUE with a pointer to the data.

    If the data is not returned in the first call, the caller
    may request the data later with Wait = TRUE.  It is not required
    that the caller request the data later.

    If the caller subsequently modifies the data, it should call
    CcSetDirtyPinnedData.

    In any case, the caller MUST subsequently call CcUnpinData.
    Naturally if CcPinRead or CcPreparePinWrite were called multiple
    times for the same data, CcUnpinData must be called the same number
    of times.

    Note there are no performance counters in this routine, as the misses
    will almost always occur on the map above, and there will seldom be a
    miss on this conversion.

Arguments:

    FileObject - Pointer to the file object for a file which was
                 opened with NO_INTERMEDIATE_BUFFERING clear, i.e., for
                 which CcInitializeCacheMap was called by the file system.

    FileOffset - Byte offset in file for desired data.

    Length - Length of desired data in bytes.

    Flags - (PIN_WAIT, PIN_EXCLUSIVE, PIN_NO_READ, etc. as defined in cache.h)
            If the caller specifies PIN_NO_READ and PIN_EXCLUSIVE, then he must
            guarantee that no one else will be attempting to map the view, if he
            wants to guarantee that the Bcb is not mapped (view may be purged).
            If the caller specifies PIN_NO_READ without PIN_EXCLUSIVE, the data
            may or may not be mapped in the return Bcb.

    Bcb - On the first call this returns a pointer to a Bcb
          parameter which must be supplied as input on all subsequent
          calls, for this buffer

Return Value:

    FALSE - if Wait was not set and the data was not delivered

    TRUE - if the data is being delivered

--*/

{
    PVOID Buffer;
    LARGE_INTEGER BeyondLastByte;
    PSHARED_CACHE_MAP SharedCacheMap;
    LARGE_INTEGER LocalFileOffset = *FileOffset;
    POBCB MyBcb = NULL;
    PBCB *CurrentBcbPtr = (PBCB *)&MyBcb;
    BOOLEAN Result = FALSE;

    DebugTrace(+1, me, "CcPinMappedData\n", 0 );

    //
    // If the Bcb is no longer ReadOnly, then just return.
    //

    if ((*(PULONG)Bcb & 1) == 0) {
        return TRUE;
    }

    //
    // Remove the Read Only flag
    //

    *(PCHAR *)Bcb -= 1;

    //
    //  Get pointer to SharedCacheMap.
    //

    SharedCacheMap = *(PSHARED_CACHE_MAP *)((PCHAR)FileObject->SectionObjectPointer
                                            + sizeof(PVOID));

    //
    //  We only count the calls to this routine, since they are almost guaranteed
    //  to be hits.
    //

    CcPinMappedDataCount += 1;

    //
    //  Guarantee we will put the flag back if required.
    //

    try {

        if (((PBCB)*Bcb)->NodeTypeCode != CACHE_NTC_BCB) {

            //
            //  Form loop to handle occasional overlapped Bcb case.
            //

            do {

                //
                //  If we have already been through the loop, then adjust
                //  our file offset and length from the last time.
                //

                if (MyBcb != NULL) {

                    //
                    //  If this is the second time through the loop, then it is time
                    //  to handle the overlap case and allocate an OBCB.
                    //

                    if (CurrentBcbPtr == (PBCB *)&MyBcb) {

                        MyBcb = CcAllocateObcb( FileOffset, Length, (PBCB)MyBcb );

                        //
                        //  Set CurrentBcbPtr to point at the first entry in
                        //  the vector (which is already filled in), before
                        //  advancing it below.
                        //

                        CurrentBcbPtr = &MyBcb->Bcbs[0];
                    }

                    Length -= (ULONG)(BeyondLastByte.QuadPart - LocalFileOffset.QuadPart);
                    LocalFileOffset.QuadPart = BeyondLastByte.QuadPart;
                    CurrentBcbPtr += 1;
                }

                //
                //  Call local routine to Map or Access the file data.  If we cannot map
                //  the data because of a Wait condition, return FALSE.
                //

                if (!CcPinFileData( FileObject,
                                    &LocalFileOffset,
                                    Length,
                                    (BOOLEAN)!FlagOn(SharedCacheMap->Flags, MODIFIED_WRITE_DISABLED),
                                    FALSE,
                                    Flags,
                                    CurrentBcbPtr,
                                    &Buffer,
                                    &BeyondLastByte )) {

                    try_return( Result = FALSE );
                }

            //
            //  Continue looping if we did not get everything.
            //

            } while((BeyondLastByte.QuadPart - LocalFileOffset.QuadPart) < Length);

            //
            //  Free the Vacb before going on.
            //

            CcFreeVirtualAddress( (PVACB)*Bcb );

            *Bcb = MyBcb;

            //
            //  Debug routines used to insert and remove Bcbs from the global list
            //

#if LIST_DBG
            {
                KIRQL OldIrql;
                PBCB BcbTemp = (PBCB)*Bcb;

                OldIrql = KeAcquireQueuedSpinLock( LockQueueBcbLock );

                if (BcbTemp->CcBcbLinks.Flink == NULL) {

                    InsertTailList( &CcBcbList, &BcbTemp->CcBcbLinks );
                    CcBcbCount += 1;
                    KeReleaseQueuedSpinLock( LockQueueBcbLock, OldIrql );
                    SetCallersAddress( BcbTemp );

                } else {
                    KeReleaseQueuedSpinLock( LockQueueBcbLock, OldIrql );
                }

            }
#endif
        }

        //
        //  If he really has a Bcb, all we have to do is acquire it shared since he is
        //  no longer ReadOnly.
        //

        else {

            if (!ExAcquireSharedStarveExclusive( &((PBCB)*Bcb)->Resource, BooleanFlagOn(Flags, PIN_WAIT))) {

                try_return( Result = FALSE );
            }
        }

        Result = TRUE;

    try_exit: NOTHING;
    }
    finally {

        if (!Result) {

            //
            //  Put the Read Only flag back
            //

            *(PCHAR *)Bcb += 1;

            //
            //  We may have gotten partway through
            //

            if (MyBcb != NULL) {
                CcUnpinData( MyBcb );
            }
        }

        DebugTrace(-1, me, "CcPinMappedData -> %02lx\n", Result );
    }
    return Result;
}


BOOLEAN
CcPinRead (
    IN PFILE_OBJECT FileObject,
    IN PLARGE_INTEGER FileOffset,
    IN ULONG Length,
    IN ULONG Flags,
    OUT PVOID *Bcb,
    OUT PVOID *Buffer
    )

/*++

Routine Description:

    This routine attempts to pin the specified file data in the cache.
    A pointer is returned to the desired data in the cache.  This routine
    is intended for File System support and is not intended to be called
    from Dpc level.

    If the caller does not want to block on this call, then
    Wait should be supplied as FALSE.  If Wait was supplied as FALSE and
    it is currently impossible to supply the requested data without
    blocking, then this routine will return FALSE.  However, if the
    data is immediately accessible in the cache and no blocking is
    required, this routine returns TRUE with a pointer to the data.

    If the data is not returned in the first call, the caller
    may request the data later with Wait = TRUE.  It is not required
    that the caller request the data later.

    If the caller subsequently modifies the data, it should call
    CcSetDirtyPinnedData.

    In any case, the caller MUST subsequently call CcUnpinData.
    Naturally if CcPinRead or CcPreparePinWrite were called multiple
    times for the same data, CcUnpinData must be called the same number
    of times.

    The returned Buffer pointer is valid until the data is unpinned, at
    which point it is invalid to use the pointer further.

Arguments:

    FileObject - Pointer to the file object for a file which was
                 opened with NO_INTERMEDIATE_BUFFERING clear, i.e., for
                 which CcInitializeCacheMap was called by the file system.

    FileOffset - Byte offset in file for desired data.

    Length - Length of desired data in bytes.

    Flags - (PIN_WAIT, PIN_EXCLUSIVE, PIN_NO_READ, etc. as defined in cache.h)
            If the caller specifies PIN_NO_READ and PIN_EXCLUSIVE, then he must
            guarantee that no one else will be attempting to map the view, if he
            wants to guarantee that the Bcb is not mapped (view may be purged).
            If the caller specifies PIN_NO_READ without PIN_EXCLUSIVE, the data
            may or may not be mapped in the return Bcb.

    Bcb - On the first call this returns a pointer to a Bcb
          parameter which must be supplied as input on all subsequent
          calls, for this buffer

    Buffer - Returns pointer to desired data, valid until the buffer is
             unpinned or freed.

Return Value:

    FALSE - if Wait was not set and the data was not delivered

    TRUE - if the data is being delivered

--*/

{
    PSHARED_CACHE_MAP SharedCacheMap;
    PVOID LocalBuffer;
    LARGE_INTEGER BeyondLastByte;
    LARGE_INTEGER LocalFileOffset = *FileOffset;
    POBCB MyBcb = NULL;
    PBCB *CurrentBcbPtr = (PBCB *)&MyBcb;
    BOOLEAN Result = FALSE;

    DebugTrace(+1, me, "CcPinRead\n", 0 );

    //
    //  Increment performance counters
    //

    if (FlagOn(Flags, PIN_WAIT)) {

        CcPinReadWait += 1;

        //
        //  Initialize the indirect pointer to our miss counter.
        //

        CcMissCounter = &CcPinReadWaitMiss;

    } else {
        CcPinReadNoWait += 1;
    }

    //
    //  Get pointer to SharedCacheMap.
    //

    SharedCacheMap = *(PSHARED_CACHE_MAP *)((PCHAR)FileObject->SectionObjectPointer
                                            + sizeof(PVOID));

    try {

        //
        //  Form loop to handle occasional overlapped Bcb case.
        //

        do {

            //
            //  If we have already been through the loop, then adjust
            //  our file offset and length from the last time.
            //

            if (MyBcb != NULL) {

                //
                //  If this is the second time through the loop, then it is time
                //  to handle the overlap case and allocate an OBCB.
                //

                if (CurrentBcbPtr == (PBCB *)&MyBcb) {

                    MyBcb = CcAllocateObcb( FileOffset, Length, (PBCB)MyBcb );

                    //
                    //  Set CurrentBcbPtr to point at the first entry in
                    //  the vector (which is already filled in), before
                    //  advancing it below.
                    //

                    CurrentBcbPtr = &MyBcb->Bcbs[0];

                    //
                    //  Also on second time through, return starting Buffer
                    //

                    *Buffer = LocalBuffer;
                }

                Length -= (ULONG)(BeyondLastByte.QuadPart - LocalFileOffset.QuadPart);
                LocalFileOffset.QuadPart = BeyondLastByte.QuadPart;
                CurrentBcbPtr += 1;
            }

            //
            //  Call local routine to Map or Access the file data.  If we cannot map
            //  the data because of a Wait condition, return FALSE.
            //

            if (!CcPinFileData( FileObject,
                                &LocalFileOffset,
                                Length,
                                (BOOLEAN)!FlagOn(SharedCacheMap->Flags, MODIFIED_WRITE_DISABLED),
                                FALSE,
                                Flags,
                                CurrentBcbPtr,
                                &LocalBuffer,
                                &BeyondLastByte )) {

                CcPinReadNoWaitMiss += 1;

                try_return( Result = FALSE );
            }

        //
        //  Continue looping if we did not get everything.
        //

        } while((BeyondLastByte.QuadPart - LocalFileOffset.QuadPart) < Length);

        *Bcb = MyBcb;

        //
        //  Debug routines used to insert and remove Bcbs from the global list
        //

#if LIST_DBG

        {
            KIRQL OldIrql;
            PBCB BcbTemp = (PBCB)*Bcb;

            OldIrql = KeAcquireQueuedSpinLock( LockQueueBcbLock );

            if (BcbTemp->CcBcbLinks.Flink == NULL) {

                InsertTailList( &CcBcbList, &BcbTemp->CcBcbLinks );
                CcBcbCount += 1;
                KeReleaseQueuedSpinLock( LockQueueBcbLock, OldIrql );
                SetCallersAddress( BcbTemp );

            } else {
                KeReleaseQueuedSpinLock( LockQueueBcbLock, OldIrql );
            }

        }

#endif

        //
        //  In the normal (nonoverlapping) case we return the
        //  correct buffer address here.
        //

        if (CurrentBcbPtr == (PBCB *)&MyBcb) {
            *Buffer = LocalBuffer;
        }

        Result = TRUE;

    try_exit: NOTHING;
    }
    finally {

        CcMissCounter = &CcThrowAway;

        if (!Result) {

            //
            //  We may have gotten partway through
            //

            if (MyBcb != NULL) {
                CcUnpinData( MyBcb );
            }
        }

        DebugTrace(-1, me, "CcPinRead -> %02lx\n", Result );
    }

    return Result;
}


BOOLEAN
CcPreparePinWrite (
    IN PFILE_OBJECT FileObject,
    IN PLARGE_INTEGER FileOffset,
    IN ULONG Length,
    IN BOOLEAN Zero,
    IN ULONG Flags,
    OUT PVOID *Bcb,
    OUT PVOID *Buffer
    )

/*++

Routine Description:

    This routine attempts to lock the specified file data in the cache
    and return a pointer to it along with the correct
    I/O status.  Pages to be completely overwritten may be satisfied
    with emtpy pages.

    If not all of the pages can be prepared, and Wait was supplied as
    FALSE, then this routine will return FALSE, and its outputs will
    be meaningless.  The caller may request the data later with
    Wait = TRUE.  However, it is not required that the caller request
    the data later.

    If Wait is supplied as TRUE, and all of the pages can be prepared
    without blocking, this call will return TRUE immediately.  Otherwise,
    this call will block until all of the pages can be prepared, and
    then return TRUE.

    When this call returns with TRUE, the caller may immediately begin
    to transfer data into the buffers via the Buffer pointer.  The
    buffer will already be marked dirty.

    The caller MUST subsequently call CcUnpinData.
    Naturally if CcPinRead or CcPreparePinWrite were called multiple
    times for the same data, CcUnpinData must be called the same number
    of times.

    The returned Buffer pointer is valid until the data is unpinned, at
    which point it is invalid to use the pointer further.

Arguments:

    FileObject - Pointer to the file object for a file which was
                 opened with NO_INTERMEDIATE_BUFFERING clear, i.e., for
                 which CcInitializeCacheMap was called by the file system.

    FileOffset - Byte offset in file for desired data.

    Length - Length of desired data in bytes.

    Zero - If supplied as TRUE, the buffer will be zeroed on return.

    Flags - (PIN_WAIT, PIN_EXCLUSIVE, PIN_NO_READ, etc. as defined in cache.h)
            If the caller specifies PIN_NO_READ and PIN_EXCLUSIVE, then he must
            guarantee that no one else will be attempting to map the view, if he
            wants to guarantee that the Bcb is not mapped (view may be purged).
            If the caller specifies PIN_NO_READ without PIN_EXCLUSIVE, the data
            may or may not be mapped in the return Bcb.

    Bcb - This returns a pointer to a Bcb parameter which must be
          supplied as input to CcPinWriteComplete.

    Buffer - Returns pointer to desired data, valid until the buffer is
             unpinned or freed.

Return Value:

    FALSE - if Wait was not set and the data was not delivered

    TRUE - if the pages are being delivered

--*/

{
    PSHARED_CACHE_MAP SharedCacheMap;
    PVOID LocalBuffer;
    LARGE_INTEGER BeyondLastByte;
    LARGE_INTEGER LocalFileOffset = *FileOffset;
    POBCB MyBcb = NULL;
    PBCB *CurrentBcbPtr = (PBCB *)&MyBcb;
    ULONG OriginalLength = Length;
    BOOLEAN Result = FALSE;

    DebugTrace(+1, me, "CcPreparePinWrite\n", 0 );

    //
    //  Get pointer to SharedCacheMap.
    //

    SharedCacheMap = *(PSHARED_CACHE_MAP *)((PCHAR)FileObject->SectionObjectPointer
                                            + sizeof(PVOID));

    try {

        //
        //  Form loop to handle occasional overlapped Bcb case.
        //

        do {

            //
            //  If we have already been through the loop, then adjust
            //  our file offset and length from the last time.
            //

            if (MyBcb != NULL) {

                //
                //  If this is the second time through the loop, then it is time
                //  to handle the overlap case and allocate an OBCB.
                //

                if (CurrentBcbPtr == (PBCB *)&MyBcb) {

                    MyBcb = CcAllocateObcb( FileOffset, Length, (PBCB)MyBcb );

                    //
                    //  Set CurrentBcbPtr to point at the first entry in
                    //  the vector (which is already filled in), before
                    //  advancing it below.
                    //

                    CurrentBcbPtr = &MyBcb->Bcbs[0];

                    //
                    //  Also on second time through, return starting Buffer
                    //

                    *Buffer = LocalBuffer;
                }

                Length -= (ULONG)(BeyondLastByte.QuadPart - LocalFileOffset.QuadPart);
                LocalFileOffset.QuadPart = BeyondLastByte.QuadPart;
                CurrentBcbPtr += 1;
            }

            //
            //  Call local routine to Map or Access the file data.  If we cannot map
            //  the data because of a Wait condition, return FALSE.
            //

            if (!CcPinFileData( FileObject,
                                &LocalFileOffset,
                                Length,
                                FALSE,
                                TRUE,
                                Flags,
                                CurrentBcbPtr,
                                &LocalBuffer,
                                &BeyondLastByte )) {

                try_return( Result = FALSE );
            }

        //
        //  Continue looping if we did not get everything.
        //

        } while((BeyondLastByte.QuadPart - LocalFileOffset.QuadPart) < Length);

        //
        //  Debug routines used to insert and remove Bcbs from the global list
        //

#if LIST_DBG

        {
            KIRQL OldIrql;
            PBCB BcbTemp = (PBCB)*Bcb;

            OldIrql = KeAcquireQueuedSpinLock( LockQueueBcbLock );

            if (BcbTemp->CcBcbLinks.Flink == NULL) {

                InsertTailList( &CcBcbList, &BcbTemp->CcBcbLinks );
                CcBcbCount += 1;
                KeReleaseQueuedSpinLock( LockQueueBcbLock, OldIrql );
                SetCallersAddress( BcbTemp );

            } else {
                KeReleaseQueuedSpinLock( LockQueueBcbLock, OldIrql );
            }

        }

#endif

        //
        //  In the normal (nonoverlapping) case we return the
        //  correct buffer address here.
        //

        if (CurrentBcbPtr == (PBCB *)&MyBcb) {
            *Buffer = LocalBuffer;
        }

        if (Zero) {
            RtlZeroMemory( *Buffer, OriginalLength );
        }

        CcSetDirtyPinnedData( MyBcb, NULL );

        //
        //  Fill in the return argument.
        //

        *Bcb = MyBcb;
        
        Result = TRUE;

    try_exit: NOTHING;
    }
    finally {

        CcMissCounter = &CcThrowAway;

        if (!Result) {

            //
            //  We may have gotten partway through
            //

            if (MyBcb != NULL) {
                CcUnpinData( MyBcb );
            }
        }

        DebugTrace(-1, me, "CcPreparePinWrite -> %02lx\n", Result );
    }

    return Result;
}


VOID
CcUnpinData (
    IN PVOID Bcb
    )

/*++

Routine Description:

    This routine must be called at IPL0, some time after calling CcPinRead
    or CcPreparePinWrite.  It performs any cleanup that is necessary.

Arguments:

    Bcb - Bcb parameter returned from the last call to CcPinRead.

Return Value:

    None.

--*/

{
    DebugTrace(+1, me, "CcUnpinData:\n", 0 );
    DebugTrace( 0, me, "    >Bcb = %08lx\n", Bcb );

    //
    //  Test for ReadOnly and unpin accordingly.
    //

    if (((ULONG_PTR)Bcb & 1) != 0) {

        //
        //  Remove the Read Only flag
        //

        Bcb = (PVOID) ((ULONG_PTR)Bcb & ~1);

        CcUnpinFileData( (PBCB)Bcb, TRUE, UNPIN );

    } else {

        //
        //  Handle the overlapped Bcb case.
        //

        if (((POBCB)Bcb)->NodeTypeCode == CACHE_NTC_OBCB) {

            PBCB *BcbPtrPtr = &((POBCB)Bcb)->Bcbs[0];

            //
            //  Loop to free all Bcbs with recursive calls
            //  (rather than dealing with RO for this uncommon case).
            //

            while (*BcbPtrPtr != NULL) {
                CcUnpinData(*(BcbPtrPtr++));
            }

            //
            //  Then free the pool for the Obcb
            //

            ExFreePool( Bcb );

        //
        //  Otherwise, it is a normal Bcb
        //

        } else {
            CcUnpinFileData( (PBCB)Bcb, FALSE, UNPIN );
        }
    }

    DebugTrace(-1, me, "CcUnPinData -> VOID\n", 0 );
}


VOID
CcSetBcbOwnerPointer (
    IN PVOID Bcb,
    IN PVOID OwnerPointer
    )

/*++

Routine Description:

    This routine may be called to set the resource owner for the Bcb resource,
    for cases where another thread will do the unpin *and* the current thread
    may exit.

Arguments:

    Bcb - Bcb parameter returned from the last call to CcPinRead.

    OwnerPointer - A valid resource owner pointer, which means a pointer to
                   an allocated system address, with the low-order two bits
                   set.  The address may not be deallocated until after the
                   unpin call.

Return Value:

    None.

--*/

{
    ASSERT(((ULONG_PTR)Bcb & 1) == 0);

    //
    //  Handle the overlapped Bcb case.
    //

    if (((POBCB)Bcb)->NodeTypeCode == CACHE_NTC_OBCB) {

        PBCB *BcbPtrPtr = &((POBCB)Bcb)->Bcbs[0];

        //
        //  Loop to set owner for all Bcbs.
        //

        while (*BcbPtrPtr != NULL) {
            ExSetResourceOwnerPointer( &(*BcbPtrPtr)->Resource, OwnerPointer );
            BcbPtrPtr++;
        }

    //
    //  Otherwise, it is a normal Bcb
    //

    } else {

        //
        //  Handle normal case.
        //

        ExSetResourceOwnerPointer( &((PBCB)Bcb)->Resource, OwnerPointer );
    }
}


VOID
CcUnpinDataForThread (
    IN PVOID Bcb,
    IN ERESOURCE_THREAD ResourceThreadId
    )

/*++

Routine Description:

    This routine must be called at IPL0, some time after calling CcPinRead
    or CcPreparePinWrite.  It performs any cleanup that is necessary,
    releasing the Bcb resource for the given thread.

Arguments:

    Bcb - Bcb parameter returned from the last call to CcPinRead.

Return Value:

    None.

--*/

{
    DebugTrace(+1, me, "CcUnpinDataForThread:\n", 0 );
    DebugTrace( 0, me, "    >Bcb = %08lx\n", Bcb );
    DebugTrace( 0, me, "    >ResoureceThreadId = %08lx\n", ResoureceThreadId );

    //
    //  Test for ReadOnly and unpin accordingly.
    //

    if (((ULONG_PTR)Bcb & 1) != 0) {

        //
        //  Remove the Read Only flag
        //

        Bcb = (PVOID) ((ULONG_PTR)Bcb & ~1);

        CcUnpinFileData( (PBCB)Bcb, TRUE, UNPIN );

    } else {

        //
        //  Handle the overlapped Bcb case.
        //

        if (((POBCB)Bcb)->NodeTypeCode == CACHE_NTC_OBCB) {

            PBCB *BcbPtrPtr = &((POBCB)Bcb)->Bcbs[0];

            //
            //  Loop to free all Bcbs with recursive calls
            //  (rather than dealing with RO for this uncommon case).
            //

            while (*BcbPtrPtr != NULL) {
                CcUnpinDataForThread( *(BcbPtrPtr++), ResourceThreadId );
            }

            //
            //  Then free the pool for the Obcb
            //

            ExFreePool( Bcb );

        //
        //  Otherwise, it is a normal Bcb
        //

        } else {

            //
            //  If not readonly, we can release the resource for the thread first,
            //  and then call CcUnpinFileData.  Release resource first in case
            //  Bcb gets deallocated.
            //

            ExReleaseResourceForThreadLite( &((PBCB)Bcb)->Resource, ResourceThreadId );
            CcUnpinFileData( (PBCB)Bcb, TRUE, UNPIN );
        }
    }
    DebugTrace(-1, me, "CcUnpinDataForThread -> VOID\n", 0 );
}


POBCB
CcAllocateObcb (
    IN PLARGE_INTEGER FileOffset,
    IN ULONG Length,
    IN PBCB FirstBcb
    )

/*++

Routine Description:

    This routine is called by the various pinning routines to allocate and
    initialize an overlap Bcb.

Arguments:

    FileOffset - Starting file offset for the Obcb (An Obcb starts with a
                 public structure, which someone could use)

    Length - Length of the range covered by the Obcb

    FirstBcb - First Bcb already created, which only covers the start of
               the desired range (low order bit may be set to indicate ReadOnly)

Return Value:

    Pointer to the allocated Obcb

--*/

{
    ULONG LengthToAllocate;
    POBCB Obcb;
    PBCB Bcb = (PBCB)((ULONG_PTR)FirstBcb & ~1);

    //
    //  Allocate according to the worst case, assuming that we
    //  will need as many additional Bcbs as there are pages
    //  remaining. Also throw in one more pointer to guarantee
    //  users of the OBCB can always terminate on NULL.
    //
    //  We remove fron consideration the range described by the
    //  first Bcb (note that the range of the Obcb is not strictly
    //  starting at the first Bcb) and add in locations for the first
    //  bcb and the null.
    //

    LengthToAllocate = FIELD_OFFSET(OBCB, Bcbs) + (2 * sizeof(PBCB)) +
                       ((Length -
                         (Bcb->ByteLength -
                          (FileOffset->HighPart?
                           (ULONG)(FileOffset->QuadPart - Bcb->FileOffset.QuadPart) :
                           FileOffset->LowPart - Bcb->FileOffset.LowPart)) +
                         PAGE_SIZE - 1) / PAGE_SIZE) * sizeof(PBCB);

    Obcb = ExAllocatePoolWithTag( NonPagedPool, LengthToAllocate, 'bOcC' );
    if (Obcb == NULL) {
        ExRaiseStatus( STATUS_INSUFFICIENT_RESOURCES );
    }

    RtlZeroMemory( Obcb, LengthToAllocate );
    Obcb->NodeTypeCode = CACHE_NTC_OBCB;
    Obcb->NodeByteSize = (USHORT)LengthToAllocate;
    Obcb->ByteLength = Length;
    Obcb->FileOffset = *FileOffset;
    Obcb->Bcbs[0] = FirstBcb;

    return Obcb;
}
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\base\ntos\cache\sources.inc ===
MAJORCOMP=ntos
MINORCOMP=cache

TARGETNAME=cache
TARGETTYPE=LIBRARY
TARGETPATH=obj

INCLUDES=..;..\..\inc

SOURCES=..\cachedat.c   \
        ..\cachesub.c   \
        ..\copysup.c    \
        ..\fssup.c      \
        ..\lazyrite.c   \
        ..\logsup.c     \
        ..\mdlsup.c     \
        ..\pinsup.c     \
        ..\prefboot.c   \
        ..\prefetch.c   \
        ..\prefparm.c   \
        ..\ccperf.c     \
        ..\vacbsup.c

PRECOMPILED_INCLUDE=..\cc.h
PRECOMPILED_PCH=cc.pch
PRECOMPILED_OBJ=cc.obj

SOURCES_USED=..\sources.inc
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\base\ntos\config\cmalloc.c ===
/*++

Copyright (c) 20001 Microsoft Corporation

Module Name:

    cmalloc.c

Abstract:

    Provides routines for implementing the registry's own pool allocator.

Author:

    Dragos C. Sambotin (DragosS) 07-Feb-2001

Revision History:


--*/
#include "cmp.h"

#ifdef ALLOC_PRAGMA
#pragma alloc_text(INIT,CmpInitCmPrivateAlloc)
#pragma alloc_text(PAGE,CmpDestroyCmPrivateAlloc)
#pragma alloc_text(PAGE,CmpAllocateKeyControlBlock)
#pragma alloc_text(PAGE,CmpFreeKeyControlBlock)
#endif

typedef struct _CM_ALLOC_PAGE {
    ULONG       FreeCount;		// number of free kcbs
    ULONG       Reserved;		// alignment
#if DBG
	LIST_ENTRY	CmPageListEntry;// debug only to track pages we are using
#endif
    PVOID       AllocPage;      // crud allocations - this member is NOT USED
} CM_ALLOC_PAGE, *PCM_ALLOC_PAGE;

#define CM_KCB_ENTRY_SIZE   sizeof( CM_KEY_CONTROL_BLOCK )
#define CM_ALLOC_PAGES      (PAGE_SIZE / sizeof(CM_ALLOC_ENTRY))
#define CM_KCBS_PER_PAGE    ((PAGE_SIZE - FIELD_OFFSET(CM_ALLOC_PAGE,AllocPage)) / CM_KCB_ENTRY_SIZE)

#define KCB_TO_PAGE_ADDRESS( kcb ) (PVOID)(((ULONG_PTR)(kcb)) & ~(PAGE_SIZE - 1))
#define KCB_TO_ALLOC_PAGE( kcb ) ((PCM_ALLOC_PAGE)KCB_TO_PAGE_ADDRESS(kcb))

LIST_ENTRY          CmpFreeKCBListHead;   // list of free kcbs
BOOLEAN				CmpAllocInited = FALSE;

#if DBG
ULONG               CmpTotalKcbUsed   = 0;
ULONG               CmpTotalKcbFree   = 0;
LIST_ENTRY			CmPageListHead;
#endif

FAST_MUTEX			CmpAllocBucketLock;                // used to protect the bucket

#define LOCK_ALLOC_BUCKET() ExAcquireFastMutexUnsafe(&CmpAllocBucketLock)
#define UNLOCK_ALLOC_BUCKET() ExReleaseFastMutexUnsafe(&CmpAllocBucketLock)

VOID
CmpInitCmPrivateAlloc( )

/*++

Routine Description:

    Initialize the CmPrivate pool allocation module

Arguments:


Return Value:


--*/

{
    if( CmpAllocInited ) {
        //
        // already inited
        //
        return;
    }
    
    
#if DBG
    InitializeListHead(&(CmPageListHead));   
#endif //DBG

    InitializeListHead(&(CmpFreeKCBListHead));   

    //
	// init the bucket lock
	//
	ExInitializeFastMutex(&CmpAllocBucketLock);
	
	CmpAllocInited = TRUE;
}

VOID
CmpDestroyCmPrivateAlloc( )

/*++

Routine Description:

    Frees memory used byt the CmPrivate pool allocation module

Arguments:


Return Value:


--*/

{
    PAGED_CODE();
    
    if( !CmpAllocInited ) {
        return;
    }
    
#if DBG
	//
	// sanity
	//
	ASSERT( CmpTotalKcbUsed == 0 );
	ASSERT( CmpTotalKcbUsed == 0 );
	ASSERT( IsListEmpty(&(CmPageListHead)) == TRUE );
#endif

}


PCM_KEY_CONTROL_BLOCK
CmpAllocateKeyControlBlock( )

/*++

Routine Description:

    Allocates a kcb; first try from our own allocator.
    If it doesn't work (we have maxed out our number of allocs
    or private allocator is not inited)
    try from paged pool

Arguments:


Return Value:

    The  new kcb

--*/

{
    USHORT                  j;
    PCM_KEY_CONTROL_BLOCK   kcb = NULL;
    PVOID                   Page;
	PCM_ALLOC_PAGE			AllocPage;

    PAGED_CODE();
    
    if( !CmpAllocInited ) {
        //
        // not inited
        //
        goto AllocFromPool;
    }
    
	LOCK_ALLOC_BUCKET();

SearchFreeKcb:
    //
    // try to find a free one
    //
    if( IsListEmpty(&CmpFreeKCBListHead) == FALSE ) {
        //
        // found one
        //
        kcb = (PCM_KEY_CONTROL_BLOCK)RemoveHeadList(&CmpFreeKCBListHead);
        kcb = CONTAINING_RECORD(kcb,
                                CM_KEY_CONTROL_BLOCK,
                                FreeListEntry);

		AllocPage = (PCM_ALLOC_PAGE)KCB_TO_ALLOC_PAGE( kcb );

        ASSERT( AllocPage->FreeCount != 0 );

        AllocPage->FreeCount--;
        
		//
		// set when page was allocated
		//
		ASSERT( kcb->PrivateAlloc == 1);

#if DBG
        CmpTotalKcbUsed++;
        CmpTotalKcbFree--;
#endif //DBG
		
		UNLOCK_ALLOC_BUCKET();
        return kcb;
    }

    ASSERT( IsListEmpty(&CmpFreeKCBListHead) == TRUE );
    ASSERT( CmpTotalKcbFree == 0 );

    //
    // we need to allocate a new page as we ran out of free kcbs
    //
            
    //
    // allocate a new page and insert all kcbs in the freelist
    //
    AllocPage = (PCM_ALLOC_PAGE)ExAllocatePoolWithTag(PagedPool, PAGE_SIZE, CM_ALLOCATE_TAG|PROTECTED_POOL);
    if( AllocPage == NULL ) {
        //
        // we might be low on pool; maybe small pool chunks will work
        //
		UNLOCK_ALLOC_BUCKET();
        goto AllocFromPool;
    }

	//
	// set up the page
	//
    AllocPage->FreeCount = CM_KCBS_PER_PAGE;

#if DBG
    AllocPage->Reserved = 0;
    InsertTailList(
        &CmPageListHead,
        &(AllocPage->CmPageListEntry)
        );
#endif //DBG


    //
    // now the dirty job; insert all kcbs inside the page in the free list
    //
    for(j=0;j<CM_KCBS_PER_PAGE;j++) {
        kcb = (PCM_KEY_CONTROL_BLOCK)((PUCHAR)AllocPage + FIELD_OFFSET(CM_ALLOC_PAGE,AllocPage) + j*CM_KCB_ENTRY_SIZE);

		//
		// set it here; only once
		//
		kcb->PrivateAlloc = 1;
        
        InsertTailList(
            &CmpFreeKCBListHead,
            &(kcb->FreeListEntry)
            );
    }
            
#if DBG
	CmpTotalKcbFree += CM_KCBS_PER_PAGE;
#endif //DBG

    //
    // this time will find one for sure
    //
    goto SearchFreeKcb;

AllocFromPool:
    kcb = ExAllocatePoolWithTag(PagedPool,
                                sizeof(CM_KEY_CONTROL_BLOCK),
                                CM_KCB_TAG | PROTECTED_POOL);

    if( kcb != NULL ) {
        //
        // clear the private alloc flag
        //
        kcb->PrivateAlloc = 0;
    }

    return kcb;
}


VOID
CmpFreeKeyControlBlock( PCM_KEY_CONTROL_BLOCK kcb )

/*++

Routine Description:

    Frees a kcb; if it's allocated from our own pool put it back in the free list.
    If it's allocated from general pool, just free it.

Arguments:

    kcb to free

Return Value:


--*/
{
    USHORT			j;
	PCM_ALLOC_PAGE	AllocPage;

    PAGED_CODE();

    ASSERT_KEYBODY_LIST_EMPTY(kcb);

    if( !kcb->PrivateAlloc ) {
        //
        // just free it and be done with it
        //
        ExFreePoolWithTag(kcb, CM_KCB_TAG | PROTECTED_POOL);
        return;
    }

	LOCK_ALLOC_BUCKET();

#if DBG
    CmpTotalKcbFree ++;
    CmpTotalKcbUsed --;
#endif

    //
    // add kcb to freelist
    //
    InsertTailList(
        &CmpFreeKCBListHead,
        &(kcb->FreeListEntry)
        );

	//
	// get the page
	//
	AllocPage = (PCM_ALLOC_PAGE)KCB_TO_ALLOC_PAGE( kcb );

    //
	// not all are free
	//
	ASSERT( AllocPage->FreeCount != CM_KCBS_PER_PAGE);

	AllocPage->FreeCount++;

    if( AllocPage->FreeCount == CM_KCBS_PER_PAGE ) {
        //
        // entire page is free; let it go
        //
        //
        // first; iterate through the free kcb list and remove all kcbs inside this page
        //
        for(j=0;j<CM_KCBS_PER_PAGE;j++) {
            kcb = (PCM_KEY_CONTROL_BLOCK)((PUCHAR)AllocPage + FIELD_OFFSET(CM_ALLOC_PAGE,AllocPage) + j*CM_KCB_ENTRY_SIZE);
        
            RemoveEntryList(&(kcb->FreeListEntry));
        }
#if DBG
        CmpTotalKcbFree -= CM_KCBS_PER_PAGE;
		RemoveEntryList(&(AllocPage->CmPageListEntry));
#endif
        ExFreePoolWithTag(AllocPage, CM_ALLOCATE_TAG|PROTECTED_POOL);
    }

	UNLOCK_ALLOC_BUCKET();

}
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\base\ntos\cache\vacbsup.c ===
/*++

Copyright (c) 1990  Microsoft Corporation

Module Name:

    vacbsup.c

Abstract:

    This module implements the support routines for the Virtual Address
    Control Block support for the Cache Manager.  These routines are used
    to manage a large number of relatively small address windows to map
    file data for all forms of cache access.

Author:

    Tom Miller      [TomM]      8-Feb-1992

Revision History:

--*/

#include "cc.h"
#include "ex.h"

//
//  Define our debug constant
//

#define me 0x000000040

//
//  Internal Support Routines.
//

VOID
CcUnmapVacb (
    IN PVACB Vacb,
    IN PSHARED_CACHE_MAP SharedCacheMap,
    IN BOOLEAN UnmapBehind
    );

PVACB
CcGetVacbMiss (
    IN PSHARED_CACHE_MAP SharedCacheMap,
    IN LARGE_INTEGER FileOffset,
    IN OUT PKIRQL OldIrql
    );

VOID
CcCalculateVacbLevelLockCount (
    IN PSHARED_CACHE_MAP SharedCacheMap,
    IN PVACB *VacbArray,
    IN ULONG Level
    );

PVACB
CcGetVacbLargeOffset (
    IN PSHARED_CACHE_MAP SharedCacheMap,
    IN LONGLONG FileOffset
    );

VOID
CcSetVacbLargeOffset (
    IN PSHARED_CACHE_MAP SharedCacheMap,
    IN LONGLONG FileOffset,
    IN PVACB Vacb
    );

#ifdef ALLOC_PRAGMA
#pragma alloc_text(INIT, CcInitializeVacbs)
#endif

//
//  Define a few macros for manipulating the Vacb array.
//

#define GetVacb(SCM,OFF) (                                                                \
    ((SCM)->SectionSize.QuadPart > VACB_SIZE_OF_FIRST_LEVEL) ?                            \
    CcGetVacbLargeOffset((SCM),(OFF).QuadPart) :                                          \
    (SCM)->Vacbs[(OFF).LowPart >> VACB_OFFSET_SHIFT]                                      \
)

_inline
VOID
SetVacb (
    IN PSHARED_CACHE_MAP SharedCacheMap,
    IN LARGE_INTEGER Offset,
    IN PVACB Vacb
    )
{
    if (SharedCacheMap->SectionSize.QuadPart > VACB_SIZE_OF_FIRST_LEVEL) {
        CcSetVacbLargeOffset(SharedCacheMap, Offset.QuadPart, Vacb);
#ifdef VACB_DBG
        ASSERT(Vacb >= VACB_SPECIAL_FIRST_VALID || CcGetVacbLargeOffset(SharedCacheMap, Offset.QuadPart) == Vacb);
#endif // VACB_DBG
    } else if (Vacb < VACB_SPECIAL_FIRST_VALID) {
        SharedCacheMap->Vacbs[Offset.LowPart >> VACB_OFFSET_SHIFT] = Vacb;
    }
#ifdef VACB_DBG
    //
    //  Note, we need a new field if we turn this check on again - ReservedForAlignment
    //  has been stolen for other purposes.
    //

    if (Vacb < VACB_SPECIAL_FIRST_VALID) {
        if (Vacb != NULL) {
            SharedCacheMap->ReservedForAlignment++;
        } else {
            SharedCacheMap->ReservedForAlignment--;
        }
    }
    ASSERT((SharedCacheMap->SectionSize.QuadPart <= VACB_SIZE_OF_FIRST_LEVEL) ||
           (SharedCacheMap->ReservedForAlignment == 0) ||
           IsVacbLevelReferenced( SharedCacheMap, SharedCacheMap->Vacbs, 1 ));
#endif // VACB_DBG
}

//
//  Define the macro for referencing the multilevel Vacb array.
//

_inline
VOID
ReferenceVacbLevel (
    IN PSHARED_CACHE_MAP SharedCacheMap,
    IN PVACB *VacbArray,
    IN ULONG Level,
    IN LONG Amount,
    IN LOGICAL Special
    )
{
    PVACB_LEVEL_REFERENCE VacbReference = VacbLevelReference( SharedCacheMap, VacbArray, Level );

    ASSERT( Amount > 0 ||
            (!Special && VacbReference->Reference >= (0 - Amount)) ||
            ( Special && VacbReference->SpecialReference >= (0 - Amount)));

    if (Special) {
        VacbReference->SpecialReference += Amount;
    } else {
        VacbReference->Reference += Amount;
    }

#ifdef VACB_DBG
    //
    //  For debugging purposes, we can assert that the regular reference count
    //  corresponds to the population of the level.
    //

    {
        LONG Current = VacbReference->Reference;
        CcCalculateVacbLevelLockCount( SharedCacheMap, VacbArray, Level );
        ASSERT( Current == VacbReference->Reference );
    }
#endif // VACB_DBG
}

//
//  Define the macros for moving the VACBs on the LRU list
//

#define CcMoveVacbToReuseFree(V)        RemoveEntryList( &(V)->LruList );                 \
                                        InsertHeadList( &CcVacbFreeList, &(V)->LruList );

#define CcMoveVacbToReuseTail(V)        RemoveEntryList( &(V)->LruList );                 \
                                        InsertTailList( &CcVacbLru, &(V)->LruList );

//
//  If the HighPart is nonzero, then we will go to a multi-level structure anyway, which is
//  most easily triggered by returning MAXULONG.
//

#define SizeOfVacbArray(LSZ) (                                                            \
    ((LSZ).HighPart != 0) ? MAXULONG :                                                    \
    ((LSZ).LowPart > (PREALLOCATED_VACBS * VACB_MAPPING_GRANULARITY) ?                    \
     (((LSZ).LowPart >> VACB_OFFSET_SHIFT) * sizeof(PVACB)) :                             \
     (PREALLOCATED_VACBS * sizeof(PVACB)))                                                \
)

#define CheckedDec(N) {  \
    ASSERT((N) != 0);    \
    (N) -= 1;            \
}

#ifdef ALLOC_PRAGMA
#pragma alloc_text(INIT,CcInitializeVacbs)
#pragma alloc_text(PAGE,CcCreateVacbArray)
#pragma alloc_text(PAGE,CcUnmapVacb)
#endif


VOID
CcInitializeVacbs(
)

/*++

Routine Description:

    This routine must be called during Cache Manager initialization to
    initialize the Virtual Address Control Block structures.

Arguments:

    None.

Return Value:

    None.

--*/

{
    SIZE_T VacbBytes;
    PVACB NextVacb;

    CcNumberVacbs = (MmSizeOfSystemCacheInPages >> (VACB_OFFSET_SHIFT - PAGE_SHIFT)) - 2;
    VacbBytes = CcNumberVacbs * sizeof(VACB);

    CcVacbs = (PVACB) ExAllocatePoolWithTag( NonPagedPool, VacbBytes, 'aVcC' );

    if (CcVacbs != NULL) {
        CcBeyondVacbs = (PVACB)((PCHAR)CcVacbs + VacbBytes);
        RtlZeroMemory( CcVacbs, VacbBytes );

        InitializeListHead( &CcVacbLru );
        InitializeListHead( &CcVacbFreeList );

        for (NextVacb = CcVacbs; NextVacb < CcBeyondVacbs; NextVacb++) {

            InsertTailList( &CcVacbFreeList, &NextVacb->LruList );
        }
    }
}


PVOID
CcGetVirtualAddressIfMapped (
    IN PSHARED_CACHE_MAP SharedCacheMap,
    IN LONGLONG FileOffset,
    OUT PVACB *Vacb,
    OUT PULONG ReceivedLength
    )

/*++

Routine Description:

    This routine returns a virtual address for the specified FileOffset,
    iff it is mapped.  Otherwise, it informs the caller that the specified
    virtual address was not mapped.  In the latter case, it still returns
    a ReceivedLength, which may be used to advance to the next view boundary.

Arguments:

    SharedCacheMap - Supplies a pointer to the Shared Cache Map for the file.

    FileOffset - Supplies the desired FileOffset within the file.

    Vach - Returns a Vacb pointer which must be supplied later to free
           this virtual address, or NULL if not mapped.

    ReceivedLength - Returns the number of bytes to the next view boundary,
                     whether the desired file offset is mapped or not.

Return Value:

    The virtual address at which the desired data is mapped, or NULL if it
    is not mapped.

--*/

{
    KIRQL OldIrql;
    ULONG VacbOffset = (ULONG)FileOffset & (VACB_MAPPING_GRANULARITY - 1);
    PVOID Value = NULL;

    ASSERT(KeGetCurrentIrql() < DISPATCH_LEVEL);

    //
    //  Generate ReceivedLength return right away.
    //

    *ReceivedLength = VACB_MAPPING_GRANULARITY - VacbOffset;

    //
    //  Modifiers of VacbArray hold the VacbLock to synchronize access.  The
    //  VacbLock must be released during the call to CcUnmapVacb() because it
    //  contains a call to MmUnmapViewInSystemCache().  It is this MM call that
    //  is responsible for copying the dirty bit from the PTEs back to the PFN.
    //
    //  During this time the worker thread may call CcFlushCache() on the
    //  Vacb being unmapped.  CcGetVirtualAddressIfMapped() is used to determine
    //  if the Vacb's memory is mapped and will correctly report that the address
    //  is not mapped so CcFlushCache() will proceed to call MmFlushSection().
    //
    //  This is where we have synchronization problems.  If MmUnmapViewInSystemCache()
    //  is not finished propogating the dirty PTE information back to the
    //  PFN when MmFlushSection() is run the MM doesn't thing there is anything
    //  to flush.
    //
    //  Later this results in noncached I/O returning different page data than
    //  cached I/O.
    //
    //  The solution to this problem is to use a multiple reader/single writer
    //  EX to delay CcGetVirtualAddressIfMapped() until any existing calls to
    //  MmUnmapViewInSystemCache() via CcUnmapVacb() complete.
    //

    ExAcquirePushLockExclusive( &SharedCacheMap->VacbPushLock );

    //
    //  Acquire the Vacb lock to see if the desired offset is already mapped.
    //

    CcAcquireVacbLock( &OldIrql );

    ASSERT( FileOffset <= SharedCacheMap->SectionSize.QuadPart );

    if ((*Vacb = GetVacb( SharedCacheMap, *(PLARGE_INTEGER)&FileOffset )) != NULL) {

        if ((*Vacb)->Overlay.ActiveCount == 0) {
            SharedCacheMap->VacbActiveCount += 1;
        }

        (*Vacb)->Overlay.ActiveCount += 1;

        //
        //  Move this range away from the front to avoid wasting cycles
        //  looking at it for reuse.
        //

        CcMoveVacbToReuseTail( *Vacb );

        Value = (PVOID)((PCHAR)(*Vacb)->BaseAddress + VacbOffset);
    }

    CcReleaseVacbLock( OldIrql );
    
    ExReleasePushLockExclusive( &SharedCacheMap->VacbPushLock );
    
    return Value;
}


PVOID
CcGetVirtualAddress (
    IN PSHARED_CACHE_MAP SharedCacheMap,
    IN LARGE_INTEGER FileOffset,
    OUT PVACB *Vacb,
    IN OUT PULONG ReceivedLength
    )

/*++

Routine Description:

    This is the main routine for Vacb management.  It may be called to acquire
    a virtual address for a given file offset.  If the desired file offset is
    already mapped, this routine does very little work before returning with
    the desired virtual address and Vacb pointer (which must be supplied to
    free the mapping).

    If the desired virtual address is not currently mapped, then this routine
    claims a Vacb from the tail of the Vacb LRU to reuse its mapping.  This Vacb
    is then unmapped if necessary (normally not required), and mapped to the
    desired address.

Arguments:

    SharedCacheMap - Supplies a pointer to the Shared Cache Map for the file.

    FileOffset - Supplies the desired FileOffset within the file.

    Vacb - Returns a Vacb pointer which must be supplied later to free
           this virtual address.

    ReceivedLength - Returns the number of bytes which are contiguously
                     mapped starting at the virtual address returned.

Return Value:

    The virtual address at which the desired data is mapped.

--*/

{
    KIRQL OldIrql;
    PVACB TempVacb;
    ULONG VacbOffset = FileOffset.LowPart & (VACB_MAPPING_GRANULARITY - 1);

    ASSERT(KeGetCurrentIrql() < DISPATCH_LEVEL);

    //
    //  Acquire the shared lock on the VacbArray because CcGetVacbMiss()
    //  might unmap a Vacb.  See CcGetVirtualAddressIfMapped() for more
    //  details.
    //
            
    ExAcquirePushLockShared( &SharedCacheMap->VacbPushLock );

    //
    //  Acquire the Vacb lock to see if the desired offset is already mapped.
    //

    CcAcquireVacbLock( &OldIrql );

    ASSERT( FileOffset.QuadPart <= SharedCacheMap->SectionSize.QuadPart );

    if ((TempVacb = GetVacb( SharedCacheMap, FileOffset )) == NULL) {

        TempVacb = CcGetVacbMiss( SharedCacheMap, FileOffset, &OldIrql );

    } else {

        if (TempVacb->Overlay.ActiveCount == 0) {
            SharedCacheMap->VacbActiveCount += 1;
        }

        TempVacb->Overlay.ActiveCount += 1;
    }

    //
    //  Move this range away from the front to avoid wasting cycles
    //  looking at it for reuse.
    //

    CcMoveVacbToReuseTail( TempVacb );

    CcReleaseVacbLock( OldIrql );

    ExReleasePushLockShared( &SharedCacheMap->VacbPushLock );
    
    //
    //  Now form all outputs.
    //

    *Vacb = TempVacb;
    *ReceivedLength = VACB_MAPPING_GRANULARITY - VacbOffset;

    ASSERT(KeGetCurrentIrql() < DISPATCH_LEVEL);

    //
    //  PREfix wants to know this cannot be NULL, otherwise it will complain
    //  about users of this function.
    //

    ASSERT( TempVacb->BaseAddress != NULL );

    return (PVOID)((PCHAR)TempVacb->BaseAddress + VacbOffset);
}


PVACB
CcGetVacbMiss (
    IN PSHARED_CACHE_MAP SharedCacheMap,
    IN LARGE_INTEGER FileOffset,
    IN OUT PKIRQL OldIrql
    )

/*++

Routine Description:

    This is the main routine for Vacb management.  It may be called to acquire
    a virtual address for a given file offset.  If the desired file offset is
    already mapped, this routine does very little work before returning with
    the desired virtual address and Vacb pointer (which must be supplied to
    free the mapping).

    If the desired virtual address is not currently mapped, then this routine
    claims a Vacb from the tail of the Vacb LRU to reuse its mapping.  This Vacb
    is then unmapped if necessary (normally not required), and mapped to the
    desired address.

Arguments:

    SharedCacheMap - Supplies a pointer to the Shared Cache Map for the file.

    FileOffset - Supplies the desired FileOffset within the file.

    OldIrql - Pointer to the OldIrql variable in the caller

Return Value:

    The Vacb.

--*/

{
    PSHARED_CACHE_MAP OldSharedCacheMap;
    PVACB Vacb, TempVacb;
    LARGE_INTEGER MappedLength;
    LARGE_INTEGER NormalOffset;
    NTSTATUS Status;
    ULONG ActivePage;
    ULONG PageIsDirty;
    PVACB ActiveVacb = NULL;
    ULONG VacbOffset = FileOffset.LowPart & (VACB_MAPPING_GRANULARITY - 1);

    NormalOffset = FileOffset;
    NormalOffset.LowPart -= VacbOffset;

    //
    //  For files that are not open for random access, we assume sequential
    //  access and periodically unmap unused views behind us as we go, to
    //  keep from hogging memory.
    //
    //  We used to only do this for pure FO_SEQUENTIAL_ONLY access.  The
    //  sequential flags still has an effect (to put the pages at the front
    //  of the standby lists) but we intend for the majority of the file
    //  cache to live on the standby and are willing to take transition
    //  faults to bring it back.  Granted, this exacerbates the problem that
    //  it is hard to figure out how big the filecache really is since even
    //  less of it is going to be mapped at any given time.  It may also
    //  promote the synchronization bottlenecks in view mapping (MmPfnLock)
    //  to the forefront when significant view thrashing occurs.
    //
    //  This isn't as bad as it seems.  When we see access take a view miss,
    //  it is really likely that it is a result of sequential access.  As long
    //  as the pages go onto the back of the standby, they'll live for a while.
    //  The problem we're dealing with here is that the cache can be filled at
    //  high speed, but the working set manager can't possibly trim it as fast,
    //  intelligently, while we have a pretty good guess where the candidate
    //  pages should come from.  We can't let the filecache size make large
    //  excursions, or we'll kick out a lot of valuable pages in the process.
    //

    if (!FlagOn(SharedCacheMap->Flags, RANDOM_ACCESS_SEEN) &&
        ((NormalOffset.LowPart & (SEQUENTIAL_MAP_LIMIT - 1)) == 0) &&
        (NormalOffset.QuadPart >= (SEQUENTIAL_MAP_LIMIT * 2))) {

        //
        //  Use MappedLength as a scratch variable to form the offset
        //  to start unmapping.  We are not synchronized with these past
        //  views, so it is possible that CcUnmapVacbArray will kick out
        //  early when it sees an active view.  That is why we go back
        //  twice the distance, and effectively try to unmap everything
        //  twice.  The second time should normally do it.  If the file
        //  is truly sequential only, then the only collision expected
        //  might be the previous view if we are being called from readahead,
        //  or there is a small chance that we can collide with the
        //  Lazy Writer during the small window where he briefly maps
        //  the file to push out the dirty bits.
        //

        CcReleaseVacbLock( *OldIrql );
        MappedLength.QuadPart = NormalOffset.QuadPart - (SEQUENTIAL_MAP_LIMIT * 2);
        CcUnmapVacbArray( SharedCacheMap, &MappedLength, (SEQUENTIAL_MAP_LIMIT * 2), TRUE );
        CcAcquireVacbLock( OldIrql );
    }

    //
    //  If there is a free view, move it to the LRU and we're done.
    //

    if (!IsListEmpty(&CcVacbFreeList)) {
    
        Vacb = CONTAINING_RECORD( CcVacbFreeList.Flink, VACB, LruList );
        CcMoveVacbToReuseTail( Vacb );

    } else {

        //
        //  Scan from the front of the lru for the next victim Vacb
        //

        Vacb = CONTAINING_RECORD( CcVacbLru.Flink, VACB, LruList );

        while (TRUE) {

            //
            //  If this guy is not active, break out and use him.  Also, if
            //  it is an Active Vacb, nuke it now, because the reader may be idle and we
            //  want to clean up.
            //

            OldSharedCacheMap = Vacb->SharedCacheMap;
            if ((Vacb->Overlay.ActiveCount == 0) ||
                ((ActiveVacb == NULL) &&
                 (OldSharedCacheMap != NULL) &&
                 (OldSharedCacheMap->ActiveVacb == Vacb))) {

                //
                //  The normal case is that the Vacb is no longer mapped
                //  and we can just get out and use it, however, here we
                //  handle the case where it is mapped.
                //

                if (Vacb->BaseAddress != NULL) {


                    //
                    //  If this Vacb is active, it must be the ActiveVacb.
                    //

                    if (Vacb->Overlay.ActiveCount != 0) {

                        //
                        //  Get the active Vacb.
                        //

                        GetActiveVacbAtDpcLevel( Vacb->SharedCacheMap, ActiveVacb, ActivePage, PageIsDirty );

                    //
                    //  Otherwise we will break out and use this Vacb.  If it
                    //  is still mapped we can now safely increment the open
                    //  count.
                    //

                    } else {

                        //
                        //  Note that if the SharedCacheMap is currently
                        //  being deleted, we need to skip over
                        //  it, otherwise we will become the second
                        //  deleter.  CcDeleteSharedCacheMap clears the
                        //  pointer in the SectionObjectPointer.
                        //

                        CcAcquireMasterLockAtDpcLevel();
                        if (Vacb->SharedCacheMap->FileObject->SectionObjectPointer->SharedCacheMap ==
                            Vacb->SharedCacheMap) {

                            CcIncrementOpenCount( Vacb->SharedCacheMap, 'mvGS' );
                            CcReleaseMasterLockFromDpcLevel();
                            break;
                        }
                        CcReleaseMasterLockFromDpcLevel();
                    }
                } else {
                    break;
                }
            }

            //
            //  Advance to the next guy if we haven't scanned
            //  the entire list.
            //

            if (Vacb->LruList.Flink != &CcVacbLru) {

                Vacb = CONTAINING_RECORD( Vacb->LruList.Flink, VACB, LruList );

            } else {

                CcReleaseVacbLock( *OldIrql );

                //
                //  If we found an active vacb, then free it and go back and
                //  try again.  Else it's time to bail.
                //

                if (ActiveVacb != NULL) {
                    CcFreeActiveVacb( ActiveVacb->SharedCacheMap, ActiveVacb, ActivePage, PageIsDirty );
                    ActiveVacb = NULL;

                    //
                    //  Reacquire spinlocks to loop back and position ourselves at the head
                    //  of the LRU for the next pass.
                    //

                    CcAcquireVacbLock( OldIrql );

                    Vacb = CONTAINING_RECORD( CcVacbLru.Flink, VACB, LruList );

                } else {

                    ExReleasePushLockShared( &SharedCacheMap->VacbPushLock );

                    ExRaiseStatus( STATUS_INSUFFICIENT_RESOURCES );
                }
            }
        }
    }

    //
    //  Unlink it from the other SharedCacheMap, so the other
    //  guy will not try to use it when we free the spin lock.
    //

    if (Vacb->SharedCacheMap != NULL) {

        OldSharedCacheMap = Vacb->SharedCacheMap;
        SetVacb( OldSharedCacheMap, Vacb->Overlay.FileOffset, NULL );
        Vacb->SharedCacheMap = NULL;
    }

    //
    //  Mark it in use so no one else will muck with it after
    //  we release the spin lock.
    //

    Vacb->Overlay.ActiveCount = 1;
    SharedCacheMap->VacbActiveCount += 1;

    CcReleaseVacbLock( *OldIrql );

    //
    //  If the Vacb is already mapped, then unmap it.
    //

    if (Vacb->BaseAddress != NULL) {

        //
        //  Check to see if we need to drain the zone.
        //

        CcDrainVacbLevelZone();

        CcUnmapVacb( Vacb, OldSharedCacheMap, FALSE );

        //
        //  Now we can decrement the open count as we normally
        //  do, possibly deleting the guy.
        //

        CcAcquireMasterLock( OldIrql );

        //
        //  Now release our open count.
        //

        CcDecrementOpenCount( OldSharedCacheMap, 'mvGF' );

        if ((OldSharedCacheMap->OpenCount == 0) &&
            !FlagOn(OldSharedCacheMap->Flags, WRITE_QUEUED) &&
            (OldSharedCacheMap->DirtyPages == 0)) {

            //
            //  Move to the dirty list.
            //

            RemoveEntryList( &OldSharedCacheMap->SharedCacheMapLinks );
            InsertTailList( &CcDirtySharedCacheMapList.SharedCacheMapLinks,
                            &OldSharedCacheMap->SharedCacheMapLinks );

            //
            //  Make sure the Lazy Writer will wake up, because we
            //  want him to delete this SharedCacheMap.
            //

            LazyWriter.OtherWork = TRUE;
            if (!LazyWriter.ScanActive) {
                CcScheduleLazyWriteScan( FALSE );
            }
        }

        CcReleaseMasterLock( *OldIrql );
    }

    //
    //  Use try-finally to return this guy to the list if we get an
    //  exception.
    //

    try {

        //
        //  Assume we are mapping to the end of the section, but
        //  reduce to our normal mapping granularity if the section
        //  is too large.
        //

        MappedLength.QuadPart = SharedCacheMap->SectionSize.QuadPart - NormalOffset.QuadPart;

        if ((MappedLength.HighPart != 0) ||
            (MappedLength.LowPart > VACB_MAPPING_GRANULARITY)) {

            MappedLength.LowPart = VACB_MAPPING_GRANULARITY;
        }

        //
        //  Now map this one in the system cache.
        //

        DebugTrace( 0, mm, "MmMapViewInSystemCache:\n", 0 );
        DebugTrace( 0, mm, "    Section = %08lx\n", SharedCacheMap->Section );
        DebugTrace2(0, mm, "    Offset = %08lx, %08lx\n",
                                NormalOffset.LowPart,
                                NormalOffset.HighPart );
        DebugTrace( 0, mm, "    ViewSize = %08lx\n", MappedLength.LowPart );

        Status =
          MmMapViewInSystemCache( SharedCacheMap->Section,
                                  &Vacb->BaseAddress,
                                  &NormalOffset,
                                  &MappedLength.LowPart );

        DebugTrace( 0, mm, "    <BaseAddress = %08lx\n", Vacb->BaseAddress );
        DebugTrace( 0, mm, "    <ViewSize = %08lx\n", MappedLength.LowPart );

        if (!NT_SUCCESS( Status )) {

            DebugTrace( 0, 0, "Error from Map, Status = %08lx\n", Status );

            ExReleasePushLockShared( &SharedCacheMap->VacbPushLock );

            ExRaiseStatus( FsRtlNormalizeNtstatus( Status,
                                                   STATUS_UNEXPECTED_MM_MAP_ERROR ));
        }

    } finally {

        //
        //  Take this opportunity to free the active vacb.
        //

        if (ActiveVacb != NULL) {

            CcFreeActiveVacb( ActiveVacb->SharedCacheMap, ActiveVacb, ActivePage, PageIsDirty );
        }

        //
        //  On abnormal termination, get this guy back in the list.
        //

        if (AbnormalTermination()) {

            CcAcquireVacbLock( OldIrql );

            //
            //  This is like the unlucky case below.  Just back out the stuff
            //  we did and put the guy at the tail of the list.  Basically
            //  only the Map should fail, and we clear BaseAddress accordingly.
            //

            Vacb->BaseAddress = NULL;

            CheckedDec(Vacb->Overlay.ActiveCount);
            CheckedDec(SharedCacheMap->VacbActiveCount);

            //
            //  If there is someone waiting for this count to go to zero,
            //  wake them here.
            //

            if (SharedCacheMap->WaitOnActiveCount != NULL) {
                KeSetEvent( SharedCacheMap->WaitOnActiveCount, 0, FALSE );
            }

            CcReleaseVacbLock( *OldIrql );
        }
    }

    //
    //  Make sure the zone contains the worst case number of entries.
    //

    if (SharedCacheMap->SectionSize.QuadPart > VACB_SIZE_OF_FIRST_LEVEL) {

        //
        //  Raise if we cannot preallocate enough buffers.
        //

        if (!CcPrefillVacbLevelZone( CcMaxVacbLevelsSeen - 1,
                                     OldIrql,
                                     FlagOn(SharedCacheMap->Flags, MODIFIED_WRITE_DISABLED) )) {

            ExReleasePushLockShared( &SharedCacheMap->VacbPushLock );

            ExRaiseStatus( STATUS_INSUFFICIENT_RESOURCES );
        }

    } else {

        CcAcquireVacbLock( OldIrql );
    }

    //
    //  Finish filling in the Vacb, and store its address in the array in
    //  the Shared Cache Map.  (We have to rewrite the ActiveCount
    //  since it is overlaid.)  To do this we must reacquire the
    //  spin lock one more time.  Note we have to check for the unusual
    //  case that someone beat us to mapping this view, since we had to
    //  drop the spin lock.
    //

    if ((TempVacb = GetVacb( SharedCacheMap, NormalOffset )) == NULL) {

        Vacb->SharedCacheMap = SharedCacheMap;
        Vacb->Overlay.FileOffset = NormalOffset;
        Vacb->Overlay.ActiveCount = 1;

        SetVacb( SharedCacheMap, NormalOffset, Vacb );

    //
    //  This is the unlucky case where we collided with someone else
    //  trying to map the same view.  He can get in because we dropped
    //  the spin lock above.  Rather than allocating events and making
    //  someone wait, considering this case is fairly unlikely, we just
    //  dump this one at the head of the LRU and use the one from the
    //  guy who beat us.
    //

    } else {

        //
        //  Now we have to increment all of the counts for the one that
        //  was already there, then ditch the one we had.
        //

        if (TempVacb->Overlay.ActiveCount == 0) {
            SharedCacheMap->VacbActiveCount += 1;
        }

        TempVacb->Overlay.ActiveCount += 1;

        //
        //  Now unmap the one we mapped and proceed with the other Vacb.
        //  On this path we have to release the spinlock to do the unmap,
        //  and then reacquire the spinlock before cleaning up.
        //

        CcReleaseVacbLock( *OldIrql );

        CcUnmapVacb( Vacb, SharedCacheMap, FALSE );

        CcAcquireVacbLock( OldIrql );
        CheckedDec(Vacb->Overlay.ActiveCount);
        CheckedDec(SharedCacheMap->VacbActiveCount);
        Vacb->SharedCacheMap = NULL;

        CcMoveVacbToReuseFree( Vacb );

        Vacb = TempVacb;
    }

    return Vacb;
}


VOID
FASTCALL
CcFreeVirtualAddress (
    IN PVACB Vacb
    )

/*++

Routine Description:

    This routine must be called once for each call to CcGetVirtualAddress
    to free that virtual address.

Arguments:

    Vacb - Supplies the Vacb which was returned from CcGetVirtualAddress.

Return Value:

    None.

--*/

{
    KIRQL OldIrql;
    PSHARED_CACHE_MAP SharedCacheMap = Vacb->SharedCacheMap;

    CcAcquireVacbLock( &OldIrql );

    CheckedDec(Vacb->Overlay.ActiveCount);

    //
    //  If the count goes to zero, then we want to decrement the global
    //  Active count.
    //

    if (Vacb->Overlay.ActiveCount == 0) {

        //
        //  If the SharedCacheMap address is not NULL, then this one is
        //  in use by a shared cache map, and we have to decrement his
        //  count and see if anyone is waiting.
        //

        if (SharedCacheMap != NULL) {

            CheckedDec(SharedCacheMap->VacbActiveCount);

            //
            //  If there is someone waiting for this count to go to zero,
            //  wake them here.
            //

            if (SharedCacheMap->WaitOnActiveCount != NULL) {
                KeSetEvent( SharedCacheMap->WaitOnActiveCount, 0, FALSE );
            }

            //
            //  Go to the back of the LRU to save this range for a bit
            //

            CcMoveVacbToReuseTail( Vacb );

        } else {

            //
            //  This range is no longer referenced, so make it available
            //

            ASSERT( Vacb->BaseAddress == NULL );

            CcMoveVacbToReuseFree( Vacb );
        }

    } else {

        //
        //  This range is still in use, so move it away from the front
        //  so that it doesn't consume cycles being checked.
        //

        CcMoveVacbToReuseTail( Vacb );
    }

    CcReleaseVacbLock( OldIrql );
}


VOID
CcReferenceFileOffset (
    IN PSHARED_CACHE_MAP SharedCacheMap,
    IN LARGE_INTEGER FileOffset
    )

/*++

Routine Description:

    This is a special form of reference that insures that the multi-level
    Vacb structures are expanded to cover a given file offset.

Arguments:

    SharedCacheMap - Supplies a pointer to the Shared Cache Map for the file.

    FileOffset - Supplies the desired FileOffset within the file.

Return Value:

    None

--*/

{
    KIRQL OldIrql;

    ASSERT(KeGetCurrentIrql() < DISPATCH_LEVEL);

    //
    //  This operation only has meaning if the Vacbs are in the multilevel form.
    //

    if (SharedCacheMap->SectionSize.QuadPart > VACB_SIZE_OF_FIRST_LEVEL) {

        //
        //  Prefill the level zone so that we can expand the tree if required.
        //

        if (!CcPrefillVacbLevelZone( CcMaxVacbLevelsSeen - 1,
                                     &OldIrql,
                                     FlagOn(SharedCacheMap->Flags, MODIFIED_WRITE_DISABLED) )) {

            ExRaiseStatus( STATUS_INSUFFICIENT_RESOURCES );
        }

        ASSERT( FileOffset.QuadPart <= SharedCacheMap->SectionSize.QuadPart );

        SetVacb( SharedCacheMap, FileOffset, VACB_SPECIAL_REFERENCE );

        CcReleaseVacbLock( OldIrql );
    }

    ASSERT(KeGetCurrentIrql() < DISPATCH_LEVEL);

    return;
}


VOID
CcDereferenceFileOffset (
    IN PSHARED_CACHE_MAP SharedCacheMap,
    IN LARGE_INTEGER FileOffset
    )

/*++

Routine Description:

    This routine must be called once for each call to CcReferenceFileOffset
    to remove the reference.

Arguments:

    SharedCacheMap - Supplies a pointer to the Shared Cache Map for the file.

    FileOffset - Supplies the desired FileOffset within the file.

Return Value:

    None

--*/

{
    KIRQL OldIrql;

    ASSERT(KeGetCurrentIrql() < DISPATCH_LEVEL);

    //
    //  This operation only has meaning if the Vacbs are in the multilevel form.
    //

    if (SharedCacheMap->SectionSize.QuadPart > VACB_SIZE_OF_FIRST_LEVEL) {

        //
        //  Acquire the Vacb lock to synchronize the dereference.
        //

        CcAcquireVacbLock( &OldIrql );

        ASSERT( FileOffset.QuadPart <= SharedCacheMap->SectionSize.QuadPart );

        SetVacb( SharedCacheMap, FileOffset, VACB_SPECIAL_DEREFERENCE );

        CcReleaseVacbLock( OldIrql );
    }

    ASSERT(KeGetCurrentIrql() < DISPATCH_LEVEL);

    return;
}


VOID
CcWaitOnActiveCount (
    IN PSHARED_CACHE_MAP SharedCacheMap
    )

/*++

Routine Description:

    This routine may be called to wait for outstanding mappings for
    a given SharedCacheMap to go inactive.  It is intended to be called
    from CcUninitializeCacheMap, which is called by the file systems
    during cleanup processing.  In that case this routine only has to
    wait if the user closed a handle without waiting for all I/Os on the
    handle to complete.

    This routine returns each time the active count is decremented.  The
    caller must recheck his wait conditions on return, either waiting for
    the ActiveCount to go to 0, or for specific views to go inactive
    (CcPurgeCacheSection case).

Arguments:

    SharedCacheMap - Supplies the Shared Cache Map on whose VacbActiveCount
                     we wish to wait.

Return Value:

    None.

--*/

{
    KIRQL OldIrql;
    PKEVENT Event;

    //
    //  In the unusual case that we get a cleanup while I/O is still going
    //  on, we can wait here.  The caller must test the count for nonzero
    //  before calling this routine.
    //
    //  Since we are being called from cleanup, we cannot afford to
    //  fail here.
    //

    CcAcquireVacbLock( &OldIrql );

    //
    //  It is possible that the count went to zero before we acquired the
    //  spinlock, so we must handle two cases here.
    //

    if (SharedCacheMap->VacbActiveCount != 0) {

        Event = SharedCacheMap->WaitOnActiveCount;

        if (Event == NULL) {

            //
            //  Take the event.  We avoid dispatcher lock overhead for
            //  every single zero transition by only picking up the event
            //  when we actually need it.
            //

            Event = &SharedCacheMap->Event;

            KeInitializeEvent( Event,
                               NotificationEvent,
                               FALSE );

            SharedCacheMap->WaitOnActiveCount = Event;
        }
        else {
            KeClearEvent( Event );
        }

        CcReleaseVacbLock( OldIrql );

        KeWaitForSingleObject( Event,
                               Executive,
                               KernelMode,
                               FALSE,
                               (PLARGE_INTEGER)NULL);
    } else {

        CcReleaseVacbLock( OldIrql );
    }
}


//
//  Internal Support Routine.
//

VOID
CcUnmapVacb (
    IN PVACB Vacb,
    IN PSHARED_CACHE_MAP SharedCacheMap,
    IN BOOLEAN UnmapBehind
    )

/*++

Routine Description:

    This routine may be called to unmap a previously mapped Vacb, and
    clear its BaseAddress field.

Arguments:

    Vacb - Supplies the Vacb which was returned from CcGetVirtualAddress.

    UnmapBehind - If this is a result of our unmap behind logic (the
        only case in which we pay attention to sequential hints)

Return Value:

    None.

--*/

{
    //
    //  Make sure it is mapped.
    //

    ASSERT(SharedCacheMap != NULL);
    ASSERT(Vacb->BaseAddress != NULL);

    //
    //  Call MM to unmap it.
    //

    DebugTrace( 0, mm, "MmUnmapViewInSystemCache:\n", 0 );
    DebugTrace( 0, mm, "    BaseAddress = %08lx\n", Vacb->BaseAddress );

    MmUnmapViewInSystemCache( Vacb->BaseAddress,
                              SharedCacheMap->Section,
                              UnmapBehind &&
                              FlagOn(SharedCacheMap->Flags, ONLY_SEQUENTIAL_ONLY_SEEN) );

    Vacb->BaseAddress = NULL;
}


NTSTATUS
FASTCALL
CcCreateVacbArray (
    IN PSHARED_CACHE_MAP SharedCacheMap,
    IN LARGE_INTEGER NewSectionSize
    )

/*++

Routine Description:

    This routine must be called when a SharedCacheMap is created to create
    and initialize the initial Vacb array.

Arguments:

    SharedCacheMap - Supplies the shared cache map for which the array is
                     to be created.

    NewSectionSize - Supplies the current size of the section which must be
                     covered by the Vacb array.

Return Value:

    NTSTATUS.

--*/

{
    PVACB *NewAddresses;
    ULONG NewSize, SizeToAllocate;
    PLIST_ENTRY BcbListHead;
    LOGICAL CreateBcbListHeads = FALSE, CreateReference = FALSE;

    NewSize = SizeToAllocate = SizeOfVacbArray(NewSectionSize);

    //
    //  The following limit is greater than the MM limit
    //  (i.e., MM actually only supports even smaller sections).
    //  We have to reject the sign bit, and testing the high byte
    //  for nonzero will surely only catch errors.
    //

    if (NewSectionSize.HighPart & ~(PAGE_SIZE - 1)) {
        return STATUS_SECTION_TOO_BIG;
    }

    //
    //  See if we can use the array inside the shared cache map.
    //

    if (NewSize == (PREALLOCATED_VACBS * sizeof(PVACB))) {

        NewAddresses = &SharedCacheMap->InitialVacbs[0];

    //
    //  Else allocate the array.
    //

    } else {

        //
        //  For large metadata streams, double the size to allocate
        //  an array of Bcb listheads.  Each two Vacb pointers also
        //  gets its own Bcb listhead, thus requiring double the size.
        //

        ASSERT(SIZE_PER_BCB_LIST == (VACB_MAPPING_GRANULARITY * 2));

        //
        //  If this stream is larger than the size for multi-level Vacbs,
        //  then fix the size to allocate the root.
        //

        if (NewSize > VACB_LEVEL_BLOCK_SIZE) {

            ULONG Level = 0;
            ULONG Shift = VACB_OFFSET_SHIFT + VACB_LEVEL_SHIFT;

            NewSize = SizeToAllocate = VACB_LEVEL_BLOCK_SIZE;
            SizeToAllocate += sizeof(VACB_LEVEL_REFERENCE);
            CreateReference = TRUE;

            //
            //  Loop to calculate how many levels we have and how much we have to
            //  shift to index into the first level.
            //

            do {

                Level += 1;
                Shift += VACB_LEVEL_SHIFT;

            } while ((NewSectionSize.QuadPart > ((LONGLONG)1 << Shift)) != 0);

            //
            //  Remember the maximum level ever seen (which is actually Level + 1).
            //

            if (Level >= CcMaxVacbLevelsSeen) {
                ASSERT(Level <= VACB_NUMBER_OF_LEVELS);
                CcMaxVacbLevelsSeen = Level + 1;
            }

        } else {

            //
            //  Does this stream get a Bcb Listhead array?
            //

            if (FlagOn(SharedCacheMap->Flags, MODIFIED_WRITE_DISABLED) &&
                (NewSectionSize.QuadPart > BEGIN_BCB_LIST_ARRAY)) {

                SizeToAllocate *= 2;
                CreateBcbListHeads = TRUE;
            }

            //
            //  Handle the boundary case by giving the proto-level a
            //  reference count.  This will allow us to simply push it
            //  in the expansion case.  In practice, due to pool granularity
            //  this will not change the amount of space allocated
            //

            if (NewSize == VACB_LEVEL_BLOCK_SIZE) {

                SizeToAllocate += sizeof(VACB_LEVEL_REFERENCE);
                CreateReference = TRUE;
            }
        }

        NewAddresses = ExAllocatePoolWithTag( NonPagedPool, SizeToAllocate, 'pVcC' );
        if (NewAddresses == NULL) {
            SharedCacheMap->Status = STATUS_INSUFFICIENT_RESOURCES;
            return STATUS_INSUFFICIENT_RESOURCES;
        }
    }

    //
    //  Zero out the Vacb array and the trailing reference counts.
    //

    RtlZeroMemory( (PCHAR)NewAddresses, NewSize );

    if (CreateReference) {

        SizeToAllocate -= sizeof(VACB_LEVEL_REFERENCE);
        RtlZeroMemory( (PCHAR)NewAddresses + SizeToAllocate, sizeof(VACB_LEVEL_REFERENCE) );
    }

    //
    //  Loop to insert the Bcb listheads (if any) in the *descending* order
    //  Bcb list.
    //

    if (CreateBcbListHeads) {

        for (BcbListHead = (PLIST_ENTRY)((PCHAR)NewAddresses + NewSize);
             BcbListHead < (PLIST_ENTRY)((PCHAR)NewAddresses + SizeToAllocate);
             BcbListHead++) {

            InsertHeadList( &SharedCacheMap->BcbList, BcbListHead );
        }
    }

    SharedCacheMap->Vacbs = NewAddresses;
    SharedCacheMap->SectionSize = NewSectionSize;

    return STATUS_SUCCESS;
}


NTSTATUS
CcExtendVacbArray (
    IN PSHARED_CACHE_MAP SharedCacheMap,
    IN LARGE_INTEGER NewSectionSize
    )

/*++

Routine Description:

    This routine must be called any time the section for a shared cache
    map is extended, in order to extend the Vacb array (if necessary).

Arguments:

    SharedCacheMap - Supplies the shared cache map for which the array is
                     to be created.

    NewSectionSize - Supplies the new size of the section which must be
                     covered by the Vacb array.

Return Value:

    NTSTATUS.

--*/

{
    KLOCK_QUEUE_HANDLE LockHandle;
    PVACB *OldAddresses;
    PVACB *NewAddresses;
    ULONG OldSize;
    ULONG NewSize, SizeToAllocate;
    LARGE_INTEGER NextLevelSize;
    LOGICAL GrowingBcbListHeads = FALSE, CreateReference = FALSE;

    //
    //  The following limit is greater than the MM limit
    //  (i.e., MM actually only supports even smaller sections).
    //  We have to reject the sign bit, and testing the high byte
    //  for nonzero will surely only catch errors.
    //

    if (NewSectionSize.HighPart & ~(PAGE_SIZE - 1)) {
        return STATUS_SECTION_TOO_BIG;
    }

    //
    //  See if we will be growing the Bcb ListHeads, so we can take out the
    //  master lock if so.
    //

    if (FlagOn(SharedCacheMap->Flags, MODIFIED_WRITE_DISABLED) &&
        (NewSectionSize.QuadPart > BEGIN_BCB_LIST_ARRAY)) {

        GrowingBcbListHeads = TRUE;
    }

    //
    //  Is there any work to do?
    //

    if (NewSectionSize.QuadPart > SharedCacheMap->SectionSize.QuadPart) {

        //
        //  Handle the growth of the first level here.
        //

        if (SharedCacheMap->SectionSize.QuadPart < VACB_SIZE_OF_FIRST_LEVEL) {

            NextLevelSize = NewSectionSize;

            //
            //  Limit the growth of this level
            //

            if (NextLevelSize.QuadPart >= VACB_SIZE_OF_FIRST_LEVEL) {
                NextLevelSize.QuadPart = VACB_SIZE_OF_FIRST_LEVEL;
                CreateReference = TRUE;
            }

            //
            //  N.B.: SizeOfVacbArray only calculates the size of the VACB
            //  pointer block.  We must adjust for Bcb listheads and the
            //  multilevel reference count.
            //

            NewSize = SizeToAllocate = SizeOfVacbArray(NextLevelSize);
            OldSize = SizeOfVacbArray(SharedCacheMap->SectionSize);

            //
            //  Only do something if the size is growing.
            //

            if (NewSize > OldSize) {

                //
                //  Does this stream get a Bcb Listhead array?
                //

                if (GrowingBcbListHeads) {
                    SizeToAllocate *= 2;
                }

                //
                //  Do we need space for the reference count?
                //

                if (CreateReference) {
                    SizeToAllocate += sizeof(VACB_LEVEL_REFERENCE);
                }

                NewAddresses = ExAllocatePoolWithTag( NonPagedPool, SizeToAllocate, 'pVcC' );
                if (NewAddresses == NULL) {
                    return STATUS_INSUFFICIENT_RESOURCES;
                }

                //
                //  See if we will be growing the Bcb ListHeads, so we can take out the
                //  master lock if so.
                //

                if (GrowingBcbListHeads) {

                    KeAcquireInStackQueuedSpinLock( &SharedCacheMap->BcbSpinLock, &LockHandle );
                    CcAcquireVacbLockAtDpcLevel();

                } else {

                    //
                    //  Acquire the spin lock to serialize with anyone who might like
                    //  to "steal" one of the mappings we are going to move.
                    //

                    CcAcquireVacbLock( &LockHandle.OldIrql );
                }

                OldAddresses = SharedCacheMap->Vacbs;
                if (OldAddresses != NULL) {
                    RtlCopyMemory( NewAddresses, OldAddresses, OldSize );
                } else {
                    OldSize = 0;
                }

                RtlZeroMemory( (PCHAR)NewAddresses + OldSize, NewSize - OldSize );

                if (CreateReference) {

                    SizeToAllocate -= sizeof(VACB_LEVEL_REFERENCE);
                    RtlZeroMemory( (PCHAR)NewAddresses + SizeToAllocate, sizeof(VACB_LEVEL_REFERENCE) );
                }

                //
                //  See if we have to initialize Bcb Listheads.
                //

                if (GrowingBcbListHeads) {

                    LARGE_INTEGER Offset;
                    PLIST_ENTRY BcbListHeadNew, TempEntry;

                    Offset.QuadPart = 0;
                    BcbListHeadNew = (PLIST_ENTRY)((PCHAR)NewAddresses + NewSize );

                    //
                    //  Handle case where the old array had Bcb Listheads.
                    //

                    if ((SharedCacheMap->SectionSize.QuadPart > BEGIN_BCB_LIST_ARRAY) &&
                        (OldAddresses != NULL)) {

                        PLIST_ENTRY BcbListHeadOld;

                        BcbListHeadOld = (PLIST_ENTRY)((PCHAR)OldAddresses + OldSize);

                        //
                        //  Loop to remove each old listhead and insert the new one
                        //  in its place.
                        //

                        do {
                            TempEntry = BcbListHeadOld->Flink;
                            RemoveEntryList( BcbListHeadOld );
                            InsertTailList( TempEntry, BcbListHeadNew );
                            Offset.QuadPart += SIZE_PER_BCB_LIST;
                            BcbListHeadOld += 1;
                            BcbListHeadNew += 1;
                        } while (Offset.QuadPart < SharedCacheMap->SectionSize.QuadPart);

                    //
                    //  Otherwise, handle the case where we are adding Bcb
                    //  Listheads.
                    //

                    } else {

                        TempEntry = SharedCacheMap->BcbList.Blink;

                        //
                        //  Loop through any/all Bcbs to insert the new listheads.
                        //

                        while (TempEntry != &SharedCacheMap->BcbList) {

                            //
                            //  Sit on this Bcb until we have inserted all listheads
                            //  that go before it.
                            //

                            while (Offset.QuadPart <= ((PBCB)CONTAINING_RECORD(TempEntry, BCB, BcbLinks))->FileOffset.QuadPart) {

                                InsertHeadList(TempEntry, BcbListHeadNew);
                                Offset.QuadPart += SIZE_PER_BCB_LIST;
                                BcbListHeadNew += 1;
                            }
                            TempEntry = TempEntry->Blink;
                        }
                    }

                    //
                    //  Now insert the rest of the new listhead entries that were
                    //  not finished in either loop above.
                    //

                    while (Offset.QuadPart < NextLevelSize.QuadPart) {

                        InsertHeadList(&SharedCacheMap->BcbList, BcbListHeadNew);
                        Offset.QuadPart += SIZE_PER_BCB_LIST;
                        BcbListHeadNew += 1;
                    }
                }

                //
                //  These two fields must be changed while still holding the spinlock.
                //

                SharedCacheMap->Vacbs = NewAddresses;
                SharedCacheMap->SectionSize = NextLevelSize;

                //
                //  Now we can free the spinlocks ahead of freeing pool.
                //

                if (GrowingBcbListHeads) {
                    CcReleaseVacbLockFromDpcLevel();
                    KeReleaseInStackQueuedSpinLock( &LockHandle );
                } else {
                    CcReleaseVacbLock( LockHandle.OldIrql );
                }

                if ((OldAddresses != &SharedCacheMap->InitialVacbs[0]) &&
                    (OldAddresses != NULL)) {
                    ExFreePool( OldAddresses );
                }
            }

            //
            //  Make sure SectionSize gets updated.  It is ok to fall through here
            //  without a spinlock, so long as either Vacbs was not changed, or it
            //  was changed together with SectionSize under the spinlock(s) above.
            //

            SharedCacheMap->SectionSize = NextLevelSize;
        }

        //
        //  Handle extends up to and within multi-level Vacb arrays here.  This is fairly simple.
        //  If no additional Vacb levels are required, then there is no work to do, otherwise
        //  we just have to push the root one or more levels linked through the first pointer
        //  in the new root(s).
        //

        if (NewSectionSize.QuadPart > SharedCacheMap->SectionSize.QuadPart) {

            PVACB *NextVacbArray;
            ULONG NewLevel;
            ULONG Level = 1;
            ULONG Shift = VACB_OFFSET_SHIFT + VACB_LEVEL_SHIFT;

            //
            //  Loop to calculate how many levels we currently have.
            //

            while (SharedCacheMap->SectionSize.QuadPart > ((LONGLONG)1 << Shift)) {

                Level += 1;
                Shift += VACB_LEVEL_SHIFT;
            }

            NewLevel = Level;

            //
            //  Loop to calculate how many levels we need.
            //

            while (((NewSectionSize.QuadPart - 1) >> Shift) != 0) {

                NewLevel += 1;
                Shift += VACB_LEVEL_SHIFT;
            }

            //
            //  Now see if we have any work to do.
            //

            if (NewLevel > Level) {

                //
                //  Remember the maximum level ever seen (which is actually NewLevel + 1).
                //

                if (NewLevel >= CcMaxVacbLevelsSeen) {
                    ASSERT(NewLevel <= VACB_NUMBER_OF_LEVELS);
                    CcMaxVacbLevelsSeen = NewLevel + 1;
                }

                //
                //  Raise if we cannot preallocate enough buffers.
                //

                if (!CcPrefillVacbLevelZone( NewLevel - Level, &LockHandle.OldIrql, FALSE )) {

                    return STATUS_INSUFFICIENT_RESOURCES;
                }

                //
                //  Now if the current Level of the file is 1, we have not been maintaining
                //  a reference count, so we have to calculate it before pushing.  In the
                //  boundary case we have made sure that the reference space is available.
                //

                if (Level == 1) {

                    //
                    //  We know this is always a leaf-like level right now.
                    //

                    CcCalculateVacbLevelLockCount( SharedCacheMap, SharedCacheMap->Vacbs, 0 );
                }

                //
                //  Finally, if there are any active pointers in the first level, then we
                //  have to create new levels by adding a new root enough times to create
                //  additional levels.  On the other hand, if the pointer count in the top
                //  level is zero, then we must not do any pushes, because we never allow
                //  empty leaves!
                //

                if (IsVacbLevelReferenced( SharedCacheMap, SharedCacheMap->Vacbs, Level - 1 )) {

                    while (NewLevel > Level++) {

                        ASSERT(CcVacbLevelEntries != 0);
                        NextVacbArray = CcAllocateVacbLevel(FALSE);

                        NextVacbArray[0] = (PVACB)SharedCacheMap->Vacbs;
                        ReferenceVacbLevel( SharedCacheMap, NextVacbArray, Level, 1, FALSE );

                        SharedCacheMap->Vacbs = NextVacbArray;
                    }

                } else {

                    //
                    //  We are now possesed of the additional problem that this level has no
                    //  references but may have Bcb listheads due to the boundary case where
                    //  we have expanded up to the multilevel Vacbs above.  This level can't
                    //  remain at the root and needs to be destroyed.  What we need to do is
                    //  replace it with one of our prefilled (non Bcb) levels and unlink the
                    //  Bcb listheads in the old one.
                    //

                    if (Level == 1 && FlagOn(SharedCacheMap->Flags, MODIFIED_WRITE_DISABLED)) {

                        PLIST_ENTRY PredecessorListHead, SuccessorListHead;

                        NextVacbArray = SharedCacheMap->Vacbs;
                        SharedCacheMap->Vacbs = CcAllocateVacbLevel(FALSE);

                        PredecessorListHead = ((PLIST_ENTRY)((PCHAR)NextVacbArray + VACB_LEVEL_BLOCK_SIZE))->Flink;
                        SuccessorListHead = ((PLIST_ENTRY)((PCHAR)NextVacbArray + (VACB_LEVEL_BLOCK_SIZE * 2) - sizeof(LIST_ENTRY)))->Blink;
                        PredecessorListHead->Blink = SuccessorListHead;
                        SuccessorListHead->Flink = PredecessorListHead;

                        CcDeallocateVacbLevel( NextVacbArray, TRUE );
                    }
                }

                //
                //  These two fields (Vacbs and SectionSize) must be changed while still
                //  holding the spinlock.
                //

                SharedCacheMap->SectionSize = NewSectionSize;
                CcReleaseVacbLock( LockHandle.OldIrql );
            }

            //
            //  Make sure SectionSize gets updated.  It is ok to fall through here
            //  without a spinlock, so long as either Vacbs was not changed, or it
            //  was changed together with SectionSize under the spinlock(s) above.
            //

            SharedCacheMap->SectionSize = NewSectionSize;
        }
    }
    return STATUS_SUCCESS;
}


BOOLEAN
FASTCALL
CcUnmapVacbArray (
    IN PSHARED_CACHE_MAP SharedCacheMap,
    IN PLARGE_INTEGER FileOffset OPTIONAL,
    IN ULONG Length,
    IN BOOLEAN UnmapBehind
    )

/*++

Routine Description:

    This routine must be called to do any unmapping and associated
    cleanup for a shared cache map, just before it is deleted.

Arguments:

    SharedCacheMap - Supplies a pointer to the shared cache map
                     which is about to be deleted.

    FileOffset - If supplied, only unmap the specified offset and length

    Length - Completes range to unmap if FileOffset specified.  If FileOffset
             is specified, Length of 0 means unmap to the end of the section.

    UnmapBehind - If this is a result of our unmap behind logic

Return Value:

    FALSE -- if an the unmap was not done due to an active vacb
    TRUE -- if the unmap was done

--*/

{
    PVACB Vacb;
    KIRQL OldIrql;
    LARGE_INTEGER StartingFileOffset = {0,0};
    LARGE_INTEGER EndingFileOffset = SharedCacheMap->SectionSize;

    //
    //  We could be just cleaning up for error recovery.
    //

    if (SharedCacheMap->Vacbs == NULL) {
        return TRUE;
    }

    //
    //  See if a range was specified. Align it to the VACB boundaries so it
    //  works in the loop below
    //

    if (ARGUMENT_PRESENT(FileOffset)) {
        StartingFileOffset.QuadPart = ((FileOffset->QuadPart) & (~((LONGLONG)VACB_MAPPING_GRANULARITY - 1)));
        if (Length != 0) {

            EndingFileOffset.QuadPart = FileOffset->QuadPart + Length;

        }
    }

    //
    //  Acquire the spin lock to
    //

    CcAcquireVacbLock( &OldIrql );

    while (StartingFileOffset.QuadPart < EndingFileOffset.QuadPart) {

        //
        //  Note that the caller with an explicit range may be off the
        //  end of the section (example CcPurgeCacheSection for cache
        //  coherency).  That is the reason for the first part of the
        //  test below.
        //
        //  Check the next cell once without the spin lock, it probably will
        //  not change, but we will handle it if it does not.
        //

        if ((StartingFileOffset.QuadPart < SharedCacheMap->SectionSize.QuadPart) &&
            ((Vacb = GetVacb( SharedCacheMap, StartingFileOffset )) != NULL)) {

            //
            //  Return here if we are unlucky and see an active
            //  Vacb.  It could be Purge calling, and the Lazy Writer
            //  may have done a CcGetVirtualAddressIfMapped!
            //

            if (Vacb->Overlay.ActiveCount != 0) {

                CcReleaseVacbLock( OldIrql );
                return FALSE;
            }

            //
            //  Unlink it from the other SharedCacheMap, so the other
            //  guy will not try to use it when we free the spin lock.
            //

            SetVacb( SharedCacheMap, StartingFileOffset, NULL );
            Vacb->SharedCacheMap = NULL;

            //
            //  Increment the open count so that no one else will
            //  try to unmap or reuse until we are done.
            //

            Vacb->Overlay.ActiveCount += 1;

            //
            //  Release the spin lock.
            //

            CcReleaseVacbLock( OldIrql );

            //
            //  Unmap and free it if we really got it above.
            //

            CcUnmapVacb( Vacb, SharedCacheMap, UnmapBehind );

            //
            //  Reacquire the spin lock so that we can decrment the count.
            //

            CcAcquireVacbLock( &OldIrql );
            Vacb->Overlay.ActiveCount -= 1;

            //
            //  Place this VACB at the head of the LRU
            //

            CcMoveVacbToReuseFree( Vacb );
        }

        StartingFileOffset.QuadPart = StartingFileOffset.QuadPart + VACB_MAPPING_GRANULARITY;
    }

    CcReleaseVacbLock( OldIrql );

    CcDrainVacbLevelZone();

    return TRUE;
}


ULONG
CcPrefillVacbLevelZone (
    IN ULONG NumberNeeded,
    OUT PKIRQL OldIrql,
    IN ULONG NeedBcbListHeads
    )

/*++

Routine Description:

    This routine may be called to prefill the VacbLevelZone with the number of
    entries required, and return with CcVacbSpinLock acquired.  This approach is
    taken so that the pool allocations and RtlZeroMemory calls can occur without
    holding any spinlock, yet the caller may proceed to peform a single indivisible
    operation without error handling, since there is a guaranteed minimum number of
    entries in the zone.

Arguments:

    NumberNeeded - Number of VacbLevel entries needed, not counting the possible
                   one with Bcb listheads.

    OldIrql = supplies a pointer to where OldIrql should be returned upon acquiring
              the spinlock.

    NeedBcbListHeads - Supplies true if a level is also needed which contains listheads.

Return Value:

    FALSE if the buffers could not be preallocated, TRUE otherwise.

Environment:

    No spinlocks should be held upon entry.

--*/

{
    PVACB *NextVacbArray;

    CcAcquireVacbLock( OldIrql );

    //
    //  Loop until there is enough entries, else return failure...
    //

    while ((NumberNeeded > CcVacbLevelEntries) ||
           (NeedBcbListHeads && (CcVacbLevelWithBcbsFreeList == NULL))) {


        //
        //  Else release the spinlock so we can do the allocate/zero.
        //

        CcReleaseVacbLock( *OldIrql );

        //
        //  First handle the case where we need a VacbListHead with Bcb Listheads.
        //  The pointer test is unsafe but see below.
        //

        if (NeedBcbListHeads && (CcVacbLevelWithBcbsFreeList == NULL)) {

            //
            //  Allocate and initialize the Vacb block for this level, and store its pointer
            //  back into our parent.  We do not zero the listhead area.
            //

            NextVacbArray =
            (PVACB *)ExAllocatePoolWithTag( NonPagedPool, (VACB_LEVEL_BLOCK_SIZE * 2) + sizeof(VACB_LEVEL_REFERENCE), 'lVcC' );

            if (NextVacbArray == NULL) {
                return FALSE;
            }

            RtlZeroMemory( (PCHAR)NextVacbArray, VACB_LEVEL_BLOCK_SIZE );
            RtlZeroMemory( (PCHAR)NextVacbArray + (VACB_LEVEL_BLOCK_SIZE * 2), sizeof(VACB_LEVEL_REFERENCE) );

            CcAcquireVacbLock( OldIrql );

            NextVacbArray[0] = (PVACB)CcVacbLevelWithBcbsFreeList;
            CcVacbLevelWithBcbsFreeList = NextVacbArray;
            CcVacbLevelWithBcbsEntries += 1;

        } else {

            //
            //  Allocate and initialize the Vacb block for this level, and store its pointer
            //  back into our parent.
            //

            NextVacbArray =
            (PVACB *)ExAllocatePoolWithTag( NonPagedPool, VACB_LEVEL_BLOCK_SIZE + sizeof(VACB_LEVEL_REFERENCE), 'lVcC' );

            if (NextVacbArray == NULL) {
                return FALSE;
            }

            RtlZeroMemory( (PCHAR)NextVacbArray, VACB_LEVEL_BLOCK_SIZE + sizeof(VACB_LEVEL_REFERENCE) );

            CcAcquireVacbLock( OldIrql );

            NextVacbArray[0] = (PVACB)CcVacbLevelFreeList;
            CcVacbLevelFreeList = NextVacbArray;
            CcVacbLevelEntries += 1;
        }
    }

    return TRUE;
}


VOID
CcDrainVacbLevelZone (
    )

/*++

Routine Description:

    This routine should be called any time some entries have been deallocated to
    the VacbLevel zone, and we want to insure the zone is returned to a normal level.

Arguments:

Return Value:

    None.

Environment:

    No spinlocks should be held upon entry.

--*/

{
    KIRQL OldIrql;
    PVACB *NextVacbArray;

    //
    //  This is an unsafe loop to see if it looks like there is stuff to
    //  clean up.
    //

    while ((CcVacbLevelEntries > (CcMaxVacbLevelsSeen * 4)) ||
           (CcVacbLevelWithBcbsEntries > 2)) {

        //
        //  Now go in and try to pick up one entry to free under a FastLock.
        //

        NextVacbArray = NULL;
        CcAcquireVacbLock( &OldIrql );
        if (CcVacbLevelEntries > (CcMaxVacbLevelsSeen * 4)) {
            NextVacbArray = CcVacbLevelFreeList;
            CcVacbLevelFreeList = (PVACB *)NextVacbArray[0];
            CcVacbLevelEntries -= 1;
        } else if (CcVacbLevelWithBcbsEntries > 2) {
            NextVacbArray = CcVacbLevelWithBcbsFreeList;
            CcVacbLevelWithBcbsFreeList = (PVACB *)NextVacbArray[0];
            CcVacbLevelWithBcbsEntries -= 1;
        }
        CcReleaseVacbLock( OldIrql );

        //
        //  Since the loop is unsafe, we may not have gotten anything.
        //

        if (NextVacbArray != NULL) {
            ExFreePool(NextVacbArray);
        }
    }
}


PLIST_ENTRY
CcGetBcbListHeadLargeOffset (
    IN PSHARED_CACHE_MAP SharedCacheMap,
    IN LONGLONG FileOffset,
    IN BOOLEAN FailToSuccessor
    )

/*++

Routine Description:

    This routine may be called to return the Bcb listhead for the specified FileOffset.
    It should only be called if the SectionSize is greater than VACB_SIZE_OF_FIRST_LEVEL.

Arguments:

    SharedCacheMap - Supplies the pointer to the SharedCacheMap for which the listhead
                     is desired.

    FileOffset - Supplies the fileOffset corresponding to the desired listhead.

    FailToSuccessor - Instructs whether not finding the exact listhead should cause us to
        return the predecessor or successor Bcb listhead.

Return Value:

    Returns the desired Listhead pointer.  If the desired listhead does not actually exist
    yet, then it returns the appropriate listhead.

Environment:

    The BcbSpinlock should be held on entry.

--*/

{
    ULONG Level, Shift;
    PVACB *VacbArray, *NextVacbArray;
    ULONG Index;
    ULONG SavedIndexes[VACB_NUMBER_OF_LEVELS];
    PVACB *SavedVacbArrays[VACB_NUMBER_OF_LEVELS];
    ULONG SavedLevels = 0;

    //
    //  Initialize variables controlling our descent into the hierarchy.
    //

    Level = 0;
    Shift = VACB_OFFSET_SHIFT + VACB_LEVEL_SHIFT;
    VacbArray = SharedCacheMap->Vacbs;

    //
    //  Caller must have verified that we have a hierarchy, otherwise this routine
    //  would fail.
    //

    ASSERT(SharedCacheMap->SectionSize.QuadPart > VACB_SIZE_OF_FIRST_LEVEL);

    //
    //  Loop to calculate how many levels we have and how much we have to
    //  shift to index into the first level.
    //

    do {

        Level += 1;
        Shift += VACB_LEVEL_SHIFT;

    } while (SharedCacheMap->SectionSize.QuadPart > ((LONGLONG)1 << Shift));

    //
    //  Our caller could be asking for an offset off the end of section size, so if he
    //  is actually off the size of the level, then return the main listhead.
    //

    if (FileOffset >= ((LONGLONG)1 << Shift)) {
        return &SharedCacheMap->BcbList;
    }

    //
    //  Now descend the tree to the bottom level to get the caller's Bcb ListHead.
    //

    Shift -= VACB_LEVEL_SHIFT;
    do {

        //
        //  Decrement back to the level that describes the size we are within.
        //

        Level -= 1;

        //
        //  Calculate the index into the Vacb block for this level.
        //

        Index = (ULONG)(FileOffset >> Shift);
        ASSERT(Index <= VACB_LAST_INDEX_FOR_LEVEL);

        //
        //  Get block address for next level.
        //

        NextVacbArray = (PVACB *)VacbArray[Index];

        //
        //  If it is NULL then we have to go find the highest Bcb or listhead which
        //  comes before the guy we are looking for, i.e., its predecessor.
        //

        if (NextVacbArray == NULL) {

            //
            //  Back up to look for the highest guy earlier in this tree, i.e., the
            //  predecessor listhead.
            //

            while (TRUE) {

                //
                //  Scan, if we can, in the current array for a non-null index.
                //

                if (FailToSuccessor) {

                    if (Index != VACB_LAST_INDEX_FOR_LEVEL) {

                        while ((Index != VACB_LAST_INDEX_FOR_LEVEL) && (VacbArray[++Index] == NULL)) {
                            continue;
                        }

                        //
                        //  If we found a non-null index, get out and try to return the
                        //  listhead.
                        //

                        if ((NextVacbArray = (PVACB *)VacbArray[Index]) != NULL) {
                            break;
                        }
                    }

                } else {

                    if (Index != 0) {

                        while ((Index != 0) && (VacbArray[--Index] == NULL)) {
                            continue;
                        }

                        //
                        //  If we found a non-null index, get out and try to return the
                        //  listhead.
                        //

                        if ((NextVacbArray = (PVACB *)VacbArray[Index]) != NULL) {
                            break;
                        }
                    }
                }

                //
                //  If there are no saved levels yet, then there is no predecessor or
                //  successor - it is the main listhead.
                //

                if (SavedLevels == 0) {
                    return &SharedCacheMap->BcbList;
                }

                //
                //  Otherwise, we can pop up a level in the tree and start scanning
                //  from that guy for a path to the right listhead.
                //

                Level += 1;
                Index = SavedIndexes[--SavedLevels];
                VacbArray = SavedVacbArrays[SavedLevels];
            }

            //
            //  We have backed up in the hierarchy, so now we are just looking for the
            //  highest/lowest guy in the level we want, i.e., the level-linking listhead.
            //  So smash FileOffset accordingly (we mask the high bits out anyway).
            //

            if (FailToSuccessor) {
                FileOffset = 0;
            } else {
                FileOffset = MAXLONGLONG;
            }
        }

        //
        //  We save Index and VacbArray at each level, for the case that we
        //  have to walk back up the tree to find a predecessor.
        //

        SavedIndexes[SavedLevels] = Index;
        SavedVacbArrays[SavedLevels] = VacbArray;
        SavedLevels += 1;

        //
        //  Now make this one our current pointer, and mask away the extraneous high-order
        //  FileOffset bits for this level.
        //

        VacbArray = NextVacbArray;
        FileOffset &= ((LONGLONG)1 << Shift) - 1;
        Shift -= VACB_LEVEL_SHIFT;

    //
    //  Loop until we hit the bottom level.
    //

    } while (Level != 0);

    //
    //  Now calculate the index for the bottom level and return the appropriate listhead.
    //  (The normal Vacb index indexes to a pointer to a Vacb for a .25MB view, so dropping
    //  the low bit gets you to the even-indexed Vacb pointer which is one block size below
    //  the two-pointer listhead for the Bcbs for that .5MB range...)
    //

    Index = (ULONG)(FileOffset >> Shift);
    return (PLIST_ENTRY)((PCHAR)&VacbArray[Index & ~1] + VACB_LEVEL_BLOCK_SIZE);
}


VOID
CcAdjustVacbLevelLockCount (
    IN PSHARED_CACHE_MAP SharedCacheMap,
    IN LONGLONG FileOffset,
    IN LONG Adjustment
    )

/*++

Routine Description:

    This routine may be called to adjust the lock count of the bottom Vacb level when
    Bcbs are inserted or deleted.  If the count goes to zero, the level will be
    eliminated.  The bottom level must exist, or we crash!

Arguments:

    SharedCacheMap - Supplies the pointer to the SharedCacheMap for which the Vacb
                     is desired.

    FileOffset - Supplies the fileOffset corresponding to the desired Vacb.

    Adjustment - Generally -1 or +1.

Return Value:

    None.

Environment:

    CcVacbSpinLock should be held on entry.

--*/

{
    ULONG Level, Shift;
    PVACB *VacbArray;
    LONGLONG OriginalFileOffset = FileOffset;

    //
    //  Initialize variables controlling our descent into the hierarchy.
    //

    Level = 0;
    Shift = VACB_OFFSET_SHIFT + VACB_LEVEL_SHIFT;

    VacbArray = SharedCacheMap->Vacbs;

    //
    //  Caller must have verified that we have a hierarchy, otherwise this routine
    //  would fail.
    //

    ASSERT(SharedCacheMap->SectionSize.QuadPart > VACB_SIZE_OF_FIRST_LEVEL);

    //
    //  Loop to calculate how many levels we have and how much we have to
    //  shift to index into the first level.
    //

    do {

        Level += 1;
        Shift += VACB_LEVEL_SHIFT;

    } while (SharedCacheMap->SectionSize.QuadPart > ((LONGLONG)1 << Shift));

    //
    //  Now descend the tree to the bottom level to get the caller's Vacb.
    //

    Shift -= VACB_LEVEL_SHIFT;
    do {

        VacbArray = (PVACB *)VacbArray[(ULONG)(FileOffset >> Shift)];

        Level -= 1;

        FileOffset &= ((LONGLONG)1 << Shift) - 1;

        Shift -= VACB_LEVEL_SHIFT;

    } while (Level != 0);

    //
    //  Now we have reached the final level, do the adjustment.
    //

    ReferenceVacbLevel( SharedCacheMap, VacbArray, Level, Adjustment, FALSE );

    //
    //  Now, if we decremented the count to 0, then force the collapse to happen by
    //  upping count and resetting to NULL.  Then smash OriginalFileOffset to be
    //  the first entry so we do not recalculate!
    //

    if (!IsVacbLevelReferenced( SharedCacheMap, VacbArray, Level )) {
        ReferenceVacbLevel( SharedCacheMap, VacbArray, Level, 1, TRUE );
        OriginalFileOffset &= ~(VACB_SIZE_OF_FIRST_LEVEL - 1);
        CcSetVacbLargeOffset( SharedCacheMap, OriginalFileOffset, VACB_SPECIAL_DEREFERENCE );
    }
}


VOID
CcCalculateVacbLevelLockCount (
    IN PSHARED_CACHE_MAP SharedCacheMap,
    IN PVACB *VacbArray,
    IN ULONG Level
    )

/*++

Routine Description:

    This routine may be called to calculate or recalculate the lock count on a
    given Vacb level array.  It is called, for example, when we are extending a
    section up to the point where we activate multilevel logic and want to start
    keeping the count.

Arguments:

    SharedCacheMap - Supplies the pointer to the SharedCacheMap for which the Vacb
                     is desired.

    VacbArray - The Vacb Level array to recalculate

    Level - Supplies 0 for the bottom level, nonzero otherwise.

Return Value:

    None.

Environment:

    CcVacbSpinLock should be held on entry.

--*/

{
    PBCB Bcb;
    ULONG Index;
    LONG Count = 0;
    PVACB *VacbTemp = VacbArray;
    PVACB_LEVEL_REFERENCE VacbReference;

    //
    //  First loop through to count how many Vacb pointers are in use.
    //

    for (Index = 0; Index <= VACB_LAST_INDEX_FOR_LEVEL; Index++) {
        if (*(VacbTemp++) != NULL) {
            Count += 1;
        }
    }

    //
    //  If this is a metadata stream, we also have to count the Bcbs in the
    //  corresponding listheads.
    //

    if (FlagOn(SharedCacheMap->Flags, MODIFIED_WRITE_DISABLED) && (Level == 0)) {

        //
        //  Pick up the Blink of the first listhead, casting it to a Bcb.
        //

        Bcb = (PBCB)CONTAINING_RECORD(((PLIST_ENTRY)VacbTemp)->Blink, BCB, BcbLinks);
        Index = 0;

        //
        //  Now loop through the list.  For each Bcb we see, increment the count,
        //  and for each listhead, increment Index.  We are done when we hit the
        //  last listhead, which is actually the next listhead past the ones in this
        //  block.
        //

        do {

            if (Bcb->NodeTypeCode == CACHE_NTC_BCB) {
                Count += 1;
            } else {
                Index += 1;
            }

            Bcb = (PBCB)CONTAINING_RECORD(Bcb->BcbLinks.Blink, BCB, BcbLinks);

        } while (Index <= (VACB_LAST_INDEX_FOR_LEVEL / 2));
    }

    //
    //  Store the count and get out... (by hand, don't touch the special count)
    //

    VacbReference = VacbLevelReference( SharedCacheMap, VacbArray, Level );
    VacbReference->Reference = Count;
}


PVACB
CcGetVacbLargeOffset (
    IN PSHARED_CACHE_MAP SharedCacheMap,
    IN LONGLONG FileOffset
    )

/*++

Routine Description:

    This routine may be called to return the Vacb for the specified FileOffset.
    It should only be called if the SectionSize is greater than VACB_SIZE_OF_FIRST_LEVEL.

Arguments:

    SharedCacheMap - Supplies the pointer to the SharedCacheMap for which the Vacb
                     is desired.

    FileOffset - Supplies the fileOffset corresponding to the desired Vacb.

Return Value:

    Returns the desired Vacb pointer or NULL if there is none.

Environment:

    CcVacbSpinLock should be held on entry.

--*/

{
    ULONG Level, Shift;
    PVACB *VacbArray;
    PVACB Vacb;

    //
    //  Initialize variables controlling our descent into the hierarchy.
    //

    Level = 0;
    Shift = VACB_OFFSET_SHIFT + VACB_LEVEL_SHIFT;
    VacbArray = SharedCacheMap->Vacbs;

    //
    //  Caller must have verified that we have a hierarchy, otherwise this routine
    //  would fail.
    //

    ASSERT(SharedCacheMap->SectionSize.QuadPart > VACB_SIZE_OF_FIRST_LEVEL);

    //
    //  Loop to calculate how many levels we have and how much we have to
    //  shift to index into the first level.
    //

    do {

        Level += 1;
        Shift += VACB_LEVEL_SHIFT;

    } while (SharedCacheMap->SectionSize.QuadPart > ((LONGLONG)1 << Shift));

    //
    //  Now descend the tree to the bottom level to get the caller's Vacb.
    //

    Shift -= VACB_LEVEL_SHIFT;
    while (((Vacb = (PVACB)VacbArray[FileOffset >> Shift]) != NULL) && (Level != 0)) {

        Level -= 1;

        VacbArray = (PVACB *)Vacb;
        FileOffset &= ((LONGLONG)1 << Shift) - 1;

        Shift -= VACB_LEVEL_SHIFT;
    }

    //
    //  If the Vacb we exited with is not NULL, we want to make sure it looks OK.
    //

    ASSERT(Vacb == NULL || ((Vacb >= CcVacbs) && (Vacb < CcBeyondVacbs)));

    return Vacb;
}


VOID
CcSetVacbLargeOffset (
    IN PSHARED_CACHE_MAP SharedCacheMap,
    IN LONGLONG FileOffset,
    IN PVACB Vacb
    )

/*++

Routine Description:

    This routine may be called to set the specified Vacb pointer for the specified FileOffset.
    It should only be called if the SectionSize is greater than VACB_SIZE_OF_FIRST_LEVEL.

    For non-null Vacb, intermediate Vacb levels will be added as necessary, and if the lowest
    level has Bcb listheads, these will also be added.  For this case the caller must acquire
    the spinlock by calling CcPrefillVacbLevelZone specifying the worst-case number of levels
    required.

    For a null Vacb pointer, the tree is pruned of all Vacb levels that go empty.  If the lowest
    level has Bcb listheads, then they are removed.  The caller should subsequently call
    CcDrainVacbLevelZone once the spinlock is release to actually free some of this zone to the
    pool.

Arguments:

    SharedCacheMap - Supplies the pointer to the SharedCacheMap for which the Vacb
                     is desired.

    FileOffset - Supplies the fileOffset corresponding to the desired Vacb.

Return Value:

    Returns the desired Vacb pointer or NULL if there is none.

Environment:

    CcVacbSpinLock should be held on entry.

--*/

{
    ULONG Level, Shift;
    PVACB *VacbArray, *NextVacbArray;
    ULONG Index;
    ULONG SavedIndexes[VACB_NUMBER_OF_LEVELS];
    PVACB *SavedVacbArrays[VACB_NUMBER_OF_LEVELS];
    PLIST_ENTRY PredecessorListHead, SuccessorListHead, CurrentListHead;
    LOGICAL AllocatingBcbListHeads, Special = FALSE;
    LONGLONG OriginalFileOffset = FileOffset;
    ULONG SavedLevels = 0;

    //
    //  Initialize variables controlling our descent into the hierarchy.
    //

    Level = 0;
    Shift = VACB_OFFSET_SHIFT + VACB_LEVEL_SHIFT;
    VacbArray = SharedCacheMap->Vacbs;

    //
    //  Caller must have verified that we have a hierarchy, otherwise this routine
    //  would fail.
    //

    ASSERT(SharedCacheMap->SectionSize.QuadPart > VACB_SIZE_OF_FIRST_LEVEL);

    //
    //  Loop to calculate how many levels we have and how much we have to
    //  shift to index into the first level.
    //

    do {

        Level += 1;
        Shift += VACB_LEVEL_SHIFT;

    } while (SharedCacheMap->SectionSize.QuadPart > ((LONGLONG)1 << Shift));

    //
    //  Now descend the tree to the bottom level to set the caller's Vacb.
    //

    Shift -= VACB_LEVEL_SHIFT;
    do {

        //
        //  Decrement back to the level that describes the size we are within.
        //

        Level -= 1;

        //
        //  Calculate the index into the Vacb block for this level.
        //

        Index = (ULONG)(FileOffset >> Shift);
        ASSERT(Index <= VACB_LAST_INDEX_FOR_LEVEL);

        //
        //  We save Index and VacbArray at each level, for the case that we
        //  are collapsing and deallocating blocks below.
        //

        SavedIndexes[SavedLevels] = Index;
        SavedVacbArrays[SavedLevels] = VacbArray;
        SavedLevels += 1;

        //
        //  Get block address for next level.
        //

        NextVacbArray = (PVACB *)VacbArray[Index];

        //
        //  If it is NULL then we have to allocate the next level to fill it in.
        //

        if (NextVacbArray == NULL) {

            //
            //  We better not be thinking we're dereferencing a level if the level
            //  doesn't currently exist.
            //

            ASSERT( Vacb != VACB_SPECIAL_DEREFERENCE );

            AllocatingBcbListHeads = FlagOn(SharedCacheMap->Flags, MODIFIED_WRITE_DISABLED) && (Level == 0);

            //
            //  This is only valid if we are setting a nonzero pointer!
            //

            ASSERT(Vacb != NULL);

            NextVacbArray = CcAllocateVacbLevel(AllocatingBcbListHeads);

            //
            //  If we allocated Bcb Listheads, we must link them in.
            //

            if (AllocatingBcbListHeads) {

                ULONG i;

                //
                //  Find our predecessor.
                //

                PredecessorListHead = CcGetBcbListHeadLargeOffset( SharedCacheMap, OriginalFileOffset, FALSE );

                //
                //  If he is followed by any Bcbs, they "belong" to him, and we have to
                //  skip over them.
                //

                while (((PBCB)CONTAINING_RECORD(PredecessorListHead->Blink, BCB, BcbLinks))->NodeTypeCode ==
                       CACHE_NTC_BCB) {
                    PredecessorListHead = (PLIST_ENTRY)PredecessorListHead->Blink;
                }

                //
                //  Point to the first newly allocated listhead.
                //

                CurrentListHead = (PLIST_ENTRY)((PCHAR)NextVacbArray + VACB_LEVEL_BLOCK_SIZE);

                //
                //  Link first new listhead to predecessor.
                //

                SuccessorListHead = PredecessorListHead->Blink;
                PredecessorListHead->Blink = CurrentListHead;
                CurrentListHead->Flink = PredecessorListHead;

                //
                //  Now loop to link all of the new listheads together.
                //

                for (i = 0; i < ((VACB_LEVEL_BLOCK_SIZE / sizeof(LIST_ENTRY) - 1)); i++) {

                    CurrentListHead->Blink = CurrentListHead + 1;
                    CurrentListHead += 1;
                    CurrentListHead->Flink = CurrentListHead - 1;
                }

                //
                //  Finally link the last new listhead to the successor.
                //

                CurrentListHead->Blink = SuccessorListHead;
                SuccessorListHead->Flink = CurrentListHead;
            }

            VacbArray[Index] = (PVACB)NextVacbArray;

            //
            //  Increment the reference count.  Note that Level right now properly indicates
            //  what level NextVacbArray is at, not VacbArray.
            //

            ReferenceVacbLevel( SharedCacheMap, VacbArray, Level + 1, 1, FALSE );
        }

        //
        //  Now make this one our current pointer, and mask away the extraneous high-order
        //  FileOffset bits for this level and reduce the shift count.
        //

        VacbArray = NextVacbArray;
        FileOffset &= ((LONGLONG)1 << Shift) - 1;
        Shift -= VACB_LEVEL_SHIFT;

    //
    //  Loop until we hit the bottom level.
    //

    } while (Level != 0);

    if (Vacb < VACB_SPECIAL_FIRST_VALID) {

        //
        //  Now calculate the index for the bottom level and store the caller's Vacb pointer.
        //

        Index = (ULONG)(FileOffset >> Shift);
        VacbArray[Index] = Vacb;

    //
    //  Handle the special actions.
    //

    } else {

        Special = TRUE;

        //
        //  Induce the dereference.
        //

        if (Vacb == VACB_SPECIAL_DEREFERENCE) {

            Vacb = NULL;
        }
    }

    //
    //  If he is storing a nonzero pointer, just reference the level.
    //

    if (Vacb != NULL) {

        ASSERT( !(Special && Level != 0) );

        ReferenceVacbLevel( SharedCacheMap, VacbArray, Level, 1, Special );

    //
    //  Otherwise we are storing a NULL pointer, and we have to see if we can collapse
    //  the tree by deallocating empty blocks of pointers.
    //

    } else {

        //
        //  Loop until doing all possible collapse except for the top level.
        //

        while (TRUE) {

            ReferenceVacbLevel( SharedCacheMap, VacbArray, Level, -1, Special );

            //
            //  If this was a special dereference, then recognize that this was
            //  the only one.  The rest, as we tear up the tree, are regular
            //  (calculable) references.
            //

            Special = FALSE;

            //
            //  Now, if we have an empty block (other than the top one), then we should free the
            //  block and keep looping.
            //

            if (!IsVacbLevelReferenced( SharedCacheMap, VacbArray, Level ) && (SavedLevels != 0)) {

                SavedLevels -= 1;

                //
                //  First see if we have Bcb Listheads to delete and if so, we have to unlink
                //  the whole block first.
                //

                AllocatingBcbListHeads = FALSE;
                if ((Level++ == 0) && FlagOn(SharedCacheMap->Flags, MODIFIED_WRITE_DISABLED)) {

                    AllocatingBcbListHeads = TRUE;
                    PredecessorListHead = ((PLIST_ENTRY)((PCHAR)VacbArray + VACB_LEVEL_BLOCK_SIZE))->Flink;
                    SuccessorListHead = ((PLIST_ENTRY)((PCHAR)VacbArray + (VACB_LEVEL_BLOCK_SIZE * 2) - sizeof(LIST_ENTRY)))->Blink;
                    PredecessorListHead->Blink = SuccessorListHead;
                    SuccessorListHead->Flink = PredecessorListHead;
                }

                //
                //  Free the unused block and then pick up the saved parent pointer array and
                //  index and erase the pointer to this block.
                //

                CcDeallocateVacbLevel( VacbArray, AllocatingBcbListHeads );
                Index = SavedIndexes[SavedLevels];
                VacbArray = SavedVacbArrays[SavedLevels];
                VacbArray[Index] = NULL;

            //
            //  No more collapsing if we hit a block that still has pointers, or we hit the root.
            //

            } else {
                break;
            }
        }
    }
}


VOID
CcGetActiveVacb (
    IN PSHARED_CACHE_MAP SharedCacheMap,
    OUT PVACB *Vacb,
    OUT PULONG Page,
    OUT PULONG Dirty
    )

/*++

Routine Description:

    This routine retrieves and clears the active page hint from a shared cache map.

    Originally, this routine is a macro.  To reduce the nonpaged footprint of the
    system we want to page as much as possible, and it turns out this was the only
    reason a substantial part of the cache manager wasn't.

Arguments:

    SharedCacheMap - Supplies the pointer to the SharedCacheMap for which the active
                Vacb is desired.

    Vacb - Receives the active Vacb

    Page - Receives the active Page #

    Dirty - Receives ACTIVE_PAGE_IS_DIRTY if the page has dirty data

Return Value:

    None.

Environment:

    Passive.

--*/

{
    KIRQL Irql;

    ExAcquireFastLock(&SharedCacheMap->ActiveVacbSpinLock, &Irql);
    *Vacb = SharedCacheMap->ActiveVacb;
    if (*Vacb != NULL) {
        *Page = SharedCacheMap->ActivePage;
        SharedCacheMap->ActiveVacb = NULL;
        *Dirty = SharedCacheMap->Flags & ACTIVE_PAGE_IS_DIRTY;
    }
    ExReleaseFastLock(&SharedCacheMap->ActiveVacbSpinLock, Irql);
}


VOID
CcSetActiveVacb (
    IN PSHARED_CACHE_MAP SharedCacheMap,
    IN OUT PVACB *Vacb,
    IN ULONG Page,
    IN ULONG Dirty
    )

/*++

Routine Description:

    This routine sets the active page hint for a shared cache map.

    Originally, this routine is a macro.  To reduce the nonpaged footprint of the
    system we want to page as much as possible, and it turns out this was the only
    reason a substantial part of the cache manager wasn't.

Arguments:

    SharedCacheMap - Supplies the pointer to the SharedCacheMap for which the active
                Vacb is desired.

    Vacb - Supplies the new active Vacb

    Page - Supplies the new active Page #

    Dirty - Supplies ACTIVE_PAGE_IS_DIRTY if the page has dirty data

Return Value:

    None.

Environment:

    Passive.

--*/

{
    KIRQL Irql;

    //
    //  When setting dirty, when we set ACTIVE_PAGE_IS_DIRTY the first time,
    //  we increment the dirty counts, and they never get decremented until
    //  CcFreeActiveVacb.  If we are trying to set and there is already an
    //  active Vacb *or* we are trying to set a clean one and the flag above
    //  is set, we do not allow it, and we just free the vacb (we only want
    //  to handle the clean transition in one place).
    //
    //  MP & UP cases are separately defined, because I do not trust the compiler
    //  to otherwise generate the optimal UP code.
    //

    //
    //  In the MP case, we test if we are setting the page dirty, because then
    //  we must acquire CcMasterSpinLock to diddle CcDirtyPages.
    //

    //
    //  In the UP case, any FastLock will do, so we just use the ActiveVacb lock, and do not
    //  explicitly acquire CcMasterSpinLock.
    //

#if !defined(NT_UP)
    if (Dirty) {
        CcAcquireMasterLock(&Irql);
        ExAcquireSpinLockAtDpcLevel(&SharedCacheMap->ActiveVacbSpinLock);
    } else {
        ExAcquireSpinLock(&SharedCacheMap->ActiveVacbSpinLock, &Irql);
    }
#else
    ExAcquireFastLock(&SharedCacheMap->ActiveVacbSpinLock, &Irql);
#endif

    do {
        if (SharedCacheMap->ActiveVacb == NULL) {
            if ((SharedCacheMap->Flags & ACTIVE_PAGE_IS_DIRTY) != Dirty) {
                if (Dirty) {
                    SharedCacheMap->ActiveVacb = *Vacb;
                    SharedCacheMap->ActivePage = Page;
                    *Vacb = NULL;
                    SetFlag(SharedCacheMap->Flags, ACTIVE_PAGE_IS_DIRTY);
                    CcTotalDirtyPages += 1;
                    SharedCacheMap->DirtyPages += 1;
                    if (SharedCacheMap->DirtyPages == 1) {
                        PLIST_ENTRY Blink;
                        PLIST_ENTRY Entry;
                        PLIST_ENTRY Flink;
                        PLIST_ENTRY Head;
                        Entry = &SharedCacheMap->SharedCacheMapLinks;
                        Blink = Entry->Blink;
                        Flink = Entry->Flink;
                        Blink->Flink = Flink;
                        Flink->Blink = Blink;
                        Head = &CcDirtySharedCacheMapList.SharedCacheMapLinks;
                        Blink = Head->Blink;
                        Entry->Flink = Head;
                        Entry->Blink = Blink;
                        Blink->Flink = Entry;
                        Head->Blink = Entry;
                        if (!LazyWriter.ScanActive) {
                            LazyWriter.ScanActive = TRUE;
#if !defined(NT_UP)
                            ExReleaseSpinLockFromDpcLevel(&SharedCacheMap->ActiveVacbSpinLock);
                            CcReleaseMasterLock(Irql);
#else
                            ExReleaseFastLock(&SharedCacheMap->ActiveVacbSpinLock, Irql);
#endif
                            KeSetTimer( &LazyWriter.ScanTimer,
                                        CcFirstDelay,
                                        &LazyWriter.ScanDpc );
                            break;
                        }
                    }
                }
            } else {
                SharedCacheMap->ActiveVacb = *Vacb;
                SharedCacheMap->ActivePage = Page;
                *Vacb = NULL;
            }
        }
#if !defined(NT_UP)
        if (Dirty) {
            ExReleaseSpinLockFromDpcLevel(&SharedCacheMap->ActiveVacbSpinLock);
            CcReleaseMasterLock(Irql);
        } else {
            ExReleaseSpinLock(&SharedCacheMap->ActiveVacbSpinLock, Irql);
        }
#else
        ExReleaseFastLock(&SharedCacheMap->ActiveVacbSpinLock, Irql);
#endif
        if (*Vacb != NULL) {
            CcFreeActiveVacb( SharedCacheMap, *Vacb, Page, Dirty);
        }
    } while (FALSE);
}
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\base\ntos\cache\preftchp.h ===
/*++

Copyright (c 1999 Microsoft Corporation

Module Name:

    preftchp.h

Abstract:

    This module contains the private definitions for the kernel mode
    prefetcher for optimizing demand paging. Page faults for a
    scenario are logged and the next time scenario starts, these pages
    are prefetched efficiently via asynchronous paging I/O.

Author:

    Stuart Sechrest (stuartse)
    Chuck Lenzmeier (chuckl)
    Cenk Ergan (cenke)

Revision History:

--*/

#ifndef _PREFTCHP_H
#define _PREFTCHP_H

//
// Define tags used in prefetcher routines.
//

#define CCPF_PREFETCHER_TAG         'fPcC'

#define CCPF_ALLOC_SCENARIO_TAG     'SPcC'
#define CCPF_ALLOC_TRACE_TAG        'TPcC'
#define CCPF_ALLOC_TRCBUF_TAG       'BPcC'
#define CCPF_ALLOC_SECTTBL_TAG      'sPcC'
#define CCPF_ALLOC_TRCDMP_TAG       'DPcC'
#define CCPF_ALLOC_QUERY_TAG        'qPcC'
#define CCPF_ALLOC_FILENAME_TAG     'FPcC'
#define CCPF_ALLOC_CONTEXT_TAG      'CPcC'
#define CCPF_ALLOC_INTRTABL_TAG     'IPcC'
#define CCPF_ALLOC_PREFSCEN_TAG     'pPcC'
#define CCPF_ALLOC_BOOTWRKR_TAG     'wPcC'
#define CCPF_ALLOC_VOLUME_TAG       'vPcC'
#define CCPF_ALLOC_READLIST_TAG     'LPcC'
#define CCPF_ALLOC_METADATA_TAG     'MPcC'

//
// Whether the scenario type is for a system-wide scenario, meaning that 
// only it can be active while running.
//

#define CCPF_IS_SYSTEM_WIDE_SCENARIO_TYPE(ScenarioType) \
    ((ScenarioType) == PfSystemBootScenarioType)

//
// In the kernel, we have to look for named objects under this
// directory for them to visible to Win32 prefetcher service.
//

#define CCPF_BASE_NAMED_OBJ_ROOT_DIR L"\\BaseNamedObjects"

//
// This is the invalid index value used with section tables.
//

#define CCPF_INVALID_TABLE_INDEX     (-1)

//
// This is the max number of file metadata that NTFS can prefetch
// at a time.
//

#define CCPF_MAX_FILE_METADATA_PREFETCH_COUNT 0x300

//
// Define structure to hold prefetcher parameters state.
//

typedef struct _CCPF_PREFETCHER_PARAMETERS {

    //
    // This is the named event that is used to signal the service that
    // parameters have been updated.
    //

    HANDLE ParametersChangedEvent;

    //
    // This is the registry key containing prefetch parameters.
    //
    
    HANDLE ParametersKey;

    //
    // Fields used in registering for change notify on parameters
    // registry key.
    //

    IO_STATUS_BLOCK RegistryWatchIosb;
    WORK_QUEUE_ITEM RegistryWatchWorkItem;
    ULONG RegistryWatchBuffer;

    //
    // System wide prefetching parameters. When using any parameters
    // whose update may cause problems [e.g. strings], get the
    // ParametersLock shared. When you need to update Parameters,
    // after getting the ParametersLock exclusive, bump
    // ParametersVersion before updating parameters.
    //

    PF_SYSTEM_PREFETCH_PARAMETERS Parameters;
    ERESOURCE ParametersLock;
    LONG ParametersVersion;

    //
    // Prefixes to registry values for different scenario types.
    //

    WCHAR *ScenarioTypePrefixes[PfMaxScenarioType];

    //
    // This is set to InitSafeBootMode during initialization.
    //
    
    ULONG SafeBootMode;

} CCPF_PREFETCHER_PARAMETERS, *PCCPF_PREFETCHER_PARAMETERS;

//
// Define structure to hold prefetcher's global state.
//

typedef struct _CCPF_PREFETCHER_GLOBALS {

    //
    // List of active traces and the lock to protect it. The number
    // of items on this list is a global, since it is used by other
    // kernel components to make a fast check.
    //

    LIST_ENTRY ActiveTraces;
    KSPIN_LOCK ActiveTracesLock;

    //
    // Pointer to the global trace if one is active. While there is a
    // global trace active we don't trace & prefetch other scenarios.
    // Boot tracing is an example of global trace.
    //

    struct _CCPF_TRACE_HEADER *SystemWideTrace;

    //
    // List and number of saved completed prefetch traces and lock to
    // protect it.
    //

    LIST_ENTRY CompletedTraces; 
    FAST_MUTEX CompletedTracesLock;
    LONG NumCompletedTraces;

    //
    // This is the named event that is used to signal the service that
    // there are traces ready for it to get.
    //

    HANDLE CompletedTracesEvent;

    //
    // Prefetcher parameters.
    //

    CCPF_PREFETCHER_PARAMETERS Parameters;

} CCPF_PREFETCHER_GLOBALS, *PCCPF_PREFETCHER_GLOBALS;

//
// Reference count structure.
//

typedef struct _CCPF_REFCOUNT {

    //
    // When initialized or reset, this reference count starts from
    // 1. When exclusive access is granted it stays at 0: even if it
    // may get bumped by an AddRef by mistake, it will return to 0.
    //

    LONG RefCount;

    //
    // This is set when somebody wants to gain exclusive access to the
    // protected structure.
    //

    LONG Exclusive;   

} CCPF_REFCOUNT, *PCCPF_REFCOUNT;

//
// Define structures used for logging pagefaults:
//

//
// One of these is logged for every page fault.
//

typedef struct _CCPF_LOG_ENTRY {

    //
    // File offset of the page that was faulted.
    //
    
    ULONG FileOffset;

    //
    // Index into the section table in the trace header that helps us
    // identify the file.
    //

    USHORT SectionId;

    //
    // Whether this page was faulted as an image page or data page.
    //

    BOOLEAN IsImage;

    //
    // Whether this is a fault that happened in the process in which
    // the scenario is associated with.
    //

    BOOLEAN InProcess;

} CCPF_LOG_ENTRY, *PCCPF_LOG_ENTRY;

//
// CCPF_LOG_ENTRIES is a buffer of log entries with a small header containing
// an index to the highest used entry. This is used so that a trace can consist
// of several smaller trace buffers instead of one large, fixed-size buffer.
// The current index must be contained in the buffer in order to allow entries
// to be added without acquiring a spin lock.
//

typedef struct _CCPF_LOG_ENTRIES {

    //
    // Link used to put this buffer in the traces's buffer list.
    //

    LIST_ENTRY TraceBuffersLink;

    //
    // NumEntries is the current number of entries in the buffer. MaxEntries
    // is the maximum number of entries that can be placed in the buffer.
    // (Currently MaxEntries always equals CCPF_TRACE_BUFFER_MAX_ENTRIES.)
    //

    LONG NumEntries;
    LONG MaxEntries;

    //
    // The logged entries start here.
    //

    CCPF_LOG_ENTRY Entries[1];

} CCPF_LOG_ENTRIES, *PCCPF_LOG_ENTRIES;

//
// CCPF_TRACE_BUFFER_SIZE is the size of an allocated CCPF_LOG_ENTRIES structure
// (including the header). This should be a multiple of the page size.
//

#define CCPF_TRACE_BUFFER_SIZE 8192

//
// CCPF_TRACE_BUFFER_MAX_ENTRIES is the number of log entries that will fit in
// a trace buffer of size CCPF_TRACE_BUFFER_SIZE.
//

#define CCPF_TRACE_BUFFER_MAX_ENTRIES (((CCPF_TRACE_BUFFER_SIZE - sizeof(CCPF_LOG_ENTRIES)) / sizeof(CCPF_LOG_ENTRY)) + 1)

//
// This structure associates a SectionObjectPointer with a file name
// in the runtime trace buffer. There is a table of these in the trace
// header and every page fault has an index into this table denoting
// which file it is to.
//

typedef struct DECLSPEC_ALIGN(MEMORY_ALLOCATION_ALIGNMENT) _CCPF_SECTION_INFO {

    //
    // Section info entries are kept in a hash. This field is
    // InterlockedCompareExchange'd to denote that it is in use.
    //

    LONG EntryValid;

    //
    // Whether this section is used for file systems to map metafile.
    //

    ULONG Metafile:1;
    ULONG Unused:31;

    //
    // SectionObjectPointer used as a unique identifier to a file
    // mapping. The same file may be mapped using a number of file
    // objects, but the SectionObjectPointer fields of all those file
    // objects will be the same.
    //

    PSECTION_OBJECT_POINTERS SectionObjectPointer;

    //
    // All references to all file objects for a file may be released,
    // and a new file may be opened using the same memory block for
    // its FCB at which point the SectionObjectPointer would no longer
    // be unique. This would result in pagefaults getting logged under
    // the entry for the file that was closed. The consequences would
    // be misprefetching wrong pages from a couple of sections until
    // the scenario corrects itself by looking at new traces. By
    // keeping track of these two fields of the SectionObjectPointers
    // to check for uniqueness we make this case very unlikely to
    // happen. The other solutions we thought of to solve this issue
    // 100% were too costly in terms of complication or efficiency.
    //

    //
    // In order to avoid adding two entries to the table for the
    // section when it is used as data first then image (or vice
    // versa) it is assumed that it is still the same section if the
    // current entry's Data/ImageSectionObject is NULL but the
    // Data/ImageSectionObject of the section we are logging a new
    // pagefault to is not. Then we try to update the NULL pointer
    // with the new value using InterlockedCompareExchangePointer.
    //

    PVOID DataSectionObject;
    PVOID ImageSectionObject;

    //
    // This may point to a file object that we have referenced to
    // ensure the section object stays around until we can get a name.
    //

    PFILE_OBJECT ReferencedFileObject;

    //
    // The name is set as soon as we can get a file name. We cannot
    // access the file name while running at a high IRQL.
    //

    WCHAR *FileName;

    //
    // We queue a section to the get-file-name list using this field.
    //

    SINGLE_LIST_ENTRY GetNameLink;

} CCPF_SECTION_INFO, *PCCPF_SECTION_INFO;

//
// This structure contains information on a volume on which sections
// in the trace are located on.
//

typedef struct _CCPF_VOLUME_INFO {
    
    //
    // Link in the trace's volume list.
    //

    LIST_ENTRY VolumeLink;

    //
    // Volume creation time and serial number used to identify the
    // volume in case its NT/device path e.g. \Device\HarddiskVolume1
    // changes.
    //

    LARGE_INTEGER CreationTime;
    ULONG SerialNumber;

    //
    // Current NT/device path for the volume and its length in
    // characters excluding terminating NUL.
    //

    ULONG VolumePathLength;
    WCHAR VolumePath[1];

} CCPF_VOLUME_INFO, *PCCPF_VOLUME_INFO;

//
// This is the runtime trace header for a scenario.
//

typedef struct _CCPF_TRACE_HEADER {

    //
    // Magic number identifying this structure as a trace.
    //

    ULONG Magic;

    //
    // Link in the active traces list.
    //

    LIST_ENTRY ActiveTracesLink;

    //
    // Scenario id for which we are acquiring this trace.
    //

    PF_SCENARIO_ID ScenarioId;

    //
    // Type of this scenario.
    //

    PF_SCENARIO_TYPE ScenarioType;

    //
    // CurrentTraceBuffer is the active trace buffer. 
    //
    
    PCCPF_LOG_ENTRIES CurrentTraceBuffer;

    //
    // This is the list of trace buffers for this trace.
    // CurrentTraceBuffer is the last element. Both this list and
    // CurrentTraceBuffer are protected by TraceBufferSpinLock.
    //

    LIST_ENTRY TraceBuffersList;
    ULONG NumTraceBuffers;
    KSPIN_LOCK TraceBufferSpinLock;

    //
    // This is the table for section info.
    //
    
    PCCPF_SECTION_INFO SectionInfoTable;
    LONG NumSections;
    LONG MaxSections;
    ULONG SectionTableSize;

    //
    // We don't log timestamps with page faults but it helps to know
    // how many we are logging per given time. This information can be
    // used to mark the end of a scenario.
    //

    KTIMER TraceTimer;
    LARGE_INTEGER TraceTimerPeriod;
    KDPC TraceTimerDpc;
    KSPIN_LOCK TraceTimerSpinLock;
    
    //
    // This array contains the number of page faults logged per trace
    // period.
    //

    ULONG FaultsPerPeriod[PF_MAX_NUM_TRACE_PERIODS];
    LONG LastNumFaults;
    LONG CurPeriod;
    
    //
    // NumFaults is the number of faults that have been logged so far, in all
    // trace buffers. MaxFaults is the maximum number of page faults we will
    // log, in all trace buffers.
    //

    LONG NumFaults;
    LONG MaxFaults;

    //
    // This workitem is queued to get names for file objects we are
    // logging page faults to. First GetFileNameWorkItemQueued should
    // be InterlockedCompareExchange'd from 0 to 1 and a reference
    // should be acquired on the scenario. The workitem will free this
    // reference just before it completes.
    //

    WORK_QUEUE_ITEM GetFileNameWorkItem;
    LONG GetFileNameWorkItemQueued;

    //
    // Sections for which we have to get names are pushed and popped
    // to/from this slist.
    //

    SLIST_HEADER SectionsWithoutNamesList;

    //
    // Because we don't want to incur the cost of queuing a work item
    // to get file names for every one or two sections, the worker we
    // queue will wait on this event before returning. The event can
    // be signaled when a new section comes, or when the scenario is
    // ending.
    //

    KEVENT GetFileNameWorkerEvent;

    //
    // This is the process we are associated with.
    //

    PEPROCESS Process;

    //
    // This is the removal reference count protecting us.
    //

    CCPF_REFCOUNT RefCount;

    //
    // This work item can be queued to call the end trace function if
    // the trace times out or we log to many entries etc. First
    // EndTraceCalled should be InterlockedCompareExchange'd from 0 to
    // 1.
    //

    WORK_QUEUE_ITEM EndTraceWorkItem;

    //
    // Before anybody calls end trace function, they have to
    // InterlockedCompareExchange this from 0 to 1 to ensure this
    // function gets called only once.
    //

    LONG EndTraceCalled;

    //
    // This is the list of volumes the sections we are tracing are
    // located on. It is sorted lexically by the volume NT/device path.
    //

    LIST_ENTRY VolumeList;
    ULONG NumVolumes;

    //
    // This is the pointer to the built trace dump from this runtime
    // trace structure and the status with which dumping failed if it
    // did.
    //
    
    struct _CCPF_TRACE_DUMP *TraceDump;
    NTSTATUS TraceDumpStatus;

    //
    // System time when we started tracing.
    //
    
    LARGE_INTEGER LaunchTime;

} CCPF_TRACE_HEADER, *PCCPF_TRACE_HEADER;

//
// This structure is used to save completed traces in a list. The
// trace extends beyond this structure as necessary.
//

typedef struct _CCPF_TRACE_DUMP {
    
    //
    // Link in the completed traces list.
    //

    LIST_ENTRY CompletedTracesLink;
    
    //
    // Completed trace.
    //

    PF_TRACE_HEADER Trace;

} CCPF_TRACE_DUMP, *PCCPF_TRACE_DUMP;

//
// This structure contains information for a volume used during prefetching.
//

typedef struct _CCPF_PREFETCH_VOLUME_INFO {

    //
    // Link in the lists this volume gets put on.
    //

    LIST_ENTRY VolumeLink;

    //
    // Volume path.
    //

    WCHAR *VolumePath;
    ULONG VolumePathLength;

    //
    // Handle to the opened volume.
    //

    HANDLE VolumeHandle;

} CCPF_PREFETCH_VOLUME_INFO, *PCCPF_PREFETCH_VOLUME_INFO;

//
// This structure is used to keep track of prefetched pages & context.
//

//
// Note: This structure is used as a stack variable. Don't add events
// etc, without changing that.
//

typedef struct _CCPF_PREFETCH_HEADER {

    //
    // Pointer to prefetch instructions. The instructions should not
    // be removed / freed until the prefetch header is cleaned up.
    // E.g. VolumeNodes may point to volume paths in the scenario.
    //

    PPF_SCENARIO_HEADER Scenario;

    //
    // Nodes for the volumes we are going to prefetch from.
    //

    PCCPF_PREFETCH_VOLUME_INFO VolumeNodes;

    //
    // List of volumes we won't prefetch on.
    //

    LIST_ENTRY BadVolumeList;

    //
    // List of volumes we have opened. They are opened with the following 
    // flags: FILE_READ_ATTRIBUTES | FILE_WRITE_ATTRIBUTES | SYNCHRONIZE
    //

    LIST_ENTRY OpenedVolumeList;

} CCPF_PREFETCH_HEADER, *PCCPF_PREFETCH_HEADER;

//
// Define types of prefetching CcPfPrefetchSections can be called to
// perform.
//

typedef enum _CCPF_PREFETCH_TYPE {
    CcPfPrefetchAllDataPages,
    CcPfPrefetchAllImagePages,
    CcPfPrefetchPartOfDataPages,
    CcPfPrefetchPartOfImagePages,
    CcPfMaxPrefetchType
} CCPF_PREFETCH_TYPE, *PCCPF_PREFETCH_TYPE;

//
// This structure stands for the position in the prefetch
// instructions. It is used and updated by CcPfPrefetchSections when
// prefetching parts of a scenario at a time.
//

typedef struct _CCPF_PREFETCH_CURSOR {
    
    //
    // Index of the current section and the page in that section.
    //

    ULONG SectionIdx;
    ULONG PageIdx;
    
} CCPF_PREFETCH_CURSOR, *PCCPF_PREFETCH_CURSOR;

//
// This type is used in CcPfPrefetchSections.
//

typedef struct _SECTION *PSECTION;

//
// Define types of information CcPfQueryScenarioInformation can be
// asked to return.
//

typedef enum _CCPF_SCENARIO_INFORMATION_TYPE {
    CcPfBasicScenarioInformation,
    CcPfBootScenarioInformation,
    CcPfMaxScenarioInformationType
} CCPF_SCENARIO_INFORMATION_TYPE, *PCCPF_SCENARIO_INFORMATION_TYPE;

//
// This structure contains basic scenario information.
//

typedef struct _CCPF_BASIC_SCENARIO_INFORMATION {
    
    //
    // Number of pages that will be prefetched as data pages.
    //
    
    ULONG NumDataPages;

    //
    // Number of pages that will be prefetched as image pages.
    //

    ULONG NumImagePages;

    //
    // Number of sections for which only data pages will be
    // prefetched.
    //

    ULONG NumDataOnlySections;

    //
    // Number of sections for which only image pages will be
    // prefetched excluding the header page.
    //

    ULONG NumImageOnlySections;

    //
    // Number of ignored pages.
    //
    
    ULONG NumIgnoredPages;

    //
    // Number of ignored sections.
    //

    ULONG NumIgnoredSections;

} CCPF_BASIC_SCENARIO_INFORMATION, *PCCPF_BASIC_SCENARIO_INFORMATION;

//
// Routines used in the core prefetcher.
//

//
// Routines used in prefetch tracing.
//

NTSTATUS
CcPfBeginTrace(
    IN PF_SCENARIO_ID *ScenarioId,
    IN PF_SCENARIO_TYPE ScenarioType,
    IN HANDLE ProcessHandle
    );

NTSTATUS
CcPfActivateTrace(
    IN PCCPF_TRACE_HEADER Scenario
    );

NTSTATUS
CcPfDeactivateTrace(
    IN PCCPF_TRACE_HEADER Scenario
    );

NTSTATUS
CcPfEndTrace(
    IN PCCPF_TRACE_HEADER Trace
    );

NTSTATUS
CcPfBuildDumpFromTrace(
    OUT PCCPF_TRACE_DUMP *TraceDump, 
    IN PCCPF_TRACE_HEADER RuntimeTrace
    );

VOID
CcPfCleanupTrace(
    IN PCCPF_TRACE_HEADER Trace
    );

VOID
CcPfTraceTimerRoutine(
    IN PKDPC Dpc,
    IN PVOID DeferredContext,
    IN PVOID SystemArgument1,
    IN PVOID SystemArgument2
    );

NTSTATUS
CcPfCancelTraceTimer(
    IN PCCPF_TRACE_HEADER Trace
    );

VOID
CcPfEndTraceWorkerThreadRoutine(
    PVOID Parameter
    );

VOID
CcPfGetFileNamesWorkerRoutine(
    PVOID Parameter
    );

LONG
CcPfLookUpSection(
    PCCPF_SECTION_INFO Table,
    ULONG TableSize,
    PSECTION_OBJECT_POINTERS SectionObjectPointer,
    PLONG AvailablePosition
    );

NTSTATUS
CcPfGetCompletedTrace (
    PVOID Buffer,
    ULONG BufferSize,
    PULONG ReturnSize
    );               

NTSTATUS
CcPfUpdateVolumeList(
    PCCPF_TRACE_HEADER Trace,
    WCHAR *VolumePath,
    ULONG VolumePathLength
    );
    
//
// Routines used for prefetching and dealing with prefetch instructions.
//

NTSTATUS
CcPfPrefetchScenario (
    PPF_SCENARIO_HEADER Scenario
    );

NTSTATUS
CcPfPrefetchSections(
    IN PCCPF_PREFETCH_HEADER PrefetchHeader,
    IN CCPF_PREFETCH_TYPE PrefetchType,
    OPTIONAL IN PCCPF_PREFETCH_CURSOR StartCursor,
    OPTIONAL ULONG TotalPagesToPrefetch,
    OPTIONAL OUT PULONG NumPagesPrefetched,
    OPTIONAL OUT PCCPF_PREFETCH_CURSOR EndCursor
    );

NTSTATUS
CcPfPrefetchMetadata(
    IN PCCPF_PREFETCH_HEADER PrefetchHeader
    );

NTSTATUS
CcPfPrefetchDirectoryContents(
    WCHAR *DirectoryPath,
    WCHAR DirectoryPathlength
    );

NTSTATUS
CcPfPrefetchFileMetadata(
    HANDLE VolumeHandle,
    PFILE_PREFETCH FilePrefetch
    );

VOID
CcPfInitializePrefetchHeader (
    OUT PCCPF_PREFETCH_HEADER PrefetchHeader
);

VOID
CcPfCleanupPrefetchHeader (
    IN PCCPF_PREFETCH_HEADER PrefetchHeader
    );

NTSTATUS
CcPfGetPrefetchInstructions(
    IN PPF_SCENARIO_ID ScenarioId,
    IN PF_SCENARIO_TYPE ScenarioType,
    OUT PPF_SCENARIO_HEADER *Scenario
    );

NTSTATUS
CcPfQueryScenarioInformation(
    IN PPF_SCENARIO_HEADER Scenario,
    IN CCPF_SCENARIO_INFORMATION_TYPE InformationType,
    OUT PVOID Buffer,
    IN ULONG BufferSize,
    OUT PULONG RequiredSize
    );

NTSTATUS
CcPfOpenVolumesForPrefetch (
    IN PCCPF_PREFETCH_HEADER PrefetchHeader
    );

PCCPF_PREFETCH_VOLUME_INFO 
CcPfFindPrefetchVolumeInfoInList(
    WCHAR *Path,
    PLIST_ENTRY List
    );
    
NTSTATUS
CcPfGetSectionObject(
    IN PUNICODE_STRING FileName,
    IN LOGICAL ImageSection,
    OUT PVOID* SectionObject,
    OUT PFILE_OBJECT* FileObject,
    OUT HANDLE* FileHandle
    );

//
// Routines used for application launch prefetching.
//

BOOLEAN
CcPfIsHostingApplication(
    IN PWCHAR ExecutableName
    );

NTSTATUS
CcPfScanCommandLine(
    OUT PULONG PrefetchHint,
    OPTIONAL OUT PULONG HashId
    );

//
// Reference count functions:
//

VOID
CcPfInitializeRefCount(
    PCCPF_REFCOUNT RefCount
    );

NTSTATUS
FASTCALL
CcPfAddRef(
    PCCPF_REFCOUNT RefCount
    );

VOID
FASTCALL
CcPfDecRef(
    PCCPF_REFCOUNT RefCount
    );

NTSTATUS
FASTCALL
CcPfAddRefEx(
    PCCPF_REFCOUNT RefCount,
    ULONG Count
    );

VOID
FASTCALL
CcPfDecRefEx(
    PCCPF_REFCOUNT RefCount,
    ULONG Count
    );

NTSTATUS
CcPfAcquireExclusiveRef(
    PCCPF_REFCOUNT RefCount
    );

PCCPF_TRACE_HEADER
CcPfReferenceProcessTrace(
    PEPROCESS Process
    );

PCCPF_TRACE_HEADER
CcPfRemoveProcessTrace(
    PEPROCESS Process
    );

NTSTATUS
CcPfAddProcessTrace(
    PEPROCESS Process,
    PCCPF_TRACE_HEADER Trace
    );

//
// Utility routines.
//

PWCHAR
CcPfFindString (
    PUNICODE_STRING SearchIn,
    PUNICODE_STRING SearchFor
    );
    
ULONG
CcPfHashValue(
    PVOID Key,
    ULONG Len
    );

NTSTATUS 
CcPfIsVolumeMounted (
    IN WCHAR *VolumePath,
    OUT BOOLEAN *VolumeMounted
    );
    
NTSTATUS
CcPfQueryVolumeInfo (
    IN WCHAR *VolumePath,
    OPTIONAL OUT HANDLE *VolumeHandleOut,
    OUT PLARGE_INTEGER CreationTime,
    OUT PULONG SerialNumber
    );
    
//
// Declarations and definitions for prefetcher parameters.
//

//
// Define location of registry key for prefetch parameters.
//

#define CCPF_PARAMETERS_KEY L"\\Registry\\Machine\\System\\CurrentControlSet\\Control\\Session Manager\\Memory Management\\PrefetchParameters"

//
// Maximum characters in registry value names for prefetch parameters.
//

#define CCPF_MAX_PARAMETER_NAME_LENGTH  80

//
// Maximum bytes needed to query a prefetch parameter from the
// registry. Currently our largest parameter would be the hosting
// application list.
//

#define CCPF_MAX_PARAMETER_VALUE_BUFFER ((PF_HOSTING_APP_LIST_MAX_CHARS * sizeof(WCHAR)) + sizeof(KEY_VALUE_PARTIAL_INFORMATION))

NTSTATUS
CcPfParametersInitialize (
    PCCPF_PREFETCHER_PARAMETERS PrefetcherParameters
    );
    
VOID
CcPfParametersSetDefaults (
    PCCPF_PREFETCHER_PARAMETERS PrefetcherParameters
    );
    
NTSTATUS
CcPfParametersRead (
    PCCPF_PREFETCHER_PARAMETERS PrefetcherParameters
    );
 
NTSTATUS
CcPfParametersSave (
    PCCPF_PREFETCHER_PARAMETERS PrefetcherParameters
    );

NTSTATUS
CcPfParametersVerify (
    PPF_SYSTEM_PREFETCH_PARAMETERS Parameters
    );

VOID
CcPfParametersWatcher (
    IN PVOID Context
    );

NTSTATUS
CcPfParametersSetChangedEvent (
    PCCPF_PREFETCHER_PARAMETERS PrefetcherParameters
    );

NTSTATUS
CcPfGetParameter (
    HANDLE ParametersKey,
    WCHAR *ValueNameBuffer,
    ULONG ValueType,
    PVOID Value,
    ULONG *ValueSize
    );

NTSTATUS
CcPfSetParameter (
    HANDLE ParametersKey,
    WCHAR *ValueNameBuffer,
    ULONG ValueType,
    PVOID Value,
    ULONG ValueSize
    );

LOGICAL
CcPfDetermineEnablePrefetcher(
    VOID
    );

//
// Declarations and definitions for boot prefetching.
//

//
// Value name under prefetcher parameters key where we store how long
// video initialization took during boot.
//

#define CCPF_VIDEO_INIT_TIME_VALUE_NAME      L"VideoInitTime"

//
// How long (in milliseconds) video initialization could take max. This value 
// is used to sanity check the value read from the registry.
//

#define CCPF_MAX_VIDEO_INIT_TIME             (10 * 1000) // 10 seconds

//
// Value name under prefetcher parameters key where we store how many
// pages we should try to prefetch per second of video initialization.
//

#define CCPF_VIDEO_INIT_PAGES_PER_SECOND_VALUE_NAME L"VideoInitPagesPerSecond"

//
// Sanity check maximum value for video init pages per second.
//

#define CCPF_VIDEO_INIT_MAX_PAGES_PER_SECOND        128000

//
// How many pages will we try to prefetch in parallel to video initialization
// per second of it.
//

#define CCPF_VIDEO_INIT_DEFAULT_PAGES_PER_SECOND    1500

//
// Maximum number of chunks in which we will prefetch for boot.
//

#define CCPF_MAX_BOOT_PREFETCH_PHASES        16

//
// Different phases of boot we return page counts for in
// CCPF_BOOT_SCENARIO_INFORMATION.
//

typedef enum _CCPF_BOOT_SCENARIO_PHASE {

    CcPfBootScenDriverInitPhase,
    CcPfBootScenSubsystemInitPhase,
    CcPfBootScenSystemProcInitPhase,
    CcPfBootScenServicesInitPhase,
    CcPfBootScenUserInitPhase,
    CcPfBootScenMaxPhase

} CCPF_BOOT_SCENARIO_PHASE, *PCCPF_BOOT_SCENARIO_PHASE;

//
// Define structure to hold boot prefetching state.
//

typedef struct _CCPF_BOOT_PREFETCHER {

    //
    // These events are signaled by the boot prefetch worker when 
    // it has completed prefetching for the specified phase. 
    //

    KEVENT SystemDriversPrefetchingDone;
    KEVENT PreSmssPrefetchingDone;
    KEVENT VideoInitPrefetchingDone;

    //
    // This event will be signaled when we start initializing video
    // on the console. Boot prefetcher waits on this event to perform
    // prefetching parallel to video initialization.
    //
    
    KEVENT VideoInitStarted;

} CCPF_BOOT_PREFETCHER, *PCCPF_BOOT_PREFETCHER;

//
// This structure contains boot scenario information.
//

typedef struct _CCPF_BOOT_SCENARIO_INFORMATION {

    //
    // These are the number of data/image pages to prefetch for the
    // different phase of boot.
    //

    ULONG NumDataPages[CcPfBootScenMaxPhase];
    ULONG NumImagePages[CcPfBootScenMaxPhase];
    
} CCPF_BOOT_SCENARIO_INFORMATION, *PCCPF_BOOT_SCENARIO_INFORMATION;

//
// We will be prefetching data and image pages for boot in parts. Since the
// code is mostly same to prefetch the data and image pages, we keep track
// of where we left off and what to prefetch next in a common boot prefetch 
// cursor structure and make two passes (first for data, then for image).
//

typedef struct _CCPF_BOOT_PREFETCH_CURSOR {

    //
    // Start & end cursors passed to prefetch sections function.
    //

    CCPF_PREFETCH_CURSOR StartCursor;
    CCPF_PREFETCH_CURSOR EndCursor;

    //
    // How to prefetch (e.g. part of data pages or part of image pages).
    //

    CCPF_PREFETCH_TYPE PrefetchType; 

    //
    // How many pages to prefetch per phase.
    //

    ULONG NumPagesForPhase[CCPF_MAX_BOOT_PREFETCH_PHASES];
   
} CCPF_BOOT_PREFETCH_CURSOR, *PCCPF_BOOT_PREFETCH_CURSOR;

//
// Boot prefetching routines.
//

VOID
CcPfBootWorker(
    PCCPF_BOOT_PREFETCHER BootPrefetcher
    );

NTSTATUS
CcPfBootQueueEndTraceTimer (
    PLARGE_INTEGER Timeout
    );    

VOID
CcPfEndBootTimerRoutine(
    IN PKDPC Dpc,
    IN PVOID DeferredContext,
    IN PVOID SystemArgument1,
    IN PVOID SystemArgument2
    );

//
// Debug routines.
//

#if CCPF_DBG

NTSTATUS
CcPfWriteToFile(
    IN PVOID pData,
    IN ULONG Size,
    IN WCHAR *pFileName
    );

#endif // CCPF_DBG

//
// Define useful macros. As with all macros, must be careful of
// parameter reevalation. Don't use expressions as macro parameters.
//

#define CCPF_MAX(A,B) (((A) >= (B)) ? (A) : (B))
#define CCPF_MIN(A,B) (((A) <= (B)) ? (A) : (B))
        
//
// Define debugging macros:
//

//
// Define the component ID we use.
//

#define CCPFID     DPFLTR_PREFETCHER_ID

//
// Define DbgPrintEx levels.
//

#define PFERR      DPFLTR_ERROR_LEVEL
#define PFWARN     DPFLTR_WARNING_LEVEL
#define PFTRC      DPFLTR_TRACE_LEVEL
#define PFINFO     DPFLTR_INFO_LEVEL
#define PFPREF     4
#define PFPRFD     5
#define PFPRFF     6
#define PFPRFZ     7
#define PFTRAC     8
#define PFTMR      9
#define PFNAME     10
#define PFNAMS     11
#define PFLKUP     12
#define PFBOOT     13

//
// DbgPrintEx levels 20 - 31 are reserved for the service.
//

//
//  This may help you determine what to set the DbgPrintEx mask.
//
//  3 3 2 2  2 2 2 2  2 2 2 2  1 1 1 1   1 1 1 1  1 1 0 0  0 0 0 0  0 0 0 0
//  1 0 9 8  7 6 5 4  3 2 1 0  9 8 7 6   5 4 3 2  1 0 9 8  7 6 5 4  3 2 1 0
//  _ _ _ _  _ _ _ _  _ _ _ _  _ _ _ _   _ _ _ _  _ _ _ _  _ _ _ _  _ _ _ _
//

//
// CCPF_DBG can be defined if you want to turn on asserts and debug
// prints in prefetcher code but you do not want to have a checked
// kernel. Defining CCPF_DBG overrides defining DBG.
//

#if CCPF_DBG

NTSYSAPI
VOID
NTAPI
RtlAssert(
    PVOID FailedAssertion,
    PVOID FileName,
    ULONG LineNumber,
    PCHAR Message
    );

#define DBGPR(x) DbgPrintEx x
#define CCPF_ASSERT(x) if (!(x)) RtlAssert(#x, __FILE__, __LINE__, NULL )

#else  // CCPF_DBG

//
// If CCPF_DBG is not defined, build with debug prints and asserts
// only on checked build.
//

#if DBG

#define DBGPR(x) DbgPrintEx x
#define CCPF_ASSERT(x) ASSERT(x)

#else // DBG

//
// On a free build we don't compile with debug prints or asserts.
//

#define DBGPR(x)
#define CCPF_ASSERT(x)

#endif // DBG

#endif // CCPF_DBG

#endif // _PREFTCHP_H
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\base\ntos\cache\prefetch.c ===
/*++

Copyright (c) 1999 Microsoft Corporation

Module Name:

    prefetch.c

Abstract:

    This module contains the prefetcher for optimizing demand
    paging. Page faults for a scenario are logged and the next time
    scenario starts, these pages are prefetched efficiently via
    asynchronous paging I/O.

Author:

    Arthur Zwiegincew (arthurz) 13-May-1999
    Stuart Sechrest (stuartse)  15-Jul-1999
    Chuck Lenzmeier (chuckl)    15-Mar-2000
    Cenk Ergan (cenke)          15-Mar-2000

Revision History:

--*/

#include "cc.h"
#include "zwapi.h"
#include "prefetch.h"
#include "preftchp.h"
#include "stdio.h"
#include "stdlib.h"

//
// Mark pagable routines to save footprint.
//

#ifdef ALLOC_PRAGMA
#pragma alloc_text(INIT, CcPfInitializePrefetcher)
#pragma alloc_text(PAGE, CcPfBeginAppLaunch)
#pragma alloc_text(PAGE, CcPfBeginTrace)
#pragma alloc_text(PAGE, CcPfGetPrefetchInstructions)
#pragma alloc_text(PAGE, CcPfQueryScenarioInformation)
#pragma alloc_text(PAGE, CcPfPrefetchFileMetadata)
#pragma alloc_text(PAGE, CcPfPrefetchDirectoryContents)
#pragma alloc_text(PAGE, CcPfPrefetchMetadata)
#pragma alloc_text(PAGE, CcPfPrefetchScenario)
#pragma alloc_text(PAGE, CcPfPrefetchSections)
#pragma alloc_text(PAGE, CcPfOpenVolumesForPrefetch)
#pragma alloc_text(PAGE, CcPfUpdateVolumeList)
#pragma alloc_text(PAGE, CcPfFindString)
#pragma alloc_text(PAGE, CcPfIsVolumeMounted)
#pragma alloc_text(PAGE, CcPfQueryVolumeInfo)
#pragma alloc_text(PAGE, CcPfEndTrace)
#pragma alloc_text(PAGE, CcPfBuildDumpFromTrace)
#pragma alloc_text(PAGE, CcPfCleanupTrace)
#pragma alloc_text(PAGE, CcPfInitializePrefetchHeader)
#pragma alloc_text(PAGE, CcPfCleanupPrefetchHeader)
#pragma alloc_text(PAGE, CcPfEndTraceWorkerThreadRoutine)
#pragma alloc_text(PAGE, CcPfInitializeRefCount)
#pragma alloc_text(PAGE, CcPfAcquireExclusiveRef)
#pragma alloc_text(PAGE, CcPfGetSectionObject)
#pragma alloc_text(PAGE, CcPfScanCommandLine)
#pragma alloc_text(PAGE, CcPfGetCompletedTrace)
#pragma alloc_text(PAGE, CcPfGetFileNamesWorkerRoutine)
#pragma alloc_text(PAGE, CcPfSetPrefetcherInformation)
#pragma alloc_text(PAGE, CcPfQueryPrefetcherInformation)
#pragma alloc_text(PAGE, CcPfProcessExitNotification)
#pragma alloc_text(PAGE, PfWithinBounds)
#pragma alloc_text(PAGE, PfVerifyScenarioId)
#pragma alloc_text(PAGE, PfVerifyScenarioBuffer)
#pragma alloc_text(PAGE, PfVerifyTraceBuffer)
#endif

//
// Globals:
//

//
// Whether prefetching is enabled.
//

LOGICAL CcPfEnablePrefetcher = 0;

//
// Number of active prefetcher traces.
//

LONG CcPfNumActiveTraces = 0;

//
// This structure contains prefetcher globals except the ones above
// that are accessed by other kernel components. It is important that
// this structure is initialized to zeros.
//

CCPF_PREFETCHER_GLOBALS CcPfGlobals = {0};

//
// Routines exported to other kernel components:
//
 
NTSTATUS
CcPfInitializePrefetcher(
    VOID
    )

/*++

Routine Description:

    This routine is called to initialize the prefetcher. 

Arguments:

    None.

Return Value:

    Status.

Environment:

    Kernel mode. IRQL == PASSIVE_LEVEL.

Notes:

    The code & local constants for this function gets discarded after system boots.   

--*/

{   
    DBGPR((CCPFID,PFTRC,"CCPF: InitializePrefetcher()\n"));

    //
    // Since CcPfGlobals is zeroed in its global definition e.g. CcPfGlobals = {0};
    // we don't have to initialize:
    //
    // NumCompletedTraces
    // CompletedTracesEvent
    //

    //
    // Initialize the active traces list and lock.
    //

    InitializeListHead(&CcPfGlobals.ActiveTraces);
    KeInitializeSpinLock(&CcPfGlobals.ActiveTracesLock);

    //
    // Initialize list of saved completed prefetch traces and its lock.
    //

    InitializeListHead(&CcPfGlobals.CompletedTraces);
    ExInitializeFastMutex(&CcPfGlobals.CompletedTracesLock);

    //
    // Initialize prefetcher parameters.
    //

    CcPfParametersInitialize(&CcPfGlobals.Parameters);
    
    //
    // Determine from the global parameters if the prefetcher is
    // enabled and update the global enable status.
    //

    CcPfDetermineEnablePrefetcher();

    //
    // Fall through with status.
    //

    return STATUS_SUCCESS;
}

NTSTATUS
CcPfBeginAppLaunch(
    PEPROCESS Process,
    PVOID Section
    )

/*++

Routine Description:

    This routine is called when the first user thread is starting up
    in the process. It may attempt to access the PEB for the command 
    line parameters.

Arguments:

    Process - Pointer to new process created for the application.

    Section - Pointer to section mapped to newly created process.

Return Value:

    Status.

Environment:

    Kernel mode. IRQL == PASSIVE_LEVEL.

--*/

{
    LARGE_INTEGER CurrentTime;
    LARGE_INTEGER TimeSinceLastLaunch;
    PPF_SCENARIO_HEADER Scenario;
    NTSTATUS Status;
    PF_SCENARIO_ID ScenarioId;
    ULONG NameNumChars;
    ULONG PathNumChars;
    WCHAR *CurCharPtr;
    WCHAR *FileNamePtr;
    PULONG CommandLineHashId;
    ULONG NumCharsToCopy;
    ULONG CharIdx;
    STRING AnsiFilePath;
    UNICODE_STRING FilePath;
    ULONG HashId;
    ULONG PrefetchHint;
    BOOLEAN AllocatedUnicodePath;
    BOOLEAN ShouldTraceScenario;
    BOOLEAN IsHostingApplication;

    DBGPR((CCPFID,PFTRC,"CCPF: BeginAppLaunch()\n"));
    
    //
    // Initialize locals.
    //

    AllocatedUnicodePath = FALSE;
    Scenario = NULL;

    //
    // Check to see if the prefetcher is enabled.
    //

    if (!CCPF_IS_PREFETCHER_ENABLED()) {
        Status = STATUS_NOT_SUPPORTED;
        goto cleanup;
    }
    
    //
    // Check if prefetching is enabled for application launches.
    //

    if (CcPfGlobals.Parameters.Parameters.EnableStatus[PfApplicationLaunchScenarioType] != PfSvEnabled) {
        Status = STATUS_NOT_SUPPORTED;
        goto cleanup;
    }

    //
    // Don't prefetch or start tracing if there is an active system-wide trace.
    //

    if (CcPfGlobals.SystemWideTrace != NULL) {
        Status = STATUS_USER_EXISTS;
        goto cleanup;
    }

    //
    // Query name from the section. Unfortunately this returns us an
    // ANSI string which we then have to convert back to UNICODE. We
    // have to it this way for now because we could not add an API to
    // Mm.
    //

    Status = MmGetFileNameForSection(Section, &AnsiFilePath);

    if (!NT_SUCCESS(Status)) {
        goto cleanup;
    }

    //
    // Convert ANSI path to UNICODE path.
    //
    
    Status = RtlAnsiStringToUnicodeString(&FilePath, &AnsiFilePath, TRUE);
    
    //
    // Don't leak the ANSI buffer...
    //

    ExFreePool (AnsiFilePath.Buffer);

    if (!NT_SUCCESS(Status)) {
        goto cleanup;
    }

    AllocatedUnicodePath = TRUE;

    //
    // Scenario Id requires us to be case insensitive.
    //
       
    RtlUpcaseUnicodeString(&FilePath, &FilePath, FALSE);
    
    //
    // We need to copy just the real file name into the scenario
    // name. Make a first pass to calculate the size of real file
    // name.
    //

    NameNumChars = 0;
    PathNumChars = FilePath.Length / sizeof(WCHAR);
    
    for (CurCharPtr = &FilePath.Buffer[PathNumChars - 1];
         CurCharPtr >= FilePath.Buffer;
         CurCharPtr--) {

        if (*CurCharPtr == L'\\') {
            break;
        }

        NameNumChars++;
    }

    //
    // Check if we got a name.
    //

    if (NameNumChars == 0) {
        Status = STATUS_INVALID_PARAMETER;
        goto cleanup;
    }

    //
    // Set pointer to where file name begins.
    //

    FileNamePtr = &FilePath.Buffer[PathNumChars - NameNumChars];

    //
    // Copy up to PF_SCEN_ID_MAX_CHARS characters into the scenario
    // name buffer.
    //

    NumCharsToCopy = CCPF_MIN(PF_SCEN_ID_MAX_CHARS, NameNumChars);

    for (CharIdx = 0; CharIdx < NumCharsToCopy; CharIdx++) {
        
        ScenarioId.ScenName[CharIdx] = FileNamePtr[CharIdx];
    }

    //
    // Make sure scenario name is NUL terminated.
    //

    ScenarioId.ScenName[NumCharsToCopy] = 0;

    //
    // Calculate scenario hash id from the full path name.
    //

    ScenarioId.HashId = CcPfHashValue(FilePath.Buffer,
                                      FilePath.Length);


    //
    // If this is a "hosting" application (e.g. dllhost, rundll32, mmc)
    // we want to have unique scenarios based on the command line, so 
    // we update the hash id.
    //

    IsHostingApplication = CcPfIsHostingApplication(ScenarioId.ScenName);

    if (IsHostingApplication) {
        CommandLineHashId = &HashId;
    } else {
        CommandLineHashId = NULL;
    }

    //
    // Scan the command line for this process, calculating a hash if
    // requested and checking for a prefetch hint.
    //

    Status = CcPfScanCommandLine(&PrefetchHint, CommandLineHashId);

    if (!NT_SUCCESS(Status)) {

        //
        // If we failed to access the PEB to get the command line,
        // the process may be exiting etc. Do not continue.
        //

        goto cleanup;
    }

    if (IsHostingApplication) {

        //
        // Update the hash ID calculated from full path name.
        //

        ScenarioId.HashId += HashId;
    }

    //
    // If there is a specific hint in the command line add it to the 
    // hash id to make it a unique scenario.
    //
        
    ScenarioId.HashId += PrefetchHint;

    //
    // Get prefetch instructions for this scenario. If there are
    // instructions we will use them to determine whether we should
    // prefetch and/or trace this scenario. By default we will trace
    // the scenario even if there are no instructions.
    //

    ShouldTraceScenario = TRUE;

    Status = CcPfGetPrefetchInstructions(&ScenarioId,
                                         PfApplicationLaunchScenarioType,
                                         &Scenario);

    if (NT_SUCCESS(Status)) {

        CCPF_ASSERT(Scenario);

        //
        // Determine how much time has passed since the last launch
        // for which instructions were updated. Note that the way
        // checks are done below we will recover after a while if the
        // user changes the system time.
        //
        
        KeQuerySystemTime(&CurrentTime);
        TimeSinceLastLaunch.QuadPart = CurrentTime.QuadPart - Scenario->LastLaunchTime.QuadPart;

        if (TimeSinceLastLaunch.QuadPart >= Scenario->MinRePrefetchTime.QuadPart) {
            Status = CcPfPrefetchScenario(Scenario);
        } else {
            DBGPR((CCPFID,PFPREF,"CCPF: BeginAppLaunch-NotRePrefetching\n"));
        }

        if (TimeSinceLastLaunch.QuadPart < Scenario->MinReTraceTime.QuadPart) {
            DBGPR((CCPFID,PFPREF,"CCPF: BeginAppLaunch-NotReTracing\n"));
            ShouldTraceScenario = FALSE;
        }
    }

    if (ShouldTraceScenario) {

        //
        // Start tracing the application launch. Fall through with status.
        // The trace will end when we time out or when the process
        // terminates.
        //
    
        Status = CcPfBeginTrace(&ScenarioId, 
                                PfApplicationLaunchScenarioType,
                                Process);
    }

    //
    // We will fall through with either the status from
    // CcPfGetPrefetchInstructions, CcPfPrefetchScenario or
    // CcPfBeginTrace.
    //

 cleanup:

    if (AllocatedUnicodePath) {
        RtlFreeUnicodeString(&FilePath);
    }

    if (Scenario) {
        ExFreePool(Scenario);
    }

    DBGPR((CCPFID,PFTRC,"CCPF: BeginAppLaunch()=%x\n", Status));

    return Status;
}

NTSTATUS
CcPfProcessExitNotification(
    PEPROCESS Process
    )

/*++

Routine Description:

    This routine gets called when a process is exiting while there are
    active prefetch traces. It checks for active traces that are
    associated with this process, and makes sure they don't stay
    around much longer.

Arguments:

    Process - Process that is terminating.

Return Value:

    Status.

Environment:

    Kernel mode, IRQL == PASSIVE_LEVEL.

--*/

{
    PCCPF_TRACE_HEADER Trace;
   
    DBGPR((CCPFID,PFTRC,"CCPF: ProcessExit(%p)\n", Process));

    //
    // Validate parameters. We should have been called with a valid
    // process.
    //

    CCPF_ASSERT(Process);

    //
    // Get the trace associated with this process if any.
    //

    Trace = CcPfReferenceProcessTrace(Process);

    if (Trace) {

        if (!InterlockedCompareExchange(&Trace->EndTraceCalled, 1, 0)) {
        
            //
            // We set EndTraceCalled from 0 to 1. Queue the
            // workitem to end the trace.
            //
            
            ExQueueWorkItem(&Trace->EndTraceWorkItem, DelayedWorkQueue);
        }

        CcPfDecRef(&Trace->RefCount);
    }

    //
    // We are done.
    //
    
    return STATUS_SUCCESS;
}

VOID
CcPfLogPageFault(
    IN PFILE_OBJECT FileObject,
    IN ULONGLONG FileOffset,
    IN ULONG Flags
    )

/*++

Routine Description:

    This routine logs the specified page fault in appropriate prefetch
    traces.

Arguments:

    FileObject - Supplies the file object for the faulting address.

    FileOffset - Supplies the file offset for the faulting address.

    Flags - Supplies various bits indicating attributes of the fault.

Return Value:

    None.

Environment:

    Kernel mode. IRQL <= DISPATCH_LEVEL. 
    Uses interlocked slist operation.
    Acquires spinlock.

--*/

{
    PCCPF_TRACE_HEADER Trace;
    NTSTATUS Status;
    KIRQL OrigIrql;
    PSECTION_OBJECT_POINTERS SectionObjectPointer;
    LONG FoundIndex;
    LONG AvailIndex;
    PCCPF_SECTION_INFO SectionInfo;
    BOOLEAN IncrementedNumSections;
    LONG NewNumSections;
    LONG NewNumFaults;
    LONG NewNumEntries;
    ULONG NumHashLookups;
    PCCPF_LOG_ENTRIES TraceBuffer;
    PCCPF_LOG_ENTRIES NewTraceBuffer;
    PCCPF_LOG_ENTRY LogEntry;
    LONG MaxEntries;   
    PVPB Vpb;

    DBGPR((CCPFID,PFTRAC,"CCPF: LogPageFault(%p,%I64x,%x)\n", 
           FileObject, FileOffset, Flags));

    //
    // Get the trace associated with this process.
    //

    Trace = CcPfReferenceProcessTrace(PsGetCurrentProcess());

    //
    // If there is no trace associated with this process, see if there is
    // a system-wide trace.
    //

    if (Trace == NULL) {

        if (CcPfGlobals.SystemWideTrace) {

            Trace = CcPfReferenceProcessTrace(PsInitialSystemProcess);

            if (Trace) {

                CCPF_ASSERT(Trace == CcPfGlobals.SystemWideTrace);

            } else {

                Status = STATUS_NO_SUCH_MEMBER;
                goto cleanup;
            }

        } else {

            Status = STATUS_NO_SUCH_MEMBER;
            goto cleanup;
        }
    }

    //
    // Make sure the trace is really a trace.
    //

    CCPF_ASSERT(Trace && Trace->Magic == PF_TRACE_MAGIC_NUMBER);

    //
    // Don't prefetch ROM-backed pages.
    //

    if (Flags & CCPF_TYPE_ROM) {
        Status = STATUS_NOT_SUPPORTED;
        goto cleanup;
    }

    //
    // Check file offset for this page fault. We don't support files >
    // 4GB for the prefetcher.
    //
       
    if (((PLARGE_INTEGER) &FileOffset)->HighPart != 0) {
        Status = STATUS_INVALID_PARAMETER;
        goto cleanup;
    }

    //
    // If the volume this file object is on is not mounted, this is probably 
    // an internal file system file object we don't want to reference.
    // Remote file systems may have file objects for which the device object
    // does not have a VPB. We don't support prefetching on remote file
    // systems.
    //

    Vpb = FileObject->Vpb;

    if (!Vpb) {
        Status = STATUS_NOT_SUPPORTED;
        goto cleanup;
    }

    if (!(Vpb->Flags & VPB_MOUNTED)) {
        Status = STATUS_DEVICE_NOT_READY;
        goto cleanup;
    }

    //
    // Check if the section in which we hit this pagefault is in the
    // hash for this trace [so we will have a file name for it]. If
    // not we will have to add it.
    //

    SectionObjectPointer = FileObject->SectionObjectPointer;

    NumHashLookups = 0;
    IncrementedNumSections = FALSE;

    do {
        
        FoundIndex = CcPfLookUpSection(Trace->SectionInfoTable,
                                       Trace->SectionTableSize,
                                       SectionObjectPointer,
                                       &AvailIndex);

        if (FoundIndex != CCPF_INVALID_TABLE_INDEX) {
            
            //
            // We found the section.
            //
            
            break;
        }

        if (AvailIndex == CCPF_INVALID_TABLE_INDEX) {

            //
            // We don't have room in the table for anything else. The
            // table is allocated so that SectionTableSize >
            // MaxSections. This should not be the case.
            //

            CCPF_ASSERT(FALSE);
            
            Status = STATUS_INSUFFICIENT_RESOURCES;
            goto cleanup;
        }

        //
        // We have to add the section. Before we compete for the
        // available index, check if we are allowed to have another
        // section.
        //

        if (!IncrementedNumSections) {

            NewNumSections = InterlockedIncrement(&Trace->NumSections);
            
            if (NewNumSections > Trace->MaxSections) {

                //
                // We cannot add any more sections to this trace. So
                // we cannot log this page fault.
                //

                InterlockedDecrement(&Trace->NumSections);

                Status = STATUS_INSUFFICIENT_RESOURCES;
                goto cleanup;
            }
            
            IncrementedNumSections = TRUE;
        }

        //
        // Try to get the available spot for ourselves.
        //
        
        SectionInfo = &Trace->SectionInfoTable[AvailIndex];

        if (!InterlockedCompareExchange(&SectionInfo->EntryValid, 1, 0)) {
            
            //
            // We have to be careful with how we are initializing the
            // new entry here. Don't forget, there are no locks.
            //

            //
            // EntryValid was 0 and we set it to 1. It is ours now.
            //

            //
            // First save the other fields of SectionObjectPointers. We check the
            // SectionObjectPointer first to find an entry in the hash.
            // 

            SectionInfo->DataSectionObject = SectionObjectPointer->DataSectionObject;
            SectionInfo->ImageSectionObject = SectionObjectPointer->ImageSectionObject;

            SectionInfo->SectionObjectPointer = SectionObjectPointer;

            //
            // In case we have to queue a worker to get the name for
            // this section, try to get another reference to the trace
            // up front. We already hold a reference so we don't have
            // to acquire any locks.
            //

            Status = CcPfAddRef(&Trace->RefCount);

            if (NT_SUCCESS(Status)) {

                //
                // Reference the file object, so it does not go away until
                // we get a name for it.
                //
                
                ObReferenceObject(FileObject);
                SectionInfo->ReferencedFileObject = FileObject;
                        
                //
                // Push this section into the list for which the worker
                // will get file names. Do this before checking to see if
                // a worker needs to be queued.
                //
                
                InterlockedPushEntrySList(&Trace->SectionsWithoutNamesList,
                                          &SectionInfo->GetNameLink);
                
                //
                // If there is not already a worker queued to get
                // names, queue one.
                // 
                
                if (!InterlockedCompareExchange(&Trace->GetFileNameWorkItemQueued, 
                                                1, 
                                                0)) {
                    
                    //
                    // Queue the worker.
                    //
                    
                    ExQueueWorkItem(&Trace->GetFileNameWorkItem, DelayedWorkQueue);
                    
                } else {

                    //
                    // Notify the event that an existing worker may be
                    // waiting on for new sections.
                    //
                    
                    KeSetEvent(&Trace->GetFileNameWorkerEvent,
                               IO_NO_INCREMENT,
                               FALSE);

                    //
                    // We don't need the reference since we did not
                    // queue a worker.
                    //

                    CcPfDecRef(&Trace->RefCount);
                }

            } else {

                //
                // We added the section but the trace has already
                // ended. We will not be able to get a file name for
                // this section. Fall through to log the entry. The
                // entry will be ignored though because its section
                // won't have a file name.
                //

            }

            //
            // Break out of the loop.
            //
            
            FoundIndex = AvailIndex;
            
            break;
        }

        //
        // We could not have filled up the table, because the table is
        // bigger than the maximum allowed size [MaxSections]
        //

        CCPF_ASSERT((ULONG) Trace->NumSections < Trace->SectionTableSize);
        
        //
        // Updated number of times we've looped. We should not have to
        // loop more than SectionTableSize. If there is a free entry,
        // we should have found it after that many lookups.
        //
            
        NumHashLookups++;

    } while (NumHashLookups < Trace->SectionTableSize);

    //
    // FoundIndex is set to the index of the section in the table.
    //

    if (FoundIndex == CCPF_INVALID_TABLE_INDEX) {
        CCPF_ASSERT(FoundIndex != CCPF_INVALID_TABLE_INDEX);
        Status = STATUS_INSUFFICIENT_RESOURCES;
        goto cleanup;
    }

    //
    // If the section is a metafile (e.g. directory) section, don't need to 
    // log more faults for it. We just need to know that we accessed it since
    // we can only prefetch all or nothing from metafile.
    //

    if (Trace->SectionInfoTable[FoundIndex].Metafile) {
        Status = STATUS_SUCCESS;
        goto cleanup;
    }

    //
    // See if we've already logged too many faults.
    //

    NewNumFaults = InterlockedIncrement(&Trace->NumFaults);

    //
    // If we are beyond bounds we cannot log anymore.
    //

    if (NewNumFaults > Trace->MaxFaults) {

        InterlockedDecrement(&Trace->NumFaults);

        //
        // Try to queue the end of trace workitem.
        //
        
        if (!Trace->EndTraceCalled &&
            !InterlockedCompareExchange(&Trace->EndTraceCalled, 1, 0)) {
            
            //
            // We set EndTraceCalled from 0 to 1. We can queue the
            // workitem now.
            //

            ExQueueWorkItem(&Trace->EndTraceWorkItem, DelayedWorkQueue);
        }

        Status = STATUS_INSUFFICIENT_RESOURCES;
        goto cleanup;
    }

    //
    // Get space for the entry we are going to log.
    //

    do {

        TraceBuffer = Trace->CurrentTraceBuffer;

        NewNumEntries = InterlockedIncrement(&TraceBuffer->NumEntries);
    
        //
        // If we are beyond bounds, try to allocate a new buffer.
        //
    
        if (NewNumEntries > TraceBuffer->MaxEntries) {

            InterlockedDecrement(&TraceBuffer->NumEntries);

            //
            // Allocate a new trace buffer.
            //

            MaxEntries = CCPF_TRACE_BUFFER_MAX_ENTRIES;
            NewTraceBuffer = ExAllocatePoolWithTag(NonPagedPool,
                                                   CCPF_TRACE_BUFFER_SIZE,
                                                   CCPF_ALLOC_TRCBUF_TAG);
            
            if (NewTraceBuffer == NULL) {

                //
                // Couldn't allocate a new buffer. Decrement the count
                // of logged faults and go away.
                //

                InterlockedDecrement(&Trace->NumFaults);
                Status = STATUS_INSUFFICIENT_RESOURCES;
                break;
            }

            //
            // Acquire the right to make trace buffer changes.
            //

            KeAcquireSpinLock(&Trace->TraceBufferSpinLock, &OrigIrql);

            //
            // If the trace buffer has already been changed, start over.
            //

            if (Trace->CurrentTraceBuffer != TraceBuffer) {
                KeReleaseSpinLock(&Trace->TraceBufferSpinLock, OrigIrql);
                ExFreePool(NewTraceBuffer);
                continue;
            }

            //
            // Number of entries field of the full trace buffer should
            // be equal to or greater than max entries, because
            // somebody may have bumped it just to see it can't log
            // its entry here. It should not be less than, however.
            //

            CCPF_ASSERT(TraceBuffer->NumEntries >= TraceBuffer->MaxEntries);

            //
            // Initialize the new trace buffer.
            //

            NewTraceBuffer->NumEntries = 0;
            NewTraceBuffer->MaxEntries = MaxEntries;

            //
            // Insert it at the end of buffers list.
            //

            InsertTailList(&Trace->TraceBuffersList,
                           &NewTraceBuffer->TraceBuffersLink);

            Trace->NumTraceBuffers++;

            //
            // Make it the current buffer.
            //

            Trace->CurrentTraceBuffer = NewTraceBuffer;

            //
            // Release the spinlock and start over.
            //

            KeReleaseSpinLock(&Trace->TraceBufferSpinLock, OrigIrql);
            continue;
        }

        LogEntry = &TraceBuffer->Entries[NewNumEntries - 1];
    
        LogEntry->FileOffset = (ULONG) FileOffset;
        LogEntry->SectionId = (USHORT) FoundIndex;
        LogEntry->IsImage = (Flags & CCPF_TYPE_IMAGE)? TRUE : FALSE;

        break;

    } while (TRUE);

    Status = STATUS_SUCCESS;

cleanup:

    if (Trace != NULL) {
        CcPfDecRef(&Trace->RefCount);
    }

    DBGPR((CCPFID,PFTRAC,"CCPF: LogPageFault()=%x\n", Status)); 

    return;
}

NTSTATUS
CcPfQueryPrefetcherInformation (
    IN SYSTEM_INFORMATION_CLASS SystemInformationClass,
    IN PVOID SystemInformation,
    IN ULONG SystemInformationLength,
    IN KPROCESSOR_MODE PreviousMode,
    OUT PULONG Length
    )

/*++

Routine Description:

    This routine gets called from NtQuerySystemInformation for
    prefetcher related queries.

Arguments:

    SystemInformationClass - The system information class about which
      to retrieve information.

    SystemInformation - A pointer to a buffer which receives the specified
      information.

    SystemInformationLength - Specifies the length in bytes of the system
      information buffer.    

    PreviousMode - Previous processor mode.

    Length - Size of data put into SystemInformation buffer.

Return Value:

    Status.

Environment:

    Kernel mode. IRQL == PASSIVE_LEVEL.

--*/

{
    PPREFETCHER_INFORMATION PrefetcherInformation;
    NTSTATUS Status;
    PF_SYSTEM_PREFETCH_PARAMETERS Temp;
    PKTHREAD CurrentThread;

    UNREFERENCED_PARAMETER (SystemInformationClass);

    DBGPR((CCPFID,PFTRC,"CCPF: QueryPrefetcherInformation()\n"));

    //
    // Check permissions.
    //

    if (!SeSinglePrivilegeCheck(SeProfileSingleProcessPrivilege,PreviousMode)) {
        Status = STATUS_ACCESS_DENIED;
        goto cleanup;
    }

    //
    // Check parameters.
    //

    if (SystemInformationLength != sizeof(PREFETCHER_INFORMATION)) {
        Status = STATUS_INFO_LENGTH_MISMATCH;
        goto cleanup;
    }

    PrefetcherInformation = SystemInformation;

    //
    // Verify version and magic.
    //

    if (PrefetcherInformation->Version != PF_CURRENT_VERSION ||
        PrefetcherInformation->Magic != PF_SYSINFO_MAGIC_NUMBER) {
        Status = STATUS_INVALID_PARAMETER;
        goto cleanup;
    }

    //
    // Process requested information class.
    //
        
    switch (PrefetcherInformation->PrefetcherInformationClass) {
    
    case PrefetcherRetrieveTrace:
        Status = CcPfGetCompletedTrace(PrefetcherInformation->PrefetcherInformation,
                                       PrefetcherInformation->PrefetcherInformationLength,
                                       Length);
        break;

    case PrefetcherSystemParameters:
        
        //
        // Make sure input buffer is big enough.
        //

        if (PrefetcherInformation->PrefetcherInformationLength != 
            sizeof(PF_SYSTEM_PREFETCH_PARAMETERS)) {
            Status = STATUS_BUFFER_TOO_SMALL;
            break;
        }

        //
        // Acquire parameters lock and copy current parameters into
        // user's buffer.
        //
        
        Status = STATUS_SUCCESS;

        CurrentThread = KeGetCurrentThread ();
        KeEnterCriticalRegionThread(CurrentThread);
        ExAcquireResourceSharedLite(&CcPfGlobals.Parameters.ParametersLock, TRUE);

        RtlCopyMemory(&Temp,
                      &CcPfGlobals.Parameters.Parameters,
                      sizeof(PF_SYSTEM_PREFETCH_PARAMETERS));            

        ExReleaseResourceLite(&CcPfGlobals.Parameters.ParametersLock);
        KeLeaveCriticalRegionThread(CurrentThread);

        try {

            //
            // If called from user-mode, probe whether it is safe to write 
            // to the pointer passed in.
            //
            
            if (PreviousMode != KernelMode) {
                ProbeForWriteSmallStructure(PrefetcherInformation->PrefetcherInformation, 
                                            sizeof(PF_SYSTEM_PREFETCH_PARAMETERS), 
                                            _alignof(PF_SYSTEM_PREFETCH_PARAMETERS));
            }

            RtlCopyMemory(PrefetcherInformation->PrefetcherInformation,
                          &Temp,
                          sizeof(PF_SYSTEM_PREFETCH_PARAMETERS));
            
        } except (EXCEPTION_EXECUTE_HANDLER) {

            Status = GetExceptionCode();
        }


        //
        // Set returned number of bytes.
        //

        if (NT_SUCCESS(Status)) {
            if (Length) {
                *Length = sizeof(PF_SYSTEM_PREFETCH_PARAMETERS);
            }
        }

        break;

    default:

        Status = STATUS_INVALID_INFO_CLASS;
    }

    //
    // Fall through with status from switch statement.
    //

 cleanup:

    DBGPR((CCPFID,PFTRC,"CCPF: QueryPrefetcherInformation()=%x\n", Status));

    return Status;
}

NTSTATUS
CcPfSetPrefetcherInformation (
    IN SYSTEM_INFORMATION_CLASS SystemInformationClass,
    IN PVOID SystemInformation,
    IN ULONG SystemInformationLength,
    IN KPROCESSOR_MODE PreviousMode
    )

/*++

Routine Description:

    This routine gets called from NtSetSystemInformation for
    prefetcher related settings.

Arguments:

    SystemInformationClass - The system information which is to be 
      modified.

    SystemInformation - A pointer to a buffer which contains the specified
      information.

    SystemInformationLength - Specifies the length in bytes of the system
      information buffer.    

    PreviousMode - Previous processor mode.

Return Value:

    Status.

Environment:

    Kernel mode. IRQL == PASSIVE_LEVEL.

--*/

{
    PPREFETCHER_INFORMATION PrefetcherInformation;
    PCCPF_PREFETCHER_PARAMETERS PrefetcherParameters;
    PF_SYSTEM_PREFETCH_PARAMETERS Parameters;
    NTSTATUS Status;
    PF_BOOT_PHASE_ID NewPhaseId;
    PKTHREAD CurrentThread;

    UNREFERENCED_PARAMETER (SystemInformationClass);

    DBGPR((CCPFID,PFTRC,"CCPF: SetPrefetcherInformation()\n"));

    //
    // Check permissions.
    //

    if (!SeSinglePrivilegeCheck(SeProfileSingleProcessPrivilege,PreviousMode)) {
        Status = STATUS_ACCESS_DENIED;
        goto cleanup;
    }

    //
    // Check parameters.
    //

    if (SystemInformationLength != sizeof(PREFETCHER_INFORMATION)) {
        Status = STATUS_INFO_LENGTH_MISMATCH;
        goto cleanup;
    }

    PrefetcherInformation = SystemInformation;

    //
    // Verify version and magic.
    //

    if (PrefetcherInformation->Version != PF_CURRENT_VERSION ||
        PrefetcherInformation->Magic != PF_SYSINFO_MAGIC_NUMBER) {
        Status = STATUS_INVALID_PARAMETER;
        goto cleanup;
    }

    //
    // Process requested information class.
    //

    switch (PrefetcherInformation->PrefetcherInformationClass) {
    
    case PrefetcherRetrieveTrace:
        Status = STATUS_INVALID_INFO_CLASS;
        break;

    case PrefetcherSystemParameters:
        
        //
        // Make sure input buffer is the right size.
        //

        if (PrefetcherInformation->PrefetcherInformationLength != 
            sizeof(PF_SYSTEM_PREFETCH_PARAMETERS)) {
            Status = STATUS_BUFFER_TOO_SMALL;
            break;
        }

        //
        // *Copy* the parameters, in case the caller changes them
        // beneath our feet to break us.
        //

        Status = STATUS_SUCCESS;

        try {

            //
            // If called from user-mode, probe whether it is safe to read
            // from the pointer passed in.
            //

            if (PreviousMode != KernelMode) {
                ProbeForReadSmallStructure(PrefetcherInformation->PrefetcherInformation,
                                           sizeof(PF_SYSTEM_PREFETCH_PARAMETERS),
                                           _alignof(PF_SYSTEM_PREFETCH_PARAMETERS));
            }

            RtlCopyMemory(&Parameters,
                          PrefetcherInformation->PrefetcherInformation,
                          sizeof(PF_SYSTEM_PREFETCH_PARAMETERS));

        } except (EXCEPTION_EXECUTE_HANDLER) {

            Status = GetExceptionCode();
        }

        if (!NT_SUCCESS(Status)) {
            break;
        }

        //
        // Verify new parameters.
        //
        
        Status = CcPfParametersVerify(&Parameters);

        if (!NT_SUCCESS(Status)) {
            break;
        }

        //
        // Acquire the parameters lock exclusive.
        //

        PrefetcherParameters = &CcPfGlobals.Parameters;

        CurrentThread = KeGetCurrentThread ();
        KeEnterCriticalRegionThread(CurrentThread);
        ExAcquireResourceExclusiveLite(&PrefetcherParameters->ParametersLock, TRUE);
           
        //
        // Copy them over to our globals.
        //
        
        PrefetcherParameters->Parameters = Parameters;

        //
        // Release the exclusive hold on parameters lock.
        //

        ExReleaseResourceLite(&PrefetcherParameters->ParametersLock);
        KeLeaveCriticalRegionThread(CurrentThread);
        
        //
        // Determine if prefetching is still enabled.
        //

        CcPfDetermineEnablePrefetcher();

        //
        // Set the event so the service queries for the latest
        // parameters.
        //
        
        CcPfParametersSetChangedEvent(PrefetcherParameters);
        
        //
        // If the parameters update was successful, update the registry.
        //
        
        Status = CcPfParametersSave(PrefetcherParameters);

        break;
    
    case PrefetcherBootPhase:
        
        //
        // This is called to notify the prefetcher that a new boot
        // phase has started. The new phase id is at PrefetcherInformation.
        //

        //
        // Check length of PrefetcherInformation.
        //

        if (PrefetcherInformation->PrefetcherInformationLength != sizeof(PF_BOOT_PHASE_ID)) {
            Status = STATUS_BUFFER_TOO_SMALL;
            break;
        }

        //
        // Get new phase id.
        //
        
        Status = STATUS_SUCCESS;
        
        try {

            //
            // If called from user-mode, probe whether it is safe to read
            // from the pointer passed in.
            //

            if (PreviousMode != KernelMode) {
                ProbeForReadSmallStructure(PrefetcherInformation->PrefetcherInformation,
                                           sizeof(PF_BOOT_PHASE_ID),
                                           _alignof(PF_BOOT_PHASE_ID));
            }

            NewPhaseId = *((PPF_BOOT_PHASE_ID)(PrefetcherInformation->PrefetcherInformation));

        } except (EXCEPTION_EXECUTE_HANDLER) {

            Status = GetExceptionCode();
        }

        if (NT_SUCCESS(Status)) {
            
            //
            // Call the function to note the new boot phase.
            //

            Status = CcPfBeginBootPhase(NewPhaseId);
        }

        break;

    default:

        Status = STATUS_INVALID_INFO_CLASS;
    }

    //
    // Fall through with status from the switch statement.
    //

 cleanup:

    DBGPR((CCPFID,PFTRC,"CCPF: SetPrefetcherInformation()=%x\n", Status));

    return Status;
}

//
// Internal prefetcher routines:
//

//
// Routines used in prefetch tracing.
//

NTSTATUS
CcPfBeginTrace(
    IN PF_SCENARIO_ID *ScenarioId,
    IN PF_SCENARIO_TYPE ScenarioType,
    IN PEPROCESS Process
    )

/*++

Routine Description:

    This function is called to begin tracing for a prefetch scenario.

Arguments:

    ScenarioId - Identifier for the scenario.

    ScenarioType - Type of scenario.

    Process - The process new scenario is associated with.

Return Value:

    Status.

Environment:

    Kernel mode, IRQL == PASSIVE_LEVEL.

--*/

{
    PCCPF_TRACE_HEADER Trace;
    PPF_TRACE_LIMITS TraceLimits; 
    NTSTATUS Status;
    ULONG AllocationSize;
    ULONG SectionTableSize;
    LONG MaxEntries;
    
    //
    // Initialize locals.
    //
    
    Trace = NULL;

    DBGPR((CCPFID,PFTRC,"CCPF: BeginTrace()-%d-%d\n", 
           CcPfNumActiveTraces, CcPfGlobals.NumCompletedTraces));

    //
    // Check if prefetching is enabled.
    //
    
    if (!CCPF_IS_PREFETCHER_ENABLED()) {
        Status = STATUS_NOT_SUPPORTED;
        goto cleanup;
    }

    //
    // Make sure the scenario type is valid.
    // 

    if (ScenarioType >= PfMaxScenarioType) {
        Status = STATUS_INVALID_PARAMETER;
        goto cleanup;
    }
    
    //
    // Check if prefetching is enabled for the specified scenario type.
    //

    if (CcPfGlobals.Parameters.Parameters.EnableStatus[ScenarioType] != PfSvEnabled) {
        Status = STATUS_NOT_SUPPORTED;
        goto cleanup;
    }

    //
    // Check if a system-wide trace is active. If so only it can be active.
    //

    if (CcPfGlobals.SystemWideTrace) {
        Status = STATUS_USER_EXISTS;
        goto cleanup;
    }

    //
    // Make a quick check to see if we already have too many outstanding 
    // traces. Since we don't make this check under a lock, the limit is
    // not enforced exactly.
    //  

    if ((ULONG)CcPfNumActiveTraces >= CcPfGlobals.Parameters.Parameters.MaxNumActiveTraces) {
        Status = STATUS_TOO_MANY_SESSIONS;
        goto cleanup;
    }   

    //
    // Make a quick check to see if we already have too many completed 
    // traces that the service has not picked up.
    //   
    
    if ((ULONG)CcPfGlobals.NumCompletedTraces >= CcPfGlobals.Parameters.Parameters.MaxNumSavedTraces) {
        Status = STATUS_TOO_MANY_SESSIONS;
        goto cleanup;
    }
    
    //
    // If a process was not specified we cannot start a trace.
    //

    if (!Process) {
        Status = STATUS_NOT_SUPPORTED;
        goto cleanup;
    } 

    //
    // Allocate and initialize trace structure.
    //

    Trace = ExAllocatePoolWithTag(NonPagedPool,
                                  sizeof(CCPF_TRACE_HEADER),
                                  CCPF_ALLOC_TRACE_TAG);
    
    if (!Trace) {
        Status = STATUS_INSUFFICIENT_RESOURCES;
        goto cleanup;
    }

    //
    // Zero the whole structure so that we don't have to write zeroes
    // one field at a time to initialize it. Note that most fields
    // really have to be initialized to 0's.
    //

    RtlZeroMemory(Trace, sizeof(CCPF_TRACE_HEADER));
    
    //
    // Initialize other trace fields so we know what to cleanup.
    //

    Trace->Magic = PF_TRACE_MAGIC_NUMBER;
    KeInitializeTimer(&Trace->TraceTimer);
    InitializeListHead(&Trace->TraceBuffersList);
    KeInitializeSpinLock(&Trace->TraceBufferSpinLock);
    InitializeListHead(&Trace->VolumeList);
    Trace->TraceDumpStatus = STATUS_NOT_COMMITTED;
    KeQuerySystemTime(&Trace->LaunchTime);

    //
    // Initialize the spinlock and DPC for the trace timer.
    //

    KeInitializeSpinLock(&Trace->TraceTimerSpinLock);

    KeInitializeDpc(&Trace->TraceTimerDpc, 
                    CcPfTraceTimerRoutine, 
                    Trace);
                                                  
    //
    // Initialize reference count structure. A reference to a trace
    // can only be acquired while holding the active traces spinlock.
    //

    CcPfInitializeRefCount(&Trace->RefCount);
    
    //
    // Get reference to associated process so it does
    // not go away while our timer routines etc. are running.
    //

    ObReferenceObject(Process);
    Trace->Process = Process;

    //
    // Initialize the workitem that may be queued to call end trace
    // function and the field that has to be InterlockedCompareExchange'd 
    // to 1 before anybody queues the workitem or makes the call.
    //

    ExInitializeWorkItem(&Trace->EndTraceWorkItem,
                         CcPfEndTraceWorkerThreadRoutine,
                         Trace);

    Trace->EndTraceCalled = 0;

    //
    // Initialize the workitem queued to get names for file objects.
    //

    ExInitializeWorkItem(&Trace->GetFileNameWorkItem,
                         CcPfGetFileNamesWorkerRoutine,
                         Trace);

    Trace->GetFileNameWorkItemQueued = 0;

    KeInitializeEvent(&Trace->GetFileNameWorkerEvent,
                      SynchronizationEvent,
                      FALSE);

    //
    // Initialize the list where we put sections we have to get names
    // for.
    //

    InitializeSListHead(&Trace->SectionsWithoutNamesList);

    //
    // Initialize scenario id and type fields.
    //

    Trace->ScenarioId = *ScenarioId;
    Trace->ScenarioType = ScenarioType;

    //
    // Determine trace limits and timer period from scenario type.
    // We have already checked that ScenarioType is within limits.
    //
    
    TraceLimits = &CcPfGlobals.Parameters.Parameters.TraceLimits[Trace->ScenarioType];

    Trace->MaxFaults = TraceLimits->MaxNumPages;
    Trace->MaxSections = TraceLimits->MaxNumSections;
    Trace->TraceTimerPeriod.QuadPart = TraceLimits->TimerPeriod;

    //
    // Make sure the sizes are within sanity limits.
    //

    if ((Trace->MaxFaults == 0) || (Trace->MaxSections == 0)) {
        Status = STATUS_INVALID_PARAMETER;
        goto cleanup;
    }

    if (Trace->MaxFaults > PF_MAXIMUM_LOG_ENTRIES) {
        Trace->MaxFaults = PF_MAXIMUM_LOG_ENTRIES;
    }
    
    if (Trace->MaxSections > PF_MAXIMUM_SECTIONS) {
        Trace->MaxSections = PF_MAXIMUM_SECTIONS;
    }

    //
    // Allocate a trace buffer and section info table.
    //

    MaxEntries = CCPF_TRACE_BUFFER_MAX_ENTRIES;
    Trace->CurrentTraceBuffer = ExAllocatePoolWithTag(NonPagedPool,
                                                      CCPF_TRACE_BUFFER_SIZE,
                                                      CCPF_ALLOC_TRCBUF_TAG);
    
    if (Trace->CurrentTraceBuffer == NULL) {
        Status = STATUS_INSUFFICIENT_RESOURCES;
        goto cleanup;
    }

    Trace->CurrentTraceBuffer->NumEntries = 0;
    Trace->CurrentTraceBuffer->MaxEntries = MaxEntries;

    //
    // Insert the current trace buffer to the trace buffers list.
    //

    InsertTailList(&Trace->TraceBuffersList, 
                   &Trace->CurrentTraceBuffer->TraceBuffersLink);

    Trace->NumTraceBuffers = 1;

    //
    // SectionInfoTable is a hash. To give it enough room and avoid
    // too many hash conflicts, allocate it to be bigger.
    //

    SectionTableSize = Trace->MaxSections + (Trace->MaxSections / 2);
    AllocationSize = SectionTableSize * sizeof(CCPF_SECTION_INFO);
    Trace->SectionInfoTable = ExAllocatePoolWithTag(NonPagedPool,
                                                    AllocationSize,
                                                    CCPF_ALLOC_SECTTBL_TAG);
    
    if (!Trace->SectionInfoTable) {
        Status = STATUS_INSUFFICIENT_RESOURCES;
        goto cleanup;
    }  

    Trace->SectionTableSize = SectionTableSize;

    //
    // Initialize entries in the section table. We want the whole table
    // to contain zeroes, so just use RtlZeroMemory. 
    //
    // EntryValid is the crucial field in section info entries allowing
    // us not to have any locks. The first to (interlocked) set it
    // to 1 gets the entry in the table. In case someone tries to
    // access the entry right afterwards we initialize the other
    // fields to sensible values upfront.
    //
    // It is important to set SectionObjectPointer to NULL. When EntryValid is
    // InterlockedCompareExchange'd into 1, we don't want anybody
    // to match before we set it up.
    //

    RtlZeroMemory(Trace->SectionInfoTable, AllocationSize);
  
    //
    // Add this trace to active traces list. 
    // Set the trace on process header.
    // Start the trace timer.
    // We'll start logging page faults, processing process delete notificatios etc.
    //

    CcPfActivateTrace(Trace);

    //
    // NOTE: FROM THIS POINT ON WE SHOULD NOT FAIL. 
    // CcPfEndTrace has to be called to stop & cleanup the trace.
    //

    Status = STATUS_SUCCESS;

 cleanup:

    if (!NT_SUCCESS(Status)) {       
        if (Trace) {
            CcPfCleanupTrace(Trace);
            ExFreePool(Trace);
        }
    }

    DBGPR((CCPFID,PFTRC,"CCPF: BeginTrace(%p)=%x\n", Trace, Status));

    return Status;
}

NTSTATUS
CcPfActivateTrace(
    IN PCCPF_TRACE_HEADER Trace
    )

/*++

Routine Description:

    This routine adds the specified trace to the list of active
    traces.

Arguments:

    Trace - Pointer to trace header.

Return Value:

    STATUS_SUCCESS.

Environment:

    Kernel mode, IRQL == PASSIVE_LEVEL. Acquires spinlock.

--*/

{
    KIRQL OrigIrql;
    NTSTATUS Status;
    BOOLEAN TimerAlreadyQueued;

    DBGPR((CCPFID,PFTRC,"CCPF: ActivateTrace(%p)\n", Trace));

    //
    // Get a reference to the trace for the timer.
    //

    Status = CcPfAddRef(&Trace->RefCount);
    CCPF_ASSERT(NT_SUCCESS(Status));

    //
    // Insert to active traces list.
    //
    
    KeAcquireSpinLock(&CcPfGlobals.ActiveTracesLock, &OrigIrql);
    
    //
    // Insert the entry before the found position.
    //

    InsertTailList(&CcPfGlobals.ActiveTraces, &Trace->ActiveTracesLink);
    CcPfNumActiveTraces++;

    //
    // Start the timer.
    //

    TimerAlreadyQueued = KeSetTimer(&Trace->TraceTimer,
                                    Trace->TraceTimerPeriod,
                                    &Trace->TraceTimerDpc);

    //
    // We just initialized the timer. It could not have been already queued.
    //

    CCPF_ASSERT(!TimerAlreadyQueued);

    //
    // Set up the trace pointer on the process with fast ref. Since we are 
    // already holding a reference, this operation should not fail.
    //

    Status = CcPfAddProcessTrace(Trace->Process, Trace);
    CCPF_ASSERT(NT_SUCCESS(Status));

    //
    // Do we trace system-wide for this scenario type?
    //

    if (CCPF_IS_SYSTEM_WIDE_SCENARIO_TYPE(Trace->ScenarioType)) {

        CcPfGlobals.SystemWideTrace = Trace;

    } else {

        //
        // If we are the only active trace, place ourselves on the system
        // process as well so we can trace ReadFile & metafile access.
        //

        if (CcPfNumActiveTraces == 1) {
            Status = CcPfAddProcessTrace(PsInitialSystemProcess, Trace);
            CCPF_ASSERT(NT_SUCCESS(Status));
        }
    }

    //
    // NOTE: AddProcessTrace and KeSetTimer(TraceTimer) has to be done 
    // inside the spinlock so DeactivateTrace can know activation has been
    // fully completed by acquiring and releasing the spinlock.
    //

    KeReleaseSpinLock(&CcPfGlobals.ActiveTracesLock, OrigIrql);
    
    return STATUS_SUCCESS;
}

NTSTATUS
CcPfDeactivateTrace(
    IN PCCPF_TRACE_HEADER Trace
    )

/*++

Routine Description:

    This routine waits for all references to the trace to go away, and
    removes it from the active traces list. This function should only
    be called after CcPfActivateTrace has been called on the trace.

Arguments:

    Trace - Pointer to trace header.

Return Value:

    STATUS_SUCCESS.

Environment:

    Kernel mode, IRQL == PASSIVE_LEVEL. Acquires spinlock.

--*/

{
    PCCPF_TRACE_HEADER RemovedTrace;
    PCCPF_TRACE_HEADER ReferencedTrace;
    KIRQL OrigIrql;
    NTSTATUS Status;  

    DBGPR((CCPFID,PFTRC,"CCPF: DeactivateTrace(%p)\n", Trace));

    //
    // Acquire and release the active traces spinlock. This makes sure we
    // don't try to deactivate before activation (which also holds this lock) 
    // has fully completed.
    //

#if !defined (NT_UP)
    KeAcquireSpinLock(&CcPfGlobals.ActiveTracesLock, &OrigIrql);   
    KeReleaseSpinLock(&CcPfGlobals.ActiveTracesLock, OrigIrql);
#endif // NT_UP

    //
    // Remove the trace from process header and release the fast refs.
    //

    RemovedTrace = CcPfRemoveProcessTrace(Trace->Process);
    CCPF_ASSERT(RemovedTrace == Trace);

    //
    // Release the reference associated with the fast ref itself.
    //

    CcPfDecRef(&Trace->RefCount);

    //
    // If we were placed on the system process as well, remove that.
    //

    ReferencedTrace = CcPfReferenceProcessTrace(PsInitialSystemProcess);

    if (ReferencedTrace) {

        if (Trace == ReferencedTrace) {

            //
            // Remove ourselves from the system process header.
            //

            RemovedTrace = CcPfRemoveProcessTrace(PsInitialSystemProcess);
            CCPF_ASSERT(RemovedTrace == Trace);

            //
            // Release the reference associated with the fast ref itself.
            //

            CcPfDecRef(&Trace->RefCount);           
        }

        //
        // Release the reference we just got.
        //

        CcPfDecRef(&ReferencedTrace->RefCount);
    }
    
    //
    // Cancel the timer.
    //

    CcPfCancelTraceTimer(Trace);

    //
    // Signal the trace's get-file-name worker to return [in case it
    // is active] and release its reference. Give it a priority bump
    // so it releases its reference before we begin waiting for it.
    //

    KeSetEvent(&Trace->GetFileNameWorkerEvent,
               EVENT_INCREMENT,
               FALSE);


    //
    // Wait for all references to go away.
    //
    
    Status = CcPfAcquireExclusiveRef(&Trace->RefCount);

    DBGPR((CCPFID,PFTRAC,"CCPF: DeactivateTrace-Exclusive=%x\n", Status));

    //
    // We should have been able to acquire the trace exclusively.
    // Otherwise this trace may have already been deactivated.
    //

    CCPF_ASSERT(NT_SUCCESS(Status));

    //
    // Get the active traces lock.
    //
     
    KeAcquireSpinLock(&CcPfGlobals.ActiveTracesLock, &OrigIrql);

    //
    // Remove us from the active trace list.
    //
    
    RemoveEntryList(&Trace->ActiveTracesLink);
    CcPfNumActiveTraces--;
    
    //
    // If this was a system-wide trace, it is over now.
    //

    if (CCPF_IS_SYSTEM_WIDE_SCENARIO_TYPE(Trace->ScenarioType)) {
        CCPF_ASSERT(CcPfGlobals.SystemWideTrace == Trace);
        CcPfGlobals.SystemWideTrace = NULL;
    }

    //
    // Release active traces lock.
    //

    KeReleaseSpinLock(&CcPfGlobals.ActiveTracesLock, OrigIrql);

    return STATUS_SUCCESS;
}

NTSTATUS
CcPfEndTrace(
    IN PCCPF_TRACE_HEADER Trace
    )

/*++

Routine Description:

    This function is called to end a prefetch trace. In order to
    ensure this function gets called only once, EndTraceCalled field
    of the trace has to be InterlockedCompareExchange'd from 0 to
    1. All intermediate references and allocations are freed. The
    trace is saved until the service queries for it and the service
    event is signaled.

Arguments:

    Trace - Pointer to trace header.

Return Value:

    Status.

Environment:

    Kernel mode. IRQL == PASSIVE_LEVEL.

--*/

{
    PCCPF_TRACE_DUMP TraceDump;
    PCCPF_TRACE_DUMP RemovedTraceDump;
    PLIST_ENTRY ListHead;
    OBJECT_ATTRIBUTES EventObjAttr;
    UNICODE_STRING EventName;
    HANDLE EventHandle;
    NTSTATUS Status;
    LONG FaultsLoggedAfterTimeout;

    DBGPR((CCPFID,PFTRC,"CCPF: EndTrace(%p)\n", Trace));

    //
    // Make sure the trace we are called on is valid.
    //

    CCPF_ASSERT(Trace && Trace->Magic == PF_TRACE_MAGIC_NUMBER);

    //
    // Before anyone called us, they should have
    // InterlockedCompareExchange'd this to 1 to ensure this function
    // gets called only once for this trace.
    //

    CCPF_ASSERT(Trace->EndTraceCalled == 1);

    //
    // Deactivate the trace, if necessary waiting for all the references to 
    // it to go away.
    // This function makes sure activation fully finished before deactivating.
    // This needs to be done before we do anything else with the trace.
    //
                
    CcPfDeactivateTrace(Trace);   

    //
    // If we did not timeout, save the number of pagefaults logged
    // since the last period into the next period.
    //

    if (Trace->CurPeriod < PF_MAX_NUM_TRACE_PERIODS) {

        //
        // Number of log entries could only have increased since the
        // last time we saved them.
        //
     
        CCPF_ASSERT(Trace->NumFaults >= Trace->LastNumFaults);
   
        Trace->FaultsPerPeriod[Trace->CurPeriod] = 
            Trace->NumFaults - Trace->LastNumFaults;
    
        Trace->LastNumFaults = Trace->NumFaults;
        
        Trace->CurPeriod++;

    } else {

        //
        // If we did time out, we may have logged more faults since we
        // saved the number of faults, until the end trace function
        // got run. Update the number faults in the last period.
        //
        
        if (Trace->LastNumFaults != Trace->NumFaults) {
            
            //
            // What we saved as LastNumFaults in the timer routine
            // cannot be greater than what we really logged.
            //
            
            CCPF_ASSERT(Trace->LastNumFaults < Trace->NumFaults);
            
            FaultsLoggedAfterTimeout = Trace->NumFaults - Trace->LastNumFaults;
            
            Trace->FaultsPerPeriod[Trace->CurPeriod - 1] += FaultsLoggedAfterTimeout;
        }
    }

    //
    // Convert the trace into a paged, single buffer dump that we can
    // give to the user mode service.
    //

    Status = CcPfBuildDumpFromTrace(&TraceDump, Trace);

    Trace->TraceDumpStatus = Status;
    Trace->TraceDump = TraceDump;

    //
    // Cleanup and deallocate the trace structure.
    //

    CcPfCleanupTrace(Trace);
    ExFreePool(Trace);

    //
    // If we could not create a dump from the trace we acquired, we
    // are done.
    //

    if (!NT_SUCCESS(Status)) {
        goto cleanup;
    }

    //
    // Put the dump on the saved traces list. If we have too many,
    // trim in a round robin fashion. First get the lock.
    //

    ExAcquireFastMutex(&CcPfGlobals.CompletedTracesLock);
    
    InsertTailList(&CcPfGlobals.CompletedTraces, &TraceDump->CompletedTracesLink);
    CcPfGlobals.NumCompletedTraces++;

    while ((ULONG) CcPfGlobals.NumCompletedTraces > 
           CcPfGlobals.Parameters.Parameters.MaxNumSavedTraces) {

        //
        // While NumCompletedTraces > MaxNumSavedTraces we should have at
        // least a completed trace in the list.
        //
        
        if (IsListEmpty(&CcPfGlobals.CompletedTraces)) {
            CCPF_ASSERT(FALSE);
            break;
        }

        ListHead = RemoveHeadList(&CcPfGlobals.CompletedTraces);
        
        RemovedTraceDump = CONTAINING_RECORD(ListHead,
                                             CCPF_TRACE_DUMP,
                                             CompletedTracesLink);
       
        //
        // Free the tracedump structure.
        //
    
        CCPF_ASSERT(RemovedTraceDump->Trace.MagicNumber == PF_TRACE_MAGIC_NUMBER);
        ExFreePool(RemovedTraceDump);

        CcPfGlobals.NumCompletedTraces--;
    }
    
    ExReleaseFastMutex(&CcPfGlobals.CompletedTracesLock);   

    //
    // Signal the event service is waiting on for new traces. If we
    // have not opened it yet, first we have to open it.
    //

    if (CcPfGlobals.CompletedTracesEvent) {

        ZwSetEvent(CcPfGlobals.CompletedTracesEvent, NULL);

    } else {

        //
        // Try to open the event. We don't open this at initialization
        // because our service may not have started to create this
        // event yet. If csrss.exe has not initialized, we may not
        // even have the BaseNamedObjects object directory created, in
        // which Win32 events reside.
        //

        RtlInitUnicodeString(&EventName, PF_COMPLETED_TRACES_EVENT_NAME);

        InitializeObjectAttributes(&EventObjAttr,
                                   &EventName,
                                   OBJ_CASE_INSENSITIVE | OBJ_KERNEL_HANDLE,
                                   NULL,
                                   NULL);
        
        Status = ZwOpenEvent(&EventHandle,
                             EVENT_ALL_ACCESS,
                             &EventObjAttr);
        
        if (NT_SUCCESS(Status)) {

            //
            // Acquire the lock and set the global handle.
            //

            ExAcquireFastMutex(&CcPfGlobals.CompletedTracesLock);

            if (!CcPfGlobals.CompletedTracesEvent) {

                //
                // Set the global handle.
                //

                CcPfGlobals.CompletedTracesEvent = EventHandle;
                CCPF_ASSERT(EventHandle);

            } else {

                //
                // Somebody already initialized the global handle
                // before us. Close our handle and use the one they
                // initialized.
                //

                ZwClose(EventHandle);
            }

            ExReleaseFastMutex(&CcPfGlobals.CompletedTracesLock);

            //
            // We have an event now. Signal it.
            //
            
            ZwSetEvent(CcPfGlobals.CompletedTracesEvent, NULL);
        }
    }

    Status = STATUS_SUCCESS;

 cleanup:

    DBGPR((CCPFID,PFTRC,"CCPF: EndTrace(%p)=%x\n", Trace, Status));

    return Status;
}

NTSTATUS
CcPfBuildDumpFromTrace(
    OUT PCCPF_TRACE_DUMP *TraceDump, 
    IN PCCPF_TRACE_HEADER RuntimeTrace
    )

/*++

Routine Description:

    This routine allocates (from paged pool) and prepares a TraceDump
    structure from a run-time trace that can be saved on a list. It
    tries to get file names for all sections in the passed in run-time
    trace structure. The file names that are obtained are allocated
    from paged pool and put on the run-time trace's section info table
    and are cleaned up when that is cleaned up. The trace dump
    structure contains a pointer to an allocated (from paged pool)
    trace buffer that was built from the run-time trace, that can be
    passed to the user mode service. The caller is responsible for
    freeing both the TraceDump structure and the prepared trace.

Arguments:

    TraceDump - Where pointer to the allocated trace buffer is put if
      success is returned. If failure is returned, this is undefined.
    
    RuntimeTrace - Run-time trace structure to put into dump format.

Return Value:

    Status.

Environment:

    Kernel mode, IRQL == PASSIVE_LEVEL.

--*/

{
    NTSTATUS Status;
    ULONG SectionIdx;
    PCCPF_SECTION_INFO SectionInfo;
    ULONG FileNameLength;
    ULONG TraceSize;
    PPF_TRACE_HEADER Trace;
    ULONG FileNameDataNumChars;
    PSHORT SectIdTranslationTable;
    ULONG TranslationTableSize;
    PPF_SECTION_INFO TargetSectionInfo;
    LONG EntryIdx;
    LONG NumEntries;
    PCCPF_LOG_ENTRY LogEntry;
    PPF_LOG_ENTRY TargetLogEntry;
    ULONG NumEntriesCopied;
    ULONG NumSectionsCopied;
    PCHAR DestPtr;
    SHORT NewSectionId;
    PPF_LOG_ENTRY NewTraceEntries;
    ULONG SectionInfoSize;
    PCCPF_LOG_ENTRIES TraceBuffer;
    PLIST_ENTRY HeadEntry;
    PLIST_ENTRY NextEntry;
    LONG CurrentFaultIdx;
    LONG CurrentPeriodIdx;
    LONG CurrentPeriodEndFaultIdx;
    ULONG_PTR AlignmentOffset;
    ULONG AllocationSize;
    ULONG NumVolumes;
    ULONG TotalVolumeInfoSize;
    ULONG VolumeInfoSize;
    PCCPF_VOLUME_INFO VolumeInfo;
    PPF_VOLUME_INFO TargetVolumeInfo;
    ULONG FailedCheck;

    //
    // Initialize locals.
    //

    SectIdTranslationTable = NULL;
    Trace = NULL;
    *TraceDump = NULL;
    NumEntriesCopied = 0;

    DBGPR((CCPFID,PFTRC,"CCPF: DumpTrace(%p)\n", RuntimeTrace));

    //
    // If the acquired trace is too small, don't bother.
    //
      
    if (RuntimeTrace->NumFaults < PF_MIN_SCENARIO_PAGES) {
        Status = STATUS_BUFFER_TOO_SMALL;
        goto cleanup;
    }

    //
    // If the acquired trace does not contain any sections or volumes
    // it is useless.
    //

    if (!RuntimeTrace->NumSections || !RuntimeTrace->NumVolumes) {
        Status = STATUS_BUFFER_TOO_SMALL;
        goto cleanup;
    }

    //
    // Calculate the maximum size of trace we will build.
    //
    
    TraceSize = sizeof(PF_TRACE_HEADER);
    TraceSize += RuntimeTrace->NumFaults * sizeof(PF_LOG_ENTRY);
    TraceSize += RuntimeTrace->NumSections * sizeof(PF_SECTION_INFO);

    //
    // Add up file name data size.
    //

    FileNameDataNumChars = 0;
    
    for (SectionIdx = 0; 
         SectionIdx < RuntimeTrace->SectionTableSize; 
         SectionIdx++) {

        SectionInfo = &RuntimeTrace->SectionInfoTable[SectionIdx];
        
        if (SectionInfo->EntryValid && SectionInfo->FileName) {
            
            //
            // We would add space for terminating NUL but the space
            // for one character in section info accounts for that.
            //

            FileNameDataNumChars += wcslen(SectionInfo->FileName);
        }
    }

    TraceSize += FileNameDataNumChars * sizeof(WCHAR);

    //
    // We may have to align LogEntries coming after section infos that
    // contain WCHAR strings.
    //

    TraceSize += _alignof(PF_LOG_ENTRY);
    
    //
    // Add space for the volume info nodes.
    //

    HeadEntry = &RuntimeTrace->VolumeList;
    NextEntry = HeadEntry->Flink;

    NumVolumes = 0;
    TotalVolumeInfoSize = 0;
    
    while (NextEntry != HeadEntry) {
        
        VolumeInfo = CONTAINING_RECORD(NextEntry,
                                       CCPF_VOLUME_INFO,
                                       VolumeLink);
        
        NextEntry = NextEntry->Flink;

        //
        // Keep track of number of volumes on the list so we can
        // verify it.
        //

        NumVolumes++;

        //
        // Calculate size of this volume info in the dumped
        // trace. Note that PF_VOLUME_INFO contains space for the
        // terminating NUL.
        //

        VolumeInfoSize = sizeof(PF_VOLUME_INFO);
        VolumeInfoSize += VolumeInfo->VolumePathLength * sizeof(WCHAR);

        //
        // Update size for the volume info block. Add space for
        // aligning a volume info node if necessary.
        //
        
        TotalVolumeInfoSize += VolumeInfoSize;
        TotalVolumeInfoSize += _alignof(PF_VOLUME_INFO);        
    }

    CCPF_ASSERT(NumVolumes == RuntimeTrace->NumVolumes);

    TraceSize += TotalVolumeInfoSize;

    //
    // Allocate the trace dump structure we are going to
    // return. Subtract sizeof(PF_TRACE_HEADER) since both
    // CCPF_TRACE_DUMP and TraceSize include this.
    //

    AllocationSize = sizeof(CCPF_TRACE_DUMP);
    AllocationSize += TraceSize - sizeof(PF_TRACE_HEADER);

    *TraceDump = ExAllocatePoolWithTag(PagedPool,
                                       AllocationSize,
                                       CCPF_ALLOC_TRCDMP_TAG);

    if ((*TraceDump) == NULL) {
        Status = STATUS_INSUFFICIENT_RESOURCES;
        goto cleanup;
    }

    //
    // Get pointer to the trace structure.
    //
    
    Trace = &(*TraceDump)->Trace;
    
    //
    // Setup trace header.
    //

    Trace->Version = PF_CURRENT_VERSION;
    Trace->MagicNumber = PF_TRACE_MAGIC_NUMBER;
    Trace->ScenarioId = RuntimeTrace->ScenarioId;
    Trace->ScenarioType = RuntimeTrace->ScenarioType;
    Trace->LaunchTime = RuntimeTrace->LaunchTime;
    Trace->PeriodLength = RuntimeTrace->TraceTimerPeriod.QuadPart;

    //
    // Initialize faults per period to 0's. We will update these as we
    // copy valid entries from the runtime trace.
    //

    RtlZeroMemory(Trace->FaultsPerPeriod, sizeof(Trace->FaultsPerPeriod));

    DestPtr = (PCHAR) Trace + sizeof(PF_TRACE_HEADER);

    //
    // Copy over sections for which we have names. Since their indices
    // in the new table will be different, build a translation table
    // that we will use to translate the section id's of log
    // entries. First allocate this table.
    //

    TranslationTableSize = RuntimeTrace->SectionTableSize * sizeof(USHORT);

    SectIdTranslationTable = ExAllocatePoolWithTag(PagedPool,
                                                   TranslationTableSize,
                                                   CCPF_ALLOC_TRCDMP_TAG);
    
    if (!SectIdTranslationTable) {
        Status = STATUS_INSUFFICIENT_RESOURCES;
        goto cleanup;
    }
       
    //
    // Copy section information to the trace buffer while setting up
    // the translation table.
    //

    Trace->SectionInfoOffset = (ULONG) (DestPtr - (PCHAR) Trace);
    
    NumSectionsCopied = 0;
                                        
    for (SectionIdx = 0;
         SectionIdx < RuntimeTrace->SectionTableSize; 
         SectionIdx++) {
        
        SectionInfo = &RuntimeTrace->SectionInfoTable[SectionIdx];

        if (SectionInfo->EntryValid && 
            SectionInfo->FileName &&
            (FileNameLength = wcslen(SectionInfo->FileName)) > 0) {
            
            TargetSectionInfo = (PPF_SECTION_INFO) DestPtr;

            SectionInfoSize = sizeof(PF_SECTION_INFO);
            SectionInfoSize += FileNameLength * sizeof(WCHAR);

            //
            // Make sure we are not going off bounds.
            //
            
            if (DestPtr + SectionInfoSize > (PCHAR) Trace + TraceSize) {
                SectIdTranslationTable[SectionIdx] = CCPF_INVALID_TABLE_INDEX;
                CCPF_ASSERT(FALSE);
                continue;
            }

            TargetSectionInfo->FileNameLength = (USHORT) FileNameLength;

            TargetSectionInfo->Metafile = (USHORT) SectionInfo->Metafile;
            
            //
            // Copy the file name including the terminating NUL.
            //

            RtlCopyMemory(TargetSectionInfo->FileName,
                          SectionInfo->FileName,
                          (FileNameLength + 1) * sizeof(WCHAR));

            //
            // Update our position in the destination buffer.
            //
            
            DestPtr += SectionInfoSize;

            //
            // Update the translation table:
            //

            SectIdTranslationTable[SectionIdx] = (USHORT) NumSectionsCopied;

            NumSectionsCopied++;

        } else {

            SectIdTranslationTable[SectionIdx] = CCPF_INVALID_TABLE_INDEX;
        }
    }

    Trace->NumSections = NumSectionsCopied;
    CCPF_ASSERT(Trace->NumSections <= (ULONG) RuntimeTrace->NumSections);

    //
    // Make sure DestPtr is aligned for Log Entries coming next. We
    // had reserved max space we'd need for this adjustment upfront.
    //

    AlignmentOffset = ((ULONG_PTR) DestPtr) % _alignof(PF_LOG_ENTRY);
    
    if (AlignmentOffset) {
        DestPtr += (_alignof(PF_LOG_ENTRY) - AlignmentOffset);
    }

    //
    // Copy the log entries.
    //

    Trace->TraceBufferOffset = (ULONG) (DestPtr - (PCHAR) Trace);
    NewTraceEntries = (PPF_LOG_ENTRY) DestPtr;

    //
    // Initialize index of the current log entry in the whole runtime
    // trace, which period it was logged in, and what the index of the
    // first fault logged after this period was.
    //

    CurrentFaultIdx = 0;
    CurrentPeriodIdx = 0;
    CurrentPeriodEndFaultIdx = RuntimeTrace->FaultsPerPeriod[0];

    //
    // Walk through the trace buffers list and copy over
    // entries. NumEntriesCopied is initialized to 0 at the top.
    //

    HeadEntry = &RuntimeTrace->TraceBuffersList;
    NextEntry = HeadEntry->Flink;

    while (NextEntry != HeadEntry) {

        TraceBuffer = CONTAINING_RECORD(NextEntry,
                                        CCPF_LOG_ENTRIES,
                                        TraceBuffersLink);
        
        NumEntries = TraceBuffer->NumEntries;

        NextEntry = NextEntry->Flink;

        for (EntryIdx = 0, LogEntry = TraceBuffer->Entries;
             EntryIdx < NumEntries;
             EntryIdx++, LogEntry++, CurrentFaultIdx++) {    

            //
            // Current fault index should not be greater than the
            // total number of faults we logged in the trace.
            //

            if (CurrentFaultIdx >= RuntimeTrace->NumFaults) {
                CCPF_ASSERT(FALSE);
                Status = STATUS_INVALID_PARAMETER;
                goto cleanup;
            }

            //
            // Update the period this fault was logged in
            //

            while (CurrentFaultIdx >= CurrentPeriodEndFaultIdx) {
                
                CurrentPeriodIdx++;

                //
                // Check bounds on period.
                //

                if (CurrentPeriodIdx >= PF_MAX_NUM_TRACE_PERIODS) {
                    CCPF_ASSERT(FALSE);
                    Status = STATUS_INVALID_PARAMETER;
                    goto cleanup;
                }

                //
                // Update the end for this period. It is beyond the
                // current end by the number of entries logged in the
                // period.
                //
                
                CurrentPeriodEndFaultIdx += RuntimeTrace->FaultsPerPeriod[CurrentPeriodIdx];

                //
                // This end fault index should not be greater than the
                // total number of faults we logged.
                //

                if (CurrentPeriodEndFaultIdx > RuntimeTrace->NumFaults) {
                    CCPF_ASSERT(FALSE);
                    Status = STATUS_INVALID_PARAMETER;
                    goto cleanup;
                }
            }

            //
            // Make sure log entry's section id is within bounds.
            //

            if (LogEntry->SectionId >= RuntimeTrace->SectionTableSize) {
                CCPF_ASSERT(FALSE);
                continue;
            }

            NewSectionId = SectIdTranslationTable[LogEntry->SectionId];

            //
            // Copy only those entries for which we have a valid file
            // name.
            //
   
            if (NewSectionId != CCPF_INVALID_TABLE_INDEX) {

                //
                // New section id should be within the number of sections in
                // the final trace.
                //
            
                if ((USHORT) NewSectionId >= Trace->NumSections) {
                    CCPF_ASSERT(FALSE);
                    continue;
                }

                TargetLogEntry = &NewTraceEntries[NumEntriesCopied];

                //
                // Don't ever go beyond the buffer we had allocated.
                //

                if ((PCHAR) (TargetLogEntry + 1) > (PCHAR) Trace + TraceSize) {
                    CCPF_ASSERT(FALSE);
                    continue;
                }
            
                TargetLogEntry->FileOffset = LogEntry->FileOffset;
                TargetLogEntry->SectionId = NewSectionId;
                TargetLogEntry->IsImage = LogEntry->IsImage;
                TargetLogEntry->InProcess = LogEntry->InProcess;

                //
                // Update number of entries copied for this period. 
                //

                Trace->FaultsPerPeriod[CurrentPeriodIdx]++;

                //
                // Update the total number of entries copied.
                //

                NumEntriesCopied++;
            }
        }
    }

    Trace->NumEntries = NumEntriesCopied;
    CCPF_ASSERT(Trace->NumEntries <= (ULONG) RuntimeTrace->NumFaults);

    //
    // Update destination pointer.
    //
    
    DestPtr += NumEntriesCopied * sizeof(PF_LOG_ENTRY);

    //
    // Add volume info structures. Clear the VolumeInfoOffset, so it
    // will get set appropriately when we add the first volume.
    //

    Trace->VolumeInfoOffset = 0;
    Trace->NumVolumes = 0;
    Trace->VolumeInfoSize = 0;   

    HeadEntry = &RuntimeTrace->VolumeList;
    NextEntry = HeadEntry->Flink;
    
    while (NextEntry != HeadEntry) {
        
        VolumeInfo = CONTAINING_RECORD(NextEntry,
                                       CCPF_VOLUME_INFO,
                                       VolumeLink);
        
        NextEntry = NextEntry->Flink;

        //
        // Align the DestPtr for the VolumeInfo structure.
        //

        CCPF_ASSERT(PF_IS_POWER_OF_TWO(_alignof(PF_VOLUME_INFO)));
        DestPtr = PF_ALIGN_UP(DestPtr, _alignof(PF_VOLUME_INFO));

        //
        // If this is the first VolumeInfo, update the offset in the
        // trace header.
        //

        if (!Trace->VolumeInfoOffset) {
            Trace->VolumeInfoOffset = (ULONG) (DestPtr - (PCHAR) Trace);
        }

        //
        // Calculate size of this volume info in the dumped
        // trace. Note that PF_VOLUME_INFO contains space for the
        // terminating NUL.
        //

        VolumeInfoSize = sizeof(PF_VOLUME_INFO);
        VolumeInfoSize += VolumeInfo->VolumePathLength * sizeof(WCHAR);

        //
        // Make sure we have space for this entry.
        //
        
        if (DestPtr + VolumeInfoSize  > (PCHAR) Trace + TraceSize) {
            CCPF_ASSERT(FALSE);
            Status = STATUS_BUFFER_TOO_SMALL;
            goto cleanup;
        }

        //
        // Copy the data over.
        //

        TargetVolumeInfo = (PPF_VOLUME_INFO) DestPtr;
        
        TargetVolumeInfo->CreationTime = VolumeInfo->CreationTime;
        TargetVolumeInfo->SerialNumber = VolumeInfo->SerialNumber;
        
        RtlCopyMemory(TargetVolumeInfo->VolumePath,
                      VolumeInfo->VolumePath,
                      (VolumeInfo->VolumePathLength + 1) * sizeof(WCHAR));
        
        TargetVolumeInfo->VolumePathLength = VolumeInfo->VolumePathLength;

        //
        // Update DestPtr and the Trace header.
        //

        Trace->NumVolumes++;
        DestPtr = DestPtr + VolumeInfoSize;
    }    
    
    //
    // Update VolumeInfoSize on the trace header.
    //

    Trace->VolumeInfoSize = (ULONG) (DestPtr - (PCHAR) Trace) - Trace->VolumeInfoOffset;

    //
    // Update trace header. We should not have copied more than what
    // we allocated for.
    //

    Trace->Size = (ULONG) (DestPtr - (PCHAR) Trace);
    CCPF_ASSERT(Trace->Size <= TraceSize);

    //
    // Make sure the trace we built passes the tests.
    //

    if (!PfVerifyTraceBuffer(Trace, Trace->Size, &FailedCheck)) {
        CCPF_ASSERT(FALSE);
        Status = STATUS_UNSUCCESSFUL;
        goto cleanup;
    }
    
    Status = STATUS_SUCCESS;

 cleanup:

    if (SectIdTranslationTable) {
        ExFreePool(SectIdTranslationTable);
    }

    if (!NT_SUCCESS(Status)) {
        
        if (*TraceDump) {
            ExFreePool(*TraceDump);
        }
    }

    DBGPR((CCPFID,PFTRC,"CCPF: DumpTrace(%p)=%x [%d,%d]\n", 
           RuntimeTrace, Status, NumEntriesCopied, RuntimeTrace->NumFaults));

    return Status;
}

VOID
CcPfCleanupTrace (
    IN PCCPF_TRACE_HEADER Trace
    )

/*++

Routine Description:

    This routine cleans up allocated fields of a trace header, and
    releases references. It does not free the trace structure
    itself.

Arguments:

    Trace - Trace to cleanup.

Return Value:

    None.

Environment:

    Kernel mode, IRQL == PASSIVE_LEVEL.

--*/

{
    ULONG SectionIdx;
    PCCPF_SECTION_INFO SectionInfo;
    PCCPF_LOG_ENTRIES TraceBufferToFree;
    PLIST_ENTRY ListHead;
    PCCPF_VOLUME_INFO VolumeInfo;

    DBGPR((CCPFID,PFTRC,"CCPF: CleanupTrace(%p)\n", Trace));

    //
    // Validate parameters.
    //

    CCPF_ASSERT(Trace && Trace->Magic == PF_TRACE_MAGIC_NUMBER);

    //
    // We should not have any sections we are still trying to get
    // names for: we would have acquired a trace reference and cleanup
    // functions would not get called with pending references.
    //

    CCPF_ASSERT(ExQueryDepthSList(&Trace->SectionsWithoutNamesList) == 0);

    //
    // Free the trace buffers. 
    //

    while (!IsListEmpty(&Trace->TraceBuffersList)) {
        
        ListHead = RemoveHeadList(&Trace->TraceBuffersList);
        
        CCPF_ASSERT(Trace->NumTraceBuffers);
        Trace->NumTraceBuffers--;

        TraceBufferToFree = CONTAINING_RECORD(ListHead,
                                              CCPF_LOG_ENTRIES,
                                              TraceBuffersLink);
        
        ExFreePool(TraceBufferToFree);
    }
    
    //
    // Go through the section info hash. Free the file names and make
    // sure we don't have any file objects referenced anymore.
    //
    
    if (Trace->SectionInfoTable) {

        for (SectionIdx = 0; SectionIdx < Trace->SectionTableSize; SectionIdx++) {
            
            SectionInfo = &Trace->SectionInfoTable[SectionIdx];
            
            if (SectionInfo->EntryValid) {
                
                if (SectionInfo->FileName) {
                    ExFreePool(SectionInfo->FileName);
                }
                
                if (SectionInfo->ReferencedFileObject) {
                    ObDereferenceObject(SectionInfo->ReferencedFileObject);
                }
            }
        }

        ExFreePool(Trace->SectionInfoTable);
    }

    //
    // If there was a process we were associated with, release the
    // reference we got on it.
    //

    if (Trace->Process) {
        ObDereferenceObject(Trace->Process);
    }

    //
    // Free the volume info nodes.
    //

    while (!IsListEmpty(&Trace->VolumeList)) {
        
        CCPF_ASSERT(Trace->NumVolumes);
        
        Trace->NumVolumes--;

        ListHead = RemoveHeadList(&Trace->VolumeList);
        
        VolumeInfo = CONTAINING_RECORD(ListHead,
                                       CCPF_VOLUME_INFO,
                                       VolumeLink);
        
        ExFreePool(VolumeInfo);
    }   
}

VOID
CcPfTraceTimerRoutine(
    IN PKDPC Dpc,
    IN PVOID DeferredContext,
    IN PVOID SystemArgument1,
    IN PVOID SystemArgument2
    )

/*++

Routine Description:

    This routine is invoked as the DPC handler for the trace timer to
    keep track of page faults per period as well as trace timeout.

    Note that the timer may fire before the trace has been activated.

    There is always a trace reference associated with the timer queued,
    If the timer fires, this reference must be freed before this routine 
    returns. If the timer is canceled while in the queue, this reference
    must be freed by who has canceled it.

Arguments:

    DeferredContext - Pointer to the trace header.

Return Value:

    None.

Environment:

    Kernel mode. IRQL == DISPATCH_LEVEL.

--*/

{
    PCCPF_TRACE_HEADER Trace;
    NTSTATUS Status;
    LONG NumFaults;
    
    UNREFERENCED_PARAMETER (Dpc);
    UNREFERENCED_PARAMETER (SystemArgument1);
    UNREFERENCED_PARAMETER (SystemArgument2);

    //
    // Initialize locals.
    //

    Trace = DeferredContext;

    DBGPR((CCPFID,PFTMR,"CCPF: TraceTimer(%p)\n", Trace));

    //
    // We already got a reference to our trace when the timer was queued.
    // The fields we access / update in this routine are only accessed by
    // the timer routine. There should be a single instance of this 
    // routine running on this trace.
    //

    CCPF_ASSERT(Trace && Trace->Magic == PF_TRACE_MAGIC_NUMBER);

    //
    // If the trace is going away don't do anything.
    //

    if (Trace->EndTraceCalled) {
        Status = STATUS_TOO_LATE;
        goto cleanup;
    }

    //
    // Update number of faults for this period.
    //

    NumFaults = Trace->NumFaults;

    //
    // Don't let NumFaults be bigger than MaxFaults. We may interlocked increment
    // then decrement Trace->NumFaults if it goes over MaxFaults.
    //

    if (NumFaults > Trace->MaxFaults) {
        NumFaults = Trace->MaxFaults;
    }
        
    Trace->FaultsPerPeriod[Trace->CurPeriod] = NumFaults - Trace->LastNumFaults;
    
    Trace->LastNumFaults = NumFaults;

    //
    // Update current period.
    //
    
    Trace->CurPeriod++;

    //
    // If current period is past max number of periods, try to queue
    // end of trace work item.
    //

    if (Trace->CurPeriod >= PF_MAX_NUM_TRACE_PERIODS) {
        
        //
        // We should have caught CurPeriod before it goes above max.
        //

        CCPF_ASSERT(Trace->CurPeriod == PF_MAX_NUM_TRACE_PERIODS);

        if (!InterlockedCompareExchange(&Trace->EndTraceCalled, 1, 0)) {
            
            //
            // We set EndTraceCalled from 0 to 1. We can queue the
            // workitem now.
            //

            ExQueueWorkItem(&Trace->EndTraceWorkItem, DelayedWorkQueue);
        }

    } else {

        //
        // Queue ourselves for the next period.
        //

        KeAcquireSpinLockAtDpcLevel(&Trace->TraceTimerSpinLock);       

        if (!Trace->EndTraceCalled) {

            //
            // Requeue the timer only if the trace is not being ended.
            //

            Status = CcPfAddRef(&Trace->RefCount);

            if (NT_SUCCESS(Status)) {
        
                KeSetTimer(&Trace->TraceTimer,
                           Trace->TraceTimerPeriod,
                           &Trace->TraceTimerDpc);
            }
        }

        KeReleaseSpinLockFromDpcLevel(&Trace->TraceTimerSpinLock);

        //
        // We should not touch any fields of the Trace beyond this point
        // except releasing our reference count.
        //
    }

    Status = STATUS_SUCCESS;

 cleanup:

    //
    // Release the trace reference acquired when this timer was queued.
    //

    CcPfDecRef(&Trace->RefCount);

    DBGPR((CCPFID,PFTMR,"CCPF: TraceTimer(%p)=%x\n", Trace, Status));

    return;
}

NTSTATUS
CcPfCancelTraceTimer(
    IN PCCPF_TRACE_HEADER Trace
    )

/*++

Routine Description:

    This function is called from CcPfEndTrace to cancel the timer and
    release its refcount if it was in the queue. 

    It is a seperate function because it needs to acquire a spinlock and
    CcPfEndTrace can remain pagable.
    
Arguments:

    Trace - Pointer to trace header.

Return Value:

    STATUS_SUCCESS.

Environment:

    Kernel mode. IRQL == PASSIVE_LEVEL. Acquires spinlock.


--*/

{
    KIRQL OrigIrql;

    KeAcquireSpinLock(&Trace->TraceTimerSpinLock, &OrigIrql);

    //
    // We know that no new timers can be queued from here on because EndTraceCalled
    // has been set and we have acquired the trace's timer lock. Running timer 
    // routines will release their references as they return. 
    //

    if (KeCancelTimer(&Trace->TraceTimer)) {

        //
        // If we canceled a timer that was in the queue, then there was a reference 
        // associated with it. It is our responsibility to release it.
        // 

        CcPfDecRef(&Trace->RefCount);
    }

    KeReleaseSpinLock(&Trace->TraceTimerSpinLock, OrigIrql);

    return STATUS_SUCCESS;
}

VOID
CcPfEndTraceWorkerThreadRoutine(
    PVOID Parameter
    )

/*++

Routine Description:

    This routine is queued to call end of trace function for the
    specified trace.

Arguments:

    Parameter - Pointer to trace to end.

Return Value:

    None.

Environment:

    Kernel mode. IRQL == PASSIVE_LEVEL.

--*/

{
    PCCPF_TRACE_HEADER Trace;

    //
    // Initialize locals.
    //

    Trace = Parameter;

    DBGPR((CCPFID,PFTRC,"CCPF: EndTraceWorker(%p)\n", Trace));

    //
    // Call the real end of trace routine.
    //

    CcPfEndTrace(Trace);

    return;
}

VOID
CcPfGetFileNamesWorkerRoutine(
    PVOID Parameter
    )

/*++

Routine Description:

    This routine is queued to get file names for sections we have
    logged page faults to. GetFileNameWorkItemQueued on the trace
    header should have been InterlockedCompareExchange'd from 0 to 1
    and a reference to the trace should have been acquired before
    this is queued. There are no locks protecting the trace's
    SectionInfoTable, and this is how we make sure there is only one
    routine trying to get filenames and update the table.

    Note: This whole function is in a way a cleanup clause. We will
    empty the SectionsWithoutNamesList queue, we get names or not. So
    do not just put a return anywhere in the function without really
    understanding the flow and making sure the list is cleaned up, so
    all the file object references are deref'ed.

Arguments:

    Parameter - Pointer to trace header.

Return Value:

    None.

Environment:

    Kernel mode. IRQL == PASSIVE_LEVEL. Uses interlocked slist operation.

--*/

{
    PCCPF_TRACE_HEADER Trace;
    PDEVICE_OBJECT DeviceObject;
    POBJECT_NAME_INFORMATION FileNameInfo;
    PFSRTL_COMMON_FCB_HEADER FcbHeader;
    PWCHAR Suffix;
    PWCHAR MFTFileSuffix;
    ULONG QueryBufferSize;
    ULONG ReturnedLength;
    ULONG FileNameLength;
    PCCPF_SECTION_INFO SectionInfo;
    PSINGLE_LIST_ENTRY SectionLink;
    ULONG NumNamesAcquired;
    ULONG NumSectionsWithoutNames;
    LONG NumPasses;
    NTSTATUS Status;
    LARGE_INTEGER WaitTimeout;
    ULONG MFTFileSuffixLength;
    LONG NumSleeps;
    CSHORT NodeTypeCode;

    //
    // Initialize locals and validate parameters.
    //

    Trace = Parameter;
    CCPF_ASSERT(Trace && Trace->Magic == PF_TRACE_MAGIC_NUMBER);

    FileNameInfo = NULL;
    NumNamesAcquired = 0;
    NumSectionsWithoutNames = 0;
    MFTFileSuffix = L"\\$Mft";
    MFTFileSuffixLength = wcslen(MFTFileSuffix);

    DBGPR((CCPFID,PFNAME,"CCPF: GetNames(%p)\n", Trace)); 

    //
    // Allocate a file name query buffer.
    //

    QueryBufferSize = sizeof(OBJECT_NAME_INFORMATION);
    QueryBufferSize += PF_MAXIMUM_SECTION_FILE_NAME_LENGTH * sizeof(WCHAR);

    FileNameInfo = ExAllocatePoolWithTag (PagedPool | POOL_COLD_ALLOCATION, 
                                          QueryBufferSize, 
                                          CCPF_ALLOC_QUERY_TAG);

    if (!FileNameInfo) {

        //
        // We could not allocate a file name query buffer. Bummer, we
        // still have to empty the queue, although we can't be getting
        // any file names.
        //

        QueryBufferSize = 0;

        DBGPR((CCPFID,PFWARN,"CCPF: GetNames-FailedQueryAlloc\n")); 
    }   

    NumPasses = 0;
    NumSleeps = 0;

    do {

        //
        // We may come back here if after saying that we (the get-name
        // worker) are no longer active, and we see that there are
        // still sections to get names for, and we reactivate
        // ourselves. This covers the case when somebody decides not
        // to start us because we are active, just as we are
        // deactivating ourselves.
        //

        //
        // While there are sections we have to get names for...
        //
        
        while (SectionLink = InterlockedPopEntrySList(&Trace->SectionsWithoutNamesList)) {

            SectionInfo = CONTAINING_RECORD(SectionLink,
                                            CCPF_SECTION_INFO,
                                            GetNameLink);
            
            NumSectionsWithoutNames++;

            //
            // We are getting names for sections. Clear the event that
            // may have been signalled to tell us to do so.
            //

            KeClearEvent(&Trace->GetFileNameWorkerEvent);

            //
            // We should not have already gotten a file name for this
            // valid section entry. We should have a referenced file
            // object from which we can safely get a name, i.e. not a
            // special file system object.
            //

            CCPF_ASSERT(SectionInfo->EntryValid);
            CCPF_ASSERT(!SectionInfo->FileName);
            CCPF_ASSERT(SectionInfo->ReferencedFileObject);

            //
            // If we could not allocate a file name query buffer, just skip this
            // section. Note that we still had to dequeue it however.
            //

            if (!FileNameInfo) {
                goto NextQueuedSection;
            }

            //
            // Check if this pagefault is for a file that's on a fixed disk.
            //

            DeviceObject = IoGetRelatedDeviceObject(SectionInfo->ReferencedFileObject);
            
            if ((DeviceObject == NULL) ||
                (DeviceObject->DeviceType != FILE_DEVICE_DISK_FILE_SYSTEM) ||
                (DeviceObject->Characteristics & (FILE_REMOVABLE_MEDIA | FILE_REMOTE_DEVICE))) {

                //
                // We will not get a section name for this section. This results 
                // in this section being ignored when preparing a trace dump.               
                //

                goto NextQueuedSection;
            }

            //
            // If this is a metafile section (e.g. for a directory) see if 
            // it is on a filesystem that supports metafile prefetching. 
            // A section is for internal file system metafile if its FsContext2 
            // is NULL. 
            //

            if (SectionInfo->ReferencedFileObject->FsContext2 == 0) {

                FcbHeader = SectionInfo->ReferencedFileObject->FsContext;

                if (FcbHeader) {

                    //
                    // Currently only NTFS supports metafile prefetching. FAT hits 
                    // a race condition  if we ask names for metafile sections. 
                    // To determine if it is for NTFS, we check the NodeType range  
                    // on FsContext. 0x07xx is reserved for NTFS and 0x05xx 
                    // is reserved for FAT.

                    NodeTypeCode = FcbHeader->NodeTypeCode;

                    if ((NodeTypeCode >> 8) != 0x07) {

                        //
                        // Skip this section.
                        //

                        goto NextQueuedSection;
                    }

                    //
                    // Note that this section is for metafile.
                    //

                    SectionInfo->Metafile = 1;

                } else {

                    //
                    // We will not get a section name for this metafile section. This 
                    // results in this section being ignored when preparing a trace dump.
                    //

                    goto NextQueuedSection;
                }
            }

            //
            // Try to get the name for the file object. This will most
            // likely fail if we could not allocate a FileNameInfo
            // buffer.
            //
                
            Status = ObQueryNameString(SectionInfo->ReferencedFileObject,
                                       FileNameInfo,
                                       QueryBufferSize,
                                       &ReturnedLength);

            
            if (!NT_SUCCESS(Status)) {
                goto NextQueuedSection;
            }

            //
            // Allocate a file name buffer and copy into
            // it. The file names will be NUL terminated.
            // Allocate extra for that.
            //
                
            FileNameLength = FileNameInfo->Name.Length / sizeof(WCHAR);
                
            SectionInfo->FileName = ExAllocatePoolWithTag(PagedPool | POOL_COLD_ALLOCATION,
                                                          (FileNameLength + 1) * sizeof(WCHAR),
                                                          CCPF_ALLOC_FILENAME_TAG);
                
            if (SectionInfo->FileName) {
                    
                RtlCopyMemory(SectionInfo->FileName,
                              FileNameInfo->Name.Buffer,
                              FileNameLength * sizeof(WCHAR));
                    
                //
                // Make sure it is NUL terminated.
                //

                SectionInfo->FileName[FileNameLength] = 0;

                //
                // If the section is for a metafile check if it is for Mft. 
                // Unlike other metafile, we are interested in faults from
                // Mft in addition to knowing that we accessed it at all.
                //

                if (SectionInfo->Metafile) {

                    if (FileNameLength >= MFTFileSuffixLength) {

                        Suffix = SectionInfo->FileName + FileNameLength;
                        Suffix -= MFTFileSuffixLength;

                        if (wcscmp(Suffix, MFTFileSuffix) == 0) {

                            //
                            // Clear the "Metafile" bit of MFT so we keep
                            // track of faults from it.
                            //

                            SectionInfo->Metafile = 0;
                        }
                    }
                }

                //
                // Update the volume list with the volume this
                // section is on. We reuse the existing query
                // buffer to get volume's name since we've already
                // copied the file's name to another buffer. The
                // device object for the file should be for the
                // volume.
                //

                Status = ObQueryNameString(SectionInfo->ReferencedFileObject->DeviceObject,
                                           FileNameInfo,
                                           QueryBufferSize,
                                           &ReturnedLength);
                
                if (NT_SUCCESS(Status)) {                 

                    RtlUpcaseUnicodeString(&FileNameInfo->Name, &FileNameInfo->Name, FALSE);

                    Status = CcPfUpdateVolumeList(Trace,
                                                  FileNameInfo->Name.Buffer,
                                                  FileNameInfo->Name.Length / sizeof(WCHAR));
                }

                if (!NT_SUCCESS(Status)) {

                    //
                    // If we could not update the volume list as
                    // necessary for this section, we have to
                    // cleanup and ignore this section.
                    //
                    
                    ExFreePool(SectionInfo->FileName);
                    SectionInfo->FileName = NULL;
                    
                } else {
                    
                    NumNamesAcquired++;
                }

            }

          NextQueuedSection:
          
            //
            // Dereference the file object, and clear it on the section
            // entry.
            //

            ObDereferenceObject(SectionInfo->ReferencedFileObject);
            SectionInfo->ReferencedFileObject = NULL;

            //
            // If we could not get a name because the query failed or
            // we could not allocate a name buffer, too bad. For this
            // run, pagefaults for this section will be ignored. Over
            // time it will straighten itself out.
            //
        }

        //
        // We don't seem to have any more queued section
        // entries. Before marking ourself inactive, wait a
        // little. Maybe someone will want us to get name for another
        // section. Then we'll save the overhead of queuing another
        // workitem. Set a limit on how long we'll wait though
        // [negative because it is relative, in 100ns].
        //

        //
        // Note that we are sleeping while holding a trace
        // reference. If end trace gets called, it also signals the
        // event to make us release that reference quicker.
        //

        //
        // If we could not even allocate a query buffer,
        // no reason to wait for more misery.
        //

        if (FileNameInfo) {

            WaitTimeout.QuadPart = - 200 * 1000 * 10; // 200 ms.

            DBGPR((CCPFID,PFNAMS,"CCPF: GetNames-Sleeping:%p\n", Trace)); 

            NumSleeps++;

            Status = KeWaitForSingleObject(&Trace->GetFileNameWorkerEvent,
                                           Executive,
                                           KernelMode,
                                           FALSE,
                                           &WaitTimeout);

            DBGPR((CCPFID,PFNAMS,"CCPF: GetNames-WokeUp:%x\n", Status)); 
        }
        
        //
        // If there are no new sections to get names for, go ahead and
        // mark ourselves inactive, otherwise we will loop to get more
        // names.
        //

        if (!ExQueryDepthSList(&Trace->SectionsWithoutNamesList)) {

            //
            // We went through all the queued section entries. Note that
            // we are no longer active.
            //

            InterlockedExchange(&Trace->GetFileNameWorkItemQueued, 0);

            //
            // Check to see if there are new sections to get file
            // names for since we last checked and marked ourselves
            // inactive.
            //
        
            if (ExQueryDepthSList(&Trace->SectionsWithoutNamesList)) {

                //
                // Somebody may have inserted a section to get name for,
                // but seeing us active may not have queued another work
                // item. If it is so and we don't get name for that
                // section, we may keep the file object referenced for
                // longer than we'd like to. Try to mark ourselves active
                // again.
                //

                if (!InterlockedCompareExchange(&Trace->GetFileNameWorkItemQueued, 
                                                1, 
                                                0)) {

                    //
                    // We marked ourselves active. They really may not
                    // have queued another worker. Loop and check for
                    // more work.
                    //

                    //
                    // Note that, they may not fool us to loop more
                    // than MaxSections through this path, since they
                    // have to still queue a new section to make the
                    // ExQueryDepthSList above return != 0, and there
                    // may be max MaxSections.
                    //

                } else {
                
                    //
                    // It seems another worker was queued. Any items
                    // on the work list are that guy's problem
                    // now. Break out and cleanup.
                    //

                    break;
                }

            } else {

                //
                // No more work items on the list. We are really
                // done. Just break out and cleanup.
                //

                break;
            }
        }

        //
        // Bump number of passes we've made over the sections-without-
        // names-list. We should not have to make more passes than the
        // max number of section info entries we can have. This is an
        // infinite loop protection and should not happen. If it does,
        // however, in the worst case we will keep a reference to a
        // file object longer than we'd like to, and we may not get a
        // file name for it.
        //

        NumPasses++;
        if (NumPasses > Trace->MaxSections) {    
            CCPF_ASSERT(FALSE);
            break;
        }
       
    } while (TRUE);

    //
    // Clean up:
    //

    if (FileNameInfo) {
        ExFreePool(FileNameInfo);
    }

    //
    // Release reference on the trace as the very last thing. Don't
    // touch anything from the trace after this.
    //

    CcPfDecRef(&Trace->RefCount);

    DBGPR((CCPFID,PFNAME,"CCPF: GetNames(%p)=%d-%d,[%d-%d]\n", 
           Trace, NumSectionsWithoutNames, NumNamesAcquired,
           NumPasses, NumSleeps)); 

    return;
}

LONG
CcPfLookUpSection(
    PCCPF_SECTION_INFO Table,
    ULONG TableSize,
    PSECTION_OBJECT_POINTERS SectionObjectPointer,
    PLONG AvailablePosition
    )

/*++

Routine Description:

    This routine is called to look up a section in the specified
    section table hash. If the section is found its index is
    returned. Otherwise index to where the section should go in the
    table is put into AvailablePosition, if the table is not
    full.

Arguments:

    Table - An array of section info entries used as a hash table.

    TableSize - Maximum size of the table.

    SectionObjectPointer - This is used as a key to identify a mapping.

    AvailablePosition - If section is not found and there is room in
      the table, index of where the section should go is put here.

Return Value:

    Index into the table where the section is found or CCPF_INVALID_TABLE_INDEX

Environment:

    Kernel mode, IRQL <= DISPATCH_LEVEL if Table is NonPaged.

--*/

{
    PCCPF_SECTION_INFO Entry;
    ULONG StartIdx;
    ULONG EndIdx;
    ULONG EntryIdx;
    ULONG HashIndex;
    ULONG NumPasses;

    //
    // Get the hashed index into the table where the entry ideally
    // should be at.
    //

    HashIndex = CcPfHashValue((PVOID)&SectionObjectPointer, 
                              sizeof(SectionObjectPointer)) % TableSize;

    //
    // We will make two runs through the table looking for the
    // entry. First starting from the hashed position up to the end of
    // the table. Next from the beginning of the table up to the
    // hashed position.
    //

    NumPasses = 0;

    do {

        //
        // Setup start and end indices accordingly.
        //

        if (NumPasses == 0) {
            StartIdx = HashIndex;
            EndIdx = TableSize;
        } else {
            StartIdx = 0;
            EndIdx = HashIndex;
        }
    
        for (EntryIdx = StartIdx; EntryIdx < EndIdx; EntryIdx++) {
            
            Entry = &Table[EntryIdx];
            
            if (Entry->EntryValid) {
                
                if (Entry->SectionObjectPointer == SectionObjectPointer) {

                    //
                    // Check if other saved fields match the fields of
                    // the SectionObjectPointer we are trying to find.
                    // Please see the comments in CCPF_SECTION_INFO
                    // definition.
                    //
                    
                    if (Entry->DataSectionObject == SectionObjectPointer->DataSectionObject &&
                        Entry->ImageSectionObject == SectionObjectPointer->ImageSectionObject) {
                    
                        //
                        // We found the entry.
                        //
                        
                        *AvailablePosition = CCPF_INVALID_TABLE_INDEX;
                    
                        return EntryIdx;

                    } else if (Entry->DataSectionObject == SectionObjectPointer->DataSectionObject ||
                               Entry->ImageSectionObject == SectionObjectPointer->ImageSectionObject) {
                        
                        //
                        // If one of them matches, check to see if the
                        // one that does not match is NULL on the
                        // Entry. We don't want to create two entries
                        // for the same file when it is first opened
                        // as data and then as image or vice
                        // versa. Note that if later image or data
                        // segment gets deleted, we may end up
                        // creating a new entry. We are optimizing
                        // only for the case that we think is likely
                        // to happen often.
                        //
                        
                        if (Entry->DataSectionObject == NULL &&
                            SectionObjectPointer->DataSectionObject != NULL) {

                            DBGPR((CCPFID,PFLKUP,"CCPF: LookupSect-DataSectUpt(%p)\n", SectionObjectPointer)); 

                            //
                            // Try to update the entry. If our update
                            // was succesful, return found entry.
                            //

                            InterlockedCompareExchangePointer(&Entry->DataSectionObject,
                                                              SectionObjectPointer->DataSectionObject,
                                                              NULL);

                            if (Entry->DataSectionObject == SectionObjectPointer->DataSectionObject) {
                                 *AvailablePosition = CCPF_INVALID_TABLE_INDEX;
                                 return EntryIdx;
                            }
                        }
                        
                        if (Entry->ImageSectionObject == NULL &&
                            SectionObjectPointer->ImageSectionObject != NULL) {

                            DBGPR((CCPFID,PFLKUP,"CCPF: LookupSect-ImgSectUpt(%p)\n", SectionObjectPointer)); 

                            //
                            // Try to update the entry. If our update
                            // was succesful, return found entry.
                            //
                            
                            InterlockedCompareExchangePointer(&Entry->ImageSectionObject,
                                                              SectionObjectPointer->ImageSectionObject,
                                                              NULL);

                            if (Entry->ImageSectionObject == SectionObjectPointer->ImageSectionObject) {
                                 *AvailablePosition = CCPF_INVALID_TABLE_INDEX;
                                 return EntryIdx;
                            }
                        }

                        //
                        // Most likely, the field that matched was
                        // NULL, signifying nothing. Fall through to
                        // continue with the lookup.
                        //
                    }

                    //
                    // Although the SectionObjectPointer matches the
                    // other fields don't match. The old file may be
                    // gone and this may be a new file that somehow
                    // ended up with the same SectionObjectPointer.
                    // Continue the lookup.
                    //

                }
                
            } else {
                
                //
                // This is an available position. The fact that the entry
                // is not here means the entry is not in the table.
                //
                
                *AvailablePosition = EntryIdx;
                
                return CCPF_INVALID_TABLE_INDEX;
            }

        }

        NumPasses++;

    } while (NumPasses < 2);

    //
    // We could not find the entry or an available position.
    //

    *AvailablePosition = CCPF_INVALID_TABLE_INDEX;

    return CCPF_INVALID_TABLE_INDEX;
}

NTSTATUS
CcPfGetCompletedTrace (
    PVOID Buffer,
    ULONG BufferSize,
    PULONG ReturnSize
    )

/*++

Routine Description:

    If there is a completed scenario trace on the completed traces
    list, this routine tries to copy it into the supplied buffer and
    remove it. If BufferSize is too small, nothing is copied or
    removed from the list, but ReturnSize is set to how big a buffer
    is needed to get the first trace on the list. If BufferSize is
    large enough, the number of bytes copied into the buffer is set on
    the ReturnSize.

Arguments:

    Buffer - Caller supplied buffer to copy a completed trace into.

    BufferSize - Size of the caller supplied buffer in bytes.

    ReturnSize - If BufferSize is big enough for the completed trace
      number of bytes copied is put here. If BufferSize is not big
      enough for the trace, the required size is put here. If there
      are no more entries, this variable undefined.

Return Value:

    STATUS_BUFFER_TOO_SMALL - BufferSize is not big enough for the
      first completed trace on the list.

    STATUS_NO_MORE_ENTRIES - There are no more completed traces on the
      list.

    STATUS_SUCCESS - A trace was removed from the list and copied into
      the buffer.

    or other status.

Environment:

    Kernel mode, IRQL == PASSIVE_LEVEL.

--*/

{
    PCCPF_TRACE_DUMP TraceDump;
    NTSTATUS Status;
    KPROCESSOR_MODE PreviousMode;
    BOOLEAN HoldingCompletedTracesLock;

    //
    // Initialize locals.
    //

    HoldingCompletedTracesLock = FALSE;

    DBGPR((CCPFID,PFTRC,"CCPF: GetCompletedTrace()\n"));

    //
    // Get the completed traces lock. 
    //

    ExAcquireFastMutex(&CcPfGlobals.CompletedTracesLock);

    HoldingCompletedTracesLock = TRUE;

    //
    // If the list is empty, there are no more completed trace entries.
    //
    
    if (IsListEmpty(&CcPfGlobals.CompletedTraces)) {
        Status = STATUS_NO_MORE_ENTRIES;
        goto cleanup;
    }

    //
    // Peek at the trace to see if it will fit into the supplied
    // buffer.
    //

    TraceDump = CONTAINING_RECORD(CcPfGlobals.CompletedTraces.Flink,
                                  CCPF_TRACE_DUMP,
                                  CompletedTracesLink);
    
    if (TraceDump->Trace.Size > BufferSize) {
        *ReturnSize = TraceDump->Trace.Size;
        Status = STATUS_BUFFER_TOO_SMALL;
        goto cleanup;
    }

    //
    // The trace will fit in the user supplied buffer. Remove it from
    // the list, release the lock and copy it.
    //
    
    RemoveHeadList(&CcPfGlobals.CompletedTraces);
    CcPfGlobals.NumCompletedTraces--;
    
    ExReleaseFastMutex(&CcPfGlobals.CompletedTracesLock);

    HoldingCompletedTracesLock = FALSE;
    
    //
    // Copy the completed trace buffer.
    //

    Status = STATUS_SUCCESS;

    try {

        //
        // If called from user-mode, probe whether it is safe to write 
        // to the pointer passed in.
        //

        PreviousMode = KeGetPreviousMode();

        if (PreviousMode != KernelMode) {
            ProbeForWrite(Buffer, BufferSize, _alignof(PF_TRACE_HEADER));
        }

        //
        // Copy into the probed user buffer.
        //

        RtlCopyMemory(Buffer,
                      &TraceDump->Trace,
                      TraceDump->Trace.Size);

    } except (EXCEPTION_EXECUTE_HANDLER) {

        Status = GetExceptionCode();
    }

    if (!NT_SUCCESS(Status)) {

        //
        // The copy failed. Requeue the trace for the next query.
        // Note that we might end up with one too many traces in
        // the list because of this, but that's OK.
        //

        ExAcquireFastMutex(&CcPfGlobals.CompletedTracesLock);
        HoldingCompletedTracesLock = TRUE;
        InsertHeadList(&CcPfGlobals.CompletedTraces,&TraceDump->CompletedTracesLink);
        CcPfGlobals.NumCompletedTraces++;

    } else {
    
        //
        // Set number of bytes copied.
        //

        *ReturnSize = TraceDump->Trace.Size;
    
        //
        // Free the trace dump entry.
        //
    
        ExFreePool(TraceDump);

        //
        // We are done.
        //

        Status = STATUS_SUCCESS;
    }

 cleanup:

    if (HoldingCompletedTracesLock) {
        ExReleaseFastMutex(&CcPfGlobals.CompletedTracesLock);
    }

    DBGPR((CCPFID,PFTRC,"CCPF: GetCompletedTrace()=%x\n", Status));

    return Status;
}


NTSTATUS
CcPfUpdateVolumeList(
    PCCPF_TRACE_HEADER Trace,
    WCHAR *VolumePath,
    ULONG VolumePathLength
    )

/*++

Routine Description:

    If the specified volume is not in the volume list of Trace, its
    information is acquired and added to the list.

    This routine does not use any synchronization when accessing and
    updating the volume list on the trace.
    
Arguments:

    Trace - Pointer to trace.
    
    VolumePath - Pointer to UPCASED volume path. Does NOT need to be NUL
      terminated.
    
    VolumePathLength - Length of VolumePath in characters excluding
      NUL.

Return Value:

    Status.

Environment:

    Kernel mode. IRQL == PASSIVE_LEVEL.

--*/

{
    NTSTATUS Status;
    PLIST_ENTRY NextEntry;
    PLIST_ENTRY FoundPosition;
    PLIST_ENTRY HeadEntry;
    PCCPF_VOLUME_INFO CurrentVolumeInfo;
    PCCPF_VOLUME_INFO NewVolumeInfo;
    LONG ComparisonResult;
    ULONG AllocationSize;
    BOOLEAN InsertedNewVolume;

    //
    // Define an enumeration for the passes we make over the volume
    // list.
    //

    enum {
        LookingForVolume,
        AddingNewVolume,
        MaxLoopIdx
    } LoopIdx;

    //
    // Initialize locals.
    //
    
    NewVolumeInfo = NULL;
    InsertedNewVolume = FALSE;

    //
    // We should be called with a valid volume name.
    //
    
    if (!VolumePathLength) {
        CCPF_ASSERT(VolumePathLength != 0);
        Status = STATUS_INVALID_PARAMETER;
        goto cleanup;
    }

    //
    // Walk the volume list. We will make two passes. First we will 
    // check to see if the volume already exists in the list. If it 
    // does not, we'll release the lock, build a new volume node and 
    // make a second pass to insert it.
    //
    
    for (LoopIdx = LookingForVolume; LoopIdx < MaxLoopIdx; LoopIdx++) {

        //
        // Determine what to do based on which pass we are in.
        //

        if (LoopIdx == LookingForVolume) {
            
            CCPF_ASSERT(!InsertedNewVolume);
            CCPF_ASSERT(!NewVolumeInfo);

        } else if (LoopIdx == AddingNewVolume) {
            
            CCPF_ASSERT(!InsertedNewVolume);
            CCPF_ASSERT(NewVolumeInfo);    

        } else {

            //
            // We should only loop two times.
            //

            CCPF_ASSERT(FALSE);

            Status = STATUS_UNSUCCESSFUL;
            goto cleanup;
        }

        HeadEntry = &Trace->VolumeList;
        NextEntry = HeadEntry->Flink;
        FoundPosition = NULL;
        
        while (NextEntry != HeadEntry) {
        
            CurrentVolumeInfo = CONTAINING_RECORD(NextEntry,
                                                  CCPF_VOLUME_INFO,
                                                  VolumeLink);

            NextEntry = NextEntry->Flink;

            ComparisonResult = wcsncmp(VolumePath, 
                                       CurrentVolumeInfo->VolumePath, 
                                       VolumePathLength);
        
            if (ComparisonResult == 0) {

                //
                // Make sure VolumePathLength's are equal
                //
            
                if (CurrentVolumeInfo->VolumePathLength != VolumePathLength) {
                
                    //
                    // Continue searching.
                    //
                
                    continue;
                }
            
                //
                // The volume already exists in the list.
                //
            
                Status = STATUS_SUCCESS;
                goto cleanup;

            } else if (ComparisonResult < 0) {
            
                //
                // The volume paths are sorted lexically. The file
                // path would be less than other volumes too. We'd
                // insert the new node before this entry.
                //

                FoundPosition = &CurrentVolumeInfo->VolumeLink;

                break;
            }

            //
            // Continue looking...
            //
        
        }

        //
        // If we could not find an entry to insert the new node
        // before, it goes before the list head.
        //

        if (!FoundPosition) {
            FoundPosition = HeadEntry;
        }

        //
        // If we come here, we could not find the volume in the list.
        //

        //
        // If this is the first pass over the list (we were checking
        // if the volume already exists), release the lock and build a
        // volume node.
        //

        if (LoopIdx == LookingForVolume) {

            // 
            // Build a new node. Note that CCPF_VOLUME_INFO already
            // has space for the terminating NUL character.
            //

            AllocationSize = sizeof(CCPF_VOLUME_INFO);
            AllocationSize += VolumePathLength * sizeof(WCHAR);

            NewVolumeInfo = ExAllocatePoolWithTag(PagedPool | POOL_COLD_ALLOCATION,
                                                  AllocationSize,
                                                  CCPF_ALLOC_VOLUME_TAG);
    
            if (!NewVolumeInfo) {
                Status = STATUS_INSUFFICIENT_RESOURCES;
                goto cleanup;
            }

            //
            // Copy the volume name and terminate it.
            //
    
            RtlCopyMemory(NewVolumeInfo->VolumePath,
                          VolumePath,
                          VolumePathLength * sizeof(WCHAR));
    
            NewVolumeInfo->VolumePath[VolumePathLength] = 0;
            NewVolumeInfo->VolumePathLength = VolumePathLength;

            //
            // Query the signature and creation time.
            //

            Status = CcPfQueryVolumeInfo(NewVolumeInfo->VolumePath,
                                         NULL,
                                         &NewVolumeInfo->CreationTime,
                                         &NewVolumeInfo->SerialNumber);

            if (!NT_SUCCESS(Status)) {
                goto cleanup;
            }

            //
            // The new volume is ready to be inserted into the list,
            // if somebody has not acted before us. Loop and go
            // through the volume list again.
            //

        } else if (LoopIdx == AddingNewVolume) {
    
            //
            // Insert the volume node before the found position.
            //
            
            InsertTailList(FoundPosition, &NewVolumeInfo->VolumeLink);
            Trace->NumVolumes++;
            InsertedNewVolume = TRUE;

            Status = STATUS_SUCCESS;
            goto cleanup;

        } else {

            //
            // We should only loop two times.
            //

            CCPF_ASSERT(FALSE);

            Status = STATUS_UNSUCCESSFUL;
            goto cleanup;   
        }
    }

    //
    // We should not come here.
    //
    
    CCPF_ASSERT(FALSE);

    Status = STATUS_UNSUCCESSFUL;

 cleanup:

    if (!NT_SUCCESS(Status)) {
        if (NewVolumeInfo) {
            ExFreePool(NewVolumeInfo);
        }
    } else {
        if (!InsertedNewVolume && NewVolumeInfo) {
            ExFreePool(NewVolumeInfo);
        }
    }

    return Status;
}

//
// Routines used for prefetching and dealing with prefetch instructions.
//

NTSTATUS
CcPfPrefetchScenario (
    PPF_SCENARIO_HEADER Scenario
    )

/*++

Routine Description:

    This routine checks for prefetch instructions for the specified
    scenario and asks Mm to prefetch those pages. 

Arguments:

    Scenario - Prefetch instructions for the scenario.

Return Value:

    Status.

Environment:

    Kernel mode, IRQL == PASSIVE_LEVEL.

--*/

{
    NTSTATUS Status;
    CCPF_PREFETCH_HEADER PrefetchHeader;

    //
    // Initialize locals & prefetch context.
    //
    
    CcPfInitializePrefetchHeader(&PrefetchHeader);

    DBGPR((CCPFID,PFPREF,"CCPF: PrefetchScenario(%p)\n", Scenario)); 

    //
    // Scenario instructions should be passed in.
    //
    
    if (!Scenario) {
        CCPF_ASSERT(Scenario);
        Status = STATUS_INVALID_PARAMETER;
        goto cleanup;
    }

    //
    // Check if prefetching is enabled.
    //
    
    if (!CCPF_IS_PREFETCHER_ENABLED()) {
        Status = STATUS_NOT_SUPPORTED;
        goto cleanup;
    }
    
    //
    // Check if prefetching is enabled for the specified scenario type.
    //

    if (CcPfGlobals.Parameters.Parameters.EnableStatus[Scenario->ScenarioType] != PfSvEnabled) {
        Status = STATUS_NOT_SUPPORTED;
        goto cleanup;
    }

    //
    // Save prefetch instructions pointer on the header.
    //

    PrefetchHeader.Scenario = Scenario;

    //
    // Try to make sure we have enough available memory to prefetch
    // what we want to prefetch.
    //

    if (!MmIsMemoryAvailable(PrefetchHeader.Scenario->NumPages)) {
        Status = STATUS_INSUFFICIENT_RESOURCES;
        DBGPR((CCPFID,PFPREF,"CCPF: PrefetchScenario-MemNotAvailable\n")); 
        goto cleanup;
    }

    //
    // Open the volumes we will prefetch on, making sure they are 
    // already mounted and the serials match etc.
    //

    Status = CcPfOpenVolumesForPrefetch(&PrefetchHeader);
    
    if (!NT_SUCCESS(Status)) {
        goto cleanup;
    }

    //
    // Prefetch the filesystem metadata we will need, so metadata I/Os
    // do not get in the way of efficient prefetch I/O. Since this is
    // not critical, ignore return value.
    //

    CcPfPrefetchMetadata(&PrefetchHeader);

    //
    // Prefetch the pages accessed through data mappings. This will
    // also bring in the header pages for image mappings.
    //

    Status = CcPfPrefetchSections(&PrefetchHeader, 
                                  CcPfPrefetchAllDataPages,  
                                  NULL,
                                  0,
                                  NULL,
                                  NULL);

    if (!NT_SUCCESS(Status)) {
        goto cleanup;
    }

    //
    // Prefetch the pages accessed through image mappings.
    //

    Status = CcPfPrefetchSections(&PrefetchHeader, 
                                  CcPfPrefetchAllImagePages,
                                  NULL,
                                  0,
                                  NULL,
                                  NULL);

    if (!NT_SUCCESS(Status)) {
        goto cleanup;
    }

    Status = STATUS_SUCCESS;

 cleanup:

    CcPfCleanupPrefetchHeader(&PrefetchHeader);

    DBGPR((CCPFID,PFPREF,"CCPF: PrefetchScenario(%ws)=%x\n", Scenario->ScenarioId.ScenName, Status)); 

    return Status;
}

NTSTATUS
CcPfPrefetchSections(
    IN PCCPF_PREFETCH_HEADER PrefetchHeader,
    IN CCPF_PREFETCH_TYPE PrefetchType,
    OPTIONAL IN PCCPF_PREFETCH_CURSOR StartCursor,
    OPTIONAL ULONG TotalPagesToPrefetch,
    OPTIONAL OUT PULONG NumPagesPrefetched,
    OPTIONAL OUT PCCPF_PREFETCH_CURSOR EndCursor
    )

/*++

Routine Description:

    This routine prepares read lists for the specified pages in the
    scenario and calls Mm to prefetch them. This function is usually
    called first to prefetch data pages then image pages. When
    prefetching data pages, header pages for any image mappings are
    also prefetched, which would otherwise hurt efficiency when
    prefetching image pages.   

Arguments:

    PrefetchHeader - Pointer to the prefetch header.

    PrefetchType - What/How to prefetch.

    StartCursor - If prefetching only part of the scenario, where to
      start prefetching from.

    TotalPagesToPrefetch - If prefetching only part of the scenario, how
      many pages to prefetch. This function may prefetch more or less pages
      as it sees fit.

    NumPagesPrefetched - If prefetching only part of the scenario,
      this is the number of pages we asked Mm to prefetch.

    EndCursor - If prefetching only part of the scenario, this is
      updated to the position NumPages pages after the StartCursor.

Return Value:

    Status.

Environment:

    Kernel mode. IRQL == PASSIVE_LEVEL.

--*/

{
    PWCHAR FilePath;
    PCCPF_PREFETCH_VOLUME_INFO VolumeNode;
    PREAD_LIST *ReadLists;
    PREAD_LIST ReadList;
    HANDLE *FileHandleTable;
    HANDLE FileHandle;
    PFILE_OBJECT *FileObjectTable;
    PFILE_OBJECT FileObject;
    PSECTION *SectionObjectTable;
    PSECTION SectionObject;
    PPF_SECTION_RECORD SectionRecord;
    PPF_SECTION_RECORD SectionRecords;
    PCHAR FileNameData;
    UNICODE_STRING SectionName;
    PPF_PAGE_RECORD PageRecord;
    PPF_PAGE_RECORD PageRecords;
    ULONG SectionIdx;
    ULONG ReadListIdx;
    LONG PageIdx;
    LONG PreviousPageIdx;
    ULONG NumReadLists;
    ULONG AllocationSize;
    NTSTATUS Status;
    LOGICAL PrefetchingImagePages;
    BOOLEAN AddedHeaderPage;
    BOOLEAN PrefetchingPartOfScenario;
    ULONGLONG LastOffset;
    ULONG NumberOfSections;
    ULONG NumPagesToPrefetch;
    ULONG NumSectionPages;
    PUCHAR Tables;
    PUCHAR CurrentPosition;
    PPF_SCENARIO_HEADER Scenario;
    ULONG StartSectionNumber;
    ULONG StartPageNumber;

    //
    // Initialize locals so we know what to cleanup.
    //

    Scenario = PrefetchHeader->Scenario;
    Tables = NULL;
    ReadList = NULL;
    ReadLists = NULL;
    FileHandle = NULL;
    FileHandleTable = NULL;
    FileObject = NULL;
    FileObjectTable = NULL;
    SectionObject = NULL;
    SectionObjectTable = NULL;
    NumReadLists = 0;
    NumberOfSections = Scenario->NumSections;
    NumPagesToPrefetch = 0;
    NumSectionPages = 0;
    PageIdx = 0;

    DBGPR((CCPFID,PFPREF,"CCPF: PrefetchSections(%p,%d,%d,%d)\n", 
           PrefetchHeader, PrefetchType,
           (StartCursor)?StartCursor->SectionIdx:0,
           (StartCursor)?StartCursor->PageIdx:0)); 

    //
    // Validate parameters.
    //

    if (PrefetchType >= CcPfMaxPrefetchType) {
        Status = STATUS_INVALID_PARAMETER;
        goto cleanup;
    }

    //
    // Determine whether we are prefetching data or image pages and
    // other parameters based on prefetch type.
    //

    switch (PrefetchType) {

    case CcPfPrefetchAllDataPages:
        StartSectionNumber = 0;
        StartPageNumber = 0;
        PrefetchingImagePages = FALSE;
        PrefetchingPartOfScenario = FALSE;
        break;

    case CcPfPrefetchAllImagePages:
        StartSectionNumber = 0;
        StartPageNumber = 0;
        PrefetchingImagePages = TRUE;
        PrefetchingPartOfScenario = FALSE;
        break;

    case CcPfPrefetchPartOfDataPages:

        if (!StartCursor) {
            CCPF_ASSERT(StartCursor);
            Status = STATUS_INVALID_PARAMETER;
            goto cleanup;
        }

        StartSectionNumber = StartCursor->SectionIdx;
        StartPageNumber = StartCursor->PageIdx;
        PrefetchingImagePages = FALSE;
        PrefetchingPartOfScenario = TRUE;
        break;

    case CcPfPrefetchPartOfImagePages:

        if (!StartCursor) {
            CCPF_ASSERT(StartCursor);
            Status = STATUS_INVALID_PARAMETER;
            goto cleanup;
        }

        StartSectionNumber = StartCursor->SectionIdx;
        StartPageNumber = StartCursor->PageIdx;
        PrefetchingImagePages = TRUE;
        PrefetchingPartOfScenario = TRUE;
        break;

    default:
        
        //
        // We should be handling all types above.
        //
        
        CCPF_ASSERT(FALSE);

        Status = STATUS_INVALID_PARAMETER;
        goto cleanup;
    }

    //
    // Allocate and initialize intermediate tables. We will make a
    // single allocation for all the tables.
    //

    AllocationSize = sizeof(PREAD_LIST) * NumberOfSections;
    AllocationSize += sizeof(HANDLE) * NumberOfSections;
    AllocationSize += sizeof(PFILE_OBJECT) * NumberOfSections;
    AllocationSize += sizeof(PSECTION) * NumberOfSections;

    Tables = ExAllocatePoolWithTag(PagedPool,
                                   AllocationSize,
                                   CCPF_ALLOC_INTRTABL_TAG);

    if (!Tables) {
        Status = STATUS_INSUFFICIENT_RESOURCES;
        goto cleanup;
    }

    //
    // Zero out the whole buffer. This initializes all elements of the
    // tables to NULL.
    //

    RtlZeroMemory(Tables, AllocationSize);
    
    //
    // Determine where each table goes in the buffer.
    //

    CurrentPosition = Tables;

    ReadLists = (PREAD_LIST *) CurrentPosition;
    CurrentPosition += sizeof(PREAD_LIST) * NumberOfSections;
    FileHandleTable = (HANDLE *) CurrentPosition;
    CurrentPosition += sizeof(HANDLE) * NumberOfSections;
    FileObjectTable = (PFILE_OBJECT *) CurrentPosition;
    CurrentPosition += sizeof(PFILE_OBJECT) * NumberOfSections;
    SectionObjectTable = (PSECTION *) CurrentPosition;
    CurrentPosition += sizeof(PSECTION) * NumberOfSections;

    //
    // We should have allocated the right size buffer.
    //

    CCPF_ASSERT(CurrentPosition == Tables + AllocationSize);

    //
    // Go through the sections and prepare read lists. We may not have
    // a read list for every section in the scenario so keep another
    // counter, NumReadLists, to keep our read list array compact.
    //

    SectionRecords = (PPF_SECTION_RECORD) 
        ((PCHAR) Scenario + Scenario->SectionInfoOffset);

    PageRecords = (PPF_PAGE_RECORD) 
        ((PCHAR) Scenario + Scenario->PageInfoOffset);

    FileNameData = (PCHAR) Scenario + Scenario->FileNameInfoOffset;
    
    for (SectionIdx = StartSectionNumber; 
         SectionIdx < NumberOfSections; 
         SectionIdx ++) {

        SectionRecord = &SectionRecords[SectionIdx];

        //
        // Skip this section if it was marked ignore for some reason.
        //

        if (SectionRecord->IsIgnore) {
            continue;
        }

        //
        // If this section is on a bad volume (e.g. one that was not
        // mounted or whose serial / creation time did not match the
        // volume we had traced), we cannot prefetch this section.
        //

        FilePath = (WCHAR *) (FileNameData + SectionRecord->FileNameOffset);
        
        VolumeNode = CcPfFindPrefetchVolumeInfoInList(FilePath,
                                                      &PrefetchHeader->BadVolumeList);

        if (VolumeNode) {
            continue;
        }

        //
        // The section info should either be for an image or data
        // mapping or both.
        //

        CCPF_ASSERT(SectionRecord->IsImage || SectionRecord->IsData);

        //
        // If we are mapping images and this section does not have an
        // image mapping skip it. Note that the reverse is not
        // true. We prefetch headers for isimage section when
        // prefedata pages so we don't check for that.
        //

        if (PrefetchingImagePages && !SectionRecord->IsImage) {
            continue;
        }

        //
        // Allocate a read list. Note that READ_LIST has storage for a
        // FILE_SEGMENT_ELEMENT. We allocate space for one extra page
        // in case we have to also bring in a header page for image
        // mapping.
        //

        AllocationSize = sizeof(READ_LIST) + 
            (SectionRecord->NumPages * sizeof(FILE_SEGMENT_ELEMENT));

        ReadList = ExAllocatePoolWithTag(NonPagedPool,
                                         AllocationSize,
                                         CCPF_ALLOC_READLIST_TAG);

        if (ReadList == NULL) {
            Status = STATUS_INSUFFICIENT_RESOURCES;
            goto cleanup;
        }
        
        //
        // Initialize header fields of the read list.
        //

        ReadList->FileObject = 0;
        ReadList->IsImage = PrefetchingImagePages;
        ReadList->NumberOfEntries = 0;
        
        //
        // If we are prefetching data pages and this section was
        // mapped as an image, add the header page to the readlist.
        // This way when creating the image mapping to prefetch image
        // pages we don't have to read it from the disk inefficiently.
        //

        AddedHeaderPage = FALSE;

        if((PrefetchingImagePages == FALSE) && SectionRecord->IsImage) {

            //
            // Don't add the header page if we are prefetching only
            // part of the section and we are past the first page.
            //

            if (!PrefetchingPartOfScenario ||
                (StartSectionNumber != SectionIdx) ||
                StartPageNumber > 0) {

                //
                // Header page starts at offset 0.
                //
                
                ReadList->List[ReadList->NumberOfEntries].Alignment = 0;
                
                ReadList->NumberOfEntries++;
                
                NumPagesToPrefetch++;
                
                //
                // Note that if we are prefetching only part of the
                // scenario, we do not check to see if we've
                // prefetched enough pages here. This is to avoid
                // having to prefetch the header page twice in case it
                // maxes the number of pages to prefetch and
                // PrefetchSections is called again.
                //

                AddedHeaderPage = TRUE;
            }
        }

        //
        // Go through all the pages in the section and put offsets for
        // pages to prefetch into the readlist.
        //

        PageIdx = SectionRecord->FirstPageIdx;
        NumSectionPages = 0;
        PreviousPageIdx = PF_INVALID_PAGE_IDX;

        while (PageIdx != PF_INVALID_PAGE_IDX) {

            PageRecord = &PageRecords[PageIdx];

            //
            // Update the number of pages we've seen on the list so
            // far. If it is greater than what there should be on the
            // list we have a problem. We may have even hit a loop. We
            // should have caught this when we verified the scenario.
            //

            NumSectionPages++;
            if (NumSectionPages > SectionRecord->NumPages) {
                DBGPR((CCPFID,PFWARN,"CCPF: PrefetchSections-Corrupt0\n"));
                Status = STATUS_INVALID_PARAMETER;
                CCPF_ASSERT(FALSE);
                goto cleanup;
            }

            //
            // Get the index for the next page in the list.
            //
            
            PageIdx = PageRecord->NextPageIdx;

            //
            // If we are prefetching parts of the scenario and this is
            // the first section, skip the pages up to the start
            // cursor. Note that NumSectionPages has already been
            // incremented above.
            //

            if (PrefetchingPartOfScenario &&
                StartSectionNumber == SectionIdx &&
                NumSectionPages <= StartPageNumber) {
                continue;
            }

            //
            // Skip pages we have marked "ignore" for some reason.
            //

            if (PageRecord->IsIgnore) {
                continue;
            }

            //
            // Except for the header page, we should not have put
            // more entries into the read list then the number of
            // pages for the section in the scenario file.
            //
            
            if (ReadList->NumberOfEntries > SectionRecord->NumPages + 1) {
                DBGPR((CCPFID,PFWARN,"CCPF: PrefetchSections-Corrupt1\n"));
                Status = STATUS_INVALID_PARAMETER;
                CCPF_ASSERT(FALSE);
                goto cleanup;
            }
            
            //
            // Add this page to the list only if it's type (image
            // or data) matches the type of pages we are prefetching.
            //
            
            if (((PrefetchingImagePages == FALSE) && !PageRecord->IsData) ||
                ((PrefetchingImagePages == TRUE) && !PageRecord->IsImage)) {
                continue;
            }

            //
            // If we already added the header page to the list,
            // don't add another entry for the same offset.
            //
            
            if (AddedHeaderPage && (PageRecord->FileOffset == 0)) {
                continue;
            }

            //
            // Check to see if this page comes after the last page
            // we put in the read list. Perform this check as the
            // very last check before adding the page to the
            // readlist.
            //

            if (ReadList->NumberOfEntries) {
                
                LastOffset = ReadList->List[ReadList->NumberOfEntries - 1].Alignment;
                    
                if (PageRecord->FileOffset <= (ULONG) LastOffset) {
                    DBGPR((CCPFID,PFWARN,"CCPF: PrefetchSections-Corrupt2\n"));
                    Status = STATUS_INVALID_PARAMETER;
                    CCPF_ASSERT(FALSE);
                    goto cleanup;
                }
            }
      
            //
            // Add this page to the readlist for this section.
            //
            
            ReadList->List[ReadList->NumberOfEntries].Alignment = PageRecord->FileOffset;
            ReadList->NumberOfEntries++;
            
            //
            // Update number of pages we are asking mm to bring for us.
            //
            
            NumPagesToPrefetch++;

            //
            // Break out if we are prefetching requested number of
            // pages.
            //

            if (PrefetchingPartOfScenario && 
                NumPagesToPrefetch >= TotalPagesToPrefetch) {
                break;
            }
        }

        if (ReadList->NumberOfEntries) {

            //
            // Get the section object.
            //
            
            RtlInitUnicodeString(&SectionName, FilePath);
            
            Status = CcPfGetSectionObject(&SectionName,
                                          PrefetchingImagePages,
                                          &SectionObject,
                                          &FileObject,
                                          &FileHandle);
            
            if (!NT_SUCCESS(Status)) {
                
                if (Status == STATUS_SHARING_VIOLATION) {
                    
                    //
                    // We cannot open registry files due to sharing
                    // violation. Pass the file name and readlist to
                    // registry in case this is a registry file.
                    //

                    CmPrefetchHivePages(&SectionName, ReadList);
                }

                //
                // Free the built read list.
                //

                ExFreePool(ReadList);
                ReadList = NULL;

                continue;
            }

            //
            // We should have got a file object and a section object
            // pointer if we created the section successfully.
            //
            
            CCPF_ASSERT(FileObject != NULL && SectionObject != NULL);
            
            ReadList->FileObject = FileObject;

            //
            // Put data into the tables, so we know what to cleanup.
            //
            
            ReadLists[NumReadLists] = ReadList;
            FileHandleTable[NumReadLists] = FileHandle;
            FileObjectTable[NumReadLists] = FileObject;  
            SectionObjectTable[NumReadLists] = SectionObject;
            
            NumReadLists++;

        } else {
            
            //
            // We won't be prefetching anything for this section.
            //
            
            ExFreePool(ReadList);
        }

        //
        // Reset these so we know what to cleanup.
        //

        ReadList = NULL;
        FileHandle = NULL;
        FileObject = NULL;
        SectionObject = NULL;

        //
        // Break out if we are prefetching requested number of
        // pages.
        //
        
        if (PrefetchingPartOfScenario && 
            NumPagesToPrefetch == TotalPagesToPrefetch) {
            break;
        }
    }

    //
    // If prefetching only part of the the scenario, update return
    // values.
    //

    if (PrefetchingPartOfScenario) {

        if (NumPagesPrefetched) {
            *NumPagesPrefetched = NumPagesToPrefetch;
        }

        if (EndCursor) {

            //
            // If we did the last page of the current section, then
            // start from the next section. Otherwise start from the
            // next page in this section.
            //

            if (PageIdx == PF_INVALID_PAGE_IDX) {
                EndCursor->SectionIdx = SectionIdx + 1;  
                EndCursor->PageIdx = 0;
            } else {
                EndCursor->SectionIdx = SectionIdx;  
                EndCursor->PageIdx = NumSectionPages;
            }
            
            //
            // Make sure the end position is equal to or greater than
            // start position.
            //
            
            if (EndCursor->SectionIdx < StartSectionNumber) {
                EndCursor->SectionIdx = StartSectionNumber;
            }
            
            if (EndCursor->SectionIdx == StartSectionNumber) {
                if (EndCursor->PageIdx < StartPageNumber) {
                    EndCursor->PageIdx = StartPageNumber;
                }
            }
        }
    }

    //
    // Ask Mm to process the readlists only if we actually have pages
    // to ask for.
    //

    if (NumReadLists) {

        if (NumPagesToPrefetch) {

            DBGPR((CCPFID,PFPRFD,"CCPF: Prefetching %d sections %d pages\n", 
                   NumReadLists, NumPagesToPrefetch)); 

            Status = MmPrefetchPages(NumReadLists, ReadLists);

        } else {
            Status = STATUS_UNSUCCESSFUL;
            
            //
            // We cannot have any read lists if we don't have any
            // pages to prefetch.
            //
        }

    } else {

        Status = STATUS_SUCCESS;

    }

cleanup:

    if (Tables) {

        for (ReadListIdx = 0; ReadListIdx < NumReadLists; ReadListIdx++) {
            
            if (ReadLists[ReadListIdx]) {
                ExFreePool(ReadLists[ReadListIdx]);
            }
            
            if (FileHandleTable[ReadListIdx]) {
                ZwClose(FileHandleTable[ReadListIdx]);
            }
            
            if (FileObjectTable[ReadListIdx]) {
                ObDereferenceObject(FileObjectTable[ReadListIdx]);
            }
            
            if (SectionObjectTable[ReadListIdx]) {
                ObDereferenceObject(SectionObjectTable[ReadListIdx]);
            }
        }

        ExFreePool(Tables);
    }

    if (ReadList) {
        ExFreePool(ReadList);
    }
    
    if (FileHandle) {
        ZwClose(FileHandle);
    }
    
    if (FileObject) {
        ObDereferenceObject(FileObject);
    }
    
    if (SectionObject) {
        ObDereferenceObject(SectionObject);
    }

    DBGPR((CCPFID,PFPREF,"CCPF: PrefetchSections(%p)=%x,%d,%d\n", 
           PrefetchHeader, Status, NumReadLists, NumPagesToPrefetch)); 

    return Status;
}

NTSTATUS
CcPfPrefetchMetadata(
    IN PCCPF_PREFETCH_HEADER PrefetchHeader
    )

/*++

Routine Description:

    This routine tries to prefetch the filesystem metadata that will
    be needed to prefetch pages for the scenario, so metadata I/Os do
    not get in the way of efficient page prefetch I/O.

    This function should be called only after the prefetch header has
    been initialized and the routine to open the volumes for prefetch
    has been called.

Arguments:

    PrefetchHeader - Pointer to prefetch header.

Return Value:

    Status.

Environment:

    Kernel mode, IRQL == PASSIVE_LEVEL.

--*/

{
    PCHAR MetadataInfoBase;
    PPF_METADATA_RECORD MetadataRecordTable;
    PPF_METADATA_RECORD MetadataRecord;
    PWCHAR VolumePath;
    PFILE_PREFETCH FilePrefetchInfo;
    PPF_SCENARIO_HEADER Scenario;
    PPF_COUNTED_STRING DirectoryPath;
    PCCPF_PREFETCH_VOLUME_INFO VolumeNode;
    ULONG MetadataRecordIdx;
    ULONG DirectoryIdx;
    NTSTATUS Status;

    //
    // Initialize locals.
    //

    Scenario = PrefetchHeader->Scenario;

    if (Scenario == NULL) {
        CCPF_ASSERT(Scenario);
        Status = STATUS_INVALID_PARAMETER;
        goto cleanup;
    }
    
    DBGPR((CCPFID,PFPREF,"CCPF: PrefetchMetadata(%p)\n",PrefetchHeader)); 

    //
    // Get pointer to metadata prefetch information.
    //

    MetadataInfoBase = (PCHAR)Scenario + Scenario->MetadataInfoOffset;
    MetadataRecordTable = (PPF_METADATA_RECORD) MetadataInfoBase;

    //
    // Go through and prefetch requested metadata from volumes.
    //

    for (MetadataRecordIdx = 0;
         MetadataRecordIdx < Scenario->NumMetadataRecords;
         MetadataRecordIdx++) {

        MetadataRecord = &MetadataRecordTable[MetadataRecordIdx];

        VolumePath = (PWCHAR)
            (MetadataInfoBase + MetadataRecord->VolumeNameOffset);  

        //
        // Find the volume node for this volume containing opened handle.
        //

        VolumeNode = CcPfFindPrefetchVolumeInfoInList(VolumePath,
                                                      &PrefetchHeader->OpenedVolumeList);

        if (!VolumeNode) {

            //
            // If it is not in the opened volume list, it should be in the
            // bad volume list (because it was not mounted, or its serial 
            // did not match etc.)
            //

            CCPF_ASSERT(CcPfFindPrefetchVolumeInfoInList(VolumePath, &PrefetchHeader->BadVolumeList));

            //
            // We cannot prefetch metadata on this volume.
            //

            continue;

        } else {

            //
            // We should have already opened a handle to this volume.
            //

            CCPF_ASSERT(VolumeNode->VolumeHandle);
        }

        //
        // Prefetch MFT entries and such for the files and directories
        // we will access.
        //
        
        FilePrefetchInfo = (PFILE_PREFETCH) 
            (MetadataInfoBase + MetadataRecord->FilePrefetchInfoOffset);       

        Status = CcPfPrefetchFileMetadata(VolumeNode->VolumeHandle, FilePrefetchInfo);

        //
        // Walk through the contents of the directories sequentially
        // so we don't jump around when opening the files. The
        // directory list is sorted, so we will prefetch the parent
        // directories before children.
        //

        DirectoryPath = (PPF_COUNTED_STRING)
            (MetadataInfoBase + MetadataRecord->DirectoryPathsOffset);
        
        for (DirectoryIdx = 0;
             DirectoryIdx < MetadataRecord->NumDirectories;
             DirectoryIdx++) {

            Status = CcPfPrefetchDirectoryContents(DirectoryPath->String,
                                                   DirectoryPath->Length);

            if (Status == STATUS_UNRECOGNIZED_VOLUME ||
                Status == STATUS_INVALID_PARAMETER) {

                //
                // This volume may not have been mounted or got dismounted.
                //

                break;
            }
            
            //
            // Get next directory.
            //

            DirectoryPath = (PPF_COUNTED_STRING) 
                (&DirectoryPath->String[DirectoryPath->Length + 1]);
        }
    }

    Status = STATUS_SUCCESS;

 cleanup:

    DBGPR((CCPFID,PFPREF,"CCPF: PrefetchMetadata(%p)=%x\n",PrefetchHeader,Status)); 

    return Status;
}

NTSTATUS
CcPfPrefetchFileMetadata(
    HANDLE VolumeHandle,
    PFILE_PREFETCH FilePrefetch
    )

/*++

Routine Description:

    This routine issues the specified metadata prefetch request to the
    file system.

Arguments:

    VolumeHandle - Volume this request should be issued to.

    FilePrefetch - POinter to prefetch request.

Return Value:

    Status.

Environment:

    Kernel mode, IRQL == PASSIVE_LEVEL.

--*/

{
    PFILE_PREFETCH SplitFilePrefetch;
    IO_STATUS_BLOCK IoStatusBlock;
    ULONG FilePrefetchSize;
    ULONG CurrentFileMetadataIdx;
    ULONG NumFileMetadataToPrefetch;
    ULONG RemainingFileMetadata;
    ULONG CopySize;
    NTSTATUS Status;
    
    //
    // Initialize locals.
    //

    SplitFilePrefetch = NULL;
    Status = STATUS_SUCCESS;

    DBGPR((CCPFID,PFPRFD,"CCPF: PrefetchFileMetadata(%p)\n", FilePrefetch)); 
    
    //
    // If the number of file prefetch entries are small, simply pass the
    // buffer in the scenario instructions to the file system.
    //

    if (FilePrefetch->Count < CCPF_MAX_FILE_METADATA_PREFETCH_COUNT) {

        FilePrefetchSize = sizeof(FILE_PREFETCH);
        if (FilePrefetch->Count) {
            FilePrefetchSize += (FilePrefetch->Count - 1) * sizeof(ULONGLONG);
        }
        
        Status = ZwFsControlFile(VolumeHandle,
                                 NULL,
                                 NULL,
                                 NULL,
                                 &IoStatusBlock,
                                 FSCTL_FILE_PREFETCH,
                                 FilePrefetch,
                                 FilePrefetchSize,
                                 NULL,
                                 0);

    } else {

        //
        // We need to allocate an intermediary buffer and split up the 
        // requests.
        //

        FilePrefetchSize = sizeof(FILE_PREFETCH);
        FilePrefetchSize += (CCPF_MAX_FILE_METADATA_PREFETCH_COUNT - 1) * sizeof(ULONGLONG);

        SplitFilePrefetch = ExAllocatePoolWithTag(PagedPool,
                                                  FilePrefetchSize,
                                                  CCPF_ALLOC_METADATA_TAG);
        
        if (!SplitFilePrefetch) {
            Status = STATUS_INSUFFICIENT_RESOURCES;
            goto cleanup;
        }

        //
        // Copy header.
        //

        *SplitFilePrefetch = *FilePrefetch;

        for (CurrentFileMetadataIdx = 0;
             CurrentFileMetadataIdx < FilePrefetch->Count;
             CurrentFileMetadataIdx += NumFileMetadataToPrefetch) {

            //
            // Calculate how many more file metadata entries we have to prefetch.
            // Adjust it so we don't go beyond FilePrefetch->Count.
            //

            NumFileMetadataToPrefetch = CCPF_MAX_FILE_METADATA_PREFETCH_COUNT;

            RemainingFileMetadata = FilePrefetch->Count - CurrentFileMetadataIdx;

            if (NumFileMetadataToPrefetch > RemainingFileMetadata) {
                NumFileMetadataToPrefetch = RemainingFileMetadata;
            }

            //
            // Update the count on header.
            //

            SplitFilePrefetch->Count = NumFileMetadataToPrefetch;

            //
            // Copy over the file metadata indices.
            //

            CopySize = NumFileMetadataToPrefetch * sizeof(ULONGLONG);

            RtlCopyMemory(SplitFilePrefetch->Prefetch, 
                          &FilePrefetch->Prefetch[CurrentFileMetadataIdx],
                          CopySize);

            //
            // Calculate the request size.
            //

            CCPF_ASSERT(SplitFilePrefetch->Count);
            CCPF_ASSERT(SplitFilePrefetch->Count <= CCPF_MAX_FILE_METADATA_PREFETCH_COUNT);

            FilePrefetchSize = sizeof(FILE_PREFETCH);
            FilePrefetchSize +=  (SplitFilePrefetch->Count - 1) * sizeof(ULONGLONG);

            //
            // Issue the request.
            //

            Status = ZwFsControlFile(VolumeHandle,
                                     NULL,
                                     NULL,
                                     NULL,
                                     &IoStatusBlock,
                                     FSCTL_FILE_PREFETCH,
                                     SplitFilePrefetch,
                                     FilePrefetchSize,
                                     NULL,
                                     0);

            if (NT_ERROR(Status)) {
                goto cleanup;
            }
        }
    }
    
    //
    // Fall through with status.
    //

 cleanup:

    if (SplitFilePrefetch) {
        ExFreePool(SplitFilePrefetch);
    }

    DBGPR((CCPFID,PFPRFD,"CCPF: PrefetchFileMetadata()=%x\n", Status)); 

    return Status;
}

NTSTATUS
CcPfPrefetchDirectoryContents(
    WCHAR *DirectoryPath,
    WCHAR DirectoryPathlength
    )

/*++

Routine Description:

    This routine attempts to prefetch the contents of a directory.

Arguments:

    DirectoryPath - NUL terminated path.
    
    DirectoryPathLength - Number of characters exclusing terminating NUL.

Return Value:

    Status.

Environment:

    Kernel mode, IRQL == PASSIVE_LEVEL.

--*/

{
    NTSTATUS Status;
    HANDLE DirectoryHandle;
    UNICODE_STRING DirectoryPathU;
    OBJECT_ATTRIBUTES ObjectAttributes;
    IO_STATUS_BLOCK IoStatusBlock;
    BOOLEAN OpenedDirectory;
    PVOID QueryBuffer;
    ULONG QueryBufferSize;
    ULONG QueryIdx;
    BOOLEAN RestartScan;

    UNREFERENCED_PARAMETER (DirectoryPathlength);

    //
    // Initialize locals.
    //

    OpenedDirectory = FALSE;
    QueryBuffer = NULL;

    DBGPR((CCPFID,PFPRFD,"CCPF: PrefetchDirectory(%ws)\n",DirectoryPath)); 

    //
    // Open the directory.
    //

    RtlInitUnicodeString(&DirectoryPathU, DirectoryPath);
    
    InitializeObjectAttributes(&ObjectAttributes,
                               &DirectoryPathU,
                               OBJ_CASE_INSENSITIVE | OBJ_KERNEL_HANDLE,
                               NULL,
                               NULL);
    
    Status = ZwCreateFile(&DirectoryHandle,
                          FILE_LIST_DIRECTORY | SYNCHRONIZE,
                          &ObjectAttributes,
                          &IoStatusBlock,
                          0,
                          0,
                          FILE_SHARE_READ |
                            FILE_SHARE_WRITE |
                            FILE_SHARE_DELETE,
                          FILE_OPEN,
                          FILE_DIRECTORY_FILE | 
                            FILE_SYNCHRONOUS_IO_NONALERT | 
                            FILE_OPEN_FOR_BACKUP_INTENT,
                          NULL,
                          0);

    if (!NT_SUCCESS(Status)) {
        goto cleanup;
    }

    OpenedDirectory = TRUE;

    //
    // Allocate a big query buffer so we have to make only a small
    // number of calls to cause the file system to walk through the
    // contents of the directory.
    //

    QueryBufferSize = 4 * PAGE_SIZE;
    QueryBuffer = ExAllocatePoolWithTag(PagedPool | POOL_COLD_ALLOCATION,
                                        QueryBufferSize,
                                        CCPF_ALLOC_QUERY_TAG);

    if (!QueryBuffer) {
        Status = STATUS_INSUFFICIENT_RESOURCES;
        goto cleanup;
    }

    //
    // Query names of files in the directory hopefully causing the
    // file system to touch the directory contents sequentially. If
    // the directory is really big, we don't want to attempt to bring
    // it all in, so we limit the number of times we query. 
    //
    // Assuming filenames are 16 characters long on average, we can
    // fit 32 filenames in 1KB, 128 on an x86 page. A 4 page query
    // buffer holds 512 file names. If we do it 10 times, we end up
    // prefetching data for about 5000 files.
    //
    
    RestartScan = TRUE;

    for (QueryIdx = 0; QueryIdx < 10; QueryIdx++) {
        
        Status = ZwQueryDirectoryFile(DirectoryHandle,
                                      NULL,
                                      NULL,
                                      NULL,
                                      &IoStatusBlock,
                                      QueryBuffer,
                                      QueryBufferSize,
                                      FileNamesInformation,
                                      FALSE,
                                      NULL,
                                      RestartScan);
        
        RestartScan = FALSE;

        if (!NT_SUCCESS(Status)) {
            
            //
            // If the status is that we got all the files, we are done.
            //

            if (Status == STATUS_NO_MORE_FILES) {
                break;
            }

            goto cleanup;
        }
    }

    Status = STATUS_SUCCESS;

 cleanup:

    if (QueryBuffer) {
        ExFreePool(QueryBuffer);
    }
    
    if (OpenedDirectory) {
        ZwClose(DirectoryHandle);
    }

    DBGPR((CCPFID,PFPRFD,"CCPF: PrefetchDirectory(%ws)=%x\n",DirectoryPath, Status)); 

    return Status;
}

VOID
CcPfInitializePrefetchHeader (
    OUT PCCPF_PREFETCH_HEADER PrefetchHeader
)

/*++

Routine Description:

    This routine initalizes the prefetch header fields.

Arguments:

    PrefetchHeader - Pointer to prefetch header.

Return Value:

    None.

Environment:

    Kernel mode, IRQL == PASSIVE_LEVEL.

--*/

{

    //
    // Zero out the structure. This initializes the following:
    //
    // Scenario
    // VolumeNodes
    //

    RtlZeroMemory(PrefetchHeader, sizeof(CCPF_PREFETCH_HEADER));

    //
    // Initialize the volume lists.
    //

    InitializeListHead(&PrefetchHeader->BadVolumeList);
    InitializeListHead(&PrefetchHeader->OpenedVolumeList);
    
}

VOID
CcPfCleanupPrefetchHeader (
    IN PCCPF_PREFETCH_HEADER PrefetchHeader
    )

/*++

Routine Description:

    This routine cleans up allocations / references in the
    PrefetchHeader. It does not free the structure itself. 

Arguments:

    PrefetchHeader - Prefetch header to cleanup.

Return Value:

    None.

Environment:

    Kernel mode, IRQL == PASSIVE_LEVEL.

--*/

{
    PCCPF_PREFETCH_VOLUME_INFO VolumeNode;
    PLIST_ENTRY RemovedEntry;
    
    DBGPR((CCPFID,PFTRC,"CCPF: CleanupPrefetchHeader(%p)\n", PrefetchHeader));

    //
    // Walk the opened volumes list and close the handles.
    //

    while (!IsListEmpty(&PrefetchHeader->OpenedVolumeList)) {

        RemovedEntry = RemoveHeadList(&PrefetchHeader->OpenedVolumeList);

        VolumeNode = CONTAINING_RECORD(RemovedEntry,
                                       CCPF_PREFETCH_VOLUME_INFO,
                                       VolumeLink);

        CCPF_ASSERT(VolumeNode->VolumeHandle);

        ZwClose(VolumeNode->VolumeHandle);
    }
    
    //
    // Free allocated volume nodes.
    //

    if (PrefetchHeader->VolumeNodes) {
        ExFreePool(PrefetchHeader->VolumeNodes);
    }

}

NTSTATUS
CcPfGetPrefetchInstructions(
    IN PPF_SCENARIO_ID ScenarioId,
    IN PF_SCENARIO_TYPE ScenarioType,
    OUT PPF_SCENARIO_HEADER *ScenarioHeader
    )

/*++

Routine Description:

    This routine checks for prefetch instructions for the specified
    scenario, verifies them and returns them in an allocated buffer
    from paged pool the caller should free.

Arguments:

    ScenarioId - Scenario identifier.

    ScenarioType - Scenario type.

    Scenario - Where pointer to allocated buffer should be put.

Return Value:

    Status.

Environment:

    Kernel mode, IRQL == PASSIVE_LEVEL.

--*/

{
    NTSTATUS Status;  
    PWSTR SystemRootPath = L"\\SystemRoot";
    PWSTR FilePath;
    UNICODE_STRING ScenarioFilePath;
    ULONG FilePathSize;
    HANDLE ScenarioFile;
    PPF_SCENARIO_HEADER Scenario;
    ULONG ScenarioSize;
    OBJECT_ATTRIBUTES ObjectAttributes;
    IO_STATUS_BLOCK IoStatus;
    FILE_STANDARD_INFORMATION StandardInfo;
    ULONG FailedCheck;
    BOOLEAN OpenedScenarioFile;
    PKTHREAD CurrentThread;

    //
    // Initialize locals.
    //

    FilePath = NULL;
    Scenario = NULL;
    OpenedScenarioFile = FALSE;

    DBGPR((CCPFID,PFPREF,"CCPF: GetInstructions(%ws)\n", ScenarioId->ScenName)); 

    //
    // Hold the parameters lock while building path to instructions so
    // RootDirPath does not change beneath our feet.
    //

    CurrentThread = KeGetCurrentThread ();
    KeEnterCriticalRegionThread(CurrentThread);
    ExAcquireResourceSharedLite(&CcPfGlobals.Parameters.ParametersLock, TRUE);

    //
    // Build file path for prefetch instructions for this scenario
    // id. +1 to wcslen(SystemRootPath) is for the "\" after it. The last
    // sizeof(WCHAR) is added for the terminating NUL.
    //

    FilePathSize = (wcslen(SystemRootPath) + 1) * sizeof(WCHAR);
    FilePathSize += wcslen(CcPfGlobals.Parameters.Parameters.RootDirPath) * sizeof(WCHAR);
    FilePathSize += PF_MAX_SCENARIO_FILE_NAME * sizeof(WCHAR);
    FilePathSize += sizeof(WCHAR);
    
    FilePath = ExAllocatePoolWithTag(PagedPool | POOL_COLD_ALLOCATION,
                                     FilePathSize,
                                     CCPF_ALLOC_FILENAME_TAG);

    if (!FilePath) {
        ExReleaseResourceLite(&CcPfGlobals.Parameters.ParametersLock);
        KeLeaveCriticalRegionThread(CurrentThread);
        Status = STATUS_INSUFFICIENT_RESOURCES;
        goto cleanup;
    }

    swprintf(FilePath,
             L"%s\\%s\\" PF_SCEN_FILE_NAME_FORMAT, 
             SystemRootPath,
             CcPfGlobals.Parameters.Parameters.RootDirPath,
             ScenarioId->ScenName,
             ScenarioId->HashId,
             PF_PREFETCH_FILE_EXTENSION);

    //
    // Release the parameters lock.
    //

    ExReleaseResourceLite(&CcPfGlobals.Parameters.ParametersLock);
    KeLeaveCriticalRegionThread(CurrentThread);

    //
    // Open the scenario file. We open the file exlusive so we do not
    // end up with half a file when the service is updating it etc.
    //

    DBGPR((CCPFID,PFPRFD,"CCPF: GetInstructions-[%ws]\n", FilePath)); 

    RtlInitUnicodeString(&ScenarioFilePath, FilePath);
    
    InitializeObjectAttributes(&ObjectAttributes,
                               &ScenarioFilePath,
                               OBJ_CASE_INSENSITIVE | OBJ_KERNEL_HANDLE,
                               NULL,
                               NULL);
                                        
    Status = ZwOpenFile(&ScenarioFile,
                        GENERIC_READ | SYNCHRONIZE,
                        &ObjectAttributes,
                        &IoStatus,
                        0,
                        FILE_SYNCHRONOUS_IO_NONALERT);

    if (!NT_SUCCESS(Status)) {
        DBGPR((CCPFID,PFWARN,"CCPF: GetInstructions-FailedOpenFile\n")); 
        goto cleanup;
    }

    OpenedScenarioFile = TRUE;

    //
    // Get file size. If it is too big or too small, give up.
    //

    Status = ZwQueryInformationFile(ScenarioFile,
                                    &IoStatus,
                                    &StandardInfo,
                                    sizeof(StandardInfo),
                                    FileStandardInformation);

    if (!NT_SUCCESS(Status)) {
        DBGPR((CCPFID,PFWARN,"CCPF: GetInstructions-FailedGetInfo\n")); 
        goto cleanup;
    }

    ScenarioSize = StandardInfo.EndOfFile.LowPart;

    if (ScenarioSize > PF_MAXIMUM_SCENARIO_SIZE ||
        ScenarioSize == 0 ||
        StandardInfo.EndOfFile.HighPart) {

        DBGPR((CCPFID,PFWARN,"CCPF: GetInstructions-FileTooBig\n")); 
        Status = STATUS_UNSUCCESSFUL;
        goto cleanup;
    }

    //
    // Allocate scenario buffer.
    //

    Scenario = ExAllocatePoolWithTag(PagedPool,
                                     ScenarioSize,
                                     CCPF_ALLOC_PREFSCEN_TAG);

    if (!Scenario) {
        Status = STATUS_INSUFFICIENT_RESOURCES;
        goto cleanup;
    }

    //
    // Read the scenario file.
    //

    Status = ZwReadFile(ScenarioFile,
                        0,
                        0,
                        0,
                        &IoStatus,
                        Scenario,
                        ScenarioSize,
                        0,
                        0);
    
    if (!NT_SUCCESS(Status)) {
        DBGPR((CCPFID,PFWARN,"CCPF: GetInstructions-FailedRead\n")); 
        goto cleanup;
    }

    //
    // Verify the scenario file.
    //
    
    if (!PfVerifyScenarioBuffer(Scenario, ScenarioSize, &FailedCheck)) {
        DBGPR((CCPFID,PFWARN,"CCPF: GetInstructions-FailedVerify\n")); 
        Status = STATUS_UNSUCCESSFUL;
        goto cleanup;
    }

    //
    // Verify that the scenario type matches.
    //

    if (Scenario->ScenarioType != ScenarioType) {
        DBGPR((CCPFID,PFWARN,"CCPF: GetInstructions-ScenTypeMismatch\n")); 
        Status = STATUS_UNSUCCESSFUL;
        goto cleanup;
    }

    //
    // Setup return pointer.
    //
    
    *ScenarioHeader = Scenario;

    Status = STATUS_SUCCESS;

 cleanup:

    if (OpenedScenarioFile) {
        ZwClose(ScenarioFile);
    }

    if (FilePath) {
        ExFreePool(FilePath);
    }

    if (!NT_SUCCESS(Status)) {
        if (Scenario) {
            ExFreePool(Scenario);
        }
    }

    DBGPR((CCPFID,PFPREF,"CCPF: GetInstructions(%ws)=%x,%p\n", ScenarioId->ScenName, Status, Scenario)); 

    return Status;
}

NTSTATUS
CcPfQueryScenarioInformation(
    IN PPF_SCENARIO_HEADER Scenario,
    IN CCPF_SCENARIO_INFORMATION_TYPE InformationType,
    OUT PVOID Buffer,
    IN ULONG BufferSize,
    OUT PULONG RequiredSize
    )

/*++

Routine Description:

    This routine gathers requested information from the scenario structure.

Arguments:

    Scenario - Pointer to scenario.

    InformationType - Type of information requested.

    Buffer - Where requested information will be put.

    BufferSize - Max size of buffer in bytes.

    RequiredSize - How big the buffer should be if it is too small.

Return Value:

    Status.

Environment:

    Kernel mode, IRQL == PASSIVE_LEVEL.

--*/

{
    NTSTATUS Status;
    PPF_SECTION_RECORD SectionRecord;
    PPF_SECTION_RECORD SectionRecords;
    ULONG SectionIdx;
    PPF_PAGE_RECORD PageRecord;
    PPF_PAGE_RECORD PageRecords;
    PCHAR FileNameData;
    LONG PageIdx;
    PCCPF_BASIC_SCENARIO_INFORMATION BasicInfo;
    PCCPF_BOOT_SCENARIO_INFORMATION BootInfo;
    BOOLEAN AddedHeaderPage;
    ULONG NumDataPages;
    ULONG NumImagePages;
    WCHAR *SectionName;
    WCHAR *SectionNameSuffix;
    WCHAR *SmssSuffix;
    WCHAR *WinlogonSuffix;
    WCHAR *SvchostSuffix;
    WCHAR *UserinitSuffix;
    ULONG SmssSuffixLength;
    ULONG WinlogonSuffixLength;
    ULONG SvchostSuffixLength;
    ULONG UserinitSuffixLength;
    CCPF_BOOT_SCENARIO_PHASE BootPhaseIdx;

    //
    // Initialize locals.
    //

    BootPhaseIdx = 0;
    SmssSuffix = L"\\SYSTEM32\\SMSS.EXE";
    SmssSuffixLength = wcslen(SmssSuffix);
    WinlogonSuffix = L"\\SYSTEM32\\WINLOGON.EXE";
    WinlogonSuffixLength = wcslen(WinlogonSuffix);
    SvchostSuffix = L"\\SYSTEM32\\SVCHOST.EXE";
    SvchostSuffixLength = wcslen(SvchostSuffix);
    UserinitSuffix = L"\\SYSTEM32\\USERINIT.EXE";
    UserinitSuffixLength = wcslen(UserinitSuffix);

    DBGPR((CCPFID,PFTRC,"CCPF: QueryScenario(%p,%x,%p)\n",Scenario,InformationType,Buffer));

    //
    // Check requested information type.
    //

    if (InformationType >= CcPfMaxScenarioInformationType) {
        Status = STATUS_INVALID_PARAMETER;
        goto cleanup;
    }

    //
    // Initialize pointers to data in the scenario.
    //
    
    SectionRecords = (PPF_SECTION_RECORD) 
        ((PCHAR) Scenario + Scenario->SectionInfoOffset);
    
    PageRecords = (PPF_PAGE_RECORD) 
        ((PCHAR) Scenario + Scenario->PageInfoOffset);

    FileNameData = (PCHAR) Scenario + Scenario->FileNameInfoOffset;
    
    //
    // Collect requested information.
    //

    switch(InformationType) {

    case CcPfBasicScenarioInformation:

        //
        // Check buffer size.
        //

        if (BufferSize < sizeof(CCPF_BASIC_SCENARIO_INFORMATION)) {
            *RequiredSize = sizeof(CCPF_BASIC_SCENARIO_INFORMATION);
            Status = STATUS_BUFFER_TOO_SMALL;
            goto cleanup;
        }
        
        //
        // Initialize return buffer.
        //

        BasicInfo = Buffer;
        RtlZeroMemory(BasicInfo, sizeof(CCPF_BASIC_SCENARIO_INFORMATION));

        //
        // Go through the scenario's sections.
        //

        for (SectionIdx = 0; SectionIdx < Scenario->NumSections; SectionIdx ++) {
            
            SectionRecord = &SectionRecords[SectionIdx];
              
            //
            // Skip this section if it was marked ignore for some reason.
            //
            
            if (SectionRecord->IsIgnore) {
                BasicInfo->NumIgnoredSections++;
                continue;
            }
            
            //
            // Initialize loop locals.
            //

            AddedHeaderPage = FALSE;
            NumDataPages = 0;
            NumImagePages = 0;

            //
            // Note that we will prefetch the header page as a data
            // page if this section will be prefetched as image.
            //
            
            if (SectionRecord->IsImage) {
                NumDataPages++;
                AddedHeaderPage = TRUE;
            }

            //
            // Go through the section's pages.
            //

            PageIdx = SectionRecord->FirstPageIdx;
            while (PageIdx != PF_INVALID_PAGE_IDX) {
                
                PageRecord = &PageRecords[PageIdx];

                //
                // Get the index for the next page in the list.
                //
                
                PageIdx = PageRecord->NextPageIdx;
            
                //
                // Skip pages we have marked "ignore" for some reason.
                //
                
                if (PageRecord->IsIgnore) {
                    BasicInfo->NumIgnoredPages++;
                    continue;
                }

                if (PageRecord->IsData) {

                    //
                    // If this page is the first page, count it only
                    // if we have not already counted the header page
                    // for image mapping.
                    //

                    if (PageRecord->FileOffset != 0 ||
                        AddedHeaderPage == FALSE) {
                        NumDataPages++;
                    }
                }

                if (PageRecord->IsImage) {
                    NumImagePages++;
                }
            }
            
            //
            // Update the information structure.
            //

            BasicInfo->NumDataPages += NumDataPages;
            BasicInfo->NumImagePages += NumImagePages;

            if (!NumImagePages && NumDataPages) {
                BasicInfo->NumDataOnlySections++;
            }

            if (NumImagePages && (NumDataPages == 1)) {
                BasicInfo->NumImageOnlySections++;
            }
        }

        Status = STATUS_SUCCESS;

        break;

    case CcPfBootScenarioInformation:

        //
        // Check buffer size.
        //

        if (BufferSize < sizeof(CCPF_BOOT_SCENARIO_INFORMATION)) {
            *RequiredSize = sizeof(CCPF_BOOT_SCENARIO_INFORMATION);
            Status = STATUS_BUFFER_TOO_SMALL;
            goto cleanup;
        }
        
        //
        // Initialize return buffer.
        //

        BootInfo = Buffer;
        RtlZeroMemory(BootInfo, sizeof(CCPF_BOOT_SCENARIO_INFORMATION));

        //
        // Verify that this is a boot scenario.
        //

        if (Scenario->ScenarioType != PfSystemBootScenarioType) {
            Status = STATUS_INVALID_PARAMETER;
            goto cleanup;
        }

        //
        // Go through the scenario's sections.
        //

        for (SectionIdx = 0; SectionIdx < Scenario->NumSections; SectionIdx ++) {
            
            SectionRecord = &SectionRecords[SectionIdx];
        
            SectionName = (WCHAR *) (FileNameData + SectionRecord->FileNameOffset);

            //
            // Update boot phase based on section name.
            //
            
            if (SectionRecord->FileNameLength > SmssSuffixLength) {               
                SectionNameSuffix = SectionName + (SectionRecord->FileNameLength - SmssSuffixLength);               
                if (!wcscmp(SectionNameSuffix, SmssSuffix)) {                   
                    BootPhaseIdx = CcPfBootScenSubsystemInitPhase;
                }
            }

            if (SectionRecord->FileNameLength > WinlogonSuffixLength) {               
                SectionNameSuffix = SectionName + (SectionRecord->FileNameLength - WinlogonSuffixLength);               
                if (!wcscmp(SectionNameSuffix, WinlogonSuffix)) {                   
                    BootPhaseIdx = CcPfBootScenSystemProcInitPhase;
                }
            }

            if (SectionRecord->FileNameLength > SvchostSuffixLength) {               
                SectionNameSuffix = SectionName + (SectionRecord->FileNameLength - SvchostSuffixLength);               
                if (!wcscmp(SectionNameSuffix, SvchostSuffix)) {                   
                    BootPhaseIdx = CcPfBootScenServicesInitPhase;
                }
            }

            if (SectionRecord->FileNameLength > UserinitSuffixLength) {               
                SectionNameSuffix = SectionName + (SectionRecord->FileNameLength - UserinitSuffixLength);               
                if (!wcscmp(SectionNameSuffix, UserinitSuffix)) {                   
                    BootPhaseIdx = CcPfBootScenUserInitPhase;
                }
            }

            CCPF_ASSERT(BootPhaseIdx < CcPfBootScenMaxPhase);
              
            //
            // Skip this section if it was marked ignore for some reason.
            //
            
            if (SectionRecord->IsIgnore) {
                continue;
            }
            
            //
            // Note that we will prefetch the header page as a data
            // page if this section will be prefetched as image.
            //
            
            if (SectionRecord->IsImage) {
                BootInfo->NumDataPages[BootPhaseIdx]++;
                AddedHeaderPage = TRUE;
            } else {
                AddedHeaderPage = FALSE;
            }

            //
            // Go through the section's pages.
            //

            PageIdx = SectionRecord->FirstPageIdx;
            while (PageIdx != PF_INVALID_PAGE_IDX) {
                
                PageRecord = &PageRecords[PageIdx];

                //
                // Get the index for the next page in the list.
                //
                
                PageIdx = PageRecord->NextPageIdx;
            
                //
                // Skip pages we have marked "ignore" for some reason.
                //
                
                if (PageRecord->IsIgnore) {
                    continue;
                }

                if (PageRecord->IsData) {

                    //
                    // If this page is the first page, count it only
                    // if we have not already counted the header page
                    // for image mapping.
                    //

                    if (PageRecord->FileOffset != 0 ||
                        AddedHeaderPage == FALSE) {
                        BootInfo->NumDataPages[BootPhaseIdx]++;
                    }
                }

                if (PageRecord->IsImage) {
                    BootInfo->NumImagePages[BootPhaseIdx]++;
                }
            }
        }
        
        Status = STATUS_SUCCESS;

        break;

    default:

        Status = STATUS_NOT_SUPPORTED;
    }

    //
    // Fall through with status from the switch statement.
    //
        
 cleanup:

    DBGPR((CCPFID,PFTRC,"CCPF: QueryScenario(%p,%x)=%x\n",Scenario,InformationType,Status));

    return Status;
}

NTSTATUS
CcPfOpenVolumesForPrefetch (
    IN PCCPF_PREFETCH_HEADER PrefetchHeader
    )

/*++

Routine Description:

    This routine is called on an initialized PrefetchHeader with the scenario
    field specified. It opens the volumes specified in the scenario updating
    VolumeNodes and the list of volumes we can't prefetch from and the list 
    of volumes we have successfully opened and saved a handle for.

Arguments:

    PrefetchHeader - Pointer to prefetch header that contains the
      prefetch instructions.

Return Value:

    Status.

Environment:

    Kernel mode, IRQL == PASSIVE_LEVEL.

--*/

{
    LARGE_INTEGER CreationTime;
    PCHAR MetadataInfoBase;
    PPF_METADATA_RECORD MetadataRecordTable;
    PPF_METADATA_RECORD MetadataRecord;
    PWCHAR VolumePath;
    PPF_SCENARIO_HEADER Scenario;
    PCCPF_PREFETCH_VOLUME_INFO VolumeNode;
    HANDLE VolumeHandle;
    ULONG SerialNumber;
    ULONG MetadataRecordIdx;
    ULONG AllocationSize;
    NTSTATUS Status;
    BOOLEAN VolumeMounted;

    //
    // Initialize locals.
    //

    Scenario = PrefetchHeader->Scenario;

    DBGPR((CCPFID,PFPREF,"CCPF: OpenVolumesForPrefetch(%p)\n",PrefetchHeader)); 

    //
    // Verify parameters.
    //

    if (Scenario == NULL) {
        CCPF_ASSERT(Scenario);
        Status = STATUS_INVALID_PARAMETER;
        goto cleanup;
    }

    //
    // Allocate volume nodes.
    //

    AllocationSize = Scenario->NumMetadataRecords * sizeof(CCPF_PREFETCH_VOLUME_INFO);

    PrefetchHeader->VolumeNodes = ExAllocatePoolWithTag(PagedPool, 
                                                        AllocationSize,
                                                        CCPF_ALLOC_VOLUME_TAG);

    if (!PrefetchHeader->VolumeNodes) {
        Status = STATUS_INSUFFICIENT_RESOURCES;
        goto cleanup;
    }

    //
    // Get pointer to metadata prefetch information.
    //

    MetadataInfoBase = (PCHAR)Scenario + Scenario->MetadataInfoOffset;
    MetadataRecordTable = (PPF_METADATA_RECORD) MetadataInfoBase;

    //
    // Go through metadata records and build the volume nodes for prefetching.
    //

    for (MetadataRecordIdx = 0;
         MetadataRecordIdx < Scenario->NumMetadataRecords;
         MetadataRecordIdx++) {

        //
        // Initialize loop locals.
        //
        
        MetadataRecord = &MetadataRecordTable[MetadataRecordIdx];
        VolumeHandle = NULL;
        
        VolumePath = (PWCHAR)
            (MetadataInfoBase + MetadataRecord->VolumeNameOffset);  

        //
        // Is the volume mounted?
        //

        Status = CcPfIsVolumeMounted(VolumePath, &VolumeMounted);

        if (!NT_SUCCESS(Status)) {

            //
            // Since we could not tell for sure, treat this volume as 
            // if it were not mounted.
            //

            VolumeMounted = FALSE;
        }

        //
        // If the volume is not mounted we don't want to cause it to be
        // mounted. This creates a problem especially during boot for 
        // clustering where a single physical disk is shared by many 
        // computers.
        //

        if (!VolumeMounted) {
            Status = STATUS_VOLUME_DISMOUNTED;
            goto NextVolume;
        }

        //
        // Open the volume and get relevant information.
        //

        Status = CcPfQueryVolumeInfo(VolumePath,
                                     &VolumeHandle,
                                     &CreationTime,
                                     &SerialNumber);
        
        if (!NT_SUCCESS(Status)) {
            goto NextVolume;
        }

        //
        // For simplicity we save NT paths for the files to prefetch
        // from. If volumes are mounted in a different order, or new ones
        // are created these paths would not work:
        // (e.g. \Device\HarddiskVolume2 should be \Device\HarddiskVolume3 etc.)
        // Verify that such a change has not taken place.
        //
        
        if (SerialNumber != MetadataRecord->SerialNumber ||
            CreationTime.QuadPart != MetadataRecord->CreationTime.QuadPart) {

            Status = STATUS_REVISION_MISMATCH;
            goto NextVolume;
        }

        Status = STATUS_SUCCESS;

      NextVolume:

        //
        // Update the volume node we'll keep around for prefetching.
        //
    
        VolumeNode = &PrefetchHeader->VolumeNodes[MetadataRecordIdx];

        VolumeNode->VolumePath = VolumePath;
        VolumeNode->VolumePathLength = MetadataRecord->VolumeNameLength;

        //
        // If we failed to open the volume, or if it was not mounted or if
        // its SerialNumber / CreationTime has changed put it in the list of
        // volumes we won't prefetch from. Otherwise put it in the list of 
        // opened volumes so we don't have to open it again.
        //

        if (NT_SUCCESS(Status) && VolumeHandle) {
            VolumeNode->VolumeHandle = VolumeHandle;
            VolumeHandle = NULL;
            InsertTailList(&PrefetchHeader->OpenedVolumeList, &VolumeNode->VolumeLink);
        } else {
            VolumeNode->VolumeHandle = NULL;
            InsertTailList(&PrefetchHeader->BadVolumeList, &VolumeNode->VolumeLink);
        }

        if (VolumeHandle) {
            ZwClose(VolumeHandle);
            VolumeHandle = NULL;
        }
    }

    //
    // We've dealt with all the volumes in the prefetch instructions.
    //

    Status = STATUS_SUCCESS;

 cleanup:

    DBGPR((CCPFID,PFPREF,"CCPF: OpenVolumesForPrefetch(%p)=%x\n",PrefetchHeader,Status)); 
    
    return Status;
}

PCCPF_PREFETCH_VOLUME_INFO 
CcPfFindPrefetchVolumeInfoInList(
    WCHAR *Path,
    PLIST_ENTRY List
    )
/*++

Routine Description:

    This routine looks for the volume on which "Path" would be in the list of 
    volumes and returns it.

Arguments:

    Path - NUL terminated path of the volume or a file/directory on the volume.

    List - List of volumes to search.

Return Value:

    Found volume or NULL.

Environment:

    Kernel mode, IRQL == PASSIVE_LEVEL.

--*/

{
    PCCPF_PREFETCH_VOLUME_INFO FoundVolume;
    PCCPF_PREFETCH_VOLUME_INFO VolumeInfo;
    PLIST_ENTRY NextEntry;

    //
    // Initialize locals.
    //

    FoundVolume = NULL;

    //
    // Walk the list.
    //

    for (NextEntry = List->Flink;
         NextEntry != List;
         NextEntry = NextEntry->Flink) {

        VolumeInfo = CONTAINING_RECORD(NextEntry,
                                       CCPF_PREFETCH_VOLUME_INFO,
                                       VolumeLink);

        if (!wcsncmp(Path, VolumeInfo->VolumePath, VolumeInfo->VolumePathLength)) {
            FoundVolume = VolumeInfo;
            break;
        }
    }

    return FoundVolume;
}

NTSTATUS
CcPfGetSectionObject(
    IN PUNICODE_STRING FilePath,
    IN LOGICAL ImageSection,
    OUT PVOID* SectionObject,
    OUT PFILE_OBJECT* FileObject,
    OUT HANDLE* FileHandle
    )

/*++

Routine Description:

    This routine ensures that a section for the specified file exists.

Arguments:

    FilePath - Path to file to get section object for.
    
    ImageSection - TRUE if we want to map as image
    
    SectionObject - Receives the section object if successful (addref'd).
    
    FileObject - Receives the file object if successful (addref'd).
    
    FileHandle - Receives the file handle. We need to keep the file handle,
                 because otherwise non-paging I/O would stop working.

Return Value:

    Status.

Environment:

    Kernel mode. IRQL == PASSIVE_LEVEL.

--*/

{
    HANDLE SectionHandle;
    OBJECT_ATTRIBUTES ObjectAttributes;
    IO_STATUS_BLOCK IoStatus;
    NTSTATUS status;
    ULONG SectionFlags;
    ULONG SectionAccess;
    ULONG FileAccess;
    extern POBJECT_TYPE IoFileObjectType;

    DBGPR((CCPFID,PFPRFD,"CCPF: GetSection(%wZ,%d)\n", FilePath, ImageSection)); 
 
    //
    // Reset parameters.
    //

    *SectionObject = NULL;
    *FileObject = NULL;
    *FileHandle = NULL;

    if (!ImageSection) {
        SectionFlags = SEC_RESERVE;
        FileAccess =  FILE_READ_DATA | FILE_READ_ATTRIBUTES;
        SectionAccess = PAGE_READWRITE;
    } else {
        SectionFlags = SEC_IMAGE;
        FileAccess = FILE_EXECUTE;
        SectionAccess = PAGE_EXECUTE;
    }

    //
    // To ensure that the section exists and is addref'd, we simply
    // open the file and create a section. This way we let Io and Mm
    // handle all the details.
    //

    InitializeObjectAttributes(&ObjectAttributes,
                               FilePath,
                               OBJ_CASE_INSENSITIVE | OBJ_KERNEL_HANDLE,
                               NULL,
                               NULL);

    status = IoCreateFile(FileHandle,
                          (ACCESS_MASK) FileAccess,
                          &ObjectAttributes,
                          &IoStatus,
                          NULL,
                          FILE_ATTRIBUTE_NORMAL,
                          FILE_SHARE_READ | FILE_SHARE_DELETE,
                          FILE_OPEN,
                          FILE_NON_DIRECTORY_FILE,
                          NULL,
                          0,
                          CreateFileTypeNone,
                          (PVOID)NULL,
                          IO_FORCE_ACCESS_CHECK |
                            IO_NO_PARAMETER_CHECKING |
                            IO_CHECK_CREATE_PARAMETERS);

    if (!NT_SUCCESS(status)) {
        goto _return;
    }

    //
    // Create section.
    //

    InitializeObjectAttributes(&ObjectAttributes,
                               NULL,
                               OBJ_CASE_INSENSITIVE | OBJ_KERNEL_HANDLE,
                               NULL,
                               NULL);

    status = ZwCreateSection(&SectionHandle,
                             SECTION_MAP_READ | SECTION_MAP_EXECUTE | SECTION_QUERY,
                             &ObjectAttributes,
                             NULL,
                             SectionAccess,
                             SectionFlags,
                             *FileHandle);

    if (!NT_SUCCESS(status)) {
        ZwClose(*FileHandle);
        *FileHandle = NULL;
        goto _return;
    }

    //
    // Get section object pointer.
    //

    status = ObReferenceObjectByHandle(
        SectionHandle,
        SECTION_MAP_READ | SECTION_MAP_EXECUTE | SECTION_QUERY,
        MmSectionObjectType,
        KernelMode,
        SectionObject,
        NULL
        );

    ZwClose(SectionHandle);

    if (!NT_SUCCESS(status)) {
        *SectionObject = NULL;
        ZwClose(*FileHandle);
        *FileHandle = NULL;
        goto _return;
    }

    //
    // Get file object pointer.
    //

    status = ObReferenceObjectByHandle(*FileHandle,
                                       FileAccess,
                                       IoFileObjectType,
                                       KernelMode,
                                       (PVOID*)FileObject,
                                       NULL);

    if (!NT_SUCCESS(status)) {
        ObDereferenceObject(*SectionObject);
        *SectionObject = NULL;
        *FileObject = NULL;
        ZwClose(*FileHandle);
        *FileHandle = NULL;
        goto _return;
    }

 _return:

    DBGPR((CCPFID,PFPRFD,"CCPF: GetSection(%wZ)=%x\n", FilePath, status)); 

    return status;
}

//
// Routines used for application launch prefetching.
//

NTSTATUS
CcPfScanCommandLine(
    OUT PULONG PrefetchHint,
    OPTIONAL OUT PULONG HashId
    )

/*++

Routine Description:

    Scan the command line (in the PEB) for the current process.

    Checks for /prefetch:XXX in the command line. This is specified by 
    applications to distinguish different ways they are launched in so
    we can customize application launch prefetching for them (e.g. have
    different prefetch instructions for Windows Media player that is 
    launched to play a CD than one that is launched to browse the web.

    If HashId is requested, calculates a hash ID from the full command line.

Arguments:

    PrefetchHint - Hint specified in the command line. If no hint is 
      specified, 0 will be returned.
      
    HashId - Calculated hash id is returned here.

Return Value:

    Status.

Environment:

    Kernel mode. IRQL == PASSIVE_LEVEL.

--*/

{
    PEPROCESS CurrentProcess;
    PPEB Peb;
    PRTL_USER_PROCESS_PARAMETERS ProcessParameters;
    PWCHAR FoundPosition;
    PWCHAR Source;
    PWCHAR SourceEnd;
    PWCHAR Destination;
    PWCHAR DestinationEnd;
    UNICODE_STRING CommandLine;
    UNICODE_STRING PrefetchParameterName;
    NTSTATUS Status;
    ULONG PrefetchHintStringMaxChars;
    WCHAR PrefetchHintString[15];
    
    //
    // Initialize locals.
    //

    RtlInitUnicodeString(&PrefetchParameterName, L"/prefetch:");
    PrefetchHintStringMaxChars = sizeof(PrefetchHintString) / sizeof(PrefetchHintString[0]);
    CurrentProcess = PsGetCurrentProcess();
    Peb = CurrentProcess->Peb;

    //
    // Initialize output parameters.
    //

    *PrefetchHint = 0;

    //
    // Make sure the user mode process environment block is not gone.
    //

    if (!Peb) {
        Status = STATUS_TOO_LATE;
        goto cleanup;
    }

    try {

        //
        // Make sure we can access the process parameters structure.
        //

        ProcessParameters = Peb->ProcessParameters;
        ProbeForReadSmallStructure(ProcessParameters,
                                   sizeof(*ProcessParameters),
                                   _alignof(RTL_USER_PROCESS_PARAMETERS));

        //
        // Copy CommandLine UNICODE_STRING structure to a local.
        //

        CommandLine = ProcessParameters->CommandLine;

        //
        // Is there a command line?
        //

        if (!CommandLine.Buffer) {
            Status = STATUS_NOT_FOUND;
            goto cleanup;
        }

        //
        // If ProcessParameters has been de-normalized, normalize CommandLine.
        //

        if ((ProcessParameters->Flags & RTL_USER_PROC_PARAMS_NORMALIZED) == 0) {
            CommandLine.Buffer = (PWSTR)((PCHAR)ProcessParameters + (ULONG_PTR) CommandLine.Buffer);
        }

        //
        // Probe the command line string.
        //

        ProbeForRead(CommandLine.Buffer, CommandLine.Length, _alignof(WCHAR));

        //
        // Look for the prefetch hint parameter.
        //

        FoundPosition = CcPfFindString(&CommandLine, &PrefetchParameterName);

        if (FoundPosition) {

            //
            // Copy the decimal number following the prefetch hint switch into
            // our local buffer and NUL terminate it.
            //

            Source = FoundPosition + (PrefetchParameterName.Length / sizeof(WCHAR));
            SourceEnd = CommandLine.Buffer + (CommandLine.Length / sizeof(WCHAR));

            Destination = PrefetchHintString;
            DestinationEnd = PrefetchHintString + PrefetchHintStringMaxChars - 1;

            //
            // Copy while we don't hit the end of the command line string and the
            // end of our local buffer (we left room for a terminating NUL), and
            // we don't hit a space (' ') that would mark the end of the prefetch
            // hint command line parameter.
            //

            while ((Source < SourceEnd) && 
                   (Destination < DestinationEnd) && 
                   (*Source != L' ')) {

                *Destination = *Source;

                Source++;
                Destination++;
            }

            //
            // Terminate prefetch hint string. DestinationEnd is the last 
            // character within the PrefetchHintString bounds. Destination
            // can only be <= DestinationEnd.
            //

            CCPF_ASSERT(Destination <= DestinationEnd);

            *Destination = 0;

            //
            // Convert prefetch hint to a number.
            //

            *PrefetchHint = _wtol(PrefetchHintString);

        }

        //
        // Calculate hash id.
        //

        if (HashId) {
            *HashId = CcPfHashValue(CommandLine.Buffer, CommandLine.Length);
        }

        //
        // We are done.
        //

        Status = STATUS_SUCCESS;

    } except (EXCEPTION_EXECUTE_HANDLER) {

        Status = GetExceptionCode();
        CCPF_ASSERT(!NT_SUCCESS(Status));
    }

    //
    // Fall through with the status.
    //

cleanup:

    return Status;    
}

//
// Reference count implementation:
//

VOID
CcPfInitializeRefCount(
    PCCPF_REFCOUNT RefCount
    )

/*++

Routine Description:

    This routine initializes a reference count structure.

Arguments:

    RefCount - Pointer to reference count structure.
    
Return Value:

    None.

Environment:

    Kernel Mode, IRQL == PASSIVE_LEVEL.

--*/   

{
    //
    // Start reference count from 1. When somebody wants to gain
    // exclusive access they decrement it one extra so it may become
    // 0.
    //
    
    RefCount->RefCount = 1;

    //
    // Nobody has exclusive access to start with. 
    //

    RefCount->Exclusive = 0;
}

NTSTATUS
FASTCALL
CcPfAddRef(
    PCCPF_REFCOUNT RefCount
    )

/*++

Routine Description:

    This routine tries to bump the reference count if it has not been
    acquired exclusive.

Arguments:

    RefCount - Pointer to reference count structure.
    
Return Value:

    Status.

Environment:

    Kernel Mode, IRQL <= DISPATCH_LEVEL if RefCount is non-paged.

--*/   

{
    //
    // Do a fast check if the lock was acquire exclusive. If so just
    // return.
    //
    
    if (RefCount->Exclusive) {
        return STATUS_UNSUCCESSFUL;
    }

    //
    // Bump the reference count.
    //

    InterlockedIncrement(&RefCount->RefCount);
    
    //
    // If it was acquired exclusive, pull back.
    //

    if (RefCount->Exclusive) {
        
        InterlockedDecrement(&RefCount->RefCount);

        //
        // Reference count should never go negative.
        //
        
        CCPF_ASSERT(RefCount->RefCount >= 0);
                
        return STATUS_UNSUCCESSFUL;

    } else {

        //
        // We got our reference.
        //

        return STATUS_SUCCESS;
    }  
}

VOID
FASTCALL
CcPfDecRef(
    PCCPF_REFCOUNT RefCount
    )

/*++

Routine Description:

    This routine decrements the reference count. 

Arguments:

    RefCount - Pointer to reference count structure.
    
Return Value:

    None.

Environment:

    Kernel Mode, IRQL <= DISPATCH_LEVEL if RefCount is non-paged.

--*/   

{
    //
    // Decrement the reference count.
    //

    InterlockedDecrement(&RefCount->RefCount);   

    //
    // Reference count should never go negative.
    //

    CCPF_ASSERT(RefCount->RefCount >= 0);
}

NTSTATUS
FASTCALL
CcPfAddRefEx(
    PCCPF_REFCOUNT RefCount,
    ULONG Count
    )

/*++

Routine Description:

    This routine tries to bump the reference count if it has not been
    acquired exclusive.

Arguments:

    RefCount - Pointer to reference count structure.
    Count    - Amount to bump the reference count by
    
Return Value:

    Status.

Environment:

    Kernel Mode, IRQL <= DISPATCH_LEVEL if RefCount is non-paged.

--*/   

{
    //
    // Do a fast check if the lock was acquire exclusive. If so just
    // return.
    //
    
    if (RefCount->Exclusive) {
        return STATUS_UNSUCCESSFUL;
    }

    //
    // Bump the reference count.
    //

    InterlockedExchangeAdd(&RefCount->RefCount, Count);
    
    //
    // If it was acquired exclusive, pull back.
    //

    if (RefCount->Exclusive) {
        
        InterlockedExchangeAdd(&RefCount->RefCount, -(LONG) Count);

        //
        // Reference count should never go negative.
        //
        
        CCPF_ASSERT(RefCount->RefCount >= 0);
                
        return STATUS_UNSUCCESSFUL;

    } else {

        //
        // We got our reference.
        //

        return STATUS_SUCCESS;
    }  
}

VOID
FASTCALL
CcPfDecRefEx(
    PCCPF_REFCOUNT RefCount,
    ULONG Count
    )

/*++

Routine Description:

    This routine decrements the reference count. 

Arguments:

    RefCount - Pointer to reference count structure.
    Count    - Count of how far to decrement the reference count by
    
Return Value:

    None.

Environment:

    Kernel Mode, IRQL <= DISPATCH_LEVEL if RefCount is non-paged.

--*/   

{
    //
    // Decrement the reference count.
    //

    InterlockedExchangeAdd(&RefCount->RefCount, -(LONG) Count);   

    //
    // Reference count should never go negative.
    //

    CCPF_ASSERT(RefCount->RefCount >= 0);
}

NTSTATUS
CcPfAcquireExclusiveRef(
    PCCPF_REFCOUNT RefCount
    )

/*++

Routine Description:

    This routine attempts to get exclusive reference. If there is
    already an exclusive reference, it fails. Othwerwise it waits for
    all normal references to go away.

Arguments:

    RefCount - Pointer to reference count structure.
    
Return Value:

    Status.

Environment:

    Kernel Mode, IRQL == PASSIVE_LEVEL.

--*/   

{
    LONG OldValue;
    LARGE_INTEGER SleepTime;

    //
    // Try to get exclusive access by setting Exclusive from 0 to 1.
    //

    OldValue = InterlockedCompareExchange(&RefCount->Exclusive, 1, 0);

    if (OldValue != 0) {

        //
        // Somebody already had the lock.
        //
        
        return STATUS_UNSUCCESSFUL;
    }

    //
    // Decrement the reference count once so it may become 0.
    //

    InterlockedDecrement(&RefCount->RefCount);

    //
    // No new references will be given away. We poll until existing
    // references are released.
    //

    do {

        if (RefCount->RefCount == 0) {

            break;

        } else {

            //
            // Sleep for a while [in 100ns, negative so it is relative
            // to current system time].
            //

            SleepTime.QuadPart = - 10 * 1000 * 10; // 10 ms.

            KeDelayExecutionThread(KernelMode, FALSE, &SleepTime);
        }

    } while(TRUE);

    return STATUS_SUCCESS;
}

PCCPF_TRACE_HEADER
CcPfReferenceProcessTrace(
    PEPROCESS Process
    )
/*++

Routine Description:

    This routine references the trace associated with the specified process
    if possible. It uses fast references to avoid taking the trace lock
    to improve performance.

Arguments:

    Process - The process whose trace should be referenced

Return Value:

    The referenced trace buffer or NULL if it could not be referenced

--*/
{
    EX_FAST_REF OldRef;
    PCCPF_TRACE_HEADER Trace;
    ULONG RefsToAdd, Unused;
    NTSTATUS Status;
    KIRQL OldIrql;

    //
    // Attempt the fast reference
    //
    
    OldRef = ExFastReference (&Process->PrefetchTrace);

    Trace = ExFastRefGetObject (OldRef);

    //
    // Optimize the common path where there won't be a trace on the
    // process header (since traces are just for the application launch.)
    //

    if (Trace == NULL) {
        return 0;
    }
    
    //
    // We fail if there wasn't a trace or if it has no cached references
    // left. Both of these cases had the cached reference count zero.
    //
    
    Unused = ExFastRefGetUnusedReferences (OldRef);

    if (Unused <= 1) {
        //
        // If there are no references left then we have to do this under the lock
        //
        if (Unused == 0) {
            Status = STATUS_SUCCESS;
            KeAcquireSpinLock(&CcPfGlobals.ActiveTracesLock, &OldIrql);                    

            Trace = ExFastRefGetObject (Process->PrefetchTrace);
            if (Trace != NULL) {
                Status = CcPfAddRef(&Trace->RefCount);
            }
            KeReleaseSpinLock(&CcPfGlobals.ActiveTracesLock, OldIrql);

            if (!NT_SUCCESS (Status)) {
                Trace = NULL;
            }
            return Trace;
        }

        //
        // If we took the counter to zero then attempt to make life easier for
        // the next referencer by resetting the counter to its max. Since we now
        // have a reference to the object we can do this.
        //
        
        RefsToAdd = ExFastRefGetAdditionalReferenceCount ();
        Status = CcPfAddRefEx (&Trace->RefCount, RefsToAdd);

        //
        // If we failed to obtain additional references then just ignore the fixup.
        //
        
        if (NT_SUCCESS (Status)) {

            //
            // If we fail to add them to the fast reference structure then
            // give them back to the trace and forget about fixup.
            //
            
            if (!ExFastRefAddAdditionalReferenceCounts (&Process->PrefetchTrace, Trace, RefsToAdd)) {
                CcPfDecRefEx (&Trace->RefCount, RefsToAdd);
            }
        }

    }
    return Trace;
}

PCCPF_TRACE_HEADER
CcPfRemoveProcessTrace(
    PEPROCESS Process
    )
/*++

Routine Description:

    This routine removes the trace associated with the specified process.

    It returns the trace with the original reference acquired by AddProcessTrace.

Arguments:

    Process - The process whose trace should be removed

Return Value:

    The removed trace buffer.

--*/
{
    EX_FAST_REF OldRef;
    PCCPF_TRACE_HEADER Trace;
    ULONG RefsToReturn;
    KIRQL OldIrql;

    //
    // Do the swap.
    //

    OldRef = ExFastRefSwapObject (&Process->PrefetchTrace, NULL);
    Trace = ExFastRefGetObject (OldRef);

    //
    // We should have a trace on the process if we are trying to remove it.
    //

    CCPF_ASSERT(Trace);

    //
    // Work out how many cached references there were (if any) and 
    // return them.
    //

    RefsToReturn = ExFastRefGetUnusedReferences (OldRef);

    if (RefsToReturn > 0) {
        CcPfDecRefEx (&Trace->RefCount, RefsToReturn);
    }

    //
    // Force any slow path references out of that path now before we return 
    // the trace.
    //

#if !defined (NT_UP)
    KeAcquireSpinLock(&CcPfGlobals.ActiveTracesLock, &OldIrql);                    
    KeReleaseSpinLock(&CcPfGlobals.ActiveTracesLock, OldIrql);
#endif // NT_UP

    //
    // We are returning the trace with the extra reference we had acquired in
    // AddProcessTrace.
    //

    return Trace;

}

NTSTATUS
CcPfAddProcessTrace(
    PEPROCESS Process,
    PCCPF_TRACE_HEADER Trace
    )
/*++

Routine Description:

    This routine adds the trace associated with the specified process
    if possible.

Arguments:

    Process - The process whose trace should be removed
    Trace - The trace to associate with the process

Return Value:

    Status.

--*/
{
    NTSTATUS Status;

    //
    // Bias the trace reference by the cache size + an additional reference to
    // be associated with the fast reference as a whole (allowing the slow
    // path to access the trace.)
    //
    
    Status = CcPfAddRefEx (&Trace->RefCount, ExFastRefGetAdditionalReferenceCount () + 1);
    if (NT_SUCCESS (Status)) {
        ExFastRefInitialize (&Process->PrefetchTrace, Trace);
    }
    
    return Status;
}

//
// Utility routines.
//

PWCHAR
CcPfFindString (
    PUNICODE_STRING SearchIn,
    PUNICODE_STRING SearchFor
    )

/*++

Routine Description:

    Finds SearchFor string in SearchIn string and returns pointer to the 
    beginning of the match in SearchIn.

Arguments:

    SearchIn - Pointer to string to search in.

    SearchFor - Pointer to string to search for.

Return Value:

    Pointer to beginning of match in SearchIn, or NULL if not found.

Environment:

    Kernel mode, IRQL <= DISPATCH_LEVEL if *Key is NonPaged.

--*/

{
    PWCHAR SearchInPosition;
    PWCHAR SearchInEnd;
    PWCHAR SearchInMatchPosition;
    PWCHAR SearchForPosition;
    PWCHAR SearchForEnd;

    SearchInPosition = SearchIn->Buffer;
    SearchInEnd = SearchIn->Buffer + (SearchIn->Length / sizeof(WCHAR));

    SearchForEnd = SearchFor->Buffer + (SearchFor->Length / sizeof(WCHAR));

    while (SearchInPosition < SearchInEnd) {

        //
        // Try to match the SearchFor string starting at SearchInPosition.
        //

        SearchInMatchPosition = SearchInPosition;
        SearchForPosition = SearchFor->Buffer;
        
        while ((SearchInMatchPosition < SearchInEnd) &&
               (SearchForPosition < SearchForEnd) &&
               (*SearchInMatchPosition == *SearchForPosition)) {

            SearchInMatchPosition++;
            SearchForPosition++;
        }

        //
        // We should not go beyond bounds.
        //

        CCPF_ASSERT(SearchInMatchPosition <= SearchInEnd);
        CCPF_ASSERT(SearchForPosition <= SearchForEnd);
               
        //
        // If we matched up to the end of SearchFor string, we found it.
        //

        if (SearchForPosition == SearchForEnd) {
            return SearchInPosition;
        }

        //
        // Look for a match starting at the next character in the SearchIn string.
        //

        SearchInPosition++;
    }

    //
    // We could not find the SearchFor string in SearchIn string.
    //

    return NULL;
}

ULONG
CcPfHashValue(
    PVOID key,
    ULONG len
    )

/*++

Routine Description:

    Generic hash routine.

Arguments:

    Key - Pointer to data to calculate a hash value for.

    Len - Number of bytes pointed to by key.

Return Value:

    Hash value.

Environment:

    Kernel mode, IRQL <= DISPATCH_LEVEL if *Key is NonPaged.

--*/

{
    char *cp = key;
    ULONG i, convkey=0;
    for(i = 0; i < len; i++)
    {
        convkey = 37 * convkey + (unsigned int) *cp;
        cp++;
    }

    #define CCPF_RNDM_CONSTANT   314159269
    #define CCPF_RNDM_PRIME     1000000007

    return (abs(CCPF_RNDM_CONSTANT * convkey) % CCPF_RNDM_PRIME);
}

NTSTATUS 
CcPfIsVolumeMounted (
    IN WCHAR *VolumePath,
    OUT BOOLEAN *VolumeMounted
    )

/*++

Routine Description:

    Determines if the volume is mounted without causing it to be
    mounted..

Arguments:

    VolumePath - Pointer to NUL terminated volume path.

    VolumeMounted - Whether the volume mounted is returned here.

Return Value:

    Status.

Environment:

    Kernel mode. IRQL == PASSIVE_LEVEL.

--*/

{
    HANDLE VolumeHandle;
    FILE_FS_DEVICE_INFORMATION DeviceInfo;
    UNICODE_STRING VolumePathU;
    OBJECT_ATTRIBUTES ObjectAttributes;
    IO_STATUS_BLOCK IoStatusBlock;
    NTSTATUS Status;
    BOOLEAN OpenedVolume;

    //
    // Initialize locals.
    //
      
    OpenedVolume = FALSE;

    //
    // Open the device so we can query if a volume is mounted without
    // causing it to be mounted.
    //

    RtlInitUnicodeString(&VolumePathU, VolumePath);  

    InitializeObjectAttributes(&ObjectAttributes,
                               &VolumePathU,
                               OBJ_CASE_INSENSITIVE | OBJ_KERNEL_HANDLE,
                               NULL,
                               NULL);
   
    
    Status = ZwCreateFile(&VolumeHandle,
                          FILE_READ_ATTRIBUTES | SYNCHRONIZE,
                          &ObjectAttributes,
                          &IoStatusBlock,
                          0,
                          0,
                          FILE_SHARE_READ|FILE_SHARE_WRITE|FILE_SHARE_DELETE,
                          FILE_OPEN,
                          FILE_SYNCHRONOUS_IO_NONALERT,
                          NULL,
                          0);

    if (!NT_SUCCESS(Status)) {
        goto cleanup;
    }

    OpenedVolume = TRUE;

    //
    // Make the device info query.
    //

    Status = ZwQueryVolumeInformationFile(VolumeHandle,
                                          &IoStatusBlock,
                                          &DeviceInfo,
                                          sizeof(DeviceInfo),
                                          FileFsDeviceInformation);
    
    if (NT_ERROR(Status)) {
        goto cleanup;
    }

    //
    // Is a volume mounted on this device?
    //

    *VolumeMounted = (DeviceInfo.Characteristics & FILE_DEVICE_IS_MOUNTED) ? TRUE : FALSE;

    Status = STATUS_SUCCESS;

cleanup:

    if (OpenedVolume) {
        ZwClose(VolumeHandle);
    }

    return Status;

}

NTSTATUS
CcPfQueryVolumeInfo (
    IN WCHAR *VolumePath,
    OPTIONAL OUT HANDLE *VolumeHandleOut,
    OUT PLARGE_INTEGER CreationTime,
    OUT PULONG SerialNumber
    )

/*++

Routine Description:

    Queries volume information for the specified volume.

Arguments:

    VolumePath - Pointer to NUL terminated volume path.

    VolumeHandleOut - If specified, the volume handle is returned here. 
       The caller has to close the volume when done with it.

    VolumeMounted - If specified, first we check the volume is already
       mounted. If volume is not mounted we don't query anything else.
    
    CreationTime - Pointer to where creation time of the volume will
      be put. 

    SerialNumber - Pointer to where serial number of the volume will be put.

Return Value:

    Status.

Environment:

    Kernel mode. IRQL == PASSIVE_LEVEL.

--*/

{
    HANDLE VolumeHandle;
    FILE_FS_VOLUME_INFORMATION VolumeInfo;
    UNICODE_STRING VolumePathU;
    OBJECT_ATTRIBUTES ObjectAttributes;
    IO_STATUS_BLOCK IoStatusBlock;
    NTSTATUS Status;
    BOOLEAN OpenedVolume;
        
    //
    // Initialize locals.
    //
      
    OpenedVolume = FALSE;

    //
    // Open the volume so we can make queries to the file system
    // mounted on it. This will cause a mount if the volume has not been
    // mounted.
    //

    RtlInitUnicodeString(&VolumePathU, VolumePath);  

    InitializeObjectAttributes(&ObjectAttributes,
                               &VolumePathU,
                               OBJ_CASE_INSENSITIVE | OBJ_KERNEL_HANDLE,
                               NULL,
                               NULL);
   
    
    Status = ZwCreateFile(&VolumeHandle,
                          FILE_WRITE_ATTRIBUTES | FILE_READ_ATTRIBUTES | SYNCHRONIZE,
                          &ObjectAttributes,
                          &IoStatusBlock,
                          0,
                          0,
                          FILE_SHARE_READ|FILE_SHARE_WRITE|FILE_SHARE_DELETE,
                          FILE_OPEN,
                          FILE_SYNCHRONOUS_IO_NONALERT,
                          NULL,
                          0);

    if (!NT_SUCCESS(Status)) {
        goto cleanup;
    }
    
    OpenedVolume = TRUE;

    //
    // Query volume information. We won't have space for the full
    // volume label in our buffer but we don't really need it. The
    // file systems seem to fill in the SerialNo/CreationTime fields
    // and return a STATUS_MORE_DATA warning status.
    //

    Status = ZwQueryVolumeInformationFile(VolumeHandle,
                                          &IoStatusBlock,
                                          &VolumeInfo,
                                          sizeof(VolumeInfo),
                                          FileFsVolumeInformation);
    
    if (NT_ERROR(Status)) {
        goto cleanup;
    }

    *CreationTime = VolumeInfo.VolumeCreationTime;
    *SerialNumber = VolumeInfo.VolumeSerialNumber;

    Status = STATUS_SUCCESS;

 cleanup:

    if (NT_SUCCESS(Status)) {

        //
        // If the caller wants the volume handle, hand it over to them.
        // It is their responsibility to close the handle.
        //

        if (VolumeHandleOut) {
            *VolumeHandleOut = VolumeHandle;
            OpenedVolume = FALSE;
        }
    }
   
    if (OpenedVolume) {
        ZwClose(VolumeHandle);
    }

    return Status;
}

//
// Verification code shared between the kernel and user mode
// components. This code should be kept in sync with a simple copy &
// paste, so don't add any kernel/user specific code/macros. Note that
// the prefix on the function names are Pf, just like it is with
// shared structures / constants.
//

BOOLEAN
PfWithinBounds(
    PVOID Pointer,
    PVOID Base,
    ULONG Length
    )

/*++

Routine Description:

    Check whether the pointer is within Length bytes from the base.

Arguments:

    Pointer - Pointer to check.

    Base - Pointer to base of mapping/array etc.

    Length - Number of bytes that are valid starting from Base.

Return Value:

    TRUE - Pointer is within bounds.
    
    FALSE - Pointer is not within bounds.

--*/

{
    if (((PCHAR)Pointer < (PCHAR)Base) ||
        ((PCHAR)Pointer >= ((PCHAR)Base + Length))) {

        return FALSE;
    } else {

        return TRUE;
    }
}

BOOLEAN
PfVerifyScenarioId (
    PPF_SCENARIO_ID ScenarioId
    )

/*++

Routine Description:

    Verify that the scenario id is sensible.

Arguments:

    ScenarioId - Scenario Id to verify.

Return Value:

    TRUE - ScenarioId is fine.
    FALSE - ScenarioId is corrupt.

--*/
    
{
    LONG CurCharIdx;

    //
    // Make sure the scenario name is NUL terminated.
    //

    for (CurCharIdx = PF_SCEN_ID_MAX_CHARS; CurCharIdx >= 0; CurCharIdx--) {

        if (ScenarioId->ScenName[CurCharIdx] == 0) {
            break;
        }
    }

    if (ScenarioId->ScenName[CurCharIdx] != 0) {
        return FALSE;
    }

    //
    // Make sure there is a scenario name.
    //

    if (CurCharIdx == 0) {
        return FALSE;
    }

    //
    // Checks passed.
    //
    
    return TRUE;
}

BOOLEAN
PfVerifyScenarioBuffer(
    PPF_SCENARIO_HEADER Scenario,
    ULONG BufferSize,
    PULONG FailedCheck
    )

/*++

Routine Description:

    Verify offset and indices in a scenario file are not beyond
    bounds. This code is shared between the user mode service and
    kernel mode component. If you update this function, update it in
    both.

Arguments:

    Scenario - Base of mapped view of the whole file.

    BufferSize - Size of the scenario buffer.

    FailedCheck - If verify failed, Id for the check that was failed.

Return Value:

    TRUE - Scenario is fine.
    FALSE - Scenario is corrupt.

--*/

{
    PPF_SECTION_RECORD Sections;
    PPF_SECTION_RECORD pSection;
    ULONG SectionIdx;
    PPF_PAGE_RECORD Pages;
    PPF_PAGE_RECORD pPage;
    LONG PageIdx;   
    PCHAR FileNames;
    PCHAR pFileNameStart;
    PCHAR pFileNameEnd;
    PWCHAR pwFileName;
    LONG FailedCheckId;
    ULONG NumRemainingPages;
    ULONG NumPages;
    LONG PreviousPageIdx;
    ULONG FileNameSize;
    BOOLEAN ScenarioVerified;
    PCHAR MetadataInfoBase;
    PPF_METADATA_RECORD MetadataRecordTable;
    PPF_METADATA_RECORD MetadataRecord;
    ULONG MetadataRecordIdx;
    PWCHAR VolumePath;
    PFILE_PREFETCH FilePrefetchInfo;
    ULONG FilePrefetchInfoSize;
    PPF_COUNTED_STRING DirectoryPath;
    ULONG DirectoryIdx;

    //
    // Initialize locals.
    //

    FailedCheckId = 0;
        
    //
    // Initialize return value to FALSE. It will be set to TRUE only
    // after all the checks pass.
    //
    
    ScenarioVerified = FALSE;

    //
    // The buffer should at least contain the scenario header.
    //

    if (BufferSize < sizeof(PF_SCENARIO_HEADER)) {
        
        FailedCheckId = 10;
        goto cleanup;
    }

    //
    // Check version and magic on the header.
    //

    if (Scenario->Version != PF_CURRENT_VERSION ||
        Scenario->MagicNumber != PF_SCENARIO_MAGIC_NUMBER) { 

        FailedCheckId = 20;
        goto cleanup;
    }

    //
    // The buffer should not be greater than max allowed size.
    //

    if (BufferSize > PF_MAXIMUM_SCENARIO_SIZE) {
        
        FailedCheckId = 25;
        goto cleanup;
    }

    //
    // Check for legal scenario type.
    //

    if (Scenario->ScenarioType >= PfMaxScenarioType) {
        FailedCheckId = 27;
        goto cleanup;
    }

    //
    // Check limits on number of pages, sections etc.
    //

    if (Scenario->NumSections > PF_MAXIMUM_SECTIONS ||
        Scenario->NumMetadataRecords > PF_MAXIMUM_SECTIONS ||
        Scenario->NumPages > PF_MAXIMUM_PAGES ||
        Scenario->FileNameInfoSize > PF_MAXIMUM_FILE_NAME_DATA_SIZE) {
        
        FailedCheckId = 30;
        goto cleanup;
    }

    if (Scenario->NumSections == 0 ||
        Scenario->NumPages == 0 ||
        Scenario->FileNameInfoSize == 0) {
        
        FailedCheckId = 33;
        goto cleanup;
    }
    
    //
    // Check limit on sensitivity.
    //

    if (Scenario->Sensitivity < PF_MIN_SENSITIVITY ||
        Scenario->Sensitivity > PF_MAX_SENSITIVITY) {
        
        FailedCheckId = 35;
        goto cleanup;
    }

    //
    // Make sure the scenario id is valid.
    //

    if (!PfVerifyScenarioId(&Scenario->ScenarioId)) {
        
        FailedCheckId = 37;
        goto cleanup;
    }

    //
    // Initialize pointers to tables.
    //

    Sections = (PPF_SECTION_RECORD) ((PCHAR)Scenario + Scenario->SectionInfoOffset);
       
    if (!PfWithinBounds(Sections, Scenario, BufferSize)) {
        FailedCheckId = 40;
        goto cleanup;
    }

    if (!PfWithinBounds((PCHAR) &Sections[Scenario->NumSections] - 1, 
                        Scenario, 
                        BufferSize)) {
        FailedCheckId = 45;
        goto cleanup;
    }   

    Pages = (PPF_PAGE_RECORD) ((PCHAR)Scenario + Scenario->PageInfoOffset);
       
    if (!PfWithinBounds(Pages, Scenario, BufferSize)) {
        FailedCheckId = 50;
        goto cleanup;
    }

    if (!PfWithinBounds((PCHAR) &Pages[Scenario->NumPages] - 1, 
                        Scenario, 
                        BufferSize)) {
        FailedCheckId = 55;
        goto cleanup;
    }

    FileNames = (PCHAR)Scenario + Scenario->FileNameInfoOffset;
      
    if (!PfWithinBounds(FileNames, Scenario, BufferSize)) {
        FailedCheckId = 60;
        goto cleanup;
    }

    if (!PfWithinBounds(FileNames + Scenario->FileNameInfoSize - 1, 
                        Scenario, 
                        BufferSize)) {
        FailedCheckId = 70;
        goto cleanup;
    }

    MetadataInfoBase = (PCHAR)Scenario + Scenario->MetadataInfoOffset;
    MetadataRecordTable = (PPF_METADATA_RECORD) MetadataInfoBase;

    if (!PfWithinBounds(MetadataInfoBase, Scenario, BufferSize)) {
        FailedCheckId = 73;
        goto cleanup;
    }

    if (!PfWithinBounds(MetadataInfoBase + Scenario->MetadataInfoSize - 1, 
                        Scenario, 
                        BufferSize)) {
        FailedCheckId = 74;
        goto cleanup;
    }   

    if (!PfWithinBounds(((PCHAR) &MetadataRecordTable[Scenario->NumMetadataRecords]) - 1, 
                        Scenario, 
                        BufferSize)) {
        FailedCheckId = 75;
        goto cleanup;
    }   
    
    //
    // Verify that sections contain valid information.
    //

    NumRemainingPages = Scenario->NumPages;

    for (SectionIdx = 0; SectionIdx < Scenario->NumSections; SectionIdx++) {
        
        pSection = &Sections[SectionIdx];

        //
        // Check if file name is within bounds. 
        //

        pFileNameStart = FileNames + pSection->FileNameOffset;

        if (!PfWithinBounds(pFileNameStart, Scenario, BufferSize)) {
            FailedCheckId = 80;
            goto cleanup;
        }

        //
        // Make sure there is a valid sized file name. 
        //

        if (pSection->FileNameLength == 0) {
            FailedCheckId = 90;
            goto cleanup;    
        }

        //
        // Check file name max length.
        //

        if (pSection->FileNameLength > PF_MAXIMUM_SECTION_FILE_NAME_LENGTH) {
            FailedCheckId = 100;
            goto cleanup;    
        }

        //
        // Note that pFileNameEnd gets a -1 so it is the address of
        // the last byte.
        //

        FileNameSize = (pSection->FileNameLength + 1) * sizeof(WCHAR);
        pFileNameEnd = pFileNameStart + FileNameSize - 1;

        if (!PfWithinBounds(pFileNameEnd, Scenario, BufferSize)) {
            FailedCheckId = 110;
            goto cleanup;
        }

        //
        // Check if the file name is NUL terminated.
        //
        
        pwFileName = (PWCHAR) pFileNameStart;
        
        if (pwFileName[pSection->FileNameLength] != 0) {
            FailedCheckId = 120;
            goto cleanup;
        }

        //
        // Check max number of pages in a section.
        //

        if (pSection->NumPages > PF_MAXIMUM_SECTION_PAGES) {
            FailedCheckId = 140;
            goto cleanup;    
        }

        //
        // Make sure NumPages for the section is at least less
        // than the remaining pages in the scenario. Then update the
        // remaining pages.
        //

        if (pSection->NumPages > NumRemainingPages) {
            FailedCheckId = 150;
            goto cleanup;
        }

        NumRemainingPages -= pSection->NumPages;

        //
        // Verify that there are NumPages pages in our page list and
        // they are sorted by file offset.
        //

        PageIdx = pSection->FirstPageIdx;
        NumPages = 0;
        PreviousPageIdx = PF_INVALID_PAGE_IDX;

        while (PageIdx != PF_INVALID_PAGE_IDX) {
            
            //
            // Check that page idx is within range.
            //
            
            if (PageIdx < 0 || (ULONG) PageIdx >= Scenario->NumPages) {
                FailedCheckId = 160;
                goto cleanup;
            }

            //
            // If this is not the first page record, make sure it
            // comes after the previous one. We also check for
            // duplicate offset here.
            //

            if (PreviousPageIdx != PF_INVALID_PAGE_IDX) {
                if (Pages[PageIdx].FileOffset <= 
                    Pages[PreviousPageIdx].FileOffset) {

                    FailedCheckId = 165;
                    goto cleanup;
                }
            }

            //
            // Update the last page index.
            //

            PreviousPageIdx = PageIdx;

            //
            // Get the next page index.
            //

            pPage = &Pages[PageIdx];
            PageIdx = pPage->NextPageIdx;
            
            //
            // Update the number of pages we've seen on the list so
            // far. If it is greater than what there should be on the
            // list we have a problem. We may have even hit a list.
            //

            NumPages++;
            if (NumPages > pSection->NumPages) {
                FailedCheckId = 170;
                goto cleanup;
            }
        }
        
        //
        // Make sure the section has exactly the number of pages it
        // says it does.
        //

        if (NumPages != pSection->NumPages) {
            FailedCheckId = 180;
            goto cleanup;
        }
    }

    //
    // We should have accounted for all pages in the scenario.
    //

    if (NumRemainingPages) {
        FailedCheckId = 190;
        goto cleanup;
    }

    //
    // Make sure metadata prefetch records make sense.
    //

    for (MetadataRecordIdx = 0;
         MetadataRecordIdx < Scenario->NumMetadataRecords;
         MetadataRecordIdx++) {

        MetadataRecord = &MetadataRecordTable[MetadataRecordIdx];
        
        //
        // Make sure that the volume path is within bounds and NUL
        // terminated.
        //

        VolumePath = (PWCHAR)(MetadataInfoBase + MetadataRecord->VolumeNameOffset);  
        
        if (!PfWithinBounds(VolumePath, Scenario, BufferSize)) {
            FailedCheckId = 200;
            goto cleanup;
        }

        if (!PfWithinBounds(((PCHAR)(VolumePath + MetadataRecord->VolumeNameLength + 1)) - 1, 
                            Scenario, 
                            BufferSize)) {
            FailedCheckId = 210;
            goto cleanup;
        }

        if (VolumePath[MetadataRecord->VolumeNameLength] != 0) {
            FailedCheckId = 220;
            goto cleanup;           
        }

        //
        // Make sure that FilePrefetchInformation is within bounds.
        //

        FilePrefetchInfo = (PFILE_PREFETCH) 
            (MetadataInfoBase + MetadataRecord->FilePrefetchInfoOffset);
        
        if (!PfWithinBounds(FilePrefetchInfo, Scenario, BufferSize)) {
            FailedCheckId = 230;
            goto cleanup;
        }

        //
        // Its size should be greater than size of a FILE_PREFETCH
        // structure (so we can safely access the fields).
        //

        if (MetadataRecord->FilePrefetchInfoSize < sizeof(FILE_PREFETCH)) {
            FailedCheckId = 240;
            goto cleanup;
        }
        
        //
        // It should be for prefetching file creates.
        //

        if (FilePrefetchInfo->Type != FILE_PREFETCH_TYPE_FOR_CREATE) {
            FailedCheckId = 250;
            goto cleanup;
        }

        //
        // There should not be more entries then are files and
        // directories. The number of inidividual directories may be
        // more than what we allow for, but it would be highly rare to
        // be suspicious and thus ignored.
        //

        if (FilePrefetchInfo->Count > PF_MAXIMUM_DIRECTORIES + PF_MAXIMUM_SECTIONS) {
            FailedCheckId = 260;
            goto cleanup;
        }

        //
        // Its size should match the size calculated by number of file
        // index numbers specified in the header.
        //

        FilePrefetchInfoSize = sizeof(FILE_PREFETCH);
        if (FilePrefetchInfo->Count) {
            FilePrefetchInfoSize += (FilePrefetchInfo->Count - 1) * sizeof(ULONGLONG);
        }

        if (!PfWithinBounds((PCHAR) FilePrefetchInfo + MetadataRecord->FilePrefetchInfoSize - 1,
                            Scenario,
                            BufferSize)) {
            FailedCheckId = 270;
            goto cleanup;
        }

        //
        // Make sure that the directory paths for this volume make
        // sense.
        //

        if (MetadataRecord->NumDirectories > PF_MAXIMUM_DIRECTORIES) {
            FailedCheckId = 280;
            goto cleanup;
        }

        DirectoryPath = (PPF_COUNTED_STRING) 
            (MetadataInfoBase + MetadataRecord->DirectoryPathsOffset);
        
        for (DirectoryIdx = 0;
             DirectoryIdx < MetadataRecord->NumDirectories;
             DirectoryIdx ++) {
            
            //
            // Make sure head of the structure is within bounds.
            //

            if (!PfWithinBounds((PCHAR)DirectoryPath + sizeof(PF_COUNTED_STRING) - 1, 
                                Scenario, 
                                BufferSize)) {
                FailedCheckId = 290;
                goto cleanup;
            }
                
            //
            // Check the length of the string.
            //
            
            if (DirectoryPath->Length >= PF_MAXIMUM_SECTION_FILE_NAME_LENGTH) {
                FailedCheckId = 300;
                goto cleanup;
            }

            //
            // Make sure end of the string is within bounds.
            //
            
            if (!PfWithinBounds((PCHAR)(&DirectoryPath->String[DirectoryPath->Length + 1]) - 1,
                                Scenario, 
                                BufferSize)) {
                FailedCheckId = 310;
                goto cleanup;
            }
            
            //
            // Make sure the string is NUL terminated.
            //
            
            if (DirectoryPath->String[DirectoryPath->Length] != 0) {
                FailedCheckId = 320;
                goto cleanup;   
            }
            
            //
            // Set pointer to next DirectoryPath.
            //
            
            DirectoryPath = (PPF_COUNTED_STRING) 
                (&DirectoryPath->String[DirectoryPath->Length + 1]);
        }            
    }

    //
    // We've passed all the checks.
    //

    ScenarioVerified = TRUE;

 cleanup:

    *FailedCheck = FailedCheckId;

    return ScenarioVerified;
}

BOOLEAN
PfVerifyTraceBuffer(
    PPF_TRACE_HEADER Trace,
    ULONG BufferSize,
    PULONG FailedCheck
    )

/*++

Routine Description:

    Verify offset and indices in a trace buffer are not beyond
    bounds. This code is shared between the user mode service and
    kernel mode component. If you update this function, update it in
    both.

Arguments:

    Trace - Base of Trace buffer.

    BufferSize - Size of the scenario file / mapping.

    FailedCheck - If verify failed, Id for the check that was failed.

Return Value:

    TRUE - Trace is fine.
    FALSE - Trace is corrupt;

--*/

{
    LONG FailedCheckId;
    PPF_LOG_ENTRY LogEntries;
    PPF_SECTION_INFO Section;
    PPF_VOLUME_INFO VolumeInfo;
    ULONG SectionLength;
    ULONG EntryIdx;
    ULONG SectionIdx;
    ULONG TotalFaults;
    ULONG PeriodIdx;
    ULONG VolumeIdx;
    BOOLEAN TraceVerified;
    ULONG VolumeInfoSize;

    //
    // Initialize locals:
    //

    FailedCheckId = 0;

    //
    // Initialize return value to FALSE. It will be set to TRUE only
    // after all the checks pass.
    //

    TraceVerified = FALSE;;

    //
    // The buffer should at least contain the scenario header.
    //

    if (BufferSize < sizeof(PF_TRACE_HEADER)) {
        FailedCheckId = 10;
        goto cleanup;
    }

    //
    // Check version and magic on the header.
    //

    if (Trace->Version != PF_CURRENT_VERSION ||
        Trace->MagicNumber != PF_TRACE_MAGIC_NUMBER) {
        FailedCheckId = 20;
        goto cleanup;
    }

    //
    // The buffer should not be greater than max allowed size.
    //

    if (BufferSize > PF_MAXIMUM_TRACE_SIZE) {
        FailedCheckId = 23;
        goto cleanup;
    }

    //
    // Check for legal scenario type.
    //

    if (Trace->ScenarioType >= PfMaxScenarioType) {
        FailedCheckId = 25;
        goto cleanup;
    }

    //
    // Check limits on number of pages, sections etc.
    //

    if (Trace->NumSections > PF_MAXIMUM_SECTIONS ||
        Trace->NumEntries > PF_MAXIMUM_LOG_ENTRIES ||
        Trace->NumVolumes > PF_MAXIMUM_SECTIONS) {
        FailedCheckId = 30;
        goto cleanup;
    }

    //
    // Check buffer size and the size of the trace.
    //

    if (Trace->Size != BufferSize) {
        FailedCheckId = 35;
        goto cleanup;
    }

    //
    // Make sure the scenario id is valid.
    //

    if (!PfVerifyScenarioId(&Trace->ScenarioId)) {
        
        FailedCheckId = 37;
        goto cleanup;
    }

    //
    // Check Bounds of Trace Buffer
    //

    LogEntries = (PPF_LOG_ENTRY) ((PCHAR)Trace + Trace->TraceBufferOffset);

    if (!PfWithinBounds(LogEntries, Trace, BufferSize)) {
        FailedCheckId = 40;
        goto cleanup;
    }

    if (!PfWithinBounds((PCHAR)&LogEntries[Trace->NumEntries] - 1, 
                        Trace, 
                        BufferSize)) {
        FailedCheckId = 50;
        goto cleanup;
    }

    //
    // Verify pages contain valid information.
    //

    for (EntryIdx = 0; EntryIdx < Trace->NumEntries; EntryIdx++) {

        //
        // Make sure sequence number is within bounds.
        //

        if (LogEntries[EntryIdx].SectionId >= Trace->NumSections) {
            FailedCheckId = 60;
            goto cleanup;
        }
    }

    //
    // Verify section info entries are valid.
    //

    Section = (PPF_SECTION_INFO) ((PCHAR)Trace + Trace->SectionInfoOffset);

    for (SectionIdx = 0; SectionIdx < Trace->NumSections; SectionIdx++) {

        //
        // Make sure the section is within bounds.
        //

        if (!PfWithinBounds(Section, Trace, BufferSize)) {
            FailedCheckId = 70;
            goto cleanup;
        }

        //
        // Make sure the file name is not too big.
        //

        if(Section->FileNameLength > PF_MAXIMUM_SECTION_FILE_NAME_LENGTH) {
            FailedCheckId = 80;
            goto cleanup;
        }
        
        //
        // Make sure the file name is NUL terminated.
        //
        
        if (Section->FileName[Section->FileNameLength] != 0) {
            FailedCheckId = 90;
            goto cleanup;
        }

        //
        // Calculate size of this section entry.
        //

        SectionLength = sizeof(PF_SECTION_INFO) +
            (Section->FileNameLength) * sizeof(WCHAR);

        //
        // Make sure all of the data in the section info is within
        // bounds.
        //

        if (!PfWithinBounds((PUCHAR)Section + SectionLength - 1, 
                            Trace, 
                            BufferSize)) {

            FailedCheckId = 100;
            goto cleanup;
        }

        //
        // Set pointer to next section.
        //

        Section = (PPF_SECTION_INFO) ((PUCHAR) Section + SectionLength);
    }

    //
    // Check FaultsPerPeriod information.
    //

    if (!PfWithinBounds((PCHAR)&Trace->FaultsPerPeriod[PF_MAX_NUM_TRACE_PERIODS] - 1,
                        Trace,
                        BufferSize)) {
        FailedCheckId = 110;
        goto cleanup;
    }

    TotalFaults = 0;

    for (PeriodIdx = 0; PeriodIdx < PF_MAX_NUM_TRACE_PERIODS; PeriodIdx++) {
        TotalFaults += Trace->FaultsPerPeriod[PeriodIdx];
    }

    if (TotalFaults > Trace->NumEntries) {
        FailedCheckId = 120;
        goto cleanup;
    }

    //
    // Verify the volume information block.
    //

    VolumeInfo = (PPF_VOLUME_INFO) ((PCHAR)Trace + Trace->VolumeInfoOffset);

    if (!PfWithinBounds(VolumeInfo, Trace, BufferSize)) {
        FailedCheckId = 130;
        goto cleanup;
    }

    if (!PfWithinBounds((PCHAR)VolumeInfo + Trace->VolumeInfoSize - 1, 
                        Trace, 
                        BufferSize)) {
        FailedCheckId = 140;
        goto cleanup;
    }
    
    //
    // If there are sections, we should have at least one volume.
    //

    if (Trace->NumSections && !Trace->NumVolumes) {
        FailedCheckId = 150;
        goto cleanup;
    }

    //
    // Verify the volume info structures per volume.
    //

    for (VolumeIdx = 0; VolumeIdx < Trace->NumVolumes; VolumeIdx++) {
        
        //
        // Make sure the whole volume structure is within bounds. Note
        // that VolumeInfo structure contains space for the
        // terminating NUL.
        //

        VolumeInfoSize = sizeof(PF_VOLUME_INFO);
        VolumeInfoSize += VolumeInfo->VolumePathLength * sizeof(WCHAR);
        
        if (!PfWithinBounds((PCHAR) VolumeInfo + VolumeInfoSize - 1,
                            Trace,
                            BufferSize)) {
            FailedCheckId = 160;
            goto cleanup;
        }
        
        //
        // Verify that the volume path string is terminated.
        //

        if (VolumeInfo->VolumePath[VolumeInfo->VolumePathLength] != 0) {
            FailedCheckId = 170;
            goto cleanup;
        }
        
        //
        // Get the next volume.
        //

        VolumeInfo = (PPF_VOLUME_INFO) ((PCHAR) VolumeInfo + VolumeInfoSize);
        
        //
        // Make sure VolumeInfo is aligned.
        //

        VolumeInfo = PF_ALIGN_UP(VolumeInfo, _alignof(PF_VOLUME_INFO));
    }

    //
    // We've passed all the checks.
    //
    
    TraceVerified = TRUE;
    
 cleanup:

    *FailedCheck = FailedCheckId;

    return TraceVerified;
}
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\base\ntos\cache\prefparm.c ===
/*++

Copyright (c) 1999 Microsoft Corporation

Module Name:

    prefparm.c

Abstract:

    This module contains the code for prefetcher parameter handling.

Author:

    Cenk Ergan (cenke)          15-Mar-2000

Revision History:

--*/

#include "cc.h"
#include "zwapi.h"
#include "prefetch.h"
#include "preftchp.h"
#include "stdio.h"

#ifdef ALLOC_PRAGMA
#pragma alloc_text(INIT, CcPfParametersInitialize)
#pragma alloc_text(INIT, CcPfParametersSetDefaults)
#pragma alloc_text(PAGE, CcPfParametersRead)
#pragma alloc_text(PAGE, CcPfParametersSave)
#pragma alloc_text(PAGE, CcPfParametersVerify)
#pragma alloc_text(PAGE, CcPfParametersWatcher)
#pragma alloc_text(PAGE, CcPfParametersSetChangedEvent)
#pragma alloc_text(PAGE, CcPfGetParameter)
#pragma alloc_text(PAGE, CcPfSetParameter)
#pragma alloc_text(PAGE, CcPfDetermineEnablePrefetcher)
#pragma alloc_text(PAGE, CcPfIsHostingApplication)
#endif // ALLOC_PRAGMA

//
// Globals:
//

extern CCPF_PREFETCHER_GLOBALS CcPfGlobals;

//
// Constants:
//

//
// The following are used as prefixs for the value names for registry
// parameters that are per scenario type.
//

WCHAR *CcPfAppLaunchScenarioTypePrefix = L"AppLaunch";
WCHAR *CcPfBootScenarioTypePrefix = L"Boot";

//
// Routines for prefetcher parameter handling.
//

NTSTATUS
CcPfParametersInitialize (
    PCCPF_PREFETCHER_PARAMETERS PrefetcherParameters
    )

/*++

Routine Description:

    Initializes specified prefetcher parameters structure.

Arguments:

    PrefetcherParameters - Pointer to structure to initialize.

Return Value:

    Status.

Environment:

    Kernel mode. IRQL == PASSIVE_LEVEL.

Notes:

    The code & local constants for this function gets discarded after system boots.   

--*/

{   
    OBJECT_ATTRIBUTES ObjectAttributes;
    UNICODE_STRING KeyName;
    NTSTATUS Status;

    //
    // Zero out the structure. This initializes:
    // ParametersVersion
    //

    RtlZeroMemory(PrefetcherParameters, sizeof(*PrefetcherParameters));

    //
    // Initialize the lock protecting the parameters and parameters
    // version. Each time parameters are updated, the version is
    // bumped.
    //

    ExInitializeResourceLite(&PrefetcherParameters->ParametersLock);
    
    //
    // Initialize the workitem used for registry notifications on the
    // parameters key.
    //

    ExInitializeWorkItem(&PrefetcherParameters->RegistryWatchWorkItem, 
                         CcPfParametersWatcher, 
                         PrefetcherParameters);

    //
    // Set default parameters.
    //

    CcPfParametersSetDefaults(PrefetcherParameters);

    //
    // Create / Open the registry key that contains our parameters.
    //

    RtlInitUnicodeString(&KeyName, CCPF_PARAMETERS_KEY);

    InitializeObjectAttributes(&ObjectAttributes,
                               &KeyName,
                               OBJ_CASE_INSENSITIVE | OBJ_KERNEL_HANDLE,
                               NULL,
                               NULL);

    Status = ZwCreateKey(&PrefetcherParameters->ParametersKey,
                         KEY_ALL_ACCESS,
                         &ObjectAttributes,
                         0,
                         NULL,
                         REG_OPTION_NON_VOLATILE,
                         0);

    if (NT_SUCCESS(Status)) {      

        //
        // Update the default parameters with those in the registry.
        //
    
        Status = CcPfParametersRead(PrefetcherParameters); 
    
        if (!NT_SUCCESS(Status)) {
            DBGPR((CCPFID,PFERR,"CCPF: Init-FailedReadParams=%x\n",Status));
        }

        //
        // Request notification when something changes in the
        // prefetcher parameters key.
        //
    
        Status = ZwNotifyChangeKey(PrefetcherParameters->ParametersKey,
                                   NULL,
                                   (PIO_APC_ROUTINE)&PrefetcherParameters->RegistryWatchWorkItem,
                                   (PVOID)(UINT_PTR)(unsigned int)DelayedWorkQueue,
                                   &PrefetcherParameters->RegistryWatchIosb,
                                   REG_LEGAL_CHANGE_FILTER,
                                   FALSE,
                                   &PrefetcherParameters->RegistryWatchBuffer,
                                   sizeof(PrefetcherParameters->RegistryWatchBuffer),
                                   TRUE);
    
        if (!NT_SUCCESS(Status)) {

            //
            // Although we could not register a notification, this
            // is not a fatal error.
            //

            DBGPR((CCPFID,PFERR,"CCPF: Init-FailedSetParamNotify=%x\n",Status));
        }

    } else {
        DBGPR((CCPFID,PFERR,"CCPF: Init-FailedCreateParamKey=%x\n",Status));
    }

    return Status;
}

VOID
CcPfParametersSetDefaults (
    PCCPF_PREFETCHER_PARAMETERS PrefetcherParameters
    )

/*++

Routine Description:

    Initializes specified parameters structure to default values.

Arguments:

    Parameters - Pointer to structure to initialize.

Return Value:

    None.

Environment:

    Kernel mode. IRQL == PASSIVE_LEVEL.

Notes:

    The code & local constants for this function gets discarded after system boots.   

--*/

{
    PPF_SYSTEM_PREFETCH_PARAMETERS Parameters;
    PPF_TRACE_LIMITS TraceLimits;
    PF_SCENARIO_TYPE ScenarioType;

    //
    // Initialize locals.
    //

    Parameters = &PrefetcherParameters->Parameters;

    for (ScenarioType = 0; ScenarioType < PfMaxScenarioType; ScenarioType++) {

        //
        // PfSvNotSpecified is currently treated as disabled.
        //

        Parameters->EnableStatus[ScenarioType] = PfSvNotSpecified;

        //
        // Trace limits are determined based on scenario type.
        //

        TraceLimits = &Parameters->TraceLimits[ScenarioType];

        switch(ScenarioType) {

        case PfApplicationLaunchScenarioType:

            TraceLimits->MaxNumPages =    4000;
            TraceLimits->MaxNumSections = 170;
            TraceLimits->TimerPeriod =    (-1 * 1000 * 1000 * 10);

            PrefetcherParameters->ScenarioTypePrefixes[ScenarioType] = 
                CcPfAppLaunchScenarioTypePrefix;

            break;

        case PfSystemBootScenarioType:

            TraceLimits->MaxNumPages =    128000;
            TraceLimits->MaxNumSections = 4080;
            TraceLimits->TimerPeriod =    (-1 * 12000 * 1000 * 10);

            PrefetcherParameters->ScenarioTypePrefixes[ScenarioType] = 
                CcPfBootScenarioTypePrefix;

            break;
        
        default:
        
            //
            // We should be handling all scenario types above.
            //

            CCPF_ASSERT(FALSE);

            TraceLimits->MaxNumPages =    PF_MAXIMUM_PAGES;
            TraceLimits->MaxNumSections = PF_MAXIMUM_SECTIONS;
            TraceLimits->TimerPeriod =    (-1 * 1000 * 1000 * 10);

            PrefetcherParameters->ScenarioTypePrefixes[ScenarioType] = L"XXX";
        }
    }

    //
    // These limits ensure that we don't monopolize system resources
    // for prefetching.
    //

    Parameters->MaxNumActiveTraces = 8;
    Parameters->MaxNumSavedTraces = 8;

    //
    // This is the default directory under SystemRoot where we
    // find prefetch instructions for scenarios. During upgrades
    // we remove the contents of this directory, so "Prefetch" is
    // hardcoded in txtsetup.inx.
    //

    wcsncpy(Parameters->RootDirPath, 
            L"Prefetch",
            PF_MAX_PREFETCH_ROOT_PATH);

    Parameters->RootDirPath[PF_MAX_PREFETCH_ROOT_PATH - 1] = 0;

    //
    // This is the default list of known hosting applications.
    //

    wcsncpy(Parameters->HostingApplicationList,
            L"DLLHOST.EXE,MMC.EXE,RUNDLL32.EXE",
            PF_HOSTING_APP_LIST_MAX_CHARS);

    Parameters->HostingApplicationList[PF_HOSTING_APP_LIST_MAX_CHARS - 1] = 0;

    //
    // Make sure the default parameters make sense.
    //

    CCPF_ASSERT(NT_SUCCESS(CcPfParametersVerify(Parameters)));

}

NTSTATUS
CcPfParametersRead (
    PCCPF_PREFETCHER_PARAMETERS PrefetcherParameters
    )

/*++

Routine Description:

    This routine updates the parameters structure with the
    parameters in the registry.

    Keep the value names that are used in sync with the function to
    save the parameters.

Arguments:

    PrefetcherParameters - Pointer to parameters.

Return Value:

    Status.

Environment:

    Kernel mode. IRQL == PASSIVE_LEVEL.

--*/

{
    NTSTATUS Status;
    PF_SYSTEM_PREFETCH_PARAMETERS Parameters;
    PPF_TRACE_LIMITS TraceLimits;
    PF_SCENARIO_TYPE ScenarioType;
    WCHAR ValueName[CCPF_MAX_PARAMETER_NAME_LENGTH];
    WCHAR *ValueNamePrefix;
    HANDLE ParametersKey;
    BOOLEAN EnableStatusSpecified;
    ULONG EnablePrefetcher;
    BOOLEAN AcquiredParametersLock;
    ULONG Length;
    LONG CurrentVersion;
    ULONG RetryCount;
    PKTHREAD CurrentThread;

    //
    // Initialize locals.
    //

    CurrentThread = KeGetCurrentThread ();
    AcquiredParametersLock = FALSE;
    RetryCount = 0;

    DBGPR((CCPFID,PFTRC,"CCPF: ParametersRead()\n"));

    //
    // If we could not initialize the parameters key, we would fail
    // all the following ops miserably.
    //

    if (!PrefetcherParameters->ParametersKey) {
        Status = STATUS_REINITIALIZATION_NEEDED;
        goto cleanup;
    }

    do {

        //
        // Get the parameters lock shared. 
        // 
        
        KeEnterCriticalRegionThread(CurrentThread);
        ExAcquireResourceSharedLite(&PrefetcherParameters->ParametersLock, TRUE);
        AcquiredParametersLock = TRUE;

        ParametersKey = PrefetcherParameters->ParametersKey;

        //
        // Save current version of parameters. Each time parameters gets
        // updated, the version is bumped.
        //
        
        CurrentVersion = PrefetcherParameters->ParametersVersion;

        //
        // Copy over existing parameters to the parameters structure we
        // are building. This way, if we cannot get a value from the
        // registry we'll keep the value we already have.
        //

        Parameters = PrefetcherParameters->Parameters;

        //
        // Read the prefetcher enable value. Depending on whether it is
        // specified and if so its value we will set enable status for
        // prefetch scenario types.
        //

        Length = sizeof(EnablePrefetcher);
        Status = CcPfGetParameter(ParametersKey,
                                  L"EnablePrefetcher",
                                  REG_DWORD,
                                  &EnablePrefetcher,
                                  &Length);

        if (!NT_SUCCESS(Status)) {
        
            //
            // Enable status is not specified or we cannot access it.
            //

            EnableStatusSpecified = FALSE;

        } else {
        
            EnableStatusSpecified = TRUE;
        }

        //
        // Get per scenario parameters.
        //

        for (ScenarioType = 0; ScenarioType < PfMaxScenarioType; ScenarioType++) {

            ValueNamePrefix = PrefetcherParameters->ScenarioTypePrefixes[ScenarioType];

            //
            // Determine enable status. If EnableStatusSpecified, whether
            // prefeching for this scenario type is on or off is
            // determined by the ScenarioType'th bit in EnablePrefetcher.
            //
        
            if (EnableStatusSpecified) {
                if (EnablePrefetcher & (1 << ScenarioType)) {
                    Parameters.EnableStatus[ScenarioType] = PfSvEnabled;
                } else {
                    Parameters.EnableStatus[ScenarioType] = PfSvDisabled;
                }
            } else {
                Parameters.EnableStatus[ScenarioType] = PfSvNotSpecified;
            }

            //
            // Update trace limits for this scenario type. Ignore return
            // value from GetParameter since the value may not be
            // specified in the registry. If so the current value is kept
            // intact.
            //

            TraceLimits = &Parameters.TraceLimits[ScenarioType];
            
            wcscpy(ValueName, ValueNamePrefix);       
            wcscat(ValueName, L"MaxNumPages");
            Length = sizeof(TraceLimits->MaxNumPages);
            CcPfGetParameter(ParametersKey,
                             ValueName,
                             REG_DWORD,
                             &TraceLimits->MaxNumPages,
                             &Length);

            wcscpy(ValueName, ValueNamePrefix);       
            wcscat(ValueName, L"MaxNumSections");
            Length = sizeof(TraceLimits->MaxNumSections);
            CcPfGetParameter(ParametersKey,
                             ValueName,
                             REG_DWORD,
                             &TraceLimits->MaxNumSections,
                             &Length);

            wcscpy(ValueName, ValueNamePrefix);       
            wcscat(ValueName, L"TimerPeriod");
            Length = sizeof(TraceLimits->TimerPeriod);
            CcPfGetParameter(ParametersKey,
                             ValueName,
                             REG_BINARY,
                             &TraceLimits->TimerPeriod,
                             &Length);
        }

        //
        // Update maximum number of active traces. 
        //

        Length = sizeof(Parameters.MaxNumActiveTraces);
        CcPfGetParameter(ParametersKey,
                         L"MaxNumActiveTraces",
                         REG_DWORD,
                         &Parameters.MaxNumActiveTraces,
                         &Length);
    
        //
        // Update maximum number of saved traces. 
        //

        Length = sizeof(Parameters.MaxNumSavedTraces);
        CcPfGetParameter(ParametersKey,
                         L"MaxNumSavedTraces",
                         REG_DWORD,
                         &Parameters.MaxNumSavedTraces,
                         &Length);
    
        //
        // Update the root directory path.
        //
    
        Length = sizeof(Parameters.RootDirPath);
        CcPfGetParameter(ParametersKey,
                         L"RootDirPath",
                         REG_SZ,
                         Parameters.RootDirPath,
                         &Length);

        //
        // Update list of known hosting applications.
        //

        Length = sizeof(Parameters.HostingApplicationList);
        CcPfGetParameter(ParametersKey,
                         L"HostingAppList",
                         REG_SZ,
                         Parameters.HostingApplicationList,
                         &Length);
        
        Parameters.HostingApplicationList[PF_HOSTING_APP_LIST_MAX_CHARS - 1] = 0;
        _wcsupr(Parameters.HostingApplicationList);
         
        //
        // Verify the parameters updated from the registry.
        //

        Status = CcPfParametersVerify(&Parameters);
    
        if (!NT_SUCCESS(Status)) {
            goto cleanup;
        }
        
        //
        // Release the shared lock and acquire it exclusive.
        //

        ExReleaseResourceLite(&PrefetcherParameters->ParametersLock);
        KeLeaveCriticalRegionThread(CurrentThread);

        KeEnterCriticalRegionThread(CurrentThread);
        ExAcquireResourceExclusiveLite(&PrefetcherParameters->ParametersLock, TRUE);
        
        //
        // Check if somebody already updated the parameters before us.
        //
        
        if (CurrentVersion != PrefetcherParameters->ParametersVersion) {

            //
            // Bummer. Somebody updated parameters when we released
            // our shared lock to acquire it exclusive. We have to try
            // again. The default values we used for parameters that
            // were not in the registry may have been changed.
            //

            ExReleaseResourceLite(&PrefetcherParameters->ParametersLock);
            KeLeaveCriticalRegionThread(CurrentThread);
            AcquiredParametersLock = FALSE;

            RetryCount++;
            continue;
        }
        
        //
        // We are updating the parameters, bump the version.
        //

        PrefetcherParameters->ParametersVersion++;
        
        PrefetcherParameters->Parameters = Parameters;

        //
        // Release the exclusive lock and break out.
        //
        
        ExReleaseResourceLite(&PrefetcherParameters->ParametersLock);
        KeLeaveCriticalRegionThread(CurrentThread);
        AcquiredParametersLock = FALSE;
        
        break;

    } while (RetryCount < 10);

    //
    // See if we looped too many times and could not achive updating
    // the parameters.
    //

    if (RetryCount >= 10) {
        Status = STATUS_RETRY;
        goto cleanup;
    }

    //
    // Otherwise we were successful.
    //

    Status = STATUS_SUCCESS;

 cleanup:

    if (AcquiredParametersLock) {
        ExReleaseResourceLite(&PrefetcherParameters->ParametersLock);
        KeLeaveCriticalRegionThread(CurrentThread);
    }

    DBGPR((CCPFID,PFTRC,"CCPF: ParametersRead()=%x\n", Status));

    return Status;
}

NTSTATUS
CcPfParametersSave (
    PCCPF_PREFETCHER_PARAMETERS PrefetcherParameters
    )

/*++

Routine Description:

    This routine updates the registry with the specified prefetch
    parameters.

Arguments:

    PrefetcherParameters - Pointer to parameters structure.

Return Value:

    Status.

Environment:

    Kernel mode. IRQL == PASSIVE_LEVEL.

--*/

{
    NTSTATUS Status;
    PPF_TRACE_LIMITS TraceLimits;
    PF_SCENARIO_TYPE ScenarioType;
    WCHAR ValueName[CCPF_MAX_PARAMETER_NAME_LENGTH];
    WCHAR *ValueNamePrefix;
    HANDLE ParametersKey;
    BOOLEAN EnableStatusSpecified;
    ULONG EnablePrefetcher;
    BOOLEAN AcquiredParametersLock;
    ULONG Length;
    PPF_SYSTEM_PREFETCH_PARAMETERS Parameters;
    PKTHREAD CurrentThread;

    //
    // Initialize locals.
    //

    CurrentThread = KeGetCurrentThread ();
    ParametersKey = PrefetcherParameters->ParametersKey;
    Parameters = &PrefetcherParameters->Parameters;
    AcquiredParametersLock = FALSE;

    DBGPR((CCPFID,PFTRC,"CCPF: ParametersSave()\n"));

    //
    // If we could not initialize the parameters key, we would fail
    // all the following ops miserably.
    //

    if (!PrefetcherParameters->ParametersKey) {
        Status = STATUS_REINITIALIZATION_NEEDED;
        goto cleanup;
    }

    //
    // Get the parameters lock shared. 
    // 
    
    KeEnterCriticalRegionThread(CurrentThread);
    ExAcquireResourceSharedLite(&PrefetcherParameters->ParametersLock, TRUE);
    AcquiredParametersLock = TRUE;

    //
    // Build up the prefetcher enable value.
    //
    
    EnableStatusSpecified = FALSE;
    EnablePrefetcher = 0;

    for (ScenarioType = 0; ScenarioType < PfMaxScenarioType; ScenarioType++) {

        //
        // By default prefetching for all scenario types will be
        // disabled, except it is explicitly enabled.
        //

        if (Parameters->EnableStatus[ScenarioType] == PfSvEnabled) {
            EnablePrefetcher |= (1 << ScenarioType);
        }       
        
        //
        // Even if enable status for one scenario type is specified,
        // we have to save the enable prefetcher key. 
        //

        if (Parameters->EnableStatus[ScenarioType] != PfSvNotSpecified) {
            EnableStatusSpecified = TRUE;
        }
    }

    if (EnableStatusSpecified) {

        //
        // Save the prefetcher enable key.
        //

        Length = sizeof(EnablePrefetcher);

        Status = CcPfSetParameter(ParametersKey,
                                  L"EnablePrefetcher",
                                  REG_DWORD,
                                  &EnablePrefetcher,
                                  Length);

        if (!NT_SUCCESS(Status)) {
            goto cleanup;
        }
    }

    //
    // Save per scenario parameters.
    //

    for (ScenarioType = 0; ScenarioType < PfMaxScenarioType; ScenarioType++) {
        
        ValueNamePrefix = PrefetcherParameters->ScenarioTypePrefixes[ScenarioType];
        
        //
        // Update trace limits for this scenario type.
        //

        TraceLimits = &Parameters->TraceLimits[ScenarioType];
        
        wcscpy(ValueName, ValueNamePrefix);       
        wcscat(ValueName, L"MaxNumPages");
        Length = sizeof(TraceLimits->MaxNumPages);
        Status = CcPfSetParameter(ParametersKey,
                                  ValueName,
                                  REG_DWORD,
                                  &TraceLimits->MaxNumPages,
                                  Length);
        if (!NT_SUCCESS(Status)) {
            goto cleanup;
        }
        
        wcscpy(ValueName, ValueNamePrefix);       
        wcscat(ValueName, L"MaxNumSections");
        Length = sizeof(TraceLimits->MaxNumSections);
        Status = CcPfSetParameter(ParametersKey,
                         ValueName,
                         REG_DWORD,
                         &TraceLimits->MaxNumSections,
                         Length);
        if (!NT_SUCCESS(Status)) {
            goto cleanup;
        }

        wcscpy(ValueName, ValueNamePrefix);       
        wcscat(ValueName, L"TimerPeriod");
        Length = sizeof(TraceLimits->TimerPeriod);
        Status = CcPfSetParameter(ParametersKey,
                                  ValueName,
                                  REG_BINARY,
                                  &TraceLimits->TimerPeriod,
                                  Length);
        if (!NT_SUCCESS(Status)) {
            goto cleanup;
        }
    }
    
    //
    // Update maximum number of active traces. 
    //
    
    Length = sizeof(Parameters->MaxNumActiveTraces);
    Status = CcPfSetParameter(ParametersKey,
                              L"MaxNumActiveTraces",
                              REG_DWORD,
                              &Parameters->MaxNumActiveTraces,
                              Length);
    if (!NT_SUCCESS(Status)) {
        goto cleanup;
    }
    
    //
    // Update maximum number of saved traces. 
    //

    Length = sizeof(Parameters->MaxNumSavedTraces);
    Status = CcPfSetParameter(ParametersKey,
                              L"MaxNumSavedTraces",
                              REG_DWORD,
                              &Parameters->MaxNumSavedTraces,
                              Length);
    if (!NT_SUCCESS(Status)) {
        goto cleanup;
    }

    //
    // Update the root directory path.
    //
    
    Length = (wcslen(Parameters->RootDirPath) + 1) * sizeof(WCHAR);
    Status = CcPfSetParameter(ParametersKey,
                              L"RootDirPath",
                              REG_SZ,
                              Parameters->RootDirPath,
                              Length);
    if (!NT_SUCCESS(Status)) {
        goto cleanup;
    }

    //
    // Update the hosting application list path.
    //
    
    Length = (wcslen(Parameters->HostingApplicationList) + 1) * sizeof(WCHAR);
    Status = CcPfSetParameter(ParametersKey,
                              L"HostingAppList",
                              REG_SZ,
                              Parameters->HostingApplicationList,
                              Length);
    if (!NT_SUCCESS(Status)) {
        goto cleanup;
    }

    Status = STATUS_SUCCESS;

 cleanup:

    if (AcquiredParametersLock) {
        ExReleaseResourceLite(&PrefetcherParameters->ParametersLock);
        KeLeaveCriticalRegionThread(CurrentThread);
    }
    
    DBGPR((CCPFID,PFTRC,"CCPF: ParametersSave()=%x\n", Status));

    return Status;
}

NTSTATUS
CcPfParametersVerify (
    PPF_SYSTEM_PREFETCH_PARAMETERS Parameters
    )

/*++

Routine Description:

    This routine verifies that the specified parameters structure is
    valid and within sanity limits.

Arguments:

    Parameters - Pointer to parameters structure.

Return Value:

    Status.

Environment:

    Kernel mode. IRQL == PASSIVE_LEVEL.

--*/

{
    NTSTATUS Status;
    ULONG FailedCheckId;
    ULONG CharIdx;
    BOOLEAN FoundNUL;
    PF_SCENARIO_TYPE ScenarioType;
    PPF_TRACE_LIMITS TraceLimits;

    //
    // Initialize locals.
    //

    Status = STATUS_INVALID_PARAMETER;
    FailedCheckId = 0;

    DBGPR((CCPFID,PFTRC,"CCPF: ParametersVerify\n"));

    //
    // Make sure RootDirPath is NUL terminated.
    //
    
    FoundNUL = FALSE;

    for (CharIdx = 0; CharIdx < PF_MAX_PREFETCH_ROOT_PATH; CharIdx++) {
        if (Parameters->RootDirPath[CharIdx] == 0) {
            FoundNUL = TRUE;
            break;
        }
    }

    if (FoundNUL == FALSE) {
        FailedCheckId = 10;
        goto cleanup;
    }

    //
    // Make sure HostingApplicationList is NUL terminated.
    //

    FoundNUL = FALSE;

    for (CharIdx = 0; CharIdx < PF_HOSTING_APP_LIST_MAX_CHARS; CharIdx++) {
        if (Parameters->HostingApplicationList[CharIdx] == 0) {
            FoundNUL = TRUE;
            break;
        }
    }

    if (FoundNUL == FALSE) {
        FailedCheckId = 15;
        goto cleanup;
    }

    //
    // Make sure all per scenario type parameters types are within
    // sanity limits.
    //

    for (ScenarioType = 0; ScenarioType < PfMaxScenarioType; ScenarioType++) {

        if (Parameters->EnableStatus[ScenarioType] >= PfSvMaxEnableStatus) {
            FailedCheckId = 20;
            goto cleanup;
        }

        //
        // Check trace limits.
        //
        
        TraceLimits = &Parameters->TraceLimits[ScenarioType];
        
        if (TraceLimits->MaxNumPages > PF_MAXIMUM_PAGES) {
            FailedCheckId = 30;
            goto cleanup;
        }
        
        if (TraceLimits->MaxNumSections > PF_MAXIMUM_SECTIONS) {
            FailedCheckId = 40;
            goto cleanup;
        }

        if ((TraceLimits->TimerPeriod < PF_MAXIMUM_TIMER_PERIOD) ||
            (TraceLimits->TimerPeriod >= 0)) {
            FailedCheckId = 50;
            goto cleanup;
        }
    }

    //
    // Check limits on active/saved traces.
    //

    if (Parameters->MaxNumActiveTraces > PF_MAXIMUM_ACTIVE_TRACES) {
        FailedCheckId = 60;
        goto cleanup;
    }

    if (Parameters->MaxNumSavedTraces > PF_MAXIMUM_SAVED_TRACES) {
        FailedCheckId = 70;
        goto cleanup;
    }

    //
    // We passed all the checks.
    //

    Status = STATUS_SUCCESS;

 cleanup:

    DBGPR((CCPFID,PFTRC,"CCPF: ParametersVerify()=%x,%d\n", Status, FailedCheckId));

    return Status;
}

VOID
CcPfParametersWatcher(
    IN PCCPF_PREFETCHER_PARAMETERS PrefetcherParameters
    )

/*++

Routine Description:

    This routine gets called when our parameters in the registry change.

Arguments:

    PrefetcherParameters - Pointer to parameters structure.

Return Value:

    None.

Environment:

    Kernel mode. IRQL == PASSIVE_LEVEL.

--*/

{
    NTSTATUS Status;
    UNICODE_STRING KeyName;
    OBJECT_ATTRIBUTES ObjectAttributes;
    HANDLE ParametersKey;
    PKTHREAD CurrentThread;
    HANDLE TempHandle;

    DBGPR((CCPFID,PFTRC,"CCPF: ParametersWatcher()\n"));

    //
    // In order to have setup a registry watch, we should have
    // initialized the parameters key successfully.
    //

    CCPF_ASSERT(PrefetcherParameters->ParametersKey);

    //
    // Our change notify triggered. Request further notification. But
    // first wait until we can get the parameters lock exclusive, so
    // while we are saving parameters to the registry we don't kick
    // off a notification for each key.
    //

    CurrentThread = KeGetCurrentThread ();
    KeEnterCriticalRegionThread(CurrentThread);
    ExAcquireResourceExclusiveLite(&PrefetcherParameters->ParametersLock, TRUE);
    ExReleaseResourceLite(&PrefetcherParameters->ParametersLock);
    KeLeaveCriticalRegionThread(CurrentThread);

    Status = ZwNotifyChangeKey(PrefetcherParameters->ParametersKey,
                               NULL,
                               (PIO_APC_ROUTINE)&PrefetcherParameters->RegistryWatchWorkItem,
                               (PVOID)(UINT_PTR)(unsigned int)DelayedWorkQueue,
                               &PrefetcherParameters->RegistryWatchIosb,
                               REG_LEGAL_CHANGE_FILTER,
                               FALSE,
                               &PrefetcherParameters->RegistryWatchBuffer,
                               sizeof(PrefetcherParameters->RegistryWatchBuffer),
                               TRUE);

    if (!NT_SUCCESS(Status)) {

        //
        // Somebody may have deleted the key. We have to recreate it then.
        //

        if (Status == STATUS_KEY_DELETED) {

            RtlInitUnicodeString(&KeyName, CCPF_PARAMETERS_KEY);
            
            InitializeObjectAttributes(&ObjectAttributes,
                                       &KeyName,
                                       OBJ_CASE_INSENSITIVE | OBJ_KERNEL_HANDLE,
                                       NULL,
                                       NULL);
            
            Status = ZwCreateKey(&ParametersKey,
                                 KEY_ALL_ACCESS,
                                 &ObjectAttributes,
                                 0,
                                 NULL,
                                 REG_OPTION_NON_VOLATILE,
                                 0);

            if (!NT_SUCCESS(Status)) {
                DBGPR((CCPFID,PFERR,"CCPF: ParametersWatcher-FailedRecreate=%x\n",Status));
                return;
            }

            //
            // Update global key handle.
            //

            KeEnterCriticalRegionThread(CurrentThread);
            ExAcquireResourceExclusiveLite(&PrefetcherParameters->ParametersLock, TRUE);

            TempHandle = PrefetcherParameters->ParametersKey;
            PrefetcherParameters->ParametersKey = ParametersKey;
            
            ExReleaseResourceLite(&PrefetcherParameters->ParametersLock);
            KeLeaveCriticalRegionThread(CurrentThread);

            ZwClose(TempHandle);

            //
            // Retry setting a notification again.
            //

            Status = ZwNotifyChangeKey(PrefetcherParameters->ParametersKey,
                                       NULL,
                                       (PIO_APC_ROUTINE)&PrefetcherParameters->RegistryWatchWorkItem,
                                       (PVOID)(UINT_PTR)(unsigned int)DelayedWorkQueue,
                                       &PrefetcherParameters->RegistryWatchIosb,
                                       REG_LEGAL_CHANGE_FILTER,
                                       FALSE,
                                       &PrefetcherParameters->RegistryWatchBuffer,
                                       sizeof(PrefetcherParameters->RegistryWatchBuffer),
                                       TRUE);

            if (!NT_SUCCESS(Status)) {
                DBGPR((CCPFID,PFERR,"CCPF: ParametersWatcher-FailedReSetNotify=%x\n",Status));
                return;
            }

        } else {
            DBGPR((CCPFID,PFERR,"CCPF: ParametersWatcher-FailedSetNotify=%x\n",Status));
            return;
        }
    }

    //
    // Update the global parameters.
    //

    Status = CcPfParametersRead(PrefetcherParameters);

    if (NT_SUCCESS(Status)) {

        //
        // Determine if prefetching is enabled.
        //
        
        CcPfDetermineEnablePrefetcher();
        
        //
        // Set the event so the service queries for the latest parameters.
        //
        
        CcPfParametersSetChangedEvent(PrefetcherParameters);
    }

    return;
}

NTSTATUS
CcPfParametersSetChangedEvent(
    PCCPF_PREFETCHER_PARAMETERS PrefetcherParameters
    )

/*++

Routine Description:

    This routine tries to open and set the event that tells the
    service system prefetch parameters have changed.

Arguments:

    None.

Return Value:

    Status.

Environment:

    Kernel mode. IRQL == PASSIVE_LEVEL.

--*/

{
    NTSTATUS Status;
    UNICODE_STRING EventName;
    OBJECT_ATTRIBUTES EventObjAttr;
    HANDLE EventHandle;
    PKTHREAD CurrentThread;

    DBGPR((CCPFID,PFTRC,"CCPF: ParametersSetChangedEvent()\n"));

    //
    // If we have already opened the event, just signal it.
    //

    if (PrefetcherParameters->ParametersChangedEvent) {

        ZwSetEvent(PrefetcherParameters->ParametersChangedEvent, NULL);

        Status = STATUS_SUCCESS;

    } else {

        //
        // Try to open the event. We don't open this at initialization
        // because our service may not have started to create this
        // event yet. If csrss.exe has not initialized, we may not
        // even have the BaseNamedObjects object directory created, in
        // which Win32 events reside.
        //

        RtlInitUnicodeString(&EventName, PF_PARAMETERS_CHANGED_EVENT_NAME);

        InitializeObjectAttributes(&EventObjAttr,
                                   &EventName,
                                   OBJ_CASE_INSENSITIVE | OBJ_KERNEL_HANDLE,
                                   NULL,
                                   NULL);
        
        Status = ZwOpenEvent(&EventHandle,
                             EVENT_ALL_ACCESS,
                             &EventObjAttr);
        
        if (NT_SUCCESS(Status)) {

            //
            // Acquire the lock and set the global handle.
            //
            CurrentThread = KeGetCurrentThread ();

            KeEnterCriticalRegionThread(CurrentThread);
            ExAcquireResourceExclusiveLite(&PrefetcherParameters->ParametersLock, TRUE);

            if (!PrefetcherParameters->ParametersChangedEvent) {

                //
                // Set the global handle.
                //

                PrefetcherParameters->ParametersChangedEvent = EventHandle;
                CCPF_ASSERT(EventHandle);

                EventHandle = NULL;
            }

            ExReleaseResourceLite(&PrefetcherParameters->ParametersLock);
            KeLeaveCriticalRegionThread(CurrentThread);

            if (EventHandle != NULL) {
                //
                // Somebody already initialized the global handle
                // before us. Close our handle and use the one they
                // initialized.
                //

                ZwClose(EventHandle);
            }

            
            //
            // We have an event now. Signal it.
            //
            
            ZwSetEvent(PrefetcherParameters->ParametersChangedEvent, NULL);
        }
    }

    DBGPR((CCPFID,PFTRC,"CCPF: ParametersSetChangedEvent()=%x\n", Status));
 
    return Status;
}
                 
NTSTATUS
CcPfGetParameter (
    HANDLE ParametersKey,
    WCHAR *ValueNameBuffer,
    ULONG ValueType,
    PVOID Value,
    ULONG *ValueSize
    )

/*++

Routine Description:

    This routine queries a value under the specified registry into the
    specified buffer. Contents of Value and ValueSize are not changed
    if returning failure.

Arguments:

    ParametersKey - Handle to key to query value under.

    ValueNameBuffer - Name of the value.
    
    ValueType - What the type of that value should be. (e.g. REG_DWORD).

    Value - Queried value data gets put here.

    ValueSize - Size of Value buffer in bytes. On successful return
      this is set to number of bytes copied into Value.

Return Value:

    Status.

Environment:

    Kernel mode. IRQL == PASSIVE_LEVEL.

--*/

{
    UNICODE_STRING ValueName;    
    CHAR Buffer[CCPF_MAX_PARAMETER_VALUE_BUFFER];
    PKEY_VALUE_PARTIAL_INFORMATION ValueBuffer;
    ULONG Length;
    NTSTATUS Status;

    //
    // Initialize locals.
    //

    ValueBuffer = (PKEY_VALUE_PARTIAL_INFORMATION) Buffer;
    Length = CCPF_MAX_PARAMETER_VALUE_BUFFER;
    RtlInitUnicodeString(&ValueName, ValueNameBuffer);

    DBGPR((CCPFID,PFTRC,"CCPF: GetParameter(%ws,%x)\n", ValueNameBuffer, ValueType));

    //
    // Query value.
    //

    Status = ZwQueryValueKey(ParametersKey,
                             &ValueName,
                             KeyValuePartialInformation,
                             ValueBuffer,
                             Length,
                             &Length);
    
    if (!NT_SUCCESS(Status)) {
        goto cleanup;
    }

    //
    // Make sure ZwQueryValue returns valid information.
    //
    
    if (Length < sizeof(KEY_VALUE_PARTIAL_INFORMATION)) {
        CCPF_ASSERT(Length >= sizeof(KEY_VALUE_PARTIAL_INFORMATION));
        Status = STATUS_UNSUCCESSFUL;
        goto cleanup;
    }
    
    //
    // Check value type.
    //

    if (ValueBuffer->Type != ValueType) {
        Status = STATUS_OBJECT_TYPE_MISMATCH;
        goto cleanup;
    }

    //
    // Check if data will fit into the buffer caller passed in.
    //

    if (ValueBuffer->DataLength > *ValueSize) {
        Status = STATUS_BUFFER_TOO_SMALL;
        goto cleanup;
    }

    //
    // Copy data into user's buffer.
    //

    RtlCopyMemory(Value, ValueBuffer->Data, ValueBuffer->DataLength);

    //
    // Set copied number of bytes.
    //

    *ValueSize = ValueBuffer->DataLength;

    Status = STATUS_SUCCESS;

 cleanup:

    DBGPR((CCPFID,PFTRC,"CCPF: GetParameter(%ws)=%x\n", ValueNameBuffer, Status));

    return Status;
}  
                 
NTSTATUS
CcPfSetParameter (
    HANDLE ParametersKey,
    WCHAR *ValueNameBuffer,
    ULONG ValueType,
    PVOID Value,
    ULONG ValueSize
    )

/*++

Routine Description:

    This routine sets a parameter under the specified registry.

Arguments:

    ParametersKey - Handle to key to query value under.

    ValueNameBuffer - Name of the value.
    
    ValueType - What the type of that value should be. (e.g. REG_DWORD).

    Value - Data to save.

    ValueSize - Size of Value buffer in bytes.

Return Value:

    Status.

Environment:

    Kernel mode. IRQL == PASSIVE_LEVEL.

--*/

{
    UNICODE_STRING ValueName;    
    NTSTATUS Status;

    //
    // Initialize locals.
    //

    RtlInitUnicodeString(&ValueName, ValueNameBuffer);

    DBGPR((CCPFID,PFTRC,"CCPF: SetParameter(%ws,%x)\n", ValueNameBuffer, ValueType));

    //
    // Save the value.
    //

    Status = ZwSetValueKey(ParametersKey,
                           &ValueName,
                           0,
                           ValueType,
                           Value,
                           ValueSize);
    
    //
    // Return the status.
    //

    DBGPR((CCPFID,PFTRC,"CCPF: SetParameter(%ws)=%x\n", ValueNameBuffer, Status));

    return Status;
}  

LOGICAL
CcPfDetermineEnablePrefetcher(
    VOID
    )

/*++

Routine Description:

    This routine sets the global CcPfEnablePrefetcher based on the
    EnableStatus'es for all scenario types in global parameters as
    well as other factors, such as whether we have booted safe mode.

    Note: Acquires Parameters lock exclusive.

Arguments:

    None.

Return Value:

    New value of CcPfEnablePrefetcher.

Environment:

    Kernel mode. IRQL == PASSIVE_LEVEL.

--*/

{
    PF_SCENARIO_TYPE ScenarioType;
    LOGICAL EnablePrefetcher;
    PKTHREAD CurrentThread;
    BOOLEAN IgnoreBootScenarioType;
    PCCPF_PREFETCHER_PARAMETERS PrefetcherParameters;

    extern PF_BOOT_PHASE_ID CcPfBootPhase;

    //
    // Initialize locals.
    //

    EnablePrefetcher = FALSE;
    PrefetcherParameters = &CcPfGlobals.Parameters;
    CurrentThread = KeGetCurrentThread ();

    //
    // Ignore whether prefetching is enabled for boot, if we've
    // already past the point in boot where this matters.
    //
    
    IgnoreBootScenarioType = (CcPfBootPhase >= PfSessionManagerInitPhase) ? TRUE : FALSE;

    KeEnterCriticalRegionThread(CurrentThread);
    ExAcquireResourceExclusiveLite(&PrefetcherParameters->ParametersLock, TRUE);

    //
    // If we have booted to safe mode, the prefetcher will be disabled.
    //

    if (InitSafeBootMode) {

        EnablePrefetcher = FALSE;

    } else {
        
        //
        // By default prefetching is disabled. If prefetching is
        // enabled for any scenario type, then the prefetcher is
        // enabled.
        //
    
        for (ScenarioType = 0; ScenarioType < PfMaxScenarioType; ScenarioType++) {
            
            //
            // Skip enable status for the boot scenario if requested.
            //
            
            if (IgnoreBootScenarioType) {
                if (ScenarioType == PfSystemBootScenarioType) {
                    continue;
                }
            }
            
            if (PrefetcherParameters->Parameters.EnableStatus[ScenarioType] == PfSvEnabled) {
                EnablePrefetcher = TRUE;
                break;
            }
        }
    }

    //
    // Update global enable status.
    //

    CcPfEnablePrefetcher = EnablePrefetcher;

    ExReleaseResourceLite(&PrefetcherParameters->ParametersLock);
    KeLeaveCriticalRegionThread(CurrentThread);

    return CcPfEnablePrefetcher;
}

BOOLEAN
CcPfIsHostingApplication(
    IN PWCHAR ExecutableName
    )

/*++

Routine Description:

    This routine determines whether the specified executable is in the
    list of known hosting applications, e.g. rundll32, dllhost etc.

Arguments:

    ExecutableName - NUL terminated UPCASED executable name, e.g. "MMC.EXE"

Return Value:

    TRUE - Executable is for a known hosting application.

    FALSE - It is not.

Environment:

    Kernel mode. IRQL == PASSIVE_LEVEL.

--*/

{
    PCCPF_PREFETCHER_PARAMETERS PrefetcherParameters;
    PKTHREAD CurrentThread;
    PWCHAR CurrentPosition;
    PWCHAR ListStart;
    PWCHAR ListEnd;
    ULONG ExecutableNameLength;
    BOOLEAN FoundInList;
    
    //
    // Initialize locals.
    //

    PrefetcherParameters = &CcPfGlobals.Parameters;
    CurrentThread = KeGetCurrentThread();
    ExecutableNameLength = wcslen(ExecutableName);
    FoundInList = FALSE;

    //
    // Get the parameters lock for read.
    //

    KeEnterCriticalRegionThread(CurrentThread);
    ExAcquireResourceSharedLite(&PrefetcherParameters->ParametersLock, TRUE);

    //
    // Search for executable in hosting application list.
    //

    ListStart = PrefetcherParameters->Parameters.HostingApplicationList;
    ListEnd = ListStart + wcslen(PrefetcherParameters->Parameters.HostingApplicationList);

    for (CurrentPosition = wcsstr(ListStart, ExecutableName);
         CurrentPosition != NULL;
         CurrentPosition = wcsstr(CurrentPosition + 1, ExecutableName)) {

        //
        // We should not go beyond the limits.
        //

        if (CurrentPosition < ListStart || CurrentPosition >= ListEnd) {
            CCPF_ASSERT(CurrentPosition >= ListStart);
            CCPF_ASSERT(CurrentPosition < ListEnd);
            break;
        }

        //
        // It should be the first item in the list or be preceded by a comma.
        //

        if (CurrentPosition != ListStart && *(CurrentPosition - 1) != L',') {
            continue;
        }

        //
        // It should be the last item in the list or be followed by a comma.
        //

        if (CurrentPosition + ExecutableNameLength != ListEnd &&
            CurrentPosition[ExecutableNameLength] != L',') {
            continue;
        }

        //
        // We found it in the list.
        //

        FoundInList = TRUE;
        break;

    }

    //
    // Release the parameters lock.
    //

    ExReleaseResourceLite(&PrefetcherParameters->ParametersLock);
    KeLeaveCriticalRegionThread(CurrentThread);

    //
    // Return whether the executable was found in the list.
    //

    return FoundInList;    
}
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\base\ntos\config\cmapi.c ===
/*++

Copyright (c) 1991  Microsoft Corporation

Module Name:

    cmapi.c

Abstract:

    This module contains CM level entry points for the registry.

Author:

    Bryan M. Willman (bryanwi) 30-Aug-1991

Revision History:

--*/

#include "cmp.h"



extern  BOOLEAN     CmpNoWrite;

extern  LIST_ENTRY  CmpHiveListHead;

extern  BOOLEAN CmpProfileLoaded;
extern  BOOLEAN CmpWasSetupBoot;

extern  UNICODE_STRING CmSymbolicLinkValueName;

extern ULONG   CmpGlobalQuotaAllowed;
extern ULONG   CmpGlobalQuotaWarning;
extern PCMHIVE CmpMasterHive;
extern HIVE_LIST_ENTRY CmpMachineHiveList[];

VOID
CmpDereferenceNameControlBlockWithLock(
    PCM_NAME_CONTROL_BLOCK   Ncb
    );

//
// procedures private to this file
//
NTSTATUS
CmpSetValueKeyExisting(
    IN PHHIVE  Hive,
    IN HCELL_INDEX OldChild,
    IN PCM_KEY_VALUE Value,
    IN ULONG Type,
    IN PVOID Data,
    IN ULONG DataSize,
    IN ULONG StorageType,
    IN ULONG TempData
    );


NTSTATUS
CmpSetValueKeyNew(
    IN PHHIVE  Hive,
    IN PCM_KEY_NODE Parent,
    IN PUNICODE_STRING ValueName,
    IN ULONG Index,
    IN ULONG Type,
    IN PVOID Data,
    IN ULONG DataSize,
    IN ULONG StorageType,
    IN ULONG TempData
    );

VOID
CmpRemoveKeyHash(
    IN PCM_KEY_HASH KeyHash
    );

PCM_KEY_CONTROL_BLOCK
CmpInsertKeyHash(
    IN PCM_KEY_HASH KeyHash,
    IN BOOLEAN      FakeKey
    );

#if DBG
ULONG
CmpUnloadKeyWorker(
    PCM_KEY_CONTROL_BLOCK Current,
    PVOID                 Context1,
    PVOID                 Context2
    );
#endif

ULONG
CmpCompressKeyWorker(
    PCM_KEY_CONTROL_BLOCK Current,
    PVOID                 Context1,
    PVOID                 Context2
    );

NTSTATUS
CmpDuplicateKey(
    PHHIVE          Hive,
    HCELL_INDEX     OldKeyCell,
    PHCELL_INDEX    NewKeyCell
    );


VOID
CmpDestroyTemporaryHive(
    PCMHIVE CmHive
    );

BOOLEAN
CmpCompareNewValueDataAgainstKCBCache(  PCM_KEY_CONTROL_BLOCK KeyControlBlock,
                                        PUNICODE_STRING ValueName,
                                        ULONG Type,
                                        PVOID Data,
                                        ULONG DataSize
                                        );
BOOLEAN
CmpGetValueDataFromCache(
    IN PHHIVE               Hive,
    IN PPCM_CACHED_VALUE    ContainingList,
    IN PCELL_DATA           ValueKey,
    IN BOOLEAN              ValueCached,
    OUT PUCHAR              *DataPointer,
    OUT PBOOLEAN            Allocated,
    OUT PHCELL_INDEX        CellToRelease
);

BOOLEAN
CmpCompareNewValueDataAgainstKCBCache(  PCM_KEY_CONTROL_BLOCK KeyControlBlock,
                                        PUNICODE_STRING ValueName,
                                        ULONG Type,
                                        PVOID Data,
                                        ULONG DataSize
                                        );
BOOLEAN
CmpGetValueDataFromCache(
    IN PHHIVE               Hive,
    IN PPCM_CACHED_VALUE    ContainingList,
    IN PCELL_DATA           ValueKey,
    IN BOOLEAN              ValueCached,
    OUT PUCHAR              *DataPointer,
    OUT PBOOLEAN            Allocated,
    OUT PHCELL_INDEX        CellToRelease
);

BOOLEAN
CmpIsHiveAlreadyLoaded( IN HANDLE KeyHandle,
                        IN POBJECT_ATTRIBUTES SourceFile
                        );

NTSTATUS
static
__forceinline
CmpCheckReplaceHive(    IN PHHIVE           Hive,
                        OUT PHCELL_INDEX    Key
                    );


#ifdef ALLOC_PRAGMA
#pragma alloc_text(PAGE,CmDeleteValueKey)
#pragma alloc_text(PAGE,CmEnumerateKey)
#pragma alloc_text(PAGE,CmEnumerateValueKey)
#pragma alloc_text(PAGE,CmFlushKey)
#pragma alloc_text(PAGE,CmQueryKey)
#pragma alloc_text(PAGE,CmQueryValueKey)
#pragma alloc_text(PAGE,CmQueryMultipleValueKey)
#pragma alloc_text(PAGE,CmSetValueKey)
#pragma alloc_text(PAGE,CmpSetValueKeyExisting)
#pragma alloc_text(PAGE,CmpSetValueKeyNew)
#pragma alloc_text(PAGE,CmSetLastWriteTimeKey)
#pragma alloc_text(PAGE,CmSetKeyUserFlags)
#pragma alloc_text(PAGE,CmLoadKey)
#pragma alloc_text(PAGE,CmUnloadKey)

#ifdef NT_UNLOAD_KEY_EX
#pragma alloc_text(PAGE,CmUnloadKeyEx)
#endif //NT_UNLOAD_KEY_EX

#pragma alloc_text(PAGE,CmpDoFlushAll)
#pragma alloc_text(PAGE,CmReplaceKey)

#ifdef WRITE_PROTECTED_REGISTRY_POOL
#pragma alloc_text(PAGE,CmpMarkAllBinsReadOnly)
#endif //WRITE_PROTECTED_REGISTRY_POOL

#ifdef NT_RENAME_KEY
#pragma alloc_text(PAGE,CmRenameKey)
#endif //NT_RENAME_KEY

#pragma alloc_text(PAGE,CmLockKcbForWrite)

#if DBG
#pragma alloc_text(PAGE,CmpUnloadKeyWorker)
#endif

#pragma alloc_text(PAGE,CmMoveKey)
#pragma alloc_text(PAGE,CmpDuplicateKey)
#pragma alloc_text(PAGE,CmCompressKey)
#pragma alloc_text(PAGE,CmpCompressKeyWorker)
#pragma alloc_text(PAGE,CmpCompareNewValueDataAgainstKCBCache)
#pragma alloc_text(PAGE,CmpIsHiveAlreadyLoaded)
#pragma alloc_text(PAGE,CmpCheckReplaceHive)
#endif

NTSTATUS
CmDeleteValueKey(
    IN PCM_KEY_CONTROL_BLOCK    KeyControlBlock,
    IN UNICODE_STRING           ValueName         // RAW
    )
/*++

Routine Description:

    One of the value entries of a registry key may be removed with this call.

    The value entry with ValueName matching ValueName is removed from the key.
    If no such entry exists, an error is returned.

Arguments:

    KeyControlBlock - pointer to kcb for key to operate on

    ValueName - The name of the value to be deleted.  NULL is a legal name.

Return Value:

    NTSTATUS - Result code from call, among the following:

        <TBS>

--*/
{
    NTSTATUS        status;
    PCM_KEY_NODE    pcell = NULL;
    PCHILD_LIST     plist;
    PCM_KEY_VALUE   Value = NULL;
    ULONG           targetindex;
    HCELL_INDEX     ChildCell;
    PHHIVE          Hive;
    HCELL_INDEX     Cell;
    ULONG           realsize;
    LARGE_INTEGER   systemtime;

    CmKdPrintEx((DPFLTR_CONFIG_ID,CML_CM,"CmDeleteValueKey\n"));

    CmpLockRegistryExclusive();

#ifdef CHECK_REGISTRY_USECOUNT
    CmpCheckRegistryUseCount();
#endif //CHECK_REGISTRY_USECOUNT

    PERFINFO_REG_DELETE_VALUE(KeyControlBlock, &ValueName);

    try {
        //
        // no edits, not even this one, on keys marked for deletion
        //
        if (KeyControlBlock->Delete) {
            return STATUS_KEY_DELETED;
        }

        Hive = KeyControlBlock->KeyHive;
        Cell = KeyControlBlock->KeyCell;

        pcell = (PCM_KEY_NODE)HvGetCell(Hive, Cell);
        if( pcell == NULL ) {
            //
            // we couldn't map a view for the bin containing this cell
            //
            return STATUS_INSUFFICIENT_RESOURCES;
        }

        // Mark the hive as read only
        CmpMarkAllBinsReadOnly(Hive);

        status = STATUS_OBJECT_NAME_NOT_FOUND;

        plist = &(pcell->ValueList);
        ChildCell = HCELL_NIL;

        if (plist->Count != 0) {

            //
            // The parent has at least one value, map in the list of
            // values and call CmpFindChildInList
            //

            //
            // plist -> the CHILD_LIST structure
            // pchild -> the child node structure being examined
            //

            if( CmpFindNameInList(Hive,
                                  plist,
                                  &ValueName,
                                  &targetindex,
                                  &ChildCell) == FALSE ) {
            
                    // Mark the hive as read only
                    CmpMarkAllBinsReadOnly(Hive);

                    return STATUS_INSUFFICIENT_RESOURCES;
            }

            if (ChildCell != HCELL_NIL) {

                //
                // 1. the desired target was found
                // 2. ChildCell is it's HCELL_INDEX
                // 3. targetaddress points to it
                // 4. targetindex is it's index
                //

                //
                // attempt to mark all relevent cells dirty
                //
                if (!(HvMarkCellDirty(Hive, Cell) &&
                      HvMarkCellDirty(Hive, pcell->ValueList.List) &&
                      HvMarkCellDirty(Hive, ChildCell)))

                {
                    // Mark the hive as read only
                    CmpMarkAllBinsReadOnly(Hive);

                    return STATUS_NO_LOG_SPACE;
                }

                Value = (PCM_KEY_VALUE)HvGetCell(Hive,ChildCell);
                if( Value == NULL ) {
                    //
                    // could not map view inside
                    // this is impossible as we just dirtied the view
                    //
                    ASSERT( FALSE );
                    // Mark the hive as read only
                    CmpMarkAllBinsReadOnly(Hive);

                    return STATUS_INSUFFICIENT_RESOURCES;
                }
                if( !CmpMarkValueDataDirty(Hive,Value) ) {
                    // Mark the hive as read only
                    CmpMarkAllBinsReadOnly(Hive);

                    return(STATUS_NO_LOG_SPACE);
                }

                // sanity
                ASSERT_CELL_DIRTY(Hive,pcell->ValueList.List);
                ASSERT_CELL_DIRTY(Hive,ChildCell);

                if( !NT_SUCCESS(CmpRemoveValueFromList(Hive,targetindex,plist)) ) {
                    //
                    // bail out !
                    //
                    return STATUS_INSUFFICIENT_RESOURCES;
                }
                if( CmpFreeValue(Hive, ChildCell) == FALSE ) {
                    //
                    // we couldn't map a view inside above call
                    //
                    return STATUS_INSUFFICIENT_RESOURCES;
                }

                KeQuerySystemTime(&systemtime);
                pcell->LastWriteTime = systemtime;
                // cache it in the kcb too.
                KeyControlBlock->KcbLastWriteTime = systemtime;
                
                // some sanity asserts
                ASSERT( pcell->MaxValueNameLen == KeyControlBlock->KcbMaxValueNameLen );
                ASSERT( pcell->MaxValueDataLen == KeyControlBlock->KcbMaxValueDataLen );
                ASSERT_CELL_DIRTY(Hive,Cell);

                if (pcell->ValueList.Count == 0) {
                    pcell->MaxValueNameLen = 0;
                    pcell->MaxValueDataLen = 0;
                    // update the kcb cache too
                    KeyControlBlock->KcbMaxValueNameLen = 0;
                    KeyControlBlock->KcbMaxValueDataLen = 0;
                }

                //
                // We are changing the KCB cache. Since the registry is locked exclusively,
                // we do not need a KCB lock.
                //
                ASSERT_CM_LOCK_OWNED_EXCLUSIVE();

                //
                // Invalidate and rebuild the cache
                //
                CmpCleanUpKcbValueCache(KeyControlBlock);
                CmpSetUpKcbValueCache(KeyControlBlock,plist->Count,plist->List);
    
                CmpReportNotify(
                        KeyControlBlock,
                        KeyControlBlock->KeyHive,
                        KeyControlBlock->KeyCell,
                        REG_NOTIFY_CHANGE_LAST_SET
                        );
                status = STATUS_SUCCESS;
            } else {
                status = STATUS_OBJECT_NAME_NOT_FOUND;
            }
        }
    } finally {
        if(pcell != NULL){
            HvReleaseCell(Hive, Cell);
        }
        if(Value != NULL){
            ASSERT( ChildCell != HCELL_NIL );
            HvReleaseCell(Hive, ChildCell);
        }

#ifdef CHECK_REGISTRY_USECOUNT
        CmpCheckRegistryUseCount();
#endif //CHECK_REGISTRY_USECOUNT

        CmpUnlockRegistry();
    }

    // Mark the hive as read only
    CmpMarkAllBinsReadOnly(Hive);

    return status;
}


NTSTATUS
CmEnumerateKey(
    IN PCM_KEY_CONTROL_BLOCK    KeyControlBlock,
    IN ULONG Index,
    IN KEY_INFORMATION_CLASS KeyInformationClass,
    IN PVOID KeyInformation,
    IN ULONG Length,
    IN PULONG ResultLength
    )
/*++

Routine Description:

    Enumerate sub keys, return data on Index'th entry.

    CmEnumerateKey returns the name of the Index'th sub key of the open
    key specified.  The value STATUS_NO_MORE_ENTRIES will be
    returned if value of Index is larger than the number of sub keys.

    Note that Index is simply a way to select among child keys.  Two calls
    to CmEnumerateKey with the same Index are NOT guaranteed to return
    the same results.

    If KeyInformation is not long enough to hold all requested data,
    STATUS_BUFFER_OVERFLOW will be returned, and ResultLength will be
    set to the number of bytes actually required.

Arguments:

    KeyControlBlock - pointer to the KCB that describes the key

    Index - Specifies the (0-based) number of the sub key to be returned.

    KeyInformationClass - Specifies the type of information returned in
        Buffer.  One of the following types:

        KeyBasicInformation - return last write time, title index, and name.
            (see KEY_BASIC_INFORMATION structure)

        KeyNodeInformation - return last write time, title index, name, class.
            (see KEY_NODE_INFORMATION structure)

    KeyInformation -Supplies pointer to buffer to receive the data.

    Length - Length of KeyInformation in bytes.

    ResultLength - Number of bytes actually written into KeyInformation.

Return Value:

    NTSTATUS - Result code from call, among the following:

        <TBS>

--*/
{
    NTSTATUS        status;
    HCELL_INDEX     childcell;
    PHHIVE          Hive;
    HCELL_INDEX     Cell;
    PCM_KEY_NODE    Node;

    CmKdPrintEx((DPFLTR_CONFIG_ID,CML_CM,"CmEnumerateKey\n"));


    CmpLockRegistry();

    PERFINFO_REG_ENUM_KEY(KeyControlBlock, Index);

    if (KeyControlBlock->Delete) {
        CmpUnlockRegistry();
        return STATUS_KEY_DELETED;
    }

    Hive = KeyControlBlock->KeyHive;
    Cell = KeyControlBlock->KeyCell;

    // Mark the hive as read only
    CmpMarkAllBinsReadOnly(Hive);

    //
    // fetch the child of interest
    //

    Node = (PCM_KEY_NODE)HvGetCell(Hive, Cell);
    if( Node == NULL ) {
        //
        // we couldn't map a view for the bin containing this cell
        //
        CmpUnlockRegistry();
        CmpMarkAllBinsReadOnly(Hive);
        return STATUS_INSUFFICIENT_RESOURCES;

    }
    childcell = CmpFindSubKeyByNumber(Hive, Node, Index);
    
    // release this cell here as we don't need this Node anymore
    HvReleaseCell(Hive, Cell);

    if (childcell == HCELL_NIL) {
        //
        // no such child, clean up and return error
        //
        // we cannot return STATUS_INSUFFICIENT_RESOURCES because of Iop 
        // subsystem which treats INSUFFICIENT RESOURCES as no fatal error
        //
        CmpUnlockRegistry();

        // Mark the hive as read only
        CmpMarkAllBinsReadOnly(Hive);

        return STATUS_NO_MORE_ENTRIES;
    }

    Node = (PCM_KEY_NODE)HvGetCell(Hive,childcell);
    if( Node == NULL ) {
        //
        // we couldn't map a view for the bin containing this cell
        //
        CmpMarkAllBinsReadOnly(Hive);
        CmpUnlockRegistry();
        return STATUS_INSUFFICIENT_RESOURCES;
    }

    try {

        //
        // call a worker to perform data transfer
        //

        status = CmpQueryKeyData(Hive,
                                 Node,
                                 KeyInformationClass,
                                 KeyInformation,
                                 Length,
                                 ResultLength
#if defined(CMP_STATS) || defined(CMP_KCB_CACHE_VALIDATION)
                                 ,
                                 NULL
#endif
                                 );

     } except (EXCEPTION_EXECUTE_HANDLER) {

        HvReleaseCell(Hive, childcell);

        CmpUnlockRegistry();
        status = GetExceptionCode();

        // Mark the hive as read only
        CmpMarkAllBinsReadOnly(Hive);

        return status;
    }

    HvReleaseCell(Hive, childcell);

    CmpUnlockRegistry();

    // Mark the hive as read only
    CmpMarkAllBinsReadOnly(Hive);

    return status;
}



NTSTATUS
CmEnumerateValueKey(
    IN PCM_KEY_CONTROL_BLOCK    KeyControlBlock,
    IN ULONG Index,
    IN KEY_VALUE_INFORMATION_CLASS KeyValueInformationClass,
    IN PVOID KeyValueInformation,
    IN ULONG Length,
    IN PULONG ResultLength
    )
/*++

Routine Description:

    The value entries of an open key may be enumerated.

    CmEnumerateValueKey returns the name of the Index'th value
    entry of the open key specified by KeyHandle.  The value
    STATUS_NO_MORE_ENTRIES will be returned if value of Index is
    larger than the number of sub keys.

    Note that Index is simply a way to select among value
    entries.  Two calls to NtEnumerateValueKey with the same Index
    are NOT guaranteed to return the same results.

    If KeyValueInformation is not long enough to hold all requested data,
    STATUS_BUFFER_OVERFLOW will be returned, and ResultLength will be
    set to the number of bytes actually required.

Arguments:

    KeyControlBlock - pointer to the KCB that describes the key

    Index - Specifies the (0-based) number of the sub key to be returned.

    KeyValueInformationClass - Specifies the type of information returned
    in Buffer. One of the following types:

        KeyValueBasicInformation - return time of last write,
            title index, and name.  (See KEY_VALUE_BASIC_INFORMATION)

        KeyValueFullInformation - return time of last write,
            title index, name, class.  (See KEY_VALUE_FULL_INFORMATION)

    KeyValueInformation -Supplies pointer to buffer to receive the data.

    Length - Length of KeyValueInformation in bytes.

    ResultLength - Number of bytes actually written into KeyValueInformation.

Return Value:

    NTSTATUS - Result code from call, among the following:

        <TBS>

--*/
{
    NTSTATUS            status;
    PHHIVE              Hive;
    PCM_KEY_NODE        Node;
    PCELL_DATA          ChildList;
    PCM_KEY_VALUE       ValueData;
    BOOLEAN             IndexCached;
    BOOLEAN             ValueCached;
    PPCM_CACHED_VALUE   ContainingList;
    HCELL_INDEX         ValueDataCellToRelease = HCELL_NIL;

    CmKdPrintEx((DPFLTR_CONFIG_ID,CML_CM,"CmEnumerateValueKey\n"));


    //
    // lock the parent cell
    //

    CmpLockRegistry();

    PERFINFO_REG_ENUM_VALUE(KeyControlBlock, Index);

    if (KeyControlBlock->Delete) {
        CmpUnlockRegistry();
        return STATUS_KEY_DELETED;
    }
    Hive = KeyControlBlock->KeyHive;
    Node = (PCM_KEY_NODE)HvGetCell(Hive, KeyControlBlock->KeyCell);
    if( Node == NULL ) {
        //
        // we couldn't map a view for the bin containing this cell
        //
        CmpUnlockRegistry();
        return STATUS_INSUFFICIENT_RESOURCES;
    }

    //
    // fetch the child of interest
    //
    //
    // Do it using the cache
    //
    if (Index >= KeyControlBlock->ValueCache.Count) {
        //
        // No such child, clean up and return error.
        //
        HvReleaseCell(Hive, KeyControlBlock->KeyCell);
        CmpUnlockRegistry();
        return(STATUS_NO_MORE_ENTRIES);
    }

    // Mark the hive as read only
    CmpMarkAllBinsReadOnly(Hive);

    BEGIN_KCB_LOCK_GUARD;
    CmpLockKCBTreeExclusive();

    if (KeyControlBlock->ExtFlags & CM_KCB_SYM_LINK_FOUND) {
        //
        // The value list is now set to the KCB for symbolic link,
        // Clean it up and set the value right before we do the query.
        //
        CmpCleanUpKcbValueCache(KeyControlBlock);
        CmpSetUpKcbValueCache(KeyControlBlock,Node->ValueList.Count,Node->ValueList.List);
    }

    ChildList = CmpGetValueListFromCache(Hive, &(KeyControlBlock->ValueCache), &IndexCached);
    if( ChildList == NULL ) {
        //
        // couldn't map view; treat it as insufficient resources
        //

        HvReleaseCell(Hive, KeyControlBlock->KeyCell);

        // Mark the hive as read only
        CmpMarkAllBinsReadOnly(Hive);

        CmpUnlockKCBTree();
        CmpUnlockRegistry();
        return(STATUS_INSUFFICIENT_RESOURCES);

    }
    ValueData = CmpGetValueKeyFromCache(Hive, ChildList, Index, &ContainingList, IndexCached, &ValueCached,&ValueDataCellToRelease);    
    if( ValueData == NULL ) {
        //
        // couldn't map view; treat it as insufficient resources
        //

        HvReleaseCell(Hive, KeyControlBlock->KeyCell);
        if( ValueDataCellToRelease != HCELL_NIL ) {
            HvReleaseCell(Hive,ValueDataCellToRelease);
        }

        // Mark the hive as read only
        CmpMarkAllBinsReadOnly(Hive);

        CmpUnlockKCBTree();
        CmpUnlockRegistry();
        return(STATUS_INSUFFICIENT_RESOURCES);
    }

    END_KCB_LOCK_GUARD;


    // Trying to catch the BAD guy who writes over our pool.
    CmpMakeValueCacheReadWrite(ValueCached,CMP_GET_CACHED_ADDRESS(KeyControlBlock->ValueCache.ValueList));

    try {

        //
        // call a worker to perform data transfer; we are touching user-mode address; do it in a try/except
        //
        status = CmpQueryKeyValueData(Hive,
                                  ContainingList,
                                  ValueData,
                                  ValueCached,
                                  KeyValueInformationClass,
                                  KeyValueInformation,
                                  Length,
                                  ResultLength);

    } except (EXCEPTION_EXECUTE_HANDLER) {
        CmKdPrintEx((DPFLTR_CONFIG_ID,CML_EXCEPTION,"CmEnumerateValueKey: code:%08lx\n", GetExceptionCode()));
        status = GetExceptionCode();
    }

     // Trying to catch the BAD guy who writes over our pool.
    CmpMakeValueCacheReadOnly(ValueCached,CMP_GET_CACHED_ADDRESS(KeyControlBlock->ValueCache.ValueList));

    HvReleaseCell(Hive, KeyControlBlock->KeyCell);

    if( ValueDataCellToRelease != HCELL_NIL ) {
        HvReleaseCell(Hive,ValueDataCellToRelease);
    }

    CmpUnlockKCBTree();
    CmpUnlockRegistry();

    // Mark the hive as read only
    CmpMarkAllBinsReadOnly(Hive);

    return status;
}



NTSTATUS
CmFlushKey(
    IN PHHIVE Hive,
    IN HCELL_INDEX Cell
    )
/*++

Routine Description:

    Forces changes made to a key to disk.

    CmFlushKey will not return to its caller until any changed data
    associated with the key has been written out.

    WARNING: CmFlushKey will flush the entire registry tree, and thus will
    burn cycles and I/O.

Arguments:

    Hive - supplies a pointer to the hive control structure for the hive

    Cell - supplies index of node to whose sub keys are to be found

Return Value:

    NTSTATUS - Result code from call, among the following:

        <TBS>

--*/
{
    PCMHIVE CmHive;
    NTSTATUS    status = STATUS_SUCCESS;

    CmKdPrintEx((DPFLTR_CONFIG_ID,CML_CM,"CmFlushKey\n"));

    //
    // If writes are not working, lie and say we succeeded, will
    // clean up in a short time.  Only early system init code
    // will ever know the difference.
    //
    if (CmpNoWrite) {
        return STATUS_SUCCESS;
    }


    // Mark the hive as read only
    CmpMarkAllBinsReadOnly(Hive);

    CmHive = CONTAINING_RECORD(Hive, CMHIVE, Hive);

    //
    // Don't flush the master hive.  If somebody asks for a flushkey on
    // the master hive, do a CmpDoFlushAll instead.  CmpDoFlushAll flushes
    // every hive except the master hive, which is what they REALLY want.
    //
    if (CmHive == CmpMasterHive) {
        CmpDoFlushAll(FALSE);
    } else {
        DCmCheckRegistry(CONTAINING_RECORD(Hive, CMHIVE, Hive));

        CmLockHive (CmHive);
        CmLockHiveViews (CmHive);

        if( HvHiveWillShrink( &(CmHive->Hive) ) ) {
            //
            // we may end up here is when the hive shrinks and we need
            // exclusive access over the registry, as we are going to CcPurge !
            //
            CmUnlockHiveViews (CmHive);
            CmUnlockHive (CmHive);
            CmpUnlockRegistry();
            CmpLockRegistryExclusive();

#ifdef CHECK_REGISTRY_USECOUNT
            CmpCheckRegistryUseCount();
#endif //CHECK_REGISTRY_USECOUNT

            CmLockHive (CmHive);

            if( CmHive->UseCount != 0) {
                ASSERT_CM_LOCK_OWNED_EXCLUSIVE();
                CmpFixHiveUsageCount(CmHive);
                ASSERT( CmHive->UseCount == 0 );
            }
        } else {
            //
            // release the views
            //
            CmUnlockHiveViews (CmHive);
        }

        if (! HvSyncHive(Hive)) {

            status = STATUS_REGISTRY_IO_FAILED;

            CmKdPrintEx((DPFLTR_CONFIG_ID,CML_BUGCHECK,"CmFlushKey: HvSyncHive failed\n"));
        }

        CmUnlockHive (CmHive);
    }

    // Mark the hive as read only
    CmpMarkAllBinsReadOnly(Hive);

    return  status;
}


NTSTATUS
CmQueryKey(
    IN PCM_KEY_CONTROL_BLOCK    KeyControlBlock,
    IN KEY_INFORMATION_CLASS    KeyInformationClass,
    IN PVOID                    KeyInformation,
    IN ULONG                    Length,
    IN PULONG                   ResultLength
    )
/*++

Routine Description:

    Data about the class of a key, and the numbers and sizes of its
    children and value entries may be queried with CmQueryKey.

    NOTE: The returned lengths are guaranteed to be at least as
          long as the described values, but may be longer in
          some circumstances.

Arguments:

    KeyControlBlock - pointer to the KCB that describes the key

    KeyInformationClass - Specifies the type of information
        returned in Buffer.  One of the following types:

        KeyBasicInformation - return last write time, title index, and name.
            (See KEY_BASIC_INFORMATION)

        KeyNodeInformation - return last write time, title index, name, class.
            (See KEY_NODE_INFORMATION)

        KeyFullInformation - return all data except for name and security.
            (See KEY_FULL_INFORMATION)

    KeyInformation -Supplies pointer to buffer to receive the data.

    Length - Length of KeyInformation in bytes.

    ResultLength - Number of bytes actually written into KeyInformation.

Return Value:

    NTSTATUS - Result code from call, among the following:

        <TBS>

--*/
{
    NTSTATUS        status;
    PCM_KEY_NODE    Node = NULL;
    PUNICODE_STRING Name = NULL;

    CmKdPrintEx((DPFLTR_CONFIG_ID,CML_CM,"CmQueryKey\n"));

    CmpLockRegistry();

    PERFINFO_REG_QUERY_KEY(KeyControlBlock);

    // Mark the hive as read only
    CmpMarkAllBinsReadOnly(KeyControlBlock->KeyHive);

    try {

        //
        // request for the FULL path of the key
        //
        if( KeyInformationClass == KeyNameInformation ) {
            if (KeyControlBlock->Delete ) {
                //
                // special case: return key deleted status, but still fill the full name of the key.
                //
                status = STATUS_KEY_DELETED;
            } else {
                status = STATUS_SUCCESS;
            }
            
            if( KeyControlBlock->NameBlock ) {

                Name = CmpConstructName(KeyControlBlock);
                if (Name == NULL) {
                    status = STATUS_INSUFFICIENT_RESOURCES;
                } else {
                    ULONG       requiredlength;
                    ULONG       minimumlength;
                    USHORT      NameLength;
                    LONG        leftlength;
                    PKEY_INFORMATION pbuffer = (PKEY_INFORMATION)KeyInformation;

                    NameLength = Name->Length;

                    requiredlength = FIELD_OFFSET(KEY_NAME_INFORMATION, Name) + NameLength;
                    
                    minimumlength = FIELD_OFFSET(KEY_NAME_INFORMATION, Name);

                    *ResultLength = requiredlength;
                    if (Length < minimumlength) {

                        status = STATUS_BUFFER_TOO_SMALL;

                    } else {
                        //
                        // Fill in the length of the name
                        //
                        pbuffer->KeyNameInformation.NameLength = NameLength;
                        
                        //
                        // Now copy the full name into the user buffer, if enough space
                        //
                        leftlength = Length - minimumlength;
                        requiredlength = NameLength;
                        if (leftlength < (LONG)requiredlength) {
                            requiredlength = leftlength;
                            status = STATUS_BUFFER_OVERFLOW;
                        }

                        //
                        // If not enough space, copy how much we can and return overflow
                        //
                        RtlCopyMemory(
                            &(pbuffer->KeyNameInformation.Name[0]),
                            Name->Buffer,
                            requiredlength
                            );
                    }
                }
            }
        } else if(KeyControlBlock->Delete ) {
            // 
            // key already deleted
            //
            status = STATUS_KEY_DELETED;
        } else if( KeyInformationClass == KeyFlagsInformation ) {
            //
            // we only want to get the user defined flags;
            //
            PKEY_INFORMATION    pbuffer = (PKEY_INFORMATION)KeyInformation;
            ULONG               requiredlength;

            requiredlength = sizeof(KEY_FLAGS_INFORMATION);

            *ResultLength = requiredlength;

            if (Length < requiredlength) {
                status = STATUS_BUFFER_TOO_SMALL;
            } else {
                pbuffer->KeyFlagsInformation.UserFlags = (ULONG)((USHORT)KeyControlBlock->Flags >> KEY_USER_FLAGS_SHIFT);
                status = STATUS_SUCCESS;
            }
        } else {
            //
            // call a worker to perform data transfer
            //

            if( KeyInformationClass == KeyCachedInformation ) {
                //
                // call the fast version
                //
                status = CmpQueryKeyDataFromCache(  KeyControlBlock,
                                                    KeyInformationClass,
                                                    KeyInformation,
                                                    Length,
                                                    ResultLength );
            } else {
                //
                // old'n plain slow version
                //
                Node = (PCM_KEY_NODE)HvGetCell(KeyControlBlock->KeyHive, KeyControlBlock->KeyCell);
                if( Node == NULL ) {
                    //
                    // we couldn't map a view for the bin containing this cell
                    //
                    status = STATUS_INSUFFICIENT_RESOURCES;
                } else {
                    status = CmpQueryKeyData(KeyControlBlock->KeyHive,
                                             Node,
                                             KeyInformationClass,
                                             KeyInformation,
                                             Length,
                                             ResultLength 
#if defined(CMP_STATS) || defined(CMP_KCB_CACHE_VALIDATION)
                                 ,
                                 KeyControlBlock
#endif
                                             );
                }
            }
        }

    } finally {
        if( Node != NULL ) {
            HvReleaseCell(KeyControlBlock->KeyHive, KeyControlBlock->KeyCell);
        }

        if( Name != NULL ) {
            ExFreePoolWithTag(Name, CM_NAME_TAG | PROTECTED_POOL);
        }
        CmpUnlockRegistry();
    }

    // Mark the hive as read only
    CmpMarkAllBinsReadOnly(KeyControlBlock->KeyHive);

    return status;
}


NTSTATUS
CmQueryValueKey(
    IN PCM_KEY_CONTROL_BLOCK    KeyControlBlock,
    IN UNICODE_STRING ValueName,
    IN KEY_VALUE_INFORMATION_CLASS KeyValueInformationClass,
    IN PVOID KeyValueInformation,
    IN ULONG Length,
    IN PULONG ResultLength
    )
/*++

Routine Description:

    The ValueName, TitleIndex, Type, and Data for any one of a key's
    value entries may be queried with CmQueryValueKey.

    If KeyValueInformation is not long enough to hold all requested data,
    STATUS_BUFFER_OVERFLOW will be returned, and ResultLength will be
    set to the number of bytes actually required.

Arguments:

    KeyControlBlock - pointer to the KCB that describes the key

    ValueName  - The name of the value entry to return data for.

    KeyValueInformationClass - Specifies the type of information
        returned in KeyValueInformation.  One of the following types:

        KeyValueBasicInformation - return time of last write, title
            index, and name.  (See KEY_VALUE_BASIC_INFORMATION)

        KeyValueFullInformation - return time of last write, title
            index, name, class.  (See KEY_VALUE_FULL_INFORMATION)

    KeyValueInformation -Supplies pointer to buffer to receive the data.

    Length - Length of KeyValueInformation in bytes.

    ResultLength - Number of bytes actually written into KeyValueInformation.

Return Value:

    NTSTATUS - Result code from call, among the following:

        <TBS>

--*/
{
    NTSTATUS            status;
    HCELL_INDEX         childcell;
    PHCELL_INDEX        childindex;
    HCELL_INDEX         Cell;
    PCM_KEY_VALUE       ValueData;
    ULONG               Index;
    BOOLEAN             ValueCached;
    PPCM_CACHED_VALUE   ContainingList;
    HCELL_INDEX         ValueDataCellToRelease = HCELL_NIL;

    PAGED_CODE();
    CmKdPrintEx((DPFLTR_CONFIG_ID,CML_CM,"CmQueryValueKey\n"));


    CmpLockRegistry();

    PERFINFO_REG_QUERY_VALUE(KeyControlBlock, &ValueName);

    if (KeyControlBlock->Delete) {

        CmpUnlockRegistry();
        return STATUS_KEY_DELETED;
    }

    // Mark the hive as read only
    CmpMarkAllBinsReadOnly(KeyControlBlock->KeyHive);

    BEGIN_KCB_LOCK_GUARD;

    CmpLockKCBTreeExclusive();

    if (KeyControlBlock->ExtFlags & CM_KCB_SYM_LINK_FOUND) {
        //
        // The value list is now set to the KCB for symbolic link,
        // Clean it up and set the value right before we do the query.
        //
        CmpCleanUpKcbValueCache(KeyControlBlock);

        {
            PCM_KEY_NODE Node = (PCM_KEY_NODE)HvGetCell(KeyControlBlock->KeyHive, KeyControlBlock->KeyCell);
            if( Node == NULL ) {
                //
                // we couldn't map a view for the bin containing this cell
                //
                
                CmpUnlockKCBTree();
                CmpUnlockRegistry();
                // Mark the hive as read only
                CmpMarkAllBinsReadOnly(KeyControlBlock->KeyHive);

                return STATUS_INSUFFICIENT_RESOURCES;

            }
            
            CmpSetUpKcbValueCache(KeyControlBlock,Node->ValueList.Count,Node->ValueList.List);

            HvReleaseCell(KeyControlBlock->KeyHive, KeyControlBlock->KeyCell);
        }
    }

    //
    // Find the data
    //

    ValueData = CmpFindValueByNameFromCache(KeyControlBlock->KeyHive,
                                            &(KeyControlBlock->ValueCache),
                                            &ValueName,
                                            &ContainingList,
                                            &Index,
                                            &ValueCached,
                                            &ValueDataCellToRelease
                                            );

    END_KCB_LOCK_GUARD;

    if (ValueData) {

        // Trying to catch the BAD guy who writes over our pool.
        CmpMakeValueCacheReadWrite(ValueCached,CMP_GET_CACHED_ADDRESS(KeyControlBlock->ValueCache.ValueList));

        try {

            //
            // call a worker to perform data transfer; we are touching user-mode address; do it in a try/except
            //

            status = CmpQueryKeyValueData(KeyControlBlock->KeyHive,
                                          ContainingList,
                                          ValueData,
                                          ValueCached,
                                          KeyValueInformationClass,
                                          KeyValueInformation,
                                          Length,
                                          ResultLength);


        } except (EXCEPTION_EXECUTE_HANDLER) {
            CmKdPrintEx((DPFLTR_CONFIG_ID,CML_EXCEPTION,"CmQueryValueKey: code:%08lx\n", GetExceptionCode()));
            status = GetExceptionCode();
        }

        // Trying to catch the BAD guy who writes over our pool.
        CmpMakeValueCacheReadOnly(ValueCached,CMP_GET_CACHED_ADDRESS(KeyControlBlock->ValueCache.ValueList));
    } else {
        status = STATUS_OBJECT_NAME_NOT_FOUND;
    }


    if(ValueDataCellToRelease != HCELL_NIL) {
        HvReleaseCell(KeyControlBlock->KeyHive,ValueDataCellToRelease);
    }
    CmpUnlockKCBTree();
    CmpUnlockRegistry();

    // Mark the hive as read only
    CmpMarkAllBinsReadOnly(KeyControlBlock->KeyHive);

    return status;
}


NTSTATUS
CmQueryMultipleValueKey(
    IN PCM_KEY_CONTROL_BLOCK KeyControlBlock,
    IN PKEY_VALUE_ENTRY ValueEntries,
    IN ULONG EntryCount,
    IN PVOID ValueBuffer,
    IN OUT PULONG BufferLength,
    IN OPTIONAL PULONG ResultLength
    )
/*++

Routine Description:

    Multiple values of any key may be queried atomically with
    this api.

Arguments:

    KeyControlBlock - Supplies the key to be queried.

    ValueEntries - Returns an array of KEY_VALUE_ENTRY structures, one for each value.

    EntryCount - Supplies the number of entries in the ValueNames and ValueEntries arrays

    ValueBuffer - Returns the value data for each value.

    BufferLength - Supplies the length of the ValueBuffer array in bytes.
                   Returns the length of the ValueBuffer array that was filled in.

    ResultLength - if present, Returns the length in bytes of the ValueBuffer
                    array required to return the requested values of this key.

Return Value:

    NTSTATUS

--*/

{
    PHHIVE          Hive;
    NTSTATUS        Status;
    ULONG           i;
    UNICODE_STRING  CurrentName;
    HCELL_INDEX     ValueCell = HCELL_NIL;
    PCM_KEY_VALUE   ValueNode;
    ULONG           RequiredLength = 0;
    ULONG           UsedLength = 0;
    ULONG           DataLength;
    BOOLEAN         BufferFull = FALSE;
    BOOLEAN         Small;
    PUCHAR          Data;
    KPROCESSOR_MODE PreviousMode;
    PCM_KEY_NODE    Node;

    PAGED_CODE();
    CmKdPrintEx((DPFLTR_CONFIG_ID,CML_CM,"CmQueryMultipleValueKey\n"));


    CmpLockRegistry();

    if (KeyControlBlock->Delete) {
        CmpUnlockRegistry();
        return STATUS_KEY_DELETED;
    }
    Hive = KeyControlBlock->KeyHive;
    Status = STATUS_SUCCESS;

    Node = (PCM_KEY_NODE)HvGetCell(Hive, KeyControlBlock->KeyCell);
    if( Node == NULL ) {
        //
        // we couldn't map a view for the bin containing this cell
        //
        CmpUnlockRegistry();
        return STATUS_INSUFFICIENT_RESOURCES;
    }

    // Mark the hive as read only
    CmpMarkAllBinsReadOnly(Hive);

    PreviousMode = KeGetPreviousMode();
    try {
        for (i=0; i < EntryCount; i++) {
            //
            // find the data
            //
            if (PreviousMode == UserMode) {
                CurrentName = ProbeAndReadUnicodeString(ValueEntries[i].ValueName);
                ProbeForRead(CurrentName.Buffer,CurrentName.Length,sizeof(WCHAR));
            } else {
                CurrentName = *(ValueEntries[i].ValueName);
            }

            PERFINFO_REG_QUERY_MULTIVALUE(KeyControlBlock, &CurrentName); 

            ValueCell = CmpFindValueByName(Hive,
                                           Node,
                                           &CurrentName);
            if (ValueCell != HCELL_NIL) {

                ValueNode = (PCM_KEY_VALUE)HvGetCell(Hive, ValueCell);
                if( ValueNode == NULL ) {
                    //
                    // we couldn't map a view for the bin containing this cell
                    //
                
                    Status = STATUS_INSUFFICIENT_RESOURCES;
                    break;
                }
                Small = CmpIsHKeyValueSmall(DataLength, ValueNode->DataLength);

                //
                // Round up UsedLength and RequiredLength to a ULONG boundary
                //
                UsedLength = (UsedLength + sizeof(ULONG)-1) & ~(sizeof(ULONG)-1);
                RequiredLength = (RequiredLength + sizeof(ULONG)-1) & ~(sizeof(ULONG)-1);

                //
                // If there is enough room for this data value in the buffer,
                // fill it in now. Otherwise, mark the buffer as full. We must
                // keep iterating through the values in order to determine the
                // RequiredLength.
                //
                if ((UsedLength + DataLength <= *BufferLength) &&
                    (!BufferFull)) {
                    PCELL_DATA  Buffer;
                    BOOLEAN     BufferAllocated;
                    HCELL_INDEX CellToRelease;
                    //
                    // get the data from source, regardless of the size
                    //
                    if( CmpGetValueData(Hive,ValueNode,&DataLength,&Buffer,&BufferAllocated,&CellToRelease) == FALSE ) {
                        //
                        // insufficient resources; return NULL
                        //
                        ASSERT( BufferAllocated == FALSE );
                        ASSERT( Buffer == NULL );
                        Status = STATUS_INSUFFICIENT_RESOURCES;
                        break;
                    }

                    RtlCopyMemory((PUCHAR)ValueBuffer + UsedLength,
                                  Buffer,
                                  DataLength);
                    //
                    // cleanup the temporary buffer
                    //
                    if( BufferAllocated == TRUE ) {
                        ExFreePool( Buffer );
                    }
                    //
                    // release the buffer in case we are using hive storage
                    //
                    if( CellToRelease != HCELL_NIL ) {
                        HvReleaseCell(Hive,CellToRelease);
                    }

                    ValueEntries[i].Type = ValueNode->Type;
                    ValueEntries[i].DataLength = DataLength;
                    ValueEntries[i].DataOffset = UsedLength;
                    UsedLength += DataLength;
                } else {
                    BufferFull = TRUE;
                    Status = STATUS_BUFFER_OVERFLOW;
                }
                RequiredLength += DataLength;
                HvReleaseCell(Hive, ValueCell);
                ValueCell = HCELL_NIL;
            } else {
                Status = STATUS_OBJECT_NAME_NOT_FOUND;
                break;
            }
        }

        if (NT_SUCCESS(Status) ||
            (Status == STATUS_BUFFER_OVERFLOW)) {
            *BufferLength = UsedLength;
            if (ARGUMENT_PRESENT(ResultLength)) {
                *ResultLength = RequiredLength;
            }
        }

    } finally {
        if( ValueCell != HCELL_NIL) {
            HvReleaseCell(Hive, ValueCell);
        }
        HvReleaseCell(Hive, KeyControlBlock->KeyCell);
        
        CmpUnlockRegistry();
    }

    // Mark the hive as read only
    CmpMarkAllBinsReadOnly(Hive);

    return Status;
}

NTSTATUS
CmSetValueKey(
    IN PCM_KEY_CONTROL_BLOCK KeyControlBlock,
    IN PUNICODE_STRING ValueName,
    IN ULONG Type,
    IN PVOID Data,
    IN ULONG DataSize
    )
/*++

Routine Description:

    A value entry may be created or replaced with CmSetValueKey.

    If a value entry with a Value ID (i.e. name) matching the
    one specified by ValueName exists, it is deleted and replaced
    with the one specified.  If no such value entry exists, a new
    one is created.  NULL is a legal Value ID.  While Value IDs must
    be unique within any given key, the same Value ID may appear
    in many different keys.

Arguments:

    KeyControlBlock - pointer to kcb for the key to operate on

    ValueName - The unique (relative to the containing key) name
        of the value entry.  May be NULL.

    Type - The integer type number of the value entry.

    Data - Pointer to buffer with actual data for the value entry.

    DataSize - Size of Data buffer.


Return Value:

    NTSTATUS - Result code from call, among the following:

        <TBS>

--*/
{
    NTSTATUS        status;
    PCM_KEY_NODE    parent = NULL;
    HCELL_INDEX     oldchild;
    ULONG           count;
    PHHIVE          Hive;
    HCELL_INDEX     Cell;
    ULONG           StorageType;
    ULONG           TempData;
    BOOLEAN         found;
    PCM_KEY_VALUE   Value = NULL;
    LARGE_INTEGER   systemtime;
    ULONG           mustChange=FALSE;
    ULONG           ChildIndex;
    HCELL_INDEX     ParentToRelease = HCELL_NIL;
    HCELL_INDEX     ChildToRelease = HCELL_NIL;

    PERFINFO_REG_SET_VALUE_DECL();

    CmKdPrintEx((DPFLTR_CONFIG_ID,CML_CM,"CmSetValueKey\n"));

    CmpLockRegistry();

    ASSERT(sizeof(ULONG) == CM_KEY_VALUE_SMALL);

    PERFINFO_REG_SET_VALUE(KeyControlBlock);

    // Mark the hive as read only
    CmpMarkAllBinsReadOnly(KeyControlBlock->KeyHive);

    while (TRUE) {
        //
        // Check that we are not being asked to add a value to a key
        // that has been deleted
        //
        if (KeyControlBlock->Delete == TRUE) {
            status = STATUS_KEY_DELETED;
            goto Exit;
        }

        //
        // Check to see if this is a symbolic link node.  If so caller
        // is only allowed to create/change the SymbolicLinkValue
        // value name
        //

#ifdef CMP_KCB_CACHE_VALIDATION
        {
            PCM_KEY_NODE    Node;
            Node = (PCM_KEY_NODE)HvGetCell(KeyControlBlock->KeyHive, KeyControlBlock->KeyCell);
            if( Node == NULL ) {
                //
                // we couldn't map a view for the bin containing this cell
                //
        
                status = STATUS_INSUFFICIENT_RESOURCES;
                goto Exit;
            }
            ASSERT( Node->Flags == KeyControlBlock->Flags );
            HvReleaseCell(KeyControlBlock->KeyHive, KeyControlBlock->KeyCell);
        }
#endif
        if (KeyControlBlock->Flags & KEY_SYM_LINK &&
            (( (Type != REG_LINK) 
#ifdef CM_DYN_SYM_LINK
            && (Type != REG_DYN_LINK)
#endif //CM_DYN_SYM_LINK
            ) ||
             ValueName == NULL ||
             !RtlEqualUnicodeString(&CmSymbolicLinkValueName, ValueName, TRUE)))
        {
            //
            // Disallow attempts to manipulate any value names under a symbolic link
            // except for the "SymbolicLinkValue" value name or type other than REG_LINK
            //

            // Mark the hive as read only
            CmpMarkAllBinsReadOnly(KeyControlBlock->KeyHive);

            status = STATUS_ACCESS_DENIED;
            goto Exit;
        }

        if( mustChange == FALSE ) {
            //
            // first iteration; look inside the kcb cache
            //
            
            if( CmpCompareNewValueDataAgainstKCBCache(KeyControlBlock,ValueName,Type,Data,DataSize) == TRUE ) {
                //
                // the value is in the cache and is the same; make this call a noop
                //
                status = STATUS_SUCCESS;
                goto Exit;
            }
            //
            // To Get here, we must either be changing a value, or setting a new one
            //
            mustChange=TRUE;
        } else {
            //
            // second iteration; look inside the hive
            //

            
            //
            // get reference to parent key,
            //
            Hive = KeyControlBlock->KeyHive;
            Cell = KeyControlBlock->KeyCell;
            if( ParentToRelease != HCELL_NIL ) {
                HvReleaseCell(Hive,ParentToRelease);
                ParentToRelease = HCELL_NIL;
            }
            parent = (PCM_KEY_NODE)HvGetCell(Hive, Cell);
            if( parent == NULL ) {
                //
                // we couldn't map a view for the bin containing this cell
                //
        
                status = STATUS_INSUFFICIENT_RESOURCES;
                goto Exit;
            }
            ParentToRelease = Cell;
            //
            // try to find an existing value entry by the same name
            //
            count = parent->ValueList.Count;
            found = FALSE;

            if (count > 0) {
                if( CmpFindNameInList(Hive,
                                     &parent->ValueList,
                                     ValueName,
                                     &ChildIndex,
                                     &oldchild) == FALSE ) {
                    //
                    // we couldn't map a view for the bin containing this cell
                    //
        
                    status = STATUS_INSUFFICIENT_RESOURCES;
                    goto Exit;
                }

                if (oldchild != HCELL_NIL) {
                    if( ChildToRelease != HCELL_NIL ) {
                        HvReleaseCell(Hive,ChildToRelease);
                        ChildToRelease = HCELL_NIL;
                    }
                    Value = (PCM_KEY_VALUE)HvGetCell(Hive,oldchild);
                    if( Value == NULL ) {
                        //
                        // could no map view
                        //
                        status = STATUS_INSUFFICIENT_RESOURCES;
                        goto Exit;
                    }
                    ChildToRelease = oldchild;
                    found = TRUE;
                }
            } else {
                //
                // empty list; add it first
                //
                ChildIndex = 0;
            }

            //
            // Performance Hack:
            // If a Set is asking us to set a key to the current value (IE does this a lot)
            // drop it (and, therefore, the last modified time) on the floor, but return success
            // this stops the page from being dirtied, and us having to flush the registry.
            //
            //
            break;
        }

        //
        // We're going through these gyrations so that if someone does come in and try and delete the
        // key we're setting we're safe. Once we know we have to change the key, take the
        // Exclusive (write) lock then restart
        //
        //
        CmpUnlockRegistry();
        CmpLockRegistryExclusive();

#ifdef CHECK_REGISTRY_USECOUNT
    CmpCheckRegistryUseCount();
#endif //CHECK_REGISTRY_USECOUNT

    }// while

    ASSERT( mustChange == TRUE );

    // It's a different or new value, mark it dirty, since we'll
    // at least set its time stamp

    if (! HvMarkCellDirty(Hive, Cell)) {
        status = STATUS_NO_LOG_SPACE;
        goto Exit;
    }

    StorageType = HvGetCellType(Cell);

    //
    // stash small data if relevent
    //
    TempData = 0;
    if ((DataSize <= CM_KEY_VALUE_SMALL) &&
        (DataSize > 0))
    {
        try {
            RtlMoveMemory(          // yes, move memory, could be 1 byte
                &TempData,          // at the end of a page.
                Data,
                DataSize
                );
         } except (EXCEPTION_EXECUTE_HANDLER) {
            CmKdPrintEx((DPFLTR_CONFIG_ID,CML_EXCEPTION,"!!CmSetValueKey: code:%08lx\n", GetExceptionCode()));
            status = GetExceptionCode();
            goto Exit;
        }
    }

    if (found) {

        //
        // ----- Existing Value Entry Path -----
        //

        //
        // An existing value entry of the specified name exists,
        // set our data into it.
        //
        status = CmpSetValueKeyExisting(Hive,
                                        oldchild,
                                        Value,
                                        Type,
                                        Data,
                                        DataSize,
                                        StorageType,
                                        TempData);

        PERFINFO_REG_SET_VALUE_EXIST();
    } else {

        //
        // ----- New Value Entry Path -----
        //

        //
        // Either there are no existing value entries, or the one
        // specified is not in the list.  In either case, create and
        // fill a new one, and add it to the list
        //
        status = CmpSetValueKeyNew(Hive,
                                   parent,
                                   ValueName,
                                   ChildIndex,
                                   Type,
                                   Data,
                                   DataSize,
                                   StorageType,
                                   TempData);
        PERFINFO_REG_SET_VALUE_NEW();
    }

    if (NT_SUCCESS(status)) {

        // sanity assert
        ASSERT( parent->MaxValueNameLen == KeyControlBlock->KcbMaxValueNameLen );
        if (parent->MaxValueNameLen < ValueName->Length) {
            parent->MaxValueNameLen = ValueName->Length;
            // update the kcb cache too
            KeyControlBlock->KcbMaxValueNameLen = ValueName->Length;
        }

        //sanity assert
        ASSERT( parent->MaxValueDataLen == KeyControlBlock->KcbMaxValueDataLen );
        if (parent->MaxValueDataLen < DataSize) {
            parent->MaxValueDataLen = DataSize;
            // update the kcb cache too
            KeyControlBlock->KcbMaxValueDataLen = parent->MaxValueDataLen;
        }

        KeQuerySystemTime(&systemtime);
        parent->LastWriteTime = systemtime;
        // update the kcb cache too.
        KeyControlBlock->KcbLastWriteTime = systemtime;
    
        //
        // Update the cache, no need for KCB lock as the registry is locked exclusively.
        //
        ASSERT_CM_LOCK_OWNED_EXCLUSIVE();

        if( found && (CMP_IS_CELL_CACHED(KeyControlBlock->ValueCache.ValueList)) ) {
            //
            // invalidate only the entry we changed.
            //
            PULONG_PTR CachedList = (PULONG_PTR) CMP_GET_CACHED_CELLDATA(KeyControlBlock->ValueCache.ValueList);
            if (CMP_IS_CELL_CACHED(CachedList[ChildIndex])) {

                ExFreePool((PVOID) CMP_GET_CACHED_ADDRESS(CachedList[ChildIndex]));
            }
            CachedList[ChildIndex] = oldchild;

        } else {
            //
            // rebuild ALL KCB cache
            // 
            CmpCleanUpKcbValueCache(KeyControlBlock);
            CmpSetUpKcbValueCache(KeyControlBlock,parent->ValueList.Count,parent->ValueList.List);
        }
        CmpReportNotify(KeyControlBlock,
                        KeyControlBlock->KeyHive,
                        KeyControlBlock->KeyCell,
                        REG_NOTIFY_CHANGE_LAST_SET);
    }

Exit:
    PERFINFO_REG_SET_VALUE_DONE(ValueName);

    if( ParentToRelease != HCELL_NIL ) {
        HvReleaseCell(Hive,ParentToRelease);
    }
    if( ChildToRelease != HCELL_NIL ) {
        HvReleaseCell(Hive,ChildToRelease);
    }

    CmpUnlockRegistry();
  
    // Mark the hive as read only
    CmpMarkAllBinsReadOnly(KeyControlBlock->KeyHive);

    return status;
}


NTSTATUS
CmpSetValueKeyExisting(
    IN PHHIVE  Hive,
    IN HCELL_INDEX OldChild,
    IN PCM_KEY_VALUE Value,
    IN ULONG Type,
    IN PVOID Data,
    IN ULONG DataSize,
    IN ULONG StorageType,
    IN ULONG TempData
    )
/*++

Routine Description:

    Helper for CmSetValueKey, implements the case where the value entry
    being set already exists.

Arguments:

    Hive - hive of interest

    OldChild - hcell_index of the value entry body to which we are to
                    set new data

    Type - The integer type number of the value entry.

    Data - Pointer to buffer with actual data for the value entry.

    DataSize - Size of Data buffer.

    StorageType - stable or volatile

    TempData - small values are passed here

Return Value:

    STATUS_SUCCESS if it worked, appropriate status code if it did not

Note: 
    
    For new hives format, we have the following cases:

    New Data                Old Data
    --------                --------

1.  small                   small
2.  small                   normal
3.  small                   bigdata
4.  normal                  small
5.  normal                  normal
6.  normal                  bigdata
7.  bigdata                 small
8.  bigdata                 normal
9.  bigdata                 bigdata  



--*/
{
    HCELL_INDEX     DataCell;
    HCELL_INDEX     OldDataCell;
    PCELL_DATA      pdata;
    HCELL_INDEX     NewCell;
    ULONG           OldRealSize;
    USHORT          OldSizeType;    // 0 - small
    USHORT          NewSizeType;    // 1 - normal
                                    // 2 - bigdata
    HANDLE          hSecure = 0;
    NTSTATUS        status = STATUS_SUCCESS;

    ASSERT_CM_LOCK_OWNED_EXCLUSIVE();


    //
    // value entry by the specified name already exists
    // oldchild is hcell_index of its value entry body
    //  which we will always edit, so mark it dirty
    //
    if (! HvMarkCellDirty(Hive, OldChild)) {
        return STATUS_NO_LOG_SPACE;
    }

    if(CmpIsHKeyValueSmall(OldRealSize, Value->DataLength) == TRUE ) {
        //
        // old data was small
        //
        OldSizeType = 0;
    } else if( CmpIsHKeyValueBig(Hive,OldRealSize) == TRUE ) {
        //
        // old data was big
        //
        OldSizeType = 2;
    } else {
        //
        // old data was normal
        //
        OldSizeType = 1;
    }

    if( DataSize <= CM_KEY_VALUE_SMALL ) {
        //
        // new data is small
        //
        NewSizeType = 0;
    } else if( CmpIsHKeyValueBig(Hive,DataSize) == TRUE ) {
        //
        // new data is big
        //
        NewSizeType = 2;
    } else {
        //
        // new data is normal
        //
        NewSizeType = 1;
    }


    //
    // this will handle all cases and will make sure data is marked dirty 
    //
    if( !CmpMarkValueDataDirty(Hive,Value) ) {
        return STATUS_NO_LOG_SPACE;
    }

    //
    // cases 1,2,3
    //
    if( NewSizeType == 0 ) {
        if( ((OldSizeType == 1) && (OldRealSize > 0) ) ||
            (OldSizeType == 2) 
            ) {
            CmpFreeValueData(Hive,Value->Data,OldRealSize);
        }
        
        //
        // write our new small data into value entry body
        //
        Value->DataLength = DataSize + CM_KEY_VALUE_SPECIAL_SIZE;
        Value->Data = TempData;
        Value->Type = Type;

        return STATUS_SUCCESS;
    }
    
    //
    // secure the user buffer so we don't get inconsistencies.
    // ONLY if we are called with a user mode buffer !!!
    //

    if ( (ULONG_PTR)Data <= (ULONG_PTR)MM_HIGHEST_USER_ADDRESS ) {
        hSecure = MmSecureVirtualMemory(Data,DataSize, PAGE_READONLY);
        if (hSecure == 0) {
            return STATUS_INVALID_PARAMETER;
        }
    }
    
    //
    // store it to be freed if the allocation succeeds
    //
    OldDataCell = Value->Data;

    //
    // cases 4,5,6
    //
    if( NewSizeType == 1 ){

        if( (OldSizeType == 1) && (OldRealSize > 0)) { 
            //
            // we already have a cell; see if we can reuse it !
            //
            DataCell = Value->Data;
            ASSERT(DataCell != HCELL_NIL);
            pdata = HvGetCell(Hive, DataCell);
            if( pdata == NULL ) {
                //
                // we couldn't map a view for the bin containing this cell
                //
                status = STATUS_INSUFFICIENT_RESOURCES;
                goto Exit;
            }
            // release it right here, as the registry is locked exclusively, so we don't care
            HvReleaseCell(Hive, DataCell);

            ASSERT(HvGetCellSize(Hive, pdata) > 0);

            if (DataSize <= (ULONG)(HvGetCellSize(Hive, pdata))) {

                //
                // The existing data cell is big enough to hold the new data.  
                //

                //
                // we'll keep this cell
                //
                NewCell = DataCell;

            } else {
                //
                // grow the existing cell
                //
                NewCell = HvReallocateCell(Hive,DataCell,DataSize);
                if (NewCell == HCELL_NIL) {
                    status = STATUS_INSUFFICIENT_RESOURCES;
                    goto Exit;
                }
            }

        } else {
            //
            // allocate a new cell 
            //
            NewCell = HvAllocateCell(Hive, DataSize, StorageType,(HvGetCellType(OldChild)==StorageType)?OldChild:HCELL_NIL);

            if (NewCell == HCELL_NIL) {
                status = STATUS_INSUFFICIENT_RESOURCES;
                goto Exit;
            }
        }
        
        //
        // now we have a cell that can accomodate the data
        //
        pdata = HvGetCell(Hive, NewCell);
        if( pdata == NULL ) {
            //
            // we couldn't map a view for the bin containing this cell
            //
            // this shouldn't happen as we just allocated/ reallocated/ marked dirty this cell
            //
            ASSERT( FALSE );
            status = STATUS_INSUFFICIENT_RESOURCES;
            goto Exit;
        }
        // release it right here, as the registry is locked exclusively, so we don't care
        HvReleaseCell(Hive, NewCell);

        //
        // copy the actual data
        //
        RtlCopyMemory(pdata,Data,DataSize);
        Value->Data = NewCell;
        Value->DataLength = DataSize;
        Value->Type = Type;
        
        // sanity
        ASSERT_CELL_DIRTY(Hive,NewCell);

        if( OldSizeType == 2 ) {
            //
            // old data was big; free it
            //
            ASSERT( OldDataCell != NewCell );
            CmpFreeValueData(Hive,OldDataCell,OldRealSize);
        }

        status = STATUS_SUCCESS;
        goto Exit;
    }
    
    //
    // cases 7,8,9
    //
    if( NewSizeType == 2 ) {

        if( OldSizeType == 2 ) { 
            //
            // data was previously big; grow it!
            //
            
            status =CmpSetValueDataExisting(Hive,Data,DataSize,StorageType,OldDataCell);
            if( !NT_SUCCESS(status) ) {
                goto Exit;
            }
            NewCell = OldDataCell;
            
        } else {
            //
            // data was small or normal. 
            // allocate and copy to a new big data cell; 
            // then free the old cell
            //
            status = CmpSetValueDataNew(Hive,Data,DataSize,StorageType,OldChild,&NewCell);
            if( !NT_SUCCESS(status) ) {
                //
                // We have bombed out loading user data, clean up and exit.
                //
                goto Exit;
            }
            
            if( (OldSizeType != 0) && (OldRealSize != 0) ) {
                //
                // there is something to free
                //
                HvFreeCell(Hive, Value->Data);
            }
        }

        Value->DataLength = DataSize;
        Value->Data = NewCell;
        Value->Type = Type;

        // sanity
        ASSERT_CELL_DIRTY(Hive,NewCell);

        status = STATUS_SUCCESS;
        goto Exit;

    }

    //
    // we shouldn't go here
    //
    ASSERT( FALSE );

Exit:
    if( hSecure) {
        MmUnsecureVirtualMemory(hSecure);
    }
    return status;
}

NTSTATUS
CmpSetValueKeyNew(
    IN PHHIVE  Hive,
    IN PCM_KEY_NODE Parent,
    IN PUNICODE_STRING ValueName,
    IN ULONG Index,
    IN ULONG Type,
    IN PVOID Data,
    IN ULONG DataSize,
    IN ULONG StorageType,
    IN ULONG TempData
    )
/*++

Routine Description:

    Helper for CmSetValueKey, implements the case where the value entry
    being set does not exist.  Will create new value entry and data,
    place in list (which may be created)

Arguments:

    Hive - hive of interest

    Parent - pointer to key node value entry is for

    ValueName - The unique (relative to the containing key) name
        of the value entry.  May be NULL.

    Index - where in the list should this value be inserted

    Type - The integer type number of the value entry.

    Data - Pointer to buffer with actual data for the value entry.

    DataSize - Size of Data buffer.

    StorageType - stable or volatile

    TempData - small data values passed here


Return Value:

    STATUS_SUCCESS if it worked, appropriate status code if it did not

--*/
{
    PCELL_DATA  pvalue;
    HCELL_INDEX ValueCell;
    NTSTATUS    Status;

    ASSERT_CM_LOCK_OWNED_EXCLUSIVE();

    //
    // Either Count == 0 (no list) or our entry is simply not in
    // the list.  Create a new value entry body, and data.  Add to list.
    // (May create the list.)
    //
    if (Parent->ValueList.Count != 0) {
        ASSERT(Parent->ValueList.List != HCELL_NIL);
        if (! HvMarkCellDirty(Hive, Parent->ValueList.List)) {
            return STATUS_NO_LOG_SPACE;
        }
    }

    //
    // allocate the body of the value entry, and the data
    //
    ValueCell = HvAllocateCell(
                    Hive,
                    CmpHKeyValueSize(Hive, ValueName),
                    StorageType,
                    HCELL_NIL
                    );

    if (ValueCell == HCELL_NIL) {
        return STATUS_INSUFFICIENT_RESOURCES;
    }

    //
    // map in the body, and fill in its fixed portion
    //
    pvalue = HvGetCell(Hive, ValueCell);
    if( pvalue == NULL ) {
        //
        // we couldn't map a view for the bin containing this cell
        //

        //
        // normally this shouldn't happen as we just allocated ValueCell
        // i.e. the bin containing ValueCell should be mapped in memory at this point.
        //
        ASSERT( FALSE );
        HvFreeCell(Hive, ValueCell);
        return STATUS_INSUFFICIENT_RESOURCES;
    }
    // release it right here, as the registry is locked exclusively, so we don't care
    HvReleaseCell(Hive, ValueCell);

    // sanity
    ASSERT_CELL_DIRTY(Hive,ValueCell);

    pvalue->u.KeyValue.Signature = CM_KEY_VALUE_SIGNATURE;

    //
    // fill in the variable portions of the new value entry,  name and
    // and data are copied from caller space, could fault.
    //
    try {

        //
        // fill in the name
        //
        pvalue->u.KeyValue.NameLength = CmpCopyName(Hive,
                                                    pvalue->u.KeyValue.Name,
                                                    ValueName);
    } except (EXCEPTION_EXECUTE_HANDLER) {
        CmKdPrintEx((DPFLTR_CONFIG_ID,CML_EXCEPTION,"!!CmSetValueKey: code:%08lx\n", GetExceptionCode()));

        //
        // We have bombed out loading user data, clean up and exit.
        //
        HvFreeCell(Hive, ValueCell);
        return GetExceptionCode();
    }

    if (pvalue->u.KeyValue.NameLength < ValueName->Length) {
        pvalue->u.KeyValue.Flags = VALUE_COMP_NAME;
    } else {
        pvalue->u.KeyValue.Flags = 0;
    }

    //
    // fill in the data
    //
    if (DataSize > CM_KEY_VALUE_SMALL) {
        Status = CmpSetValueDataNew(Hive,Data,DataSize,StorageType,ValueCell,&(pvalue->u.KeyValue.Data));
        if( !NT_SUCCESS(Status) ) {
            //
            // We have bombed out loading user data, clean up and exit.
            //
            HvFreeCell(Hive, ValueCell);
            return Status;
        }

        pvalue->u.KeyValue.DataLength = DataSize;
        // sanity
        ASSERT_CELL_DIRTY(Hive,pvalue->u.KeyValue.Data);

    } else {
        pvalue->u.KeyValue.DataLength = DataSize + CM_KEY_VALUE_SPECIAL_SIZE;
        pvalue->u.KeyValue.Data = TempData;
    }
    pvalue->u.KeyValue.Type = Type;

    if( !NT_SUCCESS(CmpAddValueToList(Hive,ValueCell,Index,StorageType,&(Parent->ValueList)) ) ) {
        // out of space, free all allocated stuff
        // this will free embeded cigdata cell info too (if any)
        CmpFreeValue(Hive,ValueCell);
        return STATUS_INSUFFICIENT_RESOURCES;
    }

    return STATUS_SUCCESS;
}

NTSTATUS
CmSetLastWriteTimeKey(
    IN PCM_KEY_CONTROL_BLOCK KeyControlBlock,
    IN PLARGE_INTEGER LastWriteTime
    )
/*++

Routine Description:

    The LastWriteTime associated with a key node can be set with
    CmSetLastWriteTimeKey

Arguments:

    KeyControlBlock - pointer to kcb for the key to operate on

    LastWriteTime - new time for key

Return Value:

    NTSTATUS - Result code from call, among the following:

        <TBS>

--*/
{
    PCM_KEY_NODE parent;
    PHHIVE      Hive;
    HCELL_INDEX Cell;
    NTSTATUS    status = STATUS_SUCCESS;

    CmKdPrintEx((DPFLTR_CONFIG_ID,CML_CM,"CmSetLastWriteTimeKey\n"));

    CmpLockRegistryExclusive();

    //
    // Check that we are not being asked to modify a key
    // that has been deleted
    //
    if (KeyControlBlock->Delete == TRUE) {
        status = STATUS_KEY_DELETED;
        goto Exit;
    }

    Hive = KeyControlBlock->KeyHive;
    Cell = KeyControlBlock->KeyCell;
    parent = (PCM_KEY_NODE)HvGetCell(Hive, Cell);
    if( parent == NULL ) {
        //
        // we couldn't map a view for the bin containing this cell
        //

        status = STATUS_INSUFFICIENT_RESOURCES;
        goto Exit;
    }

    // release the cell right here, as the registry is locked exclusively, so we don't care
    HvReleaseCell(Hive, Cell);

    if (! HvMarkCellDirty(Hive, Cell)) {
        status = STATUS_NO_LOG_SPACE;
        goto Exit;
    }

    parent->LastWriteTime = *LastWriteTime;
    // update the kcb cache too.
    KeyControlBlock->KcbLastWriteTime = *LastWriteTime;

Exit:

    CmpUnlockRegistry();
    return status;
}

NTSTATUS
CmSetKeyUserFlags(
    IN PCM_KEY_CONTROL_BLOCK    KeyControlBlock,
    IN ULONG                    UserFlags
    )
/*++

Routine Description:

    Sets the user defined flags for the key; At this point there are only 
    4 bits reserved for user defined flags. kcb and knode must be kept in 
    sync.

Arguments:

    KeyControlBlock - pointer to kcb for the key to operate on

    UserFlags - user defined flags to be set on this key.

Return Value:

    NTSTATUS - Result code from call, among the following:

        <TBS>

--*/
{
    PCM_KEY_NODE    Node;
    PHHIVE          Hive;
    HCELL_INDEX     Cell;
    LARGE_INTEGER   LastWriteTime;
    NTSTATUS        status = STATUS_SUCCESS;

    CmKdPrintEx((DPFLTR_CONFIG_ID,CML_CM,"CmSetKeyUserFlags\n"));

    CmpLockRegistryExclusive();

    //
    // Check that we are not being asked to modify a key
    // that has been deleted
    //
    if (KeyControlBlock->Delete == TRUE) {
        status = STATUS_KEY_DELETED;
        goto Exit;
    }

    if( UserFlags & (~((ULONG)KEY_USER_FLAGS_VALID_MASK)) ) {
        //
        // number of user defined flags exceeded; punt
        //
        status = STATUS_INVALID_PARAMETER;
        goto Exit;

    }

    Hive = KeyControlBlock->KeyHive;
    Cell = KeyControlBlock->KeyCell;

    Node = (PCM_KEY_NODE)HvGetCell(Hive, Cell);
    if( Node == NULL ) {
        //
        // we couldn't map a view for the bin containing this cell
        //

        status = STATUS_INSUFFICIENT_RESOURCES;
        goto Exit;
    }

    // release the cell right here, as the registry is locked exclusively, so we don't care
    HvReleaseCell(Hive, Cell);

    if (! HvMarkCellDirty(Hive, Cell)) {
        status = STATUS_NO_LOG_SPACE;
        goto Exit;
    }
    
    //
    // shift/(pack) the user defined flags and
    // update knode and kcb cache
    //
    // first, erase the old flags
    Node->Flags &= KEY_USER_FLAGS_CLEAR_MASK;
    Node->Flags |= (USHORT)(UserFlags<<KEY_USER_FLAGS_SHIFT);
    // update the kcb cache
    KeyControlBlock->Flags = Node->Flags;

    //
    // we need to update the LstWriteTime as well
    //
    KeQuerySystemTime(&LastWriteTime);
    Node->LastWriteTime = LastWriteTime;
    // update the kcb cache too.
    KeyControlBlock->KcbLastWriteTime = LastWriteTime;

Exit:
    CmpUnlockRegistry();
    return status;
}

BOOLEAN
CmpIsHiveAlreadyLoaded( IN HANDLE KeyHandle,
                        IN POBJECT_ATTRIBUTES SourceFile
                        )
/*++

Routine Description:

    Checks if the SourceFile is already loaded in the same spot as KeyHandle.

Arguments:

    KeyHandle - should be the root of a hive. We'll query the name of the primary file
                and compare it against the name of SourceFile

    SourceFile - specifies a file.  while file could be remote,
                that is strongly discouraged.

Return Value:

    TRUE/FALSE
--*/
{
    NTSTATUS                    status;
    PCM_KEY_BODY                KeyBody;
    BOOLEAN                     Result = FALSE; // pesimistic
    PCMHIVE                     CmHive;

    PAGED_CODE();

    ASSERT_CM_LOCK_OWNED_EXCLUSIVE();

    status = ObReferenceObjectByHandle(KeyHandle,
                                       0,
                                       CmpKeyObjectType,
                                       KernelMode,
                                       (PVOID *)(&KeyBody),
                                       NULL);
    if(!NT_SUCCESS(status)) {
        return FALSE;
    }
    
    CmHive = (PCMHIVE)CONTAINING_RECORD(KeyBody->KeyControlBlock->KeyHive, CMHIVE, Hive);

    //
    // should be the root of a hive
    // 
    if( !(KeyBody->KeyControlBlock->Flags & KEY_HIVE_ENTRY) || // not root of a hive
        (CmHive->FileUserName.Buffer == NULL)// no name captured
        ) {
        goto ExitCleanup;
    }
    
    if( RtlCompareUnicodeString(&(CmHive->FileUserName),
                                SourceFile->ObjectName,
                                TRUE) == 0 ) {
        //
        // same file; same spot
        //
        Result = TRUE;
        //
        // unfreeze the hive;hive will become just a regular hive from now on
        // it is safe to do this because we hold an extra refcount on the root of the hive
        // as we have specifically opened the root to check if it's already loaded
        //
        if( IsHiveFrozen(CmHive) ) {
            CmHive->Frozen = FALSE;
            if( CmHive->UnloadWorkItem != NULL ) {
                ExFreePool( CmHive->UnloadWorkItem );
                CmHive->UnloadWorkItem = NULL;
            }
            if( CmHive->RootKcb ) {
                CmpDereferenceKeyControlBlockWithLock(CmHive->RootKcb);
                CmHive->RootKcb = NULL;
            }

        }

    }
    
ExitCleanup:
    ObDereferenceObject((PVOID)KeyBody);
    return Result;
}


NTSTATUS
CmLoadKey(
    IN POBJECT_ATTRIBUTES TargetKey,
    IN POBJECT_ATTRIBUTES SourceFile,
    IN ULONG Flags
    )

/*++

Routine Description:

    A hive (file in the format created by NtSaveKey) may be linked
    into the active registry with this call.  UNLIKE NtRestoreKey,
    the file specified to NtLoadKey will become the actual backing
    store of part of the registry (that is, it will NOT be copied.)

    The file may have an associated .log file.

    If the hive file is marked as needing a .log file, and one is
    not present, the call will fail.

    The name specified by SourceFile must be such that ".log" can
    be appended to it to generate the name of the log file.  Thus,
    on FAT file systems, the hive file may not have an extension.

    This call is used by logon to make the user's profile available
    in the registry.  It is not intended for use doing backup,
    restore, etc.  Use NtRestoreKey for that.

    N.B.  This routine assumes that the object attributes for the file
          to be opened have been captured into kernel space so that
          they can safely be passed to the worker thread to open the file
          and do the actual I/O.

Arguments:

    TargetKey - specifies the path to a key to link the hive to.
                path must be of the form "\registry\user\<username>"

    SourceFile - specifies a file.  while file could be remote,
                that is strongly discouraged.

    Flags - specifies any flags that should be used for the load operation.
            The only valid flag is REG_NO_LAZY_FLUSH.

Return Value:

    NTSTATUS - values TBS.

--*/
{
    PCMHIVE                     NewHive;
    NTSTATUS                    Status;
    BOOLEAN                     Allocate;
    BOOLEAN                     RegistryLockAquired;
    SECURITY_QUALITY_OF_SERVICE ServiceQos;
    SECURITY_CLIENT_CONTEXT     ClientSecurityContext;
    HANDLE                      KeyHandle;



    //
    // Obtain the security context here so we can use it
    // later to impersonate the user, which we will do
    // if we cannot access the file as SYSTEM.  This
    // usually occurs if the file is on a remote machine.
    //
    ServiceQos.Length = sizeof(SECURITY_QUALITY_OF_SERVICE);
    ServiceQos.ImpersonationLevel = SecurityImpersonation;
    ServiceQos.ContextTrackingMode = SECURITY_DYNAMIC_TRACKING;
    ServiceQos.EffectiveOnly = TRUE;
    Status = SeCreateClientSecurity(CONTAINING_RECORD(KeGetCurrentThread(),ETHREAD,Tcb),
                                    &ServiceQos,
                                    FALSE,
                                    &ClientSecurityContext);
    if (!NT_SUCCESS(Status)) {
        return(Status);
    }

    //
    // we open the root of the hive here. if it already exists,this will prevent it from going
    // away from under us while we are doing the "already loaded" check (due to delay unload logic)
    //
    Status = ObOpenObjectByName(TargetKey,
                                CmpKeyObjectType,
                                KernelMode,
                                NULL,
                                KEY_READ,
                                NULL,
                                &KeyHandle);
    if(!NT_SUCCESS(Status)) {
        KeyHandle = NULL;
    }

    //
    // Do not lock the registry; Instead set the RegistryLockAquired member 
    // of REGISTRY_COMMAND so CmpWorker can lock it after opening the hive files
    //
    //CmpLockRegistryExclusive();
    //

    RegistryLockAquired = FALSE;
    Allocate = TRUE;
    Status = CmpCmdHiveOpen(    SourceFile,             // FileAttributes
                                &ClientSecurityContext, // ImpersonationContext
                                &Allocate,              // Allocate
                                &RegistryLockAquired,   // RegistryLockAquired
                                &NewHive,               // NewHive
								CM_CHECK_REGISTRY_CHECK_CLEAN //CheckFlags
                            );

    SeDeleteClientSecurity( &ClientSecurityContext );


    if (!NT_SUCCESS(Status)) {
        if( KeyHandle != NULL ) {
            //
            // lock the registry exclusive while we are checking attempt to load same file into the same spot
            //
            if( !RegistryLockAquired ) {
                CmpLockRegistryExclusive();
                RegistryLockAquired = TRUE;
            }
            
            //
            // check if the same file is loaded in the same spot
            //
            if( CmpIsHiveAlreadyLoaded(KeyHandle,SourceFile) ) {
                Status = STATUS_SUCCESS;
            }
        }
        
        if( RegistryLockAquired ) {
            // if CmpWorker has locked the registry, unlock it now.
            CmpUnlockRegistry();
        }

        if( KeyHandle != NULL ) {
            ZwClose(KeyHandle);
        }
        return(Status);
    } else {
        //
        // if we got here, CmpWorker should have locked the registry exclusive.
        //
        ASSERT( RegistryLockAquired );
    }

    //
    // if this is a NO_LAZY_FLUSH hive, set the appropriate bit.
    //
    if (Flags & REG_NO_LAZY_FLUSH) {
        NewHive->Hive.HiveFlags |= HIVE_NOLAZYFLUSH;
    }

    //
    // We now have a succesfully loaded and initialized CmHive, so we
    // just need to link that into the appropriate spot in the master hive.
    //
    Status = CmpLinkHiveToMaster(TargetKey->ObjectName,
                                 TargetKey->RootDirectory,
                                 NewHive,
                                 Allocate,
                                 TargetKey->SecurityDescriptor);

    if (NT_SUCCESS(Status)) {
        //
        // add new hive to hivelist
        //
        CmpAddToHiveFileList(NewHive);
        //
        // flush the hive right here if just created; this is to avoid situations where 
        // the lazy flusher doesn't get a chance to flush the hive, or it can't (because
        // the hive is a no_lazy_flush hive and it is never explicitly flushed)
        // 
        if( Allocate == TRUE ) {
            HvSyncHive(&(NewHive->Hive));
        }

    } else {
        LOCK_HIVE_LIST();
        CmpRemoveEntryList(&(NewHive->HiveList));
        UNLOCK_HIVE_LIST();

        CmpCheckForOrphanedKcbs((PHHIVE)NewHive);

        CmpDestroyHiveViewList(NewHive);
        CmpDestroySecurityCache (NewHive);
        CmpDropFileObjectForHive(NewHive);

        HvFreeHive((PHHIVE)NewHive);

        //
        // Close the hive files
        //
        CmpCmdHiveClose(NewHive);

        //
        // free the cm level structure
        //
        ASSERT( NewHive->HiveLock );
        ExFreePool(NewHive->HiveLock);
        ASSERT( NewHive->ViewLock );
        ExFreePool(NewHive->ViewLock);
        CmpFree(NewHive, sizeof(CMHIVE));
    }

    //
    // We've given user chance to log on, so turn on quota
    //
    if ((CmpProfileLoaded == FALSE) &&
        (CmpWasSetupBoot == FALSE)) {
        CmpProfileLoaded = TRUE;
        CmpSetGlobalQuotaAllowed();
    }

#ifdef CHECK_REGISTRY_USECOUNT
    CmpCheckRegistryUseCount();
#endif //CHECK_REGISTRY_USECOUNT

    CmpUnlockRegistry();

    if( KeyHandle != NULL ) {
        ZwClose(KeyHandle);
    }
    return(Status);
}

#if DBG
ULONG
CmpUnloadKeyWorker(
    PCM_KEY_CONTROL_BLOCK Current,
    PVOID                 Context1,
    PVOID                 Context2
    )
{
    PUNICODE_STRING ConstructedName;
    if (Current->KeyHive == Context1) {
        ConstructedName = CmpConstructName(Current);

        if (ConstructedName) {
            CmKdPrintEx((DPFLTR_CONFIG_ID,DPFLTR_TRACE_LEVEL,"%wZ\n", ConstructedName));
            ExFreePoolWithTag(ConstructedName, CM_NAME_TAG | PROTECTED_POOL);
        }
    }
    return KCB_WORKER_CONTINUE;   // always keep searching
}
#endif

NTSTATUS
CmUnloadKey(
    IN PHHIVE Hive,
    IN HCELL_INDEX Cell,
    IN PCM_KEY_CONTROL_BLOCK Kcb
    )

/*++

Routine Description:

    Unlinks a hive from its location in the registry, closes its file
    handles, and deallocates all its memory.

    There must be no key control blocks currently referencing the hive
    to be unloaded.

Arguments:

    Hive - Supplies a pointer to the hive control structure for the
           hive to be unloaded

    Cell - supplies the HCELL_INDEX for the root cell of the hive.

    Kcb - Supplies the key control block

Return Value:

    NTSTATUS

--*/

{
    PCMHIVE CmHive;
    BOOLEAN Success;

    CmKdPrintEx((DPFLTR_CONFIG_ID,CML_CM,"CmUnloadKey\n"));

    //
    // Make sure the cell passed in is the root cell of the hive.
    //
    if (Cell != Hive->BaseBlock->RootCell) {
        return(STATUS_INVALID_PARAMETER);
    }

    //
    // Make sure there are no open references to key control blocks
    // for this hive.  If there are none, then we can unload the hive.
    //

    CmHive = CONTAINING_RECORD(Hive, CMHIVE, Hive);
    if(Kcb->RefCount != 1) {
        Success = (CmpSearchForOpenSubKeys(Kcb,SearchIfExist) == 0);
        Success = Success && (Kcb->RefCount == 1);
        
        if( Success == FALSE) {
#if DBG
            CmKdPrintEx((DPFLTR_CONFIG_ID,DPFLTR_TRACE_LEVEL,"List of keys open against hive unload was attempted on:\n"));
            CmpSearchKeyControlBlockTree(
                CmpUnloadKeyWorker,
                Hive,
                NULL
                );
#endif
            return STATUS_CANNOT_DELETE;
        }
    }
    
    ASSERT( Kcb->RefCount == 1 );

    //
    // Flush any dirty data to disk. If this fails, too bad.
    //
    CmFlushKey(Hive, Cell);

    //
    // Remove the hive from the HiveFileList
    //
    CmpRemoveFromHiveFileList((PCMHIVE)Hive);

    //
    // Unlink from master hive, remove from list
    //
    Success = CmpDestroyHive(Hive, Cell);

    if (Success) {
        //
        // signal the user event (if any), then do the cleanup (i.e. deref the event
        // and the artificial refcount we set on the root kcb)
        //
        if( CmHive->UnloadEvent != NULL ) {
            KeSetEvent(CmHive->UnloadEvent,0,FALSE);
            ObDereferenceObject(CmHive->UnloadEvent);
        }

        CmpDestroyHiveViewList(CmHive);
        CmpDestroySecurityCache (CmHive);
        CmpDropFileObjectForHive(CmHive);

        HvFreeHive(Hive);

        //
        // Close the hive files
        //
        CmpCmdHiveClose(CmHive);

        //
        // free the cm level structure
        //
        ASSERT( CmHive->HiveLock );
        ExFreePool(CmHive->HiveLock);
        ASSERT( CmHive->ViewLock );
        ExFreePool(CmHive->ViewLock);
        CmpFree(CmHive, sizeof(CMHIVE));

        return(STATUS_SUCCESS);
    } else {
        return(STATUS_INSUFFICIENT_RESOURCES);
    }

}

#ifdef NT_UNLOAD_KEY_EX
NTSTATUS
CmUnloadKeyEx(
    IN PCM_KEY_CONTROL_BLOCK kcb,
    IN PKEVENT UserEvent
    )

/*++

Routine Description:

    First tries to unlink the hive, by calling the sync version
    
    If the hive cannot be unloaded (there are open handles inside it),
    reference the root of the hive (i.e. kcb) and freeze the hive.

Arguments:

    Kcb - Supplies the key control block

    UserEvent - the event to be signaled after the hive was unloaded
                (only if late - unload is needed)

Return Value:

    STATUS_PENDING - the hive was frozen and it'll be unloaded later

    STATUS_SUCCESS - the hive was successfully sync-unloaded (no need 
                to signal for UserEvent)

    <other> - an error occured, operation failed

--*/
{
    PCMHIVE         CmHive;
    HCELL_INDEX     Cell;    
    NTSTATUS        Status;

    PAGED_CODE();

    Cell = kcb->KeyCell;
    CmHive = (PCMHIVE)CONTAINING_RECORD(kcb->KeyHive, CMHIVE, Hive);

    if( IsHiveFrozen(CmHive) ) {
        //
        // don't let them hurt themselves by calling it twice
        //
        return STATUS_TOO_LATE;
    }
    //
    // first, try out he sync routine; this may or may not unload the hive,
    // but at least will kick kcbs with refcount = 0 out of cache
    //
    Status = CmUnloadKey(&(CmHive->Hive),Cell,kcb);
    if( Status != STATUS_CANNOT_DELETE ) {
        //
        // the hive was either unloaded, or some bad thing happened
        //
        return Status;
    }

    ASSERT( kcb->RefCount > 1 );
    ASSERT_CM_LOCK_OWNED_EXCLUSIVE();

    //
    // Prepare for late-unloading:
    // 1. reference the kcb, to make sure it won't go away without us noticing
    //  (we have the registry locked in exclusive mode, so we don't need to lock the kcbtree
    //
    if (!CmpReferenceKeyControlBlock(kcb)) {
        return STATUS_INSUFFICIENT_RESOURCES;
    }

	//
	// parse the kcb tree and mark all open kcbs inside this hive and "no delay close"
	//
    CmpSearchForOpenSubKeys(kcb,SearchAndTagNoDelayClose);
	kcb->ExtFlags |= CM_KCB_NO_DELAY_CLOSE;

    //
    // 2. Freeze the hive
    //
    CmHive->RootKcb = kcb;
    CmHive->Frozen = TRUE;
    CmHive->UnloadEvent = UserEvent;

    return STATUS_PENDING;
}

#endif //NT_UNLOAD_KEY_EX

// define in cmworker.c
extern BOOLEAN CmpForceForceFlush;

BOOLEAN
CmpDoFlushAll(
    BOOLEAN ForceFlush
    )
/*++

Routine Description:

    Flush all hives.

    Runs in the context of the CmpWorkerThread.

    Runs down list of Hives and applies HvSyncHive to them.

    NOTE: Hives which are marked as HV_NOLAZYFLUSH are *NOT* flushed
          by this call.  You must call HvSyncHive explicitly to flush
          a hive marked as HV_NOLAZYFLUSH.

Arguments:

    ForceFlush - used as a contingency plan when a prior exception left 
                some hive in a used state. When set to TRUE, assumes the 
                registry is locked exclusive. It also repairs the broken 
                hives.

               - When FALSE saves only the hives with UseCount == 0.

Return Value:

    NONE

Notes:

    If any of the hives is about to shrink CmpForceForceFlush is set to TRUE, 
    otherwise, it is set to FALSE

--*/
{
    NTSTATUS    Status;
    PLIST_ENTRY p;
    PCMHIVE     h;
    BOOLEAN     Result = TRUE;    
/*
    ULONG rc;
*/
    extern PCMHIVE CmpMasterHive;

    //
    // If writes are not working, lie and say we succeeded, will
    // clean up in a short time.  Only early system init code
    // will ever know the difference.
    //
    if (CmpNoWrite) {
        return TRUE;
    }
    
    CmpForceForceFlush = FALSE;

    //
    // traverse list of hives, sync each one
    //
    LOCK_HIVE_LIST();
    p = CmpHiveListHead.Flink;
    while (p != &CmpHiveListHead) {

        h = CONTAINING_RECORD(p, CMHIVE, HiveList);

        if (!(h->Hive.HiveFlags & HIVE_NOLAZYFLUSH)) {

            //
            //Lock the hive before we flush it.
            //-- since we now allow multiple readers
            // during a flush (a flush is considered a read)
            // we have to force a serialization on the vector table
            //
            CmLockHive (h);
            
            if( (ForceFlush == TRUE) &&  (h->UseCount != 0) ) {
                //
                // hive was left in an instable state by a prior exception raised 
                // somewhere inside a CM function.
                //
                ASSERT_CM_LOCK_OWNED_EXCLUSIVE();
                CmpFixHiveUsageCount(h);
                ASSERT( h->UseCount == 0 );
            }

            
            if( (ForceFlush == TRUE) || (!HvHiveWillShrink((PHHIVE)h)) ) {
                CmKdPrintEx((DPFLTR_CONFIG_ID,CML_IO,"CmpDoFlushAll hive = %p ForceFlush = %lu IsHiveShrinking = %lu BaseLength = %lx StableLength = %lx\n",
                    h,(ULONG)ForceFlush,(ULONG)HvHiveWillShrink((PHHIVE)h),((PHHIVE)h)->BaseBlock->Length,((PHHIVE)h)->Storage[Stable].Length));
                Status = HvSyncHive((PHHIVE)h);

                if( !NT_SUCCESS( Status ) ) {
                    Result = FALSE;
                }
            } else {
                CmKdPrintEx((DPFLTR_CONFIG_ID,DPFLTR_TRACE_LEVEL,"CmpDoFlushAll: Fail to flush hive %p because is shrinking\n",h));
                Result = FALSE;
                //
                // another unsuccessful attempt to save this hive, because we needed the reglock exclisive
                //
                CmpForceForceFlush = TRUE;
            }

            CmUnlockHive (h);
            //
            // WARNNOTE - the above means that a lazy flush or
            //            or shutdown flush did not work.  we don't
            //            know why.  there is noone to report an error
            //            to, so continue on and hope for the best.
            //            (in theory, worst that can happen is user changes
            //             are lost.)
            //
        }


        p = p->Flink;
    }
    UNLOCK_HIVE_LIST();
    
    return Result;
}


NTSTATUS
CmReplaceKey(
    IN PHHIVE Hive,
    IN HCELL_INDEX Cell,
    IN PUNICODE_STRING NewHiveName,
    IN PUNICODE_STRING OldFileName
    )

/*++

Routine Description:

    Renames the hive file for a running system and replaces it with a new
    file.  The new file is not actually used until the next boot.

Arguments:

    Hive - Supplies a hive control structure for the hive to be replaced.

    Cell - Supplies the HCELL_INDEX of the root cell of the hive to be
           replaced.

    NewHiveName - Supplies the name of the file which is to be installed
            as the new hive.

    OldFileName - Supplies the name of the file which the existing hive
            file is to be renamed to.

Return Value:

    NTSTATUS

--*/

{
    CHAR                        ObjectInfoBuffer[512];
    NTSTATUS                    Status;
    NTSTATUS                    Status2;
    OBJECT_ATTRIBUTES           Attributes;
    PCMHIVE                     NewHive;
    PCMHIVE                     CmHive; 
    POBJECT_NAME_INFORMATION    NameInfo;
    ULONG                       OldQuotaAllowed;
    ULONG                       OldQuotaWarning;
    BOOLEAN                     Allocate;
    BOOLEAN                     RegistryLockAquired;

    UNREFERENCED_PARAMETER (Cell);
    CmpLockRegistryExclusive();

#ifdef CHECK_REGISTRY_USECOUNT
    CmpCheckRegistryUseCount();
#endif //CHECK_REGISTRY_USECOUNT

    if (Hive->HiveFlags & HIVE_HAS_BEEN_REPLACED) {
        CmpUnlockRegistry();
        return STATUS_FILE_RENAMED;
    }

    //
    // temporarily disable registry quota as we will be giving this memory back immediately!
    //
    OldQuotaAllowed = CmpGlobalQuotaAllowed;
    OldQuotaWarning = CmpGlobalQuotaWarning;
    CmpGlobalQuotaAllowed = CM_WRAP_LIMIT;
    CmpGlobalQuotaWarning = CM_WRAP_LIMIT;

    //
    // First open the new hive file and check to make sure it is valid.
    //
    InitializeObjectAttributes(&Attributes,
                               NewHiveName,
                               OBJ_CASE_INSENSITIVE,
                               NULL,
                               NULL);

    Allocate = FALSE;
    RegistryLockAquired = TRUE;
    Status = CmpCmdHiveOpen(    &Attributes,            // FileAttributes
                                NULL,                   // ImpersonationContext
                                &Allocate,              // Allocate
                                &RegistryLockAquired,   // RegistryLockAquired
                                &NewHive,               // NewHive
								CM_CHECK_REGISTRY_CHECK_CLEAN // CheckFlags
                            );

    
    if (!NT_SUCCESS(Status)) {
        goto ErrorExit;
    }
    ASSERT(Allocate == FALSE);

    if( Hive == (PHHIVE)(CmpMachineHiveList[SYSTEM_HIVE_INDEX].CmHive) ) {
        //
        // Somebody attempts to replace the system hive: do the WPA test
        //
        HCELL_INDEX Src,Dest;

        Status = CmpCheckReplaceHive(Hive,&Src);
        if( !NT_SUCCESS(Status) ) {
            goto ErrorCleanup;
        }
        Status = CmpCheckReplaceHive((PHHIVE)NewHive,&Dest);
        if( !NT_SUCCESS(Status) ) {
            goto ErrorCleanup;
        }

        ASSERT( Src != HCELL_NIL );
        ASSERT( Dest != HCELL_NIL );
        //
        // now stuff the current WPA subtree into the new hive
        //
        if( !CmpSyncTrees(Hive, Src, (PHHIVE)NewHive, Dest, FALSE ) ) {
            Status = STATUS_REGISTRY_CORRUPT;
            goto ErrorCleanup;
        }

        //
        // commit the changes we've made in the destination hive
        //
        if( !HvSyncHive((PHHIVE)NewHive) ) {
            Status = STATUS_REGISTRY_CORRUPT;
            goto ErrorCleanup;
        }
    }
    //
    // The new hive exists, and is consistent, and we have it open.
    // Now rename the current hive file.
    //
    CmHive = (PCMHIVE)CONTAINING_RECORD(Hive, CMHIVE, Hive);
    Status = CmpCmdRenameHive(  CmHive,                                     // CmHive
                                (POBJECT_NAME_INFORMATION)ObjectInfoBuffer, // OldName
                                OldFileName,                                // NewName
                                sizeof(ObjectInfoBuffer)                    // NameInfoLength
                                );

    if (!NT_SUCCESS(Status)) {
        //
        // rename failed, close the files associated with the new hive
        //
        goto ErrorCleanup;
    }

    //
    // The existing hive was successfully renamed, so try to rename the
    // new file to what the old hive file was named.  (which was returned
    // into ObjectInfoBuffer by the worker thread)
    //
    Hive->HiveFlags |= HIVE_HAS_BEEN_REPLACED;
    NameInfo = (POBJECT_NAME_INFORMATION)ObjectInfoBuffer;

    Status = CmpCmdRenameHive(  NewHive,        // CmHive
                                NULL,           // OldName
                                &NameInfo->Name,// NewName
                                0               // NameInfoLength
                            );
   
    if (!NT_SUCCESS(Status)) {

        //
        // We are in trouble now.  We have renamed the existing hive file,
        // but we couldn't rename the new hive file!  Try to rename the
        // existing hive file back to where it was.
        //

        CmHive = (PCMHIVE)CONTAINING_RECORD(Hive, CMHIVE, Hive);
        Status2 = CmpCmdRenameHive( CmHive,             // CmHive            
                                    NULL,               // OldName
                                    &NameInfo->Name,    // NewName
                                    0                   // NameInfoLength
                                );
        
        if (!NT_SUCCESS(Status2)) {

            CmKdPrintEx((DPFLTR_CONFIG_ID,CML_BUGCHECK,"CmReplaceKey: renamed existing hive file, but couldn't\n"));
            CmKdPrintEx((DPFLTR_CONFIG_ID,CML_BUGCHECK,"              rename new hive file (%08lx) ",Status));
            CmKdPrintEx((DPFLTR_CONFIG_ID,CML_BUGCHECK," or replace old hive file (%08lx)!\n",Status2));

            //
            // WARNNOTE:
            //      To get into this state, the user must have relevent
            //      privileges, deliberately mess with system in an attempt
            //      to defeat it, AND get it done in a narrow timing window.
            //
            //      Further, if it's a user profile, the system will
            //      still come up.
            //
            //      Therefore, return an error code and go on.
            //

            Status = STATUS_REGISTRY_CORRUPT;

        }
    } else {
        //
        // flush file buffers (we are particulary interested in ValidDataLength to be updated on-disk)
        //
        IO_STATUS_BLOCK IoStatus;
        Status = ZwFlushBuffersFile(NewHive->FileHandles[HFILE_TYPE_PRIMARY],&IoStatus);
        if (!NT_SUCCESS(Status)) {
            //
            // failed to set ValidDataLength, close the files associated with the new hive
            //

            //
            // We are in trouble now.  We have renamed the existing hive file,
            // but we couldn't rename the new hive file!  Try to rename the
            // existing hive file back to where it was.
            //

            CmHive = (PCMHIVE)CONTAINING_RECORD(Hive, CMHIVE, Hive);
            Status2 = CmpCmdRenameHive( CmHive,             // CmHive            
                                        NULL,               // OldName
                                        &NameInfo->Name,    // NewName
                                        0                   // NameInfoLength
                                    );
        
            if (!NT_SUCCESS(Status2)) {

                CmKdPrintEx((DPFLTR_CONFIG_ID,CML_BUGCHECK,"CmReplaceKey: renamed existing hive file, but couldn't\n"));
                CmKdPrintEx((DPFLTR_CONFIG_ID,CML_BUGCHECK,"              rename new hive file (%08lx) ",Status));
                CmKdPrintEx((DPFLTR_CONFIG_ID,CML_BUGCHECK," or replace old hive file (%08lx)!\n",Status2));

                //
                // WARNNOTE:
                //      To get into this state, the user must have relevent
                //      privileges, deliberately mess with system in an attempt
                //      to defeat it, AND get it done in a narrow timing window.
                //
                //      Further, if it's a user profile, the system will
                //      still come up.
                //
                //      Therefore, return an error code and go on.
                //

                Status = STATUS_REGISTRY_CORRUPT;

            }
        }
    }
    //
    // All of the renaming is done.  However, we are holding an in-memory
    // image of the new hive.  Release it, since it will not actually
    // be used until next boot.
    //
    // Do not close the open file handles to the new hive, we need to
    // keep it locked exclusively until the system is rebooted to prevent
    // people from mucking with it.
    //
ErrorCleanup:

    LOCK_HIVE_LIST();
    CmpRemoveEntryList(&(NewHive->HiveList));
    UNLOCK_HIVE_LIST();

    CmpDestroyHiveViewList(NewHive);
    CmpDestroySecurityCache(NewHive);
    CmpDropFileObjectForHive(NewHive);

    HvFreeHive((PHHIVE)NewHive);

    //
    // only close handles on error
    //
    if( !NT_SUCCESS(Status) ) {
        CmpCmdHiveClose(NewHive);
    }

    ASSERT( NewHive->HiveLock );
    ExFreePool(NewHive->HiveLock);
    ASSERT( NewHive->ViewLock );
    ExFreePool(NewHive->ViewLock);
    CmpFree(NewHive, sizeof(CMHIVE));

ErrorExit:
    //
    // Set global quota back to what it was.
    //
    CmpGlobalQuotaAllowed = OldQuotaAllowed;
    CmpGlobalQuotaWarning = OldQuotaWarning;

#ifdef CHECK_REGISTRY_USECOUNT
    CmpCheckRegistryUseCount();
#endif //CHECK_REGISTRY_USECOUNT

    CmpUnlockRegistry();
    return(Status);
}

#ifdef NT_RENAME_KEY

ULONG
CmpComputeKcbConvKey(
    PCM_KEY_CONTROL_BLOCK   KeyControlBlock
    );

NTSTATUS
CmRenameKey(
    IN PCM_KEY_CONTROL_BLOCK    KeyControlBlock,
    IN UNICODE_STRING           NewKeyName         // RAW
    )
/*++

Routine Description:

    Changes the name of the key to the given one.

    What needs to be done:
    
    1. Allocate a cell big enough to accomodate new knode 
    2. make a duplicate of the index in subkeylist of kcb's parent
    3. replace parent's subkeylist with the duplicate
    4. add new subkey to parent
    5. remove old subkey
    6. free storage.

Arguments:

    KeyControlBlock - pointer to kcb for key to operate on

    NewKeyName - The new name to be given to this key

Return Value:

    NTSTATUS - Result code from call, among the following:

        <TBS>

Comments:

    What do we do with symbolic links?
--*/
{
    NTSTATUS                Status;
    PHHIVE                  Hive;
    HCELL_INDEX             Cell;
    PCM_KEY_NODE            Node;
    PCM_KEY_NODE            ParentNode;
    ULONG                   NodeSize;
    HCELL_INDEX             NewKeyCell = HCELL_NIL;
    HSTORAGE_TYPE           StorageType;
    HCELL_INDEX             OldSubKeyList = HCELL_NIL;
    PCM_KEY_NODE            NewKeyNode;
    PCM_KEY_INDEX           Index;
    ULONG                   i;
    LARGE_INTEGER           TimeStamp;
    ULONG                   NameLength;
    PCM_NAME_CONTROL_BLOCK  OldNcb;
    ULONG                   ConvKey;

    CmKdPrintEx((DPFLTR_CONFIG_ID,CML_CM,"CmRenameKey\n"));

    ASSERT_CM_LOCK_OWNED_EXCLUSIVE();

    //
    // no edits, on keys marked for deletion
    //
    if (KeyControlBlock->Delete) {
        return STATUS_KEY_DELETED;
    }

    //
    // see if the newName is not already a subkey of parentKcb
    //
    Hive = KeyControlBlock->KeyHive;
    Cell = KeyControlBlock->KeyCell;
    StorageType = HvGetCellType(Cell);

    //
    // OBS. we could have worked with the kcb tree instead, but if this is not 
    // going to work, we are in trouble anyway, so it's better to find out soon
    //
    Node = (PCM_KEY_NODE)HvGetCell(Hive,Cell);
    if( Node == NULL ) {
        //
        // cannot map view
        //
        return STATUS_INSUFFICIENT_RESOURCES;
    }

    // release the cell right here, as the registry is locked exclusively, so we don't care
    HvReleaseCell(Hive, Cell);

    //
    // cannot rename the root of a hive; or anything in the master hive !!!
    //
    if((Hive == &CmpMasterHive->Hive) || (KeyControlBlock->ParentKcb == NULL) || (KeyControlBlock->ParentKcb->KeyHive == &CmpMasterHive->Hive) ) {
        return STATUS_ACCESS_DENIED;
    }

    ParentNode = (PCM_KEY_NODE)HvGetCell(Hive,Node->Parent);
    if( ParentNode == NULL ) {
        //
        // cannot map view
        //
        return STATUS_INSUFFICIENT_RESOURCES;
    }
    
    // release the cell right here, as the registry is locked exclusively, so we don't care
    HvReleaseCell(Hive, Node->Parent);

    try {
        if( CmpFindSubKeyByName(Hive,ParentNode,&NewKeyName) != HCELL_NIL ) {
            //
            // a subkey with this name already exists
            //
            return STATUS_CANNOT_DELETE;
        }

        //
        // since we are in try-except, compute the new node size
        //
        NodeSize = CmpHKeyNodeSize(Hive, &NewKeyName);

    } except (EXCEPTION_EXECUTE_HANDLER) {
        CmKdPrintEx((DPFLTR_CONFIG_ID,CML_EXCEPTION,"!!CmRenameKey: code:%08lx\n", GetExceptionCode()));
        return GetExceptionCode();
    }    
    
    //
    // 1. Allocate the new knode cell and copy the data from the old one, updating 
    // the name. 
    
    //
    // mark the parent dirty, as we will modify its SubkeyLists
    //
    if(!HvMarkCellDirty(Hive, Node->Parent)) {
        return STATUS_NO_LOG_SPACE;
    }

    //
    // mark the index dirty as we are going to free it on success
    //
    if ( !CmpMarkIndexDirty(Hive, Node->Parent, Cell) ) {
        return STATUS_NO_LOG_SPACE;
    }
    //
    // mark key_node as dirty as we are going to free it if we succeed
    //
    if(!HvMarkCellDirty(Hive, Cell)) {
        return STATUS_NO_LOG_SPACE;
    }
   
    OldSubKeyList = ParentNode->SubKeyLists[StorageType];       
    ASSERT( OldSubKeyList != HCELL_NIL );
    if(!HvMarkCellDirty(Hive, OldSubKeyList)) {
        return STATUS_NO_LOG_SPACE;
    }
    Index = (PCM_KEY_INDEX)HvGetCell(Hive,OldSubKeyList);
    if( Index == NULL ) {
        //
        // this is a bad joke; we just marked this dirty
        //
        ASSERT( FALSE );
        Status = STATUS_INSUFFICIENT_RESOURCES;
        goto ErrorExit;
    }
    // release the cell right here, as the registry is locked exclusively, so we don't care
    HvReleaseCell(Hive, OldSubKeyList);

    //
    // mark all the index cells dirty
    //
    if( Index->Signature == CM_KEY_INDEX_ROOT ) {
        //
        // it's a root
        //
        for(i=0;i<Index->Count;i++) {
            // common sense
            ASSERT( (Index->List[i] != 0) && (Index->List[i] != HCELL_NIL) );
            if(!HvMarkCellDirty(Hive, Index->List[i])) {
                return STATUS_NO_LOG_SPACE;
            }
        }

    } 


    NewKeyCell = HvAllocateCell(
                    Hive,
                    NodeSize,
                    StorageType,
                    Cell // in the same vicinity
                    );
    if( NewKeyCell == HCELL_NIL ) {
        return STATUS_INSUFFICIENT_RESOURCES;
    }
    
    NewKeyNode = (PCM_KEY_NODE)HvGetCell(Hive,NewKeyCell);
    if( NewKeyNode == NULL ) {
        //
        // cannot map view; this shouldn't happen as we just allocated 
        // this cell (i.e. it should be dirty/pinned into memory)
        //
        ASSERT( FALSE );
        Status = STATUS_INSUFFICIENT_RESOURCES;
        goto ErrorExit;
    }
    // release the cell right here, as the registry is locked exclusively, so we don't care
    HvReleaseCell(Hive, NewKeyCell);

    //
    // copy old keynode info onto the new cell and update the name
    //
    // first everything BUT the name
    RtlCopyMemory(NewKeyNode,Node,FIELD_OFFSET(CM_KEY_NODE, Name));
    // second, the new name
    try {
        NewKeyNode->NameLength = CmpCopyName(   Hive,
                                                NewKeyNode->Name,
                                                &NewKeyName);
        NameLength = NewKeyName.Length;

        if (NewKeyNode->NameLength < NameLength ) {
            NewKeyNode->Flags |= KEY_COMP_NAME;
        } else {
            NewKeyNode->Flags &= ~KEY_COMP_NAME;
        }
    } except (EXCEPTION_EXECUTE_HANDLER) {
        CmKdPrintEx((DPFLTR_CONFIG_ID,CML_EXCEPTION,"!!CmRenameKey: code:%08lx\n", GetExceptionCode()));
        Status = GetExceptionCode();
        goto ErrorExit;
    }    
    // third, the timestamp
    KeQuerySystemTime(&TimeStamp);
    NewKeyNode->LastWriteTime = TimeStamp;
    
    //
    // at this point we have the new key_node all built up.
    //

    //
    // 2.3. Make a duplicate of the parent's subkeylist and replace the original
    //
    ParentNode->SubKeyLists[StorageType] = CmpDuplicateIndex(Hive,OldSubKeyList,StorageType);
    if( ParentNode->SubKeyLists[StorageType] == HCELL_NIL ) {
        Status = STATUS_INSUFFICIENT_RESOURCES;
        goto ErrorExit;
    }

    //
    // 4. Add new subkey to the parent. This will take care of index 
    // grow and rebalance problems. 
    // Note: the index is at this point a duplicate, so if we fail, we still have the 
    // original one handy to recover
    //
    if( !CmpAddSubKey(Hive,Node->Parent,NewKeyCell) ) {
        Status = STATUS_INSUFFICIENT_RESOURCES;
        goto ErrorExit;
    }

    //
    // 5. remove old subkey;
    //
    if( !CmpRemoveSubKey(Hive,Node->Parent,Cell) ) {
        Status = STATUS_INSUFFICIENT_RESOURCES;
        goto ErrorExit;
    }

    //
    // 5'. update the parent on each and every son.
    //
    if( !CmpUpdateParentForEachSon(Hive,NewKeyCell) ) {
        Status = STATUS_INSUFFICIENT_RESOURCES;
        goto ErrorExit;
    }

    //
    // update the NCB in the kcb; at the end of this function, the kcbs underneath this 
    // will eventually get rehashed
    //
    OldNcb = KeyControlBlock->NameBlock;
    try {
        KeyControlBlock->NameBlock = CmpGetNameControlBlock (&NewKeyName);
    } except (EXCEPTION_EXECUTE_HANDLER) {
        CmKdPrintEx((DPFLTR_CONFIG_ID,CML_EXCEPTION,"!!CmRenameKey: code:%08lx\n", GetExceptionCode()));
        Status = GetExceptionCode();
        goto ErrorExit;
    }    

    //
    // 6. At this point we have it all done. We just need to free the old index and key_cell
    //
    
    //
    // free old index
    //
    Index = (PCM_KEY_INDEX)HvGetCell(Hive,OldSubKeyList);
    if( Index == NULL ) {
        //
        // this is a bad joke; we just marked this dirty
        //
        ASSERT( FALSE );
        Status = STATUS_INSUFFICIENT_RESOURCES;
        goto ErrorExit;
    }
    // release the cell right here, as the registry is locked exclusively, so we don't care
    HvReleaseCell(Hive, OldSubKeyList);

    if( Index->Signature == CM_KEY_INDEX_ROOT ) {
        //
        // it's a root
        //
        for(i=0;i<Index->Count;i++) {
            // common sense
            ASSERT( (Index->List[i] != 0) && (Index->List[i] != HCELL_NIL) );
            HvFreeCell(Hive, Index->List[i]);
        }

    } else {
        //
        // should be a leaf 
        //
        ASSERT((Index->Signature == CM_KEY_INDEX_LEAF)  ||
               (Index->Signature == CM_KEY_FAST_LEAF)   ||
               (Index->Signature == CM_KEY_HASH_LEAF)
               );
        ASSERT(Index->Count != 0);
    }
    HvFreeCell(Hive, OldSubKeyList);
    
    //
    // free old cell
    //
    HvFreeCell(Hive,Cell);

    //
    // update the node KeyCell for this kcb and the timestamp on the kcb;
    //
    KeyControlBlock->KeyCell = NewKeyCell;
    KeyControlBlock->KcbLastWriteTime = TimeStamp;

    //
    // and one last "little" thing: update parent's maxnamelen and reset parents cache
    //
    CmpCleanUpSubKeyInfo (KeyControlBlock->ParentKcb);

    if (ParentNode->MaxNameLen < NameLength) {
        ParentNode->MaxNameLen = NameLength;
        KeyControlBlock->ParentKcb->KcbMaxNameLen = (USHORT)NameLength;
    }
    
    //
    // rehash this kcb
    //
    ConvKey = CmpComputeKcbConvKey(KeyControlBlock);
    if( ConvKey != KeyControlBlock->ConvKey ) {
        //
        // rehash the kcb by removing it from hash, and then inserting it
        // again with th new ConvKey
        //
        CmpRemoveKeyHash(&(KeyControlBlock->KeyHash));
        KeyControlBlock->ConvKey = ConvKey;
        CmpInsertKeyHash(&(KeyControlBlock->KeyHash),FALSE);
    }

    //
    // Aditional work: take care of the kcb subtree; this cannot fail, punt
    //
    CmpSearchForOpenSubKeys(KeyControlBlock,SearchAndRehash);

    //
    // last, dereference the OldNcb for this kcb
    //
    ASSERT( OldNcb != NULL );
    CmpDereferenceNameControlBlockWithLock(OldNcb);

    return STATUS_SUCCESS;

ErrorExit:
    if( OldSubKeyList != HCELL_NIL ) {
        //
        // we have attempted (maybe even succedded) to duplicate parent's index)
        //
        if( ParentNode->SubKeyLists[StorageType] != HCELL_NIL ) {
            //
            // we need to free this as it is a duplicate
            //
            Index = (PCM_KEY_INDEX)HvGetCell(Hive,ParentNode->SubKeyLists[StorageType]);
            if( Index == NULL ) {
                //
                // could not map view;this shouldn't happen as we just allocated this cell
                //
                ASSERT( FALSE );
            } else {
                // release the cell right here, as the registry is locked exclusively, so we don't care
                HvReleaseCell(Hive, ParentNode->SubKeyLists[StorageType]);

                if( Index->Signature == CM_KEY_INDEX_ROOT ) {
                    //
                    // it's a root
                    //
                    for(i=0;i<Index->Count;i++) {
                        // common sense
                        ASSERT( (Index->List[i] != 0) && (Index->List[i] != HCELL_NIL) );
                        HvFreeCell(Hive, Index->List[i]);
                    }

                } else {
                    //
                    // should be a leaf 
                    //
                    ASSERT((Index->Signature == CM_KEY_INDEX_LEAF)  ||
                           (Index->Signature == CM_KEY_FAST_LEAF)   ||
                           (Index->Signature == CM_KEY_HASH_LEAF)
                           );
                    ASSERT(Index->Count != 0);
                }
                HvFreeCell(Hive, ParentNode->SubKeyLists[StorageType]);
            }

        }
        //
        // restore the parent's index
        //
        ParentNode->SubKeyLists[StorageType] = OldSubKeyList;
    }
    ASSERT( NewKeyCell != HCELL_NIL );
    HvFreeCell(Hive,NewKeyCell);
    
    if( OldNcb != NULL ) {
        KeyControlBlock->NameBlock = OldNcb;
    }
    
    return Status;
}
#endif

NTSTATUS
CmMoveKey(
    IN PCM_KEY_CONTROL_BLOCK    KeyControlBlock
    )
/*++

Routine Description:

    Moves all the cells related to this kcb above the specified fileoffset.

    What needs to be done:
    
    1. mark all data that we are going to touch dirty
    2. Duplicate the key_node (and values and all cells involved)
    3. Update the parent for all children
    4. replace the new Key_cell in the parent's subkeylist
    5. Update the kcb and the kcb cache
    6. remove old subkey

WARNING:
    after 3 we cannot fail anymore. if we do, we'll leak cells.

Arguments:

    KeyControlBlock - pointer to kcb for key to operate on

Return Value:

    NTSTATUS - Result code from call, among the following:

        <TBS>

--*/
{
    NTSTATUS                Status;
    PHHIVE                  Hive;
    HCELL_INDEX             OldKeyCell;
    HCELL_INDEX             NewKeyCell = HCELL_NIL;
    HCELL_INDEX             ParentKeyCell;
    HSTORAGE_TYPE           StorageType;
    PCM_KEY_NODE            OldKeyNode;
    PCM_KEY_NODE            ParentKeyNode;
    PCM_KEY_NODE            NewKeyNode;
    PCM_KEY_INDEX           ParentIndex;
    PCM_KEY_INDEX           OldIndex;
    ULONG                   i,j;
    HCELL_INDEX             LeafCell;
    PCM_KEY_INDEX           Leaf;
    PCM_KEY_FAST_INDEX      FastIndex;
    PHCELL_INDEX            ParentIndexLocation = NULL;

    PAGED_CODE();

    CmKdPrintEx((DPFLTR_CONFIG_ID,CML_CM,"CmMoveKey\n"));

    ASSERT_CM_LOCK_OWNED_EXCLUSIVE();

    //
    // no edits, on keys marked for deletion
    //
    if (KeyControlBlock->Delete) {
        return STATUS_KEY_DELETED;
    }

    //
    // see if the newName is not already a subkey of parentKcb
    //
    Hive = KeyControlBlock->KeyHive;
    OldKeyCell = KeyControlBlock->KeyCell;
    StorageType = HvGetCellType(OldKeyCell);

    if( StorageType != Stable ) {
        //
        // nop the volatiles
        //
        return STATUS_SUCCESS;
    }

    if( OldKeyCell ==  Hive->BaseBlock->RootCell ) {
        //
        // this works only for stable keys.
        //
        return STATUS_INVALID_PARAMETER;
    }

    //
    // 1. mark all data that we are going to touch dirty
    //
    // parent's index, as we will replace the key node cell in it
    // we only search in the Stable storage. It is supposed to be there
    //
    OldKeyNode = (PCM_KEY_NODE)HvGetCell(Hive,OldKeyCell);
    if( OldKeyNode == NULL ) {
        //
        // cannot map view
        //
        return STATUS_INSUFFICIENT_RESOURCES;
    }

    if (! CmpMarkKeyDirty(Hive, OldKeyCell
#if DBG
		,FALSE
#endif //DBG
		)) {
        HvReleaseCell(Hive, OldKeyCell);
        return STATUS_NO_LOG_SPACE;
    }
    // release the cell right here, as the registry is locked exclusively, and the key_cell is marked as dirty
    HvReleaseCell(Hive, OldKeyCell);

	if( OldKeyNode->Flags & KEY_SYM_LINK ) {
		//
		// we do not compact links
		//
		return STATUS_INVALID_PARAMETER;
	}
	if( OldKeyNode->SubKeyLists[Stable] != HCELL_NIL ) {
		//
		// mark the index dirty
		//
		OldIndex = (PCM_KEY_INDEX)HvGetCell(Hive, OldKeyNode->SubKeyLists[Stable]);
		if( OldIndex == NULL ) {
			//
			// we couldn't map the bin containing this cell
			//
			return STATUS_INSUFFICIENT_RESOURCES;
		}
		HvReleaseCell(Hive, OldKeyNode->SubKeyLists[Stable]);
		if( !HvMarkCellDirty(Hive, OldKeyNode->SubKeyLists[Stable]) ) {
			return STATUS_NO_LOG_SPACE;
		}

		if(OldIndex->Signature == CM_KEY_INDEX_ROOT) {
			for (i = 0; i < OldIndex->Count; i++) {
				if( !HvMarkCellDirty(Hive, OldIndex->List[i]) ) {
					return STATUS_NO_LOG_SPACE;
				}
			}
		} 
	}

    ParentKeyCell = OldKeyNode->Parent;
    //
    // now in the parent's spot
    //
    ParentKeyNode = (PCM_KEY_NODE)HvGetCell(Hive,ParentKeyCell);
    if( ParentKeyNode == NULL ) {
        //
        // cannot map view
        //
        return STATUS_INSUFFICIENT_RESOURCES;
    }
    if( !HvMarkCellDirty(Hive, ParentKeyCell) ) {
        HvReleaseCell(Hive, ParentKeyCell);
        return STATUS_NO_LOG_SPACE;
    }
    // release the cell right here, as the registry is locked exclusively, so we don't care
    // Key_cell is marked dirty to keep the parent knode mapped
    HvReleaseCell(Hive, ParentKeyCell);

    ParentIndex = (PCM_KEY_INDEX)HvGetCell(Hive, ParentKeyNode->SubKeyLists[Stable]);
    if( ParentIndex == NULL ) {
        //
        // we couldn't map the bin containing this cell
        //
        return STATUS_INSUFFICIENT_RESOURCES;
    }
    HvReleaseCell(Hive, ParentKeyNode->SubKeyLists[Stable]);

    if(ParentIndex->Signature == CM_KEY_INDEX_ROOT) {

        //
        // step through root, till we find the right leaf
        //
        for (i = 0; i < ParentIndex->Count; i++) {
            LeafCell = ParentIndex->List[i];
            Leaf = (PCM_KEY_INDEX)HvGetCell(Hive, LeafCell);
            if( Leaf == NULL ) {
                //
                // we couldn't map the bin containing this cell
                //
                return STATUS_INSUFFICIENT_RESOURCES;
            }
            HvReleaseCell(Hive, LeafCell);

            if ( (Leaf->Signature == CM_KEY_FAST_LEAF) ||
                 (Leaf->Signature == CM_KEY_HASH_LEAF)
                ) {
                FastIndex = (PCM_KEY_FAST_INDEX)Leaf;
                for(j=0;j<FastIndex->Count;j++) {
                    if( FastIndex->List[j].Cell == OldKeyCell ) {
                        //
                        // found it! remember the locations we want to update later and break the loop
                        //
                        if( !HvMarkCellDirty(Hive, LeafCell) ) {
					        return STATUS_NO_LOG_SPACE;
                        }
                        ParentIndexLocation = &(FastIndex->List[j].Cell);
                        break;
                    }
                }
                if( ParentIndexLocation != NULL ) {
                    break;
                }
            } else {
                for(j=0;j<Leaf->Count;j++) {
                    if( Leaf->List[j] == OldKeyCell ) {
                        //
                        // found it! remember the locations we want to update later and break the loop
                        //
                        if( !HvMarkCellDirty(Hive, LeafCell) ) {
					        return STATUS_NO_LOG_SPACE;
                        }
                        ParentIndexLocation = &(Leaf->List[j]);
                        break;
                    }
                }
                if( ParentIndexLocation != NULL ) {
                    break;
                }
            }
        }
    } else if ( (ParentIndex->Signature == CM_KEY_FAST_LEAF) ||
                (ParentIndex->Signature == CM_KEY_HASH_LEAF)
        ) {
        FastIndex = (PCM_KEY_FAST_INDEX)ParentIndex;
        for(j=0;j<FastIndex->Count;j++) {
            if( FastIndex->List[j].Cell == OldKeyCell ) {
                //
                // found it! remember the locations we want to update later and break the loop
                //
                if( !HvMarkCellDirty(Hive, ParentKeyNode->SubKeyLists[Stable]) ) {
			        return STATUS_NO_LOG_SPACE;
                }
                ParentIndexLocation = &(FastIndex->List[j].Cell);
                break;
            }
        }
    } else {
        for(j=0;j<ParentIndex->Count;j++) {
            if( ParentIndex->List[j] == OldKeyCell ) {
                //
                // found it! remember the locations we want to update later and break the loop
                //
                if( !HvMarkCellDirty(Hive, ParentKeyNode->SubKeyLists[Stable]) ) {
			        return STATUS_NO_LOG_SPACE;
                }
                ParentIndexLocation = &(ParentIndex->List[j]);
                break;
            }
        }
    }

    // we should've find it !!!
    ASSERT( ParentIndexLocation != NULL );

    // 
    // 2. Duplicate the key_node (and values and all cells involved)
    //
    Status = CmpDuplicateKey(Hive,OldKeyCell,&NewKeyCell);
    if( !NT_SUCCESS(Status) ) {
        return Status;
    }

    // sanity
    ASSERT( (NewKeyCell != HCELL_NIL) && (StorageType == (HSTORAGE_TYPE)HvGetCellType(NewKeyCell)));

    //
    // 3. update the parent on each and every son.
    //
    if( !CmpUpdateParentForEachSon(Hive,NewKeyCell) ) {
        Status = STATUS_INSUFFICIENT_RESOURCES;
        goto ErrorExit;
    }

    //
    // 4. replace the new Key_cell in the parent's subkeylist
    // From now on, WE CANNOT fails. we have everything marked dirty
    // we just update some fields. no resources required !
    // If we fail to free some cells, too bad, we'll leak some cells.
    //
    *ParentIndexLocation = NewKeyCell;

    //
    // 5. Update the kcb and the kcb cache
    //
    CmpCleanUpSubKeyInfo(KeyControlBlock->ParentKcb);
    KeyControlBlock->KeyCell = NewKeyCell;
    CmpRebuildKcbCache(KeyControlBlock);

    //
    // 6. remove old subkey
    //
    // First the Index; it's already marked dirty (i.e. PINNED)
    //
	if( OldKeyNode->SubKeyLists[Stable] != HCELL_NIL ) {
		OldIndex = (PCM_KEY_INDEX)HvGetCell(Hive, OldKeyNode->SubKeyLists[Stable]);
		ASSERT( OldIndex != NULL );
		HvReleaseCell(Hive, OldKeyNode->SubKeyLists[Stable]);
		if(OldIndex->Signature == CM_KEY_INDEX_ROOT) {
			for (i = 0; i < OldIndex->Count; i++) {
				HvFreeCell(Hive, OldIndex->List[i]);
			}
		} 
		HvFreeCell(Hive,OldKeyNode->SubKeyLists[Stable]);
	}

	OldKeyNode->SubKeyCounts[Stable] = 0;
    OldKeyNode->SubKeyCounts[Volatile] = 0;

    CmpFreeKeyByCell(Hive,OldKeyCell,FALSE);

    return STATUS_SUCCESS;

ErrorExit:
    //
    // we need to free the new knode allocated
    //
    NewKeyNode = (PCM_KEY_NODE)HvGetCell(Hive,NewKeyCell);
    // must be dirty
    ASSERT( NewKeyNode != NULL );
	HvReleaseCell(Hive, NewKeyCell);
	if( NewKeyNode->SubKeyLists[Stable] != HCELL_NIL ) {
		OldIndex = (PCM_KEY_INDEX)HvGetCell(Hive, NewKeyNode->SubKeyLists[Stable]);
		ASSERT( OldIndex != NULL );
		HvReleaseCell(Hive, NewKeyNode->SubKeyLists[Stable]);
		if(OldIndex->Signature == CM_KEY_INDEX_ROOT) {
			for (i = 0; i < OldIndex->Count; i++) {
				HvFreeCell(Hive, OldIndex->List[i]);
			}
		} 
		HvFreeCell(Hive,NewKeyNode->SubKeyLists[Stable]);
	}
    NewKeyNode->SubKeyCounts[Stable] = 0;
    NewKeyNode->SubKeyCounts[Volatile] = 0;

    CmpFreeKeyByCell(Hive,NewKeyCell,FALSE);
    return Status;

}

NTSTATUS
CmpDuplicateKey(
    PHHIVE          Hive,
    HCELL_INDEX     OldKeyCell,
    PHCELL_INDEX    NewKeyCell
    )
/*++

Routine Description:

    Makes an exact clone of OldKeyCell key_node in the 
    space above AboveFileOffset.
    Operates on Stable storage ONLY!!!

Arguments:


Return Value:

    NTSTATUS - Result code from call, among the following:

        <TBS>

--*/
{
    PCM_KEY_NODE			OldKeyNode;
    PCM_KEY_NODE			NewKeyNode;
    ULONG					i;
    PRELEASE_CELL_ROUTINE   TargetReleaseCellRoutine;

    PAGED_CODE();

    ASSERT_CM_LOCK_OWNED_EXCLUSIVE();
    ASSERT( HvGetCellType(OldKeyCell) == Stable );
    
    OldKeyNode = (PCM_KEY_NODE)HvGetCell(Hive,OldKeyCell);
    if( OldKeyNode == NULL ) {
        //
        // cannot map view
        //
        return STATUS_INSUFFICIENT_RESOURCES;
    }

    //
    // since the registry is locked exclusively here, we don't need to lock/release cells 
    // while copying the trees; So, we just set the release routines to NULL and restore after
    // the copy is complete; this saves some pain
    //
    TargetReleaseCellRoutine = Hive->ReleaseCellRoutine;
    Hive->ReleaseCellRoutine = NULL;

    *NewKeyCell = CmpCopyKeyPartial(Hive,OldKeyCell,Hive,OldKeyNode->Parent,TRUE);
    Hive->ReleaseCellRoutine  = TargetReleaseCellRoutine;

    if( *NewKeyCell == HCELL_NIL ) {
	    HvReleaseCell(Hive, OldKeyCell);
        return STATUS_INSUFFICIENT_RESOURCES;
    }

    NewKeyNode = (PCM_KEY_NODE)HvGetCell(Hive,*NewKeyCell);
    if( NewKeyNode == NULL ) {
        //
        // cannot map view
        //
	    HvReleaseCell(Hive, OldKeyCell);
        CmpFreeKeyByCell(Hive,*NewKeyCell,FALSE);
        return STATUS_INSUFFICIENT_RESOURCES;
    }

    //
    // now we have the key_cell duplicated. Values and security has also been taken care of
    // Go ahead and duplicate the Index.
    //
    if( OldKeyNode->SubKeyLists[Stable] != HCELL_NIL ) {
		NewKeyNode->SubKeyLists[Stable] = CmpDuplicateIndex(Hive,OldKeyNode->SubKeyLists[Stable],Stable);
		if( NewKeyNode->SubKeyLists[Stable] == HCELL_NIL ) {
			HvReleaseCell(Hive, OldKeyCell);
			CmpFreeKeyByCell(Hive,*NewKeyCell,FALSE);
			HvReleaseCell(Hive, *NewKeyCell);
			return STATUS_INSUFFICIENT_RESOURCES;
		}
	} else {
		ASSERT( OldKeyNode->SubKeyCounts[Stable] == 0 );
		NewKeyNode->SubKeyLists[Stable] = HCELL_NIL;
	}
    NewKeyNode->SubKeyCounts[Stable] = OldKeyNode->SubKeyCounts[Stable];
    NewKeyNode->SubKeyLists[Volatile] = OldKeyNode->SubKeyLists[Volatile];
    NewKeyNode->SubKeyCounts[Volatile] = OldKeyNode->SubKeyCounts[Volatile];

	HvReleaseCell(Hive, *NewKeyCell);
    HvReleaseCell(Hive, OldKeyCell);
    return STATUS_SUCCESS;

}


#ifdef WRITE_PROTECTED_REGISTRY_POOL

VOID
CmpMarkAllBinsReadOnly(
    PHHIVE      Hive
    )
/*++

Routine Description:

    Marks the memory allocated for all the stable bins in this hive as read only.

Arguments:

    Hive - supplies a pointer to the hive control structure for the
            hive of interest

Return Value:

    NONE (It should work!)

--*/
{
    PHMAP_ENTRY t;
    PHBIN       Bin;
    HCELL_INDEX p;
    ULONG       Length;

    //
    // we are only interested in the stable storage
    //
    Length = Hive->Storage[Stable].Length;

    p = 0;

    //
    // for each bin in the space
    //
    while (p < Length) {
        t = HvpGetCellMap(Hive, p);
        VALIDATE_CELL_MAP(__LINE__,t,Hive,p);

        Bin = (PHBIN)HBIN_BASE(t->BinAddress);

        if (t->BinAddress & HMAP_NEWALLOC) {

            //
            // Mark it as read Only
            //
            HvpChangeBinAllocation(Bin,TRUE);
        }

        // next one, please
        p = (ULONG)p + Bin->Size;

    }

}

#endif //WRITE_PROTECTED_REGISTRY_POOL

ULONG
CmpCompressKeyWorker(
    PCM_KEY_CONTROL_BLOCK Current,
    PVOID                 Context1,
    PVOID                 Context2
    )
{
	PLIST_ENTRY				pListHead;
	PCM_KCB_REMAP_BLOCK		kcbRemapBlock;
	//PLIST_ENTRY             AnchorAddr;

    if (Current->KeyHive == Context1) {
		
		pListHead = (PLIST_ENTRY)Context2;
		ASSERT( pListHead );
/*
		//
		// check if we didn't already recorded this kcb
		//
		AnchorAddr = pListHead;
		kcbRemapBlock = (PCM_KCB_REMAP_BLOCK)(pListHead->Flink);

		while ( kcbRemapBlock != (PCM_KCB_REMAP_BLOCK)AnchorAddr ) {
			kcbRemapBlock = CONTAINING_RECORD(
							kcbRemapBlock,
							CM_KCB_REMAP_BLOCK,
							RemapList
							);
			if( kcbRemapBlock->KeyControlBlock == Current ) {
				//
				// we already have this kcb
				//
				return KCB_WORKER_CONTINUE;
			}
            //
            // skip to the next element
            //
            kcbRemapBlock = (PCM_KCB_REMAP_BLOCK)(kcbRemapBlock->RemapList.Flink);
		}
*/

		kcbRemapBlock = (PCM_KCB_REMAP_BLOCK)ExAllocatePool(PagedPool, sizeof(CM_KCB_REMAP_BLOCK));
		if( kcbRemapBlock == NULL ) {
			return KCB_WORKER_ERROR;
		}
		kcbRemapBlock->KeyControlBlock = Current;
		kcbRemapBlock->NewCellIndex = HCELL_NIL;
		kcbRemapBlock->OldCellIndex = Current->KeyCell;
		kcbRemapBlock->ValueCount = 0;
		kcbRemapBlock->ValueList = HCELL_NIL;
        InsertTailList(pListHead,&(kcbRemapBlock->RemapList));

    }
    return KCB_WORKER_CONTINUE;   // always keep searching
}

NTSTATUS
CmCompressKey(
    IN PHHIVE Hive
    )
/*++

Routine Description:

	Compresses the kcb, by means of simulating an "in-place" SaveKey

    What needs to be done:

	1. iterate through the kcb tree and make a list of all the kcbs 
	that need to be changed (their keycell will change during the process)
	2. iterate through the cache and compute an array of security cells.
	We'll need it to map security cells into the new hive.
	3. Save the hive into a temporary hive, preserving
	the volatile info in keynodes and updating the cell mappings.
	4. Update the cache by adding volatile security cells from the old hive.
	5. Dump temporary (compressed) hive over to the old file.
	6. Switch hive data from the compressed one to the existing one and update
	the kcb KeyCell and security mapping
	7. Invalidate the map and drop paged bins.
	8. Free storage for the new hive (OK if we fail)

Arguments:

    Hive - Hive to operate on

Return Value:

    NTSTATUS - Result code from call, among the following:

        <TBS>

--*/
{
    NTSTATUS                Status = STATUS_SUCCESS;
    HCELL_INDEX             KeyCell;
    PCMHIVE                 CmHive;
    PCM_KCB_REMAP_BLOCK     RemapBlock;
    PCMHIVE                 NewHive = NULL;
    HCELL_INDEX             LinkCell;
    PCM_KEY_NODE            LinkNode;
    PCM_KNODE_REMAP_BLOCK   KnodeRemapBlock;
    ULONG                   OldLength;

    
	PAGED_CODE();

    CmKdPrintEx((DPFLTR_CONFIG_ID,CML_CM,"CmCompressKey\n"));

    ASSERT_CM_LOCK_OWNED_EXCLUSIVE();

    if( HvAutoCompressCheck(Hive) == FALSE ) {
        return STATUS_SUCCESS;
    }

    KeyCell = Hive->BaseBlock->RootCell;
    CmHive = CONTAINING_RECORD(Hive, CMHIVE, Hive);
    //
    // Make sure the cell passed in is the root cell of the hive.
    //
    if ( CmHive == CmpMasterHive ) {
        return STATUS_INVALID_PARAMETER;
    }

	//
	// 0. Get the cells we need to relink the compressed hive
	//
	LinkNode = (PCM_KEY_NODE)HvGetCell(Hive,KeyCell);
	if( LinkNode == NULL ) {
        return STATUS_INSUFFICIENT_RESOURCES;
	}
	LinkCell = LinkNode->Parent;
	HvReleaseCell(Hive,KeyCell);
	LinkNode = (PCM_KEY_NODE)HvGetCell((PHHIVE)CmpMasterHive,LinkCell);
	// master storage is paged pool
	ASSERT(LinkNode != NULL);
	HvReleaseCell((PHHIVE)CmpMasterHive,LinkCell);


    OldLength = Hive->BaseBlock->Length;
	//
	//	1. iterate through the kcb tree and make a list of all the kcbs 
	//	that need to be changed (their keycell will change during the process)
	//
	ASSERT( IsListEmpty(&(CmHive->KcbConvertListHead)) );
	//
	// this will kick all kcb with refcount == 0 out of cache, so we can use 
	// CmpSearchKeyControlBlockTree for recording referenced kcbs
	//
	CmpCleanUpKCBCacheTable();
	//CmpSearchForOpenSubKeys(KeyControlBlock,SearchIfExist);
    if( !CmpSearchKeyControlBlockTree(CmpCompressKeyWorker,(PVOID)Hive,(PVOID)(&(CmHive->KcbConvertListHead))) ) {
		Status = STATUS_INSUFFICIENT_RESOURCES;
		goto Exit;
	}

	//
	// 2. iterate through the cache and compute an array of security cells.
	// We'll need it to map security cells into the new hive.
	//
	if( !CmpBuildSecurityCellMappingArray(CmHive) ) {
		Status = STATUS_INSUFFICIENT_RESOURCES;
		goto Exit;
	}

	//
	// 3. Save the hive into a temporary hive , preserving
	// the volatile info in keynodes and updating the cell mappings.
	//
	Status = CmpShiftHiveFreeBins(CmHive,&NewHive);
	if( !NT_SUCCESS(Status) ) {
		goto Exit;
	}

	//
	// 5. Dump temporary (compressed) hive over to the old file.
	//
	Status = CmpOverwriteHive(CmHive,NewHive,LinkCell);
    if (!NT_SUCCESS(Status)) {
        goto Exit;
    }


	//
	// From this point on, we WILL NOT FAIL!
	//

	//
	// get the root node and link it into the master storage
	//
	LinkNode->ChildHiveReference.KeyCell = NewHive->Hive.BaseBlock->RootCell;

	//
	// 6. Switch hive data from the compressed one to the existing one and update
	// the kcb KeyCell and security mapping
	// This should better NOT fail!!! If it does, we are doomed, as we have partial
	// data => bugcheck
	//
	CmpSwitchStorageAndRebuildMappings(CmHive,NewHive);

	
	//
	// 7. Invalidate the map and drop paged bins. If system hive, check for the hysteresis callback.
	//
    HvpDropAllPagedBins(&(CmHive->Hive));
    if( OldLength < CmHive->Hive.BaseBlock->Length ) {
        CmpUpdateSystemHiveHysteresis(&(CmHive->Hive),CmHive->Hive.BaseBlock->Length,OldLength);
    }


Exit:

	//
	// 8. Free storage for the new hive (OK if we fail)
	//
	if( NewHive != NULL ) { 
		CmpDestroyTemporaryHive(NewHive);	
	}

	if( CmHive->CellRemapArray != NULL ) {
		ExFreePool(CmHive->CellRemapArray);
		CmHive->CellRemapArray = NULL;
	}
	//
	// remove all remap blocks and free them
	//
	while (IsListEmpty(&(CmHive->KcbConvertListHead)) == FALSE) {
        RemapBlock = (PCM_KCB_REMAP_BLOCK)RemoveHeadList(&(CmHive->KcbConvertListHead));
        RemapBlock = CONTAINING_RECORD(
                        RemapBlock,
                        CM_KCB_REMAP_BLOCK,
                        RemapList
                        );
		ExFreePool(RemapBlock);
	}
	while (IsListEmpty(&(CmHive->KnodeConvertListHead)) == FALSE) {
        KnodeRemapBlock = (PCM_KNODE_REMAP_BLOCK)RemoveHeadList(&(CmHive->KnodeConvertListHead));
        KnodeRemapBlock = CONTAINING_RECORD(
                            KnodeRemapBlock,
                            CM_KNODE_REMAP_BLOCK,
                            RemapList
                        );
		ExFreePool(KnodeRemapBlock);
	}

	return Status;
}

NTSTATUS
CmLockKcbForWrite(PCM_KEY_CONTROL_BLOCK KeyControlBlock)
/*++

Routine Description:

    Tags the kcb as being read-only and no-delay-close

Arguments:

    KeyControlBlock

Return Value:

    TBS

--*/
{
    PAGED_CODE();

    CmpLockKCBTreeExclusive();

    ASSERT_KCB(KeyControlBlock);
    if( KeyControlBlock->Delete ) {
        CmpUnlockKCBTree();
        return STATUS_KEY_DELETED;
    }
    //
    // sanity check in case we are called twice
    //
    ASSERT( ((KeyControlBlock->ExtFlags&CM_KCB_READ_ONLY_KEY) && (KeyControlBlock->ExtFlags&CM_KCB_NO_DELAY_CLOSE)) ||
            (!(KeyControlBlock->ExtFlags&CM_KCB_READ_ONLY_KEY))
        );

    //
    // tag the kcb as read-only; also make it no-delay close so it can revert to the normal state after all handles are closed.
    //
    KeyControlBlock->ExtFlags |= (CM_KCB_READ_ONLY_KEY|CM_KCB_NO_DELAY_CLOSE);

    //
    // add an artificial refcount on this kcb. This will keep the kcb (and the read only flag set in memory for as long as the system is up)
    //
    InterlockedIncrement( (PLONG)&KeyControlBlock->RefCount );

    CmpUnlockKCBTree();

    return STATUS_SUCCESS;
}


BOOLEAN
CmpCompareNewValueDataAgainstKCBCache(  PCM_KEY_CONTROL_BLOCK KeyControlBlock,
                                        PUNICODE_STRING ValueName,
                                        ULONG Type,
                                        PVOID Data,
                                        ULONG DataSize
                                        )

/*++

Routine Description:

    Most of the SetValue calls are noops (i.e. they are setting the same 
    value name to the same value data). By comparing against the data already 
    in the kcb cache (i.e. faulted in) we can save page faults.


Arguments:

    KeyControlBlock - pointer to kcb for the key to operate on

    ValueName - The unique (relative to the containing key) name
        of the value entry.  May be NULL.

    Type - The integer type number of the value entry.

    Data - Pointer to buffer with actual data for the value entry.

    DataSize - Size of Data buffer.


Return Value:

    TRUE - same value with the same data exist in the cache.

--*/
{
    PCM_KEY_VALUE       Value;
    ULONG               Index;
    BOOLEAN             ValueCached;
    PPCM_CACHED_VALUE   ContainingList;
    HCELL_INDEX         ValueDataCellToRelease = HCELL_NIL;
    BOOLEAN             Result = FALSE;
    PUCHAR              datapointer;
    BOOLEAN             BufferAllocated = FALSE;
    HCELL_INDEX         CellToRelease = HCELL_NIL;
    ULONG               compareSize;
    ULONG               realsize;
    BOOLEAN             small;

    PAGED_CODE();

    BEGIN_KCB_LOCK_GUARD;
    CmpLockKCBTreeExclusive();

    if( KeyControlBlock->Flags & KEY_SYM_LINK ) {
        //
        // need to rebuild the value cache, so we could runt the same code
        //
        PCM_KEY_NODE    Node = (PCM_KEY_NODE)HvGetCell(KeyControlBlock->KeyHive,KeyControlBlock->KeyCell);

        if( Node == NULL ) {
            //
            // we couldn't map the bin containing this cell
            //
            goto Exit;
        }

        CmpCleanUpKcbValueCache(KeyControlBlock);
        CmpSetUpKcbValueCache(KeyControlBlock,Node->ValueList.Count,Node->ValueList.List);

        HvReleaseCell(KeyControlBlock->KeyHive,KeyControlBlock->KeyCell);
    }

    Value = CmpFindValueByNameFromCache(KeyControlBlock->KeyHive,
                                        &(KeyControlBlock->ValueCache),
                                        ValueName,
                                        &ContainingList,
                                        &Index,
                                        &ValueCached,
                                        &ValueDataCellToRelease
                                        );

    if(Value) {
        if( (Type == Value->Type) && (DataSize == (Value->DataLength & ~CM_KEY_VALUE_SPECIAL_SIZE)) ) {
        
            small = CmpIsHKeyValueSmall(realsize, Value->DataLength);
            if (small == TRUE) {
                datapointer = (PUCHAR)(&(Value->Data));
            } else if( CmpGetValueDataFromCache(KeyControlBlock->KeyHive, ContainingList,(PCELL_DATA)Value, 
                                                ValueCached,&datapointer,&BufferAllocated,&CellToRelease) == FALSE ){
                //
                // we couldn't map view for cell; treat it as insufficient resources problem
                //
                ASSERT( datapointer == NULL );
                ASSERT( BufferAllocated == FALSE );
                goto Exit;
            } 
            //
            // compare data
            //
            if (DataSize > 0) {

                try {
                    compareSize = (ULONG)RtlCompareMemory ((PVOID)datapointer,Data,(DataSize & ~CM_KEY_VALUE_SPECIAL_SIZE));
                } except (EXCEPTION_EXECUTE_HANDLER) {
                    goto Exit;
                }

            } else {
                compareSize = 0;
            }

            if (compareSize == DataSize) {
                Result = TRUE;
            }

        }
    }

Exit:

    CmpUnlockKCBTree();
    END_KCB_LOCK_GUARD;

    if(ValueDataCellToRelease != HCELL_NIL) {
        HvReleaseCell(KeyControlBlock->KeyHive,ValueDataCellToRelease);
    }
    if( BufferAllocated == TRUE ) {
        ExFreePool(datapointer);
    }
    if(CellToRelease != HCELL_NIL) {
        HvReleaseCell(KeyControlBlock->KeyHive,CellToRelease);
    }
    
    return Result;
}

NTSTATUS
static
__forceinline
CmpCheckReplaceHive(    IN PHHIVE           Hive,
                        OUT PHCELL_INDEX    Key
                    )
{
    HCELL_INDEX             RootCell;
    UNICODE_STRING          Name;
    NTSTATUS                Status = STATUS_SUCCESS;
    PRELEASE_CELL_ROUTINE   TargetReleaseCellRoutine;
    WCHAR                   Buffer[4];

    PAGED_CODE();
    
    ASSERT_CM_LOCK_OWNED_EXCLUSIVE();
    //
    // disable refcounting
    //
    TargetReleaseCellRoutine = Hive->ReleaseCellRoutine;
    Hive->ReleaseCellRoutine = NULL;
    
    Buffer[3] = 0;
    *Key = HCELL_NIL;
    Buffer[1] = (WCHAR)'P';

    RootCell = Hive->BaseBlock->RootCell;
    Buffer[2] = (WCHAR)'A';

    if( RootCell == HCELL_NIL ) {
        //
        // could not find root cell. Bogus.
        //
        Status =  STATUS_REGISTRY_CORRUPT;
        goto Exit;
    }
    Buffer[0] = (WCHAR)'W';

    RtlInitUnicodeString(&Name, Buffer);
    RootCell = CmpFindSubKeyByName(Hive,
                                   (PCM_KEY_NODE)HvGetCell(Hive,RootCell),
                                   &Name);


    if( RootCell != HCELL_NIL ) {
        //
        // found it.
        //
        *Key = RootCell;
    } else {
        //
        // WPA key should be present; it's created by GUI mode.
        //
        Status =  STATUS_REGISTRY_CORRUPT;
        goto Exit;
    }

Exit:
    Hive->ReleaseCellRoutine = TargetReleaseCellRoutine;
    return Status;
}
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\base\ntos\config\cmapi2.c ===
/*++

Copyright (c) 1991  Microsoft Corporation

Module Name:

    cmapi2.c

Abstract:

    This module contains CM level entry points for the registry,
    particularly those which we don't want to link into tools,
    setup, the boot loader, etc.

Author:

    Bryan M. Willman (bryanwi) 26-Jan-1993

Revision History:

--*/

#include "cmp.h"

#ifdef ALLOC_PRAGMA
#pragma alloc_text(PAGE,CmDeleteKey)
#endif


NTSTATUS
CmDeleteKey(
    IN PCM_KEY_BODY KeyBody
    )
/*++

Routine Description:

    Delete a registry key, clean up Notify block.

Arguments:

    KeyBody - pointer to key handle object

Return Value:

    NTSTATUS

--*/
{
    NTSTATUS                status;
    PCM_KEY_NODE            ptarget;
    PHHIVE                  Hive;
    HCELL_INDEX             Cell;
    HCELL_INDEX             Parent;
    PCM_KEY_CONTROL_BLOCK   KeyControlBlock;
    LARGE_INTEGER           TimeStamp;

    CmKdPrintEx((DPFLTR_CONFIG_ID,CML_CM,"CmDeleteKey\n"));

    CmpLockRegistryExclusive();

#ifdef CHECK_REGISTRY_USECOUNT
    CmpCheckRegistryUseCount();
#endif //CHECK_REGISTRY_USECOUNT

    //
    // If already marked for deletion, storage is gone, so
    // do nothing and return success.
    //
    KeyControlBlock = KeyBody->KeyControlBlock;

    PERFINFO_REG_DELETE_KEY(KeyControlBlock);

    if (KeyControlBlock->Delete == TRUE) {
        status = STATUS_SUCCESS;
        goto Exit;
    }

    // Mark the hive as read only
    CmpMarkAllBinsReadOnly(KeyControlBlock->KeyHive);

    ptarget = (PCM_KEY_NODE)HvGetCell(KeyControlBlock->KeyHive, KeyControlBlock->KeyCell);
    if( ptarget == NULL ) {
        //
        // we couldn't map a view for the bin containing this cell
        //

        status = STATUS_INSUFFICIENT_RESOURCES;
        goto Exit;
    }

    // release the cell right here, as the registry is locked exclusively, so we don't care
    HvReleaseCell(KeyControlBlock->KeyHive, KeyControlBlock->KeyCell);

    ASSERT( ptarget->Flags == KeyControlBlock->Flags );

    if ( ((ptarget->SubKeyCounts[Stable] + ptarget->SubKeyCounts[Volatile]) == 0) &&
         ((ptarget->Flags & KEY_NO_DELETE) == 0))
    {
        //
        // Cell is NOT marked NO_DELETE and does NOT have children
        // Send Notification while key still present, if delete fails,
        //   we'll have sent a spurious notify, that doesn't matter
        // Delete the actual storage
        //
        Hive = KeyControlBlock->KeyHive;
        Cell = KeyControlBlock->KeyCell;
        Parent = ptarget->Parent;

        CmpReportNotify(
            KeyControlBlock,
            Hive,
            Cell,
            REG_NOTIFY_CHANGE_NAME
            );

        status = CmpFreeKeyByCell(Hive, Cell, TRUE);

        if (NT_SUCCESS(status)) {
            //
            // post any waiting notifies
            //
            CmpFlushNotifiesOnKeyBodyList(KeyControlBlock);

            //
            // Remove kcb out of cache, but do NOT
            // free its storage, CmDelete will do that when
            // the RefCount becomes zero.
            //
            // There are two things that can hold the RefCount non-zero.
            //
            // 1. open handles for this key
            // 2. Fake subKeys that are still in DelayClose.
            //
            // At this point, we have no way of deleting the fake subkeys from cache
            // unless we do a search for the whole cache, which is too expensive.
            // Thus, we decide to either let the fake keys age out of cache or when 
            // someone is doing the lookup for the fake key, then we delete it at that point.
            // See routine CmpCacheLookup in cmparse.c for more details.
            //
            // If the parent has the subkey info or hint cached, free it.
            // Again, registry is locked exclusively, no need to lock KCB.
            //
            ASSERT_CM_LOCK_OWNED_EXCLUSIVE();
            CmpCleanUpSubKeyInfo(KeyControlBlock->ParentKcb);
            ptarget = (PCM_KEY_NODE)HvGetCell(Hive, Parent);
            if( ptarget != NULL ) {
                // release the cell right here, as the registry is locked exclusively, so we don't care
                HvReleaseCell(Hive, Parent);

                //
                // this should always be true as CmpFreeKeyByCell always marks the parent dirty on success
                //
                KeyControlBlock->ParentKcb->KcbMaxNameLen = (USHORT)ptarget->MaxNameLen;
                // sanity
                ASSERT_CELL_DIRTY(Hive,Parent);
                //
                // update the LastWriteTime on parent and kcb too
                //
                KeQuerySystemTime(&TimeStamp);
                ptarget->LastWriteTime = TimeStamp;
                KeyBody->KeyControlBlock->ParentKcb->KcbLastWriteTime = TimeStamp;

            }

            KeyControlBlock->Delete = TRUE;
            CmpRemoveKeyControlBlock(KeyControlBlock);
            KeyControlBlock->KeyCell = HCELL_NIL;
        }

    } else {

        status = STATUS_CANNOT_DELETE;

    }

Exit:

#ifdef CHECK_REGISTRY_USECOUNT
    CmpCheckRegistryUseCount();
#endif //CHECK_REGISTRY_USECOUNT

    CmpUnlockRegistry();

    // Mark the hive as read only
    CmpMarkAllBinsReadOnly(KeyControlBlock->KeyHive);

    return status;
}
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\base\ntos\config\cmchek.c ===
/*++

Copyright (c) 1991  Microsoft Corporation

Module Name:

    cmchek.c

Abstract:

    This module implements consistency checking for the registry.
    This module can be linked standalone, cmchek2.c cannot.

Author:

    Bryan M. Willman (bryanwi) 27-Jan-92

Environment:


Revision History:

--*/

#include    "cmp.h"

#define     REG_MAX_PLAUSIBLE_KEY_SIZE \
                ((FIELD_OFFSET(CM_KEY_NODE, Name)) + \
                 (sizeof(WCHAR) * REG_MAX_KEY_NAME_LENGTH) + 16)

extern PCMHIVE CmpMasterHive;

//
// Private prototypes
//

ULONG
CmpCheckRegistry2(
    PHHIVE      HiveToCheck,
    ULONG       CheckFlags,
    HCELL_INDEX Cell,
    HCELL_INDEX ParentCell,
    BOOLEAN     ResetSD
    );

ULONG
CmpCheckKey(
    PHHIVE      HiveToCheck,
    ULONG       CheckFlags,
    HCELL_INDEX Cell,
    HCELL_INDEX ParentCell,
    BOOLEAN     ResetSD
    );

ULONG
CmpCheckValueList(
    PHHIVE      Hive,
    PCELL_DATA  List,
    ULONG       Count,
    HCELL_INDEX KeyCell
    );

#ifdef ALLOC_PRAGMA
#pragma alloc_text(PAGE,CmCheckRegistry)
#pragma alloc_text(PAGE,CmpCheckRegistry2)
#pragma alloc_text(PAGE,CmpCheckKey)
#pragma alloc_text(PAGE,CmpCheckValueList)

#ifdef CHECK_REGISTRY_USECOUNT
#pragma alloc_text(PAGE,CmpCheckRegistryUseCount)
#endif

#endif

//
// debug structures
//

extern struct {
    PHHIVE      Hive;
    ULONG       Status;
} CmCheckRegistryDebug;

extern struct {
    PHHIVE      Hive;
    ULONG       Status;
} CmpCheckRegistry2Debug;

extern struct {
    PHHIVE      Hive;
    ULONG       Status;
    HCELL_INDEX Cell;
    PCELL_DATA  CellPoint;
    PVOID       RootPoint;
    ULONG       Index;
} CmpCheckKeyDebug;

extern struct {
    PHHIVE      Hive;
    ULONG       Status;
    PCELL_DATA  List;
    ULONG       Index;
    HCELL_INDEX Cell;
    PCELL_DATA  CellPoint;
} CmpCheckValueListDebug;


ULONG
CmCheckRegistry(
    PCMHIVE CmHive,
    ULONG   Flags
    )
/*++

Routine Description:

    Check consistency of the registry within a given hive.  Start from
    root, and check that:
        .   Each child key points back to its parent.
        .   All allocated cells are refered to exactly once
            (requires looking inside the hive structure...)
            [This also detects space leaks.]
        .   All allocated cells are reachable from the root.

    NOTE:   Exactly 1 ref rule may change with security.

Arguments:

    CmHive - supplies a pointer to the CM hive control structure for the
            hive of interest.

    Clean   - if TRUE, references to volatile cells will be zapped
              (done at startup only to avoid groveling hives twice.)
              if FALSE, nothing will be changed.
    
    HiveCheck - If TRUE, performs hive consistency check too (i.e. checks
                the bins)

Return Value:

    0 if Hive is OK.  Error return indicator if not.

    RANGE:  3000 - 3999

--*/
{
    PHHIVE                  Hive;
    ULONG                   rc = 0;
    ULONG                   Storage;
    PRELEASE_CELL_ROUTINE   ReleaseCellRoutine;
    BOOLEAN                 ResetSD = FALSE;

    if (CmHive == CmpMasterHive) {
        return(0);
    }

    CmCheckRegistryDebug.Hive = (PHHIVE)CmHive;
    CmCheckRegistryDebug.Status = 0;


    //
    // check the underlying hive and get storage use
    //
    Hive = &CmHive->Hive;

    if( Flags & CM_CHECK_REGISTRY_HIVE_CHECK ) {
        rc = HvCheckHive(Hive, &Storage);
        if (rc != 0) {
            CmCheckRegistryDebug.Status = rc;
            return rc;
        }
    }

    //
    // Store the release cell procedure so we can restore at the end;
    // Set it to NULL so we don't count : this saves us some pain during the check
    //
    ReleaseCellRoutine = Hive->ReleaseCellRoutine;
    Hive->ReleaseCellRoutine = NULL;

    //
    // Validate all the security descriptors in the hive
    //
    if (!CmpValidateHiveSecurityDescriptors(Hive,&ResetSD)) {
        CmKdPrintEx((DPFLTR_CONFIG_ID,DPFLTR_ERROR_LEVEL,"CmCheckRegistry:"));
        CmKdPrintEx((DPFLTR_CONFIG_ID,DPFLTR_ERROR_LEVEL," CmpValidateHiveSecurityDescriptors failed\n"));
        rc = 3040;
        CmCheckRegistryDebug.Status = rc;
    }

    rc = CmpCheckRegistry2((PHHIVE)CmHive,Flags,Hive->BaseBlock->RootCell, HCELL_NIL,ResetSD);

    //
    // Print a bit of a summary (make sure this data avail in all error cases)
    //
    if (rc > 0) {
        CmKdPrintEx((DPFLTR_CONFIG_ID,DPFLTR_ERROR_LEVEL,"CmCheckRegistry Failed (%d): CmHive:%p\n", rc, CmHive));
        CmKdPrintEx((DPFLTR_CONFIG_ID,DPFLTR_ERROR_LEVEL," Hive:%p Root:%08lx\n", Hive, Hive->BaseBlock->RootCell));
    }

    //
    // restore the release cell routine
    // this saves us some pain during the check
    //
    Hive->ReleaseCellRoutine = ReleaseCellRoutine;

    return rc;
}

#ifndef _CM_LDR_

ULONG
CmpCheckRegistry2(
    PHHIVE      HiveToCheck,
    ULONG       CheckFlags,
    HCELL_INDEX Cell,
    HCELL_INDEX ParentCell,
    BOOLEAN     ResetSD
    )
/*++

Routine Description:

    Check consistency of the registry, from a particular cell on down.

        .   Check that the cell's value list, child key list, class,
            security are OK.
        .   Check that each value entry IN the list is OK.
        .   Apply self to each child key list.

    
    This version uses a stack in order to parse the tree "in-depth", 
    but not to touch any key_node.

Arguments:

    Cell - HCELL_INDEX of subkey to work on.

    ParentCell - expected value of parent cell for Cell, unless
                 HCELL_NIL, in which case ignore.

Return Value:

    0 if Hive is OK.  Error return indicator if not.

    RANGE:  4000 - 4999

--*/
{
    PCMP_CHECK_REGISTRY_STACK_ENTRY     CheckStack;
    LONG                                StackIndex;
    PCM_KEY_NODE                        Node;
    ULONG                               rc = 0;
    HCELL_INDEX                         SubKey;


    CmpCheckRegistry2Debug.Hive = HiveToCheck;
    CmpCheckRegistry2Debug.Status = 0;
    
    ASSERT( HiveToCheck->ReleaseCellRoutine == NULL );

    //
    // Initialize the stack to simulate recursion here
    //

    CheckStack = ExAllocatePool(PagedPool,sizeof(CMP_CHECK_REGISTRY_STACK_ENTRY)*CMP_MAX_REGISTRY_DEPTH);
    if (CheckStack == NULL) {
        CmpCheckRegistry2Debug.Status = 4099;
        return 4099;
    }

Restart:

    CheckStack[0].Cell = Cell;
    CheckStack[0].ParentCell = ParentCell;
    CheckStack[0].ChildIndex = 0;
    CheckStack[0].CellChecked = FALSE;
    StackIndex = 0;


    while(StackIndex >=0) {
        //
        // first check the current cell
        //
        if( CheckStack[StackIndex].CellChecked == FALSE ) {
            CheckStack[StackIndex].CellChecked = TRUE;

            rc = CmpCheckKey(HiveToCheck,CheckFlags,CheckStack[StackIndex].Cell, CheckStack[StackIndex].ParentCell,ResetSD);
            if (rc != 0) {
                CmKdPrintEx((DPFLTR_CONFIG_ID,DPFLTR_ERROR_LEVEL,"\tChild is list entry #%08lx\n", CheckStack[StackIndex].ChildIndex));
                CmpCheckRegistry2Debug.Status = rc;
                if( CmDoSelfHeal() && StackIndex ) { // root cell damage is fatal.
                    //
                    // delete this key from the parent's list and restart the whole iteration (not best performance, but safest).
                    //
                    if( !CmpRemoveSubKeyCellNoCellRef(HiveToCheck,CheckStack[StackIndex].ParentCell,CheckStack[StackIndex].Cell) ) {
                        //
                        // unable to delete subkey; punt.
                        //
                        break;
                    }
                    CmMarkSelfHeal(HiveToCheck);
                    rc = 0;
                    goto Restart;
                } else {
                    // bail out
                    break;
                }
            }
        }

        Node = (PCM_KEY_NODE)HvGetCell(HiveToCheck, CheckStack[StackIndex].Cell);
        if( Node == NULL ) {
            //
            // we couldn't map a view for the bin containing this cell
            //
            CmKdPrintEx((DPFLTR_CONFIG_ID,DPFLTR_ERROR_LEVEL,"\tCould not map cell #%08lx\n", CheckStack[StackIndex].Cell));
            CmpCheckRegistry2Debug.Status = 4098;
            rc = 4098;
            // bail out
            break;
        }

        if( CheckStack[StackIndex].ChildIndex < Node->SubKeyCounts[Stable] ) {
            //
            // we still have childs to check; add another entry for them and advance the 
            // StackIndex
            //
            SubKey = CmpFindSubKeyByNumber(HiveToCheck,
                                           Node,
                                           CheckStack[StackIndex].ChildIndex);
            if( SubKey == HCELL_NIL ) {
                //
                // we couldn't map cell;bail out
                //
                CmKdPrintEx((DPFLTR_CONFIG_ID,DPFLTR_ERROR_LEVEL,"\tCould not map cell #%08lx\n", CheckStack[StackIndex].Cell));
                CmpCheckRegistry2Debug.Status = 4097;
                rc = 4097;
                break;
            }
            //
            // next iteration will check the next child
            //
            CheckStack[StackIndex].ChildIndex++;

            StackIndex++;
            if( StackIndex == CMP_MAX_REGISTRY_DEPTH ) {
                //
                // we've run out of stack; registry tree has too many levels
                //
                CmpCheckRegistry2Debug.Status = 4096;
                rc = 4096;
                // bail out
                break;
            }
            CheckStack[StackIndex].Cell = SubKey;
            CheckStack[StackIndex].ParentCell = CheckStack[StackIndex-1].Cell;
            CheckStack[StackIndex].ChildIndex = 0;
            CheckStack[StackIndex].CellChecked = FALSE;

        } else {
            //
            // we have checked all childs for this node; go back
            //
            StackIndex--;

        }

    }

    ExFreePool(CheckStack);
    return rc;
}

#else 

ULONG
CmpCheckRegistry2(
    PHHIVE      HiveToCheck,
    ULONG       CheckFlags,
    HCELL_INDEX Cell,
    HCELL_INDEX ParentCell,
    BOOLEAN     ResetSD
    )
/*++

Routine Description:

    Check consistency of the registry, from a particular cell on down.

        .   Check that the cell's value list, child key list, class,
            security are OK.
        .   Check that each value entry IN the list is OK.
        .   Apply self to each child key list.

Arguments:

    Cell - HCELL_INDEX of subkey to work on.

    ParentCell - expected value of parent cell for Cell, unless
                 HCELL_NIL, in which case ignore.

Return Value:

    0 if Hive is OK.  Error return indicator if not.

    RANGE:  4000 - 4999

--*/
{
    ULONG           Index;
    HCELL_INDEX     StartCell;
    HCELL_INDEX     SubKey;
    ULONG           rc = 0;
    PCELL_DATA      pcell;
    PCM_KEY_NODE    Node;
    HCELL_INDEX     EnterParent = ParentCell;
    HCELL_INDEX     EnterCell = Cell;


    CmpCheckRegistry2Debug.Hive = HiveToCheck;
    CmpCheckRegistry2Debug.Status = 0;
    
    ASSERT( HiveToCheck->ReleaseCellRoutine == NULL );

Restart:
    Cell = EnterCell;
    ParentCell = EnterParent;
    StartCell = EnterCell;
    Index = 0;
    //
    // A jump to NewKey amounts to a virtual call to check the
    // next child cell. (a descent into the tree)
    //
    // Cell, ParentCell, Index, and globals are defined
    //
    NewKey:
        rc = CmpCheckKey(HiveToCheck,CheckFlags,Cell, ParentCell,ResetSD);
        if (rc != 0) {
            CmKdPrintEx((DPFLTR_CONFIG_ID,DPFLTR_ERROR_LEVEL,"\tChild is list entry #%08lx\n", Index));
            CmpCheckRegistry2Debug.Status = rc;
            if( CmDoSelfHeal() && (Cell != EnterCell)) { // root cell damage is fatal.
                //
                // delete this key from the parent's list and restart the whole iteration (not best performance, but safest).
                //
                if( !CmpRemoveSubKeyCellNoCellRef(HiveToCheck,ParentCell,Cell) ) {
                    //
                    // unable to delete subkey; punt.
                    //
                    return rc;
                }
                CmMarkSelfHeal(HiveToCheck);
                rc = 0;
                goto Restart;
            } else {
                // bail out
                return rc;
            }
        }

        //
        // save Index and check out children
        //
        pcell = HvGetCell(HiveToCheck, Cell);
        if( pcell == NULL ) {
            //
            // we couldn't map a view for the bin containing this cell
            //
            CmKdPrintEx((DPFLTR_CONFIG_ID,DPFLTR_ERROR_LEVEL,"\tCould not map cell #%08lx\n", Cell));
            CmpCheckRegistry2Debug.Status = 4099;
            return 4099;
        }
        pcell->u.KeyNode.WorkVar = Index;

        for (Index = 0; Index<pcell->u.KeyNode.SubKeyCounts[Stable]; Index++) {

            Node = (PCM_KEY_NODE)HvGetCell(HiveToCheck,Cell);
            if( Node == NULL ) {
                //
                // we couldn't map a view for the bin containing this cell
                //
                CmKdPrintEx((DPFLTR_CONFIG_ID,DPFLTR_ERROR_LEVEL,"\tCould not map cell #%08lx\n", Cell));
                CmpCheckRegistry2Debug.Status = 4098;
                return 4098;
            }
            SubKey = CmpFindSubKeyByNumber(HiveToCheck,
                                           Node,
                                           Index);
            if( SubKey == HCELL_NIL ) {
                //
                // we couldn't map cell;bail out
                //
                return 0;
            }

            //
            // "recurse" onto child
            //
            ParentCell = Cell;
            Cell = SubKey;
            goto NewKey;

            ResumeKey:;                 // A jump here is a virtual return
                                        // Cell, ParentCell and Index
                                        // must be defined
        }

        //
        // since we're here, we've checked out all the children
        // of the current cell.
        //
        if (Cell == StartCell) {

            //
            // we are done
            //
            return 0;
        }

        //
        // "return" to "parent instance"
        //
        pcell = HvGetCell(HiveToCheck, Cell);
        if( pcell == NULL ) {
            //
            // we couldn't map a view for the bin containing this cell
            //
            CmKdPrintEx((DPFLTR_CONFIG_ID,DPFLTR_ERROR_LEVEL,"\tCould not map cell #%08lx\n", Cell));
            CmpCheckRegistry2Debug.Status = 4097;
            return 4097;
        }

        Index = pcell->u.KeyNode.WorkVar;

        Cell = ParentCell;

        pcell = HvGetCell(HiveToCheck, Cell);
        if( pcell == NULL ) {
            //
            // we couldn't map a view for the bin containing this cell
            //
            CmKdPrintEx((DPFLTR_CONFIG_ID,DPFLTR_ERROR_LEVEL,"\tCould not map cell #%08lx\n", Cell));
            CmpCheckRegistry2Debug.Status = 4096;
            return 4096;
        }
        ParentCell = pcell->u.KeyNode.Parent;

        goto ResumeKey;
}

#endif //_CM_LDR_

#if DBG

#define VOLATILE_KEY_NAME_LENGTH        PAGE_SIZE

HCELL_INDEX     CmpKeyCellDebug = 0;
WCHAR           CmpVolatileKeyNameBuffer[VOLATILE_KEY_NAME_LENGTH/2];
#endif //DBG

ULONG
CmpCheckKey(
    PHHIVE      HiveToCheck,
    ULONG       CheckFlags,
    HCELL_INDEX Cell,
    HCELL_INDEX ParentCell,
    BOOLEAN     ResetSD
    )
/*++

Routine Description:

    Check consistency of the registry, for a particular cell

        .   Check that the cell's value list, child key list, class,
            security are OK.
        .   Check that each value entry IN the list is OK.

Arguments:

    Cell - HCELL_INDEX of subkey to work on.

    ParentCell - expected value of parent cell for Cell, unless
                 HCELL_NIL, in which case ignore.

Return Value:

    0 if Hive is OK.  Error return indicator if not.

    RANGE:  4000 - 4999

--*/
{
    PCELL_DATA      pcell;
    ULONG           size;
    ULONG           usedlen;
    ULONG           ClassLength;
    HCELL_INDEX     Class;
    ULONG           ValueCount;
    HCELL_INDEX     ValueList;
    HCELL_INDEX     Security;
    ULONG           rc = 0;
    ULONG           nrc = 0;
    ULONG           i;
    PCM_KEY_INDEX   Root;
    PCM_KEY_INDEX   Leaf;
    ULONG           SubCount;

    CmpCheckKeyDebug.Hive = HiveToCheck;
    CmpCheckKeyDebug.Status = 0;
    CmpCheckKeyDebug.Cell = Cell;
    CmpCheckKeyDebug.CellPoint = NULL;
    CmpCheckKeyDebug.RootPoint = NULL;
    CmpCheckKeyDebug.Index = (ULONG)-1;

#if DBG
    if(CmpKeyCellDebug == Cell) {
        CmKdPrintEx((DPFLTR_CONFIG_ID,DPFLTR_TRACE_LEVEL,"Hive = %p :: Cell to debug = %lx\n",HiveToCheck,(ULONG)Cell));
        DbgBreakPoint();
    }
#endif //DBG

    //
    // Check key itself
    //
    if (! HvIsCellAllocated(HiveToCheck, Cell)) {
        CmKdPrintEx((DPFLTR_CONFIG_ID,DPFLTR_ERROR_LEVEL,"CmpCheckKey: HiveToCheck:%p Cell:%08lx\n", HiveToCheck, Cell));
        CmKdPrintEx((DPFLTR_CONFIG_ID,DPFLTR_ERROR_LEVEL,"\tNot allocated\n"));
        rc = 4010;
        CmpCheckKeyDebug.Status = rc;
        return rc;
    }
    pcell = HvGetCell(HiveToCheck, Cell);
    if( pcell == NULL ) {
        //
        // we couldn't map a view for the bin containing this cell
        //
        CmKdPrintEx((DPFLTR_CONFIG_ID,DPFLTR_ERROR_LEVEL,"\tCould not map cell #%08lx\n", Cell));
        CmpCheckKeyDebug.Status = 4095;
        return 4095;
    }

    CmpCheckKeyDebug.CellPoint = pcell;

    size = HvGetCellSize(HiveToCheck, pcell);
    if (size > REG_MAX_PLAUSIBLE_KEY_SIZE) {
        CmKdPrintEx((DPFLTR_CONFIG_ID,DPFLTR_ERROR_LEVEL,"CmpCheckKey: HiveToCheck:%p Cell:%08lx\n", HiveToCheck, Cell));
        CmKdPrintEx((DPFLTR_CONFIG_ID,DPFLTR_ERROR_LEVEL,"\tImplausible size %lx\n", size));
        rc = 4020;
        CmpCheckKeyDebug.Status = rc;
        return rc;
    }
    usedlen = FIELD_OFFSET(CM_KEY_NODE, Name) + pcell->u.KeyNode.NameLength;
    if( (!pcell->u.KeyNode.NameLength) || (usedlen > size)) {
        CmKdPrintEx((DPFLTR_CONFIG_ID,DPFLTR_ERROR_LEVEL,"CmpCheckKey: HiveToCheck:%p Cell:%08lx\n", HiveToCheck, Cell));
        CmKdPrintEx((DPFLTR_CONFIG_ID,DPFLTR_ERROR_LEVEL,"\tKey is bigger than containing cell.\n"));
        rc = 4030;
        CmpCheckKeyDebug.Status = rc;
        return rc;
    }
    if (pcell->u.KeyNode.Signature != CM_KEY_NODE_SIGNATURE) {
        CmKdPrintEx((DPFLTR_CONFIG_ID,DPFLTR_ERROR_LEVEL,"CmpCheckKey: HiveToCheck:%p Cell:%08lx\n", HiveToCheck, Cell));
        CmKdPrintEx((DPFLTR_CONFIG_ID,DPFLTR_ERROR_LEVEL,"\tNo key signature\n"));
        rc = 4040;
        CmpCheckKeyDebug.Status = rc;
        if( CmDoSelfHeal() ) {
            //
            // this could be only signature corruption; fix it;
            //
            if( HvMarkCellDirty(HiveToCheck, Cell) ) {
                pcell->u.KeyNode.Signature = CM_KEY_NODE_SIGNATURE;
                rc = 0;
                CmMarkSelfHeal(HiveToCheck);
            } else {
                return rc;
            }
        } else {
            return rc;
        }
    }
    if (ParentCell != HCELL_NIL) {
        if (pcell->u.KeyNode.Parent != ParentCell) {
            CmKdPrintEx((DPFLTR_CONFIG_ID,DPFLTR_ERROR_LEVEL,"CmpCheckKey: HiveToCheck:%p Cell:%08lx\n", HiveToCheck, Cell));
            CmKdPrintEx((DPFLTR_CONFIG_ID,DPFLTR_ERROR_LEVEL,"\tWrong parent value.\n"));
            rc = 4045;
            CmpCheckKeyDebug.Status = rc;
            if( CmDoSelfHeal() ) {
                //
                // this could isolated corruption; fix it;
                //
                if( HvMarkCellDirty(HiveToCheck, Cell) ) {
                    pcell->u.KeyNode.Parent = ParentCell;
                    CmMarkSelfHeal(HiveToCheck);
                    rc = 0;
                } else {
                    return rc;
                }
            } else {
                return rc;
            }
        }
    }
    ClassLength = pcell->u.KeyNode.ClassLength;
    Class = pcell->u.KeyNode.Class;
    ValueCount = pcell->u.KeyNode.ValueList.Count;
    ValueList = pcell->u.KeyNode.ValueList.List;
    Security = pcell->u.KeyNode.Security;

    //
    // Check simple non-empty cases
    //
    if (ClassLength > 0) {
        if( Class == HCELL_NIL ) {
            pcell->u.KeyNode.ClassLength = 0;
            HvMarkCellDirty(HiveToCheck, Cell);
            CmKdPrintEx((DPFLTR_CONFIG_ID,DPFLTR_ERROR_LEVEL,"CmpCheckKey: HiveToCheck:%p Cell:%08lx has ClassLength = %lu and Class == HCELL_NIL\n", HiveToCheck, Cell,ClassLength));
        } else {
            if (HvIsCellAllocated(HiveToCheck, Class) == FALSE) {
                    CmKdPrintEx((DPFLTR_CONFIG_ID,DPFLTR_ERROR_LEVEL,"CmpCheckKey: HiveToCheck:%p Cell:%08lx\n", HiveToCheck, Cell));
                    CmKdPrintEx((DPFLTR_CONFIG_ID,DPFLTR_ERROR_LEVEL,"\tClass:%08lx - unallocated class\n", Class));
                    rc = 4080;
                    CmpCheckKeyDebug.Status = rc;
                    if( CmDoSelfHeal() ) {
                        //
                        // yank the class
                        //
                        if( HvMarkCellDirty(HiveToCheck, Cell) ) {
                            pcell->u.KeyNode.Class = HCELL_NIL;
                            pcell->u.KeyNode.ClassLength = 0;
                            CmMarkSelfHeal(HiveToCheck);
                            rc = 0;
                        } else {
                            return rc;
                        }
                    } else {
                        return rc;
                    }
            } 
        }
    }

    if (Security != HCELL_NIL) {
        if ((HvIsCellAllocated(HiveToCheck, Security) == FALSE) || 
            ((ParentCell != HCELL_NIL) && CmDoSelfHeal() && ResetSD) ) {
            CmKdPrintEx((DPFLTR_CONFIG_ID,DPFLTR_ERROR_LEVEL,"CmpCheckKey: HiveToCheck:%p Cell:%08lx\n", HiveToCheck, Cell));
            CmKdPrintEx((DPFLTR_CONFIG_ID,DPFLTR_ERROR_LEVEL,"\tSecurity:%08lx - unallocated security\n", Security));
            rc = 4090;
            CmpCheckKeyDebug.Status = rc;
            goto SetParentSecurity;
        } 
        //
        // Else CmpValidateHiveSecurityDescriptors must do computation
        //
    } else {
        CmKdPrintEx((DPFLTR_CONFIG_ID,DPFLTR_ERROR_LEVEL,"SecurityCell is HCELL_NIL for (%p,%08lx) !!!\n", HiveToCheck, Cell));
        rc = 4130;
        CmpCheckKeyDebug.Status = rc;
SetParentSecurity:
        if( CmDoSelfHeal() ) {
            //
            // attempt to set the same security as it's parent
            //
            PCM_KEY_NODE ParentNode = NULL;
            PCM_KEY_SECURITY SecurityNode = NULL;

            if( ParentCell != HCELL_NIL ) {
                ParentNode = (PCM_KEY_NODE )HvGetCell(HiveToCheck, ParentCell);
                SecurityNode = (PCM_KEY_SECURITY)HvGetCell(HiveToCheck, ParentNode->Security);
            }

            if( ParentNode == NULL || SecurityNode == NULL ) {
                //
                // we couldn't map a view for the bin containing this cell
                //
                return rc;
            }

            if( HvMarkCellDirty(HiveToCheck, Cell) &&  HvMarkCellDirty(HiveToCheck, ParentNode->Security) ) {
                pcell->u.KeyNode.Security = ParentNode->Security;
                SecurityNode->ReferenceCount++;
                rc = 0;
                CmMarkSelfHeal(HiveToCheck);
            } else {
                return rc;
            }
        } else {
            return rc;
        }
        
    }

    //
    // Check value list case
    //
    if (ValueCount > 0) {
        if (HvIsCellAllocated(HiveToCheck, ValueList) == FALSE) {
            CmKdPrintEx((DPFLTR_CONFIG_ID,DPFLTR_ERROR_LEVEL,"CmpCheckKey: HiveToCheck:%p Cell:%08lx\n", HiveToCheck, Cell));
            CmKdPrintEx((DPFLTR_CONFIG_ID,DPFLTR_ERROR_LEVEL,"\tValueList:%08lx - unallocated valuelist\n", ValueList));
            rc = 4100;
            CmpCheckKeyDebug.Status = rc;
            goto YankValueList;
        } else {
            pcell = HvGetCell(HiveToCheck, ValueList);
            if( pcell == NULL ) {
                //
                // we couldn't map a view for the bin containing this cell
                //
                CmKdPrintEx((DPFLTR_CONFIG_ID,DPFLTR_ERROR_LEVEL,"\tCould not map cell #%08lx\n", ValueList));
                CmpCheckKeyDebug.Status = 4094;
                return 4094;
            }
            if( ValueCount * sizeof(HCELL_INDEX) > (ULONG)HvGetCellSize(HiveToCheck,pcell) ) {
                //
                // implausible value count.
                //
                CmKdPrintEx((DPFLTR_CONFIG_ID,DPFLTR_ERROR_LEVEL,"CmpCheckKey: HiveToCheck:%p Cell:%08lx\n", HiveToCheck, Cell));
                CmKdPrintEx((DPFLTR_CONFIG_ID,DPFLTR_ERROR_LEVEL,"\tValueList:%08lx - Implausible ValueCount = %08lx\n", ValueList,ValueCount));
                rc = 4095;
                CmpCheckKeyDebug.Status = rc;
                goto YankValueList;
            }

            nrc = CmpCheckValueList(HiveToCheck, pcell, ValueCount,Cell);
            if (nrc != 0) {
                CmKdPrintEx((DPFLTR_CONFIG_ID,DPFLTR_ERROR_LEVEL,"List was for HiveToCheck:%p Cell:%08lx\n", HiveToCheck, Cell));
                rc = nrc;
                CmpCheckKeyDebug.CellPoint = pcell;
                CmpCheckKeyDebug.Status = rc;
YankValueList:
                if( CmDoSelfHeal() ) {
                    PCM_KEY_NODE KeyNode;
                    //
                    // make the key valueless
                    //
                    if( HvMarkCellDirty(HiveToCheck, Cell) && (KeyNode = (PCM_KEY_NODE)HvGetCell(HiveToCheck, Cell) ) ) {
                        KeyNode->ValueList.Count = 0;
                        KeyNode->ValueList.List = HCELL_NIL;
                        CmMarkSelfHeal(HiveToCheck);
                        rc = 0;
                    } else {
                        return rc;
                    }
                } else {
                    return rc;
                }
            }
        }
    }


    //
    // Check subkey list case
    //

    pcell = HvGetCell(HiveToCheck, Cell);
    if( pcell == NULL ) {
        //
        // we couldn't map a view for the bin containing this cell
        //
        CmKdPrintEx((DPFLTR_CONFIG_ID,DPFLTR_ERROR_LEVEL,"\tCould not map cell #%08lx\n", Cell));
        CmpCheckKeyDebug.Status = 4093;
        return 4093;
    }
    CmpCheckKeyDebug.CellPoint = pcell;
    if ((HvGetCellType(Cell) == Volatile) &&
        (pcell->u.KeyNode.SubKeyCounts[Stable] != 0))
    {
        CmKdPrintEx((DPFLTR_CONFIG_ID,DPFLTR_ERROR_LEVEL,"CmpCheckKey: HiveToCheck:%p Cell:%08lx\n", HiveToCheck, Cell));
        CmKdPrintEx((DPFLTR_CONFIG_ID,DPFLTR_ERROR_LEVEL,"\tVolatile Cell has Stable children\n"));
        rc = 4108;
        CmpCheckKeyDebug.Status = rc;
        return rc;
    } else if (pcell->u.KeyNode.SubKeyCounts[Stable] > 0) {
        if (! HvIsCellAllocated(HiveToCheck, pcell->u.KeyNode.SubKeyLists[Stable])) {
            CmKdPrintEx((DPFLTR_CONFIG_ID,DPFLTR_ERROR_LEVEL,"CmpCheckKey: HiveToCheck:%p Cell:%08lx\n", HiveToCheck, Cell));
            CmKdPrintEx((DPFLTR_CONFIG_ID,DPFLTR_ERROR_LEVEL,"\tStableKeyList:%08lx - unallocated\n", pcell->u.KeyNode.SubKeyLists[Stable]));
            rc = 4110;
            CmpCheckKeyDebug.Status = rc;
            goto YankStableSubkeys;
        } else {
            //
            // Prove that the index is OK
            //
            Root = (PCM_KEY_INDEX)HvGetCell(
                                    HiveToCheck,
                                    pcell->u.KeyNode.SubKeyLists[Stable]
                                    );
            if( Root == NULL ) {
                //
                // we couldn't map a view for the bin containing this cell
                //
                CmKdPrintEx((DPFLTR_CONFIG_ID,DPFLTR_ERROR_LEVEL,"\tCould not map cell #%08lx\n", pcell->u.KeyNode.SubKeyLists[Stable]));
                CmpCheckKeyDebug.Status = 4093;
                return 4093;
            }
            CmpCheckKeyDebug.RootPoint = Root;
            if ((Root->Signature == CM_KEY_INDEX_LEAF) ||
                (Root->Signature == CM_KEY_FAST_LEAF)  ||
                (Root->Signature == CM_KEY_HASH_LEAF) ) {
                if ((ULONG)Root->Count != pcell->u.KeyNode.SubKeyCounts[Stable]) {
                    CmKdPrintEx((DPFLTR_CONFIG_ID,DPFLTR_ERROR_LEVEL,"CmpCheckKey: HiveToCheck:%p Cell:%08lx\n", HiveToCheck, Cell));
                    CmKdPrintEx((DPFLTR_CONFIG_ID,DPFLTR_ERROR_LEVEL,"\tBad Index count @%08lx\n", Root));
                    rc = 4120;
                    CmpCheckKeyDebug.Status = rc;
                    if( CmDoSelfHeal() ) {
                        //
                        // fix the subkeycount
                        //
                        if( HvMarkCellDirty(HiveToCheck, Cell) ) {
                            pcell->u.KeyNode.SubKeyCounts[Stable] = (ULONG)Root->Count;
                            CmMarkSelfHeal(HiveToCheck);
                            rc = 0;
                        } else {
                            return rc;
                        }
                    } else {
                        return rc;
                    } 
                }
            } else if (Root->Signature == CM_KEY_INDEX_ROOT) {
                SubCount = 0;
                for (i = 0; i < Root->Count; i++) {
                    CmpCheckKeyDebug.Index = i;
                    if (! HvIsCellAllocated(HiveToCheck, Root->List[i])) {
                        CmKdPrintEx((DPFLTR_CONFIG_ID,DPFLTR_ERROR_LEVEL,"CmpCheckKey: Hive:%p Cell:%08lx\n", HiveToCheck, Cell));
                        CmKdPrintEx((DPFLTR_CONFIG_ID,DPFLTR_ERROR_LEVEL,"\tBad Leaf Cell %08lx Root@%08lx\n", Root->List[i], Root));
                        rc = 4130;
                        CmpCheckKeyDebug.Status = rc;
                        goto YankStableSubkeys;
                    }
                    Leaf = (PCM_KEY_INDEX)HvGetCell(HiveToCheck,
                                                    Root->List[i]);
                    if( Leaf == NULL ) {
                        //
                        // we couldn't map a view for the bin containing this cell
                        //
                        CmKdPrintEx((DPFLTR_CONFIG_ID,DPFLTR_ERROR_LEVEL,"\tCould not map cell #%08lx\n", Root->List[i]));
                        CmpCheckKeyDebug.Status = 4092;
                        return 4092;
                    }

                    if ((Leaf->Signature != CM_KEY_INDEX_LEAF) &&
                        (Leaf->Signature != CM_KEY_FAST_LEAF)  &&
                        (Leaf->Signature != CM_KEY_HASH_LEAF) ) {
                        CmKdPrintEx((DPFLTR_CONFIG_ID,DPFLTR_ERROR_LEVEL,"CmpCheckKey: HiveToCheck:%p Cell:%08lx\n", HiveToCheck, Cell));
                        CmKdPrintEx((DPFLTR_CONFIG_ID,DPFLTR_ERROR_LEVEL,"\tBad Leaf Index @%08lx Root@%08lx\n", Leaf, Root));
                        rc = 4140;
                        CmpCheckKeyDebug.Status = rc;
                        goto YankStableSubkeys;
                    }
                    SubCount += Leaf->Count;
                }
                if (pcell->u.KeyNode.SubKeyCounts[Stable] != SubCount) {
                    CmKdPrintEx((DPFLTR_CONFIG_ID,DPFLTR_ERROR_LEVEL,"CmpCheckKey: HiveToCheck:%p Cell:%08lx\n", HiveToCheck, Cell));
                    CmKdPrintEx((DPFLTR_CONFIG_ID,DPFLTR_ERROR_LEVEL,"\tBad count in index, SubCount=%08lx\n", SubCount));
                    rc = 4150;
                    CmpCheckKeyDebug.Status = rc;
                    if( CmDoSelfHeal() ) {
                        //
                        // fix the subkeycount
                        //
                        if( HvMarkCellDirty(HiveToCheck, Cell) ) {
                            pcell->u.KeyNode.SubKeyCounts[Stable] = SubCount;
                            CmMarkSelfHeal(HiveToCheck);
                            rc = 0;
                        } else {
                            return rc;
                        }
                    } else {
                        return rc;
                    } 
                }
            } else {
                CmKdPrintEx((DPFLTR_CONFIG_ID,DPFLTR_ERROR_LEVEL,"CmpCheckKey: HiveToCheck:%p Cell:%08lx\n", HiveToCheck, Cell));
                CmKdPrintEx((DPFLTR_CONFIG_ID,DPFLTR_ERROR_LEVEL,"\tBad Root index signature @%08lx\n", Root));
                rc = 4120;
                CmpCheckKeyDebug.Status = rc;
                goto YankStableSubkeys;
            }
        }
    }
    if( FALSE ) {
YankStableSubkeys:
        if( CmDoSelfHeal() ) {
            //
            // mark the key as no subkeys
            //
            if( HvMarkCellDirty(HiveToCheck, Cell) ) {
                pcell->u.KeyNode.SubKeyCounts[Stable] = 0;
                pcell->u.KeyNode.SubKeyLists[Stable] = HCELL_NIL;
                CmMarkSelfHeal(HiveToCheck);
                rc = 0;
            } else {
                return rc;
            }
        } else {
            return rc;
        } 
    }
    //
    // force volatiles to be empty, if this is a load operation
    //
    if ( (CheckFlags & CM_CHECK_REGISTRY_FORCE_CLEAN) || // force clear out volatile info 
         ( 
             ( CheckFlags & (CM_CHECK_REGISTRY_CHECK_CLEAN | CM_CHECK_REGISTRY_LOADER_CLEAN) ) &&  // if asked to clear volatile info
             ( pcell->u.KeyNode.SubKeyCounts[Volatile] != 0 )                               // there is some volatile info saved from a previous version
         )                                             ||
         (
             ( CheckFlags & CM_CHECK_REGISTRY_SYSTEM_CLEAN ) &&         // system hive special case; the loader has cleaned only subkeycount
             (( pcell->u.KeyNode.SubKeyLists[Volatile] != HCELL_NIL ) ||    // now it is our job to clear Subkeylist, too
             (HiveToCheck->Version < HSYS_WHISTLER_BETA1) )
         ) 
        
        ) {
        //
        // go ahead and clear the volatile info for this key
        //
        if( CheckFlags & CM_CHECK_REGISTRY_SYSTEM_CLEAN ) {
            //
            // the loader must've left this on the previous value and cleared only the count
            //
            ASSERT( pcell->u.KeyNode.SubKeyLists[Volatile] == 0xBAADF00D || HiveToCheck->Version < HSYS_WHISTLER_BETA1 );
            ASSERT( pcell->u.KeyNode.SubKeyCounts[Volatile] == 0 );
#if DBG
#ifndef _CM_LDR_
            //
            // see who those volatile keys are
            //
            {
                ULONG           TotalLength = 0;
                HCELL_INDEX     CurrCell = Cell;
                PCM_KEY_NODE    CurrNode;
                PUCHAR          Dest;
                ULONG           k;

                Dest = ((PUCHAR)CmpVolatileKeyNameBuffer) + VOLATILE_KEY_NAME_LENGTH - 2;
                while(TRUE) {
                    CurrNode = (PCM_KEY_NODE)HvGetCell(HiveToCheck,CurrCell);
                    Dest -= CurrNode->NameLength;
                    TotalLength += CurrNode->NameLength;
                    if (CurrNode->Flags & KEY_COMP_NAME) {
                        Dest -= CurrNode->NameLength;
                        for (k=0;k<CurrNode->NameLength;k++) {
                            ((PWCHAR)Dest)[k] = (WCHAR)(((PUCHAR)CurrNode->Name)[k]);
                        }
                    } else {
                        RtlCopyMemory(
                            Dest,
                            CurrNode->Name,
                            CurrNode->NameLength
                            );
                    }
                    Dest -= 2;
                    TotalLength += (CurrNode->NameLength +2);
                    ((PWCHAR)Dest)[0] = (WCHAR)'\\';
                    if( CurrCell == HiveToCheck->BaseBlock->RootCell ) {
                        break;
                    }
                    CurrCell = CurrNode->Parent;
                }  
                CmKdPrintEx((DPFLTR_CONFIG_ID,DPFLTR_TRACE_LEVEL,"%.*S\n",TotalLength/2,Dest));
                
            }
#endif
#endif

        }

        HvMarkCellDirty(HiveToCheck, Cell);
        //CmKdPrintEx((DPFLTR_CONFIG_ID,DPFLTR_TRACE_LEVEL,"Clear Volatile Info for Hive = %p Cell = %lx\n", HiveToCheck, Cell));
        pcell->u.KeyNode.SubKeyCounts[Volatile] = 0;
        if( (CheckFlags & CM_CHECK_REGISTRY_LOADER_CLEAN) &&
            (HiveToCheck->Version >= HSYS_WHISTLER_BETA1)
            ) {
            //
            // mark this as bad food
            //
            pcell->u.KeyNode.SubKeyLists[Volatile] = 0xBAADF00D;
        } else {
            //
            // clean it up 
            //
            pcell->u.KeyNode.SubKeyLists[Volatile] = HCELL_NIL;
        }
    }

    return rc;
}

ULONG
CmpCheckValueList(
    PHHIVE      Hive,
    PCELL_DATA  List,
    ULONG       Count,
    HCELL_INDEX KeyCell
    )
/*++

Routine Description:

    Check consistency of a value list.
        .   Each element allocated?
        .   Each element have valid signature?
        .   Data properly allocated?

Arguments:

    Hive - containing Hive.

    List - pointer to an array of HCELL_INDEX entries.

    Count - number of entries in list.

Return Value:

    0 if Hive is OK.  Error return indicator if not.

    RANGE:  5000 - 5999

--*/
{
    ULONG           i = 0,j;
    HCELL_INDEX     Cell;
    PCELL_DATA      pcell;
    ULONG           size;
    ULONG           usedlen;
    ULONG           DataLength;
    HCELL_INDEX     Data;
    ULONG           rc = 0;

    CmpCheckValueListDebug.Hive = Hive;
    CmpCheckValueListDebug.Status = 0;
    CmpCheckValueListDebug.List = List;
    CmpCheckValueListDebug.Index = (ULONG)-1;
    CmpCheckValueListDebug.Cell = 0;   // NOT HCELL_NIL
    CmpCheckValueListDebug.CellPoint = NULL;

    if( FALSE ) {
RemoveThisValue:
        if( CmDoSelfHeal() ) {
            //
            // remove value at index i
            //
            PCM_KEY_NODE    Node;
            Node = (PCM_KEY_NODE)HvGetCell(Hive,KeyCell);
            if( Node == NULL ) {
                return rc;
            }
            HvReleaseCell(Hive,KeyCell);

            if( HvMarkCellDirty(Hive, KeyCell) &&
                HvMarkCellDirty(Hive, Node->ValueList.List)) {
                Node->ValueList.Count--;
                Count--;
                RtlMoveMemory(&(List->u.KeyList[i]),&(List->u.KeyList[i+1]),(Count - i)*sizeof(HCELL_INDEX));
                rc = 0;
                CmMarkSelfHeal(Hive);
            } else {
                return rc;
            }
        } else {
            return rc;
        } 
    }

    for (; i < Count; i++) {

        //
        // Check out value entry's refs.
        //
        Cell = List->u.KeyList[i];
        if (Cell == HCELL_NIL) {
            CmKdPrintEx((DPFLTR_CONFIG_ID,DPFLTR_ERROR_LEVEL,"CmpCheckValueList: List:%p i:%08lx\n", List, i));
            CmKdPrintEx((DPFLTR_CONFIG_ID,DPFLTR_ERROR_LEVEL,"\tEntry is null\n"));
            rc = 5010;
            CmpCheckValueListDebug.Status = rc;
            CmpCheckValueListDebug.Index = i;
            CmpCheckValueListDebug.Cell = Cell;
            goto RemoveThisValue;
        }
        if (HvIsCellAllocated(Hive, Cell) == FALSE) {
            CmKdPrintEx((DPFLTR_CONFIG_ID,DPFLTR_ERROR_LEVEL,"CmpCheckValueList: List:%p i:%08lx\n", List, i));
            CmKdPrintEx((DPFLTR_CONFIG_ID,DPFLTR_ERROR_LEVEL,"\tEntry is not allocated\n"));
            rc = 5020;
            CmpCheckValueListDebug.Status = rc;
            CmpCheckValueListDebug.Index = i;
            CmpCheckValueListDebug.Cell = Cell;
            goto RemoveThisValue;
        } 

        //
        // Check out the value entry itself
        //
        pcell = HvGetCell(Hive, Cell);
        if( pcell == NULL ) {
            //
            // we couldn't map a view for the bin containing this cell
            //
            CmKdPrintEx((DPFLTR_CONFIG_ID,DPFLTR_ERROR_LEVEL,"\tCould not map cell #%08lx\n", Cell));
            CmpCheckValueListDebug.Status = 5099;
            CmpCheckValueListDebug.Index = i;
            CmpCheckValueListDebug.Cell = Cell;
            rc = 5099;
            goto Exit;
        }
        size = HvGetCellSize(Hive, pcell);
        if (pcell->u.KeyValue.Signature != CM_KEY_VALUE_SIGNATURE) {
            CmKdPrintEx((DPFLTR_CONFIG_ID,DPFLTR_ERROR_LEVEL,"CmpCheckValueList: List:%p i:%08lx\n", List, i));
            CmKdPrintEx((DPFLTR_CONFIG_ID,DPFLTR_ERROR_LEVEL,"\tCell:%08lx - invalid value signature\n", Cell));
            rc = 5030;
            CmpCheckValueListDebug.Status = rc;
            CmpCheckValueListDebug.Index = i;
            CmpCheckValueListDebug.Cell = Cell;
            CmpCheckValueListDebug.CellPoint = pcell;
            goto RemoveThisValue;
        }
        usedlen = FIELD_OFFSET(CM_KEY_VALUE, Name) + pcell->u.KeyValue.NameLength;
        if (usedlen > size) {
            CmKdPrintEx((DPFLTR_CONFIG_ID,DPFLTR_ERROR_LEVEL,"CmpCheckValueList: List:%p i:%08lx\n", List, i));
            CmKdPrintEx((DPFLTR_CONFIG_ID,DPFLTR_ERROR_LEVEL,"\tCell:%08lx - value bigger than containing cell\n", Cell));
            rc = 5040;
            CmpCheckValueListDebug.Status = rc;
            CmpCheckValueListDebug.Index = i;
            CmpCheckValueListDebug.Cell = Cell;
            CmpCheckValueListDebug.CellPoint = pcell;
            goto RemoveThisValue;
        }

        //
        // Check out value entry's data
        //
        DataLength = pcell->u.KeyValue.DataLength;
        if (DataLength < CM_KEY_VALUE_SPECIAL_SIZE) {
            Data = pcell->u.KeyValue.Data;
            if ((DataLength == 0) && (Data != HCELL_NIL)) {
                CmKdPrintEx((DPFLTR_CONFIG_ID,DPFLTR_ERROR_LEVEL,"CmpCheckValueList: List:%p i:%08lx\n", List, i));
                CmKdPrintEx((DPFLTR_CONFIG_ID,DPFLTR_ERROR_LEVEL,"\tCell:%08lx Data:%08lx - data not null\n", Cell, Data));
                rc = 5050;
                CmpCheckValueListDebug.Status = rc;
                CmpCheckValueListDebug.Index = i;
                CmpCheckValueListDebug.Cell = Cell;
                CmpCheckValueListDebug.CellPoint = pcell;
                goto RemoveThisValue;
            }
            if (DataLength > 0) {
                if (HvIsCellAllocated(Hive, Data) == FALSE) {
                    CmKdPrintEx((DPFLTR_CONFIG_ID,DPFLTR_ERROR_LEVEL,"CmpCheckValueList: List:%p i:%08lx\n", List, i));
                    CmKdPrintEx((DPFLTR_CONFIG_ID,DPFLTR_ERROR_LEVEL,"\tCell:%08lx Data:%08lx - unallocated\n", Cell, Data));
                    rc = 5060;
                    CmpCheckValueListDebug.Status = rc;
                    CmpCheckValueListDebug.Index = i;
                    CmpCheckValueListDebug.Cell = Cell;
                    CmpCheckValueListDebug.CellPoint = pcell;
                    goto RemoveThisValue;
                }
            }
            if( CmpIsHKeyValueBig(Hive,DataLength) == TRUE ) {
                PCM_BIG_DATA    BigData;
                PHCELL_INDEX    Plist;

                BigData = (PCM_BIG_DATA)HvGetCell(Hive, Data);
                if( BigData == NULL ) {
                    //
                    // we couldn't map a view for the bin containing this cell
                    //
                    CmKdPrintEx((DPFLTR_CONFIG_ID,DPFLTR_ERROR_LEVEL,"\tCould not map cell #%08lx\n", Data));
                    CmpCheckValueListDebug.Status = 5098;
                    CmpCheckValueListDebug.Index = i;
                    CmpCheckValueListDebug.Cell = Data;
                    rc = 5098;
                    goto Exit;
                }
                
                if( (BigData->Signature != CM_BIG_DATA_SIGNATURE) ||
                    (BigData->Count == 0 ) ||
                    (BigData->List == HCELL_NIL) 
                    ) {
                    CmKdPrintEx((DPFLTR_CONFIG_ID,DPFLTR_ERROR_LEVEL,"\tinvalid big data cell #%08lx\n", Data));
                    CmpCheckValueListDebug.Status = 5097;
                    CmpCheckValueListDebug.Index = i;
                    CmpCheckValueListDebug.Cell = Data;
                    rc = 5097;
                    goto RemoveThisValue;
                }
                
                if (HvIsCellAllocated(Hive, BigData->List) == FALSE) {
                    CmKdPrintEx((DPFLTR_CONFIG_ID,DPFLTR_ERROR_LEVEL,"CmpCheckValueList: List:%p i:%08lx\n", List, i));
                    CmKdPrintEx((DPFLTR_CONFIG_ID,DPFLTR_ERROR_LEVEL,"\tCell:%08lx DataList:%08lx - unallocated\n", Cell, BigData->List));
                    rc = 5096;
                    CmpCheckValueListDebug.Status = rc;
                    CmpCheckValueListDebug.Index = i;
                    CmpCheckValueListDebug.Cell = BigData->List;
                    CmpCheckValueListDebug.CellPoint = (PCELL_DATA)BigData;
                    goto RemoveThisValue;
                }

                Plist = (PHCELL_INDEX)HvGetCell(Hive,BigData->List);
                if( Plist == NULL ) {
                    //
                    // we couldn't map a view for the bin containing this cell
                    //
                    CmKdPrintEx((DPFLTR_CONFIG_ID,DPFLTR_ERROR_LEVEL,"\tCould not map cell #%08lx\n", BigData->List));
                    CmpCheckValueListDebug.Status = 5098;
                    CmpCheckValueListDebug.Index = i;
                    CmpCheckValueListDebug.Cell = BigData->List;
                    rc = 5095;
                    goto Exit;
                }

                //
                // check each and every big data cell to see if it is allocated.
                // 
                for(j=0;j<BigData->Count;j++) {
                    if (HvIsCellAllocated(Hive, Plist[j]) == FALSE) {
                        CmKdPrintEx((DPFLTR_CONFIG_ID,DPFLTR_ERROR_LEVEL,"CmpCheckValueList: List:%p j:%08lx\n", BigData->List, j));
                        CmKdPrintEx((DPFLTR_CONFIG_ID,DPFLTR_ERROR_LEVEL,"\tCell:%08lx BigData:%08lx - unallocated\n", Plist[j], BigData->List));
                        rc = 5094;
                        CmpCheckValueListDebug.Status = rc;
                        CmpCheckValueListDebug.Index = j;
                        CmpCheckValueListDebug.Cell = Plist[j];
                        CmpCheckValueListDebug.CellPoint = (PCELL_DATA)BigData;
                        goto RemoveThisValue;
                    }
                }
            }

        }
    }

Exit:
    // cleanup
        
    return rc;
}

#ifdef CHECK_REGISTRY_USECOUNT

extern LIST_ENTRY CmpHiveListHead;

VOID
CmpCheckRegistryUseCount( ) 
{
    PLIST_ENTRY p;
    PCMHIVE     CmHive;

    ASSERT_CM_LOCK_OWNED_EXCLUSIVE();
    
    LOCK_HIVE_LIST();
    p = CmpHiveListHead.Flink;
    while(p != &CmpHiveListHead) {
        CmHive = CONTAINING_RECORD(p, CMHIVE, HiveList);
        
        if( CmHive->UseCount != 0 ){
            DbgPrintEx(DPFLTR_CONFIG_ID,DPFLTR_ERROR_LEVEL,"Hive (%p) is supposed to have USECount == 0 at this point; instead UseCount = %lu\n",CmHive,CmHive->UseCount);  
            DbgBreakPoint();
        }

        p=p->Flink;
    }
    UNLOCK_HIVE_LIST();

}
#endif
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\base\ntos\config\cmchek2.c ===
/*++

Copyright (c) 1991  Microsoft Corporation

Module Name:

    cmchek2.c

Abstract:

    This module implements consistency checking for the registry.


Author:

    Bryan M. Willman (bryanwi) 27-Jan-92

Environment:


Revision History:

--*/

#include    "cmp.h"

#ifdef ALLOC_PRAGMA
#pragma alloc_text(PAGE,CmpValidateHiveSecurityDescriptors)
#endif

extern ULONG   CmpUsedStorage;

#ifdef HIVE_SECURITY_STATS
ULONG
CmpCheckForSecurityDuplicates(
    IN OUT PCMHIVE      CmHive
                              );
#endif

BOOLEAN
CmpValidateHiveSecurityDescriptors(
    IN PHHIVE       Hive,
    OUT PBOOLEAN    ResetSD
    )
/*++

Routine Description:

    Walks the list of security descriptors present in the hive and passes
    each security descriptor to RtlValidSecurityDescriptor.

    Only applies to descriptors in Stable store.  Those in Volatile store
    cannot have come from disk and therefore do not need this treatment
    anyway.

Arguments:

    Hive - Supplies pointer to the hive control structure

Return Value:

    TRUE  - All security descriptors are valid
    FALSE - At least one security descriptor is invalid

--*/

{
    PCM_KEY_NODE        RootNode;
    PCM_KEY_SECURITY    SecurityCell;
    HCELL_INDEX         ListAnchor;
    HCELL_INDEX         NextCell;
    HCELL_INDEX         LastCell;
    BOOLEAN             BuildSecurityCache;

#ifdef HIVE_SECURITY_STATS
    UNICODE_STRING      HiveName;
    ULONG               NoOfCells = 0;
    ULONG               SmallestSize = 0;
    ULONG               BiggestSize = 0;
    ULONG               TotalSecuritySize = 0;

    RtlInitUnicodeString(&HiveName, (PCWSTR)Hive->BaseBlock->FileName);
#ifndef _CM_LDR_
    DbgPrintEx(DPFLTR_CONFIG_ID,DPFLTR_TRACE_LEVEL,"Security stats for hive (%lx) (%.*S):\n",Hive,HiveName.Length / sizeof(WCHAR),HiveName.Buffer);
#endif //_CM_LDR_

#endif

    CmKdPrintEx((DPFLTR_CONFIG_ID,CML_SEC,"CmpValidateHiveSecurityDescriptor: Hive = %p\n",(ULONG_PTR)Hive));

    ASSERT( Hive->ReleaseCellRoutine == NULL );

    *ResetSD = FALSE;

    if( ((PCMHIVE)Hive)->SecurityCount == 0 ) {
        BuildSecurityCache = TRUE;
    } else {
        BuildSecurityCache = FALSE;
    }
    if (!HvIsCellAllocated(Hive,Hive->BaseBlock->RootCell)) {
        //
        // root cell HCELL_INDEX is bogus
        //
        return(FALSE);
    }
    RootNode = (PCM_KEY_NODE) HvGetCell(Hive, Hive->BaseBlock->RootCell);
    if( RootNode == NULL ) {
        //
        // we couldn't map a view for the bin containing this cell
        //
        return FALSE;
    }
    
    if( FALSE ) {
YankSD:
        if( CmDoSelfHeal() ) {
            //
            // reset all security for the entire hive to the root security. There is no reliable way to 
            // patch the security list
            //
            SecurityCell = (PCM_KEY_SECURITY) HvGetCell(Hive, RootNode->Security);
            if( SecurityCell == NULL ) {
                return FALSE;
            }

            if( HvMarkCellDirty(Hive, RootNode->Security) ) {
                SecurityCell->Flink = SecurityCell->Blink = RootNode->Security;
            } else {
                return FALSE;
            }
            //
            // destroy existing cache and set up an empty one
            //
            CmpDestroySecurityCache((PCMHIVE)Hive);
            CmpInitSecurityCache((PCMHIVE)Hive);
            CmMarkSelfHeal(Hive);
            *ResetSD = TRUE;

        } else {
            return FALSE;
        }

    }

    LastCell = 0;
    ListAnchor = NextCell = RootNode->Security;

    do {
        if (!HvIsCellAllocated(Hive, NextCell)) {
            CmKdPrintEx((DPFLTR_CONFIG_ID,CML_SEC,"CM: CmpValidateHiveSecurityDescriptors\n"));
            CmKdPrintEx((DPFLTR_CONFIG_ID,CML_SEC,"    NextCell: %08lx is invalid HCELL_INDEX\n",NextCell));
            goto YankSD;
        }
        SecurityCell = (PCM_KEY_SECURITY) HvGetCell(Hive, NextCell);
        if( SecurityCell == NULL ) {
            //
            // we couldn't map a view for the bin containing this cell
            //
            return FALSE;
        }
#ifdef HIVE_SECURITY_STATS
        NoOfCells++;
        if( (SmallestSize == 0) || ((SecurityCell->DescriptorLength + FIELD_OFFSET(CM_KEY_SECURITY, Descriptor)) < SmallestSize) ) {
            SmallestSize = SecurityCell->DescriptorLength + FIELD_OFFSET(CM_KEY_SECURITY, Descriptor);
        }
        if( (BiggestSize == 0) || ((SecurityCell->DescriptorLength + FIELD_OFFSET(CM_KEY_SECURITY, Descriptor)) > BiggestSize) ) {
            BiggestSize = SecurityCell->DescriptorLength + FIELD_OFFSET(CM_KEY_SECURITY, Descriptor);
        }
        TotalSecuritySize += (SecurityCell->DescriptorLength + FIELD_OFFSET(CM_KEY_SECURITY, Descriptor));

#endif

        if (NextCell != ListAnchor) {
            //
            // Check to make sure that our Blink points to where we just
            // came from.
            //
            if (SecurityCell->Blink != LastCell) {
                CmKdPrintEx((DPFLTR_CONFIG_ID,CML_SEC,"  Invalid Blink (%08lx) on security cell %08lx\n",SecurityCell->Blink, NextCell));
                CmKdPrintEx((DPFLTR_CONFIG_ID,CML_SEC,"  should point to %08lx\n", LastCell));
                return(FALSE);
            }
        }

        CmKdPrintEx((DPFLTR_CONFIG_ID,CML_SEC,"CmpValidSD:  SD shared by %d nodes\n",SecurityCell->ReferenceCount));
        if (!SeValidSecurityDescriptor(SecurityCell->DescriptorLength, &SecurityCell->Descriptor)) {
#if DBG
            CmpDumpSecurityDescriptor(&SecurityCell->Descriptor,"INVALID DESCRIPTOR");
#endif
            goto YankSD;
        }
        //
        // cache this security cell; now that we know it is valid
        //
        if( BuildSecurityCache == TRUE ) {
            if( !NT_SUCCESS(CmpAddSecurityCellToCache ( (PCMHIVE)Hive,NextCell,TRUE) ) ) {
                return FALSE;
            }
        } else {
            //
            // just check this cell is there
            //
            ULONG Index;
            if( CmpFindSecurityCellCacheIndex ((PCMHIVE)Hive,NextCell,&Index) == FALSE ) {
                //
                // bad things happened; maybe an error in our caching code?
                //
                return FALSE;
            }

        }

        LastCell = NextCell;
        NextCell = SecurityCell->Flink;
    } while ( NextCell != ListAnchor );
#ifdef HIVE_SECURITY_STATS

#ifndef _CM_LDR_
    DbgPrintEx(DPFLTR_CONFIG_ID,DPFLTR_TRACE_LEVEL,"\t NumberOfCells    \t = %20lu (%8lx) \n",NoOfCells,NoOfCells);
    DbgPrintEx(DPFLTR_CONFIG_ID,DPFLTR_TRACE_LEVEL,"\t SmallestCellSize \t = %20lu (%8lx) \n",SmallestSize,SmallestSize);
    DbgPrintEx(DPFLTR_CONFIG_ID,DPFLTR_TRACE_LEVEL,"\t BiggestCellSize  \t = %20lu (%8lx) \n",BiggestSize,BiggestSize);
    DbgPrintEx(DPFLTR_CONFIG_ID,DPFLTR_TRACE_LEVEL,"\t TotalSecuritySize\t = %20lu (%8lx) \n",TotalSecuritySize,TotalSecuritySize);
    DbgPrintEx(DPFLTR_CONFIG_ID,DPFLTR_TRACE_LEVEL,"\t HiveLength       \t = %20lu (%8lx) \n",Hive->BaseBlock->Length,Hive->BaseBlock->Length);
    DbgPrintEx(DPFLTR_CONFIG_ID,DPFLTR_TRACE_LEVEL,"\n");
#endif //_CM_LDR_

#endif

    if( BuildSecurityCache == TRUE ) {
        //
        // adjust the size of the cache in case we allocated too much
        //
        CmpAdjustSecurityCacheSize ( (PCMHIVE)Hive );
#ifdef HIVE_SECURITY_STATS
        {
            ULONG Duplicates;
            
            Duplicates = CmpCheckForSecurityDuplicates((PCMHIVE)Hive);
            if( Duplicates ) {
#ifndef _CM_LDR_
                DbgPrintEx(DPFLTR_CONFIG_ID,DPFLTR_TRACE_LEVEL,"Hive %p %lu security cells duplicated !!!\n",Hive,Duplicates);
#endif //_CM_LDR_
            }
        }
#endif
    }

    return(TRUE);
}
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\base\ntos\config\cmboot.c ===
/*++

Copyright (c) 1991  Microsoft Corporation

Module Name:

    cmboot.c

Abstract:

    This provides routines for determining driver load lists from the
    registry.  The relevant drivers are extracted from the registry,
    sorted by groups, and then dependencies are resolved.

    This module is used both by the OS Loader for determining the boot
    driver list (CmScanRegistry) and by IoInitSystem for determining
    the drivers to be loaded in Phase 1 Initialization
    (CmGetSystemDriverList)

Author:

    John Vert (jvert) 7-Apr-1992

Environment:

    OS Loader environment
        or
    kernel mode

Revision History:

--*/
#include "cmp.h"
#include <profiles.h>

#define LOAD_LAST 0xffffffff
#define LOAD_NEXT_TO_LAST (LOAD_LAST-1)

//
// Private function prototypes.
//
BOOLEAN
CmpAddDriverToList(
    IN PHHIVE Hive,
    IN HCELL_INDEX DriverCell,
    IN HCELL_INDEX GroupOrderCell,
    IN PUNICODE_STRING RegistryPath,
    IN PLIST_ENTRY BootDriverListHead
    );

BOOLEAN
CmpDoSort(
    IN PLIST_ENTRY DriverListHead,
    IN PUNICODE_STRING OrderList
    );

ULONG
CmpFindTagIndex(
    IN PHHIVE Hive,
    IN HCELL_INDEX TagCell,
    IN HCELL_INDEX GroupOrderCell,
    IN PUNICODE_STRING GroupName
    );

BOOLEAN
CmpIsLoadType(
    IN PHHIVE Hive,
    IN HCELL_INDEX Cell,
    IN SERVICE_LOAD_TYPE LoadType
    );

BOOLEAN
CmpOrderGroup(
    IN PBOOT_DRIVER_NODE GroupStart,
    IN PBOOT_DRIVER_NODE GroupEnd
    );

VOID
BlPrint(
    PCHAR cp,
    ...
    );

#ifdef ALLOC_PRAGMA
#pragma alloc_text(INIT,CmpFindNLSData)
#pragma alloc_text(INIT,CmpFindDrivers)
#pragma alloc_text(INIT,CmpIsLoadType)
#pragma alloc_text(INIT,CmpAddDriverToList)
#pragma alloc_text(INIT,CmpSortDriverList)
#pragma alloc_text(INIT,CmpDoSort)
#pragma alloc_text(INIT,CmpResolveDriverDependencies)
#pragma alloc_text(INIT,CmpSetCurrentProfile)
#pragma alloc_text(INIT,CmpOrderGroup)
#pragma alloc_text(PAGE,CmpFindControlSet)
#pragma alloc_text(INIT,CmpFindTagIndex)
#pragma alloc_text(INIT,CmpFindProfileOption)
#pragma alloc_text(INIT,CmpValidateSelect)
#ifdef _WANT_MACHINE_IDENTIFICATION
#pragma alloc_text(INIT,CmpGetBiosDateFromRegistry)
#endif
#endif


BOOLEAN
CmpFindNLSData(
    IN PHHIVE Hive,
    IN HCELL_INDEX ControlSet,
    OUT PUNICODE_STRING AnsiFilename,
    OUT PUNICODE_STRING OemFilename,
    OUT PUNICODE_STRING CaseTableFilename,
    OUT PUNICODE_STRING OemHalFont
    )

/*++

Routine Description:

    Traverses a particular control set and determines the filenames for
    the NLS data files that need to be loaded.

Arguments:

    Hive - Supplies the hive control structure for the SYSTEM hive.

    ControlSet - Supplies the HCELL_INDEX of the root of the control set.

    AnsiFileName - Returns the name of the Ansi codepage file (c_1252.nls)

    OemFileName -  Returns the name of the OEM codepage file  (c_437.nls)

    CaseTableFileName - Returns the name of the Unicode upper/lowercase
            table for the language (l_intl.nls)

    OemHalfont - Returns the name of the font file to be used by the HAL.

Return Value:

    TRUE - filenames successfully determined

    FALSE - hive is corrupt

--*/

{
    UNICODE_STRING Name;
    HCELL_INDEX Control;
    HCELL_INDEX Nls;
    HCELL_INDEX CodePage;
    HCELL_INDEX Language;
    HCELL_INDEX ValueCell;
    PHCELL_INDEX Index;
    PCM_KEY_VALUE Value;
    NTSTATUS Status;
    ULONG realsize;
    PCM_KEY_NODE Node;

    //
    // no mapped hives at this point. don't bother releasing cells
    //
    ASSERT( Hive->ReleaseCellRoutine == NULL );
    //
    // Find CONTROL node
    //
    Node = (PCM_KEY_NODE)HvGetCell(Hive,ControlSet);
    if( Node == NULL ) {
        //
        // we couldn't map a view for the bin containing this cell
        //

        return FALSE;
    }
    RtlInitUnicodeString(&Name, L"Control");
    Control = CmpFindSubKeyByName(Hive,
                                 Node,
                                 &Name);
    if (Control == HCELL_NIL) {
        return(FALSE);
    }

    //
    // Find NLS node
    //
    Node = (PCM_KEY_NODE)HvGetCell(Hive,Control);
    if( Node == NULL ) {
        //
        // we couldn't map a view for the bin containing this cell
        //

        return FALSE;
    }
    RtlInitUnicodeString(&Name, L"NLS");
    Nls = CmpFindSubKeyByName(Hive,
                             Node,
                             &Name);
    if (Nls == HCELL_NIL) {
        return(FALSE);
    }

    //
    // Find CodePage node
    //
    Node = (PCM_KEY_NODE)HvGetCell(Hive,Nls);
    if( Node == NULL ) {
        //
        // we couldn't map a view for the bin containing this cell
        //

        return FALSE;
    }
    RtlInitUnicodeString(&Name, L"CodePage");
    CodePage = CmpFindSubKeyByName(Hive,
                                  Node,
                                  &Name);
    if (CodePage == HCELL_NIL) {
        return(FALSE);
    }

    //
    // Find ACP value
    //
    Node = (PCM_KEY_NODE)HvGetCell(Hive,CodePage);
    if( Node == NULL ) {
        //
        // we couldn't map a view for the bin containing this cell
        //

        return FALSE;
    }
    RtlInitUnicodeString(&Name, L"ACP");
    ValueCell = CmpFindValueByName(Hive,
                                   Node,
                                   &Name);
    if (ValueCell == HCELL_NIL) {
        return(FALSE);
    }

    Value = (PCM_KEY_VALUE)HvGetCell(Hive, ValueCell);
    if( Value == NULL ) {
        //
        // we couldn't map a view for the bin containing this cell
        //

        return FALSE;
    }
    Name.Buffer = (PWSTR)CmpValueToData(Hive,Value,&realsize);
    if( Name.Buffer == NULL ) {
        //
        // HvGetCell inside CmpValueToData failed; bail out safely
        //
        return FALSE;
    }
    Name.MaximumLength=(USHORT)realsize;
    Name.Length = 0;
    while ((Name.Length<Name.MaximumLength) &&
           (Name.Buffer[Name.Length/sizeof(WCHAR)] != UNICODE_NULL)) {
        Name.Length += sizeof(WCHAR);
    }

    //
    // Find ACP filename
    //
    Node = (PCM_KEY_NODE)HvGetCell(Hive,CodePage);
    if( Node == NULL ) {
        //
        // we couldn't map a view for the bin containing this cell
        //

        return FALSE;
    }
    ValueCell = CmpFindValueByName(Hive,
                                   Node,
                                   &Name);
    if (ValueCell == HCELL_NIL) {
        return(FALSE);
    }

    Value = (PCM_KEY_VALUE)HvGetCell(Hive, ValueCell);
    if( Value == NULL ) {
        //
        // we couldn't map a view for the bin containing this cell
        //

        return FALSE;
    }
    AnsiFilename->Buffer = (PWSTR)CmpValueToData(Hive,Value,&realsize);
    if( AnsiFilename->Buffer == NULL ) {
        //
        // HvGetCell inside CmpValueToData failed; bail out safely
        //
        return FALSE;
    }
    AnsiFilename->Length = AnsiFilename->MaximumLength = (USHORT)realsize;

    //
    // Find OEMCP node
    //
    Node = (PCM_KEY_NODE)HvGetCell(Hive,CodePage);
    if( Node == NULL ) {
        //
        // we couldn't map a view for the bin containing this cell
        //

        return FALSE;
    }
    RtlInitUnicodeString(&Name, L"OEMCP");
    ValueCell = CmpFindValueByName(Hive,
                                   Node,
                                   &Name);
    if (ValueCell == HCELL_NIL) {
        return(FALSE);
    }

    Value = (PCM_KEY_VALUE)HvGetCell(Hive, ValueCell);
    if( Value == NULL ) {
        //
        // we couldn't map a view for the bin containing this cell
        //

        return FALSE;
    }
    Name.Buffer = (PWSTR)CmpValueToData(Hive,Value,&realsize);
    if( Name.Buffer == NULL ) {
        //
        // HvGetCell inside CmpValueToData failed; bail out safely
        //
        return FALSE;
    }
    Name.MaximumLength = (USHORT)realsize;
    Name.Length = 0;
    while ((Name.Length<Name.MaximumLength) &&
           (Name.Buffer[Name.Length/sizeof(WCHAR)] != UNICODE_NULL)) {
        Name.Length += sizeof(WCHAR);
    }

    //
    // Find OEMCP filename
    //
    Node = (PCM_KEY_NODE)HvGetCell(Hive,CodePage);
    if( Node == NULL ) {
        //
        // we couldn't map a view for the bin containing this cell
        //

        return FALSE;
    }
    ValueCell = CmpFindValueByName(Hive,
                                   Node,
                                   &Name);
    if (ValueCell == HCELL_NIL) {
        return(FALSE);
    }

    Value = (PCM_KEY_VALUE)HvGetCell(Hive, ValueCell);
    if( Value == NULL ) {
        //
        // we couldn't map a view for the bin containing this cell
        //

        return FALSE;
    }
    OemFilename->Buffer = (PWSTR)CmpValueToData(Hive, Value,&realsize);
    if( OemFilename->Buffer == NULL ) {
        //
        // HvGetCell inside CmpValueToData failed; bail out safely
        //
        return FALSE;
    }
    OemFilename->Length = OemFilename->MaximumLength = (USHORT)realsize;

    //
    // Find Language node
    //
    Node = (PCM_KEY_NODE)HvGetCell(Hive,Nls);
    if( Node == NULL ) {
        //
        // we couldn't map a view for the bin containing this cell
        //

        return FALSE;
    }
    RtlInitUnicodeString(&Name, L"Language");
    Language = CmpFindSubKeyByName(Hive,
                                   Node,
                                   &Name);
    if (Language == HCELL_NIL) {
        return(FALSE);
    }

    //
    // Find Default value
    //
    Node = (PCM_KEY_NODE)HvGetCell(Hive,Language);
    if( Node == NULL ) {
        //
        // we couldn't map a view for the bin containing this cell
        //

        return FALSE;
    }
    RtlInitUnicodeString(&Name, L"Default");
    ValueCell = CmpFindValueByName(Hive,
                                   Node,
                                   &Name);
    if (ValueCell == HCELL_NIL) {
            return(FALSE);
    }

    Value = (PCM_KEY_VALUE)HvGetCell(Hive, ValueCell);
    if( Value == NULL ) {
        //
        // we couldn't map a view for the bin containing this cell
        //

        return FALSE;
    }
    Name.Buffer = (PWSTR)CmpValueToData(Hive, Value,&realsize);
    if( Name.Buffer == NULL ) {
        //
        // HvGetCell inside CmpValueToData failed; bail out safely
        //
        return FALSE;
    }
    Name.MaximumLength = (USHORT)realsize;
    Name.Length = 0;

    while ((Name.Length<Name.MaximumLength) &&
           (Name.Buffer[Name.Length/sizeof(WCHAR)] != UNICODE_NULL)) {
        Name.Length+=sizeof(WCHAR);
    }

    //
    // Find default filename
    //
    Node = (PCM_KEY_NODE)HvGetCell(Hive,Language);
    if( Node == NULL ) {
        //
        // we couldn't map a view for the bin containing this cell
        //

        return FALSE;
    }
    ValueCell = CmpFindValueByName(Hive,
                                   Node,
                                   &Name);
    if (ValueCell == HCELL_NIL) {
        return(FALSE);
    }

    Value = (PCM_KEY_VALUE)HvGetCell(Hive, ValueCell);
    if( Value == NULL ) {
        //
        // we couldn't map a view for the bin containing this cell
        //

        return FALSE;
    }
    CaseTableFilename->Buffer = (PWSTR)CmpValueToData(Hive, Value,&realsize);
    if( CaseTableFilename->Buffer == NULL ) {
        //
        // HvGetCell inside CmpValueToData failed; bail out safely
        //
        return FALSE;
    }
    CaseTableFilename->Length = CaseTableFilename->MaximumLength = (USHORT)realsize;

    //
    // Find OEMHAL filename
    //
    Node = (PCM_KEY_NODE)HvGetCell(Hive,CodePage);
    if( Node == NULL ) {
        //
        // we couldn't map a view for the bin containing this cell
        //

        return FALSE;
    }
    RtlInitUnicodeString(&Name, L"OEMHAL");
    ValueCell = CmpFindValueByName(Hive,
                                   Node,
                                   &Name);
    if (ValueCell == HCELL_NIL) {
#ifdef i386
        OemHalFont->Buffer = NULL;
        OemHalFont->Length = 0;
        OemHalFont->MaximumLength = 0;
        return TRUE;
#endif
        return(FALSE);
    }

    Value = (PCM_KEY_VALUE)HvGetCell(Hive, ValueCell);
    if( Value == NULL ) {
        //
        // we couldn't map a view for the bin containing this cell
        //

        return FALSE;
    }
    OemHalFont->Buffer = (PWSTR)CmpValueToData(Hive,Value,&realsize);
    if( OemHalFont->Buffer == NULL ) {
        //
        // HvGetCell inside CmpValueToData failed; bail out safely
        //
        return FALSE;
    }
    OemHalFont->Length = (USHORT)realsize;
    OemHalFont->MaximumLength = (USHORT)realsize;

    return(TRUE);
}


BOOLEAN
CmpFindDrivers(
    IN PHHIVE Hive,
    IN HCELL_INDEX ControlSet,
    IN SERVICE_LOAD_TYPE LoadType,
    IN PWSTR BootFileSystem OPTIONAL,
    IN PLIST_ENTRY DriverListHead
    )

/*++

Routine Description:

    Traverses a particular control set and creates a list of boot drivers
    to be loaded.  This list is unordered, but complete.

Arguments:

    Hive - Supplies the hive control structure for the SYSTEM hive.

    ControlSet - Supplies the HCELL_INDEX of the root of the control set.

    LoadType - Supplies the type of drivers to be loaded (BootLoad,
            SystemLoad, AutoLoad, etc)

    BootFileSystem - If present, supplies the base name of the boot
        filesystem, which is explicitly added to the driver list.

    DriverListHead - Supplies a pointer to the head of the (empty) list
            of boot drivers to load.

Return Value:

    TRUE - List successfully created.

    FALSE - Hive is corrupt.

--*/

{
    HCELL_INDEX Services;
    HCELL_INDEX Control;
    HCELL_INDEX GroupOrder;
    HCELL_INDEX DriverCell;
    UNICODE_STRING Name;
    PHCELL_INDEX Index;
    int i;
    UNICODE_STRING UnicodeString;
    UNICODE_STRING BasePath;
    WCHAR BaseBuffer[128];
    PBOOT_DRIVER_NODE BootFileSystemNode;
    PCM_KEY_NODE ControlNode;
    PCM_KEY_NODE ServicesNode;
    PCM_KEY_NODE Node;

    //
    // no mapped hives at this point. don't bother releasing cells
    //
    ASSERT( Hive->ReleaseCellRoutine == NULL );
    //
    // Find SERVICES node.
    //
    ControlNode = (PCM_KEY_NODE)HvGetCell(Hive,ControlSet);
    if( ControlNode == NULL ) {
        //
        // we couldn't map a view for the bin containing this cell
        //

        return FALSE;
    }
    RtlInitUnicodeString(&Name, L"Services");
    Services = CmpFindSubKeyByName(Hive,
                                   ControlNode,
                                   &Name);
    if (Services == HCELL_NIL) {
        return(FALSE);
    }
    ServicesNode = (PCM_KEY_NODE)HvGetCell(Hive,Services);
    if( ServicesNode == NULL ) {
        //
        // we couldn't map a view for the bin containing this cell
        //

        return FALSE;
    }

    //
    // Find CONTROL node.
    //
    RtlInitUnicodeString(&Name, L"Control");
    Control = CmpFindSubKeyByName(Hive,
                                  ControlNode,
                                  &Name);
    if (Control == HCELL_NIL) {
        return(FALSE);
    }

    //
    // Find GroupOrderList node.
    //
    RtlInitUnicodeString(&Name, L"GroupOrderList");
    Node = (PCM_KEY_NODE)HvGetCell(Hive,Control);
    if( Node == NULL ) {
        //
        // we couldn't map a view for the bin containing this cell
        //

        return FALSE;
    }
    GroupOrder = CmpFindSubKeyByName(Hive,
                                     Node,
                                     &Name);
    if (GroupOrder == HCELL_NIL) {
        return(FALSE);
    }

    BasePath.Length = 0;
    BasePath.MaximumLength = sizeof(BaseBuffer);
    BasePath.Buffer = BaseBuffer;
    RtlAppendUnicodeToString(&BasePath, L"\\Registry\\Machine\\System\\");
    RtlAppendUnicodeToString(&BasePath, L"CurrentControlSet\\Services\\");

    i=0;
    do {
        DriverCell = CmpFindSubKeyByNumber(Hive,ServicesNode,i++);
        if (DriverCell != HCELL_NIL) {
            if (CmpIsLoadType(Hive, DriverCell, LoadType)) {
                CmpAddDriverToList(Hive,
                                   DriverCell,
                                   GroupOrder,
                                   &BasePath,
                                   DriverListHead);

            }
        }
    } while ( DriverCell != HCELL_NIL );

    if (ARGUMENT_PRESENT(BootFileSystem)) {
        //
        // Add boot filesystem to boot driver list
        //

        RtlInitUnicodeString(&UnicodeString, BootFileSystem);
        DriverCell = CmpFindSubKeyByName(Hive,
                                         ServicesNode,
                                         &UnicodeString);
        if (DriverCell != HCELL_NIL) {
            CmpAddDriverToList(Hive,
                               DriverCell,
                               GroupOrder,
                               &BasePath,
                               DriverListHead);

            //
            // mark the Boot Filesystem critical
            //
            BootFileSystemNode = CONTAINING_RECORD(DriverListHead->Flink,
                                                   BOOT_DRIVER_NODE,
                                                   ListEntry.Link);
            BootFileSystemNode->ErrorControl = SERVICE_ERROR_CRITICAL;
        }
    }
    return(TRUE);

}


BOOLEAN
CmpIsLoadType(
    IN PHHIVE Hive,
    IN HCELL_INDEX Cell,
    IN SERVICE_LOAD_TYPE LoadType
    )

/*++

Routine Description:

    Determines if the driver is of a specified LoadType, based on its
    node values.

Arguments:

    Hive - Supplies a pointer to the hive control structure for the system
           hive.

    Cell - Supplies the cell index of the driver's node in the system hive.

    LoadType - Supplies the type of drivers to be loaded (BootLoad,
            SystemLoad, AutoLoad, etc)

Return Value:

    TRUE - Driver is the correct type and should be loaded.

    FALSE - Driver is not the correct type and should not be loaded.

--*/

{
    HCELL_INDEX ValueCell;
    PLONG Data;
    PHCELL_INDEX Index;
    UNICODE_STRING Name;
    PCM_KEY_VALUE Value;
    NTSTATUS Status;
    ULONG realsize;
    PCM_KEY_NODE Node;

    //
    // no mapped hives at this point. don't bother releasing cells
    //
    ASSERT( Hive->ReleaseCellRoutine == NULL );
    //
    // Must have a Start=BootLoad value in order to be a boot driver, so
    // look for that first.
    //
    Node = (PCM_KEY_NODE)HvGetCell(Hive,Cell);
    if( Node == NULL ) {
        //
        // we couldn't map a view for the bin containing this cell
        //

        return FALSE;
    }
    RtlInitUnicodeString(&Name, L"Start");
    ValueCell = CmpFindValueByName(Hive,
                                   Node,
                                   &Name);
    if (ValueCell == HCELL_NIL) {
        return(FALSE);
    }

    Value = (PCM_KEY_VALUE)HvGetCell(Hive, ValueCell);
    if( Value == NULL ) {
        //
        // we couldn't map a view for the bin containing this cell
        //

        return FALSE;
    }

    Data = (PLONG)CmpValueToData(Hive,Value,&realsize);
    if( Data == NULL ) {
        //
        // HvGetCell inside CmpValueToData failed; bail out safely
        //
        return FALSE;
    }

    if (*Data != LoadType) {
        return(FALSE);
    }

    return(TRUE);
}


BOOLEAN
CmpAddDriverToList(
    IN PHHIVE Hive,
    IN HCELL_INDEX DriverCell,
    IN HCELL_INDEX GroupOrderCell,
    IN PUNICODE_STRING RegistryPath,
    IN PLIST_ENTRY BootDriverListHead
    )

/*++

Routine Description:

    This routine allocates a list entry node for a particular driver.
    It initializes it with the registry path, filename, group name, and
    dependency list.  Finally, it inserts the new node into the boot
    driver list.

    Note that this routine allocates memory by calling the Hive's
    memory allocation procedure.

Arguments:

    Hive - Supplies a pointer to the hive control structure

    DriverCell - Supplies the HCELL_INDEX of the driver's node in the hive.

    GroupOrderCell - Supplies the HCELL_INDEX of the GroupOrderList key.
        ( \Registry\Machine\System\CurrentControlSet\Control\GroupOrderList )

    RegistryPath - Supplies the full registry path to the SERVICES node
            of the current control set.

    BootDriverListHead - Supplies the head of the boot driver list

Return Value:

    TRUE - Driver successfully added to boot driver list.

    FALSE - Could not add driver to boot driver list.

--*/

{
    PCM_KEY_NODE            Driver;
    USHORT                  DriverNameLength;
    PCM_KEY_VALUE           Value;
    PBOOT_DRIVER_NODE       DriverNode;
    PBOOT_DRIVER_LIST_ENTRY DriverEntry;
    HCELL_INDEX             ValueCell;
    HCELL_INDEX             Tag;
    UNICODE_STRING          UnicodeString;
    PUNICODE_STRING         FileName;
    NTSTATUS                Status;
    ULONG                   Length;
    PHCELL_INDEX            Index;
    ULONG                   realsize;
    PULONG                  TempULong;
    PWSTR                   TempBuffer;

    //
    // no mapped hives at this point. don't bother releasing cells
    //
    ASSERT( Hive->ReleaseCellRoutine == NULL );

    Driver = (PCM_KEY_NODE)HvGetCell(Hive, DriverCell);
    if( Driver == NULL ) {
        //
        // we couldn't map a view for the bin containing this cell
        //

        return FALSE;
    }
    DriverNode = (Hive->Allocate)(sizeof(BOOT_DRIVER_NODE),FALSE,CM_FIND_LEAK_TAG1);
    if (DriverNode == NULL) {
        return(FALSE);
    }
    DriverEntry = &DriverNode->ListEntry;

    DriverEntry->RegistryPath.Buffer = NULL;
    DriverEntry->FilePath.Buffer = NULL;

    if (Driver->Flags & KEY_COMP_NAME) {
        DriverNode->Name.Length = CmpCompressedNameSize(Driver->Name,Driver->NameLength);
        DriverNode->Name.Buffer = (Hive->Allocate)(DriverNode->Name.Length, FALSE,CM_FIND_LEAK_TAG2);
        if (DriverNode->Name.Buffer == NULL) {
            return(FALSE);
        }
        CmpCopyCompressedName(DriverNode->Name.Buffer,
                              DriverNode->Name.Length,
                              Driver->Name,
                              Driver->NameLength);

    } else {
        DriverNode->Name.Length = Driver->NameLength;
        DriverNode->Name.Buffer = (Hive->Allocate)(DriverNode->Name.Length, FALSE,CM_FIND_LEAK_TAG2);
        if (DriverNode->Name.Buffer == NULL) {
            return(FALSE);
        }
        RtlCopyMemory((PVOID)(DriverNode->Name.Buffer), (PVOID)(Driver->Name), Driver->NameLength);
    }
    DriverNode->Name.MaximumLength = DriverNode->Name.Length;
    DriverNameLength = DriverNode->Name.Length;

    //
    // Check for ImagePath value, which will override the default name
    // if it is present.
    //
    RtlInitUnicodeString(&UnicodeString, L"ImagePath");
    ValueCell = CmpFindValueByName(Hive,
                                   Driver,
                                   &UnicodeString);
    if (ValueCell == HCELL_NIL) {

        //
        // No ImagePath, so generate default filename.
        // Build up Unicode filename  ("system32\drivers\<nodename>.sys");
        //

        Length = sizeof(L"System32\\Drivers\\") +
                 DriverNameLength  +
                 sizeof(L".sys");

        FileName = &DriverEntry->FilePath;
        FileName->Length = 0;
        FileName->MaximumLength = (USHORT)Length;
        FileName->Buffer = (PWSTR)(Hive->Allocate)(Length, FALSE,CM_FIND_LEAK_TAG3);
        if (FileName->Buffer == NULL) {
            return(FALSE);
        }
        if (!NT_SUCCESS(RtlAppendUnicodeToString(FileName, L"System32\\"))) {
            return(FALSE);
        }
        if (!NT_SUCCESS(RtlAppendUnicodeToString(FileName, L"Drivers\\"))) {
            return(FALSE);
        }
        if (!NT_SUCCESS(
                RtlAppendUnicodeStringToString(FileName,
                                               &DriverNode->Name))) {
            return(FALSE);
        }
        if (!NT_SUCCESS(RtlAppendUnicodeToString(FileName, L".sys"))) {
            return(FALSE);
        }

    } else {
        Value = (PCM_KEY_VALUE)HvGetCell(Hive,ValueCell);
        if( Value == NULL ) {
            //
            // we couldn't map a view for the bin containing this cell
            //

            return FALSE;
        }
        FileName = &DriverEntry->FilePath;
        TempBuffer = (PWSTR)CmpValueToData(Hive,Value,&realsize);
        FileName->Buffer = (PWSTR)(Hive->Allocate)(realsize, FALSE,CM_FIND_LEAK_TAG3);
        if( (FileName->Buffer == NULL) || (TempBuffer == NULL) ) {
            //
            // HvGetCell inside CmpValueToData failed; bail out safely
            //
            return FALSE;
        }
        RtlCopyMemory((PVOID)(FileName->Buffer), (PVOID)(TempBuffer), realsize);
        FileName->MaximumLength = FileName->Length = (USHORT)realsize;
    }

    FileName = &DriverEntry->RegistryPath;
    FileName->Length = 0;
    FileName->MaximumLength = RegistryPath->Length + DriverNameLength;
    FileName->Buffer = (Hive->Allocate)(FileName->MaximumLength,FALSE,CM_FIND_LEAK_TAG4);
    if (FileName->Buffer == NULL) {
        return(FALSE);
    }
    RtlAppendUnicodeStringToString(FileName, RegistryPath);
    RtlAppendUnicodeStringToString(FileName, &DriverNode->Name);

    InsertHeadList(BootDriverListHead, &DriverEntry->Link);

    //
    // Find "ErrorControl" value
    //

    RtlInitUnicodeString(&UnicodeString, L"ErrorControl");
    ValueCell = CmpFindValueByName(Hive,
                                   Driver,
                                   &UnicodeString);
    if (ValueCell == HCELL_NIL) {
        DriverNode->ErrorControl = NormalError;
    } else {
        Value = (PCM_KEY_VALUE)HvGetCell(Hive, ValueCell);
        if( Value == NULL ) {
            //
            // we couldn't map a view for the bin containing this cell
            //

            return FALSE;
        }

        TempULong = (PULONG)CmpValueToData(Hive,Value,&realsize);
        if( TempULong == NULL ) {
            //
            // HvGetCell inside CmpValueToData failed; bail out safely
            //
            return FALSE;
        }
        DriverNode->ErrorControl = *TempULong;
    }

    //
    // Find "Group" value
    //
    RtlInitUnicodeString(&UnicodeString, L"group");
    ValueCell = CmpFindValueByName(Hive,
                                   Driver,
                                   &UnicodeString);
    if (ValueCell == HCELL_NIL) {
        DriverNode->Group.Length = 0;
        DriverNode->Group.MaximumLength = 0;
        DriverNode->Group.Buffer = NULL;
    } else {
        Value = (PCM_KEY_VALUE)HvGetCell(Hive, ValueCell);
        if( Value == NULL ) {
            //
            // we couldn't map a view for the bin containing this cell
            //

            return FALSE;
        }

        DriverNode->Group.Buffer = (PWSTR)CmpValueToData(Hive,Value,&realsize);
        if( DriverNode->Group.Buffer == NULL ) {
            //
            // HvGetCell inside CmpValueToData failed; bail out safely
            //
            return FALSE;
        }
        DriverNode->Group.Length = (USHORT)realsize - sizeof(WCHAR);
        DriverNode->Group.MaximumLength = (USHORT)DriverNode->Group.Length;
    }

    //
    // Calculate the tag value for the driver.  If the driver has no tag,
    // this defaults to 0xffffffff, so the driver is loaded last in the
    // group.
    //
    RtlInitUnicodeString(&UnicodeString, L"Tag");
    Tag = CmpFindValueByName(Hive,
                             Driver,
                             &UnicodeString);
    if (Tag == HCELL_NIL) {
        DriverNode->Tag = LOAD_LAST;
    } else {
        //
        // Now we have to find this tag in the tag list for the group.
        // If the tag is not in the tag list, then it defaults to 0xfffffffe,
        // so it is loaded after all the drivers in the tag list, but before
        // all the drivers without tags at all.
        //

        DriverNode->Tag = CmpFindTagIndex(Hive,
                                          Tag,
                                          GroupOrderCell,
                                          &DriverNode->Group);
    }

    return(TRUE);

}


BOOLEAN
CmpSortDriverList(
    IN PHHIVE Hive,
    IN HCELL_INDEX ControlSet,
    IN PLIST_ENTRY DriverListHead
    )

/*++

Routine Description:

    Sorts the list of boot drivers by their groups based on the group
    ordering in <control_set>\CONTROL\SERVICE_GROUP_ORDER:list

    Does NOT do dependency ordering.

Arguments:

    Hive - Supplies the hive control structure for the SYSTEM hive.

    ControlSet - Supplies the HCELL_INDEX of the root of the control set.

    DriverListHead - Supplies a pointer to the head of the list of
            boot drivers to be sorted.

Return Value:

    TRUE - List successfully sorted

    FALSE - List is inconsistent and could not be sorted.

--*/

{
    HCELL_INDEX Controls;
    HCELL_INDEX GroupOrder;
    HCELL_INDEX ListCell;
    UNICODE_STRING Name;
    UNICODE_STRING DependList;
    PHCELL_INDEX Index;
    NTSTATUS Status;
    PCM_KEY_VALUE ListNode;
    ULONG realsize;
    PCM_KEY_NODE Node;

    //
    // no mapped hives at this point. don't bother releasing cells
    //
    ASSERT( Hive->ReleaseCellRoutine == NULL );
    //
    // Find "CONTROL" node.
    //
    Node = (PCM_KEY_NODE)HvGetCell(Hive,ControlSet);
    if( Node == NULL ) {
        //
        // we couldn't map a view for the bin containing this cell
        //

        return FALSE;
    }
    RtlInitUnicodeString(&Name, L"Control");
    Controls = CmpFindSubKeyByName(Hive,
                                   Node,
                                   &Name);
    if (Controls == HCELL_NIL) {
        return(FALSE);
    }

    //
    // Find "SERVICE_GROUP_ORDER" subkey
    //
    Node = (PCM_KEY_NODE)HvGetCell(Hive,Controls);
    if( Node == NULL ) {
        //
        // we couldn't map a view for the bin containing this cell
        //

        return FALSE;
    }
    RtlInitUnicodeString(&Name, L"ServiceGroupOrder");
    GroupOrder = CmpFindSubKeyByName(Hive,
                                     Node,
                                     &Name);
    if (GroupOrder == HCELL_NIL) {
        return(FALSE);
    }

    //
    // Find "list" value
    //
    Node = (PCM_KEY_NODE)HvGetCell(Hive,GroupOrder);
    if( Node == NULL ) {
        //
        // we couldn't map a view for the bin containing this cell
        //

        return FALSE;
    }
    RtlInitUnicodeString(&Name, L"list");
    ListCell = CmpFindValueByName(Hive,
                                  Node,
                                  &Name);
    if (ListCell == HCELL_NIL) {
        return(FALSE);
    }
    ListNode = (PCM_KEY_VALUE)HvGetCell(Hive, ListCell);
    if( ListNode == NULL ) {
        //
        // we couldn't map a view for the bin containing this cell
        //

        return FALSE;
    }
    if (ListNode->Type != REG_MULTI_SZ) {
        return(FALSE);
    }

    DependList.Buffer = (PWSTR)CmpValueToData(Hive,ListNode,&realsize);
    if( DependList.Buffer == NULL ) {
        //
        // HvGetCell inside CmpValueToData failed; bail out safely
        //
        return FALSE;
    }
    DependList.Length = DependList.MaximumLength = (USHORT)realsize - sizeof(WCHAR);

    //
    // Dependency list is now pointed to by DependList->Buffer.  We need
    // to sort the driver entry list.
    //

    return (CmpDoSort(DriverListHead, &DependList));

}

BOOLEAN
CmpDoSort(
    IN PLIST_ENTRY DriverListHead,
    IN PUNICODE_STRING OrderList
    )

/*++

Routine Description:

    Sorts the boot driver list based on the order list

    Start with the last entry in the group order list and work towards
    the beginning.  For each group entry, move all driver entries that
    are members of the group to the front of the list.  Driver entries
    with no groups, or with a group that does not match any in the
    group list will be shoved to the end of the list.

Arguments:

    DriverListHead - Supplies a pointer to the head of the list of
            boot drivers to be sorted.

    OrderList - Supplies pointer to the order list

Return Value:

    TRUE - List successfully ordered

    FALSE - List is inconsistent and could not be ordered.

--*/

{
    PWSTR Current;
    PWSTR End;
    PLIST_ENTRY Next;
    PBOOT_DRIVER_NODE CurrentNode;
    UNICODE_STRING CurrentGroup;


    Current = (PWSTR) ((PUCHAR)(OrderList->Buffer)+OrderList->Length);

    while (Current > OrderList->Buffer) {
        do {
            if (*(Current) == UNICODE_NULL) {
                End = Current;
            }
            --Current;
        } while ((*(Current-1) != UNICODE_NULL) &&
                 ( Current != OrderList->Buffer));

        //
        // Current now points to the beginning of the NULL-terminated
        // Unicode string.
        // End now points to the end of the string
        //
        CurrentGroup.Length = (USHORT) ((PCHAR)End - (PCHAR)Current);
        CurrentGroup.MaximumLength = CurrentGroup.Length;
        CurrentGroup.Buffer = Current;
        Next = DriverListHead->Flink;
        while (Next != DriverListHead) {
            CurrentNode = CONTAINING_RECORD(Next,
                                            BOOT_DRIVER_NODE,
                                            ListEntry.Link);
            Next = CurrentNode->ListEntry.Link.Flink;
            if (CurrentNode->Group.Buffer != NULL) {
                if (RtlEqualUnicodeString(&CurrentGroup, &CurrentNode->Group,TRUE)) {
                    RemoveEntryList(&CurrentNode->ListEntry.Link);
                    InsertHeadList(DriverListHead,
                                   &CurrentNode->ListEntry.Link);
                }
            }
        }
        --Current;

    }

    return(TRUE);

}


BOOLEAN
CmpResolveDriverDependencies(
    IN PLIST_ENTRY DriverListHead
    )

/*++

Routine Description:

    This routine orders driver nodes in a group based on their dependencies
    on one another.  It removes any drivers that have circular dependencies
    from the list.

Arguments:

    DriverListHead - Supplies a pointer to the head of the list of
            boot drivers to be sorted.

Return Value:

    TRUE - Dependencies successfully resolved

    FALSE - Corrupt hive.

--*/

{
    PLIST_ENTRY CurrentEntry;
    PBOOT_DRIVER_NODE GroupStart;
    PBOOT_DRIVER_NODE GroupEnd;
    PBOOT_DRIVER_NODE CurrentNode;

    CurrentEntry = DriverListHead->Flink;

    while (CurrentEntry != DriverListHead) {
        //
        // The list is already ordered by groups.  Find the first and
        // last entry in each group, and order each of these sub-lists
        // based on their dependencies.
        //

        GroupStart = CONTAINING_RECORD(CurrentEntry,
                                       BOOT_DRIVER_NODE,
                                       ListEntry.Link);
        do {
            GroupEnd = CONTAINING_RECORD(CurrentEntry,
                                         BOOT_DRIVER_NODE,
                                         ListEntry.Link);

            CurrentEntry = CurrentEntry->Flink;
            CurrentNode = CONTAINING_RECORD(CurrentEntry,
                                            BOOT_DRIVER_NODE,
                                            ListEntry.Link);

            if (CurrentEntry == DriverListHead) {
                break;
            }

            if (!RtlEqualUnicodeString(&GroupStart->Group,
                                       &CurrentNode->Group,
                                       TRUE)) {
                break;
            }

        } while ( CurrentEntry != DriverListHead );

        //
        // GroupStart now points to the first driver node in the group,
        // and GroupEnd points to the last driver node in the group.
        //
        CmpOrderGroup(GroupStart, GroupEnd);

    }
    return(TRUE);
}


BOOLEAN
CmpOrderGroup(
    IN PBOOT_DRIVER_NODE GroupStart,
    IN PBOOT_DRIVER_NODE GroupEnd
    )

/*++

Routine Description:

    Reorders the nodes in a driver group based on their tag values.

Arguments:

    GroupStart - Supplies the first node in the group.

    GroupEnd - Supplies the last node in the group.

Return Value:

    TRUE - Group successfully reordered

    FALSE - Circular dependencies detected.

--*/

{
    PBOOT_DRIVER_NODE Current;
    PBOOT_DRIVER_NODE Previous;
    PLIST_ENTRY ListEntry;
    BOOLEAN StartOver=FALSE;

    if (GroupStart == GroupEnd) {
        return(TRUE);
    }

    Current = GroupStart;

    do {
        //
        // If the driver before the current one has a lower tag, then
        // we do not need to move it.  If not, then remove the driver
        // from the list and scan backwards until we find a driver with
        // a tag that is <= the current tag, or we reach the beginning
        // of the list.
        //
        Previous = Current;
        ListEntry = Current->ListEntry.Link.Flink;
        Current = CONTAINING_RECORD(ListEntry,
                                    BOOT_DRIVER_NODE,
                                    ListEntry.Link);

        if (Previous->Tag > Current->Tag) {
            //
            // Remove the Current driver from the list, and search
            // backwards until we find a tag that is <= the current
            // driver's tag.  Reinsert the current driver there.
            //
            if (Current == GroupEnd) {
                ListEntry = Current->ListEntry.Link.Blink;
                GroupEnd = CONTAINING_RECORD(ListEntry,
                                             BOOT_DRIVER_NODE,
                                             ListEntry.Link);
            }
            RemoveEntryList(&Current->ListEntry.Link);
            while ( (Previous->Tag > Current->Tag) &&
                    (Previous != GroupStart) ) {
                ListEntry = Previous->ListEntry.Link.Blink;
                Previous = CONTAINING_RECORD(ListEntry,
                                             BOOT_DRIVER_NODE,
                                             ListEntry.Link);
            }
            InsertTailList(&Previous->ListEntry.Link,
                           &Current->ListEntry.Link);
            if (Previous == GroupStart) {
                GroupStart = Current;
            }
        }

    } while ( Current != GroupEnd );

    return(TRUE);
}

BOOLEAN
CmpValidateSelect(
     IN PHHIVE SystemHive,
     IN HCELL_INDEX RootCell
     )
/*++

Routine Description:

    This routines parses the SYSTEM hive and "Select" node
    and verifies the following values:

    Current
    Default
    Failed
    LastKnownGood


    If any of these is missing the the loader will put the corrupt
    system hive message

    This routine is to be called by the loader just after it loads the
    system hive. It's purpose is to ensure a uniform and consistent way
    to treat missing values in this area.

Arguments:

    SystemHive - Supplies the hive control structure for the SYSTEM hive.

    RootCell - Supplies the HCELL_INDEX of the root cell of the hive.


Return Value:

    TRUE - all the values are here
    FALSE - some of them are missing

--*/
{
    HCELL_INDEX     Select;
    PCM_KEY_NODE    Node;
    UNICODE_STRING  Name;

    //
    // no mapped hives at this point. don't bother releasing cells
    //
    ASSERT( SystemHive->ReleaseCellRoutine == NULL );

    //
    // Find \SYSTEM\SELECT node.
    //
    Node = (PCM_KEY_NODE)HvGetCell(SystemHive,RootCell);
    if( Node == NULL ) {
        //
        // we couldn't map a view for the bin containing this cell
        //

        return FALSE;
    }
    RtlInitUnicodeString(&Name, L"select");
    Select = CmpFindSubKeyByName(SystemHive,
                                Node,
                                &Name);
    if (Select == HCELL_NIL) {
        return FALSE;
    }

    //
    // Find AutoSelect value
    //
    Node = (PCM_KEY_NODE)HvGetCell(SystemHive,Select);
    if( Node == NULL ) {
        //
        // we couldn't map a view for the bin containing this cell
        //

        return FALSE;
    }

    // search for current
    RtlInitUnicodeString(&Name, L"current");
    Select = CmpFindValueByName(SystemHive,
                                Node,
                                &Name);
    if (Select == HCELL_NIL) {
        return FALSE;
    }

    // search for default
    RtlInitUnicodeString(&Name, L"default");
    Select = CmpFindValueByName(SystemHive,
                                Node,
                                &Name);
    if (Select == HCELL_NIL) {
        return FALSE;
    }

    // search for failed
    RtlInitUnicodeString(&Name, L"failed");
    Select = CmpFindValueByName(SystemHive,
                                Node,
                                &Name);
    if (Select == HCELL_NIL) {
        return FALSE;
    }

    // search for LKG
    RtlInitUnicodeString(&Name, L"LastKnownGood");
    Select = CmpFindValueByName(SystemHive,
                                Node,
                                &Name);
    if (Select == HCELL_NIL) {
        return FALSE;
    }

    return TRUE;
}

HCELL_INDEX
CmpFindControlSet(
     IN PHHIVE SystemHive,
     IN HCELL_INDEX RootCell,
     IN PUNICODE_STRING SelectName,
     OUT PBOOLEAN AutoSelect
     )

/*++

Routine Description:

    This routines parses the SYSTEM hive and "Select" node
    to locate the control set to be used for booting.

    Note that this routines also updates the value of Current to reflect
    the control set that was just found.  This is what we want to do
    when this is called during boot.  During I/O initialization, this
    is irrelevant, since we're just changing it to what it already is.

Arguments:

    SystemHive - Supplies the hive control structure for the SYSTEM hive.

    RootCell - Supplies the HCELL_INDEX of the root cell of the hive.

    SelectName - Supplies the name of the Select value to be used in
            determining the control set.  This should be one of "Current"
            "Default" or "LastKnownGood"

    AutoSelect - Returns the value of the AutoSelect value under
            the Select node.

Return Value:

    != HCELL_NIL - Cell Index of the control set to be used for booting.
    == HCELL_NIL - Indicates the hive is corrupt or inconsistent

--*/

{
    HCELL_INDEX     Select;
    HCELL_INDEX     ValueCell;
    HCELL_INDEX     ControlSet;
    HCELL_INDEX     AutoSelectCell;
    NTSTATUS        Status;
    UNICODE_STRING  Name;
    ANSI_STRING     AnsiString;
    PHCELL_INDEX    Index;
    PCM_KEY_VALUE   Value;
    PULONG          ControlSetIndex;
    PULONG          CurrentControl;
    CHAR            AsciiBuffer[128];
    WCHAR           UnicodeBuffer[128];
    ULONG           realsize;
    PCM_KEY_NODE    Node;
    PBOOLEAN        TempBoolean;

    //
    // no mapped hives at this point. don't bother releasing cells
    //
    ASSERT( SystemHive->ReleaseCellRoutine == NULL );
    //
    // Find \SYSTEM\SELECT node.
    //
    Node = (PCM_KEY_NODE)HvGetCell(SystemHive,RootCell);
    if( Node == NULL ) {
        //
        // we couldn't map a view for the bin containing this cell
        //

        return HCELL_NIL;
    }
    RtlInitUnicodeString(&Name, L"select");
    Select = CmpFindSubKeyByName(SystemHive,
                                Node,
                                &Name);
    if (Select == HCELL_NIL) {
        return(HCELL_NIL);
    }

    //
    // Find AutoSelect value
    //
    Node = (PCM_KEY_NODE)HvGetCell(SystemHive,Select);
    if( Node == NULL ) {
        //
        // we couldn't map a view for the bin containing this cell
        //

        return HCELL_NIL;
    }
    RtlInitUnicodeString(&Name, L"AutoSelect");
    AutoSelectCell = CmpFindValueByName(SystemHive,
                                        Node,
                                        &Name);
    if (AutoSelectCell == HCELL_NIL) {
        //
        // It's not there, we don't care.  Set autoselect to TRUE
        //
        *AutoSelect = TRUE;
    } else {
        Value = (PCM_KEY_VALUE)HvGetCell(SystemHive, AutoSelectCell);
        if( Value == NULL ) {
            //
            // we couldn't map a view for the bin containing this cell
            //

            return HCELL_NIL;
        }

        TempBoolean = (PBOOLEAN)(CmpValueToData(SystemHive,Value,&realsize));
        if( TempBoolean == NULL ) {
            //
            // HvGetCell inside CmpValueToData failed; bail out safely
            //
            return HCELL_NIL;
        }

        *AutoSelect = *TempBoolean;
    }

    Node = (PCM_KEY_NODE)HvGetCell(SystemHive,Select);
    if( Node == NULL ) {
        //
        // we couldn't map a view for the bin containing this cell
        //

        return HCELL_NIL;
    }
    ValueCell = CmpFindValueByName(SystemHive,
                                   Node,
                                   SelectName);
    if (ValueCell == HCELL_NIL) {
        return(HCELL_NIL);
    }
    Value = (PCM_KEY_VALUE)HvGetCell(SystemHive, ValueCell);
    if( Value == NULL ) {
        //
        // we couldn't map a view for the bin containing this cell
        //

        return HCELL_NIL;
    }
    if (Value->Type != REG_DWORD) {
        return(HCELL_NIL);
    }

    ControlSetIndex = (PULONG)CmpValueToData(SystemHive, Value,&realsize);
    if( ControlSetIndex == NULL ) {
        //
        // HvGetCell inside CmpValueToData failed; bail out safely
        //
        return HCELL_NIL;
    }

    //
    // Find appropriate control set
    //

    sprintf(AsciiBuffer, "ControlSet%03d", *ControlSetIndex);
    AnsiString.Length = AnsiString.MaximumLength = (USHORT) strlen(&(AsciiBuffer[0]));
    AnsiString.Buffer = AsciiBuffer;
    Name.MaximumLength = 128*sizeof(WCHAR);
    Name.Buffer = UnicodeBuffer;
    Status = RtlAnsiStringToUnicodeString(&Name,
                                          &AnsiString,
                                          FALSE);
    if (!NT_SUCCESS(Status)) {
        return(HCELL_NIL);
    }

    Node = (PCM_KEY_NODE)HvGetCell(SystemHive,RootCell);
    if( Node == NULL ) {
        //
        // we couldn't map a view for the bin containing this cell
        //

        return HCELL_NIL;
    }
    ControlSet = CmpFindSubKeyByName(SystemHive,
                                     Node,
                                     &Name);
    if (ControlSet == HCELL_NIL) {
        return(HCELL_NIL);
    }

    //
    // Control set was successfully found, so update the value in "Current"
    // to reflect the control set we are going to use.
    //
    Node = (PCM_KEY_NODE)HvGetCell(SystemHive,Select);
    if( Node == NULL ) {
        //
        // we couldn't map a view for the bin containing this cell
        //

        return HCELL_NIL;
    }
    RtlInitUnicodeString(&Name, L"Current");
    ValueCell = CmpFindValueByName(SystemHive,
                                   Node,
                                   &Name);
    if (ValueCell != HCELL_NIL) {
        Value = (PCM_KEY_VALUE)HvGetCell(SystemHive, ValueCell);
        if( Value == NULL ) {
            //
            // we couldn't map a view for the bin containing this cell
            //

            return HCELL_NIL;
        }
        if (Value->Type == REG_DWORD) {
            CurrentControl = (PULONG)CmpValueToData(SystemHive, Value,&realsize);
            if( CurrentControl == NULL ) {
                //
                // HvGetCell inside CmpValueToData failed; bail out safely
                //
                return HCELL_NIL;
            }
            *CurrentControl = *ControlSetIndex;
        }
    }
    return(ControlSet);

}


VOID
CmpSetCurrentProfile(
    IN PHHIVE Hive,
    IN HCELL_INDEX ControlSet,
    IN PCM_HARDWARE_PROFILE Profile
    )

/*++

Routine Description:

    Edits the in-memory copy of the registry to reflect the hardware
    profile that the system is booting from.

Arguments:

    Hive - Supplies a pointer to the hive control structure

    ControlSet - Supplies the HCELL_INDEX of the current control set.

    Profile - Supplies a pointer to the selected hardware profile

Return Value:

    None.

--*/

{
    HCELL_INDEX IDConfigDB;
    PCM_KEY_NODE IDConfigNode;
    HCELL_INDEX CurrentConfigCell;
    PCM_KEY_VALUE CurrentConfigValue;
    UNICODE_STRING Name;
    PULONG CurrentConfig;
    ULONG realsize;

    //
    // no mapped hives at this point. don't bother releasing cells
    //
    ASSERT( Hive->ReleaseCellRoutine == NULL );

    IDConfigDB = CmpFindProfileOption(Hive,
                                      ControlSet,
                                      NULL,
                                      NULL,
                                      NULL);
    if (IDConfigDB != HCELL_NIL) {
        IDConfigNode = (PCM_KEY_NODE)HvGetCell(Hive, IDConfigDB);
        if( IDConfigNode == NULL ) {
            //
            // we couldn't map a view for the bin containing this cell
            //
            return;
        }

        RtlInitUnicodeString(&Name, L"CurrentConfig");
        CurrentConfigCell = CmpFindValueByName(Hive,
                                               IDConfigNode,
                                               &Name);
        if (CurrentConfigCell != HCELL_NIL) {
            CurrentConfigValue = (PCM_KEY_VALUE)HvGetCell(Hive, CurrentConfigCell);
            if( CurrentConfigValue == NULL ) {
                //
                // we couldn't map a view for the bin containing this cell
                //
                return;
            }
            if (CurrentConfigValue->Type == REG_DWORD) {
                CurrentConfig = (PULONG)CmpValueToData(Hive,
                                                       CurrentConfigValue,
                                                       &realsize);
                if( CurrentConfig == NULL ) {
                    //
                    // HvGetCell inside CmpValueToData failed; bail out safely
                    //
                    return;
                }
                *CurrentConfig = Profile->Id;
            }
        }
    }


}


HCELL_INDEX
CmpFindProfileOption(
     IN PHHIVE SystemHive,
     IN HCELL_INDEX ControlSet,
     OUT OPTIONAL PCM_HARDWARE_PROFILE_LIST *ReturnedProfileList,
     OUT OPTIONAL PCM_HARDWARE_PROFILE_ALIAS_LIST *ReturnedAliasList,
     OUT OPTIONAL PULONG ProfileTimeout
     )

/*++

Routine Description:

    This routines parses the SYSTEM hive and locates the
    "CurrentControlSet\Control\IDConfigDB" node to determine the
    hardware profile configuration settings.

Arguments:

    SystemHive - Supplies the hive control structure for the SYSTEM hive.

    ControlSet - Supplies the HCELL_INDEX of the root cell of the hive.

    ProfileList - Returns the list of available hardware profiles sorted
                  by preference. Will be allocated by this routine if
                  NULL is passed in, or a pointer to a CM_HARDWARE_PROFILE_LIST
                  structure that is too small is passed in.

    ProfileTimeout - Returns the timeout value for the config menu.

Return Value:

    != HCELL_NIL - Cell Index of the IDConfigDB node.
    == HCELL_NIL - Indicates IDConfigDB does not exist

--*/
{
    HCELL_INDEX                     ControlCell;
    HCELL_INDEX                     IDConfigDB;
    HCELL_INDEX                     DefaultCell;
    HCELL_INDEX                     TimeoutCell;
    HCELL_INDEX                     ProfileCell;
    HCELL_INDEX                     AliasCell;
    HCELL_INDEX                     HWCell;
    PCM_KEY_NODE                    HWNode;
    PCM_KEY_NODE                    ProfileNode;
    PCM_KEY_NODE                    AliasNode;
    PCM_KEY_NODE                    ConfigDBNode;
    PCM_KEY_NODE                    Control;
    PCM_KEY_VALUE                   TimeoutValue;
    UNICODE_STRING                  Name;
    ULONG                           realsize;
    PCM_HARDWARE_PROFILE_LIST       ProfileList;
    PCM_HARDWARE_PROFILE_ALIAS_LIST AliasList;
    ULONG                           ProfileCount;
    ULONG                           AliasCount;
    ULONG                           i,j;
    WCHAR                           NameBuf[20];
    PCM_KEY_NODE                    Node;
    PULONG                          TempULong;

    //
    // no mapped hives at this point. don't bother releasing cells
    //
    ASSERT( SystemHive->ReleaseCellRoutine == NULL );
    //
    // Find Control node
    //
    Node = (PCM_KEY_NODE)HvGetCell(SystemHive,ControlSet);
    if( Node == NULL ) {
        //
        // we couldn't map a view for the bin containing this cell
        //

        return HCELL_NIL;
    }
    RtlInitUnicodeString(&Name, L"Control");
    ControlCell = CmpFindSubKeyByName(SystemHive,
                                      Node,
                                      &Name);
    if (ControlCell == HCELL_NIL) {
        return(HCELL_NIL);
    }
    Control = (PCM_KEY_NODE)HvGetCell(SystemHive, ControlCell);
    if( Control == NULL ) {
        //
        // we couldn't map a view for the bin containing this cell
        //

        return HCELL_NIL;
    }

    //
    // Find IDConfigDB node
    //
    RtlInitUnicodeString(&Name, L"IDConfigDB");
    IDConfigDB = CmpFindSubKeyByName(SystemHive,
                                     Control,
                                     &Name);
    if (IDConfigDB == HCELL_NIL) {
        return(HCELL_NIL);
    }
    ConfigDBNode = (PCM_KEY_NODE)HvGetCell(SystemHive, IDConfigDB);
    if( ConfigDBNode == NULL ) {
        //
        // we couldn't map a view for the bin containing this cell
        //

        return HCELL_NIL;
    }

    if (ARGUMENT_PRESENT(ProfileTimeout)) {
        //
        // Find UserWaitInterval value. This is the timeout
        //
        RtlInitUnicodeString(&Name, L"UserWaitInterval");
        TimeoutCell = CmpFindValueByName(SystemHive,
                                         ConfigDBNode,
                                         &Name);
        if (TimeoutCell == HCELL_NIL) {
            *ProfileTimeout = 0;
        } else {
            TimeoutValue = (PCM_KEY_VALUE)HvGetCell(SystemHive, TimeoutCell);
            if( TimeoutValue == NULL ) {
                //
                // we couldn't map a view for the bin containing this cell
                //

                return HCELL_NIL;
            }
            if (TimeoutValue->Type != REG_DWORD) {
                *ProfileTimeout = 0;
            } else {
                TempULong = (PULONG)CmpValueToData(SystemHive, TimeoutValue, &realsize);
                if( TempULong == NULL ) {
                    //
                    // HvGetCell inside CmpValueToData failed; bail out safely
                    //
                    return HCELL_NIL;
                }
                *ProfileTimeout = *TempULong;
            }
        }
    }

    if (ARGUMENT_PRESENT(ReturnedProfileList)) {
        ProfileList = *ReturnedProfileList;
        //
        // Enumerate the keys under IDConfigDB\Hardware Profiles
        // and build the list of available hardware profiles.  The list
        // is built sorted by PreferenceOrder.  Therefore, when the
        // list is complete, the default hardware profile is at the
        // head of the list.
        //
        RtlInitUnicodeString(&Name, L"Hardware Profiles");
        ProfileCell = CmpFindSubKeyByName(SystemHive,
                                          ConfigDBNode,
                                          &Name);
        if (ProfileCell == HCELL_NIL) {
            ProfileCount = 0;
            if (ProfileList != NULL) {
                ProfileList->CurrentProfileCount = 0;
            }
        } else {
            ProfileNode = (PCM_KEY_NODE)HvGetCell(SystemHive, ProfileCell);
            if( ProfileNode == NULL ) {
                //
                // we couldn't map a view for the bin containing this cell
                //

                return HCELL_NIL;
            }
            ProfileCount = ProfileNode->SubKeyCounts[Stable];
            if ((ProfileList == NULL) || (ProfileList->MaxProfileCount < ProfileCount)) {
                //
                // Allocate a larger ProfileList
                //
                ProfileList = (SystemHive->Allocate)(sizeof(CM_HARDWARE_PROFILE_LIST)
                                                     + (ProfileCount-1) * sizeof(CM_HARDWARE_PROFILE),
                                                     FALSE
                                                     ,CM_FIND_LEAK_TAG5);
                if (ProfileList == NULL) {
                    return(HCELL_NIL);
                }
                ProfileList->MaxProfileCount = ProfileCount;
            }
            ProfileList->CurrentProfileCount = 0;

            //
            // Enumerate the keys and fill in the profile list.
            //
            for (i=0; i<ProfileCount; i++) {
                CM_HARDWARE_PROFILE TempProfile;
                HCELL_INDEX ValueCell;
                PCM_KEY_VALUE ValueNode;
                UNICODE_STRING KeyName;
                ULONG realsize;

                HWCell = CmpFindSubKeyByNumber(SystemHive, ProfileNode, i);
                if (HWCell == HCELL_NIL) {
                    //
                    // This should never happen.
                    //
                    ProfileList->CurrentProfileCount = i;
                    break;
                }
                HWNode = (PCM_KEY_NODE)HvGetCell(SystemHive, HWCell);
                if( HWNode == NULL ) {
                    //
                    // we couldn't map a view for the bin containing this cell
                    //

                    return HCELL_NIL;
                }
                if (HWNode->Flags & KEY_COMP_NAME) {
                    KeyName.Length = CmpCompressedNameSize(HWNode->Name,
                                                           HWNode->NameLength);
                    KeyName.MaximumLength = sizeof(NameBuf);
                    if (KeyName.MaximumLength < KeyName.Length) {
                        KeyName.Length = KeyName.MaximumLength;
                    }
                    KeyName.Buffer = NameBuf;
                    CmpCopyCompressedName(KeyName.Buffer,
                                          KeyName.Length,
                                          HWNode->Name,
                                          HWNode->NameLength);
                } else {
                    KeyName.Length = KeyName.MaximumLength = HWNode->NameLength;
                    KeyName.Buffer = HWNode->Name;
                }

                //
                // Fill in the temporary profile structure with this
                // profile's data.
                //
                RtlUnicodeStringToInteger(&KeyName, 0, &TempProfile.Id);
                RtlInitUnicodeString(&Name, CM_HARDWARE_PROFILE_STR_PREFERENCE_ORDER);
                ValueCell = CmpFindValueByName(SystemHive,
                                               HWNode,
                                               &Name);
                if (ValueCell == HCELL_NIL) {
                    TempProfile.PreferenceOrder = (ULONG)-1;
                } else {
                    ValueNode = (PCM_KEY_VALUE)HvGetCell(SystemHive, ValueCell);
                    if( ValueNode == NULL ) {
                        //
                        // we couldn't map a view for the bin containing this cell
                        //

                        return HCELL_NIL;
                    }

                    TempULong = (PULONG)CmpValueToData(SystemHive,
                                                      ValueNode,
                                                      &realsize);
                    if( TempULong == NULL ) {
                        //
                        // HvGetCell inside CmpValueToData failed; bail out safely
                        //
                        return HCELL_NIL;
                    }
                    TempProfile.PreferenceOrder = *TempULong;
                }
                RtlInitUnicodeString(&Name, CM_HARDWARE_PROFILE_STR_FRIENDLY_NAME);
                ValueCell = CmpFindValueByName(SystemHive,
                                               HWNode,
                                               &Name);
                if (ValueCell == HCELL_NIL) {
                    TempProfile.FriendlyName = L"-------";
                    TempProfile.NameLength = wcslen(TempProfile.FriendlyName) * sizeof(WCHAR);
                } else {
                    ValueNode = (PCM_KEY_VALUE)HvGetCell(SystemHive, ValueCell);
                    if( ValueNode == NULL ) {
                        //
                        // we couldn't map a view for the bin containing this cell
                        //

                        return HCELL_NIL;
                    }
                    TempProfile.FriendlyName = (PWSTR)CmpValueToData(SystemHive,
                                                                     ValueNode,
                                                                     &realsize);
                    if( TempProfile.FriendlyName == NULL ) {
                        //
                        // HvGetCell inside CmpValueToData failed; bail out safely
                        //
                        return HCELL_NIL;
                    }
                    TempProfile.NameLength = realsize - sizeof(WCHAR);
                }

                TempProfile.Flags = 0;

                RtlInitUnicodeString(&Name, CM_HARDWARE_PROFILE_STR_ALIASABLE);
                ValueCell = CmpFindValueByName(SystemHive,
                                               HWNode,
                                               &Name);
                if (ValueCell == HCELL_NIL) {
                    TempProfile.Flags = CM_HP_FLAGS_ALIASABLE;
                } else {
                    ValueNode = (PCM_KEY_VALUE)HvGetCell(SystemHive, ValueCell);
                    if( ValueNode == NULL ) {
                        //
                        // we couldn't map a view for the bin containing this cell
                        //

                        return HCELL_NIL;
                    }

                    TempULong = (PULONG)CmpValueToData (SystemHive,ValueNode,&realsize);
                    if( TempULong == NULL ) {
                        //
                        // HvGetCell inside CmpValueToData failed; bail out safely
                        //
                        return HCELL_NIL;
                    }
                    if (*TempULong) {
                        TempProfile.Flags = CM_HP_FLAGS_ALIASABLE;
                        // NO other flags set.
                    }
                }

                RtlInitUnicodeString(&Name, CM_HARDWARE_PROFILE_STR_PRISTINE);
                ValueCell = CmpFindValueByName(SystemHive,
                                               HWNode,
                                               &Name);
                if (ValueCell != HCELL_NIL) {

                    ValueNode = (PCM_KEY_VALUE)HvGetCell(SystemHive, ValueCell);
                    if( ValueNode == NULL ) {
                        //
                        // we couldn't map a view for the bin containing this cell
                        //

                        return HCELL_NIL;
                    }

                    TempULong = (PULONG)CmpValueToData (SystemHive,ValueNode,&realsize);
                    if( TempULong == NULL ) {
                        //
                        // HvGetCell inside CmpValueToData failed; bail out safely
                        //
                        return HCELL_NIL;
                    }
                    if (*TempULong) {
                        TempProfile.Flags = CM_HP_FLAGS_PRISTINE;
                        // NO other flags set.
                    }
                }

                //
                // If we see a profile with the ID of zero (AKA an illegal)
                // ID for a hardware profile to possess, then we know that this
                // must be a pristine profile.
                //
                if (0 == TempProfile.Id) {
                    TempProfile.Flags = CM_HP_FLAGS_PRISTINE;
                    // NO other flags set.

                    TempProfile.PreferenceOrder = -1; // move to the end of the list.
                }


                //
                // Insert this new profile into the appropriate spot in the
                // profile array. Entries are sorted by preference order.
                //
                for (j=0; j<ProfileList->CurrentProfileCount; j++) {
                    if (ProfileList->Profile[j].PreferenceOrder >= TempProfile.PreferenceOrder) {
                        //
                        // Insert at position j.
                        //
                        RtlMoveMemory(&ProfileList->Profile[j+1],
                                      &ProfileList->Profile[j],
                                      sizeof(CM_HARDWARE_PROFILE)*(ProfileList->MaxProfileCount-j-1));
                        break;
                    }
                }
                ProfileList->Profile[j] = TempProfile;
                ++ProfileList->CurrentProfileCount;
            }
        }
        *ReturnedProfileList = ProfileList;
    }

    if (ARGUMENT_PRESENT(ReturnedAliasList)) {
        AliasList = *ReturnedAliasList;
        //
        // Enumerate the keys under IDConfigDB\Alias
        // and build the list of available hardware profiles aliases.
        // So that if we know our docking state we can find it in the alias
        // table.
        //
        RtlInitUnicodeString(&Name, L"Alias");
        AliasCell = CmpFindSubKeyByName(SystemHive,
                                        ConfigDBNode,
                                        &Name);
        if (AliasCell == HCELL_NIL) {
            AliasCount = 0;
            if (AliasList != NULL) {
                AliasList->CurrentAliasCount = 0;
            }
        } else {
            AliasNode = (PCM_KEY_NODE)HvGetCell(SystemHive, AliasCell);
            if( AliasNode == NULL ) {
                //
                // we couldn't map a view for the bin containing this cell
                //

                return HCELL_NIL;
            }
            AliasCount = AliasNode->SubKeyCounts[Stable];
            if ((AliasList == NULL) || (AliasList->MaxAliasCount < AliasCount)) {
                //
                // Allocate a larger AliasList
                //
                AliasList = (SystemHive->Allocate)(sizeof(CM_HARDWARE_PROFILE_LIST)
                                                   + (AliasCount-1) * sizeof(CM_HARDWARE_PROFILE),
                                                   FALSE
                                                   ,CM_FIND_LEAK_TAG6);
                if (AliasList == NULL) {
                    return(HCELL_NIL);
                }
                AliasList->MaxAliasCount = AliasCount;
            }
            AliasList->CurrentAliasCount = 0;

            //
            // Enumerate the keys and fill in the profile list.
            //
            for (i=0; i<AliasCount; i++) {
#define TempAlias AliasList->Alias[i]
                HCELL_INDEX ValueCell;
                PCM_KEY_VALUE ValueNode;
                UNICODE_STRING KeyName;
                ULONG realsize;

                HWCell = CmpFindSubKeyByNumber(SystemHive, AliasNode, i);
                if (HWCell == HCELL_NIL) {
                    //
                    // This should never happen.
                    //
                    AliasList->CurrentAliasCount = i;
                    break;
                }
                HWNode = (PCM_KEY_NODE)HvGetCell(SystemHive, HWCell);
                if( HWNode == NULL ) {
                    //
                    // we couldn't map a view for the bin containing this cell
                    //

                    return HCELL_NIL;
                }
                if (HWNode->Flags & KEY_COMP_NAME) {
                    KeyName.Length = CmpCompressedNameSize(HWNode->Name,
                                                           HWNode->NameLength);
                    KeyName.MaximumLength = sizeof(NameBuf);
                    if (KeyName.MaximumLength < KeyName.Length) {
                        KeyName.Length = KeyName.MaximumLength;
                    }
                    KeyName.Buffer = NameBuf;
                    CmpCopyCompressedName(KeyName.Buffer,
                                          KeyName.Length,
                                          HWNode->Name,
                                          HWNode->NameLength);
                } else {
                    KeyName.Length = KeyName.MaximumLength = HWNode->NameLength;
                    KeyName.Buffer = HWNode->Name;
                }

                //
                // Fill in the temporary profile structure with this
                // profile's data.
                //
                RtlInitUnicodeString(&Name, L"ProfileNumber");
                ValueCell = CmpFindValueByName(SystemHive,
                                               HWNode,
                                               &Name);
                if (ValueCell == HCELL_NIL) {
                    TempAlias.ProfileNumber = 0;
                } else {
                    ValueNode = (PCM_KEY_VALUE)HvGetCell(SystemHive, ValueCell);
                    if( ValueNode == NULL ) {
                        //
                        // we couldn't map a view for the bin containing this cell
                        //

                        return HCELL_NIL;
                    }

                    TempULong = (PULONG)CmpValueToData(SystemHive,ValueNode,&realsize);
                    if( TempULong == NULL ) {
                        //
                        // HvGetCell inside CmpValueToData failed; bail out safely
                        //
                        return HCELL_NIL;
                    }
                    TempAlias.ProfileNumber = *TempULong;
                }
                RtlInitUnicodeString(&Name, L"DockState");
                ValueCell = CmpFindValueByName(SystemHive,
                                               HWNode,
                                               &Name);
                if (ValueCell == HCELL_NIL) {
                    TempAlias.DockState = 0;
                } else {
                    ValueNode = (PCM_KEY_VALUE)HvGetCell(SystemHive, ValueCell);
                    if( ValueNode == NULL ) {
                        //
                        // we couldn't map a view for the bin containing this cell
                        //

                        return HCELL_NIL;
                    }

                    TempULong = (PULONG)CmpValueToData(SystemHive,ValueNode,&realsize);
                    if( TempULong == NULL ) {
                        //
                        // HvGetCell inside CmpValueToData failed; bail out safely
                        //
                        return HCELL_NIL;
                    }
                    TempAlias.DockState = *TempULong;
                }
                RtlInitUnicodeString(&Name, L"DockID");
                ValueCell = CmpFindValueByName(SystemHive,
                                               HWNode,
                                               &Name);
                if (ValueCell == HCELL_NIL) {
                    TempAlias.DockID = 0;
                } else {
                    ValueNode = (PCM_KEY_VALUE)HvGetCell(SystemHive, ValueCell);
                    if( ValueNode == NULL ) {
                        //
                        // we couldn't map a view for the bin containing this cell
                        //

                        return HCELL_NIL;
                    }

                    TempULong = (PULONG)CmpValueToData(SystemHive,ValueNode,&realsize);
                    if( TempULong == NULL ) {
                        //
                        // HvGetCell inside CmpValueToData failed; bail out safely
                        //
                        return HCELL_NIL;
                    }
                    TempAlias.DockID = *TempULong;
                }
                RtlInitUnicodeString(&Name, L"SerialNumber");
                ValueCell = CmpFindValueByName(SystemHive,
                                               HWNode,
                                               &Name);
                if (ValueCell == HCELL_NIL) {
                    TempAlias.SerialNumber = 0;
                } else {
                    ValueNode = (PCM_KEY_VALUE)HvGetCell(SystemHive, ValueCell);
                    if( ValueNode == NULL ) {
                        //
                        // we couldn't map a view for the bin containing this cell
                        //

                        return HCELL_NIL;
                    }

                    TempULong = (PULONG)CmpValueToData(SystemHive,ValueNode,&realsize);
                    if( TempULong == NULL ) {
                        //
                        // HvGetCell inside CmpValueToData failed; bail out safely
                        //
                        return HCELL_NIL;
                    }
                    TempAlias.SerialNumber = *TempULong;
                }

                ++AliasList->CurrentAliasCount;
            }
        }
        *ReturnedAliasList = AliasList;
    }

    return(IDConfigDB);
}


ULONG
CmpFindTagIndex(
    IN PHHIVE Hive,
    IN HCELL_INDEX TagCell,
    IN HCELL_INDEX GroupOrderCell,
    IN PUNICODE_STRING GroupName
    )

/*++

Routine Description:

    Calculates the tag index for a driver based on its tag value and
    the GroupOrderList entry for its group.

Arguments:

    Hive - Supplies the hive control structure for the driver.

    TagCell - Supplies the cell index of the driver's tag value cell.

    GroupOrderCell - Supplies the cell index for the control set's
            GroupOrderList:

            \Registry\Machine\System\CurrentControlSet\Control\GroupOrderList

    GroupName - Supplies the name of the group the driver belongs to.
            Note that if a driver's group does not have an entry under
            GroupOrderList, its tags will be ignored.  Also note that if
            a driver belongs to no group (GroupName is NULL) its tags will
            be ignored.

Return Value:

    The index that the driver should be sorted by.

--*/

{
    PCM_KEY_VALUE TagValue;
    PCM_KEY_VALUE DriverTagValue;
    HCELL_INDEX OrderCell;
    PULONG OrderVector;
    PULONG DriverTag;
    NTSTATUS Status;
    ULONG CurrentTag;
    ULONG realsize;
    PCM_KEY_NODE Node;
    BOOLEAN     BufferAllocated;

    //
    // no mapped hives at this point. don't bother releasing cells
    //
    ASSERT( Hive->ReleaseCellRoutine == NULL );

    DriverTagValue = (PCM_KEY_VALUE)HvGetCell(Hive, TagCell);
    if( DriverTagValue == NULL ) {
        //
        // we couldn't map a view for the bin containing this cell
        //

        return LOAD_NEXT_TO_LAST;
    }

    DriverTag = (PULONG)CmpValueToData(Hive, DriverTagValue, &realsize);
    if( DriverTag == NULL ) {
        //
        // HvGetCell inside CmpValueToData failed; bail out safely
        //
        return LOAD_NEXT_TO_LAST;
    }

    Node = (PCM_KEY_NODE)HvGetCell(Hive,GroupOrderCell);
    if( Node == NULL ) {
        //
        // we couldn't map a view for the bin containing this cell
        //

        return LOAD_NEXT_TO_LAST;
    }
    OrderCell = CmpFindValueByName(Hive,
                                   Node,
                                   GroupName);
    if (OrderCell == HCELL_NIL) {
        return(LOAD_NEXT_TO_LAST);
    }

    TagValue = (PCM_KEY_VALUE)HvGetCell(Hive, OrderCell);
    if( TagValue == NULL ) {
        //
        // we couldn't map a view for the bin containing this cell
        //

        return LOAD_NEXT_TO_LAST;
    }
    CmpGetValueData(Hive,TagValue,&realsize,&OrderVector,&BufferAllocated,&OrderCell);
    //OrderVector = (PULONG)CmpValueToData(Hive, TagValue,&realsize);
    if( OrderVector == NULL ) {
        //
        // HvGetCell inside CmpValueToData failed; bail out safely
        //
        return LOAD_NEXT_TO_LAST;
    }

    for (CurrentTag=1; CurrentTag <= OrderVector[0]; CurrentTag++) {
        if (OrderVector[CurrentTag] == *DriverTag) {
            //
            // We have found a matching tag in the OrderVector, so return
            // its index.
            //
#ifndef _CM_LDR_
            if( BufferAllocated ) {
                ExFreePool( OrderVector );
            }
#endif //_CM_LDR_
            return(CurrentTag);
        }
    }

#ifndef _CM_LDR_
    if( BufferAllocated ) {
        ExFreePool( OrderVector );
    }
#endif //_CM_LDR_
    //
    // There was no matching tag in the OrderVector.
    //
    return(LOAD_NEXT_TO_LAST);

}

#ifdef _WANT_MACHINE_IDENTIFICATION

BOOLEAN
CmpGetBiosDateFromRegistry(
    IN PHHIVE Hive,
    IN HCELL_INDEX ControlSet,
    OUT PUNICODE_STRING Date
    )

/*++

Routine Description:

    Reads and returns the BIOS date from the registry.

Arguments:

    Hive - Supplies the hive control structure for the driver.

    ControlSet - Supplies the HCELL_INDEX of the root cell of the hive.

    Date - Receives the date string in the format "mm/dd/yy".

Return Value:

 	TRUE iff successful, else FALSE.
 	
--*/

{
    UNICODE_STRING  name;
    HCELL_INDEX     control;
    HCELL_INDEX     biosInfo;
    HCELL_INDEX     valueCell;
    PCM_KEY_VALUE   value;
    ULONG           realSize;
    PCM_KEY_NODE    Node;
    //
    // no mapped hives at this point. don't bother releasing cells
    //
    ASSERT( Hive->ReleaseCellRoutine == NULL );

    //
    // Find CONTROL node
    //
    Node = (PCM_KEY_NODE)HvGetCell(Hive, ControlSet);
    if( Node == NULL ) {
        //
        // we couldn't map a view for the bin containing this cell
        //

        return FALSE;
    }
    RtlInitUnicodeString(&name, L"Control");
    control = CmpFindSubKeyByName(  Hive,
                                    Node,
                                    &name);
    if (control == HCELL_NIL) {

        return(FALSE);
    }

    //
    // Find BIOSINFO node
    //
    Node = (PCM_KEY_NODE)HvGetCell(Hive, control);
    if( Node == NULL ) {
        //
        // we couldn't map a view for the bin containing this cell
        //

        return FALSE;
    }
    RtlInitUnicodeString(&name, L"BIOSINFO");
    biosInfo = CmpFindSubKeyByName( Hive,
                                    Node,
                                    &name);
    if (biosInfo == HCELL_NIL) {

        return(FALSE);
    }

    //
    // Find SystemBiosDate value
    //
    Node = (PCM_KEY_NODE)HvGetCell(Hive, biosInfo);
    if( Node == NULL ) {
        //
        // we couldn't map a view for the bin containing this cell
        //

        return FALSE;
    }
    RtlInitUnicodeString(&name, L"SystemBiosDate");
    valueCell = CmpFindValueByName( Hive,
                                    Node,
                                    &name);
    if (valueCell == HCELL_NIL) {

        return(FALSE);
    }

    value = (PCM_KEY_VALUE)HvGetCell(Hive, valueCell);
    if( value == NULL ) {
        //
        // we couldn't map a view for the bin containing this cell
        //

        return FALSE;
    }
    Date->Buffer = (PWSTR)CmpValueToData(Hive, value, &realSize);
    if( Date->Buffer == NULL ) {
        //
        // we couldn't map a view for the bin containing this cell
        //

        return FALSE;
    }
    Date->MaximumLength=(USHORT)realSize;
    Date->Length = 0;
    while ( (Date->Length < Date->MaximumLength) &&
            (Date->Buffer[Date->Length/sizeof(WCHAR)] != UNICODE_NULL)) {

        Date->Length += sizeof(WCHAR);
    }

    return (TRUE);
}

BOOLEAN
CmpGetBiosinfoFileNameFromRegistry(
    IN PHHIVE Hive,
    IN HCELL_INDEX ControlSet,
    OUT PUNICODE_STRING InfName
    )
{
    UNICODE_STRING  name;
    HCELL_INDEX     control;
    HCELL_INDEX     biosInfo;
    HCELL_INDEX     valueCell;
    PCM_KEY_VALUE   value;
    ULONG           realSize;
    PCM_KEY_NODE    Node;

    //
    // no mapped hives at this point. don't bother releasing cells
    //
    ASSERT( Hive->ReleaseCellRoutine == NULL );
    //
    // Find CONTROL node
    //
    Node = (PCM_KEY_NODE)HvGetCell(Hive, ControlSet);
    if( Node == NULL ) {
        //
        // we couldn't map a view for the bin containing this cell
        //

        return FALSE;
    }
    RtlInitUnicodeString(&name, L"Control");
    control = CmpFindSubKeyByName(  Hive,
                                    Node,
                                    &name);
    if (control == HCELL_NIL) {

        return(FALSE);
    }

    //
    // Find BIOSINFO node
    //
    Node = (PCM_KEY_NODE)HvGetCell(Hive, control);
    if( Node == NULL ) {
        //
        // we couldn't map a view for the bin containing this cell
        //

        return FALSE;
    }
    RtlInitUnicodeString(&name, L"BIOSINFO");
    biosInfo = CmpFindSubKeyByName( Hive,
                                    Node,
                                    &name);
    if (biosInfo == HCELL_NIL) {

        return(FALSE);
    }

    //
    // Find InfName value
    //
    Node = (PCM_KEY_NODE)HvGetCell(Hive, biosInfo);
    if( Node == NULL ) {
        //
        // we couldn't map a view for the bin containing this cell
        //

        return FALSE;
    }
    RtlInitUnicodeString(&name, L"InfName");
    valueCell = CmpFindValueByName( Hive,
                                    Node,
                                    &name);
    if (valueCell == HCELL_NIL) {

        return(FALSE);
    }

    value = (PCM_KEY_VALUE)HvGetCell(Hive, valueCell);
    if( value == NULL ) {
        //
        // we couldn't map a view for the bin containing this cell
        //

        return FALSE;
    }
    InfName->Buffer = (PWSTR)CmpValueToData(Hive, value, &realSize);
    if( InfName->Buffer == NULL ) {
        //
        // we couldn't map a view for the bin containing this cell
        //

        return FALSE;
    }
    InfName->MaximumLength=(USHORT)realSize;
    InfName->Length = 0;
    while ( (InfName->Length < InfName->MaximumLength) &&
            (InfName->Buffer[InfName->Length/sizeof(WCHAR)] != UNICODE_NULL)) {

        InfName->Length += sizeof(WCHAR);
    }

    return (TRUE);
}

#endif
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\base\ntos\config\cmconfig.c ===
/*++

Copyright (c) 1990, 1991  Microsoft Corporation


Module Name:

    cmconfig.c

Abstract:

    This module is responsible to build the hardware tree of the
    registry data base.

Author:

    Shie-Lin Tzong (shielint) 23-Jan-1992


Environment:

    Kernel mode.

Revision History:

--*/

#include "cmp.h"

//
// Title Index - Never used for Product 1, set to 0 for now.
//

#define TITLE_INDEX_VALUE 0


extern ULONG CmpTypeCount[];


#define EISA_ADAPTER_INDEX EisaAdapter
#define TURBOCHANNEL_ADAPTER_INDEX TcAdapter

//
// The following variables are used to cross-reference multifunction
// adapters to their corresponding NT interface type.
//

extern struct {
    PUCHAR  AscString;
    USHORT  InterfaceType;
    USHORT  Count;
} CmpMultifunctionTypes[];

extern USHORT CmpUnknownBusCount;


//
// CmpConfigurationData - A pointer to the area reserved for the purpose
//     of reconstructing Configuration Data.
//
// CmpConfigurationAreaSize - Record the size of the Configuration Data
//     area.

extern ULONG CmpConfigurationAreaSize;
extern PCM_FULL_RESOURCE_DESCRIPTOR CmpConfigurationData;

//
// Function prototypes for internal erferences
//

NTSTATUS
CmpSetupConfigurationTree(
     IN PCONFIGURATION_COMPONENT_DATA CurrentEntry,
     IN HANDLE ParentHandle,
     IN INTERFACE_TYPE InterfaceType,
     IN ULONG BusNumber
     );

#ifdef ALLOC_PRAGMA
#pragma alloc_text(INIT,CmpInitializeHardwareConfiguration)
#pragma alloc_text(INIT,CmpSetupConfigurationTree)
#pragma alloc_text(INIT,CmpInitializeRegistryNode)
#endif


NTSTATUS
CmpInitializeHardwareConfiguration(
    IN PLOADER_PARAMETER_BLOCK LoaderBlock
    )
/*++

Routine Description:

    This routine creates \\Registry\Machine\Hardware node in
    the registry and calls SetupTree routine to put the hardware
    information to the registry.

Arguments:

    LoaderBlock - supplies a pointer to the LoaderBlock passed in from the
                  OS Loader.

Returns:

    NTSTATUS code for sucess or reason of failure.

--*/
{
    NTSTATUS Status;
    OBJECT_ATTRIBUTES ObjectAttributes;
    HANDLE BaseHandle;
    PCONFIGURATION_COMPONENT_DATA ConfigurationRoot;
    ULONG Disposition;

    ConfigurationRoot = (PCONFIGURATION_COMPONENT_DATA)LoaderBlock->ConfigurationRoot;

    //
    // Create \\Registry\Machine\Hardware\DeviceMap
    //

    InitializeObjectAttributes(
        &ObjectAttributes,
        &CmRegistryMachineHardwareDeviceMapName,
        0,
        (HANDLE)NULL,
        NULL
        );
    ObjectAttributes.Attributes |= OBJ_CASE_INSENSITIVE;

    Status = NtCreateKey(                   // Paht may already exist
                &BaseHandle,
                KEY_READ | KEY_WRITE,
                &ObjectAttributes,
                TITLE_INDEX_VALUE,
                NULL,
                0,
                &Disposition
                );

    if (!NT_SUCCESS(Status)) {
        return(Status);
    }

    NtClose(BaseHandle);

    ASSERT(Disposition == REG_CREATED_NEW_KEY);

    //
    // Create \\Registry\Machine\Hardware\Description and use the
    // returned handle as the BaseHandle to build the hardware tree.
    //

    InitializeObjectAttributes(
        &ObjectAttributes,
        &CmRegistryMachineHardwareDescriptionName,
        0,
        (HANDLE)NULL,
        NULL
        );
    ObjectAttributes.Attributes |= OBJ_CASE_INSENSITIVE;

    Status = NtCreateKey(                   // Path may already exist
                &BaseHandle,
                KEY_READ | KEY_WRITE,
                &ObjectAttributes,
                TITLE_INDEX_VALUE,
                NULL,
                0,
                &Disposition
                );

    if (!NT_SUCCESS(Status)) {
        return(Status);
    }

    ASSERT(Disposition == REG_CREATED_NEW_KEY);

    //
    // Allocate 16K bytes memory from paged pool for constructing
    // configuration data for controller component.
    // NOTE:  The configuration Data for controller component
    //    usually takes less than 100 bytes.  But on EISA machine, the
    //    EISA configuration information takes more than 10K and up to
    //    64K.  I believe 16K is the reasonable number to handler 99.9%
    //    of the machines.  Therefore, 16K is the initial value.
    //

    CmpConfigurationData = (PCM_FULL_RESOURCE_DESCRIPTOR)ExAllocatePool(
                                        PagedPool,
                                        CmpConfigurationAreaSize
                                        );

    if (CmpConfigurationData == NULL) {
        return(STATUS_INSUFFICIENT_RESOURCES);
    }

    //
    // Call SetupConfigurationTree routine to go over each component
    // of the tree and add component information to registry database.
    //

    if (ConfigurationRoot) {
        Status = CmpSetupConfigurationTree(ConfigurationRoot,
                                           BaseHandle,
                                           -1,
                                           (ULONG)-1);
    } else {
        Status = STATUS_SUCCESS;
    }

    ExFreePool((PVOID)CmpConfigurationData);
    NtClose(BaseHandle);
    return(Status);
}

NTSTATUS
CmpSetupConfigurationTree(
     IN PCONFIGURATION_COMPONENT_DATA CurrentEntry,
     IN HANDLE ParentHandle,
     IN INTERFACE_TYPE InterfaceType,
     IN ULONG BusNumber
     )
/*++

Routine Description:

    This routine traverses loader configuration tree and register
    the hardware information to the registry data base.

    Note to reduce the stack usage on machines with large number of PCI buses,
    we do not recursively process the sibling nodes.  We only recursively
    process the child trees.

Arguments:

    CurrentEntry - Supplies a pointer to a loader configuration
        tree or subtree.

    ParentHandle - Supplies the parent handle of CurrentEntry node.

    InterfaceType - Specify the Interface type of the bus that the
        CurrentEntry component resides.

    BusNumber - Specify the Bus Number of the bus that the CurrentEntry
        component resides.  If Bus number is -1, it means InterfaceType
        and BusNumber are meaningless for this component.

Returns:

    None.

--*/
{
    NTSTATUS Status;
    HANDLE NewHandle;
    USHORT i;
    CONFIGURATION_COMPONENT *Component;
    INTERFACE_TYPE LocalInterfaceType = InterfaceType;
    ULONG LocalBusNumber = BusNumber;
    USHORT DeviceIndexTable[NUMBER_TYPES];

    for (i = 0; i < NUMBER_TYPES; i++) {
        DeviceIndexTable[i] = 0;
    }

    //
    // Process current entry and its siblings
    //

    while (CurrentEntry) {

        //
        // Register current entry first before going down to its children
        //

        Component = &CurrentEntry->ComponentEntry;

        //
        // If the current component is a bus component, we will set up
        // its bus number and Interface type and use them to initialize
        // its subtree.
        //

        if (Component->Class == AdapterClass &&
            CurrentEntry->Parent->ComponentEntry.Class == SystemClass) {

            switch (Component->Type) {

            case EisaAdapter:
                LocalInterfaceType = Eisa;
                LocalBusNumber = CmpTypeCount[EISA_ADAPTER_INDEX]++;
                break;
            case TcAdapter:
                LocalInterfaceType = TurboChannel;
                LocalBusNumber = CmpTypeCount[TURBOCHANNEL_ADAPTER_INDEX]++;
                break;
            case MultiFunctionAdapter:

                //
                // Here we try to distinguish if the Multifunction adapter is
                // Isa, Mca, Internal bus and assign BusNumber based on
                // its interface type (bus type.)
                //

                if (Component->Identifier) {
                    for (i=0; CmpMultifunctionTypes[i].AscString; i++) {
                        if (_stricmp(CmpMultifunctionTypes[i].AscString,
                                    Component->Identifier) == 0) {
                                        break;
                        }
                    }

                    LocalInterfaceType = CmpMultifunctionTypes[i].InterfaceType;
                    LocalBusNumber = CmpMultifunctionTypes[i].Count++;
                }
                break;

            case ScsiAdapter:

                //
                // Set the bus type to internal.
                //

                LocalInterfaceType = Internal;
                LocalBusNumber = CmpTypeCount[ScsiAdapter]++;
                break;

            default:
                LocalInterfaceType = -1;
                LocalBusNumber = CmpUnknownBusCount++;
                break;
            }
        }

        //
        // Initialize and copy current component to hardware registry
        //

        Status = CmpInitializeRegistryNode(
                     CurrentEntry,
                     ParentHandle,
                     &NewHandle,
                     LocalInterfaceType,
                     LocalBusNumber,
                     DeviceIndexTable
                     );

        if (!NT_SUCCESS(Status)) {
            return(Status);
        }

        //
        // Once we are going one level down, we need to clear the TypeCount
        // table for everything under the current component class ...
        //

        if (CurrentEntry->Child) {

            //
            // Process the child entry of current entry
            //

            Status = CmpSetupConfigurationTree(CurrentEntry->Child,
                                               NewHandle,
                                               LocalInterfaceType,
                                               LocalBusNumber
                                               );
            if (!NT_SUCCESS(Status)) {
                NtClose(NewHandle);
                return(Status);
            }
        }
        NtClose(NewHandle);
        CurrentEntry = CurrentEntry->Sibling;
    }
    return(STATUS_SUCCESS);
}


NTSTATUS
CmpInitializeRegistryNode(
    IN PCONFIGURATION_COMPONENT_DATA CurrentEntry,
    IN HANDLE ParentHandle,
    OUT PHANDLE NewHandle,
    IN INTERFACE_TYPE InterfaceType,
    IN ULONG BusNumber,
    IN PUSHORT DeviceIndexTable
    )

/*++

Routine Description:

    This routine creates a node for the current firmware component
    and puts component data to the data part of the node.

Arguments:

    CurrentEntry - Supplies a pointer to a configuration component.

    Handle - Supplies the parent handle of CurrentEntry node.

    NewHandle - Suppiles a pointer to a HANDLE to receive the handle of
        the newly created node.

    InterfaceType - Specify the Interface type of the bus that the
        CurrentEntry component resides. (See BusNumber also)

    BusNumber - Specify the Bus Number of the bus that the CurrentEntry
        component resides on.  If Bus number is -1, it means InterfaceType
        and BusNumber are meaningless for this component.

Returns:

    None.

--*/
{

    NTSTATUS Status;
    OBJECT_ATTRIBUTES ObjectAttributes;
    UNICODE_STRING KeyName;
    UNICODE_STRING ValueName;
    UNICODE_STRING ValueData;
    HANDLE Handle;
    HANDLE OldHandle;
    ANSI_STRING AnsiString;
    UCHAR Buffer[12];
    WCHAR UnicodeBuffer[12];
    CONFIGURATION_COMPONENT *Component;
    ULONG Disposition;
    ULONG ConfigurationDataLength;
    PCM_FULL_RESOURCE_DESCRIPTOR NewArea;

    Component = &CurrentEntry->ComponentEntry;

    //
    // If the component class is SystemClass, we set its Type to be
    // ArcSystem.  The reason is because the detection code sets
    // its type to MaximumType to indicate it is NOT ARC compatible.
    // Here, we are only interested in building a System Node.  So we
    // change its Type to ArcSystem to ease the setup.
    //

    if (Component->Class == SystemClass) {
        Component->Type = ArcSystem;
    }

    //
    // Create a new key to describe the Component.
    //
    // The type of the component will be used as the keyname of the
    // registry node.  The class is the class of the component.
    //

    InitializeObjectAttributes(
        &ObjectAttributes,
        &(CmTypeName[Component->Type]),
        0,
        ParentHandle,
        NULL
        );
    ObjectAttributes.Attributes |= OBJ_CASE_INSENSITIVE;

    Status = NtCreateKey(                   // Paht may already exist
                &Handle,
                KEY_READ | KEY_WRITE,
                &ObjectAttributes,
                0,
                NULL,
                0,
                &Disposition
                );

    if (!NT_SUCCESS(Status)) {
        return(Status);
    }

    //
    // If this component is NOT a SystemClass component, we will
    // create a subkey to identify the component's ordering.
    //

    if (Component->Class != SystemClass) {

        RtlIntegerToChar(
            DeviceIndexTable[Component->Type]++,
            10,
            12,
            Buffer
            );

        RtlInitAnsiString(
            &AnsiString,
            Buffer
            );

        KeyName.Buffer = (PWSTR)UnicodeBuffer;
        KeyName.Length = 0;
        KeyName.MaximumLength = sizeof(UnicodeBuffer);

        RtlAnsiStringToUnicodeString(
            &KeyName,
            &AnsiString,
            FALSE
            );

        OldHandle = Handle;

        InitializeObjectAttributes(
            &ObjectAttributes,
            &KeyName,
            0,
            OldHandle,
            NULL
            );
        ObjectAttributes.Attributes |= OBJ_CASE_INSENSITIVE;

        Status = NtCreateKey(
                    &Handle,
                    KEY_READ | KEY_WRITE,
                    &ObjectAttributes,
                    0,
                    NULL,
                    0,
                    &Disposition
                    );

        NtClose(OldHandle);

        if (!NT_SUCCESS(Status)) {
            return(Status);
        }

        ASSERT(Disposition == REG_CREATED_NEW_KEY);
    }

    //
    // Create a value which describes the following component information:
    //     Flags, Cersion, Key, AffinityMask.
    //

    RtlInitUnicodeString(
        &ValueName,
        L"Component Information"
        );

    Status = NtSetValueKey(
                Handle,
                &ValueName,
                TITLE_INDEX_VALUE,
                REG_BINARY,
                &Component->Flags,
                FIELD_OFFSET(CONFIGURATION_COMPONENT, ConfigurationDataLength) -
                    FIELD_OFFSET(CONFIGURATION_COMPONENT, Flags)
                );

    if (!NT_SUCCESS(Status)) {
        NtClose(Handle);
        return(Status);
    }

    //
    // Create a value which describes the component identifier, if any.
    //

    if (Component->IdentifierLength) {

        RtlInitUnicodeString(
            &ValueName,
            L"Identifier"
            );

        RtlInitAnsiString(
            &AnsiString,
            Component->Identifier
            );

        RtlAnsiStringToUnicodeString(
            &ValueData,
            &AnsiString,
            TRUE
            );

        Status = NtSetValueKey(
                    Handle,
                    &ValueName,
                    TITLE_INDEX_VALUE,
                    REG_SZ,
                    ValueData.Buffer,
                    ValueData.Length + sizeof( UNICODE_NULL )
                    );

        RtlFreeUnicodeString(&ValueData);

        if (!NT_SUCCESS(Status)) {
            NtClose(Handle);
            return(Status);
        }
    }

    //
    // Create a value entry for component configuration data.
    //

    RtlInitUnicodeString(
        &ValueName,
        L"Configuration Data"
        );

    //
    // Create the configuration data based on CM_FULL_RESOURCE_DESCRIPTOR.
    //
    // Note the configuration data in firmware tree may be in the form of
    // CM_PARTIAL_RESOURCE_LIST or nothing.  In both cases, we need to
    // set up the registry configuration data to be in the form of
    // CM_FULL_RESOURCE_DESCRIPTOR.
    //

    if (CurrentEntry->ConfigurationData) {

        //
        // This component has configuration data, we copy the data
        // to our work area, add some more data items and copy the new
        // configuration data to the registry.
        //

        ConfigurationDataLength = Component->ConfigurationDataLength +
                      FIELD_OFFSET(CM_FULL_RESOURCE_DESCRIPTOR,
                      PartialResourceList);

        //
        // Make sure our reserved area is big enough to hold the data.
        //

        if (ConfigurationDataLength > CmpConfigurationAreaSize) {

            //
            // If reserved area is not big enough, we resize our reserved
            // area.  If, unfortunately, the reallocation fails, we simply
            // loss the configuration data of this particular component.
            //

            NewArea = (PCM_FULL_RESOURCE_DESCRIPTOR)ExAllocatePool(
                                            PagedPool,
                                            ConfigurationDataLength
                                            );

            if (NewArea) {
                CmpConfigurationAreaSize = ConfigurationDataLength;
                ExFreePool(CmpConfigurationData);
                CmpConfigurationData = NewArea;
                RtlCopyMemory(
                    (PUCHAR)&CmpConfigurationData->PartialResourceList.Version,
                    CurrentEntry->ConfigurationData,
                    Component->ConfigurationDataLength
                    );
            } else {
                Component->ConfigurationDataLength = 0;
                CurrentEntry->ConfigurationData = NULL;
            }
        } else {
            RtlCopyMemory(
                (PUCHAR)&CmpConfigurationData->PartialResourceList.Version,
                CurrentEntry->ConfigurationData,
                Component->ConfigurationDataLength
                );
        }

    }

    if (CurrentEntry->ConfigurationData == NULL) {

        //
        // This component has NO configuration data (or we can't resize
        // our reserved area to hold the data), we simple add whatever
        // is required to set up a CM_FULL_RESOURCE_LIST.
        //

        CmpConfigurationData->PartialResourceList.Version = 0;
        CmpConfigurationData->PartialResourceList.Revision = 0;
        CmpConfigurationData->PartialResourceList.Count = 0;
        ConfigurationDataLength = FIELD_OFFSET(CM_FULL_RESOURCE_DESCRIPTOR,
                                               PartialResourceList) +
                                  FIELD_OFFSET(CM_PARTIAL_RESOURCE_LIST,
                                               PartialDescriptors);
    }

    //
    // Set up InterfaceType and BusNumber for the component.
    //

    CmpConfigurationData->InterfaceType = InterfaceType;
    CmpConfigurationData->BusNumber = BusNumber;

    //
    // Write the newly constructed configuration data to the hardware registry
    //

    Status = NtSetValueKey(
                Handle,
                &ValueName,
                TITLE_INDEX_VALUE,
                REG_FULL_RESOURCE_DESCRIPTOR,
                CmpConfigurationData,
                ConfigurationDataLength
                );

    if (!NT_SUCCESS(Status)) {
        NtClose(Handle);
        return(Status);
    }

    *NewHandle = Handle;
    return(STATUS_SUCCESS);

}
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\base\ntos\config\cmclose.c ===
/*++

Copyright (c) 1991  Microsoft Corporation

Module Name:

    cmclose.c

Abstract:

    This module contains the close object method.

Author:

    Bryan M. Willman (bryanwi) 07-Jan-92

Revision History:

--*/

#include    "cmp.h"

#ifdef ALLOC_PRAGMA
#pragma alloc_text(PAGE,CmpCloseKeyObject)
#endif

VOID
CmpCloseKeyObject(
    IN PEPROCESS Process OPTIONAL,
    IN PVOID Object,
    IN ACCESS_MASK GrantedAccess,
    IN ULONG ProcessHandleCount,
    IN ULONG SystemHandleCount
    )
/*++

Routine Description:

    This routine interfaces to the NT Object Manager.  It is invoked when
    a Key object (or Key Root object) is closed.

    It's function is to do cleanup processing by waking up any notifies
    pending on the handle.  This keeps the key object from hanging around
    forever because a synchronous notify is stuck on it somewhere.

    All other cleanup, in particular, the freeing of storage, will be
    done in CmpDeleteKeyObject.

Arguments:

    Process - ignored

    Object - supplies a pointer to a KeyRoot or Key, thus -> KEY_BODY.

    GrantedAccess, ProcessHandleCount, SystemHandleCount - ignored

Return Value:

    NONE.

--*/
{
    PCM_KEY_BODY        KeyBody;
    PCM_NOTIFY_BLOCK    NotifyBlock;

    PAGED_CODE();
    CmKdPrintEx((DPFLTR_CONFIG_ID,CML_POOL,"CmpCloseKeyObject: Object = %p\n", Object));

    if( SystemHandleCount > 1 ) {
        //
        // There are still has open handles on this key. Do nothing
        //
        return;
    }

    CmpLockRegistry();

    KeyBody = (PCM_KEY_BODY)Object;

    //
    // Check the type, it will be something else if we are closing a predefined
    // handle key
    //
    if (KeyBody->Type == KEY_BODY_TYPE) {
        //
        // Clean up any outstanding notifies attached to the KeyBody
        //
        if (KeyBody->NotifyBlock != NULL) {
            //
            // Post all PostBlocks waiting on the NotifyBlock
            //
            NotifyBlock = KeyBody->NotifyBlock;
            if (IsListEmpty(&(NotifyBlock->PostList)) == FALSE) {
                //
                // we need to follow the rule here and aquire kcb lock before hive lock
                // other wise we could deadlock down in CmDeleteKeyObject
                //
                BEGIN_KCB_LOCK_GUARD;    
                CmpLockKCBTreeExclusive();
                CmLockHive((PCMHIVE)(KeyBody->KeyControlBlock->KeyHive));
                CmpPostNotify(NotifyBlock,
                              NULL,
                              0,
                              STATUS_NOTIFY_CLEANUP,
                              NULL
#ifdef CM_NOTIFY_CHANGED_KCB_FULLPATH  
                              ,
                              NULL
#endif //CM_NOTIFY_CHANGED_KCB_FULLPATH  
                              );
                CmUnlockHive((PCMHIVE)(KeyBody->KeyControlBlock->KeyHive));
                CmpUnlockKCBTree();
                END_KCB_LOCK_GUARD;    
            }
        }
    }

    CmpUnlockRegistry();
    return;
}
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\base\ntos\config\cmcontrl.c ===
/*++

Copyright (c) 1992  Microsoft Corporation

Module Name:

    cmcontrl.c

Abstract:

    The module contains CmGetSystemControlValues, see cmdat.c for data.

Author:

    Bryan M. Willman (bryanwi) 12-May-92

Revision History:

--*/

#include    "cmp.h"

extern WCHAR   CmDefaultLanguageId[];
extern ULONG   CmDefaultLanguageIdLength;
extern ULONG   CmDefaultLanguageIdType;

extern WCHAR   CmInstallUILanguageId[];
extern ULONG   CmInstallUILanguageIdLength;
extern ULONG   CmInstallUILanguageIdType;

HCELL_INDEX
CmpWalkPath(
    PHHIVE      SystemHive,
    HCELL_INDEX ParentCell,
    PWSTR       Path
    );

LANGID
CmpConvertLangId(
    PWSTR LangIdString,
    ULONG LangIdStringLength
);

#ifdef ALLOC_PRAGMA
#pragma alloc_text(INIT,CmGetSystemControlValues)
#pragma alloc_text(INIT,CmpWalkPath)
#pragma alloc_text(INIT,CmpConvertLangId)
#endif

VOID
CmGetSystemControlValues(
    PVOID                   SystemHiveBuffer,
    PCM_SYSTEM_CONTROL_VECTOR  ControlVector
    )
/*++

Routine Description:

    Look for registry values in current control set, as specified
    by entries in ControlVector.  Report data for value entries
    (if any) to variables ControlVector points to.

Arguments:

    SystemHiveBuffer - pointer to flat image of the system hive

    ControlVector - pointer to structure that describes what values
                    to pull out and store

Return Value:

    NONE.

--*/
{
    NTSTATUS        status;
    PHHIVE          SystemHive;
    CMHIVE          TempHive;
    HCELL_INDEX     RootCell;
    HCELL_INDEX     BaseCell;
    UNICODE_STRING  Name;
    PHCELL_INDEX    Index;
    HCELL_INDEX     KeyCell;
    HCELL_INDEX     ValueCell;
    PCM_KEY_VALUE   ValueBody;
    PVOID           ValueData;
    ULONG           Length;
    BOOLEAN         AutoSelect;
    BOOLEAN         small;
    ULONG           tmplength;
    PCM_KEY_NODE    Node;

    //
    // set up to read flat system hive image loader passes us
    //
    RtlZeroMemory((PVOID)&TempHive, sizeof(TempHive));
    SystemHive = &(TempHive.Hive);
    CmpInitHiveViewList((PCMHIVE)SystemHive);
    CmpInitSecurityCache((PCMHIVE)SystemHive);
    status = HvInitializeHive(
                SystemHive,
                HINIT_FLAT,
                HIVE_VOLATILE,
                HFILE_TYPE_PRIMARY,
                SystemHiveBuffer,
                NULL,
                NULL,
                NULL,
                NULL,
                NULL,
                NULL,
                1,
                NULL
                );
    if (!NT_SUCCESS(status)) {
         CM_BUGCHECK(BAD_SYSTEM_CONFIG_INFO,BAD_SYSTEM_CONTROL_VALUES,1,SystemHive,status);
    }

    //
    // don't bother locking/releasing cells
    //
    ASSERT( SystemHive->ReleaseCellRoutine == NULL );
    //
    // get hive.cell of root of current control set
    //
    RootCell = ((PHBASE_BLOCK)SystemHiveBuffer)->RootCell;
    RtlInitUnicodeString(&Name, L"current");
    BaseCell = CmpFindControlSet(
                    SystemHive,
                    RootCell,
                    &Name,
                    &AutoSelect
                    );
    if (BaseCell == HCELL_NIL) {
        CM_BUGCHECK(BAD_SYSTEM_CONFIG_INFO,BAD_SYSTEM_CONTROL_VALUES,2,SystemHive,&Name);
    }

    Node = (PCM_KEY_NODE)HvGetCell(SystemHive,BaseCell);
    if( Node == NULL ) {
        //
        // we couldn't map a view for the bin containing this cell
        //
        return;
    }
    RtlInitUnicodeString(&Name, L"control");
    BaseCell = CmpFindSubKeyByName(SystemHive,
                                   Node,
                                   &Name);
    if (BaseCell == HCELL_NIL) {
        CM_BUGCHECK(BAD_SYSTEM_CONFIG_INFO,BAD_SYSTEM_CONTROL_VALUES,3,Node,&Name);
    }

    //
    // SystemHive.BaseCell = \registry\machine\system\currentcontrolset\control
    //

    //
    // step through vector, trying to fetch each value
    //
    while (ControlVector->KeyPath != NULL) {

        //
        //  Assume we will fail to find the key or value.
        //
        
        Length = (ULONG)-1;

        KeyCell = CmpWalkPath(SystemHive, BaseCell, ControlVector->KeyPath);

        if (KeyCell != HCELL_NIL) {

            //
            // found the key, look for the value entry
            //
            Node = (PCM_KEY_NODE)HvGetCell(SystemHive,KeyCell);
            if( Node == NULL ) {
                //
                // we couldn't map a view for the bin containing this cell
                //
                return;
            }
            RtlInitUnicodeString(&Name, ControlVector->ValueName);
            ValueCell = CmpFindValueByName(SystemHive,
                                           Node,
                                           &Name);
            if (ValueCell != HCELL_NIL) {

                //
                // SystemHive.ValueCell is value entry body
                //

                if (ControlVector->BufferLength == NULL) {
                    tmplength = sizeof(ULONG);
                } else {
                    tmplength = *(ControlVector->BufferLength);
                }

                ValueBody = (PCM_KEY_VALUE)HvGetCell(SystemHive, ValueCell);
                if( ValueBody == NULL ) {
                    //
                    // we couldn't map a view for the bin containing this cell
                    //
                    return;
                }

                small = CmpIsHKeyValueSmall(Length, ValueBody->DataLength);

                if (tmplength < Length) {
                    Length = tmplength;
                }

                if (Length > 0) {

                    PCELL_DATA  Buffer;
                    BOOLEAN     BufferAllocated;
                    ULONG       realsize;
                    HCELL_INDEX CellToRelease;

                    ASSERT((small ? (Length <= CM_KEY_VALUE_SMALL) : TRUE));
                    //
                    // get the data from source, regardless of the size
                    //
                    if( CmpGetValueData(SystemHive,ValueBody,&realsize,&Buffer,&BufferAllocated,&CellToRelease) == FALSE ) {
                        //
                        // insufficient resources; return NULL
                        //
                        ASSERT( BufferAllocated == FALSE );
                        ASSERT( Buffer == NULL );
                        return;
                    }

                    RtlCopyMemory(
                        ControlVector->Buffer,
                        Buffer,
                        Length
                        );

                    //
                    // cleanup the temporary buffer
                    //
                    if( BufferAllocated == TRUE ) {
                        ExFreePool( Buffer );
                    }
                    if( CellToRelease != HCELL_NIL ) {
                        HvReleaseCell(SystemHive,CellToRelease);
                    }
                }

                if (ControlVector->Type != NULL) {
                    *(ControlVector->Type) = ValueBody->Type;
                }
            }
        }

        //
        // Stash the length of result (-1 if nothing was found)
        //
        
        if (ControlVector->BufferLength != NULL) {
            *(ControlVector->BufferLength) = Length;
        }

        ControlVector++;
    }

    //
    // Get the default locale ID for the system from the registry.
    //

    if (CmDefaultLanguageIdType == REG_SZ) {
        PsDefaultSystemLocaleId = (LCID) CmpConvertLangId( 
                                                CmDefaultLanguageId,
                                                CmDefaultLanguageIdLength);
    } else {
        PsDefaultSystemLocaleId = 0x00000409;
    }

    //
    // Get the install (native UI) language ID for the system from the registry.
    //

    if (CmInstallUILanguageIdType == REG_SZ) {
        PsInstallUILanguageId =  CmpConvertLangId( 
                                                CmInstallUILanguageId,
                                                CmInstallUILanguageIdLength);
    } else {
        PsInstallUILanguageId = LANGIDFROMLCID(PsDefaultSystemLocaleId);
    }

    //
    // Set the default thread locale to the default system locale
    // for now.  This will get changed as soon as somebody logs in.
    // Use the install (native) language id as our default UI language id. 
    // This also will get changed as soon as somebody logs in.
    //

    PsDefaultThreadLocaleId = PsDefaultSystemLocaleId;
    PsDefaultUILanguageId = PsInstallUILanguageId;
}


HCELL_INDEX
CmpWalkPath(
    PHHIVE      SystemHive,
    HCELL_INDEX ParentCell,
    PWSTR       Path
    )
/*++

Routine Description:

    Walk the path.

Arguments:

    SystemHive - hive

    ParentCell - where to start

    Path - string to walk

Return Value:

    HCELL_INDEX of found key cell, or HCELL_NIL for error

--*/
{
    NTSTATUS        status;
    UNICODE_STRING  PathString;
    UNICODE_STRING  NextName;
    BOOLEAN         Last;
    PHCELL_INDEX    Index;
    HCELL_INDEX     KeyCell;
    PCM_KEY_NODE    Node;

    //
    // don't bother counting/releasing used cells
    //
    ASSERT( SystemHive->ReleaseCellRoutine == NULL );

    KeyCell = ParentCell;
    RtlInitUnicodeString(&PathString, Path);

    while (TRUE) {

        CmpGetNextName(&PathString, &NextName, &Last);

        if (NextName.Length == 0) {
            return KeyCell;
        }

        Node = (PCM_KEY_NODE)HvGetCell(SystemHive,KeyCell);
        if( Node == NULL ) {
            //
            // we couldn't map a view for the bin containing this cell
            //
            return HCELL_NIL;
        }
        KeyCell = CmpFindSubKeyByName(SystemHive,
                                      Node,
                                      &NextName);

        if (KeyCell == HCELL_NIL) {
            return HCELL_NIL;
        }
    }
}

LANGID
CmpConvertLangId(
    PWSTR LangIdString,
    ULONG LangIdStringLength
)
{


    USHORT i, Digit;
    WCHAR c;
    LANGID LangId;

    LangId = 0;
    LangIdStringLength = LangIdStringLength / sizeof( WCHAR );
    for (i=0; i < LangIdStringLength; i++) {
        c = LangIdString[ i ];

        if (c >= L'0' && c <= L'9') {
            Digit = c - L'0';

        } else if (c >= L'A' && c <= L'F') {
            Digit = c - L'A' + 10;

        } else if (c >= L'a' && c <= L'f') {
            Digit = c - L'a' + 10;

        } else {
            break;
        }

        if (Digit >= 16) {
            break;
        }

        LangId = (LangId << 4) | Digit;
    }

    return LangId;
}
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\base\ntos\config\cmdat2.c ===
/*++

Copyright (c) 1990, 1991  Microsoft Corporation


Module Name:

    cmdat2.c

Abstract:

    This module contains data strings that describes the registry space
    and that are exported to the rest of the system.

Author:

    Andre Vachon (andreva) 08-Apr-1992


Environment:

    Kernel mode.

Revision History:

--*/

#include "cmp.h"

//
// ***** PAGE *****
//

#ifdef ALLOC_DATA_PRAGMA
#pragma data_seg("PAGEDATA")
#endif

//
// control values/overrides read from registry
//
ULONG CmRegistrySizeLimit = { 0 };
ULONG CmRegistrySizeLimitLength = 4;
ULONG CmRegistrySizeLimitType = { 0 };

//
// Maximum number of bytes of Global Quota the registry may use.
// Set to largest positive number for use in boot.  Will be set down
// based on pool and explicit registry values.
//
ULONG   CmpGlobalQuotaAllowed = CM_WRAP_LIMIT;
ULONG   CmpGlobalQuota = CM_WRAP_LIMIT;
ULONG   CmpGlobalQuotaWarning = CM_WRAP_LIMIT;
BOOLEAN CmpQuotaWarningPopupDisplayed = FALSE;
BOOLEAN CmpSystemQuotaWarningPopupDisplayed = FALSE;

//
// the "disk full" popup has already been displayed
//
BOOLEAN CmpDiskFullWorkerPopupDisplayed = FALSE;
BOOLEAN CmpCannotWriteConfiguration = FALSE;
//
// GQ actually in use
//
ULONG   CmpGlobalQuotaUsed = 0;

//
// State flag to remember when to turn it on
//
BOOLEAN CmpProfileLoaded = FALSE;

PUCHAR CmpStashBuffer = NULL;
ULONG  CmpStashBufferSize = 0;
FAST_MUTEX CmpStashBufferLock;

//
// Shutdown control
//
BOOLEAN HvShutdownComplete = FALSE;     // Set to true after shutdown
                                        // to disable any further I/O

PCM_KEY_CONTROL_BLOCK CmpKeyControlBlockRoot = NULL;

HANDLE CmpRegistryRootHandle = NULL;

struct {
    PHHIVE      Hive;
    ULONG       Status;
} CmCheckRegistryDebug = { 0 };

//
// The last I/O error status code
//
struct {
    ULONG       Action;
    HANDLE      Handle;
    NTSTATUS    Status;
} CmRegistryIODebug = { 0 };

//
// globals private to check code
//

struct {
    PHHIVE      Hive;
    ULONG       Status;
} CmpCheckRegistry2Debug = { 0 };

struct {
    PHHIVE      Hive;
    ULONG       Status;
    HCELL_INDEX Cell;
    PCELL_DATA  CellPoint;
    PVOID       RootPoint;
    ULONG       Index;
} CmpCheckKeyDebug = { 0 };

struct {
    PHHIVE      Hive;
    ULONG       Status;
    PCELL_DATA  List;
    ULONG       Index;
    HCELL_INDEX Cell;
    PCELL_DATA  CellPoint;
} CmpCheckValueListDebug = { 0 };

ULONG CmpUsedStorage = { 0 };

// hivechek.c
struct {
    PHHIVE      Hive;
    ULONG       Status;
    ULONG       Space;
    HCELL_INDEX MapPoint;
    PHBIN       BinPoint;
} HvCheckHiveDebug = { 0 };

struct {
    PHBIN       Bin;
    ULONG       Status;
    PHCELL      CellPoint;
} HvCheckBinDebug = { 0 };

struct {
    PHHIVE      Hive;
    ULONG       FileOffset;
    ULONG       FailPoint; // look in HvpRecoverData for exact point of failure
} HvRecoverDataDebug = { 0 };

//
// when a local hive cannot be loded, set this to it's index
// and the load hive worker thread responsible for it will be held of 
// until all the others finish; We can then debug the offending hive
//
ULONG   CmpCheckHiveIndex = CM_NUMBER_OF_MACHINE_HIVES;


#ifdef CMP_STATS

struct {
    ULONG       CmpMaxKcbNo;
    ULONG       CmpKcbNo;
    ULONG       CmpStatNo;
    ULONG       CmpNtCreateKeyNo;
    ULONG       CmpNtDeleteKeyNo;
    ULONG       CmpNtDeleteValueKeyNo;
    ULONG       CmpNtEnumerateKeyNo;
    ULONG       CmpNtEnumerateValueKeyNo;
    ULONG       CmpNtFlushKeyNo;
    ULONG       CmpNtInitializeRegistryNo;
    ULONG       CmpNtNotifyChangeMultipleKeysNo;
    ULONG       CmpNtOpenKeyNo;
    ULONG       CmpNtQueryKeyNo;
    ULONG       CmpNtQueryValueKeyNo;
    ULONG       CmpNtQueryMultipleValueKeyNo;
    ULONG       CmpNtRestoreKeyNo;
    ULONG       CmpNtSaveKeyNo;
    ULONG       CmpNtSaveMergedKeysNo;
    ULONG       CmpNtSetValueKeyNo;
    ULONG       CmpNtLoadKeyNo;
    ULONG       CmpNtUnloadKeyNo;
    ULONG       CmpNtSetInformationKeyNo;
    ULONG       CmpNtReplaceKeyNo;
    ULONG       CmpNtQueryOpenSubKeysNo;
} CmpStatsDebug = { 0 };

#endif

#ifdef ALLOC_DATA_PRAGMA
#pragma  data_seg()
#endif
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\base\ntos\config\cmdat3.c ===
/*++

Copyright (c) 1990, 1991  Microsoft Corporation


Module Name:

    cmdat3.c

Abstract:

    This module contains registry "static" data which we don't
    want pulled into the loader.

Author:

    Bryan Willman (bryanwi) 19-Oct-93


Environment:

    Kernel mode.

Revision History:

--*/

#include "cmp.h"
#pragma hdrstop
#include "dpfiltercm.h"

//
// ***** INIT *****
//

//
// Data for CmGetSystemControlValues
//
//
// ----- CmControlVector -----
//
#ifdef ALLOC_DATA_PRAGMA
#pragma data_seg("INIT")
#endif

//
//  Local examples
//
WCHAR   CmDefaultLanguageId[ 12 ] = { 0 };
ULONG   CmDefaultLanguageIdLength = sizeof( CmDefaultLanguageId );
ULONG   CmDefaultLanguageIdType = REG_NONE;

WCHAR   CmInstallUILanguageId[ 12 ] = { 0 };
ULONG   CmInstallUILanguageIdLength = sizeof( CmInstallUILanguageId );
ULONG   CmInstallUILanguageIdType = REG_NONE;
//
// suite data
//
WCHAR   CmSuiteBuffer[128] = {0};
ULONG   CmSuiteBufferLength = sizeof(CmSuiteBuffer);
ULONG   CmSuiteBufferType = REG_NONE;

//
// Verify driver list data
//
extern LONG    CmRegistryLogSizeLimit;
extern WCHAR   MmVerifyDriverBuffer[];
extern ULONG   MmVerifyDriverBufferLength;
extern ULONG   MmVerifyDriverBufferType;
extern ULONG   MmVerifyDriverLevel;
extern LOGICAL MmDontVerifyRandomDrivers;

extern ULONG IopAutoReboot;
extern ULONG ObpProtectionMode;
extern ULONG ObpAuditBaseDirectories;
extern ULONG ObpAuditBaseObjects;
extern ACCESS_MASK SepProcessAccessesToAudit;
extern ULONG CmNtGlobalFlag;
extern SIZE_T MmAllocationFragment;
extern SIZE_T MmSizeOfPagedPoolInBytes;
extern SIZE_T MmSizeOfNonPagedPoolInBytes;
extern ULONG MmMaximumNonPagedPoolPercent;
extern ULONG MmLargeSystemCache;
#if defined (_X86_)
extern ULONG MmLargeStackSize;
#endif
extern ULONG MmAllocationPreference;
extern ULONG MmNumberOfSystemPtes;
extern ULONG MmLowMemoryThreshold;
extern ULONG MmHighMemoryThreshold;
extern ULONG MmConsumedPoolPercentage;
extern ULONG MmSecondaryColors;
extern ULONG MmDisablePagingExecutive;
extern ULONG MmModifiedPageLifeInSeconds;
extern LOGICAL MmSpecialPoolCatchOverruns;
#if 0
extern ULONG MmCompressionThresholdRatio;
#endif
extern ULONG MmSpecialPoolTag;
extern ULONG MmDynamicPfn;
extern ULONG MmMirroring;
extern SIZE_T MmSystemViewSize;
extern SIZE_T MmSessionViewSize;
extern SIZE_T MmSessionPoolSize;
extern SIZE_T MmSessionImageSize;
extern ULONG MmEnforceWriteProtection;
extern ULONG MmLargePageMinimum;
extern LOGICAL MmSnapUnloads;
extern LOGICAL MmTrackLockedPages;
extern LOGICAL MmMakeLowMemory;
extern LOGICAL MmProtectFreedNonPagedPool;
extern ULONG MmTrackPtes;
extern ULONG CmRegistrySizeLimit;
extern ULONG CmRegistrySizeLimitLength;
extern ULONG CmRegistrySizeLimitType;
extern ULONG PspDefaultPagedLimit;
extern ULONG PspDefaultNonPagedLimit;
extern ULONG PspDefaultPagefileLimit;
extern ULONG ExResourceTimeoutCount;
extern ULONG MmCritsectTimeoutSeconds;
extern SIZE_T MmHeapSegmentReserve;
extern SIZE_T MmHeapSegmentCommit;
extern SIZE_T MmHeapDeCommitTotalFreeThreshold;
extern SIZE_T MmHeapDeCommitFreeBlockThreshold;
extern ULONG ExpAdditionalCriticalWorkerThreads;
extern ULONG ExpAdditionalDelayedWorkerThreads;
extern ULONG MmProductType;
extern ULONG CmBrand;
extern ULONG ExpHydraEnabled;
extern ULONG ExpMultiUserTS;
extern LOGICAL IoCountOperations;
extern ULONG IopLargeIrpStackLocations;
extern ULONG IovpVerifierLevel;
extern ULONG MmZeroPageFile;
extern ULONG ExpNtExpirationData[3];
extern ULONG ExpNtExpirationDataLength;
extern ULONG ExpMaxTimeSeperationBeforeCorrect;
extern ULONG PopSimulate;
extern ULONG PopIdleDefaultMinThrottle;
extern ULONG PopIdleThrottleCheckRate;
extern ULONG PopIdleThrottleCheckTimeout;
extern ULONG PopIdleFrom0Delay;
extern ULONG PopIdleFrom0IdlePercent;
extern ULONG PopIdle0TimeCheck;
extern ULONG PopIdleTimeCheck;
extern ULONG PopIdleTo0Percent;
extern ULONG PopIdleDefaultDemotePercent;
extern ULONG PopIdleDefaultDemoteTime;
extern ULONG PopIdleDefaultPromotePercent;
extern ULONG PopIdleDefaultPromoteTime;
extern ULONG PopPerfTimeDelta;
extern ULONG PopPerfCriticalTimeDelta;
extern ULONG PopPerfCriticalFrequencyDelta;
extern ULONG PopPerfIncreasePercentModifier;
extern ULONG PopPerfIncreaseAbsoluteModifier;
extern ULONG PopPerfDecreasePercentModifier;
extern ULONG PopPerfDecreaseAbsoluteModifier;
extern ULONG PopPerfIncreaseTimeValue;
extern ULONG PopPerfIncreaseMinimumTime;
extern ULONG PopPerfDecreaseTimeValue;
extern ULONG PopPerfDecreaseMinimumTime;
extern ULONG PopPerfDegradeThrottleMinCapacity;
extern ULONG PopPerfDegradeThrottleMinFrequency;
extern ULONG PopPerfMaxC3Frequency;
extern ULONG KiEnableTimerWatchdog;
extern ULONG ObpTraceNoDeregister;
extern WCHAR ObpTracePoolTagsBuffer[];
extern ULONG ObpTracePoolTagsLength;
extern ULONG ObpCaseInsensitive;
extern ULONG ViSearchedNodesLimitFromRegistry;
extern ULONG ViRecursionDepthLimitFromRegistry;
extern ULONG MmMinimumStackCommitInBytes;
extern ULONG ObpLUIDDeviceMapsDisabled;

#if defined(_AMD64_) || defined(_IA64_)
extern ULONG KiEnableAlignmentFaultExceptions;
#endif

extern ULONG KiMaximumDpcQueueDepth;
extern ULONG KiMinimumDpcRate;
extern ULONG KiAdjustDpcThreshold;
extern ULONG KiIdealDpcRate;
extern LARGE_INTEGER ExpLastShutDown;
ULONG shutdownlength = 0;

#if defined (_X86_)
extern ULONG KiFastSystemCallDisable;
extern ULONG KeVerifyNumaPageShift;
extern ULONG KeVerifyNumaPageMask;
extern ULONG KeVerifyNumaAffinityShift;
extern ULONG KeVerifyNumaAffinity;
extern ULONG KeVerifyNumaNodeCount;
#endif

#if defined(_IA64_)
extern ULONG KiExceptionDeferralMode;
#endif

//Debugger Retries
extern KD_CONTEXT KdpContext;

//
// WMI Control Variables
extern ULONG WmipMaxKmWnodeEventSize;
#if defined (_IA64_)
extern ULONG WmipDisableMCAPopups;
#endif
extern ULONG WmiTraceAlignment;

// Initial user-mode process to start and arguments.
extern WCHAR NtInitialUserProcessBuffer[];
extern ULONG NtInitialUserProcessBufferLength;
extern ULONG NtInitialUserProcessBufferType;

//
// CmpUlongPtrLength is used for registry values that are 4-byte on 32-bit
// machines and can be 64-bit on 64-bit machines.
//
ULONG CmpUlongPtrLength = sizeof (ULONG_PTR);

//
//  Vector - see ntos\inc\cm.h for definition
//
CM_SYSTEM_CONTROL_VECTOR   CmControlVector[] = {

    { L"Session Manager",
      L"ProtectionMode",
      &ObpProtectionMode,
      NULL,
      NULL
    },


    { L"Session Manager",
      L"LUIDDeviceMapsDisabled",
      &ObpLUIDDeviceMapsDisabled,
      NULL,
      NULL
    },


    { L"LSA",
      L"AuditBaseDirectories",
      &ObpAuditBaseDirectories,
      NULL,
      NULL
    },


    { L"LSA",
      L"AuditBaseObjects",
      &ObpAuditBaseObjects,
      NULL,
      NULL
    },


    { L"LSA\\audit",
      L"ProcessAccessesToAudit",
      &SepProcessAccessesToAudit,
      NULL,
      NULL
    },


    { L"TimeZoneInformation",
      L"ActiveTimeBias",
      &ExpLastTimeZoneBias,
      NULL,
      NULL
    },


    { L"TimeZoneInformation",
      L"Bias",
      &ExpAltTimeZoneBias,
      NULL,
      NULL
    },

    { L"TimeZoneInformation",
      L"RealTimeIsUniversal",
      &ExpRealTimeIsUniversal,
      NULL,
      NULL
    },

    { L"Session Manager",
      L"GlobalFlag",
      &CmNtGlobalFlag,
      NULL,
      NULL
    },

    { L"Session Manager\\Memory Management",
      L"DontVerifyRandomDrivers",
      &MmDontVerifyRandomDrivers,
      NULL,
      NULL
    },

    { L"Session Manager\\Memory Management",
      L"PagedPoolQuota",
      &PspDefaultPagedLimit,
      NULL,
      NULL
    },

    { L"Session Manager\\Memory Management",
      L"NonPagedPoolQuota",
      &PspDefaultNonPagedLimit,
      NULL,
      NULL
    },

    { L"Session Manager\\Memory Management",
      L"PagingFileQuota",
      &PspDefaultPagefileLimit,
      NULL,
      NULL
    },

    { L"Session Manager\\Memory Management",
      L"AllocationPreference",
      &MmAllocationPreference,
      NULL,
      NULL
    },

    { L"Session Manager\\Memory Management",
      L"DynamicMemory",
      &MmDynamicPfn,
      NULL,
      NULL
    },

    { L"Session Manager\\Memory Management",
      L"Mirroring",
      &MmMirroring,
      NULL,
      NULL
    },

    { L"Session Manager\\Memory Management",
      L"SystemViewSize",
      &MmSystemViewSize,
      NULL,
      NULL
    },

    { L"Session Manager\\Memory Management",
      L"SessionViewSize",
      &MmSessionViewSize,
      NULL,
      NULL
    },

    { L"Session Manager\\Memory Management",
      L"SessionImageSize",
      &MmSessionImageSize,
      NULL,
      NULL
    },

    { L"Session Manager\\Memory Management",
      L"SessionPoolSize",
      &MmSessionPoolSize,
      NULL,
      NULL
    },

#if 0
    { L"Session Manager\\Memory Management",
      L"CompressionThresholdPercentage",
      &MmCompressionThresholdRatio,
      NULL,
      NULL
    },
#endif

    { L"Session Manager\\Memory Management",
      L"PoolUsageMaximum",
      &MmConsumedPoolPercentage,
      NULL,
      NULL
    },

    { L"Session Manager\\Memory Management",
      L"MapAllocationFragment",
      &MmAllocationFragment,
      NULL,
      NULL
    },

    { L"Session Manager\\Memory Management",
      L"PagedPoolSize",
      &MmSizeOfPagedPoolInBytes,
      &CmpUlongPtrLength,
      NULL
    },

    { L"Session Manager\\Memory Management",
      L"NonPagedPoolSize",
      &MmSizeOfNonPagedPoolInBytes,
      &CmpUlongPtrLength,
      NULL
    },

    { L"Session Manager\\Memory Management",
      L"NonPagedPoolMaximumPercent",
      &MmMaximumNonPagedPoolPercent,
      NULL,
      NULL
    },

    { L"Session Manager\\Memory Management",
      L"LargeSystemCache",
      &MmLargeSystemCache,
      NULL,
      NULL
    },

#if defined (_X86_)
    { L"Session Manager\\Memory Management",
      L"LargeStackSize",
      &MmLargeStackSize,
      NULL,
      NULL
    },
#endif

    { L"Session Manager\\Memory Management",
      L"SystemPages",
      &MmNumberOfSystemPtes,
      NULL,
      NULL
    },

    { L"Session Manager\\Memory Management",
      L"LowMemoryThreshold",
      &MmLowMemoryThreshold,
      NULL,
      NULL
    },

    { L"Session Manager\\Memory Management",
      L"HighMemoryThreshold",
      &MmHighMemoryThreshold,
      NULL,
      NULL
    },

    { L"Session Manager\\Memory Management",
      L"DisablePagingExecutive",
      &MmDisablePagingExecutive,
      NULL,
      NULL
    },

    { L"Session Manager\\Memory Management",
      L"ModifiedPageLife",
      &MmModifiedPageLifeInSeconds,
      NULL,
      NULL
    },

    { L"Session Manager\\Memory Management",
      L"SecondLevelDataCache",
      &MmSecondaryColors,
      NULL,
      NULL
    },

    { L"Session Manager\\Memory Management",
      L"ClearPageFileAtShutdown",
      &MmZeroPageFile,
      NULL,
      NULL
    },

    { L"Session Manager\\Memory Management",
      L"PoolTag",
      &MmSpecialPoolTag,
      NULL,
      NULL
    },

    { L"Session Manager\\Memory Management",
      L"PoolTagOverruns",
      &MmSpecialPoolCatchOverruns,
      NULL,
      NULL
    },

    { L"Session Manager\\Memory Management",
      L"SnapUnloads",
      &MmSnapUnloads,
      NULL,
      NULL
    },

    { L"Session Manager\\Memory Management",
      L"ProtectNonPagedPool",
      &MmProtectFreedNonPagedPool,
      NULL,
      NULL
    },


    { L"Session Manager\\Memory Management",
      L"TrackLockedPages",
      &MmTrackLockedPages,
      NULL,
      NULL
    },

    { L"Session Manager\\Memory Management",
      L"TrackPtes",
      &MmTrackPtes,
      NULL,
      NULL
    },

    { L"Session Manager\\Memory Management",
      L"VerifyDrivers",
      MmVerifyDriverBuffer,
      &MmVerifyDriverBufferLength,
      &MmVerifyDriverBufferType
    },

    { L"Session Manager\\Memory Management",
      L"VerifyDriverLevel",
      &MmVerifyDriverLevel,
      NULL,
      NULL
    },

    { L"Session Manager\\Memory Management",
      L"LargePageMinimum",
      &MmLargePageMinimum,
      NULL,
      NULL
    },

    { L"Session Manager\\Memory Management",
      L"EnforceWriteProtection",
      &MmEnforceWriteProtection,
      NULL,
      NULL
    },

    { L"Session Manager\\Memory Management",
      L"MakeLowMemory",
      &MmMakeLowMemory,
      NULL,
      NULL
    },

    { L"Session Manager\\Memory Management",
      L"DeadlockRecursionDepthLimit",
      &ViRecursionDepthLimitFromRegistry,
      NULL,
      NULL
    },

    { L"Session Manager\\Memory Management",
      L"DeadlockSearchNodesLimit",
      &ViSearchedNodesLimitFromRegistry,
      NULL,
      NULL
    },

    { L"Session Manager\\Memory Management",
      L"MinimumStackCommitInBytes",
      &MmMinimumStackCommitInBytes,
      NULL,
      NULL
    },

    { L"Session Manager\\Executive",
      L"AdditionalCriticalWorkerThreads",
      &ExpAdditionalCriticalWorkerThreads,
      NULL,
      NULL
    },


    { L"Session Manager\\Executive",
      L"AdditionalDelayedWorkerThreads",
      &ExpAdditionalDelayedWorkerThreads,
      NULL,
      NULL
    },

    { L"Session Manager\\Executive",
      L"PriorityQuantumMatrix",
      &ExpNtExpirationData,
      &ExpNtExpirationDataLength,
      NULL
    },

    { L"Session Manager\\Kernel",
      L"DpcQueueDepth",
      &KiMaximumDpcQueueDepth,
      NULL,
      NULL
    },

    { L"Session Manager\\Kernel",
      L"MinimumDpcRate",
      &KiMinimumDpcRate,
      NULL,
      NULL
    },

    { L"Session Manager\\Kernel",
      L"AdjustDpcThreshold",
      &KiAdjustDpcThreshold,
      NULL,
      NULL
    },

#if defined(_IA64_)

    { L"Session Manager\\Kernel",
      L"ExceptionDeferralMode",
      &KiExceptionDeferralMode,
      NULL,
      NULL
    },

#endif

    { L"Session Manager\\Kernel",
      L"IdealDpcRate",
      &KiIdealDpcRate,
      NULL,
      NULL
    },

#if defined(_X86_)

    { L"Session Manager\\Kernel",
      L"FastSystemCallDisable",
      &KiFastSystemCallDisable,
      NULL,
      NULL
    },

#endif

    { L"Session Manager\\Kernel",
      L"ObTracePoolTags",
      &ObpTracePoolTagsBuffer,
      &ObpTracePoolTagsLength,
      NULL
    },

    { L"Session Manager\\Kernel",
      L"ObTraceNoDeregister",
      &ObpTraceNoDeregister,
      NULL,
      NULL
    },

    { L"Session Manager\\Kernel",
      L"PoCleanShutdownFlags",
      &PopShutdownCleanly,
      NULL,
      NULL
    },

    { L"Session Manager\\Power",
      L"IdleDefaultMinThrottle",
      &PopIdleDefaultMinThrottle,
      NULL,
      NULL
    },

    { L"Session Manager\\Power",
      L"IdleThrottleCheckRate",
      &PopIdleThrottleCheckRate,
      NULL,
      NULL
    },

    { L"Session Manager\\Power",
      L"IdleThrottleCheckTimeout",
      &PopIdleThrottleCheckTimeout,
      NULL,
      NULL
    },

    { L"Session Manager\\Power",
      L"IdleFrom0Delay",
      &PopIdleFrom0Delay,
      NULL,
      NULL
    },

    { L"Session Manager\\Power",
      L"IdleFrom0IdlePercent",
      &PopIdleFrom0IdlePercent,
      NULL,
      NULL
    },

    { L"Session Manager\\Power",
      L"Idle0TimeCheck",
      &PopIdle0TimeCheck,
      NULL,
      NULL
    },

    { L"Session Manager\\Power",
      L"IdleTimeCheck",
      &PopIdleTimeCheck,
      NULL,
      NULL
    },

    { L"Session Manager\\Power",
      L"IdleTo0Percent",
      &PopIdleTo0Percent,
      NULL,
      NULL
    },

    { L"Session Manager\\Power",
      L"IdleDefaultDemotePercent",
      &PopIdleDefaultDemotePercent,
      NULL,
      NULL
    },

    { L"Session Manager\\Power",
      L"IdleDefaultDemoteTime",
      &PopIdleDefaultDemoteTime,
      NULL,
      NULL
    },

    { L"Session Manager\\Power",
      L"IdleDefaultPromotePercent",
      &PopIdleDefaultPromotePercent,
      NULL,
      NULL
    },

    { L"Session Manager\\Power",
      L"IdleDefaultPromoteTime",
      &PopIdleDefaultPromoteTime,
      NULL,
      NULL
    },

    { L"Session Manager\\Throttle",
      L"PerfTimeDelta",
      &PopPerfTimeDelta,
      NULL,
      NULL
    },

    { L"Session Manager\\Throttle",
      L"PerfCriticalTimeDelta",
      &PopPerfCriticalTimeDelta,
      NULL,
      NULL
    },

    { L"Session Manager\\Throttle",
      L"PerfCriticalFrequencyDelta",
      &PopPerfCriticalFrequencyDelta,
      NULL,
      NULL
    },

    { L"Session Manager\\Throttle",
      L"PerfIncreasePercentModifier",
      &PopPerfIncreasePercentModifier,
      NULL,
      NULL
    },

    { L"Session Manager\\Throttle",
      L"PerfIncreaseAbsoluteModifier",
      &PopPerfIncreaseAbsoluteModifier,
      NULL,
      NULL
    },

    { L"Session Manager\\Throttle",
      L"PerfDecreasePercentModifier",
      &PopPerfDecreasePercentModifier,
      NULL,
      NULL
    },

    { L"Session Manager\\Throttle",
      L"PerfDecreaseAbsoluteModifier",
      &PopPerfIncreaseAbsoluteModifier,
      NULL,
      NULL
    },

    { L"Session Manager\\Throttle",
      L"PerfIncreaseTimeValue",
      &PopPerfIncreaseTimeValue,
      NULL,
      NULL
    },

    { L"Session Manager\\Throttle",
      L"PerfIncreaseMinimumTime",
      &PopPerfIncreaseMinimumTime,
      NULL,
      NULL
    },

    { L"Session Manager\\Throttle",
      L"PerfDecreaseTimeValue",
      &PopPerfDecreaseTimeValue,
      NULL,
      NULL
    },

    { L"Session Manager\\Throttle",
      L"PerfDecreaseMinimumTime",
      &PopPerfDecreaseMinimumTime,
      NULL,
      NULL
    },

    { L"Session Manager\\Throttle",
      L"PerfDegradeThrottleMinCapacity",
      &PopPerfDegradeThrottleMinCapacity,
      NULL,
      NULL
    },

    { L"Session Manager\\Throttle",
      L"PerfDegradeThrottleMinFrequency",
      &PopPerfDegradeThrottleMinFrequency,
      NULL,
      NULL
    },

    { L"Session Manager\\Throttle",
      L"PerfMaxC3Frequency",
      &PopPerfMaxC3Frequency,
      NULL,
      NULL
    },

    { L"Session Manager\\Kernel",
      L"ObCaseInsensitive",
      &ObpCaseInsensitive,
      NULL,
      NULL
    },

    { L"Session Manager\\I/O System",
      L"CountOperations",
      &IoCountOperations,
      NULL,
      NULL
    },

    { L"Session Manager\\I/O System",
      L"LargeIrpStackLocations",
      &IopLargeIrpStackLocations,
      NULL,
      NULL
    },

    { L"Session Manager\\I/O System",
      L"IoVerifierLevel",
      &IovpVerifierLevel,
      NULL,
      NULL
    },

    { L"Session Manager",
      L"ResourceTimeoutCount",
      &ExResourceTimeoutCount,
      NULL,
      NULL
    },

    { L"Session Manager",
      L"CriticalSectionTimeout",
      &MmCritsectTimeoutSeconds,
      NULL,
      NULL
    },

    { L"Session Manager",
      L"HeapSegmentReserve",
      &MmHeapSegmentReserve,
      NULL,
      NULL
    },

    { L"Session Manager",
      L"HeapSegmentCommit",
      &MmHeapSegmentCommit,
      NULL,
      NULL
    },

    { L"Session Manager",
      L"HeapDeCommitTotalFreeThreshold",
      &MmHeapDeCommitTotalFreeThreshold,
      NULL,
      NULL
    },

    { L"Session Manager",
      L"HeapDeCommitFreeBlockThreshold",
      &MmHeapDeCommitFreeBlockThreshold,
      NULL,
      NULL
    },

#if defined(_AMD64_) || defined(_IA64_)

    { L"Session Manager",
      L"EnableAlignmentFaultExceptions",
      &KiEnableAlignmentFaultExceptions,
      NULL,
      NULL
    },

#endif

    { L"ProductOptions",
      L"ProductType",
      &MmProductType,
      NULL,
      NULL
    },
    
    { L"ProductOptions",
      L"Brand",
      &CmBrand,
      NULL,
      NULL
    },

    { L"Terminal Server",
      L"TSEnabled",
      &ExpHydraEnabled,
      NULL,
      NULL
    },

    { L"Terminal Server",
      L"TSAppCompat",
      &ExpMultiUserTS,
      NULL,
      NULL
    },

    { L"ProductOptions",
      L"ProductSuite",
      CmSuiteBuffer,
      &CmSuiteBufferLength,
      &CmSuiteBufferType
    },

    { L"Windows",
      L"CSDVersion",
      &CmNtCSDVersion,
      NULL,
      NULL
    },

    { L"Windows",
      L"CSDReleaseType",
      &CmNtCSDReleaseType,
      NULL,
      NULL
    },

    { L"Nls\\Language",
      L"Default",
      CmDefaultLanguageId,
      &CmDefaultLanguageIdLength,
      &CmDefaultLanguageIdType
    },

    { L"Nls\\Language",
      L"InstallLanguage",
      CmInstallUILanguageId,
      &CmInstallUILanguageIdLength,
      &CmInstallUILanguageIdType
    },

    { L"\0\0",
      L"RegistrySizeLimit",
      &CmRegistrySizeLimit,
      &CmRegistrySizeLimitLength,
      &CmRegistrySizeLimitType
    },

    { L"Session Manager\\Configuration Manager",
      L"RegistryLogSizeLimit",
      &CmRegistryLogSizeLimit,
      NULL,
      NULL
    },

#if defined (_X86_)
    //
    // The following are used for testing NUMA configurations on
    // non-NUMA machines.
    //

    { L"Session Manager\\Memory Management\\FakeNuma",
      L"NodeCount",
      &KeVerifyNumaNodeCount,
      NULL,
      NULL
    },

    { L"Session Manager\\Memory Management\\FakeNuma",
      L"Affinity",
      &KeVerifyNumaAffinity,
      NULL,
      NULL
    },

    { L"Session Manager\\Memory Management\\FakeNuma",
      L"AffinityShift",
      &KeVerifyNumaAffinityShift,
      NULL,
      NULL
    },

    { L"Session Manager\\Memory Management\\FakeNuma",
      L"PageMask",
      &KeVerifyNumaPageMask,
      NULL,
      NULL
    },

    { L"Session Manager\\Memory Management\\FakeNuma",
      L"PageShift",
      &KeVerifyNumaPageShift,
      NULL,
      NULL
    },

#endif

#if !defined(NT_UP)
    { L"Session Manager",
      L"RegisteredProcessors",
      &KeRegisteredProcessors,
      NULL,
      NULL
    },
    { L"Session Manager",
      L"LicensedProcessors",
      &KeLicensedProcessors,
      NULL,
      NULL
    },
#endif

    { L"Session Manager",
      L"PowerPolicySimulate",
      &PopSimulate,
      NULL,
      NULL
    },

    { L"Session Manager\\Executive",
      L"MaxTimeSeparationBeforeCorrect",
      &ExpMaxTimeSeperationBeforeCorrect,
      NULL,
      NULL
    },

    { L"Windows",
      L"ShutdownTime",
      &ExpLastShutDown,
      &shutdownlength,
      NULL
    },

    { L"PriorityControl",
      L"Win32PrioritySeparation",
      &PsRawPrioritySeparation,
      NULL,
      NULL
    },

#if defined(_X86_)
    { L"Session Manager",
      L"EnableTimerWatchdog",
      &KiEnableTimerWatchdog,
      NULL,
      NULL
    },
#endif

    { L"Session Manager",
      L"Debugger Retries",
      &KdpContext.KdpDefaultRetries,
      NULL,
      NULL
    },

    { L"Session Manager\\Debug Print Filter",
      L"WIN2000",
      &Kd_WIN2000_Mask,
      NULL,
      NULL
    },

#include "dpfiltercm.c"

    { L"WMI",
      L"MaxEventSize",
      &WmipMaxKmWnodeEventSize,
      NULL,
      NULL
    },

#if defined(_IA64_)
    { L"WMI",
      L"DisableMCAPopups",
      &WmipDisableMCAPopups,
      NULL,
      NULL
    },
#endif

    { L"WMI\\Trace",
      L"UsePerformanceClock",
      &WmiUsePerfClock,
      NULL,
      NULL
    },

    { L"WMI\\Trace",
      L"TraceAlignment",
      &WmiTraceAlignment,
      NULL,
      NULL
    },

    { L"Session Manager",
      L"Initial Process",
      NtInitialUserProcessBuffer,
      &NtInitialUserProcessBufferLength,
      &NtInitialUserProcessBufferType
    },

    { L"EmbeddedNT\\Executive",
      L"KernelOnlyConfiguration",
      &PsEmbeddedNTMask,
      NULL,
      NULL
    },

    { L"CrashControl",
      L"AutoReboot",
      &IopAutoReboot,
      NULL,
      NULL
    },

    { NULL, NULL, NULL, NULL, NULL }    // end marker
    };

#ifdef ALLOC_DATA_PRAGMA
#pragma  data_seg()
#endif
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\base\ntos\config\cmdatini.c ===
/*++

Copyright (c) 1990, 1991  Microsoft Corporation


Module Name:

   cmdatini.c

Abstract:

   contains code to init static STRING structures for registry name space.

Author:

    Andre Vachon (andreva) 08-Apr-1992


Environment:

    Kernel mode.

Revision History:

--*/

#include "cmp.h"

#ifdef ALLOC_PRAGMA
#pragma alloc_text(INIT,CmpInitializeRegistryNames)
#endif

extern UNICODE_STRING CmRegistryRootName;
extern UNICODE_STRING CmRegistryMachineName;
extern UNICODE_STRING CmRegistryMachineHardwareName;
extern UNICODE_STRING CmRegistryMachineHardwareDescriptionName;
extern UNICODE_STRING CmRegistryMachineHardwareDescriptionSystemName;
extern UNICODE_STRING CmRegistryMachineHardwareDeviceMapName;
extern UNICODE_STRING CmRegistryMachineHardwareResourceMapName;
extern UNICODE_STRING CmRegistryMachineHardwareOwnerMapName;
extern UNICODE_STRING CmRegistryMachineSystemName;
extern UNICODE_STRING CmRegistryMachineSystemCurrentControlSet;
extern UNICODE_STRING CmRegistryUserName;
extern UNICODE_STRING CmRegistrySystemCloneName;
extern UNICODE_STRING CmpSystemFileName;
extern UNICODE_STRING CmRegistryMachineSystemCurrentControlSetEnumName;
extern UNICODE_STRING CmRegistryMachineSystemCurrentControlSetEnumRootName;
extern UNICODE_STRING CmRegistryMachineSystemCurrentControlSetServices;
extern UNICODE_STRING CmRegistryMachineSystemCurrentControlSetHardwareProfilesCurrent;
extern UNICODE_STRING CmRegistryMachineSystemCurrentControlSetControlClass;
extern UNICODE_STRING CmSymbolicLinkValueName;

#ifdef _WANT_MACHINE_IDENTIFICATION
extern UNICODE_STRING CmRegistryMachineSystemCurrentControlSetControlBiosInfo;
#endif

extern const PWCHAR CmpRegistryRootString;
extern const PWCHAR CmpRegistryMachineString;
extern const PWCHAR CmpRegistryMachineHardwareString;
extern const PWCHAR CmpRegistryMachineHardwareDescriptionString;
extern const PWCHAR CmpRegistryMachineHardwareDescriptionSystemString;
extern const PWCHAR CmpRegistryMachineHardwareDeviceMapString;
extern const PWCHAR CmpRegistryMachineHardwareResourceMapString;
extern const PWCHAR CmpRegistryMachineHardwareOwnerMapString;
extern const PWCHAR CmpRegistryMachineSystemString;
extern const PWCHAR CmpRegistryMachineSystemCurrentControlSetString;
extern const PWCHAR CmpRegistryUserString;
extern const PWCHAR CmpRegistrySystemCloneString;
extern const PWCHAR CmpRegistrySystemFileNameString;
extern const PWCHAR CmpRegistryMachineSystemCurrentControlSetEnumString;
extern const PWCHAR CmpRegistryMachineSystemCurrentControlSetEnumRootString;
extern const PWCHAR CmpRegistryMachineSystemCurrentControlSetServicesString;
extern const PWCHAR CmpRegistryMachineSystemCurrentControlSetHardwareProfilesCurrentString;
extern const PWCHAR CmpRegistryMachineSystemCurrentControlSetControlClassString;
extern const PWCHAR CmpRegistryMachineSystemCurrentControlSetControlSafeBootString;
extern const PWCHAR CmpRegistryMachineSystemCurrentControlSetControlSessionManagerMemoryManagementString;

extern const PWCHAR CmpRegistryMachineSystemCurrentControlSetControlBootLogString;
extern const PWCHAR CmpRegistryMachineSystemCurrentControlSetServicesEventLogString;
extern const PWCHAR CmpSymbolicLinkValueName;

#ifdef _WANT_MACHINE_IDENTIFICATION
extern const PWCHAR CmpRegistryMachineSystemCurrentControlSetControlBiosInfoString;
#endif



VOID
CmpInitializeRegistryNames(
VOID
)

/*++

Routine Description:

    This routine creates all the Unicode strings for the various names used
    in and by the registry

Arguments:

    None.

Returns:

    None.

--*/
{
    ULONG i;

    RtlInitUnicodeString( &CmRegistryRootName,
                          CmpRegistryRootString );

    RtlInitUnicodeString( &CmRegistryMachineName,
                          CmpRegistryMachineString );

    RtlInitUnicodeString( &CmRegistryMachineHardwareName,
                          CmpRegistryMachineHardwareString );

    RtlInitUnicodeString( &CmRegistryMachineHardwareDescriptionName,
                          CmpRegistryMachineHardwareDescriptionString );

    RtlInitUnicodeString( &CmRegistryMachineHardwareDescriptionSystemName,
                          CmpRegistryMachineHardwareDescriptionSystemString );

    RtlInitUnicodeString( &CmRegistryMachineHardwareDeviceMapName,
                          CmpRegistryMachineHardwareDeviceMapString );

    RtlInitUnicodeString( &CmRegistryMachineHardwareResourceMapName,
                          CmpRegistryMachineHardwareResourceMapString );

    RtlInitUnicodeString( &CmRegistryMachineHardwareOwnerMapName,
                          CmpRegistryMachineHardwareOwnerMapString );

    RtlInitUnicodeString( &CmRegistryMachineSystemName,
                          CmpRegistryMachineSystemString );

    RtlInitUnicodeString( &CmRegistryMachineSystemCurrentControlSet,
                          CmpRegistryMachineSystemCurrentControlSetString);

    RtlInitUnicodeString( &CmRegistryUserName,
                          CmpRegistryUserString );

    RtlInitUnicodeString( &CmRegistrySystemCloneName,
                          CmpRegistrySystemCloneString );

    RtlInitUnicodeString( &CmpSystemFileName,
                          CmpRegistrySystemFileNameString );

    RtlInitUnicodeString( &CmRegistryMachineSystemCurrentControlSetEnumName,
                          CmpRegistryMachineSystemCurrentControlSetEnumString);

    RtlInitUnicodeString( &CmRegistryMachineSystemCurrentControlSetEnumRootName,
                          CmpRegistryMachineSystemCurrentControlSetEnumRootString);

    RtlInitUnicodeString( &CmRegistryMachineSystemCurrentControlSetServices,
                          CmpRegistryMachineSystemCurrentControlSetServicesString);

    RtlInitUnicodeString( &CmRegistryMachineSystemCurrentControlSetHardwareProfilesCurrent,
                          CmpRegistryMachineSystemCurrentControlSetHardwareProfilesCurrentString);

    RtlInitUnicodeString( &CmRegistryMachineSystemCurrentControlSetControlClass,
                          CmpRegistryMachineSystemCurrentControlSetControlClassString);

    RtlInitUnicodeString( &CmRegistryMachineSystemCurrentControlSetControlSafeBoot,
                          CmpRegistryMachineSystemCurrentControlSetControlSafeBootString);

    RtlInitUnicodeString( &CmRegistryMachineSystemCurrentControlSetControlSessionManagerMemoryManagement,
                          CmpRegistryMachineSystemCurrentControlSetControlSessionManagerMemoryManagementString);

    RtlInitUnicodeString( &CmRegistryMachineSystemCurrentControlSetControlBootLog,
                          CmpRegistryMachineSystemCurrentControlSetControlBootLogString);

    RtlInitUnicodeString( &CmRegistryMachineSystemCurrentControlSetServicesEventLog,
                          CmpRegistryMachineSystemCurrentControlSetServicesEventLogString);

    RtlInitUnicodeString( &CmSymbolicLinkValueName,
                          CmpSymbolicLinkValueName);

#ifdef _WANT_MACHINE_IDENTIFICATION
    RtlInitUnicodeString( &CmRegistryMachineSystemCurrentControlSetControlBiosInfo,
                          CmpRegistryMachineSystemCurrentControlSetControlBiosInfoString);
#endif

    //
    // Initialize the type names for the hardware tree.
    //

    for (i = 0; i <= MaximumType; i++) {

        RtlInitUnicodeString( &(CmTypeName[i]),
                              CmTypeString[i] );

    }

    //
    // Initialize the class names for the hardware tree.
    //

    for (i = 0; i <= MaximumClass; i++) {

        RtlInitUnicodeString( &(CmClassName[i]),
                              CmClassString[i] );

    }

    return;
}
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\base\ntos\config\cmdelete.c ===
/*++

Copyright (c) 1991  Microsoft Corporation

Module Name:

    cmdelete.c

Abstract:

    This module contains the delete object method (used to delete key
    control blocks  when last handle to a key is closed, and to delete
    keys marked for deletetion when last reference to them goes away.)

Author:

    Bryan M. Willman (bryanwi) 13-Nov-91

Revision History:

--*/

#include    "cmp.h"

extern  BOOLEAN HvShutdownComplete;

#ifdef NT_UNLOAD_KEY_EX
VOID
CmpLateUnloadHiveWorker(
    IN PVOID Hive
    );
#endif //NT_UNLOAD_KEY_EX

#ifdef ALLOC_PRAGMA
#pragma alloc_text(PAGE,CmpDeleteKeyObject)

#ifdef NT_UNLOAD_KEY_EX
#pragma alloc_text(PAGE,CmpLateUnloadHiveWorker)
#endif //NT_UNLOAD_KEY_EX

#endif


VOID
CmpDeleteKeyObject(
    IN  PVOID   Object
    )
/*++

Routine Description:

    This routine interfaces to the NT Object Manager.  It is invoked when
    the last reference to a particular Key object (or Key Root object)
    is destroyed.

    If the Key object going away holds the last reference to
    the extension it is associated with, that extension is destroyed.

Arguments:

    Object - supplies a pointer to a KeyRoot or Key, thus -> KEY_BODY.

Return Value:

    NONE.

--*/
{
    PCM_KEY_CONTROL_BLOCK   KeyControlBlock;
    PCM_KEY_BODY            KeyBody;
#ifdef NT_UNLOAD_KEY_EX
    PCMHIVE                 CmHive;
    BOOLEAN                 DoUnloadCheck;
#endif //NT_UNLOAD_KEY_EX

    PAGED_CODE();

    CmKdPrintEx((DPFLTR_CONFIG_ID,CML_FLOW,"CmpDeleteKeyObject: Object = %p\n", Object));

    //
    // HandleClose callback
    //
    if ( CmAreCallbacksRegistered() ) {
        REG_KEY_HANDLE_CLOSE_INFORMATION  KeyHandleCloseInfo;
       
        KeyHandleCloseInfo.Object = Object;

        CmpCallCallBacks(RegNtKeyHandleClose,&KeyHandleCloseInfo);
    }

    BEGIN_LOCK_CHECKPOINT;

    CmpLockRegistry();

#ifdef NT_UNLOAD_KEY_EX
    DoUnloadCheck = FALSE;
#endif //NT_UNLOAD_KEY_EX

    KeyBody = (PCM_KEY_BODY)Object;

    if (KeyBody->Type==KEY_BODY_TYPE) {
        KeyControlBlock = KeyBody->KeyControlBlock;

        //
        // the keybody should be initialized; when kcb is null, something went wrong
        // between the creation and the dereferenciation of the object
        //
        if( KeyControlBlock != NULL ) {
            //
            // Clean up any outstanding notifies attached to the KeyBody
            //
            CmpFlushNotify(KeyBody);

            //
            // Remove our reference to the KeyControlBlock, clean it up, perform any
            // pend-till-final-close operations.
            //
            // NOTE: Delete notification is seen at the parent of the deleted key,
            //       not the deleted key itself.  If any notify was outstanding on
            //       this key, it was cleared away above us.  Only parent/ancestor
            //       keys will see the report.
            //
            //
            // The dereference will free the KeyControlBlock.  If the key was deleted, it
            // has already been removed from the hash table, and relevent notifications
            // posted then as well.  All we are doing is freeing the tombstone.
            //
            // If it was not deleted, we're both cutting the kcb out of
            // the kcb list/tree, AND freeing its storage.
            //

            DELIST_KEYBODY_FROM_KEYBODY_LIST(KeyBody);

            //
            // change of plans. once locked, the kcb will be locked for as long as the machine is up&running
            //

/*
            BEGIN_KCB_LOCK_GUARD;                                                                   
            CmpLockKCBTreeExclusive();                                                              
            if(IsListEmpty(&(KeyBody->KeyControlBlock->KeyBodyListHead)) == TRUE) {
                //
                // remove the read-only flag on the kcb (if any); as last handle to this key was closed
                //
                KeyControlBlock->ExtFlags &= (~CM_KCB_READ_ONLY_KEY);
            }
            CmpUnlockKCBTree();                                                                     
            END_KCB_LOCK_GUARD
*/

#ifdef NT_UNLOAD_KEY_EX
            //
            // take aditional precaution in the case the hive has been unloaded and this is the root
            //
            if( !KeyControlBlock->Delete ) {
                CmHive = (PCMHIVE)CONTAINING_RECORD(KeyControlBlock->KeyHive, CMHIVE, Hive);
                if( IsHiveFrozen(CmHive) ) {
                    //
                    // unload is pending for this hive;
                    //
                    DoUnloadCheck = TRUE;

                }
            }
#endif //NT_UNLOAD_KEY_EX
            CmpDereferenceKeyControlBlock(KeyControlBlock);
        }
    } else {
        //
        // This must be a predefined handle
        //  some sanity asserts
        //
        KeyControlBlock = KeyBody->KeyControlBlock;

        ASSERT( KeyBody->Type&REG_PREDEF_HANDLE_MASK);
        ASSERT( KeyControlBlock->Flags&KEY_PREDEF_HANDLE );

        if( KeyControlBlock != NULL ) {
#ifdef NT_UNLOAD_KEY_EX
            CmHive = (PCMHIVE)CONTAINING_RECORD(KeyControlBlock->KeyHive, CMHIVE, Hive);
            if( IsHiveFrozen(CmHive) ) {
                //
                // unload is pending for this hive; we shouldn't put the kcb in the delay
                // close table
                //
                DoUnloadCheck = TRUE;

            }
#endif //NT_UNLOAD_KEY_EX
            CmpDereferenceKeyControlBlock(KeyControlBlock);
        }

    }

#ifdef NT_UNLOAD_KEY_EX
    //
    // if a handle inside a frozen hive has been closed, we may need to unload the hive
    //
    if( DoUnloadCheck == TRUE ) {
        ASSERT( CmHive->RootKcb != NULL );

        BEGIN_KCB_LOCK_GUARD;
        CmpLockKCBTree();
        CmLockHive(CmHive);

        if( (CmHive->RootKcb->RefCount == 1) && (CmHive->UnloadWorkItem == NULL) ) {
            //
            // the only reference on the rookcb is the one that we artificially created
            // queue a work item to late unload the hive
            //
            CmHive->UnloadWorkItem = ExAllocatePool(NonPagedPool, sizeof(WORK_QUEUE_ITEM));
            if (CmHive->UnloadWorkItem != NULL) {

                ExInitializeWorkItem(CmHive->UnloadWorkItem,
                                     CmpLateUnloadHiveWorker,
                                     CmHive);
                ExQueueWorkItem(CmHive->UnloadWorkItem, DelayedWorkQueue);
            }

        }

        CmUnlockHive(CmHive);
        CmpUnlockKCBTree();
        END_KCB_LOCK_GUARD;
    }
#endif //NT_UNLOAD_KEY_EX

    CmpUnlockRegistry();
    END_LOCK_CHECKPOINT;

    return;
}


#ifdef NT_UNLOAD_KEY_EX
VOID
CmpLateUnloadHiveWorker(
    IN PVOID Hive
    )
/*++

Routine Description:

    "Late" unloads the hive; If nothing goes badly wrong (i.e. insufficient resources),
    this function should succeed

Arguments:

    CmHive - the frozen hive to be unloaded

Return Value:

    NONE.

--*/
{
    NTSTATUS                Status;
    HCELL_INDEX             Cell;
    PCM_KEY_CONTROL_BLOCK   RootKcb;
    PCMHIVE                 CmHive;

    PAGED_CODE();

    //
    // first, load the registry exclusive
    //
    CmpLockRegistryExclusive();

#ifdef CHECK_REGISTRY_USECOUNT
    CmpCheckRegistryUseCount();
#endif //CHECK_REGISTRY_USECOUNT

    //
    // hive is the parameter to this worker; make sure we free the work item
    // allocated by CmpDeleteKeyObject
    //
    CmHive = (PCMHIVE)Hive;
    ASSERT( CmHive->UnloadWorkItem != NULL );
    ExFreePool( CmHive->UnloadWorkItem );

    //
    // if this attempt doesn't succeed, mark that we can try another
    //
    CmHive->UnloadWorkItem = NULL;

    //
    // this is just about the only possible way the hive can get corrupted in between
    //
    if( HvShutdownComplete == TRUE ) {
        // too late to do anything
        CmpUnlockRegistry();
        return;
    }

    //
    // hive should be frozen, otherwise we wouldn't get here
    //
    ASSERT( CmHive->Frozen == TRUE );

    RootKcb = CmHive->RootKcb;
    //
    // root kcb must be valid and has only our "artificial" refcount on it
    //
    ASSERT( RootKcb != NULL );

    if( RootKcb->RefCount > 1 ) {
        //
        // somebody else must've gotten in between dropping/reacquiring the reglock
        // and opened a handle inside this hive; bad luck, we can't unload
        //
        CmpUnlockRegistry();
        return;
    }

    ASSERT_KCB(RootKcb);

    Cell = RootKcb->KeyCell;
    Status = CmUnloadKey(&(CmHive->Hive),Cell,RootKcb);
    ASSERT( (Status != STATUS_CANNOT_DELETE) && (Status != STATUS_INVALID_PARAMETER) );

    if(NT_SUCCESS(Status)) {
        //
        // Mark the root kcb as deleted so that it won't get put on the delayed close list.
        //
        RootKcb->Delete = TRUE;
        //
        // If the parent has the subkey info or hint cached, free it.
        //
        CmpCleanUpSubKeyInfo(RootKcb->ParentKcb);
        CmpRemoveKeyControlBlock(RootKcb);
        CmpDereferenceKeyControlBlockWithLock(RootKcb);
    }

    CmpUnlockRegistry();
}

#endif //NT_UNLOAD_KEY_EX
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\base\ntos\config\cmdelay.c ===
/*++

Copyright (c) 1999  Microsoft Corporation

Module Name:

    cmdelay.c

Abstract:

    This module implements the new algorithm (LRU style) for the 
    Delayed Close KCB table.

    Functions in this module are thread safe protected by the kcb lock.
    When kcb lock is converted to a resource, we should assert (enforce)
    exclusivity of that resource here !!!

Note:
    
    We might want to convert these functions to macros after enough testing
    provides that they work well

Author:

    Dragos C. Sambotin (dragoss) 09-Aug-1999

Revision History:

--*/

#include    "cmp.h"

ULONG                   CmpDelayedCloseSize = 2048; // !!!! Cannot be bigger that 4094 !!!!!
CM_DELAYED_CLOSE_ENTRY  *CmpDelayedCloseTable;
LIST_ENTRY              CmpDelayedLRUListHead;  // head of the LRU list of Delayed Close Table entries


ULONG
CmpGetDelayedCloseIndex( );

#ifdef ALLOC_PRAGMA
#pragma alloc_text(PAGE,CmpInitializeDelayedCloseTable)
#pragma alloc_text(PAGE,CmpRemoveFromDelayedClose)
#pragma alloc_text(PAGE,CmpGetDelayedCloseIndex)
#pragma alloc_text(PAGE,CmpAddToDelayedClose)
#endif

VOID
CmpInitializeDelayedCloseTable()
/*++

Routine Description:

    Initialize delayed close table; allocation + LRU list initialization.

Arguments:


Return Value:

    NONE.

--*/
{
    ULONG i;

    PAGED_CODE();

    //
    // allocate the table from paged pool; it is important that the table 
    // is contiguous in memory as we compute the index based on this assumption
    //
    CmpDelayedCloseTable = ExAllocatePoolWithTag(PagedPool,
                                                 CmpDelayedCloseSize * sizeof(CM_DELAYED_CLOSE_ENTRY),
                                                 CM_DELAYCLOSE_TAG);
    if (CmpDelayedCloseTable == NULL) {
        CM_BUGCHECK(CONFIG_INITIALIZATION_FAILED,INIT_DELAYED_CLOSE_TABLE,1,0,0);
        return;
    }
    
    // 
    // Init LRUlist head.
    //
    InitializeListHead(&CmpDelayedLRUListHead);

    for (i=0; i<CmpDelayedCloseSize; i++) {
        //
        // mark it as available and add it to the end of the LRU list
        //
        CmpDelayedCloseTable[i].KeyControlBlock = NULL; 
        InsertTailList(
            &CmpDelayedLRUListHead,
            &(CmpDelayedCloseTable[i].DelayedLRUList)
            );
    }

}


VOID
CmpRemoveFromDelayedClose(
    IN PCM_KEY_CONTROL_BLOCK kcb
    )
/*++

Routine Description:

    Removes a KCB from the delayed close table;

Arguments:

    kcb - the kcb in question

Note: 
    
    kcb lock/resource should be aquired exclusively when this function is called

Return Value:

    NONE.

--*/
{
    ULONG i;

    PAGED_CODE();

    i = kcb->DelayedCloseIndex;

    CmKdPrintEx((DPFLTR_CONFIG_ID,CML_FLOW,"[CmpRemoveFromDelayedClose] : Removing kcb = %p from DelayedCloseTable; index = %lu\n",kcb,(ULONG)i));
    //
    // at this index should be the this kcb and the index should not be bigger 
    // than the size of the table
    //
    ASSERT(CmpDelayedCloseTable[i].KeyControlBlock == kcb);
    ASSERT( i < CmpDelayedCloseSize );

    //
    // nobody should hold references on this particular kcb
    //
    ASSERT( kcb->RefCount == 0 );

    //
    // mark the entry as available and add it to the end of the LRU list
    //
    CmpDelayedCloseTable[i].KeyControlBlock = NULL;
    CmpRemoveEntryList(&(CmpDelayedCloseTable[i].DelayedLRUList));
    InsertTailList(
        &CmpDelayedLRUListHead,
        &(CmpDelayedCloseTable[i].DelayedLRUList)
        );

    kcb->DelayedCloseIndex = CmpDelayedCloseSize;
}


ULONG
CmpGetDelayedCloseIndex( )
/*++

Routine Description:

    Finds a free entry in the delayed close table and returns it.
    If the table is full, the kcb in the last entry (LRU-wise) is
    kicked out of the table and its entry is reused.

Arguments:


Note: 
    
    kcb lock/resource should be aquired exclusively when this function is called

Return Value:

    NONE.

--*/
{
    ULONG                   DelayedIndex;
    PCM_DELAYED_CLOSE_ENTRY DelayedEntry;

    PAGED_CODE();

    //
    // get the last entry in the Delayed LRU list
    //
    DelayedEntry = (PCM_DELAYED_CLOSE_ENTRY)CmpDelayedLRUListHead.Blink;
    DelayedEntry = CONTAINING_RECORD(   DelayedEntry,
                                        CM_DELAYED_CLOSE_ENTRY,
                                        DelayedLRUList);
    
    if( DelayedEntry->KeyControlBlock != NULL ) {
        //
        // entry is not available; kick the kcb out of cache
        //
        ASSERT_KCB(DelayedEntry->KeyControlBlock);
        ASSERT( DelayedEntry->KeyControlBlock->RefCount == 0 );

        //
        // lock should be held here !!!
        //
        CmpCleanUpKcbCacheWithLock(DelayedEntry->KeyControlBlock);

        CmKdPrintEx((DPFLTR_CONFIG_ID,CML_FLOW,"[CmpGetDelayedCloseIndex] : no index free; kicking kcb = %p index = %lu out of DelayedCloseTable\n",
            DelayedEntry->KeyControlBlock,(ULONG)(((PUCHAR)DelayedEntry - (PUCHAR)CmpDelayedCloseTable) / sizeof( CM_DELAYED_CLOSE_ENTRY ))));

        DelayedEntry->KeyControlBlock = NULL;
    }

    DelayedIndex = (ULONG) (((PUCHAR)DelayedEntry - (PUCHAR)CmpDelayedCloseTable) / sizeof( CM_DELAYED_CLOSE_ENTRY ));

    //
    // sanity check
    //
    ASSERT( DelayedIndex < CmpDelayedCloseSize );

#if defined(_WIN64)
    //
    // somehow DelayedIndex is ok here but it gets corupted upon return from this api
    //
    if( DelayedIndex >= CmpDelayedCloseSize ) {
        DbgPrint("CmpGetDelayedCloseIndex: Bogus index %lx; DelayedEntry = %p; sizeof( CM_DELAYED_CLOSE_ENTRY ) = %lx\n",
            DelayedIndex,DelayedEntry,sizeof( CM_DELAYED_CLOSE_ENTRY ) );
        DbgBreakPoint();
    }
#endif
    return DelayedIndex;
}



VOID
CmpAddToDelayedClose(
    IN PCM_KEY_CONTROL_BLOCK kcb
    )
/*++

Routine Description:

    Adds a kcb to the delayed close table

Arguments:

    kcb - the kcb in question

Note: 
    
    kcb lock/resource should be aquired exclusively when this function is called

Return Value:

    NONE.

--*/
{
    ULONG                   DelayedIndex;
    PCM_DELAYED_CLOSE_ENTRY DelayedEntry;

    PAGED_CODE();

    ASSERT_KCB( kcb);
    ASSERT( kcb->RefCount == 0 );
    //
    // get the delayed entry and attach the kcb to it
    //
    DelayedIndex = CmpGetDelayedCloseIndex();
#if defined(_WIN64)
    //
    // somehow DelayedIndex is corupted here, but it was ok prior to return from CmpGetDeleyedCloseIndex
    //
    if( DelayedIndex >= CmpDelayedCloseSize ) {
        DbgPrint("CmpAddToDelayedClose: Bogus index %lx; sizeof( CM_DELAYED_CLOSE_ENTRY ) = %lx\n",
            DelayedIndex,sizeof( CM_DELAYED_CLOSE_ENTRY ) );
        DbgBreakPoint();
    }
#endif
    DelayedEntry = &(CmpDelayedCloseTable[DelayedIndex]);
    ASSERT( DelayedEntry->KeyControlBlock == NULL );
    DelayedEntry->KeyControlBlock = kcb;
    kcb->DelayedCloseIndex = DelayedIndex;

    CmKdPrintEx((DPFLTR_CONFIG_ID,CML_FLOW,"[CmpAddToDelayedClose] : Adding kcb = %p to DelayedCloseTable; index = %lu\n",
        kcb,DelayedIndex));
    //
    // move the entry on top of the LRU list
    //
    CmpRemoveEntryList(&(DelayedEntry->DelayedLRUList));
    InsertHeadList(
        &CmpDelayedLRUListHead,
        &(DelayedEntry->DelayedLRUList)
        );

}
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\base\ntos\config\cmdat.c ===
/*++

Copyright (c) 1990, 1991  Microsoft Corporation


Module Name:

    cmdat.c

Abstract:

    This module contains registry "static" data, except for data
    also used by setup, which is in cmdat2.c.

Author:

    Bryan Willman (bryanwi) 19-Oct-93


Environment:

    Kernel mode.

Revision History:

--*/

#include "cmp.h"

//
// ***** INIT *****
//

#ifdef ALLOC_DATA_PRAGMA
#pragma data_seg("INIT")
#pragma const_seg("INITCONST")
#endif

//
// ---------------------------
//


UNICODE_STRING  CmpLoadOptions = { 0 };        // sys options from FW or boot.ini


//
// CmpClassString - contains strings which are used as the class
//     strings in the keynode.
// The associated enumerated type is CONFIGURATION_CLASS in arc.h
//

UNICODE_STRING CmClassName[MaximumClass + 1] = { 0 };

const PWCHAR CmClassString[MaximumClass + 1] = {
    L"System",
    L"Processor",
    L"Cache",
    L"Adapter",
    L"Controller",
    L"Peripheral",
    L"MemoryClass",
    L"Undefined"
    };


struct {
    PUCHAR  AscString;
    USHORT  InterfaceType;
    USHORT  Count;
} CmpMultifunctionTypes[] = {
    "ISA",      Isa,            0,
    "MCA",      MicroChannel,   0,
    "PCI",      PCIBus,         0,
    "VME",      VMEBus,         0,
    "PCMCIA",   PCMCIABus,      0,
    "CBUS",     CBus,           0,
    "MPIPI",    MPIBus,         0,
    "MPSA",     MPSABus,        0,
    NULL,       Internal,       0
};


USHORT CmpUnknownBusCount = 0;

ULONG CmpConfigurationAreaSize = 0x4000;        // Initialize size = 16K
PCM_FULL_RESOURCE_DESCRIPTOR CmpConfigurationData = { 0 };

//
// The following strings will be used as the keynames for registry
// nodes.
// The associated enumerated type is CONFIGURATION_TYPE in arc.h
//

UNICODE_STRING CmTypeName[MaximumType + 1] = { 0 };


//
// ***** PAGE *****
//

#ifdef ALLOC_DATA_PRAGMA
#pragma data_seg("PAGEDATA")
#pragma const_seg("PAGECONST")
#endif

const PWCHAR CmTypeString[MaximumType + 1] = {
    L"System",
    L"CentralProcessor",
    L"FloatingPointProcessor",
    L"PrimaryICache",
    L"PrimaryDCache",
    L"SecondaryICache",
    L"SecondaryDCache",
    L"SecondaryCache",
    L"EisaAdapter",
    L"TcAdapter",
    L"ScsiAdapter",
    L"DtiAdapter",
    L"MultifunctionAdapter",
    L"DiskController",
    L"TapeController",
    L"CdRomController",
    L"WormController",
    L"SerialController",
    L"NetworkController",
    L"DisplayController",
    L"ParallelController",
    L"PointerController",
    L"KeyboardController",
    L"AudioController",
    L"OtherController",
    L"DiskPeripheral",
    L"FloppyDiskPeripheral",
    L"TapePeripheral",
    L"ModemPeripheral",
    L"MonitorPeripheral",
    L"PrinterPeripheral",
    L"PointerPeripheral",
    L"KeyboardPeripheral",
    L"TerminalPeripheral",
    L"OtherPeripheral",
    L"LinePeripheral",
    L"NetworkPeripheral",
    L"SystemMemory",
    L"DockingInformation",
    L"RealModeIrqRoutingTable",    
    L"RealModePCIEnumeration",    
    L"Undefined"
    };

//
// CmpTypeCount[] - For each 'type', a count is used to keep track how many
//     keys have been created.
//

ULONG CmpTypeCount[NUMBER_TYPES] = {
            0,                  // ArcSystem
            0,                  // CentralProcessor",
            0,                  // FloatingPointProcessor",
            0,                  // PrimaryICache",
            0,                  // PrimaryDCache",
            0,                  // SecondaryICache",
            0,                  // SecondaryDCache",
            0,                  // SecondaryCache",
            0,                  // EisaAdapter", (8)
            0,                  // TcAdapter",   (9)
            0,                  // ScsiAdapter",
            0,                  // DtiAdapter",
            0,                  // MultifunctionAdapter", (12)
            0,                  // DiskController", (13)
            0,                  // TapeController",
            0,                  // CdRomController",
            0,                  // WormController",
            0,                  // SerialController",
            0,                  // NetworkController",
            0,                  // DisplayController",
            0,                  // ParallelController",
            0,                  // PointerController",
            0,                  // KeyboardController",
            0,                  // AudioController",
            0,                  // OtherController",
            0,                  // DiskPeripheral",
            0,                  // FloppyDiskPeripheral",
            0,                  // TapePeripheral",
            0,                  // ModemPeripheral",
            0,                  // MonitorPeripheral",
            0,                  // PrinterPeripheral",
            0,                  // PointerPeripheral",
            0,                  // KeyboardPeripheral",
            0,                  // TerminalPeripheral",
            0,                  // OtherPeripheral",
            0,                  // LinePeripheral",
            0,                  // NetworkPeripheral",
            0,                  // SystemMemory",
            0,                  // DockingInformation,
            0,					// RealModeIrqRoutingTable
            0                   // Undefined"
            };

const UNICODE_STRING nullclass = { 0, 0, NULL };

//
// All names used by the registry
//


UNICODE_STRING CmRegistryRootName = { 0 };
UNICODE_STRING CmRegistryMachineName = { 0 };
UNICODE_STRING CmRegistryMachineHardwareName = { 0 };
UNICODE_STRING CmRegistryMachineHardwareDescriptionName = { 0 };
UNICODE_STRING CmRegistryMachineHardwareDescriptionSystemName = { 0 };
UNICODE_STRING CmRegistryMachineHardwareDeviceMapName = { 0 };
UNICODE_STRING CmRegistryMachineHardwareResourceMapName = { 0 };
UNICODE_STRING CmRegistryMachineHardwareOwnerMapName = { 0 };
UNICODE_STRING CmRegistryMachineSystemName = { 0 };
UNICODE_STRING CmRegistryMachineSystemCurrentControlSet = { 0 };
UNICODE_STRING CmRegistryMachineSystemCurrentControlSetEnumName = { 0 };
UNICODE_STRING CmRegistryMachineSystemCurrentControlSetEnumRootName = { 0 };
UNICODE_STRING CmRegistryMachineSystemCurrentControlSetServices = { 0 };
UNICODE_STRING CmRegistryMachineSystemCurrentControlSetHardwareProfilesCurrent = { 0 };
UNICODE_STRING CmRegistryMachineSystemCurrentControlSetControlClass = { 0 };
UNICODE_STRING CmRegistryMachineSystemCurrentControlSetControlSafeBoot = { 0 };
UNICODE_STRING CmRegistryMachineSystemCurrentControlSetControlSessionManagerMemoryManagement = { 0 };
UNICODE_STRING CmRegistryMachineSystemCurrentControlSetControlBootLog = { 0 };
UNICODE_STRING CmRegistryMachineSystemCurrentControlSetServicesEventLog = { 0 };
UNICODE_STRING CmRegistryUserName = { 0 };
UNICODE_STRING CmRegistrySystemCloneName = { 0 };
UNICODE_STRING CmpSystemFileName = { 0 };
UNICODE_STRING CmSymbolicLinkValueName = { 0 };

#ifdef _WANT_MACHINE_IDENTIFICATION
UNICODE_STRING CmRegistryMachineSystemCurrentControlSetControlBiosInfo = { 0 };
#endif

const PWCHAR CmpRegistryRootString = L"\\REGISTRY";
const PWCHAR CmpRegistryMachineString = L"\\REGISTRY\\MACHINE";
const PWCHAR CmpRegistryMachineHardwareString =
                    L"\\REGISTRY\\MACHINE\\HARDWARE";
const PWCHAR CmpRegistryMachineHardwareDescriptionString =
                    L"\\REGISTRY\\MACHINE\\HARDWARE\\DESCRIPTION";
const PWCHAR CmpRegistryMachineHardwareDescriptionSystemString =
                    L"\\REGISTRY\\MACHINE\\HARDWARE\\DESCRIPTION\\SYSTEM";
const PWCHAR CmpRegistryMachineHardwareDeviceMapString =
                    L"\\REGISTRY\\MACHINE\\HARDWARE\\DEVICEMAP";
const PWCHAR CmpRegistryMachineHardwareResourceMapString =
                    L"\\REGISTRY\\MACHINE\\HARDWARE\\RESOURCEMAP";
const PWCHAR CmpRegistryMachineHardwareOwnerMapString =
                    L"\\REGISTRY\\MACHINE\\HARDWARE\\OWNERMAP";
const PWCHAR CmpRegistryMachineSystemString =
                    L"\\REGISTRY\\MACHINE\\SYSTEM";
const PWCHAR CmpRegistryMachineSystemCurrentControlSetString =
                    L"\\REGISTRY\\MACHINE\\SYSTEM\\CURRENTCONTROLSET";
const PWCHAR CmpRegistryMachineSystemCurrentControlSetEnumString =
                    L"\\REGISTRY\\MACHINE\\SYSTEM\\CURRENTCONTROLSET\\ENUM";
const PWCHAR CmpRegistryMachineSystemCurrentControlSetEnumRootString =
                    L"\\REGISTRY\\MACHINE\\SYSTEM\\CURRENTCONTROLSET\\ENUM\\ROOT";
const PWCHAR CmpRegistryMachineSystemCurrentControlSetServicesString =
                    L"\\REGISTRY\\MACHINE\\SYSTEM\\CURRENTCONTROLSET\\SERVICES";
const PWCHAR CmpRegistryMachineSystemCurrentControlSetHardwareProfilesCurrentString =
                    L"\\REGISTRY\\MACHINE\\SYSTEM\\CURRENTCONTROLSET\\HARDWARE PROFILES\\CURRENT";
const PWCHAR CmpRegistryMachineSystemCurrentControlSetControlClassString =
                    L"\\REGISTRY\\MACHINE\\SYSTEM\\CURRENTCONTROLSET\\CONTROL\\CLASS";
const PWCHAR CmpRegistryMachineSystemCurrentControlSetControlSafeBootString =
                    L"\\REGISTRY\\MACHINE\\SYSTEM\\CURRENTCONTROLSET\\CONTROL\\SAFEBOOT";
const PWCHAR CmpRegistryMachineSystemCurrentControlSetControlSessionManagerMemoryManagementString =
                    L"\\REGISTRY\\MACHINE\\SYSTEM\\CURRENTCONTROLSET\\CONTROL\\SESSION MANAGER\\MEMORY MANAGEMENT";
const PWCHAR CmpRegistryMachineSystemCurrentControlSetControlBootLogString =
                    L"\\REGISTRY\\MACHINE\\SYSTEM\\CURRENTCONTROLSET\\CONTROL\\BOOTLOG";
const PWCHAR CmpRegistryMachineSystemCurrentControlSetServicesEventLogString =
                    L"\\REGISTRY\\MACHINE\\SYSTEM\\CURRENTCONTROLSET\\SERVICES\\EVENTLOG";
const PWCHAR CmpRegistryUserString = L"\\REGISTRY\\USER";
const PWCHAR CmpRegistrySystemCloneString = L"\\REGISTRY\\MACHINE\\CLONE";
const PWCHAR CmpRegistrySystemFileNameString = L"SYSTEM";
const PWCHAR CmpRegistryPerflibString = L"\\REGISTRY\\MACHINE\\SOFTWARE\\MICROSOFT\\WINDOWS NT\\CURRENTVERSION\\PERFLIB";

const PWCHAR CmpProcessorControl = L"ProcessorControl";
const PWCHAR CmpControlSessionManager = L"Control\\Session Manager";
const PWCHAR CmpSymbolicLinkValueName = L"SymbolicLinkValue";

#ifdef _WANT_MACHINE_IDENTIFICATION
const PWCHAR CmpRegistryMachineSystemCurrentControlSetControlBiosInfoString =
                    L"\\REGISTRY\\MACHINE\\SYSTEM\\CURRENTCONTROLSET\\CONTROL\\BIOSINFO";
#endif

//
// N.B. The CLONE hive is left out of the machine Hive list if 
//      we will not be using it to clone the current control set, 
//      since that is that Hive's only purpose.
//

HIVE_LIST_ENTRY CmpMachineHiveList[] = {
    { L"HARDWARE", L"MACHINE\\", NULL, HIVE_VOLATILE    ,   NULL,   FALSE,  FALSE,  FALSE},
    { L"SECURITY", L"MACHINE\\", NULL, 0                ,   NULL,   FALSE,  FALSE,  FALSE},
    { L"SOFTWARE", L"MACHINE\\", NULL, 0                ,   NULL,   FALSE,  FALSE,  FALSE},
    { L"SYSTEM",   L"MACHINE\\", NULL, 0                ,   NULL,   FALSE,  FALSE,  FALSE},
    { L"DEFAULT",  L"USER\\.DEFAULT", NULL, 0           ,   NULL,   FALSE,  FALSE,  FALSE},
    { L"SAM",      L"MACHINE\\", NULL, HIVE_NOLAZYFLUSH ,   NULL,   FALSE,  FALSE,  FALSE},

#if CLONE_CONTROL_SET
    { L"CLONE",    L"MACHINE\\", NULL, HIVE_VOLATILE    ,   NULL,   FALSE,  FALSE,  FALSE},
#endif

//  { L"TEST",     L"MACHINE\\", NULL, HIVE_NOLAZYFLUSH ,   NULL,   FALSE,  FALSE,  FALSE},
    { NULL,        NULL,         0, 0                   ,   NULL,   FALSE,  FALSE,  FALSE}
    };


UCHAR           SystemHiveFullPathBuffer[MAX_NAME];
UNICODE_STRING  SystemHiveFullPathName;

//
// Master Hive
//
//  The KEY_NODEs for \REGISTRY, \REGISTRY\MACHINE, and \REGISTRY\USER
//  are stored in a small memory only hive called the Master Hive.
//  All other hives have link nodes in this hive which point to them.
//
PCMHIVE CmpMasterHive = { 0 };
BOOLEAN CmpNoMasterCreates = FALSE;     // Set TRUE after we're done to
                                        // prevent random creates in the
                                        // master hive, which is not backed
                                        // by a file.


LIST_ENTRY  CmpHiveListHead = { 0 };            // List of CMHIVEs
FAST_MUTEX  CmpHiveListHeadLock;                // used to protect the list above

//
// Addresses of object type descriptors:
//

POBJECT_TYPE CmpKeyObjectType = { 0 };

//
// Write-Control:
//  CmpNoWrite is initially true.  When set this way write and flush
//  do nothing, simply returning success.  When cleared to FALSE, I/O
//  is enabled.  This change is made after the I/O system is started
//  AND autocheck (chkdsk) has done its thing.
//

BOOLEAN CmpNoWrite = TRUE;


//
// NtInitializeRegistry global status flags
//

// 
// If CmFirstTime is TRUE, then NtInitializeRegistry has not yet been
// called to perform basic registry initialization
//

BOOLEAN CmFirstTime = TRUE;       

//
// trick to allow paralel threads to access the registry
//
BOOLEAN CmpSpecialBootCondition = FALSE;


//
// If CmBootAcceptFirstTime is TRUE, then NtInitializeRegistry has not 
// yet been called to accept the current Boot and save the boot
// control set as the LKG control set.
//

BOOLEAN CmBootAcceptFirstTime = TRUE;   

//
// CmpWasSetupBoot indicates whether or not the boot
// is into text mode setup.  If so, we do not turn
// on global quotas.
//
BOOLEAN CmpWasSetupBoot;

//
// Indicates whether the hives need to be loaded in memory
// and in scratch mode
//
BOOLEAN CmpMiniNTBoot = FALSE;

//
// Indicates whether the system hives need to be opened in a
// shared mode. Generally needed if we are booting WinPE (MiniNT)
// on network
//
BOOLEAN CmpShareSystemHives = FALSE;

//
// Where are we booting from
//
ULONG	CmpBootType;
//
// Self healing hives control switch
//
BOOLEAN CmpSelfHeal = TRUE;


#ifdef ALLOC_DATA_PRAGMA
#pragma  const_seg()
#pragma  data_seg()
#endif

//
// ***** FIXED *****
//
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\base\ntos\config\cmgquota.c ===
/*++

Copyright (c) 1993  Microsoft Corporation

Module Name:

    cmgquota.c

Abstract:

    The module contains CM routines to support Global Quota

    Global Quota has little to do with NT's standard per-process/user
    quota system.  Global Quota is waying of controlling the aggregate
    resource usage of the entire registry.  It is used to manage space
    consumption by objects which user apps create, but which are persistent
    and therefore cannot be assigned to the quota of a user app.

    Global Quota prevents the registry from consuming all of paged
    pool, and indirectly controls how much disk it can consume.
    Like the release 1 file systems, a single app can fill all the
    space in the registry, but at least it cannot kill the system.

    Memory objects used for known short times and protected by
    serialization, or billable as quota objects, are not counted
    in the global quota.

Author:

    Bryan M. Willman (bryanwi) 13-Jan-1993

Revision History:

    Dragos C Sambotin (dragoss) 04-Nov-1999
    Charge quota only for bins in paged pool (volatile storage and bins crossing 
    the CM_VIEW_SIZE boundary).

--*/

#include "cmp.h"

VOID
CmpSystemHiveHysteresisWorker(
    IN PVOID WorkItem
    );

VOID
CmpRaiseSelfHealWarningWorker(
    IN PVOID Arg
    );

#ifdef ALLOC_PRAGMA
#pragma alloc_text(PAGE,CmpClaimGlobalQuota)
#pragma alloc_text(PAGE,CmpReleaseGlobalQuota)
#pragma alloc_text(PAGE,CmpSetGlobalQuotaAllowed)
#pragma alloc_text(PAGE,CmpQuotaWarningWorker)
#pragma alloc_text(PAGE,CmQueryRegistryQuotaInformation)
#pragma alloc_text(PAGE,CmSetRegistryQuotaInformation)
#pragma alloc_text(PAGE,CmpCanGrowSystemHive)
#pragma alloc_text(PAGE,CmpSystemQuotaWarningWorker)
#pragma alloc_text(INIT,CmpComputeGlobalQuotaAllowed)
#pragma alloc_text(PAGE,CmpSystemHiveHysteresisWorker)
#pragma alloc_text(PAGE,CmpUpdateSystemHiveHysteresis)
#pragma alloc_text(PAGE,CmRegisterSystemHiveLimitCallback)
#pragma alloc_text(PAGE,CmpRaiseSelfHealWarning)
#pragma alloc_text(PAGE,CmpRaiseSelfHealWarningForSystemHives)
#pragma alloc_text(PAGE,CmpRaiseSelfHealWarningWorker)
#endif

//
// Registry control values
//
#define CM_DEFAULT_RATIO            (3)
#define CM_LIMIT_RATIO(x)           ((x / 10) * 8)
#define CM_MINIMUM_GLOBAL_QUOTA     (16 *1024 * 1024)

//
// Percent of used registry quota that triggers a hard error
// warning popup.
//
#define CM_REGISTRY_WARNING_LEVEL   (95)

//
// System hive hard quota limit
//
// For an x86 3GB system we set the limit at 12MB for now. Needs some MM changes before we 
// bump this up.
// For an x86 non-3GB system, we set the limit at 1/4 of physical memory
// For IA-64 we set the limit at 32MB
//

#define _200MB (200 *1024 * 1024) 

#if defined(_X86_)
#define CM_SYSTEM_HIVE_LIMIT_SIZE       (MmVirtualBias ? (12 * 1024 * 1024) : (min(MmNumberOfPhysicalPages / 4, _200MB >> PAGE_SHIFT) * PAGE_SIZE))
#else
#define CM_SYSTEM_HIVE_LIMIT_SIZE       (32 * 1024 * 1024)
#endif

#define CM_SYSTEM_HIVE_WARNING_SIZE     ((CM_SYSTEM_HIVE_LIMIT_SIZE*9)/10)


extern ULONG CmRegistrySizeLimit;
extern ULONG CmRegistrySizeLimitLength;
extern ULONG CmRegistrySizeLimitType;

extern ULONG MmSizeOfPagedPoolInBytes;

//
// Maximum number of bytes of Global Quota the registry may use.
// Set to largest positive number for use in boot.  Will be set down
// based on pool and explicit registry values.
//
extern ULONG   CmpGlobalQuota;
extern ULONG   CmpGlobalQuotaAllowed;

//
// Mark that will trigger the low-on-quota popup
//
extern ULONG   CmpGlobalQuotaWarning;

//
// Indicate whether the popup has been triggered yet or not.
//
extern BOOLEAN CmpQuotaWarningPopupDisplayed;

extern BOOLEAN CmpSystemQuotaWarningPopupDisplayed;

//
// GQ actually in use
//
extern ULONG   CmpGlobalQuotaUsed;

extern  HIVE_LIST_ENTRY CmpMachineHiveList[];


VOID
CmQueryRegistryQuotaInformation(
    IN PSYSTEM_REGISTRY_QUOTA_INFORMATION RegistryQuotaInformation
    )

/*++

Routine Description:

    Returns the registry quota information

Arguments:

    RegistryQuotaInformation - Supplies pointer to buffer that will return
        the registry quota information.

Return Value:

    None.

--*/

{
    RegistryQuotaInformation->RegistryQuotaAllowed  = CmpGlobalQuota;
    RegistryQuotaInformation->RegistryQuotaUsed     = CmpGlobalQuotaUsed;
    RegistryQuotaInformation->PagedPoolSize         = MmSizeOfPagedPoolInBytes;
}


VOID
CmSetRegistryQuotaInformation(
    IN PSYSTEM_REGISTRY_QUOTA_INFORMATION RegistryQuotaInformation
    )

/*++

Routine Description:

    Sets the registry quota information.  The caller is assumed to have
    completed the necessary security checks already.

Arguments:

    RegistryQuotaInformation - Supplies pointer to buffer that provides
        the new registry quota information.

Return Value:

    None.

--*/

{
    CmpGlobalQuota = RegistryQuotaInformation->RegistryQuotaAllowed;

    //
    // Sanity checks against insane values
    //
    if (CmpGlobalQuota > CM_WRAP_LIMIT) {
        CmpGlobalQuota = CM_WRAP_LIMIT;
    }
    if (CmpGlobalQuota < CM_MINIMUM_GLOBAL_QUOTA) {
        CmpGlobalQuota = CM_MINIMUM_GLOBAL_QUOTA;
    }

    //
    // Recompute the warning level
    //
    CmpGlobalQuotaWarning = CM_REGISTRY_WARNING_LEVEL * (CmpGlobalQuota / 100);

    CmpGlobalQuotaAllowed = CmpGlobalQuota;
}

VOID
CmpQuotaWarningWorker(
    IN PVOID WorkItem
    )

/*++

Routine Description:

    Displays hard error popup that indicates the registry quota is
    running out.

Arguments:

    WorkItem - Supplies pointer to the work item. This routine will
               free the work item.

Return Value:

    None.

--*/

{
    NTSTATUS Status;
    ULONG Response;

    ExFreePool(WorkItem);

    Status = ExRaiseHardError(STATUS_REGISTRY_QUOTA_LIMIT,
                              0,
                              0,
                              NULL,
                              OptionOk,
                              &Response);
}


BOOLEAN
CmpClaimGlobalQuota(
    IN ULONG    Size
    )
/*++

Routine Description:

    If CmpGlobalQuotaUsed + Size >= CmpGlobalQuotaAllowed, return
    false.  Otherwise, increment CmpGlobalQuotaUsed, in effect claiming
    the requested GlobalQuota.

Arguments:

    Size - number of bytes of GlobalQuota caller wants to claim

Return Value:

    TRUE - Claim succeeded, and has been counted in Used GQ

    FALSE - Claim failed, nothing counted in GQ.

--*/
{
#if 0
    //
    // We shouldn't come to this, unless we have leaks;
    // There is no quota anymore, remember?
    //
    LONG   available;
    PWORK_QUEUE_ITEM WorkItem;

    //
    // compute available space, then see if size <.  This prevents overflows.
    // Note that this must be signed. Since quota is not enforced until logon,
    // it is possible for the available bytes to be negative.
    //

    available = (LONG)CmpGlobalQuotaAllowed - (LONG)CmpGlobalQuotaUsed;

    if ((LONG)Size < available) {
        CmpGlobalQuotaUsed += Size;
        if ((CmpGlobalQuotaUsed > CmpGlobalQuotaWarning) &&
            (!CmpQuotaWarningPopupDisplayed) &&
            (ExReadyForErrors)) {


            //
            // Queue work item to display popup
            //
            WorkItem = ExAllocatePool(NonPagedPool, sizeof(WORK_QUEUE_ITEM));
            if (WorkItem != NULL) {

                CmpQuotaWarningPopupDisplayed = TRUE;
                ExInitializeWorkItem(WorkItem,
                                     CmpQuotaWarningWorker,
                                     WorkItem);
                ExQueueWorkItem(WorkItem, DelayedWorkQueue);
            }
        }
        return TRUE;
    } else {
        return FALSE;
    }
#endif //0

    CmpGlobalQuotaUsed += Size;

    return TRUE;
}


VOID
CmpReleaseGlobalQuota(
    IN ULONG    Size
    )
/*++

Routine Description:

    If Size <= CmpGlobalQuotaUsed, then decrement it.  Else BugCheck.

Arguments:

    Size - number of bytes of GlobalQuota caller wants to release

Return Value:

    NONE.

--*/
{
    if (Size > CmpGlobalQuotaUsed) {
        CM_BUGCHECK(REGISTRY_ERROR,QUOTA_ERROR,1,0,0);
    }

    CmpGlobalQuotaUsed -= Size;
}


VOID
CmpComputeGlobalQuotaAllowed(
    VOID
    )

/*++

Routine Description:

    Compute CmpGlobalQuota based on:
        (a) Size of paged pool
        (b) Explicit user registry commands to set registry GQ

Return Value:

    NONE.

--*/

{
    ULONG   PagedLimit;

    PagedLimit = CM_LIMIT_RATIO(MmSizeOfPagedPoolInBytes);

    if ((CmRegistrySizeLimitLength != 4) ||
        (CmRegistrySizeLimitType != REG_DWORD) ||
        (CmRegistrySizeLimit == 0))
    {
        //
        // If no value at all, or value of wrong type, or set to
        // zero, use internally computed default
        //
        CmpGlobalQuota = MmSizeOfPagedPoolInBytes / CM_DEFAULT_RATIO;

    } else if (CmRegistrySizeLimit >= PagedLimit) {
        //
        // If more than computed upper bound, use computed upper bound
        //
        CmpGlobalQuota = PagedLimit;

    } else {
        //
        // Use the set size
        //
        CmpGlobalQuota = CmRegistrySizeLimit;

    }

    if (CmpGlobalQuota > CM_WRAP_LIMIT) {
        CmpGlobalQuota = CM_WRAP_LIMIT;
    }
    if (CmpGlobalQuota < CM_MINIMUM_GLOBAL_QUOTA) {
        CmpGlobalQuota = CM_MINIMUM_GLOBAL_QUOTA;
    }

    CmpGlobalQuotaWarning = CM_REGISTRY_WARNING_LEVEL * (CmpGlobalQuota / 100);

    return;
}


VOID
CmpSetGlobalQuotaAllowed(
    VOID
    )
/*++

Routine Description:

    Enables registry quota

    NOTE:   Do NOT put this in init segment, we call it after
            that code has been freed!

Return Value:

    NONE.

--*/
{
     CmpGlobalQuotaAllowed = CmpGlobalQuota;
}


BOOLEAN
CmpCanGrowSystemHive(
                     IN PHHIVE  Hive,
                     IN ULONG   NewLength
                     )

/*++

Routine Description:

    Checks if the system hive is allowed to grow with the specified amount
    of data (using the hard quota limit on the system hive)

Return Value:

    NONE.

--*/
{
    PCMHIVE             CmHive;
    PWORK_QUEUE_ITEM    WorkItem;

    PAGED_CODE();

    CmHive = (PCMHIVE)CONTAINING_RECORD(Hive,CMHIVE,Hive);
    
    if( CmHive != CmpMachineHiveList[SYSTEM_HIVE_INDEX].CmHive ) {
        //
        // not the system hive, bail out
        //
        return TRUE;
    }

    // account for the header.
    NewLength += HBLOCK_SIZE;
    if( NewLength > CM_SYSTEM_HIVE_LIMIT_SIZE ) {
        //
        // this is bad; we may not be able to boot next time !!!
        //
        return FALSE;
    }

    if( (NewLength > CM_SYSTEM_HIVE_WARNING_SIZE) && 
        (!CmpSystemQuotaWarningPopupDisplayed) &&
        (ExReadyForErrors)
      ) {
        //
        // we're above the warning level, queue work item to display popup
        //
        WorkItem = ExAllocatePool(NonPagedPool, sizeof(WORK_QUEUE_ITEM));
        if (WorkItem != NULL) {

            CmpSystemQuotaWarningPopupDisplayed = TRUE;
            ExInitializeWorkItem(WorkItem,
                                 CmpSystemQuotaWarningWorker,
                                 WorkItem);
            ExQueueWorkItem(WorkItem, DelayedWorkQueue);
        }

    }

    return TRUE;
}


VOID
CmpSystemQuotaWarningWorker(
    IN PVOID WorkItem
    )

/*++

Routine Description:

    Displays hard error popup that indicates the hard quota limit
    on the system hive is running out.

Arguments:

    WorkItem - Supplies pointer to the work item. This routine will
               free the work item.

Return Value:

    None.

--*/

{
    NTSTATUS Status;
    ULONG Response;

    ExFreePool(WorkItem);

    Status = ExRaiseHardError(STATUS_REGISTRY_QUOTA_LIMIT,
                              0,
                              0,
                              NULL,
                              OptionOk,
                              &Response);
}

//
// Pnp private API 
//
ULONG                       CmpSystemHiveHysteresisLow = 0;
ULONG                       CmpSystemHiveHysteresisHigh = 0;
PVOID                       CmpSystemHiveHysteresisContext = NULL;
PCM_HYSTERESIS_CALLBACK     CmpSystemHiveHysteresisCallback = NULL;
ULONG                       CmpSystemHiveHysteresisHitRatio = 0;
BOOLEAN                     CmpSystemHiveHysteresisLowSeen = FALSE;
BOOLEAN                     CmpSystemHiveHysteresisHighSeen = FALSE;

VOID
CmpSystemHiveHysteresisWorker(
    IN PVOID WorkItem
    )

/*++

Routine Description:

    Calls the hysteresis callback

Arguments:

    WorkItem - Supplies pointer to the work item. This routine will
               free the work item.

Return Value:

    None.

--*/

{
    PCM_HYSTERESIS_CALLBACK   Callback;

    ExFreePool(WorkItem);

    Callback = CmpSystemHiveHysteresisCallback;

    if( Callback ) {
        (*Callback)(CmpSystemHiveHysteresisContext,CmpSystemHiveHysteresisHitRatio);
    }
}


VOID
CmpUpdateSystemHiveHysteresis(  PHHIVE  Hive,
                                ULONG   NewLength,
                                ULONG   OldLength
                                )
{
    PCMHIVE             CmHive;
    PWORK_QUEUE_ITEM    WorkItem;
    ULONG               CurrentRatio;
    BOOLEAN             DoWorkItem = FALSE;

    PAGED_CODE();

    CmHive = (PCMHIVE)CONTAINING_RECORD(Hive,CMHIVE,Hive);
    
    if( (!CmpSystemHiveHysteresisCallback) || (CmHive != CmpMachineHiveList[SYSTEM_HIVE_INDEX].CmHive) ) {
        //
        // not the system hive, bail out
        //
        return;
    }

    ASSERT( NewLength != OldLength );

    //
    // compute current ratio; acount for the header first
    //
    CurrentRatio = NewLength + HBLOCK_SIZE;
    CurrentRatio *= 100;
    CurrentRatio /= CM_SYSTEM_HIVE_LIMIT_SIZE;

    if( NewLength > OldLength ) {
        //
        // hive is growing
        //
        if( (CmpSystemHiveHysteresisHighSeen == FALSE) && (CurrentRatio > CmpSystemHiveHysteresisHigh) ) {
            //
            // we reached high; see if low has already been hit and queue work item
            //
            CmpSystemHiveHysteresisHighSeen = TRUE;
            if( TRUE == CmpSystemHiveHysteresisLowSeen ) {
                //
                // low to high; queue workitem
                //
                CmpSystemHiveHysteresisHitRatio = CurrentRatio;
                DoWorkItem = TRUE;
            }
        }
    } else {
        //
        // hive is shrinking
        //
        if( (FALSE == CmpSystemHiveHysteresisLowSeen) && (CurrentRatio < CmpSystemHiveHysteresisLow ) ) {
            //
            // we reached low; see if low has been hit and queue work item
            //
            CmpSystemHiveHysteresisLowSeen = TRUE;
            if( TRUE == CmpSystemHiveHysteresisHighSeen ) {
                //
                // high to low; queue workitem
                //
                CmpSystemHiveHysteresisHitRatio = CurrentRatio;
                DoWorkItem = TRUE;
            }
        }
    }

    if( DoWorkItem ) {
        ASSERT( CmpSystemHiveHysteresisLowSeen && CmpSystemHiveHysteresisHighSeen );

        WorkItem = ExAllocatePool(NonPagedPool, sizeof(WORK_QUEUE_ITEM));
        if (WorkItem != NULL) {

            ExInitializeWorkItem(WorkItem,
                                 CmpSystemHiveHysteresisWorker,
                                 WorkItem);
            ExQueueWorkItem(WorkItem, DelayedWorkQueue);
        }
        //
        // reset state so we can fire again later
        //
        CmpSystemHiveHysteresisLowSeen = FALSE;
        CmpSystemHiveHysteresisHighSeen = FALSE;
    }
}

ULONG
CmRegisterSystemHiveLimitCallback(
                                ULONG Low,
                                ULONG High,
                                PVOID Ref,
                                PCM_HYSTERESIS_CALLBACK Callback
                                )
/*++

Routine Description:

    This routine registers a hysteresis for the system hive limit ratio.
    We will call the callback :

    a. the system hive goes above High from below Low
    b. the system hive goes below Low from above High

Arguments:

    Low, High - specifies the hysteresis

    Ref - Context to give back to the callback

    Callback - callback routine.

Return Value:

    current ratio 0 - 100

--*/
{
    ULONG               Length;

    PAGED_CODE();

    if( CmpMachineHiveList[SYSTEM_HIVE_INDEX].CmHive ) {
        Length = CmpMachineHiveList[SYSTEM_HIVE_INDEX].CmHive->Hive.BaseBlock->Length + HBLOCK_SIZE;

        Length *= 100;
        Length /= CM_SYSTEM_HIVE_LIMIT_SIZE;
    } else {
        Length = 0;
    }

    //
    // allow only one call per system uptime.
    //
    if( CmpSystemHiveHysteresisCallback == NULL ) {
        CmpSystemHiveHysteresisLow = Low;
        CmpSystemHiveHysteresisHigh = High;
        CmpSystemHiveHysteresisContext = Ref;
        CmpSystemHiveHysteresisCallback = Callback;
        //
        // set state vars
        //
        if( Length <= Low ) {
            CmpSystemHiveHysteresisLowSeen = TRUE;
        } else {
            CmpSystemHiveHysteresisLowSeen = FALSE;
        }
        if( Length >= High) {
            CmpSystemHiveHysteresisHighSeen = TRUE;
        } else {
            CmpSystemHiveHysteresisHighSeen = FALSE;
        }
    }
    return Length;
}


VOID 
CmpHysteresisTest(PVOID Ref, ULONG Level)
{
    UNREFERENCED_PARAMETER (Ref);

    DbgPrint("CmpHysteresisTest called with level = %lu \n",Level);
}


typedef struct {
    PWORK_QUEUE_ITEM    WorkItem;
    UNICODE_STRING      HiveName;
    //
    // variable length; name goes here
    //
} CM_SELF_HEAL_WORK_ITEM_PARAMETER, *PCM_SELF_HEAL_WORK_ITEM_PARAMETER;

VOID
CmpRaiseSelfHealWarningWorker(
    IN PVOID Arg
    )
{
    PVOID                               ErrorParameters;
    ULONG                               ErrorResponse;
    PCM_SELF_HEAL_WORK_ITEM_PARAMETER   Param;

    Param = (PCM_SELF_HEAL_WORK_ITEM_PARAMETER)Arg;
    ErrorParameters = &(Param->HiveName);
    ExRaiseHardError(
        STATUS_REGISTRY_RECOVERED,
        1,
        1,
        (PULONG_PTR)&ErrorParameters,
        OptionOk,
        &ErrorResponse
        );

    //
    // free what we have allocated
    //
    ExFreePool(Param->WorkItem);
    ExFreePool(Param);
}

VOID 
CmpRaiseSelfHealWarning( 
                        IN PUNICODE_STRING  HiveName
                        )
/*++

Routine Description:

    Raise a hard error informing the use the specified hive has been self healed and
    it might not be entirely consitent

Arguments:

    Parameter - the hive name.

Return Value:

    None.

--*/
{
    PCM_SELF_HEAL_WORK_ITEM_PARAMETER   Param;

    PAGED_CODE();

    //
    // we're above the warning level, queue work item to display popup
    //
    Param = ExAllocatePool(NonPagedPool, sizeof(CM_SELF_HEAL_WORK_ITEM_PARAMETER) + HiveName->Length);
    if( Param ) {
        Param->WorkItem = ExAllocatePool(NonPagedPool, sizeof(WORK_QUEUE_ITEM));
        if(Param->WorkItem != NULL) {
            Param->HiveName.Length = Param->HiveName.MaximumLength = HiveName->Length;
            Param->HiveName.Buffer = (PWSTR)(((PUCHAR)Param) + sizeof(CM_SELF_HEAL_WORK_ITEM_PARAMETER));
            RtlCopyMemory(Param->HiveName.Buffer,HiveName->Buffer,HiveName->Length);
            ExInitializeWorkItem(Param->WorkItem,
                                 CmpRaiseSelfHealWarningWorker,
                                 Param);
            ExQueueWorkItem(Param->WorkItem, DelayedWorkQueue);
        } else {
            ExFreePool(Param);
        }
    }
}

VOID 
CmpRaiseSelfHealWarningForSystemHives( )
/*++

Routine Description:

    Walks the system hivelist and raises a hard error in the event one of the hives has been self healed.

    Intended to be called after controlset has been saved, from inside NtInitializeRegistry
    (i.e. we have an UI available so it will not stop the machine).

Arguments:

Return Value:

    None.

--*/
{
    ULONG           i;
    UNICODE_STRING  Name;

    PAGED_CODE();

	for (i = 0; i < CM_NUMBER_OF_MACHINE_HIVES; i++) {
        if( !(CmpMachineHiveList[i].Flags & HIVE_VOLATILE) && (((PHHIVE)(CmpMachineHiveList[i].CmHive2))->BaseBlock->BootType & HBOOT_SELFHEAL) ) {
            RtlInitUnicodeString(
                &Name,
                CmpMachineHiveList[i].Name
                );
            CmpRaiseSelfHealWarning( &Name );
        }
    }

}
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\base\ntos\config\cmdown.c ===
/*++

Copyright (c) 2000  Microsoft Corporation

Module Name:

    cmdown.c

Abstract:

    This module cleans up all the memory used by CM.

Author:

    Dragos C. Sambotin (dragoss) 21-Feb-00

Environment:

    This routine is intended to be called at system shutdown
    in order to detect memory leaks. It is supposed to free 
    all registry data that is not freed by CmShutdownSystem.

Revision History:

--*/

#include    "cmp.h"

//
// externals
//
extern  LIST_ENTRY              CmpHiveListHead;
extern  PUCHAR                  CmpStashBuffer;
extern  PCM_KEY_HASH            *CmpCacheTable;
extern  ULONG                   CmpDelayedCloseSize;
extern  CM_DELAYED_CLOSE_ENTRY  *CmpDelayedCloseTable;
extern  PCM_NAME_HASH           *CmpNameCacheTable;

extern  BOOLEAN                 HvShutdownComplete;

extern  BOOLEAN                 CmFirstTime;

extern HIVE_LIST_ENTRY CmpMachineHiveList[];

VOID
CmpFreeAllMemory(
    VOID
    );

VOID
CmpDereferenceNameControlBlockWithLock(
    PCM_NAME_CONTROL_BLOCK   Ncb
    );

VOID
CmpDumpKeyBodyList(
    IN PCM_KEY_CONTROL_BLOCK   kcb,
    IN PULONG                  Count
    );

#ifdef CM_SAVE_KCB_CACHE
VOID
CmpSaveKcbCache(
    VOID
    );
#endif //CM_SAVE_KCB_CACHE

#ifdef ALLOC_PRAGMA
#pragma alloc_text(PAGE,CmpFreeAllMemory)
#pragma alloc_text(PAGE,CmShutdownSystem)

#ifdef CM_SAVE_KCB_CACHE
#pragma alloc_text(PAGE,CmpSaveKcbCache)
#endif //CM_SAVE_KCB_CACHE

#endif


VOID
CmpFreeAllMemory(
    VOID
    )
/*++

Routine Description:

    - All hives are freed
    - KCB table is freed 
    - Name hash table is freed
    - delay close table is freed - question: We need to clean/free all delayed close KCBs
    - all notifications/postblocks-aso.

    * equivalent with MmReleaseAllMemory

Arguments:


Return Value:


--*/

{

    PCMHIVE                 CmHive;
    LONG                    i;
    PCM_KEY_CONTROL_BLOCK   KeyControlBlock;
    PCM_DELAYED_CLOSE_ENTRY DelayedEntry;
    PLIST_ENTRY             NotifyPtr;
    PCM_NOTIFY_BLOCK        NotifyBlock;
    PCM_POST_BLOCK          PostBlock;
    PCM_KEY_HASH            Current;
    PLIST_ENTRY             AnchorAddr;
    ULONG                   Count;
    BOOLEAN                 MessageDisplayed;

    //
    // Iterate through the list of the hives in the system
    //
    while (IsListEmpty(&CmpHiveListHead) == FALSE) {
        //
        // Remove the hive from the list
        //
        CmHive = (PCMHIVE)RemoveHeadList(&CmpHiveListHead);
        CmHive = (PCMHIVE)CONTAINING_RECORD(CmHive,
                                            CMHIVE,
                                            HiveList);

        //
        // close hive handles (the ones that are open)
        //
        for (i=0; i<HFILE_TYPE_MAX; i++) {
            // these should be closed by CmShutdownSystem
            ASSERT( CmHive->FileHandles[i] == NULL );
/*
            if (CmHive->FileHandles[i] != NULL) {
                CmCloseHandle(CmHive->FileHandles[i]);
                CmHive->FileHandles[i] = NULL;
            }

*/        }
        
        //
        // free the hive lock  and view lock
        //
        ASSERT( CmHive->HiveLock != NULL );
        ExFreePool(CmHive->HiveLock);
        ASSERT( CmHive->ViewLock != NULL );
        ExFreePool(CmHive->ViewLock);

/*
DRAGOSS: we don't want ot do that! rather, we want to detect why we still
        have notifications at this point!!!!
        //
        // free notify-related stuff
        //
        NotifyPtr = &(CmHive->NotifyList);
        NotifyPtr = NotifyPtr->Flink;
        while( NotifyPtr != NULL ) {
            NotifyBlock = CONTAINING_RECORD(NotifyPtr, CM_NOTIFY_BLOCK, HiveList);
            
            // free post blocks; we assume that all threads have been terminated at this point
            while (IsListEmpty(&(NotifyBlock->PostList)) == FALSE) {
                PostBlock = (PCM_POST_BLOCK)RemoveHeadList(&(NotifyBlock->PostList));
                PostBlock = CONTAINING_RECORD(PostBlock,
                                              CM_POST_BLOCK,
                                              NotifyList);

                if( PostBlock->PostKeyBody ) {
                    ExFreePool(PostBlock->PostKeyBody);
                }

                if( IsMasterPostBlock(PostBlock) ) {
                    //
                    // this members are allocated only for master post blocks
                    //
                    switch (PostBlockType(PostBlock)) {
                        case PostSynchronous:
                            ExFreePool(PostBlock->u->Sync.SystemEvent);
                            break;
                        case PostAsyncUser:
                            ExFreePool(PostBlock->u->AsyncUser.Apc);
                            break;
                        case PostAsyncKernel:
                            break;
                    }
                    ExFreePool(PostBlock->u);
                }

                ExFreePool(PostBlock);
            }
            NotifyPtr = NotifyPtr->Flink;
            ExFreePool(NotifyBlock);
        }
*/
        //
        // Spew in the debugger the names of the keynodes having notifies still set
        //
        NotifyPtr = &(CmHive->NotifyList);
        NotifyPtr = NotifyPtr->Flink;
        MessageDisplayed = FALSE;
        while( NotifyPtr != NULL ) {
            NotifyBlock = CONTAINING_RECORD(NotifyPtr, CM_NOTIFY_BLOCK, HiveList);
            
            AnchorAddr = &(NotifyBlock->PostList);
            PostBlock = (PCM_POST_BLOCK)(NotifyBlock->PostList.Flink);
            // 
            // walk through the list and spew the keynames and postblock types.
            //
            while ( PostBlock != (PCM_POST_BLOCK)AnchorAddr ) {
                PostBlock = CONTAINING_RECORD(PostBlock,
                                              CM_POST_BLOCK,
                                              NotifyList);

                if( PostBlock->PostKeyBody ) {
                    if( MessageDisplayed == FALSE ){
                        MessageDisplayed = TRUE;
                        DbgPrintEx(DPFLTR_CONFIG_ID,DPFLTR_ERROR_LEVEL,"Dumping untriggered notifications for hive (%lx) (%.*S) \n\n",CmHive,
                            HBASE_NAME_ALLOC / sizeof(WCHAR),CmHive->Hive.BaseBlock->FileName);
                    }
                    switch (PostBlockType(PostBlock)) {
                        case PostSynchronous:
                            DbgPrintEx(DPFLTR_CONFIG_ID,DPFLTR_ERROR_LEVEL,"Synchronous ");
                            break;
                        case PostAsyncUser:
                            DbgPrintEx(DPFLTR_CONFIG_ID,DPFLTR_ERROR_LEVEL,"AsyncUser   ");
                            break;
                        case PostAsyncKernel:
                            DbgPrintEx(DPFLTR_CONFIG_ID,DPFLTR_ERROR_LEVEL,"AsyncKernel ");
                            break;
                    }
                    DbgPrintEx(DPFLTR_CONFIG_ID,DPFLTR_ERROR_LEVEL,"Notification, PostBlock %p not triggered on KCB %p\n",PostBlock,
                        PostBlock->PostKeyBody->KeyBody->KeyControlBlock);
                }


                //
                // skip to the next element
                //
                PostBlock = (PCM_POST_BLOCK)(PostBlock->NotifyList.Flink);

            }
            NotifyPtr = NotifyPtr->Flink;
        }

        //
        // free security cache
        //
        CmpDestroySecurityCache (CmHive);
        
        //
        // free the hv level structure
        //
        HvFreeHive(&(CmHive->Hive));

        //
        // free the cm level structure
        //
        CmpFree(CmHive, sizeof(CMHIVE));
        
    }

    //
    // Now free the CM globals
    //
    
    // the stash buffer
    if( CmpStashBuffer != NULL ) {
        ExFreePool( CmpStashBuffer );
    }

    //
    // first, take care of all delayed closed KCBs
    // free their memory and dereference all the related.
    // name, hint, KeyHash 
    //
    for (i=0; i<(LONG)CmpDelayedCloseSize; i++) {
        DelayedEntry = &(CmpDelayedCloseTable[i]);
        if( DelayedEntry->KeyControlBlock == NULL ) {
            //
            // this is a free entry
            //
            continue;
        }
        
        KeyControlBlock = DelayedEntry->KeyControlBlock;
        ASSERT( KeyControlBlock->DelayedCloseIndex == i );
        ASSERT( KeyControlBlock->RefCount == 0 );
        
        //
        // this will take care of other stuff kcb is pointing on.
        //
        CmpCleanUpKcbCacheWithLock(KeyControlBlock);

    }

    //
    // Spew open handles and associated processes
    //
    Count = 0;
    MessageDisplayed = FALSE;
    for (i=0; i<(LONG)CmpHashTableSize; i++) {
        Current = CmpCacheTable[i];
        while (Current) {
            KeyControlBlock = CONTAINING_RECORD(Current, CM_KEY_CONTROL_BLOCK, KeyHash);
            if( MessageDisplayed == FALSE ){
                MessageDisplayed = TRUE;
                DbgPrintEx(DPFLTR_CONFIG_ID,DPFLTR_ERROR_LEVEL,"\nDumping open handles : \n\n");
            }
            CmpDumpKeyBodyList(KeyControlBlock,&Count);
            Current = Current->NextHash;
        }
    }
    
    if( Count != 0 ) {
        //
        // there some open handles; bugcheck 
        //
        CM_BUGCHECK( REGISTRY_ERROR,HANDLES_STILL_OPEN_AT_SHUTDOWN,1,Count,0);
    }

    //
    // in case of private alloc, free pages 
    //
    CmpDestroyCmPrivateAlloc();
    //
    // For the 3 tables below, the objects actually pointed from inside 
    // should be cleaned up (freed) at the last handle closure time
    // the related handles are closed
    //
    // KCB cache table
    ASSERT( CmpCacheTable != NULL );
    ExFreePool(CmpCacheTable);

    // NameCacheTable
    ASSERT( CmpNameCacheTable != NULL );
    ExFreePool( CmpNameCacheTable );


    // DelayedCloseTable
    ASSERT( CmpDelayedCloseTable != NULL );
    ExFreePool( CmpDelayedCloseTable );

}

#ifdef CMP_STATS
VOID CmpKcbStatDpcRoutine(IN PKDPC Dpc,IN PVOID DeferredContext,IN PVOID SystemArgument1,IN PVOID SystemArgument2);
#endif



#ifdef CM_SAVE_KCB_CACHE

#define CACHE_DMP_FILE_NAME L"Cache.dmp"

VOID
CmpSaveKcbCache(
    VOID
    )
/*++

Routine Description:

    Saves the content of the kcb cache to \system32\config\cache.dmp

    Format of the file:
    [ULONG]         NumberOfKeys
    
    [ULONG]         Length
    [WCHAR*Length]  Path
    [ULONG]         Length
    [WCHAR*Length]  Path
    [ULONG]         Length
    [WCHAR*Length]  Path
    [ULONG]         Length
    [WCHAR*Length]  Path
    [.................]

Arguments:

    NONE

Return Value:

    NONE

--*/
{
    UCHAR                   FileBuffer[MAX_NAME];
    UNICODE_STRING          FileName;
    UNICODE_STRING          TempName;
    HANDLE                  FileHandle;
    NTSTATUS                Status;
    OBJECT_ATTRIBUTES       ObjectAttributes;
    IO_STATUS_BLOCK         IoStatus;
    ULONG                   KcbNo = 0;
    LARGE_INTEGER           Offset;
    ULONG                   FileOffset;
    ULONG                   i;
    PCM_KEY_CONTROL_BLOCK   KeyControlBlock;
    PCM_KEY_HASH            Current;
    PUNICODE_STRING         Name;
    ULONG                   Tmp;
    PCM_DELAYED_CLOSE_ENTRY DelayedEntry;


    PAGED_CODE();

    //
    // first, open the file.
    //
    FileName.MaximumLength = MAX_NAME;
    FileName.Length = 0;
    FileName.Buffer = (PWSTR)&(FileBuffer[0]);

    RtlInitUnicodeString(
        &TempName,
        INIT_SYSTEMROOT_HIVEPATH
        );
    RtlAppendStringToString((PSTRING)&FileName, (PSTRING)&TempName);

    RtlInitUnicodeString(
        &TempName,
        CACHE_DMP_FILE_NAME
        );
    RtlAppendStringToString((PSTRING)&FileName, (PSTRING)&TempName);

    InitializeObjectAttributes(
        &ObjectAttributes,
        &FileName,
        OBJ_CASE_INSENSITIVE | OBJ_KERNEL_HANDLE,
        NULL,
        NULL
        );

    ASSERT_PASSIVE_LEVEL();

    Status = ZwCreateFile(
                &FileHandle,
                FILE_READ_DATA | FILE_WRITE_DATA,
                &ObjectAttributes,
                &IoStatus,
                NULL,                               // alloc size = none
                FILE_ATTRIBUTE_NORMAL,
                0,                                  // share nothing
                FILE_OPEN_IF,
                FILE_RANDOM_ACCESS,
                NULL,                               // eabuffer
                0                                   // ealength
                );
    if( !NT_SUCCESS(Status) ) {
        // bad luck
        return;
    }

    //
    // write the number of kcbs (we'll rewrite it at the end).
    //
    Offset.LowPart = FileOffset = 0;
    Offset.HighPart = 0L;

    Status = ZwWriteFile(FileHandle,
                         NULL,
                         NULL,
                         NULL,
                         &IoStatus,
                         &KcbNo,
                         sizeof(ULONG),
                         &Offset,
                         NULL);
    if( !NT_SUCCESS(Status) ) {
        goto Exit;
    }

    FileOffset = Offset.LowPart + sizeof(ULONG);

    //
    // iterate through the cache and dump all kcbs
    //
    for (i=0; i<CmpHashTableSize; i++) {
        Current = CmpCacheTable[i];
        while (Current) {
            KeyControlBlock = CONTAINING_RECORD(Current, CM_KEY_CONTROL_BLOCK, KeyHash);
            Name = CmpConstructName(KeyControlBlock);
            if( Name ){
                Tmp = (ULONG)Name->Length;
            
                //
                // write off the length
                //
                Offset.LowPart = FileOffset;
                Status = ZwWriteFile(FileHandle,
                                     NULL,
                                     NULL,
                                     NULL,
                                     &IoStatus,
                                     &Tmp,
                                     sizeof(ULONG),
                                     &Offset,
                                     NULL);
                if( !NT_SUCCESS(Status) ) {
                    goto Exit;
                }
                FileOffset = Offset.LowPart + sizeof(ULONG);
               
                //
                // and the buffer
                //
                Offset.LowPart = FileOffset;
                Status = ZwWriteFile(FileHandle,
                                     NULL,
                                     NULL,
                                     NULL,
                                     &IoStatus,
                                     Name->Buffer,
                                     Tmp,
                                     &Offset,
                                     NULL);
                if( !NT_SUCCESS(Status) ) {
                    goto Exit;
                }
                FileOffset = Offset.LowPart + Tmp;

                //
                // record a new kcb and free the name
                //
                KcbNo++;
                ExFreePoolWithTag(Name, CM_NAME_TAG | PROTECTED_POOL);
            }

            Current = Current->NextHash;
        }
    }
    //
    // then, take care of all delayed closed KCBs
    //
    for (i=0; i<CmpDelayedCloseSize; i++) {
        DelayedEntry = &(CmpDelayedCloseTable[i]);
        if( DelayedEntry->KeyControlBlock == NULL ) {
            //
            // this is a free entry
            //
            continue;
        }
        
        KeyControlBlock = DelayedEntry->KeyControlBlock;
        ASSERT( KeyControlBlock->DelayedCloseIndex == i );
        ASSERT( KeyControlBlock->RefCount == 0 );
        
        Name = CmpConstructName(KeyControlBlock);
        if( Name ){
            Tmp = (ULONG)Name->Length;
        
            //
            // write off the length
            //
            Offset.LowPart = FileOffset;
            Status = ZwWriteFile(FileHandle,
                                 NULL,
                                 NULL,
                                 NULL,
                                 &IoStatus,
                                 &Tmp,
                                 sizeof(ULONG),
                                 &Offset,
                                 NULL);
            if( !NT_SUCCESS(Status) ) {
                goto Exit;
            }
            FileOffset = Offset.LowPart + sizeof(ULONG);
           
            //
            // and the buffer
            //
            Offset.LowPart = FileOffset;
            Status = ZwWriteFile(FileHandle,
                                 NULL,
                                 NULL,
                                 NULL,
                                 &IoStatus,
                                 Name->Buffer,
                                 Tmp,
                                 &Offset,
                                 NULL);
            if( !NT_SUCCESS(Status) ) {
                goto Exit;
            }
            FileOffset = Offset.LowPart + Tmp;

            //
            // record a new kcb and free the name
            //
            KcbNo++;
            ExFreePoolWithTag(Name, CM_NAME_TAG | PROTECTED_POOL);
        }
    }

    //
    // write the number of kcbs 
    //
    Offset.LowPart = 0;

    Status = ZwWriteFile(FileHandle,
                         NULL,
                         NULL,
                         NULL,
                         &IoStatus,
                         &KcbNo,
                         sizeof(ULONG),
                         &Offset,
                         NULL);
    if( !NT_SUCCESS(Status) ) {
        goto Exit;
    }
    
    ZwFlushBuffersFile(
                    FileHandle,
                    &IoStatus
                    );
    
Exit:

    CmCloseHandle(FileHandle);
}

#endif //CM_SAVE_KCB_CACHE


VOID
CmShutdownSystem(
    VOID
    )
/*++

Routine Description:

    Shuts down the registry.

Arguments:

    NONE

Return Value:

    NONE

--*/
{

    PLIST_ENTRY p;
    PCMHIVE     CmHive;
    NTSTATUS    Status;
    PVOID       RegistryRoot;

    PAGED_CODE();

    if (CmpRegistryRootHandle) {
        Status = ObReferenceObjectByHandle(CmpRegistryRootHandle,
                                           KEY_READ,
                                           NULL,
                                           KernelMode,
                                           &RegistryRoot,
                                           NULL);

        if (NT_SUCCESS(Status)) {
            // We want to dereference the object twice -- once for the
            // reference we just made, and once for the reference
            // fromCmpCreateRegistryRoot.
            ObDereferenceObject(RegistryRoot);
            ObDereferenceObject(RegistryRoot);
        }

        ObCloseHandle(CmpRegistryRootHandle, KernelMode);
    }
    
    CmpLockRegistryExclusive();

    //
    // Stop the workers; only if registry has been inited
    //
    if( CmFirstTime == FALSE ) {
        CmpShutdownWorkers();
    }

    //
    // shut down the registry
    //
    CmpDoFlushAll(TRUE);

    //
    // try to compress the system hive
    //
    CmCompressKey( &(CmpMachineHiveList[SYSTEM_HIVE_INDEX].CmHive->Hive) );

#ifdef CM_SAVE_KCB_CACHE
    //
    // dump the cache for perf warm-up at next boot
    //
    CmpSaveKcbCache();
#endif //CM_SAVE_KCB_CACHE

    //
    // close all the hive files
    //
    p = CmpHiveListHead.Flink;
    while(p != &CmpHiveListHead) {
        CmHive = CONTAINING_RECORD(p, CMHIVE, HiveList);
        //
        // we need to unmap all views mapped for this hive first
        //
        CmpDestroyHiveViewList(CmHive);
        //
        // dereference the fileobject (if any).
        //
        CmpDropFileObjectForHive(CmHive);

        //
        // now we can safely close all the handles
        //
        CmpCmdHiveClose(CmHive);

        p=p->Flink;
    }

#ifdef CMP_STATS
    // last chance to dump statistics
    if( CmFirstTime == FALSE ) {
        CmpKcbStatDpcRoutine(NULL,NULL,NULL,NULL);
    }
#endif

    HvShutdownComplete = TRUE;      // Tell HvSyncHive to ignore all
                                    // further requests

    if((PoCleanShutdownEnabled() & PO_CLEAN_SHUTDOWN_REGISTRY) && (CmFirstTime == FALSE)){
        //
        // Free aux memory used internally by CM
        //
        CmpFreeAllMemory();
    }

    CmpUnlockRegistry();
    return;
}
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\base\ntos\config\cmhook.c ===
/*++

Copyright (c) 20001 Microsoft Corporation

Module Name:

    cmhook.c

Abstract:

    Provides routines for implementing callbacks into the registry code.
    Callbacks are to be used by the virus filter drivers and cluster 
    replication engine.

Author:

    Dragos C. Sambotin (DragosS) 20-Mar-2001

Revision History:


--*/
#include "cmp.h"

#define CM_MAX_CALLBACKS    100  //TBD

typedef struct _CM_CALLBACK_CONTEXT_BLOCK {
    LARGE_INTEGER               Cookie;             // to identify a specific callback for deregistration purposes
    LIST_ENTRY                  ThreadListHead;     // Active threads inside this callback
    FAST_MUTEX                  ThreadListLock;     // syncronize access to the above
    PVOID                       CallerContext;
} CM_CALLBACK_CONTEXT_BLOCK, *PCM_CALLBACK_CONTEXT_BLOCK;

typedef struct _CM_ACTIVE_NOTIFY_THREAD {
    LIST_ENTRY  ThreadList;
    PETHREAD    Thread;
} CM_ACTIVE_NOTIFY_THREAD, *PCM_ACTIVE_NOTIFY_THREAD;

#ifdef ALLOC_DATA_PRAGMA
#pragma data_seg("PAGEDATA")
#endif

ULONG       CmpCallBackCount = 0;
EX_CALLBACK CmpCallBackVector[CM_MAX_CALLBACKS];


VOID
CmpInitCallback(VOID);

BOOLEAN
CmpCheckRecursionAndRecordThreadInfo(
                                     PCM_CALLBACK_CONTEXT_BLOCK         CallbackBlock,
                                     PCM_ACTIVE_NOTIFY_THREAD   ActiveThreadInfo
                                     );

#ifdef ALLOC_PRAGMA
#pragma alloc_text(PAGE,CmRegisterCallback)
#pragma alloc_text(PAGE,CmUnRegisterCallback)
#pragma alloc_text(PAGE,CmpInitCallback)
#pragma alloc_text(PAGE,CmpCallCallBacks)
#pragma alloc_text(PAGE,CmpCheckRecursionAndRecordThreadInfo)
#endif


NTSTATUS
CmRegisterCallback(IN PEX_CALLBACK_FUNCTION Function,
                   IN PVOID                 Context,
                   IN OUT PLARGE_INTEGER    Cookie
                    )
/*++

Routine Description:

    Registers a new callback.

Arguments:



Return Value:


--*/
{
    PEX_CALLBACK_ROUTINE_BLOCK  RoutineBlock;
    ULONG                       i;
    PCM_CALLBACK_CONTEXT_BLOCK  CmCallbackContext;

    PAGED_CODE();
    
    CmCallbackContext = (PCM_CALLBACK_CONTEXT_BLOCK)ExAllocatePoolWithTag (PagedPool,
                                                                    sizeof (CM_CALLBACK_CONTEXT_BLOCK),
                                                                    'bcMC');
    if( CmCallbackContext == NULL ) {
        return STATUS_INSUFFICIENT_RESOURCES;
    }

    RoutineBlock = ExAllocateCallBack (Function,CmCallbackContext);
    if( RoutineBlock == NULL ) {
        ExFreePool(CmCallbackContext);
        return STATUS_INSUFFICIENT_RESOURCES;
    }

    //
    // init the context
    //
    KeQuerySystemTime(&(CmCallbackContext->Cookie));
    *Cookie = CmCallbackContext->Cookie;
    InitializeListHead(&(CmCallbackContext->ThreadListHead));   
	ExInitializeFastMutex(&(CmCallbackContext->ThreadListLock));
    CmCallbackContext->CallerContext = Context;

    //
    // find a spot where we could add this callback
    //
    for( i=0;i<CM_MAX_CALLBACKS;i++) {
        if( ExCompareExchangeCallBack (&CmpCallBackVector[i],RoutineBlock,NULL) ) {
            InterlockedExchangeAdd ((PLONG) &CmpCallBackCount, 1);
            return STATUS_SUCCESS;
        }
    }
    
    //
    // no more callbacks
    //
    ExFreePool(CmCallbackContext);
    ExFreeCallBack(RoutineBlock);
    return STATUS_INSUFFICIENT_RESOURCES;
}


NTSTATUS
CmUnRegisterCallback(IN LARGE_INTEGER  Cookie)
/*++

Routine Description:

    Unregisters a callback.

Arguments:



Return Value:


--*/
{
    ULONG                       i;
    PCM_CALLBACK_CONTEXT_BLOCK  CmCallbackContext;
    PEX_CALLBACK_ROUTINE_BLOCK  RoutineBlock;
    NTSTATUS                    Status;

    PAGED_CODE();
    
    //
    // Search for this cookie
    //
    for( i=0;i<CM_MAX_CALLBACKS;i++) {
        RoutineBlock = ExReferenceCallBackBlock(&(CmpCallBackVector[i]) );
        if( RoutineBlock  ) {
            CmCallbackContext = (PCM_CALLBACK_CONTEXT_BLOCK)ExGetCallBackBlockContext(RoutineBlock);
            if( CmCallbackContext && (CmCallbackContext->Cookie.QuadPart  == Cookie.QuadPart) ) {
                //
                // found it
                //
                if( ExCompareExchangeCallBack (&CmpCallBackVector[i],NULL,RoutineBlock) ) {
                    InterlockedExchangeAdd ((PLONG) &CmpCallBackCount, -1);
    
                    ExDereferenceCallBackBlock (&(CmpCallBackVector[i]),RoutineBlock);
                    //
                    // wait for others to release their reference, then tear down the structure
                    //
                    ExWaitForCallBacks (RoutineBlock);

                    ExFreePool(CmCallbackContext);
                    ExFreeCallBack(RoutineBlock);
                    return STATUS_SUCCESS;
                }

            } else {
                ExDereferenceCallBackBlock (&(CmpCallBackVector[i]),RoutineBlock);
            }
        }
            
    }

    return STATUS_INVALID_PARAMETER;
}

NTSTATUS CmpTestCallback(
    IN PVOID CallbackContext,
    IN PVOID Argument1,
    IN PVOID Argument2
    );

//
// Cm internals
//
NTSTATUS
CmpCallCallBacks (
    IN REG_NOTIFY_CLASS Type,
    IN PVOID Argument
    )
/*++

Routine Description:

    This function calls the callback thats inside a callback structure

Arguments:

    Type - Nt call selector

    Argument - Caller provided argument to pass on (one of the REG_*_INFORMATION )

Return Value:

    NTSTATUS - STATUS_SUCCESS or error status returned by the first callback

--*/
{
    NTSTATUS                    Status;
    ULONG                       i;
    PEX_CALLBACK_ROUTINE_BLOCK  RoutineBlock;
    PCM_CALLBACK_CONTEXT_BLOCK  CmCallbackContext;

    PAGED_CODE();

    for(i=0;i<CM_MAX_CALLBACKS;i++) {
        RoutineBlock = ExReferenceCallBackBlock(&(CmpCallBackVector[i]) );
        if( RoutineBlock != NULL ) {
            //
            // we have a safe reference on this block.
            //
            //
            // record thread on a stack struct, so we don't need to allocate pool for it. We unlink
            // it from our lists prior to this function exit, so we are on the safe side.
            //
            CM_ACTIVE_NOTIFY_THREAD ActiveThreadInfo;
            
            //
            // get context info
            //
            CmCallbackContext = (PCM_CALLBACK_CONTEXT_BLOCK)ExGetCallBackBlockContext(RoutineBlock);
            ASSERT( CmCallbackContext != NULL );

            ActiveThreadInfo.Thread = PsGetCurrentThread();
#if DBG
            InitializeListHead(&(ActiveThreadInfo.ThreadList));   
#endif //DBG

            if( CmpCheckRecursionAndRecordThreadInfo(CmCallbackContext,&ActiveThreadInfo) ) {
                Status = ExGetCallBackBlockRoutine(RoutineBlock)(CmCallbackContext->CallerContext,(PVOID)Type,Argument);
                //
                // now that we're down, remove ourselves from the thread list
                //
                ExAcquireFastMutex(&(CmCallbackContext->ThreadListLock));
                RemoveEntryList(&(ActiveThreadInfo.ThreadList));
                ExReleaseFastMutex(&(CmCallbackContext->ThreadListLock));
            } else {
                ASSERT( IsListEmpty(&(ActiveThreadInfo.ThreadList)) );
            }

            ExDereferenceCallBackBlock (&(CmpCallBackVector[i]),RoutineBlock);

            if( !NT_SUCCESS(Status) ) {
                //
                // don't bother calling other callbacks if this one vetoed.
                //
                return Status;
            }
        }
    }
    return STATUS_SUCCESS;
}

VOID
CmpInitCallback(VOID)
/*++

Routine Description:

    Init the callback module

Arguments:



Return Value:


--*/
{
    ULONG   i;

    PAGED_CODE();
    
    CmpCallBackCount = 0;
    for( i=0;i<CM_MAX_CALLBACKS;i++) {
        ExInitializeCallBack (&(CmpCallBackVector[i]));
    }

/*
    {
        LARGE_INTEGER Cookie;
        if( NT_SUCCESS(CmRegisterCallback(CmpTestCallback,NULL,&Cookie) ) ) {
            DbgPrint("Test Hooks installed\n");
        }
    }
*/
}

BOOLEAN
CmpCheckRecursionAndRecordThreadInfo(
                                     PCM_CALLBACK_CONTEXT_BLOCK CallbackBlock,
                                     PCM_ACTIVE_NOTIFY_THREAD   ActiveThreadInfo
                                     )
/*++

Routine Description:

    Checks if current thread is already inside the callback (recursion avoidance)

Arguments:


Return Value:


--*/
{
    PLIST_ENTRY                 AnchorAddr;
    PCM_ACTIVE_NOTIFY_THREAD    CurrentThreadInfo;

    PAGED_CODE();

    ExAcquireFastMutex(&(CallbackBlock->ThreadListLock));

    //
	// walk the ActiveThreadList and see if we are already active
	//
	AnchorAddr = &(CallbackBlock->ThreadListHead);
	CurrentThreadInfo = (PCM_ACTIVE_NOTIFY_THREAD)(CallbackBlock->ThreadListHead.Flink);

	while ( CurrentThreadInfo != (PCM_ACTIVE_NOTIFY_THREAD)AnchorAddr ) {
		CurrentThreadInfo = CONTAINING_RECORD(
						                    CurrentThreadInfo,
						                    CM_ACTIVE_NOTIFY_THREAD,
						                    ThreadList
						                    );
		if( CurrentThreadInfo->Thread == ActiveThreadInfo->Thread ) {
			//
			// already there!
			//
            ExReleaseFastMutex(&(CallbackBlock->ThreadListLock));
            return FALSE;
		}
        //
        // skip to the next element
        //
        CurrentThreadInfo = (PCM_ACTIVE_NOTIFY_THREAD)(CurrentThreadInfo->ThreadList.Flink);
	}

    //
    // add this thread
    //
    InsertTailList(&(CallbackBlock->ThreadListHead), &(ActiveThreadInfo->ThreadList));
    ExReleaseFastMutex(&(CallbackBlock->ThreadListLock));
    return TRUE;
}

//
// test hook procedure
//

BOOLEAN CmpCallbackSpew = FALSE;

NTSTATUS CmpTestCallback(
    IN PVOID CallbackContext,
    IN PVOID Argument1,
    IN PVOID Argument2
    )
{
    REG_NOTIFY_CLASS Type;

    PAGED_CODE();
    
    if( !CmpCallbackSpew ) return STATUS_SUCCESS;

    Type = (REG_NOTIFY_CLASS)Argument1;
    switch( Type ) {
    case RegNtDeleteKey:
        {
            PREG_DELETE_KEY_INFORMATION  pDelete = (PREG_DELETE_KEY_INFORMATION)Argument2;
            //
            // Code to handle NtDeleteKey
            //
            DbgPrint("Callback(NtDeleteKey) called, arg = %p\n",pDelete);
        }
        break;
    case RegNtSetValueKey:
        {
            PREG_SET_VALUE_KEY_INFORMATION  pSetValue = (PREG_SET_VALUE_KEY_INFORMATION)Argument2;
            //
            // Code to handle NtSetValueKey
            //
            DbgPrint("Callback(NtSetValueKey) called, arg = %p\n",pSetValue);
        }
        break;
    case RegNtDeleteValueKey:
        {
            PREG_DELETE_VALUE_KEY_INFORMATION  pDeteteValue = (PREG_DELETE_VALUE_KEY_INFORMATION)Argument2;
            //
            // Code to handle NtDeleteValueKey
            //
            DbgPrint("Callback(NtDeleteValueKey) called, arg = %p\n",pDeteteValue);
        }
        break;
    case RegNtSetInformationKey:
        {
            PREG_SET_INFORMATION_KEY_INFORMATION  pSetInfo = (PREG_SET_INFORMATION_KEY_INFORMATION)Argument2;
            //
            // Code to handle NtSetInformationKey
            //
            DbgPrint("Callback(NtSetInformationKey) called, arg = %p\n",pSetInfo);
        }
        break;
    default:
        DbgPrint("Callback(%lx) called, arg = %p - We don't handle this call\n",(ULONG)Type,Argument2);
        break;
    }
    
    return STATUS_SUCCESS;
}
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\base\ntos\config\cmindex.c ===
//depot/main/Base/ntos/config/cmindex.c#12 - integrate change 19035 (text)
/*++

Copyright (c) 1991  Microsoft Corporation

Module Name:

    cmindex.c

Abstract:

    This module contains cm routines that understand the structure
    of child subkey indicies.

Author:

    Bryan M. Willman (bryanwi) 21-Apr-92

Revision History:

--*/

/*

The Structure:

    Use a 1 or 2 level tree.  Leaf nodes are arrays of pointers to
    cells, sorted.  Binary search to find cell of interest.  Directory
    node (can be only one) is an array of pointers to leaf blocks.
    Do compare on last entry of each leaf block.

    One Level:

        Key--->+----+
               |    |
               |  x----------><key whose name is "apple", string in key>
               |    |
               +----+
               |    |
               |  x----------><as above, but key named "banana">
               |    |
               +----+
               |    |
               |    |
               |    |
               +----+
               |    |
               |    |
               |    |
               +----+
               |    |
               |  x----------><as above, but key named "zumwat">
               |    |
               +----+


    Two Level:

        Key--->+----+
               |    |    +-----+
               |  x----->|     |
               |    |    |  x----------------->"aaa"
               +----+    |     |
               |    |    +-----+
               |    |    |     |
               |    |    |     |
               +----+    |     |
               |    |    +-----+
               |    |    |     |
               |    |    |  x----------------->"abc"
               +----+    |     |
               |    |    +-----+
               |    |
               |    |
               +----+
               |    |    +-----+
               |  x----->|     |
               |    |    |  x----------------->"w"
               +----+    |     |
                         +-----+
                         |     |
                         |     |
                         |     |
                         +-----+
                         |     |
                         |  x----------------->"z"
                         |     |
                         +-----+


    Never more than two levels.

    Each block must fix in on HBLOCK_SIZE Cell.  Allows about 1000
    entries.  Max of 1 million total, best case.  Worst case something
    like 1/4 of that.

*/

#include    "cmp.h"

ULONG
CmpFindSubKeyInRoot(
    PHHIVE          Hive,
    PCM_KEY_INDEX   Index,
    PUNICODE_STRING SearchName,
    PHCELL_INDEX    Child
    );

ULONG
CmpFindSubKeyInLeaf(
    PHHIVE          Hive,
    PCM_KEY_INDEX   Index,
    PUNICODE_STRING SearchName,
    PHCELL_INDEX    Child
    );

LONG
CmpCompareInIndex(
    PHHIVE          Hive,
    PUNICODE_STRING SearchName,
    ULONG           Count,
    PCM_KEY_INDEX   Index,
    PHCELL_INDEX    Child
    );

LONG
CmpDoCompareKeyName(
    PHHIVE          Hive,
    PUNICODE_STRING SearchName,
    HCELL_INDEX     Cell
    );

HCELL_INDEX
CmpDoFindSubKeyByNumber(
    PHHIVE          Hive,
    PCM_KEY_INDEX   Index,
    ULONG           Number
    );

HCELL_INDEX
CmpAddToLeaf(
    PHHIVE          Hive,
    HCELL_INDEX     LeafCell,
    HCELL_INDEX     NewKey,
    PUNICODE_STRING NewName
    );

HCELL_INDEX
CmpSelectLeaf(
    PHHIVE          Hive,
    PCM_KEY_NODE    ParentKey,
    PUNICODE_STRING NewName,
    HSTORAGE_TYPE   Type,
    PHCELL_INDEX    *RootPointer
    );

HCELL_INDEX
CmpSplitLeaf(
    PHHIVE          Hive,
    HCELL_INDEX     RootCell,
    ULONG           RootSelect,
    HSTORAGE_TYPE   Type
    );

HCELL_INDEX
CmpFindSubKeyByHash(
    PHHIVE                  Hive,
    PCM_KEY_FAST_INDEX      FastIndex,
    PUNICODE_STRING         SearchName
    );

#ifdef ALLOC_PRAGMA
#pragma alloc_text(PAGE,CmpFindSubKeyByName)
#pragma alloc_text(PAGE,CmpFindSubKeyInRoot)
#pragma alloc_text(PAGE,CmpFindSubKeyInLeaf)
#pragma alloc_text(PAGE,CmpDoCompareKeyName)
#pragma alloc_text(PAGE,CmpCompareInIndex)
#pragma alloc_text(PAGE,CmpFindSubKeyByNumber)
#pragma alloc_text(PAGE,CmpDoFindSubKeyByNumber)
#pragma alloc_text(PAGE,CmpAddSubKey)
#pragma alloc_text(PAGE,CmpAddToLeaf)
#pragma alloc_text(PAGE,CmpSelectLeaf)
#pragma alloc_text(PAGE,CmpSplitLeaf)
#pragma alloc_text(PAGE,CmpMarkIndexDirty)
#pragma alloc_text(PAGE,CmpRemoveSubKey)
#pragma alloc_text(PAGE,CmpComputeHashKey)
#pragma alloc_text(PAGE,CmpComputeHashKeyForCompressedName)
#pragma alloc_text(PAGE,CmpFindSubKeyByHash)

#ifdef NT_RENAME_KEY
#pragma alloc_text(PAGE,CmpDuplicateIndex)
#pragma alloc_text(PAGE,CmpUpdateParentForEachSon)
#endif //NT_RENAME_KEY

#pragma alloc_text(PAGE,CmpRemoveSubKeyCellNoCellRef)
#endif


HCELL_INDEX
CmpFindSubKeyByName(
    PHHIVE          Hive,
    PCM_KEY_NODE    Parent,
    PUNICODE_STRING SearchName
    )
/*++

Routine Description:

    Find the child cell (either subkey or value) specified by name.

Arguments:

    Hive - pointer to hive control structure for hive of interest

    Parent - cell of key body which is parent of child of interest

    SearchName - name of child of interest

Return Value:

    Cell of matching child key, or HCELL_NIL if none.

--*/
{
    PCM_KEY_INDEX   IndexRoot;
    HCELL_INDEX     Child;
    ULONG           i;
    ULONG           FoundIndex;
    HCELL_INDEX     CellToRelease = HCELL_NIL;

#ifndef _CM_LDR_
    PAGED_CODE();
#endif //_CM_LDR_

    CmKdPrintEx((DPFLTR_CONFIG_ID,CML_INDEX,"CmpFindSubKeyByName:\n\t"));
    CmKdPrintEx((DPFLTR_CONFIG_ID,CML_INDEX,"Hive=%p Parent=%p SearchName=%p\n", Hive, Parent, SearchName));

    //
    // Try first the Stable, then the Volatile store.  Assumes that
    // all Volatile refs in Stable space are zeroed out at boot.
    //
    for (i = 0; i < Hive->StorageTypeCount; i++) {
        if (Parent->SubKeyCounts[i] != 0) {
            IndexRoot = (PCM_KEY_INDEX)HvGetCell(Hive, Parent->SubKeyLists[i]);
            ASSERT( (IndexRoot == NULL) || HvIsCellAllocated(Hive, Parent->SubKeyLists[i]) );
            if( IndexRoot == NULL ) {
                //
                // we couldn't map a view for the bin containing this cell
                //
                return HCELL_NIL;
            }
            CellToRelease = Parent->SubKeyLists[i];

            if (IndexRoot->Signature == CM_KEY_INDEX_ROOT) {
                if( INVALID_INDEX & CmpFindSubKeyInRoot(Hive, IndexRoot, SearchName, &Child) ) {
                    //
                    // couldn't map view inside
                    //
                    ASSERT( CellToRelease != HCELL_NIL );
                    HvReleaseCell(Hive,CellToRelease);
                    return HCELL_NIL;
                }

                ASSERT( CellToRelease != HCELL_NIL );
                HvReleaseCell(Hive,CellToRelease);

                if (Child == HCELL_NIL) {
                    continue;
                }
                IndexRoot = (PCM_KEY_INDEX)HvGetCell(Hive, Child);
                if( IndexRoot == NULL ) {
                    //
                    // we couldn't map a view for the bin containing this cell
                    //
                    return HCELL_NIL;
                }
                CellToRelease = Child;
            }
            ASSERT((IndexRoot->Signature == CM_KEY_INDEX_LEAF)  ||
                   (IndexRoot->Signature == CM_KEY_FAST_LEAF)   ||
                   (IndexRoot->Signature == CM_KEY_HASH_LEAF)
                   );


            if( IndexRoot->Signature == CM_KEY_HASH_LEAF ) {
                Child = CmpFindSubKeyByHash(Hive,(PCM_KEY_FAST_INDEX)IndexRoot,SearchName);
                ASSERT( CellToRelease != HCELL_NIL );
                HvReleaseCell(Hive,CellToRelease);
            } else {
                FoundIndex = CmpFindSubKeyInLeaf(Hive,
                                                 IndexRoot,
                                                 SearchName,
                                                 &Child);

                ASSERT( CellToRelease != HCELL_NIL );
                HvReleaseCell(Hive,CellToRelease);

                if( INVALID_INDEX & FoundIndex ) {
                    //
                    // couldn't map view
                    // 
                    return HCELL_NIL;
                }
            }

            if (Child != HCELL_NIL) {
                //
                // success
                //
                return Child;
            }
        }
    }
#if 0 //DBG
	//
	// Validation code. manually search for the key and break when found
	//
	if (Parent->SubKeyCounts[Stable] != 0) {
		ULONG			Cnt1,Cnt2;
		LONG			Result;
		HCELL_INDEX		Cell;
		PCM_KEY_INDEX   Leaf;
		PCM_KEY_INDEX   DbgIndexRoot = (PCM_KEY_INDEX)HvGetCell(Hive, Parent->SubKeyLists[Stable]);

		if(DbgIndexRoot->Signature == CM_KEY_INDEX_ROOT ) {
			for(Cnt1=0;Cnt1<DbgIndexRoot->Count;Cnt1++) {
				Leaf = (PCM_KEY_INDEX)HvGetCell(Hive, DbgIndexRoot->List[Cnt1]);			
				for( Cnt2=0;Cnt2<Leaf->Count;Cnt2++) {
					Result = CmpCompareInIndex(	Hive,
												SearchName,
												Cnt2,
												Leaf,
												&Cell);

					if( Result == 0 ) {
						//
						// Found it !!! Error above !!!
						//
						DbgPrint("CmpFindSubKeyByName: Hive = %p, Parent = %p, SearchName = %p\n",Hive,Parent,SearchName);
						DbgPrint("                   : IndexRoot = %p, DbgIndexRoot = %p, Cnt1 = %lx, Cnt2 = %lx\n",IndexRoot,DbgIndexRoot,Cnt1,Cnt2);
						DbgPrint("                   : Leaf = %p\n",Leaf);

						DbgBreakPoint();

					}
					
				}
                HvReleaseCell(Hive,DbgIndexRoot->List[Cnt1]);
			}
		}
		HvReleaseCell(Hive,Parent->SubKeyLists[Stable]);
	}

#endif //0

    return HCELL_NIL;
}


ULONG
CmpFindSubKeyInRoot(
    PHHIVE          Hive,
    PCM_KEY_INDEX   Index,
    PUNICODE_STRING SearchName,
    PHCELL_INDEX    Child
    )
/*++

Routine Description:

    Find the leaf index that would contain a key, if there is one.

Arguments:

    Hive - pointer to hive control structure for hive of interest

    Index - pointer to root index block

    SearchName - pointer to name of key of interest

    Child - pointer to variable to receive hcell_index of found leaf index
            block, HCELL_NIL if none.  Non nil does not necessarily mean
            the key is present, call FindSubKeyInLeaf to decide that.

Return Value:

    Index in List of last Leaf Cell entry examined.  If Child != HCELL_NIL,
    Index is entry that matched, else, index is for last entry we looked
    at.  (Target Leaf will be this value plus or minus 1)

    If an error appears while searching the subkey (i.e. a cell cannot be 
    mapped into memory) INVALID_INDEX is returned.

--*/
{
    ULONG           High;
    ULONG           Low;
    ULONG           CanCount;
    HCELL_INDEX     LeafCell;
    PCM_KEY_INDEX   Leaf;
    LONG            Result;
    ULONG           ReturnIndex = INVALID_INDEX;

    CmKdPrintEx((DPFLTR_CONFIG_ID,CML_INDEX,"CmpFindSubKeyInRoot:\n\t"));
    CmKdPrintEx((DPFLTR_CONFIG_ID,CML_INDEX,"Hive=%p Index=%p SearchName=%p\n",Hive,Index,SearchName));


    ASSERT(Index->Count != 0);
    ASSERT(Index->Signature == CM_KEY_INDEX_ROOT);

    High = Index->Count - 1;
    Low = 0;

    while (TRUE) {

        //
        // Compute where to look next, get correct pointer, do compare
        //
        CanCount = ((High-Low)/2)+Low;
        LeafCell = Index->List[CanCount];
        Leaf = (PCM_KEY_INDEX)HvGetCell(Hive, LeafCell);
        if( Leaf == NULL ) {
            //
            // we couldn't map the bin containing this cell
            //
            *Child = HCELL_NIL;
            ReturnIndex = INVALID_INDEX;
            goto JustReturn;
        }

        ASSERT((Leaf->Signature == CM_KEY_INDEX_LEAF) ||
               (Leaf->Signature == CM_KEY_FAST_LEAF)  || 
               (Leaf->Signature == CM_KEY_HASH_LEAF)
               );
        ASSERT(Leaf->Count != 0);

        Result = CmpCompareInIndex(Hive,
                                   SearchName,
                                   Leaf->Count-1,
                                   Leaf,
                                   Child);

        if( Result == 2 ) {
            //
            // couldn't map view inside; bail out
            //
            *Child = HCELL_NIL;
            ReturnIndex = INVALID_INDEX;
            goto JustReturn;
        }
        if (Result == 0) {

            //
            // SearchName == KeyName of last key in leaf, so
            //  this is our leaf
            //
            *Child = LeafCell;
            ReturnIndex = CanCount;
            goto JustReturn;
        }

        if (Result < 0) {

            ASSERT( Result == -1 );
            //
            // SearchName < KeyName, so this may still be our leaf
            //
            Result = CmpCompareInIndex(Hive,
                                       SearchName,
                                       0,
                                       Leaf,
                                       Child);

            if( Result == 2 ) {
                //
                // couldn't map view inside; bail out
                //
                *Child = HCELL_NIL;
                ReturnIndex = INVALID_INDEX;
                goto JustReturn;
            }

            if (Result >= 0) {

                ASSERT( (Result == 1) || (Result == 0) );
                //
                // we know from above that SearchName is less than
                // last key in leaf.
                // since it is also >= first key in leaf, it must
                // reside in leaf somewhere, and we are done
                //
                *Child = LeafCell;
                ReturnIndex = CanCount;
                goto JustReturn;
            }

            High = CanCount;

        } else {

            //
            // SearchName > KeyName
            //
            Low = CanCount;
        }

        if ((High - Low) <= 1) {
            break;
        }
        HvReleaseCell(Hive, LeafCell);
    }

    HvReleaseCell(Hive, LeafCell);
    //
    // If we get here, High - Low = 1 or High == Low
    //
    ASSERT((High - Low == 1) || (High == Low));
    LeafCell = Index->List[Low];
    Leaf = (PCM_KEY_INDEX)HvGetCell(Hive, LeafCell);
    if( Leaf == NULL ) {
        //
        // we couldn't map the bin containing this cell
        //
        *Child = HCELL_NIL;
        ReturnIndex = INVALID_INDEX;
        goto JustReturn;
    }
    Result = CmpCompareInIndex(Hive,
                               SearchName,
                               Leaf->Count-1,
                               Leaf,
                               Child);

    if( Result == 2 ) {
        //
        // couldn't map view inside; bail out
        //
        *Child = HCELL_NIL;
        ReturnIndex = INVALID_INDEX;
        goto JustReturn;
    }

    if (Result == 0) {

        //
        // found it
        //
        *Child = LeafCell;
        ReturnIndex = Low;
        goto JustReturn;
    }

    if (Result < 0) {

        ASSERT( Result == -1 );
        //
        // SearchName < KeyName, so this may still be our leaf
        //
        Result = CmpCompareInIndex(Hive,
                                   SearchName,
                                   0,
                                   Leaf,
                                   Child);

        if( Result == 2 ) {
            //
            // couldn't map view inside; bail out
            //
            *Child = HCELL_NIL;
            ReturnIndex = INVALID_INDEX;
            goto JustReturn;
        }

        if (Result >= 0) {

            ASSERT( (Result == 1) || (Result == 0) );
            //
            // we know from above that SearchName is less than
            // last key in leaf.
            // since it is also >= first key in leaf, it must
            // reside in leaf somewhere, and we are done
            //
            *Child = LeafCell;
            ReturnIndex = Low;
            goto JustReturn;
        }

        //
        // does not exist, but belongs in Low or Leaf below low
        //
        *Child = HCELL_NIL;
        ReturnIndex = Low;
        goto JustReturn;
    }

    HvReleaseCell(Hive, LeafCell);
    //
    // see if High matches
    //
    LeafCell = Index->List[High];
    Leaf = (PCM_KEY_INDEX)HvGetCell(Hive, LeafCell);
    if( Leaf == NULL ) {
        //
        // we couldn't map the bin containing this cell
        //
        *Child = HCELL_NIL;
        ReturnIndex = INVALID_INDEX;
        goto JustReturn;
    }
    Result = CmpCompareInIndex(Hive,
                               SearchName,
                               Leaf->Count - 1,
                               Leaf,
                               Child);
    if( Result == 2 ) {
        //
        // couldn't map view inside; bail out
        //
        *Child = HCELL_NIL;
        ReturnIndex = INVALID_INDEX;
        goto JustReturn;
    }
    if (Result == 0) {

        //
        // found it
        //
        *Child = LeafCell;
        ReturnIndex = High;
        goto JustReturn;

    } else if (Result < 0) {

        ASSERT( Result == -1 );
        //
        // Clearly greater than low, or we wouldn't be here.
        // So regardless of whether it's below the start
        // of this leaf, it would be in this leaf if it were
        // where, so report this leaf.
        //
        *Child = LeafCell;
        ReturnIndex = High;
        goto JustReturn;

    }

    //
    // Off the high end
    //
    *Child = HCELL_NIL;
    ReturnIndex = High;

JustReturn:
    if(Leaf != NULL){
        HvReleaseCell(Hive, LeafCell);
    }
    return ReturnIndex;
}


ULONG
CmpFindSubKeyInLeaf(
    PHHIVE          Hive,
    PCM_KEY_INDEX   Index,
    PUNICODE_STRING SearchName,
    PHCELL_INDEX    Child
    )
/*++

Routine Description:

    Find a named key in a leaf index, if it exists. The supplied index
    may be either a fast index or a slow one.

Arguments:

    Hive - pointer to hive control structure for hive of interest

    Index - pointer to leaf block

    SearchName - pointer to name of key of interest

    Child - pointer to variable to receive hcell_index of found key
            HCELL_NIL if none found

Return Value:

    Index in List of last cell.  If Child != HCELL_NIL, is offset in
    list at which Child was found.  Else, is offset of last place
    we looked.

    INVALID_INDEX - resources problem; couldn't map view
--*/
{
    ULONG       High;
    ULONG       Low;
    ULONG       CanCount;
    LONG        Result;

    CmKdPrintEx((DPFLTR_CONFIG_ID,CML_INDEX,"CmpFindSubKeyInLeaf:\n\t"));
    CmKdPrintEx((DPFLTR_CONFIG_ID,CML_INDEX,"Hive=%p Index=%p SearchName=%p\n",Hive,Index,SearchName));

    ASSERT((Index->Signature == CM_KEY_INDEX_LEAF)  ||
           (Index->Signature == CM_KEY_FAST_LEAF)   ||
           (Index->Signature == CM_KEY_HASH_LEAF)
           );

    High = Index->Count - 1;
    Low = 0;
    CanCount = High/2;

    if (Index->Count == 0) {
        *Child = HCELL_NIL;
        return 0;
    }

    while (TRUE) {

        //
        // Compute where to look next, get correct pointer, do compare
        //
        Result = CmpCompareInIndex(Hive,
                                   SearchName,
                                   CanCount,
                                   Index,
                                   Child);

        if( Result == 2 ) {
            //
            // couldn't map view inside; bail out
            //
            *Child = HCELL_NIL;
            return INVALID_INDEX;
        }

        if (Result == 0) {

            //
            // SearchName == KeyName
            //
            return CanCount;
        }

        if (Result < 0) {

            ASSERT( Result == -1 );
            //
            // SearchName < KeyName
            //
            High = CanCount;

        } else {

            ASSERT( Result == 1 );
            //
            // SearchName > KeyName
            //
            Low = CanCount;
        }

        if ((High - Low) <= 1) {
            break;
        }
        CanCount = ((High-Low)/2)+Low;
    }

    //
    // If we get here, High - Low = 1 or High == Low
    // Simply look first at Low, then at High
    //
    Result = CmpCompareInIndex(Hive,
                               SearchName,
                               Low,
                               Index,
                               Child);
    if( Result == 2 ) {
        //
        // couldn't map view inside; bail out
        //
        *Child = HCELL_NIL;
        return INVALID_INDEX;
    }

    if (Result == 0) {

        //
        // found it
        //
        return Low;
    }

    if (Result < 0) {

        ASSERT( Result == -1 );
        //
        // does not exist, under
        //
        return Low;
    }

    //
    // see if High matches, we will return High as the
    // closest key regardless.
    //
    Result = CmpCompareInIndex(Hive,
                               SearchName,
                               High,
                               Index,
                               Child);
    if( Result == 2 ) {
        //
        // couldn't map view inside; bail out
        //
        *Child = HCELL_NIL;
        return INVALID_INDEX;
    }

    return High;
}


LONG
CmpCompareInIndex(
    PHHIVE          Hive,
    PUNICODE_STRING SearchName,
    ULONG           Count,
    PCM_KEY_INDEX   Index,
    PHCELL_INDEX    Child
    )
/*++

Routine Description:

    Do a compare of a name in an index. This routine handles both
    fast leafs and slow ones.

Arguments:

    Hive - pointer to hive control structure for hive of interest

    SearchName - pointer to name of key we are searching for

    Count - supplies index that we are searching at.

    Index - Supplies pointer to either a CM_KEY_INDEX or
            a CM_KEY_FAST_INDEX. This routine will determine which
            type of index it is passed.

    Child - pointer to variable to receive hcell_index of found key
            HCELL_NIL if result != 0

Return Value:

    0 = SearchName == KeyName (of Cell)

    -1 = SearchName < KeyName

    +1 = SearchName > KeyName

    +2 = Error, insufficient resources

--*/
{
    PCM_KEY_FAST_INDEX  FastIndex;
    LONG                Result;
    ULONG               i;
    WCHAR               c1;
    WCHAR               c2;
    ULONG               HintLength;
    ULONG               ValidChars;
    ULONG               NameLength;
    PCM_INDEX           Hint;

    *Child = HCELL_NIL;
    if ( (Index->Signature == CM_KEY_FAST_LEAF) ||
         (Index->Signature == CM_KEY_HASH_LEAF) ) {
        FastIndex = (PCM_KEY_FAST_INDEX)Index;
        Hint = &FastIndex->List[Count];

        if(Index->Signature == CM_KEY_FAST_LEAF) {
            //
            // Compute the number of valid characters in the hint to compare.
            //
            HintLength = 4;
            for (i=0;i<4;i++) {
                if (Hint->NameHint[i] == 0) {
                    HintLength = i;
                    break;
                }
            }
            NameLength = SearchName->Length / sizeof(WCHAR);
            if (NameLength < HintLength) {
                ValidChars = NameLength;
            } else {
                ValidChars = HintLength;
            }
            for (i=0; i<ValidChars; i++) {
                c1 = SearchName->Buffer[i];
                c2 = FastIndex->List[Count].NameHint[i];
                Result = (LONG)RtlUpcaseUnicodeChar(c1) -
                         (LONG)RtlUpcaseUnicodeChar(c2);
                if (Result != 0) {

                    //
                    // We have found a mismatched character in the hint,
                    // we can now tell which direction to go.
                    //
                    return (Result > 0) ? 1 : -1 ;
                }
            }
        }

        //
        // We have compared all the available characters without a
        // discrepancy. Go ahead and do the actual comparison now.
        //
        Result = CmpDoCompareKeyName(Hive,SearchName,FastIndex->List[Count].Cell);
        if( Result == 2 ) {
            //
            // couldn't map view inside; signal it to the caller
            //
            return 2;
        }
        if (Result == 0) {
            *Child = Hint->Cell;
        }
    } else {
        //
        // This is just a normal old slow index.
        //
        Result = CmpDoCompareKeyName(Hive,SearchName,Index->List[Count]);
        if( Result == 2 ) {
            //
            // couldn't map view inside; signal it to the caller
            //
            return 2;
        }
        if (Result == 0) {
            *Child = Index->List[Count];
        }
    }
    return(Result);
}


LONG
CmpDoCompareKeyName(
    PHHIVE          Hive,
    PUNICODE_STRING SearchName,
    HCELL_INDEX     Cell
    )
/*++

Routine Description:

    Do a compare of a name with a key.

Arguments:

    Hive - pointer to hive control structure for hive of interest

    SearchName - pointer to name of key we are searching for

    Cell - cell of key we are to compare with

Return Value:

    0   = SearchName == KeyName (of Cell)

    -1  = SearchName < KeyName

    +1  = SearchName > KeyName

    +2  = Error (couldn't map bin)

--*/
{
    PCM_KEY_NODE    Pcan;
    UNICODE_STRING  KeyName;
    LONG            Result;

    Pcan = (PCM_KEY_NODE)HvGetCell(Hive, Cell);
    if( Pcan == NULL ) {
        //
        // we couldn't map the bin containing this cell
        // return error, so the caller could safely bail out
        //
        return 2;
    }
    if (Pcan->Flags & KEY_COMP_NAME) {
        
        Result = CmpCompareCompressedName(SearchName,
                                        Pcan->Name,
                                        Pcan->NameLength,
                                        0);
    } else {
        KeyName.Buffer = &(Pcan->Name[0]);
        KeyName.Length = Pcan->NameLength;
        KeyName.MaximumLength = KeyName.Length;
        Result = RtlCompareUnicodeString(SearchName,
                                        &KeyName,
                                        TRUE);
    }
    
    HvReleaseCell(Hive, Cell);

    if( Result == 0 ) {
        //
        // match
        //
        return 0;
    }
    
    return (Result < 0) ? -1 : 1;
}


HCELL_INDEX
CmpFindSubKeyByNumber(
    PHHIVE          Hive,
    PCM_KEY_NODE    Node,
    ULONG           Number
    )
/*++

Routine Description:

    Find the Number'th entry in the index, starting from 0.

Arguments:

    Hive - pointer to hive control structure for hive of interest

    Node - pointer to key body which is parent of child of interest

    Number - ordinal of child key to return

Return Value:

    Cell of matching child key, or HCELL_NIL if none or error.

--*/
{
    PCM_KEY_INDEX   Index;
    HCELL_INDEX     Result = HCELL_NIL;

    CmKdPrintEx((DPFLTR_CONFIG_ID,CML_INDEX,"CmpFindSubKeyByNumber:\n\t"));
    CmKdPrintEx((DPFLTR_CONFIG_ID,CML_INDEX,"Hive=%p Node=%p Number=%08lx\n",Hive,Node,Number));

    if (Number < Node->SubKeyCounts[Stable]) {

        //
        // It's in the stable set
        //
        Index = (PCM_KEY_INDEX)HvGetCell(Hive, Node->SubKeyLists[Stable]);
        if( Index == NULL ) {
            //
            // we couldn't map the bin containing this cell
            //
            return HCELL_NIL;
        }
        Result = CmpDoFindSubKeyByNumber(Hive, Index, Number);
        HvReleaseCell(Hive, Node->SubKeyLists[Stable]);
        return Result;

    } else if (Hive->StorageTypeCount > Volatile) {

        //
        // It's in the volatile set
        //
        Number = Number - Node->SubKeyCounts[Stable];
        if (Number < Node->SubKeyCounts[Volatile]) {

            Index = (PCM_KEY_INDEX)HvGetCell(Hive, Node->SubKeyLists[Volatile]);
            if( Index == NULL ) {
                //
                // we couldn't map the bin containing this cell
                //
                return HCELL_NIL;
            }
            Result = CmpDoFindSubKeyByNumber(Hive, Index, Number);
            HvReleaseCell(Hive, Node->SubKeyLists[Volatile]);
            return Result;
        }
    }
    //
    // It's nowhere
    //
    return HCELL_NIL;
}


HCELL_INDEX
CmpDoFindSubKeyByNumber(
    PHHIVE          Hive,
    PCM_KEY_INDEX   Index,
    ULONG           Number
    )
/*++

Routine Description:

    Helper for CmpFindSubKeyByNumber,
    Find the Number'th entry in the index, starting from 0.

Arguments:

    Hive - pointer to hive control structure for hive of interest

    Index - root or leaf of the index

    Number - ordinal of child key to return

Return Value:

    Cell of requested entry. HCELL_NIL on resources problem

--*/
{
    ULONG           i;
    HCELL_INDEX     LeafCell;
    PCM_KEY_INDEX   Leaf;
    PCM_KEY_FAST_INDEX FastIndex;
    HCELL_INDEX     Result;

    if (Index->Signature == CM_KEY_INDEX_ROOT) {

        //
        // step through root, till we find the right leaf
        //
        for (i = 0; i < Index->Count; i++) {
            if( i ) {
                ASSERT( Leaf!= NULL );
                ASSERT( LeafCell == Index->List[i-1] );
                HvReleaseCell(Hive,LeafCell);
            }
            LeafCell = Index->List[i];
            Leaf = (PCM_KEY_INDEX)HvGetCell(Hive, LeafCell);
            if( Leaf == NULL ) {
                //
                // we couldn't map the bin containing this cell
                //
                return HCELL_NIL;
            }
            if (Number < Leaf->Count) {
                if ( (Leaf->Signature == CM_KEY_FAST_LEAF) ||
                     (Leaf->Signature == CM_KEY_HASH_LEAF) ) {
                    FastIndex = (PCM_KEY_FAST_INDEX)Leaf;
                    Result = FastIndex->List[Number].Cell;
                    HvReleaseCell(Hive,LeafCell);
                    return Result;
                } else {
                    Result = Leaf->List[Number];
                    HvReleaseCell(Hive,LeafCell);
                    return Result;
                }
            } else {
                Number = Number - Leaf->Count;
            }
        }
        ASSERT(FALSE);
    }
    ASSERT(Number < Index->Count);
    if ( (Index->Signature == CM_KEY_FAST_LEAF) ||
         (Index->Signature == CM_KEY_HASH_LEAF) ) {
        FastIndex = (PCM_KEY_FAST_INDEX)Index;
        return(FastIndex->List[Number].Cell);
    } else {
        return (Index->List[Number]);
    }
}

BOOLEAN
CmpRemoveSubKeyCellNoCellRef(
    PHHIVE          Hive,
    HCELL_INDEX     Parent,
    HCELL_INDEX     Child
    )
/*++

Routine Description:

    Removes a subkey by cell index; Also marks relevant data dirty.
    Intended for self healing process.

Arguments:

    Hive - pointer to hive control structure for hive of interest

    Parent - cell of key that will be parent of new key

    Child - key to delete from Paren't sub key list

Return Value:

    TRUE - it worked

    FALSE - resource problem

--*/
{
    PCM_KEY_NODE        Node = NULL;
    PCM_KEY_INDEX       Index = NULL;
    BOOLEAN             Result = TRUE;
    ULONG               i,j;
    HCELL_INDEX         LeafCell = 0;
    PCM_KEY_INDEX       Leaf = NULL;
    PCM_KEY_FAST_INDEX  FastIndex;

#ifndef _CM_LDR_
    PAGED_CODE();
#endif //_CM_LDR_

    Node = (PCM_KEY_NODE)HvGetCell(Hive,Parent);
    if( Node == NULL ) {
        Result = FALSE;
        goto Exit;
    }
    Index = (PCM_KEY_INDEX)HvGetCell(Hive, Node->SubKeyLists[Stable]);
    if( Index == NULL ) {
        Result = FALSE;
        goto Exit;
    }
    if (Index->Signature == CM_KEY_INDEX_ROOT) {
        //
        // step through root, till we find the right leaf
        //
        for (i = 0; i < Index->Count; i++) {
            if( i ) {
                ASSERT( Leaf!= NULL );
                ASSERT( LeafCell == Index->List[i-1] );
                HvReleaseCell(Hive,LeafCell);
            }
            LeafCell = Index->List[i];
            Leaf = (PCM_KEY_INDEX)HvGetCell(Hive, LeafCell);
            if( Leaf == NULL ) {
                Result = FALSE;
                goto Exit;
            }
            for(j=0;j<Leaf->Count;j++) {
                if ( (Leaf->Signature == CM_KEY_FAST_LEAF) ||
                     (Leaf->Signature == CM_KEY_HASH_LEAF) ) {
                    FastIndex = (PCM_KEY_FAST_INDEX)Leaf;
                    if( FastIndex->List[j].Cell == Child ) {
                        //
                        // found it!
                        //
                        HvReleaseCell(Hive,LeafCell);
                        HvMarkCellDirty(Hive,LeafCell);
                        FastIndex->Count--;
                        RtlMoveMemory((PVOID)&(FastIndex->List[j]),
                                      (PVOID)&(FastIndex->List[j+1]),
                                      (FastIndex->Count - j) * sizeof(CM_INDEX));
                        goto DirtyParentAndIndex;
                    }
                } else {
                    if( Leaf->List[j] == Child ) {
                        //
                        // found it!
                        //
                        HvReleaseCell(Hive,LeafCell);
                        HvMarkCellDirty(Hive,LeafCell);
                        Leaf->Count--;
                        RtlMoveMemory((PVOID)&(Leaf->List[j]),
                                      (PVOID)&(Leaf->List[j+1]),
                                      (Leaf->Count - j) * sizeof(HCELL_INDEX));
                        goto DirtyParentAndIndex;
                    }
                }
            }
        }
    } else {
        for(j=0;j<Index->Count;j++) {
            if ( (Index->Signature == CM_KEY_FAST_LEAF) ||
                 (Index->Signature == CM_KEY_HASH_LEAF) ) {
                FastIndex = (PCM_KEY_FAST_INDEX)Index;
                if( FastIndex->List[j].Cell == Child ) {
                    //
                    // found it!
                    //
                    RtlMoveMemory((PVOID)&(FastIndex->List[j]),
                                  (PVOID)&(FastIndex->List[j+1]),
                                  (FastIndex->Count - j) * sizeof(CM_INDEX));
                    goto DirtyParentAndIndex;
                }
            } else {
                if( Index->List[j] == Child ) {
                    //
                    // found it!
                    //
                    RtlMoveMemory((PVOID)&(Index->List[j]),
                                  (PVOID)&(Index->List[j+1]),
                                  (Index->Count - j) * sizeof(HCELL_INDEX));
                    goto DirtyParentAndIndex;
                }
            }
        }
    }
    ASSERT( FALSE );

DirtyParentAndIndex:
    //
    // mark parent and index dirty and decrement index count.
    //
    HvMarkCellDirty(Hive,Node->SubKeyLists[Stable]);
    HvMarkCellDirty(Hive,Parent);
    Index->Count--;
    Node->SubKeyCounts[Stable]--;
Exit:
    if( Index ) {
        ASSERT( Node );
        HvReleaseCell(Hive,Node->SubKeyLists[Stable]);
    }
    if( Node ) {
        HvReleaseCell(Hive,Parent);
    }
    return Result;
}

BOOLEAN
CmpAddSubKey(
    PHHIVE          Hive,
    HCELL_INDEX     Parent,
    HCELL_INDEX     Child
    )
/*++

Routine Description:

    Add a new child subkey to the subkey index for a cell.  The
    child MUST NOT already be present (bugcheck if so.)

    NOTE:   We expect Parent to already be marked dirty.
            We will mark stuff in Index dirty

Arguments:

    Hive - pointer to hive control structure for hive of interest

    Parent - cell of key that will be parent of new key

    Child - new key to put in Paren't sub key list

Return Value:

    TRUE - it worked

    FALSE - resource problem

--*/
{
    PCM_KEY_NODE    pcell;
    HCELL_INDEX     WorkCell;
    PCM_KEY_INDEX   Index;
    PCM_KEY_FAST_INDEX FastIndex;
    UNICODE_STRING  NewName;
    HCELL_INDEX     LeafCell;
    PHCELL_INDEX    RootPointer = NULL;
    ULONG           cleanup = 0;
    ULONG           Type;
    BOOLEAN         IsCompressed;
    ULONG           i;

#ifndef _CM_LDR_
    PAGED_CODE();
#endif //_CM_LDR_

    CmKdPrintEx((DPFLTR_CONFIG_ID,CML_INDEX,"CmpAddSubKey:\n\t"));
    CmKdPrintEx((DPFLTR_CONFIG_ID,CML_INDEX,"Hive=%p Parent=%08lx Child=%08lx\n",Hive,Parent,Child));

    //
    // we have the lock exclusive or nobody is operating inside this hive
    //
    //ASSERT_CM_LOCK_OWNED_EXCLUSIVE();
    ASSERT_CM_EXCLUSIVE_HIVE_ACCESS(Hive);
    //
    // build a name string
    //
    pcell = (PCM_KEY_NODE)HvGetCell(Hive, Child);
    if( pcell == NULL ) {
        //
        // we couldn't map the bin containing this cell
        //
        return FALSE;
    }

    // release the cell here; as the registry is locked exclusive (i.e. we don't care)
    HvReleaseCell(Hive, Child);

    if (pcell->Flags & KEY_COMP_NAME) {
        IsCompressed = TRUE;
        NewName.Length = CmpCompressedNameSize(pcell->Name, pcell->NameLength);
        NewName.MaximumLength = NewName.Length;
        NewName.Buffer = (Hive->Allocate)(NewName.Length, FALSE,CM_FIND_LEAK_TAG8);
        if (NewName.Buffer==NULL) {
            return(FALSE);
        }
        CmpCopyCompressedName(NewName.Buffer,
                              NewName.MaximumLength,
                              pcell->Name,
                              pcell->NameLength);
    } else {
        IsCompressed = FALSE;
        NewName.Length = pcell->NameLength;
        NewName.MaximumLength = pcell->NameLength;
        NewName.Buffer = &(pcell->Name[0]);
    }

    pcell = (PCM_KEY_NODE)HvGetCell(Hive, Parent);
    if( pcell == NULL ) {
        //
        // we couldn't map the bin containing this cell
        //
        goto ErrorExit;
    }

    //ASSERT_CELL_DIRTY(Hive,Parent);

    // release the cell here; as the registry is locked exclusive (i.e. we don't care)
    HvReleaseCell(Hive, Parent);

    Type = HvGetCellType(Child);

    if (pcell->SubKeyCounts[Type] == 0) {

        ULONG Signature;

        //
        // we must allocate a leaf
        //
        WorkCell = HvAllocateCell(Hive, sizeof(CM_KEY_FAST_INDEX), Type,(HvGetCellType(Parent)==Type)?Parent:HCELL_NIL);
        if (WorkCell == HCELL_NIL) {
            goto ErrorExit;
        }
        Index = (PCM_KEY_INDEX)HvGetCell(Hive, WorkCell);
        if( Index == NULL ) {
            //
            // we couldn't map the bin containing this cell
            // this shouldn't happen 'cause we just allocated this
            // cell (i.e. bin is PINNED in memory ! )
            //
            ASSERT( FALSE );
            goto ErrorExit;
        }
        // release the cell here; as the registry is locked exclusive (i.e. we don't care)
        HvReleaseCell(Hive, WorkCell);

        if( UseHashIndex(Hive) ) {
            Index->Signature = CM_KEY_HASH_LEAF;
        } else if( UseFastIndex(Hive) ) {
            Index->Signature = CM_KEY_FAST_LEAF;
        } else {
            Index->Signature = CM_KEY_INDEX_LEAF;
        }
        Index->Count = 0;
        pcell->SubKeyLists[Type] = WorkCell;
        cleanup = 1;
    } else {

        Index = (PCM_KEY_INDEX)HvGetCell(Hive, pcell->SubKeyLists[Type]);
        if( Index == NULL ) {
            //
            // we couldn't map the bin containing this cell
            //
            goto ErrorExit;
        }
        // release the cell here; as the registry is locked exclusive (i.e. we don't care)
        HvReleaseCell(Hive, pcell->SubKeyLists[Type]);

        if ( (Index->Signature == CM_KEY_FAST_LEAF) &&
             (Index->Count >= (CM_MAX_FAST_INDEX)) ) {
            //
            // We must change fast index to a slow index to accomodate
            // growth.
            //

            FastIndex = (PCM_KEY_FAST_INDEX)Index;
            for (i=0; i<Index->Count; i++) {
                Index->List[i] = FastIndex->List[i].Cell;
            }
            Index->Signature = CM_KEY_INDEX_LEAF;

        } else if (((Index->Signature == CM_KEY_INDEX_LEAF) ||
                    (Index->Signature == CM_KEY_HASH_LEAF)) &&
                   (Index->Count >= (CM_MAX_INDEX - 1) )) {
            //
            // We must change flat entry to a root/leaf tree
            //
            WorkCell = HvAllocateCell(
                         Hive,
                         sizeof(CM_KEY_INDEX) + sizeof(HCELL_INDEX), // allow for 2
                         Type,
                         (HvGetCellType(Parent)==Type)?Parent:HCELL_NIL
                         );
            if (WorkCell == HCELL_NIL) {
                goto ErrorExit;
            }

            Index = (PCM_KEY_INDEX)HvGetCell(Hive, WorkCell);
            if( Index == NULL ) {
                //
                // we couldn't map the bin containing this cell
                // this shouldn't happen 'cause we just allocated this
                // cell (i.e. bin is PINNED in memory
                ASSERT( FALSE );
                goto ErrorExit;
            }
            // release the cell here; as the registry is locked exclusive (i.e. we don't care)
            HvReleaseCell(Hive, WorkCell);

            Index->Signature = CM_KEY_INDEX_ROOT;
            Index->Count = 1;
            Index->List[0] = pcell->SubKeyLists[Type];
            pcell->SubKeyLists[Type] = WorkCell;
            cleanup = 2;
        }
    }
    LeafCell = pcell->SubKeyLists[Type];

    //
    // LeafCell is target for add, or perhaps root
    // Index is pointer to fast leaf, slow Leaf or Root, whichever applies
    //
    if (Index->Signature == CM_KEY_INDEX_ROOT) {
        LeafCell = CmpSelectLeaf(Hive, pcell, &NewName, Type, &RootPointer);
        if (LeafCell == HCELL_NIL) {
            goto ErrorExit;
        }
    }

#if 0
	//
	// Validation code. manually search for the key and break when found
	//
	if(Index->Signature == CM_KEY_INDEX_ROOT) {
		LONG			Result;
	    PCM_KEY_INDEX   Leaf;
		HCELL_INDEX		Cell;
		ULONG			iCnt;
	    PCM_KEY_INDEX   PrevLeaf;

		Leaf = (PCM_KEY_INDEX)HvGetCell(Hive, LeafCell);
	    HvReleaseCell(Hive, LeafCell);

		if( Leaf->Count ) {
			Result = CmpCompareInIndex(	Hive,
								&NewName,
								0,
								Leaf,
								&Cell);

			//
			// must be bigger, or the first leaf
			//
			if( (Result < 0) && (RootPointer != &(Index->List[0])) ) {
				for( iCnt=0;iCnt<Index->Count;iCnt++) {
					if( Index->List[iCnt] == LeafCell ) {
						break;
					}
				}

				ASSERT( Index->List[iCnt] == LeafCell );
				ASSERT( iCnt > 0 );
				PrevLeaf = (PCM_KEY_INDEX)HvGetCell(Hive, Index->List[iCnt-1]);
				HvReleaseCell(Hive, Index->List[iCnt-1]);
				
				if( PrevLeaf->Count ) {
					//
					// must be bigger than last in prev leaf
					//
					Result = CmpCompareInIndex(	Hive,
										&NewName,
										PrevLeaf->Count - 1,
										PrevLeaf,
										&Cell);

					if( Result <= 0 ) {
						//
						// Error ==> Debug
						//
						DbgPrint("CmpAddSubKey: Wrong spot selected [1]!!!\n");
						DbgPrint("Hive = %p Parent = %lx Child = %lx , Leaf = %p\n",Hive,Parent,Child,Leaf);
						DbgPrint("RootPointer = %p Index = %p PrevLeaf = %p\n",RootPointer,Index,PrevLeaf);
						DbgBreakPoint();
					}
				}
			}
		}

		Result = CmpCompareInIndex(	Hive,
							&NewName,
							Leaf->Count - 1,
							Leaf,
							&Cell);

		if( Result > 0) {
			//
			// must be the last one 
			//
			if( (ULONG)(Index->Count - 1) > (ULONG)(((PUCHAR)RootPointer - (PUCHAR)(&(Index->List[0])))/sizeof(HCELL_INDEX)) ) {
				//
				// Error ==> Debug
				//
				DbgPrint("CmpAddSubKey: Wrong spot selected [2]!!!\n");
				DbgPrint("Hive = %p Parent = %lx Child = %lx , Leaf = %p\n",Hive,Parent,Child,Leaf);
				DbgPrint("RootPointer = %p Index = %p\n",RootPointer,Index);
				DbgBreakPoint();
			}
		}

	}

#endif //0

    //
    // Add new cell to Leaf, update pointers
    //
    LeafCell = CmpAddToLeaf(Hive, LeafCell, Child, &NewName);

    if (LeafCell == HCELL_NIL) {
        goto ErrorExit;
    }

    pcell->SubKeyCounts[Type] += 1;

    if (RootPointer != NULL) {
        *RootPointer = LeafCell;
    } else {
        pcell->SubKeyLists[Type] = LeafCell;
    }

    if (IsCompressed) {
        (Hive->Free)(NewName.Buffer, NewName.Length);
    }

    return TRUE;



ErrorExit:
    if (IsCompressed) {
        (Hive->Free)(NewName.Buffer, NewName.Length);
    }

    switch (cleanup) {
    case 1:
        HvFreeCell(Hive, pcell->SubKeyLists[Type]);
        pcell->SubKeyLists[Type] = HCELL_NIL;
        break;

    case 2:
        Index = (PCM_KEY_INDEX)HvGetCell(Hive, pcell->SubKeyLists[Type]);
        if( Index == NULL ) {
            //
            // we couldn't map the bin containing this cell
            // this shouldn't happen 'cause we just allocated this
            // cell (i.e. bin is PINNED in memory). 
            // But ... better safe than sorry
            //
            ASSERT( FALSE );
            return FALSE;
        }
        // release the cell here; as the registry is locked exclusive (i.e. we don't care)
        HvReleaseCell(Hive, pcell->SubKeyLists[Type]);
        WorkCell = Index->List[0];
        HvFreeCell(Hive, pcell->SubKeyLists[Type]);
        pcell->SubKeyLists[Type] = WorkCell;
        break;
    }

    return  FALSE;
}


HCELL_INDEX
CmpAddToLeaf(
    PHHIVE          Hive,
    HCELL_INDEX     LeafCell,
    HCELL_INDEX     NewKey,
    PUNICODE_STRING NewName
    )
/*++

Routine Description:

    Insert a new subkey into a Leaf index. Supports both fast and slow
    leaf indexes and will determine which sort of index the given leaf is.

    NOTE:   We expect Root to already be marked dirty by caller if non NULL.
            We expect Leaf to always be marked dirty by caller.

Arguments:

    Hive - pointer to hive control structure for hive of interest

    LeafCell - cell of index leaf node we are to add entry too

    NewKey - cell of KEY_NODE we are to add

    NewName - pointer to unicode string with name to we are to add

Return Value:

    HCELL_NIL - some resource problem

    Else - cell of Leaf index when are done, caller is expected to
            set this into Root index or Key body.

--*/
{
    PCM_KEY_INDEX   Leaf;
    PCM_KEY_FAST_INDEX FastLeaf;
    ULONG           Size;
    ULONG           OldSize;
    ULONG           freecount;
    HCELL_INDEX     NewCell;
    HCELL_INDEX     Child;
    ULONG           Select;
    LONG            Result;
    ULONG           EntrySize;
    ULONG           i;

    CmKdPrintEx((DPFLTR_CONFIG_ID,CML_INDEX,"CmpAddToLeaf:\n\t"));
    CmKdPrintEx((DPFLTR_CONFIG_ID,CML_INDEX,"Hive=%p LeafCell=%08lx NewKey=%08lx\n",Hive,LeafCell,NewKey));

    //
    // we have the lock exclusive or nobody is operating inside this hive
    //
    //ASSERT_CM_LOCK_OWNED_EXCLUSIVE();
    ASSERT_CM_EXCLUSIVE_HIVE_ACCESS(Hive);

    if (!HvMarkCellDirty(Hive, LeafCell)) {
        return HCELL_NIL;
    }

    //
    // compute number free slots left in the leaf
    //
    Leaf = (PCM_KEY_INDEX)HvGetCell(Hive, LeafCell);
    if( Leaf == NULL ) {
        //
        // we couldn't map the bin containing this cell
        // this shouldn't happen as marking dirty means 
        // PINNING the view into memory
        //
        ASSERT( FALSE );
        return HCELL_NIL;
    }
    // release the cell here; as the registry is locked exclusive (i.e. we don't care)
    HvReleaseCell(Hive, LeafCell);

    if (Leaf->Signature == CM_KEY_INDEX_LEAF) {
        FastLeaf = NULL;
        EntrySize = sizeof(HCELL_INDEX);
    } else {
        ASSERT( (Leaf->Signature == CM_KEY_FAST_LEAF) ||
                (Leaf->Signature == CM_KEY_HASH_LEAF)
            );
        FastLeaf = (PCM_KEY_FAST_INDEX)Leaf;
        EntrySize = sizeof(CM_INDEX);
    }
    OldSize = HvGetCellSize(Hive, Leaf);
    Size = OldSize - ((EntrySize * Leaf->Count) +
              FIELD_OFFSET(CM_KEY_INDEX, List));
    freecount = Size / EntrySize;

    //
    // grow the leaf if it isn't big enough
    //
    NewCell = LeafCell;
    if (freecount < 1) {
        Size = OldSize + OldSize / 2;
        if (Size < (OldSize + EntrySize)) {
            Size = OldSize + EntrySize;
        }
        NewCell = HvReallocateCell(Hive, LeafCell, Size);
        if (NewCell == HCELL_NIL) {
            return HCELL_NIL;
        }
        Leaf = (PCM_KEY_INDEX)HvGetCell(Hive, NewCell);
        if( Leaf == NULL ) {
            //
            // we couldn't map the bin containing this cell
            // this shouldn't happen 'cause we just allocated this
            // cell (i.e. bin is PINNED in memory)
            //
            ASSERT( FALSE );
            return HCELL_NIL;
        }
        // release the cell here; as the registry is locked exclusive (i.e. we don't care)
        HvReleaseCell(Hive, NewCell);
        if (FastLeaf != NULL) {
            FastLeaf = (PCM_KEY_FAST_INDEX)Leaf;
        }
    }

    //
    // Find where to put the new entry
    //
    Select = CmpFindSubKeyInLeaf(Hive, Leaf, NewName, &Child);
    if( INVALID_INDEX & Select ) {
        //
        // couldn't map view
        // 
        return HCELL_NIL;
    }

    ASSERT(Child == HCELL_NIL);

    //
    // Select is the index in List of the entry nearest where the
    // new entry should go.
    // Decide wether the new entry goes before or after Offset entry,
    // and then ripple copy and set.
    // If Select == Count, then the leaf is empty, so simply set our entry
    //
    if (Select != Leaf->Count) {

        Result = CmpCompareInIndex(Hive,
                                   NewName,
                                   Select,
                                   Leaf,
                                   &Child);
        if( Result == 2 ) {
            //
            // couldn't map view inside; bail out
            //
            return HCELL_NIL;
        }

        ASSERT(Result != 0);

        //
        // Result -1 - NewName/NewKey less than selected key, insert before
        //        +1 - NewName/NewKey greater than selected key, insert after
        //
        if (Result > 0) {
            ASSERT( Result == 1 );
            Select++;
        }

        if (Select != Leaf->Count) {

            //
            // ripple copy to make space and insert
            //

            if (FastLeaf != NULL) {
                RtlMoveMemory((PVOID)&(FastLeaf->List[Select+1]),
                              (PVOID)&(FastLeaf->List[Select]),
                              sizeof(CM_INDEX)*(FastLeaf->Count - Select));
            } else {
                RtlMoveMemory((PVOID)&(Leaf->List[Select+1]),
                              (PVOID)&(Leaf->List[Select]),
                              sizeof(HCELL_INDEX)*(Leaf->Count - Select));
            }
        }
    }
    if (FastLeaf != NULL) {
        FastLeaf->List[Select].Cell = NewKey;
        if( FastLeaf->Signature == CM_KEY_HASH_LEAF ) {
            //
            // Hash leaf; store the HashKey
            //
            FastLeaf->List[Select].HashKey = CmpComputeHashKey(NewName);
        } else {
            FastLeaf->List[Select].NameHint[0] = 0;
            FastLeaf->List[Select].NameHint[1] = 0;
            FastLeaf->List[Select].NameHint[2] = 0;
            FastLeaf->List[Select].NameHint[3] = 0;
            if (NewName->Length/sizeof(WCHAR) < 4) {
                i = NewName->Length/sizeof(WCHAR);
            } else {
                i = 4;
            }
            do {
                if ((USHORT)NewName->Buffer[i-1] > (UCHAR)-1) {
                    //
                    // Can't compress this name. Leave NameHint[0]==0
                    // to force the name to be looked up in the key.
                    //
                    break;
                }
                FastLeaf->List[Select].NameHint[i-1] = (UCHAR)NewName->Buffer[i-1];
                i--;
            } while ( i>0 );
        }
    } else {
        Leaf->List[Select] = NewKey;
    }
    Leaf->Count += 1;
    
	return NewCell;
}


HCELL_INDEX
CmpSelectLeaf(
    PHHIVE          Hive,
    PCM_KEY_NODE    ParentKey,
    PUNICODE_STRING NewName,
    HSTORAGE_TYPE   Type,
    PHCELL_INDEX    *RootPointer
    )
/*++

Routine Description:

    This routine is only called if the subkey index for a cell is NOT
    simply a single Leaf index block.

    It selects the Leaf index block to which a new entry is to be
    added.  It may create this block by splitting an existing Leaf
    block.

Arguments:

    Hive - pointer to hive control structure for hive of interest

    ParentKey - mapped pointer to parent key

    NewName - pointer to unicode string naming entry to add

    Type - Stable or Volatile, describes Child's storage

    RootPointer - pointer to variable to receive address of HCELL_INDEX
                that points to Leaf block returned as function argument.
                Used for updates.

Return Value:

    HCELL_NIL - resource problem

    Else, cell index of Leaf index block to add entry to

--*/
{
    HCELL_INDEX         LeafCell;
    HCELL_INDEX         WorkCell;
    PCM_KEY_INDEX       Index;
    PCM_KEY_INDEX       Leaf;
    PCM_KEY_FAST_INDEX  FastLeaf;
    ULONG               RootSelect;
    LONG                Result;

    CmKdPrintEx((DPFLTR_CONFIG_ID,CML_INDEX,"CmpSelectLeaf:\n\t"));
    CmKdPrintEx((DPFLTR_CONFIG_ID,CML_INDEX,"Hive=%p ParentKey=%p\n", Hive, ParentKey));

    //
    // we have the lock exclusive or nobody is operating inside this hive
    //
    //ASSERT_CM_LOCK_OWNED_EXCLUSIVE();
    ASSERT_CM_EXCLUSIVE_HIVE_ACCESS(Hive);

    //
    // Force root to always be dirty, since we'll either grow it or edit it,
    // and it needs to be marked dirty for BOTH cases.  (Edit may not
    // occur until after we leave
    //
    if (! HvMarkCellDirty(Hive, ParentKey->SubKeyLists[Type])) {
        return HCELL_NIL;
    }

    //
    // must find the proper leaf
    //
    Index = (PCM_KEY_INDEX)HvGetCell(Hive, ParentKey->SubKeyLists[Type]);
    if( Index == NULL ) {
        //
        // we couldn't map the bin containing this cell
        // this shouldn't happen as marking dirty means 
        // PINNING the view into memory
        //
        ASSERT( FALSE );
        return HCELL_NIL;
    }
    ASSERT(Index->Signature == CM_KEY_INDEX_ROOT);

    // release the cell here; as the registry is locked exclusive (i.e. we don't care)
    HvReleaseCell(Hive, ParentKey->SubKeyLists[Type]);

    while (TRUE) {

        RootSelect = CmpFindSubKeyInRoot(Hive, Index, NewName, &LeafCell);
        if( INVALID_INDEX & RootSelect ) {
            //
            // couldn't map view inside; bail out
            //
            return HCELL_NIL;
        }

        if (LeafCell == HCELL_NIL) {

            //
            // Leaf of interest is somewhere near RootSelect
            //
            // . Always use lowest order leaf we can get away with
            // . Never split a leaf if there's one with space we can use
            // . When we split a leaf, we have to repeat search
            //
            // If (NewKey is below lowest key in selected)
            //    If there's a Leaf below selected with space
            //       use the leaf below
            //    else
            //       use the leaf (split it if not enough space)
            // Else
            //    must be above highest key in selected, less than
            //      lowest key in Leaf to right of selected
            //       if space in selected
            //          use selected
            //       else if space in leaf above selected
            //          use leaf above
            //       else
            //          split selected
            //
            LeafCell = Index->List[RootSelect];
            Leaf = (PCM_KEY_INDEX)HvGetCell(Hive, LeafCell);
            if( Leaf == NULL ) {
                //
                // we couldn't map the bin containing this cell
                //
                return HCELL_NIL;
            }

            // release the cell here; as the registry is locked exclusive (i.e. we don't care)
            HvReleaseCell(Hive, LeafCell);

            if( (Leaf->Signature == CM_KEY_FAST_LEAF)   ||
                (Leaf->Signature == CM_KEY_HASH_LEAF) ) {
                FastLeaf = (PCM_KEY_FAST_INDEX)Leaf;
                WorkCell = FastLeaf->List[0].Cell;
            } else {
                ASSERT( Leaf->Signature == CM_KEY_INDEX_LEAF );
                WorkCell = Leaf->List[0];
            }

            Result = CmpDoCompareKeyName(Hive, NewName, WorkCell);
            if( Result == 2 ) {
                //
                // couldn't map view inside; bail out
                // 
                return HCELL_NIL;
            }
            ASSERT(Result != 0);

            if (Result < 0) {

                //
                // new is off the left end of Selected
                //
                if (RootSelect > 0) {

                    //
                    // there's a Leaf to the left, try to use it
                    //
                    LeafCell = Index->List[RootSelect-1];
                    Leaf = (PCM_KEY_INDEX)HvGetCell(Hive, LeafCell);
                    if( Leaf == NULL ) {
                        //
                        // we couldn't map the bin containing this cell
                        //
                        return HCELL_NIL;
                    }
                    // release the cell here; as the registry is locked exclusive (i.e. we don't care)
                    HvReleaseCell(Hive, LeafCell);

                    if (Leaf->Count < (CM_MAX_INDEX - 1)) {
                        RootSelect--;
                        *RootPointer = &(Index->List[RootSelect]);
                        break;
                    }

                } else {
                    //
                    // new key is off the left end of the leftmost leaf.
                    // Use the leftmost leaf, if there's enough room
                    //
                    LeafCell = Index->List[0];
                    Leaf = (PCM_KEY_INDEX)HvGetCell(Hive, LeafCell);
                    if( Leaf == NULL ) {
                        //
                        // we couldn't map the bin containing this cell
                        //
                        return HCELL_NIL;
                    }
                    // release the cell here; as the registry is locked exclusive (i.e. we don't care)
                    HvReleaseCell(Hive, LeafCell);
                    if (Leaf->Count < (CM_MAX_INDEX - 1)) {
                        *RootPointer = &(Index->List[0]);
                        break;
                    }
                }

                //
                // else fall to split case
                //

            } else {

                //
                // since new key is not in a Leaf, and is not off
                // the left end of the ResultSelect Leaf, it must
                // be off the right end.
                //
                LeafCell = Index->List[RootSelect];
                Leaf = (PCM_KEY_INDEX)HvGetCell(Hive, LeafCell);
                if( Leaf == NULL ) {
                    //
                    // we couldn't map the bin containing this cell
                    //
                    return HCELL_NIL;
                }
                // release the cell here; as the registry is locked exclusive (i.e. we don't care)
                HvReleaseCell(Hive, LeafCell);

                if (Leaf->Count < (CM_MAX_INDEX - 1)) {
                    *RootPointer = &(Index->List[RootSelect]);
                    break;
                }

                //
                // No space, see if there's a leaf to the rigth
                // and if it has space
                //
                if (RootSelect < (ULONG)(Index->Count - 1)) {

                    LeafCell = Index->List[RootSelect+1];
                    Leaf = (PCM_KEY_INDEX)HvGetCell(Hive, LeafCell);
                    if( Leaf == NULL ) {
                        //
                        // we couldn't map the bin containing this cell
                        //
                        return HCELL_NIL;
                    }
                    // release the cell here; as the registry is locked exclusive (i.e. we don't care)
                    HvReleaseCell(Hive, LeafCell);

                    if (Leaf->Count < (CM_MAX_INDEX - 1)) {
                        *RootPointer = &(Index->List[RootSelect+1]);
                        break;
                    }
                }

                //
                // fall to split case
                //
            }

        } else {   // LeafCell != HCELL_NIL

            //
            // Since newkey cannot already be in tree, it must be
            // greater than the bottom of Leaf and less than the top,
            // therefore it must go in Leaf.  If no space, split it.
            //
            Leaf = (PCM_KEY_INDEX)HvGetCell(Hive, LeafCell);
            if( Leaf == NULL ) {
                //
                // we couldn't map the bin containing this cell
                //
                return HCELL_NIL;
            }

            // release the cell here; as the registry is locked exclusive (i.e. we don't care)
            HvReleaseCell(Hive, LeafCell);

            if (Leaf->Count < (CM_MAX_INDEX - 1)) {

                *RootPointer = &(Index->List[RootSelect]);
                break;
            }

            //
            // fall to split case
            //
        }

        //
        // either no neigbor, or no space in neighbor, so split
        //
        WorkCell = CmpSplitLeaf(
                        Hive,
                        ParentKey->SubKeyLists[Type],       // root cell
                        RootSelect,
                        Type
                        );
        if (WorkCell == HCELL_NIL) {
            return HCELL_NIL;
        }

        ParentKey->SubKeyLists[Type] = WorkCell;
        Index = (PCM_KEY_INDEX)HvGetCell(Hive, WorkCell);
        if( Index == NULL ) {
            //
            // we couldn't map the bin containing this cell
            //
            return HCELL_NIL;
        }

        // release the cell here; as the registry is locked exclusive (i.e. we don't care)
        HvReleaseCell(Hive, WorkCell);

        ASSERT(Index->Signature == CM_KEY_INDEX_ROOT);

    } // while(true)
    return LeafCell;
}


HCELL_INDEX
CmpSplitLeaf(
    PHHIVE          Hive,
    HCELL_INDEX     RootCell,
    ULONG           RootSelect,
    HSTORAGE_TYPE   Type
    )
/*++

Routine Description:

    Split the Leaf index block specified by RootSelect, causing both
    of the split out Leaf blocks to appear in the Root index block
    specified by RootCell.

    Caller is expected to have marked old root cell dirty.

Arguments:

    Hive - pointer to hive control structure for hive of interest

    RootCell - cell of the Root index block of index being grown

    RootSelect - indicates which child of Root to split

    Type - Stable or Volatile

Return Value:

    HCELL_NIL - some resource problem

    Else - cell of new (e.g. reallocated) Root index block

--*/
{
    PCM_KEY_INDEX   Root;
    HCELL_INDEX     LeafCell;
    PCM_KEY_INDEX   Leaf;
    HCELL_INDEX     NewLeafCell;
    PCM_KEY_INDEX   NewLeaf;
	PCM_KEY_FAST_INDEX	FastLeaf;
    ULONG           Size;
    ULONG           freecount;
    USHORT          OldCount;
    USHORT          KeepCount;
    USHORT          NewCount;
    USHORT          ElemSize;

    CmKdPrintEx((DPFLTR_CONFIG_ID,CML_INDEX,"CmpSplitLeaf:\n\t"));
    CmKdPrintEx((DPFLTR_CONFIG_ID,CML_INDEX,"Hive=%p RootCell=%08lx RootSelect\n", Hive, RootCell, RootSelect));

    //
    // we have the lock exclusive or nobody is operating inside this hive
    //
    //ASSERT_CM_LOCK_OWNED_EXCLUSIVE();
    ASSERT_CM_EXCLUSIVE_HIVE_ACCESS(Hive);
    //
    // allocate new Leaf index block
    //
    Root = (PCM_KEY_INDEX)HvGetCell(Hive, RootCell);
    if( Root == NULL ) {
        //
        // we couldn't map the bin containing this cell
        //
        return HCELL_NIL;
    }

    // release the cell here; as the registry is locked exclusive (i.e. we don't care)
    HvReleaseCell(Hive, RootCell);

    LeafCell = Root->List[RootSelect];
    Leaf = (PCM_KEY_INDEX)HvGetCell(Hive, LeafCell);
    if( Leaf == NULL ) {
        //
        // we couldn't map the bin containing this cell
        //
        return HCELL_NIL;
    }
    OldCount = Leaf->Count;

    // release the cell here; as the registry is locked exclusive (i.e. we don't care)
    HvReleaseCell(Hive, LeafCell);

    KeepCount = (USHORT)(OldCount / 2);     // # of entries to keep in org. Leaf
    NewCount = (OldCount - KeepCount);      // # of entries to move

    if( UseHashIndex(Hive) ) {
        ASSERT( Leaf->Signature == CM_KEY_HASH_LEAF );
        ElemSize = sizeof(CM_INDEX);
    } else {
        ElemSize = sizeof(HCELL_INDEX);
        ASSERT( Leaf->Signature == CM_KEY_INDEX_LEAF );
    }

    ASSERT( FIELD_OFFSET(CM_KEY_INDEX, List) == FIELD_OFFSET(CM_KEY_FAST_INDEX, List) );
    Size = (ElemSize * NewCount) +
            FIELD_OFFSET(CM_KEY_INDEX, List) + 1;   // +1 to assure room for add

    if (!HvMarkCellDirty(Hive, LeafCell)) {
        return HCELL_NIL;
    }

    //
    //
    //
    ASSERT( (HvGetCellType(LeafCell) == (ULONG)Type) );

    NewLeafCell = HvAllocateCell(Hive, Size, Type,LeafCell);
    if (NewLeafCell == HCELL_NIL) {
        return HCELL_NIL;
    }
    NewLeaf = (PCM_KEY_INDEX)HvGetCell(Hive, NewLeafCell);
    if( NewLeaf == NULL ) {
        //
        // we couldn't map the bin containing this cell
        // this shouldn't happen as we just allocated this cell
        // so it's bin should be PINNED into memory
        //
        ASSERT( FALSE );
        HvFreeCell(Hive, NewLeafCell);
        return HCELL_NIL;
    }
    if( UseHashIndex(Hive) ) {
        NewLeaf->Signature = CM_KEY_HASH_LEAF;
    } else {
        NewLeaf->Signature = CM_KEY_INDEX_LEAF;
    }

    // release the cell here; as the registry is locked exclusive (i.e. we don't care)
    HvReleaseCell(Hive, NewLeafCell);


    //
    // compute number of free slots left in the root
    //
    Size = HvGetCellSize(Hive, Root);
    Size = Size - ((sizeof(HCELL_INDEX) * Root->Count) +
              FIELD_OFFSET(CM_KEY_INDEX, List));
    freecount = Size / sizeof(HCELL_INDEX);


    //
    // grow the root if it isn't big enough
    //
    if (freecount < 1) {
        Size = HvGetCellSize(Hive, Root) + sizeof(HCELL_INDEX);
        RootCell = HvReallocateCell(Hive, RootCell, Size);
        if (RootCell == HCELL_NIL) {
            HvFreeCell(Hive, NewLeafCell);
            return HCELL_NIL;
        }
        Root = (PCM_KEY_INDEX)HvGetCell(Hive, RootCell);
        if( Root == NULL ) {
            //
            // we couldn't map the bin containing this cell
            // this shouldn't happen as we just allocated this cell
            // so it's bin should be PINNED into memory
            //
            ASSERT( FALSE );
            HvFreeCell(Hive, NewLeafCell);
            return HCELL_NIL;
        }
        // release the cell here; as the registry is locked exclusive (i.e. we don't care)
        HvReleaseCell(Hive, RootCell);

    }


    //
    // copy data from one Leaf to the other
    //
    //
    if( UseHashIndex(Hive) ) {
		FastLeaf = (PCM_KEY_FAST_INDEX)Leaf;
#if 0 //DBG
    {
        HCELL_INDEX     PrevCell = HCELL_NIL;
        HCELL_INDEX     CurCell;
        ULONG           i;
        for( i=0;i<(ULONG)(Leaf->Count);i++) {
            CurCell = FastLeaf->List[i].Cell;

            if( (PrevCell != HCELL_NIL) && (PrevCell == CurCell) ) {
			    DbgPrint("CmpSplitLeaf(%p,%lx,%lx) \n",Hive,RootCell,RootSelect);
			    DbgPrint("\t Leaf = %p\n",Leaf);
			    DbgPrint("\t at index %lx we have duplicate cell - BEFORE\n",i);
			    DbgBreakPoint();
		    }
            PrevCell = CurCell;
	    }
    }
#endif //DBG
		RtlMoveMemory(
			(PVOID)&(NewLeaf->List[0]),
			(PVOID)&(FastLeaf->List[KeepCount]),
			ElemSize * NewCount
			);
	} else {
		RtlMoveMemory(
			(PVOID)&(NewLeaf->List[0]),
			(PVOID)&(Leaf->List[KeepCount]),
			ElemSize * NewCount
			);
	}

    ASSERT(KeepCount != 0);
    ASSERT(NewCount  != 0);

    Leaf->Count = KeepCount;
    NewLeaf->Count = NewCount;


    //
    // make an open slot in the root
    //
    if (RootSelect < (ULONG)(Root->Count-1)) {
        RtlMoveMemory(
            (PVOID)&(Root->List[RootSelect+2]),
            (PVOID)&(Root->List[RootSelect+1]),
            (Root->Count - (RootSelect + 1)) * sizeof(HCELL_INDEX)
            );
    }

    //
    // update the root
    //
    Root->Count += 1;
    Root->List[RootSelect+1] = NewLeafCell;
    return RootCell;
}


BOOLEAN
CmpMarkIndexDirty(
    PHHIVE          Hive,
    HCELL_INDEX     ParentKey,
    HCELL_INDEX     TargetKey
    )
/*++

Routine Description:

    Mark as dirty relevent cells of a subkey index.  The Leaf that
    points to TargetKey, and the Root index block, if applicable,
    will be marked dirty.  This call assumes we are setting up
    for a subkey delete.

Arguments:

    Hive - pointer to hive control structure for hive of interest

    ParentKey - key from whose subkey list delete is to be performed

    TargetKey - key being deleted

Return Value:

    TRUE - it worked, FALSE - it didn't, some resource problem

--*/
{
    PCM_KEY_NODE    pcell;
    ULONG           i;
    HCELL_INDEX     IndexCell;
    PCM_KEY_INDEX   Index;
    HCELL_INDEX     Child = HCELL_NIL;
    UNICODE_STRING  SearchName;
    BOOLEAN         IsCompressed;
    HCELL_INDEX     CellToRelease = HCELL_NIL;


    pcell = (PCM_KEY_NODE)HvGetCell(Hive, TargetKey);
    if( pcell == NULL ) {
        //
        // we couldn't map the bin containing this cell
        //
        return FALSE;
    }

    if (pcell->Flags & KEY_COMP_NAME) {
        IsCompressed = TRUE;
        SearchName.Length = CmpCompressedNameSize(pcell->Name, pcell->NameLength);
        SearchName.MaximumLength = SearchName.Length;
#if defined(_CM_LDR_)
        SearchName.Buffer = (Hive->Allocate)(SearchName.Length, FALSE,CM_FIND_LEAK_TAG9);
#else
        SearchName.Buffer = ExAllocatePool(PagedPool, SearchName.Length);
#endif
        if (SearchName.Buffer==NULL) {
            HvReleaseCell(Hive, TargetKey);
            return(FALSE);
        }
        CmpCopyCompressedName(SearchName.Buffer,
                              SearchName.MaximumLength,
                              pcell->Name,
                              pcell->NameLength);
    } else {
        IsCompressed = FALSE;
        SearchName.Length = pcell->NameLength;
        SearchName.MaximumLength = pcell->NameLength;
        SearchName.Buffer = &(pcell->Name[0]);
    }

    HvReleaseCell(Hive, TargetKey);

    pcell = (PCM_KEY_NODE)HvGetCell(Hive, ParentKey);
    if( pcell == NULL ) {
        //
        // we couldn't map the bin containing this cell
        //
        goto ErrorExit;
    }

    for (i = 0; i < Hive->StorageTypeCount; i++) {
        if (pcell->SubKeyCounts[i] != 0) {
            ASSERT(HvIsCellAllocated(Hive, pcell->SubKeyLists[i]));
            IndexCell = pcell->SubKeyLists[i];
            if( CellToRelease != HCELL_NIL ) {
                HvReleaseCell(Hive, CellToRelease);
                CellToRelease = HCELL_NIL;
            }
            Index = (PCM_KEY_INDEX)HvGetCell(Hive, IndexCell);
            if( Index == NULL ) {
                //
                // we couldn't map the bin containing this cell
                //
                goto ErrorExit;
            }
            CellToRelease = IndexCell;

            if (Index->Signature == CM_KEY_INDEX_ROOT) {

                //
                // target even in index?
                //
                if( INVALID_INDEX & CmpFindSubKeyInRoot(Hive, Index, &SearchName, &Child) ) {
                    //
                    // couldn't map view inside; bail out
                    //
                    goto ErrorExit;
                }

                if (Child == HCELL_NIL) {
                    continue;
                }

                //
                // mark root dirty
                //
                if (! HvMarkCellDirty(Hive, IndexCell)) {
                    goto ErrorExit;
                }

                if( CellToRelease != HCELL_NIL ) {
                    HvReleaseCell(Hive, CellToRelease);
                    CellToRelease = HCELL_NIL;
                }
                IndexCell = Child;
                Index = (PCM_KEY_INDEX)HvGetCell(Hive, Child);
                if( Index == NULL ) {
                    //
                    // we couldn't map the bin containing this cell
                    //
                    goto ErrorExit;
                }

                CellToRelease = Child;

            }
            ASSERT((Index->Signature == CM_KEY_INDEX_LEAF)  ||
                   (Index->Signature == CM_KEY_FAST_LEAF)   ||
                   (Index->Signature == CM_KEY_HASH_LEAF)
                   );

            if( INVALID_INDEX & CmpFindSubKeyInLeaf(Hive, Index, &SearchName, &Child) ) {
                //
                // couldn't map view
                // 
                goto ErrorExit;
            }

            if (Child != HCELL_NIL) {
                if (IsCompressed) {
#if defined(_CM_LDR_)
                    (Hive->Free)(SearchName.Buffer, SearchName.Length);
#else
                    ExFreePool(SearchName.Buffer);
#endif
                }
                // cleanup
                HvReleaseCell(Hive, ParentKey);
                if( CellToRelease != HCELL_NIL ) {
                    HvReleaseCell(Hive, CellToRelease);
                }
                return(HvMarkCellDirty(Hive, IndexCell));
            }
        }
    }

ErrorExit:
    if( pcell!= NULL ) {
        HvReleaseCell(Hive, ParentKey);
    }
    if( CellToRelease != HCELL_NIL ) {
        HvReleaseCell(Hive, CellToRelease);
    }

    if (IsCompressed) {
#if defined(_CM_LDR_)
        (Hive->Free)(SearchName.Buffer, SearchName.Length);
#else
        ExFreePool(SearchName.Buffer);
#endif
    }
    return FALSE;
}


BOOLEAN
CmpRemoveSubKey(
    PHHIVE          Hive,
    HCELL_INDEX     ParentKey,
    HCELL_INDEX     TargetKey
    )
/*++

Routine Description:

    Remove the subkey TargetKey refers to from ParentKey's list.

    NOTE:   Assumes that caller has marked relevent cells dirty,
            see CmpMarkIndexDirty.

Arguments:

    Hive - pointer to hive control structure for hive of interest

    ParentKey - key from whose subkey list delete is to be performed

    TargetKey - key being deleted

Return Value:

    TRUE - it worked, FALSE - it didn't, some resource problem

--*/
{
    PCM_KEY_NODE    pcell;
    HCELL_INDEX     LeafCell;
    PCM_KEY_INDEX   Leaf;
    PCM_KEY_FAST_INDEX FastIndex;
    HCELL_INDEX     RootCell = HCELL_NIL;
    PCM_KEY_INDEX   Root = NULL;
    HCELL_INDEX     Child;
    ULONG           Type;
    ULONG           RootSelect;
    ULONG           LeafSelect;
    UNICODE_STRING  SearchName;
    BOOLEAN         IsCompressed;
    WCHAR           CompressedBuffer[50];
    BOOLEAN         Result;
    HCELL_INDEX     CellToRelease1 = HCELL_NIL,CellToRelease2  = HCELL_NIL;

    pcell = (PCM_KEY_NODE)HvGetCell(Hive, TargetKey);
    if( pcell == NULL ) {
        //
        // we couldn't map the bin containing this cell
        //
        return FALSE;
    }

    ASSERT_CELL_DIRTY(Hive,TargetKey);

    //
    // release the cell here; as key is dirty/pinned
    //
    HvReleaseCell(Hive, TargetKey);

    if (pcell->Flags & KEY_COMP_NAME) {
        IsCompressed = TRUE;
        SearchName.Length = CmpCompressedNameSize(pcell->Name, pcell->NameLength);
        SearchName.MaximumLength = SearchName.Length;
        if (SearchName.MaximumLength > sizeof(CompressedBuffer)) {
#if defined(_CM_LDR_)
            SearchName.Buffer = (Hive->Allocate)(SearchName.Length, FALSE,CM_FIND_LEAK_TAG40);
#else
            SearchName.Buffer = ExAllocatePool(PagedPool, SearchName.Length);
#endif
            if (SearchName.Buffer==NULL) {
                return(FALSE);
            }
        } else {
            SearchName.Buffer = CompressedBuffer;
        }
        CmpCopyCompressedName(SearchName.Buffer,
                              SearchName.MaximumLength,
                              pcell->Name,
                              pcell->NameLength);
    } else {
        IsCompressed = FALSE;
        SearchName.Length = pcell->NameLength;
        SearchName.MaximumLength = pcell->NameLength;
        SearchName.Buffer = &(pcell->Name[0]);
    }

    pcell = (PCM_KEY_NODE)HvGetCell(Hive, ParentKey);
    if( pcell == NULL ) {
        //
        // we couldn't map the bin containing this cell
        //
        Result = FALSE;
        goto Exit;
    }

    ASSERT_CELL_DIRTY(Hive,ParentKey);

    //
    // release the cell here; as key is dirty/pinned
    //
    HvReleaseCell(Hive, ParentKey);

    Type = HvGetCellType(TargetKey);

    ASSERT(pcell->SubKeyCounts[Type] != 0);
    ASSERT(HvIsCellAllocated(Hive, pcell->SubKeyLists[Type]));

    LeafCell = pcell->SubKeyLists[Type];
    Leaf = (PCM_KEY_INDEX)HvGetCell(Hive, LeafCell);
    if( Leaf == NULL ) {
        //
        // we couldn't map the bin containing this cell
        //
        Result = FALSE;
        goto Exit;
    }

    CellToRelease1 = LeafCell;

    if (Leaf->Signature == CM_KEY_INDEX_ROOT) {
        RootSelect = CmpFindSubKeyInRoot(Hive, Leaf, &SearchName, &Child);

        if( INVALID_INDEX & RootSelect ) {
            //
            // couldn't map view inside; bail out
            //
            Result = FALSE;
            goto Exit;
        }
        ASSERT(Child != FALSE);

        Root = Leaf;
        RootCell = LeafCell;
        LeafCell = Child;
        Leaf = (PCM_KEY_INDEX)HvGetCell(Hive, LeafCell);
        if( Leaf == NULL ) {
            //
            // we couldn't map the bin containing this cell
            //
            Result = FALSE;
            goto Exit;
        }
        CellToRelease2  = LeafCell;

    }

    ASSERT((Leaf->Signature == CM_KEY_INDEX_LEAF)   ||
           (Leaf->Signature == CM_KEY_FAST_LEAF)    ||
           (Leaf->Signature == CM_KEY_HASH_LEAF)
           );

    LeafSelect = CmpFindSubKeyInLeaf(Hive, Leaf, &SearchName, &Child);
    if( INVALID_INDEX & LeafSelect ) {
        //
        // couldn't map view
        // 
        Result = FALSE;
        goto Exit;
    }

    ASSERT(Child != HCELL_NIL);


    //
    // Leaf points to Index Leaf block
    // Child is Index Leaf block cell
    // LeafSelect is Index for List[]
    //
    pcell->SubKeyCounts[Type] -= 1;

    Leaf->Count -= 1;
    if (Leaf->Count == 0) {

        //
        // Empty Leaf, drop it.
        //
        HvFreeCell(Hive, LeafCell);

        if (Root != NULL) {

            Root->Count -= 1;
            if (Root->Count == 0) {

                //
                // Root is empty, free it too.
                //
                HvFreeCell(Hive, RootCell);
                pcell->SubKeyLists[Type] = HCELL_NIL;

            } else if (RootSelect < (ULONG)(Root->Count)) {

                //
                // Middle entry, squeeze root
                //
                RtlMoveMemory(
                    (PVOID)&(Root->List[RootSelect]),
                    (PVOID)&(Root->List[RootSelect+1]),
                    (Root->Count - RootSelect) * sizeof(HCELL_INDEX)
                    );
            }
            //
            // Else RootSelect == last entry, so decrementing count
            // was all we needed to do
            //

        } else {

            pcell->SubKeyLists[Type] = HCELL_NIL;

        }

    } else if (LeafSelect < (ULONG)(Leaf->Count)) {

        if (Leaf->Signature == CM_KEY_INDEX_LEAF) {
            RtlMoveMemory((PVOID)&(Leaf->List[LeafSelect]),
                          (PVOID)&(Leaf->List[LeafSelect+1]),
                          (Leaf->Count - LeafSelect) * sizeof(HCELL_INDEX));
        } else {
            FastIndex = (PCM_KEY_FAST_INDEX)Leaf;
            RtlMoveMemory((PVOID)&(FastIndex->List[LeafSelect]),
                          (PVOID)&(FastIndex->List[LeafSelect+1]),
                          (FastIndex->Count - LeafSelect) * sizeof(CM_INDEX));
        }
    }
    //
    // Else LeafSelect == last entry, so decrementing count was enough
    //

    // things went OK
    Result = TRUE;

Exit:
    if( CellToRelease1 != HCELL_NIL ) {
        HvReleaseCell(Hive,CellToRelease1);
    }
    if( CellToRelease2 != HCELL_NIL ) {
        HvReleaseCell(Hive,CellToRelease2);
    }

    if ((IsCompressed) &&
        (SearchName.MaximumLength > sizeof(CompressedBuffer))) {
#if defined(_CM_LDR_)
        (Hive->Free)(SearchName.Buffer, SearchName.Length);
#else
        ExFreePool(SearchName.Buffer);
#endif
    }
    return Result;
}

#ifdef NT_RENAME_KEY
HCELL_INDEX
CmpDuplicateIndex(
    PHHIVE          Hive,
    HCELL_INDEX     IndexCell,
    ULONG           StorageType
    )
/*++

Routine Description:

    Duplicate an index, regardless of its type; Needed for NtRenameKey

Arguments:

    Hive - pointer to hive control structure for hive of interest

    IndexCell - the index to be duplicated

    StorageType - storagetype (Stable or Volatile)

Return Value:

    cellindex of a duplicate or HCELL_NIL

--*/
{

    PCM_KEY_INDEX   Index;
    PCM_KEY_INDEX   Leaf;
    ULONG           i;
    PCM_KEY_INDEX   NewIndex = NULL;
    HCELL_INDEX     NewIndexCell;
    HCELL_INDEX     LeafCell;

    PAGED_CODE();

    //
    // we have the lock exclusive or nobody is operating inside this hive
    //
    //ASSERT_CM_LOCK_OWNED_EXCLUSIVE();
    ASSERT_CM_EXCLUSIVE_HIVE_ACCESS(Hive);

    ASSERT( HvGetCellType(IndexCell) == StorageType );

    Index = (PCM_KEY_INDEX)HvGetCell(Hive, IndexCell);
    if( Index == NULL ) {
        //
        // we couldn't map a view for the bin containing this cell
        //
        return HCELL_NIL;
    }

    // release the cell here; as the registry is locked exclusive (i.e. we don't care)
    HvReleaseCell(Hive, IndexCell);

    if (Index->Signature == CM_KEY_INDEX_ROOT) {
        //
        // first duplicate IndexCell, zeroing out the new content
        //
        NewIndexCell = HvDuplicateCell(Hive,IndexCell,StorageType,FALSE);
        if( NewIndexCell == HCELL_NIL ) {
            return HCELL_NIL;
        }

        NewIndex = (PCM_KEY_INDEX)HvGetCell(Hive, NewIndexCell);
        if( NewIndex == NULL ) {
            //
            // we couldn't map a view for the bin containing this cell
            // this shouldn't happen as we just allocated this cell (i.e. is dirty/pinned into memory)
            //
            ASSERT( FALSE );
            goto ErrorExit;
        }
        // release the cell here; as the registry is locked exclusive (i.e. we don't care)
        HvReleaseCell(Hive, NewIndexCell);

        //
        // we have a root index;
        //
        NewIndex->Signature = CM_KEY_INDEX_ROOT;
        NewIndex->Count = 0;

        //
        // copy first level.
        //
        for( i=0;i<Index->Count;i++) {
#if DBG
            Leaf = (PCM_KEY_INDEX)HvGetCell(Hive, Index->List[i]);
            if( Leaf == NULL ) {
                //
                // we couldn't map the bin containing this cell
                //
                goto ErrorExit;
            }

            // release the cell here; as the registry is locked exclusive (i.e. we don't care)
            HvReleaseCell(Hive, Index->List[i]);

            ASSERT((Leaf->Signature == CM_KEY_INDEX_LEAF)   ||
                   (Leaf->Signature == CM_KEY_FAST_LEAF)    ||
                   (Leaf->Signature == CM_KEY_HASH_LEAF)
                   );
            ASSERT(Leaf->Count != 0);
#endif
            
            LeafCell = HvDuplicateCell(Hive,Index->List[i],StorageType,TRUE);
            if( LeafCell == HCELL_NIL ) {
                goto ErrorExit;
            }
            
            NewIndex->List[i] = LeafCell;
            NewIndex->Count++;
        }
        
        ASSERT( NewIndex->Count == Index->Count );

    } else {
        //
        // leaf index
        //
        ASSERT((Index->Signature == CM_KEY_INDEX_LEAF)  ||
               (Index->Signature == CM_KEY_FAST_LEAF)   ||
               (Index->Signature == CM_KEY_HASH_LEAF)
               );
        ASSERT(Index->Count != 0);

        //
        // first duplicate IndexCell, copying the old content
        //
        NewIndexCell = HvDuplicateCell(Hive,IndexCell,StorageType,TRUE);
    }

    return NewIndexCell;

ErrorExit:
    if( NewIndex != NULL ){
        // we can get here only if we are trying to duplicate an index_root
        ASSERT( NewIndex->Signature == CM_KEY_INDEX_ROOT );
       
        //
        // free the space we already allocated
        //
        for(i=0;i<NewIndex->Count;i++) {
            ASSERT(NewIndex->List[i] != 0 );
            HvFreeCell(Hive, NewIndex->List[i]);
        }
    }

    HvFreeCell(Hive, NewIndexCell);
    return HCELL_NIL;
}

BOOLEAN
CmpUpdateParentForEachSon(
    PHHIVE          Hive,
    HCELL_INDEX     Parent
    )
/*++

Routine Description:

    Walks the child's list (both stable and volatile and marks updates
    the parent link to Parent.

    First step is to mark all children dirty, and then to update the link.
    This way, if we fail part through, we leave everything in good order

Arguments:

    Hive - pointer to hive control structure for hive of interest

    Parent - cell index of the cell who's son's to be updated.

Return Value:

    TRUE - successfully updated

--*/
{
    PCM_KEY_NODE    ParentNode;
    PCM_KEY_NODE    CurrentSon;
    HCELL_INDEX     Child;
    ULONG           Count;   
    ULONG           i;   

    PAGED_CODE();

    //
    // we have the lock exclusive or nobody is operating inside this hive
    //
    //ASSERT_CM_LOCK_OWNED_EXCLUSIVE();
    ASSERT_CM_EXCLUSIVE_HIVE_ACCESS(Hive);

    //
    // grab the parent node; this was already marked as dirty, we shouldn't 
    // have any problem here;
    //
    ParentNode = (PCM_KEY_NODE)HvGetCell(Hive,Parent);
    if( ParentNode == NULL ) {
        //
        // cannot map view; this shouldn't happen as we just allocated 
        // this cell (i.e. it should be dirty/pinned into memory)
        //
        ASSERT( FALSE );
        return FALSE;
    }

    // release the cell here; as the registry is locked exclusive (i.e. we don't care)
    HvReleaseCell(Hive, Parent);
    
    //
    // iterate through the child list (both stable and volatile), marking every
    // child dirty; this will pin the cell into memory and we will have no problems 
    // changine the parent later on
    //
    Count = ParentNode->SubKeyCounts[Stable] + ParentNode->SubKeyCounts[Volatile];
    for( i=0;i<Count;i++) {
        Child = CmpFindSubKeyByNumber(Hive,ParentNode,i);
        if( Child == HCELL_NIL ) {
            return FALSE;
        }
        if(!HvMarkCellDirty(Hive,Child)) {
            return FALSE;
        }
    }

    //
    // second iteration, change the parent for each and every son
    //
    for( i=0;i<Count;i++) {
        Child = CmpFindSubKeyByNumber(Hive,ParentNode,i);

        //
        // sanity test: we marked this dirty few lines above!
        //
        ASSERT( Child != HCELL_NIL );

        CurrentSon = (PCM_KEY_NODE)HvGetCell(Hive,Child);

        // release the cell here; as the registry is locked exclusive (i.e. we don't care)
        HvReleaseCell(Hive, Child);

        //
        // sanity test: this cell should be pinned in memory by now
        //
        ASSERT( CurrentSon != NULL );

        //
        // change the parent
        //
        CurrentSon->Parent = Parent;
    }

    return TRUE;
}


#endif //NT_RENAME_KEY

ULONG
CmpComputeHashKey(
    PUNICODE_STRING Name
    )
{
    ULONG                   ConvKey = 0;
    ULONG                   Cnt;
    WCHAR                   *Cp;

    ASSERT( (Name->Buffer[0] != OBJ_NAME_PATH_SEPARATOR) || (Name->Length == 0));
    //
    // Manually compute the hash to use.
    //

    Cp = Name->Buffer;
    for (Cnt=0; Cnt<Name->Length; Cnt += sizeof(WCHAR)) {
        ASSERT( *Cp != OBJ_NAME_PATH_SEPARATOR );
        ConvKey = 37 * ConvKey + (ULONG)RtlUpcaseUnicodeChar(*Cp);
        ++Cp;
    }

    return ConvKey;
}

ULONG
CmpComputeHashKeyForCompressedName(
                                    IN PWCHAR Source,
                                    IN ULONG SourceLength
                                    )
{
    ULONG   ConvKey = 0;
    ULONG   i;

    for (i=0;i<SourceLength;i++) {
        ConvKey = 37*ConvKey + (ULONG)RtlUpcaseUnicodeChar((WCHAR)(((PUCHAR)Source)[i]));
    }

    return ConvKey;
}

//
// HashIndex routines
//


HCELL_INDEX
CmpFindSubKeyByHash(
    PHHIVE                  Hive,
    PCM_KEY_FAST_INDEX      FastIndex,
    PUNICODE_STRING         SearchName
    )
/*++

Routine Description:

    Find the child cell (either subkey or value) specified by name.
    It searched in the index table ordered by the hash

Arguments:

    Hive - pointer to hive control structure for hive of interest

    Index - 

    SearchName - name of child of interest

Return Value:

    Cell of matching child key, or HCELL_NIL if none.

--*/
{
    USHORT      Current;
    ULONG       HashKey;
    LONG        Result;

#ifndef _CM_LDR_
    PAGED_CODE();
#endif //_CM_LDR_

    ASSERT( FastIndex->Signature == CM_KEY_HASH_LEAF );

    HashKey = CmpComputeHashKey(SearchName);

    for(Current = 0; Current < FastIndex->Count; Current++ ) {
        if( HashKey == FastIndex->List[Current].HashKey ) {
            //
            // HashKey matches; see if this is a real hit
            //

            Result = CmpDoCompareKeyName(Hive,SearchName,FastIndex->List[Current].Cell);
            if (Result == 0) {
                return FastIndex->List[Current].Cell;
            }

        }
    }

    return HCELL_NIL;
}
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\base\ntos\config\cminit.c ===
/*++

Copyright (c) 1992  Microsoft Corporation

Module Name:

    cminit.c

Abstract:

    This module contains init support for the CM level of the
    config manager/hive.

Author:

    Bryan M. Willman (bryanwi) 2-Apr-1992

Revision History:

--*/

#include    "cmp.h"

//
// Prototypes local to this module
//
NTSTATUS
CmpOpenFileWithExtremePrejudice(
    OUT PHANDLE Primary,
    IN POBJECT_ATTRIBUTES Obja,
    IN ULONG IoFlags,
    IN ULONG AttributeFlags
    );


#ifdef ALLOC_PRAGMA
#pragma alloc_text(PAGE,CmpOpenHiveFiles)
#pragma alloc_text(PAGE,CmpInitializeHive)
#pragma alloc_text(PAGE,CmpDestroyHive)
#pragma alloc_text(PAGE,CmpOpenFileWithExtremePrejudice)
#endif

extern PCMHIVE CmpMasterHive;
extern LIST_ENTRY CmpHiveListHead;

NTSTATUS
CmpOpenHiveFiles(
    PUNICODE_STRING     BaseName,
    PWSTR               Extension OPTIONAL,
    PHANDLE             Primary,
    PHANDLE             Secondary,
    PULONG              PrimaryDisposition,
    PULONG              SecondaryDisposition,
    BOOLEAN             CreateAllowed,
    BOOLEAN             MarkAsSystemHive,
    BOOLEAN             NoBuffering,
    OUT OPTIONAL PULONG ClusterSize
    )
/*++

Routine Description:

    Open/Create Primary, and Log files for Hives.

    BaseName is some name like "\winnt\system32\config\system".
    Extension is ".alt" or ".log" or NULL.

    If extension is NULL skip secondary work.

    If extension is .alt or .log, open/create a secondary file
    (e.g. "\winnt\system32\config\system.alt")

    If extension is .log, open secondary for buffered I/O, else,
    open for non-buffered I/O.  Primary always uses non-buffered I/O.

    If primary is newly created, supersede secondary.  If secondary
    does not exist, simply create (other code will complain if Log
    is needed but does not exist.)

    WARNING:    If Secondary handle is NULL, you have no log
                or alternate!

Arguments:

    BaseName - unicode string of base hive file, must have space for
                extension if that is used.

    Extension - unicode type extension of secondary file, including
                the leading "."

    Primary - will get handle to primary file

    Secondary - will get handle to secondary, or NULL

    PrimaryDisposition - STATUS_SUCCESS or STATUS_CREATED, of primary file.

    SecondaryDisposition - STATUS_SUCCESS or STATUS_CREATED, of secondary file.

    CreateAllowed - if TRUE will create nonexistent primary, if FALSE will
                    fail if primary does not exist.  no effect on log

    MarkAsSystemHive - if TRUE will call into file system to mark this
                       as a critical system hive.

    ClusterSize - if not NULL, will compute and return the appropriate
        cluster size for the primary file.

Return Value:

    status - if status is success, Primay succeeded, check Secondary
             value to see if it succeeded.

--*/
{
    IO_STATUS_BLOCK     IoStatus;
    IO_STATUS_BLOCK     FsctlIoStatus;
    FILE_FS_SIZE_INFORMATION FsSizeInformation;
    ULONG Cluster;
    ULONG               CreateDisposition;
    OBJECT_ATTRIBUTES   ObjectAttributes;
    NTSTATUS            status;
    UNICODE_STRING      ExtName;
    UNICODE_STRING      WorkName;
    PVOID               WorkBuffer;
    USHORT              NameSize;
    ULONG               IoFlags;
    ULONG               AttributeFlags;
    ULONG               ShareMode;
    ULONG               DesiredAccess;
    USHORT              CompressionState;
    HANDLE              hEvent;
    PKEVENT             pEvent;
#ifdef CM_RETRY_CREATE_FILE
    ULONG               RetryCreateCount = 0;
#endif //CM_RETRY_CREATE_FILE

    //
    // Allocate an event to use for our overlapped I/O
    //
    status = CmpCreateEvent(NotificationEvent, &hEvent, &pEvent);
    if (!NT_SUCCESS(status)) {
        return(status);
    }
    
    //
    // Allocate a buffer big enough to hold the full name
    //
    WorkName.Length = 0;
    WorkName.MaximumLength = 0;
    WorkName.Buffer = NULL;
    WorkBuffer = NULL;

    NameSize = BaseName->Length;
    if (ARGUMENT_PRESENT(Extension)) {
        NameSize += (wcslen(Extension)+1) * sizeof(WCHAR);
        WorkBuffer = ExAllocatePool(PagedPool, NameSize);
        WorkName.Buffer = WorkBuffer;
        if (WorkBuffer == NULL) {
            ObDereferenceObject(pEvent);
            ZwClose(hEvent);
            return STATUS_NO_MEMORY;
        }
        WorkName.MaximumLength = NameSize;
        RtlAppendStringToString((PSTRING)&WorkName, (PSTRING)BaseName);
    } else {
        WorkName = *BaseName;
    }


    //
    // Open/Create the primary
    //
    InitializeObjectAttributes(
        &ObjectAttributes,
        &WorkName,
        OBJ_CASE_INSENSITIVE | OBJ_KERNEL_HANDLE,
        NULL,
        NULL
        );

    if (CreateAllowed && !CmpShareSystemHives) {
        CreateDisposition = FILE_OPEN_IF;
    } else {
        CreateDisposition = FILE_OPEN;
    }

    ASSERT_PASSIVE_LEVEL();

    AttributeFlags = FILE_OPEN_FOR_BACKUP_INTENT | FILE_NO_COMPRESSION | FILE_RANDOM_ACCESS;
    if( NoBuffering == TRUE ) {
        AttributeFlags |= FILE_NO_INTERMEDIATE_BUFFERING;
    }
#ifdef CM_RETRY_CREATE_FILE
RetryCreate1:
#endif //CM_RETRY_CREATE_FILE

    //
    // Share the file if needed
    //
    if (CmpMiniNTBoot && CmpShareSystemHives) {
    	DesiredAccess = FILE_READ_DATA;
    	ShareMode = FILE_SHARE_READ;	
    } else {
    	ShareMode = 0;
    	DesiredAccess = FILE_READ_DATA | FILE_WRITE_DATA;
    }				

    status = ZwCreateFile(
                Primary,
                DesiredAccess,
                &ObjectAttributes,
                &IoStatus,
                NULL,                               // alloc size = none
                FILE_ATTRIBUTE_NORMAL,
                ShareMode,                                  // share nothing
                CreateDisposition,
                ////FILE_NO_INTERMEDIATE_BUFFERING | 
                //FILE_OPEN_FOR_BACKUP_INTENT |
                //FILE_NO_COMPRESSION,
                AttributeFlags,
                NULL,                               // eabuffer
                0                                   // ealength
                );
#ifdef CM_RETRY_CREATE_FILE
    if( !NT_SUCCESS(status) ) {
        if( RetryCreateCount == 0 ) {
            RetryCreateCount++;
            DbgBreakPoint();
            goto RetryCreate1;
        } 
    } 
    //
    // reset it for the log
    //
    RetryCreateCount = 0;
#endif //CM_RETRY_CREATE_FILE

    if (status == STATUS_ACCESS_DENIED) {

        //
        // This means some  person has put a read-only attribute
        // on one of the critical system hive files. Remove it so they
        // don't hurt themselves.
        //

        status = CmpOpenFileWithExtremePrejudice(Primary,
                                                 &ObjectAttributes,
                                                 AttributeFlags,
                                                 FILE_ATTRIBUTE_NORMAL);
    }

    if (!CmpShareSystemHives && (MarkAsSystemHive) &&
        (NT_SUCCESS(status))) {

        ASSERT_PASSIVE_LEVEL();
        status = ZwFsControlFile(*Primary,
                                 hEvent,
                                 NULL,
                                 NULL,
                                 &FsctlIoStatus,
                                 FSCTL_MARK_AS_SYSTEM_HIVE,
                                 NULL,
                                 0,
                                 NULL,
                                 0);
        if (status == STATUS_PENDING) {
            KeWaitForSingleObject(pEvent,
                                  Executive,
                                  KernelMode,
                                  FALSE,
                                  NULL);
            status = FsctlIoStatus.Status;
        }

        //
        //  STATUS_INVALID_DEVICE_REQUEST is OK.
        //

        if (status == STATUS_INVALID_DEVICE_REQUEST) {
            status = STATUS_SUCCESS;

        } else if (!NT_SUCCESS(status)) {
            ZwClose(*Primary);
        }
    }

    if (!NT_SUCCESS(status)) {

        CmKdPrintEx((DPFLTR_CONFIG_ID,CML_BUGCHECK,"CMINIT: CmpOpenHiveFile: "));
        CmKdPrintEx((DPFLTR_CONFIG_ID,CML_BUGCHECK,"\tPrimary Open/Create failed for:\n"));
        CmKdPrintEx((DPFLTR_CONFIG_ID,CML_BUGCHECK,"\t%wZ\n", &WorkName));
        CmKdPrintEx((DPFLTR_CONFIG_ID,CML_BUGCHECK,"\tstatus = %08lx\n", status));

        if (WorkBuffer != NULL) {
            ExFreePool(WorkBuffer);
        }
        ObDereferenceObject(pEvent);
        ZwClose(hEvent);
        return status;
    }

    //
    // Make sure the file is uncompressed in order to prevent the filesystem
    // from failing our updates due to disk full conditions.
    //
    // Do not fail to open the file if this fails, we don't want to prevent
    // people from booting just because their disk is full. Although they
    // will not be able to update their registry, they will at lease be
    // able to delete some files.
    //
    CompressionState = 0;
    ASSERT_PASSIVE_LEVEL();
    status = ZwFsControlFile(*Primary,
                             hEvent,
                             NULL,
                             NULL,
                             &FsctlIoStatus,
                             FSCTL_SET_COMPRESSION,
                             &CompressionState,
                             sizeof(CompressionState),
                             NULL,
                             0);
    if (status == STATUS_PENDING) {
        KeWaitForSingleObject(pEvent,
                              Executive,
                              KernelMode,
                              FALSE,
                              NULL);
    }

    *PrimaryDisposition = (ULONG) IoStatus.Information;

    if( *PrimaryDisposition != FILE_CREATED ) {
        //
        // 0-lengthed file case
        //
        FILE_STANDARD_INFORMATION   FileInformation;
        NTSTATUS                    status2;
        
        status2 = ZwQueryInformationFile(*Primary,
                                         &IoStatus,
                                         (PVOID)&FileInformation,
                                         sizeof( FileInformation ),
                                         FileStandardInformation
                                       );
        if (NT_SUCCESS( status2 )) {
            if(FileInformation.EndOfFile.QuadPart == 0) {
                //
                // treat it as a non-existant one.
                //
                *PrimaryDisposition = FILE_CREATED;
                CmKdPrintEx((DPFLTR_CONFIG_ID,DPFLTR_TRACE_LEVEL,"Primary file is zero-lengthed => treat it as non-existant\n"));
            }
        }
    }

    if (ARGUMENT_PRESENT(ClusterSize)) {

        ASSERT_PASSIVE_LEVEL();
        status = ZwQueryVolumeInformationFile(*Primary,
                                              &IoStatus,
                                              &FsSizeInformation,
                                              sizeof(FILE_FS_SIZE_INFORMATION),
                                              FileFsSizeInformation);
        if (!NT_SUCCESS(status)) {
            ObDereferenceObject(pEvent);
            ZwClose(hEvent);
            return(status);
        }
        if (FsSizeInformation.BytesPerSector > HBLOCK_SIZE) {
            CmKdPrintEx((DPFLTR_CONFIG_ID,CML_BUGCHECK,"CmpOpenHiveFiles: sectorsize %lx > HBLOCK_SIZE\n"));
            ObDereferenceObject(pEvent);
            ZwClose(hEvent);
            return(STATUS_CANNOT_LOAD_REGISTRY_FILE);
        }

        Cluster = FsSizeInformation.BytesPerSector / HSECTOR_SIZE;
        *ClusterSize = (Cluster < 1) ? 1 : Cluster;

    }

    if ( ! ARGUMENT_PRESENT(Extension)) {
        if (WorkBuffer != NULL) {
            ExFreePool(WorkBuffer);
        }
        ObDereferenceObject(pEvent);
        ZwClose(hEvent);
        return STATUS_SUCCESS;
    }

    //
    // Open/Create the secondary
    //
    CreateDisposition = CmpShareSystemHives ? FILE_OPEN : FILE_OPEN_IF;
    
    if (*PrimaryDisposition == FILE_CREATED) {
        CreateDisposition = FILE_SUPERSEDE;
    }

    RtlInitUnicodeString(&ExtName,Extension);
    status = RtlAppendStringToString((PSTRING)&WorkName, (PSTRING)&ExtName);

    InitializeObjectAttributes(&ObjectAttributes,
                               &WorkName,
                               OBJ_CASE_INSENSITIVE | OBJ_KERNEL_HANDLE,
                               NULL,
                               NULL);

    //
    // non-cached log files (or alternates)
    //
    IoFlags = FILE_NO_COMPRESSION | FILE_NO_INTERMEDIATE_BUFFERING;
    if (_wcsnicmp(Extension, L".log", 4) != 0) {
        AttributeFlags = FILE_ATTRIBUTE_NORMAL;
    } else {
        AttributeFlags = FILE_ATTRIBUTE_NORMAL | FILE_ATTRIBUTE_HIDDEN;
    }

#ifdef CM_RETRY_CREATE_FILE
RetryCreate2:
#endif //CM_RETRY_CREATE_FILE


    ASSERT_PASSIVE_LEVEL();
    status = ZwCreateFile(
                Secondary,
                DesiredAccess,
                &ObjectAttributes,
                &IoStatus,
                NULL,                               // alloc size = none
                AttributeFlags,
                ShareMode,
                CreateDisposition,
                IoFlags,
                NULL,                               // eabuffer
                0                                   // ealength
                );
#ifdef CM_RETRY_CREATE_FILE
    if( !NT_SUCCESS(status) ) {
        if( RetryCreateCount == 0 ) {
            RetryCreateCount++;
            DbgBreakPoint();
            goto RetryCreate2;
        } 
    } 
#endif //CM_RETRY_CREATE_FILE

    if (status == STATUS_ACCESS_DENIED) {

        //
        // This means some person has put a read-only attribute
        // on one of the critical system hive files. Remove it so they
        // don't hurt themselves.
        //

        status = CmpOpenFileWithExtremePrejudice(Secondary,
                                                 &ObjectAttributes,
                                                 IoFlags,
                                                 AttributeFlags);
    }

    if (!CmpShareSystemHives && (MarkAsSystemHive) &&
        (NT_SUCCESS(status))) {

        ASSERT_PASSIVE_LEVEL();
        status = ZwFsControlFile(*Secondary,
                                 hEvent,
                                 NULL,
                                 NULL,
                                 &FsctlIoStatus,
                                 FSCTL_MARK_AS_SYSTEM_HIVE,
                                 NULL,
                                 0,
                                 NULL,
                                 0);
        if (status == STATUS_PENDING) {
            KeWaitForSingleObject(pEvent,
                                  Executive,
                                  KernelMode,
                                  FALSE,
                                  NULL);
            status = FsctlIoStatus.Status;
        }
        //
        //  STATUS_INVALID_DEVICE_REQUEST is OK.
        //

        if (status == STATUS_INVALID_DEVICE_REQUEST) {
            status = STATUS_SUCCESS;

        } else if (!NT_SUCCESS(status)) {

            ZwClose(*Secondary);
        }
    }

    if (!NT_SUCCESS(status)) {

        CmKdPrintEx((DPFLTR_CONFIG_ID,CML_BUGCHECK,"CMINIT: CmpOpenHiveFile: "));
        CmKdPrintEx((DPFLTR_CONFIG_ID,CML_BUGCHECK,"\tSecondary Open/Create failed for:\n"));
        CmKdPrintEx((DPFLTR_CONFIG_ID,CML_BUGCHECK,"\t%wZ\n", &WorkName));
        CmKdPrintEx((DPFLTR_CONFIG_ID,CML_BUGCHECK,"\tstatus = %08lx\n", status));

        *Secondary = NULL;
    }

    *SecondaryDisposition = (ULONG) IoStatus.Information;

    //
    // Make sure the file is uncompressed in order to prevent the filesystem
    // from failing our updates due to disk full conditions.
    //
    // Do not fail to open the file if this fails, we don't want to prevent
    // people from booting just because their disk is full. Although they
    // will not be able to update their registry, they will at lease be
    // able to delete some files.
    //
    CompressionState = 0;

    ASSERT_PASSIVE_LEVEL();
    status = ZwFsControlFile(*Secondary,
                             hEvent,
                             NULL,
                             NULL,
                             &FsctlIoStatus,
                             FSCTL_SET_COMPRESSION,
                             &CompressionState,
                             sizeof(CompressionState),
                             NULL,
                             0);
    if (status == STATUS_PENDING) {
        KeWaitForSingleObject(pEvent,
                              Executive,
                              KernelMode,
                              FALSE,
                              NULL);
    }

    if (WorkBuffer != NULL) {
        ExFreePool(WorkBuffer);
    }
    ObDereferenceObject(pEvent);
    ZwClose(hEvent);
    return STATUS_SUCCESS;
}


NTSTATUS
CmpInitializeHive(
    PCMHIVE         *CmHive,
    ULONG           OperationType,
    ULONG           HiveFlags,
    ULONG           FileType,
    PVOID           HiveData OPTIONAL,
    HANDLE          Primary,
    HANDLE          Log,
    HANDLE          External,
    PUNICODE_STRING FileName OPTIONAL,
    ULONG           CheckFlags
    )
/*++

Routine Description:

    Initialize a hive.

Arguments:

    CmHive - pointer to a variable to receive a pointer to the CmHive structure

    OperationType - specifies whether to create a new hive from scratch,
            from a memory image, or by reading a file from disk.
            [HINIT_CREATE | HINIT_MEMORY | HINIT_FILE | HINIT_MAPFILE]

    HiveFlags - HIVE_VOLATILE - Entire hive is to be volatile, regardless
                                   of the types of cells allocated
                HIVE_NO_LAZY_FLUSH - Data in this hive is never written
                                   to disk except by an explicit FlushKey

    FileType - HFILE_TYPE_*, HFILE_TYPE_LOG set up for logging support 

    HiveData - if present, supplies a pointer to an in memory image of
            from which to init the hive.  Only useful when OperationType
            is set to HINIT_MEMORY.

    Primary - File handle for primary hive file (e.g. SYSTEM)

    Log - File handle for log hive file (e.g. SOFTWARE.LOG)

    External - File handle for primary hive file  (e.g.  BACKUP.REG)

    FileName - some path like "...\system32\config\system", which will
                be written into the base block as an aid to debugging.
                may be NULL.

    CheckFlags - Flags to be passed to CmCheckRegistry

        usually this is CM_CHECK_REGISTRY_CHECK_CLEAN, except for the system hive 
        where CM_CHECK_REGISTRY_FORCE_CLEAN is passed

Return Value:

    NTSTATUS

--*/
{
    FILE_FS_SIZE_INFORMATION    FsSizeInformation;
    IO_STATUS_BLOCK             IoStatusBlock;
    ULONG                       Cluster;
    NTSTATUS                    Status;
    PCMHIVE                     cmhive2;
    ULONG                       rc;

    CmKdPrintEx((DPFLTR_CONFIG_ID,CML_INIT,"CmpInitializeHive:\t\n"));

    //
    // Reject illegal parms
    //
    if ( (External && (Primary || Log)) ||
         (Log && !Primary) ||
         (!CmpShareSystemHives && (HiveFlags & HIVE_VOLATILE) && (Primary || External || Log)) ||
         ((OperationType == HINIT_MEMORY) && (!ARGUMENT_PRESENT(HiveData))) ||
         (Log && (FileType != HFILE_TYPE_LOG)) 
       )
    {
        return (STATUS_INVALID_PARAMETER);
    }

    //
    // compute control
    //
    if (Primary) {

        ASSERT_PASSIVE_LEVEL();
        Status = ZwQueryVolumeInformationFile(
                    Primary,
                    &IoStatusBlock,
                    &FsSizeInformation,
                    sizeof(FILE_FS_SIZE_INFORMATION),
                    FileFsSizeInformation
                    );
        if (!NT_SUCCESS(Status)) {
            return (Status);
        }
        if (FsSizeInformation.BytesPerSector > HBLOCK_SIZE) {
            return (STATUS_REGISTRY_IO_FAILED);
        }
        Cluster = FsSizeInformation.BytesPerSector / HSECTOR_SIZE;
        Cluster = (Cluster < 1) ? 1 : Cluster;
    } else {
        Cluster = 1;
    }

    cmhive2 = CmpAllocate(sizeof(CMHIVE), FALSE,CM_FIND_LEAK_TAG10);

    if (cmhive2 == NULL) {
        return (STATUS_INSUFFICIENT_RESOURCES);
    }

#ifdef NT_UNLOAD_KEY_EX
    cmhive2->UnloadEvent = NULL;
    cmhive2->RootKcb = NULL;
    cmhive2->Frozen = FALSE;
    cmhive2->UnloadWorkItem = NULL;
#endif //NT_UNLOAD_KEY_EX

    cmhive2->GrowOnlyMode = FALSE;
    cmhive2->GrowOffset = 0;

    InitializeListHead(&(cmhive2->KcbConvertListHead));
    InitializeListHead(&(cmhive2->KnodeConvertListHead));
	cmhive2->CellRemapArray	= NULL;
    //
    // Allocate the mutex from NonPagedPool so it will not be swapped to the disk
    //
    cmhive2->HiveLock = (PFAST_MUTEX)ExAllocatePoolWithTag(NonPagedPool, sizeof(FAST_MUTEX), CM_POOL_TAG );
    if( cmhive2->HiveLock == NULL ) {
        CmpFree(cmhive2, sizeof(CMHIVE));
        return (STATUS_INSUFFICIENT_RESOURCES);
    }

    cmhive2->ViewLock = (PFAST_MUTEX)ExAllocatePoolWithTag(NonPagedPool, sizeof(FAST_MUTEX), CM_POOL_TAG );
    if( cmhive2->ViewLock == NULL ) {
        ASSERT( cmhive2->HiveLock );
        ExFreePool(cmhive2->HiveLock);
        CmpFree(cmhive2, sizeof(CMHIVE));
        return (STATUS_INSUFFICIENT_RESOURCES);
    }

    // need to do this consistently!!!
    cmhive2->FileObject = NULL;
    cmhive2->FileFullPath.Buffer = NULL;
    cmhive2->FileFullPath.Length = 0;
    cmhive2->FileFullPath.MaximumLength = 0;

    cmhive2->FileUserName.Buffer = NULL;
    cmhive2->FileUserName.Length = 0;
    cmhive2->FileUserName.MaximumLength = 0;

    //
    // Initialize the Cm hive control block
    //
    //
    ASSERT((HFILE_TYPE_EXTERNAL+1) == HFILE_TYPE_MAX);
    cmhive2->FileHandles[HFILE_TYPE_PRIMARY] = Primary;
    cmhive2->FileHandles[HFILE_TYPE_LOG] = Log;
    cmhive2->FileHandles[HFILE_TYPE_EXTERNAL] = External;

    cmhive2->NotifyList.Flink = NULL;
    cmhive2->NotifyList.Blink = NULL;

    ExInitializeFastMutex(cmhive2->HiveLock);
    ExInitializeFastMutex(cmhive2->ViewLock);

    CmpInitHiveViewList(cmhive2);
    //
    // Initialize the view list
    //
#if DBG
    if( FileName ) {
        CmKdPrintEx((DPFLTR_CONFIG_ID,DPFLTR_TRACE_LEVEL,"Initializing HiveViewList for hive (%p) (%.*S) \n\n",cmhive2,FileName->Length / sizeof(WCHAR),FileName->Buffer));
    }
#endif

    //
    // Initialize the security cache
    // 
    CmpInitSecurityCache(cmhive2);
    
    //
    // Initialize the Hv hive control block
    //
    Status = HvInitializeHive(
                &(cmhive2->Hive),
                OperationType,
                HiveFlags,
                FileType,
                HiveData,
                CmpAllocate,
                CmpFree,
                CmpFileSetSize,
                CmpFileWrite,
                CmpFileRead,
                CmpFileFlush,
                Cluster,
                FileName
                );
    if (!NT_SUCCESS(Status)) {
        CmKdPrintEx((DPFLTR_CONFIG_ID,CML_BUGCHECK,"CmpInitializeHive: "));
        CmKdPrintEx((DPFLTR_CONFIG_ID,CML_BUGCHECK,"HvInitializeHive failed, Status = %08lx\n", Status));
        
#ifdef DRAGOSS_PRIVATE_DEBUG
        if( OperationType == HINIT_FILE ) DbgBreakPoint();
#endif //DRAGOSS_PRIVATE_DEBUG
        
        ASSERT( cmhive2->HiveLock );
        ExFreePool(cmhive2->HiveLock);
        ASSERT( cmhive2->ViewLock );
        ExFreePool(cmhive2->ViewLock);
        CmpDestroyHiveViewList(cmhive2);
        CmpDestroySecurityCache (cmhive2);
        CmpDropFileObjectForHive(cmhive2);

        CmpCheckForOrphanedKcbs((PHHIVE)cmhive2);

        CmpFree(cmhive2, sizeof(CMHIVE));
        return (Status);
    }
    if ( (OperationType == HINIT_FILE) ||
         (OperationType == HINIT_MAPFILE) ||
         (OperationType == HINIT_MEMORY) ||
         (OperationType == HINIT_MEMORY_INPLACE))
    {

        rc = CmCheckRegistry(cmhive2, CheckFlags);
        if (rc != 0) {
            PCM_VIEW_OF_FILE    CmView;

            CmKdPrintEx((DPFLTR_CONFIG_ID,CML_BUGCHECK,"CmpInitializeHive: "));
            CmKdPrintEx((DPFLTR_CONFIG_ID,CML_BUGCHECK,"CmCheckRegistry failed, rc = %08lx\n",rc));
            // 
            // we have dirtied some cells (by clearing the volatile information)
            // we need first to unpin all the views

#ifdef DRAGOSS_PRIVATE_DEBUG
            if( OperationType == HINIT_FILE ) DbgBreakPoint();
#endif //DRAGOSS_PRIVATE_DEBUG

            //
            // in theory we should do this for MEMORY and MEMORY_INPLACE
            // as well, but they're only used at init time.
            //
            CmpDestroyHiveViewList(cmhive2);
            CmpDestroySecurityCache(cmhive2);
            CmpDropFileObjectForHive(cmhive2);

            if (OperationType == HINIT_FILE) {
                HvFreeHive((PHHIVE)cmhive2);
            } else {
                CmpCheckForOrphanedKcbs((PHHIVE)cmhive2);
            }
            ASSERT( cmhive2->HiveLock );
            ExFreePool(cmhive2->HiveLock);
            ASSERT( cmhive2->ViewLock );
            ExFreePool(cmhive2->ViewLock);

            CmpFree(cmhive2, sizeof(CMHIVE));
            return(STATUS_REGISTRY_CORRUPT);
        }
    }

    LOCK_HIVE_LIST();
    InsertHeadList(&CmpHiveListHead, &(cmhive2->HiveList));
    UNLOCK_HIVE_LIST();
    *CmHive = cmhive2;
    return (STATUS_SUCCESS);
}


BOOLEAN
CmpDestroyHive(
    IN PHHIVE Hive,
    IN HCELL_INDEX Cell
    )

/*++

Routine Description:

    This routine tears down a cmhive.

Arguments:

    Hive - Supplies a pointer to the hive to be freed.

    Cell - Supplies index of the hive's root cell.

Return Value:

    TRUE if successful
    FALSE if some failure occurred

--*/

{
    PCELL_DATA CellData;
    HCELL_INDEX LinkCell;
    NTSTATUS Status;

    //
    // First find the link cell.
    //
    CellData = HvGetCell(Hive, Cell);
    if( CellData == NULL ) {
        //
        // we couldn't map the bin containing this cell
        //
        return FALSE;
    }
    LinkCell = CellData->u.KeyNode.Parent;
    HvReleaseCell(Hive, Cell);

    //
    // Now delete the link cell.
    //
    ASSERT(FIELD_OFFSET(CMHIVE, Hive) == 0);
    Status = CmpFreeKeyByCell((PHHIVE)CmpMasterHive, LinkCell, TRUE);

    if (NT_SUCCESS(Status)) {
        //
        // Take the hive out of the hive list
        //
        LOCK_HIVE_LIST();
        CmpRemoveEntryList(&( ((PCMHIVE)Hive)->HiveList));
        UNLOCK_HIVE_LIST();
        return(TRUE);
    } else {
        return(FALSE);
    }
}


NTSTATUS
CmpOpenFileWithExtremePrejudice(
    OUT PHANDLE Primary,
    IN POBJECT_ATTRIBUTES Obja,
    IN ULONG IoFlags,
    IN ULONG AttributeFlags
    )

/*++

Routine Description:

    This routine opens a hive file that some person has put a
    read-only attribute on. It is used to prevent people from hurting
    themselves by making the critical system hive files read-only.

Arguments:

    Primary - Returns handle to file

    Obja - Supplies Object Attributes of file.

    IoFlags - Supplies flags to pass to ZwCreateFile

Return Value:

    NTSTATUS

--*/

{
    NTSTATUS Status;
    HANDLE Handle;
    IO_STATUS_BLOCK IoStatusBlock;
    FILE_BASIC_INFORMATION FileInfo;

    RtlZeroMemory(&FileInfo, sizeof(FileInfo));
    //
    // Get the current file attributes
    //
    ASSERT_PASSIVE_LEVEL();
    Status = ZwQueryAttributesFile(Obja, &FileInfo);
    if (!NT_SUCCESS(Status)) {
        CmKdPrintEx((DPFLTR_CONFIG_ID,DPFLTR_ERROR_LEVEL,"ZwQueryAttributesFile failed with IO status  %lx\n",Status));
        return(Status);
    }

    //
    // Clear the readonly bit.
    //
    FileInfo.FileAttributes &= ~FILE_ATTRIBUTE_READONLY;

    //
    // Open the file
    //
    Status = ZwOpenFile(&Handle,
                        FILE_WRITE_ATTRIBUTES,
                        Obja,
                        &IoStatusBlock,
                        FILE_SHARE_READ | FILE_SHARE_WRITE | FILE_SHARE_DELETE,
                        FILE_OPEN_FOR_BACKUP_INTENT);
    if (!NT_SUCCESS(Status)) {
        return(Status);
    }

    //
    // Set the new attributes
    //
    Status = ZwSetInformationFile(Handle,
                                  &IoStatusBlock,
                                  &FileInfo,
                                  sizeof(FileInfo),
                                  FileBasicInformation);
    ZwClose(Handle);
    if (NT_SUCCESS(Status)) {
        //
        // Reopen the file with the access that we really need.
        //
        Status = ZwCreateFile(Primary,
                              FILE_READ_DATA | FILE_WRITE_DATA,
                              Obja,
                              &IoStatusBlock,
                              NULL,
                              AttributeFlags,
                              0,
                              FILE_OPEN,
                              IoFlags,
                              NULL,
                              0);
    }
#if DBG
    else {
        CmKdPrintEx((DPFLTR_CONFIG_ID,DPFLTR_ERROR_LEVEL,"ZwSetInformationFile failed with IO status  %lx\n",Status));
    }
    CmKdPrintEx((DPFLTR_CONFIG_ID,DPFLTR_ERROR_LEVEL,"CmpOpenFileWithExtremePrejudice returns with IO status  %lx\n",Status));
#endif

    return(Status);

}
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\base\ntos\config\cmhvlist.c ===
/*++

Copyright (c) 1991  Microsoft Corporation

Module Name:

    cmhvlist.c

Abstract:

    Code to maintain registry node that lists where the roots of
    hives are and what files they map to.

Author:

    Bryan M. Willman (bryanwi) 14-May-1992

Revision History:

--*/

#include "cmp.h"

#define HIVE_LIST L"\\registry\\machine\\system\\currentcontrolset\\control\\hivelist"

extern PCMHIVE CmpMasterHive;

BOOLEAN
CmpGetHiveName(
    PCMHIVE         CmHive,
    PUNICODE_STRING HiveName
    );

#ifdef ALLOC_PRAGMA
#pragma alloc_text(PAGE,CmpAddToHiveFileList)
#pragma alloc_text(PAGE,CmpRemoveFromHiveFileList)
#pragma alloc_text(PAGE,CmpGetHiveName)
#endif


NTSTATUS
CmpAddToHiveFileList(
    PCMHIVE CmHive
    )
/*++

Routine Description:

    Add Hive to list of hives and their files in
    \registry\machine\system\currentcontrolset\control\hivelist

Arguments:

    HivePath - path to root of hive (e.g. \registry\machine\system)

    CmHive - pointer to CM_HIVE structure for hive.

Return Value:

    ntstatus

--*/
{
//
//  PERFNOTE - allocate small instead of large buffers after
//           NtQueryObject is fixec - bryanwi 15may92
//
#define NAME_BUFFER_SIZE    512
    OBJECT_ATTRIBUTES   ObjectAttributes;
    HANDLE              KeyHandle;
    NTSTATUS            Status;
    PUCHAR              Buffer;
    ULONG               Length;
    PWSTR               FilePath;
    WCHAR               UnicodeNull=UNICODE_NULL;
    UNICODE_STRING      TempName;
    UNICODE_STRING      HivePath;

    //
    // create/open the hive list key
    //
    RtlInitUnicodeString(
        &TempName,
        HIVE_LIST
        );

    InitializeObjectAttributes(
        &ObjectAttributes,
        &TempName,
        OBJ_CASE_INSENSITIVE,
        (HANDLE)NULL,
        NULL
        );

    Status = ZwCreateKey(
                &KeyHandle,
                KEY_READ | KEY_WRITE,
                &ObjectAttributes,
                0,
                NULL,
                REG_OPTION_VOLATILE,
                NULL
                );

    if (!NT_SUCCESS(Status)) {
        CmKdPrintEx((DPFLTR_CONFIG_ID,CML_BUGCHECK,"CmpAddToHiveFileList: "));
        CmKdPrintEx((DPFLTR_CONFIG_ID,CML_BUGCHECK,"Create/Open of Hive list failed status = %08lx\n", Status));
        return Status;
    }

    //
    // allocate work buffers
    //
    Buffer = ExAllocatePool(PagedPool, NAME_BUFFER_SIZE);
    if (Buffer == NULL) {
        NtClose(KeyHandle);
        return STATUS_NO_MEMORY;
    }

    //
    // compute name of hive
    //
    if (! CmpGetHiveName(CmHive, &HivePath)) {
        NtClose(KeyHandle);
        ExFreePool(Buffer);
        return STATUS_NO_MEMORY;
    }


    //
    // get name of file
    //
    if (!(CmHive->Hive.HiveFlags & HIVE_VOLATILE)) {
        Status = ZwQueryObject(
                    CmHive->FileHandles[HFILE_TYPE_PRIMARY],
                    ObjectNameInformation,
                    (PVOID)Buffer,
                    NAME_BUFFER_SIZE,
                    &Length
                    );
        Length -= sizeof(UNICODE_STRING);
        if (!NT_SUCCESS(Status)) {
            CmKdPrintEx((DPFLTR_CONFIG_ID,CML_BUGCHECK,"CmpAddToHiveFileList: "));
            CmKdPrintEx((DPFLTR_CONFIG_ID,CML_BUGCHECK,"Query of name2 failed status = %08lx\n", Status));
            NtClose(KeyHandle);
            ExFreePool(HivePath.Buffer);
            ExFreePool(Buffer);
            return  Status;
        }
        FilePath = ((POBJECT_NAME_INFORMATION)Buffer)->Name.Buffer;
        FilePath[Length/sizeof(WCHAR)] = UNICODE_NULL;
        Length+=sizeof(WCHAR);
    } else {
        FilePath = &UnicodeNull;
        Length = sizeof(UnicodeNull);
    }

    //
    // set entry in list
    //
    Status = ZwSetValueKey(
                KeyHandle,
                &HivePath,
                0,
                REG_SZ,
                FilePath,
                Length
                );
    if (!NT_SUCCESS(Status)) {
        CmKdPrintEx((DPFLTR_CONFIG_ID,CML_BUGCHECK,"CmpAddToHiveFileList: "));
        CmKdPrintEx((DPFLTR_CONFIG_ID,CML_BUGCHECK,"Set of entry in Hive list failed status = %08lx\n", Status));
    }

    NtClose(KeyHandle);
    ExFreePool(HivePath.Buffer);
    ExFreePool(Buffer);
    return  Status;
}


VOID
CmpRemoveFromHiveFileList(
    PCMHIVE         CmHive
    )
/*++

Routine Description:

    Remove hive name from hive file list key

Arguments:

    CmHive - pointer to CM_HIVE structure for hive.

Return Value:

    ntstatus

--*/
{
    NTSTATUS        Status;
    UNICODE_STRING  EntryName;
    UNICODE_STRING  TempName;
    OBJECT_ATTRIBUTES   ObjectAttributes;
    HANDLE          KeyHandle;

    //
    // open the hive list key
    //
    RtlInitUnicodeString(
        &TempName,
        HIVE_LIST
        );

    InitializeObjectAttributes(
        &ObjectAttributes,
        &TempName,
        OBJ_CASE_INSENSITIVE,
        (HANDLE)NULL,
        NULL
        );

    Status = ZwOpenKey(
                &KeyHandle,
                KEY_READ | KEY_WRITE,
                &ObjectAttributes
                );

    if (!NT_SUCCESS(Status)) {
        return;
    }

    if( CmpGetHiveName(CmHive, &EntryName) ) {
        ZwDeleteValueKey(KeyHandle, &EntryName);
        ExFreePool(EntryName.Buffer);
    }

    NtClose(KeyHandle);

    return;
}


BOOLEAN
CmpGetHiveName(
    PCMHIVE         CmHive,
    PUNICODE_STRING HiveName
    )
/*++

Routine Description:

    Compute full path to a hive.

Arguments:

    CmHive - pointer to CmHive structure

    HiveName - supplies pointer to unicode string structure that
                 will be filled in with pointer to name.

                CALL IS EXPECTED TO FREE BUFFER

Return Value:

    TRUE = it worked, FALSE = it failed (memory)

--*/
{
    HCELL_INDEX     RootCell;
    HCELL_INDEX     LinkCell;
    PCM_KEY_NODE    LinkKey;
    PCM_KEY_NODE    LinkParent;
    ULONG           size;
    ULONG           rsize;
    ULONG           KeySize;
    ULONG           ParentSize;
    PWCHAR          p;
    PCM_KEY_NODE    EntryKey;

    //
    // First find the link cell.
    //
    RootCell = CmHive->Hive.BaseBlock->RootCell;
    EntryKey = (PCM_KEY_NODE)HvGetCell((PHHIVE)CmHive, RootCell);
    if( EntryKey == NULL ) {
        //
        // we couldn't map a view for the bin containing this cell
        //
        return FALSE;
    }
    LinkCell = EntryKey->Parent;
    HvReleaseCell((PHHIVE)CmHive, RootCell);

    // for master we don't need to count cell usage
    ASSERT( ((PHHIVE)CmpMasterHive)->ReleaseCellRoutine == NULL );
    //
    // Compute the value entry name, which is of the form:
    //      \registry\<parent of link node name>\<link node name>
    //
    LinkKey = (PCM_KEY_NODE)HvGetCell((PHHIVE)CmpMasterHive, LinkCell);
    if( LinkKey == NULL ) {
        //
        // we couldn't map a view for the bin containing this cell
        //
        return FALSE;
    }
    LinkParent = (PCM_KEY_NODE)HvGetCell(
                                (PHHIVE)CmpMasterHive,
                                LinkKey->Parent
                                );
    if( LinkParent == NULL ) {
        //
        // we couldn't map a view for the bin containing this cell
        //
        return FALSE;
    }
    rsize = wcslen(L"\\REGISTRY\\");

    KeySize = CmpHKeyNameLen(LinkKey);
    ParentSize = CmpHKeyNameLen(LinkParent);
    size = KeySize + ParentSize +
           (rsize * sizeof(WCHAR)) + sizeof(WCHAR);

    HiveName->Buffer = ExAllocatePool(PagedPool, size);
    if (HiveName->Buffer == NULL) {
        return FALSE;
    }

    HiveName->Length = (USHORT)size;
    HiveName->MaximumLength = (USHORT)size;
    p = HiveName->Buffer;

    RtlCopyMemory(
        (PVOID)p,
        (PVOID)L"\\REGISTRY\\",
        rsize * sizeof(WCHAR)
        );
    p += rsize;

    if (LinkParent->Flags & KEY_COMP_NAME) {
        CmpCopyCompressedName(p,
                              ParentSize,
                              LinkParent->Name,
                              LinkParent->NameLength);
    } else {
        RtlCopyMemory(
            (PVOID)p,
            (PVOID)&(LinkParent->Name[0]),
            ParentSize
            );
    }

    p += ParentSize / sizeof(WCHAR);

    *p = OBJ_NAME_PATH_SEPARATOR;
    p++;

    if (LinkKey->Flags & KEY_COMP_NAME) {
        CmpCopyCompressedName(p,
                              KeySize,
                              LinkKey->Name,
                              LinkKey->NameLength);

    } else {
        RtlCopyMemory(
            (PVOID)p,
            (PVOID)&(LinkKey->Name[0]),
            KeySize
            );
    }

    return TRUE;
}
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\base\ntos\config\cmname.c ===
/*++

Copyright (c) 1992  Microsoft Corporation

Module Name:

    cmname.c

Abstract:

    Provides routines for handling name comparisons and converting to/from the registry
    compressed name format.

Author:

    John Vert (jvert) 28-Oct-1993

Revision History:


--*/
#include "cmp.h"
#ifdef ALLOC_PRAGMA
#pragma alloc_text(PAGE,CmpNameSize)
#pragma alloc_text(PAGE,CmpCopyName)
#pragma alloc_text(PAGE,CmpCompressedNameSize)
#pragma alloc_text(PAGE,CmpCopyCompressedName)
#pragma alloc_text(PAGE,CmpCompareCompressedName)
#pragma alloc_text(PAGE,CmpCompareUnicodeString)
#endif


USHORT
CmpNameSize(
    IN PHHIVE Hive,
    IN PUNICODE_STRING Name
    )

/*++

Routine Description:

    Determines the space needed to store a given string in the registry.  May apply
    any relevant compression to compute the length, but the compression used is
    guaranteed to be the same as CmpCopyName.

Arguments:

    Hive - supplies the hive control structure (for version checking)

    Name - Supplies the unicode string to be copied into the registry.

Return Value:

    The number of bytes of storage required to store this name.

--*/

{
    ULONG i;

    if (Hive->Version == 1) {
        return(Name->Length);
    }
    for (i=0;i<Name->Length/sizeof(WCHAR);i++) {
        if ((USHORT)Name->Buffer[i] > (UCHAR)-1) {
            return(Name->Length);
        }
    }
    return(Name->Length / sizeof(WCHAR));

}

USHORT
CmpCopyName(
    IN PHHIVE Hive,
    IN PWCHAR Destination,
    IN PUNICODE_STRING Source
    )

/*++

Routine Description:

    Copies the given unicode name into the registry, applying any relevant compression
    at the same time.

Arguments:

    Hive - supplies the hive control structure (For version checking)

    Destination - Supplies the destination of the given string.

    Source - Supplies the unicode string to copy into the registry.

Return Value:

    Number of bytes of storage copied

--*/

{
    ULONG i;

    if (Hive->Version==1) {
        RtlCopyMemory(Destination,Source->Buffer, Source->Length);
        return(Source->Length);
    }

    for (i=0;i<Source->Length/sizeof(WCHAR);i++) {
        if ((USHORT)Source->Buffer[i] > (UCHAR)-1) {
            RtlCopyMemory(Destination,Source->Buffer, Source->Length);
            return(Source->Length);
        }
        ((PUCHAR)Destination)[i] = (UCHAR)(Source->Buffer[i]);
    }
    return(Source->Length / sizeof(WCHAR));
}


USHORT
CmpCompressedNameSize(
    IN PWCHAR Name,
    IN ULONG Length
    )

/*++

Routine Description:

    Computes the length of the unicode string that the given compressed name
    expands into.

Arguments:

    Name - Supplies the compressed name.

    Length - Supplies the length in bytes of the compressed name

Return Value:

    The number of bytes of storage required to hold the Unicode expanded name.

--*/

{
    return((USHORT)Length*sizeof(WCHAR));
}


VOID
CmpCopyCompressedName(
    IN PWCHAR Destination,
    IN ULONG DestinationLength,
    IN PWCHAR Source,
    IN ULONG SourceLength
    )

/*++

Routine Description:

    Copies a compressed name from the registry and expands it to Unicode.

Arguments:

    Destination - Supplies the destination Unicode buffer

    DestinationLength - Supplies the max length of the destination buffer in bytes

    Source - Supplies the compressed string.

    SourceLength - Supplies the length of the compressed string in bytes

Return Value:

    None.

--*/

{
    ULONG i;
    ULONG Chars;

    Chars = (DestinationLength/sizeof(WCHAR) < SourceLength)
             ? DestinationLength/sizeof(WCHAR)
             : SourceLength;

    for (i=0;i<Chars;i++) {
        Destination[i] = (WCHAR)(((PUCHAR)Source)[i]);
    }
}

LONG
CmpCompareCompressedName(
    IN PUNICODE_STRING  SearchName,
    IN PWCHAR           CompressedName,
    IN ULONG            NameLength,
    IN ULONG            CompareFlags
    )

/*++

Routine Description:

    Compares a compressed registry string to a Unicode string.  Does a case-insensitive
    comparison.

Arguments:

    SearchName - Supplies the Unicode string to be compared

    CompressedName - Supplies the compressed string to be compared

    NameLength - Supplies the length of the compressed string

Return Value:

    0 = SearchName == CompressedName (of Cell)

    < 0 = SearchName < CompressedName

    > 0 = SearchName > CompressedName

--*/

{
    WCHAR *s1;
    UCHAR *s2;
    USHORT n1, n2;
    WCHAR c1;
    WCHAR c2;
    LONG cDiff;

    s1 = SearchName->Buffer;
    s2 = (UCHAR *)CompressedName;
    n1 = (USHORT )(SearchName->Length / sizeof(WCHAR));
    n2 = (USHORT )(NameLength);
    while (n1 && n2) {
        c1 = *s1++;
        c2 = (WCHAR)(*s2++);

        c1 = (CompareFlags&CMP_SOURCE_UP)?c1:RtlUpcaseUnicodeChar(c1);
        c2 = (CompareFlags&CMP_DEST_UP)?c2:RtlUpcaseUnicodeChar(c2);

        if ((cDiff = ((LONG)c1 - (LONG)c2)) != 0) {
            return( cDiff );
        }

        n1--;
        n2--;
    }

    return( n1 - n2 );
}


LONG
CmpCompareUnicodeString(
    IN PUNICODE_STRING  SourceName,
    IN PUNICODE_STRING  DestName,
    IN ULONG            CompareFlags
    )

/*++

Routine Description:

    Compares 2 unicode strings; Case insensitive comparison.
    Uses flags to avoid UpCasing strings again.
    

Arguments:

    SourceName - Supplies the Unicode string to be compared

    DestName - Supplies the compressed string to be compared

    CompareFlags - Supplies the flags to control comparison (see cmp.h)

Return Value:

    0 = SearchName == CompressedName (of Cell)

    < 0 = SearchName < CompressedName

    > 0 = SearchName > CompressedName

--*/

{
    WCHAR *s1, *s2;
    USHORT n1, n2;
    WCHAR c1, c2;
    LONG cDiff;

    s1 = SourceName->Buffer;
    s2 = DestName->Buffer;
    n1 = (USHORT )(SourceName->Length / sizeof(WCHAR));
    n2 = (USHORT )(DestName->Length / sizeof(WCHAR));
    while (n1 && n2) {
        c1 = *s1++;
        c2 = *s2++;

        c1 = (CompareFlags&CMP_SOURCE_UP)?c1:RtlUpcaseUnicodeChar(c1);
        c2 = (CompareFlags&CMP_DEST_UP)?c2:RtlUpcaseUnicodeChar(c2);

        if ((cDiff = ((LONG)c1 - (LONG)c2)) != 0) {
            return( cDiff );
        }

        n1--;
        n2--;
    }

    return( n1 - n2 );
}
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\base\ntos\config\cmmapvw.c ===
/*++

Copyright (c) 1999  Microsoft Corporation

Module Name:

    cmmapvw.c

Abstract:

    This module contains mapped view support for hives.

Author:

    Dragos C. Sambotin (dragoss) 14-Jun-1999

Revision History:

--*/

#include "cmp.h"

#define  CM_TRACK_DIRTY_PAGES

#ifdef CM_TRACK_DIRTY_PAGES
#include "..\cache\cc.h"
#endif


VOID
CmpUnmapCmView(
    IN PCMHIVE              CmHive,
    IN PCM_VIEW_OF_FILE     CmView,
    IN BOOLEAN              MapIsValid,
    IN BOOLEAN              MoveToEnd
    );

PCM_VIEW_OF_FILE
CmpAllocateCmView (
        IN  PCMHIVE             CmHive
                             );

VOID
CmpFreeCmView (
        PCM_VIEW_OF_FILE  CmView
                             );

VOID
CmpUnmapCmViewSurroundingOffset(
        IN  PCMHIVE             CmHive,
        IN  ULONG               FileOffset
        );

VOID
CmpUnmapUnusedViews(
            IN  PCMHIVE             CmHive
    );

#ifdef CMP_CMVIEW_VALIDATION

VOID
CmpCheckCmView(
    IN  PCMHIVE             CmHive,
    IN  PCM_VIEW_OF_FILE    CmView
    );

#endif //CMP_CMVIEW_VALIDATION


BOOLEAN
CmIsFileLoadedAsHive(PFILE_OBJECT FileObject);

VOID
CmpReferenceHiveView(   IN PCMHIVE          CmHive,
                        IN PCM_VIEW_OF_FILE CmView
                     );
VOID
CmpDereferenceHiveView(   IN PCMHIVE          CmHive,
                        IN PCM_VIEW_OF_FILE CmView
                     );

VOID
CmpReferenceHiveViewWithLock(   IN PCMHIVE          CmHive,
                                IN PCM_VIEW_OF_FILE CmView
                            );

VOID
CmpDereferenceHiveViewWithLock(     IN PCMHIVE          CmHive,
                                    IN PCM_VIEW_OF_FILE CmView
                                );


extern  LIST_ENTRY  CmpHiveListHead;
extern  PUCHAR      CmpStashBuffer;
extern  ULONG       CmpStashBufferSize;

BOOLEAN CmpTrackHiveClose = FALSE;


#ifdef ALLOC_PRAGMA
#pragma alloc_text(PAGE,CmpUnmapCmView)
#pragma alloc_text(PAGE,CmpTouchView)
#pragma alloc_text(PAGE,CmpMapCmView)
#pragma alloc_text(PAGE,CmpAquireFileObjectForFile)
#pragma alloc_text(PAGE,CmpDropFileObjectForHive)
#pragma alloc_text(PAGE,CmpInitHiveViewList)
#pragma alloc_text(PAGE,CmpDestroyHiveViewList)
#pragma alloc_text(PAGE,CmpAllocateCmView)
#pragma alloc_text(PAGE,CmpFreeCmView)
#pragma alloc_text(PAGE,CmpPinCmView)
#pragma alloc_text(PAGE,CmpUnPinCmView)
#pragma alloc_text(PAGE,CmpMapThisBin)
#pragma alloc_text(PAGE,CmpFixHiveUsageCount)
#pragma alloc_text(PAGE,CmpUnmapUnusedViews)

#if 0
#pragma alloc_text(PAGE,CmpMapEntireFileInFakeViews)
#pragma alloc_text(PAGE,CmpUnmapFakeViews)
#pragma alloc_text(PAGE,CmpUnmapAditionalViews)
#endif

#ifdef CMP_CMVIEW_VALIDATION
#pragma alloc_text(PAGE,CmpCheckCmView)
#endif //CMP_CMVIEW_VALIDATION

#pragma alloc_text(PAGE,CmpUnmapCmViewSurroundingOffset)
#pragma alloc_text(PAGE,CmpPrefetchHiveFile)
#pragma alloc_text(PAGE,CmPrefetchHivePages)
#pragma alloc_text(PAGE,CmIsFileLoadedAsHive)
#pragma alloc_text(PAGE,CmpReferenceHiveView)
#pragma alloc_text(PAGE,CmpDereferenceHiveView)
#pragma alloc_text(PAGE,CmpReferenceHiveViewWithLock)
#pragma alloc_text(PAGE,CmpDereferenceHiveViewWithLock)
#endif

//
// this controls how many views we allow per each hive (bassically how many address space we 
// allow per hive). We use this to optimize boot time.
//
ULONG   CmMaxViewsPerHive = MAX_VIEWS_PER_HIVE;

VOID
CmpUnmapCmView(
    IN PCMHIVE              CmHive,
    IN PCM_VIEW_OF_FILE     CmView,
    IN BOOLEAN              MapIsValid,
    IN BOOLEAN              MoveToEnd
    )
/*++

Routine Description:

    Unmaps the view by marking all the bins that maps inside of it as invalid.

Arguments:

    Hive - Hive containing the section

    CmView - pointer to the view to operate on

    MapIsValid - Hive's map has been successfully inited (and not yet freed)

    MoveToEnd - moves the view to the end of the LRUList after unmapping
                This is normally TRUE, unless we want to be able to iterate through 
                the entire list and unmap views in the same time


Return Value:

    <none>

--*/
{

    ULONG           Offset;
    ULONG_PTR       Address;
    ULONG_PTR       AddressEnd;
    PHMAP_ENTRY     Me;

    PAGED_CODE();

    ASSERT( (CmView->FileOffset + CmView->Size) != 0 && (CmView->ViewAddress != 0));
    //
    // it is forbidden to unmap a view still in use!
    //
    ASSERT( CmView->UseCount == 0 );

    //
    // only if the map is still valid
    //
    if( MapIsValid == TRUE ) {
        Offset = CmView->FileOffset;

        AddressEnd = Address = (ULONG_PTR)(CmView->ViewAddress);
        AddressEnd += CmView->Size;
    
        if( Offset == 0 ) {
            //
            // oops; we are at the beginning, we have to skip the base block
            //
            Address += HBLOCK_SIZE;
        } else {
            //
            // we are in the middle of the file. just adjust the offset
            //
            Offset -= HBLOCK_SIZE;
        }
   
        while((Address < AddressEnd) && (Offset < CmHive->Hive.Storage[Stable].Length))
        {
            Me = HvpGetCellMap(&(CmHive->Hive), Offset);
            VALIDATE_CELL_MAP(__LINE__,Me,&(CmHive->Hive),Offset);

            if( Me->BinAddress & HMAP_INPAGEDPOOL ) {
                //
                // if bin is mapped in paged pool for some ubiquitous reason,
                // leave it like that (don't alter it's mapping).
                //
            } else {
                //
                // Invalidate the bin
                //
                //ASSERT_BIN_INVIEW(Me);
        
                Me->BinAddress &= (~HMAP_INVIEW);
        
                // we don't need to set it - just for debug purposes
                ASSERT( (Me->CmView = NULL) == NULL );
            }

            Offset += HBLOCK_SIZE;
            Address += HBLOCK_SIZE;
        }
    }

    //
    // Invalidate the view
    //

    CcUnpinData( CmView->Bcb );
/*
    MmUnmapViewInSystemCache (CmView->ViewAddress,CmHive->HiveSection,FALSE);
*/
#if 0 //this code gave me a lot of headache
    {
        UNICODE_STRING  HiveName;
        RtlInitUnicodeString(&HiveName, (PCWSTR)CmHive->Hive.BaseBlock->FileName);
        CmKdPrintEx((DPFLTR_CONFIG_ID,CML_BIN_MAP,"CmpUnmapCmView for hive (%p) (%.*S), Address = %p Size = %lx\n",CmHive,HiveName.Length / sizeof(WCHAR),HiveName.Buffer,CmView->ViewAddress,CmView->Size));
    }
#endif

    CmView->FileOffset = 0;
    CmView->Size = 0;
    CmView->ViewAddress = 0;
    CmView->Bcb = NULL;
    CmView->UseCount = 0;

    if( MoveToEnd == TRUE ) {
        //
        // remove the view from the LRU list
        //
        RemoveEntryList(&(CmView->LRUViewList));

        //
        // add it to the end of LRU list
        //
        InsertTailList(
            &(CmHive->LRUViewListHead),
            &(CmView->LRUViewList)
            );
    }
}

VOID
CmpTouchView(
    IN PCMHIVE              CmHive,
    IN PCM_VIEW_OF_FILE     CmView,
    IN ULONG                Cell
            )
/*++

Warning:
    
    This function should be called with the viewlock held!!!

Routine Description:

    Touches the view by moving it at the top of the LRU list.
    This function is to be called from HvpGetCellPaged, every 
    time a view is touched.

Arguments:

    Hive - Hive containing the section

    CmView - pointer to the view to operate on

Return Value:

    <none>

--*/
{
    PAGED_CODE();

#if DBG
    {
        UNICODE_STRING  HiveName;
        RtlInitUnicodeString(&HiveName, (PCWSTR)CmHive->Hive.BaseBlock->FileName);
        CmKdPrintEx((DPFLTR_CONFIG_ID,CML_BIN_MAP,"CmpTouchView for hive (%p) (%.*S),",CmHive,HiveName.Length / sizeof(WCHAR),HiveName.Buffer));
        CmKdPrintEx((DPFLTR_CONFIG_ID,CML_BIN_MAP,"Cell = %8lx ViewAddress = %p ViewSize = %lx\n",Cell,CmView->ViewAddress,CmView->Size));
    }
#endif
    
    ASSERT( (CmView->FileOffset + CmView->Size) != 0 && (CmView->ViewAddress != 0));

    if( IsListEmpty(&(CmView->PinViewList)) == FALSE ) {
        //
        // the view is pinned; don't mess with it as it is guaranteed
        // that it'll be in memory until the next flush
        //
        return;
    }

    //
    // optimization: if already is first, do nothing
    //

    if( CmHive->LRUViewListHead.Flink == &(CmView->LRUViewList) ) {
        // remove the bp after making sure it's working properly
        CmKdPrintEx((DPFLTR_CONFIG_ID,CML_BIN_MAP,"CmView %p already first\n",CmView));
/*
        DbgBreakPoint();
*/
        //it's already first
        return;
    }

    //
    // remove the view from the LRU list
    //
    RemoveEntryList(&(CmView->LRUViewList));

    //
    // add it on top of LRU list
    //
    InsertHeadList(
        &(CmHive->LRUViewListHead),
        &(CmView->LRUViewList)
        );

}

NTSTATUS
CmpMapCmView(
    IN  PCMHIVE             CmHive,
    IN  ULONG               FileOffset,
    OUT PCM_VIEW_OF_FILE    *CmView,
    IN  BOOLEAN             MapInited
    )
/*++

Warning:
    
    This function should be called with the hivelock held!!!

Routine Description:

    Unmaps the view by marking all the bins that maps inside of it as invalid.

Arguments:

    CmHive - Hive containing the section

    FileOffset - Offset where to map the view

    CmView - pointer to the view to operate on

    MapInited - when TRUE, we can rely on the map info.

Return Value:

    status of the operation

--*/
{

    PHMAP_ENTRY     Me;
    NTSTATUS        Status = STATUS_SUCCESS;
    LARGE_INTEGER   SectionOffset;
    ULONG           Offset;
    ULONG_PTR       Address;
    ULONG_PTR       AddressEnd;
    ULONG_PTR       BinAddress;
    PHBIN           Bin;
    LONG            PrevMappedBinSize; 
    BOOLEAN         FirstTry = TRUE;

    PAGED_CODE();

    if( CmHive->MappedViews == 0 ){
        //
        // we've run out of views; all are pinned
        //
        ASSERT( IsListEmpty(&(CmHive->LRUViewListHead)) == TRUE );
        *CmView = CmpAllocateCmView(CmHive);

    } else {
        //
        // Remove the last view from LRU list (i.e. the LEAST recently used)
        //
        *CmView = (PCM_VIEW_OF_FILE)CmHive->LRUViewListHead.Blink;
        *CmView = CONTAINING_RECORD( *CmView,
                                    CM_VIEW_OF_FILE,
                                    LRUViewList);


        if( (*CmView)->ViewAddress != 0 ) {
            PCM_VIEW_OF_FILE    TempCmView = NULL;
            //
            // the last view is mapped
            //
            if( CmHive->MappedViews < CmMaxViewsPerHive ) { 
                //
                // we are still allowed to add views 
                //
                TempCmView = CmpAllocateCmView(CmHive);
            }
            if( TempCmView == NULL ) {                
                //  
                // we couldn't allocate a new view, or we need to use an existent one
                //
                if( (*CmView)->UseCount != 0 ) {
                    BOOLEAN  FoundView = FALSE;
                    //
                    // view is in use; try walking to the top and find an unused view
                    // 
                    while( (*CmView)->LRUViewList.Blink != CmHive->LRUViewListHead.Flink ) {
                        *CmView = (PCM_VIEW_OF_FILE)(*CmView)->LRUViewList.Blink;
                        *CmView = CONTAINING_RECORD( *CmView,
                                                    CM_VIEW_OF_FILE,
                                                    LRUViewList);
                        if( (*CmView)->UseCount == 0 ) {
                            //
                            // this one is free go ahead and use it !
                            // first unmap, then signal that we found it
                            //
                            if( (*CmView)->ViewAddress != 0 ) {
                                //
                                // unnmap only if mapped
                                //
                                CmpUnmapCmView(CmHive,(*CmView),TRUE,TRUE);
                            }
                            FoundView = TRUE;
                            break;

                        }
                    }
                
                    if( FoundView == FALSE ) {
                        //
                        // no luck, all views are in use allocate a new one (we are forced to do so)
                        //
                        *CmView = CmpAllocateCmView(CmHive);
                    }
                } else {
                    //
                    // unmap it!
                    //
                    CmpUnmapCmView(CmHive,(*CmView),TRUE,TRUE);
                }
            } else {
                //
                // we successfully allocated a new view
                //
                (*CmView) = TempCmView;
            }
        }
    }

    if( (*CmView) == NULL ) {
        //
        // we're running low on resources
        //
        return STATUS_INSUFFICIENT_RESOURCES;
    }

#if DBG
    {
        UNICODE_STRING  HiveName;
        RtlInitUnicodeString(&HiveName, (PCWSTR)CmHive->Hive.BaseBlock->FileName);
        CmKdPrintEx((DPFLTR_CONFIG_ID,CML_BIN_MAP,"CmpMapCmView for hive (%p) (%.*S),",CmHive,HiveName.Length / sizeof(WCHAR),HiveName.Buffer));
        CmKdPrintEx((DPFLTR_CONFIG_ID,CML_BIN_MAP," FileOfset = %lx ... ",FileOffset));
    }
#endif
    //
    // On this call, FileOffset must be a multiple of CM_VIEW_SIZE
    //

    
    //
    // adjust the file offset to respect the CM_VIEW_SIZE alingment
    //
    Offset = ((FileOffset+HBLOCK_SIZE) & ~(CM_VIEW_SIZE - 1) );
    SectionOffset.LowPart = Offset;
    SectionOffset.HighPart = 0;
    
    (*CmView)->Size = CM_VIEW_SIZE;//(FileOffset + Size) - Offset;

    if( (Offset + (*CmView)->Size) > (CmHive->Hive.Storage[Stable].Length + HBLOCK_SIZE ) ){
        (*CmView)->Size = CmHive->Hive.Storage[Stable].Length + HBLOCK_SIZE - Offset;
    }


/*    
    Status = MmMapViewInSystemCache (   CmHive->HiveSection,
                                        &((*CmView)->ViewAddress),
                                        &SectionOffset,
                                        &((*CmView)->Size));

*/
RetryToMap:

    try {

        ASSERT( (*CmView)->Size != 0 );
        ASSERT( (*CmView)->ViewAddress == NULL );
        ASSERT( (*CmView)->UseCount == 0 );

        if (!CcMapData( CmHive->FileObject,
                        (PLARGE_INTEGER)&SectionOffset,
                        (*CmView)->Size,
                        MAP_WAIT 
#ifdef CM_MAP_NO_READ
                        | MAP_NO_READ
#endif
                        ,
                        (PVOID *)(&((*CmView)->Bcb)),
                        (PVOID *)(&((*CmView)->ViewAddress)) )) {
            Status = STATUS_CANT_WAIT;
        }
    } except (EXCEPTION_EXECUTE_HANDLER) {
        //
        // in low-memory scenarios, CcMapData throws a STATUS_IN_PAGE_ERROR
        // this happens when the IO issued to touch the just-mapped data fails (usually with
        // STATUS_INSUFFICIENT_RESOURCES; We want to catch this and treat as a 
        // "not enough resources" problem, rather than letting it to surface the kernel call
        //
        CmKdPrintEx((DPFLTR_CONFIG_ID,DPFLTR_ERROR_LEVEL,"CmpMapCmView : CcMapData has raised :%08lx\n",GetExceptionCode()));
        Status = STATUS_INSUFFICIENT_RESOURCES;
    }

    if(!NT_SUCCESS(Status) ){
        if( FirstTry == TRUE ) {
            //
            // unmap all unneccessary views and try again
            //
            FirstTry = FALSE;
            CmpUnmapUnusedViews(CmHive);
            Status = STATUS_SUCCESS;
            goto RetryToMap;
        }
        CmKdPrintEx((DPFLTR_CONFIG_ID,CML_BIN_MAP,"Fail\n"));
        ASSERT(FALSE);
        return Status;
    }

    CmKdPrintEx((DPFLTR_CONFIG_ID,CML_BIN_MAP,"Succedeed Address = %p Size = %lx\n",(*CmView)->ViewAddress,(*CmView)->Size));

    (*CmView)->FileOffset = SectionOffset.LowPart;

    ASSERT( Offset == (*CmView)->FileOffset);

    AddressEnd = Address = (ULONG_PTR)((*CmView)->ViewAddress);
    AddressEnd += (*CmView)->Size;
    
    if( Offset == 0 ) {
        //
        // oops; we are at the beginning, we have to skip the base block
        //
        Address += HBLOCK_SIZE;
    } else {
        //
        // we are in the middle of the file. just adjust the offset
        //
        Offset -= HBLOCK_SIZE;
    }

#ifdef CMP_CMVIEW_VALIDATION
    CmpCheckCmView(CmHive,*CmView);
#endif //CMP_CMVIEW_VALIDATION

    CmKdPrintEx((DPFLTR_CONFIG_ID,CML_BIN_MAP,"CmpMapCmView :: Address = %p AddressEnd = %p ; Size = %lx\n",Address,AddressEnd,(*CmView)->Size));
   
    //
    // here we can optimize not to touch all the bins!!!
    //
     
    //
    // we don't know yet if the first bin is mapped.
    //
    PrevMappedBinSize = 0;
    BinAddress = Address;
    while(Address < AddressEnd)
    {
        Me = HvpGetCellMap(&(CmHive->Hive), Offset);
        VALIDATE_CELL_MAP(__LINE__,Me,&(CmHive->Hive),Offset);

        if( Me->BinAddress & HMAP_INPAGEDPOOL ) {
            //
            // if bin is mapped in paged pool for some reason,
            // leave it like that (don't alter it's mapping).
            //
            
            //
            // next mapped bin should start updating his bin address
            //
            PrevMappedBinSize = 0;
        } else {
            //
            // at this point the bin should be invalid.
            //
            ASSERT_BIN_INVALID(Me);

            Me->BinAddress |= HMAP_INVIEW;
            Me->CmView = *CmView;

            //
            // set the new BinAddress, but take care to preserve the flags
            //
            ASSERT( HBIN_FLAGS(Address) == 0 );

            

            //
            // new bins are Always tagged with this flag (we can start updating BinAddress) 
            //
            if( MapInited && ( Me->BinAddress & HMAP_NEWALLOC ) ) {
#ifdef CM_CHECK_MAP_NO_READ_SCHEME
                ASSERT( PrevMappedBinSize == 0 );
                //
                // Validate the bin
                //
                Bin = (PHBIN)Address;
                //ASSERT( Bin->Signature == HBIN_SIGNATURE );
                PrevMappedBinSize = (LONG)Bin->Size;
#endif //CM_CHECK_MAP_NO_READ_SCHEME

                //
                // we are at the beginning of a new bin
                //
                BinAddress = Address;
            } else if( (!MapInited) &&(PrevMappedBinSize == 0) ) {
                //
                // we cannot rely on the map to cary the bin flags; we have to fault data in
                //
                //
                // Validate the bin
                //
                Bin = (PHBIN)Address;
                //ASSERT( Bin->Signature == HBIN_SIGNATURE );
                PrevMappedBinSize = (LONG)Bin->Size;
                //
                // we are at the beginning of a new bin
                //
                BinAddress = Address;
            }

            //
            // common sense
            //
            ASSERT( (!MapInited) || ((PrevMappedBinSize >=0) && (PrevMappedBinSize%HBLOCK_SIZE == 0)) );

#ifdef CM_CHECK_MAP_NO_READ_SCHEME
            ASSERT( (PrevMappedBinSize >=0) && (PrevMappedBinSize%HBLOCK_SIZE == 0) );
#endif //CM_CHECK_MAP_NO_READ_SCHEME

            Me->BinAddress = ( HBIN_BASE(BinAddress) | HBIN_FLAGS(Me->BinAddress) );
            if( (Me->BinAddress & HMAP_DISCARDABLE) == 0 ) {
                //
                // for discardable bins do not alter this member, as it contains
                // the address of the free bin
                //
                Me->BlockAddress = Address;
            }

            if( !MapInited ) {
                //
                // compute the remaining size of this bin; next iteration will update BinAddress only if 
                // this variable reaches 0
                //
                PrevMappedBinSize -= HBLOCK_SIZE;
            } else {
#ifdef CM_CHECK_MAP_NO_READ_SCHEME
                //
                // compute the remaining size of this bin; next iteration will update BinAddress only if 
                // this variable reaches 0
                //
                PrevMappedBinSize -= HBLOCK_SIZE;
#endif //CM_CHECK_MAP_NO_READ_SCHEME
            }

            ASSERT_BIN_INVIEW(Me);
        }

        Offset += HBLOCK_SIZE;
        Address += HBLOCK_SIZE;
    }
    
    return Status;
}

VOID
CmpUnmapCmViewSurroundingOffset(
        IN  PCMHIVE             CmHive,
        IN  ULONG               FileOffset
        )
/*++

Routine Description:

    Parses the mapped view list and if it finds one surrounding this offest, unmaps it.
      
Arguments:

    CmHive - Hive in question

    FileOffset - the offest in question

Return Value:

    none

Note: 
    
    Offset is an absolute value, 
--*/
{
    PCM_VIEW_OF_FILE    CmView;
    USHORT              NrViews;
    BOOLEAN             UnMap = FALSE;
    
    PAGED_CODE();

    // 
    // Walk through the LRU list and compare view addresses
    //
    CmView = (PCM_VIEW_OF_FILE)CmHive->LRUViewListHead.Flink;

    for(NrViews = CmHive->MappedViews;NrViews;NrViews--) {
        CmView = CONTAINING_RECORD( CmView,
                                    CM_VIEW_OF_FILE,
                                    LRUViewList);
        
        if( ((CmView->Size + CmView->FileOffset) != 0) && (CmView->ViewAddress != 0) )  {
            //
            // view is valid
            //
            if( (CmView->FileOffset <= FileOffset) && ((CmView->FileOffset + CmView->Size) > FileOffset) ) {
                //
                // the file offset is surrounded by this view
                //
                UnMap = TRUE;
                break;
            }
        }

        CmView = (PCM_VIEW_OF_FILE)CmView->LRUViewList.Flink;
    }

    if( UnMap == TRUE ) {
        // unmap the view anyway (this implies unpinning).
        ASSERT_VIEW_MAPPED( CmView );
        ASSERT( CmView->UseCount == 0 );
        CmpUnmapCmView(CmHive,CmView,TRUE,TRUE);
    }
}

PCM_VIEW_OF_FILE
CmpAllocateCmView (
        IN  PCMHIVE             CmHive
                             )
/*++

Routine Description:

    Allocate a CM-view.
    Insert it in  various list.

Arguments:

    CmHive - Hive in question


Return Value:

    TBS - the new view

--*/
{
    PCM_VIEW_OF_FILE  CmView;
    
    PAGED_CODE();

    CmView = ExAllocatePoolWithTag(PagedPool,sizeof(CM_VIEW_OF_FILE),CM_MAPPEDVIEW_TAG | PROTECTED_POOL);
    
    if (CmView == NULL) {
        //
        // we're low on resources; we should handle the error path for this.
        //
        return NULL;
    }
    
    //
    // Init the view
    //
    CmView->FileOffset = 0;
    CmView->Size = 0;
    CmView->ViewAddress = NULL;
    CmView->Bcb = NULL;
    CmView->UseCount =0;
    
    //
    // add it to the list(s)
    //
    InitializeListHead(&(CmView->PinViewList));

    InsertTailList(
        &(CmHive->LRUViewListHead),
        &(CmView->LRUViewList)
        );
    
    CmHive->MappedViews++;
    return CmView;
}

VOID
CmpInitHiveViewList (
        IN  PCMHIVE             CmHive
                             )
/*++

Routine Description:

    adds the first view to the LRU list.
    others are added as needed.!

Arguments:

    CmHive - Hive in question


Return Value:

    TBS - status of the operation

--*/
{

    PAGED_CODE();

    // 
    // Init the heads.
    //
    InitializeListHead(&(CmHive->PinViewListHead));
    InitializeListHead(&(CmHive->LRUViewListHead));
#if 0
    InitializeListHead(&(CmHive->FakeViewListHead));
    CmHive->FakeViews = 0;          
#endif

    CmHive->MappedViews = 0;
    CmHive->PinnedViews = 0;
    CmHive->UseCount = 0;
}

VOID
CmpDestroyHiveViewList (
        IN  PCMHIVE             CmHive
                             )
/*++

Routine Description:

    Frees the storage fo all the views used by this hive

Arguments:

    CmHive - Hive in question

    Purge - whether to purge the cache or not.


Return Value:

    TBS - status of the operation

--*/
{
    PCM_VIEW_OF_FILE    CmView;

    PAGED_CODE();

    if( CmHive->FileObject == NULL ) {
        //
        // hive is not mapped.
        //
        return;
    }
#if 0
    //
    // get rid of fake views first; we shouldn't have any fake views here, unless we are on 
    // some error path (the hive is corrupted).
    //
    CmpUnmapFakeViews(CmHive);
#endif

    // 
    // Walk through the Pinned View list and free all the views
    //
    while( IsListEmpty( &(CmHive->PinViewListHead) ) == FALSE ) {
        CmView = (PCM_VIEW_OF_FILE)RemoveHeadList(&(CmHive->PinViewListHead));
        CmView = CONTAINING_RECORD( CmView,
                                    CM_VIEW_OF_FILE,
                                    PinViewList);
        
        ASSERT_VIEW_PINNED(CmView);
        //
        // we need to move this view to the mapped view list and remember to purge after all 
        // views have been unmapped. Otherwise we rick deadlock on CcWaitOnActiveCount, when we purge

        //
        //
        // sanity check; we shouldn't get here for a read-only hive
        //
        ASSERT( CmHive->Hive.ReadOnly == FALSE );

        //
        // empty the LRUList for this view
        //
        InitializeListHead(&(CmView->PinViewList));
    
        //
        // update the counters
        //
        CmHive->PinnedViews--;        
        CmHive->MappedViews++;        

        //
        // add it at the tail of LRU list for this hive
        //
        InsertTailList(
            &(CmHive->LRUViewListHead),
            &(CmView->LRUViewList)
            );
        
    }

    //
    // At this point, there should be no pinned view
    //
    ASSERT( IsListEmpty(&(CmHive->PinViewListHead)) == TRUE);
    ASSERT( CmHive->PinnedViews == 0 );

    // 
    // Walk through the LRU list and free all the views
    //
    while( IsListEmpty( &(CmHive->LRUViewListHead) ) == FALSE ) {
        CmView = (PCM_VIEW_OF_FILE)CmHive->LRUViewListHead.Flink;
        CmView = CONTAINING_RECORD( CmView,
                                    CM_VIEW_OF_FILE,
                                    LRUViewList);
        if( CmView->ViewAddress != 0 ) {
            //
            // view is mapped; unmap it
            // we should not encounter that in sane systems
            // this can happen only when a hive-loading fails 
            // in HvpMapFileImageAndBuildMap
            // no need move it as we are going to free it anyway
            //
            CmpUnmapCmView(CmHive,CmView,FALSE,FALSE);
        }

        //
        // update the counter
        //
        CmHive->MappedViews--;

        //
        // remove the view from the LRU list
        //
        RemoveEntryList(&(CmView->LRUViewList));

        ExFreePoolWithTag(CmView, CM_MAPPEDVIEW_TAG | PROTECTED_POOL);
    }

    ASSERT( CmHive->MappedViews == 0 );
    ASSERT( CmHive->UseCount == 0 );

    //
    // we need to purge as the FS cannot do it for us (private writers)
    // valid data is already on the disk by now (it should!)
    // purge and flush everything 
    //
    CcPurgeCacheSection(CmHive->FileObject->SectionObjectPointer,(PLARGE_INTEGER)(((ULONG_PTR)NULL) + 1)/*we are private writers*/,0/*ignored*/,FALSE);
    //
    // This is for the case where the last flush failed (we couldn't write the log file....) 
    // .... then : flush the cache to clear dirty hints added by the purge
    //
    CcFlushCache (CmHive->FileObject->SectionObjectPointer,(PLARGE_INTEGER)(((ULONG_PTR)NULL) + 1)/*we are private writers*/,0/*ignored*/,NULL);

    //
    // Flush again to take care of the dirty pages that may appear due to FS page zeroing
    //
    CcFlushCache (CmHive->FileObject->SectionObjectPointer,(PLARGE_INTEGER)(((ULONG_PTR)NULL) + 1)/*we are private writers*/,0/*ignored*/,NULL);

#ifdef  CM_TRACK_DIRTY_PAGES
    if( ((PSHARED_CACHE_MAP)(CmHive->FileObject->SectionObjectPointer->SharedCacheMap))->DirtyPages != 0 ) {
        DbgPrint("SharedCacheMap still has dirty pages after purge and flush; FileObject = %p \n",CmHive->FileObject);
        DbgBreakPoint();
    }
#endif //CM_TRACK_DIRTY_PAGES

}

VOID
CmpDropFileObjectForHive(
        IN  PCMHIVE             CmHive
            )
/*++

Routine Description:

    Drops the extra reference kept on the file object (if any)
    and frees the name 

Arguments:

    CmHive

Return Value:

    none

--*/
{
    
    PAGED_CODE();

    if( CmHive->FileUserName.Buffer != NULL ) {
        ExFreePoolWithTag(CmHive->FileUserName.Buffer, CM_NAME_TAG | PROTECTED_POOL);
        CmHive->FileUserName.Buffer = NULL;
        CmHive->FileUserName.Length = 0;
        CmHive->FileUserName.MaximumLength = 0;
    } else {
        ASSERT(CmHive->FileUserName.Length == 0);
        ASSERT(CmHive->FileUserName.MaximumLength == 0);
    }

    if( CmHive->FileObject == NULL ) {
        // debug only code
        ASSERT(CmHive->FileFullPath.Buffer == NULL);
        ASSERT(CmHive->FileFullPath.Length == 0);
        ASSERT(CmHive->FileFullPath.MaximumLength == 0);
        return;
    }
    
    // debug only code
    if( CmHive->FileFullPath.Buffer != NULL ) {
        ExFreePoolWithTag(CmHive->FileFullPath.Buffer, CM_NAME_TAG | PROTECTED_POOL);
        CmHive->FileFullPath.Buffer = NULL;
        CmHive->FileFullPath.Length = 0;
        CmHive->FileFullPath.MaximumLength = 0;
    } else {
        ASSERT(CmHive->FileFullPath.Length == 0);
        ASSERT(CmHive->FileFullPath.MaximumLength == 0);
    }

    ObDereferenceObject((PVOID)(CmHive->FileObject));

    CmHive->FileObject = NULL;
}

NTSTATUS
CmpAquireFileObjectForFile(
        IN  PCMHIVE         CmHive,
        IN HANDLE           FileHandle,
        OUT PFILE_OBJECT    *FileObject
            )
/*++

Routine Description:

    Creates the section for the given file handle.
    the section is used to map/unmap views of the file

Arguments:

    FileHandle - Handle of the file

    SectionPointer - the section object

Return Value:

    TBS - status of the operation

--*/
{
    NTSTATUS                    Status,Status2;
    IO_STATUS_BLOCK             IoStatus;
    POBJECT_NAME_INFORMATION    FileNameInfo;
    ULONG                       ReturnedLength;
    ULONG                       FileNameLength;

    PAGED_CODE();

    Status = ObReferenceObjectByHandle ( FileHandle,
                                         FILE_READ_DATA | FILE_WRITE_DATA,
                                         IoFileObjectType,
                                         KernelMode,
                                         (PVOID *)FileObject,
                                         NULL );
    if (!NT_SUCCESS(Status)) {
        CmKdPrintEx((DPFLTR_CONFIG_ID,DPFLTR_ERROR_LEVEL,"[CmpAquireFileObjectForFile] Could not reference file object status = %x\n",Status));
    } else {
        //
        // call cc private to mark the stream as Modify-No-Write
        //
        if( !CcSetPrivateWriteFile(*FileObject) ) {
            //
            // filter out invalid failures to initialize the cache
            // top-level routine CmpInitHiveFromFile will retry to load the hive in the old fashion way.
            //
            CmpDropFileObjectForHive(CmHive);
            (*FileObject) = NULL;
            return STATUS_RETRY;
        }
        
        LOCK_STASH_BUFFER();
        //
        // capture the full path of the file
        //
        ASSERT( CmpStashBuffer != NULL );
        
        FileNameInfo = (POBJECT_NAME_INFORMATION)CmpStashBuffer;

        //
        // we need to protect against multiple threads using the stash buffer
        // this could happen only during the paralel hive loading at boot
        //
        LOCK_HIVE_LIST();
        //
        // Try to get the name for the file object. 
        //
        Status2 = ObQueryNameString(*FileObject,
                                    FileNameInfo,
                                    CmpStashBufferSize,
                                    &ReturnedLength);
        if (NT_SUCCESS(Status2)) {

            //
            // Allocate a file name buffer and copy into it. 
            // The file names will be NUL terminated. Allocate extra for that.
            //

            FileNameLength = FileNameInfo->Name.Length / sizeof(WCHAR);

            CmHive->FileFullPath.Buffer = ExAllocatePoolWithTag(PagedPool,
                                                                (FileNameLength + 1) * sizeof(WCHAR),
                                                                CM_NAME_TAG | PROTECTED_POOL);

            if (CmHive->FileFullPath.Buffer) {

                RtlCopyMemory(CmHive->FileFullPath.Buffer,
                              FileNameInfo->Name.Buffer,
                              FileNameLength * sizeof(WCHAR));

                //
                // Make sure it is NUL terminated.
                //

                CmHive->FileFullPath.Buffer[FileNameLength] = 0;
                CmHive->FileFullPath.Length = FileNameInfo->Name.Length;
                CmHive->FileFullPath.MaximumLength = FileNameInfo->Name.Length + sizeof(WCHAR);

            } else {
                //
                // not fatal, just that we won't be able to prefetch this hive
                //
                CmKdPrintEx((DPFLTR_CONFIG_ID,DPFLTR_TRACE_LEVEL,"[CmpAquireFileObjectForFile] Could not allocate buffer for fullpath for fileobject %p\n",*FileObject));
            }

        } else {
            //
            // not fatal, just that we won't be able to prefetch this hive
            //
            CmKdPrintEx((DPFLTR_CONFIG_ID,DPFLTR_TRACE_LEVEL,"[CmpAquireFileObjectForFile] Could not retrieve name for fileobject %p, Status = %lx\n",*FileObject,Status2));
            CmHive->FileFullPath.Buffer = NULL;
        }
        UNLOCK_HIVE_LIST();
        UNLOCK_STASH_BUFFER();
        
    }    

    return Status;
}

NTSTATUS
CmpMapThisBin(
                PCMHIVE         CmHive,
                HCELL_INDEX     Cell,
                BOOLEAN         Touch
              )
/*++

Routine Description:

    Makes sure the bin is mapped in memory. 

Arguments:

Return Value:


--*/
{
    PCM_VIEW_OF_FILE CmView;
    
    PAGED_CODE();

    //
    // ViewLock must be held 
    //

    //
    // bin is either mapped, or invalid
    //
    ASSERT( HvGetCellType(Cell) == Stable );
    //
    // map the bin
    //
    if( !NT_SUCCESS (CmpMapCmView(CmHive,Cell,&CmView,TRUE) ) ) {
        return STATUS_INSUFFICIENT_RESOURCES;
    }

    if( Touch == TRUE ) {
        //
        // touch the view
        //
        CmpTouchView(CmHive,CmView,(ULONG)Cell);
    } else {
        //
        // if we are here; we should have either the reg lock exclusive
        // or the reg lock shared AND the hive lock. 
        // Find a way to assert that!!!
        //
    }
    
    return STATUS_SUCCESS;
}

NTSTATUS
CmpPinCmView (
        IN  PCMHIVE             CmHive,
        PCM_VIEW_OF_FILE        CmView
                             )
/*++

Routine Description:

    Pins the specified view into memory

    The view is removed from the LRU list.
    Then, the view is moved to the PinList

Arguments:

    CmHive - Hive in question
    
    CmView - View in question

Return Value:

    TBS - the new view

--*/
{
    LARGE_INTEGER   SectionOffset;
    NTSTATUS        Status = STATUS_SUCCESS;
    PVOID           SaveBcb;                
    
    PAGED_CODE();

#if DBG
    {
        UNICODE_STRING  HiveName;
        RtlInitUnicodeString(&HiveName, (PCWSTR)CmHive->Hive.BaseBlock->FileName);
        CmKdPrintEx((DPFLTR_CONFIG_ID,CML_BIN_MAP,"CmpPinCmView %lx for hive (%p) (%.*S), Address = %p Size = %lx\n",CmView,CmHive,HiveName.Length / sizeof(WCHAR),HiveName.Buffer,CmView->ViewAddress,CmView->Size));
    }
#endif

    //
    // We only pin mapped views
    //
    ASSERT_VIEW_MAPPED(CmView);
    
    //
    // sanity check; we shouldn't get here for a read-only hive
    //
    ASSERT( CmHive->Hive.ReadOnly == FALSE );

    // we may need this later
    SaveBcb = CmView->Bcb;

    SectionOffset.LowPart = CmView->FileOffset;
    SectionOffset.HighPart = 0;
    try {
        //
        // the MOST important: pin the view
        //
        if( !CcPinMappedData(   CmHive->FileObject,
                                &SectionOffset,
                                CmView->Size,
                                TRUE, // wait == syncronous call
                                &(CmView->Bcb) )) {
            //
            // this should never happen; handle it, though
            //
        
            ASSERT( FALSE );
            Status = STATUS_INSUFFICIENT_RESOURCES;
        }
    } except (EXCEPTION_EXECUTE_HANDLER) {
        //
        // in low-memory scenarios, CcPinMappedData throws a STATUS_INSUFFICIENT_RESOURCES
        // We want to catch this and treat as a  "not enough resources" problem, 
        // rather than letting it to surface the kernel call
        //
        CmKdPrintEx((DPFLTR_CONFIG_ID,DPFLTR_ERROR_LEVEL,"CmpPinCmView : CcPinMappedData has raised :%08lx\n",GetExceptionCode()));
        Status = STATUS_INSUFFICIENT_RESOURCES;
    }

    if( NT_SUCCESS(Status) ) {
        //
        // Pin succeeded, move the view to the pinned list
        // remove the view from the LRU list
        //
        RemoveEntryList(&(CmView->LRUViewList));
        //
        // empty the LRUList for this view
        //
        InitializeListHead(&(CmView->LRUViewList));
    
        //
        // add it at the tail of pinned list for this hive
        //
        InsertTailList(
            &(CmHive->PinViewListHead),
            &(CmView->PinViewList)
            );
    
        //
        // update the counters
        //
        CmHive->MappedViews--;        
        CmHive->PinnedViews++;        
    } else {
        //
        // pin failed; we need to restore view data that may have been altered by the pin call
        // view will remain mapped
        //
        CmView->Bcb = SaveBcb;
    }

    // make sure we didn't unmapped/punned more than we mapped/pinned
    ASSERT( (CmHive->MappedViews >= 0) ); // && (CmHive->MappedViews < CmMaxViewsPerHive) );
    ASSERT( (CmHive->PinnedViews >= 0) );
    
#ifdef CMP_CMVIEW_VALIDATION
    CmpCheckCmView(CmHive,CmView);
#endif //CMP_CMVIEW_VALIDATION
    return Status;
}

VOID
CmpUnPinCmView (
        IN  PCMHIVE             CmHive,
        IN  PCM_VIEW_OF_FILE    CmView,
        IN  BOOLEAN             SetClean,
        IN  BOOLEAN             MapValid
                             )
/*++

Routine Description:

    UnPins the specified view from memory

    The view is NOT in the PinViewList !!! (it has already been removed !!!!!!)
    Then, the view is moved to the LRUList.
    If more than CmMaxViewsPerHive are in LRU list, the view is freed

    This function always grabs the ViewLock for the hive!!!

Arguments:

    CmHive - Hive in question
    
    CmView - View in question

    SetClean - Tells whether the changes made to this view should be discarded

Return Value:

    TBS - the new view

--*/
{
    LARGE_INTEGER   FileOffset;         // where the mapping starts
    ULONG           Size;               // size the view maps

    
    PAGED_CODE();

#if 0 // this gave me a lot of headaches
    {
        UNICODE_STRING  HiveName;
        RtlInitUnicodeString(&HiveName, (PCWSTR)CmHive->Hive.BaseBlock->FileName);
        CmKdPrintEx((DPFLTR_CONFIG_ID,CML_BIN_MAP,"CmpUnPinCmView %lx for hive (%p) (%.*S), Address = %p Size = %lx\n",CmView,CmHive,HiveName.Length / sizeof(WCHAR),HiveName.Buffer,CmView->ViewAddress,CmView->Size));
    }
#endif

    //
    // Grab the viewLock, to protect the viewlist
    //
    CmLockHiveViews (CmHive);

    //
    // We only pin mapped views
    //
    ASSERT_VIEW_PINNED(CmView);
    
    //
    // sanity check; we shouldn't get here for a read-only hive
    //
    ASSERT( CmHive->Hive.ReadOnly == FALSE );

    //
    // empty the LRUList for this view
    //
    InitializeListHead(&(CmView->PinViewList));
    
    //
    // update the counters
    //
    CmHive->PinnedViews--;        
    CmHive->MappedViews++;        

    //
    // add it at the tail of LRU list for this hive
    //
    InsertTailList(
        &(CmHive->LRUViewListHead),
        &(CmView->LRUViewList)
        );
    
    //
    // store the FileOffset and size as we will need them for purging
    //
    FileOffset.LowPart = CmView->FileOffset;
    FileOffset.HighPart = 0;
    Size = CmView->Size;

    if( SetClean == TRUE ) {
        ASSERT( CmView->UseCount == 0 );
        //
        // unmap the view (this implies unpinning).
        //
        CmpUnmapCmView(CmHive,CmView,MapValid,TRUE);
        //
        // purge cache data
        //
        ASSERT_CM_LOCK_OWNED_EXCLUSIVE();
        CcPurgeCacheSection(CmHive->FileObject->SectionObjectPointer,(PLARGE_INTEGER)(((ULONG_PTR)(&FileOffset)) + 1)/*we are private writers*/,Size,FALSE);
    } else {
        PVOID           NewBcb;
        PULONG_PTR      NewViewAddress;        
        NTSTATUS        Status = STATUS_SUCCESS;

        //
        // the data is to be saved to the file,
        // notify the cache manager that the data is dirty
        //
        CcSetDirtyPinnedData (CmView->Bcb,NULL);

        //
        // remap this view so we don't lose the refcount on this address range
        //
        try {
            if (!CcMapData( CmHive->FileObject,
                            (PLARGE_INTEGER)&FileOffset,
                            CmView->Size,
                            MAP_WAIT 
#ifdef CM_MAP_NO_READ
                            | MAP_NO_READ
#endif
                            ,
                            (PVOID *)(&NewBcb),
                            (PVOID *)(&NewViewAddress) )) {

                Status = STATUS_CANT_WAIT;
            }
        } except (EXCEPTION_EXECUTE_HANDLER) {
            //
            // in low-memory scenarios, CcMapData throws a STATUS_IN_PAGE_ERROR
            // this happens when the IO issued to touch the just-mapped data fails (usually with
            // STATUS_INSUFFICIENT_RESOURCES; We want to catch this and treat as a 
            // "not enough resources" problem, rather than letting it to surface the kernel call
            //
            CmKdPrintEx((DPFLTR_CONFIG_ID,DPFLTR_ERROR_LEVEL,"CmpUnPinCmView : CcMapData has raised :%08lx\n",GetExceptionCode()));
            Status = STATUS_INSUFFICIENT_RESOURCES;
        }

        if( !NT_SUCCESS(Status) ) {
            //
            // CcMap didn't succeeded; bad luck, just unmap (implies unpinning).
            //
            CmpUnmapCmView(CmHive,CmView,MapValid,TRUE);
        } else {
            BOOLEAN  FoundView = FALSE;
            //
            // sanity asserts; Cc guarantees the same address is returned.
            //
            ASSERT( FileOffset.LowPart == CmView->FileOffset );
            ASSERT( NewViewAddress == CmView->ViewAddress );
            //
            // unpin old data
            //
            CcUnpinData( CmView->Bcb );
            //
            // replace the bcb for this view; there is no need to modify the map as the 
            // address and the size of the view remains the same; We just need to update the bcb
            //
            CmView->Bcb = NewBcb;
            //
            // move the view on top of the LRU list (consider it as "hot")
            //
            RemoveEntryList(&(CmView->LRUViewList));
            InsertHeadList(
                &(CmHive->LRUViewListHead),
                &(CmView->LRUViewList)
                );
            //
            // walk the LRU list back-wards until we find an unused view
            // 
            CmView = (PCM_VIEW_OF_FILE)CmHive->LRUViewListHead.Blink;
            CmView = CONTAINING_RECORD( CmView,
                                        CM_VIEW_OF_FILE,
                                        LRUViewList);
            while( CmView->LRUViewList.Blink != CmHive->LRUViewListHead.Flink ) {
                if( CmView->UseCount == 0 ) {
                    //
                    // this one is free go ahead and use it !
                    // first unmap, then signal that we found it
                    //
                    if( (CmHive->MappedViews >= CmMaxViewsPerHive) && (CmView->Bcb != NULL) ) {
                        CmpUnmapCmView(CmHive,CmView,MapValid,TRUE);
                    }
                    FoundView = TRUE;
                    break;

                }
                CmView = (PCM_VIEW_OF_FILE)CmView->LRUViewList.Blink;
                CmView = CONTAINING_RECORD( CmView,
                                            CM_VIEW_OF_FILE,
                                            LRUViewList);
            }
            //
            // all views are in use; bad luck, we just have to live with it (extend past MAX_VIEW_SIZE)
            //
            if( FoundView == FALSE ) {
                CmView = NULL;
            }

        }
    }
    //
    // immediately flush the cache so these dirty pages won't throttle other IOs
    // in case we did a CcPurge, this will clean out the Cc dirty hints. 
	//
    CcFlushCache (CmHive->FileObject->SectionObjectPointer,(PLARGE_INTEGER)(((ULONG_PTR)(&FileOffset)) + 1)/*we are private writers*/,Size,NULL);

    if( (CmHive->MappedViews >= CmMaxViewsPerHive) && (CmView != NULL) ) {
        
        // assert view unmapped
        ASSERT( ((CmView->FileOffset + CmView->Size) == 0) && (CmView->ViewAddress == 0) );
        //
        // no more views are allowed for this hive
        //
        RemoveEntryList(&(CmView->LRUViewList));
#if DBG
        //
        // do this to signal that LRUViewList is empty.
        //
        InitializeListHead(&(CmView->LRUViewList));
#endif
        CmpFreeCmView(CmView);        
        CmHive->MappedViews --;
    } 

    // make sure we didn't unmapped/unpinned more than we mapped/pinned
    ASSERT( (CmHive->MappedViews >= 0) ); // && (CmHive->MappedViews < CmMaxViewsPerHive) );
    ASSERT( (CmHive->PinnedViews >= 0) );
    
    //
    // at last, release the view lock
    //
    CmUnlockHiveViews (CmHive);

    return;
}

VOID
CmpFreeCmView (
        PCM_VIEW_OF_FILE  CmView
                             )
/*++

Routine Description:

    frees a CM View

Arguments:


Return Value:

    TBS - the new view

--*/
{
    
    PAGED_CODE();

    if (CmView == NULL) {
        CM_BUGCHECK(REGISTRY_ERROR,CMVIEW_ERROR,2,0,0);
    }
    
    //
    // Init the view
    //
    ASSERT( CmView->FileOffset == 0 );
    ASSERT( CmView->Size == 0 );
    ASSERT( CmView->ViewAddress == NULL );
    ASSERT( CmView->Bcb == NULL );
    ASSERT( CmView->UseCount == 0 );
    ASSERT( IsListEmpty(&(CmView->PinViewList)) == TRUE );
    ASSERT( IsListEmpty(&(CmView->LRUViewList)) == TRUE );
    
    ExFreePoolWithTag(CmView, CM_MAPPEDVIEW_TAG | PROTECTED_POOL);
    
    return;
}

VOID
CmpFixHiveUsageCount(
                    IN  PCMHIVE             CmHive
                    )

/*++

Routine Description:

    This is registry's contingency plan against bad and misbehaved apps.
    In a perfect world this should never be called; If we get here, somewhere
    inside a cm function we took an exception and never had a chance to 
    release all used cells. We fix that here, and as we hold the reglock exclusive,
    we are safe to do so.

    We have to clear each view UseCount and the hive UseCount.
    Also, unmap all views that are beyond CmMaxViewsPerHive


Arguments:

    Hive to be fixed

Return Value:

    none
--*/
{
    PCM_VIEW_OF_FILE    CmCurrentView;
    USHORT              NrViews;

    PAGED_CODE();

    CmKdPrintEx((DPFLTR_CONFIG_ID,DPFLTR_TRACE_LEVEL,"CmpFixHiveUsageCount : Contingency plan, fixing hive %p UseCount = %lx \n",CmHive,CmHive->UseCount));

    //
    // lock should be held exclusive and we should have a good reason to come here
    //
    ASSERT_CM_LOCK_OWNED_EXCLUSIVE();
    ASSERT( CmHive->UseCount );

    // 
    // Walk through the LRU list and fix each view
    //
    CmCurrentView = (PCM_VIEW_OF_FILE)CmHive->LRUViewListHead.Flink;

    for(NrViews = CmHive->MappedViews;NrViews;NrViews--) {
        CmCurrentView = CONTAINING_RECORD(  CmCurrentView,
                                            CM_VIEW_OF_FILE,
                                            LRUViewList);

        CmCurrentView->UseCount = 0;

        CmCurrentView = (PCM_VIEW_OF_FILE)CmCurrentView->LRUViewList.Flink;
    }

    //
    // unmap views from CmHive->MappedViews to CmMaxViewsPerHive
    //
    while( CmHive->MappedViews >= CmMaxViewsPerHive ) {
        //
        // get the last view from the list
        //
        CmCurrentView = (PCM_VIEW_OF_FILE)CmHive->LRUViewListHead.Blink;
        CmCurrentView = CONTAINING_RECORD(  CmCurrentView,
                                            CM_VIEW_OF_FILE,
                                            LRUViewList);

        //
        // unmap it; no need to move it at the end as we shall free it anyway
        //
        CmpUnmapCmView(CmHive,CmCurrentView,TRUE,FALSE);

        //
        // remove it from LRU list
        //
        RemoveEntryList(&(CmCurrentView->LRUViewList));
#if DBG
        //
        // do this to signal that LRUViewList is empty.
        //
        InitializeListHead(&(CmCurrentView->LRUViewList));
#endif
        CmpFreeCmView(CmCurrentView);        
        CmHive->MappedViews --;

    }

    // 
    // Walk through the pinned list and fix each view 
    //
    CmCurrentView = (PCM_VIEW_OF_FILE)CmHive->PinViewListHead.Flink;

    for(NrViews = CmHive->PinnedViews;NrViews;NrViews--) {
        CmCurrentView = CONTAINING_RECORD(  CmCurrentView,
                                            CM_VIEW_OF_FILE,
                                            PinViewList);
        
        CmCurrentView->UseCount = 0;

        CmCurrentView = (PCM_VIEW_OF_FILE)CmCurrentView->PinViewList.Flink;
    }

    //
    // finally, fix hive use count
    //
    CmHive->UseCount = 0;

}

#ifdef CMP_CMVIEW_VALIDATION

VOID
CmpCheckCmView(
    IN  PCMHIVE             CmHive,
    IN  PCM_VIEW_OF_FILE    CmView
    )
/*++

Routine Description:

    Makes sure the view is not mapped or pinned twice
    and that the entire range mapped by the view is correct 

Arguments:


Return Value:

    none
--*/
{
    PCM_VIEW_OF_FILE    CmCurrentView;
    USHORT              NrViews;
    ULONG               UseCount = 0;

    PAGED_CODE();

    ASSERT( ((CmView->Size + CmView->FileOffset) != 0 ) && (CmView->ViewAddress !=0 ) );

    // 
    // Walk through the LRU list and compare view addresses
    //
    CmCurrentView = (PCM_VIEW_OF_FILE)CmHive->LRUViewListHead.Flink;

    for(NrViews = CmHive->MappedViews;NrViews;NrViews--) {
        CmCurrentView = CONTAINING_RECORD(  CmCurrentView,
                                            CM_VIEW_OF_FILE,
                                            LRUViewList);
        
        if( ((CmCurrentView->Size + CmCurrentView->FileOffset) != 0) && (CmCurrentView->ViewAddress != 0) )  {
            //
            // view is valid
            //
            if( CmCurrentView != CmView ) {
                //
                // and is not the same view
                //
                if( (CmCurrentView->FileOffset == CmView->FileOffset) || 
                    (CmCurrentView->ViewAddress == CmView->ViewAddress)
                    ) {
                    //
                    // that's really bad! 2 views map the same address
                    //
#ifndef _CM_LDR_
                    DbgPrintEx(DPFLTR_CONFIG_ID,DPFLTR_ERROR_LEVEL,"CmpCheckCmView:: Two views map the same address (%lx,%p) for hive %p\n",CmView->FileOffset,CmView->ViewAddress,CmHive);
                    DbgPrintEx(DPFLTR_CONFIG_ID,DPFLTR_ERROR_LEVEL,"\tView1 = %p, Size = %lx\n",CmView,CmView->Size);
                    DbgPrintEx(DPFLTR_CONFIG_ID,DPFLTR_ERROR_LEVEL,"\tView2 = %p, Size = %lx\n",CmCurrentView,CmCurrentView->Size);
                    DbgBreakPoint();
#endif //_CM_LDR_
                }
            }
            UseCount += CmCurrentView->UseCount;
        } else {
            ASSERT( CmCurrentView->UseCount == 0 );
        }

        CmCurrentView = (PCM_VIEW_OF_FILE)CmCurrentView->LRUViewList.Flink;
    }

    // 
    // Walk through the pinned list and compare view addresses
    //
    CmCurrentView = (PCM_VIEW_OF_FILE)CmHive->PinViewListHead.Flink;

    for(NrViews = CmHive->PinnedViews;NrViews;NrViews--) {
        CmCurrentView = CONTAINING_RECORD(  CmCurrentView,
                                            CM_VIEW_OF_FILE,
                                            PinViewList);
        
        if( ((CmCurrentView->Size + CmCurrentView->FileOffset) != 0) && (CmCurrentView->ViewAddress != 0) )  {
            //
            // view is valid
            //
            if( CmCurrentView != CmView ) {
                //
                // and is not the same view
                //
                if( (CmCurrentView->FileOffset == CmView->FileOffset) || 
                    (CmCurrentView->ViewAddress == CmView->ViewAddress)
                    ) {
                    //
                    // that's really bad! 2 views map the same address
                    //
#ifndef _CM_LDR_
                    DbgPrintEx(DPFLTR_CONFIG_ID,DPFLTR_ERROR_LEVEL,"CmpCheckCmView:: Two views map the same address (%lx,%p) for hive %p\n",CmView->FileOffset,CmView->ViewAddress,CmHive);
                    DbgPrintEx(DPFLTR_CONFIG_ID,DPFLTR_ERROR_LEVEL,"\tView1 = %p, Size = %lx\n",CmView,CmView->Size);
                    DbgPrintEx(DPFLTR_CONFIG_ID,DPFLTR_ERROR_LEVEL,"\tView2 = %p, Size = %lx\n",CmCurrentView,CmCurrentView->Size);
                    DbgBreakPoint();
#endif //_CM_LDR_
                }
            }
            UseCount += CmCurrentView->UseCount;
        } else {
            ASSERT( CmCurrentView->UseCount == 0 );
        }

        CmCurrentView = (PCM_VIEW_OF_FILE)CmCurrentView->PinViewList.Flink;
    }

    if( CmHive->UseCount < UseCount ) {
#ifndef _CM_LDR_
        DbgPrintEx(DPFLTR_CONFIG_ID,DPFLTR_ERROR_LEVEL,"CmpCheckCmView:: Hive's (%p) UseCount smaller than total views UseCount %lu,%lu\n",CmHive,CmHive->UseCount,UseCount);
        DbgBreakPoint();
#endif //_CM_LDR_
        
    }
}

#endif //CMP_CMVIEW_VALIDATION

#if 0

VOID
CmpUnmapAditionalViews(
    IN PCMHIVE              CmHive
    )
/*++

Routine Description:

    Unmap all views that are beyond CmMaxViewsPerHive. 
    This routine is to be called at the end of CmpInitializeHiveList

Arguments:

    Hive to be fixed

Return Value:

    none
--*/
{
    PCM_VIEW_OF_FILE    CmCurrentView;
    USHORT              NrViews;

    PAGED_CODE();

    CmKdPrintEx((DPFLTR_CONFIG_ID,DPFLTR_TRACE_LEVEL,"CmpUnmapAditionalViews : Fixing hive %p MappedViews = %lx \n",CmHive,CmHive->MappedViews));

    ASSERT_CM_LOCK_OWNED_EXCLUSIVE();
    ASSERT( CmHive->UseCount == 0 );

    //
    // unmap views from CmHive->MappedViews to CmMaxViewsPerHive
    //
    while( CmHive->MappedViews >= CmMaxViewsPerHive ) {
        //
        // get the last view from the list
        //
        CmCurrentView = (PCM_VIEW_OF_FILE)CmHive->LRUViewListHead.Blink;
        CmCurrentView = CONTAINING_RECORD(  CmCurrentView,
                                            CM_VIEW_OF_FILE,
                                            LRUViewList);

        ASSERT( CmCurrentView->UseCount == 0 );
        //
        // unmap it
        //
        CmpUnmapCmView(CmHive,CmCurrentView,TRUE,FALSE);

        //
        // remove it from LRU list
        //
        RemoveEntryList(&(CmCurrentView->LRUViewList));
#if DBG
        //
        // do this to signal that LRUViewList is empty.
        //
        InitializeListHead(&(CmCurrentView->LRUViewList));
#endif
        CmpFreeCmView(CmCurrentView);        
        CmHive->MappedViews --;

    }

}

VOID
CmpMapEntireFileInFakeViews(
    IN PCMHIVE              CmHive,
    IN ULONG                Length
    )
/*++

Routine Description:

    Maps and faults all the file in, in chunks of 256K if possible.
    This should improve boot performance; After the hive is mapped
    (maps are build and hive is checked we'll get rid of this aditional 
    views
    
Arguments:

    CmHive - Hive to be mapped
    
    Length - length of the hive ==> add HBLOCK_SIZE

Return Value:

    none
--*/
{
    ULONG               Offset;
    ULONG               Size;
    PCM_VIEW_OF_FILE    CmView;
    LARGE_INTEGER       SectionOffset;  

    PAGED_CODE();

    ASSERT_CM_LOCK_OWNED_EXCLUSIVE();
    ASSERT( IsListEmpty(&(CmHive->FakeViewListHead)) );
#if DBG
    ASSERT( CmHive->FakeViews == 0 );  
#endif

    //
    // adjust the size to get the real size of the file
    Length += HBLOCK_SIZE;

    //
    // start from the beggining and map 256K of data from the hive
    // allocate a view and insert it in the FakeViewList, use LRUViewList for that.
    //
    Offset =0;
    SectionOffset.HighPart = 0;

    while( Offset < Length ) {
        CmView = ExAllocatePoolWithTag(PagedPool,sizeof(CM_VIEW_OF_FILE),CM_MAPPEDVIEW_TAG | PROTECTED_POOL);
    
        if (CmView == NULL) {
            CM_BUGCHECK(REGISTRY_ERROR,CMVIEW_ERROR,2,0,0);
        }
    
        //
        // Init the view
        //
        CmView->ViewAddress = NULL;
        CmView->Bcb = NULL;
    
        InsertTailList(
            &(CmHive->FakeViewListHead),
            &(CmView->LRUViewList)
            );
#if DBG
        CmHive->FakeViews++; 
#endif

        //
        // now try to map the view
        //
        Size = _256K;
        if( (Offset + Size) > Length ) {
            Size = Length - Offset;
        }

        SectionOffset.LowPart = Offset;
        try {
            if (!CcMapData( CmHive->FileObject,
                            (PLARGE_INTEGER)&SectionOffset,
                            Size,
                            MAP_WAIT 
#ifdef CM_MAP_NO_READ
                            | MAP_NO_READ
#endif
                            ,
                            (PVOID *)(&(CmView->Bcb)),
                            (PVOID *)(&(CmView->ViewAddress)) )) {
                CmKdPrintEx((DPFLTR_CONFIG_ID,DPFLTR_TRACE_LEVEL,"CmpMapEntireFileInFakeViews: Error mapping data at offset %lx for hive %p\n",Offset,CmHive));
                CmView->Bcb = NULL;
            }
        } except (EXCEPTION_EXECUTE_HANDLER) {
            //
            // in low-memory scenarios, CcMapData throws a STATUS_IN_PAGE_ERROR
            // this happens when the IO issued to touch the just-mapped data fails (usually with
            // STATUS_INSUFFICIENT_RESOURCES; We want to catch this and treat as a 
            // "not enough resources" problem, rather than letting it to surface the kernel call
            //
            // signal that the view is not mapped
            CmView->Bcb = NULL;
            CmKdPrintEx((DPFLTR_CONFIG_ID,DPFLTR_TRACE_LEVEL,"CmpMapEntireFileInFakeViews: Error mapping data at offset %lx for hive %p\n",Offset,CmHive));
        }

        if( CmView->Bcb == NULL ) {
            //
            // we are already short on memory; don't make things worse than they are
            // free what we have already allocated and bail out
            //
            CmKdPrintEx((DPFLTR_CONFIG_ID,DPFLTR_TRACE_LEVEL,"CmpMapEntireFileInFakeViews: Could not map entire file for hive %p ... bailing out\n",CmHive));
            CmpUnmapFakeViews(CmHive);
            return;
        }

        //
        // advance the offset
        //
        Offset += Size;
    }

#if DBG
    CmKdPrintEx((DPFLTR_CONFIG_ID,DPFLTR_TRACE_LEVEL,"CmpMapEntireFileInFakeViews: Successfully mapped %lx FakeViews for hive %p\n",CmHive->FakeViews,CmHive));
#endif
}

VOID
CmpUnmapFakeViews(
    IN PCMHIVE              CmHive
    )
/*++

Routine Description:

    Walks through the FakeViewList and unmaps all views.
  
Arguments:

    CmHive - Hive to be unmapped
    
Return Value:

    none
--*/
{
    PCM_VIEW_OF_FILE    CmView;

    PAGED_CODE();

    ASSERT_CM_LOCK_OWNED_EXCLUSIVE();

#if DBG
    CmKdPrintEx((DPFLTR_CONFIG_ID,DPFLTR_TRACE_LEVEL,"CmpUnmapFakeViews: Unmapping %lx views for hive %p\n",CmHive->FakeViews,CmHive));
#endif

    while( IsListEmpty( &(CmHive->FakeViewListHead) ) == FALSE ) {
        CmView = (PCM_VIEW_OF_FILE)RemoveHeadList(&(CmHive->FakeViewListHead));
        CmView = CONTAINING_RECORD( CmView,
                                    CM_VIEW_OF_FILE,
                                    LRUViewList);
        
        if( CmView->Bcb != NULL ) {
            //
            // view is mapped; unpin it.
            //
            CcUnpinData( CmView->Bcb );
        }

        //
        // now free the memory for this view.
        //
        ExFreePoolWithTag(CmView, CM_MAPPEDVIEW_TAG | PROTECTED_POOL);
#if DBG
        CmHive->FakeViews--;          
#endif

    }

    ASSERT( IsListEmpty( &(CmHive->FakeViewListHead) ) == TRUE );
#if DBG
    ASSERT( CmHive->FakeViews == 0 );          
#endif
}

#endif

VOID
CmpPrefetchHiveFile( 
                    IN PFILE_OBJECT FileObject,
                    IN ULONG        Length
                    )
/*++

Routine Description:

    Prefetch all file into memory.
    We're using MmPrefetchPages fast routine; Pages will be put in the transition
    state, and they'll be used by the hive load worker while mapping data
  
Arguments:

    FileObject - file object associated with the file to be prefetched

    Length - length of the file
    
Return Value:

    none
--*/
{
    ULONG       NumberOfPages;
    PREAD_LIST  *ReadLists;
    PREAD_LIST  ReadList;
    ULONG       AllocationSize;
    ULONG       Offset;

    PAGED_CODE();

    ASSERT_CM_LOCK_OWNED_EXCLUSIVE();
    
    NumberOfPages = ROUND_UP(Length,PAGE_SIZE) / PAGE_SIZE ;

    ReadLists = ExAllocatePoolWithTag(NonPagedPool, sizeof(PREAD_LIST), CM_POOL_TAG);
    if (ReadLists == NULL) {
        return;
    }

    AllocationSize = sizeof(READ_LIST) + (NumberOfPages * sizeof(FILE_SEGMENT_ELEMENT));

    ReadList = ExAllocatePoolWithTag(NonPagedPool,AllocationSize,CM_POOL_TAG);

    if (ReadList == NULL) {
        ExFreePool(ReadLists);
        return;
    }

    ReadList->FileObject = FileObject;
    ReadList->IsImage = FALSE;
    ReadList->NumberOfEntries = 0;
    Offset = 0;
    while( Offset < Length ) {
        ReadList->List[ReadList->NumberOfEntries].Alignment = Offset;
        ReadList->NumberOfEntries++;
        Offset += PAGE_SIZE;
    }
    ASSERT( ReadList->NumberOfEntries == NumberOfPages );

    ReadLists[0] = ReadList;

    MmPrefetchPages (1,ReadLists);
    
    // just to make sure !
    // this assert has been moved inside CcSetPrivateWriteFile !!! 
    // there is no need to assert this here
    //ASSERT( MmDisableModifiedWriteOfSection (FileObject->SectionObjectPointer) );

    ExFreePool(ReadList);
    ExFreePool(ReadLists);
}


VOID
CmpUnmapUnusedViews(
        IN  PCMHIVE             CmHive
    )
/*++

Routine Description:

    Unmaps all mapped views than are not currently in-use.

    The purpose of this is to allow a retry in case CcMapData failed
    because of the system having to many mapped views.

    We should not run into this too often ( - at all ).

Arguments:
    
      CmHive - hive for which we already have the viewlist lock owned
    
Return Value:

    none
--*/
{
    PCM_VIEW_OF_FILE    CmView;
    USHORT              NrViews;
    PCMHIVE             CmCurrentHive;
    PLIST_ENTRY         p;

    PAGED_CODE();

    //
    // iterate through the hive list
    //
    LOCK_HIVE_LIST();
    p = CmpHiveListHead.Flink;
    while(p != &CmpHiveListHead) {
        CmCurrentHive = (PCMHIVE)CONTAINING_RECORD(p, CMHIVE, HiveList);
        
        if( CmCurrentHive != CmHive ) {
            //
            // we need to be the only ones operating on this list
            //
            CmLockHiveViews (CmCurrentHive);
        } else {
            //
            // we already have the mutex owned
            //
            NOTHING;
        }
        //
        // try to unmap all mapped views
        //
        CmView = (PCM_VIEW_OF_FILE)CmCurrentHive->LRUViewListHead.Flink;

        for(NrViews = CmCurrentHive->MappedViews;NrViews;NrViews--) {
            CmView = CONTAINING_RECORD( CmView,
                                        CM_VIEW_OF_FILE,
                                        LRUViewList);
        
            if( (CmView->ViewAddress != 0) && ( CmView->UseCount == 0 ) ) {
                //
                // view is mapped and it is not in use 
                //
                ASSERT( (CmView->FileOffset + CmView->Size) != 0 && (CmView->Bcb != 0));

                //
                // unmap it without altering its position in the list
                //
                CmpUnmapCmView(CmCurrentHive,CmView,TRUE,FALSE);
            }
    
            CmView = (PCM_VIEW_OF_FILE)CmView->LRUViewList.Flink;
        }

        if( CmCurrentHive != CmHive ) {
            CmUnlockHiveViews (CmCurrentHive);
        }

        p=p->Flink;
    }
    UNLOCK_HIVE_LIST();

}

NTSTATUS
CmPrefetchHivePages(
                    IN  PUNICODE_STRING     FullHivePath,
                    IN  OUT PREAD_LIST      ReadList
                           )
/*++

Routine Description:

    Searches through the hive list for a hive with the backing file of name FullHivePath
    Builds a READ_LIST based on the given page offsets array and prefetches the pages 

Arguments:

    FullHivePath - Full Path of the file

    ReadList - read_list of page offsets to be prefetched.

Return Value:

    STATUS_SUCCESS - OK, pages prefetched

    STATUS_INVALID_PARAMETER - file was not found in the machine's hive list

    else, status returned by MmPrefetchPages.

--*/
{
    PCMHIVE             CmHive;
    PLIST_ENTRY         p;
    BOOLEAN             HiveFound = FALSE;
    NTSTATUS            Status;
    ULONG               i;

    PAGED_CODE();

    CmpLockRegistry();

    //
    // iterate through the hive list
    //
    LOCK_HIVE_LIST();
    p = CmpHiveListHead.Flink;
    while(p != &CmpHiveListHead) {
        CmHive = (PCMHIVE)CONTAINING_RECORD(p, CMHIVE, HiveList);
        
        if( (CmHive->FileObject != NULL) && (CmHive->FileFullPath.Buffer != NULL) ) {
            //
            // there is a chance this might be the one
            //
            if( RtlCompareUnicodeString(FullHivePath,&(CmHive->FileFullPath),TRUE) == 0 ) {
                //
                // we found it !
                //
                HiveFound = TRUE;
                break;
            }
            
        }

        p=p->Flink;
    }
    UNLOCK_HIVE_LIST();
    
    if( (HiveFound == FALSE) || ( ReadList == NULL ) ) {
        //
        // bad luck;
        //
        CmpUnlockRegistry();
        return STATUS_INVALID_PARAMETER;
    }

    ASSERT( CmHive->FileObject != NULL );

    //
    // at this point, we have successfully identified the hive 
    //
    
    //
    // build up the READ_LIST with the requested page offsets
    //
    ReadList->FileObject = CmHive->FileObject;
    ReadList->IsImage = FALSE;
    ASSERT( ReadList->NumberOfEntries != 0 );
    
    Status = MmPrefetchPages (1,&ReadList);
    
    // just to make sure !
    ASSERT( MmDisableModifiedWriteOfSection (CmHive->FileObject->SectionObjectPointer) );

    CmpUnlockRegistry();
    return Status;
}

BOOLEAN
CmIsFileLoadedAsHive(PFILE_OBJECT FileObject)
{
    PCMHIVE             CmHive;
    PLIST_ENTRY         p;
    BOOLEAN             HiveFound = FALSE;

    //
    // iterate through the hive list
    //
    LOCK_HIVE_LIST();
    p = CmpHiveListHead.Flink;
    while(p != &CmpHiveListHead) {
        CmHive = (PCMHIVE)CONTAINING_RECORD(p, CMHIVE, HiveList);
        
        if( CmHive->FileObject == FileObject ) {
            //
            // we found it !
            //
            HiveFound = TRUE;
            break;
        }

        p=p->Flink;
    }
    UNLOCK_HIVE_LIST();

    return HiveFound;
}

VOID
CmpReferenceHiveView(   IN PCMHIVE          CmHive,
                        IN PCM_VIEW_OF_FILE CmView
                     )
/*++

Routine Description:

    Adds a refcount to the hive and view, to prevent it from going away from under us;
    Assumes the viewlock is held by the caller. 
    Can be converted to a macro.

Arguments:


Return Value:


--*/
{
    PAGED_CODE();

    if(CmView && CmHive->Hive.ReleaseCellRoutine) {
        //
        // up the view use count if any
        //
        CmView->UseCount++;
    }

}

VOID
CmpDereferenceHiveView(   IN PCMHIVE          CmHive,
                          IN PCM_VIEW_OF_FILE CmView
                     )
/*++

Routine Description:

    Pair of CmpReferenceHiveView
    Assumes the viewlock is held by the caller. 
    Can be converted to a macro.

Arguments:


Return Value:


--*/
{
    PAGED_CODE();

    if(CmView && CmHive->Hive.ReleaseCellRoutine) {
        CmView->UseCount--;
    }
}


VOID
CmpReferenceHiveViewWithLock(   IN PCMHIVE          CmHive,
                                IN PCM_VIEW_OF_FILE CmView
                            )
/*++

Routine Description:

    Adds a refcount to the hive and view, to prevent it from going away from under us;
    Can be converted to a macro.

Arguments:


Return Value:


--*/
{
    PAGED_CODE();

    CmLockHiveViews(CmHive);
    //
    // call the unsafe routine
    //
    CmpReferenceHiveView(CmHive,CmView);

    CmUnlockHiveViews(CmHive);
}

VOID
CmpDereferenceHiveViewWithLock(     IN PCMHIVE          CmHive,
                                    IN PCM_VIEW_OF_FILE CmView
                                )
/*++

Routine Description:

    Pair of CmpDereferenceHiveViewWithLock
    Can be converted to a macro.

Arguments:


Return Value:


--*/
{
    PAGED_CODE();

    CmLockHiveViews(CmHive);
    //
    // call the unsafe routine
    //
    CmpDereferenceHiveView(CmHive,CmView);

    CmUnlockHiveViews(CmHive);
}
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\base\ntos\config\cmnotify.c ===
/*++

Copyright (c) 1991  Microsoft Corporation

Module Name:

    cmnotify.c

Abstract:

    This module contains support for NtNotifyChangeKey.

Author:

    Bryan M. Willman (bryanwi) 03-Feb-1992

Revision History:

    Dragos C. Sambotin (dragoss) 16-Mar-1999
        - fixing race conditions that when more than one thread simultaneously operates over the post list
--*/


//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//                                                                                                                      //
//   "The" POST BLOCK RULE :                                                                                            //
//                                                                                                                      //
//      To operate on a post block (i.e. add or remove it from a list - notify,thread,slave),                           //
//      you should at least:                                                                                            //
//          1. Hold the registry lock exclusively                                                                       //
//                     OR                                                                                               //
//          2. Hold the registry lock shared and aquire the postblock mutex.                                            //
//                                                                                                                      //
//                                                                                                                      //
//      WARNING!!!                                                                                                      //
//          Failing to do that could arise in obscure registry deadlocks or usage of already freed memory (bugcheck)    //
//                                                                                                                      //
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//                                                                                                                      //
//  Other important rules to follow:                                                                                    //
//                                                                                                                      //
//      1. We DO NOT dereference objects in CmpPostApc !                                                                //
//      2. We DO NOT dereference objects while walking the notify list!                                                 //
//      3. All operations with Thread PostList are done in CmpPostApc or at APC level. This should avoid two threads    //
//          operating on the same list at the same time                                                                 //
//                                                                                                                      //
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////

#include    "cmp.h"

#ifdef CMP_NOTIFY_POSTBLOCK_CHECK
/*++
Routine Description:
    Check if the post block or it's slave (if any) has no reference 
    to any key body object
++*/

#define CmpCheckPostBlock(PostBlock )                                               \
    {                                                                               \
        PCM_POST_BLOCK  SlavePostBlock;                                             \
                                                                                    \
        /* this post block should have the link with key body already broken*/      \
        ASSERT( PostBlock->PostKeyBody == NULL );                                   \
                                                                                    \
        /* only masters get to CmpPostApc */                                        \
        ASSERT( IsMasterPostBlock(PostBlock) );                             \
                                                                                    \
        if (CmpIsListEmpty(&(PostBlock->CancelPostList)) == FALSE) {                   \
                                                                                    \
            /* get the slave and verify him too */                                  \
            SlavePostBlock = (PCM_POST_BLOCK)PostBlock->CancelPostList.Flink;       \
            SlavePostBlock = CONTAINING_RECORD(SlavePostBlock,                      \
                                               CM_POST_BLOCK,                       \
                                               CancelPostList);                     \
            /* This should be true !*/                                              \
            ASSERT( !IsMasterPostBlock(SlavePostBlock) );                           \
                                                                                    \
            /* this post block shoul have the link with key body already broken */  \
            ASSERT( SlavePostBlock->PostKeyBody == NULL );                          \
        }                                                                           \
    }
#else
#define CmpCheckPostBlock(a) //nothing
#endif


//
// "Back Side" of notify
//

extern  PCMHIVE  CmpMasterHive;

VOID
CmpReportNotifyHelper(
    PCM_KEY_CONTROL_BLOCK KeyControlBlock,
    IN PHHIVE SearchHive,
    IN PHHIVE Hive,
    IN HCELL_INDEX Cell,
    IN ULONG Filter
    );

VOID
CmpCancelSlavePost(
    PCM_POST_BLOCK  PostBlock,
    PLIST_ENTRY     DelayedDeref
    );

VOID
CmpFreeSlavePost(
    PCM_POST_BLOCK  MasterPostBlock
    );

VOID
CmpAddToDelayedDeref(
    PCM_POST_BLOCK  PostBlock,
    PLIST_ENTRY     DelayedDeref
    );

VOID
CmpDelayedDerefKeys(
                    PLIST_ENTRY DelayedDeref
                    );

BOOLEAN
CmpNotifyTriggerCheck(
    IN PCM_NOTIFY_BLOCK NotifyBlock,
    IN PHHIVE Hive,
    IN PCM_KEY_NODE Node
    );

VOID
CmpDummyApc(
    struct _KAPC *Apc,
    PVOID *SystemArgument1,
    PVOID *SystemArgument2
    );

#ifdef CM_NOTIFY_CHANGED_KCB_FULLPATH  
VOID
CmpFillPostBlockBuffer(
                    PCM_POST_BLOCK  PostBlock,
                    PUNICODE_STRING ChangedKcbName  OPTIONAL
                    );
#endif //CM_NOTIFY_CHANGED_KCB_FULLPATH  

#ifdef ALLOC_PRAGMA
#pragma alloc_text(PAGE,CmpReportNotify)
#pragma alloc_text(PAGE,CmpReportNotifyHelper)
#pragma alloc_text(PAGE,CmpPostNotify)
#pragma alloc_text(PAGE,CmpPostApc)
#pragma alloc_text(PAGE,CmpPostApcRunDown)
#pragma alloc_text(PAGE,CmNotifyRunDown)
#pragma alloc_text(PAGE,CmpFlushNotify)
#pragma alloc_text(PAGE,CmpNotifyChangeKey)
#pragma alloc_text(PAGE,CmpCancelSlavePost)
#pragma alloc_text(PAGE,CmpFreeSlavePost)
#pragma alloc_text(PAGE,CmpAddToDelayedDeref)
#pragma alloc_text(PAGE,CmpDelayedDerefKeys)
#pragma alloc_text(PAGE,CmpNotifyTriggerCheck)
#pragma alloc_text(PAGE,CmpDummyApc)

#ifdef CM_NOTIFY_CHANGED_KCB_FULLPATH  
#pragma alloc_text(PAGE,CmpFillCallerBuffer)
#pragma alloc_text(PAGE,CmpFillPostBlockBuffer)
#endif //CM_NOTIFY_CHANGED_KCB_FULLPATH  

#endif

VOID
CmpDummyApc(
    struct _KAPC *Apc,
    PVOID *SystemArgument1,
    PVOID *SystemArgument2
    )
/*++

Routine Description:

    Dummy routine to prevent user-mode callers to set special kernel apcs

Arguments:

    Apc - pointer to apc object

    SystemArgument1 -  IN: Status value for IoStatusBlock
                      OUT: Ptr to IoStatusBlock (2nd arg to user apc routine)

    SystemArgument2 - Pointer to the PostBlock

Return Value:

    NONE.

--*/
{
    UNREFERENCED_PARAMETER(Apc);
    UNREFERENCED_PARAMETER(SystemArgument1);
    UNREFERENCED_PARAMETER(SystemArgument2);
}

VOID
CmpReportNotify(
    PCM_KEY_CONTROL_BLOCK   KeyControlBlock,
    PHHIVE                  Hive,
    HCELL_INDEX             Cell,
    ULONG                   Filter
    )
/*++

Routine Description:

    This routine is called when a notifiable event occurs. It will
    apply CmpReportNotifyHelper to the hive the event occured in,
    and the master hive if different.

Arguments:

    KeyControlBlock - KCB of the key at which the event occured.
            For create or delete this is the created or deleted key.

    Hive - pointer to hive containing cell of Key at which event occured.

    Cell - cell of Key at which event occured

            (hive and cell correspond with name.)

    Filter - event to be reported

Return Value:

    NONE.

--*/
{
    HCELL_INDEX     CellToRelease = HCELL_NIL;

    PAGED_CODE();
    CmKdPrintEx((DPFLTR_CONFIG_ID,CML_NOTIFY,"CmpReportNotify:\n"));
    CmKdPrintEx((DPFLTR_CONFIG_ID,CML_NOTIFY,"\tHive:%p Cell:%08lx Filter:%08lx\n", Hive, Cell, Filter));

    //
    // If the operation was create or delete, treat it as a change
    // to the parent.
    //
    if (Filter == REG_NOTIFY_CHANGE_NAME) {
        PCM_KEY_NODE pcell;
        ULONG       flags;

        pcell = (PCM_KEY_NODE)HvGetCell(Hive, Cell);
        if( pcell == NULL ) {
            //
            // we couldn't map the bin containing this cell
            // Bad luck! notifications will be broken.
            //
            return;
        }
        
        CellToRelease = Cell;

        flags = pcell->Flags;
        Cell = pcell->Parent;
        if (flags & KEY_HIVE_ENTRY) {
            ASSERT( CellToRelease != HCELL_NIL );
            HvReleaseCell(Hive,CellToRelease);

            Hive = &(CmpMasterHive->Hive);
            pcell = (PCM_KEY_NODE)HvGetCell(Hive, Cell);
            if( pcell == NULL ) {
                //
                // we couldn't map the bin containing this cell
                // Bad luck! notifications will be broken.
                //
                return;
            }
            CellToRelease = Cell;
        }


        KeyControlBlock = KeyControlBlock->ParentKcb;

        //
        // if we're at an exit/link node, back up the real node
        // that MUST be it's parent.
        //
        if (pcell->Flags & KEY_HIVE_EXIT) {
            Cell = pcell->Parent;
        }

        ASSERT( CellToRelease != HCELL_NIL );
        HvReleaseCell(Hive,CellToRelease);

    }

    //
    // Report to notifies waiting on the event's hive
    //
    CmpReportNotifyHelper(KeyControlBlock, Hive, Hive, Cell, Filter);


    //
    // If containing hive is not the master hive, apply to master hive
    //
    if (Hive != &(CmpMasterHive->Hive)) {
        CmpReportNotifyHelper(KeyControlBlock,
                              &(CmpMasterHive->Hive),
                              Hive,
                              Cell,
                              Filter);
    }

    return;
}

BOOLEAN
CmpNotifyTriggerCheck(
    IN PCM_NOTIFY_BLOCK NotifyBlock,
    IN PHHIVE Hive,
    IN PCM_KEY_NODE Node
    )
/*++

Routine Description:

    Checks if a notify can be triggered

Arguments:

    NotifyBlock - the notify block

    Hive - Supplies hive containing node to match with.

    Node - pointer to key to match with (and check access to)


Return Value:

    TRUE - yes.
    FALSE - no

--*/
{
    PCM_POST_BLOCK PostBlock;
    POST_BLOCK_TYPE NotifyType;

    PAGED_CODE();

    if(IsListEmpty(&(NotifyBlock->PostList)) == FALSE) {

        //
        // check if it is a kernel notify. Look at the first post block
        // to see that. If is a kernel post-block, then all posts in 
        // the list should be kernel notifies
        //
        PostBlock = (PCM_POST_BLOCK)NotifyBlock->PostList.Flink;
        PostBlock = CONTAINING_RECORD(PostBlock,
                                      CM_POST_BLOCK,
                                      NotifyList);

        NotifyType = PostBlockType(PostBlock);

        if( NotifyType == PostAsyncKernel ) {
            // this is a kernel notify; always trigger it
#if DBG
            //
            // DEBUG only code: All post blocks should be of the same type
            // (kernel/user)
            //
            while( PostBlock->NotifyList.Flink != &(NotifyBlock->PostList) ) {
                PostBlock = (PCM_POST_BLOCK)PostBlock->NotifyList.Flink;
                PostBlock = CONTAINING_RECORD(PostBlock,
                                            CM_POST_BLOCK,
                                            NotifyList);
                
                CmKdPrintEx((DPFLTR_CONFIG_ID,CML_NOTIFY,"CmpNotifyTriggerCheck : NotifyBlock = %p\n",NotifyBlock));
                
                ASSERT( PostBlockType(PostBlock) == NotifyType );
            }
#endif
        
            return TRUE;
        }
    }

    //
    // else, check if the caller has the right access
    //
    return CmpCheckNotifyAccess(NotifyBlock,Hive,Node);
}

VOID
CmpReportNotifyHelper(
    PCM_KEY_CONTROL_BLOCK KeyControlBlock,
    IN PHHIVE SearchHive,
    IN PHHIVE Hive,
    IN HCELL_INDEX Cell,
    IN ULONG Filter
    )
/*++

Routine Description:

    Scan the list of active notifies for the specified hive.  For
    any with scope including KeyControlBlock and filter matching
    Filter, and with proper security access, post the notify.

Arguments:

    Name - canonical path name (as in a key control block) of the key
            at which the event occured.  (This is the name for
            reporting purposes.)

    SearchHive - hive to search for matches (which notify list to check)

    Hive - Supplies hive containing node to match with.

    Cell - cell identifying the node in Hive

    Filter - type of event

Return Value:

    NONE.

--*/
{
    PLIST_ENTRY         NotifyPtr;
    PCM_NOTIFY_BLOCK    NotifyBlock;
    PCMHIVE             CmSearchHive;
    PUNICODE_STRING     NotifyName;
    KIRQL               OldIrql;
    LIST_ENTRY          DelayedDeref;
    PCM_KEY_NODE        Node;
#ifdef CM_NOTIFY_CHANGED_KCB_FULLPATH  
    PUNICODE_STRING     FullKcbName;
#endif //CM_NOTIFY_CHANGED_KCB_FULLPATH  

    PAGED_CODE();

    Node = (PCM_KEY_NODE)HvGetCell(Hive,Cell);
    if( Node == NULL ) {
        //
        // bad luck, we cannot map the view containing this cell
        //
        return;
    }

#ifdef CM_NOTIFY_CHANGED_KCB_FULLPATH  
    FullKcbName = CmpConstructName(KeyControlBlock);
#endif //CM_NOTIFY_CHANGED_KCB_FULLPATH  

    KeRaiseIrql(APC_LEVEL, &OldIrql);

    CmSearchHive = CONTAINING_RECORD(SearchHive, CMHIVE, Hive);

    NotifyPtr = &(CmSearchHive->NotifyList);

    InitializeListHead(&(DelayedDeref));

    while (NotifyPtr->Flink != NULL) {

        NotifyPtr = NotifyPtr->Flink;

        NotifyBlock = CONTAINING_RECORD(NotifyPtr, CM_NOTIFY_BLOCK, HiveList);
        if (NotifyBlock->KeyControlBlock->TotalLevels > KeyControlBlock->TotalLevels) {
            //
            // list is level sorted, we're past all shorter entries
            //
            break;
        } else {
            PCM_KEY_CONTROL_BLOCK kcb;
            ULONG LevelDiff, l;

            LevelDiff = KeyControlBlock->TotalLevels - NotifyBlock->KeyControlBlock->TotalLevels;

            kcb = KeyControlBlock;
            for (l=0; l<LevelDiff; l++) {
                kcb = kcb->ParentKcb;
            }

            if (kcb == NotifyBlock->KeyControlBlock) {
                //
                // This Notify path is the prefix of this kcb.
                //
                if ((NotifyBlock->Filter & Filter)
                            &&
                    ((NotifyBlock->WatchTree == TRUE) ||
                     (Cell == kcb->KeyCell))
                   )
                {
                    // Filter matches, this event is relevent to this notify
                    //                  AND
                    // Either the notify spans the whole subtree, or the cell
                    // (key) of interest is the one it applies to
                    //
                    // THEREFORE:   The notify is relevent.
                    //

                    //
                    // Correct scope, does caller have access?
                    //
                    if (CmpNotifyTriggerCheck(NotifyBlock,Hive,Node)) {
                        //
                        // Notify block has KEY_NOTIFY access to the node
                        // the event occured at.  It is relevent.  Therefore,
                        // it gets to see this event.  Post and be done.
                        //
                        // we specify that we want no key body dereferenciation 
                        // during the CmpPostNotify call. This is to prevent the 
                        // deletion of the current notify block
                        //
                        CmpPostNotify(
                            NotifyBlock,
                            NULL,
                            Filter,
                            STATUS_NOTIFY_ENUM_DIR,
                            &DelayedDeref
#ifdef CM_NOTIFY_CHANGED_KCB_FULLPATH  
                            ,
                            FullKcbName
#endif //CM_NOTIFY_CHANGED_KCB_FULLPATH  
                            );

                    }  // else no KEY_NOTIFY access to node event occured at
                } // else not relevent (wrong scope, filter, etc)
            }
        }
    }
    
    KeLowerIrql(OldIrql);

    HvReleaseCell(Hive,Cell);

    //
    // finish the job started in CmpPostNotify (i.e. dereference the keybodies
    // we prevented. this may cause some notifyblocks to be freed
    //
    CmpDelayedDerefKeys(&DelayedDeref);

#ifdef CM_NOTIFY_CHANGED_KCB_FULLPATH  
    if( FullKcbName != NULL ) {
        ExFreePoolWithTag(FullKcbName, CM_NAME_TAG | PROTECTED_POOL);
    }
#endif //CM_NOTIFY_CHANGED_KCB_FULLPATH  
    
    return;
}


VOID
CmpPostNotify(
    PCM_NOTIFY_BLOCK    NotifyBlock,
    PUNICODE_STRING     Name OPTIONAL,
    ULONG               Filter,
    NTSTATUS            Status,
    PLIST_ENTRY         ExternalKeyDeref OPTIONAL
#ifdef CM_NOTIFY_CHANGED_KCB_FULLPATH  
    ,
    PUNICODE_STRING     ChangedKcbName OPTIONAL
#endif //CM_NOTIFY_CHANGED_KCB_FULLPATH  
    )
/*++

Routine Description:

    Actually report the notify event by signalling events, enqueing
    APCs, and so forth.

    When Status is STATUS_NOTIFY_CLEANUP:

      - if the post block is a slave one, just cancel it.
      - if the post block is a master one, cancel all slave post blocks
        and trigger event on the master block.

Comments:
    
    This routine is using a "delayed dereferencing" technique to prevent
    deadlocks that may appear when a keybody is dereferenced while holding
    the post block lock. As for this, a list with keybodies that have to be 
    dereferenced is constructed while walking the list of postblocks attached
    to the current notify block and the related (slave or master) post blocks.
    The list is built by tricking postblocks. For all postblock about to be 
    freed the PostKeyBody member is added to the local list and then set to NULL
    on the postblock. This will avoid the key body dereferencing in CmpFreePostBlock.
    Instead, after the postblock lock is released, the local list is iterated and 
    the keybodies are dereferenced and the storage for associated CM_POST_KEY_BODY 
    objects is freed.

  
Arguments:

    NotifyBlock - pointer to structure that describes the notify
                  operation.  (Where to post to)

    Name - name of key at which event occurred.

    Filter - nature of event

    Status - completion status to report

    ExternalKeyDeref - this parameter (when not NULL) specifies that the caller doesn't 
                    want any keybody to be dereferenced while in this routine

Return Value:

    NONE.

--*/
{
    PCM_POST_BLOCK      PostBlock;
    PCM_POST_BLOCK      SlavePostBlock;
    LIST_ENTRY          LocalDelayedDeref;
    KIRQL               OldIrql;
    PLIST_ENTRY         DelayedDeref;

    Filter;
    Name;

    PAGED_CODE();
    CmKdPrintEx((DPFLTR_CONFIG_ID,CML_NOTIFY,"CmpPostNotify:\n"));
    CmKdPrintEx((DPFLTR_CONFIG_ID,CML_NOTIFY,"\tNotifyBlock:%p  ", NotifyBlock));
    CmKdPrintEx((DPFLTR_CONFIG_ID,CML_NOTIFY,"\tName = %wZ\n", Name));
    CmKdPrintEx((DPFLTR_CONFIG_ID,CML_NOTIFY,"\tFilter:%08lx  Status=%08lx\n", Filter, Status));
    ASSERT_CM_LOCK_OWNED();

    if( ARGUMENT_PRESENT(ExternalKeyDeref) ) {
        //
        // The caller want to do all keybody dereferencing by himself
        //
        DelayedDeref = ExternalKeyDeref;
    } else {
        // local delayed dereferencing (the caller doesn't care!)
        DelayedDeref = &LocalDelayedDeref;
        InitializeListHead(DelayedDeref);
    }

    //
    // Aquire exclusive access over the postlist(s)
    //
    LOCK_POST_LIST();

    if (IsListEmpty(&(NotifyBlock->PostList)) == TRUE) {
        //
        // Nothing to post, set a mark and return
        //
        NotifyBlock->NotifyPending = TRUE;
        UNLOCK_POST_LIST();
        return;
    }
    NotifyBlock->NotifyPending = FALSE;

    //
    // IMPLEMENTATION NOTE:
    //      If we ever want to actually implement the code that returns
    //      names of things that changed, this is the place to add the
    //      name and operation type to the buffer.
    //

    //
    // Pull and post all the entries in the post list
    //
    while (IsListEmpty(&(NotifyBlock->PostList)) == FALSE) {

        //
        // Remove from the notify block list, and enqueue the apc.
        // The apc will remove itself from the thread list
        //
        PostBlock = (PCM_POST_BLOCK)RemoveHeadList(&(NotifyBlock->PostList));
        PostBlock = CONTAINING_RECORD(PostBlock,
                                      CM_POST_BLOCK,
                                      NotifyList);

        // Protect for multiple deletion of the same object
        CmpClearListEntry(&(PostBlock->NotifyList));
        
        if( (Status == STATUS_NOTIFY_CLEANUP) && !IsMasterPostBlock(PostBlock) ) {
            //
            // Cleanup notification (i.e. the key handle was closed or the key was deleted)
            // When the post is a slave one, just cancel it. Canceling means:
            //      1. Removing from the notify PostList (aldready done at this point - see above)
            //      2. Unchaining from the Master Block CancelPostList
            //      3. Delisting from the thread PostBlockList
            //      4. Actually freeing the memory
            //

            // Use Cmp variant to protect for multiple deletion of the same object
            CmpRemoveEntryList(&(PostBlock->CancelPostList));
            //
            // FIX 289351
            //
            // Use Cmp variant to protect for multiple deletion of the same object
            KeRaiseIrql(APC_LEVEL, &OldIrql);
            CmpRemoveEntryList(&(PostBlock->ThreadList));
            KeLowerIrql(OldIrql);

            if( PostBlock->NotifyType != PostSynchronous ) {

                // add to the deref list and clean the post block
                CmpAddToDelayedDeref(PostBlock,DelayedDeref);

                //
                // Front-end routine will do self cleanup for syncrounous notifications
                CmpFreePostBlock(PostBlock);
            }

#if DBG
            if(PostBlock->TraceIntoDebugger) {
                CmKdPrintEx((DPFLTR_CONFIG_ID,CML_NOTIFY,"[CM]\tCmpPostNotify: PostBlock:%p is a slave block,and notify is CLEANUP==> just cleanning\n", PostBlock));
            }
#endif

            continue; //try the next one
        }

        //
        // Simulate that this block is the master one, so we can free the others
        // Doing that will ensure the right memory dealocation when the master
        // (from now on this block) will be freed.
        //
        if(!IsMasterPostBlock(PostBlock)) {
            //
            // oops.,this is not the master block, we have some more work to do
            //
            SlavePostBlock = PostBlock;
            do {
                SlavePostBlock = (PCM_POST_BLOCK)SlavePostBlock->CancelPostList.Flink;
                SlavePostBlock = CONTAINING_RECORD(SlavePostBlock,
                                                   CM_POST_BLOCK,
                                                   CancelPostList);
                //
                // reset the "master flag" if set
                //
                ClearMasterPostBlockFlag(SlavePostBlock);
            } while (SlavePostBlock != PostBlock);

            //
            // Make this post block the master one
            //
            SetMasterPostBlockFlag(PostBlock);
        }

#if DBG
        if(PostBlock->TraceIntoDebugger) {
            CmKdPrintEx((DPFLTR_CONFIG_ID,CML_NOTIFY,"[CM]\tCmpPostNotify: Master block switched to :%p\n", PostBlock));
        }
#endif

        //
        // Cancel all slave Post requests that may be linked to self
        //

        if( PostBlockType(PostBlock) != PostSynchronous ) {
            //
            // Front-end routine will do self cleanup for syncrounous notifications
            CmpCancelSlavePost(PostBlock,DelayedDeref);
            //
            // Do the same for the master (in case master and slave got switched)
            // This will avoid dereferencing the keybody from CmpPostApc
            CmpAddToDelayedDeref(PostBlock,DelayedDeref);
        }

        switch (PostBlockType(PostBlock)) {
            case PostSynchronous:
                //
                // This is a SYNC notify call.  There will be no user event,
                // and no user apc routine.  Quick exit here, just fill in
                // the Status and poke the event.
                //
                // Holder of the systemevent will wake up and free the
                // postblock.  If we free it here, we get a race & bugcheck.
                //
                // Set the flink to NULL so that the front side can tell this
                // has been removed if its wait aborts.
                //
                PostBlock->NotifyList.Flink = NULL;
                PostBlock->u->Sync.Status = Status;
                KeSetEvent(PostBlock->u->Sync.SystemEvent,
                           0,
                           FALSE);
#ifdef CM_NOTIFY_CHANGED_KCB_FULLPATH  
                //
                // store full qualified name into the post block private kernel buffer
                //
                CmpFillPostBlockBuffer(PostBlock,ChangedKcbName);
#endif //CM_NOTIFY_CHANGED_KCB_FULLPATH  

                break;

            case PostAsyncUser:

#ifdef CM_NOTIFY_CHANGED_KCB_FULLPATH  
                //
                // store full qualified name into the post block private kernel buffer
                //
                CmpFillPostBlockBuffer(PostBlock,ChangedKcbName);
#endif //CM_NOTIFY_CHANGED_KCB_FULLPATH  

                //
                // Insert the APC into the queue
                //
                KeInsertQueueApc(PostBlock->u->AsyncUser.Apc,
                                 (PVOID)ULongToPtr(Status),
                                 (PVOID)PostBlock,
                                 0);
                break;

            case PostAsyncKernel:
                //
                // Queue the work item, then free the post block.
                //
                if (PostBlock->u->AsyncKernel.WorkItem != NULL) {
                    ExQueueWorkItem(PostBlock->u->AsyncKernel.WorkItem,
                                    PostBlock->u->AsyncKernel.QueueType);
                }

#ifdef CM_NOTIFY_CHANGED_KCB_FULLPATH  
                //
                // fill the caller buffer (if any) - we only handle kernel mode adresses 
                //
                CmpFillCallerBuffer(PostBlock,ChangedKcbName);
#endif //CM_NOTIFY_CHANGED_KCB_FULLPATH  

                //
                // Signal Event if present, and deref it.
                //
                if (PostBlock->u->AsyncKernel.Event != NULL) {
                    KeSetEvent(PostBlock->u->AsyncKernel.Event,
                               0,
                               FALSE);
                    ObDereferenceObject(PostBlock->u->AsyncKernel.Event);
                }

				//
				// Multiple async kernel notification are not allowed
				//
				ASSERT(IsListEmpty(&(PostBlock->CancelPostList)) == TRUE);
				//
                // remove the post block from the thread list, and free it
                //
                // Use Cmp variant to protect for multiple deletion of the same object
                KeRaiseIrql(APC_LEVEL, &OldIrql);
                CmpRemoveEntryList(&(PostBlock->ThreadList));
                KeLowerIrql(OldIrql);
                
                // it was already added to delayed deref.
                CmpFreePostBlock(PostBlock);
                break;
        }
    }

    UNLOCK_POST_LIST();

    //
    // At this point we have a list of keybody elements that have to be dereferenciated
    // and the associated storage for the covering objects freed. The keybodies in this 
    // list have only one reference count on them (they were referenced only in 
    // NtNotifyChangeMultipleKeys), dereferencing them here should free the object
    //

    if( ARGUMENT_PRESENT(ExternalKeyDeref) ) {
        // do nothing; the caller wants to handle the dereferenciation by himself!
    } else {
        // dereferenciate all keybodies in the delayed list
        CmpDelayedDerefKeys(DelayedDeref);
    }
   
    return;
}


VOID
CmpPostApc(
    struct _KAPC *Apc,
    PKNORMAL_ROUTINE *NormalRoutine,
    PVOID *NormalContext,
    PVOID *SystemArgument1,
    PVOID *SystemArgument2
    )
/*++

Routine Description:

    This is the kernel apc routine.  It is called for all notifies,
    regardless of what form of notification the caller requested.

    We compute the postblock address from the apc object address.
    IoStatus is set.  SystemEvent and UserEvent will be signalled
    as appropriate.  If the user requested an APC, then NormalRoutine
    will be set at entry and executed when we exit.  The PostBlock
    is freed here.

Arguments:

    Apc - pointer to apc object

    NormalRoutine - Will be called when we return

    NormalContext - will be 1st argument to normal routine, ApcContext
                    passed in when NtNotifyChangeKey was called

    SystemArgument1 -  IN: Status value for IoStatusBlock
                      OUT: Ptr to IoStatusBlock (2nd arg to user apc routine)

    SystemArgument2 - Pointer to the PostBlock

Return Value:

    NONE.

--*/
{
    PCM_POST_BLOCK  PostBlock;

    PAGED_CODE();
    CmKdPrintEx((DPFLTR_CONFIG_ID,CML_NOTIFY,"CmpPostApc:\n"));
    CmKdPrintEx((DPFLTR_CONFIG_ID,CML_NOTIFY,"\tApc:%p ", Apc));
    CmKdPrintEx((DPFLTR_CONFIG_ID,CML_NOTIFY,"NormalRoutine:%p\n", NormalRoutine));
    CmKdPrintEx((DPFLTR_CONFIG_ID,CML_NOTIFY,"\tNormalContext:%08lx", NormalContext));
    CmKdPrintEx((DPFLTR_CONFIG_ID,CML_NOTIFY,"\tSystemArgument1=IoStatusBlock:%p\n", SystemArgument1));


    PostBlock = *(PCM_POST_BLOCK *)SystemArgument2;

#if DBG
    if(PostBlock->TraceIntoDebugger) {
        CmKdPrintEx((DPFLTR_CONFIG_ID,CML_NOTIFY,"[CM]CmpPostApc: PostBlock:%p\n", PostBlock));
    }
#endif

    
    //
    // Fill in IO Status Block
    //
    // IMPLEMENTATION NOTE:
    //      If we ever want to actually implement the code that returns
    //      names of things that changed, this is the place to copy the
    //      buffer into the caller's buffer.
    //
    //  Sundown only: Use a 32bit IO_STATUS_BLOCK if the caller is 32bit.

#ifdef CM_NOTIFY_CHANGED_KCB_FULLPATH  
    //
    // It looks like the time finally came :-)
    //
    CmpFillCallerBuffer(PostBlock,PostBlock->ChangedKcbFullName);
#endif //CM_NOTIFY_CHANGED_KCB_FULLPATH  
    
    try {
        CmpSetIoStatus(PostBlock->u->AsyncUser.IoStatusBlock, 
                       *((ULONG *)SystemArgument1), 
                       0L,
                       PsGetCurrentProcess()->Wow64Process != NULL);
    } except (EXCEPTION_EXECUTE_HANDLER) {
        NOTHING;
    }
    *SystemArgument1 = PostBlock->u->AsyncUser.IoStatusBlock;

    //
    // This is an Async notify, do all work here, including
    // cleaning up the post block
    //

    //
    // Signal UserEvent if present, and deref it.
    //
    if (PostBlock->u->AsyncUser.UserEvent != NULL) {
        KeSetEvent(PostBlock->u->AsyncUser.UserEvent,
                   0,
                   FALSE);
        ObDereferenceObject(PostBlock->u->AsyncUser.UserEvent);
    }

    //
    // remove the post block from the thread list, and free it
    //
    // Use Cmp variant to protect for multiple deletion of the same object
    CmpRemoveEntryList(&(PostBlock->ThreadList));

    // debug only checks
    CmpCheckPostBlock(PostBlock);
    //
	// Free the slave post block to avoid "dangling" postblocks
	//
	CmpFreeSlavePost(PostBlock);
    //
	// free this post block
	// 
	CmpFreePostBlock(PostBlock);

    return;
}


VOID
CmpPostApcRunDown(
    struct _KAPC *Apc
    )
/*++

Routine Description:

    This routine is called to clear away apcs in the apc queue
    of a thread that has been terminated.

    Since the apc is in the apc queue, we know that it is NOT in
    any NotifyBlock's post list.  It is, however, in the threads's
    PostBlockList.

    Therefore, poke any user events so that waiters are not stuck,
    drop the references so the event can be cleaned up, delist the
    PostBlock and free it.

    Since we are cleaning up the thread, SystemEvents are not interesting.

    Since the apc is in the apc queue, we know that if there were any other
    notifications related to this one, they are cleaned up by the
    CmPostNotify routine

Arguments:

    Apc - pointer to apc object

Return Value:

    NONE.

--*/
{
    PCM_POST_BLOCK  PostBlock;
    KIRQL           OldIrql;

    PAGED_CODE();
    CmKdPrintEx((DPFLTR_CONFIG_ID,CML_NOTIFY,"CmpApcRunDown:"));
    CmKdPrintEx((DPFLTR_CONFIG_ID,CML_NOTIFY,"\tApc:%p \n", Apc));

    KeRaiseIrql(APC_LEVEL, &OldIrql);

    PostBlock = (PCM_POST_BLOCK)Apc->SystemArgument2;

#if DBG
    if(PostBlock->TraceIntoDebugger) {
        CmKdPrintEx((DPFLTR_CONFIG_ID,CML_NOTIFY,"[CM]CmpPostApcRunDown: PostBlock:%p\n", PostBlock));
    }
#endif

    //
    // report status and wake up any threads that might otherwise
    // be stuck.  also drop any event references we hold
    //
    //  Sundown only: Use a 32bit IO_STATUS_BLOCK if the caller is 32bit. 

    try {
        CmpSetIoStatus(PostBlock->u->AsyncUser.IoStatusBlock, 
                       STATUS_NOTIFY_CLEANUP, 
                       0L, 
                       PsGetCurrentProcess()->Wow64Process != NULL);
    } except (EXCEPTION_EXECUTE_HANDLER) {
        NOTHING;
    }

    if (PostBlock->u->AsyncUser.UserEvent != NULL) {
        KeSetEvent(
            PostBlock->u->AsyncUser.UserEvent,
            0,
            FALSE
            );
        ObDereferenceObject(PostBlock->u->AsyncUser.UserEvent);
    }

    //
    // delist the post block
    //
    // Use Cmp variant to protect for multiple deletion of the same object
    CmpRemoveEntryList(&(PostBlock->ThreadList));

	//
	// Free the slave post block to avoid "dangling" postblocks
	//
	CmpFreeSlavePost(PostBlock);
    //
    // Free the post block.  Use Ex call because PostBlocks are NOT
    // part of the global registry pool computation, but are instead
    // part of NonPagedPool with Quota.
    //
    CmpFreePostBlock(PostBlock);

    KeLowerIrql(OldIrql);

    return;
}


//
// Cleanup procedure
//
VOID
CmNotifyRunDown(
    PETHREAD    Thread
    )
/*++

Routine Description:

    This routine is called from PspExitThread to clean up any pending
    notify requests.

    It will traverse the thread's PostBlockList, for each PostBlock it
    finds, it will:

        1.  Remove it from the relevent NotifyBlock.  This requires
            that we hold the Registry mutex.

        2.  Remove it from the thread's PostBlockList.  This requires
            that we run at APC level.

        3.  By the time this procedure runs, user apcs are not interesting
            and neither are SystemEvents, so do not bother processing
            them.

            UserEvents and IoStatusBlocks could be refered to by other
            threads in the same process, or even a different process,
            so process them so those threads know what happened, use
            status code of STATUS_NOTIFY_CLEANUP.

            If the notify is a master one, cancel all slave notifications.
            Else only remove this notification from the master CancelPortList

        4.  Free the post block.

Arguments:

    Thread - pointer to the executive thread object for the thread
             we wish to do rundown on.

Return Value:

    NONE.

--*/
{
    PCM_POST_BLOCK      PostBlock;
    PCM_NOTIFY_BLOCK    NotifyBlock;
    KIRQL               OldIrql;

    PAGED_CODE();

    if ( IsListEmpty(&(Thread->PostBlockList)) == TRUE ) {
        return;
    }

    CmKdPrintEx((DPFLTR_CONFIG_ID,CML_FLOW,"CmNotifyRunDown: ethread:%p\n", Thread));

    CmpLockRegistryExclusive();

	//
    // Aquire exclusive access over the postlist(s)
    //
    // This is not needed (see the rule above)
    //LOCK_POST_LIST(); 

    KeRaiseIrql(APC_LEVEL, &OldIrql);
    while (IsListEmpty(&(Thread->PostBlockList)) == FALSE) {

        //
        // remove from thread list
        //
        PostBlock = (PCM_POST_BLOCK)RemoveHeadList(&(Thread->PostBlockList));
        PostBlock = CONTAINING_RECORD(
                        PostBlock,
                        CM_POST_BLOCK,
                        ThreadList
                        );

        // Protect for multiple deletion of the same object
        CmpClearListEntry(&(PostBlock->ThreadList));

#if DBG
        if(PostBlock->TraceIntoDebugger) {
            CmKdPrintEx((DPFLTR_CONFIG_ID,CML_FLOW,"[CM]CmpNotifyRunDown: ethread:%p, PostBlock:%p\n", Thread,PostBlock));
        }
#endif

        //
        // Canceling a master notification implies canceling all the slave notifications
        // from the CancelPostList
        //
        if(IsMasterPostBlock(PostBlock)) {

#if DBG
            if(PostBlock->TraceIntoDebugger) {
                    CmKdPrintEx((DPFLTR_CONFIG_ID,CML_FLOW,"[CM]\tCmpNotifyRunDown: PostBlock:%p is a master block\n", PostBlock));
            }
#endif
            //
            // at this point, CmpReportNotify and friends will no longer
            // attempt to post this post block.
            //
            if (PostBlockType(PostBlock) == PostAsyncUser) {
                //
                // report status and wake up any threads that might otherwise
                // be stuck.  also drop any event references we hold
                //
                //  Sundown only: Use a 32bit IO_STATUS_BLOCK if the caller is 32bit. 

                try {
                    CmpSetIoStatus(PostBlock->u->AsyncUser.IoStatusBlock, 
                                   STATUS_NOTIFY_CLEANUP, 
                                   0L, 
                                   PsGetCurrentProcess()->Wow64Process != NULL);
                } except (EXCEPTION_EXECUTE_HANDLER) {
                    CmKdPrintEx((DPFLTR_CONFIG_ID,CML_EXCEPTION,"!!CmNotifyRundown: code:%08lx\n", GetExceptionCode()));
                    NOTHING;
                }

                if (PostBlock->u->AsyncUser.UserEvent != NULL) {
                    KeSetEvent(
                        PostBlock->u->AsyncUser.UserEvent,
                        0,
                        FALSE
                        );
                    ObDereferenceObject(PostBlock->u->AsyncUser.UserEvent);
                }

                //
                // Cancel the APC. Otherwise the rundown routine will also
                // free the post block if the APC happens to be queued at
                // this point. If the APC is queued, then the post block has
                // already been removed from the notify list, so don't remove
                // it again.
                //
                if (!KeRemoveQueueApc(PostBlock->u->AsyncUser.Apc)) {

                    //
                    // remove from notify block's list
                    //
                    // Use Cmp variant to protect for multiple deletion of the same object
                    CmpRemoveEntryList(&(PostBlock->NotifyList));
                    //
                    // Cancel all slave Post requests that may be linked to self
                    //
                    CmpCancelSlavePost(PostBlock,NULL); // we do not want delayed deref
                } else {
                    //
                    // if we are here, the apc was in the apc queue, i.e. both master and slave 
                    // post blocks were removed from the notify list. nothing more to do.
                    //
                    ASSERT( CmpIsListEmpty(&(PostBlock->NotifyList)) );
                    NOTHING;
                }
            } else {
                //
                // remove from notify block's list
                //
                // Use Cmp variant to protect for multiple deletion of the same object
                CmpRemoveEntryList(&(PostBlock->NotifyList));
                //
                // Cancel all slave Post requests that may be linked to self
                //
                CmpCancelSlavePost(PostBlock,NULL); // we do not want delayed deref
            }

			//
			// Free the slave Post blocks too
			//
			CmpFreeSlavePost(PostBlock);
            //
            // Free the post block.  Use Ex call because PostBlocks are NOT
            // part of the global registry pool computation, but are instead
            // part of NonPagedPool with Quota.
            //
            CmpFreePostBlock(PostBlock);
        } else {

#if DBG
            if(PostBlock->TraceIntoDebugger) {
                CmKdPrintEx((DPFLTR_CONFIG_ID,CML_FLOW,"[CM]\tCmpNotifyRunDown: PostBlock:%p is a slave block\n", PostBlock));
            }
#endif
            //
            // master should always be ahead of slaves; if we got here, we switched master
            // and slaves back in CmpPostNotify; Show some respect and add slave at the end;
            // master will control the cleanup
            //
            ASSERT( CmpIsListEmpty(&(PostBlock->CancelPostList)) == FALSE );
            ASSERT( IsListEmpty(&(Thread->PostBlockList)) == FALSE );
                       
            InsertTailList(
                &(Thread->PostBlockList),
                &(PostBlock->ThreadList)
                );
        }
    }

    KeLowerIrql(OldIrql);

    // This is not needed (see the rule above)
    //UNLOCK_POST_LIST();

    CmpUnlockRegistry();
    return;
}


VOID
CmpFlushNotify(
    PCM_KEY_BODY        KeyBody
    )
/*++

Routine Description:

    Clean up notifyblock when a handle is closed or the key it refers
    to is deleted.

Arguments:

    KeyBody - supplies pointer to key object body for handle we
                are cleaning up.

Return Value:

    NONE

--*/
{
    PCM_NOTIFY_BLOCK    NotifyBlock;
    PCMHIVE             Hive;

    PAGED_CODE();
    ASSERT_CM_LOCK_OWNED();

    if (KeyBody->NotifyBlock == NULL) {
        return;
    }

    ASSERT( KeyBody->KeyControlBlock->Delete == FALSE );

    //
    // Lock the hive exclusively to prevent multiple threads from whacking
    // on the list.
    //
    Hive = CONTAINING_RECORD(KeyBody->KeyControlBlock->KeyHive,
                             CMHIVE,
                             Hive);
    CmLockHive(Hive);
    //
    // Reread the notify block in case it has already been freed.
    //
    NotifyBlock = KeyBody->NotifyBlock;
    if (NotifyBlock == NULL) {
        CmUnlockHive(Hive);
        return;
    }

    //
    // Clean up all PostBlocks waiting on the NotifyBlock
    //
    if (IsListEmpty(&(NotifyBlock->PostList)) == FALSE) {
        CmpPostNotify(
            NotifyBlock,
            NULL,
            0,
            STATUS_NOTIFY_CLEANUP,
            NULL
#ifdef CM_NOTIFY_CHANGED_KCB_FULLPATH  
            ,
            NULL
#endif //CM_NOTIFY_CHANGED_KCB_FULLPATH  
            );
    }

    //
    // Release the subject context
    //
    SeReleaseSubjectContext(&NotifyBlock->SubjectContext);

    //
    // IMPLEMENTATION NOTE:
    //      If we ever do code to report names and types of events,
    //      this is the place to free the buffer.
    //

    //
    // Remove the NotifyBlock from the hive chain
    //
    NotifyBlock->HiveList.Blink->Flink = NotifyBlock->HiveList.Flink;
    if (NotifyBlock->HiveList.Flink != NULL) {
        NotifyBlock->HiveList.Flink->Blink = NotifyBlock->HiveList.Blink;
    }

    // Protect for multiple deletion of the same object
    CmpClearListEntry(&(NotifyBlock->HiveList));

    KeyBody->NotifyBlock = NULL;

#ifdef CMP_ENTRYLIST_MANIPULATION
    if (IsListEmpty(&(NotifyBlock->PostList)) == FALSE) {
        DbgPrintEx(DPFLTR_CONFIG_ID,DPFLTR_ERROR_LEVEL,"CmpFlushNotify: NotifyBlock %08lx\n",NotifyBlock);
        DbgBreakPoint();
    }
    //check is the notify has been deleted from the hive notify list
    {
        PCM_NOTIFY_BLOCK ValidNotifyBlock;
        PLIST_ENTRY NotifyPtr;

        NotifyPtr = &(Hive->NotifyList);

        while (NotifyPtr->Flink != NULL) {
            NotifyPtr = NotifyPtr->Flink;

            ValidNotifyBlock = CONTAINING_RECORD(NotifyPtr, CM_NOTIFY_BLOCK, HiveList);
            if( ValidNotifyBlock == NotifyBlock ) {
                DbgPrintEx(DPFLTR_CONFIG_ID,DPFLTR_ERROR_LEVEL,"CmpFlushNotify: NotifyBlock %08lx is about to be deleted but is still in the hive notify list\n",NotifyBlock);
                DbgBreakPoint();
            }
        }
    }
    RtlZeroMemory((PVOID)NotifyBlock, sizeof(CM_NOTIFY_BLOCK));
#endif
    
    CmUnlockHive(Hive);

    //
    // Free the block, clean up the KeyBody
    //
    ExFreePool(NotifyBlock);
    return;
}


//
// "Front Side" of notify.  See also Ntapi.c: ntnotifychangekey
//
NTSTATUS
CmpNotifyChangeKey(
    IN PCM_KEY_BODY     KeyBody,
    IN PCM_POST_BLOCK   PostBlock,
    IN ULONG            CompletionFilter,
    IN BOOLEAN          WatchTree,
    IN PVOID            Buffer,
    IN ULONG            BufferSize,
    IN PCM_POST_BLOCK   MasterPostBlock
    )
/*++

Routine Description:

    This routine sets up the NotifyBlock, and attaches the PostBlock
    to it.  When it returns, the Notify is visible to the system,
    and will receive event reports.

    If there is already an event report pending, then the notify
    call will be satisified at once.

Arguments:

    KeyBody - pointer to key object that handle refers to, allows access
              to key control block, notify block, etc.

    PostBlock - pointer to structure that describes how/where the caller
                is to be notified.

                WARNING:    PostBlock must come from Pool, THIS routine
                            will keep it, back side will free it.  This
                            routine WILL free it in case of error.

    CompletionFilter - what types of events the caller wants to see

    WatchTree - TRUE to watch whole subtree, FALSE to watch only immediate
                key the notify is applied to

    Buffer - pointer to area to recieve notify data

    BufferSize - size of buffer, also size user would like to allocate
                 for internal buffer

    MasterPostBlock - the post block of the master notification. Used to
                      insert the PostBlock into the CancelPostList list.

Return Value:

    Status.

--*/
{
    PCM_NOTIFY_BLOCK    NotifyBlock;
    PCM_NOTIFY_BLOCK    node;
    PLIST_ENTRY         ptr;
    PCMHIVE             Hive;
    KIRQL               OldIrql;

    PAGED_CODE();
    CmKdPrintEx((DPFLTR_CONFIG_ID,CML_NOTIFY,"CmpNotifyChangeKey:\n"));
    CmKdPrintEx((DPFLTR_CONFIG_ID,CML_NOTIFY,"\tKeyBody:%p PostBlock:%p ", KeyBody, PostBlock));
    CmKdPrintEx((DPFLTR_CONFIG_ID,CML_NOTIFY,"Filter:%08lx WatchTree:%08lx\n", CompletionFilter, WatchTree));

    //
    // The registry lock should be aquired exclusively by the caller !!!
    //
    ASSERT_CM_LOCK_OWNED_EXCLUSIVE();

    if (KeyBody->KeyControlBlock->Delete) {
        ASSERT( KeyBody->NotifyBlock == NULL );
        CmpFreePostBlock(PostBlock);
        return STATUS_KEY_DELETED;
    }

#if DBG
    if(PostBlock->TraceIntoDebugger) {
        WCHAR                   *NameBuffer = NULL;
        UNICODE_STRING          KeyName;
        PCM_KEY_NODE            TempNode;

        CmKdPrintEx((DPFLTR_CONFIG_ID,CML_NOTIFY,"[CM]CmpNotifyChangeKey: PostBlock:%p\tMasterBlock: %p\n", PostBlock,MasterPostBlock));
        
        TempNode = (PCM_KEY_NODE)HvGetCell(KeyBody->KeyControlBlock->KeyHive, KeyBody->KeyControlBlock->KeyCell);
        if( TempNode != NULL ) {
            NameBuffer = ExAllocatePool(PagedPool, REG_MAX_KEY_NAME_LENGTH);
            if(NameBuffer&& (KeyBody->KeyControlBlock->KeyCell != HCELL_NIL)) {
               CmpInitializeKeyNameString(TempNode,&KeyName,NameBuffer);
               CmKdPrintEx((DPFLTR_CONFIG_ID,CML_NOTIFY,"\t[CM]CmpNotifyChangeKey: Key = %.*S\n",KeyName.Length / sizeof(WCHAR),KeyName.Buffer));
               ExFreePool(NameBuffer);
            }
            HvReleaseCell(KeyBody->KeyControlBlock->KeyHive, KeyBody->KeyControlBlock->KeyCell);
        }
    }
#endif

    Hive = (PCMHIVE)KeyBody->KeyControlBlock->KeyHive;
    Hive = CONTAINING_RECORD(Hive, CMHIVE, Hive);
    NotifyBlock = KeyBody->NotifyBlock;

    if (NotifyBlock == NULL) {
        //
        // Set up new notify session
        //
        NotifyBlock = ExAllocatePoolWithQuotaTag(PagedPool|POOL_QUOTA_FAIL_INSTEAD_OF_RAISE,sizeof(CM_NOTIFY_BLOCK),CM_NOTIFYBLOCK_TAG);
        CmKdPrintEx((DPFLTR_CONFIG_ID,CML_POOL,"**CmpNotifyChangeKey: allocate:%08lx, ", sizeof(CM_NOTIFY_BLOCK)));
        CmKdPrintEx((DPFLTR_CONFIG_ID,CML_POOL,"type:%d, at:%p\n", PagedPool, NotifyBlock));

        if (NotifyBlock == NULL) {
            CmpFreePostBlock(PostBlock);
            return STATUS_INSUFFICIENT_RESOURCES;
        }
        NotifyBlock->KeyControlBlock = KeyBody->KeyControlBlock;
        NotifyBlock->Filter = CompletionFilter;
        NotifyBlock->WatchTree = WatchTree;
        NotifyBlock->NotifyPending = FALSE;
        InitializeListHead(&(NotifyBlock->PostList));
        KeyBody->NotifyBlock = NotifyBlock;
        NotifyBlock->KeyBody = KeyBody;
        ASSERT( KeyBody->KeyControlBlock->Delete == FALSE );

#if DBG
        if(PostBlock->TraceIntoDebugger) {
            WCHAR                   *NameBuffer = NULL;
            UNICODE_STRING          KeyName;
            PCM_KEY_NODE            TempNode;

            TempNode = (PCM_KEY_NODE)HvGetCell(KeyBody->KeyControlBlock->KeyHive, KeyBody->KeyControlBlock->KeyCell);
            if( TempNode != NULL ) {
                NameBuffer = ExAllocatePool(PagedPool, REG_MAX_KEY_NAME_LENGTH);
                if(NameBuffer) {
                   CmpInitializeKeyNameString(TempNode,&KeyName,NameBuffer);
                   CmKdPrintEx((DPFLTR_CONFIG_ID,CML_NOTIFY,"[CM]\tCmpNotifyChangeKey: New NotifyBlock at:%p was allocated for Key = %.*S\n",NotifyBlock,KeyName.Length / sizeof(WCHAR),KeyName.Buffer));
                   ExFreePool(NameBuffer);
                }
                HvReleaseCell(KeyBody->KeyControlBlock->KeyHive, KeyBody->KeyControlBlock->KeyCell);
            }
        }
#endif

        //
        // IMPLEMENTATION NOTE:
        //      If we ever want to actually return the buffers full of
        //      data, the buffer should be allocated and its address
        //      stored in the notify block here.
        //

        //
        // Capture the subject context so we can do checking once the
        // notify goes off.
        //
        SeCaptureSubjectContext(&NotifyBlock->SubjectContext);

        //
        // Attach notify block to hive in properly sorted order
        //
        ptr = &(Hive->NotifyList);
        while (TRUE) {
            if (ptr->Flink == NULL) {
                //
                // End of list, add self after ptr.
                //
                ptr->Flink = &(NotifyBlock->HiveList);
                NotifyBlock->HiveList.Flink = NULL;
                NotifyBlock->HiveList.Blink = ptr;
                break;
            }

            ptr = ptr->Flink;

            node = CONTAINING_RECORD(ptr, CM_NOTIFY_BLOCK, HiveList);

            if (node->KeyControlBlock->TotalLevels >
                KeyBody->KeyControlBlock->TotalLevels)
            {
                //
                // ptr -> notify with longer name than us, insert in FRONT
                //
                NotifyBlock->HiveList.Flink = ptr;
                ptr->Blink->Flink = &(NotifyBlock->HiveList);
                NotifyBlock->HiveList.Blink = ptr->Blink;
                ptr->Blink = &(NotifyBlock->HiveList);
                break;
            }
        }
    }


    //
    // Add post block to front of notify block's list, and add it to thread list.
    //
    InsertHeadList(
        &(NotifyBlock->PostList),
        &(PostBlock->NotifyList)
        );



    if( IsMasterPostBlock(PostBlock) ) {
        //
        // Protect against outrageous calls
        //
        ASSERT(PostBlock == MasterPostBlock);

        //
        // When the notification is a master one, initialize the CancelPostList list
        //
        InitializeListHead(&(PostBlock->CancelPostList));
    } else {
        //
        // Add PostBlock at the end of the CancelPostList list from the master post
        //
        InsertTailList(
            &(MasterPostBlock->CancelPostList),
            &(PostBlock->CancelPostList)
            );
    }


    KeRaiseIrql(APC_LEVEL, &OldIrql);
    //
    // show some respect and add masters to the front and slaves to the tail
    //
    if( IsMasterPostBlock(PostBlock) ) {
        InsertHeadList(
            &(PsGetCurrentThread()->PostBlockList),
            &(PostBlock->ThreadList)
            );
    } else {
        InsertTailList(
            &(PsGetCurrentThread()->PostBlockList),
            &(PostBlock->ThreadList)
            );
    }

#if DBG
    if(PostBlock->TraceIntoDebugger) {
        CmKdPrintEx((DPFLTR_CONFIG_ID,CML_NOTIFY,"[CM]\tCmpNotifyChangeKey: Attaching the post:%p\t to thread:%p\n",PostBlock,PsGetCurrentThread()));
    }
#endif

    KeLowerIrql(OldIrql);

    //
    // If there is a notify pending (will not be if we just created
    // the notify block) then post it at once.  Note that this call
    // ALWAYS returns STATUS_PENDING unless it fails.  Caller must
    // ALWAYS look in IoStatusBlock to see what happened.
    //
    if (NotifyBlock->NotifyPending == TRUE) {

#ifdef CM_NOTIFY_CHANGED_KCB_FULLPATH  
        PUNICODE_STRING FullKcbName = CmpConstructName(KeyBody->KeyControlBlock);
#endif //CM_NOTIFY_CHANGED_KCB_FULLPATH  

        CmpPostNotify(
            NotifyBlock,
            NULL,
            0,
            STATUS_NOTIFY_ENUM_DIR,
            NULL
#ifdef CM_NOTIFY_CHANGED_KCB_FULLPATH  
            ,
            FullKcbName
#endif //CM_NOTIFY_CHANGED_KCB_FULLPATH  
            );

#ifdef CM_NOTIFY_CHANGED_KCB_FULLPATH  
        if( FullKcbName != NULL ) {
            ExFreePoolWithTag(FullKcbName, CM_NAME_TAG | PROTECTED_POOL);
        }
#endif //CM_NOTIFY_CHANGED_KCB_FULLPATH  

        //
        // return STATUS_SUCCESS to signal to the caller the the notify already been triggered
        //
        return STATUS_SUCCESS;
    }

    //
    // return STATUS_PENDING to signal to the caller the the notify has not been triggered yet
    //
    return STATUS_PENDING;
}

VOID
CmpFreeSlavePost(
    PCM_POST_BLOCK  MasterPostBlock
    )
/*++

Routine Description:

	Free the slave post block related to this master post block

Arguments:

    MasterPostBlock - pointer to structure that describes the post requests.
                It should be a master post!!
Return Value:

    NONE.

--*/
{
    PCM_POST_BLOCK  SlavePostBlock;

    PAGED_CODE();
    CmKdPrintEx((DPFLTR_CONFIG_ID,CML_NOTIFY,"CmpCancelSlavePost:\t"));
    CmKdPrintEx((DPFLTR_CONFIG_ID,CML_NOTIFY,"MasterPostBlock:%p\n", MasterPostBlock));

    ASSERT(IsMasterPostBlock(MasterPostBlock));

#if DBG
    if(MasterPostBlock->TraceIntoDebugger) {
        CmKdPrintEx((DPFLTR_CONFIG_ID,CML_NOTIFY,"[CM]CmCancelSlavePost: MasterPostBlock:%p\n", MasterPostBlock));
    }
#endif

    if (IsListEmpty(&(MasterPostBlock->CancelPostList)) == TRUE) {
        //
        // Nothing to cancel, just return
        //
#if DBG
        if(MasterPostBlock->TraceIntoDebugger) {
            CmKdPrintEx((DPFLTR_CONFIG_ID,CML_NOTIFY,"[CM]CmCancelSlavePost: MasterPostBlock:%p has no slaves\n", MasterPostBlock));
        }
#endif

        return;
    }


    //
    // Pull all the entries in the cancel post list and unlink them (when they are slave requests)
    // We base here on the assumption that there is only one slave.
    //
    //     NOTE!!!
    //       When more than slave allowed, here to modify
    //


    SlavePostBlock = (PCM_POST_BLOCK)MasterPostBlock->CancelPostList.Flink;
    SlavePostBlock = CONTAINING_RECORD(SlavePostBlock,
                                       CM_POST_BLOCK,
                                       CancelPostList);

#if DBG
    if(MasterPostBlock->TraceIntoDebugger) {
        CmKdPrintEx((DPFLTR_CONFIG_ID,CML_NOTIFY,"[CM]CmCancelSlavePost: Cleaning SlavePostBlock:%p\n", SlavePostBlock));
    }
#endif

    //
    // This should be true !
    //
    ASSERT( !IsMasterPostBlock(SlavePostBlock) );

    //
    // Unchain from the Master CancelPostList
    //
    // Use Cmp variant to protect for multiple deletion of the same object
    CmpRemoveEntryList(&(SlavePostBlock->CancelPostList));

    //
    // delist the post block from the thread postblocklist
    //
    // Use Cmp variant to protect for multiple deletion of the same object
    CmpRemoveEntryList(&(SlavePostBlock->ThreadList));

    //
    // Free the post block.
    //
    CmpFreePostBlock(SlavePostBlock);

    //
    // Result validation. was it the only slave?
    //
    ASSERT(IsListEmpty(&(MasterPostBlock->CancelPostList)));
}

VOID
CmpCancelSlavePost(
    PCM_POST_BLOCK  MasterPostBlock,
    PLIST_ENTRY     DelayedDeref
    )
/*++

Routine Description:

	Unlink the slave postblock from its notify list and dereferences (or adds to the delayed deref list)
	the keybody related to this thread. This should disable the slave post block. 
	It will be cleared later in CmpPostApc.

Arguments:

    MasterPostBlock - pointer to structure that describes the post requests.
                It should be a master post!!
    DelayedDeref - pointer to list of delayed deref keybodies. If this parameter is not NULL,
                the keybody for the slave is not cleared before calling CmpFreePostBlock, 
                and instead is added to the list


Return Value:

    NONE.

--*/
{
    PCM_POST_BLOCK  SlavePostBlock;

    PAGED_CODE();
    CmKdPrintEx((DPFLTR_CONFIG_ID,CML_NOTIFY,"CmpCancelSlavePost:\t"));
    CmKdPrintEx((DPFLTR_CONFIG_ID,CML_NOTIFY,"MasterPostBlock:%p\n", MasterPostBlock));

    ASSERT_CM_LOCK_OWNED();

    ASSERT(IsMasterPostBlock(MasterPostBlock));

#if DBG
    if(MasterPostBlock->TraceIntoDebugger) {
        CmKdPrintEx((DPFLTR_CONFIG_ID,CML_NOTIFY,"[CM]CmCancelSlavePost: MasterPostBlock:%p\n", MasterPostBlock));
    }
#endif

    if (IsListEmpty(&(MasterPostBlock->CancelPostList)) == TRUE) {
        //
        // Nothing to cancel, just return
        //
#if DBG
        if(MasterPostBlock->TraceIntoDebugger) {
            CmKdPrintEx((DPFLTR_CONFIG_ID,CML_NOTIFY,"[CM]CmCancelSlavePost: MasterPostBlock:%p has no slaves\n", MasterPostBlock));
        }
#endif

        return;
    }


    //
    // Pull all the entries in the cancel post list and unlink them (when they are slave requests)
    // We base here on the assumption that there is only one slave.
    //
    //     NOTE!!!
    //       When more than slave allowed, here to modify
    //


    SlavePostBlock = (PCM_POST_BLOCK)MasterPostBlock->CancelPostList.Flink;
    SlavePostBlock = CONTAINING_RECORD(SlavePostBlock,
                                       CM_POST_BLOCK,
                                       CancelPostList);

#if DBG
    if(MasterPostBlock->TraceIntoDebugger) {
        CmKdPrintEx((DPFLTR_CONFIG_ID,CML_NOTIFY,"[CM]CmCancelSlavePost: Cleaning SlavePostBlock:%p\n", SlavePostBlock));
    }
#endif

    //
    // This should be true !
    //
    ASSERT( !IsMasterPostBlock(SlavePostBlock) );

    //
    // Remove it from notify block's list
    //
    // Use Cmp variant to protect for multiple deletion of the same object
	// This will disable the notifications that might come on the slave key
	//
    CmpRemoveEntryList(&(SlavePostBlock->NotifyList));

    if( DelayedDeref ) {
        // 
        // the caller wants to handle key body dereferenciation by himself
        //
        CmpAddToDelayedDeref(SlavePostBlock,DelayedDeref);
    }
}

VOID
CmpAddToDelayedDeref(
    PCM_POST_BLOCK  PostBlock,
    PLIST_ENTRY     DelayedDeref
    )
/*++

Routine Description:

    Add the key body attached to the post block to the delayed deref list.
    Cleans the post block KeyBody member, so it will not be dereferenced 
    when the post block is freed.

Arguments:

    PostBlock - pointer to structure that describes the post requests.

    DelayedDeref - the delayed deref list

Return Value:

    NONE.

--*/

{
    PAGED_CODE();

    // common sense
    ASSERT( PostBlock != NULL );

    if( PostBlock->PostKeyBody ) {
        //
        // If the post block has a keybody attached, add it to delayed deref list and 
        // clear the post block member. The key body will be deref'd prior after 
        // postblock lock is released.
        //
    
        // extra validation
        ASSERT(PostBlock->PostKeyBody->KeyBody != NULL);
        ASSERT(DelayedDeref);

        // add it to the end of the list
        InsertTailList(
            DelayedDeref,
            &(PostBlock->PostKeyBody->KeyBodyList)
            );
    
        // make sure we don't deref it in CmpFreePostBlock
        PostBlock->PostKeyBody = NULL;
    }

    return;
}

VOID
CmpDelayedDerefKeys(
                    PLIST_ENTRY DelayedDeref
                    )
/*++

Routine Description:

    Walk through the entire list, dereference each keybody and free storage for the 
    CM_POST_KEY_BODY allocated for this purpose.

Arguments:

    DelayedDeref - the delayed deref list

Return Value:

    NONE.

--*/
{
    PCM_POST_KEY_BODY   PostKeyBody;

    PAGED_CODE();

    // common sense
    ASSERT( DelayedDeref != NULL );

    while(IsListEmpty(DelayedDeref) == FALSE) {
        //
        // Remove from the delayed deref list and deref the coresponding keybody
        // free the storage associated with CM_POST_KEY_BODY
        //
        PostKeyBody = (PCM_POST_KEY_BODY)RemoveHeadList(DelayedDeref);
        PostKeyBody = CONTAINING_RECORD(PostKeyBody,
                                      CM_POST_KEY_BODY,
                                      KeyBodyList);

        // extra validation
        ASSERT(PostKeyBody->KeyBody != NULL);
        // this should be a valid key body
        ASSERT(PostKeyBody->KeyBody->Type == KEY_BODY_TYPE);
        
        // at last ..... dereference the key object
        ObDereferenceObject(PostKeyBody->KeyBody);

        // Free the storage for the CM_POST_KEY_BODY object (allocated by CmpAllocatePostBlock)
        ExFreePool(PostKeyBody);
    }
}

#ifdef CM_NOTIFY_CHANGED_KCB_FULLPATH  

VOID
CmpFillCallerBuffer(
                    PCM_POST_BLOCK  PostBlock,
                    PUNICODE_STRING ChangedKcbName
                    )
/*++

Routine Description:

    Copies the full qualified name of the changed kcb to the 
    caller buffer (stored in the postblock). 

Arguments:

    PostBlock - post block holding the user buffer address and size
    
    ChangedKcbName - unicode string holding the full qualified path of the kcb
        - this may be null


Return Value:

    NONE.

--*/
{
    USHORT              RequestedSize;
    USHORT              Length;
    PUNICODE_STRING     CallerUnicode;
    
    PAGED_CODE();

    if( PostBlock->CallerBuffer == NULL ) {
        //
        // nothing to do; the caller didn't request this info.
        //
        return;
    }
    
    //
    // compute the requested size for the caller buffer
    //
    RequestedSize = sizeof(UNICODE_STRING);
    
    if( PostBlock->CallerBufferSize < RequestedSize ) {
        //
        // bad luck!; not enough space- not even for an empty unicode string
        //
        return;
    }

    if(ChangedKcbName != NULL) {
        Length = ChangedKcbName->Length;
    } else {
        Length = 0;
    }
    RequestedSize += Length;

    //
    // fill up the caller buffer
    //
    try {
        CallerUnicode = (PUNICODE_STRING)PostBlock->CallerBuffer;
        CallerUnicode->Buffer = (USHORT *) ((ULONG_PTR) CallerUnicode + sizeof(UNICODE_STRING));
        CallerUnicode->MaximumLength = (USHORT)(PostBlock->CallerBufferSize - sizeof(UNICODE_STRING));
        if( CallerUnicode->MaximumLength < Length ) {
            Length = CallerUnicode->MaximumLength;
        }
            
        //
        // copy the actual data
        //
        if( Length > 0 ) {
            ASSERT( ChangedKcbName != NULL );
            RtlCopyMemory(CallerUnicode->Buffer,ChangedKcbName->Buffer,Length);
        }

        CallerUnicode->Length = Length;
        
    } except (EXCEPTION_EXECUTE_HANDLER) {
        NOTHING;
    }

}

VOID
CmpFillPostBlockBuffer(
                    PCM_POST_BLOCK  PostBlock,
                    PUNICODE_STRING ChangedKcbName  OPTIONAL
                    )
/*++

Routine Description:

    Copies the full qualified name of the changed kcb to the 
    postblock private kernel buffer

Arguments:

    PostBlock - post block in question
    
    ChangedKcbName - unicode string holding the full qualified path of the kcb
        - this may be null


Return Value:

    NONE.

--*/
{
    PUNICODE_STRING FullName;
    USHORT          Size;
    
    PAGED_CODE();

    //
    // we only store this info in masters (or promoted)
    //
    ASSERT( IsMasterPostBlock(PostBlock) );

    //
    // copy the kcb name (if any) into the postblock kernel mode buffer
    //
    if( ARGUMENT_PRESENT(ChangedKcbName) && //  we have a kcb name
        (PostBlock->CallerBuffer != NULL)   //  and the user requested for the info.  
        ) {
       
        Size = sizeof(UNICODE_STRING) + ChangedKcbName->Length;

        //
        // allocate a kernel buffer to store the name; it'll be freed in CmpFreePostBlock
        //
        FullName = (PUNICODE_STRING) ExAllocatePoolWithTag(PagedPool,Size,CM_FIND_LEAK_TAG43);

        if (FullName) {
            FullName->Buffer = (USHORT *) ((ULONG_PTR) FullName + sizeof(UNICODE_STRING));
            FullName->Length = ChangedKcbName->Length;
            FullName->MaximumLength = ChangedKcbName->Length;
            RtlCopyMemory(FullName->Buffer,ChangedKcbName->Buffer,FullName->Length);
            PostBlock->ChangedKcbFullName = FullName;
        }
        
        //
        // we successfully stored the full kcb name into the post block
        // the apc (or the sync side of the notification will take care 
        // of transfering it to the caller buffer
        //
    }

}

#endif //CM_NOTIFY_CHANGED_KCB_FULLPATH
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\base\ntos\config\cmp.h ===
/*++

Copyright (c) 1991  Microsoft Corporation

Module Name:

    cmp.h

Abstract:

    This module contains the private (internal) header file for the
    configuration manager.

Author:

    Bryan M. Willman (bryanwi) 10-Sep-91

Environment:

    Kernel mode only.

Revision History:

    13-Jan-99 Dragos C. Sambotin (dragoss) - factoring the data structure declarations
        in \nt\private\ntos\inc\cmdata.h :: to be available from outside.
--*/

#ifndef _CMP_
#define _CMP_

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Begin SCS (Switch Control Section)
//
// 1. Code to check consistency and to help catch bugs: To be turned on when problems
// appear in that area; Word of caution: some of these switches may affect performance
//
#if DBG

#define CMP_NOTIFY_POSTBLOCK_CHECK      // controls the CmpCheckPostBlock macro, used to check
                                        // validity and consistency of a notify post block


#define CMP_ENTRYLIST_MANIPULATION      // controls the removal of an element from a LIST_ENTRY
                                        // by setting the Blink and Flink to NULL;
                                        // macros affected : IsListEmpty and RemoveEmptyList
                                        // WARNING : to be defined only when not linking against the loader

#define CMP_KCB_CACHE_VALIDATION        // validates KCB cached members changes by comparing against the knode values.
                                        // We shall disable this after proven the caching mechanism works OK

//#define CMP_CMVIEW_VALIDATION           // validates the view mapping mechanism

#define CHECK_REGISTRY_USECOUNT         // Validates the GetCell/ReleaseCell call matching, to ensure mapped views
                                        // don't get unmapped while in use

//#define SYNC_HIVE_VALIDATION            // validate the HvpDoWriteHive paged dirty data algorithm
                                        // We shall disable this after we catch saving alternate problem

//#define HIVE_SECURITY_STATS             // collect statistics about security cells

//#define CMP_STATS                       // collect statistics about kcbs

//#define WRITE_PROTECTED_REGISTRY_POOL   // applies only for registry hives stored in paged pool
                                        // controls access over registry bins

//#define WRITE_PROTECTED_VALUE_CACHE     // protects pool allocations used for kcb value cache

//#define DRAGOSS_PRIVATE_DEBUG           // private debug session

//#define CM_CHECK_MAP_NO_READ_SCHEME       // validates the mapping code assumption (i.e. each bin map should start
                                          // with HMAP_NEW_ALLOC; this is true only for mapped bins

#define REGISTRY_LOCK_CHECKING          // on each Nt API level call, checks the thread has released all locks
                                        // acquired. We may want to remove it, as it can hide bugs in other components
                                        // bellow registry (Ob, Se, Ps, Mm)

//#define CM_PERF_ISSUES                  // keep track of how long CmpInitializeHiveList and CmpConvertHiveToMapped takes


#define CM_CHECK_FOR_ORPHANED_KCBS      // check for orphaned kcbs every time we free a hive.

#endif //DBG

//#define CM_RETRY_CREATE_FILE            // when an error is returned from ZwCreateFile calls, retry the call

//#define CM_NOTIFY_CHANGED_KCB_FULLPATH  // return the full qualified path of the changed kcb in the Buffer arg of NtNotifyChangeKey

#if defined(_X86_)
#define CM_LEAK_STACK_TRACES            // keeps stacks traces for opened handles
#endif //_X86_

//
// 2. these section controls whether or not a certain feature goes into product or not;
// The goal is to remove these switches as new features are accepted, tested and proven to work
//
#ifndef _CM_LDR_

#define NT_RENAME_KEY                   // NtRenameKey API

#define NT_UNLOAD_KEY_EX                // NtUnloadKeyEx API

#endif //_CM_LDR_

#define CM_ENABLE_MAPPED_VIEWS          // controls whether the mapped views feature (using Cc interfaces) is used
                                        // by commenting this, registry hives are reverted to paged pool
                                        // WARNING: This should be always on !!!

//#define CM_ENABLE_WRITE_ONLY_BINS           // use MmSetPageProtection to catch writes on data not marked dirty

#define CM_MAP_NO_READ                  // this switch contols whether we map (touch all pages) or just pin_no_read
                                        // now it makes sense to use this as mm will fault in one page at a time for
                                        // MNW streams

#define CM_BREAK_ON_KEY_OPEN            // breaks when a key with Flags & KEY_BREAK_ON_OPEN is opened or a subkey is added

//#define CM_SAVE_KCB_CACHE               // at shutdown, save the kcb cache into a file

//#define CM_DYN_SYM_LINK               // dynamic symbolic links enabled.

//#define HV_TRACK_FREE_SPACE             // keep track of the actual free space inside the hive
//
// End SCS
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////

#ifdef CM_DYN_SYM_LINK
#define REG_DYN_LINK            21  // this should be moved to the proper place
#endif


#include "ntos.h"
#include "hive.h"
#include "wchar.h"
#include "zwapi.h"
#include <stdio.h>
#include <profiles.h>

// bugcheck description and defines
#include "cmpbug.h"

#include "kddll.h"

// CM data structure declarations
// file location: \nt\private\ntos\inc
#include "cmdata.h"


#ifdef CMP_STATS
VOID
CmpKcbStat(
    VOID
    );
#endif

#ifndef _CM_LDR_
#define CmKdPrintEx(_x_)  KdPrintEx(_x_)
#else
#define CmKdPrintEx(_x_) //nothing
#endif //_CM_LDR_


#define     _64K    64L*1024L   //64K
#define     _256K   256L*1024L  //256K

//
// this constant defines the size of a Cc view that is mapped -in every time a cell
// is accessed; It can be any power of 2, no less than 16K and no bigger than 256K
//
#define     CM_VIEW_SIZE            16L*1024L  //16K

//
// control the granularity the primary file grows;
// Warning: this should be multiple of 4K (HBLOCK_SIZE) !!!
//
#define     CM_FILE_GROW_INCREMENT  256L*1024L  //256K

//
// this controls the maximmum adress space allowed per hive. It should be specified in
// multiples of 256K
//
//  4  means 1   MB
//  6  means 1.5 MB
//  12 means 3   MB
//  .....
//
#define     MAX_MB_PER_HIVE     16          // 4MB


#define MAX_NAME    128

#ifdef CMP_ENTRYLIST_MANIPULATION
#define CmpRemoveEntryList(a) \
    if(((a)->Flink == NULL) && ((a)->Blink == NULL) ) {\
        DbgPrintEx(DPFLTR_CONFIG_ID,DPFLTR_ERROR_LEVEL,"CmpRemoveEntryList: Entry %08lx\n",a);\
        DbgBreakPoint();\
    }\
    RemoveEntryList(a);\
    (a)->Flink = (a)->Blink = NULL

#define CmpClearListEntry(a) (a)->Flink = (a)->Blink = NULL

#define CmpIsListEmpty(a) ( ( ((a)->Flink == NULL) && ((a)->Blink == NULL) ) || ( ((a)->Flink != NULL) && ((a)->Blink != NULL) && IsListEmpty(a) ) )

#else
#define CmpRemoveEntryList(a) RemoveEntryList(a)
#define CmpClearListEntry(a) //nothing
#define CmpIsListEmpty(a) IsListEmpty(a)
#endif // CMP_ENTRYLIST_MANIPULATION


extern PCM_TRACE_NOTIFY_ROUTINE CmpTraceRoutine;

VOID
CmpWmiDumpKcb(
    PCM_KEY_CONTROL_BLOCK       kcb
);

#define CmpWmiFireEvent(Status,Kcb,ElapsedTime,Index,KeyName,Type)  \
try {                                                               \
    PCM_TRACE_NOTIFY_ROUTINE TraceRoutine = CmpTraceRoutine;        \
    if( TraceRoutine != NULL ) {                                    \
        (*TraceRoutine)(Status,Kcb,ElapsedTime,Index,KeyName,Type); \
    }                                                               \
} except (EXCEPTION_EXECUTE_HANDLER) { }

#define StartWmiCmTrace()\
    LARGE_INTEGER   StartSystemTime;\
    LARGE_INTEGER   EndSystemTime;\
    PVOID           HookKcb = NULL;\
    if (CmpTraceRoutine) {\
        PerfTimeStamp(StartSystemTime); \
    }


#define EndWmiCmTrace(Status,Index,KeyName,Type)\
    if (CmpTraceRoutine) {\
        try {\
            PerfTimeStamp(EndSystemTime); \
            CmpWmiFireEvent(Status,HookKcb,EndSystemTime.QuadPart - StartSystemTime.QuadPart,Index,KeyName,Type);\
        } except (EXCEPTION_EXECUTE_HANDLER) {\
        }\
    }

#define HookKcbForWmiCmTrace(KeyBody) \
    if (CmpTraceRoutine) {\
        if(KeyBody) {\
            HookKcb = KeyBody->KeyControlBlock;\
        }\
    }

#define HookKcbFromHandleForWmiCmTrace(KeyHandle) \
    if (CmpTraceRoutine) {\
        PCM_KEY_BODY KeyBody;\
        NTSTATUS status;\
        status = ObReferenceObjectByHandle(\
                    KeyHandle,\
                    0,\
                    CmpKeyObjectType,\
                    KeGetPreviousMode(),\
                    (PVOID *)(&KeyBody),\
                    NULL\
                    );\
        if (NT_SUCCESS(status)) {\
            HookKcb = KeyBody->KeyControlBlock;\
            ObDereferenceObject((PVOID)KeyBody);\
        }\
    }

#define CmpTraceKcbCreate(kcb) \
    if (CmpTraceRoutine) {\
        CmpWmiDumpKcb(kcb);\
    }

#ifdef WRITE_PROTECTED_VALUE_CACHE

#define CmpMakeSpecialPoolReadOnly(PoolAddress) \
    { \
        if( !MmProtectSpecialPool( (PVOID) PoolAddress, PAGE_READONLY) ) \
        CmKdPrintEx((DPFLTR_CONFIG_ID,CML_POOL,"[CmpMakeSpecialPoolReadOnly]: Failed to Mark SpecialPool %p as ReadOnly", PoolAddress )); \
    }

#define CmpMakeSpecialPoolReadWrite(PoolAddress) \
    { \
        if( !MmProtectSpecialPool( (PVOID) PoolAddress, PAGE_READWRITE) ) { \
           CmKdPrintEx((DPFLTR_CONFIG_ID,CML_POOL,"[CmpMakeSpecialPoolReadWrite]: Failed to Mark SpecialPool %p as ReadWrite", PoolAddress )); \
        } \
    }
#define CmpMakeValueCacheReadOnly(ValueCached,PoolAddress) \
    if(ValueCached) { \
        CmpMakeSpecialPoolReadOnly( PoolAddress );\
    }

#define CmpMakeValueCacheReadWrite(ValueCached,PoolAddress) \
    if(ValueCached) { \
        CmpMakeSpecialPoolReadWrite( PoolAddress );\
    }

#else
#define CmpMakeSpecialPoolReadOnly(a)  //nothing
#define CmpMakeSpecialPoolReadWrite(a)  //nothing
#define CmpMakeValueCacheReadOnly(a,b) //nothing
#define CmpMakeValueCacheReadWrite(a,b) //nothing
#endif

#ifdef WRITE_PROTECTED_REGISTRY_POOL

VOID
HvpMarkBinReadWrite(
    PHHIVE      Hive,
    HCELL_INDEX Cell
    );

VOID
HvpChangeBinAllocation(
    PHBIN       Bin,
    BOOLEAN     ReadOnly
    );

VOID
CmpMarkAllBinsReadOnly(
    PHHIVE      Hive
    );

#else
#define HvpChangeBinAllocation(a,b) //nothing
#define HvpMarkBinReadWrite(a,b) //nothing
#define CmpMarkAllBinsReadOnly(a) //nothing
#endif

#ifdef POOL_TAGGING
//
// Pool Tag
//
#define  CM_POOL_TAG        '  MC'
#define  CM_KCB_TAG         'bkMC'
#define  CM_POSTBLOCK_TAG   'bpMC'
#define  CM_NOTIFYBLOCK_TAG 'bnMC'
#define  CM_POSTEVENT_TAG   'epMC'
#define  CM_POSTAPC_TAG     'apMC'
#define  CM_MAPPEDVIEW_TAG  'wVMC'
#define  CM_SECCACHE_TAG    'cSMC'
#define  CM_DELAYCLOSE_TAG  'cDMC'
#define  CM_STASHBUFFER_TAG 'bSMC'
#define  CM_HVBIN_TAG       'bHMC'
#define  CM_ALLOCATE_TAG    'lAMC'

//
// Find leaks
//
#define  CM_FIND_LEAK_TAG1    ' 1MC'
#define  CM_FIND_LEAK_TAG2    ' 2MC'
#define  CM_FIND_LEAK_TAG3    ' 3MC'
#define  CM_FIND_LEAK_TAG4    ' 4MC'
#define  CM_FIND_LEAK_TAG5    ' 5MC'
#define  CM_FIND_LEAK_TAG6    ' 6MC'
#define  CM_FIND_LEAK_TAG7    ' 7MC'
#define  CM_FIND_LEAK_TAG8    ' 8MC'
#define  CM_FIND_LEAK_TAG9    ' 9MC'
#define  CM_FIND_LEAK_TAG10    '01MC'
#define  CM_FIND_LEAK_TAG11    '11MC'
#define  CM_FIND_LEAK_TAG12    '21MC'
#define  CM_FIND_LEAK_TAG13    '31MC'
#define  CM_FIND_LEAK_TAG14    '41MC'
#define  CM_FIND_LEAK_TAG15    '51MC'
#define  CM_FIND_LEAK_TAG16    '61MC'
#define  CM_FIND_LEAK_TAG17    '71MC'
#define  CM_FIND_LEAK_TAG18    '81MC'
#define  CM_FIND_LEAK_TAG19    '91MC'
#define  CM_FIND_LEAK_TAG20    '02MC'
#define  CM_FIND_LEAK_TAG21    '12MC'
#define  CM_FIND_LEAK_TAG22    '22MC'
#define  CM_FIND_LEAK_TAG23    '32MC'
#define  CM_FIND_LEAK_TAG24    '42MC'
#define  CM_FIND_LEAK_TAG25    '52MC'
#define  CM_FIND_LEAK_TAG26    '62MC'
#define  CM_FIND_LEAK_TAG27    '72MC'
#define  CM_FIND_LEAK_TAG28    '82MC'
#define  CM_FIND_LEAK_TAG29    '92MC'
#define  CM_FIND_LEAK_TAG30    '03MC'
#define  CM_FIND_LEAK_TAG31    '13MC'
#define  CM_FIND_LEAK_TAG32    '23MC'
#define  CM_FIND_LEAK_TAG33    '33MC'
#define  CM_FIND_LEAK_TAG34    '43MC'
#define  CM_FIND_LEAK_TAG35    '53MC'
#define  CM_FIND_LEAK_TAG36    '63MC'
#define  CM_FIND_LEAK_TAG37    '73MC'
#define  CM_FIND_LEAK_TAG38    '83MC'
#define  CM_FIND_LEAK_TAG39    '93MC'
#define  CM_FIND_LEAK_TAG40    '04MC'
#define  CM_FIND_LEAK_TAG41    '14MC'
#define  CM_FIND_LEAK_TAG42    '24MC'
#define  CM_FIND_LEAK_TAG43    '34MC'
#define  CM_FIND_LEAK_TAG44    '44MC'
#define  CM_FIND_LEAK_TAG45    '54MC'

#ifdef _WANT_MACHINE_IDENTIFICATION

#define CM_PARSEINI_TAG 'ipMC'
#define CM_GENINST_TAG  'igMC'

#endif

//
// Extra Tags for cache.
// We may want to merge these tags later.
//
#define  CM_CACHE_VALUE_INDEX_TAG 'IVMC'
#define  CM_CACHE_VALUE_TAG       'aVMC'
#define  CM_CACHE_INDEX_TAG       'nIMC'
#define  CM_CACHE_VALUE_DATA_TAG  'aDMC'
#define  CM_NAME_TAG              'bNMC'


#define ExAllocatePool(a,b) ExAllocatePoolWithTag(a,b,CM_POOL_TAG)
#define ExAllocatePoolWithQuota(a,b) ExAllocatePoolWithQuotaTag(a,b,CM_POOL_TAG)

PVOID
CmpAllocateTag(
    ULONG   Size,
    BOOLEAN UseForIo,
    ULONG   Tag
    );
#else
#define CmpAllocateTag(a,b,c) CmpAllocate(a,b,c)
#endif

//
// A variable so can turn on/off certain performance features.
//
extern const ULONG CmpCacheOnFlag;

#define CM_CACHE_FAKE_KEY  0x00000001      // Create Fake key KCB

//
// This lock protects the KCB cache, including the KCB structures,
// NameBlock and Value Index.
//

extern ERESOURCE CmpKcbLock;

//
// This is \REGISTRY
//
extern HANDLE CmpRegistryRootHandle;

#if 0
#define CmpLockKCBTree() ExAcquireResourceShared(&CmpKcbLock, TRUE)

#define CmpLockKCBTreeExclusive() ExAcquireResourceExclusive(&CmpKcbLock);

#else
VOID
CmpLockKCBTreeExclusive(
    VOID
    );
VOID
CmpLockKCBTree(
    VOID
    );
#endif

VOID
CmpUnlockKCBTree(
    );

#if DBG
BOOLEAN
CmpTestKCBLock(
    VOID
    );
BOOLEAN
CmpTestKCBLockExclusive(
    VOID
    );
#define ASSERT_KCB_LOCK_OWNED() \
    ASSERT(CmpTestKCBLock() == TRUE)

#define ASSERT_KCB_LOCK_OWNED_EXCLUSIVE() \
    ASSERT(CmpTestKCBLockExclusive() == TRUE)
#else
#define ASSERT_KCB_LOCK_OWNED()
#define ASSERT_KCB_LOCK_OWNED_EXCLUSIVE()
#endif

//
// Logging: remember, first 4 levels (0-3) are reserved system-wide
//
#define CML_BUGCHECK    4   // fatal errors
#define CML_EXCEPTION   5   // all exception's
#define CML_NTAPI       6   // NtApi calls
#define CML_NTAPI_ARGS  7   // NtApi parameters
#define CML_CM          8   // Cm level, general
#define CML_NOTIFY      9   // Notify level, general
#define CML_HIVE        10  // Hv level, general
#define CML_IO          11  // IO level
#define CML_SEC         12  // Security level
#define CML_INIT        13  // Init level, general
#define CML_INDEX       14  // Index level, general
#define CML_BIN_MAP     15  // bin mapping level
#define CML_FREECELL    16  // Free cell hints
#define CML_POOL        17  // Pool
#define CML_LOCKING     18  // Lock/unlock level
#define CML_FLOW        19  // General flow
#define CML_PARSE       20  // Parse algorithm
#define CML_SAVRES      21  // SavRes operations


#define REGCHECKING 1

#if DBG

#if REGCHECKING
#define DCmCheckRegistry(a) if(HvHiveChecking) ASSERT(CmCheckRegistry(a, CM_CHECK_REGISTRY_HIVE_CHECK) == 0)
#else
#define DCmCheckRegistry(a)
#endif

#else
#define DCmCheckRegistry(a)
#endif

#ifdef CHECK_REGISTRY_USECOUNT
VOID
CmpCheckRegistryUseCount( );
#endif //CHECK_REGISTRY_USECOUNT

#ifdef  REGISTRY_LOCK_CHECKING
ULONG
CmpCheckLockExceptionFilter(
    IN PEXCEPTION_POINTERS ExceptionPointers
    );

//
// updated to check both registry and kcb
//
#define BEGIN_LOCK_CHECKPOINT                                                       \
    {                                                                               \
        ULONG   RegistryLockCountBefore,RegistryLockCountAfter;                     \
        ULONG   KCBLockCountBefore,KCBLockCountAfter;                               \
        RegistryLockCountBefore = ExIsResourceAcquiredShared(&CmpRegistryLock);     \
        RegistryLockCountBefore += ExIsResourceAcquiredExclusive(&CmpRegistryLock); \
        KCBLockCountBefore = ExIsResourceAcquiredShared(&CmpKcbLock);               \
        KCBLockCountBefore += ExIsResourceAcquiredExclusive(&CmpKcbLock);           \
        try {

#define END_LOCK_CHECKPOINT                                                                                         \
        } except(CmpCheckLockExceptionFilter(GetExceptionInformation())) {}                                         \
        RegistryLockCountAfter = ExIsResourceAcquiredShared(&CmpRegistryLock);                                      \
        RegistryLockCountAfter += ExIsResourceAcquiredExclusive(&CmpRegistryLock);                                  \
        KCBLockCountAfter = ExIsResourceAcquiredShared(&CmpKcbLock);                                                \
        KCBLockCountAfter += ExIsResourceAcquiredExclusive(&CmpKcbLock);                                            \
        if( RegistryLockCountBefore != RegistryLockCountAfter ) {                                                   \
            CM_BUGCHECK(REGISTRY_ERROR,REGISTRY_LOCK_CHECKPOINT,0,RegistryLockCountBefore,RegistryLockCountAfter);  \
        }                                                                                                           \
        if( KCBLockCountBefore != KCBLockCountAfter ) {                                                             \
            CM_BUGCHECK(REGISTRY_ERROR,REGISTRY_LOCK_CHECKPOINT,1,KCBLockCountBefore,KCBLockCountAfter);            \
        }                                                                                                           \
    }


#define BEGIN_KCB_LOCK_GUARD    \
        try {

#define END_KCB_LOCK_GUARD      \
        } except(CmpCheckLockExceptionFilter(GetExceptionInformation())) {}

#else
#define BEGIN_LOCK_CHECKPOINT
#define END_LOCK_CHECKPOINT
#define BEGIN_KCB_LOCK_GUARD
#define END_KCB_LOCK_GUARD
#endif //REGISTRY_LOCK_CHECKING

extern BOOLEAN CmpSpecialBootCondition;

#if DBG
#define ASSERT_CM_LOCK_OWNED() \
    ASSERT( (CmpSpecialBootCondition == TRUE) || (CmpTestRegistryLock() == TRUE) )
#define ASSERT_CM_LOCK_OWNED_EXCLUSIVE() \
    ASSERT((CmpSpecialBootCondition == TRUE) || (CmpTestRegistryLockExclusive() == TRUE) )
#define ASSERT_CM_EXCLUSIVE_HIVE_ACCESS(Hive) \
    ASSERT((CmpSpecialBootCondition == TRUE) || (CmpTestRegistryLockExclusive() == TRUE) || (Hive->ReleaseCellRoutine == NULL) )
#else
#define ASSERT_CM_LOCK_OWNED()
#define ASSERT_CM_LOCK_OWNED_EXCLUSIVE()
#define ASSERT_CM_EXCLUSIVE_HIVE_ACCESS(Hive)
#endif

#if DBG
#ifndef _CM_LDR_
#define ASSERT_PASSIVE_LEVEL()                                              \
    {                                                                       \
        KIRQL   Irql;                                                       \
        Irql = KeGetCurrentIrql();                                          \
        if( KeGetCurrentIrql() != PASSIVE_LEVEL ) {                         \
            DbgPrintEx(DPFLTR_CONFIG_ID,DPFLTR_ERROR_LEVEL,"ASSERT_PASSIVE_LEVEL failed ... Irql = %lu\n",Irql);  \
            ASSERT( FALSE );                                                \
        }                                                                   \
    }
#endif //_CM_LDR_
#else
#define ASSERT_PASSIVE_LEVEL()
#endif

#define VALIDATE_CELL_MAP(LINE,Map,Hive,Address)                                                    \
    if( Map == NULL ) {                                                                             \
            CM_BUGCHECK (REGISTRY_ERROR,BAD_CELL_MAP,(ULONG_PTR)(Hive),(ULONG)(Address),(ULONG)(LINE)) ;      \
    }

#if DBG
VOID
SepDumpSecurityDescriptor(
    IN PSECURITY_DESCRIPTOR SecurityDescriptor,
    IN PSZ TitleString
    );

extern BOOLEAN SepDumpSD;

#define CmpDumpSecurityDescriptor(x,y) \
        { \
            SepDumpSD=TRUE;     \
            SepDumpSecurityDescriptor(x, y);  \
            SepDumpSD=FALSE;    \
        }
#else

#define CmpDumpSecurityDescriptor(x,y)

#endif


//
// misc stuff
//

extern  UNICODE_STRING  CmRegistrySystemCloneName;

//
// Determines whether the Current Control Set used during booting
// is cloned in order to fully preserve it for being saved
// as the LKG Control Set.
//

#define CLONE_CONTROL_SET FALSE

#if CLONE_CONTROL_SET
#define     CM_NUMBER_OF_MACHINE_HIVES  7
#else
#define     CM_NUMBER_OF_MACHINE_HIVES  6
#endif

#define NUMBER_TYPES (MaximumType + 1)

#define CM_WRAP_LIMIT               0x7fffffff


//
// Tuning and control constants
//
#define CM_MAX_STASH           1024*1024        // If size of data for a set
                                                // is bigger than this,

#define CM_MAX_REASONABLE_VALUES    100         // If number of values for a
                                                // key is greater than this,
                                                // round up value list size


//
// Limit on the number of layers of hive there may be.  We allow only
// the master hive and hives directly linked into it for now, for currently
// value is always 2..
//

#define MAX_HIVE_LAYERS         2


//
// structure used to create and sort ordered list of drivers to be loaded.
// This is also used by the OS Loader when loading the boot drivers.
// (Particularly the ErrorControl field)
//

typedef struct _BOOT_DRIVER_NODE {
    BOOT_DRIVER_LIST_ENTRY ListEntry;
    UNICODE_STRING Group;
    UNICODE_STRING Name;
    ULONG Tag;
    ULONG ErrorControl;
} BOOT_DRIVER_NODE, *PBOOT_DRIVER_NODE;

//
// extern for object type pointer
//

extern  POBJECT_TYPE CmpKeyObjectType;
extern  POBJECT_TYPE IoFileObjectType;

//
// indexes in CmpMachineHiveList
//
#define SYSTEM_HIVE_INDEX 3
#define CLONE_HIVE_INDEX 6

//
// Miscelaneous Hash routines
//
#define RNDM_CONSTANT   314159269    /* default value for "scrambling constant" */
#define RNDM_PRIME     1000000007    /* prime number, also used for scrambling  */

#define HASH_KEY(_convkey_) ((RNDM_CONSTANT * (_convkey_)) % RNDM_PRIME)

#define GET_HASH_INDEX(Key) HASH_KEY(Key) % CmpHashTableSize
#define GET_HASH_ENTRY(Table, Key) Table[GET_HASH_INDEX(Key)]

//
// CM_KEY_BODY
//
//  Same structure used for KEY_ROOT and KEY objects.  This is the
//  Cm defined part of the object.
//
//  This object represents an open instance, several of them could refer
//  to a single key control block.
//
#define KEY_BODY_TYPE           0x6b793032      // "ky02"

struct _CM_NOTIFY_BLOCK; //forward

typedef struct _CM_KEY_BODY {
    ULONG                   Type;
    PCM_KEY_CONTROL_BLOCK   KeyControlBlock;
    struct _CM_NOTIFY_BLOCK *NotifyBlock;
    PEPROCESS               Process;        // the owner process

#ifdef CM_LEAK_STACK_TRACES
    ULONG                   Callers;
    PVOID                   CallerAddress[10];
#endif //CM_LEAK_STACK_TRACES

    LIST_ENTRY              KeyBodyList;    // key_nodes using the same kcb
} CM_KEY_BODY, *PCM_KEY_BODY;

#ifdef CM_LEAK_STACK_TRACES
// just because we need this #define code inside a macro !
#define CmpSetNoCallers(KeyBody) KeyBody->Callers = 0

#define CmpAddKeyTracker(KeyHandle,mode)                                                    \
if(PoCleanShutdownEnabled() & PO_CLEAN_SHUTDOWN_REGISTRY) {                                 \
    PCM_KEY_BODY    KeyBody;                                                                \
    NTSTATUS        status;                                                                 \
    status = ObReferenceObjectByHandle(                                                     \
            KeyHandle,                                                                      \
            0,                                                                              \
            CmpKeyObjectType,                                                               \
            mode,                                                                           \
            (PVOID *)(&KeyBody),                                                            \
            NULL                                                                            \
            );                                                                              \
    if( NT_SUCCESS(status) ) {                                                              \
            KeyBody->Callers = RtlWalkFrameChain(&(KeyBody->CallerAddress[0]), 10, 0);      \
            ObDereferenceObject((PVOID)KeyBody);                                            \
    }                                                                                       \
}
#else
#define CmpSetNoCallers(KeyBody) // nothing
#define CmpAddKeyTracker(KeyHandle,mode) // nothing yet
#endif  //CM_LEAK_STACK_TRACES


#define INIT_KCB_KEYBODY_LIST(kcb)  InitializeListHead(&(kcb->KeyBodyListHead))

#define ASSERT_KEYBODY_LIST_EMPTY(kcb)  ASSERT(IsListEmpty(&(kcb->KeyBodyListHead)) == TRUE)

#define ENLIST_KEYBODY_IN_KEYBODY_LIST(KeyBody)                                             \
    ASSERT( KeyBody->KeyControlBlock != NULL );                                             \
    BEGIN_KCB_LOCK_GUARD;                                                                   \
    CmpLockKCBTreeExclusive();                                                              \
    InsertTailList(&(KeyBody->KeyControlBlock->KeyBodyListHead),&(KeyBody->KeyBodyList));   \
    CmpSetNoCallers(KeyBody);                                                               \
    CmpUnlockKCBTree();                                                                     \
    END_KCB_LOCK_GUARD

#define DELIST_KEYBODY_FROM_KEYBODY_LIST(KeyBody)                                           \
    ASSERT( KeyBody->KeyControlBlock != NULL );                                             \
    ASSERT(IsListEmpty(&(KeyBody->KeyControlBlock->KeyBodyListHead)) == FALSE);             \
    BEGIN_KCB_LOCK_GUARD;                                                                   \
    CmpLockKCBTreeExclusive();                                                              \
    RemoveEntryList(&(KeyBody->KeyBodyList));                                               \
    CmpUnlockKCBTree();                                                                     \
    END_KCB_LOCK_GUARD


#define ASSERT_KEY_OBJECT(x) ASSERT(((PCM_KEY_BODY)x)->Type == KEY_BODY_TYPE)
#define ASSERT_NODE(x) ASSERT(((PCM_KEY_NODE)x)->Signature == CM_KEY_NODE_SIGNATURE)
#define ASSERT_SECURITY(x) ASSERT(((PCM_KEY_SECURITY)x)->Signature == CM_KEY_SECURITY_SIGNATURE)

//
// CM_POST_KEY_BODY
//
// A post block can have attached a keybody which has to be dereferenced
// when the post block goes out of scope. This structure allows the
// implementation of keybody "delayed dereferencing". (see CmpPostNotify for comments)
//

typedef struct _CM_POST_KEY_BODY {
    LIST_ENTRY                  KeyBodyList;
    struct _CM_KEY_BODY         *KeyBody;        // this key body object
} CM_POST_KEY_BODY, *PCM_POST_KEY_BODY;


//
// CM_NOTIFY_BLOCK
//
//  A notify block tracks an active notification waiting for notification.
//  Any one open instance (CM_KEY_BODY) will refer to at most one
//  notify block.  A given key control block may have as many notify
//  blocks refering to it as there are CM_KEY_BODYs refering to it.
//  Notify blocks are attached to hives and sorted by length of name.
//

typedef struct _CM_NOTIFY_BLOCK {
    LIST_ENTRY                  HiveList;        // sorted list of notifies
    LIST_ENTRY                  PostList;        // Posts to fill
    PCM_KEY_CONTROL_BLOCK       KeyControlBlock; // Open instance notify is on
    struct _CM_KEY_BODY         *KeyBody;        // our owning key handle object
    struct {
        ULONG                       Filter          : 30;    // Events of interest
        ULONG                       WatchTree       : 1;
        ULONG                       NotifyPending   : 1;
    };
    SECURITY_SUBJECT_CONTEXT    SubjectContext;  // Security stuff
} CM_NOTIFY_BLOCK, *PCM_NOTIFY_BLOCK;

//
// CM_POST_BLOCK
//
//  Whenever a notify call is made, a post block is created and attached
//  to the notify block.  Each time an event is posted against the notify,
//  the waiter described by the post block is signaled.  (i.e. APC enqueued,
//  event signalled, etc.)
//

//
//  The NotifyType ULONG is a combination of POST_BLOCK_TYPE enum and flags
//

typedef enum _POST_BLOCK_TYPE {
    PostSynchronous = 1,
    PostAsyncUser = 2,
    PostAsyncKernel = 3
} POST_BLOCK_TYPE;

typedef struct _CM_SYNC_POST_BLOCK {
    PKEVENT                 SystemEvent;
    NTSTATUS                Status;
} CM_SYNC_POST_BLOCK, *PCM_SYNC_POST_BLOCK;

typedef struct _CM_ASYNC_USER_POST_BLOCK {
    PKEVENT                 UserEvent;
    PKAPC                   Apc;
    PIO_STATUS_BLOCK        IoStatusBlock;
} CM_ASYNC_USER_POST_BLOCK, *PCM_ASYNC_USER_POST_BLOCK;

typedef struct _CM_ASYNC_KERNEL_POST_BLOCK {
    PKEVENT                 Event;
    PWORK_QUEUE_ITEM        WorkItem;
    WORK_QUEUE_TYPE         QueueType;
} CM_ASYNC_KERNEL_POST_BLOCK, *PCM_ASYNC_KERNEL_POST_BLOCK;

typedef union _CM_POST_BLOCK_UNION {
    CM_SYNC_POST_BLOCK  Sync;
    CM_ASYNC_USER_POST_BLOCK AsyncUser;
    CM_ASYNC_KERNEL_POST_BLOCK AsyncKernel;
} CM_POST_BLOCK_UNION, *PCM_POST_BLOCK_UNION;

typedef struct _CM_POST_BLOCK {
#if DBG
    BOOLEAN                     TraceIntoDebugger;
#endif
    LIST_ENTRY                  NotifyList;
    LIST_ENTRY                  ThreadList;
    LIST_ENTRY                  CancelPostList; // slave notifications that are attached to this notification
    struct _CM_POST_KEY_BODY    *PostKeyBody;

#ifdef CM_NOTIFY_CHANGED_KCB_FULLPATH
    PUNICODE_STRING             ChangedKcbFullName; // full qualified name of the kcb that triggered this notification
    PVOID                       CallerBuffer;       // used to return full qualified name of the changed kcb to the caller
    ULONG                       CallerBufferSize;   // these are supposed to be filled by CmpAllocatePostBlock
#endif //CM_NOTIFY_CHANGED_KCB_FULLPATH

    ULONG                       NotifyType;
    PCM_POST_BLOCK_UNION        u;
} CM_POST_BLOCK, *PCM_POST_BLOCK;

#define REG_NOTIFY_POST_TYPE_MASK (0x0000FFFFL)   // mask for finding out the type of the post block

#define REG_NOTIFY_MASTER_POST    (0x00010000L)   // The current post block is a master one

//
// Usefull macros to manipulate the NotifyType field in CM_POST_BLOCK
//
#define PostBlockType(_post_) ((POST_BLOCK_TYPE)( ((_post_)->NotifyType) & REG_NOTIFY_POST_TYPE_MASK ))

#define IsMasterPostBlock(_post_)           ( ((_post_)->NotifyType) &   REG_NOTIFY_MASTER_POST )
#define SetMasterPostBlockFlag(_post_)      ( ((_post_)->NotifyType) |=  REG_NOTIFY_MASTER_POST )
#define ClearMasterPostBlockFlag(_post_)    ( ((_post_)->NotifyType) &= ~REG_NOTIFY_MASTER_POST )

//
// This lock protects the PostList(s) in Notification objects.
// It is used to prevent attempts for simultaneous changes of
// CancelPostList list in PostBlocks
//

extern FAST_MUTEX CmpPostLock;
#define LOCK_POST_LIST() ExAcquireFastMutexUnsafe(&CmpPostLock)
#define UNLOCK_POST_LIST() ExReleaseFastMutexUnsafe(&CmpPostLock)


extern FAST_MUTEX CmpStashBufferLock;
#define LOCK_STASH_BUFFER() ExAcquireFastMutexUnsafe(&CmpStashBufferLock)
#define UNLOCK_STASH_BUFFER() ExReleaseFastMutexUnsafe(&CmpStashBufferLock)


//
// protection for CmpHiveListHead
//
extern FAST_MUTEX CmpHiveListHeadLock;
#ifndef _CM_LDR_
#define LOCK_HIVE_LIST() ExAcquireFastMutexUnsafe(&CmpHiveListHeadLock)
#define UNLOCK_HIVE_LIST() ExReleaseFastMutexUnsafe(&CmpHiveListHeadLock)
#else
#define LOCK_HIVE_LIST()    //nothing
#define UNLOCK_HIVE_LIST()  //nothing
#endif

//
// used by CmpFileWrite, so it doesn't take up so much stack.
//
typedef struct _CM_WRITE_BLOCK {
    HANDLE          EventHandles[MAXIMUM_WAIT_OBJECTS];
    PKEVENT         EventObjects[MAXIMUM_WAIT_OBJECTS];
    KWAIT_BLOCK     WaitBlockArray[MAXIMUM_WAIT_OBJECTS];
    IO_STATUS_BLOCK IoStatus[MAXIMUM_WAIT_OBJECTS];
} CM_WRITE_BLOCK, *PCM_WRITE_BLOCK;

//
// CM data to manipulate views inside the primary hive file
//

//#define MAPPED_VIEWS_PER_HIVE   12 * (_256K / CM_VIEW_SIZE ) // max 3 MB per hive ; we don't really need this
#define MAX_VIEWS_PER_HIVE      MAX_MB_PER_HIVE * ( (_256K) / (CM_VIEW_SIZE) )

#define ASSERT_VIEW_MAPPED(a)                           \
    ASSERT((a)->Size != 0);                             \
    ASSERT((a)->ViewAddress != 0);                      \
    ASSERT((a)->Bcb != 0);                              \
    ASSERT( IsListEmpty(&((a)->LRUViewList)) == FALSE); \
    ASSERT( IsListEmpty(&((a)->PinViewList)) == TRUE)

#define ASSERT_VIEW_PINNED(a)                           \
    ASSERT((a)->Size != 0);                             \
    ASSERT((a)->ViewAddress != 0);                      \
    ASSERT((a)->Bcb != 0);                              \
    ASSERT( IsListEmpty(&((a)->LRUViewList)) == TRUE)

typedef struct _CM_VIEW_OF_FILE {
    LIST_ENTRY      LRUViewList;        // LRU connection ==> when this is empty, the view is pinned
    LIST_ENTRY      PinViewList;        // list of views pinned into memory ==> when this is empty, the view is in LRU list
    ULONG           FileOffset;         // file offset at which the mapping starts
    ULONG           Size;               // size the view maps
    PULONG_PTR      ViewAddress;        // memory address containing the mapping
    PVOID           Bcb;                // BCB needed for map/pin/unpin access
    ULONG           UseCount;           // how many cells are currently in use inside this view
} CM_VIEW_OF_FILE, *PCM_VIEW_OF_FILE;


//
// security hash manipulation
//
#define CmpSecHashTableSize             64      // size of the hash table

typedef struct _CM_KCB_REMAP_BLOCK {
    LIST_ENTRY              RemapList;
    PCM_KEY_CONTROL_BLOCK   KeyControlBlock;
    HCELL_INDEX             OldCellIndex;
    HCELL_INDEX             NewCellIndex;
    ULONG                   ValueCount;
    HCELL_INDEX             ValueList;
} CM_KCB_REMAP_BLOCK, *PCM_KCB_REMAP_BLOCK;

typedef struct _CM_CELL_REMAP_BLOCK {
    HCELL_INDEX             OldCell;
    HCELL_INDEX             NewCell;
} CM_CELL_REMAP_BLOCK, *PCM_CELL_REMAP_BLOCK;

typedef struct _CM_KNODE_REMAP_BLOCK {
    LIST_ENTRY              RemapList;
    PCM_KEY_NODE            KeyNode;
    HCELL_INDEX             NewParent;
} CM_KNODE_REMAP_BLOCK, *PCM_KNODE_REMAP_BLOCK;

// ----- Cm version of Hive structure (CMHIVE) -----
//
typedef struct _CMHIVE {
    HHIVE                           Hive;
    HANDLE                          FileHandles[HFILE_TYPE_MAX];
    LIST_ENTRY                      NotifyList;
    LIST_ENTRY                      HiveList;           // Used to find hives at shutdown
    PFAST_MUTEX                     HiveLock;           // Used to synchronize operations on the hive (NotifyList and Flush)
    PFAST_MUTEX                     ViewLock;           // Used to control access over the view list, UseCount
    LIST_ENTRY                      LRUViewListHead;    // Head of the same list as above but ordered (LRU)
    LIST_ENTRY                      PinViewListHead;    // Head of the List of Views pinned into memory inside the primary hive file
#if 0 // it didn't work
    LIST_ENTRY                      FakeViewListHead;   // Used to optimize boot process (fault all the data in in 256K chunks at once)
#endif
    PFILE_OBJECT                    FileObject;         // FileObject needed for Cc operations on the mapped views
    UNICODE_STRING                  FileFullPath;       // full path of the hive file- needed for CmPrefetchHivePages
    UNICODE_STRING                  FileUserName;       // file name as passed onto NtLoadKey 
    USHORT                          MappedViews;        // number of mapped (but not pinned views) i.e. the number of elements in LRUViewList
    USHORT                          PinnedViews;        // number of pinned views i.e. the number of elements in PinViewList
    ULONG                           UseCount;           // how many cells are currently in use inside this hive
#if 0
    ULONG                           FakeViews;          // number of FakeViews (debug-only)
#endif
    ULONG                           SecurityCount;      // number of security cells cached
    ULONG                           SecurityCacheSize;  // number of entries in the cache (to avoid memory fragmentation)
    LONG                            SecurityHitHint;    // index of the last cell we've searched on
    PCM_KEY_SECURITY_CACHE_ENTRY    SecurityCache;      // the security cache

                                                        // hash table (to retrieve the security cells by descriptor)
    LIST_ENTRY                      SecurityHash[CmpSecHashTableSize];

#ifdef NT_UNLOAD_KEY_EX
    PKEVENT                         UnloadEvent;        // the event to be signaled when the hive unloads
                                                        // this may be valid (not NULL) only in conjunction with
                                                        // a not NULL RootKcb and a TRUE Frozen (bellow)

    PCM_KEY_CONTROL_BLOCK           RootKcb;            // kcb to the root of the hive. We keep a reference on it, which
                                                        // will be released at the time the hive unloads (i.e. it is the last
                                                        // reference somebody has on this kcb); This is should be valid (not NULL)
                                                        // only when the Frozen flag is set to TRUE

    BOOLEAN                         Frozen;             // set to TRUE when the hive is frozen (no further operations are allowed on
                                                        // this hive

    PWORK_QUEUE_ITEM                UnloadWorkItem;     // Work Item to actually perform the late unload
#endif //NT_UNLOAD_KEY_EX

    BOOLEAN                         GrowOnlyMode;       // the hive is in "grow only" mode; new cells are allocated past GrowOffset
    ULONG                           GrowOffset;

    LIST_ENTRY                      KcbConvertListHead; // list of CM_KCB_REMAP_BLOCK storing the associations to the new hive.
    LIST_ENTRY                      KnodeConvertListHead;
    PCM_CELL_REMAP_BLOCK            CellRemapArray;     // array of mappings used for security cells

} CMHIVE, *PCMHIVE;

#ifdef NT_UNLOAD_KEY_EX
#define IsHiveFrozen(_CmHive_) (((PCMHIVE)(_CmHive_))->Frozen == TRUE)
#endif

#define HiveWritesThroughCache(Hive,FileType) ((FileType == HFILE_TYPE_PRIMARY) && (((PCMHIVE)CONTAINING_RECORD(Hive, CMHIVE, Hive))->FileObject != NULL))


//
// Delayed close kcb list
//
typedef struct _CM_DELAYED_CLOSE_ENTRY {
    LIST_ENTRY              DelayedLRUList;     //  LRU list of entries in the Delayed Close Table
    PCM_KEY_CONTROL_BLOCK   KeyControlBlock;    //  KCB in this entry; NULL if the entry is available
} CM_DELAYED_CLOSE_ENTRY, *PCM_DELAYED_CLOSE_ENTRY;


//
// Hive locking support
//
//
#define CmLockHive(_hive_)  ASSERT( (_hive_)->HiveLock );\
                            ExAcquireFastMutexUnsafe((_hive_)->HiveLock)
#define CmUnlockHive(_hive_) ASSERT( (_hive_)->HiveLock );\
                             ExReleaseFastMutexUnsafe((_hive_)->HiveLock)

//
// View locking support
//
#define CmLockHiveViews(_hive_)     ASSERT( (_hive_)->ViewLock );\
                                    ExAcquireFastMutexUnsafe((_hive_)->ViewLock)
#define CmUnlockHiveViews(_hive_)   ASSERT( (_hive_)->ViewLock );\
                                    ExReleaseFastMutexUnsafe((_hive_)->ViewLock)

//
// Macros
//

//
// ----- CM_KEY_NODE -----
//
#define CmpHKeyNameLen(Key) \
        (((Key)->Flags & KEY_COMP_NAME) ? \
            CmpCompressedNameSize((Key)->Name,(Key)->NameLength) : \
            (Key)->NameLength)

#define CmpNcbNameLen(Ncb) \
        (((Ncb)->Compressed) ? \
            CmpCompressedNameSize((Ncb)->Name,(Ncb)->NameLength) : \
            (Ncb)->NameLength)

#define CmpHKeyNodeSize(Hive, KeyName) \
    (FIELD_OFFSET(CM_KEY_NODE, Name) + CmpNameSize(Hive, KeyName))


//
// ----- CM_KEY_VALUE -----
//


#define CmpValueNameLen(Value)                                       \
        (((Value)->Flags & VALUE_COMP_NAME) ?                           \
            CmpCompressedNameSize((Value)->Name,(Value)->NameLength) :  \
            (Value)->NameLength)

#define CmpHKeyValueSize(Hive, ValueName) \
    (FIELD_OFFSET(CM_KEY_VALUE, Name) + CmpNameSize(Hive, ValueName))


//
// ----- Procedure Prototypes -----
//

//
// Configuration Manager private procedure prototypes
//

#define REG_OPTION_PREDEF_HANDLE (0x01000000L)
#define REG_PREDEF_HANDLE_MASK   (0x80000000L)

typedef struct _CM_PARSE_CONTEXT {
    ULONG               TitleIndex;
    UNICODE_STRING      Class;
    ULONG               CreateOptions;
    ULONG               Disposition;
    BOOLEAN             CreateLink;
    CM_KEY_REFERENCE    ChildHive;
    HANDLE              PredefinedHandle;
} CM_PARSE_CONTEXT, *PCM_PARSE_CONTEXT;

NTSTATUS
CmpParseKey(
    IN PVOID ParseObject,
    IN PVOID ObjectType,
    IN OUT PACCESS_STATE AccessState,
    IN KPROCESSOR_MODE AccessMode,
    IN ULONG Attributes,
    IN OUT PUNICODE_STRING CompleteName,
    IN OUT PUNICODE_STRING RemainingName,
    IN OUT PVOID Context OPTIONAL,
    IN PSECURITY_QUALITY_OF_SERVICE SecurityQos OPTIONAL,
    OUT PVOID *Object
    );

NTSTATUS
CmpDoCreate(
    IN PHHIVE Hive,
    IN HCELL_INDEX Cell,
    IN PACCESS_STATE AccessState,
    IN PUNICODE_STRING Name,
    IN KPROCESSOR_MODE AccessMode,
    IN PCM_PARSE_CONTEXT Context,
    IN PCM_KEY_CONTROL_BLOCK ParentKcb,
    OUT PVOID *Object
    );

NTSTATUS
CmpDoCreateChild(
    IN PHHIVE Hive,
    IN HCELL_INDEX ParentCell,
    IN PSECURITY_DESCRIPTOR ParentDescriptor OPTIONAL,
    IN PACCESS_STATE AccessState,
    IN PUNICODE_STRING Name,
    IN KPROCESSOR_MODE AccessMode,
    IN PCM_PARSE_CONTEXT Context,
    IN PCM_KEY_CONTROL_BLOCK ParentKcb,
    IN USHORT Flags,
    OUT PHCELL_INDEX KeyCell,
    OUT PVOID *Object
    );

NTSTATUS
CmpQueryKeyName(
    IN PVOID Object,
    IN BOOLEAN HasObjectName,
    OUT POBJECT_NAME_INFORMATION ObjectNameInfo,
    IN ULONG Length,
    OUT PULONG ReturnLength
    );

VOID
CmpDeleteKeyObject(
    IN  PVOID   Object
    );

VOID
CmpCloseKeyObject(
    IN PEPROCESS Process OPTIONAL,
    IN PVOID Object,
    IN ACCESS_MASK GrantedAccess,
    IN ULONG ProcessHandleCount,
    IN ULONG SystemHandleCount
    );

NTSTATUS
CmpSecurityMethod (
    IN PVOID Object,
    IN SECURITY_OPERATION_CODE OperationCode,
    IN PSECURITY_INFORMATION SecurityInformation,
    IN OUT PSECURITY_DESCRIPTOR SecurityDescriptor,
    IN OUT PULONG CapturedLength,
    IN OUT PSECURITY_DESCRIPTOR *ObjectsSecurityDescriptor,
    IN POOL_TYPE PoolType,
    IN PGENERIC_MAPPING GenericMapping
    );

#define KCB_WORKER_CONTINUE     0
#define KCB_WORKER_DONE         1
#define KCB_WORKER_DELETE       2
#define KCB_WORKER_ERROR        3

typedef
ULONG
(*PKCB_WORKER_ROUTINE) (
    PCM_KEY_CONTROL_BLOCK Current,
    PVOID                 Context1,
    PVOID                 Context2
    );


BOOLEAN
CmpSearchKeyControlBlockTree(
    PKCB_WORKER_ROUTINE WorkerRoutine,
    PVOID               Context1,
    PVOID               Context2
    );

//
// Wrappers
//

PVOID
CmpAllocate(
    ULONG   Size,
    BOOLEAN UseForIo,
    ULONG   Tag
    );

VOID
CmpFree(
    PVOID   MemoryBlock,
    ULONG   GlobalQuotaSize
    );

BOOLEAN
CmpFileSetSize(
    PHHIVE      Hive,
    ULONG       FileType,
    ULONG       FileSize,
    ULONG       OldFileSize
    );

NTSTATUS
CmpDoFileSetSize(
    PHHIVE      Hive,
    ULONG       FileType,
    ULONG       FileSize,
    ULONG       OldFileSize
    );

BOOLEAN
CmpFileWrite(
    PHHIVE      Hive,
    ULONG       FileType,
    PCMP_OFFSET_ARRAY offsetArray,
    ULONG offsetArrayCount,
    PULONG      FileOffset
    );

BOOLEAN
CmpFileWriteThroughCache(
    PHHIVE              Hive,
    ULONG               FileType,
    PCMP_OFFSET_ARRAY   offsetArray,
    ULONG               offsetArrayCount
    );

BOOLEAN
CmpFileRead (
    PHHIVE      Hive,
    ULONG       FileType,
    PULONG      FileOffset,
    PVOID       DataBuffer,
    ULONG       DataLength
    );

BOOLEAN
CmpFileFlush (
    PHHIVE          Hive,
    ULONG           FileType,
    PLARGE_INTEGER  FileOffset,
    ULONG           Length
    );

NTSTATUS
CmpCreateEvent(
    IN EVENT_TYPE  eventType,
    OUT PHANDLE eventHandle,
    OUT PKEVENT *event
    );


//
// Configuration Manager CM level registry functions
//

NTSTATUS
CmDeleteKey(
    IN PCM_KEY_BODY KeyBody
    );

NTSTATUS
CmDeleteValueKey(
    IN PCM_KEY_CONTROL_BLOCK KeyControlBlock,
    IN UNICODE_STRING ValueName
    );

NTSTATUS
CmEnumerateKey(
    IN PCM_KEY_CONTROL_BLOCK KeyControlBlock,
    IN ULONG Index,
    IN KEY_INFORMATION_CLASS KeyInformationClass,
    IN PVOID KeyInformation,
    IN ULONG Length,
    IN PULONG ResultLength
    );

NTSTATUS
CmEnumerateValueKey(
    IN PCM_KEY_CONTROL_BLOCK KeyControlBlock,
    IN ULONG Index,
    IN KEY_VALUE_INFORMATION_CLASS KeyValueInformationClass,
    IN PVOID KeyValueInformation,
    IN ULONG Length,
    IN PULONG ResultLength
    );

NTSTATUS
CmFlushKey(
    IN PHHIVE Hive,
    IN HCELL_INDEX Cell
    );

NTSTATUS
CmQueryKey(
    IN PCM_KEY_CONTROL_BLOCK KeyControlBlock,
    IN KEY_INFORMATION_CLASS KeyInformationClass,
    IN PVOID KeyInformation,
    IN ULONG Length,
    IN PULONG ResultLength
    );

NTSTATUS
CmQueryValueKey(
    IN PCM_KEY_CONTROL_BLOCK KeyControlBlock,
    IN UNICODE_STRING ValueName,
    IN KEY_VALUE_INFORMATION_CLASS KeyValueInformationClass,
    IN PVOID KeyValueInformation,
    IN ULONG Length,
    IN PULONG ResultLength
    );

NTSTATUS
CmQueryMultipleValueKey(
    IN PCM_KEY_CONTROL_BLOCK KeyControlBlock,
    IN PKEY_VALUE_ENTRY ValueEntries,
    IN ULONG EntryCount,
    IN PVOID ValueBuffer,
    IN OUT PULONG BufferLength,
    IN OPTIONAL PULONG ResultLength
    );

NTSTATUS
CmRenameValueKey(
    IN PCM_KEY_CONTROL_BLOCK KeyControlBlock,
    IN UNICODE_STRING SourceValueName,
    IN UNICODE_STRING TargetValueName,
    IN ULONG TargetIndex
    );

NTSTATUS
CmReplaceKey(
    IN PHHIVE Hive,
    IN HCELL_INDEX Cell,
    IN PUNICODE_STRING NewHiveName,
    IN PUNICODE_STRING OldFileName
    );

NTSTATUS
CmRestoreKey(
    IN PCM_KEY_CONTROL_BLOCK KeyControlBlock,
    IN HANDLE  FileHandle,
    IN ULONG Flags
    );

NTSTATUS
CmSaveKey(
    IN PCM_KEY_CONTROL_BLOCK    KeyControlBlock,
    IN HANDLE                   FileHandle,
    IN ULONG                    HiveVersion
    );

NTSTATUS
CmDumpKey(
    IN PCM_KEY_CONTROL_BLOCK    KeyControlBlock,
    IN HANDLE                   FileHandle
    );

NTSTATUS
CmSaveMergedKeys(
    IN PCM_KEY_CONTROL_BLOCK    HighPrecedenceKcb,
    IN PCM_KEY_CONTROL_BLOCK    LowPrecedenceKcb,
    IN HANDLE   FileHandle
    );

NTSTATUS
CmpShiftHiveFreeBins(
                      PCMHIVE           CmHive,
                      PCMHIVE           *NewHive
                      );

NTSTATUS
CmpOverwriteHive(
                    PCMHIVE         CmHive,
                    PCMHIVE         NewHive,
                    HCELL_INDEX     LinkCell
                    );

VOID
CmpSwitchStorageAndRebuildMappings(PCMHIVE  OldCmHive,
                                   PCMHIVE  NewHive
                                   );

NTSTATUS
CmSetValueKey(
    IN PCM_KEY_CONTROL_BLOCK KeyControlBlock,
    IN PUNICODE_STRING ValueName,
    IN ULONG Type,
    IN PVOID Data,
    IN ULONG DataSize
    );

NTSTATUS
CmSetLastWriteTimeKey(
    IN PCM_KEY_CONTROL_BLOCK KeyControlBlock,
    IN PLARGE_INTEGER LastWriteTime
    );

NTSTATUS
CmSetKeyUserFlags(
    IN PCM_KEY_CONTROL_BLOCK    KeyControlBlock,
    IN ULONG                    UserFlags
    );

NTSTATUS
CmpNotifyChangeKey(
    IN PCM_KEY_BODY     KeyBody,
    IN PCM_POST_BLOCK   PostBlock,
    IN ULONG            CompletionFilter,
    IN BOOLEAN          WatchTree,
    IN PVOID            Buffer,
    IN ULONG            BufferSize,
    IN PCM_POST_BLOCK   MasterPostBlock
    );

NTSTATUS
CmLoadKey(
    IN POBJECT_ATTRIBUTES TargetKey,
    IN POBJECT_ATTRIBUTES SourceFile,
    IN ULONG Flags
    );

NTSTATUS
CmUnloadKey(
    IN PHHIVE Hive,
    IN HCELL_INDEX Cell,
    IN PCM_KEY_CONTROL_BLOCK Kcb
    );

NTSTATUS
CmMoveKey(
    IN PCM_KEY_CONTROL_BLOCK    KeyControlBlock
    );

NTSTATUS
CmCompressKey(
    IN PHHIVE Hive
    );

//
// Procedures private to CM
//

BOOLEAN
CmpMarkKeyDirty(
    PHHIVE Hive,
    HCELL_INDEX Cell
#if DBG
    ,
    BOOLEAN CheckNoSubkeys
#endif
    );

BOOLEAN
CmpDoFlushAll(
    BOOLEAN ForceFlush
    );

VOID
CmpFixHiveUsageCount(
                    IN  PCMHIVE             CmHive
                    );

VOID
CmpLazyFlush(
    VOID
    );

VOID
CmpQuotaWarningWorker(
    IN PVOID WorkItem
    );

VOID
CmpComputeGlobalQuotaAllowed(
    VOID
    );

BOOLEAN
CmpClaimGlobalQuota(
    IN ULONG    Size
    );

VOID
CmpReleaseGlobalQuota(
    IN ULONG    Size
    );

VOID
CmpSetGlobalQuotaAllowed(
    VOID
    );

VOID
CmpSystemQuotaWarningWorker(
    IN PVOID WorkItem
    );

BOOLEAN
CmpCanGrowSystemHive(
                     IN PHHIVE  Hive,
                     IN ULONG   NewLength
                     );

//
// security functions (cmse.c)
//

NTSTATUS
CmpAssignSecurityDescriptor(
    IN PHHIVE Hive,
    IN HCELL_INDEX Cell,
    IN PCM_KEY_NODE Node,
    IN PSECURITY_DESCRIPTOR SecurityDescriptor
    );

BOOLEAN
CmpCheckCreateAccess(
    IN PUNICODE_STRING RelativeName,
    IN PSECURITY_DESCRIPTOR Descriptor,
    IN PACCESS_STATE AccessState,
    IN KPROCESSOR_MODE PreviousMode,
    IN ACCESS_MASK AdditionalAccess,
    OUT PNTSTATUS AccessStatus
    );

BOOLEAN
CmpCheckNotifyAccess(
    IN PCM_NOTIFY_BLOCK NotifyBlock,
    IN PHHIVE Hive,
    IN PCM_KEY_NODE Node
    );

PSECURITY_DESCRIPTOR
CmpHiveRootSecurityDescriptor(
    VOID
    );

VOID
CmpFreeSecurityDescriptor(
    IN PHHIVE Hive,
    IN HCELL_INDEX Cell
    );


//
// Access to the registry is serialized by a shared resource, CmpRegistryLock.
//
extern ERESOURCE    CmpRegistryLock;

//
// Support for "StarveExclusive" mode suring a flush
//
extern ULONG        CmpFlushStarveWriters;

#define ENTER_FLUSH_MODE()  InterlockedIncrement (&CmpFlushStarveWriters);

#if DBG
#define EXIT_FLUSH_MODE()                                                       \
{                                                                               \
    LONG LocalIncrement = (LONG)InterlockedDecrement (&CmpFlushStarveWriters);  \
    ASSERT( LocalIncrement >= 0 );                                              \
}
#else
#define EXIT_FLUSH_MODE() InterlockedDecrement (&CmpFlushStarveWriters)
#endif


#if 0
#define CmpLockRegistry() KeEnterCriticalRegion(); \
                          ExAcquireResourceShared(&CmpRegistryLock, TRUE)

#define CmpLockRegistryExclusive() KeEnterCriticalRegion(); \
                                   ExAcquireResourceExclusive(&CmpRegistryLock,TRUE)

#else
VOID
CmpLockRegistryExclusive(
    VOID
    );
VOID
CmpLockRegistry(
    VOID
    );
#endif

VOID
CmpUnlockRegistry(
    );

#if DBG
BOOLEAN
CmpTestRegistryLock(
    VOID
    );
BOOLEAN
CmpTestRegistryLockExclusive(
    VOID
    );
#endif

NTSTATUS
CmpQueryKeyData(
    PHHIVE Hive,
    PCM_KEY_NODE Node,
    KEY_INFORMATION_CLASS KeyInformationClass,
    PVOID KeyInformation,
    ULONG Length,
    PULONG ResultLength
#if defined(CMP_STATS) || defined(CMP_KCB_CACHE_VALIDATION)
    ,
    PCM_KEY_CONTROL_BLOCK   Kcb
#endif
    );

NTSTATUS
CmpQueryKeyDataFromCache(
    PCM_KEY_CONTROL_BLOCK   Kcb,
    KEY_INFORMATION_CLASS   KeyInformationClass,
    PVOID                   KeyInformation,
    ULONG                   Length,
    PULONG                  ResultLength
    );


BOOLEAN
CmpFreeKeyBody(
    PHHIVE Hive,
    HCELL_INDEX Cell
    );

BOOLEAN
CmpFreeValue(
    PHHIVE Hive,
    HCELL_INDEX Cell
    );

HCELL_INDEX
CmpFindValueByName(
    PHHIVE Hive,
    PCM_KEY_NODE KeyNode,
    PUNICODE_STRING Name
    );

NTSTATUS
CmpDeleteChildByName(
    PHHIVE  Hive,
    HCELL_INDEX Cell,
    UNICODE_STRING  Name,
    PHCELL_INDEX    ChildCell
    );

NTSTATUS
CmpFreeKeyByCell(
    PHHIVE Hive,
    HCELL_INDEX Cell,
    BOOLEAN Unlink
    );

BOOLEAN
CmpFindNameInList(
    IN PHHIVE  Hive,
    IN PCHILD_LIST ChildList,
    IN PUNICODE_STRING Name,
    IN OPTIONAL PULONG ChildIndex,
    OUT PHCELL_INDEX    CellIndex
    );

HCELL_INDEX
CmpCopyCell(
    PHHIVE  SourceHive,
    HCELL_INDEX SourceCell,
    PHHIVE  TargetHive,
    HSTORAGE_TYPE   Type
    );

HCELL_INDEX
CmpCopyValue(
    PHHIVE  SourceHive,
    HCELL_INDEX SourceValueCell,
    PHHIVE  TargetHive,
    HSTORAGE_TYPE Type
    );

HCELL_INDEX
CmpCopyKeyPartial(
    PHHIVE  SourceHive,
    HCELL_INDEX SourceKeyCell,
    PHHIVE  TargetHive,
    HCELL_INDEX Parent,
    BOOLEAN CopyValues
    );

BOOLEAN
CmpCopySyncTree(
    PHHIVE                  SourceHive,
    HCELL_INDEX             SourceCell,
    PHHIVE                  TargetHive,
    HCELL_INDEX             TargetCell,
    BOOLEAN                 CopyVolatile,
    CMP_COPY_TYPE           CopyType
    );

//
// BOOLEAN
// CmpCopyTree(
//    PHHIVE      SourceHive,
//    HCELL_INDEX SourceCell,
//    PHHIVE      TargetHive,
//    HCELL_INDEX TargetCell
//    );
//

#define CmpCopyTree(s,c,t,l) CmpCopySyncTree(s,c,t,l,FALSE,Copy)

//
// BOOLEAN
// CmpCopyTreeEx(
//    PHHIVE      SourceHive,
//    HCELL_INDEX SourceCell,
//    PHHIVE      TargetHive,
//    HCELL_INDEX TargetCell,
//    BOOLEAN     CopyVolatile
//    );
//

#define CmpCopyTreeEx(s,c,t,l,f) CmpCopySyncTree(s,c,t,l,f,Copy)

//
// BOOLEAN
// CmpSyncTrees(
//   PHHIVE      SourceHive,
//   HCELL_INDEX SourceCell,
//   PHHIVE      TargetHive,
//   HCELL_INDEX TargetCell,
//   BOOLEAN     CopyVolatile);
//

#define CmpSyncTrees(s,c,t,l,f) CmpCopySyncTree(s,c,t,l,f,Sync)


//
// BOOLEAN
// CmpMergeTrees(
//   PHHIVE      SourceHive,
//   HCELL_INDEX SourceCell,
//   PHHIVE      TargetHive,
//   HCELL_INDEX TargetCell);
//

#define CmpMergeTrees(s,c,t,l) CmpCopySyncTree(s,c,t,l,FALSE,Merge)

VOID
CmpDeleteTree(
    PHHIVE      Hive,
    HCELL_INDEX Cell
    );

VOID
CmpSetVersionData(
    VOID
    );

NTSTATUS
CmpInitializeHardwareConfiguration(
    IN PLOADER_PARAMETER_BLOCK LoaderBlock
    );

NTSTATUS
CmpInitializeMachineDependentConfiguration(
    IN PLOADER_PARAMETER_BLOCK LoaderBlock
    );

NTSTATUS
CmpInitializeRegistryNode(
    IN PCONFIGURATION_COMPONENT_DATA CurrentEntry,
    IN HANDLE ParentHandle,
    OUT PHANDLE NewHandle,
    IN INTERFACE_TYPE InterfaceType,
    IN ULONG BusNumber,
    IN PUSHORT DeviceIndexTable
    );

NTSTATUS
CmpInitializeHive(
    PCMHIVE         *CmHive,
    ULONG           OperationType,
    ULONG           HiveFlags,
    ULONG           FileType,
    PVOID           HiveData OPTIONAL,
    HANDLE          Primary,
    HANDLE          Log,
    HANDLE          External,
    PUNICODE_STRING FileName OPTIONAL,
    ULONG           CheckFlags
    );

BOOLEAN
CmpDestroyHive(
    IN PHHIVE Hive,
    IN HCELL_INDEX Cell
    );

VOID
CmpInitializeRegistryNames(
    VOID
    );

VOID
CmpInitializeCache(
    VOID
    );

PCM_KEY_CONTROL_BLOCK
CmpCreateKeyControlBlock(
    PHHIVE          Hive,
    HCELL_INDEX     Cell,
    PCM_KEY_NODE    Node,
    PCM_KEY_CONTROL_BLOCK ParentKcb,
    BOOLEAN FakeKey,
    PUNICODE_STRING KeyName
    );

VOID CmpCleanUpKCBCacheTable();

ULONG
CmpSearchForOpenSubKeys(
    IN PCM_KEY_CONTROL_BLOCK SearchKey,
    IN SUBKEY_SEARCH_TYPE SearchType
    );

VOID
CmpDereferenceKeyControlBlock(
    PCM_KEY_CONTROL_BLOCK   KeyControlBlock
    );

VOID
CmpRemoveKeyControlBlock(
    PCM_KEY_CONTROL_BLOCK   KeyControlBlock
    );

VOID
CmpReportNotify(
    PCM_KEY_CONTROL_BLOCK KeyControlBlock,
    PHHIVE          Hive,
    HCELL_INDEX     Cell,
    ULONG           NotifyMask
    );

VOID
CmpPostNotify(
    PCM_NOTIFY_BLOCK    NotifyBlock,
    PUNICODE_STRING     Name OPTIONAL,
    ULONG               Filter,
    NTSTATUS            Status,
    PLIST_ENTRY         ExternalKeyDeref OPTIONAL
#ifdef CM_NOTIFY_CHANGED_KCB_FULLPATH
    ,
    PUNICODE_STRING     ChangedKcbName OPTIONAL
#endif //CM_NOTIFY_CHANGED_KCB_FULLPATH
    );

PCM_POST_BLOCK
CmpAllocatePostBlock(
    IN POST_BLOCK_TYPE BlockType,
    IN ULONG           PostFlags,
    IN PCM_KEY_BODY    KeyBody,
    IN PCM_POST_BLOCK  MasterBlock
    );

//
//PCM_POST_BLOCK
//CmpAllocateMasterPostBlock(
//    IN POST_BLOCK_TYPE BlockType
//     );
//
#define CmpAllocateMasterPostBlock(b) CmpAllocatePostBlock(b,REG_NOTIFY_MASTER_POST,NULL,NULL)

//
//PCM_POST_BLOCK
//CmpAllocateSlavePostBlock(
//    IN POST_BLOCK_TYPE BlockType,
//    IN PCM_KEY_BODY     KeyBody,
//    IN PCM_POST_BLOCK  MasterBlock
//     );
//
#define CmpAllocateSlavePostBlock(b,k,m) CmpAllocatePostBlock(b,0,k,m)

VOID
CmpFreePostBlock(
    IN PCM_POST_BLOCK PostBlock
    );

VOID
CmpPostApc(
    struct _KAPC *Apc,
    PKNORMAL_ROUTINE *NormalRoutine,
    PVOID *NormalContext,
    PVOID *SystemArgument1,
    PVOID *SystemArgument2
    );

VOID
CmpFlushNotify(
    PCM_KEY_BODY    KeyBody
    );

VOID
CmpPostApcRunDown(
    struct _KAPC *Apc
    );

NTSTATUS
CmpOpenHiveFiles(
    PUNICODE_STRING     BaseName,
    PWSTR               Extension OPTIONAL,
    PHANDLE             Primary,
    PHANDLE             Secondary,
    PULONG              PrimaryDisposition,
    PULONG              SecondaryDispoition,
    BOOLEAN             CreateAllowed,
    BOOLEAN             MarkAsSystemHive,
    BOOLEAN             NoBuffering,
    PULONG              ClusterSize
    );

NTSTATUS
CmpLinkHiveToMaster(
    PUNICODE_STRING LinkName,
    HANDLE RootDirectory,
    PCMHIVE CmHive,
    BOOLEAN Allocate,
    PSECURITY_DESCRIPTOR SecurityDescriptor
    );

NTSTATUS
CmpSaveBootControlSet(
     IN USHORT ControlSetNum
     );

//
// checkout procedure
//

//
// Flags to be passed to CmCheckRegistry
//
#define     CM_CHECK_REGISTRY_CHECK_CLEAN       0x00000001
#define     CM_CHECK_REGISTRY_FORCE_CLEAN       0x00000002
#define     CM_CHECK_REGISTRY_LOADER_CLEAN      0x00000004
#define     CM_CHECK_REGISTRY_SYSTEM_CLEAN      0x00000008
#define     CM_CHECK_REGISTRY_HIVE_CHECK        0x00010000

ULONG
CmCheckRegistry(
    PCMHIVE CmHive,
    ULONG   Flags
    );

BOOLEAN
CmpValidateHiveSecurityDescriptors(
    IN PHHIVE       Hive,
    OUT PBOOLEAN    ResetSD
    );

//
// cmboot - functions for determining driver load lists
//

#define CM_HARDWARE_PROFILE_STR_DATABASE L"\\Registry\\Machine\\System\\CurrentControlSet\\Control\\IDConfigDB"
#define CM_HARDWARE_PROFILE_STR_CCS_HWPROFILE L"\\Registry\\Machine\\System\\CurrentControlSet\\Hardware Profiles"
#define CM_HARDWARE_PROFILE_STR_CCS_CURRENT L"\\Registry\\Machine\\System\\CurrentControlSet\\Hardware Profiles\\Current"
//
// Alias table key names in IDConfigDB
//
#define CM_HARDWARE_PROFILE_STR_ALIAS L"Alias"
#define CM_HARDWARE_PROFILE_STR_ACPI_ALIAS L"AcpiAlias"
#define CM_HARDWARE_PROFILE_STR_HARDWARE_PROFILES L"Hardware Profiles"

//
// Entries in the alias tables (value names)
//
#define CM_HARDWARE_PROFILE_STR_DOCKING_STATE L"DockingState"
#define CM_HARDWARE_PROFILE_STR_CAPABILITIES L"Capabilities"
#define CM_HARDWARE_PROFILE_STR_DOCKID L"DockID"
#define CM_HARDWARE_PROFILE_STR_SERIAL_NUMBER L"SerialNumber"
#define CM_HARDWARE_PROFILE_STR_ACPI_SERIAL_NUMBER L"AcpiSerialNumber"
#define CM_HARDWARE_PROFILE_STR_PROFILE_NUMBER L"ProfileNumber"
#define CM_HARDWARE_PROFILE_STR_ALIASABLE L"Aliasable"
#define CM_HARDWARE_PROFILE_STR_CLONED L"Cloned"
//
// Entries in the profile tables.
//
#define CM_HARDWARE_PROFILE_STR_PRISTINE L"Pristine"
#define CM_HARDWARE_PROFILE_STR_PREFERENCE_ORDER L"PreferenceOrder"
#define CM_HARDWARE_PROFILE_STR_FRIENDLY_NAME L"FriendlyName"
#define CM_HARDWARE_PROFILE_STR_CURRENT_DOCK_INFO L"CurrentDockInfo"
#define CM_HARDWARE_PROFILE_STR_HW_PROFILE_GUID L"HwProfileGuid"
//
// Entries for the root Hardware Profiles key.
//
#define CM_HARDWARE_PROFILE_STR_DOCKED L"Docked"
#define CM_HARDWARE_PROFILE_STR_UNDOCKED L"Undocked"
#define CM_HARDWARE_PROFILE_STR_UNKNOWN L"Unknown"

//
// List structure used in config manager init
//

typedef struct _HIVE_LIST_ENTRY {
    PWSTR       Name;
    PWSTR       BaseName;                       // MACHINE or USER
    PCMHIVE     CmHive;
    ULONG       Flags;
    PCMHIVE     CmHive2;
    BOOLEAN     ThreadFinished;
    BOOLEAN     ThreadStarted;
    BOOLEAN     Allocate;
} HIVE_LIST_ENTRY, *PHIVE_LIST_ENTRY;

//
// structure definitions shared with the boot loader
// to select the hardware profile.
//
typedef struct _CM_HARDWARE_PROFILE {
    ULONG   NameLength;
    PWSTR   FriendlyName;
    ULONG   PreferenceOrder;
    ULONG   Id;
    ULONG   Flags;
} CM_HARDWARE_PROFILE, *PCM_HARDWARE_PROFILE;

#define CM_HP_FLAGS_ALIASABLE  1
#define CM_HP_FLAGS_TRUE_MATCH 2
#define CM_HP_FLAGS_PRISTINE   4
#define CM_HP_FLAGS_DUPLICATE  8

typedef struct _CM_HARDWARE_PROFILE_LIST {
    ULONG MaxProfileCount;
    ULONG CurrentProfileCount;
    CM_HARDWARE_PROFILE Profile[1];
} CM_HARDWARE_PROFILE_LIST, *PCM_HARDWARE_PROFILE_LIST;

typedef struct _CM_HARDWARE_PROFILE_ALIAS {
    ULONG   ProfileNumber;
    ULONG   DockState;
    ULONG   DockID;
    ULONG   SerialNumber;
} CM_HARDWARE_PROFILE_ALIAS, *PCM_HARDWARE_PROFILE_ALIAS;

typedef struct _CM_HARDWARE_PROFILE_ALIAS_LIST {
    ULONG MaxAliasCount;
    ULONG CurrentAliasCount;
    CM_HARDWARE_PROFILE_ALIAS Alias[1];
} CM_HARDWARE_PROFILE_ALIAS_LIST, *PCM_HARDWARE_PROFILE_ALIAS_LIST;

typedef struct _CM_HARDWARE_PROFILE_ACPI_ALIAS {
    ULONG   ProfileNumber;
    ULONG   DockState;
    ULONG   SerialLength;
    PCHAR   SerialNumber;
} CM_HARDWARE_PROFILE_ACPI_ALIAS, *PCM_HARDWARE_PROFILE_ACPI_ALIAS;

typedef struct _CM_HARDWARE_PROFILE_ACPI_ALIAS_LIST {
    ULONG   MaxAliasCount;
    ULONG   CurrentAliasCount;
    CM_HARDWARE_PROFILE_ACPI_ALIAS Alias[1];
} CM_HARDWARE_PROFILE_ACPI_ALIAS_LIST, *PCM_HARDWARE_PROFILE_ACPI_ALIAS_LIST;

HCELL_INDEX
CmpFindControlSet(
     IN PHHIVE SystemHive,
     IN HCELL_INDEX RootCell,
     IN PUNICODE_STRING SelectName,
     OUT PBOOLEAN AutoSelect
     );

BOOLEAN
CmpValidateSelect(
     IN PHHIVE SystemHive,
     IN HCELL_INDEX RootCell
     );

BOOLEAN
CmpFindDrivers(
    IN PHHIVE Hive,
    IN HCELL_INDEX ControlSet,
    IN SERVICE_LOAD_TYPE LoadType,
    IN PWSTR BootFileSystem OPTIONAL,
    IN PLIST_ENTRY DriverListHead
    );

BOOLEAN
CmpFindNLSData(
    IN PHHIVE Hive,
    IN HCELL_INDEX ControlSet,
    OUT PUNICODE_STRING AnsiFilename,
    OUT PUNICODE_STRING OemFilename,
    OUT PUNICODE_STRING CaseTableFilename,
    OUT PUNICODE_STRING OemHalFilename
    );

HCELL_INDEX
CmpFindProfileOption(
    IN PHHIVE Hive,
    IN HCELL_INDEX ControlSet,
    OUT PCM_HARDWARE_PROFILE_LIST *ProfileList,
    OUT PCM_HARDWARE_PROFILE_ALIAS_LIST *AliasList,
    OUT PULONG Timeout
    );

VOID
CmpSetCurrentProfile(
    IN PHHIVE Hive,
    IN HCELL_INDEX ControlSet,
    IN PCM_HARDWARE_PROFILE Profile
    );

BOOLEAN
CmpResolveDriverDependencies(
    IN PLIST_ENTRY DriverListHead
    );

BOOLEAN
CmpSortDriverList(
    IN PHHIVE Hive,
    IN HCELL_INDEX ControlSet,
    IN PLIST_ENTRY DriverListHead
    );

HCELL_INDEX
CmpFindSubKeyByName(
    PHHIVE          Hive,
    PCM_KEY_NODE    Parent,
    PUNICODE_STRING SearchName
    );

HCELL_INDEX
CmpFindSubKeyByNumber(
    PHHIVE          Hive,
    PCM_KEY_NODE    Parent,
    ULONG           Number
    );

BOOLEAN
CmpAddSubKey(
    PHHIVE          Hive,
    HCELL_INDEX     Parent,
    HCELL_INDEX     Child
    );

BOOLEAN
CmpMarkIndexDirty(
    PHHIVE          Hive,
    HCELL_INDEX     ParentKey,
    HCELL_INDEX     TargetKey
    );

BOOLEAN
CmpRemoveSubKey(
    PHHIVE          Hive,
    HCELL_INDEX     ParentKey,
    HCELL_INDEX     TargetKey
    );

BOOLEAN
CmpGetNextName(
    IN OUT PUNICODE_STRING  RemainingName,
    OUT    PUNICODE_STRING  NextName,
    OUT    PBOOLEAN  Last
    );

NTSTATUS
CmpAddToHiveFileList(
    PCMHIVE CmHive
    );

VOID
CmpRemoveFromHiveFileList(
    );

NTSTATUS
CmpInitHiveFromFile(
    IN PUNICODE_STRING FileName,
    IN ULONG HiveFlags,
    OUT PCMHIVE *CmHive,
    IN OUT PBOOLEAN Allocate,
    IN OUT PBOOLEAN RegistryLocked,
    IN  ULONG       CheckFlags
    );

NTSTATUS
CmpCloneHwProfile (
    IN HANDLE IDConfigDB,
    IN HANDLE Parent,
    IN HANDLE OldProfile,
    IN ULONG  OldProfileNumber,
    IN USHORT DockingState,
    OUT PHANDLE NewProfile,
    OUT PULONG  NewProfileNumber
    );

NTSTATUS
CmpCreateHwProfileFriendlyName (
    IN HANDLE IDConfigDB,
    IN ULONG  DockingState,
    IN ULONG  NewProfileNumber,
    OUT PUNICODE_STRING FriendlyName
    );

typedef
NTSTATUS
(*PCM_ACPI_SELECTION_ROUTINE) (
    IN  PCM_HARDWARE_PROFILE_LIST ProfileList,
    OUT PULONG ProfileIndexToUse, // Set to -1 for none.
    IN  PVOID Context
    );

NTSTATUS
CmSetAcpiHwProfile (
    IN  PPROFILE_ACPI_DOCKING_STATE DockState,
    IN  PCM_ACPI_SELECTION_ROUTINE,
    IN  PVOID Context,
    OUT PHANDLE NewProfile,
    OUT PBOOLEAN ProfileChanged
    );

NTSTATUS
CmpAddAcpiAliasEntry (
    IN HANDLE                       IDConfigDB,
    IN PPROFILE_ACPI_DOCKING_STATE  NewDockState,
    IN ULONG                        ProfileNumber,
    IN PWCHAR                       nameBuffer,
    IN PVOID                        valueBuffer,
    IN ULONG                        valueBufferLength,
    IN BOOLEAN                      PreventDuplication
    );

//
// Routines for handling registry compressed names
//
USHORT
CmpNameSize(
    IN PHHIVE Hive,
    IN PUNICODE_STRING Name
    );

USHORT
CmpCopyName(
    IN PHHIVE Hive,
    IN PWCHAR Destination,
    IN PUNICODE_STRING Source
    );

VOID
CmpCopyCompressedName(
    IN PWCHAR Destination,
    IN ULONG DestinationLength,
    IN PWCHAR Source,
    IN ULONG SourceLength
    );

USHORT
CmpCompressedNameSize(
    IN PWCHAR Name,
    IN ULONG Length
    );


//
// ----- CACHED_DATA -----
//
// When values are not cached, List in ValueCache is the Hive cell index to the value list.
// When they are cached, List will be pointer to the allocation.  We distinguish them by
// marking the lowest bit in the variable to indicate it is a cached allocation.
//
// Note that the cell index for value list
// is stored in the cached allocation.  It is not used now but may be in further performance
// optimization.
//
// When value key and vaule data are cached, there is only one allocation for both.
// Value data is appended that the end of value key.  DataCacheType indicates
// whether data is cached and ValueKeySize tells how big is the value key (so
// we can calculate the address of cached value data)
//
//

PCM_NAME_CONTROL_BLOCK
CmpGetNameControlBlock(
    PUNICODE_STRING NodeName
    );

VOID
CmpDereferenceKeyControlBlockWithLock(
    PCM_KEY_CONTROL_BLOCK   KeyControlBlock
    );

VOID
CmpCleanUpSubKeyInfo(
    PCM_KEY_CONTROL_BLOCK   KeyControlBlock
    );

VOID
CmpCleanUpKcbValueCache(
    PCM_KEY_CONTROL_BLOCK   KeyControlBlock
    );


VOID
CmpRebuildKcbCache(
    PCM_KEY_CONTROL_BLOCK   KeyControlBlock
    );



/*
VOID
CmpSetUpKcbValueCache(
    PCM_KEY_CONTROL_BLOCK   KeyControlBlock,
    ULONG                   Count,
    ULONG_PTR               ValueList
    )
*/
#define CmpSetUpKcbValueCache(KeyControlBlock,_Count,_List)                 \
    ASSERT( !(CMP_IS_CELL_CACHED(KeyControlBlock->ValueCache.ValueList)) ); \
    ASSERT( !(KeyControlBlock->ExtFlags & CM_KCB_SYM_LINK_FOUND) );         \
    KeyControlBlock->ValueCache.Count = (ULONG)(_Count);                    \
    KeyControlBlock->ValueCache.ValueList = (ULONG_PTR)(_List)


VOID
CmpCleanUpKcbCacheWithLock(
    PCM_KEY_CONTROL_BLOCK   KeyControlBlock
    );

VOID
CmpRemoveFromDelayedClose(
    IN PCM_KEY_CONTROL_BLOCK kcb
    );

PUNICODE_STRING
CmpConstructName(
    PCM_KEY_CONTROL_BLOCK kcb
);

PCELL_DATA
CmpGetValueListFromCache(
    IN PHHIVE  Hive,
    IN PCACHED_CHILD_LIST ChildList,
    IN OUT BOOLEAN    *IndexCached
);

PCM_KEY_VALUE
CmpGetValueKeyFromCache(
    IN PHHIVE         Hive,
    IN PCELL_DATA     List,
    IN ULONG          Index,
    OUT PPCM_CACHED_VALUE *ContainingList,
    IN BOOLEAN        IndexCached,
    OUT BOOLEAN         *ValueCached,
    OUT PHCELL_INDEX    CellToRelease
);

PCM_KEY_VALUE
CmpFindValueByNameFromCache(
    IN PHHIVE  Hive,
    IN PCACHED_CHILD_LIST ChildList,
    IN PUNICODE_STRING Name,
    OUT PPCM_CACHED_VALUE *ContainingList,
    OUT ULONG *Index,
    OUT BOOLEAN             *ValueCached,
    OUT PHCELL_INDEX        CellToRelease
    );

NTSTATUS
CmpQueryKeyValueData(
    PHHIVE Hive,
    PCM_CACHED_VALUE *ContainingList,
    PCM_KEY_VALUE ValueKey,
    BOOLEAN       ValueCached,
    KEY_VALUE_INFORMATION_CLASS KeyValueInformationClass,
    PVOID KeyValueInformation,
    ULONG Length,
    PULONG ResultLength
    );

BOOLEAN
CmpReferenceKeyControlBlock(
    PCM_KEY_CONTROL_BLOCK   KeyControlBlock
    );

VOID
CmpInitializeKeyNameString(PCM_KEY_NODE Cell,
                           PUNICODE_STRING KeyName,
                           WCHAR *NameBuffer
                           );

VOID
CmpInitializeValueNameString(PCM_KEY_VALUE Cell,
                             PUNICODE_STRING ValueName,
                             WCHAR *NameBuffer
                             );

VOID
CmpFlushNotifiesOnKeyBodyList(
    IN PCM_KEY_CONTROL_BLOCK   kcb
    );

#ifdef CM_NOTIFY_CHANGED_KCB_FULLPATH
VOID
CmpFillCallerBuffer(
                    PCM_POST_BLOCK  PostBlock,
                    PUNICODE_STRING ChangedKcbName
                    );
#endif //CM_NOTIFY_CHANGED_KCB_FULLPATH

extern ULONG CmpHashTableSize;
extern PCM_KEY_HASH *CmpCacheTable;

#ifdef _WANT_MACHINE_IDENTIFICATION

BOOLEAN
CmpGetBiosDateFromRegistry(
    IN PHHIVE Hive,
    IN HCELL_INDEX ControlSet,
    OUT PUNICODE_STRING Date
    );

BOOLEAN
CmpGetBiosinfoFileNameFromRegistry(
    IN PHHIVE Hive,
    IN HCELL_INDEX ControlSet,
    OUT PUNICODE_STRING InfName
    );


#endif

// Utility macro to set the fields of an IO_STATUS_BLOCK.  On sundown, 32bit processes
// will pass in a 32bit Iosb, and 64bit processes will pass in a 64bit Iosb.
#if defined(_WIN64)

#define CmpSetIoStatus(Iosb, s, i, UseIosb32)                              \
if ((UseIosb32)) {                                                         \
    ((PIO_STATUS_BLOCK32)(Iosb))->Status = (NTSTATUS)(s);                  \
    ((PIO_STATUS_BLOCK32)(Iosb))->Information = (ULONG)(i);                \
}                                                                          \
else {                                                                     \
    (Iosb)->Status = (s);                                                  \
    (Iosb)->Information = (i);                                             \
}                                                                          \

#else

#define CmpSetIoStatus(Iosb, s, i, UseIosb32)                              \
(Iosb)->Status = (s);                                                      \
(Iosb)->Information = (i);                                                 \

#endif



// Dragos: new functions (prototyping)

NTSTATUS
CmpAquireFileObjectForFile(
        IN  PCMHIVE         CmHive,
        IN HANDLE           FileHandle,
        OUT PFILE_OBJECT    *FileObject
            );

VOID
CmpDropFileObjectForHive(
        IN  PCMHIVE             CmHive
            );

VOID
CmpTouchView(
    IN PCMHIVE              CmHive,
    IN PCM_VIEW_OF_FILE     CmView,
    IN ULONG                Cell
            );

NTSTATUS
CmpMapCmView(
    IN  PCMHIVE             CmHive,
    IN  ULONG               FileOffset,
    OUT PCM_VIEW_OF_FILE    *CmView,
    IN  BOOLEAN             MapInited
    );

VOID
CmpInitHiveViewList (
        IN  PCMHIVE             CmHive
                             );

VOID
CmpDestroyHiveViewList (
        IN  PCMHIVE             CmHive
                             );

NTSTATUS
CmpPinCmView (
        IN  PCMHIVE             CmHive,
        PCM_VIEW_OF_FILE        CmView
                             );
VOID
CmpUnPinCmView (
        IN  PCMHIVE             CmHive,
        IN  PCM_VIEW_OF_FILE    CmView,
        IN  BOOLEAN             SetClean,
        IN  BOOLEAN             MapIsValid
                             );

NTSTATUS
CmpMapThisBin(
                PCMHIVE         CmHive,
                HCELL_INDEX     Cell,
                BOOLEAN         Touch
              );
#if 0
VOID
CmpUnmapAditionalViews(
    IN PCMHIVE              CmHive
    );

VOID
CmpUnmapFakeViews(
    IN PCMHIVE              CmHive
    );

VOID
CmpMapEntireFileInFakeViews(
    IN PCMHIVE              CmHive,
    IN ULONG                Length
    );

#endif

VOID
CmpInitializeDelayedCloseTable();

VOID
CmpAddToDelayedClose(
    IN PCM_KEY_CONTROL_BLOCK kcb
    );

NTSTATUS
CmpAddValueToList(
    IN PHHIVE  Hive,
    IN HCELL_INDEX ValueCell,
    IN ULONG Index,
    IN ULONG Type,
    IN OUT PCHILD_LIST ChildList
    );

NTSTATUS
CmpRemoveValueFromList(
    IN PHHIVE  Hive,
    IN ULONG Index,
    IN OUT PCHILD_LIST ChildList
    );

BOOLEAN
CmpGetValueData(IN PHHIVE Hive,
                IN PCM_KEY_VALUE Value,
                OUT PULONG realsize,
                IN OUT PVOID *Buffer,
                OUT PBOOLEAN Allocated,
                OUT PHCELL_INDEX CellToRelease
               );

PCELL_DATA
CmpValueToData(IN PHHIVE Hive,
               IN PCM_KEY_VALUE Value,
               OUT PULONG realsize
               );

BOOLEAN
CmpMarkValueDataDirty(  IN PHHIVE Hive,
                        IN PCM_KEY_VALUE Value
                      );

NTSTATUS
CmpSetValueDataNew(
    IN PHHIVE           Hive,
    IN PVOID            Data,
    IN ULONG            DataSize,
    IN ULONG            StorageType,
    IN HCELL_INDEX      ValueCell,
    OUT PHCELL_INDEX    DataCell
    );

NTSTATUS
CmpSetValueDataExisting(
    IN PHHIVE           Hive,
    IN PVOID            Data,
    IN ULONG            DataSize,
    IN ULONG            StorageType,
    IN HCELL_INDEX      OldDataCell
    );

BOOLEAN
CmpFreeValueData(
    PHHIVE      Hive,
    HCELL_INDEX DataCell,
    ULONG       DataLength
    );


NTSTATUS
CmpAddSecurityCellToCache (
    IN OUT PCMHIVE      CmHive,
    IN HCELL_INDEX      SecurityCell,
    IN BOOLEAN          BuildUp
    );

BOOLEAN
CmpFindSecurityCellCacheIndex (
    IN PCMHIVE      CmHive,
    IN HCELL_INDEX  SecurityCell,
    OUT PULONG      Index
    );

BOOLEAN
CmpAdjustSecurityCacheSize (
    IN PCMHIVE      CmHive
    );

VOID
CmpRemoveFromSecurityCache (
    IN OUT PCMHIVE      CmHive,
    IN HCELL_INDEX      SecurityCell
    );

VOID
CmpDestroySecurityCache (
    IN OUT PCMHIVE      CmHive
    );


VOID
CmpInitSecurityCache(
    IN OUT PCMHIVE      CmHive
    );

BOOLEAN
CmpRebuildSecurityCache(
                        IN OUT PCMHIVE      CmHive
                        );

ULONG
CmpSecConvKey(
              IN ULONG  DescriptorLength,
              IN PULONG Descriptor
              );

VOID
CmpAssignSecurityToKcb(
    IN PCM_KEY_CONTROL_BLOCK    Kcb,
    IN HCELL_INDEX              SecurityCell
    );

BOOLEAN
CmpBuildSecurityCellMappingArray(
    IN PCMHIVE CmHive
    );


//
// new function replacing CmpWorker
//
VOID
CmpCmdHiveClose(
                     PCMHIVE    CmHive
                     );

VOID
CmpCmdInit(
           BOOLEAN SetupBoot
            );

NTSTATUS
CmpCmdRenameHive(
            PCMHIVE                     CmHive,
            POBJECT_NAME_INFORMATION    OldName,
            PUNICODE_STRING             NewName,
            ULONG                       NameInfoLength
            );

NTSTATUS
CmpCmdHiveOpen(
            POBJECT_ATTRIBUTES          FileAttributes,
            PSECURITY_CLIENT_CONTEXT    ImpersonationContext,
            PBOOLEAN                    Allocate,
            PBOOLEAN                    RegistryLockAquired,
            PCMHIVE                     *NewHive,
            ULONG                       CheckFlags
            );

#ifdef NT_RENAME_KEY
HCELL_INDEX
CmpDuplicateIndex(
    PHHIVE          Hive,
    HCELL_INDEX     IndexCell,
    ULONG           StorageType
    );

NTSTATUS
CmRenameKey(
    IN PCM_KEY_CONTROL_BLOCK    KeyControlBlock,
    IN UNICODE_STRING           NewKeyName
    );

BOOLEAN
CmpUpdateParentForEachSon(
    PHHIVE          Hive,
    HCELL_INDEX     Parent
    );
#endif //NT_RENAME_KEY

#ifdef NT_UNLOAD_KEY_EX
NTSTATUS
CmUnloadKeyEx(
    IN PCM_KEY_CONTROL_BLOCK Kcb,
    IN PKEVENT UserEvent
    );
#endif //NT_UNLOAD_KEY_EX

VOID
CmpShutdownWorkers(
    VOID
    );

VOID
CmpPrefetchHiveFile(
                    IN PFILE_OBJECT FileObject,
                    IN ULONG        Length
                    );

#ifdef CM_CHECK_FOR_ORPHANED_KCBS
VOID
CmpCheckForOrphanedKcbs(
    PHHIVE          Hive
    );
#else

#define CmpCheckForOrphanedKcbs(Hive) //nothing
#endif //CM_CHECK_FOR_ORPHANED_KCBS

#define CM_HIVE_COMPRESS_LEVEL   (25)


#define CMP_MAX_REGISTRY_DEPTH      512        // levels

typedef struct {
    HCELL_INDEX Cell;
    HCELL_INDEX ParentCell;
    ULONG       ChildIndex;
    BOOLEAN     CellChecked;
} CMP_CHECK_REGISTRY_STACK_ENTRY, *PCMP_CHECK_REGISTRY_STACK_ENTRY;


#define CmIsKcbReadOnly(kcb)        ((kcb)->ExtFlags & CM_KCB_READ_ONLY_KEY)

NTSTATUS
CmLockKcbForWrite(PCM_KEY_CONTROL_BLOCK KeyControlBlock);

//
// Wrapper to RtlCompareUnicodeString; uses CompareFlags to avoid upcasing names
//

#define CMP_SOURCE_UP       0x00000001
#define CMP_DEST_UP         0x00000002

LONG
CmpCompareUnicodeString(
    IN PUNICODE_STRING  SourceName,
    IN PUNICODE_STRING  DestName,
    IN ULONG            CompareFlags
    );

LONG
CmpCompareCompressedName(
    IN PUNICODE_STRING  SearchName,
    IN PWCHAR           CompressedName,
    IN ULONG            NameLength,
    IN ULONG            CompareFlags
    );

#define INIT_SYSTEMROOT_HIVEPATH L"\\SystemRoot\\System32\\Config\\"


ULONG
CmpComputeHashKey(
    PUNICODE_STRING Name
    );


ULONG
CmpComputeHashKeyForCompressedName(
                                    IN PWCHAR Source,
                                    IN ULONG SourceLength
                                    );
//
// KCB allocator routines
//
VOID CmpInitCmPrivateAlloc();
VOID CmpDestroyCmPrivateAlloc();
PCM_KEY_CONTROL_BLOCK CmpAllocateKeyControlBlock( );
VOID CmpFreeKeyControlBlock( PCM_KEY_CONTROL_BLOCK kcb );


//
// make handles protected, so we control handle closure
//

#define CmpSetHandleProtection(Handle,Protection)                       \
{                                                                       \
    OBJECT_HANDLE_FLAG_INFORMATION  Ohfi = {    FALSE,                  \
                                                FALSE                   \
                                            };                          \
    Ohfi.ProtectFromClose = Protection;                                 \
    ZwSetInformationObject( Handle,                                     \
                            ObjectHandleFlagInformation,                \
                            &Ohfi,                                      \
                            sizeof (OBJECT_HANDLE_FLAG_INFORMATION));   \
}

#define CmCloseHandle(Handle)               \
    CmpSetHandleProtection(Handle,FALSE);   \
    ZwClose(Handle)


VOID
CmpUpdateSystemHiveHysteresis(  PHHIVE  Hive,
                                ULONG   NewLength,
                                ULONG   OldLength
                                );

NTSTATUS
CmpCallCallBacks (
    IN REG_NOTIFY_CLASS Type,
    IN PVOID Argument
    );

extern ULONG CmpCallBackCount;

#define CmAreCallbacksRegistered() (CmpCallBackCount != 0)
//
// Self healing hives control switch
//
extern BOOLEAN  CmpSelfHeal;
extern ULONG    CmpBootType;

#define CmDoSelfHeal() (CmpSelfHeal || (CmpBootType & (HBOOT_BACKUP|HBOOT_SELFHEAL)))

#ifndef _CM_LDR_
#if DBG
#define CmMarkSelfHeal(Hive) ( (Hive)->BaseBlock->BootType |= HBOOT_SELFHEAL ); \
                             DbgBreakPoint()   
#else
#define CmMarkSelfHeal(Hive) ( (Hive)->BaseBlock->BootType |= HBOOT_SELFHEAL )
#endif
#else
#define CmMarkSelfHeal(Hive) ( (Hive)->BaseBlock->BootType |= HBOOT_SELFHEAL )
#endif

BOOLEAN
CmpRemoveSubKeyCellNoCellRef(
    PHHIVE          Hive,
    HCELL_INDEX     Parent,
    HCELL_INDEX     Child
    );

VOID 
CmpRaiseSelfHealWarning( 
                        IN PUNICODE_STRING  HiveName
                        );

VOID 
CmpRaiseSelfHealWarningForSystemHives();

//
// Mini NT boot indicator
//
extern BOOLEAN CmpMiniNTBoot;
extern BOOLEAN CmpShareSystemHives;

#endif //_CMP_
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\base\ntos\config\cmparse2.c ===
/*++

Copyright (c) 1991  Microsoft Corporation

Module Name:

    cmparse2.c

Abstract:

    This module contains parse routines for the configuration manager, particularly
    the registry.

Author:

    Bryan M. Willman (bryanwi) 10-Sep-1991

Revision History:

--*/

#include    "cmp.h"

#ifdef ALLOC_PRAGMA
#pragma alloc_text(PAGE,CmpDoCreate)
#pragma alloc_text(PAGE,CmpDoCreateChild)
#endif

extern  PCM_KEY_CONTROL_BLOCK CmpKeyControlBlockRoot;


NTSTATUS
CmpDoCreate(
    IN PHHIVE Hive,
    IN HCELL_INDEX Cell,
    IN PACCESS_STATE AccessState,
    IN PUNICODE_STRING Name,
    IN KPROCESSOR_MODE AccessMode,
    IN PCM_PARSE_CONTEXT Context,
    IN PCM_KEY_CONTROL_BLOCK ParentKcb,
    OUT PVOID *Object
    )
/*++

Routine Description:

    Performs the first step in the creation of a registry key.  This
    routine checks to make sure the caller has the proper access to
    create a key here, and allocates space for the child in the parent
    cell.  It then calls CmpDoCreateChild to initialize the key and
    create the key object.

    This two phase creation allows us to share the child creation code
    with the creation of link nodes.

Arguments:

    Hive - supplies a pointer to the hive control structure for the hive

    Cell - supplies index of node to create child under.

    AccessState - Running security access state information for operation.

    Name - supplies pointer to a UNICODE string which is the name of
            the child to be created.

    AccessMode - Access mode of the original caller.

    Context - pointer to CM_PARSE_CONTEXT structure passed through
                the object manager

    BaseName - Name of object create is relative to

    KeyName - Relative name (to BaseName)

    Object - The address of a variable to receive the created key object, if
             any.

Return Value:

    NTSTATUS

--*/
{
    NTSTATUS                status;
    PCELL_DATA              pdata;
    HCELL_INDEX             KeyCell;
    ULONG                   ParentType;
    ACCESS_MASK             AdditionalAccess;
    BOOLEAN                 CreateAccess;
    PCM_KEY_BODY            KeyBody;
    PSECURITY_DESCRIPTOR    SecurityDescriptor;
    LARGE_INTEGER           TimeStamp;
    BOOLEAN                 BackupRestore;
    KPROCESSOR_MODE         mode;
    PCM_KEY_NODE            ParentNode;

#ifdef CMP_KCB_CACHE_VALIDATION
    //
    // we this only for debug validation purposes. We shall delete it even
    // for debug code after we make sure it works OK.
    //
    ULONG                   Index;
#endif //CMP_KCB_CACHE_VALIDATION

    CmKdPrintEx((DPFLTR_CONFIG_ID,CML_PARSE,"CmpDoCreate:\n"));

    BackupRestore = FALSE;
    if (ARGUMENT_PRESENT(Context)) {

        if (Context->CreateOptions & REG_OPTION_BACKUP_RESTORE) {

            //
            // allow backup operators to create new keys
            //
            BackupRestore = TRUE;
        }

        //
        // Operation is a create, so set Disposition
        //
        Context->Disposition = REG_CREATED_NEW_KEY;
    }

/*
    //
    // this is a create, so we need exclusive access on the registry
    // first get the time stamp to see if somebody messed with this key
    // this might be more easier if we decide to cache the LastWriteTime
    // in the KCB ; now it IS !!!
    //
    TimeStamp = ParentKcb->KcbLastWriteTime;
*/
    if( CmIsKcbReadOnly(ParentKcb) ) {
        //
        // key is protected
        //
        return STATUS_ACCESS_DENIED;
    } 

    CmpUnlockRegistry();
    CmpLockRegistryExclusive();

#ifdef CHECK_REGISTRY_USECOUNT
    CmpCheckRegistryUseCount();
#endif //CHECK_REGISTRY_USECOUNT

    //
    // make sure nothing changed in between:
    //  1. ParentKcb is still valid
    //  2. Child was not already added by somebody else
    //
    if( ParentKcb->Delete ) {
        //
        // key was deleted in between
        //
        return STATUS_OBJECT_NAME_NOT_FOUND;
    }

/*
Apparently KeQuerySystemTime doesn't give us a fine resolution to copunt on
    //
    // we need to read the parent again (because of the mapping view stuff !)
    //
    if( TimeStamp.QuadPart != ParentKcb->KcbLastWriteTime.QuadPart ) {
        //
        // key was changed in between; possibly this key was already created ==> reparse
        //
        return STATUS_REPARSE;
    }
*/
    //
    // apparently, the KeQuerySystemTime doesn't give us a fine resolution
    // so we have to search if the child has not been created already
    //
    ParentNode = (PCM_KEY_NODE)HvGetCell(Hive, Cell);
    if( ParentNode == NULL ) {
        //
        // we couldn't map the bin containing this cell
        //
        return STATUS_INSUFFICIENT_RESOURCES;
    }

    // release the cell right here as we are holding the reglock exclusive
    HvReleaseCell(Hive,Cell);

    if( CmpFindSubKeyByName(Hive,ParentNode,Name) != HCELL_NIL ) {
        //
        // key was changed in between; possibly this key was already created ==> reparse
        //
#ifdef CHECK_REGISTRY_USECOUNT
        CmpCheckRegistryUseCount();
#endif //CHECK_REGISTRY_USECOUNT
        return STATUS_REPARSE;
    }


    ASSERT( Cell == ParentKcb->KeyCell );

#ifdef CMP_KCB_CACHE_VALIDATION
    //
    // Check to make sure the caller can create a sub-key here.
    //
    //
    // get the security descriptor from cache
    //
    if( CmpFindSecurityCellCacheIndex ((PCMHIVE)Hive,ParentNode->Security,&Index) == FALSE ) {
#ifdef CHECK_REGISTRY_USECOUNT
        CmpCheckRegistryUseCount();
#endif //CHECK_REGISTRY_USECOUNT
        return STATUS_INSUFFICIENT_RESOURCES;
    }

    ASSERT( ((PCMHIVE)Hive)->SecurityCache[Index].Cell == ParentNode->Security );
    ASSERT( ((PCMHIVE)Hive)->SecurityCache[Index].CachedSecurity == ParentKcb->CachedSecurity );

#endif //CMP_KCB_CACHE_VALIDATION

    ASSERT( ParentKcb->CachedSecurity != NULL );
    SecurityDescriptor = &(ParentKcb->CachedSecurity->Descriptor);

    ParentType = HvGetCellType(Cell);

    if ( (ParentType == Volatile) &&
         ((Context->CreateOptions & REG_OPTION_VOLATILE) == 0) )
    {
        //
        // Trying to create stable child under volatile parent, report error
        //
#ifdef CHECK_REGISTRY_USECOUNT
        CmpCheckRegistryUseCount();
#endif //CHECK_REGISTRY_USECOUNT
        return STATUS_CHILD_MUST_BE_VOLATILE;
    }

#ifdef CMP_KCB_CACHE_VALIDATION
    ASSERT( ParentNode->Flags == ParentKcb->Flags );
#endif //CMP_KCB_CACHE_VALIDATION

    if (ParentKcb->Flags &   KEY_SYM_LINK) {
        //
        // Disallow attempts to create anything under a symbolic link
        //
#ifdef CHECK_REGISTRY_USECOUNT
        CmpCheckRegistryUseCount();
#endif //CHECK_REGISTRY_USECOUNT
        return STATUS_ACCESS_DENIED;
    }

    AdditionalAccess = (Context->CreateOptions & REG_OPTION_CREATE_LINK) ? KEY_CREATE_LINK : 0;

    if( BackupRestore == TRUE ) {
        //
        // this is a create to support a backup or restore
        // operation, do the special case work
        //
        AccessState->RemainingDesiredAccess = 0;
        AccessState->PreviouslyGrantedAccess = 0;

        mode = KeGetPreviousMode();

        if (SeSinglePrivilegeCheck(SeBackupPrivilege, mode)) {
            AccessState->PreviouslyGrantedAccess |=
                KEY_READ | ACCESS_SYSTEM_SECURITY;
        }

        if (SeSinglePrivilegeCheck(SeRestorePrivilege, mode)) {
            AccessState->PreviouslyGrantedAccess |=
                KEY_WRITE | ACCESS_SYSTEM_SECURITY | WRITE_DAC | WRITE_OWNER;
        }

        if (AccessState->PreviouslyGrantedAccess == 0) {
            CmKdPrintEx((DPFLTR_CONFIG_ID,CML_PARSE,"CmpDoCreate for backup restore: access denied\n"));
            status = STATUS_ACCESS_DENIED;
            //
            // this is not a backup-restore operator; deny the create
            //
            CreateAccess = FALSE;
        } else {
            //
            // allow backup operators to create new keys
            //
            CreateAccess = TRUE;
        }

    } else {
        //
        // The FullName is not used in the routine CmpCheckCreateAccess,
        //
        CreateAccess = CmpCheckCreateAccess(NULL,
                                            SecurityDescriptor,
                                            AccessState,
                                            AccessMode,
                                            AdditionalAccess,
                                            &status);
    }

    if (CreateAccess) {

        //
        // Security check passed, so we can go ahead and create
        // the sub-key.
        //
        if ( !HvMarkCellDirty(Hive, Cell) ) {
#ifdef CHECK_REGISTRY_USECOUNT
            CmpCheckRegistryUseCount();
#endif //CHECK_REGISTRY_USECOUNT

            return STATUS_NO_LOG_SPACE;
        }

        //
        // Create and initialize the new sub-key
        //
        status = CmpDoCreateChild( Hive,
                                   Cell,
                                   SecurityDescriptor,
                                   AccessState,
                                   Name,
                                   AccessMode,
                                   Context,
                                   ParentKcb,
                                   0,
                                   &KeyCell,
                                   Object );

        if (NT_SUCCESS(status)) {
            PCM_KEY_NODE KeyNode;

            //
            // Child successfully created, add to parent's list.
            //
            if (! CmpAddSubKey(Hive, Cell, KeyCell)) {

                //
                // Unable to add child, so free it
                //
                CmpFreeKeyByCell(Hive, KeyCell, FALSE);
#ifdef CHECK_REGISTRY_USECOUNT
                CmpCheckRegistryUseCount();
#endi