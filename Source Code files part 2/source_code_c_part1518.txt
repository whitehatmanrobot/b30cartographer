 since some of the things we called remunge the
    // data

    if (pVideoInfo->bmiHeader.biHeight < 0) {
        pVideoInfo->bmiHeader.biHeight = -pVideoInfo->bmiHeader.biHeight;
        NOTE("Height in source video is negative (top down DIB)");
    }

    return NOERROR;
}


// Called to prepare the allocator's count of buffers and sizes, we don't care
// who provides the allocator so long as it will give us a media sample. The
// output format we produce is not temporally compressed so in principle we
// could use any number of output buffers but it doesn't appear to gain much
// performance and does add to the overall memory footprint of the system

HRESULT CColour::DecideBufferSize(IMemAllocator *pAllocator,
                                  ALLOCATOR_PROPERTIES *pProperties)
{
    NOTE("Entering DecideBufferSize");
    ASSERT(pAllocator);
    ASSERT(pProperties);
    HRESULT hr = NOERROR;

    pProperties->cBuffers = COLOUR_BUFFERS;
    pProperties->cbBuffer = m_mtOut.GetSampleSize();
    ASSERT(pProperties->cbBuffer);

    // Ask the allocator to reserve us some sample memory, NOTE the function
    // can succeed (that is return NOERROR) but still not have allocated the
    // memory that we requested, so we must check we got whatever we wanted

    ALLOCATOR_PROPERTIES Actual;
    hr = pAllocator->SetProperties(pProperties,&Actual);
    if (FAILED(hr)) {
        NOTE("Properties failed");
        return hr;
    }

    // Did we get the buffering requirements

    if (Actual.cbBuffer >= (LONG) m_mtOut.GetSampleSize()) {
        if (Actual.cBuffers >= COLOUR_BUFFERS) {
            NOTE("Request ok");
            return NOERROR;
        }
    }
    return VFW_E_SIZENOTSET;
}

inline BOOL CColour::IsUsingFakeAllocator( )
{
    if( m_ColourInputPin.Allocator() == (IMemAllocator *)&m_ColourAllocator )
    {
        return TRUE;
    }
    return FALSE;
}

// Called when the filter goes into a running or paused state. By this point
// the input and output pins must have been connected with valid media types
// We use these media types to find a position in the transform table. That
// position will be used to create the appropriate convertor object. When
// the convertor object is created it will also be committed ready to work

HRESULT CColour::StartStreaming()
{
    NOTE("Entering StartStreaming");
    CAutoLock cAutoLock(&m_csReceive);

    // Have we already got a convertor

    if (m_pConvertor) {
        NOTE("Already active");
        return NOERROR;
    }

    m_bPassThrough = FALSE;

    // Can we start off in pass through mode
    // This only works if we're using our own allocator
    // otherwise the video renderer might get samples from an allocator
    // it doesn't understand

    if( IsUsingFakeAllocator( ) )
    {
        if( m_ColourInputPin.CanSupplyType(&m_mtOut) == S_OK )
        {
            m_bPassThrough = m_bPassThruAllowed;
        }
    }
    return CreateConvertorObject();
}


// Creates an object to do the conversion work. We may be called while we are
// streaming to recreate a convertor object based on a changed output format.
// For several of the convertors the create and commit is very expensive so
// we check that the new object required is not the same as the current. If
// it is the same then we simply reinitialise the rectangles as they may be
// different. If the convertor object has changed then we create a new one

HRESULT CColour::CreateConvertorObject()
{
    VIDEOINFO *pIn = (VIDEOINFO *) m_pInput->CurrentMediaType().Format();
    VIDEOINFO *pOut = (VIDEOINFO *) m_mtOut.Format();
    NOTE("Entering CreateConvertorObject");

    // Create an object to do the conversions

    INT TypeIndex = FindTransform(m_pInput->CurrentMediaType().Subtype(),m_mtOut.Subtype());
    if (TypeIndex == (-1)) {
        NOTE("No transform available");
        return VFW_E_TYPE_NOT_ACCEPTED;
    }

    // This handles dynamic format changes efficiently

    if (m_pConvertor) {
        if (m_TypeIndex == TypeIndex) {
            m_pConvertor->InitRectangles(pIn,pOut);
            NOTE("Using sample convertor");
            return NOERROR;
        }
    }

    DeleteConvertorObject();

    // Use the static creation function
    m_pConvertor = TypeMap[TypeIndex].pConvertor(pIn,pOut);
    if (m_pConvertor == NULL) {
        NOTE("Create failed");
        ASSERT(m_pConvertor);
        return E_OUTOFMEMORY;
    }

    // the converter defaults to NOT filling in the alpha channel,
    // if it's not the directdraw color convertor
    //
    if( ( *m_mtOut.Subtype( ) == MEDIASUBTYPE_ARGB32 ) && ( *m_pInput->CurrentMediaType( ).Subtype( ) != MEDIASUBTYPE_ARGB32 ) )
    {
        m_pConvertor->SetFillInAlpha( );
    }

    // Commit the convertor

    m_TypeIndex = TypeIndex;
    m_pConvertor->Commit();
    NOTE("Commit convertor");
    return NOERROR;
}


// Destroys any object created to do the conversions

HRESULT CColour::DeleteConvertorObject()
{
    NOTE("Entering DeleteConvertorObject");

    // Do we have a convertor created

    if (m_pConvertor == NULL) {
        NOTE("None made");
        return NOERROR;
    }

    // Decommit and free the object

    m_pConvertor->Decommit();
    delete m_pConvertor;
    NOTE("Delete convertor");

    // Reset the convertor state

    m_pConvertor = NULL;
    m_TypeIndex = (-1);
    return NOERROR;
}


// Called when a media type is set on either of our pins. The convertors find
// it much easier to handle strides and offsets if they can be sure that the
// source and destination rectangles in the output format have been fully set
// This function fills them out if they have been left empty. We don't really
// care about the source type rectangles so we just zero fill both of them

HRESULT CColour::SetMediaType(PIN_DIRECTION direction,const CMediaType *pmt)
{
    NOTE("Entering SetMediaType");
    CAutoLock cAutoLock(&m_csReceive);

    // Take a copy of the input type

    if (direction == PINDIR_INPUT) {
        return NOERROR;
    }

    // Return the VIDEOINFO after the copy

    VIDEOINFO *pSource = (VIDEOINFO *) m_pInput->CurrentMediaType().Format();

    m_mtOut = *pmt;

    // Likewise set the output rectangles

    VIDEOINFO *pTarget = (VIDEOINFO *) m_mtOut.Format();
    if (IsRectEmpty(&pTarget->rcSource)) {
        pTarget->rcSource.left = pTarget->rcSource.top = 0;
        pTarget->rcSource.right = pSource->bmiHeader.biWidth;
        pTarget->rcSource.bottom = ABSOL(pSource->bmiHeader.biHeight);
        NOTE("Output source rectangle was empty");
    }

    // Make sure the destination is filled out

    if (IsRectEmpty(&pTarget->rcTarget)) {
        pTarget->rcTarget.left = pTarget->rcTarget.top = 0;
        pTarget->rcTarget.right = pTarget->bmiHeader.biWidth;
        pTarget->rcTarget.bottom = ABSOL(pTarget->bmiHeader.biHeight);
        NOTE("Output destination rectangle was empty");
    }
    return NOERROR;
}


// Called when one of our pins is disconnected

HRESULT CColour::BreakConnect(PIN_DIRECTION dir)
{
    NOTE("Entering BreakConnect");
    CAutoLock cAutoLock(&m_csReceive);
    DeleteConvertorObject();

    if (dir == PINDIR_OUTPUT) {
        m_bOutputConnected = FALSE;
        m_mtOut.SetType(&GUID_NULL);
        NOTE("Reset output format");
        return NOERROR;
    }

    ASSERT(dir == PINDIR_INPUT);
    return NOERROR;
}


// We override this virtual transform function to return our own base input
// class. The reason we do this is because we want more control over what
// happens when Receive is called. If we are doing a real pass through with
// no buffer copy then when Receive is called we pass it straight to the
// sink filter. This also requires some manipulation with the allocators

CBasePin *CColour::GetPin(int n)
{
    NOTE("Entering GetPin");

    if (m_pInput == NULL) {
        HRESULT hr = S_OK;

        m_pOutput = (CTransformOutputPin *) new CColourOutputPin(
            NAME("Transform output pin"),
            this,            // Owner filter
            &hr,             // Result code
            L"XForm Out");   // Pin name

        // Can't fail
        ASSERT(SUCCEEDED(hr));

        // Only set the input pin pointer if we have an output pin
        if (m_pOutput != NULL)
            m_pInput = &m_ColourInputPin;
    }

    // Return the appropriate pin
    if (n == 0)
        return m_pInput;
    else if (n == 1)
        return m_pOutput;
    else
        return NULL;
}


// This colour space filter offers all permutations of the RGB formats. It is
// therefore never really valid to try and connect a convertor to another one
// The reason why this might be harmful is when trying to make a connection
// between filters that really can't be made (for example MPEG decoder and
// audio renderer), the filtergraph chains up a number of colour convertors
// to try and make the connection. This speeds up failure connection times.

HRESULT CColour::CheckConnect(PIN_DIRECTION dir,IPin *pPin)
{
    PIN_INFO PinInfo;
    ASSERT(pPin);
    CLSID Clsid;

    // Only applicable to output pins

    if (dir == PINDIR_INPUT) {
        return NOERROR;
    }

    ASSERT(dir == PINDIR_OUTPUT);
    pPin->QueryPinInfo(&PinInfo);
    PinInfo.pFilter->GetClassID(&Clsid);
    QueryPinInfoReleaseFilter(PinInfo);

    // Are we connecting to a colour filter

    if (Clsid == CLSID_Colour) {
        return E_FAIL;
    }
    return NOERROR;
}


// There is one slight snag to the colour convertion filter. The source may
// be able to give us any number of different formats, if when we get round
// to completing the output pin connection we find the source could supply
// the output type directly then we reconnect the pin. By agreeing the same
// type for input and output we are most likely to be able to pass through

HRESULT CColour::CompleteConnect(PIN_DIRECTION dir,IPin *pReceivePin)
{
    NOTE("Entering CompleteConnect");
    CAutoLock cAutoLock(&m_csReceive);
    ASSERT(m_pConvertor == NULL);
    ASSERT(m_TypeIndex == (-1));

    // Need this for reconnecting

    if (m_pGraph == NULL) {
        NOTE("No filtergraph");
        return E_UNEXPECTED;
    }

	// Load the non RGB formats the source supplies

    if (dir == PINDIR_INPUT) {
	m_fReconnecting = FALSE;	// the reconnect is obviously over
        NOTE("Loading media types from source filter");
        LoadMediaTypes(m_ColourInputPin.GetConnected());
        if (m_bOutputConnected == TRUE) {
            NOTE("Reconnecting output pin");
            m_pGraph->Reconnect(m_pOutput);
        }
        return NOERROR;
    }

    return NOERROR;
}

// Separated from the normal CompleteConnect because we want this to
// execute after the NotifyAllocator negotiation, and the
// CTransformOutputPin base class calls us before
// NotifyAllocator. This is a temporary work-around for the VMR which
// is changing the connection type during NotifyAllocator breaking
// reconnects.
// 
HRESULT CColour::OutputCompleteConnect(IPin *pReceivePin)
{
    NOTE("Entering CompleteConnect");
    CAutoLock cAutoLock(&m_csReceive);
    ASSERT(m_pConvertor == NULL);
    ASSERT(m_TypeIndex == (-1));

    // Need this for reconnecting

    if (m_pGraph == NULL) {
        NOTE("No filtergraph");
        return E_UNEXPECTED;
    }

    m_bOutputConnected = TRUE;

    // Reconnect our input pin  to match with the output format
    if (*m_pInput->CurrentMediaType().Subtype() != *m_mtOut.Subtype()) {
        if (m_ColourInputPin.CanSupplyType(&m_mtOut) == NOERROR) {
            NOTE("Reconnecting input pin");
	    // !!! If the reconnect fails, we'll never let our input accept
	    // types other than the output type, but that's not a big deal,
	    // this code worked like that for 1.0
	    m_fReconnecting = TRUE;	// this will make our input only accept
					// a type that matches our output

            //  Pass the type to the reconnect.
            //  Sometimes when we get to the Connect call our caller
            //  doesn't know what type to use and in fact we don't bother
            //  to enumerate our output type in GetMediaType
            ReconnectPin(m_pInput, &m_mtOut);
        }
    }
    return NOERROR;


}


// Constructor for our colour space allocator

CColourAllocator::CColourAllocator(TCHAR *pName,
                                   CColour *pColour,
                                   HRESULT *phr,
                                   CCritSec *pLock) :
    CMemAllocator(pName,NULL,phr),
    m_pColour(pColour),
    m_pLock(pLock)
{
    ASSERT(pColour);
    ASSERT(m_pLock);
    m_fEnableReleaseCallback = FALSE;
}


// Overriden to increment the owning object's reference count

STDMETHODIMP_(ULONG) CColourAllocator::NonDelegatingAddRef()
{
    NOTE("Entering allocator AddRef");
    return m_pColour->AddRef();
}


// Overriden to decrement the owning object's reference count

STDMETHODIMP_(ULONG) CColourAllocator::NonDelegatingRelease()
{
    NOTE("Entering allocator Release");
    return m_pColour->Release();
}


// If the sample was released without calling Receive then we must release the
// output buffer we were holding ready for the transform. If we are not using
// our allocator then this should never be called. If we are passing through
// and the source filter releases its sample then it will be released directly
// into the downstream filters allocator rather than ours. This should not be
// a problem because we hold no resources when we pass back the output sample

STDMETHODIMP CColourAllocator::ReleaseBuffer(IMediaSample *pSample)
{
    NOTE("Entering ReleaseBuffer");
    CheckPointer(pSample,E_POINTER);
    CAutoLock cAutoLock(m_pLock);

    // Release the output buffer we were going to use

    if (m_pColour->m_pOutSample) {
        NOTE("Output buffer needs releasing");
        m_pColour->m_pOutSample->Release();
        m_pColour->m_pOutSample = NULL;
    }
    return CMemAllocator::ReleaseBuffer(pSample);
}


// Ask the output sample for its media type. This will return NULL if it is
// the same as the previous buffer. If it is non NULL then the target filter
// is asking us to change the output format. We only change when non NULL
// otherwise we would have to compare types on all the samples. If we can't
// get the source filter to supply the type directly then we will have to do
// a conversion ourselves. Because the buffer may be discarded as preroll we
// must create a new convertor object whenever we switch out of pass through

BOOL CColourAllocator::ChangeType(IMediaSample *pIn,IMediaSample *pOut)
{
    NOTE("Entering ChangeType");
    AM_MEDIA_TYPE *pMediaType;

    // Has the output format been changed

    pOut->GetMediaType(&pMediaType);
    if (pMediaType == NULL) {
        NOTE("Output format is unchanged");
        return m_pColour->m_bPassThrough;
    }

    CMediaType cmt(*pMediaType);
    DeleteMediaType(pMediaType);
    NOTE("Trying output format");

    // It's changed but can the source supply it directly

    if (m_pColour->m_ColourInputPin.CanSupplyType(&cmt) == S_OK) {
        NOTE("Passing output sample back");
        m_pColour->m_bPassThrough = m_pColour->m_bPassThruAllowed;
        return TRUE;
    }

    // Reset the source format if necessary

    if (m_pColour->m_bPassThrough == TRUE) {
        pIn->SetMediaType(&m_pColour->m_pInput->CurrentMediaType());
        NOTE("Reset format for source filter");
    }

    // Create a new convertor object

    NOTE("Forcing update after output changed");
    m_pColour->SetMediaType(PINDIR_OUTPUT,&cmt);
    m_pColour->CreateConvertorObject();
    m_pColour->m_bPassThrough = FALSE;

    return FALSE;
}

// ehr:  This is only called when our own special allocator is being used on the
// input pin. We IMMEDIATELY get an output buffer from the output pin.
// (This will either be an allocator that we created ourselves, or the downstream
// filter's allocator) (In any case, it's a place to put bits). Then we check
// and see if we can receive the bits directly into this (output) buffer. If so,
// we pass back the output's buffer to fill. If we cannot receive
// directly into the output buffer, we pass back the buffer we allocated in this
// fake allocator.

// This is an implementation of GetBuffer we have for our own allocator. What
// we do when asked for a buffer is to immediately get an output buffer from
// the target filter. Having got that we can then assertain whether we can
// act as a pass through filter and simply pass the output buffer back to the
// source filter to fill. If we can't pass through then we store the output
// buffer in the filter and when delivered the input sample do the transform

STDMETHODIMP CColourAllocator::GetBuffer(IMediaSample **ppBuffer,
                                         REFERENCE_TIME *pStart,
                                         REFERENCE_TIME *pEnd,
                                         DWORD dwFlags)
{
    CheckPointer(ppBuffer,E_POINTER);
    IMediaSample *pInput, *pOutput;
    NOTE("Entering GetBuffer");
    HRESULT hr = NOERROR;
    *ppBuffer = NULL;


    // Get a normal buffer from the colour allocator

    hr = CBaseAllocator::GetBuffer(&pInput,pStart,pEnd,0);
    if (FAILED(hr) || pInput == NULL) {
        NOTE("No input buffer");
        return VFW_E_STATE_CHANGED;
    }

    // If our allocator (used by our input pin) has more than 1 buffer,
    // calling our output pin's allocator's GetBuffer (like we're about to
    // do) may HANG!  Chances are, downstream is a video renderer, with only
    // 1 buffer, so if we have >1 buffer for our input, and the upstream filter
    // decides to call GetBuffer >1 times (which the proxy does) we will HANG
    // blocked forever trying to get multiple buffers at a time from the
    // video renderer.
    // If the notify interface is set we have to return the buffer
    // immediately so don't try passthru

    if (m_lCount > 1) {
        *ppBuffer = pInput;
        return hr;
    }

    // Then get an output buffer from the downstream filter

    hr = m_pColour->m_pOutput->GetDeliveryBuffer(&pOutput,pStart,pEnd,dwFlags);
    if (FAILED(hr) || pOutput == NULL) {
        NOTE("No output buffer");
        pInput->Release();
        return VFW_E_STATE_CHANGED;
    }

    CAutoLock cAutoLock(m_pLock);

    // Handle dynamic format changes and set the output buffers

    if (ChangeType(pInput,pOutput) == TRUE) {
        NOTE("Passing through");
        *ppBuffer = pOutput;
        pInput->Release();
        return NOERROR;
    }

    // Pass back the downstream buffer

    NOTE("Returning transform buffer");
    m_pColour->m_pOutSample = pOutput;
    *ppBuffer = pInput;
    return NOERROR;
}


STDMETHODIMP CColourAllocator::SetProperties(
    	    ALLOCATOR_PROPERTIES* pRequest,
    	    ALLOCATOR_PROPERTIES* pActual)
{
    //  Don't support more than 1 buffer or passthrough won't work
    if (pRequest->cBuffers > 1) {
        return E_INVALIDARG;
    }
    HRESULT hr = CMemAllocator::SetProperties(pRequest, pActual);
    ASSERT(FAILED(hr) || m_lCount <= 1);
    return hr;
}

// Constructor for our colour space conversion input pin

CColourInputPin::CColourInputPin(TCHAR *pObjectName,
                                 CColour *pColour,
                                 CCritSec *pLock,
                                 HRESULT *phr,
                                 LPCWSTR pName) :

    CTransformInputPin(pObjectName,pColour,phr,pName),
    m_pColour(pColour),
    m_pLock(pLock)
{
    ASSERT(pObjectName);
    ASSERT(m_pColour);
    ASSERT(phr);
    ASSERT(pName);
    ASSERT(m_pLock);
}


// Can the source pin supply a format directly. We can't pass through eight
// bit formats because managing palette changes by a source filter is too
// hard to do. In any case the value of this filter in the DirectDraw cases
// is to dither when the source cannot but pass through true colour formats
// when we switch surfaces in the renderer (without involving a data copy)

HRESULT CColourInputPin::CanSupplyType(const AM_MEDIA_TYPE *pMediaType)
{
    NOTE("Entering CanSupplyType");

    // Is the input pin connected

    if (m_Connected == NULL) {
        NOTE("Not connected");
        return VFW_E_NOT_CONNECTED;
    }

#if 0	// we can now
    // We cannot pass through palettised formats
    if (pMediaType->subtype == MEDIASUBTYPE_RGB8) {
        NOTE("Cannot pass palettised");
        return VFW_E_TYPE_NOT_ACCEPTED;
    }
#endif

#if 0	// what was this???
    // We cannot pass through if the source is palettised
    if (*CurrentMediaType().Subtype() == MEDIASUBTYPE_RGB8) {
        NOTE("Source format palettised");
        return VFW_E_TYPE_NOT_ACCEPTED;
    }
#endif

    return m_Connected->QueryAccept(pMediaType);
}


#ifdef MEANINGLESS_DRIVEL
// If we have our input pin reconnected while the output is connected we are
// very picky about which formats we accept. Basicly we only accept the same
// subtype as the output. This covers over a problem in pass through filters
// where they don't try to match input and output formats when they reconnect
// their input pins, all they do is QueryAccept on the downstream filter. As
// we accept just about anything we have to do the format matching for them.
#else
// !!! Don't listen to the above paragraph.  Here's what's really going on.
// We would love to be connected in a pass-through mode, without changing
// the format.  Let's say you connect two filters through a colour converter,
// and it just so happens they connect with RGB32 being transformed to RGB24.
// It just so happens that if we had insisted on making the filter before us
// produce RGB24, it would have, so we could have been clever and connected
// as RGB24 to RGB24 (pass through) but we didn't.  So we get around that by,
// everytime we finish connecting our output, forcing a reconnect of our
// input.  And the reconnect of our input will only allow the same format as
// the output.  So what happens is, you connect a filter to the input of the
// colour converter, and it will pick an input at random, say RGB32.  Now you
// connect the output to somebody who only accepts 24 bit.  This will,
// behind your back, check to see if the filter before the converter can
// supply 24 bit RGB.  If so, it will trigger a reconnect of the input pin
// (behind your back) and this code below will only allow the reconnect
// to be made with RGB24.  Voila.  You will, by default, get the converter
// in a pass through mode instead of a converting mode whenever possible.

// The bad thing about this method is that if somebody has a graph connected
// where a colour converter is transforming (say, RGB32 to RGB24) and you
// disconnect the input pin and reconnect it, it will FAIL to reconnect
// unless the filter before it can supply RGB24 because it will think it's
// in the wierd mode described above.

// So to make everything work, if we're reconnecting our input, we'll accept
// any type if the source cannot supply the output format, but only the
// output type if the source can supply it.
#endif

HRESULT CColourInputPin::CheckMediaType(const CMediaType *pmtIn)
{
    CheckPointer(pmtIn,E_POINTER);
    CAutoLock cAutoLock(m_pLock);
    CMediaType OutputType;
    NOTE("Entering CheckMediaType");

    // Has the output pin been created yet

    if (m_pColour->m_pOutput == NULL) {
        NOTE("No output pin instantiated yet");
        return CTransformInputPin::CheckMediaType(pmtIn);
    }

    // Do we have an output pin connection at the moment

    if (CurrentMediaType().IsValid() == TRUE) {
        if (m_pColour->m_mtOut.IsValid() == TRUE) {
	    // If we are in our "reconnecting" mode, we're only supposed to
	    // accept a format that matches our output
            if (*pmtIn->Subtype() != *m_pColour->m_mtOut.Subtype() &&
				m_pColour->m_fReconnecting) {
#if 0	// we allow 8->8 now
                	(*m_pColour->m_mtOut.Subtype() == MEDIASUBTYPE_RGB8)
#endif
                    NOTE("Formats don't yet match");
                    return VFW_E_TYPE_NOT_ACCEPTED;
            }
        }
    }
    return CTransformInputPin::CheckMediaType(pmtIn);
}



// This overrides the CBaseInputPin virtual method to return an allocator we
// have derived from CMemAllocator so we can control calls made to GetBuffer
// When NotifyAllocator is called it sets the current allocator in the base
// input pin class (m_pAllocator), this is what GetAllocator should return
// unless it is NULL in which case we return the allocator we would like

STDMETHODIMP CColourInputPin::GetAllocator(IMemAllocator **ppAllocator)
{
    CheckPointer(ppAllocator,E_POINTER);
    CAutoLock cAutoLock(m_pLock);
    NOTE("Entering GetAllocator");

    // Has an allocator been set yet in the base class

    if (m_pAllocator == NULL) {
        NOTE("Allocator not yet instantiated");
        m_pAllocator = &m_pColour->m_ColourAllocator;
        m_pAllocator->AddRef();
    }

    // Store and AddRef the allocator

    m_pAllocator->AddRef();
    *ppAllocator = m_pAllocator;
    NOTE("AddRef on allocator");
    return NOERROR;
}


// When we do a transform from input sample to output we also copy the source
// properties to the output buffer. This ensures that things like time stamps
// get propogated downstream. The other properties we are interested in are
// the preroll, sync point, discontinuity and the actual output data length
// These are already placed if we pass the output buffer back to the source

void CColourInputPin::CopyProperties(IMediaSample *pSrc,IMediaSample *pDst)
{
    // Copy the start and end times

    REFERENCE_TIME TimeStart,TimeEnd;
    if (pSrc->GetTime(&TimeStart,&TimeEnd) == NOERROR) {
	pDst->SetTime(&TimeStart,&TimeEnd);
    }

    // Copy the associated media times (if set)

    LONGLONG MediaStart,MediaEnd;
    if (pSrc->GetMediaTime(&MediaStart,&MediaEnd) == NOERROR) {
        pDst->SetMediaTime(&MediaStart,&MediaEnd);
    }

    // Copy the Sync point property

    HRESULT hr = pSrc->IsSyncPoint();
    BOOL IsSync = (hr == S_OK ? TRUE : FALSE);
    pDst->SetSyncPoint(IsSync);

    // Copy the preroll property

    hr = pSrc->IsPreroll();
    BOOL IsPreroll = (hr == S_OK ? TRUE : FALSE);
    pDst->SetPreroll(IsPreroll);

    // Copy the discontinuity property

    hr = pSrc->IsDiscontinuity();
    BOOL IsBreak = (hr == S_OK ? TRUE : FALSE);
    pDst->SetDiscontinuity(IsBreak);
    pDst->SetActualDataLength(pDst->GetSize());
}


// We override this from the base transform class input pin because we want
// to pass through samples. If the downstream filter asks for a media type
// and the source filter can supply it directly then so long as the source
// is using our allocator we will pass through samples without us touching
// them (and therefore NOT copying the data from input to output). By doing
// this we can act as a null filter when appropriate but also do conversions
// as and when required (maybe the sink filter lost its DirectDraw surface)

STDMETHODIMP CColourInputPin::Receive(IMediaSample *pSample)
{
    CheckPointer(pSample,E_POINTER);
    CAutoLock cAutoLock(m_pLock);
    NOTE("Entering Receive");

    // Is this sample just passing through? Only two places change this flag:
    // StartStreaming( ), and ChangeType( ). ChangeType is checked every time
    // the input allocator's GetBuffer is called.
    // !!! can we optimize that?

    if (m_pColour->m_bPassThrough == TRUE)
    {
        NOTE("Sample received was a pass through");
        HRESULT hr = CheckStreaming();
        if (S_OK == hr)
        {
            hr =  m_pColour->m_pOutput->Deliver(pSample);
        }
        return hr;
    }

    // Check for type changes and streaming for optimizing cases

    if (m_pColour->m_pOutSample != NULL) {
        HRESULT hr = CBaseInputPin::Receive(pSample);
        if (S_OK != hr) {
            return hr;
        }
    }


    // Default behaviour if not using our input pin allocator

    if (m_pColour->m_pOutSample == NULL) {
        NOTE("Passing to base transform class");
        return CTransformInputPin::Receive(pSample);
    }

    // Call the colour conversion filter to do the transform

    NOTE("Sample was not a pass through (doing transform)");
    CopyProperties(pSample,m_pColour->m_pOutSample);
    m_pColour->Transform(pSample,m_pColour->m_pOutSample);
    HRESULT hr = m_pColour->m_pOutput->Deliver(m_pColour->m_pOutSample);

    // Release the output sample

    NOTE("Delivered the sample");
    m_pColour->m_pOutSample->Release();
    m_pColour->m_pOutSample = NULL;
    return hr;
}


// Simply ask the enumerator for the next media type and return a pointer to
// the memory allocated by the interface. Whoever calls this function should
// release the media type when they are finished using the DeleteMediaType

AM_MEDIA_TYPE *CColour::GetNextMediaType(IEnumMediaTypes *pEnumMediaTypes)
{
    NOTE("Entering GetNextMediaType");
    ASSERT(pEnumMediaTypes);
    AM_MEDIA_TYPE *pMediaType = NULL;
    ULONG ulMediaCount = 0;
    HRESULT hr = NOERROR;

    // Retrieve the next media type

    hr = pEnumMediaTypes->Next(1,&pMediaType,&ulMediaCount);
    if (hr != NOERROR) {
        return NULL;
    }

    // Quick sanity check on the returned values

    ASSERT(ulMediaCount == 1);
    ASSERT(pMediaType);
    return pMediaType;
}


// Scan the list deleting the media types in turn

void CColour::InitTypeList()
{
    NOTE("Entering InitTypeList");
    POSITION pos = m_TypeList.GetHeadPosition();
    while (pos) {
        AM_MEDIA_TYPE *pMediaType = m_TypeList.GetNext(pos);
        DeleteMediaType(pMediaType);
    }
    m_TypeList.RemoveAll();
}


// The colour conversion filter exposes five typical media types, namely RGB8
// RGB555/565/24 and RGB32 or ARGB32. We can also act as a pass through filter so that
// we effectively do nothing and add no copy overhead. This does however mean
// that the list of media types we support through our enumerator must include
// the NON RGB formats of our source filter - this method loads these formats

HRESULT CColour::FillTypeList(IEnumMediaTypes *pEnumMediaTypes)
{
    NOTE("Entering FillTypeList");
    ASSERT(pEnumMediaTypes);
    IPin *pPin;

    // Reset the current enumerator position

    HRESULT hr = pEnumMediaTypes->Reset();
    if (FAILED(hr)) {
        NOTE("Reset failed");
        return hr;
    }

    // Get the output pin we are connecting with

    hr = m_pInput->ConnectedTo(&pPin);
    if (FAILED(hr)) {
        NOTE("No pin");
        return hr;
    }

    // When we retrieve each source filter type from it's enumerator we check
    // that it is useful, meaning we can provide some transforms with it, if
    // not then we must make sure we delete it with the global task allocator

    AM_MEDIA_TYPE *pMediaType = NULL;
    while (TRUE) {

        // Retrieve the next media type from the enumerator

        pMediaType = GetNextMediaType(pEnumMediaTypes);
        if (pMediaType == NULL) {
            NOTE("No more types");
            pPin->Release();
            return NOERROR;
        }

        // BEWARE QueryAccept returns S_FALSE on failure

        hr = pPin->QueryAccept(pMediaType);
        if (hr != S_OK) {
            NOTE("Source rejected type");
            DeleteMediaType(pMediaType);
            continue;
        }

        // Check this is a video format

        hr = CheckVideoType(pMediaType);
        if (FAILED(hr)) {
            NOTE("Source rejected type");
            DeleteMediaType(pMediaType);
            continue;
        }

        // Is this a RGB format (either BI_RGB or BI_BITFIELDS)

        VIDEOINFO *pVideoInfo = (VIDEOINFO *) pMediaType->pbFormat;
        if (pVideoInfo->bmiHeader.biCompression == BI_RGB ||
                pVideoInfo->bmiHeader.biCompression == BI_BITFIELDS) {
                    DeleteMediaType(pMediaType);
                    NOTE("Format is RGB");
                    continue;
        }

        // Add the media type to the list

        POSITION pos = m_TypeList.AddTail(pMediaType);
        if (pos == NULL) {
            NOTE("AddTail failed");
            DeleteMediaType(pMediaType);
            pPin->Release();
            return E_OUTOFMEMORY;
        }
    }
}


// This is called when the input pin has it's media type set so that we can
// enumerate all the media types available from the connecting output pin
// These are used to prode the media types we can provide as output as that
// list is dependant on the source types combined with the transforms we do

HRESULT CColour::LoadMediaTypes(IPin *pPin)
{
    NOTE("Entering LoadMediaTypes");

    ASSERT(pPin);
    HRESULT hr;
    InitTypeList();

    IEnumMediaTypes *pEnumMediaTypes = NULL;

    // Query the output pin we are connecting to for a media type enumerator
    // which we use to provide a complete list of all the possible formats
    // that we can supply based on the different transforms we implement */

    hr = pPin->EnumMediaTypes(&pEnumMediaTypes);
    if (FAILED(hr)) {
        return hr;
    }

    ASSERT(pEnumMediaTypes);
    FillTypeList(pEnumMediaTypes);
    pEnumMediaTypes->Release();
    return NOERROR;
}


// Return the media type stored at this zero based position in the list

AM_MEDIA_TYPE *CColour::GetListMediaType(INT Position)
{
    NOTE("Entering GetListMediaType");
    AM_MEDIA_TYPE *pMediaType = NULL;
    Position += 1;

    // Scan the list from the start

    POSITION pos = m_TypeList.GetHeadPosition();
    while (Position--) {
        pMediaType = m_TypeList.GetNext(pos);
    }
    ASSERT(pMediaType);
    return pMediaType;
}

CColourOutputPin::CColourOutputPin(
    TCHAR * pObjectName,
    CColour * pFilter,
    HRESULT * phr,
    LPCWSTR pName )
: CTransformOutputPin( pObjectName, pFilter, phr, pName )
, m_pColour( pFilter )
{
}

HRESULT
CColourOutputPin::DecideAllocator(IMemInputPin *pPin, IMemAllocator **ppAlloc)
{
    HRESULT hr = NOERROR;
    *ppAlloc = NULL;

    // get downstream prop request
    // the derived class may modify this in DecideBufferSize, but
    // we assume that he will consistently modify it the same way,
    // so we only get it once
    ALLOCATOR_PROPERTIES prop;
    ZeroMemory(&prop, sizeof(prop));

    // whatever he returns, we assume prop is either all zeros
    // or he has filled it out.
    pPin->GetAllocatorRequirements(&prop);

    // if he doesn't care about alignment, then set it to 1
    if (prop.cbAlign == 0) {
        prop.cbAlign = 1;
    }

    /* Try the allocator provided by the input pin */

    // what is the read-only state of our input pin's allocator?
    //
    BOOL ReadOnly = m_pColour->m_pInput->IsReadOnly( );

    // preset the passthrough allowance to true.
    //
    m_pColour->m_bPassThruAllowed = TRUE;

    // if we're using some upstream guy's allocator, then we can never
    // "fake it out" and provide a passthru, so we don't have to worry
    // about whether to pass a ReadOnly flag downstream.
    //
    if( !m_pColour->IsUsingFakeAllocator( ) )
    {
        // well, we thought we were readonly, but
        // we're really not, so reset the readonly flag.
        //
        ReadOnly = FALSE;

        // never allow passthrough
        //
        m_pColour->m_bPassThruAllowed = FALSE;
    }

    hr = pPin->GetAllocator(ppAlloc);
    if (SUCCEEDED(hr))
    {
        // downstream pin provided an allocator to stuff things
        // into. We must inform the downstream allocator of the input
        // pin's ReadOnly status because once in a while, the "fake" allocator
        // on our input pin may pass back the output allocator's buffer, and
        // we want it to have the same properties.
        //
	hr = DecideBufferSize(*ppAlloc, &prop);

	if (SUCCEEDED(hr))
        {
	    hr = pPin->NotifyAllocator(*ppAlloc, ReadOnly );
	    if (SUCCEEDED(hr))
            {
                return NOERROR;
	    }
            // the downstream pin didn't like being told to be
            // read only, so change flag to never allow passthrough mode
            // and then ask the pin again if it will accept read/write
            // mode. This time it should work.
            //
            m_pColour->m_bPassThruAllowed = FALSE;
	    hr = pPin->NotifyAllocator(*ppAlloc, FALSE);
	    if (SUCCEEDED(hr))
            {
                return NOERROR;
	    }
	}
    }

    /* If the GetAllocator failed we may not have an interface */

    if (*ppAlloc) {
	(*ppAlloc)->Release();
	*ppAlloc = NULL;
    }

    /* Try the output pin's allocator by the same method */

    hr = InitAllocator(ppAlloc);
    if (SUCCEEDED(hr))
    {
        // note - the properties passed here are in the same
        // structure as above and may have been modified by
        // the previous call to DecideBufferSize
	hr = DecideBufferSize(*ppAlloc, &prop);

	if (SUCCEEDED(hr))
        {
	    hr = pPin->NotifyAllocator(*ppAlloc, ReadOnly);
	    if (SUCCEEDED(hr))
            {
                return NOERROR;
	    }
            // the downstream pin didn't like being told to be
            // read only, so change flag to never allow passthrough mode
            // and then ask the pin again if it will accept read/write
            // mode. This time it should work.
            //
            m_pColour->m_bPassThruAllowed = FALSE;
	    hr = pPin->NotifyAllocator(*ppAlloc, FALSE);
	    if (SUCCEEDED(hr))
            {
                return NOERROR;
	    }
	}
    }

    /* Likewise we may not have an interface to release */

    if (*ppAlloc) {
	(*ppAlloc)->Release();
	*ppAlloc = NULL;
    }
    return hr;
}

HRESULT CColourOutputPin::CompleteConnect(IPin *pReceivePin)
{
    HRESULT hr = CTransformOutputPin::CompleteConnect(pReceivePin);
    if(SUCCEEDED(hr))
    {
        hr = m_pColour->OutputCompleteConnect(pReceivePin);
    }

    return hr;
}
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\multimedia\dshow\filters\image\colour\convert.cpp ===
// Copyright (c) Microsoft Corporation 1994-1996. All Rights Reserved
// This filter implements popular colour space conversions, May 1995

#include <streams.h>
#include <colour.h>

// Constructor for a conversion to the given subtype. This base class is used
// by all the output type specific transform methods to initialise our state
// To keep the transforms as fast as possible we store the BITMAPINFOHEADER
// from the VIDEOINFO media format before starting (see the HEADER macro)
// The base class also looks after calculating strides and offsets so that we
// can source and target images from DCI/DirectDraw surfaces. Furthermore the
// base class handles alignment so that we can stream pixels very efficiently
// when they are DWORD aligned but handle the pixels at line ends that aren't

// The m_SrcStride will be set so that when added to the input image pointer
// will reference the first byte of the top scan line of the source. Likewise
// m_DstStride is set to when added to the output image pointer will point to
// the first byte of the output image top scan line. The source can then be
// transformed to the output and each of the scan line pointers moved on by
// m_SrcStride or m_DstStride respectively (these strides may be negative).
// Therefore both the source and target images can be upside down oriented

// We can handle input RGB images either top down or bottom up and can output
// both top down and bottom up so there are a total of four permutations of
// input and output image. InitRectangles looks after setting up the strides
// and offsets in all cases. Note that we always offer bottom up (DIB format)
// images to start with. The destination and source rectangles are stored as
// absolute values so they should not reflect any orientation of the image

CConvertor::CConvertor(VIDEOINFO *pIn,VIDEOINFO *pOut) :

    m_pInputInfo(pIn),                  // Input image format VIDEOINFO
    m_pOutputInfo(pOut),                // And likewise format to go to
    m_pInputHeader(HEADER(pIn)),        // Extract the input header
    m_pOutputHeader(HEADER(pOut)),      // Also get the output header
    m_bCommitted(FALSE),                // Has the convertor been committed
    m_SrcOffset(0),                     // Source original offset
    m_SrcStride(0),                     // Length in bytes of a scan line
    m_DstStride(0),                     // Likewise offset into target
    m_DstOffset(0),                     // And the length of each line
    m_bAligned(FALSE),                  // Are the rectangles aligned
    m_bSetAlpha(FALSE)
{
    ASSERT(pIn);
    ASSERT(pOut);
}


// Destructor

CConvertor::~CConvertor()
{
    ASSERT(m_bCommitted == FALSE);
}


// Change the alignment explicitely

void CConvertor::ForceAlignment(BOOL bAligned)
{
    m_bAligned = bAligned;
}


// To handle DirectDraw and DCI surfaces we have to be able to convert into
// upside down buffers and into buffers with different source and destination
// rectangles. This resets the four most interesting fields namely the source
// stride and offset - and the destination stride and offset. The derived
// classes can then use these fields during the colour space transformations

void CConvertor::InitRectangles(VIDEOINFO *pIn,VIDEOINFO *pOut)
{
    // Reset the VIDEOINFO state pointers

    m_bAligned = FALSE;
    m_pInputInfo = pIn;
    m_pOutputInfo = pOut;
    m_pInputHeader = HEADER(pIn);
    m_pOutputHeader = HEADER(pOut);

    // Check the source rectangle is ok and calculate the source stride

    ASSERT(m_pOutputInfo->rcSource.top <= m_pOutputInfo->rcSource.bottom);
    ASSERT(IsRectEmpty(&m_pOutputInfo->rcSource) == FALSE);
    m_SrcStride = DIBWIDTHBYTES(*m_pInputHeader);
    m_SrcStride = (m_pInputHeader->biHeight > 0) ? (-m_SrcStride) : m_SrcStride;

    // Set the source offset to reference the top scan line of the image

    m_SrcOffset = (m_pInputHeader->biHeight > 0) ? m_pInputHeader->biHeight : 1;
    m_SrcOffset = (m_SrcOffset - 1) * DIBWIDTHBYTES(*m_pInputHeader);
    m_SrcOffset += m_pOutputInfo->rcSource.top * m_SrcStride;
    m_SrcOffset += m_pOutputInfo->rcSource.left * m_pInputHeader->biBitCount / 8;

    // Likewise do the same for the destination rectangle and stride

    ASSERT(m_pOutputInfo->rcTarget.top <= m_pOutputInfo->rcTarget.bottom);
    ASSERT(IsRectEmpty(&m_pOutputInfo->rcTarget) == FALSE);
    m_DstStride = DIBWIDTHBYTES(*m_pOutputHeader);
    m_DstStride = (m_pOutputHeader->biHeight > 0) ? (-m_DstStride) : m_DstStride;

    // Calculate the offset to the top scan line of the image

    m_DstOffset = (m_pOutputHeader->biHeight > 0) ? m_pOutputHeader->biHeight : 1;
    m_DstOffset = (m_DstOffset - 1) * DIBWIDTHBYTES(*m_pOutputHeader);
    m_DstOffset += m_pOutputInfo->rcTarget.top * m_DstStride;
    m_DstOffset += m_pOutputInfo->rcTarget.left * m_pOutputHeader->biBitCount / 8;

    // Are the source and destination rectangles aligned

    if ((WIDTH(&pOut->rcTarget) & 3) == 0)
        if ((WIDTH(&pOut->rcSource) & 3) == 0)
            if ((pOut->rcSource.left & 3) == 0)
                if ((pOut->rcTarget.left & 3) == 0)
                    m_bAligned = TRUE;
}


// This is the base class implementation of commit

HRESULT CConvertor::Commit()
{
    InitRectangles(m_pInputInfo,m_pOutputInfo);
    m_bCommitted = TRUE;

    // Setup the dither table if not already done

    if (m_pInputHeader->biBitCount > 8) {
        if (m_pOutputHeader->biBitCount == 8) {
            InitDitherMap();
        }
    }
    return NOERROR;
}


// Clean up any resources held for the last commit called. Like the Commit
// this function is used by all the decommit functions regardless of their
// specific transform type just to clean up any common state that we have

HRESULT CConvertor::Decommit()
{
    m_bCommitted = FALSE;
    return NOERROR;
}


// This is called when we commit the memory for colour to palette transforms
// Since the lookup table for this transform is only 12kb we have it defined
// in the module statically negating the need for dynamic memory allocation
// We implement a simple ordered dithering algorithm as explained in Graphics
// Gems II page 72 and 509, published by Academic Press, author James Arvo
// This uses a spatial dithering algorithm although we use a smaller four by
// four magic square rather than sixteen by sixteen in the book to keep the
// size of the lookup table down with only a marginal loss in image quality

BYTE g_DitherMap[3][4][4][256];
DWORD g_DitherInit;

const INT g_magic4x4[4][4] = {  0,  45,   9,  41,
                               35,  16,  25,  19,
                               38,   6,  48,   3,
                               22,  29,  13,  32 };
void InitDitherMap()
{
    INT x,y,z,t,ndiv51,nmod51;
    if (g_DitherInit) return;

    // Calculate the RED, GREEN and BLUE table entries

    for (x = 0;x < 4;x++) {
        for (y = 0;y < 4;y++) {
            for (z = 0;z < 256;z++) {
                t = g_magic4x4[x][y];
                ndiv51 = (z & 0xF8) / 51; nmod51 = (z & 0xF8) % 51;
                g_DitherMap[0][x][y][z] = (ndiv51 + (nmod51 > t));
                g_DitherMap[2][x][y][z] = 36 * (ndiv51 + (nmod51 > t)) + OFFSET;
                ndiv51 = (z & 0xFC) / 51; nmod51 = (z & 0xFC) % 51;
                g_DitherMap[1][x][y][z] = 6 * (ndiv51 + (nmod51 > t));
            }
        }
    }
    g_DitherInit++;
}


// This is a generic conversion class. The conversion it does is to simply
// invert the scan lines so that the output can be placed directly onto a
// DirectDraw surface. We work with all the input formats RGB32/24/555/565
// and 8 bit palettised. If the input and output buffer formats are the
// same then our pins look after just passing the samples straight through

CDirectDrawConvertor::CDirectDrawConvertor(VIDEOINFO *pIn,VIDEOINFO *pOut) :
    CConvertor(pIn,pOut)
{
    ASSERT(pIn);
    ASSERT(pOut);
}


// This goes in the table of available lookups to create a transform object
// derived from the base CConvertor class that does the type specific work.
// We initialise the constructor with the fields that it will need to do the
// conversion work and return a pointer to the object or NULL if it failed

CConvertor *CDirectDrawConvertor::CreateInstance(VIDEOINFO *pIn,
                                                 VIDEOINFO *pOut)
{
    return new CDirectDrawConvertor(pIn,pOut);
}


// Simple buffer copy that inverts the scan line order. This also works if
// the input scan lines are in the right order, but it will obviously add
// an additional image copy that slows us down considerably. This should
// be compiled with intrinsics enabled so that CopyMemory will eventually
// be preprocessed down to a machine instruction on Intel cloned machines
// If you take a 320x240x32 bpp image and read it in a DWORD at a time and
// then write each out it takes approximately 38ms on a 486-66 and 20ms on
// a P5-90. Using CopyMemory is much faster bit still takes quite a while.

HRESULT CDirectDrawConvertor::Transform(BYTE *pInput,BYTE *pOutput)
{
    ASSERT(m_pInputHeader->biBitCount == m_pOutputHeader->biBitCount);

    // Adjust the height to allow for an immediate decrement

    LONG Height = HEIGHT(&m_pOutputInfo->rcTarget) + 1;
    LONG Width = WIDTH(&m_pOutputInfo->rcTarget) * m_pOutputHeader->biBitCount / 8;
    pInput += m_SrcOffset;
    pOutput += m_DstOffset;

    while (--Height) {
        CopyMemory((PVOID)pOutput,(PVOID)pInput,Width);
        pInput += m_SrcStride;
        pOutput += m_DstStride;
    }
    return NOERROR;
}

CMemoryCopyAlphaConvertor::CMemoryCopyAlphaConvertor (VIDEOINFO *pIn,VIDEOINFO *pOut) :
    CConvertor(pIn,pOut)
{
    ASSERT(pIn);
    ASSERT(pOut);
}


CConvertor *CMemoryCopyAlphaConvertor ::CreateInstance(VIDEOINFO *pIn,
                                                 VIDEOINFO *pOut)
{
    return new CMemoryCopyAlphaConvertor (pIn,pOut);
}


HRESULT CMemoryCopyAlphaConvertor ::Transform(BYTE *pInput,BYTE *pOutput)
{
    ASSERT(m_pInputHeader->biBitCount == m_pOutputHeader->biBitCount);

    LONG Height = HEIGHT(&m_pOutputInfo->rcTarget);

    if( m_bSetAlpha )
    {
        LONG Width = WIDTH(&m_pOutputInfo->rcTarget);

        pInput += m_SrcOffset;
        pOutput += m_DstOffset;

        while (Height--) {
            unsigned long * po = (unsigned long*) pOutput;
            unsigned long * pi = (unsigned long*) pInput;
            long W = Width;
            while( W-- ) {
                *po = *pi | unsigned long( 0xFF000000 );
                po++;
                pi++;
            }
            pInput += m_SrcStride;
            pOutput += m_DstStride;
        }
    }
    else
    {
        LONG Width = WIDTH(&m_pOutputInfo->rcTarget) * m_pOutputHeader->biBitCount / 8;

        pInput += m_SrcOffset;
        pOutput += m_DstOffset;

        while (Height--) {
            CopyMemory((PVOID)pOutput,(PVOID)pInput,Width);
            pInput += m_SrcStride;
            pOutput += m_DstStride;
        }
    }

    return NOERROR;
}
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\multimedia\dshow\filters\image\colour\rgb16.h ===
// Copyright (c) Microsoft Corporation 1994-1996. All Rights Reserved
// This file implements RGB16 colour space conversions, May 1995

#ifndef __RGB16__
#define __RGB16__

// This does a similar transform from RGB565 pixel representation to RGB24, as
// for the previous colour conversion we use no lookup tables as the transform
// is very simple, involving little more than an AND to retrieve each colour
// component and then a right shift to align the bits in the byte position

class CRGB565ToRGB24Convertor : public CConvertor {
public:

    CRGB565ToRGB24Convertor(VIDEOINFO *pIn,VIDEOINFO *pOut);
    HRESULT Transform(BYTE *pInput,BYTE *pOutput);
    static CConvertor *CreateInstance(VIDEOINFO *pIn,VIDEOINFO *pOut);
};


// This class converts between RGB555 pixel representation and RGB24, RGB24
// uses one byte per colour component whereas RGB555 uses five bits per pixel
// but they are packed together into a WORD with one bit remaining unused

class CRGB555ToRGB24Convertor : public CConvertor {
public:

    CRGB555ToRGB24Convertor(VIDEOINFO *pIn,VIDEOINFO *pOut);
    HRESULT Transform(BYTE *pInput,BYTE *pOutput);
    static CConvertor *CreateInstance(VIDEOINFO *pIn,VIDEOINFO *pOut);
};


// The RGB565 to RGB8 conversion class uses a 12kb lookup table that is used
// to map an incoming RGB triplet to it's closest matching palette index with
// an approximation to full error diffusion built in. The four indices to the
// table are colour index (red, green or blue), the current row modulo four
// and likewise the column value modulo four and the RGB value respectively

class CRGB565ToRGB8Convertor : public CConvertor {
public:
    CRGB565ToRGB8Convertor(VIDEOINFO *pIn,VIDEOINFO *pOut);
    static CConvertor *CreateInstance(VIDEOINFO *pIn,VIDEOINFO *pOut);
    HRESULT Transform(BYTE *pInput,BYTE *pOutput);
    HRESULT TransformAligned(BYTE *pInput,BYTE *pOutput);
};


// Cheap conversion from RGB565 to RGB555 formats

class CRGB565ToRGB555Convertor : public CConvertor {
public:

    CRGB565ToRGB555Convertor(VIDEOINFO *pIn,VIDEOINFO *pOut);
    HRESULT Transform(BYTE *pInput,BYTE *pOutput);
    static CConvertor *CreateInstance(VIDEOINFO *pIn,VIDEOINFO *pOut);
};


// Another cheap conversion from RGB555 to RGB565 formats

class CRGB555ToRGB565Convertor : public CConvertor {
public:

    CRGB555ToRGB565Convertor(VIDEOINFO *pIn,VIDEOINFO *pOut);
    HRESULT Transform(BYTE *pInput,BYTE *pOutput);
    static CConvertor *CreateInstance(VIDEOINFO *pIn,VIDEOINFO *pOut);
};


// Conversion from RGB565 to RGB32 formats

class CRGB565ToRGB32Convertor : public CConvertor {
public:

    CRGB565ToRGB32Convertor(VIDEOINFO *pIn,VIDEOINFO *pOut);
    HRESULT Transform(BYTE *pInput,BYTE *pOutput);
    static CConvertor *CreateInstance(VIDEOINFO *pIn,VIDEOINFO *pOut);
};


// Conversion from RGB555 to RGB32 formats

class CRGB555ToRGB32Convertor : public CConvertor {
public:

    CRGB555ToRGB32Convertor(VIDEOINFO *pIn,VIDEOINFO *pOut);
    HRESULT Transform(BYTE *pInput,BYTE *pOutput);
    static CConvertor *CreateInstance(VIDEOINFO *pIn,VIDEOINFO *pOut);
};


// The RGB555 to RGB8 conversion class uses a 12kb lookup table that is used
// to map an incoming RGB triplet to it's closest matching palette index with
// an approximation to full error diffusion built in. The four indices to the
// table are colour index (red, green or blue), the current row modulo four
// and likewise the column value modulo four and the RGB value respectively

class CRGB555ToRGB8Convertor : public CConvertor {
public:
    CRGB555ToRGB8Convertor(VIDEOINFO *pIn,VIDEOINFO *pOut);
    static CConvertor *CreateInstance(VIDEOINFO *pIn,VIDEOINFO *pOut);
    HRESULT Transform(BYTE *pInput,BYTE *pOutput);
    HRESULT TransformAligned(BYTE *pInput,BYTE *pOutput);
};

#endif // __RGB16__


=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\multimedia\dshow\filters\image\colour\convert.h ===
// Copyright (c) Microsoft Corporation 1994-1996. All Rights Reserved
// This filter implements popular colour space conversions, May 1995

#ifndef __CONVERT__
#define __CONVERT__

const INT COLOUR_BUFFERS = 1;   // Use just the one output sample buffer
const INT STDPALCOLOURS = 226;  // Number of colours in standard palette
const INT OFFSET = 10;          // First ten colours are used by Windows

#define WIDTH(x) ((*(x)).right - (*(x)).left)
#define HEIGHT(x) ((*(x)).bottom - (*(x)).top)
extern const INT magic4x4[4][4];
extern BYTE g_DitherMap[3][4][4][256];
extern DWORD g_DitherInit;

void InitDitherMap();

// In general the transforms have much in common with the framework they live
// in, so we have a generic (abstract) base class that each and every one of
// the specific transforms derives from. To their derived class they add an
// implementation of Transform, perhaps overriding Commit to allocate lookup
// tables they require (and Decommit to clean them up). They may also add
// other private member variables for mapping and colour lookup tables

class CConvertor {
protected:

    VIDEOINFO *m_pInputInfo;             // Input media type information
    VIDEOINFO *m_pOutputInfo;            // Output type information
    BITMAPINFOHEADER *m_pInputHeader;    // Input bitmap header
    BITMAPINFOHEADER *m_pOutputHeader;   // Output bitmap header
    BOOL m_bCommitted;                   // Have we been committed
    LONG m_SrcOffset;                    // Source original offset
    LONG m_SrcStride;                    // Length in bytes of a scan line
    LONG m_DstStride;                    // Likewise offset into target
    LONG m_DstOffset;                    // And the length of each line
    BOOL m_bAligned;                     // Are our rectangles aligned
    BOOL m_bSetAlpha;

public:

    // Constructor and destructor

    CConvertor(VIDEOINFO *pIn,VIDEOINFO *pOut);
    virtual ~CConvertor();

    // These are the methods that do the work

    void ForceAlignment(BOOL bAligned);
    void InitRectangles(VIDEOINFO *pIn,VIDEOINFO *pOut);
    virtual HRESULT Commit();
    virtual HRESULT Decommit();
    virtual HRESULT Transform(BYTE *pInput,BYTE *pOutput) PURE;

    void SetFillInAlpha( ) { m_bSetAlpha = TRUE; }
};

// These header files define the type specific transform classes

#include "rgb32.h"
#include "rgb24.h"
#include "rgb16.h"
#include "rgb8.h"

// This class acts as a low cost pass through convertor where all it does is
// to rearrange the scan lines from bottom up order (as defined for DIBs) to
// top down that DirectDraw surfaces use. This allows a file source filter
// to be connected to the renderer with a minimum of work to gain access to
// DirectDraw. Doing this scan line inversion introduces a memory copy but
// that is balanced by the saving from not having to use GDI to draw after.
// This class works across all DIB formats (eg RGB32/24/565/555 and 8 bit)

class CDirectDrawConvertor : public CConvertor {
public:

    CDirectDrawConvertor(VIDEOINFO *pIn,VIDEOINFO *pOut);
    HRESULT Transform(BYTE *pInput,BYTE *pOutput);
    static CConvertor *CreateInstance(VIDEOINFO *pIn,VIDEOINFO *pOut);
};

class CMemoryCopyAlphaConvertor : public CConvertor {
public:

    CMemoryCopyAlphaConvertor(VIDEOINFO *pIn,VIDEOINFO *pOut);
    HRESULT Transform(BYTE *pInput,BYTE *pOutput);
    static CConvertor *CreateInstance(VIDEOINFO *pIn,VIDEOINFO *pOut);
};

// We keep a default dithering palette and some lookup tables in a section of
// shared memory (shared between all loadings of this DLL) but we cannot just
// include the header file into all the source files as the tables will all be
// defined multiple times (and produce linker warnings), so we extern them in
// here and then the main source file really includes the full definitions

extern const RGBQUAD StandardPalette[];
extern const BYTE RedScale[];
extern const BYTE BlueScale[];
extern const BYTE GreenScale[];
extern const BYTE PalettePad[];

// This is the list of colour space conversions that thie filter supports.
// The memory for the GUIDS is actually allocated in the DLL curtosy of the
// colour source file that includes initguid which causes DEFINE_GUID to
// actually allocate memory. The table is scanned to provide possible media
// types for the media type enumerator and also to check we can support a
// transform - WARNING the list of transforms must match with TRANSFORMS

typedef CConvertor *(*PCONVERTOR)(VIDEOINFO *pIn,VIDEOINFO *pOut);

const struct {
    const GUID *pInputType;     // Source video media subtype
    const GUID *pOutputType;    // Output media subtype
    PCONVERTOR pConvertor;      // Object implementing transforms
} TypeMap[] = {

      &MEDIASUBTYPE_ARGB32,    &MEDIASUBTYPE_ARGB32,
      CDirectDrawConvertor::CreateInstance,

      &MEDIASUBTYPE_ARGB32,    &MEDIASUBTYPE_RGB32, // just does a memcopy, yuck
      CMemoryCopyAlphaConvertor::CreateInstance,

      &MEDIASUBTYPE_ARGB32,    &MEDIASUBTYPE_RGB565,
      CRGB32ToRGB565Convertor::CreateInstance,

      &MEDIASUBTYPE_ARGB32,    &MEDIASUBTYPE_RGB555,
      CRGB32ToRGB555Convertor::CreateInstance,

      &MEDIASUBTYPE_ARGB32,    &MEDIASUBTYPE_RGB24,
      CRGB32ToRGB24Convertor::CreateInstance,

      &MEDIASUBTYPE_ARGB32,    &MEDIASUBTYPE_RGB8,
      CRGB32ToRGB8Convertor::CreateInstance,


      &MEDIASUBTYPE_RGB32,    &MEDIASUBTYPE_RGB32,
      CDirectDrawConvertor::CreateInstance,

      &MEDIASUBTYPE_RGB32,    &MEDIASUBTYPE_ARGB32, // does a memcpy with alpha fill
      CMemoryCopyAlphaConvertor::CreateInstance,

      &MEDIASUBTYPE_RGB32,    &MEDIASUBTYPE_RGB24,
      CRGB32ToRGB24Convertor::CreateInstance,

      &MEDIASUBTYPE_RGB32,    &MEDIASUBTYPE_RGB565,
      CRGB32ToRGB565Convertor::CreateInstance,

      &MEDIASUBTYPE_RGB32,    &MEDIASUBTYPE_RGB555,
      CRGB32ToRGB555Convertor::CreateInstance,

      &MEDIASUBTYPE_RGB32,    &MEDIASUBTYPE_RGB8,
      CRGB32ToRGB8Convertor::CreateInstance,


      &MEDIASUBTYPE_RGB24,    &MEDIASUBTYPE_RGB32,
      CRGB24ToRGB32Convertor::CreateInstance,

      &MEDIASUBTYPE_RGB24,    &MEDIASUBTYPE_ARGB32,
      CRGB24ToRGB32Convertor::CreateInstance,

      &MEDIASUBTYPE_RGB24,    &MEDIASUBTYPE_RGB24,
      CDirectDrawConvertor::CreateInstance,

      &MEDIASUBTYPE_RGB24,    &MEDIASUBTYPE_RGB565,
      CRGB24ToRGB565Convertor::CreateInstance,

      &MEDIASUBTYPE_RGB24,    &MEDIASUBTYPE_RGB555,
      CRGB24ToRGB555Convertor::CreateInstance,

      &MEDIASUBTYPE_RGB24,    &MEDIASUBTYPE_RGB8,
      CRGB24ToRGB8Convertor::CreateInstance,


      &MEDIASUBTYPE_RGB565,   &MEDIASUBTYPE_RGB32,
      CRGB565ToRGB32Convertor::CreateInstance,

      &MEDIASUBTYPE_RGB565,   &MEDIASUBTYPE_ARGB32,
      CRGB565ToRGB32Convertor::CreateInstance,

      &MEDIASUBTYPE_RGB565,   &MEDIASUBTYPE_RGB24,
      CRGB565ToRGB24Convertor::CreateInstance,

      &MEDIASUBTYPE_RGB565,   &MEDIASUBTYPE_RGB565,
      CDirectDrawConvertor::CreateInstance,

      &MEDIASUBTYPE_RGB565,   &MEDIASUBTYPE_RGB555,
      CRGB565ToRGB555Convertor::CreateInstance,

      &MEDIASUBTYPE_RGB565,   &MEDIASUBTYPE_RGB8,
      CRGB565ToRGB8Convertor::CreateInstance,


      &MEDIASUBTYPE_RGB555,   &MEDIASUBTYPE_RGB32,
      CRGB555ToRGB32Convertor::CreateInstance,

      &MEDIASUBTYPE_RGB555,   &MEDIASUBTYPE_ARGB32,
      CRGB555ToRGB32Convertor::CreateInstance,

      &MEDIASUBTYPE_RGB555,   &MEDIASUBTYPE_RGB24,
      CRGB555ToRGB24Convertor::CreateInstance,

      &MEDIASUBTYPE_RGB555,   &MEDIASUBTYPE_RGB565,
      CRGB555ToRGB565Convertor::CreateInstance,

      &MEDIASUBTYPE_RGB555,   &MEDIASUBTYPE_RGB555,
      CDirectDrawConvertor::CreateInstance,

      &MEDIASUBTYPE_RGB555,   &MEDIASUBTYPE_RGB8,
      CRGB555ToRGB8Convertor::CreateInstance,


      &MEDIASUBTYPE_RGB8,     &MEDIASUBTYPE_RGB32,
      CRGB8ToRGB32Convertor::CreateInstance,

      &MEDIASUBTYPE_RGB8,     &MEDIASUBTYPE_ARGB32,
      CRGB8ToRGB32Convertor::CreateInstance,

      &MEDIASUBTYPE_RGB8,     &MEDIASUBTYPE_RGB24,
      CRGB8ToRGB24Convertor::CreateInstance,

      &MEDIASUBTYPE_RGB8,     &MEDIASUBTYPE_RGB565,
      CRGB8ToRGB565Convertor::CreateInstance,

      &MEDIASUBTYPE_RGB8,     &MEDIASUBTYPE_RGB555,
      CRGB8ToRGB555Convertor::CreateInstance,

      &MEDIASUBTYPE_RGB8,     &MEDIASUBTYPE_RGB8,
      CDirectDrawConvertor::CreateInstance };

const INT TRANSFORMS = sizeof(TypeMap) / sizeof(TypeMap[0]);

#endif // __CONVERT__
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\multimedia\dshow\filters\image\colour\rgb16.cpp ===
// Copyright (c) Microsoft Corporation 1994-1996. All Rights Reserved
// This file implements RGB 16 colour space conversions, May 1995

#include <streams.h>
#include <colour.h>

// We do RGB555 and RGB565 formats converted to RGB8,RGB24,and RGB32. We also
// convert RGB555 to RGB565 and vica versa although they are unlikely ever to
// be used because the formats are so similar any self respecting codec will
// do both formats themselves. The RGB555 and RGB565 to 8 bit uses a dither
// table we create and initialise when the filter is instantiated. The other
// conversions require reading the data and rearranging the pixel bits. Only
// the dithering conversions have aligned optimised versions (in which the
// source and target rectangles as well as their sizes must be DWORD aligned)


// Constructor for RGB565 to RGB24 colour conversions

CRGB565ToRGB24Convertor::CRGB565ToRGB24Convertor(VIDEOINFO *pIn,
                                                 VIDEOINFO *pOut) :
    CConvertor(pIn,pOut)
{
    ASSERT(pIn);
    ASSERT(pOut);
}


// This goes in the table of available lookups to create a transform object
// derived from the base CConvertor class that does the type specific work.
// We initialise the constructor with the fields that it will need to do the
// conversion work and return a pointer to the object or NULL if it failed

CConvertor *CRGB565ToRGB24Convertor::CreateInstance(VIDEOINFO *pIn,
                                                    VIDEOINFO *pOut)
{
    return new CRGB565ToRGB24Convertor(pIn,pOut);
}


// Constructor for RGB555 to RGB24 colour conversions

CRGB555ToRGB24Convertor::CRGB555ToRGB24Convertor(VIDEOINFO *pIn,
                                                 VIDEOINFO *pOut) :
    CConvertor(pIn,pOut)
{
    ASSERT(pIn);
    ASSERT(pOut);
}


// This goes in the table of available lookups to create a transform object
// derived from the base CConvertor class that does the type specific work.
// We initialise the constructor with the fields that it will need to do the
// conversion work and return a pointer to the object or NULL if it failed

CConvertor *CRGB555ToRGB24Convertor::CreateInstance(VIDEOINFO *pIn,
                                                    VIDEOINFO *pOut)
{
    return new CRGB555ToRGB24Convertor(pIn,pOut);
}


// This converts an input RGB555 image into an output RGB24 format. We could
// use a large lookup table for this but the large number of memory accesses
// as well as the not insignificant footprint meant that we normally better
// off doing a little arithmetic in the CPU to calculate the colour values

HRESULT CRGB555ToRGB24Convertor::Transform(BYTE *pInput,BYTE *pOutput)
{
    // Adjust the height to allow for an immediate decrement

    LONG Height = HEIGHT(&m_pOutputInfo->rcTarget) + 1;
    pInput += m_SrcOffset;
    pOutput += m_DstOffset;

    while (--Height) {

        LONG Width = WIDTH(&m_pOutputInfo->rcTarget) + 1;
        WORD *pRGB555 = (WORD *) pInput;
        BYTE *pRGB24 = pOutput;

        while (--Width) {
            DWORD Pixel = *pRGB555++;
            pRGB24[0] = (UCHAR) ((Pixel & 0x001F) << 3);
            pRGB24[1] = (UCHAR) ((Pixel & 0x03E0) >> 2);
            pRGB24[2] = (UCHAR) ((Pixel & 0x7C00) >> 7);
            pRGB24 += 3;
        }
        pOutput += m_DstStride;
        pInput += m_SrcStride;
    }
    return NOERROR;
}


// This converts an input RGB565 image into an output RGB24 format. We could
// use a large lookup table for this but the large number of memory accesses
// as well as the not insignificant footprint meant that we normally better
// off doing a little arithmetic in the CPU to calculate the colour values

HRESULT CRGB565ToRGB24Convertor::Transform(BYTE *pInput,BYTE *pOutput)
{
    // Adjust the height to allow for an immediate decrement

    LONG Height = HEIGHT(&m_pOutputInfo->rcTarget) + 1;
    pInput += m_SrcOffset;
    pOutput += m_DstOffset;

    while (--Height) {

        LONG Width = WIDTH(&m_pOutputInfo->rcTarget) + 1;
        WORD *pRGB565 = (WORD *) pInput;
        BYTE *pRGB24 = pOutput;

        while (--Width) {
            DWORD Pixel = *pRGB565++;
            pRGB24[0] = (UCHAR) ((Pixel & 0x001F) << 3);
            pRGB24[1] = (UCHAR) ((Pixel & 0x07E0) >> 3);
            pRGB24[2] = (UCHAR) ((Pixel & 0xF800) >> 8);
            pRGB24 += 3;
        }
        pInput += m_SrcStride;
        pOutput += m_DstStride;
    }
    return NOERROR;
}


// Constructor for RGB565 to RGB8 colour conversions

CRGB565ToRGB8Convertor::CRGB565ToRGB8Convertor(VIDEOINFO *pIn,
                                               VIDEOINFO *pOut) :
    CConvertor(pIn,pOut)
{
    ASSERT(pIn);
    ASSERT(pOut);
}


// This goes in the table of available lookups to create a transform object
// derived from the base CConvertor class that does the type specific work.
// We initialise the constructor with the fields that it will need to do the
// conversion work and return a pointer to the object or NULL if it failed

CConvertor *CRGB565ToRGB8Convertor::CreateInstance(VIDEOINFO *pIn,
                                                   VIDEOINFO *pOut)
{
    return new CRGB565ToRGB8Convertor(pIn,pOut);
}


// This converts an input RGB565 pixel image into a dithered RGB8 palettised
// image, we scan through the image converting each pixel in turn using the
// ordered dithering algorithm that selects output pixels dependant on their
// coordinate position in the source image. This makes a rough approximation
// to full error propogation but without the heavy computational overhead

#define DITH565(x,y,rgb)                                     \
    (g_DitherMap[0][((x)&3)][((y)&3)][(((rgb)>>8)&0xF8)] +   \
     g_DitherMap[1][((x)&3)][((y)&3)][(((rgb)>>3)&0xFC)] +   \
     g_DitherMap[2][((x)&3)][((y)&3)][(((rgb)<<3)&0xF8)])

HRESULT CRGB565ToRGB8Convertor::Transform(BYTE *pInput,BYTE *pOutput)
{
    // Can we do an alignment optimised transform

    if (m_bAligned == TRUE) {
        return TransformAligned(pInput,pOutput);
    }

    // Adjust the height to allow for an immediate decrement

    LONG Height = HEIGHT(&m_pOutputInfo->rcTarget) + 1;
    pInput += m_SrcOffset;
    pOutput += m_DstOffset;

    while (--Height) {

        LONG Width = WIDTH(&m_pOutputInfo->rcTarget) + 1;
        WORD *pRGB565 = (WORD *) pInput;
        BYTE *pRGB8 = pOutput;

        while (--Width) {
            DWORD RGB565 = *pRGB565++;
            *pRGB8++ = DITH565(Width,Height,RGB565);
        }
        pInput += m_SrcStride;
        pOutput += m_DstStride;
    }
    return NOERROR;
}


// This does the same colour space conversion as the RGB565 to RGB8 convertor
// except that it goes a little faster. The way it does this is by reading
// and writing DWORDs into memory. For example we write four of the dithered
// palettised pixels at once. The relies on the source and target pointers
// being aligned correctly otherwise we will start geting exceptions on RISC

HRESULT CRGB565ToRGB8Convertor::TransformAligned(BYTE *pInput,BYTE *pOutput)
{
    // Adjust the height to allow for an immediate decrement

    LONG Height = HEIGHT(&m_pOutputInfo->rcTarget) + 1;
    pInput += m_SrcOffset;
    pOutput += m_DstOffset;

    while (--Height) {

        LONG Width = (WIDTH(&m_pOutputInfo->rcTarget) >> 2) + 1;
        DWORD *pRGB565 = (DWORD *) pInput;
        DWORD *pRGB8 = (DWORD *) pOutput;

        while (--Width) {

            // Read the two DWORDs that hold four sixteen bit pixels

            DWORD RGB565a = *pRGB565++;
            DWORD RGB565b = *pRGB565++;

            // Construct a DWORD containing four palettised pixels

            *pRGB8++ = (DITH565(0,Height,RGB565a)) |
                       (DITH565(1,Height,(RGB565a >> 16)) << 8) |
                       (DITH565(2,Height,RGB565b) << 16) |
                       (DITH565(3,Height,(RGB565b >> 16)) << 24);
        }
        pInput += m_SrcStride;
        pOutput += m_DstStride;
    }
    return NOERROR;
}


// Constructor for RGB565 to RGB555 colour conversions

CRGB565ToRGB555Convertor::CRGB565ToRGB555Convertor(VIDEOINFO *pIn,
                                                   VIDEOINFO *pOut) :
    CConvertor(pIn,pOut)
{
    ASSERT(pIn);
    ASSERT(pOut);
}


// This goes in the table of available lookups to create a transform object
// derived from the base CConvertor class that does the type specific work.
// We initialise the constructor with the fields that it will need to do the
// conversion work and return a pointer to the object or NULL if it failed

CConvertor *CRGB565ToRGB555Convertor::CreateInstance(VIDEOINFO *pIn,
                                                     VIDEOINFO *pOut)
{
    return new CRGB565ToRGB555Convertor(pIn,pOut);
}


// This converts an input RGB565 image into an output RGB555 format. We could
// use a large lookup table for this but the large number of memory accesses
// as well as the not insignificant footprint meant that we normally better
// off doing a little arithmetic in the CPU to calculate the colour values

HRESULT CRGB565ToRGB555Convertor::Transform(BYTE *pInput,BYTE *pOutput)
{
    // Adjust the height to allow for an immediate decrement

    LONG Height = HEIGHT(&m_pOutputInfo->rcTarget) + 1;
    pInput += m_SrcOffset;
    pOutput += m_DstOffset;

    while (--Height) {

        LONG Width = WIDTH(&m_pOutputInfo->rcTarget) + 1;
        WORD *pRGB565 = (WORD *) pInput;
        WORD *pRGB555 = (WORD *) pOutput;

        while (--Width) {
            *pRGB555++ = (*pRGB565 & 0x1F) | ((*pRGB565 & 0xFFC0) >> 1);
            pRGB565++;
        }
        pInput += m_SrcStride;
        pOutput += m_DstStride;
    }
    return NOERROR;
}


// Constructor for RGB555 to RGB565 colour conversions

CRGB555ToRGB565Convertor::CRGB555ToRGB565Convertor(VIDEOINFO *pIn,
                                                   VIDEOINFO *pOut) :
    CConvertor(pIn,pOut)
{
    ASSERT(pIn);
    ASSERT(pOut);
}


// This goes in the table of available lookups to create a transform object
// derived from the base CConvertor class that does the type specific work.
// We initialise the constructor with the fields that it will need to do the
// conversion work and return a pointer to the object or NULL if it failed

CConvertor *CRGB555ToRGB565Convertor::CreateInstance(VIDEOINFO *pIn,
                                                     VIDEOINFO *pOut)
{
    return new CRGB555ToRGB565Convertor(pIn,pOut);
}


// This converts an input RGB555 image into an output RGB565 format. We could
// use a large lookup table for this but the large number of memory accesses
// as well as the not insignificant footprint meant that we normally better
// off doing a little arithmetic in the CPU to calculate the colour values

HRESULT CRGB555ToRGB565Convertor::Transform(BYTE *pInput,BYTE *pOutput)
{
    // Adjust the height to allow for an immediate decrement

    LONG Height = HEIGHT(&m_pOutputInfo->rcTarget) + 1;
    pInput += m_SrcOffset;
    pOutput += m_DstOffset;

    while (--Height) {

        LONG Width = WIDTH(&m_pOutputInfo->rcTarget) + 1;
        WORD *pRGB555 = (WORD *) pInput;
        WORD *pRGB565 = (WORD *) pOutput;

        while (--Width) {
            *pRGB565++ = (*pRGB555 & 0x1F) | ((*pRGB555 & 0x7FE0) << 1);
            pRGB555++;
        }
        pInput += m_SrcStride;
        pOutput += m_DstStride;
    }
    return NOERROR;
}


// Constructor for RGB565 to RGB32 colour conversions

CRGB565ToRGB32Convertor::CRGB565ToRGB32Convertor(VIDEOINFO *pIn,
                                                 VIDEOINFO *pOut) :
    CConvertor(pIn,pOut)
{
    ASSERT(pIn);
    ASSERT(pOut);
}


// This goes in the table of available lookups to create a transform object
// derived from the base CConvertor class that does the type specific work.
// We initialise the constructor with the fields that it will need to do the
// conversion work and return a pointer to the object or NULL if it failed

CConvertor *CRGB565ToRGB32Convertor::CreateInstance(VIDEOINFO *pIn,
                                                    VIDEOINFO *pOut)
{
    return new CRGB565ToRGB32Convertor(pIn,pOut);
}


// This converts an input RGB565 image into an output RGB32 format. We could
// use a large lookup table for this but the large number of memory accesses
// as well as the not insignificant footprint meant that we normally better
// off doing a little arithmetic in the CPU to calculate the colour values

HRESULT CRGB565ToRGB32Convertor::Transform(BYTE *pInput,BYTE *pOutput)
{
    // Adjust the height to allow for an immediate decrement

    LONG Height = HEIGHT(&m_pOutputInfo->rcTarget) + 1;
    pInput += m_SrcOffset;
    pOutput += m_DstOffset;

    if( m_bSetAlpha )
    {
        while (--Height) {

            LONG Width = WIDTH(&m_pOutputInfo->rcTarget) + 1;
            WORD *pRGB565 = (WORD *) pInput;
            DWORD *pRGB32 = (DWORD *) pOutput;

            while (--Width) {
                *pRGB32++ = 0xFF000000 | // white in the alpha
                            ((*pRGB565 & 0x001F) << 3) |
                            ((*pRGB565 & 0x07E0) << 5) |
                            ((*pRGB565 & 0xF800) << 8);
                pRGB565++;
            }
            pInput += m_SrcStride;
            pOutput += m_DstStride;
        }
    }
    else
    {
        while (--Height) {

            LONG Width = WIDTH(&m_pOutputInfo->rcTarget) + 1;
            WORD *pRGB565 = (WORD *) pInput;
            DWORD *pRGB32 = (DWORD *) pOutput;

            while (--Width) {
                *pRGB32++ = ((*pRGB565 & 0x001F) << 3) |
                            ((*pRGB565 & 0x07E0) << 5) |
                            ((*pRGB565 & 0xF800) << 8);
                pRGB565++;
            }
            pInput += m_SrcStride;
            pOutput += m_DstStride;
        }
    }
    return NOERROR;
}


// Constructor for RGB555 to RGB32 colour conversions

CRGB555ToRGB32Convertor::CRGB555ToRGB32Convertor(VIDEOINFO *pIn,
                                                 VIDEOINFO *pOut) :
    CConvertor(pIn,pOut)
{
    ASSERT(pIn);
    ASSERT(pOut);
}


// This goes in the table of available lookups to create a transform object
// derived from the base CConvertor class that does the type specific work.
// We initialise the constructor with the fields that it will need to do the
// conversion work and return a pointer to the object or NULL if it failed

CConvertor *CRGB555ToRGB32Convertor::CreateInstance(VIDEOINFO *pIn,
                                                    VIDEOINFO *pOut)
{
    return new CRGB555ToRGB32Convertor(pIn,pOut);
}


// This converts an input RGB555 image into an output RGB32 format. We could
// use a large lookup table for this but the large number of memory accesses
// as well as the not insignificant footprint meant that we normally better
// off doing a little arithmetic in the CPU to calculate the colour values

HRESULT CRGB555ToRGB32Convertor::Transform(BYTE *pInput,BYTE *pOutput)
{
    // Adjust the height to allow for an immediate decrement

    LONG Height = HEIGHT(&m_pOutputInfo->rcTarget) + 1;
    pInput += m_SrcOffset;
    pOutput += m_DstOffset;

    if( m_bSetAlpha )
    {
        while (--Height) {

            LONG Width = WIDTH(&m_pOutputInfo->rcTarget) + 1;
            WORD *pRGB555 = (WORD *) pInput;
            DWORD *pRGB32 = (DWORD *) pOutput;

            while (--Width) {
                *pRGB32++ = 0xFF000000 |
                            ((*pRGB555 & 0x001F) << 3) |
                            ((*pRGB555 & 0x03E0) << 6) |
                            ((*pRGB555 & 0x7C00) << 9);
                pRGB555++;
            }
            pInput += m_SrcStride;
            pOutput += m_DstStride;
        }
    }
    else
    {
        while (--Height) {

            LONG Width = WIDTH(&m_pOutputInfo->rcTarget) + 1;
            WORD *pRGB555 = (WORD *) pInput;
            DWORD *pRGB32 = (DWORD *) pOutput;

            while (--Width) {
                *pRGB32++ = ((*pRGB555 & 0x001F) << 3) |
                            ((*pRGB555 & 0x03E0) << 6) |
                            ((*pRGB555 & 0x7C00) << 9);
                pRGB555++;
            }
            pInput += m_SrcStride;
            pOutput += m_DstStride;
        }
    }
    return NOERROR;
}


// Constructor for RGB555 to RGB8 colour conversions

CRGB555ToRGB8Convertor::CRGB555ToRGB8Convertor(VIDEOINFO *pIn,
                                               VIDEOINFO *pOut) :
    CConvertor(pIn,pOut)
{
    ASSERT(pIn);
    ASSERT(pOut);
}


// This goes in the table of available lookups to create a transform object
// derived from the base CConvertor class that does the type specific work.
// We initialise the constructor with the fields that it will need to do the
// conversion work and return a pointer to the object or NULL if it failed

CConvertor *CRGB555ToRGB8Convertor::CreateInstance(VIDEOINFO *pIn,
                                                   VIDEOINFO *pOut)
{
    return new CRGB555ToRGB8Convertor(pIn,pOut);
}


// This converts an input RGB555 pixel image into a dithered RGB8 palettised
// image, we scan through the image converting each pixel in turn using the
// ordered dithering algorithm that selects output pixels dependant on their
// coordinate position in the source image. This makes a rough approximation
// to full error propogation but without the heavy computational overhead

#define DITH555(x,y,rgb)                                       \
    (g_DitherMap[0][((x)&3)][((y)&3)][(((rgb)>>7)&0xF8)] +     \
     g_DitherMap[1][((x)&3)][((y)&3)][(((rgb)>>2)&0xF8)] +     \
     g_DitherMap[2][((x)&3)][((y)&3)][(((rgb)<<3)&0xF8)])

HRESULT CRGB555ToRGB8Convertor::Transform(BYTE *pInput,BYTE *pOutput)
{
    // Can we do an alignment optimised transform

    if (m_bAligned == TRUE) {
        return TransformAligned(pInput,pOutput);
    }

    // Adjust the height to allow for an immediate decrement

    LONG Height = HEIGHT(&m_pOutputInfo->rcTarget) + 1;
    pInput += m_SrcOffset;
    pOutput += m_DstOffset;

    while (--Height) {

        LONG Width = WIDTH(&m_pOutputInfo->rcTarget) + 1;
        WORD *pRGB555 = (WORD *) pInput;
        BYTE *pRGB8 = pOutput;

        while (--Width) {
            DWORD RGB555 = *pRGB555++;
            *pRGB8++ = DITH555(Width,Height,RGB555);
        }
        pInput += m_SrcStride;
        pOutput += m_DstStride;
    }
    return NOERROR;
}


// This does the same colour space conversion as the RGB555 to RGB8 convertor
// except that it goes a little faster. The way it does this is by reading
// and writing DWORDs into memory. For example we write four of the dithered
// palettised pixels at once. The relies on the source and target pointers
// being aligned correctly otherwise we will start geting exceptions on RISC

HRESULT CRGB555ToRGB8Convertor::TransformAligned(BYTE *pInput,BYTE *pOutput)
{
    // Adjust the height to allow for an immediate decrement

    LONG Height = HEIGHT(&m_pOutputInfo->rcTarget) + 1;
    pInput += m_SrcOffset;
    pOutput += m_DstOffset;

    while (--Height) {

        LONG Width = (WIDTH(&m_pOutputInfo->rcTarget) >> 2) + 1;
        DWORD *pRGB555 = (DWORD *) pInput;
        DWORD *pRGB8 = (DWORD *) pOutput;

        while (--Width) {

            // Read the two DWORDs that hold four sixteen bit pixels

            DWORD RGB555a = *pRGB555++;
            DWORD RGB555b = *pRGB555++;

            // Construct a DWORD containing four palettised pixels

            *pRGB8++ = (DITH555(0,Height,RGB555a)) |
                       (DITH555(1,Height,(RGB555a >> 16)) << 8) |
                       (DITH555(2,Height,RGB555b) << 16) |
                       (DITH555(3,Height,(RGB555b >> 16)) << 24);
        }
        pInput += m_SrcStride;
        pOutput += m_DstStride;
    }
    return NOERROR;
}
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\multimedia\dshow\filters\image\colour\colour.h ===
// Copyright (c) 1994 - 1999  Microsoft Corporation.  All Rights Reserved.
// This filter implements popular colour space conversions, May 1995

#ifndef __COLOUR__
#define __COLOUR__

extern const AMOVIESETUP_FILTER sudColourFilter;

// Forward declarations

class CColour;
class CColourAllocator;
class CColourInputPin;

#include <convert.h>

// We provide our own allocator for the input pin. We do this so that when a
// downstream filter asks if we can supply a given format we can see if our
// source will provide it directly - in which case we are effectively a null
// filter in the middle doing nothing. To handle this type changing requires
// an allocator. All we have to override is GetBuffer to manage which buffer
// to return (ours or the downstream filters if we are passing through) and
// also to handle released samples which haven't been passed to the input pin

class CColourAllocator : public CMemAllocator
{
    CColour *m_pColour;     // Main colour filter
    CCritSec *m_pLock;      // The receive lock

public:

    CColourAllocator(TCHAR *pName,
                     CColour *pColour,
                     HRESULT *phr,
                     CCritSec *pLock);

    // Overriden to delegate reference counts to the filter

    STDMETHODIMP_(ULONG) NonDelegatingAddRef();
    STDMETHODIMP_(ULONG) NonDelegatingRelease();

    BOOL ChangeType(IMediaSample *pIn,IMediaSample *pOut);
    STDMETHODIMP ReleaseBuffer(IMediaSample *pSample);
    STDMETHODIMP GetBuffer(IMediaSample **ppBuffer,
                           REFERENCE_TIME *pStart,
                           REFERENCE_TIME *pEnd,
                           DWORD dwFlags);
    STDMETHODIMP SetProperties(
		    ALLOCATOR_PROPERTIES* pRequest,
		    ALLOCATOR_PROPERTIES* pActual);

};


// To help with returning our own allocator we must provide our own input pin
// instead of using the transform class. We override the input pin so that we
// can return our own allocator when GetAllocator is called. It also lets us
// handle Receive being called. If we are handed back a sample that we just
// passed through from the downstream filter then we only have to deliver it
// rather than do any colour conversion. We must cooperate with the allocator
// to do this switching - in particular the state of variable m_bPassThrough

class CColourInputPin : public CTransformInputPin
{
    CColour *m_pColour;     // Main colour filter
    CCritSec *m_pLock;      // The receive lock

public:

    CColourInputPin(TCHAR *pObjectName,     // DEBUG only string
                    CColour *pColour,       // Main colour filter
                    CCritSec *pLock,        // The receive lock
                    HRESULT *phr,           // Quartz return code
                    LPCWSTR pName);         // Actual pin name

    STDMETHODIMP GetAllocator(IMemAllocator **ppAllocator);
    STDMETHODIMP Receive(IMediaSample *pSample);
    HRESULT CheckMediaType(const CMediaType *pmtIn);
    HRESULT CanSupplyType(const AM_MEDIA_TYPE *pMediaType);
    void CopyProperties(IMediaSample *pSrc,IMediaSample *pDst);
    IMemAllocator *Allocator() const { return m_pAllocator; }
};

class CColourOutputPin : public CTransformOutputPin
{
    CColour * m_pColour;

public:

    CColourOutputPin(
        TCHAR *pObjectName,
        CColour * pTransformFilter,
        HRESULT * phr,
        LPCWSTR pName);

    HRESULT DecideAllocator(IMemInputPin *pPin, IMemAllocator **ppAlloc);
    HRESULT CompleteConnect(IPin *pReceivePin);
};

// This is the basic colour conversion filter, we inherit from the base class
// defined CTransformFilter so that it can look after most of the framework
// involved with setting up connections, providing media type enumerators and
// other generally boring hassle. This filter does all conversions from any
// input to any output which makes it much easier to agree input and output
// formats and to change them dynamically (such us when using DirectDraw) as
// we can guarantee never to have to reconnect the input pin. If we were not
// symmetrical we may have to reconnect the input to be able to provide some
// output formats (which is very hard to do when we are already streaming)

class CColour : public CTransformFilter
{
    friend class CColourAllocator;
    friend class CColourInputPin;
    friend class CColourOutputPin;

    // Typed media type list derived from the generic list template
    typedef CGenericList<AM_MEDIA_TYPE> CTypeList;

    CConvertor *m_pConvertor;               // Does the transform functions
    INT m_TypeIndex;                        // Current convertor position
    CColourAllocator m_ColourAllocator;     // Our own derived allocator
    CColourInputPin m_ColourInputPin;       // Our specialised input pin
    BOOL m_bPassThrough;                    // Are we just passing through
    BOOL m_bPassThruAllowed;                // can we go into pass-through?
    IMediaSample *m_pOutSample;             // Output buffer sample pointer
    BOOL m_bOutputConnected;                // Is the output really done
    CTypeList m_TypeList;                   // List of source media types
    CMediaType m_mtOut;                     // And likewise the output type
    BOOL m_fReconnecting;		    // reconnecting our input pin?

    // Prepare an output media type for the enumerator

    void DisplayVideoType(TCHAR *pDescription,const CMediaType *pmt);
    VIDEOINFO *PreparePalette(CMediaType *pmtOut);
    VIDEOINFO *PrepareTrueColour(CMediaType *pmtOut);
    HRESULT PrepareMediaType(CMediaType *pmtOut,const GUID *pSubtype);
    const GUID *FindOutputType(const GUID *pInputType,INT iIndex);
    INT FindTransform(const GUID *pInputType,const GUID *pOutputType);
    HRESULT CheckVideoType(const AM_MEDIA_TYPE *pmt);
    BOOL IsUsingFakeAllocator( );

    // Load and manage the list of YUV source formats

    AM_MEDIA_TYPE *GetNextMediaType(IEnumMediaTypes *pEnumMediaTypes);
    HRESULT FillTypeList(IEnumMediaTypes *pEnumMediaTypes);
    AM_MEDIA_TYPE *GetListMediaType(INT Position);
    HRESULT LoadMediaTypes(IPin *pPin);
    void InitTypeList();

public:

    // Constructor and destructor

    CColour(TCHAR *pName,LPUNKNOWN pUnk,HRESULT *phr);
    ~CColour();

    // This goes in the factory template table to create new instances
    static CUnknown *CreateInstance(LPUNKNOWN pUnk,HRESULT *phr);

    // Manage type checking and the format conversions

    HRESULT CheckInputType(const CMediaType *pmtIn);
    HRESULT CheckTransform(const CMediaType *pmtIn,const CMediaType *pmtOut);
    HRESULT BreakConnect(PIN_DIRECTION dir);
    HRESULT CheckConnect(PIN_DIRECTION dir,IPin *pPin);
    HRESULT CompleteConnect(PIN_DIRECTION dir,IPin *pReceivePin);
    HRESULT OutputCompleteConnect(IPin *pReceivePin);
    HRESULT Transform(IMediaSample *pIn,IMediaSample *pOut);
    HRESULT PrepareTransform(IMediaSample *pIn,IMediaSample *pOut);
    HRESULT StartStreaming();

    // Prepare the allocator's count of buffers and sizes
    HRESULT DecideBufferSize(IMemAllocator *pAllocator,
                             ALLOCATOR_PROPERTIES *pProperties);

    // Overriden to manage the media type negotiation

    HRESULT GetMediaType(int iPosition,CMediaType *pmtOut);
    HRESULT SetMediaType(PIN_DIRECTION direction,const CMediaType *pmt);
    HRESULT CreateConvertorObject();
    HRESULT DeleteConvertorObject();
    CBasePin *GetPin(int n);
};

#endif // __COLOUR__
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\multimedia\dshow\filters\image\colour\rgb24.cpp ===
// Copyright (c) Microsoft Corporation 1994-1996. All Rights Reserved
// This file implements RGB 24 colour space conversions, May 1995

#include <streams.h>
#include <colour.h>

// We do RGB24 to RGB8,RGB555,RGB565 and RGB32 colour space conversions here
// The only really interesting conversion here is RGB24 to RGB8 which uses
// the global dithering table created and initialised when we instantiate
// the filter. The RGB24 to RGB8 transform has an alignment optimised version
// that can be used when the source and destination rectangles and also their
// respective widths are aligned on DWORD boundaries. None of the others have
// any alignment optimisation. The RGB24 to 16 and 32 bit formats are fairly
// straightforward but are very expensive simply because of the amount of
// data being passed across the bus. It is therefore relatively unlikely that
// these will be used for video but might be used for still image transforms


// Constructor

CRGB24ToRGB16Convertor::CRGB24ToRGB16Convertor(VIDEOINFO *pIn,
                                               VIDEOINFO *pOut) :
    CConvertor(pIn,pOut),
    m_pRGB16RedTable(NULL),
    m_pRGB16GreenTable(NULL),
    m_pRGB16BlueTable(NULL)
{
    ASSERT(pIn);
    ASSERT(pOut);
}


// Destructor

CRGB24ToRGB16Convertor::~CRGB24ToRGB16Convertor()
{
    ASSERT(m_pRGB16RedTable == NULL);
    ASSERT(m_pRGB16GreenTable == NULL);
    ASSERT(m_pRGB16BlueTable == NULL);
}


// We have three lookup tables that both the RGB555 and RGB565 transforms will
// share. They have their own specific commit functions that set the tables up
// appropriately but they share the overall committing and decommitting of the
// memory. They also share the same transform function as once the tables are
// initialised the actual conversion work just involves looking up values

HRESULT CRGB24ToRGB16Convertor::Commit()
{
    CConvertor::Commit();

    // Allocate the memory for the lookup tables

    m_pRGB16RedTable = new DWORD[256];
    m_pRGB16GreenTable = new DWORD[256];
    m_pRGB16BlueTable = new DWORD[256];

    // Check they were all allocated correctly

    if (m_pRGB16BlueTable == NULL || m_pRGB16RedTable == NULL || m_pRGB16GreenTable == NULL) {
        Decommit();
        return E_OUTOFMEMORY;
    }
    return NOERROR;
}


// This is called when we finish transforming RGB24 to RGB16 images, we must
// call the global decommit function and then delete the lookup tables which
// we use. Some or all of these may not be present if an error has occured

HRESULT CRGB24ToRGB16Convertor::Decommit()
{
    CConvertor::Decommit();

    // Delete the RED lookup table

    if (m_pRGB16RedTable) {
        delete[] m_pRGB16RedTable;
        m_pRGB16RedTable = NULL;
    }

    // Delete the GREEN lookup table

    if (m_pRGB16GreenTable) {
        delete[] m_pRGB16GreenTable;
        m_pRGB16GreenTable = NULL;
    }

    // Delete the BLUE lookup table

    if (m_pRGB16BlueTable) {
        delete[] m_pRGB16BlueTable;
        m_pRGB16BlueTable = NULL;
    }
    return NOERROR;
}


// Transform the input RGB24 image to an output RGB16 16 bit image. This is
// a tight loop taking each three byte triplet and converting the individual
// colour components to their 16 bit representation and then combining them
// We use the same function to convert to both RGB555 and RGB565, we can do
// this because we have separate commit methods that build different tables

HRESULT CRGB24ToRGB16Convertor::Transform(BYTE *pInput,BYTE *pOutput)
{
    // Adjust the height to allow for an immediate decrement

    LONG Height = HEIGHT(&m_pOutputInfo->rcTarget) + 1;
    pInput += m_SrcOffset;
    pOutput += m_DstOffset;

    while (--Height) {

        LONG Width = WIDTH(&m_pOutputInfo->rcTarget) + 1;
        WORD *pRGB16 = (WORD *) pOutput;
        BYTE *pRGB24 = pInput;

        while (--Width) {

            *pRGB16++ = (WORD) (m_pRGB16BlueTable[pRGB24[0]] |
                                m_pRGB16GreenTable[pRGB24[1]] |
                                m_pRGB16RedTable[pRGB24[2]]);
            pRGB24 += 3;

        }
        pInput += m_SrcStride;
        pOutput += m_DstStride;
    }
    return NOERROR;
}


// RGB24 to RGB565 constructor

CRGB24ToRGB565Convertor::CRGB24ToRGB565Convertor(VIDEOINFO *pIn,
                                                 VIDEOINFO *pOut) :
    CRGB24ToRGB16Convertor(pIn,pOut)
{
    ASSERT(pIn);
    ASSERT(pOut);
}


// This goes in the table of available lookups to create a transform object
// derived from the base CConvertor class that does the type specific work.
// We initialise the constructor with the fields that it will need to do the
// conversion work and return a pointer to the object or NULL if it failed

CConvertor *CRGB24ToRGB565Convertor::CreateInstance(VIDEOINFO *pIn,
                                                    VIDEOINFO *pOut)
{
    return new CRGB24ToRGB565Convertor(pIn,pOut);
}


// This allocates the memory for transforming RGB24 to RGB16 images. We have
// three lookup tables (one for each colour component). When we parse out the
// individual colours in a pixel value we look up in the table using them as
// an index to find out what their representation is in the output format

HRESULT CRGB24ToRGB565Convertor::Commit()
{
    // Initialise the lookup tables

    HRESULT hr = CRGB24ToRGB16Convertor::Commit();
    if (FAILED(hr)) {
        return hr;
    }

    // For each possible byte value we insert a lookup table entry for it so
    // that when we come to convert a colour component value we know exactly
    // what it should be changed to and where in the output WORD it goes

    for (DWORD Position = 0;Position < 256;Position++) {

        DWORD FiveBitAdjust = Position;
        DWORD SixBitAdjust = Position;

        // Adjust the values according to the number of bits that will be left
        // after we start dropping some of their trailing bits. This is either
        // five or six bits, the adjustment stops the output image darkening

        ADJUST(FiveBitAdjust,4);
        ADJUST(SixBitAdjust,2);

        m_pRGB16RedTable[Position] = (FiveBitAdjust >> 3) << 11;
        m_pRGB16GreenTable[Position] = (SixBitAdjust >> 2) << 5;
        m_pRGB16BlueTable[Position] = FiveBitAdjust >> 3;
    }
    return NOERROR;
}


// RGB24 to RGB555 constructor

CRGB24ToRGB555Convertor::CRGB24ToRGB555Convertor(VIDEOINFO *pIn,
                                                 VIDEOINFO *pOut) :
    CRGB24ToRGB16Convertor(pIn,pOut)
{
    ASSERT(pIn);
    ASSERT(pOut);
}


// This goes in the table of available lookups to create a transform object
// derived from the base CConvertor class that does the type specific work.
// We initialise the constructor with the fields that it will need to do the
// conversion work and return a pointer to the object or NULL if it failed

CConvertor *CRGB24ToRGB555Convertor::CreateInstance(VIDEOINFO *pIn,
                                                    VIDEOINFO *pOut)
{
    return new CRGB24ToRGB555Convertor(pIn,pOut);
}


// This allocates the memory for transforming RGB24 to RGB555 images. We have
// three lookup tables (one for each colour component). When we parse out the
// individual colours in a pixel value we look up in the table using them as
// an index to find out what their representation is in the output format

HRESULT CRGB24ToRGB555Convertor::Commit()
{
    // Initialise the lookup tables

    HRESULT hr = CRGB24ToRGB16Convertor::Commit();
    if (FAILED(hr)) {
        return hr;
    }

    // For each possible byte value we insert a lookup table entry for it so
    // that when we come to convert a colour component value we know exactly
    // what it should be changed to and where in the output WORD it goes

    for (DWORD Position = 0;Position < 256;Position++) {

        // This is going to be an eight bit value transformed into a five
        // bit value so we see if the 0x100 bit is set and if so we round
        // the value up, this stops the output transformed image darkening

        DWORD FiveBitAdjust = Position;
        ADJUST(FiveBitAdjust,4);

        m_pRGB16RedTable[Position] = (FiveBitAdjust >> 3) << 10;
        m_pRGB16GreenTable[Position] = (FiveBitAdjust >> 3) << 5;
        m_pRGB16BlueTable[Position] = FiveBitAdjust >> 3;
    }
    return NOERROR;
}


CConvertor *CRGB24ToRGB32Convertor::CreateInstance(VIDEOINFO *pIn,
                                                   VIDEOINFO *pOut)
{
    return new CRGB24ToRGB32Convertor(pIn,pOut);
}


// Constructor

CRGB24ToRGB32Convertor::CRGB24ToRGB32Convertor(VIDEOINFO *pIn,
                                               VIDEOINFO *pOut) :
    CConvertor(pIn,pOut)
{
    ASSERT(pIn);
    ASSERT(pOut);
}


// Transform the input RGB24 image to an output RGB32 image

HRESULT CRGB24ToRGB32Convertor::Transform(BYTE *pInput,BYTE *pOutput)
{
    // Adjust the height to allow for an immediate decrement

    LONG Height = HEIGHT(&m_pOutputInfo->rcTarget) + 1;
    pInput += m_SrcOffset;
    pOutput += m_DstOffset;

    if( m_bSetAlpha )
    {
        while (--Height) {

            LONG Width = WIDTH(&m_pOutputInfo->rcTarget) + 1;
            DWORD *pRGB32 = (DWORD *) pOutput;
            BYTE *pRGB24 = pInput;

            while (--Width) {
                *pRGB32++ = 0xFF000000 | pRGB24[0] | (pRGB24[1] << 8) | (pRGB24[2] << 16); // alpha
                pRGB24 += 3;
            }
            pInput += m_SrcStride;
            pOutput += m_DstStride;
        }
    }
    else
    {
        while (--Height) {

            LONG Width = WIDTH(&m_pOutputInfo->rcTarget) + 1;
            DWORD *pRGB32 = (DWORD *) pOutput;
            BYTE *pRGB24 = pInput;

            while (--Width) {
                *pRGB32++ = pRGB24[0] | (pRGB24[1] << 8) | (pRGB24[2] << 16);
                pRGB24 += 3;
            }
            pInput += m_SrcStride;
            pOutput += m_DstStride;
        }
    }
    return NOERROR;
}


// Constructor for RGB24 to RGB8 colour conversions

CRGB24ToRGB8Convertor::CRGB24ToRGB8Convertor(VIDEOINFO *pIn,
                                             VIDEOINFO *pOut) :
    CConvertor(pIn,pOut)
{
    ASSERT(pIn);
    ASSERT(pOut);
}


// This goes in the table of available lookups to create a transform object
// derived from the base CConvertor class that does the type specific work.
// We initialise the constructor with the fields that it will need to do the
// conversion work and return a pointer to the object or NULL if it failed

CConvertor *CRGB24ToRGB8Convertor::CreateInstance(VIDEOINFO *pIn,
                                                  VIDEOINFO *pOut)
{
    return new CRGB24ToRGB8Convertor(pIn,pOut);
}


// This converts an input RGB24 pixel image into a dithered RGB8 palettised
// image, we scan through the image converting each pixel in turn using the
// ordered dithering algorithm that selects output pixels dependant on their
// coordinate position in the source image. This makes a rough approximation
// to full error propogation but without the heavy computational overhead

#define DITH24(x,y,r,g,b)                    \
    (g_DitherMap[0][((x)&3)][((y)&3)][r] +   \
     g_DitherMap[1][((x)&3)][((y)&3)][g] +   \
     g_DitherMap[2][((x)&3)][((y)&3)][b])

HRESULT CRGB24ToRGB8Convertor::Transform(BYTE *pInput,BYTE *pOutput)
{
    // Can we do an alignment optimised transform

    if (m_bAligned == TRUE) {
        return TransformAligned(pInput,pOutput);
    }

    // Adjust the height to allow for an immediate decrement

    LONG Height = HEIGHT(&m_pOutputInfo->rcTarget) + 1;
    pInput += m_SrcOffset;
    pOutput += m_DstOffset;

    while (--Height) {

        LONG Width = WIDTH(&m_pOutputInfo->rcTarget) + 1;
        BYTE *pRGB24 = pInput;
        BYTE *pRGB8 = pOutput;

        while (--Width) {
            *pRGB8++ = DITH24(Width,Height,pRGB24[2],pRGB24[1],pRGB24[0]);
            pRGB24 += 3;
        }
        pOutput += m_DstStride;
        pInput += m_SrcStride;
    }
    return NOERROR;
}


// This does the same colour space conversion as the RGB24 to RGB8 convertor
// except that it goes a little faster. The way it does this is by reading
// and writing DWORDs into memory. For example we write four of the dithered
// palettised pixels at once. The relies on the source and target pointers
// being aligned correctly otherwise we will start geting exceptions on RISC
// NOTE RGB24 pixels are stored in the buffer on BLUE, GREEN, RED byte order
// So if you have a pointer to a RGB24 triplet and you cast it to a pointer
// to a DWORD then the blue colour component is the least significant byte

HRESULT CRGB24ToRGB8Convertor::TransformAligned(BYTE *pInput,BYTE *pOutput)
{
    // Adjust the height to allow for an immediate decrement

    LONG Height = HEIGHT(&m_pOutputInfo->rcTarget) + 1;
    pInput += m_SrcOffset;
    pOutput += m_DstOffset;

    while (--Height) {

        LONG Width = (WIDTH(&m_pOutputInfo->rcTarget) >> 2) + 1;
        DWORD *pRGB24 = (DWORD *) pInput;
        DWORD *pRGB8 = (DWORD *) pOutput;

        while (--Width) {

            // Three DWORDs gets us four RGB24 pixels

            DWORD RGB24a = *pRGB24++;
            DWORD RGB24b = *pRGB24++;
            DWORD RGB24c = *pRGB24++;

            // Construct four palettised pixels from the three DWORD inputs
            // After reading the three DWORDs the colour components can be
            // found layed out within the DWORDs as follows. To extract the
            // colour components typically requires a shift and an AND with
            // 0xFF since the DITH24 macro takes values not exceeding 0xFF

            //   DWORD        LSB         LSB+1       LSB+2         MSB
            //     0       Blue[0]      Green[0]      Red[0]     Blue[1]
            //     1      Green[1]        Red[1]     Blue[2]    Green[2]
            //     2        Red[2]       Blue[3]    Green[3]      Red[3]

            *pRGB8++ = (DITH24(0,Height,((BYTE)(RGB24a >> 16)),
                                        ((BYTE)(RGB24a >> 8)),
                                        (RGB24a & 0xFF))) |

                       (DITH24(1,Height,((BYTE)(RGB24b >> 8)),
                                        ((BYTE) RGB24b),
                                        (RGB24a >> 24)) << 8) |

                       (DITH24(2,Height,((BYTE) RGB24c),
                                        (RGB24b >> 24),
                                        ((BYTE)(RGB24b >> 16))) << 16) |

                       (DITH24(3,Height,(RGB24c >> 24),
                                        ((BYTE)(RGB24c >> 16)),
                                        ((BYTE)(RGB24c >> 8))) << 24);
        }
        pOutput += m_DstStride;
        pInput += m_SrcStride;
    }
    return NOERROR;
}
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\multimedia\dshow\filters\image\colour\rgb24.h ===
// Copyright (c) Microsoft Corporation 1994-1996. All Rights Reserved
// This file implements RGB24 colour space conversions, May 1995

#ifndef __RGB24__
#define __RGB24__


// We have three lookup tables that both the RGB555 and RGB565 transforms will
// share. They have their own specific commit functions that set the tables up
// appropriately but they share the overall committing and decommitting of the
// memory. They also share the same transform function as once the tables are
// initialise the actual conversion work just involves looking up values

class CRGB24ToRGB16Convertor : public CConvertor {
protected:

    DWORD *m_pRGB16RedTable;
    DWORD *m_pRGB16GreenTable;
    DWORD *m_pRGB16BlueTable;

public:

    // Constructor and destructor

    CRGB24ToRGB16Convertor(VIDEOINFO *pIn,VIDEOINFO *pOut);
    ~CRGB24ToRGB16Convertor();

    HRESULT Commit();
    HRESULT Decommit();
    HRESULT Transform(BYTE *pInput,BYTE *pOutput);
};


// This class looks after doing RGB24 to RGB16 (565 colour bit representation)
// conversions. We use the base class Commit, Decommit and Transform functions
// to manage the lookup tables. We override the virtual Commit function to
// initialise the lookup tables appropriately once they have been allocated

class CRGB24ToRGB565Convertor : public CRGB24ToRGB16Convertor {
public:

    CRGB24ToRGB565Convertor(VIDEOINFO *pIn,VIDEOINFO *pOut);
    HRESULT Commit();
    static CConvertor *CreateInstance(VIDEOINFO *pIn,VIDEOINFO *pOut);
};


// This class looks after doing RGB24 to RGB16 (555 colour bit representation)
// conversions. We use the base class Commit, Decommit and Transform functions
// to manage the lookup tables. We override the virtual Commit function to
// initialise the lookup tables appropriately once they have been allocated

class CRGB24ToRGB555Convertor : public CRGB24ToRGB16Convertor {
public:

    CRGB24ToRGB555Convertor(VIDEOINFO *pIn,VIDEOINFO *pOut);
    HRESULT Commit();
    static CConvertor *CreateInstance(VIDEOINFO *pIn,VIDEOINFO *pOut);
};


// RGB24 to RGB32 colour space conversions

class CRGB24ToRGB32Convertor : public CConvertor {
public:
    CRGB24ToRGB32Convertor(VIDEOINFO *pIn,VIDEOINFO *pOut);
    HRESULT Transform(BYTE *pInput,BYTE *pOutput);
    static CConvertor *CreateInstance(VIDEOINFO *pIn,VIDEOINFO *pOut);
};


// The RGB24 to RGB8 conversion class uses a 12kb lookup table that is used
// to map an incoming RGB triplet to it's closest matching palette index with
// an approximation to full error diffusion built in. The four indices to the
// table are colour index (red, green or blue), the current row modulo four
// and likewise the column value modulo four and the RGB value respectively

class CRGB24ToRGB8Convertor : public CConvertor {

public:
    CRGB24ToRGB8Convertor(VIDEOINFO *pIn,VIDEOINFO *pOut);
    static CConvertor *CreateInstance(VIDEOINFO *pIn,VIDEOINFO *pOut);
    HRESULT Transform(BYTE *pInput,BYTE *pOutput);
    HRESULT TransformAligned(BYTE *pInput,BYTE *pOutput);
};

#endif // __RGB24__
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\multimedia\dshow\filters\image\colour\rgb32.h ===
// Copyright (c) Microsoft Corporation 1994-1996. All Rights Reserved
// This file implements RGB32 colour space conversions, May 1995

#ifndef __RGB32__
#define __RGB32__


// The RGB32 to RGB8 conversion class uses a 12kb lookup table that is used
// to map an incoming RGB triplet to it's closest matching palette index with
// an approximation to full error diffusion built in. The four indices to the
// table are colour index (red, green or blue), the current row modulo four
// and likewise the column value modulo four and the RGB value respectively

class CRGB32ToRGB8Convertor : public CConvertor {

public:
    CRGB32ToRGB8Convertor(VIDEOINFO *pIn,VIDEOINFO *pOut);
    static CConvertor *CreateInstance(VIDEOINFO *pIn,VIDEOINFO *pOut);
    HRESULT Transform(BYTE *pInput,BYTE *pOutput);
    HRESULT TransformAligned(BYTE *pInput,BYTE *pOutput);
};


// RGB32 to RGB24 colour space conversions

class CRGB32ToRGB24Convertor : public CConvertor {
public:
    CRGB32ToRGB24Convertor(VIDEOINFO *pIn,VIDEOINFO *pOut);
    HRESULT Transform(BYTE *pInput,BYTE *pOutput);
    static CConvertor *CreateInstance(VIDEOINFO *pIn,VIDEOINFO *pOut);
};


// RGB32 to RGB565 colour space conversions

class CRGB32ToRGB565Convertor : public CConvertor {
public:
    CRGB32ToRGB565Convertor(VIDEOINFO *pIn,VIDEOINFO *pOut);
    HRESULT Transform(BYTE *pInput,BYTE *pOutput);
    static CConvertor *CreateInstance(VIDEOINFO *pIn,VIDEOINFO *pOut);
};


// RGB32 to RGB555 colour space conversions

class CRGB32ToRGB555Convertor : public CConvertor {
public:
    CRGB32ToRGB555Convertor(VIDEOINFO *pIn,VIDEOINFO *pOut);
    HRESULT Transform(BYTE *pInput,BYTE *pOutput);
    static CConvertor *CreateInstance(VIDEOINFO *pIn,VIDEOINFO *pOut);
};

#endif // __RGB32__


=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\multimedia\dshow\filters\image\dither\makefile.inc ===
# NOTE:
# this directory contains a makefile which contains a single line that
# includes the global build process makefile.def. If the
# NTTARGETFILE1 or NTTARGETFILE0 environment
# variable is set then makefile.def includes makefile.inc from the current
# directory. This makefile.inc creates an extra target for nmake to create
# when it is run. NTTARGETFILE0 is built before everything else, and
# NTTARGETFILE1 is built after everything else.

copyfiles:
  @if exist obj\$(TARGET_DIRECTORY)\$(TARGETNAME).dll  \
    copy obj\$(TARGET_DIRECTORY)\$(TARGETNAME).dll     \
         $(SDK_ROOT)\bin\*.*
  @if not exist $(QUARTZ)\lib\$(TARGET_DIRECTORY) \
    md $(QUARTZ)\lib\$(TARGET_DIRECTORY)
  @if exist obj\$(TARGET_DIRECTORY)\$(TARGETNAME).lib  \
    copy obj\$(TARGET_DIRECTORY)\$(TARGETNAME).lib     \
         $(QUARTZ)\lib\$(TARGET_DIRECTORY)\*.*


=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\multimedia\dshow\filters\image\colour\stdpal.h ===
// Copyright (c) Microsoft Corporation 1994-1996. All Rights Reserved
// This file contains the standard video dithering palette, May 1995

#ifndef __STDPAL__
#define __STDPAL__

// The first thing to note is that this header file is only included by the
// main colour conversion source file, the variables we define in here are
// defined as extern in the main header file. This avoids getting any linker
// warnings as we would be defining the static variables multiple times. We
// have a default palette and a number of lookup tables defined in here which
// are put in a shared memory block to reduce the overall memory footprint

#pragma data_seg(".sdata")

// This is the palette we use when converting true colour formats to palette
// formats. We cannot dither to an arbitrary palette provided through the
// application as it takes too long to build conversion tables and to do the
// mapping. This fixed palette has the standard ten leading VGA entries in
// order to make it an identity palette. Then follows in BLUE GREEN RED order
// the definitions for 216 palette entries. Basicly we split the range for a
// colour component from 0 to 255 into a level of 0 to 5. An obvious way to
// do this would be to divide by 51. We then have three colour components in
// the range 0 to 5. So each value in that range represents 51 values in the
// original, we then fill out a palette with all the permutations of the value
// 51 and it's multiples, to which you will see there are 216 possibilities.
//
// Now the ordering of the palette entries becomes important. The blue values
// (on the left) are always increasing, so we have all the zero values first
// followed by all the 51s and so on. Then within any blue range we do the
// same for the green, so they are always increasing in the same way. And
// finally for the red values on the far right we also do this. This allows
// us to calculate with a very simple equation the palette index that maps
// from a RGB level (remember each is 0 to 5 now) to the ordinal position.
//
// Given three colour element values R, G and B in the range 0 to 5.
// The start of the blue section is at B * 36.
// The start of the green section is at G * 6.
// The position of the red entry is at R.
//
// And putting them all together gives us  Index = (B * 36) + (G * 6) + R
//
// As it turns out this computation can be done even more directly by having
// a lookup table that maps from an 8 bit RGB value directly into the palette
// index, the table is normally built when we go into a streaming state (it
// doesn't take all that long). NOTE We don't ever map to the VGA colours

const RGBQUAD StandardPalette[STDPALCOLOURS] =
{
    // These are the first ten standard VGA colours WARNING RGBQUAD defines
    // the fields in BGR ordering NOT RGB ! The odd looking entries further
    // down are entered to ensure that we get an identity palette with GDI
    // If we entered an all zero palette entry for example it would be taken
    // out and GDI would use a slow internal mapping table to generate it

    {   0,   0,   0 },     // 0 Sys Black
    {   0,   0, 128 },     // 1 Sys Dk Red
    {   0, 128,   0 },     // 2 Sys Dk Green
    {   0, 128, 128 },     // 3 Sys Dk Yellow
    { 128,   0,   0 },     // 4 Sys Dk Blue
    { 128,   0, 128 },     // 5 Sys Dk Violet
    { 128, 128,   0 },     // 6 Sys Dk Cyan
    { 192, 192, 192 },     // 7 Sys Lt Grey
    { 192, 220, 192 },     // 8 Sys 8
    { 240, 202, 166 },     // 9 Sys 9

    {   1,   1,   1 },
    {   1,   1,  51 },
    {   1,   1, 102 },
    {   1,   1, 153 },
    {   1,   1, 204 },
    {   1,   1, 254 },
    {   1,  51,   1 },
    {   1,  51,  51 },
    {   1,  51, 102 },
    {   1,  51, 153 },
    {   1,  51, 204 },
    {   1,  51, 254 },
    {   1, 102,   1 },
    {   1, 102,  51 },
    {   1, 102, 102 },
    {   1, 102, 153 },
    {   1, 102, 204 },
    {   1, 102, 254 },
    {   1, 153,   1 },
    {   1, 153,  51 },
    {   1, 153, 102 },
    {   1, 153, 153 },
    {   1, 153, 204 },
    {   1, 153, 254 },
    {   1, 204,   1 },
    {   1, 204,  51 },
    {   1, 204, 102 },
    {   1, 204, 153 },
    {   1, 204, 204 },
    {   1, 204, 254 },
    {   1, 254,   1 },
    {   1, 254,  51 },
    {   1, 254, 102 },
    {   1, 254, 153 },
    {   1, 254, 204 },
    {   1, 254, 254 },

    {  51,   1,   1 },
    {  51,   1,  51 },
    {  51,   1, 102 },
    {  51,   1, 153 },
    {  51,   1, 204 },
    {  51,   1, 254 },
    {  51,  51,   1 },
    {  51,  51,  51 },
    {  51,  51, 102 },
    {  51,  51, 153 },
    {  51,  51, 204 },
    {  51,  51, 254 },
    {  51, 102,   1 },
    {  51, 102,  51 },
    {  51, 102, 102 },
    {  51, 102, 153 },
    {  51, 102, 204 },
    {  51, 102, 254 },
    {  51, 153,   1 },
    {  51, 153,  51 },
    {  51, 153, 102 },
    {  51, 153, 153 },
    {  51, 153, 204 },
    {  51, 153, 254 },
    {  51, 204,   1 },
    {  51, 204,  51 },
    {  51, 204, 102 },
    {  51, 204, 153 },
    {  51, 204, 204 },
    {  51, 204, 254 },
    {  51, 254,   1 },
    {  51, 254,  51 },
    {  51, 254, 102 },
    {  51, 254, 153 },
    {  51, 254, 204 },
    {  51, 254, 254 },

    { 102,   1,   1 },
    { 102,   1,  51 },
    { 102,   1, 102 },
    { 102,   1, 153 },
    { 102,   1, 204 },
    { 102,   1, 254 },
    { 102,  51,   1 },
    { 102,  51,  51 },
    { 102,  51, 102 },
    { 102,  51, 153 },
    { 102,  51, 204 },
    { 102,  51, 254 },
    { 102, 102,   1 },
    { 102, 102,  51 },
    { 102, 102, 102 },
    { 102, 102, 153 },
    { 102, 102, 204 },
    { 102, 102, 254 },
    { 102, 153,   1 },
    { 102, 153,  51 },
    { 102, 153, 102 },
    { 102, 153, 153 },
    { 102, 153, 204 },
    { 102, 153, 254 },
    { 102, 204,   1 },
    { 102, 204,  51 },
    { 102, 204, 102 },
    { 102, 204, 153 },
    { 102, 204, 204 },
    { 102, 204, 254 },
    { 102, 254,   1 },
    { 102, 254,  51 },
    { 102, 254, 102 },
    { 102, 254, 153 },
    { 102, 254, 204 },
    { 102, 254, 254 },

    { 153,   1,   1 },
    { 153,   1,  51 },
    { 153,   1, 102 },
    { 153,   1, 153 },
    { 153,   1, 204 },
    { 153,   1, 254 },
    { 153,  51,   1 },
    { 153,  51,  51 },
    { 153,  51, 102 },
    { 153,  51, 153 },
    { 153,  51, 204 },
    { 153,  51, 254 },
    { 153, 102,   1 },
    { 153, 102,  51 },
    { 153, 102, 102 },
    { 153, 102, 153 },
    { 153, 102, 204 },
    { 153, 102, 254 },
    { 153, 153,   1 },
    { 153, 153,  51 },
    { 153, 153, 102 },
    { 153, 153, 153 },
    { 153, 153, 204 },
    { 153, 153, 254 },
    { 153, 204,   1 },
    { 153, 204,  51 },
    { 153, 204, 102 },
    { 153, 204, 153 },
    { 153, 204, 204 },
    { 153, 204, 254 },
    { 153, 254,   1 },
    { 153, 254,  51 },
    { 153, 254, 102 },
    { 153, 254, 153 },
    { 153, 254, 204 },
    { 153, 254, 254 },

    { 204,   1,   1 },
    { 204,   1,  51 },
    { 204,   1, 102 },
    { 204,   1, 153 },
    { 204,   1, 204 },
    { 204,   1, 254 },
    { 204,  51,   1 },
    { 204,  51,  51 },
    { 204,  51, 102 },
    { 204,  51, 153 },
    { 204,  51, 204 },
    { 204,  51, 254 },
    { 204, 102,   1 },
    { 204, 102,  51 },
    { 204, 102, 102 },
    { 204, 102, 153 },
    { 204, 102, 204 },
    { 204, 102, 254 },
    { 204, 153,   1 },
    { 204, 153,  51 },
    { 204, 153, 102 },
    { 204, 153, 153 },
    { 204, 153, 204 },
    { 204, 153, 254 },
    { 204, 204,   1 },
    { 204, 204,  51 },
    { 204, 204, 102 },
    { 204, 204, 153 },
    { 204, 204, 204 },
    { 204, 204, 254 },
    { 204, 254,   1 },
    { 204, 254,  51 },
    { 204, 254, 102 },
    { 204, 254, 153 },
    { 204, 254, 204 },
    { 204, 254, 254 },

    { 254,   1,   1 },
    { 254,   1,  51 },
    { 254,   1, 102 },
    { 254,   1, 153 },
    { 254,   1, 204 },
    { 254,   1, 254 },
    { 254,  51,   1 },
    { 254,  51,  51 },
    { 254,  51, 102 },
    { 254,  51, 153 },
    { 254,  51, 204 },
    { 254,  51, 254 },
    { 254, 102,   1 },
    { 254, 102,  51 },
    { 254, 102, 102 },
    { 254, 102, 153 },
    { 254, 102, 204 },
    { 254, 102, 254 },
    { 254, 153,   1 },
    { 254, 153,  51 },
    { 254, 153, 102 },
    { 254, 153, 153 },
    { 254, 153, 204 },
    { 254, 153, 254 },
    { 254, 204,   1 },
    { 254, 204,  51 },
    { 254, 204, 102 },
    { 254, 204, 153 },
    { 254, 204, 204 },
    { 254, 204, 254 },
    { 254, 254,   1 },
    { 254, 254,  51 },
    { 254, 254, 102 },
    { 254, 254, 153 },
    { 254, 254, 204 },
    { 254, 254, 254 },
};

#pragma data_seg()

#endif // __STDPAL__


=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\multimedia\dshow\filters\image\dither\dither.cpp ===
// Copyright (c) Microsoft Corporation 1994-1996. All Rights Reserved
// This implements VGA colour dithering, April 1996, Anthony Phillips

#include <streams.h>
#include <initguid.h>
#include <dither.h>
#include <limits.h>

// This is a VGA colour dithering filter. When ActiveMovie is installed it
// may be done on a system set with a 16 colour display mode. Without this
// we would not be able to show any video as none of the AVI/MPEG decoders
// can dither to 16 colours. As a quick hack we dither to 16 colours but
// we only use the black, white and grey thereby doing a halftoned dither

// This filter does not have a worker thread so it executes the colour space
// conversion on the calling thread. It is meant to be as lightweight as is
// possible so we do very little type checking on connection over and above
// ensuring we understand the types involved. The assumption is that when the
// type eventually gets through to an end point (probably the video renderer
// supplied) it will do a thorough type checking and reject bad streams.

// List of CLSIDs and creator functions for class factory

#ifdef FILTER_DLL
CFactoryTemplate g_Templates[1] = {
    { L""
    , &CLSID_Dither
    , CDither::CreateInstance
    , NULL
    , &sudDitherFilter }
};
int g_cTemplates = sizeof(g_Templates) / sizeof(g_Templates[0]);
#endif


// This goes in the factory template table to create new instances

CUnknown *CDither::CreateInstance(LPUNKNOWN pUnk,HRESULT *phr)
{
    return new CDither(NAME("VGA Ditherer"),pUnk);
}


// Setup data

const AMOVIESETUP_MEDIATYPE
sudDitherInputPinTypes =
{
    &MEDIATYPE_Video,           // Major
    &MEDIASUBTYPE_RGB8          // Subtype
};
const AMOVIESETUP_MEDIATYPE
sudDitherOutpinPinTypes =
{
    &MEDIATYPE_Video,           // Major
    &MEDIASUBTYPE_RGB4          // Subtype
};

const AMOVIESETUP_PIN
sudDitherPin[] =
{
    { L"Input",                 // Name of the pin
      FALSE,                    // Is pin rendered
      FALSE,                    // Is an Output pin
      FALSE,                    // Ok for no pins
      FALSE,                    // Can we have many
      &CLSID_NULL,              // Connects to filter
      NULL,                     // Name of pin connect
      1,                        // Number of pin types
      &sudDitherInputPinTypes}, // Details for pins

    { L"Output",                // Name of the pin
      FALSE,                    // Is pin rendered
      TRUE,                     // Is an Output pin
      FALSE,                    // Ok for no pins
      FALSE,                    // Can we have many
      &CLSID_NULL,              // Connects to filter
      NULL,                     // Name of pin connect
      1,                        // Number of pin types
      &sudDitherOutpinPinTypes} // Details for pins
};

const AMOVIESETUP_FILTER
sudDitherFilter =
{
    &CLSID_Dither,              // CLSID of filter
    L"VGA 16 Color Ditherer",   // Filter name
    MERIT_UNLIKELY,             // Filter merit
    2,                          // Number of pins
    sudDitherPin                // Pin information
};


#pragma warning(disable:4355)

// Constructor initialises base transform class
CDither::CDither(TCHAR *pName,LPUNKNOWN pUnk) :

    CTransformFilter(pName,pUnk,CLSID_Dither),
    m_fInit(FALSE)
{
}


// Do the actual transform into the VGA colours

HRESULT CDither::Transform(IMediaSample *pIn,IMediaSample *pOut)
{
    NOTE("Entering Transform");
    BYTE *pInput = NULL;
    BYTE *pOutput = NULL;
    HRESULT hr = NOERROR;
    AM_MEDIA_TYPE   *pmt;

    if (!m_fInit) {
        return E_FAIL;
    }

    // Retrieve the output image pointer

    hr = pOut->GetPointer(&pOutput);
    if (FAILED(hr)) {
        NOTE("No output");
        return hr;
    }

    // And the input image buffer as well

    hr = pIn->GetPointer(&pInput);
    if (FAILED(hr)) {
        NOTE("No input");
        return hr;
    }

    //
    // If the media type has changed then pmt is NOT NULL
    //

    pOut->GetMediaType(&pmt);
    if (pmt != NULL) {
        CMediaType cmt(*pmt);
        DeleteMediaType(pmt);
        SetOutputPinMediaType(&cmt);
    }

    pIn->GetMediaType(&pmt);
    if (pmt != NULL) {
        CMediaType cmt(*pmt);
        DeleteMediaType(pmt);
        hr = SetInputPinMediaType(&cmt);
        if (FAILED(hr)) {
            return hr;
        }
    }

    Dither8(pOutput, pInput);

    return NOERROR;
}


// This function is handed a media type object and it looks after making sure
// that it is superficially correct. This doesn't amount to a whole lot more
// than making sure the type is right and that the media format block exists
// So we delegate type checking to the downstream filter that really draws it

HRESULT CDither::CheckVideoType(const CMediaType *pmt)
{
    NOTE("Entering CheckVideoType");

    // Check the major type is digital video

    if (pmt->majortype != MEDIATYPE_Video) {
        NOTE("Major type not MEDIATYPE_Video");
        return VFW_E_TYPE_NOT_ACCEPTED;
    }

    // Check this is a VIDEOINFO type

    if (pmt->formattype != FORMAT_VideoInfo) {
        NOTE("Format not a VIDEOINFO");
        return VFW_E_TYPE_NOT_ACCEPTED;
    }

    // Quick sanity check on the input format

    if (pmt->cbFormat < SIZE_VIDEOHEADER) {
        NOTE("Format too small for a VIDEOINFO");
        return VFW_E_TYPE_NOT_ACCEPTED;
    }
    return NOERROR;
}


// Check we like the look of this input format

HRESULT CDither::CheckInputType(const CMediaType *pmtIn)
{
    NOTE("Entering CheckInputType");

    // Is the input type MEDIASUBTYPE_RGB8

    if (pmtIn->subtype != MEDIASUBTYPE_RGB8) {
        NOTE("Subtype not MEDIASUBTYPE_RGB8");
        return VFW_E_TYPE_NOT_ACCEPTED;
    }
    return CheckVideoType(pmtIn);
}


// Can we do this input to output transform. We will only be called here if
// the input pin is connected. We cannot stretch nor compress the image and
// the only allowed output format is MEDIASUBTYPE_RGB4. There is no point us
// doing pass through like the colour space convertor because DirectDraw is
// not available in any VGA display modes - it works with a minimum of 8bpp

HRESULT CDither::CheckTransform(const CMediaType *pmtIn,const CMediaType *pmtOut)
{
    VIDEOINFO *pTrgInfo = (VIDEOINFO *) pmtOut->Format();
    VIDEOINFO *pSrcInfo = (VIDEOINFO *) pmtIn->Format();
    NOTE("Entering CheckTransform");

    // Quick sanity check on the output format

    HRESULT hr = CheckVideoType(pmtOut);
    if (FAILED(hr)) {
        return hr;
    }

    // Check the output format is VGA colours

    if (*pmtOut->Subtype() != MEDIASUBTYPE_RGB4) {
        NOTE("Output not VGA");
        return E_INVALIDARG;
    }

    // See if we can use direct draw

    if (IsRectEmpty(&pTrgInfo->rcSource) == TRUE) {
        ASSERT(IsRectEmpty(&pTrgInfo->rcTarget) == TRUE);
        if (pSrcInfo->bmiHeader.biWidth == pTrgInfo->bmiHeader.biWidth) {
            if (pSrcInfo->bmiHeader.biHeight == pTrgInfo->bmiHeader.biHeight) {
                return S_OK;
            }
        }
        return VFW_E_TYPE_NOT_ACCEPTED;
    }


    // Create a source rectangle if it's empty

    RECT Source = pTrgInfo->rcSource;
    if (IsRectEmpty(&Source) == TRUE) {
        NOTE("Source rectangle filled in");
        Source.left = Source.top = 0;
        Source.right = pSrcInfo->bmiHeader.biWidth;
        Source.bottom = ABSOL(pSrcInfo->bmiHeader.biHeight);
    }

    // Create a destination rectangle if it's empty

    RECT Target = pTrgInfo->rcTarget;
    if (IsRectEmpty(&Target) == TRUE) {
        NOTE("Target rectangle filled in");
        Target.left = Target.top = 0;
        Target.right = pSrcInfo->bmiHeader.biWidth;
        Target.bottom = ABSOL(pSrcInfo->bmiHeader.biHeight);
    }

    // Check we are not stretching nor compressing the image

    if (WIDTH(&Source) == WIDTH(&Target)) {
        if (HEIGHT(&Source) == HEIGHT(&Target)) {
            NOTE("No stretch");
            return NOERROR;
        }
    }
    return VFW_E_TYPE_NOT_ACCEPTED;
}


// We offer only one output format which is MEDIASUBTYPE_RGB4. The VGA colours
// are fixed in time and space forever so we just copy the 16 colours onto the
// end of the output VIDEOINFO we construct. We set the image size field to be
// the actual image size rather than the default zero so that when we come to
// deciding and allocating buffering we can use this to specify the image size

HRESULT CDither::GetMediaType(int iPosition,CMediaType *pmtOut)
{
    NOTE("Entering GetMediaType");
    CMediaType InputType;
    ASSERT(pmtOut);

    // We only offer one format

    if (iPosition) {
        NOTE("Exceeds types supplied");
        return VFW_S_NO_MORE_ITEMS;
    }

    // Allocate and zero fill the output format

    pmtOut->ReallocFormatBuffer(sizeof(VIDEOINFO));
    VIDEOINFO *pVideoInfo = (VIDEOINFO *) pmtOut->Format();
    if (pVideoInfo == NULL) {
        NOTE("No type memory");
        return E_OUTOFMEMORY;
    }

    // Reset the output format and install the palette

    ZeroMemory((PVOID) pVideoInfo,sizeof(VIDEOINFO));
    m_pInput->ConnectionMediaType(&InputType);
    VIDEOINFO *pInput = (VIDEOINFO *) InputType.Format();
    BITMAPINFOHEADER *pHeader = HEADER(pVideoInfo);

    // Copy the system colours from the VGA palette

    for (LONG Index = 0;Index < 16;Index++) {
        pVideoInfo->bmiColors[Index].rgbRed = VGAColours[Index].rgbRed;
        pVideoInfo->bmiColors[Index].rgbGreen = VGAColours[Index].rgbGreen;
        pVideoInfo->bmiColors[Index].rgbBlue = VGAColours[Index].rgbBlue;
        pVideoInfo->bmiColors[Index].rgbReserved = 0;
    }

    // Copy these fields from the source format

    pVideoInfo->rcSource = pInput->rcSource;
    pVideoInfo->rcTarget = pInput->rcTarget;
    pVideoInfo->dwBitRate = pInput->dwBitRate;
    pVideoInfo->dwBitErrorRate = pInput->dwBitErrorRate;
    pVideoInfo->AvgTimePerFrame = pInput->AvgTimePerFrame;

    pHeader->biSize = sizeof(BITMAPINFOHEADER);
    pHeader->biWidth = pInput->bmiHeader.biWidth;
    pHeader->biHeight = pInput->bmiHeader.biHeight;
    pHeader->biPlanes = pInput->bmiHeader.biPlanes;
    pHeader->biBitCount = 4;
    pHeader->biCompression = BI_RGB;
    pHeader->biXPelsPerMeter = 0;
    pHeader->biYPelsPerMeter = 0;
    pHeader->biClrUsed = 16;
    pHeader->biClrImportant = 16;
    pHeader->biSizeImage = GetBitmapSize(pHeader);

    pmtOut->SetType(&MEDIATYPE_Video);
    pmtOut->SetSubtype(&MEDIASUBTYPE_RGB4);
    pmtOut->SetFormatType(&FORMAT_VideoInfo);
    pmtOut->SetSampleSize(pHeader->biSizeImage);
    pmtOut->SetTemporalCompression(FALSE);

    return NOERROR;
}


// Called to prepare the allocator's count of buffers and sizes, we don't care
// who provides the allocator so long as it will give us a media sample. The
// output format we produce is not temporally compressed so in principle we
// could use any number of output buffers but it doesn't appear to gain much
// performance and does add to the overall memory footprint of the system

HRESULT CDither::DecideBufferSize(IMemAllocator *pAllocator,
                                  ALLOCATOR_PROPERTIES *pProperties)
{
    NOTE("Entering DecideBufferSize");
    CMediaType OutputType;
    ASSERT(pAllocator);
    ASSERT(pProperties);
    HRESULT hr = NOERROR;

    m_pOutput->ConnectionMediaType(&OutputType);
    pProperties->cBuffers = 1;
    pProperties->cbBuffer = OutputType.GetSampleSize();
    ASSERT(pProperties->cbBuffer);

    // Ask the allocator to reserve us some sample memory, NOTE the function
    // can succeed (that is return NOERROR) but still not have allocated the
    // memory that we requested, so we must check we got whatever we wanted

    ALLOCATOR_PROPERTIES Actual;
    hr = pAllocator->SetProperties(pProperties,&Actual);
    if (FAILED(hr)) {
        NOTE("Properties failed");
        return hr;
    }

    // Did we get the buffering requirements

    if (Actual.cbBuffer >= (LONG) OutputType.GetSampleSize()) {
        if (Actual.cBuffers >= 1) {
            NOTE("Request ok");
            return NOERROR;
        }
    }
    return VFW_E_SIZENOTSET;
}


// Called when the media type is set for one of our pins

HRESULT CDither::SetMediaType(PIN_DIRECTION direction,const CMediaType *pmt)
{
    HRESULT hr = S_OK;

    if (direction == PINDIR_INPUT) {
        ASSERT(*pmt->Subtype() == MEDIASUBTYPE_RGB8);
        hr = SetInputPinMediaType(pmt);
    }
    else {
        ASSERT(*pmt->Subtype() == MEDIASUBTYPE_RGB4);
        SetOutputPinMediaType(pmt);
    }
    return hr;
}


HRESULT CDither::SetInputPinMediaType(const CMediaType *pmt)
{
    VIDEOINFO *pInput = (VIDEOINFO *)pmt->pbFormat;
    BITMAPINFOHEADER *pbiSrc = HEADER(pInput);

    m_fInit = DitherDeviceInit(pbiSrc);
    if (!m_fInit) {
        return E_OUTOFMEMORY;
    }

    ASSERT(pbiSrc->biBitCount == 8);
    m_wWidthSrc = (pbiSrc->biWidth + 3) & ~3;

    return S_OK;
}


void CDither::SetOutputPinMediaType(const CMediaType *pmt)
{
    VIDEOINFO *pOutput = (VIDEOINFO *)pmt->pbFormat;
    BITMAPINFOHEADER *pbiDst = HEADER(pOutput);

    ASSERT(pbiDst->biBitCount == 4);

    m_wWidthDst = ((pbiDst->biWidth * 4) + 7) / 8;
    m_wWidthDst = (m_wWidthDst + 3) & ~3;

    m_DstXE = pbiDst->biWidth;
    m_DstYE = pbiDst->biHeight;
}


// Dither to the colors of the display driver

BOOL CDither::DitherDeviceInit(LPBITMAPINFOHEADER lpbi)
{
    HBRUSH      hbr = (HBRUSH) NULL;
    HDC         hdcMem = (HDC) NULL;
    HDC         hdc = (HDC) NULL;
    HBITMAP     hbm = (HBITMAP) NULL;
    HBITMAP     hbmT = (HBITMAP) NULL;
    int         i;
    int         nColors;
    LPBYTE      lpDitherTable;
    LPRGBQUAD   prgb;
    BYTE        biSave[sizeof(BITMAPINFOHEADER) + 256 * sizeof(RGBQUAD)];
    LPBITMAPINFOHEADER lpbiOut = (LPBITMAPINFOHEADER)&biSave;

    NOTE("DitherDeviceInit called");

    //
    // we dont need to re-init the dither table, unless it is not ours then
    // we should free it.
    //
    lpDitherTable = (LPBYTE)GlobalAllocPtr(GHND, 256*8*4);
    if (lpDitherTable == NULL)
    {
        return FALSE;
    }

    hdc = GetDC(NULL);
    if ( ! hdc )
        goto ErrorExit;
    hdcMem = CreateCompatibleDC(hdc);
    if ( ! hdcMem )
        goto ErrorExit;
    hbm  = CreateCompatibleBitmap(hdc, 256*8, 8);
    if ( ! hbm )
        goto ErrorExit;

    hbmT = (HBITMAP)SelectObject(hdcMem, (HBITMAP)hbm);

    if ((nColors = (int)lpbi->biClrUsed) == 0)
        nColors = 1 << (int)lpbi->biBitCount;

    prgb = (LPRGBQUAD)(lpbi+1);

    for (i=0; i<nColors; i++)
    {
        hbr = CreateSolidBrush(RGB(prgb[i].rgbRed,
                                   prgb[i].rgbGreen,
                                   prgb[i].rgbBlue));
        if ( hbr )
        {
            hbr = (HBRUSH)SelectObject(hdcMem, hbr);
            PatBlt(hdcMem, i*8, 0, 8, 8, PATCOPY);
            hbr = (HBRUSH)SelectObject(hdcMem, hbr);
            DeleteObject(hbr);
        }
    }

    SelectObject(hdcMem, hbmT);
    DeleteDC(hdcMem);

    lpbiOut->biSize           = sizeof(BITMAPINFOHEADER);
    lpbiOut->biPlanes         = 1;
    lpbiOut->biBitCount       = 4;
    lpbiOut->biWidth          = 256*8;
    lpbiOut->biHeight         = 8;
    lpbiOut->biCompression    = BI_RGB;
    lpbiOut->biSizeImage      = 256*8*4;
    lpbiOut->biXPelsPerMeter  = 0;
    lpbiOut->biYPelsPerMeter  = 0;
    lpbiOut->biClrUsed        = 0;
    lpbiOut->biClrImportant   = 0;
    GetDIBits(hdc, hbm, 0, 8, lpDitherTable,
              (LPBITMAPINFO)lpbiOut, DIB_RGB_COLORS);

    DeleteObject(hbm);
    ReleaseDC(NULL, hdc);

    for (i = 0; i < 256*8*4; i++) {

        BYTE twoPels = lpDitherTable[i];

        m_DitherTable[(i * 2) + 0] = (BYTE)((twoPels & 0xF0) >> 4);
        m_DitherTable[(i * 2) + 1] = (BYTE)(twoPels & 0x0F);
    }

    GlobalFreePtr(lpDitherTable);
    return TRUE;
ErrorExit:
    if ( NULL != hdcMem && NULL != hbmT )
        SelectObject(hdcMem, hbmT);
    if ( NULL != hdcMem )
        DeleteDC(hdcMem);
    if ( hbm )
        DeleteObject(hbm);
    if ( hdc )
        ReleaseDC(NULL, hdc);
    if ( lpDitherTable )
        GlobalFreePtr(lpDitherTable);
    return FALSE;
}


#define DODITH8(px, _x_) (m_DitherTable)[yDith + (px) * 8 + (_x_)]

// Call this to actually do the dither.

void CDither::Dither8(LPBYTE lpDst,LPBYTE lpSrc)
{
    int     x,y;
    BYTE    *pbS;
    BYTE    *pbD;
    DWORD   dw;

    NOTE("Dither8");

    for (y=0; y < m_DstYE; y++) {

        int yDith = (y & 7) * 256 * 8;

        pbD = lpDst;
        pbS = lpSrc;

        // write one DWORD (one dither cell horizontally) at once

        for (x=0; x + 8 <= m_DstXE; x += 8) {

            dw  = DODITH8(*(pbS + 6), 6);
            dw <<= 4;

            dw |= DODITH8(*(pbS + 7), 7);
            dw <<= 4;

            dw |= DODITH8(*(pbS + 4), 4);
            dw <<= 4;

            dw |= DODITH8(*(pbS + 5), 5);
            dw <<= 4;

            dw |= DODITH8(*(pbS + 2), 2);
            dw <<= 4;

            dw |= DODITH8(*(pbS + 3), 3);
            dw <<= 4;

            dw |= DODITH8(*(pbS + 0), 0);
            dw <<= 4;

            dw |= DODITH8(*(pbS + 1), 1);
            *((DWORD UNALIGNED *) pbD) = dw;

            pbS += 8;
            pbD += 4;
        }

	// clean up remainder (less than 8 bytes per row)
        int EvenPelsLeft = ((m_DstXE - x) & ~1);
        int OddPelLeft   = ((m_DstXE - x) &  1);

        for (x = 0; x < EvenPelsLeft; x += 2) {
            *pbD++ = (DODITH8(*pbS++, x  ) << 4) |
                      DODITH8(*pbS++, x+1);
        }

        if (OddPelLeft) {
            *pbD++ = (DODITH8(*pbS++, x) << 4);
        }

        lpSrc += m_wWidthSrc;
        lpDst += m_wWidthDst;
    }
}
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\multimedia\dshow\filters\image\colour\rgb32.cpp ===
// Copyright (c) Microsoft Corporation 1994-1996. All Rights Reserved
// This file implements RGB 32 colour space conversions, November 1995

#include <streams.h>
#include <colour.h>

// We do RGB32 to RGB8,RGB555,RGB565 and RGB24 colour space conversions here
// The only really interesting conversion here is RGB32 to RGB8 which uses
// the global dithering table created and initialised when we instantiate
// the filter. The RGB32 to RGB8 transform has an alignment optimised version
// that can be used when the source and destination rectangles and also their
// respective widths are aligned on DWORD boundaries. None of the others have
// any alignment optimisation. The RGB32 to 16 and 24 bit formats are fairly
// straightforward but are very expensive simply because of the amount of
// data being passed across the bus. It is therefore relatively unlikely that
// these will be used for video but might be used for still image transforms


// Constructor for RGB32 to RGB8 colour conversions

CRGB32ToRGB8Convertor::CRGB32ToRGB8Convertor(VIDEOINFO *pIn,
                                             VIDEOINFO *pOut) :
    CConvertor(pIn,pOut)
{
    ASSERT(pIn);
    ASSERT(pOut);
}


// This goes in the table of available lookups to create a transform object
// derived from the base CConvertor class that does the type specific work.
// We initialise the constructor with the fields that it will need to do the
// conversion work and return a pointer to the object or NULL if it failed

CConvertor *CRGB32ToRGB8Convertor::CreateInstance(VIDEOINFO *pIn,
                                                   VIDEOINFO *pOut)
{
    return new CRGB32ToRGB8Convertor(pIn,pOut);
}


// This converts an input RGB32 pixel image into a dithered RGB8 palettised
// image, we scan through the image converting each pixel in turn using the
// ordered dithering algorithm that selects output pixels dependant on their
// coordinate position in the source image. This makes a rough approximation
// to full error propogation but without the heavy computational overhead

#define DITH32(x,y,rgb)                                      \
    (g_DitherMap[0][((x)&3)][((y)&3)][(BYTE)((rgb)>>16)] +   \
     g_DitherMap[1][((x)&3)][((y)&3)][(BYTE)((rgb)>>8)] +    \
     g_DitherMap[2][((x)&3)][((y)&3)][(BYTE)((rgb))])

HRESULT CRGB32ToRGB8Convertor::Transform(BYTE *pInput,BYTE *pOutput)
{
    // Can we do an alignment optimised transform

    if (m_bAligned == TRUE) {
        return TransformAligned(pInput,pOutput);
    }

    // Adjust the height to allow for an immediate decrement

    LONG Height = HEIGHT(&m_pOutputInfo->rcTarget) + 1;
    pInput += m_SrcOffset;
    pOutput += m_DstOffset;

    while (--Height) {

        LONG Width = WIDTH(&m_pOutputInfo->rcTarget) + 1;
        DWORD *pRGB32 = (DWORD *) pInput;
        BYTE *pRGB8 = pOutput;

        while (--Width) {
            DWORD RGB32 = *pRGB32++;
            *pRGB8++ = DITH32(Width,Height,RGB32);
        }
        pInput += m_SrcStride;
        pOutput += m_DstStride;
    }
    return NOERROR;
}


// This does the same colour space conversion as the RGB32 to RGB8 convertor
// except that it goes a little faster. The way it does this is by reading
// and writing DWORDs into memory. For example we write four of the dithered
// palettised pixels at once. The relies on the source and target pointers
// being aligned correctly otherwise we will start geting exceptions on RISC

HRESULT CRGB32ToRGB8Convertor::TransformAligned(BYTE *pInput,BYTE *pOutput)
{
    // Adjust the height to allow for an immediate decrement

    LONG Height = HEIGHT(&m_pOutputInfo->rcTarget) + 1;
    pInput += m_SrcOffset;
    pOutput += m_DstOffset;

    while (--Height) {

        LONG Width = (WIDTH(&m_pOutputInfo->rcTarget) >> 2) + 1;
        DWORD *pRGB32 = (DWORD *) pInput;
        DWORD *pRGB8 = (DWORD *) pOutput;

        while (--Width) {

            // Read in four RGB32 pixels at once

            DWORD RGB32a = *pRGB32++;
            DWORD RGB32b = *pRGB32++;
            DWORD RGB32c = *pRGB32++;
            DWORD RGB32d = *pRGB32++;

            // Colour convert all four and write in a single DWORD out

            *pRGB8++ = (DITH32(0,Height,RGB32a)) |
                       (DITH32(1,Height,RGB32b) << 8) |
                       (DITH32(2,Height,RGB32c) << 16) |
                       (DITH32(3,Height,RGB32d) << 24);
        }
        pInput += m_SrcStride;
        pOutput += m_DstStride;
    }
    return NOERROR;
}


// Creator function for RGB32 to RGB24 formats

CConvertor *CRGB32ToRGB24Convertor::CreateInstance(VIDEOINFO *pIn,
                                                   VIDEOINFO *pOut)
{
    return new CRGB32ToRGB24Convertor(pIn,pOut);
}


// Constructor

CRGB32ToRGB24Convertor::CRGB32ToRGB24Convertor(VIDEOINFO *pIn,
                                               VIDEOINFO *pOut) :
    CConvertor(pIn,pOut)
{
    ASSERT(pIn);
    ASSERT(pOut);
}


// Transform the input RGB24 image to an output RGB32 image

HRESULT CRGB32ToRGB24Convertor::Transform(BYTE *pInput,BYTE *pOutput)
{
    // Adjust the height to allow for an immediate decrement

    LONG Height = HEIGHT(&m_pOutputInfo->rcTarget) + 1;
    pInput += m_SrcOffset;
    pOutput += m_DstOffset;

    while (--Height) {

        LONG Width = WIDTH(&m_pOutputInfo->rcTarget) + 1;
        DWORD *pRGB32 = (DWORD *) pInput;
        BYTE *pRGB24 = pOutput;

        while (--Width) {
            DWORD RGB32 = *pRGB32++;
            pRGB24[0] = (BYTE) RGB32;
            pRGB24[1] = (BYTE) (RGB32 >> 8);
            pRGB24[2] = (BYTE) (RGB32 >> 16);
            pRGB24 += 3;
        }
        pInput += m_SrcStride;
        pOutput += m_DstStride;
    }
    return NOERROR;
}


// Creator function for RGB32 to RGB565 formats

CConvertor *CRGB32ToRGB565Convertor::CreateInstance(VIDEOINFO *pIn,
                                                    VIDEOINFO *pOut)
{
    return new CRGB32ToRGB565Convertor(pIn,pOut);
}


// Constructor

CRGB32ToRGB565Convertor::CRGB32ToRGB565Convertor(VIDEOINFO *pIn,
                                                 VIDEOINFO *pOut) :
    CConvertor(pIn,pOut)
{
    ASSERT(pIn);
    ASSERT(pOut);
}


// Transform the input RGB32 image to an output RGB565 image

HRESULT CRGB32ToRGB565Convertor::Transform(BYTE *pInput,BYTE *pOutput)
{
    // Adjust the height to allow for an immediate decrement

    LONG Height = HEIGHT(&m_pOutputInfo->rcTarget) + 1;
    pInput += m_SrcOffset;
    pOutput += m_DstOffset;

    while (--Height) {

        LONG Width = WIDTH(&m_pOutputInfo->rcTarget) + 1;
        DWORD *pRGB32 = (DWORD *) pInput;
        WORD *pRGB565 = (WORD *) pOutput;

        while (--Width) {
            *pRGB565++ = (WORD) ((((BYTE) *pRGB32) >> 3) |
                                (((*pRGB32 & 0xFF00) >> 10) << 5) |
                                (((*pRGB32 & 0xFF0000) >> 19) << 11));
            pRGB32++;
        }
        pInput += m_SrcStride;
        pOutput += m_DstStride;
    }
    return NOERROR;
}


// Creator function for RGB32 to RGB555 formats

CConvertor *CRGB32ToRGB555Convertor::CreateInstance(VIDEOINFO *pIn,
                                                    VIDEOINFO *pOut)
{
    return new CRGB32ToRGB555Convertor(pIn,pOut);
}


// Constructor

CRGB32ToRGB555Convertor::CRGB32ToRGB555Convertor(VIDEOINFO *pIn,
                                                 VIDEOINFO *pOut) :
    CConvertor(pIn,pOut)
{
    ASSERT(pIn);
    ASSERT(pOut);
}


// Transform the input RGB32 image to an output RGB555 image

HRESULT CRGB32ToRGB555Convertor::Transform(BYTE *pInput,BYTE *pOutput)
{
    // Adjust the height to allow for an immediate decrement

    LONG Height = HEIGHT(&m_pOutputInfo->rcTarget) + 1;
    pInput += m_SrcOffset;
    pOutput += m_DstOffset;

    while (--Height) {

        LONG Width = WIDTH(&m_pOutputInfo->rcTarget) + 1;
        DWORD *pRGB32 = (DWORD *) pInput;
        WORD *pRGB555 = (WORD *) pOutput;

        while (--Width) {
            *pRGB555++ = (WORD) ((((BYTE) *pRGB32) >> 3) |
                                (((*pRGB32 & 0xFF00) >> 11) << 5) |
                                (((*pRGB32 & 0xFF0000) >> 19) << 10));
            pRGB32++;
        }
        pInput += m_SrcStride;
        pOutput += m_DstStride;
    }
    return NOERROR;
}


=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\multimedia\dshow\filters\image\colour\rgb8.h ===
// Copyright (c) Microsoft Corporation 1994-1996. All Rights Reserved
// This filter implements RGB 8 colour space conversions, May 1995

#ifndef __RGB8__
#define __RGB8__

// Round up values before chopping bits off them, this is done when we convert
// RGB colour component values into RGB 16 bit representation where they have
// fewer bits per pixel (such as RGB555). The rounding allows for the reduced
// accuracy otherwise the bit chopping gives the output image less contrast

#define ADJUST(Colour,Adjust)                      \
    if (Colour & Adjust) {                         \
        Colour = min(255,(Colour + Adjust));       \
    }


// We use a special lookup table that both the RGB555 and RGB565 transforms
// share. They have their own specific commit functions that set the tables up
// appropriately but they share the overall committing and decommitting of the
// memory. They also share the same transform function as once the tables are
// initialise the actual conversion work just involves looking up values

class CRGB8ToRGB16Convertor : public CConvertor {
protected:

    DWORD *m_pRGB16Table;

public:

    // Constructor and destructor

    CRGB8ToRGB16Convertor(VIDEOINFO *pIn,VIDEOINFO *pOut);
    ~CRGB8ToRGB16Convertor();

    HRESULT Commit();
    HRESULT Decommit();
    HRESULT Transform(BYTE *pInput,BYTE *pOutput);
    HRESULT TransformAligned(BYTE *pInput,BYTE *pOutput);
};


// This class looks after doing RGB8 to RGB16 (565 colour bit representation)
// conversions. We use the base class Commit, Decommit and Transform functions
// to manage the lookup tables. We override the virtual Commit function to
// initialise the lookup tables appropriately once they have been allocated

class CRGB8ToRGB565Convertor : public CRGB8ToRGB16Convertor {
public:

    CRGB8ToRGB565Convertor(VIDEOINFO *pIn,VIDEOINFO *pOut);
    static CConvertor *CreateInstance(VIDEOINFO *pIn,VIDEOINFO *pOut);
    HRESULT Commit();
};


// This class looks after doing RGB8 to RGB16 (555 colour bit representation)
// conversions. We use the base class Commit, Decommit and Transform functions
// to manage the lookup tables. We override the virtual Commit function to
// initialise the lookup tables appropriately once they have been allocated

class CRGB8ToRGB555Convertor : public CRGB8ToRGB16Convertor {
public:

    CRGB8ToRGB555Convertor(VIDEOINFO *pIn,VIDEOINFO *pOut);
    static CConvertor *CreateInstance(VIDEOINFO *pIn,VIDEOINFO *pOut);
    HRESULT Commit();
};


// This class looks after doing RGB8 to RGB24 colour conversions. We use the
// base class Commit and Decommit since we have no lookup tables (all that is
// really involved is memory copying) but we override the Transform method

class CRGB8ToRGB24Convertor : public CConvertor {
public:

    CRGB8ToRGB24Convertor(VIDEOINFO *pIn,VIDEOINFO *pOut);
    static CConvertor *CreateInstance(VIDEOINFO *pIn,VIDEOINFO *pOut);
    HRESULT Transform(BYTE *pInput,BYTE *pOutput);
    HRESULT TransformAligned(BYTE *pInput,BYTE *pOutput);
};


// RGB8 to true colour RGB32 pixel format

class CRGB8ToRGB32Convertor : public CConvertor {
public:

    CRGB8ToRGB32Convertor(VIDEOINFO *pIn,VIDEOINFO *pOut);
    static CConvertor *CreateInstance(VIDEOINFO *pIn,VIDEOINFO *pOut);
    HRESULT Transform(BYTE *pInput,BYTE *pOutput);
};

#endif // __RGB8 __
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\multimedia\dshow\filters\image\colour\rgb8.cpp ===
// Copyright (c) 1994 - 1998  Microsoft Corporation.  All Rights Reserved.
// This file implements RGB 8 colour space conversions, May 1995

#include <streams.h>
#include <colour.h>

// The file implements RGB8 (palettised) formats to RGB555,RGB565,RGB24 and
// RGB32 types. Some filters can only deal with palettised types (like the
// sample colour contrast filter) so having a good true colour conversion is
// reasonably worthwhile. For these formats we have an alignment optimised
// transforms for RGB8 to RGB555,RGB565 and RGB24. To use these the source
// and target rectangles and the widths must be aligned on DWORD boundaries.
// Because RGB555 and RGB565 are so similar we use common code for the two
// colour space conversions but the convertor objects have different Commit
// methods that build a lookup table differently for their respective types


// Generic RGB8 to RGB16 Constructor initialises base class

CRGB8ToRGB16Convertor::CRGB8ToRGB16Convertor(VIDEOINFO *pIn,
                                             VIDEOINFO *pOut) :
    CConvertor(pIn,pOut),
    m_pRGB16Table(NULL)
{
    ASSERT(pIn);
    ASSERT(pOut);
}


// Destructor just checks the table has been deleted

CRGB8ToRGB16Convertor::~CRGB8ToRGB16Convertor()
{
    ASSERT(m_pRGB16Table == NULL);
}


// This allocates the memory for transforming RGB8 to RGB16 images. We have
// a single lookup table that is indexed by the palette value, this maps the
// palette index whose actual colours are defined by the input palette into
// an output 16 bit representation which also includes a colour adjustment

HRESULT CRGB8ToRGB16Convertor::Commit()
{
    CConvertor::Commit();
    m_pRGB16Table = new DWORD[256];

    // Check it was allocated correctly

    if (m_pRGB16Table == NULL) {
        Decommit();
        return E_OUTOFMEMORY;
    }

    return NOERROR;
}


// This is called when we complete transforming RGB8 to RGB16 images, we must
// call the global decommit function and then delete the lookup table which we
// created in the commit, the table may not be present if an error occured

HRESULT CRGB8ToRGB16Convertor::Decommit()
{
    CConvertor::Decommit();

    // Delete the lookup table

    if (m_pRGB16Table) {
        delete[] m_pRGB16Table;
        m_pRGB16Table = NULL;
    }
    return NOERROR;
}


// Transform the input RGB8 image to an output RGB16 16 bit image. This is a
// tight loop taking each palette value and using it as an index to the table
// we initialised during the commit, this produces the output representation
// The table includes an adjustment that stops the image coming out slightly
// duller which it would do when we start dropping the trailing bits off

HRESULT CRGB8ToRGB16Convertor::Transform(BYTE *pInput,BYTE *pOutput)
{
    // Can we do an alignment optimised transform

    if (m_bAligned == TRUE) {
        return TransformAligned(pInput,pOutput);
    }

    // Adjust the height to allow for an immediate decrement

    LONG Height = HEIGHT(&m_pOutputInfo->rcTarget) + 1;
    pInput += m_SrcOffset;
    pOutput += m_DstOffset;

    while (--Height) {

        LONG Width = WIDTH(&m_pOutputInfo->rcTarget) + 1;
        BYTE *pRGB8 = pInput;
        WORD *pRGB16 = (WORD *) pOutput;

        while (--Width) {
            *pRGB16++ = (WORD) m_pRGB16Table[*pRGB8++];
        }
        pInput += m_SrcStride;
        pOutput += m_DstStride;
    }
    return NOERROR;
}


// This does the same colour space conversion as the RGB8 to RGB16 convertor
// except that it goes a little faster. The way it does this is by reading
// and writing DWORDs into memory. For example we read four of the dithered
// palettised pixels at once. The relies on the source and target pointers
// being aligned correctly otherwise we will start geting exceptions on RISC

HRESULT CRGB8ToRGB16Convertor::TransformAligned(BYTE *pInput,BYTE *pOutput)
{
    // Adjust the height to allow for an immediate decrement

    LONG Height = HEIGHT(&m_pOutputInfo->rcTarget) + 1;
    pInput += m_SrcOffset;
    pOutput += m_DstOffset;

    while (--Height) {

        LONG Width = (WIDTH(&m_pOutputInfo->rcTarget) >> 2) + 1;
        DWORD *pRGB8 = (DWORD *) pInput;
        DWORD *pRGB16 = (DWORD *) pOutput;

        while (--Width) {

            DWORD RGB8 = *pRGB8++;

            *pRGB16++ = m_pRGB16Table[(BYTE)RGB8] |
                        (m_pRGB16Table[(BYTE)(RGB8 >> 8)] << 16);
            *pRGB16++ = m_pRGB16Table[(BYTE)(RGB8 >> 16)] |
                        (m_pRGB16Table[(BYTE)(RGB8 >> 24)] << 16);
        }
        pInput += m_SrcStride;
        pOutput += m_DstStride;
    }
    return NOERROR;
}


// Constructor

CRGB8ToRGB565Convertor::CRGB8ToRGB565Convertor(VIDEOINFO *pIn,
                                               VIDEOINFO *pOut) :
    CRGB8ToRGB16Convertor(pIn,pOut)
{
    ASSERT(pIn);
    ASSERT(pOut);
}


// This goes in the table of available lookups to create a transform object
// derived from the base CConvertor class that does the type specific work.
// We initialise the constructor with the fields that it will need to do the
// conversion work and return a pointer to the object or NULL if it failed

CConvertor *CRGB8ToRGB565Convertor::CreateInstance(VIDEOINFO *pIn,
                                                   VIDEOINFO *pOut)
{
    return new CRGB8ToRGB565Convertor(pIn,pOut);
}


// This is a specific commit function for RGB8 to RGB565 transformations, we
// create a lookup table for mapping the input palette values into an output
// 16 bit representation. We create a lookup table partly for speed and also
// so that we can account for the loss in bits. In fact many capture devices
// produce palettes where the there are only first five bits in the colours

HRESULT CRGB8ToRGB565Convertor::Commit()
{
    // Allocate the lookup table memory

    HRESULT hr = CRGB8ToRGB16Convertor::Commit();
    if (FAILED(hr)) {
        return hr;
    }

    // This creates the palette index lookup table

    ASSERT(m_pInputHeader->biBitCount == 8); // valid assertion?
    DWORD cClrUsed = m_pInputHeader->biClrUsed ? m_pInputHeader->biClrUsed : 256;
    for (DWORD Position = 0;Position < cClrUsed;Position++) {

        // Get the current palette colours ready for adjustment

        DWORD RedAdjust = m_pInputInfo->bmiColors[Position].rgbRed;
        DWORD GreenAdjust = m_pInputInfo->bmiColors[Position].rgbGreen;
        DWORD BlueAdjust = m_pInputInfo->bmiColors[Position].rgbBlue;

        // For the red and blue values we transform eight bit palette colours
        // into five bit output values by cutting off the trailing three bits
        // to stop this making the output duller we round the values first
        // Likewise for the green but we only allow for two bits dropped

        ADJUST(RedAdjust,4);
        ADJUST(BlueAdjust,4);
        ADJUST(GreenAdjust,2);

        m_pRGB16Table[Position] = ((RedAdjust >> 3) << 11) |
                                  ((GreenAdjust >> 2) << 5) |
                                  ((BlueAdjust >> 3));
    }
    return NOERROR;
}


// Constructor

CRGB8ToRGB555Convertor::CRGB8ToRGB555Convertor(VIDEOINFO *pIn,
                                               VIDEOINFO *pOut) :
    CRGB8ToRGB16Convertor(pIn,pOut)
{
    ASSERT(pIn);
    ASSERT(pOut);
}


// This goes in the table of available lookups to create a transform object
// derived from the base CConvertor class that does the type specific work.
// We initialise the constructor with the fields that it will need to do the
// conversion work and return a pointer to the object or NULL if it failed

CConvertor *CRGB8ToRGB555Convertor::CreateInstance(VIDEOINFO *pIn,
                                                   VIDEOINFO *pOut)
{
    return new CRGB8ToRGB555Convertor(pIn,pOut);
}


// This is a specific commit function for RGB8 to RGB555 transformations, we
// create a lookup table for mapping the input palette values into an output
// 16 bit representation. We create a lookup table partly for speed and also
// so that we can account for the loss in bits. In fact many capture devices
// produce palettes where the there are only first five bits in the colours

HRESULT CRGB8ToRGB555Convertor::Commit()
{
    // Allocate the lookup table memory

    HRESULT hr = CRGB8ToRGB16Convertor::Commit();
    if (FAILED(hr)) {
        return hr;
    }

    // This creates the palette index lookup table

    ASSERT(m_pInputHeader->biBitCount == 8); // valid assertion?
    DWORD cClrUsed = m_pInputHeader->biClrUsed ? m_pInputHeader->biClrUsed : 256;
    for (DWORD Position = 0;Position < cClrUsed;Position++) {

        // Get the current palette colours ready for adjustment

        DWORD RedAdjust = m_pInputInfo->bmiColors[Position].rgbRed;
        DWORD GreenAdjust = m_pInputInfo->bmiColors[Position].rgbGreen;
        DWORD BlueAdjust = m_pInputInfo->bmiColors[Position].rgbBlue;

        // For all the three colour components we transform eight bit palette
        // colours into five bit output values by cutting off the trailing
        // three bits, this stops the output appearing duller by rounding

        ADJUST(RedAdjust,4);
        ADJUST(BlueAdjust,4);
        ADJUST(GreenAdjust,4);

        m_pRGB16Table[Position] = ((RedAdjust >> 3) << 10) |
                                  ((GreenAdjust >> 3) << 5) |
                                  ((BlueAdjust >> 3));
    }
    return NOERROR;
}


// Constructor

CRGB8ToRGB24Convertor::CRGB8ToRGB24Convertor(VIDEOINFO *pIn,
                                             VIDEOINFO *pOut) :
    CConvertor(pIn,pOut)
{
    ASSERT(pIn);
    ASSERT(pOut);
}


// This goes in the table of available lookups to create a transform object
// derived from the base CConvertor class that does the type specific work.
// We initialise the constructor with the fields that it will need to do the
// conversion work and return a pointer to the object or NULL if it failed

CConvertor *CRGB8ToRGB24Convertor::CreateInstance(VIDEOINFO *pIn,
                                                  VIDEOINFO *pOut)
{
    return new CRGB8ToRGB24Convertor(pIn,pOut);
}


// This transforms a RGB8 input image to a RGB24 output image. We could have
// done this by having a large lookup table whose index is the palette value
// and whose output would be the RGB24 triplet, however it seems to gain so
// little over copying the three colours independantly that I didn't bother

HRESULT CRGB8ToRGB24Convertor::Transform(BYTE *pInput,BYTE *pOutput)
{
    // Can we do an alignment optimised transform?

    if (m_bAligned == TRUE) {
        if (S_OK == TransformAligned(pInput,pOutput))
	    return S_OK;
    }

    // Adjust the height to allow for an immediate decrement

    LONG Height = HEIGHT(&m_pOutputInfo->rcTarget) + 1;
    pInput += m_SrcOffset;
    pOutput += m_DstOffset;

    while (--Height) {

        LONG Width = WIDTH(&m_pOutputInfo->rcTarget) + 1;
        BYTE *pRGB8 = pInput;
        BYTE *pRGB24 = pOutput;

        while (--Width) {

            pRGB24[0] = m_pInputInfo->bmiColors[*pRGB8].rgbBlue;
            pRGB24[1] = m_pInputInfo->bmiColors[*pRGB8].rgbGreen;
            pRGB24[2] = m_pInputInfo->bmiColors[*pRGB8].rgbRed;

            pRGB8++;
            pRGB24 += 3;
        }
        pInput += m_SrcStride;
        pOutput += m_DstStride;
    }
    return NOERROR;
}


// This does the same colour space conversion as the RGB8 to RGB24 convertor
// except that it goes a little faster. The way it does this is by reading
// and writing DWORDs into memory. For example we read four of the dithered
// palettised pixels at once. The relies on the source and target pointers
// being aligned correctly otherwise we will start geting exceptions on RISC
// This assumes that the rgbReserved field in the RGBQUAD palette colours is
// set to zero (as it should be), otherwise the transform will have to do so

HRESULT CRGB8ToRGB24Convertor::TransformAligned(BYTE *pInput,BYTE *pOutput)
{
    // Adjust the height to allow for an immediate decrement

    LONG Height = HEIGHT(&m_pOutputInfo->rcTarget) + 1;
    pInput += m_SrcOffset;
    pOutput += m_DstOffset;

    // All the reserved fields should be set zero, or this function won't work!

    ASSERT(m_pInputHeader->biBitCount == 8); // !!! valid assertion?
    DWORD cClrUsed = m_pInputHeader->biClrUsed ? m_pInputHeader->biClrUsed : 256;
    for (DWORD i = 0;i < cClrUsed;i++) {
        //ASSERT(m_pInputInfo->bmiColors[i].rgbReserved == 0);
        if (m_pInputInfo->bmiColors[i].rgbReserved != 0)
	    return S_FALSE;
    }

    while (--Height) {

        LONG Width = (WIDTH(&m_pOutputInfo->rcTarget) >> 2) + 1;
        DWORD *pRGB8 = (DWORD *) pInput;
        DWORD *pRGB24 = (DWORD *) pOutput;

        while (--Width) {

            // Read four palettised pixels and get their RGBQUAD values

            DWORD RGB8 = *pRGB8++;
            DWORD RGB24a = *((DWORD *)&m_pInputInfo->bmiColors[(BYTE)RGB8]);
            DWORD RGB24b = *((DWORD *)&m_pInputInfo->bmiColors[(BYTE)(RGB8 >> 8)]);
            DWORD RGB24c = *((DWORD *)&m_pInputInfo->bmiColors[(BYTE)(RGB8 >> 16)]);
            DWORD RGB24d = *((DWORD *)&m_pInputInfo->bmiColors[(BYTE)(RGB8 >> 24)]);

            // Construct three DWORDs for the four RGB24 pixels

            *pRGB24++ = (RGB24a) | (RGB24b << 24);
            *pRGB24++ = (RGB24b >> 8) | (RGB24c << 16);
            *pRGB24++ = (RGB24c >> 16) | (RGB24d << 8);
        }
        pInput += m_SrcStride;
        pOutput += m_DstStride;
    }
    return NOERROR;
}


// Constructor

CRGB8ToRGB32Convertor::CRGB8ToRGB32Convertor(VIDEOINFO *pIn,
                                             VIDEOINFO *pOut) :
    CConvertor(pIn,pOut)
{
    ASSERT(pIn);
    ASSERT(pOut);
}


// This goes in the table of available lookups to create a transform object
// derived from the base CConvertor class that does the type specific work.
// We initialise the constructor with the fields that it will need to do the
// conversion work and return a pointer to the object or NULL if it failed

CConvertor *CRGB8ToRGB32Convertor::CreateInstance(VIDEOINFO *pIn,
                                                  VIDEOINFO *pOut)
{
    return new CRGB8ToRGB32Convertor(pIn,pOut);
}


// This transforms a RGB8 input image to a RGB32 output image. As luck would
// have it transforming a palettised image to a 32 bit format is easy since
// the palette RGBQUADs are in exactly the same format as the 32 pixels are
// represented by. Therefore we can just copy the four bytes into the output
// buffer for each pixel. We assume that the output buffer is DWORD aligned

HRESULT CRGB8ToRGB32Convertor::Transform(BYTE *pInput,BYTE *pOutput)
{
    // Adjust the height to allow for an immediate decrement

    LONG Height = HEIGHT(&m_pOutputInfo->rcTarget) + 1;
    pInput += m_SrcOffset;
    pOutput += m_DstOffset;

    if( m_bSetAlpha )
    {
        while (--Height) {

            LONG Width = WIDTH(&m_pOutputInfo->rcTarget) + 1;
            BYTE *pRGB8 = pInput;
            DWORD *pRGB32 = (DWORD *) pOutput;

            while (--Width) {
                *pRGB32++ = 0xFF000000 | *((DWORD *) &m_pInputInfo->bmiColors[*pRGB8++]); // alpha
            }
            pInput += m_SrcStride;
            pOutput += m_DstStride;
        }
    }
    else
    {
        while (--Height) {

            LONG Width = WIDTH(&m_pOutputInfo->rcTarget) + 1;
            BYTE *pRGB8 = pInput;
            DWORD *pRGB32 = (DWORD *) pOutput;

            while (--Width) {
                *pRGB32++ = *((DWORD *) &m_pInputInfo->bmiColors[*pRGB8++]);
            }
            pInput += m_SrcStride;
            pOutput += m_DstStride;
        }
    }
    return NOERROR;
}
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\multimedia\dshow\filters\image\dither\dither.h ===
// Copyright (c) Microsoft Corporation 1994-1996. All Rights Reserved
// This implements VGA colour dithering, April 1996, Anthony Phillips

#ifndef __DITHER__
#define __DITHER__

extern const AMOVIESETUP_FILTER sudDitherFilter;

// These are the cosmic VGA colours

const RGBQUAD VGAColours[] =
{
     {0x00, 0x00, 0x00},
     {0x00, 0x00, 0x80},
     {0x00, 0x80, 0x00},
     {0x00, 0x80, 0x80},
     {0x80, 0x00, 0x00},
     {0x80, 0x00, 0x80},
     {0x80, 0x80, 0x00},
     {0xc0, 0xc0, 0xc0},
     {0x80, 0x80, 0x80},
     {0x00, 0x00, 0xff},
     {0x00, 0xff, 0x00},
     {0x00, 0xff, 0xff},
     {0xff, 0x00, 0x00},
     {0xff, 0x00, 0xff},
     {0xff, 0xff, 0x00},
     {0xff, 0xff, 0xff}
};

// An RGB24 to VGA system colour dithering transform filter

class CDither : public CTransformFilter
{
public:

    CDither(TCHAR *pName,LPUNKNOWN pUnk);
    static CUnknown *CreateInstance(LPUNKNOWN pUnk,HRESULT *phr);

    // Manage type checking and the VGA colour conversion

    HRESULT CheckVideoType(const CMediaType *pmtIn);
    HRESULT CheckInputType(const CMediaType *pmtIn);
    HRESULT CheckTransform(const CMediaType *pmtIn,const CMediaType *pmtOut);
    HRESULT GetMediaType(int iPosition,CMediaType *pmtOut);
    HRESULT SetMediaType(PIN_DIRECTION direction, const CMediaType *pmt);
    HRESULT Transform(IMediaSample *pIn,IMediaSample *pOut);


    // Prepare the allocator's count of buffers and sizes
    HRESULT DecideBufferSize(IMemAllocator *pAllocator,
                             ALLOCATOR_PROPERTIES *pProperties);

private:
    BYTE    m_DitherTable[256 * 8 * 8];
    BOOL    m_fInit;
    UINT    m_wWidthSrc;
    UINT    m_wWidthDst;
    int     m_DstXE;
    int     m_DstYE;

    HRESULT SetInputPinMediaType(const CMediaType *pmt);
    void SetOutputPinMediaType(const CMediaType *pmt);

    BOOL    DitherDeviceInit(LPBITMAPINFOHEADER lpbi);
    void    Dither8(LPBYTE lpDst, LPBYTE lpSrc);
};

#endif // __DITHER__
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\multimedia\dshow\filters\image\dither\dithuids.h ===
//==========================================================================;
//
//  THIS CODE AND INFORMATION IS PROVIDED "AS IS" WITHOUT WARRANTY OF ANY
//  KIND, EITHER EXPRESSED OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE
//  IMPLIED WARRANTIES OF MERCHANTABILITY AND/OR FITNESS FOR A PARTICULAR
//  PURPOSE.
//
//  Copyright (c) 1992 - 1996  Microsoft Corporation.  All Rights Reserved.
//
//--------------------------------------------------------------------------;

DEFINE_GUID(CLSID_Dither,
0x1da08500, 0x9edc, 0x11cf, 0xbc, 0x10, 0x00, 0xaa, 0x00, 0xac, 0x74, 0xf6);
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\multimedia\dshow\filters\image\modex\allocate.cpp ===
// Copyright (c) 1994 - 1999  Microsoft Corporation.  All Rights Reserved.
// Implements a Modex buffer allocator, Anthony Phillips, January 1996

#include <streams.h>
#include <windowsx.h>
#include <vidprop.h>
#include <modex.h>
#include <render.h>
#include <viddbg.h>
#include <amaudio.h>

// This implements a specialist allocator for the Modex renderer. Because we
// use a special display mode where neither us nor GDI can touch the display
// (since it's in a weird planar format when set to 320x240x8) we can only
// use our own allocator, this prevents us from being connected to someone
// like the infinite tee filter. When we are activated (either through pause
// or run) we load DirectDraw and allocate our surfaces, these are either a
// set of three triple buffered surfaces or just a pair. We try to create the
// surfaces in VRAM first but if that fails we drop back into system memory.
//
// We also use 320x200x8 (another Modex display mode) but most video content
// is 320x240 or larger (such as typically 352x240 in an MPEG case) so going
// to the smaller mode may lose considerably more of the image. However we
// will pick 320x200 by default (because we initialise the clip loss factor
// to 25%). For 352x288 images the clip is a bit less than 25%. If the image
// is larger than the 320x240 mode we ask the source to compress the image.
// If it cannot do this then we ask it for a central portion so dropping an
// equal amount of the picture off the left and right edges as well as the
// top and bottom where appropriate. If the image is smaller than the display
// mode then we ask it to centre the video in the surface we'll be providing
// or failing that we will decode into an offscreen surface and stretch that
//
// Most of the work is done during connection and activation. When we have a
// CompleteConnect called we check that the source filter can provide a type
// we will be able to display in any of the modes we support. If not we will
// reject the call, this may lead to having a colour space convertor put in
// between us so that it can do the clipping or necessary colour conversion
//
// When we are activated we switch display modes to the mode we agreed during
// the connection and then create the surfaces (the VRAM may not be available
// until we have switched modes). If we manage to create the surfaces then we
// are done otherwise we have to reject the activation. Since we are a full
// screen exclusive mode application which should get complete VRAM access
// and we can drop back to using system memory buffers if insufficient VRAM
// is available we should in most common situations always be able to pause
//
// Our implementation of GetBuffer looks after switching between GDI buffers
// and DirectDraw surfaces when it notices that either we are not activated
// any more (by the user hitting ALT-TAB) or we have lost the surface through
// a similar mechanism. We use GDI buffers for the source to dump their video
// in just through convenience, we don't actually draw the buffers we receive


// Constructor

CModexAllocator::CModexAllocator(CModexRenderer *pRenderer,
                                 CModexVideo *pModexVideo,
                                 CModexWindow *pModexWindow,
                                 CCritSec *pLock,
                                 HRESULT *phr) :

    CImageAllocator(pRenderer,NAME("Modex Allocator"),phr),
    m_pModexVideo(pModexVideo),
    m_pModexWindow(pModexWindow),
    m_pInterfaceLock(pLock),
    m_pRenderer(pRenderer),
    m_pDirectDraw(NULL),
    m_pFrontBuffer(NULL),
    m_pBackBuffer(NULL),
    m_pDrawPalette(NULL),
    m_bModeChanged(FALSE),
    m_cbSurfaceSize(0),
    m_bModexSamples(FALSE),
    m_bIsFrontStale(TRUE),
    m_ModeWidth(0),
    m_ModeHeight(0),
    m_ModeDepth(0),
    m_bTripleBuffered(FALSE),
    m_bOffScreen(FALSE),
    m_pDrawSurface(NULL)
{
    ASSERT(m_pRenderer);
    ASSERT(m_pModexVideo);
    ASSERT(m_pModexWindow);
    ASSERT(phr);

    m_fDirectDrawVersion1 = m_LoadDirectDraw.IsDirectDrawVersion1();

    // Allocate and zero fill the output format

    m_SurfaceFormat.AllocFormatBuffer(sizeof(VIDEOINFO));
    VIDEOINFO *pVideoInfo = (VIDEOINFO *) m_SurfaceFormat.Format();
    if (pVideoInfo) {
        ZeroMemory((PVOID)pVideoInfo,sizeof(VIDEOINFO));
    }
}


// Check our DirectDraw buffers have been released

CModexAllocator::~CModexAllocator()
{
    ASSERT(m_bCommitted == FALSE);
    ASSERT(m_pFrontBuffer == NULL);
    ASSERT(m_pDrawSurface == NULL);
    ASSERT(m_pDirectDraw == NULL);
}


// Overriden to increment the owning object's reference count

STDMETHODIMP_(ULONG) CModexAllocator::NonDelegatingAddRef()
{
    NOTE("Entering NonDelegatingAddRef");
    return m_pRenderer->AddRef();
}


// Overriden to decrement the owning object's reference count

STDMETHODIMP_(ULONG) CModexAllocator::NonDelegatingRelease()
{
    NOTE("Entering NonDelegatingRelease");
    return m_pRenderer->Release();
}


// Prepare the allocator by checking the input parameters. The Modex renderer
// only ever works with one buffer so we change the input count accordingly
// If the source filter requires more than one buffer to operate then they
// cannot be connected to us. We also update the buffer size so that it does
// not exceed the size of the video image that it will contain in the future

STDMETHODIMP CModexAllocator::CheckSizes(ALLOCATOR_PROPERTIES *pRequest)
{
    NOTE("Entering CheckSizes");

    // Check we have a valid connection

    if (m_pMediaType == NULL) {
        return VFW_E_NOT_CONNECTED;
    }

    // We always create a DirectDraw surface with the source format

    VIDEOINFO *pVideoInfo = (VIDEOINFO *) m_pMediaType->Format();
    if ((DWORD) pRequest->cbBuffer < pVideoInfo->bmiHeader.biSizeImage) {
        return E_INVALIDARG;
    }

    // Reject buffer prefixes

    if (pRequest->cbPrefix > 0) {
        return E_INVALIDARG;
    }

    pRequest->cbBuffer = pVideoInfo->bmiHeader.biSizeImage;
    pRequest->cBuffers = 1;
    return NOERROR;
}


// Agree the number of media sample buffers and their sizes. The base class
// this allocator is derived from allows samples to be aligned only on byte
// boundaries NOTE the buffers are not allocated until the Commit is called
// Because the samples we return are DirectDraw surfaces we only allow one
// sample ever to be allocated, so reset the incoming sample count to one.
// If the source must have more than one sample then it can't connect to us

STDMETHODIMP CModexAllocator::SetProperties(ALLOCATOR_PROPERTIES *pRequest,
                                            ALLOCATOR_PROPERTIES *pActual)
{
    ALLOCATOR_PROPERTIES Adjusted = *pRequest;
    NOTE("Entering SetProperties");

    // Check the parameters fit with the current connection

    HRESULT hr = CheckSizes(&Adjusted);
    if (FAILED(hr)) {
        return hr;
    }
    return CBaseAllocator::SetProperties(&Adjusted,pActual);
}


// The base CImageAllocator class calls this virtual method to actually make
// the samples. It is deliberately virtual so that we can override to create
// more specialised sample objects. On our case our samples are derived from
// CImageSample but add the DirectDraw guff. We return a CImageSample object
// which is easy enough because the CVideoSample class is derived from that

CImageSample *CModexAllocator::CreateImageSample(LPBYTE pData,LONG Length)
{
    NOTE("Entering CreateImageSample");
    HRESULT hr = NOERROR;
    CVideoSample *pSample;

    // Allocate the new sample and check the return codes

    pSample = new CVideoSample((CModexAllocator*) this,    // Base allocator
                               NAME("Video sample"),       // DEBUG name
                               (HRESULT *) &hr,            // Return code
                               (LPBYTE) pData,             // DIB address
                               (LONG) Length);             // Size of DIB

    if (pSample == NULL || FAILED(hr)) {
        delete pSample;
        return NULL;
    }
    return pSample;
}


// Called when the format changes for the source video. Modex only works with
// eight bit palettised formats so we always have to create a palette through
// DirectDraw. All we have to do is hand it 256 colours even if we don't have
// that many and let it create an IDirectDrawPalette object. If we don't have
// DirectDraw loaded yet then we defer the palette object creation until later

HRESULT CModexAllocator::UpdateDrawPalette(const CMediaType *pMediaType)
{
    VIDEOINFO *pVideoInfo = (VIDEOINFO *) pMediaType->Format();
    VIDEOINFO *pSurfaceInfo = (VIDEOINFO *) m_SurfaceFormat.Format();
    NOTE("Entering UpdateDrawPalette");
    PALETTEENTRY ColourTable[256];
    CAutoLock cVideoLock(this);

    // Do we have created our surfaces yet

    if (m_pFrontBuffer == NULL) {
        NOTE("No DirectDraw");
        return NOERROR;
    }

    // Does this surface require a palette

    if (m_ModeDepth != 8) {
        NOTE("No palette");
        return NOERROR;
    }

    // We should have a palette to extract

    if (PALETTISED(pVideoInfo) == FALSE) {
        ASSERT(!TEXT("No source palette"));
        return VFW_E_TYPE_NOT_ACCEPTED;
    }

    // Initialise the palette colours if default used

    ULONG PaletteColours = pVideoInfo->bmiHeader.biClrUsed;
    if (pVideoInfo->bmiHeader.biClrUsed == 0) {
        PaletteColours = PALETTE_ENTRIES(pVideoInfo);
    }

    // Copy the palette colours into our output format

    CopyMemory((PVOID) pSurfaceInfo->bmiColors,
               (PVOID) pVideoInfo->bmiColors,
               PaletteColours * sizeof(RGBQUAD));

    ASSERT(*pMediaType->Subtype() == MEDIASUBTYPE_RGB8);
    ASSERT(pVideoInfo->bmiHeader.biClrUsed <= 256);
    ASSERT(pVideoInfo->bmiHeader.biCompression == BI_RGB);
    ASSERT(pVideoInfo->bmiHeader.biBitCount == 8);
    ZeroMemory((PVOID) ColourTable,sizeof(ColourTable));

    // Copy the colours into a PALETTEENTRY array

    for (WORD i = 0;i < PaletteColours;i++) {
        ColourTable[i].peRed = (BYTE) pVideoInfo->bmiColors[i].rgbRed;
        ColourTable[i].peGreen = (BYTE) pVideoInfo->bmiColors[i].rgbGreen;
        ColourTable[i].peBlue = (BYTE) pVideoInfo->bmiColors[i].rgbBlue;
        ColourTable[i].peFlags = (BYTE) PC_NOCOLLAPSE;
    }

    // Are we updating the colours in an existing palette
    if (m_pDrawPalette) return m_pDrawPalette->SetEntries(0,0,256,ColourTable);

    // Create the palette object for the colour table

    HRESULT hr = m_pDirectDraw->CreatePalette(DDPCAPS_8BIT,
                                              ColourTable,
                                              &m_pDrawPalette,
                                              (IUnknown *) NULL);
    if (FAILED(hr)) {
        NOTE("No palette");
        return hr;
    }
    return m_pFrontBuffer->SetPalette(m_pDrawPalette);
}


// Called when we have a sample delivered to our input pin

void CModexAllocator::OnReceive(IMediaSample *pMediaSample)
{
    NOTE("Entering CModexAllocator OnReceive");
    CVideoSample *pVideoSample = (CVideoSample *) pMediaSample;
    pVideoSample->SetDirectInfo(NULL,NULL,0,NULL);

    // Set up the surface we should be unlocking
    LPDIRECTDRAWSURFACE pSurface = GetDirectDrawSurface();

    // We may have switched to using DIBSECTION samples

    if (m_bModexSamples == TRUE) {
        pSurface->Unlock(NULL);
        m_bIsFrontStale = FALSE;
    }
}


// Return TRUE if we are using DirectDraw at the moment

BOOL CModexAllocator::GetDirectDrawStatus()
{
    NOTE("GetDirectDrawStatus");
    CAutoLock cVideoLock(this);
    return m_bModexSamples;
}


// Overriden from CBaseAllocator and called when the final reference count
// is released on a media sample so that it can be added to the tail of the
// allocator free list. We intervene at this point to make sure that if the
// display was locked when GetBuffer was called that it is always unlocked
// regardless of whether the source calls Receive on our input pin or not

STDMETHODIMP CModexAllocator::ReleaseBuffer(IMediaSample *pMediaSample)
{
    NOTE("Entering ReleaseBuffer");

    CheckPointer(pMediaSample,E_POINTER);
    CVideoSample *pVideoSample = (CVideoSample *) pMediaSample;
    BYTE *pBuffer = pVideoSample->GetDirectBuffer();
    pVideoSample->SetDirectInfo(NULL,NULL,0,NULL);

    // Set up the surface we should be unlocking
    LPDIRECTDRAWSURFACE pSurface = GetDirectDrawSurface();

    // Is this a preroll sample (still locked)

    if (pBuffer != NULL) {
        ASSERT(pSurface);
        pSurface->Unlock(NULL);
        m_bIsFrontStale = TRUE;
    }
    return CBaseAllocator::ReleaseBuffer(pMediaSample);
}


// We override the IMemAllocator GetBuffer function so that after retrieving
// the next sample from the free queue we prepare it with a pointer to the
// DirectDraw surface. If the lock fails then we have probably been switched
// away from using ALT-TAB so the best thing to do is to return an error to
// to the source filter. When the sample is subsequently delivered to our
// input pin or released we will reset the DirectDraw information held by it

STDMETHODIMP CModexAllocator::GetBuffer(IMediaSample **ppSample,
                                        REFERENCE_TIME *pStartTime,
                                        REFERENCE_TIME *pEndTime,
                                        DWORD dwFlags)
{
    CheckPointer(ppSample,E_POINTER);
    NOTE("Entering GetBuffer");
    HRESULT hr;

    // Synchronise by getting a sample from the base class queue

    hr = CBaseAllocator::GetBuffer(ppSample,pStartTime,pEndTime,dwFlags);
    if (FAILED(hr)) {
        return hr;
    }

    CAutoLock cVideoLock(this);
    NOTE("Locked Modex allocator");

    // Keep trying to use our DirectDraw surfaces

    hr = StartDirectAccess(*ppSample,dwFlags);
    if (FAILED(hr)) {
        return StopUsingDirectDraw(ppSample);
    }
    return NOERROR;
}


// Called to switch back to using normal DIBSECTION buffers. We may be called
// when we are not using DirectDraw anyway in which case we do nothing except
// setting the type back to NULL (just in case it has a DirectDraw type). If
// the type has to be changed back then we do not query it with the source as
// it should always accept it - even if when changed it has to seek forwards

HRESULT CModexAllocator::StopUsingDirectDraw(IMediaSample **ppSample)
{
    NOTE("Entering StopUsingDirectDraw");
    IMediaSample *pSample = *ppSample;

    // Is there anything to do

    if (m_bModexSamples == FALSE) {
        pSample->SetMediaType(NULL);
        return NOERROR;
    }

    m_bModexSamples = FALSE;
    pSample->SetMediaType(&m_pRenderer->m_mtIn);
    pSample->SetDiscontinuity(TRUE);
    NOTE("Attached original type to sample");

    return NOERROR;
}


// Return the surface we should be using as primary lock destination

inline LPDIRECTDRAWSURFACE CModexAllocator::GetDirectDrawSurface()
{
    if (m_pDrawSurface == NULL) {
        return m_pBackBuffer;
    }
    return m_pDrawSurface;
}


// This tries to lock the backing surface for the source filter to use as an
// output buffer. We may be called in a number of situations. Firstly of all
// when we are switching into using Modex samples for the first time after
// some break in which case we must set the output format type on it. We may
// also get in here to find the surface has gone in which case we return an
// error code and leave GetBuffer to switch the source back to using a DIB
// buffer. We don't do anything with the DIB buffer but it's easy to handle

HRESULT CModexAllocator::StartDirectAccess(IMediaSample *pMediaSample,DWORD dwFlags)
{
    NOTE("Entering StartDirectAccess");

    // Initialise the size field in the DDSURFACEDESC structure

    CVideoSample *pVideoSample = (CVideoSample *) pMediaSample;
    DDSURFACEDESC SurfaceDesc;
    SurfaceDesc.dwSize = sizeof(DDSURFACEDESC);

    // Check we still have a surface

    if (m_pFrontBuffer == NULL) {
        NOTE("No front buffer");
        return E_UNEXPECTED;
    }

    // What state is the display in

    if (m_bModeChanged == FALSE) {
        NOTE("No display change");
        return E_UNEXPECTED;
    }

    // Handle our window being switched away from

    if (m_pFrontBuffer->IsLost() == DDERR_SURFACELOST) {
        NOTE("Surface is lost");
        return E_UNEXPECTED;
    }

    // Only copy if the back buffer is needed

    if (dwFlags & AM_GBF_NOTASYNCPOINT) {
        if (m_pDrawSurface == NULL) {
            PrepareBackBuffer(m_pBackBuffer);
        }
    }

    // Set up the surface we should be locking
    LPDIRECTDRAWSURFACE pSurface = GetDirectDrawSurface();

    // Lock the surface to get the buffer pointer

    HRESULT hr = pSurface->Lock((RECT *) NULL,    // Target rectangle
                                &SurfaceDesc,     // Return information
                                DDLOCK_WAIT,      // Wait for surface
                                (HANDLE) NULL);   // Don't use event
    if (FAILED(hr)) {
        NOTE1("No lock %lx",hr);
        return hr;
    }

    // Does this sample need the output format attached

    if (m_bModexSamples == FALSE) {
        NOTE("Attaching DirectDraw type to sample");
        pVideoSample->SetMediaType(&m_SurfaceFormat);
        pVideoSample->SetDiscontinuity(TRUE);
        m_bModexSamples = TRUE;
    }

    // Display some surface information

    NOTE1("Stride %d",SurfaceDesc.lPitch);
    NOTE1("Width %d",SurfaceDesc.dwWidth);
    NOTE1("Height %d",SurfaceDesc.dwHeight);
    NOTE1("Surface %x",SurfaceDesc.lpSurface);
    BYTE *pBuffer = (PBYTE) SurfaceDesc.lpSurface;

    // Initialise the sample with the DirectDraw information

    pVideoSample->SetDirectInfo(pSurface,           // The surface
                                m_pDirectDraw,      // DirectDraw
                                m_cbSurfaceSize,    // Buffer size
                                pBuffer);           // Data buffer
    return NOERROR;
}


// In Modex the triple and double buffered surfaces aren't real flip surfaces
// but are made to look that way, amy attempt to lock the front buffer or blt
// from front to back fails. When we are using the normal 640x480 mode but
// with double and triple buffered surfaces this isn't the case as they are
// real surfaces. This means that we may have to look after keeping the back
// buffer upto date with the contents as most decompressors need that image
// We always try to do the BltFast and just ignore any failure return codes

HRESULT CModexAllocator::PrepareBackBuffer(LPDIRECTDRAWSURFACE pSurface)
{
    VIDEOINFO *pSurfaceInfo = (VIDEOINFO *) m_SurfaceFormat.Format();
    RECT DestinationRect = pSurfaceInfo->rcTarget;
    NOTE("Entering PrepareBackBuffer");
    ASSERT(m_pDrawSurface == NULL);

    // Which surface is most upto date

    ASSERT(pSurface);
    if (m_bIsFrontStale == TRUE) {
        NOTE("Front is stale");
        return NOERROR;
    }

    // Are we even in a DirectDraw mode

    if (m_bModexSamples == FALSE) {
        NOTE("Not upto date");
        return NOERROR;
    }

    ASSERT(m_pFrontBuffer);
    ASSERT(m_pDirectDraw);
    NOTERC("Modex",DestinationRect);

    // If in system memory then only one buffer is created

    if (m_SurfaceCaps.dwCaps & DDSCAPS_SYSTEMMEMORY) {
        NOTE("Front buffer emulated");
        return NOERROR;
    }

    // Modex has emulated flipping surfaces

    if (m_SurfaceCaps.dwCaps & DDSCAPS_MODEX) {
        NOTE("Front buffer is Modex");
        return NOERROR;
    }

    // Update the back buffer with the current image

    HRESULT hr = pSurface->BltFast(DestinationRect.left,   // Target left
    				               DestinationRect.top,	   // And the left
                 	       	       m_pFrontBuffer,         // Image source
			       	               &DestinationRect,       // Source rectangle
			                       DDBLTFAST_WAIT);        // No completion

    NOTE1("Blt returned %lx",hr);
    return NOERROR;
}


// Zero fill the DirectDraw surface we are passed

HRESULT CModexAllocator::ResetBackBuffer(LPDIRECTDRAWSURFACE pSurface)
{
    NOTE("Entering ResetDirectDrawSurface");
    DDBLTFX ddbltfx;
    ddbltfx.dwSize = sizeof(DDBLTFX);
    ddbltfx.dwFillColor = 0;
    return pSurface->Blt(NULL,NULL,NULL,DDBLT_COLORFILL | DDBLT_WAIT,&ddbltfx);
}


// Create a single primary (not page flipped) for drawing with

HRESULT CModexAllocator::CreatePrimary()
{
    NOTE("Entering CreatePrimary");
    ASSERT(m_bTripleBuffered == FALSE);
    ASSERT(m_pDrawSurface == NULL);
    ASSERT(m_pFrontBuffer == NULL);
    ASSERT(m_pDirectDraw);
    DDSURFACEDESC SurfaceDesc;

    // Initialise the primary surface descriptor
    SurfaceDesc.dwSize = sizeof(DDSURFACEDESC);
    SurfaceDesc.dwFlags = DDSD_CAPS;
    SurfaceDesc.ddsCaps.dwCaps = DDSCAPS_PRIMARYSURFACE;

    // Ask DirectDraw to create the surface

    HRESULT hr = m_pDirectDraw->CreateSurface(&SurfaceDesc,&m_pFrontBuffer,NULL);
    if (FAILED(hr)) {
        NOTE1("No primary %lx",hr);
        return hr;
    }

    // Get the primary surface capabilities

    hr = m_pFrontBuffer->GetCaps(&m_SurfaceCaps);
    if (FAILED(hr)) {
        NOTE("No caps");
        return hr;
    }
    return NOERROR;
}


// Create an RGB offscreen surface that matches the current display mode. We
// will try and get it in video memory first assuming the display isn't bank
// switch (because stretching between banks is awful). Failing that we will
// try and get it in system memory (so we should always succeed in creation)
// We also need a front buffer (primary surface) to act as the blting target

HRESULT CModexAllocator::CreateOffScreen(BOOL bCreatePrimary)
{
    NOTE("Entering CreateOffScreen");
    ASSERT(m_pDirectDraw);
    ASSERT(m_pDrawSurface == NULL);
    DDSURFACEDESC SurfaceDesc;

    // Create a single primary surface

    if (bCreatePrimary == TRUE) {
        HRESULT hr = CreatePrimary();
        if (FAILED(hr)) {
            return hr;
        }
    }

    // We should have a primary surface by now

    ASSERT(m_pBackBuffer || m_bOffScreen);
    ASSERT(m_pFrontBuffer);
    ASSERT(m_pDrawSurface == NULL);
    ASSERT(m_pDirectDraw);

    // We need both the original type and the surface format

    VIDEOINFO *pVideoInfo = (VIDEOINFO *) m_SurfaceFormat.Format();
    VIDEOINFO *pInputInfo = (VIDEOINFO *) m_pRenderer->m_mtIn.Format();
    BITMAPINFOHEADER *pHeader = HEADER(pVideoInfo);

    // Set the surface description of the offscreen

    SurfaceDesc.dwSize = sizeof(DDSURFACEDESC);
    SurfaceDesc.dwFlags = DDSD_CAPS | DDSD_HEIGHT | DDSD_WIDTH;
    SurfaceDesc.dwHeight = pInputInfo->bmiHeader.biHeight;
    SurfaceDesc.dwWidth = pInputInfo->bmiHeader.biWidth;
    SurfaceDesc.ddsCaps.dwCaps = DDSCAPS_OFFSCREENPLAIN | DDSCAPS_VIDEOMEMORY;

    // Check the primary surface is not bank switched

    if (m_SurfaceCaps.dwCaps & DDCAPS_BANKSWITCHED) {
        NOTE("Primary surface is bank switched");
        SurfaceDesc.ddsCaps.dwCaps = DDSCAPS_OFFSCREENPLAIN;
    }

    // Store the masks in the DDSURFACEDESC

    const DWORD *pBitMasks = m_pRenderer->m_Display.GetBitMasks(pVideoInfo);
    SurfaceDesc.ddpfPixelFormat.dwRGBBitCount = pHeader->biBitCount;
    SurfaceDesc.ddpfPixelFormat.dwRBitMask = pBitMasks[0];
    SurfaceDesc.ddpfPixelFormat.dwGBitMask = pBitMasks[1];
    SurfaceDesc.ddpfPixelFormat.dwBBitMask = pBitMasks[2];

    // It appears that DirectDraw ignores any true colours masks

    NOTE1("Bit count %d",SurfaceDesc.ddpfPixelFormat.dwRGBBitCount);
    NOTE1("Red mask %x",SurfaceDesc.ddpfPixelFormat.dwRBitMask);
    NOTE1("Green mask %x",SurfaceDesc.ddpfPixelFormat.dwGBitMask);
    NOTE1("Blue mask %x",SurfaceDesc.ddpfPixelFormat.dwBBitMask);
    NOTE1("Width %d",SurfaceDesc.dwWidth);
    NOTE1("Height %d",SurfaceDesc.dwHeight);
    NOTE1("Flags %d",SurfaceDesc.ddsCaps.dwCaps);

    // Create the offscreen drawing surface

    HRESULT hr = m_pDirectDraw->CreateSurface(&SurfaceDesc,&m_pDrawSurface,NULL);
    if (FAILED(hr)) {
        SurfaceDesc.ddsCaps.dwCaps = DDSCAPS_OFFSCREENPLAIN;
        hr = m_pDirectDraw->CreateSurface(&SurfaceDesc,&m_pDrawSurface,NULL);
        if (FAILED(hr)) {
            NOTE1("No surface %lx",hr);
            return hr;
        }
    }

    NOTE("Created DirectDraw offscreen surface");
    NOTE1("Back buffer %x",m_pBackBuffer);
    NOTE1("Front buffer %x",m_pFrontBuffer);

    // Ask DirectDraw for a description of the surface

    m_SurfaceDesc.dwSize = sizeof(DDSURFACEDESC);
    hr = m_pDrawSurface->GetSurfaceDesc(&m_SurfaceDesc);
    if (FAILED(hr)) {
        NOTE("No description");
        return hr;
    }

    UpdateSurfaceFormat();

    // Overwrite with the real surface capabilities

    hr = m_pDrawSurface->GetCaps(&m_SurfaceCaps);
    if (FAILED(hr)) {
        NOTE("No caps");
        return hr;
    }
    return UpdateDrawPalette(m_pMediaType);
}


// There are two problems with agreeing a format before creating the surfaces
// The first is that we don't know whether the surface will be RGB565 or 555
// when we specify a 16bit surface. The second problem is that we don't know
// the stride for the surface. For most surfaces it will normally be the new
// display width but it doesn't have to be. Therefore after actually changing
// modes and creating the surfaces we update the format we give to the source

HRESULT CModexAllocator::UpdateSurfaceFormat()
{
    VIDEOINFO *pVideoInfo = (VIDEOINFO *) m_SurfaceFormat.Format();
    BITMAPINFOHEADER *pHeader = HEADER(pVideoInfo);
    NOTE1("Updating format (stride %d)",m_SurfaceDesc.lPitch);

    // When we connect and decide upon using a true colour format we check
    // the source filter can provide both RGB565 and RGB555 varieties as
    // we don't know until we actually create the surface what they'll be
    // At this point we have created the surface so we must initialise the
    // output surface format with the bit fields and also the media subtype

    if (*m_SurfaceFormat.Subtype() == MEDIASUBTYPE_RGB565) {
        pVideoInfo->dwBitMasks[0] = m_SurfaceDesc.ddpfPixelFormat.dwRBitMask;
        pVideoInfo->dwBitMasks[1] = m_SurfaceDesc.ddpfPixelFormat.dwGBitMask;
        pVideoInfo->dwBitMasks[2] = m_SurfaceDesc.ddpfPixelFormat.dwBBitMask;
        const GUID SubType = GetBitmapSubtype(&pVideoInfo->bmiHeader);
        m_SurfaceFormat.SetSubtype(&SubType);
    }

    // Update the DirectDraw capabilities structures

    ASSERT(m_pDirectDraw);
    m_DirectCaps.dwSize = sizeof(DDCAPS);
    m_DirectSoftCaps.dwSize = sizeof(DDCAPS);

    // Load the hardware and emulation capabilities

    HRESULT hr = m_pDirectDraw->GetCaps(&m_DirectCaps,&m_DirectSoftCaps);
    if (FAILED(hr)) {
        return hr;
    }

    // Display the hardware and emulated alignment restrictions

    NOTE1("Target size alignment %d",m_DirectCaps.dwAlignSizeDest);
    NOTE1("Target boundary alignment %d",m_DirectCaps.dwAlignBoundaryDest);
    NOTE1("Source size alignment %d",m_DirectCaps.dwAlignSizeSrc);
    NOTE1("Source boundary alignment %d",m_DirectCaps.dwAlignBoundarySrc);
    NOTE1("Emulated Source size alignment %d",m_DirectSoftCaps.dwAlignSizeDest);
    NOTE1("Emulated boundary alignment %d",m_DirectSoftCaps.dwAlignBoundaryDest);
    NOTE1("Emulated Target size alignment %d",m_DirectSoftCaps.dwAlignSizeSrc);
    NOTE1("Emulated boundary alignment %d",m_DirectSoftCaps.dwAlignBoundarySrc);

    // If we're stretching force the alignment to no less than DWORDs
    //     this is done for pure performance on the basis that if
    //         we are stretching nobody is going to notice it

    if (m_DirectCaps.dwAlignBoundarySrc < 4) m_DirectCaps.dwAlignBoundarySrc = 4;
    if (m_DirectCaps.dwAlignSizeSrc < 4) m_DirectCaps.dwAlignSizeSrc = 4;
    if (m_DirectCaps.dwAlignBoundaryDest < 4) m_DirectCaps.dwAlignBoundaryDest = 4;
    if (m_DirectCaps.dwAlignSizeDest < 4) m_DirectCaps.dwAlignSizeDest = 4;

    // The stride may be different to our approximate calculation
    pHeader->biWidth = m_SurfaceDesc.lPitch / (pHeader->biBitCount / 8);
    SetSurfaceSize(pVideoInfo);
    NOTE1("Resulting surface size %d",pHeader->biSizeImage);

    // Make sure the source and target are aligned
    if (m_pDrawSurface) AlignRectangles(&m_ScaledSource,&m_ScaledTarget);

    // Will the source filter provide this format

    hr = QueryAcceptOnPeer(&m_SurfaceFormat);
    if (hr != NOERROR) {
        NOTE("Update failed");
        return hr;
    }
    return NOERROR;
}


// Called to allocate the DirectDraw surfaces. We only use primary flipping
// surfaces so we try to create them first in video memory. If we can't get
// any VRAM buffered surface we try again without specifying VRAM and we'll
// get back a system memory surface. That won't use hardware page flipping
// but at least we'll run. Because we run fullscreen exclusive we can limit
// ourselves to dealing with primary surfaces only and not other types. We
// have to recreate the flipping surfaces each time we change display mode
// as it may not be until then that the necessary video memory will be free

HRESULT CModexAllocator::CreateSurfaces()
{
    NOTE("Entering CreateSurfaces");
    ASSERT(m_pDirectDraw);
    HRESULT hr = NOERROR;
    m_bModexSamples = FALSE;

    // Did we agree to stretch an offscreen surface
    if (m_bOffScreen == TRUE)
        if (m_ModeWidth > AMSCAPS_MUST_FLIP)
            return CreateOffScreen(TRUE);

    // Start with triple buffered primary flipping surfaces

    ZeroMemory(&m_SurfaceDesc,sizeof(DDSURFACEDESC));
    m_SurfaceDesc.dwSize = sizeof(m_SurfaceDesc);
    m_SurfaceDesc.dwFlags = DDSD_CAPS | DDSD_BACKBUFFERCOUNT;
    m_SurfaceDesc.dwBackBufferCount = 2;

    m_SurfaceDesc.ddsCaps.dwCaps = DDSCAPS_PRIMARYSURFACE |
                                   DDSCAPS_FLIP |
                                   DDSCAPS_COMPLEX |
                                   DDSCAPS_VIDEOMEMORY;

    // Try to get a triple or double buffered surface in VRAM

    hr = m_pDirectDraw->CreateSurface(&m_SurfaceDesc,&m_pFrontBuffer,NULL);
    if (FAILED(hr)) {
        NOTE1("No triple VRAM buffered %lx",hr);
        m_SurfaceDesc.dwBackBufferCount = 1;
        hr = m_pDirectDraw->CreateSurface(&m_SurfaceDesc,&m_pFrontBuffer,NULL);
    }

    // Try double buffered surfaces in normal system memory

    if (FAILED(hr)) {
        NOTE1("No double VRAM buffered %lx",hr);
        m_SurfaceDesc.ddsCaps.dwCaps &= ~DDSCAPS_VIDEOMEMORY;
        hr = m_pDirectDraw->CreateSurface(&m_SurfaceDesc,&m_pFrontBuffer,NULL);
        if (FAILED(hr)) {
            NOTE1("No double system buffered %lx",hr);
            return hr;
        }
    }

    // Have we got triple buffered surfaces

    m_bTripleBuffered = FALSE;
    if (m_SurfaceDesc.dwBackBufferCount == 2) {
        m_bTripleBuffered = TRUE;
    }

    // Get a pointer to the back buffer

    NOTE1("Triple Buffered (%d)",m_bTripleBuffered);
    DDSCAPS SurfaceCaps;
    ZeroMemory(&SurfaceCaps,sizeof(DDSCAPS));
    SurfaceCaps.dwCaps = DDSCAPS_BACKBUFFER;

    hr = m_pFrontBuffer->GetAttachedSurface(&SurfaceCaps,&m_pBackBuffer);
    if (FAILED(hr)) {
        NOTE("No attached surface");
        return hr;
    }

    // Get the front buffer capabilities

    hr = m_pFrontBuffer->GetCaps(&m_SurfaceCaps);
    if (FAILED(hr)) {
        return hr;
    }

    // Did we agree to use an offscreen surface
    if (m_bOffScreen) return CreateOffScreen(FALSE);

    // Ask DirectDraw for a description of the surface

    m_SurfaceDesc.dwSize = sizeof(DDSURFACEDESC);
    hr = m_pFrontBuffer->GetSurfaceDesc(&m_SurfaceDesc);
    if (FAILED(hr)) {
        ReleaseSurfaces();
        return hr;
    }

    UpdateSurfaceFormat();

    // If we are going to a low resolution display mode and we have got here
    // then we are going to decode direct to the back buffer and flip it. If
    // we cannot do that then we might be able to decode to an offscreen and
    // stretch that to the back buffer to subsequently flip. This is useful
    // for small videos where stretching upto larger display modes looks bad

    return UpdateDrawPalette(m_pMediaType);
}


// When we complete a connection we decide which surface to use depending on
// the source filter capabilities. We use 640x480x16 surfaces as they offer
// better quality than palettised formats, unforunately without creating the
// surface we have no way to know what kind of surface it is (RGB555/RGB565)
// So what we do is when we ask the source if it can supply a format we ask
// it first of all in RGB565 format and it it agrees then we also ask it in
// RGB555 format. This means that whatever the surface turns out to be when
// we actually allocate it during activation we know the source can supply it

HRESULT CModexAllocator::QuerySurfaceFormat(CMediaType *pmt)
{
    NOTE("Entering QuerySurfaceFormat");

    // Will the source filter provide this format

    HRESULT hr = QueryAcceptOnPeer(&m_SurfaceFormat);
    if (hr != NOERROR) {
        NOTE("Query failed");
        return hr;
    }

    // We only catch the RGB565 formats

    if (*pmt->Subtype() == MEDIASUBTYPE_RGB8) {
        NOTE("Format is RGB8");
        return NOERROR;
    }

    NOTE("Trying RGB555 format");
    CMediaType TrueColour(*pmt);

    // Change the bit fields to be RGB555 compatible

    VIDEOINFO *pVideoInfo = (VIDEOINFO *) TrueColour.Format();
    TrueColour.SetSubtype(&MEDIASUBTYPE_RGB555);
    pVideoInfo->dwBitMasks[0] = bits555[0];
    pVideoInfo->dwBitMasks[1] = bits555[1];
    pVideoInfo->dwBitMasks[2] = bits555[2];

    return QueryAcceptOnPeer(&TrueColour);
}


// Make sure we keep the pixel aspect ratio when filling the display. We do
// this by scaling the vertical and horizontal dimensions of the video into
// the surface size. Whichever vertice needs scaling most becomes the scale
// factor - both axis are then adjusted accordingly. Depending on the video
// this can leave black stripes at the display top/bottom or the left/right
// We return the total number of pixels that will be displayed if accepted

LONG CModexAllocator::ScaleToSurface(VIDEOINFO *pInputInfo,
                                     RECT *pTargetRect,
                                     LONG SurfaceWidth,
                                     LONG SurfaceHeight)
{
    BITMAPINFOHEADER *pInputHeader = HEADER(pInputInfo);
    NOTE("Entering ScaleToSurface");
    LONG Width = pInputHeader->biWidth;
    LONG Height = pInputHeader->biHeight;
	double dPixelAspectRatio, dResolutionRatio;
	
	// The only assumption being made here is that the movie was authored for
	// a display aspect ratio of 4:3 (this a display of 4:3 can be assumed to have
	// square pixels).
	// Our aim is to find the new ResolutionRatio
	// since the ResultionRatio * PixelAspectRatio = PictureAspectRatio (a constant)
	// Thus 4/3 * 1 = newPixelAspectRatio * SurfaceWidth/SurfaceHeight
	// the variables dPixelAspectRatio and dResolutionRatio pertain to the current
	// display mode. Note the whole reason of doing this is modes like 640/400, where
	// the pixel-aspect-ratio becomes different from 4:3
	dPixelAspectRatio = (4.0/3.0)  / ( ((double)SurfaceWidth) / ((double)SurfaceHeight) );

	dResolutionRatio = ( ((double)Width) / ((double)Height) ) / (dPixelAspectRatio);

	// So now we just have to find two numbers, x and y such that
	// x <= SurfaceWidth && y <= SurfaceHeight &&  (x / y = dResolutionRatio) &&
	// (x == SurfaceHeight || y == SurfaceWidth)

    NOTE2("Screen size (%dx%d)",SurfaceWidth,SurfaceHeight);
    NOTE2("Video size (%dx%d)",Width,Height);
    NOTE1("Pixel aspect ratio scale (x1000) (%d)",LONG(dPixelAspectRatio*1000));

    // This calculates the ideal destination video position
    LONG ScaledWidth = min(SurfaceWidth,LONG((double(SurfaceHeight) * dResolutionRatio)));
    LONG ScaledHeight = min(SurfaceHeight,LONG((double(SurfaceWidth) / dResolutionRatio)));

    // Set the ideal scaled dimensions in the destination
    pTargetRect->left = (SurfaceWidth - ScaledWidth) / 2;
    pTargetRect->top = (SurfaceHeight - ScaledHeight) / 2;
    pTargetRect->right = pTargetRect->left + ScaledWidth;
    pTargetRect->bottom = pTargetRect->top + ScaledHeight;

    NOTE4("Scaled video (left %d top %d right %d bottom %d)",
            pTargetRect->left, pTargetRect->top,
              pTargetRect->right, pTargetRect->bottom);

    return (ScaledWidth * ScaledHeight);
}


// It's unlikely that the video source will match the new display dimensions
// we will be using exactly. Therefore we ask the source filter to size the
// video appropriately. If it cannot and if the source is smaller than the
// display we position it in the middle, if it's larger then we clip an equal
// amount off either end (ie the left and right and/or the top and bottom) so
// that the picture is still centred as best we can. If the source still does
// not accept the format then it cannot supply any type compatible with Modex

HRESULT CModexAllocator::AgreeDirectDrawFormat(LONG Mode)
{
    NOTE("Entering AgreeDirectDrawFormat");
    LONG Width, Height, Depth;
    LONG Stride = m_pModexVideo->GetStride(Mode);
    m_pModexVideo->GetModeInfo(Mode,&Width,&Height,&Depth);

    // We need the input and output VIDEOINFO descriptors

    VIDEOINFO *pInputInfo = (VIDEOINFO *) m_pRenderer->m_mtIn.Format();
    VIDEOINFO *pOutputInfo = (VIDEOINFO *) m_SurfaceFormat.Format();
    BITMAPINFOHEADER *pInputHeader = HEADER(pInputInfo);
    BITMAPINFOHEADER *pOutputHeader = HEADER(pOutputInfo);
    LONG Pixels = ScaleToSurface(pInputInfo,&m_ScaledTarget,Width,Height);

    // To start with we will use all the available video
    pOutputInfo->rcSource.left = pOutputInfo->rcSource.top = 0;
    pOutputInfo->rcSource.right = pInputHeader->biWidth;
    pOutputInfo->rcSource.bottom = pInputHeader->biHeight;
    pOutputInfo->rcTarget = m_ScaledTarget;

    // Will the source filter provide this format

    HRESULT hr = QuerySurfaceFormat(&m_SurfaceFormat);
    if (hr == NOERROR) {
        NOTE("Source can stretch");
        return NOERROR;
    }

    // The source and target rectangles are calculated differently depending
    // on whether the video width and height are smaller or larger than the
    // primary surface (remember we know the source filter can't stretch to
    // fit the surface exactly so we will clip the video). The formula for
    // working out the source and destination video rectangles is defined by
    // the following calculations. They also make sure the left coordinates
    // are always positioned on DWORD boundaries to maximise our performance

    if (pInputHeader->biWidth <= Width) {
        pOutputInfo->rcSource.right = pInputHeader->biWidth;
        pOutputInfo->rcSource.left = 0;
        LONG ExcessSurface = Width - pInputHeader->biWidth;
        pOutputInfo->rcTarget.left = (ExcessSurface / 2) & ~ 3;
        pOutputInfo->rcTarget.right = pOutputInfo->rcTarget.left;
        pOutputInfo->rcTarget.right += pInputHeader->biWidth;
    }

    // Is the video width smaller or larger than the surface

    if (pInputHeader->biWidth > Width) {
        pOutputInfo->rcTarget.right = Width;
        pOutputInfo->rcTarget.left = 0;
        LONG ExcessVideo = pInputHeader->biWidth - Width;
        pOutputInfo->rcSource.left = (ExcessVideo / 2) & ~3;
        pOutputInfo->rcSource.right = pOutputInfo->rcSource.left;
        pOutputInfo->rcSource.right += Width;
    }

    // Is the video height smaller or larger than the surface. BEWARE because
    // all DirectDraw surfaces are top down (not bottom up like DIBs) we keep
    // the output height as a negative value. Therefore whenever we use it in
    // these calculations we must make sure we use an absolute positive value

    if (pInputHeader->biHeight <= (-pOutputHeader->biHeight)) {
        pOutputInfo->rcSource.top = 0;
        pOutputInfo->rcSource.bottom = pInputHeader->biHeight;
        LONG ExcessSurface = (-pOutputHeader->biHeight) - pInputHeader->biHeight;
        pOutputInfo->rcTarget.top = ExcessSurface / 2;
        pOutputInfo->rcTarget.bottom = pOutputInfo->rcTarget.top;
        pOutputInfo->rcTarget.bottom += pInputHeader->biHeight;
    }

    // Is the video width smaller or larger than the surface

    if (pInputHeader->biHeight > (-pOutputHeader->biHeight)) {
        pOutputInfo->rcTarget.top = 0;
        pOutputInfo->rcTarget.bottom = (-pOutputHeader->biHeight);
        LONG ExcessVideo = pInputHeader->biHeight - (-pOutputHeader->biHeight);
        pOutputInfo->rcSource.top = ExcessVideo / 2;
        pOutputInfo->rcSource.bottom = pOutputInfo->rcSource.top;
        pOutputInfo->rcSource.bottom += (-pOutputHeader->biHeight);
    }

    // Check we are not losing more than the allowed clip loss

    LONG InputSize = pInputHeader->biWidth * pInputHeader->biHeight;
    LONG OutputSize = WIDTH(&pOutputInfo->rcSource) * HEIGHT(&pOutputInfo->rcSource);
    LONG ClippedVideo = 100 - (OutputSize * 100 / InputSize);
    LONG ClipLoss = m_pModexVideo->GetClipLoss();
    LONG TargetSize = WIDTH(&pOutputInfo->rcTarget) * HEIGHT(&pOutputInfo->rcTarget);
    LONG LostTarget = 100 - ((TargetSize * 100) / Pixels);

    NOTE("Checking display mode for allowed clipping");
    NOTE1("Original input image size %d",InputSize);
    NOTE1("Clipped output source size %d",OutputSize);
    NOTE1("Current clip loss factor %d",ClipLoss);
    NOTE1("Percentage of video lost to clipping %d",ClippedVideo);
    NOTE1("Total pixels displayed if stretched %d",Pixels);
    NOTE1("Pixels used from clipped destination %d",TargetSize);
    NOTE1("Difference from stretched video %d",LostTarget);

    // Inspect the percentage of total image we are losing

    if ( (ClippedVideo <= ClipLoss) &&
         (LostTarget <= ClipLoss)) {
        hr = QuerySurfaceFormat(&m_SurfaceFormat);
        if (hr == NOERROR) {
            NOTE("Source can clip");
            return NOERROR;
        }
    }
	else {
		return VFW_E_NO_ACCEPTABLE_TYPES;
	}

    // Update the surface format with an approximate stride


    LONG ScreenWidth = GetSystemMetrics( SM_CXSCREEN );
    pOutputHeader->biWidth = ScreenWidth;
    pOutputHeader->biHeight = -pInputHeader->biHeight;
    SetSurfaceSize(pOutputInfo);

	// ok the source cannot clip, so lets clip using ddraw
	// This sets up the scaled source and destination
	m_ScaledSource = pOutputInfo->rcSource;
	m_ScaledTarget = pOutputInfo->rcTarget;

    // Initialise the source and destination rectangles

    pOutputInfo->rcSource.left = 0; pOutputInfo->rcSource.top = 0;
    pOutputInfo->rcSource.right = pInputHeader->biWidth;
    pOutputInfo->rcSource.bottom = pInputHeader->biHeight;
    pOutputInfo->rcTarget.left = 0; pOutputInfo->rcTarget.top = 0;
    pOutputInfo->rcTarget.right = pInputHeader->biWidth;
    pOutputInfo->rcTarget.bottom = pInputHeader->biHeight;



    // Will the source filter provide this format

    hr = QuerySurfaceFormat(&m_SurfaceFormat);
    if (hr == NOERROR) {
        NOTE("Offscreen ok");
        return VFW_S_RESERVED;
    }
    return VFW_E_NO_ACCEPTABLE_TYPES;
}


// Check this media type is acceptable to our input pin. All we do is to call
// QueryAccept on the source's output pin. To get this far we have locked the
// object so there should be no way for our pin to have become disconnected

HRESULT CModexAllocator::QueryAcceptOnPeer(CMediaType *pMediaType)
{
    NOTE("Entering QueryAcceptOnPeer");

    DisplayType(TEXT("Proposing output type"),pMediaType);
    IPin *pPin = m_pRenderer->m_ModexInputPin.GetPeerPin();
    ASSERT(m_pRenderer->m_ModexInputPin.IsConnected() == TRUE);
    return pPin->QueryAccept(pMediaType);
}


// If this is a normal uncompressed DIB format then set the size of the image
// as usual with the DIBSIZE macro. Otherwise the DIB specification says that
// the width of the image will be set in the width as a count of bytes so we
// just multiply that by the absolute height to get the total number of bytes
// This trickery is all handled by a utility function in the SDK base classes

void CModexAllocator::SetSurfaceSize(VIDEOINFO *pVideoInfo)
{
    NOTE("Entering SetSurfaceSize");

    BITMAPINFOHEADER *pHeader = HEADER(pVideoInfo);
    pVideoInfo->bmiHeader.biSizeImage = GetBitmapSize(pHeader);
    m_cbSurfaceSize = pVideoInfo->bmiHeader.biSizeImage;

    NOTE("Setting surface size based on video");
    NOTE1("  Width %d",pHeader->biWidth);
    NOTE1("  Height %d",pHeader->biHeight);
    NOTE1("  Depth %d",pHeader->biBitCount);
    NOTE1("  Size %d",pHeader->biSizeImage);
}


// Initialise our output type based on the DirectDraw surface. As DirectDraw
// only deals with top down display devices so we must convert the height of
// the surface into a negative height. This is because DIBs use a positive
// height to indicate a bottom up image. We must also initialise the other
// VIDEOINFO fields to represent a normal video format. Because we know the
// surface formats we will be using we can call this with the target sizes
// to initialise an output format, that can then be used to check the source
// filter will provide the format before we change display modes. This helps
// to prevent doing a lot of unnecessary display changes as we reject modes

HRESULT CModexAllocator::InitDirectDrawFormat(int Mode)
{
    VIDEOINFO *pVideoInfo = (VIDEOINFO *) m_SurfaceFormat.Format();
    NOTE("Entering InitDirectDrawFormat");
    LONG Width, Height, Depth;
    BOOL b565;
    LONG Stride = m_pModexVideo->GetStride(Mode);

    m_pModexVideo->GetModeInfoThatWorks(Mode,&Width,&Height,&Depth,&b565);

    pVideoInfo->bmiHeader.biSize          = sizeof(BITMAPINFOHEADER);
    pVideoInfo->bmiHeader.biWidth         = Stride / (Depth / 8);
    pVideoInfo->bmiHeader.biHeight        = -Height;
    pVideoInfo->bmiHeader.biPlanes        = 1;
    pVideoInfo->bmiHeader.biBitCount      = (WORD) Depth;
    pVideoInfo->bmiHeader.biCompression   = BI_RGB;
    pVideoInfo->bmiHeader.biXPelsPerMeter = 0;
    pVideoInfo->bmiHeader.biYPelsPerMeter = 0;
    pVideoInfo->bmiHeader.biClrUsed       = 0;
    pVideoInfo->bmiHeader.biClrImportant  = 0;

    SetSurfaceSize(pVideoInfo);

    // Complete the VIDEOINFO structure

    SetRectEmpty(&pVideoInfo->rcSource);
    SetRectEmpty(&pVideoInfo->rcTarget);
    pVideoInfo->dwBitRate = 0;
    pVideoInfo->dwBitErrorRate = 0;
    pVideoInfo->AvgTimePerFrame = 0;

    // must set up destination rectangle if stride != width
    if (pVideoInfo->bmiHeader.biWidth != Width) {
	pVideoInfo->rcTarget.right = Width;
	pVideoInfo->rcTarget.bottom = Height;
    }

    // And finish it off with the other media type fields

    m_SurfaceFormat.SetSampleSize(pVideoInfo->bmiHeader.biSizeImage);
    m_SurfaceFormat.SetType(&MEDIATYPE_Video);
    m_SurfaceFormat.SetSubtype(&MEDIASUBTYPE_RGB8);
    m_SurfaceFormat.SetFormatType(&FORMAT_VideoInfo);
    m_SurfaceFormat.SetTemporalCompression(FALSE);

    // For true colour 565 format tell the source there are bit fields

    if (pVideoInfo->bmiHeader.biBitCount == 16) {
	if (b565 == TRUE) {
            m_SurfaceFormat.SetSubtype(&MEDIASUBTYPE_RGB565);
            pVideoInfo->bmiHeader.biCompression = BI_BITFIELDS;
            pVideoInfo->dwBitMasks[0] = bits565[0];
            pVideoInfo->dwBitMasks[1] = bits565[1];
            pVideoInfo->dwBitMasks[2] = bits565[2];
	} else {
            m_SurfaceFormat.SetSubtype(&MEDIASUBTYPE_RGB555);
	}
    }

    // Is this a palettised format

    if (PALETTISED(pVideoInfo) == FALSE) {
        return NOERROR;
    }

    // Copy the palette entries into the surface format

    VIDEOINFO *pInput = (VIDEOINFO *) m_pRenderer->m_mtIn.Format();
    ASSERT(pInput->bmiHeader.biClrUsed);
    LONG Bytes = pInput->bmiHeader.biClrUsed * sizeof(RGBQUAD);
    CopyMemory(pVideoInfo->bmiColors,pInput->bmiColors,Bytes);
    pVideoInfo->bmiHeader.biClrUsed = pInput->bmiHeader.biClrUsed;

    return NOERROR;
}


// Overlay the image time stamps on the picture. Access to this method is
// serialised by the caller (who should also lock the object). We display
// the sample start and end times on the video using TextOut on an HDC we
// get from the DirectDraw surface (which must be released before ending)
// We put the times in the middle of the picture so that each successive
// image that is decompressed will overwrite the previous time otherwise
// we can be displaying the times on top of each other in the clipped area

HRESULT CModexAllocator::DisplaySampleTimes(IMediaSample *pSample)
{
    NOTE("Entering DisplaySampleTimes");

    TCHAR szTimes[TIMELENGTH];      // Format the time stamps
    CRefTime StartSample;           // Start time for sample
    CRefTime EndSample;             // And likewise it's end
    HDC hdcSurface;                 // Used for drawing
    SIZE Size;                      // Size of text output

    // Get a device context for the drawing surface
    LPDIRECTDRAWSURFACE pSurface = GetDirectDrawSurface();

    // This allows us to draw on top of the video
    if (pSurface->GetDC(&hdcSurface) != DD_OK) {
        return E_FAIL;
    }

    // Format the sample time stamps

    pSample->GetTime((REFERENCE_TIME *) &StartSample,
                     (REFERENCE_TIME *) &EndSample);

    wsprintf(szTimes,TEXT("%08d : %08d"),
             StartSample.Millisecs(),
             EndSample.Millisecs());

    ASSERT(lstrlen(szTimes) < TIMELENGTH);
    SetBkMode(hdcSurface,TRANSPARENT);
    SetTextColor(hdcSurface,RGB(255,255,255));

    // Put the times in the middle of the video picture

    GetTextExtentPoint32(hdcSurface,szTimes,lstrlen(szTimes),&Size);
    INT xPos = (m_SurfaceDesc.dwWidth - Size.cx) / 2;
    INT yPos = (m_SurfaceDesc.dwHeight - Size.cy) / 2;
    TextOut(hdcSurface,xPos,yPos,szTimes,lstrlen(szTimes));
    return pSurface->ReleaseDC(hdcSurface);
}


// When using a hardware offscreen draw surface we will normally wait for the
// monitor scan line to move past the destination rectangle before drawing so
// that we avoid tearing where possible. Of course not all display cards can
// support this feature and even those that do will see a performance drop of
// about 10% because we sit polling (oh for a generic PCI monitor interrupt)

void CModexAllocator::WaitForScanLine()
{
    ASSERT(m_pFrontBuffer);
    ASSERT(m_pDrawSurface);
    HRESULT hr = NOERROR;
    DWORD dwScanLine;

    // Some display cards like the ATI Mach64 support reporting of the scan
    // line they are processing. However not all drivers are setting the
    // DDCAPS_READSCANLINE capability flag so we just go ahead and ask for
    // it anyway. We allow for 10 scan lines above the top of our rectangle
    // so that we have a little time to thunk down and set the draw call up

    #define SCANLINEFUDGE 10
    while (TRUE) {

    	hr = m_pDirectDraw->GetScanLine(&dwScanLine);
        if (FAILED(hr)) {
            NOTE("No scan line");
            break;
        }

        NOTE1("Scan line returned %lx",dwScanLine);

    	if ((LONG) dwScanLine + SCANLINEFUDGE >= 0) {
            if ((LONG) dwScanLine <= m_ModeHeight) {
                NOTE("Scan inside");
                continue;
            }
        }
        break;
    }
}


// Lots more similar code to the normal video renderer, this time we are used
// when drawing offscreen surfaces. In which case we must make sure the pixel
// aspect ratio is maintained. To do this we stretch the video horizontally
// and vertically as appropriate. This might leave the target rectangle badly
// aligned so we shrink the source and target rectangles in to match alignment

BOOL CModexAllocator::AlignRectangles(RECT *pSource,RECT *pTarget)
{
    NOTE("Entering AlignRectangles");

    DWORD SourceLost = 0;           // Pixels to shift source left by
    DWORD TargetLost = 0;           // Likewise for the destination
    DWORD SourceWidthLost = 0;      // Chop pixels off the width
    DWORD TargetWidthLost = 0;      // And also for the destination

    BOOL bMatch = (WIDTH(pSource) == WIDTH(pTarget) ? TRUE : FALSE);

    // Shift the source rectangle to align it appropriately

    if (m_DirectCaps.dwAlignBoundarySrc) {
        SourceLost = pSource->left % m_DirectCaps.dwAlignBoundarySrc;
        if (SourceLost) {
            SourceLost = m_DirectCaps.dwAlignBoundarySrc - SourceLost;
            if ((DWORD)WIDTH(pSource) > SourceLost) {
                NOTE1("Source left %d",SourceLost);
                pSource->left += SourceLost;
            }
        }
    }

    // Shift the destination rectangle to align it appropriately

    if (m_DirectCaps.dwAlignBoundaryDest) {
        TargetLost = pTarget->left % m_DirectCaps.dwAlignBoundaryDest;
        if (TargetLost) {
            TargetLost = m_DirectCaps.dwAlignBoundaryDest - TargetLost;
            if ((DWORD)WIDTH(pTarget) > TargetLost) {
                NOTE1("Target left %d",TargetLost);
                pTarget->left += TargetLost;
            }
        }
    }

    // We may have to shrink the source rectangle size to align it

    if (m_DirectCaps.dwAlignSizeSrc) {
        SourceWidthLost = WIDTH(pSource) % m_DirectCaps.dwAlignSizeSrc;
        if (SourceWidthLost) {
            if ((DWORD)WIDTH(pSource) > SourceWidthLost) {
                pSource->right -= SourceWidthLost;
                NOTE1("Source width %d",SourceWidthLost);
            }
        }
    }

    // We may have to shrink the target rectangle size to align it

    if (m_DirectCaps.dwAlignSizeDest) {
        TargetWidthLost = WIDTH(pTarget) % m_DirectCaps.dwAlignSizeDest;
        if (TargetWidthLost) {
            if ((DWORD)WIDTH(pTarget) > TargetWidthLost) {
                pTarget->right -= TargetWidthLost;
                NOTE1("Target width %d",TargetWidthLost);
            }
        }
    }

    // If the source and destination originally differed then we're done

    if (bMatch == FALSE) {
        NOTE("No match");
        return TRUE;
    }

    // If the source and destination were originally the same size and they
    // now differ then we try to make them match. If the source is larger
    // than the destination then we shrink it down but only if the source
    // rectangle width we end up with is still aligned correctly otherwise
    // we won't have got anywhere (we do the same in the opposite case)

    LONG Difference = WIDTH(pSource) - WIDTH(pTarget);
    if (Difference == 0) {
        NOTE("No difference");
        return TRUE;
    }

    // Is the destination bigger than the source or vica versa

    if (Difference < 0) {
        RECT AdjustTarget = *pTarget;
        AdjustTarget.right += Difference; // NOTE Difference < 0
        if (WIDTH(&AdjustTarget) > 0) {
            if ((m_DirectCaps.dwAlignSizeDest == 0) ||
                (WIDTH(&AdjustTarget) % m_DirectCaps.dwAlignSizeDest) == 0) {
                    pTarget->right = AdjustTarget.right;
                    TargetWidthLost -= Difference; // NOTE Difference < 0
            }
        }
    } else {
        RECT AdjustSource = *pSource;
        AdjustSource.right -= Difference; // NOTE Difference > 0
        if (WIDTH(&AdjustSource) > 0) {
            if ((m_DirectCaps.dwAlignSizeDest == 0) ||
                (WIDTH(&AdjustSource) % m_DirectCaps.dwAlignSizeDest) == 0) {
                    pSource->right = AdjustSource.right;
                    SourceWidthLost += Difference; // NOTE Difference > 0
            }
        }
    }

    NOTE1("Alignment difference %d",Difference);
    NOTE1("  Source left %d",SourceLost);
    NOTE1("  Source width %d",SourceWidthLost);
    NOTE1("  Target left %d",TargetLost);
    NOTE1("  Target width %d",TargetWidthLost);

    return TRUE;
}


// Ask DirectDraw to blt the surface to the screen. We will try and wait for
// the scan line to move out of the way as in fullscreen mode we have a very
// good chance of tearing otherwise. We start off by using all of the source
// and destination but shrink the right hand side down so that it is aligned
// according to the hardware restrictions (so that the blt won't ever fail)

HRESULT CModexAllocator::DrawSurface(LPDIRECTDRAWSURFACE pBuffer)
{
    VIDEOINFO *pVideoInfo = (VIDEOINFO *) m_SurfaceFormat.Format();
    LPDIRECTDRAWSURFACE pSurface = (pBuffer ? pBuffer : m_pFrontBuffer);
    NOTE1("Entering DrawSurface (Back buffer %x)",pBuffer);

    ASSERT(m_pDirectDraw);
    ASSERT(m_pFrontBuffer);
    ASSERT(m_pDrawSurface);
    WaitForScanLine();

    // Draw the offscreen surface and wait for it to complete

    HRESULT hr = pSurface->Blt(&m_ScaledTarget,  // Target rectangle
                               m_pDrawSurface,   // Source surface
                               &m_ScaledSource,  // Source rectangle
                               DDBLT_WAIT,       // Wait to complete
                               NULL);            // No effects flags

    NOTE1("Blt returned %lx",hr);
    NOTERC("Source",m_ScaledSource);
    NOTERC("Target",m_ScaledTarget);

    return (pBuffer ? S_OK : VFW_S_NO_MORE_ITEMS);
}


// Called to actually draw the sample. We use the hardware blter to prepare
// the back buffer with the upto date contents when it is locked so now we
// flip it to the primary display. When we issue the flip we do not require
// it to complete so we don't wait for it (we don't send a DDFLIP_WAIT flag)
// We don't restore surfaces in here as that tends to activate the window if
// it's minimised, so we leave the restore for when we get a WM_ACTIVATEAPP
// although we still do the flip so that hopefully the buffers are arranged

HRESULT CModexAllocator::DoRenderSample(IMediaSample *pMediaSample)
{
    NOTE("Entering DoRenderSample");
    CAutoLock cVideoLock(this);
    CVideoSample *pVideoSample;

    // Have we already flipped this surface

    pVideoSample = (CVideoSample *) pMediaSample;
    if (pVideoSample->GetDrawStatus() == FALSE) {
        NOTE("Flipped");
        return TRUE;
    }

    pVideoSample->SetDrawStatus(FALSE);

    // Have we switched to normal DIBSECTION samples

    if (m_bModexSamples == FALSE) {
        NOTE("Not Modex sample");
        return NOERROR;
    }

    // has the window been minimised

    HWND hwnd = m_pModexWindow->GetWindowHWND();
    if (IsIconic(hwnd) || m_bModeChanged == FALSE) {
        NOTE("Mode not changed");
        m_bIsFrontStale = TRUE;
        return NOERROR;
    }

    #ifdef DEBUG
    DisplaySampleTimes(pMediaSample);
    #endif

    // Are we stretching an offscreen surface

    if (m_bOffScreen == TRUE) {
        HRESULT hr = DrawSurface(m_pBackBuffer);
        if (hr == VFW_S_NO_MORE_ITEMS) {
            return NOERROR;
        }
    }

    ASSERT(m_pDirectDraw);
    ASSERT(m_pFrontBuffer);
    ASSERT(m_pBackBuffer);

    // Flip the back buffer to the visible primary

    HRESULT hr = DDERR_WASSTILLDRAWING;
    while (hr == DDERR_WASSTILLDRAWING) {
        hr = m_pFrontBuffer->Flip(NULL,(DWORD) 0);
        if (hr == DDERR_WASSTILLDRAWING) {
            if (m_bTripleBuffered == FALSE) break;
            Sleep(DDGFS_FLIP_TIMEOUT);
        }
    }
    return NOERROR;
}


// Release any DirectDraw flipping primary surfaces we are currently holding
// we may be called at any time especially when something goes badly wrong
// and we need to clean up before returning, so we can't guarantee that
// our state is consistent so free only those that we have really allocated
// NOTE DirectDraw has a feature with flipping surfaces, GetAttachedSurface
// returns a DirectDraw surface interface that isn't AddRef'd, hence when we
// destroy all the surfaces we reset the interface instead of releasing it

void CModexAllocator::ReleaseSurfaces()
{
    NOTE("Entering ReleaseSurfaces");
    CAutoLock cVideoLock(this);
    m_pBackBuffer = NULL;
    m_bIsFrontStale = TRUE;
    m_bTripleBuffered = FALSE;

    // Release the DirectDraw flipping surfaces

    if (m_pFrontBuffer) {
        m_pFrontBuffer->Release();
        m_pFrontBuffer = NULL;
    }

    // Release any single backbuffer surface

    if (m_pDrawSurface) {
        m_pDrawSurface->Release();
        m_pDrawSurface = NULL;
    }

    // Free any palette object we made

    if (m_pDrawPalette) {
        m_pDrawPalette->Release();
        m_pDrawPalette = NULL;
    }
}


// Called to release any DirectDraw instance we have

void CModexAllocator::ReleaseDirectDraw()
{
    NOTE("Entering ReleaseDirectDraw");
    CAutoLock cVideoLock(this);
    ReleaseSurfaces();

    // Release any DirectDraw provider interface

    if (m_pDirectDraw) {
        m_pDirectDraw->Release();
        m_pDirectDraw = NULL;
    }
    m_LoadDirectDraw.ReleaseDirectDraw();
}


// The fullscreen renderer relies on some bug fixes in DirectDraw 2.0 so we
// will only allow connections if we detect that library. In DirectDraw 2.0
// we may also have multiple objects per process so we can load DirectDraw
// as we're created and unload when destroyed. This also lets us know which
// display modes the DirectDraw can support and which it can't - we should
// always be able to get hold of 320x240x8 and 640x480x8 regardless of card

HRESULT CModexAllocator::LoadDirectDraw()
{
    NOTE("Entering LoadDirectDraw");
    ASSERT(m_pDirectDraw == NULL);
    ASSERT(m_pFrontBuffer == NULL);
    HRESULT hr = NOERROR;

    // We rely on some DirectDraw 2 features

    if (m_fDirectDrawVersion1) {
        NOTE("Version incorrect");
        return E_UNEXPECTED;
    }

    // Ask the loader to create an instance

    // !!! BROKEN on multiple monitors
    hr = m_LoadDirectDraw.LoadDirectDraw(NULL);
    if (FAILED(hr)) {
        NOTE("No DirectDraw");
        return hr;
    }

    // Get the IDirectDraw instance

    m_pDirectDraw = m_LoadDirectDraw.GetDirectDraw();
    if (m_pDirectDraw == NULL) {
        NOTE("No instance");
        return E_FAIL;
    }

    // Initialise our capabilities structures
    m_DirectCaps.dwSize = sizeof(DDCAPS);
    m_DirectSoftCaps.dwSize = sizeof(DDCAPS);

    // Load the hardware and emulation capabilities

    hr = m_pDirectDraw->GetCaps(&m_DirectCaps,&m_DirectSoftCaps);
    if (FAILED(hr)) {
        ReleaseDirectDraw();
        return hr;
    }

    // Load the available display modes

    hr = m_pModexVideo->SetDirectDraw(m_pDirectDraw);
    if (FAILED(hr)) {
        ReleaseDirectDraw();
        return VFW_E_NO_MODEX_AVAILABLE;
    }
    return NOERROR;
}


// When we decode to use a true colour mode we need to know whether or not we
// will get the buffers in display memory or not. To know that without doing
// the actual surface allocation we guess using the available display memory
// The total video memory available from DirectDraw does not include the mode
// we are currently in so when we change mode we will hopefully release some
// more memory, so going from 1024x768x8 to 640x480x16 gives us 172,032 bytes

BOOL CModexAllocator::CheckTotalMemory(int Mode)
{
    NOTE1("Checking memory (mode %d)",Mode);
    DDSURFACEDESC SurfaceDesc;
    SurfaceDesc.dwSize = sizeof(DDSURFACEDESC);
    LONG Width, Height, Depth;

    // Find the display mode dimensions

    m_pDirectDraw->GetDisplayMode(&SurfaceDesc);
    m_pModexVideo->GetModeInfo(Mode,&Width,&Height,&Depth);
    DWORD RequiredMemory = Width * Height * Depth / 8;

    // Calculate the total theoretical display memory

    DWORD TotalMemory = (SurfaceDesc.ddpfPixelFormat.dwRGBBitCount / 8) *
                            SurfaceDesc.dwWidth * SurfaceDesc.dwHeight +
                                m_DirectCaps.dwVidMemTotal;

    return (RequiredMemory > TotalMemory ? FALSE : TRUE);
}


// Initialises the display dimensions to be those of the mode we'll use. We
// use eight bit palettised and sixteen bit true colour depending what the
// source filter and display capabilities are. We would prefer to use 16 bit
// surfaces as they offer better quality but there may be insufficient VRAM
// We try to check the condition of whether when we change mode we'll be able
// to get the surfaces in VRAM or not. If there looks to be too little VRAM
// available then we use the palettised mode. We always try to use the Modex
// low resolution modes (which can be either 8/16 bits) ahead of the others

HRESULT CModexAllocator::InitTargetMode(int Mode)
{
    NOTE("Entering InitTargetMode");
    DDSURFACEDESC SurfaceDesc;
    SurfaceDesc.dwSize = sizeof(DDSURFACEDESC);
    HRESULT hr = NOERROR;

    // Check this surface is available and enabled

    if (m_pModexVideo->IsModeAvailable(Mode) == S_FALSE ||
            m_pModexVideo->IsModeEnabled(Mode) == S_FALSE ||
                CheckTotalMemory(Mode) == FALSE) {
                    NOTE("Not acceptable");
                    return E_INVALIDARG;
                }

    // Next create a format for this surface

    hr = InitDirectDrawFormat(Mode);
    if (FAILED(hr)) {
        return hr;
    }

    // We have initialised a media type that represents the display mode to
    // use. We must now setup the source and target video rectangles, we do
    // this separately because in any given mode we have a choice of whether
    // to stretch (or compress) the video into the display dimensions or to
    // clip (or blank out) the border depending on the relative video size

    hr = AgreeDirectDrawFormat(Mode);
    if (FAILED(hr)) {
        return hr;
    }

    // Are we going to stretch offscreen
    m_bOffScreen = FALSE;
    if (hr == VFW_S_RESERVED)
        m_bOffScreen = TRUE;

    m_pModexVideo->GetModeInfo(Mode,&m_ModeWidth,&m_ModeHeight,&m_ModeDepth);

    NOTE("Agreed display mode...");
    NOTE1("Width %d",m_ModeWidth);
    NOTE1("Height %d",m_ModeHeight);
    NOTE1("Depth %d",m_ModeDepth);

    m_pModexVideo->SetMode(Mode);
    return NOERROR;
}


// We initialise an output format for the display modes we provide and check
// the source filter can supply a type of video that can be drawn with. If
// the source filter is not DirectDraw enabled or doesn't have the necessary
// capabilities then we do not complete the connection. This means that an
// application knows during connection whether it can connect a filter to a
// Modex renderer or if a colour space convertor needs to be put in between

HRESULT CModexAllocator::NegotiateSurfaceFormat()
{
    NOTE("Entering NegotiateSurfaceFormat");
    CAutoLock cVideoLock(this);
    ASSERT(m_bModeChanged == FALSE);
    long DisplayModes;

    // Did we manage to load DirectDraw

    if (m_pDirectDraw == NULL) {
        NOTE("No instance");
        return E_FAIL;
    }

    // Initialise the fullscreen object

    m_pModexVideo->SetDirectDraw(m_pDirectDraw);
    m_pModexVideo->CountModes(&DisplayModes);
    ASSERT(!m_fDirectDrawVersion1);

	// Compute the order in which the modes are to be tried
    m_pModexVideo->OrderModes();

	// if no valid modes, then return failure
	if (m_pModexVideo->m_dwNumValidModes == 0)
		return E_FAIL;

    // See if we can find a surface to use

    for (DWORD Loop = 0;Loop < m_pModexVideo->m_dwNumValidModes; Loop++) {
		DWORD dwMode = m_pModexVideo->m_ModesOrder[Loop];
        HRESULT hr = InitTargetMode(dwMode);
        if (hr == NOERROR) {
            return NOERROR;
        }
    }
    return E_FAIL;
}




// this function is used to call SetFocusWindow(hwnd) on every filter supporting
// IAMDirectSound in the graph. The reason is if in the same process, if
// SetCooperativeLevel is level on DiurectSound and DirectDraw(requesting exclusive
// mode) then the two hwnds have to be the same.
void CModexAllocator::DistributeSetFocusWindow(HWND hwnd)
{
	// We want to get a pointer to IFilterGraph, so get the Filter_Info structure
	FILTER_INFO Filter_Info;
	IFilterGraph *pFilterGraph = NULL;
	IEnumFilters *pEnumFilters = NULL;
	IAMDirectSound *pAMDS = NULL;
	IBaseFilter *pFilter = NULL;
	ULONG lFilters_Fetched = 0;
	HRESULT hr = NOERROR;

	// get the FilterInfo structure from the renderer
	hr = m_pFilter->QueryFilterInfo(&Filter_Info);
	if (FAILED(hr))
	{
		DbgLog((LOG_ERROR,0,TEXT("m_pFilter->QueryFilterInfo failed")));
		goto CleanUp;
	}

	// ge the pointer to IFilterGraph
	pFilterGraph = Filter_Info.pGraph;
	ASSERT(pFilterGraph);

	// get the pointer to IEnumFilters
	hr = pFilterGraph->EnumFilters(&pEnumFilters);
    if(FAILED(hr))
    {
		DbgLog((LOG_TRACE, 0, TEXT("QueryInterface  for IID_IEnumFilters failed.")));
		goto CleanUp;
    }

	pEnumFilters->Reset();
	do
	{	
		lFilters_Fetched = 0;
		hr = pEnumFilters->Next(1, &pFilter, &lFilters_Fetched);
	
		if (FAILED(hr) || (lFilters_Fetched != 1))
			break;

		ASSERT(pFilter);

		// call SetFocusWindow on every filter supporting IAMDirectSound
		hr = pFilter->QueryInterface(IID_IAMDirectSound, (void**)&pAMDS);
		if(SUCCEEDED(hr) && pAMDS)
		{
			pAMDS->SetFocusWindow(hwnd, TRUE);
		}

		if (pAMDS)
		{
			pAMDS->Release();
			pAMDS = NULL;
		}

		if (pFilter)
		{
			pFilter->Release();
			pFilter = NULL;
		}
	}
	while (1);

CleanUp:
	if (pFilter)
	{
		pFilter->Release();
		pFilter = NULL;
	}

	if (pEnumFilters)
	{
		pEnumFilters->Release();
		pEnumFilters = NULL;
	}

	if (pFilterGraph)
	{
		pFilterGraph->Release();
		pFilterGraph = NULL;
	}

}

// Used to create the surfaces from DirectDraw. We only use primary flipping
// surfaces (triple/double in video RAM and also system memory). We also set
// the display mode according to the display variables we initialised during
// the CompleteConnect call. We don't need to initialise an output format as
// we also did that when we worked out which display mode to use, since the
// mode we use is also dependant on the formats the source filter can supply

HRESULT CModexAllocator::Active()
{
    // Show the window before locking up

    NOTE("Activating allocator");
    HWND hwnd = m_pModexWindow->GetWindowHWND();

    // Match the display size to the window

    MoveWindow(hwnd,(int) 0,(int) 0,
               GetSystemMetrics(SM_CXSCREEN),
               GetSystemMetrics(SM_CYSCREEN),
               (BOOL) FALSE);
    ShowWindow(hwnd,SW_SHOWNORMAL);
    SetForegroundWindow(hwnd);
    UpdateWindow(hwnd);
    CAutoLock cVideoLock(this);

    // Make us the fullscreen exclusive application

    HRESULT hr = m_pDirectDraw->SetCooperativeLevel(hwnd,DDSCL_EXCLUSIVE |
                                                         DDSCL_FULLSCREEN |
                                                         DDSCL_ALLOWREBOOT |
                                                         DDSCL_ALLOWMODEX);
    NOTE2("SetCooperativeLevel EXCLUSIVE %x returned %lx", hwnd, hr);
#if 0
    if (hr == DDERR_HWNDALREADYSET)
        hr = S_OK;
    NOTE2("SetCooperativeLevel %x returned %lx", hwnd, hr);
#endif
    if (FAILED(hr)) {
        return hr;
    }

    // Enumerate the modes again
    NegotiateSurfaceFormat();

    // Change the display mode as we just agreed

    hr = m_pDirectDraw->SetDisplayMode(m_ModeWidth,m_ModeHeight,m_ModeDepth);
    NOTE1("SetDisplayMode returned %lx", hr);
    if (FAILED(hr)) {
        return hr;
    }

    NOTE("Changed display modes");
    m_bModeChanged = TRUE;
    NOTE("Creating surfaces");

    // Create the primary flipping surfaces

    hr = CreateSurfaces();
    if (FAILED(hr)) {
        return hr;
    }
    return BlankDisplay();
}


// Reset the back buffer and blank the display

HRESULT CModexAllocator::BlankDisplay()
{
    LPDIRECTDRAWSURFACE pSurface = GetDirectDrawSurface();
    if (pSurface == NULL) return NOERROR;
    NOTE("Entering BlankDisplay");
    ResetBackBuffer(pSurface);

    // Draw or flip the blank backbuffer

    if (m_pBackBuffer == NULL) return DrawSurface(NULL);
    if (m_pDrawSurface) ResetBackBuffer(m_pBackBuffer);
    HRESULT hr = m_pFrontBuffer->Flip(NULL,DDFLIP_WAIT);
    NOTE1("Flip to blank display returned %lx",hr);

    ResetBackBuffer(m_pBackBuffer);
    while (m_pFrontBuffer->GetFlipStatus(DDGFS_ISFLIPDONE) ==
        DDERR_WASSTILLDRAWING) {
            NOTE("Waiting for flip to complete");
    }
    return NOERROR;
}


// Called when we receive WM_ACTIVATEAPP messages. If we have a surface and it
// is lost (the user probably tabbed away from the window using ALT-TAB) then
// we restore the video memory for it. Calling restore on a lost surface has
// much the same affect as recreating the surfaces but is much more efficient

HRESULT CModexAllocator::OnActivate(BOOL bActive)
{
    // Don't lock allocator if being hidden

    if (bActive == FALSE) {
        NOTE("Deactivated");
        return NOERROR;
    }

    NOTE("Entering OnActivate");
    CAutoLock cVideoLock(this);
    ASSERT(bActive == TRUE);

    // Is the mode changing

    if (m_bModeChanged == FALSE) {
        NOTE("Deactivating");
        return NOERROR;
    }

    // Restore the front buffer

    if (m_pFrontBuffer) {
        if (m_pFrontBuffer->IsLost() != DD_OK) {
            NOTE("Restoring surface");
            m_pFrontBuffer->Restore();
        }
    }

    // Do we have a stretching offscreen

    if (m_pDrawSurface) {
        if (m_pDrawSurface->IsLost() != DD_OK) {
            NOTE("Restoring offscreen");
            m_pDrawSurface->Restore();
        }
    }
    return BlankDisplay();
}


// Restore the display mode and GDI surface. Most times the user will stop us
// by hitting ALT-TAB back to the main application and pressing Stop. When we
// get in here to be deactivated it does mean that the window could be in a
// minimised state and the surface will have been restored. In that case we
// do not short circuit DirectDraw and leave it to sort the display mode out

HRESULT CModexAllocator::Inactive()
{
    HWND hwnd = m_pModexWindow->GetWindowHWND();

    // It is dangerous to leave ourselves locked when we restore the display
    // mode because that along with the ShowWindow(SW_HIDE) can cause a host
    // of messages to be sent to us. Amongst these is WM_ACTIVATEAPP which
    // causes a callback to this allocator. Therefore we unlock before doing
    // the restore and hide - and use m_bModeChanged to make us thread safe
    {
        NOTE("Entering Inactive");
        CAutoLock cVideoLock(this);

        // Have we got anything to undo

        if (m_bModeChanged == FALSE) {
            NOTE("No mode to restore");
            ShowWindow(hwnd,SW_HIDE);
            return NOERROR;
        }

        ASSERT(m_pDirectDraw);
        m_bModeChanged = FALSE;
        NOTE("Restoring display mode");
    }

    // Restore the palette before changing display modes

    if (m_pFrontBuffer) {
        HRESULT hr = BlankDisplay();
        hr = m_pFrontBuffer->SetPalette(NULL);
        if (hr == DDERR_SURFACELOST) {
            m_pFrontBuffer->Restore();
            m_pFrontBuffer->SetPalette(NULL);
        }
    }

    // Switch back to the normal display

    m_pDirectDraw->RestoreDisplayMode();
    m_pDirectDraw->FlipToGDISurface();
    ShowWindow(hwnd,SW_HIDE);
    NOTE("Restored GDI display mode");

    // Restore the exclusive level for this window
    HRESULT hr = m_pDirectDraw->SetCooperativeLevel(hwnd,DDSCL_NORMAL);
    NOTE2("SetCooperativeLevel NORMAL %x returned %lx", hwnd, hr);

    ReleaseSurfaces();

    return NOERROR;
}
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\multimedia\dshow\filters\image\modex\fullscr.cpp ===
// Copyright (c) 1994 - 1998  Microsoft Corporation.  All Rights Reserved.
// Implements a fullscreen interface, Anthony Phillips, March 1996

#include <streams.h>
#include <windowsx.h>
#include <string.h>
#include <limits.h>
#include <vidprop.h>
#include <modex.h>
#include <viddbg.h>

// The IFullScreenVideo interface allows an application to control a full
// screen renderer. The Modex renderer supports this interface. When we
// are connected we load the display modes DirectDraw has made available
// The number of modes available can be obtained through CountModes. Then
// information on each individual mode is available by calling GetModeInfo
// and IsModeAvailable. An application may enable and disable any modes
// by calling the SetEnabled flag with OATRUE or OAFALSE (not C/C++ TRUE
// and FALSE values) - the current value may be queried by IsModeEnabled

// A more generic way of setting the modes enabled that is easier to use
// when writing applications is the clip loss factor. This defines the
// amount of video that can be lost when deciding which display mode to
// use. Assuming the decoder cannot compress the video then playing an
// MPEG file (say 352x288) into a 320x200 display will lose over 40% of
// the image. The clip loss factor specifies the upper range permissible.
// To allow typical MPEG video to be played in 320x200 it defaults to 50%

// These are the display modes that we support. New modes can just be added
// in the right place and should work straight away. When selecting the mode
// to use we start at the top and work our way down. Not only must the mode
// be available but the amount of video lost by clipping if it is to be used
// (assuming the filter can't compress the video) must not exceed the clip
// lost factor. The display modes enabled (which may not be available) and
// the clip loss factor can all be changed by the IFullScreenVideo interface

struct {

    LONG Width;            // Width of the display mode
    LONG Height;           // Likewise the mode height
    LONG Depth;            // Number of bits per pixel
    BOOL b565;             // For 16 bit modes, is this 565 or 555?

} aModes[MAXMODES] = {
    { 320,  200,  16 },
    { 320,  200,  8  },
    { 320,  240,  16 },
    { 320,  240,  8  },
    { 640,  400,  16 },
    { 640,  400,  8  },
    { 640,  480,  16 },
    { 640,  480,  8  },
    { 800,  600,  16 },
    { 800,  600,  8  },
    { 1024, 768,  16 },
    { 1024, 768,  8  },
    { 1152, 864,  16 },
    { 1152, 864,  8  },
    { 1280, 1024, 16 },
    { 1280, 1024, 8  }
};

double myfabs(double x)
{
    if (x >= 0)
        return x;
    else
        return -x;
}

// Constructor

CModexVideo::CModexVideo(CModexRenderer *pRenderer,
                         TCHAR *pName,
                         HRESULT *phr) :

    CUnknown(pName,pRenderer->GetOwner()),
    m_ClipFactor(CLIPFACTOR),
    m_pRenderer(pRenderer),
    m_pDirectDraw(NULL),
    m_ModesAvailable(0),
    m_ModesEnabled(0),
    m_CurrentMode(0),
    m_hwndDrain(NULL),
    m_Monitor(MONITOR),
    m_bHideOnDeactivate(FALSE)
{
    ASSERT(pRenderer);
    ASSERT(phr);
    InitialiseModes();
}


// Destructor

CModexVideo::~CModexVideo()
{
    ASSERT(m_pDirectDraw == NULL);
}


// This is a private helper method to install us with the DirectDraw driver
// we should be using. All our methods except GetCurrentMode may be called
// when we're not connected. Calling GetCurrentMode when not connected will
// return VFW_E_NOT_CONNECTED. We use this to enumerate the display modes
// available of the current display card. We do not AddRef nor release the
// interface as the lifetime of the interface is controlled by the filter

HRESULT CModexVideo::SetDirectDraw(IDirectDraw *pDirectDraw)
{
    NOTE("Entering SetDirectDraw");
    CAutoLock Lock(this);
    m_pDirectDraw = pDirectDraw;
    m_ModesAvailable = 0;
    m_CurrentMode = 0;

    // Are we being reset

    if (m_pDirectDraw == NULL) {
        NOTE("No driver");
        return NOERROR;
    }

    // Enumerate all the available display modes

    m_pDirectDraw->EnumDisplayModes((DWORD) 0,        // Surface count
                                    NULL,             // No template
                                    (PVOID) this,     // Allocator object
                                    ModeCallBack);    // Callback method


    // WARNING: Platform Specific hacks here: The modex mode 320x240x8 is available on every
    // video card on win95 platform. However the modex modes are only available on NT5.0 on higher.
    if ((g_osInfo.dwPlatformId == VER_PLATFORM_WIN32_WINDOWS) ||
	((g_osInfo.dwPlatformId == VER_PLATFORM_WIN32_NT) && (g_osInfo.dwMajorVersion >= 5)))
	m_bAvailable[3] = TRUE;

    // Check there is at least one mode available

    if (m_ModesAvailable == 0) {
        NOTE("No Modes are available");
        return VFW_E_NO_MODEX_AVAILABLE;
    }
    return NOERROR;
}


// Called once for each display mode available. We are interested in scanning
// the list of available display modes so that during connection we can find
// out if the source filter will be able to supply us with a suitable format
// If none of the modes we support are available (see the list at the top)
// then we return VFW_E_NO_MODEX_AVAILABLE from CompleteConnect. If one of
// them is available but the source can't provide the type then we return a
// different error code (E_FAIL) so that a colour convertor is put inbetween

HRESULT CALLBACK ModeCallBack(LPDDSURFACEDESC pSurfaceDesc,LPVOID lParam)
{
    CModexVideo *pVideo = (CModexVideo *) lParam;
    NOTE("Entering ModeCallBack");
    TCHAR FormatString[128];

    wsprintf(FormatString,TEXT("%dx%dx%d (%d bytes)"),
             pSurfaceDesc->dwWidth,
             pSurfaceDesc->dwHeight,
             pSurfaceDesc->ddpfPixelFormat.dwRGBBitCount,
             pSurfaceDesc->lPitch);

    DbgLog((LOG_TRACE,5,FormatString));

    // Yet more platform specific hacks - On Windows/NT 4 the stride is not
    // calculated correctly based on the bit depth but just returns a pixel
    // stride. We can try and detect this if the surface width matches the
    // stride and the bit count is greater than eight. The stride should be
    // greater than the surface width in all cases except if its palettised

    LONG lStride = pSurfaceDesc->lPitch;
    if (pSurfaceDesc->ddpfPixelFormat.dwRGBBitCount > 8) {
        if (lStride == LONG(pSurfaceDesc->dwWidth)) {
            LONG lBytes = pSurfaceDesc->ddpfPixelFormat.dwRGBBitCount / 8;
            lStride = pSurfaceDesc->dwWidth * lBytes;
        }
    }

    // Scan the supported list looking for a match

    for (int Loop = 0;Loop < MAXMODES;Loop++) {
        if (pSurfaceDesc->ddpfPixelFormat.dwRGBBitCount == (DWORD) aModes[Loop].Depth) {
            if (pSurfaceDesc->dwWidth == (DWORD) aModes[Loop].Width) {
                if (pSurfaceDesc->dwHeight == (DWORD) aModes[Loop].Height) {
                    NOTE("Surface is supported");
                    pVideo->m_bAvailable[Loop] = TRUE;
                    pVideo->m_ModesAvailable++;
                    pVideo->m_Stride[Loop] = lStride;
		    // Is it a 555 or 565 mode?
		    // !!! Some buggy ddraw drivers may give 0 for bitmasks,
		    // and I'm assuming that means 555... if there's a buggy
		    // driver that means 565, I'm doing the wrong thing, but
		    // every DDraw app will probably be broken
		    if (aModes[Loop].Depth == 16 &&
				pSurfaceDesc->ddpfPixelFormat.dwRBitMask ==
				0x0000f800) {
			aModes[Loop].b565 = TRUE;
		    } else {
			aModes[Loop].b565 = FALSE;
		    }
                }
            }
        }
    }
    return S_FALSE;     // Return NOERROR to stop enumerating
}


// Reset the display modes enabled and available

void CModexVideo::InitialiseModes()
{
    NOTE("Entering InitialiseModes");
    m_ModesEnabled = MAXMODES;
    for (int Loop = 0;Loop < MAXMODES;Loop++) {
        m_bAvailable[Loop] = FALSE;
        m_bEnabled[Loop] = TRUE;
        m_Stride[Loop] = 0;
    }
    LoadDefaults();
}


// Increment the owning object reference count

STDMETHODIMP_(ULONG) CModexVideo::NonDelegatingAddRef()
{
    NOTE("ModexVideo NonDelegatingAddRef");
    return m_pRenderer->AddRef();
}


// Decrement the owning object reference count

STDMETHODIMP_(ULONG) CModexVideo::NonDelegatingRelease()
{
    NOTE("ModexVideo NonDelegatingRelease");
    return m_pRenderer->Release();
}


// Expose the IModexVideo interface we implement

STDMETHODIMP CModexVideo::NonDelegatingQueryInterface(REFIID riid,VOID **ppv)
{
    NOTE("ModexVideo NonDelegatingQueryInterface");

    // We return the IFullScreenVideo interfaces

    if (riid == IID_IFullScreenVideo) {
        NOTE("Returning IFullScreenVideo interface");
        return GetInterface((IFullScreenVideo *)this,ppv);
    } else if (riid == IID_IFullScreenVideoEx) {
        NOTE("Returning IFullScreenVideoEx interface");
        return GetInterface((IFullScreenVideoEx *)this,ppv);
    }
    return m_pRenderer->QueryInterface(riid,ppv);
}


// Return the number of modes we support

STDMETHODIMP CModexVideo::CountModes(long *pModes)
{
    NOTE("Entering CountModes");
    CheckPointer(pModes,E_POINTER);
    CAutoLock Lock(this);
    *pModes = MAXMODES;
    return NOERROR;
}


// Return the width, height and depth for the given mode index. The modes are
// indexed starting at zero. We have a table containing the available display
// modes whose size is MAXMODES (saves us dynamically allocating the arrays)
// If we get as far as returning the dimensions then we check to see if the
// mode is going to be useable (must be available and enabled) and if so we
// return NOERROR. Otherwise we return S_FALSE which might save further calls
// by the application to IsEnabled/IsAvailable to determine this information

STDMETHODIMP CModexVideo::GetModeInfo(long Mode,long *pWidth,long *pHeight,long *pDepth)
{
    NOTE("Entering GetModeInfo");
    CheckPointer(pWidth,E_POINTER);
    CheckPointer(pHeight,E_POINTER);
    CheckPointer(pDepth,E_POINTER);
    CAutoLock Lock(this);

    // Check the mode is in our range

    if (Mode < 0 || Mode >= MAXMODES) {
        NOTE("Invalid mode");
        return E_INVALIDARG;
    }

    // Load the display dimensions

    *pWidth = aModes[Mode].Width;
    *pHeight = aModes[Mode].Height;
    *pDepth = aModes[Mode].Depth;

    return (m_bAvailable[Mode] || m_bEnabled[Mode] ? NOERROR : S_FALSE);
}

// and now the version that works... and tells you if a 16 bit mode is 565

STDMETHODIMP CModexVideo::GetModeInfoThatWorks(long Mode,long *pWidth,long *pHeight,long *pDepth, BOOL *pb565)
{
    NOTE("Entering GetModeInfoThatWorks");
    CheckPointer(pWidth,E_POINTER);
    CheckPointer(pHeight,E_POINTER);
    CheckPointer(pDepth,E_POINTER);
    CheckPointer(pb565,E_POINTER);
    CAutoLock Lock(this);

    // Check the mode is in our range

    if (Mode < 0 || Mode >= MAXMODES) {
        NOTE("Invalid mode");
        return E_INVALIDARG;
    }

    // Load the display dimensions

    *pWidth = aModes[Mode].Width;
    *pHeight = aModes[Mode].Height;
    *pDepth = aModes[Mode].Depth;
    *pb565 = aModes[Mode].b565;

    return (m_bAvailable[Mode] || m_bEnabled[Mode] ? NOERROR : S_FALSE);
}


// Return the mode the allocator is going to use

STDMETHODIMP CModexVideo::GetCurrentMode(long *pMode)
{
    NOTE("Entering GetCurrentMode");
    CheckPointer(m_pDirectDraw,VFW_E_NOT_CONNECTED);
    CheckPointer(pMode,E_POINTER);
    CAutoLock Lock(this);

    *pMode = m_CurrentMode;
    return NOERROR;
}


// Returns NOERROR (S_OK) if the mode supplied is available

STDMETHODIMP CModexVideo::IsModeAvailable(long Mode)
{
    NOTE("Entering IsModeAvailable");
    CAutoLock Lock(this);

    // Check the mode is in our range

    if (Mode < 0 || Mode >= MAXMODES) {
        NOTE("Invalid mode");
        return E_INVALIDARG;
    }
    return (m_bAvailable[Mode] ? NOERROR : S_FALSE);
}


// Returns NOERROR (S_OK) if the mode suppiled is enabled

STDMETHODIMP CModexVideo::IsModeEnabled(long Mode)
{
    NOTE("Entering IsModeEnabled");
    CAutoLock Lock(this);

    // Check the mode is in our range

    if (Mode < 0 || Mode >= MAXMODES) {
        NOTE("Invalid mode");
        return E_INVALIDARG;
    }
    return (m_bEnabled[Mode] ? NOERROR : S_FALSE);
}


// Disables the given mode used when selecting the surface

STDMETHODIMP CModexVideo::SetEnabled(long Mode,long bEnabled)
{
    NOTE("Entering SetEnabled");
    CAutoLock Lock(this);

    // Check the mode is in our range

    if (Mode < 0 || Mode >= MAXMODES) {
        NOTE("Invalid mode");
        return E_INVALIDARG;
    }

    // Check the flag passed in is valid

    if (bEnabled != OATRUE) {
        if (bEnabled != OAFALSE) {
            NOTE("Invalid enabled");
            return E_INVALIDARG;
        }
    }
    m_bEnabled[Mode] = (bEnabled == OATRUE ? TRUE : FALSE);
    return NOERROR;
}


// Return the amount of video permissible to clip off

STDMETHODIMP CModexVideo::GetClipFactor(long *pClipFactor)
{
    NOTE("Entering GetClipFactor");
    CheckPointer(pClipFactor,E_POINTER);
    CAutoLock Lock(this);

    *pClipFactor = m_ClipFactor;
    return NOERROR;
}


// Set the amount of video permissible to clip off

STDMETHODIMP CModexVideo::SetClipFactor(long ClipFactor)
{
    NOTE("Entering SetClipFactor");
    CAutoLock Lock(this);

    // Check the value is a percentage

    if (ClipFactor < 0 || ClipFactor > 100) {
        NOTE("Invalid clip factor");
        return E_INVALIDARG;
    }
    m_ClipFactor = ClipFactor;
    return NOERROR;
}


// Set the target window for posting on our messages

STDMETHODIMP CModexVideo::SetMessageDrain(HWND hwnd)
{
    NOTE("Entering SetMessageDrain");
    CAutoLock Lock(this);
    m_hwndDrain = (HWND) hwnd;
    return NOERROR;
}


// Return the current window message sink

STDMETHODIMP CModexVideo::GetMessageDrain(HWND *hwnd)
{
    NOTE("Entering GetMessageDrain");
    CheckPointer(hwnd,E_POINTER);
    CAutoLock Lock(this);
    *hwnd = m_hwndDrain;
    return NOERROR;
}


// Set the default monitor to play fullscreen on

STDMETHODIMP CModexVideo::SetMonitor(long Monitor)
{
    NOTE("Entering SetMonitor");
    CAutoLock Lock(this);

    // Check the monitor passed in is valid

    if (Monitor != 0) {
        NOTE("Invalid monitor");
        return E_INVALIDARG;
    }
    return NOERROR;
}


// Return whether we will we hide the window when iconic

STDMETHODIMP CModexVideo::GetMonitor(long *Monitor)
{
    NOTE("Entering GetMonitor");
    CheckPointer(Monitor,E_POINTER);
    *Monitor = m_Monitor;
    return NOERROR;
}


// Store the enabled settings in WIN.INI for simplicity

STDMETHODIMP CModexVideo::SetDefault()
{
    NOTE("Entering SetDefault");
    CAutoLock Lock(this);
    TCHAR Profile[PROFILESTR];
    TCHAR KeyName[PROFILESTR];

    // Save the current clip loss factor

    wsprintf(Profile,TEXT("%d"),m_ClipFactor);
    NOTE1("Saving clip factor %d",m_ClipFactor);
    WriteProfileString(TEXT("Quartz"),TEXT("ClipFactor"),Profile);

    // Save a key for each of our supported display modes

    for (int Loop = 0;Loop < MAXMODES;Loop++) {
        wsprintf(KeyName,TEXT("%dx%dx%d"),aModes[Loop].Width,aModes[Loop].Height,aModes[Loop].Depth);
        wsprintf(Profile,TEXT("%d"),m_bEnabled[Loop]);
        NOTE2("Saving mode setting %s (enabled %d)",KeyName,m_bEnabled[Loop]);
        WriteProfileString(TEXT("Quartz"),KeyName,Profile);
    }
    return NOERROR;
}


// Load the enabled modes and the clip factor. Neither the window caption nor
// the hide when iconic flag are stored as persistent properties. They appear
// in the property sheet partly as a test application but also for the user
// to fiddle with. Therefore the application has ultimate control over these
// when using the Modex renderer or can let the user adjust them. The plug in
// distributor uses these properties so that it can switch back into a window

HRESULT CModexVideo::LoadDefaults()
{
    NOTE("Entering LoadDefaults");
    CAutoLock Lock(this);
    TCHAR KeyName[PROFILESTR];
    m_ModesEnabled = 0;

    // Load the permissible clip loss factor

    m_ClipFactor = GetProfileInt(TEXT("Quartz"),TEXT("ClipFactor"),CLIPFACTOR);
    NOTE1("Clip factor %d",m_ClipFactor);

    // Load the key for each of our supported display modes

    for (int Loop = 0;Loop < MAXMODES;Loop++) {
        wsprintf(KeyName,TEXT("%dx%dx%d"),aModes[Loop].Width,aModes[Loop].Height,aModes[Loop].Depth);
        m_bEnabled[Loop] = GetProfileInt(TEXT("Quartz"),KeyName,TRUE);
        NOTE2("Loaded setting for mode %s (enabled %d)",KeyName,m_bEnabled[Loop]);
        if (m_bEnabled[Loop] == TRUE) { m_ModesEnabled++; }
    }

    return NOERROR;
}


// Should the window be hidden when deactivated

STDMETHODIMP CModexVideo::HideOnDeactivate(long Hide)
{
    NOTE("Entering HideOnDeactivate");
    CAutoLock Lock(this);

    // Check this is a valid automation boolean type

    if (Hide != OATRUE) {
        if (Hide != OAFALSE) {
            return E_INVALIDARG;
        }
    }
    m_bHideOnDeactivate = (Hide == OATRUE ? TRUE : FALSE);
    return NOERROR;
}


// Will we hide the window when deactivated

STDMETHODIMP CModexVideo::IsHideOnDeactivate()
{
    NOTE("Entering IsHideOnDeactivate");
    CAutoLock Lock(this);
    return (m_bHideOnDeactivate ? S_OK : S_FALSE);
}


#include <atlconv.h>
// Change the title of the Modex window

STDMETHODIMP CModexVideo::SetCaption(BSTR strCaption)
{
    NOTE("Entering SetCaption");
    CheckPointer(strCaption,E_POINTER);
    CAutoLock Lock(this);
    HWND hwnd = m_pRenderer->m_ModexWindow.GetWindowHWND();

    USES_CONVERSION;
    SetWindowText(hwnd,W2T(strCaption));
    return NOERROR;
}


// Get the title of the Modex window

STDMETHODIMP CModexVideo::GetCaption(BSTR *pstrCaption)
{
    NOTE("Entering GetCaption");
    CheckPointer(pstrCaption,E_POINTER);
    CAutoLock Lock(this);

    TCHAR Caption[CAPTION];

    // Convert the ASCII caption to a UNICODE string

    HWND hwnd = m_pRenderer->m_ModexWindow.GetWindowHWND();
    GetWindowText(hwnd,Caption,CAPTION);
    USES_CONVERSION;
    *pstrCaption = T2BSTR(Caption);
    return *pstrCaption ? S_OK : E_OUTOFMEMORY;
}


// Return the stride for any given display mode

LONG CModexVideo::GetStride(long Mode)
{
    NOTE("Entering GetStride");
    CAutoLock Lock(this);

    // Check the mode is in our range

    if (Mode < 0 || Mode >= MAXMODES) {
        NOTE("Invalid mode");
        return LONG(0);
    }
    return m_Stride[Mode];
}

// this functions computes the order in which are to be tried. The criteria
// it uses are the following (in order) :
// 1) First since stretched video looks better than shrunk video, so modes in which
// both dimensions are getting stretched are given preferrence over ones in which
// dimension is getting stretched which are preferred over ones in which both
// dimensions are getting shrunk. Note that this criterion is really only relavant
// when the decoder is doing the stretching. Otherwise we always clip.
// 2) Second criterion is the amount by which we will have to scale/clip. Lesser this
// amount, the better it is.
// 3) Third, we prefer higher depth(16 bit) modes over lower depth (8 bit) ones.
void CModexVideo::OrderModes()
{
    double dEpsilon = 0.001;
    DWORD dwNativeWidth, dwNativeHeight;
    DWORD dwMode, dwMode1, dwMode2;
    VIDEOINFO *pVideoInfo = NULL;
    int i, j;
    BOOL bSorted;

    struct
    {
        DWORD dwStretchGrade;
        double dScaleAmount;
        DWORD dwDepth;
    } ModeProperties[MAXMODES];

    pVideoInfo = (VIDEOINFO *) m_pRenderer->m_mtIn.Format();

    dwNativeWidth = pVideoInfo->bmiHeader.biWidth;
    dwNativeHeight = pVideoInfo->bmiHeader.biHeight;

    // initialize the array to an invalid value
    for (i = 0, j = 0; i < MAXMODES; i++)
    {
        m_ModesOrder[i] = MAXMODES;
    }

    // take out the modes which are not available or not allowed
    for (i = 0, j = 0; i < MAXMODES; i++)
    {
        if (m_bAvailable[i] && m_bEnabled[i])
        {
            m_ModesOrder[j] = i;
            ASSERT(i >= 0 && i < MAXMODES);
            j++;
        }
    }
    m_dwNumValidModes = j;
    ASSERT(m_dwNumValidModes <= MAXMODES);


    if (m_dwNumValidModes == 0)
        return;

    // Now calculate the mode properties for the valid modes
    for (i = 0; i < MAXMODES; i++)
    {
        RECT rcTarget;
        DWORD dwTargetWidth, dwTargetHeight;

        // get the target rect which will maintain the aspect ratio
        m_pRenderer->m_ModexAllocator.ScaleToSurface(pVideoInfo, &rcTarget,
            aModes[i].Width, aModes[i].Height);

        dwTargetWidth = rcTarget.right - rcTarget.left;
        dwTargetHeight = rcTarget.bottom - rcTarget.top;

        // we assign points for stretching of width and heigth. Makes it easy to
        // change this rule later on
        ModeProperties[i].dwStretchGrade =
            ((dwTargetWidth  >= dwNativeWidth ) ? 1 : 0) +
            ((dwTargetHeight >= dwNativeHeight) ? 1 : 0);

        // calculate the factor by which we need to stretch/shrink and then make this
        // value relative to zero
        ModeProperties[i].dScaleAmount = (double) (dwTargetWidth * dwTargetHeight);
        ModeProperties[i].dScaleAmount /= (double) (dwNativeWidth * dwNativeHeight);
        ModeProperties[i].dScaleAmount = myfabs(ModeProperties[i].dScaleAmount - 1);

        ModeProperties[i].dwDepth = aModes[i].Depth;
    }



    // Now sort the modes such that the modes in which we have to stretch
    // are preferred than the ones in which we have to shrink.
    do
    {
        bSorted = TRUE;
        for (i = 0; i < (int)m_dwNumValidModes-1; i++)
        {
            dwMode1 = m_ModesOrder[i];
            dwMode2 = m_ModesOrder[i+1];

            ASSERT(dwMode1 < MAXMODES);
            ASSERT(dwMode2 < MAXMODES);

            // if the second is better than the first then swap
            if (ModeProperties[dwMode2].dwStretchGrade > ModeProperties[dwMode1].dwStretchGrade)
            {
                m_ModesOrder[i] = dwMode2;
                m_ModesOrder[i+1] = dwMode1;
                bSorted = FALSE;
            }
        }
    }
    while(!bSorted);

    // Now if the above criterion is the same then sort such that those modes which
    // have to be scaled less are preferred over those in which have to be scaled more
    do
    {
        bSorted = TRUE;
        for (i = 0; i < (int)m_dwNumValidModes-1; i++)
        {
            dwMode1 = m_ModesOrder[i];
            dwMode2 = m_ModesOrder[i+1];

            ASSERT(dwMode1 < MAXMODES);
            ASSERT(dwMode2 < MAXMODES);

            // if the second is better than the first then swap
            // since the ScaleAmount is a double, we use dEpsilon
            if ((ModeProperties[dwMode2].dwStretchGrade == ModeProperties[dwMode1].dwStretchGrade) &&
                (ModeProperties[dwMode2].dScaleAmount < ModeProperties[dwMode1].dScaleAmount-dEpsilon))
            {
                m_ModesOrder[i] = dwMode2;
                m_ModesOrder[i+1] = dwMode1;
                bSorted = FALSE;
            }
        }
    }
    while(!bSorted);

    // Now if the above criterion is the same then sort such that those modes which
    // are 16 bit are preferred over 8 bit (better quality that way).
    do
    {
        bSorted = TRUE;
        for (i = 0; i < (int)m_dwNumValidModes-1; i++)
        {
            dwMode1 = m_ModesOrder[i];
            dwMode2 = m_ModesOrder[i+1];

            ASSERT(dwMode1 < MAXMODES);
            ASSERT(dwMode2 < MAXMODES);
            // if the second is better than the first then swap
            // since the ScaleAmount is a double, two ScaleAmounts are considered
            // equal, if they are within dEpsilon.
            if ((ModeProperties[dwMode2].dwStretchGrade == ModeProperties[dwMode1].dwStretchGrade) &&
                (myfabs(ModeProperties[dwMode2].dScaleAmount - ModeProperties[dwMode1].dScaleAmount) < dEpsilon) &&
                (ModeProperties[dwMode2].dwDepth > ModeProperties[dwMode1].dwDepth))
            {
                m_ModesOrder[i] = dwMode2;
                m_ModesOrder[i+1] = dwMode1;
                bSorted = FALSE;
            }
        }
    }
    while(!bSorted);

    // generate some debug spew
    DbgLog((LOG_TRACE, 1, TEXT("Mode preferrence order ->")));
    for (i = 0; i < (int)m_dwNumValidModes; i++)
    {
        dwMode = m_ModesOrder[i];
        ASSERT(dwMode < MAXMODES);
        DbgLog((LOG_TRACE, 1, TEXT("%d Width=%d, Height=%d, Depth=%d"),
            i, aModes[dwMode].Width, aModes[dwMode].Height, aModes[dwMode].Depth));
    }

    // assert that all the other values are invalid
    for (i = m_dwNumValidModes; i < MAXMODES; i++)
    {
        ASSERT(m_ModesOrder[i] == MAXMODES);
    }

} // end of function OrderModes()

// Set the accelerator table we should dispatch messages with

STDMETHODIMP CModexVideo::SetAcceleratorTable(HWND hwnd,HACCEL hAccel)
{
    NOTE2("SetAcceleratorTable HWND %x HACCEL %x",hwnd,hAccel);
    CAutoLock Lock(this);
    m_pRenderer->m_ModexWindow.SetAcceleratorInfo(hwnd,hAccel);
    return NOERROR;
}


// Return the accelerator table we are dispatching messages with

STDMETHODIMP CModexVideo::GetAcceleratorTable(HWND *phwnd,HACCEL *phAccel)
{
    NOTE("GetAcceleratorTable");
    CheckPointer(phAccel,E_POINTER);
    CheckPointer(phwnd,E_POINTER);

    CAutoLock Lock(this);
    m_pRenderer->m_ModexWindow.GetAcceleratorInfo(phwnd,phAccel);
    return NOERROR;
}


// We always currently keep pixel aspect ratio

STDMETHODIMP CModexVideo::KeepPixelAspectRatio(long KeepAspect)
{
    NOTE1("KeepPixelAspectRatio %d",KeepAspect);
    if (KeepAspect == OAFALSE) {
        NOTE("Not supported");
        return E_NOTIMPL;
    }
    return (KeepAspect == OATRUE ? S_OK : E_INVALIDARG);
}


// We always currently keep pixel aspect ratio

STDMETHODIMP CModexVideo::IsKeepPixelAspectRatio(long *pKeepAspect)
{
    CheckPointer(pKeepAspect,E_POINTER);
    NOTE("IsKeepPixelAspectRatio");
    *pKeepAspect = OATRUE;

    return NOERROR;
}
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\multimedia\dshow\filters\image\modex\modex.h ===
// Copyright (c) 1994 - 1998  Microsoft Corporation.  All Rights Reserved.
// Implements a Modex renderer filter, Anthony Phillips, January 1996

#ifndef __MODEX__
#define __MODEX__

extern const AMOVIESETUP_FILTER sudModexFilter;

// Forward declarations

class CModexRenderer;
class CModexInputPin;
class CModexWindow;
class CModexAllocator;
class CModexVideo;

#define MODEXCLASS TEXT("ModexRenderer")
#define FULLSCREEN TEXT("FullScreen")
#define NORMAL TEXT("NORMAL")
#define ACTIVATE TEXT("ACTIVATE")
#define DDGFS_FLIP_TIMEOUT 1
#define AMSCAPS_MUST_FLIP 320

// This class implements the IFullScreenVideoEx interface that allows someone
// to query a full screen enabled video renderer for the display modes they
// support and enable or disable them on a mode by mode basis. The selection
// the make is for this particular instance only although through SetDefault
// they can be made the global default. We only currently support the use of
// the primary display monitor (monitor number 0) asking for anything else
// will return an error. When the renderer is fullscreen we can be asked to
// forward any messages we receive to another window with the message drain

class CModexVideo : public IFullScreenVideoEx, public CUnknown, public CCritSec
{
    friend class CModexAllocator;

    LPDIRECTDRAW m_pDirectDraw;           // DirectDraw service provider
    CModexRenderer *m_pRenderer;          // Main video renderer object
    DWORD m_ModesOrder[MAXMODES];		  // Order in which modes should be tried
    DWORD m_dwNumValidModes;			  // number of modes to be tried
    BOOL m_bAvailable[MAXMODES];          // Which modes are available
    BOOL m_bEnabled[MAXMODES];            // And the modes we have enabled
    LONG m_Stride[MAXMODES];              // Stride for each display mode
    DWORD m_ModesAvailable;               // Number of modes supported
    DWORD m_ModesEnabled;                 // Total number made available
    LONG m_CurrentMode;                   // Current display mode selected
    LONG m_ClipFactor;                    // Amount of video we can clip
    LONG m_Monitor;                       // Current monitor for playback
    HWND m_hwndDrain;                     // Where to send window messages
    BOOL m_bHideOnDeactivate;             // Should we hide when switched

    void InitialiseModes();

    friend HRESULT CALLBACK ModeCallBack(LPDDSURFACEDESC pSurfaceDesc,LPVOID lParam);
    friend class CModexRenderer;

public:

    // Constructor and destructor

    CModexVideo(CModexRenderer *pRenderer,
                TCHAR *pName,
                HRESULT *phr);

    ~CModexVideo();
    DECLARE_IUNKNOWN;

    // Accessor functions for IFullScreenVideo interfaces

    void SetMode(LONG Mode) { m_CurrentMode = Mode; };
    LONG GetClipLoss() { return m_ClipFactor; };
    IDirectDraw *GetDirectDraw() { return m_pDirectDraw; };
    HWND GetMessageDrain() { return m_hwndDrain; };
    BOOL HideOnDeactivate() { return m_bHideOnDeactivate; };

    // Access information about our display modes

    HRESULT SetDirectDraw(IDirectDraw *pDirectDraw);
    HRESULT LoadDefaults();
    LONG GetStride(long Mode);
    void OrderModes();

    // Manage the interface IUnknown

    STDMETHODIMP_(ULONG) NonDelegatingAddRef();
    STDMETHODIMP_(ULONG) NonDelegatingRelease();
    STDMETHODIMP NonDelegatingQueryInterface(REFIID riid,VOID **ppv);

    // These are the base IFullScreenVideo methods

    STDMETHODIMP CountModes(long *pModes);
    STDMETHODIMP GetModeInfo(long Mode,long *pWidth,long *pHeight,long *pDepth);
    STDMETHODIMP GetCurrentMode(long *pMode);
    STDMETHODIMP IsModeAvailable(long Mode);
    STDMETHODIMP IsModeEnabled(long Mode);
    STDMETHODIMP SetEnabled(long Mode,long bEnabled);
    STDMETHODIMP GetClipFactor(long *pClipFactor);
    STDMETHODIMP SetClipFactor(long ClipFactor);
    STDMETHODIMP SetMessageDrain(HWND hwnd);
    STDMETHODIMP GetMessageDrain(HWND *hwnd);
    STDMETHODIMP SetMonitor(long Monitor);
    STDMETHODIMP GetMonitor(long *Monitor);
    STDMETHODIMP HideOnDeactivate(long Hide);
    STDMETHODIMP IsHideOnDeactivate();
    STDMETHODIMP SetCaption(BSTR strCaption);
    STDMETHODIMP GetCaption(BSTR *pstrCaption);
    STDMETHODIMP SetDefault();

    // These are the extended IFullScreenVideoEx methods

    STDMETHODIMP SetAcceleratorTable(HWND hwnd,HACCEL hAccel);
    STDMETHODIMP GetAcceleratorTable(HWND *phwnd,HACCEL *phAccel);
    STDMETHODIMP KeepPixelAspectRatio(long KeepAspect);
    STDMETHODIMP IsKeepPixelAspectRatio(long *pKeepAspect);

    // And this is a GetModeInfo that tells us if a 16 bit mode is 565 or not

    STDMETHODIMP GetModeInfoThatWorks(long Mode,long *pWidth,long *pHeight,long *pDepth, BOOL *pb565);

};


// This is an allocator derived from the CImageAllocator utility class that
// allocates sample buffers in shared memory. The number and size of these
// are determined when the output pin calls Prepare on us. The shared memory
// blocks are used in subsequent calls to GDI CreateDIBSection, once that
// has been done the output pin can fill the buffers with data which will
// then be handed to GDI through BitBlt calls and thereby remove one copy

class CModexAllocator : public CImageAllocator
{
    CModexRenderer *m_pRenderer;          // Main video renderer object
    CModexVideo *m_pModexVideo;           // Handles our IFullScreenVideo
    CModexWindow *m_pModexWindow;         // DirectDraw exclusive window
    CCritSec *m_pInterfaceLock;           // Main renderer interface lock
    DDCAPS m_DirectCaps;                  // Actual hardware capabilities
    DDCAPS m_DirectSoftCaps;              // Capabilities emulated for us
    DDSURFACEDESC m_SurfaceDesc;	  // Describes the front buffer
    BOOL m_bTripleBuffered;               // Can we triple buffer flips
    DDSCAPS m_SurfaceCaps;		  // And likewise its capabilities
    LPDIRECTDRAW m_pDirectDraw;           // DirectDraw service provider
    LPDIRECTDRAWSURFACE m_pFrontBuffer;   // DirectDraw primary surface
    LPDIRECTDRAWSURFACE m_pBackBuffer;    // Back buffer flipping surface
    LPDIRECTDRAWPALETTE m_pDrawPalette;   // The palette for the surface
    LPDIRECTDRAWSURFACE m_pDrawSurface;   // Single backbuffer for stretch
    CLoadDirectDraw m_LoadDirectDraw;     // Handles loading DirectDraw
    LONG m_ModeWidth;                     // Width we will change mode to
    LONG m_ModeHeight;                    // Likewise the display height
    LONG m_ModeDepth;                     // And finally the target depth
    BOOL m_bOffScreen;                    // Are we stretching an offscreen
    SIZE m_Screen;                        // Current display mode size
    BOOL m_bModeChanged;                  // Have we changed display mode
    CMediaType m_SurfaceFormat;           // Holds current output format
    LONG m_cbSurfaceSize;                 // Accurate size of our surface
    BOOL m_bModexSamples;                 // Are we using Modex samples
    BOOL m_bIsFrontStale;                 // Are we prerolling some images
    BOOL m_fDirectDrawVersion1;           // Is this DDraw version 1?
    RECT m_ScaledTarget;                  // Scaled destination rectangle
    RECT m_ScaledSource;                  // Likewise aligned source details

public:

    // Constructor and destructor

    CModexAllocator(CModexRenderer *pRenderer,
                    CModexVideo *pModexVideo,
                    CModexWindow *pModexWindow,
                    CCritSec *pLock,
                    HRESULT *phr);

    ~CModexAllocator();

    // Help with managing DirectDraw surfaces

    HRESULT LoadDirectDraw();
    void ReleaseDirectDraw();
    void ReleaseSurfaces();
    HRESULT CreateSurfaces();
    HRESULT CreatePrimary();
    HRESULT CreateOffScreen(BOOL bCreatePrimary);

    // Initialise the surface we will be using

    void SetSurfaceSize(VIDEOINFO *pVideoInfo);
    CImageSample *CreateImageSample(LPBYTE pData,LONG Length);
    HRESULT InitDirectDrawFormat(int Mode);
    BOOL CheckTotalMemory(int Mode);
    HRESULT InitTargetMode(int Mode);
    HRESULT AgreeDirectDrawFormat(LONG Mode);
    HRESULT QueryAcceptOnPeer(CMediaType *pMediaType);
    HRESULT NegotiateSurfaceFormat();
    HRESULT QuerySurfaceFormat(CMediaType *pmt);
    BOOL GetDirectDrawStatus();

    // Make sure the pixel aspect ratio is kept

    LONG ScaleToSurface(VIDEOINFO *pInputInfo,
                        RECT *pTargetRect,
                        LONG SurfaceWidth,
                        LONG SurfaceHeight);

    // Lets the renderer know if DirectDraw is loaded

    BOOL IsDirectDrawLoaded() {
        CAutoLock cVideoLock(this);
        return (m_pDirectDraw == NULL ? FALSE : TRUE);
    };

    // Return the static format for the surface

    CMediaType *GetSurfaceFormat() {
        CAutoLock cVideoLock(this);
        return &m_SurfaceFormat;
    };

    // Install our samples with DirectDraw information

    STDMETHODIMP_(ULONG) NonDelegatingAddRef();
    STDMETHODIMP_(ULONG) NonDelegatingRelease();
    STDMETHODIMP CheckSizes(ALLOCATOR_PROPERTIES *pRequest);
    STDMETHODIMP ReleaseBuffer(IMediaSample *pMediaSample);

    STDMETHODIMP GetBuffer(IMediaSample **ppSample,
                           REFERENCE_TIME *pStartTime,
                           REFERENCE_TIME *pEndTime,
                           DWORD dwFlags);

    STDMETHODIMP SetProperties(ALLOCATOR_PROPERTIES *pRequest,
                               ALLOCATOR_PROPERTIES *pActual);

    // Used to manage samples as we are processing data

    HRESULT DoRenderSample(IMediaSample *pMediaSample);
    HRESULT DisplaySampleTimes(IMediaSample *pMediaSample);
    HRESULT DrawSurface(LPDIRECTDRAWSURFACE pBuffer);
    void WaitForScanLine();
    BOOL AlignRectangles(RECT *pSource,RECT *pTarget);
    HRESULT UpdateDrawPalette(const CMediaType *pMediaType);
    HRESULT UpdateSurfaceFormat();
    void OnReceive(IMediaSample *pMediaSample);
    HRESULT StopUsingDirectDraw(IMediaSample **ppSample);
    HRESULT StartDirectAccess(IMediaSample *pMediaSample,DWORD dwFlags);
    HRESULT ResetBackBuffer(LPDIRECTDRAWSURFACE pSurface);
    HRESULT PrepareBackBuffer(LPDIRECTDRAWSURFACE pSurface);
    LPDIRECTDRAWSURFACE GetDirectDrawSurface();

    // Called when the filter changes state

    HRESULT OnActivate(BOOL bActive);
    HRESULT BlankDisplay();
    HRESULT Active();
    HRESULT Inactive();
    HRESULT BreakConnect();

	void DistributeSetFocusWindow(HWND hwnd);
};


// Derived class for our windows. To access DirectDraw Modex we supply it
// with a window, this is granted exclusive mode access rights. DirectDraw
// hooks the window and manages a lot of the functionality associated with
// handling Modex. For example when you switch display modes it maximises
// the window, when the user hits ALT-TAB the window is minimised. When the
// user then clicks on the minimised window the Modex is likewise restored

class CModexWindow : public CBaseWindow
{
protected:

    CModexRenderer *m_pRenderer;    // Owning sample renderer object
    HACCEL m_hAccel;                // Handle to application translators
    HWND m_hwndAccel;               // Where to translate messages to

public:

    CModexWindow(CModexRenderer *pRenderer,     // Delegates locking to
                 TCHAR *pName,                  // Object description
                 HRESULT *phr);                 // OLE failure code

    // Message handling methods

    BOOL SendToDrain(PMSG pMessage);
    LRESULT RestoreWindow();
    LRESULT OnSetCursor();
    void OnPaint();

    // Set the window and accelerator table to use
    void SetAcceleratorInfo(HWND hwnd,HACCEL hAccel) {
        m_hwndAccel = hwnd;
        m_hAccel = hAccel;
    };

    // Return the window and accelerator table we're using
    void GetAcceleratorInfo(HWND *phwnd,HACCEL *phAccel) {
        *phwnd = m_hwndAccel;
        *phAccel = m_hAccel;
    };

    // Overriden to return our window and class styles
    LPTSTR GetClassWindowStyles(DWORD *pClassStyles,
                                DWORD *pWindowStyles,
                                DWORD *pWindowStylesEx);

    // Method that gets all the window messages
    LRESULT OnReceiveMessage(HWND hwnd,          // Window handle
                             UINT uMsg,          // Message ID
                             WPARAM wParam,      // First parameter
                             LPARAM lParam);     // Other parameter
};


// This class supports the renderer input pin. We have to override the base
// class input pin because we provide our own special allocator which hands
// out buffers based on DirectDraw surfaces. We have a limitation which is
// that we only connect to source filters that agree to use our allocator.
// This stops us from connecting to the tee for example. The reason being
// that the buffers we hand out don't have any emulation capabilities but
// are based solely on DirectDraw surfaces, to draw someone else's sample
// into a ModeX window would be difficult to do (in fact I don't know how)

class CModexInputPin : public CRendererInputPin
{
    CModexRenderer *m_pRenderer;        // The renderer that owns us
    CCritSec *m_pInterfaceLock;         // Main critical section lock

public:

    // Constructor

    CModexInputPin(
        CModexRenderer *pRenderer,      // The main Modex renderer
        CCritSec *pInterfaceLock,       // Main critical section
        TCHAR *pObjectName,             // Object string description
        HRESULT *phr,                   // OLE failure return code
        LPCWSTR pPinName);              // This pins identification

    // Returns the pin currently connected to us
    IPin *GetPeerPin() {
        return m_Connected;
    };

    // Manage our DirectDraw video allocator

    STDMETHODIMP GetAllocator(IMemAllocator **ppAllocator);
    STDMETHODIMP NotifyAllocator(IMemAllocator *pAllocator,BOOL bReadOnly);
    STDMETHODIMP Receive(IMediaSample *pSample);
};


// This is the COM object that represents a Modex video rendering filter. It
// supports IBaseFilter and IMediaFilter and has a single input stream (pin)
// We support interfaces through a number of nested classes which are made
// as part of the complete object and initialised during our construction.
// By deriving from CBaseVideoRenderer we get all the quality management we
// need and can override the virtual methods to control the type negotiation
// We have two windows, one that we register with DirectDraw to be the top
// most exclusive mode window and another for use when not in fullscreen mode

class CModexRenderer : public ISpecifyPropertyPages, public CBaseVideoRenderer
{
public:

    // Constructor and destructor

    static CUnknown *CreateInstance(LPUNKNOWN, HRESULT *);
    CModexRenderer(TCHAR *pName,LPUNKNOWN pUnk,HRESULT *phr);
    ~CModexRenderer();

    // Implement the ISpecifyPropertyPages interface

    DECLARE_IUNKNOWN
    STDMETHODIMP NonDelegatingQueryInterface(REFIID, void **);
    STDMETHODIMP GetPages(CAUUID *pPages);

    CBasePin *GetPin(int n);

    HRESULT SetMediaType(const CMediaType *pmt);
    HRESULT CompleteConnect(IPin *pReceivePin);
    HRESULT CheckMediaType(const CMediaType *pmtIn);
    HRESULT DoRenderSample(IMediaSample *pMediaSample);
    HRESULT CopyPalette(const CMediaType *pSrc,CMediaType *pDest);
    void OnReceiveFirstSample(IMediaSample *pMediaSample);
    HRESULT OnActivate(HWND hwnd,WPARAM wParam);
    HRESULT BreakConnect();
    HRESULT Active();
    HRESULT Inactive();
    void ResetKeyboardState();

public:

    CModexAllocator m_ModexAllocator;   // Our DirectDraw surface allocator
    CModexInputPin m_ModexInputPin;     // Implements pin based interfaces
    CImageDisplay m_Display;            // Manages the video display type
    CMediaType m_mtIn;                  // Source connection media type
    CModexWindow m_ModexWindow;         // Does the actual video rendering
    CModexVideo m_ModexVideo;           // Handles our IFullScreenVideoEx
    BOOL m_bActive;                     // Has the filter been activated
    UINT m_msgFullScreen;               // Sent to window to go fullscreen	
    UINT m_msgNormal;                   // And likewise used to deactivate
    CAMEvent m_evWaitInactive;          // Wait for this after PostMessage
                                        // for m_msgNormal
    UINT m_msgActivate;                 // Activation posted back to ourselves
};

#endif // __MODEX__
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\multimedia\dshow\filters\image\modex\modex.cpp ===
// Copyright (c) 1994 - 1999  Microsoft Corporation.  All Rights Reserved.
// Implements a Modex renderer filter, Anthony Phillips, January 1996

#include <streams.h>
#include <windowsx.h>
#include <string.h>
#include <vidprop.h>
#include <modex.h>
#include <viddbg.h>

// This is a fullscreen DirectDraw video renderer. We use Modex which is a
// facilitity provided by DirectDraw which allows an application to change
// to different display modes (we currently use 320x200x8/16, 320x240x8/16
// 640x480x8/16 and 640x400x8/16). Most VGA cards which DirectDraw runs on
// have Modex facilities available. We work like any other video renderer
// except that when we go active we switch display modes and render video
// into the different mode using DirectDraw primary flipping surfaces. If
// Modex is not available then we reject any attempts to complete connect
// and we will not let the video window be opened out of a minimised state
//
// As well as true Modex modes we also use larger display modes such as the
// 640x480x8/16 if the source can't provide a Modex type (also with primary
// flipping surfaces in fullscreen exclusive mode). These require a little
// more work on our part because we have to notice when we're switched away
// from so that we can stop using the surfaces, in Modex when we're switched
// away from we lose the surfaces (calling them returns DDERR_SURFACELOST)
//
// The main filter object inherits from the base video renderer class so that
// it gets the quality management implementation and the IQualProp property
// stuff (so that we can monitor frame rates and so on). We have a specialist
// allocator that hands out DirectDraw buffers. The allocator is build on the
// SDK CImageAllocator base class. This may seem a little strange since we
// can never draw DIB images when in Modex. We use the DIBSECTION buffer when
// the fullscreen window is switched away from so that we can continue giving
// the source filter a buffer to decompress into (the DirectDraw surface is
// no longer available after switching). When we switch back to fullscreen
// we restore the DirectDraw surfaces and switch the source filter back again

#ifdef FILTER_DLL
#include <initguid.h>
#endif

// List of class IDs and creator functions for the class factory. This
// provides the link between the OLE entry point in the DLL and an object
// being created. The class factory will call the static CreateInstance
// function when it is asked to create a CLSID_ModexRenderer COM object

#ifdef FILTER_DLL
CFactoryTemplate g_Templates[] = {
    {L"", &CLSID_ModexRenderer,      CModexRenderer::CreateInstance},
    {L"", &CLSID_QualityProperties,  CQualityProperties::CreateInstance},
    {L"", &CLSID_ModexProperties,    CModexProperties::CreateInstance}
};
int g_cTemplates = sizeof(g_Templates) / sizeof(g_Templates[0]);
STDAPI DllRegisterServer()
{
    return AMovieDllRegisterServer2( TRUE );
}

STDAPI DllUnregisterServer()
{
    return AMovieDllRegisterServer2( FALSE );
}
#endif


// This goes in the factory template table to create new filter instances

CUnknown *CModexRenderer::CreateInstance(LPUNKNOWN pUnk, HRESULT *phr)
{
    return new CModexRenderer(NAME("Modex Video Renderer"),pUnk,phr);
}


// Setup data

const AMOVIESETUP_MEDIATYPE
sudModexPinTypes =
{
    &MEDIATYPE_Video,           // Major type
    &MEDIASUBTYPE_NULL          // And subtype
};

const AMOVIESETUP_PIN
sudModexPin =
{
    L"Input",                   // Name of the pin
    TRUE,                       // Is pin rendered
    FALSE,                      // Is an Output pin
    FALSE,                      // Ok for no pins
    FALSE,                      // Can we have many
    &CLSID_NULL,                // Connects to filter
    L"Output",                  // Name of pin connect
    1,                          // Number of pin types
    &sudModexPinTypes           // Details for pins
};

const AMOVIESETUP_FILTER
sudModexFilter =
{
    &CLSID_ModexRenderer,       // CLSID of filter
    L"Full Screen Renderer",    // Filter name
    MERIT_DO_NOT_USE,           // Filter merit
    1,                          // Number pins
    &sudModexPin                // Pin details
};


// This is the constructor for the main Modex renderer filter class. We keep
// an input pin that derives from the base video renderer pin class. We also
// have a DirectDraw enabled allocator that handles the Modex interactions.
// When using Modex we also need a window that gains exclusive mode access
// so we also initialise an object derived from the SDK CBaseWindow class

#pragma warning(disable:4355)

CModexRenderer::CModexRenderer(TCHAR *pName,LPUNKNOWN pUnk,HRESULT *phr) :

    CBaseVideoRenderer(CLSID_ModexRenderer,pName,pUnk,phr),
    m_ModexInputPin(this,&m_InterfaceLock,NAME("Modex Pin"),phr,L"Input"),
    m_ModexAllocator(this,&m_ModexVideo,&m_ModexWindow,&m_InterfaceLock,phr),
    m_ModexWindow(this,NAME("Modex Window"),phr),
    m_ModexVideo(this,NAME("Modex Video"),phr),
    m_bActive(FALSE)
{
    m_msgFullScreen = RegisterWindowMessage(FULLSCREEN);
    m_msgNormal = RegisterWindowMessage(NORMAL);
    m_msgActivate = RegisterWindowMessage(ACTIVATE);
    m_ModexWindow.PrepareWindow();
    m_ModexAllocator.LoadDirectDraw();
}


// Destructor must set the input pin pointer to NULL before letting the base
// class in, this is because the base class deletes its pointer working with
// the assumption that the object was dynamically allocated. For convenience
// we statically create the input pin as part of the overall Modex renderer

CModexRenderer::~CModexRenderer()
{
    m_pInputPin = NULL;
    m_ModexVideo.SetDirectDraw(NULL);
    m_ModexWindow.DoneWithWindow();
    m_ModexAllocator.ReleaseDirectDraw();
}


// We only accept palettised video formats to start with

HRESULT CModexRenderer::CheckMediaType(const CMediaType *pmtIn)
{
    CAutoLock cInterfaceLock(&m_InterfaceLock);
    NOTE("QueryAccept on input pin");

	// since m_Display.CheckMediaType() does not let direct-draw
	// surfaces pass through, this test should be made first.

    // Does this format match the DirectDraw surface format

    if (m_ModexAllocator.IsDirectDrawLoaded() == TRUE) {
        CMediaType *pSurface = m_ModexAllocator.GetSurfaceFormat();
        if (*pmtIn->Subtype() != MEDIASUBTYPE_RGB8) {
	    if (*pmtIn == *pSurface) {
		NOTE("match found");
		return NOERROR;
	    }
	}
	else {
	    BOOL bFormatsMatch = FALSE;
	    DWORD dwCompareSize = 0;

	    bFormatsMatch = (IsEqualGUID(pmtIn->majortype, pSurface->majortype) == TRUE) &&
			    (IsEqualGUID(pmtIn->subtype, pSurface->subtype) == TRUE) &&
			    (IsEqualGUID(pmtIn->formattype, pSurface->formattype) == TRUE);

	    // in the palettized case we not want to compare palette entries. Furthermore we do not 
	    // want to compare the values of biClrUsed OR biClrImportant
	    ASSERT(pmtIn->cbFormat >= sizeof(VIDEOINFOHEADER));
	    ASSERT(pSurface->cbFormat >= sizeof(VIDEOINFOHEADER));
            dwCompareSize = FIELD_OFFSET(VIDEOINFOHEADER, bmiHeader.biClrUsed);
	    ASSERT(dwCompareSize < sizeof(VIDEOINFOHEADER));
	    bFormatsMatch = bFormatsMatch && (memcmp(pmtIn->pbFormat, pSurface->pbFormat, dwCompareSize) == 0);
	    if (bFormatsMatch) {
		return NOERROR;
	    }
	}
    }

	// Is this format eight bit palettised

    if (*pmtIn->Subtype() == MEDIASUBTYPE_RGB8) {
        return m_Display.CheckMediaType(pmtIn);
    }

    return E_INVALIDARG;
}


// We only support one input pin and it is numbered zero

CBasePin *CModexRenderer::GetPin(int n)
{
    ASSERT(n == 0);
    if (n != 0) {
        return NULL;
    }

    // Assign the input pin if not already done so

    if (m_pInputPin == NULL) {
        m_pInputPin = &m_ModexInputPin;
    }
    return m_pInputPin;
}


// Overriden to say what interfaces we support and where

STDMETHODIMP CModexRenderer::NonDelegatingQueryInterface(REFIID riid,void **ppv)
{
    if (riid == IID_ISpecifyPropertyPages) {
        return GetInterface((ISpecifyPropertyPages *)this, ppv);
    } else if (riid == IID_IFullScreenVideo) {
        return m_ModexVideo.NonDelegatingQueryInterface(riid,ppv);
    } else if (riid == IID_IFullScreenVideoEx) {
        return m_ModexVideo.NonDelegatingQueryInterface(riid,ppv);
    }
    return CBaseVideoRenderer::NonDelegatingQueryInterface(riid,ppv);
}


// Return the CLSIDs for the property pages we support

STDMETHODIMP CModexRenderer::GetPages(CAUUID *pPages)
{
    CheckPointer(pPages,E_POINTER);
    NOTE("Entering GetPages");
    pPages->cElems = 1;

    // Are we allowed to expose the display modes property page

    HKEY hk;
    DWORD dwValue = 0, cb = sizeof(DWORD);
    TCHAR ach[80] = {'C','L','S','I','D','\\'};
    REFGUID rguid = CLSID_ModexProperties;
    wsprintf(&ach[6], TEXT("{%08lX-%04X-%04X-%02X%02X-%02X%02X%02X%02X%02X%02X}"),
	    rguid.Data1, rguid.Data2, rguid.Data3,
	    rguid.Data4[0], rguid.Data4[1],
	    rguid.Data4[2], rguid.Data4[3],
	    rguid.Data4[4], rguid.Data4[5],
	    rguid.Data4[6], rguid.Data4[7]);

    if (!RegOpenKey(HKEY_CLASSES_ROOT, ach, &hk)) {
        if (!RegQueryValueEx(hk, TEXT("ShowMe"), NULL, NULL, (LPBYTE)&dwValue, &cb) &&
								dwValue) {
	    pPages->cElems = 2;
            NOTE("Using property page");
	}
    }

    // allocate enough room for the varying number of pages

    pPages->pElems = (GUID *) QzTaskMemAlloc(pPages->cElems * sizeof(GUID));
    if (pPages->pElems == NULL) {
        return E_OUTOFMEMORY;
    }

    // We may not be returning CLSID_ModexProperties

    pPages->pElems[0] = CLSID_QualityProperties;
    if (pPages->cElems > 1) {
    	pPages->pElems[1] = CLSID_ModexProperties;
    }
    return NOERROR;
}


// Pass the DirectDraw sample onto the allocator to deal with

HRESULT CModexRenderer::DoRenderSample(IMediaSample *pMediaSample)
{
    return m_ModexAllocator.DoRenderSample(pMediaSample);
}


// If we are not streaming then display a poster image and also have any
// state transition completed. Transitions to paused states don't fully
// complete until the first image is available for drawing. Any GetState
// calls on IMediaFilter will return State_Intermediate until complete

void CModexRenderer::OnReceiveFirstSample(IMediaSample *pMediaSample)
{
    NOTE("OnReceiveFirstSample");
    DoRenderSample(pMediaSample);
}


// Overriden so that when we try to complete a connection we check that the
// source filter can provide a format we can use in our display modes. If
// the source is not DirectDraw enabled then we would have to change mode
// to say 320x240, find they can't supply a clipped version of their video
// and reject the Pause call. What applications really want is to have the
// connection rejected if we detect the source won't be able to handle it

HRESULT CModexRenderer::CompleteConnect(IPin *pReceivePin)
{
    NOTE("Entering Modex CompleteConnect");
    CAutoLock cInterfaceLock(&m_InterfaceLock);
    CBaseVideoRenderer::CompleteConnect(pReceivePin);

    // Pass the video window handle upstream
    HWND hwnd = m_ModexWindow.GetWindowHWND();
    NOTE1("Sending EC_NOTIFY_WINDOW %x",hwnd);
    SendNotifyWindow(pReceivePin,hwnd);

    return m_ModexAllocator.NegotiateSurfaceFormat();
}


// Called when a connection is broken

HRESULT CModexRenderer::BreakConnect()
{
    NOTE("Entering Modex BreakConnect");
    CAutoLock cInterfaceLock(&m_InterfaceLock);
    CBaseVideoRenderer::BreakConnect();
    m_ModexWindow.InactivateWindow();

    // The window is not used when disconnected
    IPin *pPin = m_ModexInputPin.GetConnected();
    if (pPin) SendNotifyWindow(pPin,NULL);

    return NOERROR;
}


// Helper function to copy a palette out of any kind of VIDEOINFO (ie it may
// be s DirectDraw sample) into a palettised VIDEOINFO. We use this changing
// palettes on DirectDraw samples as a source filter can attach a palette to
// any buffer (eg Modex) and hand it back. We make a new palette out of that
// format and then copy the palette colours into the current connection type

HRESULT CModexRenderer::CopyPalette(const CMediaType *pSrc,CMediaType *pDest)
{
    // Reset the destination palette before starting

    VIDEOINFO *pDestInfo = (VIDEOINFO *) pDest->Format();
    pDestInfo->bmiHeader.biClrUsed = 0;
    pDestInfo->bmiHeader.biClrImportant = 0;
    ASSERT(PALETTISED(pDestInfo) == TRUE);

    // Does the source contain a palette

    const VIDEOINFO *pSrcInfo = (VIDEOINFO *) pSrc->Format();
    if (ContainsPalette((VIDEOINFOHEADER *)pSrcInfo) == FALSE) {
        NOTE("No source palette");
        return S_FALSE;
    }

    // The number of colours may be zero filled

    DWORD PaletteEntries = pSrcInfo->bmiHeader.biClrUsed;
    if (PaletteEntries == 0) {
        NOTE("Setting maximum colours");
        PaletteEntries = iPALETTE_COLORS;
    }

    // Make sure the destination has enough room for the palette

    ASSERT(pSrcInfo->bmiHeader.biClrUsed <= iPALETTE_COLORS);
    ASSERT(pSrcInfo->bmiHeader.biClrImportant <= PaletteEntries);
    ASSERT(pDestInfo->bmiColors == GetBitmapPalette((VIDEOINFOHEADER *)pDestInfo));
    pDestInfo->bmiHeader.biClrUsed = PaletteEntries;
    pDestInfo->bmiHeader.biClrImportant = pSrcInfo->bmiHeader.biClrImportant;
    ULONG BitmapSize = GetBitmapFormatSize(HEADER(pSrcInfo));

    if (pDest->FormatLength() < BitmapSize) {
        NOTE("Reallocating destination");
        pDest->ReallocFormatBuffer(BitmapSize);
    }

    // Now copy the palette colours across

    CopyMemory((PVOID) pDestInfo->bmiColors,
               (PVOID) GetBitmapPalette((VIDEOINFOHEADER *)pSrcInfo),
               PaletteEntries * sizeof(RGBQUAD));

    return NOERROR;
}


// We store a copy of the media type used for the connection in the renderer
// because it is required by many different parts of the running renderer
// This can be called when we come to draw a media sample that has a format
// change with it since we delay the completion to maintain synchronisation
// This must also handle Modex DirectDraw media samples and palette changes

HRESULT CModexRenderer::SetMediaType(const CMediaType *pmt)
{
    CAutoLock cInterfaceLock(&m_InterfaceLock);
    NOTE("Entering Modex SetMediaType");

    // Is this a DirectDraw sample with a format change

    if (m_ModexAllocator.GetDirectDrawStatus() == TRUE) {
        NOTE("Copying palette into DIB format");
        CopyPalette(pmt,&m_mtIn);
        m_ModexAllocator.NotifyMediaType(&m_mtIn);
        return m_ModexAllocator.UpdateDrawPalette(pmt);
    }

    m_mtIn = *pmt;

    // Expand the palette provided in the media type

    m_mtIn.ReallocFormatBuffer(sizeof(VIDEOINFO));
    VIDEOINFO *pVideoInfo = (VIDEOINFO *) m_mtIn.Format();
    BITMAPINFOHEADER *pHeader = HEADER(pVideoInfo);
    m_Display.UpdateFormat(pVideoInfo);

    // Notify the application of the video dimensions

    NotifyEvent(EC_VIDEO_SIZE_CHANGED,
                MAKELPARAM(pHeader->biWidth,pHeader->biHeight),
                MAKEWPARAM(0,0));

    // Update the palette and source format

    NOTE("Updating Modex allocator with format");
    m_ModexAllocator.NotifyMediaType(&m_mtIn);
    return m_ModexAllocator.UpdateDrawPalette(&m_mtIn);
}


// Reset the keyboard state for this thread

void CModexRenderer::ResetKeyboardState()
{
    BYTE KeyboardState[256];
    GetKeyboardState(KeyboardState);
    KeyboardState[VK_MENU] = FALSE;
    KeyboardState[VK_SHIFT] = FALSE;
    KeyboardState[VK_CONTROL] = FALSE;
    SetKeyboardState(KeyboardState);
}


// Called by the base filter class when we are paused or run

HRESULT CModexRenderer::Active()
{
    NOTE("Entering Modex Active");
    LRESULT Result;

    // Are we already activated

    if (m_bActive == TRUE) {
        NOTE("Already Active");
        return NOERROR;
    }

    // Activate the allocator

    SetRepaintStatus(FALSE);
    HWND hwnd = m_ModexWindow.GetWindowHWND();

	// call SetFocusWindow on all DSound Renderers
	m_ModexAllocator.DistributeSetFocusWindow(hwnd);

    Result = SendMessage(hwnd,m_msgFullScreen,0,0);
    m_bActive = TRUE;

    // Check the allocator activated

    if (Result == (LRESULT) 0) {
        Inactive();
        return E_FAIL;
    }
    return CBaseVideoRenderer::Active();
}


// Called when the filter is stopped

HRESULT CModexRenderer::Inactive()
{
    NOTE("Entering Modex Inactive");

    // Are we already deactivated

    if (m_bActive == FALSE) {
        NOTE("Already Inactive");
        return NOERROR;
    }

    // Deactivate the allocator

    SetRepaintStatus(TRUE);
    m_bActive = FALSE;
    HWND hwnd = m_ModexWindow.GetWindowHWND();

    //  If we're already on the window thread we can inactivate
    //  the allocator here
    //  If we're on another thread avoid a bug in DirectDraw
    //  by posting a message to ourselves
    //  The problem occurs because DirectDraw calls ShowWindow
    //  in response to WM_ACTIVATEAPP (they hooked our window proc
    //  inside SetCooperativeLevel) and ShowWindow allows through
    //  this message if we send it via SendMessage.  Unfortunately
    //  at this point DirectDraw holds its critical section so we
    //  deadlock with the player thread when it tries to call
    //  Lock (player thread has allocator CS, tries to get DDraw CS,
    //  window thread has DDraw CS, tries to get allocator CS).
    if (GetWindowThreadProcessId(hwnd, NULL) ==
            GetCurrentThreadId()) {
        DbgLog((LOG_TRACE, 2, TEXT("Inactive on window thread")));
     	m_ModexAllocator.Inactive();
    } else {
        SendMessage(hwnd,m_msgNormal,0,0);
        m_evWaitInactive.Wait();
	}
	
	// call SetFocusWindow on all DSound Renderers
	m_ModexAllocator.DistributeSetFocusWindow(NULL);
    
    CBaseVideoRenderer::Inactive();

    return NOERROR;
}


// Called when we receive WM_ACTIVATEAPP messages. DirectDraw seems to arrange
// through its window hooking that we get notified of activation and likewise
// deactivation as the user tabs away from the window. If we have any surfaces
// created we will have lost them during deactivation so we take this chance
// to restore them - the restore will reclaim the video memory that they need

HRESULT CModexRenderer::OnActivate(HWND hwnd,WPARAM wParam)
{
    NOTE("In WM_ACTIVATEAPP method");
    IBaseFilter *pFilter = NULL;
    BOOL bActive = (BOOL) wParam;

    // Have we been activated yet

    if (m_bActive == FALSE) {
        NOTE("Not activated");
        return NOERROR;
    }

    // Extra window activation checks

    if (bActive == TRUE) {
        NOTE("Restoring window...");
        m_ModexWindow.RestoreWindow();
        NOTE("Restored window");
    }

    // Tell the plug in distributor what happened

    QueryInterface(IID_IBaseFilter,(void **) &pFilter);
    NotifyEvent(EC_ACTIVATE,wParam,(LPARAM) pFilter);
    NOTE1("Notification of EC_ACTIVATE (%d)",bActive);

    // Pass on EC_FULLSCREEN_LOST event codes
    if (bActive == FALSE)
        NotifyEvent(EC_FULLSCREEN_LOST,0,(LPARAM) pFilter);

    pFilter->Release();

    // Should we deactivate ourselves immediately

    if (m_ModexVideo.HideOnDeactivate() == TRUE) {
        if (bActive == FALSE) {
            NOTE("Deactivating");
            return Inactive();
        }
    }

    // No new data to paint with so signal the filtergraph that another image
    // is required, this has the filtergraph component set the whole graph to
    // a paused state which causes us to receive an image. This function must
    // be asynchronous otherwise the window will stop responding to the user

    if (bActive == TRUE) {
    	NOTE("Sending Repaint");
        SendRepaint();
    }
    return m_ModexAllocator.OnActivate(bActive);
}


// Constructor for our derived input pin class. We override the base renderer
// pin class so that we can control the allocator negotiation. This rendering
// filter only operates in Modex so we can only draw buffers provided by our
// allocator. If the source insists on using its allocator then we cannot do
// a connection. We must also make sure that when we have samples delivered
// to our input pin that we hand them to our allocator to unlock the surface

CModexInputPin::CModexInputPin(CModexRenderer *pRenderer,
                               CCritSec *pInterfaceLock,
                               TCHAR *pObjectName,
                               HRESULT *phr,
                               LPCWSTR pPinName) :

    CRendererInputPin(pRenderer,phr,pPinName),
    m_pRenderer(pRenderer),
    m_pInterfaceLock(pInterfaceLock)
{
    ASSERT(m_pRenderer);
    ASSERT(pInterfaceLock);
}


// This overrides the CBaseInputPin virtual method to return our allocator
// When NotifyAllocator is called it sets the current allocator in the base
// input pin class (m_pAllocator), this is what GetAllocator should return
// unless it is NULL in which case we return the allocator we would like

STDMETHODIMP CModexInputPin::GetAllocator(IMemAllocator **ppAllocator)
{
    CheckPointer(ppAllocator,E_POINTER);
    CAutoLock cInterfaceLock(m_pInterfaceLock);
    NOTE("Entering GetAllocator");

    // Has an allocator been set yet in the base class

    if (m_pAllocator == NULL) {
        m_pAllocator = &m_pRenderer->m_ModexAllocator;
        m_pAllocator->AddRef();
    }

    m_pAllocator->AddRef();
    *ppAllocator = m_pAllocator;
    return NOERROR;
}


// The COM specification says any two IUnknown pointers to the same object
// should always match which provides a way for us to see if they are using
// our allocator or not. Since we are only really interested in equality
// and our object always hands out the same IMemAllocator interface we can
// just see if the pointers match. We must always use our Modex allocator

STDMETHODIMP
CModexInputPin::NotifyAllocator(IMemAllocator *pAllocator,BOOL bReadOnly)
{
    NOTE("Entering NotifyAllocator");
    CAutoLock cInterfaceLock(m_pInterfaceLock);
    if (pAllocator == &m_pRenderer->m_ModexAllocator) {
        return CBaseInputPin::NotifyAllocator(pAllocator,bReadOnly);
    }
    return E_FAIL;
}


// We have been delivered a sample that holds the DirectDraw surface lock so
// we pass it onto the allocator to deal with before handing to the renderer
// It would be bad to leave the surface locked while the sample is queued by
// the renderer as it locks out any other threads from accessing the surface

STDMETHODIMP CModexInputPin::Receive(IMediaSample *pSample)
{
    CheckPointer(pSample,E_POINTER);
    NOTE("Pin received a sample");
    m_pRenderer->m_ModexAllocator.OnReceive(pSample);
    return m_pRenderer->Receive(pSample);
}


// Constructor for our window class. To access DirectDraw Modex we supply it
// with a window, this is granted exclusive mode access rights. DirectDraw
// hooks the window and manages a lot of the functionality associated with
// handling Modex. For example when you switch display modes it maximises
// the window, when the user hits ALT-TAB the window is minimised. When the
// user then clicks on the minimised window the Modex is likewise restored

CModexWindow::CModexWindow(CModexRenderer *pRenderer,   // Delegates locking
                           TCHAR *pName,                // Object description
                           HRESULT *phr) :              // OLE failure code
    m_pRenderer(pRenderer),
    m_hAccel(NULL),
    m_hwndAccel(NULL)
{
    ASSERT(m_pRenderer);
}


// it is going to create the window to get our window and class styles. The
// return code is the class name and must be allocated in static storage. We
// specify a normal window during creation although the window styles as well
// as the extended styles may be changed by the application via IVideoWindow

LPTSTR CModexWindow::GetClassWindowStyles(DWORD *pClassStyles,
                                          DWORD *pWindowStyles,
                                          DWORD *pWindowStylesEx)
{
    NOTE("Entering GetClassWindowStyles");

    *pClassStyles = CS_HREDRAW | CS_VREDRAW | CS_BYTEALIGNCLIENT | CS_DBLCLKS;
    *pWindowStyles = WS_POPUP | WS_CLIPCHILDREN;
    *pWindowStylesEx = WS_EX_TOPMOST;
    return MODEXCLASS;
}


// When we change display modes to 640x480 DirectDraw seems to switch us to a
// software cursor. When we start flipping the primary surfaces we can end up
// leaving a trail of previous mouse positions as it is moved. The solution
// is to hide the mouse when it is needed and the window is in exclusive mode

LRESULT CModexWindow::OnSetCursor()
{
    NOTE("Entering OnSetCursor");

    // Pass to default processing if iconic

    if (IsIconic(m_hwnd) == TRUE) {
        NOTE("Not hiding cursor");
        return (LRESULT) 0;
    }

    NOTE("Hiding software cursor");
    SetCursor(NULL);
    return (LRESULT) 1;
}


// When the fullscreen mode is activated we restore our window

LRESULT CModexWindow::RestoreWindow()
{
    NOTE("Entering RestoreWindow");

    // Is the window currently minimised

    if (GetForegroundWindow() != m_hwnd || IsIconic(m_hwnd)) {
        NOTE("Window is iconic");
        return (LRESULT) 1;
    }

    NOTE("Making window fullscreen");

    SetWindowPos(m_hwnd,NULL,(LONG) 0,(LONG) 0,
                 GetSystemMetrics(SM_CXSCREEN),
                 GetSystemMetrics(SM_CYSCREEN),
                 SWP_NOACTIVATE | SWP_NOZORDER);

    UpdateWindow(m_hwnd);
    return (LRESULT) 1;
}


// Used to blank the window after a mode change

void CModexWindow::OnPaint()
{
    NOTE("Entering OnPaint");
    RECT ClientRect;
    PAINTSTRUCT ps;
    BeginPaint(m_hwnd,&ps);
    EndPaint(m_hwnd,&ps);

    GetClientRect(m_hwnd,&ClientRect);
    COLORREF BackColour = SetBkColor(m_hdc,VIDEO_COLOUR);
    ExtTextOut(m_hdc,0,0,ETO_OPAQUE,&ClientRect,NULL,0,NULL);
    SetBkColor(m_hdc,BackColour);
}


// This is the derived class window message handler

LRESULT CModexWindow::OnReceiveMessage(HWND hwnd,          // Window handle
                                       UINT uMsg,          // Message ID
                                       WPARAM wParam,      // First parameter
                                       LPARAM lParam)      // Other parameter
{
    if (::PossiblyEatMessage(m_pRenderer->m_ModexVideo.GetMessageDrain(),
                             uMsg,
                             wParam,
                             lParam)) {
        return 0;
    }
    // Due to a bug in DirectDraw we must call SetCooperativeLevel and also
    // SetDisplayMode on the window thread, otherwise it gets confused and
    // blocks us from completing the display change successfully. Therefore
    // when we're activated we send a message to the window to go fullscreen
    // The return value is used by the main renderer to know if we succeeded

    if (uMsg == m_pRenderer->m_msgFullScreen) {
        m_pRenderer->ResetKeyboardState();
     	HRESULT hr = m_pRenderer->m_ModexAllocator.Active();
    	return (FAILED(hr) ? (LRESULT) 0 : (LRESULT) 1);
    }

    // And likewise we also deactivate the renderer from fullscreen mode on
    // the window thread rather than the application thread. Otherwise we
    // get a load of confusing WM_ACTIVATEAPP messages coming through that
    // cause us to believe we have been restored from a minimised state and
    // so send repaints and also restore surfaces we are currently releasing

    if (uMsg == m_pRenderer->m_msgNormal) {
     	NOTE("Restoring on WINDOW thread");
     	m_pRenderer->m_ModexAllocator.Inactive();
        m_pRenderer->m_evWaitInactive.Set();
        return (LRESULT) 1;
    }

    // DirectDraw holds it's critical section while it sends us an activate
    // message - if the decoder thread is about to call DirectDraw it will
    // have the allocator lock and may deadlock trying to enter DirectDraw
    // The solution is to post activation messages back to ourselves using
    // a custom message so they can be handled without the DirectDraw lock

    if (uMsg == m_pRenderer->m_msgActivate) {
     	NOTE("Activation message received");
     	m_pRenderer->OnActivate(hwnd,wParam);
        return (LRESULT) 0;
    }

    switch (uMsg)
    {
        // Use ALT-ENTER as a means of deactivating

        case WM_SYSKEYDOWN:
            if (wParam == VK_RETURN) {
                NOTE("ALT-ENTER selected");
                m_pRenderer->m_ModexAllocator.Inactive();
            }
            return (LRESULT) 0;

        // Handle WM_CLOSE by aborting the playback

        case WM_CLOSE:
            m_pRenderer->NotifyEvent(EC_USERABORT,0,0);
            NOTE("Sent an EC_USERABORT to graph");
            return (LRESULT) 1;

        // See if we are still the fullscreen window

        case WM_ACTIVATEAPP:
            PostMessage(hwnd,m_pRenderer->m_msgActivate,wParam,lParam);
            return (LRESULT) 0;

        // Paint the background black

        case WM_PAINT:
            OnPaint();
            return (LRESULT) 0;

        // Disable cursors when fullscreen active

        case WM_SETCURSOR:
            if (OnSetCursor() == 1) {
                return (LRESULT) 1;
            }
    }
    return CBaseWindow::OnReceiveMessage(hwnd,uMsg,wParam,lParam);
}


#if 0
// This is the windows message loop for our worker thread. It does a loop
// processing and dispatching messages until it receives a WM_QUIT message
// which will normally be generated through the owning object's destructor
// We override this so that we can pass messages on in fullscreen mode to
// another window - that window is set through the SetMessageDrain method

HRESULT CModexWindow::MessageLoop()
{
    HANDLE hEvent = (HANDLE) m_SyncWorker;
    MSG Message;
    DWORD dwResult;

    while (TRUE) {

        // Has the close down event been signalled

        dwResult = MsgWaitForMultipleObjects(1,&hEvent,FALSE,INFINITE,QS_ALLINPUT);
        if (dwResult == WAIT_OBJECT_0) {
            HWND hwnd = m_hwnd;
            UninitialiseWindow();
            DestroyWindow(hwnd);
            return NOERROR;
        }

        // Dispatch the message to the window procedure

        if (dwResult == WAIT_OBJECT_0 + 1) {
            while (PeekMessage(&Message,NULL,0,0,PM_REMOVE)) {
                if ((m_hAccel == NULL) || (TranslateAccelerator(m_hwndAccel,m_hAccel,&Message) == FALSE)) {
                    SendToDrain(&Message);
                    TranslateMessage(&Message);
                    DispatchMessage(&Message);
                }
            }
        }
    }
    return NOERROR;
}
#endif


// This checks to see whether the window has a drain. When we are playing in
// fullscreen an application can register itself through IFullScreenVideo to
// get any mouse and keyboard messages we get sent. This might allow it to
// support seeking hot keys for example without switching back to a window.
// We pass these messages on untranslated returning TRUE if we're successful

BOOL CModexWindow::SendToDrain(PMSG pMessage)
{
    HWND hwndDrain = m_pRenderer->m_ModexVideo.GetMessageDrain();

    if (hwndDrain != NULL)
    {
        switch (pMessage->message)
        {
            case WM_CHAR:
            case WM_DEADCHAR:
            case WM_KEYDOWN:
            case WM_KEYUP:
            case WM_LBUTTONDBLCLK:
            case WM_LBUTTONDOWN:
            case WM_LBUTTONUP:
            case WM_MBUTTONDBLCLK:
            case WM_MBUTTONDOWN:
            case WM_MBUTTONUP:
            case WM_MOUSEACTIVATE:
            case WM_MOUSEMOVE:
            case WM_NCHITTEST:
            case WM_NCLBUTTONDBLCLK:
            case WM_NCLBUTTONDOWN:
            case WM_NCLBUTTONUP:
            case WM_NCMBUTTONDBLCLK:
            case WM_NCMBUTTONDOWN:
            case WM_NCMBUTTONUP:
            case WM_NCMOUSEMOVE:
            case WM_NCRBUTTONDBLCLK:
            case WM_NCRBUTTONDOWN:
            case WM_NCRBUTTONUP:
            case WM_RBUTTONDBLCLK:
            case WM_RBUTTONDOWN:
            case WM_RBUTTONUP:

                PostMessage(hwndDrain,
                            pMessage->message,
                            pMessage->wParam,
                            pMessage->lParam);

                return TRUE;
        }
    }
    return FALSE;
}
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\multimedia\dshow\filters\image\oversrc\viduids.h ===
//==========================================================================;
//
//  THIS CODE AND INFORMATION IS PROVIDED "AS IS" WITHOUT WARRANTY OF ANY
//  KIND, EITHER EXPRESSED OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE
//  IMPLIED WARRANTIES OF MERCHANTABILITY AND/OR FITNESS FOR A PARTICULAR
//  PURPOSE.
//
//  Copyright (c) 1992 - 1996  Microsoft Corporation.  All Rights Reserved.
//
//--------------------------------------------------------------------------;

DEFINE_GUID(CLSID_OverlaySource,
0xab2809b0, 0xce83, 0x11cf, 0xbc, 0x25, 0x00, 0xaa, 0x00, 0xac, 0x74, 0xf6);
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\multimedia\dshow\filters\image\screen\screen.cpp ===
//==========================================================================;
//
//  THIS CODE AND INFORMATION IS PROVIDED "AS IS" WITHOUT WARRANTY OF ANY
//  KIND, EITHER EXPRESSED OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE
//  IMPLIED WARRANTIES OF MERCHANTABILITY AND/OR FITNESS FOR A PARTICULAR
//  PURPOSE.
//
//  Copyright (c) 1992 - 1996  Microsoft Corporation.  All Rights Reserved.
//
//--------------------------------------------------------------------------;

#include <streams.h>
#include <stdlib.h>
#include <stdio.h>
#include <viddbg.h>
#include <screen.h>

// This is a simple fullscreen movie application. Many applications want a
// fair degree of control over which display modes get used for fullscreen
// playback. This sample code creates a graph, switches renderers to the
// fullscreen renderer and selects the desired display modes. In the future
// we will be able to make this much easier for applications by having the
// filtergraph support a fullscreen plug in distributor but in the meantime

HWND g_hwndFrame;       // Handle to the main window frame
int g_cTemplates;       // Otherwise the compiler complains

CFactoryTemplate g_Templates[] = {
    {L"", &GUID_NULL,NULL,NULL}
};

// Standard Windows program entry point called by runtime code

INT PASCAL WinMain(HINSTANCE hInstance,        // This instance identifier
                   HINSTANCE hPrevInstance,    // Previous instance
                   LPSTR lpszCmdLine,          // Command line parameters
                   INT nCmdShow)               // Initial display mode
{
    WNDCLASS wndclass;      // Used to register classes
    MSG msg;                // Windows message structure

    // Register the frame window class

    wndclass.style         = CS_HREDRAW | CS_VREDRAW;
    wndclass.lpfnWndProc   = FrameWndProc;
    wndclass.cbClsExtra    = 0;
    wndclass.cbWndExtra    = 0;
    wndclass.hInstance     = hInstance;
    wndclass.hIcon         = NULL;
    wndclass.hCursor       = LoadCursor (NULL,IDC_ARROW);
    wndclass.hbrBackground = (HBRUSH)(COLOR_APPWORKSPACE + 1);
    wndclass.lpszMenuName  = NULL;
    wndclass.lpszClassName = FrameClass;

    RegisterClass (&wndclass);

    // Create the frame window

    g_hwndFrame = CreateWindow(FrameClass,              // Class of window
                               Title,                   // Window's title
                               WS_OVERLAPPEDWINDOW |    // Window styles
                               WS_CLIPCHILDREN |        // Clip any children
                               WS_VISIBLE,              // Make it visible
                               CW_USEDEFAULT,           // Default x position
                               CW_USEDEFAULT,           // Default y position
                               200,250,                 // The initial size
                               NULL,                    // Window parent
                               NULL,                    // Menu handle
                               hInstance,               // Instance handle
                               NULL);                   // Creation data
    ASSERT(g_hwndFrame);
    CoInitialize(NULL);
    DbgInitialise(hInstance);
    g_hInst = hInstance;
    MeasureLoadTime();

    // Normal Windows message loop

    while (GetMessage(&msg,NULL,0,0)) {
        TranslateMessage(&msg);
        DispatchMessage(&msg);
    }

    CoUninitialize();
    DbgTerminate();
    return msg.wParam;
}


// Measure how long it takes to load ActiveMovie

void MeasureLoadTime()
{
    DWORD Start = timeGetTime();
    HINSTANCE hLibrary = LoadLibrary("QUARTZ.DLL");
    DWORD End = timeGetTime() - Start;
    TCHAR LoadTimeString[256];
    wsprintf(LoadTimeString,"ActiveMovie load time %dms\n",End);
    OutputDebugString(LoadTimeString);
    FreeLibrary(hLibrary);
}


// And likewise the normal windows procedure for message handling

LRESULT CALLBACK FrameWndProc(HWND hwnd,        // Our window handle
                              UINT message,     // Message information
                              UINT wParam,      // First parameter
                              LONG lParam)      // And other details
{
    switch (message)
    {
        case WM_DESTROY:
            PostQuitMessage(FALSE);
            return (LRESULT) 0;
    }
    return DefWindowProc(hwnd,message,wParam,lParam);
}


//
// FullScreenVideo
//
HRESULT FullScreenVideo(TCHAR *pFileName)
{
    IGraphBuilder *pGraph;
    WCHAR wszFileName[128];
    ASSERT(pFileName);

    // Quick check on thread parameter

    if (pFileName == NULL) {
        return E_FAIL;
    }

    // Create the ActiveMovie filtergraph

    HRESULT hr = CoCreateInstance(CLSID_FilterGraph,
                                  NULL,
                                  CLSCTX_INPROC_SERVER,
                                  IID_IGraphBuilder,
                                  (void **) &pGraph);

    // Quick check on parameters

    if (pGraph == NULL) {
        NOTE1("No graph %lx",hr);
        return E_FAIL;
    }

    MultiByteToWideChar(CP_ACP,0,pFileName,-1,wszFileName,128);
    NOTE1("Created graph %lx",GetCurrentThreadId());

    // Try and render the file

    hr = pGraph->RenderFile(wszFileName,NULL);
    if (FAILED(hr)) {
        pGraph->Release();
        NOTE2("Render failed on %s (error %lx)",pFileName,hr);
        return E_FAIL;
    }

    NOTE1("Render %s ok (%lx)",pFileName);

    PlayFullScreen(pGraph);
    pGraph->Release();
    return NOERROR;
}


//
// PlayFullScreen
//
HRESULT PlayFullScreen(IFilterGraph *pGraph)
{
    ASSERT(pGraph);

    // We need this to change renderers

    IPin *pVideoPin = FindVideoPin(pGraph);
    if (pVideoPin == NULL) {
        return E_FAIL;
    }

    // We need this to change renderers

    IBaseFilter *pModexFilter = FindModexFilter(pGraph);
    if (pModexFilter == NULL) {
        pVideoPin->Release();
        return E_FAIL;
    }

    // Get a fullscreen renderer pin

    IPin *pModexPin = FindModexPin(pModexFilter);
    if (pModexPin == NULL) {
        pVideoPin->Release();
        pModexFilter->Release();
        return E_FAIL;
    }

    // Connect the fullscreen renderer up instead

    HRESULT hr = ConnectModexFilter(pGraph,pModexFilter,pVideoPin,pModexPin);
    if (hr == S_OK)
        DoPlayFullScreen(pGraph);

    // Release all the junk allocated

    if (pVideoPin) pVideoPin->Release();
    if (pModexPin) pModexPin->Release();
    if (pModexFilter) pModexFilter->Release();

    return NOERROR;
}


//
// ConnectModexFilter
//
HRESULT ConnectModexFilter(IFilterGraph *pGraph,
                           IBaseFilter *pModexFilter,
                           IPin *pVideoPin,
                           IPin *pModexPin)
{
    IFullScreenVideo *pFullVideo;
    NOTE("ConnectModexFilter");
    HRESULT hr = NOERROR;
    IPin *pPin = NULL;
    ASSERT(pGraph);

    // Find out who it's connected to

    pVideoPin->ConnectedTo(&pPin);
    if (pPin == NULL) {
        NOTE("No peer pin");
        return E_FAIL;
    }

    // Add the Modex renderer to the graph

    hr = pGraph->AddFilter(pModexFilter,L"FullScreen Renderer");
    if (FAILED(hr)) {
        pPin->Release();
        return E_FAIL;
    }

    // Get an IFullScreenVideo interface from the fullscreen filter

    hr = pModexFilter->QueryInterface(IID_IFullScreenVideo,(VOID **)&pFullVideo);
    if (FAILED(hr)) {
        pPin->Release();
        return E_FAIL;
    }

    // Set the display modes acceptable

    hr = EnableRightModes(pFullVideo);
    if (FAILED(hr)) {
        pPin->Release();
        pFullVideo->Release();
        return E_FAIL;
    }

    // Disconnect the normal renderer
    pGraph->Disconnect(pPin);
    pGraph->Disconnect(pVideoPin);
    pFullVideo->Release();

    // Try and connect the output to the Modex filter

    hr = pGraph->ConnectDirect(pPin,pModexPin,NULL);
    if (FAILED(hr)) {
        pPin->Release();
        return E_FAIL;
    }

    pPin->Release();
    return NOERROR;
}


//
// FindVideoPin
//
IPin *FindVideoPin(IFilterGraph *pGraph)
{
    IBaseFilter *pFilter;
    IPin *pPin;
    ASSERT(pGraph);

    // Find the video renderer in the graph

    pGraph->FindFilterByName(L"Video Renderer",&pFilter);
    if (pFilter == NULL) {
        return NULL;
    }

    IEnumPins *pEnumPins = NULL;
    ULONG FetchedPins = 0;
    pFilter->EnumPins(&pEnumPins);
    pFilter->Release();

    // Did we get an enumerator

    if (pEnumPins == NULL) {
        NOTE("No enumerator");
        return NULL;
    }

    // Get the first and hopefully only input pin

    pEnumPins->Next(1,&pPin,&FetchedPins);
    pEnumPins->Release();
    if (pPin == NULL) {
        NOTE("No input pin");
    }
    return pPin;
}


//
// FindModexFilter
//
IBaseFilter *FindModexFilter(IFilterGraph *pGraph)
{
    IBaseFilter *pFilter;
    ASSERT(pGraph);

    // Create ourselves a new fullscreen filter

    HRESULT hr = CoCreateInstance(CLSID_ModexRenderer,
                                  NULL,
                                  CLSCTX_INPROC_SERVER,
                                  IID_IBaseFilter,
                                  (void **) &pFilter);
    if (FAILED(hr)) {
        NOTE("No object");
        return NULL;
    }
    return pFilter;
}


//
// FindModexPin
//
IPin *FindModexPin(IBaseFilter *pFilter)
{
    IEnumPins *pEnumPins = NULL;
    ULONG FetchedPins = 0;
    pFilter->EnumPins(&pEnumPins);
    IPin *pPin;

    // Did we get an enumerator

    if (pEnumPins == NULL) {
        NOTE("No enumerator");
        return NULL;
    }

    // Get the one and only input pin

    pEnumPins->Next(1,&pPin,&FetchedPins);
    pEnumPins->Release();
    if (pPin == NULL) {
        NOTE("No input pin");
    }
    return pPin;
}


//
// WaitForCompletion
//
HRESULT WaitForCompletion(IFilterGraph *pGraph)
{
    NOTE("WaitForCompletion");
    IMediaEvent *pEvent;
    LONG EventCode,Param1,Param2;
    HANDLE hEvent;

    // We need this to manage state transitions

    pGraph->QueryInterface(IID_IMediaEvent,(VOID **)&pEvent);
    if (pEvent == NULL) {
        NOTE("No IMediaEvent");
        return E_UNEXPECTED;
    }

    // Any of these error codes cause playback to complete

    pEvent->GetEventHandle((OAEVENT*)&hEvent);
    while (TRUE) {
        WaitForSingleObject(hEvent,INFINITE);
        pEvent->GetEvent(&EventCode,&Param1,&Param2,INFINITE);
        NOTE1("Event received %d",EventCode);
        if (EventCode == EC_USERABORT || EventCode == EC_ERRORABORT ||
              EventCode == EC_FULLSCREEN_LOST || EventCode == EC_COMPLETE) {
                break;
        }
    }

    NOTE("File completed");
    pEvent->Release();
    return NOERROR;
}


//
// DoPlayFullScreen
//
// The actual run is a real hack which calls Run and then sleeps for a while
// which is very dangerous as we should really process messages while running
// otherwise we may block the fullscreen window (if for example as it comes
// up we get deactivated in which case we must process any WM_ACTIVATEAPPs)
//
HRESULT DoPlayFullScreen(IFilterGraph *pGraph)
{
    NOTE("DoPlayFullScreen");
    IMediaControl *pControl;

    // We need this to manage state transitions

    pGraph->QueryInterface(IID_IMediaControl,(VOID **)&pControl);
    if (pControl == NULL) {
        NOTE("No IMediaControl");
        return E_UNEXPECTED;
    }

    // Run the graph for a while

    pControl->Run();
    WaitForCompletion(pGraph);
    pControl->Stop();
    pControl->Release();

    return NOERROR;
}


//
// EnableRightModes
//
// For each display mode supported disable it unless it is 320x240 - this
// must be done BEFORE connecting the fullscreen renderer up as it is then
// that it chooses which display mode to use. Any modes we disable apply to
// that renderer instance only (ie they are not global changes). To make a
// set of changes apply globally (not to be recommended) call SetDefault
//
// This enables both 320x240x8 and 320x240x16 modes because the latter is not
// available on all display cards, note that the fullscreen renderer will try
// to get 320x240x16 before any 320x240x8 so it will look as good as it can
// (But note that DirectDraw on NTSUR cannot change display mode to 320x240)

HRESULT EnableRightModes(IFullScreenVideo *pFullVideo)
{
    NOTE("EnableRightModes");
    ASSERT(pFullVideo);
    LONG Width,Height,Depth,Modes;
    BOOL bModeAvailable = FALSE;

    pFullVideo->CountModes(&Modes);
    ASSERT(Modes > 0);
    pFullVideo->SetClipFactor(100);

    // Loop through each display mode supported

    for (int Loop = 0;Loop < Modes;Loop++) {
        pFullVideo->GetModeInfo(Loop,&Width,&Height,&Depth);
        if (Width == 640 && Height == 480) {
            bModeAvailable = TRUE;
            continue;
        }
        pFullVideo->SetEnabled(Loop,FALSE);
    }
    return (bModeAvailable ? S_OK : E_FAIL);
}
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\multimedia\dshow\filters\image\oversrc\oversrc.h ===
//==========================================================================;
//
//  THIS CODE AND INFORMATION IS PROVIDED "AS IS" WITHOUT WARRANTY OF ANY
//  KIND, EITHER EXPRESSED OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE
//  IMPLIED WARRANTIES OF MERCHANTABILITY AND/OR FITNESS FOR A PARTICULAR
//  PURPOSE.
//
//  Copyright (c) 1992 - 1996  Microsoft Corporation.  All Rights Reserved.
//
//--------------------------------------------------------------------------;

#ifndef __OVERSRC__
#define __OVERSRC__

#define DURATION 500                 // Total number of frames in stream
#define FRAMERATE 15                 // Default to 15 frames per second
#define INCREMENT (1000/FRAMERATE)   // Set according to the frame rate
#define BUFFERWIDTH 320              // Default to this wide backbuffer
#define BUFFERHEIGHT 240             // And likewise this many pixels deep
#define BUFFERSIZE 76800             // Total size of the back buffer
#define BUFFERCOLOURS 16             // Number of colours we draw with
#define DELIVERWAIT 250              // Wait after sending end of stream

// This is the main filter class. As with most source filters all the work is
// done in the pin classes (our CVideoStream objects). This object is left to
// manage the COM CreateInstance hooking. In our constructor we create a pin
// for the base source class, it can then look after all the filter workings

class CVideoSource : public CSource
{
public:

    CVideoSource(TCHAR *pName,LPUNKNOWN lpunk,HRESULT *phr);
    static CUnknown *CreateInstance(LPUNKNOWN lpunk, HRESULT *phr);
    LPAMOVIESETUP_FILTER GetSetupData();

    // Handle filter state changes

    STDMETHODIMP Stop();
    STDMETHODIMP Pause();
    STDMETHODIMP Run(REFERENCE_TIME tStart);
};


// This is the main source class, we implement IMediaPosition on the output
// pin as we have a fixed number of frames. Each frame has a time stamp but
// we just run flat out to make the transitions look as smooth as possible.
// We make sure we run flat out by setting a NULL sync source downstream on
// the video renderer - only by doing that can we block quality management.

class CVideoStream : public IOverlayNotify,
                     public CSourceStream,
                     public CMediaPosition
{
public:

    CVideoStream(HRESULT *phr,CVideoSource *pVideoSource,LPCWSTR pPinName);
    ~CVideoStream();

    // Provide an IUnknown for our IMediaSelection and IMediaEventSink

    STDMETHODIMP QueryInterface(REFIID riid, void **ppv) {
        return CSourceStream::GetOwner()->QueryInterface(riid,ppv);
    };
    STDMETHODIMP_(ULONG) AddRef() {
        return CSourceStream::GetOwner()->AddRef();
    };
    STDMETHODIMP_(ULONG) Release() {
        return CSourceStream::GetOwner()->Release();
    };

    // Expose the IMediaPosition interface
    STDMETHODIMP NonDelegatingQueryInterface(REFIID riid,VOID **ppv);
    CCritSec *GetLock() { return m_pFilter->pStateLock(); };

    // Handle overlay transport connections

    HRESULT CheckConnect(IPin *pPin);
    HRESULT BreakConnect();
    HRESULT CompleteConnect(IPin *pPin);
    HRESULT Inactive();
    HRESULT Active();
    HRESULT StopStreaming();
    HRESULT StartStreaming(REFERENCE_TIME tStart);

    // Ask for buffers of the size appropriate to the agreed media type
    HRESULT DecideBufferSize(IMemAllocator *pIMemAlloc,ALLOCATOR_PROPERTIES *pProperties);

    STDMETHODIMP Notify(IBaseFilter *pSender,Quality q);
    HRESULT GetMediaType(int iPosition, CMediaType *pmt);
    HRESULT GetMediaType(CMediaType *pmt);
    HRESULT OnThreadCreate();
    HRESULT OnThreadDestroy();
    HRESULT FillBuffer(IMediaSample *pSample);
    HRESULT DrawNextFrame();
    HRESULT ReleaseNumbersFrame();
    HRESULT InitNumbersFrame();
    void SendNewSegment();
    BOOL IsWindowFrozen();
    INT GetHeightFromPointsString(LPCTSTR szPoints);
    HRESULT DoBufferProcessingLoop();

public:

    // IMediaPosition properties

    STDMETHODIMP get_Duration(REFTIME *pLength);
    STDMETHODIMP put_CurrentPosition(REFTIME Time);
    STDMETHODIMP get_CurrentPosition(REFTIME *pTime);
    STDMETHODIMP get_StopTime(REFTIME *pTime);
    STDMETHODIMP put_StopTime(REFTIME Time);
    STDMETHODIMP get_PrerollTime(REFTIME *pTime);
    STDMETHODIMP put_PrerollTime(REFTIME Time);
    STDMETHODIMP get_Rate(double *pdRate);
    STDMETHODIMP put_Rate(double dRate);
    STDMETHODIMP CanSeekForward(LONG *pCanSeekForward);
    STDMETHODIMP CanSeekBackward(LONG *pCanSeekBackward);

public:

    // IOverlayNotify methods

    STDMETHODIMP OnColorKeyChange(const COLORKEY *pColorKey);
    STDMETHODIMP OnWindowChange(HWND hwnd);

    // If the window rectangle is all zero then the window is invisible, the
    // filter must take a copy of the information if it wants to keep it. As
    // for the palette we don't copy the data as all we do is to log them

    STDMETHODIMP OnClipChange(
        const RECT *pSourceRect,            // Area of video to play with
        const RECT *pDestinationRect,       // Area video goes
        const RGNDATA *pRgnData);           // Describes clipping data

    // This notifies the filter of palette changes, the filter should copy
    // the array of RGBQUADs if it needs to use them after returning. All
    // we use them for is logging so we don't bother to copy the palette

    STDMETHODIMP OnPaletteChange(
        DWORD dwColors,                     // Number of colours present
        const PALETTEENTRY *pPalette);      // Array of palette colours

    STDMETHODIMP OnPositionChange(
        const RECT *pSourceRect,            // Section of video to play with
        const RECT *pDestinationRect);      // Area on display video appears

private:

    CCritSec m_SourceLock;          // A play lock rather than state lock
    CVideoSource *m_pVideoSource;   // Holds our parent video source filter
    REFERENCE_TIME m_rtIncrement;   // Time between our successive frames
    LONG m_CurrentFrame;            // Contains the current frame number
    LONG m_StopFrame;               // Holds the last frame number to send
    BYTE *m_pBase;                  // Pointer to the actual image buffer
    HANDLE m_hMapping;              // Handle to memory mapping object
    HBITMAP m_hBitmap;              // The DIB section bitmap handle
    HDC m_hdcDisplay;               // Device context for the main display
    HDC m_hdcMemory;                // Use this to draw our current frame
    HFONT m_hFont;                  // Font used to draw the frame numbers
    double m_dbRate;                // Currently selected filtergraph rate
    BOOL m_bNewSegment;             // Should we send a new segment call
    IOverlay *m_pOverlay;           // Has the input pin overlay interface
    CCritSec m_ClipLock;            // Controls access to clip rectangles
    RECT m_SourceRect;              // Holds the current source rectangle
    RECT m_TargetRect;              // And likewise the destination target
    RGNDATA *m_pRgnData;            // List of window clipping rectangles
    LONG m_StartFrame;              // Store time between subsequent frames
};

#endif // __OVERSRC__
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\multimedia\dshow\filters\image\oversrc\oversrc.cpp ===
//==========================================================================;
//
//  THIS CODE AND INFORMATION IS PROVIDED "AS IS" WITHOUT WARRANTY OF ANY
//  KIND, EITHER EXPRESSED OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE
//  IMPLIED WARRANTIES OF MERCHANTABILITY AND/OR FITNESS FOR A PARTICULAR
//  PURPOSE.
//
//  Copyright (c) 1992 - 1999  Microsoft Corporation.  All Rights Reserved.
//
//--------------------------------------------------------------------------;

#include <streams.h>
#include <olectl.h>
#include <initguid.h>
#include <olectlid.h>
#include <viduids.h>
#include <oversrc.h>
#include <viddbg.h>


// List of class IDs and creator functions for the class factory. This
// provides the link between the OLE entry point in the DLL and an object
// being created. The class factory will call the static CreateInstance
// function when it is asked to create a CLSID_VideoRenderer COM object

CFactoryTemplate g_Templates[] = {
  { L"Overlay source",&CLSID_OverlaySource,CVideoSource::CreateInstance }
};
int g_cTemplates = sizeof(g_Templates) / sizeof(g_Templates[0]);


// Setup data

AMOVIESETUP_MEDIATYPE sudSourcePinTypes =
{
    &MEDIATYPE_Video,           // Major type
    &MEDIASUBTYPE_NULL          // And subtype
};

AMOVIESETUP_PIN sudSourcePin =
{
    L"Output",                  // The pin's name
    FALSE,                      // Is it rendered
    TRUE,                       // Is it an output
    FALSE,                      // Can we have zero
    FALSE,                      // Are many allowed
    &CLSID_NULL,                // Filter connects
    NULL,                       // And pin connects
    1,                          // Number of types
    &sudSourcePinTypes          // The pin details
};

AMOVIESETUP_FILTER sudSourceFilter =
{
    &CLSID_OverlaySource,       // Filter CLSID
    L"Video Source",            // String name
    MERIT_UNLIKELY,             // Filter merit
    1,                          // Number of pins
    &sudSourcePin               // Pin details
};

// Exported entry points for registration of server

STDAPI DllRegisterServer()
{
  return AMovieDllRegisterServer();
}

STDAPI DllUnregisterServer()
{
  return AMovieDllUnregisterServer();
}

// Return the filter's registry information

LPAMOVIESETUP_FILTER CVideoSource::GetSetupData()
{
  return &sudSourceFilter;
}


// This is the standard VGA colour palette

const RGBQUAD Palette[BUFFERCOLOURS] =
{
    {   0,   0,   0 },
    {   0,   0, 128 },
    {   0, 128,   0 },
    {   0, 128, 128 },
    { 128,   0,   0 },
    { 128,   0, 128 },
    { 128, 128,   0 },
    { 192, 192, 192 },
    { 128, 128, 128 },
    {   0,   0, 255 },
    {   0, 255,   0 },
    {   0, 255, 255 },
    { 255,   0,   0 },
    { 255,   0, 255 },
    { 255, 255,   0 },
    { 255, 255, 255 }
};


// Creator function for video source filters

CUnknown *CVideoSource::CreateInstance(LPUNKNOWN pUnk,HRESULT *phr)
{
    CUnknown *pObject = new CVideoSource(NAME("Overlay Source"),pUnk,phr);
    if (pObject == NULL) {
        NOTE("No object made");
        *phr = E_OUTOFMEMORY;
    }
    return pObject;
}


// Constructor

CVideoSource::CVideoSource(TCHAR *pName,
                           LPUNKNOWN pUnk,
                           HRESULT *phr) :

    CSource(pName,pUnk,CLSID_OverlaySource)
{
    // Allocate the array for the streams

    m_paStreams = (CSourceStream **) new CVideoStream *[1];
    if (m_paStreams == NULL) {
        *phr = E_OUTOFMEMORY;
        NOTE("No stream memory");
        return;
    }

    // Create the actual stream object

    m_paStreams[0] = new CVideoStream(phr,this,L"Source");
    if (m_paStreams[0] == NULL) {
        *phr = E_OUTOFMEMORY;
        NOTE("No stream object");
        return;
    }
}


// We only render when running so stop the thread when stopped

STDMETHODIMP CVideoSource::Stop()
{
    CAutoLock cObjectLock(m_pLock);

    // Have the base class stop first

    HRESULT hr = CSource::Stop();
    if (FAILED(hr)) {
        return hr;
    }
    return ((CVideoStream *) m_paStreams[0])->StopStreaming();
}


// We only render when running so stop the thread when paused

STDMETHODIMP CVideoSource::Pause()
{
    CAutoLock cObjectLock(m_pLock);

    // Have the base class stop first

    HRESULT hr = CSource::Pause();
    if (FAILED(hr)) {
        return hr;
    }
    return ((CVideoStream *) m_paStreams[0])->StopStreaming();
}


// Overriden to have the worker thread started

STDMETHODIMP CVideoSource::Run(REFERENCE_TIME tStart)
{
    CAutoLock cObjectLock(m_pLock);

    // Have the base class stop first

    HRESULT hr = CSource::Run(tStart);
    if (FAILED(hr)) {
        return hr;
    }
    return ((CVideoStream *) m_paStreams[0])->StartStreaming(tStart);
}


// Constructor

CVideoStream::CVideoStream(HRESULT *phr,
                           CVideoSource *pVideoSource,
                           LPCWSTR pPinName) :

    CSourceStream(NAME("Stream"),phr,pVideoSource,pPinName),
    CMediaPosition(NAME("Position"),CSourceStream::GetOwner()),
    m_pVideoSource(pVideoSource),
    m_StopFrame(DURATION-1),
    m_bNewSegment(TRUE),
    m_rtIncrement(INCREMENT),
    m_CurrentFrame(0),
    m_pOverlay(NULL),
    m_pBase(NULL),
    m_hMapping(NULL),
    m_hBitmap(NULL),
    m_hdcDisplay(NULL),
    m_hdcMemory(NULL),
    m_hFont(NULL),
    m_dbRate(1.0),
    m_pRgnData(NULL),
    m_StartFrame(0)
{
    NOTE("CVideoStream Constructor");
    ASSERT(pVideoSource);
    SetRectEmpty(&m_SourceRect);
    SetRectEmpty(&m_TargetRect);
}


// Destructor

CVideoStream::~CVideoStream()
{
    NOTE("CVideoStream Destructor");
    if (m_pRgnData) delete[] (CHAR *) m_pRgnData;
}


// Overriden to say what interfaces we support

STDMETHODIMP CVideoStream::NonDelegatingQueryInterface(REFIID riid,VOID **ppv)
{
    NOTE("Entering NonDelegatingQueryInterface");

    // We return IMediaPosition from here

    if (riid == IID_IMediaPosition) {
        NOTE("Returning IMediaPosition");
        return CMediaPosition::NonDelegatingQueryInterface(riid,ppv);
    } else if (riid == IID_IOverlayNotify) {
        NOTE("Returning IOverlayNotify");
        return GetInterface((IOverlayNotify *) this, ppv);
    }
    return CSourceStream::NonDelegatingQueryInterface(riid,ppv);
}


// Release the offscreen buffer resources

HRESULT CVideoStream::ReleaseNumbersFrame()
{
    NOTE("DeleteNumbersFrame");

    if (m_hBitmap) DeleteObject(m_hBitmap);
    if (m_hMapping) CloseHandle(m_hMapping);
    if (m_hdcDisplay) ReleaseDC(NULL,m_hdcDisplay);
    if (m_hdcMemory) DeleteDC(m_hdcMemory);
    if (m_hFont) DeleteObject(m_hFont);

    m_hMapping = NULL;
    m_hBitmap = NULL;
    m_pBase = NULL;
    m_hdcMemory = NULL;
    m_hdcDisplay = NULL;
    m_hFont = NULL;
    return NOERROR;
}


// The way we draw numbers into an image is to create an offscreen buffer. We
// create a bitmap from this and select it into an offscreen HDC. Using this
// we can draw the text using GDI. Once we have our image we can use the base
// buffer pointer from the CreateFileMapping call and copy each frame into it
// To be more efficient we could draw the text into a monochrome bitmap and
// read the bits set from it and generate the output image by setting pixels

HRESULT CVideoStream::InitNumbersFrame()
{
    NOTE("InitNumbersFrame");

    VIDEOINFO *pVideoInfo = (VIDEOINFO *) m_mt.Format();
    BITMAPINFO *pbmi = (BITMAPINFO *) HEADER(pVideoInfo);
    LONG InSize = pVideoInfo->bmiHeader.biSizeImage;

    // Create a file mapping object and map into our address space

    m_hMapping = CreateFileMapping(INVALID_HANDLE_VALUE,  // Use page file
                                   NULL,                  // No security used
                                   PAGE_READWRITE,        // Complete access
                                   (DWORD) 0,             // Less than 4Gb
                                   InSize,                // Size of buffer
                                   NULL);                 // No section name
    if (m_hMapping == NULL) {
        DWORD Error = GetLastError();
        NOTE("No file mappping");
        ReleaseNumbersFrame();
        return AmHresultFromWin32(Error);
    }

    // Now create the shared memory DIBSECTION

    m_hBitmap = CreateDIBSection((HDC) NULL,          // NO device context
                                 pbmi,                // Format information
                                 DIB_RGB_COLORS,      // Use the palette
                                 (VOID **) &m_pBase,  // Pointer to image data
                                 m_hMapping,          // Mapped memory handle
                                 (DWORD) 0);          // Offset into memory

    if (m_hBitmap == NULL || m_pBase == NULL) {
        DWORD Error = GetLastError();
        NOTE("No DIBSECTION made");
        ReleaseNumbersFrame();
        return AmHresultFromWin32(Error);
    }

    // Get a device context for the display

    m_hdcDisplay = GetDC(NULL);
    if (m_hdcDisplay == NULL) {
        NOTE("No device context");
        ReleaseNumbersFrame();
        return E_UNEXPECTED;
    }

    // Create an offscreen HDC for drawing into

    m_hdcMemory = CreateCompatibleDC(m_hdcDisplay);
    if (m_hdcMemory == NULL) {
        NOTE("No memory context");
        ReleaseNumbersFrame();
        return E_UNEXPECTED;
    }

    // Make a humungous font for the frame numbers

    m_hFont = CreateFont(GetHeightFromPointsString(TEXT("72")),0,0,0,400,0,0,0,
                         ANSI_CHARSET,OUT_DEFAULT_PRECIS,CLIP_DEFAULT_PRECIS,
                         DEFAULT_QUALITY,DEFAULT_PITCH | FF_SWISS,TEXT("ARIAL"));

    if (m_hFont == NULL) {
        NOTE("No large font");
        ReleaseNumbersFrame();
        return E_UNEXPECTED;
    }

    // Set the offscreen device properties

    SetBkColor(m_hdcMemory,RGB(0,0,0));
    SetTextColor(m_hdcMemory,RGB(255,255,255));
    SelectObject(m_hdcMemory,m_hFont);

    return NOERROR;
}


// Return the height for this point size

INT CVideoStream::GetHeightFromPointsString(LPCTSTR szPoints)
{
    HDC hdc;
    INT height;

    hdc = GetDC(NULL);
    height = MulDiv(-atoi(szPoints), GetDeviceCaps(hdc, LOGPIXELSY), 72);
    ReleaseDC(NULL, hdc);

    return height;
}


// Deliver new segment calls after a seek instruction

void CVideoStream::SendNewSegment()
{
    REFERENCE_TIME tStart,tStop;

    // Send the NewSegment call downstream

    if (m_bNewSegment == TRUE) {
        tStart = (REFERENCE_TIME) COARefTime(double(m_CurrentFrame) / double(FRAMERATE));
        tStop = (REFERENCE_TIME) COARefTime(double(m_StopFrame) / double(FRAMERATE));
        DeliverNewSegment(tStart,tStop,m_dbRate);
        NOTE2("Segment (Start %d Stop %d)",m_CurrentFrame,m_StopFrame);
    }
    m_bNewSegment = FALSE;
}


// PURE virtual placeholder that shouldn't ever be called

HRESULT CVideoStream::FillBuffer(IMediaSample *pSample)
{
    return E_UNEXPECTED;
}


// Returns TRUE if we should not access the window

BOOL CVideoStream::IsWindowFrozen()
{
    if (IsRectEmpty(&m_SourceRect) == FALSE) {
        if (IsRectEmpty(&m_TargetRect) == FALSE) {
            if (m_pRgnData) {
                if (m_pRgnData->rdh.nCount) {
                    return FALSE;
                }
            }
        }
    }
    return TRUE;
}


// This draws the current frame number onto the image. We must zero fill the
// frame holding buffer to clear any previous image, then we can draw a new
// frame number into the buffer (just using normal GDI calls). Having done
// that we can use the buffer pointer we originally saved when creating the
// buffer (actually a file mapping) and finally draw the image to the screen
// We return the time taken to draw a frame so we can synchronise the stream

HRESULT CVideoStream::DrawNextFrame()
{
    CAutoLock cAutoLock(&m_ClipLock);
    TCHAR szFrameNumber[64];

    // Is the window locked at the moment

    if (IsWindowFrozen() == TRUE) {
        return NOERROR;
    }

    // Reset the prospective back buffer

    VIDEOINFO *pVideoInfo = (VIDEOINFO *) m_mt.Format();
    BITMAPINFOHEADER *pbmi = HEADER(pVideoInfo);
    ZeroMemory(m_pBase,pVideoInfo->bmiHeader.biSizeImage);

    EXECUTE_ASSERT(SelectObject(m_hdcMemory,m_hBitmap));
    RECT TargetRect = {0,0,pbmi->biWidth,pbmi->biHeight};
    wsprintf(szFrameNumber,TEXT("%d"),m_CurrentFrame);
    UINT Options = DT_CENTER | DT_VCENTER | DT_SINGLELINE;

    DrawText(m_hdcMemory,       // Memory device context
             szFrameNumber,     // Holds string frame number
             (int) -1,          // Let it calculate length
             &TargetRect,       // Display in middle of image
             Options);          // Centred and single line

    // Draw the current frame onto the display

    RECT SourceRect,*pClipRect = (RECT *) m_pRgnData->Buffer;
    for (DWORD Count = 0;Count < m_pRgnData->rdh.nCount;Count++) {

        // Calculate which section of the source is needed

        SourceRect.left = pClipRect[Count].left - m_TargetRect.left;
        SourceRect.left *= WIDTH(&m_SourceRect);
        SourceRect.left /= WIDTH(&m_TargetRect);
        SourceRect.left += m_SourceRect.left;
        SourceRect.right = pClipRect[Count].right - m_TargetRect.left;
        SourceRect.right *= WIDTH(&m_SourceRect);
        SourceRect.right /= WIDTH(&m_TargetRect);
        SourceRect.right += m_SourceRect.left;
        SourceRect.top = pClipRect[Count].top - m_TargetRect.top;
        SourceRect.top *= HEIGHT(&m_SourceRect);
        SourceRect.top /= HEIGHT(&m_TargetRect);
        SourceRect.top += m_SourceRect.top;
        SourceRect.bottom = pClipRect[Count].bottom - m_TargetRect.top;
        SourceRect.bottom *= HEIGHT(&m_SourceRect);
        SourceRect.bottom /= HEIGHT(&m_TargetRect);
        SourceRect.bottom += m_SourceRect.top;

        NOTERC("Current clip",pClipRect[Count]);
        NOTERC("Source",m_SourceRect);
        NOTERC("Destination",m_TargetRect);
        NOTERC("Derived source",SourceRect);
        HDC hdcDisplay = GetDC(NULL);

        StretchBlt((HDC) hdcDisplay,            // Target device HDC
                   pClipRect[Count].left,       // Horizontal offset
                   pClipRect[Count].top,        // Vertical offset
                   WIDTH(&pClipRect[Count]),    // Height of destination
                   HEIGHT(&pClipRect[Count]),   // And likewise a width
                   (HDC) m_hdcMemory,           // Source device context
                   SourceRect.left,             // Horizontal offset
                   SourceRect.top,              // Vertical offset
                   WIDTH(&SourceRect),          // Height of source
                   HEIGHT(&SourceRect),         // And likewise a width
                   SRCCOPY);                    // Simple source copy

        GdiFlush();
        ReleaseDC(NULL,hdcDisplay);
    }
    return NOERROR;
}


// Overriden to return our single output format

HRESULT CVideoStream::GetMediaType(CMediaType *pmt)
{
    return GetMediaType(0,pmt);
}


// Also to make things simple we offer one image format. On most displays the
// RGB8 image will be directly displayable so when being rendered we won't get
// a colour space convertor put between us and the renderer to do a transform.
// It would be relatively straightforward to offer more formats like bouncing
// ball does but would only confuse the main point of showing off the workers

HRESULT CVideoStream::GetMediaType(int iPosition, CMediaType *pmt)
{
    NOTE("GetMediaType");

    // We only offer one media type

    if (iPosition) {
        NOTE("No more media types");
        return VFW_S_NO_MORE_ITEMS;
    }

    // Allocate an entire VIDEOINFO for simplicity

    pmt->AllocFormatBuffer(sizeof(VIDEOINFO));
    VIDEOINFO *pVideoInfo = (VIDEOINFO *) pmt->Format();
    if (pVideoInfo == NULL) {
	return E_OUTOFMEMORY;
    }

    ZeroMemory(pVideoInfo,sizeof(VIDEOINFO));

    // This describes the logical bitmap we will use

    BITMAPINFOHEADER *pHeader = HEADER(pVideoInfo);
    pVideoInfo->bmiHeader.biSize = sizeof(BITMAPINFOHEADER);
    pVideoInfo->bmiHeader.biWidth = BUFFERWIDTH;
    pVideoInfo->bmiHeader.biHeight = BUFFERHEIGHT;
    pVideoInfo->bmiHeader.biPlanes = 1;
    pVideoInfo->bmiHeader.biBitCount = 8;
    pVideoInfo->bmiHeader.biCompression = BI_RGB;
    pVideoInfo->bmiHeader.biClrUsed = BUFFERCOLOURS;
    pVideoInfo->bmiHeader.biClrImportant = BUFFERCOLOURS;
    pVideoInfo->bmiHeader.biSizeImage = GetBitmapSize(pHeader);

    // Copy the palette we draw to one colour at a time

    for (int Index = 0;Index < BUFFERCOLOURS;Index++) {
        pVideoInfo->bmiColors[Index].rgbRed = Palette[Index].rgbRed;
        pVideoInfo->bmiColors[Index].rgbGreen = Palette[Index].rgbGreen;
        pVideoInfo->bmiColors[Index].rgbBlue = Palette[Index].rgbBlue;
    }

    SetRectEmpty(&pVideoInfo->rcSource);
    SetRectEmpty(&pVideoInfo->rcTarget);

    pmt->SetType(&MEDIATYPE_Video);
    pmt->SetSubtype(&MEDIASUBTYPE_Overlay);
    pmt->SetFormatType(&FORMAT_VideoInfo);
    pmt->SetTemporalCompression(FALSE);
    pmt->SetSampleSize(pVideoInfo->bmiHeader.biSizeImage);

    return NOERROR;
}


// Called to initialise the output stream

HRESULT CVideoStream::OnThreadCreate()
{
    NOTE("OnThreadCreate");
    m_bNewSegment = TRUE;
    return NOERROR;
}


// Called when the worker threads is destroyed

HRESULT CVideoStream::OnThreadDestroy()
{
    NOTE("OnThreadDestroy");
    return NOERROR;
}


// We don't do any quality management

STDMETHODIMP CVideoStream::Notify(IBaseFilter *pSender,Quality q)
{
    NOTE("Notify");
    return NOERROR;
}


// We can only connect to the standard video renderer

HRESULT CVideoStream::CheckConnect(IPin *pPin)
{
    CAutoLock lock(GetLock());
    ASSERT(m_pOverlay == NULL);
    NOTE("Looking for IOverlay");

    // Make sure it is a valid pin

    HRESULT hr = CBasePin::CheckConnect(pPin);
    if (FAILED(hr)) {
        return hr;
    }

    // Query the pin for IOverlay transport

    pPin->QueryInterface(IID_IOverlay,(VOID**) &m_pOverlay);
    if (m_pOverlay == NULL) {
        NOTE("No IOverlay");
        return E_NOINTERFACE;
    }
    return NOERROR;
}


// We override this to avoid making buffer decisions

HRESULT CVideoStream::CompleteConnect(IPin *pPin)
{
    CAutoLock lock(GetLock());
    NOTE("CompleteConnect");
    ASSERT(m_pOverlay);
    InitNumbersFrame();

    return m_pOverlay->Advise((IOverlayNotify *) this, ADVISE_ALL);
}


// Overriden to avoid allocator commits

HRESULT CVideoStream::Active()
{
    CAutoLock lock(GetLock());
    if (m_pOverlay == NULL) {
        NOTE("No IOverlay");
        return E_UNEXPECTED;
    }
    return NOERROR;
}


// Overriden to avoid allocator decommits

HRESULT CVideoStream::Inactive()
{
    CAutoLock lock(GetLock());
    if (m_pOverlay == NULL) {
        NOTE("No IOverlay");
        return E_UNEXPECTED;
    }
    return NOERROR;
}


// Overriden to start the worker thread running - when we're paused or stopped
// we will still have an advise link set to the renderer and will handle clip
// changes by redrawing the current frame as it is delivered. When we are set
// running the worker thread reads the current clip list and draws the frames
// Therefore when stopped or paused we do not need a worker thread like other
// source filters do because there is no allocator going to stop us processing

HRESULT CVideoStream::StartStreaming(REFERENCE_TIME tStart)
{
    UNREFERENCED_PARAMETER(tStart);
    CAutoLock lock(GetLock());
    m_StartFrame = 0;

    // Check we are connected correctly

    if (m_pOverlay == NULL) {
        NOTE("No IOverlay");
        return E_UNEXPECTED;
    }

    // Start the worker thread

    if (Create() == FALSE) {
        return E_FAIL;
    }

    // Tell thread to initialize

    HRESULT hr = Init();
    if (FAILED(hr)) {
	return hr;
    }
    return CSourceStream::Pause();
}


// Called to stop the worker thread running

HRESULT CVideoStream::StopStreaming()
{
    CAutoLock lock(GetLock());
    if (ThreadExists() == FALSE) {
        return NOERROR;
    }

    // Stop the worker thread running

    HRESULT hr = Stop();
    if (FAILED(hr)) {
        return hr;
    }

    // Make the worker thread exit

    hr = Exit();
    if (FAILED(hr)) {
        return hr;
    }

    Close();
    return NOERROR;
}


// Must override this PURE virtual base class method

HRESULT CVideoStream::DecideBufferSize(IMemAllocator *pAlloc,ALLOCATOR_PROPERTIES *pProperties)
{
    NOTE("DecideBufferSize");
    return E_UNEXPECTED;
}


// Release any overlay interface we obtained

HRESULT CVideoStream::BreakConnect()
{
    NOTE("BreakConnect called");
    CAutoLock lock(GetLock());

    if (m_pOverlay) {
        m_pOverlay->Unadvise();
        m_pOverlay->Release();
        m_pOverlay = NULL;
    }

    ReleaseNumbersFrame();
    return NOERROR;
}


// We override this to handle any extra seeking mechanisms we might need. This
// is executed in the context of a worker thread. Messages may be sent to the
// worker thread through CallWorker. A call to CallWorker doesn't return until
// the worker thread has called Reply. This can be used to make sure we gain
// control of the thread, for example when flushing we should not complete the
// flush until the worker thread has returned and been stopped. We do not have
// buffers to fill from downstream allocators as we use the IOverlay transport

HRESULT CVideoStream::DoBufferProcessingLoop()
{
    Command com;

    do { while (CheckRequest(&com) == FALSE) {

            // Have we reached the end of stream yet

            if (m_CurrentFrame > m_StopFrame) {
                DeliverEndOfStream();
                Sleep(DELIVERWAIT);
                continue;
            }

            // Draw the frame and send any segment change

            SendNewSegment();
            DrawNextFrame();
            m_CurrentFrame++;

            // We do all the necessary synchronisation

            LONG EndFrame = timeGetTime() - m_StartFrame;
            Sleep(INCREMENT - min(INCREMENT,EndFrame));
            m_StartFrame = timeGetTime();
        }

        // Process the new thread message

        if (com == CMD_RUN || com == CMD_PAUSE) {
            Reply(NOERROR);
        } else if (com != CMD_STOP) {
   	    Reply(E_UNEXPECTED);
        }

    } while (com != CMD_STOP);

    return S_FALSE;
}


// Return the total duration for our media

STDMETHODIMP CVideoStream::get_Duration(REFTIME *pLength)
{
    NOTE("Entering get_Duration");
    CheckPointer(pLength,E_POINTER);
    CAutoLock cAutoLock(&m_SourceLock);
    *pLength = double(DURATION) / double(FRAMERATE);

    NOTE1("Duration %s",CDisp(*pLength));
    return NOERROR;
}


// Return the current position in seconds based on the current frame number

STDMETHODIMP CVideoStream::get_CurrentPosition(REFTIME *pTime)
{
    NOTE("Entering get_CurrentPosition");
    CheckPointer(pTime,E_POINTER);
    CAutoLock cAutoLock(&m_SourceLock);

    *pTime = double(m_CurrentFrame) / double(FRAMERATE);
    NOTE1("Position %s",CDisp(*pTime));
    return NOERROR;
}


// Set the new current frame number based on the time

STDMETHODIMP CVideoStream::put_CurrentPosition(REFTIME Time)
{
    CAutoLock StateLock(m_pVideoSource->pStateLock());
    BOOL bRunning = ThreadExists();

    // Stop the worker thread

    if (bRunning == TRUE) {
        DeliverBeginFlush();
        CallWorker(CMD_STOP);
        DeliverEndFlush();
    }

    // Only lock the object when updating the frame number

    NOTE1("put_CurrentPosition %s",CDisp(Time));
    m_CurrentFrame = (LONG) (double(FRAMERATE) * Time);
    m_CurrentFrame = min(m_CurrentFrame,DURATION - 1);
    NOTE1("Setting frame number to %d",m_CurrentFrame);

    // Restart the worker thread again

    m_bNewSegment = TRUE;
    DrawNextFrame();
    m_StartFrame = 0;

    if (bRunning == TRUE) {
        CallWorker(CMD_RUN);
    }
    return NOERROR;
}


// Return the current stop position

STDMETHODIMP CVideoStream::get_StopTime(REFTIME *pTime)
{
    CheckPointer(pTime,E_POINTER);
    CAutoLock cAutoLock(&m_SourceLock);
    *pTime = double(m_StopFrame) / double(FRAMERATE);
    NOTE1("get_StopTime %s",CDisp(*pTime));
    return NOERROR;
}


// Changing the stop time may cause us to flush already sent frames. If we're
// still inbound then the current position should be unaffected. If the stop
// position is before the current position then we effectively set them to be
// the same - setting a current position will have any data we've already sent
// to be flushed - note when setting a current position we must hold no locks

STDMETHODIMP CVideoStream::put_StopTime(REFTIME Time)
{
    NOTE1("put_StopTime %s",CDisp(Time));
    LONG StopFrame = LONG(double(Time) * double(FRAMERATE));
    NOTE1("put_StopTime frame %d",StopFrame);

    // Manually lock the filter

    m_SourceLock.Lock();
    m_bNewSegment = TRUE;
    m_StopFrame = StopFrame;

    // Are we still processing in range

    if (m_CurrentFrame < StopFrame) {
        m_SourceLock.Unlock();
        NOTE("Still in range");
        return NOERROR;
    }

    NOTE("Flushing sent data");
    m_SourceLock.Unlock();
    put_CurrentPosition(Time);
    return NOERROR;
}


// We have no preroll time mechanism

STDMETHODIMP CVideoStream::get_PrerollTime(REFTIME *pTime)
{
    NOTE("Entering get_PrerollTime");
    CheckPointer(pTime,E_POINTER);
    return E_NOTIMPL;
}


// We have no preroll time so ignore this call

STDMETHODIMP CVideoStream::put_PrerollTime(REFTIME Time)
{
    NOTE1("put_PrerollTime %s",CDisp(Time));
    CAutoLock cAutoLock(&m_SourceLock);
    return E_NOTIMPL;
}


// Return the current (positive only) rate

STDMETHODIMP CVideoStream::get_Rate(double *pdRate)
{
    NOTE("Entering Get_Rate");
    CheckPointer(pdRate,E_POINTER);
    CAutoLock cAutoLock(&m_SourceLock);
    *pdRate = m_dbRate;
    return NOERROR;
}


// Adjust the rate but only allow positive values

STDMETHODIMP CVideoStream::put_Rate(double dRate)
{
    NOTE1("put_Rate %s",CDisp(dRate));
    CAutoLock cAutoLock(&m_SourceLock);

    // Ignore negative and zero rates

    if (dRate <= double(0.0)) {
        return E_INVALIDARG;
    }

    // Calculate the time between successive frames

    m_dbRate = dRate;
    m_rtIncrement = (INCREMENT * 1000);
    m_rtIncrement /= LONGLONG(m_dbRate * 1000);
    return NOERROR;
}


// By default we can seek forwards

STDMETHODIMP CVideoStream::CanSeekForward(LONG *pCanSeekForward)
{
    CheckPointer(pCanSeekForward,E_POINTER);
    *pCanSeekForward = OATRUE;
    return S_OK;
}


// By default we can seek backwards

STDMETHODIMP CVideoStream::CanSeekBackward(LONG *pCanSeekBackward)
{
    CheckPointer(pCanSeekBackward,E_POINTER);
    *pCanSeekBackward = OATRUE;
    return S_OK;
}


// This is called with the colour key when it changes. What happens when we
// ask for a colour key through IOverlay is that the renderer selects one of
// the possible colours we pass in and notifies us of which one it is using
// It stores the original requirements so that should the display be changed
// through the control panel it can recalculate a suitable key and update
// all the notification interfaces (this isn't currently implemented though)

STDMETHODIMP CVideoStream::OnColorKeyChange(const COLORKEY *pColorKey)
{
    NOTE("Colour key callback");
    return NOERROR;
}


// Called when the window is primed on us or changed

STDMETHODIMP CVideoStream::OnWindowChange(HWND hwnd)
{
    NOTE("Window change callback");
    return NOERROR;
}


// This provides synchronous window clip changes so that the client is called
// before the window is moved to freeze the video, and then when the window
// (and display) has stabilised it is called again to start playback again.
// If the window rectangle is all zero then the window has been hidden. NOTE
// The filter must take a copy of the information if it wants to maintain it

STDMETHODIMP CVideoStream::OnClipChange(
    const RECT *pSourceRect,            // Area of video to play with
    const RECT *pDestinationRect,       // Area video goes
    const RGNDATA *pRgnData)            // Header describing clipping
{
    CAutoLock cAutoLock(&m_ClipLock);
    m_SourceRect = *pSourceRect;
    m_TargetRect = *pDestinationRect;

    NOTE("Overlay OnClipChange callback");
    NOTERC("Source",m_SourceRect);
    NOTERC("Target",m_TargetRect);
    NOTERC("Bounding",pRgnData->rdh.rcBound);
    NOTE1("Count %d",pRgnData->rdh.nCount);

    // Release any current clip list

    if (m_pRgnData) {
        delete[] (CHAR *) m_pRgnData;
        m_pRgnData = NULL;
    }

    // Are we being frozen

    if (pRgnData == NULL) {
        return NOERROR;
    }

    // Allocate the memory for the clip list

    LONG Size = sizeof(RGNDATAHEADER);
    Size += pRgnData->rdh.nCount * sizeof(RECT);
    m_pRgnData = (RGNDATA *) new CHAR[Size];

    if (m_pRgnData == NULL) {
        return E_OUTOFMEMORY;
    }

    // Copy the clip list and update the display

    CopyMemory(m_pRgnData,pRgnData,Size);
    DrawNextFrame();
    return NOERROR;
}


// This notifies the filter of palette changes, the filter should copy the
// array of RGBQUADs if it needs to use them after returning. If we set a
// palette through the IOverlay interface then we should see one of these
// This callback can be used by decoders that can decode to any colour set

STDMETHODIMP CVideoStream::OnPaletteChange(
    DWORD dwColors,                     // Number of colours present
    const PALETTEENTRY *pPalette)       // Array of palette colours
{
    NOTE("Palette callback");
    return NOERROR;
}


// The calls to OnClipChange happen in sync with the window. So it's called
// with an empty clip list before the window moves to freeze the video, and
// then when the window has stabilised it is called again with the new clip
// list. The OnPositionChange callback is for overlay cards that don't want
// the expense of synchronous clipping updates and just want to know when
// the source or destination video positions change. They will NOT be called
// in sync with the window but at some point after the window has changed
// (basicly in time with WM_SIZE etc messages received). This is therefore
// suitable for overlay cards that don't inlay their data to the framebuffer

STDMETHODIMP CVideoStream::OnPositionChange(
    const RECT *pSourceRect,            // Area of video to play with
    const RECT *pDestinationRect)       // Area on display video goes
{
    NOTE("Position or size callback");
    NOTERC("Source",(*pSourceRect));
    NOTERC("Target",(*pDestinationRect));
    return NOERROR;
}
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\multimedia\dshow\filters\image\stretch\stretch.cpp ===
//==========================================================================;
//
//  THIS CODE AND INFORMATION IS PROVIDED "AS IS" WITHOUT WARRANTY OF ANY
//  KIND, EITHER EXPRESSED OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE
//  IMPLIED WARRANTIES OF MERCHANTABILITY AND/OR FITNESS FOR A PARTICULAR
//  PURPOSE.
//
//  Copyright (c) 1992 - 1997  Microsoft Corporation.  All Rights Reserved.
//
//--------------------------------------------------------------------------;

// A Transform filter that stretches a video image as it passes through

#include <windows.h>
#include <streams.h>
#include <initguid.h>
#include <Stretch.h>


// List of class IDs and creator functions for the class factory. This
// provides the link between the OLE entry point in the DLL and an object
// being created. The class factory will call the static CreateInstance
// function when it is asked to create a CLSID_VideoRenderer COM object

CFactoryTemplate g_Templates[] = {

    {L"", &CLSID_Stretch, CStretch::CreateInstance},
};
int g_cTemplates = sizeof(g_Templates) / sizeof(g_Templates[0]);


// Setup data

AMOVIESETUP_MEDIATYPE sudStretchPinTypes =
{
    &MEDIATYPE_Video,           // Major
    &MEDIASUBTYPE_NULL          // Subtype
};

AMOVIESETUP_PIN sudStretchPin[] =
{
    { L"Input",                 // Name of the pin
      FALSE,                    // Is pin rendered
      FALSE,                    // Is an Output pin
      FALSE,                    // Ok for no pins
      FALSE,                    // Can we have many
      &CLSID_NULL,              // Connects to filter
      NULL,                     // Name of pin connect
      1,                        // Number of pin types
      &sudStretchPinTypes },    // Details for pins

    { L"Output",                // Name of the pin
      FALSE,                    // Is pin rendered
      TRUE,                     // Is an Output pin
      FALSE,                    // Ok for no pins
      FALSE,                    // Can we have many
      &CLSID_NULL,              // Connects to filter
      NULL,                     // Name of pin connect
      1,                        // Number of pin types
      &sudStretchPinTypes }     // Details for pins
};

AMOVIESETUP_FILTER sudStretchFilter =
{
    &CLSID_Stretch,             // CLSID of filter
    L"Stretch Video",           // Filter name
    MERIT_NORMAL,               // Filter merit
    2,                          // Number of pins
    sudStretchPin               // Pin information
};

// Exported entry points for registration of server

STDAPI DllRegisterServer()
{
  return AMovieDllRegisterServer();
}

STDAPI DllUnregisterServer()
{
  return AMovieDllUnregisterServer();
}

// Return the filter's registry information

LPAMOVIESETUP_FILTER CStretch::GetSetupData()
{
  return &sudStretchFilter;
}


// Constructor

CStretch::CStretch(LPUNKNOWN pUnk) :
    CTransformFilter(NAME("Stretch"),pUnk,CLSID_Stretch),
    m_lBufferRequest(1)
{
}


// This goes in the factory template table to create new filter instances

CUnknown *CStretch::CreateInstance(LPUNKNOWN punk, HRESULT *phr)
{
    CStretch *pNewObject = new CStretch(punk);
    if (pNewObject == NULL) {
        *phr = E_OUTOFMEMORY;
    }
    return pNewObject;
}


// Copy the input sample into the output sample and transform in place

HRESULT CStretch::Transform(IMediaSample *pIn, IMediaSample *pOut)
{
    // Copy the sample time

    REFERENCE_TIME TimeStart,TimeEnd;
    if (pIn->GetTime(&TimeStart,&TimeEnd) == NOERROR) {
	pOut->SetTime(&TimeStart,&TimeEnd);
    }

    // Copy the associated media times (if set)

    LONGLONG MediaStart,MediaEnd;
    if (pIn->GetMediaTime(&MediaStart,&MediaEnd) == NOERROR) {
        pOut->SetMediaTime(&MediaStart,&MediaEnd);
    }

    // Pass on the rest of the properties

    pOut->SetSyncPoint(TRUE);
    pOut->SetPreroll(pIn->IsPreroll() == S_OK);
    pOut->SetDiscontinuity(pIn->IsDiscontinuity() == S_OK);
    pOut->SetActualDataLength(pIn->GetActualDataLength());

    BYTE *pInBuffer, *pOutBuffer;
    pIn->GetPointer(&pInBuffer);
    pOut->GetPointer(&pOutBuffer);

    BITMAPINFOHEADER *pbiOut = HEADER(m_mtOut.Format());
    BITMAPINFOHEADER *pbiIn = HEADER(m_mtIn.Format());
    if (pbiIn->biCompression == MKFOURCC('Y','U','Y','2') ||
	pbiIn->biCompression == MKFOURCC('U','Y','V','Y')) {

	// cheat, stretch like RGB32
	DWORD biOutWidthSave = pbiOut->biWidth;
	DWORD biInWidthSave = pbiIn->biWidth;

	DWORD biCompressionSave = pbiIn->biCompression;

	// make the bitmaps seem like 32-bit RGB, but half as wide
	pbiOut->biCompression = BI_RGB;
	pbiIn->biCompression = BI_RGB;
	
	pbiOut->biBitCount = 32;
	pbiIn->biBitCount = 32;

	pbiOut->biWidth >>= 1;
	pbiIn->biWidth >>= 1;

	StretchDIB(pbiOut, pOutBuffer,
		   0, 0, pbiOut->biWidth, pbiOut->biHeight,
		   pbiIn, pInBuffer,
		   0, 0, pbiIn->biWidth, pbiIn->biHeight);

	// put back headers
	pbiOut->biCompression = biCompressionSave;
	pbiIn->biCompression = biCompressionSave;
	
	pbiOut->biBitCount = 16;
	pbiIn->biBitCount = 16;

	pbiOut->biWidth = biOutWidthSave;
	pbiIn->biWidth = biInWidthSave;
	
    } else {
	// normal RGB case

	StretchDIB(pbiOut, pOutBuffer,
		   0, 0, pbiOut->biWidth, pbiOut->biHeight,
		   pbiIn, pInBuffer,
		   0, 0, pbiIn->biWidth, pbiIn->biHeight);
    }

    return NOERROR;
}


// Check the source input type is acceptable

HRESULT CStretch::CheckInputType(const CMediaType *mtIn)
{
    // Check this is a VIDEOINFO type

    if (*mtIn->FormatType() != FORMAT_VideoInfo) {
        return E_INVALIDARG;
    }

    // Look at the major type to check for video

    if (*mtIn->Type() != MEDIATYPE_Video) {
        return E_INVALIDARG;
    }

    VIDEOINFO *pvi = (VIDEOINFO *) mtIn->Format();

    if ((pvi->bmiHeader.biCompression != BI_BITFIELDS) &&
        (pvi->bmiHeader.biCompression != BI_RGB) &&
        (pvi->bmiHeader.biCompression != MKFOURCC('U','Y','V','Y')) &&
        (pvi->bmiHeader.biCompression != MKFOURCC('Y','U','Y','2'))) {
	return E_INVALIDARG;
    }
    return NOERROR;
}


// Check we can transform from input to output

HRESULT CStretch::CheckTransform(const CMediaType *mtIn, const CMediaType *mtOut)
{
    HRESULT hr = CheckInputType(mtOut);
    if (FAILED(hr)) {
        return hr;
    }
    if (*mtIn->Subtype() == *mtOut->Subtype()) {
        return NOERROR;
    }
    return E_FAIL;
}


// Tell the output pin's allocator what size buffers we require

HRESULT CStretch::DecideBufferSize(IMemAllocator *pAlloc,ALLOCATOR_PROPERTIES *pProperties)
{
    ASSERT(pAlloc);
    ASSERT(pProperties);

    if (m_pInput->IsConnected() == FALSE) {
        return E_UNEXPECTED;
    }

    pProperties->cBuffers = 1;
    pProperties->cbBuffer = m_mtOut.GetSampleSize();

    ASSERT(pProperties->cbBuffer);

    // Ask the allocator to reserve us some sample memory, NOTE the function
    // can succeed (that is return NOERROR) but still not have allocated the
    // memory that we requested, so we must check we got whatever we wanted

    ALLOCATOR_PROPERTIES Actual;
    HRESULT hr = pAlloc->SetProperties(pProperties,&Actual);
    if (FAILED(hr)) {
        return hr;
    }

    // Check we got at least what we asked for

    if ((pProperties->cBuffers > Actual.cBuffers) ||
        (pProperties->cbBuffer > Actual.cbBuffer)) {
            return E_FAIL;
    }
    return NOERROR;
}


// Disconnected one of our pins

HRESULT CStretch::BreakConnect(PIN_DIRECTION dir)
{
    if (dir == PINDIR_INPUT) {
        m_mtIn.SetType(&GUID_NULL);
        return NOERROR;
    }

    ASSERT(dir == PINDIR_OUTPUT);
    m_mtOut.SetType(&GUID_NULL);
    return NOERROR;
}


// Tells us what media type we will be transforming

HRESULT CStretch::SetMediaType(PIN_DIRECTION direction,const CMediaType *pmt)
{
    if (direction == PINDIR_INPUT) {
        m_mtIn = *pmt;
        return NOERROR;
    }

    ASSERT(direction == PINDIR_OUTPUT);
    m_mtOut = *pmt;
    return NOERROR;
}


// I support one type namely the type of the input pin

HRESULT CStretch::GetMediaType(int iPosition, CMediaType *pMediaType)
{
    if (m_pInput->IsConnected() == FALSE) {
        return E_UNEXPECTED;
    }

    ASSERT(iPosition >= 0);
    if (iPosition > 0) {
        return VFW_S_NO_MORE_ITEMS;
    }
    *pMediaType = m_mtIn;
    return NOERROR;
}
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\multimedia\dshow\filters\image\stretch\stretch.h ===
//==========================================================================;
//
//  THIS CODE AND INFORMATION IS PROVIDED "AS IS" WITHOUT WARRANTY OF ANY
//  KIND, EITHER EXPRESSED OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE
//  IMPLIED WARRANTIES OF MERCHANTABILITY AND/OR FITNESS FOR A PARTICULAR
//  PURPOSE.
//
//  Copyright (c) 1992 - 1996  Microsoft Corporation.  All Rights Reserved.
//
//--------------------------------------------------------------------------;

// Stretch Filter Object

// { F97B8A60-31AD-11cf-B2DE-00DD01101B85 }
DEFINE_GUID(CLSID_Stretch,
0xf97b8a60, 0x31ad, 0x11cf, 0xb2, 0xde, 0x0, 0xdd, 0x1, 0x10, 0x1b, 0x85);

class CStretch : public CTransformFilter
{

public:

    static CUnknown *CreateInstance(LPUNKNOWN punk, HRESULT *phr);
    LPAMOVIESETUP_FILTER GetSetupData();

    HRESULT Transform(IMediaSample *pIn, IMediaSample *pOut);
    HRESULT CheckInputType(const CMediaType *mtIn);
    HRESULT CheckTransform(const CMediaType *mtIn, const CMediaType *mtOut);
    HRESULT DecideBufferSize(IMemAllocator *pAlloc,ALLOCATOR_PROPERTIES *pProperties);
    HRESULT GetMediaType(int iPosition, CMediaType *pMediaType);
    HRESULT SetMediaType(PIN_DIRECTION direction,const CMediaType *pmt);
    HRESULT BreakConnect(PIN_DIRECTION dir);

private:

    CStretch(LPUNKNOWN punk);

    HRESULT Copy(IMediaSample *pSource, IMediaSample *pDest) const;
    HRESULT Transform(IMediaSample *pMediaSample);

    CCritSec m_StretchLock;             // Internal play critical section
    CMediaType m_mtIn;                  // Source filter media type
    CMediaType m_mtOut;                 // Output connection media type
    const long m_lBufferRequest;        // Number of buffers to request
};


// This is what we use to do the real video stretch

extern "C" void FAR PASCAL StretchDIB(
	LPBITMAPINFOHEADER biDst,   //	BITMAPINFO of destination
	LPVOID	lpDst,		    //	The destination bits
	int	DstX,		    //	Destination origin - x coordinate
	int	DstY,		    //	Destination origin - y coordinate
	int	DstXE,		    //	x extent of the BLT
	int	DstYE,		    //	y extent of the BLT
	LPBITMAPINFOHEADER biSrc,   //	BITMAPINFO of source
	LPVOID	lpSrc,		    //	The source bits
	int	SrcX,		    //	Source origin - x coordinate
	int	SrcY,		    //	Source origin - y coordinate
	int	SrcXE,		    //	x extent of the BLT
	int	SrcYE); 	    //	y extent of the BLT
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\multimedia\dshow\filters\image\screen\screen.h ===
//==========================================================================;
//
//  THIS CODE AND INFORMATION IS PROVIDED "AS IS" WITHOUT WARRANTY OF ANY
//  KIND, EITHER EXPRESSED OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE
//  IMPLIED WARRANTIES OF MERCHANTABILITY AND/OR FITNESS FOR A PARTICULAR
//  PURPOSE.
//
//  Copyright (c) 1992 - 1996  Microsoft Corporation.  All Rights Reserved.
//
//--------------------------------------------------------------------------;

#ifndef _SCREEN__
#define _SCREEN__

#define FrameClass TEXT("ActiveMovieClass")
#define Title TEXT("ActiveMovie Test")

INT PASCAL WinMain(HINSTANCE hInstance,        // This instance identifier
                   HINSTANCE hPrevInstance,    // Previous instance
                   LPSTR lpszCmdLine,          // Command line parameters
                   INT nCmdShow);              // Initial display mode

LRESULT CALLBACK FrameWndProc(HWND hwnd,        // Our window handle
                              UINT message,     // Message information
                              UINT wParam,      // First parameter
                              LONG lParam);     // And other details

HRESULT FullScreenVideo(TCHAR *pFileName);
IPin *FindVideoPin(IFilterGraph *pGraph);
IBaseFilter *FindModexFilter(IFilterGraph *pGraph);
IPin *FindModexPin(IBaseFilter *pFilter);
HRESULT DoPlayFullScreen(IFilterGraph *pGraph);
HRESULT EnableRightModes(IFullScreenVideo *pFullVideo);
HRESULT PlayFullScreen(IFilterGraph *pGraph);
void MeasureLoadTime();
HRESULT WaitForCompletion(IFilterGraph *pGraph);

HRESULT ConnectModexFilter(IFilterGraph *pGraph,
                           IBaseFilter *pModexFilter,
                           IPin *pVideoPin,
                           IPin *pModexPin);

#endif // _SCREEN__
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\multimedia\dshow\filters\image\vidcrtx\vidcrtx.h ===
//==========================================================================;
//
//  THIS CODE AND INFORMATION IS PROVIDED "AS IS" WITHOUT WARRANTY OF ANY
//  KIND, EITHER EXPRESSED OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE
//  IMPLIED WARRANTIES OF MERCHANTABILITY AND/OR FITNESS FOR A PARTICULAR
//  PURPOSE.
//
//  Copyright (c) 1992 - 1996  Microsoft Corporation.  All Rights Reserved.
//
//--------------------------------------------------------------------------;

#ifndef __VIDCRTX__
#define __VIDCRTX__

#define FRAMERATE 25                // Default to 25 frames per second
#define INCREMENT (1000/25)         // Set according to the frame rate
#define BUFFERWIDTH 500             // Default to this wide backbuffer
#define BUFFERHEIGHT 80             // And likewise 80 pixels deep
#define BUFFERSIZE 40000            // Total size of the back buffer
#define BUFFERCOLOURS 16            // Number of colours we draw with
#define TYPEFACE "ARIAL BOLD"       // Font we use to draw the names
#define BUFFERFONTS 5               // Number of display fonts we use
#define BUFFERLETTERS 53            // Total letters we use and space
#define BUFFERLOOPS 50              // Number of times we loop per name
#define BUFFERHALF 25               // This must be half of BUFFERLOOPS
#define BUFFERUPPER 26              // First uppercase letter in array
#define BUFFERNAMES 49              // Number of peoples names we have
#define BUFFERVOWELS 5              // The vowels we offset vertically
#define BUFFERTEXTHEIGHT 45         // Allow this many lines in source
#define BUFFERWAIT 5                // Wait this long after each name
#define BUFFERREALWAIT 2000         // Additional wait at the good times
#define BUFFEROFFSET 50             // Always start drawing this far in
#define BUFFERSQUASH 4              // Power of two we squash letters in
#define BUFFERMAXHEIGHT 140         // Don't make the letters too large

#define DURATION (BUFFERNAMES * BUFFERLOOPS)

// This is the main filter class. As with most source filters all the work is
// done in the pin classes (our CVideoStream objects). This object is left to
// manage the COM CreateInstance hooking. In our constructor we create a pin
// for the base source class, it can then look after all the filter workings

class CVideoSource : public CSource
{
public:

    CVideoSource(TCHAR *pName,LPUNKNOWN lpunk,HRESULT *phr);
    static CUnknown *CreateInstance(LPUNKNOWN lpunk, HRESULT *phr);
};


// This is the main source class, we implement IMediaPosition on the output
// pin as we have a fixed number of frames. Each frame has a time stamp but
// we just run flat out to make the transitions look as smooth as possible.
// We make sure we run flat out by setting a NULL sync source downstream on
// the video renderer - only by doing that can we block quality management.

class CVideoStream : public CSourceStream, public CMediaPosition
{
public:

    CVideoStream(HRESULT *phr,CVideoSource *pVideoSource,LPCWSTR pPinName);
    ~CVideoStream();

    // Provide an IUnknown for our filter

    STDMETHODIMP QueryInterface(REFIID riid, void **ppv) {
        return CSourceStream::GetOwner()->QueryInterface(riid,ppv);
    };
    STDMETHODIMP_(ULONG) AddRef() {
        return CSourceStream::GetOwner()->AddRef();
    };
    STDMETHODIMP_(ULONG) Release() {
        return CSourceStream::GetOwner()->Release();
    };

    // Ask for buffers of the size appropriate to the agreed media type
    HRESULT DecideBufferSize(IMemAllocator *pIMemAlloc,ALLOCATOR_PROPERTIES *pProperties);

    // Expose the IMediaPosition and interface
    STDMETHODIMP NonDelegatingQueryInterface(REFIID riid,VOID **ppv);

    HRESULT GetMediaType(int iPosition, CMediaType *pmt);
    HRESULT GetMediaType(CMediaType *pmt);
    HRESULT OnThreadCreate();
    HRESULT OnThreadDestroy();
    HRESULT FillBuffer(IMediaSample *pms);
    HRESULT DrawCurrentFrame(BYTE *pBuffer);
    INT GetHeightFromPointsString(LPCTSTR szPoints);
    HRESULT DoBufferProcessingLoop();

    // These look after drawing the images

    LONG GetWidthFromLetter(TCHAR Letter);
    int lstrlenAInternal(const TCHAR *pString);
    COLORREF GetActiveColour(LONG Letter);
    void PrepareLetterSizes(HDC hdcNames);
    LONG GetHeightFromLetter(TCHAR Letter);
    HRESULT ReleaseBackBuffer();
    HRESULT CreateBackBuffer();

public:

    // IMediaPosition properties

    STDMETHODIMP get_Duration(REFTIME *pLength);
    STDMETHODIMP put_CurrentPosition(REFTIME Time);
    STDMETHODIMP get_CurrentPosition(REFTIME *pTime);
    STDMETHODIMP get_StopTime(REFTIME *pTime);
    STDMETHODIMP put_StopTime(REFTIME Time);
    STDMETHODIMP get_PrerollTime(REFTIME *pTime);
    STDMETHODIMP put_PrerollTime(REFTIME Time);
    STDMETHODIMP get_Rate(double *pdRate);
    STDMETHODIMP put_Rate(double dRate);
    STDMETHODIMP CanSeekForward(LONG *pCanSeekForward);
    STDMETHODIMP CanSeekBackward(LONG *pCanSeekBackward);

private:

    CCritSec m_SourceLock;          // A play lock rather than state lock
    REFERENCE_TIME m_rtSampleTime;  // The next sample will get this time
    REFERENCE_TIME m_rtIncrement;   // Time difference between the samples
    CVideoSource *m_pVideoSource;   // Holds our parent video source filter
    LONG m_CurrentFrame;            // Contains the current frame number
    LONG m_StopFrame;               // Holds the last frame number to send
    BYTE *m_pBase;                  // Pointer to the actual image buffer
    HANDLE m_hMapping;              // Handle to memory mapping object
    HBITMAP m_hBitmap;              // The DIB section bitmap handle
    HDC m_hdcDisplay;               // Device context for the main display
    HDC m_hdcMemory;                // Use this to draw our current frame
    HFONT m_hFont;                  // Font used to draw the frame numbers
    double m_dbRate;                // Currently selected filtergraph rate
    BOOL m_bNewSegment;             // Should we send a new segment call
    LONG m_StartSegment;            // Start time when we began a segment
};

#endif // __VIDCRTX__
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\multimedia\dshow\filters\image\vidcrtx\vidcrtx.cpp ===
//==========================================================================;
//
//  THIS CODE AND INFORMATION IS PROVIDED "AS IS" WITHOUT WARRANTY OF ANY
//  KIND, EITHER EXPRESSED OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE
//  IMPLIED WARRANTIES OF MERCHANTABILITY AND/OR FITNESS FOR A PARTICULAR
//  PURPOSE.
//
//  Copyright (c) 1992 - 1999  Microsoft Corporation.  All Rights Reserved.
//
//--------------------------------------------------------------------------;

#include <streams.h>
#include <olectl.h>
#include <initguid.h>
#include <olectlid.h>
#include <vidcrtx.h>

DEFINE_GUID(CLSID_VideoExtensions,
0x351a1c70, 0xbf7f, 0x11cf, 0xbc, 0x20, 0x00, 0xaa, 0x00, 0xac, 0x74, 0xf6);

SIZE LetterSize[BUFFERLETTERS];

TCHAR Letters[BUFFERLETTERS] = {
    'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k',
    'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v',
    'w', 'x', 'y', 'z', 'A', 'B', 'C', 'D', 'E', 'F', 'G',
    'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R',
    'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', ' '
};

const RGBQUAD BackBufferPalette[BUFFERCOLOURS] =
{
    {   0,   0,   0 },
    {   0,   0, 128 },
    {   0, 128,   0 },
    {   0, 128, 128 },
    { 128,   0,   0 },
    { 128,   0, 128 },
    { 128, 128,   0 },
    { 192, 192, 192 },
    { 128, 128, 128 },
    {   0,   0, 255 },
    {   0, 255,   0 },
    {   0, 255, 255 },
    { 255,   0,   0 },
    { 255,   0, 255 },
    { 255, 255,   0 },
    { 255, 255, 255 }
};


TCHAR *MovieNames[BUFFERNAMES] = {

"\xd4\xe9\xe7\xa3\xc5\xe6\xf2\xee\xfe\xec\xc7\xe4\xfa\xe4\xeb\xaf\xc4\xf4\xf3"
"\xfe","\xc0\xe6\xe2\xe9\xa5\xc1\xeb\xe9\xfa\xf9","\xc0\xee\xea\xf7\xf1\xe7"
"\xee\xfa\xa9\xc8\xea\xe2\xe6\xfd","\xc0\xee\xec\xef\xa5\xc5\xef\xe9\xe2\xf8"
"\xea\xee\xec\xfc\xfb\xf9","\xc5\xe8\xef\xf3\xa8\xca\xe2\xea\xf8\xf9\xeb\xfd"
"\xfa\xf4\xf7","\xc0\xec\xe7\xf6\xe0\xf1\xa7\xca\xec\xe6\xe7","\xc1\xef\xe6"
"\xf1\xe1\xf2\xa6\xc0\xfd\xf0","\xc0\xec\xf7\xec\xea\xe8\xfe\xa8\xd9\xe2\xe2"
"\xe0\xe1\xe7\xff\xe3","\xc6\xf7\xef\xe6\xe6\xa9\xce\xee\xe2\xe3\xe7\xfc",
"\xca\xe2\xea\xe2\xe3\xe7\xe1\xf7\xb1\xc4\xf6\xe6\xf7\xf3\xf4\xf3","\xc6\xf4"
"\xee\xfb\xfd\xe3\xea\xe2\xe2\xae\xdf\xf9\xf4\xe0\xe1\xed","\xc5\xe3\xed\xea"
"\xfc\xa6\xca\xe1\xe5\xe6\xee\xfe","\xce\xea\xfa\xe4\xea\xaf\xdd\xf0\xeb\xfe"
"\xe1\xf1\xf3\xe4","\xc3\xed\xeb\xe8\xe2\xe9\xad\xd9\xee\xe4\xfa\xfb\xfd\xe7",
"\xc0\xe0\xf4\xe2\xe3\xa9\xd9\xe7\xe3\xe3\xeb","\xc5\xed\xed\xa4\xc2\xef\xeb"
"\xea\xec\xf8\xff","\xcb\xff\xff\xfc\xb3\xd9\xfa\xe4\xe4\xfd","\xca\xeb\xfd"
"\xf1\xf8\xfc\xe7\xb4\xd1\xf7\xe1\xf1\xfc\xe9","\xcc\xe0\xe8\xec\xaf\xdb\xe3"
"\xfb\xe5\xfb\xe6\xfe\xf2\xfd\xef","\xce\xf8\xee\xeb\xad\xcc\xe3\xff\xfe\xe0",
"\xcd\xe9\xe4\xef\xf8\xac\xcb\xfb\xe1\xf1\xe3\xfd","\xcf\xe7\xfe\xa8\xcb\xe5"
"\xf9\xff\xe8\xfa\xe7","\xc9\xe5\xfc\xa6\xd3\xe7\xfb\xe8\xe4\xfe\xea","\xcb"
"\xeb\xef\xe8\xa5\xce\xe2\xe9\xe5","\xd2\xf6\xf2\xf5\xbc\xd9\xff\xed\xcc\xc8"
"\xcc\xc4\xd0\xca\xc8","\xdd\xf7\xf1\xf4\xbb\xd7\xf3\xf1\xfa\xcc\xcd\xc7\xd1",
"\xdc\xf8\xf0\xf7\xba\xd6\xff\xdc\xf2\xfa\xc5\xcd\xdb","\xdf\xf9\xff\xf6\xb9"
"\xcb\xee\xf5\xfe\xf5","\xde\xfa\xfe\xf9\xb8\xcb\xf5\xfc\xf9\xef\xed","\xd9"
"\xf5\xf6\xfd\xb7\xcb\xed\xff\xeb\xf4\xf8\xf0\xec","\xd8\xfc\xfa\xb5\xdb\xf6"
"\xea\xea\xf2\xfa\xf0\xf1","\xdb\xfd\xe1\xf3\xb5\xd4\xf6\xed\xfc\xe8","\xdc"
"\xf0\xe7\xe1\xfd\xf0\xb6\xd0\xea\xf0\xfc\xfd\xf5\xe9\xf6\xec","\xc2\xf9\xfa"
"\xf7\xb3\xd3\xfc\xf4\xe4\xf7\xf7","\xc3\xe6\xfb\xf4\xb2\xc1\xf1\xf1\xfb\xf8"
"\xf6\xfd","\xc0\xe7\xec\xf8\xf0\xf7\xff\xb4\xc6\xf7\xe1\xf9\xfe\xff","\xc1"
"\xe4\xe5\xea\xb0\xc5\xe0\xfa\xf7\xfe\xf3\xe5","\xdb\xe9\xf9\xeb\xfd\xb0\xd6"
"\xfb\xf1\xf6\xe6","\xd8\xe2\xef\xe5\xef\xfd\xf4\xb1\xd8\xf6\xe6\xfb\xff\xf0"
"\xf9\xf7","\xdb\xe3\xe8\xe4\xec\xfc\xeb\xb0\xc2\xf3\xe6\xf1\xe7","\xda\xe0"
"\xe9\xe0\xac\xcf\xef\xf7\xe4\xf4\xe0","\xd5\xe7\xeb\xe3\xe5\xac\xde\xfe\xea"
"\xf5\xf5","\xd5\xf3\xed\xf9\xe2\xee\xe2\xad\xcc\xee\xe2\xf6\xf7\xff\xe0",
"\xd6\xf2\xe2\xf8\xe1\xef\xe5\xac\xc8\xfd\xfb\xe2\xfe\xe2","\xd7\xf1\xe3\xf1"
"\xed\xa9\xc8\xea\xe2\xeb\xe7\xea\xfc\xf5","\xd0\xf0\xe0\xf0\xe2\xa8\xcb\xef"
"\xe5\xe8\xe8\xfa\xfb\xff","\xd1\xf7\xe1\xf3\xe3\xa7\xcc\xe8\xfc\xe2\xe9\xfe",
"\xd2\xf6\xe6\xf2\xe0\xa6\xd5\xe9\xe7\xef\xf2","\xd3\xf8\xed\xed\xa4\xc7\xee"
"\xe6\xfc\xfd\xeb\xe8\xe4\xec\xfc\xf6\xf1"
};


// List of class IDs and creator functions for the class factory. This
// provides the link between the OLE entry point in the DLL and an object
// being created. The class factory will call the static CreateInstance
// function when it is asked to create a CLSID_VideoRenderer COM object

CFactoryTemplate g_Templates[] = {
  { L"Video source",&CLSID_VideoExtensions,CVideoSource::CreateInstance }
};
int g_cTemplates = sizeof(g_Templates) / sizeof(g_Templates[0]);


// Creator function for video source filters

CUnknown *CVideoSource::CreateInstance(LPUNKNOWN pUnk,HRESULT *phr)
{
    CUnknown *pObject = new CVideoSource(NAME("Video Source"),pUnk,phr);
    if (pObject == NULL) {
        NOTE("No object made");
        *phr = E_OUTOFMEMORY;
    }
    return pObject;
}


// Constructor

CVideoSource::CVideoSource(TCHAR *pName,
                           LPUNKNOWN pUnk,
                           HRESULT *phr) :

    CSource(pName,pUnk,CLSID_VideoExtensions)
{
    // Allocate the array for the streams

    m_paStreams = (CSourceStream **) new CVideoStream *[1];
    if (m_paStreams == NULL) {
        *phr = E_OUTOFMEMORY;
        NOTE("No stream memory");
        return;
    }

    // Create the actual stream object

    m_paStreams[0] = new CVideoStream(phr,this,L"Source");
    if (m_paStreams[0] == NULL) {
        *phr = E_OUTOFMEMORY;
        NOTE("No stream object");
        return;
    }
}


// Constructor

CVideoStream::CVideoStream(HRESULT *phr,
                           CVideoSource *pVideoSource,
                           LPCWSTR pPinName) :

    CSourceStream(NAME("Stream"),phr,pVideoSource,pPinName),
    CMediaPosition(NAME("Position"),CSourceStream::GetOwner()),
    m_pVideoSource(pVideoSource),
    m_StopFrame(DURATION-1),
    m_bNewSegment(TRUE),
    m_rtSampleTime(0),
    m_CurrentFrame(0),
    m_pBase(NULL),
    m_hMapping(NULL),
    m_hBitmap(NULL),
    m_hdcDisplay(NULL),
    m_hdcMemory(NULL),
    m_hFont(NULL),
    m_dbRate(1.0),
    m_StartSegment(0)
{
    NOTE("CVideoStream Constructor");
    ASSERT(pVideoSource);
    m_rtIncrement = MILLISECONDS_TO_100NS_UNITS(INCREMENT);
}


// Destructor

CVideoStream::~CVideoStream()
{
    NOTE("CVideoStream Destructor");
}


// Overriden to say what interfaces we support

STDMETHODIMP CVideoStream::NonDelegatingQueryInterface(REFIID riid,VOID **ppv)
{
    NOTE("Entering NonDelegatingQueryInterface");

    // We return IMediaPosition from here

    if (riid == IID_IMediaPosition) {
        return CMediaPosition::NonDelegatingQueryInterface(riid,ppv);
    }
    return CSourceStream::NonDelegatingQueryInterface(riid,ppv);
}


// Release the offscreen buffer resources

HRESULT CVideoStream::ReleaseBackBuffer()
{
    NOTE("ReleaseBackBuffer");

    if (m_hBitmap) DeleteObject(m_hBitmap);
    if (m_hMapping) CloseHandle(m_hMapping);
    if (m_hdcDisplay) ReleaseDC(NULL,m_hdcDisplay);
    if (m_hdcMemory) DeleteDC(m_hdcMemory);
    if (m_hFont) DeleteObject(m_hFont);

    m_hMapping = NULL;
    m_hBitmap = NULL;
    m_pBase = NULL;
    m_hdcMemory = NULL;
    m_hdcDisplay = NULL;
    m_hFont = NULL;
    return NOERROR;
}


// The way we draw numbers into an image is to create an offscreen buffer. We
// create a bitmap from this and select it into an offscreen HDC. Using this
// we can draw the text using GDI. Once we have our image we can use the base
// buffer pointer from the CreateFileMapping call and copy each frame into it
// To be more efficient we could draw the text into a monochrome bitmap and
// read the bits set from it and generate the output image by setting pixels

HRESULT CVideoStream::CreateBackBuffer()
{
    NOTE("CreateBackBuffer");

    VIDEOINFO *pVideoInfo = (VIDEOINFO *) m_mt.Format();
    BITMAPINFO *pbmi = (BITMAPINFO *) HEADER(pVideoInfo);
    LONG InSize = pVideoInfo->bmiHeader.biSizeImage;

    // Create a file mapping object and map into our address space

    m_hMapping = CreateFileMapping(INVALID_HANDLE_VALUE,  // Use page file
                                   NULL,                  // No security used
                                   PAGE_READWRITE,        // Complete access
                                   (DWORD) 0,             // Less than 4Gb
                                   InSize,                // Size of buffer
                                   NULL);                 // No section name
    if (m_hMapping == NULL) {
        DWORD Error = GetLastError();
        NOTE("No file mappping");
        ReleaseBackBuffer();
        return AmHresultFromWin32(Error);
    }

    // Now create the shared memory DIBSECTION

    m_hBitmap = CreateDIBSection((HDC) NULL,          // NO device context
                                 pbmi,                // Format information
                                 DIB_RGB_COLORS,      // Use the palette
                                 (VOID **) &m_pBase,  // Pointer to image data
                                 m_hMapping,          // Mapped memory handle
                                 (DWORD) 0);          // Offset into memory

    if (m_hBitmap == NULL || m_pBase == NULL) {
        DWORD Error = GetLastError();
        NOTE("No DIBSECTION made");
        ReleaseBackBuffer();
        return AmHresultFromWin32(Error);
    }

    // Get a device context for the display

    m_hdcDisplay = GetDC(NULL);
    if (m_hdcDisplay == NULL) {
        NOTE("No device context");
        ReleaseBackBuffer();
        return E_UNEXPECTED;
    }

    // Create an offscreen HDC for drawing into

    m_hdcMemory = CreateCompatibleDC(m_hdcDisplay);
    if (m_hdcMemory == NULL) {
        NOTE("No memory context");
        ReleaseBackBuffer();
        return E_UNEXPECTED;
    }

    // Make a humungous font for the frame numbers

    m_hFont = CreateFont(GetHeightFromPointsString(TEXT("48")),0,0,0,400,0,0,0,
                         ANSI_CHARSET,OUT_DEFAULT_PRECIS,CLIP_DEFAULT_PRECIS,
                         DEFAULT_QUALITY,DEFAULT_PITCH | FF_SWISS,TEXT("ARIAL BOLD"));

    if (m_hFont == NULL) {
        NOTE("No large font");
        ReleaseBackBuffer();
        return E_UNEXPECTED;
    }

    // Set the offscreen device properties

    SetBkColor(m_hdcMemory,RGB(0,0,0));
    SelectObject(m_hdcMemory,m_hFont);
    SetStretchBltMode(m_hdcMemory,COLORONCOLOR);
    PrepareLetterSizes(m_hdcMemory);
    SetBkMode(m_hdcMemory,TRANSPARENT);

    return NOERROR;
}


// Return the height for this point size

INT CVideoStream::GetHeightFromPointsString(LPCTSTR szPoints)
{
    HDC hdc = GetDC(NULL);
    INT height = MulDiv(-atoi(szPoints), GetDeviceCaps(hdc, LOGPIXELSY), 72);
    ReleaseDC(NULL, hdc);

    return height;
}


// Return the text width for the given letter in our font

LONG CVideoStream::GetWidthFromLetter(TCHAR Letter)
{
    // Special case the darn space character

    if (Letter == ' ') {
        return LetterSize[BUFFERLETTERS - 1].cx;
    }

    // Is this an uppercase letter

    if (Letter >= 'A' && Letter <= 'Z') {
        return LetterSize[BUFFERUPPER + Letter - 'A'].cx;
    }
    return LetterSize[Letter - 'a'].cx;
}


// Return the text height for the given letter in our font

LONG CVideoStream::GetHeightFromLetter(TCHAR Letter)
{
    // Special case the darn space character

    if (Letter == ' ') {
        return LetterSize[BUFFERLETTERS - 1].cy;
    }

    // Is this an uppercase letter

    if (Letter >= 'A' && Letter <= 'Z') {
        return LetterSize[BUFFERUPPER + Letter - 'A'].cy;
    }
    return LetterSize[Letter - 'a'].cy;
}


// Internal string length function that ignores spaces

int CVideoStream::lstrlenAInternal(const TCHAR *pString)
{
    int i = -1;
    while (*(pString+(++i)))
        ;
    return i;
}


// For each letter of each name allocate a different colour

COLORREF CVideoStream::GetActiveColour(LONG Letter)
{
    LONG Colour = (Letter % (BUFFERCOLOURS - 1)) + 1;
    return RGB(BackBufferPalette[Colour].rgbRed,
               BackBufferPalette[Colour].rgbGreen,
               BackBufferPalette[Colour].rgbBlue);
}


// Prepare the width and vertical offset for each letter

void CVideoStream::PrepareLetterSizes(HDC hdcNames)
{
    TCHAR Vowels[BUFFERVOWELS] = { 'a', 'e', 'i', 'o', 'u' };

    // Load up an array with the sizes of each letter

    for (int Index = 0;Index < BUFFERLETTERS;Index++) {
        GetTextExtentPoint32(hdcNames,&Letters[Index],1,&LetterSize[Index]);
        LetterSize[Index].cy = 0;
        for (int Vowel = 0;Vowel < BUFFERVOWELS;Vowel++) {
            if (Letters[Index] == Vowels[Vowel]) {
                LetterSize[Index].cy = 4;
            }
        }
    }
}


// This draws the current frame number onto the image. We must zero fill the
// frame holding buffer to clear any previous image, then we can draw a new
// frame number into the buffer (just using normal GDI calls). Having done
// that we can use the buffer pointer we originally saved when creating the
// buffer (actually a file mapping) and copy the data into the output buffer

HRESULT CVideoStream::DrawCurrentFrame(BYTE *pBuffer)
{
    VIDEOINFO *pVideoInfo = (VIDEOINFO *) m_mt.Format();
    BITMAPINFOHEADER *pbmi = HEADER(pVideoInfo);
    ZeroMemory(m_pBase,pVideoInfo->bmiHeader.biSizeImage);
    EXECUTE_ASSERT(SelectObject(m_hdcMemory,m_hBitmap));
    TCHAR DecodeString[24];

    // Work out which name and loop we are on

    LONG Width = 0, Name = (m_CurrentFrame / BUFFERLOOPS);
    LONG Loop = m_CurrentFrame % BUFFERLOOPS;
    const TCHAR *pName = MovieNames[Name];
    LONG Length = lstrlenAInternal(pName);

    // Decode the current string from the data segment

    INT Encrypt = BUFFERNAMES % (Name + 1);
    for (int Letter = 0;Letter < Length;Letter++) {
        DecodeString[Letter] = (BYTE)(pName[Letter] ^(128 | (Encrypt++ & 127)));
    }
    DecodeString[Letter] = '\0';

    // Pause as we reach the halfway point

    pName = DecodeString;
    if (m_bNewSegment == FALSE) {
        if (Loop == BUFFERHALF) {
            LONG EndSegment = timeGetTime() - m_StartSegment;
            Sleep(BUFFERREALWAIT - min(BUFFERREALWAIT,EndSegment));
            m_StartSegment = timeGetTime();
        }
    }

    // Calculate the length of the entire word

    if (Name == 0) Loop = max(BUFFERHALF,Loop);
    for (Letter = 0;Letter < Length;Letter++) {
        LONG LetterWidth = GetWidthFromLetter(pName[Letter]);
        Width += (LetterWidth >> BUFFERSQUASH);
        LONG RealLoop = (Loop < BUFFERHALF ? Loop : BUFFERHALF - (Loop - BUFFERHALF));
        Width += (LetterWidth * RealLoop / (BUFFERLOOPS * 3 / 4));
    }

    // Draw each letter of the name in a different colour

    LONG Position = (BUFFERWIDTH - Width) / 2;
    for (Letter = 0;Letter < Length;Letter++) {
        COLORREF TextColor = GetActiveColour(Letter);
        SetTextColor(m_hdcMemory,TextColor);
        TextOut(m_hdcMemory,Position,GetHeightFromLetter(*pName),pName,1);
        LONG Width = GetWidthFromLetter(*pName++);
        Position += (Width >> BUFFERSQUASH);
        Width -= (Width >> BUFFERSQUASH);
        LONG RealLoop = (Loop < BUFFERHALF ? Loop : BUFFERHALF - (Loop - BUFFERHALF));
        Position += (Width * RealLoop / (BUFFERLOOPS * 3 / 4));
    }

    // Without the flush some letters don't appear

    GdiFlush();
    CopyMemory(pBuffer,m_pBase,pVideoInfo->bmiHeader.biSizeImage);
    return NOERROR;
}


// Overrides the base class method to fill the next buffer. We detect in here
// if either the section of media to be played has been changed. We check in
// here that we haven't run off the end of the stream before doing anything.
// If we've started a new section of media then m_bNewSegment will have been
// set and we should send a NewSegment call to inform the downstream filter

HRESULT CVideoStream::FillBuffer(IMediaSample *pMediaSample)
{
    NOTE("FillBuffer");
    BYTE *pBuffer;
    LONG lDataLen;

    CAutoLock cAutoLock(&m_SourceLock);
    pMediaSample->GetPointer(&pBuffer);
    lDataLen = pMediaSample->GetSize();

    // Have we reached the end of stream yet

    if (m_CurrentFrame > m_StopFrame) {
        return S_FALSE;
    }

    // Send the NewSegment call downstream

    if (m_bNewSegment == TRUE) {
        REFERENCE_TIME tStart = (REFERENCE_TIME) COARefTime(double(m_CurrentFrame) / double(FRAMERATE));
        REFERENCE_TIME tStop = (REFERENCE_TIME) COARefTime(double(m_StopFrame) / double(FRAMERATE));
        DeliverNewSegment(tStart,tStop,m_dbRate);
        NOTE2("Segment (Start %d Stop %d)",m_CurrentFrame,m_StopFrame);
    }

    // Use the frame difference to calculate the end time

    REFERENCE_TIME rtStart = m_rtSampleTime;
    LONGLONG CurrentFrame = m_CurrentFrame;
    m_rtSampleTime += ((m_rtIncrement * 1000) / LONGLONG(m_dbRate * 1000));

    // Set the sample properties

    pMediaSample->SetSyncPoint(TRUE);
    pMediaSample->SetDiscontinuity(FALSE);
    pMediaSample->SetPreroll(FALSE);
    pMediaSample->SetTime(&rtStart,&m_rtSampleTime);

    DrawCurrentFrame(pBuffer);
    m_bNewSegment = FALSE;
    m_CurrentFrame++;
    return NOERROR;
}


// Overriden to return our single output format

HRESULT CVideoStream::GetMediaType(CMediaType *pmt)
{
    return GetMediaType(0,pmt);
}


// Also to make things simple we offer one image format. On most displays the
// RGB8 image will be directly displayable so when being rendered we won't get
// a colour space convertor put between us and the renderer to do a transform.
// It would be relatively straightforward to offer more formats like bouncing
// ball does but would only confuse the main point of showing off the workers

HRESULT CVideoStream::GetMediaType(int iPosition, CMediaType *pmt)
{
    NOTE("GetMediaType");

    // We only offer one media type

    if (iPosition) {
        NOTE("No more media types");
        return VFW_S_NO_MORE_ITEMS;
    }

    // Allocate an entire VIDEOINFO for simplicity

    pmt->AllocFormatBuffer(sizeof(VIDEOINFO));
    VIDEOINFO *pVideoInfo = (VIDEOINFO *) pmt->Format();
    if (pVideoInfo == NULL) {
	return E_OUTOFMEMORY;
    }

    ZeroMemory(pVideoInfo,sizeof(VIDEOINFO));

    // This describes the logical bitmap we will use

    BITMAPINFOHEADER *pHeader = HEADER(pVideoInfo);
    pVideoInfo->bmiHeader.biSize = sizeof(BITMAPINFOHEADER);
    pVideoInfo->bmiHeader.biWidth = BUFFERWIDTH;
    pVideoInfo->bmiHeader.biHeight = BUFFERHEIGHT;
    pVideoInfo->bmiHeader.biPlanes = 1;
    pVideoInfo->bmiHeader.biBitCount = 8;
    pVideoInfo->bmiHeader.biCompression = BI_RGB;
    pVideoInfo->bmiHeader.biClrUsed = BUFFERCOLOURS;
    pVideoInfo->bmiHeader.biClrImportant = BUFFERCOLOURS;
    pVideoInfo->bmiHeader.biSizeImage = GetBitmapSize(pHeader);

    // Copy the palette we draw to one colour at a time

    for (int Index = 0;Index < BUFFERCOLOURS;Index++) {
        pVideoInfo->bmiColors[Index].rgbRed = BackBufferPalette[Index].rgbRed;
        pVideoInfo->bmiColors[Index].rgbGreen = BackBufferPalette[Index].rgbGreen;
        pVideoInfo->bmiColors[Index].rgbBlue = BackBufferPalette[Index].rgbBlue;
    }

    SetRectEmpty(&pVideoInfo->rcSource);
    SetRectEmpty(&pVideoInfo->rcTarget);

    pmt->SetType(&MEDIATYPE_Video);
    pmt->SetSubtype(&MEDIASUBTYPE_RGB8);
    pmt->SetFormatType(&FORMAT_VideoInfo);
    pmt->SetTemporalCompression(FALSE);
    pmt->SetSampleSize(pVideoInfo->bmiHeader.biSizeImage);

    return NOERROR;
}


// Request a single output buffer based on the image size

HRESULT CVideoStream::DecideBufferSize(IMemAllocator *pAlloc,ALLOCATOR_PROPERTIES *pProperties)
{
    NOTE("DecideBufferSize");
    ASSERT(pProperties);
    HRESULT hr = NOERROR;

    VIDEOINFO *pVideoInfo = (VIDEOINFO *) m_mt.Format();
    pProperties->cBuffers = 1;
    pProperties->cbBuffer = pVideoInfo->bmiHeader.biSizeImage;

    ASSERT(pProperties->cbBuffer);

    // Ask the allocator to reserve us some sample memory, Note the function
    // can succeed (that is return NOERROR) but still not have allocated the
    // memory that we requested, so we must check we got whatever we wanted

    ALLOCATOR_PROPERTIES Actual;
    hr = pAlloc->SetProperties(pProperties,&Actual);
    if (FAILED(hr)) {
        return hr;
    }

    // Is this allocator unsuitable

    if (Actual.cbBuffer < pProperties->cbBuffer) {
        return E_FAIL;
    }
    return NOERROR;
}


// Called to initialise the output stream

HRESULT CVideoStream::OnThreadCreate()
{
    IMediaFilter *pMediaFilter;
    NOTE("OnThreadCreate");
    ASSERT(m_Connected);
    PIN_INFO Info;

    // Set a NULL sync source downstream

    m_Connected->QueryPinInfo(&Info);
    if (Info.pFilter) {
        Info.pFilter->QueryInterface(IID_IMediaFilter,(VOID **) &pMediaFilter);
        pMediaFilter->SetSyncSource(NULL);
        Info.pFilter->Release();
        pMediaFilter->Release();
    }

    // Complete the thread initialisation

    CreateBackBuffer();
    PrepareLetterSizes(m_hdcMemory);
    m_rtSampleTime = 0;
    m_bNewSegment = TRUE;
    return NOERROR;
}


// Called when the worker threads is destroyed

HRESULT CVideoStream::OnThreadDestroy()
{
    NOTE("OnThreadDestroy");
    ReleaseBackBuffer();
    return NOERROR;
}


// We override this to handle any extra seeking mechanisms we might need. This
// is executed in the context of a worker thread. Messages may be sent to the
// worker thread through CallWorker. A call to CallWorker doesn't return until
// the worker thread has called Reply. This can be used to make sure we gain
// control of the thread, for example when flushing we should not complete the
// flush until the worker thread has returned and been stopped. If we get an
// error from GetDeliveryBuffer then we keep going and wait for a stop signal

HRESULT CVideoStream::DoBufferProcessingLoop()
{
    IMediaSample *pSample;
    Command com;
    HRESULT hr;

    do { while (CheckRequest(&com) == FALSE) {

            // If we get an error then keep trying until we're stopped

	    hr = GetDeliveryBuffer(&pSample,NULL,NULL,0);
	    if (FAILED(hr)) {
    	        Sleep(1);
		continue;
	    }

    	    // Generate our next frame

	    hr = FillBuffer(pSample);
	    if (hr == S_FALSE) {
	        pSample->Release();
	        DeliverEndOfStream();
	        return S_OK;
       	    }

       	    // Only deliver filled buffers
	
            if (hr == S_OK) {
                Deliver(pSample);
	    }
	    pSample->Release();
        }

   	// For all commands sent to us there must be a Reply call!

	if (com == CMD_RUN || com == CMD_PAUSE) {
            m_StartSegment = 0;
   	    Reply(NOERROR);
        } else if (com != CMD_STOP) {
   	    Reply(E_UNEXPECTED);
	}

    } while (com != CMD_STOP);

    return S_FALSE;
}


// Return the total duration for our media

STDMETHODIMP CVideoStream::get_Duration(REFTIME *pLength)
{
    NOTE("Entering get_Duration");
    CheckPointer(pLength,E_POINTER);
    CAutoLock cAutoLock(&m_SourceLock);
    *pLength = double(BUFFERREALWAIT * BUFFERNAMES / MILLISECONDS);

    NOTE1("Duration %s",CDisp(*pLength));
    return NOERROR;
}


// Return the current position in seconds based on the current frame number

STDMETHODIMP CVideoStream::get_CurrentPosition(REFTIME *pTime)
{
    NOTE("Entering get_CurrentPosition");
    CheckPointer(pTime,E_POINTER);
    CAutoLock cAutoLock(&m_SourceLock);

    *pTime = double(m_CurrentFrame) / double(FRAMERATE);
    NOTE1("Position %s",CDisp(*pTime));
    return NOERROR;
}


// Set the new current frame number based on the time

STDMETHODIMP CVideoStream::put_CurrentPosition(REFTIME Time)
{
    CAutoLock StateLock(m_pVideoSource->pStateLock());
    BOOL bRunning = ThreadExists();

    // Stop the worker thread

    if (bRunning == TRUE) {
        DeliverBeginFlush();
        CallWorker(CMD_STOP);
        DeliverEndFlush();
    }

    // Only lock the object when updating the frame number

    NOTE1("put_CurrentPosition %s",CDisp(Time));
    m_CurrentFrame = (LONG) (double(FRAMERATE) * Time);
    m_CurrentFrame = min(m_CurrentFrame,DURATION - 1);
    NOTE1("Setting frame number to %d",m_CurrentFrame);

    // Restart the worker thread again

    m_bNewSegment = TRUE;
    if (bRunning == TRUE) {
        m_rtSampleTime = 0;
        CallWorker(CMD_RUN);
    }
    return NOERROR;
}


// Return the current stop position

STDMETHODIMP CVideoStream::get_StopTime(REFTIME *pTime)
{
    CheckPointer(pTime,E_POINTER);
    CAutoLock cAutoLock(&m_SourceLock);
    *pTime = double(m_StopFrame) / double(FRAMERATE);
    NOTE1("get_StopTime %s",CDisp(*pTime));
    return NOERROR;
}


// Changing the stop time may cause us to flush already sent frames. If we're
// still inbound then the current position should be unaffected. If the stop
// position is before the current position then we effectively set them to be
// the same - setting a current position will have any data we've already sent
// to be flushed - note when setting a current position we must hold no locks

STDMETHODIMP CVideoStream::put_StopTime(REFTIME Time)
{
    NOTE1("put_StopTime %s",CDisp(Time));
    LONG StopFrame = LONG(double(Time) * double(FRAMERATE));
    StopFrame = min(StopFrame,DURATION-1);
    NOTE1("put_StopTime frame %d",StopFrame);

    // Manually lock the filter

    m_SourceLock.Lock();
    m_bNewSegment = TRUE;
    m_StopFrame = StopFrame;

    // Are we still processing in range

    if (m_CurrentFrame < StopFrame) {
        m_SourceLock.Unlock();
        NOTE("Still in range");
        return NOERROR;
    }

    NOTE("Flushing sent data");
    m_SourceLock.Unlock();
    put_CurrentPosition(Time);
    return NOERROR;
}


// We have no preroll time mechanism

STDMETHODIMP CVideoStream::get_PrerollTime(REFTIME *pTime)
{
    NOTE("Entering get_PrerollTime");
    CheckPointer(pTime,E_POINTER);
    return E_NOTIMPL;
}


// We have no preroll time so ignore this call

STDMETHODIMP CVideoStream::put_PrerollTime(REFTIME Time)
{
    NOTE1("put_PrerollTime %s",CDisp(Time));
    CAutoLock cAutoLock(&m_SourceLock);
    return E_NOTIMPL;
}


// Return the current (positive only) rate

STDMETHODIMP CVideoStream::get_Rate(double *pdRate)
{
    NOTE("Entering Get_Rate");
    CheckPointer(pdRate,E_POINTER);
    CAutoLock cAutoLock(&m_SourceLock);
    *pdRate = m_dbRate;
    return NOERROR;
}


// Adjust the rate but only allow positive values

STDMETHODIMP CVideoStream::put_Rate(double dRate)
{
    NOTE1("put_Rate %s",CDisp(dRate));
    CAutoLock cAutoLock(&m_SourceLock);

    // Ignore negative and zero rates

    if (dRate <= double(0.0)) {
        return E_INVALIDARG;
    }
    m_dbRate = dRate;
    return NOERROR;
}


// By default we can seek forwards

STDMETHODIMP CVideoStream::CanSeekForward(LONG *pCanSeekForward)
{
    CheckPointer(pCanSeekForward,E_POINTER);
    *pCanSeekForward = OATRUE;
    return S_OK;
}


// By default we can seek backwards

STDMETHODIMP CVideoStream::CanSeekBackward(LONG *pCanSeekBackward)
{
    CheckPointer(pCanSeekBackward,E_POINTER);
    *pCanSeekBackward = OATRUE;
    return S_OK;
}
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\multimedia\dshow\filters\image\video\allocate.h ===
// Copyright (c) 1994 - 1999  Microsoft Corporation.  All Rights Reserved.
// Implements a DirectDraw allocator, Anthony Phillips, January 1995

#ifndef __ALLOCATE__
#define __ALLOCATE__

// This class inherits from CImageSample and is overriden to store DirectDraw
// information. In particular these samples change dynamically so that if we
// have access to a surface then the allocator changes the format with the
// source filter and then initialises us with a pointer to the locked surface
// The m_bDrawStatus flag indicates whether a flipping surface has been done

class CVideoSample : public CImageSample
{
    IDirectDrawSurface *m_pDrawSurface;   // The DirectDraw surface instance
    IDirectDraw *m_pDirectDraw;           // The actual DirectDraw provider
    LONG m_SurfaceSize;                   // Size of DCI/DirectDraw buffer
    BYTE *m_pSurfaceBuffer;               // Pointer to DCI/DirectDraw buffer
    BOOL m_bDrawStatus;                   // Can this sample be rendered flag
    CAggDirectDraw m_AggDirectDraw;       // Aggregates IDirectDraw interface
    CAggDrawSurface m_AggDrawSurface;     // Likewise with IDirectDrawSurface

public:

    // Constructor

    CVideoSample(CImageAllocator *pVideoAllocator,
                 TCHAR *pName,
                 HRESULT *phr,
                 LPBYTE pBuffer,
                 LONG length);

    STDMETHODIMP QueryInterface(REFIID riid,void **ppv);

    // Maintain the DCI/DirectDraw state

    void SetDirectInfo(IDirectDrawSurface *pDrawSurface,
                       IDirectDraw *pDirectDraw,
                       LONG SurfaceSize,
                       BYTE *pSurface);

    void UpdateBuffer(LONG cbBuffer,BYTE *pBuffer);
    BYTE *GetDirectBuffer();
    void SetDrawStatus(BOOL bStatus);
    BOOL GetDrawStatus();

    // Override these IMediaSample functions

    STDMETHODIMP GetPointer(BYTE **ppBuffer);
    STDMETHODIMP_(LONG) GetSize();
    STDMETHODIMP SetActualDataLength(LONG lActual);
};


// This is an allocator derived from the CImageAllocator utility class that
// allocates sample buffers in shared memory. The number and size of these
// are determined when the output pin calls Prepare on us. The shared memory
// blocks are used in subsequent calls to GDI CreateDIBSection, once that
// has been done the output pin can fill the buffers with data which will
// then be handed to GDI through BitBlt calls and thereby remove one copy

class CVideoAllocator : public CImageAllocator
{
    CRenderer *m_pRenderer;             // The owning renderer object
    CDirectDraw *m_pDirectDraw;         // DirectDraw helper object
    BOOL m_bDirectDrawStatus;           // What type are we using now
    BOOL m_bDirectDrawAvailable;        // Are we allowed to go direct
    BOOL m_bPrimarySurface;             // Are we using the primary
    CCritSec *m_pInterfaceLock;         // Main renderer interface lock
    IMediaSample *m_pMediaSample;       // Sample waiting for rendering
    BOOL m_bVideoSizeChanged;           // Signals a change in video size
    BOOL m_bNoDirectDraw;

    // Used to create and delete samples

    HRESULT Alloc();
    void Free();

    // Look after the state changes when switching sample types

    HRESULT QueryAcceptOnPeer(CMediaType *pMediaType);
    HRESULT InitDirectAccess(CMediaType *pmtIn);
    BOOL PrepareDirectDraw(IMediaSample *pSample,DWORD dwFlags,
					BOOL fForcePrepareForMultiMonitorHack);
    BOOL UpdateImage(IMediaSample **ppSample,CMediaType *pBuffer);
    BOOL MatchWindowSize(IMediaSample **ppSample,DWORD dwFlags);
    BOOL StopUsingDirectDraw(IMediaSample **ppSample,DWORD dwFlags);
    BOOL FindSpeedyType(IPin *pReceivePin);
    CImageSample *CreateImageSample(LPBYTE pData,LONG Length);

public:

    // Constructor and destructor

    CVideoAllocator(CRenderer *pRenderer,       // Main renderer object
                    CDirectDraw *pDirectDraw,   // DirectDraw hander code
                    CCritSec *pLock,            // Object to use for lock
                    HRESULT *phr);              // Constructor return code

    ~CVideoAllocator();

    // Overriden to delegate reference counts to the filter

    STDMETHODIMP_(ULONG) NonDelegatingAddRef();
    STDMETHODIMP_(ULONG) NonDelegatingRelease();

    // Handle returning DCI/DirectDraw surfaces at the right time

    STDMETHODIMP GetBuffer(IMediaSample **ppSample,
                           REFERENCE_TIME *pStartTime,
                           REFERENCE_TIME *pEndTime,
                           DWORD dwFlags);

    STDMETHODIMP ReleaseBuffer(IMediaSample *pMediaSample);
    HRESULT OnReceive(IMediaSample *pMediaSample);
    BOOL IsSurfaceFormat(const CMediaType *pmtIn);
    HRESULT StartStreaming();
    BOOL GetDirectDrawStatus();
    void ResetDirectDrawStatus();
    BOOL IsSamplePending();
    STDMETHODIMP Decommit();

    // Called when the destination changes

    void OnDestinationChange() {
        NOTE("Destination changed");
        m_bVideoSizeChanged = TRUE;
    }

    // Lets the renderer know if DirectDraw is available

    BOOL IsDirectDrawAvailable() {
        NOTE("IsDirectDrawAvailable");
        CAutoLock cVideoLock(this);
        return m_bDirectDrawAvailable;
    };

    void NoDirectDraw(BOOL fDraw) {
        CAutoLock cVideoLock(this);
        m_bNoDirectDraw = fDraw;
    }

    BOOL m_fWasOnWrongMonitor;
    BOOL m_fForcePrepareForMultiMonitorHack;

    // KsProxy hack to disable NotifyRelease when just handling WM_PAINT
    IMemAllocatorNotifyCallbackTemp * InternalGetAllocatorNotifyCallback() {
       return m_pNotify;
    };

    void InternalSetAllocatorNotifyCallback(IMemAllocatorNotifyCallbackTemp * pNotify) {
       m_pNotify = pNotify;
    };

    //  Check all samples are returned
    BOOL AnySamplesOutstanding() const
    {
        return m_lFree.GetCount() != m_lAllocated;
    }

    BOOL UsingDDraw() const
    {
        return m_bDirectDrawStatus;
    }

};

#endif // __ALLOCATE__
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\multimedia\dshow\filters\image\video\ddmm.cpp ===
/*==========================================================================
 *
 *  Copyright (c) 1995 - 1999  Microsoft Corporation.  All Rights Reserved.
 *
 *  File:       ddmm.cpp
 *  Content:    Routines for using DirectDraw on a multimonitor system
 *
 ***************************************************************************/

//#define WIN32_LEAN_AND_MEAN
//#define WINVER 0x0400
//#define _WIN32_WINDOWS 0x0400
#include <streams.h>
#include <ddraw.h>
#include "ddmm.h"

#define COMPILE_MULTIMON_STUBS
#include "MultMon.h"  // our version of multimon.h include ChangeDisplaySettingsEx

/*
 *  OneMonitorCallback
 */
BOOL CALLBACK OneMonitorCallback(HMONITOR hMonitor, HDC hdc, LPRECT prc, LPARAM lParam)
{
    HMONITOR *phMonitorFound = (HMONITOR *)lParam;

    MONITORINFOEX mi;
    mi.cbSize = sizeof(mi);
    GetMonitorInfo(hMonitor, &mi);

    //
    // look for this monitor among all the display devices,
    // reject this monitor if it is not part of the desktop or
    // if it is a NetMeeting mirroring monitor.
    //

    BOOL rc = TRUE;
    for (DWORD iDevNum = 0; rc; iDevNum++) {

        DISPLAY_DEVICE DisplayDevice;
        DisplayDevice.cb = sizeof(DisplayDevice);
        rc = EnumDisplayDevices(NULL, iDevNum, &DisplayDevice, 0);

        //
        // Does this device match the current monitor ?
        //

        if (rc && (0 == lstrcmpi(DisplayDevice.DeviceName, mi.szDevice))) {

            if (!(DisplayDevice.StateFlags & DISPLAY_DEVICE_ATTACHED_TO_DESKTOP)) {
               return TRUE;
            }

            if (DisplayDevice.StateFlags & DISPLAY_DEVICE_MIRRORING_DRIVER) {
                return TRUE;
            }

            // This monitor is OK so break out the loop
            break;
        }
    }

    //
    // If rc is FALSE then we did not find this monitor among the
    // attached display devices.  This should NOT happen.
    //

    ASSERT(rc == TRUE);


    if (*phMonitorFound == 0)
        *phMonitorFound = hMonitor;
    else
        *phMonitorFound = (HMONITOR)INVALID_HANDLE_VALUE;

    return TRUE;
}

/*
 *  OneMonitorFromWindow
 *
 *  similar to the Win32 function MonitorFromWindow, except
 *  only returns a HMONITOR if a window is on a single monitor.
 *
 *  if the window handle is NULL, the primary monitor is returned
 *  if the window is not visible returns NULL
 *  if the window is on a single monitor returns its HMONITOR
 *  if the window is on more than on monitor returns INVALID_HANDLE_VALUE
 */
HMONITOR OneMonitorFromWindow(HWND hwnd)
{
    HMONITOR hMonitor = NULL;
    RECT rc;

    if (hwnd)
    {
        GetClientRect(hwnd, &rc);
        ClientToScreen(hwnd, (LPPOINT)&rc);
        ClientToScreen(hwnd, (LPPOINT)&rc+1);
    }
    else
    {
	// Todd, looky here
        SetRect(&rc,0,0,10,10);
        //SetRectEmpty(&rc);
    }

    EnumDisplayMonitors(NULL, &rc, OneMonitorCallback, (LPARAM)&hMonitor);
    return hMonitor;
}

#include <atlconv.h>

/*
 * DeviceFromWindow
 *
 * find the direct draw device that should be used for a given window
 *
 * the return code is a "unique id" for the device, it should be used
 * to determine when your window moves from one device to another.
 *
 *      case WM_MOVE:
 *          if (MyDevice != DirectDrawDeviceFromWindow(hwnd,NULL,NULL))
 *          {
 *              // handle moving to a new device.
 *          }
 *
 */
INT_PTR DeviceFromWindow(HWND hwnd, LPSTR szDevice, RECT *prc)
{
    HMONITOR hMonitor;

    if (GetSystemMetrics(SM_CMONITORS) <= 1)
    {
        if (prc) SetRect(prc,0,0,GetSystemMetrics(SM_CXSCREEN),GetSystemMetrics(SM_CYSCREEN));
        if (szDevice) lstrcpyA(szDevice, "DISPLAY");
        return -1;
    }

    hMonitor = OneMonitorFromWindow(hwnd);

    if (hMonitor == NULL || hMonitor == INVALID_HANDLE_VALUE)
    {
	if (prc) SetRectEmpty(prc);
	if (szDevice) *szDevice=0;
        return 0;
    }
    else
    {
	if (prc != NULL || szDevice != NULL)
	{
	    MONITORINFOEX mi;
	    mi.cbSize = sizeof(mi);
	    GetMonitorInfo(hMonitor, &mi);
	    if (prc) *prc = mi.rcMonitor;
	    USES_CONVERSION;
	    if (szDevice) lstrcpyA(szDevice, T2A(mi.szDevice));
	}
        return (INT_PTR)hMonitor;
    }
}
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\multimedia\dshow\filters\image\video\allocate.cpp ===
// Copyright (c) 1994 - 1999  Microsoft Corporation.  All Rights Reserved.
// Implements the CVideoAllocator class, Anthony Phillips, January 1995

#include <streams.h>
#include <windowsx.h>
#include <render.h>

// This implements a DCI/DirectDraw enabled allocator along with a specialised
// sample class that it uses. We override Free and Alloc to allocate surfaces
// based on DCI and DirectDraw. The majority of the work is done in GetBuffer
// where we dynamically switch the source between buffer types. When and where
// we switch types depends on the surface being used, the state the filter is
// in and the current environment. For example primary surfaces are not used
// when we are paused however overlays are. If the window is complex clipped
// then we don't use primary surfaces but we can use overlays when there is a
// colour key available (some of this policy is decided by the direct object)


// Constructor must initialise the base image allocator

CVideoAllocator::CVideoAllocator(CRenderer *pRenderer,      // Main renderer
                                 CDirectDraw *pDirectDraw,  // DirectDraw code
                                 CCritSec *pLock,           // Object to lock
                                 HRESULT *phr) :            // Return code

    CImageAllocator(pRenderer,NAME("Video Allocator"),phr),
    m_pDirectDraw(pDirectDraw),
    m_pRenderer(pRenderer),
    m_pInterfaceLock(pLock),
    m_bDirectDrawStatus(FALSE),
    m_bDirectDrawAvailable(FALSE),
    m_pMediaSample(NULL),
    m_bPrimarySurface(FALSE),
    m_bVideoSizeChanged(TRUE),
    m_fWasOnWrongMonitor(FALSE),
    m_fForcePrepareForMultiMonitorHack(FALSE),
    m_bNoDirectDraw(FALSE)
{
    ASSERT(pDirectDraw);
    ASSERT(m_pInterfaceLock);
    ASSERT(m_pRenderer);
}


// Check our DIB buffers and DirectDraw surfaces have been released

CVideoAllocator::~CVideoAllocator()
{
    ASSERT(m_bCommitted == FALSE);
}


// Called from destructor and also from base class to free resources. We must
// NOT reset the m_bDirectDrawStatus flag here because the current DirectDraw
// state is persistent across any state changes. Therefore when we next give
// out a buffer we will carry on as usual, and more importantly if we cannot
// offer a DirectDraw buffer we will make sure we change the output type back

void CVideoAllocator::Free()
{
    NOTE("Entering Free resources");

    // Reset our DirectDraw state

    m_pDirectDraw->ReleaseSurfaces();
    m_pDirectDraw->StopRefreshTimer();
    m_bDirectDrawAvailable = FALSE;
    m_bPrimarySurface = FALSE;
    m_bVideoSizeChanged = TRUE;

    CImageAllocator::Free();
}


// Overriden to allocate DirectDraw resources

HRESULT CVideoAllocator::Alloc(void)
{
    NOTE("Allocating video resources");

    // Check we don't have an overlay connection

    if (*m_pRenderer->m_mtIn.Subtype() == MEDIASUBTYPE_Overlay) {
        NOTE("Allocate samples for overlay");
        return VFW_E_NOT_SAMPLE_CONNECTION;
    }

    // Check the base allocator says it's ok to continue

    HRESULT hr = CImageAllocator::Alloc();
    if (FAILED(hr)) {
        return hr;
    }
    return InitDirectAccess(&m_pRenderer->m_mtIn);
}


// The base CImageAllocator class calls this virtual method to actually make
// the samples. It is deliberately virtual so that we can override to create
// more specialised sample objects. On our case our samples are derived from
// CImageSample but add the DirectDraw guff. We return a CImageSample object
// which is easy enough because the CVideoSample class is derived from that

CImageSample *CVideoAllocator::CreateImageSample(LPBYTE pData,LONG Length)
{
    HRESULT hr = NOERROR;
    CVideoSample *pSample;
    NOTE("Creating sample");

    // Allocate the new sample and check the return codes

    pSample = new CVideoSample((CImageAllocator*) this,    // Base allocator
                               NAME("Video sample"),       // DEBUG name
                               (HRESULT *) &hr,            // Return code
                               (LPBYTE) pData,             // DIB address
                               (LONG) Length);             // Size of DIB

    if (pSample == NULL || FAILED(hr)) {
        delete pSample;
        return NULL;
    }
    return pSample;
}


// This is called when we go active (paused or running). We have negotiated a
// media type to use which may or may not have direct DCI/DirectDraw surface
// support. The connection phase looks after trying to agree a type that does
// have hardware accelleration. So when we get here we try and get hold of a
// surface, if there isn't one then we will render using DIBSECTION buffers

HRESULT CVideoAllocator::InitDirectAccess(CMediaType *pmtIn)
{
    ASSERT(m_pRenderer->m_InputPin.IsConnected() == TRUE);
    ASSERT(m_bDirectDrawAvailable == FALSE);
    ASSERT(m_bPrimarySurface == FALSE);
    NOTE("Initialising DCI/DirectDraw");

    if (m_bNoDirectDraw) {
        m_bDirectDrawAvailable = FALSE;
        return NOERROR;
    }

    // We use the connected output pin to query media types

    IPin *pOutputPin = m_pRenderer->m_InputPin.GetConnected();
    if (m_lCount == 1) {
        if (FindSpeedyType(pOutputPin) == TRUE) {
            NOTE("Found DCI/DirectDraw surface");
            m_bDirectDrawAvailable = TRUE;
        }
    }
    return NOERROR;
}


// This is passed a media type from QueryAccept. We return TRUE if it matches
// the current output surface format, otherwise FALSE.

BOOL CVideoAllocator::IsSurfaceFormat(const CMediaType *pmtIn)
{
    NOTE("IsSurfaceFormat");
    CAutoLock cVideoLock(this);

    // Do we have any surfaces available at all

    if (m_bDirectDrawAvailable == FALSE) {
        NOTE("No surface");
        return FALSE;
    }

    // Compare against the current output format

    CMediaType *pmtOut = m_pDirectDraw->GetSurfaceFormat();
    if (*pmtOut == *pmtIn) {
        NOTE("Matches surface");
        return TRUE;
    }
    return FALSE;
}


// Asks if we have a sample waiting to be scheduled

BOOL CVideoAllocator::IsSamplePending()
{
    NOTE("Entering SamplePending");
    CAutoLock cVideoLock(this);

    // Do we have a sample waiting

    if (m_pMediaSample == NULL) {
        NOTE("No current sample");
        return FALSE;
    }
    return TRUE;
}


// If we schedule the sample before returning the buffer (like overlays and
// primary surfaces) then when we pause the source will decode an image, it
// then calls GetBuffer again where it will be blocked in WaitForRenderTime
// When we start running we can't just release the thread because the next
// image will appear immediately. Therefore we take the pending sample that
// is registered in GetBuffer and send it through the scheduling code again

HRESULT CVideoAllocator::StartStreaming()
{
    CAutoLock cVideoLock(this);
    if (m_pMediaSample == NULL) {
        NOTE("No run sample");
        return NOERROR;
    }

    // Schedule the sample for subsequent release

    if (m_pRenderer->ScheduleSample(m_pMediaSample) == FALSE) {
        ASSERT(m_pRenderer->CancelNotification() == S_FALSE);
        NOTE("First image scheduled is VFW_E_SAMPLE_REJECTED");
        m_pRenderer->GetRenderEvent()->Set();
    }
    return NOERROR;
}


// This overrides the IMemAllocator GetBuffer interface function. We return
// standard DIBSECTION and DCI/DirectDraw buffers. We manage switching the
// source filter between surface types and the synchronisation required for
// surfaces where the filling is effectively the drawing (examples include
// primary and overlay surfaces). We cannot return DCI/DirectDraw buffers
// if either of the time stamps are NULL as we use them for synchronisation

STDMETHODIMP CVideoAllocator::GetBuffer(IMediaSample **ppSample,
                                        REFERENCE_TIME *pStartTime,
                                        REFERENCE_TIME *pEndTime,
                                        DWORD dwFlags)
{
    CheckPointer(ppSample,E_POINTER);
    BOOL bWaitForDraw = FALSE;
    HRESULT hr = NOERROR;

    //NOTE("CVideoAllocator::GetBuffer");

    // We always need a buffer to start with if only to synchronise correctly
    // By enforcing DCI/DirectDraw access with connections that have a single
    // buffer we know we won't be doing any of this when the source still has
    // a buffer waiting to be drawn along our normal software draw code path

    hr = CBaseAllocator::GetBuffer(ppSample,pStartTime,pEndTime,dwFlags);
    if (hr != NOERROR) {
        //NOTE("BASE CLASS ERROR!");
        return hr;
    }

    // If we have allocated and are using a sync on fill surface then we set
    // a timer notification before the WaitForDrawTime call. After the wait
    // we may find we can no longer use the surface but that is unavoidable
    // the alternative would be to check the surface format before and after
    // the wait which would double our cost since we must check clipping etc

    {
        CAutoLock cInterfaceLock(m_pInterfaceLock);
        CAutoLock cVideoLock(this);

    // !!! FULLSCREEN PLAYBACK ON MULTIMON IS HOSED - wrong monitor, wrong colours,
    //     and it hangs

        // We are not on the monitor we are using h/w acceleration for (on
        // a multi-monitor system) so BAD things happen if we try to use
        // DDraw.

        INT_PTR ID;
        if (m_pRenderer->IsWindowOnWrongMonitor(&ID)) {

            m_fWasOnWrongMonitor = TRUE;

            // We know now that we are at least partially on a monitor other
            // than the one we're using hardware for
            //
            // ID == 0 means we are spanning monitors and we should fall back
            // to software
            // ID != 0 means we are wholly on another monitor and should start
            // using h/w for that monitor

            // InterlockedExchange() does not work on multiprocessor x86 systems and on non-x86
            // systems if m_pRenderer->m_fDisplayChangePosted is not aligned on a 32 bit boundary.
            ASSERT((DWORD_PTR)&m_pRenderer->m_fDisplayChangePosted == ((DWORD_PTR)&m_pRenderer->m_fDisplayChangePosted & ~3));
            
            // The video renderer only wants to send one WM_DISPLAYCHANGE message when 
            // the window is being moved to a new monitor.  Performance suffers if the
            // video renderer sends multiple WM_DISPLAYCHANGE messages.
            if (ID && !InterlockedExchange(&m_pRenderer->m_fDisplayChangePosted,TRUE)) {

                DbgLog((LOG_TRACE,3,TEXT("Window is on a DIFFERENT MONITOR!")));
                DbgLog((LOG_TRACE,3,TEXT("Reset the world!")));
                PostMessage(m_pRenderer->m_VideoWindow.GetWindowHWND(),
                            WM_DISPLAYCHANGE, 0, 0);
            }

            if (m_bDirectDrawStatus) {

                DbgLog((LOG_TRACE,3,TEXT("Window is on the WRONG MONITOR!")));
                DbgLog((LOG_TRACE,3,TEXT("Falling back to software")));

                if (StopUsingDirectDraw(ppSample,dwFlags) == FALSE) {
                    ASSERT(*ppSample == NULL);
                    DbgLog((LOG_ERROR,1,TEXT("*** Could not STOP!")));
                    NOTE("Could not reset format");
                    return VFW_E_CHANGING_FORMAT;
                }
            }

            return NOERROR;
        }

        // Last time we were on the wrong monitor.  Now we aren't.  We should
        // try and get DirectDraw back now!
        if (m_fWasOnWrongMonitor) {
            m_fForcePrepareForMultiMonitorHack = TRUE;
        }
        m_fWasOnWrongMonitor = FALSE;

        // DirectDraw can only be used if the time stamps are valid. A source
        // may call us with NULL time stamps when it wants to switch back to
        // DIBs. It could do this if it wants to make a palette change. The
        // next time the source sends valid time stamps we will make sure it
        // gets back into using the surface by marking the status as changed

	// NOTE, though, that we only really need time stamps if we're doing
	// sync on fill (overlay w/o flipping or primary surface)

        if ((pStartTime == NULL || pEndTime == NULL) &&
        			m_bDirectDrawStatus == TRUE &&
				m_pDirectDraw->SyncOnFill() == TRUE) {
            //NOTE("*** NO TIME STAMPS!");
            if (StopUsingDirectDraw(ppSample,dwFlags) == FALSE) {
                ASSERT(*ppSample == NULL);
                NOTE("Could not reset format");
		//DbgLog((LOG_ERROR,1,TEXT("*** NULL TIME STAMPS!")));
                return VFW_E_CHANGING_FORMAT;
            }
            return NOERROR;
        }

        // Have the sample scheduled if we wait before the fill. If we are in
        // a paused state then we do not schedule the sample for drawing but
        // we must only return a buffer if we are still waiting for the first
        // one through. Otherwise we stall the source filter thread by making
        // it sit in WaitForDrawTime without an advise time set on the clock

        if (m_bDirectDrawStatus == TRUE) {
            if (m_pDirectDraw->SyncOnFill() == TRUE) {
                bWaitForDraw = m_pRenderer->CheckReady();
                if (m_pRenderer->GetRealState() == State_Running) {
                    (*ppSample)->SetDiscontinuity((dwFlags & AM_GBF_PREVFRAMESKIPPED) != 0);
                    (*ppSample)->SetTime(pStartTime,pEndTime);
                    bWaitForDraw = m_pRenderer->ScheduleSample(*ppSample);
                    (*ppSample)->SetDiscontinuity(FALSE);
                    (*ppSample)->SetTime(NULL,NULL);
                }
            }
        }

        // Store the interface if we wait

        if (bWaitForDraw == TRUE) {
            NOTE("Registering sample");
            m_pMediaSample = (*ppSample);
        }
    }

    // Have the sample scheduled for drawing, if the scheduling decides we
    // should drop this image there is little we can do about it. We can't
    // return S_FALSE as it will never send more data to us. Therefore all
    // we can do is decode it and wait for the quality management to start

    if (bWaitForDraw == TRUE) {
        hr = m_pRenderer->WaitForRenderTime();
    }

    // We must wait for the rendering time without the objects locked so that
    // state changes can get in and release us in WaitForRenderTime. After we
    // return we must relock the objects. If we find the surface unavailable
    // then we must switch back to DIBs. Alternatively we may find that while
    // we are using DIBs now that we can switch into a DCI/DirectDraw buffer

    {
        CAutoLock cInterfaceLock(m_pInterfaceLock);
        CAutoLock cVideoLock(this);
        m_pMediaSample = NULL;

        // Did the state change while waiting

        if (hr == VFW_E_STATE_CHANGED) {
            NOTE("State has changed");
            (*ppSample)->Release();
            *ppSample = NULL;
            return VFW_E_STATE_CHANGED;
        }

        // Check they are still ok with the current environment

        if (PrepareDirectDraw(*ppSample,dwFlags,
                m_fForcePrepareForMultiMonitorHack) == TRUE) {
            m_fForcePrepareForMultiMonitorHack = FALSE;
            if (m_pDirectDraw->InitVideoSample(*ppSample,dwFlags) == TRUE) {
                NOTE("In direct mode");
                return NOERROR;
            }
        }

        // Switch the source filter away from DirectDraw

        if (StopUsingDirectDraw(ppSample,dwFlags) == FALSE) {
            NOTE("Failed to switch back");
            ASSERT(*ppSample == NULL);
	    //DbgLog((LOG_ERROR,1,TEXT("*** GET BUFFER PROBLEM")));
            return VFW_E_CHANGING_FORMAT;
        }
        return NOERROR;
    }
}


// This is called when we have determined the source filter can stretch their
// video according to the media passed passed in. We swap the current format
// with the main renderer and then create a new DIBSECTION for the sample. If
// anything fails it is hard to back out so we just abort playback completely
// The new buffer format must also be attached to the sample for the codec to
// process. The samples we supply allow the buffer and its size to be changed

BOOL CVideoAllocator::UpdateImage(IMediaSample **ppSample,CMediaType *pBuffer)
{
    NOTE("Entering UpdateImage");
    DIBDATA *pOriginal,Updated;
    m_pRenderer->m_mtIn = *pBuffer;

    // Update the buffer size held by the allocator

    BITMAPINFOHEADER *pHeader = HEADER(pBuffer->Format());
    VIDEOINFO *pVideoInfo = (VIDEOINFO *) pBuffer->Format();
    CVideoSample *pVideoSample = (CVideoSample *) *ppSample;
    m_lSize = pVideoInfo->bmiHeader.biSizeImage;

    // Create the updated DIB with the new dimensions

    HRESULT hr = CreateDIB(m_lSize,Updated);
    if (FAILED(hr)) {
        pVideoSample->Release();
        (*ppSample) = NULL;
        return FALSE;
    }

    // Swap over to the updated DIBSECTION resource

    pOriginal = pVideoSample->GetDIBData();
    EXECUTE_ASSERT(DeleteObject(pOriginal->hBitmap));
    EXECUTE_ASSERT(CloseHandle(pOriginal->hMapping));
    pVideoSample->SetDIBData(&Updated);
    pVideoSample->SetMediaType(pBuffer);
    pVideoSample->UpdateBuffer(m_lSize,Updated.pBase);
    NOTE("Stretching video to match window");

    return TRUE;
}


// When the window becomes stretched we would normally use GDI to stretch the
// video to match it. However the source filter codec may be able to stretch
// the video which may be much more efficient. Also, if the current video GDI
// format is palettised then the codec may also be able to stretch before the
// dithering rather than us stretch the already dithering image which is ugly

BOOL CVideoAllocator::MatchWindowSize(IMediaSample **ppSample,DWORD dwFlags)
{
    CVideoWindow *pVideoWindow = &m_pRenderer->m_VideoWindow;
    ASSERT(m_bDirectDrawStatus == FALSE);
    NOTE("Entering MatchWindowSize");
    RECT TargetRect;

    // Try to change only on a key frame

    if (dwFlags & AM_GBF_NOTASYNCPOINT) {
        NOTE("AM_GBF_NOTASYNCPOINT");
        return TRUE;
    }

    // Is it a typical video decoder

    if (m_lCount > 1) {
        NOTE("Too many buffers");
        return TRUE;
    }

    // Has the video size changed

    if (m_bVideoSizeChanged == FALSE) {
        NOTE("No video change");
        return TRUE;
    }

    // Check we are using the default source rectangle

    if (pVideoWindow->IsDefaultSourceRect() == S_FALSE) {
        NOTE("Not default source");
        return TRUE;
    }

    // Only do this if the destination looks reasonably normal

    pVideoWindow->GetTargetRect(&TargetRect);
    if (WIDTH(&TargetRect) < 32 || HEIGHT(&TargetRect) < 32) {
        NOTE("Target odd shape");
        return TRUE;
    }

    // Does the target rectangle match the current format

    BITMAPINFOHEADER *pInputHeader;
    pInputHeader = HEADER(m_pRenderer->m_mtIn.Format());
    m_bVideoSizeChanged = FALSE;

    if (pInputHeader->biWidth == WIDTH(&TargetRect)) {
        if (pInputHeader->biHeight == HEIGHT(&TargetRect)) {
            NOTE("Sizes match");
            return TRUE;
        }
    }

    // Create an output format based on the current target

    CMediaType Buffer = m_pRenderer->m_mtIn;
    VIDEOINFO *pVideoInfo = (VIDEOINFO *) Buffer.Format();
    pVideoInfo->bmiHeader.biWidth = WIDTH(&TargetRect);
    pVideoInfo->bmiHeader.biHeight = HEIGHT(&TargetRect);
    pVideoInfo->bmiHeader.biSizeImage = GetBitmapSize(HEADER(pVideoInfo));

    NOTE("Asking source filter to stretch");
    NOTE1("Width (%d)",pVideoInfo->bmiHeader.biWidth);
    NOTE1("Height (%d)",pVideoInfo->bmiHeader.biHeight);
    NOTE1("Depth (%d)",pVideoInfo->bmiHeader.biBitCount);

    // Will the source filter do the stretching

    if (QueryAcceptOnPeer(&Buffer) != S_OK) {
        NOTE("Rejected");
        return TRUE;
    }
    return UpdateImage(ppSample,&Buffer);
}


// Called to switch back to using normal DIBSECTION buffers. We may be called
// when we are not using DirectDraw anyway in which case we do nothing except
// setting the type back to NULL (just in case it has a DirectDraw type). If
// the type has to be changed back then we do not query it with the source as
// it should always accept it - even if when changed it has to seek forwards

BOOL CVideoAllocator::StopUsingDirectDraw(IMediaSample **ppSample,DWORD dwFlags)
{
    NOTE("Entering StopUsingDirectDraw");
    IMediaSample *pSample = (*ppSample);

    // Is there anything to do

    if (m_bDirectDrawStatus == FALSE) {
        pSample->SetMediaType(NULL);
        NOTE("Matching window size");
        return MatchWindowSize(ppSample,dwFlags);
    }

    DbgLog((LOG_TRACE,3,TEXT("StopUsingDirectDraw")));

    // Hide any overlay surface we have

    m_pDirectDraw->HideOverlaySurface();
    m_bDirectDrawStatus = FALSE;
    pSample->SetMediaType(&m_pRenderer->m_mtIn);
    pSample->SetDiscontinuity(TRUE);
    NOTE("Attached original output format");

    return MatchWindowSize(ppSample,dwFlags);
}


// Called when the GetBuffer wants to know if we can return something better
// than the normal run of the mill media sample. We see that DCI/DirectDraw
// is available and if so ensure the source can handle the clipping and/or
// stretching requirements. If we're being transitioned into paused then we
// return a DIB buffer if we are using the primary surface as there is no
// advantage to using surfaces and we may end up doing pointless EC_REPAINTs

BOOL CVideoAllocator::PrepareDirectDraw(IMediaSample *pSample,DWORD dwFlags,
                    BOOL fForcePrepareForMultiMonitorHack)
{
    FILTER_STATE State = m_pRenderer->GetRealState();
    NOTE("Entering PrepareDirectDraw");
    CMediaType *pSurface;
    BOOL bFormatChanged;

    // Do we have any surfaces available at all

    if (m_bDirectDrawAvailable == FALSE) {
        return FALSE;
    }

    // Can only switch on a key frame

    if (m_bDirectDrawStatus == FALSE) {
        if (dwFlags & AM_GBF_NOTASYNCPOINT) {
            NOTE("AM_GBF_NOTASYNCPOINT");
            return FALSE;
        }
    }

    // Is it worth returning a DirectDraw surface buffer

    if (State == State_Paused) {
        if (m_pDirectDraw->AvailableWhenPaused() == FALSE) {
            NOTE("Paused block");
            return FALSE;
        }
    }

    // Check we can still get an output surface format

    pSurface = m_pDirectDraw->UpdateSurface(bFormatChanged);
    if (pSurface == NULL) {
        NOTE("No format");
        return FALSE;
    }

    // Has the format changed from last time

    if (bFormatChanged == FALSE && !fForcePrepareForMultiMonitorHack) {
        NOTE("Format is unchanged");
        return m_bDirectDrawStatus;
    }

    // Query the format with the source

    if (QueryAcceptOnPeer(pSurface) != S_OK) {
        NOTE("Query failed");
        return FALSE;
    }

    DbgLog((LOG_TRACE,3,TEXT("Start using DirectDraw")));

    NOTE("Attaching DCI/DD format");
    pSample->SetMediaType(pSurface);
    pSample->SetDiscontinuity(TRUE);
    m_bDirectDrawStatus = TRUE;

    return TRUE;
}


// Check this media type is acceptable to our input pin. All we do is to call
// QueryAccept on the source's output pin. To get this far we have locked the
// object so there should be no way for our pin to have become disconnected

HRESULT CVideoAllocator::QueryAcceptOnPeer(CMediaType *pMediaType)
{
    DisplayType(TEXT("Proposing output type"),pMediaType);
    IPin *pPin = m_pRenderer->m_InputPin.GetPeerPin();
    ASSERT(m_pRenderer->m_InputPin.IsConnected() == TRUE);
    return pPin->QueryAccept(pMediaType);
}


// Called when we get our DCI/DirectDraw sample delivered, we return TRUE to
// say this is a DCI/DirectDraw sample so don't pass it to the window object
// Return VFW_E_SAMPLE_REJECTED if it isn't a hardware buffer, NOERROR if it
// is a hardware buffer ready for real drawing or VFW_S_NO_MORE_ITEMS if it
// is a hardware buffer that has been finished with (like primary surfaces)
// We also have to handle the unlock failing, the only thing this amounts to
// is making sure the overlay got shown if we are going into a paused state

HRESULT CVideoAllocator::OnReceive(IMediaSample *pMediaSample)
{
    NOTE("Entering OnReceive");

    // Ask the DirectDraw object to unlock the sample first

    if (m_pDirectDraw->ResetSample(pMediaSample,FALSE) == FALSE) {
        NOTE("Sample not DCI/DirectDraw");
        return VFW_E_SAMPLE_REJECTED;
    }

    // Are we finished with this sample

    if (m_pDirectDraw->SyncOnFill() == FALSE) {
        NOTE("Not SyncOnFill");
        return NOERROR;
    }

    // Pretend we actually had to do something

    CAutoLock cInterfaceLock(m_pInterfaceLock);
    ASSERT(m_pRenderer->m_InputPin.IsConnected());
    m_pRenderer->OnDirectRender(pMediaSample);
    m_pRenderer->SetRepaintStatus(TRUE);

    // Now that we have unlocked the DirectDraw surface we can complete the
    // handling of sync on fill buffers (such as overlay surfaces). Since
    // we do not hand the sample onto the window object we must make sure
    // that paused state transitions complete and that the scheduling code
    // is given enough information for it's quality management decisions

    if (m_pRenderer->GetRealState() != State_Paused) {
        NOTE("Returning VFW_S_NO_MORE_ITEMS");
        return VFW_S_NO_MORE_ITEMS;
    }

    // We may run into a problem showing the overlay surface (perhaps someone
    // else got in first and grabbed the only available visible overlay). So
    // we check it actually got shown after unlocking and if it was not then
    // we immediately send a repaint. This works because the only surfaces we
    // use which are sync on fill are primary and the overlays (not flipping)

    if (m_bPrimarySurface == FALSE) {
        if (m_pDirectDraw->IsOverlayEnabled() == FALSE) {
            NOTE("Overlay was not shown");
            m_pRenderer->SendRepaint();
            return VFW_S_NO_MORE_ITEMS;
        }
    }

    NOTE("Pause state completed");
    m_pRenderer->Ready();
    return VFW_S_NO_MORE_ITEMS;
}


// Overriden so that we don't always release DirectDraw when stopped

STDMETHODIMP CVideoAllocator::Decommit()
{
    CAutoLock cInterfaceLock(m_pInterfaceLock);

    // Should we block the allocator from doing a decommit

    if (m_pRenderer->m_DirectDraw.IsOverlayEnabled() == FALSE) {
        NOTE("Decommitting base allocator");
        return CBaseAllocator::Decommit();
    }

    NOTE("Blocking the decommit");

    CAutoLock cVideoLock(this);
    m_bDecommitInProgress = TRUE;
    m_bCommitted = FALSE;
    return NOERROR;
}


// Overriden from CBaseAllocator and called when the final reference count
// is released on a media sample so that it can be added to the tail of the
// allocator free list. We intervene at this point to make sure that if the
// display was locked when GetBuffer was called that it is always unlocked
// regardless of whether the source calls Receive on our input pin or not

STDMETHODIMP CVideoAllocator::ReleaseBuffer(IMediaSample *pMediaSample)
{
    CheckPointer(pMediaSample,E_POINTER);
    NOTE("Entering ReleaseBuffer");
    m_pDirectDraw->ResetSample(pMediaSample,TRUE);
    BOOL bRelease = FALSE;

    // If there is a pending Decommit, then we need to complete it by calling
    // Free() when the last buffer is placed on the free list. If there is an
    // overlay surface still showing (either true overlay or flipping) then
    // we do not free now as that would release all the DirectDraw surfaces
    // and remove the overlay with it (which we always want to keep visible)
    {
        CAutoLock cVideoLock(this);
        m_lFree.Add((CMediaSample*)pMediaSample);
        NotifySample();

        // If the overlay is visible then don't free our resources

        if (m_bDecommitInProgress == TRUE) {
            if (m_lFree.GetCount() == m_lAllocated) {
                if (m_pRenderer->m_DirectDraw.IsOverlayEnabled() == FALSE) {
                    NOTE("Free allocator resources");
                    ASSERT(m_bCommitted == FALSE);
                    CVideoAllocator::Free();
                    bRelease = TRUE;
                    m_bDecommitInProgress = FALSE;
                }
            }
        }
    }

    if (m_pNotify) {
        //
        // Note that this is not synchronized with setting up a notification
        // method.
        //
        m_pNotify->NotifyRelease();
    }
    if (bRelease) {
        Release();
    }
    return NOERROR;
}


// This is called when our input pin connects to an output pin. We search the
// formats that pin provides and see if there are any that may have hardware
// accelleration through DCI/DirectDraw. If we find a possible format then we
// create the surface (actually done by the DirectDraw object). The DirectDraw
// object will also create an output format that represents the surface which
// we use to call QueryAccept on the output pin to see if it will accept it

BOOL CVideoAllocator::FindSpeedyType(IPin *pReceivePin)
{
    IEnumMediaTypes *pEnumMediaTypes;
    AM_MEDIA_TYPE *pMediaType = NULL;
    CMediaType cMediaType;
    BOOL bFound = FALSE;
    CMediaType *pmtOut;
    ULONG ulFetched;
    ASSERT(pReceivePin);

    // Find a media type enumerator for the output pin

    HRESULT hr = pReceivePin->EnumMediaTypes(&pEnumMediaTypes);
    if (FAILED(hr)) {
        return FALSE;
    }

    NOTE("Searching for direct format");
    ASSERT(pEnumMediaTypes);
    m_pDirectDraw->ReleaseSurfaces();

    // First, try flipping overlay surfaces with all the types
    pEnumMediaTypes->Reset();
    while (TRUE) {

        // Get the next media type from the enumerator

        hr = pEnumMediaTypes->Next(1,&pMediaType,&ulFetched);
        if (FAILED(hr) || ulFetched != 1) {
            break;
        }

        ASSERT(pMediaType);
        cMediaType = *pMediaType;
        DeleteMediaType(pMediaType);

        // Find a hardware accellerated surface for this media type. We do a
        // few checks first, to see the format block is a VIDEOINFO (so it's
        // a video type), and that the format is sufficiently large. We also
        // check that the source filter can actually supply this type. After
        // that we then go looking for a suitable DCI/DirectDraw surface

        NOTE1("Enumerated %x", HEADER(cMediaType.Format())->biCompression);

        const GUID *pFormatType = cMediaType.FormatType();
        if (*pFormatType == FORMAT_VideoInfo) {
            if (cMediaType.FormatLength() >= SIZE_VIDEOHEADER) {
                if (pReceivePin->QueryAccept(&cMediaType) == S_OK) {
            // TRUE ==> Find only flipping surfaces
                    if (m_pDirectDraw->FindSurface(&cMediaType, TRUE) == TRUE) {
                        pmtOut = m_pDirectDraw->GetSurfaceFormat();
                        if (QueryAcceptOnPeer(pmtOut) == S_OK) {
                            bFound = TRUE; break;
                        }
                    }
                }
            }
        }
        m_pDirectDraw->ReleaseSurfaces();
    }

    // If that failed, try non-flipping surface types with all the formats
    pEnumMediaTypes->Reset();
    while (!bFound) {

        // Get the next media type from the enumerator

        hr = pEnumMediaTypes->Next(1,&pMediaType,&ulFetched);
        if (FAILED(hr) || ulFetched != 1) {
            break;
        }

        ASSERT(pMediaType);
        cMediaType = *pMediaType;
        DeleteMediaType(pMediaType);

        // Find a hardware accellerated surface for this media type. We do a
        // few checks first, to see the format block is a VIDEOINFO (so it's
        // a video type), and that the format is sufficiently large. We also
        // check that the source filter can actually supply this type. After
        // that we then go looking for a suitable DCI/DirectDraw surface

        NOTE1("Enumerated %x", HEADER(cMediaType.Format())->biCompression);

        const GUID *pFormatType = cMediaType.FormatType();
        if (*pFormatType == FORMAT_VideoInfo) {
            if (cMediaType.FormatLength() >= SIZE_VIDEOHEADER) {
                if (pReceivePin->QueryAccept(&cMediaType) == S_OK) {
            // FALSE ==> Find only non-flipping surfaces
                    if (m_pDirectDraw->FindSurface(&cMediaType,FALSE) == TRUE) {
                        pmtOut = m_pDirectDraw->GetSurfaceFormat();
                        if (QueryAcceptOnPeer(pmtOut) == S_OK) {
                            bFound = TRUE; break;
                        }
                    }
                }
            }
        }
        m_pDirectDraw->ReleaseSurfaces();
    }

    pEnumMediaTypes->Release();

    // If we found a surface then great, when we start streaming for real our
    // allocator is reset (and likewise the DirectDraw object status as well)
    // UpdateSurface will return TRUE and we will check the type is still ok
    // If we could not find anything then we try and create a primary surface
    // This we keep around all the time and continually ask the source if it
    // likes it when the status changes (such as the window being stretched)
    // Asking the source now if it likes the primary won't work because it
    // may have been stretched by one pixel but is just about to be resized

    if (bFound == TRUE) {
        DisplayType(TEXT("Surface available"),pmtOut);
        return TRUE;
    }

    // Switch to using a DCI/DirectDraw primary surface

    if (m_pDirectDraw->FindPrimarySurface(&m_pRenderer->m_mtIn) == FALSE) {
        NOTE("No primary surface");
        return FALSE;
    }

    NOTE("Using primary surface");
    m_bPrimarySurface = TRUE;
    return TRUE;
}


// When we pause we want to know whether there is a DCI/DirectDraw sample due
// back in at any time (or indeed may be waiting in WaitForDrawTime). Our
// m_bDirectDrawStatus has exactly these semantics as it is FALSE when we've
// returned a DIBSECTION buffer and TRUE for direct surfaces. It is reset to
// FALSE in the constructor so we're ok when using someone else's allocator

BOOL CVideoAllocator::GetDirectDrawStatus()
{
    CAutoLock cVideoLock(this);
    return m_bDirectDrawStatus;
}


// Set our DirectDraw status to FALSE when disconnected. We cannot do this
// when we are decommitted because the current buffer format is persistent
// regardless of what the allocator is doing. The only time we can be sure
// that the media type will be reset between us is when we're disconnected

void CVideoAllocator::ResetDirectDrawStatus()
{
    CAutoLock cVideoLock(this);
    m_bDirectDrawStatus = FALSE;
}


// Overriden to increment the owning object's reference count

STDMETHODIMP_(ULONG) CVideoAllocator::NonDelegatingAddRef()
{
    return m_pRenderer->AddRef();
}


// Overriden to decrement the owning object's reference count

STDMETHODIMP_(ULONG) CVideoAllocator::NonDelegatingRelease()
{
    return m_pRenderer->Release();
}


// If you derive a class from CMediaSample that has extra variables and entry
// points then there are three alternate solutions. The first is to create a
// memory buffer larger than actually required by the sample and store your
// information either at the beginning of it or at the end, the former being
// moderately safer allowing for misbehaving transform filters. You can then
// adjust the buffer address when you create the base media sample. This does
// however break up the memory allocated to the samples into separate blocks.

// The second solution is to implement a class derived from CMediaSample and
// support additional interface(s) that convey your private data. This means
// defining a custom interface. The final alternative is to create a class
// that inherits from CMediaSample and adds the private data structures, when
// you get an IMediaSample check to see if your allocator is being used, and
// if it is then cast the IMediaSample pointer into one of your derived ones

#pragma warning(disable:4355)

CVideoSample::CVideoSample(CImageAllocator *pVideoAllocator,
                           TCHAR *pName,
                           HRESULT *phr,
                           LPBYTE pBuffer,
                           LONG length) :

    CImageSample(pVideoAllocator,pName,phr,pBuffer,length),
    m_AggDirectDraw(NAME("DirectDraw"),this),
    m_AggDrawSurface(NAME("DirectDrawSurface"),this),
    m_pSurfaceBuffer(NULL),
    m_bDrawStatus(TRUE),
    m_pDrawSurface(NULL),
    m_pDirectDraw(NULL),
    m_SurfaceSize(0)
{
    ASSERT(pBuffer);
}


// Overriden to expose IDirectDraw and IDirectDrawSurface

STDMETHODIMP CVideoSample::QueryInterface(REFIID riid,void **ppv)
{
    if (riid == IID_IDirectDraw && m_pDirectDraw) {
        return m_AggDirectDraw.NonDelegatingQueryInterface(riid,ppv);
    } else if (riid == IID_IDirectDrawSurface && m_pDrawSurface) {
        return m_AggDrawSurface.NonDelegatingQueryInterface(riid,ppv);
    }
    return CMediaSample::QueryInterface(riid, ppv);
}


// When our allocator decides to hand out DCI/DirectDraw surfaces it sets the
// data pointer in the media sample just before it hands it to the source. We
// override the GetPointer to return this pointer if set. When it returns the
// sample to the input pin (as it always should do) we will reset it to NULL
// The sample also needs the DirectDraw provider and surface interfaces along
// with the buffer size we these pieces of information are also provided here

void CVideoSample::SetDirectInfo(IDirectDrawSurface *pDrawSurface,
                                 IDirectDraw *pDirectDraw,
                                 LONG SurfaceSize,
                                 BYTE *pSurface)
{
    m_pDirectDraw = pDirectDraw;        // Associated IDirectDraw object
    m_pDrawSurface = pDrawSurface;      // IDirectDrawSurface interface
    m_pSurfaceBuffer = pSurface;        // Actual data buffer pointer
    m_SurfaceSize = SurfaceSize;        // Size of the surface we have
    m_bDrawStatus = TRUE;               // Can this sample be rendered

    // Set the interfaces in the aggregation objects
    m_AggDirectDraw.SetDirectDraw(m_pDirectDraw);
    m_AggDrawSurface.SetDirectDrawSurface(m_pDrawSurface);
}


// Return a pointer to the DCI/DirectDraw surface, this is called by our DIB
// allocator to find out of this sample was a DCI/DirectDraw sample or just
// a normal memory based one. The surface is set through SetDirectSurface

BYTE *CVideoSample::GetDirectBuffer()
{
    return m_pSurfaceBuffer;
}


// Overrides the IMediaSample interface function to return the DCI/DirectDraw
// surface pointer. If it hasn't been set then we return the normal memory
// pointer. If this sample marks a change from one to the other then it will
// also have had an updated media type attached to describe the changeover

STDMETHODIMP CVideoSample::GetPointer(BYTE **ppBuffer)
{
    CheckPointer(ppBuffer,E_POINTER);

    if (m_pSurfaceBuffer) {
        *ppBuffer = m_pSurfaceBuffer;
        return NOERROR;
    }
    return CMediaSample::GetPointer(ppBuffer);
}


// This is some painful special case handling for flipping surfaces. These
// can only be drawn once and once alone per sample otherwise you flip back
// into view the previous image. Therefore to make like easier it is useful
// to be able to ask a video allocated sample whether it can be drawn again

void CVideoSample::SetDrawStatus(BOOL bStatus)
{
    m_bDrawStatus = bStatus;
}


// We always initialise the draw status to TRUE, this is only reset to FALSE
// once a real flip has been executed for this sample. Therefore the decision
// to draw a DirectDraw sample or not can be made entirely on what the draw
// status currently is (all non flipping samples this will always be TRUE)

BOOL CVideoSample::GetDrawStatus()
{
    return m_bDrawStatus;
}


// Allow for dynamic buffer size changes

STDMETHODIMP CVideoSample::SetActualDataLength(LONG lActual)
{
    //  Break into the kernel debugger since the surface will be locked
    //  here
    // Sorry, this is a valid thing to happen
    // KASSERT(lActual > 0);

    if (lActual > (m_pSurfaceBuffer ? m_SurfaceSize : m_cbBuffer)) {
        NOTE("Data length too large");
        return VFW_E_BUFFER_OVERFLOW;
    }
    m_lActual = lActual;
    return NOERROR;
}


// Return the size of the current buffer

STDMETHODIMP_(LONG) CVideoSample::GetSize()
{
    if (m_pSurfaceBuffer) {
        return m_SurfaceSize;
    }
    return CMediaSample::GetSize();
}


// We try to match the DIB buffer with the window size so that the codec can
// do the stretching where possible. When we allocate the new buffer we must
// install it in the sample - this method allows the video allocator to set
// the new buffer pointer and also its size. We will only do this when there
// are no images outstanding so the codec can't be using it at the same time

void CVideoSample::UpdateBuffer(LONG cbBuffer,BYTE *pBuffer)
{
    ASSERT(cbBuffer);
    ASSERT(pBuffer);
    m_pBuffer = pBuffer;
    m_cbBuffer = cbBuffer;
}
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\multimedia\dshow\filters\image\video\ddmm.h ===
/*==========================================================================
 *
 *  Copyright (c) 1995 - 1998  Microsoft Corporation.  All Rights Reserved.
 *
 *  File:       ddmm.cpp
 *  Content:    Routines for using DirectDraw on a multimonitor system
 *
 ***************************************************************************/

#ifdef __cplusplus
extern "C" {            /* Assume C declarations for C++ */
#endif  /* __cplusplus */

typedef HRESULT (*PDRAWCREATE)(IID *,LPDIRECTDRAW *,LPUNKNOWN);
typedef HRESULT (*PDRAWENUM)(LPDDENUMCALLBACKA,LPVOID);

INT_PTR DeviceFromWindow(HWND hwnd, LPSTR szDevice, RECT*prc);

#ifdef __cplusplus
}
#endif	/* __cplusplus */
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\multimedia\dshow\filters\image\video\direct.h ===
// Copyright (c) 1994 - 1999  Microsoft Corporation.  All Rights Reserved.
// Defines the COverlay class, Anthony Phillips, February 1995

#ifndef __OVERLAY__
#define __OVERLAY__

// Define a class which implements the IOverlay interface. A client may ask
// for one and only one advise link to be maintained that we will call when
// any of the window details change. When setting the advise link we'll be
// given an IOverlayNotify interface to call and we will also be told which
// notifications it is interested in. This class looks after
// the window clipping notifications and we have a number of private member
// functions that the renderer's objects may call to provide us with the
// rest of the information needed such as the window handle and media type

const DWORD PALETTEFLAG = 0x1000000;
const DWORD TRUECOLOURFLAG = 0x2000000;

class COverlay : public IOverlay, public CUnknown, public CCritSec
{
    // To support overlays the renderer may have to paint the video window
    // when areas become exposed using a specific colour. We get a default
    // key colour when we start. The next available key colour is kept in
    // a shared memory segment to try and reduce the risk of conflicts. If
    // we're asked to install a colour key we may have to create a palette

    LONG m_DefaultCookie;             // Default colour key cookie for us to use
    COLORREF m_WindowColour;          // Our actual overlay window colour
    COLORKEY m_ColourKey;             // Initial colour key requirements
    BOOL m_bColourKey;                // Are we using a colour key
    BOOL m_bFrozen;                   // Have we frozen the video
    CRenderer *m_pRenderer;           // Controlling renderer object
    IOverlayNotify *m_pNotify;        // Interface to call clients
    DWORD m_dwInterests;              // Callbacks interested in
    HPALETTE m_hPalette;              // A colour key palette handle
    CCritSec *m_pInterfaceLock;       // Main renderer interface lock
    HHOOK m_hHook;                    // Handle to window message hook
    RECT m_TargetRect;                // Last known good destination
    BOOL m_bMustRemoveCookie;         // TRUE if the cookie value must be released
                                      // by calling RemoveCurrentCookie().  Otherwise
                                      // FALSE.
                                      
    CDirectDraw *m_pDirectDraw;

private:

    HRESULT ValidateOverlayCall();
    BOOL OnAdviseChange(BOOL bAdviseAdded);
    HRESULT AdjustForDestination(RGNDATA *pRgnData);
    HRESULT GetVideoRect(RECT *pVideoRect);

    // Return the clipping details for the video window

    HRESULT GetVideoClipInfo(RECT *pSourceRect,
                             RECT *pDestinationRect,
                             RGNDATA **ppRgnData);

    // Set our internal colour key state

    void ResetColourKeyState();

    HRESULT InstallColourKey(COLORKEY *pColourKey,COLORREF Colour);
    HRESULT InstallPalette(HPALETTE hPalette);

    // These create and manage a suitable colour key

    HRESULT GetWindowColourKey(COLORKEY *pColourKey);
    HRESULT CheckSetColourKey(COLORKEY *pColourKey);
    HRESULT MatchColourKey(COLORKEY *pColourKey);
    HRESULT CheckSetPalette(DWORD dwColors,PALETTEENTRY *pPaletteColors);
    HPALETTE MakePalette(DWORD dwColors,PALETTEENTRY *pPaletteColors);
    HRESULT GetDisplayPalette(DWORD *pColors,PALETTEENTRY **ppPalette);

    // Main function for calculating an overlay colour key
    HRESULT NegotiateColourKey(COLORKEY *pColourKey,
                               HPALETTE *phPalette,
                               COLORREF *pColourRef);

    // Find a system palette entry for a colour key
    HRESULT NegotiatePaletteIndex(VIDEOINFO *pDisplay,
                                  COLORKEY *pColourKey,
                                  HPALETTE *phPalette,
                                  COLORREF *pColourRef);

    // Find a RGB true colour to use as a colour key
    HRESULT NegotiateTrueColour(VIDEOINFO *pDisplay,
                                COLORKEY *pColourKey,
                                COLORREF *pColourRef);
public:

    // Constructor and destructor

    COverlay(CRenderer *pRenderer,      // Main renderer object
             CDirectDraw *pDirectDraw,
             CCritSec *pLock,           // Object to use for lock
             HRESULT *phr);             // General OLE return code

    virtual ~COverlay();

    HRESULT NotifyChange(DWORD AdviseChanges);

    BOOL OnPaint();
    HRESULT FreezeVideo();
    HRESULT ThawVideo();
    BOOL IsVideoFrozen();
    void StartUpdateTimer();
    void StopUpdateTimer();
    BOOL OnUpdateTimer();
    void OnHookMessage(BOOL bHook);
    void InitDefaultColourKey(COLORKEY *pColourKey);

public:

    DECLARE_IUNKNOWN

    // Overriden to provide our own IUnknown interface

    STDMETHODIMP NonDelegatingQueryInterface(REFIID riid,VOID **ppv);
    STDMETHODIMP_(ULONG) NonDelegatingAddRef();
    STDMETHODIMP_(ULONG) NonDelegatingRelease();

    // These manage the palette negotiation

    STDMETHODIMP GetPalette(
        DWORD *pdwColors,                   // Number of colours present
        PALETTEENTRY **ppPalette);          // Where to put palette data

    STDMETHODIMP SetPalette(
        DWORD dwColors,                     // Number of colours available
        PALETTEENTRY *pPaletteColors);      // Colours to use for palette

    // These manage the colour key negotiation

    STDMETHODIMP GetDefaultColorKey(COLORKEY *pColorKey);
    STDMETHODIMP GetColorKey(COLORKEY *pColorKey);
    STDMETHODIMP SetColorKey(COLORKEY *pColorKey);
    STDMETHODIMP GetWindowHandle(HWND *pHwnd);

    // The IOverlay interface allocates the memory for the clipping rectangles
    // as it is variable in length. The filter calling this method should free
    // the memory when it has finished using them by calling OLE CoTaskMemFree

    STDMETHODIMP GetClipList(RECT *pSourceRect,
                             RECT *pDestinationRect,
                             RGNDATA **ppRgnData);

    // The calls to OnClipChange happen in sync with the window. So it is
    // called with an empty clip list before the window moves to freeze
    // the video, and then when the window has stabilised it is called
    // again with the new clip list. The OnPositionChange callback is for
    // overlay cards that don't want the expense of synchronous clipping
    // updates and just want to know when the source or destination video
    // positions change. They will NOT be called in sync with the window
    // but at some point after the window has changed (basicly in time
    // with WM_SIZE etc messages received). This is therefore suitable
    // for overlay cards that don't inlay their data to the frame buffer

    STDMETHODIMP GetVideoPosition(RECT *pSourceRect,
                                  RECT *pDestinationRect);

    // This provides synchronous clip changes so that the client is called
    // before the window is moved to freeze the video, and then when the
    // window has stabilised it is called again to start playback again.
    // If the window rect is all zero then the window is invisible, the
    // filter must take a copy of the information if it wants to keep it

    STDMETHODIMP Advise(
        IOverlayNotify *pOverlayNotify,     // Notification interface
        DWORD dwInterests);                 // Callbacks interested in

    STDMETHODIMP Unadvise();
};

#endif // __OVERLAY__
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\multimedia\dshow\filters\image\video\makefile.inc ===
# NOTE:
# this directory contains a makefile which contains a single line that
# includes the global build process makefile.def. If the
# NTTARGETFILE1 or NTTARGETFILE0 environment
# variable is set then makefile.def includes makefile.inc from the current
# directory. This makefile.inc creates an extra target for nmake to create
# when it is run. NTTARGETFILE0 is built before everything else, and
# NTTARGETFILE1 is built after everything else.

copyfiles:
  @if exist obj\$(TARGET_DIRECTORY)\$(TARGETNAME).dll  \
    copy obj\$(TARGET_DIRECTORY)\$(TARGETNAME).dll     \
         $(SDK_ROOT)\bin\*.*
  @if not exist $(QUARTZ)\lib\$(TARGET_DIRECTORY) \
    md $(QUARTZ)\lib\$(TARGET_DIRECTORY)
  @if exist obj\$(TARGET_DIRECTORY)\$(TARGETNAME).lib  \
    copy obj\$(TARGET_DIRECTORY)\$(TARGETNAME).lib     \
         $(QUARTZ)\lib\$(TARGET_DIRECTORY)\*.*


=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\multimedia\dshow\filters\image\video\direct.cpp ===
// Copyright (c) 1994 - 1999  Microsoft Corporation.  All Rights Reserved.
// Implements the COverlay class, Anthony Phillips, February 1995

#include <streams.h>
#include <windowsx.h>
#include <render.h>
#include <viddbg.h>

// This object implements the IOverlay interface which in certain places uses
// information stored in the owning renderer object, such as the connection
// established flag and the media type. Therefore the interface methods must
// lock the complete object before starting. However other internal threads
// may call us to set our internal state, such as a notification that the
// media type connection has changed (and therefore possibly the palette).
// In which case we cannot lock the entire object so we have our own private
// critical section that ALL the objects methods lock before commencing
//
// There is some complication with providing two transport interfaces to the
// video renderer. Because we get told of the media type to use for a filter
// connection after it tries to get hold of a transport interface we always
// provide both interfaces (IMemInputPin and IOverlay). However if the media
// type is MEDIASUBTYPE_Overlay we do not permit IMemInputPin calls. If the
// connection is for normal media samples then the source filter cannot call
// this interface at all (this prevents conflicts we may get with palettes)


// Constructor NOTE we set the owner of the object to be NULL (through the
// CUnknown constructor call) and then override all of the non delegating
// IUnknown methods. Within the AddRef and Release we delegate the reference
// counting to the owning renderer. We return IOverlay interfaces from the
// QueryInterface and route any other interface requests to the input pin

COverlay::COverlay(CRenderer *pRenderer,    // Main video renderer
                   CDirectDraw *pDirectDraw,
                   CCritSec *pLock,         // Object to lock with
                   HRESULT *phr) :          // Constructor return

    CUnknown(NAME("Overlay object"),NULL),
    m_pInterfaceLock(pLock),
    m_dwInterests(ADVISE_NONE),
    m_pRenderer(pRenderer),
    m_hPalette(NULL),
    m_bFrozen(FALSE),
    m_hHook(NULL),
    m_pDirectDraw(pDirectDraw),
    m_pNotify(NULL),
    m_DefaultCookie(INVALID_COOKIE_VALUE),
    m_bMustRemoveCookie(FALSE)
{
    ASSERT(m_pRenderer);
    ASSERT(m_pInterfaceLock);
    ResetColourKeyState();
    SetRectEmpty(&m_TargetRect);
}


// Destructor

COverlay::~COverlay()
{
    // Remove any palette left around

    if (m_hPalette) {
        NOTE("Deleting palette");
        EXECUTE_ASSERT(DeleteObject(m_hPalette));
        m_hPalette = NULL;
    }

    // update the overlay colorkey cookie counter

    if (m_bMustRemoveCookie) {
        // m_DefaultCookie should contain a valid cookie
        // value if m_bMustRemoveCookie is TRUE.
        ASSERT(m_DefaultCookie != INVALID_COOKIE_VALUE);

        RemoveCurrentCookie(m_DefaultCookie);
    }

    // Release any notification link

    if (m_pNotify) {
        NOTE("Releasing link");
        m_pNotify->Release();
        m_pNotify = NULL;
    }
}


// Check we connected to use the IOverlay transport

HRESULT COverlay::ValidateOverlayCall()
{
    NOTE("Entering ValidateOverlayCall");

    // Check we are connected otherwise reject the call

    if (m_pRenderer->m_InputPin.IsConnected() == FALSE) {
        NOTE("Pin is not connected");
        return VFW_E_NOT_CONNECTED;
    }

    // Is this a purely overlay connection

    GUID SubType = *(m_pRenderer->m_mtIn.Subtype());
    if (SubType != MEDIASUBTYPE_Overlay) {
        NOTE("Not an overlay connection");
        return VFW_E_NOT_OVERLAY_CONNECTION;
    }
    return NOERROR;
}


// This resets the colour key information

void COverlay::ResetColourKeyState()
{
    NOTE("Entering ResetColourKey");

    m_bColourKey = FALSE;
    m_WindowColour = 0;
    m_ColourKey.KeyType = CK_NOCOLORKEY;
    m_ColourKey.PaletteIndex = 0;			
    m_ColourKey.LowColorValue = 0;
    m_ColourKey.HighColorValue = 0;
}


// Initialise a default colour key. We will have got the next available RGB
// colour from a shared memory segment when we were constructed. The shared
// memory segment is also used by the video DirectDraw overlay object. Once
// we have a COLORREF we will need it mapped to an actual palette index. If
// we are on a true colour device which has no palette then it returns zero

void COverlay::InitDefaultColourKey(COLORKEY *pColourKey)
{
    COLORREF DefaultColourKey;
    NOTE("Entering InitDefaultColourKey");
    // We have not gotten this yet - we can't do it in our constructor since
    // the monitor name is not valid yet
    if (INVALID_COOKIE_VALUE == m_DefaultCookie) {
        HRESULT hr = GetNextOverlayCookie(m_pRenderer->m_achMonitor, &m_DefaultCookie);
        if (SUCCEEDED(hr)) {
            m_bMustRemoveCookie = TRUE;
        } else {
            // This cookie value is used by the Video Renderer 
            // if GetNextOverlayCookie() fails.
            m_DefaultCookie = DEFAULT_COOKIE_VALUE;
        }

        // m_DefaultCookie should contain a valid cookie value because
        // GetNextOverlayCookie() sets m_DefaultCookie to a valid 
        // cookie value if it succeeds.  If GetNextOverlayCookie() 
        // fails, m_DefaultCookie is set to DEFAULT_COOKIE_VALUE
        // which is also a valid cookie value.
        ASSERT(INVALID_COOKIE_VALUE != m_DefaultCookie);
    }

    DefaultColourKey = GetColourFromCookie(m_pRenderer->m_achMonitor, m_DefaultCookie);

    pColourKey->KeyType = CK_NOCOLORKEY;
    pColourKey->LowColorValue = DefaultColourKey;
    pColourKey->HighColorValue = DefaultColourKey;
    pColourKey->PaletteIndex = GetPaletteIndex(DefaultColourKey);
}


// Return the default colour key that we could use, this sets up a colour key
// that has a palette index range from zero to zero and a RGBQUAD true colour
// space range also from zero to zero. If we're ending up using this then we
// are guaranteed that one of these could be mapped to the video display

STDMETHODIMP COverlay::GetDefaultColorKey(COLORKEY *pColorKey)
{
    NOTE("Entering GetDefaultColorKey");
    CheckPointer(pColorKey,E_POINTER);
    CAutoLock cInterfaceLock(m_pInterfaceLock);
    CAutoLock cVideoLock(this);

    // Get a default key and set the type

    NOTE("Returning default colour key");
    InitDefaultColourKey(pColorKey);
    pColorKey->KeyType = CK_INDEX | CK_RGB;
    return NOERROR;
}


// Get the current colour key the renderer is using. The window colour key
// we store (m_ColourKey) defines the actual requirements the filter asked
// for when it called SetColorKey. We return the colour key that we are
// using in the window (and which we calculated from the requirements)

STDMETHODIMP COverlay::GetColorKey(COLORKEY *pColorKey)
{
    NOTE("Entering GetColorKey");
    CheckPointer(pColorKey,E_POINTER);
    CAutoLock cInterfaceLock(m_pInterfaceLock);
    CAutoLock cVideoLock(this);
    return GetWindowColourKey(pColorKey);
}


// This returns a COLORKEY structure based on the current colour key we have
// calculated (held in m_WindowColour). GDI uses reserved bits in the flags
// field to indicate if this is a palette index or RGB colour. If we are not
// using a colour key then we return an error E_FAIL to the caller, NOTE the
// default window colour key can be obtained by calling GetDefaultColorKey

HRESULT COverlay::GetWindowColourKey(COLORKEY *pColourKey)
{
    NOTE("Entering GetWindowColourKey");
    InitDefaultColourKey(pColourKey);

    // Are we using an overlay colour key

    if (m_bColourKey == FALSE) {
        NOTE("No colour key defined");
        return VFW_E_NO_COLOR_KEY_SET;
    }

    // Is the colour key a palette entry, we cannot work out the palette index
    // they asked for from the COLORREF value we store as it only contains the
    // map into the system palette so we go back to the initial requirements

    if (m_WindowColour & PALETTEFLAG) {
        NOTE("Palette index colour key");
        pColourKey->KeyType = CK_INDEX;
        pColourKey->PaletteIndex = m_ColourKey.PaletteIndex;
        return NOERROR;
    }

    ASSERT(m_WindowColour & TRUECOLOURFLAG);
    NOTE("True colour colour key defined");

    // This must be a standard RGB colour, for the sake of simplicity we take
    // off the GDI reserved bits that identify this as a true colour value

    pColourKey->KeyType = CK_RGB;
    pColourKey->LowColorValue = m_WindowColour & ~TRUECOLOURFLAG;
    pColourKey->HighColorValue = m_WindowColour & ~TRUECOLOURFLAG;

    return NOERROR;
}


// Check the colour key can be changed doing a quick parameter check and also
// see if there was a palette installed (through SetKeyPalette) which would
// conflict with us making one. If there is a custom colour palette installed
// then the source filter must remove it first. NOTE also if we have a palette
// installed (not a colour key one) then we know that we won't ever be able to
// find a true colour colour key so it is valid to return an error code

HRESULT COverlay::CheckSetColourKey(COLORKEY *pColourKey)
{
    NOTE("Entering CheckSetColourKey");

    // Check overlay calls are allowed

    HRESULT hr = ValidateOverlayCall();
    if (FAILED(hr)) {
        return hr;
    }

    // Is there a palette installed

    if (m_bColourKey == FALSE) {
        if (m_hPalette) {
            NOTE("Palette already set");
            return VFW_E_PALETTE_SET;
        }
    }

    // Check the colour key parameter is valid

    if (pColourKey == NULL) {
        NOTE("NULL pointer");
        return E_INVALIDARG;
    }

    return NOERROR;
}


// Set the colour key the renderer is to use for painting the window, first
// of all check the colour key can be set. If the source filter has already
// successfully called SetKeyPalette to make a custom set of colours then
// this will fail as they should remove it first. We then look for either a
// true colour or a palette index that will match one of their requirements

STDMETHODIMP COverlay::SetColorKey(COLORKEY *pColorKey)
{
    NOTE("Entering SetColorKey");

    CheckPointer(pColorKey,E_POINTER);
    CAutoLock cInterfaceLock(m_pInterfaceLock);
    CAutoLock cVideoLock(this);

    // Check the colour key can be changed

    HRESULT hr = CheckSetColourKey(pColorKey);
    if (FAILED(hr)) {
        return hr;
    }

    // Are we having the colour key turned off (CK_NOCOLORKEY is 0)

    if (pColorKey->KeyType == 0) {
        ResetColourKeyState();
        InstallPalette(NULL);
        m_pRenderer->m_VideoWindow.PaintWindow(TRUE);
        return NOERROR;
    }

    // Look after the colour key negotiation

    hr = MatchColourKey(pColorKey);
    if (FAILED(hr)) {
        return hr;
    }

    NOTE("Notifying colour key");
    NotifyChange(ADVISE_COLORKEY);
    return GetColorKey(pColorKey);
}


// Find a colour key that can be used by the filter. We may be asked to unset
// any colour key use (the key type is CK_NOCOLORKEY) in which case we reset
// the colour key state and release any palette resource we were holding. If
// we are being asked to set a new colour key then we go into the negotiation
// process, this tries to satisfy the colour key requirements based on the
// current video display format. If it has a choice of creating a colour key
// based on a palette index, or on a RGB colour it will pick the index

HRESULT COverlay::MatchColourKey(COLORKEY *pColourKey)
{
    NOTE("Entering MatchColourKey");

    HPALETTE hPalette = NULL;       // New palette we may create
    COLORREF OverlayColour = 0;   	// Overlay colour for window
    HRESULT hr = NOERROR;           // General OLE return code

    // Find a suitable colour key

    hr = NegotiateColourKey(pColourKey,&hPalette,&OverlayColour);
    if (FAILED(hr)) {
        NOTE("No match");
        return hr;
    }

    InstallColourKey(pColourKey,OverlayColour);

    // We set the hPalette field to NULL before starting. If we get to here
    // and it hasn't been changed we still call the function. The function
    // not only installs a new palette if available but cleans up resources
    // we used for any previous colour key (including any colour palette)

    NOTE("Installing colour key");
    InstallPalette(hPalette);
    m_pRenderer->m_VideoWindow.PaintWindow(TRUE);
    return NOERROR;
}


// This is passed a colour key that the connected filter would like us to
// honour. This can be a range of RGB true colours or a particular palette
// index. We match it's requirements against the device capabilities and
// fill in the input parameters with the chosen colour and return NOERROR

HRESULT COverlay::NegotiateColourKey(COLORKEY *pColourKey,
                                     HPALETTE *phPalette,
                                     COLORREF *pColourRef)
{
    NOTE("Entering NegotiateColourKey");

    VIDEOINFO *pDisplay;        // Video display format
    HRESULT hr = NOERROR;       // General OLE return code

    pDisplay = (VIDEOINFO *) m_pRenderer->m_Display.GetDisplayFormat();

    // Try and find a palette colour key

    if (pColourKey->KeyType & CK_INDEX) {
        hr = NegotiatePaletteIndex(pDisplay,pColourKey,phPalette,pColourRef);
        if (SUCCEEDED(hr)) {
            NOTE("No palette");
            return hr;
        }
    }

    // Try and find a true colour match

    if (pColourKey->KeyType & CK_RGB) {
        hr = NegotiateTrueColour(pDisplay,pColourKey,pColourRef);
        if (SUCCEEDED(hr)) {
            NOTE("No true colour");
            return hr;
        }
    }
    return VFW_E_NO_COLOR_KEY_FOUND;
}


// Create a palette that references the system palette directly. This is used
// by MPEG boards the overlay their video where they see an explicit palette
// index so we cannot use a normal PALETTEENTRY as it will be mapped to the
// current system palette, where what we really want is to draw using our
// palette index value regardless of what colour will appear on the screen

HRESULT COverlay::NegotiatePaletteIndex(VIDEOINFO *pDisplay,
                                        COLORKEY *pColourKey,
                                        HPALETTE *phPalette,
                                        COLORREF *pColourRef)
{
    NOTE("Entering NegotiatePaletteIndex");
    LOGPALETTE LogPal;

    // Is the display set to use a palette

    if (PALETTISED(pDisplay) == FALSE) {
        NOTE("Not palettised");
        return E_INVALIDARG;
    }

    // Is the palette index too large for the video display

    if (pColourKey->PaletteIndex >= PALETTE_ENTRIES(pDisplay)) {
        NOTE("Too many colours");
        return E_INVALIDARG;
    }

    // The palette index specified in the input parameters becomes the source
    // of the new colour key. Instead of it being a logical value referencing
    // a colour in the palette it becomes an absolute device value so when we
    // draw with this palette index it is really that value that appears in
    // the frame buffer regardless of what colour it may actually appear as

    LogPal.palPalEntry[0].peRed = (UCHAR) pColourKey->PaletteIndex;
    LogPal.palPalEntry[0].peGreen = 0;
    LogPal.palPalEntry[0].peBlue = 0;
    LogPal.palPalEntry[0].peFlags = PC_EXPLICIT;

    LogPal.palVersion = PALVERSION;
    LogPal.palNumEntries = 1;

    *phPalette = CreatePalette(&LogPal);
    if (*phPalette == NULL) {
        NOTE("Palette failed");
        return E_FAIL;
    }
    *pColourRef = PALETTEINDEX(0);
    return NOERROR;
}


// The filter would like to use a RGB true colour value picked from a range
// of values defined in the colour key. If video display is palettised then
// we try and pick an entry that matches the colour. If the video display is
// true colour then we find an intersection of the two colour spaces

HRESULT COverlay::NegotiateTrueColour(VIDEOINFO *pDisplay,
                                      COLORKEY *pColourKey,
                                      COLORREF *pColourRef)
{
    NOTE("Entering NegotiateTrueColour");

    // Must be a true colour device

    if (PALETTISED(pDisplay) == TRUE) {
        NOTE("Palettised");
        return E_INVALIDARG;
    }

    // Get the colour bit field masks for the display, this should always
    // succeed as the information we use in this call is checked when the
    // display object is initially constructed. It returns the masks that
    // are needed to calculate the valid range of values for each colour

    DWORD MaskRed, MaskGreen, MaskBlue;
    EXECUTE_ASSERT(m_pRenderer->m_Display.GetColourMask(&MaskRed,
                                                        &MaskGreen,
                                                        &MaskBlue));

    // We take each colour component range in turn and shift the values right
    // and AND them with 0xFF so that we have their undivided attention. We
    // then loop between the low and high values trying to find one which
    // the display would accept. This is done by an AND with the display
    // bit field mask, if the resulting value is still in the source filter
    // desired range then we have a hit. The value is stored in the output
    // array until we have done all three when we then create the COLORREF

    DWORD RGBShift[] = { 0, 8, 16 };
    DWORD DisplayMask[] = { MaskRed, MaskGreen, MaskBlue };
    DWORD ColourMask[] = { INFINITE, INFINITE, INFINITE };

    DWORD MinColour, MaxColour;
    for (INT iColours = iRED;iColours <= iBLUE;iColours++) {

        // Extract the minimum and maximum colour component values

        MinColour = (pColourKey->LowColorValue >> RGBShift[iColours]) & 0xFF;
        MaxColour = (pColourKey->HighColorValue >> RGBShift[iColours]) & 0xFF;

        // Check they are the right way round

        if (MinColour > MaxColour) {
            return E_INVALIDARG;
        }

        // See if any of them are acceptable by the display format
        for (DWORD Value = MinColour;Value <= MaxColour;Value++) {

            DWORD ColourTest = Value & DisplayMask[iColours];
            if (ColourTest >= MinColour) {
                if (ColourTest <= MaxColour) {
                    ColourMask[iColours] = ColourTest;
                    break;
                }
            }
        }

        // If no colour in the source filter's range could be matched against
        // the display requirements then the colour value will be INFINITE

        if (ColourMask[iColours] == INFINITE) {
            return E_FAIL;
        }
    }

    // We now have three valid colours in the ColourMask array so all we have
    // to do is combine them into a COLORREF the GDI defined macro. The macro
    // PALETTERGB sets a reserved bit in the most significant byte which GDI
    // uses to identify the colour as a COLORREF rather than a RGB triplet

    *pColourRef = PALETTERGB(ColourMask[iRED],
                             ColourMask[iGREEN],
                             ColourMask[iBLUE]);
    return NOERROR;
}


// Install the new colour key details

HRESULT COverlay::InstallColourKey(COLORKEY *pColourKey,COLORREF Colour)
{
    NOTE("Entering InstallColourKey");

    m_bColourKey = TRUE;              // We are using an overlay colour key
    m_ColourKey = *pColourKey;        // These are the original requirements
    m_WindowColour = Colour;          // This is the actual colour selected

    return NOERROR;
}


// This is called to install a new palette into the video window but it also
// looks after freeing any previous palette resources so the input parameter
// may be NULL. In this case we simply install the standard VGA palette. We
// delete the old palette once the new has been installed using DeleteObject
// which should in principle never fail hence the EXECUTE_ASSERT round it

HRESULT COverlay::InstallPalette(HPALETTE hPalette)
{
    NOTE("Entering InstallPalette");
    BOOL bInstallSystemPalette = FALSE;

    // Is there any palette work required

    if (m_hPalette == NULL) {
        if (hPalette == NULL) {
            return NOERROR;
        }
    }

    // If we have no new palette then install a standard VGA

    if (hPalette == NULL) {
        hPalette = (HPALETTE) GetStockObject(DEFAULT_PALETTE);
        bInstallSystemPalette = TRUE;
        NOTE("Installing VGA palette");
    }

    // We have a new palette to install and possibly a previous one to delete
    // this will lock the window object critical section and then install and
    // realise our new palette. The locking stops any window thread conflicts
    // but we must be careful not to cause any messages to be sent across as
    // the window thread may be waiting to enter us to handle a WM_PAINT call

    m_pRenderer->m_VideoWindow.SetKeyPalette(hPalette);
    if (m_hPalette) {
        EXECUTE_ASSERT(DeleteObject(m_hPalette));
        NOTE("Deleting palette");
        m_hPalette = NULL;
    }

    // If we installed a VGA palette then we do not own it

    if (bInstallSystemPalette == TRUE) {
        hPalette = NULL;
    }
    m_hPalette = hPalette;
    return NOERROR;
}


// The clipping rectangles we retrieved from DCI will be for the entire client
// rectangle not just for the current destination video area. We scan through
// the list intersecting each with the video rectangle. This is complicated as
// we must remove any empty rectangles and shunt further ones down the list

HRESULT COverlay::AdjustForDestination(RGNDATA *pRgnData)
{
    NOTE("Entering AdjustForDestination");

    ASSERT(pRgnData);       // Don't call with NULL regions
    DWORD Output = 0;       // Total number of rectangles
    RECT ClipRect;          // Intersection of the clips

    RECT *pBoundRect = &(pRgnData->rdh.rcBound);
    RECT *pRectArray = (RECT *) pRgnData->Buffer;

    for (DWORD Count = 0;Count < pRgnData->rdh.nCount;Count++) {
        if (IntersectRect(&ClipRect,&pRectArray[Count],pBoundRect)) {
            pRectArray[Output++] = ClipRect;
        }
    }

    // Complete the RGNDATAHEADER structure

    pRgnData->rdh.nCount = Output;
    pRgnData->rdh.nRgnSize = Output * sizeof(RECT);
    pRgnData->rdh.iType = RDH_RECTANGLES;
    return NOERROR;
}


// The gets the video area clipping rectangles and the RGNDATAHEADER that is
// used to decribe them. The clip list is variable length so we allocate the
// memory which the caller should free it when finished (using CoTaskMemFree)
// An overlay source filter will want the clip list for the window client area
// not for the window as a whole including borders and captions so we call an
// API provided in DCI that returns the clip list based on a device context

HRESULT COverlay::GetVideoClipInfo(RECT *pSourceRect,
                                   RECT *pDestinationRect,
                                   RGNDATA **ppRgnData)
{
    NOTE("Entering GetVideoClipInfo");
    GetVideoRect(pDestinationRect);
    m_pRenderer->m_DrawVideo.GetSourceRect(pSourceRect);
    ASSERT(CritCheckIn(this));

    // Do they want the clip list as well

    if (ppRgnData == NULL) {
        return NOERROR;
    }


    DWORD dwSize;
    LPDIRECTDRAWCLIPPER lpClipper;

    lpClipper = m_pDirectDraw->GetOverlayClipper();
    if (!lpClipper) {
        NOTE("No clipper");
        return E_OUTOFMEMORY;
    }

    HWND hwnd = m_pRenderer->m_VideoWindow.GetWindowHWND();
    lpClipper->SetHWnd(0, hwnd);

    lpClipper->GetClipList(NULL, NULL, &dwSize);
    ASSERT(dwSize >= sizeof(RGNDATAHEADER));

    *ppRgnData = (RGNDATA *)QzTaskMemAlloc(dwSize);
    if (*ppRgnData == NULL) {
        NOTE("No clip memory");
        return E_OUTOFMEMORY;
    }

    lpClipper->GetClipList(NULL, *ppRgnData, &dwSize);

    IntersectRect(&(*ppRgnData)->rdh.rcBound, &(*ppRgnData)->rdh.rcBound,
                  (RECT *)pDestinationRect);

    return AdjustForDestination(*ppRgnData);
}


// Return the destination rectangle in display coordinates rather than the
// window coordinates we keep it in. This means getting the screen offset
// of where the window's client area starts and adding this to the target
// rectangle. This may produce an invalid destination rectangle if we're
// in the process of either being minimised or being restored for an icon

HRESULT COverlay::GetVideoRect(RECT *pVideoRect)
{
    NOTE("Entering GetVideoRect");
    ASSERT(pVideoRect);

    // Handle window state changes and iconic windows.  If we have been
    // made a child window of another window and that window has been
    // made "minimized" our window will not have the iconic style.  So we
    // have to navigate up to the top level window and check to see
    // if it has been made iconic.

    HWND hwnd = m_pRenderer->m_VideoWindow.GetWindowHWND();
    HWND hwndParent = hwnd;

    for ( ;; ) {

        if (IsIconic(hwndParent)) {
            SetRectEmpty(pVideoRect);
            return NOERROR;
        }

        HWND hwndT = GetParent(hwndParent);
        if (hwndT == (HWND)NULL) break;
        hwndParent = hwndT;
    }


    // Get the client corner in screen coordinates

    POINT TopLeftCorner;
    TopLeftCorner.x = TopLeftCorner.y = 0;
    EXECUTE_ASSERT(ClientToScreen(hwnd,&TopLeftCorner));
    m_pRenderer->m_DrawVideo.GetTargetRect(pVideoRect);


    // Add the actual display offset to the destination

    pVideoRect->top += TopLeftCorner.y;
    pVideoRect->bottom += TopLeftCorner.y;
    pVideoRect->left += TopLeftCorner.x;
    pVideoRect->right += TopLeftCorner.x;

    return NOERROR;
}


// This is used by source filters to retrieve the clipping information for a
// video window. We may be called when the window is currently frozen but all
// we do is to return the clipping information available through DCI and let
// it worry about any serialisation problems with other windows moving about

STDMETHODIMP COverlay::GetClipList(RECT *pSourceRect,
                                   RECT *pDestinationRect,
                                   RGNDATA **ppRgnData)
{
    NOTE("Entering GetClipList");

    // Return E_INVALIDARG if any of the pointers are NULL

    CheckPointer(pSourceRect,E_POINTER);
    CheckPointer(pDestinationRect,E_POINTER);
    CheckPointer(ppRgnData,E_POINTER);

    // Now we can go ahead and handle the clip call

    CAutoLock cInterfaceLock(m_pInterfaceLock);
    CAutoLock cVideoLock(this);
    return GetVideoClipInfo(pSourceRect,pDestinationRect,ppRgnData);
}


// This returns the current source and destination video rectangles. Source
// rectangles can be updated through this IBasicVideo interface as can the
// destination. The destination rectangle we store is in window coordinates
// and is typically updated when the window is sized. We provide a callback
// OnPositionChanged that notifies the source when either of these changes

STDMETHODIMP COverlay::GetVideoPosition(RECT *pSourceRect,
                                        RECT *pDestinationRect)
{
    NOTE("Entering GetVideoPosition");
    CheckPointer(pSourceRect,E_POINTER);
    CheckPointer(pDestinationRect,E_POINTER);

    // Lock the overlay and renderer objects

    CAutoLock cInterfaceLock(m_pInterfaceLock);
    CAutoLock cVideoLock(this);
    return GetVideoClipInfo(pSourceRect,pDestinationRect,NULL);
}


// When we create a new advise link we must prime the newly connected object
// with the overlay information which includes the clipping information, any
// palette information for the current connection and the video colour key
// When we are handed the IOverlayNotify interface we hold a reference count
// on that object so that it won't go away until the advise link is stopped

STDMETHODIMP COverlay::Advise(IOverlayNotify *pOverlayNotify,DWORD dwInterests)
{
    NOTE("Entering Advise");

    // Check the pointers provided are non NULL

    CheckPointer(pOverlayNotify,E_POINTER);
    CAutoLock cInterfaceLock(m_pInterfaceLock);
    CAutoLock cVideoLock(this);

    // Is there an advise link already defined

    if (m_pNotify) {
        NOTE("Advise link already set");
        return VFW_E_ADVISE_ALREADY_SET;
    }

    // Check they want at least one kind of notification

    if ((dwInterests & ADVISE_ALL) == 0) {
        NOTE("ADVISE_ALL failed");
        return E_INVALIDARG;
    }

    // Initialise our overlay notification state

    m_pNotify = pOverlayNotify;
    m_pNotify->AddRef();
    m_dwInterests = dwInterests;
    OnAdviseChange(TRUE);
    NotifyChange(ADVISE_ALL);
    return NOERROR;
}


// This is called when an advise link is installed or removed on the video
// renderer. If an advise link is being installed then the bAdviseAdded
// parameter is TRUE otherwise it is FALSE. We are only really interested
// when either we had a previous notification client or we are going to
// have no notification client as that starts and stops global hooking

BOOL COverlay::OnAdviseChange(BOOL bAdviseAdded)
{
    HWND hwnd = m_pRenderer->m_VideoWindow.GetWindowHWND();
    NOTE("Entering OnAdviseChange");
    NOTE2("Advised %d Interests %d",bAdviseAdded,m_dwInterests);

    // We need to reset ourselves after closing the link

    if (bAdviseAdded == FALSE) {
        NOTE("Removing global window hook");
        PostMessage(hwnd,WM_UNHOOK,0,0);
        ResetColourKeyState();
        InstallPalette(NULL);
        m_pRenderer->m_VideoWindow.PaintWindow(TRUE);
    }

    // Do we need to stop any update timer

    if (bAdviseAdded == FALSE) {
        if (m_dwInterests & ADVISE_POSITION) {
            StopUpdateTimer();
            NOTE("Stopped timer");
        }
        return TRUE;
    }

    // Should we install a global hook

    if (m_dwInterests & ADVISE_CLIPPING) {
        NOTE("Requesting global hook");
        PostMessage(hwnd,WM_HOOK,0,0);
    }

    // Do we need to start an update timer

    if (m_dwInterests & ADVISE_POSITION) {
        StartUpdateTimer();
        NOTE("Started timer");
    }
    return TRUE;
}


// Close the advise link with the renderer. Remove the associated link with
// the source, we release the interface pointer the filter gave us during
// the advise link creation. This may be the last reference count held on
// that filter and cause it to be deleted NOTE we call OnAdviseChange so
// that the overlay state is updated which may stop the global message hook

STDMETHODIMP COverlay::Unadvise()
{
    NOTE("Entering Unadvise");
    CAutoLock cInterfaceLock(m_pInterfaceLock);
    CAutoLock cVideoLock(this);

    // Do we have an advise link setup

    if (m_pNotify == NULL) {
        return VFW_E_NO_ADVISE_SET;
    }



    // Release the notification interface

    m_pNotify->Release();
    m_pNotify = NULL;
    OnAdviseChange(FALSE);
    m_dwInterests = ADVISE_NONE;
    return NOERROR;
}


// Overriden to say what interfaces we support

STDMETHODIMP COverlay::NonDelegatingQueryInterface(REFIID riid,VOID **ppv)
{
    NOTE("Entering NonDelegatingQueryInterface");

    // We return IOverlay and delegate everything else to the pin

    if (riid == IID_IOverlay) {
        return GetInterface((IOverlay *)this,ppv);
    }
    return m_pRenderer->m_InputPin.QueryInterface(riid,ppv);
}


// Overriden to increment the owning object's reference count

STDMETHODIMP_(ULONG) COverlay::NonDelegatingAddRef()
{
    NOTE("Entering NonDelegatingAddRef");
    return m_pRenderer->AddRef();
}


// Overriden to decrement the owning object's reference count

STDMETHODIMP_(ULONG) COverlay::NonDelegatingRelease()
{
    NOTE("Entering NonDelegatingRelease");
    return m_pRenderer->Release();
}


// This is called when we receive WM_PAINT messages in the window object. We
// always get first chance to handle these messages, if we have an IOverlay
// connection and the source has installed a colour key then we fill the
// window with it and return TRUE. Returning FALSE means we did not handle
// the paint message and someone else will have to do the default filling

BOOL COverlay::OnPaint()
{
    NOTE("Entering OnPaint");
    CAutoLock cAutoLock(this);
    RECT TargetRect;

    // If we receive a paint message and we are currently frozen then it's a
    // fair indication that somebody on top of us moved away without telling
    // us to thaw out. So start our video window and update any prospective
    // source filter with the clipping notifications. if we are currently
    // streaming then we do not repaint the window as it causes the window
    // to flash as another video frame will be displayed over it shortly

    m_pRenderer->m_Overlay.ThawVideo();
    if (m_bColourKey == FALSE) {
        NOTE("Handling no colour key defined");
        DWORD Mask = ADVISE_CLIPPING | ADVISE_POSITION;
        return (m_dwInterests & Mask ? TRUE : FALSE);
    }

    // Paint our colour key in the window

    HDC hdc = m_pRenderer->m_VideoWindow.GetWindowHDC();
    m_pRenderer->m_DrawVideo.GetTargetRect(&TargetRect);
    COLORREF BackColour = SetBkColor(hdc,m_WindowColour);
    ExtTextOut(hdc,0,0,ETO_OPAQUE,&TargetRect,NULL,0,NULL);
    SetBkColor(hdc,BackColour);

    return TRUE;
}


// Get the system palette we have currently realised. It is possible that a
// source filter may be interested in the current system palette. For example
// a hardware board could do on board conversion from true colour images that
// it produces during decompresses to the current system palette realised. We
// allocate the memory for the palette entries which the caller will release

STDMETHODIMP COverlay::GetPalette(DWORD *pdwColors,PALETTEENTRY **ppPalette)
{
    NOTE("Entering GetPalette");

    CheckPointer(pdwColors,E_POINTER);
    CheckPointer(ppPalette,E_POINTER);
    CAutoLock cInterfaceLock(m_pInterfaceLock);
    CAutoLock cVideoLock(this);
    return GetDisplayPalette(pdwColors,ppPalette);
}


// This allocates memory for and retrieves the current system palette. This is
// called by the GetPalette interface function and also when we want to update
// any notification clients of a system palette change. In either case whoever
// calls this function is responsible for deleting the memory we allocate

HRESULT COverlay::GetDisplayPalette(DWORD *pColors,PALETTEENTRY **ppPalette)
{
    NOTE("Entering GetDisplayPalette");

    // Does the current display device setting use a palette

    const VIDEOINFO *pDisplay = m_pRenderer->m_Display.GetDisplayFormat();
    if (PALETTISED(pDisplay) == FALSE) {
        NOTE("No palette for this display");
        return VFW_E_NO_PALETTE_AVAILABLE;
    }

    // See how many entries the palette has

    *pColors = PALETTE_ENTRIES(pDisplay);
    ASSERT(*pColors);

    // Allocate the memory for the system palette NOTE because the memory for
    // the palette is being passed over an interface to another object which
    // may or may not have been written in C++ we must use CoTaskMemAlloc

    *ppPalette = (PALETTEENTRY *) QzTaskMemAlloc(*pColors * sizeof(RGBQUAD));
    if (*ppPalette == NULL) {
        NOTE("No memory");
        *pColors = FALSE;
        return E_OUTOFMEMORY;
    }

    // Get the system palette using the window's device context

    HDC hdc = m_pRenderer->m_VideoWindow.GetWindowHDC();
    UINT uiReturn = GetSystemPaletteEntries(hdc,0,*pColors,*ppPalette);
    ASSERT(uiReturn == *pColors);

    return NOERROR;
}


// A source filter may want to install their own palette into the video window
// Before allowing them to do so we must ensure this is a palettised display
// device, that we don't have a media sample connection (which would install
// it's own palette and therefore conflict) and also that there is no colour
// key selected which also requires a special palette to be installed

HRESULT COverlay::CheckSetPalette(DWORD dwColors,PALETTEENTRY *pPaletteColors)
{
    NOTE("Entering CheckSetPalette");
    const VIDEOINFO *pDisplay;

    // Check overlay calls are allowed

    HRESULT hr = ValidateOverlayCall();
    if (FAILED(hr)) {
        return hr;
    }

    // Is the display set to use a palette

    pDisplay = (VIDEOINFO *) m_pRenderer->m_Display.GetDisplayFormat();
    if (PALETTISED(pDisplay) == FALSE) {
        NOTE("No palette for this display");
        return VFW_E_NO_DISPLAY_PALETTE;
    }

    // Check the number of colours makes sense

    if (dwColors > PALETTE_ENTRIES(pDisplay)) {
        NOTE("Too many palette colours");
        return VFW_E_TOO_MANY_COLORS;
    }

    // Are we using an overlay colour key - another alternative would be to
    // disregard the colour key palette and install the new one over the top
    // However it is probably more intuitive to make them remove the key

    if (m_bColourKey == TRUE) {
        NOTE("Colour key conflict");
        return VFW_E_COLOR_KEY_SET;
    }
    return NOERROR;
}


// A source filter may want to install it's own palette, for example an MPEG
// decoder may send palette information in a private bit stream and use that
// to dither on palettised displays. This function lets them install their
// LOGICAL palette, which is to say we create a logical palette from their
// colour selection and install it in our video window. If they want to know
// which of those colours and available they can query using GetPalette

STDMETHODIMP COverlay::SetPalette(DWORD dwColors,PALETTEENTRY *pPaletteColors)
{
    NOTE("Entering SetPalette");

    CAutoLock cInterfaceLock(m_pInterfaceLock);

    {
        CAutoLock cVideoLock(this);
        HPALETTE hPalette = NULL;

        // Make sure we can set a palette

        HRESULT hr = CheckSetPalette(dwColors,pPaletteColors);
        if (FAILED(hr)) {
            return hr;
        }

        // Creates a palette or just returns NULL if we are removing it

        hPalette = MakePalette(dwColors,pPaletteColors);
        InstallPalette(hPalette);
    }

    // The overlay object's lock cannot be held when calling 
    // CBaseWindow::PaintWindow() because this thread and the 
    // window thread could deadlock.
    m_pRenderer->m_VideoWindow.PaintWindow(TRUE);
    return NOERROR;
}


// This is called when we have been asked to install a custom colour palette
// for the source overlay filter. We copy the palette colours provided into
// a LOGPALETTE structure and then hand it to GDI for creation. If an error
// occurs we return NULL which we also do if they are setting no palette

HPALETTE COverlay::MakePalette(DWORD dwColors,PALETTEENTRY *pPaletteColors)
{
    NOTE("Entering MakePalette");
    LOGPALETTE *pPalette;
    HPALETTE hPalette;

    // Are we removing an installed palette - the source filter is forced to
    // do this if during processing (after installing a palette) it decides
    // it would like to use a colour key after all (also uses a palette)

    if (dwColors == 0 || pPaletteColors == NULL) {
        return NULL;
    }

    // We have to create a LOGPALETTE structure with the palette information
    // but rather than hassle around figuring out how much memory we really
    // need take a brute force approach and allocate the maximum possible

    pPalette = (LOGPALETTE *) new BYTE[sizeof(LOGPALETTE) + SIZE_PALETTE];
    if (pPalette == NULL) {
        NOTE("No memory");
        return NULL;
    }

    // Setup the version and the colour information

    pPalette->palVersion = PALVERSION;
    pPalette->palNumEntries = (WORD) dwColors;

    CopyMemory((PVOID) pPalette->palPalEntry,
               (PVOID) pPaletteColors,
               dwColors * sizeof(PALETTEENTRY));

    // Create the palette and delete the memory we allocated

    hPalette = CreatePalette(pPalette);
    delete[] pPalette;
    return hPalette;
}


// This is called when somebody detects a change in one or more of the states
// we keep our clients informed about, for example somebody realising their
// palette and therefore changing the system palette. The AdviseChanges field
// determines which of the four types of notification states has changed and
// the bPrimeOnly is TRUE when we want to just prime those new advise links
// If we are notifying the source of clip changes then we will be called via
// an interthread SendMessage to our window procedure by a global window hook

HRESULT COverlay::NotifyChange(DWORD AdviseChanges)
{
    NOTE1("Entering NotifyChange (%d)",AdviseChanges);

    RGNDATA *pRgnData = NULL;       // Contains clipping information
    PALETTEENTRY *pPalette = NULL;  // Pointer to list of colours
    DWORD dwColours;                // Number of palette colours
    COLORKEY ColourKey;             // The windows overlay colour
    RECT SourceRect;                // Section of video to use
    RECT DestinationRect;           // Where video is on the screen
    HRESULT hr = NOERROR;           // General OLE return code

    CAutoLock cVideoLock(this);

    // Is there a notification client

    if (m_pNotify == NULL) {
        NOTE("No client");
        return NOERROR;
    }

    // Do they want to know when the video rectangles change. These callbacks
    // do not occur in sync with the window moving like they do with the clip
    // changes, essentially we pass on information as we receive WM_MOVE etc
    // window messages. This is suitable for overlay cards that don't write
    // directly into the display and so don't mind being a little out of step

    if (AdviseChanges & ADVISE_POSITION & m_dwInterests) {
        hr = GetVideoClipInfo(&SourceRect,&DestinationRect,NULL);
        if (SUCCEEDED(hr)) {
            m_pNotify->OnPositionChange(&SourceRect,&DestinationRect);
            m_TargetRect = DestinationRect;
            NOTERC("Update destination",DestinationRect);
        }
    }

    // Do they want window clipping notifications, this is used by filters
    // doing direct inlay frame buffer video who want to know the actual
    // window clipping information which defines the video placement NOTE
    // ignore clipping changes while we are frozen as they cannot start
    // displaying video while the window size or position is changing

    if (AdviseChanges & ADVISE_CLIPPING & m_dwInterests) {
        hr = GetVideoClipInfo(&SourceRect,&DestinationRect,&pRgnData);
        if (SUCCEEDED(hr)) {
            m_pNotify->OnClipChange(&SourceRect,
                                    &DestinationRect,
                                    pRgnData);
        }
    }

    // Do they want system palette changes, it is possible that a filter
    // using a colour key to do overlay video will want to select it's
    // colour on a palettised display by choosing one from the current
    // system palette in which case it will be interested in this call

    if (AdviseChanges & ADVISE_PALETTE & m_dwInterests) {
        hr = GetDisplayPalette(&dwColours,&pPalette);
        if (SUCCEEDED(hr)) {
            m_pNotify->OnPaletteChange(dwColours,pPalette);
        }
    }

    // Do they want overlay colour key changes, this is the simplest form
    // of direct frame buffer video where a filter uses a colour key to
    // spot where it should be displaying it's video. Most cards that
    // use this also want to know the video window bounding rectangle

    if (AdviseChanges & ADVISE_COLORKEY & m_dwInterests) {
        hr = GetWindowColourKey(&ColourKey);
        if (SUCCEEDED(hr)) {
            m_pNotify->OnColorKeyChange(&ColourKey);
        }
    }

    // Release the memory allocated

    QzTaskMemFree(pRgnData);
    QzTaskMemFree(pPalette);
    return NOERROR;
}


// This is called when we need to temporarily freeze the video, for example
// when the window size is being changed (ie the clipping area is changing)
// We send the attached notification interface a clip change message where
// the new clipping area is a NULL set of rectangles. When the glitch ends
// our ThawVideo method will be called so we can reset the window clip list

HRESULT COverlay::FreezeVideo()
{
    static RECT Empty = {0,0,0,0};
    NOTE("Entering FreezeVideo");
    RGNDATAHEADER RgnData;
    CAutoLock cVideoLock(this);

    // Have we already been frozen or do we have no link

    if (m_bFrozen == TRUE || m_pNotify == NULL) {
        NOTE("No freeze");
        return NOERROR;
    }

    // Is the advise link interested in clip changes

    if ((m_dwInterests & ADVISE_CLIPPING) == 0) {
        NOTE("No ADVISE_CLIPPING");
        return NOERROR;
    }

    // Simulate a NULL clipping area for the video

    RgnData.dwSize = sizeof(RGNDATAHEADER);
    RgnData.iType = RDH_RECTANGLES;
    RgnData.nCount = 0;
    RgnData.nRgnSize = 0;
    SetRectEmpty(&RgnData.rcBound);
    m_bFrozen = TRUE;

    return m_pNotify->OnClipChange(&Empty,&Empty,(RGNDATA *)&RgnData);
}


// See if the video is currently frozen

BOOL COverlay::IsVideoFrozen()
{
    NOTE("Entering IsVideoFrozen");
    CAutoLock cVideoLock(this);
    return m_bFrozen;
}


// This is called after the video window has been temporarily frozen such as
// during the window size being changed. All we have to do is reset the flag
// and have each notification interface called with the real clipping list
// If a source filter set it's advise link when the video window was frozen
// then this will be the first time it will receive any clipping messages
// NOTE we found with some experimentation that we should always thaw the
// video when this method is called (normally via our WM_PAINT processing)
// regardless of whether or not we think that the video is currently stopped

HRESULT COverlay::ThawVideo()
{
    NOTE("Entering ThawVideo");
    CAutoLock cVideoLock(this);

    // Are we already thawed
    if (m_bFrozen == FALSE) {
        NOTE("No thaw");
        return NOERROR;
    }

    m_bFrozen = FALSE;
    NotifyChange(ADVISE_CLIPPING);
    return NOERROR;
}


// Return the window handle we are using. We don't do the usual checks when
// an IOverlay method is called as we always make the handle available. The
// reason being so that the MCI driver can get a hold of it by enumerating
// the pins on the renderer, calling QueryInterface for IOverlay and then
// calling this GetWindowHandle. This does mean that many other applications
// could do this but hopefully they will use the IVideoWindow to control us

STDMETHODIMP COverlay::GetWindowHandle(HWND *pHwnd)
{
    NOTE("Entering GetWindowHandle");
    CheckPointer(pHwnd,E_POINTER);
    *pHwnd = m_pRenderer->m_VideoWindow.GetWindowHWND();
    return NOERROR;
}


// If the source filter using IOverlay is looking for ADVISE_POSITION changes
// then we set an update timer. Each time it fires we get the current target
// rectangle and if it has changed we update the source. We cannot guarantee
// receieving WM_MOVE messages to do this as we may be a child window. We use
// a timer identifier of INFINITE which our DirectDraw code also uses as times

void COverlay::StartUpdateTimer()
{
    NOTE("Entering StartUpdateTimer");
    CAutoLock cVideoLock(this);

    // Start a timer with INFINITE as its identifier
    HWND hwnd = m_pRenderer->m_VideoWindow.GetWindowHWND();
    EXECUTE_ASSERT(SetTimer(hwnd,INFINITE,200,NULL));
}


// Complements StartUpdateTimer, will be called when a source filter calls us
// to stop an advise link with ADVISE_POSITION. We just kill the timer. If we
// get any WM_TIMER messages being fired late they will just be ignored. The
// timer is set with a period of 200 milliseconds and as mentioned before the
// ADVISE_POSITION is only suitable for deferred window update notifications

void COverlay::StopUpdateTimer()
{
    NOTE("Entering StopUpdateTimer");
    CAutoLock cVideoLock(this);
    HWND hwnd = m_pRenderer->m_VideoWindow.GetWindowHWND();
    EXECUTE_ASSERT(KillTimer(hwnd,INFINITE));
}


// Called when we get a WM_TIMER during an overlay transport connection. We
// look at the current destination rectangle and if it has changed then we
// update the source filter. The process of updating the source overlay also
// brings m_TargetRect upto date. We share a timer with our DirectDraw code
// but the two can never be used at the same time and so this should be safe

BOOL COverlay::OnUpdateTimer()
{
    NOTE("Entering OnUpdateTimer");
    CAutoLock cVideoLock(this);
    RECT SourceRect, TargetRect;

    // Is there a notification client

    if (m_pNotify == NULL) {
        NOTE("No client");
        return NOERROR;
    }

    // Do they want to know when the video rectangles change. These callbacks
    // do not occur in sync with the window moving like they do with the clip
    // changes, essentially we pass on information as we receive WM_MOVE etc
    // window messages. This is suitable for overlay cards that don't write
    // directly into the display and so don't mind being a little out of step

    if (m_dwInterests & ADVISE_POSITION) {

        HRESULT hr = GetVideoClipInfo(&SourceRect,&TargetRect,NULL);
        if (FAILED(hr)) {
            return FALSE;
        }

        // Only update when something changes unknown to us

        if (EqualRect(&m_TargetRect,&TargetRect) == TRUE) {
            NOTE("Rectangles match");
            return TRUE;
        }
        NotifyChange(ADVISE_POSITION);
    }
    return TRUE;
}


// When we have an ADVISE_CLIPPING advise link setup we cannot install hooks
// on that thread as it may go away later on and take the hook along with it
// Therefore we post a custom message (WM_HOOK and WM_UNHOOK) to our window
// which will then call us back here to do the real dirty work. We can't do
// a SendMessage as it would violate the lock hierachy for the overlay object

void COverlay::OnHookMessage(BOOL bHook)
{
    NOTE1("OnHookMessage called (%d)",bHook);
    if (m_pRenderer->m_VideoWindow.WindowExists()) {
        HWND hwnd = m_pRenderer->m_VideoWindow.GetWindowHWND();
        CAutoLock cVideoLock(this);

        if (bHook == TRUE) {
            NOTE("Installing global hook");
            m_hHook = InstallGlobalHook(hwnd);
            NOTE("Installed global hook");
            NotifyChange(ADVISE_ALL);
        } else {
            if (m_hHook) RemoveGlobalHook(hwnd,m_hHook);
            m_hHook = NULL;
            NOTE("Removed global hook");
        }
    }
}
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\multimedia\dshow\filters\image\video\hook.h ===
// Copyright (c) 1994 - 1998  Microsoft Corporation.  All Rights Reserved.
// Implements global message hooking, Anthony Phillips, April 1995

#define WM_FREEZE WM_USER           // Stop playing while clipping changes
#define WM_THAW (WM_USER + 1)       // Finished moving the window so restart
#define WM_HOOK (WM_USER + 2)       // Start global hooking of messages
#define WM_UNHOOK (WM_USER + 3)     // Likewise have any hook terminated
#define WM_ONPALETTE (WM_USER + 4)  // Post back WM_PALETTECHANGED messages
#define MAX_OVERLAYS 5              // No more than five overlays at once
#define OCR_ARROW_DEFAULT 100       // Default Windows OEM arrow cursor
#define DDGFS_FLIP_TIMEOUT 1        // Time we sleep for between flips
#define INVALID_COOKIE_VALUE -1     // Valid cookie values are between 0 and 
                                    // (MAX_OVERLAYS - 1).  For more information,
                                    // see the code for GetNextOverlayCookie() 
                                    // and GetColourFromCookie().
#define DEFAULT_COOKIE_VALUE 0      // This cookie value is used by the
                                    // Video Renderer if GetNextOverlayCookie() 
                                    // fails.
extern HINSTANCE g_hInst;           // Module instance handle for hooking

// Global memory block for interprocess communication

typedef struct {
    LONG OverlayCookieUsage[MAX_OVERLAYS];
    HWND VideoWindow[MAX_OVERLAYS];
    LONG WindowInUse[MAX_OVERLAYS];
} VIDEOMEMORY;

// Called at process attachment time

void OnProcessAttachment(BOOL bLoading,const CLSID *rclsid);
void OnProcessDetach();
void OnProcessAttach();

// These are called while we are hooking messages

void OnWindowPosChanging(CWPSTRUCT *pMessage);
void OnWindowCompletion(HWND hCurrent);
void OnWindowPosChanged(CWPSTRUCT *pMessage);
void OnExitSizeMove(CWPSTRUCT *pMessage);

LRESULT CALLBACK GlobalHookProc(INT nCode,WPARAM wParam,LPARAM lParam);
HHOOK InstallGlobalHook(HWND hwnd);
HRESULT RemoveGlobalHook(HWND hwnd,HHOOK hHook);
HRESULT GetNextOverlayCookie(LPSTR szDevice, LONG* plNextCookie);
void RemoveCurrentCookie(LONG lCurrentCookie);
COLORREF GetColourFromCookie(LPSTR szDevice, LONG lCookie);
DWORD GetPaletteIndex(COLORREF Colour);
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\multimedia\dshow\filters\image\video\dvideo.h ===
// Copyright (c) 1994 - 1999  Microsoft Corporation.  All Rights Reserved.
// Implements DirectDraw surface support, Anthony Phillips, August 1995

// This class implements IDirectDrawVideo as a control interface that allows
// an application to specify which types of DirectDraw surfaces we will
// use. It also allows the application to query the surface and provider's
// capabilities so that, for example, it can find out that the window needs
// to be aligned on a four byte boundary. The main filter exposes the control
// interface rather than it being obtained through one of the pin objects.
//
// This class supports a public interface that tries to abstract the details
// of using DirectDraw. The idea is that after connection the allocator
// will scan each of the media types the source supplies and see if any of
// them could be hardware accellerated. For each type it calls FindSurface
// with the format as input, if it succeeds then it has a surface created.
// To find out a type for this surface it calls GetSurfaceFormat, this will
// have the logical bitmap set in it and should be passed to the source to
// check it will accept this buffer type. If an error occurs at any time the
// allocator will call ReleaseSurfaces to clean up. If no surface is found
// the allocator may still open a primary surface using FindPrimarySurface.
//
// It will probably keep the primary surface around all the time as a source
// may be very temperamental as to what buffer type it'll accept. For example
// if the output size is stretched by one pixel the source may reject it but
// resizing the window back again may now make it acceptable. Therefore the
// allocator keeps a primary surface around and keeps asking the source if
// it will accept the buffer type whenever the surface status changes (which
// would be the case if the window was stretched or perhaps became clipped).
//
// The allocator can find out if the surface status has changed by calling
// UpdateDrawStatus, this returns FALSE if no change has happened since the
// last call. This provides a relatively fast way of seeing if anything has
// changed. The allocator may want to force the UpdateDrawStatus to return
// TRUE (eg after state changes) in which case it can call SetStatusChanged.
//
// The SyncOnFill returns TRUE if the current surface should not be handed
// out until the draw time arrives. If it returns FALSE then it should be
// returned from GetBuffer as soon as possible. In the later case the draw
// will typically happen later after the sample has been passed through the
// window object (just as if it was a DIBSECTION buffer). There is a hook
// in DRAW.CPP that detects whether the sample is a DirectDraw buffer and
// if so will call our DrawImage method with the sample to be rendered.
//
// Actual access to the surface is gained by calling LockSurface and should
// be unlocked by calling UnlockSurface. The display may be locked between
// lock and unlocks so calling ANY GDI/USER API may hang the system. The
// only easy way to debug problems is to log to a file and use that as a
// tracing mechansism, use the base class DbgLog logging facilities either
// sent to a file (may miss the last few lines) or set up a remote terminal
//
// Finally there are a number of notification functions that various parts
// of the video renderer call into this DirectDraw object for. These include
// setting the source and destination rectangle. We must also be told when
// we do not have the foreground palette as we must stop handing access to
// the primary surface (if we are on a palettised display device). When we
// are using overlay surfaces we need to know when the window position is
// changed so that we can reposition the overlay, we could do this each time
// an image arrives but that makes it look bad on low frame rate movies

#ifndef __DVIDEO__
#define __DVIDEO__

class CDirectDraw : public IDirectDrawVideo, public CUnknown, public CCritSec
{
    DDCAPS m_DirectCaps;                     // Actual hardware capabilities
    DDCAPS m_DirectSoftCaps;                 // Capabilities emulated for us
    LPDIRECTDRAW m_pDirectDraw;              // DirectDraw service provider
    LPDIRECTDRAW m_pOutsideDirectDraw;       // Provided by somebody else
    LPDIRECTDRAWSURFACE m_pDrawPrimary;      // DirectDraw primary surface
    LPDIRECTDRAWSURFACE m_pOverlaySurface;   // DirectDraw overlay surface
    LPDIRECTDRAWSURFACE m_pOffScreenSurface; // DirectDraw overlay surface
    LPDIRECTDRAWSURFACE m_pBackBuffer;       // Back buffer flipping surface
    LPDIRECTDRAWCLIPPER m_pDrawClipper;      // Used to handle the clipping
    LPDIRECTDRAWCLIPPER m_pOvlyClipper;      // Used to handle the clipping
    CLoadDirectDraw m_LoadDirectDraw;        // Handles loading DirectDraw

    BYTE *m_pDrawBuffer;                     // Real primary surface pointer
    CRenderer *m_pRenderer;                  // Owning renderer core object
    CCritSec *m_pInterfaceLock;              // Main renderer interface lock
    CMediaType m_SurfaceFormat;              // Holds current output format
    DWORD m_Switches;                        // Surface types enabled
    COLORREF m_BorderColour;                 // Current window border colour
    DWORD m_SurfaceType;                     // Holds the surface type in use
    COLORREF m_KeyColour;                    // Actual colour key colour
    LONG m_cbSurfaceSize;                    // Accurate size of our surface

    // Before our video allocator locks a DirectDraw surface it will call our
    // UpdateDrawStatus to check it is still available. That calls GetClipBox
    // to get the bounding video rectangle. If it is complex clipped and we
    // have no clipper nor colour key available then we have to switch back
    // to DIBs. In that situation m_bWindowLock is set to indicate not that
    // we are clipped but that the current clipping situation forced us out

    BOOL m_bIniEnabled;                      // Responds to WIN.INI setting
    BOOL m_bWindowLock;                      // Window environment lock out
    BOOL m_bOverlayVisible;                  // Have we shown the overlay
    BOOL m_bUsingColourKey;                  // Are we using a colour key
    BOOL m_bTimerStarted;                    // Do we have a refresh timer
    BOOL m_bColourKey;                       // Allocated a colour key
    BOOL m_bSurfacePending;                  // Try again when window changes
    BOOL m_bColourKeyPending;                // Set when we hit a key problem
    BOOL m_bCanUseScanLine;		     // Can we use the current line
    BOOL m_bCanUseOverlayStretch;	     // Same for overlay stretches
    BOOL m_bUseWhenFullScreen;		     // Use us when going fullscreen
    BOOL m_bOverlayStale;                    // Is the front buffer stale
    BOOL m_bTripleBuffered;                  // Do we have triple buffered

    // We adjust the source and destination rectangles so that they are
    // aligned according to the hardware restrictions. This allows us
    // to keep using DirectDraw rather than swapping back to software

    DWORD m_SourceLost;                      // Pixels to shift source left by
    DWORD m_TargetLost;                      // Likewise for the destination
    DWORD m_SourceWidthLost;                 // Chop pixels off the width
    DWORD m_TargetWidthLost;                 // And also for the destination
    BOOL m_DirectDrawVersion1;               // Is this DDraw ver. 1.0?
    RECT m_TargetRect;                       // Target destination rectangle
    RECT m_SourceRect;                       // Source image rectangle
    RECT m_TargetClipRect;                   // Target destination clipped
    RECT m_SourceClipRect;                   // Source rectangle clipped

    // Create and initialise a format for a DirectDraw surface

    BOOL InitOnScreenSurface(CMediaType *pmtIn);
    BOOL InitOffScreenSurface(CMediaType *pmtIn,BOOL bPageFlipped);
    BOOL InitDrawFormat(LPDIRECTDRAWSURFACE pSurface);
    BOOL CreateRGBOverlay(CMediaType *pmtIn);
    BOOL CreateRGBOffScreen(CMediaType *pmtIn);
    BOOL CreateYUVOverlay(CMediaType *pmtIn);
    BOOL CreateYUVOffScreen(CMediaType *pmtIn);
    BOOL CreateRGBFlipping(CMediaType *pmtIn);
    BOOL CreateYUVFlipping(CMediaType *pmtIn);
    DWORD GetMediaType(CMediaType *pmt);
    BYTE *LockDirectDrawPrimary();
    BYTE *LockPrimarySurface();
    BOOL ClipPrepare(LPDIRECTDRAWSURFACE pSurface);
    BOOL InitialiseColourKey(LPDIRECTDRAWSURFACE pSurface);
    BOOL InitialiseClipper(LPDIRECTDRAWSURFACE pSurface);
    void SetSurfaceSize(VIDEOINFO *pVideoInfo);
    LPDIRECTDRAWSURFACE GetDirectDrawSurface();
    BOOL LoadDirectDraw();

    // Used while processing samples

    BOOL DoFlipSurfaces(IMediaSample *pMediaSample);
    BOOL AlignRectangles(RECT *pSource,RECT *pTarget);
    BOOL CheckOffScreenStretch(RECT *pSource,RECT *pTarget);
    BOOL CheckStretch(RECT *pSource,RECT *pTarget);
    BOOL UpdateDisplayRectangles(RECT *pClipRect);
    BOOL UpdateRectangles(RECT *pSource,RECT *pTarget);
    void DrawColourKey(COLORREF WindowColour);
    void BlankDestination();
    BOOL FillBlankAreas();
    BYTE *LockSurface(DWORD dwFlags);
    BOOL UnlockSurface(BYTE *pSurface,BOOL bPreroll);
    BOOL CheckWindowLock();
    void ResetRectangles();

    // Helps with managing overlay and flipping surfaces

    BOOL ShowOverlaySurface();
    COLORREF GetRealKeyColour();
    BOOL ShowColourKeyOverlay();
    void OnColourKeyFailure();
    BOOL CheckCreateOverlay();

public:

    // Constructor and destructor

    CDirectDraw(CRenderer *pRenderer,  // Main video renderer
                CCritSec *pLock,       // Object to use for lock
                IUnknown *pUnk,        // Aggregating COM object
                HRESULT *phr);         // Constructor return code

    ~CDirectDraw();

    DECLARE_IUNKNOWN

    // Expose our IDirectDrawVideo interface
    STDMETHODIMP NonDelegatingQueryInterface(REFIID riid,VOID **ppv);

    // Called by the window control object

    BOOL OnPaint(IMediaSample *pMediaSample);
    BOOL OnTimer();
    BOOL OnUpdateTimer();
    void SetBorderColour(COLORREF Colour);
    void SetSourceRect(RECT *pSourceRect);
    void SetTargetRect(RECT *pTargetRect);

    // Setup and release DirectDraw

    BOOL FindSurface(CMediaType *pmtIn, BOOL fFindFlip);
    BOOL FindPrimarySurface(CMediaType *pmtIn);
    BOOL FindDirectDrawPrimary(CMediaType *pmtIn);
    void SetSurfacePending(BOOL bPending);
    BOOL IsSurfacePending();
    BOOL InitDirectDraw(BOOL fIOverlay = false);
    void ReleaseDirectDraw();
    void ReleaseSurfaces();

    // Used while actually processing samples

    BOOL InitVideoSample(IMediaSample *pMediaSample,DWORD dwFlags);
    BOOL ResetSample(IMediaSample *pMediaSample,BOOL bPreroll);
    CMediaType *UpdateSurface(BOOL &bFormatChanged);
    BOOL DrawImage(IMediaSample *pMediaSample);

    // DirectDraw status information

    BOOL CheckEmptyClip(BOOL bWindowLock);
    BOOL CheckComplexClip();
    BOOL SyncOnFill();
    void StartUpdateTimer();
    void StopUpdateTimer();
    BOOL AvailableWhenPaused();
    void WaitForFlipStatus();
    void WaitForScanLine();
    BOOL PrepareBackBuffer();

    // We need extra help for overlays

    BOOL HideOverlaySurface();
    BOOL IsOverlayEnabled();
    void OverlayIsStale();
    BOOL IsOverlayComplete();
    void StartRefreshTimer();
    void StopRefreshTimer();
    BOOL UpdateOverlaySurface();

    LPDIRECTDRAWCLIPPER GetOverlayClipper();

    // Can we use a software cursor over the window

    BOOL InSoftwareCursorMode() {
        CAutoLock cVideoLock(this);
        return !m_bOverlayVisible;
    }

    // Return the static format for the surface

    CMediaType *GetSurfaceFormat() {
        ASSERT(m_bIniEnabled == TRUE);
        return &m_SurfaceFormat;
    };

public:

    // Called indirectly by our IVideoWindow interface

    HRESULT GetMaxIdealImageSize(long *pWidth,long *pHeight);
    HRESULT GetMinIdealImageSize(long *pWidth,long *pHeight);

    // Implement the IDirectDrawVideo interface

    STDMETHODIMP GetSwitches(DWORD *pSwitches);
    STDMETHODIMP SetSwitches(DWORD Switches);
    STDMETHODIMP GetCaps(DDCAPS *pCaps);
    STDMETHODIMP GetEmulatedCaps(DDCAPS *pCaps);
    STDMETHODIMP GetSurfaceDesc(DDSURFACEDESC *pSurfaceDesc);
    STDMETHODIMP GetFourCCCodes(DWORD *pCount,DWORD *pCodes);
    STDMETHODIMP SetDirectDraw(LPDIRECTDRAW pDirectDraw);
    STDMETHODIMP GetDirectDraw(LPDIRECTDRAW *ppDirectDraw);
    STDMETHODIMP GetSurfaceType(DWORD *pSurfaceType);
    STDMETHODIMP SetDefault();
    STDMETHODIMP UseScanLine(long UseScanLine);
    STDMETHODIMP CanUseScanLine(long *UseScanLine);
    STDMETHODIMP UseOverlayStretch(long UseOverlayStretch);
    STDMETHODIMP CanUseOverlayStretch(long *UseOverlayStretch);
    STDMETHODIMP UseWhenFullScreen(long UseWhenFullScreen);
    STDMETHODIMP WillUseFullScreen(long *UseFullScreen);
};

#endif // __DVIDEO__
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\multimedia\dshow\filters\image\video\hook.cpp ===
// Copyright (c) 1994 - 1999  Microsoft Corporation.  All Rights Reserved.
// Implements global message hooking, Anthony Phillips, April 1995

#include <streams.h>
#include <windowsx.h>
#include <render.h>

// We keep in shared memory a list of overlay windows who want to be informed
// of events that effect their clipping rectangles. For each window handle we
// also keep a flag that says whether the position is in use or not, this is
// actually required to ensure multi processor safe exclusion to any given
// array position. The array is opened and initialised if need be in shared
// memory when the DLL gets attached to each process (ie DllMain gets called
// with a DLL_PROCESS_ATTACH and likewise with a DLL_PROCESS_DETACH message)

HANDLE g_hVideoMemory = NULL;
VIDEOMEMORY *g_pVideoMemory = NULL;

// This is called when we see WM_WINDOWPOSCHANGING messages for any window in
// the system. We use these as a way of detecting clip changes and freeze all
// video renderers until we subsequently receive a WM_EXITSIZEMOVE or one of
// the WM_WINDOWPOSCHANGED messages. We cannot be more selective about which
// windows are to be frozen as the rectangles sent to us are often confusing

void OnWindowPosChanging(CWPSTRUCT *pMessage)
{
    WINDOWPOS *pwp = (WINDOWPOS *) pMessage->lParam;

    // This combination gets sent during window creation
    if (pwp->flags == (SWP_NOACTIVATE | SWP_NOREDRAW | SWP_NOZORDER)) {
        OnWindowCompletion(pMessage->hwnd); return;
    }

    NOTE1("Hooked WM_WINDOWPOSCHANGING Flags %d",pwp->flags);

    // Cycle through the windows affected by our change

    for (LONG Pos = 0;Pos < MAX_OVERLAYS;Pos++) {

        HWND hwnd = g_pVideoMemory->VideoWindow[Pos];
        if (hwnd == NULL) {
            continue;
        }

        SendMessage(hwnd,WM_FREEZE,0,0);

        // Handle atomic Z order changes in Windows
        if (pwp->flags == (SWP_NOSIZE | SWP_NOMOVE)) {
            InvalidateRect(hwnd,NULL,TRUE);
        }
    }
}


// This is called when either we receive a WM_WINDOWPOSCHANGED message or a
// WM_EXITSIZEMOVE both of which cause us to scan the list of overlay windows
// and thaw out all windows immediately. We would like to be more selective
// but the parameters to WM_WINDOWPOSCHANGING are not exact enough to be able
// to do this. So we freeze at the start and thaw at the end of each change

void OnWindowCompletion(HWND hCurrent)
{
    for (LONG Pos = 0;Pos < MAX_OVERLAYS;Pos++) {

        // Read the next window handle from the shared array

        HWND hwnd = g_pVideoMemory->VideoWindow[Pos];
        if (hwnd == NULL) {
            continue;
        }
        SendMessage(hwnd,WM_THAW,0,0);
    }
}


// Handles the WM_WINDOWPOSCHANGED message

void OnWindowPosChanged(CWPSTRUCT *pMessage)
{
    OnWindowCompletion(pMessage->hwnd);
}


// Handles the WM_EXITSIZEMOVE message

void OnExitSizeMove(CWPSTRUCT *pMessage)
{
    OnWindowCompletion(pMessage->hwnd);
}


// When we install a system wide hook procedure this DLL will be mapped into
// EVERY process space in the system that has one or more window threads, we
// will be called when any of those threads retrieves a message from the
// queues. What we do is filter out those messages that effect the clipping
// information of the overlay windows and send them messages to freeze (and
// thaw as is appropriate) their video while windows are changing position

LRESULT CALLBACK GlobalHookProc(INT nCode,
                                WPARAM wParam,
                                LPARAM lParam)
{
    CWPSTRUCT *pMessage = (CWPSTRUCT *) lParam;
    if (g_pVideoMemory == NULL) {
        return FALSE;
    }

    switch (pMessage->message) {

        case WM_EXITSIZEMOVE:
            OnExitSizeMove(pMessage);
            break;

        case WM_WINDOWPOSCHANGED:
            OnWindowPosChanged(pMessage);
            break;

        case WM_WINDOWPOSCHANGING:
            OnWindowPosChanging(pMessage);
            break;
    }
    return FALSE;
}


// When we start an overlay session we must add our window handle to the list
// held in global memory so that we receive and updates that might effect our
// clipping list. To do this we scan through the list looking for a position
// that is not currently used, this can be done in a multi processor safe way
// without using a global critical section by calling InterlockedExchange

HHOOK InstallGlobalHook(HWND hwnd)
{
    ASSERT(hwnd);

    // Before hooking add our window to the global array

    for (LONG Pos = 0;Pos < MAX_OVERLAYS;Pos++) {

        LONG Usage = InterlockedExchange(&g_pVideoMemory->WindowInUse[Pos],TRUE);

        if (Usage == FALSE) {
            ASSERT(g_pVideoMemory->VideoWindow[Pos] == NULL);
            g_pVideoMemory->VideoWindow[Pos] = hwnd;
            break;
        }
    }

    // Did we find a space in the array

    if (Pos == MAX_OVERLAYS) {
        return NULL;
    }

    // Start hooking messages for the entire system, this causes the renderer
    // DLL to be mapped into every process that has one or more windows and
    // will be called whenever a window thread tries to retrieve a message

    return SetWindowsHookEx(WH_CALLWNDPROC,   // Type of message hook
                            GlobalHookProc,   // Global hook procedure
                            g_hInst,          // Module instance handle
                            (DWORD) 0);       // Global message hook
}


// When we want to remove our window from the hooking process we must scan the
// list for our handle. It is possible that someone else on a different thread
// or more likely a different processor can change the window handle while we
// are inspecting it. This isn't critical as none of the values we will ever
// actually see will match the system wide unique window handle we maintain

HRESULT RemoveGlobalHook(HWND hwnd,HHOOK hHook)
{
    // Is this a real window hook

    if (hHook == NULL) {
        return NOERROR;
    }

    // Before unhooking remove our window from the global array

    for (LONG Pos = 0;Pos < MAX_OVERLAYS;Pos++) {
        if (g_pVideoMemory->VideoWindow[Pos] == hwnd) {
            g_pVideoMemory->VideoWindow[Pos] = NULL;
            InterlockedExchange(&g_pVideoMemory->WindowInUse[Pos],FALSE);
            break;
        }
    }

    UnhookWindowsHookEx(hHook);
    return NOERROR;
}


// Called when the DLL that we're built in (either IMAGE.DLL or the overall
// QUARTZ.DLL for the main SDK runtimes) gets loaded into a process. We take
// this opportunity to create or delete the shared memory block that we use
// for interprocess communication. The block of memory is used in two ways,
// firstly to hold a list of video windows that want to be informed of clip
// changes in the system. Secondly it is used so that DirectDraw overlays
// can each allocate and use different colour keys to maintain Z ordering

void OnProcessAttachment(BOOL bLoading,const CLSID *rclsid)
{
    // Create/open the video mutex object

    HANDLE VideoMutex = CreateMutex(NULL,FALSE,WindowClassName);
    if (VideoMutex == NULL) {
        return;
    }

    WaitForSingleObject(VideoMutex,INFINITE);

    if (bLoading == TRUE) {
        OnProcessAttach();
    } else {
        OnProcessDetach();
    }

    EXECUTE_ASSERT(ReleaseMutex(VideoMutex));
    EXECUTE_ASSERT(CloseHandle(VideoMutex));
}


// Called when the DLL is detached from a process. We can't be sure that the
// process completed the attach so the state variables may or may not be set
// correctly. Furthermore just to be on the safe side we grab ownership of
// the video mutex so that we can ensure serialisation of the attachments

void OnProcessDetach()
{
    // Release the shared memory resources

    if (g_pVideoMemory) {
        UnmapViewOfFile((PVOID)g_pVideoMemory);
        g_pVideoMemory = NULL;
    }
    if (g_hVideoMemory) {
        CloseHandle(g_hVideoMemory);
        g_hVideoMemory = NULL;
    }
}


// Called when this DLL is attached to another process. We open a mutex so we
// can synchronise with other processes asking for immediate ownership of it.
// We can then map the shared memory block into our process and if we created
// the block (ie the first people in) then we also initialise it with zeroes.
// All that's then left to do is release and close the video mutex handle

void OnProcessAttach()
{
    // Create a named shared memory block

    /// !!! fails if a service is using quartz. might have been useful
    g_hVideoMemory = CreateFileMapping(hMEMORY,              // Memory block
                                       NULL,                 // Security flags
                                       PAGE_READWRITE,       // Page protection
                                       (DWORD) 0,            // High size
                                       sizeof(VIDEOMEMORY),  // Low order size
                                       TEXT("VIDEOMEMORY")); // Mapping name

    // We must now map the shared memory block into this process address space
    // The CreateFileMapping call sets the last thread error code to zero if
    // we actually created the memory block, if someone else got in first and
    // created it GetLastError returns ERROR_ALREADY_EXISTS. We are ensured
    // that nobody can get to the uninitialised memory block because we use
    // a cross process mutex critical section. The mutex is also used by the
    // window object (we use the same name) to synchronise window creation

    DWORD Status = GetLastError();

    if (g_hVideoMemory) {

        g_pVideoMemory = (VIDEOMEMORY *) MapViewOfFile(g_hVideoMemory,
                                                       FILE_MAP_ALL_ACCESS,
                                                       (DWORD) 0,
                                                       (DWORD) 0,
                                                       (DWORD) 0);
        if (g_pVideoMemory) {
            if (Status == ERROR_SUCCESS) {
                ZeroMemory((PVOID)g_pVideoMemory,sizeof(VIDEOMEMORY));
            }
        }
    }
}


// As described earlier the video renderer opens a shared memory block for a
// global hook procedure code to use. And since the hook is the main user of
// the memory block it is created and destroyed in this module. The block is
// however useful for other interprocess communication. In particular when we
// are using overlays in different processes we really want them to allocate
// different colour keys to maintain Z ordering when they overlay. For this
// reason we have a function that gets the next colour from the memory. The
// colour is one of either magenta (the default), green, red, cyan or yellow
// if we are on a palettised display or a shade of black if on a true colour

COLORREF KeyColours[] = {
    RGB(255,0,255),  RGB(16,0,16),      // Magenta
    RGB(0,255,0),    RGB(0,16,0),       // Green
    RGB(255,0,0),    RGB(16,0,0),       // Red
    RGB(0,255,255),  RGB(0,16,16),      // Cyan
    RGB(255,255,0),  RGB(16,16,0)       // Yellow
};

// use the monitor/device given
HRESULT GetNextOverlayCookie(LPSTR szDevice, LONG* plNextCookie)
{
    // The caller should pass in a valid pointer.
    ASSERT(NULL != plNextCookie);
    ValidateReadWritePtr(plNextCookie, sizeof(LONG));

    // Make sure the caller does not use a random value.
    *plNextCookie = INVALID_COOKIE_VALUE;

    LONG lMinUsedCookie = 0, lMinUsage = 1000;

    NOTE("Returning next available key colour");

    // Create/open the video mutex object

    if(g_pVideoMemory == 0) {
        NOTE("No shared memory");
        return E_FAIL;
    }

    HANDLE VideoMutex = CreateMutex(NULL,FALSE,WindowClassName);
    if (VideoMutex == NULL) {
        NOTE("No video mutex");
        return E_FAIL;
    }

    WaitForSingleObject(VideoMutex,INFINITE);

    // Now we have an exclusive lock allocate the next cookie
    for (LONG Pos = 0;Pos < MAX_OVERLAYS;Pos++)
    {
        if (g_pVideoMemory->OverlayCookieUsage[Pos] < lMinUsage)
        {
            lMinUsage = g_pVideoMemory->OverlayCookieUsage[Pos];
            lMinUsedCookie = Pos;
        }
    }
    g_pVideoMemory->OverlayCookieUsage[lMinUsedCookie]++;

    // Store our cookie value before unlocking

    EXECUTE_ASSERT(ReleaseMutex(VideoMutex));
    EXECUTE_ASSERT(CloseHandle(VideoMutex));

    // Valid cookie values are between 0 and (MAX_OVERLAYS - 1).
    ASSERT((0 <= lMinUsedCookie) && (lMinUsedCookie < MAX_OVERLAYS));

    *plNextCookie = lMinUsedCookie;

    return S_OK;
}

void RemoveCurrentCookie(LONG lCurrentCookie)
{
    // Valid cookie values are between 0 and (MAX_OVERLAYS - 1).
    ASSERT(lCurrentCookie >= 0 && lCurrentCookie < MAX_OVERLAYS);

    if (NULL != g_pVideoMemory) {
        ASSERT(g_pVideoMemory->OverlayCookieUsage[lCurrentCookie] > 0);
        InterlockedDecrement(&g_pVideoMemory->OverlayCookieUsage[lCurrentCookie]);
    }
}

COLORREF GetColourFromCookie(LPSTR szDevice, LONG lCookie)
{
    // Valid cookie values are between 0 and (MAX_OVERLAYS - 1).
    ASSERT((0 <= lCookie) && (lCookie < MAX_OVERLAYS));

    // get a DC for the monitor we care about
    DbgLog((LOG_TRACE,3,TEXT("Overlay CKey getting DC for device %s"), szDevice));
    HDC hdcScreen;
    if (szDevice == NULL || lstrcmpiA(szDevice, "DISPLAY") == 0)
        hdcScreen = CreateDCA("DISPLAY", NULL, NULL, NULL);
    else
        hdcScreen = CreateDCA(NULL, szDevice, NULL, NULL);
    if ( ! hdcScreen )
        return 0;

    // Are we in a palettised display device mode?
    INT Type = GetDeviceCaps(hdcScreen,RASTERCAPS);
    Type = (Type & RC_PALETTE ? 0 : 1);
    DeleteDC(hdcScreen);

    DWORD KeyColoursIndex = (lCookie << 1) + Type;

    // Make sure the index is valid.
    ASSERT(KeyColoursIndex < NUMELMS(KeyColours));

    return KeyColours[KeyColoursIndex];
}

// The overlay transport also uses the shared memory segment to allocate its
// colour keys. However when it is running on a palettised display it needs
// the actual palette index for any given RGB colour it is allocated. So it
// calls this method with a previously allocated colour to get an index. The
// entries in the index must equate with the entries in the RGB colour table

DWORD KeyIndex[] = { 253, 250, 249, 254, 251 };

DWORD GetPaletteIndex(COLORREF Colour)
{
    NOTE("Searching for palette index");
    for (int Count = 0;Count < MAX_OVERLAYS;Count++) {
        if (KeyColours[Count << 1] == Colour) {
            NOTE1("Index %d",Count);
            return KeyIndex[Count];
        }
    }
    return 0;
}
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\multimedia\dshow\filters\image\video\dvideo.cpp ===
// Copyright (c) 1994 - 1999  Microsoft Corporation.  All Rights Reserved.
// Implements DirectDraw surface support, Anthony Phillips, August 1995

#include <streams.h>
#include <windowsx.h>
#include <render.h>

// This class abstracts all the DCI and DirectDraw surface implementation. We
// present an interface to the allocator so that it can supply us with media
// types and ask if we can accellerate them. Typically it will connect to a
// source filter and then enumerate the available types again and see if one
// is available that offers hardware assisted drawing (primary surface access
// also falls into this category). Once we've worked out we can do something
// we supply the caller with a type that describes the surface, they use this
// to call QueryAccept on the source pin to check they can switch types. The
// assumption is that since they already connected with some type that should
// the surface become unavailable at some later stage we can swap back again.
//
// Primary surfaces are dealt with slightly differently as a fall back option
// This is because the format changes so dynamically (for example the window
// being moved) that the allocator cannot really get a format when it starts
// running and QueryAccept on the source. What it does do is if it cannot get
// a relatively static surface type then it creates a primary surface with us
// This it keeps around all the time and each time the format changes it asks
// the source if it will now accept it. The assumption being that the other
// surface types like overlays do not really change much during streaming.
//
// We keep four rectangles internally as member variables. We have a source
// and destination rectangle (in window coordinates) provided by the window
// object. We also keep a real source and destination rectangle for the video
// position on the actual display (calling our UpdateSurface updates these)
// These display rectangles are used to position the overlay and also update
// the output format that represents the primary surface when using them.
//
// Both Win95 and Windows NT have DCI support so we statically link to that
// library, however it is unclear if the DirectDraw will always be available
// so we dynamically link there. Once we have loaded the DirectDraw library
// we keep a module reference count open on it until we are later decommited.
//
// We offer a Lock and an Unlock method to get access to the actual buffer we
// provide, the allocator will normally call UpdateSurface to check we can
// still offer the buffer and indeed whether the source will accept it. There
// is a small window between calling UpdateSurface and actually locking it
// when the window state could change but it should be a fairly small chance
//
// If we get back a DDERR_SURFACELOST return code we treat it like any other
// hard error from DirectDraw - we do not call restore on the surface since
// it can cause the surface stride to change which is too difficult to handle
// For the most part that error is returned when the display mode is changed
// in which case we'll handle the WM_DISPLAYCHANGE message by having our pin
// reconnected which in turn has the DirectDraw surfaces allocated from fresh

static const TCHAR SWITCHES[] = TEXT("AMovieDraw");
static const TCHAR SCANLINE[] = TEXT("ScanLine");
static const TCHAR STRETCH[] = TEXT("Stretch");
static const TCHAR FULLSCREEN[] = TEXT("FullScreen");

#define ASSERT_FLIP_COMPLETE(hr) ASSERT(hr != DDERR_WASSTILLDRAWING)

// Constructor

CDirectDraw::CDirectDraw(CRenderer *pRenderer,  // Main video renderer
                         CCritSec *pLock,       // Object to use for lock
                         IUnknown *pUnk,        // Aggregating COM object
                         HRESULT *phr) :        // Constructor return code

    CUnknown(NAME("DirectDraw object"),pUnk),

    m_pInterfaceLock(pLock),            // Main interface critical section
    m_pRenderer(pRenderer),             // Pointer to the video renderer
    m_pOutsideDirectDraw(NULL),         // Externally provided DirectDraw
    m_pDirectDraw(NULL),                // IDirectDraw interface we're using
    m_pOverlaySurface(NULL),            // Visible overlay surface interface
    m_pOffScreenSurface(NULL),          // Offscreen plain interface pointer
    m_pBackBuffer(NULL),                // Backbuffer for flipping surfaces
    m_pDrawBuffer(NULL),                // Pointer to actual locked buffer
    m_pDrawPrimary(NULL),               // Interface to DirectDraw primary
    m_bIniEnabled(TRUE),                // Can we use DCI/DirectDraw flag
    m_bWindowLock(TRUE),                // Are we locked out from the window
    m_bSurfacePending(FALSE),           // Waiting for a window change flag
    m_bColourKeyPending(FALSE),         // Likewise before using colour keys
    m_Switches(AMDDS_ALL),              // Which surfaces can we allocate
    m_SourceLost(0),                    // Pixels lost on left source edge
    m_TargetLost(0),                    // Likewise pixels lost on target
    m_SourceWidthLost(0),               // Pixels lost from width of source
    m_TargetWidthLost(0),               // And same but for the destination
    m_pDrawClipper(NULL),               // IClipper interface for DirectDraw
    m_pOvlyClipper(NULL),               // Clipper used for IOverlay connections
    m_bOverlayVisible(FALSE),           // Is the overlay currently visible
    m_bTimerStarted(FALSE),             // Have we started an overlay timer
    m_SurfaceType(AMDDS_NONE),          // Bit setting for current surface
    m_bColourKey(FALSE),                // Can we use a colour if necessary
    m_KeyColour(VIDEO_COLOUR),          // Which COLORREF to use for the key
    m_bUsingColourKey(FALSE),           // Are we actually using a colour key
    m_cbSurfaceSize(0),                 // Size of surface in use in bytes
    m_bCanUseScanLine(TRUE),            // Can we use the current scan line
    m_bUseWhenFullScreen(FALSE),        // Always use us when fullscreen
    m_bOverlayStale(FALSE),             // Is the front overlay out of date
    m_bCanUseOverlayStretch(TRUE),      // Likewise for overlay stretching
    m_bTripleBuffered(FALSE),           // Have we triple buffered overlays
    m_DirectDrawVersion1(FALSE)         // Are we running DDraw ver 1.0?
{
    ASSERT(m_pRenderer);
    ASSERT(m_pInterfaceLock);
    ASSERT(phr);
    ASSERT(pUnk);

    ResetRectangles();

    // If DVA = 0 in WIN.INI, don't use DCI/DirectDraw surface access as PSS
    // tells people to use this if they have video problems so don't change
    // On NT the value is in the REGISTRY rather than a old type INI file in
    //
    //  HKEY_CURRENT_USER\SOFTWARE\Microsoft\Multimedia\Drawdib
    //      REG_DWORD dva 1      DCI/DirectDraw enabled
    //      REG_DWORD dva 0      DCI/DirectDraw disabled
    //
    // This value can also be set through the Video For Windows configuration
    // dialog (control panel, drivers, or via media player on an open file)
    // For the time being we default to having DCI/DirectAccess turned ON

    if (GetProfileInt(TEXT("DrawDib"),TEXT("dva"),TRUE) == FALSE) {
        m_bIniEnabled = FALSE;
    }

    // Load any saved DirectDraw switches

    DWORD Default = AMDDS_ALL;
    m_Switches = GetProfileInt(TEXT("DrawDib"),SWITCHES,Default);
    m_bCanUseScanLine = GetProfileInt(TEXT("DrawDib"),SCANLINE,TRUE);
    m_bCanUseOverlayStretch = GetProfileInt(TEXT("DrawDib"),STRETCH,TRUE);
    m_bUseWhenFullScreen = GetProfileInt(TEXT("DrawDib"),FULLSCREEN,FALSE);

    // Allocate and zero fill the output format

    m_SurfaceFormat.AllocFormatBuffer(sizeof(VIDEOINFO));
    VIDEOINFO *pVideoInfo = (VIDEOINFO *) m_SurfaceFormat.Format();
    if (pVideoInfo) {
        ZeroMemory((PVOID)pVideoInfo,sizeof(VIDEOINFO));
    } else {
        *phr = E_OUTOFMEMORY;
    }
}


// Destructor

CDirectDraw::~CDirectDraw()
{
    ASSERT(m_bTimerStarted == FALSE);
    ASSERT(m_pOverlaySurface == NULL);
    ASSERT(m_pOffScreenSurface == NULL);

    // Release any outside DirectDraw interface

    if (m_pOutsideDirectDraw) {
        m_pOutsideDirectDraw->Release();
        m_pOutsideDirectDraw = NULL;
    }

    // Clean up but should already be done

    StopRefreshTimer();
    ReleaseSurfaces();
    ReleaseDirectDraw();
}


// Overriden to say what interfaces we support

STDMETHODIMP CDirectDraw::NonDelegatingQueryInterface(REFIID riid,VOID **ppv)
{
    NOTE("Entering NonDelegatingQueryInterface");

    // We return IDirectDrawVideo and delegate everything else

    if (riid == IID_IDirectDrawVideo) {
        return GetInterface((IDirectDrawVideo *)this,ppv);
    }
    return CUnknown::NonDelegatingQueryInterface(riid,ppv);
}


// When we are asked to create a surface for a given media type we need to
// know whether it is RGB/YUV or possibly neither. This helper method will
// return the AMDDS_YUV bits set if it's YUV, likewise AMDDS_RGB if it is
// an RGB format or AMDDS_NONE if we detected neither. The RGB/YUV type of
// the image is decided on the biCompression field in the BITMAPINFOHEADER

DWORD CDirectDraw::GetMediaType(CMediaType *pmt)
{
    VIDEOINFO *pVideoInfo = (VIDEOINFO *) pmt->Format();
    BITMAPINFOHEADER *pHeader = HEADER(pVideoInfo);
    DWORD MediaType = AMDDS_YUV | AMDDS_RGB;
    NOTE("Entering GetMediaType");

    // We only recognise the GDI defined RGB formats

    if (pHeader->biCompression > BI_BITFIELDS) {
        NOTE("Not a RGB format");
        MediaType &= ~AMDDS_RGB;
    } else {
        NOTE("Not a YUV format");
        MediaType &= ~AMDDS_YUV;
    }

    // If we are on a true colour device we allow connection to palettised
    // formats since the display card can almost always handle these well
    // If this has happened then we can't write into an offscreen surface
    // This means that on a true colour device we wouldn't show a surface
    // that required a palette as switching video formats is too difficult

    if (m_pRenderer->m_Display.GetDisplayDepth() > pHeader->biBitCount) {
        NOTE("Bit depth mismatch");
        MediaType &= ~AMDDS_RGB;
    }

    // Check the compression type and GUID match

    FOURCCMap FourCCMap(pmt->Subtype());
    if (pHeader->biCompression != FourCCMap.GetFOURCC()) {
        NOTE("Subtypes don't match");
        MediaType &= ~AMDDS_YUV;
    }
    return MediaType;
}


// Check we can use direct frame buffer access, we are provided a media type
// that represents the input format and we should try and find a surface to
// accellerate the rendering of it using DCI/DirectDraw. The format that we
// return representing the surface is relatively static so the allocator will
// normally query this with the source filter so if it will accept it. We do
// not return primary surfaces (use FindPrimarySurface instead) through this
// as the type is so dynamic it is better done while we're actually running

// We much prefer flipping overlay surfaces to other types (no tearing, lower
// CPU usage) so we look separately for flipping surfaces and others using
// the fFindFlip flag

BOOL CDirectDraw::FindSurface(CMediaType *pmtIn, BOOL fFindFlip)
{
    NOTE("Entering FindSurface");
    CAutoLock cVideoLock(this);
    DWORD MediaType = GetMediaType(pmtIn);

    // Has someone stolen our surface

    if (m_pDrawPrimary) {
        if (m_pDrawPrimary->IsLost() != DD_OK) {
            NOTE("Lost primary");
            ReleaseDirectDraw();
            InitDirectDraw();
        }
    }

    // Is DCI/DirectDraw enabled

    if (m_bIniEnabled == FALSE || m_pDirectDraw == NULL) {
        NOTE("No DirectDraw available");
        return FALSE;
    }

    // Are there YUV flipping surfaces available

    if (fFindFlip && (m_Switches & AMDDS_YUVFLP)) {
        if (MediaType & AMDDS_YUVFLP) {
            if (CreateYUVFlipping(pmtIn) == TRUE) {
                m_SurfaceType = AMDDS_YUVFLP;
                NOTE("Found AMDDS_YUVFLP surface");
                return TRUE;
            }
        }
    }

    // Is there a non RGB overlay surface available

    if (!fFindFlip && (m_Switches & AMDDS_YUVOVR)) {
        if (MediaType & AMDDS_YUVOVR) {
            if (CreateYUVOverlay(pmtIn) == TRUE) {
                m_SurfaceType = AMDDS_YUVOVR;
                NOTE("Found AMDDS_YUVOVR surface");
                return TRUE;
            }
        }
    }

    // Are there RGB flipping surfaces available

    if (fFindFlip && (m_Switches & AMDDS_RGBFLP)) {
        if (MediaType & AMDDS_RGBFLP) {
            if (CreateRGBFlipping(pmtIn) == TRUE) {
                m_SurfaceType = AMDDS_RGBFLP;
                NOTE("Found AMDDS_RGBFLP surface");
                return TRUE;
            }
        }
    }

    // Is there an RGB overlay surface available

    if (!fFindFlip && (m_Switches & AMDDS_RGBOVR)) {
        if (MediaType & AMDDS_RGBOVR) {
            if (CreateRGBOverlay(pmtIn) == TRUE) {
                m_SurfaceType = AMDDS_RGBOVR;
                NOTE("Found AMDDS_RGBOVR surface");
                return TRUE;
            }
        }
    }

    // Is there a non RGB offscreen surface available

    if (!fFindFlip && (m_Switches & AMDDS_YUVOFF)) {
        if (MediaType & AMDDS_YUVOFF) {
            if (CreateYUVOffScreen(pmtIn) == TRUE) {
                m_SurfaceType = AMDDS_YUVOFF;
                NOTE("Found AMDDS_YUVOFF surface");
                return TRUE;
            }
        }
    }

    // Create an offscreen RGB drawing surface

    if (!fFindFlip && (m_Switches & AMDDS_RGBOFF)) {
        if (MediaType & AMDDS_RGBOFF) {
            if (CreateRGBOffScreen(pmtIn) == TRUE) {
                m_SurfaceType = AMDDS_RGBOFF;
                NOTE("Found AMDDS_RGBOFF surface");
                return TRUE;
            }
        }
    }
    return FALSE;
}


// This is called when the allocator wants to fall back on using the primary
// surface (probably because nothing better is available). If we can open a
// primary surface either through DCI or DirectDraw we return TRUE otherwise
// we return FALSE. We also create a format that represents the screen but
// it's of little use to query with the source until the window is shown

BOOL CDirectDraw::FindPrimarySurface(CMediaType *pmtIn)
{
    NOTE("Entering FindPrimarySurface");
    ASSERT(m_pOverlaySurface == NULL);
    ASSERT(m_pOffScreenSurface == NULL);
    ASSERT(m_pBackBuffer == NULL);

    const VIDEOINFO *pInput = (VIDEOINFO *) pmtIn->Format();

    // Don't use primary surfaces for low frame rate
    if (pInput->AvgTimePerFrame > (UNITS / 2)) {
        return FALSE;
    }


    CAutoLock cVideoLock(this);

    // Is DCI/DirectDraw enabled

    if (m_bIniEnabled == FALSE) {
        NOTE("INI disabled");
        return FALSE;
    }

    // If we are on a true colour device we allow connection to palettised
    // formats since the display card can almost always handle these well
    // If this has happened then we can't write onto the primary surface
    // This is very quick so it is best done before the following checking

    if (m_pRenderer->m_Display.GetDisplayDepth() != pInput->bmiHeader.biBitCount) {
        NOTE("Bit depth mismatch");
        return FALSE;
    }

    // We have an input media type that we would like to have put directly on
    // the DCI/DirectDraw primary surface. This means the pixel formats must
    // match exactly. The easiest way to do this is to call our check type as
    // that ensures the bit masks match on true colour displays for example

    HRESULT hr = m_pRenderer->m_Display.CheckMediaType(pmtIn);
    if (FAILED(hr)) {
        NOTE("CheckMediaType failed");
        return FALSE;
    }

    // Try first for a DirectDraw primary

    if (FindDirectDrawPrimary(pmtIn) == TRUE) {
        m_SurfaceType = AMDDS_PS;
        NOTE("AMDDS_PS surface");
        return TRUE;
    }

    return FALSE;
}


// This initialises a DirectDraw primary surface. We do not allow access to
// the primary surface if it is bank switched because out MPEG and AVI video
// decoders are block based and therefore touch multiple scan lines at once
// We must also look after re-initialising DirectDraw if we have had a game
// running in which case it will have stolen our surfaces in exclusive mode

BOOL CDirectDraw::FindDirectDrawPrimary(CMediaType *pmtIn)
{
    // Has someone stolen our surface

    // !!! I don't know why, but for some reason the current bit depth may
    // not match the primary bit depth anymore, so we need a new primary
    // or we'll blow up, but the surface isn't lost!

    if (m_pDrawPrimary) {
    	if (m_pDrawPrimary->IsLost() != DD_OK ||
			HEADER(m_SurfaceFormat.Format())->biBitCount !=
			HEADER(pmtIn->Format())->biBitCount) {
        	NOTE("Primary lost");
        	ReleaseDirectDraw();
        	InitDirectDraw();
        }
    }

    // Have we loaded DirectDraw successfully

    if (m_pDrawPrimary == NULL) {
        NOTE("No DirectDraw primary");
        return FALSE;
    }

    // Check we are not bank switched

    if (m_DirectCaps.dwCaps & DDCAPS_BANKSWITCHED) {
        NOTE("Primary surface is bank switched");
        return FALSE;
    }

    // Prepare an output format for the surface

    if (m_Switches & AMDDS_PS) {
        if (InitDrawFormat(m_pDrawPrimary) == TRUE) {
            NOTE("Primary available");
            return InitOnScreenSurface(pmtIn);
        }
    }
    return FALSE;
}


// Resets the source and destination rectangles

void CDirectDraw::ResetRectangles()
{
    NOTE("Reset display rectangles");
    SetRectEmpty(&m_TargetRect);
    SetRectEmpty(&m_SourceRect);
    SetRectEmpty(&m_TargetClipRect);
    SetRectEmpty(&m_SourceClipRect);
}


// If we are using the primary surface (either DCI or DirectDraw) and we are
// on a palettised device then we must make sure we have a one to one mapping
// for the source filter's palette colours. If not then we switch into using
// DIBs and leave GDI to map from our logical palette and the display device
// We have to do this for every frame because we canot guarantee seeing the
// palette change messages, if for example, we have been made a child window
// We return TRUE if we have got a palette lock otherwise we'll return FALSE

BOOL CDirectDraw::CheckWindowLock()
{
    VIDEOINFO *pVideoInfo = (VIDEOINFO *) m_SurfaceFormat.Format();
    BITMAPINFOHEADER *pHeader = HEADER(pVideoInfo);
    NOTE("Entering CheckWindowLock");

    // Check we are using a palettised surface

    if (PALETTISED(pVideoInfo) == FALSE) {
        NOTE("No lock to check");
        return FALSE;
    }

    // It could be an eight bit YUV format

    if (pHeader->biCompression) {
        NOTE("Not BI_RGB type");
        return FALSE;
    }

    ASSERT(pHeader->biClrUsed > 0);
    ASSERT(pHeader->biClrUsed <= 256);
    ASSERT(pHeader->biBitCount == 8);
    ASSERT(pHeader->biCompression == 0);

    // Compare as many colours as they have requested

    PALETTEENTRY apeSystem[256];
    WORD SystemColours,Entries = (WORD) pHeader->biClrUsed;
    WORD ColourBytes = Entries * sizeof(PALETTEENTRY);
    RGBQUAD *pVideo = pVideoInfo->bmiColors;

    // Check the number of logical palette entries

    // Get a DC on the right monitor - it's ugly, but this is the way you have
    // to do it
    HDC hdcScreen;
    if (m_pRenderer->m_achMonitor == NULL ||
		lstrcmpiA(m_pRenderer->m_achMonitor, "DISPLAY") == 0)
        hdcScreen = CreateDCA("DISPLAY", NULL, NULL, NULL);
    else
        hdcScreen = CreateDCA(NULL, m_pRenderer->m_achMonitor, NULL, NULL);
    if ( ! hdcScreen )
        return FALSE;
    GetSystemPaletteEntries(hdcScreen,0,Entries,&apeSystem[0]);
    SystemColours = (WORD)GetDeviceCaps(hdcScreen,SIZEPALETTE);
    DeleteDC(hdcScreen);

    // We can't use more colours than the device has available

    if (Entries > SystemColours) {
        NOTE("Too many colours");
        return TRUE;
    }

    // Check each RGBQUAD against the system palette entry

    for (WORD Count = 0;Count < Entries;Count++) {
        if (apeSystem[Count].peRed != pVideo[Count].rgbRed ||
                apeSystem[Count].peGreen != pVideo[Count].rgbGreen ||
                    apeSystem[Count].peBlue != pVideo[Count].rgbBlue) {
                        return TRUE;
        }
    }
    return FALSE;
}


// If the screen is locked then some window is being moved around which stops
// us from getting clipping information. In this case if we have a clipper or
// an overlay surface then we just assume all is still well and carry with it
// Otherwise we could be using the primary surface and write on other windows
// or desktop. If the screen isn't locked then our video window is occluded

BOOL CDirectDraw::CheckEmptyClip(BOOL bWindowLock)
{
    NOTE("Entering CheckEmptyClip");

    // Is the overlay currently visible

    if (m_bOverlayVisible == FALSE) {
        if (m_pOverlaySurface) {
            return FALSE;
        }
    }

    // Get the screen clipping rectangle

    RECT ClipRect;
    HDC hDC = GetDC(NULL);
    if ( ! hDC )
        return FALSE;
    INT Result = GetClipBox(hDC,&ClipRect);
    ReleaseDC(NULL,hDC);

    // Special cased for overlays and clippers

    if (m_pOverlaySurface || m_pDrawClipper) {
        if (Result == NULLREGION) {
            if (bWindowLock == FALSE) {
                NOTE("Empty clip ok");
                return TRUE;
            }
        }
    }
    return FALSE;
}


// If we have a complex clip region then we can still use the surface if we
// have a clipper (in which case the display driver will handle the clipping
// problem) or can switch to using a colour key (so that the presence of the
// key colour looks after the correct positioning). These are allocated when
// the surface is made. Otherwise we return FALSE to say switch back to DIBs

BOOL CDirectDraw::CheckComplexClip()
{
    NOTE("Entering CheckComplexClip");

    // Do we have a clipper or colour key

    if (m_pDrawClipper == NULL) {
        if (m_bColourKey == FALSE) {
            NOTE("CheckComplexClip failed");
            return FALSE;
        }
    }
    return (m_bColourKeyPending == TRUE ? FALSE : TRUE);
}


// This is the core method for controlling DCI/DirectDraw surfaces. Each time
// the video allocator is preparing to access a surface it calls this to find
// out if the surface is available. Our main purpose is to update the display
// rectangles and return NULL if we detect a situation where the surface can
// not be accessed for whatever reason. The allocator is also interested in
// knowing not just whether the surface is available but also if the format
// that represents it has changed, we handle this through an extra parameter

CMediaType *CDirectDraw::UpdateSurface(BOOL &bFormatChanged)
{
    NOTE("Entering UpdateSurface");
    CAutoLock cVideoLock(this);
    BOOL bWindowLock = m_bWindowLock;
    m_bWindowLock = TRUE;
    bFormatChanged = TRUE;
    RECT ClipRect;

    // See if the palette stops us using the surface

    if (CheckWindowLock() == TRUE) {
        NOTE("Window locked");
        return NULL;
    }

    // Check the current bounding clip rectangle

    HDC hdc = m_pRenderer->m_VideoWindow.GetWindowHDC();
    INT Result = GetClipBox(hdc,&ClipRect);
    if (Result == ERROR) {
        NOTE("Clip error");
        return NULL;
    }

    // Can we cope with an empty clip rectangle

    if (Result == NULLREGION) {
        NOTE("Handling NULLREGION clipping");
        m_bWindowLock = !CheckEmptyClip(bWindowLock);
        bFormatChanged = m_bWindowLock;
        return (m_bWindowLock ? NULL : &m_SurfaceFormat);
    }

    // And how about complex clipping situations

    if (Result == COMPLEXREGION) {
        if (CheckComplexClip() == FALSE) {
            NOTE("In COMPLEXREGION lock");
            return NULL;
        }
    }

    m_bWindowLock = FALSE;

    // Update the source and destination rectangles and also position the
    // overlay surface if need be. If any of our methods after the call to
    // GetClipBox fail then they can mark our window as locked and we will
    // return NULL down below. This will switch the allocator back to DIBs

    bFormatChanged = UpdateDisplayRectangles(&ClipRect);
    if (Result == COMPLEXREGION) {
        // don't do anything if the overlay can do clipping without overlays
        if (m_bOverlayVisible == TRUE && m_bColourKey) {
            if (ShowColourKeyOverlay() == FALSE) {
                NOTE("Colour key failed");
                m_bWindowLock = TRUE;
                return NULL;
            }
        }
    }

    // Either of these force a format renegotiation

    if (bWindowLock) {
        bFormatChanged = TRUE;
    }
    return (m_bSurfacePending || m_bWindowLock ? NULL : &m_SurfaceFormat);
}


// Lots of older display cards have alignment restrictions on the source and
// destination rectangle left offset and their overall size (widths). If we
// do not do something about this then we will have to swap back to using DIB
// formats more often. Therefore what we do is to shrink the image within the
// actual required source and destination rectangles to meet the restrictions

// This may in turn mean that the hardware has to do some stretching which it
// may not be capable of, but then we wouldn't have used it anyway so we have
// hardly lost much. We have to shrink the video within the allowed playback
// area rather than shifting otherwise we may write on any windows underneath

BOOL CDirectDraw::AlignRectangles(RECT *pSource,RECT *pTarget)
{
    NOTE("Entering AlignRectangles");

    DWORD SourceLost = 0;           // Pixels to shift source left by
    DWORD TargetLost = 0;           // Likewise for the destination
    DWORD SourceWidthLost = 0;      // Chop pixels off the width
    DWORD TargetWidthLost = 0;      // And also for the destination

    BOOL bMatch = (WIDTH(pSource) == WIDTH(pTarget) ? TRUE : FALSE);
    ASSERT(m_pOverlaySurface || m_pOffScreenSurface);

    // Shift the source rectangle to align it appropriately

    if (m_DirectCaps.dwAlignBoundarySrc) {
        SourceLost = pSource->left % m_DirectCaps.dwAlignBoundarySrc;
        if (SourceLost) {
            SourceLost = m_DirectCaps.dwAlignBoundarySrc - SourceLost;
            if ((DWORD)WIDTH(pSource) > SourceLost) {
                NOTE1("Source left %d",SourceLost);
                pSource->left += SourceLost;
            }
        }
    }

    // Shift the destination rectangle to align it appropriately

    if (m_DirectCaps.dwAlignBoundaryDest) {
        TargetLost = pTarget->left % m_DirectCaps.dwAlignBoundaryDest;
        if (TargetLost) {
            TargetLost = m_DirectCaps.dwAlignBoundaryDest - TargetLost;
            if ((DWORD)WIDTH(pTarget) > TargetLost) {
                NOTE1("Target left %d",TargetLost);
                pTarget->left += TargetLost;
            }
        }
    }

    // We may have to shrink the source rectangle size to align it

    if (m_DirectCaps.dwAlignSizeSrc) {
        SourceWidthLost = WIDTH(pSource) % m_DirectCaps.dwAlignSizeSrc;
        if (SourceWidthLost) {
            if ((DWORD)WIDTH(pSource) > SourceWidthLost) {
                pSource->right -= SourceWidthLost;
                NOTE1("Source width %d",SourceWidthLost);
            }
        }
    }

    // We may have to shrink the target rectangle size to align it

    if (m_DirectCaps.dwAlignSizeDest) {
        TargetWidthLost = WIDTH(pTarget) % m_DirectCaps.dwAlignSizeDest;
        if (TargetWidthLost) {
            if ((DWORD)WIDTH(pTarget) > TargetWidthLost) {
                pTarget->right -= TargetWidthLost;
                NOTE1("Target width %d",TargetWidthLost);
            }
        }
    }

    // Update the state variables

    m_SourceLost = SourceLost;
    m_TargetLost = TargetLost;
    m_SourceWidthLost = SourceWidthLost;
    m_TargetWidthLost = TargetWidthLost;

    // If the source and destination originally differed then we're done

    if (bMatch == FALSE) {
        NOTE("No match");
        return TRUE;
    }

    // If the source and destination were originally the same size and they
    // now differ then we try to make them match. If the source is larger
    // than the destination then we shrink it down but only if the source
    // rectangle width we end up with is still aligned correctly otherwise
    // we won't have got anywhere (we do the same in the opposite case)

    LONG Difference = WIDTH(pSource) - WIDTH(pTarget);
    if (Difference == 0) {
        NOTE("No difference");
        return TRUE;
    }

    // Is the destination bigger than the source or vica versa

    if (Difference < 0) {
        RECT AdjustTarget = *pTarget;
        AdjustTarget.right += Difference; // NOTE Difference < 0
        if (WIDTH(&AdjustTarget) > 0) {
            if ((m_DirectCaps.dwAlignSizeDest == 0) ||
                (WIDTH(&AdjustTarget) % m_DirectCaps.dwAlignSizeDest) == 0) {
                    pTarget->right = AdjustTarget.right;
                    m_TargetWidthLost -= Difference; // NOTE Difference < 0
            }
        }
    } else {
        RECT AdjustSource = *pSource;
        AdjustSource.right -= Difference; // NOTE Difference > 0
        if (WIDTH(&AdjustSource) > 0) {
            if ((m_DirectCaps.dwAlignSizeDest == 0) ||
                (WIDTH(&AdjustSource) % m_DirectCaps.dwAlignSizeDest) == 0) {
                    pSource->right = AdjustSource.right;
                    m_SourceWidthLost += Difference; // NOTE Difference > 0
            }
        }
    }

    NOTE1("Alignment difference %d",Difference);
    NOTE1("  Source left %d",m_SourceLost);
    NOTE1("  Source width %d",m_SourceWidthLost);
    NOTE1("  Target left %d",m_TargetLost);
    NOTE1("  Target width %d",m_TargetWidthLost);

    return TRUE;
}


// If we're using an offscreen surface then we will be asking the display to
// do the drawing through its hardware. If however we are bank switched then
// we shouldn't stretch between video memory since it causes back thrashing
// We also don't use DirectDraw to stretch if the hardware can't do it as it
// is really slow, we are much better off using the optimised GDI stretching

BOOL CDirectDraw::CheckOffScreenStretch(RECT *pSource,RECT *pTarget)
{
    NOTE("Entering CheckOffScreenStretch");

    // If no offscreen stretching is needed then we're all set

    if (WIDTH(pTarget) == WIDTH(pSource)) {
        if (HEIGHT(pTarget) == HEIGHT(pSource)) {
            NOTE("No stretch");
            return TRUE;
        }
    }

    // We should not stretch bank switched offscreen surfaces

    if (m_DirectCaps.dwCaps & DDCAPS_BANKSWITCHED) {
        NOTE("DDCAPS_BANKSWITCHED lock");
        return FALSE;
    }

    // Don't let DirectDraw stretch as it is really slow

    if (m_DirectCaps.dwCaps & DDCAPS_BLTSTRETCH) {
        NOTE("DDCAPS_BLTSTRETCH stretch");
        return TRUE;
    }
    return FALSE;
}


// We provide the minimum and maximum ideal window sizes through IVideoWindow
// An application should use this interface to work out what size the video
// window should be sized to. If the window is either too small or too large
// with respect to any DirectDraw overlay surface in use then we switch back
// to DIBs. S3 boards for example have a variety of overlay stretch factors
// when set in different display modes. We also check the source and target
// rectangles are aligned and sized according to any DirectDraw restrictions

BOOL CDirectDraw::CheckStretch(RECT *pSource,RECT *pTarget)
{
    ASSERT(m_pOverlaySurface || m_pOffScreenSurface);
    DWORD WidthTarget = WIDTH(pTarget);
    DWORD WidthSource = WIDTH(pSource);
    NOTE("Entering CheckStretch");

    // Check we don't fault if these are empty

    if (WidthSource == 0 || WidthTarget == 0) {
        NOTE("Invalid rectangles");
        return FALSE;
    }

    // Separate tests for offscreen surfaces

    if (m_pOverlaySurface == NULL) {
        NOTE("Checking offscreen stretch");
        ASSERT(m_pOffScreenSurface);
        return CheckOffScreenStretch(pSource,pTarget);
    }

    // Can the hardware handle overlay stretching

    if ((m_DirectCaps.dwCaps & DDCAPS_OVERLAYSTRETCH) == 0) {
        if (WidthTarget != WidthSource) {
            if (HEIGHT(pSource) != HEIGHT(pTarget)) {
                if (m_pOverlaySurface) {
                    NOTE("No DDCAPS_OVERLAYSTRETCH");
                    return FALSE;
                }
            }
        }
    }

    DWORD StretchWidth = WIDTH(pTarget) * 1000 / WIDTH(pSource);

    // See if our video isn't being stretched enough

    if (m_DirectCaps.dwMinOverlayStretch) {
        if (StretchWidth < m_DirectCaps.dwMinOverlayStretch) {
            if (m_bCanUseOverlayStretch == TRUE) {
            	NOTE("Fails minimum stretch");
            	return FALSE;
            }
        }
    }

    // Alternatively it may be stretched too much

    if (m_DirectCaps.dwMaxOverlayStretch) {
        if (StretchWidth > m_DirectCaps.dwMaxOverlayStretch) {
            if (m_bCanUseOverlayStretch == TRUE) {
            	NOTE("Fails maximum stretch");
            	return FALSE;
            }
        }
    }

    // Check the rectangle size and alignments

    if (m_DirectCaps.dwAlignBoundarySrc == 0 ||
        (pSource->left % m_DirectCaps.dwAlignBoundarySrc) == 0) {
        if (m_DirectCaps.dwAlignSizeSrc == 0 ||
            (WIDTH(pSource) % m_DirectCaps.dwAlignSizeSrc) == 0) {
            if (m_DirectCaps.dwAlignBoundaryDest == 0 ||
                (pTarget->left % m_DirectCaps.dwAlignBoundaryDest) == 0) {
                if (m_DirectCaps.dwAlignSizeDest == 0 ||
                    (WIDTH(pTarget) % m_DirectCaps.dwAlignSizeDest) == 0) {
                        NOTE("Stretch and alignment ok");
                        return TRUE;
                }
            }
        }
    }

    // Show why the source and/or destination rectangles failed

    if (m_DirectCaps.dwAlignBoundarySrc)
        NOTE1("Source extent %d",(pSource->left % m_DirectCaps.dwAlignBoundarySrc));
    if (m_DirectCaps.dwAlignSizeSrc)
        NOTE1("Source size extent %d",(WIDTH(pSource) % m_DirectCaps.dwAlignSizeSrc));
    if (m_DirectCaps.dwAlignBoundaryDest)
        NOTE1("Target extent %d",(pTarget->left % m_DirectCaps.dwAlignBoundaryDest));
    if (m_DirectCaps.dwAlignSizeDest)
        NOTE1("Target size extent %d",(WIDTH(pTarget) % m_DirectCaps.dwAlignSizeDest));

    return FALSE;
}


// Update the source and target rectangles for the DCI/DirectDraw surface. We
// return FALSE if the update caused no change, otherwise we return TRUE. For
// offscreen and overlay surfaces a change in source or target rectangles has
// no effect on the type we request on the source filter because the area we
// invoke UpdateOverlay or blt with is handled solely through DirectDraw. The
// method is passed in a clipping rectangle for the destination device context
// that should be used to calculate the actual visible video playback surface
// NOTE we update the m_SourceClipRect and m_TargetClipRect member variables

BOOL CDirectDraw::UpdateDisplayRectangles(RECT *pClipRect)
{
    NOTE("Entering UpdateDisplayRectangles");
    RECT TargetClipRect,SourceClipRect;
    ASSERT(pClipRect);

    // The clipping rectangle is in window coordinates

    if (IntersectRect(&TargetClipRect,&m_TargetRect,pClipRect) == FALSE) {
        NOTE("Intersect lock");
        m_bWindowLock = TRUE;
        return TRUE;
    }

    // Find in screen coordinates the corner of the client rectangle

    POINT ClientCorner = {0,0};
    HWND hwnd = m_pRenderer->m_VideoWindow.GetWindowHWND();
    EXECUTE_ASSERT(ClientToScreen(hwnd,&ClientCorner));

    // We want the offset from the start of this monitor, not (0,0) !
    ClientCorner.x -= m_pRenderer->m_rcMonitor.left;
    ClientCorner.y -= m_pRenderer->m_rcMonitor.top;

    // We use the source and destination sizes many times

    ASSERT(IsRectEmpty(&m_SourceRect) == FALSE);
    LONG SrcWidth = WIDTH(&m_SourceRect);
    LONG SrcHeight = HEIGHT(&m_SourceRect);
    LONG DstWidth = WIDTH(&m_TargetRect);
    LONG DstHeight = HEIGHT(&m_TargetRect);
    LONG xOffset = m_TargetRect.left + ClientCorner.x;
    LONG yOffset = m_TargetRect.top + ClientCorner.y;

    // Adjust the destination rectangle to be in device coordinates

    TargetClipRect.left += ClientCorner.x;
    TargetClipRect.right += ClientCorner.x;
    TargetClipRect.top += ClientCorner.y;
    TargetClipRect.bottom += ClientCorner.y;

    // From the target section visible calculate the source required

    SourceClipRect.left = m_SourceRect.left +
        ((TargetClipRect.left - xOffset) * SrcWidth / DstWidth);
    SourceClipRect.right = m_SourceRect.left +
        ((TargetClipRect.right - xOffset) * SrcWidth / DstWidth);
    SourceClipRect.top = m_SourceRect.top +
        ((TargetClipRect.top - yOffset) * SrcHeight / DstHeight);
    SourceClipRect.bottom = m_SourceRect.top +
        ((TargetClipRect.bottom - yOffset) * SrcHeight / DstHeight);

    // Check we have a valid source rectangle

    if (IsRectEmpty(&SourceClipRect)) {
        NOTE("Source is empty");
        m_bWindowLock = TRUE;
        return TRUE;
    }

    // Adjust rectangles to maximise surface usage

    if (m_pOverlaySurface || m_pOffScreenSurface) {
        AlignRectangles(&SourceClipRect,&TargetClipRect);
        if (CheckStretch(&SourceClipRect,&TargetClipRect) == FALSE) {
            NOTE("Setting window lock");
            m_bWindowLock = TRUE;
            return TRUE;
        }
    }
    return UpdateRectangles(&SourceClipRect,&TargetClipRect);
}


// We are passed in the new source and target rectangles clipped according to
// the visible area of video in the display device (they should not be empty)
// If they match the current display rectangles then we'll return FALSE as no
// format negotiation needs to take place. If we have an overlay or offscreen
// surface then likewise no format negotiation needs to take place as all the
// handling of which surface areas to use is taken care of through DirectDraw

BOOL CDirectDraw::UpdateRectangles(RECT *pSource,RECT *pTarget)
{
    VIDEOINFO *pVideoInfo = (VIDEOINFO *) m_SurfaceFormat.Format();
    BITMAPINFOHEADER *pHeader = HEADER(pVideoInfo);
    NOTE("Entering UpdateRectangles");

    // Check the target is DWORD aligned for primary surfaces

    if (GetDirectDrawSurface() == NULL) {
        if ((pTarget->left * pHeader->biBitCount / 8) & 3) {
            NOTE("Not DWORD aligned");
            m_bWindowLock = TRUE;
            return TRUE;
        }
    }

    // Are both the source and target rectangles the same

    if (EqualRect(&m_SourceClipRect,pSource)) {
        if (EqualRect(&m_TargetClipRect,pTarget)) {
            NOTE("Rectangles match");
            return FALSE;
        }
    }

    // Switch back if we were waiting for a change

    BOOL bSurfacePending = IsSurfacePending();
    DbgLog((LOG_TRACE,3,TEXT("SourceClipRect = (%d,%d,%d,%d)"),
		pSource->left, pSource->top, pSource->right, pSource->bottom));
    DbgLog((LOG_TRACE,3,TEXT("TargetClipRect = (%d,%d,%d,%d)"),
		pTarget->left, pTarget->top, pTarget->right, pTarget->bottom));
    m_SourceClipRect = *pSource;
    m_TargetClipRect = *pTarget;
    SetSurfacePending(FALSE);

    // Offscreen surfaces are not affected

    if (GetDirectDrawSurface()) {
        NOTE("Is an offscreen");
        UpdateOverlaySurface();
        return bSurfacePending;
    }

    // Update the surface format rectangles

    pVideoInfo->rcSource = m_SourceClipRect;
    NOTERC("Primary source",m_SourceClipRect);
    pVideoInfo->rcTarget = m_TargetClipRect;
    NOTERC("Primary target",m_TargetClipRect);
    return TRUE;
}


// Called to free any DCI/DirectDraw resources we are currently holding. We
// get the surface pointer passed back in because DirectDraw wants it back
// since it is possible to lock a surface simultaneously with a number of
// different destination rectangles although we just lock the whole thing
// WARNING the surface should be unlocked before the video critical section
// is unlocked, there is a small chance of us seeing an invalid state but
// there is a very big chance of hanging if we have to wait for the lock

BOOL CDirectDraw::UnlockSurface(BYTE *pSurface,BOOL bPreroll)
{
    NOTE("Entering UnlockSurface");
    ASSERT(m_bIniEnabled == TRUE);
    ASSERT(pSurface);

    // Is it just the primary that needs unlocking

    if (GetDirectDrawSurface() == NULL) {
        NOTE("Unlocking DirectDraw primary");
        m_pDrawPrimary->Unlock(m_pDrawBuffer);
        m_pDrawBuffer = NULL;
        return TRUE;
    }

    // Unlock the surface and update the overlay position - on Cirrus CL5440
    // cards in 1024x768x8 bit mode we can lock the overlay surface but when
    // we return to do the unlock DirectDraw barfs at the pointer and leaves
    // the surface locked! The answer is just to pass a NULL surface pointer

    GetDirectDrawSurface()->Unlock(NULL);
    if (bPreroll == TRUE) {
        NOTE("Preroll");
        return TRUE;
    }

    // If this is a normal overlay then have it displayed

    if (m_pBackBuffer == NULL) {
        NOTE("Showing overlay surface");
        return ShowOverlaySurface();
    }
    return TRUE;
}


// Return the current DirectDraw surface we're using. We return NULL if we
// are using the DCI/DirectDraw primary surface. So if the caller wants to
// know the DirectDraw surface so that it can lock or unlock it they will
// have to check the return code for NULL and set the surface pointer to be
// m_pDrawPrimary. With flipping surfaces we always return the back buffer

LPDIRECTDRAWSURFACE CDirectDraw::GetDirectDrawSurface()
{
    NOTE("Entering GetDirectDrawSurface");

    // Do we have an offscreen surface

    if (m_pOffScreenSurface) {
        return m_pOffScreenSurface;
    }

    // Do we have a flipping surface

    if (m_pBackBuffer) {
        return m_pBackBuffer;
    }
    return m_pOverlaySurface;
}


// The video allocator calls this when it is ready to lock the surface. The
// IMediaSample we are given is cast to a CVideoSample and then we can lock
// the surface which may return NULL if it cannot be done. In which case we
// return FALSE so that the allocator knows to switch back to DIBs. Assuming
// all went well we can initialise the video sample with the surface pointer
// as well as the two DirectDraw interfaces it exposes and the surface size

BOOL CDirectDraw::InitVideoSample(IMediaSample *pMediaSample,DWORD dwFlags)
{
    NOTE("Entering InitVideoSample");
    CVideoSample *pVideoSample = (CVideoSample *) pMediaSample;
    BYTE *pSurface = LockSurface(dwFlags);
    ASSERT(m_bIniEnabled == TRUE);

    // Last chance to do something else

    if (pSurface == NULL) {
        return FALSE;
    }

    // Set the DirectDraw surface we are using

    LPDIRECTDRAWSURFACE pDrawSurface = GetDirectDrawSurface();
    if (pDrawSurface == NULL) {
        pDrawSurface = m_pDrawPrimary;
    }

    // Set the DirectDraw instance for the sample

    LPDIRECTDRAW pDirectDraw = NULL;
    if (pDrawSurface) {
        ASSERT(m_pDirectDraw);
        pDirectDraw = m_pDirectDraw;
    }

    // Initialise the sample with the DirectDraw interfaces

    pVideoSample->SetDirectInfo(pDrawSurface,          // Surface interface
                                pDirectDraw,           // DirectDraw object
                                m_cbSurfaceSize,       // Size of the buffer
                                (BYTE *) pSurface);    // Pointer to surface
    return TRUE;
}


// Called when the video sample is delivered to our pin or released - it may
// not be a DCI/DirectDraw enabled sample, we know if it is because it holds
// a direct surface pointer available via GetDirectBuffer. If it is a direct
// buffer then we must unlock the surface. None of this requires this object
// to be locked because we don't want to contend locks with surfaces locked

BOOL CDirectDraw::ResetSample(IMediaSample *pMediaSample,BOOL bPreroll)
{
    NOTE1("Entering ResetSample (Preroll sample %d)",bPreroll);
    CVideoSample *pVideoSample = (CVideoSample *) pMediaSample;
    BYTE *pSurface = pVideoSample->GetDirectBuffer();
    pVideoSample->SetDirectInfo(NULL,NULL,0,NULL);

    // Is this a hardware DCI/DirectDraw buffer

    if (pSurface == NULL) {
        NOTE("Not hardware");
        return FALSE;
    }

    // Unlock the hardware surface

    NOTE("Unlocking DirectDraw");
    UnlockSurface(pSurface,bPreroll);
    m_bOverlayStale = bPreroll;

    return TRUE;
}


// When using a hardware offscreen draw surface we will normally wait for the
// monitor scan line to move past the destination rectangle before drawing so
// that we avoid tearing where possible. Of course not all display cards can
// support this feature and even those that do will see a performance drop of
// about 10% because we sit polling (oh for a generic PCI monitor interrupt)

void CDirectDraw::WaitForScanLine()
{
    ASSERT(m_pOverlaySurface == NULL);
    ASSERT(m_pBackBuffer == NULL);
    ASSERT(m_pOffScreenSurface);
    HRESULT hr = NOERROR;
    DWORD dwScanLine;

    // Some display cards like the ATI Mach64 support reporting of the scan
    // line they are processing. However not all drivers are setting the
    // DDCAPS_READSCANLINE capability flag so we just go ahead and ask for
    // it anyway. We allow for 10 scan lines above the top of our rectangle
    // so that we have a little time to thunk down and set the draw call up

    #define SCANLINEFUDGE 10
    while (m_bCanUseScanLine == TRUE) {

    	hr = m_pDirectDraw->GetScanLine(&dwScanLine);
        if (FAILED(hr)) {
            NOTE("No scan line");
            break;
        }

        NOTE1("Scan line returned %lx",dwScanLine);

    	if ((LONG) dwScanLine + SCANLINEFUDGE >= m_TargetClipRect.top) {
            if ((LONG) dwScanLine <= m_TargetClipRect.bottom) {
                NOTE("Scan inside");
                continue;
            }
        }
        break;
    }
}


// When issuing flips asynchrously we must sometimes wait for previous flips
// to complete before sending another. When triple buffering we do this just
// before the flip call. For double buffered we do this before locking the
// surface to decode the next frame. We should get better performance from
// triple buffering as the flip should be picked up at the next monitor sync

void CDirectDraw::WaitForFlipStatus()
{
    if (m_pBackBuffer == NULL) return;
    ASSERT(m_pOffScreenSurface == NULL);
    ASSERT(m_pDrawPrimary);
    ASSERT(m_pOverlaySurface);
    ASSERT(m_pDirectDraw);

    while (m_pBackBuffer->GetFlipStatus(DDGFS_ISFLIPDONE) ==
        DDERR_WASSTILLDRAWING) Sleep(DDGFS_FLIP_TIMEOUT);
}


// This is called just before we lock the DirectDraw surface, if we are using
// a complex overlay set, either double or triple buffered then we must copy
// the current upto date overlay into the back buffer beforehand. If however
// the flags on the GetBuffer call indicate that the buffer is not key frame
// then we don't bother doing this - which is the case for all MPEG pictures

BOOL CDirectDraw::PrepareBackBuffer()
{
    NOTE("Preparing backbuffer");
    if (m_pBackBuffer == NULL) {
        return TRUE;
    }

    // Check the overlay has not gone stale

    if (m_bOverlayStale == TRUE) {
        NOTE("Overlay is stale");
        return TRUE;
    }

    // Finally copy the overlay to the back buffer

    HRESULT hr = m_pBackBuffer->BltFast((DWORD) 0, (DWORD) 0,  // Target place
                                        m_pOverlaySurface,     // Image source
                                        (RECT *) NULL,         // All source
                                        DDBLTFAST_WAIT |       // Wait finish
                                        DDBLTFAST_NOCOLORKEY); // Copy type
    ASSERT_FLIP_COMPLETE(hr);

    if (FAILED(hr)) {
        DbgLog((LOG_TRACE, 1, TEXT("BltFast failed code %8.8X"), hr));
    }

    if (FAILED(hr)) {
        //  Give up on the back buffers
        m_pBackBuffer = NULL;
    }


    return TRUE;
}


// Begins access to the DCI/DirectDraw surface. This is a public entry point
// used by our video allocator when the time arrives for the next frame to be
// decompressed. If we tell it the sync should happen on the fill then it'll
// wait until the sample display time arrives before calling us. If we tell
// it the buffer should sync'ed on the draw it calls us as soon as possible

BYTE *CDirectDraw::LockSurface(DWORD dwFlags)
{
    NOTE("Entering LockSurface");
    ASSERT(m_bIniEnabled == TRUE);
    CAutoLock cVideoLock(this);

    // Are we using the primary surface

    if (GetDirectDrawSurface() == NULL) {
        return LockPrimarySurface();
    }

    ASSERT(m_pDirectDraw);
    ASSERT(m_pDrawPrimary);
    HRESULT hr = NOERROR;

    // For complex overlays prepare the back buffer

    if (dwFlags & AM_GBF_NOTASYNCPOINT) {
        if (PrepareBackBuffer() == FALSE) {
            NOTE("Prepare failed");
            return NULL;
        }
    }

    // Reset the size field in the DDSURFACEDESC structure

    DDSURFACEDESC SurfaceDesc;
    SurfaceDesc.dwSize = sizeof(DDSURFACEDESC);
    IDirectDrawSurface *pSurface = GetDirectDrawSurface();
    NOTE1("Locking offscreen surface %lx",pSurface);

    // Lock the surface to get the buffer pointer

    hr = pSurface->Lock((RECT *) NULL,    // Target rectangle
                        &SurfaceDesc,     // Return information
                        DDLOCK_WAIT,      // Wait for surface
                        (HANDLE) NULL);   // Don't use event


    // make sure the pitch is valid here
    if (SurfaceDesc.lPitch <= -1)
    {
	pSurface->Unlock(NULL);
	DbgLog((LOG_ERROR, 0, TEXT("inside LockSurface, Pitch = %d"), SurfaceDesc.lPitch));
	return NULL;
    }

    ASSERT_FLIP_COMPLETE(hr);

    // Is the surface otherwise engaged

    if (hr == DDERR_SURFACEBUSY) {
        NOTE("Surface is busy");
        StartUpdateTimer();
        return NULL;
    }

    // Handle real DirectDraw errors

    if (FAILED(hr)) {
        NOTE1("Lock failed %hx",hr);
        SetSurfacePending(TRUE);
        return NULL;
    }

    // Display some surface information

    NOTE1("Stride %d",SurfaceDesc.lPitch);
    NOTE1("Width %d",SurfaceDesc.dwWidth);
    NOTE1("Height %d",SurfaceDesc.dwHeight);
    NOTE1("Surface %x",SurfaceDesc.lpSurface);
    return (PBYTE) SurfaceDesc.lpSurface;
}


// Internal method to lock the DirectDraw primary surface only. We're called
// by LockPrimarySurface. If you lock a specific region with DCI the pointer
// returned is always the start of the frame buffer. In DirectDraw we get a
// pointer to the start of the actual rectangle. To make the two consistent
// we back the pointer up from DirectDraw to get to the start of the surface
// We must pass in valid rectangles so that any software cursors are handled

BYTE *CDirectDraw::LockDirectDrawPrimary()
{
    NOTE("Entering LockDirectDrawPrimary");
    ASSERT(m_pDirectDraw);
    ASSERT(m_pDrawPrimary);
    HRESULT hr = NOERROR;

    // Reset the size field in the DDSURFACEDESC structure

    VIDEOINFO *pVideoInfo = (VIDEOINFO *) m_SurfaceFormat.Format();
    DDSURFACEDESC SurfaceDesc;
    SurfaceDesc.dwSize = sizeof(DDSURFACEDESC);
    NOTE1("Locking primary surface %lx",m_pDrawPrimary);

    // Lock the DirectDraw primary surface to get the pointer

    hr = m_pDrawPrimary->Lock(&pVideoInfo->rcTarget,  // Our target rectangle
                              &SurfaceDesc,           // Surface descriptor
                              DDLOCK_WAIT,            // Wait until available
                              (HANDLE) NULL);         // Don't signal event

    // make sure the pitch is valid here
    if (SurfaceDesc.lPitch <= -1)
    {
	m_pDrawPrimary->Unlock(SurfaceDesc.lpSurface);
	DbgLog((LOG_ERROR, 0, TEXT("inside LockDirectDrawPrimary, Pitch = %d"), SurfaceDesc.lPitch));
	return NULL;
    }

    // Is the surface otherwise engaged

    if (hr == DDERR_SURFACEBUSY) {
        NOTE("Surface is busy");
        StartUpdateTimer();
        return NULL;
    }

    // Handle real DirectDraw errors

    if (FAILED(hr)) {
        NOTE1("Lock failed %hx",hr);
        SetSurfacePending(TRUE);
        return NULL;
    }

    // Back the pointer up to the start of the buffer

    NOTE("Locked primary surface successfully");
    LPBYTE pFrameBuffer = (PBYTE) SurfaceDesc.lpSurface;
    DWORD Stride = DIBWIDTHBYTES(pVideoInfo->bmiHeader);
    pFrameBuffer -= (Stride * pVideoInfo->rcTarget.top);
    DWORD BytesPixel = (SurfaceDesc.ddpfPixelFormat.dwRGBBitCount / 8);
    if (m_DirectDrawVersion1) BytesPixel = 1;
    pFrameBuffer -= (pVideoInfo->rcTarget.left * BytesPixel);
    m_pDrawBuffer = (PBYTE) SurfaceDesc.lpSurface;

    NOTE1("Frame Buffer %x",(PBYTE) SurfaceDesc.lpSurface);
    NOTE1("Stride of surface %d",Stride);
    NOTE1("Lines to skip %d",pVideoInfo->rcTarget.top);
    NOTE1("Pixels in from left edge %d",pVideoInfo->rcTarget.left);
    NOTE1("Resulting frame buffer %x",pFrameBuffer);
    NOTE1("DirectDraw version 1? = %d",m_DirectDrawVersion1);

    return pFrameBuffer;
}


// Returns a pointer to the first pixel of the primary surface (either DCI or
// DirectDraw). If we are on a bank switched DCI enabled display then we have
// to construct the linear frame buffer pointer from a segment and offset. We
// call through the DCIMAN32 entry points to get access to the surface as we
// cannot always call from a Win32 program straight to kernel drives. When we
// call DCICreatePrimary it fills the methods with either 0xFFFFFFFF or zero

BYTE *CDirectDraw::LockPrimarySurface()
{
    NOTE("Entering LockPrimarySurface");
    ASSERT(m_pDrawPrimary);

    return LockDirectDrawPrimary();
}


// Update the overlay surface to position it correctly. We split out updating
// the overlay position into this function because it is so expensive to call
// In particular it is easy to consume more than 12% of the CPU playing back
// on BrookTree and S3 cards if you dumbly call UpdateOverlay for each frame
// Therefore we only call it when something really happens to the destination
// or source rectangles. If we update a little late then we don't lose much
// as overlay surfaces don't scribble their images into the real frame buffer

BOOL CDirectDraw::UpdateOverlaySurface()
{
    NOTE("Entering UpdateOverlaySurface");
    HRESULT hr = NOERROR;
    CAutoLock cVideoLock(this);

    // Do we have a visible overlay surface

    if (m_bOverlayVisible == FALSE ||
            m_pOverlaySurface == NULL ||
                m_bWindowLock == TRUE) {

        return TRUE;
    }

    NOTE("Painting window");
    OnPaint(NULL);
    DWORD Flags = DDOVER_SHOW;
    WaitForFlipStatus();

    // Set the approprate flags to maintain our state

    if (m_bUsingColourKey) {
        Flags |= DDOVER_KEYDEST;
        NOTE("Set DDOVER_KEYDEST");
    }

    // Position the overlay with the current source and destination

    //DbgLog((LOG_TRACE,1,TEXT("UpdateOverlaySurface is SHOWing the overlay")));
    hr = m_pOverlaySurface->UpdateOverlay(&m_SourceClipRect,  // Video source
                                          m_pDrawPrimary,     // Main surface
                                          &m_TargetClipRect,  // Sink position
                                          (DWORD) Flags,      // Flag settings
                                          NULL);              // No effects
    ASSERT_FLIP_COMPLETE(hr);

    // Is the surface otherwise engaged

    if (hr == DDERR_SURFACEBUSY) {
        NOTE("Surface is busy");
        HideOverlaySurface();
        StartUpdateTimer();
        return FALSE;
    }

    NOTE1("Update overlay returned %lx",hr);
    NOTERC("Source",m_SourceClipRect);
    NOTERC("Target",m_TargetClipRect);

    // Handle real DirectDraw errors

    if (FAILED(hr)) {
        SetSurfacePending(TRUE);
        HideOverlaySurface();
        NOTE("Update failed");
        return FALSE;
    }

    // There seems to be a slight snag with using non colour keyed overlays
    // on BrookTree cards. If you call UpdateOverlay in quick succession it
    // misses some of them out thereby leaving the overlay positioned wrong
    // The simplest solution is to wait each time for the vertical refresh

    m_pDirectDraw->WaitForVerticalBlank(DDWAITVB_BLOCKEND,NULL);
    return TRUE;
}


// This function has the overlay shown if not already done. If we're showing
// the overlay surface for the first time then clear the target rectangle
// in the video window underneath. Otherwise it flashes up the wrong image
// when we are dragging the window around and then finally hide the overlay.
// After we have shown the overlay we look to see if we are complex clipped
// and if so then we try to switch to colour keys. This may fail if colour
// keys are not available in which case we continue using overlays anyway

BOOL CDirectDraw::ShowOverlaySurface()
{
    NOTE("Entering ShowOverlaySurface");
    CAutoLock cVideoLock(this);
    HRESULT hr = NOERROR;

    // Are we using an overlay surface

    if (m_pOverlaySurface == NULL ||
            m_bWindowLock == TRUE ||
                m_bOverlayVisible == TRUE) {
                    return TRUE;
    }

    WaitForFlipStatus();

    // Position the overlay with the current source and destination

    //DbgLog((LOG_TRACE,1,TEXT("ShowOverlaySurface is SHOWing the overlay!")));
    hr = m_pOverlaySurface->UpdateOverlay(&m_SourceClipRect,  // Video source
                                          m_pDrawPrimary,     // Main surface
                                          &m_TargetClipRect,  // Sink position
                                          DDOVER_SHOW,        // Show overlay
                                          NULL);              // No effects
    ASSERT_FLIP_COMPLETE(hr);

    // Is the surface otherwise engaged

    if (hr == DDERR_SURFACEBUSY) {
        NOTE("Surface is busy");
        StartUpdateTimer();
        return FALSE;
    }

    NOTE1("Show overlay returned %lx",hr);
    NOTERC("Source",m_SourceClipRect);
    NOTERC("Target",m_TargetClipRect);

    // Handle real DirectDraw errors

    if (FAILED(hr)) {
        NOTE("Overlay not shown");
        SetSurfacePending(TRUE);
        return FALSE;
    }

    m_bOverlayVisible = TRUE;
    NOTE("Painting window");
    OnPaint(NULL);

    // This helps out the BrookTree DirectDraw guys whose driver only clips
    // to DWORD boundaries when colour keys aren't being used. So when the
    // hardware signals colour keys have no overhead we always install one
    // For other DirectDraw drivers using colour keys has an implicit cost

    // only do this if we're using colour key and not a clipper
    if (m_bColourKey) {
        return ShowColourKeyOverlay();
    }
    return TRUE;
}



// When a DirectDraw object is created we allocate a RGB triplet for us to
// use for any colour keys we need. However that RGB values isn't the same
// as the RGB value that is represented in the frame buffer once the colour
// key has been painted. We therefore lock the primary surface and get the
// actual pixel value out of the frame buffer. We can then use this to pass
// to DirectDraw as the real colour key. By doing this we take into account
// the mapping between the logical RGB value and what actually gets drawn

COLORREF CDirectDraw::GetRealKeyColour()
{
    NOTE("Entering GetRealKeyColour");
    DDSURFACEDESC SurfaceDesc;
    COLORREF RealColour;
    HDC hdc;

    // Get a screen device context

    HRESULT hr = m_pDrawPrimary->GetDC(&hdc);
    if (FAILED(hr)) {
        NOTE("No screen HDC");
        return INFINITE;
    }

    // Set the colour key and then read it back

    COLORREF CurrentPixel = GetPixel(hdc,0,0);
    SetPixel(hdc,0,0,m_KeyColour);
    EXECUTE_ASSERT(GdiFlush());
    m_pDrawPrimary->ReleaseDC(hdc);
    SurfaceDesc.dwSize = sizeof(DDSURFACEDESC);

    hr = m_pDrawPrimary->Lock((RECT *) NULL,    // Lock all the surface
                              &SurfaceDesc,     // Surface description
                              DDLOCK_WAIT,      // Poll until available
                              (HANDLE) NULL);   // No event to signal
    if (FAILED(hr)) {
        NOTE("Lock failed");
        return INFINITE;
    }

    // Read the pixel value and knock off any extraneous bits

    RealColour = *(DWORD *) SurfaceDesc.lpSurface;
    DWORD Depth = SurfaceDesc.ddpfPixelFormat.dwRGBBitCount;
    if (SurfaceDesc.ddpfPixelFormat.dwRGBBitCount < 32) {
        RealColour &= ((1 << Depth) - 1);
    }
    m_pDrawPrimary->Unlock(SurfaceDesc.lpSurface);

    // Reset the pixel value we tested with

    if (m_pDrawPrimary->GetDC(&hdc) == DD_OK) {
        SetPixel(hdc,0,0,CurrentPixel);
        m_pDrawPrimary->ReleaseDC(hdc);
    }
    return RealColour;
}


// Called once the overlay has been shown and we detect a that the window has
// become complex clipped to try and switch to using a colour key. We get a
// colour to use from our shared memory block although that does not specify
// what colour really got painted. To this end we read the pixel from the top
// left hand corner of the video playback area and use that as the colour key
// If setting a colour fails then we must repaint the window background black

BOOL CDirectDraw::ShowColourKeyOverlay()
{
    NOTE("Entering ShowColourKeyOverlay");
    CAutoLock cVideoLock(this);
    HRESULT hr = NOERROR;

    // Are we already using a colour key

    if (m_bUsingColourKey == TRUE) {
        return TRUE;
    }

    // Check we can go ahead and install a colour key

    if (m_bColourKey == FALSE || m_bColourKeyPending == TRUE ||
            m_pOverlaySurface == NULL ||
                m_bWindowLock == TRUE) {
                    return FALSE;
    }

    // Have the colour key background painted

    m_bUsingColourKey = TRUE;
    OnPaint(NULL);
    WaitForFlipStatus();

    // Can we get a real colour key value

    COLORREF KeyColour = GetRealKeyColour();
    if (KeyColour == INFINITE) {
        return FALSE;
    }

    DDCOLORKEY DDColorKey = { KeyColour,0 };

    // Tell the primary surface what to expect

    //DbgLog((LOG_TRACE,3,TEXT("Setting our colour key now")));
    hr = m_pDrawPrimary->SetColorKey(DDCKEY_DESTOVERLAY,&DDColorKey);
    if (FAILED(hr)) {
        NOTE("SetColorKey failed");
        OnColourKeyFailure();
        return FALSE;
    }

    // Update the overlay with the colour key enabled flag

    //DbgLog((LOG_TRACE,1,TEXT("ShowColourKeyOverlay is SHOWing the overlay!")));
    hr = m_pOverlaySurface->UpdateOverlay(&m_SourceClipRect,  // Video source
                                          m_pDrawPrimary,     // Main surface
                                          &m_TargetClipRect,  // Sink position
                                          DDOVER_KEYDEST |    // A colour key
                                          DDOVER_SHOW,        // Show overlay
                                          NULL);              // No effects
    ASSERT_FLIP_COMPLETE(hr);

    if (FAILED(hr)) {
        NOTE("UpdateOverlay failed");
        OnColourKeyFailure();
        return FALSE;
    }

    return TRUE;
}


// Some display cards say they can do overlay colour keying but when put to
// the test fail it with DDERR_NOCOLORKEYHW. The Cirrus 5440 is an example
// of this as it can only colour key when it is stretched (typically by two)
// When we get a colour key failure we set the overlay pending and disable
// DirectDraw, when we subsequently set the surface as enabled we check the
// DDCAPS_COLOURKEY and enable colour keys again. By doing this every time
// we may do too much format switching - but we will always use colour keys

void CDirectDraw::OnColourKeyFailure()
{
    NOTE("Entering OnColourKeyFailure");
    m_bWindowLock = TRUE;
    m_bColourKeyPending = TRUE;

    // Repaint the window background

    if (m_bUsingColourKey) {
        NOTE("Colour key was set");
        m_bUsingColourKey = FALSE;
        OnPaint(NULL);
    }
}


// Lets people know if an overlay surface is visible and enabled. On S3 cards
// which have both MPEG decompression and DirectDraw the MPEG driver silently
// steals the overlay surface when the MPEG is started. This is ok when we're
// running because the surface lock will fail. However when paused or stopped
// we poll in here a few times a second to check the surface is still with us
// so we take this opportunity to hide the overlay and have a new sample sent

BOOL CDirectDraw::IsOverlayEnabled()
{
    NOTE("Entering IsOverlayEnabled");

    CAutoLock cVideoLock(this);
    if (m_bOverlayVisible == FALSE) {
        NOTE("Overlay invisible");
        return FALSE;
    }

    // Reset the size field in the DDSURFACEDESC structure

    ASSERT(m_pOverlaySurface);
    NOTE("Checking surface loss");
    DDSURFACEDESC SurfaceDesc;
    SurfaceDesc.dwSize = sizeof(DDSURFACEDESC);

    // Lock the surface to get the buffer pointer

    HRESULT hr = m_pOverlaySurface->Lock((RECT *) NULL,  // Target rectangle
                                         &SurfaceDesc,   // Return information
                                         DDLOCK_WAIT,    // Wait for surface
                                         (HANDLE) NULL); // Don't use event
    ASSERT_FLIP_COMPLETE(hr);

    // Is the surface otherwise engaged

    if (hr == DDERR_SURFACEBUSY) {
        NOTE("Surface is busy");
        HideOverlaySurface();
        return FALSE;
    }

    // Unlock the entire surface

    if (SUCCEEDED(hr)) {
        NOTE("Unlocking overlay surface");
        m_pOverlaySurface->Unlock(NULL);
    }
    return TRUE;
}


// Called during paused state transitions

BOOL CDirectDraw::IsOverlayComplete()
{
    NOTE("Entering IsOverlayComplete");

    CAutoLock cVideoLock(this);
    if (IsOverlayEnabled() == FALSE) {
        NOTE("Overlay not enabled");
        return FALSE;
    }
    return (m_bOverlayStale == TRUE ? FALSE : TRUE);
}


// Marks the overlay as being stale

void CDirectDraw::OverlayIsStale()
{
    NOTE("Overlay is stale");
    CAutoLock cVideoLock(this);

    // Make sure we continue to return surfaces

    if (IsOverlayEnabled() == TRUE) {
        m_bOverlayStale = TRUE;
    }
}


// Hides any overlay surface we are using - also reset the m_bOverlayVisible
// flag we keep so that everyone will know the overlay is hidden (hence the
// locking of our critical section just to be safe). We can be called dumbly
// even if we are not using overlays at all just to keep our code simple

BOOL CDirectDraw::HideOverlaySurface()
{
    NOTE("Entering HideOverlaySurface");
    CAutoLock cVideoLock(this);

    // Is the overlay already hidden

    if (m_bOverlayVisible == FALSE) {
        return TRUE;
    }

    // Reset our state and draw a normal background

    ASSERT(m_pOverlaySurface);
    m_bUsingColourKey = FALSE;
    m_bOverlayVisible = FALSE;
    BlankDestination();
    WaitForFlipStatus();

    // Hide the overlay with the DDOVER_HIDE flag

    //DbgLog((LOG_TRACE,1,TEXT("HIDEing the overlay")));
    m_pOverlaySurface->UpdateOverlay(NULL,  // Video source
                                     m_pDrawPrimary,     // Main surface
                                     NULL,  		 // Sink position
                                     DDOVER_HIDE,      	 // Hide overlay
                                     NULL);              // No other effects

    return TRUE;
}


// If this is a normal uncompressed DIB format then set the size of the image
// as usual with the DIBSIZE macro. Otherwise the DIB specification says that
// the width of the image will be set in the width as a count of bytes so we
// just multiply that by the absolute height to get the total number of bytes
// This trickery is all handled by a utility function in the SDK base classes

void CDirectDraw::SetSurfaceSize(VIDEOINFO *pVideoInfo)
{
    NOTE("Entering SetSurfaceSize");

    BITMAPINFOHEADER *pHeader = HEADER(pVideoInfo);
    pVideoInfo->bmiHeader.biSizeImage = GetBitmapSize(pHeader);
    m_cbSurfaceSize = pVideoInfo->bmiHeader.biSizeImage;
}


// Initialise our output type based on the DirectDraw surface. As DirectDraw
// only deals with top down display devices so we must convert the height of
// the surface returned in the DDSURFACEDESC into a negative height. This is
// because DIBs use a positive height to indicate a bottom up image. We also
// initialise the other VIDEOINFO fields in the same way as for DCI access

BOOL CDirectDraw::InitDrawFormat(LPDIRECTDRAWSURFACE pSurface)
{
    COLORKEY ColourKey;
    NOTE("Entering InitDrawFormat");

    m_pRenderer->m_Overlay.InitDefaultColourKey(&ColourKey);
    m_KeyColour = ColourKey.LowColorValue;

    VIDEOINFO *pVideoInfo = (VIDEOINFO *) m_SurfaceFormat.Format();
    DDSURFACEDESC SurfaceDesc;
    SurfaceDesc.dwSize = sizeof(DDSURFACEDESC);

    // Ask the surface for a description

    HRESULT hr = pSurface->GetSurfaceDesc(&SurfaceDesc);
    if (FAILED(hr)) {
        NOTE("GetSurfaceDesc failed");
        return FALSE;
    }

    ASSERT(SurfaceDesc.ddpfPixelFormat.dwRGBBitCount);

    // Convert a DDSURFACEDESC into a BITMAPINFOHEADER (see notes later). The
    // bit depth of the surface can be retrieved from the DDPIXELFORMAT field
    // in the DDSURFACEDESC. The documentation is a little misleading because
    // it says the field is permutations of DDBD_*'s however in this case the
    // field is initialised by DirectDraw to be the actual surface bit depth

    pVideoInfo->bmiHeader.biSize          = sizeof(BITMAPINFOHEADER);
    pVideoInfo->bmiHeader.biWidth         = SurfaceDesc.lPitch * 8;

    // For some weird reason if the format is not a standard bit depth the
    // width field in the BITMAPINFOHEADER should be set to the number of
    // bytes instead of the width in pixels. This supports odd YUV formats
    // like IF09 which uses 9bpp (the /= 8 cancels out the above multiply)

    int bpp = SurfaceDesc.ddpfPixelFormat.dwRGBBitCount;
    if (bpp == 8 || bpp == 16 || bpp == 24 || bpp == 32)
        pVideoInfo->bmiHeader.biWidth     /= bpp;
    else
        pVideoInfo->bmiHeader.biWidth     /= 8;

    pVideoInfo->bmiHeader.biHeight        = -((LONG) SurfaceDesc.dwHeight);
    pVideoInfo->bmiHeader.biPlanes        = 1;
    pVideoInfo->bmiHeader.biBitCount      = (USHORT) SurfaceDesc.ddpfPixelFormat.dwRGBBitCount;
    pVideoInfo->bmiHeader.biCompression   = SurfaceDesc.ddpfPixelFormat.dwFourCC;
    pVideoInfo->bmiHeader.biXPelsPerMeter = 0;
    pVideoInfo->bmiHeader.biYPelsPerMeter = 0;
    pVideoInfo->bmiHeader.biClrUsed       = 0;
    pVideoInfo->bmiHeader.biClrImportant  = 0;

    SetSurfaceSize(pVideoInfo);

    // For true colour RGB formats tell the source there are bit fields

    if (pVideoInfo->bmiHeader.biCompression == BI_RGB) {
        if (pVideoInfo->bmiHeader.biBitCount == 16 ||
            pVideoInfo->bmiHeader.biBitCount == 32) {
                pVideoInfo->bmiHeader.biCompression = BI_BITFIELDS;
        }
    }

    // The RGB bit fields are in the same place as for YUV formats

    if (pVideoInfo->bmiHeader.biCompression != BI_RGB) {
        pVideoInfo->dwBitMasks[0] = SurfaceDesc.ddpfPixelFormat.dwRBitMask;
        pVideoInfo->dwBitMasks[1] = SurfaceDesc.ddpfPixelFormat.dwGBitMask;
        pVideoInfo->dwBitMasks[2] = SurfaceDesc.ddpfPixelFormat.dwBBitMask;
    }

    // Complete the rest of the VIDEOINFO fields

    SetRectEmpty(&pVideoInfo->rcSource);
    SetRectEmpty(&pVideoInfo->rcTarget);
    pVideoInfo->dwBitRate = 0;
    pVideoInfo->dwBitErrorRate = 0;
    pVideoInfo->AvgTimePerFrame = 0;

    // And finish it off with the other media type fields

    const GUID SubTypeGUID = GetBitmapSubtype(&pVideoInfo->bmiHeader);
    m_SurfaceFormat.SetSampleSize(pVideoInfo->bmiHeader.biSizeImage);
    m_SurfaceFormat.SetType(&MEDIATYPE_Video);
    m_SurfaceFormat.SetSubtype(&SubTypeGUID);
    m_SurfaceFormat.SetTemporalCompression(FALSE);
    m_SurfaceFormat.SetFormatType(&FORMAT_VideoInfo);

    return TRUE;
}


// Initialise a video media type based on the DCI primary surface. We set all
// the VIDEOINFO fields as if the surface was a logical bitmap they draw to
// (which it is although it has some special properties). Some displays see
// the primary surface as a smaller viewport on larger physical bitmap so the
// stride they return is larger than the width, therefore we set the width to
// be the stride. We should also set the height negative if it is a top down
// display as DIBs think a positive height means a standard bottom up image

#define ABS(x) (x < 0 ? -x : x)


// Release any DirectDraw offscreen surface or DCI provider we are currently
// holding, we may be called at any time especially when something goes badly
// wrong and we need to clean up before returning, so we can't guarantee that
// our state is consistent so free only those that we have really allocated
// NOTE DirectDraw has a feature with flipping surfaces, GetAttachedSurface
// returns a DirectDraw surface interface that isn't AddRef'd, hence when we
// destroy all the surfaces we reset the interface instead of releasing it

void CDirectDraw::ReleaseSurfaces()
{
    NOTE("Entering ReleaseSurfaces");
    CAutoLock cVideoLock(this);
    WaitForFlipStatus();
    HideOverlaySurface();

    // Reset our internal surface state

    m_bColourKey = FALSE;
    m_SurfaceType = AMDDS_NONE;
    m_cbSurfaceSize = 0;
    m_bWindowLock = TRUE;
    m_bOverlayStale = FALSE;
    m_bColourKeyPending = FALSE;
    m_bTripleBuffered = FALSE;

    // Release any interfaces we obtained

    if (m_pOffScreenSurface) m_pOffScreenSurface->Release();
    if (m_pOverlaySurface) m_pOverlaySurface->Release();
    if (m_pDrawClipper) m_pDrawClipper->Release();
    if (m_pOvlyClipper) m_pOvlyClipper->Release();

    // Reset them so we don't release them again

    m_pOverlaySurface = NULL;
    m_pBackBuffer = NULL;
    m_pOffScreenSurface = NULL;
    m_pDrawClipper = NULL;
    m_pOvlyClipper = NULL;
}


// Called to release any DirectDraw provider we previously loaded. We may be
// called at any time especially when something goes horribly wrong and when
// we need to clean up before returning so we can't guarantee that all state
// variables are consistent so free only those really allocated. After we've
// initialised DirectDraw during CompleteConnect we keep the driver instance
// around along with a primary surface until we are disconnected. All other
// surfaces including DCI are allocated and freed in sync with the allocator

void CDirectDraw::ReleaseDirectDraw()
{
    NOTE("Entering ReleaseDirectDraw");
    CAutoLock cVideoLock(this);
    SetSurfacePending(FALSE);

    // Release the DirectDraw primary surface

    if (m_pDrawPrimary) {
        NOTE("Releasing primary");
        m_pDrawPrimary->Release();
        m_pDrawPrimary = NULL;
    }

    // Release any DirectDraw provider interface

    if (m_pDirectDraw) {
        NOTE("Releasing DirectDraw");
        m_pDirectDraw->Release();
        m_pDirectDraw = NULL;
    }
    m_LoadDirectDraw.ReleaseDirectDraw();
    //DbgLog((LOG_TRACE,1,TEXT("RELEASING m_pDirectDraw")));
}


// DirectDraw 1.0 can only be loaded once per process, attempts to load it a
// second time return DDERR_DIRECTDRAWALREADYCREATED. We typically have a
// filter graph full of independant objects controlled by an application all
// of which may want to make use of DirectDraw. Therefore this is a serious
// restriction for us. To load DirectDraw we use a helper class in the SDK
// that manages loading and unloading the library and creating the instances

BOOL CDirectDraw::LoadDirectDraw()
{
    NOTE("Entering LoadDirectDraw");
    HRESULT hr = NOERROR;

    // Is DirectDraw already loaded

    if (m_pDirectDraw) {
        NOTE("Loaded");
        return TRUE;
    }

    // Ask the loader to create an instance of DirectDraw using hardware for
    // whichever monitor the window is on (for a multi monitor system)
    // For good ol' Win95, it'll use normal DDraw
    hr = m_LoadDirectDraw.LoadDirectDraw(m_pRenderer->m_achMonitor);
    if (FAILED(hr)) {
        NOTE("No DirectDraw");
        return FALSE;
    }

    // Get the IDirectDraw instance

    m_pDirectDraw = m_LoadDirectDraw.GetDirectDraw();
    //DbgLog((LOG_TRACE,1,TEXT("m_pDirectDraw = %x"), m_pDirectDraw));
    if (m_pDirectDraw == NULL) {
        NOTE("No instance");
        return FALSE;
    }

    // we must be loaded to get the real version
    m_DirectDrawVersion1 = m_LoadDirectDraw.IsDirectDrawVersion1();

    return TRUE;
}


// This function loads the DirectDraw DLL dynamically, this is so the video
// renderer can still be loaded and executed where DirectDraw is unavailable
// We use the DirectDraw plug in distributor that the filtergraph implements
// and then having successfully loaded and initialised the DLL we ask it for
// an IDirectDraw interface with which we query it's capabilities and then
// subsequently create a primary surface as all DirectDraw operations use it

BOOL CDirectDraw::InitDirectDraw(BOOL fIOverlay)
{
    NOTE("Entering InitDirectDraw");
    ASSERT(m_pDirectDraw == NULL);
    ASSERT(m_pDrawPrimary == NULL);

    // Check we are allowed to load DirectDraw

    if (m_bIniEnabled == FALSE || m_Switches == AMDDS_NONE) {
        return FALSE;
    }

    // We may have initialised m_pDirectDraw from an IDirectDraw interface
    // we have been provided with externally from an application. In that
    // case we simply AddRef the interface (to allow for the Release we do
    // in ReleaseDirectDraw) and then try to create a primary surface. We
    // will also set cooperation levels on the driver that could conflict
    // with one already set so we check for an error DDERR_HWNDALREADYSET

    if (m_pOutsideDirectDraw) {
        m_pDirectDraw = m_pOutsideDirectDraw;
        NOTE("Using external DirectDraw");
        m_pDirectDraw->AddRef();
    }

    // Try to load DirectDraw if not already done so

    if (LoadDirectDraw() == FALSE) {
        return FALSE;
    }

    // Initialise our capabilities structures

    ASSERT(m_pDirectDraw);
    m_DirectCaps.dwSize = sizeof(DDCAPS);
    m_DirectSoftCaps.dwSize = sizeof(DDCAPS);

    // Load the hardware and emulation capabilities

    HRESULT hr = m_pDirectDraw->GetCaps(&m_DirectCaps,&m_DirectSoftCaps);
    //
    // If we are connected through IOverlay we just need the clipper.
    // The clipper does not depend on any DDraw h/w.
    //
    if (FAILED(hr) || ((m_DirectCaps.dwCaps & DDCAPS_NOHARDWARE) && !fIOverlay)) {
        NOTE("No hardware");
        ReleaseDirectDraw();
        return FALSE;
    }

    // Set the cooperation level on the surface to be shared

    HWND hwnd = m_pRenderer->m_VideoWindow.GetWindowHWND();
    hr = m_pDirectDraw->SetCooperativeLevel(hwnd,DDSCL_NORMAL);
    if (FAILED(hr)) {
        NOTE("Level failed");
        ReleaseDirectDraw();
        return FALSE;
    }

    // Initialise the primary surface descriptor
    if (!fIOverlay) {

        DDSURFACEDESC SurfaceDesc;
        SurfaceDesc.dwSize = sizeof(DDSURFACEDESC);
        SurfaceDesc.dwFlags = DDSD_CAPS;
        SurfaceDesc.ddsCaps.dwCaps = DDSCAPS_PRIMARYSURFACE;

        hr = m_pDirectDraw->CreateSurface(&SurfaceDesc,&m_pDrawPrimary,NULL);
        if (FAILED(hr)) {
            NOTE("No DD primary");
            ReleaseDirectDraw();
            return FALSE;
        }
    }
    return TRUE;
}



// When we get a DirectDraw error we don't disable all use of the surfaces as
// the error could be caused by any number of obscure reasons, examples being
// we are running in a fullscreen DOS box, we might have asked for an overlay
// to be stretched to much or too little and so on. Therefore we set a flag
// m_bSurfacePending that inhibits the surface being used until the window is
// next updated (ie either the source or destination rectangles are altered)

void CDirectDraw::SetSurfacePending(BOOL bPending)
{
    NOTE("Entering SetSurfacePending");
    m_bSurfacePending = bPending;

    // Can we enable colour keys again

    if (m_bSurfacePending == FALSE) {
        if (m_DirectCaps.dwCaps & DDCAPS_COLORKEY) {
            if (m_pOverlaySurface) {
                m_bColourKeyPending = FALSE;
            }
        }
    }
}


// Return the current surface pending flag

BOOL CDirectDraw::IsSurfacePending()
{
    return m_bSurfacePending;
}


// Update the current destination rectangle

void CDirectDraw::SetTargetRect(RECT *pTargetRect)
{
    NOTE("Entering SetTargetRect");
    ASSERT(pTargetRect);
    CAutoLock cVideoLock(this);
    m_TargetRect = *pTargetRect;
}


// Update the current source rectangle

void CDirectDraw::SetSourceRect(RECT *pSourceRect)
{
    NOTE("Entering SetSourceRect");
    ASSERT(pSourceRect);
    CAutoLock cVideoLock(this);
    m_SourceRect = *pSourceRect;
}


// Create an offscreen RGB drawing surface. This is very similar to the code
// required to create an overlay surface although I keep it separate so that
// it is simpler to change and therefore for them to diverge in the future
// At the moment the only difference is setting the DDSURFACEDESC dwCaps to
// DDSCAPS_OFFSCREENPLAIN instead of overlay although we still ask it to be
// placed in video memory, the surface is returned in m_pOffScreenSurface

BOOL CDirectDraw::CreateRGBOffScreen(CMediaType *pmtIn)
{
    NOTE("Entering CreateRGBOffScreen");
    ASSERT(m_bIniEnabled == TRUE);
    ASSERT(m_pDrawPrimary);
    DDSURFACEDESC SurfaceDesc;
    HRESULT hr = NOERROR;

    // Can this display driver handle drawing in hardware

    if ((m_DirectCaps.dwCaps & DDCAPS_BLT) == 0) {
        NOTE("No DDCAPS_BLT");
        return FALSE;
    }

    // Check the format is acceptable to the renderer

    hr = m_pRenderer->m_Display.CheckMediaType(pmtIn);
    if (FAILED(hr)) {
        NOTE("CheckMediaType failed");
        return FALSE;
    }

    // Set the surface description of the offscreen

    SurfaceDesc.dwSize = sizeof(DDSURFACEDESC);
    SurfaceDesc.dwFlags = DDSD_CAPS |
                          DDSD_HEIGHT |
                          DDSD_WIDTH |
                          DDSD_PIXELFORMAT;

    VIDEOINFO *pVideoInfo = (VIDEOINFO *) pmtIn->Format();
    BITMAPINFOHEADER *pHeader = HEADER(pVideoInfo);
    SurfaceDesc.dwHeight = pHeader->biHeight;
    SurfaceDesc.dwWidth = pHeader->biWidth;
    SurfaceDesc.ddsCaps.dwCaps = DDSCAPS_OFFSCREENPLAIN | DDSCAPS_VIDEOMEMORY;

    // Store the masks in the DDSURFACEDESC

    SurfaceDesc.ddpfPixelFormat.dwSize = sizeof(DDPIXELFORMAT);
    SurfaceDesc.ddpfPixelFormat.dwRGBBitCount = pHeader->biBitCount;
    SurfaceDesc.ddpfPixelFormat.dwFourCC = BI_RGB;
    SurfaceDesc.ddpfPixelFormat.dwFlags = DDPF_RGB;
    const DWORD *pBitMasks = m_pRenderer->m_Display.GetBitMasks(pVideoInfo);
    SurfaceDesc.ddpfPixelFormat.dwRBitMask = pBitMasks[0];
    SurfaceDesc.ddpfPixelFormat.dwGBitMask = pBitMasks[1];
    SurfaceDesc.ddpfPixelFormat.dwBBitMask = pBitMasks[2];

    // ATI seems to want this to be 0
    SurfaceDesc.ddpfPixelFormat.dwRGBAlphaBitMask = 0;

    // Create the offscreen drawing surface

    hr = m_pDirectDraw->CreateSurface(&SurfaceDesc,&m_pOffScreenSurface,NULL);
    if (FAILED(hr)) {
        NOTE("No surface");
        return FALSE;
    }
    return InitOffScreenSurface(pmtIn,FALSE);
}


// Create an offscreen YUV drawing surface. This is very similar to the code
// required to create an overlay surface although I keep it separate so that
// it is simpler to change and therefore for them to diverge in the future
// At the moment the only difference is setting the DDSURFACEDESC dwCaps to
// DDSCAPS_OFFSCREENPLAIN instead of overlay although we still ask it to be
// placed in video memory, the surface is returned in m_pOffScreenSurface

BOOL CDirectDraw::CreateYUVOffScreen(CMediaType *pmtIn)
{
    NOTE("Entering CreateYUVOffScreen");
    ASSERT(m_bIniEnabled == TRUE);
    ASSERT(m_pDrawPrimary);
    DDSURFACEDESC SurfaceDesc;
    HRESULT hr = NOERROR;

    // Can this display driver handle drawing in hardware

    if ((m_DirectCaps.dwCaps & DDCAPS_BLTFOURCC) == 0) {
        NOTE("No DDCAPS_BLTFOURCC");
        return FALSE;
    }

    // Set the surface description of the offscreen

    SurfaceDesc.dwSize = sizeof(DDSURFACEDESC);
    SurfaceDesc.dwFlags = DDSD_CAPS |
                          DDSD_HEIGHT |
                          DDSD_WIDTH |
                          DDSD_PIXELFORMAT;

    VIDEOINFO *pVideoInfo = (VIDEOINFO *) pmtIn->Format();
    BITMAPINFOHEADER *pHeader = HEADER(pVideoInfo);
    SurfaceDesc.dwHeight = pHeader->biHeight;
    SurfaceDesc.dwWidth = pHeader->biWidth;
    SurfaceDesc.ddsCaps.dwCaps = DDSCAPS_OFFSCREENPLAIN | DDSCAPS_VIDEOMEMORY;

    SurfaceDesc.ddpfPixelFormat.dwSize = sizeof(DDPIXELFORMAT);
    SurfaceDesc.ddpfPixelFormat.dwFourCC = pHeader->biCompression;
    SurfaceDesc.ddpfPixelFormat.dwFlags = DDPF_FOURCC;
    SurfaceDesc.ddpfPixelFormat.dwYUVBitCount = pHeader->biBitCount;

    // Create the offscreen overlay surface

    hr = m_pDirectDraw->CreateSurface(&SurfaceDesc,&m_pOffScreenSurface,NULL);
    if (FAILED(hr)) {
        NOTE("No surface");
        return FALSE;
    }
    return InitOffScreenSurface(pmtIn,FALSE);
}


// This creates a RGB overlay surface for doing the drawing. To use these we
// require a true colour type to be supplied and also a DirectDraw primary
// surface to act as the overlay target. The data we put on the overlay does
// not touch the frame buffer but is merged on the way to the display when a
// vertical refresh is done (which typically occur some 60 times a second)

BOOL CDirectDraw::CreateRGBOverlay(CMediaType *pmtIn)
{
    NOTE("Entering CreateRGBOverlay");
    DDSURFACEDESC SurfaceDesc;
    HRESULT hr = NOERROR;

    // Standard overlay creation tests

    if (CheckCreateOverlay() == FALSE) {
        NOTE("No overlays");
        return FALSE;
    }

    // Set the surface description of the overlay

    SurfaceDesc.dwSize = sizeof(DDSURFACEDESC);
    SurfaceDesc.dwFlags = DDSD_CAPS |
                          DDSD_HEIGHT |
                          DDSD_WIDTH |
                          DDSD_PIXELFORMAT;

    VIDEOINFO *pVideoInfo = (VIDEOINFO *) pmtIn->Format();
    BITMAPINFOHEADER *pHeader = HEADER(pVideoInfo);
    SurfaceDesc.ddsCaps.dwCaps = DDSCAPS_OVERLAY | DDSCAPS_VIDEOMEMORY;
    SurfaceDesc.dwHeight = pHeader->biHeight;
    SurfaceDesc.dwWidth = pHeader->biWidth;

    SurfaceDesc.ddpfPixelFormat.dwSize = sizeof(DDPIXELFORMAT);
    SurfaceDesc.ddpfPixelFormat.dwFourCC = BI_RGB;
    SurfaceDesc.ddpfPixelFormat.dwFlags = DDPF_RGB;
    SurfaceDesc.ddpfPixelFormat.dwRGBBitCount = pHeader->biBitCount;

    // Store the masks in the DDSURFACEDESC

    const DWORD *pBitMasks = m_pRenderer->m_Display.GetBitMasks(pVideoInfo);
    SurfaceDesc.ddpfPixelFormat.dwRBitMask = pBitMasks[0];
    SurfaceDesc.ddpfPixelFormat.dwGBitMask = pBitMasks[1];
    SurfaceDesc.ddpfPixelFormat.dwBBitMask = pBitMasks[2];

    // ATI seems to want this to be 0
    SurfaceDesc.ddpfPixelFormat.dwRGBAlphaBitMask = 0;

    // Create the offscreen overlay surface

    hr = m_pDirectDraw->CreateSurface(&SurfaceDesc,&m_pOverlaySurface,NULL);
    if (FAILED(hr)) {
        NOTE("No surface");
        return FALSE;
    }
    return InitOffScreenSurface(pmtIn,FALSE);
}


// This creates a non RGB overlay surface. We must be supplied with a format
// that has the FOURCC code set in the biCompression field in the header. We
// also require a primary surface to act as the overlay target. This surface
// type is vital for doing MPEG colour conversions efficiently (such as YUV
// to RGB). The data we put on the overlay does not touch the frame buffer
// but is merged on the way to the display when a vertical refresh is done

BOOL CDirectDraw::CreateYUVOverlay(CMediaType *pmtIn)
{
    NOTE("Entering CreateYUVOverlay");
    DDSURFACEDESC SurfaceDesc;
    HRESULT hr = NOERROR;

    // Standard overlay creation tests

    if (CheckCreateOverlay() == FALSE) {
        NOTE("No overlays");
        return FALSE;
    }

    // Set the surface description of the overlay

    SurfaceDesc.dwSize = sizeof(DDSURFACEDESC);
    SurfaceDesc.dwFlags = DDSD_CAPS |
                          DDSD_HEIGHT |
                          DDSD_WIDTH |
                          DDSD_PIXELFORMAT;

    VIDEOINFO *pVideoInfo = (VIDEOINFO *) pmtIn->Format();
    BITMAPINFOHEADER *pHeader = HEADER(pVideoInfo);
    SurfaceDesc.ddsCaps.dwCaps = DDSCAPS_OVERLAY | DDSCAPS_VIDEOMEMORY;
    SurfaceDesc.dwHeight = pHeader->biHeight;
    SurfaceDesc.dwWidth = pHeader->biWidth;

    SurfaceDesc.ddpfPixelFormat.dwSize = sizeof(DDPIXELFORMAT);
    SurfaceDesc.ddpfPixelFormat.dwFourCC = pHeader->biCompression;
    SurfaceDesc.ddpfPixelFormat.dwFlags = DDPF_FOURCC;
    SurfaceDesc.ddpfPixelFormat.dwYUVBitCount = pHeader->biBitCount;

    // Create the offscreen overlay surface

    hr = m_pDirectDraw->CreateSurface(&SurfaceDesc,&m_pOverlaySurface,NULL);
    if (FAILED(hr)) {
        NOTE("No surface");
        return FALSE;
    }
    return InitOffScreenSurface(pmtIn,FALSE);
}


// Create a set of three flipping surfaces. Flipping surfaces comprise an
// overlay front buffer which is just a normal overlay surface, backed up
// with two further offscreen surfaces in video memory. While the overlay
// is visible we will decompress into a back offscreen buffer and flip it
// to the front when completed. The flip happens after the vertical blank
// which guarantees it won't tear since the scan line isn't anywhere near

BOOL CDirectDraw::CreateRGBFlipping(CMediaType *pmtIn)
{
    NOTE("Entering CreateRGBFlipping");
    DDSURFACEDESC SurfaceDesc;
    HRESULT hr = NOERROR;

    // Standard overlay creation tests

    if (CheckCreateOverlay() == FALSE) {
        NOTE("No overlays");
        return FALSE;
    }

    // Set the surface description of the overlay

    SurfaceDesc.dwSize = sizeof(DDSURFACEDESC);
    SurfaceDesc.dwFlags = DDSD_CAPS |
                          DDSD_HEIGHT |
                          DDSD_WIDTH |
                          DDSD_PIXELFORMAT |
                          DDSD_BACKBUFFERCOUNT;

    VIDEOINFO *pVideoInfo = (VIDEOINFO *) pmtIn->Format();
    BITMAPINFOHEADER *pHeader = HEADER(pVideoInfo);
    SurfaceDesc.dwHeight = pHeader->biHeight;
    SurfaceDesc.dwWidth = pHeader->biWidth;
    SurfaceDesc.dwBackBufferCount = 2;

    SurfaceDesc.ddsCaps.dwCaps = DDSCAPS_OVERLAY |
                                 DDSCAPS_VIDEOMEMORY |
                                 DDSCAPS_FLIP |
                                 DDSCAPS_COMPLEX;

    SurfaceDesc.ddpfPixelFormat.dwSize = sizeof(DDPIXELFORMAT);
    SurfaceDesc.ddpfPixelFormat.dwFourCC = BI_RGB;
    SurfaceDesc.ddpfPixelFormat.dwFlags = DDPF_RGB;
    SurfaceDesc.ddpfPixelFormat.dwRGBBitCount = pHeader->biBitCount;

    // Store the masks in the DDSURFACEDESC

    const DWORD *pBitMasks = m_pRenderer->m_Display.GetBitMasks(pVideoInfo);
    SurfaceDesc.ddpfPixelFormat.dwRBitMask = pBitMasks[0];
    SurfaceDesc.ddpfPixelFormat.dwGBitMask = pBitMasks[1];
    SurfaceDesc.ddpfPixelFormat.dwBBitMask = pBitMasks[2];

    // ATI seems to want this to be 0
    SurfaceDesc.ddpfPixelFormat.dwRGBAlphaBitMask = 0;


    // Create the offscreen overlay surface

    hr = m_pDirectDraw->CreateSurface(&SurfaceDesc,&m_pOverlaySurface,NULL);
    if (hr == DDERR_OUTOFVIDEOMEMORY) {
        SurfaceDesc.dwBackBufferCount = 1;
        hr = m_pDirectDraw->CreateSurface(&SurfaceDesc,&m_pOverlaySurface,NULL);
    }

    // General error processing now

    if (FAILED(hr)) {
        NOTE("No surface");
        return FALSE;
    }

    // Have we got triple buffered overlays

    m_bTripleBuffered = FALSE;
    if (SurfaceDesc.dwBackBufferCount == 2) {
        m_bTripleBuffered = TRUE;
    }
    return InitOffScreenSurface(pmtIn,TRUE);
}


// Create a set of three flipping surfaces. Flipping surfaces comprise an
// overlay front buffer which is just a normal overlay surface, backed up
// with two further offscreen surfaces in video memory. While the overlay
// is visible we will decompress into a back offscreen buffer and flip it
// to the front when completed. The flip happens after the vertical blank
// which guarantees it won't tear since the scan line isn't anywhere near

BOOL CDirectDraw::CreateYUVFlipping(CMediaType *pmtIn)
{
    NOTE("Entering CreateYUVFlipping");
    DDSURFACEDESC SurfaceDesc;
    HRESULT hr = NOERROR;

    // Standard overlay creation tests

    if (CheckCreateOverlay() == FALSE) {
        NOTE("No overlays");
        return FALSE;
    }

    VIDEOINFO * const pVideoInfo = (VIDEOINFO *) pmtIn->Format();
    BITMAPINFOHEADER * const pHeader = HEADER(pVideoInfo);

    // Don't flip for motion compensation surfaces
    // This bypasses a bug in the current ATI Rage Pro driver
    if (pHeader->biCompression == MAKEFOURCC('M', 'C', '1', '2')) {
        NOTE("Don't flip for motion compensation surfaces");
        return FALSE;
    }

    // Set the surface description of the overlay

    SurfaceDesc.dwSize = sizeof(DDSURFACEDESC);
    SurfaceDesc.dwFlags = DDSD_CAPS |
                          DDSD_HEIGHT |
                          DDSD_WIDTH |
                          DDSD_PIXELFORMAT |
                          DDSD_BACKBUFFERCOUNT;

    SurfaceDesc.dwHeight = pHeader->biHeight;
    SurfaceDesc.dwWidth = pHeader->biWidth;
    SurfaceDesc.dwBackBufferCount = 2;

    SurfaceDesc.ddsCaps.dwCaps = DDSCAPS_OVERLAY |
                                 DDSCAPS_VIDEOMEMORY |
                                 DDSCAPS_FLIP |
                                 DDSCAPS_COMPLEX;

    SurfaceDesc.ddpfPixelFormat.dwSize = sizeof(DDPIXELFORMAT);
    SurfaceDesc.ddpfPixelFormat.dwFourCC = pHeader->biCompression;
    SurfaceDesc.ddpfPixelFormat.dwFlags = DDPF_FOURCC;
    SurfaceDesc.ddpfPixelFormat.dwYUVBitCount = pHeader->biBitCount;

    // Create the offscreen overlay surface

    hr = m_pDirectDraw->CreateSurface(&SurfaceDesc,&m_pOverlaySurface,NULL);
    if (hr == DDERR_OUTOFVIDEOMEMORY) {
        SurfaceDesc.dwBackBufferCount = 1;
        hr = m_pDirectDraw->CreateSurface(&SurfaceDesc,&m_pOverlaySurface,NULL);
    }

    // General error processing now

    if (FAILED(hr)) {
        NOTE("No surface");
        return FALSE;
    }

    // Have we got triple buffered overlays

    m_bTripleBuffered = FALSE;
    if (SurfaceDesc.dwBackBufferCount == 2) {
        m_bTripleBuffered = TRUE;
    }
    return InitOffScreenSurface(pmtIn,TRUE);
}


// Store the current clipped rectangles for the surface. We set all surfaces
// with empty source and target clipping rectangles. When initially created
// the clipped rectangles will be all zero. These will be updated when the
// allocator next calls UpdateSurface.

BOOL CDirectDraw::InitOnScreenSurface(CMediaType *pmtIn)
{
    NOTE("Entering InitOnScreenSurface");
    VIDEOINFO *pOutput = (VIDEOINFO *) m_SurfaceFormat.Format();
    VIDEOINFO *pInput = (VIDEOINFO *) pmtIn->Format();
    pOutput->rcSource = m_SourceClipRect;
    pOutput->rcTarget = m_TargetClipRect;

    ASSERT(m_pOverlaySurface == NULL);
    ASSERT(m_pBackBuffer == NULL);
    ASSERT(m_pDrawPrimary);
    ASSERT(m_pOffScreenSurface == NULL);

    // Is this a palettised format

    if (PALETTISED(pOutput) == FALSE) {
        return TRUE;
    }

    // pInput and pOutput should either be both paletized formats or
    // unpaletized formats.  However, it's possible the two formats
    // can differ.  For more information, see bug 151387 - "STRESS:
    // XCUH: unhandled exception hit in T3Call.exe" in the Windows
    // Bugs database.
    if (PALETTISED(pInput) == FALSE) {
        return FALSE;
    }

    // The number of colours may default to zero

    pOutput->bmiHeader.biClrUsed = pInput->bmiHeader.biClrUsed;
    if (pOutput->bmiHeader.biClrUsed == 0) {
        DWORD Maximum  = (1 << pOutput->bmiHeader.biBitCount);
        NOTE1("Setting maximum colours (%d)",Maximum);
        pOutput->bmiHeader.biClrUsed = Maximum;
    }

    // Copy the palette entries into the surface format

    ASSERT(pOutput->bmiHeader.biClrUsed <= iPALETTE_COLORS);
    LONG Bytes = pOutput->bmiHeader.biClrUsed * sizeof(RGBQUAD);
    CopyMemory(pOutput->bmiColors,pInput->bmiColors,Bytes);

    return TRUE;
}


// Handle some of the tedium to do with overlay and page flipped surfaces. We
// are passed in a flag that says if the surfaces created were page flipping
// If they are then we need the backbuffer interface to acts as the source in
// BltFast operations and also for the Flip calls. If anything fails we will
// release any surfaces created and return FALSE, otherwise we'll return TRUE

BOOL CDirectDraw::InitOffScreenSurface(CMediaType *pmtIn,BOOL bPageFlipped)
{
    NOTE("Entering InitOverlaySurface");
    ASSERT(m_bIniEnabled == TRUE);
    ASSERT(m_pDrawPrimary);
    HRESULT hr = NOERROR;


    // Either an overlay or an offscreen surface

    IDirectDrawSurface *pSurface = m_pOverlaySurface;
    if (m_pOverlaySurface == NULL) {
        pSurface = m_pOffScreenSurface;
        ASSERT(m_pOffScreenSurface);
        ASSERT(bPageFlipped == FALSE);
    }

#ifdef DEBUG
    DDSURFACEDESC ddsd;
    ddsd.dwSize = sizeof(ddsd);
    pSurface->GetSurfaceDesc(&ddsd);
    if (!(ddsd.ddsCaps.dwCaps & DDSCAPS_VIDEOMEMORY)) {
        DbgLog((LOG_TRACE, 0, TEXT("Surface is non-video memory")));
    }
#endif

    // Initialise a media type describing our output format

    if (InitDrawFormat(pSurface) == FALSE) {
        ReleaseSurfaces();
        return FALSE;
    }

    // Go in search of the backbuffer

    if (bPageFlipped == TRUE) {
        ASSERT(m_pBackBuffer == NULL);
        DDSCAPS SurfaceCaps;
        SurfaceCaps.dwCaps = DDSCAPS_BACKBUFFER;

        // Get the normal back buffer surface

        hr = pSurface->GetAttachedSurface(&SurfaceCaps,&m_pBackBuffer);
        if (FAILED(hr)) {
            ReleaseSurfaces();
            return FALSE;
        }
    }

    NOTE("Preparing source and destination rectangles");
    VIDEOINFO *pOutput = (VIDEOINFO *) m_SurfaceFormat.Format();
    VIDEOINFO *pInput = (VIDEOINFO *) pmtIn->Format();

    // Initialise the source and destination rectangles

    pOutput->rcSource.left = 0; pOutput->rcSource.top = 0;
    pOutput->rcSource.right = pInput->bmiHeader.biWidth;
    pOutput->rcSource.bottom = pInput->bmiHeader.biHeight;
    pOutput->rcTarget.left = 0; pOutput->rcTarget.top = 0;
    pOutput->rcTarget.right = pInput->bmiHeader.biWidth;
    pOutput->rcTarget.bottom = pInput->bmiHeader.biHeight;

    ClipPrepare(pSurface);

    // Is this a palettised format

    if (PALETTISED(pOutput) == FALSE) {
        NOTE("No palette");
        return TRUE;
    }

    // pInput and pOutput should either be both paletized formats or
    // unpaletized formats.  However, it's possible the two formats
    // can differ.  For more information, see bug 151387 - "STRESS:
    // XCUH: unhandled exception hit in T3Call.exe" in the Windows
    // Bugs database.
    if (PALETTISED(pInput) == FALSE) {
        return FALSE;
    }

    // It could be an eight bit YUV format

    if (pOutput->bmiHeader.biCompression) {
        NOTE("Not BI_RGB type");
        return FALSE;
    }

    ASSERT(m_pOverlaySurface == NULL);
    ASSERT(m_pBackBuffer == NULL);
    ASSERT(bPageFlipped == FALSE);
    ASSERT(m_pOffScreenSurface);

    // The number of colours may default to zero

    pOutput->bmiHeader.biClrUsed = pInput->bmiHeader.biClrUsed;
    if (pOutput->bmiHeader.biClrUsed == 0) {
        DWORD Maximum  = (1 << pOutput->bmiHeader.biBitCount);
        NOTE1("Setting maximum colours (%d)",Maximum);
        pOutput->bmiHeader.biClrUsed = Maximum;
    }

    // Copy the palette entries into the surface format

    ASSERT(pOutput->bmiHeader.biClrUsed <= iPALETTE_COLORS);
    LONG Bytes = pOutput->bmiHeader.biClrUsed * sizeof(RGBQUAD);
    CopyMemory(pOutput->bmiColors,pInput->bmiColors,Bytes);

    return TRUE;
}


// Check we can create an overlay surface (also applies to flipping surfaces)
// We check the display hardware has overlay capabilities (it's difficult to
// see how they could be emulated). We also check that the current number of
// visible overlays hasn't been exceeded otherwise we will fail when it comes
// to showing it later, so we would rather pick a different surface up front

BOOL CDirectDraw::CheckCreateOverlay()
{
    NOTE("Entering CheckCreateOverlay");
    ASSERT(m_bIniEnabled == TRUE);
    ASSERT(m_pDrawPrimary);

    // Can this display driver handle overlay in hardware, if it cannot then
    // there is little point in using this as it may end up with the driver
    // doing a software colour conversion which could be better done by the
    // source filter (such as in band during the real video decompression)

    if ((m_DirectCaps.dwCaps & DDCAPS_OVERLAY) == 0) {
        NOTE("No DDCAPS_OVERLAY");
        return FALSE;
    }

    // Don't reload the caps as we update them internally, for example if
    // we fail trying to use a colour key we take off the DDCAPS_COLORKEY
    // flags from the DDCAPS we store. Therefore when we retrieve them we
    // bring them into local storage to check the visible overlays count

    DDCAPS DDCaps,DDECaps;
    DDCaps.dwSize = sizeof(DDCAPS);
    DDECaps.dwSize = sizeof(DDCAPS);
    m_pDirectDraw->GetCaps(&DDCaps,&DDECaps);

    // Do we have maximum number of overlays already

    if (DDCaps.dwCurrVisibleOverlays >= DDCaps.dwMaxVisibleOverlays) {
        NOTE("No overlays left");
        return FALSE;
    }
    return TRUE;
}


// After we have allocated and initialised our DirectDraw surface we try and
// set it up so that should we become clipped we can carry on using it. For
// this to happen we have two options, firstly install an IDirectDrawClipper
// for the surface so that DirectDraw will handle the clipping rectangles.
// Otherwise we'll try and install a colour key which lets the hardware know
// where to place the video. Failing both of those we return FALSE, in which
// case we should still use the surface although if and when we do become
// clipped we will have to switch back to using normal memory based DIBs

BOOL CDirectDraw::ClipPrepare(LPDIRECTDRAWSURFACE pSurface)
{
    NOTE("Entering ClipPrepare");

    // First of all try and create a clipper

    if (InitialiseClipper(pSurface) && !m_pOverlaySurface) {
        NOTE("Clipper");
        return TRUE;
    }

    // Failing that try and use a colour key

    if (InitialiseColourKey(pSurface)) {
        NOTE("Colour key");
        return TRUE;
    }
    return FALSE;
}


// This checks that the hardware is capable of supporting colour keys and if
// so allocates the next available colour. The next colour is obtained from
// the hook module because it looks after the shared memory block we create.
// The shared memory block is used so that overlays in different processes
// do not conflict with the same colour (especially when they overlap). We
// set the m_bColourKey flag to TRUE if we plan on using a colour key. Note
// however that we do not start using colour keys until we become clipped

BOOL CDirectDraw::InitialiseColourKey(LPDIRECTDRAWSURFACE pSurface)
{
    NOTE("Entering InitialiseColourKey");

    ASSERT(m_bUsingColourKey == FALSE);
    ASSERT(m_bColourKey == FALSE);
    ASSERT(m_pDirectDraw);
    ASSERT(pSurface);

    // Can the overlay/blting hardware do the clipping

    if (m_DirectCaps.dwCaps & DDCAPS_COLORKEY) {
        if (m_pOverlaySurface) {
            NOTE("DDCAPS_COLORKEY on");
            m_bColourKey = TRUE;
            return TRUE;
        }
    }
    return FALSE;
}


// Create a clipper interface and attach it to the surface. DirectDraw says
// that a clipper may be attached to both offscreen and overlay surfaces so
// we'll try regardless. If we cannot create a clipper or fail to attach it
// correctly then we still go ahead but just swap away from DirectDraw when
// the window becomes complex clipped. We return TRUE if we found a clipper
// and initialised it correctly, otherwise we return FALSE as the calling
// code may be able to install a colour key instead if we become clipped

BOOL CDirectDraw::InitialiseClipper(LPDIRECTDRAWSURFACE pSurface)
{
    NOTE("Entering InitialiseClipper");

    ASSERT(m_bUsingColourKey == FALSE);
    ASSERT(m_bColourKey == FALSE);
    ASSERT(m_pDrawClipper == NULL);
    ASSERT(m_pDirectDraw);
    ASSERT(pSurface);

    // DirectDraw can be difecult sometimes, for example an overlay surface may
    // not support clipping. So you would think the surface would reject the
    // SetClipper call below, but oh no you have check a capabilities flag
    // in the DDCAPS structure which depends on the type of surface in use.
    // For offscreen surfaces (only) DirectDraw will emulate clipping by only
    // sending the rectangles that are really required down to the driver

    DDSURFACEDESC SurfaceDesc;
    SurfaceDesc.dwSize = sizeof(DDSURFACEDESC);
    HWND hwnd = m_pRenderer->m_VideoWindow.GetWindowHWND();

    // Ask the surface for a description

    HRESULT hr = pSurface->GetSurfaceDesc(&SurfaceDesc);
    if (FAILED(hr)) {
        NOTE("No description");
        return FALSE;
    }

    // Can the overlay hardware do the clipping

    if (SurfaceDesc.ddsCaps.dwCaps & DDSCAPS_OVERLAY) {
        if (m_DirectCaps.dwCaps & DDCAPS_OVERLAYCANTCLIP) {
            NOTE("DDSCAPS_OVERLAY/DDCAPS_OVERLAYCANTCLIP");
            return FALSE;
        }
    }

    // Create the IDirectDrawClipper interface

    hr = m_pDirectDraw->CreateClipper((DWORD)0,&m_pDrawClipper,NULL);
    if (FAILED(hr)) {
        NOTE("No clipper");
        return FALSE;
    }

    // Give the clipper the video window handle

    hr = m_pDrawClipper->SetHWnd((DWORD)0,hwnd);
    if (SUCCEEDED(hr)) {
        hr = m_pDrawPrimary->SetClipper(m_pDrawClipper);
        if (SUCCEEDED(hr)) {
            NOTE("Set clipper");
            return TRUE;
        }
    }

    // Release the clipper object

    m_pDrawClipper->Release();
    m_pDrawClipper = NULL;
    return FALSE;
}


// This is called when the window gets a WM_PAINT message. The IMediaSample we
// are handed may or may not be NULL depending whether or not the window has
// an image waiting to be drawn. We return TRUE if we handle the paint call or
// FALSE if someone else must do the work. If we are using flipping or overlay
// surfaces then we have nothing to do but we will have handled the paint

BOOL CDirectDraw::OnPaint(IMediaSample *pMediaSample)
{
    NOTE("Entering OnPaint");
    CAutoLock cVideoLock(this);

    // Assuming we get through the following check we will know that we have
    // either an offscreen, overlay or flipping surface. If it's an offscreen
    // surface then we try to draw it again, it that fails we return FALSE,
    // otherwise we return TRUE to say it was handled correctly. If we have a
    // flipping surface then if it hasn't been flipped yet we do so and make
    // sure the overlay is made visible. If for any reason this can't be done
    // (perhaps the window is complex clipped) then we also return FALSE.
    //
    // If we have an overlay surface and it's visible then we blank out the
    // background underneath the overlay (which we also do when handling the
    // flipping surfaces), we then return TRUE as it was handled correctly.
    // If the overlay was not visible we know that the sample interface will
    // be NULL (as they are never passed through to the window object) so we
    // drop through to the bottom and also return FALSE from this method.
    //
    // Returning FALSE when we're not streaming may eventually have the window
    // object send an EC_REPAINT to the filter graph, this has the whole graph
    // stopped and paused again. The stop has the worker threads returned to
    // their filters, the pause has them send a new frame again. And that time
    // through we get another chance to return a different kind of buffer


    FillBlankAreas();

    // Fill the video background

    if (m_bOverlayVisible == TRUE) {
        // Paint the colour key if necessary
        BOOL bFormatChanged;
        if (UpdateSurface(bFormatChanged) == NULL) {
            return FALSE;
        }

        COLORREF WindowColour = VIDEO_COLOUR;
        if (m_bUsingColourKey == TRUE) {
            NOTE("Using colour key");
            WindowColour = m_KeyColour;
        }
        DrawColourKey(WindowColour);
        if (m_pBackBuffer == NULL) {
            NOTE("No flip");
            return TRUE;
        }
    }

    // Do we have a valid surface to draw

    if (m_pBackBuffer == NULL) {
        if (m_pOffScreenSurface == NULL) {
            NOTE("No offscreen");
            return FALSE;
        }
    }

    // Do we have an image to render

    if (pMediaSample == NULL) {
        NOTE("No sample to draw");
        return m_bOverlayVisible;
    }
    return DrawImage(pMediaSample);
}


// This is used to paint overlay colour keys. We are called when we receive
// WM_PAINT messages although we do not use any device context obtained via
// BeginPaint. The area we fill is the clipped screen area calculated in a
// previous call to UpdateSurface and includes any alignment losses we have
// The clipped area must first be converted into client window coordinates

void CDirectDraw::DrawColourKey(COLORREF WindowColour)
{
    NOTE("Entering DrawColourKey");

    // Draw the current destination rectangle
    HDC hdc = m_pRenderer->m_VideoWindow.GetWindowHDC();
    HWND hwnd = m_pRenderer->m_VideoWindow.GetWindowHWND();
    RECT BlankRect = m_TargetClipRect;
    // translate from device to screen co-ordinates
    BlankRect.left += m_pRenderer->m_rcMonitor.left;
    BlankRect.top += m_pRenderer->m_rcMonitor.top;
    BlankRect.right += m_pRenderer->m_rcMonitor.left;
    BlankRect.bottom += m_pRenderer->m_rcMonitor.top;
    MapWindowPoints((HWND) NULL,hwnd,(LPPOINT) &BlankRect,(UINT) 2);
    COLORREF BackColour = SetBkColor(hdc,WindowColour);
    ExtTextOut(hdc,0,0,ETO_OPAQUE,&BlankRect,NULL,0,NULL);
    SetBkColor(hdc,BackColour);
}


// This is called when we hide overlay surfaces so that we can blank out in
// black the entire target rectangle. We cannot use DrawColourKey for this
// because it only draws on the clipped display area which doesn't include
// sections of video dropped from the left and right for alignment reasons

void CDirectDraw::BlankDestination()
{
    NOTE("Entering BlankDestination");

    // Blank out the current destination rectangle

    HDC hdc = m_pRenderer->m_VideoWindow.GetWindowHDC();
    HWND hwnd = m_pRenderer->m_VideoWindow.GetWindowHWND();
    COLORREF BackColour = SetBkColor(hdc,VIDEO_COLOUR);
    ExtTextOut(hdc,0,0,ETO_OPAQUE,&m_TargetRect,NULL,0,NULL);
    SetBkColor(hdc,BackColour);
}


// Flip the back buffer to bring it to the front. We cannot call DrawImage
// more than once for each flipping surface sample otherwise we will flip
// the previous image back to the front again. Therefore WM_PAINT messages
// have to be handled very carefully (review the OnPaint method). If the
// flip fails then it is more likely that a hard error has occured so we
// will disable DirectDraw until it's enabled by a subsequent state change

BOOL CDirectDraw::DoFlipSurfaces(IMediaSample *pMediaSample)
{
    NOTE("Entering DoFlipSurfaces");
    ASSERT(m_pOverlaySurface);
    HRESULT hr = NOERROR;
    CVideoSample *pVideoSample;

    // Have we already flipped this surface

    pVideoSample = (CVideoSample *) pMediaSample;
    if (pVideoSample->GetDrawStatus() == FALSE) {
        NOTE("(Already flipped)");
        return m_bOverlayVisible;
    }

    pVideoSample->SetDrawStatus(FALSE);

    // Flip the back buffer to the visible primary

    hr = DDERR_WASSTILLDRAWING;
    while (hr == DDERR_WASSTILLDRAWING) {
        hr = m_pOverlaySurface->Flip(NULL,(DWORD) 0);
        if (hr == DDERR_WASSTILLDRAWING) {
            if (m_bTripleBuffered == FALSE) break;
            Sleep(DDGFS_FLIP_TIMEOUT);
        }
    }

    // If the flip didn't complete then we're ok

    if (hr == DDERR_WASSTILLDRAWING) {
        NOTE("Flip left pending");
        return ShowOverlaySurface();
    }

    // Is the surface otherwise engaged

    if (hr == DDERR_SURFACEBUSY) {
        NOTE("Surface is busy");
        HideOverlaySurface();
        StartUpdateTimer();
        return FALSE;
    }

    // Handle real DirectDraw errors

    if (FAILED(hr)) {
        NOTE("Flip failed");
        SetSurfacePending(TRUE);
        HideOverlaySurface();
        return FALSE;
    }
    return ShowOverlaySurface();
}


// Used to really draw an image that has been put on an offscreen or overlay
// flipping DirectDraw surface (either RGB or YUV). Overlay surfaces should
// already have been dealt with in the OnPaint method so we should only be
// here if we have an offscreen or flipping surfaces. The flipping surfaces
// are dealt with separately as they have to prepare the back buffer with
// the current contents but offscreen surfaces only need a sample blt call

BOOL CDirectDraw::DrawImage(IMediaSample *pMediaSample)
{
    ASSERT(m_pOffScreenSurface || m_pBackBuffer);
    CAutoLock cVideoLock(this);
    NOTE("Entering DrawImage");
    BOOL bFormatChanged;
    HRESULT hr = NOERROR;

    // Flip the overlay and update its position
    if (m_pBackBuffer) return DoFlipSurfaces(pMediaSample);

    // Check all is still well with the window

    if (UpdateSurface(bFormatChanged) == NULL) {
        NOTE("No draw");
        return FALSE;
    }

    FillBlankAreas();
    WaitForScanLine();

    // Draw the offscreen surface and wait for it to complete

//    DbgLog((LOG_TRACE,3,TEXT("BLT to (%d,%d,%d,%d)"),
//		m_TargetClipRect.left, m_TargetClipRect.top,
//		m_TargetClipRect.right, m_TargetClipRect.bottom));
    hr = m_pDrawPrimary->Blt(&m_TargetClipRect,     // Target rectangle
                             m_pOffScreenSurface,   // Source surface
                             &m_SourceClipRect,     // Source rectangle
                             DDBLT_WAIT,            // Wait to complete
                             NULL);                 // No effects flags

    // Is the surface otherwise engaged

    if (hr == DDERR_SURFACEBUSY) {
        NOTE("Surface is busy");
        StartUpdateTimer();
        return FALSE;
    }

    // Handle real DirectDraw errors

    if (FAILED(hr)) {
        SetSurfacePending(TRUE);
        return FALSE;
    }
    return TRUE;
}


// When we adjust the destination rectangle so that it is aligned according
// to the cruddy display hardware we can leave thin strips of exposed area
// down the left and right hand side. This function fills these areas with
// the current border colour (set through the IVideoWindow interface). The
// left/right sections lost are updated when the allocator or timer thread
// calls UpdateSurface which in turn will call our AlignRectangles method

BOOL CDirectDraw::FillBlankAreas()
{
    NOTE("Entering FillBlankAreas");
    RECT BlankRect;

    // Short circuit if nothing to do

    if (m_TargetLost == 0) {
        if (m_TargetWidthLost == 0) {
            NOTE("No fill");
            return TRUE;
        }
    }

    // Create a coloured brush to paint the window

    HDC hdc = m_pRenderer->m_VideoWindow.GetWindowHDC();
    HWND hwnd = m_pRenderer->m_VideoWindow.GetWindowHWND();
    COLORREF Colour = m_pRenderer->m_VideoWindow.GetBorderColour();
    COLORREF BackColour = SetBkColor(hdc,Colour);
    POINT WindowOffset = { m_TargetClipRect.left, m_TargetClipRect.top };
    ScreenToClient(hwnd,&WindowOffset);

    // Look after the left edge of exposed window

    BlankRect.left = WindowOffset.x - m_TargetLost;
    BlankRect.right = WindowOffset.x;
    BlankRect.top = WindowOffset.y;
    BlankRect.bottom = WindowOffset.y + HEIGHT(&m_TargetRect);
    if (m_TargetLost) ExtTextOut(hdc,0,0,ETO_OPAQUE,&BlankRect,NULL,0,NULL);

    // Now paint the strip down the right hand side

    BlankRect.left = WindowOffset.x + WIDTH(&m_TargetClipRect);
    BlankRect.right = BlankRect.left + m_TargetWidthLost;
    if (m_TargetWidthLost) ExtTextOut(hdc,0,0,ETO_OPAQUE,&BlankRect,NULL,0,NULL);

    // Flush the painted areas out

    EXECUTE_ASSERT(GdiFlush());
    SetBkColor(hdc,BackColour);
    return TRUE;
}


// When using overlay and flipping surfaces we have an update timer which is
// used to ensure that the overlay is always correctly positioned regardless
// of whether we are paused or stopped. This could also be useful when we're
// dealing with low frame rate movies (like MPEG arf arf) - in which case we
// might not get frames through often enough to update the overlay position

BOOL CDirectDraw::OnTimer()
{
    CAutoLock cVideoLock(this);
    NOTE("Entering OnTimer");
    CMediaType *pMediaType;
    BOOL bFormatChanged;

    // Ignore late WM_TIMER messages

    if (m_bTimerStarted == FALSE) {
        NOTE("Late timer");
        return TRUE;
    }

    // Is there an overlay surface to check

    if (m_bOverlayVisible == FALSE) {
        NOTE("Not visible");
        return TRUE;
    }

    // Check all is still well with the overlay

    if (IsOverlayEnabled() == FALSE) {
        NOTE("Not enabled");
        return FALSE;
    }

    // Is the window locked or the format changed

    pMediaType = UpdateSurface(bFormatChanged);
    if (pMediaType == NULL || bFormatChanged) {
        NOTE("Format changed");
        HideOverlaySurface();
        return FALSE;
    }
    return TRUE;
}


// When we see a DDERR_SURFACEBUSY error we start an update timer so that on
// one second periods we try and switch back into DirectDraw. By using the
// timer we can avoid polling on the surface which causes lots of expensive
// format changes. All we do is see if their is a surface change pending and
// if so we reset the flag and make sure next time through we change formats

BOOL CDirectDraw::OnUpdateTimer()
{
    NOTE("Entering OnUpdateTimer");
    CAutoLock cVideoLock(this);
    StopUpdateTimer();

    // Is there a surface change pending

    if (IsSurfacePending() == TRUE) {
        NOTE("Try surface again");
        SetSurfacePending(FALSE);
    }
    return TRUE;
}


// We need to know whether to synchronise on filling the buffer typically a
// primary surface or on the drawing operation as with a flipping surface.
// We return TRUE if we should sync on the fill otherwise we return FALSE.
// We use DCI and DirectDraw primary surfaces but they are handled the same.
//
//      Surface Type         SyncOnFill
//
//      Flipping                FALSE
//      OffScreen               FALSE
//      Overlay                 TRUE
//      Primary                 TRUE
//
// Flipping surfaces are just two overlay surfaces attached together, there
// is one being shown at any given time and another being used as a target
// for the source filter to decompress its next image onto. When we get the
// buffer back we swap the visible buffer and copy the current image across

BOOL CDirectDraw::SyncOnFill()
{
    NOTE("Entering SyncOnFill");
    CAutoLock cVideoLock(this);
    ASSERT(m_bIniEnabled == TRUE);

    if (m_pOffScreenSurface == NULL) {
        if (m_pBackBuffer == NULL) {
            NOTE("SyncOnFill");
            return TRUE;
        }
    }
    return FALSE;
}


// Return TRUE if we should hand out the current surface type in use when we
// are paused. This doesn't stop the renderer holding onto images stored in
// these surfaces as they may already have been delivered. But should we get
// an error subsequently drawing it (perhaps during a WM_PAINT message) then
// we may be able to stop it doing it again (and save wasted EC_REPAINTs)

BOOL CDirectDraw::AvailableWhenPaused()
{
    NOTE("Entering AvailableWhenPaused");

    // Do we have a clipper for any offscreen surface

    if (m_pOffScreenSurface) {
        if (m_pDrawClipper) {
            NOTE("Available");
            return TRUE;
        }
    }

    // Only supported on overlay surfaces

    if (m_pOverlaySurface) {
        NOTE("Overlay");
        return TRUE;
    }
    return FALSE;
}


// When we are paused or stopped we use a Windows timer to have our overlay
// position updated periodically. Our window thread passes on WM_TIMER's to
// our OnTimer method. When we are running we rely on the source calling us
// in Receive sufficiently often to be able to update the overlay while we
// en unlocking the DirectDraw surface. Note that we do NOT receive WM_TIMER
// messages while Windows is processing a window drag and move by the user
// so to try and use them while running for this is pointless (and wasteful)

void CDirectDraw::StartRefreshTimer()
{
    NOTE("Entering StartRefreshTimer");
    CAutoLock cVideoLock(this);

    if (m_pOverlaySurface) {
        if (m_bTimerStarted == FALSE) {
            ASSERT(m_pRenderer->m_InputPin.IsConnected() == TRUE);
            HWND hwnd = m_pRenderer->m_VideoWindow.GetWindowHWND();
            EXECUTE_ASSERT(SetTimer(hwnd,(UINT_PTR)hwnd,300,NULL));
            NOTE("Starting refresh timer");
            m_bTimerStarted = TRUE;
        }
    }
}


// Kill any update timer used to refresh the overlay position. I'm not sure
// that by the time we are asked to kill any outstanding timer that the DD
// surfaces have not been released (and m_pOverlaySurface is therefore NULL)
// To cover this possibility I simply always try to kill my timer regardless
// and ignore any failed return code. Note that the timer ID we identify our
// timer with matches the HWND (so we don't need to store the ID anywhere)

void CDirectDraw::StopRefreshTimer()
{
    NOTE("Entering StopRefreshTimer");
    CAutoLock cVideoLock(this);

    if (m_bTimerStarted == TRUE) {
        HWND hwnd = m_pRenderer->m_VideoWindow.GetWindowHWND();
        EXECUTE_ASSERT(KillTimer(hwnd,(UINT_PTR) hwnd));
        NOTE("Timer was killed");
        m_bTimerStarted = FALSE;
    }
}


// This is similar to the StartRefreshTime but is used completely differently
// When we get back a DDERR_SURFACEBUSY error from a DirectDraw call it is
// telling us that the screen is busy probably in a DOS box. In this case we
// don't want to only set the surface pending as we would have to wait for a
// window movement before switching back. Therefore we set a one second timer
// and when it triggers we try and force a format switch back into DirectDraw

void CDirectDraw::StartUpdateTimer()
{
    NOTE("Entering StartUpdateTimer");
    CAutoLock cVideoLock(this);
    SetSurfacePending(TRUE);

    // Start a timer with INFINITE as its identifier

    ASSERT(m_pRenderer->m_InputPin.IsConnected() == TRUE);
    HWND hwnd = m_pRenderer->m_VideoWindow.GetWindowHWND();
    EXECUTE_ASSERT(SetTimer(hwnd,INFINITE,1000,NULL));
}


// This complements the StartUpdateTimer method. We use this timer to try and
// periodically force ourselves back into DirectDraw if we detected a DOS box
// condition (something returned DDERR_SURFACEBUSY). When the timer fires we
// typically try and switch back and if it subsequently fails we just repeat
// the process by preparing another update timer for a second in the future

void CDirectDraw::StopUpdateTimer()
{
    NOTE("Entering StopUpdateTimer");
    CAutoLock cVideoLock(this);
    HWND hwnd = m_pRenderer->m_VideoWindow.GetWindowHWND();
    EXECUTE_ASSERT(KillTimer(hwnd,INFINITE));
}


// Return the maximum ideal image size taking into account DirectDraw. We are
// passed in the current video dimensions which we may update as appropriate.
// We only need to adjust the image dimensions if we have an overlay surface
// being used as DirectDraw may specify a minimum and maximum size to stretch
// The amount to stretch is dependant upon the display resolution being used
// For example on an S3 card at 800x600x16 it is typically x2 but on the same
// display card set to 640x480x16 it is x1 (ie no stretching required). This
// is because the stretching is a way of working around bandwidth limitations

HRESULT CDirectDraw::GetMaxIdealImageSize(long *pWidth,long *pHeight)
{
    NOTE("Entering GetMaxIdealImageSize");
    CAutoLock cVideoLock(this);

    // Should we always be used fullscreen

    if (m_bUseWhenFullScreen == TRUE) {
        NOTE("Force fullscreen");
        return S_FALSE;
    }

    // Some S3 cards (in particular the Vision968 chipset) cannot stretch
    // by more than four. However, DirectDraw offers no way to find this
    // limitation out so we just hardwire the top limit we're allowed to
    // stretch the video by when going from the offscreen to the primary

    if (m_DirectCaps.dwCaps & DDCAPS_BLTSTRETCH) {
    	if (m_pOffScreenSurface) {
            NOTE("Hardwiring limit to four");
            *pWidth <<= 2; *pHeight <<= 2;
            return NOERROR;
        }
    }

    // Have we allocated an overlay surface

    if (m_pOverlaySurface == NULL) {
        NOTE("No overlay");
        return NOERROR;
    }

    // Does this overlay have any requirements

    if (m_DirectCaps.dwMaxOverlayStretch == 0) {
        NOTE("No maximum stretch");
        return S_FALSE;
    }

    // Scale both dimensions to account for the requirements
    *pWidth = (*pWidth * m_DirectCaps.dwMaxOverlayStretch) / 1000;
    *pHeight = (*pHeight * m_DirectCaps.dwMaxOverlayStretch) / 1000;

    return NOERROR;
}


// Return the minimum ideal image size taking into account DirectDraw. We are
// passed in the current video dimensions which we may update as appropriate.
// We only need to adjust the image dimensions if we have an overlay surface
// being used as DirectDraw may specify a minimum and maximum size to stretch
// The amount to stretch is dependant upon the display resolution being used
// For example on an S3 card at 800x600x16 it is typically x2 but on the same
// display card set to 640x480x16 it is x1 (ie no stretching required). This
// is because the stretching is a way of working around bandwidth limitations

HRESULT CDirectDraw::GetMinIdealImageSize(long *pWidth,long *pHeight)
{
    NOTE("Entering GetMinIdealImageSize");
    CAutoLock cVideoLock(this);

    // Should we always be used fullscreen

    if (m_bUseWhenFullScreen == TRUE) {
        NOTE("Force fullscreen");
        return S_FALSE;
    }

    // Do we have a stretchable offscreen surface

    if (m_DirectCaps.dwCaps & DDCAPS_BLTSTRETCH) {
    	if (m_pOffScreenSurface) {
            NOTE("OffScreen stretch");
            return S_FALSE;
        }
    }

    // Have we allocated an overlay surface

    if (m_pOverlaySurface == NULL) {
        NOTE("No overlay");
        return NOERROR;
    }

    // Does this overlay have any requirements

    if (m_DirectCaps.dwMinOverlayStretch == 0) {
        NOTE("No minimum stretch");
        return S_FALSE;
    }

    // Scale both dimensions to account for the requirements

    *pWidth = (*pWidth * m_DirectCaps.dwMinOverlayStretch) / 1000;
    *pHeight = (*pHeight * m_DirectCaps.dwMinOverlayStretch) / 1000;
    return NOERROR;
}


// Return the current switches

STDMETHODIMP CDirectDraw::GetSwitches(DWORD *pSwitches)
{
    NOTE("Entering GetSwitches");

    // Do the usual checking and locking stuff

    CheckPointer(pSwitches,E_POINTER);
    CAutoLock cVideoLock(m_pInterfaceLock);
    CAutoLock cInterfaceLock(this);

    ASSERT(pSwitches);
    *pSwitches = m_Switches;
    return NOERROR;
}


// Set the surface types we can use

STDMETHODIMP CDirectDraw::SetSwitches(DWORD Switches)
{
    NOTE("Entering SetSwitches");

    CAutoLock cVideoLock(m_pInterfaceLock);
    CAutoLock cInterfaceLock(this);
    m_Switches = Switches;

    // Indicate we may already have a surface

    if (m_pRenderer->m_InputPin.IsConnected() == TRUE) {
        return S_FALSE;
    }
    return NOERROR;
}


// Return the capabilities of the hardware

STDMETHODIMP CDirectDraw::GetCaps(DDCAPS *pCaps)
{
    NOTE("Entering GetCaps");

    // Do the usual checking and locking stuff

    CheckPointer(pCaps,E_POINTER);
    CAutoLock cVideoLock(m_pInterfaceLock);
    CAutoLock cInterfaceLock(this);

    // Do we have DirectDraw loaded

    if (m_pDirectDraw == NULL) {
        return E_FAIL;
    }
    *pCaps = m_DirectCaps;
    return NOERROR;
}


// Return the software emulated capabilities

STDMETHODIMP CDirectDraw::GetEmulatedCaps(DDCAPS *pCaps)
{
    NOTE("Entering GetEmulatedCaps");

    // Do the usual checking and locking stuff

    CheckPointer(pCaps,E_POINTER);
    CAutoLock cVideoLock(m_pInterfaceLock);
    CAutoLock cInterfaceLock(this);

    // Do we have DirectDraw loaded

    if (m_pDirectDraw == NULL) {
        return E_FAIL;
    }
    *pCaps = m_DirectSoftCaps;
    return NOERROR;
}


// Return the capabilities of the current surface

STDMETHODIMP CDirectDraw::GetSurfaceDesc(DDSURFACEDESC *pSurfaceDesc)
{
    NOTE("Entering GetSurfaceDesc");
    CheckPointer(pSurfaceDesc,E_POINTER);
    CAutoLock cVideoLock(m_pInterfaceLock);
    CAutoLock cInterfaceLock(this);


    // Do we have any DirectDraw surface

    if (m_pDrawPrimary == NULL) {
        return E_FAIL;
    }

    pSurfaceDesc->dwSize = sizeof(DDSURFACEDESC);

    // Set the DirectDraw surface we are using

    LPDIRECTDRAWSURFACE pDrawSurface = GetDirectDrawSurface();
    if (pDrawSurface == NULL) {
        pDrawSurface = m_pDrawPrimary;
    }
    return pDrawSurface->GetSurfaceDesc(pSurfaceDesc);
}


// Return the FOURCC codes our provider supplies

STDMETHODIMP CDirectDraw::GetFourCCCodes(DWORD *pCount,DWORD *pCodes)
{
    NOTE("Entering GetFourCCCodes");
    CheckPointer(pCount,E_POINTER);
    CAutoLock cVideoLock(m_pInterfaceLock);
    CAutoLock cInterfaceLock(this);

    // Do we have a DirectDraw object

    if (m_pDirectDraw == NULL) {
        return E_FAIL;
    }
    return m_pDirectDraw->GetFourCCCodes(pCount,pCodes);
}


// This allows an application to set the DirectDraw instance we should use
// We provide this because DirectDraw only allows one instance of it to be
// opened per process, therefore an application (such as a game) would call
// this if it wants us to be able to use DirectDraw simultaneously. We hold
// the reference counted interface until destroyed or until called with a
// NULL or different interface. Calling this may not release the interface
// completely as there might still be surfaces allocated that depend on it

STDMETHODIMP CDirectDraw::SetDirectDraw(LPDIRECTDRAW pDirectDraw)
{
    NOTE("Entering SetDirectDraw");
    CAutoLock cVideoLock(m_pInterfaceLock);
    CAutoLock cInterfaceLock(this);

    // Should we release the current driver

    if (m_pOutsideDirectDraw) {
        NOTE("Releasing outer DirectDraw");
        m_pOutsideDirectDraw->Release();
        m_pOutsideDirectDraw = NULL;
    }

    // Do we have a replacement driver

    if (pDirectDraw == NULL) {
        NOTE("No driver");
        return NOERROR;
    }

    // Store a reference counted interface

    m_pOutsideDirectDraw = pDirectDraw;
    m_pOutsideDirectDraw->AddRef();
    return NOERROR;
}


// Set the current switch settings as the default

STDMETHODIMP CDirectDraw::SetDefault()
{
    NOTE("Entering SetDefault");

    CAutoLock cVideoLock(m_pInterfaceLock);
    CAutoLock cInterfaceLock(this);
    TCHAR Profile[PROFILESTR];

    // Store the current DirectDraw switches

    wsprintf(Profile,TEXT("%d"),m_Switches);
    WriteProfileString(TEXT("DrawDib"),SWITCHES,Profile);
    wsprintf(Profile,TEXT("%d"),m_bCanUseScanLine);
    WriteProfileString(TEXT("DrawDib"),SCANLINE,Profile);
    wsprintf(Profile,TEXT("%d"),m_bCanUseOverlayStretch);
    WriteProfileString(TEXT("DrawDib"),STRETCH,Profile);
    wsprintf(Profile,TEXT("%d"),m_bUseWhenFullScreen);
    WriteProfileString(TEXT("DrawDib"),FULLSCREEN,Profile);

    return NOERROR;
}


// Return the IDirectDraw interface we are currently using - with a reference
// count added as is usual when returning COM interfaces. If we are not using
// DirectDraw at the moment but have been provided with an IDirectDraw driver
// interface to use then we will return that (also suitably AddRef'd). If we
// are not using DirectDraw and also no outside driver then we return NULL

STDMETHODIMP CDirectDraw::GetDirectDraw(LPDIRECTDRAW *ppDirectDraw)
{
    NOTE("Entering GetDirectDraw");

    // Do the usual checking and locking stuff

    CheckPointer(ppDirectDraw,E_POINTER);
    CAutoLock cVideoLock(m_pInterfaceLock);
    CAutoLock cInterfaceLock(this);

    // Are we using an externally provided interface

    if (m_pOutsideDirectDraw) {
        NOTE("Returning outer DirectDraw");
        *ppDirectDraw = m_pOutsideDirectDraw;
        m_pOutsideDirectDraw->AddRef();
        return NOERROR;
    }

    // Fill in the DirectDraw driver interface

    *ppDirectDraw = m_pDirectDraw;
    if (m_pDirectDraw) {
        NOTE("Reference counting");
        m_pDirectDraw->AddRef();
    }
    return NOERROR;
}


// Returns the current surface type

STDMETHODIMP CDirectDraw::GetSurfaceType(DWORD *pSurfaceType)
{
    NOTE("Entering GetSurfaceType");

    // Do the usual checking and locking stuff

    CheckPointer(pSurfaceType,E_POINTER);
    CAutoLock cVideoLock(m_pInterfaceLock);
    CAutoLock cInterfaceLock(this);

    *pSurfaceType = m_SurfaceType;
    return NOERROR;
}


// Tells if we are allowed to use the current scan line property when doing
// draw calls from offscreen surfaces. On some machines using the scan line
// can reduce tearing but at the expense of performance in frames delivered
// We therefore allow the user to decide on their preferences through here

STDMETHODIMP CDirectDraw::UseScanLine(long UseScanLine)
{
    NOTE("Entering UseScanLine");
    CAutoLock cVideoLock(m_pInterfaceLock);
    CAutoLock cInterfaceLock(this);

    // Check this is a valid automation boolean type

    if (UseScanLine != OATRUE) {
        if (UseScanLine != OAFALSE) {
            return E_INVALIDARG;
        }
    }
    m_bCanUseScanLine = (UseScanLine == OATRUE ? TRUE : FALSE);
    return NOERROR;
}


// Return whether or not we would use the current scan line

STDMETHODIMP CDirectDraw::CanUseScanLine(long *UseScanLine)
{
    CheckPointer(UseScanLine,E_POINTER);
    NOTE("Entering CanUseScanLine");
    CAutoLock Lock(this);
    *UseScanLine = (m_bCanUseScanLine ? OATRUE : OAFALSE);
    return NOERROR;
}


// We normally honout the minimum and maximum overlay stretching limitations
// that the driver reports, however on some displays they are not reported
// entirely accurately which often leads us to not use YUV overlays when we
// could be (which in turn makes us look worse than the competition). So we
// allow applications to change our default behaviour when checking overlays

STDMETHODIMP CDirectDraw::UseOverlayStretch(long UseOverlayStretch)
{
    NOTE("Entering UseOverlayStretch");
    CAutoLock cVideoLock(m_pInterfaceLock);
    CAutoLock cInterfaceLock(this);

    // Check this is a valid automation boolean type

    if (UseOverlayStretch != OATRUE) {
        if (UseOverlayStretch != OAFALSE) {
            return E_INVALIDARG;
        }
    }
    m_bCanUseOverlayStretch = (UseOverlayStretch == OATRUE ? TRUE : FALSE);
    return NOERROR;
}


// Return whether or not we honour the overlay stretching limits

STDMETHODIMP CDirectDraw::CanUseOverlayStretch(long *UseOverlayStretch)
{
    CheckPointer(UseOverlayStretch,E_POINTER);
    NOTE("Entering CanUseOverlayStretch");
    CAutoLock Lock(this);
    *UseOverlayStretch = (m_bCanUseOverlayStretch ? OATRUE : OAFALSE);
    return NOERROR;
}


// Allow applications to always use the window in fullscreen mode

STDMETHODIMP CDirectDraw::UseWhenFullScreen(long UseWhenFullScreen)
{
    NOTE("Entering UseWhenFullScreen");
    CAutoLock cVideoLock(m_pInterfaceLock);
    CAutoLock cInterfaceLock(this);

    // Check this is a valid automation boolean type

    if (UseWhenFullScreen != OATRUE) {
        if (UseWhenFullScreen != OAFALSE) {
            return E_INVALIDARG;
        }
    }
    m_bUseWhenFullScreen = (UseWhenFullScreen == OATRUE ? TRUE : FALSE);
    return NOERROR;
}


// Return S_OK if we will force ourselves to be used fullscreen

STDMETHODIMP CDirectDraw::WillUseFullScreen(long *UseFullScreen)
{
    CheckPointer(UseFullScreen,E_POINTER);
    NOTE("Entering WillUseFullScreen");
    CAutoLock Lock(this);
    *UseFullScreen = (m_bUseWhenFullScreen ? OATRUE : OAFALSE);
    return NOERROR;
}


LPDIRECTDRAWCLIPPER CDirectDraw::GetOverlayClipper()
{
    CAutoLock cVideoLock(this);
    HRESULT hr;

    if (m_pOvlyClipper == NULL) {
        hr = m_pDirectDraw->CreateClipper(0, &m_pOvlyClipper, NULL);
        if (FAILED(hr) ) {
            m_pOvlyClipper = NULL;
        }
    }

    return m_pOvlyClipper;
}
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\multimedia\dshow\filters\image\video\image.h ===
// Copyright (c) 1994 - 1999  Microsoft Corporation.  All Rights Reserved.
// Defines the main COM renderer object, Anthony Phillips, January 1995

#ifndef __IMAGE__
#define __IMAGE__


extern const AMOVIESETUP_FILTER sudVideoFilter;

// This class supports the renderer input pin. This class has three principle
// things to do. The first is to pass on to the main renderer object calls to
// things like CheckMediaType, and to process other calls like SetMediaType
// and CompleteConnect. It also routes calls to Receive to either the main
// object or the DirectDraw object depending what type of sample it was given
// The last thing it must also do it so handle the flushing and end of stream
// calls that the source filter makes on us, it also hands these on to the
// main object since this is where the samples are queued and then rendered

class CVideoInputPin :
    public CRendererInputPin,
    public IPinConnection
{
    CRenderer   *m_pRenderer;           // The renderer that owns us
    CBaseFilter *m_pFilter;             // The filter we are owned by
    CCritSec    *m_pInterfaceLock;      // Main renderer interface lock

public:
        DECLARE_IUNKNOWN;

    // Constructor

    CVideoInputPin(CRenderer *pRenderer,       // Used to delegate locking
                   CCritSec *pLock,            // Object to use for lock
                   HRESULT *phr,               // OLE failure return code
                   LPCWSTR pPinName);          // This pins identification

    // Overriden to say what interfaces we support and where
    STDMETHODIMP NonDelegatingQueryInterface(REFIID, void **);

    // Override ReceiveConnection to update the monitor and display info
    STDMETHODIMP ReceiveConnection(
        IPin * pConnector,      // this is the pin who we will connect to
        const AM_MEDIA_TYPE *pmt    // this is the media type we will exchange
    );

    // Manage our DirectDraw/DIB video allocator

    STDMETHODIMP GetAllocator(IMemAllocator **ppAllocator);
    STDMETHODIMP NotifyAllocator(IMemAllocator *pAllocator,BOOL bReadOnly);

    // Returns the pin currently connected to us
    IPin *GetPeerPin() {
        return m_Connected;
    };

    //  IPinConnection stuff
    //  Do you accept this type chane in your current state?
    STDMETHODIMP DynamicQueryAccept(const AM_MEDIA_TYPE *pmt);

    //  Set event when EndOfStream receive - do NOT pass it on
    //  This condition is cancelled by a flush or Stop
    STDMETHODIMP NotifyEndOfStream(HANDLE hNotifyEvent);

    //  Are you an 'end pin'
    STDMETHODIMP IsEndPin();

    STDMETHODIMP DynamicDisconnect();
};


// This is overriden from the base draw class to change the source rectangle
// that we do the drawing with. For example a renderer may ask a decoder to
// stretch the video from 320x240 to 640x480, in which case the rectangle we
// see in here will still be 320x240, although the source we really want to
// draw with should be scaled up to 640x480. The base class implementation of
// this method does nothing but return the same rectangle as it is passed in

class CDrawVideo : public CDrawImage
{
    CRenderer *m_pRenderer;

public:
    CDrawVideo(CRenderer *pRenderer,CBaseWindow *pBaseWindow);
    RECT ScaleSourceRect(const RECT *pSource);
};


// This is the COM object that represents a simple rendering filter. It
// supports IBaseFilter and IMediaFilter and a single input stream (pin)
// The classes that support these interfaces have nested scope NOTE the
// nested class objects are passed a pointer to their owning renderer
// when they are created but they should not use it during construction

class CRenderer :
    public ISpecifyPropertyPages,
    public CBaseVideoRenderer,
    public IKsPropertySet,
    public IDrawVideoImage
{
public:

    DECLARE_IUNKNOWN

    // Constructor and destructor

    CRenderer(TCHAR *pName,LPUNKNOWN pUnk,HRESULT *phr);
    virtual ~CRenderer();
    CBasePin *GetPin(int n);

    void AutoShowWindow();
    BOOL OnPaint(BOOL bMustPaint);
    BOOL OnTimer(WPARAM wParam);
    void PrepareRender();

    STDMETHODIMP Stop();
    STDMETHODIMP Pause();
    STDMETHODIMP Run(REFERENCE_TIME StartTime);

    static CUnknown *CreateInstance(LPUNKNOWN, HRESULT *);
    STDMETHODIMP NonDelegatingQueryInterface(REFIID, void **);
    STDMETHODIMP GetPages(CAUUID *pPages);

    HRESULT CompleteConnect(IPin *pReceivePin);
    HRESULT SetMediaType(const CMediaType *pmt);
    HRESULT Receive(IMediaSample *pSample);
    HRESULT CheckMediaType(const CMediaType *pmt);
    HRESULT BreakConnect();
    HRESULT NotifyEndOfStream(HANDLE hNotifyEvent);
    HRESULT EndOfStream();
    HRESULT BeginFlush();
    HRESULT EndFlush();
    HRESULT SetOverlayMediaType(const CMediaType *pmt);
    HRESULT SetDirectMediaType(const CMediaType *pmt);
    HRESULT DoRenderSample(IMediaSample *pMediaSample);
    void OnReceiveFirstSample(IMediaSample *pMediaSample);
    HRESULT CompleteStateChange(FILTER_STATE OldState);
    HRESULT Inactive();


    BOOL LockedDDrawSampleOutstanding();
    HRESULT CheckMediaTypeWorker(const CMediaType *pmt);

    // Which monitor are we on, for a multiple monitor system?
    INT_PTR GetCurrentMonitor();

    // has our window moved at least partly onto another monitor than the one
    // we think we're on?
    // ID == 0 means it spans 2 monitors now
    // ID != 0 means it's wholly on monitor ID
    BOOL IsWindowOnWrongMonitor(INT_PTR *pID);

    HRESULT ResetForDfc();

    LONG m_fDisplayChangePosted; // don't send too many and slow performance

#ifdef DEBUG
    // Used to display debug prints of palette arrays
    void DisplayGDIPalette(const CMediaType *pmt);
#endif // DEBUG

    //
    // IKsPropertySet interface methods
    //
    STDMETHODIMP Set(REFGUID guidPropSet, DWORD PropID, LPVOID pInstanceData,
                     DWORD cbInstanceData, LPVOID pPropData, DWORD cbPropData) ;
    STDMETHODIMP Get(REFGUID guidPropSet, DWORD PropID, LPVOID pInstanceData,
                     DWORD cbInstanceData, LPVOID pPropData, DWORD cbPropData,
                     DWORD *pcbReturned) ;
    STDMETHODIMP QuerySupported(REFGUID guidPropSet, DWORD PropID, DWORD *pTypeSupport) ;

    //
    // IDrawVideoImage
    //
    STDMETHODIMP DrawVideoImageBegin();
    STDMETHODIMP DrawVideoImageEnd();
    STDMETHODIMP DrawVideoImageDraw(HDC hdc, LPRECT lprcSrc, LPRECT lprcDst);

    
    LONG GetVideoWidth();
    LONG GetVideoHeight();

public:

    // Member variables for the image renderer object. This class supports
    // a number of interfaces by delegating to member classes we initialise
    // during construction. We have a specialised input pin derived from
    // CBaseInputPin that does some extra video rendering work. The base pin
    // normally stores the media type for any given connection but we take
    // the type proposed and normalise it so that it is easier to manipulate
    // when we do type checking. This normalised type is stored in m_mtIn
    // In general the classes that do the work hold the member variables
    // that they use but this represents a useful place to put filter wide
    // information that more than one interface or nested class uses

    CDrawVideo m_DrawVideo;             // Handles drawing our images
    CImagePalette m_ImagePalette;       // Manages our window's palette
    CVideoWindow m_VideoWindow;         // Looks after a rendering window
    CVideoAllocator m_VideoAllocator;   // Our DirectDraw allocator
    COverlay m_Overlay;                 // IOverlay interface
    CVideoInputPin m_InputPin;          // IPin based interfaces
    CImageDisplay m_Display;            // Manages the video display type
    CDirectDraw m_DirectDraw;           // Handles DirectDraw surfaces
    CMediaType m_mtIn;                  // Source connection media type
    SIZE m_VideoSize;                   // Size of current video stream
    RECT m_rcMonitor;                   // rect of current monitor
    int m_nNumMonitors;                 // rect of current monitor
    char m_achMonitor[CCHDEVICENAME];   // device name of current monitor
    INT_PTR m_nMonitor;                 // unique int for each monitor
    HANDLE  m_hEndOfStream;

    CRendererMacroVision m_MacroVision ; // MacroVision implementation object

    //
    // Frame Step stuff
    //
    CCritSec    m_FrameStepStateLock;   // This lock protects m_lFramesToStep.  It should 
                                        // always be held when the program accesses 
                                        // m_lFramesToStep.  The program should not send 
                                        // windows messages, wait for events or attempt to 
                                        // acquire other locks while it is holding this lock.
    HANDLE      m_StepEvent;
    LONG        m_lFramesToStep;        // -ve (-1)  == normal playback
                                        // +ve (>=0) == frames to skips
    void        FrameStep();
    void        CancelStep();
    bool        IsFrameStepEnabled();

};

inline LONG CRenderer::GetVideoWidth()
{
    // The m_VideoSize is only valid if the input pin is connected.
    ASSERT(m_pInputPin->IsConnected());

    return m_VideoSize.cx;
}

inline LONG CRenderer::GetVideoHeight()
{
    // The m_VideoSize is only valid if the input pin is connected.
    ASSERT(m_pInputPin->IsConnected());

    // The height can be negative if the Video Renderer is using 
    // the top-down DIB format.
    return abs(m_VideoSize.cy);
}

#endif // __IMAGE__
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\multimedia\dshow\filters\image\video\render.h ===
// Copyright (c) 1994 - 1999  Microsoft Corporation.  All Rights Reserved.
// Main video renderer header file, Anthony Phillips, January 1995

#ifndef __RENDER__
#define __RENDER__

// Include the global header files

#include <dciman.h>
#include <dciddi.h>
#include <ddraw.h>
#include <viddbg.h>

// Forward declarations

class CRenderer;
class CVideoWindow;
class CVideoSample;
class CVideoAllocator;
class COverlay;
class CControlWindow;
class CControlVideo;
class CDirectDraw;
class CRendererMacroVision;

// Include the rendering header files

#include "vidprop.h"        // Video renderer property pages
#include "dvideo.h"         // Implements DirectDraw surfaces
#include "allocate.h"       // A shared DIB section allocator
#include "direct.h"         // The renderer overlay extensions
#include "window.h"         // An object to maintain a window
#include "hook.h"           // Hooks window clipping messages
#include "VRMacVis.h"       // The MacroVision support object
#include "image.h"          // The main controlling COM object

#endif // __RENDER__
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\multimedia\dshow\filters\image\video\image.cpp ===
// Copyright (c) 1994 - 1999  Microsoft Corporation.  All Rights Reserved.
// Implements the CRenderer class, Anthony Phillips, January 1995

#include <streams.h>
#include <windowsx.h>
#include <render.h>
#include <limits.h>
#include <measure.h>

#ifdef FILTER_DLL
#include <initguid.h>
#endif

#include "ddmm.h"
#include "MultMon.h"  // our version of multimon.h include ChangeDisplaySettingsEx
#include "dvdmedia.h"  // for MacroVision prop set, id

// (Threading model) We can have upto three different threads accessing us
// at the same time. The first is the application (or filter graph) thread
// that changes our state, looks after connections and calls the control
// interfaces. All these interfaces are serialised through the main video
// critical section handed out to the implementation objects at creation.
//
// The second is a thread spun off to poll messages from the window queue,
// this is packaged up in an object with it's own critical section. All the
// parts of the video renderer that change properties on the video window
// (such as it's palette) call into the window object via a public entry
// method and lock the object before making the changes. In certain places
// the window thread has to call out into another one of our objects (like
// the overlay object), unfortunately the overlay object also likes to call
// into the window object which leads to a possible deadlock condition. The
// solution is to lock the overlay object first and then lock the window
// (ALWAYS in that order). For example, in the WM_PAINT processing it first
// calls the overlay object and afterwards grabs it's own critical section.
//
// The third is the source filter thread that calls Receive on our input pin
// Calls to Receive should be serialised on a single thread. The thread waits
// until the image it contains is due for drawing. The causes some difficult
// problems with state change synchronisation. When we have a thread inside
// of us and stop we set an event in the window object via CanReceiveSamples
// so that it's wait is aborted and it can return to the source. We don't
// wait for the worker thread to return before completing the stop.
//
// So we could in theory stop us and the start us running (or other very fast
// state transitions) before the worker thread has completed. Fortunately we
// know this won't happen because the entire filter graph must be transitioned
// to each state before another one can be executed. So when we stop we know
// the worker thread must be back at the source before it will fully stop. If
// this wasn't the case we would have to have an event that was reset when a
// worker thread arrived and set when it exited so we could wait on it, this
// would introduce a Set and Reset for every image we ever wanted to render.
//
// We have a fair number of critical sections to help manage all the threads
// that can be bouncing around the filter. The order that these locks are
// gained in is absolutely critical. If locks are gained in the wrong order
// we will inevitably deadlock. The hierachy of locks is as follows,
//
//      - Main renderer interface lock (sdk RENBASE.H)   (Highest)
//      - IOverlay class lock (DIRECT.H)                     |
//      - Base renderer sample lock (sdk RENBASE.H)          |
//      - Window thread lock (WINDOW.H)                      |
//      - DirectDraw video allocator (ALLOCATE.H)            |
//      - DirectVideo (DVIDEO.H) critical section            |
//      - Display base class (sdk WINUTIL.H)             (Lowest)
//
// Therefore if for example you are executing a function in the window object
// with the window lock gained, and you need to call the overlay object which
// locks it's critical section, then you must UNLOCK the window lock before
// calling. This is because the overlay object can also call into the window
// object. If it has it's lock when it calls the window object, and you have
// the window lock as you call into the overlay then we'll deadlock. There
// does not appear to be a design whereby objects only call in one direction
// (ie don't call each other) - in part this is because of the very complex
// threading interactions that can occur - so my advise is to be careful!


// List of class IDs and creator functions for the class factory. This
// provides the link between the OLE entry point in the DLL and an object
// being created. The class factory will call the static CreateInstance
// function when it is asked to create a CLSID_VideoRenderer COM object

#ifdef FILTER_DLL
CFactoryTemplate g_Templates[] = {
    {L"", &CLSID_VideoRenderer,CRenderer::CreateInstance,OnProcessAttachment},
    {L"", &CLSID_DirectDrawProperties,CVideoProperties::CreateInstance},
    {L"", &CLSID_QualityProperties,CQualityProperties::CreateInstance},
    {L"", &CLSID_PerformanceProperties,CPerformanceProperties::CreateInstance}
};
int g_cTemplates = sizeof(g_Templates) / sizeof(g_Templates[0]);
STDAPI DllRegisterServer()
{
    return AMovieDllRegisterServer2( TRUE );
}

STDAPI DllUnregisterServer()
{
    return AMovieDllRegisterServer2( FALSE );
}
#endif

// helper to let VMR create this filter without including all our
// header files
CUnknown *CRenderer_CreateInstance(LPUNKNOWN pUnk, HRESULT *phr)
{
    return CRenderer::CreateInstance(pUnk, phr);
}

// This goes in the factory template table to create new filter instances

CUnknown *CRenderer::CreateInstance(LPUNKNOWN pUnk, HRESULT *phr)
{
    return new CRenderer(NAME("Video renderer"),pUnk,phr);
}

// this is needed for rendering output of the ovmixer. perhaps we
// could change it to subtype=overlay and raise the merit to speed up
// things

// Setup data

const AMOVIESETUP_MEDIATYPE
sudVideoPinTypes =
{
    &MEDIATYPE_Video,           // Major type
    &MEDIASUBTYPE_NULL          // And subtype
};

const AMOVIESETUP_PIN
sudVideoPin =
{
    L"Input",                   // Name of the pin
    TRUE,                       // Is pin rendered
    FALSE,                      // Is an Output pin
    FALSE,                      // Ok for no pins
    FALSE,                      // Can we have many
    &CLSID_NULL,                // Connects to filter
    NULL,                       // Name of pin connect
    1,                          // Number of pin types
    &sudVideoPinTypes           // Details for pins
};

const AMOVIESETUP_FILTER
sudVideoFilter =
{
    &CLSID_VideoRenderer,       // Filter CLSID
    L"Video Renderer",          // Filter name
    MERIT_UNLIKELY,             // Filter merit
    1,                          // Number pins
    &sudVideoPin                // Pin details
};

// Constructor for the main renderer class. This was originally written to
// instantiate only the contained interfaces and not the class that looks
// after the window. This kind of late binding proved to be very buggy and
// difficult to maintain. For these reasons the constructor now creates all
// it's classes during construction. This means that as soon as a renderer
// object is created so will the window that it uses, this is unlikely to
// prove much of an overhead and indeed reduces the latency when the client
// starts streaming as the window is already initialised and ready to accept
// video images. We do however create the window object dynamically, albeit
// in the constructor. This is so that when we come to the destructor we can
// destroy the window and it's thread before anything. We therefore know
// that no more window messages will be retrieved and dispatched to various
// nested objects while we are processing any of the objects destructors

#pragma warning(disable:4355)

CRenderer::CRenderer(TCHAR *pName,
                     LPUNKNOWN pUnk,
                     HRESULT *phr) :

    CBaseVideoRenderer(CLSID_VideoRenderer,pName,pUnk,phr),
    m_VideoWindow(this,&m_InterfaceLock,GetOwner(),phr),
    m_VideoAllocator(this,&m_DirectDraw,&m_InterfaceLock,phr),
    m_Overlay(this,&m_DirectDraw,&m_InterfaceLock,phr),
    m_InputPin(this,&m_InterfaceLock,phr,L"Input"),
    m_DirectDraw(this,&m_InterfaceLock,GetOwner(),phr),
    m_ImagePalette(this,&m_VideoWindow,&m_DrawVideo),
    m_DrawVideo(this,&m_VideoWindow),
    m_fDisplayChangePosted(false),
    m_hEndOfStream(NULL),
    m_StepEvent(NULL),
    m_lFramesToStep(-1),
    m_nNumMonitors(GetSystemMetrics(SM_CMONITORS)),
    m_nMonitor(-1)
{
    // Store the video input pin
    m_pInputPin = &m_InputPin;

    // Reset the video size

    m_VideoSize.cx = 0;
    m_VideoSize.cy = 0;

    // Initialise the window and control interfaces

    HRESULT hr = m_VideoWindow.PrepareWindow();
    if (FAILED(hr)) {
        *phr = hr;
        return;
    }

    m_DrawVideo.SetDrawContext();
    m_VideoWindow.SetControlWindowPin(&m_InputPin);
    m_VideoWindow.SetControlVideoPin(&m_InputPin);

    // We have a window, figure out what monitor it's on (multi-monitor)
    // NULL means we aren't running with multiple monitors
    GetCurrentMonitor();

    // Now that we know what monitor we're on, setup for using it
    m_Display.RefreshDisplayType(m_achMonitor);

    //
    // Frame stepping stuff
    //
    // -ve == normal playback
    // +ve == frames to skips
    //  0 == time to block
    //
    m_StepEvent = CreateEvent(NULL, FALSE, FALSE, NULL);

    // CreateEvent() returns NULL if an error occurs.
    if (NULL == m_StepEvent) {
        *phr = AmGetLastErrorToHResult();
        return;
    }
}


// Close down the window before deleting the nested classes

CRenderer::~CRenderer()
{
    m_VideoWindow.InactivateWindow();
    m_Overlay.OnHookMessage(FALSE);
    m_VideoWindow.DoneWithWindow();
    m_pInputPin = NULL;

    if (m_StepEvent)
    {
        CloseHandle(m_StepEvent);
    }
}

STDMETHODIMP CRenderer::DrawVideoImageBegin()
{
    CAutoLock cSampleLock(&m_RendererLock);

    if (m_State != State_Stopped) {
        return VFW_E_WRONG_STATE;
    }

    m_VideoAllocator.NoDirectDraw(TRUE);
    return NOERROR;
}

STDMETHODIMP CRenderer::DrawVideoImageEnd()
{
    CAutoLock cSampleLock(&m_RendererLock);

    if (m_State != State_Stopped) {
        return VFW_E_WRONG_STATE;
    }

    m_VideoAllocator.NoDirectDraw(FALSE);
    return NOERROR;
}


STDMETHODIMP CRenderer::DrawVideoImageDraw(HDC hdc, LPRECT lprcSrc, LPRECT lprcDst)
{
    for (; ; )
    {
        {
            CAutoLock cSampleLock(&m_RendererLock);

            if (m_State != State_Running) {
                return VFW_E_WRONG_STATE;
            }

            if (m_VideoAllocator.GetDirectDrawStatus()) {
                return VFW_E_WRONG_STATE;
            }

            if (!m_DrawVideo.UsingImageAllocator()) {
                return VFW_E_WRONG_STATE;
            }

            if (m_pMediaSample != NULL) {
                m_ImagePalette.DrawVideoImageHere(hdc,
                                                  m_pMediaSample,
                                                  lprcSrc, lprcDst);
                return NOERROR;
            }

            //  Call the base class to avoid locking issues
            IMediaSample *pMediaSample;
            HRESULT hr;

            hr = m_VideoAllocator.CBaseAllocator::GetBuffer(&pMediaSample,
                                                            NULL, NULL,
                                                            AM_GBF_NOWAIT);
            if (SUCCEEDED(hr)) {
                m_ImagePalette.DrawVideoImageHere(hdc, pMediaSample,
                                                  lprcSrc, lprcDst);
                pMediaSample->Release();
                return NOERROR;
            }

            if (hr != VFW_E_TIMEOUT) {
                return E_FAIL;
            }
        }

        Sleep(1);
    }

    return E_FAIL;
}

#if 0
HRESULT
CRenderer::CopySampleBits(
    IMediaSample *pMediaSample,
    LPBYTE* ppDib
    )
{
    LPBYTE lpBits;
    HRESULT hr = pMediaSample->GetPointer(&lpBits);
    if (FAILED(hr)) {
        return hr;
    }

    LPBITMAPINFOHEADER lpbi = HEADER(m_mtIn.Format());
    if (lpbi) {

        ULONG ulSizeHdr;
        LPBITMAPINFOHEADER lpbiDst;

        if (lpbi->biCompression == BI_BITFIELDS) {
            ulSizeHdr = lpbi->biSize + (3 * sizeof(DWORD));
        }
        else {
            ulSizeHdr = lpbi->biSize + (int)(lpbi->biClrUsed * sizeof(RGBQUAD));
        }

        *ppDib = (LPBYTE)CoTaskMemAlloc(ulSizeHdr + DIBSIZE(*lpbi));

        if (*ppDib) {
            CopyMemory(*ppDib, lpbi, ulSizeHdr);
            CopyMemory(*ppDib + ulSizeHdr, lpBits, DIBSIZE(*lpbi));
            return NOERROR;
        }
    }

    return E_FAIL;

}

STDMETHODIMP CRenderer::DrawVideoImageGetBits(LPBYTE* ppDib)
{
    for (; ; )
    {
        {
            CAutoLock cSampleLock(&m_RendererLock);

            if (m_State != State_Running) {
                return VFW_E_WRONG_STATE;
            }

            if (m_VideoAllocator.GetDirectDrawStatus()) {
                return VFW_E_WRONG_STATE;
            }

            if (!m_DrawVideo.UsingImageAllocator()) {
                return VFW_E_WRONG_STATE;
            }

            if (m_pMediaSample != NULL) {
                return CopySampleBits(m_pMediaSample, ppDib);
            }

            //  Call the base class to avoid locking issues
            IMediaSample *pMediaSample;
            HRESULT hr;

            hr = m_VideoAllocator.CBaseAllocator::GetBuffer(&pMediaSample,
                                                            NULL, NULL,
                                                            AM_GBF_NOWAIT);
            if (SUCCEEDED(hr)) {
                hr = CopySampleBits(pMediaSample, ppDib);
                pMediaSample->Release();
                return hr;
            }

            if (hr != VFW_E_TIMEOUT) {
                return E_FAIL;
            }
        }

        Sleep(1);
    }

    return E_FAIL;
}
#endif


// what device is this window on?
INT_PTR CRenderer::GetCurrentMonitor()
{
    // This can change dynamically
    m_nNumMonitors = GetSystemMetrics(SM_CMONITORS);

    m_nMonitor = DeviceFromWindow(m_VideoWindow.GetWindowHWND(), m_achMonitor,
                                  &m_rcMonitor);
    DbgLog((LOG_TRACE,3,TEXT("Establishing current monitor = %s"),
            m_achMonitor));
    // 0 means spanning monitors or off in hyperspace, otherwise it is a
    // unique id for each monitor
    return m_nMonitor;
}


// Has the window moved at least partially onto a monitor other than the
// monitor we have a DDraw object for?  ID will be the hmonitor of the
// monitor it is on, or 0 if it spans
BOOL CRenderer::IsWindowOnWrongMonitor(INT_PTR *pID)
{

    // There is only 1 monitor.
    if (m_nNumMonitors == 1) {
        if (pID)
            *pID = m_nMonitor;
        return FALSE;
    }

    HWND hwnd = m_VideoWindow.GetWindowHWND();

    // If the window is on the same monitor as last time, this is the quickest
    // way to find out.  This is called every frame, remember
    RECT rc;
    GetWindowRect(hwnd, &rc);
    if (rc.left >= m_rcMonitor.left && rc.right <= m_rcMonitor.right &&
        rc.top >= m_rcMonitor.top && rc.bottom <= m_rcMonitor.bottom) {
        if (pID)
            *pID = m_nMonitor;
        return FALSE;
    }

    // Find out for real. This is called every frame, but only when we are
    // partially off our main monitor, so that's not so bad.
    INT_PTR ID = DeviceFromWindow(hwnd, NULL, NULL);
    if (pID)
        *pID = ID;
    //DbgLog((LOG_TRACE,3,TEXT("Current Monitor %d   New Monitor %d"), m_DDrawID, ID));
    return (m_nMonitor != ID);
}


// Overriden to say what interfaces we support and where

STDMETHODIMP CRenderer::NonDelegatingQueryInterface(REFIID riid,void **ppv)
{
    // Do we have this interface

    if (riid == IID_ISpecifyPropertyPages) {
        return GetInterface((ISpecifyPropertyPages *)this, ppv);
    } else if (riid == IID_IKsPropertySet) {
        return GetInterface((IKsPropertySet *)this, ppv);
    } else if (riid == IID_IDrawVideoImage) {
        return GetInterface((IDrawVideoImage *)this, ppv);
    } else if (riid == IID_IBasicVideo || riid == IID_IBasicVideo2) {
        return m_VideoWindow.NonDelegatingQueryInterface(riid,ppv);
    } else if (riid == IID_IVideoWindow) {
        return m_VideoWindow.NonDelegatingQueryInterface(riid,ppv);
    } else if (riid == IID_IDirectDrawVideo) {
        return m_DirectDraw.NonDelegatingQueryInterface(riid,ppv);
    }
    return CBaseVideoRenderer::NonDelegatingQueryInterface(riid,ppv);
}


// Return the CLSIDs for the property pages we support

STDMETHODIMP CRenderer::GetPages(CAUUID *pPages)
{
    CheckPointer(pPages,E_POINTER);

#if 0
    // By default, we don't want to provide the DirectDraw and performance
    // property pages, they'll just confuse a novice user. Likewise the
    // fullscreen property page that selects display modes won't be shown

    HKEY hk;
    BOOL fShowDDrawPage = FALSE, fShowPerfPage = FALSE;
    DWORD dwValue = 0, cb = sizeof(DWORD);
    TCHAR ach[80] = {'C','L','S','I','D','\\'};
    REFGUID rguid = CLSID_DirectDrawProperties;
    wsprintf(&ach[6], "{%08lX-%04X-%04X-%02X%02X-%02X%02X%02X%02X%02X%02X}",
            rguid.Data1, rguid.Data2, rguid.Data3,
            rguid.Data4[0], rguid.Data4[1],
            rguid.Data4[2], rguid.Data4[3],
            rguid.Data4[4], rguid.Data4[5],
            rguid.Data4[6], rguid.Data4[7]);

    if (!RegOpenKey(HKEY_CLASSES_ROOT, ach, &hk)) {
        if (!RegQueryValueEx(hk, "ShowMe", NULL, NULL, (LPBYTE)&dwValue, &cb) &&
                             dwValue)
            fShowDDrawPage = TRUE;
        RegCloseKey(hk);
    }

    // Next look after the performance property page

    REFGUID rguid2 = CLSID_PerformanceProperties;
    wsprintf(&ach[6], "{%08lX-%04X-%04X-%02X%02X-%02X%02X%02X%02X%02X%02X}",
            rguid2.Data1, rguid2.Data2, rguid2.Data3,
            rguid2.Data4[0], rguid2.Data4[1],
            rguid2.Data4[2], rguid2.Data4[3],
            rguid2.Data4[4], rguid2.Data4[5],
            rguid2.Data4[6], rguid2.Data4[7]);

    if (!RegOpenKey(HKEY_CLASSES_ROOT, ach, &hk)) {
        if (!RegQueryValueEx(hk, "ShowMe", NULL, NULL, (LPBYTE)&dwValue, &cb) &&
                             dwValue)
            fShowPerfPage = TRUE;
        RegCloseKey(hk);
    }
#endif

    // Allocate the memory for the GUIDs

    pPages->cElems = 1;
    pPages->pElems = (GUID *) QzTaskMemAlloc(3 * sizeof(GUID));
    if (pPages->pElems == NULL) {
        return E_OUTOFMEMORY;
    }

    // Fill in the array with the property page GUIDs

    pPages->pElems[0] = CLSID_QualityProperties;
#if 0
    if (fShowDDrawPage)
#endif
        pPages->pElems[pPages->cElems++] = CLSID_DirectDrawProperties;
#if 0
    if (fShowPerfPage)
#endif
        pPages->pElems[pPages->cElems++] = CLSID_PerformanceProperties;

    return NOERROR;
}


// This is called when we can establish a connection to prepare for running
// We store a copy of the media type used for the connection in the renderer
// because it is required by many different parts of the running renderer
// This can be called when we come to draw a media sample that has a format
// change with it since we delay the completion to maintain synchronisation

HRESULT CRenderer::SetMediaType(const CMediaType *pmt)
{
    // CAutoLock cInterfaceLock(&m_InterfaceLock);
    ASSERT(CritCheckIn(&m_InterfaceLock));
    VIDEOINFO *pVideoInfo = (VIDEOINFO *) pmt->Format();
    const GUID SubType = *pmt->Subtype();
    m_Display.UpdateFormat(pVideoInfo);
    ASSERT(CritCheckOut(&m_RendererLock));

    // Is this an overlay connection being set

    if (*pmt->Subtype() == MEDIASUBTYPE_Overlay) {
        NOTE("Setting overlay format");
        return SetOverlayMediaType(pmt);
    }

    // Look after DirectDraw samples separately

    if (m_VideoAllocator.GetDirectDrawStatus()) {
        NOTE("Setting DirectDraw format");
        return SetDirectMediaType(pmt);
    }

    if (m_bInReceive) {
        m_VideoWindow.SetRealize(FALSE);
    }
    // Change palettes using the current format
    m_ImagePalette.PreparePalette(pmt, &m_mtIn, m_achMonitor);
    m_VideoWindow.SetRealize(TRUE);

    m_mtIn = *pmt;

    // Complete the format change in the other objects
    m_DrawVideo.NotifyMediaType(&m_mtIn);
    m_VideoAllocator.NotifyMediaType(&m_mtIn);

    // Update the DirectDraw format with palette changes

    if (m_VideoAllocator.IsDirectDrawAvailable() == TRUE) {
        NOTE("Storing palette in DirectDraw format");
        CMediaType *pDirect = m_DirectDraw.GetSurfaceFormat();
        m_ImagePalette.CopyPalette(pmt,pDirect);
    }
    return NOERROR;
}


// Handles setting of a media type from a DirectDraw sample. If we get a type
// change on a DCI/DirectDraw sample then we can extract palette changes from
// them. If the colours do really differ then we need to create a new palette
// and update the original DIB format. We must also update the surface format
// so that everything remains in sync - there is a base class function called
// CopyPalette that looks after copying palette colours between media formats

HRESULT CRenderer::SetDirectMediaType(const CMediaType *pmt)
{
    NOTE("SetDirectMediaType");

    VIDEOINFO *pVideoInfo = (VIDEOINFO *) pmt->Format();
    if (ContainsPalette((VIDEOINFOHEADER *)pVideoInfo) == FALSE) {
        NOTE("No palette");
        return NOERROR;
    }

    // Check that we already have a palette

    if (*m_mtIn.Subtype() != MEDIASUBTYPE_RGB8) {
        ASSERT(!TEXT("Invalid format"));
        return VFW_E_TYPE_NOT_ACCEPTED;
    }

    // Update the current palette and copy the colours

    if (m_ImagePalette.PreparePalette(pmt, &m_mtIn, m_achMonitor) != NOERROR) {
        NOTE("No palette change");
        return NOERROR;
    }

    // Copy the palette into the renderer formats

    ASSERT(m_VideoAllocator.IsDirectDrawAvailable());
    m_ImagePalette.CopyPalette(pmt,&m_mtIn);
    CMediaType *pDirect = m_DirectDraw.GetSurfaceFormat();
    m_ImagePalette.CopyPalette(pmt,pDirect);

    return NOERROR;
}


// Handles setting of an overlay media type

HRESULT CRenderer::SetOverlayMediaType(const CMediaType *pmt)
{
    NOTE("SetOverlayMediaType");
    m_mtIn = *pmt;
    m_ImagePalette.RemovePalette();
    m_VideoWindow.OnUpdateRectangles();
    return NOERROR;
}

HRESULT CRenderer::ResetForDfc()
{
    // Free any palette resources
    m_ImagePalette.RemovePalette();
    // m_mtIn.ResetFormatBuffer();

    // Destroy DCI/DirectDraw surfaces
    m_DirectDraw.ReleaseSurfaces();
    m_DirectDraw.ReleaseDirectDraw();
    m_VideoAllocator.Decommit();
    m_VideoAllocator.ResetDirectDrawStatus();

    return S_OK;
}


// This is called when a connection or an attempted connection is terminated
// and lets us to reset the connection flag held by the base class renderer
// The filter object may be hanging onto an image to use for refreshing the
// video window so that must be freed (the allocator decommit may be waiting
// for that image to return before completing) then we must also uninstall
// any palette we were using, reset anything set with the control interfaces
// then set our overall state back to disconnected ready for the next time

HRESULT CRenderer::BreakConnect()
{
    CAutoLock cInterfaceLock(&m_InterfaceLock);

    // Check we are in a valid state

    HRESULT hr = CBaseVideoRenderer::BreakConnect();
    if (FAILED(hr)) {
        return hr;
    }

    // The window is not used when disconnected
    IPin *pPin = m_InputPin.GetConnected();
    if (pPin) SendNotifyWindow(pPin,NULL);


    // Free any palette resources
    m_ImagePalette.RemovePalette();
    m_mtIn.ResetFormatBuffer();

    // Destroy DCI/DirectDraw surfaces
    m_DirectDraw.ReleaseSurfaces();
    m_DirectDraw.ReleaseDirectDraw();
    m_VideoAllocator.Decommit();
    m_VideoAllocator.ResetDirectDrawStatus();

    // Now deactivate Macrovision, if it was activated
    if (m_MacroVision.GetCPHWND())
    {
        m_MacroVision.SetMacroVision(m_MacroVision.GetCPHWND(), 0) ;  // clear MV from display
        m_MacroVision.StopMacroVision(m_MacroVision.GetCPHWND()) ;    // reset CP key
    }

    return NOERROR;
}


// Overriden to check for overlay connections

HRESULT CRenderer::BeginFlush()
{
    NOTE("Entering BeginFlush");

    {
        CAutoLock cInterfaceLock(&m_InterfaceLock);

        //  Cancel frame stepping or we'll hang
        CancelStep();
        m_hEndOfStream = 0;
    }

    // This is valid for media samples only

    if (*m_mtIn.Subtype() == MEDIASUBTYPE_Overlay) {
        NOTE("Overlay");
        return NOERROR;
    }
    return CBaseVideoRenderer::BeginFlush();
}


// Overriden to check for overlay connections

HRESULT CRenderer::EndFlush()
{
    NOTE("Entering EndFlush");

    // Make sure the overlay gets updated
    m_DirectDraw.OverlayIsStale();

    // This is valid for media samples only

    if (*m_mtIn.Subtype() == MEDIASUBTYPE_Overlay) {
        NOTE("Overlay");
        return NOERROR;
    }
    return CBaseVideoRenderer::EndFlush();
}


// Pass EOS to the video renderer window object that sets a flag so that no
// more data will be accepted from the pin until either we transition to a
// stopped state or are flushed. It also lets it know whether it will have
// an image soon for refreshing. When we go to a stopped state we clear any
// end of stream flag set so we must make sure to reject this if received

HRESULT CRenderer::EndOfStream()
{
    {
        CAutoLock cInterfaceLock(&m_InterfaceLock);
        if (m_hEndOfStream) {
            EXECUTE_ASSERT(SetEvent(m_hEndOfStream));
            return S_OK;
        }
    }

    NOTE("Entering EndOfStream");
    CBaseVideoRenderer::EndOfStream();
    m_DirectDraw.StartRefreshTimer();
    return NOERROR;
}

HRESULT CRenderer::NotifyEndOfStream(HANDLE hNotifyEvent)
{
    CAutoLock l(&m_InterfaceLock);
    m_hEndOfStream = hNotifyEvent;
    return S_OK;
}



// This is the last thing called by both Connect and ReceiveConnect when they
// have finished their connection protocol. This point provides us a suitable
// time to reset our state such as enabling DCI/DirectDraw and clearing any
// run time error that may have been left over from the previous connection
// We don't load DirectDraw for overlay connections since they don't need it

HRESULT CRenderer::CompleteConnect(IPin *pReceivePin)
{
    m_DrawVideo.ResetPaletteVersion();
    NOTE("Entering CompleteConnect");

    // This enables us to send EC_REPAINT events again

    HRESULT hr = CBaseVideoRenderer::CompleteConnect(pReceivePin);
    if (FAILED(hr)) {
        return hr;
    }

    // Pass the video window handle upstream
    HWND hwnd = m_VideoWindow.GetWindowHWND();
    NOTE1("Sending EC_NOTIFY_WINDOW %x",hwnd);
    SendNotifyWindow(pReceivePin,hwnd);

//  // Don't load DirectDraw for overlay connections
//
//  We have to load DirectDraw of MEDIASUBTYPE_Overlay because we
//  have replaced the DCI clipper with the DirectDraw clipper
//
//  if (*m_mtIn.Subtype() != MEDIASUBTYPE_Overlay) {
        NOTE("Initialising DirectDraw");
        m_DirectDraw.InitDirectDraw(*m_mtIn.Subtype() == MEDIASUBTYPE_Overlay);
//  }

    VIDEOINFO *pVideoInfo = (VIDEOINFO *) m_mtIn.Format();

    // Has the video size changed between connections

    if (pVideoInfo->bmiHeader.biWidth == m_VideoSize.cx) {
        if (pVideoInfo->bmiHeader.biHeight == m_VideoSize.cy) {
            NOTE("No size change");
            return NOERROR;
        }
    }

    // Set properties for the current video

    m_VideoSize.cx = pVideoInfo->bmiHeader.biWidth;
    m_VideoSize.cy = pVideoInfo->bmiHeader.biHeight;
    m_VideoWindow.SetDefaultSourceRect();
    m_VideoWindow.SetDefaultTargetRect();
    m_VideoWindow.OnVideoSizeChange();

    // Notify the video window of the CompleteConnect
    m_VideoWindow.CompleteConnect();
    m_VideoWindow.ActivateWindow();

    return NOERROR;
}


HRESULT CRenderer::CheckMediaTypeWorker(const CMediaType *pmt)
{
    // Does the media type contain a NULL format

    VIDEOINFO *pVideoInfo = (VIDEOINFO *) pmt->Format();
    if (pVideoInfo == NULL) {
        NOTE("NULL format");
        return E_INVALIDARG;
    }

    // Just check the format if not using our allocator

    if (m_DrawVideo.UsingImageAllocator() == FALSE) {
        NOTE("Checking display format");
        return m_Display.CheckMediaType(pmt);
    }

    // Is this a query on the DirectDraw format

    if (m_VideoAllocator.IsSurfaceFormat(pmt) == TRUE) {
        NOTE("Matches surface");
        return NOERROR;
    }
    HRESULT hr = m_Display.CheckMediaType(pmt);
    if (FAILED(hr)) {
        DbgLog((LOG_TRACE, 2, TEXT("CheckMediaType returned %8.8X"), hr));
    }
    return hr;
}

BOOL CRenderer::LockedDDrawSampleOutstanding()
{
    if (m_DrawVideo.UsingImageAllocator()) {

        if (m_VideoAllocator.UsingDDraw()) {

            return m_VideoAllocator.AnySamplesOutstanding();
        }
    }

    return FALSE;
}

// Check that we can support a given proposed type. QueryAccept is also used
// as a trigger to change our buffer formats. If we are called with a format
// that matches the current DirectDraw format then we force a renegotiation
// when GetBuffer is next called. This can be used to delay switching into
// DirectDraw. Alternatively we may be called with the current DIB format in
// which case we also use it as a trigger to generate a format renegotiation

HRESULT CRenderer::CheckMediaType(const CMediaType *pmt)
{
    //
    // If there is a locked DDraw sample outstanding
    // don't take the renderer lock because we will
    // deadlock if a TransIP filter is up stream of us.
    //

    if (LockedDDrawSampleOutstanding()) {
        return CheckMediaTypeWorker(pmt);
    }
    else {
        CAutoLock cInterfaceLock(&m_InterfaceLock);
        return CheckMediaTypeWorker(pmt);
    }
}

//  Helper to step a frame
void CRenderer::FrameStep()
{
    CAutoLock cFrameStepStateLock(&m_FrameStepStateLock);
    if (m_lFramesToStep == 1) {
        m_lFramesToStep--;
        m_FrameStepStateLock.Unlock();
        NotifyEvent(EC_STEP_COMPLETE, FALSE, 0);
        DWORD dw = WaitForSingleObject(m_StepEvent, INFINITE);
        m_FrameStepStateLock.Lock();
        ASSERT(m_lFramesToStep != 0);
    }
}

//  Helper to cancel frame step
void CRenderer::CancelStep()
{
    CAutoLock cFrameStepStateLock(&m_FrameStepStateLock);

    //
    // cancel any outstanding steps
    //
    long l = m_lFramesToStep;
    m_lFramesToStep = -1;

    if (l == 0) {

        SetEvent(m_StepEvent);
    }
}


bool CRenderer::IsFrameStepEnabled()
{
    CAutoLock cFrameStepStateLock(&m_FrameStepStateLock);
    return (m_lFramesToStep >= 0);
}


// These implement the remaining IMemInputPin virtual method. We are called
// by the output pin from the connected filter when a sample is ready. All we
// do after some checking is pass the sample on to the object looking after
// the window which does the timing, synchronisation and presentation of the
// image. We need to AddRef the sample if we are to hold it beyond the end of
// this function, sample reference counting is managed by the window object

HRESULT CRenderer::Receive(IMediaSample *pSample)
{
    if (*m_mtIn.Subtype() == MEDIASUBTYPE_Overlay) {
        NOTE("Receive called for overlay");
        return VFW_E_NOT_SAMPLE_CONNECTION;
    }

    HRESULT hr = VFW_E_SAMPLE_REJECTED;


    // When we receive a sample we must pass it to our allocator first since
    // it may be a DCI/DirectDraw sample that has the display locked. If it
    // isn't then we pass it to our base pin class so that it can reject it
    // if we are currently flushing, it will also check the type to see if it
    // is being changed dynamically. Our allocator OnReceive method returns
    // an error if the sample still requires further processing (drawing)

    // Pass to our allocator in case it's DCI/DirectDraw

    if (m_DrawVideo.UsingImageAllocator() == TRUE) {
        hr = m_VideoAllocator.OnReceive(pSample);
    }

    // DEADLOCK Do NOT lock the renderer before having our allocator free
    // the display (if it's a DCI/DirectDraw sample). This is because a
    // state change might get in while you are waiting to get the lock.
    // State changes show and hide the video window which will wait until
    // the display is unlocked but that can't happen because the source
    // thread can't get in while the state change thread has the lock

    //
    // Frame step
    //
    // This code acts as a gate - for a frame step of N frames
    // it discards N-1 frames and then lets the Nth frame thru the
    // the gate to be renderer in the normal way i.e. at the correct
    // time.  The next time Receive is called the gate is shut and
    // the thread blocks.  The gate only opens again when the step
    // is cancelled or another frame step request comes in.
    //
    // StEstrop - Thu 10/21/1999
    //

    {
        //
        // do we have frames to discard ?
        //

        CAutoLock cLock(&m_FrameStepStateLock);
        if (m_lFramesToStep > 1) {
            m_lFramesToStep--;
            if (m_lFramesToStep > 0) {
                return NOERROR;
            }
        }
    }

    // Have we finished with this sample - this is the case when
    // we are in sync-on-fill mode.  In which case the sample has
    // already been made visible, so we just need to complete the
    // frame steping part of the procedure.

    if (hr == VFW_S_NO_MORE_ITEMS) {

        // Store the media times from this sample
        if (m_pPosition)
            m_pPosition->RegisterMediaTime(pSample);

        FrameStep();
        return NOERROR;
    }
    hr = CBaseVideoRenderer::Receive(pSample);
    FrameStep();

    return hr;
}


// Use the image just delivered to display a poster frame

void CRenderer::OnReceiveFirstSample(IMediaSample *pMediaSample)
{
    DoRenderSample(pMediaSample);
}


// A filter can have four discrete states, namely Stopped, Running, Paused,
// Intermediate. We show the window in Paused, Running states and optionally
// in Stopped state. We are in an intermediate state if we are currently
// trying to pause but haven't yet got the first sample (or if we have been
// flushed in paused state and therefore still have to wait for an image)
//
// This class contains an event called m_evComplete which is signalled when
// the current state is completed and is not signalled when we are waiting to
// complete the last state transition. As mentioned above the only time we
// use this at the moment is when we wait for a media sample in paused state
// If while we are waiting we receive an end of stream notification from the
// source filter then we know no data is imminent so we can reset the event
// This means that when we transition to paused the source filter must call
// end of stream on us or send us an image otherwise we'll hang indefinately
//
// We create ourselves a window and two drawing device contexts right at the
// start and only delete them when the whole filter is finally released. This
// is because a window is not a large nor exclusive holder of system resources
//
// When a connection is made we create any palette required and install them
// into the drawing device contexts. We may require these resources when we
// are stopped as we could be embedded in a compound document (in which case
// we would probably use their window) and have to display a poster image


// The auto show flag is used to have the window shown automatically when we
// change state. We do this only when moving to paused or running, when there
// is no outstanding EC_USERABORT set and when the window is not already up
// This can be changed through the IVideoWindow interface AutoShow property.
// If the window is not currently visible then we are showing it because of
// a state change to paused or running, in which case there is no point in
// the video window sending an EC_REPAINT as we're getting an image anyway

void CRenderer::AutoShowWindow()
{
    HWND hwnd = m_VideoWindow.GetWindowHWND();
    NOTE("AutoShowWindow");

    if (m_VideoWindow.IsAutoShowEnabled() == TRUE) {
        if (m_bAbort == FALSE) {
            if (IsWindowVisible(hwnd) == FALSE) {
                NOTE("Executing AutoShowWindow");
                SetRepaintStatus(FALSE);
                m_VideoWindow.PerformanceAlignWindow();
                m_VideoWindow.DoShowWindow(SW_SHOWNORMAL);
                m_VideoWindow.DoSetWindowForeground(TRUE);
            }
        }
    }
}


// If we are being pausing and there's no sample waiting then don't complete
// the transition and return S_FALSE until the first one arrives. However if
// the m_bAbort flag has been set (perhaps the user closed the window) then
// all samples are rejected so there is no point waiting for one. If we do
// have an image then return S_OK (NOERROR). At the moment we'll only return
// VFW_S_STATE_INTERMEDIATE from GetState if an incomplete pause has occured

// Here are some reasons why we should complete a state change
//      The input pin is not connected
//      The user aborted a playback
//      We have an overlay connection
//      We have sent an end of stream
//      There is a fresh sample pending
//      The overlay surface is showing

HRESULT CRenderer::CompleteStateChange(FILTER_STATE OldState)
{
    NOTE("CompleteStateChange");

    // Allow us to be paused when disconnected or windowless

    if (m_InputPin.IsConnected() == FALSE || m_bAbort) {
        NOTE("Not connected");
        Ready();
        return S_OK;
    }

    // Ready if we have an overlay connection

    GUID SubType = *m_mtIn.Subtype();
    if (SubType == MEDIASUBTYPE_Overlay) {
        NOTE("Overlay");
        Ready();
        return S_OK;
    }

    // Have we run off the end of stream

    if (IsEndOfStream() == TRUE) {
        NOTE("End of stream");
        Ready();
        return S_OK;
    }

    // Complete the state change if we have a sample

    if (m_VideoAllocator.IsSamplePending() == FALSE) {
        if (m_DirectDraw.IsOverlayComplete() == FALSE) {
            if (HaveCurrentSample() == FALSE) {
                NOTE("No data");
                NotReady();
                return S_FALSE;
            }
        }
    }

    // Check the previous state

    if (OldState == State_Stopped) {
        NOTE("Stopped");
        NotReady();
        return S_FALSE;
    }

    Ready();
    return S_OK;
}

// Override Inactive() to avoid freeing the sample if we own the
// allocator - this makes repaints easier
HRESULT CRenderer::Inactive()
{
    //  Do part of what the base class does
    if (m_pPosition) {
        m_pPosition->ResetMediaTime();
    }

    //  don't free the sample if it's our allocator
    if (&m_VideoAllocator != m_InputPin.Allocator())
    {
        ClearPendingSample();
    }
    return S_OK;
}

// Overrides the filter interface Stop method, after stopping the base class
// (which calls Inactive on all the CBasePin objects) we stop worker threads
// from waiting in our object, then we stop streaming thereby cancelling any
// clock advisory connection and signal that our state change is completed
// We also decommit the allocator we're using so that threads waiting in the
// GetBuffer will be released, any further Receive calls will be rejected

STDMETHODIMP CRenderer::Stop()
{
    CAutoLock cInterfaceLock(&m_InterfaceLock);
    NOTE("Changing state to stopped");

#if 0  // Video Renderer resets MV bit ONLY in the destructor
    //
    // Release the copy protection key now
    //
    if (! m_MacroVision.StopMacroVision(m_VideoWindow.GetWindowHWND()) )
    {
        DbgLog((LOG_ERROR, 0, TEXT("WARNING: Stopping copy protection failed"))) ;
        return E_UNEXPECTED ; // ??
    }
#endif // #if 0

    CancelStep();
    CBaseVideoRenderer::Stop();
    m_DirectDraw.StartRefreshTimer();

    return NOERROR;
}


// Overrides the filter interface Pause method. In paused states we accept
// samples from the source filter but we won't draw them. So we clear any
// refresh image hanging on from a previous stopped state, inform the video
// window that worker threads are now acceptable and also put the window in
// the foreground. If we haven't an image at the moment then we signal that
// our paused state transition is incomplete, this event will be reset on
// subsequent receipt of an image or if the source sends us end of stream

// When we come out of a stopped state we will release any sample we hold so
// that seeks while stopped actually get to the screen (note we release the
// sample before calling CompleteStateChange). If we have an overlay we must
// also mark it as stale for the same reason. Fortunately when we're stopped
// everyone is reset to the current position so we will get the same frame
// sent to us each time we are paused rather than edging gradually forwards

STDMETHODIMP CRenderer::Pause()
{
    {
        CAutoLock cInterfaceLock(&m_InterfaceLock);
        if (m_State == State_Paused) {
            NOTE("Paused state already set");
            return CompleteStateChange(State_Paused);
        }
	
        // Are we just going through the motions
	
        if (m_pInputPin->IsConnected() == FALSE) {
            NOTE("No pin connection");
            m_State = State_Paused;
            return CompleteStateChange(State_Paused);
        }
	
        // Make sure the overlay gets updated
        if (m_State == State_Stopped) {
            m_hEndOfStream = NULL;
            m_DirectDraw.OverlayIsStale();
        }
	
        CBaseVideoRenderer::Pause();
	
        // We must start the refresh timer after we've committed the allocator
        // Otherwise the DirectDraw code looks to see what surfaces have been
        // allocated, and in particular to see if we're using overlays, finds
        // that none have been created and so won't bother starting the timer
	
        m_DirectDraw.StartRefreshTimer();
    }
    //  DON'T hold the lock while doing these window operations
    //  If we do then we can hang if the window thread ever grabs it
    //  because some of these operation do SendMessage to our window
    //  (it's that simple - think about it)
    //  This should be safe because all this stuff really only references
    //  m_hwnd which doesn't change for the lifetime of this object
    AutoShowWindow();
    return (CheckReady() ? S_OK : S_FALSE);
}


// When we start running we do everything in the base class. If we are using
// overlays then we release the source thread as it is probably waiting. The
// base class doesn't do this in StartStreaming because we don't have samples
// for sync on fill surfaces (remember they do their wait in GetBuffer). We
// must mark the status as changed as we may have used a different format in
// paused mode (for primary surfaces we typically drop back to drawing DIBs)

STDMETHODIMP CRenderer::Run(REFERENCE_TIME StartTime)
{
    CAutoLock cInterfaceLock(&m_InterfaceLock);
    if (m_State == State_Running) {
        NOTE("State set");
        return NOERROR;
    }

    // Send EC_COMPLETE if we're not connected

    if (m_pInputPin->IsConnected() == FALSE) {
        NOTE("No pin connection");
        m_State = State_Running;
        NotifyEvent(EC_COMPLETE,S_OK,0);
        return NOERROR;
    }

    NOTE("Changing state to running");
    CBaseVideoRenderer::Run(StartTime);
    m_DirectDraw.StopRefreshTimer();
    m_VideoAllocator.StartStreaming();

    AutoShowWindow();

    return NOERROR;
}

// We only support one input pin and it is numbered zero

CBasePin *CRenderer::GetPin(int n)
{
    ASSERT(m_pInputPin);
    ASSERT(n == 0);
    return m_pInputPin;
}


// This is called with an IMediaSample interface on the image to be drawn. We
// decide on the drawing mechanism based on who's allocator we are using and
// whether the buffer should be handed to DirectDraw or not. We may be called
// indirectly when the window wants an image repainted by WM_PAINT messages
// We can't realise our palette here because this could be the source thread

HRESULT CRenderer::DoRenderSample(IMediaSample *pMediaSample)
{
    CAutoLock cWindowLock(m_VideoWindow.LockWindowUpdate());

    // Hand the buffer to GDI if not DirectDraw

    if (m_VideoAllocator.GetDirectDrawStatus() == FALSE) {
        m_DrawVideo.DrawImage(pMediaSample);
        return NOERROR;
    }

    // Have DirectDraw render the sample

    m_DrawVideo.NotifyStartDraw();
    CVideoSample *pVideoSample = (CVideoSample *) pMediaSample;
    ASSERT(pVideoSample->GetDirectBuffer() == NULL);
    m_DirectDraw.DrawImage(pMediaSample);
    m_DrawVideo.NotifyEndDraw();

    return NOERROR;
}


// Called when we receive a WM_TIMER message - we cannot synchronise with any
// state changes as the window thread cannot ever capture the interface lock
// Therefore we just call the methods and take our chances. We use a timer in
// two ways, first to update overlay positions when paused, and second to try
// and switch back to using DirectDraw periodically after going to a DOS box

BOOL CRenderer::OnTimer(WPARAM wParam)
{
    NOTE("OnTimer");

    // This is used to update overlay transports

    if (*m_mtIn.Subtype() == MEDIASUBTYPE_Overlay) {
        NOTE("IOverlay timer");
        return m_Overlay.OnUpdateTimer();
    }

    // See if the surface is still busy

    if (wParam == INFINITE) {
        NOTE("Surface busy timer");
        return m_DirectDraw.OnUpdateTimer();
    }

    // Update any overlay surface we have

    if (IsStreaming() == FALSE) {
        if (m_DirectDraw.OnTimer() == FALSE) {
            NOTE("Timer repaint");
            SendRepaint();
        }
    }
    return TRUE;
}


// This is called when we receive a WM_PAINT message which informs us some of
// the window's client area has become exposed. If we have a connected source
// filter doing colour key work then we always repaint the background window.
// The invalid window region is validated before we are called, we must make
// sure to do this validation before drawing otherwise we will not paint the
// window correctly. If we send an EC_REPAINT to the filter graph we set an
// event so that we don't send another until correct receipt of a new sample

// Without the event we can get into an awful state where the filtergraph is
// executing a repaint by stopping and then pausing us. The pause clears any
// image we have held onto. Then another WM_PAINT comes in, it sees that no
// image is available and sends another EC_REPAINT! This cycles through in a
// race condition until hopefully the user stops dragging another window over
// ours. The mass of EC_REPAINTs causes wild disk thrashing as we seek over
// and over again trying to set the correct start position and play a frame

BOOL CRenderer::OnPaint(BOOL bMustPaint)
{
    // Can the overlay object do anything with the paint

    if (m_Overlay.OnPaint() == TRUE) {
        return TRUE;
    }

    // The overlay object did not paint it's colour therefore we go through
    // here and lock ourselves up so that we see if we have a DIB sample to
    // draw with. If we have no sample then if we are not streaming we will
    // notify the filtergraph with an EC_REPAINT, this causes the graph to
    // be paused so we will get an image through to use in further paints

    CAutoLock cSampleLock(&m_RendererLock);

    // If we're not using DirectDraw grab the sample and repaint it if
    // we can
    if (!m_VideoAllocator.GetDirectDrawStatus()) {
        if (m_pMediaSample == NULL) {
            if (m_DrawVideo.UsingImageAllocator()) {
                IMediaSample *pSample;

                //  Call the base class to avoid locking issues
                m_VideoAllocator.CBaseAllocator::GetBuffer(&pSample, NULL, NULL, AM_GBF_NOWAIT);
                if (pSample) {
                    BOOL bResult = (S_OK == DoRenderSample(pSample));


                    // Disable NotifyRelease for Ksproxy
                    IMemAllocatorNotifyCallbackTemp * TempNotify = m_VideoAllocator.InternalGetAllocatorNotifyCallback();
                    m_VideoAllocator.InternalSetAllocatorNotifyCallback((IMemAllocatorNotifyCallbackTemp *) NULL);

                    pSample->Release();

                    // Re-enable NotifyRelease for Ksproxy
                    m_VideoAllocator.InternalSetAllocatorNotifyCallback(TempNotify);

                    return bResult;
                }
            }
        } else {
            return (DoRenderSample(m_pMediaSample) == S_OK);
        }
    } else {
        // Can the DirectDraw object do anything useful
	
        if (m_DirectDraw.OnPaint(m_pMediaSample) == TRUE) {
            return TRUE;
        }
    }


    // Fill the target area with the current background colour

    BOOL bOverlay = (*m_mtIn.Subtype() == MEDIASUBTYPE_Overlay);
    if (IsStreaming() == FALSE || m_bAbort || IsEndOfStream() || bOverlay || bMustPaint) {
        m_VideoWindow.EraseVideoBackground();
    }

    // No new data to paint with so signal the filtergraph that another image
    // is required, this has the filtergraph component set the whole graph to
    // a paused state which causes us to receive an image. This function must
    // be asynchronous otherwise the window will stop responding to the user

    if (!IsFrameStepEnabled()) {
        SendRepaint();
    }
    return TRUE;
}


// Filter input pin constructor

CVideoInputPin::CVideoInputPin(CRenderer *pRenderer,   // Main video renderer
                               CCritSec *pLock,        // Object to lock with
                               HRESULT *phr,           // Constructor code
                               LPCWSTR pPinName) :     // Actual pin name

    CRendererInputPin(pRenderer,phr,pPinName),
    m_pInterfaceLock(pLock),
    m_pRenderer(pRenderer)
{
    ASSERT(m_pRenderer);
    ASSERT(m_pInterfaceLock);
    SetReconnectWhenActive(true);
}

STDMETHODIMP
CVideoInputPin::ReceiveConnection(
    IPin * pConnector,          // this is the pin who we will connect to
    const AM_MEDIA_TYPE *pmt    // this is the media type we will exchange
)
{
    CAutoLock lck(m_pLock); // This is the interface lock.

    ASSERT(pConnector);
    if(pConnector != m_Connected)
    {
        // We have a window, figure out what monitor it's on (multi-monitor)
        // NULL means we aren't running with multiple monitors
        m_pRenderer->GetCurrentMonitor();

        // Now that we know what monitor we're on, setup for using it
        m_pRenderer->m_Display.RefreshDisplayType(m_pRenderer->m_achMonitor);

        return CRendererInputPin::ReceiveConnection(pConnector, pmt);
    }

    else

    {
        CMediaType cmt(*pmt);
        HRESULT hr = CheckMediaType(&cmt);
        ASSERT(hr == S_OK);
        if(hr == S_OK)
        {
            hr =  m_pRenderer->ResetForDfc();
            if(SUCCEEDED(hr))
            {
                hr = m_pRenderer->SetMediaType(&cmt);
            }
            if(SUCCEEDED(hr))
            {
                VIDEOINFO *pVideoInfo = (VIDEOINFO *) m_pRenderer->m_mtIn.Format();

                // Has the video size changed between connections

                if (pVideoInfo->bmiHeader.biWidth == m_pRenderer->m_VideoSize.cx &&
                    pVideoInfo->bmiHeader.biHeight == m_pRenderer->m_VideoSize.cy)
                {
                        NOTE("No size change");
                }
                else
                {
                    // Set properties for the current video
                    //
                    //
                    // !!! doesn't seem to do anything
                    //
                    //

                    m_pRenderer->m_VideoSize.cx = pVideoInfo->bmiHeader.biWidth;
                    m_pRenderer->m_VideoSize.cy = pVideoInfo->bmiHeader.biHeight;
                    m_pRenderer->m_VideoWindow.SetDefaultSourceRect();
                    m_pRenderer->m_VideoWindow.SetDefaultTargetRect();
                    m_pRenderer->m_VideoWindow.OnVideoSizeChange();
                }
            }
        }
        else
        {
            DbgBreak("??? CheckMediaType failed in dfc ReceiveConnection.");
            hr = E_UNEXPECTED;
        }

        return hr;
    }
}


// Overrides the CRendererInputPin virtual method to return our allocator
// we create to pass shared memory DIB buffers that GDI can directly access
// When NotifyAllocator is called it sets the current allocator in the base
// input pin class (m_pAllocator), this is what GetAllocator should return
// unless it is NULL in which case we return the allocator we would like

STDMETHODIMP CVideoInputPin::GetAllocator(IMemAllocator **ppAllocator)
{
    CAutoLock cInterfaceLock(m_pInterfaceLock);

    // Check we don't have an overlay connection

    if (*m_pRenderer->m_mtIn.Subtype() == MEDIASUBTYPE_Overlay) {
        NOTE("GetAllocator for overlay");
        return VFW_E_NOT_SAMPLE_CONNECTION;
    }

    // Has an allocator been set yet in the base class

    if (m_pAllocator == NULL) {
        m_pAllocator = &m_pRenderer->m_VideoAllocator;
        m_pAllocator->AddRef();
    }

    m_pAllocator->AddRef();
    *ppAllocator = m_pAllocator;
    return NOERROR;
}


// Notify us which allocator the output pin has decided that we should use
// The COM specification says any two IUnknown pointers to the same object
// should always match which provides a way for us to see if they are using
// our DIB allocator or not. Since we are only really interested in equality
// and our object always hands out the same IMemAllocator interface we can
// just see if the pointers match. If they are we set a flag in the main
// renderer as the window needs to know whether it can do fast rendering

STDMETHODIMP
CVideoInputPin::NotifyAllocator(IMemAllocator *pAllocator,BOOL bReadOnly)
{
    CAutoLock cInterfaceLock(m_pInterfaceLock);

    // Check we don't have an overlay connection

    if (*m_pRenderer->m_mtIn.Subtype() == MEDIASUBTYPE_Overlay) {
        NOTE("NotifyAllocator on overlay");
        return VFW_E_NOT_SAMPLE_CONNECTION;
    }

    // Make sure the base class gets a look

    HRESULT hr = CRendererInputPin::NotifyAllocator(pAllocator,bReadOnly);
    if (FAILED(hr)) {
        return hr;
    }

    // Whose allocator is the source going to use

    m_pRenderer->m_DrawVideo.NotifyAllocator(FALSE);
    if (pAllocator == &m_pRenderer->m_VideoAllocator) {
        m_pRenderer->m_DrawVideo.NotifyAllocator(TRUE);
    }

    return NOERROR;
}


// Overriden to expose our IOverlay pin transport

STDMETHODIMP CVideoInputPin::NonDelegatingQueryInterface(REFIID riid,VOID **ppv)
{
    if (riid == IID_IOverlay) {
        return m_pRenderer->m_Overlay.QueryInterface(riid,ppv);
    } else
    if (riid == IID_IPinConnection) {
        return GetInterface((IPinConnection *)this, ppv);
    } else {
        return CBaseInputPin::NonDelegatingQueryInterface(riid,ppv);
    }
}

//  Do you accept this type chane in your current state?
STDMETHODIMP CVideoInputPin::DynamicQueryAccept(const AM_MEDIA_TYPE *pmt)
{
    //return E_FAIL;
    CheckPointer(pmt, E_POINTER);

    //  BUGBUG - what locking should we do?
    CMediaType cmt(*pmt);
    HRESULT hr = m_pRenderer->CheckMediaType(&cmt);
    if (SUCCEEDED(hr) && hr != S_OK ||
        (hr == E_FAIL) ||
        (hr == E_INVALIDARG)) {
        hr = VFW_E_TYPE_NOT_ACCEPTED;
    }

    return hr;
}

//  Set event when EndOfStream receive - do NOT pass it on
//  This condition is cancelled by a flush or Stop
STDMETHODIMP CVideoInputPin::NotifyEndOfStream(HANDLE hNotifyEvent)
{
    return m_pRenderer->NotifyEndOfStream(hNotifyEvent);
}

STDMETHODIMP CVideoInputPin::DynamicDisconnect()
{
    CAutoLock cObjectLock(m_pLock);
    return CBasePin::DisconnectInternal();
}

//  Are you an 'end pin'
STDMETHODIMP CVideoInputPin::IsEndPin()
{
    return S_OK;
}

// This is overriden from the base draw class to change the source rectangle
// that we do the drawing with. For example a renderer may ask a decoder to
// stretch the video from 320x240 to 640x480, in which case the rectangle we
// see in here will still be 320x240, although the source we really want to
// draw with should be scaled up to 640x480. The base class implementation of
// this method does nothing but return the same rectangle as it is passed in

CDrawVideo::CDrawVideo(CRenderer *pRenderer,CBaseWindow *pBaseWindow) :
    CDrawImage(pBaseWindow),
    m_pRenderer(pRenderer)
{
    ASSERT(pBaseWindow);
    ASSERT(m_pRenderer);
}


// We override this from the base class to accomodate codec stretching. What
// happens is that the native video size remains constant in the m_VideoSize
// but the bitmap size changes in the actual video format. When we come to
// draw the image we must scale the logical source rectangle to account for
// the larger or smaller real bitmap (and also round against the dimensions)

RECT CDrawVideo::ScaleSourceRect(const RECT *pSource)
{
    NOTE("Entering ScaleSourceRect");
    RECT Source = *pSource;

    // Is the codec providing a stretched video format

    VIDEOINFO *pVideoInfo = (VIDEOINFO *) m_pRenderer->m_mtIn.Format();
    if (pVideoInfo->bmiHeader.biWidth == m_pRenderer->m_VideoSize.cx) {
        if (pVideoInfo->bmiHeader.biHeight == m_pRenderer->m_VideoSize.cy) {
            NOTE("No codec stretch");
            SetStretchMode();
            return Source;
        }
    }

    // Make sure we don't round beyond the actual bitmap dimensions

    Source.left = (Source.left * pVideoInfo->bmiHeader.biWidth);
    Source.left = min((Source.left / m_pRenderer->m_VideoSize.cx),pVideoInfo->bmiHeader.biWidth);
    Source.right = (Source.right * pVideoInfo->bmiHeader.biWidth);
    Source.right = min((Source.right / m_pRenderer->m_VideoSize.cx),pVideoInfo->bmiHeader.biWidth);
    Source.top = (Source.top * pVideoInfo->bmiHeader.biHeight);
    Source.top = min((Source.top / m_pRenderer->m_VideoSize.cy),pVideoInfo->bmiHeader.biHeight);
    Source.bottom = (Source.bottom * pVideoInfo->bmiHeader.biHeight);
    Source.bottom = min((Source.bottom / m_pRenderer->m_VideoSize.cy),pVideoInfo->bmiHeader.biHeight);
    NOTERC("Scaled source",Source);

    // Calculate the stretching requirements each time through

    LONG SourceWidth = Source.right - Source.left;
    LONG SinkWidth = m_TargetRect.right - m_TargetRect.left;
    LONG SourceHeight = Source.bottom - Source.top;
    LONG SinkHeight = m_TargetRect.bottom - m_TargetRect.top;

    m_bStretch = TRUE;
    if (SourceWidth == SinkWidth) {
        if (SourceHeight == SinkHeight) {
            NOTE("No stretching");
            m_bStretch = FALSE;
        }
    }
    return Source;
}


#ifdef DEBUG

// Display a palette composed of an array of RGBQUAD structures

void CRenderer::DisplayGDIPalette(const CMediaType *pmt)
{
    VIDEOINFO *pVideoInfo = (VIDEOINFO *) pmt->Format();
    DWORD dwColours = pVideoInfo->bmiHeader.biClrUsed;
    NOTE1("DisplayGDIPalette (%d colours)",dwColours);
    TCHAR strLine[256];

    // The number of colours may be zero to mean all available
    if (dwColours == 0) dwColours = (1 << pVideoInfo->bmiHeader.biBitCount);

    for (DWORD dwLoop = 0;dwLoop < dwColours;dwLoop++) {

        wsprintf(strLine,TEXT("%d) Red %d Green %d Blue %d"),dwLoop,
                 pVideoInfo->bmiColors[dwLoop].rgbRed,
                 pVideoInfo->bmiColors[dwLoop].rgbGreen,
                 pVideoInfo->bmiColors[dwLoop].rgbBlue);

        DbgLog((LOG_TRACE, 5, strLine));
    }
}

#endif // DEBUG


// Overriden to realise the palette before drawing. We have to do this for
// every image because Windows gets confused with us only realising on the
// window thread (there appears to be some thread specific state in GDI)
// Fortunately the realisation doesn't cause a thread switch so it should
// be relatively cheap (cheaper than sending a WM_QUERYNEWPALETTE anyway)

void CRenderer::PrepareRender()
{
    // Realise the palette on this thread
    m_VideoWindow.DoRealisePalette();

    // Calculate the top level parent window

//  HWND hwndTopLevel = hwnd;
//  while (hwnd = GetParent(hwndTopLevel)) {
//      hwndTopLevel = hwnd;
//  }
//
//  NOTE1("IsForegroundWindow %d",(GetForegroundWindow() == hwnd));
//  NOTE1("Foreground window %d",GetForegroundWindow());
//  NOTE1("Active window %d",GetActiveWindow());
//  BOOL bTopLevel = (GetForegroundWindow() == hwndTopLevel);
//  NOTE1("Foreground parent %d",bTopLevel);

}



// --------------------------------------------------------------------
//  IKsPropertySet interface methods -- mainly for MacroVision support
// --------------------------------------------------------------------

//
// Set() is supported only for _CopyProt prop set and MACROVISION id.
//
STDMETHODIMP
CRenderer::Set(
    REFGUID guidPropSet,
    DWORD dwPropID,
    LPVOID pInstanceData,
    DWORD cbInstanceLength,
    LPVOID pPropData,
    DWORD cbPropData
    )
{
    DbgLog((LOG_TRACE, 5, TEXT("CRenderer::Set()"))) ;


    if (guidPropSet == AM_KSPROPSETID_FrameStep)
    {
        if (dwPropID != AM_PROPERTY_FRAMESTEP_STEP &&
            dwPropID != AM_PROPERTY_FRAMESTEP_CANCEL &&
            dwPropID != AM_PROPERTY_FRAMESTEP_CANSTEP &&
            dwPropID != AM_PROPERTY_FRAMESTEP_CANSTEPMULTIPLE)
        {
            return E_PROP_ID_UNSUPPORTED;
        }

        switch (dwPropID) {
        case AM_PROPERTY_FRAMESTEP_STEP:
            if (cbPropData < sizeof(AM_FRAMESTEP_STEP))
            {
                return E_INVALIDARG;
            }

            if (1 != ((AM_FRAMESTEP_STEP *)pPropData)->dwFramesToStep)
            {
                return E_INVALIDARG;
            }
            else
            {
                CAutoLock cInterfaceLock(&m_InterfaceLock);
                CAutoLock cFrameStepStateLock(&m_FrameStepStateLock);

                long l = m_lFramesToStep;
                m_lFramesToStep = ((AM_FRAMESTEP_STEP *)pPropData)->dwFramesToStep;

                //
                // If we are currently blocked on the frame step event
                // release the receive thread so that we can get another
                // frame
                //

                if (l == 0) {

                    SetEvent(m_StepEvent);
                }
            }
            return S_OK;


        case AM_PROPERTY_FRAMESTEP_CANCEL:
            {
                CAutoLock cLock(&m_InterfaceLock);

                CancelStep();
            }
            return S_OK;

        case AM_PROPERTY_FRAMESTEP_CANSTEP:
            if (*m_mtIn.Subtype() != MEDIASUBTYPE_Overlay)
                return S_OK;

        case AM_PROPERTY_FRAMESTEP_CANSTEPMULTIPLE:
            return S_FALSE;
        }
    }


    if (guidPropSet != AM_KSPROPSETID_CopyProt)
        return E_PROP_SET_UNSUPPORTED ;

    if (dwPropID != AM_PROPERTY_COPY_MACROVISION)
        return E_PROP_ID_UNSUPPORTED ;

    if (pPropData == NULL)
        return E_INVALIDARG ;

    if (cbPropData < sizeof(DWORD))
        return E_INVALIDARG ;

    if (m_MacroVision.SetMacroVision(m_VideoWindow.GetWindowHWND(),
									 *((LPDWORD)pPropData)))
        return NOERROR ;
    else
        return VFW_E_COPYPROT_FAILED ;
}


//
// Get() not supported for now.
//
STDMETHODIMP
CRenderer::Get(
    REFGUID guidPropSet,
    DWORD dwPropID,
    LPVOID pInstanceData,
    DWORD cbInstanceLength,
    LPVOID pPropData,
    DWORD cbPropData,
    DWORD *pcbReturned
    )
{
    DbgLog((LOG_TRACE, 5, TEXT("CRenderer::Get()"))) ;
    return E_NOTIMPL ;
}


//
// Only supports Macrovision property -- returns S_OK for Set only.
//
STDMETHODIMP
CRenderer::QuerySupported(
    REFGUID guidPropSet,
    DWORD dwPropID,
    ULONG *pTypeSupport
    )
{
    DbgLog((LOG_TRACE, 5, TEXT("CRenderer::QuerySupported()"))) ;


    if (guidPropSet == AM_KSPROPSETID_FrameStep)
    {

        BOOL bOverlay = (*m_mtIn.Subtype() == MEDIASUBTYPE_Overlay);

        if (bOverlay) {
            return E_PROP_ID_UNSUPPORTED;
        }

        if (dwPropID != AM_PROPERTY_FRAMESTEP_STEP &&
            dwPropID != AM_PROPERTY_FRAMESTEP_CANCEL)
        {
            return E_PROP_ID_UNSUPPORTED;
        }

        if (pTypeSupport)
        {
            *pTypeSupport = KSPROPERTY_SUPPORT_SET ;
        }

        return S_OK;
    }

    if (guidPropSet != AM_KSPROPSETID_CopyProt)
        return E_PROP_SET_UNSUPPORTED ;

    if (dwPropID != AM_PROPERTY_COPY_MACROVISION)
        return E_PROP_ID_UNSUPPORTED ;

    if (pTypeSupport)
        *pTypeSupport = KSPROPERTY_SUPPORT_SET ;

    return S_OK;
}
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\multimedia\dshow\filters\image\video\vrmacvis.cpp ===
// Copyright (c) 1997 - 1999  Microsoft Corporation.  All Rights Reserved.
//
// VRMacVis.cpp:  Video Renderer's Macrovision support code
//

#include <streams.h>
#include <windowsx.h>

#include <atlconv.h>
#include "render.h"
#include "MultMon.h"  // our version of multimon.h include ChangeDisplaySettingsEx

CRendererMacroVision::CRendererMacroVision(void)
{
    DbgLog((LOG_TRACE, 5, TEXT("CRendererMacroVision::CRendererMacroVision()"))) ;
    m_dwCPKey = 0 ;
    m_hWndCP  = NULL ;
    m_hMon    = NULL ;
}


CRendererMacroVision::~CRendererMacroVision(void)
{
    DbgLog((LOG_TRACE, 5, TEXT("CRendererMacroVision::~CRendererMacroVision()"))) ;
    ASSERT(0 == m_dwCPKey  &&  NULL == m_hWndCP  &&  NULL == m_hMon) ;
}


BOOL
CRendererMacroVision::StopMacroVision(HWND hWnd)
{
    DbgLog((LOG_TRACE, 5, TEXT("CRendererMacroVision::StopMacroVision(0x%p)"),
            (void *) hWnd)) ;

    if (0 == m_dwCPKey)
    {
        DbgLog((LOG_TRACE, 3, TEXT("Copy prot key was not acquired. Nothing to release."))) ;
        return TRUE ;  // success, what else?
    }

    if (NULL == m_hWndCP)
    {
        DbgLog((LOG_ERROR, 0, TEXT("WARNING: No hWnd available while MV bit was already set."))) ;
        return TRUE ;  // FALSE??
    }

    LONG             lRet ;
    VIDEOPARAMETERS  VidParams ;
    DEVMODEA         DevMode ;
    DISPLAY_DEVICE   dd ;
    ZeroMemory(&dd, sizeof(dd)) ;
    dd.cb = sizeof(dd) ;

    // If we have come here then Macrovision is ON, and that means we must have
    // a valid monitor handle.  Let's use that rather than finding it via
    // MonitorFromWindow() call, which seems to fail at this stage (specially
    // when the player app is closed).
    ASSERT(m_hMon) ;
    HMONITOR hMon = m_hMon ;
    if (NULL == hMon)
    {
        DbgLog((LOG_ERROR, 0, TEXT("Cached monitor handle is NULL!!!"))) ;
        return FALSE ;
    }

    MONITORINFOEX  mi ;
    mi.cbSize = sizeof(mi) ;
    if (! GetMonitorInfo(hMon, &mi) )
    {
        DbgLog((LOG_ERROR, 0, TEXT("GetMonitorInfo() failed (Error: %ld)"),
                GetLastError())) ;
        return FALSE ;
    }
    DbgLog((LOG_TRACE, 3, TEXT("DeviceName: '%s'"), mi.szDevice)) ;
    ZeroMemory(&DevMode, sizeof(DevMode)) ;
    DevMode.dmSize = sizeof(DevMode) ;

    ZeroMemory(&VidParams, sizeof(VidParams)) ;
    VidParams.Guid      = guidVidParam ;
    VidParams.dwCommand = VP_COMMAND_GET ;

    USES_CONVERSION;
    lRet = ChangeDisplaySettingsExA(T2A(mi.szDevice), &DevMode, NULL,
                                   CDS_VIDEOPARAMETERS | CDS_NORESET | CDS_UPDATEREGISTRY,
                                   &VidParams) ;
    if (DISP_CHANGE_SUCCESSFUL != lRet)
    {
        DbgLog((LOG_ERROR, 0, TEXT("ChangeDisplaySettingsEx(_GET) failed (%ld)"), lRet)) ;
        return FALSE ;
    }

    if (! ( (VidParams.dwFlags & VP_FLAGS_COPYPROTECT) &&
            (VidParams.dwCPType & VP_CP_TYPE_APS_TRIGGER) &&
            (VidParams.dwTVStandard & VidParams.dwCPStandard) ) )
    {
        // How did we acquire CP key in teh first place?
        DbgLog((LOG_ERROR, 0,
            TEXT("Copy prot weird error case (dwFlags=0x%lx, dwCPType=0x%lx, dwTVStandard=0x%lx, dwCPStandard=0x%lx"),
                VidParams.dwFlags, VidParams.dwCPType, VidParams.dwTVStandard, VidParams.dwCPStandard)) ;
        return FALSE ;
    }

    VidParams.dwCommand    = VP_COMMAND_SET ;
    VidParams.dwFlags      = VP_FLAGS_COPYPROTECT ;
    VidParams.dwCPType     = VP_CP_TYPE_APS_TRIGGER ;
    VidParams.dwCPCommand  = VP_CP_CMD_DEACTIVATE ;
    VidParams.dwCPKey      = m_dwCPKey ;
    VidParams.bCP_APSTriggerBits = (BYTE) 0 ;  // some value
    lRet = ChangeDisplaySettingsExA(T2A(mi.szDevice), &DevMode, NULL,
                                   CDS_VIDEOPARAMETERS | CDS_NORESET | CDS_UPDATEREGISTRY,
                                   &VidParams) ;
    if (DISP_CHANGE_SUCCESSFUL != lRet)
    {
        DbgLog((LOG_ERROR, 0, TEXT("ChangeDisplaySettingsEx() failed (%ld)"), lRet)) ;
        return FALSE ;
    }

    DbgLog((LOG_TRACE, 1, TEXT("Macrovision deactivated on key %lu"), m_dwCPKey)) ;
    m_dwCPKey = 0 ;     // no CP set now
    m_hWndCP  = NULL ;  // don't need hWnd anymore
    m_hMon    = NULL ;  // don't need hMon anymore

    return TRUE ;
}


//
// This function applies Macrovision based on the input parameter dwCPBits.
// hWnd is the handle of the window in which content is played back.
//
// Returns TRUE on success and FALSE on any failure.
//
BOOL
CRendererMacroVision::SetMacroVision(HWND hWnd, DWORD dwCPBits)
{
    DbgLog((LOG_TRACE, 5, TEXT("CRendererMacroVision::SetMacroVision(0x%p, 0x%lx)"),
            (void*) hWnd, dwCPBits)) ;

    //
    // If MV is currently not set at all and the new CP bits is 0 (which happens
    // when from the Nav we reset the MV bits on start / stop of playback), we
    // don't really need to do anything -- MV not started and doesn't need to be
    // started.  So just leave queitly...
    //
    if (0 == m_dwCPKey  &&  // no key acquired so far
        0 == dwCPBits)      // MV CPBits is 0
    {
        DbgLog((LOG_TRACE, 1, TEXT("Copy prot is not enabled now and new CP bits is 0 -- so skip it."))) ;
        return TRUE ;  // we don't need to do anything, so success.
    }

    //
    // May be we need to actually do something here
    //
    LONG             lRet ;
    VIDEOPARAMETERS  VidParams ;
    DEVMODEA         DevMode ;
    DISPLAY_DEVICE   dd ;
    ZeroMemory(&dd, sizeof(dd)) ;
    dd.cb = sizeof(dd) ;

    HMONITOR hMon = MonitorFromWindow(hWnd, MONITOR_DEFAULTTONULL) ;
    if (NULL == hMon)
    {
        DbgLog((LOG_ERROR, 0,
                TEXT("MonitorFromWindow(0x%p, ..) returned NULL (Error: %ld)"),
                (void*)hWnd, GetLastError())) ;
        return FALSE ;
    }

    MONITORINFOEX  mi ;
    mi.cbSize = sizeof(mi) ;
    if (! GetMonitorInfo(hMon, &mi) )
    {
        DbgLog((LOG_ERROR, 0, TEXT("GetMonitorInfo() failed (Error: %ld)"),
                GetLastError())) ;
        return FALSE ;
    }
    DbgLog((LOG_TRACE, 3, TEXT("DeviceName: '%s'"), mi.szDevice)) ;

    ZeroMemory(&DevMode, sizeof(DevMode)) ;
    DevMode.dmSize = sizeof(DevMode) ;

    ZeroMemory(&VidParams, sizeof(VidParams)) ;
    VidParams.Guid      = guidVidParam ;
    VidParams.dwCommand = VP_COMMAND_GET ;

    USES_CONVERSION;
    lRet = ChangeDisplaySettingsExA(T2A(mi.szDevice), &DevMode, NULL,
                                   CDS_VIDEOPARAMETERS | CDS_NORESET | CDS_UPDATEREGISTRY,
                                   &VidParams) ;
    if (DISP_CHANGE_SUCCESSFUL != lRet)
    {
        DbgLog((LOG_ERROR, 0, TEXT("ChangeDisplaySettingsEx(_GET) failed (%ld)"), lRet)) ;
        return FALSE ;
    }

    if (0 == VidParams.dwFlags ||
        VP_TV_STANDARD_WIN_VGA == VidParams.dwTVStandard)
    {
        DbgLog((LOG_TRACE, 1, TEXT("** Copy protection NOT required (dwFlags=0x%lx, dwTVStandard=0x%lx"),
                VidParams.dwFlags, VidParams.dwTVStandard));
        return TRUE ;
    }

    //
    // Check to see if
    // a) the device supports copy prot
    // b) CP type is APS trigger
    // c) current TV standard and CP standard have commonality.
    // If so, apply copy prot. Otherwise error.
    //
    if ( (VidParams.dwFlags & VP_FLAGS_COPYPROTECT) &&
         (VidParams.dwCPType & VP_CP_TYPE_APS_TRIGGER) &&
         (VidParams.dwTVStandard & VidParams.dwCPStandard) )
    {
        DbgLog((LOG_TRACE, 3,
            TEXT("** Copy prot needs to be applied (dwFlags=0x%lx, dwCPType=0x%lx, dwTVStandard=0x%lx, dwCPStandard=0x%lx"),
                VidParams.dwFlags, VidParams.dwCPType, VidParams.dwTVStandard, VidParams.dwCPStandard)) ;

        VidParams.dwCommand = VP_COMMAND_SET ;          // do we have to set it again??
        VidParams.dwFlags   = VP_FLAGS_COPYPROTECT ;
        VidParams.dwCPType  = VP_CP_TYPE_APS_TRIGGER ;
        VidParams.bCP_APSTriggerBits = (BYTE) (dwCPBits & 0xFF) ;

        // Check if we already have a copy prot key; if not, get one now
        if (0 == m_dwCPKey)  // no key acquired so far
        {
            // Acquire a new key (that also aplies it, so no separate Set reqd)
            VidParams.dwCPCommand = VP_CP_CMD_ACTIVATE ;
            VidParams.dwCPKey     = 0 ;
            lRet = ChangeDisplaySettingsExA(T2A(mi.szDevice), &DevMode, NULL,
                                           CDS_VIDEOPARAMETERS | CDS_NORESET | CDS_UPDATEREGISTRY,
                                           &VidParams) ;
            if (DISP_CHANGE_SUCCESSFUL != lRet)
            {
                DbgLog((LOG_ERROR, 0,
                    TEXT("** ChangeDisplaySettingsEx() failed (%ld) to activate copy prot"), lRet)) ;
                return FALSE ;
            }

            m_dwCPKey = VidParams.dwCPKey ;
            DbgLog((LOG_TRACE, 3, TEXT("** Copy prot activated. Key value is %lu"), m_dwCPKey)) ;
        }
        else  // key already acquired
        {
            // apply the copy prot bits specified in the content
            VidParams.dwCPCommand = VP_CP_CMD_CHANGE ;
            VidParams.dwCPKey     = m_dwCPKey ;
            DbgLog((LOG_TRACE, 5, TEXT("** Going to call ChangeDisplaySettingsEx(_SET)..."))) ;
            lRet = ChangeDisplaySettingsExA(T2A(mi.szDevice), &DevMode, NULL,
                                           CDS_VIDEOPARAMETERS | CDS_NORESET | CDS_UPDATEREGISTRY,
                                           &VidParams) ;
            if (DISP_CHANGE_SUCCESSFUL != lRet)
            {
                DbgLog((LOG_ERROR, 0,
                    TEXT("** ChangeDisplaySettingsEx() failed (%ld) to set copy prot bits (%lu)"),
                    lRet, dwCPBits)) ;
                return FALSE ;
            }
            else
                DbgLog((LOG_TRACE, 3, TEXT("** Copy prot bits (0x%lx) applied"), dwCPBits)) ;
        }
    }
    else
    {
        DbgLog((LOG_ERROR, 0,
            TEXT("** Copy prot error case (dwFlags=0x%lx, dwCPType=0x%lx, dwTVStandard=0x%lx, dwCPStandard=0x%lx"),
                VidParams.dwFlags, VidParams.dwCPType, VidParams.dwTVStandard, VidParams.dwCPStandard)) ;
        return FALSE ;
    }

    m_hWndCP = hWnd ;  // latest hWnd on which MV bit was set
    m_hMon   = hMon ;  // latest hMon on which MV bit was set

    return TRUE ;
}
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\multimedia\dshow\filters\image\video\vrmacvis.h ===
// Copyright (c) 1997 - 1998  Microsoft Corporation.  All Rights Reserved.
//
// VRMacVis.h: Video Renderer's MacroVision support code header
//

#ifndef __VRMACVIS_H__
#define __VRMACVIS_H__


//
// The magic GUID for Macrovision etc enabling (from winuser.h). It has 
// not been given a name there and so is used here directly.
//
static const GUID guidVidParam = 
    {0x2c62061, 0x1097, 0x11d1, {0x92, 0xf, 0x0, 0xa0, 0x24, 0xdf, 0x15, 0x6e}} ;

//
// Combination of all the VP_TV_XXX flags (w/o _WIN_VGA) gives 0x7FFF
//
#define ValidTVStandard(dw)  (dw & 0x7FFF)

//
// MacroVision implementation wrapped in a class for Video Renderer
//
class CRendererMacroVision {

    public:
        CRendererMacroVision(void) ;
        ~CRendererMacroVision(void) ;

        BOOL  SetMacroVision(HWND hWnd, DWORD dwCPBits) ;
        BOOL  StopMacroVision(HWND hWnd) ;
        HWND  GetCPHWND(void)   { return m_hWndCP ; }

    private:
        DWORD  m_dwCPKey ;
        HWND   m_hWndCP ;
        HMONITOR m_hMon ;
} ;

#endif // __VRMACVIS_H__
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\multimedia\dshow\filters\image\video\window.h ===
// Copyright (c) 1994 - 1998  Microsoft Corporation.  All Rights Reserved.
// Defines a window management object, Anthony Phillips, January 1995

#ifndef __WINDOW__
#define __WINDOW__

// This class looks after the management of a video window. When the window
// object is first created the constructor spawns off a worker thread that
// does all the window work. The original thread waits until it is signaled
// to continue. The worker thread firstly registers the window class if it
// is not already done. Then it creates a window and sets it's size to match
// the video dimensions (the dimensions are returned through GetDefaultRect)

// Notice that the worker thread MUST be the thread that creates the window
// as it is the one who calls GetMessage. When it has done all this it will
// signal the original thread which lets it continue, this ensures a window
// is created and valid before the constructor returns. The thread's start
// address is the WindowMessageLoop function. The thread's parameter we pass
// it is the CBaseWindow this pointer for the window object that created it

#define WindowClassName TEXT("VideoRenderer")

// The window class name isn't used only as a class name for the base window
// classes, it is also used by the overlay selection code as a name to base
// a mutex creation on. Basicly it has a shared memory block where the next
// available overlay colour is returned from. The creation and preparation
// of the shared memory must be serialised through all ActiveMovie instances


class CVideoWindow : public CBaseControlWindow, public CBaseControlVideo
{
    CRenderer *m_pRenderer;             // The owning renderer object
    BOOL m_bTargetSet;                  // Do we use the default rectangle
    CCritSec *m_pInterfaceLock;         // Main renderer interface lock
    HCURSOR m_hCursor;                  // Used to display a normal cursor
    VIDEOINFOHEADER *m_pFormat;		// holds our video format
    int m_FormatSize;			// length of m_pFormat

    // Overriden method to handle window messages
    LRESULT OnReceiveMessage(HWND hwnd,      // Window handle
                             UINT uMsg,      // Message ID
                             WPARAM wParam,  // First parameter
                             LPARAM lParam); // Other parameter

    // Window message handlers

    void OnHookMessage(BOOL bHook);
    void OnWindowFreeze();
    void OnWindowThaw();
    void OnEraseBackground();
    BOOL OnClose();
    LRESULT OnPaletteChange(HWND hwnd, UINT Message);
    void OnPalette();
    BOOL OnPaint();
    BOOL OnSetCursor(LPARAM lParam);
    BOOL OnSize(LONG Width, LONG Height);

public:

    CVideoWindow(CRenderer *pRenderer,      // The owning renderer
                 CCritSec *pLock,           // Object to use for lock
                 LPUNKNOWN pUnk,            // Owning object
                 HRESULT *phr);             // OLE return code

    ~CVideoWindow();

    STDMETHODIMP NonDelegatingQueryInterface(REFIID riid,VOID **ppv);

    // Return the minimum and maximum ideal sizes
    STDMETHODIMP GetMinIdealImageSize(long *pWidth,long *pHeight);
    STDMETHODIMP GetMaxIdealImageSize(long *pWidth,long *pHeight);

    //  IBasicVideo2
    STDMETHODIMP GetPreferredAspectRatio(long *plAspectX, long *plAspectY);

    LPTSTR GetClassWindowStyles(DWORD *pClassStyles,        // Class styles
                                DWORD *pWindowStyles,       // Window styles
                                DWORD *pWindowStylesEx);    // Extended styles

    // These are called by the renderer control interfaces

    HRESULT SetDefaultTargetRect();
    HRESULT IsDefaultTargetRect();
    HRESULT SetTargetRect(RECT *pTargetRect);
    HRESULT GetTargetRect(RECT *pTargetRect);
    HRESULT SetDefaultSourceRect();
    HRESULT IsDefaultSourceRect();
    HRESULT SetSourceRect(RECT *pSourceRect);
    HRESULT GetSourceRect(RECT *pSourceRect);
    HRESULT OnUpdateRectangles();
    HRESULT GetStaticImage(long *pVideoSize,long *pVideoImage);
    VIDEOINFOHEADER *GetVideoFormat();
    RECT GetDefaultRect();
    void SetKeyPalette(HPALETTE hPalette);
    void EraseVideoBackground();

    // Synchronise with decoder thread
    CCritSec *LockWindowUpdate() {
        return (&m_WindowLock);
    };
};

#endif // __WINDOW__
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\multimedia\dshow\filters\image\vidload\vidload.h ===
// Copyright (c) 1994 - 1996  Microsoft Corporation.  All Rights Reserved.
// ActiveMovie video stress application, Anthony Phillips, May 1996

#ifndef _VIDLOAD__
#define _VIDLOAD__

void Log(TCHAR *pFormat,...);
HRESULT ThreadLoadDirectDraw();
DWORD ThreadEntryPoint(LPVOID lpvThreadParm);
void YieldToMessageQueue();
HRESULT RenderMediaFiles(TCHAR *pFile);
DWORD RenderEntryPoint(LPVOID lpvThreadParm);
HRESULT ExclusiveWindowTest();
HRESULT TwoWindowExclusiveTest();
HRESULT ExclusiveThreadWindowTest();
DWORD ExclusiveThreadEntryPoint(LPVOID lpvThreadParm);

#define FrameClass TEXT("ActiveMovieClass")
#define Title TEXT("ActiveMovie Loader Test")
#define ID_LISTBOX 100
#define THREADS 10
#define TIMEOUT 1000

INT PASCAL WinMain(HINSTANCE hInstance,        // This instance identifier
                   HINSTANCE hPrevInstance,    // Previous instance
                   LPSTR lpszCmdLine,          // Command line parameters
                   INT nCmdShow);              // Initial display mode

LRESULT CALLBACK FrameWndProc(HWND hwnd,        // Our window handle
                              UINT message,     // Message information
                              UINT wParam,      // First parameter
                              LONG lParam);     // And other details

// Derived class for our windows. To access DirectDraw Modex we supply it
// with a window, this is granted exclusive mode access rights. DirectDraw
// hooks the window and manages a lot of the functionality associated with
// handling Modex. For example when you switch display modes it maximises
// the window, when the user hits ALT-TAB the window is minimised. When the
// user then clicks on the minimised window the Modex is likewise restored

class CDirectDrawWindow : public CBaseWindow
{
public:

    LRESULT OnPaint();

    // Overriden to return our window and class styles
    LPTSTR GetClassWindowStyles(DWORD *pClassStyles,
                                DWORD *pWindowStyles,
                                DWORD *pWindowStylesEx);

    // Method that gets all the window messages
    LRESULT OnReceiveMessage(HWND hwnd,          // Window handle
                             UINT uMsg,          // Message ID
                             WPARAM wParam,      // First parameter
                             LPARAM lParam);     // Other parameter
};

#endif // _VIDLOAD__
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\multimedia\dshow\filters\image\vidload\vidload.cpp ===
// Copyright (c) 1994 - 1996  Microsoft Corporation.  All Rights Reserved.
// ActiveMovie video stress application, Anthony Phillips, May 1996

// Stress style application to test some different problems we have had. The
// first test loads DirectDraw on a number of different threads (the number
// is defined by the THREADS constant). Each thread loads the DDRAW library
// and creates a primary surface. Having done that it just releases them and
// exits. The caller application thread polls the message queue while it is
// waiting for the threads to exit (so that they can still do log messages)

// The second test is also multi threaded. The main application thread sets
// THREADS worker threads going again each with a media file name passed in
// as a program parameter. The threads then create a filtergraph manager and
// render the file. Having done so they just release their interfaces. We do
// this because there was a mapper bug where it was not locking up correctly

// The third test is a DirectDraw regression bug where if we set our window
// as the exclusive window through IDirectDraw SetCooperativeLevel twice
// with DDSCL_EXCLUSIVE then the window is maximised fullscreen with a kind
// of weird display change happening as well. The test just loads DirectDraw
// and sets an application window (based on CBaseWindow) in exclusive mode

// Test four calls SetCooperativeLevel with fullscreen exclusive access and
// then does the same on a second window. The second window fails to get the
// access rights but does make a mess of the display, large areas come out
// black and will not be repainted when the test application is terminated
// The second SetCooperativeLevel call correctly returns DERR_HWNDALREADYSET

#include <windows.h>
#include <windowsx.h>
#include <vfw.h>
#include <stdlib.h>
#include <stdio.h>
#include <time.h>
#include <limits.h>
#include <streams.h>
#include <vidload.h>
#include <viddbg.h>

HWND g_hwndList;        // Handle to the logging list box
HWND g_hwndFrame;       // Handle to the main window frame
int g_cTemplates;       // Otherwise the compiler complains

CFactoryTemplate g_Templates[] = {
    {L"", &GUID_NULL,NULL,NULL}
};


// Standard Windows program entry point called by runtime code

INT PASCAL WinMain(HINSTANCE hInstance,        // This instance identifier
                   HINSTANCE hPrevInstance,    // Previous instance
                   LPSTR lpszCmdLine,          // Command line parameters
                   INT nCmdShow)               // Initial display mode
{
    WNDCLASS wndclass;      // Used to register classes
    MSG msg;                // Windows message structure

    // Register the frame window class

    wndclass.style         = CS_HREDRAW | CS_VREDRAW;
    wndclass.lpfnWndProc   = FrameWndProc;
    wndclass.cbClsExtra    = 0;
    wndclass.cbWndExtra    = 0;
    wndclass.hInstance     = hInstance;
    wndclass.hIcon         = NULL;
    wndclass.hCursor       = LoadCursor (NULL,IDC_ARROW);
    wndclass.hbrBackground = (HBRUSH)(COLOR_APPWORKSPACE + 1);
    wndclass.lpszMenuName  = NULL;
    wndclass.lpszClassName = FrameClass;

    RegisterClass (&wndclass);

    // Create the frame window

    g_hwndFrame = CreateWindow(FrameClass,              // Class of window
                               Title,                   // Window's title
                               WS_OVERLAPPEDWINDOW |    // Window styles
                               WS_CLIPCHILDREN |        // Clip any children
                               WS_VISIBLE,              // Make it visible
                               CW_USEDEFAULT,           // Default x position
                               CW_USEDEFAULT,           // Default y position
                               450,500,                 // The initial size
                               NULL,                    // Window parent
                               NULL,                    // Menu handle
                               hInstance,               // Instance handle
                               NULL);                   // Creation data
    ASSERT(g_hwndFrame);
    CoInitialize(NULL);
    DbgInitialise(hInstance);
    g_hInst = hInstance;

    // Loop loading and unloading DirectDraw
    for (int i = 0;i < 10;i++) {
        ThreadEntryPoint(NULL);
        Sleep(i * 100);
    }

    // Normal Windows message loop

    while (GetMessage(&msg,NULL,0,0)) {
        TranslateMessage(&msg);
        DispatchMessage(&msg);
    }

    CoUninitialize();
    DbgTerminate();
    return msg.wParam;
}


// And likewise the normal windows procedure for message handling

LRESULT CALLBACK FrameWndProc(HWND hwnd,        // Our window handle
                              UINT message,     // Message information
                              UINT wParam,      // First parameter
                              LONG lParam)      // And other details
{
    switch (message)
    {
        case WM_CREATE:

            // Create the list box for our logging

            g_hwndList = CreateWindow(TEXT("listbox"),
                                      NULL,
                                      WS_CHILD | WS_VISIBLE | LBS_STANDARD | LBS_NOINTEGRALHEIGHT,
                                      0,0,0,0,
                                      hwnd,
                                      (HMENU) ID_LISTBOX,
                                      g_hInst,
                                      NULL);
            return (LRESULT) 0;

         case WM_SIZE:

            // Size the list box accordingly

            MoveWindow(g_hwndList,0,0,
                       LOWORD(lParam),
                       HIWORD(lParam),
                       TRUE);

            break;

        case WM_DESTROY:
            PostQuitMessage(FALSE);
            return (LRESULT) 0;
    }
    return DefWindowProc(hwnd,message,wParam,lParam);
}


// Allow the worker thread to send us messages

void YieldToMessageQueue()
{
    MSG msg;
    while (PeekMessage(&msg,NULL,0,0,PM_REMOVE)) {
        if (msg.message == WM_QUIT) {
            break;
        }
        TranslateMessage(&msg);
        DispatchMessage(&msg);
    }
}


// Create a number of worker threads to load the DirectDraw. Once the worker
// threads have been created we sit in a loop waiting for their handles to
// become signalled (which they will do when the threads exit). While we're
// waiting for them we must make sure we yield to our window message queue
// because that is the only way the sent logging messages will be allowed in

HRESULT ThreadLoadDirectDraw()
{
    Log("ThreadLoadDirectDraw");
    HANDLE hThreads[THREADS];
    DWORD Result = WAIT_TIMEOUT;
    HRESULT hr = NOERROR;
    DWORD dwThreadID;

    // Create the worker threads to push samples to the renderer

    LPTHREAD_START_ROUTINE lpProc = ThreadEntryPoint;
    for (INT iThread = 0;iThread < THREADS;iThread++) {

        hThreads[iThread] = CreateThread(
                               NULL,              // Security attributes
                               (DWORD) 0,         // Initial stack size
                               lpProc,            // Thread start address
                               (LPVOID) TRUE,     // Thread parameter
                               (DWORD) 0,         // Creation flags
                               &dwThreadID);      // Thread identifier

        ASSERT(hThreads[iThread]);
    }

    // Wait for all the threads to exit

    while (Result == WAIT_TIMEOUT) {
        Log("Waiting for threads...");
        YieldToMessageQueue();
        Result = WaitForMultipleObjects(THREADS,hThreads,TRUE,TIMEOUT);
        if (Result == WAIT_FAILED) {
            Log("Wait returned WAIT_TIMEOUT");
        }
    }

    // Close the thread handle resources

    Log("Worker threads completed");
    for (iThread = 0;iThread < THREADS;iThread++) {
        EXECUTE_ASSERT(CloseHandle(hThreads[iThread]));
    }
    return NOERROR;
}


// Thread start function for load DirectDraw test. Each of the threads calls
// LoadLibrary on DDRAW.DLL. With the loaded library it creates a DirectDraw
// instance and then a primary surface. If successful the surfaces are just
// released. This code is typically executed by multiple threads at the same
// time by the main application (the number of threads is define by THREADS)

DWORD ThreadEntryPoint(LPVOID lpvThreadParm)
{
    BOOL bExitThread = (BOOL) lpvThreadParm;
    DWORD ThreadId = GetCurrentThreadId();
    Log("Thread %lx started",ThreadId);
    CLoadDirectDraw Loader;

    // Try and load DirectDraw on this thread

    HRESULT hr = Loader.LoadDirectDraw();
    if (FAILED(hr)) {
        Log("No DirectDraw (%lx)",ThreadId);
        if (bExitThread) ExitThread(FALSE);
        return DWORD(1);
    }

    IDirectDraw *pDirectDraw = Loader.GetDirectDraw();
    IDirectDrawSurface *pDrawPrimary;
    DDSURFACEDESC SurfaceDesc;
    SurfaceDesc.dwSize = sizeof(DDSURFACEDESC);
    SurfaceDesc.dwFlags = DDSD_CAPS;
    SurfaceDesc.ddsCaps.dwCaps = DDSCAPS_PRIMARYSURFACE;

    // Set a normal cooperative level for the window

    hr = pDirectDraw->SetCooperativeLevel(g_hwndFrame,DDSCL_NORMAL);
    if (hr != DDERR_HWNDALREADYSET) {
        if (FAILED(hr)) {
            Log("Setting level failed");
        }
    }

    // Initialise the primary surface interface

    hr = pDirectDraw->CreateSurface(&SurfaceDesc,&pDrawPrimary,NULL);
    if (FAILED(hr)) {
        Log("No primary surface");
    }

    // Release the primary surface interface

    if (SUCCEEDED(hr)) {
        Log("Releasing primary surface");
        pDrawPrimary->Release();
    }

    // Now release DirectDraw completely

    pDirectDraw->Release();
    Loader.ReleaseDirectDraw();
    Log("Exiting thread %lx",ThreadId);
    if (bExitThread) ExitThread(FALSE);
    return DWORD(1);
}


// Log the text by adding it to the window list box. We do this by sending a
// message to the list box window. If this is the main application thread we
// will execute successfully as the SendMessage makes us alertable. If this
// is a worker thread then the SendMessage will not complete until the main
// application window thread yields to its message queue (from GetMessage)

void Log(TCHAR *pFormat,...)
{
    TCHAR LogInfo[128];

    // Format the variable length parameter list

    va_list va;
    va_start(va, pFormat);
    wvsprintf(LogInfo, pFormat, va);
    va_end(va);

    // Add it to the end of the list and update

    SendMessage(g_hwndList,LB_INSERTSTRING,(WPARAM) -1,(LONG)(LPARAM)LogInfo);
    UpdateWindow(g_hwndList);
}


// Create a number of worker threads to create filtergraphs. Once the worker
// threads have been created we sit in a loop waiting for their handles to
// become signalled (which they will do when the threads exit). While we're
// waiting for them we must make sure we yield to our window message queue
// because that is the only way the sent logging messages will be allowed in

HRESULT RenderMediaFiles(TCHAR *pFile)
{
    Log("RenderMediaFiles (file %s)",pFile);
    HANDLE hThreads[THREADS];
    DWORD Result = WAIT_TIMEOUT;
    HRESULT hr = NOERROR;
    DWORD dwThreadID;

    // Create the worker threads to push samples to the renderer

    LPTHREAD_START_ROUTINE lpProc = RenderEntryPoint;
    for (INT iThread = 0;iThread < THREADS;iThread++) {

        hThreads[iThread] = CreateThread(
                               NULL,              // Security attributes
                               (DWORD) 0,         // Initial stack size
                               lpProc,            // Thread start address
                               (LPVOID) pFile,    // Thread parameter
                               (DWORD) 0,         // Creation flags
                               &dwThreadID);      // Thread identifier

        ASSERT(hThreads[iThread]);
    }

    // Wait for all the threads to exit

    while (Result == WAIT_TIMEOUT) {
        Log("Waiting for threads...");
        YieldToMessageQueue();
        Result = WaitForMultipleObjects(THREADS,hThreads,TRUE,TIMEOUT);
        if (Result == WAIT_FAILED) {
            Log("Wait returned WAIT_TIMEOUT");
        }
    }

    // Close the thread handle resources

    Log("Worker threads completed");
    for (iThread = 0;iThread < THREADS;iThread++) {
        EXECUTE_ASSERT(CloseHandle(hThreads[iThread]));
    }
    return NOERROR;
}


// Create a filtergraph and render the thread parameter file name - the main
// application spawns off several worker threads to do this. The filtergraph
// mapper didn't use to have any locking in it so when we render some files
// simultaneously on different threads it would either access violate or it
// would fail to render correctly and return VFW_E_CANNOT_RENDER error code

DWORD RenderEntryPoint(LPVOID lpvThreadParm)
{
    DWORD ThreadId = GetCurrentThreadId();
    Log("Thread %lx started",ThreadId);
    IGraphBuilder *pGraph;
    TCHAR *pFileName = (TCHAR *) lpvThreadParm;
    WCHAR wszFileName[128];

    // Quick check on thread parameter

    if (pFileName == NULL) {
        Log("Invalid thread parameters");
        ExitThread(FALSE);
        return DWORD(1);
    }

    // Create the ActiveMovie filtergraph

    CoInitialize(NULL);
    HRESULT hr = CoCreateInstance(CLSID_FilterGraph,
                                  NULL,
                                  CLSCTX_INPROC_SERVER,
                                  IID_IGraphBuilder,
                                  (void **) &pGraph);

    // Quick check on parameters

    if (pGraph == NULL) {
        Log("No graph %lx",hr);
        CoUninitialize();
        ExitThread(FALSE);
        return DWORD(1);
    }

    MultiByteToWideChar(CP_ACP,0,pFileName,-1,wszFileName,128);
    Log("Created graph %lx",ThreadId);

    // Try and render the file

    hr = pGraph->RenderFile(wszFileName,NULL);
    if (FAILED(hr)) {
        pGraph->Release();
        Log("Render failed on %s (error %lx)",pFileName,hr);
        CoUninitialize();
        ExitThread(FALSE);
        return DWORD(1);
    }

    Log("Render %s ok (%lx)",pFileName,ThreadId);
    pGraph->Release();
    CoUninitialize();
    ExitThread(FALSE);
    return DWORD(1);
}


// We were having problems with setting DDSCL_EXCLSUIVE access on our windows
// with DirectDraw. This is a really simple test that just creates a window
// which has some typical DirectDraw styles (copied from our Modex renderer)
// and then sets the cooperative level with it. After that we do the same
// again a few more times just to make sure it will still function correctly

HRESULT ExclusiveWindowTest()
{
    DWORD ThreadId = GetCurrentThreadId();
    Log("Application thread %lx",ThreadId);
    CDirectDrawWindow DirectDrawWindow;
    CLoadDirectDraw Loader;

    // Try and load DirectDraw on this thread

    HRESULT hr = Loader.LoadDirectDraw();
    if (FAILED(hr)) {
        Log("No DirectDraw (%lx)",ThreadId);
        return DWORD(1);
    }

    // Set an exclusive cooperative level for the window

    IDirectDraw *pDirectDraw = Loader.GetDirectDraw();
    DirectDrawWindow.PrepareWindow();
    HWND hwnd = DirectDrawWindow.GetWindowHWND();
    DirectDrawWindow.DoShowWindow(SW_SHOWNORMAL);
    DirectDrawWindow.DoSetWindowForeground(TRUE);

    DWORD DirectFlags = DDSCL_EXCLUSIVE | DDSCL_FULLSCREEN |
                                DDSCL_ALLOWREBOOT |
                                    DDSCL_ALLOWMODEX;

    hr = pDirectDraw->SetCooperativeLevel(hwnd,DirectFlags);
    if (FAILED(hr)) {
        Log("DDSCL_EXCLUSIVE failed %lx",hr);
    }

    // Try a few more times to make sure it really works

    Log("Setting DDSCL_EXCLUSIVE again (1)");
    pDirectDraw->SetCooperativeLevel(hwnd,DirectFlags);
    Log("Setting DDSCL_EXCLUSIVE again (2)");
    pDirectDraw->SetCooperativeLevel(hwnd,DirectFlags);
    Log("Setting DDSCL_EXCLUSIVE again (3)");
    pDirectDraw->SetCooperativeLevel(hwnd,DirectFlags);
    Log("Setting DDSCL_EXCLUSIVE again (4)");
    pDirectDraw->SetCooperativeLevel(hwnd,DirectFlags);
    Log("Setting DDSCL_EXCLUSIVE again (5)");
    pDirectDraw->SetCooperativeLevel(hwnd,DirectFlags);
    Log("Setting DDSCL_EXCLUSIVE again (6)");
    pDirectDraw->SetCooperativeLevel(hwnd,DirectFlags);
    Log("Setting DDSCL_EXCLUSIVE again (7)");

    // Release DirectDraw completely

    Log("Exiting thread %lx",ThreadId);
    pDirectDraw->Release();
    Loader.ReleaseDirectDraw();
    DirectDrawWindow.DoneWithWindow();
    return DWORD(1);
}


// To be able to use the DirectDraw display mode functionality we supply it
// with a window, this is granted exclusive mode access rights. DirectDraw
// hooks the window and manages a lot of the functionality associated with
// handling Modex. For example when you switch display modes it maximises
// the window, when the user hits ALT-TAB the window is minimised. When the
// user then clicks on the minimised window the Modex is likewise restored

LPTSTR CDirectDrawWindow::GetClassWindowStyles(DWORD *pClassStyles,
                                               DWORD *pWindowStyles,
                                               DWORD *pWindowStylesEx)
{
    NOTE("Entering GetClassWindowStyles");

    *pClassStyles = CS_HREDRAW | CS_VREDRAW | CS_BYTEALIGNCLIENT | CS_DBLCLKS;
    *pWindowStyles = WS_POPUP | WS_CLIPCHILDREN;
    *pWindowStylesEx = WS_EX_TOPMOST;
    return TEXT("DirectDrawRenderer");
}


// Handles WM_PAINT messages by filling the window in black

LRESULT CDirectDrawWindow::OnPaint()
{
    NOTE("Entering OnPaint");
    RECT ClientRect;

    // Blank out the entire video window

    GetClientRect(m_hwnd,&ClientRect);
    HBRUSH hBrush = CreateSolidBrush(VIDEO_COLOUR);
    EXECUTE_ASSERT(FillRect(m_hdc,&ClientRect,hBrush));
    EXECUTE_ASSERT(DeleteObject(hBrush));

    return (LRESULT) 1;
}


// This is the derived class window message handler

LRESULT CDirectDrawWindow::OnReceiveMessage(HWND hwnd,      // Window handle
                                            UINT uMsg,      // Message ID
                                            WPARAM wParam,  // First parameter
                                            LPARAM lParam)  // Other parameter
{
    NOTE3("Message (uMsg 0x%x wParam 0x%x lParam 0x%x)",uMsg,wParam,lParam);

    switch (uMsg)
    {
        // Blank the window for each paint message

        case WM_PAINT:

            PAINTSTRUCT ps;
            BeginPaint(m_hwnd,&ps);
            EndPaint(m_hwnd,&ps);
            return OnPaint();
    }
    return CBaseWindow::OnReceiveMessage(hwnd,uMsg,wParam,lParam);
}


// This test function shows up two problems (probably related). The first is
// that a single application thread calling SetCooperative for fullscreen on
// two different windows (one after the other) messes up the display - we're
// left with large areas of black all over the place. The second problem is
// that we are left with two ghosting windows down the bottom on the taskbar
// The second SetCooperativeLevel call correctly returns DERR_HWNDALREADYSET

HRESULT TwoWindowExclusiveTest()
{
    DWORD ThreadId = GetCurrentThreadId();
    Log("Application thread %lx",ThreadId);
    CDirectDrawWindow DirectDrawWindow1;
    CDirectDrawWindow DirectDrawWindow2;
    CLoadDirectDraw Loader;

    // Try and load DirectDraw on this thread

    HRESULT hr = Loader.LoadDirectDraw();
    if (FAILED(hr)) {
        Log("No DirectDraw (%lx)",ThreadId);
        return DWORD(1);
    }

    // Set an exclusive cooperative level for the first window

    Log("Showing first DirectDraw window");
    IDirectDraw *pDirectDraw = Loader.GetDirectDraw();
    DirectDrawWindow1.PrepareWindow();
    HWND hwnd1 = DirectDrawWindow1.GetWindowHWND();
    DirectDrawWindow1.DoShowWindow(SW_SHOWNORMAL);
    DirectDrawWindow1.DoSetWindowForeground(TRUE);

    DWORD DirectFlags = DDSCL_EXCLUSIVE | DDSCL_FULLSCREEN |
                                DDSCL_ALLOWREBOOT |
                                    DDSCL_ALLOWMODEX;

    Log("Calling SetCooperativeLevel on %d",hwnd1);
    hr = pDirectDraw->SetCooperativeLevel(hwnd1,DirectFlags);
    if (FAILED(hr)) {
        Log("DDSCL_EXCLUSIVE failed %lx",hr);
    }

    // Set an exclusive cooperative level for the second window

    Log("Showing second DirectDraw window");
    DirectDrawWindow2.PrepareWindow();
    HWND hwnd2 = DirectDrawWindow2.GetWindowHWND();
    DirectDrawWindow2.DoShowWindow(SW_SHOWNORMAL);
    DirectDrawWindow2.DoSetWindowForeground(TRUE);

    Log("Calling SetCooperativeLevel on %d",hwnd2);
    hr = pDirectDraw->SetCooperativeLevel(hwnd2,DirectFlags);
    if (FAILED(hr)) {
        Log("DDSCL_EXCLUSIVE failed %lx",hr);
    }

    // Release DirectDraw completely

    Log("Exiting thread %lx",ThreadId);
    DirectDrawWindow1.DoneWithWindow();
    DirectDrawWindow2.DoneWithWindow();
    pDirectDraw->Release();
    Loader.ReleaseDirectDraw();
    return DWORD(1);
}


// Create a number of worker threads to call DirectDraw - once the threads
// have been created we will sit in a loop waiting for their handles to be
// signalled (which they will do when the threads exit). While we wait for
// them we must make sure we yield to our window message queue because that
// is the only way the logging messages will be allowed in (by SendMessage)

HRESULT ExclusiveThreadWindowTest()
{
    Log("ExclusiveThreadWindowTest");
    HANDLE hThreads[THREADS];
    DWORD Result = WAIT_TIMEOUT;
    HRESULT hr = NOERROR;
    DWORD dwThreadID;

    // Create the worker threads to push samples to the renderer

    LPTHREAD_START_ROUTINE lpProc = ExclusiveThreadEntryPoint;
    for (INT iThread = 0;iThread < THREADS;iThread++) {

        hThreads[iThread] = CreateThread(
                               NULL,              // Security attributes
                               (DWORD) 0,         // Initial stack size
                               lpProc,            // Thread start address
                               (LPVOID) NULL,     // Thread parameter
                               (DWORD) 0,         // Creation flags
                               &dwThreadID);      // Thread identifier

        ASSERT(hThreads[iThread]);
    }

    // Wait for all the threads to exit

    while (Result == WAIT_TIMEOUT) {
        Log("Waiting for threads...");
        YieldToMessageQueue();
        Result = WaitForMultipleObjects(THREADS,hThreads,TRUE,TIMEOUT);
        if (Result == WAIT_FAILED) {
            Log("Wait returned WAIT_TIMEOUT");
        }
    }

    // Close the thread handle resources

    Log("Worker threads completed");
    for (iThread = 0;iThread < THREADS;iThread++) {
        EXECUTE_ASSERT(CloseHandle(hThreads[iThread]));
    }
    return NOERROR;
}


// This doesn't really show any bugs up, it was designed to see if lots and
// lots of threads all calling SetCooperativeLevel would mess it up. What
// should happen is that the first thread to get scheduled will get in and
// grab the exclusive lock, then all subsequent threads will be denied the
// fullscreen (calling SetCooperativeLevel will return DDERR_HWNDALREADYSET)

DWORD ExclusiveThreadEntryPoint(LPVOID lpvThreadParm)
{
    DWORD ThreadId = GetCurrentThreadId();
    Log("Worker thread %lx",ThreadId);
    CDirectDrawWindow DirectDrawWindow;
    CLoadDirectDraw Loader;

    // Try and load DirectDraw on this thread

    HRESULT hr = Loader.LoadDirectDraw();
    if (FAILED(hr)) {
        Log("No DirectDraw (%lx)",ThreadId);
        return DWORD(1);
    }

    // Set an exclusive cooperative level for the window

    IDirectDraw *pDirectDraw = Loader.GetDirectDraw();
    DirectDrawWindow.PrepareWindow();
    HWND hwnd = DirectDrawWindow.GetWindowHWND();

    DWORD DirectFlags = DDSCL_EXCLUSIVE | DDSCL_FULLSCREEN |
                                DDSCL_ALLOWREBOOT |
                                    DDSCL_ALLOWMODEX;

    hr = pDirectDraw->SetCooperativeLevel(hwnd,DirectFlags);
    if (FAILED(hr)) {
        Log("DDSCL_EXCLUSIVE failed %lx",hr);
    }

    // Try a few more times to make sure it really works

    Log("Setting DDSCL_EXCLUSIVE again (1) - Thread (%lx)",ThreadId);
    pDirectDraw->SetCooperativeLevel(hwnd,DirectFlags);
    Log("Setting DDSCL_EXCLUSIVE again (2) - Thread (%lx)",ThreadId);
    pDirectDraw->SetCooperativeLevel(hwnd,DirectFlags);
    Log("Setting DDSCL_EXCLUSIVE again (3) - Thread (%lx)",ThreadId);
    pDirectDraw->SetCooperativeLevel(hwnd,DirectFlags);
    Log("Setting DDSCL_EXCLUSIVE again (4) - Thread (%lx)",ThreadId);
    pDirectDraw->SetCooperativeLevel(hwnd,DirectFlags);
    Log("Setting DDSCL_EXCLUSIVE again (5) - Thread (%lx)",ThreadId);
    pDirectDraw->SetCooperativeLevel(hwnd,DirectFlags);
    Log("Setting DDSCL_EXCLUSIVE again (6) - Thread (%lx)",ThreadId);
    pDirectDraw->SetCooperativeLevel(hwnd,DirectFlags);

    // Release DirectDraw completely

    Log("Exiting thread %lx",ThreadId);
    pDirectDraw->Release();
    Loader.ReleaseDirectDraw();
    DirectDrawWindow.DoneWithWindow();
    return DWORD(1);
}
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\multimedia\dshow\filters\image\vidprop\viddbg.h ===
// Copyright (c) Microsoft Corporation 1994-1996. All Rights Reserved
// Define some common video debug macros, Anthony Phillips, May 1995

#ifndef __VIDDBG__
#define __VIDDBG__

#ifdef __VIDFLTR__

#undef NOTE
#undef NOTE1
#undef NOTE2
#undef NOTE3
#undef NOTE4
#undef NOTE5

#define NOTE(_x_)             DbgLog((LOG_TRACE,0,TEXT(_x_)));
#define NOTE1(_x_,a)          DbgLog((LOG_TRACE,0,TEXT(_x_),a));
#define NOTE2(_x_,a,b)        DbgLog((LOG_TRACE,0,TEXT(_x_),a,b));
#define NOTE3(_x_,a,b,c)      DbgLog((LOG_TRACE,0,TEXT(_x_),a,b,c));
#define NOTE4(_x_,a,b,c,d)    DbgLog((LOG_TRACE,0,TEXT(_x_),a,b,c,d));
#define NOTE5(_x_,a,b,c,d,e)  DbgLog((LOG_TRACE,0,TEXT(_x_),a,b,c,d,e));

#endif // __VIDFLTR__

#define NOTERC(info,rc)                  \
    NOTE1("(%s rectangle)",TEXT(info));  \
    NOTE1("  Left %d",rc.left);          \
    NOTE1("  Top %d",rc.top);            \
    NOTE1("  Right %d",rc.right);        \
    NOTE1("  Bottom %d",rc.bottom);      \

#endif // __VIDDBG__
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\multimedia\dshow\filters\image\video\window.cpp ===
// Copyright (c) 1994 - 1999  Microsoft Corporation.  All Rights Reserved.
// Implements the CVideoWindow class, Anthony Phillips, January 1995

#include <streams.h>
#include <windowsx.h>
#include <render.h>
#include <limits.h>
#include <measure.h>
#include <mmsystem.h>
#include <dvdmedia.h> // VIDEOINFO2

//  When we are constructed we create a window and a separate thread to look
//  after it. We also create two device contexts for the window, one for the
//  window client area and another compatible with this for offscreen drawing.
//  Only source formats that match the display device format will be accepted,
//  other formats have to be converted through colour transformation filters.
//  The only exception to this being true colour devices which will normally
//  handle four and eight bit palettised images very efficiently.
//
//  When a connection has been made the output pin may ask us for an allocator
//  We provide an allocator that gives out one or more memory buffers that are
//  shared with GDI. These are created through CreateDIBSection. That requires
//  us to give it the connected source media type format BITMAPINFO structure.
//
//  When we come to rendering the images we have two separate code paths, one
//  for samples allocated with our shared memory allocator and another for the
//  normal memory buffers. As it turns out the shared memory allocator does
//  only marginally faster. However our memory allocator can also return DCI
//  and DirectDraw surfaces which can be drawn by display card hardware. DCI
//  and DirectDraw buffers may still need drawing (although not always as
//  in the case of primary surfaces) and if they do they also get sent to us
//  for synchronising. Our Render method will call the DirectDraw object if
//  it sees a DirectDraw sample, otherwise it passes it to our draw object.
//
//  For shared memory buffers we select the DIB data into the offscreen device
//  context which will also always have the source palette realized in it then
//  we BitBlt from that device context into the window device context. For the
//  normal non shared memory samples we simply call SetDIBitsToDevice and also
//  StretchDIBitsToDevice), GDI first maps the buffer into it's address space
//  (thereby making the buffer shared) and then copies it to the screen.


// Constructor

#pragma warning(disable:4355)

CVideoWindow::CVideoWindow(CRenderer *pRenderer,      // The owning renderer
                           CCritSec *pLock,           // Object to lock with
                           LPUNKNOWN pUnk,            // Owning object
                           HRESULT *phr) :            // OLE return code


    CBaseControlWindow(pRenderer,pLock,NAME("Window object"),pUnk,phr),
    CBaseControlVideo(pRenderer,pLock,NAME("Window object"),pUnk,phr),
    m_pRenderer(pRenderer),
    m_pInterfaceLock(pLock),
    m_bTargetSet(FALSE),
    m_pFormat(NULL),
    m_FormatSize(0)
{
    ASSERT(m_pRenderer);
    ASSERT(m_pInterfaceLock);

    // Create a default arrow cursor

    m_hCursor = (HCURSOR) LoadImage((HINSTANCE) NULL,
                                    MAKEINTRESOURCE(OCR_ARROW_DEFAULT),
                                    IMAGE_CURSOR,0,0,0);
}


// Must destroy the window before this destructor

CVideoWindow::~CVideoWindow()
{
    ASSERT(m_hwnd == NULL);
    ASSERT(m_hdc == NULL);
    ASSERT(m_MemoryDC == NULL);
    DestroyCursor(m_hCursor);
    if (m_pFormat)
        QzTaskMemFree(m_pFormat);
}


// Overriden to say what interfaces we support

STDMETHODIMP CVideoWindow::NonDelegatingQueryInterface(REFIID riid,VOID **ppv)
{
    if (riid == IID_IVideoWindow) {
        return CBaseControlWindow::NonDelegatingQueryInterface(riid,ppv);
    } else {
        ASSERT(riid == IID_IBasicVideo || riid == IID_IBasicVideo2);
        return CBaseControlVideo::NonDelegatingQueryInterface(riid,ppv);
    }
}


// Return the default client rectangle we would like

RECT CVideoWindow::GetDefaultRect()
{
    CAutoLock cWindowLock(&m_WindowLock);

    // Create a rectangle from the video dimensions

    VIDEOINFO *pVideoInfo = (VIDEOINFO *) m_pRenderer->m_mtIn.Format();
    BITMAPINFOHEADER *pHeader = HEADER(pVideoInfo);
    SIZE VideoSize = m_pRenderer->m_VideoSize;
    RECT DefaultRect = {0,0,VideoSize.cx,VideoSize.cy};

    return DefaultRect;
}


// We are called when the user moves the cursor over the window client area
// If we are fullscreen then we should hide the pointer so that it matches
// the fullscreen renderer behaviour. We also set a default cursor if we're
// DirectDraw overlays as software cursors won't be visible. This means we
// change the cursor as the mouse is moved but at least a cursor is visible

BOOL CVideoWindow::OnSetCursor(LPARAM lParam)
{
    // The base class that implements IVideoWindow looks after a flag that
    // says whether or not the cursor should be hidden. If so we hide the
    // cursor and return TRUE. Otherwise we pass to DefWindowProc to show
    // the cursor as normal. This is used when our window is stretched up
    // fullscreen to imitate the Modex filter that always hides the cursor

    if (IsCursorHidden() == TRUE) {
        SetCursor(NULL);
        return TRUE;
    }

    // Are DirectDraw colour key overlays visible

    if ((m_pRenderer->m_DirectDraw.InSoftwareCursorMode() == FALSE) ||
        (*m_pRenderer->m_mtIn.Subtype() == MEDIASUBTYPE_Overlay))
    {
        if (LOWORD(lParam) == HTCLIENT) {
            SetCursor(m_hCursor);
            return TRUE;
        }
    }
    return FALSE;
}


// We override the virtual CBaseWindow OnReceiveMessage call to handle more
// of the Windows messages. The base class handles some stuff like WM_CLOSE
// messages amongst others which we are also interested in. We don't need
// to use WM_SIZE and WM_MOVE messages to position source filters through
// IOverlay (with ADVISE_POSITION) as we poll with timers now. This is done
// because as a child window we cannot be guaranteed to see those messages
// Our global hook sends us WM_FREEZE and WM_THAW messages synchronously as
// it detects window changes in the system that might affect our clip list

LRESULT CVideoWindow::OnReceiveMessage(HWND hwnd,         // Window handle
                                       UINT uMsg,         // Message ID
                                       WPARAM wParam,     // First parameter
                                       LPARAM lParam)     // Other parameter
{
    IBaseFilter *pFilter = NULL;

    switch (uMsg) {

        // Handle cursors when fullscreen and in overlay mode

        case WM_SETCURSOR:

            if (OnSetCursor(lParam) == TRUE) {
                NOTE("Cursor handled");
                return (LRESULT) 0;
            }
            break;

        // We pass on WM_ACTIVATEAPP messages to the filtergraph so that the
        // IVideoWindow plug in distributor can switch us out of fullscreen
        // mode where appropriate. These messages may also be used by the
        // resource manager to keep track of which renderer has the focus

        case WM_ACTIVATEAPP:
        case WM_ACTIVATE:
        case WM_NCACTIVATE:
        case WM_MOUSEACTIVATE:
        {
            BOOL bActive = TRUE;
            IBaseFilter * const pFilter = m_pRenderer;
            switch (uMsg) {
            case WM_ACTIVATEAPP:
            case WM_NCACTIVATE:
                bActive = (BOOL)wParam;
                break;
            case WM_ACTIVATE:
                bActive = LOWORD(wParam) != WA_INACTIVE;
                break;
            }
            NOTE1("Notification of EC_ACTIVATE (%d)",bActive);
            m_pRenderer->NotifyEvent(EC_ACTIVATE,bActive,
                                     (LPARAM) pFilter);
            NOTE("EC_ACTIVATE signalled to filtergraph");

            break;
        }

        // When we detect a display change we send an EC_DISPLAY_CHANGED
        // message along with our input pin. The filtergraph will stop
        // everyone and reconnect our input pin. When being reconnected
        // we can then accept the media type that matches the new display
        // mode since we may no longer be able to draw the current format

        case WM_DISPLAYCHANGE:

            NOTE("Notification of WM_DISPLAYCHANGE");

            if (m_pRenderer->IsFrameStepEnabled()) {
                return (LRESULT)0;
            }

            m_pRenderer->OnDisplayChange();
            m_pRenderer->m_DirectDraw.HideOverlaySurface();

            // InterlockedExchange() does not work on multiprocessor x86 systems and on non-x86
            // systems if m_pRenderer->m_fDisplayChangePosted is not aligned on a 32 bit boundary.
            ASSERT((DWORD_PTR)&m_pRenderer->m_fDisplayChangePosted == ((DWORD_PTR)&m_pRenderer->m_fDisplayChangePosted & ~3));
            
            InterlockedExchange(&m_pRenderer->m_fDisplayChangePosted, FALSE); // ok again
            return (LRESULT) 0;

        // Timers are used to have DirectDraw overlays positioned

        case WM_TIMER:

            m_pRenderer->OnTimer(wParam);
            return (LRESULT) 0;

        case WM_ERASEBKGND:

            OnEraseBackground();
            return (LRESULT) 1;

        // Global system hooks are created on a specific thread, so if we get
        // an advise link created and it needs a global system hook then we
        // should install the hook on the window thread rather. The Advise
        // code can't send us a message for locking reasons so it posts us a
        // custom message to either hook the system and likewise stop a hook

        case WM_HOOK:

            OnHookMessage(TRUE);
            return (LRESULT) 1;

        case WM_UNHOOK:

            OnHookMessage(FALSE);
            return (LRESULT) 1;

        // This is a custom message send synchronously from our global hook
        // procedure when it detects that the clipping is going to change
        // on our video window - we should temporarily freeze the window

        case WM_FREEZE:

            OnWindowFreeze();
            return (LRESULT) 0;

        // This is complementary to the custom WM_FREEZE message and is sent
        // when the global hook procedure we installed detects that it is
        // now safe to resume playing the video temporarily frozen earlier

        case WM_THAW:

            OnWindowThaw();
            return (LRESULT) 0;

        case WM_SIZE:

            OnSize(LOWORD(lParam),HIWORD(lParam));
            OnUpdateRectangles();
            return (LRESULT) 0;

        // Used to delay palette change handling

        case WM_ONPALETTE:

            OnPalette();
            return (LRESULT) 0;

        // This tells us some of the window's client area has become exposed
        // If our connected filter is doing overlay work then we repaint the
        // background so that it will pick up the window clip changes. Those
        // filters will probably use an ADVISE_POSITION overlay notification

        case WM_PAINT:

            DoRealisePalette();
            OnPaint();
            return (LRESULT) 0;
    }
    return CBaseWindow::OnReceiveMessage(hwnd,uMsg,wParam,lParam);
}


// Used when the palette changes to clear the window

void CVideoWindow::EraseVideoBackground()
{
    NOTE("EraseVideoBackground");
    RECT TargetRect;

    GetTargetRect(&TargetRect);
    COLORREF BackColour = SetBkColor(m_hdc,VIDEO_COLOUR);
    ExtTextOut(m_hdc,0,0,ETO_OPAQUE,&TargetRect,NULL,0,NULL);
    SetBkColor(m_hdc,BackColour);
}


// This erases the background of the video window that does not have any video
// being put in it. During normal processing we ignore paint messages because
// we will soon be putting the next frame over the top of it, however we may
// have the destination rectangle set by the IVideoWindow control interface
// such that there are areas left untouched - this method erases over them
// We must lock the critical section as the control interface may change it

void CVideoWindow::OnEraseBackground()
{
    NOTE("Entering OnErasebackground");

    RECT ClientRect, TargetRect;
    EXECUTE_ASSERT(GetClientRect(m_hwnd,&ClientRect));
    CAutoLock cWindowLock(&m_WindowLock);
    GetTargetRect(&TargetRect);

    // Find that missing region

    HRGN ClientRgn = CreateRectRgnIndirect(&ClientRect);
    HRGN VideoRgn = CreateRectRgnIndirect(&TargetRect);
    HRGN EraseRgn = CreateRectRgn(0,0,0,0);
    HBRUSH hBrush = (HBRUSH) NULL;
    COLORREF Colour;

    if ( ( ! ClientRgn ) || ( ! VideoRgn ) || ( ! EraseRgn ) )
        goto Exit;

    CombineRgn(EraseRgn,ClientRgn,VideoRgn,RGN_DIFF);

    // Create a coloured brush to paint the window

    Colour = GetBorderColour();
    hBrush = CreateSolidBrush(Colour);
    FillRgn(m_hdc,EraseRgn,hBrush);

Exit:
    if ( ClientRgn ) DeleteObject( ClientRgn );
    if ( VideoRgn ) DeleteObject( VideoRgn );
    if ( EraseRgn ) DeleteObject( EraseRgn );
    if ( hBrush ) DeleteObject( hBrush );
}


// Pass the hook message onto the overlay object

void CVideoWindow::OnHookMessage(BOOL bHook)
{
    NOTE("Entering OnHookMessage");
    m_pRenderer->m_Overlay.OnHookMessage(bHook);
}


// This is called when we receive the custom WM_FREEZE message

void CVideoWindow::OnWindowFreeze()
{
    NOTE("Entering FreezeVideo");
    m_pRenderer->m_Overlay.FreezeVideo();
}


// This is called when we receive the custom WM_THAW message

void CVideoWindow::OnWindowThaw()
{
    NOTE("Entering OnWindowThaw");
    m_pRenderer->m_Overlay.ThawVideo();
}


// Initialise the draw object with the changed dimensions, we lock ourselves
// because the destination rectangle can be set via the IVideoWindow control
// interface. If the control interface has set a destination rectangle then
// we don't change it, otherwise we update the rectangle to match the window
// dimensions (in this case the left and top values should always be zero)

BOOL CVideoWindow::OnSize(LONG Width,LONG Height)
{
    NOTE("Entering OnSize");

    CAutoLock cWindowLock(&m_WindowLock);
    if (m_bTargetSet == TRUE) {
        NOTE("Target set");
        return FALSE;
    }

    // Create a target rectangle for the window

    RECT TargetRect = {0,0,Width,Height};
    CBaseWindow::OnSize(Width,Height);
    m_pRenderer->m_DrawVideo.SetTargetRect(&TargetRect);
    m_pRenderer->m_DirectDraw.SetTargetRect(&TargetRect);

    return TRUE;
}


// This method handles the WM_CLOSE message

BOOL CVideoWindow::OnClose()
{
    NOTE("Entering OnClose");

    m_pRenderer->m_DirectDraw.HideOverlaySurface();
    m_pRenderer->SetAbortSignal(TRUE);
    m_pRenderer->NotifyEvent(EC_USERABORT,0,0);
    return CBaseWindow::OnClose();
}


// If the palette has changed then update any overlay notification. If we see
// a palette change message then we should realise our palette again - unless
// it was us who caused it in the first place. We must also draw the current
// image again making sure that if we have no sample then we do at least blank
// out the background otherwise the window may be left with the wrong colours

void CVideoWindow::OnPalette()
{
    if (IsWindowVisible(m_hwnd) == TRUE) {
        NOTE("Handling OnPalette");
        m_pRenderer->OnPaint(TRUE);
    }
    m_pRenderer->m_Overlay.NotifyChange(ADVISE_PALETTE);
}


// Post a WM_ONPALETTE back to ourselves to avoid the window lock

LRESULT CVideoWindow::OnPaletteChange(HWND hwnd,UINT Message)
{
    NOTE("Entering OnPaletteChange");

    // Firstly is the window closing down
    if (m_hwnd == NULL || hwnd == NULL) {
        return (LRESULT) 0;
    }

    // Should we realise our palette again
    if (Message == WM_QUERYNEWPALETTE || hwnd != m_hwnd) {
        //  It seems that even if we're invisible that we can get asked
        //  to realize our palette and this can cause really ugly side-effects
        //  Seems like there's another bug but this masks it a least for the
        //  shutting down case.
        if (!IsWindowVisible(m_hwnd)) {
            DbgLog((LOG_TRACE, 1, TEXT("Realizing when invisible!")));
            return (LRESULT) 0;
        }
        DoRealisePalette(Message != WM_QUERYNEWPALETTE);
    }

    // Should we redraw the window with the new palette
    if (Message == WM_PALETTECHANGED) {
        PostMessage(m_hwnd,WM_ONPALETTE,0,0);
    }
    return (LRESULT) 1;
}


// This is called when we receive a WM_PAINT message

BOOL CVideoWindow::OnPaint()
{
    NOTE("Entering OnPaint");
    PAINTSTRUCT ps;
    BeginPaint(m_hwnd,&ps);
    EndPaint(m_hwnd,&ps);
    return m_pRenderer->OnPaint(FALSE);
}


// The base control video class calls this method when it changes either
// the source or destination rectangles. We update the overlay object as
// so that it notifies the source of the rectangle clip change and then
// invalidate the window so that the video is displayed in the new place

HRESULT CVideoWindow::OnUpdateRectangles()
{
    NOTE("Entering OnUpdateRectangles");
    m_pRenderer->m_Overlay.NotifyChange(ADVISE_CLIPPING | ADVISE_POSITION);
    m_pRenderer->m_VideoAllocator.OnDestinationChange();
    PaintWindow(TRUE);
    return NOERROR;
}


// When we call PrepareWindow in our constructor it will call this method as
// it is going to create the window to get our window and class styles. The
// return code is the class name and must be allocated in static storage. We
// specify a normal window during creation although the window styles as well
// as the extended styles may be changed by the application via IVideoWindow

LPTSTR CVideoWindow::GetClassWindowStyles(DWORD *pClassStyles,
                                          DWORD *pWindowStyles,
                                          DWORD *pWindowStylesEx)
{
    *pClassStyles = CS_HREDRAW | CS_VREDRAW | CS_BYTEALIGNCLIENT | CS_DBLCLKS;
    *pWindowStyles = WS_OVERLAPPEDWINDOW | WS_CLIPCHILDREN;
    *pWindowStylesEx = (DWORD) 0;
    return WindowClassName;
}


// Return the minimum ideal image size for the current video. This may differ
// to the actual video dimensions because we may be using DirectDraw hardware
// that has specific stretching requirements. For example the Cirrus Logic
// cards have a minimum stretch factor depending on the overlay surface size

STDMETHODIMP
CVideoWindow::GetMinIdealImageSize(long *pWidth,long *pHeight)
{
    CheckPointer(pWidth,E_POINTER);
    CheckPointer(pHeight,E_POINTER);
    FILTER_STATE State;
    CAutoLock cInterfaceLock(m_pInterfaceLock);

    // Must not be stopped for this to work correctly

    m_pRenderer->GetState(0,&State);
    if (State == State_Stopped) {
        return VFW_E_WRONG_STATE;
    }

    GetVideoSize(pWidth,pHeight);

    // Is this a purely overlay connection

    GUID SubType = *(m_pRenderer->m_mtIn.Subtype());
    if (SubType == MEDIASUBTYPE_Overlay) {
        return S_FALSE;
    }
    return m_pRenderer->m_DirectDraw.GetMinIdealImageSize(pWidth,pHeight);
}


// Return the maximum ideal image size for the current video. This may differ
// to the actual video dimensions because we may be using DirectDraw hardware
// that has specific stretching requirements. For example the Cirrus Logic
// cards have a maximum stretch factor depending on the overlay surface size

STDMETHODIMP
CVideoWindow::GetMaxIdealImageSize(long *pWidth,long *pHeight)
{
    CheckPointer(pWidth,E_POINTER);
    CheckPointer(pHeight,E_POINTER);
    FILTER_STATE State;
    CAutoLock cInterfaceLock(m_pInterfaceLock);

    // Must not be stopped for this to work correctly

    m_pRenderer->GetState(0,&State);
    if (State == State_Stopped) {
        return VFW_E_WRONG_STATE;
    }

    GetVideoSize(pWidth,pHeight);

    // Is this a purely overlay connection

    GUID SubType = *(m_pRenderer->m_mtIn.Subtype());
    if (SubType == MEDIASUBTYPE_Overlay) {
        return S_FALSE;
    }
    return m_pRenderer->m_DirectDraw.GetMaxIdealImageSize(pWidth,pHeight);
}

STDMETHODIMP
CVideoWindow::GetPreferredAspectRatio(long *plAspectX, long *plAspectY)
{
    if (plAspectX == NULL || plAspectY == NULL) {
        return E_POINTER;
    }

    CAutoLock cInterfaceLock(m_pInterfaceLock);

    //  See if the connected pin offers any aspect ratio - otherwise just
    //  return the regular stuff
    IPin *pPin = m_pRenderer->m_InputPin.GetConnected();
    if (pPin == NULL) {
        return VFW_E_NOT_CONNECTED;
    }
    IEnumMediaTypes *pEnum;
    bool fFoundVideoWidthAndHeight = false;
    if (SUCCEEDED(pPin->EnumMediaTypes(&pEnum))) {
        AM_MEDIA_TYPE *pmt;
        DWORD dwFound;
        if (S_OK == pEnum->Next(1, &pmt, &dwFound)) {
            if (pmt->formattype == FORMAT_VideoInfo2) {
                VIDEOINFOHEADER2 *pVideoInfo2 =
                    (VIDEOINFOHEADER2 *)pmt->pbFormat;
                *plAspectX = (long)pVideoInfo2->dwPictAspectRatioX;
                *plAspectY = (long)pVideoInfo2->dwPictAspectRatioY;
                fFoundVideoWidthAndHeight = true;
            }
            DeleteMediaType(pmt);
        }
        pEnum->Release();
    } 

    if (!fFoundVideoWidthAndHeight)
    {
        // Just return the normal values
        *plAspectX = m_pRenderer->GetVideoWidth();
        *plAspectY = m_pRenderer->GetVideoHeight();
    }
    return S_OK;
}


// Return a copy of the current image in the video renderer. The base control
// class implements a helper mathod that takes an IMediaSample interface and
// assuming it is a normal linear buffer copies the relevant section of the
// video into the output buffer provided. The method takes into account any
// source rectangle already specified by calling our GetSourceRect function

HRESULT CVideoWindow::GetStaticImage(long *pVideoSize,long *pVideoImage)
{
    NOTE("Entering GetStaticImage");
    IMediaSample *pMediaSample;
    RECT SourceRect;

    // Is there an image available

    pMediaSample = m_pRenderer->GetCurrentSample();
    if (pMediaSample == NULL) {
        return E_UNEXPECTED;
    }

    // Check the image isn't a DirectDraw sample

    if (m_pRenderer->m_VideoAllocator.GetDirectDrawStatus() == TRUE) {
        pMediaSample->Release();
        return E_FAIL;
    }

    // Find a scaled source rectangle for the current bitmap

    m_pRenderer->m_DrawVideo.GetSourceRect(&SourceRect);
    SourceRect = m_pRenderer->m_DrawVideo.ScaleSourceRect(&SourceRect);
    VIDEOINFO *pVideoInfo = (VIDEOINFO *) m_pRenderer->m_mtIn.Format();

    // Call the base class helper method to do the work

    HRESULT hr = CopyImage(pMediaSample,        // Buffer containing image
        (VIDEOINFOHEADER *)pVideoInfo,          // Type representing bitmap
                           pVideoSize,          // Size of buffer for DIB
                           (BYTE*) pVideoImage, // Data buffer for output
                           &SourceRect);        // Current source position

    pMediaSample->Release();
    return hr;
}


// The IVideoWindow control interface use this to reset the video destination
// We reset the flag that indicates whether we have a destination rectangle
// set explicitly or not, and then initialise the rectangle with the client
// window dimensions. These fields are used by the window thread when it does
// the drawing and also when it processes WM_SIZE messages (hence the lock)

HRESULT CVideoWindow::SetDefaultTargetRect()
{
    CAutoLock cWindowLock(&m_WindowLock);
    RECT TargetRect;

    // Update the draw objects

    EXECUTE_ASSERT(GetClientRect(m_hwnd,&TargetRect));
    m_pRenderer->m_DrawVideo.SetTargetRect(&TargetRect);
    m_pRenderer->m_DirectDraw.SetTargetRect(&TargetRect);
    m_bTargetSet = FALSE;
    return NOERROR;
}


// Return S_OK if using the default target otherwise S_FALSE

HRESULT CVideoWindow::IsDefaultTargetRect()
{
    CAutoLock cWindowLock(&m_WindowLock);
    return (m_bTargetSet ? S_FALSE : S_OK);
}


// This sets the destination rectangle for the real video. The rectangle may
// be larger or smaller than the video window is and may be offset into it as
// well so we rely on the drawing operations to clip (such as the StretchBlt)

HRESULT CVideoWindow::SetTargetRect(RECT *pTargetRect)
{
    CAutoLock cWindowLock(&m_WindowLock);
    m_bTargetSet = TRUE;

    // Update the draw objects
    m_pRenderer->m_DrawVideo.SetTargetRect(pTargetRect);
    m_pRenderer->m_DirectDraw.SetTargetRect(pTargetRect);

    return NOERROR;
}


// This complements the SetTargetRect method to return the rectangle in use
// as the destination. If we have had no rectangle explicitly set then we
// will return the client window size as updated in the WM_SIZE messages

HRESULT CVideoWindow::GetTargetRect(RECT *pTargetRect)
{
    CAutoLock cWindowLock(&m_WindowLock);
    m_pRenderer->m_DrawVideo.GetTargetRect(pTargetRect);
    return NOERROR;
}


// Reset the source rectangle to be all the available video

HRESULT CVideoWindow::SetDefaultSourceRect()
{
    CAutoLock cWindowLock(&m_WindowLock);
    SIZE VideoSize = m_pRenderer->m_VideoSize;
    RECT SourceRect = {0,0,VideoSize.cx,VideoSize.cy};

    // Update the draw objects

    m_pRenderer->m_DrawVideo.SetSourceRect(&SourceRect);
    m_pRenderer->m_DirectDraw.SetSourceRect(&SourceRect);
    return NOERROR;
}


// Return S_OK if using the default source otherwise S_FALSE

HRESULT CVideoWindow::IsDefaultSourceRect()
{
    RECT SourceRect;

    // Does the source match the native video size

    SIZE VideoSize = m_pRenderer->m_VideoSize;
    CAutoLock cWindowLock(&m_WindowLock);
    m_pRenderer->m_DrawVideo.GetSourceRect(&SourceRect);

    // Check the coordinates match the video dimensions

    if (SourceRect.right == VideoSize.cx) {
        if (SourceRect.bottom == VideoSize.cy) {
            if (SourceRect.left == 0) {
                if (SourceRect.top == 0) {
                    return S_OK;
                }
            }
        }
    }
    return S_FALSE;
}


// This is called when we want to change the section of the image to draw. We
// use this information in the drawing operation calls later on. We must also
// see if the source and destination rectangles have the same dimensions. If
// not then we must stretch during the drawing rather than doing a pixel copy

HRESULT CVideoWindow::SetSourceRect(RECT *pSourceRect)
{
    CAutoLock cWindowLock(&m_WindowLock);
    m_pRenderer->m_DrawVideo.SetSourceRect(pSourceRect);
    m_pRenderer->m_DirectDraw.SetSourceRect(pSourceRect);
    return NOERROR;
}


// This complements the SetSourceRect method

HRESULT CVideoWindow::GetSourceRect(RECT *pSourceRect)
{
    CAutoLock cWindowLock(&m_WindowLock);
    m_pRenderer->m_DrawVideo.GetSourceRect(pSourceRect);
    return NOERROR;
}


// We must override this to return a VIDEOINFO representing the video format
// The base class cannot call IPin ConnectionMediaType to get this format as
// dynamic type changes when using DirectDraw have the format show the image
// bitmap in terms of logical positions within a frame buffer surface, so a
// video might be returned as 1024x768 pixels, instead of the native 320x240

VIDEOINFOHEADER *CVideoWindow::GetVideoFormat()
{
    if (m_FormatSize < (int)m_pRenderer->m_mtIn.FormatLength()) {
        m_FormatSize = m_pRenderer->m_mtIn.FormatLength();
        if (m_pFormat)
            QzTaskMemFree(m_pFormat);
        m_pFormat = (VIDEOINFOHEADER *)QzTaskMemAlloc(m_FormatSize);
        if (m_pFormat == NULL) {
            m_FormatSize = 0;
            return NULL;
        }
    }
    CopyMemory((PVOID)m_pFormat, (PVOID)m_pRenderer->m_mtIn.Format(),
                            m_pRenderer->m_mtIn.FormatLength());
    m_pFormat->bmiHeader.biWidth = m_pRenderer->m_VideoSize.cx;
    m_pFormat->bmiHeader.biHeight = m_pRenderer->m_VideoSize.cy;
    return m_pFormat;
}


// The overlay object has on occasion to create a palette that will be used
// for colour keyed overlay source filters. However it wants to install the
// palette with it's critical section locked. Therefore it can't realise it
// as well otherwise it may end up deadlocking with an inter thread message
// sent to the window. So we install the palette but delay the realisation
// until later (by posting a WM_QUERYNEWPALETTE to the video window thread)

void CVideoWindow::SetKeyPalette(HPALETTE hPalette)
{
    // We must own the window lock during the change
    CAutoLock cWindowLock(&m_WindowLock);
    CAutoLock cPaletteLock(&m_PaletteLock);

    ASSERT(hPalette);
    m_hPalette = hPalette;

    // Select the palette into the device contexts
    SelectPalette(m_hdc,m_hPalette,m_bBackground);
    SelectPalette(m_MemoryDC,m_hPalette,m_bBackground);
    PostMessage(m_hwnd,WM_QUERYNEWPALETTE,0,0);
}
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\multimedia\dshow\filters\image\vidprop\modectl.cpp ===
// Copyright (c) 1994 - 1998  Microsoft Corporation.  All Rights Reserved.
// Implements a Modex property page, Anthony Phillips, February 1996

#include <streams.h>
#include <string.h>
#include <vidprop.h>

// This implements a display mode property page for the modex renderer. We
// communicate with the Modex renderer through the IFullScreenVideo control
// interface it implements and defined in the ActiveMovie SDK. The property
// page has one group box that shows the display modes available (if the
// display card does not support a given mode then we disable the checkbox)
// Although the fullscreen video interface allows the modes a renderer to
// support to dynamically change we use private knowledge of the modes the
// Modex renderer has enabled to construct a property page. The renderer
// enables 320x200x8/16, 320x240x8/16, 640x400x8/16 and 640x480,8/16 modes


// Constructor

CModexProperties::CModexProperties(LPUNKNOWN pUnk,HRESULT *phr) :
    CBasePropertyPage(NAME("Modex Page"),pUnk,IDD_MODEX,IDS_VID51),
    m_pModexVideo(NULL),
    m_CurrentMode(INFINITE),
    m_bInActivation(FALSE),
    m_ClipFactor(0)
{
    ASSERT(phr);
}


// Create a modex properties object

CUnknown *CModexProperties::CreateInstance(LPUNKNOWN lpUnk,HRESULT *phr)
{
    return new CModexProperties(lpUnk,phr);
}


// Load the current default property settings from the renderer

HRESULT CModexProperties::LoadProperties()
{
    NOTE("Loading properties");
    ASSERT(m_pModexVideo);
    BOOL bSetMode;

    m_pModexVideo->GetClipFactor(&m_ClipFactor);

    // What is the current mode chosen

    HRESULT hr = m_pModexVideo->GetCurrentMode(&m_CurrentMode);
    if (hr == VFW_E_NOT_CONNECTED) {
        m_CurrentMode = INFINITE;
    }

    // Store in the array a flag for each display mode

    for (LONG ModeCount = 0;ModeCount < MAXMODES;ModeCount++) {
        bSetMode = (m_pModexVideo->IsModeEnabled(ModeCount) == NOERROR ? TRUE : FALSE);
        m_bEnabledModes[ModeCount] = bSetMode;
        bSetMode = (m_pModexVideo->IsModeAvailable(ModeCount) == NOERROR ? TRUE : FALSE);
        m_bAvailableModes[ModeCount] = bSetMode;
    }
    return NOERROR;
}


// Load the current default property settings from the controls

HRESULT CModexProperties::UpdateVariables()
{
    NOTE("Updating variables");
    ASSERT(m_pModexVideo);
    HWND hwndDialog;

    // See which display modes are enabled

    for (LONG ModeCount = 0;ModeCount < MAXMODES;ModeCount++) {
        hwndDialog = GetDlgItem(m_Dlg,FIRST_MODEX_MODE + (ModeCount << 1));
        m_bEnabledModes[ModeCount] = Button_GetCheck(hwndDialog);
    }
    m_ClipFactor = (LONG) GetDlgItemInt(m_Dlg,MODEX_CLIP_EDIT,NULL,TRUE);
    return NOERROR;
}


// Initialise the check boxes in the property page

HRESULT CModexProperties::DisplayProperties()
{
    NOTE("Setting properties");
    LONG Width,Height,Depth;
    ASSERT(m_pModexVideo);
    BOOL bSetMode = FALSE;
    TCHAR Format[PROFILESTR];

    // Make a description for the current display mode chosen

    if (m_CurrentMode == INFINITE) {
        SendDlgItemMessage(m_Dlg,MODEX_CHOSEN_EDIT,WM_SETTEXT,0,(LPARAM) LoadVideoString(IDS_VID31));
    } else {
        m_pModexVideo->GetModeInfo(m_CurrentMode,&Width,&Height,&Depth);
        wsprintf(Format,TEXT("%dx%dx%d"),Width,Height,Depth);
        SendDlgItemMessage(m_Dlg,MODEX_CHOSEN_EDIT,WM_SETTEXT,0,(LPARAM) Format);
    }

    // Set the current clip percentage factor

    NOTE("Setting clip percentage");
    wsprintf(Format,TEXT("%d"),m_ClipFactor);
    SendDlgItemMessage(m_Dlg,MODEX_CLIP_EDIT,WM_SETTEXT,0,(LPARAM) Format);

    // Set the check box for each available display mode

    for (LONG ModeCount = 0;ModeCount < MAXMODES;ModeCount++) {
        HWND hwndDialog = GetDlgItem(m_Dlg,FIRST_MODEX_MODE + (ModeCount << 1));
        Button_SetCheck(hwndDialog,m_bEnabledModes[ModeCount]);
        hwndDialog = GetDlgItem(m_Dlg,FIRST_MODEX_TEXT + (ModeCount << 1));
        EnableWindow(hwndDialog,m_bAvailableModes[ModeCount]);
    }
    return NOERROR;
}


// Save the current property page settings

HRESULT CModexProperties::SaveProperties()
{
    TCHAR szExtra[STR_MAX_LENGTH];
    NOTE("Saving properties");
    ASSERT(m_pModexVideo);

    // Try and save the current clip factor

    HRESULT hr = m_pModexVideo->SetClipFactor(m_ClipFactor);
    if (FAILED(hr)) {
        MessageBox(m_hwnd,StringFromResource(szExtra,IDS_VID2),
                   LoadVideoString(IDS_VID1),
                   MB_OK | MB_ICONEXCLAMATION | MB_APPLMODAL);
    }

    // Get the check box setting for each available mode

    for (LONG ModeCount = 0;ModeCount < MAXMODES;ModeCount++) {
        BOOL bSetMode = m_bEnabledModes[ModeCount];
        m_pModexVideo->SetEnabled(ModeCount,(bSetMode == TRUE ? OATRUE : OAFALSE));
    }
    return m_pModexVideo->SetDefault();
}


// Handles the messages for our property window

INT_PTR CModexProperties::OnReceiveMessage(HWND hwnd,
                                        UINT uMsg,
                                        WPARAM wParam,
                                        LPARAM lParam)
{
    switch (uMsg) {

        case WM_COMMAND:

            // Are we setting the values to start with

            if (m_bInActivation == TRUE) {
                return (LRESULT) 1;
            }

            // Has the user clicked on one of the controls

            if (HIWORD(wParam) == BN_CLICKED || HIWORD(wParam) == EN_CHANGE) {
                if (LOWORD(wParam) >= FIRST_MODEX_BUTTON) {
                    if (LOWORD(wParam) <= LAST_MODEX_BUTTON) {
                        UpdateVariables();
                        m_bDirty = TRUE;
                        if (m_pPageSite) {
                            m_pPageSite->OnStatusChange(PROPPAGESTATUS_DIRTY);
                        }
                    }
                }
            }
            return (LRESULT) 1;
    }
    return CBasePropertyPage::OnReceiveMessage(hwnd,uMsg,wParam,lParam);
}


// Tells us the object that should be informed of the property changes. This
// is used to get the IFullScreenVideo interface the Modex renderer supports
// We are passed the IUnknown for the filter we are being attached to. If it
// doesn't support the full screen interface then we return an error which
// should stop us being shown. The application will also look after calling
// SetPageSite(NULL) and also SetObjects(0,NULL) when the page is destroyed

HRESULT CModexProperties::OnConnect(IUnknown *pUnknown)
{
    NOTE("Property SetObjects");
    ASSERT(m_pModexVideo == NULL);
    NOTE("Asking for interface");

    // Ask the renderer for it's IFullScreenVideo control interface

    HRESULT hr = pUnknown->QueryInterface(IID_IFullScreenVideo,(void **) &m_pModexVideo);
    if (FAILED(hr)) {
        NOTE("No IFullScreenVideo");
        return E_NOINTERFACE;
    }

    ASSERT(m_pModexVideo);
    LoadProperties();
    return NOERROR;
}


// Release any IFullScreenVideo interface we have

HRESULT CModexProperties::OnDisconnect()
{
    // Release the interface

    if (m_pModexVideo == NULL) {
        NOTE("Nothing to release");
        return E_UNEXPECTED;
    }

    NOTE("Releasing interface");
    m_pModexVideo->Release();
    m_pModexVideo = NULL;
    return NOERROR;
}


// Initialise the dialog box controls

HRESULT CModexProperties::OnActivate()
{
    NOTE("Property activate");
    m_bInActivation = TRUE;
    DisplayProperties();
    m_bInActivation = FALSE;
    return NOERROR;
}


// Apply any changes so far made

HRESULT CModexProperties::OnApplyChanges()
{
    NOTE("Property Apply");
    SaveProperties();
    return NOERROR;
}
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\multimedia\dshow\filters\image\vidprop\vidprop.cpp ===
// Copyright (c) 1994 - 1999  Microsoft Corporation.  All Rights Reserved.
// Video renderer property pages, Anthony Phillips, January 1996

#include <streams.h>
#include "vidprop.h"
#include <tchar.h>

// This class implements a property page for the video renderers. It uses the
// IDirectDrawVideo control interface exposed by the video renderer. Through
// this interface we can enable and disable specific DCI/DirectDraw features
// such as the use of overlay and offscreen surfaces. It also gives access
// to the capabilities of the DirectDraw provider. This can be used by the
// application if it wants to make sure the video window is aligned so that
// we can use overlay surfaces (for example). It also provides information
// so that it could find out we have a YUV offscreen surface available that
// can convert to RGB16 for example in which case it may want to change the
// display mode before we start running. We are handed an IUnknown interface
// pointer to the video renderer through the SetObjects interface function

const TCHAR TypeFace[]      = TEXT("TERMINAL");
const TCHAR FontSize[]      = TEXT("8");
const TCHAR ListBox[]       = TEXT("listbox");


// Constructor

CVideoProperties::CVideoProperties(LPUNKNOWN pUnk,HRESULT *phr) :
    CBasePropertyPage(NAME("Video Page"),pUnk,IDD_VIDEO,IDS_VID50),
    m_hwndList(NULL),
    m_hFont(NULL),
    m_pDirectDrawVideo(NULL),
    m_Switches(AMDDS_NONE)
{
    ASSERT(phr);
}


// Create a video properties object

CUnknown *CVideoProperties::CreateInstance(LPUNKNOWN lpUnk,HRESULT *phr)
{
    return new CVideoProperties(lpUnk,phr);
}


// Update the dialog box property page with the current settings

void CVideoProperties::SetDrawSwitches()
{
    Button_SetCheck(GetDlgItem(m_Dlg,DD_DCIPS),(m_Switches & AMDDS_DCIPS ? TRUE : FALSE));
    Button_SetCheck(GetDlgItem(m_Dlg,DD_PS),(m_Switches & AMDDS_PS ? TRUE : FALSE));
    Button_SetCheck(GetDlgItem(m_Dlg,DD_RGBOVR),(m_Switches & AMDDS_RGBOVR ? TRUE : FALSE));
    Button_SetCheck(GetDlgItem(m_Dlg,DD_YUVOVR),(m_Switches & AMDDS_YUVOVR ? TRUE : FALSE));
    Button_SetCheck(GetDlgItem(m_Dlg,DD_RGBOFF),(m_Switches & AMDDS_RGBOFF ? TRUE : FALSE));
    Button_SetCheck(GetDlgItem(m_Dlg,DD_YUVOFF),(m_Switches & AMDDS_YUVOFF ? TRUE : FALSE));
    Button_SetCheck(GetDlgItem(m_Dlg,DD_RGBFLP),(m_Switches & AMDDS_RGBFLP ? TRUE : FALSE));
    Button_SetCheck(GetDlgItem(m_Dlg,DD_YUVFLP),(m_Switches & AMDDS_YUVFLP ? TRUE : FALSE));
}


// Update the renderer with the current dialog box property page settings

#define GETSWITCH(x,flag,sw) {if (x == TRUE) sw |= flag;}

void CVideoProperties::GetDrawSwitches()
{
    m_Switches = AMDDS_NONE;

    GETSWITCH(Button_GetCheck(GetDlgItem(m_Dlg,DD_DCIPS)),AMDDS_DCIPS,m_Switches);
    GETSWITCH(Button_GetCheck(GetDlgItem(m_Dlg,DD_PS)),AMDDS_PS,m_Switches);
    GETSWITCH(Button_GetCheck(GetDlgItem(m_Dlg,DD_RGBOVR)),AMDDS_RGBOVR,m_Switches);
    GETSWITCH(Button_GetCheck(GetDlgItem(m_Dlg,DD_YUVOVR)),AMDDS_YUVOVR,m_Switches);
    GETSWITCH(Button_GetCheck(GetDlgItem(m_Dlg,DD_RGBOFF)),AMDDS_RGBOFF,m_Switches);
    GETSWITCH(Button_GetCheck(GetDlgItem(m_Dlg,DD_YUVOFF)),AMDDS_YUVOFF,m_Switches);
    GETSWITCH(Button_GetCheck(GetDlgItem(m_Dlg,DD_RGBFLP)),AMDDS_RGBFLP,m_Switches);
    GETSWITCH(Button_GetCheck(GetDlgItem(m_Dlg,DD_YUVFLP)),AMDDS_YUVFLP,m_Switches);
}


// Update the contents of the list box

void CVideoProperties::UpdateListBox(DWORD Id)
{
    DDSURFACEDESC SurfaceDesc;
    HRESULT hr = NOERROR;
    DDCAPS DirectCaps;

    ListBox_ResetContent(m_hwndList);

    // Do they want to see the hardware capabilities

    if (Id == DD_HARDWARE) {
        hr = m_pDirectDrawVideo->GetCaps(&DirectCaps);
        ListBox_AddString(m_hwndList,LoadVideoString(IDS_VID30));
        if (hr == NOERROR) {
            DisplayCapabilities(&DirectCaps);
        }
    }

    // Are they after the software emulation capabilities

    if (Id == DD_SOFTWARE) {
        hr = m_pDirectDrawVideo->GetEmulatedCaps(&DirectCaps);
        ListBox_AddString(m_hwndList,LoadVideoString(IDS_VID29));
        if (hr == NOERROR) {
            DisplayCapabilities(&DirectCaps);
        }
    }

    // Finally is it the surface information they want

    if (Id == DD_SURFACE) {
        hr = m_pDirectDrawVideo->GetSurfaceDesc(&SurfaceDesc);
        ListBox_AddString(m_hwndList,LoadVideoString(IDS_VID28));
        if (hr == S_FALSE) {
            ListBox_AddString(m_hwndList,LoadVideoString(IDS_VID32));
        } else if (hr == NOERROR) {
            DisplaySurfaceCapabilities(SurfaceDesc.ddsCaps);
        }
    }
}


// Handles the messages for our property window

INT_PTR CVideoProperties::OnReceiveMessage(HWND hwnd,
                                        UINT uMsg,
                                        WPARAM wParam,
                                        LPARAM lParam)
{
    switch (uMsg) {

        case WM_INITDIALOG:

            m_hwndList = GetDlgItem(hwnd,DD_LIST);
            return (LRESULT) 1;

        case WM_COMMAND:

            // User changed capabilities list box

            switch (LOWORD(wParam)) {
                case DD_SOFTWARE:
                case DD_HARDWARE:
                case DD_SURFACE:
                    UpdateListBox(LOWORD(wParam));
                    return (LRESULT) 0;
            }

            // Has the user clicked on one of the check boxes

            if (LOWORD(wParam) >= FIRST_DD_BUTTON) {
                if (LOWORD(wParam) <= LAST_DD_BUTTON) {
                    m_bDirty = TRUE;
                    GetDrawSwitches();
                    if (m_pPageSite) {
                        m_pPageSite->OnStatusChange(PROPPAGESTATUS_DIRTY);
                    }
                }
            }
            return (LRESULT) 1;
    }
    return CBasePropertyPage::OnReceiveMessage(hwnd,uMsg,wParam,lParam);
}


// Tells us the object that should be informed of the property changes

HRESULT CVideoProperties::OnConnect(IUnknown *pUnknown)
{
    ASSERT(m_pDirectDrawVideo == NULL);

    // Ask the renderer for it's IDirectDrawVideo control interface

    HRESULT hr = pUnknown->QueryInterface(IID_IDirectDrawVideo,(void **) &m_pDirectDrawVideo);
    if (FAILED(hr)) {
        return E_NOINTERFACE;
    }

    ASSERT(m_pDirectDrawVideo);
    m_pDirectDrawVideo->GetSwitches(&m_Switches);
    return NOERROR;
}


// Release any IDirectDrawVideo interface we have

HRESULT CVideoProperties::OnDisconnect()
{
    // Release the interface

    if (m_pDirectDrawVideo == NULL) {
        return E_UNEXPECTED;
    }

    m_pDirectDrawVideo->Release();
    m_pDirectDrawVideo = NULL;
    return NOERROR;
}


// Create the window we will use to edit properties

HRESULT CVideoProperties::OnActivate()
{
    // Create a small font for the capabilities - that is LOCALIZABLE

    NONCLIENTMETRICS ncm;
    ncm.cbSize = sizeof(NONCLIENTMETRICS);
    SystemParametersInfo(SPI_GETNONCLIENTMETRICS, sizeof(ncm), &ncm, 0);
    m_hFont = CreateFontIndirect(&ncm.lfStatusFont);

    Button_SetCheck(GetDlgItem(m_Dlg,DD_HARDWARE),TRUE);
    SetWindowFont(m_hwndList,m_hFont,TRUE);
    UpdateListBox(DD_HARDWARE);
    SetDrawSwitches();
    return NOERROR;
}


// Return the height this point size

INT CVideoProperties::GetHeightFromPointsString(LPCTSTR szPoints)
{
    HDC hdc;
    INT height;

    hdc = GetDC(NULL);
    if ( hdc )
        height = GetDeviceCaps(hdc, LOGPIXELSY );
    else
        height = 72;
    height = MulDiv(-_ttoi(szPoints), height, 72);
    if ( hdc )
        ReleaseDC(NULL, hdc);

    return height;
}


// Destroy the property page dialog

HRESULT CVideoProperties::OnDeactivate(void)
{
    DeleteObject(m_hFont);
    return NOERROR;
}


// Apply any changes so far made

HRESULT CVideoProperties::OnApplyChanges()
{
    TCHAR szExtra[STR_MAX_LENGTH];
    ASSERT(m_pDirectDrawVideo);
    ASSERT(m_pPageSite);

    // Apply the changes to the video renderer

    if (m_pDirectDrawVideo->SetSwitches(m_Switches) == S_FALSE) {
        MessageBox(m_hwnd,StringFromResource(szExtra,IDS_VID27),
                   LoadVideoString(IDS_VID33),
                   MB_OK | MB_ICONEXCLAMATION | MB_APPLMODAL);
    }
    return m_pDirectDrawVideo->SetDefault();
}


// For a variety of capabilities the driver can nominate certain bit depths as
// restrictions or capabilities, these may be so, for example, because it can
// handle only certain video memory bandwidths (all the bit fields have BBDB_
// prefixing them) In other situations this field can hold the real bit depth
// as an integer value such as when we create a DirectDraw primary surface

void CVideoProperties::DisplayBitDepths(DWORD dwCaps)
{
    if (dwCaps & DDBD_1) ListBox_AddString(m_hwndList,LoadVideoString(IDS_VID21));
    if (dwCaps & DDBD_2) ListBox_AddString(m_hwndList,LoadVideoString(IDS_VID22));
    if (dwCaps & DDBD_4) ListBox_AddString(m_hwndList,LoadVideoString(IDS_VID23));
    if (dwCaps & DDBD_8) ListBox_AddString(m_hwndList,LoadVideoString(IDS_VID24));
    if (dwCaps & DDBD_16) ListBox_AddString(m_hwndList,LoadVideoString(IDS_VID25));
    if (dwCaps & DDBD_32) ListBox_AddString(m_hwndList,LoadVideoString(IDS_VID26));
}


// The DDCAPS field contains all the capabilities of the driver and in general
// the surfaces it can provide although these may not be available when you
// come to request them. The capabilities are all defined through sets of bit
// fields, split into general driver, colour keys, special effects, palette,
// and stereo vision. Each set of capabilities also has specific bit depth
// restrictions assigned to it. Finally there are a bunch of miscellaneous
// capabilities and informational fields like the video memory on the card

void CVideoProperties::DisplayCapabilities(DDCAPS *pCaps)
{
    TCHAR String[PROFILESTR];

    // Deal with the driver specific capabilities

    if (pCaps->dwCaps & DDCAPS_3D) ListBox_AddString(m_hwndList,TEXT("DDCAPS_3D"));
    if (pCaps->dwCaps & DDCAPS_ALIGNBOUNDARYDEST) ListBox_AddString(m_hwndList,TEXT("DDCAPS_ALIGNBOUNDARYDEST"));
    if (pCaps->dwCaps & DDCAPS_ALIGNSIZEDEST) ListBox_AddString(m_hwndList,TEXT("DDCAPS_ALIGNSIZEDEST"));
    if (pCaps->dwCaps & DDCAPS_ALIGNBOUNDARYSRC) ListBox_AddString(m_hwndList,TEXT("DDCAPS_ALIGNBOUNDARYSRC"));
    if (pCaps->dwCaps & DDCAPS_ALIGNSIZESRC) ListBox_AddString(m_hwndList,TEXT("DDCAPS_ALIGNSIZESRC"));
    if (pCaps->dwCaps & DDCAPS_ALIGNSTRIDE) ListBox_AddString(m_hwndList,TEXT("DDCAPS_ALIGNSTRIDE"));
    if (pCaps->dwCaps & DDCAPS_BANKSWITCHED) ListBox_AddString(m_hwndList,TEXT("DDCAPS_BANKSWITCHED"));
    if (pCaps->dwCaps & DDCAPS_BLT) ListBox_AddString(m_hwndList,TEXT("DDCAPS_BLT"));
    if (pCaps->dwCaps & DDCAPS_BLTCOLORFILL) ListBox_AddString(m_hwndList,TEXT("DDCAPS_BLTCOLORFILL"));
    if (pCaps->dwCaps & DDCAPS_BLTQUEUE) ListBox_AddString(m_hwndList,TEXT("DDCAPS_BLTQUEUE"));
    if (pCaps->dwCaps & DDCAPS_BLTFOURCC) ListBox_AddString(m_hwndList,TEXT("DDCAPS_BLTFOURCC"));
    if (pCaps->dwCaps & DDCAPS_BLTSTRETCH) ListBox_AddString(m_hwndList,TEXT("DDCAPS_BLTSTRETCH"));
    if (pCaps->dwCaps & DDCAPS_GDI) ListBox_AddString(m_hwndList,TEXT("DDCAPS_GDI"));
    if (pCaps->dwCaps & DDCAPS_OVERLAY) ListBox_AddString(m_hwndList,TEXT("DDCAPS_OVERLAY"));
    if (pCaps->dwCaps & DDCAPS_OVERLAYCANTCLIP) ListBox_AddString(m_hwndList,TEXT("DDCAPS_OVERLAYCANTCLIP"));
    if (pCaps->dwCaps & DDCAPS_OVERLAYFOURCC) ListBox_AddString(m_hwndList,TEXT("DDCAPS_OVERLAYFOURCC"));
    if (pCaps->dwCaps & DDCAPS_OVERLAYSTRETCH) ListBox_AddString(m_hwndList,TEXT("DDCAPS_OVERLAYSTRETCH"));
    if (pCaps->dwCaps & DDCAPS_PALETTE) ListBox_AddString(m_hwndList,TEXT("DDCAPS_PALETTE"));
    if (pCaps->dwCaps & DDCAPS_READSCANLINE) ListBox_AddString(m_hwndList,TEXT("DDCAPS_READSCANLINE"));
//    if (pCaps->dwCaps & DDCAPS_STEREOVIEW) ListBox_AddString(m_hwndList,TEXT("DDCAPS_STEREOVIEW"));
    if (pCaps->dwCaps & DDCAPS_VBI) ListBox_AddString(m_hwndList,TEXT("DDCAPS_VBI"));
    if (pCaps->dwCaps & DDCAPS_ZBLTS) ListBox_AddString(m_hwndList,TEXT("DDCAPS_ZBLTS"));
    if (pCaps->dwCaps & DDCAPS_ZOVERLAYS) ListBox_AddString(m_hwndList,TEXT("DDCAPS_ZOVERLAYS"));
    if (pCaps->dwCaps & DDCAPS_COLORKEY) ListBox_AddString(m_hwndList,TEXT("DDCAPS_COLORKEY"));
    if (pCaps->dwCaps & DDCAPS_ALPHA) ListBox_AddString(m_hwndList,TEXT("DDCAPS_ALPHA"));
    if (pCaps->dwCaps & DDCAPS_NOHARDWARE) ListBox_AddString(m_hwndList,TEXT("DDCAPS_NOHARDWARE"));
    if (pCaps->dwCaps & DDCAPS_BLTDEPTHFILL) ListBox_AddString(m_hwndList,TEXT("DDCAPS_BLTDEPTHFILL"));
    if (pCaps->dwCaps & DDCAPS_CANCLIP) ListBox_AddString(m_hwndList,TEXT("DDCAPS_CANCLIP"));
    if (pCaps->dwCaps & DDCAPS_CANCLIPSTRETCHED) ListBox_AddString(m_hwndList,TEXT("DDCAPS_CANCLIPSTRETCHED"));
    if (pCaps->dwCaps & DDCAPS_CANBLTSYSMEM) ListBox_AddString(m_hwndList,TEXT("DDCAPS_CANBLTSYSMEM"));

    // Have a wee peek at the colour key capabilities

    if (pCaps->dwCKeyCaps & DDCKEYCAPS_DESTBLT) ListBox_AddString(m_hwndList,TEXT("DDCKEYCAPS_DESTBLT"));
    if (pCaps->dwCKeyCaps & DDCKEYCAPS_DESTBLTCLRSPACE) ListBox_AddString(m_hwndList,TEXT("DDCKEYCAPS_DESTBLTCLRSPACE"));
    if (pCaps->dwCKeyCaps & DDCKEYCAPS_DESTBLTCLRSPACEYUV) ListBox_AddString(m_hwndList,TEXT("DDCKEYCAPS_DESTBLTCLRSPACEYUV"));
    if (pCaps->dwCKeyCaps & DDCKEYCAPS_DESTBLTYUV) ListBox_AddString(m_hwndList,TEXT("DDCKEYCAPS_DESTBLTYUV"));
    if (pCaps->dwCKeyCaps & DDCKEYCAPS_DESTOVERLAY) ListBox_AddString(m_hwndList,TEXT("DDCKEYCAPS_DESTOVERLAY"));
    if (pCaps->dwCKeyCaps & DDCKEYCAPS_DESTOVERLAYCLRSPACE) ListBox_AddString(m_hwndList,TEXT("DDCKEYCAPS_DESTOVERLAYCLRSPACE"));
    if (pCaps->dwCKeyCaps & DDCKEYCAPS_DESTOVERLAYCLRSPACEYUV) ListBox_AddString(m_hwndList,TEXT("DDCKEYCAPS_DESTOVERLAYCLRSPACEYUV"));
    if (pCaps->dwCKeyCaps & DDCKEYCAPS_DESTOVERLAYONEACTIVE) ListBox_AddString(m_hwndList,TEXT("DDCKEYCAPS_DESTOVERLAYONEACTIVE"));
    if (pCaps->dwCKeyCaps & DDCKEYCAPS_DESTOVERLAYYUV) ListBox_AddString(m_hwndList,TEXT("DDCKEYCAPS_DESTOVERLAYYUV"));
    if (pCaps->dwCKeyCaps & DDCKEYCAPS_SRCBLT) ListBox_AddString(m_hwndList,TEXT("DDCKEYCAPS_SRCBLT"));
    if (pCaps->dwCKeyCaps & DDCKEYCAPS_SRCBLTCLRSPACE) ListBox_AddString(m_hwndList,TEXT("DDCKEYCAPS_SRCBLTCLRSPACE"));
    if (pCaps->dwCKeyCaps & DDCKEYCAPS_SRCBLTCLRSPACEYUV) ListBox_AddString(m_hwndList,TEXT("DDCKEYCAPS_SRCBLTCLRSPACEYUV"));
    if (pCaps->dwCKeyCaps & DDCKEYCAPS_SRCBLTYUV) ListBox_AddString(m_hwndList,TEXT("DDCKEYCAPS_SRCBLTYUV"));
    if (pCaps->dwCKeyCaps & DDCKEYCAPS_SRCOVERLAY) ListBox_AddString(m_hwndList,TEXT("DDCKEYCAPS_SRCOVERLAY"));
    if (pCaps->dwCKeyCaps & DDCKEYCAPS_SRCOVERLAYCLRSPACE) ListBox_AddString(m_hwndList,TEXT("DDCKEYCAPS_SRCOVERLAYCLRSPACE"));
    if (pCaps->dwCKeyCaps & DDCKEYCAPS_SRCOVERLAYCLRSPACEYUV) ListBox_AddString(m_hwndList,TEXT("DDCKEYCAPS_SRCOVERLAYCLRSPACEYUV"));
    if (pCaps->dwCKeyCaps & DDCKEYCAPS_SRCOVERLAYONEACTIVE) ListBox_AddString(m_hwndList,TEXT("DDCKEYCAPS_SRCOVERLAYONEACTIVE"));
    if (pCaps->dwCKeyCaps & DDCKEYCAPS_SRCOVERLAYYUV) ListBox_AddString(m_hwndList,TEXT("DDCKEYCAPS_SRCOVERLAYYUV"));
    if (pCaps->dwCKeyCaps & DDCKEYCAPS_NOCOSTOVERLAY) ListBox_AddString(m_hwndList,TEXT("DDCKEYCAPS_NOCOSTOVERLAY"));

    // Driver specific effects and stretching capabilities

    if (pCaps->dwFXCaps & DDFXCAPS_BLTARITHSTRETCHY) ListBox_AddString(m_hwndList,TEXT("DDFXCAPS_BLTARITHSTRETCHY"));
    if (pCaps->dwFXCaps & DDFXCAPS_BLTARITHSTRETCHYN) ListBox_AddString(m_hwndList,TEXT("DDFXCAPS_BLTARITHSTRETCHYN"));
    if (pCaps->dwFXCaps & DDFXCAPS_BLTMIRRORLEFTRIGHT) ListBox_AddString(m_hwndList,TEXT("DDFXCAPS_BLTMIRRORLEFTRIGHT"));
    if (pCaps->dwFXCaps & DDFXCAPS_BLTMIRRORUPDOWN) ListBox_AddString(m_hwndList,TEXT("DDFXCAPS_BLTMIRRORUPDOWN"));
    if (pCaps->dwFXCaps & DDFXCAPS_BLTROTATION) ListBox_AddString(m_hwndList,TEXT("DDFXCAPS_BLTROTATION"));
    if (pCaps->dwFXCaps & DDFXCAPS_BLTROTATION90) ListBox_AddString(m_hwndList,TEXT("DDFXCAPS_BLTROTATION90"));
    if (pCaps->dwFXCaps & DDFXCAPS_BLTSHRINKX) ListBox_AddString(m_hwndList,TEXT("DDFXCAPS_BLTSHRINKX"));
    if (pCaps->dwFXCaps & DDFXCAPS_BLTSHRINKXN) ListBox_AddString(m_hwndList,TEXT("DDFXCAPS_BLTSHRINKXN"));
    if (pCaps->dwFXCaps & DDFXCAPS_BLTSHRINKY) ListBox_AddString(m_hwndList,TEXT("DDFXCAPS_BLTSHRINKY"));
    if (pCaps->dwFXCaps & DDFXCAPS_BLTSHRINKYN) ListBox_AddString(m_hwndList,TEXT("DDFXCAPS_BLTSHRINKYN"));
    if (pCaps->dwFXCaps & DDFXCAPS_BLTSTRETCHX) ListBox_AddString(m_hwndList,TEXT("DDFXCAPS_BLTSTRETCHX"));
    if (pCaps->dwFXCaps & DDFXCAPS_BLTSTRETCHXN) ListBox_AddString(m_hwndList,TEXT("DDFXCAPS_BLTSTRETCHXN"));
    if (pCaps->dwFXCaps & DDFXCAPS_BLTSTRETCHY) ListBox_AddString(m_hwndList,TEXT("DDFXCAPS_BLTSTRETCHY"));
    if (pCaps->dwFXCaps & DDFXCAPS_BLTSTRETCHYN) ListBox_AddString(m_hwndList,TEXT("DDFXCAPS_BLTSTRETCHYN"));
    if (pCaps->dwFXCaps & DDFXCAPS_OVERLAYARITHSTRETCHY) ListBox_AddString(m_hwndList,TEXT("DDFXCAPS_OVERLAYARITHSTRETCHY"));
    if (pCaps->dwFXCaps & DDFXCAPS_OVERLAYARITHSTRETCHY) ListBox_AddString(m_hwndList,TEXT("DDFXCAPS_OVERLAYARITHSTRETCHY"));
    if (pCaps->dwFXCaps & DDFXCAPS_OVERLAYSHRINKX) ListBox_AddString(m_hwndList,TEXT("DDFXCAPS_OVERLAYSHRINKX"));
    if (pCaps->dwFXCaps & DDFXCAPS_OVERLAYSHRINKXN) ListBox_AddString(m_hwndList,TEXT("DDFXCAPS_OVERLAYSHRINKXN"));
    if (pCaps->dwFXCaps & DDFXCAPS_OVERLAYSHRINKY) ListBox_AddString(m_hwndList,TEXT("DDFXCAPS_OVERLAYSHRINKY"));
    if (pCaps->dwFXCaps & DDFXCAPS_OVERLAYSHRINKYN) ListBox_AddString(m_hwndList,TEXT("DDFXCAPS_OVERLAYSHRINKYN"));
    if (pCaps->dwFXCaps & DDFXCAPS_OVERLAYSTRETCHX) ListBox_AddString(m_hwndList,TEXT("DDFXCAPS_OVERLAYSTRETCHX"));
    if (pCaps->dwFXCaps & DDFXCAPS_OVERLAYSTRETCHXN) ListBox_AddString(m_hwndList,TEXT("DDFXCAPS_OVERLAYSTRETCHXN"));
    if (pCaps->dwFXCaps & DDFXCAPS_OVERLAYSTRETCHY) ListBox_AddString(m_hwndList,TEXT("DDFXCAPS_OVERLAYSTRETCHY"));
    if (pCaps->dwFXCaps & DDFXCAPS_OVERLAYSTRETCHYN) ListBox_AddString(m_hwndList,TEXT("DDFXCAPS_OVERLAYSTRETCHYN"));
    if (pCaps->dwFXCaps & DDFXCAPS_OVERLAYMIRRORLEFTRIGHT) ListBox_AddString(m_hwndList,TEXT("DDFXCAPS_OVERLAYMIRRORLEFTRIGHT"));
    if (pCaps->dwFXCaps & DDFXCAPS_OVERLAYMIRRORUPDOWN) ListBox_AddString(m_hwndList,TEXT("DDFXCAPS_OVERLAYMIRRORUPDOWN"));

    // Alpha channel driver specific capabilities

    if (pCaps->dwFXAlphaCaps & DDFXALPHACAPS_BLTALPHAEDGEBLEND) ListBox_AddString(m_hwndList,TEXT("DDFXCAPS_BLTALPHAEDGEBLEND"));
    if (pCaps->dwFXAlphaCaps & DDFXALPHACAPS_BLTALPHAPIXELS) ListBox_AddString(m_hwndList,TEXT("DDFXCAPS_BLTALPHAPIXELS"));
    if (pCaps->dwFXAlphaCaps & DDFXALPHACAPS_BLTALPHAPIXELSNEG) ListBox_AddString(m_hwndList,TEXT("DDFXCAPS_BLTALPHAPIXELSNEG"));
    if (pCaps->dwFXAlphaCaps & DDFXALPHACAPS_BLTALPHASURFACES) ListBox_AddString(m_hwndList,TEXT("DDFXCAPS_BLTALPHASURFACES"));
    if (pCaps->dwFXAlphaCaps & DDFXALPHACAPS_BLTALPHASURFACESNEG) ListBox_AddString(m_hwndList,TEXT("DDFXCAPS_BLTALPHASURFACESNEG"));
    if (pCaps->dwFXAlphaCaps & DDFXALPHACAPS_OVERLAYALPHAEDGEBLEND) ListBox_AddString(m_hwndList,TEXT("DDFXCAPS_OVERLAYALPHAEDGEBLEND"));
    if (pCaps->dwFXAlphaCaps & DDFXALPHACAPS_OVERLAYALPHAPIXELS) ListBox_AddString(m_hwndList,TEXT("DDFXCAPS_OVERLAYALPHAPIXELS"));
    if (pCaps->dwFXAlphaCaps & DDFXALPHACAPS_OVERLAYALPHAPIXELSNEG) ListBox_AddString(m_hwndList,TEXT("DDFXCAPS_OVERLAYALPHAPIXELSNEG"));
    if (pCaps->dwFXAlphaCaps & DDFXALPHACAPS_OVERLAYALPHASURFACES) ListBox_AddString(m_hwndList,TEXT("DDFXCAPS_OVERLAYALPHASURFACES"));
    if (pCaps->dwFXAlphaCaps & DDFXALPHACAPS_OVERLAYALPHASURFACESNEG) ListBox_AddString(m_hwndList,TEXT("DDFXCAPS_OVERLAYALPHASURFACESNEG"));

    // Palette capabilities

    if (pCaps->dwPalCaps & DDPCAPS_4BIT) ListBox_AddString(m_hwndList,TEXT("DDPCAPS_4BIT"));
    if (pCaps->dwPalCaps & DDPCAPS_8BITENTRIES) ListBox_AddString(m_hwndList,TEXT("DDPCAPS_8BITENTRIES"));
    if (pCaps->dwPalCaps & DDPCAPS_8BIT) ListBox_AddString(m_hwndList,TEXT("DDPCAPS_8BIT"));
    if (pCaps->dwPalCaps & DDPCAPS_INITIALIZE) ListBox_AddString(m_hwndList,TEXT("DDPCAPS_INITIALIZE"));
    if (pCaps->dwPalCaps & DDPCAPS_PRIMARYSURFACE) ListBox_AddString(m_hwndList,TEXT("DDPCAPS_PRIMARYSURFACE"));
//    if (pCaps->dwPalCaps & DDPCAPS_PRIMARYSURFACELEFT) ListBox_AddString(m_hwndList,TEXT("DDPCAPS_PRIMARYSURFACELEFT"));
    if (pCaps->dwPalCaps & DDPCAPS_VSYNC) ListBox_AddString(m_hwndList,TEXT("DDPCAPS_VSYNC"));
    if (pCaps->dwPalCaps & DDPCAPS_1BIT) ListBox_AddString(m_hwndList,TEXT("DDPCAPS_1BIT"));
    if (pCaps->dwPalCaps & DDPCAPS_2BIT) ListBox_AddString(m_hwndList,TEXT("DDPCAPS_2BIT"));

    // Stereo vision capabilities (very useful for video)

//    if (pCaps->dwSVCaps & DDSVCAPS_ENIGMA) ListBox_AddString(m_hwndList,TEXT("DDSVCAPS_ENIGMA"));
//    if (pCaps->dwSVCaps & DDSVCAPS_FLICKER) ListBox_AddString(m_hwndList,TEXT("DDSVCAPS_FLICKER"));
//    if (pCaps->dwSVCaps & DDSVCAPS_REDBLUE) ListBox_AddString(m_hwndList,TEXT("DDSVCAPS_REDBLUE"));
//    if (pCaps->dwSVCaps & DDSVCAPS_SPLIT) ListBox_AddString(m_hwndList,TEXT("DDSVCAPS_SPLIT"));

    // Show bit depth restrictions and limitations

    ListBox_AddString(m_hwndList,TEXT("dwAlphaBltConstBitDepths"));
    DisplayBitDepths(pCaps->dwAlphaBltConstBitDepths);
    ListBox_AddString(m_hwndList,TEXT("dwAlphaBltPixelBitDepths"));
    DisplayBitDepths(pCaps->dwAlphaBltPixelBitDepths);
    ListBox_AddString(m_hwndList,TEXT("dwAlphaBltSurfaceBitDepths"));
    DisplayBitDepths(pCaps->dwAlphaBltSurfaceBitDepths);
    ListBox_AddString(m_hwndList,TEXT("dwAlphaOverlayConstBitDepths"));
    DisplayBitDepths(pCaps->dwAlphaOverlayConstBitDepths);
    ListBox_AddString(m_hwndList,TEXT("dwAlphaOverlayPixelBitDepths"));
    DisplayBitDepths(pCaps->dwAlphaOverlayPixelBitDepths);
    ListBox_AddString(m_hwndList,TEXT("dwAlphaOverlaySurfaceBitDepths"));
    DisplayBitDepths(pCaps->dwAlphaOverlaySurfaceBitDepths);
    ListBox_AddString(m_hwndList,TEXT("dwZBufferBitDepths"));
    DisplayBitDepths(pCaps->dwZBufferBitDepths);

    // And a bunch of other random guff

    wsprintf(String,TEXT("%s %d"),LoadVideoString(IDS_VID5),pCaps->dwVidMemTotal);
    ListBox_AddString(m_hwndList,String);
    wsprintf(String,TEXT("%s %d"),LoadVideoString(IDS_VID6),pCaps->dwVidMemFree);
    ListBox_AddString(m_hwndList,String);
    wsprintf(String,TEXT("%s %d"),LoadVideoString(IDS_VID7),pCaps->dwMaxVisibleOverlays);
    ListBox_AddString(m_hwndList,String);
    wsprintf(String,TEXT("%s %d"),LoadVideoString(IDS_VID8),pCaps->dwCurrVisibleOverlays);
    ListBox_AddString(m_hwndList,String);
    wsprintf(String,TEXT("%s %d"),LoadVideoString(IDS_VID9),pCaps->dwNumFourCCCodes);
    ListBox_AddString(m_hwndList,String);
    wsprintf(String,TEXT("%s %d"),LoadVideoString(IDS_VID10),pCaps->dwAlignBoundarySrc);
    ListBox_AddString(m_hwndList,String);
    wsprintf(String,TEXT("%s %d"),LoadVideoString(IDS_VID11),pCaps->dwAlignSizeSrc);
    ListBox_AddString(m_hwndList,String);
    wsprintf(String,TEXT("%s %d"),LoadVideoString(IDS_VID12),pCaps->dwAlignBoundaryDest);
    ListBox_AddString(m_hwndList,String);
    wsprintf(String,TEXT("%s %d"),LoadVideoString(IDS_VID13),pCaps->dwAlignSizeDest);
    ListBox_AddString(m_hwndList,String);
    wsprintf(String,TEXT("%s %d"),LoadVideoString(IDS_VID14),pCaps->dwAlignStrideAlign);
    ListBox_AddString(m_hwndList,String);
    wsprintf(String,TEXT("%s %d"),LoadVideoString(IDS_VID15),pCaps->dwMinOverlayStretch);
    ListBox_AddString(m_hwndList,String);
    wsprintf(String,TEXT("%s %d"),LoadVideoString(IDS_VID16),pCaps->dwMaxOverlayStretch);
    ListBox_AddString(m_hwndList,String);
    wsprintf(String,TEXT("%s %d"),LoadVideoString(IDS_VID17),pCaps->dwMinLiveVideoStretch);
    ListBox_AddString(m_hwndList,String);
    wsprintf(String,TEXT("%s %d"),LoadVideoString(IDS_VID18),pCaps->dwMaxLiveVideoStretch);
    ListBox_AddString(m_hwndList,String);
    wsprintf(String,TEXT("%s %d"),LoadVideoString(IDS_VID19),pCaps->dwMinHwCodecStretch);
    ListBox_AddString(m_hwndList,String);
    wsprintf(String,TEXT("%s %d"),LoadVideoString(IDS_VID20),pCaps->dwMaxHwCodecStretch);
    ListBox_AddString(m_hwndList,String);

    DisplayFourCCCodes();
}


// Display the non RGB surfaces they support

void CVideoProperties::DisplayFourCCCodes()
{
    TCHAR String[PROFILESTR];
    HRESULT hr = NOERROR;
    DWORD *pArray;
    DWORD Codes;

    // Find out how many codes there are

    hr = m_pDirectDrawVideo->GetFourCCCodes(&Codes,NULL);
    if (FAILED(hr)) {
        wsprintf(String,LoadVideoString(IDS_VID4));
        ListBox_AddString(m_hwndList,String);
        return;
    }

    // Show how many FOURCC codes we have

    wsprintf(String,TEXT("%s (%d)"),LoadVideoString(IDS_VID3),Codes);
    ListBox_AddString(m_hwndList,String);
    NOTE1("Display cards supports %d FOURCCs",Codes);

    // Does it support any codes

    if (Codes == 0) {
        return;
    }

    // Allocate some memory for the codes

    pArray = new DWORD[Codes];
    if (pArray == NULL) {
        return;
    }

    m_pDirectDrawVideo->GetFourCCCodes(&Codes,pArray);

    // Dump each of the codes in turn

    DWORD szFcc[2];         // null terminated fcc
    szFcc[1] = 0;
    for (DWORD Loop = 0;Loop < Codes;Loop++) {
        szFcc[0] = pArray[Loop];
        wsprintf(String,TEXT(" %d %4.4hs"),Loop+1,szFcc);
        ListBox_AddString(m_hwndList,String);
    }
    delete[] pArray;
}


// These describe the surface capabilities available

void CVideoProperties::DisplaySurfaceCapabilities(DDSCAPS ddsCaps)
{
    if (ddsCaps.dwCaps & DDSCAPS_ALPHA) ListBox_AddString(m_hwndList,TEXT("DDSCAPS_ALPHA"));
    if (ddsCaps.dwCaps & DDSCAPS_BACKBUFFER) ListBox_AddString(m_hwndList,TEXT("DDSCAPS_BACKBUFFER"));
    if (ddsCaps.dwCaps & DDSCAPS_COMPLEX) ListBox_AddString(m_hwndList,TEXT("DDSCAPS_COMPLEX"));
    if (ddsCaps.dwCaps & DDSCAPS_FLIP) ListBox_AddString(m_hwndList,TEXT("DDSCAPS_FLIP"));
    if (ddsCaps.dwCaps & DDSCAPS_FRONTBUFFER) ListBox_AddString(m_hwndList,TEXT("DDSCAPS_FRONTBUFFER"));
    if (ddsCaps.dwCaps & DDSCAPS_OFFSCREENPLAIN) ListBox_AddString(m_hwndList,TEXT("DDSCAPS_OFFSCREENPLAIN"));
    if (ddsCaps.dwCaps & DDSCAPS_OVERLAY) ListBox_AddString(m_hwndList,TEXT("DDSCAPS_OVERLAY"));
    if (ddsCaps.dwCaps & DDSCAPS_PALETTE) ListBox_AddString(m_hwndList,TEXT("DDSCAPS_PALETTE"));
    if (ddsCaps.dwCaps & DDSCAPS_PRIMARYSURFACE) ListBox_AddString(m_hwndList,TEXT("DDSCAPS_PRIMARYSURFACE"));
//    if (ddsCaps.dwCaps & DDSCAPS_PRIMARYSURFACELEFT) ListBox_AddString(m_hwndList,TEXT("DDSCAPS_PRIMARYSURFACELEFT"));
    if (ddsCaps.dwCaps & DDSCAPS_SYSTEMMEMORY) ListBox_AddString(m_hwndList,TEXT("DDSCAPS_SYSTEMMEMORY"));
    if (ddsCaps.dwCaps & DDSCAPS_TEXTURE) ListBox_AddString(m_hwndList,TEXT("DDSCAPS_TEXTURE"));
    if (ddsCaps.dwCaps & DDSCAPS_3DDEVICE) ListBox_AddString(m_hwndList,TEXT("DDSCAPS_3DDEVICE"));
    if (ddsCaps.dwCaps & DDSCAPS_VIDEOMEMORY) ListBox_AddString(m_hwndList,TEXT("DDSCAPS_VIDEOMEMORY"));
    if (ddsCaps.dwCaps & DDSCAPS_VISIBLE) ListBox_AddString(m_hwndList,TEXT("DDSCAPS_VISIBLE"));
    if (ddsCaps.dwCaps & DDSCAPS_WRITEONLY) ListBox_AddString(m_hwndList,TEXT("DDSCAPS_WRITEONLY"));
    if (ddsCaps.dwCaps & DDSCAPS_ZBUFFER) ListBox_AddString(m_hwndList,TEXT("DDSCAPS_ZBUFFER"));
    if (ddsCaps.dwCaps & DDSCAPS_OWNDC) ListBox_AddString(m_hwndList,TEXT("DDSCAPS_OWNDC"));
    if (ddsCaps.dwCaps & DDSCAPS_LIVEVIDEO) ListBox_AddString(m_hwndList,TEXT("DDSCAPS_LIVEVIDEO"));
    if (ddsCaps.dwCaps & DDSCAPS_HWCODEC) ListBox_AddString(m_hwndList,TEXT("DDSCAPS_HWCODEC"));
    if (ddsCaps.dwCaps & DDSCAPS_MODEX) ListBox_AddString(m_hwndList,TEXT("DDSCAPS_MODEX"));
    if (ddsCaps.dwCaps & DDSCAPS_MIPMAP) ListBox_AddString(m_hwndList,TEXT("DDSCAPS_MIPMAP"));
    if (ddsCaps.dwCaps & DDSCAPS_ALLOCONLOAD) ListBox_AddString(m_hwndList,TEXT("DDSCAPS_ALLOCONLOAD"));
}


// This class implements a property page dialog for the video renderer. We
// expose certain statistics from the quality management implementation. In
// particular we have two edit fields that show the number of frames we have
// actually drawn and the number of frames that we dropped. The number of
// frames we dropped does NOT represent the total number dropped in any play
// back sequence (as expressed through MCI status frames skipped) since the
// quality management protocol may have negotiated with the source filter for
// it to send fewer frames in the first place. Dropping frames in the source
// filter is nearly always a more efficient mechanism when we are flooded


// Constructor

CQualityProperties::CQualityProperties(LPUNKNOWN pUnk,HRESULT *phr) :
    CBasePropertyPage(NAME("Quality Page"),pUnk,IDD_QUALITY,IDS_VID52),
    m_pQualProp(NULL)
{
    ASSERT(phr);
}


// Create a quality properties object

CUnknown *CQualityProperties::CreateInstance(LPUNKNOWN lpUnk, HRESULT *phr)
{
    return new CQualityProperties(lpUnk, phr);
}


// Give us the filter to communicate with

HRESULT CQualityProperties::OnConnect(IUnknown *pUnknown)
{
    ASSERT(m_pQualProp == NULL);

    // Ask the renderer for it's IQualProp interface

    HRESULT hr = pUnknown->QueryInterface(IID_IQualProp,(void **)&m_pQualProp);
    if (FAILED(hr)) {
        return E_NOINTERFACE;
    }

    ASSERT(m_pQualProp);

    // Get quality data for our page

    m_pQualProp->get_FramesDroppedInRenderer(&m_iDropped);
    m_pQualProp->get_FramesDrawn(&m_iDrawn);
    m_pQualProp->get_AvgFrameRate(&m_iFrameRate);
    m_pQualProp->get_Jitter(&m_iFrameJitter);
    m_pQualProp->get_AvgSyncOffset(&m_iSyncAvg);
    m_pQualProp->get_DevSyncOffset(&m_iSyncDev);
    return NOERROR;
}


// Release any IQualProp interface we have

HRESULT CQualityProperties::OnDisconnect()
{
    // Release the interface

    if (m_pQualProp == NULL) {
        return E_UNEXPECTED;
    }

    m_pQualProp->Release();
    m_pQualProp = NULL;
    return NOERROR;
}


// Set the text fields in the property page

HRESULT CQualityProperties::OnActivate()
{
    SetEditFieldData();
    return NOERROR;
}


// Initialise the property page fields

void CQualityProperties::SetEditFieldData()
{
    ASSERT(m_pQualProp);
    TCHAR buffer[50];

    wsprintf(buffer,TEXT("%d"), m_iDropped);
    SendDlgItemMessage(m_Dlg, IDD_QDROPPED, WM_SETTEXT, 0, (LPARAM) (LPSTR) buffer);
    wsprintf(buffer,TEXT("%d"), m_iDrawn);
    SendDlgItemMessage(m_Dlg, IDD_QDRAWN, WM_SETTEXT, 0, (LPARAM) (LPSTR) buffer);
    wsprintf(buffer,TEXT("%d.%02d"), m_iFrameRate/100, m_iFrameRate%100);
    SendDlgItemMessage(m_Dlg, IDD_QAVGFRM, WM_SETTEXT, 0, (LPARAM) (LPSTR) buffer);
    wsprintf(buffer,TEXT("%d"), m_iFrameJitter);
    SendDlgItemMessage(m_Dlg, IDD_QJITTER, WM_SETTEXT, 0, (LPARAM) (LPSTR) buffer);
    wsprintf(buffer,TEXT("%d"), m_iSyncAvg);
    SendDlgItemMessage(m_Dlg, IDD_QSYNCAVG, WM_SETTEXT, 0, (LPARAM) (LPSTR) buffer);
    wsprintf(buffer,TEXT("%d"), m_iSyncDev);
    SendDlgItemMessage(m_Dlg, IDD_QSYNCDEV, WM_SETTEXT, 0, (LPARAM) (LPSTR) buffer);
}


// We allow users to customise how the video filter optimises its performance
// This comes down to three difference options. The first is whether or not we
// use the current scan line before drawing offscreen surfaces, if we do then
// we will reduce tearing but at the cost of frame throughput. The second one
// is whether we honour the minimum and maximum overlay stretch limits. Some
// drivers still look ok even when we apparently violate the restrictions. The
// final property is whether we should always use the renderer window when we
// are made fullscreen - in which case we can guarantee the video will stretch
// fullscreen rather than perhaps being placed in the centre of the display if
// the fullscreen renderer couldn't get anyone (ie source filters) to stretch


// Constructor

CPerformanceProperties::CPerformanceProperties(LPUNKNOWN pUnk,HRESULT *phr) :
    CBasePropertyPage(NAME("Performance Page"),pUnk,IDD_PERFORMANCE,IDS_VID53),
    m_pDirectDrawVideo(NULL),
    m_WillUseFullScreen(OAFALSE),
    m_CanUseScanLine(OATRUE),
    m_CanUseOverlayStretch(OATRUE)
{
    ASSERT(phr);
}


// Create a quality properties object

CUnknown *CPerformanceProperties::CreateInstance(LPUNKNOWN lpUnk, HRESULT *phr)
{
    return new CPerformanceProperties(lpUnk, phr);
}


// Give us the filter to communicate with

HRESULT CPerformanceProperties::OnConnect(IUnknown *pUnknown)
{
    ASSERT(m_pDirectDrawVideo == NULL);

    // Ask the renderer for it's IDirectDrawVideo control interface

    HRESULT hr = pUnknown->QueryInterface(IID_IDirectDrawVideo,(void **) &m_pDirectDrawVideo);
    if (FAILED(hr)) {
        return E_NOINTERFACE;
    }

    ASSERT(m_pDirectDrawVideo);

    // Get performance properties for our page

    m_pDirectDrawVideo->CanUseScanLine(&m_CanUseScanLine);
    m_pDirectDrawVideo->CanUseOverlayStretch(&m_CanUseOverlayStretch);
    m_pDirectDrawVideo->WillUseFullScreen(&m_WillUseFullScreen);
    return NOERROR;
}


// Release any IQualProp interface we have

HRESULT CPerformanceProperties::OnDisconnect()
{
    // Release the interface

    if (m_pDirectDrawVideo == NULL) {
        return E_UNEXPECTED;
    }

    m_pDirectDrawVideo->Release();
    m_pDirectDrawVideo = NULL;
    return NOERROR;
}


// Set the check box fields in the property page

HRESULT CPerformanceProperties::OnActivate()
{
    BOOL bSetCheck = (m_CanUseScanLine == OATRUE ? TRUE : FALSE);
    Button_SetCheck(GetDlgItem(m_Dlg,IDD_SCANLINE),bSetCheck);
    bSetCheck = (m_CanUseOverlayStretch == OATRUE ? TRUE : FALSE);
    Button_SetCheck(GetDlgItem(m_Dlg,IDD_OVERLAY),bSetCheck);
    bSetCheck = (m_WillUseFullScreen == OATRUE ? TRUE : FALSE);
    Button_SetCheck(GetDlgItem(m_Dlg,IDD_FULLSCREEN),bSetCheck);

    return NOERROR;
}


// Apply any changes so far made

HRESULT CPerformanceProperties::OnApplyChanges()
{
    TCHAR m_Resource[STR_MAX_LENGTH];
    TCHAR szExtra[STR_MAX_LENGTH];
    ASSERT(m_pDirectDrawVideo);
    ASSERT(m_pPageSite);

    // Set the OLE automation compatible properties

    m_pDirectDrawVideo->UseScanLine(m_CanUseScanLine);
    m_pDirectDrawVideo->UseOverlayStretch(m_CanUseOverlayStretch);
    m_pDirectDrawVideo->UseWhenFullScreen(m_WillUseFullScreen);

    MessageBox(m_hwnd,StringFromResource(szExtra,IDS_VID27),
               LoadVideoString(IDS_VID33),
               MB_OK | MB_ICONEXCLAMATION | MB_APPLMODAL);

    return m_pDirectDrawVideo->SetDefault();
}


// Handles the messages for our property window

INT_PTR CPerformanceProperties::OnReceiveMessage(HWND hwnd,
                                              UINT uMsg,
                                              WPARAM wParam,
                                              LPARAM lParam)
{
    switch (uMsg) {

        case WM_COMMAND:

            // Has the user clicked on one of the check boxes

            if (LOWORD(wParam) >= IDD_SCANLINE) {
                if (LOWORD(wParam) <= IDD_FULLSCREEN) {
                    m_bDirty = TRUE;
                    if (m_pPageSite) {
                        m_pPageSite->OnStatusChange(PROPPAGESTATUS_DIRTY);
                    }
                    HWND hDlg = GetDlgItem(hwnd,IDD_SCANLINE);
                    m_CanUseScanLine = (Button_GetCheck(hDlg) ? OATRUE : OAFALSE);
                    hDlg = GetDlgItem(hwnd,IDD_OVERLAY);
                    m_CanUseOverlayStretch = (Button_GetCheck(hDlg) ? OATRUE : OAFALSE);
                    hDlg = GetDlgItem(hwnd,IDD_FULLSCREEN);
                    m_WillUseFullScreen = (Button_GetCheck(hDlg) ? OATRUE : OAFALSE);

                }
            }
            return (LRESULT) 1;
    }
    return CBasePropertyPage::OnReceiveMessage(hwnd,uMsg,wParam,lParam);
}
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\multimedia\dshow\filters\image\vidsrc\vidsrc.cpp ===
//==========================================================================;
//
//  THIS CODE AND INFORMATION IS PROVIDED "AS IS" WITHOUT WARRANTY OF ANY
//  KIND, EITHER EXPRESSED OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE
//  IMPLIED WARRANTIES OF MERCHANTABILITY AND/OR FITNESS FOR A PARTICULAR
//  PURPOSE.
//
//  Copyright (c) 1992 - 1999  Microsoft Corporation.  All Rights Reserved.
//
//--------------------------------------------------------------------------;

#include <streams.h>
#include <olectl.h>
#include <initguid.h>
#include <olectlid.h>
#include <viduids.h>
#include <vidsrc.h>


// List of class IDs and creator functions for the class factory. This
// provides the link between the OLE entry point in the DLL and an object
// being created. The class factory will call the static CreateInstance
// function when it is asked to create a CLSID_VideoRenderer COM object

CFactoryTemplate g_Templates[] = {
  { L"Video source",&CLSID_VideoSource,CVideoSource::CreateInstance }
};
int g_cTemplates = sizeof(g_Templates) / sizeof(g_Templates[0]);


// Setup data

AMOVIESETUP_MEDIATYPE sudSourcePinTypes =
{
    &MEDIATYPE_Video,           // Major type
    &MEDIASUBTYPE_NULL          // And subtype
};

AMOVIESETUP_PIN sudSourcePin =
{
    L"Output",                  // The pin's name
    FALSE,                      // Is it rendered
    TRUE,                       // Is it an output
    FALSE,                      // Can we have zero
    FALSE,                      // Are many allowed
    &CLSID_NULL,                // Filter connects
    NULL,                       // And pin connects
    1,                          // Number of types
    &sudSourcePinTypes          // The pin details
};

AMOVIESETUP_FILTER sudSourceFilter =
{
    &CLSID_VideoSource,         // Filter CLSID
    L"Video Source",            // String name
    MERIT_UNLIKELY,             // Filter merit
    1,                          // Number of pins
    &sudSourcePin               // Pin details
};

// Exported entry points for registration of server

STDAPI DllRegisterServer()
{
  return AMovieDllRegisterServer();
}

STDAPI DllUnregisterServer()
{
  return AMovieDllUnregisterServer();
}

// Return the filter's registry information

LPAMOVIESETUP_FILTER CVideoSource::GetSetupData()
{
  return &sudSourceFilter;
}


// Creator function for video source filters

CUnknown *CVideoSource::CreateInstance(LPUNKNOWN pUnk,HRESULT *phr)
{
    CUnknown *pObject = new CVideoSource(NAME("Video Source"),pUnk,phr);
    if (pObject == NULL) {
        NOTE("No object made");
        *phr = E_OUTOFMEMORY;
    }
    return pObject;
}


// Constructor

CVideoSource::CVideoSource(TCHAR *pName,
                           LPUNKNOWN pUnk,
                           HRESULT *phr) :

    CSource(pName,pUnk,CLSID_VideoSource)
{
    // Allocate the array for the streams

    m_paStreams = (CSourceStream **) new CVideoStream *[1];
    if (m_paStreams == NULL) {
        *phr = E_OUTOFMEMORY;
        NOTE("No stream memory");
        return;
    }

    // Create the actual stream object

    m_paStreams[0] = new CVideoStream(phr,this,L"Source");
    if (m_paStreams[0] == NULL) {
        *phr = E_OUTOFMEMORY;
        NOTE("No stream object");
        return;
    }
}


// Constructor

CVideoStream::CVideoStream(HRESULT *phr,
                           CVideoSource *pVideoSource,
                           LPCWSTR pPinName) :

    CSourceStream(NAME("Stream"),phr,pVideoSource,pPinName),
    CMediaPosition(NAME("Position"),CSourceStream::GetOwner()),
    m_pVideoSource(pVideoSource),
    m_StopFrame(DURATION-1),
    m_bStoreMediaTimes(FALSE),
    m_bNewSegment(TRUE),
    m_rtSampleTime(0),
    m_CurrentFrame(0),
    m_pBase(NULL),
    m_hMapping(NULL),
    m_hBitmap(NULL),
    m_hdcDisplay(NULL),
    m_hdcMemory(NULL),
    m_hFont(NULL),
    m_dbRate(1.0)
{
    NOTE("CVideoStream Constructor");
    ASSERT(pVideoSource);
    m_rtIncrement = MILLISECONDS_TO_100NS_UNITS(INCREMENT);
}


// Destructor

CVideoStream::~CVideoStream()
{
    NOTE("CVideoStream Destructor");
}


// Overriden to say what interfaces we support

STDMETHODIMP CVideoStream::NonDelegatingQueryInterface(REFIID riid,VOID **ppv)
{
    NOTE("Entering NonDelegatingQueryInterface");

    // We return IMediaSeeking and IMediaPosition from here

    if (riid == IID_IMediaSeeking) {
        NOTE("Returning IMediaSeeking");
        return GetInterface((IMediaSeeking *)this,ppv);
    } else if (riid == IID_IMediaPosition) {
        NOTE("Returning IMediaPosition");
        return CMediaPosition::NonDelegatingQueryInterface(riid,ppv);
    } else if (riid == IID_IMediaEventSink) {
        NOTE("Returning IMediaEventSink");
        return GetInterface((IMediaEventSink *)this,ppv);
    }
    return CSourceStream::NonDelegatingQueryInterface(riid,ppv);
}


// Release the offscreen buffer resources

HRESULT CVideoStream::ReleaseNumbersFrame()
{
    NOTE("DeleteNumbersFrame");

    if (m_hBitmap) DeleteObject(m_hBitmap);
    if (m_hMapping) CloseHandle(m_hMapping);
    if (m_hdcDisplay) ReleaseDC(NULL,m_hdcDisplay);
    if (m_hdcMemory) DeleteDC(m_hdcMemory);
    if (m_hFont) DeleteObject(m_hFont);

    m_hMapping = NULL;
    m_hBitmap = NULL;
    m_pBase = NULL;
    m_hdcMemory = NULL;
    m_hdcDisplay = NULL;
    m_hFont = NULL;
    return NOERROR;
}


// The way we draw numbers into an image is to create an offscreen buffer. We
// create a bitmap from this and select it into an offscreen HDC. Using this
// we can draw the text using GDI. Once we have our image we can use the base
// buffer pointer from the CreateFileMapping call and copy each frame into it
// To be more efficient we could draw the text into a monochrome bitmap and
// read the bits set from it and generate the output image by setting pixels

HRESULT CVideoStream::InitNumbersFrame()
{
    NOTE("InitNumbersFrame");

    VIDEOINFO *pVideoInfo = (VIDEOINFO *) m_mt.Format();
    BITMAPINFO *pbmi = (BITMAPINFO *) HEADER(pVideoInfo);
    LONG InSize = pVideoInfo->bmiHeader.biSizeImage;

    // Create a file mapping object and map into our address space

    m_hMapping = CreateFileMapping(INVALID_HANDLE_VALUE,  // Use page file
                                   NULL,                  // No security used
                                   PAGE_READWRITE,        // Complete access
                                   (DWORD) 0,             // Less than 4Gb
                                   InSize,                // Size of buffer
                                   NULL);                 // No section name
    if (m_hMapping == NULL) {
        DWORD Error = GetLastError();
        NOTE("No file mappping");
        ReleaseNumbersFrame();
        return AmHresultFromWin32(Error);
    }

    // Now create the shared memory DIBSECTION

    m_hBitmap = CreateDIBSection((HDC) NULL,          // NO device context
                                 pbmi,                // Format information
                                 DIB_RGB_COLORS,      // Use the palette
                                 (VOID **) &m_pBase,  // Pointer to image data
                                 m_hMapping,          // Mapped memory handle
                                 (DWORD) 0);          // Offset into memory

    if (m_hBitmap == NULL || m_pBase == NULL) {
        DWORD Error = GetLastError();
        NOTE("No DIBSECTION made");
        ReleaseNumbersFrame();
        return AmHresultFromWin32(Error);
    }

    // Get a device context for the display

    m_hdcDisplay = GetDC(NULL);
    if (m_hdcDisplay == NULL) {
        NOTE("No device context");
        ReleaseNumbersFrame();
        return E_UNEXPECTED;
    }

    // Create an offscreen HDC for drawing into

    m_hdcMemory = CreateCompatibleDC(m_hdcDisplay);
    if (m_hdcMemory == NULL) {
        NOTE("No memory context");
        ReleaseNumbersFrame();
        return E_UNEXPECTED;
    }

    // Make a humungous font for the frame numbers

    m_hFont = CreateFont(GetHeightFromPointsString(TEXT("72")),0,0,0,400,0,0,0,
                         ANSI_CHARSET,OUT_DEFAULT_PRECIS,CLIP_DEFAULT_PRECIS,
                         DEFAULT_QUALITY,DEFAULT_PITCH | FF_SWISS,TEXT("ARIAL"));

    if (m_hFont == NULL) {
        NOTE("No large font");
        ReleaseNumbersFrame();
        return E_UNEXPECTED;
    }

    // Set the offscreen device properties

    SetBkColor(m_hdcMemory,RGB(0,0,0));
    SetTextColor(m_hdcMemory,RGB(255,255,255));
    SelectObject(m_hdcMemory,m_hFont);

    return NOERROR;
}


// Return the height for this point size

INT CVideoStream::GetHeightFromPointsString(LPCTSTR szPoints)
{
    HDC hdc;
    INT height;

    hdc = GetDC(NULL);
    height = MulDiv(-atoi(szPoints), GetDeviceCaps(hdc, LOGPIXELSY), 72);
    ReleaseDC(NULL, hdc);

    return height;
}


// This draws the current frame number onto the image. We must zero fill the
// frame holding buffer to clear any previous image, then we can draw a new
// frame number into the buffer (just using normal GDI calls). Having done
// that we can use the buffer pointer we originally saved when creating the
// buffer (actually a file mapping) and copy the data into the output buffer

HRESULT CVideoStream::DrawCurrentFrame(BYTE *pBuffer)
{
    NOTE("DrawCurrentFrame");
    TCHAR szFrameNumber[64];

    VIDEOINFO *pVideoInfo = (VIDEOINFO *) m_mt.Format();
    BITMAPINFOHEADER *pbmi = HEADER(pVideoInfo);
    ZeroMemory(m_pBase,pVideoInfo->bmiHeader.biSizeImage);

    EXECUTE_ASSERT(SelectObject(m_hdcMemory,m_hBitmap));
    RECT TargetRect = {0,0,pbmi->biWidth,pbmi->biHeight};
    wsprintf(szFrameNumber,TEXT("%d"),m_CurrentFrame);
    UINT Options = DT_CENTER | DT_VCENTER | DT_SINGLELINE;

    DrawText(m_hdcMemory,       // Memory device context
             szFrameNumber,     // Holds string frame number
             (int) -1,          // Let it calculate length
             &TargetRect,       // Display in middle of image
             Options);          // Centred and single line

    CopyMemory(pBuffer,m_pBase,pVideoInfo->bmiHeader.biSizeImage);

    return NOERROR;
}


// Overrides the base class method to fill the next buffer. We detect in here
// if either the section of media to be played has been changed. We check in
// here that we haven't run off the end of the stream before doing anything.
// If we've started a new section of media then m_bNewSegment will have been
// set and we should send a NewSegment call to inform the downstream filter

HRESULT CVideoStream::FillBuffer(IMediaSample *pMediaSample)
{
    NOTE("FillBuffer");
    BYTE *pBuffer;
    LONG lDataLen;

    CAutoLock cAutoLock(&m_SourceLock);
    pMediaSample->GetPointer(&pBuffer);
    lDataLen = pMediaSample->GetSize();

    // Have we reached the end of stream yet

    if (m_CurrentFrame > m_StopFrame) {
        return S_FALSE;
    }

    // Send the NewSegment call downstream

    if (m_bNewSegment == TRUE) {
        REFERENCE_TIME tStart = (REFERENCE_TIME) COARefTime(double(m_CurrentFrame) / double(FRAMERATE));
        REFERENCE_TIME tStop = (REFERENCE_TIME) COARefTime(double(m_StopFrame) / double(FRAMERATE));
        DeliverNewSegment(tStart,tStop,m_dbRate);
        NOTE2("Segment (Start %d Stop %d)",m_CurrentFrame,m_StopFrame);
    }

    m_bNewSegment = FALSE;

    // Use the frame difference to calculate the end time

    REFERENCE_TIME rtStart = m_rtSampleTime;
    LONGLONG CurrentFrame = m_CurrentFrame;
    m_rtSampleTime += ((m_rtIncrement * 1000) / LONGLONG(m_dbRate * 1000));

    // Set the sample properties

    pMediaSample->SetSyncPoint(TRUE);
    pMediaSample->SetDiscontinuity(FALSE);
    pMediaSample->SetPreroll(FALSE);
    pMediaSample->SetTime(&rtStart,&m_rtSampleTime);

    // Only fill in the media times if required

    if (m_bStoreMediaTimes == TRUE) {
        pMediaSample->SetMediaTime(&CurrentFrame,&CurrentFrame);
    }

    DrawCurrentFrame(pBuffer);
    m_CurrentFrame++;
    return NOERROR;
}


// Overriden to return our single output format

HRESULT CVideoStream::GetMediaType(CMediaType *pmt)
{
    return GetMediaType(0,pmt);
}


// Also to make things simple we offer one image format. On most displays the
// RGB24 will not be directly displayable so when being renderer we will get
// a colour space convertor put between us and the renderer to do a convert.
// It would be relatively straightforward to offer more formats like bouncing
// ball does but would only confuse the main point of showing how to do seeks

HRESULT CVideoStream::GetMediaType(int iPosition, CMediaType *pmt)
{
    NOTE("GetMediaType");

    // We only offer one media type

    if (iPosition) {
        NOTE("No more media types");
        return VFW_S_NO_MORE_ITEMS;
    }

    // Allocate an entire VIDEOINFO for simplicity

    pmt->AllocFormatBuffer(sizeof(VIDEOINFO));
    VIDEOINFO *pVideoInfo = (VIDEOINFO *) pmt->Format();
    if (pVideoInfo == NULL) {
	return E_OUTOFMEMORY;
    }

    ZeroMemory(pVideoInfo,sizeof(VIDEOINFO));

    pVideoInfo->bmiHeader.biCompression         = BI_RGB;
    pVideoInfo->bmiHeader.biBitCount            = 24;
    pVideoInfo->bmiHeader.biSize                = sizeof(BITMAPINFOHEADER);
    pVideoInfo->bmiHeader.biWidth               = 320;
    pVideoInfo->bmiHeader.biHeight              = 240;
    pVideoInfo->bmiHeader.biPlanes              = 1;
    pVideoInfo->bmiHeader.biClrUsed		= 0;
    pVideoInfo->bmiHeader.biClrImportant        = 0;

    pVideoInfo->bmiHeader.biSizeImage = DIBSIZE(pVideoInfo->bmiHeader);

    SetRectEmpty(&pVideoInfo->rcSource);
    SetRectEmpty(&pVideoInfo->rcTarget);

    pmt->SetType(&MEDIATYPE_Video);
    pmt->SetSubtype(&MEDIASUBTYPE_RGB24);
    pmt->SetFormatType(&FORMAT_VideoInfo);
    pmt->SetTemporalCompression(FALSE);
    pmt->SetSampleSize(pVideoInfo->bmiHeader.biSizeImage);

    return NOERROR;
}


// Request a single output buffer based on the image size

HRESULT CVideoStream::DecideBufferSize(IMemAllocator *pAlloc,ALLOCATOR_PROPERTIES *pProperties)
{
    NOTE("DecideBufferSize");
    ASSERT(pProperties);
    HRESULT hr = NOERROR;

    VIDEOINFO *pVideoInfo = (VIDEOINFO *) m_mt.Format();
    pProperties->cBuffers = 1;
    pProperties->cbBuffer = pVideoInfo->bmiHeader.biSizeImage;

    ASSERT(pProperties->cbBuffer);

    // Ask the allocator to reserve us some sample memory, Note the function
    // can succeed (that is return NOERROR) but still not have allocated the
    // memory that we requested, so we must check we got whatever we wanted

    ALLOCATOR_PROPERTIES Actual;
    hr = pAlloc->SetProperties(pProperties,&Actual);
    if (FAILED(hr)) {
        return hr;
    }

    // Is this allocator unsuitable

    if (Actual.cbBuffer < pProperties->cbBuffer) {
        return E_FAIL;
    }
    return NOERROR;
}


// Called to initialise the output stream

HRESULT CVideoStream::OnThreadCreate()
{
    NOTE("OnThreadCreate");
    InitNumbersFrame();
    m_rtSampleTime = 0;
    m_bNewSegment = TRUE;
    return NOERROR;
}


// Called when the worker threads is destroyed

HRESULT CVideoStream::OnThreadDestroy()
{
    NOTE("OnThreadDestroy");
    ReleaseNumbersFrame();
    return NOERROR;
}


// We don't do any quality management

STDMETHODIMP CVideoStream::Notify(IBaseFilter *pSender,Quality q)
{
    NOTE("Notify");
    return NOERROR;
}


// We override this to handle any extra seeking mechanisms we might need. This
// is executed in the context of a worker thread. Messages may be sent to the
// worker thread through CallWorker. A call to CallWorker doesn't return until
// the worker thread has called Reply. This can be used to make sure we gain
// control of the thread, for example when flushing we should not complete the
// flush until the worker thread has returned and been stopped. If we get an
// error from GetDeliveryBuffer then we keep going and wait for a stop signal

HRESULT CVideoStream::DoBufferProcessingLoop()
{
    IMediaSample *pSample;
    Command com;
    HRESULT hr;

    do {
	while (CheckRequest(&com) == FALSE) {

            // If we get an error then keep trying until we're stopped

	    hr = GetDeliveryBuffer(&pSample,NULL,NULL,0);
	    if (FAILED(hr)) {
    	        Sleep(1);
		continue;
	    }

    	    // Generate our next frame

	    hr = FillBuffer(pSample);
	    if (hr == S_FALSE) {
                pSample->Release();
		DeliverEndOfStream();
		return S_OK;
       	    }

       	    // Only deliver filled buffers
	
            if (hr == S_OK) {
                Deliver(pSample);
	    }
	    pSample->Release();
        }

   	// For all commands sent to us there must be a Reply call!

	if (com == CMD_RUN || com == CMD_PAUSE) {
   	    Reply(NOERROR);
	} else if (com != CMD_STOP) {
   	    Reply(E_UNEXPECTED);
	}

    } while (com != CMD_STOP);

    return S_FALSE;
}


// Return the total duration for our media

STDMETHODIMP CVideoStream::get_Duration(REFTIME *pLength)
{
    NOTE("Entering get_Duration");
    CheckPointer(pLength,E_POINTER);
    CAutoLock cAutoLock(&m_SourceLock);
    *pLength = double(DURATION) / double(FRAMERATE);

    NOTE1("Duration %s",CDisp(*pLength));
    return NOERROR;
}


// Return the current position in seconds based on the current frame number

STDMETHODIMP CVideoStream::get_CurrentPosition(REFTIME *pTime)
{
    NOTE("Entering get_CurrentPosition");
    CheckPointer(pTime,E_POINTER);
    CAutoLock cAutoLock(&m_SourceLock);

    *pTime = double(m_CurrentFrame) / double(FRAMERATE);
    NOTE1("Position %s",CDisp(*pTime));
    return NOERROR;
}


// Set the new current frame number based on the time

STDMETHODIMP CVideoStream::put_CurrentPosition(REFTIME Time)
{
    CAutoLock StateLock(m_pVideoSource->pStateLock());
    BOOL bRunning = ThreadExists();

    // Stop the worker thread

    if (bRunning == TRUE) {
        DeliverBeginFlush();
        CallWorker(CMD_STOP);
        DeliverEndFlush();
    }

    // Only lock the object when updating the frame number

    NOTE1("put_CurrentPosition %s",CDisp(Time));
    m_CurrentFrame = (LONG) (double(FRAMERATE) * Time);
    m_CurrentFrame = min(m_CurrentFrame,DURATION - 1);
    NOTE1("Setting frame number to %d",m_CurrentFrame);

    // Restart the worker thread again

    m_bNewSegment = TRUE;
    if (bRunning == TRUE) {
        m_rtSampleTime = 0;
        CallWorker(CMD_RUN);
    }
    return NOERROR;
}


// Return the current stop position

STDMETHODIMP CVideoStream::get_StopTime(REFTIME *pTime)
{
    CheckPointer(pTime,E_POINTER);
    CAutoLock cAutoLock(&m_SourceLock);
    *pTime = double(m_StopFrame) / double(FRAMERATE);
    NOTE1("get_StopTime %s",CDisp(*pTime));
    return NOERROR;
}


// Changing the stop time may cause us to flush already sent frames. If we're
// still inbound then the current position should be unaffected. If the stop
// position is before the current position then we effectively set them to be
// the same - setting a current position will have any data we've already sent
// to be flushed - note when setting a current position we must hold no locks

STDMETHODIMP CVideoStream::put_StopTime(REFTIME Time)
{
    NOTE1("put_StopTime %s",CDisp(Time));
    LONG StopFrame = LONG(double(Time) * double(FRAMERATE));
    NOTE1("put_StopTime frame %d",StopFrame);

    // Manually lock the filter

    m_SourceLock.Lock();
    m_bNewSegment = TRUE;
    m_StopFrame = StopFrame;

    // Are we still processing in range

    if (m_CurrentFrame < StopFrame) {
        m_SourceLock.Unlock();
        NOTE("Still in range");
        return NOERROR;
    }

    NOTE("Flushing sent data");
    m_SourceLock.Unlock();
    put_CurrentPosition(Time);
    return NOERROR;
}


// We have no preroll time mechanism

STDMETHODIMP CVideoStream::get_PrerollTime(REFTIME *pTime)
{
    NOTE("Entering get_PrerollTime");
    CheckPointer(pTime,E_POINTER);
    return E_NOTIMPL;
}


// We have no preroll time so ignore this call

STDMETHODIMP CVideoStream::put_PrerollTime(REFTIME Time)
{
    NOTE1("put_PrerollTime %s",CDisp(Time));
    //CAutoLock cAutoLock(&m_SourceLock);
    return E_NOTIMPL;
}


// Return the current (positive only) rate

STDMETHODIMP CVideoStream::get_Rate(double *pdRate)
{
    NOTE("Entering Get_Rate");
    CheckPointer(pdRate,E_POINTER);
    CAutoLock cAutoLock(&m_SourceLock);
    *pdRate = m_dbRate;
    return NOERROR;
}


// Adjust the rate but only allow positive values

STDMETHODIMP CVideoStream::put_Rate(double dRate)
{
    NOTE1("put_Rate %s",CDisp(dRate));
    CAutoLock cAutoLock(&m_SourceLock);

    // Ignore negative and zero rates

    if (dRate <= double(0.0)) {
        return E_INVALIDARG;
    }
    m_dbRate = dRate;
    return NOERROR;
}


// By default we can seek forwards

STDMETHODIMP CVideoStream::CanSeekForward(LONG *pCanSeekForward)
{
    CheckPointer(pCanSeekForward,E_POINTER);
    *pCanSeekForward = OATRUE;
    return S_OK;
}


// By default we can seek backwards

STDMETHODIMP CVideoStream::CanSeekBackward(LONG *pCanSeekBackward)
{
    CheckPointer(pCanSeekBackward,E_POINTER);
    *pCanSeekBackward = OATRUE;
    return S_OK;
}


// We support media time seeking in frames only

STDMETHODIMP CVideoStream::IsFormatSupported(const GUID * pFormat)
{
    NOTE("Entering IsFormatSupported");
    CAutoLock cAutoLock(&m_SourceLock);

    if (*pFormat == TIME_FORMAT_FRAME) {
        return NOERROR;
    }
    return E_INVALIDARG;
}


// Our preferred format is TIME_FORMAT_FRAME for seeking

STDMETHODIMP CVideoStream::QueryPreferredFormat(GUID *pFormat)
{
    NOTE("Entering QueryPreferredFormat");
    CheckPointer(pFormat,E_POINTER);
    //CAutoLock cAutoLock(&m_SourceLock);
    *pFormat = TIME_FORMAT_FRAME;
    return NOERROR;
}


// Unless being reset the format should be TIME_FORMAT_FRAME only

STDMETHODIMP CVideoStream::SetTimeFormat(const GUID * pFormat)
{
    NOTE("Entering SetTimeFormat");
    CAutoLock cAutoLock(&m_SourceLock);
    HRESULT hr = S_OK;

    if (*pFormat == TIME_FORMAT_NONE) {
        m_bStoreMediaTimes = FALSE;
    }

    // We only support frame time seeking

    else if (*pFormat == TIME_FORMAT_FRAME) {
        m_bStoreMediaTimes = TRUE;
    }
    else hr = E_INVALIDARG;

    return hr;
}


// Return the current media time seeking mode

STDMETHODIMP CVideoStream::GetTimeFormat(GUID *pFormat)
{
    NOTE("Entering GetTimeFormat");
    CheckPointer(pFormat,E_POINTER);
    CAutoLock cAutoLock(&m_SourceLock);

    // Are we in media seeking mode

    if (m_bStoreMediaTimes == TRUE) {
        *pFormat = TIME_FORMAT_FRAME;
        return NOERROR;
    }
    *pFormat = TIME_FORMAT_NONE;
    return NOERROR;
}


// Returns the number of frames in our stream

STDMETHODIMP CVideoStream::GetDuration(LONGLONG *pDuration)
{
    NOTE("Entering GetDuration");
    CheckPointer(pDuration,E_POINTER);
    CAutoLock cAutoLock(&m_SourceLock);

    // Are we in media seeking mode

    if (m_bStoreMediaTimes == FALSE) {
        return VFW_E_NO_TIME_FORMAT_SET;
    }
    *pDuration = DURATION;
    return NOERROR;
}


// Return the current frame we are processing

STDMETHODIMP CVideoStream::GetCurrentPosition(LONGLONG *pCurrent)
{
    NOTE("Entering GetCurrentPosition");
    CheckPointer(pCurrent,E_POINTER);
    CAutoLock cAutoLock(&m_SourceLock);

    // Are we in media seeking mode

    if (m_bStoreMediaTimes == FALSE) {
        return VFW_E_NO_TIME_FORMAT_SET;
    }
    *pCurrent = m_CurrentFrame;
    return NOERROR;
}


// Return the last frame we will send

STDMETHODIMP CVideoStream::GetStopPosition(LONGLONG *pStop)
{
    NOTE("Entering GetStopPosition");
    CheckPointer(pStop,E_POINTER);
    CAutoLock cAutoLock(&m_SourceLock);

    // Are we in media seeking mode

    if (m_bStoreMediaTimes == FALSE) {
        return VFW_E_NO_TIME_FORMAT_SET;
    }
    *pStop = m_StopFrame;
    return NOERROR;
}


// Change the start and end frame numbers. This allows a more accurate, direct
// and native seeking mechanism than converting to reference time and calling
// IMediaPosition. Just like when seeking in time we must flush the stream and
// stop the worker thread before changing the segment to be played. To allow
// the filtergraph to resynchronise we must return the current media position
// that the new start frame equals (so other renderers can be positioned etc)

STDMETHODIMP CVideoStream::SetSelection(LONGLONG Current,
                                        LONGLONG Stop,
                                        REFTIME *pTime)
{
    CAutoLock StateLock(m_pVideoSource->pStateLock());
    NOTE("Entering SetSelection");
    CheckPointer(pTime,E_POINTER);

    // Are we in media seeking mode

    if (m_bStoreMediaTimes == FALSE) {
        return VFW_E_NO_TIME_FORMAT_SET;
    }

    BOOL bRunning = ThreadExists();

    // Stop the worker thread

    if (bRunning == TRUE) {
        DeliverBeginFlush();
        CallWorker(CMD_STOP);
        DeliverEndFlush();
    }

    NOTE2("Set current %d stop %d",(LONG) Current,(LONG) Stop);
    *pTime = (double(Current) / double(FRAMERATE));
    NOTE1("Returning current media time as %s",CDisp(*pTime));

    m_CurrentFrame = (LONG) Current;
    m_StopFrame = (LONG) Stop;
    m_bNewSegment = TRUE;

    // Restart the worker thread again

    if (bRunning == TRUE) {
        m_rtSampleTime = 0;
        CallWorker(CMD_RUN);
    }
    return NOERROR;
}


// Set the selection of media we should play

STDMETHODIMP CVideoStream::SetPositions(LONGLONG *pCurrent,
                                        DWORD CurrentFlags,
                                        LONGLONG *pStop,
                                        DWORD StopFlags)
{
    HRESULT hr;

    BOOL bCurrent = FALSE, bStop = FALSE;
    LONGLONG llCurrent = 0, llStop = 0;
    int PosBits;

    PosBits = CurrentFlags & AM_SEEKING_PositioningBitsMask;

    bCurrent = TRUE;
    if (PosBits == AM_SEEKING_RelativePositioning || !PosBits) {
        hr = GetCurrentPosition(&llCurrent);
        if (FAILED(hr)) {
            return hr;
        }
    }
    if (PosBits) llCurrent += *pCurrent;

    PosBits = StopFlags & AM_SEEKING_PositioningBitsMask;

    bStop = TRUE;
    if (PosBits == AM_SEEKING_IncrementalPositioning) {
        if (!bCurrent) {
            hr = GetCurrentPosition( &llCurrent );
            if (FAILED(hr)) {
                return hr;
            }
        }
        llStop = llCurrent + *pStop;
    } else {
        if (PosBits == AM_SEEKING_RelativePositioning || !PosBits) {
            hr = GetStopPosition( &llStop );
            if (FAILED(hr)) {
                return hr;
            }
        }
        if (PosBits) llStop += *pStop;
    }

    REFTIME dCurrent;

    hr = SetSelection(llCurrent,llStop,&dCurrent);
    if (FAILED(hr)) {
        return hr;
    }

    const REFERENCE_TIME rtCurrent = REFERENCE_TIME(1e7 * dCurrent);

    if (bStop && (StopFlags & AM_SEEKING_ReturnTime)) {
        *pStop = llMulDiv( llStop, rtCurrent, llCurrent, 0 );
    }

    if (bCurrent && (CurrentFlags & AM_SEEKING_ReturnTime)) {
        *pCurrent = rtCurrent;
    }
    return hr;
}


// Is this the current time format selected

STDMETHODIMP CVideoStream::IsUsingTimeFormat(const GUID *pFormat)
{
    GUID Format;

    HRESULT hr = GetTimeFormat(&Format);

    if (SUCCEEDED(hr))
        hr = *pFormat == Format ? S_OK : S_FALSE;

    return hr;
}


// Return the capabilities of this source filter

STDMETHODIMP CVideoStream::GetCapabilities( DWORD * pCapabilities )
{
    *pCapabilities = AM_SEEKING_CanSeekForwards
                     | AM_SEEKING_CanSeekBackwards
                     | AM_SEEKING_CanSeekAbsolute
                     | AM_SEEKING_CanGetStopPos
                     | AM_SEEKING_CanGetDuration;
    return NOERROR;
}


// Are the capabilities ones we can support

STDMETHODIMP CVideoStream::CheckCapabilities( DWORD * pCapabilities )
{
    DWORD dwCaps;

    HRESULT hr = GetCapabilities(&dwCaps);
    if (SUCCEEDED(hr))
    {
        dwCaps &= *pCapabilities;
        hr = dwCaps ? (dwCaps == *pCapabilities ? S_OK : S_FALSE) : E_FAIL;
        *pCapabilities = dwCaps;
    }
    else *pCapabilities = 0;

    return hr;
}


// We offer no coversion from frame to media time currently

STDMETHODIMP CVideoStream::ConvertTimeFormat(LONGLONG *pTarget,
                                             const GUID *pTargetFormat,
                                             LONGLONG Source,
                                             const GUID *pSourceFormat)
{
    return E_NOTIMPL;
}


// Return the current and stop positions in media time

STDMETHODIMP CVideoStream::GetPositions(LONGLONG *pCurrent,LONGLONG *pStop)
{
    ASSERT( pCurrent || pStop );

    HRESULT hrCurrent, hrStop, hrResult;

    if (pCurrent) {
        hrCurrent = GetCurrentPosition(pCurrent);
    }
    else hrCurrent = NOERROR;

    if (pStop) {
        hrStop = GetStopPosition(pStop);
    }
    else hrStop = NOERROR;

    if (SUCCEEDED(hrCurrent)) {
        if (SUCCEEDED(hrStop))
            hrResult = S_OK;
        else
            hrResult = hrStop;
    } else {
        if (SUCCEEDED(hrStop))
            hrResult = hrCurrent;
        else
            hrResult = hrCurrent == hrStop ? hrCurrent : E_FAIL;
    }
    return hrResult;
}


// Return the section of video actually available for seeking

STDMETHODIMP CVideoStream::GetAvailable(LONGLONG *pEarliest,LONGLONG * pLatest)
{
    HRESULT hr = NOERROR;

    if (pLatest)
        hr = GetDuration(pLatest);
    if (pEarliest)
        *pEarliest = 0;

    return hr;
}


// Single method to handle EC_REPAINTs for IMediaEventSink

STDMETHODIMP CVideoStream::Notify(long EventCode,
                                  long EventParam1,
                                  long EventParam2)
{
    NOTE("Notify called with EC_REPAINT");

    ASSERT(EventCode == EC_REPAINT);
    ASSERT(EventParam1 == 0);
    ASSERT(EventParam2 == 0);
    return E_NOTIMPL;
}
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\multimedia\dshow\filters\image\vidtest\ddtests.h ===
// Copyright (c) Microsoft Corporation 1994-1996. All Rights Reserved
// Main automatic renderer tests, Anthony Phillips, January 1995

#ifndef _DDTESTS_
#define _DDTESTS_

execDDTest1();          // No DCI/DirectDraw support
execDDTest2();          // DCI primary surface
execDDTest3();          // DirectDraw primary surface
execDDTest4();          // DirectDraw RGB overlay surface
execDDTest5();          // DirectDraw YUV overlay surface
execDDTest6();          // DirectDraw RGB offscreen surface
execDDTest7();          // DirectDraw YUV offscreen surface
execDDTest8();          // DirectDraw RGB flipping surface
execDDTest9();          // DirectDraw YUV flipping surface
execDDTest10();         // Run ALL tests against all modes

void ExecuteDirectDrawTests(UINT uiSurfaceType);
BOOL RunDirectDrawTests();

#endif // __DDTESTS__


=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\multimedia\dshow\filters\image\vidsrc\vidsrc.h ===
//==========================================================================;
//
//  THIS CODE AND INFORMATION IS PROVIDED "AS IS" WITHOUT WARRANTY OF ANY
//  KIND, EITHER EXPRESSED OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE
//  IMPLIED WARRANTIES OF MERCHANTABILITY AND/OR FITNESS FOR A PARTICULAR
//  PURPOSE.
//
//  Copyright (c) 1992 - 1996  Microsoft Corporation.  All Rights Reserved.
//
//--------------------------------------------------------------------------;

#ifndef __VIDSRC__
#define __VIDSRC__

#define DURATION 500                 // Total number of frames in stream
#define FRAMERATE 15                 // Default to 15 frames per second
#define INCREMENT (1000/FRAMERATE)   // Set according to the frame rate

// This is the main filter class. As with most source filters all the work is
// done in the pin classes (our CVideoStream objects). This object is left to
// manage the COM CreateInstance hooking. In our constructor we create a pin
// for the base source class, it can then look after all the filter workings

class CVideoSource : public CSource
{
public:

    CVideoSource(TCHAR *pName,LPUNKNOWN lpunk,HRESULT *phr);
    static CUnknown *CreateInstance(LPUNKNOWN lpunk, HRESULT *phr);
    LPAMOVIESETUP_FILTER GetSetupData();
};


// This is the main worker worker class - we support IMediaPosition for time
// based seeking and IMediaSeeking. We support frame based seeking through
// IMediaSeeking and integrate it with the rate and time stream properties
// available through IMediaPosition. We support alternate and negative frame
// rates since all that involves is adjusting the current frame number (like
// counting downwards instead of up) and the associated stream sample times

class CVideoStream : public IMediaSeeking,
                     public IMediaEventSink,
                     public CSourceStream,
                     public CMediaPosition
{
public:

    CVideoStream(HRESULT *phr,CVideoSource *pVideoSource,LPCWSTR pPinName);
    ~CVideoStream();

    // Provide an IUnknown for our IMediaSeeking and IMediaEventSink

    STDMETHODIMP QueryInterface(REFIID riid, void **ppv) {
        return CSourceStream::GetOwner()->QueryInterface(riid,ppv);
    };
    STDMETHODIMP_(ULONG) AddRef() {
        return CSourceStream::GetOwner()->AddRef();
    };
    STDMETHODIMP_(ULONG) Release() {
        return CSourceStream::GetOwner()->Release();
    };

    // Ask for buffers of the size appropriate to the agreed media type
    HRESULT DecideBufferSize(IMemAllocator *pIMemAlloc,ALLOCATOR_PROPERTIES *pProperties);

    // Expose the IMediaPosition and IMediaSeeking interfaces
    STDMETHODIMP NonDelegatingQueryInterface(REFIID riid,VOID **ppv);

    STDMETHODIMP Notify(IBaseFilter *pSender,Quality q);
    HRESULT GetMediaType(int iPosition, CMediaType *pmt);
    HRESULT GetMediaType(CMediaType *pmt);
    HRESULT OnThreadCreate();
    HRESULT OnThreadDestroy();
    HRESULT FillBuffer(IMediaSample *pms);
    HRESULT DrawCurrentFrame(BYTE *pBuffer);
    HRESULT ReleaseNumbersFrame();
    HRESULT InitNumbersFrame();
    INT GetHeightFromPointsString(LPCTSTR szPoints);
    HRESULT DoBufferProcessingLoop();

    // Single method to handle EC_REPAINTs from IMediaEventSink
    STDMETHODIMP Notify(long EventCode,long EventParam1,long EventParam2);

public:

    STDMETHODIMP SetSelection(LONGLONG Current,
                              LONGLONG Stop,
                              REFTIME *pTime);

    // IMediaSeeking methods

    STDMETHODIMP IsFormatSupported(const GUID *pFormat);
    STDMETHODIMP QueryPreferredFormat(GUID *pFormat);
    STDMETHODIMP SetTimeFormat(const GUID *pFormat);
    STDMETHODIMP GetTimeFormat(GUID *pFormat);
    STDMETHODIMP IsUsingTimeFormat(const GUID *pFormat);
    STDMETHODIMP GetDuration(LONGLONG *pDuration);
    STDMETHODIMP GetStopPosition(LONGLONG *pStop);
    STDMETHODIMP GetCurrentPosition(LONGLONG *pCurrent);
    STDMETHODIMP GetCapabilities(DWORD *pCapabilities);
    STDMETHODIMP CheckCapabilities(DWORD *pCapabilities);

    STDMETHODIMP ConvertTimeFormat(LONGLONG *pTarget,
                                   const GUID *pTargetFormat,
                                   LONGLONG Source,
                                   const GUID *pSourceFormat);

    STDMETHODIMP SetPositions(LONGLONG *pCurrent,
                              DWORD CurrentFlags,
			      LONGLONG *pStop,
                              DWORD StopFlags);

    STDMETHODIMP GetPositions(LONGLONG *pCurrent,LONGLONG *pStop);
    STDMETHODIMP GetAvailable(LONGLONG *pEarliest,LONGLONG *pLatest);
    STDMETHODIMP SetRate(double dRate) { return E_NOTIMPL; }
    STDMETHODIMP GetRate(double * pdRate) { return E_NOTIMPL; }
    STDMETHODIMP GetPreroll(LONGLONG *pPreroll) { return E_NOTIMPL; }

public:

    // IMediaPosition properties

    STDMETHODIMP get_Duration(REFTIME *pLength);
    STDMETHODIMP put_CurrentPosition(REFTIME Time);
    STDMETHODIMP get_CurrentPosition(REFTIME *pTime);
    STDMETHODIMP get_StopTime(REFTIME *pTime);
    STDMETHODIMP put_StopTime(REFTIME Time);
    STDMETHODIMP get_PrerollTime(REFTIME *pTime);
    STDMETHODIMP put_PrerollTime(REFTIME Time);
    STDMETHODIMP get_Rate(double *pdRate);
    STDMETHODIMP put_Rate(double dRate);
    STDMETHODIMP CanSeekForward(LONG *pCanSeekForward);
    STDMETHODIMP CanSeekBackward(LONG *pCanSeekBackward);

private:

    CCritSec m_SourceLock;          // A play lock rather than state lock
    REFERENCE_TIME m_rtSampleTime;  // The next sample will get this time
    REFERENCE_TIME m_rtIncrement;   // Time difference between the samples
    CVideoSource *m_pVideoSource;   // Holds our parent video source filter
    LONG m_CurrentFrame;            // Contains the current frame number
    LONG m_StopFrame;               // Holds the last frame number to send
    BYTE *m_pBase;                  // Pointer to the actual image buffer
    HANDLE m_hMapping;              // Handle to memory mapping object
    HBITMAP m_hBitmap;              // The DIB section bitmap handle
    HDC m_hdcDisplay;               // Device context for the main display
    HDC m_hdcMemory;                // Use this to draw our current frame
    HFONT m_hFont;                  // Font used to draw the frame numbers
    double m_dbRate;                // Currently selected filtergraph rate
    BOOL m_bNewSegment;             // Should we send a new segment call
    BOOL m_bStoreMediaTimes;        // Should we store media times as well
};


// Spin lock class - a critical section object without a critical section.
// which is suitable for lightweight serialisation perhaps protecting a few
// data elements when the caller doesn't want a real critical section. To
// try and match the functionality of CCritSec we can be re-entered on the
// same thread, to do this we have to keep track of the current thread Id

class CSpinLock {

    // Make copy constructor and assignment operator inaccessible

    CSpinLock(const CSpinLock &refSpinLock);
    CSpinLock &operator=(const CSpinLock &refSpinLock);

    LONG m_SpinLock;            // Actual spin lock we offer
    DWORD m_ThreadId;           // Who currently has the lock
    ULONG m_LockCount;          // Number of times locked

public:

    CSpinLock() {
        m_SpinLock = TRUE;
        m_LockCount = 0;
        m_ThreadId = 0;
    };

    ~CSpinLock() {
        ASSERT(m_SpinLock == TRUE);
        ASSERT(m_LockCount == 0);
        ASSERT(m_ThreadId == 0);
    };

    // If we fail to get the lock then see if we already own it
    // when we finally get the lock we store our thread Id so
    // that subsequent lock calls by this thread can re-enter
    // (although all lock and unlocks must still be balanced)

    void Lock() {
        while (InterlockedExchange(&m_SpinLock,FALSE) == FALSE) {
            if (m_ThreadId == GetCurrentThreadId()) {
                ASSERT(m_LockCount);
                ASSERT(m_ThreadId);
                m_LockCount++;
                return;
            }
            Sleep(1);
        }
        ASSERT(m_LockCount == 0);
        ASSERT(m_ThreadId == 0);
        m_LockCount = 1;
        m_ThreadId = GetCurrentThreadId();
    };

    // When we release for the last time release the main lock
    // Like ReleaseCriticalSection this should only be called
    // once a lock has been taken (through the Lock() method)
    // When we reset the thread ID other people may be looking
    // at it but the zeroing should be an atomic operation...

    void Unlock() {
        ASSERT(m_ThreadId == GetCurrentThreadId());
        if (--m_LockCount == 0) {
            m_ThreadId = 0;
            InterlockedExchange(&m_SpinLock,TRUE);
        }
    };
};


// Locks a spin lock and unlocks it automatically unlocks when out of scope

class CAutoSpinLock {

    // Make copy constructor and assignment operator inaccessible

    CAutoSpinLock(const CAutoSpinLock &refAutoSpinLock);
    CAutoSpinLock &operator=(const CAutoSpinLock &refAutoSpinLock);

    CSpinLock *m_pLock;

public:

    CAutoSpinLock(CSpinLock *plock)
    {
        m_pLock = plock;
        m_pLock->Lock();
    };

    ~CAutoSpinLock() {
        m_pLock->Unlock();
    };
};

#endif // __VIDSRC__
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\multimedia\dshow\filters\image\vidsrc\viduids.h ===
//==========================================================================;
//
//  THIS CODE AND INFORMATION IS PROVIDED "AS IS" WITHOUT WARRANTY OF ANY
//  KIND, EITHER EXPRESSED OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE
//  IMPLIED WARRANTIES OF MERCHANTABILITY AND/OR FITNESS FOR A PARTICULAR
//  PURPOSE.
//
//  Copyright (c) 1992 - 1996  Microsoft Corporation.  All Rights Reserved.
//
//--------------------------------------------------------------------------;

DEFINE_GUID(CLSID_VideoSource,
0x17ce12b0, 0x92ee, 0x11cf, 0xbc, 0x0c, 0x00, 0xaa, 0x00, 0xac, 0x74, 0xf6);


=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\multimedia\dshow\filters\image\vidprop\vidprop.h ===
// Copyright (c) 1994 - 1998  Microsoft Corporation.  All Rights Reserved.
// Video renderer property pages, Anthony Phillips, January 1996

#ifndef __VIDPROP__
#define __VIDPROP__

#define IDS_VID1     201        // Format Selection
#define IDS_VID2     202        // Invalid clip percentage
#define IDS_VID3     203        // Non RGB FOURCC codes supported
#define IDS_VID4     204        // No FOURCC codes available
#define IDS_VID5     205        // Total video memory
#define IDS_VID6     206        // Free video memory
#define IDS_VID7     207        // Max number of visible overlays
#define IDS_VID8     208        // Current number of visible overlays
#define IDS_VID9     209        // Number of FOURCC codes
#define IDS_VID10    210        // Source rectangle alignment
#define IDS_VID11    211        // Source rectangle byte size
#define IDS_VID12    212        // Destination rectangle alignment
#define IDS_VID13    213        // Destination rectangle size
#define IDS_VID14    214        // Stride alignment
#define IDS_VID15    215        // Min overlay stretch factor
#define IDS_VID16    216        // Max overlay stretch factor
#define IDS_VID17    217        // Min live video stretch factor
#define IDS_VID18    218        // Max live video stretch factor
#define IDS_VID19    219        // Min hardware codec stretch factor
#define IDS_VID20    220        // Max hardware codec stretch factor
#define IDS_VID21    221        // 1 bit per pixel
#define IDS_VID22    222        // 2 bits per pixel
#define IDS_VID23    223        // 4 bits per pixel
#define IDS_VID24    224        // 8 bits per pixel
#define IDS_VID25    225        // 16 bits per pixel
#define IDS_VID26    226        // 32 bits per pixel
#define IDS_VID27    227        // Switches may not take effect
#define IDS_VID28    228        // (Surface capabilities)
#define IDS_VID29    229        // (Emulation capabilities)
#define IDS_VID30    230        // (Hardware capabilities)
#define IDS_VID31    231        // Disconnected
#define IDS_VID32    232        // DCI primary surface
#define IDS_VID33    233        // Switch Setting Status
#define IDS_VID34    234        // FullScreen Video Renderer

#define IDS_VID50    250        // DirectDraw
#define IDS_VID51    251        // Display Modes
#define IDS_VID52    252        // Quality
#define IDS_VID53    253        // Performance

#define LoadVideoString(x) StringFromResource(m_Resource,x)
extern const TCHAR TypeFace[];  // = TEXT("TERMINAL");
extern const TCHAR FontSize[];  // = TEXT("8");
extern const TCHAR ListBox[];   // = TEXT("listbox");

// Property page built on top of the IDirectDrawVideo interface

#define IDD_VIDEO               100     // Dialog box resource identifier
#define DD_DCIPS                101     // Enable DCI primary surface
#define DD_PS                   102     // DirectDraw primary surface
#define DD_RGBOVR               103     // Enable RGB overlays
#define DD_YUVOVR               104     // NON RGB (eg YUV) overlays
#define DD_RGBOFF               105     // RGB offscreen surfaces
#define DD_YUVOFF               106     // NON RGB (eg YUV) offscreen
#define DD_RGBFLP               107     // RGB flipping surfaces
#define DD_YUVFLP               108     // Likewise YUV flipping surfaces
#define FIRST_DD_BUTTON         101     // First DirectDraw check button
#define LAST_DD_BUTTON          108     // Last DirectDraw check button
#define DD_HARDWARE             109     // DirectDraw hardware description
#define DD_SOFTWARE             110     // Emulated software capabilities
#define DD_SURFACE              111     // Current surface information
#define DD_LIST                 112     // Listbox containing details

class CVideoProperties : public CBasePropertyPage
{
    IDirectDrawVideo *m_pDirectDrawVideo; // Interface held on renderer
    TCHAR m_Resource[STR_MAX_LENGTH];     // Loads international strings
    HFONT m_hFont;                        // Special smaller listbox font
    HWND m_hwndList;                      // Custom list box control
    DWORD m_Switches;                     // DirectDraw switches enabled

    // Display the DirectDraw capabilities

    void DisplayBitDepths(DWORD dwCaps);
    void DisplayCapabilities(DDCAPS *pCaps);
    void DisplaySurfaceCapabilities(DDSCAPS ddsCaps);
    void DisplayFourCCCodes();
    void UpdateListBox(DWORD Id);
    void SetDrawSwitches();
    void GetDrawSwitches();
    INT GetHeightFromPointsString(LPCTSTR szPoints);

public:

    CVideoProperties(LPUNKNOWN lpUnk,HRESULT *phr);
    static CUnknown *CreateInstance(LPUNKNOWN pUnk, HRESULT *phr);

    INT_PTR OnReceiveMessage(HWND hwnd,UINT uMsg,WPARAM wParam,LPARAM lParam);
    HRESULT OnConnect(IUnknown *pUnknown);
    HRESULT OnDisconnect();
    HRESULT OnActivate();
    HRESULT OnDeactivate();
    HRESULT OnApplyChanges();
};


// Property page built from a renderer IQualProp interface

#define IDD_QUALITY             150     // Dialog resource
#define IDD_Q1                  151     // Frames played
#define IDD_Q2                  152     // Frames dropped
#define IDD_Q4                  154     // Frame rate
#define IDD_Q5                  155     // Frame jitter
#define IDD_Q6                  156     // Sync offset
#define IDD_Q7                  157     // Sync deviation
#define FIRST_Q_BUTTON          171     // First button
#define LAST_Q_BUTTON           177     // Last button
#define IDD_QDRAWN              171     // Frames played
#define IDD_QDROPPED            172     // Frames dropped
#define IDD_QAVGFRM             174     // Average frame rate achieved
#define IDD_QJITTER             175     // Average frame jitter
#define IDD_QSYNCAVG            176     // Average sync offset
#define IDD_QSYNCDEV            177     // Std dev sync offset

class CQualityProperties : public CBasePropertyPage
{
    IQualProp *m_pQualProp;         // Interface held on the renderer
    int m_iDropped;                 // Number of frames dropped
    int m_iDrawn;                   // Count of images drawn
    int m_iSyncAvg;                 // Average sync value
    int m_iSyncDev;                 // And standard deviation
    int m_iFrameRate;               // Total frame rate average
    int m_iFrameJitter;             // Measure of frame jitter

    static BOOL CALLBACK QualityDialogProc(HWND hwnd,
                                           UINT uMsg,
                                           WPARAM wParam,
                                           LPARAM lParam);
    void SetEditFieldData();
    void DisplayStatistics(void);

public:

    CQualityProperties(LPUNKNOWN lpUnk, HRESULT *phr);
    static CUnknown *CreateInstance(LPUNKNOWN pUnk, HRESULT *phr);

    HRESULT OnConnect(IUnknown *pUnknown);
    HRESULT OnDisconnect();
    HRESULT OnActivate();
};


// Property page to allow customisation of performance properties

#define IDD_PERFORMANCE         200     // Property dialog resource
#define IDD_SCANLINE            201     // Honour the scan line
#define IDD_OVERLAY             202     // Use overlay limitations
#define IDD_FULLSCREEN          203     // Use when made fullscreen

class CPerformanceProperties : public CBasePropertyPage
{
    IDirectDrawVideo *m_pDirectDrawVideo; 	// Interface held on renderer
    LONG m_WillUseFullScreen;                   // Use when made fullscreen
    LONG m_CanUseScanLine;               	// Can honour the scan line
    LONG m_CanUseOverlayStretch;                // Use overlay stretching

public:

    CPerformanceProperties(LPUNKNOWN lpUnk,HRESULT *phr);
    static CUnknown *CreateInstance(LPUNKNOWN pUnk, HRESULT *phr);

    INT_PTR OnReceiveMessage(HWND hcwnd,UINT uMsg,WPARAM wParam,LPARAM lParam);
    HRESULT OnConnect(IUnknown *pUnknown);
    HRESULT OnDisconnect();
    HRESULT OnActivate();
    HRESULT OnApplyChanges();
};


// Property page allowing selection of preferred display modes

#define IDD_MODEX               500     // Dialog box resource identifier
#define MODEX_CHOSEN_TEXT       501     // Static description for chosen
#define MODEX_CHOSEN_EDIT       502     // Non editable display string
#define MODEX_CLIP_TEXT         503     // Static description for clip
#define MODEX_CLIP_EDIT         504     // Non editable display string
#define FIRST_MODEX_BUTTON      501     // First actual property button
#define LAST_MODEX_BUTTON       540     // And last available display mode
#define FIRST_MODEX_MODE        510     // First available mode check box
#define FIRST_MODEX_TEXT        511     // First static text description
#define MODEX_320x200x16        510     // Not sure if this is available
#define MODEX_320x200x8         512     // Palettised bottom most mode
#define MODEX_320x240x16        514     // Modex and also as a normal mode
#define MODEX_320x240x8         516     // Can get this both as a true
#define MODEX_640x400x16        518     // 640x400 modes with flipping
#define MODEX_640x400x8         520     // Can still get the 640x480 and
#define MODEX_640x480x16        522     // a lot more hardware bandwidth
#define MODEX_640x480x8         524     // surfaces although they use up
#define MODEX_800x600x16        526     // normal ddraw mode
#define MODEX_800x600x8         528     // normal ddraw mode
#define MODEX_1024x768x16       530     // normal ddraw mode
#define MODEX_1024x768x8        532     // normal ddraw mode
#define MODEX_1152x864x16       534     // normal ddraw mode
#define MODEX_1152x864x8        536     // normal ddraw mode
#define MODEX_1280x1024x16      538     // normal ddraw mode
#define MODEX_1280x1024x8       540     // normal ddraw mode


#define MAXMODES                 16     // Number of modes supported
#define CLIPFACTOR               25     // Initial default clip factor
#define MONITOR                   0     // Default to the primary display

class CModexProperties : public CBasePropertyPage
{
    IFullScreenVideo *m_pModexVideo;      // Renderer handling interface
    TCHAR m_Resource[STR_MAX_LENGTH];     // Loads international strings
    LONG m_CurrentMode;                   // Current display mode chosen
    LONG m_ClipFactor;                    // Allowed clip percentage
    BOOL m_bAvailableModes[MAXMODES];     // List of mode availability
    BOOL m_bEnabledModes[MAXMODES];       // And whether they're enabled
    BOOL m_bInActivation;                 // Are we currently activating

public:

    CModexProperties(LPUNKNOWN lpUnk,HRESULT *phr);
    static CUnknown *CreateInstance(LPUNKNOWN pUnk, HRESULT *phr);
    INT_PTR OnReceiveMessage(HWND hwnd,UINT uMsg,WPARAM wParam,LPARAM lParam);

    HRESULT OnConnect(IUnknown *pUnknown);
    HRESULT OnDisconnect();
    HRESULT OnActivate();
    HRESULT OnApplyChanges();
    HRESULT UpdateVariables();
    HRESULT LoadProperties();
    HRESULT DisplayProperties();
    HRESULT SaveProperties();
};

#endif // __VIDPROP__
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\multimedia\dshow\filters\image\vidtest\imagedbg.h ===
// Copyright (c) Microsoft Corporation 1994-1996. All Rights Reserved
// Video renderer debugging facilities, Anthony Phillips, August 1995

#ifndef __IMAGEDBG__
#define __IMAGEDBG__

// The base classes already implement an ASSERT and EXECUTE_ASSERT macros but
// if we are being built for retail the test suite still wants access to these
// macros. We therefore redefine them so that they are always available to us
// The only function we are really interested in is one to display messages

#ifdef ASSERT
#undef ASSERT
#undef EXECUTE_ASSERT
#endif

#define ASSERT(_x_) if (!(_x_)) \
    ImageAssert(TEXT(#_x_),TEXT(__FILE__),__LINE__)

#define EXECUTE_ASSERT(_x_) ASSERT(_x_)
void ImageAssert(const TCHAR *pCondition,const TCHAR *pFileName,INT iLine);

#endif // __IMAGEDBG__


=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\multimedia\dshow\filters\image\vidtest\ddtests.cpp ===
// Copyright (c) Microsoft Corporation 1994-1996. All Rights Reserved
// Digital video renderer unit test, Anthony Phillips, January 1995

#include <streams.h>        // Includes all the IDL and base classes
#include <windows.h>        // Standard Windows SDK header file
#include <windowsx.h>       // Win32 Windows extensions and macros
#include <vidprop.h>        // Shared video properties library
#include <render.h>         // Normal video renderer header file
#include <modex.h>          // Specialised Modex video renderer
#include <convert.h>        // Defines colour space conversions
#include <colour.h>         // Rest of the colour space convertor
#include <imagetst.h>       // All our unit test header files
#include <stdio.h>          // Standard C runtime header file
#include <limits.h>         // Defines standard data type limits
#include <tchar.h>          // Unicode and ANSII portable types
#include <mmsystem.h>       // Multimedia used for timeGetTime
#include <stdlib.h>         // Standard C runtime function library
#include <tstshell.h>       // Definitions of constants eg TST_FAIL

TCHAR LogString[128];           // Used to format logging data


//==========================================================================
//
// void ExecuteDirectDrawTests(UINT uiSurfaceType)
//
// These execute the DirectDraw test cases, the tests for the test shell to
// pick up are defined in string tables in the resource file. Each test case
// has a name, a group and an identifier (amongst other things). When the
// test shell comes to run one of our tests it calls execTest with the ID
// of the test from the resource file, we have a large switch statement that
// routes the thread from there to the code that it should be executing. As
// all the tests use the same variables to hold the interfaces on the objects
// we create there is a chance that once one test goes awry that all further
// ones will be affected. To remove this dependancy would involve a lot more
// complexity for relatively gain. Picking up the first one to fail and then
// solving that problem is probably the most worthwhile part of this anyway.
//
//==========================================================================

void ExecuteDirectDrawTests(UINT uiSurfaceType)
{
    SetSurfaceMenuCheck(uiSurfaceType);

    // Run all the standard sample tests

    EXECUTE_ASSERT(execTest(ID_TEST1,ID_TEST1,ID_TEST1,GRP_SAMPLES) == TST_PASS);
    EXECUTE_ASSERT(execTest(ID_TEST2,ID_TEST2,ID_TEST2,GRP_SAMPLES) == TST_PASS);
    EXECUTE_ASSERT(execTest(ID_TEST3,ID_TEST3,ID_TEST3,GRP_SAMPLES) == TST_PASS);
    EXECUTE_ASSERT(execTest(ID_TEST4,ID_TEST4,ID_TEST4,GRP_SAMPLES) == TST_PASS);
    EXECUTE_ASSERT(execTest(ID_TEST5,ID_TEST5,ID_TEST5,GRP_SAMPLES) == TST_PASS);
    EXECUTE_ASSERT(execTest(ID_TEST6,ID_TEST6,ID_TEST6,GRP_SAMPLES) == TST_PASS);
    EXECUTE_ASSERT(execTest(ID_TEST7,ID_TEST7,ID_TEST7,GRP_SAMPLES) == TST_PASS);
    EXECUTE_ASSERT(execTest(ID_TEST8,ID_TEST8,ID_TEST8,GRP_SAMPLES) == TST_PASS);
    EXECUTE_ASSERT(execTest(ID_TEST9,ID_TEST9,ID_TEST9,GRP_SAMPLES) == TST_PASS);
    EXECUTE_ASSERT(execTest(ID_TEST10,ID_TEST10,ID_TEST10,GRP_SAMPLES) == TST_PASS);

    // Run all the overlay tests

    EXECUTE_ASSERT(execTest(ID_TEST11,ID_TEST11,ID_TEST11,GRP_OVERLAY) == TST_PASS);
    EXECUTE_ASSERT(execTest(ID_TEST12,ID_TEST12,ID_TEST12,GRP_OVERLAY) == TST_PASS);
    EXECUTE_ASSERT(execTest(ID_TEST13,ID_TEST13,ID_TEST13,GRP_OVERLAY) == TST_PASS);
    EXECUTE_ASSERT(execTest(ID_TEST14,ID_TEST14,ID_TEST14,GRP_OVERLAY) == TST_PASS);
    EXECUTE_ASSERT(execTest(ID_TEST15,ID_TEST15,ID_TEST15,GRP_OVERLAY) == TST_PASS);
    EXECUTE_ASSERT(execTest(ID_TEST16,ID_TEST16,ID_TEST16,GRP_OVERLAY) == TST_PASS);
    EXECUTE_ASSERT(execTest(ID_TEST17,ID_TEST17,ID_TEST17,GRP_OVERLAY) == TST_PASS);
    EXECUTE_ASSERT(execTest(ID_TEST18,ID_TEST18,ID_TEST18,GRP_OVERLAY) == TST_PASS);
    EXECUTE_ASSERT(execTest(ID_TEST19,ID_TEST19,ID_TEST19,GRP_OVERLAY) == TST_PASS);
    EXECUTE_ASSERT(execTest(ID_TEST20,ID_TEST20,ID_TEST20,GRP_OVERLAY) == TST_PASS);

    // Now run all the control interface tests

    EXECUTE_ASSERT(execTest(ID_TEST21,ID_TEST21,ID_TEST21,GRP_WINDOW) == TST_PASS);
    EXECUTE_ASSERT(execTest(ID_TEST22,ID_TEST22,ID_TEST22,GRP_WINDOW) == TST_PASS);
    EXECUTE_ASSERT(execTest(ID_TEST23,ID_TEST23,ID_TEST23,GRP_WINDOW) == TST_PASS);
    EXECUTE_ASSERT(execTest(ID_TEST24,ID_TEST24,ID_TEST24,GRP_WINDOW) == TST_PASS);
    EXECUTE_ASSERT(execTest(ID_TEST25,ID_TEST25,ID_TEST25,GRP_WINDOW) == TST_PASS);
    EXECUTE_ASSERT(execTest(ID_TEST26,ID_TEST26,ID_TEST26,GRP_WINDOW) == TST_PASS);
    EXECUTE_ASSERT(execTest(ID_TEST27,ID_TEST27,ID_TEST27,GRP_WINDOW) == TST_PASS);
    EXECUTE_ASSERT(execTest(ID_TEST28,ID_TEST28,ID_TEST28,GRP_WINDOW) == TST_PASS);
    EXECUTE_ASSERT(execTest(ID_TEST29,ID_TEST29,ID_TEST29,GRP_WINDOW) == TST_PASS);
    EXECUTE_ASSERT(execTest(ID_TEST30,ID_TEST30,ID_TEST30,GRP_WINDOW) == TST_PASS);
    EXECUTE_ASSERT(execTest(ID_TEST31,ID_TEST31,ID_TEST31,GRP_WINDOW) == TST_PASS);
    EXECUTE_ASSERT(execTest(ID_TEST32,ID_TEST32,ID_TEST32,GRP_WINDOW) == TST_PASS);
    EXECUTE_ASSERT(execTest(ID_TEST33,ID_TEST33,ID_TEST33,GRP_WINDOW) == TST_PASS);
    EXECUTE_ASSERT(execTest(ID_TEST34,ID_TEST34,ID_TEST34,GRP_WINDOW) == TST_PASS);
    EXECUTE_ASSERT(execTest(ID_TEST35,ID_TEST35,ID_TEST35,GRP_WINDOW) == TST_PASS);
}


//==========================================================================
//
//  int execDDTest1
//
//  Description:
//      This runs all the tests against without any DCI/DirectDraw support
//
//  Return (int): TST_PASS indicating success
//
//==========================================================================

int execDDTest1()
{
    HRESULT hr = NOERROR;

    Log(TERSE,TEXT("Entering DirectDraw test #1"));
    LogFlush();
    ExecuteDirectDrawTests(IDM_NONE);
    Log(TERSE,TEXT("Exiting DirectDraw test #1"));
    LogFlush();
    return TST_PASS;
}


//==========================================================================
//
//  int execDDTest2
//
//  Description:
//      Runs all the tests against any DCI primary surface available
//
//  Return (int): TST_PASS indicating success
//
//==========================================================================

int execDDTest2()
{
    HRESULT hr = NOERROR;

    Log(TERSE,TEXT("Entering DirectDraw test #2"));
    LogFlush();
    ExecuteDirectDrawTests(IDM_DCIPS);
    Log(TERSE,TEXT("Exiting DirectDraw test #2"));
    LogFlush();
    return TST_PASS;
}


//==========================================================================
//
//  int execDDTest3
//
//  Description:
//      Runs all the tests against any DirectDraw primary surface available
//
//  Return (int): TST_PASS indicating success
//
//==========================================================================

int execDDTest3()
{
    HRESULT hr = NOERROR;

    Log(TERSE,TEXT("Entering DirectDraw test #3"));
    LogFlush();
    ExecuteDirectDrawTests(IDM_PS);
    Log(TERSE,TEXT("Exiting DirectDraw test #3"));
    LogFlush();
    return TST_PASS;
}


//==========================================================================
//
//  int execDDTest4
//
//  Description:
//      Runs all the tests against DirectDraw RGB overlay surfaces
//
//  Return (int): TST_PASS indicating success
//
//==========================================================================

int execDDTest4()
{
    HRESULT hr = NOERROR;

    Log(TERSE,TEXT("Entering DirectDraw test #4"));
    LogFlush();
    ExecuteDirectDrawTests(IDM_RGBOVR);
    Log(TERSE,TEXT("Exiting DirectDraw test #4"));
    LogFlush();
    return TST_PASS;
}


//==========================================================================
//
//  int execDDTest5
//
//  Description:
//      Runs all the tests against DirectDraw YUV overlay surfaces
//
//  Return (int): TST_PASS indicating success
//
//==========================================================================

int execDDTest5()
{
    HRESULT hr = NOERROR;

    Log(TERSE,TEXT("Entering DirectDraw test #5"));
    LogFlush();
    ExecuteDirectDrawTests(IDM_YUVOVR);
    Log(TERSE,TEXT("Exiting DirectDraw test #5"));
    LogFlush();
    return TST_PASS;
}


//==========================================================================
//
//  int execDDTest6
//
//  Description:
//      Runs all the tests against DirectDraw RGB offscreen surfaces
//
//  Return (int): TST_PASS indicating success
//
//==========================================================================

int execDDTest6()
{
    HRESULT hr = NOERROR;

    Log(TERSE,TEXT("Entering DirectDraw test #6"));
    LogFlush();
    ExecuteDirectDrawTests(IDM_RGBOFF);
    Log(TERSE,TEXT("Exiting DirectDraw test #6"));
    LogFlush();
    return TST_PASS;
}


//==========================================================================
//
//  int execDDTest7
//
//  Description:
//      Runs all the tests against DirectDraw YUV offscreen surfaces
//
//  Return (int): TST_PASS indicating success
//
//==========================================================================

int execDDTest7()
{
    HRESULT hr = NOERROR;

    Log(TERSE,TEXT("Entering DirectDraw test #7"));
    LogFlush();
    ExecuteDirectDrawTests(IDM_YUVOFF);
    Log(TERSE,TEXT("Exiting DirectDraw test #7"));
    LogFlush();
    return TST_PASS;
}


//==========================================================================
//
//  int execDDTest8
//
//  Description:
//      Runs all the tests against DirectDraw RGB flipping surfaces
//
//  Return (int): TST_PASS indicating success
//
//==========================================================================

int execDDTest8()
{
    HRESULT hr = NOERROR;

    Log(TERSE,TEXT("Entering DirectDraw test #8"));
    LogFlush();
    ExecuteDirectDrawTests(IDM_RGBFLP);
    Log(TERSE,TEXT("Exiting DirectDraw test #8"));
    LogFlush();
    return TST_PASS;
}


//==========================================================================
//
//  int execDDTest9
//
//  Description:
//      Runs all the tests against DirectDraw YUV flipping surfaces
//
//  Return (int): TST_PASS indicating success
//
//==========================================================================

int execDDTest9()
{
    HRESULT hr = NOERROR;

    Log(TERSE,TEXT("Entering DirectDraw test #9"));
    LogFlush();
    ExecuteDirectDrawTests(IDM_YUVFLP);
    Log(TERSE,TEXT("Exiting DirectDraw test #9"));
    LogFlush();
    return TST_PASS;
}


//==========================================================================
//
//  int execDDTest10
//
//  Description:
//      Runs ALL the tests against ALL available monitor settings. We change
//      mode to each and every one allowed (including high resolution modes)
//      and run the entire DirectDraw test suite on it. We then restore the
//      display mode back to its original setting and try the next one on.
//
//  Return (int): TST_PASS indicating success
//
//==========================================================================

int execDDTest10()
{
    HRESULT hr = NOERROR;

    Log(TERSE,TEXT("Entering DirectDraw test #10"));
    LogFlush();

    // Has DirectDraw been loaded

    if (pDirectDraw == NULL) {
        Log(TERSE,TEXT("No DirectDraw available"));
        return TST_PASS;
    }

    // Try each DirectDraw display mode in turn

    for (DWORD Mode = 0;Mode <= dwDisplayModes;Mode++) {
        Log(TERSE,TEXT("\r\nSwapping DirectDraw Modes\r\n"));
        SetDisplayMode(IDM_MODE + Mode);
        RunDirectDrawTests();
        SetDisplayMode(IDM_MODE);
    }

    Log(TERSE,TEXT("Exiting DirectDraw test #10"));
    LogFlush();
    return TST_PASS;
}


//==========================================================================
//
//  BOOL RunDirectDrawTests
//
//  Description:
//      We are called by ExecDDTest10, the caller will set the display mode
//      to each and every one available in turn. It will then call us to
//      run the entire DirectDraw test suite on that setting. Each display
//      mode may have a different bit depth, width, height and stride. To
//      allow for these changes we start by searching for an image we can
//      use to connect up and send samples with. We try the highest quality
//      first and ending up with palettised last (which most displays will
//      accept by default). This test should be run last as it takes ages.
//
//==========================================================================

BOOL RunDirectDrawTests()
{
    UINT uiStoreImage = uiCurrentImageItem;
    HRESULT hr = E_UNEXPECTED;

    // Find an image we can use to run tests with

    EXECUTE_ASSERT(SUCCEEDED(CreateStream()));
    Log(TERSE,TEXT("(Ignore connection errors)"));
    for (UINT Image = IDM_WIND24;Image >= IDM_WIND8;Image--) {
        LoadDIB(Image,&VideoInfo,bImageData);
        SetImageMenuCheck(Image);
        hr = ConnectStream();
        if (SUCCEEDED(hr)) {
            EXECUTE_ASSERT(SUCCEEDED(DisconnectStream()));
            const TCHAR *pImageName = pResourceNames[Image - IDM_WIND8];
            wsprintf(LogString,TEXT("Using image %s"),pImageName);
            Log(TERSE,LogString);
            break;
        }
    }

    // Clean up any resources we used to find the image

    EXECUTE_ASSERT(SUCCEEDED(ReleaseStream()));
    if (FAILED(hr)) {
        Log(TERSE,TEXT("Could not find appropriate image to use"));
    }

    // Run all the tests if we have an image to use

    if (SUCCEEDED(hr)) {
          EXECUTE_ASSERT(execTest(ID_TEST36,ID_TEST36,ID_TEST36,GRP_DDRAW) == TST_PASS);
          EXECUTE_ASSERT(execTest(ID_TEST37,ID_TEST37,ID_TEST37,GRP_DDRAW) == TST_PASS);
          EXECUTE_ASSERT(execTest(ID_TEST38,ID_TEST38,ID_TEST38,GRP_DDRAW) == TST_PASS);
          EXECUTE_ASSERT(execTest(ID_TEST39,ID_TEST39,ID_TEST39,GRP_DDRAW) == TST_PASS);
          EXECUTE_ASSERT(execTest(ID_TEST40,ID_TEST40,ID_TEST40,GRP_DDRAW) == TST_PASS);
          EXECUTE_ASSERT(execTest(ID_TEST41,ID_TEST41,ID_TEST41,GRP_DDRAW) == TST_PASS);
          EXECUTE_ASSERT(execTest(ID_TEST42,ID_TEST42,ID_TEST42,GRP_DDRAW) == TST_PASS);
          EXECUTE_ASSERT(execTest(ID_TEST43,ID_TEST43,ID_TEST43,GRP_DDRAW) == TST_PASS);
          EXECUTE_ASSERT(execTest(ID_TEST44,ID_TEST44,ID_TEST44,GRP_DDRAW) == TST_PASS);
    }

    // Reset the image so leaving the global state untouched

    LoadDIB(uiStoreImage,&VideoInfo,bImageData);
    SetImageMenuCheck(uiStoreImage);
    return TRUE;
}


=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\multimedia\dshow\filters\image\vidtest\imagedat.h ===
// Copyright (c) Microsoft Corporation 1994-1996. All Rights Reserved
// Header file for the renderer test data, Anthony Phillips, July 1995

#ifndef __IMAGEDAT__
#define __IMAGEDAT__

extern HWND ghwndTstShell;               // Main window handle for test shell
extern HINSTANCE hinst;                  // Running instance of the test shell
extern HMENU hConnectionMenu;            // Connection type menu popup handle
extern HMENU hSurfaceMenu;               // Surface type menu popup handle
extern HMENU hImageMenu;                 // Handle to the Image popup menu
extern HMENU hModesMenu;                 // Handle to the display modes menu
extern HMENU hDirectDrawMenu;            // Controls loading of DirectDraw
extern LPTSTR szAppName;                 // The application title caption

extern VIDEOINFO VideoInfo;              // Header from loaded DIB file
extern BYTE bImageData[];                // Image data buffer for samples
extern DWORD dwIncrement;                // Period between subsequent frames
extern TCHAR szInfo[];                   // General string formatting field
extern DWORD dwDisplayModes;             // Number of display modes supplied
extern DWORD dwDDCount;                  // Samples with surfaces available
extern const TCHAR *pResourceNames[];    // Matches names to menu identifiers
extern UINT uiCurrentDisplayMode;        // Current display mode setting
extern UINT uiCurrentImageItem;          // Current image format we propose
extern UINT uiCurrentSurfaceItem;        // Type of DirectDraw surface allowed
extern UINT uiCurrentConnectionItem;     // Current connection menu selection
extern PALETTEENTRY TestPalette[10];     // Test palette entries for IOverlay

extern CImageSource *pImageSource;       // Pointer to image source object
extern IDirectDrawVideo *pDirectVideo;   // Access to DirectDraw video options
extern LPDIRECTDRAW pDirectDraw;         // DirectDraw service provider
extern HINSTANCE hDirectDraw;            // Handle for DirectDraw library
extern IPin *pOutputPin;                 // Pin provided by the source object
extern IPin *pInputPin;                  // Pin to connect with the renderer
extern IBaseFilter *pRenderFilter;       // The renderer IBaseFilter interface
extern IBaseFilter *pSourceFilter;       // The source IBaseFilter interface
extern IMediaFilter *pRenderMedia;       // The renderer IMediaFilter interface
extern IMediaFilter *pSourceMedia;       // The source IMediaFilter interface
extern IBasicVideo *pBasicVideo;         // Video renderer control interface
extern IVideoWindow *pVideoWindow;       // Another control interface
extern IOverlay *pOverlay;               // Direct video overlay interface
extern COverlayNotify *pOverlayNotify;   // Receives asynchronous updates
extern IOverlayNotify *pNotify;          // Interface we pass in to IOverlay
extern IReferenceClock *pClock;          // Reference clock implementation
extern CRefTime gtBase;                  // Time when we started running
extern CRefTime gtPausedAt;              // This was the time we paused
extern CMediaType gmtOut;                // Current output connection type

extern BOOL bConnected;                  // Have we connected the filters
extern BOOL bCreated;                    // have the objects been created
extern BOOL bRunning;                    // Are we in a running state yet

#endif // __IMAGEDAT__
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\multimedia\dshow\filters\image\vidtest\imagedib.h ===
// Copyright (c) Microsoft Corporation 1994-1996. All Rights Reserved
// Implements the DIB file helper functions, Anthony Phillips, July 1995

#ifndef __IMAGEDIB__
#define __IMAGEDIB__

HRESULT LoadDIB(UINT uiMenuItem,VIDEOINFO *pVideoInfo,BYTE *pImageData);
HRESULT DumpPalette(RGBQUAD *pRGBQuad, int iColours);

#endif // __IMAGEDIB__


=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\multimedia\dshow\filters\image\vidtest\imagedib.cpp ===
// Copyright (c) Microsoft Corporation 1994-1996. All Rights Reserved
// Implements DIB file helper functions, Anthony Phillips, July 1995

#include <streams.h>        // Includes all the IDL and base classes
#include <windows.h>        // Standard Windows SDK header file
#include <windowsx.h>       // Win32 Windows extensions and macros
#include <vidprop.h>        // Shared video properties library
#include <render.h>         // Normal video renderer header file
#include <modex.h>          // Specialised Modex video renderer
#include <convert.h>        // Defines colour space conversions
#include <colour.h>         // Rest of the colour space convertor
#include <imagetst.h>       // All our unit test header files
#include <stdio.h>          // Standard C runtime header file
#include <limits.h>         // Defines standard data type limits
#include <tchar.h>          // Unicode and ANSII portable types
#include <mmsystem.h>       // Multimedia used for timeGetTime
#include <stdlib.h>         // Standard C runtime function library
#include <tstshell.h>       // Definitions of constants eg TST_FAIL

// The DIBs are bound into the executable as resources so that we don't have
// to copy them around with the executable. These names should match those
// kept in the main resource file otherwise we won't be able to find them

const TCHAR *pResourceNames[] = { TEXT("WIND8"),
                                  TEXT("WIND555"),
                                  TEXT("WIND565"),
                                  TEXT("WIND24") };

// This function loads a DIB image that we bind into our executable instead of
// leaving it as a separate file. It initialises the VIDEOINFO structure that
// is passed as a parameter and then reads the image data in as well (which is
// little more that a memory copy once we have loaded and locked the resource)
// The maximum size the image is allowed to be MAXIMAGESIZE in bytes since the
// image data buffer is a static array (We are passed the menu identifier)

HRESULT LoadDIB(UINT uiMenuItem,VIDEOINFO *pVideoInfo,BYTE *pImageData)
{
    ASSERT(pVideoInfo);
    ASSERT(pImageData);
    ZeroMemory(pVideoInfo,sizeof(VIDEOINFO));

    const TCHAR *pResourceName =
        (uiMenuItem == IDM_WIND8 ? pResourceNames[0] :
            uiMenuItem == IDM_WIND555 ? pResourceNames[1] :
                uiMenuItem == IDM_WIND565 ? pResourceNames[2] :
                    uiMenuItem == IDM_WIND24 ? pResourceNames[3] : NULL);

    ASSERT(pResourceName);

    // We can only change the image when we are disconnected

    if (bConnected == TRUE) {

        MessageBox(ghwndTstShell,
                   TEXT("Must be disconnected to change image"),
                   TEXT("Load DIB"),
                   MB_ICONEXCLAMATION | MB_OK);

        return E_FAIL;
    }

    // Find and load the resource from the executable

    HRSRC hFindResource = FindResource(hinst,pResourceName,TEXT("DIB"));
    HGLOBAL hResource = LoadResource(hinst,hFindResource);
    if (hResource == NULL) {
        return E_FAIL;
    }

    // Retrieve an LPVOID pointer to the data

    BYTE *pResource = (BYTE *) LockResource(hResource);
    if (pResource == NULL) {
        FreeResource(hResource);
        return E_FAIL;
    }

    // Read the BITMAPINFOHEADER and a whole palette regardless of whether or
    // not it is there, this will likely read some of the image data as well
    // but we don't really care (true colour DIBs do not have a palette). We
    // also set the approximate frame and bit rates to known values so that
    // when we connect the filters up we can then retrieve these values from
    // our IBasicVideo control interface and check they haven't been changed

    CopyMemory((PVOID)&pVideoInfo->bmiHeader,
               (PVOID)(pResource + sizeof(BITMAPFILEHEADER)),
               sizeof(BITMAPINFOHEADER) + SIZE_PALETTE);

    pVideoInfo->dwBitRate = BITRATE;
    pVideoInfo->dwBitErrorRate = BITERRORRATE;
    pVideoInfo->AvgTimePerFrame = (LONGLONG) AVGTIME;

    // Calculate the offset into the resource data of the actual image pixels
    // taking into account any palette and bit field masks, for the palette
    // we assume that the number of colours used is set explicitely rather
    // than using zero to indicate the maximum number allowed for that type

    DWORD Offset = sizeof(BITMAPFILEHEADER) + sizeof(BITMAPINFOHEADER);

    if (PALETTISED(pVideoInfo) == TRUE) {
        ASSERT(pVideoInfo->bmiHeader.biCompression == BI_RGB);
        ASSERT(pVideoInfo->bmiHeader.biClrUsed);
        Offset += pVideoInfo->bmiHeader.biClrUsed * sizeof(RGBQUAD);
    }

    // Allow for BI_BITFIELDS colour masks

    if (pVideoInfo->bmiHeader.biCompression == BI_BITFIELDS) {
        Offset += SIZE_MASKS;
    }

    // Calculate the image data size and read it in

    DWORD Size = GetBitmapSize(&pVideoInfo->bmiHeader);
    ASSERT(Size <= MAXIMAGESIZE);
    pVideoInfo->bmiHeader.biSizeImage = Size;

    CopyMemory((PVOID)pImageData,
               (PVOID)(pResource + Offset),
               pVideoInfo->bmiHeader.biSizeImage);

    UnlockResource(hResource);
    FreeResource(hResource);
    return NOERROR;
}


// Displays the contents of a RGBQUAD palette

HRESULT DumpPalette(RGBQUAD *pRGBQuad,int iColours)
{
    NOTE("Palette from DIB... (RGB) \n");
    for (int iCount = 0;iCount < iColours;iCount++) {

        NOTE4("%4d %4d %4d %4d",iCount,
              pRGBQuad[iCount].rgbRed,
              pRGBQuad[iCount].rgbGreen,
              pRGBQuad[iCount].rgbBlue);
    }
    return NOERROR;
}


=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\multimedia\dshow\filters\image\vidtest\imagegrf.h ===
// Copyright (c) Microsoft Corporation 1994-1996. All Rights Reserved
// System filtergraph video tests, Anthony Phillips, March 1996

#ifndef __IMAGEGRF__
#define __IMAGEGRF__

BOOL SysFileTests(const TCHAR *pDirectory,      // Directory holding file
                  HANDLE hFindFile,             // Handle to search data
                  WIN32_FIND_DATA *pFindData);  // Used to get next file

long NextGraphEvent(CMovie *pMovie);
const TCHAR *NameFromCode(long Code);
const TCHAR *SurfaceFromCode(long Code);
int SysPlayTest(TCHAR *pFileName);
int SysSeekTest(TCHAR *pFileName);
int SysFullScreenPlayTest(TCHAR *pFileName);
int SysFullScreenSeekTest(TCHAR *pFileName);
void ResetActiveMovie();
BOOL RecurseDirectories(const TCHAR *pDirectory,const TCHAR *pExtension);

int execSysTest1();     // System test with DirectDraw
int execSysTest2();     // Same tests without DirectDraw
int execSysTest3();     // All surfaces and display modes

#endif // __IMAGEGRF__


=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\multimedia\dshow\filters\image\vidtest\imageobj.h ===
// Copyright (c) Microsoft Corporation 1994-1996. All Rights Reserved
// Manages the image renderer objects, Anthony Phillips, July 1995

#ifndef __IMAGEOBJ__
#define __IMAGEOBJ__

BOOL CheckFilterInterfaces();
HRESULT ReleaseInterfaces();
HRESULT CreateStream();
HRESULT CreateObjects();
HRESULT ReleaseStream();
HRESULT ConnectStream();
HRESULT DisconnectStream();
HRESULT EnumFilterPins(PFILTER pFilter);
HRESULT EnumeratePins();
HRESULT GetFilterInterfaces();
HRESULT GetPinInterfaces();
IPin *GetPin(IBaseFilter *pFilter, ULONG lPin);

HRESULT StartSystem(BOOL bUseClock);
HRESULT PauseSystem();
HRESULT StopSystem();
HRESULT StopWorkerThread();
HRESULT StartWorkerThread(UINT ConnectionType);
HRESULT SetStartTime();

#endif // __IMAGEOBJ__
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\multimedia\dshow\filters\image\vidtest\imagegrf.cpp ===
// Copyright (c) Microsoft Corporation 1994-1996. All Rights Reserved
// System filtergraph video tests, Anthony Phillips, March 1996

#include <streams.h>        // Includes all the IDL and base classes
#include <windows.h>        // Standard Windows SDK header file
#include <windowsx.h>       // Win32 Windows extensions and macros
#include <vidprop.h>        // Shared video properties library
#include <render.h>         // Normal video renderer header file
#include <modex.h>          // Specialised Modex video renderer
#include <convert.h>        // Defines colour space conversions
#include <colour.h>         // Rest of the colour space convertor
#include <imagetst.h>       // All our unit test header files
#include <stdio.h>          // Standard C runtime header file
#include <limits.h>         // Defines standard data type limits
#include <tchar.h>          // Unicode and ANSII portable types
#include <mmsystem.h>       // Multimedia used for timeGetTime
#include <stdlib.h>         // Standard C runtime function library
#include <tstshell.h>       // Definitions of constants eg TST_FAIL

// These are the display modes that we support. New modes can just be added
// in the right place and should work straight away. When selecting the mode
// to use we start at the top and work our way down. Not only must the mode
// be available but the amount of video lost by clipping if it is to be used
// (assuming the filter can't compress the video) must not exceed the clip
// lost factor. The display modes enabled (which may not be available) and
// the clip loss factor can all be changed by the IFullScreenVideo interface

const struct {

    LONG Width;            // Width of the display mode
    LONG Height;           // Likewise the mode height
    LONG Depth;            // Number of bits per pixel
    BOOL bAvailable;       // Does the card support it
    DWORD bEnabled;        // Has the user disabled it

} aModes[MAXMODES] = {
    { 320, 200, 8 },
    { 320, 200, 16 },
    { 320, 240, 8 },
    { 320, 240, 16 },
    { 640, 400, 8 },
    { 640, 400, 16 },
    { 640, 480, 8 },
    { 640, 480, 16 }
};


// Maps AMDDS identifiers to the actual surface name

const struct _SurfaceNames {
    long Code;
    const TCHAR *pName;
} g_SurfaceNames[] = {

    AMDDS_NONE,     TEXT("No use for DCI/DirectDraw"),
    AMDDS_DCIPS,    TEXT("Use DCI primary surface"),
    AMDDS_PS,       TEXT("Use DirectDraw primary"),
    AMDDS_RGBOVR,   TEXT("RGB overlay surfaces"),
    AMDDS_YUVOVR,   TEXT("YUV overlay surfaces"),
    AMDDS_RGBOFF,   TEXT("RGB offscreen surfaces"),
    AMDDS_YUVOFF,   TEXT("YUV offscreen surfaces"),
    AMDDS_RGBFLP,   TEXT("RGB flipping surfaces"),
    AMDDS_YUVFLP,   TEXT("YUV flipping surfaces"),
    AMDDS_ALL,      TEXT("Unknown surface type")
};


// Table to map event codes to their names

const struct _CodeNames {
    long Code;
    const TCHAR *pName;
} g_CodeNames[] = {

    EC_SYSTEMBASE,                    TEXT("EC_SYSTEMBASE"),
    EC_COMPLETE,                      TEXT("EC_COMPLETE"),
    EC_USERABORT,                     TEXT("EC_USERABORT"),
    EC_ERRORABORT,                    TEXT("EC_ERRORABORT"),
    EC_TIME,                          TEXT("EC_TIME"),
    EC_REPAINT,                       TEXT("EC_REPAINT"),
    EC_STREAM_ERROR_STOPPED,          TEXT("EC_STREAM_ERROR_STOPPED"),
    EC_STREAM_ERROR_STILLPLAYING,     TEXT("EC_STREAM_ERROR_STILLPLAYING"),
    EC_ERROR_STILLPLAYING,            TEXT("EC_ERROR_STILLPLAYING"),
    EC_PALETTE_CHANGED,               TEXT("EC_PALETTE_CHANGED"),
    EC_VIDEO_SIZE_CHANGED,            TEXT("EC_VIDEO_SIZE_CHANGED"),
    EC_QUALITY_CHANGE,                TEXT("EC_QUALITY_CHANGE"),
    EC_SHUTTING_DOWN,                 TEXT("EC_SHUTTING_DOWN"),
    EC_CLOCK_CHANGED,                 TEXT("EC_CLOCK_CHANGED"),
    EC_OPENING_FILE,                  TEXT("EC_OPENING_FILE"),
    EC_BUFFERING_DATA,                TEXT("EC_BUFFERING_DATA"),
    EC_FULLSCREEN_LOST,               TEXT("EC_FULLSCREEN_LOST"),
    EC_ACTIVATE,                      TEXT("EC_ACTIVATE"),
    EC_USER,                          TEXT("EC_USER")
};


// Return the next event code from the filtergraph queue

long NextGraphEvent(CMovie *pMovie)
{
    long lEventCode = EC_SYSTEMBASE;
    lEventCode = pMovie->GetMovieEventCode();
    switch (lEventCode) {

        case EC_FULLSCREEN_LOST:
            NOTE("EC_FULLSCREEN_LOST received");
            break;

        case EC_COMPLETE:
            NOTE("EC_COMPLETE received");
            break;

        case EC_USERABORT:
            NOTE("EC_USERABORT received");
            break;

        case EC_ERRORABORT:
            NOTE("EC_ERRORABORT received");
            break;
    }
    return lEventCode;
}


// Return the name for this event code

const TCHAR *NameFromCode(long Code)
{
    long Table = 0;
    while (g_CodeNames[Table].Code != EC_USER) {
        if (g_CodeNames[Table].Code == Code) {
            return g_CodeNames[Table].pName;
        }
        Table++;
    }
    return TEXT("Unknown event");
}


// Return the surface name for this identifier

const TCHAR *SurfaceFromCode(long Code)
{
    long Table = 0;
    while (g_SurfaceNames[Table].Code != AMDDS_ALL) {
        if (g_SurfaceNames[Table].Code == Code) {
            return g_SurfaceNames[Table].pName;
        }
        Table++;
    }
    return TEXT("Unknown surface type");
}


// Simple playback test for ActiveMovie filtergraphs. We are passed a string
// filename that we initialise the movie helper class. And if that succeeded
// which it should do then we play the movie and wait for the end to arrive
// After which we reset the current position and do a couple of quick tests
// and play it though again, while we are waiting we yield to allow logging

int SysPlayTest(TCHAR *pFileName)
{
    CMovie Movie;
    BOOL bSuccess;

    // Open the movie filename we are handed

    bSuccess = Movie.OpenMovie(pFileName);
    if (bSuccess == FALSE) {
        Log(TERSE,TEXT("Could not open movie"));
        return TST_FAIL;
    }

    EXECUTE_ASSERT(Movie.PlayMovie() == TRUE);

    // Yield until we receive an EC_COMPLETE message

    while (TRUE) {
        if (NextGraphEvent(&Movie) == EC_COMPLETE) {
            NOTE("Playback completed");
            break;
        }
        YieldAndSleep(500);
    }

    // Check there are no more EC_COMPLETE messages

    while (TRUE) {
        LONG Code = NextGraphEvent(&Movie);
        if (Code == EC_SYSTEMBASE) {
            NOTE("No more events");
            break;
        }
        NOTE1("Event obtained %s",NameFromCode(Code));
        if (Code == EC_COMPLETE) {
            Log(TERSE,TEXT("Too many EC_COMPLETEs"));
        }
    }

    // Reset the movie to the beginning

    EXECUTE_ASSERT(Movie.SeekToPosition(0) == TRUE);
    EXECUTE_ASSERT(Movie.PauseMovie() == TRUE);
    EXECUTE_ASSERT(Movie.StopMovie() == TRUE);
    EXECUTE_ASSERT(Movie.SeekToPosition(0) == TRUE);
    EXECUTE_ASSERT(Movie.PauseMovie() == TRUE);
    EXECUTE_ASSERT(Movie.PlayMovie() == TRUE);

    // Yield until we receive an EC_COMPLETE message

    while (TRUE) {
        if (NextGraphEvent(&Movie) == EC_COMPLETE) {
            NOTE("Playback completed");
            break;
        }
        YieldAndSleep(500);
    }

    // Check there are no more EC_COMPLETE messages

    while (TRUE) {
        LONG Code = NextGraphEvent(&Movie);
        if (Code == EC_SYSTEMBASE) {
            NOTE("No more events");
            break;
        }
        NOTE1("Event obtained %s",NameFromCode(Code));
        if (Code == EC_COMPLETE) {
            Log(TERSE,TEXT("Too many EC_COMPLETEs"));
        }
    }
    return TST_PASS;
}


// This test mixes a number of state changes with some position seeking. We
// read the duration of the file and use that as the amount to step forward
// and backwards through the media. If the file is very short (maybe a one
// image MPEG file) then they should still work although they will evaluate
// to zero positions each time. Each time we seek to another position the
// end of stream flag should be reset in renderers so that they can signal
// another EC_COMPLETE. Therefore the last time we actually play it through
// from start to finish we clear the filtergraph event log before starting

int SysSeekTest(TCHAR *pFileName)
{
    CMovie Movie;
    BOOL bSuccess;

    // Open the movie filename we are handed

    bSuccess = Movie.OpenMovie(pFileName);
    if (bSuccess == FALSE) {
        Log(TERSE,TEXT("Could not open movie"));
        return TST_FAIL;
    }

    // Check the durations all match

    EXECUTE_ASSERT(Movie.PlayMovie() == TRUE);
    REFTIME Duration = Movie.GetDuration();
    EXECUTE_ASSERT(Movie.PauseMovie() == TRUE);
    REFTIME PauseDuration = Movie.GetDuration();
    EXECUTE_ASSERT(PauseDuration == Duration);
    EXECUTE_ASSERT(Movie.StopMovie() == TRUE);
    REFTIME StopDuration = Movie.GetDuration();
    EXECUTE_ASSERT(StopDuration == Duration);
    EXECUTE_ASSERT(Movie.PlayMovie() == TRUE);
    YieldAndSleep((long)(Duration / 2));

    // Step our way through the file and back again without waiting

    EXECUTE_ASSERT(Movie.SeekToPosition(Duration) == TRUE);
    EXECUTE_ASSERT(Movie.SeekToPosition(Duration / 4) == TRUE);
    EXECUTE_ASSERT(Movie.SeekToPosition(Duration / 3) == TRUE);
    EXECUTE_ASSERT(Movie.SeekToPosition(Duration / 2) == TRUE);
    EXECUTE_ASSERT(Movie.SeekToPosition(Duration * 3 / 4) == TRUE);
    EXECUTE_ASSERT(Movie.SeekToPosition(Duration / 2) == TRUE);
    EXECUTE_ASSERT(Movie.SeekToPosition(Duration / 3) == TRUE);
    EXECUTE_ASSERT(Movie.SeekToPosition(Duration / 4) == TRUE);

    // Now do the same but wait for each seek to complete

    EXECUTE_ASSERT(Movie.SeekToPosition(Duration) == TRUE);
    EXECUTE_ASSERT(Movie.PauseMovie() == TRUE);
    EXECUTE_ASSERT(Movie.StatusMovie(INFINITE) == MOVIE_PAUSED);
    YieldAndSleep(1000);
    EXECUTE_ASSERT(Movie.SeekToPosition(Duration / 4) == TRUE);
    EXECUTE_ASSERT(Movie.PauseMovie() == TRUE);
    EXECUTE_ASSERT(Movie.StatusMovie(INFINITE) == MOVIE_PAUSED);
    YieldAndSleep(1000);
    EXECUTE_ASSERT(Movie.SeekToPosition(Duration / 3) == TRUE);
    EXECUTE_ASSERT(Movie.PauseMovie() == TRUE);
    EXECUTE_ASSERT(Movie.StatusMovie(INFINITE) == MOVIE_PAUSED);
    YieldAndSleep(1000);
    EXECUTE_ASSERT(Movie.SeekToPosition(Duration / 2) == TRUE);
    EXECUTE_ASSERT(Movie.PauseMovie() == TRUE);
    EXECUTE_ASSERT(Movie.StatusMovie(INFINITE) == MOVIE_PAUSED);
    YieldAndSleep(1000);
    EXECUTE_ASSERT(Movie.SeekToPosition(Duration * 3 / 4) == TRUE);
    EXECUTE_ASSERT(Movie.PauseMovie() == TRUE);
    EXECUTE_ASSERT(Movie.StatusMovie(INFINITE) == MOVIE_PAUSED);
    YieldAndSleep(1000);
    EXECUTE_ASSERT(Movie.SeekToPosition(Duration / 2) == TRUE);
    EXECUTE_ASSERT(Movie.PauseMovie() == TRUE);
    EXECUTE_ASSERT(Movie.StatusMovie(INFINITE) == MOVIE_PAUSED);
    YieldAndSleep(1000);
    EXECUTE_ASSERT(Movie.SeekToPosition(Duration / 3) == TRUE);
    EXECUTE_ASSERT(Movie.PauseMovie() == TRUE);
    EXECUTE_ASSERT(Movie.StatusMovie(INFINITE) == MOVIE_PAUSED);
    YieldAndSleep(1000);
    EXECUTE_ASSERT(Movie.SeekToPosition(Duration / 4) == TRUE);
    EXECUTE_ASSERT(Movie.PauseMovie() == TRUE);
    EXECUTE_ASSERT(Movie.StatusMovie(INFINITE) == MOVIE_PAUSED);
    YieldAndSleep(1000);

    // Mix in a number of state changes with seeks

    EXECUTE_ASSERT(Movie.SeekToPosition(Duration) == TRUE);
    YieldAndSleep(1000);
    EXECUTE_ASSERT(Movie.PlayMovie() == TRUE);
    EXECUTE_ASSERT(Movie.StatusMovie(INFINITE) == MOVIE_PLAYING);
    EXECUTE_ASSERT(Movie.PauseMovie() == TRUE);
    EXECUTE_ASSERT(Movie.StatusMovie(INFINITE) == MOVIE_PAUSED);
    EXECUTE_ASSERT(Movie.PlayMovie() == TRUE);
    EXECUTE_ASSERT(Movie.StatusMovie(INFINITE) == MOVIE_PLAYING);
    EXECUTE_ASSERT(Movie.SeekToPosition(Duration / 2) == TRUE);
    YieldAndSleep(1000);
    EXECUTE_ASSERT(Movie.PlayMovie() == TRUE);
    EXECUTE_ASSERT(Movie.StatusMovie(INFINITE) == MOVIE_PLAYING);
    EXECUTE_ASSERT(Movie.PauseMovie() == TRUE);
    EXECUTE_ASSERT(Movie.StatusMovie(INFINITE) == MOVIE_PAUSED);
    EXECUTE_ASSERT(Movie.PlayMovie() == TRUE);
    EXECUTE_ASSERT(Movie.StatusMovie(INFINITE) == MOVIE_PLAYING);
    EXECUTE_ASSERT(Movie.SeekToPosition(0) == TRUE);
    EXECUTE_ASSERT(Movie.StatusMovie(INFINITE) == MOVIE_PLAYING);
    YieldAndSleep(1000);
    EXECUTE_ASSERT(Movie.PlayMovie() == TRUE);
    EXECUTE_ASSERT(Movie.PauseMovie() == TRUE);
    EXECUTE_ASSERT(Movie.PlayMovie() == TRUE);
    EXECUTE_ASSERT(Movie.StopMovie() == TRUE);

    // Clear the event log out before running

    while (TRUE) {
        LONG Code = NextGraphEvent(&Movie);
        if (Code == EC_SYSTEMBASE) {
            break;
        }
        NOTE1("Event obtained %s",NameFromCode(Code));
    }

    // From the beginning run through the file

    EXECUTE_ASSERT(Movie.StopMovie() == TRUE);
    EXECUTE_ASSERT(Movie.SeekToPosition(0) == TRUE);
    EXECUTE_ASSERT(Movie.PauseMovie() == TRUE);
    EXECUTE_ASSERT(Movie.PlayMovie() == TRUE);

    // Yield until we receive an EC_COMPLETE message

    while (TRUE) {
        if (NextGraphEvent(&Movie) == EC_COMPLETE) {
            NOTE("Playback completed");
            break;
        }
        YieldAndSleep(500);
    }

    // Try a number of rapid state changes

    EXECUTE_ASSERT(Movie.SeekToPosition(0) == TRUE);
    EXECUTE_ASSERT(Movie.PlayMovie() == TRUE);
    EXECUTE_ASSERT(Movie.PauseMovie() == TRUE);
    EXECUTE_ASSERT(Movie.PlayMovie() == TRUE);
    EXECUTE_ASSERT(Movie.StopMovie() == TRUE);
    EXECUTE_ASSERT(Movie.PauseMovie() == TRUE);
    EXECUTE_ASSERT(Movie.PlayMovie() == TRUE);
    EXECUTE_ASSERT(Movie.StopMovie() == TRUE);
    EXECUTE_ASSERT(Movie.PauseMovie() == TRUE);
    EXECUTE_ASSERT(Movie.StopMovie() == TRUE);
    EXECUTE_ASSERT(Movie.PlayMovie() == TRUE);
    EXECUTE_ASSERT(Movie.StopMovie() == TRUE);

    return TST_PASS;
}


// This is basicly the same as the SysPlayTest except that we run the tests
// with a variety of fullscreen mode being turned on and off. Since many of
// the ActiveMovie applications have been fullscreen enabled we don't have
// to check whether it works so much as stress testing the switching under
// a number of difficult conditions. Therefore manual tests are also needed

int SysFullScreenPlayTest(TCHAR *pFileName)
{
    CMovie Movie;
    BOOL bSuccess;

    // Open the movie filename we are handed

    bSuccess = Movie.OpenMovie(pFileName);
    if (bSuccess == FALSE) {
        Log(TERSE,TEXT("Could not open movie"));
        return TST_FAIL;
    }

    EXECUTE_ASSERT(Movie.PlayMovie() == TRUE);
    EXECUTE_ASSERT(Movie.SetFullScreenMode(TRUE) == TRUE);
    EXECUTE_ASSERT(Movie.SetFullScreenMode(TRUE) == TRUE);

    // Yield until we receive an EC_COMPLETE message

    while (TRUE) {
        if (NextGraphEvent(&Movie) == EC_COMPLETE) {
            NOTE("Playback completed");
            break;
        }
        YieldAndSleep(500);
    }

    // Check there are no more EC_COMPLETE messages

    while (TRUE) {
        LONG Code = NextGraphEvent(&Movie);
        if (Code == EC_SYSTEMBASE) {
            NOTE("No more events");
            break;
        }
        NOTE1("Event obtained %s",NameFromCode(Code));
        if (Code == EC_COMPLETE) {
            Log(TERSE,TEXT("Too many EC_COMPLETEs"));
        }
    }

    // Reset the movie to the beginning

    EXECUTE_ASSERT(Movie.SeekToPosition(0) == TRUE);
    EXECUTE_ASSERT(Movie.PauseMovie() == TRUE);
    EXECUTE_ASSERT(Movie.StopMovie() == TRUE);
    EXECUTE_ASSERT(Movie.SeekToPosition(0) == TRUE);
    EXECUTE_ASSERT(Movie.PauseMovie() == TRUE);
    EXECUTE_ASSERT(Movie.PlayMovie() == TRUE);
    EXECUTE_ASSERT(Movie.SetFullScreenMode(TRUE) == TRUE);
    EXECUTE_ASSERT(Movie.SetFullScreenMode(FALSE) == TRUE);
    EXECUTE_ASSERT(Movie.SetFullScreenMode(TRUE) == TRUE);

    // Yield until we receive an EC_COMPLETE message

    while (TRUE) {
        if (NextGraphEvent(&Movie) == EC_COMPLETE) {
            NOTE("Playback completed");
            break;
        }
        YieldAndSleep(500);
    }

    // Check there are no more EC_COMPLETE messages

    while (TRUE) {
        LONG Code = NextGraphEvent(&Movie);
        if (Code == EC_SYSTEMBASE) {
            NOTE("No more events");
            break;
        }
        NOTE1("Event obtained %s",NameFromCode(Code));
        if (Code == EC_COMPLETE) {
            Log(TERSE,TEXT("Too many EC_COMPLETEs"));
        }
    }
    return TST_PASS;
}


// This is basicly the same as the SysSeekTest except that we run the tests
// with a variety of fullscreen mode being turned on and off. Since many of
// the ActiveMovie applications have been fullscreen enabled we don't have
// to check whether it works so much as stress testing the switching under
// a number of difficult conditions. Therefore manual tests are also needed

int SysFullScreenSeekTest(TCHAR *pFileName)
{
    CMovie Movie;
    BOOL bSuccess;

    // Open the movie filename we are handed

    bSuccess = Movie.OpenMovie(pFileName);
    if (bSuccess == FALSE) {
        Log(TERSE,TEXT("Could not open movie"));
        return TST_FAIL;
    }

    // Check the durations all match

    EXECUTE_ASSERT(Movie.PlayMovie() == TRUE);
    REFTIME Duration = Movie.GetDuration();
    EXECUTE_ASSERT(Movie.PauseMovie() == TRUE);
    REFTIME PauseDuration = Movie.GetDuration();
    EXECUTE_ASSERT(PauseDuration == Duration);
    EXECUTE_ASSERT(Movie.StopMovie() == TRUE);
    REFTIME StopDuration = Movie.GetDuration();
    EXECUTE_ASSERT(StopDuration == Duration);
    EXECUTE_ASSERT(Movie.PlayMovie() == TRUE);
    YieldAndSleep((long)(Duration / 2));

    // Step our way through the file and back again without waiting

    EXECUTE_ASSERT(Movie.SetFullScreenMode(TRUE) == TRUE);
    EXECUTE_ASSERT(Movie.SeekToPosition(Duration) == TRUE);
    EXECUTE_ASSERT(Movie.SeekToPosition(Duration / 4) == TRUE);
    EXECUTE_ASSERT(Movie.SeekToPosition(Duration / 3) == TRUE);
    EXECUTE_ASSERT(Movie.SeekToPosition(Duration / 2) == TRUE);
    EXECUTE_ASSERT(Movie.SeekToPosition(Duration * 3 / 4) == TRUE);
    EXECUTE_ASSERT(Movie.SeekToPosition(Duration / 2) == TRUE);
    EXECUTE_ASSERT(Movie.SeekToPosition(Duration / 3) == TRUE);
    EXECUTE_ASSERT(Movie.SeekToPosition(Duration / 4) == TRUE);

    // Now do the same but wait for each seek to complete

    EXECUTE_ASSERT(Movie.SeekToPosition(Duration) == TRUE);
    EXECUTE_ASSERT(Movie.PauseMovie() == TRUE);
    EXECUTE_ASSERT(Movie.StatusMovie(INFINITE) == MOVIE_PAUSED);
    EXECUTE_ASSERT(Movie.SetFullScreenMode(TRUE) == TRUE);
    YieldAndSleep(1000);
    EXECUTE_ASSERT(Movie.SeekToPosition(Duration / 4) == TRUE);
    EXECUTE_ASSERT(Movie.PauseMovie() == TRUE);
    EXECUTE_ASSERT(Movie.StatusMovie(INFINITE) == MOVIE_PAUSED);
    EXECUTE_ASSERT(Movie.SetFullScreenMode(TRUE) == TRUE);
    YieldAndSleep(1000);
    EXECUTE_ASSERT(Movie.SeekToPosition(Duration / 3) == TRUE);
    EXECUTE_ASSERT(Movie.PauseMovie() == TRUE);
    EXECUTE_ASSERT(Movie.StatusMovie(INFINITE) == MOVIE_PAUSED);
    EXECUTE_ASSERT(Movie.SetFullScreenMode(TRUE) == TRUE);
    YieldAndSleep(1000);
    EXECUTE_ASSERT(Movie.SeekToPosition(Duration / 2) == TRUE);
    EXECUTE_ASSERT(Movie.PauseMovie() == TRUE);
    EXECUTE_ASSERT(Movie.StatusMovie(INFINITE) == MOVIE_PAUSED);
    EXECUTE_ASSERT(Movie.SetFullScreenMode(TRUE) == TRUE);
    YieldAndSleep(1000);
    EXECUTE_ASSERT(Movie.SeekToPosition(Duration * 3 / 4) == TRUE);
    EXECUTE_ASSERT(Movie.PauseMovie() == TRUE);
    EXECUTE_ASSERT(Movie.StatusMovie(INFINITE) == MOVIE_PAUSED);
    EXECUTE_ASSERT(Movie.SetFullScreenMode(TRUE) == TRUE);
    YieldAndSleep(1000);
    EXECUTE_ASSERT(Movie.SeekToPosition(Duration / 2) == TRUE);
    EXECUTE_ASSERT(Movie.PauseMovie() == TRUE);
    EXECUTE_ASSERT(Movie.StatusMovie(INFINITE) == MOVIE_PAUSED);
    EXECUTE_ASSERT(Movie.SetFullScreenMode(TRUE) == TRUE);
    YieldAndSleep(1000);
    EXECUTE_ASSERT(Movie.SeekToPosition(Duration / 3) == TRUE);
    EXECUTE_ASSERT(Movie.PauseMovie() == TRUE);
    EXECUTE_ASSERT(Movie.StatusMovie(INFINITE) == MOVIE_PAUSED);
    EXECUTE_ASSERT(Movie.SetFullScreenMode(TRUE) == TRUE);
    YieldAndSleep(1000);
    EXECUTE_ASSERT(Movie.SeekToPosition(Duration / 4) == TRUE);
    EXECUTE_ASSERT(Movie.PauseMovie() == TRUE);
    EXECUTE_ASSERT(Movie.StatusMovie(INFINITE) == MOVIE_PAUSED);
    EXECUTE_ASSERT(Movie.SetFullScreenMode(TRUE) == TRUE);
    YieldAndSleep(1000);

    // Mix in a number of state changes with seeks

    EXECUTE_ASSERT(Movie.SeekToPosition(Duration) == TRUE);
    YieldAndSleep(1000);
    EXECUTE_ASSERT(Movie.PlayMovie() == TRUE);
    EXECUTE_ASSERT(Movie.StatusMovie(INFINITE) == MOVIE_PLAYING);
    EXECUTE_ASSERT(Movie.PauseMovie() == TRUE);
    EXECUTE_ASSERT(Movie.StatusMovie(INFINITE) == MOVIE_PAUSED);
    EXECUTE_ASSERT(Movie.PlayMovie() == TRUE);
    EXECUTE_ASSERT(Movie.StatusMovie(INFINITE) == MOVIE_PLAYING);
    EXECUTE_ASSERT(Movie.SeekToPosition(Duration / 2) == TRUE);
    YieldAndSleep(1000);
    EXECUTE_ASSERT(Movie.PlayMovie() == TRUE);
    EXECUTE_ASSERT(Movie.StatusMovie(INFINITE) == MOVIE_PLAYING);
    EXECUTE_ASSERT(Movie.PauseMovie() == TRUE);
    EXECUTE_ASSERT(Movie.StatusMovie(INFINITE) == MOVIE_PAUSED);
    EXECUTE_ASSERT(Movie.PlayMovie() == TRUE);
    EXECUTE_ASSERT(Movie.StatusMovie(INFINITE) == MOVIE_PLAYING);
    EXECUTE_ASSERT(Movie.SeekToPosition(0) == TRUE);
    EXECUTE_ASSERT(Movie.StatusMovie(INFINITE) == MOVIE_PLAYING);
    YieldAndSleep(1000);
    EXECUTE_ASSERT(Movie.PlayMovie() == TRUE);
    EXECUTE_ASSERT(Movie.PauseMovie() == TRUE);
    EXECUTE_ASSERT(Movie.PlayMovie() == TRUE);
    EXECUTE_ASSERT(Movie.StopMovie() == TRUE);

    // Clear the event log out before running

    while (TRUE) {
        LONG Code = NextGraphEvent(&Movie);
        if (Code == EC_SYSTEMBASE) {
            break;
        }
        NOTE1("Event obtained %s",NameFromCode(Code));
    }

    // From the beginning run through the file

    EXECUTE_ASSERT(Movie.StopMovie() == TRUE);
    EXECUTE_ASSERT(Movie.SeekToPosition(0) == TRUE);
    EXECUTE_ASSERT(Movie.PauseMovie() == TRUE);
    EXECUTE_ASSERT(Movie.PlayMovie() == TRUE);

    // Yield until we receive an EC_COMPLETE message

    while (TRUE) {
        if (NextGraphEvent(&Movie) == EC_COMPLETE) {
            NOTE("Playback completed");
            break;
        }
        YieldAndSleep(500);
    }

    // Try a number of rapid state changes

    EXECUTE_ASSERT(Movie.SeekToPosition(0) == TRUE);
    EXECUTE_ASSERT(Movie.PlayMovie() == TRUE);
    EXECUTE_ASSERT(Movie.PauseMovie() == TRUE);
    EXECUTE_ASSERT(Movie.PlayMovie() == TRUE);
    EXECUTE_ASSERT(Movie.StopMovie() == TRUE);
    EXECUTE_ASSERT(Movie.PauseMovie() == TRUE);
    EXECUTE_ASSERT(Movie.PlayMovie() == TRUE);
    EXECUTE_ASSERT(Movie.StopMovie() == TRUE);
    EXECUTE_ASSERT(Movie.PauseMovie() == TRUE);
    EXECUTE_ASSERT(Movie.StopMovie() == TRUE);
    EXECUTE_ASSERT(Movie.PlayMovie() == TRUE);
    EXECUTE_ASSERT(Movie.StopMovie() == TRUE);

    return TST_PASS;
}


// This is passed a file on which to run the automatic test suite. We're also
// passed the necessary information to enumerate the rest of the files in the
// directory specified. Because we know certain files are invalid we maintain
// a table of these, against each file name we look for matches and reject it
// if it is found. This table should be kept upto date with known duff files

TCHAR *g_BadFiles[] = { TEXT("SW78.MPG"),
                        TEXT("PASTE.AVI"),
                        TEXT("SCROLL.AVI"),
                        TEXT("TASKSWCH.AVI"), NULL };

BOOL SysFileTests(const TCHAR *pDirectory,      // Directory holding file
                  HANDLE hFindFile,             // Handle to search data
                  WIN32_FIND_DATA *pFindData)   // Used to get next file
{
    while (TRUE) {

        // Log the full file name

        TCHAR FileName[MAX_PATH];
        wsprintf(FileName,TEXT("%s%s"),pDirectory,pFindData->cFileName);
        Log(TERSE,FileName);
        BOOL bBadFile = FALSE;

        // Can we match against any of our known duff ones

        for (int Position = 0;g_BadFiles[Position];Position++) {
            if (lstrcmp(g_BadFiles[Position],pFindData->cFileName) == 0) {
                Log(TERSE,"(Bad file ignored)");
                bBadFile = TRUE;
            }
        }

        // Run all four automatic tests against it

        if (bBadFile == FALSE) {
            EXECUTE_ASSERT(SysPlayTest(FileName) == TST_PASS);
            EXECUTE_ASSERT(SysSeekTest(FileName) == TST_PASS);
            EXECUTE_ASSERT(SysFullScreenPlayTest(FileName) == TST_PASS);
            EXECUTE_ASSERT(SysFullScreenSeekTest(FileName) == TST_PASS);
        }

        if (FindNextFile(hFindFile,pFindData) == FALSE) {
            return TRUE;
        }
    }
}


// This is the real part of the system testing. We are passed in a directory
// with a trailing \ character, we are also given the current extension type
// With these two we search for all matching files in the current directory.
// For each file found we run the system test suite. After processing all
// available files we go back and enumerate all the subdirectories (must be
// careful not to include the . and .. entries) and for each of them call
// ourselves to process all the files in there. This means that we'll do a
// depth first search of the current drive when searching for matching files

BOOL RecurseDirectories(const TCHAR *pDirectory,const TCHAR *pExtension)
{
    NOTE2("Recursing %s%s",pDirectory,pExtension);
    TCHAR SearchString[MAX_PATH];
    WIN32_FIND_DATA FindData;

    // First enumerate all the data files

    wsprintf(SearchString,TEXT("%s%s"),pDirectory,pExtension);
    HANDLE hFindFile = FindFirstFile(SearchString,&FindData);
    if (hFindFile != INVALID_HANDLE_VALUE) {
        SysFileTests(pDirectory,hFindFile,&FindData);
        FindClose(hFindFile);
    }

    // Now enumerate all the subdirectories

    wsprintf(SearchString,TEXT("%s*"),pDirectory);
    hFindFile = FindFirstFile(SearchString,&FindData);
    if (hFindFile == INVALID_HANDLE_VALUE) {
        NOTE("Empty");
        return TRUE;
    }

    // For each subdirectory repeat the file search

    do { if (FindData.dwFileAttributes & FILE_ATTRIBUTE_DIRECTORY) {
             if (FindData.cFileName[0] != TCHAR('.')) {
                  wsprintf(SearchString,TEXT("%s%s\\"),pDirectory,FindData.cFileName);
                  RecurseDirectories(SearchString,pExtension);
             }
         }
    } while (FindNextFile(hFindFile,&FindData));

    FindClose(hFindFile);
    return TRUE;
}


// We are called during final closedown of the test application (tstTerminate)
// so that we can reset any settings that might have changed. To make life as
// simple as possible we reset the display modes and surface available to all
// the possibilities. These settings might have been changed during the calls
// to check different DirectDraw surfaces and in here for fullscreen support

void ResetActiveMovie()
{
    TCHAR Profile[MAX_PATH];
    TCHAR KeyName[MAX_PATH];

    // Save a key for each of our supported display modes

    for (int Loop = 0;Loop < MAXMODES;Loop++) {
        wsprintf(KeyName,TEXT("%dx%dx%d"),aModes[Loop].Width,aModes[Loop].Height,aModes[Loop].Depth);
        wsprintf(Profile,TEXT("%d"),TRUE);
        WriteProfileString(TEXT("Quartz"),KeyName,Profile);
    }

    // And reset the surfaces that are available

    wsprintf(Profile,TEXT("%d"),AMDDS_ALL);
    WriteProfileString(TEXT("DrawDib"),TEXT("ActiveMovieDraw"),Profile);
}


//==========================================================================
//
//  int execSysTest1
//
//  Description:
//      A system test that tests the seek and playback of many video files
//      The tests don't really check return codes but do a large number of
//      seeking and state changes. This test runs the test suite against
//      all MPG,AVI and MOV files found on the current disk. It does this
//      by recursing from the root directory through the tree for each and
//      every file extensions. As a consequence this runs for a long time!
//
//==========================================================================

int execSysTest1()
{
    Log(TERSE,TEXT("Entering system test #1"));
    LogFlush();

    // Start at the root for each extension type

    TCHAR Directory[MAX_PATH];
    GetCurrentDirectory(MAX_PATH,Directory);
    Directory[3] = (TCHAR) 0;

    // Run the tests against each file type

    Log(TERSE,TEXT("Running MPG system tests"));
    RecurseDirectories(Directory,TEXT("*.MPG"));
    Log(TERSE,TEXT("Running AVI system tests"));
    RecurseDirectories(Directory,TEXT("*.AVI"));
    Log(TERSE,TEXT("Running MOV system tests"));
    RecurseDirectories(Directory,TEXT("*.MOV"));

    Log(TERSE,TEXT("Exiting system test #1"));
    LogFlush();
    return TST_PASS;
}


//==========================================================================
//
//  int execSysTest2
//
//  Description:
//      This executes the same tests as execSysTest1 except that before the
//      tests are run we make sure to unload DirectDraw. By doing this we
//      make it available to the Quartz video renderer and the modex filter
//      After running the tests we reload DirectDraw as if nothing changed
//
//==========================================================================

int execSysTest2()
{
    Log(TERSE,TEXT("Entering system test #2"));
    ReleaseDirectDraw();
    LogFlush();

    // Start at the root for each extension type

    TCHAR Directory[MAX_PATH];
    GetCurrentDirectory(MAX_PATH,Directory);
    Directory[3] = (TCHAR) 0;

    // Run the tests against each file type

    Log(TERSE,TEXT("Running MPG system tests"));
    RecurseDirectories(Directory,TEXT("*.MPG"));
    Log(TERSE,TEXT("Running AVI system tests"));
    RecurseDirectories(Directory,TEXT("*.AVI"));
    Log(TERSE,TEXT("Running MOV system tests"));
    RecurseDirectories(Directory,TEXT("*.MOV"));

    Log(TERSE,TEXT("Exiting system test #2"));
    LogFlush();
    InitDirectDraw();
    return TST_PASS;
}


//==========================================================================
//
//  int execSysTest3
//
//  Description:
//
//      This takes a long time to run. For each display mode supported by
//      the modex renderer and for each DirectDraw surface available from
//      the normal renderer we run both system tests. The second one is
//      the most interesting as it leaves DirectDraw unavailable to the
//      renderers. We use the knowledge of the renderer registry entries
//      to change them without having to fiddle with instantiated filters
//
//==========================================================================

int execSysTest3()
{
    Log(TERSE,TEXT("Entering system test #3"));
    TCHAR Profile[MAX_PATH];
    TCHAR KeyName[MAX_PATH];
    LogFlush();

    for (int Mode = 0;Mode < MAXMODES;Mode++) {

        // Save a key for each of our supported display modes

        for (int Loop = 0;Loop < MAXMODES;Loop++) {
            wsprintf(KeyName,TEXT("%dx%dx%d"),aModes[Loop].Width,aModes[Loop].Height,aModes[Loop].Depth);
            wsprintf(Profile,TEXT("%d"),(Loop == Mode ? TRUE : FALSE));
            WriteProfileString(TEXT("Quartz"),KeyName,Profile);
        }

        for (int Surface = AMDDS_YUVFLP;;Surface /= 2) {

            wsprintf(Profile,TEXT("%d"),Surface);
            WriteProfileString(TEXT("DrawDib"),TEXT("ActiveMovieDraw"),Profile);
            wsprintf(KeyName,TEXT("%dx%dx%d"),aModes[Mode].Width,aModes[Mode].Height,aModes[Mode].Depth);
            wsprintf(Profile,TEXT("Mode %s Surface %s"),KeyName,SurfaceFromCode(Surface));
            Log(TERSE,Profile);

            EXECUTE_ASSERT(execSysTest1() == TST_PASS);
            EXECUTE_ASSERT(execSysTest2() == TST_PASS);

            if (Surface == AMDDS_NONE) {
                break;
            }
        }
    }

    Log(TERSE,TEXT("Exiting system test #3"));
    LogFlush();
    return TST_PASS;
}
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\multimedia\dshow\filters\image\vidtest\imageobj.cpp ===
// Copyright (c) Microsoft Corporation 1994-1996. All Rights Reserved
// Manages the image renderer objects, Anthony Phillips, July 1995

#include <streams.h>        // Includes all the IDL and base classes
#include <windows.h>        // Standard Windows SDK header file
#include <windowsx.h>       // Win32 Windows extensions and macros
#include <vidprop.h>        // Shared video properties library
#include <render.h>         // Normal video renderer header file
#include <modex.h>          // Specialised Modex video renderer
#include <convert.h>        // Defines colour space conversions
#include <colour.h>         // Rest of the colour space convertor
#include <imagetst.h>       // All our unit test header files
#include <stdio.h>          // Standard C runtime header file
#include <limits.h>         // Defines standard data type limits
#include <tchar.h>          // Unicode and ANSII portable types
#include <mmsystem.h>       // Multimedia used for timeGetTime
#include <stdlib.h>         // Standard C runtime function library
#include <tstshell.h>       // Definitions of constants eg TST_FAIL
#include <initguid.h>       // Has GUID definitions really made
#include <olectlid.h>       // We need IID_IPropertyPage defined

// This file provides public functions to create, manage and destroy objects
// required to test the video renderer. We can be asked to connect the source
// and video renderer pins up and to execute state changes on the objects as
// the caller sees fit. We also have an entry point to start the basic tests
// running which exercise the standard samples and overlay transports. These
// basic tests are executed on a separate worker thread created in here. We
// import some other header files to gain access to explicit object GUIDs

CImageSource *pImageSource = NULL;      // Pointer to image source object
IPin *pOutputPin = NULL;                // Pin provided by the source object
IPin *pInputPin = NULL;                 // Pin to connect with in the renderer
IDirectDrawVideo *pDirectVideo = NULL;  // Access to DirectDraw video options
IBaseFilter *pRenderFilter = NULL;      // The renderer IBaseFilter interface
IBaseFilter *pSourceFilter = NULL;      // The source IBaseFilter interface
IMediaFilter *pRenderMedia = NULL;      // The renderer IMediaFilter interface
IMediaFilter *pSourceMedia = NULL;      // The source IMediaFilter interface
IBasicVideo *pBasicVideo = NULL;        // Video renderer control interface
IVideoWindow *pVideoWindow = NULL;      // Another window control interface
IOverlay *pOverlay = NULL;              // Direct video overlay interface
COverlayNotify *pOverlayNotify = NULL;  // Receives asynchronous updates
IOverlayNotify *pNotify = NULL;         // Interface we pass in to IOverlay
IReferenceClock *pClock = NULL;         // Reference clock implementation
CRefTime gtBase;                        // Time when we started running
CRefTime gtPausedAt;                    // This was the time we paused

BOOL bConnected = FALSE;                // Have we connected the filters
BOOL bCreated = FALSE;                  // have the objects been created
BOOL bRunning = FALSE;                  // Are we in a running state yet
HANDLE hThread;                         // Handle to the worker thread
DWORD dwThreadID;                       // Thread ID for worker thread
HANDLE hState;                          // Signal the thread to change state


// List of class IDs and creation functions for the class factory. This
// provides the link between the OLE entry point in the DLL and the COM
// object to create. The class factory calls the static CreateInstance
// function when it is asked to create the objects although as the test
// harness we do not support any (we need these defined though anyway)

CFactoryTemplate g_Templates[] = { L"", &GUID_NULL, NULL };
int g_cTemplates = sizeof(g_Templates) / sizeof(g_Templates[0]);


// Release any interfaces currently hold, the filter and pin interfaces are
// all global variable so they would be initialised to NULL anyway but we do
// that anyway just in case. If when we come in here they are non NULL then
// we go ahead and release the interface and check the return code NOERROR

HRESULT ReleaseInterfaces()
{
    HRESULT hr = NOERROR;
    HRESULT Overall = NOERROR;
    Log(VERBOSE,TEXT("Releasing interfaces..."));

    // IOverlayNotify interface

    if (pNotify) {
        pNotify->Release();
        pNotify = NULL;
    }

    // IDirectDrawVideo interface

    if (pDirectVideo) {
        pDirectVideo->Release();
        pDirectVideo = NULL;
    }

    // Clock interface

    if (pClock) {
        pClock->Release();
        pClock = NULL;
    }

    // IBaseFilter interfaces

    if (pRenderFilter) {
        pRenderFilter->Release();
        pRenderFilter = NULL;
    }

    if (pSourceFilter) {
        pSourceFilter->Release();
        pSourceFilter = NULL;
    }

    // IMediaFilter interfaces

    if (pRenderMedia) {
        pRenderMedia->Release();
        pRenderMedia = NULL;
    }

    if (pSourceMedia) {
        pSourceMedia->Release();
        pSourceMedia = NULL;
    }

    // IPin interfaces

    if (pOutputPin) {
        pOutputPin->Release();
        pOutputPin = NULL;
    }

    if (pInputPin) {
        pInputPin->Release();
        pInputPin = NULL;
    }

    // Direct video overlay interface

    if (pOverlay) {
        pOverlay->Release();
        pOverlay = NULL;
    }

    // IBasicVideo control interface

    if (pBasicVideo) {
        pBasicVideo->Release();
        pBasicVideo = NULL;
    }

    // IVideoWindow control interface

    if (pVideoWindow) {
        pVideoWindow->Release();
        pVideoWindow = NULL;
    }

    Log(VERBOSE,TEXT("Released interfaces"));
    return Overall;
}


// We should check in all interface calls that pointers passed in are non NULL
// but not that the memory pointer to is valid. We decided checking the memory
// is valid would take too long in a performance critical environent and would
// not necessarily work because a different thread may get in and release the
// memory anyway. The only real solution is to enclose all code within a try
// except loop and catch memory violation exceptions. There may some value in
// doing this but certainly not whenever any base class object methods called

BOOL CheckFilterInterfaces()
{
    IOverlay *pVideoOverlay = NULL;

    EXECUTE_ASSERT(pOutputPin);         // Pin provided by the source object
    EXECUTE_ASSERT(pInputPin);          // Pin to connect with the renderer
    EXECUTE_ASSERT(pDirectVideo);       // Access to DirectDraw video options
    EXECUTE_ASSERT(pRenderFilter);      // The renderer IBaseFilter interface
    EXECUTE_ASSERT(pSourceFilter);      // The source IBaseFilter interface
    EXECUTE_ASSERT(pRenderMedia);       // The renderer IMediaFilter interface
    EXECUTE_ASSERT(pSourceMedia);       // The source IMediaFilter interface
    EXECUTE_ASSERT(pBasicVideo);        // Video renderer control interface
    EXECUTE_ASSERT(pVideoWindow);       // Another control interface
    EXECUTE_ASSERT(pClock);             // Reference clock implementation

    // Check the test source filter output pin

    EXECUTE_ASSERT(pOutputPin->Connect(NULL,NULL) == E_POINTER);
    EXECUTE_ASSERT(pOutputPin->ReceiveConnection(NULL,NULL) == E_POINTER);
    EXECUTE_ASSERT(pOutputPin->ReceiveConnection((IPin *)0x01,NULL) == E_POINTER);
    EXECUTE_ASSERT(pOutputPin->ReceiveConnection(NULL,(AM_MEDIA_TYPE *)0x01) == E_POINTER);
    EXECUTE_ASSERT(pOutputPin->ConnectedTo(NULL) == E_POINTER);
    EXECUTE_ASSERT(pOutputPin->ConnectionMediaType(NULL) == E_POINTER);
    EXECUTE_ASSERT(pOutputPin->QueryPinInfo(NULL) == E_POINTER);
    EXECUTE_ASSERT(pOutputPin->QueryId(NULL) == E_POINTER);
    EXECUTE_ASSERT(pOutputPin->QueryAccept(NULL) == E_POINTER);
    EXECUTE_ASSERT(pOutputPin->EnumMediaTypes(NULL) == E_POINTER);
    EXECUTE_ASSERT(pOutputPin->QueryInterface(IID_IUnknown,NULL) == E_POINTER);

    // Check the video renderer filter input pin

    EXECUTE_ASSERT(pInputPin->Connect(NULL,NULL) == E_POINTER);
    EXECUTE_ASSERT(pInputPin->ReceiveConnection(NULL,NULL) == E_POINTER);
    EXECUTE_ASSERT(pInputPin->ReceiveConnection((IPin *)0x01,NULL) == E_POINTER);
    EXECUTE_ASSERT(pInputPin->ReceiveConnection(NULL,(AM_MEDIA_TYPE *)0x01) == E_POINTER);
    EXECUTE_ASSERT(pInputPin->ConnectedTo(NULL) == E_POINTER);
    EXECUTE_ASSERT(pInputPin->ConnectionMediaType(NULL) == E_POINTER);
    EXECUTE_ASSERT(pInputPin->QueryPinInfo(NULL) == E_POINTER);
    EXECUTE_ASSERT(pInputPin->QueryId(NULL) == E_POINTER);
    EXECUTE_ASSERT(pInputPin->QueryAccept(NULL) == E_POINTER);
    EXECUTE_ASSERT(pInputPin->EnumMediaTypes(NULL) == E_POINTER);
    EXECUTE_ASSERT(pInputPin->QueryInterface(IID_IUnknown,NULL) == E_POINTER);

    // Next check the IDirectDraw video interface

    EXECUTE_ASSERT(pDirectVideo->GetSwitches(NULL) == E_POINTER);
    EXECUTE_ASSERT(pDirectVideo->GetCaps(NULL) == E_POINTER);
    EXECUTE_ASSERT(pDirectVideo->GetEmulatedCaps(NULL) == E_POINTER);
    EXECUTE_ASSERT(pDirectVideo->GetSurfaceDesc(NULL) == E_POINTER);
    EXECUTE_ASSERT(pDirectVideo->GetFourCCCodes(NULL,NULL) == E_POINTER);
    EXECUTE_ASSERT(pDirectVideo->GetDirectDraw(NULL) == E_POINTER);
    EXECUTE_ASSERT(pDirectVideo->GetSurfaceType(NULL) == E_POINTER);
    EXECUTE_ASSERT(pDirectVideo->QueryInterface(IID_IUnknown,NULL) == E_POINTER);

    // Try the source filter and renderer filter interfaces

    EXECUTE_ASSERT(pSourceFilter->EnumPins(NULL) == E_POINTER);
    EXECUTE_ASSERT(pSourceFilter->FindPin(NULL,NULL) == E_POINTER);
    EXECUTE_ASSERT(pSourceFilter->QueryFilterInfo(NULL) == E_POINTER);
    EXECUTE_ASSERT(pSourceFilter->JoinFilterGraph(NULL,NULL) == NOERROR);
    EXECUTE_ASSERT(pSourceMedia->GetState(0,NULL) == E_POINTER);
    EXECUTE_ASSERT(pSourceMedia->GetSyncSource(NULL) == E_POINTER);
    EXECUTE_ASSERT(pSourceMedia->QueryInterface(IID_IUnknown,NULL) == E_POINTER);
    EXECUTE_ASSERT(pRenderFilter->EnumPins(NULL) == E_POINTER);
    EXECUTE_ASSERT(pRenderFilter->FindPin(NULL,NULL) == E_POINTER);
    EXECUTE_ASSERT(pRenderFilter->QueryFilterInfo(NULL) == E_POINTER);
    EXECUTE_ASSERT(pRenderFilter->JoinFilterGraph(NULL,NULL) == NOERROR);
    EXECUTE_ASSERT(pRenderMedia->GetState(0,NULL) == E_POINTER);
    EXECUTE_ASSERT(pRenderMedia->GetSyncSource(NULL) == E_POINTER);
    EXECUTE_ASSERT(pRenderMedia->QueryInterface(IID_IUnknown,NULL) == E_POINTER);

    // Exercise the IBasicVideo control interface

    EXECUTE_ASSERT(pBasicVideo->get_AvgTimePerFrame(NULL) == E_POINTER);
    EXECUTE_ASSERT(pBasicVideo->get_BitRate(NULL) == E_POINTER);
    EXECUTE_ASSERT(pBasicVideo->get_BitErrorRate(NULL) == E_POINTER);
    EXECUTE_ASSERT(pBasicVideo->get_VideoWidth(NULL) == E_POINTER);
    EXECUTE_ASSERT(pBasicVideo->get_VideoHeight(NULL) == E_POINTER);
    EXECUTE_ASSERT(pBasicVideo->get_SourceLeft(NULL) == E_POINTER);
    EXECUTE_ASSERT(pBasicVideo->get_SourceWidth(NULL) == E_POINTER);
    EXECUTE_ASSERT(pBasicVideo->get_SourceTop(NULL) == E_POINTER);
    EXECUTE_ASSERT(pBasicVideo->get_SourceHeight(NULL) == E_POINTER);
    EXECUTE_ASSERT(pBasicVideo->get_DestinationLeft(NULL) == E_POINTER);
    EXECUTE_ASSERT(pBasicVideo->get_DestinationWidth(NULL) == E_POINTER);
    EXECUTE_ASSERT(pBasicVideo->get_DestinationTop(NULL) == E_POINTER);
    EXECUTE_ASSERT(pBasicVideo->get_DestinationHeight(NULL) == E_POINTER);
    EXECUTE_ASSERT(pBasicVideo->GetSourcePosition(NULL,(long *)1,(long *)1,(long *)1) == E_POINTER);
    EXECUTE_ASSERT(pBasicVideo->GetSourcePosition((long *)1,NULL,(long *)1,(long *)1) == E_POINTER);
    EXECUTE_ASSERT(pBasicVideo->GetSourcePosition((long *)1,(long *)1,NULL,(long *)1) == E_POINTER);
    EXECUTE_ASSERT(pBasicVideo->GetSourcePosition((long *)1,(long *)1,(long *)1,NULL) == E_POINTER);
    EXECUTE_ASSERT(pBasicVideo->GetDestinationPosition(NULL,(long *)1,(long *)1,(long *)1) == E_POINTER);
    EXECUTE_ASSERT(pBasicVideo->GetDestinationPosition((long *)1,NULL,(long *)1,(long *)1) == E_POINTER);
    EXECUTE_ASSERT(pBasicVideo->GetDestinationPosition((long *)1,(long *)1,NULL,(long *)1) == E_POINTER);
    EXECUTE_ASSERT(pBasicVideo->GetDestinationPosition((long *)1,(long *)1,(long *)1,NULL) == E_POINTER);
    EXECUTE_ASSERT(pBasicVideo->GetVideoPaletteEntries(0,0,NULL,NULL) == E_POINTER);
    EXECUTE_ASSERT(pBasicVideo->GetCurrentImage(NULL,NULL) == E_POINTER);
    EXECUTE_ASSERT(pBasicVideo->QueryInterface(IID_IUnknown,NULL) == E_POINTER);

    // Exercise the IVideoWindow control interface

    EXECUTE_ASSERT(pVideoWindow->get_Caption(NULL) == E_POINTER);
    EXECUTE_ASSERT(pVideoWindow->get_WindowStyle(NULL) == E_POINTER);
    EXECUTE_ASSERT(pVideoWindow->get_WindowStyleEx(NULL) == E_POINTER);
    EXECUTE_ASSERT(pVideoWindow->get_AutoShow(NULL) == E_POINTER);
    EXECUTE_ASSERT(pVideoWindow->get_WindowState(NULL) == E_POINTER);
    EXECUTE_ASSERT(pVideoWindow->get_BackgroundPalette(NULL) == E_POINTER);
    EXECUTE_ASSERT(pVideoWindow->get_Visible(NULL) == E_POINTER);
    EXECUTE_ASSERT(pVideoWindow->get_Left(NULL) == E_POINTER);
    EXECUTE_ASSERT(pVideoWindow->get_Width(NULL) == E_POINTER);
    EXECUTE_ASSERT(pVideoWindow->get_Top(NULL) == E_POINTER);
    EXECUTE_ASSERT(pVideoWindow->get_Height(NULL) == E_POINTER);
    EXECUTE_ASSERT(pVideoWindow->get_Owner(NULL) == E_POINTER);
    EXECUTE_ASSERT(pVideoWindow->get_MessageDrain(NULL) == E_POINTER);
    EXECUTE_ASSERT(pVideoWindow->get_BorderColor(NULL) == E_POINTER);
    EXECUTE_ASSERT(pVideoWindow->GetWindowPosition(NULL,(long *)1,(long *)1,(long *)1) == E_POINTER);
    EXECUTE_ASSERT(pVideoWindow->GetWindowPosition((long *)1,NULL,(long *)1,(long *)1) == E_POINTER);
    EXECUTE_ASSERT(pVideoWindow->GetWindowPosition((long *)1,(long *)1,NULL,(long *)1) == E_POINTER);
    EXECUTE_ASSERT(pVideoWindow->GetWindowPosition((long *)1,(long *)1,(long *)1,NULL) == E_POINTER);
    EXECUTE_ASSERT(pVideoWindow->GetMinIdealImageSize(NULL,NULL) == E_POINTER);
    EXECUTE_ASSERT(pVideoWindow->GetMinIdealImageSize(NULL,(long *)1) == E_POINTER);
    EXECUTE_ASSERT(pVideoWindow->GetMinIdealImageSize((long *)1,NULL) == E_POINTER);
    EXECUTE_ASSERT(pVideoWindow->GetMaxIdealImageSize(NULL,NULL) == E_POINTER);
    EXECUTE_ASSERT(pVideoWindow->GetMaxIdealImageSize(NULL,(long *)1) == E_POINTER);
    EXECUTE_ASSERT(pVideoWindow->GetMaxIdealImageSize((long *)1,NULL) == E_POINTER);
    EXECUTE_ASSERT(pVideoWindow->QueryInterface(IID_IUnknown,NULL) == E_POINTER);
    EXECUTE_ASSERT(pVideoWindow->GetRestorePosition(NULL,(long *)1,(long *)1,(long *)1) == E_POINTER);
    EXECUTE_ASSERT(pVideoWindow->GetRestorePosition((long *)1,NULL,(long *)1,(long *)1) == E_POINTER);
    EXECUTE_ASSERT(pVideoWindow->GetRestorePosition((long *)1,(long *)1,NULL,(long *)1) == E_POINTER);
    EXECUTE_ASSERT(pVideoWindow->GetRestorePosition((long *)1,(long *)1,(long *)1,NULL) == E_POINTER);
    EXECUTE_ASSERT(pVideoWindow->HideCursor(1) == VFW_E_NOT_CONNECTED);
    EXECUTE_ASSERT(pVideoWindow->IsCursorHidden(NULL) == E_POINTER);
    EXECUTE_ASSERT(pVideoWindow->IsCursorHidden((long*)1) == VFW_E_NOT_CONNECTED);

    // Ask the renderer input pin for its IOverlay transport

    pInputPin->QueryInterface(IID_IOverlay,(VOID **)&pVideoOverlay);
    if (pVideoOverlay == NULL) {
        return FALSE;
    }

    // Check the interface responds correctly to bad parameters

    EXECUTE_ASSERT(pVideoOverlay->GetPalette(NULL,NULL) == E_POINTER);
    EXECUTE_ASSERT(pVideoOverlay->GetDefaultColorKey(NULL) == E_POINTER);
    EXECUTE_ASSERT(pVideoOverlay->GetColorKey(NULL) == E_POINTER);
    EXECUTE_ASSERT(pVideoOverlay->SetColorKey(NULL) == E_POINTER);
    EXECUTE_ASSERT(pVideoOverlay->GetClipList(NULL,NULL,NULL) == E_POINTER);
    EXECUTE_ASSERT(pVideoOverlay->GetClipList((RECT *)1,(RECT *)1,NULL) == E_POINTER);
    EXECUTE_ASSERT(pVideoOverlay->GetClipList(NULL,(RECT *)1,(LPRGNDATA *)1) == E_POINTER);
    EXECUTE_ASSERT(pVideoOverlay->GetClipList((RECT *)1,NULL,(LPRGNDATA *)1) == E_POINTER);
    EXECUTE_ASSERT(pVideoOverlay->GetVideoPosition(NULL,NULL) == E_POINTER);
    EXECUTE_ASSERT(pVideoOverlay->GetVideoPosition((RECT *)1,NULL) == E_POINTER);
    EXECUTE_ASSERT(pVideoOverlay->GetVideoPosition(NULL,(RECT *)1) == E_POINTER);
    EXECUTE_ASSERT(pVideoOverlay->Advise(NULL,ADVISE_ALL) == E_POINTER);
    EXECUTE_ASSERT(pVideoOverlay->QueryInterface(IID_IUnknown,NULL) == E_POINTER);

    // The information returning methods should be accessible

    EXECUTE_ASSERT(SUCCEEDED(GetDefaultColourKey(pVideoOverlay)));
    EXECUTE_ASSERT(SUCCEEDED(GetSystemPalette(pVideoOverlay)));
    EXECUTE_ASSERT(SUCCEEDED(GetClippingList(pVideoOverlay)));
    EXECUTE_ASSERT(SUCCEEDED(GetWindowHandle(pVideoOverlay)));
    EXECUTE_ASSERT(SUCCEEDED(GetWindowPosition(pVideoOverlay)));
    EXECUTE_ASSERT(SUCCEEDED(pVideoOverlay->Advise(pNotify,ADVISE_ALL)));
    EXECUTE_ASSERT(SUCCEEDED(pVideoOverlay->Unadvise()));
    EXECUTE_ASSERT(FAILED(SetColourKey(pVideoOverlay,VIDEO_COLOUR)));
    EXECUTE_ASSERT(FAILED(pVideoOverlay->SetPalette(10,TestPalette)));
    EXECUTE_ASSERT(FAILED(pVideoOverlay->SetPalette(0,NULL)));

    pVideoOverlay->Release();
    return TRUE;
}


// This is called to create the test objects, after creating a video renderer
// and the source filter to supply it with images we enumerates the pins that
// are available on each (should be one input and one output pin respectively)
// Then we'll retrieve the IMediaFilter interface so we can start it running

HRESULT CreateStream()
{
    // Check we have not already created the objects

    if (bCreated == TRUE) {
        Log(TERSE,TEXT("Objects already created"));
        return S_FALSE;
    }

    HRESULT hr = CreateObjects();
    if (FAILED(hr)) {
        ReleaseInterfaces();
        return E_FAIL;
    }

    // Enumerate the filters' pins

    EnumeratePins();
    if (FAILED(hr)) {
        ReleaseInterfaces();
        return E_FAIL;
    }

    // Get the filter interfaces

    hr = GetFilterInterfaces();
    if (FAILED(hr)) {
        ReleaseInterfaces();
        return E_FAIL;
    }

    // Get the pin interfaces to work with

    hr = GetPinInterfaces();
    if (FAILED(hr)) {
        ReleaseInterfaces();
        return E_FAIL;
    }

    // Check interface calls with NULL parameters

    CheckFilterInterfaces();
    Log(VERBOSE,TEXT("Stream objects initialised"));
    bCreated = TRUE;
    return NOERROR;
}


// This is called to create the video renderer object (using CoCreateInstance)
// and the source filter object which we define in the CImageSource class. We
// also use CoCreateInstance to instantiate a generic reference system clock

HRESULT CreateObjects()
{
    HRESULT hr = NOERROR;

    // Create an IOverlayNotify interface class

    pOverlayNotify = new COverlayNotify(NULL,&hr);
    if (pOverlayNotify == NULL) {
        return E_OUTOFMEMORY;
    }

    // Query interface for IOverlayNotify

    hr = pOverlayNotify->QueryInterface(IID_IOverlayNotify,(void **)&pNotify);
    if (FAILED(hr)) {
        Log(TERSE,TEXT("Couldn't get an IOverlayNotify interface"));
        return hr;
    }

    ASSERT(pNotify);
    Log(VERBOSE,TEXT("Created an IOverlayNotify interface"));

    // Create a reference clock

    hr = CoCreateInstance(CLSID_SystemClock,        // Clock object
                          NULL,                     // Outer unknown
                          CLSCTX_INPROC,            // Inproc server
                          IID_IReferenceClock,      // Interface required
                          (void **) &pClock );      // Where to put result

    if (FAILED(hr)) {
        Log(TERSE,TEXT("Couldn't create a clock"));
        return hr;
    }

    ASSERT(pClock);
    Log(VERBOSE,TEXT("Created a reference clock"));

    // Create an image render object

    hr = CoCreateInstance(CLSID_VideoRenderer,        // Image renderer object
                          NULL,                       // Outer unknown
                          CLSCTX_INPROC,              // Inproc server
                          IID_IBaseFilter,            // Interface required
                          (void **) &pRenderFilter ); // Where to put result

    if (FAILED(hr)) {
        Log(TERSE,TEXT("Couldn't create an image renderer"));
        return hr;
    }

    ASSERT(pRenderFilter);
    Log(VERBOSE,TEXT("Created an image renderer"));

    // Now create a shell object

    pImageSource = new CImageSource(NULL,&hr);
    if (pImageSource == NULL) {
        return E_OUTOFMEMORY;
    }

    ASSERT(pImageSource);
    hr = pImageSource->NonDelegatingQueryInterface(IID_IBaseFilter,(void **) &pSourceFilter);

    if (FAILED(hr)) {
        Log(TERSE,TEXT("Couldn't create a source object"));
        return E_FAIL;
    }

    Log(VERBOSE,TEXT("Created objects successfully"));
    return NOERROR;
}


// This is the control point for releasing the filter stream objects. We must
// make sure we disconnect any objects before releasing them (it is an error
// not to) so all we do is call the ReleaseInterfaces to delete the objects

HRESULT ReleaseStream()
{
    // Check there is a valid stream

    if (bCreated == FALSE) {
        Log(TERSE,TEXT("Objects not yet created"));
        return S_FALSE;
    }

    // Disconnect before releasing

    if (bConnected == TRUE) {
        HRESULT hr = DisconnectStream();
        if (FAILED(hr)) {
            return hr;
        }
    }

    // Release the interfaces

    ReleaseInterfaces();
    bCreated = FALSE;
    return NOERROR;
}


// This is the control point for connecting the filters up, we pretend we're
// a filter graph and call Connect on our output pin supplied by the source
// image class. The base class looks after enumerating the available formats
// and finding a suitable match with the renderer. We supply a large number
// of media formats most of which are set to have invalid fields in them. We
// know that the video renderer only grabs DirectDraw when it's connected so
// before doing so we initialise it with the type of surfaces it can use and
// also any DirectDraw driver we opened. Setting the driver gets around the
// problem only one DirectDraw driver object can be instantiated per process

HRESULT ConnectStream()
{
    // Check the stream is valid

    if (bCreated == FALSE) {
        Log(TERSE,TEXT("Objects not yet created"));
        return S_FALSE;
    }

    Log(VERBOSE,TEXT("Connecting filters..."));

    // Map the surface menu type into a IDirectDrawVideo switch

    DWORD dwSwitchesSet, dwSwitches = AMDDS_NONE;
    switch (uiCurrentSurfaceItem) {
        case IDM_DCIPS:     dwSwitches = AMDDS_DCIPS;     break;
        case IDM_PS:        dwSwitches = AMDDS_PS;        break;
        case IDM_RGBOVR:    dwSwitches = AMDDS_RGBOVR;    break;
        case IDM_YUVOVR:    dwSwitches = AMDDS_YUVOVR;    break;
        case IDM_RGBOFF:    dwSwitches = AMDDS_RGBOFF;    break;
        case IDM_YUVOFF:    dwSwitches = AMDDS_YUVOFF;    break;
        case IDM_RGBFLP:    dwSwitches = AMDDS_RGBFLP;    break;
        case IDM_YUVFLP:    dwSwitches = AMDDS_YUVFLP;    break;
    }

    // Set the type of DirectDraw surface it should use

    EXECUTE_ASSERT(SUCCEEDED(pDirectVideo->SetSwitches(dwSwitches)));
    EXECUTE_ASSERT(SUCCEEDED(pDirectVideo->GetSwitches(&dwSwitchesSet)));
    EXECUTE_ASSERT(dwSwitchesSet == dwSwitches);

    // Set the IDirectDraw interface for the renderer to use

    LPDIRECTDRAW pOutsideDirectDraw = NULL;
    EXECUTE_ASSERT(SUCCEEDED(pDirectVideo->SetDirectDraw(pDirectDraw)));
    EXECUTE_ASSERT(SUCCEEDED(pDirectVideo->GetDirectDraw(&pOutsideDirectDraw)));
    EXECUTE_ASSERT(pOutsideDirectDraw == pDirectDraw || pDirectDraw == NULL);

    // Must release any interface we get back

    if (pOutsideDirectDraw) {
        pOutsideDirectDraw->Release();
        pOutsideDirectDraw = NULL;
    }

    // Try and connect the video input pin and the output source pin

    ASSERT(pOutputPin);
    ASSERT(pInputPin);

    HRESULT hr = pOutputPin->Connect(pInputPin,NULL);
    if (FAILED(hr)) {
        Log(TERSE,TEXT("Could not connect pins"));
        return E_FAIL;
    }

    Log(VERBOSE,TEXT("Connected filters"));
    bConnected = TRUE;
    return NOERROR;
}


// This complements the previous function to disconnect the filters. We must
// make sure that we are not running before disconnnecting (it is an error to
// do so otherwise) then like before we pretend to be the filter graph and
// call Disconnect on the source filter output pin, we must also do the same
// on the input pin (in this sense it is slightly different to connection)

HRESULT DisconnectStream()
{
    // Check the stream is valid

    if (bCreated == FALSE) {
        Log(TERSE,TEXT("Objects not yet created"));
        return S_FALSE;
    }

    Log(VERBOSE,TEXT("Disconnecting filters..."));

    // Disconnect the output source pin

    HRESULT hr = pOutputPin->Disconnect();
    if (FAILED(hr)) {
        Log(TERSE,TEXT("Could not disconnect source pin"));
        return E_FAIL;
    }

    // Tell the input pin to disconnect

    hr = pInputPin->Disconnect();
    if (FAILED(hr)) {
        Log(TERSE,TEXT("Could not disconnect video pin"));
        return E_FAIL;
    }

    // Reset the IDirectDraw interface we supplied it with

    EXECUTE_ASSERT(SUCCEEDED(pDirectVideo->SetDirectDraw(NULL)));
    Log(VERBOSE,TEXT("Disconnected filters"));
    bConnected = FALSE;
    return NOERROR;
}


// Once we have an IBaseFilter interface we can enumerate all the input pins
// available from it. For the source filter there should be one and only one
// output pin, and likewise for the video renderer there should be a single
// input pin. The pins can be enumerated through an IEnumPins interface

HRESULT EnumFilterPins(PFILTER pFilter)
{
    HRESULT hr;             // Return code
    PENUMPINS pEnumPins;    // Pin enumerator
    PPIN pPin = NULL;       // Holds next pin obtained
    LONG lPins = 0;         // Number of pins retrieved
    ULONG ulFetched;        // Number retrieved on each call
    PIN_INFO pi;            // Information about each pin

    // Get an IEnumPins interface

    hr = pFilter->EnumPins(&pEnumPins);
    if (FAILED(hr)) {
        Log(TERSE,TEXT("Couldn't get IEnumPins interface"));
        return E_FAIL;
    }

    Log(VERBOSE,TEXT("Got the IEnumPins interface"));
    while (TRUE) {

        // Get the next pin interface

        pEnumPins->Next(1,&pPin,&ulFetched);
        if (ulFetched != 1) {
            hr = NOERROR;
            break;
        }

        ASSERT(pPin);
        lPins++;

        // Display the pin information

        hr = pPin->QueryPinInfo(&pi);
        if (FAILED(hr)) {
            Log(TERSE,TEXT("QueryPinInfo failed"));
            break;
        }
        QueryPinInfoReleaseFilter(pi);

        // Display the pin information

        wsprintf(szInfo,TEXT("%3d %20s (%s)"),lPins,pi.achName,
                 (pi.dir == PINDIR_INPUT ? TEXT("Input") : TEXT("Output")));

        Log(VERBOSE,szInfo);
        pPin->Release();
    }
    pEnumPins->Release();
    return hr;
}


// After we have created the video renderer and the source filter we scan the
// available pin objects to see that they are the correct type (such as their
// direction and number). This function does these two functions together

HRESULT EnumeratePins()
{
    Log(VERBOSE,TEXT("Enumerating RENDERER pins..."));

    HRESULT hr = EnumFilterPins(pRenderFilter);
    if (FAILED(hr)) {
        return hr;
    }

    Log(VERBOSE,TEXT("Enumerating SOURCE pins..."));

    hr = EnumFilterPins(pSourceFilter);
    if (FAILED(hr)) {
        return hr;
    }
    return NOERROR;
}


// This function retrieves the IMediaFilter interface for each filter. We need
// this interface so that we can start them running and inform them of which
// clock to synchronise with (although the source ignores this information)
// We also get the video renderer control interfaces which can be used to get
// and set various video and window related properties such as it's position

HRESULT GetFilterInterfaces()
{
    Log(VERBOSE,TEXT("Obtaining IMediaFilter interface"));

    // Get the image IMediaFilter interface

    HRESULT hr = pRenderFilter->QueryInterface(IID_IMediaFilter,(void **) &pRenderMedia);
    if (FAILED(hr)) {
        Log(TERSE,TEXT("No Video IMediaFilter"));
        return E_FAIL;
    }

    // Get the image IDirectDrawVideo interface

    hr = pRenderFilter->QueryInterface(IID_IDirectDrawVideo,(void **) &pDirectVideo);
    if (FAILED(hr)) {
        Log(TERSE,TEXT("No Video IDirectDrawVideo"));
        return E_FAIL;
    }

    // Get the source IMediaFilter interface

    hr = pSourceFilter->QueryInterface(IID_IMediaFilter,(void **) &pSourceMedia);
    if (FAILED(hr)) {
        Log(TERSE,TEXT("No source IMediaFilter"));
        return E_FAIL;
    }

    // Get the renderer IVideoWindow interface

    hr = pRenderFilter->QueryInterface(IID_IVideoWindow,(void **) &pVideoWindow);
    if (FAILED(hr)) {
        Log(TERSE,TEXT("No renderer IVideoWindow"));
        return E_FAIL;
    }

    // And finally the IBasicVideo interface

    hr = pRenderFilter->QueryInterface(IID_IBasicVideo,(void **) &pBasicVideo);
    if (FAILED(hr)) {
        Log(TERSE,TEXT("No renderer IBasicVideo"));
        return E_FAIL;
    }

    Log(VERBOSE,TEXT("Obtained filter interfaces"));
    return NOERROR;
}


// This function retrieves the pin interfaces needed to make the connections
// between the filters so that the show can begin. We have already check that
// the video renderer provides a single input pin and that the source filter
// has one output pin so we can simply use our helper function to get them

HRESULT GetPinInterfaces()
{
    Log(VERBOSE,TEXT("Obtaining IPin interfaces"));

    // Get the pin interfaces

    pOutputPin = GetPin(pSourceFilter,0);
    if (pOutputPin == NULL) {
        return E_FAIL;
    }

    pInputPin = GetPin(pRenderFilter,0);
    if (pInputPin == NULL) {
        return E_FAIL;
    }

    Log(VERBOSE,TEXT("Obtained IPin interfaces"));
    return NOERROR;
}


// Given an IBaseFilter interface and pin enumerator index this returns the
// IPin interface that corresponds to it. It is used by the code that wants
// to connect and enumerate pin information on the test objects. If the pin
// required is not the first one available then we reset and skip to it

IPin *GetPin(IBaseFilter *pFilter, ULONG lPin)
{
    HRESULT hr;             // Return code
    PENUMPINS pEnumPins;    // Pin enumerator
    PPIN pPin;              // Holds next pin obtained
    ULONG ulFetched;        // Number retrieved on each call

    // First of all get the pin enumerator

    hr = pFilter->EnumPins(&pEnumPins);
    if (FAILED(hr)) {
        Log(TERSE,TEXT("Couldn't get IEnumPins interface"));
        return NULL;
    }

    // Skip to the relevant pin

    pEnumPins->Reset();
    hr = pEnumPins->Skip(lPin);
    if (S_OK != hr) {
        Log(TERSE,TEXT("Couldn't SKIP to pin"));
        pEnumPins->Release();
        return NULL;
    }

    // Get the next pin interface

    hr = pEnumPins->Next(1,&pPin,&ulFetched);
    if (FAILED(hr) || ulFetched != 1) {
        Log(TERSE,TEXT("Couldn't NEXT pin"));
        pEnumPins->Release();
        return NULL;
    }

    // Release the enumerator and return the pin

    pEnumPins->Release();
    return pPin;
}


// This sets the system into a paused state which is slightly confused by the
// reference time (for more information see the specifications). When we go
// from running to paused we store the current time. At some later we may go
// back into a running state but the time we pass to run is the same run time
// plus the amount of time we have been in a paused state. So for example if
// the renderer is about to draw an image with stream time 1000 and we pause
// for 10 seconds then the next run time will be the same but with 10 seconds
// added to it. This ensures that the next image is drawn at the right time

HRESULT PauseSystem()
{
    HRESULT hr = NOERROR;
    FILTER_STATE State;

    // Check there is a valid connection

    if (bConnected == FALSE) {
        Log(TERSE,TEXT("Objects not yet connected"));
        return S_FALSE;
    }

    Log(VERBOSE,TEXT("Pausing system..."));

    // When we go into a paused state from running we store the current time
    // so that if and when we start running again we will know how long it
    // is we have been paused which lets us adjust the run time we provide

    if (gtBase && gtPausedAt == 0) {
        hr = pClock->GetTime((REFERENCE_TIME *)&gtPausedAt);
        if (FAILED(hr)) {
            Log(TERSE,TEXT("Couldn't get current time"));
            return hr;
        }
    }

    hr = pRenderMedia->Pause();
    if (FAILED(hr)) {
        Log(TERSE,TEXT("Couldn't pause video"));
        return E_FAIL;
    }

    // Check the state is as we expect

    hr = pRenderMedia->GetState((DWORD)0,&State);
    if (uiCurrentConnectionItem == IDM_OVERLAY) {
        EXECUTE_ASSERT(hr == S_OK);
        EXECUTE_ASSERT(State == State_Paused);
    }

    // Pause the source filter

    hr = pSourceMedia->Pause();
    if (FAILED(hr)) {
        Log(TERSE,TEXT("Couldn't pause source"));
        return E_FAIL;
    }

    Log(VERBOSE,TEXT("Paused system"));
    return NOERROR;
}


// This is called to stop the filters running, we call their IMediaFilter Stop
// functions starting with the video renderer (downstream filters first) and
// also reset the current base time and paused at times so we know if and when
// we start running again in the future that we are not in a paused state

HRESULT StopSystem()
{
    HRESULT hr = NOERROR;
    FILTER_STATE State;

    // Check there is a valid connection

    if (bConnected == FALSE) {
        Log(TERSE,TEXT("Objects not yet connected"));
        return S_FALSE;
    }

    Log(VERBOSE,TEXT("Stopping system..."));

    // We no longer have a base time

    gtBase = 0;
    gtPausedAt = 0;

    // Change the state of the filters

    hr = pRenderMedia->Stop();
    if (FAILED(hr)) {
        Log(TERSE,TEXT("Couldn't stop video"));
        return E_FAIL;
    }

    // Stop the source filter from processing

    hr = pSourceMedia->Stop();
    if (FAILED(hr)) {
        Log(TERSE,TEXT("Couldn't stop source"));
        return E_FAIL;
    }

    // Check the state is as we expect

    hr = pRenderMedia->GetState((DWORD)0,&State);
    EXECUTE_ASSERT(SUCCEEDED(hr));
    if (uiCurrentConnectionItem == IDM_OVERLAY) {
        EXECUTE_ASSERT(hr == S_OK);
        EXECUTE_ASSERT(State == State_Stopped);
    }

    StopWorkerThread();
    Log(VERBOSE,TEXT("Stopped system"));
    bRunning = FALSE;
    ResetDDCount();
    return NOERROR;
}


// This sets the filters running - we start at the renderer end on the right
// so that as soon as we get to the source test filter everything is ready
// and primed to go. We initialise the filters when running with a run time
// (gtBase) which if we are currently stopped will be the current reference
// clock time, if we have been paused for a while then it takes the amount
// of time we have been so into account to allow for different stream times
// in the media samples (after pausing they will not necessarily be zero)

HRESULT StartSystem(BOOL bUseClock)
{
    HRESULT hr = NOERROR;
    FILTER_STATE State;

    // Check there is a valid connection

    if (bConnected == FALSE) {
        Log(TERSE,TEXT("Objects not yet connected"));
        return S_FALSE;
    }

    // Set the reference clock source

    if (bUseClock) {
        pRenderMedia->SetSyncSource(pClock);
    }

    Log(VERBOSE,TEXT("Starting system running..."));
    SetStartTime();

    hr = pRenderMedia->Run(gtBase);
    if (FAILED(hr)) {
        Log(TERSE,TEXT("Couldn't start video running"));
        return E_FAIL;
    }

    // Start the source filter running

    hr = pSourceMedia->Run(gtBase);
    if (FAILED(hr)) {
        Log(TERSE,TEXT("Couldn't start source running"));
        return E_FAIL;
    }

    // Check the state is as we expect

    hr = pRenderMedia->GetState((DWORD)0,&State);
    EXECUTE_ASSERT(SUCCEEDED(hr));
    if (uiCurrentConnectionItem == IDM_OVERLAY) {
        EXECUTE_ASSERT(hr == S_OK);
        EXECUTE_ASSERT(State == State_Running);
    }

    StartWorkerThread(uiCurrentConnectionItem);
    Log(VERBOSE,TEXT("Started system running"));
    bRunning = TRUE;
    return NOERROR;
}


// If we start running from stopped then the time at which filters should be
// starting is essentially now, although we actually give them the time plus
// a little bit to allow for start up latency. If we have been paused then
// we calculate how long we have been paused for, then we take that off the
// current time and hand that to the filters as the time when they run from

HRESULT SetStartTime()
{
    HRESULT hr = NOERROR;
    REFERENCE_TIME CurrentTime;

    // Are we restarting from paused?

    if (gtPausedAt) {

        ASSERT(gtBase);
        hr = pClock->GetTime(&CurrentTime);
        ASSERT(SUCCEEDED(hr));

        CurrentTime -= gtPausedAt;
        gtBase += CurrentTime;
        gtPausedAt = 0;
        return NOERROR;
    }

    ASSERT(gtPausedAt == 0);

    // Since the initial stream time will be zero we need to set the run time
    // to now plus a little processing time which is consumed by the filters
    // as they start running, this is arbitrarily set to 10000 100ns units

    hr = pClock->GetTime((REFERENCE_TIME *)&gtBase);
    ASSERT(SUCCEEDED(hr));
    gtBase += (REFERENCE_TIME) 10000;
    return NOERROR;
}


// This stops the worker thread and waits until it completes before exiting
// While we wait we also poll the message queue so that the worker thread
// can send us messages and therefore complete any logging it may be doing

HRESULT StopWorkerThread()
{
    // Only kill the thread if we have one

    if (hThread == NULL) {
        return NOERROR;
    }

    SetEvent(hState);

    // Wait for all the threads to exit

    DWORD Result = WAIT_TIMEOUT;
    while (Result == WAIT_TIMEOUT) {
        YieldAndSleep(TIMEOUT);
        Result = WaitForSingleObject(hThread,TIMEOUT);
    }

    // Close the thread handle and reset the signalling event

    EXECUTE_ASSERT(CloseHandle(hThread));
    EXECUTE_ASSERT(CloseHandle(hState));

    // Reset the variables to NULL so we know where we are

    hThread = NULL;
    hState = NULL;
    return NOERROR;
}


// This creates a worker thread that will either push media samples or tests
// the overlay functionality depending upon the current menu settings. The
// worker thread is signalled to stop and exit by the hState event that we
// create before starting. It is closed after the worker thread terminates

HRESULT StartWorkerThread(UINT ConnectionType)
{
    // Only start a thread if we don't already have one

    if (hThread) {
        return NOERROR;
    }

    // Create an event for signalling

    hState = CreateEvent(NULL,FALSE,FALSE,NULL);
    if (hState == NULL) {
        return E_FAIL;
    }

    LPTHREAD_START_ROUTINE lpProc = (ConnectionType == IDM_SAMPLES ?
                                     SampleLoop : OverlayLoop);

    // Create the worker thread to push samples to the renderer

    hThread = CreateThread(NULL,              // Security attributes
                           (DWORD) 0,         // Initial stack size
                           lpProc,            // Thread start address
                           (LPVOID) hState,   // Thread parameter
                           (DWORD) 0,         // Creation flags
                           &dwThreadID);      // Thread identifier
    if (hThread == NULL) {
        return E_FAIL;
    }
    return NOERROR;
}
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\multimedia\dshow\filters\image\vidtest\imageovr.cpp ===
// Copyright (c) Microsoft Corporation 1994-1996. All Rights Reserved
// Implements the COverlayNotify class, Anthony Phillips, July 1995

#include <streams.h>        // Includes all the IDL and base classes
#include <windows.h>        // Standard Windows SDK header file
#include <windowsx.h>       // Win32 Windows extensions and macros
#include <vidprop.h>        // Shared video properties library
#include <render.h>         // Normal video renderer header file
#include <modex.h>          // Specialised Modex video renderer
#include <convert.h>        // Defines colour space conversions
#include <colour.h>         // Rest of the colour space convertor
#include <imagetst.h>       // All our unit test header files
#include <stdio.h>          // Standard C runtime header file
#include <limits.h>         // Defines standard data type limits
#include <tchar.h>          // Unicode and ANSII portable types
#include <mmsystem.h>       // Multimedia used for timeGetTime
#include <stdlib.h>         // Standard C runtime function library
#include <tstshell.h>       // Definitions of constants eg TST_FAIL

// This class implements the IOverlayNotify interface, we register this with
// the video renderer when we start the overlay tests. It will be called by
// the video renderer asynchronously when something interesting happens like
// the palette, clipping or colour key changes. If we are the cause of the
// colour key change them we still get told of the key change through this
// interface. All memory passed through this interface must be left alone

// Constructor

COverlayNotify::COverlayNotify(LPUNKNOWN pUnk,HRESULT *phr) :
    CUnknown(NAME("Overlay notification interface"),pUnk,phr)
{
    ASSERT(phr);
}


// Overriden to say what interfaces we support where

STDMETHODIMP
COverlayNotify::NonDelegatingQueryInterface(REFIID riid,void ** ppv)
{
    CheckPointer(ppv,E_POINTER);

    // Do we have this interface

    if (riid == IID_IOverlayNotify) {
        return GetInterface((IOverlayNotify *) this, ppv);
    } else {
        return CUnknown::NonDelegatingQueryInterface(riid, ppv);
    }
}


// This is called with the colour key when it changes. What happens when we
// ask for a colour key through IOverlay is that the renderer selects one of
// the possible colours we pass in and notifies us of which one it is using
// It stores the original requirements so that should the display be changed
// through the control panel it can recalculate a suitable key and update
// all the notification interfaces (not currently implemented though)

STDMETHODIMP COverlayNotify::OnColorKeyChange(const COLORKEY *pColorKey)
{
    NOTE("Colour key callback");
    DisplayColourKey(pColorKey);
    return NOERROR;
}


// Called when the window is primed on us or changed

STDMETHODIMP COverlayNotify::OnWindowChange(HWND hwnd)
{
    NOTE("Window change callback");
    return NOERROR;
}


// This provides synchronous window clip changes so that the client is called
// before the window is moved to freeze the video, and then when the window
// (and display) has stabilised it is called again to start playback again.
// If the window rectangle is all zero then the window has been hidden. NOTE
// The filter must take a copy of the information if it wants to maintain it

STDMETHODIMP COverlayNotify::OnClipChange(
    const RECT *pSourceRect,            // Area of video to play with
    const RECT *pDestinationRect,       // Area video goes
    const RGNDATA *pRgnData)            // Header describing clipping
{
    NOTE("Clipping information callback");
    DisplayClippingInformation(pSourceRect,
    						   pDestinationRect,
                               pRgnData);
    return NOERROR;
}


// This notifies the filter of palette changes, the filter should copy the
// array of RGBQUADs if it needs to use them after returning. If we set a
// palette through the IOverlay interface then we should see one of these

STDMETHODIMP COverlayNotify::OnPaletteChange(
    DWORD dwColors,                     // Number of colours present
    const PALETTEENTRY *pPalette)       // Array of palette colours
{
    NOTE("Palette information callback");
    DisplaySystemPalette(dwColors,pPalette);
    return NOERROR;
}


// The calls to OnClipChange happen in sync with the window. So it's called
// with an empty clip list before the window moves to freeze the video, and
// then when the window has stabilised it is called again with the new clip
// list. The OnPositionChange callback is for overlay cards that don't want
// the expense of synchronous clipping updates and just want to know when
// the source or destination video positions change. They will NOT be called
// in sync with the window but at some point after the window has changed
// (basicly in time with WM_SIZE etc messages received). This is therefore
// suitable for overlay cards that don't inlay their data to the framebuffer

STDMETHODIMP COverlayNotify::OnPositionChange(
    const RECT *pSourceRect,            // Area of video to play with
    const RECT *pDestinationRect)       // Area video goes
{
    NOTE("Position information callback");
    DisplayClippingInformation(pSourceRect,
                               pDestinationRect,
                               (LPRGNDATA) NULL);
    return NOERROR;
}
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\multimedia\dshow\filters\image\vidtest\imageovr.h ===
// Copyright (c) Microsoft Corporation 1994-1996. All Rights Reserved
// Implements the COverlayNotify class, Anthony Phillips, July 1995

#ifndef __IMAGEOVR__
#define __IMAGEOVR__

// The renderer supports a specialised transport called IOverlay for use by
// inlay and overlay cards that decompress or write their images direct to
// the frame buffer or display. The notification mechanism for asynchronous
// messages between the renderer and the source filter is with an interface
// called IOverlayNotify, this class implements the interface to provide a
// detailed level of logging, such as on palette and colour key changes

class COverlayNotify : public IOverlayNotify, public CUnknown
{

public:

    // Override this to say what interfaces we support where
    STDMETHODIMP NonDelegatingQueryInterface(REFIID riid, void ** ppv);
    COverlayNotify(LPUNKNOWN, HRESULT *);

    // Provides the standard IUnknown interface
    DECLARE_IUNKNOWN

    // IOverlayNotify methods

    STDMETHODIMP OnColorKeyChange(const COLORKEY *pColorKey);
    STDMETHODIMP OnWindowChange(HWND hwnd);

    // If the window rectangle is all zero then the window is invisible, the
    // filter must take a copy of the information if it wants to keep it. As
    // for the palette we don't copy the data as all we do is to log them

    STDMETHODIMP OnClipChange(
        const RECT *pSourceRect,            // Area of video to play with
        const RECT *pDestinationRect,       // Area video goes
        const RGNDATA *pRgnData);           // Describes clipping data

    // This notifies the filter of palette changes, the filter should copy
    // the array of RGBQUADs if it needs to use them after returning. All
    // we use them for is logging so we don't bother to copy the palette

    STDMETHODIMP OnPaletteChange(
        DWORD dwColors,                     // Number of colours present
        const PALETTEENTRY *pPalette);      // Array of palette colours

    STDMETHODIMP OnPositionChange(
        const RECT *pSourceRect,            // Section of video to play with
        const RECT *pDestinationRect);      // Area on display video appears
};

#endif // __IMAGEOVR__


=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\multimedia\dshow\filters\image\vidtest\imagesys.h ===
// Copyright (c) Microsoft Corporation 1994-1996. All Rights Reserved
// ActiveMovie filtergraph class, Anthony Phillips, March 1996

#ifndef __IMAGESYS__
#define __IMAGESYS__

enum MovieMode { MOVIE_NOTOPENED,
                 MOVIE_OPENED,
                 MOVIE_PLAYING,
                 MOVIE_STOPPED,
                 MOVIE_PAUSED };

#define PLAY_COMMAND_WAIT 1000

// This is a helper class that controls an ActiveMovie filtergraph. We should
// be initialised first of all by calling OpenMovie with a filename. If that
// succeeds then any of the other methods may be called. The object controls
// the current position, fullscreen mode and the state changes of the graph
// We are used by the system filtergraph tests to check video functionality

class CMovie {

public:

    MovieMode m_Mode;           // What mode we are currently in
    HANDLE m_MediaEvent;        // A handle to wait for events on
    BOOL m_bFullScreen;         // Whether we are in fullscreen mode
    IFilterGraph *m_Fg;         // Graph IFilterGraph interface
    IGraphBuilder *m_Gb;        // Used for building filtergraphs
    IMediaControl *m_Mc;        // Controls the filtergraph state
    IMediaPosition *m_Mp;       // Looks after the seeking aspects
    IMediaSeeking *m_Ms;        // Handles media time selections
    IMediaEvent *m_Me;          // Interface on a asynchronous queue
    IBasicVideo *m_Bv;          // Properties for the video stream
    IBasicAudio *m_Ba;          // Properties for the audio stream
    IVideoWindow *m_Vw;         // Used for controlling fullscreen
    IQualProp *m_Qp;            // Obtains quality management data
    IDirectDrawVideo *m_Dv;     // Sets which surfaces may be used

    BOOL GetPerformanceInterfaces();

public:

    CMovie();
    ~CMovie();

    BOOL OpenMovie(TCHAR *lpFileName);
    BOOL CheckGraphInterfaces();
    void CloseMovie();
    BOOL PlayMovie();
    BOOL PauseMovie();
    BOOL StopMovie();
    HANDLE GetMovieEventHandle();
    long GetMovieEventCode();
    BOOL PutMoviePosition(LONG x,LONG y,LONG cx,LONG cy);
    BOOL GetMoviePosition(LONG *x,LONG *y,LONG *cx,LONG *cy);
    BOOL GetMovieWindowState(long *lpuState);
    BOOL SetMovieWindowState(long uState);
    REFTIME GetDuration();
    REFTIME GetCurrentPosition();
    BOOL SeekToPosition(REFTIME rt);
    MovieMode StatusMovie(DWORD Timeout);
    BOOL SetFullScreenMode(BOOL bMode);
    BOOL IsFullScreenMode();
    BOOL SetWindowForeground(long Focus);
};

#endif // __IMAGESYS__
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\multimedia\dshow\filters\image\vidtest\imagesys.cpp ===
// Copyright (c) 1994 - 1998  Microsoft Corporation.  All Rights Reserved.
// ActiveMovie filtergraph class, Anthony Phillips, March 1996

#include <streams.h>        // Includes all the IDL and base classes
#include <windows.h>        // Standard Windows SDK header file
#include <windowsx.h>       // Win32 Windows extensions and macros
#include <vidprop.h>        // Shared video properties library
#include <render.h>         // Normal video renderer header file
#include <modex.h>          // Specialised Modex video renderer
#include <convert.h>        // Defines colour space conversions
#include <colour.h>         // Rest of the colour space convertor
#include <imagetst.h>       // All our unit test header files
#include <stdio.h>          // Standard C runtime header file
#include <limits.h>         // Defines standard data type limits
#include <tchar.h>          // Unicode and ANSII portable types
#include <mmsystem.h>       // Multimedia used for timeGetTime
#include <stdlib.h>         // Standard C runtime function library
#include <tstshell.h>       // Definitions of constants eg TST_FAIL


// Constructor for movie object

CMovie::CMovie() :
    m_MediaEvent(NULL),
    m_Mode(MOVIE_NOTOPENED),
    m_bFullScreen(FALSE),
    m_Qp(NULL),
    m_Dv(NULL),
    m_Fg(NULL),
    m_Gb(NULL),
    m_Mc(NULL),
    m_Mp(NULL),
    m_Me(NULL),
    m_Vw(NULL),
    m_Ms(NULL),
    m_Ba(NULL),
    m_Bv(NULL)
{
}


// Destructor closes down movie

CMovie::~CMovie()
{
    CloseMovie();
}


// Open a movie and initialise our ActiveMovie interfaces

BOOL CMovie::OpenMovie(TCHAR *lpFileName)
{
    WCHAR FileName[MAX_PATH];
    IUnknown *pUnk;
    HRESULT hr;

    swprintf(FileName,L"%hs",lpFileName);

    // Create a new filtergraph manager

    hr = QzCreateFilterObject(CLSID_FilterGraph,
                              NULL,
                              CLSCTX_INPROC,
                              IID_IUnknown,
                              (LPVOID *) &pUnk);
    if (FAILED(hr)) {
        NOTE("No graph manager");
        return FALSE;
    }

    // Query for IFilterGraph

    hr = pUnk->QueryInterface(IID_IFilterGraph,(LPVOID *) &m_Fg);
    if (FAILED(hr)) {
        NOTE("No IFilterGraph");
        pUnk->Release();
        return FALSE;
    }

    // Query for IGraphBuilder

    hr = pUnk->QueryInterface(IID_IGraphBuilder,(LPVOID *) &m_Gb);
    if (FAILED(hr)) {
        NOTE("No IGraphBuilder");
        pUnk->Release();
        CloseMovie();
        return FALSE;
    }

    // Now render the file we were passed

    hr = m_Gb->RenderFile(FileName, NULL);
    if (FAILED(hr)) {
        NOTE("RenderFile failed");
        pUnk->Release();
        CloseMovie();
        return FALSE;
    }

    // Need this to control state changes

    hr = pUnk->QueryInterface(IID_IMediaControl,(LPVOID *) &m_Mc);
    if (FAILED(hr)) {
        NOTE("No IMediaControl");
        pUnk->Release();
        CloseMovie();
        return FALSE;
    }

    hr = pUnk->QueryInterface(IID_IMediaEvent,(LPVOID *) &m_Me);
    if (FAILED(hr)) {
        NOTE("No IMediaEvent");
        pUnk->Release();
        CloseMovie();
        return FALSE;
    }

    GetMovieEventHandle();

    // Need IMediaPosition to control seeking

    hr = pUnk->QueryInterface(IID_IMediaPosition,(LPVOID *) &m_Mp);
    if (FAILED(hr)) {
        NOTE("No IMediaPosition");
        pUnk->Release();
        CloseMovie();
        return FALSE;
    }

    // Need IMediaSeeking for media time seeking

    hr = pUnk->QueryInterface(IID_IMediaSeeking,(LPVOID *) &m_Ms);
    if (FAILED(hr)) {
        NOTE("No IMediaSeeking");
        pUnk->Release();
        CloseMovie();
        return FALSE;
    }

    GetPerformanceInterfaces();

    // Use this to control fullscreen mode

    hr = pUnk->QueryInterface(IID_IVideoWindow,(LPVOID *) &m_Vw);
    if (FAILED(hr)) {
        NOTE("No IVideoWindow");
        pUnk->Release();
        CloseMovie();
        return FALSE;
    }

    // Use this for video properties

    hr = pUnk->QueryInterface(IID_IBasicVideo,(LPVOID *) &m_Bv);
    if (FAILED(hr)) {
        NOTE("No IBasicVideo");
        pUnk->Release();
        CloseMovie();
        return FALSE;
    }

    // Returns audio stream properties

    hr = pUnk->QueryInterface(IID_IBasicAudio,(LPVOID *) &m_Ba);
    if (FAILED(hr)) {
        NOTE("No IBasicAudio");
        pUnk->Release();
        CloseMovie();
        return FALSE;
    }

    // Complete state change

    m_Mode = MOVIE_OPENED;
    pUnk->Release();
    return CheckGraphInterfaces();
}


// Check the filtergraph interfaces after loading

BOOL CMovie::CheckGraphInterfaces()
{
    // Store the count beforehand

    ULONG Count = m_Fg->AddRef();
    IUnknown *pUnknown;
    EXECUTE_ASSERT(Count);
    GUID Format = GUID_NULL;
    LONGLONG RefTime;

    // Check they all reject NULL parameters

    EXECUTE_ASSERT(m_Fg->QueryInterface(IID_IUnknown,NULL) == E_POINTER);
    EXECUTE_ASSERT(m_Gb->QueryInterface(IID_IUnknown,NULL) == E_POINTER);
    EXECUTE_ASSERT(m_Mp->QueryInterface(IID_IUnknown,NULL) == E_POINTER);
    EXECUTE_ASSERT(m_Mc->QueryInterface(IID_IUnknown,NULL) == E_POINTER);
    EXECUTE_ASSERT(m_Me->QueryInterface(IID_IUnknown,NULL) == E_POINTER);
    EXECUTE_ASSERT(m_Vw->QueryInterface(IID_IUnknown,NULL) == E_POINTER);
    EXECUTE_ASSERT(m_Ms->QueryInterface(IID_IUnknown,NULL) == E_POINTER);
    EXECUTE_ASSERT(m_Bv->QueryInterface(IID_IUnknown,NULL) == E_POINTER);
    EXECUTE_ASSERT(m_Ba->QueryInterface(IID_IUnknown,NULL) == E_POINTER);

    EXECUTE_ASSERT(m_Fg->QueryInterface(IID_IUnknown,(VOID **) &pUnknown) == NOERROR);
    EXECUTE_ASSERT(m_Fg->QueryInterface(IID_IFilterGraph,(VOID **) &pUnknown) == NOERROR);
    EXECUTE_ASSERT(m_Fg->QueryInterface(IID_IGraphBuilder,(VOID **) &pUnknown) == NOERROR);
    EXECUTE_ASSERT(m_Fg->QueryInterface(IID_IMediaPosition,(VOID **) &pUnknown) == NOERROR);
    EXECUTE_ASSERT(m_Fg->QueryInterface(IID_IMediaControl,(VOID **) &pUnknown) == NOERROR);
    EXECUTE_ASSERT(m_Fg->QueryInterface(IID_IMediaEvent,(VOID **) &pUnknown) == NOERROR);
    EXECUTE_ASSERT(m_Fg->QueryInterface(IID_IMediaSeeking,(VOID **) &pUnknown) == NOERROR);
    EXECUTE_ASSERT(m_Fg->QueryInterface(IID_IVideoWindow,(VOID **) &pUnknown) == NOERROR);
    EXECUTE_ASSERT(m_Fg->QueryInterface(IID_IBasicVideo,(VOID **) &pUnknown) == NOERROR);
    EXECUTE_ASSERT(m_Fg->QueryInterface(IID_IBasicAudio,(VOID **) &pUnknown) == NOERROR);
    for (int i = 0;i < 10;i++) pUnknown->Release();

    EXECUTE_ASSERT(m_Gb->QueryInterface(IID_IUnknown,(VOID **) &pUnknown) == NOERROR);
    EXECUTE_ASSERT(m_Gb->QueryInterface(IID_IFilterGraph,(VOID **) &pUnknown) == NOERROR);
    EXECUTE_ASSERT(m_Gb->QueryInterface(IID_IGraphBuilder,(VOID **) &pUnknown) == NOERROR);
    EXECUTE_ASSERT(m_Gb->QueryInterface(IID_IMediaPosition,(VOID **) &pUnknown) == NOERROR);
    EXECUTE_ASSERT(m_Gb->QueryInterface(IID_IMediaControl,(VOID **) &pUnknown) == NOERROR);
    EXECUTE_ASSERT(m_Gb->QueryInterface(IID_IMediaEvent,(VOID **) &pUnknown) == NOERROR);
    EXECUTE_ASSERT(m_Gb->QueryInterface(IID_IMediaSeeking,(VOID **) &pUnknown) == NOERROR);
    EXECUTE_ASSERT(m_Gb->QueryInterface(IID_IVideoWindow,(VOID **) &pUnknown) == NOERROR);
    EXECUTE_ASSERT(m_Gb->QueryInterface(IID_IBasicVideo,(VOID **) &pUnknown) == NOERROR);
    EXECUTE_ASSERT(m_Gb->QueryInterface(IID_IBasicAudio,(VOID **) &pUnknown) == NOERROR);
    for (i = 0;i < 10;i++) pUnknown->Release();

    EXECUTE_ASSERT(m_Mp->QueryInterface(IID_IUnknown,(VOID **) &pUnknown) == NOERROR);
    EXECUTE_ASSERT(m_Mp->QueryInterface(IID_IFilterGraph,(VOID **) &pUnknown) == NOERROR);
    EXECUTE_ASSERT(m_Mp->QueryInterface(IID_IGraphBuilder,(VOID **) &pUnknown) == NOERROR);
    EXECUTE_ASSERT(m_Mp->QueryInterface(IID_IMediaPosition,(VOID **) &pUnknown) == NOERROR);
    EXECUTE_ASSERT(m_Mp->QueryInterface(IID_IMediaControl,(VOID **) &pUnknown) == NOERROR);
    EXECUTE_ASSERT(m_Mp->QueryInterface(IID_IMediaEvent,(VOID **) &pUnknown) == NOERROR);
    EXECUTE_ASSERT(m_Mp->QueryInterface(IID_IMediaSeeking,(VOID **) &pUnknown) == NOERROR);
    EXECUTE_ASSERT(m_Mp->QueryInterface(IID_IVideoWindow,(VOID **) &pUnknown) == NOERROR);
    EXECUTE_ASSERT(m_Mp->QueryInterface(IID_IBasicVideo,(VOID **) &pUnknown) == NOERROR);
    EXECUTE_ASSERT(m_Mp->QueryInterface(IID_IBasicAudio,(VOID **) &pUnknown) == NOERROR);
    for (i = 0;i < 10;i++) pUnknown->Release();

    EXECUTE_ASSERT(m_Mc->QueryInterface(IID_IUnknown,(VOID **) &pUnknown) == NOERROR);
    EXECUTE_ASSERT(m_Mc->QueryInterface(IID_IFilterGraph,(VOID **) &pUnknown) == NOERROR);
    EXECUTE_ASSERT(m_Mc->QueryInterface(IID_IGraphBuilder,(VOID **) &pUnknown) == NOERROR);
    EXECUTE_ASSERT(m_Mc->QueryInterface(IID_IMediaPosition,(VOID **) &pUnknown) == NOERROR);
    EXECUTE_ASSERT(m_Mc->QueryInterface(IID_IMediaControl,(VOID **) &pUnknown) == NOERROR);
    EXECUTE_ASSERT(m_Mc->QueryInterface(IID_IMediaEvent,(VOID **) &pUnknown) == NOERROR);
    EXECUTE_ASSERT(m_Mc->QueryInterface(IID_IMediaSeeking,(VOID **) &pUnknown) == NOERROR);
    EXECUTE_ASSERT(m_Mc->QueryInterface(IID_IVideoWindow,(VOID **) &pUnknown) == NOERROR);
    EXECUTE_ASSERT(m_Mc->QueryInterface(IID_IBasicVideo,(VOID **) &pUnknown) == NOERROR);
    EXECUTE_ASSERT(m_Mc->QueryInterface(IID_IBasicAudio,(VOID **) &pUnknown) == NOERROR);
    for (i = 0;i < 10;i++) pUnknown->Release();

    EXECUTE_ASSERT(m_Me->QueryInterface(IID_IUnknown,(VOID **) &pUnknown) == NOERROR);
    EXECUTE_ASSERT(m_Me->QueryInterface(IID_IFilterGraph,(VOID **) &pUnknown) == NOERROR);
    EXECUTE_ASSERT(m_Me->QueryInterface(IID_IGraphBuilder,(VOID **) &pUnknown) == NOERROR);
    EXECUTE_ASSERT(m_Me->QueryInterface(IID_IMediaPosition,(VOID **) &pUnknown) == NOERROR);
    EXECUTE_ASSERT(m_Me->QueryInterface(IID_IMediaControl,(VOID **) &pUnknown) == NOERROR);
    EXECUTE_ASSERT(m_Me->QueryInterface(IID_IMediaEvent,(VOID **) &pUnknown) == NOERROR);
    EXECUTE_ASSERT(m_Me->QueryInterface(IID_IMediaSeeking,(VOID **) &pUnknown) == NOERROR);
    EXECUTE_ASSERT(m_Me->QueryInterface(IID_IVideoWindow,(VOID **) &pUnknown) == NOERROR);
    EXECUTE_ASSERT(m_Me->QueryInterface(IID_IBasicVideo,(VOID **) &pUnknown) == NOERROR);
    EXECUTE_ASSERT(m_Me->QueryInterface(IID_IBasicAudio,(VOID **) &pUnknown) == NOERROR);
    for (i = 0;i < 10;i++) pUnknown->Release();

    EXECUTE_ASSERT(m_Vw->QueryInterface(IID_IUnknown,(VOID **) &pUnknown) == NOERROR);
    EXECUTE_ASSERT(m_Vw->QueryInterface(IID_IFilterGraph,(VOID **) &pUnknown) == NOERROR);
    EXECUTE_ASSERT(m_Vw->QueryInterface(IID_IGraphBuilder,(VOID **) &pUnknown) == NOERROR);
    EXECUTE_ASSERT(m_Vw->QueryInterface(IID_IMediaPosition,(VOID **) &pUnknown) == NOERROR);
    EXECUTE_ASSERT(m_Vw->QueryInterface(IID_IMediaControl,(VOID **) &pUnknown) == NOERROR);
    EXECUTE_ASSERT(m_Vw->QueryInterface(IID_IMediaEvent,(VOID **) &pUnknown) == NOERROR);
    EXECUTE_ASSERT(m_Vw->QueryInterface(IID_IMediaSeeking,(VOID **) &pUnknown) == NOERROR);
    EXECUTE_ASSERT(m_Vw->QueryInterface(IID_IVideoWindow,(VOID **) &pUnknown) == NOERROR);
    EXECUTE_ASSERT(m_Vw->QueryInterface(IID_IBasicVideo,(VOID **) &pUnknown) == NOERROR);
    EXECUTE_ASSERT(m_Vw->QueryInterface(IID_IBasicAudio,(VOID **) &pUnknown) == NOERROR);
    for (i = 0;i < 10;i++) pUnknown->Release();

    EXECUTE_ASSERT(m_Bv->QueryInterface(IID_IUnknown,(VOID **) &pUnknown) == NOERROR);
    EXECUTE_ASSERT(m_Bv->QueryInterface(IID_IFilterGraph,(VOID **) &pUnknown) == NOERROR);
    EXECUTE_ASSERT(m_Bv->QueryInterface(IID_IGraphBuilder,(VOID **) &pUnknown) == NOERROR);
    EXECUTE_ASSERT(m_Bv->QueryInterface(IID_IMediaPosition,(VOID **) &pUnknown) == NOERROR);
    EXECUTE_ASSERT(m_Bv->QueryInterface(IID_IMediaControl,(VOID **) &pUnknown) == NOERROR);
    EXECUTE_ASSERT(m_Bv->QueryInterface(IID_IMediaEvent,(VOID **) &pUnknown) == NOERROR);
    EXECUTE_ASSERT(m_Bv->QueryInterface(IID_IMediaSeeking,(VOID **) &pUnknown) == NOERROR);
    EXECUTE_ASSERT(m_Bv->QueryInterface(IID_IVideoWindow,(VOID **) &pUnknown) == NOERROR);
    EXECUTE_ASSERT(m_Bv->QueryInterface(IID_IBasicVideo,(VOID **) &pUnknown) == NOERROR);
    EXECUTE_ASSERT(m_Bv->QueryInterface(IID_IBasicAudio,(VOID **) &pUnknown) == NOERROR);
    for (i = 0;i < 10;i++) pUnknown->Release();

    EXECUTE_ASSERT(m_Ba->QueryInterface(IID_IUnknown,(VOID **) &pUnknown) == NOERROR);
    EXECUTE_ASSERT(m_Ba->QueryInterface(IID_IFilterGraph,(VOID **) &pUnknown) == NOERROR);
    EXECUTE_ASSERT(m_Ba->QueryInterface(IID_IGraphBuilder,(VOID **) &pUnknown) == NOERROR);
    EXECUTE_ASSERT(m_Ba->QueryInterface(IID_IMediaPosition,(VOID **) &pUnknown) == NOERROR);
    EXECUTE_ASSERT(m_Ba->QueryInterface(IID_IMediaControl,(VOID **) &pUnknown) == NOERROR);
    EXECUTE_ASSERT(m_Ba->QueryInterface(IID_IMediaEvent,(VOID **) &pUnknown) == NOERROR);
    EXECUTE_ASSERT(m_Ba->QueryInterface(IID_IMediaSeeking,(VOID **) &pUnknown) == NOERROR);
    EXECUTE_ASSERT(m_Ba->QueryInterface(IID_IVideoWindow,(VOID **) &pUnknown) == NOERROR);
    EXECUTE_ASSERT(m_Ba->QueryInterface(IID_IBasicVideo,(VOID **) &pUnknown) == NOERROR);
    EXECUTE_ASSERT(m_Ba->QueryInterface(IID_IBasicAudio,(VOID **) &pUnknown) == NOERROR);
    for (i = 0;i < 10;i++) pUnknown->Release();

    EXECUTE_ASSERT(m_Ms->QueryInterface(IID_IUnknown,(VOID **) &pUnknown) == NOERROR);
    EXECUTE_ASSERT(m_Ms->QueryInterface(IID_IFilterGraph,(VOID **) &pUnknown) == NOERROR);
    EXECUTE_ASSERT(m_Ms->QueryInterface(IID_IGraphBuilder,(VOID **) &pUnknown) == NOERROR);
    EXECUTE_ASSERT(m_Ms->QueryInterface(IID_IMediaPosition,(VOID **) &pUnknown) == NOERROR);
    EXECUTE_ASSERT(m_Ms->QueryInterface(IID_IMediaControl,(VOID **) &pUnknown) == NOERROR);
    EXECUTE_ASSERT(m_Ms->QueryInterface(IID_IMediaEvent,(VOID **) &pUnknown) == NOERROR);
    EXECUTE_ASSERT(m_Ms->QueryInterface(IID_IMediaSeeking,(VOID **) &pUnknown) == NOERROR);
    EXECUTE_ASSERT(m_Ms->QueryInterface(IID_IVideoWindow,(VOID **) &pUnknown) == NOERROR);
    EXECUTE_ASSERT(m_Ms->QueryInterface(IID_IBasicVideo,(VOID **) &pUnknown) == NOERROR);
    EXECUTE_ASSERT(m_Ms->QueryInterface(IID_IBasicAudio,(VOID **) &pUnknown) == NOERROR);
    for (i = 0;i < 10;i++) pUnknown->Release();

    EXECUTE_ASSERT(m_Ms->GetDuration(NULL) == E_POINTER);
    EXECUTE_ASSERT(m_Ms->GetDuration(&RefTime) == NOERROR);
    EXECUTE_ASSERT(m_Ms->GetStopPosition(NULL) == E_POINTER);
    EXECUTE_ASSERT(m_Ms->GetStopPosition(&RefTime) == NOERROR);
    EXECUTE_ASSERT(m_Ms->GetCurrentPosition(NULL) == E_POINTER);
    EXECUTE_ASSERT(m_Ms->Release() == (Count - 1));

    return TRUE;
}


// Release any filtergraph manager interfaces we obtained

void CMovie::CloseMovie()
{
    m_Mode = MOVIE_NOTOPENED;
    m_bFullScreen = FALSE;
    m_MediaEvent = NULL;

    // Release the filtergraph interfaces

    if (m_Qp)   {   m_Qp->Release();    m_Qp = NULL;    }
    if (m_Dv)   {   m_Dv->Release();    m_Dv = NULL;    }
    if (m_Me)   {   m_Me->Release();    m_Me = NULL;    }
    if (m_Mp)   {   m_Mp->Release();    m_Mp = NULL;    }
    if (m_Vw)   {   m_Vw->Release();    m_Vw = NULL;    }
    if (m_Mc)   {   m_Mc->Release();    m_Mc = NULL;    }
    if (m_Gb)   {   m_Gb->Release();    m_Gb = NULL;    }
    if (m_Fg)   {   m_Fg->Release();    m_Fg = NULL;    }
    if (m_Ms)   {   m_Ms->Release();    m_Ms = NULL;    }
    if (m_Ba)   {   m_Ba->Release();    m_Ba = NULL;    }
    if (m_Bv)   {   m_Bv->Release();    m_Bv = NULL;    }
}


// Return the current window position

BOOL CMovie::GetMoviePosition(LONG *x,LONG *y,LONG *cx,LONG *cy)
{
    return (m_Vw->GetWindowPosition(x,y,cx,cy) == S_OK);
}


// Set the movie window position

BOOL CMovie::PutMoviePosition(LONG x,LONG y,LONG cx,LONG cy)
{
    return (m_Vw->SetWindowPosition(x,y,cx,cy) == S_OK);
}


// Set the movie window state

BOOL CMovie::SetMovieWindowState(long uState)
{
    return (m_Vw->put_WindowState(uState) == S_OK);
}


// Make the window the foreground application

BOOL CMovie::SetWindowForeground(long Focus)
{
    return (m_Vw->SetWindowForeground(Focus) == S_OK);
}


// Return the current movie window state

BOOL CMovie::GetMovieWindowState(long *lpuState)
{
    return (m_Vw->get_WindowState(lpuState) == S_OK);
}


// Start a movie playing

BOOL CMovie::PlayMovie()
{
    m_Mode = MOVIE_PLAYING;
    return (SUCCEEDED(m_Mc->Run()));
}


// Pause a movie

BOOL CMovie::PauseMovie()
{
    m_Mode = MOVIE_PAUSED;
    return (SUCCEEDED(m_Mc->Pause()));
}


// Stop a movie

BOOL CMovie::StopMovie()
{
    m_Mode = MOVIE_STOPPED;
    return (SUCCEEDED(m_Mc->Stop()));
}


// Return the current movie state

MovieMode CMovie::StatusMovie(DWORD Timeout)
{
    FILTER_STATE fs;
    HRESULT hr;

    // Get the current filtergraph state

    hr = m_Mc->GetState(Timeout,(OAFilterState *) &fs);
    if (hr == VFW_S_STATE_INTERMEDIATE) {
        return m_Mode;
    }

    // The graph is in a completed state

    switch (fs) {

        case State_Stopped:
            m_Mode = MOVIE_STOPPED;
            break;

        case State_Paused:
            m_Mode = MOVIE_PAUSED;
            break;

        case State_Running:
            m_Mode = MOVIE_PLAYING;
            break;
    }
    return m_Mode;
}


// Return an handle we can wait for events with

HANDLE CMovie::GetMovieEventHandle()
{
    m_Me->GetEventHandle((OAEVENT *) &m_MediaEvent);
    return m_MediaEvent;
}


// Get the next event from the filtergraph event queue

long CMovie::GetMovieEventCode()
{
    long lEventCode;
	LONG_PTR lParam1,lParam2;

    HRESULT hr = m_Me->GetEvent(&lEventCode,&lParam1,&lParam2,0);
    if (SUCCEEDED(hr)) {
        return lEventCode;
    }
    return EC_SYSTEMBASE;
}


// Return the duration of the movie

REFTIME CMovie::GetDuration()
{
    REFTIME rt;
    HRESULT hr;

    hr = m_Mp->get_Duration(&rt);
    if (SUCCEEDED(hr)) {
        return rt;
    }
    return (REFTIME) 0;
}


// Return the current movie position

REFTIME CMovie::GetCurrentPosition()
{
    REFTIME rt;
    HRESULT hr;

    hr = m_Mp->get_CurrentPosition(&rt);
    if (SUCCEEDED(hr)) {
        return rt;
    }
    return (REFTIME) 0;
}


// Set a new current position for the graph

BOOL CMovie::SeekToPosition(REFTIME rt)
{
    return (SUCCEEDED(m_Mp->put_CurrentPosition(rt)));
}


// Obtain IDirectDrawVideo and IQualProp from the renderer

BOOL CMovie::GetPerformanceInterfaces()
{
    IBaseFilter *m_VideoRenderer = NULL;

    // Get the performance monitoring interfaces.

    HRESULT hr = m_Fg->FindFilterByName(L"Video Renderer",&m_VideoRenderer);
    if (FAILED(hr)) {
        return FALSE;
    }

    // Get the IQualProp interface from the renderer

    hr = m_VideoRenderer->QueryInterface(IID_IQualProp,(LPVOID *) &m_Qp);
    if (FAILED(hr)) {
        m_Qp = NULL;
    }

    // Get the IDirectDrawVideo interface from the renderer

    hr = m_VideoRenderer->QueryInterface(IID_IDirectDrawVideo,(LPVOID *) &m_Dv);
    if (FAILED(hr)) {
        m_Dv = NULL;
    }

    m_VideoRenderer->Release();
    m_VideoRenderer = NULL;
    return TRUE;
}


// Set fullscreen mode for the movie

BOOL CMovie::SetFullScreenMode(BOOL bMode)
{
    m_bFullScreen = bMode;

    if (bMode == FALSE) {
        return (SUCCEEDED(m_Vw->put_FullScreenMode(OAFALSE)));
    } else {
        return (SUCCEEDED(m_Vw->put_FullScreenMode(OATRUE)));
    }
}


// Return the current fullscreen mode

BOOL CMovie::IsFullScreenMode()
{
    return m_bFullScreen;
}
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\multimedia\dshow\filters\image\vidtest\imagesrc.cpp ===
// Copyright (c) Microsoft Corporation 1994-1996. All Rights Reserved
// Implements the CImageSource class, Anthony Phillips, July 1995

#include <streams.h>        // Includes all the IDL and base classes
#include <windows.h>        // Standard Windows SDK header file
#include <windowsx.h>       // Win32 Windows extensions and macros
#include <vidprop.h>        // Shared video properties library
#include <render.h>         // Normal video renderer header file
#include <modex.h>          // Specialised Modex video renderer
#include <convert.h>        // Defines colour space conversions
#include <colour.h>         // Rest of the colour space convertor
#include <imagetst.h>       // All our unit test header files
#include <stdio.h>          // Standard C runtime header file
#include <limits.h>         // Defines standard data type limits
#include <tchar.h>          // Unicode and ANSII portable types
#include <mmsystem.h>       // Multimedia used for timeGetTime
#include <stdlib.h>         // Standard C runtime function library
#include <tstshell.h>       // Definitions of constants eg TST_FAIL

// This class implements the core source filter for providing test images to
// the video renderer. We are a very simple (and incomplete) filter that has
// a single output pin, an IBaseFilter/IMediaFilter implementation that uses
// the base media filter class almost exclusively. The only complication is
// when we are asked to provide a media type in GetMediaType, what we return
// is dependant on the type of connection requested (samples or overlay)

// Constructor

#pragma warning(disable:4355)

CImageSource::CImageSource(LPUNKNOWN pUnk,HRESULT *phr) :
    CBaseFilter(NAME("Video source"),pUnk,this,CLSID_NULL),
    m_ImagePin(this,this,phr,L"Output"),
    m_pClock(NULL)
{
    ASSERT(phr);
}


// Destructor

CImageSource::~CImageSource()
{
    // Release the clock if we have one

    if (m_pClock) {
        m_pClock->Release();
        m_pClock = NULL;
    }
}


// Return our single output pin (not reference counted)

CBasePin *CImageSource::GetPin(int n)
{
    // We only support one output pin and it is numbered zero

    ASSERT(n == 0);
    if (n != 0) {
        return NULL;
    }
    return &m_ImagePin;
}


// Source filter input pin Constructor

CImagePin::CImagePin(CBaseFilter *pBaseFilter,
                     CImageSource *pImageSource,
                     HRESULT *phr,
                     LPCWSTR pPinName) :

    CBaseOutputPin(NAME("Test pin"),
                   pBaseFilter,
                   pImageSource,
                   (HRESULT *) phr,
                   pPinName)
{
    m_pBaseFilter = pBaseFilter;
    m_pImageSource = pImageSource;
}


// Single method to handle EC_REPAINTs for IMediaEventSink

STDMETHODIMP CImagePin::Notify(long EventCode,
                               long EventParam1,
                               long EventParam2)
{
    NOTE("Notify called with EC_REPAINT");

    ASSERT(EventCode == EC_REPAINT);
    ASSERT(EventParam1 == 0);
    ASSERT(EventParam2 == 0);
    return E_NOTIMPL;
}


// Expose the additional IMediaEventSink interface we support

STDMETHODIMP CImagePin::NonDelegatingQueryInterface(REFIID riid,void **ppv)
{
    CheckPointer(ppv,E_POINTER);
    if (riid == IID_IMediaEventSink) {
        DbgLog((LOG_TRACE,0,"Supplying IMediaEventSink"));
	return GetInterface((IMediaEventSink *) this, ppv);
    }
    return CBaseOutputPin::NonDelegatingQueryInterface(riid, ppv);
}


// Overriden to accomodate overlay connections with no allocators

HRESULT CImagePin::Active()
{
    // Is this a normal samples connection

    if (uiCurrentConnectionItem == IDM_SAMPLES) {
        NOTE("Activating base output pin");
        EXECUTE_ASSERT(m_pAllocator);
        return CBaseOutputPin::Active();
    }

    // Check this is an overlay connection

    if (uiCurrentConnectionItem != IDM_OVERLAY) {
        EXECUTE_ASSERT(!TEXT("Invalid connection"));
    }
    return NOERROR;
}


// Likewise Inactive calls must handle overlay connections

HRESULT CImagePin::Inactive()
{
    // Is this a normal samples connection

    if (uiCurrentConnectionItem == IDM_SAMPLES) {
        NOTE("Inactivating base output pin");
        EXECUTE_ASSERT(m_pAllocator);
        return CBaseOutputPin::Inactive();
    }

    // Check this is an overlay connection

    if (uiCurrentConnectionItem != IDM_OVERLAY) {
        EXECUTE_ASSERT(!TEXT("Invalid connection"));
    }
    return NOERROR;
}


// Propose with a MEDIASUBTYPE_Overlay if we are using a direct interface or
// a media subtype based on the video header if we are running the standard
// memory transport. The base classes provide a helper function to retrieve a
// media subtype GUID from a BITMAPINFOHEADER, for example, if it is an eight
// bit colour image it will return MEDIASUBTYPE_RGB8. We must also set the
// format of the CMediaType to be the VIDEOINFO we read from the DIB file

HRESULT CImagePin::GetMediaType(int iPosition,CMediaType *pmtOut)
{
    if (iPosition >= NUMBERMEDIATYPES) {
        return VFW_S_NO_MORE_ITEMS;
    }

    const GUID SubTypeGUID = GetBitmapSubtype(&VideoInfo.bmiHeader);
    pmtOut->SetType(&MEDIATYPE_Video);
    pmtOut->SetSubtype(&SubTypeGUID);
    pmtOut->SetFormatType(&FORMAT_VideoInfo);

    if (uiCurrentConnectionItem == IDM_OVERLAY) {
        pmtOut->SetSubtype(&MEDIASUBTYPE_Overlay);
    }

    // Set the VIDEOINFO structure to be the media type format block

    pmtOut->SetFormat((BYTE *)&VideoInfo,SIZE_VIDEOHEADER + SIZE_PALETTE);
    pmtOut->SetSampleSize(VideoInfo.bmiHeader.biSizeImage);
    pmtOut->SetTemporalCompression(FALSE);
    return CorruptMediaType(iPosition,pmtOut);
}


// This is called after we have constructed a valid media type, we are passed
// in the ordinal position for this media type. If it isn't the last one in
// the list then we hack around with it's fields so that it will be rejected
// by the video renderer. We check when SetMediaType is called that it really
// didn't accept one of the media types that we fiddled with. Most of the
// changes are to invalidate the BITMAPINFOHEADER but there are some fields
// in the VIDEOINFO that are reserved for future use and should be empty

BYTE DuffFormat[1];

HRESULT CImagePin::CorruptMediaType(int iPosition,CMediaType *pmtOut)
{
    VIDEOINFO *pVideoInfo = (VIDEOINFO *) pmtOut->Format();
    BITMAPINFOHEADER *pbmi = HEADER(pmtOut->Format());
    pbmi->biSizeImage = GetBitmapSize(pbmi);

    switch (iPosition) {

        case 0:     pmtOut->SetFormat(DuffFormat,1);            break;
        case 1:     pmtOut->SetFormatType(&GUID_NULL);          break;
        case 2:     pbmi->biSize = 0;                           break;
        case 3:     pbmi->biSize = 1;                           break;
        case 4:     pbmi->biWidth = -1;                         break;
        case 5:     pbmi->biHeight = -1;                        break;
        case 6:     pbmi->biPlanes = 2;                         break;
        case 7:     pbmi->biPlanes = 0;                         break;
        case 8:     pbmi->biBitCount = 3;                       break;
        case 9:     pbmi->biBitCount = 123;                     break;
        case 10:    pbmi->biCompression = INFINITE;             break;

        case 11:    pbmi->biCompression = BI_BITFIELDS;
                    pbmi->biBitCount = 8;                       break;

        case 12:    pbmi->biSizeImage = 1;                      break;
        case 13:    pbmi->biSizeImage = INFINITE;               break;

        case 14:    pbmi->biClrUsed = INFINITE;
                    pbmi->biBitCount = 8;                       break;

        case 15:    pmtOut->SetType(&GUID_NULL);                break;
        case 16:    pmtOut->SetType(&MEDIATYPE_Audio);          break;
        case 17:    pmtOut->SetType(&MEDIATYPE_Text);           break;
        case 18:    pmtOut->SetType(&MEDIASUBTYPE_Overlay);     break;
        case 19:    pmtOut->SetSubtype(&GUID_NULL);             break;
    }
    return NOERROR;
}


// This is called when someone asks if a particular type is acceptable. We
// are also called by the base filter classes to check if our media types
// are acceptable to us before asking the downstream renderer. The formats
// we supply are mostly completely duff except for the last one so if we
// are stopped then we just display the type and say ok. When we're paused
// the renderer will start sending DCI/DirectDraw types which we validate

HRESULT CImagePin::CheckMediaType(const CMediaType *mtOut)
{
    VIDEOINFO *pVideoInfo = (VIDEOINFO *) mtOut->Format();

    // If we are being connected then accept all our types

    if (m_Connected == NULL) {
        if (mtOut->FormatLength() >= SIZE_VIDEOHEADER) {
            NOTE("Displaying format");
            DisplayMediaType(mtOut);
        }
        return NOERROR;
    }

    // The rectangles should either both be set or neither

    if (IsRectEmpty(&pVideoInfo->rcSource) == TRUE) {
        EXECUTE_ASSERT(IsRectEmpty(&pVideoInfo->rcTarget) == TRUE);
    } else {
        EXECUTE_ASSERT(IsRectEmpty(&pVideoInfo->rcTarget) == FALSE);
    }

    // Create a source rectangle if it's empty

    RECT SourceRect = pVideoInfo->rcSource;
    if (IsRectEmpty(&SourceRect) == TRUE) {
        SourceRect.left = SourceRect.top = 0;
        SourceRect.right = VideoInfo.bmiHeader.biWidth;
        SourceRect.bottom = ABSOL(VideoInfo.bmiHeader.biHeight);
        NOTERC("(Expanded) Source",SourceRect);
    }

    // Create a destination rectangle if it's empty

    RECT TargetRect = pVideoInfo->rcTarget;
    if (IsRectEmpty(&TargetRect) == TRUE) {
        TargetRect.left = TargetRect.top = 0;
        TargetRect.right = pVideoInfo->bmiHeader.biWidth;
        TargetRect.bottom = ABSOL(pVideoInfo->bmiHeader.biHeight);
        NOTERC("(Expanded) Target",TargetRect);
    }

    // Check we are not stretching nor compressing the image

    if (WIDTH(&SourceRect) == WIDTH(&TargetRect)) {
        if (HEIGHT(&SourceRect) == HEIGHT(&TargetRect)) {
            NOTE("No stretch");
            return NOERROR;
        }
    }
    return VFW_E_TYPE_NOT_ACCEPTED;
}


// This is called when we have established a connection between ourselves and
// the video renderer. We are handed the media type to use which we then use
// to make sure that it didn't accept one of our duff types. The easiest way
// to do this is simply to check the GUIDs and then compare the VIDEOINFOs

HRESULT CImagePin::SetMediaType(const CMediaType *pmtOut)
{
    gmtOut = *pmtOut;
    return NOERROR;
}


// Called when we actually want to complete a connection

HRESULT CImagePin::CompleteConnect(IPin *pReceivePin)
{
    VIDEOINFO *pVideoInfo = (VIDEOINFO *) gmtOut.Format();
    BITMAPINFOHEADER *pbmi = HEADER(pVideoInfo);

    EXECUTE_ASSERT(WIDTH(&pVideoInfo->rcSource) == 0);
    EXECUTE_ASSERT(HEIGHT(&pVideoInfo->rcSource) == 0);
    EXECUTE_ASSERT(WIDTH(&pVideoInfo->rcTarget) == 0);
    EXECUTE_ASSERT(HEIGHT(&pVideoInfo->rcTarget) == 0);

    EXECUTE_ASSERT(gmtOut.FormatLength() != 1);
    EXECUTE_ASSERT(*gmtOut.Subtype() != GUID_NULL);
    EXECUTE_ASSERT(*gmtOut.Type() == MEDIATYPE_Video);
    EXECUTE_ASSERT(memcmp(pVideoInfo,&VideoInfo,SIZE_VIDEOHEADER) == 0);

    // Base class looks after deciding allocators

    if (uiCurrentConnectionItem == IDM_SAMPLES) {
        return CBaseOutputPin::CompleteConnect(pReceivePin);
    }
    return NOERROR;
}


// For simplicity we always ask for the maximum buffer ever required and let
// the video renderer update this to match the video size. So if we ask for
// a 640x480 image and the sample type is 320x240 then when it creates the
// GDI DIB sections they will be created at a size to match the format. We
// could ask for an arbitrary number of buffers and will probably do better
// from a testing point of view if we have lots of buffers being processed

HRESULT CImagePin::DecideBufferSize(IMemAllocator *pAllocator,
                                    ALLOCATOR_PROPERTIES *pProperties)
{
    ASSERT(pAllocator);
    ASSERT(pProperties);
    HRESULT hr = NOERROR;

    NOTE("DecideBufferSize");
    pProperties->cBuffers = NUMBERBUFFERS;
    pProperties->cbBuffer = MAXIMAGESIZE;
    ASSERT(pProperties->cbBuffer);

    // Ask the allocator to reserve us some sample memory, NOTE the function
    // can succeed (that is return NOERROR) but still not have allocated the
    // memory that we requested, so we must check we got whatever we wanted

    ALLOCATOR_PROPERTIES Actual;
    hr = pAllocator->SetProperties(pProperties,&Actual);
    if (FAILED(hr)) {
        return hr;
    }

    EXECUTE_ASSERT(Actual.cBuffers == NUMBERBUFFERS);
    EXECUTE_ASSERT(Actual.cbAlign == (LONG) 1);
    EXECUTE_ASSERT(Actual.cbBuffer <= MAXIMAGESIZE);

    wsprintf(szInfo,TEXT("Buffer size %d Count %d Alignment %d Prefix %d"),
             Actual.cbBuffer,Actual.cBuffers,Actual.cbAlign,Actual.cbPrefix);

    Log(VERBOSE,szInfo);
    return hr;
}


// We override the output pin connection to query for IOverlay instead of the
// IMemInputPin transport if the user requested we test the direct interface
// We return the status code we get back from QueryInterface for IOverlay

STDMETHODIMP CImagePin::Connect(IPin *pReceivePin,const AM_MEDIA_TYPE *pmt)
{
    CAutoLock cObjectLock(m_pImageSource);

    // Are we testing the normal samples based transfer

    if (uiCurrentConnectionItem == IDM_SAMPLES) {
        NOTE("Calling output pin connect");
        return CBaseOutputPin::Connect(pReceivePin,pmt);
    }

    // Let the base output pin do it's usual work

    HRESULT hr = CBasePin::Connect(pReceivePin,pmt);
    if (FAILED(hr)) {
        return hr;
    }
    return pReceivePin->QueryInterface(IID_IOverlay,(void **)&pOverlay);
}
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\multimedia\dshow\filters\image\vidtest\imagewnd.h ===
// Copyright (c) Microsoft Corporation 1994-1996. All Rights Reserved
// Video renderer control interface test, Anthony Phillips, July 1995

#ifndef __IMAGEWND__
#define __IMAGEWND__

// OLE Automation has different ideas of TRUE and FALSE

#define OATRUE (-1)
#define OAFALSE (0)
#define OABOGUS (1)

BOOL CALLBACK EnumAllWindows(HWND hwnd,LPARAM lParam);
HWND FindVideoWindow(IVideoWindow *pVideoWindow);
void DisplayWindowStyles(LONG styles);
void DisplayWindowStylesEx(LONG style);
void InitialiseWindow();
void TerminateWindow();
void WriteImageToFile(BYTE *pImageData,DWORD ImageSize);

HRESULT CheckPalettesMatch(long StartIndex,         // Start colour position
                           long Entries,            // Number we should use
                           PALETTEENTRY *pPalette); // The palette colours

// Check source and destination methods

int CheckSourceProperties();
int CheckSourceMethods();
int CheckDestinationProperties();
int CheckDestinationMethods();

// These execute the control interface tests

execWindowTest1();      // Test the visible property
execWindowTest2();      // Test the background palette property
execWindowTest3();      // Change the window position
execWindowTest4();      // Change the window position (methods)
execWindowTest5();      // Change the source rectangle
execWindowTest6();      // Change the source (methods)
execWindowTest7();      // Change the destination rectangle
execWindowTest8();      // Change the destination (methods)
execWindowTest9();      // Make different windows the owner
execWindowTest10();     // Check the video size properties
execWindowTest11();     // Change the video window state
execWindowTest12();     // Change the style of the window
execWindowTest13();     // Set different border colours
execWindowTest14();     // Get the current video palette
execWindowTest15();     // Auto show state property
execWindowTest16();     // Current image property
execWindowTest17();     // Persistent window properties
execWindowTest18();     // Restored window position method

#endif // __IMAGEWND__


=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\multimedia\dshow\filters\image\vidtest\imagesrc.h ===
// Copyright (c) Microsoft Corporation 1994-1996. All Rights Reserved
// Implements the CImageSource class, Anthony Phillips, July 1995

#ifndef __IMAGESRC__
#define __IMAGESRC__

// We have a pseudo filter that provides images to the video renderer (psuedo
// because we don't create it through CoCreateInstance but through new). The
// filter has a specialist input pin that derives from CBaseOutputPin as is
// defined below. It acts as a normal output pin in most respects but it does
// have some extra code for providing loads of duff media types. At any given
// time we have one and only one image loaded. This has a VIDEOINFO associated
// with it that represents the picture format. When we supply our preferred
// output media types we take that VIDEOINFO and invalidate it in a variety
// of different ways and then check that the format we finally agree is the
// last one we provided which does not have any of the format irregularities

class CImagePin : public CBaseOutputPin, public IMediaEventSink
{
    CBaseFilter *m_pBaseFilter;
    CImageSource *m_pImageSource;

public:

    // Constructor

    CImagePin(CBaseFilter *pBaseFilter,
              CImageSource *pImageSource,
              HRESULT *phr,
              LPCWSTR pPinName);

    DECLARE_IUNKNOWN

    // Check that we can support this output type
    HRESULT CheckMediaType(const CMediaType *pmtOut);

    // Called from CBaseOutputPin to prepare the allocator's buffers
    HRESULT DecideBufferSize(IMemAllocator *pAllocator,
                             ALLOCATOR_PROPERTIES *pProperties);

    // Overriden to get the direct video interface
    STDMETHODIMP Connect(IPin *pReceivePin,const AM_MEDIA_TYPE *pmt);

    // Overriden to supply the media types we provide
    HRESULT GetMediaType(int iPosition,CMediaType *pmtOut);
    HRESULT CorruptMediaType(int iPosition,CMediaType *pmtOut);
    HRESULT SetMediaType(const CMediaType *pmtOut);
    HRESULT CompleteConnect(IPin *pReceivePin);

    // Overriden to control overlay connections
    HRESULT Active();
    HRESULT Inactive();

    // Single method to handle EC_REPAINTs from IMediaEventSink
    STDMETHODIMP Notify(long EventCode,long EventParam1,long EventParam2);
    STDMETHODIMP NonDelegatingQueryInterface(REFIID riid,void **ppv);

    // Overriden to accept quality messages
    STDMETHODIMP Notify(IBaseFilter *pSender, Quality q) {
        return E_NOTIMPL;   // We DO NOT handle this.
    }
};


// We create a pseudo filter object to synthesise a source connection with the
// renderer, the filter supports just one output pin that can both push images
// and use a renderer supplied IOverlay interface. We supply a number of DIB
// images in the test that are in different formats such as RGB24, RGB565 and
// so on. The user can select the image to be used in the connection or have
// the automatic tests cycle through the possibilities. We derive the source
// filter object from the SDK CBaseFilter and the pin from the CBaseOutputPin

class CImageSource : public CBaseFilter, public CCritSec
{
public:

    CImagePin m_ImagePin;               // Our pin implementation
    IReferenceClock *m_pClock;          // Reference clock to use
    CMediaType m_mtOut;                 // Media type for the pin

    // Constructors etc

    CImageSource(LPUNKNOWN pUnk, HRESULT *phr);
    ~CImageSource();

    // Return the number of pins and their interfaces

    CBasePin *GetPin(int n);
    int GetPinCount() {
        return 1;
    };
};

#endif // __IMAGESRC__
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\multimedia\dshow\filters\image\vidtest\imagetst.cpp ===
// Copyright (c) Microsoft Corporation 1994-1996. All Rights Reserved
// Digital video renderer test, Anthony Phillips, January 1995

#include <streams.h>        // Includes all the IDL and base classes
#include <windows.h>        // Standard Windows SDK header file
#include <windowsx.h>       // Win32 Windows extensions and macros
#include <vidprop.h>        // Shared video properties library
#include <render.h>         // Normal video renderer header file
#include <modex.h>          // Specialised Modex video renderer
#include <convert.h>        // Defines colour space conversions
#include <colour.h>         // Rest of the colour space convertor
#include <imagetst.h>       // All our unit test header files
#include <stdio.h>          // Standard C runtime header file
#include <limits.h>         // Defines standard data type limits
#include <tchar.h>          // Unicode and ANSII portable types
#include <mmsystem.h>       // Multimedia used for timeGetTime
#include <stdlib.h>         // Standard C runtime function library
#include <tstshell.h>       // Definitions of constants eg TST_FAIL

// This contains the main test shell entry points. The shell is a library
// that has a number of entry points for such purposes as logging (tstsLog)
// It also requires the application to define some entry points (or hooks)
// that are called at useful times such as initialisation and termination
// these are all prefixed with tst... We also have a main window procedure
// and some simple command handling so that a user can test specific areas
// manually rather than selecting tests and running them automatically. A
// point of caution we have a global string szInfo that can be used for
// string formatting before calling Log however it should only be used
// by the primary application thread, any worker threads should allocate
// their own working memory. The samples we send to the video renderer are
// readin from DIB files and the format we will supply is stored as a type
// in the VIDEOINFO, the image data is stored in the bImageData array

UINT uiCurrentDisplayMode = 0;      // Current display mode setting
UINT uiCurrentImageItem = 0;        // Current image format we propose
UINT uiCurrentSurfaceItem = 0;      // Type of DirectDraw surface allowed
UINT uiCurrentConnectionItem = 0;   // Current connection menu selection
CAMEvent LogEvent;                    // Controls access to logging
DWORD MainThreadID;                 // Main application thread ID
HWND ghwndTstShell;                 // Main test shell window handle
HINSTANCE hinst;                    // Running instance of the test shell
HMENU hConnectionMenu;              // Connection type menu popup handle
HMENU hSurfaceMenu;                 // Surface type menu popup handle
HMENU hImageMenu;                   // Handle to the Image popup menu
HMENU hModesMenu;                   // Handle to the display modes menu
HMENU hDirectDrawMenu;              // Controls loading of DirectDraw
VIDEOINFO VideoInfo;                // Header from loaded DIB file
BYTE bImageData[MAXIMAGESIZE];      // Image data buffer for samples
DWORD dwIncrement = 50;             // Period between subsequent frames
TCHAR szInfo[INFO];                 // General string formatting field
CMediaType gmtOut;                  // Current output connection type
LPDIRECTDRAW pDirectDraw = NULL;    // DirectDraw service provider
HINSTANCE hDirectDraw = NULL;       // Handle for DirectDraw library
DWORD dwDisplayModes = 0;           // Number of display modes to try
DWORD dwDDCount = 0;                // Samples with surfaces available

LPTSTR szAppName = TEXT("Quartz Video Renderer Tests");


//==========================================================================
//
//  int tstGetTestInfo
//
//  Description:
//      Called by the test shell to get information about the test. Also
//      saves a copy of the running instance of the test shell.
//
//      We also initialise custom profile handlers here so that we can set
//      everything up when running automatically from a profile.
//
//  Arguments:
//      HINSTANCE hinstance: A handle to the running instance of the shell
//
//      LPSTR lpszTestName: Pointer to buffer of name for test. Among
//          other things, it is used as a caption for the main window and
//          as the name of its class. Always ANSI.
//
//      LPSTR lpszPathSection: Pointer to buffer of name of section in
//          win.ini in which the default input and output paths are
//          stored. Always ANSI.
//
//      LPWORD wPlatform: The platform on which the tests are to be run,
//          which may be determined dynamically. In order for a test to
//          be shown on the run list, it must have all the bits found in
//          wPlatform turned on. It is enough for one bit to be turned off
//          to disqualify the test. This also means that if this value is
//          zero, all tests will be run. In order to make this more
//          mathematically precise, I shall give the relation which Test
//          Shell uses to decide whether a test with platform flags
//          wTestPlatform may run:  It may run if the following is TRUE:
//          ((wTestPlatform & wPlatform) == wPlatform)
//
//  Return (int):
//      The value which identifies the test list resouce
//      (found in the resource file for this executable)
//
//==========================================================================

int tstGetTestInfo(HINSTANCE hinstance,
                   LPSTR lpszTestName,
                   LPSTR lpszPathSection,
                   LPWORD wPlatform)
{

    // Save a copy of a handle to the running instance
    hinst = hinstance;

    // Install profile handlers for custom data
    tstInstallWriteCustomInfo(SaveCustomProfile);
    tstInstallReadCustomInfo(LoadCustomProfile);

    // Pass application name to test shell

#ifdef UNICODE
    WideCharToMultiByte(CP_ACP,0,szAppName,-1,lpszTestName,SECTION_LENGTH,NULL,NULL);
    WideCharToMultiByte(CP_ACP,0,szAppName,-1,lpszPathSection,SECTION_LENGTH,NULL,NULL);
#else
    lstrcpy(lpszTestName, szAppName);
    lstrcpy(lpszPathSection, szAppName);
#endif

    // The platform the test is running on

    *wPlatform = 0;
    return TEST_LIST;
}


//==========================================================================
//
//  void InitOptionsMenu
//
//  Description:
//      Creates an additional application specific menu. Note that this
//      function is called from within tstInit as all menu installations
//      MUST be done in tstInit or else the app's behavior is undefined.
//      Also note the calls to tstInstallCustomTest which is a shell API
//      that allows custom installation of tests. From tstshell version
//      2.0 on, it is possible to install menus the usual way and trap the
//      appropriate window messages, though the method presented here is
//      still the preferred one for Test Applications to use.
//
//      For the Quartz tests, complete menu structures and window procs
//      exist, so it is simpler to just load and append the existing menu
//      resources than to call tstInstallCustomTest once for each menu
//      option. The window message handling is done through tstAppWndProc
//
//  Arguments:
//      LRESULT (CALLBACK* MenuProc)(HWND,UINT,WPARAM,LPARAM):
//          The menu function (not used in the Quartz tests).
//
//==========================================================================

BOOL InitOptionsMenu(LRESULT (CALLBACK* MenuProc)(HWND, UINT, WPARAM, LPARAM))
{
    HMENU hImageTstMenu;

    if (NULL == (hImageTstMenu = LoadMenu(hinst, TEXT("ImageTstMenu")))) {
        return(FALSE);
    }

    if (AppendMenu(GetMenu(ghwndTstShell),
                   MF_POPUP,
                   (UINT) hImageTstMenu,
                   TEXT("Image")) == FALSE) {

        return(FALSE);
    }

    DrawMenuBar(ghwndTstShell);

    // Save handles to the image and submenu popups

    hImageMenu = GetSubMenu(hImageTstMenu,IMAGE_MENU_POS);
    hSurfaceMenu = GetSubMenu(hImageTstMenu,SURFACE_MENU_POS);
    hDirectDrawMenu = GetSubMenu(hImageTstMenu,DIRECTDRAW_MENU_POS);
    hConnectionMenu = GetSubMenu(hImageTstMenu,CONNECTION_MENU_POS);
    hModesMenu = GetSubMenu(hImageTstMenu,MODES_MENU_POS);

    ASSERT(hImageMenu);
    ASSERT(hSurfaceMenu);
    ASSERT(hModesMenu);
    ASSERT(hConnectionMenu);
    ASSERT(hDirectDrawMenu);

    return TRUE;
}


//==========================================================================
//
//  BOOL tstInit
//
//  Description:
//      Called by the test shell to provide the test program with an
//      opportunity to do whatever initialization it needs to do before
//      user interaction is initiated. It also provides the test program
//      with an opportunity to keep a copy of a handle to the main window,
//      if the test program needs it. In order to use some of the more
//      advanced features of test shell, several installation must be done
//      here:
//
//         All menu installation must be done here by calling
//          tstInstallCustomTest (that is, all menus that the test
//          application wants to add).
//
//         If the test application wants to trap the window messages of
//          the main test shell window, it must install its default
//          window procedure here by calling tstInstallDefWindowProc.
//
//         If the test application would like to use the status bar for
//          displaying the name of the currently running test, it must
//          call tstDisplayCurrentTest here.
//
//         If the test application would like to change the stop key from
//          ESC to something else, it must do so here by calling
//          tstChangeStopVKey.
//
//         If the test application would like to add dynamic test cases
//          to the test list, it must first add their names to the
//          virtual string table using tstAddNewString (and add their
//          group's name too), and then add the actual tests using
//          tstAddTestCase. The virtual string table is an abstraction
//          which behaves just like a string table from the outside with
//          the exception that it accepts dynamically added string.
//
//  Arguments:
//      HWND hwndMain: A handle to the main window
//
//  Return (BOOL):
//      TRUE if initialization went well, FALSE otherwise which will abort
//
//==========================================================================

BOOL tstInit(HWND hwndMain)
{
    CoInitialize(NULL);             // Initialise COM library
    DbgInitialise(hinst);           // Initialise debug library

    MainThreadID = GetCurrentThreadId();
    ghwndTstShell = hwndMain;
    LogEvent.Set();

    // Installs a default windows procedure which may handle messages
    // directed to Test Shell's main window. It is vital to note that
    // this window function is substituted for DefWindowProc and not in
    // addition to it and therefore DefWindowProc MUST be called from
    // within it in the default case (tstAppWndProc is an example)

    tstInstallDefWindowProc (tstAppWndProc);

    // Install the custom menus (look at InitOptionsMenu for details)

    if (InitOptionsMenu(NULL)==FALSE)
        return FALSE;  // If menu installation failed, abort execution

    // Set up the image test app

    if (InitialiseTest() == FALSE) {
        return FALSE;
    }

    // This is a shell API which tells Test Shell to display the name of
    // the currenly executing API in its status bar. It is a really nice
    // feature for test applications which do not use the toolbar for any
    // other purpose, as it tells the user of the progress of the tests

    tstDisplayCurrentTest();

    // Change the stop key from ESC to SPACE

    tstChangeStopVKey(VSTOPKEY);
    return(TRUE);
}


//==========================================================================
//
//  int execTest
//
//  Description:
//      This is the actual test function which is called from within the
//      test shell. It is passed various information about the test case
//      it is asked to run, and branches off to the appropriate test
//      function. Note that it needs not switch on nFxID, but may also
//      use iCase or wID.
//
//  Arguments:
//      int nFxID: The test case identifier, also found in the third column
//          in the third column of the test list in the resource file
//
//      int iCase: The test case's number, which expresses the ordering
//          used by the test shell.
//
//      UINT wID: The test case's string ID, which identifies the string
//          containing the description of the test case. Note that it is
//          also a good candidate for use in the switch statement, as it
//          is unique to each test case.
//
//      UINT wGroupID: The test case's group's string ID, which identifies
//          the string containing the description of the test case's group.
//
//  Return (int): Indicates the result of the test by using TST_FAIL,
//          TST_PASS, TST_OTHER, TST_ABORT, TST_TNYI, TST_TRAN, or TST_TERR
//
//==========================================================================

typedef INT (*PTESTCASE)(void);

const struct {
    INT TestID;             // Identifier for this test from resource file
    PTESTCASE pTestCase;    // Pointer to the function executing this test
} TestCaseMap[] = {

    ID_TEST1,   execTest1,          // Connect and disconnect the renderer
    ID_TEST2,   execTest2,          // Connect, pause video and disconnect
    ID_TEST3,   execTest3,          // Connect video, play and disconnect
    ID_TEST4,   execTest4,          // Connect renderer and connect again
    ID_TEST5,   execTest5,          // Connect and disconnect twice
    ID_TEST6,   execTest6,          // Try to disconnect while paused
    ID_TEST7,   execTest7,          // Try to disconnect while running
    ID_TEST8,   execTest8,          // Try multiple state changes
    ID_TEST9,   execTest9,          // Run without a reference clock
    ID_TEST10,  execTest10,         // Multithread stress test

    ID_TEST11,  execTest1,          // Connect and disconnect the renderer
    ID_TEST12,  execTest2,          // Connect, pause video and disconnect
    ID_TEST13,  execTest3,          // Connect video, play and disconnect
    ID_TEST14,  execTest4,          // Connect renderer and connect again
    ID_TEST15,  execTest5,          // Connect and disconnect twice
    ID_TEST16,  execTest6,          // Try to disconnect while paused
    ID_TEST17,  execTest7,          // Try to disconnect while running
    ID_TEST18,  execTest8,          // Try multiple state changes
    ID_TEST19,  execTest9,          // Run without a reference clock
    ID_TEST20,  execTest10,         // Multithread stress test

    ID_TEST21,  execWindowTest1,    // Test the visible property
    ID_TEST22,  execWindowTest2,    // Test the background palette property
    ID_TEST23,  execWindowTest3,    // Change the window position
    ID_TEST24,  execWindowTest4,    // Change the window position (methods)
    ID_TEST25,  execWindowTest5,    // Change the source rectangle
    ID_TEST26,  execWindowTest6,    // Change the source (methods)
    ID_TEST27,  execWindowTest7,    // Change the destination rectangle
    ID_TEST28,  execWindowTest8,    // Change the destination (methods)
    ID_TEST29,  execWindowTest9,    // Make different windows the owner
    ID_TEST30,  execWindowTest10,   // Check the video size properties
    ID_TEST31,  execWindowTest11,   // Change the video window state
    ID_TEST32,  execWindowTest12,   // Change the style of the window
    ID_TEST33,  execWindowTest13,   // Set different border colours
    ID_TEST34,  execWindowTest14,   // Get the current video palette
    ID_TEST35,  execWindowTest15,   // Auto show state property
    ID_TEST36,  execWindowTest16,   // Current image property
    ID_TEST37,  execWindowTest17,   // Persistent window properties
    ID_TEST38,  execWindowTest18,   // Restored window position method

    ID_TEST39,  execDDTest1,        // No DCI/DirectDraw support
    ID_TEST40,  execDDTest2,        // DCI primary surface
    ID_TEST41,  execDDTest3,        // DirectDraw primary surface
    ID_TEST42,  execDDTest4,        // DirectDraw RGB overlay surface
    ID_TEST43,  execDDTest5,        // DirectDraw YUV overlay surface
    ID_TEST44,  execDDTest6,        // DirectDraw RGB offscreen surface
    ID_TEST45,  execDDTest7,        // DirectDraw YUV offscreen surface
    ID_TEST46,  execDDTest8,        // DirectDraw RGB flipping surface
    ID_TEST47,  execDDTest9,        // DirectDraw YUV flipping surface
    ID_TEST48,  execDDTest10,       // Run ALL tests against all modes

    ID_TEST49,  execSpeedTest1,     // Measure performance on surfaces
    ID_TEST50,  execSpeedTest2,     // Measure colour space conversions
    ID_TEST51,  execSpeedTest3,     // Same as above but force unaligned

    ID_TEST52,  execSysTest1,       // System test with DirectDraw loaded
    ID_TEST53,  execSysTest2,       // Same tests without DirectDraw loaded
    ID_TEST54,  execSysTest3        // All tests with all surfaces and modes
};

// This executes the test associated with a particular identifier NOTE the ID
// for the tests defined in this header file must be contiguous otherwise we
// will not be able to dereference the table correctly from the base value
// We execute the same tests twice, the first time through they will connect
// and run based on a samples transport, the second time based on overlay

int execTest(int nFxID,int iCase,UINT wID,UINT wGroupID)
{
    // Start logging a new section

    int ret = TST_OTHER;
    tstBeginSection(" ");

    // First of all check the parameters look valid

    EXECUTE_ASSERT(nFxID <= ID_TESTLAST);
    EXECUTE_ASSERT(nFxID >= ID_TEST1);
    EXECUTE_ASSERT(wGroupID >= GRP_SAMPLES);
    EXECUTE_ASSERT(wGroupID <= GRP_LAST);

    nFxID -= ID_TEST1;

    // Change the connection type according to the group

    if (wGroupID == GRP_OVERLAY) {
        ChangeConnectionType(IDM_OVERLAY);
    } else {
        ChangeConnectionType(IDM_SAMPLES);
    }

    // Execute the test case

    ASSERT(TestCaseMap[nFxID].pTestCase);
    ret = (*TestCaseMap[nFxID].pTestCase)();
    tstEndSection();
    return ret;
}


//==========================================================================
//
//  void tstTerminate
//
//  Description:
//      This function is called when the test series is finished to free
//      structures and do whatever cleanup work it needs to do. If it
//      needs not do anything it may just return but it must be defined
//
//==========================================================================

void tstTerminate()
{
    // If we are asked to close we initiate the destruction
    // of all the objects that may be currently allocated

    if (bCreated == TRUE) {
        ReleaseStream();
    }

    ResetActiveMovie();
    SetDisplayMode(IDM_MODE);
    ReleaseDirectDraw();
    DbgTerminate();
    CoUninitialize();
}


//==========================================================================
//
//  LRESULT tstAppWndProc
//
//  Description:
//      This shows how a test application can trap the window messages
//      received by the main Test Shell window. It is installed in
//      in tstInit by calling tstInstallDefWindowProc, and receives
//      all window messages since. This allows the test application to
//      be notified of certain event via a window without creating its
//      own hidden window or waiting in a tight PeekMessage() loop. Note
//      that it is extremely important to call DefWindowProcA in the default
//      case as that is NOT done in tstshell's main window procedure if
//      tstInstallDefWindowProc is used. DefWindowProcA has to be used
//      as the test shell main window is an ANSI window.
//
//  Arguments:
//      HWND hWnd: A handle to the window
//      UINT msg: The message to be processed
//      WPARAM wParam: The first parameters, meaning depends on msg
//      LPARAM lParam: The second parameter, meaning depends on msg
//
//==========================================================================

LRESULT tstAppWndProc(HWND hWnd,
                      UINT msg,
                      WPARAM wParam,
                      LPARAM lParam)
{
    HRESULT hr = NOERROR;
    switch (msg)
    {
        case WM_COMMAND:

            // The number of display modes we support is variable according
            // to the number the current DirectDraw display driver supports
            // We load the number available to dwDisplayModes when we setup
            // the test application and can therefore check here it is is
            // one of those submenu items being selected (ie clicked on)

            if (wParam >= IDM_MODE) {
                if (wParam <= IDM_MODE + dwDisplayModes) {
                    SetDisplayMode(wParam);
                    return (LRESULT) 0;
                }
            }

            switch (wParam) {

                // Manage the filter state changes

                case IDM_STOP:
                    StopSystem();
                    return (LRESULT) 0;

                case IDM_PAUSE:
                    PauseSystem();
                    return (LRESULT) 0;

                case IDM_RUN:
                    StartSystem(TRUE);
                    return (LRESULT) 0;

                // These initialise the filters and their connections

                case IDM_CREATE:
                    CreateStream();
                    return (LRESULT) 0;

                case IDM_RELEASE:
                    ReleaseStream();
                    return (LRESULT) 0;

                case IDM_CONNECT:
                    ConnectStream();
                    return (LRESULT) 0;

                case IDM_DISCONNECT:
                    DisconnectStream();
                    return (LRESULT) 0;

                // Handle loading and unloading DirectDraw

                case IDM_LOADED:
                    InitDirectDraw();
                    return (LRESULT) 0;

                case IDM_UNLOADED:
                    ReleaseDirectDraw();
                    return (LRESULT) 0;

                // Extra debug facilties

                case IDM_DUMP:
                    DumpTestObjects();
                    return (LRESULT) 0;

                case IDM_BREAK:
                    DebugBreak();
                    return (LRESULT) 0;

                // Change the type of connection we make

                case IDM_OVERLAY:
                case IDM_SAMPLES:

                    ChangeConnectionType(wParam);
                    return (LRESULT) 0;

                // Change the type of DCI/DirectDraw surface we can use

                case IDM_NONE:
                case IDM_DCIPS:
                case IDM_PS:
                case IDM_RGBOVR:
                case IDM_YUVOVR:
                case IDM_RGBOFF:
                case IDM_YUVOFF:
                case IDM_RGBFLP:
                case IDM_YUVFLP:

                    SetSurfaceMenuCheck(wParam);
                    return (LRESULT) 0;

                // These change the DIB we use for the test image

                case IDM_WIND8:
                case IDM_WIND555:
                case IDM_WIND565:
                case IDM_WIND24:

                    // Must be disconnected to change the image

                    hr = LoadDIB(wParam,&VideoInfo,bImageData);
                    if (SUCCEEDED(hr)) {
                        SetImageMenuCheck(wParam);
                    }
                    return (LRESULT) 0;

                // Change the time increment between video samples

                case IDM_SETTIMEINCR:
                    DialogBox(hinst,
                              TEXT("SetTimeIncrDlg"),
                              hWnd,
                              SetTimeIncrDlgProc);	
                    return (LRESULT) 0;
            }
            break;
    }
    return DefWindowProcA(hWnd,msg,wParam,lParam);
}


//==========================================================================
//
//   void SaveCustomProfile
//
//   Description:
//       This function saves custom environment info into a profile. It is
//       installed by calling tstInstallWriteCustomInfo from tstGetTestInfo
//       and is called during normal profile handling in SaveProfile.
//
//       Assumes the profile file was created from scratch by the calling
//       function.
//
//       Custom data for this app:
//           [custom settings]   - section for custom settings
//               TimeIncrement       - value of time increment in ms
//               ConnectionType      - Overlay or Samples
//               Image               - IDM_RGB555 for example
//               SurfaceType         - IDM_RGBOVR (also for example)
//
//   Arguments:
//           LPCSTR szProfileName: name of profile file
//
//   Return (void):
//
//==========================================================================

VOID CALLBACK SaveCustomProfile(LPCSTR pszProfileName)
{
    HANDLE      hProfile;
    TCHAR       szLine[128];
    CHAR        szBuf[128];
    DWORD       dwNumberOfBytesWritten;
    LPCTSTR     tszProfileName;

#ifdef UNICODE
    WCHAR   wszProfileName[128];
    MultiByteToWideChar(CP_ACP,0,pszProfileName,-1,wszProfileName,128);
    tszProfileName = wszProfileName;
#else
    tszProfileName = pszProfileName;
#endif

    hProfile = CreateFile(tszProfileName,
                          GENERIC_WRITE,
                          0,
                          NULL,
                          OPEN_ALWAYS,
                          FILE_ATTRIBUTE_NORMAL,
                          NULL);

    if (INVALID_HANDLE_VALUE == hProfile) {
        wsprintf(szLine, TEXT("Cannot open %s for writing"), tszProfileName);
        MessageBox(ghwndTstShell, szLine, szAppName,MB_ICONEXCLAMATION | MB_OK);
        return;
    }

    if (INFINITE == SetFilePointer(hProfile, 0, NULL, FILE_END)) {
        wsprintf(szLine, TEXT("Could not seek to end of %s"), tszProfileName);
        MessageBox(ghwndTstShell, szLine, szAppName,MB_ICONEXCLAMATION | MB_OK);
        return;
    }

    wsprintfA(szBuf, "[custom settings]\r\n");
    WriteFile(hProfile, szBuf, lstrlenA(szBuf), &dwNumberOfBytesWritten, NULL);

    wsprintfA(szBuf, "TimeIncrement=%lu\r\n", dwIncrement);
    WriteFile(hProfile, szBuf, lstrlenA(szBuf), &dwNumberOfBytesWritten, NULL);

    wsprintfA(szBuf,"ConnectionType=%s\r\n",
              (uiCurrentConnectionItem == IDM_OVERLAY ? "Overlay" : "Samples"));
    WriteFile(hProfile, szBuf, lstrlenA(szBuf), &dwNumberOfBytesWritten, NULL);

    // Store the current image type

    wsprintfA(szBuf,"Image=%d\r\n",uiCurrentImageItem);
    WriteFile(hProfile,szBuf,lstrlenA(szBuf),&dwNumberOfBytesWritten,NULL);

    // Store the current surface type

    wsprintfA(szBuf,"SurfaceType=%d\r\n",uiCurrentSurfaceItem);
    WriteFile(hProfile,szBuf,lstrlenA(szBuf),&dwNumberOfBytesWritten,NULL);
    CloseHandle(hProfile);
}


//==========================================================================
//
//   BOOL LoadCustomProfile
//
//   Description:
//       This function loads custom environment info from a profile. It is
//       installed by calling tstInstallReadCustomInfo from tstGetTestInfo,
//       and is called during normal profile handling in LoadProfile.
//
//       Custom data for this app:
//           [custom settings]   - section for custom settings
//               TimeIncrement       - value of time increment in ms
//               ConnectionType      - Overlay or Samples
//               Image               - IDM_RGB555 for example
//               SurfaceType         - IDM_RGBOVR (also for example)
//
//   Arguments:
//           LPCSTR szProfileName: name of profile file
//
//   Return (void):
//
//==========================================================================

VOID CALLBACK LoadCustomProfile(LPCSTR pszProfileName)
{
    TCHAR       szBuf[128];
    HANDLE      hProfile;
    LPCTSTR     tszProfileName;

#ifdef UNICODE
    WCHAR   wszProfileName[128];
    MultiByteToWideChar(CP_ACP,0,pszProfileName,-1,wszProfileName,128);
    tszProfileName = wszProfileName;
#else
    tszProfileName = pszProfileName;
#endif

    hProfile = CreateFile(tszProfileName,
                          GENERIC_READ,
                          (DWORD) 0,
                          NULL,
                          OPEN_EXISTING,
                          FILE_ATTRIBUTE_NORMAL,
                          NULL);

    if (INVALID_HANDLE_VALUE == hProfile) {
        wsprintf(szBuf, TEXT("Cannot open profile %hs"), pszProfileName);
        MessageBox(ghwndTstShell, szBuf, szAppName,MB_ICONEXCLAMATION | MB_OK);
    }

    CloseHandle(hProfile);

    // Read the time increment setting

    wsprintf(szBuf, TEXT("%lu"), dwIncrement);
    GetPrivateProfileString(TEXT("custom settings"),
                            TEXT("TimeIncrement"),
                            szBuf,
                            szBuf,
                            MAX_PATH,
                            tszProfileName);
    dwIncrement = _tcstoul(szBuf, NULL, 10);

    // Read the connection type

    wsprintf(szBuf, TEXT("%s"), "Samples");
    GetPrivateProfileString(TEXT("custom settings"),
                            TEXT("ConnectionType"),
                            szBuf,
                            szBuf,
                            MAX_PATH,
                            tszProfileName);
    ChangeConnectionType(0 == lstrcmp(szBuf, TEXT("Samples")) ?
                         IDM_SAMPLES : IDM_OVERLAY);

    // Read the image type we should use

    wsprintf(szBuf,TEXT("%u"),IDM_WIND8);
    GetPrivateProfileString(TEXT("custom settings"),
                            TEXT("Image"),
                            szBuf,
                            szBuf,
                            MAX_PATH,
                            tszProfileName);

    UINT uiMenuItem = _tcstoul(szBuf, NULL, 10);
    LoadDIB(uiMenuItem,&VideoInfo,bImageData);
    SetImageMenuCheck(uiMenuItem);

    // Read the surface type we should use

    wsprintf(szBuf,TEXT("%u"),IDM_NONE);
    GetPrivateProfileString(TEXT("custom settings"),
                            TEXT("SurfaceType"),
                            szBuf,
                            szBuf,
                            MAX_PATH,
                            tszProfileName);

    UINT uiSurfaceItem = _tcstoul(szBuf, NULL, 10);
    SetSurfaceMenuCheck(uiSurfaceItem);
}


//==========================================================================
//
//  void Log
//
//  Description:
//      This is a fairly thin wrapper around the test shell entry provided
//      for debug logging (tstLog). The function simply passes on the log
//      level it is passed in (normally either VERBOSE or TERSE) so that
//      the test shell function can determine whether to display it or not
//
//==========================================================================

void Log(UINT iLogLevel,LPTSTR text)
{
    // If we can't log yet then yield to message queue

    while (LogEvent.Check() == FALSE) {
        tstWinYield();
    }

    tstLog(iLogLevel,text);
    LogEvent.Set();
}


//==========================================================================
//
//  void LogFlush
//
//  Description:
//      Similar to the previous Log function that we use to flush pending
//      stuff to the window. Because we also grab the logging critical
//      section we go through the same event to make sure the application
//      thread does not get blocked thereby deadlocking the whole test
//
//==========================================================================

void LogFlush()
{
    // If we can't log yet then yield to message queue

    while (LogEvent.Check() == FALSE) {
        tstWinYield();
    }

    tstLogFlush();
    LogEvent.Set();
}


//==========================================================================
//
//  BOOL DumpTestObjects
//
//  Description:
//      In DEBUG builds the video renderer exports a special entry point
//      called DbgDumpObjectRegister (actually it's exported by the base
//      classes it uses) so we provide a menu option to call this entry
//      point. What it will do is to dump all the C++ objects currently
//      active. This is useful to call to see the current object state
//
//==========================================================================

typedef void (*PDUMP)(void);

BOOL DumpTestObjects()
{
    DbgDumpObjectRegister();

    // Get a module handle for the image renderer

    HMODULE hModule = GetModuleHandle(TEXT("IMAGE.DLL"));
    if (hModule == NULL) {
        return FALSE;
    }

    // Get the DLL address of DbgDumpObjectRegister

    PDUMP pDump = (PDUMP) GetProcAddress(hModule,"DbgDumpObjectRegister");
    if (pDump == NULL) {
        return FALSE;
    }

    pDump();
    return TRUE;
}


//==========================================================================
//
//  BOOL InitialiseTest
//
//  Description:
//      The test shell calls the tstInit entry point when the application is
//      loaded. That function then calls us to reset the test state. All we
//      do is to load a default DIB image (if this can't be found them the
//      test application will terminate) and set the current image menu
//
//==========================================================================

BOOL InitialiseTest()
{
    // Set the default connection and surface types

    ChangeConnectionType(IDM_SAMPLES);
    SetSurfaceMenuCheck(IDM_NONE);
    InitDirectDraw();
    SetDisplayModeMenu(IDM_MODE);
    ResetDDCount();

    // Load the default DIB image from the current directory

    HRESULT hr = LoadDIB(DEFAULT,&VideoInfo,bImageData);
    if (FAILED(hr)) {
        MessageBox(ghwndTstShell,
                   TEXT("Could not load test image"),
                   TEXT("Load"),
                   MB_OK | MB_ICONSTOP);
        return FALSE;
    }

    // Display the period between frames we will send

    SetImageMenuCheck(DEFAULT);
    wsprintf(szInfo,TEXT("Frame period %d ms"),dwIncrement);
    Log(TERSE,szInfo);
    return TRUE;
}


//==========================================================================
//
//  void SetImageMenuCheck
//
//  Description:
//      Another fairly straightforward helper function. This time we are
//      passed the identifier from the current image menu. We unset the
//      old check mark and then set the check mark for the current item
//
//==========================================================================

void SetImageMenuCheck(UINT uiMenuItem)
{
    // Unset the old image choice and then set our current mark

    if (uiCurrentImageItem) {
        CheckMenuItem(hImageMenu,uiCurrentImageItem,MF_BYCOMMAND | MF_UNCHECKED);
    }
    CheckMenuItem(hImageMenu,uiMenuItem,MF_BYCOMMAND | MF_CHECKED);
    uiCurrentImageItem = uiMenuItem;
}


//==========================================================================
//
//  void SetConnectionMenuCheck
//
//  Description:
//      This sets the current connection mechanism, either using the normal
//      media samples (IMemInputPin) or an overlay transport (IOverlay). If
//      the test application is already running with some connected objects
//      then this will be rejected until they are disconnected (the video
//      renderer does not support the changing of transports while running)
//
//==========================================================================

void SetConnectionMenuCheck(UINT uiMenuItem)
{
    // Unset the old connection choice and then set our current mark

    if (uiCurrentConnectionItem) {
        CheckMenuItem(hConnectionMenu,uiCurrentConnectionItem,MF_BYCOMMAND | MF_UNCHECKED);
    }
    CheckMenuItem(hConnectionMenu,uiMenuItem,MF_BYCOMMAND | MF_CHECKED);
    uiCurrentConnectionItem = uiMenuItem;
}


//==========================================================================
//
//  void SetSurfaceMenuCheck
//
//  Description:
//      Sets the type of DCI/DirectDraw surfaces we will use when running
//      the test suite. Each time the test application connects up our
//      source filter to the video renderer it queries for the DirectDraw
//      control interface and adjusts it's options accordingly
//
//==========================================================================

void SetSurfaceMenuCheck(UINT uiMenuItem)
{
    // Unset the old surface choice and then set our current mark

    if (uiCurrentSurfaceItem) {
        CheckMenuItem(hSurfaceMenu,uiCurrentSurfaceItem,MF_BYCOMMAND | MF_UNCHECKED);
    }
    CheckMenuItem(hSurfaceMenu,uiMenuItem,MF_BYCOMMAND | MF_CHECKED);
    uiCurrentSurfaceItem = uiMenuItem;
}


//==========================================================================
//
//  void ChangeConnectionType
//
//  Description:
//      One of the most useful aspects to this unit test is being able to
//      test small areas of functionality individually. We can change the
//      type of connection we will make based on menu settings, it can be
//      either samples (using IMemInputPin) or overlay (using IOverlay)
//
//==========================================================================

void ChangeConnectionType(UINT uiMenuItem)
{
    // Check there is no current connection

    if (bConnected == TRUE) {

        MessageBox(ghwndTstShell,
                   TEXT("Objects are already connected"),
                   TEXT("Change connection type"),
                   MB_ICONEXCLAMATION | MB_OK);
        return;
    }

    // Check we are not running

    if (bRunning == TRUE) {

        MessageBox(ghwndTstShell,
                   TEXT("System is running"),
                   TEXT("Change connection type"),
                   MB_ICONEXCLAMATION | MB_OK);
        return;
    }
    SetConnectionMenuCheck(uiMenuItem);
}


//==========================================================================
//
//  BOOL CALLBACK SetTimeIncrDlgproc
//
//  Description:
//      The time difference between successive samples sent by our source
//      filter can be changed with the image menu. If the time between them
//      is too small the renderer may drop frames so you can't easily count
//      the performance in drawing unless you don't give the renderer a
//      clock to use in which case it will run flat out unsynchronised
//
//==========================================================================

BOOL CALLBACK SetTimeIncrDlgProc(HWND hwndDlg,      // Handle of dialog box
                                 UINT uMsg,         // Message details
                                 WPARAM wParam,     // Message parameter
                                 LPARAM lParam)     // Message parameter
{
    TCHAR ach[128];

    switch (uMsg) {

        case WM_COMMAND:

            switch (LOWORD(wParam)) {

                case IDOK:

                    // Set dwIncrement to value of edit box text and exit

                    GetDlgItemText(hwndDlg, IDC_EDIT1, ach, 128);
                    dwIncrement = _tcstoul(ach, NULL, 10);
                    EndDialog(hwndDlg, TRUE);
                    break;

                case IDCANCEL:

                    EndDialog(hwndDlg, FALSE);
                    break;
            }
            break;

        case WM_INITDIALOG:

            // Set edit box text to value of dwIncrement and select it

            wsprintf(ach, TEXT("%u"), dwIncrement);
            SetDlgItemText(hwndDlg, IDC_EDIT1, ach);	
            SendDlgItemMessage(hwndDlg, IDC_EDIT1, EM_SETSEL, 0, -1);
            SetFocus(GetDlgItem(hwndDlg, IDC_EDIT1));
            return FALSE;
    }
    return FALSE;
}


//==========================================================================
//
//  void ImageAssert
//
//  Description:
//      This implements a function that will be called through the ASSERT
//      macros when a condition fails. We redefine this function from that
//      implemented in the base classes so that this is always available
//      regardless of whether we are being build for retail or debug tests
//
//==========================================================================

void ImageAssert(const TCHAR *pCondition,const TCHAR *pFileName,INT iLine)
{
    TCHAR szInfo[128];

    wsprintf(szInfo, TEXT("%s \nAt line %d of %s\nContinue? (Cancel to debug)"),
             pCondition, iLine, pFileName);

    INT MsgId = MessageBox(NULL,szInfo,TEXT("ASSERT Failed"),
                           MB_SYSTEMMODAL |
                           MB_ICONHAND |
                           MB_YESNOCANCEL |
                           MB_SETFOREGROUND);
    switch (MsgId)
    {
        case IDNO:              // Kill the application

            FatalAppExit(FALSE,TEXT("Application terminated"));
            break;

        case IDCANCEL:          // Break into the debugger
            DebugBreak();
            break;

        case IDYES:             // Ignore assertion continue execution
            break;
    }
}


//==========================================================================
//
//  void DisplayMediaType
//
//  Description:
//      If built for debug this will display the media type information. We
//      convert the major and subtypes into strings and ask the base classes
//      for a string description of the subtype, so MEDIASUBTYPE_RGB565 will
//      become RGB 565. We also display the fields in the BITMAPINFOHEADER
//
//==========================================================================

void DisplayMediaType(const CMediaType *pmtIn)
{
    #ifdef DEBUG

    // Dump the GUID types and a short description

    NOTE("Media Type Description");
    NOTE1("Major type %s",GuidNames[*pmtIn->Type()]);
    NOTE1("Subtype %s",GuidNames[*pmtIn->Subtype()]);
    NOTE1("Subtype description %s",GetSubtypeName(pmtIn->Subtype()));

    // Dump the generic media types

    NOTE1("Fixed size sample %d",pmtIn->IsFixedSize());
    NOTE1("Temporal compression %d",pmtIn->IsTemporalCompressed());
    NOTE1("Sample size %d",pmtIn->GetSampleSize());
    NOTE1("Format size %d",pmtIn->FormatLength());

    // Dump the contents of the BITMAPINFOHEADER structure
    BITMAPINFOHEADER *pbmi = HEADER(pmtIn->Format());
    VIDEOINFO *pVideoInfo = (VIDEOINFO *)pmtIn->Format();

    NOTE4("Source rectangle (Left %d Top %d Right %d Bottom %d)",
          pVideoInfo->rcSource.left,
          pVideoInfo->rcSource.top,
          pVideoInfo->rcSource.right,
          pVideoInfo->rcSource.bottom);

    NOTE4("Target rectangle (Left %d Top %d Right %d Bottom %d)",
          pVideoInfo->rcTarget.left,
          pVideoInfo->rcTarget.top,
          pVideoInfo->rcTarget.right,
          pVideoInfo->rcTarget.bottom);

    NOTE1("Size of BITMAPINFO structure %d",pbmi->biSize);
    NOTE1("Image width %d",pbmi->biWidth);
    NOTE1("Image height %d",pbmi->biHeight);
    NOTE1("Planes %d",pbmi->biPlanes);
    NOTE1("Bit count %d",pbmi->biBitCount);
    NOTE1("Compression type %d",pbmi->biCompression);
    NOTE1("Image size %d",pbmi->biSizeImage);
    NOTE1("X Pels per metre %d",pbmi->biXPelsPerMeter);
    NOTE1("Y Pels per metre %d",pbmi->biYPelsPerMeter);
    NOTE1("Colours used %d",pbmi->biClrUsed);

    #endif
}


//==========================================================================
//
// BOOL InitDisplayModes()
//
// This is called when the application is started to load the display modes
// menu with those available through DirectDraw. DirectDraw allows us to
// change the display mode for an application (typically used by games) to
// fill the whole screen cheaply. When running all the tests we go through
// all the modes one by one running the entire test suite on each of them.
//
//==========================================================================

BOOL InitDisplayModes()
{
    // Remove all the current display modes

    for (DWORD Mode = dwDisplayModes;Mode >= 1;Mode--) {
        RemoveMenu(hModesMenu,Mode,MF_BYPOSITION);
    }

    dwDisplayModes = 0;

    // Do we have DirectDraw loaded

    if (pDirectDraw == NULL) {
        CheckMenuItem(hDirectDrawMenu,0,MF_BYPOSITION | MF_UNCHECKED);
        CheckMenuItem(hDirectDrawMenu,1,MF_BYPOSITION | MF_CHECKED);
        return FALSE;
    }

    CheckMenuItem(hDirectDrawMenu,0,MF_BYPOSITION | MF_CHECKED);
    CheckMenuItem(hDirectDrawMenu,1,MF_BYPOSITION | MF_UNCHECKED);

    // Enumerate all the available display modes

    pDirectDraw->EnumDisplayModes((DWORD) 0,              // Surface count
                                  NULL,                   // Template
                                  (PVOID)&dwDisplayModes, // Submenu place
                                  MenuCallBack);          // Function call
    return TRUE;
}


//==========================================================================
//
// HRESULT CALLBACK MenuCallBack(LPDDSURFACEDESC pSurfaceDesc,LPVOID lParam)
//
// We set up an enumerator with DirectDraw and will be called back in here
// for each display mode that is available. For each mode we add a menu
// item to the modes submenu. There is always a "Current Mode" menu item
// that has an identifier IDM_MODE, so our items we append afterwards are
// given successive identifiers after this. We know how far we are along
// by keeping a DWORD count in a variable passed in as the user data field.
//
//==========================================================================

HRESULT CALLBACK MenuCallBack(LPDDSURFACEDESC pSurfaceDesc,LPVOID lParam)
{
    // Ignore display modes less than 640x400

    if (pSurfaceDesc->dwWidth < 640 || pSurfaceDesc->dwHeight < 400) {
        return S_FALSE;
    }

    DWORD *pDisplayModes = (DWORD *) lParam;
    TCHAR FormatString[128];
    (*pDisplayModes)++;

    wsprintf(FormatString,TEXT("%dx%dx%d (%d bytes)"),
             pSurfaceDesc->dwWidth,
             pSurfaceDesc->dwHeight,
             pSurfaceDesc->ddpfPixelFormat.dwRGBBitCount,
             pSurfaceDesc->lPitch);

    AppendMenu(hModesMenu,                  // Modes menu handle
               MF_STRING,                   // Giving it a string
               IDM_MODE + *pDisplayModes,   // Its identifier
               FormatString);               // And the string

    return S_FALSE;     // Return NOERROR to STOP enumerating
}


//==========================================================================
//
// BOOL InitDirectDraw
//
// This function loads the DirectDraw DLL dynamically, this is so the video
// renderer can still be loaded and executed where DirectDraw is unavailable
// If we successfully load the DLL we hold a handle on it until we're killed
// I'm not sure whether calling DirectDrawCreate will increment this so best
// to be safe. Having successfully loaded and initialised the DLL we ask it
// for a DIRECTDRAW interface through which we query it's capabilities and
// display them. We also use DirectDraw to change display modes dynamically
//
//==========================================================================

BOOL InitDirectDraw()
{
    // Is DirectDraw already loaded

    if (pDirectDraw) {
        return TRUE;
    }

    ASSERT(pDirectDraw == NULL);
    ASSERT(hDirectDraw == NULL);

    // Make sure the library is available

    hDirectDraw = LoadLibrary(TEXT("DDRAW.DLL"));
    if (hDirectDraw == NULL) {
        ReleaseDirectDraw();
        return FALSE;
    }

    // Get the DLL address for the creation function

    PROC pProc = GetProcAddress(hDirectDraw,"DirectDrawCreate");
    if (pProc == NULL) {
        ReleaseDirectDraw();
        return FALSE;
    }

    PDRAWCREATE pDrawCreate = (PDRAWCREATE) pProc;

    // Create a default display DirectDraw provider

    HRESULT hr = pDrawCreate(NULL,&pDirectDraw,NULL);
    if (FAILED(hr)) {
        ReleaseDirectDraw();
        return FALSE;
    }
    return InitDisplayModes();
}


//==========================================================================
//
// BOOL ReleaseDirectDraw
//
// Called to release any DirectDraw provider we previously loaded. We may be
// called at any time especially when something goes horribly wrong and when
// we need to clean up before returning so we can't guarantee that all state
// variables are consistent so free only those really allocated allocated
//
//==========================================================================

BOOL ReleaseDirectDraw()
{
    // Release any DirectDraw provider interface

    if (pDirectDraw) {
        pDirectDraw->Release();
        pDirectDraw = NULL;
    }

    // Decrement module load count

    FreeLibrary(hDirectDraw);
    hDirectDraw = NULL;
    return InitDisplayModes();
}


//==========================================================================
//
// SetDisplayMode(UINT uiMode)
//
// This can be called to set the display mode. The uiMode should only be
// between IDM_MODE and IDM_MODE plus dwDisplayModes. If the uiMode equals
// IDM_MODE then we are being asked to restore the original display mode.
// Anybody changing the display mode should make sure they call this after
// they have finished with the different display mode they changed it to.
//
//==========================================================================

void SetDisplayMode(UINT uiMode)
{
    ASSERT(uiMode <= IDM_MODE + dwDisplayModes);
    ASSERT(uiMode >= IDM_MODE);
    TCHAR LogString[128];

    // Do we have a DirectDraw driver

    if (pDirectDraw == NULL || uiMode == uiCurrentDisplayMode) {
        return;
    }

    // Should we be setting the old mode back again

    if (uiMode == IDM_MODE) {
        pDirectDraw->RestoreDisplayMode();
        SetDisplayModeMenu(IDM_MODE);
        return;
    }

    // To change display modes requires exclusive access

    HRESULT hr = pDirectDraw->SetCooperativeLevel(ghwndTstShell,
                                                  DDSCL_EXCLUSIVE |
                                                  DDSCL_NOWINDOWCHANGES |
                                                  DDSCL_FULLSCREEN);
    if (FAILED(hr)) {
        if (hr != DDERR_HWNDALREADYSET) {
            wsprintf(LogString,TEXT("Error %lx setting cooperative level"),hr);
            Log(TERSE,LogString);
            return;
        }
    }

    // Get the required display mode settings

    TCHAR MenuString[128];
    DWORD Width,Height,BitDepth;
    GetMenuString(hModesMenu,uiMode,MenuString,128,MF_BYCOMMAND);
    sscanf(MenuString,TEXT("%dx%dx%d"),&Width,&Height,&BitDepth);

    // Change the display mode and set the cooperation level back

    hr = pDirectDraw->SetDisplayMode(Width,Height,BitDepth);
    pDirectDraw->SetCooperativeLevel(ghwndTstShell,DDSCL_NORMAL);

    if (FAILED(hr)) {
        if (hr != DDERR_HWNDALREADYSET) {
            wsprintf(LogString,TEXT("Error %lx mode %dx%dx%d"),hr,Width,Height,BitDepth);
            Log(TERSE,LogString);
            return;
        }
    }
    wsprintf(LogString,TEXT("Changed mode %dx%dx%d"),Width,Height,BitDepth);
    Log(TERSE,LogString);
    SetDisplayModeMenu(uiMode);
}


//==========================================================================
//
//  void SetDisplayModeMenu
//
//  Description:
//      Sets a check mark against the current display mode.
//
//==========================================================================

void SetDisplayModeMenu(UINT uiMode)
{
    ASSERT(uiMode <= IDM_MODE + dwDisplayModes);
    ASSERT(uiMode >= IDM_MODE);

    // Unset the old display mode and then set the new one

    if (uiCurrentDisplayMode) {
        CheckMenuItem(hModesMenu,uiCurrentDisplayMode,MF_BYCOMMAND | MF_UNCHECKED);
    }
    CheckMenuItem(hModesMenu,uiMode,MF_BYCOMMAND | MF_CHECKED);
    uiCurrentDisplayMode = uiMode;
}


//==========================================================================
//
//  void ResetDDCount, IncrementDDCount and (DWORD) GetDDCount
//
//  Description:
//      The samples from the video renderer expose IDirectDrawSurface and
//      IDirectDraw if they are DirectDraw surface buffers. While we are
//      running we keep a track on the number of samples that have these
//      surfaces available so that we can check they are there. When we
//      log the performance statistics we also log this DirectDraw count
//
//==========================================================================

void ResetDDCount()
{
    dwDDCount = 0;
}

void IncrementDDCount()
{
    dwDDCount++;
}

DWORD GetDDCount()
{
    return dwDDCount;
}
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\multimedia\dshow\filters\image\vidtest\imagewnd.cpp ===
// Copyright (c) Microsoft Corporation 1994-1996. All Rights Reserved
// Video renderer control interface test, Anthony Phillips, July 1995

#include <streams.h>        // Includes all the IDL and base classes
#include <windows.h>        // Standard Windows SDK header file
#include <windowsx.h>       // Win32 Windows extensions and macros
#include <vidprop.h>        // Shared video properties library
#include <render.h>         // Normal video renderer header file
#include <modex.h>          // Specialised Modex video renderer
#include <convert.h>        // Defines colour space conversions
#include <colour.h>         // Rest of the colour space convertor
#include <imagetst.h>       // All our unit test header files
#include <stdio.h>          // Standard C runtime header file
#include <limits.h>         // Defines standard data type limits
#include <tchar.h>          // Unicode and ANSII portable types
#include <mmsystem.h>       // Multimedia used for timeGetTime
#include <stdlib.h>         // Standard C runtime function library
#include <tstshell.h>       // Definitions of constants eg TST_FAIL

TCHAR WindowText[INFO];
HWND hVideoWindow;
WCHAR WideWindowText[INFO];

// This is called once for each top level window currently in the system. We
// retrieve the window title and match it against the caption that we put in
// our video window, the caption is passed in as the user defined parameter
// Because of the callback structure to this work we use a couple of global
// variables, one to hold the window handle if we find our video window and
// another as a global work field where we can store the window captions

BOOL CALLBACK EnumAllWindows(HWND hwnd,LPARAM lParam)
{
    BSTR WindowCaption = (BSTR) lParam;
    ASSERT(WindowCaption);
    GetWindowText(hwnd,WindowText,INFO);

    MultiByteToWideChar(CP_ACP,0,WindowText,-1,WideWindowText,INFO);
    if (lstrcmpWInternal(WideWindowText,WindowCaption) == 0) {
        hVideoWindow = hwnd;
    }
    return TRUE;
}

// This can be called to find a video window that we created and that we have
// a IVideoWindow control interface on. What it does is to temporarily set
// the window caption and then go looking for a window that has that matches
// it in all the top level windows, afterwards it resets the caption back

HWND FindVideoWindow(IVideoWindow *pVideoWindow)
{
    BSTR WindowCaption;
    BSTR SaveCaption;
    ASSERT(pVideoWindow);
    hVideoWindow = 0;

    // First of all get the current window caption and then set our own to be
    // one formulated with the current window handle (remembering to copy the
    // C style string into a BSTR as used by the OLE automation interfaces)

    EXECUTE_ASSERT(SUCCEEDED(pVideoWindow->get_Caption(&SaveCaption)));
    wsprintf(WindowText,TEXT("Video renderer %d"),ghwndTstShell);
    MultiByteToWideChar(CP_ACP,0,WindowText,-1,WideWindowText,INFO);
    WindowCaption = SysAllocString(WideWindowText);
    EXECUTE_ASSERT(SUCCEEDED(pVideoWindow->put_Caption(WindowCaption)));

    // Enumerate all the top level windows and see if there is one that has a
    // matching caption name (using Win32 GetWindowText API). Then reset the
    // caption we had before so leaving it untouched and free the BSTRs up

    EnumWindows(EnumAllWindows,(LPARAM)WindowCaption);
    SysFreeString(WindowCaption);
    EXECUTE_ASSERT(SUCCEEDED(pVideoWindow->put_Caption(SaveCaption)));
    SysFreeString(SaveCaption);
    return hVideoWindow;
}


// The IVideoWindow control interface allows an application to change certain
// window styles (although it's use should be cautioned as it can have some
// unpredictable results). This function is passed a long retrieved from the
// interfaces get window style property and displays the settings as they
// apply to Windows. We pause at the end to let the user see the results

void DisplayWindowStyles(LONG style)
{
    Log(TERSE,TEXT("Video window styles"));

    if (style & WS_BORDER) Log(TERSE,TEXT(" WS_BORDER"));
    if (style & WS_CAPTION) Log(TERSE,TEXT(" WS_CAPTION"));
    if (style & WS_CHILD) Log(TERSE,TEXT(" WS_CHILD"));
    if (style & WS_CHILDWINDOW) Log(TERSE,TEXT(" WS_CHILDWINDOW"));
    if (style & WS_CLIPSIBLINGS) Log(TERSE,TEXT(" WS_CLIPSIBLINGS"));
    if (style & WS_DISABLED) Log(TERSE,TEXT(" WS_DISABLED"));
    if (style & WS_DLGFRAME) Log(TERSE,TEXT(" WS_DLGFRAME"));
    if (style & WS_GROUP) Log(TERSE,TEXT(" WS_GROUP"));
    if (style & WS_HSCROLL) Log(TERSE,TEXT(" WS_SCROLL"));
    if (style & WS_MAXIMIZE) Log(TERSE,TEXT(" WS_MAXIMIZE"));
    if (style & WS_MAXIMIZEBOX) Log(TERSE,TEXT(" WS_MAXIMIZEBOX"));
    if (style & WS_MINIMIZE) Log(TERSE,TEXT(" WS_MINIMIZE"));
    if (style & WS_OVERLAPPED) Log(TERSE,TEXT(" WS_OVERLAPPED"));
    if (style & WS_POPUP) Log(TERSE,TEXT(" WS_POPUP"));
    if (style & WS_POPUPWINDOW) Log(TERSE,TEXT(" WS_POPUPWINDOW"));
    if (style & WS_SYSMENU) Log(TERSE,TEXT(" WS_SYSMENU"));
    if (style & WS_TABSTOP) Log(TERSE,TEXT(" WS_TABSTOP"));
    if (style & WS_THICKFRAME) Log(TERSE,TEXT(" WS_THICKFRAME"));
    if (style & WS_VISIBLE) Log(TERSE,TEXT(" WS_VISIBLE"));
    if (style & WS_VSCROLL) Log(TERSE,TEXT(" WS_VSCROLL"));

    YieldAndSleep(2000);
}


// The IVideoWindow control interface allows an application to change certain
// extended window styles (although it's use should be cautioned as it can
// have some unpredictable results). This function is passed a long retrieved
// from the interfaces get extended window style property and displays the
// settings as they apply to Windows - we wait a bit so the user can see them

void DisplayWindowStylesEx(LONG style)
{
    Log(TERSE,TEXT("Video window extended styles"));

    if (style & WS_EX_ACCEPTFILES) Log(TERSE,TEXT(" WS_EX_ACCEPTFILES"));
    if (style & WS_EX_DLGMODALFRAME) Log(TERSE,TEXT(" WS_EX_DLGMODALFRAME"));
    if (style & WS_EX_NOPARENTNOTIFY) Log(TERSE,TEXT(" WS_EX_NOPARENTNOTIFY"));
    if (style & WS_EX_TOPMOST) Log(TERSE,TEXT(" WS_EX_TOPMOST"));
    if (style & WS_EX_TRANSPARENT) Log(TERSE,TEXT(" WS_EX_TRANSPARENT"));

    YieldAndSleep(2000);
}


// This is called by each of the control interface tests as they start and
// when they finish so that we may create and connect the video renderer to
// our source filter and then disconnect and release our resources. In the
// process of connecting we will also query for all the other interfaces we
// use such as IMediaFilter and of course the window control interfaces

void InitialiseWindow()
{
    long Hidden,BitRate,BitErrorRate,Mode;
    REFTIME AvgTime;

    EXECUTE_ASSERT(SUCCEEDED(CreateStream()));
    EXECUTE_ASSERT(SUCCEEDED(ConnectStream()));
    EXECUTE_ASSERT(SUCCEEDED(FindVideoWindow(pVideoWindow)));

    // Since these never change we might as well check them here

    EXECUTE_ASSERT(SUCCEEDED(pBasicVideo->get_AvgTimePerFrame(&AvgTime)));
    EXECUTE_ASSERT(AvgTime == (double) COARefTime((REFERENCE_TIME)AVGTIME));
    EXECUTE_ASSERT(SUCCEEDED(pBasicVideo->get_BitRate(&BitRate)));
    EXECUTE_ASSERT(BitRate == BITRATE);
    EXECUTE_ASSERT(SUCCEEDED(pBasicVideo->get_BitErrorRate(&BitErrorRate)));
    EXECUTE_ASSERT(BitErrorRate == BITERRORRATE);
    EXECUTE_ASSERT(pVideoWindow->get_FullScreenMode(&Mode) == E_NOTIMPL);
    EXECUTE_ASSERT(pVideoWindow->put_FullScreenMode(OATRUE) == E_NOTIMPL);
    EXECUTE_ASSERT(pVideoWindow->put_FullScreenMode(OAFALSE) == E_NOTIMPL);
    EXECUTE_ASSERT(SUCCEEDED(pVideoWindow->IsCursorHidden(&Hidden)));
    EXECUTE_ASSERT(Hidden == OAFALSE);
}


// Disconnect and release the filters

void TerminateWindow()
{
    EXECUTE_ASSERT(SUCCEEDED(DisconnectStream()));
    EXECUTE_ASSERT(SUCCEEDED(ReleaseStream()));
}


//==========================================================================
//
//  int execWindowTest1
//
//  Description:
//      This tests the visible property on the IVideoWindow interface. We
//      set and get the property checking that the last operation has been
//      reflected in the current value as returned when getting it. We also
//      make the video window invisible and then check with the operation
//      system that it really did disappear since we know it's window handle
//
//  Return (int): TST_PASS indicating success
//
//==========================================================================

int execWindowTest1()
{
    LONG visible = OATRUE;
    INT Result = TST_PASS;

    Log(TERSE,TEXT("Entering window test #1"));
    LogFlush();
    InitialiseWindow();

    HWND hwndDesktop = GetDesktopWindow();

    // Make the video window visible

    EXECUTE_ASSERT(SUCCEEDED(pVideoWindow->put_Visible(OATRUE)));
    EXECUTE_ASSERT(SUCCEEDED(pVideoWindow->get_Visible(&visible)));
    if (visible != OATRUE) {
        Log(TERSE,TEXT("Visible property not set correctly"));
        return TST_FAIL;
    }

    // Now hide it again

    EXECUTE_ASSERT(SUCCEEDED(pVideoWindow->put_Visible(OAFALSE)));
    EXECUTE_ASSERT(SUCCEEDED(pVideoWindow->get_Visible(&visible)));
    if (visible != OAFALSE) {
        Log(TERSE,TEXT("Invisible property not set correctly"));
        Result = TST_FAIL;
    }

    // Try a bunch of these and ASSERT we are correct

    EXECUTE_ASSERT(SUCCEEDED(pVideoWindow->put_Visible(OATRUE)));
    EXECUTE_ASSERT(SUCCEEDED(pVideoWindow->get_Visible(&visible)));
    EXECUTE_ASSERT(visible == OATRUE);
    EXECUTE_ASSERT(SUCCEEDED(pVideoWindow->put_Visible(OATRUE)));
    EXECUTE_ASSERT(SUCCEEDED(pVideoWindow->get_Visible(&visible)));
    EXECUTE_ASSERT(visible == OATRUE);
    EXECUTE_ASSERT(SUCCEEDED(pVideoWindow->put_Visible(OAFALSE)));
    EXECUTE_ASSERT(SUCCEEDED(pVideoWindow->get_Visible(&visible)));
    EXECUTE_ASSERT(visible == OAFALSE);
    EXECUTE_ASSERT(SUCCEEDED(pVideoWindow->put_Visible(OAFALSE)));
    EXECUTE_ASSERT(SUCCEEDED(pVideoWindow->get_Visible(&visible)));
    EXECUTE_ASSERT(visible == OAFALSE);

    // Check it really did something

    if (IsWindowVisible(hVideoWindow) == TRUE) {
        Log(TERSE,TEXT("Window wasn't actually hidden"));
        return Result = TST_FAIL;
    }

    EXECUTE_ASSERT(SUCCEEDED(pVideoWindow->put_Visible(OAFALSE)));
    EXECUTE_ASSERT(SUCCEEDED(pVideoWindow->get_Visible(&visible)));
    EXECUTE_ASSERT(visible == OAFALSE);

    // Try using the bogus boolean value

    EXECUTE_ASSERT(FAILED(pVideoWindow->put_Visible(OABOGUS)));
    EXECUTE_ASSERT(SUCCEEDED(pVideoWindow->get_Visible(&visible)));
    EXECUTE_ASSERT(visible == OAFALSE);

    Log(TERSE,TEXT("Exiting window test #1"));
    TerminateWindow();
    LogFlush();
    return Result;
}


//==========================================================================
//
//  int execWindowTest2
//
//  Description:
//      The sets the background flag in the video renderer. If this is set
//      to OATRUE then any palette that it uses will be mapped onto the
//      current display palette rather than grabbing and filling it's own
//      entries when the window gets the foreground focus. An application
//      can use this to make sure the video does not disturb it's colours
//
//  Return (int): TST_PASS indicating success
//
//==========================================================================

int execWindowTest2()
{
    LONG palette = OATRUE;
    INT Result = TST_PASS;

    Log(TERSE,TEXT("Entering window test #2"));
    LogFlush();
    InitialiseWindow();

    // Get the current background palette flag

    pVideoWindow->get_BackgroundPalette(&palette);
    if (palette != OAFALSE) {
        Log(TERSE,TEXT("Background flag should default to OAFALSE"));
        Result = TST_FAIL;
    }

    // Make the palette appear in the background

    pVideoWindow->put_BackgroundPalette(OATRUE);
    pVideoWindow->get_BackgroundPalette(&palette);
    if (palette != OATRUE) {
        Log(TERSE,TEXT("Background flag not set to OATRUE correctly"));
        Result = TST_FAIL;
    }

    // Now just try a bunch in succession

    EXECUTE_ASSERT(SUCCEEDED(pVideoWindow->put_BackgroundPalette(OAFALSE)));
    EXECUTE_ASSERT(SUCCEEDED(pVideoWindow->get_BackgroundPalette(&palette)));
    EXECUTE_ASSERT(palette == OAFALSE);
    EXECUTE_ASSERT(SUCCEEDED(pVideoWindow->put_BackgroundPalette(OATRUE)));
    EXECUTE_ASSERT(SUCCEEDED(pVideoWindow->get_BackgroundPalette(&palette)));
    EXECUTE_ASSERT(palette == OATRUE);
    EXECUTE_ASSERT(SUCCEEDED(pVideoWindow->put_BackgroundPalette(OATRUE)));
    EXECUTE_ASSERT(SUCCEEDED(pVideoWindow->get_BackgroundPalette(&palette)));
    EXECUTE_ASSERT(palette == OATRUE);
    EXECUTE_ASSERT(SUCCEEDED(pVideoWindow->put_BackgroundPalette(OAFALSE)));
    EXECUTE_ASSERT(SUCCEEDED(pVideoWindow->get_BackgroundPalette(&palette)));
    EXECUTE_ASSERT(palette == OAFALSE);

    // Try using the bogus boolean value

    EXECUTE_ASSERT(FAILED(pVideoWindow->put_BackgroundPalette(OABOGUS)));
    EXECUTE_ASSERT(SUCCEEDED(pVideoWindow->get_BackgroundPalette(&palette)));
    EXECUTE_ASSERT(palette == OAFALSE);

    Log(TERSE,TEXT("Exiting window test #2"));
    TerminateWindow();
    LogFlush();
    return Result;
}


//==========================================================================
//
//  int execWindowTest3
//
//  Description:
//      This tests the video window position properties, we set all of them
//      in turn (although in different sequencies). The setting of them is
//      meant to be synchronous so not only should they return the changed
//      value if queried straight afterwards but those changes should also
//      be reflected when we go and see if the actual window has moved
//
//  Return (int): TST_PASS indicating success
//
//==========================================================================

int execWindowTest3()
{
    RECT WindowRect;
    long position;
    INT Result = TST_PASS;

    Log(TERSE,TEXT("Entering window test #3"));
    LogFlush();
    InitialiseWindow();

    // Change the position of the video window

    EXECUTE_ASSERT(SUCCEEDED(pVideoWindow->put_Left(10)));
    EXECUTE_ASSERT(SUCCEEDED(pVideoWindow->put_Width(10)));
    EXECUTE_ASSERT(SUCCEEDED(pVideoWindow->put_Height(10)));
    EXECUTE_ASSERT(SUCCEEDED(pVideoWindow->put_Top(10)));

    EXECUTE_ASSERT(SUCCEEDED(pVideoWindow->put_Left(50)));
    EXECUTE_ASSERT(SUCCEEDED(pVideoWindow->put_Width(50)));
    EXECUTE_ASSERT(SUCCEEDED(pVideoWindow->put_Height(50)));
    EXECUTE_ASSERT(SUCCEEDED(pVideoWindow->put_Top(50)));

    EXECUTE_ASSERT(SUCCEEDED(pVideoWindow->put_Left(100)));
    EXECUTE_ASSERT(SUCCEEDED(pVideoWindow->put_Left(150)));
    EXECUTE_ASSERT(SUCCEEDED(pVideoWindow->put_Left(200)));
    EXECUTE_ASSERT(SUCCEEDED(pVideoWindow->put_Width(100)));
    EXECUTE_ASSERT(SUCCEEDED(pVideoWindow->put_Width(150)));
    EXECUTE_ASSERT(SUCCEEDED(pVideoWindow->put_Width(200)));
    EXECUTE_ASSERT(SUCCEEDED(pVideoWindow->put_Height(100)));
    EXECUTE_ASSERT(SUCCEEDED(pVideoWindow->put_Height(150)));
    EXECUTE_ASSERT(SUCCEEDED(pVideoWindow->put_Height(200)));
    EXECUTE_ASSERT(SUCCEEDED(pVideoWindow->put_Top(100)));
    EXECUTE_ASSERT(SUCCEEDED(pVideoWindow->put_Top(150)));
    EXECUTE_ASSERT(SUCCEEDED(pVideoWindow->put_Top(200)));

    // Now check that they really happened

    EXECUTE_ASSERT(GetWindowRect(hVideoWindow,&WindowRect));
    if ((WindowRect.left != 200) || (WindowRect.right != 400) ||
        (WindowRect.top != 200) || (WindowRect.bottom != 400)) {
        Log(TERSE,TEXT("Window rectangle not realised correctly"));
        Result = TST_FAIL;
    }

    // Read the individual properties and check they also match

    EXECUTE_ASSERT(SUCCEEDED(pVideoWindow->get_Left(&position)));
    EXECUTE_ASSERT(position == 200);
    EXECUTE_ASSERT(SUCCEEDED(pVideoWindow->get_Width(&position)));
    EXECUTE_ASSERT(position == 200);
    EXECUTE_ASSERT(SUCCEEDED(pVideoWindow->get_Height(&position)));
    EXECUTE_ASSERT(position == 200);
    EXECUTE_ASSERT(SUCCEEDED(pVideoWindow->get_Top(&position)));
    EXECUTE_ASSERT(position == 200);

    Log(TERSE,TEXT("Exiting window test #3"));
    TerminateWindow();
    LogFlush();
    return Result;
}


//==========================================================================
//
//  int execWindowTest4
//
//  Description:
//      This tests the window position methods IVideoWindow implements. As
//      well as supporting a number of essentially design time properties
//      IVideoWindow has some methods to access the current window position
//      These are better used at run time as they allow all the coordinates
//      to be set in one atomic operation rather than four separate puts
//
//  Return (int): TST_PASS indicating success
//
//==========================================================================

int execWindowTest4()
{
    INT Result = TST_PASS;
    long left,top,width,height;
    RECT WindowRect;

    Log(TERSE,TEXT("Entering window test #4"));
    LogFlush();
    InitialiseWindow();

    // Set a variety of window positions

    EXECUTE_ASSERT(SUCCEEDED(pVideoWindow->SetWindowPosition(10,10,23,56)));
    EXECUTE_ASSERT(SUCCEEDED(pVideoWindow->SetWindowPosition(456,321,23,56)));
    EXECUTE_ASSERT(SUCCEEDED(pVideoWindow->SetWindowPosition(0,0,1,1)));
    EXECUTE_ASSERT(SUCCEEDED(pVideoWindow->SetWindowPosition(23,100,233,156)));
    EXECUTE_ASSERT(SUCCEEDED(pVideoWindow->SetWindowPosition(50,80,250,260)));

    // Now check that they really happened

    EXECUTE_ASSERT(GetWindowRect(hVideoWindow,&WindowRect));
    if ((WindowRect.left != 50) || (WindowRect.right != 300) ||
        (WindowRect.top != 80) || (WindowRect.bottom != 340)) {
        Log(TERSE,TEXT("Window rectangle not realised correctly"));
        Result = TST_FAIL;
    }

    // Read the current window position back a few times

    EXECUTE_ASSERT(SUCCEEDED(pVideoWindow->GetWindowPosition(&left,&top,&width,&height)));
    EXECUTE_ASSERT(SUCCEEDED(pVideoWindow->GetWindowPosition(&left,&top,&width,&height)));
    EXECUTE_ASSERT(SUCCEEDED(pVideoWindow->GetWindowPosition(&left,&top,&width,&height)));

    if ((left != 50) || (top != 80) || (width != 250) || (height != 260)) {
        Log(TERSE,TEXT("Window rectangle not returned correctly"));
        Result = TST_FAIL;
    }

    Log(TERSE,TEXT("Exiting window test #4"));
    TerminateWindow();
    LogFlush();
    return Result;
}


// We test the source properties while we in a stopped state with the window
// invisible, with the renderer paused and running. Then we stop the graph
// and try again (the window should still be visible). Because the source we
// provide is checked at each step the ordering of calls is important. So if
// we set a left position of 10 then the width cannot subsequently be set to
// anything more than 230 (assuming we're using the default 240 pixel image)
// And likewise if the top position is 10 the height limit we can set is 310

int CheckSourceProperties()
{
    long left,top,width,height,position;
    INT Result = TST_PASS;
    ASSERT(pBasicVideo);

    // Reset the source and check the coordinates

    EXECUTE_ASSERT(SUCCEEDED(pBasicVideo->SetDefaultSourcePosition()));
    EXECUTE_ASSERT(SUCCEEDED(pBasicVideo->GetSourcePosition(&left,&top,&width,&height)));
    EXECUTE_ASSERT(pBasicVideo->IsUsingDefaultSource() == NOERROR);
    if ((left != 0) || (width != 320) || (top != 0) || (height != 240)) {
        Log(TERSE,TEXT("Source rectangle not reset correctly"));
        Result = TST_FAIL;
    }

    // Change the source rectangle coordinates to be (100,320,100,240)

    EXECUTE_ASSERT(SUCCEEDED(pBasicVideo->put_SourceWidth(220)));
    EXECUTE_ASSERT(SUCCEEDED(pBasicVideo->put_SourceLeft(100)));
    EXECUTE_ASSERT(SUCCEEDED(pBasicVideo->put_SourceHeight(140)));
    EXECUTE_ASSERT(SUCCEEDED(pBasicVideo->put_SourceTop(100)));
    EXECUTE_ASSERT(pBasicVideo->IsUsingDefaultSource() == S_FALSE);
    YieldAndSleep(250);

    // Read the source coordinates as property values

    EXECUTE_ASSERT(SUCCEEDED(pBasicVideo->get_SourceLeft(&position)));
    EXECUTE_ASSERT(position == 100);
    EXECUTE_ASSERT(SUCCEEDED(pBasicVideo->get_SourceWidth(&position)));
    EXECUTE_ASSERT(position == 220);
    EXECUTE_ASSERT(SUCCEEDED(pBasicVideo->get_SourceTop(&position)));
    EXECUTE_ASSERT(position == 100);
    EXECUTE_ASSERT(SUCCEEDED(pBasicVideo->get_SourceHeight(&position)));
    EXECUTE_ASSERT(position == 140);
    EXECUTE_ASSERT(pBasicVideo->IsUsingDefaultSource() == S_FALSE);
    YieldAndSleep(250);

    // Try some left source coordinate positions

    EXECUTE_ASSERT(FAILED(pBasicVideo->put_SourceLeft(101)));
    EXECUTE_ASSERT(SUCCEEDED(pBasicVideo->put_SourceLeft(99)));
    EXECUTE_ASSERT(SUCCEEDED(pBasicVideo->put_SourceLeft(0)));
    EXECUTE_ASSERT(FAILED(pBasicVideo->put_SourceLeft(-1)));
    EXECUTE_ASSERT(FAILED(pBasicVideo->put_SourceLeft(-100)));
    EXECUTE_ASSERT(FAILED(pBasicVideo->put_SourceLeft(LONG_MIN)));
    EXECUTE_ASSERT(SUCCEEDED(pBasicVideo->get_SourceLeft(&position)));
    EXECUTE_ASSERT(position == 0);
    EXECUTE_ASSERT(SUCCEEDED(pBasicVideo->put_SourceLeft(1)));
    EXECUTE_ASSERT(SUCCEEDED(pBasicVideo->put_SourceLeft(100)));
    EXECUTE_ASSERT(FAILED(pBasicVideo->put_SourceLeft(101)));
    EXECUTE_ASSERT(FAILED(pBasicVideo->put_SourceLeft(LONG_MAX)));
    EXECUTE_ASSERT(SUCCEEDED(pBasicVideo->get_SourceLeft(&position)));
    EXECUTE_ASSERT(position == 100);
    EXECUTE_ASSERT(pBasicVideo->IsUsingDefaultSource() == S_FALSE);
    YieldAndSleep(250);

    // Try some different source widths

    EXECUTE_ASSERT(FAILED(pBasicVideo->put_SourceWidth(221)));
    EXECUTE_ASSERT(SUCCEEDED(pBasicVideo->put_SourceWidth(219)));
    YieldAndSleep(250);
    EXECUTE_ASSERT(FAILED(pBasicVideo->put_SourceWidth(0)));
    EXECUTE_ASSERT(FAILED(pBasicVideo->put_SourceWidth(-1)));
    EXECUTE_ASSERT(FAILED(pBasicVideo->put_SourceWidth(-100)));
    EXECUTE_ASSERT(FAILED(pBasicVideo->put_SourceWidth(LONG_MIN)));
    EXECUTE_ASSERT(SUCCEEDED(pBasicVideo->get_SourceWidth(&position)));
    EXECUTE_ASSERT(position == 219);
    EXECUTE_ASSERT(SUCCEEDED(pBasicVideo->put_SourceWidth(1)));
    EXECUTE_ASSERT(SUCCEEDED(pBasicVideo->put_SourceWidth(220)));
    EXECUTE_ASSERT(FAILED(pBasicVideo->put_SourceWidth(400)));
    EXECUTE_ASSERT(FAILED(pBasicVideo->put_SourceWidth(LONG_MAX)));
    EXECUTE_ASSERT(SUCCEEDED(pBasicVideo->get_SourceWidth(&position)));
    EXECUTE_ASSERT(position == 220);
    EXECUTE_ASSERT(pBasicVideo->IsUsingDefaultSource() == S_FALSE);
    YieldAndSleep(250);

    // Next work on the top coordinate and reset at the end

    EXECUTE_ASSERT(FAILED(pBasicVideo->put_SourceTop(101)));
    EXECUTE_ASSERT(SUCCEEDED(pBasicVideo->put_SourceTop(99)));
    EXECUTE_ASSERT(SUCCEEDED(pBasicVideo->put_SourceTop(100)));
    EXECUTE_ASSERT(FAILED(pBasicVideo->put_SourceTop(-1)));
    EXECUTE_ASSERT(FAILED(pBasicVideo->put_SourceTop(-100)));
    EXECUTE_ASSERT(FAILED(pBasicVideo->put_SourceTop(LONG_MIN)));
    EXECUTE_ASSERT(SUCCEEDED(pBasicVideo->get_SourceTop(&position)));
    EXECUTE_ASSERT(position == 100);
    EXECUTE_ASSERT(SUCCEEDED(pBasicVideo->put_SourceTop(1)));
    EXECUTE_ASSERT(SUCCEEDED(pBasicVideo->put_SourceTop(100)));
    EXECUTE_ASSERT(FAILED(pBasicVideo->put_SourceTop(200)));
    EXECUTE_ASSERT(FAILED(pBasicVideo->put_SourceTop(LONG_MAX)));
    EXECUTE_ASSERT(SUCCEEDED(pBasicVideo->get_SourceTop(&position)));
    EXECUTE_ASSERT(position == 100);
    EXECUTE_ASSERT(pBasicVideo->IsUsingDefaultSource() == S_FALSE);
    YieldAndSleep(250);

    // Finally try the height and also leave it untouched

    EXECUTE_ASSERT(FAILED(pBasicVideo->put_SourceHeight(141)));
    EXECUTE_ASSERT(SUCCEEDED(pBasicVideo->put_SourceHeight(139)));
    EXECUTE_ASSERT(FAILED(pBasicVideo->put_SourceHeight(0)));
    EXECUTE_ASSERT(FAILED(pBasicVideo->put_SourceHeight(-1)));
    EXECUTE_ASSERT(FAILED(pBasicVideo->put_SourceHeight(-100)));
    EXECUTE_ASSERT(FAILED(pBasicVideo->put_SourceHeight(LONG_MIN)));
    EXECUTE_ASSERT(SUCCEEDED(pBasicVideo->get_SourceHeight(&position)));
    EXECUTE_ASSERT(position == 139);
    EXECUTE_ASSERT(SUCCEEDED(pBasicVideo->put_SourceHeight(1)));
    EXECUTE_ASSERT(SUCCEEDED(pBasicVideo->put_SourceHeight(140)));
    EXECUTE_ASSERT(FAILED(pBasicVideo->put_SourceHeight(400)));
    EXECUTE_ASSERT(FAILED(pBasicVideo->put_SourceHeight(LONG_MAX)));
    EXECUTE_ASSERT(SUCCEEDED(pBasicVideo->get_SourceHeight(&position)));
    EXECUTE_ASSERT(position == 140);
    EXECUTE_ASSERT(pBasicVideo->IsUsingDefaultSource() == S_FALSE);
    YieldAndSleep(250);

    // Now check that they really happened

    EXECUTE_ASSERT(SUCCEEDED(pBasicVideo->GetSourcePosition(&left,&top,&width,&height)));
    if ((left != 100) || (width != 220) || (top != 100) || (height != 140)) {
        Log(TERSE,TEXT("Source rectangle not realised correctly"));
        Result = TST_FAIL;
    }

    // Reset the source back to the default values

    EXECUTE_ASSERT(pBasicVideo->IsUsingDefaultSource() == S_FALSE);
    EXECUTE_ASSERT(SUCCEEDED(pBasicVideo->put_SourceLeft(0)));
    EXECUTE_ASSERT(SUCCEEDED(pBasicVideo->put_SourceWidth(320)));
    EXECUTE_ASSERT(SUCCEEDED(pBasicVideo->put_SourceTop(0)));
    EXECUTE_ASSERT(SUCCEEDED(pBasicVideo->put_SourceHeight(240)));
    EXECUTE_ASSERT(pBasicVideo->IsUsingDefaultSource() == NOERROR);
    EXECUTE_ASSERT(pBasicVideo->IsUsingDefaultSource() == NOERROR);
    YieldAndSleep(250);
    return Result;
}


//==========================================================================
//
//  int execWindowTest5
//
//  Description:
//      This tests the video source position properties, we set all of them
//      in turn (although in different sequencies). The setting of them is
//      meant to be synchronous so not only should they return the changed
//      value if queried straight afterwards but those changes should also
//      be reflected when we go and see if the actual window has moved. We
//      should get an error E_INVALIDARG if we send a bad source rectangle
//
//  Return (int): TST_PASS indicating success
//
//==========================================================================

int execWindowTest5()
{
    Log(TERSE,TEXT("Entering window test #5"));
    LogFlush();
    InitialiseWindow();

    // Check the properties in each state

    EXECUTE_ASSERT(CheckSourceProperties() == TST_PASS);
    EXECUTE_ASSERT(SUCCEEDED(PauseSystem()));
    EXECUTE_ASSERT(CheckSourceProperties() == TST_PASS);
    EXECUTE_ASSERT(SUCCEEDED(StartSystem(TRUE)));
    EXECUTE_ASSERT(CheckSourceProperties() == TST_PASS);
    YieldAndSleep(10000);
    EXECUTE_ASSERT(CheckSourceProperties() == TST_PASS);
    EXECUTE_ASSERT(SUCCEEDED(pBasicVideo->SetDefaultSourcePosition()));
    YieldAndSleep(10000);
    EXECUTE_ASSERT(SUCCEEDED(StopSystem()));
    EXECUTE_ASSERT(CheckSourceProperties() == TST_PASS);

    Log(TERSE,TEXT("Exiting window test #5"));
    TerminateWindow();
    LogFlush();
    return TST_PASS;
}


// We test the source properties while we in a stopped state with the window
// invisible, with the renderer paused and running. Then we stop the graph
// and try again (the window should still be visible). Because the source is
// set in one atomic operation rather than as individual properties it should
// either succeed and set all values or fail and leave the properties as they
// were before. This can be checked by setting the source rectangle correctly
// and then making a few invalid calls (the source should be left untouched)

int CheckSourceMethods()
{
    long left,top,width,height;
    INT Result = TST_PASS;
    ASSERT(pBasicVideo);

    // Reset the source and check the coordinates

    EXECUTE_ASSERT(SUCCEEDED(pBasicVideo->SetDefaultSourcePosition()));
    EXECUTE_ASSERT(SUCCEEDED(pBasicVideo->GetSourcePosition(&left,&top,&width,&height)));
    EXECUTE_ASSERT(pBasicVideo->IsUsingDefaultSource() == NOERROR);
    if ((left != 0) || (width != 320) || (top != 0) || (height != 240)) {
        Log(TERSE,TEXT("Source rectangle not reset correctly"));
        Result = TST_FAIL;
    }

    // Set a variety of valid and invalid source positions

    EXECUTE_ASSERT(FAILED(pBasicVideo->SetSourcePosition(0,0,0,0)));
    EXECUTE_ASSERT(FAILED(pBasicVideo->SetSourcePosition(1,1,0,0)));
    EXECUTE_ASSERT(FAILED(pBasicVideo->SetSourcePosition(-1,1,10,10)));
    EXECUTE_ASSERT(FAILED(pBasicVideo->SetSourcePosition(1,-1,10,10)));
    EXECUTE_ASSERT(FAILED(pBasicVideo->SetSourcePosition(1,1,-10,-10)));
    EXECUTE_ASSERT(FAILED(pBasicVideo->SetSourcePosition(-1,-1,-10,-10)));
    EXECUTE_ASSERT(FAILED(pBasicVideo->SetSourcePosition(1,-1,10,-10)));
    EXECUTE_ASSERT(FAILED(pBasicVideo->SetSourcePosition(-1,1,-10,10)));
    EXECUTE_ASSERT(FAILED(pBasicVideo->SetSourcePosition(-1,1,10,-10)));
    EXECUTE_ASSERT(FAILED(pBasicVideo->SetSourcePosition(1,-1,-10,10)));
    EXECUTE_ASSERT(pBasicVideo->IsUsingDefaultSource() == NOERROR);
    YieldAndSleep(250);

    EXECUTE_ASSERT(SUCCEEDED(pBasicVideo->SetSourcePosition(1,1,1,1)));
    EXECUTE_ASSERT(SUCCEEDED(pBasicVideo->SetSourcePosition(10,10,23,56)));
    EXECUTE_ASSERT(FAILED(pBasicVideo->SetSourcePosition(LONG_MAX,321,23,56)));
    EXECUTE_ASSERT(FAILED(pBasicVideo->SetSourcePosition(456,LONG_MAX,23,56)));
    EXECUTE_ASSERT(FAILED(pBasicVideo->SetSourcePosition(456,321,LONG_MAX,56)));
    EXECUTE_ASSERT(FAILED(pBasicVideo->SetSourcePosition(456,321,23,LONG_MAX)));
    EXECUTE_ASSERT(SUCCEEDED(pBasicVideo->SetSourcePosition(0,0,1,1)));
    EXECUTE_ASSERT(SUCCEEDED(pBasicVideo->SetSourcePosition(23,100,297,140)));
    EXECUTE_ASSERT(SUCCEEDED(pBasicVideo->SetSourcePosition(40,80,240,160)));
    EXECUTE_ASSERT(FAILED(pBasicVideo->SetSourcePosition(LONG_MAX,321,23,56)));
    EXECUTE_ASSERT(FAILED(pBasicVideo->SetSourcePosition(456,LONG_MAX,23,56)));
    EXECUTE_ASSERT(FAILED(pBasicVideo->SetSourcePosition(456,321,LONG_MAX,56)));
    EXECUTE_ASSERT(FAILED(pBasicVideo->SetSourcePosition(456,321,23,LONG_MAX)));
    EXECUTE_ASSERT(pBasicVideo->IsUsingDefaultSource() == S_FALSE);
    YieldAndSleep(250);

    // Read the current window position back a few times

    EXECUTE_ASSERT(SUCCEEDED(pBasicVideo->GetSourcePosition(&left,&top,&width,&height)));
    EXECUTE_ASSERT(SUCCEEDED(pBasicVideo->GetSourcePosition(&left,&top,&width,&height)));
    EXECUTE_ASSERT(SUCCEEDED(pBasicVideo->GetSourcePosition(&left,&top,&width,&height)));
    EXECUTE_ASSERT(pBasicVideo->IsUsingDefaultSource() == S_FALSE);

    if ((left != 40) || (top != 80) || (width != 240) || (height != 160)) {
        Log(TERSE,TEXT("Source rectangle not returned correctly"));
        Result = TST_FAIL;
    }

    // Change the source rectangle and try reading it again

    EXECUTE_ASSERT(SUCCEEDED(pBasicVideo->SetSourcePosition(23,13,134,64)));
    EXECUTE_ASSERT(FAILED(pBasicVideo->SetSourcePosition(LONG_MAX,321,23,56)));
    EXECUTE_ASSERT(FAILED(pBasicVideo->SetSourcePosition(456,LONG_MAX,23,56)));
    EXECUTE_ASSERT(FAILED(pBasicVideo->SetSourcePosition(456,321,LONG_MAX,56)));
    EXECUTE_ASSERT(FAILED(pBasicVideo->SetSourcePosition(456,321,23,LONG_MAX)));
    EXECUTE_ASSERT(SUCCEEDED(pBasicVideo->GetSourcePosition(&left,&top,&width,&height)));
    EXECUTE_ASSERT(pBasicVideo->IsUsingDefaultSource() == S_FALSE);
    YieldAndSleep(250);

    EXECUTE_ASSERT(left == 23);
    EXECUTE_ASSERT(top == 13);
    EXECUTE_ASSERT(width == 134);
    EXECUTE_ASSERT(height == 64);

    // Reset the source back to the default values

    EXECUTE_ASSERT(pBasicVideo->IsUsingDefaultSource() == S_FALSE);
    EXECUTE_ASSERT(SUCCEEDED(pBasicVideo->SetSourcePosition(0,0,320,240)));
    EXECUTE_ASSERT(pBasicVideo->IsUsingDefaultSource() == NOERROR);
    EXECUTE_ASSERT(pBasicVideo->IsUsingDefaultSource() == NOERROR);
    YieldAndSleep(250);
    return TST_PASS;
}


//==========================================================================
//
//  int execWindowTest6
//
//  Description:
//      This tests the source rectangle interface to the video renderer. It
//      uses this source rectangle to define which area of the available
//      video to pull out and display. The only real way of verifying that
//      it is actually doing this is a manual check so we start the system
//      going in the hope that someone might notice it if anything goes bad
//
//  Return (int): TST_PASS indicating success
//
//==========================================================================

int execWindowTest6()
{
    Log(TERSE,TEXT("Entering window test #6"));
    LogFlush();
    InitialiseWindow();

    // Check the properties in each state

    EXECUTE_ASSERT(CheckSourceMethods() == TST_PASS);
    EXECUTE_ASSERT(SUCCEEDED(PauseSystem()));
    EXECUTE_ASSERT(CheckSourceMethods() == TST_PASS);
    EXECUTE_ASSERT(SUCCEEDED(StartSystem(TRUE)));
    EXECUTE_ASSERT(CheckSourceMethods() == TST_PASS);
    YieldAndSleep(10000);
    EXECUTE_ASSERT(CheckSourceMethods() == TST_PASS);
    EXECUTE_ASSERT(SUCCEEDED(pBasicVideo->SetDefaultSourcePosition()));
    YieldAndSleep(10000);
    EXECUTE_ASSERT(SUCCEEDED(StopSystem()));
    EXECUTE_ASSERT(CheckSourceMethods() == TST_PASS);

    Log(TERSE,TEXT("Exiting window test #6"));
    TerminateWindow();
    LogFlush();
    return TST_PASS;
}


// As for CheckSourceProperties this checks the destination properties. When
// we set the source rectangle we can do much more parameter checking because
// negative left and top positions, as well as widths or heights that exceed
// the video extents are likewise invalid. With the destination properties we
// are much more limited because it can be displayed anywhere in the logical
// window coordinates, so (-50,-50,-40,-30) is a valid destination rectangle

int CheckDestinationProperties()
{
    long left,top,width,height,position;
    INT Result = TST_PASS;
    ASSERT(pBasicVideo);

    // Reset the destination back to the entire client area

    EXECUTE_ASSERT(SUCCEEDED(pBasicVideo->SetDefaultDestinationPosition()));
    EXECUTE_ASSERT(SUCCEEDED(pBasicVideo->GetDestinationPosition(&left,&top,&width,&height)));
    EXECUTE_ASSERT(pBasicVideo->IsUsingDefaultDestination() == NOERROR);
    if ((left != 0) || (width != 320) || (top != 0) || (height != 240)) {
        Log(TERSE,TEXT("Destination rectangle not reset correctly"));
        Result = TST_FAIL;
    }

    // Change the position of the target video. NOTE after the first three of
    // these have executed the target rectangle will look like (in the normal
    // rectangle coordinate system) left 10, top 0 (because it's the default)
    // right 20 and bottom 10, when we than try to set the top to match the
    // bottom it should succeed as the rectangle is shunted down by 10 pixels

    EXECUTE_ASSERT(SUCCEEDED(pBasicVideo->put_DestinationLeft(12)));
    EXECUTE_ASSERT(SUCCEEDED(pBasicVideo->put_DestinationWidth(12)));
    EXECUTE_ASSERT(SUCCEEDED(pBasicVideo->put_DestinationHeight(12)));
    EXECUTE_ASSERT(SUCCEEDED(pBasicVideo->put_DestinationTop(12)));
    EXECUTE_ASSERT(pBasicVideo->IsUsingDefaultDestination() == S_FALSE);
    YieldAndSleep(250);

    EXECUTE_ASSERT(SUCCEEDED(pBasicVideo->put_DestinationLeft(40)));
    EXECUTE_ASSERT(SUCCEEDED(pBasicVideo->put_DestinationWidth(40)));
    EXECUTE_ASSERT(FAILED(pBasicVideo->put_DestinationWidth(-40)));
    EXECUTE_ASSERT(FAILED(pBasicVideo->put_DestinationWidth(0)));
    EXECUTE_ASSERT(FAILED(pBasicVideo->put_DestinationWidth(-1)));
    EXECUTE_ASSERT(FAILED(pBasicVideo->put_DestinationWidth(LONG_MIN)));
    EXECUTE_ASSERT(pBasicVideo->IsUsingDefaultDestination() == S_FALSE);
    YieldAndSleep(250);

    EXECUTE_ASSERT(SUCCEEDED(pBasicVideo->put_DestinationHeight(40)));
    EXECUTE_ASSERT(SUCCEEDED(pBasicVideo->put_DestinationTop(40)));
    EXECUTE_ASSERT(FAILED(pBasicVideo->put_DestinationHeight(-40)));
    EXECUTE_ASSERT(FAILED(pBasicVideo->put_DestinationHeight(0)));
    EXECUTE_ASSERT(FAILED(pBasicVideo->put_DestinationHeight(-1)));
    EXECUTE_ASSERT(FAILED(pBasicVideo->put_DestinationHeight(LONG_MIN)));
    EXECUTE_ASSERT(pBasicVideo->IsUsingDefaultDestination() == S_FALSE);
    YieldAndSleep(250);

    EXECUTE_ASSERT(SUCCEEDED(pBasicVideo->put_DestinationLeft(100)));
    EXECUTE_ASSERT(SUCCEEDED(pBasicVideo->put_DestinationLeft(150)));
    EXECUTE_ASSERT(SUCCEEDED(pBasicVideo->put_DestinationLeft(220)));
    EXECUTE_ASSERT(SUCCEEDED(pBasicVideo->put_DestinationWidth(100)));
    EXECUTE_ASSERT(SUCCEEDED(pBasicVideo->put_DestinationWidth(150)));
    EXECUTE_ASSERT(SUCCEEDED(pBasicVideo->put_DestinationWidth(220)));
    EXECUTE_ASSERT(SUCCEEDED(pBasicVideo->put_DestinationHeight(100)));
    EXECUTE_ASSERT(SUCCEEDED(pBasicVideo->put_DestinationHeight(150)));
    EXECUTE_ASSERT(SUCCEEDED(pBasicVideo->put_DestinationHeight(220)));
    EXECUTE_ASSERT(SUCCEEDED(pBasicVideo->put_DestinationTop(100)));
    EXECUTE_ASSERT(SUCCEEDED(pBasicVideo->put_DestinationTop(150)));
    EXECUTE_ASSERT(SUCCEEDED(pBasicVideo->put_DestinationTop(220)));
    EXECUTE_ASSERT(pBasicVideo->IsUsingDefaultDestination() == S_FALSE);
    YieldAndSleep(250);

    // Make some invalid calls to check the properties remain untouched

    EXECUTE_ASSERT(FAILED(pBasicVideo->put_DestinationWidth(-40)));
    EXECUTE_ASSERT(FAILED(pBasicVideo->put_DestinationWidth(0)));
    EXECUTE_ASSERT(FAILED(pBasicVideo->put_DestinationWidth(-1)));
    EXECUTE_ASSERT(FAILED(pBasicVideo->put_DestinationWidth(LONG_MIN)));
    EXECUTE_ASSERT(FAILED(pBasicVideo->put_DestinationHeight(-40)));
    EXECUTE_ASSERT(FAILED(pBasicVideo->put_DestinationHeight(0)));
    EXECUTE_ASSERT(FAILED(pBasicVideo->put_DestinationHeight(-1)));
    EXECUTE_ASSERT(FAILED(pBasicVideo->put_DestinationHeight(LONG_MIN)));
    EXECUTE_ASSERT(pBasicVideo->IsUsingDefaultDestination() == S_FALSE);
    YieldAndSleep(250);

    // Now check that they really happened

    EXECUTE_ASSERT(SUCCEEDED(pBasicVideo->GetDestinationPosition(&left,&top,&width,&height)));
    if ((left != 220) || (width != 220) || (top != 220) || (height != 220)) {
        Log(TERSE,TEXT("Destination rectangle not realised correctly"));
        Result = TST_FAIL;
    }

    // Read the individual properties and check they also match

    EXECUTE_ASSERT(SUCCEEDED(pBasicVideo->get_DestinationLeft(&position)));
    EXECUTE_ASSERT(position == 220);
    EXECUTE_ASSERT(SUCCEEDED(pBasicVideo->get_DestinationWidth(&position)));
    EXECUTE_ASSERT(position == 220);
    EXECUTE_ASSERT(SUCCEEDED(pBasicVideo->get_DestinationHeight(&position)));
    EXECUTE_ASSERT(position == 220);
    EXECUTE_ASSERT(SUCCEEDED(pBasicVideo->get_DestinationTop(&position)));
    EXECUTE_ASSERT(position == 220);
    EXECUTE_ASSERT(pBasicVideo->IsUsingDefaultDestination() == S_FALSE);
    YieldAndSleep(250);

    // Pretend to reset the destination back to the default values

    EXECUTE_ASSERT(SUCCEEDED(pBasicVideo->put_DestinationLeft(0)));
    EXECUTE_ASSERT(SUCCEEDED(pBasicVideo->put_DestinationWidth(320)));
    EXECUTE_ASSERT(SUCCEEDED(pBasicVideo->put_DestinationTop(0)));
    EXECUTE_ASSERT(SUCCEEDED(pBasicVideo->put_DestinationHeight(240)));
    EXECUTE_ASSERT(pBasicVideo->IsUsingDefaultDestination() == S_FALSE);
    YieldAndSleep(250);
    return TST_PASS;
}


//==========================================================================
//
//  int execWindowTest7
//
//  Description:
//      This tests the video destination position properties, we set all of
//      them in turn (although in different sequencies). Setting them is
//      meant to be synchronous so not only should they return the changed
//      value if queried straight afterwards but those changes should also
//      be reflected when we go and see if the actual window has moved
//
//  Return (int): TST_PASS indicating success
//
//==========================================================================

int execWindowTest7()
{
    Log(TERSE,TEXT("Entering window test #7"));
    LogFlush();
    InitialiseWindow();

    // Check the properties in each state

    EXECUTE_ASSERT(CheckDestinationProperties() == TST_PASS);
    EXECUTE_ASSERT(SUCCEEDED(PauseSystem()));
    EXECUTE_ASSERT(CheckDestinationProperties() == TST_PASS);
    EXECUTE_ASSERT(SUCCEEDED(StartSystem(TRUE)));
    EXECUTE_ASSERT(CheckDestinationProperties() == TST_PASS);
    YieldAndSleep(10000);
    EXECUTE_ASSERT(CheckDestinationProperties() == TST_PASS);
    EXECUTE_ASSERT(SUCCEEDED(pBasicVideo->SetDefaultDestinationPosition()));
    YieldAndSleep(10000);
    EXECUTE_ASSERT(SUCCEEDED(StopSystem()));
    EXECUTE_ASSERT(CheckDestinationProperties() == TST_PASS);

    Log(TERSE,TEXT("Exiting window test #7"));
    TerminateWindow();
    LogFlush();
    return TST_PASS;
}


// As for CheckSourceMethods this will check the destination methods. When we
// set the source rectangle we can do much more parameter checking because
// negative left and top positions, as well as widths or heights that exceed
// the video extents are likewise invalid. With the destination methods we
// are much more limited because it can be displayed anywhere in the logical
// window coordinates, so (-50,-50,-40,-30) is a valid destination rectangle

int CheckDestinationMethods()
{
    long left,top,width,height;
    INT Result = TST_PASS;
    ASSERT(pBasicVideo);

    // Reset the destination back to the entire client area

    EXECUTE_ASSERT(SUCCEEDED(pBasicVideo->SetDefaultDestinationPosition()));
    EXECUTE_ASSERT(SUCCEEDED(pBasicVideo->GetDestinationPosition(&left,&top,&width,&height)));
    EXECUTE_ASSERT(pBasicVideo->IsUsingDefaultDestination() == NOERROR);
    if ((left != 0) || (width != 320) || (top != 0) || (height != 240)) {
        Log(TERSE,TEXT("Destination rectangle not reset correctly"));
        Result = TST_FAIL;
    }

    // Try some invalid destination rectangles first

    EXECUTE_ASSERT(FAILED(pBasicVideo->SetDestinationPosition(0,0,0,0)));
    EXECUTE_ASSERT(FAILED(pBasicVideo->SetDestinationPosition(1,1,0,0)));
    EXECUTE_ASSERT(FAILED(pBasicVideo->SetDestinationPosition(10,10,100,-100)));
    EXECUTE_ASSERT(FAILED(pBasicVideo->SetDestinationPosition(10,10,-100,100)));
    EXECUTE_ASSERT(FAILED(pBasicVideo->SetDestinationPosition(10,10,-100,-100)));
    EXECUTE_ASSERT(FAILED(pBasicVideo->SetDestinationPosition(10,10,0,-100)));
    EXECUTE_ASSERT(FAILED(pBasicVideo->SetDestinationPosition(10,10,-100,0)));
    EXECUTE_ASSERT(FAILED(pBasicVideo->SetDestinationPosition(10,10,LONG_MIN,10)));
    EXECUTE_ASSERT(FAILED(pBasicVideo->SetDestinationPosition(10,10,10,LONG_MIN)));
    EXECUTE_ASSERT(pBasicVideo->IsUsingDefaultDestination() == NOERROR);
    YieldAndSleep(250);

    // Make sure the destination has remained untouched

    EXECUTE_ASSERT(SUCCEEDED(pBasicVideo->GetDestinationPosition(&left,&top,&width,&height)));
    if ((left != 0) || (width != 320) || (top != 0) || (height != 240)) {
        Log(TERSE,TEXT("Destination rectangle not reset correctly"));
        Result = TST_FAIL;
    }

    EXECUTE_ASSERT(SUCCEEDED(pBasicVideo->SetDestinationPosition(1,1,1,1)));
    EXECUTE_ASSERT(SUCCEEDED(pBasicVideo->SetDestinationPosition(10,10,23,56)));
    EXECUTE_ASSERT(SUCCEEDED(pBasicVideo->SetDestinationPosition(456,321,23,56)));
    EXECUTE_ASSERT(SUCCEEDED(pBasicVideo->SetDestinationPosition(0,0,1,1)));
    EXECUTE_ASSERT(SUCCEEDED(pBasicVideo->SetDestinationPosition(23,100,233,156)));
    EXECUTE_ASSERT(SUCCEEDED(pBasicVideo->SetDestinationPosition(40,60,200,100)));
    EXECUTE_ASSERT(pBasicVideo->IsUsingDefaultDestination() == S_FALSE);
    YieldAndSleep(250);

    EXECUTE_ASSERT(FAILED(pBasicVideo->SetDestinationPosition(0,0,0,0)));
    EXECUTE_ASSERT(FAILED(pBasicVideo->SetDestinationPosition(1,1,0,0)));
    EXECUTE_ASSERT(FAILED(pBasicVideo->SetDestinationPosition(10,10,100,-100)));
    EXECUTE_ASSERT(FAILED(pBasicVideo->SetDestinationPosition(10,10,-100,100)));
    EXECUTE_ASSERT(FAILED(pBasicVideo->SetDestinationPosition(10,10,-100,-100)));
    EXECUTE_ASSERT(FAILED(pBasicVideo->SetDestinationPosition(10,10,0,-100)));
    EXECUTE_ASSERT(FAILED(pBasicVideo->SetDestinationPosition(10,10,-100,0)));
    EXECUTE_ASSERT(FAILED(pBasicVideo->SetDestinationPosition(10,10,LONG_MIN,10)));
    EXECUTE_ASSERT(FAILED(pBasicVideo->SetDestinationPosition(10,10,10,LONG_MIN)));
    EXECUTE_ASSERT(pBasicVideo->IsUsingDefaultDestination() == S_FALSE);
    YieldAndSleep(250);

    // Read the current destination position back a few times

    EXECUTE_ASSERT(SUCCEEDED(pBasicVideo->GetDestinationPosition(&left,&top,&width,&height)));
    EXECUTE_ASSERT(SUCCEEDED(pBasicVideo->GetDestinationPosition(&left,&top,&width,&height)));
    EXECUTE_ASSERT(SUCCEEDED(pBasicVideo->GetDestinationPosition(&left,&top,&width,&height)));
    EXECUTE_ASSERT(pBasicVideo->IsUsingDefaultDestination() == S_FALSE);

    if ((left != 40) || (top != 60) || (width != 200) || (height != 100)) {
        Log(TERSE,TEXT("Destination rectangle not returned correctly"));
        Result = TST_FAIL;
    }

    // Change the destination rectangle and try again

    EXECUTE_ASSERT(SUCCEEDED(pBasicVideo->SetDestinationPosition(23,13,134,64)));
    EXECUTE_ASSERT(SUCCEEDED(pBasicVideo->GetDestinationPosition(&left,&top,&width,&height)));
    EXECUTE_ASSERT(pBasicVideo->IsUsingDefaultDestination() == S_FALSE);

    EXECUTE_ASSERT(left == 23);
    EXECUTE_ASSERT(top == 13);
    EXECUTE_ASSERT(width == 134);
    EXECUTE_ASSERT(height == 64);

    // Pretent to reset the destination back to the default values

    EXECUTE_ASSERT(pBasicVideo->IsUsingDefaultDestination() == S_FALSE);
    EXECUTE_ASSERT(SUCCEEDED(pBasicVideo->SetDestinationPosition(0,0,320,240)));
    EXECUTE_ASSERT(pBasicVideo->IsUsingDefaultDestination() == S_FALSE);
    EXECUTE_ASSERT(pBasicVideo->IsUsingDefaultDestination() == S_FALSE);
    YieldAndSleep(250);
    return TST_PASS;
}


//==========================================================================
//
//  int execWindowTest8
//
//  Description:
//      This tests the destination rectangle interface to the video renderer
//      It uses this destination rectangle to define which area of the video
//      window will have video in it. The only real way of verifying that
//      it is actually doing this is a manual check so we start the system
//      going in the hope that someone might notice it if anything goes bad
//
//  Return (int): TST_PASS indicating success
//
//==========================================================================

int execWindowTest8()
{
    Log(TERSE,TEXT("Entering window test #8"));
    LogFlush();
    InitialiseWindow();

    // Check the properties in each state

    EXECUTE_ASSERT(CheckDestinationMethods() == TST_PASS);
    EXECUTE_ASSERT(SUCCEEDED(PauseSystem()));
    EXECUTE_ASSERT(CheckDestinationMethods() == TST_PASS);
    EXECUTE_ASSERT(SUCCEEDED(StartSystem(TRUE)));
    EXECUTE_ASSERT(CheckDestinationMethods() == TST_PASS);
    YieldAndSleep(10000);
    EXECUTE_ASSERT(CheckDestinationMethods() == TST_PASS);
    EXECUTE_ASSERT(SUCCEEDED(pBasicVideo->SetDefaultDestinationPosition()));
    YieldAndSleep(10000);
    EXECUTE_ASSERT(SUCCEEDED(StopSystem()));
    EXECUTE_ASSERT(CheckDestinationMethods() == TST_PASS);

    Log(TERSE,TEXT("Exiting window test #8"));
    TerminateWindow();
    LogFlush();
    return TST_PASS;
}


//==========================================================================
//
//  int execWindowTest9
//
//  Description:
//      This tests the capability to set the owner of the video window. We
//      set the owner of the video window to be the desktop window and also
//      the test shell main window, both of which should always succeed. We
//      then make sure that we can get the owner and that the handles match
//      There is a distinction between setting the parent on an overlapped
//      window which just makes it the owner and taking off a WS_OVERLAPPED
//      style and adding WS_CHILD which really makes it a true child window
//
//  Return (int): TST_PASS indicating success
//
//==========================================================================

int execWindowTest9()
{
    INT Result = TST_PASS;
    HWND hwndParent;
    long WindowStyle;

    Log(TERSE,TEXT("Entering window test #9"));
    LogFlush();
    InitialiseWindow();

    EXECUTE_ASSERT(SUCCEEDED(pVideoWindow->put_Owner((OAHWND)ghwndTstShell)));
    EXECUTE_ASSERT(SUCCEEDED(pVideoWindow->get_Owner((OAHWND *)&hwndParent)));
    EXECUTE_ASSERT(hwndParent == ghwndTstShell);
    EXECUTE_ASSERT(SUCCEEDED(pVideoWindow->put_MessageDrain((OAHWND)ghwndTstShell)));
    EXECUTE_ASSERT(SUCCEEDED(pVideoWindow->get_MessageDrain((OAHWND *)&hwndParent)));
    EXECUTE_ASSERT(hwndParent == ghwndTstShell);

    // Make sure it can run correctly for a while

    EXECUTE_ASSERT(SUCCEEDED(StartSystem(TRUE)));
    EXECUTE_ASSERT(SUCCEEDED(pVideoWindow->put_Owner((OAHWND)ghwndTstShell)));
    EXECUTE_ASSERT(SUCCEEDED(pVideoWindow->get_Owner((OAHWND *)&hwndParent)));
    EXECUTE_ASSERT(hwndParent == ghwndTstShell);
    EXECUTE_ASSERT(SUCCEEDED(pVideoWindow->put_MessageDrain((OAHWND)ghwndTstShell)));
    EXECUTE_ASSERT(SUCCEEDED(pVideoWindow->get_MessageDrain((OAHWND *)&hwndParent)));
    EXECUTE_ASSERT(hwndParent == ghwndTstShell);
    YieldAndSleep(10000);

    // Reset the parent window back to the NULL desktop

    EXECUTE_ASSERT(SUCCEEDED(pVideoWindow->put_Owner((OAHWND)NULL)));
    EXECUTE_ASSERT(SUCCEEDED(pVideoWindow->get_Owner((OAHWND *)&hwndParent)));
    EXECUTE_ASSERT(hwndParent == NULL);
    EXECUTE_ASSERT(SUCCEEDED(pVideoWindow->put_MessageDrain((OAHWND)NULL)));
    EXECUTE_ASSERT(SUCCEEDED(pVideoWindow->get_MessageDrain((OAHWND *)&hwndParent)));
    EXECUTE_ASSERT(hwndParent == NULL);
    YieldAndSleep(10000);

    // Try making it a real child window rather than just owned

    EXECUTE_ASSERT(SUCCEEDED(pVideoWindow->put_Owner((OAHWND)ghwndTstShell)));
    EXECUTE_ASSERT(SUCCEEDED(pVideoWindow->get_WindowStyle(&WindowStyle)));
    WindowStyle = (WindowStyle & ~WS_OVERLAPPED) | WS_CHILD;
    EXECUTE_ASSERT(SUCCEEDED(pVideoWindow->put_WindowStyle(WindowStyle)));
    EXECUTE_ASSERT(SUCCEEDED(pVideoWindow->get_Owner((OAHWND *)&hwndParent)));
    EXECUTE_ASSERT(hwndParent == ghwndTstShell);
    EXECUTE_ASSERT(SUCCEEDED(pVideoWindow->put_MessageDrain((OAHWND)ghwndTstShell)));
    EXECUTE_ASSERT(SUCCEEDED(pVideoWindow->get_MessageDrain((OAHWND *)&hwndParent)));
    EXECUTE_ASSERT(hwndParent == ghwndTstShell);
    YieldAndSleep(10000);

    EXECUTE_ASSERT(SUCCEEDED(StopSystem()));

    Log(TERSE,TEXT("Exiting window test #9"));
    TerminateWindow();
    LogFlush();
    return Result;
}


//==========================================================================
//
//  int execWindowTest10
//
//  Description:
//      This tests the video size properties and methods on IBasicVideo
//      The video dimensions can be returned as individual properties or
//      through a method that is better suited to being used at runtime
//      as the properties can change dynamically. Asking for each of them
//      separately may return values that are in between being changed
//
//  Return (int): TST_PASS indicating success
//
//==========================================================================

int execWindowTest10()
{
    INT Result = TST_PASS;
    long size,width,height;

    Log(TERSE,TEXT("Entering window test #10"));
    LogFlush();
    InitialiseWindow();

    // Get the video property dimensions

    pBasicVideo->get_VideoHeight(&size);
    if (size != HEIGHT) {
        Log(TERSE,TEXT("Video height not correct"));
        Result = TST_FAIL;
    }

    pBasicVideo->get_VideoWidth(&size);
    if (size != WIDTH) {
        Log(TERSE,TEXT("Video width not correct"));
        Result = TST_FAIL;
    }

    // Get the video dimensions through the method

    pBasicVideo->GetVideoSize(&width,&height);
    ASSERT(width == WIDTH);
    ASSERT(height == HEIGHT);

    Log(TERSE,TEXT("Exiting window test #10"));
    TerminateWindow();
    LogFlush();
    return Result;
}


//==========================================================================
//
//  int execWindowTest11
//
//  Description:
//      This tests setting the state of the video window, the state changes
//      let the application minimise, maximise, restore, show and hide the
//      video window. Trying to do these by changing the window style will
//      have unpredictable results. The video window is initially hidden
//
//  Return (int): TST_PASS indicating success
//
//==========================================================================

int execWindowTest11()
{
    INT Result = TST_PASS;
    long state;

    Log(TERSE,TEXT("Entering window test #11"));
    LogFlush();
    InitialiseWindow();

    // Check the current window state is not shown

    EXECUTE_ASSERT(SUCCEEDED(pVideoWindow->get_WindowState(&state)));
    EXECUTE_ASSERT(IsIconic(hVideoWindow) == FALSE);
    EXECUTE_ASSERT(IsZoomed(hVideoWindow) == FALSE);
    EXECUTE_ASSERT(IsWindowVisible(hVideoWindow) == FALSE);

    EXECUTE_ASSERT(SUCCEEDED(StartSystem(TRUE)));
    YieldAndSleep(10000);

    // Now try a few different state changes

    EXECUTE_ASSERT(SUCCEEDED(pVideoWindow->put_WindowState(SW_HIDE)));
    YieldAndSleep(10000);
    EXECUTE_ASSERT(SUCCEEDED(pVideoWindow->put_WindowState(SW_MINIMIZE)));
    YieldAndSleep(10000);
    EXECUTE_ASSERT(SUCCEEDED(pVideoWindow->put_WindowState(SW_RESTORE)));
    YieldAndSleep(10000);
    EXECUTE_ASSERT(SUCCEEDED(pVideoWindow->put_WindowState(SW_MAXIMIZE)));
    YieldAndSleep(10000);
    EXECUTE_ASSERT(SUCCEEDED(pVideoWindow->put_WindowState(SW_RESTORE)));
    YieldAndSleep(10000);
    EXECUTE_ASSERT(SUCCEEDED(pVideoWindow->put_WindowState(SW_RESTORE)));
    YieldAndSleep(10000);
    EXECUTE_ASSERT(SUCCEEDED(pVideoWindow->put_WindowState(SW_MINIMIZE)));
    YieldAndSleep(10000);
    EXECUTE_ASSERT(SUCCEEDED(pVideoWindow->put_WindowState(SW_SHOWNOACTIVATE)));
    YieldAndSleep(10000);
    EXECUTE_ASSERT(SUCCEEDED(pVideoWindow->put_WindowState(SW_HIDE)));
    YieldAndSleep(10000);
    EXECUTE_ASSERT(SUCCEEDED(pVideoWindow->put_WindowState(SW_SHOW)));
    YieldAndSleep(10000);

    EXECUTE_ASSERT(SUCCEEDED(StopSystem()));

    Log(TERSE,TEXT("Exiting window test #11"));
    TerminateWindow();
    LogFlush();
    return Result;
}


//==========================================================================
//
//  int execWindowTest12
//
//  Description:
//      This tests setting the window style of the window. The interface is
//      a fairly thin wrapper around setting the window style through the
//      SetWindowLong(GWL_(EX)STYLE) and so anything that doesn't do very
//      well neither will we. Unfortunately some of the results obtainable
//      are not well documented and so changing some of the styles can
//      give very unpredictable results (such as the window disappearing)
//
//  Return (int): TST_PASS indicating success
//
//==========================================================================

int execWindowTest12()
{
    INT Result = TST_PASS;
    long style;

    Log(TERSE,TEXT("Entering window test #12"));
    LogFlush();
    InitialiseWindow();

    EXECUTE_ASSERT(pVideoWindow->put_WindowStyle(WS_DISABLED) == E_INVALIDARG);
    EXECUTE_ASSERT(pVideoWindow->put_WindowStyle(WS_ICONIC) == E_INVALIDARG);
    EXECUTE_ASSERT(pVideoWindow->put_WindowStyle(WS_MAXIMIZE) == E_INVALIDARG);
    EXECUTE_ASSERT(pVideoWindow->put_WindowStyle(WS_MINIMIZE) == E_INVALIDARG);
    EXECUTE_ASSERT(pVideoWindow->put_WindowStyle(WS_HSCROLL) == E_INVALIDARG);
    EXECUTE_ASSERT(pVideoWindow->put_WindowStyle(WS_VSCROLL) == E_INVALIDARG);

    // Display the initial window styles

    EXECUTE_ASSERT(SUCCEEDED(pVideoWindow->get_WindowStyle(&style)));
    DisplayWindowStyles(style);
    EXECUTE_ASSERT(SUCCEEDED(StartSystem(TRUE)));
    YieldAndSleep(2000);

    // Take out of caption and border

    long change = style & (~(WS_CAPTION | WS_BORDER));
    Log(TERSE,TEXT("Taking out WS_CAPTION and WS_BORDER"));
    EXECUTE_ASSERT(SUCCEEDED(pVideoWindow->put_WindowStyle(change)));
    EXECUTE_ASSERT(SUCCEEDED(pVideoWindow->get_WindowStyle(&change)));
    DisplayWindowStyles(change);

    YieldAndSleep(2000);

    // Add a dialog style double thickness window border

    EXECUTE_ASSERT(SUCCEEDED(pVideoWindow->get_WindowStyleEx(&change)));
    change = style | WS_EX_DLGMODALFRAME;
    Log(TERSE,TEXT("Adding WS_EX_DLGMODALFRAME"));
    EXECUTE_ASSERT(SUCCEEDED(pVideoWindow->put_WindowStyleEx(change)));
    EXECUTE_ASSERT(SUCCEEDED(pVideoWindow->get_WindowStyleEx(&change)));
    DisplayWindowStylesEx(change);

    YieldAndSleep(2000);

    // Take the extended style back off again

    change = style & (~WS_EX_DLGMODALFRAME);
    Log(TERSE,TEXT("Removing WS_EX_DLGMODALFRAME"));
    EXECUTE_ASSERT(SUCCEEDED(pVideoWindow->put_WindowStyleEx(change)));
    DisplayWindowStylesEx(change);

    EXECUTE_ASSERT(pVideoWindow->put_WindowStyle(WS_DISABLED) == E_INVALIDARG);
    EXECUTE_ASSERT(pVideoWindow->put_WindowStyle(WS_ICONIC) == E_INVALIDARG);
    EXECUTE_ASSERT(pVideoWindow->put_WindowStyle(WS_MAXIMIZE) == E_INVALIDARG);
    EXECUTE_ASSERT(pVideoWindow->put_WindowStyle(WS_MINIMIZE) == E_INVALIDARG);
    EXECUTE_ASSERT(pVideoWindow->put_WindowStyle(WS_HSCROLL) == E_INVALIDARG);
    EXECUTE_ASSERT(pVideoWindow->put_WindowStyle(WS_VSCROLL) == E_INVALIDARG);

    YieldAndSleep(2000);

    // Base video window without a thick frame sizing border

    change = (style & (~WS_THICKFRAME)) | WS_CAPTION;
    Log(TERSE,TEXT("Taking out WS_THICKFRAME but putting back caption"));
    EXECUTE_ASSERT(SUCCEEDED(pVideoWindow->put_WindowStyle(change)));
    EXECUTE_ASSERT(SUCCEEDED(pVideoWindow->get_WindowStyle(&change)));
    DisplayWindowStyles(change);

    YieldAndSleep(2000);
    EXECUTE_ASSERT(SUCCEEDED(StopSystem()));

    EXECUTE_ASSERT(pVideoWindow->put_WindowStyle(WS_DISABLED) == E_INVALIDARG);
    EXECUTE_ASSERT(pVideoWindow->put_WindowStyle(WS_ICONIC) == E_INVALIDARG);
    EXECUTE_ASSERT(pVideoWindow->put_WindowStyle(WS_MAXIMIZE) == E_INVALIDARG);
    EXECUTE_ASSERT(pVideoWindow->put_WindowStyle(WS_MINIMIZE) == E_INVALIDARG);
    EXECUTE_ASSERT(pVideoWindow->put_WindowStyle(WS_HSCROLL) == E_INVALIDARG);
    EXECUTE_ASSERT(pVideoWindow->put_WindowStyle(WS_VSCROLL) == E_INVALIDARG);

    // Display the initial window styles

    Log(TERSE,TEXT("(Hiding video window to change styles)"));
    EXECUTE_ASSERT(SUCCEEDED(StartSystem(TRUE)));
    EXECUTE_ASSERT(SUCCEEDED(pVideoWindow->get_WindowStyle(&style)));
    DisplayWindowStyles(style);
    YieldAndSleep(1000);

    // Take out of caption and border

    EXECUTE_ASSERT(pVideoWindow->put_Visible(OAFALSE) == NOERROR);
    change = style & (~(WS_CAPTION | WS_BORDER));
    Log(TERSE,TEXT("Taking out WS_CAPTION and WS_BORDER"));
    EXECUTE_ASSERT(SUCCEEDED(pVideoWindow->put_WindowStyle(change)));
    EXECUTE_ASSERT(SUCCEEDED(pVideoWindow->get_WindowStyle(&change)));
    DisplayWindowStyles(change);

    // Show on screen the style changes while hidden
    EXECUTE_ASSERT(pVideoWindow->put_Visible(OATRUE) == NOERROR);
    YieldAndSleep(1000);
    EXECUTE_ASSERT(pVideoWindow->put_Visible(OAFALSE) == NOERROR);
    YieldAndSleep(2000);

    // Add a dialog style double thickness window border

    EXECUTE_ASSERT(SUCCEEDED(pVideoWindow->get_WindowStyleEx(&change)));
    change = style | WS_EX_DLGMODALFRAME;
    Log(TERSE,TEXT("Adding WS_EX_DLGMODALFRAME"));
    EXECUTE_ASSERT(SUCCEEDED(pVideoWindow->put_WindowStyleEx(change)));
    EXECUTE_ASSERT(SUCCEEDED(pVideoWindow->get_WindowStyleEx(&change)));
    DisplayWindowStylesEx(change);

    // Show on screen the style changes while hidden
    EXECUTE_ASSERT(pVideoWindow->put_Visible(OATRUE) == NOERROR);
    YieldAndSleep(1000);
    EXECUTE_ASSERT(pVideoWindow->put_Visible(OAFALSE) == NOERROR);
    YieldAndSleep(2000);

    // Take the extended style back off again

    change = style & (~WS_EX_DLGMODALFRAME);
    Log(TERSE,TEXT("Removing WS_EX_DLGMODALFRAME"));
    EXECUTE_ASSERT(SUCCEEDED(pVideoWindow->put_WindowStyleEx(change)));
    DisplayWindowStylesEx(change);

    EXECUTE_ASSERT(pVideoWindow->put_WindowStyle(WS_DISABLED) == E_INVALIDARG);
    EXECUTE_ASSERT(pVideoWindow->put_WindowStyle(WS_ICONIC) == E_INVALIDARG);
    EXECUTE_ASSERT(pVideoWindow->put_WindowStyle(WS_MAXIMIZE) == E_INVALIDARG);
    EXECUTE_ASSERT(pVideoWindow->put_WindowStyle(WS_MINIMIZE) == E_INVALIDARG);
    EXECUTE_ASSERT(pVideoWindow->put_WindowStyle(WS_HSCROLL) == E_INVALIDARG);
    EXECUTE_ASSERT(pVideoWindow->put_WindowStyle(WS_VSCROLL) == E_INVALIDARG);

    // Show on screen the style changes while hidden
    EXECUTE_ASSERT(pVideoWindow->put_Visible(OATRUE) == NOERROR);
    YieldAndSleep(1000);
    EXECUTE_ASSERT(pVideoWindow->put_Visible(OAFALSE) == NOERROR);
    YieldAndSleep(2000);

    // Base video window without a thick frame sizing border

    change = (style & (~WS_THICKFRAME)) | WS_CAPTION;
    Log(TERSE,TEXT("Taking out WS_THICKFRAME but putting back caption"));
    EXECUTE_ASSERT(SUCCEEDED(pVideoWindow->put_WindowStyle(change)));
    EXECUTE_ASSERT(SUCCEEDED(pVideoWindow->get_WindowStyle(&change)));
    DisplayWindowStyles(change);

    // Show on screen the style changes while hidden
    EXECUTE_ASSERT(pVideoWindow->put_Visible(OATRUE) == NOERROR);
    YieldAndSleep(1000);
    EXECUTE_ASSERT(pVideoWindow->put_Visible(OAFALSE) == NOERROR);
    YieldAndSleep(2000);
    EXECUTE_ASSERT(SUCCEEDED(StopSystem()));

    EXECUTE_ASSERT(pVideoWindow->put_WindowStyle(WS_DISABLED) == E_INVALIDARG);
    EXECUTE_ASSERT(pVideoWindow->put_WindowStyle(WS_ICONIC) == E_INVALIDARG);
    EXECUTE_ASSERT(pVideoWindow->put_WindowStyle(WS_MAXIMIZE) == E_INVALIDARG);
    EXECUTE_ASSERT(pVideoWindow->put_WindowStyle(WS_MINIMIZE) == E_INVALIDARG);
    EXECUTE_ASSERT(pVideoWindow->put_WindowStyle(WS_HSCROLL) == E_INVALIDARG);
    EXECUTE_ASSERT(pVideoWindow->put_WindowStyle(WS_VSCROLL) == E_INVALIDARG);

    Log(TERSE,TEXT("Exiting window test #12"));
    TerminateWindow();
    LogFlush();
    return Result;
}


//==========================================================================
//
//  int execWindowTest13
//
//  Description:
//      This tests the ability to change the current background colour. We
//      start the system running then cycle through the standard Windows
//      colours setting them as the border and making sure we get back the
//      same value. After each one we let the system run free for a while
//      So that the window appears in the middle of the video window with
//      the new border colour around it we set the window styles so that
//      it has no thick frame, no window border and no caption text either
//
//  Return (int): TST_PASS indicating success
//
//==========================================================================

int execWindowTest13()
{
    HRESULT hr = NOERROR;
    COLORREF WindowColour;
    COLORREF CurrentColour;
    long style, adjust;

    Log(TERSE,TEXT("Entering window test #13"));
    LogFlush();
    InitialiseWindow();

    // Set the window size larger and different destination

    EXECUTE_ASSERT(SUCCEEDED(pVideoWindow->get_WindowStyle(&style)));
    adjust = style & ~(WS_CAPTION | WS_BORDER | WS_THICKFRAME);
    EXECUTE_ASSERT(SUCCEEDED(pVideoWindow->put_WindowStyle(adjust)));
    EXECUTE_ASSERT(SUCCEEDED(pVideoWindow->SetWindowPosition(100,100,400,320)));
    EXECUTE_ASSERT(SUCCEEDED(pBasicVideo->SetDestinationPosition(40,40,320,240)));
    YieldAndSleep(1000);
    EXECUTE_ASSERT(SUCCEEDED(pVideoWindow->put_Visible(OATRUE)));
    YieldAndSleep(1000);
    EXECUTE_ASSERT(SUCCEEDED(StartSystem(TRUE)));

    // Test each of the standard system colours

    EXECUTE_ASSERT(SUCCEEDED(pVideoWindow->get_BorderColor((LONG *)&CurrentColour)));
    EXECUTE_ASSERT(CurrentColour == VIDEO_COLOUR);

    WindowColour = GetSysColor(COLOR_ACTIVEBORDER);        // Active border
    EXECUTE_ASSERT(SUCCEEDED(pVideoWindow->put_BorderColor(WindowColour)));
    EXECUTE_ASSERT(SUCCEEDED(pVideoWindow->get_BorderColor((LONG *)&CurrentColour)));
    EXECUTE_ASSERT(CurrentColour == WindowColour);
    YieldAndSleep(1000);

    WindowColour = GetSysColor(COLOR_ACTIVECAPTION);       // Active caption
    EXECUTE_ASSERT(SUCCEEDED(pVideoWindow->put_BorderColor(WindowColour)));
    EXECUTE_ASSERT(SUCCEEDED(pVideoWindow->get_BorderColor((LONG *)&CurrentColour)));
    EXECUTE_ASSERT(CurrentColour == WindowColour);
    YieldAndSleep(1000);

    WindowColour = GetSysColor(COLOR_APPWORKSPACE);        // MDI Background
    EXECUTE_ASSERT(SUCCEEDED(pVideoWindow->put_BorderColor(WindowColour)));
    EXECUTE_ASSERT(SUCCEEDED(pVideoWindow->get_BorderColor((LONG *)&CurrentColour)));
    EXECUTE_ASSERT(CurrentColour == WindowColour);
    YieldAndSleep(1000);

    WindowColour = GetSysColor(COLOR_BACKGROUND);          // Desktop
    EXECUTE_ASSERT(SUCCEEDED(pVideoWindow->put_BorderColor(WindowColour)));
    EXECUTE_ASSERT(SUCCEEDED(pVideoWindow->get_BorderColor((LONG *)&CurrentColour)));
    EXECUTE_ASSERT(CurrentColour == WindowColour);
    YieldAndSleep(1000);

    WindowColour = GetSysColor(COLOR_BTNFACE);             // Push buttom face
    EXECUTE_ASSERT(SUCCEEDED(pVideoWindow->put_BorderColor(WindowColour)));
    EXECUTE_ASSERT(SUCCEEDED(pVideoWindow->get_BorderColor((LONG *)&CurrentColour)));
    EXECUTE_ASSERT(CurrentColour == WindowColour);
    YieldAndSleep(1000);

    WindowColour = GetSysColor(COLOR_BTNSHADOW);           // Push button edge
    EXECUTE_ASSERT(SUCCEEDED(pVideoWindow->put_BorderColor(WindowColour)));
    EXECUTE_ASSERT(SUCCEEDED(pVideoWindow->get_BorderColor((LONG *)&CurrentColour)));
    EXECUTE_ASSERT(CurrentColour == WindowColour);
    YieldAndSleep(1000);

    WindowColour = GetSysColor(COLOR_BTNTEXT);             // Text on buttons
    EXECUTE_ASSERT(SUCCEEDED(pVideoWindow->put_BorderColor(WindowColour)));
    EXECUTE_ASSERT(SUCCEEDED(pVideoWindow->get_BorderColor((LONG *)&CurrentColour)));
    EXECUTE_ASSERT(CurrentColour == WindowColour);
    YieldAndSleep(1000);

    WindowColour = GetSysColor(COLOR_CAPTIONTEXT);         // Text in caption
    EXECUTE_ASSERT(SUCCEEDED(pVideoWindow->put_BorderColor(WindowColour)));
    EXECUTE_ASSERT(SUCCEEDED(pVideoWindow->get_BorderColor((LONG *)&CurrentColour)));
    EXECUTE_ASSERT(CurrentColour == WindowColour);
    YieldAndSleep(1000);

    WindowColour = GetSysColor(COLOR_GRAYTEXT);            // Grayed text
    EXECUTE_ASSERT(SUCCEEDED(pVideoWindow->put_BorderColor(WindowColour)));
    EXECUTE_ASSERT(SUCCEEDED(pVideoWindow->get_BorderColor((LONG *)&CurrentColour)));
    EXECUTE_ASSERT(CurrentColour == WindowColour);
    YieldAndSleep(1000);

    WindowColour = GetSysColor(COLOR_HIGHLIGHT);           // Control selected
    EXECUTE_ASSERT(SUCCEEDED(pVideoWindow->put_BorderColor(WindowColour)));
    EXECUTE_ASSERT(SUCCEEDED(pVideoWindow->get_BorderColor((LONG *)&CurrentColour)));
    EXECUTE_ASSERT(CurrentColour == WindowColour);
    YieldAndSleep(1000);

    WindowColour = GetSysColor(COLOR_HIGHLIGHTTEXT);       // Text of item(s)
    EXECUTE_ASSERT(SUCCEEDED(pVideoWindow->put_BorderColor(WindowColour)));
    EXECUTE_ASSERT(SUCCEEDED(pVideoWindow->get_BorderColor((LONG *)&CurrentColour)));
    EXECUTE_ASSERT(CurrentColour == WindowColour);
    YieldAndSleep(1000);

    WindowColour = GetSysColor(COLOR_INACTIVEBORDER);      // Inactive border
    EXECUTE_ASSERT(SUCCEEDED(pVideoWindow->put_BorderColor(WindowColour)));
    EXECUTE_ASSERT(SUCCEEDED(pVideoWindow->get_BorderColor((LONG *)&CurrentColour)));
    EXECUTE_ASSERT(CurrentColour == WindowColour);
    YieldAndSleep(1000);

    WindowColour = GetSysColor(COLOR_INACTIVECAPTION);     // Inactive window
    EXECUTE_ASSERT(SUCCEEDED(pVideoWindow->put_BorderColor(WindowColour)));
    EXECUTE_ASSERT(SUCCEEDED(pVideoWindow->get_BorderColor((LONG *)&CurrentColour)));
    EXECUTE_ASSERT(CurrentColour == WindowColour);
    YieldAndSleep(1000);

    WindowColour = GetSysColor(COLOR_INACTIVECAPTIONTEXT); // Inactive caption
    EXECUTE_ASSERT(SUCCEEDED(pVideoWindow->put_BorderColor(WindowColour)));
    EXECUTE_ASSERT(SUCCEEDED(pVideoWindow->get_BorderColor((LONG *)&CurrentColour)));
    EXECUTE_ASSERT(CurrentColour == WindowColour);
    YieldAndSleep(1000);

    WindowColour = GetSysColor(COLOR_MENU);                // Menu background
    EXECUTE_ASSERT(SUCCEEDED(pVideoWindow->put_BorderColor(WindowColour)));
    EXECUTE_ASSERT(SUCCEEDED(pVideoWindow->get_BorderColor((LONG *)&CurrentColour)));
    EXECUTE_ASSERT(CurrentColour == WindowColour);
    YieldAndSleep(1000);

    WindowColour = GetSysColor(COLOR_MENUTEXT);            // Text in menus
    EXECUTE_ASSERT(SUCCEEDED(pVideoWindow->put_BorderColor(WindowColour)));
    EXECUTE_ASSERT(SUCCEEDED(pVideoWindow->get_BorderColor((LONG *)&CurrentColour)));
    EXECUTE_ASSERT(CurrentColour == WindowColour);
    YieldAndSleep(1000);

    WindowColour = GetSysColor(COLOR_SCROLLBAR);           // Scroll bar grey
    EXECUTE_ASSERT(SUCCEEDED(pVideoWindow->put_BorderColor(WindowColour)));
    EXECUTE_ASSERT(SUCCEEDED(pVideoWindow->get_BorderColor((LONG *)&CurrentColour)));
    EXECUTE_ASSERT(CurrentColour == WindowColour);
    YieldAndSleep(1000);

    WindowColour = GetSysColor(COLOR_WINDOW);              // Usual background
    EXECUTE_ASSERT(SUCCEEDED(pVideoWindow->put_BorderColor(WindowColour)));
    EXECUTE_ASSERT(SUCCEEDED(pVideoWindow->get_BorderColor((LONG *)&CurrentColour)));
    EXECUTE_ASSERT(CurrentColour == WindowColour);
    YieldAndSleep(1000);

    WindowColour = GetSysColor(COLOR_WINDOWFRAME);         // Window frame
    EXECUTE_ASSERT(SUCCEEDED(pVideoWindow->put_BorderColor(WindowColour)));
    EXECUTE_ASSERT(SUCCEEDED(pVideoWindow->get_BorderColor((LONG *)&CurrentColour)));
    EXECUTE_ASSERT(CurrentColour == WindowColour);
    YieldAndSleep(1000);

    WindowColour = GetSysColor(COLOR_WINDOWTEXT);          // Text in windows
    EXECUTE_ASSERT(SUCCEEDED(pVideoWindow->put_BorderColor(WindowColour)));
    EXECUTE_ASSERT(SUCCEEDED(pVideoWindow->get_BorderColor((LONG *)&CurrentColour)));
    EXECUTE_ASSERT(CurrentColour == WindowColour);
    YieldAndSleep(1000);

    EXECUTE_ASSERT(SUCCEEDED(StopSystem()));
    TerminateWindow();

    Log(TERSE,TEXT("Exiting window test #13"));
    LogFlush();
    return TST_PASS;
}


//==========================================================================
//
//  int execWindowTest14
//
//  Description:
//      This tests the capability to retrieve the current video palette with
//      the IBasicVideo control interface. We first of all check that we're
//      using the eight bit DIB image. We then make sure that we can get the
//      palette entries in a variety of different start positions and counts
//      We use a worker function to check that the values returned actually
//      match up with the palette we supplied in the DIB. After that we try
//      a few invalid tests cases such as negative start positions. We do
//      all of this while we're running to maximise synchronisation problems
//
//  Return (int): TST_PASS indicating success
//
//==========================================================================

int execWindowTest14()
{
    HRESULT hr = NOERROR;
    PALETTEENTRY Palette[iPALETTE_COLORS];
    LONG Count;

    Log(TERSE,TEXT("Entering window test #14"));
    LogFlush();
    InitialiseWindow();

    // See if some kind of palette is in use by asking for just a single entry
    // we know that the only palettised images we supply as eight bit DIBs so
    // we hard code the fact that we expect 256 colours in the later tests

    hr = pBasicVideo->GetVideoPaletteEntries(0,1,&Count,(long *)Palette);
    if (FAILED(hr)) {
        Log(TERSE,TEXT("Palette could not be retrieved"));
        TerminateWindow();
        return TST_PASS;
    }

    EXECUTE_ASSERT(SUCCEEDED(StartSystem(TRUE)));
    EXECUTE_ASSERT(PALETTISED((&VideoInfo)));

    EXECUTE_ASSERT(SUCCEEDED(pBasicVideo->GetVideoPaletteEntries(0,256,&Count,(long *)Palette)));
    EXECUTE_ASSERT(Count == 256);
    EXECUTE_ASSERT(SUCCEEDED(CheckPalettesMatch(0,256,Palette)));

    EXECUTE_ASSERT(SUCCEEDED(pBasicVideo->GetVideoPaletteEntries(128,128,&Count,(long *)Palette)));
    EXECUTE_ASSERT(Count == 128);
    EXECUTE_ASSERT(SUCCEEDED(CheckPalettesMatch(128,128,Palette)));

    EXECUTE_ASSERT(SUCCEEDED(pBasicVideo->GetVideoPaletteEntries(128,129,&Count,(long *)Palette)));
    EXECUTE_ASSERT(Count == 128);
    EXECUTE_ASSERT(SUCCEEDED(CheckPalettesMatch(128,128,Palette)));

    EXECUTE_ASSERT(SUCCEEDED(pBasicVideo->GetVideoPaletteEntries(0,257,&Count,(long *)Palette)));
    EXECUTE_ASSERT(Count == 256);
    EXECUTE_ASSERT(SUCCEEDED(CheckPalettesMatch(0,256,Palette)));

    // Try some invalid start offsets and a negative count

    EXECUTE_ASSERT(pBasicVideo->GetVideoPaletteEntries(0,-1,&Count,(long *)Palette) == S_FALSE);
    EXECUTE_ASSERT(FAILED(pBasicVideo->GetVideoPaletteEntries(256,0,&Count,(long *)Palette)));
    EXECUTE_ASSERT(FAILED(pBasicVideo->GetVideoPaletteEntries(-1,0,&Count,(long *)Palette)));
    EXECUTE_ASSERT(FAILED(pBasicVideo->GetVideoPaletteEntries(257,0,&Count,(long *)Palette)));

    EXECUTE_ASSERT(SUCCEEDED(StopSystem()));

    TerminateWindow();
    Log(TERSE,TEXT("Exiting window test #14"));
    LogFlush();
    return TST_PASS;
}


// This is called with a partial or complete section of a palette retrieved
// from the video renderer. The first two parameters defined the offset into
// the palette and the number of colours. We check the actual RGB triplets
// against those stored in the VIDEOINFO we originally supplied during the
// connection. This checks to some extent that the palette is stored in the
// video renderer correctly and also that it returns the colours correctly

HRESULT CheckPalettesMatch(long StartIndex,         // Start colour position
                           long Entries,            // Number we should use
                           PALETTEENTRY *pPalette)  // The palette colours
{
    EXECUTE_ASSERT(StartIndex < iPALETTE_COLORS);
    EXECUTE_ASSERT(PALETTISED((&VideoInfo)) == TRUE);
    RGBQUAD *pColours = &VideoInfo.bmiColors[StartIndex];

    while (Entries--) {
        EXECUTE_ASSERT(pColours[Entries].rgbRed == pPalette[Entries].peRed);
        EXECUTE_ASSERT(pColours[Entries].rgbGreen == pPalette[Entries].peGreen);
        EXECUTE_ASSERT(pColours[Entries].rgbBlue == pPalette[Entries].peBlue);
        EXECUTE_ASSERT(pPalette[Entries].peFlags == 0);
    }
    return NOERROR;
}


//==========================================================================
//
//  int execWindowTest15
//
//  Description:
//
//  Return (int): TST_PASS indicating success
//      This tests the auto show facility, the default setting of this is
//      TRUE such that any state change will cause the window to be shown
//      An application may set this to FALSE in which case it takes over
//      all responsibility for showing the window. However the video will
//      always be hidden following a disconnect. We also make sure that
//      once we have set the auto show property we can also read it back
//
//==========================================================================

int execWindowTest15()
{
    HRESULT hr = NOERROR;
    long AutoShow;

    Log(TERSE,TEXT("Entering window test #15"));
    LogFlush();

    InitialiseWindow();
    EXECUTE_ASSERT(SUCCEEDED(pVideoWindow->get_AutoShow(&AutoShow)));
    EXECUTE_ASSERT(AutoShow == OATRUE);
    EXECUTE_ASSERT(SUCCEEDED(StartSystem(TRUE)));
    EXECUTE_ASSERT(IsWindowVisible(hVideoWindow));
    EXECUTE_ASSERT(SUCCEEDED(StopSystem()));
    TerminateWindow();
    EXECUTE_ASSERT(IsWindowVisible(hVideoWindow) == FALSE);

    InitialiseWindow();
    EXECUTE_ASSERT(SUCCEEDED(pVideoWindow->put_AutoShow(OAFALSE)));
    EXECUTE_ASSERT(SUCCEEDED(StartSystem(TRUE)));
    EXECUTE_ASSERT(IsWindowVisible(hVideoWindow) == FALSE);
    EXECUTE_ASSERT(SUCCEEDED(pVideoWindow->put_Visible(OATRUE)));
    EXECUTE_ASSERT(IsWindowVisible(hVideoWindow));
    EXECUTE_ASSERT(SUCCEEDED(pVideoWindow->put_Visible(OAFALSE)));
    EXECUTE_ASSERT(IsWindowVisible(hVideoWindow) == FALSE);
    EXECUTE_ASSERT(SUCCEEDED(StopSystem()));
    TerminateWindow();
    EXECUTE_ASSERT(IsWindowVisible(hVideoWindow) == FALSE);

    InitialiseWindow();
    EXECUTE_ASSERT(SUCCEEDED(pVideoWindow->put_AutoShow(OAFALSE)));
    EXECUTE_ASSERT(SUCCEEDED(pVideoWindow->put_Visible(OATRUE)));
    EXECUTE_ASSERT(SUCCEEDED(StartSystem(TRUE)));
    EXECUTE_ASSERT(IsWindowVisible(hVideoWindow));
    EXECUTE_ASSERT(SUCCEEDED(StopSystem()));
    TerminateWindow();
    EXECUTE_ASSERT(IsWindowVisible(hVideoWindow) == FALSE);

    InitialiseWindow();
    EXECUTE_ASSERT(SUCCEEDED(pVideoWindow->put_AutoShow(OAFALSE)));
    EXECUTE_ASSERT(SUCCEEDED(StartSystem(TRUE)));
    EXECUTE_ASSERT(SUCCEEDED(pVideoWindow->get_AutoShow(&AutoShow)));
    EXECUTE_ASSERT(AutoShow == OAFALSE);
    EXECUTE_ASSERT(SUCCEEDED(pVideoWindow->put_Visible(OATRUE)));
    EXECUTE_ASSERT(IsWindowVisible(hVideoWindow));
    EXECUTE_ASSERT(SUCCEEDED(pVideoWindow->get_AutoShow(&AutoShow)));
    EXECUTE_ASSERT(AutoShow == OAFALSE);
    EXECUTE_ASSERT(SUCCEEDED(pVideoWindow->put_Visible(OAFALSE)));
    EXECUTE_ASSERT(IsWindowVisible(hVideoWindow) == FALSE);
    EXECUTE_ASSERT(SUCCEEDED(pVideoWindow->get_AutoShow(&AutoShow)));
    EXECUTE_ASSERT(AutoShow == OAFALSE);
    EXECUTE_ASSERT(SUCCEEDED(StopSystem()));
    TerminateWindow();
    EXECUTE_ASSERT(IsWindowVisible(hVideoWindow) == FALSE);

    Log(TERSE,TEXT("Exiting window test #15"));
    LogFlush();
    return TST_PASS;
}


//==========================================================================
//
//  int execWindowTest16
//
//  Description:
//
//  Return (int): TST_PASS indicating success
//      This tests the capability of the video renderer to provide us with
//      a copy of the current image when it is paused. The image returned
//      should reflect the current source rectangle we have set. For that
//      reason this test sets a number of different and difficult source
//      rectangles and asks for renderings each time. We start the video
//      running so that it is given images, but we adjust the time stamps
//      on these samples so that they are 10000ms apart. This means that
//      we have plenty of time to get in and pause it before it draws the
//      image and subsequently releases it. We have to assume that the
//      ability to set source rectangles correctly has already been done
//
//==========================================================================

int execWindowTest16()
{
    BYTE *pTestImage = NULL;                    // Buffer to hold the images
    HRESULT hr = NOERROR;                       // General OLE return code
    TCHAR String[128];                          // Used to format strings
    LONG BufferSize;                            // Size of buffer needed
    DWORD SaveIncrement = dwIncrement;          // Save inter frame increment
    DWORD SaveSurface = uiCurrentSurfaceItem;   // Save the surface type

    // We change the interframe gap so that when we start running there will
    // be a frame waiting at the renderer for a long time. Thus we will can
    // stop the graph and be assured that there will be a refresh sample

    Log(TERSE,TEXT("Entering window test #16"));
    LogFlush();
    dwIncrement = 10000;
    uiCurrentSurfaceItem = IDM_NONE;

    // Work out which image we are using as it affects the buffer size

    const TCHAR *pResourceName =
        (uiCurrentImageItem == IDM_WIND8 ? pResourceNames[0] :
            uiCurrentImageItem == IDM_WIND555 ? pResourceNames[1] :
                uiCurrentImageItem == IDM_WIND565 ? pResourceNames[2] :
                    uiCurrentImageItem == IDM_WIND24 ? pResourceNames[3] : NULL);

    wsprintf(String,TEXT("Using DIB image %s"),pResourceName);
    Log(TERSE,String);
    InitialiseWindow();

    EXECUTE_ASSERT(SUCCEEDED(pBasicVideo->GetCurrentImage(&BufferSize,NULL)));
    EXECUTE_ASSERT(SUCCEEDED(StartSystem(TRUE)));
    YieldAndSleep(2500);
    EXECUTE_ASSERT(SUCCEEDED(PauseSystem()));

    // We have a temporary VIDEOINFO to calculate image sizes with

    DWORD FormatSize = GetBitmapFormatSize(&VideoInfo.bmiHeader) - SIZE_PREHEADER;
    VIDEOINFO TestInfo = VideoInfo;
    EXECUTE_ASSERT(SUCCEEDED(pBasicVideo->GetCurrentImage(&BufferSize,NULL)));
    EXECUTE_ASSERT(SUCCEEDED(pBasicVideo->GetCurrentImage(&BufferSize,NULL)));

    // Try a source image of one pixel by one pixel

    TestInfo.bmiHeader.biWidth = 1;
    TestInfo.bmiHeader.biHeight = 1;
    TestInfo.bmiHeader.biSizeImage = GetBitmapSize(&TestInfo.bmiHeader);
    pTestImage = new BYTE[TestInfo.bmiHeader.biSizeImage + FormatSize];

    EXECUTE_ASSERT(SUCCEEDED(pBasicVideo->SetSourcePosition(0,0,1,1)));
    BufferSize = 0;
    EXECUTE_ASSERT(SUCCEEDED(pBasicVideo->GetCurrentImage(&BufferSize,NULL)));
    EXECUTE_ASSERT((DWORD)BufferSize == FormatSize + TestInfo.bmiHeader.biSizeImage);
    EXECUTE_ASSERT(SUCCEEDED(pBasicVideo->GetCurrentImage(&BufferSize,(LONG *)pTestImage)));
    EXECUTE_ASSERT(memcmp((PVOID)pTestImage,(PVOID)&TestInfo.bmiHeader,FormatSize) == 0);
    delete[] pTestImage;

    // Now try setting the source to equal the full image

    TestInfo.bmiHeader.biWidth = 320;
    TestInfo.bmiHeader.biHeight = 240;
    TestInfo.bmiHeader.biSizeImage = GetBitmapSize(&TestInfo.bmiHeader);
    pTestImage = new BYTE[TestInfo.bmiHeader.biSizeImage + FormatSize];

    EXECUTE_ASSERT(SUCCEEDED(pBasicVideo->SetSourcePosition(0,0,320,240)));
    BufferSize = 0;
    EXECUTE_ASSERT(SUCCEEDED(pBasicVideo->GetCurrentImage(&BufferSize,NULL)));
    EXECUTE_ASSERT((DWORD)BufferSize == FormatSize + TestInfo.bmiHeader.biSizeImage);
    EXECUTE_ASSERT(SUCCEEDED(pBasicVideo->GetCurrentImage(&BufferSize,(LONG *)pTestImage)));
    EXECUTE_ASSERT(memcmp((PVOID)pTestImage,(PVOID)&TestInfo.bmiHeader,FormatSize) == 0);

    EXECUTE_ASSERT(memcmp((PVOID)(pTestImage + FormatSize),
                          (PVOID)bImageData,
                          TestInfo.bmiHeader.biSizeImage) == 0);

    delete[] pTestImage;

    // Now try setting a source that is half the full image size

    TestInfo.bmiHeader.biWidth = 160;
    TestInfo.bmiHeader.biHeight = 120;
    TestInfo.bmiHeader.biSizeImage = GetBitmapSize(&TestInfo.bmiHeader);
    pTestImage = new BYTE[TestInfo.bmiHeader.biSizeImage + FormatSize];

    EXECUTE_ASSERT(SUCCEEDED(pBasicVideo->SetSourcePosition(0,0,160,120)));
    BufferSize = 0;
    EXECUTE_ASSERT(SUCCEEDED(pBasicVideo->GetCurrentImage(&BufferSize,NULL)));
    EXECUTE_ASSERT((DWORD)BufferSize == FormatSize + TestInfo.bmiHeader.biSizeImage);
    EXECUTE_ASSERT(SUCCEEDED(pBasicVideo->GetCurrentImage(&BufferSize,(LONG *)pTestImage)));
    EXECUTE_ASSERT(memcmp((PVOID)pTestImage,(PVOID)&TestInfo.bmiHeader,FormatSize) == 0);

    delete[] pTestImage;

    // Now try setting a square source in the middle of the image

    TestInfo.bmiHeader.biWidth = 100;
    TestInfo.bmiHeader.biHeight = 100;
    TestInfo.bmiHeader.biSizeImage = GetBitmapSize(&TestInfo.bmiHeader);
    pTestImage = new BYTE[TestInfo.bmiHeader.biSizeImage + FormatSize];

    EXECUTE_ASSERT(SUCCEEDED(pBasicVideo->SetSourcePosition(110,60,100,100)));
    BufferSize = 0;
    EXECUTE_ASSERT(SUCCEEDED(pBasicVideo->GetCurrentImage(&BufferSize,NULL)));
    EXECUTE_ASSERT((DWORD)BufferSize == FormatSize + TestInfo.bmiHeader.biSizeImage);
    EXECUTE_ASSERT(SUCCEEDED(pBasicVideo->GetCurrentImage(&BufferSize,(LONG *)pTestImage)));
    EXECUTE_ASSERT(memcmp((PVOID)pTestImage,(PVOID)&TestInfo.bmiHeader,FormatSize) == 0);

    delete[] pTestImage;

    // Clean up after the current image property test

    Log(TERSE,TEXT("Exiting window test #16"));
    EXECUTE_ASSERT(SUCCEEDED(StopSystem()));
    TerminateWindow();

    // Reset the state variables after the test

    dwIncrement = SaveIncrement;
    uiCurrentSurfaceItem = SaveSurface;
    LogFlush();
    return TST_PASS;
}


// Given test sixteen does not GP fault or otherwise fail it still leaves
// us unsure whether or not the images returned when using different source
// rectangles really match with that expected. The simpest way to verify the
// images is to call this function with the entire image data and this will
// then write it correctly formatted (including the file header) into a DIB
// file. This file can then be loaded manually into PaintBrush and examined

void WriteImageToFile(BYTE *pImageData,DWORD ImageSize)
{
    DWORD BytesWritten;
    TCHAR szFileName[] = TEXT("IMAGETST.DIB");
    HANDLE hFile = INVALID_HANDLE_VALUE;
    BITMAPFILEHEADER FileHeader;

    // Always create a new file to write the image into

    while (hFile == INVALID_HANDLE_VALUE) {

        hFile = CreateFile(szFileName,          // Image file name
                           GENERIC_WRITE,       // Access mode
                           (DWORD) 0,           // No sharing
                           NULL,                // No security
                           CREATE_ALWAYS,       // Always create it
                           (DWORD) 0,           // No attributes
                           (HANDLE) NULL);      // No template
    }

    // Write the BITMAPFILEHEADER out first

    FileHeader.bfType = 0x4d42;             // Magic bytes spells BM
    FileHeader.bfSize = ImageSize / 4;      // DWORD total file size
    FileHeader.bfReserved1 = 0;             // Zero reserved fields
    FileHeader.bfReserved2 = 0;             // And another reserved

    FileHeader.bfOffBits = sizeof(FileHeader);
    FileHeader.bfOffBits += GetBitmapFormatSize((BITMAPINFOHEADER *)pImageData);
    FileHeader.bfOffBits -= SIZE_PREHEADER;

    WriteFile(hFile,                  // Our file handle
              (LPCVOID) &FileHeader,  // Output data buffer
              sizeof(FileHeader),     // Number of bytes to write
              &BytesWritten,          // Returns number written
              NULL);                  // Synchronous operation

    EXECUTE_ASSERT(BytesWritten == sizeof(FileHeader));

    // Now write the image format and data itself

    WriteFile(hFile,                  // Our file handle
              (LPCVOID) pImageData,   // Output data buffer
              ImageSize,              // Number of bytes to write
              &BytesWritten,          // Returns number written
              NULL);                  // Synchronous operation

    EXECUTE_ASSERT(BytesWritten == ImageSize);
    EXECUTE_ASSERT(FlushFileBuffers(hFile));
    EXECUTE_ASSERT(CloseHandle(hFile));
}


//==========================================================================
//
//  int execWindowTest17
//
//  Description:
//
//  Return (int): TST_PASS indicating success
//
//      All IBasicVideo and IVideoWindow methods are persistent between
//      connections. This makes it easier to handle dynamic changes to
//      filtergraphs as the window doesn't disappear and reappear. This
//      test checks this by setting all the methods it reasonably can
//      and then disconnecting and reconnecting the render many times.
//      After the reconnections the properties should all be the same
//

//==========================================================================

int execWindowTest17()
{
    Log(TERSE,TEXT("Entering window test #17"));
    LogFlush();
    InitialiseWindow();

    BSTR Caption;
    LONG Style,StyleEx,AutoShow,State,Palette;
    LONG Left,Top,Width,Height,CursorHidden;
    LONG SourceLeft,SourceTop,SourceWidth,SourceHeight;
    LONG TargetLeft,TargetTop,TargetWidth,TargetHeight;

    // Set as many IVideoWindow and IBasicVideo properties as we can

    EXECUTE_ASSERT(SUCCEEDED(pVideoWindow->put_Caption(L"Test Window Caption")));
    EXECUTE_ASSERT(SUCCEEDED(pVideoWindow->put_WindowStyle(WS_POPUP | WS_CAPTION | WS_BORDER)));
    EXECUTE_ASSERT(SUCCEEDED(pVideoWindow->put_WindowStyleEx(WS_EX_ACCEPTFILES)));
    EXECUTE_ASSERT(SUCCEEDED(pVideoWindow->put_AutoShow(OAFALSE)));
    EXECUTE_ASSERT(SUCCEEDED(pVideoWindow->put_BackgroundPalette(OATRUE)));
    EXECUTE_ASSERT(SUCCEEDED(pVideoWindow->put_Left(100)));
    EXECUTE_ASSERT(SUCCEEDED(pVideoWindow->put_Top(50)));
    EXECUTE_ASSERT(SUCCEEDED(pVideoWindow->put_Width(200)));
    EXECUTE_ASSERT(SUCCEEDED(pVideoWindow->put_Height(200)));
    EXECUTE_ASSERT(SUCCEEDED(pBasicVideo->put_SourceWidth(100)));
    EXECUTE_ASSERT(SUCCEEDED(pBasicVideo->put_SourceHeight(100)));
    EXECUTE_ASSERT(SUCCEEDED(pBasicVideo->put_SourceLeft(10)));
    EXECUTE_ASSERT(SUCCEEDED(pBasicVideo->put_SourceTop(10)));
    EXECUTE_ASSERT(SUCCEEDED(pBasicVideo->put_DestinationHeight(100)));
    EXECUTE_ASSERT(SUCCEEDED(pBasicVideo->put_DestinationWidth(100)));
    EXECUTE_ASSERT(SUCCEEDED(pBasicVideo->put_DestinationLeft(10)));
    EXECUTE_ASSERT(SUCCEEDED(pBasicVideo->put_DestinationTop(10)));
    EXECUTE_ASSERT(SUCCEEDED(pVideoWindow->put_WindowState(SW_SHOWNORMAL)));
    EXECUTE_ASSERT(SUCCEEDED(pVideoWindow->HideCursor(OATRUE)));

    // Run with these properties for a while

    EXECUTE_ASSERT(SUCCEEDED(PauseSystem()));
    EXECUTE_ASSERT(SUCCEEDED(StartSystem(TRUE)));
    YieldAndSleep(5000);
    EXECUTE_ASSERT(SUCCEEDED(PauseSystem()));
    EXECUTE_ASSERT(SUCCEEDED(StopSystem()));

    // Disconnect and reconnect a few times

    EXECUTE_ASSERT(SUCCEEDED(DisconnectStream()));
    EXECUTE_ASSERT(SUCCEEDED(ConnectStream()));
    EXECUTE_ASSERT(SUCCEEDED(DisconnectStream()));
    EXECUTE_ASSERT(SUCCEEDED(ConnectStream()));
    EXECUTE_ASSERT(SUCCEEDED(DisconnectStream()));
    EXECUTE_ASSERT(SUCCEEDED(ConnectStream()));
    EXECUTE_ASSERT(FAILED(ConnectStream()));

    // Now read each property and check it matches

    EXECUTE_ASSERT(SUCCEEDED(pVideoWindow->get_Caption(&Caption)));
    EXECUTE_ASSERT(lstrcmpW(Caption,L"Test Window Caption") == 0);
    EXECUTE_ASSERT(SUCCEEDED(pVideoWindow->get_WindowStyle(&Style)));
    EXECUTE_ASSERT((Style & WS_POPUP));
    EXECUTE_ASSERT((Style & WS_CAPTION));
    EXECUTE_ASSERT((Style & WS_BORDER));
    EXECUTE_ASSERT(SUCCEEDED(pVideoWindow->get_WindowStyleEx(&StyleEx)));
    EXECUTE_ASSERT((StyleEx & WS_EX_ACCEPTFILES));
    EXECUTE_ASSERT(SUCCEEDED(pVideoWindow->get_AutoShow(&AutoShow)));
    EXECUTE_ASSERT((AutoShow == OAFALSE));
    EXECUTE_ASSERT(SUCCEEDED(pVideoWindow->get_BackgroundPalette(&Palette)));
    EXECUTE_ASSERT((Palette == OATRUE));
    EXECUTE_ASSERT(SUCCEEDED(pVideoWindow->get_WindowState(&State)));
    EXECUTE_ASSERT((State == SW_SHOW));
    EXECUTE_ASSERT(SUCCEEDED(pVideoWindow->IsCursorHidden(&CursorHidden)));
    EXECUTE_ASSERT(CursorHidden == OATRUE);

    // Get the video window position

    EXECUTE_ASSERT(SUCCEEDED(pVideoWindow->get_Left(&Left)));
    EXECUTE_ASSERT(SUCCEEDED(pVideoWindow->get_Top(&Top)));
    EXECUTE_ASSERT(SUCCEEDED(pVideoWindow->get_Width(&Width)));
    EXECUTE_ASSERT(SUCCEEDED(pVideoWindow->get_Height(&Height)));
    EXECUTE_ASSERT(Left == 100);
    EXECUTE_ASSERT(Top == 50);
    EXECUTE_ASSERT(Width == 200);
    EXECUTE_ASSERT(Height == 200);

    EXECUTE_ASSERT(SUCCEEDED(pBasicVideo->get_SourceLeft(&SourceLeft)));
    EXECUTE_ASSERT(SUCCEEDED(pBasicVideo->get_SourceTop(&SourceTop)));
    EXECUTE_ASSERT(SUCCEEDED(pBasicVideo->get_SourceWidth(&SourceWidth)));
    EXECUTE_ASSERT(SUCCEEDED(pBasicVideo->get_SourceHeight(&SourceHeight)));
    EXECUTE_ASSERT(SUCCEEDED(pBasicVideo->get_DestinationLeft(&TargetLeft)));
    EXECUTE_ASSERT(SUCCEEDED(pBasicVideo->get_DestinationTop(&TargetTop)));
    EXECUTE_ASSERT(SUCCEEDED(pBasicVideo->get_DestinationHeight(&TargetHeight)));
    EXECUTE_ASSERT(SUCCEEDED(pBasicVideo->get_DestinationWidth(&TargetWidth)));
    EXECUTE_ASSERT(pBasicVideo->IsUsingDefaultSource() == S_FALSE);
    EXECUTE_ASSERT(pBasicVideo->IsUsingDefaultDestination() == S_FALSE);

    EXECUTE_ASSERT(SourceLeft == 10);
    EXECUTE_ASSERT(SourceTop == 10);
    EXECUTE_ASSERT(SourceWidth == 100);
    EXECUTE_ASSERT(SourceHeight == 100);
    EXECUTE_ASSERT(TargetLeft == 10);
    EXECUTE_ASSERT(TargetTop == 10);
    EXECUTE_ASSERT(TargetWidth == 100);
    EXECUTE_ASSERT(TargetHeight == 100);

    TerminateWindow();
    Log(TERSE,TEXT("Exiting window test #17"));
    LogFlush();
    return TST_PASS;
}


//==========================================================================
//
//  int execWindowTest18
//
//  Description:
//
//  Return (int): TST_PASS indicating success
//
//      When a video window is either maximised or iconic the coordinates
//      returned from any of the window position properties or methods
//      give the actual current position. This method will return the
//      normal window size. Which is the size obtained if an application
//      called IVideoWindow put_WindowState(SW_SHOWNORMAL). This method
//      is useful for applications that want to store the window state
//
//==========================================================================

int execWindowTest18()
{
    Log(TERSE,TEXT("Entering window test #18"));
    LONG Left,Top,Width,Height;
    LONG RLeft,RTop,RWidth,RHeight;
    LogFlush();
    InitialiseWindow();

    // First of all start the window running

    EXECUTE_ASSERT(SUCCEEDED(PauseSystem()));
    EXECUTE_ASSERT(SUCCEEDED(pVideoWindow->GetWindowPosition(&Left,&Top,&Width,&Height)));
    EXECUTE_ASSERT(SUCCEEDED(StartSystem(TRUE)));
    YieldAndSleep(2500);

    // Check the restored window position before we start

    EXECUTE_ASSERT(SUCCEEDED(pVideoWindow->GetRestorePosition(&RLeft,&RTop,&RWidth,&RHeight)));
    EXECUTE_ASSERT(RLeft == Left);
    EXECUTE_ASSERT(RTop == Top);
    EXECUTE_ASSERT(RWidth == Width);
    EXECUTE_ASSERT(RHeight == Height);

    EXECUTE_ASSERT(SUCCEEDED(pVideoWindow->put_WindowState(SW_SHOWMAXIMIZED)));
    EXECUTE_ASSERT(SUCCEEDED(pVideoWindow->GetRestorePosition(&RLeft,&RTop,&RWidth,&RHeight)));
    EXECUTE_ASSERT(RLeft == Left);
    EXECUTE_ASSERT(RTop == Top);
    EXECUTE_ASSERT(RWidth == Width);
    EXECUTE_ASSERT(RHeight == Height);

    EXECUTE_ASSERT(SUCCEEDED(pVideoWindow->put_WindowState(SW_SHOWMINIMIZED)));
    EXECUTE_ASSERT(SUCCEEDED(pVideoWindow->GetRestorePosition(&RLeft,&RTop,&RWidth,&RHeight)));
    EXECUTE_ASSERT(RLeft == Left);
    EXECUTE_ASSERT(RTop == Top);
    EXECUTE_ASSERT(RWidth == Width);
    EXECUTE_ASSERT(RHeight == Height);

    EXECUTE_ASSERT(SUCCEEDED(pVideoWindow->put_WindowState(SW_SHOWNORMAL)));
    EXECUTE_ASSERT(SUCCEEDED(pVideoWindow->GetRestorePosition(&RLeft,&RTop,&RWidth,&RHeight)));
    EXECUTE_ASSERT(RLeft == Left);
    EXECUTE_ASSERT(RTop == Top);
    EXECUTE_ASSERT(RWidth == Width);
    EXECUTE_ASSERT(RHeight == Height);

    EXECUTE_ASSERT(SUCCEEDED(pVideoWindow->put_WindowState(SW_SHOWMAXIMIZED)));
    EXECUTE_ASSERT(SUCCEEDED(pVideoWindow->GetRestorePosition(&RLeft,&RTop,&RWidth,&RHeight)));
    EXECUTE_ASSERT(RLeft == Left);
    EXECUTE_ASSERT(RTop == Top);
    EXECUTE_ASSERT(RWidth == Width);
    EXECUTE_ASSERT(RHeight == Height);

    EXECUTE_ASSERT(SUCCEEDED(pVideoWindow->put_WindowState(SW_SHOWMINIMIZED)));
    EXECUTE_ASSERT(SUCCEEDED(pVideoWindow->GetRestorePosition(&RLeft,&RTop,&RWidth,&RHeight)));
    EXECUTE_ASSERT(RLeft == Left);
    EXECUTE_ASSERT(RTop == Top);
    EXECUTE_ASSERT(RWidth == Width);
    EXECUTE_ASSERT(RHeight == Height);

    EXECUTE_ASSERT(SUCCEEDED(pVideoWindow->put_WindowState(SW_SHOWNORMAL)));
    EXECUTE_ASSERT(SUCCEEDED(pVideoWindow->GetRestorePosition(&RLeft,&RTop,&RWidth,&RHeight)));
    EXECUTE_ASSERT(RLeft == Left);
    EXECUTE_ASSERT(RTop == Top);
    EXECUTE_ASSERT(RWidth == Width);
    EXECUTE_ASSERT(RHeight == Height);

    EXECUTE_ASSERT(SUCCEEDED(StopSystem()));
    TerminateWindow();
    Log(TERSE,TEXT("Exiting window test #18"));
    LogFlush();
    return TST_PASS;
}
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\multimedia\dshow\filters\image\vidtest\imagetst.h ===
// Copyright (c) Microsoft Corporation 1994-1996. All Rights Reserved
// Digital video renderer test, Anthony Phillips, January 1995

#ifndef _IMAGETST_
#define _IMAGETST_

// Forward class declarations

class COverlayNotify;       // Handles IOverlayNotify interface
class CImagePin;            // Manages a derived input pin object
class CImageSource;         // Main image source filter class

// Handle the user and test shell interfaces

VOID CALLBACK SaveCustomProfile(LPCSTR pszProfileName);
VOID CALLBACK LoadCustomProfile(LPCSTR pszProfileName);
void SetImageMenuCheck(UINT uiMenuItem);
void SetConnectionMenuCheck(UINT uiMenuItem);
void SetSurfaceMenuCheck(UINT uiMenuItem);
void ChangeConnectionType(UINT uiMenuItem);
void DisplayMediaType(const CMediaType *pmtIn);

void Log(UINT iLogLevel,LPTSTR text);
void LogFlush();
BOOL InitialiseTest();
BOOL DumpTestObjects();

BOOL CALLBACK SetTimeIncrDlgProc(HWND hwndDlg, UINT uMsg, WPARAM wParam, LPARAM lParam);
LRESULT MenuProc(HWND hwnd,UINT msg,WPARAM wParam,LPARAM lParam);
BOOL InitOptionsMenu(LRESULT (CALLBACK* ManuProc)(HWND, UINT, WPARAM, LPARAM));
LRESULT tstAppWndProc(HWND hWnd, UINT msg, WPARAM wParam, LPARAM lParam);

// Load and manage the list of DirectDraw display modes

HRESULT CALLBACK MenuCallBack(LPDDSURFACEDESC pSurfaceDesc,LPVOID lParam);
BOOL InitDirectDraw();
BOOL ReleaseDirectDraw();
BOOL InitDisplayModes();
void SetDisplayMode(UINT uiMode);
void SetDisplayModeMenu(UINT uiMode);

// Track DirectDraw enabled samples

void ResetDDCount();
void IncrementDDCount();
DWORD GetDDCount();

// Stops the logging intensive test

#define VSTOPKEY VK_SPACE
#define SECTION_LENGTH 100

// The string identifiers for the group's names

#define GRP_SAMPLES             100
#define GRP_OVERLAY             101
#define GRP_WINDOW              102
#define GRP_DDRAW               103
#define GRP_SPEED               104
#define GRP_SYSTEM              105
#define GRP_LAST                GRP_SYSTEM

// The string identifiers for the test's names

#define ID_TEST1        201     // Connect and disconnect the renderer
#define ID_TEST2        202     // Connect, pause video and disconnect
#define ID_TEST3        203     // Connect video, play and disconnect
#define ID_TEST4        204     // Connect renderer and connect again
#define ID_TEST5        205     // Connect and disconnect twice
#define ID_TEST6        206     // Try to disconnect while paused
#define ID_TEST7        207     // Try to disconnect while running
#define ID_TEST8        208     // Try multiple state changes
#define ID_TEST9        209     // Run without a reference clock
#define ID_TEST10       210     // Multithread stress test
#define ID_TEST11       211     // Connect and disconnect the renderer
#define ID_TEST12       212     // Connect, pause video and disconnect
#define ID_TEST13       213     // Connect video, play and disconnect
#define ID_TEST14       214     // Connect renderer and connect again
#define ID_TEST15       215     // Connect and disconnect twice
#define ID_TEST16       216     // Try to disconnect while paused
#define ID_TEST17       217     // Try to disconnect while running
#define ID_TEST18       218     // Try multiple state changes
#define ID_TEST19       219     // Run without a reference clock
#define ID_TEST20       220     // Multithread stress test
#define ID_TEST21       221     // Test the visible property
#define ID_TEST22       222     // Test the background palette property
#define ID_TEST23       223     // Change the window position
#define ID_TEST24       224     // (methods) Change the window position
#define ID_TEST25       225     // Change the source rectangle
#define ID_TEST26       226     // (methods) Change the source rectangle
#define ID_TEST27       227     // Change the destination rectangle
#define ID_TEST28       228     // (methods) Change the destination rectangle
#define ID_TEST29       229     // Make a different window the owner
#define ID_TEST30       230     // Check the video size properties
#define ID_TEST31       231     // Change the video window state
#define ID_TEST32       232     // Change the style of the window
#define ID_TEST33       233     // Set different border colours
#define ID_TEST34       234     // Get the current video palette
#define ID_TEST35       235     // Auto show state property
#define ID_TEST36       236     // Current image property
#define ID_TEST37       237     // Persistent video properties
#define ID_TEST38       238     // Restored window position method
#define ID_TEST39       239     // No DCI/DirectDraw support
#define ID_TEST40       240     // DCI primary surfaces
#define ID_TEST41       241     // DirectDraw primary surfaces
#define ID_TEST42       242     // DirectDraw RGB overlay surfaces
#define ID_TEST43       243     // DirectDraw YUV overlay surfaces
#define ID_TEST44       244     // DirectDraw RGB offscreen surfaces
#define ID_TEST45       245     // DirectDraw YUV offscreen surfaces
#define ID_TEST46       246     // DirectDraw RGB flipping surfaces
#define ID_TEST47       247     // DirectDraw YUV flipping surfaces
#define ID_TEST48       248     // Run ALL tests against all display modes
#define ID_TEST49       249     // Minimal range of performance tests
#define ID_TEST50       250     // Measure speed of colour conversions
#define ID_TEST51       251     // Same as above except force unaligned
#define ID_TEST52       252     // System test with DirectDraw loaded
#define ID_TEST53       253     // Same tests without DirectDraw loaded
#define ID_TEST54       254     // All tests with all surfaces and modes

#define ID_TESTLAST     ID_TEST54

// Windows identifiers

#define IDM_CREATE              101     // Create the test filters
#define IDM_RELEASE             102     // Release all filter interfaces
#define IDM_CONNECT             103     // Connect the test filters up
#define IDM_DISCONNECT          104     // Disconnect the test filters
#define IDM_STOP                105     // Have the test filters stopped
#define IDM_PAUSE               106     // Pause the samples worker thread
#define IDM_RUN                 107     // Start the worker thread running
#define IDM_EXIT                108     // Quit the image test application
#define IDM_WIND8               109     // 256 colour palettised image
#define IDM_WIND555             110     // RGB555 colour format image
#define IDM_WIND565             111     // RGB565 colour format image
#define IDM_WIND24              112     // 24 bits per pixel colour image
#define IDM_OVERLAY             113     // Connection to use IOverlay
#define IDM_SAMPLES             114     // Connections type to use samples
#define IDM_SETTIMEINCR         115     // Change rate for sending samples
#define IDC_EDIT1               116     // Used to enter the time increment
#define IDM_DUMP                117     // Display all the active objects
#define IDM_BREAK               118     // Break into the debugger
#define IDM_NONE                119     // Disable all DCI/DirectDraw
#define IDM_DCIPS               120     // Enable DCI primary surface
#define IDM_PS                  121     // DirectDraw primary surface
#define IDM_RGBOVR              122     // Enable RGB overlays
#define IDM_YUVOVR              123     // NON RGB (eg YUV) overlays
#define IDM_RGBOFF              124     // RGB offscreen surfaces
#define IDM_YUVOFF              125     // NON RGB (eg YUV) offscreen
#define IDM_RGBFLP              126     // RGB flipping surfaces
#define IDM_YUVFLP              127     // Likewise YUV flipping surfaces
#define IDM_LOADED              128     // Have we loaded DirectDraw
#define IDM_UNLOADED            129     // DirectDraw not currently loaded

// We have a submenu that we fill with all the display modes that DirectDraw
// supports for the current display card. The number varies widely but can
// be anything from none to twenty. As we add each mode description to the
// submenu we give it successive numbers after IDM_MODE. Therefore make sure
// that there are quite a few spare numbers after this to accomodate them

#define IDM_MODE                400     // First menu item in modes menu

// Identifies the test list section of the resource file

#define TEST_LIST               500

// Window details such as menu item positions and defaults

#define DEFAULT                 IDM_WIND8
#define IMAGE_MENU_POS          2
#define DIRECTDRAW_MENU_POS     3
#define SURFACE_MENU_POS        4
#define CONNECTION_MENU_POS     5
#define MODES_MENU_POS          7
#define DEFAULT_INDEX           0
#define GUID_STRING             128
#define ITERATIONS              100

// Maximum image dimensions

#define MAXIMAGEWIDTH           640
#define MAXIMAGEHEIGHT          480
#define MAXIMAGESIZE            (MAXIMAGEHEIGHT * MAXIMAGEWIDTH)

// Number of pins available and their index number

const int NUMBERMEDIATYPES = 21;    // Try lots of duff types
const int NUMBERBUFFERS = 1;        // Use one media sample
const int INFO = 128;               // Size of information string
const int WINDOW_TIMEOUT = 20;      // Keeps the window responsive
const int WAIT_RETRIES = 20;        // Waiting for threads limited
const int THREADS = 10;             // Number of stress threads
const int TIMEOUT = 100;            // Timeout waiting after 100ms
const int WIDTH = 320;              // Test images pixel width
const int HEIGHT = 240;             // And their associated height
const int BITRATE = 150;            // Approximate bits per second
const int BITERRORRATE = 100;       // Completely made up error rate
const int AVGTIME = 100000;         // Roughly 10ms per video frame

#include "imagedbg.h"               // Redefines the debug output
#include "imagedib.h"               // Loads and manages DIB files
#include "imagewnd.h"               // Runs control interface tests
#include "imageobj.h"               // Manages the video test objects
#include "imageovr.h"               // IOverlay interface test object
#include "imagesrc.h"               // Implements a test filter
#include "imagesys.h"               // ActiveMovie filtergraph class
#include "imagegrf.h"               // System filtergraph video tests
#include "overtest.h"               // Overlay test functions
#include "samptest.h"               // Sample based testing functions
#include "imagedat.h"               // Global (ug) state variables
#include "tests.h"                  // State and connection tests
#include "ddtests.h"                // DirectDraw provider tests
#include "speed.h"                  // Renderer performance tests

#define ABS(x) (x < 0 ? -x : x)

#endif // _IMAGETST_
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\multimedia\dshow\filters\image\vidtest\makefile.inc ===
# NTTARGETFILES targets

# Browse data for the app

SHELLDIR=$(SHELLTREE)\src\obj\$(TARGET_DIRECTORY)

SBRS=obj\$(TARGET_DIRECTORY)\tests.sbr   \
     obj\$(TARGET_DIRECTORY)\imagetst.sbr   \
     obj\$(TARGET_DIRECTORY)\shell.sbr   \
     obj\$(TARGET_DIRECTORY)\filter.sbr  \
     obj\$(TARGET_DIRECTORY)\pin.sbr     \
     $(SHELLDIR)\tslog.sbr               \
     $(SHELLDIR)\tsrunset.sbr            \
     $(SHELLDIR)\tsseltst.sbr            \
     $(SHELLDIR)\tssetpth.sbr            \
     $(SHELLDIR)\tsstats.sbr             \
     $(SHELLDIR)\tsstep.sbr              \
     $(SHELLDIR)\tsmain.sbr              \
     $(SHELLDIR)\wpf.sbr                 \
     $(SHELLDIR)\toolbar.sbr             \
     $(SHELLDIR)\text.sbr

BSCMAKETMP=$(SHELLDIR)\bscmake.tmp

# Build the browse file

$(TARGETPATH)\$(TARGET_DIRECTORY)\$(TARGETNAME).bsc: $(SBRS)
    md $(BSCMAKETMP)
    copy $(SHELLDIR)\*.sbr $(BSCMAKETMP)
    bscmake /o $@ $**
    copy $(BSCMAKETMP)\*.sbr $(SHELLDIR)
    deltree /y $(BSCMAKETMP)


# Test shell help file

$(TARGETPATH)\$(TARGET_DIRECTORY)\tstshell.hlp:
    copy $(SHELLTREE)\src\help\tstshell.hlp $@
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\multimedia\dshow\filters\image\vidtest\overtest.h ===
// Copyright (c) Microsoft Corporation 1994-1996. All Rights Reserved
// Implements basic overlay testing, Anthony Phillips, July 1995

#ifndef __OVERTEST__
#define __OVERTEST__

DWORD OverlayLoop(LPVOID lpvThreadParm);
DWORD ThreadOverlayLoop(LPVOID lpvThreadParm);
HRESULT GetDefaultColourKey(IOverlay *pOverlay);
HRESULT GetClippingList(IOverlay *pOverlay);
HRESULT GetSystemPalette(IOverlay *pOverlay);
HRESULT GetWindowHandle(IOverlay *pOverlay);
HRESULT GetWindowPosition(IOverlay *pOverlay);
HRESULT GetCurrentColourKey(IOverlay *pOverlay);
HRESULT DisplayColourKey(const COLORKEY *pColourKey);
HRESULT DisplaySystemPalette(DWORD dwColours,const PALETTEENTRY *pPalette);
HRESULT SetColourKey(IOverlay *pOverlay,DWORD dwColourIndex);

HRESULT DisplayClippingInformation(const RECT *pSourceRect,
                                   const RECT *pTargetRect,
                                   const RGNDATA *pRgnData);

#endif // __OVERTEST__


=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\multimedia\dshow\filters\image\vidtest\overtest.cpp ===
// Copyright (c) Microsoft Corporation 1994-1996. All Rights Reserved
// Implements basic overlay testing, Anthony Phillips, July 1995

#include <streams.h>        // Includes all the IDL and base classes
#include <windows.h>        // Standard Windows SDK header file
#include <windowsx.h>       // Win32 Windows extensions and macros
#include <vidprop.h>        // Shared video properties library
#include <render.h>         // Normal video renderer header file
#include <modex.h>          // Specialised Modex video renderer
#include <convert.h>        // Defines colour space conversions
#include <colour.h>         // Rest of the colour space convertor
#include <imagetst.h>       // All our unit test header files
#include <stdio.h>          // Standard C runtime header file
#include <limits.h>         // Defines standard data type limits
#include <tchar.h>          // Unicode and ANSII portable types
#include <mmsystem.h>       // Multimedia used for timeGetTime
#include <stdlib.h>         // Standard C runtime function library
#include <tstshell.h>       // Definitions of constants eg TST_FAIL

// The overlay interface allows a source filter to install a custom palette
// although it cannot guarantee that the palette will be realised in the
// foreground (as it depends who has the current window focus). This is a
// simple test palette that we send down the pipe and hopefully we should
// see a palette changed callback with these entries appearing somewhere

PALETTEENTRY TestPalette[10] = {{ 14,14,14,0 },
                                { 15,15,15,0 },
                                { 16,16,16,0 },
                                { 17,17,17,0 },
                                { 18,18,18,0 },
                                { 19,19,19,0 },
                                { 20,20,20,0 },
                                { 21,21,21,0 },
                                { 22,22,22,0 },
                                { 23,23,23,0 }};

// This tests the direct video IOverlay interface, this function is executed
// on a separate worker thread. The first thing to do is setup an advise link
// with the renderer so we get asynchronous notifications for palettes and
// clipping. We then try and set a palette (which may not work if this is a
// true colour device) We then go into an infinite loop setting different
// colour keys with the renderer. The thread that created us can signal that
// it wants us to stop by setting the hState event, we will cancel the advise
// link and then terminate the thread. We put a small pause in between each
// time we set the colour key otherwise it gives too little user feedback

DWORD OverlayLoop(LPVOID lpvThreadParm)
{
    DWORD dwResult = WAIT_TIMEOUT;
    NOTE("Single thread overlay test");
    ASSERT(pOverlay);

    // We are seeing this not return the correct error code

    HRESULT hr = pOverlay->Unadvise();
    if (hr != VFW_E_NO_ADVISE_SET) {
        TCHAR UnadviseProblem[INFO];
        wsprintf(UnadviseProblem,"Unadvise %x",hr);
        MessageBox(ghwndTstShell,UnadviseProblem,"Unadvise",MB_OK);
    }

    EXECUTE_ASSERT(pOverlay->Unadvise() == VFW_E_NO_ADVISE_SET);
    EXECUTE_ASSERT(pOverlay->Advise(NULL,ADVISE_ALL) == E_POINTER);
    EXECUTE_ASSERT(pOverlay->Unadvise() == VFW_E_NO_ADVISE_SET);

    // Before we start looping display the current state

    UCHAR ColourIndex = DEFAULT_INDEX;
    EXECUTE_ASSERT(SUCCEEDED(GetDefaultColourKey(pOverlay)));
    EXECUTE_ASSERT(SUCCEEDED(GetSystemPalette(pOverlay)));
    EXECUTE_ASSERT(SUCCEEDED(GetClippingList(pOverlay)));
    EXECUTE_ASSERT(SUCCEEDED(GetWindowHandle(pOverlay)));
    EXECUTE_ASSERT(SUCCEEDED(GetWindowPosition(pOverlay)));

    // Initialise the advise link with the renderer

    hr = pOverlay->Advise(pNotify,ADVISE_ALL);
    if (FAILED(hr)) {
        NOTE("Could not set up advise link");
        ExitThread(FALSE);
    }

    EXECUTE_ASSERT(pOverlay->Advise(pNotify,ADVISE_ALL) == VFW_E_ADVISE_ALREADY_SET);
    EXECUTE_ASSERT(pOverlay->Advise(pNotify,ADVISE_NONE) == VFW_E_ADVISE_ALREADY_SET);
    EXECUTE_ASSERT(pOverlay->Advise(NULL,ADVISE_ALL) == E_POINTER);

    // Check we can set a palette to some degree

    pOverlay->SetPalette(10,TestPalette);
    pOverlay->SetPalette(0,NULL);
    HANDLE hEvent = (HANDLE) lpvThreadParm;

    while (dwResult == WAIT_TIMEOUT) {
        dwResult = WaitForSingleObject(hEvent,(DWORD) 1000);
        SetColourKey(pOverlay,ColourIndex);
        GetCurrentColourKey(pOverlay);
        ColourIndex++;
    }

    // Unlink us from the notification stream

    hr = pOverlay->Unadvise();
    if (FAILED(hr)) {
        NOTE("Could not stop advise link");
        ExitThread(FALSE);
    }

    NOTE("Advise link terminated");
    ExitThread(FALSE);
    return FALSE;
}


// The normal single threaded overlay test uses the OverlayLoop function. This
// does a number of ASSERTs to check the state after setting and unsetting the
// advise links. When using a number of random threads all executing the same
// interface we cannot assume any synchronisation between them. Therefore we
// use this separate overlay function which is the same without the ASSERTs

DWORD ThreadOverlayLoop(LPVOID lpvThreadParm)
{
    DWORD dwResult = WAIT_TIMEOUT;
    NOTE("Multi thread overlay test");
    ASSERT(pOverlay);

    // Before we start looping display the current state

    UCHAR ColourIndex = DEFAULT_INDEX;
    EXECUTE_ASSERT(SUCCEEDED(GetDefaultColourKey(pOverlay)));
    EXECUTE_ASSERT(SUCCEEDED(GetSystemPalette(pOverlay)));
    EXECUTE_ASSERT(SUCCEEDED(GetClippingList(pOverlay)));
    EXECUTE_ASSERT(SUCCEEDED(GetWindowHandle(pOverlay)));
    EXECUTE_ASSERT(SUCCEEDED(GetWindowPosition(pOverlay)));

    // Initialise the advise link with the renderer

    HRESULT hr = pOverlay->Advise(pNotify,ADVISE_ALL);
    if (FAILED(hr)) {
        NOTE("Could not set up advise link");
    }

    // Check we can set a palette to some degree

    pOverlay->SetPalette(10,TestPalette);
    pOverlay->SetPalette(0,NULL);
    HANDLE hEvent = (HANDLE) lpvThreadParm;

    while (dwResult == WAIT_TIMEOUT) {
        dwResult = WaitForSingleObject(hEvent,(DWORD) 50);
        SetColourKey(pOverlay,ColourIndex);
        GetCurrentColourKey(pOverlay);
        ColourIndex++;
    }

    // Unlink us from the notification stream

    hr = pOverlay->Unadvise();
    if (FAILED(hr)) {
        NOTE("Could not stop advise link");
    }

    NOTE("Advise link terminated");
    ExitThread(FALSE);
    return FALSE;
}


// This is called by our worker thread to display the current default colour
// key that can be obtained through the IOverlay interface. The image test
// must have it's registry logging set to 5 to see the output this produces.
// We set the colour key required to be the default colour key and then get
// the default colour key again so that we can make sure it's still the same

HRESULT GetDefaultColourKey(IOverlay *pOverlay)
{
    ASSERT(pOverlay);
    COLORKEY ColourKey;
    COLORKEY MatchKey;

    NOTE("Getting default colour key from renderer");

    // Ask the overlay interface for it's colour key

    HRESULT hr = pOverlay->GetDefaultColorKey(&ColourKey);
    if (FAILED(hr)) {
        NOTE("No default key");
        return E_UNEXPECTED;
    }

    NOTE("Setting default colour key");
    COLORKEY OriginalKey = ColourKey;
    pOverlay->SetColorKey(&ColourKey);

    // Ask the overlay for it's colour key again

    hr = pOverlay->GetDefaultColorKey(&MatchKey);
    if (FAILED(hr)) {
        NOTE("No second key");
        return E_UNEXPECTED;
    }

    ASSERT(MatchKey.KeyType == OriginalKey.KeyType);
    ASSERT(MatchKey.PaletteIndex == OriginalKey.PaletteIndex);
    ASSERT(MatchKey.LowColorValue == OriginalKey.LowColorValue);
    ASSERT(MatchKey.HighColorValue == OriginalKey.HighColorValue);
    return DisplayColourKey(&ColourKey);
}


// This displays the current colour key used by the renderer, this is called
// both during colour key change callbacks and also by our worker thread when
// it starts the overlay test and retrieves the current default colour key

HRESULT GetCurrentColourKey(IOverlay *pOverlay)
{
    ASSERT(pOverlay);
    COLORKEY ColourKey;

    NOTE("Getting current colour key from renderer");

    // Ask the overlay interface for it's colour key

    HRESULT hr = pOverlay->GetColorKey(&ColourKey);
    if (FAILED(hr)) {
        NOTE("No current key");
        return E_UNEXPECTED;
    }
    return DisplayColourKey(&ColourKey);
}


// Display a COLORKEY structure, it has a type field that defines whether it
// is a palette index or a true colour value. The palette index is a single
// value offset into the current display palette, while a true colour value
// is actually a range of values that may appear in the window although in
// practice the renderer will select a single key to use and tell us that

HRESULT DisplayColourKey(const COLORKEY *pColourKey)
{
    // Does it have a colour key at all

    if (pColourKey->KeyType == CK_NOCOLORKEY) {
        NOTE("No colour key in use");
        return NOERROR;
    }

    // Does it offer a palette index

    if (pColourKey->KeyType & CK_INDEX) {
        NOTE1("Palette index %d",pColourKey->PaletteIndex);
    }

    // Does it offer a range of RGB true colour values

    if (pColourKey->KeyType & CK_RGB) {
        NOTE2("RGB range colour key (%d,%d)",
              pColourKey->LowColorValue,
              pColourKey->HighColorValue);
    }
    return NOERROR;
}


// This sets the colour key in the renderer's window to a palette value as is
// passed in by the caller and a true colour key which is completely random
// Because the true colour key is completely random we may select a colour
// that cannot be realised on non true colour devices (eg 16 bit RGB565)

HRESULT SetColourKey(IOverlay *pOverlay,DWORD Colour)
{
    ASSERT(pOverlay);
    COLORKEY ColourKey;

    // Set a standard palette index colour key

    NOTE1("Setting colour key %d",Colour);
    ColourKey.KeyType = CK_INDEX;
    ColourKey.PaletteIndex = Colour;
    ColourKey.KeyType |= CK_RGB;

    ColourKey.LowColorValue = RGB(((UCHAR) rand()),
                                  ((UCHAR) rand()),
                                  ((UCHAR) rand()));

    ColourKey.HighColorValue = RGB(UCHAR_MAX,UCHAR_MAX,UCHAR_MAX);

    HRESULT hr = pOverlay->SetColorKey(&ColourKey);
    if (FAILED(hr)) {
        NOTE("Failed to set key");
        return E_UNEXPECTED;
    }

    NOTE("Set key");
    return NOERROR;
}


// This retrieves the current clipping list for the video window, which is a
// RGBDATA structure (a RGNDATAHEADER followed by a variable length of clip
// rectangles). We log the bounding client rectangle and each of the clipping
// rectangles in turn, all of which should be within the bounding area. The
// memory returned by the interface should be deleted using CoTaskMemFree

HRESULT GetClippingList(IOverlay *pOverlay)
{
    RGNDATA *pRgnData;
    ASSERT(pOverlay);
    RECT SourceRect;
    RECT TargetRect;

    // Get the clipping information

    HRESULT hr = pOverlay->GetClipList(&SourceRect,&TargetRect,&pRgnData);
    if (FAILED(hr)) {
        NOTE("No clip information");
        return E_UNEXPECTED;
    }

    // Display the clipping information

    DisplayClippingInformation(&SourceRect,&TargetRect,pRgnData);
    CoTaskMemFree(pRgnData);
    return NOERROR;
}


// Log the window rectangles that define the exposed window area, the clip
// information is a RGNDATA structure with a header and a variable length
// list of rectangles. The header has the bounding rectangle for the video
// which may not be the same as the window client area because it supports
// a control interface called IVideoWindow that lets the destination be set

HRESULT DisplayClippingInformation(const RECT *pSourceRect,
                                   const RECT *pTargetRect,
                                   const RGNDATA *pRgnData)
{
    // Log the source rectangle

    NOTE4("Source rectangle (L %d,T %d,R %d,B %d)",
          pSourceRect->left,
          pSourceRect->top,
          pSourceRect->right,
          pSourceRect->bottom);

    // Log the destination rectangle

    NOTE4("Destination rectangle (L %d,T %d,R %d,B %d)",
          pTargetRect->left,
          pTargetRect->top,
          pTargetRect->right,
          pTargetRect->bottom);

    // Is this an ADVISE_POSITION callback

    if (pRgnData == NULL) {
        return NOERROR;
    }

    // Log how many rectangles make up the region

    RECT *pRectangles = (RECT *) pRgnData->Buffer;
    NOTE1("Number of rectangles %d",pRgnData->rdh.nCount);
    NOTE4("Bounding rectangle (L %d,T %d,R %d,B %d)",
          pRgnData->rdh.rcBound.left,
          pRgnData->rdh.rcBound.top,
          pRgnData->rdh.rcBound.right,
          pRgnData->rdh.rcBound.bottom);

    ASSERT(pRgnData->rdh.iType == RDH_RECTANGLES);
    ASSERT(pRgnData->rdh.dwSize == sizeof(RGNDATAHEADER));
    NOTE("Clipping rectangles...");

    for (DWORD dwCount = 0;dwCount < pRgnData->rdh.nCount;dwCount++) {
        NOTE5("(%d) L %d,T %d,R %d,B %d",dwCount + 1,
              pRectangles[dwCount].left,
              pRectangles[dwCount].top,
              pRectangles[dwCount].right,
              pRectangles[dwCount].bottom);
    }
    return NOERROR;
}


// Get the system palette from the renderer and display it's contents, if this
// is a true colour device then this will return an error as they do not have
// palettes. However note that a renderer running on a true colour display may
// still accept eight bit palette images through IMemInputPin as virtually all
// device controllers can display this format efficiently sometimes even more
// efficiently than the true colour types as there's less data being copied

HRESULT GetSystemPalette(IOverlay *pOverlay)
{
    PALETTEENTRY *pPalette;
    ASSERT(pOverlay);
    DWORD dwColours;

    // Get the current system palette

    HRESULT hr = pOverlay->GetPalette(&dwColours,&pPalette);
    if (FAILED(hr)) {
        NOTE("No palette");
        return S_FALSE;
    }

    DisplaySystemPalette(dwColours,pPalette);
    CoTaskMemFree(pPalette);
    return NOERROR;
}


// Display the contents of a system palette

HRESULT DisplaySystemPalette(DWORD dwColours,const PALETTEENTRY *pPalette)
{
    ASSERT(pPalette);
    ASSERT(dwColours);

    NOTE("Current system palette.. (RGB)");
    for (DWORD dwCount = 0;dwCount < dwColours;dwCount++) {
        NOTE4("%03d %03d %03d %03d",dwCount,
              pPalette[dwCount].peRed,
              pPalette[dwCount].peGreen,
              pPalette[dwCount].peBlue);
    }
    return NOERROR;
}


// Retrieve the current renderer window handle

HRESULT GetWindowHandle(IOverlay *pOverlay)
{
    ASSERT(pOverlay);
    HWND hwnd;

    // Get the video renderer window handle

    HRESULT hr = pOverlay->GetWindowHandle(&hwnd);
    if (FAILED(hr)) {
        NOTE("No window handle");
        return E_UNEXPECTED;
    }
    NOTE1("Current window handle %d",hwnd);
    return NOERROR;
}


// Retrieve the current renderer window position

HRESULT GetWindowPosition(IOverlay *pOverlay)
{
    ASSERT(pOverlay);
    RECT Source,Target;

    // Get the video renderer window handle

    HRESULT hr = pOverlay->GetVideoPosition(&Source,&Target);
    if (FAILED(hr)) {
        NOTE("No window position");
        return E_UNEXPECTED;
    }
    return DisplayClippingInformation(&Source,&Target,(LPRGNDATA) NULL);
}
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\multimedia\dshow\filters\image\vidtest\samptest.h ===
// Copyright (c) Microsoft Corporation 1994-1996. All Rights Reserved
// Implements basic sample testing, Anthony Phillips, July 1995

#ifndef __SAMPTEST__
#define __SAMPTEST__

DWORD SampleLoop(LPVOID lpvThreadParm);
void CheckSampleInterfaces(IMediaSample *pMediaSample);
HRESULT PushSample(REFERENCE_TIME *pStart,REFERENCE_TIME *pEnd);
HRESULT FillBuffer(BYTE *pBuffer);

#endif // __SAMPTEST__


=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\multimedia\dshow\filters\image\vidtest\speed.h ===
// Copyright (c) Microsoft Corporation 1994-1996. All Rights Reserved
// Video renderer performance tests, Anthony Phillips, January 1995

#ifndef __SPEED__
#define __SPEED__

execSpeedTest1();       // Measure performance on surfaces
execSpeedTest2();       // Measure colour space conversions
execSpeedTest3();       // Same as above but force unaligned

BOOL FindDisplayMode();
void MeasureDrawSpeed(UINT SurfaceType);
void InitInputImage(BYTE *pImage);
void ReportConversionTimes(INT Transform,INT Time);
INT TimeConversions(CConvertor *pObject,BYTE *pInput,BYTE *pOutput);
void InitVideoInfo(VIDEOINFO *pVideoInfo,const GUID *pSubType);
void InitSafetyBytes(VIDEOINFO *pVideoInfo,BYTE *pImage);
void CheckSafetyBytes(VIDEOINFO *pVideoInfo,BYTE *pImage);

BOOL ReportStatistics(DWORD StartTime,      // Start time for measurements
                      DWORD EndTime,        // Likewise the end time in ms
                      DWORD Surface,        // Type of surface we obtained
                      DWORD DDCount,        // Number of DirectDraw samples
                      LONG MinWidth,        // Minimum ideal image size
                      LONG MinHeight,       // Same but for minimum height
                      LONG MaxWidth,        // Maximum ideal image size
                      LONG MaxHeight);      // Same but for maximum height

#endif // __SPEED__


=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\multimedia\dshow\filters\image\vidtest\samptest.cpp ===
// Copyright (c) Microsoft Corporation 1994-1996. All Rights Reserved
// Implements basic sample testing, Anthony Phillips, July 1995

#include <streams.h>        // Includes all the IDL and base classes
#include <windows.h>        // Standard Windows SDK header file
#include <windowsx.h>       // Win32 Windows extensions and macros
#include <vidprop.h>        // Shared video properties library
#include <render.h>         // Normal video renderer header file
#include <modex.h>          // Specialised Modex video renderer
#include <convert.h>        // Defines colour space conversions
#include <colour.h>         // Rest of the colour space convertor
#include <imagetst.h>       // All our unit test header files
#include <stdio.h>          // Standard C runtime header file
#include <limits.h>         // Defines standard data type limits
#include <tchar.h>          // Unicode and ANSII portable types
#include <mmsystem.h>       // Multimedia used for timeGetTime
#include <stdlib.h>         // Standard C runtime function library
#include <tstshell.h>       // Definitions of constants eg TST_FAIL

// This executes a fairly simple sample test on the video renderer. This is
// called when we create a worker thread (ie this is the thread entry point)
// All we do is spin round asking for buffers and filling them with the image
// data we read in from the DIB earlier. If the deliver function returns an
// S_FALSE code it indicates that the user closed the window and therefore
// it will not accept any more sample images (until it's reconnected again)

DWORD SampleLoop(LPVOID lpvThreadParm)
{
    CRefTime IncrementTime((LONG) dwIncrement);  // Sample increment
    CRefTime StartTime, EndTime;                 // The sample times
    HRESULT hr = NOERROR;                        // OLE return code
    int iCount = FALSE;                          // Number of samples
    EndTime += IncrementTime;                    // Initialise end time

    // Keep going until someone stops us by setting the state event

    HANDLE hEvent = (HANDLE) lpvThreadParm;
    while (hr == NOERROR) {

        // See if we should stop

        DWORD dwResult = WaitForSingleObject(hEvent,(DWORD) 0);
        if (dwResult == WAIT_OBJECT_0) {
            break;
        }

        // Update the time stamps

        StartTime += IncrementTime;
        EndTime += IncrementTime;
        NOTE1("Increment %d",dwIncrement);

        // Pass the sample through the output pin to the renderer

        hr = PushSample((REFERENCE_TIME *) &StartTime,
                        (REFERENCE_TIME *) &EndTime);

        // Has the user closed the window
        if (hr == S_FALSE) NOTE("User closed window");

        // Just ignore errors until we are stopped
        if (FAILED(hr)) NOTE("Error pushing sample (state change?)");
    }
    ExitThread(FALSE);
    return FALSE;
}


// The video renderer allocator samples can support the DirectDraw interfaces
// if they are surface buffers. This checks that if either of the interfaces
// are available then they both are, so if we can get IDirectDrawSurface then
// we can also get IDirectDraw (and vica versa). It also checks that once we
// have got either of these interfaces then we can also get the IMediaSample

void CheckSampleInterfaces(IMediaSample *pMediaSample)
{
    IDirectDraw *pSampleDraw;               // Supports IDirectDraw
    IDirectDrawSurface *pSampleSurface;     // And likewise surface
    IMediaSample *pVideoSample;             // Back to this again

    // Does the sample have DirectDraw interfaces available

    HRESULT hr = pMediaSample->QueryInterface(IID_IDirectDraw,(PVOID *)&pSampleDraw);
    if (SUCCEEDED(hr)) {

        // Both IDirectDrawSurface and IMediaSample should be available

        hr = pMediaSample->QueryInterface(IID_IDirectDrawSurface,(PVOID *)&pSampleSurface);
        EXECUTE_ASSERT(SUCCEEDED(hr));
        hr = pSampleSurface->QueryInterface(IID_IMediaSample,(PVOID *)&pVideoSample);
        EXECUTE_ASSERT(SUCCEEDED(hr));
        hr = pSampleDraw->QueryInterface(IID_IMediaSample,(PVOID *)&pVideoSample);
        EXECUTE_ASSERT(SUCCEEDED(hr));

        // Make sure the surface is valid then release the interfaces

        EXECUTE_ASSERT(pSampleSurface->IsLost() == DD_OK);
        pVideoSample->Release();
        pVideoSample->Release();
        pSampleSurface->Release();
        pSampleDraw->Release();
    }

    // Make sure one is not available when the other is

    hr = pMediaSample->QueryInterface(IID_IDirectDrawSurface,(PVOID *)&pSampleSurface);
    if (SUCCEEDED(hr)) {

        // Both IDirectDraw and IMediaSample should be available

        hr = pMediaSample->QueryInterface(IID_IDirectDraw,(PVOID *)&pSampleDraw);
        EXECUTE_ASSERT(SUCCEEDED(hr));
        hr = pSampleSurface->QueryInterface(IID_IMediaSample,(PVOID *)&pVideoSample);
        EXECUTE_ASSERT(SUCCEEDED(hr));
        hr = pSampleDraw->QueryInterface(IID_IMediaSample,(PVOID *)&pVideoSample);
        EXECUTE_ASSERT(SUCCEEDED(hr));

        // Make sure the surface is valid then release the interfaces

        EXECUTE_ASSERT(pSampleSurface->IsLost() == DD_OK);
        pVideoSample->Release();
        pVideoSample->Release();
        pSampleSurface->Release();
        pSampleDraw->Release();
        IncrementDDCount();
    }
}


// This executes on the worker thread context to retrieve an image buffer from
// the video renderer, fill it and than send it to the input pin. With each
// buffer we get we copy the image data into it, if you want to test the video
// renderer performance then it might be wise to remove the data copy and
// just initialise the buffer once. The first sample we send has stream time
// zero and each sunsequent sample increases by the global time increment

HRESULT PushSample(REFERENCE_TIME *pStart,REFERENCE_TIME *pEnd)
{
    CBaseOutputPin *pImagePin;              // Output pin from source
    AM_MEDIA_TYPE *pMediaType =  NULL;         // Format change buffer
    PMEDIASAMPLE pMediaSample;              // Media sample for buffers
    HRESULT hr = NOERROR;                   // OLE Return code
    BYTE *pData;                            // Pointer to buffer

    // Get the output pin pointer from the shell object

    pImagePin = &pImageSource->m_ImagePin;
    ASSERT(pImagePin);

    // Fill in the next media sample's time stamps

    hr = pImagePin->GetDeliveryBuffer(&pMediaSample,pStart,pEnd,0);
    if (hr != NOERROR) {
        ASSERT(pMediaSample == NULL);
        return hr;
    }

    CheckSampleInterfaces(pMediaSample);

    // Handle dynamic format changes

    pMediaSample->GetMediaType(&pMediaType);
    if (pMediaType) {
        gmtOut = *pMediaType;
        DeleteMediaType(pMediaType);
    }

    // Set the sample properties back again

    ASSERT(pMediaSample);
    pMediaSample->SetMediaType(NULL);
    pMediaSample->SetTime(pStart,pEnd);

    // Copy the image data into the media sample buffer

    pMediaSample->GetPointer(&pData);
    FillBuffer(pData);
    pImagePin->Deliver(pMediaSample);

    // Display format changes after unlocking the display

    if (pMediaType) DisplayMediaType(&gmtOut);
    pMediaSample->Release();
    return NOERROR;
}


// If we have currently got a DCI/DirectDraw buffer than the current output
// media type will have a clipping rectangle in it, otherwise we just fill
// the whole linear buffer by copying the image into it. Filling an offset
// clipping rectangle requires calculating the start and end of each line

HRESULT FillBuffer(BYTE *pBuffer)
{
    VIDEOINFO *pVideoInfo = (VIDEOINFO *) gmtOut.Format();
    BITMAPINFOHEADER *pHeader = HEADER(pVideoInfo);

    // If a normal looking buffer then copy the whole image

    if (IsRectEmpty(&pVideoInfo->rcTarget) == TRUE) {
        CopyMemory(pBuffer,bImageData,VideoInfo.bmiHeader.biSizeImage);
        return NOERROR;
    }

    ASSERT(pHeader->biBitCount >= 8);
    ASSERT((pHeader->biBitCount % 8) == 0);
    ASSERT(IsRectEmpty(&pVideoInfo->rcSource) == FALSE);
    LONG BytesPerPixel = pHeader->biBitCount / 8;

    // Set the start positions for our image and the target buffer

    LONG OutOffset = pHeader->biWidth * BytesPerPixel * pVideoInfo->rcTarget.top;
    OutOffset += (pVideoInfo->rcTarget.left * BytesPerPixel);
    LONG InOffset = VideoInfo.bmiHeader.biWidth * BytesPerPixel * pVideoInfo->rcSource.top;
    InOffset += (pVideoInfo->rcSource.left * BytesPerPixel);

    // Calculate distance from one scan line to the next

    LONG OutStride = pHeader->biWidth * BytesPerPixel;
    LONG InStride = VideoInfo.bmiHeader.biWidth * BytesPerPixel;
    BYTE *pInput = bImageData + InOffset;
    BYTE *pOutput = pBuffer + OutOffset;

    // Copy a scan line at a time

    for (LONG Lines = 0;Lines < HEIGHT(&pVideoInfo->rcTarget);Lines++) {
        CopyMemory(pOutput,pInput,VideoInfo.bmiHeader.biWidth * BytesPerPixel);
        pOutput += OutStride;
        pInput += InStride;
    }
    return NOERROR;
}
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\multimedia\dshow\filters\image\vidtest\tests.cpp ===
// Copyright (c) Microsoft Corporation 1994-1996. All Rights Reserved
// Digital video renderer test, Anthony Phillips, January 1995

#include <streams.h>        // Includes all the IDL and base classes
#include <windows.h>        // Standard Windows SDK header file
#include <windowsx.h>       // Win32 Windows extensions and macros
#include <vidprop.h>        // Shared video properties library
#include <render.h>         // Normal video renderer header file
#include <modex.h>          // Specialised Modex video renderer
#include <convert.h>        // Defines colour space conversions
#include <colour.h>         // Rest of the colour space convertor
#include <imagetst.h>       // All our unit test header files
#include <stdio.h>          // Standard C runtime header file
#include <limits.h>         // Defines standard data type limits
#include <tchar.h>          // Unicode and ANSII portable types
#include <mmsystem.h>       // Multimedia used for timeGetTime
#include <stdlib.h>         // Standard C runtime function library
#include <tstshell.h>       // Definitions of constants eg TST_FAIL

// These execute the actual test cases, the test cases for the test shell to
// pick up are defined in string tables in the resource file. Each test case
// has a name, a group and an identifier (amongst other things). When the
// test shell comes to run one of our tests it calls execTest with the ID
// of the test from the resource file, we have a large switch statement that
// routes the thread from there to the code that it should be executing. As
// all the tests use the same variables to hold the interfaces on the objects
// we create there is a chance that once one test goes awry that all further
// ones will be affected. To remove this dependancy would involve a lot more
// complexity for relatively gain. Picking up the first one to fail and then
// solving that problem is probably the most worthwhile part of this anyway

//==========================================================================
//
//  void YieldAndSleep
//
//  Description:
//      Sleep using tstWinYield to allow other threads to log messages
//      in the main window.
//
//  Arguments:
//      DWORD  cMilliseconds:   sleep time in milliseconds
//
//==========================================================================

void YieldAndSleep(DWORD cMilliseconds)
{
    DWORD dwEndTime = GetTickCount() + cMilliseconds;
    DWORD dwCurrentTime = GetTickCount();

    while(WAIT_TIMEOUT != MsgWaitForMultipleObjects(
                            (DWORD) 0,
                            NULL,
                            FALSE,
                            dwEndTime - dwCurrentTime,
                            QS_ALLINPUT))
    {
        tstWinYield();
        if ((dwCurrentTime = GetTickCount()) >= dwEndTime) {
            return;
        }
    }
}


//==========================================================================
//
//  void YieldWithTimeout
//
//  Description:
//      Sleep using tstWinYield to allow other threads to log messages
//      in the main window. Terminate if a specified event is not signalled
//      within a timeout period.
//
//      The purpose is to allow tests which play through a video of unknown
//      length. The test can terminate after a selectable period of
//      inactivity (usually following the end of the video).
//
//  Arguments:
//      HEVENT  hEvent:          event to wait for
//      DWORD   cMilliseconds:   sleep time in milliseconds
//
//==========================================================================

void YieldWithTimeout(HEVENT hEvent,DWORD cMilliseconds)
{
    DWORD dwEndTime = GetTickCount() + cMilliseconds;
    DWORD dwCurrentTime = GetTickCount();
    DWORD dwEventID;

    while (WAIT_TIMEOUT != (dwEventID = MsgWaitForMultipleObjects(
                                            (DWORD) 1,
                                            (LPHANDLE) &hEvent,
                                            FALSE,
                                            dwEndTime - dwCurrentTime,
                                            QS_ALLINPUT)))
    {
        // Reset timeout if hEvent was signalled

        if (WAIT_OBJECT_0 == dwEventID) {
            dwEndTime = GetTickCount() + cMilliseconds;
        } else {
            tstWinYield();
        }

        // Check if we have now timed out

        if ((dwCurrentTime = GetTickCount()) >= dwEndTime) {
            return;
        }
    }
}


//==========================================================================
//
//  int execTest1
//
//  Description:
//      Very simple test to create, connect, disconnect and release the
//      video renderer on the same thread. Tests the basic connection
//      mechanism of the video renderer when supplied with media types
//      We also initialise the renderer with a clock during connection
//
//  Return (int): TST_PASS indicating success
//
//==========================================================================

int execTest1()
{
    HRESULT hr = NOERROR;

    Log(TERSE,TEXT("Entering test #1"));
    LogFlush();

    // Create the test objects

    hr = CreateStream();
    if (FAILED(hr)) {
        return TST_FAIL;
    }

    // Connect the objects together

    hr = ConnectStream();
    if (FAILED(hr)) {
        return TST_FAIL;
    }

    // Now disconnect the filters

    hr = DisconnectStream();
    if (FAILED(hr)) {
        return TST_FAIL;
    }

    // And release the interfaces we hold

    hr = ReleaseStream();
    if (FAILED(hr)) {
        return TST_FAIL;
    }

    Log(TERSE,TEXT("Exiting test #1"));
    LogFlush();
    return TST_PASS;
}


//==========================================================================
//
//  int execTest2
//
//  Description:
//      Connect renderer and our source filter, pause them for approximately
//      two seconds and then disconnect them. This tests a very simple state
//      change and the ability to exit correctly from a stopped state. This
//      test also initialises the renderer with a clock during connection
//
//  Return (int): TST_PASS indicating success
//
//==========================================================================

int execTest2()
{
    HRESULT hr = NOERROR;

    Log(TERSE,TEXT("Entering test #2"));
    LogFlush();

    // Create the test objects

    EXECUTE_ASSERT(SUCCEEDED(CreateStream()));
    EXECUTE_ASSERT(SUCCEEDED(ConnectStream()));

    tstBeginSection("Pause for 2 seconds");
    EXECUTE_ASSERT(SUCCEEDED(PauseSystem()));
    YieldAndSleep(2000);
    tstEndSection();
    EXECUTE_ASSERT(SUCCEEDED(StopSystem()));

    // Disconnect and release the objects

    EXECUTE_ASSERT(SUCCEEDED(DisconnectStream()));
    EXECUTE_ASSERT(SUCCEEDED(ReleaseStream()));

    Log(TERSE,TEXT("Exiting test #2"));
    LogFlush();
    return TST_PASS;
}


//==========================================================================
//
//  int execTest3
//
//  Description:
//      Another simple test to connect the video renderer and source filter
//      then playing the current image selection (without having a paused
//      state first) followed by disconnecting the filters as usual. This
//      test also initialises the renderer with a clock during connection
//
//  Return (int): TST_PASS indicating success
//
//==========================================================================

int execTest3()
{
    HRESULT hr = NOERROR;

    Log(TERSE,TEXT("Entering test #3"));
    LogFlush();

    // Create the test objects

    EXECUTE_ASSERT(SUCCEEDED(CreateStream()));
    EXECUTE_ASSERT(SUCCEEDED(ConnectStream()));

    tstBeginSection("Run for 15 seconds");
    EXECUTE_ASSERT(SUCCEEDED(StartSystem(TRUE)));
    YieldAndSleep(15000);
    tstEndSection();
    EXECUTE_ASSERT(SUCCEEDED(StopSystem()));

    // Disconnect and release the objects

    EXECUTE_ASSERT(SUCCEEDED(DisconnectStream()));
    EXECUTE_ASSERT(SUCCEEDED(ReleaseStream()));

    Log(TERSE,TEXT("Exiting test #3"));
    LogFlush();
    return TST_PASS;
}


//==========================================================================
//
//  int execTest4
//
//  Description:
//      This tries to create and connect the stream objects and then repeat
//      the connection which should always fail (see the base filter class
//      for confirmation of this) It should return error code E_INVALIDARG
//
//  Return (int): TST_PASS indicating success
//
//==========================================================================

int execTest4()
{
    HRESULT hr = NOERROR;
    INT Result = TST_PASS;

    Log(TERSE,TEXT("Entering test #4"));
    LogFlush();

    // Create the test objects

    EXECUTE_ASSERT(SUCCEEDED(CreateStream()));
    EXECUTE_ASSERT(SUCCEEDED(ConnectStream()));

    // Try and connect them again

    hr = ConnectStream();
    if (SUCCEEDED(hr)) {
        Log(TERSE,TEXT("Connected pins during a connection"));
        Result = TST_FAIL;
    }

    // Disconnect and release the objects

    EXECUTE_ASSERT(SUCCEEDED(DisconnectStream()));
    EXECUTE_ASSERT(SUCCEEDED(ReleaseStream()));

    Log(TERSE,TEXT("Exiting test #4"));
    LogFlush();
    return Result;
}


//==========================================================================
//
//  int execTest5
//
//  Description:
//      This extends the last test that tries to connect the pins twice to
//      do the same and then try to disconnected them twice. The second of
//      the disconnection attempts should not produce an error return. We
//      will clean up after ourselves unless a nasty error occurs when we
//      are creating, connecting, disconnecting or releasing the objects
//
//  Return (int): TST_PASS indicating success
//
//==========================================================================

int execTest5()
{
    HRESULT hr = NOERROR;
    INT Result = TST_PASS;

    Log(TERSE,TEXT("Entering test #5"));
    LogFlush();

    // Create the test objects

    EXECUTE_ASSERT(SUCCEEDED(CreateStream()));
    EXECUTE_ASSERT(SUCCEEDED(ConnectStream()));

    // Try and connect them again

    hr = ConnectStream();
    if (SUCCEEDED(hr)) {
        Log(TERSE,TEXT("Connected pins during a connection"));
        Result = TST_FAIL;
    }

    // Now try and disconnect the filters

    hr = DisconnectStream();
    if (FAILED(hr)) {
        return TST_FAIL;
    }

    // Disconnect and release the objects

    EXECUTE_ASSERT(SUCCEEDED(DisconnectStream()));
    EXECUTE_ASSERT(SUCCEEDED(ReleaseStream()));

    Log(TERSE,TEXT("Exiting test #5"));
    LogFlush();
    return Result;
}


//==========================================================================
//
//  int execTest6
//
//  Description:
//      Connect renderer and our source filter, pause them for approximately
//      two seconds and then try to disconnect them. The filter should make
//      sure that it is stopped before completing a disconnection, the error
//      code is going to change in the future but it's currently E_UNEXPECTED
//
//  Return (int): TST_PASS indicating success
//
//==========================================================================

int execTest6()
{
    HRESULT hr = NOERROR;
    INT Result = TST_PASS;

    Log(TERSE,TEXT("Entering test #6"));
    LogFlush();

    // Create the test objects

    EXECUTE_ASSERT(SUCCEEDED(CreateStream()));
    EXECUTE_ASSERT(SUCCEEDED(ConnectStream()));

    tstBeginSection("Pause for 2 seconds");
    EXECUTE_ASSERT(SUCCEEDED(PauseSystem()));
    YieldAndSleep(2000);
    tstEndSection();

    // Now try and disconnect the filters

    hr = DisconnectStream();
    if (SUCCEEDED(hr)) {
        Log(TERSE,TEXT("Succeeded in disconnection while paused"));
        Result = TST_FAIL;
    }

    EXECUTE_ASSERT(SUCCEEDED(StopSystem()));
    EXECUTE_ASSERT(SUCCEEDED(DisconnectStream()));
    EXECUTE_ASSERT(SUCCEEDED(ReleaseStream()));

    Log(TERSE,TEXT("Exiting test #6"));
    LogFlush();
    return Result;
}


//==========================================================================
//
//  int execTest7
//
//  Description:
//      Another simple test to connect the video renderer and source filter
//      then playing the current image selection (without having a paused
//      state first) followed by disconnecting the filters as usual. This
//      test also initialises the renderer with a clock during connection
//      We try to disconnect without having a stopped transation which is
//      an error that returns E_UNEXPECTED although this may be changing
//
//  Return (int): TST_PASS indicating success
//
//==========================================================================

int execTest7()
{
    HRESULT hr = NOERROR;
    INT Result = TST_PASS;

    Log(TERSE,TEXT("Entering test #7"));
    LogFlush();

    // Create the test objects

    EXECUTE_ASSERT(SUCCEEDED(CreateStream()));
    EXECUTE_ASSERT(SUCCEEDED(ConnectStream()));

    tstBeginSection("Run for 15 seconds");
    EXECUTE_ASSERT(SUCCEEDED(StartSystem(TRUE)));
    YieldAndSleep(15000);
    tstEndSection();

    // Now try and disconnect the filters

    hr = DisconnectStream();
    if (SUCCEEDED(hr)) {
        Log(TERSE,TEXT("Succeeded in disconnection while running"));
        Result = TST_FAIL;
    }

    EXECUTE_ASSERT(SUCCEEDED(StopSystem()));
    EXECUTE_ASSERT(SUCCEEDED(DisconnectStream()));
    EXECUTE_ASSERT(SUCCEEDED(ReleaseStream()));

    Log(TERSE,TEXT("Exiting test #7"));
    LogFlush();
    return Result;
}


//==========================================================================
//
//  int execTest8
//
//  Description:
//      This is almost a stress style test that simple executes a number
//      of state changes one after another on the same thread. Because of
//      streams architecture there are a number of places that threads
//      can be stalled waiting for certain events so the state changes
//      should make sure that they are released back to the filters
//
//  Return (int): TST_PASS indicating success
//
//==========================================================================

int execTest8()
{
    HRESULT hr = NOERROR;
    INT Result = TST_PASS;

    Log(TERSE,TEXT("Entering test #8"));
    LogFlush();

    // Create the test objects

    EXECUTE_ASSERT(SUCCEEDED(CreateStream()));
    EXECUTE_ASSERT(SUCCEEDED(ConnectStream()));

    // With the streams architecture there is some complexity in dealing with
    // state changes correctly so that threads are released while they are
    // waiting for buffers from various allocators. This runs a small number
    // of state change permutations where simply returning is fair comment

    tstBeginSection("Multiple state changes");

    Log(VERBOSE,TEXT("Starting system for 500ms (with clock)"));
    EXECUTE_ASSERT(SUCCEEDED(StartSystem(TRUE)));
    YieldAndSleep(500);

    Log(VERBOSE,TEXT("Stopping system"));
    EXECUTE_ASSERT(SUCCEEDED(StopSystem()));

    Log(VERBOSE,TEXT("Pausing system"));
    EXECUTE_ASSERT(SUCCEEDED(PauseSystem()));
    EXECUTE_ASSERT(SUCCEEDED(PauseSystem()));

    Log(VERBOSE,TEXT("Stopping system"));
    EXECUTE_ASSERT(SUCCEEDED(StopSystem()));

    Log(VERBOSE,TEXT("Starting system for 500ms (with clock)"));
    EXECUTE_ASSERT(SUCCEEDED(StartSystem(TRUE)));
    YieldAndSleep(500);

    Log(VERBOSE,TEXT("Pausing system for 500ms"));
    EXECUTE_ASSERT(SUCCEEDED(PauseSystem()));
    YieldAndSleep(500);

    Log(VERBOSE,TEXT("Stopping system for 1000ms"));
    EXECUTE_ASSERT(SUCCEEDED(StopSystem()));
    EXECUTE_ASSERT(SUCCEEDED(StopSystem()));
    YieldAndSleep(1000);
    EXECUTE_ASSERT(SUCCEEDED(StopSystem()));

    Log(VERBOSE,TEXT("Starting system for 1000ms (NO clock)"));
    EXECUTE_ASSERT(SUCCEEDED(StartSystem(TRUE)));
    YieldAndSleep(1000);
    EXECUTE_ASSERT(SUCCEEDED(StartSystem(TRUE)));

    Log(VERBOSE,TEXT("Pausing system for 15000ms"));
    EXECUTE_ASSERT(SUCCEEDED(PauseSystem()));
    EXECUTE_ASSERT(SUCCEEDED(PauseSystem()));

    YieldAndSleep(15000);
    tstEndSection();

    EXECUTE_ASSERT(SUCCEEDED(StopSystem()));
    EXECUTE_ASSERT(SUCCEEDED(DisconnectStream()));
    EXECUTE_ASSERT(SUCCEEDED(ReleaseStream()));

    Log(TERSE,TEXT("Exiting test #8"));
    LogFlush();
    return Result;
}


//==========================================================================
//
//  int execTest9
//
//  Description:
//      Another simple test to connect the video renderer and source filter
//      then playing the current image selection (without having a paused
//      state first) followed by disconnecting the filters as usual. This
//      test also initialises the renderer WITHOUT a system clock to use
//
//  Return (int): TST_PASS indicating success
//
//==========================================================================

int execTest9()
{
    HRESULT hr = NOERROR;

    Log(TERSE,TEXT("Entering test #9"));
    LogFlush();

    // Create the test objects

    EXECUTE_ASSERT(SUCCEEDED(CreateStream()));
    EXECUTE_ASSERT(SUCCEEDED(ConnectStream()));

    tstBeginSection("Run for 60 seconds");
    EXECUTE_ASSERT(SUCCEEDED(StartSystem(TRUE)));
    YieldAndSleep(60000);
    tstEndSection();

    EXECUTE_ASSERT(SUCCEEDED(StopSystem()));
    EXECUTE_ASSERT(SUCCEEDED(DisconnectStream()));
    EXECUTE_ASSERT(SUCCEEDED(ReleaseStream()));

    Log(TERSE,TEXT("Exiting test #9"));
    LogFlush();
    return TST_PASS;
}


//==========================================================================
//
//  int execTest10
//
//  Description:
//      This is basicly a stress test for the video renderer. We do pretty
//      much as the basic connect and run test does except once we have the
//      system running we then spin off THREADS number of threads to also
//      compete with sending it samples. Because they are all executing
//      asynchronously the video renderer will receive media samples with
//      time stamps constantly going forwards and backwards, for this reason
//      we also give the video renderer a clock to see if it can handle all
//      the synchronisation required to achieve this. We run flat out for
//      approximately 60 seconds at which point we terminate the workers
//      and stop the system, after which we can disconnect the filters
//
//  Return (int): TST_PASS indicating success
//
//==========================================================================

#define WAIT_FOR_STARTUP_THREAD 2000

int execTest10()
{
    HRESULT hr = NOERROR;
    HANDLE hThreads[THREADS];
    DWORD dwThreadID;

    Log(TERSE,TEXT("Entering test #10"));
    LogFlush();

    // Create the test objects

    EXECUTE_ASSERT(SUCCEEDED(CreateStream()));
    EXECUTE_ASSERT(SUCCEEDED(ConnectStream()));
    EXECUTE_ASSERT(SUCCEEDED(StartSystem(TRUE)));
    Sleep(WAIT_FOR_STARTUP_THREAD);

    // Create a manual reset event for signalling

    HANDLE hExit = CreateEvent(NULL,TRUE,FALSE,NULL);
    if (hExit == NULL) {
        Log(TERSE,TEXT("Error creating event"));
        return TST_FAIL;
    }

    // Use a special multithread entry point for overlay tests

    LPTHREAD_START_ROUTINE lpProc =
    	(uiCurrentConnectionItem == IDM_SAMPLES ?
        	SampleLoop : ThreadOverlayLoop);

    // Create the worker threads to push samples to the renderer

    for (INT iThread = 0;iThread < THREADS;iThread++) {

        hThreads[iThread] = CreateThread(
                               NULL,              // Security attributes
                               (DWORD) 0,         // Initial stack size
                               lpProc,            // Thread start address
                               (LPVOID) hExit,    // Thread parameter
                               (DWORD) 0,         // Creation flags
                               &dwThreadID);      // Thread identifier

        ASSERT(hThreads[iThread]);
    }

    // Run the system stable for 60 seconds

    YieldAndSleep(60000);
    SetEvent(hExit);

    // Wait for all the threads to exit

    DWORD Result = WAIT_TIMEOUT;
    DWORD ExitCount = WAIT_RETRIES;

    while (Result == WAIT_TIMEOUT) {

        YieldAndSleep(TIMEOUT);
        Result = WaitForMultipleObjects(THREADS,hThreads,TRUE,TIMEOUT);
        ASSERT(Result != WAIT_FAILED);

        // On Windows 95 the WaitForMultipleObjects continually times out
        // for no apparent reason (even though all the threads exited ok)
        // so we play safe and time out of this loop after some retries

        if (--ExitCount == 0) {
            break;
        }
    }

    // Close the thread handle resources

    for (iThread = 0;iThread < THREADS;iThread++) {
        EXECUTE_ASSERT(CloseHandle(hThreads[iThread]));
    }

    EXECUTE_ASSERT(SUCCEEDED(StopSystem()));
    EXECUTE_ASSERT(CloseHandle(hExit));
    EXECUTE_ASSERT(SUCCEEDED(DisconnectStream()));
    EXECUTE_ASSERT(SUCCEEDED(ReleaseStream()));

    Log(TERSE,TEXT("Exiting test #10"));
    LogFlush();
    return TST_PASS;
}
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\multimedia\dshow\filters\image\vidtest\speed.cpp ===
// Copyright (c) Microsoft Corporation 1994-1996. All Rights Reserved
// Video renderer performance tests, Anthony Phillips, January 1995

#include <streams.h>        // Includes all the IDL and base classes
#include <windows.h>        // Standard Windows SDK header file
#include <windowsx.h>       // Win32 Windows extensions and macros
#include <vidprop.h>        // Shared video properties library
#include <render.h>         // Normal video renderer header file
#include <modex.h>          // Specialised Modex video renderer
#include <convert.h>        // Defines colour space conversions
#include <colour.h>         // Rest of the colour space convertor
#include <imagetst.h>       // All our unit test header files
#include <stdio.h>          // Standard C runtime header file
#include <limits.h>         // Defines standard data type limits
#include <tchar.h>          // Unicode and ANSII portable types
#include <mmsystem.h>       // Multimedia used for timeGetTime
#include <stdlib.h>         // Standard C runtime function library
#include <tstshell.h>       // Definitions of constants eg TST_FAIL

const DWORD SafetyBytes[] = {0xF0ACBD23,0x478FACB1,0xFFFFFFFF,0x00000000};

//==========================================================================
//
//  int execSpeedTest1
//
//  Description:
//
//      This runs a set of performance tests against different RGB surfaces
//      available from the video renderer. The surfaces we try are primary
//      surfaces (both DCI and DirectDraw), offscreen, overlay and flipping
//      We don't offer any YUV formats so we can't really test those, we'll
//      have to leave those for full system testing to measure performance.
//      If the hardware is behaving properly there should be little relative
//      different between how the different RGB surfaces perform to how the
//      YUV surfaces do (but of course who expects any hardware to behave!)
//
//  Return (int): TST_PASS indicating success
//
//==========================================================================

int execSpeedTest1()
{
    // Store all our settings before starting

    UINT uiStoreDisplayMode = uiCurrentDisplayMode;
    UINT uiStoreImageItem = uiCurrentImageItem;
    UINT uiStoreSurfaceItem = uiCurrentSurfaceItem;
    HRESULT hr = NOERROR;

    Log(TERSE,TEXT("Entering performance test #1"));
    timeBeginPeriod(1);
    LogFlush();

    // Try to swap display modes

    if (FindDisplayMode() == FALSE) {
        LoadDIB(uiStoreImageItem,&VideoInfo,bImageData);
        SetImageMenuCheck(uiStoreImageItem);
    }

    // Try different RGB surfaces

    MeasureDrawSpeed(IDM_NONE);
    MeasureDrawSpeed(IDM_DCIPS);
    MeasureDrawSpeed(IDM_PS);
    MeasureDrawSpeed(IDM_RGBOFF);
    MeasureDrawSpeed(IDM_RGBOVR);
    MeasureDrawSpeed(IDM_RGBFLP);

    // Reset our state afterwards

    SetDisplayMode(uiStoreDisplayMode);
    LoadDIB(uiStoreImageItem,&VideoInfo,bImageData);
    SetImageMenuCheck(uiStoreImageItem);
    SetSurfaceMenuCheck(uiStoreSurfaceItem);

    Log(TERSE,TEXT("Exiting performance test #1"));
    timeEndPeriod(1);
    LogFlush();
    return TST_PASS;
}


//==========================================================================
//
//  BOOL FindDisplayMode
//
//  Description:
//
//      This function sets the display mode to 640x480x16 bit depth if it
//      is available on this display card. It then sees if either of the
//      two 16bit DIB images we have available can be used to connect the
//      video renderer to our source filter. We choose a true colour mode
//      for the performance tests because the video renderer does not use
//      offscreen nor overlay surfaces for palettised images. Before this
//      function is called the current display mode and the current image
//      selected should be stored away as we update both of these fields.
//
//  Return (BOOL): TRUE if we successfully changed modes
//
//==========================================================================

BOOL FindDisplayMode()
{
    TCHAR MenuString[128];

    // Do we have a DirectDraw driver

    if (pDirectDraw == NULL) {
        Log(TERSE,TEXT("No 640x480x16 display mode"));
        return FALSE;
    }

    // The video renderer works out the display format when it is created, so
    // we must change display modes and then create the stream objects. It'll
    // then see the sixteen bit display and accept true colour formats. After
    // making a valid connection we can release the objects and return but we
    // leave the display set in the current mode for the performance tests

    for (DWORD dwMode = 1;dwMode <= dwDisplayModes;dwMode++) {

        // Get the required display mode settings

        DWORD Width,Height,BitDepth;
        GetMenuString(hModesMenu,IDM_MODE+dwMode,MenuString,128,MF_BYCOMMAND);
        sscanf(MenuString,TEXT("%dx%dx%d"),&Width,&Height,&BitDepth);

        // Is this setting a standard 640x480x16 display mode

        if (Width == 640 && Height == 480 && BitDepth == 16) {

            // Change the display mode and create a stream

            SetDisplayMode(dwMode + IDM_MODE);
            LoadDIB(IDM_WIND565,&VideoInfo,bImageData);
            SetImageMenuCheck(IDM_WIND565);
            EXECUTE_ASSERT(SUCCEEDED(CreateStream()));

            // Try and connect using a 565 format DIB

            if (SUCCEEDED(ConnectStream())) {
                EXECUTE_ASSERT(SUCCEEDED(DisconnectStream()));
                EXECUTE_ASSERT(SUCCEEDED(ReleaseStream()));
                Log(TERSE,TEXT("Using 640x480x16 display mode"));
                return TRUE;
            }

            // Try and connect using a 555 format DIB

            LoadDIB(IDM_WIND555,&VideoInfo,bImageData);
            SetImageMenuCheck(IDM_WIND555);
            if (SUCCEEDED(ConnectStream())) {
                EXECUTE_ASSERT(SUCCEEDED(DisconnectStream()));
                EXECUTE_ASSERT(SUCCEEDED(ReleaseStream()));
                Log(TERSE,TEXT("Using 640x480x16 display mode"));
                return TRUE;
            }
            EXECUTE_ASSERT(SUCCEEDED(ReleaseStream()));
        }
    }
    Log(TERSE,TEXT("No 640x480x16 display mode"));
    return FALSE;
}


//==========================================================================
//
//  void MeasureDrawSpeed
//
//  Description:
//
//      Actually does the dirty work of starting and stopping the tests.
//      We are passed in the type of surface that the caller would like
//      us to use, we don't guarantee that this will be used because it
//      is entirely up to the renderer to select one appropriate from
//      those available. Note we must report the statistics before the
//      system is disconnected and released because the reporting code
//      needs a valid interface on the renderer to still be around so
//      it has something to query for the IQualProp interface through.
//
//==========================================================================

void MeasureDrawSpeed(UINT SurfaceType)
{
    DWORD Surface = AMDDS_NONE,StartTime,EndTime;
    LONG MinWidth,MinHeight,MaxWidth,MaxHeight;

    // Set the surface type and create the objects

    SetSurfaceMenuCheck(SurfaceType);
    EXECUTE_ASSERT(SUCCEEDED(CreateStream()));
    EXECUTE_ASSERT(SUCCEEDED(ConnectStream()));
    EXECUTE_ASSERT(FAILED(pVideoWindow->GetMaxIdealImageSize(&MaxWidth,&MaxHeight)));
    EXECUTE_ASSERT(FAILED(pVideoWindow->GetMinIdealImageSize(&MinWidth,&MinHeight)));

    // Find the ideal minimum and maximum video sizes

    EXECUTE_ASSERT(SUCCEEDED(PauseSystem()));
    EXECUTE_ASSERT(SUCCEEDED(pVideoWindow->GetMaxIdealImageSize(&MaxWidth,&MaxHeight)));
    EXECUTE_ASSERT(SUCCEEDED(pVideoWindow->GetMinIdealImageSize(&MinWidth,&MinHeight)));

    // Run without a clock for 120 seconds

    StartTime = timeGetTime();
    EXECUTE_ASSERT(SUCCEEDED(pDirectVideo->GetSurfaceType(&Surface)));
    EXECUTE_ASSERT(SUCCEEDED(StartSystem(FALSE)));
    YieldAndSleep(120000);

    // Stop and release the resources

    DWORD DDCount = GetDDCount();
    EXECUTE_ASSERT(SUCCEEDED(StopSystem()));
    EndTime = timeGetTime();

    ReportStatistics(StartTime,     // Start time for measurements
                     EndTime,       // Likewise the end time in ms
                     Surface,       // Type of surface we obtained
                     DDCount,       // Number of DirectDraw samples
                     MinWidth,      // Minimum ideal image size
                     MinHeight,     // Same but for minimum height
                     MaxWidth,      // Maximum ideal image size
                     MaxHeight);    // Same but for maximum height

    EXECUTE_ASSERT(SUCCEEDED(DisconnectStream()));
    EXECUTE_ASSERT(SUCCEEDED(ReleaseStream()));
}


//==========================================================================
//
//  void ReportStatistics
//
//  Description:
//
//      Collates the statistics from a performance measurement run. We are
//      passed in the type of surface that was used (which may be different
//      to that requested), We are also passed in the start and end times
//      for the run so to calculate the average frame rate. We display a
//      string name for the surface type and then get the statistics that
//      the video renderer keeps and makes available through its IQualProp.
//
//==========================================================================

BOOL ReportStatistics(DWORD StartTime,      // Start time for measurements
                      DWORD EndTime,        // Likewise the end time in ms
                      DWORD Surface,        // Type of surface we obtained
                      DWORD DDCount,        // Number of DirectDraw samples
                      LONG MinWidth,        // Minimum ideal image size
                      LONG MinHeight,       // Same but for minimum height
                      LONG MaxWidth,        // Maximum ideal image size
                      LONG MaxHeight)       // Same but for maximum height
{
    ASSERT(pRenderFilter);
    IQualProp *pQualProp;
    TCHAR LogString[128];
    INT iDropped,iDrawn;

    // Calculate the real elapsed time in seconds

    DWORD Elapsed = max(1,((EndTime - StartTime) / 1000));
    wsprintf(LogString,TEXT("\r\nElapsed time %d secs"),Elapsed);
    Log(TERSE,LogString);

    // Initialise the description of the surface

    TCHAR *pSurfaceName = TEXT("No Surface");
    switch (Surface) {
        case AMDDS_DCIPS :  pSurfaceName = TEXT("DCI Primary");        break;
        case AMDDS_PS :     pSurfaceName = TEXT("DirectDraw Primary"); break;
        case AMDDS_RGBOVR : pSurfaceName = TEXT("RGB Overlay");        break;
        case AMDDS_YUVOVR : pSurfaceName = TEXT("YUV Overlay");        break;
        case AMDDS_RGBOFF : pSurfaceName = TEXT("RGB OffScreen");      break;
        case AMDDS_YUVOFF : pSurfaceName = TEXT("YUV OffScreen");      break;
        case AMDDS_RGBFLP : pSurfaceName = TEXT("RGB Flipping");       break;
    }

    // Get an IQualProp interface from the renderer

    HRESULT hr = pRenderFilter->QueryInterface(IID_IQualProp,(void **)&pQualProp);
    if (FAILED(hr)) {
        Log(TERSE,TEXT("No IQualProp interface"));
        return FALSE;
    }

    // Get the performance statistics from it

    pQualProp->get_FramesDroppedInRenderer(&iDropped);
    pQualProp->get_FramesDrawn(&iDrawn);
    INT iAverage = iDrawn / Elapsed;

    // Print the statistics to the log

    wsprintf(LogString,TEXT("Surface type %s"),pSurfaceName);
    Log(TERSE,LogString);
    wsprintf(LogString,TEXT("Minimum ideal image %dx%d"),MinWidth,MinHeight);
    Log(TERSE,LogString);
    wsprintf(LogString,TEXT("Maximum ideal image %dx%d"),MaxWidth,MaxHeight);
    Log(TERSE,LogString);
    wsprintf(LogString,TEXT("Frames dropped %d"),iDropped);
    Log(TERSE,LogString);
    wsprintf(LogString,TEXT("Total frames drawn %d"),iDrawn);
    Log(TERSE,LogString);
    wsprintf(LogString,TEXT("Average frame rate %d fps"),iAverage);
    Log(TERSE,LogString);
    wsprintf(LogString,TEXT("DirectDraw enabled samples %d"),DDCount);
    Log(TERSE,LogString);

    pQualProp->Release();
    return TRUE;
}


//==========================================================================
//
//  int execSpeedTest2
//
//  Description:
//
//      We need some performance figures for the colour space convertor so
//      it can be competitive against DrawDib. This tests the time taken
//      for each and every colour space conversion the filter provides.
//      We time conversions on 320x240 input images. Because we are a unit
//      test we can get in and link to the library and therefore get access
//      to the internal conversion objects so we don't have to fiddle with
//      creating a real filter and connecting it up like a filter graph.
//
//  Return (int): TST_PASS indicating success
//
//==========================================================================

int execSpeedTest2()
{
    BYTE InputImage[MAXIMAGESIZE + sizeof(SafetyBytes)];
    BYTE OutputImage[MAXIMAGESIZE + sizeof(SafetyBytes)];
    VIDEOINFO InputInfo;
    VIDEOINFO OutputInfo;
    InitInputImage(InputImage);

    Log(TERSE,TEXT("Entering performance test #2"));
    timeBeginPeriod(1);
    InitDitherMap();
    LogFlush();

    // Scan the list of available colour transforms

    for (INT Count = 0;Count < TRANSFORMS;Count++) {

        // Initialise the input and output GUIDs

        InitVideoInfo(&InputInfo,TypeMap[Count].pInputType);
        InitVideoInfo(&OutputInfo,TypeMap[Count].pOutputType);
        InitSafetyBytes(&InputInfo,InputImage);
        InitSafetyBytes(&OutputInfo,OutputImage);

        // Create the colour space converion object

        PCONVERTOR pConvertor = TypeMap[Count].pConvertor;
        CConvertor *pObject = pConvertor(&InputInfo,&OutputInfo);
        if (pObject == NULL) {
            Log(TERSE,TEXT("NULL returned from CreateInstance"));
            continue;
        }

        // Commit the tables and run the timing measurements

        EXECUTE_ASSERT(SUCCEEDED(pObject->Commit()));
        pObject->ForceAlignment(TRUE);
        INT Time = TimeConversions(pObject,InputImage,OutputImage);
        EXECUTE_ASSERT(SUCCEEDED(pObject->Decommit()));
        ReportConversionTimes(Count,Time);
        CheckSafetyBytes(&InputInfo,InputImage);
        CheckSafetyBytes(&OutputInfo,OutputImage);
        delete pObject;
    }

    Log(TERSE,TEXT("Exiting performance test #2"));
    timeEndPeriod(1);
    LogFlush();
    return TST_PASS;
}


//==========================================================================
//
//  void InitInputImage
//
//  Description:
//
//      Fills an image buffer with random numbers. We do this so that when
//      calculating colour space conversion times they are not skewed by
//      always using the same values and therefore the same place in any
//      lookup tables used. In fact the figures we get will probably be a
//      little worse than typical. The input must be MAXIMAGESIZE bytes.
//      NOTE The C runtime library function returns short ints upto 0x7FFF
//
//==========================================================================

void InitInputImage(BYTE *pImage)
{
    SHORT *pShort = (SHORT *) pImage;
    for (INT Loop = 0;Loop < (MAXIMAGESIZE / 2);Loop++) {
        *pShort++ = rand();
    }
}


//==========================================================================
//
//  void InitVideoInfo
//
//  Description:
//
//      When we create the colour space conversion objects we have to reset
//      them with the source and destination VIDEOINFO structures. They use
//      these to calculate strides and offsets. This function sets up these
//      structures ready to be passed into the convertors. We hard code the
//      image size to be 320x240, the bit count and total image size can be
//      calculated from the sub type GUID passed in as an input parameter.
//
//==========================================================================

void InitVideoInfo(VIDEOINFO *pVideoInfo,const GUID *pSubType)
{
    ASSERT(pVideoInfo);
    ASSERT(pSubType);

    // Start with the BITMAPINFOHEADER fields

    LPBITMAPINFOHEADER lpbi = HEADER(pVideoInfo);
    lpbi->biSize            = sizeof(BITMAPINFOHEADER);
    lpbi->biWidth           = 320;
    lpbi->biHeight          = 240;
    lpbi->biPlanes          = 1;
    lpbi->biBitCount        = GetBitCount(pSubType);
    lpbi->biXPelsPerMeter   = 0;
    lpbi->biYPelsPerMeter   = 0;
    lpbi->biCompression     = BI_RGB;
    lpbi->biSizeImage       = GetBitmapSize(lpbi);

    // Exceptions to the rule are the sixteen bit formats

    if (*pSubType == MEDIASUBTYPE_RGB555) {
        lpbi->biCompression   = BI_BITFIELDS;
        pVideoInfo->dwBitMasks[0] = bits555[0];
        pVideoInfo->dwBitMasks[1] = bits555[1];
        pVideoInfo->dwBitMasks[2] = bits555[2];
    }

    // Set the bit fields for RGB565 formats

    if (*pSubType == MEDIASUBTYPE_RGB565) {
        lpbi->biCompression   = BI_BITFIELDS;
        pVideoInfo->dwBitMasks[0] = bits565[0];
        pVideoInfo->dwBitMasks[1] = bits565[1];
        pVideoInfo->dwBitMasks[2] = bits565[2];
    }

    // Fill in a completely random palette

    if (*pSubType == MEDIASUBTYPE_RGB8) {
        for (int i = 0;i < 256;i++) {
            pVideoInfo->bmiColors[i].rgbRed = (BYTE) (i + 33);
            pVideoInfo->bmiColors[i].rgbGreen = (BYTE) (i + 66);
            pVideoInfo->bmiColors[i].rgbBlue = (BYTE) (i + 99);
            pVideoInfo->bmiColors[i].rgbReserved = 0;
        }
    }

    // Set the source and destination rectangles

    pVideoInfo->rcSource.left   = 0;
    pVideoInfo->rcSource.top    = 0;
    pVideoInfo->rcSource.right  = lpbi->biWidth;
    pVideoInfo->rcSource.bottom = lpbi->biHeight;
    pVideoInfo->rcTarget        = pVideoInfo->rcSource;

    // Other odds and ends in the VIDEOINFO structure

    pVideoInfo->dwBitRate       = BITRATE;
    pVideoInfo->dwBitErrorRate  = BITERRORRATE;
    pVideoInfo->AvgTimePerFrame = (LONGLONG) AVGTIME;
}


//==========================================================================
//
//  INT TimeConversions
//
//  Description:
//
//      Time colour space transformations for this convertor
//      We return the average time per frame in milliseconds
//
//==========================================================================

INT TimeConversions(CConvertor *pObject,BYTE *pInput,BYTE *pOutput)
{
    DWORD StartTime = timeGetTime();
    for (INT Loop = 0;Loop < ITERATIONS;Loop++) {
        EXECUTE_ASSERT(SUCCEEDED(pObject->Transform(pInput,pOutput)));
    }
    DWORD EndTime = timeGetTime();
    return ((EndTime - StartTime) / ITERATIONS);
}


//==========================================================================
//
//  void ReportConversionTimes
//
//  Description:
//
//      Display the input GUID, the output GUID and average time per frame
//
//==========================================================================

void ReportConversionTimes(INT Transform,INT Time)
{
    TCHAR Format[GUID_STRING];
    wsprintf(Format,TEXT("Input %20s  Output %20s  Average %5d ms"),
             GuidNames[*TypeMap[Transform].pInputType],
             GuidNames[*TypeMap[Transform].pOutputType],Time);
    Log(TERSE,Format);
}


//==========================================================================
//
//  int execSpeedTest3
//
//  Description:
//
//      We need some performance figures for the colour space convertor so
//      it can be competitive against DrawDib. This tests the time taken
//      for each and every colour space conversion the filter provides.
//      We time conversions on 320x240 input images. Because we are a unit
//      test we can get in and link to the library and therefore get access
//      to the internal conversion objects so we don't have to fiddle with
//      creating a real filter and connecting it up like a filter graph.
//      This is the same as execSpeedTest2 except we force the transforms
//      to be such that they are not done with any alignment optimisation
//
//  Return (int): TST_PASS indicating success
//
//==========================================================================

int execSpeedTest3()
{
    BYTE InputImage[MAXIMAGESIZE + sizeof(SafetyBytes)];
    BYTE OutputImage[MAXIMAGESIZE + sizeof(SafetyBytes)];
    VIDEOINFO InputInfo;
    VIDEOINFO OutputInfo;
    InitInputImage(InputImage);

    Log(TERSE,TEXT("Entering performance test #3"));
    timeBeginPeriod(1);
    InitDitherMap();
    LogFlush();

    // Scan the list of available colour transforms

    for (INT Count = 0;Count < TRANSFORMS;Count++) {

        // Initialise the input and output GUIDs and safety buffer

        InitVideoInfo(&InputInfo,TypeMap[Count].pInputType);
        InitVideoInfo(&OutputInfo,TypeMap[Count].pOutputType);
        InitSafetyBytes(&InputInfo,InputImage);
        InitSafetyBytes(&OutputInfo,OutputImage);

        // Create the colour space converion object

        PCONVERTOR pConvertor = TypeMap[Count].pConvertor;
        CConvertor *pObject = pConvertor(&InputInfo,&OutputInfo);
        if (pObject == NULL) {
            Log(TERSE,TEXT("NULL returned from CreateInstance"));
            continue;
        }

        // Commit the tables and run the timing measurements

        EXECUTE_ASSERT(SUCCEEDED(pObject->Commit()));
        pObject->ForceAlignment(FALSE);
        INT Time = TimeConversions(pObject,InputImage,OutputImage);
        EXECUTE_ASSERT(SUCCEEDED(pObject->Decommit()));
        ReportConversionTimes(Count,Time);
        CheckSafetyBytes(&InputInfo,InputImage);
        CheckSafetyBytes(&OutputInfo,OutputImage);
        delete pObject;
    }

    Log(TERSE,TEXT("Exiting performance test #3"));
    timeEndPeriod(1);
    LogFlush();
    return TST_PASS;
}


//==========================================================================
//
//  void InitSafetyBytes
//
//  Description:
//
//      We write twelve bytes after the input and output images so that we
//      can check the colour space conversions are not writing outside of
//      their buffers. This means that the input and output buffers must be
//      at least the largest possible image size plus sizeof(SafetyBytes)
//
//==========================================================================

void InitSafetyBytes(VIDEOINFO *pVideoInfo,BYTE *pImage)
{
    BYTE *pSafetyPlace = pImage + GetBitmapSize(&pVideoInfo->bmiHeader);
    CopyMemory((PVOID)pSafetyPlace,(PVOID)SafetyBytes,sizeof(SafetyBytes));
}


//==========================================================================
//
//  void CheckSafetyBytes
//
//  Description:
//
//      Check that the safety bytes are still in place after a conversion
//      We can just use the C runtime compare memory function, all we are
//      really interested in knowing is if they are ok or not, so we will
//      ASSERT if the check bytes don't match (SafetyBytes defined at top)
//
//==========================================================================

void CheckSafetyBytes(VIDEOINFO *pVideoInfo,BYTE *pImage)
{
    BYTE *pSafetyPlace = pImage + GetBitmapSize(&pVideoInfo->bmiHeader);
    ASSERT(memcmp(pSafetyPlace,SafetyBytes,sizeof(SafetyBytes)) == 0);
}


=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\multimedia\dshow\filters\image\vidtest\tests.h ===
// Copyright (c) Microsoft Corporation 1994-1996. All Rights Reserved
// Main automatic renderer tests, Anthony Phillips, January 1995

#ifndef _TESTS_
#define _TESTS_

int expect(UINT uExpected, UINT uActual, LPSTR CaseDesc);
void YieldAndSleep(DWORD cMilliseconds);
void YieldWithTimeout(HEVENT hEvent,DWORD cMilliseconds);

execTest1();            // Connect and disconnect the renderer
execTest2();            // Connect(); pause video and disconnect
execTest3();            // Connect video(); play and disconnect
execTest4();            // Connect renderer and connect again
execTest5();            // Connect and disconnect twice
execTest6();            // Try to disconnect while paused
execTest7();            // Try to disconnect while running
execTest8();            // Try multiple state changes
execTest9();            // Run without a reference clock
execTest10();           // Multithread stress test

#endif // __TESTS__


=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\multimedia\dshow\filters\image2\ap\ap.cpp ===
/******************************Module*Header*******************************\
* Module Name: AP.cpp
*
* The default DShow allocator presenter
*
*
* Created: Wed 02/23/2000
* Author:  Stephen Estrop [StEstrop]
*
* Copyright (c) 2000 Microsoft Corporation
\**************************************************************************/
#include <streams.h>
#include <windowsx.h>
#include <limits.h>

#ifdef FILTER_DLL
#include <initguid.h>
#endif
#include "VMRuuids.h"

#include "apobj.h"
#include "MediaSType.h"

#if defined(CHECK_FOR_LEAKS)
#include "ifleak.h"
#endif

#ifndef DECLSPEC_SELECTANY
#if (_MSC_VER >= 1100)
#define DECLSPEC_SELECTANY  __declspec(selectany)
#else
#define DECLSPEC_SELECTANY
#endif
#endif

EXTERN_C const GUID DECLSPEC_SELECTANY IID_IDirectDraw7 =
{
    0x15e65ec0, 0x3b9c, 0x11d2,
    {
        0xb9, 0x2f, 0x00, 0x60, 0x97, 0x97, 0xea, 0x5b
    }
};



#ifdef FILTER_DLL

STDAPI DllRegisterServer()
{
    AMTRACE((TEXT("DllRegisterServer")));
    return AMovieDllRegisterServer2( TRUE );
}

STDAPI DllUnregisterServer()
{
    AMTRACE((TEXT("DllUnregisterServer")));
    return AMovieDllRegisterServer2( FALSE );
}

CFactoryTemplate g_Templates[] = {
    {
        L"",
        &CLSID_AllocPresenter,
        CAllocatorPresenter::CreateInstance,
        CAllocatorPresenter::InitClass,
        NULL
    },
    {
        L"",
        &CLSID_AllocPresenterDDXclMode,
        CAllocatorPresenter::CreateInstanceDDXclMode,
        NULL,
        NULL
    }
};
int g_cTemplates = sizeof(g_Templates) / sizeof(g_Templates[0]);
#endif


/******************************Public*Routine******************************\
* CreateInstance
*
*
*
* History:
* Wed 02/23/2000 - StEstrop - Created
*
\**************************************************************************/
CUnknown*
CAllocatorPresenter::CreateInstance(
    LPUNKNOWN pUnk,
    HRESULT *phr
    )
{
    AMTRACE((TEXT("CVMRFilter::CreateInstance")));
    return new CAllocatorPresenter(pUnk, phr, FALSE);
}


/******************************Public*Routine******************************\
* CreateInstanceDDXclMode
*
*
*
* History:
* Wed 02/23/2000 - StEstrop - Created
*
\**************************************************************************/
CUnknown*
CAllocatorPresenter::CreateInstanceDDXclMode(
    LPUNKNOWN pUnk,
    HRESULT *phr
    )
{
    AMTRACE((TEXT("CVMRFilter::CreateInstanceDDXclMode")));
    return new CAllocatorPresenter(pUnk, phr, TRUE);
}


/******************************Public*Routine******************************\
* InitClass
*
*
*
* History:
* Thu 12/14/2000 - StEstrop - Created
*
\**************************************************************************/

#if defined(CHECK_FOR_LEAKS)
// the one and only g_IFLeak object.
CInterfaceLeak  g_IFLeak;

void
CAllocatorPresenter::InitClass(
    BOOL bLoading,
    const CLSID *clsid
    )
{
    if (bLoading) {
        DbgLog((LOG_TRACE, 0, TEXT("AP Thunks: Loaded") ));
        g_IFLeak.Init();
    }
    else {
        DbgLog((LOG_TRACE, 0, TEXT("AP Thunks: Unloaded") ));
        g_IFLeak.Term();
    }
}
#else
void
CAllocatorPresenter::InitClass(
    BOOL bLoading,
    const CLSID *clsid
    )
{
}
#endif


/******************************Public*Routine******************************\
* CAllocatorPresenter
*
*
*
* History:
* Wed 02/23/2000 - StEstrop - Created
*
\**************************************************************************/
CAllocatorPresenter::CAllocatorPresenter(
    LPUNKNOWN pUnk,
    HRESULT *phr,
    BOOL fDDXclMode
    )
    : CUnknown(NAME("Allocator Presenter"), pUnk)
    , m_lpCurrMon(NULL)
    , m_lpNewMon(NULL)
    , m_hwndClip(NULL)
    , m_clrBorder(RGB(0, 0, 0))
    , m_clrKey(RGB(16,0,16))
    , m_dwMappedColorKey(CLR_INVALID)
    , m_bMonitorStraddleInProgress(FALSE)
    , m_bStreaming(FALSE)
    , m_pSurfAllocatorNotify(NULL)
    , m_bDirectedFlips(FALSE)
    , m_bFlippable(false)
    , m_bUsingOverlays(false)
    , m_bOverlayVisible(false)
    , m_bDisableOverlays(false)
    , m_dwRenderingPrefs(RenderPrefs_AllowOverlays)
    , m_dwARMode(VMR_ARMODE_NONE)
    , m_pDDSDecode(NULL)
    , m_dwInterlaceFlags(0)
    , m_bSysMem(FALSE)
    , m_bDecimating(FALSE)
    , m_MMTimerId(0)
    , m_fDDXclMode(fDDXclMode)
{
    AMTRACE((TEXT("CAllocatorPresenter::CAllocatorPresenter")));

    ZeroMemory(&m_VideoSizeAct, sizeof(m_VideoSizeAct));
    ZeroMemory(&m_ARSize, sizeof(m_ARSize));

    ZeroMemory(&m_rcDstDesktop, sizeof(m_rcDstDesktop));

    ZeroMemory(&m_rcDstApp, sizeof(m_rcDstApp));
    ZeroMemory(&m_rcSrcApp, sizeof(m_rcSrcApp));

    ZeroMemory(&m_rcBdrTL, sizeof(m_rcBdrTL));
    ZeroMemory(&m_rcBdrBR, sizeof(m_rcBdrBR));

#ifdef DEBUG
    m_SleepTime = GetProfileIntA("VMR", "WaitForScanLine", 0);
#else
    m_SleepTime = 0;
#endif

    if (!m_fDDXclMode) {

        HRESULT hr = m_monitors.InitializeDisplaySystem( m_hwndClip );
        if (SUCCEEDED(hr)) {

            VMRGUID GUID;
            GetDefaultMonitor(&GUID);
            SetMonitor(&GUID);

            if (!m_lpCurrMon) {
                DbgLog((LOG_ERROR, 1, TEXT("No Primary monitor set !!")));
                *phr = E_FAIL;
            }
        }
        else {
            DbgLog((LOG_ERROR, 1, TEXT("Cannot initialize display system !!")));
            *phr = hr;
        }
    }

    const DWORD HEART_BEAT_TICK = 250;  // 250 mSec qtr second
    if (m_fDDXclMode) {
        m_uTimerID = SetTimer(NULL, 0, HEART_BEAT_TICK, GetTimerProc());
    }
    else {
        m_uTimerID = CompatibleTimeSetEvent(HEART_BEAT_TICK, HEART_BEAT_TICK / 2,
                                            CAllocatorPresenter::APHeartBeatTimerProc,
                                            (DWORD_PTR)this, TIME_PERIODIC);
    }
}

/******************************Public*Routine******************************\
* CAllocatorPresenter
*
*
*
* History:
* Wed 02/23/2000 - StEstrop - Created
*
\**************************************************************************/
CAllocatorPresenter::~CAllocatorPresenter()
{
    AMTRACE((TEXT("CAllocatorPresenter::~CAllocatorPresenter")));

    if (m_uTimerID) {
        if (m_fDDXclMode) {
            KillTimer(NULL, m_uTimerID);
        }
        else {
            timeKillEvent((DWORD)m_uTimerID);
        }
    }

    RELEASE(m_pSurfAllocatorNotify);
}


/******************************Public*Routine******************************\
* NonDelegatingQueryInterface
*
*
*
* History:
* Wed 02/23/2000 - StEstrop - Created
*
\**************************************************************************/
STDMETHODIMP
CAllocatorPresenter::NonDelegatingQueryInterface(
    REFIID riid,
    void ** ppv)
{
    AMTRACE((TEXT("CAlocatorPresenter::NonDelegatingQueryInterface")));

    HRESULT hr = E_NOINTERFACE;
    *ppv = NULL;

    if (riid == IID_IVMRSurfaceAllocator) {
        hr = GetInterface(static_cast<IVMRSurfaceAllocator*>(this), ppv);
    }
    else if (riid == IID_IVMRWindowlessControl) {
        hr = GetInterface(static_cast<IVMRWindowlessControl*>(this), ppv);
    }
    else if (riid == IID_IVMRImagePresenter) {
        hr = GetInterface(static_cast<IVMRImagePresenter*>(this), ppv);
    }
    else if (riid == IID_IVMRImagePresenterExclModeConfig) {
        if (m_fDDXclMode) {
            hr = GetInterface(static_cast<IVMRImagePresenterExclModeConfig*>(this), ppv);
        }
    }
    else if (riid == IID_IVMRImagePresenterConfig) {
        if (!m_fDDXclMode) {
            hr = GetInterface(static_cast<IVMRImagePresenterConfig*>(this), ppv);
        }
    }
    else if (riid == IID_IVMRMonitorConfig) {
        hr = GetInterface(static_cast<IVMRMonitorConfig*>(this), ppv);
    }
    else {
        hr = CUnknown::NonDelegatingQueryInterface(riid, ppv);
    }

#if defined(CHECK_FOR_LEAKS)
    if (hr == S_OK) {
        _pIFLeak->AddThunk((IUnknown **)ppv, "AP Object",  riid);
    }
#endif
    return hr;
}
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\multimedia\dshow\filters\image2\alloclib\alloclib.cpp ===
/******************************Module*Header*******************************\
* Module Name: AllocLib
*
*
*
*
* Created: Fri 03/10/2000
* Author:  Stephen Estrop [StEstrop]
*
* Copyright (c) 2000 Microsoft Corporation
\**************************************************************************/
#include <streams.h>
#include <dvdmedia.h>
#include <windowsx.h>
#include <d3d.h>
#include <limits.h>
#include <malloc.h>

#include "vmrp.h"
#include "AllocLib.h"

/////////////////////////////////////////////////////////////////////////////
//
// Utility functions for rectangles
//
/////////////////////////////////////////////////////////////////////////////

/*****************************Private*Routine******************************\
* EqualSizeRect
*
* returns true if the size of rc1 is the same as rc2.  Note that the
* position of the two rectangles may be different
*
* History:
* Thu 04/27/2000 - StEstrop - Created
*
\**************************************************************************/
bool
EqualSizeRect(
    const RECT* lpRc1,
    const RECT* lpRc2
    )
{
    return HEIGHT(lpRc1) == HEIGHT(lpRc2) && WIDTH(lpRc1) == WIDTH(lpRc2);
}

/*****************************Private*Routine******************************\
* ContainedRect
*
* returns true if rc1 is fully contained within rc2
*
* History:
* Thu 05/04/2000 - StEstrop - Created
*
\**************************************************************************/
bool
ContainedRect(
    const RECT* lpRc1,
    const RECT* lpRc2
    )
{
    return !(lpRc1->left   < lpRc2->left  ||
             lpRc1->right  > lpRc2->right ||
             lpRc1->top    < lpRc2->top   ||
             lpRc1->bottom > lpRc2->bottom);

}

/*****************************Private*Routine******************************\
* LetterBoxDstRect
*
* Takes a src rectangle and constructs the largest possible destination
* rectangle within the specifed destination rectangle such that
* the video maintains its current shape.
*
* This function assumes that pels are the same shape within both the src
* and dst rectangles.
*
* History:
* Tue 05/02/2000 - StEstrop - Created
*
\**************************************************************************/
void
LetterBoxDstRect(
    LPRECT lprcLBDst,
    const RECT& rcSrc,
    const RECT& rcDst,
    LPRECT lprcBdrTL,
    LPRECT lprcBdrBR
    )
{
    // figure out src/dest scale ratios
    int iSrcWidth  = WIDTH(&rcSrc);
    int iSrcHeight = HEIGHT(&rcSrc);

    int iDstWidth  = WIDTH(&rcDst);
    int iDstHeight = HEIGHT(&rcDst);

    int iDstLBWidth;
    int iDstLBHeight;

    //
    // work out if we are Column or Row letter boxing
    //

    if (MulDiv(iSrcWidth, iDstHeight, iSrcHeight) <= iDstWidth) {

        //
        // column letter boxing - we add border color bars to the
        // left and right of the video image to fill the destination
        // rectangle.
        //
        iDstLBWidth  = MulDiv(iDstHeight, iSrcWidth, iSrcHeight);
        iDstLBHeight = iDstHeight;
    }
    else {

        //
        // row letter boxing - we add border color bars to the top
        // and bottom of the video image to fill the destination
        // rectangle
        //
        iDstLBWidth  = iDstWidth;
        iDstLBHeight = MulDiv(iDstWidth, iSrcHeight, iSrcWidth);
    }


    //
    // now create a centered LB rectangle within the current destination rect
    //

    lprcLBDst->left   = rcDst.left + ((iDstWidth - iDstLBWidth) / 2);
    lprcLBDst->right  = lprcLBDst->left + iDstLBWidth;

    lprcLBDst->top    = rcDst.top + ((iDstHeight - iDstLBHeight) / 2);
    lprcLBDst->bottom = lprcLBDst->top + iDstLBHeight;

    //
    // Fill out the border rects if asked to do so
    //

    if (lprcBdrTL) {

        if (rcDst.top != lprcLBDst->top) {
            // border is on the top
            SetRect(lprcBdrTL, rcDst.left, rcDst.top,
                    lprcLBDst->right, lprcLBDst->top);
        }
        else {
            // border is on the left
            SetRect(lprcBdrTL, rcDst.left, rcDst.top,
                    lprcLBDst->left, lprcLBDst->bottom);
        }
    }

    if (lprcBdrBR) {

        if (rcDst.top != lprcLBDst->top) {
            // border is on the bottom
            SetRect(lprcBdrBR, lprcLBDst->left,
                    lprcLBDst->bottom, rcDst.right, rcDst.bottom);
        }
        else {
            // border is on the right
            SetRect(lprcBdrBR, lprcLBDst->right,
                    lprcLBDst->top, rcDst.right, rcDst.bottom);
        }
    }
}


/*****************************Private*Routine******************************\
* AspectRatioCorrectSize
*
* Corrects the supplied size structure so that it becomes the same shape
* as the specified aspect ratio, the correction is always applied in the
* horizontal axis
*
* History:
* Tue 05/02/2000 - StEstrop - Created
*
\**************************************************************************/
void
AspectRatioCorrectSize(
    LPSIZE lpSizeImage,
    const SIZE& sizeAr
    )
{
    int cxAR = sizeAr.cx * 1000;
    int cyAR = sizeAr.cy * 1000;

    long lCalcX = MulDiv(lpSizeImage->cx, cyAR, lpSizeImage->cy);

    if (lCalcX != cxAR) {
        lpSizeImage->cx = MulDiv(lpSizeImage->cy, cxAR, cyAR);
    }
}



/*****************************Private*Routine******************************\
* GetBitMasks
*
* Return the bit masks for the true colour VIDEOINFO or VIDEOINFO2 provided
*
* History:
* Wed 02/23/2000 - StEstrop - Created
*
\**************************************************************************/
const DWORD*
GetBitMasks(
    const BITMAPINFOHEADER *pHeader
    )
{
    AMTRACE((TEXT("GetBitMasks")));
    static DWORD FailMasks[] = {0, 0, 0};
    const DWORD *pdwBitMasks = NULL;

    ASSERT(pHeader);

    if (pHeader->biCompression != BI_RGB)
    {
        pdwBitMasks = (const DWORD *)((LPBYTE)pHeader + pHeader->biSize);
    }
    else {
        ASSERT(pHeader->biCompression == BI_RGB);
        switch (pHeader->biBitCount) {
        case 16:
            pdwBitMasks = bits555;
            break;

        case 24:
            pdwBitMasks = bits888;
            break;

        case 32:
            pdwBitMasks = bits888;
            break;

        default:
            pdwBitMasks = FailMasks;
            break;
        }
    }

    return pdwBitMasks;
}

/******************************Public*Routine******************************\
* FixupMediaType
*
* DShow filters have the habit of sometimes not setting the src and dst
* rectangles, in this case we should imply that the these rectangles
* should be the same width and height as the bitmap in the media format.
*
* History:
* Tue 08/22/2000 - StEstrop - Created
*
\**************************************************************************/
void
FixupMediaType(
    AM_MEDIA_TYPE* pmt
    )
{
    AMTRACE((TEXT("FixupMediaType")));

    LPRECT lprc;
    LPBITMAPINFOHEADER lpbi = GetbmiHeader(pmt);

    if (lpbi) {

        lprc = GetTargetRectFromMediaType(pmt);
        if (lprc && IsRectEmpty(lprc)) {
            SetRect(lprc, 0, 0, abs(lpbi->biWidth), abs(lpbi->biHeight));
        }

        lprc = GetSourceRectFromMediaType(pmt);
        if (lprc && IsRectEmpty(lprc)) {
            SetRect(lprc, 0, 0, abs(lpbi->biWidth), abs(lpbi->biHeight));
        }
    }
}



/******************************Public*Routine******************************\
* GetTargetRectFromMediaType
*
*
*
* History:
* Mon 06/26/2000 - StEstrop - Created
*
\**************************************************************************/
LPRECT
GetTargetRectFromMediaType(
    const AM_MEDIA_TYPE *pMediaType
    )
{
    AMTRACE((TEXT("GetTargetRectFromMediaType")));

    if (!pMediaType)
    {
        DbgLog((LOG_ERROR, 1, TEXT("pMediaType is NULL")));
        return NULL;
    }

    if (!(pMediaType->pbFormat))
    {
        DbgLog((LOG_ERROR, 1, TEXT("pMediaType->pbFormat is NULL")));
        return NULL;
    }

    LPRECT lpRect = NULL;
    if ((pMediaType->formattype == FORMAT_VideoInfo) &&
        (pMediaType->cbFormat >= sizeof(VIDEOINFOHEADER)))
    {
        lpRect = &(((VIDEOINFOHEADER*)(pMediaType->pbFormat))->rcTarget);
    }
    else if ((pMediaType->formattype == FORMAT_VideoInfo2) &&
             (pMediaType->cbFormat >= sizeof(VIDEOINFOHEADER2)))
    {
        lpRect = &(((VIDEOINFOHEADER2*)(pMediaType->pbFormat))->rcTarget);
    }

    return lpRect;

}

/******************************Public*Routine******************************\
* GetTargetScaleFromMediaType(
*
*   Check the mediatype for the PAD_4x3 or PAD_16x9 flags and compute the stretch.
*
*   If the flags are present, then we need to pad the image to 4x3 or 16x9.
*   We accomplish this by stretching the destination region then compressing
*   the target rectangle.  For example, to pad a 16x9 into a 4x3 area (and maintain
*   the width), we need to place the image in an area that is 16x9/4x3 = 4/3 times
*   taller.  Then we 'unstretch' the video by the inverse 3/4 to return it to a 16x9
*   image in the 4x3 area.
*
*   Similarly, if we want to place a 4x3 image in a 16x9 area, we need to pad the
*   sides (and keep the same height).  So we stretch the output area horizontally
*   by 16x9/4x3 then compress the target image rectangle by 4x3/16x9.
*
* History:
* Tue 03/14/2000 - GlennE - Created
*
\**************************************************************************/

void
GetTargetScaleFromMediaType(
    const AM_MEDIA_TYPE *pMediaType,
    TargetScale* pScale
    )
{
    pScale->fX = 1.0F;
    pScale->fY = 1.0F;

    if ((pMediaType->formattype == FORMAT_VideoInfo2) &&
        (pMediaType->cbFormat >= sizeof(VIDEOINFOHEADER2)))
    {
        const VIDEOINFOHEADER2& header = *(VIDEOINFOHEADER2*)(pMediaType->pbFormat);

        // fit source into the target area by reducing its size

        LONG lTargetARWidth;
        LONG lTargetARHeight;
        LONG lSourceARWidth = header.dwPictAspectRatioX;
        LONG lSourceARHeight = header.dwPictAspectRatioY;

        if( header.dwControlFlags & AMCONTROL_PAD_TO_16x9 ) {
            lTargetARWidth = 16;
            lTargetARHeight = 9;
        } else if( header.dwControlFlags & AMCONTROL_PAD_TO_4x3 ) {
            lTargetARWidth = 4;
            lTargetARHeight = 3;
        } else {
            // lTargetARWidth = lSourceARWidth;
            // lTargetARHeight = lSourceARHeight;
            // leave at 1.0 x/y
            return;
        }
        // float TargetRatio = float(lTargetARWidth)/lTargetARHeight;
        // float SourceRatio = float(lSourceARWidth)/lSourceARHeight;

        // if( Target > Source ) --> lTargetARWidth/lTargetARHeight > lSourceARWidth/lSourceARHeight
        //                  .... or after clearing fractions (since all positive)
        //                       --> lTargetARWidth * lSourceARHeight > lSourceARWidth * lTargetARHeight

        LONG TargetWidth = lTargetARWidth * lSourceARHeight;
        LONG SourceWidth = lSourceARWidth * lTargetARHeight;

        if( TargetWidth > SourceWidth ) {
            // wider, pad width
            // Assume heights equal, pad sides.  Pad fraction = ratio of ratios
            pScale->fX = float(SourceWidth) / TargetWidth;
            pScale->fY = 1.0F;
        } else if (TargetWidth < SourceWidth ) {
            // taller, pad height
            // Assume widths equal, pad top/bot.  Pad fraction = ratio of ratios
            pScale->fX = 1.0F;
            pScale->fY = float(TargetWidth) / SourceWidth;
        } else { // equal
            // no change
        }
    }
}

/******************************Public*Routine******************************\
* GetSourceRectFromMediaType
*
*
*
* History:
* Mon 06/26/2000 - StEstrop - Created
*
\**************************************************************************/
LPRECT
GetSourceRectFromMediaType(
    const AM_MEDIA_TYPE *pMediaType
    )
{
    AMTRACE((TEXT("GetSourceRectFromMediaType")));

    if (!pMediaType)
    {
        DbgLog((LOG_ERROR, 1, TEXT("pMediaType is NULL")));
        return NULL;
    }

    if (!(pMediaType->pbFormat))
    {
        DbgLog((LOG_ERROR, 1, TEXT("pMediaType->pbFormat is NULL")));
        return NULL;
    }

    LPRECT lpRect = NULL;
    if ((pMediaType->formattype == FORMAT_VideoInfo) &&
        (pMediaType->cbFormat >= sizeof(VIDEOINFOHEADER)))
    {
        lpRect = &(((VIDEOINFOHEADER*)(pMediaType->pbFormat))->rcSource);
    }
    else if ((pMediaType->formattype == FORMAT_VideoInfo2) &&
             (pMediaType->cbFormat >= sizeof(VIDEOINFOHEADER2)))
    {
        lpRect = &(((VIDEOINFOHEADER2*)(pMediaType->pbFormat))->rcSource);
    }

    return lpRect;

}

/*****************************Private*Routine******************************\
* GetbmiHeader
*
* Returns the bitmap info header associated with the specified CMediaType.
* Returns NULL if the CMediaType is not either of FORMAT_VideoInfo or
* FORMAT_VideoInfo2.
*
* History:
* Wed 02/23/2000 - StEstrop - Created
*
\**************************************************************************/
LPBITMAPINFOHEADER
GetbmiHeader(
    const AM_MEDIA_TYPE *pMediaType
    )
{
    AMTRACE((TEXT("GetbmiHeader")));

    if (!pMediaType)
    {
        DbgLog((LOG_ERROR, 1, TEXT("pMediaType is NULL")));
        return NULL;
    }

    if (!(pMediaType->pbFormat))
    {
        DbgLog((LOG_ERROR, 1, TEXT("pMediaType->pbFormat is NULL")));
        return NULL;
    }

    LPBITMAPINFOHEADER lpHeader = NULL;
    if ((pMediaType->formattype == FORMAT_VideoInfo) &&
        (pMediaType->cbFormat >= sizeof(VIDEOINFOHEADER)))
    {
        lpHeader = &(((VIDEOINFOHEADER*)(pMediaType->pbFormat))->bmiHeader);
    }
    else if ((pMediaType->formattype == FORMAT_VideoInfo2) &&
             (pMediaType->cbFormat >= sizeof(VIDEOINFOHEADER2)))
    {
        lpHeader = &(((VIDEOINFOHEADER2*)(pMediaType->pbFormat))->bmiHeader);
    }

    return lpHeader;
}

/*****************************Private*Routine******************************\
* AllocVideoMediaType
*
* This comes in useful when using the IEnumMediaTypes interface so
* that you can copy a media type, you can do nearly the same by creating
* a CMediaType object but as soon as it goes out of scope the destructor
* will delete the memory it allocated (this takes a copy of the memory)
*
*
* History:
* Wed 02/23/2000 - StEstrop - Created
*
\**************************************************************************/
HRESULT
AllocVideoMediaType(
    const AM_MEDIA_TYPE *pmtSource,
    AM_MEDIA_TYPE** ppmt
    )
{
    AMTRACE((TEXT("AllocVideoMediaType")));
    DWORD dwFormatSize = 0;
    BYTE *pFormatPtr = NULL;
    AM_MEDIA_TYPE *pMediaType = NULL;
    HRESULT hr = NOERROR;

    if (pmtSource->formattype == FORMAT_VideoInfo)
        dwFormatSize = sizeof(VIDEOINFO);
    else if (pmtSource->formattype == FORMAT_VideoInfo2)
        dwFormatSize = sizeof(TRUECOLORINFO) + sizeof(VIDEOINFOHEADER2) + 4;

    // actually this should be sizeof sizeof(VIDEOINFO2) once we define that

    pMediaType = (AM_MEDIA_TYPE *)CoTaskMemAlloc(sizeof(AM_MEDIA_TYPE));
    if (!pMediaType)
    {
        DbgLog((LOG_ERROR, 1, TEXT("Out of memory!!")));
        return E_OUTOFMEMORY;
    }

    pFormatPtr = (BYTE *)CoTaskMemAlloc(dwFormatSize);
    if (!pFormatPtr)
    {
        CoTaskMemFree((PVOID)pMediaType);
        DbgLog((LOG_ERROR, 1, TEXT("Out of memory!!")));
        return E_OUTOFMEMORY;
    }

    *pMediaType = *pmtSource;
    pMediaType->cbFormat = dwFormatSize;
    CopyMemory(pFormatPtr, pmtSource->pbFormat, pmtSource->cbFormat);

    pMediaType->pbFormat = pFormatPtr;
    *ppmt = pMediaType;
    return S_OK;
}


/*****************************Private*Routine******************************\
* ConvertSurfaceDescToMediaType
*
* Helper function converts a DirectDraw surface to a media type.
* The surface description must have:
*   Height
*   Width
*   lPitch
*   PixelFormat
*
* Initialise our output type based on the DirectDraw surface. As DirectDraw
* only deals with top down display devices so we must convert the height of
* the surface returned in the DDSURFACEDESC into a negative height. This is
* because DIBs use a positive height to indicate a bottom up image. We also
* initialise the other VIDEOINFO fields although they're hardly ever needed
*
*
* History:
* Wed 02/23/2000 - StEstrop - Created
*
\**************************************************************************/
HRESULT
ConvertSurfaceDescToMediaType(
    const LPDDSURFACEDESC2 pSurfaceDesc,
    const AM_MEDIA_TYPE* pTemplateMediaType,
    AM_MEDIA_TYPE** ppMediaType
    )
{
    AMTRACE((TEXT("ConvertSurfaceDescToMediaType")));
    HRESULT hr = NOERROR;
    BITMAPINFOHEADER *pbmiHeader = NULL;
    *ppMediaType = NULL;

    if ((pTemplateMediaType->formattype != FORMAT_VideoInfo ||
        pTemplateMediaType->cbFormat < sizeof(VIDEOINFOHEADER)) &&
        (pTemplateMediaType->formattype != FORMAT_VideoInfo2 ||
        pTemplateMediaType->cbFormat < sizeof(VIDEOINFOHEADER2)))
    {
        return NULL;
    }

    hr = AllocVideoMediaType(pTemplateMediaType, ppMediaType);
    if (FAILED(hr)) {
        return hr;
    }

    pbmiHeader = GetbmiHeader((const CMediaType*)*ppMediaType);
    if (!pbmiHeader)
    {
        FreeMediaType(**ppMediaType);
        DbgLog((LOG_ERROR, 1, TEXT("pbmiHeader is NULL, UNEXPECTED!!")));
        return E_FAIL;
    }

    //
    // Convert a DDSURFACEDESC2 into a BITMAPINFOHEADER (see notes later). The
    // bit depth of the surface can be retrieved from the DDPIXELFORMAT field
    // in the DDpSurfaceDesc-> The documentation is a little misleading because
    // it says the field is permutations of DDBD_*'s however in this case the
    // field is initialised by DirectDraw to be the actual surface bit depth
    //

    pbmiHeader->biSize = sizeof(BITMAPINFOHEADER);

    if (pSurfaceDesc->dwFlags & DDSD_PITCH)
    {
        pbmiHeader->biWidth = pSurfaceDesc->lPitch;

        // Convert the pitch from a byte count to a pixel count.
        // For some weird reason if the format is not a standard bit depth the
        // width field in the BITMAPINFOHEADER should be set to the number of
        // bytes instead of the width in pixels. This supports odd YUV formats
        // like IF09 which uses 9bpp.
        //

        int bpp = pSurfaceDesc->ddpfPixelFormat.dwRGBBitCount;
        if (bpp == 8 || bpp == 16 || bpp == 24 || bpp == 32)
        {
            pbmiHeader->biWidth /= (bpp / 8); // Divide by number of BYTES per pixel.
        }
    }
    else
    {
        pbmiHeader->biWidth = pSurfaceDesc->dwWidth;
        // BUGUBUG -- Do something odd here with strange YUV pixel formats?
        // Or does it matter?
    }

    pbmiHeader->biHeight        = -(LONG)pSurfaceDesc->dwHeight;
    pbmiHeader->biPlanes        = 1;
    pbmiHeader->biBitCount      = (USHORT)pSurfaceDesc->ddpfPixelFormat.dwRGBBitCount;
    pbmiHeader->biCompression   = pSurfaceDesc->ddpfPixelFormat.dwFourCC;
    pbmiHeader->biClrUsed       = 0;
    pbmiHeader->biClrImportant  = 0;


    // For true colour RGB formats tell the source there are bit
    // fields. But preserve BI_RGB from source (pTemplateMediaType) if
    // it's the standard mask.
    if (pbmiHeader->biCompression == BI_RGB)
    {
        BITMAPINFOHEADER *pbmiHeaderTempl = GetbmiHeader(pTemplateMediaType);
        if (pbmiHeader->biBitCount == 16 || pbmiHeader->biBitCount == 32)
        {
            if(pbmiHeaderTempl->biCompression == BI_BITFIELDS ||

               pbmiHeader->biBitCount == 32 &&
               !(0x00FF0000 == pSurfaceDesc->ddpfPixelFormat.dwRBitMask &&
                 0x0000FF00 == pSurfaceDesc->ddpfPixelFormat.dwGBitMask &&
                 0x000000FF == pSurfaceDesc->ddpfPixelFormat.dwBBitMask) ||

               pbmiHeader->biBitCount == 16 &&
               !((0x1f<<10) == pSurfaceDesc->ddpfPixelFormat.dwRBitMask &&
                 (0x1f<< 5) == pSurfaceDesc->ddpfPixelFormat.dwGBitMask &&
                 (0x1f<< 0) == pSurfaceDesc->ddpfPixelFormat.dwBBitMask))
            {
                pbmiHeader->biCompression = BI_BITFIELDS;
            }
        }
    }

    if (pbmiHeader->biBitCount <= iPALETTE)
    {
        pbmiHeader->biClrUsed = 1 << pbmiHeader->biBitCount;
    }

    pbmiHeader->biSizeImage = DIBSIZE(*pbmiHeader);



    // The RGB bit fields are in the same place as for YUV formats
    if (pbmiHeader->biCompression != BI_RGB)
    {
        DWORD *pdwBitMasks = NULL;
        pdwBitMasks = (DWORD*)GetBitMasks(pbmiHeader);
        ASSERT(pdwBitMasks);
        // GetBitMasks only returns the pointer to the actual bitmasks
        // in the mediatype if biCompression == BI_BITFIELDS
        pdwBitMasks[0] = pSurfaceDesc->ddpfPixelFormat.dwRBitMask;
        pdwBitMasks[1] = pSurfaceDesc->ddpfPixelFormat.dwGBitMask;
        pdwBitMasks[2] = pSurfaceDesc->ddpfPixelFormat.dwBBitMask;
    }

    // And finish it off with the other media type fields
    // The sub-type can fall into one of the following categories.
    //
    // 1. Some kind of DX7 D3D render target - with or without ALPHA
    // 2. Some kind of Alpha format - RGB or YUV
    // 3. Standard 4CC (YUV)
    // 4. Standard RGB

    (*ppMediaType)->subtype = GetBitmapSubtype(pbmiHeader);

    //
    // Look for 3D devices
    //
    if (pSurfaceDesc->ddsCaps.dwCaps & DDSCAPS_3DDEVICE) {

        //
        // We only support RGB Render Targets for now.
        //

        if (pSurfaceDesc->ddpfPixelFormat.dwFlags & DDPF_RGB) {

            if (pSurfaceDesc->ddpfPixelFormat.dwFlags & DDPF_ALPHAPIXELS) {

                switch (pbmiHeader->biBitCount) {
                case 32:
                    ASSERT(0x00FF0000 == pSurfaceDesc->ddpfPixelFormat.dwRBitMask &&
                           0x0000FF00 == pSurfaceDesc->ddpfPixelFormat.dwGBitMask &&
                           0x000000FF == pSurfaceDesc->ddpfPixelFormat.dwBBitMask);
                    (*ppMediaType)->subtype = MEDIASUBTYPE_ARGB32_D3D_DX7_RT;
                    break;

                case 16:
                    switch (pSurfaceDesc->ddpfPixelFormat.dwRGBAlphaBitMask) {
                    case 0X8000:
                        ASSERT((0x1f<<10) == pSurfaceDesc->ddpfPixelFormat.dwRBitMask &&
                               (0x1f<< 5) == pSurfaceDesc->ddpfPixelFormat.dwGBitMask &&
                               (0x1f<< 0) == pSurfaceDesc->ddpfPixelFormat.dwBBitMask);
                        (*ppMediaType)->subtype = MEDIASUBTYPE_ARGB1555_D3D_DX7_RT;
                        break;

                    case 0XF000:
                        ASSERT(0x0F00 == pSurfaceDesc->ddpfPixelFormat.dwRBitMask &&
                               0x00F0 == pSurfaceDesc->ddpfPixelFormat.dwGBitMask &&
                               0x000F == pSurfaceDesc->ddpfPixelFormat.dwBBitMask);
                        (*ppMediaType)->subtype = MEDIASUBTYPE_ARGB4444_D3D_DX7_RT;
                        break;
                    }
                }
            }
            else {

                switch (pbmiHeader->biBitCount) {
                case 32:
                    (*ppMediaType)->subtype = MEDIASUBTYPE_RGB32_D3D_DX7_RT;
                    break;

                case 16:
                    (*ppMediaType)->subtype = MEDIASUBTYPE_RGB16_D3D_DX7_RT;
                    break;
                }
            }
        }

    }

    //
    // Look for per-pixel alpha formats
    //

    else if (pSurfaceDesc->ddpfPixelFormat.dwFlags & DDPF_ALPHAPIXELS) {

        //
        // Is it RGB ?
        //

        if (pSurfaceDesc->ddpfPixelFormat.dwFlags & DDPF_RGB) {

            switch (pbmiHeader->biBitCount) {
            case 32:
                ASSERT(0x00FF0000 == pSurfaceDesc->ddpfPixelFormat.dwRBitMask &&
                       0x0000FF00 == pSurfaceDesc->ddpfPixelFormat.dwGBitMask &&
                       0x000000FF == pSurfaceDesc->ddpfPixelFormat.dwBBitMask);
                (*ppMediaType)->subtype = MEDIASUBTYPE_ARGB32;
                break;

            case 16:
                switch (pSurfaceDesc->ddpfPixelFormat.dwRGBAlphaBitMask) {
                case 0X8000:
                    ASSERT((0x1f<<10) == pSurfaceDesc->ddpfPixelFormat.dwRBitMask &&
                           (0x1f<< 5) == pSurfaceDesc->ddpfPixelFormat.dwGBitMask &&
                           (0x1f<< 0) == pSurfaceDesc->ddpfPixelFormat.dwBBitMask);
                    (*ppMediaType)->subtype = MEDIASUBTYPE_ARGB1555;
                    break;

                case 0XF000:
                    ASSERT(0x0f00 == pSurfaceDesc->ddpfPixelFormat.dwRBitMask &&
                           0x00f0 == pSurfaceDesc->ddpfPixelFormat.dwGBitMask &&
                           0x000f == pSurfaceDesc->ddpfPixelFormat.dwBBitMask);
                    (*ppMediaType)->subtype = MEDIASUBTYPE_ARGB4444;
                    break;
                }
            }
        }

        //
        // Is it YUV ?
        //

        else if (pSurfaceDesc->ddpfPixelFormat.dwFlags & DDPF_FOURCC) {

            switch (pbmiHeader->biBitCount) {
            case 32:
                ASSERT(0xFF000000 == pSurfaceDesc->ddpfPixelFormat.dwYUVAlphaBitMask &&
                       0x00FF0000 == pSurfaceDesc->ddpfPixelFormat.dwYBitMask &&
                       0x0000FF00 == pSurfaceDesc->ddpfPixelFormat.dwUBitMask &&
                       0x000000FF == pSurfaceDesc->ddpfPixelFormat.dwVBitMask);
                (*ppMediaType)->subtype = MEDIASUBTYPE_AYUV;
                break;
            }
        }
    }

    (*ppMediaType)->lSampleSize = pbmiHeader->biSizeImage;

    // set the src and dest rects if necessary
    if ((*ppMediaType)->formattype == FORMAT_VideoInfo)
    {
        VIDEOINFOHEADER *pVideoInfo = (VIDEOINFOHEADER *)(*ppMediaType)->pbFormat;
        VIDEOINFOHEADER *pSrcVideoInfo = (VIDEOINFOHEADER *)pTemplateMediaType->pbFormat;

        // if the surface allocated is different than the size specified by the decoder
        // then use the src and dest to ask the decoder to clip the video
        if ((abs(pVideoInfo->bmiHeader.biHeight) != abs(pSrcVideoInfo->bmiHeader.biHeight)) ||
            (abs(pVideoInfo->bmiHeader.biWidth) != abs(pSrcVideoInfo->bmiHeader.biWidth)))
        {
            if (IsRectEmpty(&(pVideoInfo->rcSource)))
            {
                pVideoInfo->rcSource.left = pVideoInfo->rcSource.top = 0;
                pVideoInfo->rcSource.right = abs(pSrcVideoInfo->bmiHeader.biWidth);
                pVideoInfo->rcSource.bottom = abs(pSrcVideoInfo->bmiHeader.biHeight);
            }
            if (IsRectEmpty(&(pVideoInfo->rcTarget)))
            {
                pVideoInfo->rcTarget.left = pVideoInfo->rcTarget.top = 0;
                pVideoInfo->rcTarget.right = abs(pSrcVideoInfo->bmiHeader.biWidth);
                pVideoInfo->rcTarget.bottom = abs(pSrcVideoInfo->bmiHeader.biHeight);
            }
        }
    }
    else if ((*ppMediaType)->formattype == FORMAT_VideoInfo2)
    {
        VIDEOINFOHEADER2 *pVideoInfo2 = (VIDEOINFOHEADER2 *)(*ppMediaType)->pbFormat;
        VIDEOINFOHEADER2 *pSrcVideoInfo2 = (VIDEOINFOHEADER2 *)pTemplateMediaType->pbFormat;

        // if the surface allocated is different than the size specified by the decoder
        // then use the src and dest to ask the decoder to clip the video
        if ((abs(pVideoInfo2->bmiHeader.biHeight) != abs(pSrcVideoInfo2->bmiHeader.biHeight)) ||
            (abs(pVideoInfo2->bmiHeader.biWidth) != abs(pSrcVideoInfo2->bmiHeader.biWidth)))
        {
            if (IsRectEmpty(&(pVideoInfo2->rcSource)))
            {
                pVideoInfo2->rcSource.left = pVideoInfo2->rcSource.top = 0;
                pVideoInfo2->rcSource.right = abs(pSrcVideoInfo2->bmiHeader.biWidth);
                pVideoInfo2->rcSource.bottom = abs(pSrcVideoInfo2->bmiHeader.biHeight);
            }

            if (IsRectEmpty(&(pVideoInfo2->rcTarget)))
            {
                pVideoInfo2->rcTarget.left = pVideoInfo2->rcTarget.top = 0;
                pVideoInfo2->rcTarget.right = abs(pSrcVideoInfo2->bmiHeader.biWidth);
                pVideoInfo2->rcTarget.bottom = abs(pSrcVideoInfo2->bmiHeader.biHeight);
            }
        }
    }

    return hr;
}


/******************************Public*Routine******************************\
* VMRCopyFourCC
*
*
*
* History:
* Fri 01/19/2001 - StEstrop - Created
*
\**************************************************************************/
HRESULT
VMRCopyFourCC(
    LPDIRECTDRAWSURFACE7 lpDst,
    LPDIRECTDRAWSURFACE7 lpSrc
    )
{
    bool fDstLocked = false;
    bool fSrcLocked = false;

    DDSURFACEDESC2 ddsdS = {sizeof(DDSURFACEDESC2)};
    DDSURFACEDESC2 ddsdD = {sizeof(DDSURFACEDESC2)};
    HRESULT hr = E_FAIL;

    __try {

        CHECK_HR(hr = lpDst->Lock(NULL, &ddsdD, DDLOCK_NOSYSLOCK | DDLOCK_WAIT, NULL));
        fDstLocked = true;

        CHECK_HR(hr = lpSrc->Lock(NULL, &ddsdS, DDLOCK_NOSYSLOCK | DDLOCK_WAIT, NULL));
        fSrcLocked = true;

        ASSERT(ddsdS.ddpfPixelFormat.dwFourCC == ddsdD.ddpfPixelFormat.dwFourCC);
        ASSERT(ddsdS.ddpfPixelFormat.dwRGBBitCount == ddsdD.ddpfPixelFormat.dwRGBBitCount);
        ASSERT(ddsdS.lPitch == ddsdD.lPitch);

        LPBYTE pSrc = (LPBYTE)ddsdS.lpSurface;
        LPBYTE pDst = (LPBYTE)ddsdD.lpSurface;

        switch (ddsdS.ddpfPixelFormat.dwFourCC) {

        // planar 4:2:0 formats
        case mmioFOURCC('Y','V','1','2'):
        case mmioFOURCC('I','4','2','0'):
        case mmioFOURCC('I','Y','U','V'): {

                LONG lSize  = (3 * ddsdS.lPitch * ddsdS.dwHeight) / 2;
                CopyMemory(pDst, pSrc, lSize);
            }
            break;

        // RGB formats - fall thru to packed YUV case
        case 0:
            ASSERT((ddsdS.dwFlags & DDPF_RGB) == DDPF_RGB);

        // packed 4:2:2 formats
        case mmioFOURCC('Y','U','Y','2'):
        case mmioFOURCC('U','Y','V','Y'): {

                LONG lSize  = ddsdS.lPitch * ddsdS.dwHeight;
                CopyMemory(pDst, pSrc, lSize);
            }
            break;
        }

    }
    __finally {

        if (fDstLocked) {
            lpDst->Unlock(NULL);
        }

        if (fSrcLocked) {
            lpSrc->Unlock(NULL);
        }
    }

    return hr;
}

/*****************************Private*Routine******************************\
* AlphaPalPaintSurfaceBlack
*
*
*
* History:
* Tue 02/29/2000 - StEstrop - Created
*
\**************************************************************************/
HRESULT
AlphaPalPaintSurfaceBlack(
    LPDIRECTDRAWSURFACE7 pDDrawSurface
    )
{
    AMTRACE((TEXT("AlphaPalPaintSurfaceBlack")));

    DDBLTFX ddFX;
    ZeroMemory(&ddFX, sizeof(ddFX));
    ddFX.dwSize = sizeof(ddFX);
    return pDDrawSurface->Blt(NULL, NULL, NULL, DDBLT_COLORFILL | DDBLT_WAIT, &ddFX);
}


/*****************************Private*Routine******************************\
* YV12PaintSurfaceBlack
*
*
*
* History:
* Tue 02/29/2000 - StEstrop - Created
*
\**************************************************************************/
HRESULT
YV12PaintSurfaceBlack(
    LPDIRECTDRAWSURFACE7 pDDrawSurface
    )
{
    AMTRACE((TEXT("YV12PaintSurfaceBlack")));
    HRESULT hr = NOERROR;
    DDSURFACEDESC2 ddsd;

    // now lock the surface so we can start filling the surface with black
    ddsd.dwSize = sizeof(ddsd);
    hr = pDDrawSurface->Lock(NULL, &ddsd, DDLOCK_NOSYSLOCK | DDLOCK_WAIT, NULL);
    if (hr == DD_OK)
    {
        DWORD y;
        LPBYTE pDst = (LPBYTE)ddsd.lpSurface;
        LONG  OutStride = ddsd.lPitch;
        DWORD VSize = ddsd.dwHeight;
        DWORD HSize = ddsd.dwWidth;

        // Y Component
        for (y = 0; y < VSize; y++) {
            FillMemory(pDst, HSize, (BYTE)0x10);     // 1 line at a time
            pDst += OutStride;
        }

        HSize /= 2;
        VSize /= 2;
        OutStride /= 2;

        // Cb Component
        for (y = 0; y < VSize; y++) {
            FillMemory(pDst, HSize, (BYTE)0x80);     // 1 line at a time
            pDst += OutStride;
        }

        // Cr Component
        for (y = 0; y < VSize; y++) {
            FillMemory(pDst, HSize, (BYTE)0x80);     // 1 line at a time
            pDst += OutStride;
        }

        pDDrawSurface->Unlock(NULL);
    }

    return hr;
}

/*****************************Private*Routine******************************\
* NV12PaintSurfaceBlack
*
*
*
* History:
* Tue 02/29/2000 - StEstrop - Created
*
\**************************************************************************/
HRESULT
NV12PaintSurfaceBlack(
    LPDIRECTDRAWSURFACE7 pDDrawSurface
    )
{
    AMTRACE((TEXT("NV12PaintSurfaceBlack")));
    HRESULT hr = NOERROR;
    DDSURFACEDESC2 ddsd;

    // now lock the surface so we can start filling the surface with black
    ddsd.dwSize = sizeof(ddsd);
    hr = pDDrawSurface->Lock(NULL, &ddsd, DDLOCK_NOSYSLOCK | DDLOCK_WAIT, NULL);
    if (hr == DD_OK)
    {
        DWORD y;
        LPBYTE pDst = (LPBYTE)ddsd.lpSurface;
        LONG  OutStride = ddsd.lPitch;
        DWORD VSize = ddsd.dwHeight;
        DWORD HSize = ddsd.dwWidth;

        // Y Component
        for (y = 0; y < VSize; y++) {
            FillMemory(pDst, HSize, (BYTE)0x10);     // 1 line at a time
            pDst += OutStride;
        }

        VSize /= 2;

        // Cb and Cr components are interleaved together
        for (y = 0; y < VSize; y++) {
            FillMemory(pDst, HSize, (BYTE)0x80);     // 1 line at a time
            pDst += OutStride;
        }

        pDDrawSurface->Unlock(NULL);
    }

    return hr;
}


/*****************************Private*Routine******************************\
* IMC1andIMC3PaintSurfaceBlack
*
*
*
* History:
* Tue 02/29/2000 - StEstrop - Created
*
\**************************************************************************/
HRESULT
IMC1andIMC3PaintSurfaceBlack(
    LPDIRECTDRAWSURFACE7 pDDrawSurface
    )
{
    AMTRACE((TEXT("IMC1andIMC3PaintSurfaceBlack")));

    // DDBLTFX ddFX;
    // INITDDSTRUCT(ddFX);
    // //                    V U Y A
    // ddFX.dwFillColor = 0x80801000;
    // return pDDrawSurface->Blt(NULL, NULL, NULL, DDBLT_COLORFILL, &ddFX);

    HRESULT hr = NOERROR;
    DDSURFACEDESC2 ddsd;

    // now lock the surface so we can start filling the surface with black
    ddsd.dwSize = sizeof(ddsd);


    hr = pDDrawSurface->Lock(NULL, &ddsd, DDLOCK_NOSYSLOCK | DDLOCK_WAIT, NULL);
    if (hr == DD_OK)
    {
        DWORD y;
        LPBYTE pDst = (LPBYTE)ddsd.lpSurface;
        LONG  OutStride = ddsd.lPitch;
        DWORD VSize = ddsd.dwHeight;
        DWORD HSize = ddsd.dwWidth;

        // Y Component
        for (y = 0; y < VSize; y++) {
            FillMemory(pDst, HSize, (BYTE)0x10);     // 1 line at a time
            pDst += OutStride;
        }

        HSize /= 2;
        VSize /= 2;

        // Cb Component
        for (y = 0; y < VSize; y++) {
            FillMemory(pDst, HSize, (BYTE)0x80);     // 1 line at a time
            pDst += OutStride;
        }

        // Cr Component
        for (y = 0; y < VSize; y++) {
            FillMemory(pDst, HSize, (BYTE)0x80);     // 1 line at a time
            pDst += OutStride;
        }

        pDDrawSurface->Unlock(NULL);
    }

    return hr;
}


/******************************Public*Routine******************************\
* YUV16PaintSurfaceBlack
*
*
*
* History:
* Wed 09/13/2000 - StEstrop - Created
*
\**************************************************************************/
HRESULT
YUV16PaintSurfaceBlack(
    LPDIRECTDRAWSURFACE7 pdds,
    DWORD dwBlack
    )
{
    AMTRACE((TEXT("YUV16PaintSurfaceBlack")));
    HRESULT hr = NOERROR;
    DDSURFACEDESC2 ddsd;

    // now lock the surface so we can start filling the surface with black
    ddsd.dwSize = sizeof(ddsd);

    for ( ;; ) {

        hr = pdds->Lock(NULL, &ddsd, DDLOCK_NOSYSLOCK | DDLOCK_WAIT, NULL);

        if (hr == DD_OK || hr != DDERR_WASSTILLDRAWING) {
            break;
        }

        Sleep(1);
    }

    if (hr == DD_OK)
    {
        DWORD y, x;
        LPDWORD pDst = (LPDWORD)ddsd.lpSurface;
        LONG  OutStride = ddsd.lPitch;

        for (y = 0; y < ddsd.dwHeight; y++) {

            for (x = 0; x < ddsd.dwWidth / 2; x++) {
                pDst[x] = dwBlack;
            }

            // Dont forget that the stride is a byte count
            *((LPBYTE*)&pDst) += OutStride;
        }

        pdds->Unlock(NULL);
    }

    return hr;
}


/*****************************Private*Routine******************************\
* BlackPaintProc
*
*
*
* History:
* Tue 02/29/2000 - StEstrop - Created
*
\**************************************************************************/
HRESULT
BlackPaintProc(
    LPDIRECTDRAWSURFACE7 pDDrawSurface,
    DDSURFACEDESC2* lpddSurfaceDesc
    )
{
    AMTRACE((TEXT("BlackPaintProc")));

    //
    // If the surface is YUV take care of the types that we
    // know the pixel format for.  Those surfaces that we don't know
    // about will get painted '0' which may be bright green for
    // YUV surfaces.
    //

    if (lpddSurfaceDesc->ddpfPixelFormat.dwFlags & DDPF_FOURCC) {

        //
        // compute the black value if the fourCC code is suitable,
        // otherwise can't handle it
        //

        switch (lpddSurfaceDesc->ddpfPixelFormat.dwFourCC) {

        case mmioFOURCC('I','A','4','4'):
        case mmioFOURCC('A','I','4','4'):
            return AlphaPalPaintSurfaceBlack(pDDrawSurface);

        case mmioFOURCC('I','M','C','1'):
        case mmioFOURCC('I','M','C','3'):
            return IMC1andIMC3PaintSurfaceBlack(pDDrawSurface);

        case mmioFOURCC('Y','V','1','2'):
        case mmioFOURCC('I','4','2','0'):
        case mmioFOURCC('I','Y','U','V'):
            return YV12PaintSurfaceBlack(pDDrawSurface);

        case mmioFOURCC('N','V','1','2'):
        case mmioFOURCC('N','V','2','1'):
            return NV12PaintSurfaceBlack(pDDrawSurface);

        case mmioFOURCC('Y','U','Y','2'):
            return YUV16PaintSurfaceBlack(pDDrawSurface, 0x80108010);

        case mmioFOURCC('U','Y','V','Y'):
            return YUV16PaintSurfaceBlack(pDDrawSurface, 0x10801080);
        }

        return E_FAIL;
    }

    DDBLTFX ddFX;
    INITDDSTRUCT(ddFX);
    return pDDrawSurface->Blt(NULL, NULL, NULL, DDBLT_COLORFILL, &ddFX);
}



/*****************************Private*Routine******************************\
* PaintSurfaceBlack
*
*
*
* History:
* Tue 02/29/2000 - StEstrop - Created
*
\**************************************************************************/
HRESULT
PaintDDrawSurfaceBlack(
    LPDIRECTDRAWSURFACE7 pDDrawSurface
    )
{
    AMTRACE((TEXT("PaintDDrawSurfaceBlack")));

    LPDIRECTDRAWSURFACE7 *ppDDrawSurface = NULL;
    DDSCAPS2 ddSurfaceCaps;
    DDSURFACEDESC2 ddSurfaceDesc;
    DWORD dwAllocSize;
    DWORD i = 0, dwBackBufferCount = 0;

    // get the surface description
    INITDDSTRUCT(ddSurfaceDesc);
    HRESULT hr = pDDrawSurface->GetSurfaceDesc(&ddSurfaceDesc);
    if (SUCCEEDED(hr)) {

        if (ddSurfaceDesc.dwFlags & DDSD_BACKBUFFERCOUNT) {
            dwBackBufferCount = ddSurfaceDesc.dwBackBufferCount;
        }

        hr = BlackPaintProc(pDDrawSurface, &ddSurfaceDesc);
        if (FAILED(hr))
        {
            DbgLog((LOG_ERROR,1,
                    TEXT("pDDrawSurface->Blt failed, hr = 0x%x"), hr));
            return hr;
        }

        if (dwBackBufferCount > 0) {

            dwAllocSize = (dwBackBufferCount + 1) * sizeof(LPDIRECTDRAWSURFACE);
            ppDDrawSurface = (LPDIRECTDRAWSURFACE7*)_alloca(dwAllocSize);

            ZeroMemory(ppDDrawSurface, dwAllocSize);
            ZeroMemory(&ddSurfaceCaps, sizeof(ddSurfaceCaps));
            ddSurfaceCaps.dwCaps = DDSCAPS_FLIP | DDSCAPS_COMPLEX;

            if( DDSCAPS_OVERLAY & ddSurfaceDesc.ddsCaps.dwCaps ) {
                ddSurfaceCaps.dwCaps |= DDSCAPS_OVERLAY;
            }

            for (i = 0; i < dwBackBufferCount; i++) {

                LPDIRECTDRAWSURFACE7 pCurrentDDrawSurface = NULL;
                if (i == 0) {
                    pCurrentDDrawSurface = pDDrawSurface;
                }
                else {
                    pCurrentDDrawSurface = ppDDrawSurface[i];
                }
                ASSERT(pCurrentDDrawSurface);


                //
                // Get the back buffer surface and store it in the
                // next (in the circular sense) entry
                //

                hr = pCurrentDDrawSurface->GetAttachedSurface(
                        &ddSurfaceCaps,
                        &ppDDrawSurface[i + 1]);

                if (FAILED(hr))
                {
                    DbgLog((LOG_ERROR,1,
                            TEXT("Function pDDrawSurface->GetAttachedSurface ")
                            TEXT("failed, hr = 0x%x"), hr ));
                    break;
                }

                ASSERT(ppDDrawSurface[i+1]);

                //
                // Peform a DirectDraw colorfill BLT
                //

                hr = BlackPaintProc(ppDDrawSurface[i + 1], &ddSurfaceDesc);
                if (FAILED(hr)) {
                    DbgLog((LOG_ERROR,1,
                            TEXT("ppDDrawSurface[i + 1]->Blt failed, ")
                            TEXT("hr = 0x%x"), hr));
                    break;
                }
            }
        }
    }

    if (ppDDrawSurface) {
        for (i = 0; i < dwBackBufferCount + 1; i++) {
            if (ppDDrawSurface[i]) {
                ppDDrawSurface[i]->Release();
            }
        }
    }

    if (hr != DD_OK) {
        DbgLog((LOG_ERROR, 1, TEXT("PaintSurfaceBlack failed")));
        hr = S_OK;
    }

    return hr;
}


/*****************************Private*Routine******************************\
* GetImageAspectRatio
*
*
*
* History:
* Tue 03/07/2000 - StEstrop - Created
*
\**************************************************************************/
HRESULT
GetImageAspectRatio(
    const AM_MEDIA_TYPE* pMediaType,
    long* lpARWidth,
    long* lpARHeight
    )
{
    AMTRACE((TEXT("GetImageAspectRatio")));

    if ((pMediaType->formattype == FORMAT_VideoInfo) &&
        (pMediaType->cbFormat >= sizeof(VIDEOINFOHEADER)))
    {
        VIDEOINFOHEADER* pVideoInfo = (VIDEOINFOHEADER*)(pMediaType->pbFormat);

        long Width;
        long Height;

        LPRECT lprc = &pVideoInfo->rcTarget;
        if (IsRectEmpty(lprc)) {
            Width  = abs(pVideoInfo->bmiHeader.biWidth);
            Height = abs(pVideoInfo->bmiHeader.biHeight);
        }
        else {
            Width  = WIDTH(lprc);
            Height = HEIGHT(lprc);
        }

        *lpARWidth = Width;
        *lpARHeight = Height;

        return S_OK;
    }

    if ((pMediaType->formattype == FORMAT_VideoInfo2) &&
        (pMediaType->cbFormat >= sizeof(VIDEOINFOHEADER2)))
    {
        const VIDEOINFOHEADER2& header = *(VIDEOINFOHEADER2*)(pMediaType->pbFormat);


        if( header.dwControlFlags & AMCONTROL_PAD_TO_16x9 ) {
            *lpARWidth = 16;
            *lpARHeight = 9;
        } else if( header.dwControlFlags & AMCONTROL_PAD_TO_4x3 ) {
            *lpARWidth = 4;
            *lpARHeight = 3;
        } else {
            *lpARWidth = header.dwPictAspectRatioX;
            *lpARHeight = header.dwPictAspectRatioY;
        }
        return S_OK;
    }

    DbgLog((LOG_ERROR, 1, TEXT("MediaType does not contain AR info!!")));
    return E_FAIL;

}


/*****************************Private*Routine******************************\
* D3DEnumDevicesCallback7
*
*
*
* History:
* Wed 07/19/2000 - StEstrop - Created
*
\**************************************************************************/

HRESULT CALLBACK
D3DEnumDevicesCallback7(
    LPSTR lpDeviceDescription,
    LPSTR lpDeviceName,
    LPD3DDEVICEDESC7 lpD3DDeviceDesc,
    LPVOID lpContext
    )
{
    AMTRACE((TEXT("D3DEnumDevicesCallback7")));
    DWORD* ps = (DWORD*)lpContext;

    if (lpD3DDeviceDesc->deviceGUID == IID_IDirect3DHALDevice) {

        if (lpD3DDeviceDesc->dpcTriCaps.dwTextureCaps & D3DPTEXTURECAPS_TRANSPARENCY) {
            *ps |= TXTR_SRCKEY;
        }

        if (!(lpD3DDeviceDesc->dpcTriCaps.dwTextureCaps & D3DPTEXTURECAPS_NONPOW2CONDITIONAL)) {
            *ps |= TXTR_POWER2;
        }

        if (lpD3DDeviceDesc->dwDevCaps & D3DDEVCAPS_TEXTURENONLOCALVIDMEM) {
            *ps |= (TXTR_AGPYUVMEM | TXTR_AGPRGBMEM);
        }
    }

    return (HRESULT) D3DENUMRET_OK;
}


/*****************************Private*Routine******************************\
* GetTextureCaps
*
*
*
* History:
* Wed 07/19/2000 - StEstrop - Created
*
\**************************************************************************/
HRESULT
GetTextureCaps(
    LPDIRECTDRAW7 pDD,
    DWORD* ptc
    )
{
    AMTRACE((TEXT("GetTextureCaps")));
    LPDIRECT3D7 pD3D = NULL;

    DDCAPS_DX7 ddCaps;
    INITDDSTRUCT(ddCaps);

    *ptc = 0;
    HRESULT hr = pDD->GetCaps((LPDDCAPS)&ddCaps, NULL);
    if (hr != DD_OK) {
        return hr;
    }

    hr = pDD->QueryInterface(IID_IDirect3D7, (LPVOID *)&pD3D);

    if (SUCCEEDED(hr)) {
        pD3D->EnumDevices(D3DEnumDevicesCallback7, (LPVOID)ptc);
    }

    //
    // Only turn on the AGPYUV flag if we can Blt from it as well
    // as texture
    //

    const DWORD dwCaps = (DDCAPS_BLTFOURCC | DDCAPS_BLTSTRETCH);
    if ((dwCaps & ddCaps.dwNLVBCaps) != dwCaps) {
        *ptc &= ~TXTR_AGPYUVMEM;
    }

    RELEASE(pD3D);
    return hr;
}

/*****************************Private*Routine******************************\
* DDColorMatch
*
* convert a RGB color to a pysical color.
* we do this by leting GDI SetPixel() do the color matching
* then we lock the memory and see what it got mapped to.
*
* Static function since only called from DDColorMatchOffscreen
*
* History:
* Fri 04/07/2000 - GlennE - Created
*
\**************************************************************************/
DWORD
DDColorMatch(
    IDirectDrawSurface7 *pdds,
    COLORREF rgb,
    HRESULT& hr
    )
{
    AMTRACE((TEXT("DDColorMatch")));
    COLORREF rgbT;
    HDC hdc;
    DWORD dw = CLR_INVALID;
    DDSURFACEDESC2 ddsd;

    //  use GDI SetPixel to color match for us
    if (rgb != CLR_INVALID && pdds->GetDC(&hdc) == DD_OK)
    {
        rgbT = GetPixel(hdc, 0, 0);             // save current pixel value
        SetPixel(hdc, 0, 0, rgb);               // set our value
        pdds->ReleaseDC(hdc);
    }

    // now lock the surface so we can read back the converted color
    ddsd.dwSize = sizeof(ddsd);
    while( (hr = pdds->Lock(NULL, &ddsd, 0, NULL)) == DDERR_WASSTILLDRAWING) {
        // yield to the next thread (or return if we're the highest priority)
        Sleep(0);
    }
    if (hr == DD_OK)
    {
        // get DWORD
        dw  = *(DWORD *)ddsd.lpSurface;

        // mask it to bpp
        if (ddsd.ddpfPixelFormat.dwRGBBitCount < 32)
            dw &= (1 << ddsd.ddpfPixelFormat.dwRGBBitCount)-1;
        pdds->Unlock(NULL);
    }

    //  now put the color that was there back.
    if (rgb != CLR_INVALID && pdds->GetDC(&hdc) == DD_OK)
    {
        SetPixel(hdc, 0, 0, rgbT);
        pdds->ReleaseDC(hdc);
    }

    return dw;
}

/******************************Public*Routine******************************\
* GetInterlaceFlagsFromMediaType
*
* Get the InterlaceFlags from the mediatype. If the format is VideoInfo,
* it returns the flags as zero.
*
* History:
* Mon 01/08/2001 - StEstrop - Created
*
\**************************************************************************/
HRESULT
GetInterlaceFlagsFromMediaType(
    const AM_MEDIA_TYPE *pMediaType,
    DWORD *pdwInterlaceFlags
    )
{
    HRESULT hr = NOERROR;
    BITMAPINFOHEADER *pHeader = NULL;

    AMTRACE((TEXT("GetInterlaceFlagsFromMediaType")));

    __try {

        if (!pMediaType)
        {
            DbgLog((LOG_ERROR, 1, TEXT("pMediaType is NULL")));
            hr = E_INVALIDARG;
            __leave;
        }

        if (!pdwInterlaceFlags)
        {
            DbgLog((LOG_ERROR, 1, TEXT("pdwInterlaceFlags is NULL")));
            hr = E_INVALIDARG;
            __leave;
        }

        // get the header just to make sure the mediatype is ok
        pHeader = GetbmiHeader(pMediaType);
        if (!pHeader)
        {
            DbgLog((LOG_ERROR, 1, TEXT("pHeader is NULL")));
            hr = E_INVALIDARG;
            __leave;
        }

        if (pMediaType->formattype == FORMAT_VideoInfo)
        {
            *pdwInterlaceFlags = 0;
        }
        else if (pMediaType->formattype == FORMAT_VideoInfo2)
        {
            *pdwInterlaceFlags = ((VIDEOINFOHEADER2*)(pMediaType->pbFormat))->dwInterlaceFlags;
        }
    }
    __finally {
    }

    return hr;
}

/*****************************Private*Routine******************************\
* NeedToFlipOddEven
*
* given the interlace flags and the type-specific flags, this function
* determines whether we are supposed to display the sample in bob-mode or not.
* It also tells us, which direct-draw flag are we supposed to use when
* flipping. When displaying an interleaved frame, it assumes we are
* talking about the field which is supposed to be displayed first.
*
* History:
* Mon 01/08/2001 - StEstrop - Created (from the OVMixer original)
*
\**************************************************************************/
BOOL
NeedToFlipOddEven(
    DWORD dwInterlaceFlags,
    DWORD dwTypeSpecificFlags,
    DWORD *pdwFlipFlag,
    BOOL bUsingOverlays
    )
{
    AMTRACE((TEXT("NeedToFlipOddEven")));

    BOOL bDisplayField1 = TRUE;
    BOOL bField1IsOdd = TRUE;
    BOOL bNeedToFlipOddEven = FALSE;
    DWORD dwFlipFlag = 0;

    __try {

        // if not interlaced content, mode is not bob
        // if not using overlay nothing to do either
        if (!(dwInterlaceFlags & AMINTERLACE_IsInterlaced) || !bUsingOverlays)
        {
            __leave;
        }
        // if sample have a single field, then check the field pattern
        if ((dwInterlaceFlags & AMINTERLACE_1FieldPerSample) &&
            (((dwInterlaceFlags & AMINTERLACE_FieldPatternMask) == AMINTERLACE_FieldPatField1Only) ||
             ((dwInterlaceFlags & AMINTERLACE_FieldPatternMask) == AMINTERLACE_FieldPatField2Only)))
        {
            bNeedToFlipOddEven = FALSE;
            __leave;
        }

        if (((dwInterlaceFlags & AMINTERLACE_DisplayModeMask) == AMINTERLACE_DisplayModeBobOnly) ||
            (((dwInterlaceFlags & AMINTERLACE_DisplayModeMask) == AMINTERLACE_DisplayModeBobOrWeave) &&
             (!(dwTypeSpecificFlags & AM_VIDEO_FLAG_WEAVE))))
        {
            // first determine which field do we want to display here
            if (dwInterlaceFlags & AMINTERLACE_1FieldPerSample)
            {
                // if we are in 1FieldPerSample mode, check which field is it
                ASSERT(((dwTypeSpecificFlags & AM_VIDEO_FLAG_FIELD_MASK) == AM_VIDEO_FLAG_FIELD1) ||
                    ((dwTypeSpecificFlags & AM_VIDEO_FLAG_FIELD_MASK) == AM_VIDEO_FLAG_FIELD2));
                bDisplayField1 = ((dwTypeSpecificFlags & AM_VIDEO_FLAG_FIELD_MASK) == AM_VIDEO_FLAG_FIELD1);
            }
            else
            {
                // ok the sample is an interleaved frame
                ASSERT((dwTypeSpecificFlags & AM_VIDEO_FLAG_FIELD_MASK) == AM_VIDEO_FLAG_INTERLEAVED_FRAME);
                bDisplayField1 = (dwTypeSpecificFlags & AM_VIDEO_FLAG_FIELD1FIRST);
            }

            bField1IsOdd = (dwInterlaceFlags & AMINTERLACE_Field1First);

            // if we displaying field 1 and field 1 is odd or we are displaying field2 and field 2 is odd
            // then use DDFLIP_ODD. Exactly the opposite for DDFLIP_EVEN
            if ((bDisplayField1 && bField1IsOdd) || (!bDisplayField1 && !bField1IsOdd))
                dwFlipFlag = DDFLIP_ODD;
            else
                dwFlipFlag = DDFLIP_EVEN;

            bNeedToFlipOddEven = TRUE;
        }
    }
    __finally {
        if (pdwFlipFlag) {
            *pdwFlipFlag = dwFlipFlag;
        }
    }

    return bNeedToFlipOddEven;
}

/******************************Public*Routine******************************\
* GetVideoDescFromMT
*
*
*
* History:
* 3/15/2002 - StEstrop - Created
*
\**************************************************************************/
HRESULT
GetVideoDescFromMT(
    LPDXVA_VideoDesc lpVideoDesc,
    const AM_MEDIA_TYPE *pMT
    )
{
    LPBITMAPINFOHEADER lpHdr = GetbmiHeader(pMT);
    DXVA_VideoDesc& VideoDesc = *lpVideoDesc;

    //
    // we can't create a valid VideoDesc from RGB content.
    //
    if (lpHdr->biCompression <= BI_BITFIELDS) {
        return E_FAIL;
    }

    VideoDesc.Size = sizeof(DXVA_VideoDesc);
    VideoDesc.SampleWidth = abs(lpHdr->biWidth);
    VideoDesc.SampleHeight = abs(lpHdr->biHeight);


    //
    // determine the sample format from the interlace flags
    // the MT interlace flags are a total disater!
    //

    if (pMT->formattype == FORMAT_VideoInfo)
    {
        VideoDesc.SampleFormat = DXVA_SampleProgressiveFrame;
    }
    else if (pMT->formattype == FORMAT_VideoInfo2)
    {
        DWORD& dwInterlaceFlags =
            ((VIDEOINFOHEADER2*)(pMT->pbFormat))->dwInterlaceFlags;

        if (dwInterlaceFlags & AMINTERLACE_IsInterlaced) {

            if (dwInterlaceFlags & AMINTERLACE_1FieldPerSample) {

                if (dwInterlaceFlags & AMINTERLACE_Field1First) {
                    VideoDesc.SampleFormat= DXVA_SampleFieldSingleEven;
                }
                else {
                    VideoDesc.SampleFormat= DXVA_SampleFieldSingleOdd;
                }
            }
            else {

                if (dwInterlaceFlags & AMINTERLACE_Field1First) {
                    VideoDesc.SampleFormat= DXVA_SampleFieldInterleavedEvenFirst;
                }
                else {
                    VideoDesc.SampleFormat= DXVA_SampleFieldInterleavedOddFirst;
                }
            }
        }
        else {
            VideoDesc.SampleFormat = DXVA_SampleProgressiveFrame;
        }
    }


    VideoDesc.d3dFormat = lpHdr->biCompression;

    //
    // Work out the frame rate from AvgTimePerFrame - there are 10,000,000
    // ref time ticks in a single second.
    //
    DWORD rtAvg = (DWORD)GetAvgTimePerFrame(pMT);

    //
    // look for the "interesting" cases ie 23.97, 24, 25, 29.97, 50 and 59.94
    //
    switch (rtAvg) {
    case 166833:    // 59.94    NTSC
        VideoDesc.InputSampleFreq.Numerator   = 60000;
        VideoDesc.InputSampleFreq.Denominator = 1001;
        break;

    case 200000:    // 50.00    PAL
        VideoDesc.InputSampleFreq.Numerator   = 50;
        VideoDesc.InputSampleFreq.Denominator = 1;
        break;

    case 333667:    // 29.97    NTSC
        VideoDesc.InputSampleFreq.Numerator   = 30000;
        VideoDesc.InputSampleFreq.Denominator = 1001;
        break;

    case 400000:    // 25.00    PAL
        VideoDesc.InputSampleFreq.Numerator   = 25;
        VideoDesc.InputSampleFreq.Denominator = 1;
        break;

    case 416667:    // 24.00    FILM
        VideoDesc.InputSampleFreq.Numerator   = 24;
        VideoDesc.InputSampleFreq.Denominator = 1;
        break;

    case 417188:    // 23.97    NTSC again
        VideoDesc.InputSampleFreq.Numerator   = 24000;
        VideoDesc.InputSampleFreq.Denominator = 1001;
        break;

    default:
        VideoDesc.InputSampleFreq.Numerator   = 10000000;
        VideoDesc.InputSampleFreq.Denominator = rtAvg;
        break;
    }


    if (VideoDesc.SampleFormat == DXVA_SampleFieldInterleavedEvenFirst ||
        VideoDesc.SampleFormat == DXVA_SampleFieldInterleavedOddFirst) {

        VideoDesc.OutputFrameFreq.Numerator   =
            2 * VideoDesc.InputSampleFreq.Numerator;
    }
    else {
        VideoDesc.OutputFrameFreq.Numerator   =
            VideoDesc.InputSampleFreq.Numerator;
    }
    VideoDesc.OutputFrameFreq.Denominator =
        VideoDesc.InputSampleFreq.Denominator;

    return S_OK;
}

/******************************Public*Routine******************************\
* IsSingleFieldPerSample
*
*
*
* History:
* Wed 03/20/2002 - StEstrop - Created
*
\**************************************************************************/
BOOL
IsSingleFieldPerSample(
    DWORD dwFlags
    )
{
    const DWORD dwSingleField =
                (AMINTERLACE_IsInterlaced | AMINTERLACE_1FieldPerSample);

    return (dwSingleField == (dwSingleField & dwFlags));
}

/******************************Public*Routine******************************\
* GetAvgTimePerFrame
*
*
*
* History:
* Tue 03/26/2002 - StEstrop - Created
*
\**************************************************************************/
REFERENCE_TIME
GetAvgTimePerFrame(
    const AM_MEDIA_TYPE *pMT
    )
{
    if (pMT->formattype == FORMAT_VideoInfo)
    {
        VIDEOINFOHEADER* pVIH = (VIDEOINFOHEADER*)pMT->pbFormat;
        return pVIH->AvgTimePerFrame;

    }
    else if (pMT->formattype == FORMAT_VideoInfo2)
    {
        VIDEOINFOHEADER2* pVIH2 = (VIDEOINFOHEADER2*)pMT->pbFormat;
        return pVIH2->AvgTimePerFrame;

    }
    return (REFERENCE_TIME)0;
}


/******************************Public*Routine******************************\
* MapPool
*
*
*
* History:
* Wed 03/27/2002 - StEstrop - Created
*
\**************************************************************************/
DWORD
MapPool(
    DWORD Pool
    )
{
    switch (Pool) {
    case D3DPOOL_DEFAULT:
    case D3DPOOL_LOCALVIDMEM:
        Pool = DDSCAPS_VIDEOMEMORY | DDSCAPS_LOCALVIDMEM | DDSCAPS_OFFSCREENPLAIN;
        break;

    case D3DPOOL_NONLOCALVIDMEM:
        Pool = DDSCAPS_VIDEOMEMORY | DDSCAPS_NONLOCALVIDMEM | DDSCAPS_OFFSCREENPLAIN;
        break;

    case D3DPOOL_MANAGED:
    case D3DPOOL_SYSTEMMEM:
    case D3DPOOL_SCRATCH:
    default:
        Pool = DDSCAPS_OFFSCREENPLAIN | DDSCAPS_SYSTEMMEMORY;
        break;
    }

    return Pool;
}

/******************************Public*Routine******************************\
* MapInterlaceFlags
*
*
*
* History:
* Tue 03/26/2002 - StEstrop - Created
*
\**************************************************************************/
DXVA_SampleFormat
MapInterlaceFlags(
    DWORD dwInterlaceFlags,
    DWORD dwTypeSpecificFlags
    )
{
    if (!(dwInterlaceFlags & AMINTERLACE_IsInterlaced)) {
        return DXVA_SampleProgressiveFrame;
    }

    BOOL bDisplayField1;

    if (((dwInterlaceFlags & AMINTERLACE_DisplayModeMask) == AMINTERLACE_DisplayModeBobOnly) ||
        (((dwInterlaceFlags & AMINTERLACE_DisplayModeMask) == AMINTERLACE_DisplayModeBobOrWeave) &&
         (!(dwTypeSpecificFlags & AM_VIDEO_FLAG_WEAVE))))
    {
        // first determine which field do we want to display here
        if (dwInterlaceFlags & AMINTERLACE_1FieldPerSample)
        {
            // if we are in 1FieldPerSample mode, check which field is it
            ASSERT(((dwTypeSpecificFlags & AM_VIDEO_FLAG_FIELD_MASK) == AM_VIDEO_FLAG_FIELD1) ||
                ((dwTypeSpecificFlags & AM_VIDEO_FLAG_FIELD_MASK) == AM_VIDEO_FLAG_FIELD2));
            bDisplayField1 = ((dwTypeSpecificFlags & AM_VIDEO_FLAG_FIELD_MASK) == AM_VIDEO_FLAG_FIELD1);
            if (bDisplayField1) {
                return DXVA_SampleFieldSingleEven;
            }
            else {
                return DXVA_SampleFieldSingleOdd;
            }
        }
        else
        {
            // ok the sample is an interleaved frame
            ASSERT((dwTypeSpecificFlags & AM_VIDEO_FLAG_FIELD_MASK) == AM_VIDEO_FLAG_INTERLEAVED_FRAME);
            bDisplayField1 = (dwTypeSpecificFlags & AM_VIDEO_FLAG_FIELD1FIRST);
            if (bDisplayField1) {
                return DXVA_SampleFieldInterleavedEvenFirst;
            }
            else {
                return DXVA_SampleFieldInterleavedOddFirst;
            }
        }
    }
    return DXVA_SampleProgressiveFrame;
}
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\multimedia\dshow\filters\image2\ap\apmon.cpp ===
/******************************Module*Header*******************************\
* Module Name: apmon.cpp
*
* Monitor configuration support.
*
*
* Created: Tue 09/19/2000
* Author:  Stephen Estrop [StEstrop]
*
* Copyright (c) 2000 Microsoft Corporation
\**************************************************************************/
#include <streams.h>
#include <dvdmedia.h>
#include <windowsx.h>
#include <limits.h>
#include <malloc.h>


#include <atlconv.h>
#ifdef FILTER_DLL
LPWSTR WINAPI AtlA2WHelper(LPWSTR lpw, LPCSTR lpa, int nChars)
{
        ASSERT(lpa != NULL);
        ASSERT(lpw != NULL);
        // verify that no illegal character present
        // since lpw was allocated based on the size of lpa
        // don't worry about the number of chars
        lpw[0] = '\0';
        MultiByteToWideChar(CP_ACP, 0, lpa, -1, lpw, nChars);
        return lpw;
}

LPSTR WINAPI AtlW2AHelper(LPSTR lpa, LPCWSTR lpw, int nChars)
{
        ASSERT(lpw != NULL);
        ASSERT(lpa != NULL);
        // verify that no illegal character present
        // since lpa was allocated based on the size of lpw
        // don't worry about the number of chars
        lpa[0] = '\0';
        WideCharToMultiByte(CP_ACP, 0, lpw, -1, lpa, nChars, NULL, NULL);
        return lpa;
}
#endif

#include "apobj.h"
#include "AllocLib.h"
#include "MediaSType.h"
#include "vmrp.h"

extern "C"
const TCHAR chRegistryKey[] = TEXT("Software\\Microsoft\\Multimedia\\")
                              TEXT("ActiveMovie Filters\\Video Mixing Renderer");
const TCHAR szDDrawGUID[] = TEXT("DDraw Connection Device GUID");

/*****************************Private*Routine******************************\
* SetRegistryString
*
*
*
* History:
* Wed 08/18/1999 - StEstrop - Created
*
\**************************************************************************/
HRESULT
SetRegistryString(
    HKEY hk,
    const TCHAR* pKey,
    const TCHAR* szString
    )
{
    HKEY hKey;
    LONG lRet;

    lRet = RegCreateKey(hk, chRegistryKey, &hKey);
    if (lRet == ERROR_SUCCESS) {

        lRet = RegSetValueEx(hKey, pKey, 0L, REG_SZ,
                             (LPBYTE)szString,
                             sizeof(TCHAR) * lstrlen(szString));
        RegCloseKey(hKey);
    }

    if (lRet == ERROR_SUCCESS) {
        return S_OK;
    }

    return AmHresultFromWin32(lRet);
}


/*****************************Private*Routine******************************\
* GetRegistryString
*
*
*
* History:
* Wed 08/18/1999 - StEstrop - Created
*
\**************************************************************************/
HRESULT
GetRegistryString(
    HKEY hk,
    const TCHAR* pKey,
    TCHAR* szString,
    PLONG lpLength
    )
{
    HKEY hKey;
    LONG lRet;

    lRet = RegOpenKeyEx(hk, chRegistryKey, 0, KEY_QUERY_VALUE, &hKey);
    if (lRet == ERROR_SUCCESS) {

        DWORD dwType;
        lRet = RegQueryValueEx(hKey, pKey, 0L, &dwType,
                               (LPBYTE)szString, (LPDWORD)lpLength);
        RegCloseKey(hKey);
    }

    if (lRet == ERROR_SUCCESS) {
        return S_OK;
    }

    return AmHresultFromWin32(lRet);
}

/******************************Public*Routine******************************\
* SetMonitor
*
*
*
* History:
* Tue 04/25/2000 - GlennE - Created
*
\**************************************************************************/
STDMETHODIMP
CAllocatorPresenter::SetMonitor(
    const VMRGUID *pGUID
    )
{
    AMTRACE((TEXT("CAllocatorPresenter::SetMonitor")));
    // TBD: Check that we aren't already using a DDraw device
    //if (m_pDirectDraw) {
    //    return VFW_E_ALREADY_CONNECTED;
    //}

    if (ISBADREADPTR(pGUID)) {
        DbgLog((LOG_ERROR, 1, TEXT("Invalid pointer")));
        return E_POINTER;
    }

    if (pGUID->pGUID) {
        if (!IsEqualGUID(pGUID->GUID, *pGUID->pGUID)) {
            return E_INVALIDARG;
        }
    }

    CAutoLock Lock(&m_ObjectLock);
    DWORD dwMatchID;

    HRESULT hr = m_monitors.MatchGUID(pGUID->pGUID, &dwMatchID);
    if (hr == S_FALSE) {
        return E_INVALIDARG;
    }

    m_lpCurrMon = &m_monitors[dwMatchID];

    if (pGUID->pGUID) {
        m_ConnectionGUID.pGUID = &m_ConnectionGUID.GUID;
        m_ConnectionGUID.GUID = pGUID->GUID;
    } else {
        m_ConnectionGUID.pGUID = NULL;
        m_ConnectionGUID.GUID = GUID_NULL;
    }

    return S_OK;
}

/******************************Public*Routine******************************\
* GetMonitor
*
*
*
* History:
* Tue 04/25/2000 - GlennE - Created
*
\**************************************************************************/
STDMETHODIMP
CAllocatorPresenter::GetMonitor(
    VMRGUID *pGUID
    )
{
    AMTRACE((TEXT("CAllocatorPresenter::GetMonitor")));
    CAutoLock Lock(&m_ObjectLock);
    if (ISBADWRITEPTR(pGUID))
    {
        DbgLog((LOG_ERROR, 1, TEXT("Invalid pointer")));
        return E_POINTER;
    }

    // copy GUID and return S_OK;
    *pGUID = m_ConnectionGUID;

    return S_OK;
}

/******************************Public*Routine******************************\
* SetDefaultMonitor
*
*
*
* History:
* Tue 04/25/2000 - GlennE - Created
*
\**************************************************************************/
STDMETHODIMP
CAllocatorPresenter::SetDefaultMonitor(
    const VMRGUID *pGUID
    )
{
    AMTRACE((TEXT("CAllocatorPresenter::SetDefaultMonitor")));
    CAutoLock Lock(&m_ObjectLock);

    if (ISBADREADPTR(pGUID))
    {
        DbgLog((LOG_ERROR, 1, TEXT("Invalid pointer")));
        return E_POINTER;
    }

    if (pGUID->pGUID) {
        if (!IsEqualGUID(pGUID->GUID, *pGUID->pGUID)) {
            return E_INVALIDARG;
        }
    }

    // match the supplied GUID with those DDraw devices available
    DWORD dwMatchID;
    HRESULT hr = m_monitors.MatchGUID(pGUID->pGUID, &dwMatchID);

    // if match not found return E_INVALIDARG
    if (hr == S_FALSE) {
        return E_INVALIDARG;
    }

    // if the caller is trying to make the default device the NULL
    // DDraw device, just delete the registry key.
    if (pGUID->pGUID == NULL) {

        HKEY hKey;
        LONG lRet = RegOpenKeyEx(HKEY_LOCAL_MACHINE,
                                 chRegistryKey, 0,
                                 KEY_SET_VALUE, &hKey);

        if (lRet == ERROR_FILE_NOT_FOUND) {
            lRet = ERROR_SUCCESS;
        }
        else if (lRet == ERROR_SUCCESS) {

            lRet = RegDeleteValue(hKey, szDDrawGUID);
            if (lRet == ERROR_FILE_NOT_FOUND) {
                lRet = ERROR_SUCCESS;
            }
            RegCloseKey(hKey);
        }

        if (lRet == ERROR_SUCCESS)
            return S_OK;

        return AmHresultFromWin32(lRet);
    }

    // convert GUID into string
    LPOLESTR lpsz;
    hr = StringFromCLSID(pGUID->GUID, &lpsz);
    if (FAILED(hr)) {
        return hr;
    }

    // write the string into the registry
    USES_CONVERSION;
    hr = SetRegistryString(HKEY_LOCAL_MACHINE, szDDrawGUID, OLE2T(lpsz));

    CoTaskMemFree(lpsz);

    return hr;
}

/******************************Public*Routine******************************\
* GetDefaultMonitor
*
*
*
* History:
* Tue 04/25/2000 - GlennE - Created
*
\**************************************************************************/
STDMETHODIMP
CAllocatorPresenter::GetDefaultMonitor(
    VMRGUID *pGUID
    )
{
    AMTRACE((TEXT("CAllocatorPresenter::GetDefaultMonitor")));
    CAutoLock Lock(&m_ObjectLock);
    if (ISBADWRITEPTR(pGUID)) {
        DbgLog((LOG_ERROR, 1, TEXT("Invalid pointer")));
        return E_POINTER;
    }

    // read string from the registry
    TCHAR   szGUID[64];
    LONG    lLen = 64;
    HRESULT hr = GetRegistryString(HKEY_LOCAL_MACHINE, szDDrawGUID,
                                   szGUID, &lLen);

    // if string not in registry return the default (NULL) DDraw device
    if (FAILED(hr)) {
        pGUID->pGUID = NULL;
        return S_OK;
    }

    // convert string into GUID and return
    pGUID->pGUID = &pGUID->GUID;

    USES_CONVERSION;
    hr = IIDFromString(T2OLE(szGUID), pGUID->pGUID);

    return hr;
}

/******************************Public*Routine******************************\
* GetAvailableMonitors
*
* Allocates and returns an array of VMRMONITORINFO structures, one for
* for each direct draw device attached to a display monitor.
*
*
* History:
* Tue 04/25/2000 - GlennE - Created
*
\**************************************************************************/
STDMETHODIMP
CAllocatorPresenter::GetAvailableMonitors(
    VMRMONITORINFO* pInfo,
    DWORD dwMaxInfoArraySize,
    DWORD* pdwNumDevices
    )
{
    AMTRACE((TEXT("CAllocatorPresenter::GetAvailableMonitors")));
    CAutoLock Lock(&m_ObjectLock);

    if (ISBADWRITEPTR(pdwNumDevices)) {

        DbgLog((LOG_ERROR, 1, TEXT("Invalid pointer")));
        return E_POINTER;
    }

    if (pInfo) {

        if (0 == dwMaxInfoArraySize) {
            DbgLog((LOG_ERROR, 1, TEXT("Invalid array size of 0")));
            return E_INVALIDARG;
        }

        if (ISBADWRITEARRAY( pInfo, dwMaxInfoArraySize)) {
            DbgLog((LOG_ERROR, 1, TEXT("Invalid pointer")));
            return E_POINTER;
        }
    }
    else {

        // they just want the count
        *pdwNumDevices = m_monitors.Count();
        return S_OK;
    }

    *pdwNumDevices = min(dwMaxInfoArraySize, m_monitors.Count());

    // copy the VRMMONITORINFO portion of each monitor info block
    for (DWORD i = 0; i < *pdwNumDevices; i++)  {

        pInfo[i] = m_monitors[i];

        DDDEVICEIDENTIFIER2 did;
        if (DD_OK == m_monitors[i].pDD->GetDeviceIdentifier(&did, 0)) {

            pInfo[i].liDriverVersion = did.liDriverVersion;
            pInfo[i].dwVendorId = did.dwVendorId;
            pInfo[i].dwDeviceId = did.dwDeviceId;
            pInfo[i].dwSubSysId = did.dwSubSysId;
            pInfo[i].dwRevision = did.dwRevision;
        }
    }

    return S_OK;
}
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\multimedia\dshow\filters\image2\ap\apcurrimg.cpp ===
/******************************Module*Header*******************************\
* Module Name: apCurrImg.cpp
*
* Collection of functions dedicated to retrieve the currently displayed image.
*
* Created: Sat 10/14/2000
* Author:  Stephen Estrop [StEstrop]
*
* Copyright (c) 2000 Microsoft Corporation
\**************************************************************************/
#include <streams.h>
#include <dvdmedia.h>
#include <windowsx.h>
#include <limits.h>
#include <malloc.h>

#include "apobj.h"
#include "AllocLib.h"
#include "MediaSType.h"
#include "vmrp.h"



/*****************************Private*Routine******************************\
* CopyRGBSurfToDIB
*
*
*
* History:
* Sat 10/14/2000 - StEstrop - Created
*
\**************************************************************************/
HRESULT
CAllocatorPresenter::CopyRGBSurfToDIB(
    LPBYTE* lpDib,
    LPDIRECTDRAWSURFACE7 lpRGBSurf
    )
{
    HRESULT hr = E_FAIL;
    LPBITMAPINFOHEADER lpbih = NULL;
    DDSURFACEDESC2 ddsd = {sizeof(ddsd)};

    __try {

        CHECK_HR(hr = lpRGBSurf->GetSurfaceDesc(&ddsd));

        ULONG ulBits = ddsd.dwWidth * ddsd.ddpfPixelFormat.dwRGBBitCount;
        ULONG ulStrideSrc = WIDTHBYTES(ulBits);

        ULONG ulStrideDst = ddsd.dwWidth * 4;
        ULONG ulSize = sizeof(BITMAPINFOHEADER) +
                        (ulStrideDst * ddsd.dwHeight);

        lpbih = (LPBITMAPINFOHEADER)CoTaskMemAlloc(ulSize);
        if (lpbih == NULL) {
            hr = E_OUTOFMEMORY;
            __leave;
        }

        lpbih->biSize = sizeof(BITMAPINFOHEADER);
        lpbih->biWidth = (LONG)ddsd.dwWidth;
        lpbih->biHeight = (LONG)ddsd.dwHeight;
        lpbih->biPlanes = 1;
        lpbih->biBitCount = 32;
        lpbih->biCompression = BI_RGB;
        lpbih->biSizeImage = ulStrideDst * ddsd.dwHeight;
        lpbih->biXPelsPerMeter = 0;
        lpbih->biYPelsPerMeter = 0;
        lpbih->biClrUsed = 0;
        lpbih->biClrImportant = 0;

        LPBYTE lpSrc;
        LPDWORD lpdwDst = ((LPDWORD)((LPBYTE)(lpbih) + (int)(lpbih)->biSize));

        //
        // We want an upside down DIB so offset the start of the
        // dst pointer to the last scan line.
        //
        lpdwDst += ((ddsd.dwHeight - 1) * ddsd.dwWidth);

        CHECK_HR(hr = lpRGBSurf->Lock(NULL, &ddsd, DDLOCK_NOSYSLOCK, NULL));

        switch (ddsd.ddpfPixelFormat.dwRGBBitCount) {
        case 32:
            lpSrc = (LPBYTE)ddsd.lpSurface;
            for (DWORD y = 0; y < ddsd.dwHeight; y++) {

                CopyMemory(lpdwDst, lpSrc, ddsd.dwWidth * 4);

                lpdwDst -= ddsd.dwWidth;
                lpSrc += ddsd.lPitch;
            }
            break;


        case 24:
            lpSrc = (LPBYTE)ddsd.lpSurface;
            for (DWORD y = 0; y < ddsd.dwHeight; y++) {

                LPBYTE lpSrcTmp = lpSrc;
                LPBYTE lpDstTmp = (LPBYTE)lpdwDst;

                for (DWORD x = 0; x < ddsd.dwWidth; x++) {

                    *lpDstTmp++ = *lpSrcTmp++;
                    *lpDstTmp++ = *lpSrcTmp++;
                    *lpDstTmp++ = *lpSrcTmp++;
                    *lpDstTmp++ = 0; // This is the alpha byte
                }

                lpdwDst -= ddsd.dwWidth;
                lpSrc += ddsd.lPitch;
            }
            break;


        case 16:
            if (ddsd.ddpfPixelFormat.dwGBitMask == 0x7E0) {

                // 5:6:5
                lpSrc = (LPBYTE)ddsd.lpSurface;
                for (DWORD y = 0; y < ddsd.dwHeight; y++) {

                    LPBYTE lpSrcTmp = (LPBYTE)lpSrc;
                    RGBQUAD dw = {0, 0, 0, 0};

                    for (DWORD x = 0; x < ddsd.dwWidth; x++) {

                        WORD w = MAKEWORD(lpSrcTmp[0], lpSrcTmp[1]);
                        lpSrcTmp += 2;

                        dw.rgbRed   = ((w & 0xF800) >>  8);
                        dw.rgbGreen = ((w & 0x07E0) >>  3);
                        dw.rgbBlue  = ((w & 0x001F) <<  3);


                        lpdwDst[x] = *((LPDWORD)&dw);
                    }

                    lpdwDst -= ddsd.dwWidth;
                    lpSrc += ddsd.lPitch;
                }
            }
            else {

                // 5:5:5
                lpSrc = (LPBYTE)ddsd.lpSurface;
                for (DWORD y = 0; y < ddsd.dwHeight; y++) {

                    LPBYTE lpSrcTmp = (LPBYTE)lpSrc;
                    RGBQUAD dw = {0, 0, 0, 0};

                    for (DWORD x = 0; x < ddsd.dwWidth; x++) {

                        WORD w = MAKEWORD(lpSrcTmp[0], lpSrcTmp[1]);
                        lpSrcTmp += 2;

                        dw.rgbRed   = ((w & 0x7C00) >>  7);
                        dw.rgbGreen = ((w & 0x03E0) >>  2);
                        dw.rgbBlue  = ((w & 0x001F) <<  3);

                        lpdwDst[x] = *((LPDWORD)&dw);
                    }

                    lpdwDst -= ddsd.dwWidth;
                    lpSrc += ddsd.lPitch;
                }
            }
            break;
        }

        CHECK_HR(hr = lpRGBSurf->Unlock(NULL));
    }
    __finally {

        if (hr != DD_OK) {
            CoTaskMemFree(lpbih);
            lpbih = NULL;
        }

        *lpDib = (LPBYTE)lpbih;
    }

    return hr;
}


/*****************************Private*Routine******************************\
* Clamp
*
* Converts a floating point number to a byte value clamping to range 0-255.
*
* History:
* Tue 01/02/2001 - StEstrop - Created
*
\**************************************************************************/
__inline BYTE Clamp(float clr)
{
    clr += 0.5f;

    if (clr < 0.0f) {
        return (BYTE)0;
    }

    if (clr > 255.0f) {
        return (BYTE)255;
    }

    return (BYTE)clr;
}


/*****************************Private*Routine******************************\
* ConvertYCrCbToRGB
*
* This equation was taken from Video Demystified (2nd Edition)
* by Keith Jack, page 43.
*
*
* History:
* Tue 01/02/2001 - StEstrop - Created
*
\**************************************************************************/
__inline RGBQUAD
ConvertYCrCbToRGB(
    int y,
    int cr,
    int cb
    )
{
    RGBQUAD rgbq;

    float r = (1.1644f * (y-16)) + (1.5960f * (cr-128));
    float g = (1.1644f * (y-16)) - (0.8150f * (cr-128)) - (0.3912f * (cb-128));
    float b = (1.1644f * (y-16))                        + (2.0140f * (cb-128));


    rgbq.rgbBlue  = Clamp(b);
    rgbq.rgbGreen = Clamp(g);
    rgbq.rgbRed   = Clamp(r);
    rgbq.rgbReserved = 0; // Alpha

    return rgbq;
}


/*****************************Private*Routine******************************\
* CopyIMCXSurf
*
*
*
* History:
* Sat 10/14/2000 - StEstrop - Created
*
\**************************************************************************/
HRESULT
CAllocatorPresenter::CopyIMCXSurf(
    LPDIRECTDRAWSURFACE7 lpRGBSurf,
    BOOL fInterleavedCbCr,
    BOOL fCbFirst
    )
{
    HRESULT hr;
    DWORD y, x;

    DDSURFACEDESC2 ddsdS = {sizeof(ddsdS)};
    DDSURFACEDESC2 ddsdT = {sizeof(ddsdT)};

    hr = m_pDDSDecode->Lock(NULL, &ddsdS, DDLOCK_NOSYSLOCK, NULL);
    if (hr != DD_OK) {
        return hr;
    }

    hr = lpRGBSurf->Lock(NULL, &ddsdT, DDLOCK_NOSYSLOCK, NULL);
    if (hr != DD_OK) {
        m_pDDSDecode->Unlock(NULL);
        return hr;
    }

    LPBYTE lpBitsY = (LPBYTE)ddsdS.lpSurface;
    LPBYTE lpBitsCb;
    LPBYTE lpBitsCr;

    if (fInterleavedCbCr) {

        if (fCbFirst) {
            lpBitsCb = lpBitsY  + (ddsdS.dwHeight * ddsdS.lPitch);
            lpBitsCr = lpBitsCb + (ddsdS.lPitch / 2);
        }
        else {
            lpBitsCr = lpBitsY  + (ddsdS.dwHeight * ddsdS.lPitch);
            lpBitsCb = lpBitsCr + (ddsdS.lPitch / 2);
        }
    }
    else {
        if (fCbFirst) {
            lpBitsCb = lpBitsY  +  (ddsdS.dwHeight * ddsdS.lPitch);
            lpBitsCr = lpBitsCb + ((ddsdS.dwHeight * ddsdS.lPitch) / 2);
        }
        else {
            lpBitsCr = lpBitsY  +  (ddsdS.dwHeight * ddsdS.lPitch);
            lpBitsCb = lpBitsCr + ((ddsdS.dwHeight * ddsdS.lPitch) / 2);
        }
    }


    LONG   lStrideCbCr = ddsdS.lPitch;
    LPBYTE lpDibBits = (LPBYTE)(LPBYTE)ddsdT.lpSurface;

    for (y = 0; y < ddsdS.dwHeight; y += 2) {

        LPBYTE lpLineY1 = lpBitsY;
        LPBYTE lpLineY2 = lpBitsY + ddsdS.lPitch;
        LPBYTE lpLineCr = lpBitsCr;
        LPBYTE lpLineCb = lpBitsCb;

        LPBYTE lpDibLine1 = lpDibBits;
        LPBYTE lpDibLine2 = lpDibBits + ddsdT.lPitch;

        for (x = 0; x < ddsdS.dwWidth; x += 2) {

            int  y0 = (int)lpLineY1[0];
            int  y1 = (int)lpLineY1[1];
            int  y2 = (int)lpLineY2[0];
            int  y3 = (int)lpLineY2[1];
            int  cb = (int)lpLineCb[0];
            int  cr = (int)lpLineCr[0];

            RGBQUAD r = ConvertYCrCbToRGB(y0, cr, cb);
            lpDibLine1[0] = r.rgbBlue;
            lpDibLine1[1] = r.rgbGreen;
            lpDibLine1[2] = r.rgbRed;
            lpDibLine1[3] = 0; // Alpha


            r = ConvertYCrCbToRGB(y1, cr, cb);
            lpDibLine1[4] = r.rgbBlue;
            lpDibLine1[5] = r.rgbGreen;
            lpDibLine1[6] = r.rgbRed;
            lpDibLine1[7] = 0; // Alpha


            r = ConvertYCrCbToRGB(y2, cr, cb);
            lpDibLine2[0] = r.rgbBlue;
            lpDibLine2[1] = r.rgbGreen;
            lpDibLine2[2] = r.rgbRed;
            lpDibLine2[3] = 0; // Alpha

            r = ConvertYCrCbToRGB(y3, cr, cb);
            lpDibLine2[4] = r.rgbBlue;
            lpDibLine2[5] = r.rgbGreen;
            lpDibLine2[6] = r.rgbRed;
            lpDibLine2[7] = 0; // Alpha

            lpLineY1 += 2;
            lpLineY2 += 2;
            lpLineCr += 1;
            lpLineCb += 1;

            lpDibLine1 += 8;
            lpDibLine2 += 8;
        }

        lpDibBits += (2 * ddsdT.lPitch);
        lpBitsY   += (2 * ddsdS.lPitch);
        lpBitsCr  += lStrideCbCr;
        lpBitsCb  += lStrideCbCr;
    }

    lpRGBSurf->Unlock(NULL);
    m_pDDSDecode->Unlock(NULL);

    return S_OK;
}


/*****************************Private*Routine******************************\
* CopyYV12Surf
*
*
*
* History:
* Sat 10/14/2000 - StEstrop - Created
*
\**************************************************************************/
HRESULT
CAllocatorPresenter::CopyYV12Surf(
    LPDIRECTDRAWSURFACE7 lpRGBSurf,
    BOOL fInterleavedCbCr,
    BOOL fCbFirst
    )
{
    HRESULT hr;
    DWORD y, x;

    DDSURFACEDESC2 ddsdS = {sizeof(ddsdS)};
    DDSURFACEDESC2 ddsdT = {sizeof(ddsdT)};

    hr = m_pDDSDecode->Lock(NULL, &ddsdS, DDLOCK_NOSYSLOCK, NULL);
    if (hr != DD_OK) {
        return hr;
    }

    hr = lpRGBSurf->Lock(NULL, &ddsdT, DDLOCK_NOSYSLOCK, NULL);
    if (hr != DD_OK) {
        m_pDDSDecode->Unlock(NULL);
        return hr;
    }

    LPBYTE lpBitsY = (LPBYTE)ddsdS.lpSurface;
    LPBYTE lpBitsCr;
    LPBYTE lpBitsCb;
    int    iCbCrInc;
    LONG   lStrideCbCr;

    if (fInterleavedCbCr) {

        lStrideCbCr = ddsdS.lPitch;
        iCbCrInc = 2;
        if (fCbFirst) {
            // NV12
            lpBitsCb = lpBitsY  +  (ddsdS.dwHeight * ddsdS.lPitch);
            lpBitsCr = lpBitsCb + 1;
        }
        else {
            // NV21
            lpBitsCr = lpBitsY  +  (ddsdS.dwHeight * ddsdS.lPitch);
            lpBitsCb = lpBitsCr + 1;
        }
    }
    else {

        lStrideCbCr = ddsdS.lPitch / 2;
        iCbCrInc = 1;

        if (fCbFirst) {
            // IYUV
            lpBitsCb = lpBitsY  +  (ddsdS.dwHeight * ddsdS.lPitch);
            lpBitsCr = lpBitsCb + ((ddsdS.dwHeight * ddsdS.lPitch) / 4);
        }
        else {
            // YV12
            lpBitsCr = lpBitsY  +  (ddsdS.dwHeight * ddsdS.lPitch);
            lpBitsCb = lpBitsCr + ((ddsdS.dwHeight * ddsdS.lPitch) / 4);
        }
    }


    LPBYTE lpDibBits = (LPBYTE)(LPBYTE)ddsdT.lpSurface;

    for (y = 0; y < ddsdS.dwHeight; y += 2) {

        LPBYTE lpLineY1 = lpBitsY;
        LPBYTE lpLineY2 = lpBitsY + ddsdS.lPitch;
        LPBYTE lpLineCr = lpBitsCr;
        LPBYTE lpLineCb = lpBitsCb;

        LPBYTE lpDibLine1 = lpDibBits;
        LPBYTE lpDibLine2 = lpDibBits + ddsdT.lPitch;

        for (x = 0; x < ddsdS.dwWidth; x += 2) {

            int  y0 = (int)lpLineY1[0];
            int  y1 = (int)lpLineY1[1];
            int  y2 = (int)lpLineY2[0];
            int  y3 = (int)lpLineY2[1];
            int  cb = (int)lpLineCb[0];
            int  cr = (int)lpLineCr[0];

            RGBQUAD r = ConvertYCrCbToRGB(y0, cr, cb);
            lpDibLine1[0] = r.rgbBlue;
            lpDibLine1[1] = r.rgbGreen;
            lpDibLine1[2] = r.rgbRed;
            lpDibLine1[3] = 0; // Alpha


            r = ConvertYCrCbToRGB(y1, cr, cb);
            lpDibLine1[4] = r.rgbBlue;
            lpDibLine1[5] = r.rgbGreen;
            lpDibLine1[6] = r.rgbRed;
            lpDibLine1[7] = 0; // Alpha


            r = ConvertYCrCbToRGB(y2, cr, cb);
            lpDibLine2[0] = r.rgbBlue;
            lpDibLine2[1] = r.rgbGreen;
            lpDibLine2[2] = r.rgbRed;
            lpDibLine2[3] = 0; // Alpha

            r = ConvertYCrCbToRGB(y3, cr, cb);
            lpDibLine2[4] = r.rgbBlue;
            lpDibLine2[5] = r.rgbGreen;
            lpDibLine2[6] = r.rgbRed;
            lpDibLine2[7] = 0; // Alpha

            lpLineY1 += 2;
            lpLineY2 += 2;
            lpLineCr += iCbCrInc;
            lpLineCb += iCbCrInc;

            lpDibLine1 += 8;
            lpDibLine2 += 8;
        }

        lpDibBits += (2 * ddsdT.lPitch);
        lpBitsY   += (2 * ddsdS.lPitch);
        lpBitsCr  += lStrideCbCr;
        lpBitsCb  += lStrideCbCr;
    }

    lpRGBSurf->Unlock(NULL);
    m_pDDSDecode->Unlock(NULL);

    return S_OK;
}



/*****************************Private*Routine******************************\
* CopyYUY2Surf
*
*
*
* History:
* Sat 10/14/2000 - StEstrop - Created
*
\**************************************************************************/
HRESULT
CAllocatorPresenter::CopyYUY2Surf(
    LPDIRECTDRAWSURFACE7 lpRGBSurf
    )
{
    HRESULT hr;
    DWORD y, x;

    DDSURFACEDESC2 ddsdS = {sizeof(ddsdS)};
    DDSURFACEDESC2 ddsdT = {sizeof(ddsdT)};

    hr = m_pDDSDecode->Lock(NULL, &ddsdS, DDLOCK_NOSYSLOCK, NULL);
    if (hr != DD_OK) {
        return hr;
    }

    hr = lpRGBSurf->Lock(NULL, &ddsdT, DDLOCK_NOSYSLOCK, NULL);
    if (hr != DD_OK) {
        m_pDDSDecode->Unlock(NULL);
        return hr;
    }

    LPBYTE lpBits = (LPBYTE)ddsdS.lpSurface;
    LPBYTE lpLine;

    LPBYTE lpDibLine = (LPBYTE)(LPBYTE)ddsdT.lpSurface;
    LPBYTE lpDib;

    for (y = 0; y < ddsdS.dwHeight; y++) {

        lpLine = lpBits;
        lpDib = lpDibLine;

        for (x = 0; x < ddsdS.dwWidth; x += 2) {

            int  y0 = (int)lpLine[0];
            int  cb = (int)lpLine[1];
            int  y1 = (int)lpLine[2];
            int  cr = (int)lpLine[3];

            RGBQUAD r = ConvertYCrCbToRGB(y0, cr, cb);
            lpDib[0] = r.rgbBlue;
            lpDib[1] = r.rgbGreen;
            lpDib[2] = r.rgbRed;
            lpDib[3] = 0; // Alpha


            r = ConvertYCrCbToRGB(y1, cr, cb);
            lpDib[4] = r.rgbBlue;
            lpDib[5] = r.rgbGreen;
            lpDib[6] = r.rgbRed;
            lpDib[7] = 0; // Alpha

            lpLine += 4;
            lpDib  += 8;
        }

        lpBits    += ddsdS.lPitch;
        lpDibLine += ddsdT.lPitch;
    }

    lpRGBSurf->Unlock(NULL);
    m_pDDSDecode->Unlock(NULL);

    return S_OK;
}



/*****************************Private*Routine******************************\
* CopyUYVYSurf
*
*
*
* History:
* Sat 10/14/2000 - StEstrop - Created
*
\**************************************************************************/
HRESULT
CAllocatorPresenter::CopyUYVYSurf(
    LPDIRECTDRAWSURFACE7 lpRGBSurf
    )
{
    HRESULT hr;
    DWORD y, x;

    DDSURFACEDESC2 ddsdS = {sizeof(ddsdS)};
    DDSURFACEDESC2 ddsdT = {sizeof(ddsdT)};

    hr = m_pDDSDecode->Lock(NULL, &ddsdS, DDLOCK_NOSYSLOCK, NULL);
    if (hr != DD_OK) {
        return hr;
    }

    hr = lpRGBSurf->Lock(NULL, &ddsdT, DDLOCK_NOSYSLOCK, NULL);
    if (hr != DD_OK) {
        m_pDDSDecode->Unlock(NULL);
        return hr;
    }

    LPBYTE lpBits = (LPBYTE)ddsdS.lpSurface;
    LPBYTE lpLine;

    LPBYTE lpDibLine = (LPBYTE)(LPBYTE)ddsdT.lpSurface;
    LPBYTE lpDib;

    for (y = 0; y < ddsdS.dwHeight; y++) {

        lpLine = lpBits;
        lpDib = lpDibLine;

        for (x = 0; x < ddsdS.dwWidth; x += 2) {

            int  cb = (int)lpLine[0];
            int  y0 = (int)lpLine[1];
            int  cr = (int)lpLine[2];
            int  y1 = (int)lpLine[3];

            RGBQUAD r = ConvertYCrCbToRGB(y0, cr, cb);
            lpDib[0] = r.rgbBlue;
            lpDib[1] = r.rgbGreen;
            lpDib[2] = r.rgbRed;
            lpDib[3] = 0; // Alpha


            r = ConvertYCrCbToRGB(y1, cr, cb);
            lpDib[4] = r.rgbBlue;
            lpDib[5] = r.rgbGreen;
            lpDib[6] = r.rgbRed;
            lpDib[7] = 0; // Alpha

            lpLine += 4;
            lpDib  += 8;
        }

        lpBits    += ddsdS.lPitch;
        lpDibLine += ddsdT.lPitch;
    }

    lpRGBSurf->Unlock(NULL);
    m_pDDSDecode->Unlock(NULL);

    return S_OK;
}



/*****************************Private*Routine******************************\
* CreateRGBShadowSurface
*
*
* History:
* Mon 08/02/1999 - StEstrop - Created
*
\**************************************************************************/
HRESULT
CAllocatorPresenter::CreateRGBShadowSurface(
    LPDIRECTDRAWSURFACE7* lplpDDS,
    DWORD dwBitsPerPel,
    BOOL fSysMem,
    DWORD dwWidth,
    DWORD dwHeight
    )
{
    AMTRACE((TEXT("CAllocatorPresenter::CreateRGBShadowSurface")));

    DDSURFACEDESC2 ddsd;
    INITDDSTRUCT(ddsd);

    ddsd.ddpfPixelFormat.dwSize = sizeof(DDPIXELFORMAT);
    switch (dwBitsPerPel) {
    case 0:
        {
            DDSURFACEDESC2 ddsdP;
            INITDDSTRUCT(ddsdP);
            HRESULT hRet = m_lpCurrMon->pDDSPrimary->GetSurfaceDesc(&ddsdP);
            if (hRet != DD_OK) {
                return hRet;
            }
            ddsd.ddpfPixelFormat = ddsdP.ddpfPixelFormat;
        }
        break;

    case 32:
        ddsd.ddpfPixelFormat.dwRGBBitCount = 32;
        ddsd.ddpfPixelFormat.dwFlags = DDPF_RGB;
        ddsd.ddpfPixelFormat.dwRBitMask = 0x00FF0000;
        ddsd.ddpfPixelFormat.dwGBitMask = 0x0000FF00;
        ddsd.ddpfPixelFormat.dwBBitMask = 0x000000FF;
        break;

    case 24:
        ddsd.ddpfPixelFormat.dwRGBBitCount = 24;
        ddsd.ddpfPixelFormat.dwFlags = DDPF_RGB;
        ddsd.ddpfPixelFormat.dwRBitMask = 0x00FF0000;
        ddsd.ddpfPixelFormat.dwGBitMask = 0x00000FF0;
        ddsd.ddpfPixelFormat.dwBBitMask = 0x000000FF;
        break;

    case 16:
        ddsd.ddpfPixelFormat.dwRGBBitCount = 16;
        ddsd.ddpfPixelFormat.dwFlags = DDPF_RGB;
        ddsd.ddpfPixelFormat.dwRBitMask = 0xF800;
        ddsd.ddpfPixelFormat.dwGBitMask = 0x07e0;
        ddsd.ddpfPixelFormat.dwBBitMask = 0x001F;
        break;
    }

    if (fSysMem) {
        ddsd.ddsCaps.dwCaps = DDSCAPS_SYSTEMMEMORY | DDSCAPS_OFFSCREENPLAIN;
    }
    else {
        ddsd.ddsCaps.dwCaps = DDSCAPS_VIDEOMEMORY | DDSCAPS_LOCALVIDMEM |
                              DDSCAPS_OFFSCREENPLAIN;
    }

    ddsd.dwFlags = DDSD_CAPS | DDSD_HEIGHT | DDSD_WIDTH | DDSD_PIXELFORMAT;
    ddsd.dwWidth = dwWidth;
    ddsd.dwHeight = dwHeight;

    // Attempt to create the surface with theses settings
    return m_lpCurrMon->pDD->CreateSurface(&ddsd, lplpDDS, NULL);
}




/*****************************Private*Routine******************************\
* HandleYUVSurface
*
* Copies the current YUV image into a shadow RGB system memory surface.
* The RGB shadow surface can be in either video or system memory.
*
* History:
* Tue 12/26/2000 - StEstrop - Created
*
\**************************************************************************/
HRESULT
CAllocatorPresenter::HandleYUVSurface(
    const DDSURFACEDESC2& ddsd,
    LPDIRECTDRAWSURFACE7* lplpRGBSurf
    )
{
    HRESULT hr = DD_OK;
    LPDIRECTDRAWSURFACE7 lpRGBSurf = NULL;

    *lplpRGBSurf = NULL;

    if (((ddsd.ddsCaps.dwCaps & DDSCAPS_OVERLAY) != DDSCAPS_OVERLAY) &&
        (m_lpCurrMon->ddHWCaps.dwCaps & DDCAPS_BLTFOURCC)) {

        //
        // Try to allocate an RGB shadow surface, in the array
        // below 0 means use the RGB format of the monitor
        //

        const DWORD dwNumBits = 4;
        const DWORD dwBits[dwNumBits] = {32,24,16,0};

        for (const DWORD* lpBits = dwBits;
             lpBits < &dwBits[dwNumBits]; lpBits++) {

            hr = CreateRGBShadowSurface(&lpRGBSurf, *lpBits,
                                        FALSE,
                                        m_VideoSizeAct.cx,
                                        m_VideoSizeAct.cy);
            if (hr == DD_OK) {

                RECT r = {0, 0, m_VideoSizeAct.cx, m_VideoSizeAct.cy};

                hr = lpRGBSurf->Blt(&r, m_pDDSDecode,
                                    &r, DDBLT_WAIT, NULL);

                if (hr == DD_OK) {
                    *lplpRGBSurf = lpRGBSurf;
                    return hr;
                }
                else {
                    RELEASE(lpRGBSurf);
                }
            }
        }
    }

    //
    // Still here - this must be a low-end graphics card or a poorly
    // featured driver.  We are using a YUV surface but we
    // can't perform a color space converting blt or we
    // have run out of video memory.
    //

    hr = CreateRGBShadowSurface(&lpRGBSurf, 32, TRUE,
                                m_VideoSizeAct.cx,
                                m_VideoSizeAct.cy);
    if (hr == DD_OK) {

        switch (ddsd.ddpfPixelFormat.dwFourCC) {

        case mmioFOURCC('I','M','C','1'):
            hr = CopyIMCXSurf(lpRGBSurf, FALSE, FALSE);
            break;

        case mmioFOURCC('I','M','C','2'):
            hr = CopyIMCXSurf(lpRGBSurf, TRUE, FALSE);
            break;

        case mmioFOURCC('I','M','C','3'):
            hr = CopyIMCXSurf(lpRGBSurf, FALSE, TRUE);
            break;

        case mmioFOURCC('I','M','C','4'):
            hr = CopyIMCXSurf(lpRGBSurf, TRUE, TRUE);
            break;

        case mmioFOURCC('Y','V','1','2'):
            hr = CopyYV12Surf(lpRGBSurf, FALSE, FALSE);
            break;

        case mmioFOURCC('I','Y','U','V'):
            hr = CopyYV12Surf(lpRGBSurf, FALSE, TRUE);
            break;

        case mmioFOURCC('N','V','1','2'):
            hr = CopyYV12Surf(lpRGBSurf, TRUE, TRUE);
            break;

        case mmioFOURCC('N','V','2','1'):
            hr = CopyYV12Surf(lpRGBSurf, TRUE, FALSE);
            break;

        case mmioFOURCC('Y','U','Y','2'):
            hr = CopyYUY2Surf(lpRGBSurf);
            break;

        case mmioFOURCC('U','Y','V','Y'):
            hr = CopyUYVYSurf(lpRGBSurf);
            break;

        default:
            hr = E_FAIL;
            break;
        }

        if (hr == DD_OK) {
            *lplpRGBSurf = lpRGBSurf;
        }
        else {
            RELEASE(lpRGBSurf);
        }
    }

    return hr;
}



/******************************Public*Routine******************************\
* GetCurrentImage
*
*
*
* History:
* Fri 06/23/2000 - StEstrop - Created
*
\**************************************************************************/
STDMETHODIMP
CAllocatorPresenter::GetCurrentImage(
    BYTE** lpDib
    )
{
    AMTRACE((TEXT("CAllocatorPresenter::GetCurrentImage")));
    CAutoLock Lock(&m_ObjectLock);

    if (ISBADWRITEPTR(lpDib)) {
        DbgLog((LOG_ERROR, 1, TEXT("GetCurrentImage: Bad pointer")));
        return E_POINTER;
    }

    if (!m_lpCurrMon ||
        !m_lpCurrMon->pDDSPrimary ||
        !SurfaceAllocated())
    {
        DbgLog((LOG_ERROR, 1,
                TEXT("GetCurrentImage: Display system not initialized")));
        return E_FAIL;
    }

    *lpDib = NULL;
    HRESULT hr = E_FAIL;
    DDSURFACEDESC2 ddsd = {sizeof(ddsd)};
    LPDIRECTDRAWSURFACE7 lpRGBSurf = NULL;

    __try {

        CHECK_HR(hr = m_pDDSDecode->GetSurfaceDesc(&ddsd));

        if (ddsd.ddpfPixelFormat.dwFlags & DDPF_FOURCC) {

            CHECK_HR(hr = HandleYUVSurface(ddsd, &lpRGBSurf));
        }
        else {

            lpRGBSurf = m_pDDSDecode;
            lpRGBSurf->AddRef();
        }

        CHECK_HR(hr = CopyRGBSurfToDIB(lpDib, lpRGBSurf));

    }
    __finally {

        RELEASE(lpRGBSurf);
    }

    return hr;
}
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\multimedia\dshow\filters\image2\ap\apobj.cpp ===
/******************************Module*Header*******************************\
* Module Name: APObj.cpp
*
*
*
*
* Created: Mon 01/24/2000
* Author:  Stephen Estrop [StEstrop]
*
* Copyright (c) 2000 Microsoft Corporation
\**************************************************************************/
#include <streams.h>
#include <dvdmedia.h>
#include <windowsx.h>
#include <limits.h>
#include <malloc.h>

#include "apobj.h"
#include "AllocLib.h"
#include "MediaSType.h"
#include "vmrp.h"


/*****************************Private*Routine******************************\
* StretchCapsOK
*
*
*
* History:
* Tue 06/05/2001 - StEstrop - Created
*
\**************************************************************************/
BOOL
StretchCapsOK(
    DDCAPS_DX7* lpCaps,
    BOOL fRGB
    )
{
    BOOL fBltOk = TRUE;
    DWORD dwCaps = 0;
    const DWORD dwFXCaps =  DDFXCAPS_BLTSHRINKX | DDFXCAPS_BLTSHRINKX  |
                            DDFXCAPS_BLTSTRETCHX | DDFXCAPS_BLTSTRETCHY;

    if (fRGB) {
        dwCaps = DDCAPS_BLTSTRETCH;
    }
    else {
        dwCaps = (DDCAPS_BLTFOURCC | DDCAPS_BLTSTRETCH);
    }

   fBltOk &= ((dwCaps   & lpCaps->dwCaps)   == dwCaps);
   fBltOk &= ((dwFXCaps & lpCaps->dwFXCaps) == dwFXCaps);


   return fBltOk;
}


/******************************Private*Routine******************************\
* ClipRectPair
*
* Clip a destination rectangle & update the scaled source accordingly
*
*
* History:
* Fri 04/07/2000 - GlennE - Created
*
\**************************************************************************/
void
CAllocatorPresenter::ClipRectPair(
    RECT& rdSrc,
    RECT& rdDest,
    const RECT& rdDestWith
    )
{
    AMTRACE((TEXT("CAllocatorPresenter::ClipRectPair")));

    // figure out src/dest scale ratios
    int iSrcWidth  = WIDTH(&rdSrc);
    int iSrcHeight = HEIGHT(&rdSrc);

    int iDestWidth  = WIDTH(&rdDest);
    int iDestHeight = HEIGHT(&rdDest);

    // clip destination (and adjust the source when we change the destination)

    // see if we have to clip horizontally
    if( iDestWidth ) {
        if( rdDestWith.left > rdDest.left ) {
            int iDelta = rdDestWith.left - rdDest.left;
            rdDest.left += iDelta;
            int iDeltaSrc = MulDiv(iDelta, iSrcWidth, iDestWidth);
            rdSrc.left += iDeltaSrc;
        }

        if( rdDestWith.right < rdDest.right ) {
            int iDelta = rdDest.right-rdDestWith.right;
            rdDest.right -= iDelta;
            int iDeltaSrc = MulDiv(iDelta, iSrcWidth, iDestWidth);
            rdSrc.right -= iDeltaSrc;
        }
    }
    // see if we have to clip vertically
    if( iDestHeight ) {
        if( rdDestWith.top > rdDest.top ) {
            int iDelta = rdDestWith.top - rdDest.top;
            rdDest.top += iDelta;
            int iDeltaSrc = MulDiv(iDelta, iSrcHeight, iDestHeight );
            rdSrc.top += iDeltaSrc;
        }

        if( rdDestWith.bottom < rdDest.bottom ) {
            int iDelta = rdDest.bottom-rdDestWith.bottom;
            rdDest.bottom -= iDelta;
            int iDeltaSrc = MulDiv(iDelta, iSrcHeight, iDestHeight );
            rdSrc.bottom -= iDeltaSrc;
        }
    }
}




/******************************Local*Routine******************************\
* DDColorMatchOffscreen
*
* convert a RGB color to a pysical color.
* we do this by leting GDI SetPixel() do the color matching
* then we lock the memory and see what it got mapped to.
*
* Static function since only called from MapColorToMonitor
*
* History:
* Fri 04/07/2000 - GlennE - Created
*
\**************************************************************************/
DWORD
DDColorMatchOffscreen(
    IDirectDraw7 *pdd,
    COLORREF rgb,
    HRESULT& hr
    )
{
    AMTRACE((TEXT("DDColorMatchOffscreen")));
    DDSURFACEDESC2 ddsd;

    INITDDSTRUCT(ddsd);
    ddsd.dwFlags = DDSD_CAPS | DDSD_HEIGHT | DDSD_WIDTH;
    ddsd.ddsCaps.dwCaps = DDSCAPS_OFFSCREENPLAIN;
    ddsd.dwWidth = 16;
    ddsd.dwHeight = 16;

    IDirectDrawSurface7* pdds;
    hr = pdd->CreateSurface(&ddsd, &pdds, NULL);
    if (hr != DD_OK) {
        return 0;
    }

    DWORD dw = DDColorMatch( pdds, rgb, hr);
    pdds->Release();
    return dw;
}


/******************************Private*Routine******************************\
* MapColorToMonitor
*
*
*
* History:
* Wed 04/05/2000 - GlennE - Created
*
\**************************************************************************/
DWORD
CAllocatorPresenter::MapColorToMonitor(
    CAMDDrawMonitorInfo& monitor,
    COLORREF clr
    )
{
    AMTRACE((TEXT("CAllocatorPresenter::MapColorToMonitor")));
    DWORD dwColor = CLR_INVALID;
    if( monitor.pDD ) {
        HRESULT hr;
        dwColor = DDColorMatchOffscreen(monitor.pDD, clr, hr);
    } else {
        DbgLog((LOG_ERROR, 1, TEXT("can't map color!")));
    }

    return dwColor;
}


/*****************************Private*Routine******************************\
* UpdateRectangles
*
* Updates m_rcDstDesktop and m_rcSrcVideo according to the current m_rcDstApp,
* m_rcSrcApp and m_dwARMode mode values.
*
* Returns a mask identifying any size or position changes that have occurred.
* This info can be used to determine if UpdateOverlay needs to be called or
* if a WM_PAINT message needs to be generated.  If no new rectangle parameters
* passed in the function just remaps the current SRC and DST rectangles into
* movie and desktop co-ordinates respectively and then determines if any
* movement or resizing has taken place.  This function is called when apps
* call SetVideoPosition and each time GetNextSurface and PresentImage is
* called.
*
* History:
* Mon 05/01/2000 - StEstrop - Created
*
\**************************************************************************/
DWORD
CAllocatorPresenter::UpdateRectangles(
    LPRECT lprcNewSrc,
    LPRECT lprcNewDst
    )
{
    AMTRACE((TEXT("CAllocatorPresenter::UpdateRectangles")));
    DWORD dwRetFlags = UR_NOCHANGE;

    RECT rcSrc = m_rcSrcApp;
    if (lprcNewSrc) {
        m_rcSrcApp = *lprcNewSrc;
    }

    if (lprcNewDst) {
        m_rcDstApp = *lprcNewDst;
    }

    //
    // Process the destination rectangle
    //

    m_rcDstDskIncl = m_rcDstApp;
    MapWindowRect(m_hwndClip, HWND_DESKTOP, &m_rcDstDskIncl);

    RECT rcDst;
    if (m_dwARMode == VMR_ARMODE_LETTER_BOX) {

        SIZE im = {WIDTH(&m_rcSrcApp), HEIGHT(&m_rcSrcApp)};
        AspectRatioCorrectSize(&im, m_ARSize);

        RECT Src = {0, 0, im.cx, im.cy};
        LetterBoxDstRect(&rcDst, Src, m_rcDstApp, &m_rcBdrTL, &m_rcBdrBR);
    }
    else {
        rcDst = m_rcDstApp;
    }
    MapWindowRect(m_hwndClip, HWND_DESKTOP, &rcDst);

    if (!EqualSizeRect(&m_rcDstDesktop, &rcDst)){

        dwRetFlags |= UR_SIZE;
    }

    if (!EqualRect(&m_rcDstDesktop, &rcDst)) {
        dwRetFlags |= UR_MOVE;
    }

    m_rcDstDesktop = rcDst;


    //
    // Process the source rectangle - for now don't make any adjustments
    //

    if (!EqualSizeRect(&m_rcSrcApp, &rcSrc)) {
        dwRetFlags |= UR_SIZE;
    }

    if (!EqualRect(&m_rcSrcApp, &rcSrc)) {
        dwRetFlags |= UR_MOVE;
    }

    return dwRetFlags;
}



/////////////////////////////////////////////////////////////////////////////
// CAllocatorPresenter
//
/////////////////////////////////////////////////////////////////////////////

/******************************Public*Routine******************************\
* CAllocatorPresenter::PrepareSurface
*
*
*
* History:
* Tue 01/11/2000 - StEstrop - Created
*
\**************************************************************************/
STDMETHODIMP
CAllocatorPresenter::PrepareSurface(
    DWORD_PTR dwUserID,
    LPDIRECTDRAWSURFACE7 lpSample,
    DWORD dwSampleFlags
    )
{
    AMTRACE((TEXT("CAllocatorPresenter::PrepareSurface")));
    CAutoLock Lock(&m_ObjectLock);

    if (!lpSample) {
        DbgLog((LOG_ERROR, 1, TEXT("PrepareSurface: lpSample is NULL!!")));
        return E_POINTER;
    }

    if (!m_lpCurrMon) {
        DbgLog((LOG_ERROR, 1,
                TEXT("PrepareSurface: Don't have a current monitor")));
        return E_FAIL;
    }

    if (!SurfaceAllocated()) {

        if (MonitorChangeInProgress()) {

            DbgLog((LOG_ERROR, 1,
                    TEXT("PrepareSurface: Backbuffer is NULL ")
                    TEXT("during monitor change")));
        }
        else {

            // Need something better here
            DbgLog((LOG_ERROR, 1,
                    TEXT("PrepareSurface: Backbuffer surface is NULL!!")));
        }

        return E_FAIL;
    }

    //
    // Have we moved onto a different monitor ?
    //

    CAMDDrawMonitorInfo* lpNewMon;
    if (IsDestRectOnWrongMonitor(&lpNewMon)) {

        DbgLog((LOG_TRACE, 1,
                TEXT("Moved to new monitor %s"), lpNewMon->szDevice));

        //
        // tell the DShow filter about the monitor change and
        // then return S_FALSE to the mixer component.
        //

        if (m_lpNewMon != lpNewMon) {
            if (m_pSurfAllocatorNotify) {
                m_pSurfAllocatorNotify->ChangeDDrawDevice(lpNewMon->pDD,
                                                          lpNewMon->hMon);
            }

            m_lpNewMon = lpNewMon;
        }

        return S_FALSE;

    }

    ASSERT(SurfaceAllocated());

    //
    // if deocoder needs the last frame, copy it from the visible surface
    // to the back buffer
    //
    HRESULT hr = S_OK;
    if (dwSampleFlags & AM_GBF_NOTASYNCPOINT) {

        hr = lpSample->Blt(NULL, m_pDDSDecode,
                           NULL, DDBLT_WAIT, NULL);

        if (hr == E_NOTIMPL) {
            hr = VMRCopyFourCC(lpSample, m_pDDSDecode);
        }
    }

    return hr;
}


/******************************Public*Routine******************************\
* AllocateSurface
*
*
*
* History:
* Fri 02/18/2000 - StEstrop - Created
*
\**************************************************************************/
STDMETHODIMP
CAllocatorPresenter::AllocateSurface(
    DWORD_PTR dwUserID,
    VMRALLOCATIONINFO* lpAllocInfo,
    DWORD* lpdwBuffer,
    LPDIRECTDRAWSURFACE7* lplpSurface
    )
{
    AMTRACE((TEXT("CAllocatorPresenter::AllocateSurface")));
    CAutoLock Lock(&m_ObjectLock);
    HRESULT hr;

    if (ISBADREADPTR(lpAllocInfo)) {
        DbgLog((LOG_ERROR, 1, TEXT("Invalid VMRALLOCATIONINFO pointer")));
        return E_POINTER;
    }

    DWORD dwFlags               = lpAllocInfo->dwFlags;
    LPBITMAPINFOHEADER lpHdr    = lpAllocInfo->lpHdr;
    LPDDPIXELFORMAT lpPixFmt    = lpAllocInfo->lpPixFmt;
    LPSIZE lpAspectRatio        = &lpAllocInfo->szAspectRatio;
    DWORD dwMinBuffers          = lpAllocInfo->dwMinBuffers;
    DWORD dwMaxBuffers          = lpAllocInfo->dwMaxBuffers;

    if (ISBADREADPTR(lpHdr)) {
        DbgLog((LOG_ERROR, 1, TEXT("Invalid BITMAPINFOHEADER pointer")));
        return E_POINTER;
    }

    const DWORD AMAP_INVALID_FLAGS = ~(AMAP_PIXELFORMAT_VALID | AMAP_3D_TARGET |
                                       AMAP_ALLOW_SYSMEM | AMAP_FORCE_SYSMEM |
                                       AMAP_DIRECTED_FLIP | AMAP_DXVA_TARGET);

    if (dwFlags & AMAP_INVALID_FLAGS) {
        DbgLog((LOG_ERROR, 1, TEXT("Invalid flags")));
        return E_INVALIDARG;
    }

    const DWORD AMAP_SYSMEM_FLAGS = (AMAP_ALLOW_SYSMEM | AMAP_FORCE_SYSMEM);
    if (AMAP_SYSMEM_FLAGS == (dwFlags & AMAP_SYSMEM_FLAGS)) {
        DbgLog((LOG_ERROR, 1,
                TEXT("AMAP_ALLOW_SYSMEM can't be used with AMAP_FORCE_SYSMEM);")));
        return E_INVALIDARG;
    }

    if (ISBADREADPTR(lpAspectRatio)) {
        DbgLog((LOG_ERROR, 1, TEXT("Invalid aspect ratio pointer")));
        return E_POINTER;
    }

    if (ISBADWRITEPTR(lplpSurface)) {
        DbgLog((LOG_ERROR, 1, TEXT("Invalid LPDIRECTDRAWSURFACE7 pointer")));
        return E_POINTER;
    }

    if (ISBADREADWRITEPTR(lpdwBuffer)) {
        DbgLog((LOG_ERROR, 1, TEXT("Invalid DWORD buffer pointer")));
        return E_POINTER;
    }

    if (dwMinBuffers == 0 || dwMaxBuffers == 0) {
        DbgLog((LOG_ERROR, 1, TEXT("Invalid (min or max) buffer value")));
        return E_INVALIDARG;
    }

    if (dwMinBuffers > dwMaxBuffers) {
        DbgLog((LOG_ERROR, 1, TEXT("Min buffer value greater than max")));
        return E_INVALIDARG;
    }

    if (dwMaxBuffers > MAX_ALLOWED_BUFFER) {
        DbgLog((LOG_ERROR, 1, TEXT("Can't allocate more than %d buffers"),
                MAX_ALLOWED_BUFFER ));
        return E_INVALIDARG;
    }

    if (dwFlags & AMAP_PIXELFORMAT_VALID) {
        if (ISBADREADPTR(lpPixFmt)) {
            DbgLog((LOG_ERROR, 1, TEXT("Invalid DDPIXELFORMAT pointer")));
            return E_POINTER;
        }
    }
    else {
        lpPixFmt = NULL;
    }


    if (lpAspectRatio->cx < 1 || lpAspectRatio->cy < 1) {
        DbgLog((LOG_ERROR, 1, TEXT("Invalid aspect ratio parameter") ));
        return E_INVALIDARG;
    }

    //
    // Do we have a monitor/display change event in progress ?  If
    // so we need to create the surface using the new DDraw Object and
    // then switch the m_lpCurrMon member variable to the new monitor.
    //

    if (MonitorChangeInProgress()) {
        m_lpCurrMon = m_lpNewMon;
    }

    if (!FoundCurrentMonitor()) {
        return E_FAIL;
    }

    //
    // Make sure the bitmapinfo header is valid and big enough
    //
    VIDEOINFO vi;
    if (dwFlags & AMAP_3D_TARGET) {

        CopyMemory(&vi.bmiHeader, lpHdr, lpHdr->biSize);
        lpHdr = &vi.bmiHeader;

        if (dwFlags & (AMAP_FORCE_SYSMEM | AMAP_ALLOW_SYSMEM)) {
            DbgLog((LOG_ERROR, 1, TEXT("Can't mix 3D target with sysmem flags")));
            return E_INVALIDARG;
        }

        //
        // Are we being asked to use the same format as the current monitor ?
        //
        if (lpHdr->biCompression == BI_RGB && lpHdr->biBitCount == 0) {

            lpHdr->biBitCount = m_lpCurrMon->DispInfo.bmiHeader.biBitCount;
            lpHdr->biCompression = m_lpCurrMon->DispInfo.bmiHeader.biCompression;

            if (lpHdr->biCompression == BI_BITFIELDS) {

                const DWORD *pMonMasks = GetBitMasks(&m_lpCurrMon->DispInfo.bmiHeader);
                DWORD *pBitMasks = (DWORD *)((LPBYTE)lpHdr + lpHdr->biSize);
                pBitMasks[0] = pMonMasks[0];
                pBitMasks[1] = pMonMasks[1];
                pBitMasks[2] = pMonMasks[2];
            }
        }
    }

    hr = AllocateSurfaceWorker(dwFlags, lpHdr, lpPixFmt, lpAspectRatio,
                               dwMinBuffers, dwMaxBuffers,
                               lpdwBuffer, lplpSurface,
                               lpAllocInfo->dwInterlaceFlags,
                               &lpAllocInfo->szNativeSize);

    if (SUCCEEDED(hr)) {

        if (MonitorChangeInProgress()) {
            m_lpNewMon = NULL;
        }

        m_bDirectedFlips = (AMAP_DIRECTED_FLIP == (dwFlags & AMAP_DIRECTED_FLIP));
    }

    return hr;
}


/*****************************Private*Routine******************************\
* TryAllocOverlaySurface
*
*
*
* History:
* Tue 10/03/2000 - StEstrop - Created
*
\**************************************************************************/
HRESULT
CAllocatorPresenter::TryAllocOverlaySurface(
    LPDIRECTDRAWSURFACE7* lplpSurf,
    DWORD dwFlags,
    DDSURFACEDESC2* pddsd,
    DWORD dwMinBuffers,
    DWORD dwMaxBuffers,
    DWORD* lpdwBuffer
    )
{
    HRESULT hr = S_OK;
    LPDIRECTDRAWSURFACE7 lpSurface7 = NULL;

    m_bFlippable = FALSE;

    pddsd->dwFlags = DDSD_CAPS | DDSD_WIDTH | DDSD_HEIGHT |
                     DDSD_PIXELFORMAT | DDSD_BACKBUFFERCOUNT;

    pddsd->ddsCaps.dwCaps = DDSCAPS_VIDEOMEMORY | DDSCAPS_LOCALVIDMEM |
                            DDSCAPS_OVERLAY | DDSCAPS_FLIP | DDSCAPS_COMPLEX;

    if (dwFlags & AMAP_3D_TARGET) {
        pddsd->ddsCaps.dwCaps |= DDSCAPS_3DDEVICE;
    }

    //
    // If we are in DX-VA mode - indicated by the presence of the
    // AMAP_DXVA_TARGET flag - honour the buffer allocation numbers.
    // Otherwise, always add EXTRA_OVERLAY_BUFFERS to allocation.
    //

    DWORD dwMinBuff = dwMinBuffers;
    DWORD dwMaxBuff = dwMaxBuffers;

    if (AMAP_DXVA_TARGET != (dwFlags & AMAP_DXVA_TARGET))
    {
        //dwMinBuff += (EXTRA_OVERLAY_BUFFERS - 1);
        dwMaxBuff +=  EXTRA_OVERLAY_BUFFERS;
    }

    for (DWORD dwTotalBufferCount =  dwMaxBuff;
         dwTotalBufferCount >= dwMinBuff; dwTotalBufferCount--) {

        // CleanUp stuff from the last loop
        RELEASE(lpSurface7);
        m_bUsingOverlays = true;

        pddsd->dwBackBufferCount = dwTotalBufferCount - 1;
        if (dwTotalBufferCount == 1) {
            pddsd->dwFlags &= ~DDSD_BACKBUFFERCOUNT;
            pddsd->ddsCaps.dwCaps &= ~(DDSCAPS_FLIP | DDSCAPS_COMPLEX);
        }

        hr = m_lpCurrMon->pDD->CreateSurface(pddsd, &lpSurface7, NULL);

        if (hr == DD_OK) {

            SetColorKey(m_clrKey);
            hr = CheckOverlayAvailable(lpSurface7);

            if (SUCCEEDED(hr)) {

                DbgLog((LOG_TRACE, 1,
                        TEXT("Overlay Surface is %4.4hs %dx%d, %d bits"),
                        (pddsd->ddpfPixelFormat.dwFlags == DDPF_RGB)
                            ? "RGB "
                            : (LPSTR)&pddsd->ddpfPixelFormat.dwFourCC,
                        pddsd->dwWidth,
                        pddsd->dwHeight,
                        pddsd->ddpfPixelFormat.dwRGBBitCount));

                m_bFlippable = (dwTotalBufferCount > 1);
                *lpdwBuffer = dwTotalBufferCount;

                DbgLog((LOG_TRACE, 1, TEXT("EC_VMR_RENDERDEVICE_SET::VMR_RENDER_DEVICE_OVERLAY")));

                if (m_pSurfAllocatorNotify) {
                    m_pSurfAllocatorNotify->NotifyEvent(
                            EC_VMR_RENDERDEVICE_SET,
                            VMR_RENDER_DEVICE_OVERLAY,
                            0);
                }
                break;
            }
            else {
                RELEASE(lpSurface7);
                m_bUsingOverlays = false;

                DbgLog((LOG_ERROR, 1,
                        TEXT("Overlay is already in use hr = 0x%X"), hr));
            }
        }
        else {
            m_bUsingOverlays = false;
            DbgLog((LOG_ERROR, 1,
                    TEXT("CreateSurface %4.4hs failed in Video memory, ")
                    TEXT("BufferCount = %d, hr = 0x%X"),
                    (pddsd->ddpfPixelFormat.dwFlags == DDPF_RGB)
                        ? "RGB "
                        : (LPSTR)&pddsd->ddpfPixelFormat.dwFourCC,
                    dwTotalBufferCount, hr));
        }
    }

    *lplpSurf = lpSurface7;
    return hr;
}

/*****************************Private*Routine******************************\
* TryAllocOffScrnDXVASurface
*
*
*
* History:
* Tue 10/03/2000 - StEstrop - Created
*
\**************************************************************************/
HRESULT
CAllocatorPresenter::TryAllocOffScrnDXVASurface(
    LPDIRECTDRAWSURFACE7* lplpSurf,
    DWORD dwFlags,
    DDSURFACEDESC2* pddsd,
    DWORD dwMinBuffers,
    DWORD dwMaxBuffers,
    DWORD* lpdwBuffer
    )
{
    HRESULT hr = S_OK;
    LPDIRECTDRAWSURFACE7 lpSurface7 = NULL;

    m_bFlippable = FALSE;

    pddsd->dwFlags = DDSD_CAPS | DDSD_WIDTH | DDSD_HEIGHT |
                     DDSD_PIXELFORMAT | DDSD_BACKBUFFERCOUNT;

    pddsd->ddsCaps.dwCaps = DDSCAPS_VIDEOMEMORY | DDSCAPS_LOCALVIDMEM |
                            DDSCAPS_OFFSCREENPLAIN | DDSCAPS_FLIP |
                            DDSCAPS_COMPLEX;

    if (dwFlags & AMAP_3D_TARGET) {
        pddsd->ddsCaps.dwCaps |= DDSCAPS_3DDEVICE;
    }

    DWORD dwMinBuff = dwMinBuffers;
    DWORD dwMaxBuff = dwMaxBuffers;

    for (DWORD dwTotalBufferCount =  dwMaxBuff;
         dwTotalBufferCount >= dwMinBuff; dwTotalBufferCount--) {

        // CleanUp stuff from the last loop
        RELEASE(lpSurface7);
        pddsd->dwBackBufferCount = dwTotalBufferCount - 1;

        hr = m_lpCurrMon->pDD->CreateSurface(pddsd, &lpSurface7, NULL);

        if (hr == DD_OK) {

            DbgLog((LOG_TRACE, 1,
                    TEXT("DX-VA offscreen surface is %4.4hs %dx%d, %d bits"),
                    (pddsd->ddpfPixelFormat.dwFlags == DDPF_RGB)
                        ? "RGB "
                        : (LPSTR)&pddsd->ddpfPixelFormat.dwFourCC,
                    pddsd->dwWidth,
                    pddsd->dwHeight,
                    pddsd->ddpfPixelFormat.dwRGBBitCount));

            ASSERT(dwTotalBufferCount > 1);
            m_bFlippable = TRUE;
            *lpdwBuffer = dwTotalBufferCount;
            if (m_pSurfAllocatorNotify) {
                DbgLog((LOG_TRACE, 1, TEXT("EC_VMR_RENDERDEVICE_SET::VMR_RENDER_DEVICE_VIDMEM")));
                m_pSurfAllocatorNotify->NotifyEvent(
                        EC_VMR_RENDERDEVICE_SET,
                        VMR_RENDER_DEVICE_VIDMEM,
                        0);
            }
            break;
        }
        else {
            DbgLog((LOG_ERROR, 1,
                    TEXT("CreateSurface %4.4hs failed in Video memory, ")
                    TEXT("BufferCount = %d, hr = 0x%X"),
                    (pddsd->ddpfPixelFormat.dwFlags == DDPF_RGB)
                        ? "RGB "
                        : (LPSTR)&pddsd->ddpfPixelFormat.dwFourCC,
                    dwTotalBufferCount, hr));
        }
    }

    *lplpSurf = lpSurface7;
    return hr;
}


/*****************************Private*Routine******************************\
* TryAllocOffScrnSurface
*
*
*
* History:
* Tue 10/03/2000 - StEstrop - Created
*
\**************************************************************************/
HRESULT
CAllocatorPresenter::TryAllocOffScrnSurface(
    LPDIRECTDRAWSURFACE7* lplpSurf,
    DWORD dwFlags,
    DDSURFACEDESC2* pddsd,
    DWORD dwMinBuffers,
    DWORD dwMaxBuffers,
    DWORD* lpdwBuffer,
    BOOL fAllowBackBuffer
    )
{
    HRESULT hr = S_OK;
    LPDIRECTDRAWSURFACE7 lpSurf7FB = NULL;
    DWORD dwTotalBufferCount = 0;

    ASSERT(*lplpSurf == NULL);

    //
    // Setup the surface descriptor and try to allocate the
    // front buffer.
    //

    *lpdwBuffer = 0;
    pddsd->dwBackBufferCount = 0;
    pddsd->dwFlags = DDSD_CAPS | DDSD_WIDTH | DDSD_HEIGHT | DDSD_PIXELFORMAT;

    if (dwFlags & AMAP_FORCE_SYSMEM) {
        pddsd->ddsCaps.dwCaps = DDSCAPS_OFFSCREENPLAIN | DDSCAPS_SYSTEMMEMORY;
        m_bSysMem = TRUE;
    }
    else {
        pddsd->ddsCaps.dwCaps = DDSCAPS_VIDEOMEMORY | DDSCAPS_LOCALVIDMEM |
                                DDSCAPS_OFFSCREENPLAIN;
        m_bSysMem = FALSE;
    }

    if (dwFlags & AMAP_3D_TARGET) {
        ASSERT(!(dwFlags & AMAP_FORCE_SYSMEM));
        pddsd->ddsCaps.dwCaps |= DDSCAPS_3DDEVICE;
    }

    hr = m_lpCurrMon->pDD->CreateSurface(pddsd, &lpSurf7FB, NULL);

    if (hr != DD_OK) {
        m_bSysMem = FALSE;
        DbgLog((LOG_ERROR, 1,
                TEXT("CreateSurface %4.4hs failed in Video memory, ")
                TEXT("hr = 0x%X"),
                (pddsd->ddpfPixelFormat.dwFlags == DDPF_RGB)
                    ? "RGB " : (LPSTR)&pddsd->ddpfPixelFormat.dwFourCC, hr));
        return hr;
    }

    //
    // Now try to allocate the back buffers
    //

    DbgLog((LOG_TRACE, 1,
            TEXT("OffScreen Surface is %4.4hs %dx%d, %d bits"),
            (pddsd->ddpfPixelFormat.dwFlags == DDPF_RGB)
                ? "RGB "
                : (LPSTR)&pddsd->ddpfPixelFormat.dwFourCC,
            pddsd->dwWidth,
            pddsd->dwHeight,
            pddsd->ddpfPixelFormat.dwRGBBitCount));

    //
    // FORCE_SYSMEM is not used by the VMR - it gets set by people
    // who override the AllocateSurface method "or in" the FORCE_SYSMEM
    // flag and then pass the call onto us.
    //
    // We do not allocate shadow buffers in this case as the app is not
    // aware of their presence and probably does not know what to do with
    // them.
    //

    DWORD dwMinBuff;
    DWORD dwMaxBuff;

    if (fAllowBackBuffer) {

        dwMinBuff = dwMinBuffers + 1;
        dwMaxBuff = dwMaxBuffers + 1;

        if (dwMinBuffers <= EXTRA_OFFSCREEN_BUFFERS + 1) {
            dwMinBuff = dwMinBuffers + EXTRA_OFFSCREEN_BUFFERS;
        }

        if (dwMaxBuffers <= EXTRA_OFFSCREEN_BUFFERS + 1) {
            dwMaxBuff = dwMaxBuffers + EXTRA_OFFSCREEN_BUFFERS;
        }
    }
    else {

        dwMinBuff = dwMinBuffers;
        dwMaxBuff = dwMaxBuffers;
    }

    dwTotalBufferCount = 1;

    __try {

        LPDIRECTDRAWSURFACE7 lpSurf7 = lpSurf7FB;

        for ( ; dwTotalBufferCount < dwMaxBuff; dwTotalBufferCount++) {

            LPDIRECTDRAWSURFACE7 lpSurf7_2 = NULL;
            hr = m_lpCurrMon->pDD->CreateSurface(pddsd, &lpSurf7_2, NULL);
            if (hr != DD_OK)
                __leave;


            LPDIRECTDRAWSURFACE4 lp4FB;
            lpSurf7->QueryInterface(IID_IDirectDrawSurface4, (LPVOID*)&lp4FB);

            LPDIRECTDRAWSURFACE4 lp4BB;
            lpSurf7_2->QueryInterface(IID_IDirectDrawSurface4, (LPVOID*)&lp4BB);

            hr = lp4FB->AddAttachedSurface(lp4BB);

            RELEASE(lp4FB);
            RELEASE(lp4BB);

            lpSurf7 = lpSurf7_2;
            RELEASE(lpSurf7_2);

            if (hr != DD_OK)
                __leave;

            DbgLog((LOG_TRACE, 1,
                    TEXT("Attached OffScreen Surface %4.4hs %dx%d, %d bits"),
                    (pddsd->ddpfPixelFormat.dwFlags == DDPF_RGB)
                        ? "RGB "
                        : (LPSTR)&pddsd->ddpfPixelFormat.dwFourCC,
                    pddsd->dwWidth,
                    pddsd->dwHeight,
                    pddsd->ddpfPixelFormat.dwRGBBitCount));
        }
    }
    __finally {

        if (hr != DD_OK) {

            if (dwTotalBufferCount >= dwMinBuff) {
                hr = DD_OK;
            }
            else {

                DbgLog((LOG_ERROR, 1,
                        TEXT("CreateSurface %4.4hs failed in Video memory, ")
                        TEXT("BufferCount = %d, hr = 0x%X"),
                        (pddsd->ddpfPixelFormat.dwFlags == DDPF_RGB)
                            ? "RGB "
                            : (LPSTR)&pddsd->ddpfPixelFormat.dwFourCC,
                        dwTotalBufferCount, hr));

                m_bSysMem = FALSE;
                dwTotalBufferCount = 0;
                RELEASE(lpSurf7FB);
            }
        }

        if (hr == DD_OK) {

            ASSERT(dwTotalBufferCount >= dwMinBuff);

            *lpdwBuffer = dwTotalBufferCount;
            m_bFlippable = (dwTotalBufferCount > 1);

            DbgLog((LOG_TRACE, 1, TEXT("EC_VMR_RENDERDEVICE_SET::VMR_RENDER_DEVICE_VIDMEM or VMR_RENDER_DEVICE_SYSMEM")));

            if (m_pSurfAllocatorNotify) {
                m_pSurfAllocatorNotify->NotifyEvent(
                        EC_VMR_RENDERDEVICE_SET,
                        (dwFlags & AMAP_FORCE_SYSMEM)
                            ? VMR_RENDER_DEVICE_SYSMEM : VMR_RENDER_DEVICE_VIDMEM,
                        0);
            }
        }
    }

    *lplpSurf = lpSurf7FB;
    return hr;
}


/*****************************Private*Routine******************************\
* AllocateSurfaceWorker
*
*
*
* History:
* Wed 03/08/2000 - StEstrop - Created
*
\**************************************************************************/
HRESULT
CAllocatorPresenter::AllocateSurfaceWorker(
    DWORD dwFlags,
    LPBITMAPINFOHEADER lpHdr,
    LPDDPIXELFORMAT lpPixFmt,
    LPSIZE lpAspectRatio,
    DWORD dwMinBuffers,
    DWORD dwMaxBuffers,
    DWORD* lpdwBuffer,
    LPDIRECTDRAWSURFACE7* lplpSurface,
    DWORD dwInterlaceFlags,
    LPSIZE lpszNativeSize
    )
{
    AMTRACE((TEXT("CAllocatorPresenter::AllocateSampleWorker")));

    if (!lpHdr) {
        DbgLog((LOG_ERROR, 1,
                TEXT("Can't get bitmapinfoheader from media type!!")));
        return E_INVALIDARG;
    }

    ASSERT(!SurfaceAllocated());

    HRESULT hr = E_FAIL;
    LPDIRECTDRAWSURFACE7 lpSurface7 = NULL;

    //
    // Setup the DDSURFACEDESC2 structure - then...
    //
    // if RenderPrefs_ForceOffscreen isn't set try to create an overlay surface
    // the try to allocate 2 back buffers for this surface.
    //
    // if we can't create an overlay surface then try regular offscreen
    // surfaces, but only if RenderPrefs_ForceOverlays isn't set.  When using
    // offscreen surfaces we try to allocate at least 1 back buffer.
    //

    DDSURFACEDESC2 ddsd;
    INITDDSTRUCT(ddsd);

    ddsd.dwWidth = abs(lpHdr->biWidth);
    ddsd.dwHeight = abs(lpHdr->biHeight);

    //
    // define the pixel format
    //

    if (lpPixFmt) {

        ddsd.ddpfPixelFormat = *lpPixFmt;
    }
    else {

        ddsd.ddpfPixelFormat.dwSize = sizeof(DDPIXELFORMAT);

        if (lpHdr->biCompression <= BI_BITFIELDS &&
            m_lpCurrMon->DispInfo.bmiHeader.biBitCount <= lpHdr->biBitCount)
        {
            ddsd.ddpfPixelFormat.dwFourCC = BI_RGB;
            ddsd.ddpfPixelFormat.dwFlags = DDPF_RGB;
            ddsd.ddpfPixelFormat.dwRGBBitCount = lpHdr->biBitCount;

            if (dwFlags & AMAP_3D_TARGET) {
                ddsd.ddsCaps.dwCaps |= DDSCAPS_3DDEVICE;
            }
            // Store the masks in the DDSURFACEDESC
            const DWORD *pBitMasks = GetBitMasks(lpHdr);
            ASSERT(pBitMasks);
            ddsd.ddpfPixelFormat.dwRBitMask = pBitMasks[0];
            ddsd.ddpfPixelFormat.dwGBitMask = pBitMasks[1];
            ddsd.ddpfPixelFormat.dwBBitMask = pBitMasks[2];
        }
        else if (lpHdr->biCompression > BI_BITFIELDS)
        {
            ddsd.ddpfPixelFormat.dwFourCC = lpHdr->biCompression;
            ddsd.ddpfPixelFormat.dwFlags = DDPF_FOURCC;
            ddsd.ddpfPixelFormat.dwYUVBitCount = lpHdr->biBitCount;
        }
        else
        {
            DbgLog((LOG_ERROR, 1, TEXT("Supplied mediatype not suitable ")
                    TEXT("for either YUV or RGB surfaces")));
            return E_FAIL;
        }
    }

    //
    // The VMR (or a plugged in Allocator Presenter) may want us
    // to always use system memory surfaces.  This would be required
    // if for example you wanted GDI to process the video before it
    // was rendered.
    //

    if (dwFlags & AMAP_FORCE_SYSMEM) {

        //
        // We can only allow YUV sysmem surfaces if we can BltFOURCC
        // from them
        //
	if (lpHdr->biCompression > BI_BITFIELDS && !CanBltFourCCSysMem()) {
            return VFW_E_DDRAW_CAPS_NOT_SUITABLE;
	}

        //
        // We can only allow RGB sysmem surfaces that match the
        // current display format.
        //
        if (lpHdr->biCompression <= BI_BITFIELDS &&
            m_lpCurrMon->DispInfo.bmiHeader.biBitCount != lpHdr->biBitCount) {
            return DDERR_INCOMPATIBLEPRIMARY;
        }

        hr = TryAllocOffScrnSurface(&lpSurface7, AMAP_FORCE_SYSMEM, &ddsd,
                                        dwMinBuffers, dwMaxBuffers,
                                        lpdwBuffer, FALSE);
    }
    else {

        //
        //  Now try to create the overlay
        //

        if (!(m_dwRenderingPrefs & RenderPrefs_ForceOffscreen)) {

            hr = TryAllocOverlaySurface(&lpSurface7, dwFlags, &ddsd,
                                        dwMinBuffers, dwMaxBuffers, lpdwBuffer);
        }


        //
        // If we could not create the overlay check to see if we are only allowed
        // to use overlays.  If so, fail the call.
        //
        if ((hr != DD_OK) || (m_dwRenderingPrefs & RenderPrefs_ForceOffscreen)) {

            if (m_dwRenderingPrefs & RenderPrefs_ForceOverlays) {

                DbgLog((LOG_ERROR, 1,
                        TEXT("RenderPrefs_ForceOverlays is set and ")
                        TEXT("failed tp create an overlay hr = 0x%X"), hr));
                return hr;
            }

            //
            // If we are using offscreen surfaces we have to be a little
            // more restrictive with what we try to allocate.  Basically,
            // if we can BLT_STRETCH we don't try to allocate video memory
            // surfaces.
            //
            // We allow creating FOURCC surfaces if we can BLT_FOURCC and
            // BLT_STRETCH.
            //
            // If we are creating an RGB surface then its format must
            // match the that of the display.
            //

            if (lpHdr->biCompression > BI_BITFIELDS) {
                if (!StretchCapsOK(&m_lpCurrMon->ddHWCaps, FALSE)) {
                    DbgLog((LOG_ERROR, 1,
                            TEXT("Can't BLT_FOURCC | BLT_STRETCH!!")));
                    return VFW_E_DDRAW_CAPS_NOT_SUITABLE;
                }
            }
            else {

                LPBITMAPINFOHEADER lpMon = &m_lpCurrMon->DispInfo.bmiHeader;
                if (lpHdr->biBitCount != lpMon->biBitCount) {

                    DbgLog((LOG_ERROR, 1,
                            TEXT("RGB bit count does not match the display")));
                    return DDERR_INCOMPATIBLEPRIMARY;
                }

                //
                // Some decoders get confused about RGB32.  They think
                // that BI_RGB is the correct value to use.  It should be
                // BIT_BITFIELDS - but we will let them off with a error
                // message written to the debugger.
                //
                if (lpHdr->biCompression != lpMon->biCompression) {

                    if (lpHdr->biBitCount != 32) {
                        DbgLog((LOG_ERROR, 1,
                                TEXT("RGB bit field type does not match the display")));
                        return DDERR_INCOMPATIBLEPRIMARY;
                    }
                    else {
                        DbgLog((LOG_ERROR, 1,
                                TEXT("RGB32 should have BI_BITFIELDS set")));
                    }
                }
            }

            //
            // Only allow creating offscreen surfaces in video memory
            // if the VGA can stretch them in h/w.  Otherwise fall thru
            // to system memory surface creation if the caller allows it.
            //
            if (StretchCapsOK(&m_lpCurrMon->ddHWCaps,
                             (lpHdr->biCompression <= BI_BITFIELDS))) {

                if (dwFlags & AMAP_DXVA_TARGET) {
                    hr = TryAllocOffScrnDXVASurface(&lpSurface7, dwFlags, &ddsd,
                                                    dwMinBuffers, dwMaxBuffers,
                                                    lpdwBuffer);
                }
                else {
                    hr = TryAllocOffScrnSurface(&lpSurface7, dwFlags, &ddsd,
                                                dwMinBuffers, dwMaxBuffers,
                                                lpdwBuffer, TRUE);
                }
            }
            else {
                hr = VFW_E_DDRAW_CAPS_NOT_SUITABLE;
            }
        }


        //
        // If we could not create an offscreen video memory surface
        // see if we can get a offscreen system memory surface.
        //
        if ((hr != DD_OK) && (dwFlags & AMAP_ALLOW_SYSMEM)) {

            //
            // We can only allow sysmem surfaces that match the
            // current display format.
            //
            if (lpHdr->biCompression <= BI_BITFIELDS &&
                m_lpCurrMon->DispInfo.bmiHeader.biBitCount == lpHdr->biBitCount) {

                hr = TryAllocOffScrnSurface(&lpSurface7, AMAP_FORCE_SYSMEM, &ddsd,
                                            dwMinBuffers, dwMaxBuffers,
                                            lpdwBuffer, TRUE);
            }
            else {
                hr = VFW_E_DDRAW_CAPS_NOT_SUITABLE;
            }
        }
    }


    if (hr == DD_OK) {

        m_ARSize = *lpAspectRatio;
        m_VideoSizeAct = *lpszNativeSize;

        m_bDecimating = (dwFlags & AMAP_3D_TARGET) &&
                        (m_VideoSizeAct.cx == (2*abs(lpHdr->biWidth))) &&
                        (m_VideoSizeAct.cy == (2*abs(lpHdr->biHeight)));

        m_dwInterlaceFlags = dwInterlaceFlags;
        m_dwUpdateOverlayFlags = GetUpdateOverlayFlags(m_dwInterlaceFlags,
                                                       AM_VIDEO_FLAG_WEAVE);

        if (IsSingleFieldPerSample(m_dwInterlaceFlags)) {
            m_VideoSizeAct.cy *= 2;
        }
        SetRect(&m_rcSrcApp, 0, 0, m_VideoSizeAct.cx, m_VideoSizeAct.cy);

        PaintDDrawSurfaceBlack(lpSurface7);
    }


    *lplpSurface = lpSurface7;
    m_pDDSDecode = lpSurface7;

    return hr;
}


/******************************Public*Routine******************************\
* FreeSurfaces
*
*
*
* History:
* Fri 02/18/2000 - StEstrop - Created
*
\**************************************************************************/
STDMETHODIMP
CAllocatorPresenter::FreeSurface(
    DWORD_PTR dwUserID
    )
{
    AMTRACE((TEXT("CAllocatorPresenter::FreeSurface")));
    CAutoLock Lock(&m_ObjectLock);

    if (m_bUsingOverlays) {
        HideOverlaySurface();
    }

    m_bDirectedFlips = false;
    m_bFlippable = false;
    m_bUsingOverlays = false;
    m_bOverlayVisible = false;
    m_bDisableOverlays = false;
    m_bSysMem = FALSE;
    m_dwInterlaceFlags = 0;

    RELEASE(m_pDDSDecode);

    return S_OK;
}

/*****************************Private*Routine******************************\
* WaitForScanLine()
*
* When using a hardware offscreen draw surface we will normally wait for the
* monitor scan line to move past the destination rectangle before drawing so
* that we avoid tearing where possible. Of course not all display cards can
* support this feature and even those that do will see a performance drop of
* about 10% because we sit polling (oh for a generic PCI monitor interrupt)
*
* History:
* Thu 03/30/2000 - StEstrop - Created
*
\**************************************************************************/
void
CAllocatorPresenter::WaitForScanLine(
    const RECT& rcDst
    )
{
    AMTRACE((TEXT("CAllocatorPresenter::WaitForScanLine")));

    HRESULT hr = NOERROR;
    DWORD dwScanLine;

    if (m_SleepTime == -1) {
        return;
    }

    //
    // Some display cards like the ATI Mach64 support reporting of the scan
    // line they are processing. However not all drivers are setting the
    // DDCAPS_READSCANLINE capability flag so we just go ahead and ask for
    // it anyway. We allow for 10 scan lines above the top of our rectangle
    // so that we have a little time to thunk down and set the draw call up
    //

    #define SCANLINEFUDGE 10
    for ( ;; ) {

        hr = m_lpCurrMon->pDD->GetScanLine(&dwScanLine);
        if (FAILED(hr)) {
            DbgLog((LOG_TRACE, 3, TEXT("No scan line")));
            break;
        }

        NOTE1("Scan line returned %lx",dwScanLine);

        if ((LONG)dwScanLine + SCANLINEFUDGE >= rcDst.top) {
            if ((LONG) dwScanLine <= rcDst.bottom) {
                DbgLog((LOG_TRACE, 3, TEXT("Scan inside")));
                if (m_SleepTime >= 0) {
                    Sleep(m_SleepTime);
                }
                continue;
            }
        }

        break;
    }
}

/******************************Public*Routine******************************\
* SetXlcModeDDObjAndPrimarySurface
*
*
*
* History:
* Wed 04/04/2001 - StEstrop - Created
*
\**************************************************************************/
STDMETHODIMP
CAllocatorPresenter::SetXlcModeDDObjAndPrimarySurface(
    LPDIRECTDRAW7 lpDD,
    LPDIRECTDRAWSURFACE7 lpPS
    )
{
    AMTRACE((TEXT("CAllocatorPresenter::SetXlcModeDDObjAndPrimarySurface")));
    CAutoLock Lock(&m_ObjectLock);

    if (!m_fDDXclMode) {
        return E_NOTIMPL;
    }

    if (lpDD == NULL) {
        DbgLog((LOG_ERROR, 1, TEXT("NULL DDraw device") ));
        return E_POINTER;
    }

    if (lpPS == NULL) {
        DbgLog((LOG_ERROR, 1, TEXT("NULL Primary Surface") ));
        return E_POINTER;
    }

    m_monitors.TerminateDisplaySystem();

    m_lpNewMon = NULL;
    m_lpCurrMon = NULL;

    HRESULT hr = m_monitors.InitializeXclModeDisplaySystem(m_hwndClip, lpDD, lpPS);
    if (SUCCEEDED(hr)) {
        VMRGUID guid;
        ZeroMemory(&guid, sizeof(guid));
        hr = SetMonitor(&guid);
    }
    return hr;
}

/******************************Public*Routine******************************\
* GetXlcModeDDObjAndPrimarySurface
*
*
*
* History:
* Wed 04/04/2001 - StEstrop - Created
*
\**************************************************************************/
STDMETHODIMP
CAllocatorPresenter::GetXlcModeDDObjAndPrimarySurface(
    LPDIRECTDRAW7* lpDDObj,
    LPDIRECTDRAWSURFACE7* lpPrimarySurf
    )
{
    AMTRACE((TEXT("CAllocatorPresenter::GetXlcModeDDObjAndPrimarySurface")));
    CAutoLock Lock(&m_ObjectLock);

    if (!m_fDDXclMode) {
        return E_NOTIMPL;
    }

    if (lpDDObj == NULL) {
        DbgLog((LOG_ERROR, 1, TEXT("NULL DDraw device") ));
        return E_POINTER;
    }

    if (lpPrimarySurf == NULL) {
        DbgLog((LOG_ERROR, 1, TEXT("NULL Primary Surface") ));
        return E_POINTER;
    }

    *lpDDObj = m_lpCurrMon->pDD;
    if (*lpDDObj) {
        (*lpDDObj)->AddRef();
    }

    *lpPrimarySurf = m_lpCurrMon->pDDSPrimary;
    if (*lpPrimarySurf) {
        (*lpPrimarySurf)->AddRef();
    }

    return S_OK;
}


/******************************Public*Routine******************************\
* SetRenderingPrefs
*
*
*
* History:
* Fri 02/18/2000 - GlennE - Created
*
\**************************************************************************/
STDMETHODIMP
CAllocatorPresenter::SetRenderingPrefs(
    DWORD dwRenderingPrefs
    )
{
    AMTRACE((TEXT("CAllocatorPresenter::SetRenderingPrefs")));
    CAutoLock Lock(&m_ObjectLock);
    if ( dwRenderingPrefs & ~(RenderPrefs_Mask ) )
    {
        DbgLog((LOG_ERROR, 1, TEXT("Invalid rendering prefs")));
        return E_INVALIDARG;
    }
    m_dwRenderingPrefs = dwRenderingPrefs;
    return S_OK;
}


/******************************Public*Routine******************************\
* GetRenderingPrefs
*
*
*
* History:
* Fri 02/18/2000 - GlennE - Created
*
\**************************************************************************/
STDMETHODIMP
CAllocatorPresenter::GetRenderingPrefs(
    DWORD* lpdwRenderingPrefs
    )
{
    AMTRACE((TEXT("CAllocatorPresenter::GetRenderingPrefs")));
    CAutoLock Lock(&m_ObjectLock);
    *lpdwRenderingPrefs = m_dwRenderingPrefs;
    return S_OK;
}


/*****************************Private*Routine******************************\
* ValidatePresInfoStruc
*
*
*
* History:
* Mon 02/19/2001 - StEstrop - Created
*
\**************************************************************************/
HRESULT
ValidatePresInfoStruc(
    VMRPRESENTATIONINFO* lpPresInfo
    )
{
    AMTRACE((TEXT("ValidatePresInfoStruc")));

    //
    // Validate the lpPresInfo ptr.
    //
    if (ISBADREADPTR(lpPresInfo)) {
        DbgLog((LOG_ERROR, 1,
                TEXT("CAllocatorPresenter::PresentImage: ")
                TEXT("Invalid VMRPRESENTATIONINFO pointer")));
        return E_POINTER;
    }

    //
    // Validate the flags are good
    //
    const DWORD dwInvalidFlags = ~(VMRSample_SyncPoint | VMRSample_Preroll |
                                   VMRSample_Discontinuity |
                                   VMRSample_TimeValid);

    if (lpPresInfo->dwFlags & dwInvalidFlags) {
        DbgLog((LOG_ERROR, 1,
                TEXT("CAllocatorPresenter::PresentImage: ")
                TEXT("Invalid dwFlags parameter") ));
        return E_INVALIDARG;
    }

    //
    // Validate the time stamps are good
    //
    if (lpPresInfo->dwFlags & VMRSample_TimeValid) {

        if (lpPresInfo->rtEnd < lpPresInfo->rtStart) {
            DbgLog((LOG_ERROR, 1,
                    TEXT("CAllocatorPresenter::PresentImage: ")
                    TEXT("rtEnd time before rtStart time") ));
            return E_INVALIDARG;
        }
    }

    //
    // Validate the AR is good
    //
    if (lpPresInfo->szAspectRatio.cx < 1 ||
        lpPresInfo->szAspectRatio.cy < 1) {

        DbgLog((LOG_ERROR, 1,
                TEXT("CAllocatorPresenter::PresentImage: ")
                TEXT("Invalid aspect ratio parameter") ));
        return E_INVALIDARG;
    }

    //
    // The Src and Dst rects arn't used just yet so make sure they
    // are zero'ed out (and therefore empty).
    //
    if (lpPresInfo->rcSrc.left != 0 && lpPresInfo->rcSrc.top != 0 &&
        lpPresInfo->rcSrc.right != 0 && lpPresInfo->rcSrc.bottom != 0) {

        DbgLog((LOG_ERROR, 1,
                TEXT("CAllocatorPresenter::PresentImage: ")
                TEXT("Invalid rcSrc parameter") ));
        return E_INVALIDARG;
    }

    if (lpPresInfo->rcDst.left != 0 && lpPresInfo->rcDst.top != 0 &&
        lpPresInfo->rcDst.right != 0 && lpPresInfo->rcDst.bottom != 0) {

        DbgLog((LOG_ERROR, 1,
                TEXT("CAllocatorPresenter::PresentImage: ")
                TEXT("Invalid rcDst parameter") ));
        return E_INVALIDARG;
    }

    return S_OK;
}


/******************************Public*Routine******************************\
* PresentImage
*
* This function is called to present the specifed video image to the
* screen.  It is vital that the image is presented in a timely manner.
* Therefore all parameter validation will only be performed on the DEBUG
* build, see ValidPresInfo above.
*
* History:
* Fri 02/18/2000 - StEstrop - Created
*
\**************************************************************************/
STDMETHODIMP
CAllocatorPresenter::PresentImage(
    DWORD_PTR dwUserID,
    VMRPRESENTATIONINFO* lpPresInfo
    )
{
    AMTRACE((TEXT("CAllocatorPresenter::PresentImage")));
    CAutoLock Lock(&m_ObjectLock);

    HRESULT hr;

    hr = ValidatePresInfoStruc(lpPresInfo);
    if (FAILED(hr)) {
        return hr;
    }

    m_ARSize = lpPresInfo->szAspectRatio;
    m_dwInterlaceFlags = lpPresInfo->dwInterlaceFlags;
    BOOL bNeedToFlipOddEven = NeedToFlipOddEven(m_dwInterlaceFlags,
                                                lpPresInfo->dwTypeSpecificFlags,
                                                &m_dwCurrentField,
                                                m_bUsingOverlays);

    DWORD dwNewFlags = GetUpdateOverlayFlags(m_dwInterlaceFlags,
                                             lpPresInfo->dwTypeSpecificFlags);
    if (dwNewFlags != m_dwUpdateOverlayFlags) {

        m_dwUpdateOverlayFlags = dwNewFlags;
        if (m_bUsingOverlays) {
            UpdateOverlaySurface();
        }
    }

    hr = PresentImageWorker(lpPresInfo->lpSurf, lpPresInfo->dwFlags, true);

    if (hr == S_OK) {

        if (bNeedToFlipOddEven &&
            !IsSingleFieldPerSample(m_dwInterlaceFlags)) {

            //
            // work out the start time of the other field and
            // the schedule the sample to be delivered on the
            // MM timer thread.
            //

            if (lpPresInfo->dwFlags & VMRSample_TimeValid) {
                lpPresInfo->rtStart = (lpPresInfo->rtStart + lpPresInfo->rtEnd) / 2;
            }

            // call the sync object
            hr = ScheduleSampleUsingMMThread(lpPresInfo);
        }
    }
    else {

        DbgLog((LOG_ERROR, 1,
                TEXT("Error %#X from CAllocatorPresenter::PresentImage"),
                hr));
    }
    return hr;
}

/*****************************Private*Routine******************************\
* StretchBltSysMemDDSurfToDesktop
*
*
*
* History:
* Mon 02/26/2001 - StEstrop - Created
*
\**************************************************************************/
HRESULT
StretchBltSysMemDDSurfToDesktop(
    HWND hwndClip,
    LPDIRECTDRAWSURFACE7 lpSample,
    LPRECT lpDst,
    LPRECT lpSrc
    )
{

    HRESULT hr = S_OK;

    if (!IsRectEmpty(lpDst)) {

        HDC hdcDst, hdcSrc;
        bool fDst = FALSE;
        bool fSrc = FALSE;

        __try {

            hdcDst = GetDC(hwndClip);
            if (!hdcDst) {
                LONG lRet = GetLastError();
                hr = AmHresultFromWin32(lRet);
                __leave;
            }
            fDst = TRUE;

            CHECK_HR(hr = lpSample->GetDC(&hdcSrc));
            fSrc = TRUE;


            SetStretchBltMode(hdcDst, COLORONCOLOR);
            SetStretchBltMode(hdcSrc, COLORONCOLOR);

            MapWindowRect(HWND_DESKTOP, hwndClip, lpDst);

            if (!StretchBlt(hdcDst, lpDst->left, lpDst->top,
                       WIDTH(lpDst), HEIGHT(lpDst),
                       hdcSrc, lpSrc->left, lpSrc->top,
                       WIDTH(lpSrc), HEIGHT(lpSrc),
                       SRCCOPY)) {

                LONG lRet = GetLastError();
                hr = AmHresultFromWin32(lRet);
                __leave;
            }
        }
        __finally {

            if (fDst) {
                ReleaseDC(hwndClip, hdcDst);
            }
            if (fSrc) {
                lpSample->ReleaseDC(hdcSrc);
            }
        }
    }

    return hr;
}

/*****************************Private*Routine******************************\
* BltImageToPrimary
*
*
*
* History:
* Wed 09/27/2000 - StEstrop - Created
*
\**************************************************************************/
HRESULT
CAllocatorPresenter::BltImageToPrimary(
    LPDIRECTDRAWSURFACE7 lpSample,
    LPRECT lpDst,
    LPRECT lpSrc
    )
{
    HRESULT hr = S_OK;

    if (IsSingleFieldPerSample(m_dwInterlaceFlags)) {
        lpSrc->top /= 2;
        lpSrc->bottom /= 2;
    }

    if (m_bSysMem && !CanBltSysMem()) {
        hr = StretchBltSysMemDDSurfToDesktop(m_hwndClip, lpSample, lpDst, lpSrc);
        if (hr != DD_OK) {
            DbgLog((LOG_ERROR, 1,
                    TEXT("SYSMEM Blt to the primary failed err= %#X"), hr));
        }
    }
    else {
        OffsetRect(lpDst,
                   -m_lpCurrMon->rcMonitor.left,
                   -m_lpCurrMon->rcMonitor.top);

        if (!IsRectEmpty(lpDst)) {

            WaitForScanLine(*lpDst);
            hr = m_lpCurrMon->pDDSPrimary->Blt(lpDst, lpSample,
                                               lpSrc, DDBLT_WAIT, NULL);

            if (hr != DD_OK) {
                DbgLog((LOG_ERROR, 1,
                        TEXT("Blt to the primary failed err= %#X"), hr));
            }
        }
    }

    return S_OK;
}



/******************************Public*Routine******************************\
* PresentImageWorker
*
* Important - this function returns S_FALSE if and only if there is a
* monitor change or display change in progress.  It is important that this
* value is returned to the VMR.
*
* History:
* Fri 02/18/2000 - StEstrop - Created
*
\**************************************************************************/
HRESULT
CAllocatorPresenter::PresentImageWorker(
    LPDIRECTDRAWSURFACE7 lpSample,
    DWORD dwSampleFlags,
    BOOL fFlip
    )
{
    AMTRACE((TEXT("CAllocatorPresenter::PresentImageWorker")));
    CAutoLock Lock(&m_ObjectLock);

    //
    // It is valid for us to be called with lpSample equal to NULL
    // but only during a Monitor change in response to a WM_PAINT message
    //
    if (!lpSample) {
        ASSERT(MonitorChangeInProgress());
        return S_FALSE;
    }

    //
    // Check that we actually have a target monitor to present too.
    // If we don't this is a runtime error from which we cannot
    // recover.  Playback must stop now.
    //
    if (!m_lpCurrMon) {
        DbgLog((LOG_ERROR, 1, TEXT("PresentImageWorker: No monitor set!")));
        return E_FAIL;
    }

    DWORD dwUR = UpdateRectangles(NULL, NULL);

    RECT TargetRect = m_rcDstDesktop;
    RECT SourceRect = m_rcSrcApp;

    ClipRectPair(SourceRect, TargetRect, m_lpCurrMon->rcMonitor);

    if (m_bDecimating) {
        SourceRect.left    /= 2;
        SourceRect.top     /= 2;
        SourceRect.right   /= 2;
        SourceRect.bottom  /= 2;
    }


    HRESULT hr = S_OK;
    if (m_bUsingOverlays) {

        if (m_bDisableOverlays) {
            BltImageToPrimary(lpSample, &TargetRect, &SourceRect);
        }

        if (dwUR || !m_bOverlayVisible) {
            hr = UpdateOverlaySurface();
            if (SUCCEEDED(hr) && !m_bDisableOverlays) {
                hr = PaintColorKey();
            }
        }

        if (fFlip) {
            FlipSurface(lpSample);
        }
    }
    else {

        hr = BltImageToPrimary(lpSample, &TargetRect, &SourceRect);
        if (fFlip) {
            FlipSurface(lpSample);
        }
    }

    PaintBorder();
    PaintMonitorBorder();

    return S_OK;
}

/******************************Public*Routine******************************\
* StartPresenting
*
*
*
* History:
* Tue 02/29/2000 - StEstrop - Created
*
\**************************************************************************/
STDMETHODIMP
CAllocatorPresenter::StartPresenting(
    DWORD_PTR dwUserID
    )
{
    AMTRACE((TEXT("CAllocatorPresenter::StartPresenting")));
    CAutoLock Lock(&m_ObjectLock);
    m_bStreaming = TRUE;
    return S_OK;
}

/******************************Public*Routine******************************\
* StopPresenting
*
*
*
* History:
* Tue 02/29/2000 - StEstrop - Created
*
\**************************************************************************/
STDMETHODIMP
CAllocatorPresenter::StopPresenting(
    DWORD_PTR dwUserID
    )
{
    AMTRACE((TEXT("CAllocatorPresenter::StopPresenting")));
    CAutoLock Lock(&m_ObjectLock);
    m_bStreaming = FALSE;
    CancelMMTimer();
    return S_OK;
}


/******************************Public*Routine******************************\
* AdviseNotify
*
*
*
* History:
* Mon 02/21/2000 - StEstrop - Created
*
\**************************************************************************/
STDMETHODIMP
CAllocatorPresenter::AdviseNotify(
    IVMRSurfaceAllocatorNotify* lpIVMRSurfaceAllocatorNotify
    )
{
    AMTRACE((TEXT("CAllocatorPresenter::AdviseNotify")));
    CAutoLock Lock(&m_ObjectLock);

    RELEASE(m_pSurfAllocatorNotify);

    if (lpIVMRSurfaceAllocatorNotify) {
        lpIVMRSurfaceAllocatorNotify->AddRef();
    }

    m_pSurfAllocatorNotify = lpIVMRSurfaceAllocatorNotify;

    if (m_pSurfAllocatorNotify) {
        m_pSurfAllocatorNotify->SetDDrawDevice(m_lpCurrMon->pDD,
                                               m_lpCurrMon->hMon);
    }
    return S_OK;
}


/******************************Public*Routine******************************\
* GetNativeVideoSize
*
*
*
* History:
* Mon 02/28/2000 - StEstrop - Created
*
\**************************************************************************/
STDMETHODIMP
CAllocatorPresenter::GetNativeVideoSize(
    LONG* lpWidth,
    LONG* lpHeight,
    LONG* lpARWidth,
    LONG* lpARHeight
    )
{
    AMTRACE((TEXT("CAllocatorPresenter::GetNativeVideoSize")));
    CAutoLock Lock(&m_ObjectLock);
    if (!(lpWidth || lpHeight || lpARWidth || lpARHeight)) {
        DbgLog((LOG_ERROR, 1, TEXT("all input parameters are NULL!!")));
        return E_POINTER;
    }

    if (lpWidth) {
        *lpWidth = m_VideoSizeAct.cx;
    }

    if (lpHeight) {
        *lpHeight = m_VideoSizeAct.cy;
    }

    if (lpARWidth) {
        *lpARWidth = m_ARSize.cx;
    }

    if (lpARHeight) {
        *lpARHeight = m_ARSize.cy;
    }

    return S_OK;
}

/******************************Public*Routine******************************\
* GetMinIdealVideoSize
*
*
*
* History:
* Mon 02/28/2000 - StEstrop - Created
*
\**************************************************************************/
STDMETHODIMP
CAllocatorPresenter::GetMinIdealVideoSize(
    LONG* lWidth,
    LONG* lHeight
    )
{
    AMTRACE((TEXT("CAllocatorPresenter::GetMinIdealVideoSize")));
    CAutoLock Lock(&m_ObjectLock);

    if ( ISBADWRITEPTR(lWidth) )
    {
        DbgLog((LOG_ERROR, 1, TEXT("Invalid pointer")));
        return E_POINTER;
    }
    if ( ISBADWRITEPTR(lHeight) )
    {
        DbgLog((LOG_ERROR, 1, TEXT("Invalid pointer")));
        return E_POINTER;
    }
    if (!FoundCurrentMonitor()) {
        return E_FAIL;
    }

    GetNativeVideoSize(lWidth, lHeight, NULL, NULL);

    if (m_bUsingOverlays) {

        if (m_lpCurrMon->ddHWCaps.dwFXCaps & DDFXCAPS_OVERLAYSHRINKY) {
            if (m_lpCurrMon->ddHWCaps.dwMinOverlayStretch != 0) {
                *lHeight = MulDiv(*lHeight,
                                 (int)m_lpCurrMon->ddHWCaps.dwMinOverlayStretch,
                                 1000);
            }
            else {
                *lHeight = 1;
            }
        }

        if (m_lpCurrMon->ddHWCaps.dwFXCaps & DDFXCAPS_OVERLAYSHRINKX) {
            if (m_lpCurrMon->ddHWCaps.dwMinOverlayStretch != 0) {
                *lWidth = MulDiv(*lWidth,
                                (int)m_lpCurrMon->ddHWCaps.dwMinOverlayStretch,
                                1000);
            }
            else {
                *lWidth = 1;
            }
        }
    }
    else {

        if (m_lpCurrMon->ddHWCaps.dwFXCaps & DDFXCAPS_BLTSHRINKY) {
            *lHeight = 1;
        }

        if (m_lpCurrMon->ddHWCaps.dwFXCaps & DDFXCAPS_BLTSHRINKX) {
            *lWidth = 1;
        }
    }

    return S_OK;
}

/******************************Public*Routine******************************\
* GetMaxIdealVideoSize
*
*
*
* History:
* Mon 02/28/2000 - StEstrop - Created
*
\**************************************************************************/
STDMETHODIMP
CAllocatorPresenter::GetMaxIdealVideoSize(
    LONG* lWidth,
    LONG* lHeight
    )
{
    AMTRACE((TEXT("CAllocatorPresenter::GetMaxIdealVideoSize")));
    CAutoLock Lock(&m_ObjectLock);

    if ( ISBADWRITEPTR(lWidth) )
    {
        DbgLog((LOG_ERROR, 1, TEXT("Invalid pointer")));
        return E_POINTER;
    }
    if ( ISBADWRITEPTR(lHeight) )
    {
        DbgLog((LOG_ERROR, 1, TEXT("Invalid pointer")));
        return E_POINTER;
    }
    if (!FoundCurrentMonitor()) {
        return E_FAIL;
    }

    GetNativeVideoSize(lWidth, lHeight, NULL, NULL);

    if (m_bUsingOverlays) {

        if (m_lpCurrMon->ddHWCaps.dwFXCaps & DDFXCAPS_OVERLAYSTRETCHY) {
            *lHeight = MulDiv(*lHeight,
                              (int)m_lpCurrMon->ddHWCaps.dwMaxOverlayStretch,
                              1000);
        }

        if (m_lpCurrMon->ddHWCaps.dwFXCaps & DDFXCAPS_OVERLAYSTRETCHX) {
            *lWidth = MulDiv(*lWidth,
                             (int)m_lpCurrMon->ddHWCaps.dwMaxOverlayStretch,
                             1000);
        }
    }
    else {

        if (m_lpCurrMon->ddHWCaps.dwFXCaps & DDFXCAPS_BLTSTRETCHY) {
            *lHeight = HEIGHT(&m_lpCurrMon->rcMonitor) + 1;
        }

        if (m_lpCurrMon->ddHWCaps.dwFXCaps & DDFXCAPS_BLTSTRETCHX) {
            *lWidth = WIDTH(&m_lpCurrMon->rcMonitor) + 1;
        }
    }

    return S_OK;
}


/*****************************Private*Routine******************************\
* CheckDstRect
*
* Check the target rectangle has some valid coordinates, which amounts to
* little more than checking the destination rectangle isn't empty.
*
*
* History:
* Fri 01/26/2001 - StEstrop - Created
*
\**************************************************************************/
HRESULT
CAllocatorPresenter::CheckDstRect(
    const LPRECT lpDSTRect
    )
{
    AMTRACE((TEXT("CAllocatorPresenter::CheckDstRect")));

    DbgLog((LOG_TRACE, 4, TEXT("DST: %d %d %d %d"),
            lpDSTRect->left, lpDSTRect->top,
            lpDSTRect->right, lpDSTRect->bottom));

    // These overflow the WIDTH and HEIGHT checks

    if (lpDSTRect->left > lpDSTRect->right ||
        lpDSTRect->top > lpDSTRect->bottom)
    {
        return E_INVALIDARG;
    }

    // Check the rectangle has valid coordinates

    if (WIDTH(lpDSTRect) < 0 || HEIGHT(lpDSTRect) < 0)
    {
        return E_INVALIDARG;
    }

    return S_OK;
}


/*****************************Private*Routine******************************\
* CheckSrcRect
*
* We must check the source rectangle against  the actual video dimensions
* otherwise when we come to draw the pictures we get errors from DDraw.
*
* History:
* Fri 01/26/2001 - StEstrop - Created
*
\**************************************************************************/
HRESULT
CAllocatorPresenter::CheckSrcRect(
    const LPRECT lpSRCRect
    )
{
    AMTRACE((TEXT("CAllocatorPresenter::CheckSrcRect")));

    DbgLog((LOG_TRACE, 4, TEXT("SRC: %d %d %d %d"),
            lpSRCRect->left, lpSRCRect->top,
            lpSRCRect->right, lpSRCRect->bottom));

    LONG Width, Height;
    HRESULT hr = E_INVALIDARG;

    __try {

        CHECK_HR(hr = GetNativeVideoSize(&Width, &Height, NULL, NULL));

        if ((lpSRCRect->left > lpSRCRect->right) ||
            (lpSRCRect->left < 0) ||
            (lpSRCRect->top  > lpSRCRect->bottom) ||
            (lpSRCRect->top  < 0))
        {
            hr = E_INVALIDARG;
            __leave;
        }

        if (lpSRCRect->right > Width || lpSRCRect->bottom > Height)
        {
            hr = E_INVALIDARG;
            __leave;
        }
    }
    __finally {
    }

    return hr;
}

/******************************Public*Routine******************************\
* SetVideoPosition
*
*
*
* History:
* Mon 02/28/2000 - StEstrop - Created
*
\**************************************************************************/
STDMETHODIMP
CAllocatorPresenter::SetVideoPosition(
    const LPRECT lpSRCRect,
    const LPRECT lpDSTRect
    )
{
    AMTRACE((TEXT("CAllocatorPresenter::SetVideoPosition")));
    CAutoLock Lock(&m_ObjectLock);

    HRESULT hr = S_OK;

    if (!lpSRCRect && !lpDSTRect) {
        return E_POINTER;
    }

    if (lpDSTRect) {
        hr = CheckDstRect(lpDSTRect);
        if (FAILED(hr)) {
            return hr;
        }
    }

    if (lpSRCRect) {
        hr = CheckSrcRect(lpSRCRect);
        if (FAILED(hr)) {
            return hr;
        }
    }

    if (m_lpCurrMon && m_lpCurrMon->pDDSPrimary) {

        DWORD dwUR = UpdateRectangles(lpSRCRect, lpDSTRect);

        //
        // if the video SRC or DST sizes have changed make sure the clipping
        // window's contents are still valid.
        //

        if ((dwUR & UR_SIZE) && (m_hwndClip != NULL)) {
            InvalidateRect(m_hwndClip, &m_rcDstApp, FALSE);
        }

        if (!MonitorChangeInProgress() && m_bUsingOverlays && (dwUR & UR_MOVE)) {

            //
            // If we're using overlays, but there's some restriction on
            // the shrink/alignment then switch off the overlay and blit
            // to the primary
            //

            m_bDisableOverlays =
                !(m_dwRenderingPrefs & RenderPrefs_ForceOverlays) &&
                ShouldDisableOverlays(m_lpCurrMon->ddHWCaps, m_rcSrcApp,
                                      m_rcDstDesktop);

            hr = UpdateOverlaySurface();
            if( SUCCEEDED( hr ) && !m_bDisableOverlays ) {
                hr = PaintColorKey();
            }
        }
    }
    else {
        hr = VFW_E_BUFFER_NOTSET;
    }

    return hr;
}

/******************************Public*Routine******************************\
* GetVideoPosition
*
*
*
* History:
* Mon 02/28/2000 - StEstrop - Created
*
\**************************************************************************/
STDMETHODIMP
CAllocatorPresenter::GetVideoPosition(
    LPRECT lpSRCRect,
    LPRECT lpDSTRect
    )
{
    AMTRACE((TEXT("CAllocatorPresenter::GetVideoPosition")));
    CAutoLock Lock(&m_ObjectLock);

    HRESULT hr = VFW_E_BUFFER_NOTSET;
    if (m_lpCurrMon && m_lpCurrMon->pDDSPrimary) {

        hr = E_POINTER;

        if (lpSRCRect) {
            *lpSRCRect = m_rcSrcApp;
            hr = S_OK;
        }

        if (lpDSTRect) {
            *lpDSTRect = m_rcDstApp;
            hr = S_OK;
        }
    }
    return hr;
}


/******************************Public*Routine******************************\
* CAllocatorPresenter::GetAspectRatioMode
*
*
*
* History:
* Tue 02/29/2000 - StEstrop - Created
*
\**************************************************************************/
STDMETHODIMP
CAllocatorPresenter::GetAspectRatioMode(
    DWORD* lpAspectRatioMode
    )
{
    AMTRACE((TEXT("CAllocatorPresenter::GetAspectRationMode")));
    CAutoLock Lock(&m_ObjectLock);

    HRESULT hr = S_OK;

    if (!lpAspectRatioMode) {
        hr = E_POINTER;
    }

    if (SUCCEEDED(hr)) {
        *lpAspectRatioMode = m_dwARMode;
    }

    return hr;
}


/******************************Public*Routine******************************\
* CAllocatorPresenter::SetAspectRatioMode
*
*
*
* History:
* Tue 02/29/2000 - StEstrop - Created
*
\**************************************************************************/
STDMETHODIMP
CAllocatorPresenter::SetAspectRatioMode(
    DWORD AspectRatioMode
    )
{
    AMTRACE((TEXT("CAllocatorPresenter::SetAspectRationMode")));
    CAutoLock Lock(&m_ObjectLock);

    HRESULT hr = S_OK;

    if (AspectRatioMode != VMR_ARMODE_LETTER_BOX &&
        AspectRatioMode != VMR_ARMODE_NONE) {

        hr = E_INVALIDARG;
    }

    if (SUCCEEDED(hr)) {
        if (AspectRatioMode != m_dwARMode) {

            //
            // We can get away with repaint the dest rect
            // before setting the new mode becuase InvalidateRect
            // isn't synchronous.
            //

            InvalidateRect(m_hwndClip, &m_rcDstApp, FALSE);
        }

        m_dwARMode = AspectRatioMode;
    }

    return hr;
}


/******************************Public*Routine******************************\
* SetVideoClippingWindow
*
*
*
* History:
* Mon 02/28/2000 - StEstrop - Created
*
\**************************************************************************/
STDMETHODIMP
CAllocatorPresenter::SetVideoClippingWindow(
    HWND hwnd
    )
{
    AMTRACE((TEXT("CAllocatorPresenter::SetVideoClippingWindow")));
    CAutoLock Lock(&m_ObjectLock);

    HRESULT hr = E_INVALIDARG;

    if ( ! IsWindow(hwnd) )
    {
        DbgLog((LOG_ERROR, 1, TEXT("Invalid HWND")));
        return E_INVALIDARG;
    }

    for (DWORD i = 0; i < m_monitors.Count(); i++) {
        LPDIRECTDRAWSURFACE7 pPriSurf = m_monitors[i].pDDSPrimary;
        if ( pPriSurf ) {

            LPDIRECTDRAWCLIPPER lpDDClipper;
            hr = pPriSurf->GetClipper(&lpDDClipper);
            if (SUCCEEDED(hr)) {
                lpDDClipper->SetHWnd(0, hwnd);
                lpDDClipper->Release();
            }
        }
    }

    m_hwndClip = hwnd;

    return hr;
}


/******************************Public*Routine******************************\
* CAllocatorPresenter::RepaintVideo
*
*
*
* History:
* Tue 02/29/2000 - StEstrop - Created
*
\**************************************************************************/
HRESULT
CAllocatorPresenter::RepaintVideo(
    HWND hwnd,
    HDC hdc
    )
{
    AMTRACE((TEXT("CAllocatorPresenter::RepaintVideo")));
    CAutoLock Lock(&m_ObjectLock);

    HRESULT hr = VFW_E_BUFFER_NOTSET;

    if (m_lpCurrMon && m_lpCurrMon->pDDSPrimary && SurfaceAllocated()) {

        hr = PresentImageWorker(m_pDDSDecode, 0, FALSE);

        PaintBorder();

        if (m_bUsingOverlays && !m_bDisableOverlays) {
            PaintColorKey();
        }

        PaintMonitorBorder();
    }

    return hr;
}

/******************************Private*Routine******************************\
* CAllocatorPresenter::PaintBorder
*
*
*
* History:
* Wed 04/03/2000 - GlennE - Created
*
\**************************************************************************/
HRESULT
CAllocatorPresenter::PaintBorder()
{
    AMTRACE((TEXT("CAllocatorPresenter::PaintBorder")));
    CAutoLock Lock(&m_ObjectLock);

    if (m_dwRenderingPrefs & RenderPrefs_DoNotRenderColorKeyAndBorder) {
        return S_OK;
    }

    if (m_dwARMode != VMR_ARMODE_LETTER_BOX) {
        return S_OK;
    }

    HRESULT hr = S_OK;
    RECT TargetRect;

    DDBLTFX ddFX;
    INITDDSTRUCT(ddFX);
    ddFX.dwFillColor = m_lpCurrMon->dwMappedBdrClr;

    RECT rcTmp = m_rcBdrTL;
    MapWindowRect(m_hwndClip, HWND_DESKTOP, &rcTmp);
    IntersectRect(&TargetRect, &rcTmp, &m_lpCurrMon->rcMonitor);


    if (!IsRectEmpty(&TargetRect)) {
        ASSERT( NULL != m_lpCurrMon->pDDSPrimary );
        OffsetRect(&TargetRect,
                   -m_lpCurrMon->rcMonitor.left,
                   -m_lpCurrMon->rcMonitor.top);

        hr = m_lpCurrMon->pDDSPrimary->Blt(&TargetRect, NULL, NULL,
                                           DDBLT_COLORFILL | DDBLT_WAIT,
                                           &ddFX);
        if (hr != DD_OK) {
            return hr;
        }
    }

    rcTmp = m_rcBdrBR;
    MapWindowRect(m_hwndClip, HWND_DESKTOP, &rcTmp);
    IntersectRect(&TargetRect, &rcTmp, &m_lpCurrMon->rcMonitor);

    if (!IsRectEmpty(&TargetRect)) {
        ASSERT( NULL != m_lpCurrMon->pDDSPrimary );
        OffsetRect(&TargetRect,
                   -m_lpCurrMon->rcMonitor.left,
                   -m_lpCurrMon->rcMonitor.top);

        hr = m_lpCurrMon->pDDSPrimary->Blt(&TargetRect, NULL, NULL,
                                           DDBLT_COLORFILL | DDBLT_WAIT,
                                           &ddFX);
    }

    return hr;
}


/*****************************Private*Routine******************************\
* MonitorBorderProc
*
*
*
* History:
* Wed 09/20/2000 - StEstrop - Created
*
\**************************************************************************/
BOOL CALLBACK
CAllocatorPresenter::MonitorBorderProc(
    HMONITOR hMonitor,
    HDC hdcMonitor,
    LPRECT lprcMonitor,
    LPARAM dwData
    )
{
    CAllocatorPresenter* lpThis = (CAllocatorPresenter*)dwData;
    lpThis->PaintMonitorBorderWorker(hMonitor, lprcMonitor);
    return TRUE;
}


/*****************************Private*Routine******************************\
* PaintMonitorBorderWorker
*
*
*
* History:
* Wed 09/20/2000 - StEstrop - Created
*
\**************************************************************************/
HRESULT
CAllocatorPresenter::PaintMonitorBorderWorker(
    HMONITOR hMonitor,
    LPRECT lprcDst
    )
{
    if (hMonitor != m_lpCurrMon->hMon) {

        CAMDDrawMonitorInfo* lp = m_monitors.FindMonitor(hMonitor);

        // CMonitorArray::FindMonitor() returns NULL if a mirroring display
        // device is installed on the system.  Direct Draw does not enumerate
        // mirroring display devices so the VMR does not create a
        // CAMDDrawMonitorInfo object which corresponded to the device.  This
        // is by design.  However, EnumDisplayMonitors() does enumerate mirroring
        // display devices and it passes handles to these devices to
        // PaintMonitorBorderWorker() (actually EnumDisplayMonitors() calls
        // CAllocatorPresenter::MonitorBorderProc() and MonitorBorderProc() calls
        // PaintMonitorBorderWorker()) .  PaintMonitorBorderWorker() calls
        // FindMonitor() to get the CAMDDrawMonitorInfo object which corresponds
        // to the monitor handle.  FindMonitor() returns NULL if it cannot find
        // a CAMDDrawMonitorInfo object which corresponds to the handle.
        // FindMonitor() cannot find a CAMDDrawMonitorInfo objects for monitors
        // which are not enumerated by Direct Draw and therefore it cannot find
        // a CAMDDrawMonitorInfo object for a mirroring display device.
        if (NULL != lp) {
            DDBLTFX ddFX;
            INITDDSTRUCT(ddFX);
            ddFX.dwFillColor = lp->dwMappedBdrClr;

            RECT TargetRect;
            RECT rcTmp = *lprcDst;
            IntersectRect(&TargetRect, &rcTmp, &lp->rcMonitor);

            if (!IsRectEmpty(&TargetRect)) {
                ASSERT( NULL != lp->pDDSPrimary );
                OffsetRect(&TargetRect, -lp->rcMonitor.left, -lp->rcMonitor.top);

                lp->pDDSPrimary->Blt(&TargetRect, NULL, NULL,
                                     DDBLT_COLORFILL | DDBLT_WAIT,
                                     &ddFX);
            }
        }
    }

    return S_OK;
}

/******************************Public*Routine******************************\
* PaintMonitorBorder
*
* Paints the are of the playback window that falls on a diferent monitor to
* current monitor.  This function only performs painting if we are on a
* multimonitor system and the playback rectangle actually intersects more
* one monitor.
*
* Playback perf may well drop off dramatically!
*
* History:
* Wed 09/20/2000 - StEstrop - Created
*
\**************************************************************************/
HRESULT
CAllocatorPresenter::PaintMonitorBorder()
{
    AMTRACE((TEXT("CAllocatorPresenter::PaintKey")));
    CAutoLock Lock(&m_ObjectLock);

    if (m_dwRenderingPrefs & RenderPrefs_DoNotRenderColorKeyAndBorder) {
        return S_OK;
    }

    if (m_bMonitorStraddleInProgress|| !m_bStreaming) {
        EnumDisplayMonitors((HDC)NULL, &m_rcDstDskIncl, MonitorBorderProc,
                            (LPARAM)this);
    }

    return S_OK;
}


/******************************Private*Routine******************************\
* CAllocatorPresenter::PaintColorKey
*
*
*
* History:
* Wed 04/03/2000 - GlennE - Created
*
\**************************************************************************/
HRESULT
CAllocatorPresenter::PaintColorKey()
{
    AMTRACE((TEXT("CAllocatorPresenter::PaintColorKey")));
    CAutoLock Lock(&m_ObjectLock);

    if (m_dwRenderingPrefs & RenderPrefs_DoNotRenderColorKeyAndBorder) {
        return S_OK;
    }

    if( !IsRectEmpty( &m_rcDstDesktop )) {

        if( m_dwMappedColorKey == CLR_INVALID ) {
            m_dwMappedColorKey = MapColorToMonitor( *m_lpCurrMon, m_clrKey );
        }

        //
        // Peform a DirectDraw colorfill BLT.  DirectDraw will automatically
        // query the attached clipper object, handling occlusion.
        //

        DDBLTFX ddFX;
        INITDDSTRUCT(ddFX);
        ddFX.dwFillColor = m_dwMappedColorKey;

        ASSERT( NULL != m_lpCurrMon->pDDSPrimary );

        RECT TargetRect;
        IntersectRect(&TargetRect, &m_rcDstDesktop, &m_lpCurrMon->rcMonitor);
        HRESULT hr = S_OK;
        if (!IsRectEmpty(&TargetRect)) {

            OffsetRect(&TargetRect,
                       -m_lpCurrMon->rcMonitor.left,
                       -m_lpCurrMon->rcMonitor.top);

            hr = m_lpCurrMon->pDDSPrimary->Blt(&TargetRect, NULL, NULL,
                                               DDBLT_COLORFILL | DDBLT_WAIT,
                                               &ddFX);
        }

        if (FAILED(hr))
        {
            DbgLog((LOG_ERROR,0,
                    TEXT("m_pPrimarySurface->Blt ")
                    TEXT("{%d, %d, %d, %d} failed, hr = 0x%X"),
                    TargetRect.left, TargetRect.top,
                    TargetRect.right, TargetRect.bottom, hr));
        }

        return hr;
    }
    return S_OK;
}

/******************************Public*Routine******************************\
* CAllocatorPresenter::DisplayModeChanged
*
*
*
* History:
* Tue 02/29/2000 - StEstrop - Created
*
\**************************************************************************/
STDMETHODIMP
CAllocatorPresenter::DisplayModeChanged()
{
    AMTRACE((TEXT("CAllocatorPresenter::DisplayModeChanged")));
    CAutoLock Lock(&m_ObjectLock);

    //
    // DisplayModeChanged() holds this lock because it prevents multiple threads
    // from simultaneously calling it.  It also holds the lock because it prevents
    // a thread from modifing m_monitors while DisplayModeChanged() calls
    // IVMRSurfaceAllocatorNotify::ChangeDDrawDevice().
    //
    CAutoLock DisplayModeChangedLock(&m_DisplayModeChangedLock);

    HRESULT hr = S_OK;
    DbgLog((LOG_TRACE, 1, TEXT("CAllocatorPresenter::DisplayModeChanged")));

    m_monitors.TerminateDisplaySystem();
    m_lpNewMon = NULL;
    m_lpCurrMon = NULL;
    hr = m_monitors.InitializeDisplaySystem( m_hwndClip );

    DbgLog((LOG_TRACE, 1, TEXT("Display system re-initialized")));

    if (SUCCEEDED(hr)) {

        //
        // The docs say that MonitorFromRect will always return a Monitor.
        //

        HMONITOR hMon = MonitorFromRect(&m_rcDstDesktop, MONITOR_DEFAULTTONEAREST);

        //
        // now look for this monitor in our monitor info array
        //

        CAMDDrawMonitorInfo* lpMon = m_monitors.FindMonitor( hMon );
        if (lpMon) {
            m_lpCurrMon = m_lpNewMon = lpMon;
        }
        ASSERT(m_lpCurrMon != NULL);

        if (m_pSurfAllocatorNotify && lpMon) {
            m_ObjectLock.Unlock();
            m_pSurfAllocatorNotify->ChangeDDrawDevice(lpMon->pDD,
                                                      lpMon->hMon);
            m_ObjectLock.Lock();
        }
        return S_OK;
    }

    DbgLog((LOG_ERROR, 1, TEXT("display system re-init failed err: %#X"), hr));

    return hr;
}


/******************************Public*Routine******************************\
* SetBorderColor
*
*
*
* History:
* Mon 02/28/2000 - StEstrop - Created
*
\**************************************************************************/
STDMETHODIMP
CAllocatorPresenter::SetBorderColor(
    COLORREF Clr
    )
{
    AMTRACE((TEXT("CAllocatorPresenter::SetBorderColor")));
    CAutoLock Lock(&m_ObjectLock);

    // PaintBorder() and PaintMonitorBorder() expect FoundCurrentMonitor()
    // to return true.  Both functions crash if they are called and
    // FoundCurrentMonitor() returns false.
    if (!FoundCurrentMonitor()) {
        return E_FAIL;
    }

    m_clrBorder = Clr;
    for (DWORD i = 0; i < m_monitors.Count(); i++) {
        m_monitors[i].dwMappedBdrClr = MapColorToMonitor(m_monitors[i], Clr);
    }

    PaintBorder();
    PaintMonitorBorder();

    m_pSurfAllocatorNotify->SetBorderColor(Clr);

    return S_OK;
}

/******************************Public*Routine******************************\
* GetBorderColor
*
*
*
* History:
* Mon 02/28/2000 - StEstrop - Created
*
\**************************************************************************/
STDMETHODIMP
CAllocatorPresenter::GetBorderColor(
    COLORREF* lpClr
    )
{
    AMTRACE((TEXT("CAllocatorPresenter::GetBorderColor")));
    if (!lpClr ) {
        DbgLog((LOG_ERROR, 1, TEXT("border key parameter is NULL!!")));
        return E_POINTER;
    }
    CAutoLock Lock(&m_ObjectLock);
    *lpClr = m_clrBorder;

    return S_OK;
}

/******************************Public*Routine******************************\
* SetColorKey
*
*
*
* History:
* Mon 02/28/2000 - StEstrop - Created
*
\**************************************************************************/
STDMETHODIMP
CAllocatorPresenter::SetColorKey(
    COLORREF Clr
    )
{
    AMTRACE((TEXT("CAllocatorPresenter::SetColorKey")));
    CAutoLock Lock(&m_ObjectLock);
    m_clrKey = Clr;

    // map now (if possible) to avoid locking the primary later
    HRESULT hr = S_OK;
    ASSERT(m_lpCurrMon);

    if (m_lpCurrMon) {

        m_dwMappedColorKey = MapColorToMonitor(*m_lpCurrMon, Clr);

        if (m_bUsingOverlays) {

            ASSERT(NULL != m_lpCurrMon->pDDSPrimary);

            DDCOLORKEY DDColorKey = {m_dwMappedColorKey, m_dwMappedColorKey};
            hr = m_lpCurrMon->pDDSPrimary->SetColorKey(DDCKEY_DESTOVERLAY,&DDColorKey);
        }
    }

    return hr;
}

/******************************Public*Routine******************************\
* GetColorKey
*
*
*
* History:
* Mon 02/28/2000 - StEstrop - Created
*
\**************************************************************************/
STDMETHODIMP
CAllocatorPresenter::GetColorKey(
    COLORREF* lpClr
    )
{
    AMTRACE((TEXT("CAllocatorPresenter::GetColorKey")));
    if (!lpClr ) {
        DbgLog((LOG_ERROR, 1, TEXT("colour key parameter is NULL!!")));
        return E_POINTER;
    }
    CAutoLock Lock(&m_ObjectLock);
    *lpClr = m_clrKey;
    return S_OK;
}



/*****************************Private*Routine******************************\
* IsDestRectOnWrongMonitor
*
* Has the DstRect moved at least 50% onto a monitor other than the current
* monitor.  If so, pMonitor will be the hMonitor of the monitor the DstRect
* is now on.
*
* History:
* Fri 04/14/2000 - StEstrop - Created
*
\**************************************************************************/
bool
CAllocatorPresenter::IsDestRectOnWrongMonitor(
    CAMDDrawMonitorInfo** lplpNewMon
    )
{
    AMTRACE((TEXT("CAllocatorPresenter::IsDestRectOnWrongMonitor")));

    HMONITOR hMon = m_lpCurrMon->hMon;
    *lplpNewMon = m_lpCurrMon;
    m_bMonitorStraddleInProgress = FALSE;

    if (!IsWindow(m_hwndClip)) {

        DbgLog((LOG_ERROR, 1, TEXT("Playback Window destroyed!")));
        return false;
    }

    if (GetSystemMetrics(SM_CMONITORS) > 1 && !IsIconic(m_hwndClip)) {

        //
        // Look for any part of our destination rect going over
        // another monitor
        //
        if (!IsRectEmpty(&m_rcDstDskIncl) &&
            !ContainedRect(&m_rcDstDskIncl, &m_lpCurrMon->rcMonitor)) {

            m_bMonitorStraddleInProgress = TRUE;
        }

        //
        // If the dstRect is on a different monitor from last time, this is the
        // quickest way to find out.  This is called every frame, remember.
        //
        if (!IsRectEmpty(&m_rcDstDesktop) &&
            !ContainedRect(&m_rcDstDesktop, &m_lpCurrMon->rcMonitor)) {

            //
            // The docs say that MonitorFromRect will always return a Monitor.
            //

            hMon = MonitorFromRect(&m_rcDstDesktop, MONITOR_DEFAULTTONEAREST);

            DbgLog((LOG_TRACE, 2, TEXT("Curr Mon %#X New Mon %#X"),
                    m_lpCurrMon->hMon, hMon));

            //
            // now look for this monitor in our monitor info array
            //

            CAMDDrawMonitorInfo* lpMon = m_monitors.FindMonitor(hMon);
            if( lpMon ) {
                *lplpNewMon = lpMon;
            }
        }
    }

    return  m_lpCurrMon->hMon != hMon;
}
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\multimedia\dshow\filters\image2\ap\apobj.h ===
/******************************Module*Header*******************************\
* Module Name: APObj.h
*
* Declaration of the CAllocatorPresenter
*
*
* Created: Wed 02/23/2000
* Author:  Stephen Estrop [StEstrop]
*
* Copyright (c) 2000 Microsoft Corporation
\**************************************************************************/

#include <ddraw.h>
#include <d3d.h>
#include <dvdmedia.h>
#include "display.h"
#include "vmrp.h"
#include "thunkproc.h"  // for template for MSDVD timer

/////////////////////////////////////////////////////////////////////////////
// CAlocatorPresenter
class CAllocatorPresenter :
    public CUnknown,
    public IVMRSurfaceAllocator,
    public IVMRImagePresenter,
    public IVMRWindowlessControl,
    public IVMRImagePresenterExclModeConfig,
    public IVMRMonitorConfig,
    public CMSDVDTimer<CAllocatorPresenter>
{
public:
    DECLARE_IUNKNOWN
    STDMETHODIMP NonDelegatingQueryInterface(REFIID, void**);
    static CUnknown *CreateInstance(LPUNKNOWN, HRESULT *);
    static CUnknown *CreateInstanceDDXclMode(LPUNKNOWN, HRESULT *);
    static void InitClass(BOOL bLoading,const CLSID *clsid);

    CAllocatorPresenter(LPUNKNOWN pUnk, HRESULT *phr, BOOL fDDXclMode);
    virtual ~CAllocatorPresenter();


// IVMRImagePresenterConfig and IVMRImagePresenterExclModeConfig
public:
    STDMETHODIMP SetRenderingPrefs(DWORD  dwRenderFlags);
    STDMETHODIMP GetRenderingPrefs(DWORD* lpdwRenderFlags);
    STDMETHODIMP SetXlcModeDDObjAndPrimarySurface(
        LPDIRECTDRAW7 lpDDObj, LPDIRECTDRAWSURFACE7 lpPrimarySurf);
    STDMETHODIMP GetXlcModeDDObjAndPrimarySurface(
        LPDIRECTDRAW7* lpDDObj, LPDIRECTDRAWSURFACE7* lpPrimarySurf);

// IVMRSurfaceAllocator
public:
    STDMETHODIMP AllocateSurface(DWORD_PTR dwUserID,
                                 VMRALLOCATIONINFO* lpAllocInfo,
                                 DWORD* lpdwActualBackBuffers,
                                 LPDIRECTDRAWSURFACE7* lplpSurface);

    STDMETHODIMP FreeSurface(DWORD_PTR dwUserID);
    STDMETHODIMP PrepareSurface(DWORD_PTR dwUserID,
                                LPDIRECTDRAWSURFACE7 lplpSurface,
                                DWORD dwSurfaceFlags);
    STDMETHODIMP AdviseNotify(IVMRSurfaceAllocatorNotify* lpIVMRSurfAllocNotify);

// IVMRImagePresenter
    STDMETHODIMP StartPresenting(DWORD_PTR dwUserID);
    STDMETHODIMP StopPresenting(DWORD_PTR dwUserID);
    STDMETHODIMP PresentImage(DWORD_PTR dwUserID, VMRPRESENTATIONINFO* lpPresInfo);

// IVMRWindowlessControl
public:
    STDMETHODIMP GetNativeVideoSize(LONG* lWidth, LONG* lHeight,
                                    LONG* lARWidth, LONG* lARHeight);
    STDMETHODIMP GetMinIdealVideoSize(LONG* lWidth, LONG* lHeight);
    STDMETHODIMP GetMaxIdealVideoSize(LONG* lWidth, LONG* lHeight);
    STDMETHODIMP SetVideoPosition(const LPRECT lpSRCRect, const LPRECT lpDSTRect);
    STDMETHODIMP GetVideoPosition(LPRECT lpSRCRect,LPRECT lpDSTRect);
    STDMETHODIMP GetAspectRatioMode(DWORD* lpAspectRatioMode);
    STDMETHODIMP SetAspectRatioMode(DWORD AspectRatioMode);

    STDMETHODIMP SetVideoClippingWindow(HWND hwnd);
    STDMETHODIMP RepaintVideo(HWND hwnd, HDC hdc);
    STDMETHODIMP DisplayModeChanged();
    STDMETHODIMP GetCurrentImage(BYTE** lpDib);

    STDMETHODIMP SetBorderColor(COLORREF Clr);
    STDMETHODIMP GetBorderColor(COLORREF* lpClr);
    STDMETHODIMP SetColorKey(COLORREF Clr);
    STDMETHODIMP GetColorKey(COLORREF* lpClr);

// IVMRMonitorConfig
public:
    STDMETHODIMP SetMonitor( const VMRGUID *pGUID );
    STDMETHODIMP GetMonitor( VMRGUID *pGUID );
    STDMETHODIMP SetDefaultMonitor( const VMRGUID *pGUID );
    STDMETHODIMP GetDefaultMonitor( VMRGUID *pGUID );
    STDMETHODIMP GetAvailableMonitors( VMRMONITORINFO* pInfo, DWORD dwMaxInfoArraySize,
                    DWORD* pdwNumDevices );

public:
    static void CALLBACK APHeartBeatTimerProc(UINT uID, UINT uMsg,
                                              DWORD_PTR dwUser,
                                              DWORD_PTR dw1, DWORD_PTR dw2);

    HRESULT TimerProc(); // needs to be called from a timer proc

public: // called by a callback, callback could be friend function instead
    bool            PaintMonitorBorder(
                      HMONITOR hMonitor,  // handle to display monitor
                      HDC hdcMonitor,     // handle to monitor DC
                      LPRECT lprcMonitor); // monitor intersection rectangle)
private:
    void            WaitForScanLine(const RECT& rcDst);

    HRESULT         TryAllocOverlaySurface(LPDIRECTDRAWSURFACE7* lplpSurf,
                                           DWORD dwFlags,
                                           DDSURFACEDESC2* pddsd,
                                           DWORD dwMinBackBuffers,
                                           DWORD dwMaxBackBuffers,
                                           DWORD* lpdwBuffer);

    HRESULT         TryAllocOffScrnDXVASurface(LPDIRECTDRAWSURFACE7* lplpSurf,
                                           DWORD dwFlags,
                                           DDSURFACEDESC2* pddsd,
                                           DWORD dwMinBackBuffers,
                                           DWORD dwMaxBackBuffers,
                                           DWORD* lpdwBuffer);

    HRESULT         TryAllocOffScrnSurface(LPDIRECTDRAWSURFACE7* lplpSurf,
                                           DWORD dwFlags,
                                           DDSURFACEDESC2* pddsd,
                                           DWORD dwMinBackBuffers,
                                           DWORD dwMaxBackBuffers,
                                           DWORD* lpdwBuffer,
                                           BOOL fAllowBackBuffer);

    HRESULT         AllocateSurfaceWorker(DWORD dwFlags,
                                          LPBITMAPINFOHEADER lpHdr,
                                          LPDDPIXELFORMAT lpPixFmt,
                                          LPSIZE lpAspectRatio,
                                          DWORD dwMinBackBuffers,
                                          DWORD dwMaxBackBuffers,
                                          DWORD* lpdwBackBuffer,
                                          LPDIRECTDRAWSURFACE7* lplpSurface,
                                          DWORD dwInterlaceFlags,
                                          LPSIZE lpNativeSize);

    HRESULT         BltImageToPrimary(LPDIRECTDRAWSURFACE7 lpSample,
                                      LPRECT lpDst, LPRECT lpSrc);

    HRESULT         PresentImageWorker(LPDIRECTDRAWSURFACE7 dwSurface,
                                       DWORD dwSurfaceFlags,
                                       BOOL fFlip);

    HRESULT         PaintColorKey();
    HRESULT         PaintBorder();
    HRESULT         PaintMonitorBorder();
    HRESULT         PaintMonitorBorderWorker(HMONITOR hMon, LPRECT lprcDst);
    static BOOL CALLBACK MonitorBorderProc(HMONITOR hMonitor,
                                           HDC hdcMonitor,
                                           LPRECT lprcMonitor,
                                           LPARAM dwData
                                           );

    void            WaitForFlipStatus();
    HRESULT         UpdateOverlaySurface();
    void            HideOverlaySurface();
    HRESULT         FlipSurface(LPDIRECTDRAWSURFACE7 lpSurface);

    static DWORD    MapColorToMonitor( CAMDDrawMonitorInfo& monitor, COLORREF clr );
    static void     ClipRectPair( RECT& rdSrc, RECT& rdDest, const RECT& rdDestWith );
    static void     AlignOverlayRects(const DDCAPS_DX7& ddCaps, RECT& rcSrc, RECT& rcDest);
    static bool     ShouldDisableOverlays(const DDCAPS_DX7& ddCaps, const RECT& rcSrc, const RECT& rcDest);
    HRESULT         CheckOverlayAvailable(LPDIRECTDRAWSURFACE7 lpSurface);

    bool MonitorChangeInProgress() {
        return m_lpNewMon != NULL;
    };
    bool FoundCurrentMonitor();

    bool IsDestRectOnWrongMonitor(CAMDDrawMonitorInfo** lplpNewMon);

    bool CanBltFourCCSysMem();
    bool CanBltSysMem();

    enum {UR_NOCHANGE = 0x00, UR_MOVE = 0x01, UR_SIZE = 0x02};
    DWORD UpdateRectangles(LPRECT lprcNewSrc, LPRECT lprcNewDst);
    HRESULT CheckDstRect(const LPRECT lpDSTRect);
    HRESULT CheckSrcRect(const LPRECT lpSRCRect);

    bool SurfaceAllocated();

private:
    CCritSec                m_ObjectLock;           // Controls access to internals

    // This lock is held when CAllocatorPresenter::DisplayModeChanged() is called.
    // It prevents multiple threads from simultaneously calling DisplayModeChanged().
    // It also prevents a thread from modifing m_monitors while DisplayModeChanged()
    // calls IVMRSurfaceAllocatorNotify::ChangeDDrawDevice().
    CCritSec                m_DisplayModeChangedLock;
    CMonitorArray           m_monitors;
    CAMDDrawMonitorInfo*    m_lpCurrMon;
    CAMDDrawMonitorInfo*    m_lpNewMon;
    BOOL                    m_bMonitorStraddleInProgress;
    BOOL                    m_bStreaming;
    UINT_PTR                m_uTimerID;
    int                     m_SleepTime;
    VMRGUID                 m_ConnectionGUID;
    LPDIRECTDRAWSURFACE7    m_pDDSDecode;

    IVMRSurfaceAllocatorNotify* m_pSurfAllocatorNotify;

    BOOL        m_fDDXclMode;   // true if being used in DDrawXcl mode
    BOOL        m_bDecimating;
    SIZE        m_VideoSizeAct; // actual size of video received from upstream

    SIZE        m_ARSize;       // aspect ratio of this video image

    RECT        m_rcDstDskIncl; // dst rect in desktop co-ordinates including borders
    RECT        m_rcDstDesktop; // dst rect in desktop co-ordinates may have been letterboxed


    RECT        m_rcDstApp;     // dst rect in apps co-ordinates
    RECT        m_rcSrcApp;     // src rect in adjusted video co-ordinates

    RECT        m_rcBdrTL;      // border rect top/left
    RECT        m_rcBdrBR;      // border rect bottom/right

    DWORD       m_dwARMode;
    HWND        m_hwndClip;

    COLORREF    m_clrBorder;
    COLORREF    m_clrKey;

    // true if decode surface can be flipped
    BOOL                m_bFlippable;
    BOOL                m_bSysMem;

    // color key fields for overlays
    BOOL                m_bDirectedFlips;
    BOOL                m_bOverlayVisible;
    BOOL                m_bDisableOverlays;
    BOOL                m_bUsingOverlays;
    DWORD               m_dwMappedColorKey;
    DWORD               m_dwRenderingPrefs;


    // interlace info
    //
    // m_dwInterlaceFlags is passed to us during the AllocateSurface routine.
    // This flag identifies the interlace mode we are currently in.
    //
    // m_dwCurrentField is either 0 (a non-interleaved sample), DDFLIP_ODD
    // or DDFLIP_EVEN.  This is the field that should currently be displayed.
    // If m_dwInterlaceFlags identifies that we are in an interleaved BOB mode,
    // this value will toggle during the "FlipOverlayToSelf" timer event.
    //
    // Note: as yet I have not found a way to show the correct field when in
    // interleaved BOB mode and not using the overlay.
    //
    DWORD               m_dwInterlaceFlags;
    DWORD               m_dwCurrentField;
    DWORD               m_dwUpdateOverlayFlags;
    VMRPRESENTATIONINFO m_PresInfo;
    DWORD               m_MMTimerId;

    DWORD GetUpdateOverlayFlags(DWORD dwInterlaceFlags,
                                DWORD dwTypeSpecificFlags);

    void CancelMMTimer();
    HRESULT ScheduleSampleUsingMMThread(VMRPRESENTATIONINFO* lpPresInfo);

    static void CALLBACK RenderSampleOnMMThread(UINT uID, UINT uMsg,
                                                DWORD_PTR dwUser,
                                                DWORD_PTR dw1, DWORD_PTR dw2);
    //
    // GetCurrentImage helper functions
    //

    HRESULT CreateRGBShadowSurface(
        LPDIRECTDRAWSURFACE7* lplpDDS,
        DWORD dwBitsPerPel,
        BOOL fSysMem,
        DWORD dwWidth,
        DWORD dwHeight
        );

    HRESULT HandleYUVSurface(
        const DDSURFACEDESC2& ddsd,
        LPDIRECTDRAWSURFACE7* lplpRGBSurf
        );

    HRESULT CopyRGBSurfToDIB(LPBYTE* lpDib, LPDIRECTDRAWSURFACE7 lpRGBSurf);

    HRESULT CopyIMCXSurf(LPDIRECTDRAWSURFACE7 lpRGBSurf, BOOL fInterleavedCbCr, BOOL fCbFirst);
    HRESULT CopyYV12Surf(LPDIRECTDRAWSURFACE7 lpRGBSurf, BOOL fInterleavedCbCr, BOOL fCbFirst);

    HRESULT CopyYUY2Surf(LPDIRECTDRAWSURFACE7 lpRGBSurf);
    HRESULT CopyUYVYSurf(LPDIRECTDRAWSURFACE7 lpRGBSurf);

};

inline bool CAllocatorPresenter::FoundCurrentMonitor()
{
    // m_lpCurrMon can be NULL if an error occurs while the CAllocatorPresenter
    // object is being created.  It can also be NULL if the call to
    // InitializeDisplaySystem() in DisplayModeChanged() fails.
    return NULL != m_lpCurrMon;
}

inline bool CAllocatorPresenter::SurfaceAllocated()
{
    return NULL != m_pDDSDecode;
}


inline bool CAllocatorPresenter::CanBltFourCCSysMem()
{
    if (m_lpCurrMon->ddHWCaps.dwSVBCaps & DDCAPS_BLTFOURCC) {
        return CanBltSysMem();
    }
    return false;
}


inline bool CAllocatorPresenter::CanBltSysMem()
{
    if (m_lpCurrMon->ddHWCaps.dwSVBCaps & DDCAPS_BLTSTRETCH) {

        const DWORD caps = DDFXCAPS_BLTSHRINKX | DDFXCAPS_BLTSHRINKX  |
                           DDFXCAPS_BLTSTRETCHX | DDFXCAPS_BLTSTRETCHY;

        if ((m_lpCurrMon->ddHWCaps.dwSVBFXCaps & caps) == caps) {
            return true;
        }
    }
    return false;
}
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\multimedia\dshow\filters\image2\ap\aptimer.cpp ===
/******************************Module*Header*******************************\
* Module Name: aptimer.cpp
*
* Heartbeat timer proc for the allocator/presenter.  Takes care of
* surface loss and restoration.  Notifies the VMR of a sucessful
* surface restore (via RestoreDDrawSurfaces on IVMRSurfaceAllocatorNotify).
*
*
* Created: Thu 09/07/2000
* Author:  Stephen Estrop [StEstrop]
*
* Copyright (c) 2000 Microsoft Corporation
\**************************************************************************/
#include <streams.h>
#include <dvdmedia.h>
#include <windowsx.h>
#include <limits.h>
#include <malloc.h>

#include "apobj.h"
#include "AllocLib.h"
#include "MediaSType.h"
#include "vmrp.h"


/******************************Public*Routine******************************\
* APHeartBeatTimerProc
*
*
*
* History:
* Wed 03/15/2000 - StEstrop - Created
*
\**************************************************************************/
void CALLBACK
CAllocatorPresenter::APHeartBeatTimerProc(
    UINT uID,
    UINT uMsg,
    DWORD_PTR dwUser,
    DWORD_PTR dw1,
    DWORD_PTR dw2
    )
{
    AMTRACE((TEXT("CAllocatorPresenter::APHeartBeatTimerProc")));
    CAllocatorPresenter* lp = (CAllocatorPresenter*)dwUser;
    lp->TimerProc();
}


/*****************************Private*Routine******************************\
* TimerProc
*
* Used to restore lost DDraw surfaces and also to make sure that the
* overlay (if used) is correctly positioned.
*
* History:
* Fri 03/17/2000 - StEstrop - Created
*
\**************************************************************************/
HRESULT
CAllocatorPresenter::TimerProc()
{
    AMTRACE((TEXT("CAllocatorPresenter::RestoreSurfaceIfNeeded")));
    CAutoLock Lock(&m_ObjectLock);

    if (m_lpCurrMon && m_lpCurrMon->pDDSPrimary) {

        if (m_lpCurrMon->pDDSPrimary->IsLost() == DDERR_SURFACELOST) {

            DbgLog((LOG_TRACE, 0, TEXT("Surfaces lost")));


            //
            // Restore all the surfaces for each monitor.
            //

            for (DWORD i = 0; i < m_monitors.Count(); i++) {

                if (m_monitors[i].pDD) {
                    HRESULT hr = m_monitors[i].pDD->RestoreAllSurfaces();
                    DbgLog((LOG_TRACE, 0,
                            TEXT("Restore for monitor %i = %#X"), i, hr));
                }
            }


            if (SurfaceAllocated() && m_pSurfAllocatorNotify) {

                DbgLog((LOG_TRACE, 0, TEXT("Notifying VMR")));

                PaintDDrawSurfaceBlack(m_pDDSDecode);

                m_ObjectLock.Unlock();
                m_pSurfAllocatorNotify->RestoreDDrawSurfaces();
                m_ObjectLock.Lock();

                if (m_bUsingOverlays && !m_bDisableOverlays) {

                    UpdateRectangles(NULL, NULL);
                    HRESULT hr = UpdateOverlaySurface();
                    if (SUCCEEDED(hr)) {
                        hr = PaintColorKey();
                    }

                    return S_OK;
                }
            }
        }

        if (SurfaceAllocated() &&
            m_bUsingOverlays && !m_bDisableOverlays) {

            if (UpdateRectangles(NULL, NULL)) {
                HRESULT hr = UpdateOverlaySurface();
                if (SUCCEEDED(hr)) {
                    hr = PaintColorKey();
                }
            }
        }
    }

    return S_OK;
}


/*****************************Private*Routine******************************\
* RenderSampleOnMMThread
*
*
*
* History:
* Wed 01/17/2001 - StEstrop - Created
*
\**************************************************************************/
void CALLBACK
CAllocatorPresenter::RenderSampleOnMMThread(
    UINT uID,
    UINT uMsg,
    DWORD_PTR dwUser,
    DWORD_PTR dw1,
    DWORD_PTR dw2
    )
{
    CAllocatorPresenter* lp = (CAllocatorPresenter*)dwUser;
    CAutoLock Lock(&lp->m_ObjectLock);

    LPDIRECTDRAWSURFACE7 lpDDS = lp->m_pDDSDecode;
    if (uID == lp->m_MMTimerId && lpDDS) {

        DWORD dwFlipFlag = DDFLIP_EVEN;

        if (lp->m_dwCurrentField == DDFLIP_EVEN) {
            dwFlipFlag = DDFLIP_ODD;
        }
        dwFlipFlag |= (DDFLIP_DONOTWAIT | DDFLIP_NOVSYNC);

        HRESULT hr = lpDDS->Flip(lpDDS, dwFlipFlag);
    }
}

/*****************************Private*Routine******************************\
* ScheduleSampleUsingMMThread
*
*
*
* History:
* Wed 01/17/2001 - StEstrop - Created
*
\**************************************************************************/
HRESULT
CAllocatorPresenter::ScheduleSampleUsingMMThread(
    VMRPRESENTATIONINFO* lpPresInfo
    )
{
    LONG lDelay = (LONG)ConvertToMilliseconds(lpPresInfo->rtEnd - lpPresInfo->rtStart);

    m_PresInfo = *lpPresInfo;
    if (lDelay > 0) {
        DbgLog((LOG_TRACE, 1, TEXT("lDelay = %d"), lDelay));
        m_MMTimerId = CompatibleTimeSetEvent(lDelay,
                                             1,
                                             RenderSampleOnMMThread,
                                             (DWORD_PTR)this,
                                             TIME_ONESHOT);
    }
    else {
        RenderSampleOnMMThread(0, 0, (DWORD_PTR)this, 0, 0);
    }

    return S_OK;
}

/*****************************Private*Routine******************************\
* CancelMMTimer
*
*
*
* History:
* Thu 01/18/2001 - StEstrop - Created
*
\**************************************************************************/
void
CAllocatorPresenter::CancelMMTimer()
{
    // kill the MMthread timer as well
    if (m_MMTimerId)
    {
        timeKillEvent(m_MMTimerId);

        CAutoLock cObjLock(&m_ObjectLock);
        m_MMTimerId = 0;
    }
}
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\multimedia\dshow\filters\image2\ap\apovly.cpp ===
/******************************Module*Header*******************************\
* Module Name: apovly.cpp
*
* Overlay support functions
*
*
* Created: Tue 09/19/2000
* Author:  Stephen Estrop [StEstrop]
*
* Copyright (c) 2000 Microsoft Corporation
\**************************************************************************/
#include <streams.h>
#include <dvdmedia.h>
#include <windowsx.h>
#include <limits.h>
#include <malloc.h>

#include "apobj.h"
#include "AllocLib.h"
#include "MediaSType.h"
#include "vmrp.h"



/*****************************Private*Routine******************************\
* GetUpdateOverlayFlags
*
* given the interlace flags and the type-specific flags, this function
* determines whether we are supposed to display the sample in bob-mode or not.
* It also tells us, which direct-draw flag are we supposed to use when
* flipping. When displaying an interleaved frame, it assumes we are
* talking about the field which is supposed to be displayed first.
*
* History:
* Mon 01/08/2001 - StEstrop - Created (from the OVMixer original)
*
\**************************************************************************/
DWORD
CAllocatorPresenter::GetUpdateOverlayFlags(
    DWORD dwInterlaceFlags,
    DWORD dwTypeSpecificFlags
    )
{
    AMTRACE((TEXT("CAllocatorPresenter::GetUpdateOverlayFlags")));

    //
    // early out if not using overlays.
    //
    if (!m_bUsingOverlays) {
        return 0;
    }

    DWORD dwFlags = DDOVER_SHOW | DDOVER_KEYDEST;
    DWORD dwFlipFlag;

    if (NeedToFlipOddEven(dwInterlaceFlags, dwTypeSpecificFlags,
                          &dwFlipFlag, m_bUsingOverlays))
    {
        dwFlags |= DDOVER_BOB;
        if (!IsSingleFieldPerSample(dwInterlaceFlags))
            dwFlags |= DDOVER_INTERLEAVED;
    }

    return dwFlags;
}


/******************************Private*Routine******************************\
* CAllocatorPresenter::ShouldDisableOverlays
*
* Certain src/dest combinations might not be valid for overlay
* stretching/alignments In these cases, we turn off the overlay and
* stretch blit to the primary
*
*
* History:
* Fri 04/07/2000 - GlennE - Created
*
\**************************************************************************/
bool
CAllocatorPresenter::ShouldDisableOverlays(
    const DDCAPS_DX7& ddCaps,
    const RECT& rcSrc,
    const RECT& rcDest
    )
{
    AMTRACE((TEXT("CAllocatorPresenter::ShouldDisableOverlays")));

    //
    // Unfortunately it is not always possible to Blt from an active
    // overlay.  So this "feature" needs to be disabled.
    //
    return false;

    DWORD dwSrcWidth = WIDTH(&rcSrc);
    DWORD dwSrcHeight = HEIGHT(&rcSrc);

    DWORD dwDestWidth = WIDTH(&rcDest);
    DWORD dwDestHeight = HEIGHT(&rcDest);

    // shrinking horizontally and driver can't arbitrarly shrink in X ?
    if ( 0==(ddCaps.dwFXCaps & DDFXCAPS_OVERLAYSHRINKX) &&
        dwSrcWidth > dwDestWidth )
    {
        return true;
    }

    // shrinking vertically and driver can't arbitrarly shrink in Y ?
    if ( 0==(ddCaps.dwFXCaps & DDFXCAPS_OVERLAYSHRINKY) &&
        dwSrcHeight > dwDestHeight ) {

        return true;
    }

    if( dwSrcWidth ) {
        // check to see if we're in the scaling range of the card
        DWORD dwScaleX = (DWORD) MulDiv( 1000, (int) dwDestWidth, (int) dwSrcWidth );
        if (ddCaps.dwMinOverlayStretch && dwScaleX < ddCaps.dwMinOverlayStretch ) {
            return true;
        }
        if (ddCaps.dwMaxOverlayStretch && dwScaleX > ddCaps.dwMaxOverlayStretch ) {
            return true;
        }
    }
    else {
        return true;
    }

    if( dwSrcHeight ) {
        DWORD dwScaleY = (DWORD) MulDiv( 1000, (int) dwDestHeight, (int) dwSrcHeight );

        if (ddCaps.dwMinOverlayStretch && dwScaleY < ddCaps.dwMinOverlayStretch ) {
            return true;
        }
        if (ddCaps.dwMaxOverlayStretch && dwScaleY > ddCaps.dwMaxOverlayStretch ) {
            return true;
        }
    }
    else {
        return true;
    }

    return false;
}

/******************************Private*Routine******************************\
* CAllocatorPresenter::AlignOverlayRects
*
* Adjust src & destination rectangles to hardware alignments
*
*
* History:
* Fri 04/07/2000 - GlennE - Created
*
\**************************************************************************/
void
CAllocatorPresenter::AlignOverlayRects(
    const DDCAPS_DX7& ddCaps,
    RECT& rcSrc,
    RECT& rcDest
    )
{
    // m_bDisableOverlays = !(m_dwRenderingPrefs & RenderPrefs_ForceOverlays) &&

    AMTRACE((TEXT("CAllocatorPresenter::AlignOverlayRects")));

    // precrop if we can't reduce scale
    {
        DWORD dwSrcWidth = WIDTH(&rcSrc);
        DWORD dwDestWidth = WIDTH(&rcDest);

        // shrinking horizontally and driver can't arbitrarly shrink in X ?
        if ((!(ddCaps.dwFXCaps & DDFXCAPS_OVERLAYSHRINKX)) && dwSrcWidth > dwDestWidth ) {
            // crop n copy at 1:1 scale
            dwSrcWidth = dwDestWidth;
        } else if( ddCaps.dwMinOverlayStretch ) {
            // check to see if we're in the scaling range of the card
            DWORD dwScaleX = (DWORD) MulDiv( 1000, (int) dwDestWidth, (int) dwSrcWidth );
            if ( dwScaleX < ddCaps.dwMinOverlayStretch ) {
                // compute fraction of dest to crop
                // at the minimum:
                // dest = src * (minOverlayStretch_1000/1000)
                // so
                //  src = dest * 1000 / (minOverlayStretch_1000 + eps)
                //
                // The EPS forces the rounding so that we'll be slightly over scale and not
                // underflow under the MinStretch
                dwSrcWidth = MulDiv( dwDestWidth, 1000,  ddCaps.dwMinOverlayStretch+1);
            }
        }

        DWORD dwSrcHeight = HEIGHT(&rcSrc);
        DWORD dwDestHeight = HEIGHT(&rcDest);

        // shrinking vertically and driver can't arbitrarly shrink in Y ?
        if ((!(ddCaps.dwFXCaps & DDFXCAPS_OVERLAYSHRINKY)) && dwSrcHeight > dwDestHeight ) {
            // crop n copy at 1:1 scale
            dwSrcHeight = dwDestHeight;
        } else if( ddCaps.dwMinOverlayStretch ) {

            // check to see if we're in the scaling range of the card
            DWORD dwScaleY = (DWORD) MulDiv(1000, (int) dwDestHeight, (int)dwSrcHeight);
            if (dwScaleY < ddCaps.dwMinOverlayStretch ) {
                // compute fraction of dest to crop
                // at the minimum:
                // dest = src * (minOverlayStretch_1000/1000)
                // so
                //  src = dest * 1000 / (minOverlayStretch_1000 + eps)
                //
                // The EPS forces the rounding so that we'll be slightly over scale and not
                // underflow under the MinStretch
                dwSrcHeight = MulDiv(dwDestHeight, 1000, ddCaps.dwMinOverlayStretch+1);
            }
        }

        // adjust rectangle to agree with new sizes
        rcSrc.right = rcSrc.left + dwSrcWidth;
        rcSrc.bottom = rcSrc.top + dwSrcHeight;
    }

    // align the dest boundary (remember we can only decrease the DestRect.left).
    // Use of colorkey will make sure that that we are clipped properly.
    if ((ddCaps.dwCaps) & DDCAPS_ALIGNBOUNDARYDEST)
    {
        DWORD dwDelta = rcDest.left & (ddCaps.dwAlignBoundaryDest-1);
        rcDest.left -= dwDelta;
        ASSERT(rcDest.left >= 0);
    }

    // align the dest width (remember we can only increase the DestRect.right).
    // Use of colorkey will make sure that that we are clipped properly.
    if ((ddCaps.dwCaps) & DDCAPS_ALIGNSIZEDEST)
    {
        DWORD dwDelta = (rcDest.right - rcDest.left) & (ddCaps.dwAlignSizeDest-1);
        if (dwDelta != 0)
        {
            rcDest.right += ddCaps.dwAlignBoundaryDest - dwDelta;
        }
    }

    // align the src boundary (remember we can only increase the SrcRect.left)
    if ((ddCaps.dwCaps) & DDCAPS_ALIGNBOUNDARYSRC)
    {
        DWORD dwDelta = rcSrc.left & (ddCaps.dwAlignBoundarySrc-1);
        if (dwDelta != 0)
        {
            rcSrc.left += ddCaps.dwAlignBoundarySrc - dwDelta;
        }
    }

    // align the src width (remember we can only decrease the SrcRect.right)
    if ((ddCaps.dwCaps) & DDCAPS_ALIGNSIZESRC)
    {
        DWORD dwDelta = (rcSrc.right - rcSrc.left) & (ddCaps.dwAlignSizeSrc-1);
        rcSrc.right -= dwDelta;
    }
}


/******************************Private*Routine******************************\
* WaitForFlipStatus
*
* Wait until the flip completes
*
*
* History:
* Fri 04/07/2000 - GlennE - Created
*
\**************************************************************************/
void
CAllocatorPresenter::WaitForFlipStatus()
{
#if 0
    ASSERT( m_lpCurrMon->pOverlayBack );
    while (m_lpCurrMon->pOverlayBack->GetFlipStatus(DDGFS_ISFLIPDONE) == DDERR_WASSTILLDRAWING)
        Sleep(0);
#endif
}

/******************************Private*Routine******************************\
* HideOverlaySurface
*
* Hides the overlay surface
*
*
* History:
* Fri 04/07/2000 - GlennE - Created
*
\**************************************************************************/
void
CAllocatorPresenter::HideOverlaySurface()
{
    AMTRACE((TEXT("CAllocatorPresenter::HideOverlaySurface")));

    // Is the overlay already hidden
    if (m_bOverlayVisible && FoundCurrentMonitor() && SurfaceAllocated()) {

        // Reset our state and draw a normal background

        m_bOverlayVisible = false;
        WaitForFlipStatus();

        // Hide the overlay with the DDOVER_HIDE flag
        m_pDDSDecode->UpdateOverlay(NULL,
                                    m_lpCurrMon->pDDSPrimary,
                                    NULL,  		
                                    DDOVER_HIDE,
                                    NULL);
    }
}

/******************************Private*Routine******************************\
* CAllocatorPresenter::UpdateOverlaySurface
*
* Update the overlay surface to position it correctly.
*
* History:
* Fri 04/07/2000 - GlennE - Created
*
\**************************************************************************/
HRESULT
CAllocatorPresenter::UpdateOverlaySurface()
{
    AMTRACE((TEXT("CAllocatorPresenter::UpdateOverlaySurface")));
    CAutoLock Lock(&m_ObjectLock);

    ASSERT(m_bUsingOverlays);

    if (!m_lpCurrMon) {
        DbgLog((LOG_ERROR, 1, TEXT("No current monitor")));
        return E_FAIL;
    }

    if (!SurfaceAllocated()) {
        DbgLog((LOG_ERROR, 1, TEXT("No overlay surface")));
        return E_FAIL;
    }

    HRESULT hr = NOERROR;

    // Position the overlay with the current source and destination

    RECT rcDest = m_rcDstDesktop;
    RECT rcSrc = m_rcSrcApp;

    // clip destination & adjust source to mirror destination changes
    ClipRectPair(rcSrc, rcDest, m_lpCurrMon->rcMonitor);

    if (IsSingleFieldPerSample(m_dwInterlaceFlags)) {
        rcSrc.top /= 2;
        rcSrc.bottom /= 2;
    }

    if (m_bDecimating) {
        rcSrc.left    /= 2;
        rcSrc.top     /= 2;
        rcSrc.right   /= 2;
        rcSrc.bottom  /= 2;
    }

    if (m_bDisableOverlays || IsRectEmpty(&rcDest)) {

        HideOverlaySurface();

    }
    else if (!IsRectEmpty(&rcSrc)) {

        OffsetRect(&rcDest,
                   -m_lpCurrMon->rcMonitor.left,
                   -m_lpCurrMon->rcMonitor.top);

        // align it
        AlignOverlayRects( m_lpCurrMon->ddHWCaps, rcSrc, rcDest );

        if (!IsRectEmpty(&rcDest) && !IsRectEmpty( &rcSrc)) {

            WaitForFlipStatus();

            hr = m_pDDSDecode->UpdateOverlay(&rcSrc,
                                             m_lpCurrMon->pDDSPrimary,
                                             &rcDest,
                                             m_dwUpdateOverlayFlags,
                                             NULL);
            m_bOverlayVisible = true;
            ASSERT(hr != DDERR_WASSTILLDRAWING);
        }
        else {
            HideOverlaySurface();
        }

    }
    else {

        ASSERT( !"This shouldn't occur" );
        hr = E_FAIL;
    }

    return hr;
}

/******************************Private*Routine******************************\
* CAllocatorPresenter::FlipSurface
*
* Flip the back buffer to the visible primary
*
*
* History:
* Fri 04/07/2000 - GlennE - Created
*
\**************************************************************************/

HRESULT CAllocatorPresenter::FlipSurface(
    LPDIRECTDRAWSURFACE7 lpSurface
    )
{
    AMTRACE((TEXT("CAllocatorPresenter::FlipSurface")));
    HRESULT hr;

    if (!m_bFlippable)
        return S_OK;

    do  {

        ASSERT( SurfaceAllocated() );

        if (m_bDirectedFlips) {
            hr = m_pDDSDecode->Flip(lpSurface, m_dwCurrentField);
        }
        else {
            hr = m_pDDSDecode->Flip(NULL, m_dwCurrentField);
        }

        if (hr == DDERR_WASSTILLDRAWING) {
            // yield to the next thread
            Sleep(0);
        }

    } while(hr == DDERR_WASSTILLDRAWING);

    if (m_pSurfAllocatorNotify) {
        m_pSurfAllocatorNotify->NotifyEvent(EC_VMR_SURFACE_FLIPPED, hr, 0);
    }

    return hr;
}

/******************************Private*Routine******************************\
* CAllocatorPresenter::CheckOverlayAvailable
*
* Attempt to move the overlay so we can see if we can allocate it.
* We'll try to move it quickly as a small square at 0,0.  The AllocatorPuts
* it there anyways.  The user won't see much since its dest color keyed and
* we haven't painted the colour key yet
*
*
* History:
* Fri 04/07/2000 - GlennE - Created
*
\**************************************************************************/
HRESULT
CAllocatorPresenter::CheckOverlayAvailable(
    LPDIRECTDRAWSURFACE7 lpSurface7
    )
{
    AMTRACE((TEXT("CAllocatorPresenter::CheckOverlayAvailable")));
    const DWORD cxVideoSize = 64;// ATI doesn't seem to like 1x1 overlay surfaces
    const DWORD cyVideoSize = 64;

    RECT rcSrc, rcDest;
    SetRect(&rcDest, 0, 0, cxVideoSize, cyVideoSize);
    rcSrc = rcDest;

    AlignOverlayRects(m_lpCurrMon->ddHWCaps, rcSrc, rcDest);
    HRESULT hr = lpSurface7->UpdateOverlay(&rcSrc,
                                           m_lpCurrMon->pDDSPrimary,
                                           &rcDest,
                                           DDOVER_SHOW | DDOVER_KEYDEST,
                                           NULL);
    return hr;
}
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\multimedia\dshow\filters\image2\ap\display.h ===
/******************************Module*Header*******************************\
* Module Name: display.h
*
*
*
*
* Created: Mon 01/24/2000
* Author:  Stephen Estrop [StEstrop]
*
* Copyright (c) 2000 Microsoft Corporation
\**************************************************************************/

#define AMDDRAWMONITORINFO_PRIMARY_MONITOR          0x0001

typedef struct {
    BITMAPINFOHEADER    bmiHeader;
    union {
        RGBQUAD         bmiColors[iPALETTE_COLORS];
        DWORD           dwBitMasks[iMASK_COLORS];
        TRUECOLORINFO   TrueColorInfo;
    };
} AMDISPLAYINFO;

struct CAMDDrawMonitorInfo : public VMRMONITORINFO
{
    DDCAPS_DX7              ddHWCaps;
    AMDISPLAYINFO           DispInfo;
    LPDIRECTDRAW7           pDD;
    LPDIRECTDRAWSURFACE7    pDDSPrimary;    // DDraw Primary Surface
    DWORD                   dwMappedBdrClr; // Border clr mapped to this monitor
};



#ifndef MAX_MONITORS
#define MAX_MONITORS    4
#endif

class CMonitorArray
{
public:
    CMonitorArray();
    ~CMonitorArray();

    HRESULT                 InitializeDisplaySystem( HWND hwnd );
    HRESULT                 InitializeXclModeDisplaySystem(
                                    HWND hwnd,
                                    LPDIRECTDRAW7 lpDD,
                                    LPDIRECTDRAWSURFACE7 lpPS);

    void                    TerminateDisplaySystem();
    CAMDDrawMonitorInfo*    FindMonitor( HMONITOR hMon );
    HRESULT                 MatchGUID( const GUID* lpGUID, DWORD* pdwMatchID );


    CAMDDrawMonitorInfo&    operator[](int i)
                            { return m_DDMon[i]; }
    DWORD                   Count() const
                            { return m_dwNumMonitors; }
private:
    DWORD                   m_dwNumMonitors;
    CAMDDrawMonitorInfo     m_DDMon[MAX_MONITORS];
};
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\multimedia\dshow\filters\image2\ap\thunkproc.h ===
/*************************************************************************/
/* Copyright (C) 1999 Microsoft Corporation                              */
/* File: ThunkProc.h                                                     */
/* Description: In order to get rid of the thread. Which causes problems */
/* since we have to marshal we use this timer stuff from ATL.            */
/* The basic problem is that we would like to have a timer associated    */
/* with an object and this is a way to do so                             */
/* Author: David Janecek                                                 */
/*************************************************************************/

#ifndef __THUNKPROC_H
#define __THUNKPROC_H

//this nasty stuff was taken from "AtlWin.h"
#if defined(_M_IX86)
#pragma pack(push,1)
struct _TimerProcThunk
{
    DWORD   m_mov;          // mov dword ptr [esp+0x4], pThis (esp+0x4 is hWnd)
    DWORD   m_this;         //
    BYTE    m_jmp;          // jmp WndProc
    DWORD   m_relproc;      // relative jmp
};
#pragma pack(pop)
#elif defined (_M_AMD64)
#pragma pack(push,2)
struct _TimerProcThunk
{
    USHORT  RcxMov;         // mov rcx, pThis
    ULONG64 RcxImm;         //
    USHORT  RaxMov;         // mov rax, target
    ULONG64 RaxImm;         //
    USHORT  RaxJmp;         // jmp target
};
#pragma pack(pop)
#elif defined (_M_IA64)
#pragma pack(push,8)
extern "C" LRESULT CALLBACK _TimerProcThunkProc( HWND hwnd, UINT uMsg, UINT_PTR idEvent, DWORD dwTime);
struct _TimerFuncDesc
{
   void* pfn;
   void* gp;
};
struct _TimerProcThunk
{
   _TimerFuncDesc funcdesc;
   void* pRealTimerProcDesc;
   void* pThis;
};
extern "C" LRESULT CALLBACK _TimerProcThunkProc( HWND hwnd, UINT uMsg, UINT_PTR idEvent, DWORD dwTime);
#pragma pack(pop)
#else
#error Only AMD64, IA64, and X86 supported
#endif

class CTimerProcThunk
{
public:
    _TimerProcThunk thunk;

    void Init(TIMERPROC proc, void* pThis)
    {
#if defined (_M_IX86)
        thunk.m_mov = 0x042444C7;  //C7 44 24 0C
        thunk.m_this = (DWORD)pThis;
        thunk.m_jmp = 0xe9;
        thunk.m_relproc = (int)proc - ((int)this+sizeof(_TimerProcThunk));
#elif defined (_M_AMD64)
        thunk.RcxMov = 0xb948;          // mov rcx, pThis
        thunk.RcxImm = (ULONG64)pThis;  //
        thunk.RaxMov = 0xb848;          // mov rax, target
        thunk.RaxImm = (ULONG64)proc;   // absolute address
        thunk.RaxJmp = 0xe0ff;          // jmp rax
#elif defined (_M_IA64)
        _TimerFuncDesc* pFuncDesc;
        pFuncDesc = (_TimerFuncDesc*)_TimerProcThunkProc;
        thunk.funcdesc.pfn = pFuncDesc->pfn;
        thunk.funcdesc.gp = &thunk.pRealTimerProcDesc;  // Set gp up to point to our thunk data
        thunk.pRealTimerProcDesc = proc;
        thunk.pThis = pThis;
#endif
        // write block from data cache and
        //  flush from instruction cache
        FlushInstructionCache(GetCurrentProcess(), &thunk, sizeof(thunk));
    }
};

template <class T>
class  CMSDVDTimer {
private:
    CTimerProcThunk   m_TimerThunk;
    HWND            m_hwnd;

/*************************************************************************/
/* Function: FakeTimerProc                                               */
/*************************************************************************/
static void CALLBACK FakeTimerProc(HWND hwnd, UINT uMsg, UINT_PTR idEvent, DWORD dwTime){

    CMSDVDTimer* pThis = (CMSDVDTimer*)hwnd;
    pThis->RealTimerProc(pThis->m_hwnd, uMsg, idEvent, dwTime);
}/* end of function FakeTimerProc */

/*************************************************************************/
/* Function: RealTimerProc                                               */
/*************************************************************************/
void RealTimerProc(HWND hwnd, UINT uMsg, UINT_PTR idEvent, DWORD dwTime){

    T* pT = static_cast<T*>(this);

    if(NULL == pT){

        return;
    }/* end of if statement */

    pT->TimerProc();
}/* end of function RealTimerProc */

public:
/*************************************************************************/
/* Function: MyTimerClass                                                */
/*************************************************************************/
CMSDVDTimer(HWND hwnd = (HWND)NULL){

    m_hwnd = hwnd;
    m_TimerThunk.Init(FakeTimerProc, this);
}/* end of function MyTimerClass */

/*************************************************************************/
/* Function: GetTimerProc                                                */
/*************************************************************************/
TIMERPROC GetTimerProc() {

    return (TIMERPROC)&(m_TimerThunk.thunk);
}/* end of function GetTimerProc */

};

#endif // __THUNKPROC_H
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\multimedia\dshow\filters\image2\ap\display.cpp ===
/******************************Module*Header*******************************\
* Module Name: display.cpp
*
* Support for DDraw device on Multiple Monitors.
*
*
* Created: Mon 01/24/2000
* Author:  Stephen Estrop [StEstrop]
*
* Copyright (c) 2000 Microsoft Corporation
\**************************************************************************/
#include <streams.h>
#include <windowsx.h>
#include <atlconv.h>
#include <limits.h>

#include <ddraw.h>
#include <vmrp.h>

#include "AllocLib.h"
#include "apobj.h"


/* -------------------------------------------------------------------------
** Structure use to pass info to the DDrawEnumEx callback
** -------------------------------------------------------------------------
*/

struct DDRAWINFO {
    DWORD               dwCount;
    DWORD               dwPmiSize;
    HRESULT             hrCallback;
    const GUID*         pGUID;
    CAMDDrawMonitorInfo* pmi;
    HWND                hwnd;
};

const WCHAR  szDisplay[] = L"DISPLAY";
const WCHAR  szDesc[]    = L"Primary Display Driver";


/******************************Public*Routine******************************\
* TermDDrawMonitorInfo
*
*
*
* History:
* 01-17-2000 - StEstrop - Created
*
\**************************************************************************/
void
TermDDrawMonitorInfo(
    CAMDDrawMonitorInfo* pmi
    )
{
    AMTRACE((TEXT("TermDDrawMonitorInfo")));
    RELEASE(pmi->pDDSPrimary);
    RELEASE(pmi->pDD);

    ZeroMemory(pmi, sizeof(VMRMONITORINFO));
}


/******************************Public*Routine******************************\
* InitDDrawMonitorInfo
*
*
*
* History:
* 01-17-2000 - StEstrop - Created
*
\**************************************************************************/
HRESULT
InitDDrawMonitorInfo(
    CAMDDrawMonitorInfo* pmi,
    HWND hwnd,
    BOOL fXclMode
    )
{
    AMTRACE((TEXT("InitDDrawMonitorInfo")));

    //
    // Create DirectDraw object
    //

    HRESULT hRet = DD_OK;
    LPDIRECTDRAWCLIPPER lpDrawClipper = NULL;

    __try {

        if (!fXclMode) {

            CHECK_HR(hRet = DirectDrawCreateEx(pmi->guid.pGUID,
                                               (LPVOID *)&pmi->pDD,
                                               IID_IDirectDraw7, NULL));

            CHECK_HR(hRet = pmi->pDD->SetCooperativeLevel(NULL,
                                            DDSCL_FPUPRESERVE | DDSCL_NORMAL));

            //
            // Create the primary surface and the clipper
            //

            DDSURFACEDESC2 ddsd;  // A surface description structure
            INITDDSTRUCT(ddsd);

            ddsd.dwFlags = DDSD_CAPS;
            ddsd.ddsCaps.dwCaps = DDSCAPS_PRIMARYSURFACE;
            CHECK_HR(hRet = pmi->pDD->CreateSurface(&ddsd, &pmi->pDDSPrimary, NULL));
        }

        INITDDSTRUCT(pmi->ddHWCaps);
        CHECK_HR( hRet = pmi->pDD->GetCaps((LPDDCAPS)&pmi->ddHWCaps, NULL) );

        //DDDEVICEIDENTIFIER2 did;
        //CHECK_HR( hRet = pmi->pDD->GetDeviceIdentifier(&did, 0));
        //pmi->liDriverVersion = did.liDriverVersion;
        //pmi->dwVendorId = did.dwVendorId;
        //pmi->dwDeviceId = did.dwDeviceId;
        //pmi->dwSubSysId = did.dwSubSysId;
        //pmi->dwRevision = did.dwRevision;

        CHECK_HR( hRet = pmi->pDD->CreateClipper((DWORD)0, &lpDrawClipper, NULL) );

        if (hwnd)
        {
            CHECK_HR( hRet = lpDrawClipper->SetHWnd(0, hwnd) );
        }

        CHECK_HR( hRet = pmi->pDDSPrimary->SetClipper(lpDrawClipper) );
    }
    __finally {

        //
        // release the local instance of the clipper - if SetClipper succeeded,
        // it got AddRef'd. In case of error, it did not and goes away here
        //

        RELEASE(lpDrawClipper);
        if (hRet != DD_OK) {
            TermDDrawMonitorInfo(pmi);
        }
    }

    return hRet;
}


/*****************************Private*Routine******************************\
* GetAMDDrawMonitorInfo
*
*
*
* History:
* Tue 08/17/1999 - StEstrop - Created
*
\**************************************************************************/
BOOL
GetAMDDrawMonitorInfo(
    const GUID* pGUID,
    LPCWSTR lpDriverDesc,
    LPCWSTR lpDriverName,
    CAMDDrawMonitorInfo* lpmi,
    HMONITOR hm
    )
{
    AMTRACE((TEXT("GetAMDDrawMonitorInfo")));

    MONITORINFOEX miInfoEx;
    miInfoEx.cbSize = sizeof(miInfoEx);

    lstrcpynW(lpmi->szDevice, lpDriverName, NUMELMS(lpmi->szDevice) );
    lstrcpynW(lpmi->szDescription, lpDriverDesc, NUMELMS(lpmi->szDescription) );


    HDC hdcDisplay;

    USES_CONVERSION;
    if (lstrcmpiW(lpDriverName, szDisplay) == 0) {
        hdcDisplay = CreateDC(W2CT(szDisplay), NULL, NULL, NULL);
    }
    else {
        hdcDisplay = CreateDC(NULL, W2CT(lpDriverName), NULL, NULL);
    }

    if (hdcDisplay == NULL) {
        ASSERT(FALSE);
        DbgLog((LOG_ERROR,1,TEXT("Can't get a DC for %hs"), lpDriverName));
        return FALSE;
    } else {
        DbgLog((LOG_TRACE,3,TEXT("Created a DC for %hs"), lpDriverName));
    }

    ZeroMemory(&lpmi->DispInfo, sizeof(lpmi->DispInfo));
    HBITMAP hbm = CreateCompatibleBitmap(hdcDisplay, 1, 1);
    if (!hbm) {
        DbgLog((LOG_ERROR,1,TEXT("Can't create a compatible bitmap for %hs"),
                lpDriverName));
        DeleteDC(hdcDisplay);
        return FALSE;
    }

    lpmi->DispInfo.bmiHeader.biSize = sizeof(BITMAPINFOHEADER);
    GetDIBits(hdcDisplay, hbm, 0, 1, NULL, (BITMAPINFO *)&lpmi->DispInfo, DIB_RGB_COLORS);
    GetDIBits(hdcDisplay, hbm, 0, 1, NULL, (BITMAPINFO *)&lpmi->DispInfo, DIB_RGB_COLORS);

    DeleteObject(hbm);
    DeleteDC(hdcDisplay);

    if (pGUID == NULL) {
        lpmi->hMon = MonitorFromWindow(HWND_DESKTOP, MONITOR_DEFAULTTOPRIMARY);
        lpmi->dwFlags = MONITORINFOF_PRIMARY;
        lpmi->guid.pGUID = NULL;

        SetRect(&lpmi->rcMonitor, 0, 0,
                GetSystemMetrics(SM_CXSCREEN),
                GetSystemMetrics(SM_CYSCREEN));

        lpmi->guid.GUID = GUID_NULL;
    }
    else if (GetMonitorInfo(hm, &miInfoEx)) {
        lpmi->dwFlags = miInfoEx.dwFlags;
        lpmi->rcMonitor = miInfoEx.rcMonitor;
        lpmi->hMon = hm;
        lpmi->guid.pGUID = &lpmi->guid.GUID;
        lpmi->guid.GUID = *pGUID;
    }
    else return FALSE;

    return TRUE;
}



/*****************************Private*Routine******************************\
* DDEnumCallbackEx
*
*
*
* History:
* Fri 08/13/1999 - StEstrop - Created
*
\**************************************************************************/
BOOL WINAPI
DDEnumCallbackExW(
    GUID *pGUID,
    LPWSTR lpDriverDesc,
    LPWSTR lpDriverName,
    LPVOID lpContext,
    HMONITOR  hm
    )
{
    AMTRACE((TEXT("DDEnumCallbackEx")));

    DDRAWINFO* lpDDInfo = (DDRAWINFO*)lpContext;

    if (lpDDInfo->dwCount < lpDDInfo->dwPmiSize) {
        if (GetAMDDrawMonitorInfo(pGUID,
                                  lpDriverDesc,
                                  lpDriverName,
                                  &lpDDInfo->pmi[lpDDInfo->dwCount],
                                  hm))
        {
            lpDDInfo->hrCallback = InitDDrawMonitorInfo(
                &lpDDInfo->pmi[lpDDInfo->dwCount],
                lpDDInfo->hwnd,
                FALSE);

            if (FAILED(lpDDInfo->hrCallback))
            {
                return FALSE;
            }

            lpDDInfo->dwCount++;
        }
    }

    return TRUE;
}

#define CCHDEVICEDESCRIPTION  256

BOOL WINAPI
DDEnumCallbackExA(
    GUID *pGUID,
    LPSTR lpDriverDesc,
    LPSTR lpDriverName,
    LPVOID lpContext,
    HMONITOR  hm
    )
{
    USES_CONVERSION;

    BOOL b = DDEnumCallbackExW(pGUID,
                               A2W(lpDriverDesc),
                               A2W(lpDriverName),
                               lpContext,
                               hm);
    return b;
}

/*****************************Private*Routine******************************\
* InitializeDisplaySystem
*
*
*
* History:
* Mon 01/24/2000 - StEstrop - Created
*
\**************************************************************************/
HRESULT
CMonitorArray::InitializeDisplaySystem(
    HWND hwnd
    )
{
    AMTRACE((TEXT("CMonitorArray::InitializeDisplaySystem")));

    HRESULT hr;
    m_dwNumMonitors = 0;
    if (GetSystemMetrics(SM_CMONITORS) <= 1)
    {
        BOOL ok = GetAMDDrawMonitorInfo(NULL, szDesc, szDisplay,
                                    &m_DDMon[0],
                                    MonitorFromWindow(HWND_DESKTOP,
                                                      MONITOR_DEFAULTTONEAREST));
        if (!ok) {
            return E_FAIL;
        }
        hr = InitDDrawMonitorInfo(&m_DDMon[0], hwnd, FALSE);
        m_dwNumMonitors = 1;
    }
    else {

        DDRAWINFO DDrawInfo;
        DDrawInfo.dwCount = 0;
        DDrawInfo.dwPmiSize = NUMELMS( m_DDMon );
        DDrawInfo.pmi = m_DDMon;
        DDrawInfo.hwnd = hwnd;
        DDrawInfo.hrCallback = S_OK;

        hr = DirectDrawEnumerateExW(DDEnumCallbackExW,
                                    (LPVOID)&DDrawInfo,
                                    DDENUM_ATTACHEDSECONDARYDEVICES);
        if( FAILED(hr)) {
            hr = DirectDrawEnumerateExA(DDEnumCallbackExA,
                                        (LPVOID)&DDrawInfo,
                                        DDENUM_ATTACHEDSECONDARYDEVICES);
        }

        if (SUCCEEDED(hr)) {
            if (SUCCEEDED(DDrawInfo.hrCallback)) {
                m_dwNumMonitors = DDrawInfo.dwCount;
            }
            else {
                hr = DDrawInfo.hrCallback;
            }
        }
    }

    return hr;
}

/******************************Public*Routine******************************\
* InitializeXclModeDisplaySystem
*
*
*
* History:
* Thu 04/05/2001 - StEstrop - Created
*
\**************************************************************************/
HRESULT
CMonitorArray::InitializeXclModeDisplaySystem(
    HWND hwnd,
    LPDIRECTDRAW7 lpDD,
    LPDIRECTDRAWSURFACE7 lpPS
    )
{
    AMTRACE((TEXT("CMonitorArray::InitializeXclModeDisplaySystem]")));


    HRESULT hr = S_OK;
    __try {

        DDSURFACEDESC2 ddsd = {sizeof(DDSURFACEDESC2)};
        CHECK_HR(hr = lpDD->GetDisplayMode(&ddsd));

        CAMDDrawMonitorInfo* lpmi = &m_DDMon[0];

        //
        // fix up the monitor stuff
        //
        lpmi->hMon = MonitorFromWindow(hwnd, MONITOR_DEFAULTTOPRIMARY);
        lpmi->dwFlags = 0;
        lpmi->guid.pGUID = NULL;
        SetRect(&lpmi->rcMonitor, 0, 0, ddsd.dwWidth, ddsd.dwHeight);

        LPBITMAPINFOHEADER lpbi = &lpmi->DispInfo.bmiHeader;

        lpbi->biSize = sizeof(lpmi->DispInfo.bmiHeader);
        lpbi->biWidth = ddsd.dwWidth;
        lpbi->biHeight = ddsd.dwHeight;
        lpbi->biHeight = ddsd.dwHeight;
        lpbi->biPlanes = 1;
        lpbi->biBitCount = (WORD)ddsd.ddpfPixelFormat.dwRGBBitCount;
        lpbi->biClrUsed = 0;
        lpbi->biClrImportant = 0;


        lpbi->biCompression = ddsd.ddpfPixelFormat.dwFourCC;
        lpbi->biSizeImage = DIBSIZE(*lpbi);

        if (lpbi->biCompression == BI_RGB) {

            if (lpbi->biBitCount == 16 &&
                ddsd.ddpfPixelFormat.dwGBitMask == 0x7E0) {
                lpbi->biCompression = BI_BITFIELDS;
            }

            if (lpbi->biBitCount == 32) {
                lpbi->biCompression = BI_BITFIELDS;
            }
        }


        if (lpbi->biCompression != BI_RGB) {
            lpmi->DispInfo.dwBitMasks[0] = ddsd.ddpfPixelFormat.dwRBitMask;
            lpmi->DispInfo.dwBitMasks[1] = ddsd.ddpfPixelFormat.dwGBitMask;
            lpmi->DispInfo.dwBitMasks[2] = ddsd.ddpfPixelFormat.dwBBitMask;
        }

        //
        // initialize the DDraw stuff
        //
        lpDD->AddRef();
        lpmi->pDD = lpDD;

        lpPS->AddRef();
        lpmi->pDDSPrimary = lpPS;

        CHECK_HR(hr = InitDDrawMonitorInfo(&m_DDMon[0], hwnd, TRUE));
        m_dwNumMonitors = 1;
    }
    __finally {

        if (FAILED(hr)) {
            TerminateDisplaySystem();
        }
    }

    return hr;
}


/*****************************Private*Routine******************************\
* FindMonitor
*
* find the current monitor
*
* History:
* Fri 04/25/2000 - GlennE - Created
*
\**************************************************************************/
CAMDDrawMonitorInfo*
CMonitorArray::FindMonitor(
     HMONITOR hMon
    )
{
    AMTRACE((TEXT("CMonitorArray::FindMonitor")));
    for (DWORD i = 0; i < m_dwNumMonitors; i++) {

        if (hMon == m_DDMon[i].hMon ) {
            return &m_DDMon[i];
        }
    }
    DbgLog((LOG_TRACE, 3, TEXT("Find monitor not found") ));
    return NULL;
}

/*****************************Private*Routine******************************\
* MatchGUID
*
*
*
* History:
* Fri 04/25/2000 - GlennE - Created
*
\**************************************************************************/
HRESULT
CMonitorArray::MatchGUID(
    const GUID* pGUID,
    DWORD* pdwMatchID
    )
{
    AMTRACE((TEXT("CMonitorArray::MatchGUID")));
    for (DWORD i = 0; i < m_dwNumMonitors; i++) {

        const GUID* pMonGUID = m_DDMon[i].guid.pGUID;

        if ((pMonGUID == NULL && pGUID == NULL) ||
            (pMonGUID && pGUID && IsEqualGUID(*pGUID, *pMonGUID))) {

            *pdwMatchID = i;
            return S_OK;
        }
    }

    return S_FALSE;
}

CMonitorArray::CMonitorArray()
: m_dwNumMonitors( 0 )
{
    AMTRACE((TEXT("CMonitorArray::CMonitorArray")));
    ZeroMemory(m_DDMon, sizeof(m_DDMon));
}

/*****************************Private*Routine******************************\
* TerminateDisplaySystem
*
*
*
* History:
* Mon 01/24/2000 - StEstrop - Created
*
\**************************************************************************/
void CMonitorArray::TerminateDisplaySystem()
{
    AMTRACE((TEXT("CMonitorArray::TerminateDisplaySystem")));

    for (DWORD i = 0; i < m_dwNumMonitors; i++) {
        TermDDrawMonitorInfo(&m_DDMon[i]);
    }
    m_dwNumMonitors = 0;
}

CMonitorArray::~CMonitorArray()
{
    AMTRACE((TEXT("CMonitorArray::~CMonitorArray")));
    TerminateDisplaySystem();
}
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\multimedia\dshow\filters\image2\core\imagesync.cpp ===
/******************************Module*Header*******************************\
* Module Name: ImageSync.cpp
*
* Implementation of DLL Exports.  This file was create by the ATL wizard !!
*
*
* Created: Wed 01/12/2000
* Author:  Stephen Estrop [StEstrop]
*
* Copyright (c) 2000 Microsoft Corporation
\**************************************************************************/
#include <streams.h>
#include <windowsx.h>
#include <limits.h>

#ifdef FILTER_DLL
#include <initguid.h>
#include <perfstruct.h>
#endif

#include "imagesyncobj.h"
#include "VMRuuids.h"

#if defined(CHECK_FOR_LEAKS)
#include "ifleak.h"
#endif

#ifdef FILTER_DLL
STDAPI DllRegisterServer()
{
    AMTRACE((TEXT("DllRegisterServer")));
    return AMovieDllRegisterServer2( TRUE );
}

STDAPI DllUnregisterServer()
{
    AMTRACE((TEXT("DllUnregisterServer")));
    return AMovieDllRegisterServer2( FALSE );
}

CFactoryTemplate g_Templates[] = {
    {
        L"",
        &CLSID_ImageSynchronization,
        CImageSync::CreateInstance,
        CImageSync::InitClass,
        NULL
    }
};
int g_cTemplates = sizeof(g_Templates) / sizeof(g_Templates[0]);
#endif

/******************************Public*Routine******************************\
* InitClass
*
*
*
* History:
* Thu 12/14/2000 - StEstrop - Created
*
\**************************************************************************/
#if defined(CHECK_FOR_LEAKS)
// the one and only g_IFLeak object.
CInterfaceLeak  g_IFLeak;

void
CImageSync::InitClass(
    BOOL bLoading,
    const CLSID *clsid
    )
{
    if (bLoading) {
        DbgLog((LOG_TRACE, 0, TEXT("ImageSync Thunks: Loaded") ));
        g_IFLeak.Init();
    }
    else {
        DbgLog((LOG_TRACE, 0, TEXT("ImageSync Thunks: Unloaded") ));
        g_IFLeak.Term();
    }
}
#else
void
CImageSync::InitClass(
    BOOL bLoading,
    const CLSID *clsid
    )
{
}
#endif

CUnknown* CImageSync::CreateInstance(LPUNKNOWN pUnk, HRESULT *phr)
{
    AMTRACE((TEXT("CImageSync::CreateInstance")));
    return new CImageSync(pUnk, phr);
}

STDMETHODIMP
CImageSync::NonDelegatingQueryInterface(
    REFIID riid,
    void ** ppv)
{
    AMTRACE((TEXT("CImageSync::NonDelegatingQueryInterface")));

    HRESULT hr = E_NOINTERFACE;
    *ppv = NULL;

    if (riid == IID_IImageSync) {
        hr = GetInterface((IImageSync*)this, ppv);
    }
    else if (riid == IID_IImageSyncControl) {
        hr = GetInterface((IImageSyncControl*)this, ppv);
    }
    else if (riid == IID_IQualProp) {
        hr = GetInterface((IQualProp*)this, ppv);
    }
    else {
        hr = CUnknown::NonDelegatingQueryInterface(riid,ppv);
    }

#if defined(CHECK_FOR_LEAKS)
    if (hr == S_OK) {
        _pIFLeak->AddThunk((IUnknown **)ppv, "Image Sync Object",  riid);
    }
#endif

    return hr;
}
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\multimedia\dshow\filters\image2\core\imagesyncqual.cpp ===
/******************************Module*Header*******************************\
* Module Name: ImageSyncQual.cpp
*
* Implements the IQualProp interface of the core Image Synchronization
* Object - based on DShow base classes CBaseRenderer and CBaseVideoRenderer.
*
*
* Created: Wed 01/12/2000
* Author:  Stephen Estrop [StEstrop]
*
* Copyright (c) 2000 Microsoft Corporation
\**************************************************************************/
#include <streams.h>
#include <windowsx.h>
#include <limits.h>

#include "resource.h"
#include "ImageSyncObj.h"

// To avoid dragging in the maths library - a cheap
// approximate integer square root.
// We do this by getting a starting guess which is between 1
// and 2 times too large, followed by THREE iterations of
// Newton Raphson.  (That will give accuracy to the nearest mSec
// for the range in question - roughly 0..1000)
//
// It would be faster to use a linear interpolation and ONE NR, but
// who cares.  If anyone does - the best linear interpolation is
// to approximates sqrt(x) by
// y = x * (sqrt(2)-1) + 1 - 1/sqrt(2) + 1/(8*(sqrt(2)-1))
// 0r y = x*0.41421 + 0.59467
// This minimises the maximal error in the range in question.
// (error is about +0.008883 and then one NR will give error .0000something
// (Of course these are integers, so you can't just multiply by 0.41421
// you'd have to do some sort of MulDiv).
// Anyone wanna check my maths?  (This is only for a property display!)

static int isqrt(int x)
{
    int s = 1;
    // Make s an initial guess for sqrt(x)
    if (x > 0x40000000) {
       s = 0x8000;     // prevent any conceivable closed loop
    } else {
	while (s*s<x) {    // loop cannot possible go more than 31 times
	    s = 2*s;       // normally it goes about 6 times
	}
	// Three NR iterations.
	if (x==0) {
	   s= 0; // Wouldn't it be tragic to divide by zero whenever our
		 // accuracy was perfect!
	} else {
	    s = (s*s+x)/(2*s);
	    if (s>=0) s = (s*s+x)/(2*s);
	    if (s>=0) s = (s*s+x)/(2*s);
	}
    }
    return s;
}

/*****************************Private*Routine******************************\
* GetStdDev
*
* Do estimates for standard deviations for per-frame statistics
*
* History:
* Mon 05/22/2000 - StEstrop - Created
*
\**************************************************************************/
HRESULT
CImageSync::GetStdDev(
    int nSamples,
    int *piResult,
    LONGLONG llSumSq,
    LONGLONG iTot
    )
{
    CheckPointer(piResult,E_POINTER);
    CAutoLock cVideoLock(&m_InterfaceLock);

    if (NULL==m_pClock) {
	*piResult = 0;
	return NOERROR;
    }

    // If S is the Sum of the Squares of observations and
    //    T the Total (i.e. sum) of the observations and there were
    //    N observations, then an estimate of the standard deviation is
    //      sqrt( (S - T**2/N) / (N-1) )

    if (nSamples<=1) {
	*piResult = 0;
    } else {
	LONGLONG x;
	// First frames have bogus stamps, so we get no stats for them
	// So we need 2 frames to get 1 datum, so N is cFramesDrawn-1

	// so we use m_cFramesDrawn-1 here
	x = llSumSq - llMulDiv(iTot, iTot, nSamples, 0);
	x = x / (nSamples-1);
	ASSERT(x>=0);
	*piResult = isqrt((LONG)x);
    }
    return NOERROR;
}


/******************************Public*Routine******************************\
* get_FramesDroppedInRenderer
*
*
*
* History:
* Tue 01/11/2000 - StEstrop - Created
*
\**************************************************************************/
STDMETHODIMP
CImageSync::get_FramesDroppedInRenderer(
    int *pcFramesDropped
    )
{
    CheckPointer(pcFramesDropped,E_POINTER);
    CAutoLock cVideoLock(&m_InterfaceLock);
    *pcFramesDropped = m_cFramesDropped;
    return NOERROR;
}


/******************************Public*Routine******************************\
* get_FramesDrawn
*
*
*
* History:
* Tue 01/11/2000 - StEstrop - Created
*
\**************************************************************************/
STDMETHODIMP
CImageSync::get_FramesDrawn(
    int *pcFramesDrawn
    )
{
    CheckPointer(pcFramesDrawn,E_POINTER);
    CAutoLock cVideoLock(&m_InterfaceLock);
    *pcFramesDrawn = m_cFramesDrawn;
    return NOERROR;
}


/******************************Public*Routine******************************\
* get_AvgFrameRate
*
*
*
* History:
* Tue 01/11/2000 - StEstrop - Created
*
\**************************************************************************/
STDMETHODIMP
CImageSync::get_AvgFrameRate(
    int *piAvgFrameRate
    )
{
    CheckPointer(piAvgFrameRate,E_POINTER);

    CAutoLock cVideoLock(&m_InterfaceLock);
    CAutoLock cRendererLock(&m_RendererLock);

    int t;
    if (IsStreaming()) {
        t = timeGetTime()-m_tStreamingStart;
    } else {
        t = m_tStreamingStart;
    }

    if (t<=0) {
        *piAvgFrameRate = 0;
        ASSERT(m_cFramesDrawn == 0);
    } else {
        // i is frames per hundred seconds
        *piAvgFrameRate = MulDiv(100000, m_cFramesDrawn, t);
    }
    return NOERROR;
}


/******************************Public*Routine******************************\
* get_Jitter
*
*
*
* History:
* Tue 01/11/2000 - StEstrop - Created
*
\**************************************************************************/
STDMETHODIMP
CImageSync::get_Jitter(
    int *piJitter
    )
{
    // First frames have bogus stamps, so we get no stats for them
    // So second frame gives bogus inter-frame time
    // So we need 3 frames to get 1 datum, so N is cFramesDrawn-2
    return GetStdDev(m_cFramesDrawn - 2,
		     piJitter,
		     m_iSumSqFrameTime,
		     m_iSumFrameTime);
}


/******************************Public*Routine******************************\
* get_AvgSyncOffset
*
*
*
* History:
* Tue 01/11/2000 - StEstrop - Created
*
\**************************************************************************/
STDMETHODIMP
CImageSync::get_AvgSyncOffset(
    int *piAvg
    )
{
    CheckPointer(piAvg,E_POINTER);
    CAutoLock cVideoLock(&m_InterfaceLock);

    if (NULL==m_pClock) {
	*piAvg = 0;
	return NOERROR;
    }

    // Note that we didn't gather the stats on the first frame
    // so we use m_cFramesDrawn-1 here
    if (m_cFramesDrawn<=1) {
	*piAvg = 0;
    } else {
	*piAvg = (int)(m_iTotAcc / (m_cFramesDrawn-1));
    }
    return NOERROR;
}


/******************************Public*Routine******************************\
* get_DevSyncOffset
*
*
*
* History:
* Tue 01/11/2000 - StEstrop - Created
*
\**************************************************************************/
STDMETHODIMP
CImageSync::get_DevSyncOffset(
    int *piDev
    )
{
    // First frames have bogus stamps, so we get no stats for them
    // So we need 2 frames to get 1 datum, so N is cFramesDrawn-1
    return GetStdDev(m_cFramesDrawn - 1,
		     piDev,
		     m_iSumSqAcc,
		     m_iTotAcc);
}
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\multimedia\dshow\filters\image2\core\imagesyncobj.h ===
// ImageSyncObj.h : Declaration of the CImageSync
#include "vmrp.h"


/////////////////////////////////////////////////////////////////////////////
// CImageSync
class CImageSync :
    public CUnknown,
    public IImageSync,
    public IImageSyncControl,
    public IQualProp
{
public:

    DECLARE_IUNKNOWN
    STDMETHODIMP NonDelegatingQueryInterface(REFIID, void**);
    static CUnknown *CreateInstance(LPUNKNOWN, HRESULT *);
    static void InitClass(BOOL fLoaded, const CLSID *clsid);

    CImageSync(LPUNKNOWN pUnk, HRESULT *phr) :
        CUnknown(NAME("Image Sync"), pUnk),
        m_bAbort(false),
        m_bStreaming(false),
        m_dwAdvise(0),
        m_bInReceive(false),
        m_ImagePresenter(NULL),
        m_lpEventNotify(NULL),
        m_pClock(NULL),
        m_bQualityMsgValid(false),
        m_bLastQualityMessageRead(false),
        m_bFlushing(false),
        m_bEOS(false),
        m_bEOSDelivered(FALSE),
        m_pSample(NULL),
        m_evComplete(TRUE),
        m_ThreadSignal(TRUE),
        m_State(ImageSync_State_Stopped),
        m_SignalTime(0),
        m_EndOfStreamTimer(0)
    {
        AMTRACE((TEXT("CImageSync::CImageSync")));

        //
        // Frame stepping stuff
        //
        // -ve == normal playback
        // +ve == frames to skips
        //  0 == time to block
        //
        m_lFramesToStep = -1;
        m_StepEvent = CreateEvent(NULL, FALSE, FALSE, NULL);

        ResetStreamingTimes();
        Ready();
    }


    virtual ~CImageSync()
    {
        AMTRACE((TEXT("CImageSync::FinalRelease")));

        if (m_StepEvent) {
            CloseHandle(m_StepEvent);
        }

        if (m_ImagePresenter) {
            m_ImagePresenter->Release();
        }

        if (m_pClock) {
            m_pClock->Release();
        }
    }

// IImageSync
public:
    // return the buffer to the renderer along with time stamps relating to
    // when the buffer should be presented.
    STDMETHODIMP Receive(VMRPRESENTATIONINFO* lpPresInfo);

    // ask for quality control information from the renderer
    STDMETHODIMP GetQualityControlMessage(Quality* pQualityMsg);


// IImageSyncControl
public:

    // ============================================================
    // Synchronisation control
    // ============================================================

    STDMETHODIMP SetImagePresenter(IVMRImagePresenter* lpImagePresenter,
                                   DWORD_PTR dwUID);
    STDMETHODIMP SetReferenceClock(IReferenceClock* lpRefClock);
    STDMETHODIMP SetEventNotify(IImageSyncNotifyEvent* lpEventNotify);

    // ============================================================
    // Image sequence control
    // ============================================================

    STDMETHODIMP BeginImageSequence(REFERENCE_TIME* pStartTime);
    STDMETHODIMP CueImageSequence();
    STDMETHODIMP EndImageSequence();
    STDMETHODIMP GetImageSequenceState(DWORD dwMSecsTimeOut, DWORD* lpdwState);
    STDMETHODIMP BeginFlush();
    STDMETHODIMP EndFlush();
    STDMETHODIMP EndOfStream();
    STDMETHODIMP ResetEndOfStream();
    STDMETHODIMP SetAbortSignal(BOOL bAbort);
    STDMETHODIMP GetAbortSignal(BOOL* lpbAbort);
    STDMETHODIMP RuntimeAbortPlayback();

    // ============================================================
    // Frame Step control
    // ============================================================

    STDMETHODIMP FrameStep(
        DWORD nFramesToStep,
        DWORD dwStepFlags);

    STDMETHODIMP CancelFrameStep();


// IQualProp
public:
    STDMETHODIMP get_FramesDroppedInRenderer(int *cFramesDropped);
    STDMETHODIMP get_FramesDrawn(int *pcFramesDrawn);
    STDMETHODIMP get_AvgFrameRate(int *piAvgFrameRate);
    STDMETHODIMP get_Jitter(int *piJitter);
    STDMETHODIMP get_AvgSyncOffset(int *piAvg);
    STDMETHODIMP get_DevSyncOffset(int *piDev);


private:
    CAMEvent            m_RenderEvent;  // Used to signal timer events
    CAMEvent            m_ThreadSignal; // Signalled to release worker thread
    CAMEvent            m_evComplete;


    HANDLE              m_StepEvent;    // Used to block when frame stepping
    LONG                m_lFramesToStep;

    void Ready()
    {
        AMTRACE((TEXT("CImageSync::Ready")));
        m_evComplete.Set();
    };

    void NotReady()
    {
        AMTRACE((TEXT("CImageSync::Notready")));
        m_evComplete.Reset();
    };

    DWORD_PTR           m_dwAdvise;
    DWORD               m_State;
    BOOL                m_bEOS;         // Any more samples in the stream
    BOOL                m_bEOSDelivered;// Have we delivered an EC_COMPLETE

    // The Renderer lock protects the following variables.
    // This list is not a complete list of the variables 
    // protected by the renderer lock.
    //      - m_bStreaming
    //      - m_bEOSDelivered
    // 
    CCritSec                m_RendererLock; // Controls access to internals
    CCritSec                m_InterfaceLock;// Controls access to the Control interface
    IVMRImagePresenter*     m_ImagePresenter;
    DWORD_PTR               m_dwUserID;
    IImageSyncNotifyEvent*  m_lpEventNotify;
    IReferenceClock*        m_pClock;       // A pointer to the supplied clock
    CRefTime                m_tStart;       // cached start time
    Quality                 m_QualityMsg;   // Saved quality MSG

    BOOL                m_bQualityMsgValid;
    BOOL                m_bLastQualityMessageRead;
    BOOL                m_bInReceive;
    BOOL                m_bAbort;
    BOOL                m_bStreaming;
    BOOL                m_bFlushing;

    REFERENCE_TIME      m_SignalTime;       // Time when we signal EC_COMPLETE
    UINT                m_EndOfStreamTimer; // Used to signal end of stream

    VMRPRESENTATIONINFO*    m_pSample;
    HRESULT SaveSample(VMRPRESENTATIONINFO* pSample);
    HRESULT GetSavedSample(VMRPRESENTATIONINFO** ppSample);

    void ClearSavedSample();
    BOOL HaveSavedSample();
    void FrameStepWorker();


    // CBaseVideoRenderer is a renderer class (see its ancestor class) and
    // it handles scheduling of media samples so that they are drawn at the
    // correct time by the reference clock.  It implements a degradation
    // strategy.  Possible degradation modes are:
    //    Drop frames here (only useful if the drawing takes significant time)
    //    Signal supplier (upstream) to drop some frame(s) - i.e. one-off skip.
    //    Signal supplier to change the frame rate - i.e. ongoing skipping.
    //    Or any combination of the above.
    // In order to determine what's useful to try we need to know what's going
    // on.  This is done by timing various operations (including the supplier).
    // This timing is done by using timeGetTime as it is accurate enough and
    // usually cheaper than calling the reference clock.  It also tells the
    // truth if there is an audio break and the reference clock stops.
    // We provide a number of public entry points (named OnXxxStart, OnXxxEnd)
    // which the rest of the renderer calls at significant moments.  These do
    // the timing.

    // the number of frames that the sliding averages are averaged over.
    // the rule is (1024*NewObservation + (AVGPERIOD-1) * PreviousAverage)/AVGPERIOD
#define AVGPERIOD 4
#define RENDER_TIMEOUT 10000
//  enum { AVGPERIOD = 4, RENDER_TIMEOUT = 10000 };

    // Hungarian:
    //     tFoo is the time Foo in mSec (beware m_tStart from filter.h)
    //     trBar is the time Bar by the reference clock

    //******************************************************************
    // State variables to control synchronisation
    //******************************************************************

    // Control of sending Quality messages.  We need to know whether
    // we are in trouble (e.g. frames being dropped) and where the time
    // is being spent.

    // When we drop a frame we play the next one early.
    // The frame after that is likely to wait before drawing and counting this
    // wait as spare time is unfair, so we count it as a zero wait.
    // We therefore need to know whether we are playing frames early or not.

    int m_nNormal;                  // The number of consecutive frames
                                    // drawn at their normal time (not early)
                                    // -1 means we just dropped a frame.

    BOOL m_bSupplierHandlingQuality;// The response to Quality messages says
                                    // our supplier is handling things.
                                    // We will allow things to go extra late
                                    // before dropping frames.  We will play
                                    // very early after he has dropped one.

    // Control of scheduling, frame dropping etc.
    // We need to know where the time is being spent so as to tell whether
    // we should be taking action here, signalling supplier or what.
    // The variables are initialised to a mode of NOT dropping frames.
    // They will tell the truth after a few frames.
    // We typically record a start time for an event, later we get the time
    // again and subtract to get the elapsed time, and we average this over
    // a few frames.  The average is used to tell what mode we are in.

    // Although these are reference times (64 bit) they are all DIFFERENCES
    // between times which are small.  An int will go up to 214 secs before
    // overflow.  Avoiding 64 bit multiplications and divisions seems
    // worth while.



    // Audio-video throttling.  If the user has turned up audio quality
    // very high (in principle it could be any other stream, not just audio)
    // then we can receive cries for help via the graph manager.  In this case
    // we put in a wait for some time after rendering each frame.
    int m_trThrottle;

    // The time taken to render (i.e. BitBlt) frames controls which component
    // needs to degrade.  If the blt is expensive, the renderer degrades.
    // If the blt is cheap it's done anyway and the supplier degrades.
    int m_trRenderAvg;              // Time frames are taking to blt
    int m_trRenderLast;             // Time for last frame blt
    int m_tRenderStart;             // Just before we started drawing (mSec)
                                    // derived from timeGetTime.

    // When frames are dropped we will play the next frame as early as we can.
    // If it was a false alarm and the machine is fast we slide gently back to
    // normal timing.  To do this, we record the offset showing just how early
    // we really are.  This will normally be negative meaning early or zero.
    int m_trEarliness;

    // Target provides slow long-term feedback to try to reduce the
    // average sync offset to zero.  Whenever a frame is actually rendered
    // early we add a msec or two, whenever late we take off a few.
    // We add or take off 1/32 of the error time.
    // Eventually we should be hovering around zero.  For a really bad case
    // where we were (say) 300mSec off, it might take 100 odd frames to
    // settle down.  The rate of change of this is intended to be slower
    // than any other mechanism in Quartz, thereby avoiding hunting.
    int m_trTarget;

    // The proportion of time spent waiting for the right moment to blt
    // controls whether we bother to drop a frame or whether we reckon that
    // we're doing well enough that we can stand a one-frame glitch.
    int m_trWaitAvg;                // Average of last few wait times
                                    // (actually we just average how early
                                    // we were).  Negative here means LATE.

    // The average inter-frame time.
    // This is used to calculate the proportion of the time used by the
    // three operations (supplying us, waiting, rendering)
    int m_trFrameAvg;               // Average inter-frame time
    int m_trDuration;               // duration of last frame.

    REFERENCE_TIME m_trRememberStampForPerf;  // original time stamp of frame
                                              // with no earliness fudges etc.
    // PROPERTY PAGE
    // This has edit fields that show the user what's happening
    // These member variables hold these counts.

    int m_cFramesDropped;           // cumulative frames dropped IN THE RENDERER
    int m_cFramesDrawn;             // Frames since streaming started seen BY THE
                                    // RENDERER (some may be dropped upstream)

    // Next two support average sync offset and standard deviation of sync offset.
    LONGLONG m_iTotAcc;             // Sum of accuracies in mSec
    LONGLONG m_iSumSqAcc;           // Sum of squares of (accuracies in mSec)

    // Next two allow jitter calculation.  Jitter is std deviation of frame time.
    REFERENCE_TIME m_trLastDraw;    // Time of prev frame (for inter-frame times)
    LONGLONG m_iSumSqFrameTime;     // Sum of squares of (inter-frame time in mSec)
    LONGLONG m_iSumFrameTime;       // Sum of inter-frame times in mSec

    // To get performance statistics on frame rate, jitter etc, we need
    // to record the lateness and inter-frame time.  What we actually need are the
    // data above (sum, sum of squares and number of entries for each) but the data
    // is generated just ahead of time and only later do we discover whether the
    // frame was actually drawn or not.  So we have to hang on to the data
    int m_trLate;                   // hold onto frame lateness
    int m_trFrame;                  // hold onto inter-frame time

    int m_tStreamingStart;          // if streaming then time streaming started
                                    // else time of last streaming session
                                    // used for property page statistics



    // These provide a full video quality management implementation

    HRESULT StartStreaming();
    HRESULT StopStreaming();
    HRESULT SourceThreadCanWait(BOOL bCanWait);
    HRESULT CompleteStateChange(DWORD OldState);

    HRESULT OnStartStreaming();
    HRESULT OnStopStreaming();
    HRESULT OnReceiveFirstSample(VMRPRESENTATIONINFO* pSample);
    HRESULT DoRenderSample(VMRPRESENTATIONINFO* pSample);
    HRESULT Render(VMRPRESENTATIONINFO* pSample);

    void OnRenderStart(VMRPRESENTATIONINFO* pSample);
    void OnRenderEnd(VMRPRESENTATIONINFO* pSample);

    void OnWaitStart();
    void OnWaitEnd();
    void ThrottleWait();
    void WaitForReceiveToComplete();

    // Handle the statistics gathering for our quality management

    void PreparePerformanceData(int trLate, int trFrame);
    void RecordFrameLateness(int trLate, int trFrame);
    HRESULT ResetStreamingTimes();
    HRESULT ReceiveWorker(VMRPRESENTATIONINFO* pSample);
    HRESULT PrepareReceive(VMRPRESENTATIONINFO* pSample);
    HRESULT ScheduleSampleWorker(VMRPRESENTATIONINFO* pSample);
    HRESULT ScheduleSample(VMRPRESENTATIONINFO* pSample);
    HRESULT CheckSampleTimes(VMRPRESENTATIONINFO* pSample,
                             REFERENCE_TIME *ptrStart,
                             REFERENCE_TIME *ptrEnd);

    HRESULT ShouldDrawSampleNow(VMRPRESENTATIONINFO* pSample,
                                REFERENCE_TIME *ptrStart,
                                REFERENCE_TIME *ptrEnd);

    // Lots of end of stream complexities
public:
    void TimerCallback();

private:
    void ResetEndOfStreamTimer();
    HRESULT NotifyEndOfStream();
    HRESULT SendEndOfStream();


    HRESULT SendQuality(REFERENCE_TIME trLate, REFERENCE_TIME trRealStream);
    HRESULT CancelNotification();
    HRESULT WaitForRenderTime();
    void SignalTimerFired();
    BOOL IsEndOfStream() { return m_bEOS; };
    BOOL IsEndOfStreamDelivered();
    BOOL IsStreaming();

    //
    //  Do estimates for standard deviations for per-frame
    //  statistics
    //
    //  *piResult = (llSumSq - iTot * iTot / m_cFramesDrawn - 1) /
    //                            (m_cFramesDrawn - 2)
    //  or 0 if m_cFramesDrawn <= 3
    //
    HRESULT GetStdDev(int nSamples,int *piResult,LONGLONG llSumSq,LONGLONG iTot);
};

inline BOOL CImageSync::IsStreaming()
{
    // The caller must hold the m_RendererLock because this function
    // uses m_bStreaming.
    ASSERT(CritCheckIn(&m_RendererLock));

    return m_bStreaming;
}

inline BOOL CImageSync::IsEndOfStreamDelivered()
{
    // The caller must hold the m_RendererLock because this function
    // uses m_bEOSDelivered.
    ASSERT(CritCheckIn(&m_RendererLock));

    return m_bEOSDelivered;
}
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\multimedia\dshow\filters\image2\ap\ia64\atltmr21.s ===
.global	_TimerProcThunkProc
	.proc	_TimerProcThunkProc
	.align	32

_TimerProcThunkProc:
	// On entry, gp is actually a pointer to the pRealWndProcDesc member of 
	// the _WndProcThunk struct
	alloc	r36=ar.pfs,4,6,4,0
	mov		r37=rp  // Save return address
	mov		r38=gp  // Save gp
	mov		r40=gp  // r40 = &thunk.pRealWndProcDesc
	ld8		r30=[r40],8  // r30 = thunk.pRealWndProcDesc, r40 = &thunk.pThis
	ld8		r42=[r40]  // r42 = pThis
	ld8		r31=[r30],8  // r31 = thunk.pRealWndProcDesc->pfn, r30 = &thunk.pRealWndProcDesc->gp
	ld8		gp=[r30]  // gp = thunk.pRealWndProcDesc->gp
	mov		r43=r33  // r43 = nMsg
	mov		r44=r34  // r44 = wParam
	mov		r45=r35  // r45 = lParam
	mov		b6=r31  // b6 = thunk.pRealWndProcDesc->pfn
	br.call.sptk.many	rp=b6  // Call thunk.pRealWndProcDesc->pfn
	mov		gp=r38  // restore gp
	mov		rp=r37  // restore return address
	mov		ar.pfs=r36  // restore previous function state
	br.ret.sptk.many	rp  // return
	.endp	_TimerProcThunkProc
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\multimedia\dshow\filters\image2\core\imagesyncctrl.cpp ===
/******************************Module*Header*******************************\
* Module Name: ImageSyncCtrl.cpp
*
* Implements the IImageSyncControl interface of the  core Image Synchronization
* Object - based on DShow base classes CBaseRenderer and CBaseVideoRenderer.
*
*
* Created: Wed 01/12/2000
* Author:  Stephen Estrop [StEstrop]
*
* Copyright (c) 2000 Microsoft Corporation
\**************************************************************************/
#include <streams.h>
#include <windowsx.h>
#include <limits.h>

#include "ImageSyncObj.h"



/////////////////////////////////////////////////////////////////////////////
// CImageSync
//
/////////////////////////////////////////////////////////////////////////////

// --------------------------------------------------------------------------
// Some helper inline functions
// --------------------------------------------------------------------------
__inline bool IsDiscontinuity(DWORD dwSampleFlags)
{
    return 0 != (dwSampleFlags & VMRSample_Discontinuity);
}

__inline bool IsTimeValid(DWORD dwSampleFlags)
{
    return 0 != (dwSampleFlags & VMRSample_TimeValid);
}

__inline bool IsSyncPoint(DWORD dwSampleFlags)
{
    return 0 != (dwSampleFlags & VMRSample_SyncPoint);
}


/******************************Public*Routine******************************\
* SetImagePresenter
*
*
*
* History:
* Tue 01/11/2000 - StEstrop - Created
*
\**************************************************************************/
STDMETHODIMP
CImageSync::SetImagePresenter(
    IVMRImagePresenter* lpImagePresenter,
    DWORD_PTR dwUserID
    )
{
    AMTRACE((TEXT("CImageSync::SetImagePresenter")));
    CAutoLock cILock(&m_InterfaceLock);
    CAutoLock cRLock(&m_RendererLock);

    if (lpImagePresenter) {
        lpImagePresenter->AddRef();
    }

    if (m_ImagePresenter) {
        m_ImagePresenter->Release();
    }

    m_ImagePresenter = lpImagePresenter;
    m_dwUserID = dwUserID;

    return S_OK;
}

/******************************Public*Routine******************************\
* SetReferenceClock
*
*
*
* History:
* Tue 01/11/2000 - StEstrop - Created
*
\**************************************************************************/
STDMETHODIMP
CImageSync::SetReferenceClock(
    IReferenceClock* lpRefClock
    )
{
    AMTRACE((TEXT("CImageSync::SetReferenceClock")));
    CAutoLock cILock(&m_InterfaceLock);
    CAutoLock cRLock(&m_RendererLock);

    if (lpRefClock) {
        lpRefClock->AddRef();
    }

    if (m_pClock) {
        m_pClock->Release();
    }

    m_pClock = lpRefClock;

    return S_OK;
}

/******************************Public*Routine******************************\
* SetEventNotify
*
*
*
* History:
* Tue 01/11/2000 - StEstrop - Created
*
\**************************************************************************/
STDMETHODIMP
CImageSync::SetEventNotify(
    IImageSyncNotifyEvent* lpEventNotify
    )
{
    AMTRACE((TEXT("CImageSync::SetEventNotify")));
    CAutoLock cILock(&m_InterfaceLock);
    CAutoLock cRLock(&m_RendererLock);

    if (lpEventNotify) {
        lpEventNotify->AddRef();
    }

    if (m_lpEventNotify) {
        m_lpEventNotify->Release();
    }

    m_lpEventNotify = lpEventNotify;

    return S_OK;
}


/*****************************Private*Routine******************************\
* ResetStreamingTimes
*
* Reset all times controlling streaming.
* Set them so that
* 1. Frames will not initially be dropped
* 2. The first frame will definitely be drawn (achieved by saying that there
*    has not ben a frame drawn for a long time).
*
* History:
* Thu 01/13/2000 - StEstrop - Created
*
\**************************************************************************/
HRESULT
CImageSync::ResetStreamingTimes()
{
    AMTRACE((TEXT("CImageSync::ResetStreamingTimes")));
    m_trLastDraw = -1000;     // set up as first frame since ages (1 sec) ago
    m_tStreamingStart = timeGetTime();
    m_trRenderAvg = 0;
    m_trFrameAvg = -1;        // -1000 fps == "unset"
    m_trDuration = 0;         // 0 - value
    m_trRenderLast = 0;
    m_trWaitAvg = 0;
    m_tRenderStart = 0;
    m_cFramesDrawn = 0;
    m_cFramesDropped = 0;
    m_iTotAcc = 0;
    m_iSumSqAcc = 0;
    m_iSumSqFrameTime = 0;
    m_trFrame = 0;          // hygeine - not really needed
    m_trLate = 0;           // hygeine - not really needed
    m_iSumFrameTime = 0;
    m_nNormal = 0;
    m_trEarliness = 0;
    m_trTarget = -300000;  // 30mSec early
    m_trThrottle = 0;
    m_trRememberStampForPerf = 0;

#ifdef PERF
    m_trRememberFrameForPerf = 0;
#endif

    return S_OK;
}



/******************************Public*Routine******************************\
* BeginImageSequence
*
* This is called when we start running so that we can schedule any pending
* image we have with the clock and display any timing information. If we
* don't have any sample but we return straight away.
*
* History:
* Tue 01/11/2000 - StEstrop - Created
*
\**************************************************************************/
STDMETHODIMP
CImageSync::BeginImageSequence(
    REFERENCE_TIME* pStartTime
    )
{
    AMTRACE((TEXT("CImageSync::BeginImageSequence")));
    CAutoLock cILock(&m_InterfaceLock);
    DWORD OldState = m_State;

    if (m_State == ImageSync_State_Playing) {
        return S_OK;
    }

    //
    // We can't begin an image sequence if
    // nothing is cued
    //

    if (m_State == ImageSync_State_Stopped) {
        return VFW_E_WRONG_STATE;
    }


    Ready();

    m_tStart = *pStartTime;
    m_State = ImageSync_State_Playing;

    SourceThreadCanWait(TRUE);


    //
    // There should be no outstanding advise
    //

    ASSERT(CancelNotification() == S_FALSE);
    ASSERT(WAIT_TIMEOUT == WaitForSingleObject((HANDLE)m_RenderEvent,0));
    ASSERT(m_EndOfStreamTimer == 0);

    //
    // When we come out of a stopped state we must clear any image we were
    // holding onto for frame refreshing. Since renderers see state changes
    // first we can reset ourselves ready to accept the source thread data
    // Paused or running after being stopped causes the current position to
    // be reset so we're not interested in passing end of stream signals
    //

    if (OldState == ImageSync_State_Stopped) {
        m_bAbort = FALSE;
        ClearSavedSample();
    }

    return StartStreaming();
}


void CALLBACK VMREndOfStreamTimer(UINT uID,        // Timer identifier
		                  UINT uMsg,       // Not currently used
		                  DWORD_PTR dwUser,// User information
		                  DWORD_PTR dw1,   // Windows reserved
			          DWORD_PTR dw2)   // is also reserved
{
    CImageSync* pRenderer = (CImageSync *) dwUser;
    NOTE1("VMREndOfStreamTimer called (%d)",uID);
    pRenderer->TimerCallback();
}

//  Do the timer callback work
void CImageSync::TimerCallback()
{
    //  Lock for synchronization (but don't hold this lock when calling
    //  timeKillEvent)
    CAutoLock cRendererLock(&m_RendererLock);

    // See if we should signal end of stream now

    if (m_EndOfStreamTimer) {
        m_EndOfStreamTimer = 0;
        SendEndOfStream();
    }
}


// If we are at the end of the stream signal the filter graph but do not set
// the state flag back to FALSE. Once we drop off the end of the stream we
// leave the flag set (until a subsequent ResetEndOfStream). Each sample we
// get delivered will update m_SignalTime to be the last sample's end time.
// We must wait this long before signalling end of stream to the filtergraph

#define TIMEOUT_DELIVERYWAIT 50
#define TIMEOUT_RESOLUTION 10

HRESULT CImageSync::SendEndOfStream()
{
    ASSERT(CritCheckIn(&m_RendererLock));

    if (m_bEOS == FALSE || IsEndOfStreamDelivered() || m_EndOfStreamTimer) {
        return NOERROR;
    }

    // If there is no clock then signal immediately
    if (m_pClock == NULL) {
        return NotifyEndOfStream();
    }

    // How long into the future is the delivery time

    REFERENCE_TIME Signal = m_tStart + m_SignalTime;
    REFERENCE_TIME CurrentTime;
    m_pClock->GetTime(&CurrentTime);
    LONG Delay = LONG((Signal - CurrentTime) / 10000);

    // Dump the timing information to the debugger

    NOTE1("Delay until end of stream delivery %d",Delay);
    NOTE1("Current %s",(LPCTSTR)CDisp((LONGLONG)CurrentTime));
    NOTE1("Signal %s",(LPCTSTR)CDisp((LONGLONG)Signal));

    // Wait for the delivery time to arrive

    if (Delay < TIMEOUT_DELIVERYWAIT) {
        return NotifyEndOfStream();
    }

    // Signal a timer callback on another worker thread

    m_EndOfStreamTimer = CompatibleTimeSetEvent((UINT) Delay,        // Period of timer
                                                TIMEOUT_RESOLUTION,  // Timer resolution
                                                VMREndOfStreamTimer, // Callback function
                                                DWORD_PTR(this),     // Used information
                                                TIME_ONESHOT);       // Type of callback
    if (m_EndOfStreamTimer == 0) {
        return NotifyEndOfStream();
    }
    return NOERROR;
}


// Signals EC_COMPLETE to the filtergraph manager

HRESULT CImageSync::NotifyEndOfStream()
{
    CAutoLock cRendererLock(&m_RendererLock);
    ASSERT(!IsEndOfStreamDelivered());
    ASSERT(m_EndOfStreamTimer == 0);

    // Has the filter changed state

    if (!IsStreaming()) {
        ASSERT(m_EndOfStreamTimer == 0);
        return NOERROR;
    }

    // Reset the end of stream timer
    m_EndOfStreamTimer = 0;

    // If we've been using the IMediaPosition interface, set it's start
    // and end media "times" to the stop position by hand.  This ensures
    // that we actually get to the end, even if the MPEG guestimate has
    // been bad or if the quality management dropped the last few frames

    m_bEOSDelivered = TRUE;
    NOTE("Sending EC_COMPLETE...");

    if (m_lpEventNotify) {
        return m_lpEventNotify->NotifyEvent(EC_COMPLETE, 0, 0);
    }

    return E_FAIL;
}


// Reset the end of stream flag, this is typically called when we transfer to
// stopped states since that resets the current position back to the start so
// we will receive more samples or another EndOfStream if there aren't any. We
// keep two separate flags one to say we have run off the end of the stream
// (this is the m_bEOS flag) and another to say we have delivered EC_COMPLETE
// to the filter graph. We need the latter otherwise we can end up sending an
// EC_COMPLETE every time the source changes state and calls our EndOfStream

STDMETHODIMP
CImageSync::ResetEndOfStream()
{
    ResetEndOfStreamTimer();
    CAutoLock cRendererLock(&m_RendererLock);

    m_bEOS = FALSE;
    m_bEOSDelivered = FALSE;
    m_SignalTime = 0;

    return NOERROR;
}


STDMETHODIMP
CImageSync::SetAbortSignal(BOOL fAbort)
{
    m_bAbort = fAbort;
    return NOERROR;
}

STDMETHODIMP
CImageSync::GetAbortSignal(BOOL* lpfAbort)
{
    *lpfAbort = m_bAbort;
    return NOERROR;
}


STDMETHODIMP
CImageSync::RuntimeAbortPlayback()
{
    // This function must hold the renderer lock because it 
    // calls IsStreaming() and IsEndOfStreamDelivered().
    CAutoLock cRendererLock(&m_RendererLock);

    if (IsStreaming() && !IsEndOfStreamDelivered())
    {
        NotifyEndOfStream();
        return S_OK;
    }

    return S_FALSE;
}

// Kills any outstanding end of stream timer

void CImageSync::ResetEndOfStreamTimer()
{
    ASSERT(CritCheckOut(&m_RendererLock));
    if (m_EndOfStreamTimer) {
        timeKillEvent(m_EndOfStreamTimer);
        m_EndOfStreamTimer = 0;
    }
}

/*****************************Private*Routine******************************\
* StartStreaming
*
* This is called when we start running so that we can schedule any pending
* image we have with the clock and display any timing information.
* If we do have a sample then we wait until that has been rendered before we
* signal the filter graph otherwise we may change state before it's done
*
* History:
* Fri 01/21/2000 - StEstrop - Created
*
\**************************************************************************/
HRESULT
CImageSync::StartStreaming(
    )
{
    AMTRACE((TEXT("CImageSync::StartStreaming")));
    CAutoLock cRLock(&m_RendererLock);

    //
    // StartStreaming already called
    //

    if (IsStreaming()) {
        return S_OK;
    }

    //
    // Reset the streaming times ready for running
    //

    m_bStreaming = TRUE;
    timeBeginPeriod(1);
    OnStartStreaming();


    //
    // There should be no outstanding advise
    //

    ASSERT(WAIT_TIMEOUT == WaitForSingleObject((HANDLE)m_RenderEvent,0));
    ASSERT(CancelNotification() == S_FALSE);

    // If we have an EOS and no data then deliver it now

    if (!HaveSavedSample()) {
        // reset m_EOSDelivered in case we got our last eos 
        // and need to resend the EC_COMPLETE immediately
        m_bEOSDelivered = FALSE;
        return SendEndOfStream();
    }


    //
    // Get the saved pending sample and schedule it, if no sample is waiting
    // return straight away.
    //

    VMRPRESENTATIONINFO *pSample;

    HRESULT hr = GetSavedSample(&pSample);

    if (SUCCEEDED(hr)) {

        //
        // Have the data rendered
        //

        ASSERT(pSample);
        hr = ScheduleSample(pSample);

        if (FAILED(hr)) {
            m_RenderEvent.Set();
            hr = S_OK;
        }
    }

    return hr;
}

/*****************************Private*Routine******************************\
* OnStartStreaming
*
* Reset all times controlling streaming. Note that we're now streaming. We
* don't need to set the rendering event to have the source filter released
* as it is done during the Run processing. When we are run we immediately
* release the source filter thread and draw any image waiting (that image
* may already have been drawn once as a poster frame while we were paused)
*
* History:
* Thu 01/13/2000 - StEstrop - Created
*
\**************************************************************************/
HRESULT
CImageSync::OnStartStreaming()
{
    AMTRACE((TEXT("CImageSync::OnStartStreaming")));

    if (m_ImagePresenter) {
        m_ImagePresenter->StartPresenting(m_dwUserID);
    }

    ResetStreamingTimes();
    return S_OK;
}


/*****************************Private*Routine******************************\
* OnStopStreaming
*
*
* Called at end of streaming.  Fixes times for property page report
*
* History:
* Thu 01/13/2000 - StEstrop - Created
*
\**************************************************************************/
HRESULT
CImageSync::OnStopStreaming()
{
    AMTRACE((TEXT("CImageSync::OnStopStreaming")));
    m_tStreamingStart = timeGetTime() - m_tStreamingStart;

    if (m_ImagePresenter) {
        m_ImagePresenter->StopPresenting(m_dwUserID);
    }

    return S_OK;
}


/******************************Public*Routine******************************\
* EndImageSequence
*
* When we end an image sequence the thing we do are:
*
*   Release any thread that may be waiting in Receive
*   Cancel any advise link we set up with the clock
*
* History:
* Tue 01/11/2000 - StEstrop - Created
*
\**************************************************************************/
STDMETHODIMP
CImageSync::EndImageSequence(
    )
{
    AMTRACE((TEXT("CImageSync::EndImageSequence")));
    CAutoLock cRLock(&m_InterfaceLock);

    //
    // Make sure there really is a state change
    //

    if (m_State == ImageSync_State_Stopped) {
        return NOERROR;
    }

    m_State = ImageSync_State_Stopped;


    //
    // Cancel any scheduled rendering
    //
    StopStreaming();
    SourceThreadCanWait(FALSE);
    ResetEndOfStream();
    CancelNotification();

    //
    // There should be no outstanding clock advise
    //
    ASSERT(CancelNotification() == S_FALSE);
    ASSERT(WAIT_TIMEOUT == WaitForSingleObject((HANDLE)m_RenderEvent,0));
    ASSERT(m_EndOfStreamTimer == 0);

    Ready();
    WaitForReceiveToComplete();
    m_bAbort = FALSE;
    return S_OK;
}

/*****************************Private*Routine******************************\
* CompleteStateChange
*
* If we're pausing and we have no samples we don't complete the transition
* to State_Paused and we return S_FALSE.
*
* If we do have a sample then return NOERROR.
*
* We will only ever return * VFW_S_STATE_INTERMEDIATE from GetState after
* being paused with no sample * (calling GetState after either being stopped
* or Run will NOT return this)
*
* History:
* Fri 01/21/2000 - StEstrop - Created
*
\**************************************************************************/
HRESULT
CImageSync::CompleteStateChange(
    DWORD OldState
    )
{
    AMTRACE((TEXT("CImageSync::CompleteStateChange")));

    // Have we run off the end of stream

    if (IsEndOfStream() == TRUE) {
        Ready();
        return S_OK;
    }



    //
    // Make sure we get fresh data after being stopped
    //

    if (HaveSavedSample() == TRUE) {

        if (OldState != ImageSync_State_Stopped) {

            Ready();
            return S_OK;
        }
    }

    NotReady();

    return S_FALSE;
}


/*****************************Private*Routine******************************\
* CueImageSequence
*
* When we pause the filter the things we do are:-
*
*      Allow a threads to wait in Receive
*      Cancel any clock advise link (we may be playing an image sequence)
*      Possibly complete the state change if we have data
*
* History:
* Fri 01/21/2000 - StEstrop - Created
*
\**************************************************************************/
STDMETHODIMP
CImageSync::CueImageSequence(
    )
{
    AMTRACE((TEXT("CImageSync::CueImageSequence")));
    CAutoLock cIk(&m_InterfaceLock);

    DWORD OldState = m_State;

    //
    // Make sure there really is a state change
    //

    if (m_State == ImageSync_State_Cued) {
        return CompleteStateChange(ImageSync_State_Cued);
    }

    //
    // Pause the base filter class
    //
    m_State = ImageSync_State_Cued;

    StopStreaming();
    SourceThreadCanWait(TRUE);
    CancelNotification();
    ResetEndOfStreamTimer();

    //
    // There should be no outstanding advise
    //

    ASSERT(CancelNotification() == S_FALSE);
    ASSERT(WAIT_TIMEOUT == WaitForSingleObject((HANDLE)m_RenderEvent,0));
    ASSERT(m_EndOfStreamTimer == 0);


    //
    // When we come out of a stopped state we must clear any image we were
    // holding onto for frame refreshing. Since renderers see state changes
    // first we can reset ourselves ready to accept the source thread data
    // Paused or running after being stopped causes the current position to
    // be reset so we're not interested in passing end of stream signals
    //

    if (OldState == ImageSync_State_Stopped) {
        m_bAbort = FALSE;
        ClearSavedSample();
    }

    return CompleteStateChange(OldState);
}


/******************************Public*Routine******************************\
* GetImageSequenceState
*
* The renderer doesn't complete the full transition to paused states until
* it has got one media sample to render. If you ask it for its state while
* it's waiting it will return the state along with VFW_S_STATE_INTERMEDIATE
*
*
* History:
* Fri 01/21/2000 - StEstrop - Created
*
\**************************************************************************/
STDMETHODIMP
CImageSync::GetImageSequenceState(
    DWORD dwMSecs,
    DWORD *State
    )
{
    AMTRACE((TEXT("CImageSync::GetImageSequenceState")));
    if (!State)
        return E_POINTER;

    if (WaitDispatchingMessages(m_evComplete, dwMSecs) == WAIT_TIMEOUT) {
//  if (WaitForSingleObject(m_evComplete, dwMSecs) == WAIT_TIMEOUT) {
        *State = m_State;
        return VFW_S_STATE_INTERMEDIATE;
    }

    *State = m_State;

    return NOERROR;
}


/******************************Public*Routine******************************\
* BeginFlush
*
* When we are told to flush we should release the source thread
*
* History:
* Wed 03/29/2000 - StEstrop - Created
*
\**************************************************************************/
STDMETHODIMP
CImageSync::BeginFlush()
{
    AMTRACE((TEXT("CImageSync::BeginFlush")));

    CAutoLock cRendererLock(&m_InterfaceLock);
    {
        if (m_bFlushing) {
            return S_OK;
        }
        m_bFlushing = true;

        CAutoLock cSampleLock(&m_RendererLock);

        if (ImageSync_State_Cued == m_State) {
            NotReady();
        }

        SourceThreadCanWait(FALSE);
        CancelNotification();
        ClearSavedSample();

        //  Wait for Receive to complete
        WaitForReceiveToComplete();
    }

    return ResetEndOfStream();
}


/******************************Public*Routine******************************\
* EndFlush
*
* After flushing the source thread can wait in Receive again
*
* History:
* Wed 03/29/2000 - StEstrop - Created
*
\**************************************************************************/
STDMETHODIMP
CImageSync::EndFlush()
{
    AMTRACE((TEXT("CImageSync::EndFlush")));

    CAutoLock cRendererLock(&m_InterfaceLock);
    CAutoLock cSampleLock(&m_RendererLock);

    if (!m_bFlushing) {
        return S_OK;
    }
    m_bFlushing = false;

    // There should be no outstanding advise

    ASSERT(CancelNotification() == S_FALSE);
    SourceThreadCanWait(TRUE);
    return S_OK;

}

/******************************Public*Routine******************************\
* EndOfStream
*
*
* Called when the input pin receives an EndOfStream notification. If we have
* not got a sample, then notify EC_COMPLETE now. If we have samples, then set
* m_bEOS and check for this on completing samples. If we're waiting to pause
* then complete the transition to paused state by setting the state event
*
* History:
* Thu 03/30/2000 - StEstrop - Created
*
\**************************************************************************/
STDMETHODIMP
CImageSync::EndOfStream()
{
    AMTRACE((TEXT("CImageSync::EndOfStream")));

    CAutoLock cRendererLock(&m_InterfaceLock);
    CAutoLock cSampleLock(&m_RendererLock);

    // Ignore these calls if we are stopped

    if (m_State == ImageSync_State_Stopped) {
        return S_OK;
    }

    // If we have a sample then wait for it to be rendered

    m_bEOS = TRUE;
    if (HaveSavedSample()) {
        return S_OK;
    }

    //
    // If we are waiting for pause then we are now ready since we cannot now
    // carry on waiting for a sample to arrive since we are being told there
    // won't be any. This sets an event that the GetState function picks up
    //

    Ready();

    //
    // Only signal completion now if we are running otherwise queue it until
    // we do run in StartStreaming. This is used when we seek because a seek
    // causes a pause where early notification of completion is misleading
    //

    if (IsStreaming()) {
        SendEndOfStream();
    }

    return S_OK;
}


/******************************Public*Routine******************************\
* StopStreaming
*
* This is called when we stop streaming so that we can set our internal flag
* indicating we are not now to schedule any more samples arriving. The state
* change methods in the filter implementation take care of cancelling any
* clock advise link we have set up and clearing any pending sample we have
*
* History:
* Tue 01/11/2000 - StEstrop - Created
*
\**************************************************************************/
HRESULT
CImageSync::StopStreaming()
{
    AMTRACE((TEXT("CImageSync::StopStreaming")));
    CAutoLock cRLock(&m_RendererLock);

    if (IsStreaming()) {
        m_bStreaming = FALSE;
        OnStopStreaming();
        timeEndPeriod(1);
    }

    return S_OK;;
}


/*****************************Private*Routine******************************\
* WaitForReceiveToComplete
*
* Poll waiting for Receive to complete.  This really matters when
* Receive may set the palette and cause window messages
* The problem is that if we don't really wait for a renderer to
* stop processing we can deadlock waiting for a transform which
* is calling the renderer's Receive() method because the transform's
* Stop method doesn't know to process window messages to unblock
* the renderer's Receive processing
*
*
* History:
* Thu 01/13/2000 - StEstrop - Created
*
\**************************************************************************/
void
CImageSync::WaitForReceiveToComplete()
{
    AMTRACE((TEXT("CImageSync::WaitForReceiveToComplete")));
    for (; ; ) {

        if (!m_bInReceive) {
            break;
        }

        //
        //  Receive all interthread sendmessages
        //

        MSG msg;
        PeekMessage(&msg, NULL, WM_NULL, WM_NULL, PM_NOREMOVE);

        Sleep(1);
    }

    //
    // If the wakebit for QS_POSTMESSAGE is set, the PeekMessage call
    // above just cleared the changebit which will cause some messaging
    // calls to block (waitMessage, MsgWaitFor...) now.
    // Post a dummy message to set the QS_POSTMESSAGE bit again
    //

    if (HIWORD(GetQueueStatus(QS_POSTMESSAGE)) & QS_POSTMESSAGE) {

        //  Post dummy message
        PostThreadMessage(GetCurrentThreadId(), WM_NULL, 0, 0);
    }
}

/*****************************Private*Routine******************************\
* SourceThreadCanWait
*
* This is called whenever we change states, we have a manual reset event that
* is signalled whenever we don't won't the source filter thread to wait in us
* (such as in a stopped state) and likewise is not signalled whenever it can
* wait (during paused and running) this function sets or resets the thread
* event. The event is used to stop source filter threads waiting in Receive
*
* History:
* Fri 01/21/2000 - StEstrop - Created
*
\**************************************************************************/
HRESULT
CImageSync::SourceThreadCanWait(
    BOOL bCanWait
    )
{
    AMTRACE((TEXT("CImageSync::SourceThreadCanWait")));
    if (bCanWait == TRUE) {
        m_ThreadSignal.Reset();
    } else {
        CancelFrameStep();
        m_ThreadSignal.Set();
    }

    return NOERROR;
}



/******************************Public*Routine******************************\
* FrameStep
*
*
*
* History:
* Tue 01/11/2000 - StEstrop - Created
*
\**************************************************************************/
STDMETHODIMP
CImageSync::FrameStep(
    DWORD nFramesToStep,
    DWORD dwStepFlags
    )
{
    AMTRACE((TEXT("CImageSync::FrameStep")));
    CAutoLock cLock(&m_InterfaceLock);

    long l = m_lFramesToStep;
    m_lFramesToStep = nFramesToStep;

    //
    // If we are currently blocked on the frame step event
    // release the receive thread so that we can get another
    // frame
    //

    if (l == 0) {
        SetEvent(m_StepEvent);
    }
    return S_OK;
}


/******************************Public*Routine******************************\
* CancelFrameStep
*
*
*
* History:
* Tue 01/11/2000 - StEstrop - Created
*
\**************************************************************************/
STDMETHODIMP
CImageSync::CancelFrameStep()
{
    AMTRACE((TEXT("CImageSync::CancelFrameStep")));
    CAutoLock cLock(&m_InterfaceLock);

    //
    // cancel any outstanding steps
    //
    long l = m_lFramesToStep;
    m_lFramesToStep = -1;

    if (l == 0) {
        SetEvent(m_StepEvent);
    }

    return S_OK;
}
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\multimedia\dshow\filters\image2\core\resource.h ===
//{{NO_DEPENDENCIES}}
// Microsoft Developer Studio generated include file.
// Used by ImageSync.rc
//
#define IDS_PROJNAME                    100
#define IDR_IMAGESYNC                   101

// Next default values for new objects
// 
#ifdef APSTUDIO_INVOKED
#ifndef APSTUDIO_READONLY_SYMBOLS
#define _APS_NEXT_RESOURCE_VALUE        201
#define _APS_NEXT_COMMAND_VALUE         32768
#define _APS_NEXT_CONTROL_VALUE         201
#define _APS_NEXT_SYMED_VALUE           102
#endif
#endif
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\multimedia\dshow\filters\image2\core\imagesyncren.cpp ===
/******************************Module*Header*******************************\
* Module Name: ImageSyncRen.cpp
*
* Implements the IImageSync interface of the core Image Synchronization
* Object - based on DShow base classes CBaseRenderer and CBaseVideoRenderer.
*
*
* Created: Wed 01/12/2000
* Author:  Stephen Estrop [StEstrop]
*
* Copyright (c) 2000 Microsoft Corporation
\**************************************************************************/
#include <streams.h>
#include <windowsx.h>
#include <limits.h>


#include "ImageSyncObj.h"
#include "resource.h"
#include "dxmperf.h"


/////////////////////////////////////////////////////////////////////////////
// CImageSync
//
/////////////////////////////////////////////////////////////////////////////

// --------------------------------------------------------------------------
// Some helper inline functions
// --------------------------------------------------------------------------
__inline bool IsDiscontinuity(DWORD dwSampleFlags)
{
    return 0 != (dwSampleFlags & VMRSample_Discontinuity);
}

__inline bool IsTimeValid(DWORD dwSampleFlags)
{
    return 0 != (dwSampleFlags & VMRSample_TimeValid);
}

__inline bool IsSyncPoint(DWORD dwSampleFlags)
{
    return 0 != (dwSampleFlags & VMRSample_SyncPoint);
}


/*****************************Private*Routine******************************\
* TimeDiff
*
* Helper function for clamping time differences
*
* History:
* Wed 01/12/2000 - StEstrop - Created
*
\**************************************************************************/
__inline int TimeDiff(REFERENCE_TIME rt)
{
    AMTRACE((TEXT("TimeDiff")));
    if (rt < - (50 * UNITS))
    {
        return -(50 * UNITS);
    }
    else if (rt > 50 * UNITS)
    {
        return 50 * UNITS;
    }
    else
    {
        return (int)rt;
    }
}


/*****************************Private*Routine******************************\
* DoRenderSample
*
* Here is where the actual presentation occurs.
*
* History:
* Wed 01/12/2000 - StEstrop - Created
*
\**************************************************************************/
HRESULT
CImageSync::DoRenderSample(
    VMRPRESENTATIONINFO* lpPresInfo
    )
{
    AMTRACE((TEXT("CImageSync::DoRenderSample")));
    if (m_ImagePresenter) {
        return m_ImagePresenter->PresentImage(m_dwUserID, lpPresInfo);
    }
    return S_FALSE;
}

/*****************************Private*Routine******************************\
* RecordFrameLateness
*
* update the statistics:
* m_iTotAcc, m_iSumSqAcc, m_iSumSqFrameTime, m_iSumFrameTime, m_cFramesDrawn
* Note that because the properties page reports using these variables,
* 1. We need to be inside a critical section
* 2. They must all be updated together.  Updating the sums here and the count
* elsewhere can result in imaginary jitter (i.e. attempts to find square roots
* of negative numbers) in the property page code.
*
* History:
* Wed 01/12/2000 - StEstrop - Created
*
\**************************************************************************/
void
CImageSync::RecordFrameLateness(
    int trLate,
    int trFrame
    )
{
    AMTRACE((TEXT("CImageSync::RecordFrameLateness")));
    //
    // Record how timely we are.
    //

    int tLate = trLate/10000;

    //
    // Best estimate of moment of appearing on the screen is average of
    // start and end draw times.  Here we have only the end time.  This may
    // tend to show us as spuriously late by up to 1/2 frame rate achieved.
    // Decoder probably monitors draw time.  We don't bother.
    //

//  MSR_INTEGER( m_idFrameAccuracy, tLate );

    //
    // This is a hack - we can get frames that are ridiculously late
    // especially (at start-up) and they sod up the statistics.
    // So ignore things that are more than 1 sec off.
    //

    if (tLate>1000 || tLate<-1000) {

        if (m_cFramesDrawn<=1) {
            tLate = 0;
        } else if (tLate>0) {
            tLate = 1000;
        } else {
            tLate = -1000;
        }
    }

    //
    // The very first frame often has a bogus time, so I'm just
    // not going to count it into the statistics.   ???
    //

    if (m_cFramesDrawn>1) {
        m_iTotAcc += tLate;
        m_iSumSqAcc += (tLate*tLate);
    }

    //
    // calculate inter-frame time.  Doesn't make sense for first frame
    // second frame suffers from bogus first frame stamp.
    //

    if (m_cFramesDrawn>2) {
        int tFrame = trFrame/10000;    // convert to mSec else it overflows

        //
        // This is a hack.  It can overflow anyway (a pause can cause
        // a very long inter-frame time) and it overflows at 2**31/10**7
        // or about 215 seconds i.e. 3min 35sec
        //

        if (tFrame>1000||tFrame<0)
            tFrame = 1000;

        m_iSumSqFrameTime += tFrame*tFrame;
        ASSERT(m_iSumSqFrameTime>=0);
        m_iSumFrameTime += tFrame;
    }

    ++m_cFramesDrawn;

}


/*****************************Private*Routine******************************\
* ThrottleWait
*
*
*
* History:
* Wed 01/12/2000 - StEstrop - Created
*
\**************************************************************************/
void
CImageSync::ThrottleWait()
{
    AMTRACE((TEXT("CImageSync::ThrottleWait")));
    if (m_trThrottle > 0) {
        int iThrottle = m_trThrottle/10000;    // convert to mSec
//      MSR_INTEGER( m_idThrottle, iThrottle);
//      DbgLog((LOG_TRACE, 0, TEXT("Throttle %d ms"), iThrottle));
        Sleep(iThrottle);
    } else {
        Sleep(0);
    }
}


/*****************************Private*Routine******************************\
* OnRenderStart
*
* Called just before we start drawing.  All we do is to get the current clock
* time (from the system) and return.  We have to store the start render time
* in a member variable because it isn't used until we complete the drawing
* The rest is just performance logging.
*
* History:
* Wed 01/12/2000 - StEstrop - Created
*
\**************************************************************************/
void
CImageSync::OnRenderStart(
    VMRPRESENTATIONINFO* pSample
    )
{
    AMTRACE((TEXT("CImageSync::OnRenderStart")));

    if (PerflogTracingEnabled()) {
        REFERENCE_TIME rtClock = 0;
        if (NULL != m_pClock) {
            m_pClock->GetTime(&rtClock);
            rtClock -= m_tStart;
        }
        PERFLOG_VIDEOREND(pSample->rtStart, rtClock, lpSurf);
    }

    RecordFrameLateness(m_trLate, m_trFrame);
    m_tRenderStart = timeGetTime();
}


/*****************************Private*Routine******************************\
* OnRenderEnd
*
* Called directly after drawing an image.  We calculate the time spent in the
* drawing code and if this doesn't appear to have any odd looking spikes in
* it then we add it to the current average draw time.  Measurement spikes may
* occur if the drawing thread is interrupted and switched to somewhere else.
*
* History:
* Wed 01/12/2000 - StEstrop - Created
*
\**************************************************************************/
void
CImageSync::OnRenderEnd(
    VMRPRESENTATIONINFO* pSample
    )
{
    AMTRACE((TEXT("CImageSync::OnRenderEnd")));

    //
    // The renderer time can vary erratically if we are interrupted so we do
    // some smoothing to help get more sensible figures out but even that is
    // not enough as figures can go 9,10,9,9,83,9 and we must disregard 83
    //

    // convert mSec->UNITS
    int tr = (timeGetTime() - m_tRenderStart)*10000;

    if (tr < m_trRenderAvg*2 || tr < 2 * m_trRenderLast) {
        // DO_MOVING_AVG(m_trRenderAvg, tr);
        m_trRenderAvg = (tr + (AVGPERIOD-1)*m_trRenderAvg)/AVGPERIOD;
    }

    m_trRenderLast = tr;
    ThrottleWait();
}

/*****************************Private*Routine******************************\
* Render
*
* This is called when a sample comes due for rendering. We pass the sample
* on to the derived class. After rendering we will initialise the timer for
* the next sample, NOTE signal that the last one fired first, if we don't
* do this it thinks there is still one outstanding that hasn't completed
*
* History:
* Wed 01/12/2000 - StEstrop - Created
*
\**************************************************************************/
HRESULT
CImageSync::Render(
    VMRPRESENTATIONINFO* pSample
    )
{
    AMTRACE((TEXT("CImageSync::Render")));

    //
    // If the media sample is NULL then we will have been notified by the
    // clock that another sample is ready but in the mean time someone has
    // stopped us streaming which causes the next sample to be released
    //

    if (pSample == NULL) {
        return S_FALSE;
    }


    //
    // If we havn't been given anything to renderer with we are hosed too.
    //

    if (m_ImagePresenter == NULL) {
        return S_FALSE;
    }


    //
    // Time how long the rendering takes
    //

    OnRenderStart(pSample);
    HRESULT hr = DoRenderSample(pSample);
    OnRenderEnd(pSample);

    return hr;
}



/*****************************Private*Routine******************************\
* SendQuality
*
* Send a message to indicate what our supplier should do about quality.
* Theory:
* What a supplier wants to know is "is the frame I'm working on NOW
* going to be late?".
* F1 is the frame at the supplier (as above)
* Tf1 is the due time for F1
* T1 is the time at that point (NOW!)
* Tr1 is the time that f1 WILL actually be rendered
* L1 is the latency of the graph for frame F1 = Tr1-T1
* D1 (for delay) is how late F1 will be beyond its due time i.e.
* D1 = (Tr1-Tf1) which is what the supplier really wants to know.
* Unfortunately Tr1 is in the future and is unknown, so is L1
*
* We could estimate L1 by its value for a previous frame,
* L0 = Tr0-T0 and work off
* D1' = ((T1+L0)-Tf1) = (T1 + (Tr0-T0) -Tf1)
* Rearranging terms:
* D1' = (T1-T0) + (Tr0-Tf1)
*       adding (Tf0-Tf0) and rearranging again:
*     = (T1-T0) + (Tr0-Tf0) + (Tf0-Tf1)
*     = (T1-T0) - (Tf1-Tf0) + (Tr0-Tf0)
* But (Tr0-Tf0) is just D0 - how late frame zero was, and this is the
* Late field in the quality message that we send.
* The other two terms just state what correction should be applied before
* using the lateness of F0 to predict the lateness of F1.
* (T1-T0) says how much time has actually passed (we have lost this much)
* (Tf1-Tf0) says how much time should have passed if we were keeping pace
* (we have gained this much).
*
* Suppliers should therefore work off:
*    Quality.Late + (T1-T0)  - (Tf1-Tf0)
* and see if this is "acceptably late" or even early (i.e. negative).
* They get T1 and T0 by polling the clock, they get Tf1 and Tf0 from
* the time stamps in the frames.  They get Quality.Late from us.
*
*
*
* History:
* Wed 01/12/2000 - StEstrop - Created
*
\**************************************************************************/
HRESULT
CImageSync::SendQuality(
    REFERENCE_TIME trLate,
    REFERENCE_TIME trRealStream
    )
{
    AMTRACE((TEXT("CImageSync::SendQuality")));
    Quality q;
    HRESULT hr;

    //
    // If we are the main user of time, then report this as Flood/Dry.
    // If our suppliers are, then report it as Famine/Glut.
    //
    // We need to take action, but avoid hunting.  Hunting is caused by
    // 1. Taking too much action too soon and overshooting
    // 2. Taking too long to react (so averaging can CAUSE hunting).
    //
    // The reason why we use trLate as well as Wait is to reduce hunting;
    // if the wait time is coming down and about to go into the red, we do
    // NOT want to rely on some average which is only telling is that it used
    // to be OK once.
    //

    q.TimeStamp = (REFERENCE_TIME)trRealStream;

    if (m_trFrameAvg < 0) {
        q.Type = Famine;      // guess
    }

    //
    // Is the greater part of the time taken bltting or something else
    //

    else if (m_trFrameAvg > 2*m_trRenderAvg) {
        q.Type = Famine;                        // mainly other
    } else {
        q.Type = Flood;                         // mainly bltting
    }

    q.Proportion = 1000;               // default

    if (m_trFrameAvg < 0) {

        //
        // leave it alone - we don't know enough
        //
    }
    else if ( trLate> 0 ) {

        //
        // try to catch up over the next second
        // We could be Really, REALLY late, but rendering all the frames
        // anyway, just because it's so cheap.
        //

        q.Proportion = 1000 - (int)((trLate)/(UNITS/1000));
        if (q.Proportion<500) {
           q.Proportion = 500;      // don't go daft. (could've been negative!)
        } else {
        }

    }
    else if (m_trWaitAvg > 20000 && trLate < -20000 )
    {
        //
        // Go cautiously faster - aim at 2mSec wait.
        //

        if (m_trWaitAvg>=m_trFrameAvg) {

            //
            // This can happen because of some fudges.
            // The waitAvg is how long we originally planned to wait
            // The frameAvg is more honest.
            // It means that we are spending a LOT of time waiting
            //

            q.Proportion = 2000;    // double.
        } else {
            if (m_trFrameAvg+20000 > m_trWaitAvg) {
                q.Proportion
                    = 1000 * (m_trFrameAvg / (m_trFrameAvg + 20000 - m_trWaitAvg));
            } else {

                //
                // We're apparently spending more than the whole frame time waiting.
                // Assume that the averages are slightly out of kilter, but that we
                // are indeed doing a lot of waiting.  (This leg probably never
                // happens, but the code avoids any potential divide by zero).
                //

                q.Proportion = 2000;
            }
        }

        if (q.Proportion>2000) {
            q.Proportion = 2000;    // don't go crazy.
        }
    }

    //
    // Tell the supplier how late frames are when they get rendered
    // That's how late we are now.
    // If we are in directdraw mode then the guy upstream can see the drawing
    // times and we'll just report on the start time.  He can figure out any
    // offset to apply.  If we are in DIB Section mode then we will apply an
    // extra offset which is half of our drawing time.  This is usually small
    // but can sometimes be the dominant effect.  For this we will use the
    // average drawing time rather than the last frame.  If the last frame took
    // a long time to draw and made us late, that's already in the lateness
    // figure.  We should not add it in again unless we expect the next frame
    // to be the same.  We don't, we expect the average to be a better shot.
    // In direct draw mode the RenderAvg will be zero.
    //

    q.Late = trLate + m_trRenderAvg / 2;

    // log what we're doing
//  MSR_INTEGER(m_idQualityRate, q.Proportion);
//  MSR_INTEGER( m_idQualityTime, (int)q.Late / 10000 );

    //
    // We can't call the supplier directly - they have to call us when
    // Receive returns.  So save this message and return S_FALSE or S_OK
    // depending upon whether the previous quality message was retrieved or
    // not.
    //

    BOOL bLastMessageRead = m_bLastQualityMessageRead;
    m_bLastQualityMessageRead = false;
    m_bQualityMsgValid = true;
    m_QualityMsg = q;

    return bLastMessageRead ? S_OK : S_FALSE;

}

/*****************************Private*Routine******************************\
* PreparePerformanceData
*
* Put data on one side that describes the lateness of the current frame.
* We don't yet know whether it will actually be drawn.  In direct draw mode,
* this decision is up to the filter upstream, and it could change its mind.
* The rules say that if it did draw it must call Receive().  One way or
* another we eventually get into either OnRenderStart or OnDirectRender and
* these both call RecordFrameLateness to update the statistics.
*
* History:
* Wed 01/12/2000 - StEstrop - Created
*
\**************************************************************************/
void
CImageSync::PreparePerformanceData(
    int trLate,
    int trFrame
    )
{
    AMTRACE((TEXT("CImageSync::PreparePerformanceData")));
    m_trLate = trLate;
    m_trFrame = trFrame;
}


/******************************Public*Routine******************************\
* ShouldDrawSampleNow
*
* We are called to decide whether the current sample is to be
* be drawn or not.  There must be a reference clock in operation.
*
* Return S_OK if it is to be drawn Now (as soon as possible)
*
* Return S_FALSE if it is to be drawn when it's due
*
* Return an error if we want to drop it
* m_nNormal=-1 indicates that we dropped the previous frame and so this
* one should be drawn early.  Respect it and update it.
* Use current stream time plus a number of heuristics (detailed below)
* to make the decision
*
* History:
* Tue 01/11/2000 - StEstrop - Modified from CBaseRenderer
*
\**************************************************************************/
HRESULT
CImageSync::ShouldDrawSampleNow(
    VMRPRESENTATIONINFO* pSample,
    REFERENCE_TIME *ptrStart,
    REFERENCE_TIME *ptrEnd
    )
{
    AMTRACE((TEXT("CImageSync::ShouldDrawSampleNow")));
    //
    // Don't call us unless there's a clock interface to synchronise with
    //

    ASSERT(m_pClock);

//  MSR_INTEGER(m_idTimeStamp, (int)((*ptrStart)>>32));   // high order 32 bits
//  MSR_INTEGER(m_idTimeStamp, (int)(*ptrStart));         // low order 32 bits

    //
    // We lose a bit of time depending on the monitor type waiting for the next
    // screen refresh.  On average this might be about 8mSec - so it will be
    // later than we think when the picture appears.  To compensate a bit
    // we bias the media samples by -8mSec i.e. 80000 UNITs.
    // We don't ever make a stream time negative (call it paranoia)
    //

    if (*ptrStart>=80000) {
        *ptrStart -= 80000;
        *ptrEnd -= 80000;       // bias stop to to retain valid frame duration
    }

    //
    // Cache the time stamp now.  We will want to compare what we did with what
    // we started with (after making the monitor allowance).
    //

    m_trRememberStampForPerf = *ptrStart;

    //
    // Get reference times (current and late)
    // the real time now expressed as stream time.
    //

    REFERENCE_TIME trRealStream;
    m_pClock->GetTime(&trRealStream);

#ifdef PERF
    //
    // While the reference clock is expensive:
    // Remember the offset from timeGetTime and use that.
    // This overflows all over the place, but when we subtract to get
    // differences the overflows all cancel out.
    //

    m_llTimeOffset = trRealStream-timeGetTime()*10000;
#endif
    trRealStream -= m_tStart;     // convert to stream time (this is a reftime)

    //
    // We have to wory about two versions of "lateness".  The truth, which we
    // try to work out here and the one measured against m_trTarget which
    // includes long term feedback.  We report statistics against the truth
    // but for operational decisions we work to the target.
    // We use TimeDiff to make sure we get an integer because we
    // may actually be late (or more likely early if there is a big time
    // gap) by a very long time.
    //

    const int trTrueLate = TimeDiff(trRealStream - *ptrStart);
    const int trLate = trTrueLate;

//  MSR_INTEGER(m_idSchLateTime, trTrueLate/10000);

    //
    // Send quality control messages upstream, measured against target
    //

    HRESULT hr = SendQuality(trLate, trRealStream);

    //
    // Note: the filter upstream is allowed to this FAIL meaning "you do it".
    //

    m_bSupplierHandlingQuality = (hr==S_OK);

    //
    // Decision time!  Do we drop, draw when ready or draw immediately?
    //

    const int trDuration = (int)(*ptrEnd - *ptrStart);
    {
        //
        // We need to see if the frame rate of the file has just changed.
        // This would make comparing our previous frame rate with the current
        // frame rate difficult.  Hang on a moment though.  I've seen files
        // where the frames vary between 33 and 34 mSec so as to average
        // 30fps.  A minor variation like that won't hurt us.
        //

        int t = m_trDuration/32;
        if (trDuration > m_trDuration+t || trDuration < m_trDuration-t )
        {
            //
            // There's a major variation.  Reset the average frame rate to
            // exactly the current rate to disable decision 9002 for this frame,
            // and remember the new rate.
            //

            m_trFrameAvg = trDuration;
            m_trDuration = trDuration;
        }
    }

//  MSR_INTEGER(m_idEarliness, m_trEarliness/10000);
//  MSR_INTEGER(m_idRenderAvg, m_trRenderAvg/10000);
//  MSR_INTEGER(m_idFrameAvg, m_trFrameAvg/10000);
//  MSR_INTEGER(m_idWaitAvg, m_trWaitAvg/10000);
//  MSR_INTEGER(m_idDuration, trDuration/10000);

#ifdef PERF
    if (S_OK==IsDiscontinuity(dwSampleFlags)) {
        MSR_INTEGER(m_idDecision, 9000);
    }
#endif

    //
    // Control the graceful slide back from slow to fast machine mode.
    // After a frame drop accept an early frame and set the earliness to here
    // If this frame is already later than the earliness then slide it to here
    // otherwise do the standard slide (reduce by about 12% per frame).
    // Note: earliness is normally NEGATIVE
    //

    BOOL bJustDroppedFrame
        = (  m_bSupplierHandlingQuality
          //  Can't use the pin sample properties because we might
          //  not be in Receive when we call this
          && (S_OK == IsDiscontinuity(pSample->dwFlags))// he just dropped one
          )
       || (m_nNormal==-1);                              // we just dropped one

    //
    // Set m_trEarliness (slide back from slow to fast machine mode)
    //

    if (trLate>0) {
        m_trEarliness = 0;   // we are no longer in fast machine mode at all!
    } else if (  (trLate>=m_trEarliness) || bJustDroppedFrame) {
        m_trEarliness = trLate;  // Things have slipped of their own accord
    } else {
        m_trEarliness = m_trEarliness - m_trEarliness/8;  // graceful slide
    }

    //
    // prepare the new wait average - but don't pollute the old one until
    // we have finished with it.
    //

    int trWaitAvg;
    {
        //
        // We never mix in a negative wait.  This causes us to believe
        // in fast machines slightly more.
        //

        int trL = trLate<0 ? -trLate : 0;
        trWaitAvg = (trL + m_trWaitAvg*(AVGPERIOD-1))/AVGPERIOD;
    }


    int trFrame;
    {
        REFERENCE_TIME tr = trRealStream - m_trLastDraw; // Cd be large - 4 min pause!
        if (tr>10000000) {
            tr = 10000000;   // 1 second - arbitrarily.
        }
        trFrame = int(tr);
    }

    //
    // We will DRAW this frame IF...
    //

    if (
          // ...the time we are spending drawing is a small fraction of the total
          // observed inter-frame time so that dropping it won't help much.
          (3*m_trRenderAvg <= m_trFrameAvg)

         // ...or our supplier is NOT handling things and the next frame would
         // be less timely than this one or our supplier CLAIMS to be handling
         // things, and is now less than a full FOUR frames late.
       || ( m_bSupplierHandlingQuality
          ? (trLate <= trDuration*4)
          : (trLate+trLate < trDuration)
          )

          // ...or we are on average waiting for over eight milliseconds then
          // this may be just a glitch.  Draw it and we'll hope to catch up.
       || (m_trWaitAvg > 80000)

          // ...or we haven't drawn an image for over a second.  We will update
          // the display, which stops the video looking hung.
          // Do this regardless of how late this media sample is.
       || ((trRealStream - m_trLastDraw) > UNITS)

    ) {
        HRESULT Result;

        //
        // We are going to play this frame.  We may want to play it early.
        // We will play it early if we think we are in slow machine mode.
        // If we think we are NOT in slow machine mode, we will still play
        // it early by m_trEarliness as this controls the graceful slide back.
        // and in addition we aim at being m_trTarget late rather than "on time".
        //

        BOOL bPlayASAP = FALSE;

        //
        // we will play it AT ONCE (slow machine mode) if...
        //

        // ...we are playing catch-up
        if ( bJustDroppedFrame) {
            bPlayASAP = TRUE;
//          MSR_INTEGER(m_idDecision, 9001);
        }

        //
        // ...or if we are running below the true frame rate
        // exact comparisons are glitchy, for these measurements,
        // so add an extra 5% or so
        //

        else if (  (m_trFrameAvg > trDuration + trDuration/16)

           // It's possible to get into a state where we are losing ground, but
           // are a very long way ahead.  To avoid this or recover from it
           // we refuse to play early by more than 10 frames.

                && (trLate > - trDuration*10)
                ){
            bPlayASAP = TRUE;
//          MSR_INTEGER(m_idDecision, 9002);
        }

        //
        // We will NOT play it at once if we are grossly early.  On very slow frame
        // rate movies - e.g. clock.avi - it is not a good idea to leap ahead just
        // because we got starved (for instance by the net) and dropped one frame
        // some time or other.  If we are more than 900mSec early, then wait.
        //

        if (trLate<-9000000) {
            bPlayASAP = FALSE;
        }

        if (bPlayASAP) {

            m_nNormal = 0;
//          MSR_INTEGER(m_idDecision, 0);

            //
            // When we are here, we are in slow-machine mode.  trLate may well
            // oscillate between negative and positive when the supplier is
            // dropping frames to keep sync.  We should not let that mislead
            // us into thinking that we have as much as zero spare time!
            // We just update with a zero wait.
            //

            m_trWaitAvg = (m_trWaitAvg*(AVGPERIOD-1))/AVGPERIOD;

            //
            // Assume that we draw it immediately.  Update inter-frame stats
            //

            m_trFrameAvg = (trFrame + m_trFrameAvg*(AVGPERIOD-1))/AVGPERIOD;
#ifndef PERF
            //
            // if this is NOT a perf build, then report what we know so far
            // without looking at the clock any more.  This assumes that we
            // actually wait for exactly the time we hope to.  it also reports
            // how close we get to the hacked up time stamps that we now have
            // rather than the ones we originally started with.  It will
            // therefore be a little optimistic.  However it's fast.
            //

            PreparePerformanceData(trTrueLate, trFrame);
#endif
            m_trLastDraw = trRealStream;
            if (m_trEarliness > trLate) {
                m_trEarliness = trLate; // if we are actually early, this is neg
            }
            Result = S_OK;              // Draw it now

        } else {
            ++m_nNormal;

            //
            // Set the average frame rate to EXACTLY the ideal rate.
            // If we are exiting slow-machine mode then we will have caught up
            // and be running ahead, so as we slide back to exact timing we will
            // have a longer than usual gap at this point.  If we record this
            // real gap then we'll think that we're running slow and go back
            // into slow-machine mode and vever get it straight.
            //

            m_trFrameAvg = trDuration;
//          MSR_INTEGER(m_idDecision, 1);

            //
            // Play it early by m_trEarliness and by m_trTarget
            //

            {
                int trE = m_trEarliness;
                if (trE < -m_trFrameAvg) {
                    trE = -m_trFrameAvg;
                }
                *ptrStart += trE;           // N.B. earliness is negative
            }

            int Delay = -trTrueLate;
            Result = Delay<=0 ? S_OK : S_FALSE;  // OK = draw now, FALSE = wait

            m_trWaitAvg = trWaitAvg;

            //
            // Predict when it will actually be drawn and update frame stats
            //

            if (Result==S_FALSE) {   // We are going to wait
                trFrame = TimeDiff(*ptrStart-m_trLastDraw);
                m_trLastDraw = *ptrStart;
            } else {
                // trFrame is already = trRealStream-m_trLastDraw;
                m_trLastDraw = trRealStream;
            }
#ifndef PERF
            int iAccuracy;
            if (Delay>0) {
                // Report lateness based on when we intend to play it
                iAccuracy = TimeDiff(*ptrStart-m_trRememberStampForPerf);
            } else {
                // Report lateness based on playing it *now*.
                iAccuracy = trTrueLate;     // trRealStream-RememberStampForPerf;
            }
            PreparePerformanceData(iAccuracy, trFrame);
#endif
        }
        return Result;
    }

    //
    // We are going to drop this frame!
    // Of course in DirectDraw mode the guy upstream may draw it anyway.
    //

    //
    // This will probably give a large negative wack to the wait avg.
    //

    m_trWaitAvg = trWaitAvg;

#ifdef PERF
    // Respect registry setting - debug only!
    if (m_bDrawLateFrames) {
       return S_OK;                        // draw it when it's ready
    }                                      // even though it's late.
#endif

    //
    // We are going to drop this frame so draw the next one early
    // n.b. if the supplier is doing direct draw then he may draw it anyway
    // but he's doing something funny to arrive here in that case.
    //

//  MSR_INTEGER(m_idDecision, 2);
    m_nNormal = -1;
    return E_FAIL;                         // drop it
}


/*****************************Private*Routine******************************\
* CheckSampleTime
*
* Check the sample times for this samples (note the sample times are
* passed in by reference not value). We return S_FALSE to say schedule this
* sample according to the times on the sample. We also return S_OK in
* which case the object should simply render the sample data immediately
*
* History:
* Tue 01/11/2000 - StEstrop - Created
*
\**************************************************************************/
HRESULT
CImageSync::CheckSampleTimes(
    VMRPRESENTATIONINFO* pSample,
    REFERENCE_TIME *pStartTime,
    REFERENCE_TIME *pEndTime
    )
{
    AMTRACE((TEXT("CImageSync::CheckSampleTimes")));
    ASSERT(m_dwAdvise == 0);

    //
    // If the stop time for this sample is before or the same as start time,
    // then just ignore it
    //

    if (IsTimeValid(pSample->dwFlags)) {
        if (*pEndTime < *pStartTime) {
            return VFW_E_START_TIME_AFTER_END;
        }
    } else {
        // no time set in the sample... draw it now?
        return S_OK;
    }

    // Can't synchronise without a clock so we return S_OK which tells the
    // caller that the sample should be rendered immediately without going
    // through the overhead of setting a timer advise link with the clock

    if (m_pClock == NULL) {
        return S_OK;
    }

    return ShouldDrawSampleNow(pSample, pStartTime, pEndTime);
}


/*****************************Private*Routine******************************\
* ScheduleSample
*
*
*
* History:
* Thu 01/13/2000 - StEstrop - Created
*
\**************************************************************************/
HRESULT
CImageSync::ScheduleSample(
    VMRPRESENTATIONINFO* pSample
    )
{
    AMTRACE((TEXT("CImageSync::ScheduleSample")));
    HRESULT hr = ScheduleSampleWorker(pSample);

    if (FAILED(hr)) {
#if defined( EHOME_WMI_INSTRUMENTATION )
        PERFLOG_STREAMTRACE( 1, PERFINFO_STREAMTRACE_VMR_DROPPED_FRAME,
            0, pSample->rtStart, pSample->rtEnd, 0, 0 );
#endif
        ++m_cFramesDropped;
    }

    //
    // m_cFramesDrawn must NOT be updated here.  It has to be updated
    // in RecordFrameLateness at the same time as the other statistics.
    //

    return hr;
}


/*****************************Private*Routine******************************\
* ScheduleSampleWorker
*
* Responsible for setting up one shot advise links with the clock
*
* Returns a filure code (probably VFW_E_SAMPLE_REJECTED) if the sample was
* dropped (not drawn at all).
*
* Returns S_OK if the sample is scheduled to be drawn and in this case also
* arrange for m_RenderEvent to be set at the appropriate time
*
* History:
* Tue 01/11/2000 - StEstrop - Modified from CBaseRenderer
*
\**************************************************************************/
HRESULT
CImageSync::ScheduleSampleWorker(
    VMRPRESENTATIONINFO* pSample
    )
{
    AMTRACE((TEXT("CImageSync::ScheduleSampleWorker")));

    //
    // If the samples times arn't valid or if there is no
    // reference clock
    //
    REFERENCE_TIME startTime = pSample->rtStart;
    REFERENCE_TIME endTime   = pSample->rtEnd;

    HRESULT hr = CheckSampleTimes(pSample, &startTime, &endTime);
    if (FAILED(hr)) {
        if (hr != VFW_E_START_TIME_AFTER_END) {
            hr = VFW_E_SAMPLE_REJECTED;
        }
        return hr;
    }

    //
    // If we don't have a reference clock then we cannot set up the advise
    // time so we simply set the event indicating an image to render. This
    // will cause us to run flat out without any timing or synchronisation
    //

    if (hr == S_OK) {
        EXECUTE_ASSERT(SetEvent((HANDLE)m_RenderEvent));
        return S_OK;
    }

    ASSERT(m_dwAdvise == 0);
    ASSERT(m_pClock);
    ASSERT(WAIT_TIMEOUT == WaitForSingleObject((HANDLE)m_RenderEvent, 0));

    //
    // We do have a valid reference clock interface so we can ask it to
    // set an event when the image comes due for rendering. We pass in
    // the reference time we were told to start at and also the current
    // stream time which is the offset from the start reference time
    //

#if defined( EHOME_WMI_INSTRUMENTATION )
    PERFLOG_STREAMTRACE(
        1,
        PERFINFO_STREAMTRACE_VMR_BEGIN_ADVISE,
        startTime, m_tStart, 0, 0, 0 );
#endif

    hr = m_pClock->AdviseTime(
            (REFERENCE_TIME)m_tStart,           // Start run time
            startTime,                          // Stream time
            (HEVENT)(HANDLE)m_RenderEvent,      // Render notification
            &m_dwAdvise);                       // Advise cookie

    if (SUCCEEDED(hr)) {
        return S_OK;
    }

    //
    // We could not schedule the next sample for rendering despite the fact
    // we have a valid sample here. This is a fair indication that either
    // the system clock is wrong or the time stamp for the sample is duff
    //

    ASSERT(m_dwAdvise == 0);
    return VFW_E_SAMPLE_REJECTED;
}


/*****************************Private*Routine******************************\
* OnWaitStart()
*
* Called when we start waiting for a rendering event.
* Used to update times spent waiting and not waiting.
*
*
* History:
* Tue 01/11/2000 - StEstrop - Modified from CBaseRenderer
*
\**************************************************************************/
void CImageSync::OnWaitStart()
{
    AMTRACE((TEXT("CImageSync::OnWaitStart")));
#ifdef PERF
    MSR_START(m_idWaitReal);
#endif //PERF
}


/*****************************Private*Routine******************************\
* OnWaitEnd
*
*
* History:
* Tue 01/11/2000 - StEstrop - Modified from CBaseRenderer
*
\**************************************************************************/
void
CImageSync::OnWaitEnd()
{
    AMTRACE((TEXT("CImageSync::OnWaitEnd")));
#ifdef PERF

    MSR_STOP(m_idWaitReal);

    //
    // for a perf build we want to know just exactly how late we REALLY are.
    // even if this means that we have to look at the clock again.
    //

    REFERENCE_TIME trRealStream;  // the real time now expressed as stream time.

    //
    // We will be discarding overflows like mad here!
    // This is wrong really because timeGetTime() can wrap but it's
    // only for PERF
    //

    REFERENCE_TIME tr = timeGetTime()*10000;
    trRealStream = tr + m_llTimeOffset;
    trRealStream -= m_tStart;     // convert to stream time (this is a reftime)

    if (m_trRememberStampForPerf==0) {

        //
        // This is probably the poster frame at the start, and it is not scheduled
        // in the usual way at all.  Just count it.  The rememberstamp gets set
        // in ShouldDrawSampleNow, so this does bogus frame recording until we
        // actually start playing.
        //

        PreparePerformanceData(0, 0);
    }
    else {

        int trLate = (int)(trRealStream - m_trRememberStampForPerf);
        int trFrame = (int)(tr - m_trRememberFrameForPerf);
        PreparePerformanceData(trLate, trFrame);
    }
    m_trRememberFrameForPerf = tr;

#endif //PERF
}


/*****************************Private*Routine******************************\
* WaitForRenderTime
*
* Wait until the clock sets the timer event or we're otherwise signalled. We
* set an arbitrary timeout for this wait and if it fires then we display the
* current renderer state on the debugger. It will often fire if the filter's
* left paused in an application however it may also fire during stress tests
* if the synchronisation with application seeks and state changes is faulty
*
* History:
* Tue 01/11/2000 - StEstrop - Modified from CBaseRenderer
*
\**************************************************************************/
HRESULT
CImageSync::WaitForRenderTime()
{
    AMTRACE((TEXT("CImageSync::WaitForRenderTime")));
    HANDLE WaitObjects[] = { m_ThreadSignal, m_RenderEvent };
    DWORD Result = WAIT_TIMEOUT;

    //
    // Wait for either the time to arrive or for us to be stopped
    //

    OnWaitStart();
    while (Result == WAIT_TIMEOUT) {

        Result = WaitForMultipleObjects(2, WaitObjects, FALSE, RENDER_TIMEOUT);

        //#ifdef DEBUG
        //    if (Result == WAIT_TIMEOUT) DisplayRendererState();
        //#endif

    }
    OnWaitEnd();

    //
    // We may have been awoken without the timer firing
    //

    if (Result == WAIT_OBJECT_0) {
        return VFW_E_STATE_CHANGED;
    }

    SignalTimerFired();
    return S_OK;
}


/*****************************Private*Routine******************************\
* SignalTimerFired
*
* We must always reset the current advise time to zero after a timer fires
* because there are several possible ways which lead us not to do any more
* scheduling such as the pending image being cleared after state changes
*
* History:
* Tue 01/11/2000 - StEstrop - Modified from CBaseRenderer
*
\**************************************************************************/
void
CImageSync::SignalTimerFired()
{
    AMTRACE((TEXT("CImageSync::SignalTimerFired")));
    m_dwAdvise = 0;

#if defined( EHOME_WMI_INSTRUMENTATION )
    PERFLOG_STREAMTRACE(
        1,
        PERFINFO_STREAMTRACE_VMR_END_ADVISE,
        0, 0, 0, 0, 0 );
#endif

}


/*****************************Private*Routine******************************\
* SaveSample
*
*
*
* History:
* Thu 01/13/2000 - StEstrop - Created
*
\**************************************************************************/
HRESULT
CImageSync::SaveSample(
    VMRPRESENTATIONINFO* pSample
    )
{
    AMTRACE((TEXT("CImageSync::SaveSample")));
    CAutoLock cRendererLock(&m_RendererLock);
    if (m_pSample) {
        return E_FAIL;
    }

    m_pSample = pSample;

    return S_OK;
}


/*****************************Private*Routine******************************\
* GetSavedSample
*
*
*
* History:
* Thu 01/13/2000 - StEstrop - Created
*
\**************************************************************************/
HRESULT
CImageSync::GetSavedSample(
    VMRPRESENTATIONINFO** ppSample
    )
{
    AMTRACE((TEXT("CImageSync::GetSavedSample")));
    CAutoLock cRendererLock(&m_RendererLock);
    if (!m_pSample) {

        DbgLog((LOG_TRACE, 1,
                TEXT("CImageSync::GetSavedSample  Sample not available") ));
        return E_FAIL;
    }

    *ppSample = m_pSample;

    return S_OK;
}

/*****************************Private*Routine******************************\
* HaveSavedSample
*
* Checks if there is a sample waiting at the renderer
*
* History:
* Thu 01/13/2000 - StEstrop - Created
*
\**************************************************************************/
BOOL CImageSync::HaveSavedSample()
{
    AMTRACE((TEXT("CImageSync::HaveSavedSample")));
    CAutoLock cRendererLock(&m_RendererLock);
    DbgLog((LOG_TRACE, 1,
            TEXT("CImageSync::HaveSavedSample = %d"), m_pSample != NULL));
    return m_pSample != NULL;
}

/*****************************Private*Routine******************************\
* ClearSavedSample
*
*
*
* History:
* Thu 01/13/2000 - StEstrop - Created
*
\**************************************************************************/
void
CImageSync::ClearSavedSample()
{
    AMTRACE((TEXT("CImageSync::ClearSavedSample")));
    CAutoLock cRendererLock(&m_RendererLock);
    m_pSample = NULL;
}


/*****************************Private*Routine******************************\
* CancelNotification
*
* Cancel any notification currently scheduled. This is called by the owning
* window object when it is told to stop streaming. If there is no timer link
* outstanding then calling this is benign otherwise we go ahead and cancel
* We must always reset the render event as the quality management code can
* signal immediate rendering by setting the event without setting an advise
* link. If we're subsequently stopped and run the first attempt to setup an
* advise link with the reference clock will find the event still signalled
*
* History:
* Tue 01/11/2000 - StEstrop - Modified from CBaseRenderer
*
\**************************************************************************/
HRESULT
CImageSync::CancelNotification()
{
    AMTRACE((TEXT("CImageSync::CancelNotification")));
    ASSERT(m_dwAdvise == 0 || m_pClock);
    DWORD_PTR dwAdvise = m_dwAdvise;

    //
    // Have we a live advise link
    //

    if (m_dwAdvise) {
        m_pClock->Unadvise(m_dwAdvise);
        SignalTimerFired();
        ASSERT(m_dwAdvise == 0);
    }

    //
    // Clear the event and return our status
    //

    m_RenderEvent.Reset();

    return (dwAdvise ? S_OK : S_FALSE);
}

/*****************************Private*Routine******************************\
* OnReceiveFirstSample
*
*
*
* History:
* Wed 01/12/2000 - StEstrop - Created
*
\**************************************************************************/
HRESULT
CImageSync::OnReceiveFirstSample(
    VMRPRESENTATIONINFO* pSample
    )
{
    AMTRACE((TEXT("CImageSync::OnReceiveFirstSample")));
    return DoRenderSample(pSample);
}


/*****************************Private*Routine******************************\
* PrepareReceive
*
* Called when the source delivers us a sample. We go through a few checks to
* make sure the sample can be rendered. If we are running (streaming) then we
* have the sample scheduled with the reference clock, if we are not streaming
* then we have received an sample in paused mode so we can complete any state
* transition. On leaving this function everything will be unlocked so an app
* thread may get in and change our state to stopped (for example) in which
* case it will also signal the thread event so that our wait call is stopped
*
* History:
* Thu 01/13/2000 - StEstrop - Created
*
\**************************************************************************/
HRESULT
CImageSync::PrepareReceive(
    VMRPRESENTATIONINFO* pSample
    )
{
    AMTRACE((TEXT("CImageSync::PrepareReceive")));
    CAutoLock cILock(&m_InterfaceLock);
    m_bInReceive = TRUE;

    // Check our flushing state

    if (m_bFlushing) {
        m_bInReceive = FALSE;
        return E_FAIL;
    }

    CAutoLock cRLock(&m_RendererLock);

    //
    // Return an error if we already have a sample waiting for rendering
    // source pins must serialise the Receive calls - we also check that
    // no data is being sent after the source signalled an end of stream
    //

    if (HaveSavedSample() || m_bEOS || m_bAbort) {
        Ready();
        m_bInReceive = FALSE;
        return E_UNEXPECTED;
    }

    //
    // Schedule the next sample if we are streaming
    //

    if (IsStreaming()) {

        if (FAILED(ScheduleSample(pSample))) {

            ASSERT(WAIT_TIMEOUT == WaitForSingleObject((HANDLE)m_RenderEvent,0));
            ASSERT(CancelNotification() == S_FALSE);
            m_bInReceive = FALSE;
            return VFW_E_SAMPLE_REJECTED;
        }

        EXECUTE_ASSERT(S_OK == SaveSample(pSample));
    }

    //
    // else we are not streaming yet, just save the sample and wait in Receive
    // until BeginImageSequence is called.  BeginImageSequence passes a base
    // start time with which we schedule the saved sample.
    //

    else {

        // ASSERT(IsFirstSample(dwSampleFlags));
        EXECUTE_ASSERT(S_OK == SaveSample(pSample));
    }

    // Store the sample end time for EC_COMPLETE handling
    m_SignalTime = pSample->rtEnd;

    return S_OK;
}


/*****************************Private*Routine******************************\
* FrameStepWorker
*
*
*
* History:
* Tue 08/29/2000 - StEstrop - Created
*
\**************************************************************************/
void CImageSync::FrameStepWorker()
{
    AMTRACE((TEXT("CImageSync::FrameStepWorker")));
    CAutoLock cLock(&m_InterfaceLock);

    if (m_lFramesToStep == 1) {
        m_lFramesToStep--;
        m_InterfaceLock.Unlock();
        m_lpEventNotify->NotifyEvent(EC_STEP_COMPLETE, FALSE, 0);
        DWORD dw = WaitForSingleObject(m_StepEvent, INFINITE);
        m_InterfaceLock.Lock();
        ASSERT(m_lFramesToStep != 0);
    }
}


/******************************Public*Routine******************************\
* Receive
*
* Return the buffer to the renderer along with time stamps relating to
* when the buffer should be presented.
*
* History:
* Tue 01/11/2000 - StEstrop - Created
*
\**************************************************************************/
STDMETHODIMP
CImageSync::Receive(
    VMRPRESENTATIONINFO* lpPresInfo
    )
{
    AMTRACE((TEXT("CImageSync::Receive")));

    //
    // Frame step hack-o-matic
    //
    // This code acts as a gate - for a frame step of N frames
    // it discards N-1 frames and then lets the Nth frame thru the
    // the gate to be rendered in the normal way i.e. at the correct
    // time.  The next time Receive is called the gate is shut and
    // the thread blocks.  The gate only opens again when the step
    // is cancelled or another frame step request comes in.
    //
    // StEstrop - Thu 10/21/1999
    //

    {
        CAutoLock cLock(&m_InterfaceLock);

        //
        // do we have frames to discard ?
        //

        if (m_lFramesToStep > 1) {
            m_lFramesToStep--;
            if (m_lFramesToStep > 0) {
                return NOERROR;
            }
        }
    }

    return ReceiveWorker(lpPresInfo);
}

/******************************Public*Routine******************************\
* ReceiveWorker
*
* Return the buffer to the renderer along with time stamps relating to
* when the buffer should be presented.
*
* History:
* Tue 01/11/2000 - StEstrop - Created
*
\**************************************************************************/
HRESULT
CImageSync::ReceiveWorker(
    VMRPRESENTATIONINFO* pSample
    )
{
    AMTRACE((TEXT("CImageSync::ReceiveWorker")));

    ASSERT(pSample);

    //
    // Prepare for this Receive call, this may return the VFW_E_SAMPLE_REJECTED
    // error code to say don't bother - depending on the quality management.
    //

    HRESULT hr = PrepareReceive(pSample);
    ASSERT(m_bInReceive == SUCCEEDED(hr));
    if (FAILED(hr)) {
        if (hr == VFW_E_SAMPLE_REJECTED) {
            return S_OK;
        }
        return hr;
    }


    //
    // We special case "first samples"
    //
    BOOL bSampleRendered = FALSE;
    if (m_State == ImageSync_State_Cued) {

        //
        // no need to use InterlockedExchange
        //

        m_bInReceive = FALSE;
        {
            //
            // We must hold both these locks
            //

            CAutoLock cILock(&m_InterfaceLock);

            if (m_State == ImageSync_State_Stopped)
                return S_OK;

            m_bInReceive = TRUE;
            CAutoLock cRLock(&m_RendererLock);
            hr = OnReceiveFirstSample(pSample);
            bSampleRendered = TRUE;
        }
        Ready();
    }

    //
    // Having set an advise link with the clock we sit and wait. We may be
    // awoken by the clock firing or by the CancelRender event.
    //

    if (FAILED(WaitForRenderTime())) {
        m_bInReceive = FALSE;
        return hr;
    }
    DbgLog((LOG_TIMING, 3,
       TEXT("CImageSync::ReceiveWorker WaitForRenderTime completed for this video sample") ));

    m_bInReceive = FALSE;

    //
    // Deal with this sample - We must hold both these locks
    //
    {
        CAutoLock cILock(&m_InterfaceLock);
        if (m_State == ImageSync_State_Stopped)
            return S_OK;

        CAutoLock cRLock(&m_RendererLock);
        if (!bSampleRendered) {
            hr = Render(m_pSample);
        }
    }

    FrameStepWorker();

    {
        CAutoLock cILock(&m_InterfaceLock);
        CAutoLock cRLock(&m_RendererLock);
        //
        // Clean up
        //

        ClearSavedSample();
        SendEndOfStream();
        CancelNotification();
    }

    return hr;
}


/******************************Public*Routine******************************\
* GetQualityControlMessage
*
* ask for quality control information from the renderer
*
* History:
* Tue 01/11/2000 - StEstrop - Created
*
\**************************************************************************/
STDMETHODIMP
CImageSync::GetQualityControlMessage(
    Quality* pQualityMsg
    )
{
    AMTRACE((TEXT("CImageSync::GetQualityControlMessage")));
    CAutoLock cILock(&m_InterfaceLock);
    CAutoLock cRLock(&m_RendererLock);

    if (!pQualityMsg) {
        return E_POINTER;
    }

    if (m_bQualityMsgValid) {
        *pQualityMsg = m_QualityMsg;
        m_bLastQualityMessageRead = TRUE;
        return S_OK;
    }
    else
        return S_FALSE;
}
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\multimedia\dshow\filters\image2\inc\amva.h ===
/*==========================================================================;
 *
 *  Copyright (C) 1997 Microsoft Corporation.  All Rights Reserved.
 *
 *  File:	amva.h
 *  Content:	DirectShowMotionComp include file
 *
 ***************************************************************************/


#ifndef __AMVA_INCLUDED__
#define __AMVA_INCLUDED__

#ifdef __cplusplus
extern "C" {
#endif


#define AMVA_TYPEINDEX_OUTPUTFRAME 0xFFFFFFFF

//  Flags for QueryRenderStatus
#define AMVA_QUERYRENDERSTATUSF_READ     0x00000001  // Query for read
                                                     // set this bit to 0
                                                     // if query for update

typedef struct _tag_AMVAUncompBufferInfo
{
 DWORD                   dwMinNumSurfaces;           // IN   min number of surfaces to be allocated
 DWORD                   dwMaxNumSurfaces;           // IN   max number of surfaces to be allocated
 DDPIXELFORMAT           ddUncompPixelFormat;        // IN   pixel format of surfaces to be allocated
} AMVAUncompBufferInfo, *LPAMVAUncompBufferInfo;

typedef struct _tag_AMVAUncompDataInfo
{
    DWORD                   dwUncompWidth;              // [in]     width of uncompressed data
    DWORD                   dwUncompHeight;             // [in]     height of uncompressed data
    DDPIXELFORMAT           ddUncompPixelFormat;        // [in]     pixel-format of uncompressed data
} AMVAUncompDataInfo, *LPAMVAUncompDataInfo;

typedef struct _tag_AMVAInternalMemInfo
{
    DWORD                   dwScratchMemAlloc;          // [out]    amount of scratch memory will the hal allocate for its private use
} AMVAInternalMemInfo, *LPAMVAInternalMemInfo;


typedef struct _tag_AMVACompBufferInfo
{
    DWORD                   dwNumCompBuffers;           // [out]    number of buffers reqd for compressed data
    DWORD                   dwWidthToCreate;            // [out]    Width of surface to create
    DWORD                   dwHeightToCreate;           // [out]    Height of surface to create
    DWORD                   dwBytesToAllocate;          // [out]    Total number of bytes used by each surface
    DDSCAPS2                ddCompCaps;                 // [out]    caps to create surfaces to store compressed data
    DDPIXELFORMAT           ddPixelFormat;              // [out]    fourcc to create surfaces to store compressed data
} AMVACompBufferInfo, *LPAMVACompBufferInfo;


// Note that you are NOT allowed to store any pointer in pMiscData
typedef struct _tag_AMVABeginFrameInfo
{
    DWORD                dwDestSurfaceIndex;         // IN  destination buffer in which to decoding this frame
    LPVOID               pInputData;                 // IN  pointer to misc data
    DWORD                dwSizeInputData;            // IN  size of other misc data to begin frame
    LPVOID               pOutputData;                // OUT pointer to data which the VGA is going to fill
    DWORD                dwSizeOutputData;           // IN  size of data which the VGA is going to fill
} AMVABeginFrameInfo, *LPAMVABeginFrameInfo;

// Note that you are NOT allowed to store any pointer in pMiscData
typedef struct _tag_AMVAEndFrameInfo
{
    DWORD                   dwSizeMiscData;             // [in]     size of other misc data to begin frame
    LPVOID                  pMiscData;                  // [in]     pointer to misc data
} AMVAEndFrameInfo, *LPAMVAEndFrameInfo;

typedef struct _tag_AMVABUFFERINFO
{
    DWORD                   dwTypeIndex;                // [in]    Type of buffer
    DWORD                   dwBufferIndex;              // [in]    Buffer index
    DWORD                   dwDataOffset;               // [in]    offset of relevant data from the beginning of buffer
    DWORD                   dwDataSize;                 // [in]    size of relevant data
} AMVABUFFERINFO, *LPAMVABUFFERINFO;

#ifdef __cplusplus
};
#endif

#endif // _AMVA_INCLUDED
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\multimedia\dshow\filters\image2\inc\ddva.h ===
/*==========================================================================;
 *
 *  Copyright (c) 1997 - 1998  Microsoft Corporation.  All Rights Reserved.
 *
 *  File:	ddmc.h
 *  Content:	DirectDrawMotionComp include file
 *@@BEGIN_MSINTERNAL
 *  History:
 *   Date	By	Reason
 *   ====	==	======
 *   22-sep-97	smac
 *@@END_MSINTERNAL
 *
 ***************************************************************************/

#ifndef __DDVA_INCLUDED__
#define __DDVA_INCLUDED__
#if defined( _WIN32 )  && !defined( _NO_COM )
#define COM_NO_WINDOWS_H
#include <objbase.h>
#else
#define IUnknown	    void
#undef  CO_E_NOTINITIALIZED
#define CO_E_NOTINITIALIZED 0x800401F0L
#endif

#ifdef __cplusplus
extern "C" {
#endif

/*
 * GUIDS used by DirectDrawVideoAccelerator objects
 */
#if defined( _WIN32 ) && !defined( _NO_COM )
DEFINE_GUID( IID_IDDVideoAcceleratorContainer,	0xACA12120,0x3356,0x11D1,0x8F,0xCF,0x00,0xC0,0x4F,0xC2,0x9B,0x4E );
DEFINE_GUID( IID_IDirectDrawVideoAccelerator,   0xC9B2D740,0x3356,0x11D1,0x8F,0xCF,0x00,0xC0,0x4F,0xC2,0x9B,0x4E );
#endif

/*============================================================================
 *
 * DirectDraw Structures
 *
 * Various structures used to invoke DirectDraw.
 *
 *==========================================================================*/

struct IDirectDraw;
struct IDirectDrawSurface;
struct IDirectDrawPalette;
struct IDirectDrawClipper;

typedef struct IDDVideoAcceleratorContainer		FAR *LPDDVIDEOACCELERATORCONTAINER;
typedef struct IDirectDrawVideoAccelerator		FAR *LPDIRECTDRAWVIDEOACCELERATOR;

typedef struct IDDVideoAcceleratorContainerVtbl DDVIDEOACCELERATORCONTAINERCALLBACKS;
typedef struct IDirectDrawVideoAcceleratorVtbl  DIRECTDRAWVIDEOACCELERATORCALLBACKS;


typedef struct _tag_DDVAUncompDataInfo
{
    DWORD                   dwSize;                     // [in]     size of the struct
    DWORD                   dwUncompWidth;              // [in]     width of uncompressed data
    DWORD                   dwUncompHeight;             // [in]     height of uncompressed data
    DDPIXELFORMAT           ddUncompPixelFormat;        // [in]     pixel-format of uncompressed data
} DDVAUncompDataInfo, *LPDDVAUncompDataInfo;

typedef struct _tag_DDVAInternalMemInfo
{
    DWORD                   dwSize;                     // [in]     size of the struct
    DWORD                   dwScratchMemAlloc;          // [out]    amount of scratch memory will the hal allocate for its private use
} DDVAInternalMemInfo, *LPDDVAInternalMemInfo;


typedef struct _tag_DDVACompBufferInfo
{
    DWORD                   dwSize;                     // [in]     size of the struct
    DWORD                   dwNumCompBuffers;           // [out]    number of buffers reqd for compressed data
    DWORD                   dwWidthToCreate;            // [out]    Width of surface to create
    DWORD                   dwHeightToCreate;           // [out]    Height of surface to create
    DWORD                   dwBytesToAllocate;          // [out]    Total number of bytes used by each surface
    DDSCAPS2                ddCompCaps;                 // [out]    caps to create surfaces to store compressed data
    DDPIXELFORMAT           ddPixelFormat;              // [out]    fourcc to create surfaces to store compressed data
} DDVACompBufferInfo, *LPDDVACompBufferInfo;


// Note that you are NOT allowed to store any pointer in pMiscData
typedef struct _tag_DDVABeginFrameInfo
{
    DWORD                   dwSize;                     // [in]     size of the struct
    LPDIRECTDRAWSURFACE7    pddDestSurface;             // [in]     destination buffer in which to decoding this frame
    DWORD                   dwSizeInputData;            // [in]     size of other misc data to begin frame
    LPVOID                  pInputData;                 // [in]     pointer to misc data
    DWORD                   dwSizeOutputData;           // [in/out] size of other misc data to begin frame
    LPVOID                  pOutputData;                // [out]    pointer to misc data
} DDVABeginFrameInfo, *LPDDVABeginFrameInfo;

// Note that you are NOT allowed to store any pointer in pMiscData
typedef struct _tag_DDVAEndFrameInfo
{
    DWORD                   dwSize;                     // [in]     size of the struct
    DWORD                   dwSizeMiscData;             // [in]     size of other misc data to begin frame
    LPVOID                  pMiscData;                  // [in]     pointer to misc data
} DDVAEndFrameInfo, *LPDDVAEndFrameInfo;

typedef struct _tag_DDVABUFFERINFO
{
    DWORD                   dwSize;                     // [in]    size of the struct
    LPDIRECTDRAWSURFACE7    pddCompSurface;             // [in]    pointer to buffer containing compressed data
    DWORD                   dwDataOffset;               // [in]    offset of relevant data from the beginning of buffer
    DWORD                   dwDataSize;                 // [in]    size of relevant data
} DDVABUFFERINFO, *LPDDVABUFFERINFO;


/*
 * INTERACES FOLLOW:
 *	IDDVideoAcceleratorContainer
 *	IDirectDrawVideoAccelerator
 */

/*
 * IDDVideoAcceleratorContainer
 */
#if defined( _WIN32 ) && !defined( _NO_COM )
#undef INTERFACE
#define INTERFACE IDDVideoAcceleratorContainer
DECLARE_INTERFACE_( IDDVideoAcceleratorContainer, IUnknown )
{
    /*** IUnknown methods ***/
    STDMETHOD(QueryInterface) (THIS_ REFIID riid, LPVOID FAR * ppvObj) PURE;
    STDMETHOD_(ULONG,AddRef) (THIS)  PURE;
    STDMETHOD_(ULONG,Release) (THIS) PURE;
    /*** IDDVideoAcceleratorContainer methods ***/
    STDMETHOD(CreateVideoAccelerator)(THIS_ LPGUID, LPDDVAUncompDataInfo, LPVOID, DWORD, LPDIRECTDRAWVIDEOACCELERATOR FAR *, IUnknown FAR *) PURE;
    STDMETHOD(GetCompBufferInfo)(THIS_ LPGUID, LPDDVAUncompDataInfo, LPDWORD, LPDDVACompBufferInfo ) PURE;
    STDMETHOD(GetInternalMemInfo)(THIS_ LPGUID, LPDDVAUncompDataInfo, LPDDVAInternalMemInfo ) PURE;
    STDMETHOD(GetVideoAcceleratorGUIDs)(THIS_ LPDWORD, LPGUID ) PURE;
    STDMETHOD(GetUncompFormatsSupported)(THIS_ LPGUID, LPDWORD, LPDDPIXELFORMAT ) PURE;
};

#if !defined(__cplusplus) || defined(CINTERFACE)
#define IVideoAcceleratorContainer_QueryInterface(p, a, b)            (p)->lpVtbl->QueryInterface(p, a, b)
#define IVideoAcceleratorContainer_AddRef(p)                          (p)->lpVtbl->AddRef(p)
#define IVideoAcceleratorContainer_Release(p)                         (p)->lpVtbl->Release(p)
#define IVideoAcceleratorContainer_CreateVideoAccelerator(p,a,b,c,d,e,f)    (p)->lpVtbl->CreateVideoAccelerator(p, a, b, c, d, e, f)
#define IVideoAcceleratorContainer_GetCompBufferInfo(p, a, b, c, d)   (p)->lpVtbl->GetCompBufferInfo(p, a, b, c, d)
#define IVideoAcceleratorContainer_GetInternalMemInfo(p, a, b, c)     (p)->lpVtbl->GetInternalMemInfo(p, a, b, c)
#define IVideoAcceleratorContainer_GetVideoAcceleratorGUIDs(p, a, b)        (p)->lpVtbl->GetVideoAcceleratorGUIDs(p, a, b)
#define IVideoAcceleratorContainer_GetUncompFormatsSupported(p,a,b,c) (p)->GetUncompFormatsSupported(p, a, b, c)
#else
#define IVideoAcceleratorContainer_QueryInterface(p, a, b)            (p)->QueryInterface(a, b)
#define IVideoAcceleratorContainer_AddRef(p)                          (p)->AddRef()
#define IVideoAcceleratorContainer_Release(p)                         (p)->Release()
#define IVideoAcceleratorContainer_CreateVideoAccelerator(p, a, b, c,d,e,f) (p)->CreateVideoAccelerator(a, b, c, d, e, f)
#define IVideoAcceleratorContainer_GetCompBufferInfo(p, a, b, c, d)   (p)->lpVtbl->GetCompBufferInfo(a, b, c, d)
#define IVideoAcceleratorContainer_GetInternalMemInfo(p, a, b, c)     (p)->lpVtbl->GetInternalMemInfo(a, b, c)
#define IVideoAcceleratorContainer_GetVideoAcceleratorGUIDs(p, a, b)        (p)->GetVideoAcceleratorGUIDs(a, b)
#define IVideoAcceleratorContainer_GetUncompFormatsSupported(p,a,b,c) (p)->GetUncompFormatsSupported(a, b, c)
#endif

#endif


/*
 * IDirectDrawVideoAccelerator
 */
#if defined( _WIN32 ) && !defined( _NO_COM )
#undef INTERFACE
#define INTERFACE IDirectDrawVideoAccelerator
DECLARE_INTERFACE_( IDirectDrawVideoAccelerator, IUnknown )
{
    /*** IUnknown methods ***/
    STDMETHOD(QueryInterface) (THIS_ REFIID riid, LPVOID FAR * ppvObj) PURE;
    STDMETHOD_(ULONG,AddRef) (THIS)  PURE;
    STDMETHOD_(ULONG,Release) (THIS) PURE;
    /*** IDirecytDrawVideoAccelerator methods ***/
    STDMETHOD(BeginFrame)(THIS_ LPDDVABeginFrameInfo) PURE;
    STDMETHOD(EndFrame)(THIS_ LPDDVAEndFrameInfo) PURE;
    STDMETHOD(QueryRenderStatus)(THIS_ LPDIRECTDRAWSURFACE7, DWORD)PURE;
    STDMETHOD(Execute)(THIS_
                       DWORD,            // Function
                       LPVOID,           // Input data
                       DWORD,            // Input data length
                       LPVOID,           // Output data
                       DWORD,            // Output data length
                       DWORD,            // Number of buffers
                       LPDDVABUFFERINFO  // Buffer info array
                       ) PURE;
};

//  Flags for QueryRenderStatus
#define DDVA_QUERYRENDERSTATUSF_READ     0x00000001  // Query for read
                                                     // set this bit to 0
                                                     // if query for update

#if !defined(__cplusplus) || defined(CINTERFACE)
#define IVideoAccelerator_QueryInterface(p,a,b)      (p)->lpVtbl->QueryInterface(p,a,b)
#define IVideoAccelerator_AddRef(p)                  (p)->lpVtbl->AddRef(p)
#define IVideoAccelerator_Release(p)                 (p)->lpVtbl->Release(p)
#define IVideoAccelerator_BeginFrame(p,a)            (p)->lpVtbl->BeginFrame(p,a)
#define IVideoAccelerator_EndFrame(p,a)              (p)->lpVtbl->EndFrame(p,a)
#define IVideoAccelerator_QueryRenderStatus(p,a,b)   (p)->lpVtbl->QueryRenderStatus(p,a,b)
#define IVideoAccelerator_RenderMacroBlocks(p,a,b)   (p)->lpVtbl->RenderMacroBlocks(p,a,b)
#else
#define IVideoAccelerator_QueryInterface(p,a,b)      (p)->QueryInterface(a,b)
#define IVideoAccelerator_AddRef(p)                  (p)->AddRef()
#define IVideoAccelerator_Release(p)                 (p)->Release()
#define IVideoAccelerator_BeginFrame(p,a)            (p)->BeginFrame(a)
#define IVideoAccelerator_EndFrame(p,a)              (p)->EndFrame(a)
#define IVideoAccelerator_QueryRenderStatus(p,a,b)   (p)->QueryRenderStatus(a,b)
#define IVideoAccelerator_RenderMacroBlocks(p,a,b)   (p)->RenderMacroBlocks(a,b)
#endif

#endif


#ifdef __cplusplus
};
#endif

#endif
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\multimedia\dshow\filters\image2\inc\cvmrmediasample.h ===
/******************************Module*Header*******************************\
* Module Name: CVMRMediaSample.h
*
*
*
*
* Created: Tue 03/21/2000
* Author:  Stephen Estrop [StEstrop]
*
* Copyright (c) 2000 Microsoft Corporation
\**************************************************************************/

#ifndef CVMRMediaSample_H_INC
#define CVMRMediaSample_H_INC

#include "vmrp.h"

class CVMRMixerQueue;

/* -------------------------------------------------------------------------
** Media sample class
** -------------------------------------------------------------------------
*/
class CVMRMediaSample :
    public CMediaSample,
    public IVMRSurface
{
    friend class CVMRMixerQueue;
    friend class CVMRPinAllocator;

    bool m_bSampleLocked;
    LONG m_lDeltaDecodeSize;
    LPDIRECTDRAWSURFACE7 m_pDDSFB;
    LPDIRECTDRAWSURFACE7 m_pDDS;
    CVMRMediaSample* m_lpMixerQueueNext;
    HANDLE m_hEvent;
    LPBYTE m_lpDeltaDecodeBuffer;
    DWORD m_dwIndex;

    DWORD m_dwNumInSamples;
    DXVA_VideoSample m_DDSrcSamples[MAX_DEINTERLACE_SURFACES];

public:
    CVMRMediaSample(TCHAR *pName, CBaseAllocator *pAllocator, HRESULT *phr,
                    LPBYTE pBuffer = NULL,
                    LONG length = 0,
                    HANDLE hEvent = NULL)
        :   CMediaSample(pName, pAllocator, phr, pBuffer, length),
            m_bSampleLocked(false),
            m_lpDeltaDecodeBuffer(NULL),
            m_lDeltaDecodeSize(0),
            m_pDDS(NULL),
            m_pDDSFB(NULL),
            m_hEvent(hEvent),
            m_lpMixerQueueNext(NULL),
            m_dwNumInSamples(0),
            m_dwIndex(0)
    {
        ZeroMemory(&m_DDSrcSamples, sizeof(m_DDSrcSamples));
    }

    ~CVMRMediaSample() {

        //
        // If we have been given a "Front Buffer" then m_pDDS is an
        // "attached" surface.
        //
        // Release the "attached" surface - this does not make
        // the surface go away because the front buffer still has a
        // reference on the attached surface.  Releasing the front buffer,
        // which is done in the allocator/presenter, releases this for real.
        //

        RELEASE(m_pDDS);
        RELEASE(m_pDDSFB);

        delete m_lpDeltaDecodeBuffer;
    }

    /* Note the media sample does not delegate to its owner */
    STDMETHODIMP QueryInterface(REFIID riid, void **ppv)
    {
        AMTRACE((TEXT("CVMRMediaSample::QueryInterface")));
        if (riid == IID_IVMRSurface) {
            return GetInterface( static_cast<IVMRSurface*>(this), ppv);
        }
        return CMediaSample::QueryInterface(riid, ppv);
    }

    STDMETHODIMP_(ULONG) AddRef()
    {
        AMTRACE((TEXT("CVMRMediaSample::AddRef")));
        return CMediaSample::AddRef();
    }

    STDMETHODIMP_(ULONG) Release()
    {
        AMTRACE((TEXT("CVMRMediaSample::Release")));

        ULONG cRef;

        if (IsDXVASample()) {
            cRef = InterlockedDecrement(&m_cRef);
        }
        else {
            cRef = CMediaSample::Release();
        }

        return cRef;

    }

    void SignalReleaseSurfaceEvent() {
        AMTRACE((TEXT("CVMRMediaSample::SignalReleaseSurfaceEvent")));
        if (m_hEvent != NULL) {
            SetEvent(m_hEvent);
        }
    }

    //
    // Start the delta decode optimization.  If the VGA driver does not
    // support COPY_FOURCC then we should hand out a fake DD surface
    // for the decoder to decode into.  During "Unlock" we lock the real
    // DD surface, copies the fake surface into it and unlock the real
    // surface.  In order to start the process we have to create the
    // fake surface and seed it with the current frame contents.
    //
    HRESULT StartDeltaDecodeState()
    {
        AMTRACE((TEXT("CVMRMediaSample::StartDeltaDecodeState")));
        HRESULT hr = S_OK;

        if (!m_lpDeltaDecodeBuffer) {

            ASSERT(m_lDeltaDecodeSize == 0);
            DDSURFACEDESC2 ddsdS = {sizeof(DDSURFACEDESC2)};

            bool fSrcLocked = false;
            __try {

                CHECK_HR(hr = m_pDDS->Lock(NULL, &ddsdS,
                                           DDLOCK_NOSYSLOCK | DDLOCK_WAIT, NULL));
                fSrcLocked = true;
                LPBYTE pSrc = (LPBYTE)ddsdS.lpSurface;

                switch (ddsdS.ddpfPixelFormat.dwFourCC) {

                // planar 4:2:0 formats - 12 bits per pixel
                case mmioFOURCC('Y','V','1','2'):
                case mmioFOURCC('I','4','2','0'):
                case mmioFOURCC('I','Y','U','V'):
                case mmioFOURCC('N','V','2','1'):
                case mmioFOURCC('N','V','1','2'): {
                        m_lDeltaDecodeSize  = (3 * ddsdS.lPitch * ddsdS.dwHeight) / 2;
                        m_lpDeltaDecodeBuffer = new BYTE[m_lDeltaDecodeSize];
                        if (!m_lpDeltaDecodeBuffer) {
                            hr = E_OUTOFMEMORY;
                            __leave;
                        }
                        CopyMemory(m_lpDeltaDecodeBuffer, pSrc, m_lDeltaDecodeSize);
                    }
                    break;

                // RGB formats - fall thru to packed YUV case
                case 0:
                        ASSERT((ddsdS.dwFlags & DDPF_RGB) == DDPF_RGB);

                // packed 4:2:2 formats
                case mmioFOURCC('Y','U','Y','2'):
                case mmioFOURCC('U','Y','V','Y'): {
                        m_lDeltaDecodeSize = ddsdS.lPitch * ddsdS.dwHeight;
                        m_lpDeltaDecodeBuffer = new BYTE[m_lDeltaDecodeSize];
                        if (!m_lpDeltaDecodeBuffer) {
                            hr = E_OUTOFMEMORY;
                            __leave;
                        }
                        CopyMemory(m_lpDeltaDecodeBuffer, pSrc, m_lDeltaDecodeSize);
                    }
                    break;
                }
            }
            __finally {

                if (fSrcLocked) {
                    m_pDDS->Unlock(NULL);
                }

                if (FAILED(hr)) {
                    delete m_lpDeltaDecodeBuffer;
                    m_lpDeltaDecodeBuffer = NULL;
                    m_lDeltaDecodeSize = 0;
                }
            }
        }

        return hr;
    }

    void SetSurface(LPDIRECTDRAWSURFACE7 pDDS, LPDIRECTDRAWSURFACE7 pDDSFB = NULL)
    {
        AMTRACE((TEXT("CVMRMediaSample::SetSurface")));

        RELEASE(m_pDDS);
        RELEASE(m_pDDSFB);

        m_pDDS = pDDS;
        m_pDDSFB = pDDSFB;

        //
        // if we have been given a pointer to the Front Buffer then
        // we need to AddRef it here.  This is to ensure that our back buffer
        // does not get deleted when the front buffer is released by the VMR.
        //
        if (pDDSFB) {

            pDDSFB->AddRef();
        }

        //
        // if pDDSFB is null then pDDS is a front buffer - in which case
        // we need to add ref pDDS to keep the surface ref counts consistant
        //

        else {

            if (pDDS) {
                pDDS->AddRef();
            }
        }
    }

    STDMETHODIMP GetSurface(LPDIRECTDRAWSURFACE7* pDDS)
    {
        AMTRACE((TEXT("CVMRMediaSample::GetSurface")));
        if (!pDDS) {
            return E_POINTER;
        }

        if (!m_pDDS) {
            return E_FAIL;
        }

        *pDDS = m_pDDS;
        (*pDDS)->AddRef();

        return S_OK;
    }

    STDMETHODIMP LockSurface(LPBYTE* lplpSample)
    {
        AMTRACE((TEXT("CVMRMediaSample::LockSurface")));

        if (!lplpSample) {
            return E_POINTER;
        }

        if (!m_pDDS) {
            return E_FAIL;
        }

        ASSERT(S_FALSE == IsSurfaceLocked());

        if (m_lpDeltaDecodeBuffer) {
            ASSERT(m_lDeltaDecodeSize != 0);
            m_bSampleLocked = true;
            *lplpSample = m_lpDeltaDecodeBuffer;
            return S_OK;
        }

        //
        // lock the surface
        //

        DDSURFACEDESC2 ddSurfaceDesc;
        INITDDSTRUCT(ddSurfaceDesc);

        HRESULT hr = m_pDDS->Lock(NULL, &ddSurfaceDesc,
                                    DDLOCK_NOSYSLOCK | DDLOCK_WAIT,
                                    (HANDLE)NULL);
        if (SUCCEEDED(hr)) {

            m_bSampleLocked = true;
            *lplpSample = (LPBYTE)ddSurfaceDesc.lpSurface;
            DbgLog((LOG_TRACE, 3, TEXT("Locked Surf: %#X"),
                    ddSurfaceDesc.lpSurface));
        }
        else {

            m_bSampleLocked = false;

            DbgLog((LOG_ERROR, 1,
                    TEXT("m_pDDS->Lock() failed, hr = 0x%x"), hr));
        }

        return hr;
    }

    STDMETHODIMP UnlockSurface()
    {
        AMTRACE((TEXT("CVMRMediaSample::UnlockSurface")));

        if (!m_pDDS) {
            return E_FAIL;
        }

        ASSERT(S_OK == IsSurfaceLocked());

        HRESULT hr = S_OK;
        if (m_lpDeltaDecodeBuffer) {

            ASSERT(m_lDeltaDecodeSize != 0);
            bool fSrcLocked = false;
            DDSURFACEDESC2 ddsdS = {sizeof(DDSURFACEDESC2)};

            __try {

                CHECK_HR(hr = m_pDDS->Lock(NULL, &ddsdS,
                                           DDLOCK_NOSYSLOCK | DDLOCK_WAIT, NULL));
                fSrcLocked = true;
                LPBYTE pDst = (LPBYTE)ddsdS.lpSurface;
                CopyMemory(pDst, m_lpDeltaDecodeBuffer, m_lDeltaDecodeSize);
            }
            __finally {
                if (fSrcLocked) {
                    m_pDDS->Unlock(NULL);
                }
            }

            m_bSampleLocked = false;
            return hr;
        }

        hr = m_pDDS->Unlock(NULL);

        //
        // The surface may not actually be locked even though our flag
        // says it is.  This is because surfaces automatically become "un-locked"
        // when they are lost.  The surface can be lost (and resored) at any moment.
        // If the surface is really unlocked our flag must be updated to reflect the
        // true state of the surface.
        //
        if (hr == DDERR_NOTLOCKED) {
            hr = DD_OK;
        }

        if (SUCCEEDED(hr)) {
            m_bSampleLocked = false;
        }
        else {
            DbgLog((LOG_ERROR, 1,
                    TEXT("m_pDDS->Unlock() failed, hr = 0x%x"), hr));
        }
        return hr;
    }

    STDMETHODIMP IsSurfaceLocked()
    {
        AMTRACE((TEXT("CVMRMediaSample::IsSurfaceLocked")));
        ASSERT(m_pDDS);
        return m_bSampleLocked ? S_OK : S_FALSE;
    }

    BOOL IsDXVASample()
    {
        AMTRACE((TEXT("CVMRMediaSample::IsSurfaceLocked")));
        return  (m_pAllocator == (CBaseAllocator *)-1);
    }

    /*  Hack to get at the list */
    CMediaSample* &Next() { return m_pNext; }

    BOOL HasTypeChanged()
    {
        if (m_dwFlags & 0x80000000) {
            return FALSE;
        }

        if (m_dwFlags & AM_SAMPLE_TYPECHANGED) {
            m_dwFlags |= 0x80000000;
            return TRUE;
        }

        return FALSE;
    }

    HRESULT SetProps(
        const AM_SAMPLE2_PROPERTIES& Props,
        LPDIRECTDRAWSURFACE7 pDDS
        )
    {
        SetSurface(pDDS);

        m_dwStreamId = Props.dwStreamId;
        m_dwFlags = Props.dwSampleFlags;
        m_dwTypeSpecificFlags = Props.dwTypeSpecificFlags;
        m_lActual = Props.lActual;
        m_End   = Props.tStop;
        m_Start = Props.tStart;

        if (m_dwFlags & AM_SAMPLE_TYPECHANGED) {

            m_pMediaType = CreateMediaType(Props.pMediaType);
            if (m_pMediaType == NULL) {
                return E_OUTOFMEMORY;
            }
        }
        else {
            m_pMediaType =  NULL;
        }

        return S_OK;
    }

    void SetIndex(DWORD dwIndx)
    {
        m_dwIndex = dwIndx;
    }

    DWORD GetIndex()
    {
        return m_dwIndex;
    }


    DWORD GetTypeSpecificFlags()
    {
        return m_dwTypeSpecificFlags;
    }

    DWORD GetNumInputSamples()
    {
        return m_dwNumInSamples;
    }

    void SetNumInputSamples(DWORD dwNumInSamples)
    {
        m_dwNumInSamples = dwNumInSamples;
    }

    DXVA_VideoSample* GetInputSamples()
    {
        return &m_DDSrcSamples[0];
    }
};

#endif
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\multimedia\dshow\filters\image2\inc\ifleak.h ===
/******************************Module*Header*******************************\
* Module Name: ifleak.h
*
* Interface leak tracking thunks - borrowed from ATL.  Modified so that we
* keep a few bytes of the stack at the time the thunk was created, this
* allows us to do a !sas on the saved stack and determine who created the leaked
* interface.
*
* Also, allows us to determine who is using an interface AFTER it has been
* released.
*
* Created: Tue 08/31/1999
* Author:  Stephen Estrop [StEstrop]
*
* Copyright (c) 1999 Microsoft Corporation
\**************************************************************************/

//#define AM_INTERFACE_LEAK_CHECKING

#if defined(DEBUG) && !defined(_WIN64) && defined(_X86_) && defined(AM_INTERFACE_LEAK_CHECKING)
class CInterfaceLeak;
__declspec(selectany) CInterfaceLeak* _pIFLeak = NULL;
extern CInterfaceLeak g_IFLeak;

template <class T>
class CIFLeakSimpleArray
{
public:
    T* m_aT;
    int m_nSize;
    int m_nAllocSize;

// Construction/destruction
    CIFLeakSimpleArray() : m_aT(NULL), m_nSize(0), m_nAllocSize(0)
    { }

    ~CIFLeakSimpleArray()
    {
        RemoveAll();
    }

// Operations
    int GetSize() const
    {
        return m_nSize;
    }
    BOOL Add(T& t)
    {
        if(m_nSize == m_nAllocSize)
        {
            T* aT;
            int nNewAllocSize = (m_nAllocSize == 0) ? 1 : (m_nSize * 2);
            aT = (T*)realloc(m_aT, nNewAllocSize * sizeof(T));
            if(aT == NULL)
                return FALSE;
            m_nAllocSize = nNewAllocSize;
            m_aT = aT;
        }
        m_nSize++;
        SetAtIndex(m_nSize - 1, t);
        return TRUE;
    }
    BOOL Remove(T& t)
    {
        int nIndex = Find(t);
        if(nIndex == -1)
            return FALSE;
        return RemoveAt(nIndex);
    }
    BOOL RemoveAt(int nIndex)
    {
        if(nIndex != (m_nSize - 1))
        {
#if _MSC_VER >= 1200
            m_aT[nIndex].~T();
#else
            T* MyT;
            MyT = &m_aT[nIndex];
            MyT->~T();
#endif
            memmove((void*)&m_aT[nIndex], (void*)&m_aT[nIndex + 1],
                    (m_nSize - (nIndex + 1)) * sizeof(T));
        }
        m_nSize--;
        return TRUE;
    }
    void RemoveAll()
    {
        if(m_aT != NULL)
        {
            for(int i = 0; i < m_nSize; i++) {
#if _MSC_VER >= 1200
                m_aT[i].~T();
#else
                T* MyT;
                MyT = &m_aT[i];
                MyT->~T();
#endif
            }
            free(m_aT);
            m_aT = NULL;
        }
        m_nSize = 0;
        m_nAllocSize = 0;
    }
    T& operator[] (int nIndex) const
    {
        //ATLASSERT(nIndex >= 0 && nIndex < m_nSize);
        return m_aT[nIndex];
    }
    T* GetData() const
    {
        return m_aT;
    }

// Implementation
    class Wrapper
    {
    public:
        Wrapper(T& _t) : t(_t)
        {
        }
        template <class _Ty>
        void *operator new(size_t, _Ty* p)
        {
            return p;
        }
        T t;
    };
    void SetAtIndex(int nIndex, T& t)
    {
        //ATLASSERT(nIndex >= 0 && nIndex < m_nSize);
        new(&m_aT[nIndex]) Wrapper(t);
    }
    int Find(T& t) const
    {
        for(int i = 0; i < m_nSize; i++)
        {
            if(m_aT[i] == t)
                return i;
        }
        return -1;  // not found
    }
};


inline void WINAPI
DumpIID(
    REFIID iid,
    LPCSTR pszClassName
    )
{
    char szName[100];
    LPOLESTR pszGUID = NULL;

    StringFromCLSID(iid, &pszGUID);
    OutputDebugStringA(pszClassName);
    OutputDebugStringA(" - ");
    wsprintfA(szName, "%ls", pszGUID);
    OutputDebugStringA(szName);
    OutputDebugStringA("\n");

    CoTaskMemFree(pszGUID);
}

struct _QIThunk
{
    STDMETHOD(QueryInterface)(REFIID iid, void** pp)
    {
        return pUnk->QueryInterface(iid, pp);
    }

    STDMETHOD_(ULONG, AddRef)()
    {
        if (bBreak)
            DebugBreak();
        pUnk->AddRef();
        return InternalAddRef();
    }

    ULONG InternalAddRef()
    {
        if (bBreak)
            DebugBreak();
        long l = InterlockedIncrement(&m_dwRef);
        if (l > m_dwMaxRef)
            m_dwMaxRef = l;
        return l;
    }

    STDMETHOD_(ULONG, Release)();
    STDMETHOD(f3)();
    STDMETHOD(f4)();
    STDMETHOD(f5)();
    STDMETHOD(f6)();
    STDMETHOD(f7)();
    STDMETHOD(f8)();
    STDMETHOD(f9)();
    STDMETHOD(f10)();
    STDMETHOD(f11)();
    STDMETHOD(f12)();
    STDMETHOD(f13)();
    STDMETHOD(f14)();
    STDMETHOD(f15)();
    STDMETHOD(f16)();
    STDMETHOD(f17)();
    STDMETHOD(f18)();
    STDMETHOD(f19)();
    STDMETHOD(f20)();
    STDMETHOD(f21)();
    STDMETHOD(f22)();
    STDMETHOD(f23)();
    STDMETHOD(f24)();
    STDMETHOD(f25)();
    STDMETHOD(f26)();
    STDMETHOD(f27)();
    STDMETHOD(f28)();
    STDMETHOD(f29)();
    STDMETHOD(f30)();
    STDMETHOD(f31)();
    STDMETHOD(f32)();
    STDMETHOD(f33)();
    STDMETHOD(f34)();
    STDMETHOD(f35)();
    STDMETHOD(f36)();
    STDMETHOD(f37)();
    STDMETHOD(f38)();
    STDMETHOD(f39)();
    STDMETHOD(f40)();
    STDMETHOD(f41)();
    STDMETHOD(f42)();
    STDMETHOD(f43)();
    STDMETHOD(f44)();
    STDMETHOD(f45)();
    STDMETHOD(f46)();
    STDMETHOD(f47)();
    STDMETHOD(f48)();
    STDMETHOD(f49)();
    STDMETHOD(f50)();
    STDMETHOD(f51)();
    STDMETHOD(f52)();
    STDMETHOD(f53)();
    STDMETHOD(f54)();
    STDMETHOD(f55)();
    STDMETHOD(f56)();
    STDMETHOD(f57)();
    STDMETHOD(f58)();
    STDMETHOD(f59)();
    STDMETHOD(f60)();
    STDMETHOD(f61)();
    STDMETHOD(f62)();
    STDMETHOD(f63)();
    STDMETHOD(f64)();

    _QIThunk(IUnknown* pOrig, LPCSTR p, const IID& i, UINT n, bool b)
    {
        lpszClassName = p;
        iid = i;
        nIndex = n;
        m_dwRef = 0;
        m_dwMaxRef = 0;
        pUnk = pOrig;
        bBreak = b;

        //
        // remember some bytes from the current stack at this allocation,
        // this will provide a back trace that we can use in the debugger.
        //
        __try {
            LPVOID lp;
            __asm mov dword ptr [lp], esp
            CopyMemory(bStack, lp, sizeof(bStack));
        }
        __except(1) {
            ;
        }
    }

    /* do not add and member variables here */
    IUnknown* pUnk;
    long m_dwRef;
    /* end: do not add and member variables here */

    long m_dwMaxRef;
    LPCSTR lpszClassName;
    IID iid;
    UINT nIndex;
    bool bBreak;
    BYTE bStack[512];

    void Dump()
    {
        char buf[256];
        if (m_dwRef > 0)
        {
            wsprintfA(buf,
                      "INTERFACE LEAK: RefCount = %d, MaxRefCount = %d,\n"
                      "{Allocation = %d} {Stack at %#X}\n",
                      m_dwRef, m_dwMaxRef, nIndex, &bStack);
            OutputDebugStringA(buf);
            DumpIID(iid, lpszClassName);
        }
        else
        {
            wsprintfA(buf, "NonAddRef Thunk LEAK: {Allocation = %d}\n", nIndex);
            OutputDebugStringA(buf);
        }
    }
};


class CInterfaceLeak
{
public:
    UINT m_nIndexQI;
    UINT m_nIndexBreakAt;
    CRITICAL_SECTION m_csObjMap;
    CIFLeakSimpleArray<_QIThunk*>* m_paThunks;


    HRESULT
    Init()
    {
        m_nIndexQI = 0;
        m_nIndexBreakAt = 0;
        m_paThunks = NULL;
        _pIFLeak = this;

        InitializeCriticalSection(&m_csObjMap);

        m_paThunks = new CIFLeakSimpleArray<_QIThunk*>;

        if (m_paThunks == NULL)
            return E_OUTOFMEMORY;

        return S_OK;
    }

    HRESULT
    AddThunk(
        IUnknown** pp,
        LPCSTR lpsz,
        REFIID iid
        )
    {
        if ((pp == NULL) || (*pp == NULL))
            return E_POINTER;

        IUnknown* p = *pp;
        _QIThunk* pThunk = NULL;

        EnterCriticalSection(&m_csObjMap);

        // Check if exists already for identity
        if (IsEqualIID(IID_IUnknown, iid))
        {
            for (int i = 0; i < m_paThunks->GetSize(); i++)
            {
                if (m_paThunks->operator[](i)->pUnk == p)
                {
                    m_paThunks->operator[](i)->InternalAddRef();
                    pThunk = m_paThunks->operator[](i);
                    break;
                }
            }
        }

        if (pThunk == NULL)
        {
            ++m_nIndexQI;
            if (m_nIndexBreakAt == m_nIndexQI)
                DebugBreak();

            pThunk = new _QIThunk(p, lpsz, iid, m_nIndexQI,
                                  (m_nIndexBreakAt == m_nIndexQI));
            if (pThunk == NULL)
                return E_OUTOFMEMORY;

            pThunk->InternalAddRef();
            m_paThunks->Add(pThunk);
        }

        LeaveCriticalSection(&m_csObjMap);
        *pp = (IUnknown*)pThunk;
        return S_OK;
    }

    void
    DeleteThunk(
        _QIThunk* p
        )
    {
        EnterCriticalSection(&m_csObjMap);
        int nIndex = m_paThunks->Find(p);
        if (nIndex != -1)
        {
            delete m_paThunks->operator[](nIndex);
            m_paThunks->RemoveAt(nIndex);
        }
        LeaveCriticalSection(&m_csObjMap);
    }

    bool
    DumpLeakedThunks()
    {
        bool b = false;
        for (int i = 0; i < m_paThunks->GetSize(); i++)
        {
            b = true;
            m_paThunks->operator[](i)->Dump();
            //delete m_paThunks->operator[](i);
        }
        // m_paThunks->RemoveAll();
        return b;
    }

    void Term()
    {
        if (DumpLeakedThunks()) {

            DebugBreak();

            for (int i = 0; i < m_paThunks->GetSize(); i++)
            {
                delete m_paThunks->operator[](i);
            }
            m_paThunks->RemoveAll();
        }

        delete m_paThunks;
        DeleteCriticalSection(&m_csObjMap);
    }
};


inline ULONG _QIThunk::Release()
{
    if (bBreak)
        DebugBreak();

    ULONG l = InterlockedDecrement(&m_dwRef);
    if (m_dwRef == 0) {
//      OutputDebugStringA(lpszClassName);
//      OutputDebugStringA("\n");
//      __asm int 3
    }
    pUnk->Release();

//
//  if we free up the thunk we miss all the calls thru a released interface
//

   if (l == 0)
        _pIFLeak->DeleteThunk(this);

    return l;
}

//
// When we enter this function, eax contains the address of the thunk
// object
//
inline static void atlBadThunkCall()
{
    static DWORD dwEAX;
    __asm mov dword ptr [dwEAX], eax
    ASSERT(FALSE && "Call through deleted thunk - ptr in dwEAX");
}

#ifdef _M_IX86
#define IMPL_THUNK(n)\
__declspec(naked) inline HRESULT _QIThunk::f##n()\
{\
    __asm mov eax, [esp+4]\
    __asm cmp dword ptr [eax+8], 0\
    __asm jg goodref\
    __asm call atlBadThunkCall\
    __asm goodref:\
    __asm mov eax, [esp+4]\
    __asm mov eax, dword ptr [eax+4]\
    __asm mov [esp+4], eax\
    __asm mov eax, dword ptr [eax]\
    __asm mov eax, dword ptr [eax+4*n]\
    __asm jmp eax\
}

#else
#define IMPL_THUNK(x)
#endif

IMPL_THUNK(3)
IMPL_THUNK(4)
IMPL_THUNK(5)
IMPL_THUNK(6)
IMPL_THUNK(7)
IMPL_THUNK(8)
IMPL_THUNK(9)
IMPL_THUNK(10)
IMPL_THUNK(11)
IMPL_THUNK(12)
IMPL_THUNK(13)
IMPL_THUNK(14)
IMPL_THUNK(15)
IMPL_THUNK(16)
IMPL_THUNK(17)
IMPL_THUNK(18)
IMPL_THUNK(19)
IMPL_THUNK(20)
IMPL_THUNK(21)
IMPL_THUNK(22)
IMPL_THUNK(23)
IMPL_THUNK(24)
IMPL_THUNK(25)
IMPL_THUNK(26)
IMPL_THUNK(27)
IMPL_THUNK(28)
IMPL_THUNK(29)
IMPL_THUNK(30)
IMPL_THUNK(31)
IMPL_THUNK(32)
IMPL_THUNK(33)
IMPL_THUNK(34)
IMPL_THUNK(35)
IMPL_THUNK(36)
IMPL_THUNK(37)
IMPL_THUNK(38)
IMPL_THUNK(39)
IMPL_THUNK(40)
IMPL_THUNK(41)
IMPL_THUNK(42)
IMPL_THUNK(43)
IMPL_THUNK(44)
IMPL_THUNK(45)
IMPL_THUNK(46)
IMPL_THUNK(47)
IMPL_THUNK(48)
IMPL_THUNK(49)
IMPL_THUNK(50)
IMPL_THUNK(51)
IMPL_THUNK(52)
IMPL_THUNK(53)
IMPL_THUNK(54)
IMPL_THUNK(55)
IMPL_THUNK(56)
IMPL_THUNK(57)
IMPL_THUNK(58)
IMPL_THUNK(59)
IMPL_THUNK(60)
IMPL_THUNK(61)
IMPL_THUNK(62)
IMPL_THUNK(63)
IMPL_THUNK(64)

//
// uuid fix ups.
//
struct __declspec(uuid("1bd0ecb0-f8e2-11ce-aac6-0020af0b99a3")) IQualProp;
struct __declspec(uuid("6C14DB80-A733-11CE-A521-0020AF0BE560")) IDirectDraw;
struct __declspec(uuid("6C14DB81-A733-11CE-A521-0020AF0BE560")) IDirectDrawSurface;
struct __declspec(uuid("69f09720-8ec8-11ce-aab9-0020af0b99a3")) ITestFilterGraph;

//struct __declspec(uuid("")) CEnumCachedFilter

struct __declspec(uuid("8E1C39A1-DE53-11cf-AA63-0080C744528D")) IAMOpenProgress;
struct __declspec(uuid("1B544c22-FD0B-11ce-8C63-00AA0044B520")) IVfwCaptureOptions;
struct __declspec(uuid("666F1EC0-511B-11cf-8A2F-0020AF9CBBA0")) IBlockAllocator;
struct __declspec(uuid("a5ea8d22-253d-11d1-b3f1-00aa003761c5")) ICutList;
struct __declspec(uuid("a5ea8d21-253d-11d1-b3f1-00aa003761c5")) ICutListSourceFilter;
struct __declspec(uuid("FBF2EE40-5360-11cf-A5DC-0020AF053D8F")) ICompoundFileSourceFilter;
struct __declspec(uuid("E26C9EF2-108E-11cf-89ED-0020AF9CBBA0")) IMediaChunk;
struct __declspec(uuid("B8D344E2-78FF-11cf-A609-0020AF053D8F")) IAudioMediaSample;
struct __declspec(uuid("666F1EC0-511B-11cf-8A2F-0020AF9CBBA0")) IBlockAllocator;
struct __declspec(uuid("496E8730-12C7-11cf-89EE-0020AF9CBBA0")) ICache;
struct __declspec(uuid("496E8731-12C7-11cf-89EE-0020AF9CBBA0")) IBlock;
struct __declspec(uuid("9B3DF900-20FB-11cf-89FF-0020AF9CBBA0")) ISourceDescriptor;
struct __declspec(uuid("E26C9EF2-108E-11cf-89ED-0020AF9CBBA0")) IMediaChunk;
struct __declspec(uuid("a5ea8d2c-253d-11d1-b3f1-00aa003761c5")) ICutListGraphBuilder;
struct __declspec(uuid("a5ea8d28-253d-11d1-b3f1-00aa003761c5")) IElementDefinition;
struct __declspec(uuid("a5ea8d2b-253d-11d1-b3f1-00aa003761c5")) IElementInfo;
struct __declspec(uuid("CDE29520-3418-11CF-A5B0-0020AF053D8F")) IAMCutListElement;
struct __declspec(uuid("CDE29522-3418-11CF-A5B0-0020AF053D8F")) IAMVideoCutListElement;
struct __declspec(uuid("CDE29524-3418-11CF-A5B0-0020AF053D8F")) IAMAudioCutListElement;
struct __declspec(uuid("a5ea8d2e-253d-11d1-b3f1-00aa003761c5")) INotifyCallback;
struct __declspec(uuid("F0947070-276C-11d0-8316-0020AF11C010")) IAMFileCutListElement;
struct __declspec(uuid("a5ea8d22-253d-11d1-b3f1-00aa003761c5")) ICctList;
struct __declspec(uuid("a5ea8d29-253d-11d1-b3f1-00aa003761c5")) IStandardCutList;
struct __declspec(uuid("a5ea8d2a-253d-11d1-b3f1-00aa003761c5")) IFileClip;
struct __declspec(uuid("36d39eb0-dd75-11ce-bf0e-00aa0055595a")) IDirectDrawVideo;
struct __declspec(uuid("dd1d7110-7836-11cf-bf47-00aa0055595a")) IFullScreenVideo;
struct __declspec(uuid("53479470-f1dd-11cf-bc42-00aa00ac74f6")) IFullScreenVideoEx;
struct __declspec(uuid("FA2AA8F4-8B62-11D0-A520-000000000000")) IAMMediaContent;
struct __declspec(uuid("b45dd570-3c77-11d1-abe1-00a0c905f375")) IMpegAudioDecoder;
struct __declspec(uuid("EB1BB270-F71F-11CE-8E85-02608C9BABA2")) IMpegVideoDecoder;
struct __declspec(uuid("546F4260-D53E-11cf-B3F0-00AA003761C5")) IAMDirectSound;
struct __declspec(uuid("279AFA84-4981-11CE-A521-0020AF0BE560")) IDirectSound3DListener;
struct __declspec(uuid("279AFA86-4981-11CE-A521-0020AF0BE560")) IDirectSound3DBuffer;
struct __declspec(uuid("C76794A1-D6C5-11d0-9E69-00C04FD7C15B")) IVPNotify;
struct __declspec(uuid("EBF47183-8764-11d1-9E69-00C04FD7C15B")) IVPNotify2;
struct __declspec(uuid("CE292862-FC88-11d0-9E69-00C04FD7C15B")) IVPObject;
struct __declspec(uuid("E37786D2-B5B0-11d2-8854-0000F80883E3")) IVPInfo;
struct __declspec(uuid("4EC741E2-BFAE-11d2-8856-0000F80883E3")) IAMOverlayMixerPosition2;
struct __declspec(uuid("ED7DA472-C083-11d2-8856-0000F80883E3")) IEnumPinConfig;
struct __declspec(uuid("c5265dba-3de3-4919-940b-5ac661c82ef4")) IAMSpecifyDDrawConnectionDevice;
struct __declspec(uuid("25DF12C1-3DE0-11d1-9E69-00C04FD7C15B")) IVPControl;
struct __declspec(uuid("b61178d1-a2d9-11cf-9e53-00aa00a216a1")) IKsPin;
struct __declspec(uuid("593CDDE1-0759-11d1-9E69-00C04FD7C15B")) IMixerPinConfig;
struct __declspec(uuid("EBF47182-8764-11d1-9E69-00C04FD7C15B")) IMixerPinConfig2;
struct __declspec(uuid("CC2E5332-CCF8-11d2-8853-0000F80883E3")) IMixerPinConfig3;
struct __declspec(uuid("6E8D4A21-310C-11d0-B79A-00AA003767A7")) IAMLine21Decoder;
struct __declspec(uuid("c47a3420-005c-11d2-9038-00a0c9697298")) IAMParse;
struct __declspec(uuid("1BB05960-5FBF-11d2-A521-44DF07C10000")) IXMLGraphBuilder;
struct __declspec(uuid("FA2AA8F4-8B62-11D0-A520-000000000000")) IAMMediaContent;
struct __declspec(uuid("48025244-2d39-11ce-875d-00608cb78066")) ITextThing;
struct __declspec(uuid("56A868BE-0AD4-11CE-B03A-0020AF0BA770")) IMediaContent;
struct __declspec(uuid("56A868BE-0AD4-11CE-B03A-0020AF0BA770")) IMediaPositionBengalHack;
struct __declspec(uuid("FA2AA8F9-8B62-11D0-A520-000000000000")) IAMExtendedSeeking;
#endif
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\multimedia\dshow\filters\image2\inc\alloclib.h ===
/******************************Module*Header*******************************\
* Module Name: AllocLib.h
*
*
*
*
* Created: Fri 03/10/2000
* Author:  Stephen Estrop [StEstrop]
*
* Copyright (c) 2000 Microsoft Corporation
\**************************************************************************/


#ifndef __INC_ALLOCLIB_H__
#define __INC_ALLOCLIB_H__

#include "dxva.h"

#ifndef __ZEROSTRUCT_DEFINED
#define __ZEROSTRUCT_DEFINED
template <typename T>
__inline void ZeroStruct(T& t)
{
    ZeroMemory(&t, sizeof(t));
}
#endif

#ifndef __INITDDSTRUCT_DEFINED
#define __INITDDSTRUCT_DEFINED
template <typename T>
__inline void INITDDSTRUCT(T& dd)
{
    ZeroStruct(dd);
    dd.dwSize = sizeof(dd);
}
#endif

#if 0
template< typename T >
__inline CopyStruct(T& pDest, const T& pSrc)
{
    CopyMemory( &pDest, &pSrc, sizeof(pSrc));
}
#endif

const DWORD*
GetBitMasks(
    const BITMAPINFOHEADER *pHeader
    );

LPBITMAPINFOHEADER
GetbmiHeader(
    const AM_MEDIA_TYPE *pMediaType
    );

void
FixupMediaType(
    AM_MEDIA_TYPE* pmt
    );

LPRECT
GetTargetRectFromMediaType(
    const AM_MEDIA_TYPE *pMediaType
    );

struct TargetScale
{
    float fX;
    float fY;
};

void
GetTargetScaleFromMediaType(
    const AM_MEDIA_TYPE *pMediaType,
    TargetScale* pScale
    );

LPRECT
GetSourceRectFromMediaType(
    const AM_MEDIA_TYPE *pMediaType
    );

HRESULT
ConvertSurfaceDescToMediaType(
    const LPDDSURFACEDESC2 pSurfaceDesc,
    const AM_MEDIA_TYPE* pTemplateMediaType,
    AM_MEDIA_TYPE** ppMediaType
    );


HRESULT
PaintDDrawSurfaceBlack(
    LPDIRECTDRAWSURFACE7 pDDrawSurface
    );

HRESULT
GetImageAspectRatio(
    const AM_MEDIA_TYPE* pMediaType,
    long* lpARWidth,
    long* lpARHeight
    );


bool
EqualSizeRect(
    const RECT* lpRc1,
    const RECT* lpRc2
    );


bool
ContainedRect(
    const RECT* lpRc1,
    const RECT* lpRc2
    );

void
LetterBoxDstRect(
    LPRECT lprcLBDst,
    const RECT& rcSrc,
    const RECT& rcDst,
    LPRECT lprcBdrTL,
    LPRECT lprcBdrBR
    );


void
AspectRatioCorrectSize(
    LPSIZE lpSizeImage,
    const SIZE& sizeAr
    );

enum {
    TXTR_POWER2     = 0x01,
    TXTR_AGPYUVMEM  = 0x02,
    TXTR_AGPRGBMEM  = 0x04,
    TXTR_SRCKEY     = 0x08
};

HRESULT
GetTextureCaps(
    LPDIRECTDRAW7 pDD,
    DWORD* ptc
    );

DWORD
DDColorMatch(
    IDirectDrawSurface7 *pdds,
    COLORREF rgb,
    HRESULT& hr
    );

HRESULT
VMRCopyFourCC(
    LPDIRECTDRAWSURFACE7 lpDst,
    LPDIRECTDRAWSURFACE7 lpSrc
    );


HRESULT
GetInterlaceFlagsFromMediaType(
    const AM_MEDIA_TYPE *pMediaType,
    DWORD *pdwInterlaceFlags
    );

BOOL
NeedToFlipOddEven(
    DWORD dwInterlaceFlags,
    DWORD dwTypeSpecificFlags,
    DWORD *pdwFlipFlag,
    BOOL bUsingOverlays
    );

HRESULT
GetVideoDescFromMT(
    LPDXVA_VideoDesc lpVideoDesc,
    const AM_MEDIA_TYPE *pMT
    );

BOOL
IsSingleFieldPerSample(
    DWORD dwFlags
    );

REFERENCE_TIME
GetAvgTimePerFrame(
    const AM_MEDIA_TYPE *pMT
    );

DWORD
MapPool(
    DWORD Pool
    );

DXVA_SampleFormat
MapInterlaceFlags(
    DWORD dwInterlaceFlags,
    DWORD dwTypeSpecificFlags
    );

#ifdef DEBUG
void __inline DumpDDSAddress(const TCHAR *szText, LPDIRECTDRAWSURFACE7 lpDDS)
{
    DDSURFACEDESC2 ddSurfaceDesc;
    INITDDSTRUCT(ddSurfaceDesc);

    HRESULT hr;

    hr = lpDDS->Lock(NULL, &ddSurfaceDesc, DDLOCK_NOSYSLOCK | DDLOCK_WAIT, (HANDLE)NULL);
    if (hr != DD_OK) {
        DbgLog((LOG_TRACE, 0, TEXT("Lock failed hr = %#X"), hr));
    }

    hr = lpDDS->Unlock(NULL);
    if (hr != DD_OK) {
        DbgLog((LOG_TRACE, 0, TEXT("Unlock failed hr = %#X"), hr));
    }

    DbgLog((LOG_TRACE, 0, TEXT("%s%p"), szText, ddSurfaceDesc.lpSurface));
}
#else
#define DumpDDSAddress( _x_, _y_ )
#endif


#endif
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\multimedia\dshow\filters\image2\inc\vmrp.h ===
//=====================================================================
//
// vmrp.h
//
// Private header for Video Mixing Renderer
//
// Copyright (C) 2000 by Microsoft Corporation.  All rights reserved.
//
//=====================================================================

#ifndef __INC_VMRP__
#define __INC_VMRP__

#include "dxva.h"

#define MAX_MIXER_PINS              16
#define MAX_MIXER_STREAMS           (MAX_MIXER_PINS)
#define MIN_BUFFERS_TO_ALLOCATE     1

#define MAX_ALLOWED_BUFFER          64
#define EXTRA_OVERLAY_BUFFERS       2
#define EXTRA_OFFSCREEN_BUFFERS     1 // should really be 1 but as yet
                                      // most graphics drivers don't like
                                      // back buffers when the overlay is
                                      // not being requested too.


//
// Private intel mixer render target, IMC3
//
#define MixerPref_RenderTargetIntelIMC3 0x00008100

#ifndef __RELEASE_DEFINED
#define __RELEASE_DEFINED
template<typename T>
__inline void RELEASE( T* &p )
{
    if( p ) {
        p->Release();
        p = NULL;
    }
}
#endif

#ifndef CHECK_HR
    #define CHECK_HR(expr) do { if (FAILED(expr)) __leave; } while(0);
#endif

#if defined(DEBUG)
#define ISBADREADPTR(p) (IsBadReadPtr( (p), (sizeof(*p))))
#define ISBADWRITEPTR(p) (IsBadWritePtr( (p), (sizeof(*p))))
#define ISBADREADARRAY(p,c) (IsBadReadPtr( (p), (c)*(sizeof(*p))))
#define ISBADWRITEARRAY(p,c) (IsBadWritePtr( (p), (c)*(sizeof(*p))))
#else
#define ISBADREADPTR(p) (NULL==(p))
#define ISBADWRITEPTR(p) (NULL==(p))
#define ISBADREADARRAY(p,c) (NULL==(p))
#define ISBADWRITEARRAY(p,c) (NULL==(p))
#endif

#define ISWINDOW(hwnd) (IsWindow(hwnd))
#define ISBADREADWRITEPTR(p) (ISBADREADPTR(p)||ISBADWRITEPTR(p))
#define ISBADREADWRITEARRAY(p,c) (ISBADREADARRAY(p,c)||ISBADWRITEARRAY(p,c))

//  Debug helper
#ifdef DEBUG
class CDispPixelFormat : public CDispBasic
{
public:
    CDispPixelFormat(const DDPIXELFORMAT *pFormat)
    {
        wsprintf(m_String, TEXT("  Flags(0x%8.8X) bpp(%d) 4CC(%4.4hs)"),
                 pFormat->dwFlags,
                 pFormat->dwRGBBitCount,
                 pFormat->dwFlags & DDPF_FOURCC ?
                     (CHAR *)&pFormat->dwFourCC : "None");
    }
    //  Implement cast to (LPCTSTR) as parameter to logger
    operator LPCTSTR()
    {
        return (LPCTSTR)m_pString;
    };
};
#endif // DEBUG


/* -------------------------------------------------------------------------
** VMR file persist helpers
** -------------------------------------------------------------------------
*/
struct VMRStreamInfo {
    float           alpha;
    DWORD           zOrder;
    NORMALIZEDRECT  rect;
};

struct VMRFilterInfo {
    DWORD           dwSize;
    DWORD           dwNumPins;
    VMRStreamInfo   StreamInfo[MAX_MIXER_STREAMS];
};


// internal interfaces used by the VMR
// interface IImageSyncNotifyEvent;
// interface IImageSyncControl;
// interface IImageSync;
// interface IVMRMixerControl;
// interface IVMRMixerStream;


//
// 1DBCA562-5C92-474a-A276-382079164970),
//
DEFINE_GUID(IID_IImageSyncNotifyEvent,
0x1DBCA562, 0x5C92, 0x474a, 0xA2, 0x76, 0x38, 0x20, 0x79, 0x16, 0x49, 0x70);

DECLARE_INTERFACE_(IImageSyncNotifyEvent, IUnknown)
{
    STDMETHOD (NotifyEvent)(THIS_
                            long EventCode,
                            LONG_PTR EventParam1,
                            LONG_PTR EventParam2
                            ) PURE;
};


typedef enum {
        ImageSync_State_Stopped,
        ImageSync_State_Cued,
        ImageSync_State_Playing
} ImageSequenceState;


//
// A67F6A0D-883B-44ce-AA93-87BA3017E19C
//
DEFINE_GUID(IID_IImageSyncControl,
0xA67F6A0D, 0x883B, 0x44ce, 0xAA, 0x93, 0x87, 0xBA, 0x30, 0x17, 0xE1, 0x9C);

DECLARE_INTERFACE_(IImageSyncControl, IUnknown)
{
    // ============================================================
    // Synchronisation control
    // ============================================================

    STDMETHOD (SetImagePresenter)(THIS_
        IVMRImagePresenter* lpImagePresenter,
        DWORD_PTR dwUserID
        ) PURE;

    STDMETHOD (SetReferenceClock)(THIS_
        IReferenceClock* lpRefClock
        ) PURE;

    STDMETHOD (SetEventNotify)(THIS_
        IImageSyncNotifyEvent* lpEventNotify
        ) PURE;


    // ============================================================
    // Image sequence control
    // ============================================================

    STDMETHOD (CueImageSequence)(THIS_
        ) PURE;

    STDMETHOD (BeginImageSequence)(THIS_
        REFERENCE_TIME* baseTime
        ) PURE;

    STDMETHOD (EndImageSequence)(THIS_
        ) PURE;

    STDMETHOD (GetImageSequenceState)(THIS_
        DWORD dwMSecsTimeOut,
        DWORD* lpdwState
        ) PURE;

    STDMETHOD (BeginFlush)(THIS_
        ) PURE;

    STDMETHOD (EndFlush)(THIS_
        ) PURE;

    STDMETHOD (EndOfStream)(THIS_
        ) PURE;

    STDMETHOD (ResetEndOfStream)(THIS_
        ) PURE;

    STDMETHOD (SetAbortSignal)(THIS_
        BOOL bAbort
        ) PURE;

    STDMETHOD (GetAbortSignal)(THIS_
        BOOL* lpbAbort
        ) PURE;

    STDMETHOD (RuntimeAbortPlayback)(THIS_
        ) PURE;

    // ============================================================
    // Frame stepping
    // ============================================================

    STDMETHOD (FrameStep)(THIS_
        DWORD nFramesToStep,
        DWORD dwStepFlags
        ) PURE;

    STDMETHOD (CancelFrameStep)(THIS_
        ) PURE;
};

//
// a38cc06e-5926-48df-9926-571458145e80
//
DEFINE_GUID(IID_IImageSync,
0xa38cc06e, 0x5926, 0x48df, 0x99, 0x26, 0x57, 0x14, 0x58, 0x14, 0x5e, 0x80);

DECLARE_INTERFACE_(IImageSync, IUnknown)
{
    STDMETHOD (Receive)(THIS_
        VMRPRESENTATIONINFO* lpPresInfo
        ) PURE;

    STDMETHOD (GetQualityControlMessage)(THIS_
         Quality* pQualityMsg
        ) PURE;
};


///////////////////////////////////////////////////////////////////////////////
//
// Mixer interfaces
//
///////////////////////////////////////////////////////////////////////////////

//
// 56949f22-aa07-4061-bb8c-10159d8f92e5
//
DEFINE_GUID(IID_IVMRMixerControlInternal,
0x56949f22, 0xaa07, 0x4061, 0xbb, 0x8c, 0x10, 0x15, 0x9d, 0x8f, 0x92, 0xe5);

DECLARE_INTERFACE_(IVMRMixerControlInternal, IUnknown)
{
    STDMETHOD (SetImageCompositor)(THIS_
        IVMRImageCompositor* lpVMRImgCompositor
        ) PURE;

    STDMETHOD (SetBackEndAllocator)(THIS_
        IVMRSurfaceAllocator* lpAllocator,
        DWORD_PTR dwUserID
        ) PURE;

    STDMETHOD (SetBackEndImageSync)(THIS_
        IImageSync* lpImageSync
        ) PURE;
    	
    STDMETHOD (SetNumberOfStreams)(THIS_
        DWORD dwMaxStreams
        ) PURE;

    STDMETHOD (GetNumberOfStreams)(THIS_
        DWORD* pdwMaxStreams
        ) PURE;

    STDMETHOD (DisplayModeChanged)(THIS_) PURE;

    STDMETHOD (WaitForMixerIdle)(THIS_
        DWORD dwTimeOut
        ) PURE;

    STDMETHOD (SetBackgroundColor)(THIS_
        COLORREF clrBorder
        ) PURE;

    STDMETHOD (GetBackgroundColor)(THIS_
        COLORREF* lpClrBorder
        ) PURE;

    STDMETHOD (SetMixingPrefs)(THIS_
        DWORD dwMixerPrefs
        ) PURE;

    STDMETHOD (GetMixingPrefs)(THIS_
        DWORD* pdwMixerPrefs
        ) PURE;

};



typedef enum {
        VMR_SF_NONE                      = 0x00000000,
        VMR_SF_TEXTURE                   = 0x00000001,
} VMR_SF_Flags;

//
// 43062408-3d55-43cc-9415-0daf218db422
//
DEFINE_GUID(IID_IVMRMixerStream,
0x43062408, 0x3d55, 0x43cc, 0x94, 0x15, 0x0d, 0xaf, 0x21, 0x8d, 0xb4, 0x22);

DECLARE_INTERFACE_(IVMRMixerStream, IUnknown)
{
    STDMETHOD (QueueStreamMediaSample)(THIS_
            DWORD dwStreamID,
            IMediaSample* lpSample
            ) PURE;

    STDMETHOD (BeginFlush)(THIS_
            DWORD dwStreamID
            ) PURE;

    STDMETHOD (EndFlush)(THIS_
            DWORD dwStreamID
            ) PURE;

    STDMETHOD (SetStreamMediaType)(THIS_
            DWORD dwStreamID,
            AM_MEDIA_TYPE* pmt,
            DWORD dwSurfFlags,
            LPGUID lpDeinterlaceGUID,
            DXVA_DeinterlaceCaps* lpCaps
            ) PURE;

    STDMETHOD (SetStreamActiveState)(THIS_
            DWORD dwStreamID,
            BOOL fActive
            ) PURE;

    STDMETHOD (GetStreamActiveState)(THIS_
            DWORD dwStreamID,
            BOOL* lpfActive
            ) PURE;

    STDMETHOD (SetStreamColorKey)(THIS_
            DWORD dwStreamID,
            LPDDCOLORKEY lpClrKey
            ) PURE;

    STDMETHOD (GetStreamColorKey)(THIS_
            DWORD dwStreamID,
            LPDDCOLORKEY lpClrKey
            ) PURE;

    STDMETHOD (SetStreamAlpha)(THIS_
            DWORD dwStreamID,
            float Alpha
            ) PURE;

    STDMETHOD (GetStreamAlpha)(THIS_
            DWORD dwStreamID,
            float* pAlpha
            ) PURE;

    STDMETHOD (SetStreamZOrder)(THIS_
            DWORD dwStreamID,
            DWORD dwZ
            ) PURE;

    STDMETHOD (GetStreamZOrder)(THIS_
            DWORD dwStreamID,
            DWORD* pdwZ
            ) PURE;

    STDMETHOD (SetStreamOutputRect)(THIS_
            DWORD dwStreamID,
            const NORMALIZEDRECT *pRect
            ) PURE;

    STDMETHOD (GetStreamOutputRect)(THIS_
            DWORD dwStreamID,
            NORMALIZEDRECT* pRect
            ) PURE;
};


//
// ede80b5c-bad6-4623-b537-65 58 6c 9f 8d fd
//
DEFINE_GUID(IID_IVMRFilterConfigInternal,
0xede80b5c, 0xbad6, 0x4623, 0xb5, 0x37, 0x65, 0x58, 0x6c, 0x9f, 0x8d, 0xfd);

DECLARE_INTERFACE_(IVMRFilterConfigInternal, IUnknown)
{
    STDMETHOD (GetAspectRatioModePrivate)(THIS_
            LPDWORD lpdwARMode
            ) PURE;

    STDMETHOD (SetAspectRatioModePrivate)(THIS_
            DWORD dwARMode
            ) PURE;
};
#endif
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\multimedia\dshow\filters\image2\inc\vmruuids.h ===
#ifndef __VMRuuids_h__
#define __VMRuuids_h__

#ifndef OUR_GUID_ENTRY
    #define OUR_GUID_ENTRY(name, l, w1, w2, b1, b2, b3, b4, b5, b6, b7, b8) \
    DEFINE_GUID(name, l, w1, w2, b1, b2, b3, b4, b5, b6, b7, b8);
#endif


// {99d54f63-1a69-41ae-aa4d-c976eb3f0713}
OUR_GUID_ENTRY(CLSID_AllocPresenter,
0x99d54f63, 0x1a69, 0x41ae, 0xaa, 0x4d, 0xc9, 0x76, 0xeb, 0x3f, 0x07, 0x13)

// {7D8AA343-6E63-4663-BE90-6B80F66540A3}
OUR_GUID_ENTRY(CLSID_ImageSynchronization,
0x7D8AA343, 0x6E63, 0x4663, 0xBE, 0x90, 0x6B, 0x80, 0xF6, 0x65, 0x40, 0xA3)

// {06b32aee-77da-484b-973b-5d64f47201b0}
OUR_GUID_ENTRY(CLSID_VideoMixer,
0x06b32aee, 0x77da, 0x484b, 0x97, 0x3b, 0x5d, 0x64, 0xf4, 0x72, 0x01, 0xb0)

#undef OUR_GUID_ENTRY
#endif
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\multimedia\dshow\filters\image2\inc\mediastype.h ===
/******************************Module*Header*******************************\
* Module Name: MediaSType.h
*
*  Definition of VMR unique media sub-types.
*
*
* Created: Wed 03/08/2000
* Author:  Stephen Estrop [StEstrop]
*
* Copyright (c) 2000 Microsoft Corporation
\**************************************************************************/

// 5860b2bd-619f-4306-a472-9a2f256253b8
DEFINE_GUID(MEDIASUBTYPE_SameAsMonitor,
0x5860b2bd, 0x619f, 0x4306, 0xa4, 0x72, 0x9a, 0x2f, 0x25, 0x62, 0x53, 0xb8);
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\multimedia\dshow\filters\image2\mixer\mixerdeinterlace.h ===
/******************************Module*Header*******************************\
* Module Name: mixerDeinterlace.h
*
*
*
*
* Created: Tue 03/12/2002
* Author:  Stephen Estrop [StEstrop]
*
* Copyright (c) 2002 Microsoft Corporation
\**************************************************************************/

#include "ddva.h"

class CDeinterlaceDevice {

public:

    CDeinterlaceDevice(LPDIRECTDRAW7 pDD,
                       LPGUID pGuid,
                       DXVA_VideoDesc* lpVideoDescription,
                       HRESULT* phr);
    ~CDeinterlaceDevice();

    HRESULT Blt(REFERENCE_TIME rtTargetFrame,
                LPRECT lprcDstRect,
                LPDIRECTDRAWSURFACE7 lpDDSDstSurface,
                LPRECT lprcSrcRect,
                LPDXVA_VideoSample lpDDSrcSurfaces,
                DWORD dwNumSurfaces,
                FLOAT fAlpha);
private:
    IDirectDrawVideoAccelerator*    m_pIDDVideoAccelerator;
    GUID                            m_Guid;
};
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\multimedia\dshow\filters\image2\mixer\mixerdeinterlace.cpp ===
/******************************Module*Header*******************************\
* Module Name: mixerDeinterlace.cpp
*
*
*
*
* Created: Tue 03/12/2002
* Author:  Stephen Estrop [StEstrop]
*
* Copyright (c) 2002 Microsoft Corporation
\**************************************************************************/
#include <streams.h>
#include <windowsx.h>
#include <limits.h>

#include "vmrp.h"
#include "mixerDeinterlace.h"


/******************************Public*Routine******************************\
* CDeinterlaceDevice
*
*
*
* History:
* Thu 02/28/2002 - StEstrop - Created
*
\**************************************************************************/
CDeinterlaceDevice::CDeinterlaceDevice(
    LPDIRECTDRAW7 pDD,
    LPGUID pGuid,
    DXVA_VideoDesc* lpVideoDescription,
    HRESULT* phr
    ) :
    m_pIDDVideoAccelerator(NULL),
    m_Guid(*pGuid)
{
    DDVAUncompDataInfo UncompInfo = {sizeof(DDVAUncompDataInfo), 0, 0, 0};
    IDDVideoAcceleratorContainer* pIDDVAContainer = NULL;

    HRESULT hr = pDD->QueryInterface(IID_IDDVideoAcceleratorContainer,
                                     (void**)&pIDDVAContainer);
    if (hr == DD_OK) {
        hr = pIDDVAContainer->CreateVideoAccelerator(
                                 pGuid, &UncompInfo,
                                 lpVideoDescription,
                                 sizeof(DXVA_VideoDesc),
                                 &m_pIDDVideoAccelerator,
                                 NULL);
        pIDDVAContainer->Release();
    }

    if (hr != DD_OK) {
        *phr = hr;
    }
}



/******************************Public*Routine******************************\
* ~CDeinterlaceDevice
*
*
*
* History:
* Thu 02/28/2002 - StEstrop - Created
*
\**************************************************************************/
CDeinterlaceDevice::~CDeinterlaceDevice()
{
    RELEASE(m_pIDDVideoAccelerator);
}



/******************************Public*Routine******************************\
* Blt
*
*
*
* History:
* Thu 02/28/2002 - StEstrop - Created
*
\**************************************************************************/
HRESULT
CDeinterlaceDevice::Blt(
    REFERENCE_TIME rtTargetFrame,
    LPRECT lprcDstRect,
    LPDIRECTDRAWSURFACE7 lpDDSDstSurface,
    LPRECT lprcSrcRect,
    LPDXVA_VideoSample lpDDSrcSurfaces,
    DWORD NumSourceSurfaces,
    FLOAT Alpha
    )
{
    // lpInput => DXVA_DeinterlaceBlt*
    // lpOuput => NULL /* not currently used */

    DXVA_DeinterlaceBlt blt;
    blt.Size = sizeof(DXVA_DeinterlaceBlt);
    blt.rtTarget = rtTargetFrame;
    blt.DstRect = *lprcDstRect;
    blt.SrcRect = *lprcSrcRect;
    blt.NumSourceSurfaces = NumSourceSurfaces;
    blt.Alpha = Alpha;

    DDVABUFFERINFO* pBuffInfo = new DDVABUFFERINFO[NumSourceSurfaces+1];
    if (pBuffInfo == NULL) {
        return E_OUTOFMEMORY;
    }

    pBuffInfo[0].dwDataOffset   = 0;
    pBuffInfo[0].dwDataSize     = 0;
    pBuffInfo[0].pddCompSurface = lpDDSDstSurface;

    for (DWORD i = 0; i < NumSourceSurfaces; i++) {
        pBuffInfo[i + 1].dwDataOffset   = 0;
        pBuffInfo[i + 1].dwDataSize     = 0;
        pBuffInfo[i + 1].pddCompSurface =
                (LPDIRECTDRAWSURFACE7)lpDDSrcSurfaces[i].lpDDSSrcSurface;
        blt.Source[i] = lpDDSrcSurfaces[i];
    }


    HRESULT hr = m_pIDDVideoAccelerator->Execute(
                    DXVA_DeinterlaceBltFnCode,
                    &blt, sizeof(DXVA_DeinterlaceBlt),
                    NULL, 0,
                    NumSourceSurfaces+1, pBuffInfo);

#ifdef DEBUG
    if (hr != S_OK) {
        DbgLog((LOG_ERROR, 1, TEXT("DeinterlaceBlt failed hr=%#X"), hr));
    }
#endif

    delete [] pBuffInfo;

    return hr;
}
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\multimedia\dshow\filters\image2\mixer\mixer.cpp ===
/******************************Module*Header*******************************\
* Module Name: AP.cpp
*
* The default DShow allocator presenter
*
*
* Created: Wed 02/23/2000
* Author:  Stephen Estrop [StEstrop]
*
* Copyright (c) 2000 Microsoft Corporation
\**************************************************************************/
#include <streams.h>
#include <windowsx.h>
#include <limits.h>

#ifdef FILTER_DLL
#include <initguid.h>
#endif

#include "mixerobj.h"
#if defined(CHECK_FOR_LEAKS)
#include "ifleak.h"
#endif

#ifdef FILTER_DLL
DEFINE_GUID(IID_IDirectDraw7,
            0x15e65ec0,0x3b9c,0x11d2,0xb9,0x2f,0x00,0x60,0x97,0x97,0xea,0x5b);

STDAPI DllRegisterServer()
{
    AMTRACE((TEXT("DllRegisterServer")));
    return AMovieDllRegisterServer2( TRUE );
}

STDAPI DllUnregisterServer()
{
    AMTRACE((TEXT("DllUnregisterServer")));
    return AMovieDllRegisterServer2( FALSE );
}

CFactoryTemplate g_Templates[] = {
    {
        L"",
        &CLSID_VideoMixer,
        CVideoMixer::CreateInstance,
        CVideoMixer::InitClass,
        NULL
    }
};
int g_cTemplates = sizeof(g_Templates) / sizeof(g_Templates[0]);
#endif


/******************************Public*Routine******************************\
* CreateInstance
*
*
*
* History:
* Wed 02/23/2000 - StEstrop - Created
*
\**************************************************************************/
CUnknown* CVideoMixer::CreateInstance(LPUNKNOWN pUnk, HRESULT *phr)
{
    AMTRACE((TEXT("CVMRFilter::CreateInstance")));
    return new CVideoMixer(pUnk, phr);
}


/******************************Public*Routine******************************\
* InitClass
*
*
*
* History:
* Thu 12/14/2000 - StEstrop - Created
*
\**************************************************************************/
#if defined(CHECK_FOR_LEAKS)

// the one and only g_IFLeak object.
CInterfaceLeak  g_IFLeak;

void
CVideoMixer::InitClass(
    BOOL bLoading,
    const CLSID *clsid
    )
{
    if (bLoading) {
        DbgLog((LOG_TRACE, 0, TEXT("Mixer Thunks: Loaded\n") ));
        g_IFLeak.Init();
    }
    else {
        DbgLog((LOG_TRACE, 0, TEXT("Mixer Thunks: Unloaded") ));
        g_IFLeak.Term();
    }
}
#else
void
CVideoMixer::InitClass(
    BOOL bLoading,
    const CLSID *clsid
    )
{
}
#endif


/******************************Public*Routine******************************\
* MixerThreadProc
*
*
*
* History:
* Wed 03/15/2000 - StEstrop - Created
*
\**************************************************************************/
DWORD WINAPI
CVideoMixer::MixerThreadProc(
    LPVOID lpParameter
    )
{
    CVideoMixer* lp = (CVideoMixer*)lpParameter;
    return lp->MixerThread();
}


/******************************Public*Routine******************************\
* CVideoMixer
*
*
*
* History:
* Wed 02/23/2000 - StEstrop - Created
*
\**************************************************************************/
#pragma warning(disable:4355)
CVideoMixer::CVideoMixer(LPUNKNOWN pUnk, HRESULT *phr)
    : CUnknown(NAME("Video Mixer"), pUnk),
    m_pBackEndAllocator(NULL),
    m_pImageSync(NULL),
    m_ImageCompositor(this),
    m_pImageCompositor(NULL),
    m_hThread(NULL),
    m_hMixerIdle(NULL),
    m_dwThreadID(0),
    m_MixingPrefs(MixerPref_NoDecimation |
                  MixerPref_BiLinearFiltering | MixerPref_RenderTargetRGB),
    m_pmt(NULL),
    m_ppMixerStreams(NULL),
    m_dwNumStreams(0),
    m_pDDSAppImage(NULL),
    m_hbmpAppImage(NULL),
    m_dwWidthAppImage(0),
    m_dwHeightAppImage(0),
    m_pDD(NULL),
    m_pD3D(NULL),
    m_pD3DDevice(NULL),
    m_pDDSTextureMirror(NULL),
    m_dwClrBorderMapped(0),
    m_clrBorder(RGB(0,0,0)),
    m_dwAppImageFlags(APPIMG_NOIMAGE)
//  m_fOverlayRT(FALSE),
//  m_dwInterlaceFlags(0),
//  m_dwTypeSpecificFlags(0)
{
    AMTRACE((TEXT("CVideoMixer::CVideoMixer")));
    HRESULT hr = SetImageCompositor(&m_ImageCompositor);
    if (FAILED(hr)) {
        *phr = hr;
    }

    ZeroMemory(&m_rcAppImageSrc, sizeof(m_rcAppImageSrc));

#ifdef DEBUG
    if (GetProfileIntA("VMR", "Decimate", 0)) {
        m_MixingPrefs |= MixerPref_DecimateOutput;
    }

    if (GetProfileIntA("VMR", "PointFiltering", 0)) {
        m_MixingPrefs &= ~MixerPref_FilteringMask;
        m_MixingPrefs |= MixerPref_PointFiltering;
    }

    //
    // BiLinear takes priority over Point Filtering.
    //
    if (GetProfileIntA("VMR", "BiLinearFiltering", 0)) {
        m_MixingPrefs &= ~MixerPref_FilteringMask;
        m_MixingPrefs |= MixerPref_BiLinearFiltering;
    }

    //
    // Sort out the render target.
    //
    if (GetProfileIntA("VMR", "RT_RGB", 0)) {
        m_MixingPrefs &= ~MixerPref_RenderTargetMask;
        m_MixingPrefs |= MixerPref_RenderTargetRGB;
    }
    else if (GetProfileIntA("VMR", "RT_YUV420", 0)) {
        m_MixingPrefs &= ~MixerPref_RenderTargetMask;
        m_MixingPrefs |= MixerPref_RenderTargetYUV420;
    }
    else if (GetProfileIntA("VMR", "RT_YUV422", 0)) {
        m_MixingPrefs &= ~MixerPref_RenderTargetMask;
        m_MixingPrefs |= MixerPref_RenderTargetYUV422;
    }
    else if (GetProfileIntA("VMR", "RT_YUV444", 0)) {
        m_MixingPrefs &= ~MixerPref_RenderTargetMask;
        m_MixingPrefs |= MixerPref_RenderTargetYUV444;
    }
    else if (GetProfileIntA("VMR", "RT_IMC3", 0)) {
        m_MixingPrefs &= ~MixerPref_RenderTargetMask;
        m_MixingPrefs |= MixerPref_RenderTargetIntelIMC3;
    }
#endif

}

/******************************Public*Routine******************************\
* CVideoMixer
*
*
*
* History:
* Wed 02/23/2000 - StEstrop - Created
*
\**************************************************************************/
CVideoMixer::~CVideoMixer()
{
    AMTRACE((TEXT("CVideoMixer::~CVideoMixer")));

    //
    // The mixer object must not be deleted on the mixers own
    // worker thread!
    //
    ASSERT(m_dwThreadID != GetCurrentThreadId());

    if (m_hbmpAppImage) {
        DeleteObject( m_hbmpAppImage );
    }

    RELEASE(m_pDDSTextureMirror);
    RELEASE(m_pDDSAppImage);

    FreeSurface();

    RELEASE(m_pImageCompositor);
    RELEASE(m_pBackEndAllocator);
    RELEASE(m_pImageSync);

    if (m_hThread) {
        for ( int i = 0; i < 100; i++ )
        {
            if ( 0 == PostThreadMessage(m_dwThreadID, WM_USER, 0, 0) )
                Sleep(0);
            else
                break;
        }

        WaitForSingleObject(m_hThread, INFINITE);
        CloseHandle(m_hThread);
    }

    if (m_hMixerIdle) {
        CloseHandle(m_hMixerIdle);
    }

    if (m_ppMixerStreams) {
        for (DWORD i = 0; i < m_dwNumStreams; i++) {
            delete m_ppMixerStreams[i];
        }
    }
    delete[] m_ppMixerStreams;

}


/******************************Public*Routine******************************\
* NonDelegatingQueryInterface
*
*
*
* History:
* Wed 02/23/2000 - StEstrop - Created
*
\**************************************************************************/
STDMETHODIMP
CVideoMixer::NonDelegatingQueryInterface(
    REFIID riid,
    void ** ppv)
{
    AMTRACE((TEXT("CVideoMixer::NonDelegatingQueryInterface")));

    HRESULT hr = E_NOINTERFACE;
    *ppv = NULL;

    if (riid == IID_IVMRMixerControlInternal) {
        hr = GetInterface((IVMRMixerControlInternal *)this, ppv);
    }
    else if (riid == IID_IVMRMixerStream) {
        hr =  GetInterface((IVMRMixerStream *)this, ppv);
    }
    else if (riid == IID_IVMRMixerBitmap) {
        hr = GetInterface((IVMRMixerBitmap *)this, ppv );
    }
    else {
        hr = CUnknown::NonDelegatingQueryInterface(riid,ppv);
    }

#if defined(CHECK_FOR_LEAKS)
    if (hr == S_OK) {
        _pIFLeak->AddThunk((IUnknown **)ppv, "Mixer Object",  riid);
    }
#endif

    return hr;
}
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\multimedia\dshow\filters\image2\mixer\mixercomp.cpp ===
/******************************Module*Header*******************************\
* Module Name: mixerComp.cpp
*
* Mixer compositor functions
*
* Created: Tue 10/03/2000
* Author:  Stephen Estrop [StEstrop]
*
* Copyright (c) 2000 Microsoft Corporation
\**************************************************************************/
#include <streams.h>
#include <dvdmedia.h>
#include <windowsx.h>
#include <limits.h>

#include "vmrp.h"
#include "mixerobj.h"

#if defined( EHOME_WMI_INSTRUMENTATION )
#include "dxmperf.h"
#endif

/*****************************Private*Routine******************************\
* AllocateTextureMirror
*
* Makes sure the video memory texture is big enough to accommodate the
* input surface.  Frees and reallocates it (bumping to next power of 2)
* if it is not.
*
* Allocates the video memory texture mirror for the first time if it has
* not been allocated yet.
*
* This routine should never be called if the hardware supports YUV texturing.
* SetStreamMediaType checks for DDSCAPS_TEXTURE on the decode surface before
* calling this routine.
*
* History:
* Thu 06/29/2000 - nwilt - Created
*
\**************************************************************************/

// global data structures and static helper function for AllocateTextureMirror
const DDPIXELFORMAT g_rgTextMirFormats[] = {
    { sizeof(DDPIXELFORMAT), DDPF_RGB, 0, 24, 0xff0000, 0xff00,  0xff, 0},
    { sizeof(DDPIXELFORMAT), DDPF_RGB, 0, 32, 0xff0000, 0xff00,  0xff, 0},
    { sizeof(DDPIXELFORMAT), DDPF_RGB, 0, 16, 0x1f<<11, 0x3f<<5, 0x1f, 0},
    { sizeof(DDPIXELFORMAT), DDPF_RGB, 0, 16, 0x1f<<10, 0x1f<<5, 0x1f, 0}
};

const UINT g_cTextMirFormats = sizeof(g_rgTextMirFormats)/sizeof(DDPIXELFORMAT);

UINT NextPow2(UINT i)
{
    UINT ret = 1;
    while ( ret < i )
    {
        ret <<= 1;
    }
    return ret;
}

HRESULT
CVideoMixer::AllocateTextureMirror( DWORD dwWidth, DWORD dwHeight )
{
    HRESULT hr;
    DDSURFACEDESC2 ddsd = {sizeof(ddsd)};

    __try
    {
        if (m_pDDSTextureMirror)
        {
            CHECK_HR(hr = m_pDDSTextureMirror->GetSurfaceDesc(&ddsd));

            //
            // early out if mirror already exists and is large enough
            // to accommodate pDDS
            //

            if (ddsd.dwWidth >= dwWidth && ddsd.dwHeight >= dwHeight) {
                hr = S_OK;
                __leave;
            }

            dwWidth = max(ddsd.dwWidth, dwWidth);
            dwHeight = max(ddsd.dwHeight, dwHeight);
        }
        RELEASE(m_pDDSTextureMirror);

        //
        // bump dimensions out to next power of 2 if the 3D hardware needs
        // it that way
        //

        if (m_dwTextureCaps & TXTR_POWER2) {
            dwWidth = NextPow2(dwWidth);
            dwHeight = NextPow2(dwHeight);
        }

        DDSURFACEDESC2 ddsd = {sizeof(ddsd)};
        ddsd.dwFlags = DDSD_WIDTH | DDSD_HEIGHT | DDSD_CAPS | DDSD_PIXELFORMAT;
        ddsd.dwWidth = dwWidth;
        ddsd.dwHeight = dwHeight;
        ddsd.ddsCaps.dwCaps = DDSCAPS_TEXTURE |
                              DDSCAPS_VIDEOMEMORY | DDSCAPS_LOCALVIDMEM;

        //
        // loop over texture formats and return as soon as CreateSurface succeeds
        //

        for (UINT i = 0; i < g_cTextMirFormats; i++ )
        {
            //
            // create texture mirror
            //

            ddsd.ddpfPixelFormat = g_rgTextMirFormats[i];
            hr = m_pDD->CreateSurface(&ddsd, &m_pDDSTextureMirror, NULL);
            if (SUCCEEDED(hr)) {
                break;
            }
        }
    }
    __finally {
    }

    return hr;
}


/*****************************Private*Routine******************************\
* CreateAppImageMirror
*
*
*
* History:
* Tue 10/03/2000 - NWilt - Created
*
\**************************************************************************/
HRESULT
CVideoMixer::CreateAppImageMirror( )
{
    AMTRACE((TEXT("CVideoMixer::CreateAppImageMirror")));
    HRESULT hr;
    LPDIRECTDRAWSURFACE7 pDDS;
    HDC hdcSrc = NULL;
    HDC hdcDest = NULL;
    float fTexWid = 0.0f, fTexHgt = 0.0f;

    __try
    {
        DDSURFACEDESC2 ddsd = {sizeof(ddsd)};

        if (m_dwTextureCaps & TXTR_POWER2) {
            ddsd.dwWidth = NextPow2( m_dwWidthAppImage );
            ddsd.dwHeight = NextPow2( m_dwHeightAppImage );
        }
        else {
            ddsd.dwWidth = m_dwWidthAppImage;
            ddsd.dwHeight = m_dwHeightAppImage;
        }

        // create texture mirror
        ddsd.dwFlags = DDSD_WIDTH | DDSD_HEIGHT | DDSD_CAPS;

        //
        // The following seems to make the NVidia drivers work
        // without making everyone else fail.
        //
        ddsd.ddsCaps.dwCaps = DDSCAPS_TEXTURE;
        ddsd.ddsCaps.dwCaps2 = DDSCAPS2_TEXTUREMANAGE | DDSCAPS2_HINTSTATIC;

        //
        // Take care of DDraw surface app images.
        //
        if (m_dwAppImageFlags & (APPIMG_DDSURFARGB32|APPIMG_DDSURFRGB32)) {

            ddsd.dwFlags |= DDSD_PIXELFORMAT;

            //
            // Slot 1. of the g_rgTextMirFormats is an RGB32 pixel format.
            //

            ddsd.ddpfPixelFormat = g_rgTextMirFormats[1];

            if (m_dwAppImageFlags & APPIMG_DDSURFARGB32) {
                ddsd.ddpfPixelFormat.dwFlags |= DDPF_ALPHAPIXELS;
            }
        }

        hr = m_pDD->CreateSurface( &ddsd, &pDDS, NULL );
        if (SUCCEEDED(hr))
        {
            m_fAppImageTexWid = 1.0F / (float)ddsd.dwWidth;
            m_fAppImageTexHgt = 1.0F / (float)ddsd.dwHeight;

            if (m_clrTrans != CLR_INVALID) {
                m_dwClrTransMapped = DDColorMatch(pDDS, m_clrTrans, hr);
                if (hr == DD_OK) {
                    DDCOLORKEY key = {m_dwClrTransMapped, m_dwClrTransMapped};
                    CHECK_HR(hr = pDDS->SetColorKey(DDCKEY_SRCBLT, &key));
                }
            }
        }


        if (FAILED(hr)) {
            __leave;
        }

        CHECK_HR( hr = pDDS->GetDC( &hdcDest ) );

        hdcSrc = CreateCompatibleDC( hdcDest );
        if (!hdcSrc)
        {
            DbgLog((LOG_ERROR, 1, TEXT("Could not create DC")));
            hr = E_OUTOFMEMORY;
            __leave;
        }

        HBITMAP hbmOld = (HBITMAP)SelectObject(hdcSrc, m_hbmpAppImage);
        if (!hbmOld) {
            DbgLog((LOG_ERROR, 1, TEXT("Selectobject failed copying into app image surface")));
            hr = E_FAIL;
            __leave;
        }

        BOOL fRc = BitBlt(hdcDest, 0, 0, m_dwWidthAppImage, m_dwHeightAppImage,
                          hdcSrc, 0, 0, SRCCOPY);
        SelectObject(hdcSrc, hbmOld);
        if (!fRc)
        {
            DbgLog((LOG_ERROR, 1, TEXT("BitBlt failed copying into app image surface")));
            hr = E_FAIL;
            __leave;
        }
    }
    __finally
    {
        if (hdcSrc)
        {
            DeleteDC(hdcSrc);
        }

        if (hdcDest )
        {
            pDDS->ReleaseDC(hdcDest);
        }
    }

    if ( S_OK == hr )
    {
        RELEASE(m_pDDSAppImage);
        m_pDDSAppImage = pDDS;
    }
    else
    {
        RELEASE( pDDS );
    }
    return hr;
}


/*****************************Private*Routine******************************\
* BlendAppImage
*
*
*
* History:
* Tue 10/03/2000 - NWilt - Created
*
\**************************************************************************/
HRESULT
CVideoMixer::BlendAppImage(
    LPDIRECTDRAWSURFACE7 pDDS,
    LPDIRECT3DDEVICE7 pD3DDevice
    )
{
    CAutoLock Lock(&m_ObjectLock);

    HRESULT hr;
    DDSURFACEDESC2 ddsd = {sizeof(ddsd)};
    struct {
        float x, y, z, rhw;
        D3DCOLOR clr;
        float tu, tv;
    } V[4];

    __try {

        if (!m_pDDSAppImage)
        {
            CHECK_HR( hr = CreateAppImageMirror() );
        }

        CHECK_HR( hr = pDDS->GetSurfaceDesc(&ddsd) );

        float fWid = (float)ddsd.dwWidth;
        float fHgt = (float)ddsd.dwHeight;
        BYTE alpha = (BYTE)(255.0f * m_fAlpha);

        // top-left
        V[0].x = (m_rDest.left  *fWid) - 0.5F;
        V[0].y = (m_rDest.top   *fHgt) - 0.5F;
        V[0].z = 0.5f;
        V[0].rhw = 2.0f;
        V[0].clr = RGBA_MAKE(0xff, 0xff, 0xff, alpha);

        // top-right
        V[1].x = (m_rDest.right *fWid) - 0.5F;
        V[1].y = (m_rDest.top   *fHgt) - 0.5F;
        V[1].z = 0.5f;
        V[1].rhw = 2.0f;
        V[1].clr = RGBA_MAKE(0xff, 0xff, 0xff, alpha);

        // bottom-left
        V[2].x = (m_rDest.left  *fWid) - 0.5F;
        V[2].y = (m_rDest.bottom*fHgt) - 0.5F;
        V[2].z = 0.5f;
        V[2].rhw = 2.0f;
        V[2].clr = RGBA_MAKE(0xff, 0xff, 0xff, alpha);

        // bottom-right
        V[3].x = (m_rDest.right *fWid) - 0.5F;
        V[3].y = (m_rDest.bottom*fHgt) - 0.5F;
        V[3].z = 0.5f;
        V[3].rhw = 2.0f;
        V[3].clr = RGBA_MAKE(0xff, 0xff, 0xff, alpha);

        // top-left
        V[0].tu = (float)m_rcAppImageSrc.left * m_fAppImageTexWid;
        V[0].tv = (float)m_rcAppImageSrc.top * m_fAppImageTexHgt;

        // top-rigth
        V[1].tu = (float)m_rcAppImageSrc.right * m_fAppImageTexWid;
        V[1].tv = (float)m_rcAppImageSrc.top * m_fAppImageTexHgt;

        // bottom-left
        V[2].tu = (float)m_rcAppImageSrc.left * m_fAppImageTexWid;
        V[2].tv = (float)m_rcAppImageSrc.bottom * m_fAppImageTexHgt;

        // bottom-right
        V[3].tu = (float)m_rcAppImageSrc.right * m_fAppImageTexWid;
        V[3].tv = (float)m_rcAppImageSrc.bottom * m_fAppImageTexHgt;

        CHECK_HR(hr = pD3DDevice->SetTexture(0, m_pDDSAppImage));
        CHECK_HR(hr = pD3DDevice->SetRenderState(D3DRENDERSTATE_CULLMODE, D3DCULL_NONE));
        CHECK_HR(hr = pD3DDevice->SetRenderState(D3DRENDERSTATE_LIGHTING, FALSE));
        CHECK_HR(hr = pD3DDevice->SetRenderState(D3DRENDERSTATE_BLENDENABLE, TRUE));
        CHECK_HR(hr = pD3DDevice->SetRenderState(D3DRENDERSTATE_SRCBLEND, D3DBLEND_SRCALPHA));
        CHECK_HR(hr = pD3DDevice->SetRenderState(D3DRENDERSTATE_DESTBLEND, D3DBLEND_INVSRCALPHA));

        if (m_dwAppImageFlags & APPIMG_DDSURFARGB32)
        {
            CHECK_HR(hr = pD3DDevice->SetTextureStageState(0, D3DTSS_ALPHAOP, D3DTOP_MODULATE));
            CHECK_HR(hr = pD3DDevice->SetTextureStageState(0, D3DTSS_ALPHAARG1, D3DTA_TEXTURE));
            CHECK_HR(hr = pD3DDevice->SetTextureStageState(0, D3DTSS_ALPHAARG2, D3DTA_DIFFUSE));
            CHECK_HR(hr = pD3DDevice->SetRenderState(D3DRENDERSTATE_ALPHATESTENABLE, TRUE));
            CHECK_HR(hr = pD3DDevice->SetRenderState(D3DRENDERSTATE_ALPHAREF, 0x10));
            CHECK_HR(hr = pD3DDevice->SetRenderState(D3DRENDERSTATE_ALPHAFUNC, D3DCMP_GREATER));
            CHECK_HR(hr = pD3DDevice->SetRenderState(D3DRENDERSTATE_COLORKEYENABLE, FALSE));
        }
        else
        {
            CHECK_HR( hr = pD3DDevice->SetTextureStageState( 0, D3DTSS_ALPHAOP, D3DTOP_SELECTARG1));
            CHECK_HR( hr = pD3DDevice->SetTextureStageState( 0, D3DTSS_ALPHAARG1, D3DTA_DIFFUSE));
            CHECK_HR( hr = pD3DDevice->SetRenderState( D3DRENDERSTATE_ALPHATESTENABLE, FALSE ) );

            BOOL fKey = (m_clrTrans != CLR_INVALID);
            pD3DDevice->SetRenderState(D3DRENDERSTATE_COLORKEYENABLE, fKey);
        }

        if (m_MixingPrefs & MixerPref_BiLinearFiltering) {
            CHECK_HR(hr = pD3DDevice->SetTextureStageState(0, D3DTSS_MAGFILTER, D3DTFG_LINEAR));
            CHECK_HR(hr = pD3DDevice->SetTextureStageState(0, D3DTSS_MINFILTER, D3DTFN_LINEAR));
            CHECK_HR(hr = pD3DDevice->SetTextureStageState(0, D3DTSS_MIPFILTER, D3DTFP_LINEAR));
        }
        else {
            // ATi Rage Pro preferes these settings
            CHECK_HR(hr = pD3DDevice->SetTextureStageState(0, D3DTSS_MAGFILTER, D3DTFG_POINT));
            CHECK_HR(hr = pD3DDevice->SetTextureStageState(0, D3DTSS_MINFILTER, D3DTFN_POINT));
            CHECK_HR(hr = pD3DDevice->SetTextureStageState(0, D3DTSS_MIPFILTER, D3DTFP_POINT));
        }

        CHECK_HR(hr = pD3DDevice->SetTextureStageState(0, D3DTSS_COLORARG1, D3DTA_TEXTURE));
        CHECK_HR(hr = pD3DDevice->SetTextureStageState(0, D3DTSS_ADDRESS, D3DTADDRESS_CLAMP));

        CHECK_HR(hr = pD3DDevice->BeginScene());
        CHECK_HR(hr = pD3DDevice->DrawPrimitive(D3DPT_TRIANGLESTRIP,
                                                D3DFVF_XYZRHW |
                                                D3DFVF_DIFFUSE | D3DFVF_TEX1,
                                                V, 4, D3DDP_WAIT));
        CHECK_HR(hr = pD3DDevice->EndScene());
        CHECK_HR(hr = pD3DDevice->SetTexture(0, NULL));
    }
    __finally
    {
    }
    return hr;
}


/*****************************Private*Routine******************************\
* CompositeStreams
*
* Prepares the streams ready to call the plugin compositor.
*
* History:
* Wed 07/19/2000 - NWilt    - Created
* Wed 07/19/2000 - StEstrop - made it call the plug-in compositor
*
\**************************************************************************/
HRESULT
CVideoMixer::CompositeStreams(
    LPDIRECTDRAWSURFACE7 pDDSBack,
    LPDIRECT3DDEVICE7 pD3DDevice,
    REFERENCE_TIME rtStart,
    REFERENCE_TIME rtEnd,
    LPDIRECTDRAWSURFACE7 *ppDDSSamples,
    DWORD dwStrmIDs[],
    UINT cStreams
    )
{
    HRESULT hr;
    UINT iMap[MAX_MIXER_STREAMS];
    DWORD dwZ[MAX_MIXER_STREAMS];
    VMRVIDEOSTREAMINFO strmMT[MAX_MIXER_STREAMS];
    ZeroMemory(strmMT, sizeof(strmMT));

    __try {

        // Get the Z-Order for each stream
        UINT i;
        for ( i = 0; i < cStreams; i++ )
        {
            iMap[i] = i;
            m_ppMixerStreams[dwStrmIDs[i]]->GetStreamZOrder( &dwZ[i] );
        }


        // insertion sort in Z such that highest Z gets drawn first
        for ( i = 1; i < cStreams; i++ )
        {
            UINT j = i;
            while ( j > 0 && dwZ[iMap[j-1]] < dwZ[iMap[j]] )
            {
                UINT t = iMap[j-1];
                iMap[j-1] = iMap[j];
                iMap[j] = t;
                j -= 1;
            }
        }

        for ( i = 0; i < cStreams; i++ )
        {
            DDSURFACEDESC2 ddsd = {sizeof(ddsd)};
            UINT k = iMap[i];
            UINT j = dwStrmIDs[k];

            strmMT[i].pddsVideoSurface = ppDDSSamples[k];
            strmMT[i].dwStrmID = j;
            CHECK_HR(hr = ppDDSSamples[k]->GetSurfaceDesc(&ddsd));
            strmMT[i].dwWidth = ddsd.dwWidth;
            strmMT[i].dwHeight = ddsd.dwHeight;

            CHECK_HR(hr = m_ppMixerStreams[j]->GetStreamColorKey(&strmMT[i].ddClrKey));
            CHECK_HR(hr = m_ppMixerStreams[j]->GetStreamAlpha(&strmMT[i].fAlpha));
            CHECK_HR(hr = m_ppMixerStreams[j]->GetStreamOutputRect(&strmMT[i].rNormal));
        }


        CHECK_HR( hr = m_pImageCompositor->CompositeImage(pD3DDevice,
                                                          pDDSBack,
                                                          m_pmt,
                                                          rtStart,
                                                          rtEnd,
                                                          m_dwClrBorderMapped,
                                                          strmMT,
                                                          cStreams) );
    }
    __finally {}


    return hr;
}

/******************************Public*Routine******************************\
* InitCompositionTarget
*
*
*
* History:
* Fri 06/23/2000 - StEstrop - Created
*
\**************************************************************************/
STDMETHODIMP
CVideoMixer::CIIVMRImageCompositor::InitCompositionTarget(
    IUnknown* pD3DDevice,
    LPDIRECTDRAWSURFACE7 pddsRenderTarget
    )
{
    AMTRACE((TEXT("CVideoMixer::CIIVMRImageCompositor::InitCompositionTarget")));
    return S_OK;
}

/******************************Public*Routine******************************\
* TermCompositionTarget
*
*
*
* History:
* Fri 06/23/2000 - StEstrop - Created
*
\**************************************************************************/
STDMETHODIMP
CVideoMixer::CIIVMRImageCompositor::TermCompositionTarget(
    IUnknown* pD3DDevice,
    LPDIRECTDRAWSURFACE7 pddsRenderTarget
    )
{
    AMTRACE((TEXT("CVideoMixer::CIIVMRImageCompositor::TermCompositionTarget")));
    return S_OK;
}

/******************************Public*Routine******************************\
* SetStreamMediaType
*
*
*
* History:
* Wed 02/28/2001 - StEstrop - Created
*
\**************************************************************************/
STDMETHODIMP
CVideoMixer::CIIVMRImageCompositor::SetStreamMediaType(
    DWORD dwStrmID,
    AM_MEDIA_TYPE *pmt,
    BOOL fTexture
    )
{
    AMTRACE((TEXT("CVideoMixer::CIIVMRImageCompositor::TermCompositionTarget")));

    AM_MEDIA_TYPE *pmtStrm = &StrmProps[dwStrmID].mt;

    FreeMediaType(*pmtStrm);

    if (pmt) {
        CopyMediaType(pmtStrm, pmt);
        FixupMediaType(pmtStrm);
    }
    else {
        ZeroMemory(pmtStrm, sizeof(*pmtStrm));
    }

    StrmProps[dwStrmID].fTexture = fTexture;

    return S_OK;
}


/*****************************Private*Routine******************************\
* CalcSrcAndDstFromMT
*
*
*
* History:
*  - StEstrop - Created
*
\**************************************************************************/
void
CalcSrcAndDstFromMT(
    const AM_MEDIA_TYPE& pmt,
    const RECT& Target,
    LPRECT lpSrc,
    LPRECT lpDst,
    LPRECT lprcBdrTL = NULL,
    LPRECT lprcBdrBR = NULL
    )
{
    RECT Trg = *GetTargetRectFromMediaType(&pmt);
    *lpSrc = *GetSourceRectFromMediaType(&pmt);

    SIZE ar;
    GetImageAspectRatio(&pmt, &ar.cx, &ar.cy);

    SIZE im = {WIDTH(&Trg), HEIGHT(&Trg)};
    AspectRatioCorrectSize(&im, ar);

    RECT Src = {0, 0, im.cx, im.cy};
    LetterBoxDstRect(lpDst, Src, Target, lprcBdrTL, lprcBdrBR);
}


/*****************************Private*Routine******************************\
* OptimizeBackground
*
* Simple optimization.
*
* If the bottom layer of video covers the composition space and
* it has an Alpha value of 1 then just BLT the video image into
* place.  Otherwise we have to clear the back buffer to black and
* blend the video with it.
*
* History:
* Tue 09/12/2000 - StEstrop - Created
*
\**************************************************************************/
HRESULT
CVideoMixer::CIIVMRImageCompositor::OptimizeBackground(
    REFERENCE_TIME rtStart,
    LPDIRECTDRAWSURFACE7 pDDSBack,
    LPRECT lpTarget,
    const VMRVIDEOSTREAMINFO* ps,
    DWORD dwMappedBdrClr,
    UINT* uNextStrm
    )
{
    HRESULT hr = DD_OK;
    *uNextStrm = 0;

    CVideoMixerStream* thisStream = m_pObj->m_ppMixerStreams[ps->dwStrmID];

    __try {

        DDSURFACEDESC2 ddsdV = {sizeof(ddsdV)};
        DDSURFACEDESC2 ddsdB = {sizeof(ddsdB)};

        BOOL fBltOk = TRUE;

        CHECK_HR(hr = ps->pddsVideoSurface->GetSurfaceDesc(&ddsdV));
        CHECK_HR(hr = pDDSBack->GetSurfaceDesc(&ddsdB));

        //
        // We have to blend video surfaces that contain embedded alpha
        //
        if (ddsdV.ddpfPixelFormat.dwFlags & DDPF_ALPHAPIXELS) {
            fBltOk = FALSE;
        }

        //
        // if the video surface is RGB it must match the pixel format
        // of the render target otherwise the Blt will fail
        //
        else if (DDPF_RGB == (ddsdV.ddpfPixelFormat.dwFlags & DDPF_RGB)) {

            DDPIXELFORMAT* ddpfB = &ddsdB.ddpfPixelFormat;
            DDPIXELFORMAT* ddpfV = &ddsdV.ddpfPixelFormat;

            fBltOk = (ddpfB->dwRGBBitCount == ddpfV->dwRGBBitCount &&
                      ddpfB->dwRBitMask    == ddpfV->dwRBitMask    &&
                      ddpfB->dwGBitMask    == ddpfV->dwGBitMask    &&
                      ddpfB->dwBBitMask    == ddpfV->dwBBitMask);
        }

        DDCAPS_DX7& ddCaps = m_pObj->m_ddHWCaps;

        //
        // Check the Blt stretching caps.  Make sure the caps we look
        // at match the surface we are blting from ie. VIDMem or AGPMem.
        //
        if (ddsdV.ddsCaps.dwCaps & DDSCAPS_NONLOCALVIDMEM) {

            DWORD dwCaps = 0;
            const DWORD dwFXCaps =  DDFXCAPS_BLTSHRINKX | DDFXCAPS_BLTSHRINKX  |
                                    DDFXCAPS_BLTSTRETCHX | DDFXCAPS_BLTSTRETCHY;

            if (DDPF_RGB == (ddsdV.ddpfPixelFormat.dwFlags & DDPF_RGB)) {
                dwCaps = DDCAPS_BLTSTRETCH;
            }
            else if (DDPF_FOURCC == (ddsdV.ddpfPixelFormat.dwFlags & DDPF_FOURCC)) {
                dwCaps = (DDCAPS_BLTFOURCC | DDCAPS_BLTSTRETCH);
            }

            fBltOk &= ((dwCaps & ddCaps.dwNLVBCaps) == dwCaps);
            fBltOk &= ((dwFXCaps & ddCaps.dwNLVBFXCaps) == dwFXCaps);
        }
        else {

            DWORD dwCaps = 0;
            const DWORD dwFXCaps =  DDFXCAPS_BLTSHRINKX | DDFXCAPS_BLTSHRINKX  |
                                    DDFXCAPS_BLTSTRETCHX | DDFXCAPS_BLTSTRETCHY;

            if (DDPF_RGB == (ddsdV.ddpfPixelFormat.dwFlags & DDPF_RGB)) {
                dwCaps = DDCAPS_BLTSTRETCH;
            }
            else if (DDPF_FOURCC == (ddsdV.ddpfPixelFormat.dwFlags & DDPF_FOURCC)) {
                dwCaps = (DDCAPS_BLTFOURCC | DDCAPS_BLTSTRETCH);
            }

            fBltOk &= ((dwCaps & ddCaps.dwCaps) == dwCaps);
            fBltOk &= ((dwFXCaps & ddCaps.dwFXCaps) == dwFXCaps);
        }

        DDBLTFX ddFX;
        INITDDSTRUCT(ddFX);

        if (SpecialIMC3Mode(m_pObj->m_MixingPrefs)) {
            // we should really convert the rgb background colour
            // specified by the user into an AYUV color here.
            ddFX.dwFillColor = 0x80801000;
        }
        else {
            ddFX.dwFillColor = dwMappedBdrClr;
        }
        AM_MEDIA_TYPE* pmt = &StrmProps[ps->dwStrmID].mt;

        TargetScale postScale;
        GetTargetScaleFromMediaType(pmt, &postScale);


        //
        // only optimize if no custom user rectangle, no anamorphic hacks
        // and Alpha of 1.0
        //

        if (ps->rNormal.left == 0.0F && ps->rNormal.top == 0.0F &&
            ps->rNormal.right == 1.0F && ps->rNormal.bottom == 1.0F &&
            ps->fAlpha == 1.0F && postScale.fX == 1.0F && postScale.fY == 1.0F )
        {
            RECT rcDst, rcSrc, rcBdrTL, rcBdrBR;

            CalcSrcAndDstFromMT(*pmt, *lpTarget, &rcSrc, &rcDst,
                                &rcBdrTL, &rcBdrBR);
            if (fBltOk) {

                //
                // We need to de-interlace this video image if:
                //
                // 1. the stream is interlaced
                // 2. the stream has a deinterlacing device
                // 3. we are not in the special IMC3 mode.
                //

                if (thisStream->IsStreamInterlaced() &&
                    thisStream->CanBeDeinterlaced() &&
                    !SpecialIMC3Mode(m_pObj->m_MixingPrefs)) {

                    if (S_OK == thisStream->DeinterlaceStream(
                                    rtStart, &rcDst, pDDSBack, &rcSrc,
                                    !!(ddsdB.ddpfPixelFormat.dwFlags & DDPF_RGB))) {

                        *uNextStrm = 1; // move on to the next stream
                    }
                }
                else {

                    CHECK_HR(hr = pDDSBack->Blt(&rcDst, ps->pddsVideoSurface,
                                                &rcSrc, DDBLT_WAIT, NULL));
                    *uNextStrm = 1; // move on to the next stream
                }
            }

            if (!IsRectEmpty(&rcBdrTL)) {
                CHECK_HR(hr = pDDSBack->Blt(&rcBdrTL, NULL, NULL,
                                            DDBLT_COLORFILL | DDBLT_WAIT,
                                            &ddFX));
            }

            if (!IsRectEmpty(&rcBdrBR)) {
                CHECK_HR(hr = pDDSBack->Blt(&rcBdrBR, NULL, NULL,
                                            DDBLT_COLORFILL | DDBLT_WAIT,
                                            &ddFX));
            }
        }
        else
        {
            //
            // Clear the back buffer with colorfill Blt, for some reason
            // D3D's Clear introduces rendering artifacts
            //

            CHECK_HR(hr = pDDSBack->Blt(NULL, NULL, NULL,
                                        DDBLT_COLORFILL | DDBLT_WAIT,
                                        &ddFX));
        }
    }
    __finally {}

    return hr;
}

/******************************Public*Routine******************************\
* CenterInverseScale
*
*   Scale the rectangle (about its center) by the given scale
*
* History:
* Tue 03/14/2000 - GlennE - Created
*
\**************************************************************************/
static void CenterScale( NORMALIZEDRECT* prDest,  const TargetScale& scale )
{
    if( scale.fX != 1.0F ) {
        float centerX = (prDest->left+prDest->right)/2;
        float halfWidth = (prDest->right - prDest->left)/2 * scale.fX;

        prDest->left = centerX - halfWidth;
        prDest->right = centerX + halfWidth;
    }
    if( scale.fY != 1.0F ) {
        float centerY = (prDest->top + prDest->bottom)/2;
        float halfHeight = (prDest->bottom - prDest->top)/2 * scale.fY;
        prDest->top = centerY - halfHeight;
        prDest->bottom = centerY + halfHeight;
    }
}

static void CopyRectFromTo( const RECT& from, NORMALIZEDRECT* pTo )
{
    // Note: to float
    pTo->left = float(from.left);
    pTo->top = float(from.top);
    pTo->right = float(from.right);
    pTo->bottom = float(from.bottom);
}

/*****************************Private*Routine******************************\
* SpecialIMC3Composite
*
* A stripped down compositor for IMC3 render targets.
*
* History:
* Tue 05/08/2001 - StEstrop - Created
*
\**************************************************************************/
HRESULT
CVideoMixer::CIIVMRImageCompositor::SpecialIMC3Composite(
    LPDIRECTDRAWSURFACE7 pDDSBack,
    LPRECT lprcRenderTarget,
    VMRVIDEOSTREAMINFO* pStrmInfo,
    UINT i,
    UINT cStreams
    )
{
    HRESULT hr = S_OK;

    for ( ; i < cStreams; i++, pStrmInfo++) {

        //
        // start with the user rectangle and place an aspect ratio
        // corrected version inside of it.
        //
        NORMALIZEDRECT rDest = pStrmInfo[i].rNormal;

        //
        // Compute letterbox of userTarget
        //
        RECT rcSrc, rcUserDst;
        AM_MEDIA_TYPE* pmt = &StrmProps[pStrmInfo[i].dwStrmID].mt;
        CalcSrcAndDstFromMT(*pmt, *lprcRenderTarget, &rcSrc, &rcUserDst);

        //
        // Copy letterboxed UserTarget back to overall Target image
        //
        NORMALIZEDRECT rLetterboxedDest;
        CopyRectFromTo(rcUserDst, &rLetterboxedDest );

        //
        // We reduce the image within destination rectangle to the
        // internal aspect ratio. The squish is applied to the FINAL
        // displayed image
        //
        TargetScale postScale;
        GetTargetScaleFromMediaType(pmt, &postScale);
        CenterScale(&rLetterboxedDest, postScale);

        // now map the normalized destination to the target
        float fWidth = (rLetterboxedDest.right - rLetterboxedDest.left);
        float fHeight= (rLetterboxedDest.bottom - rLetterboxedDest.top);

        float rdWidth  = (rDest.right - rDest.left);
        float rdHeight = (rDest.bottom - rDest.top);

        // work out the position of the stream
        float fLeft = (rLetterboxedDest.left * rdWidth)  + (WIDTH(lprcRenderTarget)  * rDest.left);
        float fTop  = (rLetterboxedDest.top  * rdHeight) + (HEIGHT(lprcRenderTarget) * rDest.top);

        // work out the size of the stream
        // investigate: should be able to do this using only rDest.right
        float fRight  = fLeft + (fWidth  * rdWidth);
        float fBottom = fTop  + (fHeight * rdHeight);

        RECT rcDst = {(int)fLeft, (int)fTop, (int)fRight, (int)fBottom};
        hr = pDDSBack->Blt(&rcDst, pStrmInfo[i].pddsVideoSurface,
                           &rcSrc, DDBLT_WAIT, NULL);
        if (FAILED(hr)) {
            return hr;
        }
    }

    return hr;
}

/******************************Public*Routine******************************\
* CompositeImage
*
*
*
* History:
* Fri 06/23/2000 - StEstrop - Created
*
\**************************************************************************/
STDMETHODIMP
CVideoMixer::CIIVMRImageCompositor::CompositeImage(
    IUnknown* pUnk,
    LPDIRECTDRAWSURFACE7 pDDSBack,
    AM_MEDIA_TYPE* pmtRT,
    REFERENCE_TIME rtStart,
    REFERENCE_TIME rtEnd,
    DWORD dwBkgClr,
    VMRVIDEOSTREAMINFO* pStrmInfo,
    UINT cStreams
    )
{
    AMTRACE((TEXT("CVideoMixer::CIIVMRImageCompositor::CompositeImage")));

    HRESULT hr = S_OK;
    LPDIRECT3DDEVICE7 pD3DDevice = (LPDIRECT3DDEVICE7)pUnk;
    DDSURFACEDESC2 ddsdTextureMirror = { sizeof(ddsdTextureMirror) };
    bool bInScene = false;

    __try {

        //
        // Start by processing the composition background, normally
        // the lowest layer stream completely covers the background.
        // In which case we can Blt it to the composition surface and
        // move on to the next stream.  If there are no more streams
        // then we are done.
        //

        UINT i = 0;
        LPRECT lprcRenderTarget = GetTargetRectFromMediaType(pmtRT);
        ASSERT(lprcRenderTarget);

        //
        // copy the first stream if no special requirements and
        // increment 'i'.  Otherwise black fill the image and
        // leave 'i' at 0.
        //
        CHECK_HR( hr = OptimizeBackground(rtStart, pDDSBack, lprcRenderTarget,
                                          &pStrmInfo[0], dwBkgClr, &i));
        if (i == cStreams) {
            __leave;
        }


        //
        // Special case code to get the Intel i810 and i815 working correctly.
        //

        if (SpecialIMC3Mode(m_pObj->m_MixingPrefs)) {
            hr = SpecialIMC3Composite(pDDSBack, lprcRenderTarget,
                                      pStrmInfo, i, cStreams);
            __leave;
        }

        if (m_pObj->m_pDDSTextureMirror)
            CHECK_HR(hr = m_pObj->m_pDDSTextureMirror->GetSurfaceDesc(&ddsdTextureMirror));

        CHECK_HR(hr = pD3DDevice->SetRenderState( D3DRENDERSTATE_CULLMODE, D3DCULL_NONE));
        CHECK_HR(hr = pD3DDevice->SetRenderState( D3DRENDERSTATE_LIGHTING, FALSE));
        CHECK_HR(hr = pD3DDevice->SetRenderState( D3DRENDERSTATE_BLENDENABLE, TRUE));
        CHECK_HR(hr = pD3DDevice->SetRenderState( D3DRENDERSTATE_SRCBLEND, D3DBLEND_SRCALPHA));
        CHECK_HR(hr = pD3DDevice->SetRenderState( D3DRENDERSTATE_DESTBLEND, D3DBLEND_INVSRCALPHA));

        // use diffuse alpha from vertices, not texture alpha
        CHECK_HR(hr = pD3DDevice->SetTextureStageState(0, D3DTSS_COLOROP, D3DTOP_SELECTARG1));

        if (m_pObj->m_MixingPrefs & MixerPref_BiLinearFiltering) {
            CHECK_HR(hr = pD3DDevice->SetTextureStageState(0, D3DTSS_MAGFILTER, D3DTFG_LINEAR));
            CHECK_HR(hr = pD3DDevice->SetTextureStageState(0, D3DTSS_MINFILTER, D3DTFN_LINEAR));
            CHECK_HR(hr = pD3DDevice->SetTextureStageState(0, D3DTSS_MIPFILTER, D3DTFP_LINEAR));
        }
        else {
            // ATi Rage Pro preferes these settings
            CHECK_HR(hr = pD3DDevice->SetTextureStageState(0, D3DTSS_MAGFILTER, D3DTFG_POINT));
            CHECK_HR(hr = pD3DDevice->SetTextureStageState(0, D3DTSS_MINFILTER, D3DTFN_POINT));
            CHECK_HR(hr = pD3DDevice->SetTextureStageState(0, D3DTSS_MIPFILTER, D3DTFP_POINT));
        }


        CHECK_HR(hr = pD3DDevice->SetTextureStageState(0, D3DTSS_COLORARG1, D3DTA_TEXTURE));
        CHECK_HR(hr = pD3DDevice->SetTextureStageState(0, D3DTSS_ADDRESS, D3DTADDRESS_CLAMP));
        CHECK_HR(hr = pD3DDevice->SetTextureStageState(0, D3DTSS_ALPHAARG1, D3DTA_DIFFUSE));


        CHECK_HR(hr = pD3DDevice->BeginScene());
        bInScene = true;

        for ( ; i < cStreams; i++ )
        {
            LPDIRECTDRAWSURFACE7 pDDS;
            float fTexWidRatio;
            float fTexHgtRatio;

            BOOL fTexture = StrmProps[pStrmInfo[i].dwStrmID].fTexture;
            LPDIRECTDRAWSURFACE7 pDDSSrc = pStrmInfo[i].pddsVideoSurface;
            CVideoMixerStream* thisStream =
                m_pObj->m_ppMixerStreams[pStrmInfo[i].dwStrmID];

            //
            // determine if this stream is interlaced, if it is
            // we need to get it de-interlaced before we can do anything
            // with it.  Each stream has its own dedicated de-interlacing
            // device and de-interlace destination surface.  The destination
            // surface could be a texture or a regular offscreen plain
            // surface.
            //

            if (thisStream->IsStreamInterlaced() &&
                thisStream->CanBeDeinterlaced()) {

                if (S_OK == thisStream->DeinterlaceStream(rtStart, NULL, NULL, NULL, FALSE)) {

                    fTexture  = thisStream->IsDeinterlaceDestATexture();
                    pDDSSrc = thisStream->GetDeinterlaceDestSurface();
                }
                else {

                    fTexture = FALSE;
                }
            }

            if (fTexture) {

                pDDS = pDDSSrc;
                fTexWidRatio = 1.0F / (float)pStrmInfo[i].dwWidth;
                fTexHgtRatio = 1.0F / (float)pStrmInfo[i].dwHeight;
            }
            else {

                RECT r = {0, 0, pStrmInfo[i].dwWidth, pStrmInfo[i].dwHeight};

                pDDS = m_pObj->m_pDDSTextureMirror;
                ASSERT(pDDS != NULL);

                CHECK_HR(hr = pDDS->Blt(&r, pDDSSrc, &r, DDBLT_WAIT, NULL));
                fTexWidRatio = 1.0F / (float)ddsdTextureMirror.dwWidth;
                fTexHgtRatio = 1.0F / (float)ddsdTextureMirror.dwHeight;
            }

            CHECK_HR(hr = pD3DDevice->SetTexture(0, pDDS));

            AM_MEDIA_TYPE* pmt = &StrmProps[pStrmInfo[i].dwStrmID].mt;
            if (MEDIASUBTYPE_HASALPHA(*pmt))
            {
                CHECK_HR( hr = pD3DDevice->SetTextureStageState( 0, D3DTSS_ALPHAOP, D3DTOP_MODULATE /*D3DTOP_SELECTARG1 */ ) );
                CHECK_HR( hr = pD3DDevice->SetTextureStageState( 0, D3DTSS_ALPHAARG1, D3DTA_TEXTURE ) );
                CHECK_HR( hr = pD3DDevice->SetTextureStageState( 0, D3DTSS_ALPHAARG2, D3DTA_DIFFUSE ) );
                CHECK_HR( hr = pD3DDevice->SetRenderState( D3DRENDERSTATE_ALPHATESTENABLE, TRUE ) );
                CHECK_HR( hr = pD3DDevice->SetRenderState( D3DRENDERSTATE_ALPHAREF, 0x10 ) );
                CHECK_HR( hr = pD3DDevice->SetRenderState( D3DRENDERSTATE_ALPHAFUNC, D3DCMP_GREATER));
                CHECK_HR( hr = pD3DDevice->SetRenderState(D3DRENDERSTATE_COLORKEYENABLE, FALSE));
            }
            else
            {
                CHECK_HR( hr = pD3DDevice->SetTextureStageState( 0, D3DTSS_ALPHAOP, D3DTOP_SELECTARG1));
                CHECK_HR( hr = pD3DDevice->SetTextureStageState( 0, D3DTSS_ALPHAARG1, D3DTA_DIFFUSE));
                CHECK_HR( hr = pD3DDevice->SetRenderState( D3DRENDERSTATE_ALPHATESTENABLE, FALSE ) );

                BOOL fKey = ((pStrmInfo[i].ddClrKey.dwColorSpaceLowValue != 0xFFFFFFFF) &&
                             (pStrmInfo[i].ddClrKey.dwColorSpaceHighValue != 0xFFFFFFFF));
                CHECK_HR( hr = pD3DDevice->SetRenderState(D3DRENDERSTATE_COLORKEYENABLE, fKey));
                if (fKey) {
                    CHECK_HR(hr = pDDS->SetColorKey(DDCKEY_SRCBLT, &pStrmInfo[i].ddClrKey));
                }
            }

            struct {
                float x, y, z, rhw;
                D3DCOLOR clr;
                float tu, tv;
            } V[4];

            //
            // start with the user rectangle and place an aspect ratio
            // corrected version inside of it.
            //
            NORMALIZEDRECT rDest = pStrmInfo[i].rNormal;

            //
            // Compute letterbox of userTarget
            //
            RECT rcSrc, rcUserDst;
            CalcSrcAndDstFromMT(*pmt, *lprcRenderTarget, &rcSrc, &rcUserDst);

            //
            // Copy letterboxed UserTarget back to overall Target image
            //
            NORMALIZEDRECT rLetterboxedDest;
            CopyRectFromTo(rcUserDst, &rLetterboxedDest );

            //
            // We reduce the image within destination rectangle to the
            // internal aspect ratio. The squish is applied to the FINAL
            // displayed image
            //
            TargetScale postScale;
            GetTargetScaleFromMediaType(pmt, &postScale);
            CenterScale(&rLetterboxedDest, postScale);

            // now map the normalized destination to the target
            float fWidth = (rLetterboxedDest.right - rLetterboxedDest.left);
            float fHeight= (rLetterboxedDest.bottom - rLetterboxedDest.top);

            float rdWidth  = (rDest.right - rDest.left);
            float rdHeight = (rDest.bottom - rDest.top);

            // work out the position of the stream
            float fLeft = (rLetterboxedDest.left * rdWidth)  + (WIDTH(lprcRenderTarget)  * rDest.left);
            float fTop  = (rLetterboxedDest.top  * rdHeight) + (HEIGHT(lprcRenderTarget) * rDest.top);

            // work out the size of the stream
            // investigate: should be able to do this using only rDest.right
            float fRight  = fLeft + (fWidth  * rdWidth);
            float fBottom = fTop  + (fHeight * rdHeight);

            BYTE bAlpha = (BYTE) ((UINT) 0xff * pStrmInfo[i].fAlpha);

            V[0].x = fLeft - 0.5F;
            V[0].y = fTop - 0.5F;
            V[0].z = 0.5f;
            V[0].rhw = 2.0f;
            V[0].clr = RGBA_MAKE(0xff, 0xff, 0xff, bAlpha);

            V[1].x = fRight - 0.5F;
            V[1].y = fTop - 0.5F;
            V[1].z = 0.5f;
            V[1].rhw = 2.0f;
            V[1].clr = RGBA_MAKE(0xff, 0xff, 0xff, bAlpha);

            V[2].x = fLeft - 0.5F;
            V[2].y = fBottom - 0.5F;
            V[2].z = 0.5f;   V[2].rhw = 2.0f;
            V[2].clr = RGBA_MAKE(0xff, 0xff, 0xff, bAlpha);

            V[3].x = fRight - 0.5F;
            V[3].y = fBottom - 0.5F;
            V[3].z = 0.5f;
            V[3].rhw = 2.0f;
            V[3].clr = RGBA_MAKE(0xff, 0xff, 0xff, bAlpha);

            //
            // Setup the SRC info
            //
            V[0].tu = (float)rcSrc.left * fTexWidRatio;
            V[0].tv = (float)rcSrc.top * fTexHgtRatio;

            V[1].tu = (float)rcSrc.right * fTexWidRatio;
            V[1].tv = (float)rcSrc.top * fTexHgtRatio;

            V[2].tu = (float)rcSrc.left * fTexWidRatio;
            V[2].tv = (float)rcSrc.bottom * fTexHgtRatio;

            V[3].tu = (float)rcSrc.right * fTexWidRatio;
            V[3].tv = (float)rcSrc.bottom * fTexHgtRatio;

            CHECK_HR( hr = pD3DDevice->DrawPrimitive(D3DPT_TRIANGLESTRIP,
                                                     D3DFVF_XYZRHW |
                                                     D3DFVF_DIFFUSE |
                                                     D3DFVF_TEX1,
                                                     V, 4, D3DDP_WAIT) );
        }

        CHECK_HR( hr = pD3DDevice->EndScene( ) );
        bInScene = false;
        CHECK_HR( hr = pD3DDevice->SetTexture( 0, NULL ) );
    }
    __finally
    {
        if ( bInScene )
            pD3DDevice->EndScene( );
    }
    return hr;
}

/*****************************Private*Routine******************************\
* ApplyInBandMTChanges
*
* only selected parts of the media type are allowed to change whilst the
* graph is streaming.  We make sure that only those parts are passed on
* to the compositor.
*
* History:
* Thu 04/12/2001 - StEstrop - Created
*
\**************************************************************************/
BOOL
ApplyInBandMTChanges(
    AM_MEDIA_TYPE* pmtDst,
    AM_MEDIA_TYPE* pmtSrc
    )
{
    // the only parts of the media type that can change in band are
    // certain fields in the format block.

    if (pmtSrc->formattype == FORMAT_VideoInfo) {
        ASSERT(pmtDst->formattype == FORMAT_VideoInfo);

        VIDEOINFOHEADER* lpviSrc = (VIDEOINFOHEADER*)pmtSrc->pbFormat;
        VIDEOINFOHEADER* lpviDst = (VIDEOINFOHEADER*)pmtDst->pbFormat;
        DWORD dwCompareSize = FIELD_OFFSET(VIDEOINFOHEADER, bmiHeader);
        if (memcmp(lpviDst, lpviSrc, dwCompareSize) != 0) {
            CopyMemory(lpviDst, lpviSrc, dwCompareSize);
            return TRUE;
        }
    }
    else if (pmtSrc->formattype == FORMAT_VideoInfo2) {
        ASSERT(pmtDst->formattype == FORMAT_VideoInfo2);

        VIDEOINFOHEADER2* lpviSrc = (VIDEOINFOHEADER2*)pmtSrc->pbFormat;
        VIDEOINFOHEADER2* lpviDst = (VIDEOINFOHEADER2*)pmtDst->pbFormat;
        DWORD dwCompareSize = FIELD_OFFSET(VIDEOINFOHEADER2, bmiHeader);
        if (memcmp(lpviDst, lpviSrc, dwCompareSize) != 0) {
            CopyMemory(lpviDst, lpviSrc, dwCompareSize);
            return TRUE;
        }
    }

    return FALSE;
}

/*****************************Private*Routine******************************\
* MixerThread()
*
*
*
* History:
* Fri 03/17/2000 - StEstrop - Created
*
\**************************************************************************/
DWORD
CVideoMixer::MixerThread()
{

    AMTRACE((TEXT("CVideoMixer::MixerThread")));
    HANDLE hActiveStreams[MAX_MIXER_STREAMS];
    DWORD i;
    REFERENCE_TIME rtStartTime = 0;

    for (i = 0; i < m_dwNumStreams; i++) {
        hActiveStreams[i] = m_ppMixerStreams[i]->GetActiveHandle();
    }

    for (; ; ) {

        IMediaSample* lpSample[MAX_MIXER_STREAMS];
        DWORD dwActiveStreamIDs[MAX_MIXER_STREAMS];
        LPDIRECTDRAWSURFACE7 lpSurfSamp[MAX_MIXER_STREAMS];
        REFERENCE_TIME rtEnd[MAX_MIXER_STREAMS];
        LPBITMAPINFOHEADER* lpBmi[MAX_MIXER_STREAMS];
        bool bActualSampleEnd[MAX_MIXER_STREAMS];

        ZeroMemory(lpSurfSamp, sizeof(lpSurfSamp));

        //
        // try to get a sample from each active stream
        //

        HRESULT hr = E_FAIL;
        BOOL fTimeValid = FALSE;

        DWORD nActiveStreams = 0;
        REFERENCE_TIME rtNextEndTime = MAX_REFERENCE_TIME;

        DbgLog((LOG_TRACE, 2, TEXT("\n+++ New Frame +++"),
                nActiveStreams, rtEnd[nActiveStreams]));

        BOOL fFirstStreamInterlaced = FALSE;

        for (i = 0; i < m_dwNumStreams; i++) {

            IMediaSample* lp = m_ppMixerStreams[i]->GetNextStreamSample();

            if (lp) {

                // if (nActiveStreams == 0) {
                //     m_dwTypeSpecificFlags =
                //         ((CVMRMediaSample*)lp)->GetTypeSpecificFlags();
                // }

                lpSample[nActiveStreams] = lp;
                DbgLog((LOG_TRACE, 2, TEXT("Getting Surf from stream %d"), i));
                hr = ((CVMRMediaSample*)lp)->GetSurface( &lpSurfSamp[nActiveStreams] );

                REFERENCE_TIME rtStart;
                hr = lpSample[nActiveStreams]->GetTime(&rtStart,
                                                       &rtEnd[nActiveStreams]);
                bActualSampleEnd[nActiveStreams] = true;

                if (hr == S_OK || hr == VFW_S_NO_STOP_TIME) {

                    DbgLog((LOG_TRACE, 2, TEXT("ET for Stream %d = %I64d"),
                            i, rtEnd[nActiveStreams]));

                    if (rtStart >= 0 && rtEnd[nActiveStreams] > 0) {

                        fTimeValid = TRUE;

                        if (m_ppMixerStreams[i]->IsStreamTwoInterlacedFields() &&
                            m_ppMixerStreams[i]->CanBeDeinterlaced()) {

                            fFirstStreamInterlaced = (nActiveStreams == 0);

                            REFERENCE_TIME rtMid =
                                (rtStart + rtEnd[nActiveStreams]) / 2;

                            // do we need to display the second field?
                            if (rtStartTime < rtMid) {

                                rtEnd[nActiveStreams] = rtMid;
                                bActualSampleEnd[nActiveStreams] = false;
                            }
                        }
                    }
                    else {

                        DbgLog((LOG_ERROR, 0,
                                TEXT("Negative start or end time for Stream %d"), i));

                        rtStart = 0;
                        rtEnd[nActiveStreams] = 0;
                    }
                }
                else {
                    DbgLog((LOG_ERROR, 1,
                            TEXT("Failed to get sample time for Stream %d\n")
                            TEXT("Are you sure this is a live stream?"), i));

                    hr = S_OK;
                    if (fFirstStreamInterlaced) {
                        rtEnd[nActiveStreams] = rtEnd[0];
                        bActualSampleEnd[nActiveStreams] = bActualSampleEnd[0];
                    }
                    else {
                        rtStart = 0;
                        rtEnd[nActiveStreams] = 0;
                    }
                }

                if (rtStartTime == 0) {
                    rtStartTime = rtStart;
                }

                if (rtEnd[nActiveStreams] != 0) {
                    rtNextEndTime = min(rtNextEndTime, rtEnd[nActiveStreams]);
                }

                ASSERT(m_ppMixerStreams[i]->CheckQValid());

                dwActiveStreamIDs[nActiveStreams] = i;
                nActiveStreams++;
            }
        }


        if (!fTimeValid) {
            ASSERT(rtNextEndTime == (REFERENCE_TIME)MAX_REFERENCE_TIME);
            rtNextEndTime = rtStartTime;
        }

        //
        // If none of the streams are active wait for one to become active
        // or a termination command to come in
        //
        if (nActiveStreams == 0) {

            BOOL fContinue = false;
            for (i = 0; i < m_dwNumStreams; i++) {
                if (m_ppMixerStreams[i]->CheckFlushing()) {
                    fContinue = true;
                    break;
                }
            }

            if (fContinue) {
                continue;
            }

            SetEvent(m_hMixerIdle);
            DWORD rc = MsgWaitForMultipleObjects(m_dwNumStreams,
                                                 hActiveStreams,
                                                 FALSE,
                                                 INFINITE,
                                                 QS_POSTMESSAGE );
            ResetEvent(m_hMixerIdle);

            //
            // Have we been asked to terminate ?
            //

            if (rc == (WAIT_OBJECT_0 + m_dwNumStreams)) {
                return 0;
            }

            continue;
        }

        //
        // composite the samples together
        //

        m_ObjectLock.Lock();

        //
        // fix up any media type changes
        //
        for (i = 0; i < nActiveStreams; i++) {

            CVMRMediaSample* lpVMRSample = (CVMRMediaSample*)lpSample[i];
            if (lpVMRSample->HasTypeChanged()) {

                DWORD k = dwActiveStreamIDs[i];
                AM_MEDIA_TYPE *pmt = NULL;

                if (SUCCEEDED(lpVMRSample->GetMediaType(&pmt))) {

                    DWORD dwSurfaceFlags;
                    AM_MEDIA_TYPE mt;

                    if (SUCCEEDED(m_ppMixerStreams[k]->GetStreamMediaType(
                                        &mt, &dwSurfaceFlags))) {

                        if (ApplyInBandMTChanges(&mt, pmt)) {
                            SetStreamMediaType(k, &mt, dwSurfaceFlags, NULL, NULL);
                            //if (i == 0) {
                            //    GetInterlaceFlagsFromMediaType(&mt, &m_dwInterlaceFlags);
                            //}
                        }

                        FreeMediaType(mt);
                    }

                    DeleteMediaType(pmt);
                }
            }
        }

        if (SUCCEEDED(hr)) {

            LPDIRECTDRAWSURFACE7 lpSurf = m_BufferQueue.GetNextSurface();
            if (lpSurf) {

                hr = m_pBackEndAllocator->PrepareSurface(m_dwUserID, lpSurf, 0);
                if (hr == S_OK) {

#if defined( EHOME_WMI_INSTRUMENTATION )
                    PERFLOG_STREAMTRACE(
                        1,
                        PERFINFO_STREAMTRACE_VMR_BEGIN_DEINTERLACE,
                        rtStartTime, 0, 0, 0, 0 );
#endif

                    CompositeStreams(lpSurf, m_pD3DDevice,
                                     rtStartTime, rtNextEndTime,
                                     lpSurfSamp,
                                     dwActiveStreamIDs,
                                     nActiveStreams);

                    if ( m_hbmpAppImage ) {
                        BlendAppImage(lpSurf, m_pD3DDevice);
                    }

                    DWORD_PTR dwSurf = (DWORD_PTR)lpSurf;
                    DWORD dwSampleFlags = 0;

                    if (fTimeValid)  {
                        dwSampleFlags |= VMRSample_TimeValid;
                    }

                    VMRPRESENTATIONINFO m;
                    ZeroMemory(&m, sizeof(m));

                    m.dwFlags = dwSampleFlags;
                    m.lpSurf = lpSurf;
                    m.rtStart = rtStartTime;
                    m.rtEnd = rtNextEndTime;
                    LPRECT lpTrg = GetTargetRectFromMediaType(m_pmt);
                    m.szAspectRatio.cx = WIDTH(lpTrg);
                    m.szAspectRatio.cy = HEIGHT(lpTrg);

                    //m.dwInterlaceFlags = m_dwInterlaceFlags;
                    //m.dwTypeSpecificFlags = m_dwTypeSpecificFlags;

                    m_ObjectLock.Unlock();

#if defined( EHOME_WMI_INSTRUMENTATION )
                    PERFLOG_STREAMTRACE(
                        1,
                        PERFINFO_STREAMTRACE_VMR_END_DEINTERLACE,
                        rtStartTime, 0, 0, 0, 0 );
#endif

                    hr = m_pImageSync->Receive(&m);

                    m_ObjectLock.Lock();

                    if (hr == S_FALSE) {

                        DbgLog((LOG_TRACE, 0,
                                TEXT("S_FALSE returned from SynObj::Receive")));

                        for (i = 0; i < nActiveStreams; i++) {
                            ASSERT(lpSurfSamp[i] != NULL);
                            RELEASE(lpSurfSamp[i]);
                        }
                        nActiveStreams = 0;
                    }

                    if (!m_BufferQueue.GetNextSurface()) {

                        DbgLog((LOG_TRACE, 0,
                                TEXT("Display Change during receive")));
                        //
                        // The stream queues will have already been flushed of samples
                        // and each sample released.  We reset nActiveStreams so that
                        // we don't release the samples a second time.
                        //
                        for (i = 0; i < nActiveStreams; i++) {
                            ASSERT(lpSurfSamp[i] != NULL);
                            RELEASE(lpSurfSamp[i]);
                        }
                        nActiveStreams = 0;
                    }

                    if (hr != S_OK) {

                        DbgLog((LOG_TRACE, 2, TEXT("Sample Rejected")));
                    }

                    rtStartTime = rtNextEndTime;
                }

                else if (hr == S_FALSE) {

                    DbgLog((LOG_TRACE, 0,
                            TEXT("Display Change during Render Target prepare")));

                    //
                    // The stream queues will have already been flushed of samples
                    // and each sample released.  We reset nActiveStreams so that
                    // we don't release the samples a second time.
                    //

                    ASSERT(!m_BufferQueue.GetNextSurface());
                    for (i = 0; i < nActiveStreams; i++) {

                        ASSERT(lpSample[i] != NULL);
                        ASSERT(lpSurfSamp[i] != NULL);
                        RELEASE(lpSurfSamp[i]);

                        if (m_ppMixerStreams[dwActiveStreamIDs[i]]->RemoveNextStreamSample())
                        {
                            CVMRMediaSample* lpVMRSample = (CVMRMediaSample*)lpSample[i];

                            if (lpVMRSample->IsDXVASample()) {
                                lpVMRSample->SignalReleaseSurfaceEvent();
                            }
                            else {
                                lpVMRSample->Release();
                            }
                        }

                    }
                    nActiveStreams = 0;
                }

                else {
                    DbgLog((LOG_ERROR, 1,
                            TEXT("GetNextSurface failed error =%#X"), hr));
                }

                m_BufferQueue.FreeSurface(lpSurf);
            }
            else {

                DbgLog((LOG_TRACE, 0,
                        TEXT("Display Change during stream surface prepare")));
                //
                // The stream queues will have already been flushed of samples
                // and each sample released.  We reset nActiveStreams so that
                // we don't release the samples a second time.
                //
                ASSERT(!m_BufferQueue.GetNextSurface());

                for (i = 0; i < nActiveStreams; i++) {

                    ASSERT(lpSurfSamp[i] != NULL);
                    RELEASE(lpSurfSamp[i]);
                }
                nActiveStreams = 0;
            }

            //
            // tidy up
            //
            DbgLog((LOG_TRACE, 2, TEXT("EndTime = %I64d"), rtNextEndTime));

            for (i = 0; i < nActiveStreams; i++) {

                ASSERT(lpSurfSamp[i] != NULL);
                ASSERT(lpSample[i] != NULL);

                RELEASE(lpSurfSamp[i]);

                //
                // for each stream, work out dead samples and remove them
                // from that streams mixer queue
                //

                if (bActualSampleEnd[i] && rtEnd[i] <= rtNextEndTime) {

                    DbgLog((LOG_TRACE, 2,
                            TEXT("Discarding sample from stream %d with time %I64d"),
                            dwActiveStreamIDs[i], rtNextEndTime));

                    if (m_ppMixerStreams[dwActiveStreamIDs[i]]->RemoveNextStreamSample())
                    {
                        CVMRMediaSample* lpVMRSample = (CVMRMediaSample*)lpSample[i];

                        if (lpVMRSample->IsDXVASample()) {
                            lpVMRSample->SignalReleaseSurfaceEvent();
                        }
                        else {
                            lpVMRSample->Release();
                        }
                    }
                }
            }
        }

        m_ObjectLock.Unlock();
    }
}
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\multimedia\dshow\filters\image2\inc\vmrwindow.h ===
// Copyright (c) 1994 - 1998  Microsoft Corporation.  All Rights Reserved.
// Defines a window management object, Anthony Phillips, January 1995

#ifndef __VMRWINDOW__
#define __VMRWINDOW__

#define OCR_ARROW_DEFAULT 100       // Default Windows OEM arrow cursor

// This class looks after the management of a video window. When the window
// object is first created the constructor spawns off a worker thread that
// does all the window work. The original thread waits until it is signaled
// to continue. The worker thread firstly registers the window class if it
// is not already done. Then it creates a window and sets it's size to match
// the video dimensions (the dimensions are returned through GetDefaultRect)

// Notice that the worker thread MUST be the thread that creates the window
// as it is the one who calls GetMessage. When it has done all this it will
// signal the original thread which lets it continue, this ensures a window
// is created and valid before the constructor returns. The thread's start
// address is the WindowMessageLoop function. The thread's parameter we pass
// it is the CBaseWindow this pointer for the window object that created it

#define WindowClassName TEXT("VideoRenderer")
#define VMR_ACTIVATE_WINDOW TEXT("WM_VMR_ACTIVATE_WINDOW")

// The window class name isn't used only as a class name for the base window
// classes, it is also used by the overlay selection code as a name to base
// a mutex creation on. Basicly it has a shared memory block where the next
// available overlay colour is returned from. The creation and preparation
// of the shared memory must be serialised through all ActiveMovie instances

class CVMRFilter;

class CVMRVideoWindow : public CVMRBaseControlWindow, public CVMRBaseControlVideo
{
    CVMRFilter *m_pRenderer;                // The owning renderer object
    BOOL m_bTargetSet;                      // Do we use the default rectangle
    CCritSec *m_pInterfaceLock;             // Main renderer interface lock
    HCURSOR m_hCursor;                      // Used to display a normal cursor
    VIDEOINFOHEADER *m_pFormat;             // holds our video format
    int m_FormatSize;                       // length of m_pFormat
    UINT m_VMRActivateWindow;               // Makes the window WS_EX_TOPMOST

    // Handle the drawing and repainting of the window
    BOOL RefreshImage(COLORREF WindowColour);

    // Overriden method to handle window messages
    LRESULT OnReceiveMessage(HWND hwnd,      // Window handle
                             UINT uMsg,      // Message ID
                             WPARAM wParam,  // First parameter
                             LPARAM lParam); // Other parameter

    // Window message handlers

    void OnEraseBackground();
    BOOL OnClose();
    BOOL OnPaint();
    BOOL OnSetCursor(LPARAM lParam);
    BOOL OnSize(LONG Width, LONG Height);

public:

    CVMRVideoWindow(CVMRFilter *pRenderer,     // The owning renderer
                 CCritSec *pLock,           // Object to use for lock
                 LPUNKNOWN pUnk,            // Owning object
                 HRESULT *phr);             // OLE return code

    ~CVMRVideoWindow();

    STDMETHODIMP NonDelegatingQueryInterface(REFIID riid,VOID **ppv);

    // Return the minimum and maximum ideal sizes
    STDMETHODIMP GetMinIdealImageSize(long *pWidth,long *pHeight);
    STDMETHODIMP GetMaxIdealImageSize(long *pWidth,long *pHeight);

    //  IBasicVideo2
    STDMETHODIMP GetPreferredAspectRatio(long *plAspectX, long *plAspectY);

    LPTSTR GetClassWindowStyles(DWORD *pClassStyles,        // Class styles
                                DWORD *pWindowStyles,       // Window styles
                                DWORD *pWindowStylesEx);    // Extended styles

    HRESULT PrepareWindow();
    HRESULT ActivateWindowAsync(BOOL fAvtivate);

    // These are called by the renderer control interfaces
    HRESULT SetDefaultTargetRect();
    HRESULT IsDefaultTargetRect();
    HRESULT SetTargetRect(RECT *pTargetRect);
    HRESULT GetTargetRect(RECT *pTargetRect);
    HRESULT SetDefaultSourceRect();
    HRESULT IsDefaultSourceRect();
    HRESULT SetSourceRect(RECT *pSourceRect);
    HRESULT GetSourceRect(RECT *pSourceRect);
    HRESULT OnUpdateRectangles();
    HRESULT GetStaticImage(long *pVideoSize,long *pVideoImage);
    VIDEOINFOHEADER *GetVideoFormat();
    RECT GetDefaultRect();
    void EraseVideoBackground();

#ifdef DEBUG
#define FRAME_RATE_TIMER 76872
    void StartFrameRateTimer();
#endif

    // Synchronise with decoder thread
    CCritSec *LockWindowUpdate() {
        return (&m_WindowLock);
    };
};

#endif // __WINDOW__
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\multimedia\dshow\filters\image2\mixer\mixerobj.h ===
/******************************Module*Header*******************************\
* Module Name: MixerObj.h
*
* Declaration of the CVideoMixer
*
*
* Created: Wed 02/23/2000
* Author:  Stephen Estrop [StEstrop]
*
* Copyright (c) 2000 Microsoft Corporation
\**************************************************************************/

#include "alloclib.h"
#include "VMRuuids.h"
#include "CVMRMediaSample.h"
#include "MediaSType.h"
#include "vmrp.h"
#include <d3d.h>
#include "mixerDeinterlace.h"

#ifndef MAX_MIXER_STREAMS
#define MAX_MIXER_STREAMS   16
#endif

#define MAX_REFERENCE_TIME (REFERENCE_TIME)9223372036854775807i64

/////////////////////////////////////////////////////////////////////////////
// CVMRMixerBufferQueue
//
// Simple queue of DDraw Surfaces - we get buffers from the front of the
// queue and return them to the end of the queue.  The queue itself is just
// an array of DDraw Surface pointers.  When each buffer is returned we shift
// entire array "up" one notch and then save the returned surface at the end
// of the array.
//
#if ALLOCATOR_IS_USING_DIRECTED_FLIPS
class CVMRMixerBufferQueue
{
private:
    DWORD                   m_dwAllocated;
    LPDIRECTDRAWSURFACE7    *m_lpDDSurf;

public:
    CVMRMixerBufferQueue() : m_dwAllocated(0), m_lpDDSurf(NULL)
    {};

    HRESULT InitBufferQueue(LPDIRECTDRAWSURFACE7 lpDDSurf)
    {
        ASSERT(m_lpDDSurf == NULL);
        ASSERT(m_dwAllocated == 0);

        DWORD dwBuffCount;
        DDSURFACEDESC2 ddSurfaceDesc;
        INITDDSTRUCT(ddSurfaceDesc);

        HRESULT hr = lpDDSurf->GetSurfaceDesc(&ddSurfaceDesc);
        if (FAILED(hr)) {
            return hr;
        }

        dwBuffCount = 1;
        if ((ddSurfaceDesc.dwFlags & DDSD_BACKBUFFERCOUNT) &&
            (ddSurfaceDesc.dwBackBufferCount > 0)) {

            dwBuffCount = ddSurfaceDesc.dwBackBufferCount;
        }

        //
        // allocate the new stuff
        //
        m_lpDDSurf = new LPDIRECTDRAWSURFACE7[dwBuffCount];
        if (!m_lpDDSurf) {
            return E_OUTOFMEMORY;
        }
        ZeroMemory(m_lpDDSurf, sizeof(LPDIRECTDRAWSURFACE7) * dwBuffCount);
        m_dwAllocated = dwBuffCount;


        if ((ddSurfaceDesc.dwFlags & DDSD_BACKBUFFERCOUNT) &&
            (ddSurfaceDesc.dwBackBufferCount > 0)) {

            //
            // fill in the array
            //
            ddSurfaceDesc.ddsCaps.dwCaps &= ~(DDSCAPS_FRONTBUFFER |
                                              DDSCAPS_VISIBLE);

            for (DWORD i = 0; i < dwBuffCount; i++) {

                hr = lpDDSurf->GetAttachedSurface(&ddSurfaceDesc.ddsCaps,
                                                  &m_lpDDSurf[i]);
                if (FAILED(hr)) {
                    break;
                }
                lpDDSurf = m_lpDDSurf[i];
            }
        }
        else {

            ASSERT(m_dwAllocated == 1);
            m_lpDDSurf[0] = lpDDSurf;
        }

        return hr;
    };

    void TermBufferQueue()
    {
        //
        // delete the old stuff
        //
        if (m_lpDDSurf) {

            ASSERT(m_dwAllocated > 0);
            for (DWORD i = 0; i < m_dwAllocated; i++) {
                RELEASE(m_lpDDSurf[i]);
            }
        }

        delete m_lpDDSurf;

        m_lpDDSurf = NULL;
        m_dwAllocated = 0;
    };


    LPDIRECTDRAWSURFACE7 GetNextSurface()
    {
        return m_lpDDSurf[0];
    };

    void FreeSurface(LPDIRECTDRAWSURFACE7 lpDDSurf)
    {
        if (m_lpDDSurf) {
            ASSERT(lpDDSurf == m_lpDDSurf[0]);

            if (m_dwAllocated > 1) {
                MoveMemory(&m_lpDDSurf[0], &m_lpDDSurf[1],
                           sizeof(LPDIRECTDRAWSURFACE7) * (m_dwAllocated - 1));
                m_lpDDSurf[m_dwAllocated - 1] = lpDDSurf;
            }
        }
    }
};

#else

class CVMRMixerBufferQueue
{
private:
    LPDIRECTDRAWSURFACE7    m_lpDDSurf;

public:
    CVMRMixerBufferQueue() : m_lpDDSurf(NULL)
    {};

    HRESULT InitBufferQueue(LPDIRECTDRAWSURFACE7 lpDDSurf)
    {
        DWORD dwBuffCount;
        DDSURFACEDESC2 ddSurfaceDesc;
        INITDDSTRUCT(ddSurfaceDesc);

        HRESULT hr = lpDDSurf->GetSurfaceDesc(&ddSurfaceDesc);
        if (FAILED(hr)) {
            return hr;
        }

        //
        // Overlay surfaces have these flags set, we need to remove
        // these flags prior to calling GetAttachedSurface
        //
        ddSurfaceDesc.ddsCaps.dwCaps &= ~(DDSCAPS_FRONTBUFFER |
                                          DDSCAPS_VISIBLE);

        hr = lpDDSurf->GetAttachedSurface(&ddSurfaceDesc.ddsCaps,
                                          &m_lpDDSurf);
        return hr;
    }

    LPDIRECTDRAWSURFACE7 GetNextSurface()
    {
        return m_lpDDSurf;
    }

    void FreeSurface(LPDIRECTDRAWSURFACE7 lpDDSurf)
    {
    }

    void TermBufferQueue()
    {
        //
        // Release the "attached" surface - this does not make
        // the surface go away because the front buffer still has a
        // reference on the attached surface.  Release the front buffer,
        // which is done in the allocator/presenter, releases this for real.
        //
        RELEASE(m_lpDDSurf);
    }
};

#endif


/////////////////////////////////////////////////////////////////////////////
// CVMRMixerQueue
class CVMRMixerQueue
{

private:
    HANDLE              m_hSem;     // Semaphore controlling queue "getting"
    CCritSec            m_CritSect; // Thread seriallization
    long                m_lWaiting; // Waiting for a free element

    class CSampleList;
    friend class CSampleList;

    /*  Hack to get at protected member in CVMRMediaSample */
    static CVMRMediaSample * &NextSample(CVMRMediaSample *pSample)
    {
        return pSample->m_lpMixerQueueNext;
    };

    /*  Mini list class for the free list */
    class CSampleList
    {
    public:
        CSampleList() : m_List(NULL), m_nOnList(0) {};

#ifdef DEBUG
        ~CSampleList()
        {
            ASSERT(m_nOnList == 0);
        };
#endif
        int GetCount() const;
        void AddTail(CVMRMediaSample *pSample);
        CVMRMediaSample* RemoveHead();
        CVMRMediaSample* PeekHead();

    public:
        CVMRMediaSample *m_List;
        int           m_nOnList;
    };

    CSampleList m_lFree;        // Free list

public:
    CVMRMixerQueue(HRESULT *phr);
    ~CVMRMixerQueue();
    DWORD GetSampleFromQueueNoWait(IMediaSample** lplpMediaSample);
    DWORD GetSampleFromQueueNoRemove(HANDLE hNotActive,
                                     IMediaSample** lplpMediaSample);
    BOOL  RemoveSampleFromQueue();
    DWORD PutSampleOntoQueue(IMediaSample* lpSample);

    bool CheckValid() {
        if (m_lWaiting != 0) return false;
        if (m_lFree.m_List == NULL) return false;
        if (m_lFree.m_nOnList == 0) return false;
        return true;
    }
};


/////////////////////////////////////////////////////////////////////////////
// CVideoMixerStream
class CVideoMixerStream
{
private:
    CCritSec                m_ObjectLock;  // Controls access to internals
    DWORD                   m_dwID;
    BOOL                    m_fStreamConnected;
    BOOL                    m_fActive;
    BOOL                    m_bWasActive;
    float                   m_fAlpha;
    DWORD                   m_dwZOrder;
    NORMALIZEDRECT          m_rOutputRect;
    DDCOLORKEY              m_ClrKey;
    CVMRMixerQueue          m_SampleQueue;
    AM_MEDIA_TYPE           m_mt;
    HANDLE                  m_hNotActive;
    HANDLE                  m_hActive;
    BOOL                    m_bFlushing;
    DWORD                   m_dwSurfaceFlags;

    CDeinterlaceDevice*     m_pDeinterlaceDev;
    LPDIRECTDRAWSURFACE7    m_pddsDeinterlaceDst;
    GUID                    m_DeinterlaceDevGUID;
    DXVA_DeinterlaceCaps    m_DeinterlaceCaps;
    BOOL                    m_fDeinterlaceDstTexture;
    REFERENCE_TIME          m_rtDeinterlacedFrameStart;
    REFERENCE_TIME          m_rtDeinterlacedFrameEnd;
    IMediaSample*           m_pSample;
    DWORD                   m_dwInterlaceFlags;
    RECT                    m_rcSurface;

public:
    CVideoMixerStream(DWORD dwID, HRESULT* phr);
    ~CVideoMixerStream();

    HRESULT SetStreamSample(IMediaSample* lpSample);

    IMediaSample* GetNextStreamSample() {

        AMTRACE((TEXT("CVideoMixerStream::GetNextStreamSample")));

        IMediaSample* pSample = NULL;
        {
            CAutoLock Lock(&m_ObjectLock);
            if (m_bFlushing) {

                DbgLog((LOG_TRACE, 2, TEXT("GetNextStreamSample: Flushing stream %d"), m_dwID ));

                IMediaSample* lpSampTemp;

                while (m_SampleQueue.GetSampleFromQueueNoWait(&lpSampTemp)) {

                    CVMRMediaSample* lpVMRSample = (CVMRMediaSample*)lpSampTemp;
                    m_SampleQueue.RemoveSampleFromQueue();

                    if (lpVMRSample->IsDXVASample()) {
                        lpVMRSample->SignalReleaseSurfaceEvent();
                    }
                    else {
                        lpVMRSample->Release();
                    }
                }
                m_pSample = NULL;
                return NULL;
            }
        }
        m_SampleQueue.GetSampleFromQueueNoRemove(m_hNotActive, &pSample);
        m_pSample = pSample;
        return pSample;
    }

    BOOL RemoveNextStreamSample() {
        AMTRACE((TEXT("CVideoMixerStream::RemoveNextStreamSample")));
        BOOL b = m_SampleQueue.RemoveSampleFromQueue();
        m_pSample = NULL;
        return b;
    }

    HANDLE GetActiveHandle() {
        AMTRACE((TEXT("CVideoMixerStream::GetActiveHandle")));
        return m_hActive;
    }

    bool CheckQValid() {
        AMTRACE((TEXT("CVideoMixerStream::CheckQValid")));
        return m_SampleQueue.CheckValid();
    }

    HRESULT BeginFlush();
    HRESULT EndFlush();

    bool CheckFlushing() {

        AMTRACE((TEXT("CVideoMixerStream::CheckFlushing")));
        CAutoLock Lock(&m_ObjectLock);
        if (m_bFlushing) {

            IMediaSample* lpSampTemp;
            if (m_SampleQueue.GetSampleFromQueueNoWait(&lpSampTemp)) {

                CVMRMediaSample* lpVMRSample = (CVMRMediaSample*)lpSampTemp;
                m_SampleQueue.RemoveSampleFromQueue();

                if (lpVMRSample->IsDXVASample()) {
                    lpVMRSample->SignalReleaseSurfaceEvent();
                }
                else {
                    lpVMRSample->Release();
                }
                return true;
            }
        }
        return false;
    }

    HRESULT SetStreamMediaType(AM_MEDIA_TYPE* pmt, DWORD dwSurfaceFlags );
    HRESULT GetStreamMediaType(AM_MEDIA_TYPE* pmt, DWORD* pdwSurfaceFlags = NULL);
    HRESULT SetStreamActiveState(BOOL fActive);
    HRESULT GetStreamActiveState(BOOL* lpfActive);
    HRESULT SetStreamColorKey(LPDDCOLORKEY lpClrKey);
    HRESULT GetStreamColorKey(LPDDCOLORKEY lpClrKey);
    HRESULT SetStreamColorKey(DWORD dwClr);
    HRESULT GetStreamColorKey(DWORD *lpdwClr);
    HRESULT SetStreamAlpha(float Alpha);
    HRESULT GetStreamAlpha(float* lpAlpha);
    HRESULT SetStreamZOrder(DWORD ZOrder);
    HRESULT GetStreamZOrder(DWORD* pdwZOrder);
    HRESULT SetStreamOutputRect(const NORMALIZEDRECT* pRect );
    HRESULT GetStreamOutputRect(NORMALIZEDRECT* pRect);

    BOOL    IsStreamConnected() {
        return m_fStreamConnected;
    }

    HRESULT CreateDeinterlaceDevice(LPDIRECTDRAW7 pDD, LPGUID lpGuid,
                                    DXVA_DeinterlaceCaps* pCaps, DWORD dwTexCaps);
    HRESULT DestroyDeinterlaceDevice();

    BOOL    IsStreamTwoInterlacedFields();
    BOOL    IsStreamInterlaced();
    BOOL    IsDeinterlaceDestATexture();
    BOOL    CanBeDeinterlaced();
    LPDIRECTDRAWSURFACE7 GetDeinterlaceDestSurface();

    HRESULT DeinterlaceStream(REFERENCE_TIME rtStart, LPRECT lprcDst,
                              LPDIRECTDRAWSURFACE7 pddDst, LPRECT lprcSrc,
                              BOOL fDestRGB);

    HRESULT DeinterlaceStreamWorker(REFERENCE_TIME rtStart, LPRECT lprcDst,
                                    LPDIRECTDRAWSURFACE7 pddDst,
                                    LPRECT lprcSrc, bool fUpdateTimes);
};



/////////////////////////////////////////////////////////////////////////////
// CVideoMixer
class CVideoMixer :
    public CUnknown,
    public IVMRMixerControlInternal,
    public IVMRMixerStream,
    public IVMRMixerBitmap
{
public:
    DECLARE_IUNKNOWN
    STDMETHODIMP NonDelegatingQueryInterface(REFIID, void**);
    static CUnknown *CreateInstance(LPUNKNOWN, HRESULT *);
    static void InitClass(BOOL bLoading, const CLSID *clsid);
    static DWORD WINAPI MixerThreadProc(LPVOID lpParameter);

    CVideoMixer(LPUNKNOWN pUnk, HRESULT *phr);
    virtual ~CVideoMixer();

// IVMRMixerControlInternal
public:
    STDMETHODIMP SetBackEndAllocator(IVMRSurfaceAllocator* lpAllocator,
                                     DWORD_PTR dwUserID);
    STDMETHODIMP SetBackEndImageSync(IImageSync* lpImageSync);
    STDMETHODIMP SetImageCompositor(IVMRImageCompositor* lpVMRImgCompositor);
    STDMETHODIMP SetNumberOfStreams(DWORD dwMaxStreams);
    STDMETHODIMP GetNumberOfStreams(DWORD* lpdwMaxStreams);
    STDMETHODIMP DisplayModeChanged();
    STDMETHODIMP WaitForMixerIdle(DWORD dwTimeOut);
    STDMETHODIMP SetBackgroundColor(COLORREF clr);
    STDMETHODIMP GetBackgroundColor(COLORREF* clr);
    STDMETHODIMP SetMixingPrefs(DWORD dwMixerPrefs);
    STDMETHODIMP GetMixingPrefs(DWORD* pdwMixerPrefs);

// IVMRMixerStream
public:
    STDMETHODIMP QueueStreamMediaSample(DWORD dwStreamID,
                                        IMediaSample* lpSample);

    STDMETHODIMP BeginFlush(DWORD dwStreamID);
    STDMETHODIMP EndFlush(DWORD dwStreamID);

    STDMETHODIMP SetStreamMediaType(DWORD dwStreamID, AM_MEDIA_TYPE* pmt,
                                    DWORD dwSurfFlags, LPGUID lpDeInt,
                                    DXVA_DeinterlaceCaps* lpCaps);
    STDMETHODIMP SetStreamActiveState(DWORD dwStreamID,BOOL fActive);
    STDMETHODIMP GetStreamActiveState(DWORD dwStreamID,BOOL* lpfActive);
    STDMETHODIMP SetStreamColorKey(DWORD dwStreamID, LPDDCOLORKEY lpClrKey);
    STDMETHODIMP GetStreamColorKey(DWORD dwStreamID, LPDDCOLORKEY lpClrKey);
    STDMETHODIMP SetStreamAlpha(DWORD dwStreamID,float Alpha);
    STDMETHODIMP GetStreamAlpha(DWORD dwStreamID,float* lpAlpha);
    STDMETHODIMP SetStreamZOrder(DWORD dwStreamID,DWORD Z);
    STDMETHODIMP GetStreamZOrder(DWORD dwStreamID,DWORD* pZ);
    STDMETHODIMP SetStreamOutputRect( DWORD dwStreamID,const NORMALIZEDRECT *pRect );
    STDMETHODIMP GetStreamOutputRect( DWORD dwStreamID,NORMALIZEDRECT* pRect );

// IVMRMixerBitmap
public:
    STDMETHODIMP SetAlphaBitmap( const VMRALPHABITMAP *pBmpParms );
    STDMETHODIMP UpdateAlphaBitmapParameters( PVMRALPHABITMAP pBmpParms );
    STDMETHODIMP GetAlphaBitmapParameters( PVMRALPHABITMAP pBmpParms );

    class CIIVMRImageCompositor : public IVMRImageCompositor {
    private:

            struct {
                AM_MEDIA_TYPE   mt;
                BOOL            fTexture;
            } StrmProps[MAX_MIXER_STREAMS];

            LONG            m_cRef;
            CVideoMixer*    m_pObj;

        HRESULT OptimizeBackground(
            REFERENCE_TIME rtStart,
            LPDIRECTDRAWSURFACE7 pDDSBack,
            LPRECT lpDst,
            const VMRVIDEOSTREAMINFO* ps,
            DWORD dwMappedBdrClr,
            UINT* uStart
            );

    public:

        CIIVMRImageCompositor(CVideoMixer* pObj) :
            m_cRef(0), m_pObj(pObj)
        {
            ZeroMemory(&StrmProps, sizeof(StrmProps));
        }

        ~CIIVMRImageCompositor()
        {
            for (UINT i = 0; i < MAX_MIXER_STREAMS; i++ )
            {
                FreeMediaType(StrmProps[i].mt);
            }
        }

        STDMETHODIMP_(ULONG) AddRef()
        {
            return (ULONG)++m_cRef;
        }

        STDMETHODIMP_(ULONG) Release()
        {
            return (ULONG)--m_cRef;
        }

        STDMETHODIMP QueryInterface(REFIID riid, void **ppv)
        {
            return m_pObj->QueryInterface(riid, ppv);
        }


        STDMETHODIMP InitCompositionTarget(
            IUnknown* pD3DDevice,
            LPDIRECTDRAWSURFACE7 pddsRenderTarget);

        STDMETHODIMP TermCompositionTarget(
            IUnknown* pD3DDevice,
            LPDIRECTDRAWSURFACE7 pddsRenderTarget);

        STDMETHODIMP SetStreamMediaType(
            DWORD dwStrmID,
            AM_MEDIA_TYPE *pmt,
            BOOL fTexture);

        STDMETHODIMP CompositeImage(
            IUnknown* pD3DDevice,
            LPDIRECTDRAWSURFACE7 pddsRenderTarget,
            AM_MEDIA_TYPE* pmtRenderTarget,
            REFERENCE_TIME rtStart,
            REFERENCE_TIME rtEnd,
            DWORD dwclrBkGnd,
            VMRVIDEOSTREAMINFO* pVideoStreamInfo,
            UINT cStreams
            );

        STDMETHODIMP SpecialIMC3Composite(
            LPDIRECTDRAWSURFACE7 pDDSBack,
            LPRECT lpTarget,
            VMRVIDEOSTREAMINFO* pStrmInfo,
            UINT i,
            UINT cStreams
            );
    };

private:
    friend class CIIVMRImageCompositor;
    CCritSec                m_ObjectLock;  // Controls access to internals
    DWORD_PTR               m_dwUserID;
    IVMRSurfaceAllocator*   m_pBackEndAllocator;
    IImageSync*             m_pImageSync;
    DWORD                   m_dwTextureCaps;
    LPDIRECTDRAW7           m_pDD;
    LPDIRECT3D7             m_pD3D;
    LPDIRECT3DDEVICE7       m_pD3DDevice;
    DWORD                   m_dwNumStreams;
    CVideoMixerStream**     m_ppMixerStreams;

    HANDLE                  m_hMixerIdle;
    HANDLE                  m_hThread;
    DWORD                   m_dwThreadID;
    DWORD                   m_dwCurrMonBitCount;
    DDCAPS_DX7              m_ddHWCaps;
    DWORD                   m_MixingPrefs;

    AM_MEDIA_TYPE*          m_pmt;
    CVMRMixerBufferQueue    m_BufferQueue;

    IVMRImageCompositor*    m_pImageCompositor;
    CIIVMRImageCompositor   m_ImageCompositor;

    NORMALIZEDRECT          m_rDest;
    float                   m_fAlpha;
    COLORREF                m_clrTrans;
    DWORD                   m_dwClrTransMapped;
    COLORREF                m_clrBorder;
    DWORD                   m_dwClrBorderMapped;

    // vidmem mirror of the app image
    LPDIRECTDRAWSURFACE7    m_pDDSAppImage;
    float                   m_fAppImageTexWid, m_fAppImageTexHgt;
    RECT                    m_rcAppImageSrc;

    // bitmap with system memory backup of the app image
    HBITMAP                 m_hbmpAppImage;

    // width and height of app image
    DWORD                   m_dwWidthAppImage, m_dwHeightAppImage;

    enum {APPIMG_NOIMAGE     = 0, APPIMG_DDSURFARGB32 = 1,
          APPIMG_DDSURFRGB32 = 2, APPIMG_HBITMAP      = 4};
    DWORD                   m_dwAppImageFlags;


    // local vidmem texture mirror
    LPDIRECTDRAWSURFACE7    m_pDDSTextureMirror;

    // de-interlace information
    //BOOL                    m_fOverlayRT;
    //DWORD                   m_dwInterlaceFlags;
    //DWORD                   m_dwTypeSpecificFlags;

private:
    HRESULT ValidateStream(DWORD dwStrmID) {
        if (dwStrmID >= m_dwNumStreams) {
            return E_INVALIDARG;
        }
        return S_OK;
    }
    HRESULT CreateAppImageMirror( );
    HRESULT BlendAppImage(LPDIRECTDRAWSURFACE7 pDDS, LPDIRECT3DDEVICE7 pD3DDevice);
    HRESULT CompositeStreams(LPDIRECTDRAWSURFACE7 pDDSBack, LPDIRECT3DDEVICE7 pD3DDevice,
                             REFERENCE_TIME rtStart, REFERENCE_TIME rtEnd,
                             LPDIRECTDRAWSURFACE7 *ppDDSSamples,
                             DWORD dwStrmIDs[],
                             UINT cStreams );

    HRESULT AllocateSurface(const AM_MEDIA_TYPE* pmt, DWORD* lpdwBufferCount, AM_MEDIA_TYPE** ppmt);
    void    FreeSurface();

    HRESULT AllocateTextureMirror( DWORD dwWidth, DWORD dwHeight );

    DWORD MixerThread();

    HRESULT RecomputeTargetSizeFromAllStreams(LONG* plWidth, LONG* plHeight);
};


BOOL __inline SpecialIMC3Mode(DWORD dwMixerPrefs)
{
    return (MixerPref_RenderTargetIntelIMC3 ==
                    (dwMixerPrefs & MixerPref_RenderTargetMask));
}
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\multimedia\dshow\filters\image2\mixer\mixerobj.cpp ===
/******************************Module*Header*******************************\
* Module Name: MixerObj.cpp
*
*  Implements the CVideoMixer class
*
*
* Created:
* Author:  Stephen Estrop [StEstrop]
*
* Copyright (c) 2000 Microsoft Corporation
\**************************************************************************/
#include <streams.h>
#include <windowsx.h>
#include <limits.h>

#include "vmrp.h"

#include "mixerobj.h"

// IVMRMixerControl

/******************************Public*Routine******************************\
* SetNumberOfStreams
*
*
*
* History:
* Tue 03/14/2000 - StEstrop - Created
*
\**************************************************************************/
STDMETHODIMP
CVideoMixer::SetNumberOfStreams(
    DWORD dwMaxStreams
    )
{
    AMTRACE((TEXT("CVideoMixer::SetNumberOfStreams")));
    CAutoLock Lock(&m_ObjectLock);

    HRESULT hr = S_OK;
    DWORD i;

    if ( 0 != m_dwNumStreams ) {
        DbgLog((LOG_ERROR, 1, TEXT("Mixer already configured !!")));
        return E_FAIL;
    }

    __try {

        if (dwMaxStreams > MAX_MIXER_STREAMS) {
            DbgLog((LOG_ERROR, 1, TEXT("Too many Mixer Streams !!")));
            hr = E_INVALIDARG;
            __leave;
        }

        //
        // Allocate an array of stream objects dwMaxStream big and
        // initialize each stream.
        //

        m_ppMixerStreams = new CVideoMixerStream*[dwMaxStreams];
        if (!m_ppMixerStreams) {
            hr = E_OUTOFMEMORY;
            __leave;
        }

        ZeroMemory(m_ppMixerStreams,
                   sizeof(CVideoMixerStream*) * dwMaxStreams);
        for (i = 0; i < dwMaxStreams; i++) {

            HRESULT hrMix = S_OK;
            m_ppMixerStreams[i] = new CVideoMixerStream(i, &hrMix);

            if (!m_ppMixerStreams[i]) {
                hr = E_OUTOFMEMORY;
                __leave;
            }

            if (FAILED(hrMix)) {
                hr = hrMix;
                __leave;
            }
        }

        m_dwNumStreams = dwMaxStreams;

        m_hMixerIdle = CreateEvent(NULL, TRUE, FALSE, NULL);
        if (!m_hMixerIdle) {
            DWORD dwErr = GetLastError();
            hr = HRESULT_FROM_WIN32(dwErr);
            __leave;
        }

        m_hThread = CreateThread(NULL, 0, MixerThreadProc, this, 0, &m_dwThreadID);
        if (!m_hThread) {
            DWORD dwErr = GetLastError();
            hr = HRESULT_FROM_WIN32(dwErr);
            __leave;
        }

    }
    __finally {
        if (FAILED(hr)) {
            for ( i = 0; i < 100; i++ )
            {
                if ( 0 == PostThreadMessage(m_dwThreadID, WM_USER, 0, 0) )
                    Sleep(0);
                else
                    break;
            }
            if (m_ppMixerStreams) {
                for (i = 0; i < dwMaxStreams; i++) {
                    delete m_ppMixerStreams[i];
                }
            }
            delete[] m_ppMixerStreams;
            m_ppMixerStreams = NULL;
            m_dwNumStreams = 0;
        }
    }

    return hr;
}


/******************************Public*Routine******************************\
* SetBackEndAllocator
*
*
*
* History:
* Tue 03/14/2000 - StEstrop - Created
*
\**************************************************************************/
STDMETHODIMP
CVideoMixer::SetBackEndAllocator(
    IVMRSurfaceAllocator* lpAllocator,
    DWORD_PTR dwUserID
    )
{
    AMTRACE((TEXT("CVideoMixer::SetBackEndAllocator")));
    CAutoLock Lock(&m_ObjectLock);

    RELEASE( m_pBackEndAllocator );

    if (lpAllocator) {
        lpAllocator->AddRef();
    }

    m_pBackEndAllocator = lpAllocator;
    m_dwUserID = dwUserID;


    return S_OK;
}

/******************************Public*Routine******************************\
* SetBackEndImageSync
*
*
*
* History:
* Tue 03/14/2000 - StEstrop - Created
*
\**************************************************************************/
STDMETHODIMP
CVideoMixer::SetBackEndImageSync(
    IImageSync* lpImageSync
    )
{
    AMTRACE((TEXT("CVideoMixer::SetBackEndImageSync")));
    CAutoLock Lock(&m_ObjectLock);

    RELEASE( m_pImageSync);

    if (lpImageSync) {
        lpImageSync->AddRef();
    }

    m_pImageSync = lpImageSync;


    return S_OK;
}

/******************************Public*Routine******************************\
* SetImageCompositor
*
*
*
* History:
* Tue 03/14/2000 - StEstrop - Created
*
\**************************************************************************/
STDMETHODIMP
CVideoMixer::SetImageCompositor(
    IVMRImageCompositor* lpImageComp
    )
{
    AMTRACE((TEXT("CVideoMixer::SetImageCompositor")));
    CAutoLock Lock(&m_ObjectLock);

    //
    // Can't plug in new compositors when in IMC3 mode.
    //
    if (SpecialIMC3Mode(m_MixingPrefs)) {
        DbgLog((LOG_ERROR, 1, TEXT("Can't plug in compositors in this mode")));
        return E_FAIL;
    }


    //
    // must always specify a valid compositor
    //
    if (lpImageComp == NULL) {
        return E_POINTER;
    }

    RELEASE(m_pImageCompositor);

    if (lpImageComp) {
        lpImageComp->AddRef();
    }

    m_pImageCompositor = lpImageComp;


    return S_OK;
}

/******************************Public*Routine******************************\
* GetNumberOfStreams
*
*
*
* History:
* Tue 03/14/2000 - StEstrop - Created
*
\**************************************************************************/
STDMETHODIMP
CVideoMixer::GetNumberOfStreams(
    DWORD* lpdwMaxStreams
    )
{
    AMTRACE((TEXT("CVideoMixer::GetNumberOfStreams")));
    CAutoLock Lock(&m_ObjectLock);

    if (!lpdwMaxStreams) {
        return E_POINTER;
    }

    *lpdwMaxStreams = m_dwNumStreams;
    return S_OK;
}

/******************************Public*Routine******************************\
* DisplayModeChanged
*
*
*
* History:
* Tue 04/25/2000 - StEstrop - Created
*
\**************************************************************************/
STDMETHODIMP
CVideoMixer::DisplayModeChanged()
{
    AMTRACE((TEXT("CVideoMixer::DisplayModeChanged")));
    CAutoLock Lock(&m_ObjectLock);

    FreeSurface();

    for (DWORD i = 0; i < m_dwNumStreams; i++) {

        m_ppMixerStreams[i]->BeginFlush();
        m_ppMixerStreams[i]->GetNextStreamSample();
        m_ppMixerStreams[i]->EndFlush();
    }


    return S_OK;
}

/******************************Public*Routine******************************\
* WaitForMixerIdle
*
*
*
* History:
* Tue 09/19/2000 - StEstrop - Created
*
\**************************************************************************/
STDMETHODIMP
CVideoMixer::WaitForMixerIdle(DWORD dwTimeOut)
{
    AMTRACE((TEXT("CVideoMixer::WaitForMixerIdle")));

    DWORD rc = WaitForSingleObject(m_hMixerIdle, dwTimeOut);

    if (rc == WAIT_OBJECT_0) {
        return S_OK;
    }

    if (rc == WAIT_TIMEOUT) {
        return S_FALSE;
    }

    DWORD dwErr = GetLastError();
    return HRESULT_FROM_WIN32(dwErr);
}



// IVMRMixerStream

/******************************Public*Routine******************************\
* SetStreamSample
*
*
*
* History:
* Tue 03/14/2000 - StEstrop - Created
*
\**************************************************************************/
STDMETHODIMP
CVideoMixer::QueueStreamMediaSample(
    DWORD dwStreamID,
    IMediaSample* lpSample
    )
{
    AMTRACE((TEXT("CVideoMixer::QueueStreamMediaSample")));
    CAutoLock Lock(&m_ObjectLock);
    DbgLog((LOG_TRACE, 2, TEXT("lpSample= %#X"), lpSample));

    HRESULT hr = ValidateStream(dwStreamID);
    if (SUCCEEDED(hr)) {
        hr = m_ppMixerStreams[dwStreamID]->SetStreamSample(lpSample);
    }
    return hr;
}


/*****************************Private*Routine******************************\
* AspectRatioAdjustMediaType
*
*
*
* History:
* Mon 03/27/2000 - StEstrop - Created
*
\**************************************************************************/
HRESULT
AspectRatioAdjustMediaType(
    CMediaType* pmt
    )
{
    AMTRACE((TEXT("AspectRatioAdjustMediaType")));
    HRESULT hr = S_OK;
    long lX, lY;

    FixupMediaType(pmt);
    hr = GetImageAspectRatio(pmt, &lX, &lY);

    if (SUCCEEDED(hr)) {

        lX *= 1000;
        lY *= 1000;

        LPRECT lprc = GetTargetRectFromMediaType(pmt);
        LPBITMAPINFOHEADER lpHeader = GetbmiHeader(pmt);

        if (lprc && lpHeader) {

            long Width;
            long Height;
            if (IsRectEmpty(lprc)) {
                Width  = abs(lpHeader->biWidth);
                Height = abs(lpHeader->biHeight);
            }
            else {
                Width  = WIDTH(lprc);
                Height = HEIGHT(lprc);
            }

            long lCalcX = MulDiv(Width, lY, Height);

            lpHeader->biHeight = Height;
            lpHeader->biWidth = Width;

            if (lCalcX != lX) {

                lpHeader->biWidth = MulDiv(Height, lX, lY);

            }

            lprc->left = 0;
            lprc->top = 0;
            lprc->right = abs(lpHeader->biWidth);
            lprc->bottom = abs(lpHeader->biHeight);
        }
        else {
            hr = E_INVALIDARG;
        }
    }

    return hr;
}

/*****************************Private*Routine******************************\
* DecimateMediaType
*
*
*
* History:
* Thu 03/01/2001 - StEstrop - Created
*
\**************************************************************************/
HRESULT
DecimateMediaType(
    CMediaType* pmt
    )
{
    LPRECT lprcD = GetTargetRectFromMediaType(pmt);
    LPRECT lprcS = GetSourceRectFromMediaType(pmt);
    LPBITMAPINFOHEADER lpHdr = GetbmiHeader(pmt);

    if (lprcD && lprcS && lpHdr) {

        lprcD->left     /= 2;
        lprcD->top      /= 2;
        lprcD->right    /= 2;
        lprcD->bottom   /= 2;

        lprcS->left     /= 2;
        lprcS->top      /= 2;
        lprcS->right    /= 2;
        lprcS->bottom   /= 2;

        lpHdr->biWidth  /= 2;
        lpHdr->biHeight /= 2;
    }

    return S_OK;
}


/*****************************Private*Routine******************************\
* AllocateSurface
*
*
*
* History:
* Wed 05/24/2000 - StEstrop - Created
*
\**************************************************************************/
HRESULT
CVideoMixer::AllocateSurface(
    const AM_MEDIA_TYPE* pmt,
    DWORD* lpdwBufferCount,
    AM_MEDIA_TYPE** ppmt
    )
{
    AMTRACE((TEXT("CVideoMixer::AllocateSurface")));

    SIZE AR;
    LPDIRECTDRAWSURFACE7 lpSurface7;
    LPBITMAPINFOHEADER lpHdr = GetbmiHeader(pmt);
    HRESULT hr = S_OK;

    if( !lpHdr ) {
        return E_POINTER;
    }
    __try {

        ASSERT(m_pDD == NULL);
        ASSERT(m_pD3D == NULL);
        ASSERT(m_pD3DDevice == NULL);


        VMRALLOCATIONINFO p;
        CHECK_HR(hr = GetImageAspectRatio(pmt,
                                          &p.szAspectRatio.cx,
                                          &p.szAspectRatio.cy));
        p.dwFlags = AMAP_3D_TARGET;
        p.lpHdr = lpHdr;
        p.lpPixFmt = NULL;
        p.dwMinBuffers = 1;
        p.dwMaxBuffers = 1;
        //p.dwInterlaceFlags = m_dwInterlaceFlags;
        p.dwInterlaceFlags = 0;

        if (m_MixingPrefs & MixerPref_DecimateOutput) {
            p.szNativeSize.cx = 2 * lpHdr->biWidth;
            p.szNativeSize.cy = 2 * lpHdr->biHeight;
        }
        else {
            p.szNativeSize.cx = lpHdr->biWidth;
            p.szNativeSize.cy = lpHdr->biHeight;
        }

        if ((m_MixingPrefs & MixerPref_RenderTargetMask) ==
			 MixerPref_RenderTargetRGB) {

            // We try the current monitor format.

            lpHdr->biBitCount = 0;
            lpHdr->biCompression = BI_RGB;

            CHECK_HR(hr = m_pBackEndAllocator->AllocateSurface(
                                m_dwUserID, &p,
                                lpdwBufferCount,
                                &lpSurface7));
        }
        else if (SpecialIMC3Mode(m_MixingPrefs)) {

            // Try 'IMC3'

            lpHdr->biBitCount = 12;
            DbgLog((LOG_TRACE, 0, TEXT("VMR Mixer trying 'IMC3' render target")));
            lpHdr->biCompression = MAKEFOURCC('I','M','C','3');
            hr = m_pBackEndAllocator->AllocateSurface(m_dwUserID, &p,
                                                      lpdwBufferCount,
                                                      &lpSurface7);
        }
        else if ((m_MixingPrefs & MixerPref_RenderTargetMask) ==
                  MixerPref_RenderTargetYUV420) {

            // We try 'YV12' followed by 'NV12'

            lpHdr->biBitCount = 12;
            DbgLog((LOG_TRACE, 0, TEXT("VMR Mixer trying 'NV12' render target")));
            lpHdr->biCompression = MAKEFOURCC('N','V','1','2');
            hr = m_pBackEndAllocator->AllocateSurface(
                                m_dwUserID, &p,
                                lpdwBufferCount,
                                &lpSurface7);

            if (FAILED(hr)) {
                DbgLog((LOG_TRACE, 0, TEXT("VMR Mixer trying 'YV12' render target")));
                lpHdr->biCompression = MAKEFOURCC('Y','V','1','2');
                hr = m_pBackEndAllocator->AllocateSurface(
                                    m_dwUserID, &p,
                                    lpdwBufferCount,
                                    &lpSurface7);
            }

            if (FAILED(hr)) {
                DbgLog((LOG_ERROR, 1, TEXT("YUV 4:2:0 surface allocation failed")));
                __leave;
            }

        }
        else if ((m_MixingPrefs & MixerPref_RenderTargetMask) ==
                  MixerPref_RenderTargetYUV422) {

            // We try 'YUY2' followed by 'UYVY'

            lpHdr->biBitCount = 16;
            lpHdr->biCompression = MAKEFOURCC('Y','U','Y','2');

            hr = m_pBackEndAllocator->AllocateSurface(
                                m_dwUserID, &p,
                                lpdwBufferCount,
                                &lpSurface7);
            if (FAILED(hr)) {
                lpHdr->biCompression = MAKEFOURCC('U','Y','V','Y');
                CHECK_HR(hr = m_pBackEndAllocator->AllocateSurface(
                                    m_dwUserID, &p,
                                    lpdwBufferCount,
                                    &lpSurface7));
            }
        }
        else if ((m_MixingPrefs & MixerPref_RenderTargetMask) ==
                  MixerPref_RenderTargetYUV444) {

            lpHdr->biBitCount = 32;
            lpHdr->biCompression = MAKEFOURCC('A','Y','U','V');

            CHECK_HR(hr = m_pBackEndAllocator->AllocateSurface(
                                m_dwUserID, &p,
                                lpdwBufferCount,
                                &lpSurface7));
        }
        else {
            ASSERT(!"Invalid Render Target format specified");
        }




        DDSURFACEDESC2 ddSurfaceDesc;
        INITDDSTRUCT(ddSurfaceDesc);
        CHECK_HR(hr = lpSurface7->GetSurfaceDesc(&ddSurfaceDesc));
        //m_fOverlayRT = !!(ddSurfaceDesc.ddsCaps.dwCaps & DDSCAPS_OVERLAY);

        CHECK_HR(hr = ConvertSurfaceDescToMediaType(&ddSurfaceDesc, pmt, ppmt));

        CHECK_HR(hr = m_BufferQueue.InitBufferQueue(lpSurface7));

        CHECK_HR(hr = lpSurface7->GetDDInterface((LPVOID *)&m_pDD));

        INITDDSTRUCT(m_ddHWCaps);
        CHECK_HR(hr = m_pDD->GetCaps((LPDDCAPS)&m_ddHWCaps, NULL));

        CHECK_HR(hr = GetTextureCaps(m_pDD, &m_dwTextureCaps));

        //
        // No 3D stuff required when in IMC3 mode
        //
        if (!SpecialIMC3Mode(m_MixingPrefs)) {

            CHECK_HR(hr = m_pDD->QueryInterface(IID_IDirect3D7, (LPVOID *)&m_pD3D));
            CHECK_HR(hr = m_pD3D->CreateDevice(IID_IDirect3DHALDevice,
                                               m_BufferQueue.GetNextSurface(),
                                               &m_pD3DDevice));

            CHECK_HR(hr = m_pImageCompositor->InitCompositionTarget(
                                    m_pD3DDevice,
                                    m_BufferQueue.GetNextSurface()));
        }
    }
    __finally {

        if (FAILED(hr)) {
            FreeSurface();
        }
    }

    return hr;
}


/*****************************Private*Routine******************************\
* FreeSurface
*
*
*
* History:
* Wed 05/24/2000 - StEstrop - Created
*
\**************************************************************************/
void
CVideoMixer::FreeSurface(
    )
{
    AMTRACE((TEXT("CVideoMixer::FreeSurface")));


    if (!SpecialIMC3Mode(m_MixingPrefs)) {
        m_pImageCompositor->TermCompositionTarget(
                                 m_pD3DDevice,
                                 m_BufferQueue.GetNextSurface());
    }

    RELEASE(m_pDDSAppImage);
    RELEASE(m_pDDSTextureMirror);

    RELEASE(m_pD3DDevice);
    RELEASE(m_pD3D);
    RELEASE(m_pDD);

    if (m_pBackEndAllocator) {
        m_BufferQueue.TermBufferQueue();
        m_pBackEndAllocator->FreeSurface(m_dwUserID);
    }

    if (m_pmt) {
        DeleteMediaType(m_pmt);
        m_pmt = NULL;
    }
}


HRESULT
CVideoMixer::RecomputeTargetSizeFromAllStreams(
    LONG* plWidth,
    LONG* plHeight
    )
{
    *plWidth = 0;
    *plHeight = 0;

    CMediaType cmt;
    HRESULT hr = S_OK;
    DWORD dwInterlaceFlags = 0;

    for( DWORD j =0; j < m_dwNumStreams; j++ ) {

        hr = m_ppMixerStreams[j]->GetStreamMediaType(&cmt);
        if( FAILED(hr)) {
            FreeMediaType( cmt );
            break;
        }

        //
        // Are we decimating the output ?
        //
        if (m_MixingPrefs & MixerPref_DecimateOutput) {
            DecimateMediaType(&cmt);
        }

        //hr = GetInterlaceFlagsFromMediaType(&cmt, &dwInterlaceFlags);
        //if (SUCCEEDED(hr) && dwInterlaceFlags) {
        //    m_dwInterlaceFlags = dwInterlaceFlags;
        //}

        hr = AspectRatioAdjustMediaType(&cmt);
        if (SUCCEEDED(hr)) {
            LPRECT lprc = GetTargetRectFromMediaType(&cmt);
            *plWidth = max(*plWidth, WIDTH(lprc));
            *plHeight = max(*plHeight, HEIGHT(lprc));
        }
        FreeMediaType( cmt );
    }
    return hr;
}


/*****************************Private*Routine******************************\
* ValidateSpecialCase
*
*
*
* History:
* Thu 06/07/2001 - StEstrop - Created
*
\**************************************************************************/
HRESULT
ValidateSpecialCase(
    AM_MEDIA_TYPE* pmt,
    DWORD dwMixingPrefs,
    DWORD dwSurfFlags
    )
{
    if (SpecialIMC3Mode(dwMixingPrefs)) {

        LPBITMAPINFOHEADER lpHdr = GetbmiHeader(pmt);
        if (lpHdr->biCompression != '3CMI' &&
            lpHdr->biCompression != '44AI' &&
            lpHdr->biCompression != '44IA') {

            DbgLog((LOG_ERROR, 1,
                    TEXT("We only allow IMC3, AI44 and ")
                    TEXT("IA44 connections in this mode")));
            return  E_FAIL;
        }
    }
    else {

        //
        // We are not in IMC3 mixing mode - in this case we can only
        // blend IA44 and AI44 surfaces if they are textures.
        //

        LPBITMAPINFOHEADER lpHdr = GetbmiHeader(pmt);
        if (lpHdr->biCompression == '44AI' ||
            lpHdr->biCompression == '44IA') {

            if (!(dwSurfFlags & VMR_SF_TEXTURE)) {

                DbgLog((LOG_ERROR, 1,
                        TEXT("We only allow IMC3, AI44 and ")
                        TEXT("IA44 connections in this mode")));
                return E_FAIL;
            }
        }
    }

    return S_OK;
}


/******************************Public*Routine******************************\
* SetStreamMediaType
*
*
*
* History:
* Tue 03/14/2000 - StEstrop - Created
*
\**************************************************************************/
STDMETHODIMP
CVideoMixer::SetStreamMediaType(
    DWORD dwStreamID,
    AM_MEDIA_TYPE* pmt,
    DWORD dwSurfFlags,
    LPGUID lpDeint,
    DXVA_DeinterlaceCaps* lpCaps
    )
{
    AMTRACE((TEXT("CVideoMixer::SetStreamMediaType")));
    CAutoLock Lock(&m_ObjectLock);
    HRESULT hr = S_OK;

    DbgLog((LOG_TRACE, 1, TEXT("SetStreamMediaType called for stream %d"),
            dwStreamID ));

    if (FAILED(hr = ValidateStream(dwStreamID)))
        return hr;

    if (FAILED(hr = m_ppMixerStreams[dwStreamID]->SetStreamMediaType(pmt, dwSurfFlags )))
        return hr;

    if (pmt == NULL) {

        if (!SpecialIMC3Mode(m_MixingPrefs)) {
            m_ppMixerStreams[dwStreamID]->DestroyDeinterlaceDevice();
        }

        hr = m_pImageCompositor->SetStreamMediaType(dwStreamID, pmt, !!dwSurfFlags);

        //
        // check to see if there are any remaining streams connected,
        // if not free our D3D resources.
        //
        DWORD i;
        for (i = 0; i < m_dwNumStreams; i++) {
            if (m_ppMixerStreams[i]->IsStreamConnected()) {
                break;
            }
        }

        if (i == m_dwNumStreams) {
            DbgLog((LOG_TRACE, 1,
                    TEXT("No more streams connected, FreeSurface called")));
            FreeSurface();
        }
        return hr;
    }

    //
    // If we are in the special IMC3 mixing mode, only allow IMC3, AI44 and IA44
    // media types.  We can't blend anything else.
    //

    if (FAILED(hr = ValidateSpecialCase(pmt, m_MixingPrefs, dwSurfFlags))) {
        return hr;
    }

    __try {

        bool fTextureMirrorWasPresent = false;
        DWORD dwBuffers = 1;
        CMediaType cmt(*pmt);
        cmt.SetSubtype(&MEDIASUBTYPE_SameAsMonitor);

        CHECK_HR(hr = AspectRatioAdjustMediaType(&cmt));

        if (m_MixingPrefs & MixerPref_DecimateOutput) {
            DecimateMediaType(&cmt);
        }

        if (m_pmt == NULL) {

#ifdef DEBUG
            {
                LPBITMAPINFOHEADER lpHdr = GetbmiHeader(&cmt);
                DbgLog((LOG_TRACE, 1, TEXT("Allocating first back end surface %dx%d"),
                        lpHdr->biWidth, lpHdr->biHeight));
            }
#endif

            //GetInterlaceFlagsFromMediaType(&cmt, &m_dwInterlaceFlags);
            CHECK_HR(hr = AllocateSurface(&cmt, &dwBuffers, &m_pmt));
        }
        else {

            DbgLog((LOG_TRACE, 1, TEXT("Backend Surf already allocated") ));

            RECT rcOldTrg = *GetTargetRectFromMediaType(m_pmt);
            LPBITMAPINFOHEADER lpNew = GetbmiHeader(&cmt);

            // Get the size of the old render target
            LONG lOldWidth = WIDTH(&rcOldTrg);
            LONG lOldHeight = HEIGHT(&rcOldTrg);

            //
            // Recompute to determine the new target size from all the
            // connected streams
            //

            LONG lNewWidth, lNewHeight;
            RecomputeTargetSizeFromAllStreams(&lNewWidth, &lNewHeight);

            //
            // Has the render target changed size ?
            //
            if (lNewWidth != lOldWidth || lNewHeight != lOldHeight)
            {
                lpNew->biWidth = lNewWidth;
                lpNew->biHeight = lNewHeight;

                DbgLog((LOG_TRACE, 1, TEXT("Re-allocating backend surf %dx%d"),
                        lNewWidth, lNewHeight));

                fTextureMirrorWasPresent = (NULL != m_pDDSTextureMirror);
                FreeSurface();
                CHECK_HR(hr = AllocateSurface(&cmt, &dwBuffers, &m_pmt));

                LPRECT lpTarget = GetTargetRectFromMediaType(m_pmt);
                lpTarget->right =  lNewWidth;
                lpTarget->bottom = lNewHeight;
            }
        }


        if (fTextureMirrorWasPresent || !(dwSurfFlags & VMR_SF_TEXTURE)) {

            if (!SpecialIMC3Mode(m_MixingPrefs)) {

                LPBITMAPINFOHEADER lpbi = GetbmiHeader(pmt);
                CHECK_HR(hr = AllocateTextureMirror(abs(lpbi->biWidth),
                                                    abs(lpbi->biHeight)));
            }
        }


        if (!SpecialIMC3Mode(m_MixingPrefs) && lpDeint && lpCaps) {

            CHECK_HR(hr = m_ppMixerStreams[dwStreamID]->CreateDeinterlaceDevice(
                            m_pDD, lpDeint, lpCaps, m_dwTextureCaps));
        }

    }
    __finally {

        //
        // If everything succeeded inform the compositor
        //
        if (SUCCEEDED(hr)) {

            hr = m_pImageCompositor->SetStreamMediaType(dwStreamID,pmt,
                                                        !!dwSurfFlags);
        }

        if (FAILED(hr)) {
            // total failure, free everything
            FreeSurface();
        }
    }

    return hr;
}


/******************************Public*Routine******************************\
* BeginFlush
*
*
*
* History:
* Tue 03/28/2000 - StEstrop - Created
*
\**************************************************************************/
STDMETHODIMP
CVideoMixer::BeginFlush(
    DWORD dwStreamID
    )
{
    AMTRACE((TEXT("CVideoMixer::BeginFlush")));
    CAutoLock Lock(&m_ObjectLock);
    HRESULT hr = ValidateStream(dwStreamID);
    if (SUCCEEDED(hr)) {
        hr = m_ppMixerStreams[dwStreamID]->BeginFlush();
    }
    return hr;
}


/******************************Public*Routine******************************\
* EndFlush
*
*
*
* History:
* Tue 03/28/2000 - StEstrop - Created
*
\**************************************************************************/
STDMETHODIMP
CVideoMixer::EndFlush(
    DWORD dwStreamID
    )
{
    AMTRACE((TEXT("CVideoMixer::EndFlush")));
    CAutoLock Lock(&m_ObjectLock);
    HRESULT hr = ValidateStream(dwStreamID);
    if (SUCCEEDED(hr)) {
        hr = m_ppMixerStreams[dwStreamID]->EndFlush();
    }
    return hr;
}



/******************************Public*Routine******************************\
* SetStreamActiveState
*
*
*
* History:
* Tue 03/28/2000 - StEstrop - Created
*
\**************************************************************************/
STDMETHODIMP
CVideoMixer::SetStreamActiveState(
    DWORD dwStreamID,
    BOOL fActive
    )
{
    AMTRACE((TEXT("CVideoMixer::SetStreamActiveState")));
    CAutoLock Lock(&m_ObjectLock);
    HRESULT hr = ValidateStream(dwStreamID);
    if (SUCCEEDED(hr)) {
        hr = m_ppMixerStreams[dwStreamID]->SetStreamActiveState(fActive);
    }
    return hr;
}

/******************************Public*Routine******************************\
* GetStreamActiveState
*
*
*
* History:
* Tue 03/28/2000 - StEstrop - Created
*
\**************************************************************************/
STDMETHODIMP
CVideoMixer::GetStreamActiveState(
    DWORD dwStreamID,
    BOOL* lpfActive
    )
{
    AMTRACE((TEXT("CVideoMixer::GetStreamActiveState")));
    CAutoLock Lock(&m_ObjectLock);
    HRESULT hr = ValidateStream(dwStreamID);
    if (SUCCEEDED(hr)) {
        hr = m_ppMixerStreams[dwStreamID]->GetStreamActiveState(lpfActive);
    }
    return hr;
}

/******************************Public*Routine******************************\
* SetStreamColorKey
*
*
*
* History:
* Tue 03/28/2000 - StEstrop - Created
*
\**************************************************************************/
STDMETHODIMP
CVideoMixer::SetStreamColorKey(
    DWORD dwStreamID,
    LPDDCOLORKEY Clr
    )
{
    AMTRACE((TEXT("CVideoMixer::SetStreamColorKey")));
    CAutoLock Lock(&m_ObjectLock);

    HRESULT hr = ValidateStream(dwStreamID);
    if (SUCCEEDED(hr)) {

        //
        // Add more parameter validation here - clr keying and
        // embedded alpha are not allowed together.
        //
        // Need to check that the h/w actually supports clr keying
        // of textures.
        //
        // 0xFFFFFFFF turns clr keying off.  All other values
        // should be in the range 0 to 0x00FFFFFF
        //

        hr = m_ppMixerStreams[dwStreamID]->SetStreamColorKey(Clr);
    }
    return hr;
}

/******************************Public*Routine******************************\
* GetStreamColorKey
*
*
*
* History:
* Tue 03/28/2000 - StEstrop - Created
*
\**************************************************************************/
STDMETHODIMP
CVideoMixer::GetStreamColorKey(
    DWORD dwStreamID,
    LPDDCOLORKEY lpClr
    )
{
    AMTRACE((TEXT("CVideoMixer::GetStreamColorKey")));
    CAutoLock Lock(&m_ObjectLock);

    if (ISBADWRITEPTR( lpClr ) )
    {
        DbgLog((LOG_ERROR, 1, TEXT("GetStreamColorKey: NULL Clr ptr !!")));
        return E_POINTER;
    }

    HRESULT hr = ValidateStream(dwStreamID);
    if (SUCCEEDED(hr)) {
        hr = m_ppMixerStreams[dwStreamID]->GetStreamColorKey(lpClr);
    }
    return hr;
}

/******************************Public*Routine******************************\
* SetStreamAlpha
*
*
*
* History:
* Tue 03/28/2000 - StEstrop - Created
*
\**************************************************************************/
STDMETHODIMP
CVideoMixer::SetStreamAlpha(
    DWORD dwStreamID,
    float Alpha
    )
{
    AMTRACE((TEXT("CVideoMixer::SetStreamAlpha")));
    CAutoLock Lock(&m_ObjectLock);

    HRESULT hr = ValidateStream(dwStreamID);
    if (SUCCEEDED(hr)) {
        if ( Alpha < 0.0f || Alpha > 1.0f )
        {
            DbgLog((LOG_ERROR, 1,
                    TEXT("SetStreamAlpha: Alpha value must be between 0.0 and 1.0")));
            return E_INVALIDARG;
        }
        hr = m_ppMixerStreams[dwStreamID]->SetStreamAlpha(Alpha);
    }
    return hr;
}

/******************************Public*Routine******************************\
* GetStreamAlpha
*
*
*
* History:
* Tue 03/28/2000 - StEstrop - Created
*
\**************************************************************************/
STDMETHODIMP
CVideoMixer::GetStreamAlpha(
    DWORD dwStreamID,
    float* lpAlpha
    )
{
    AMTRACE((TEXT("CVideoMixer::GetStreamAlpha")));
    CAutoLock Lock(&m_ObjectLock);

    if (ISBADWRITEPTR(lpAlpha))
    {
        DbgLog((LOG_ERROR, 1, TEXT("GetStreamAlpha: NULL Alpha ptr !!")));
        return E_POINTER;
    }

    HRESULT hr = ValidateStream(dwStreamID);
    if (SUCCEEDED(hr)) {
        hr = m_ppMixerStreams[dwStreamID]->GetStreamAlpha(lpAlpha);
    }
    return hr;
}

/******************************Public*Routine******************************\
* SetStreamZOrder
*
*
*
* History:
* Tue 03/28/2000 - StEstrop - Created
*
\**************************************************************************/
STDMETHODIMP
CVideoMixer::SetStreamZOrder(
    DWORD dwStreamID,
    DWORD ZOrder
    )
{
    AMTRACE((TEXT("CVideoMixer::SetStreamZOrder")));
    CAutoLock Lock(&m_ObjectLock);

    HRESULT hr = ValidateStream(dwStreamID);
    if (SUCCEEDED(hr)) {
        hr = m_ppMixerStreams[dwStreamID]->SetStreamZOrder(ZOrder);
    }
    return hr;
}

/******************************Public*Routine******************************\
* GetStreamZOrder
*
*
*
* History:
* Tue 03/28/2000 - StEstrop - Created
*
\**************************************************************************/
STDMETHODIMP
CVideoMixer::GetStreamZOrder(
    DWORD dwStreamID,
    DWORD* pdwZOrder
    )
{
    AMTRACE((TEXT("CVideoMixer::GetStreamZOrder")));
    CAutoLock Lock(&m_ObjectLock);

    if (ISBADWRITEPTR(pdwZOrder))
    {
        DbgLog((LOG_ERROR, 1, TEXT("GetStreamZOrder: NULL ZOrder ptr!!")));
        return E_POINTER;
    }

    HRESULT hr = ValidateStream(dwStreamID);
    if (SUCCEEDED(hr)) {
        hr = m_ppMixerStreams[dwStreamID]->GetStreamZOrder(pdwZOrder);
    }
    return hr;
}

/******************************Public*Routine******************************\
* SetStreamOutputRect
*
*
*
* History:
* Tue 03/28/2000 - StEstrop - Created
* Tue 05/16/2000 - nwilt - renamed to SetStreamOutputRect
*
\**************************************************************************/
STDMETHODIMP
CVideoMixer::SetStreamOutputRect(
    DWORD dwStreamID,
    const NORMALIZEDRECT* prDest
    )
{
    AMTRACE((TEXT("CVideoMixer::SetStreamOutputRect")));
    CAutoLock Lock(&m_ObjectLock);

    if (ISBADREADPTR(prDest))
    {
        DbgLog((LOG_ERROR, 1, TEXT("SetStreamOutputRect: NULL rect ptr!!")));
        return E_POINTER;
    }

    HRESULT hr = ValidateStream(dwStreamID);
    if (SUCCEEDED(hr)) {
        hr = m_ppMixerStreams[dwStreamID]->SetStreamOutputRect(prDest);
    }
    return hr;
}

/******************************Public*Routine******************************\
* GetStreamOutputRect
*
*
*
* History:
* Tue 03/28/2000 - StEstrop - Created
* Tue 05/16/2000 - nwilt - renamed to GetStreamOutputRect
*
\**************************************************************************/
STDMETHODIMP
CVideoMixer::GetStreamOutputRect(
    DWORD dwStreamID,
    NORMALIZEDRECT* pOut
    )
{
    AMTRACE((TEXT("CVideoMixer::GetStreamOutputRect")));
    CAutoLock Lock(&m_ObjectLock);

    if (ISBADWRITEPTR(pOut))
    {
        DbgLog((LOG_ERROR, 1, TEXT("GetStreamOutputRect: NULL rect ptr!!")));
        return E_POINTER;
    }

    HRESULT hr = ValidateStream(dwStreamID);
    if (SUCCEEDED(hr)) {
        hr = m_ppMixerStreams[dwStreamID]->GetStreamOutputRect(pOut);
    }
    return hr;
}


/******************************Public*Routine******************************\
* SetAlphaBitmap
*
*
*
* History:
* Thu 05/04/2000 - nwilt - Created
*
\**************************************************************************/
STDMETHODIMP
CVideoMixer::SetAlphaBitmap( const VMRALPHABITMAP *pIn )
{
    AMTRACE((TEXT("CVideoMixer::SetAlphaBitmap")));
    CAutoLock Lock(&m_ObjectLock);

    if ( ISBADREADPTR( pIn ) )
    {
        DbgLog((LOG_ERROR, 1, TEXT("Bad input pointer")));
        return E_POINTER;
    }
    if ( pIn->dwFlags & ~(VMRBITMAP_DISABLE | VMRBITMAP_HDC |
                          VMRBITMAP_ENTIREDDS | VMRBITMAP_SRCCOLORKEY) )
    {
        DbgLog((LOG_ERROR, 1, TEXT("Invalid flags")));
        return E_INVALIDARG;
    }
    if ( pIn->dwFlags & VMRBITMAP_DISABLE )
    {
        if ( pIn->dwFlags != VMRBITMAP_DISABLE )
        {
            DbgLog((LOG_ERROR, 1, TEXT("No flags valid with VMRBITMAP_DISABLE")));
            return E_INVALIDARG;
        }
        // early out
        RELEASE( m_pDDSAppImage );
        if (m_hbmpAppImage) {
            DeleteObject( m_hbmpAppImage );
            m_hbmpAppImage = NULL;
        }
        return S_OK;
    }

    if ( ! m_pDD )
    {
        DbgLog((LOG_ERROR, 1, TEXT("DirectDraw object not yet set")));
        return E_FAIL;
    }

    if ( pIn->dwFlags & VMRBITMAP_HDC )
    {
        if ( pIn->dwFlags & VMRBITMAP_ENTIREDDS )
        {
            DbgLog((LOG_ERROR, 1, TEXT("ENTIREDDS not valid with HDC")));
            return E_INVALIDARG;
        }
        if ( NULL == pIn->hdc )
        {
            DbgLog((LOG_ERROR, 1, TEXT("No HDC specified")));
            return E_INVALIDARG;
        }
        if ( NULL != pIn->pDDS )
        {
            DbgLog((LOG_ERROR, 1, TEXT("DirectDraw surface specified even ")
                    TEXT("though VMRBITMAP_HDC set")));
            return E_INVALIDARG;
        }
    }
    else
    {
        if ( NULL != pIn->hdc )
        {
            DbgLog((LOG_ERROR, 1, TEXT("HDC cannot be specified without ")
                    TEXT("setting VMRBITMAP_HDC")));
            return E_INVALIDARG;
        }
        if ( NULL == pIn->pDDS )
        {
            DbgLog((LOG_ERROR, 1, TEXT("DirectDraw surface not specified")));
            return E_INVALIDARG;
        }
    }

    if ( pIn->fAlpha < 0.0f || pIn->fAlpha > 1.0f )
    {
        DbgLog((LOG_ERROR, 1, TEXT("Alpha must be between 0.0 and 1.0")));
        return E_INVALIDARG;
    }

    if (m_hbmpAppImage) {
        DeleteObject( m_hbmpAppImage );
        m_hbmpAppImage = NULL;
    }

    HRESULT hr = S_OK;
    HDC hdcSrc = NULL;
    HDC hdcDest = NULL;
    HBITMAP hbmpNew = NULL;
    UINT Width, Height;

    __try
    {
        DDSURFACEDESC2 ddsd = {sizeof(ddsd)};
        m_dwAppImageFlags = APPIMG_NOIMAGE;

        if (VMRBITMAP_ENTIREDDS & pIn->dwFlags)
        {
            CHECK_HR(hr = pIn->pDDS->GetSurfaceDesc(&ddsd));

            //
            // We only allow ARGB32 and RGB32 DDraw surface types.
            //
            if (ddsd.ddpfPixelFormat.dwRGBBitCount != 32) {
                DbgLog((LOG_ERROR, 1, TEXT("Only 32bit DirectDraw surfacs allowed")));
                hr = E_INVALIDARG;
                __leave;
            }

            if (ddsd.ddpfPixelFormat.dwRGBAlphaBitMask == 0xFF000000) {

                if (pIn->dwFlags & VMRBITMAP_SRCCOLORKEY) {
                    DbgLog((LOG_ERROR, 1, TEXT("Can't mix color keying and per-pixel alpha")));
                    hr = E_INVALIDARG;
                    __leave;
                }

                m_dwAppImageFlags = APPIMG_DDSURFARGB32;
            }
            else {
                m_dwAppImageFlags = APPIMG_DDSURFRGB32;
            }

            m_rcAppImageSrc.left = m_rcAppImageSrc.top = 0;
            m_rcAppImageSrc.right = ddsd.dwWidth;
            m_rcAppImageSrc.bottom = ddsd.dwHeight;
        }
        else {
            m_dwAppImageFlags = APPIMG_HBITMAP;
            m_rcAppImageSrc = pIn->rSrc;
        }

        if (IsRectEmpty(&m_rcAppImageSrc))
        {
            DbgLog((LOG_ERROR, 1, TEXT("Empty source rectangle")));
            hr = E_INVALIDARG;
            __leave;
        }

        Width = m_rcAppImageSrc.right - m_rcAppImageSrc.left;
        Height = m_rcAppImageSrc.bottom - m_rcAppImageSrc.top;

        if (pIn->dwFlags & VMRBITMAP_HDC) {
            hdcSrc = pIn->hdc;
        }
        else {
            CHECK_HR( hr = pIn->pDDS->GetDC( &hdcSrc ) );
        }

        hdcDest = CreateCompatibleDC(NULL);
        if (!hdcDest)
        {
            DbgLog((LOG_ERROR, 1, TEXT("Could not create dest DC")));
            hr = E_OUTOFMEMORY;
            __leave;
        }

        BITMAPINFO bmpinfo;
        LPVOID lpvBits;
        ZeroMemory( &bmpinfo, sizeof(bmpinfo) );
        bmpinfo.bmiHeader.biSize = sizeof(bmpinfo.bmiHeader);
        bmpinfo.bmiHeader.biWidth = Width;
        bmpinfo.bmiHeader.biHeight = Height;
        bmpinfo.bmiHeader.biPlanes = 1;
        bmpinfo.bmiHeader.biBitCount = 32;
        bmpinfo.bmiHeader.biCompression = BI_RGB;
        hbmpNew = CreateDIBSection(hdcDest, &bmpinfo, DIB_RGB_COLORS,
                                   &lpvBits, NULL, 0 );
        if (!hbmpNew)
        {
            DbgLog((LOG_ERROR, 1, TEXT("Could not create DIBsection")));
            hr = E_OUTOFMEMORY;
            __leave;
        }

        HBITMAP hbmpOld = (HBITMAP) SelectObject( hdcDest, hbmpNew );
        if (!BitBlt(hdcDest, 0, 0, Width, Height,
                    hdcSrc, m_rcAppImageSrc.left, m_rcAppImageSrc.top, SRCCOPY))
        {
            DbgLog((LOG_ERROR, 1, TEXT("BitBlt to bitmap surface failed")));
            hr = E_FAIL;
            __leave;
        }

        // successfully copied from source surface to destination
        SelectObject( hdcDest, hbmpOld );
    }
    __finally
    {
        if (NULL != hdcSrc && (!(VMRBITMAP_HDC & pIn->dwFlags))) {
            pIn->pDDS->ReleaseDC( hdcSrc );
        }

        if (hdcDest) {
            DeleteDC(hdcDest);
        }
    }

    if ( S_OK == hr )
    {
        m_hbmpAppImage = hbmpNew;

        // make sure we make a new mirror surface next time we blend
        RELEASE(m_pDDSAppImage);

        // record parameters
        if (pIn->dwFlags & VMRBITMAP_SRCCOLORKEY) {
            m_clrTrans = pIn->clrSrcKey;
        }
        else {
            m_clrTrans = CLR_INVALID;
        }

        m_dwClrTransMapped = (DWORD)-1;
        m_rDest = pIn->rDest;
        m_fAlpha = pIn->fAlpha;
        m_dwWidthAppImage = Width;
        m_dwHeightAppImage = Height;
    }

    return hr;
}

/******************************Public*Routine******************************\
* UpdateAlphaBitmapParameters
*
*
*
* History:
*  - StEstrop - Created
*
\**************************************************************************/
STDMETHODIMP
CVideoMixer::UpdateAlphaBitmapParameters(
    PVMRALPHABITMAP pIn
    )
{
    AMTRACE((TEXT("CVideoMixer::UpdateAlphaBitmapParameters")));
    CAutoLock Lock(&m_ObjectLock);


    if (pIn->dwFlags & VMRBITMAP_DISABLE)
    {
        if (pIn->dwFlags != VMRBITMAP_DISABLE)
        {
            DbgLog((LOG_ERROR, 1, TEXT("No flags valid with VMRBITMAP_DISABLE")));
            return E_INVALIDARG;
        }

        // early out
        RELEASE(m_pDDSAppImage);

        if (m_hbmpAppImage) {
            DeleteObject( m_hbmpAppImage );
            m_hbmpAppImage = NULL;
        }

        return S_OK;
    }

    //
    // Update the color key value - we only remap the color key if
    // it has actually changed.
    //
    HRESULT hr = S_OK;
    if (pIn->dwFlags & VMRBITMAP_SRCCOLORKEY) {

        if (m_clrTrans != pIn->clrSrcKey) {

            m_clrTrans = pIn->clrSrcKey;

            if (m_pDDSAppImage) {
                m_dwClrTransMapped = DDColorMatch(m_pDDSAppImage, m_clrTrans, hr);
                if (hr == DD_OK) {
                    DDCOLORKEY key = {m_dwClrTransMapped, m_dwClrTransMapped};
                    hr = m_pDDSAppImage->SetColorKey(DDCKEY_SRCBLT, &key);
                }
            }
            else {
                m_dwClrTransMapped = (DWORD)-1;
            }
        }
    }
    else {

        m_clrTrans = CLR_INVALID;
        m_dwClrTransMapped = (DWORD)-1;
    }

    if (pIn->dwFlags & VMRBITMAP_SRCRECT) {

        if (pIn->rSrc.left >= 0 &&
            pIn->rSrc.top >= 0 &&
            pIn->rSrc.right <= (LONG)m_dwWidthAppImage &&
            pIn->rSrc.bottom <=(LONG)m_dwHeightAppImage) {

            m_rcAppImageSrc = pIn->rSrc;
        }
    }

    m_rDest = pIn->rDest;
    m_fAlpha = pIn->fAlpha;

    return hr;
}

/******************************Public*Routine******************************\
* GetAlphaBitmapParameters
*
*
*
* History:
* Thu 05/04/2000 - nwilt - Created
*
\**************************************************************************/
STDMETHODIMP
CVideoMixer::GetAlphaBitmapParameters( VMRALPHABITMAP *pOut )
{
    AMTRACE((TEXT("CVideoMixer::GetAlphaBitmapParameters")));
    CAutoLock Lock(&m_ObjectLock);

    if (ISBADWRITEPTR(pOut))
    {
        DbgLog((LOG_ERROR, 1, TEXT("Invalid pointer")));
        return E_POINTER;
    }

    ZeroMemory(pOut, sizeof(*pOut));
    pOut->rSrc = m_rcAppImageSrc;
    pOut->rDest = m_rDest;
    pOut->fAlpha = m_fAlpha;
    pOut->clrSrcKey = m_clrTrans;

    return S_OK;
}


/******************************Public*Routine******************************\
* SetBackgroundColor
*
*
*
* History:
* Wed 02/28/2001 - StEstrop - Created
*
\**************************************************************************/
STDMETHODIMP
CVideoMixer::SetBackgroundColor(
    COLORREF clr
    )
{
    AMTRACE((TEXT("CVideoMixer::SetBackgroundColor")));
    CAutoLock Lock(&m_ObjectLock);

    HRESULT hr;
    LPDIRECTDRAWSURFACE7 lpSurf = m_BufferQueue.GetNextSurface();
    if (lpSurf) {
        m_clrBorder = clr;
        m_dwClrBorderMapped = DDColorMatch(lpSurf, m_clrBorder, hr);
    }
    else {
        hr = E_FAIL;
    }

    return hr;

}

/******************************Public*Routine******************************\
* GetBackgroundColor
*
*
*
* History:
* Wed 02/28/2001 - StEstrop - Created
*
\**************************************************************************/
STDMETHODIMP
CVideoMixer::GetBackgroundColor(
    COLORREF* clr
    )
{
    AMTRACE((TEXT("CVideoMixer::GetBackgroundColor")));
    CAutoLock Lock(&m_ObjectLock);

    *clr = m_clrBorder;

    return S_OK;

}

/******************************Public*Routine******************************\
* SetMixingPrefs
*
*
*
* History:
* Fri 03/02/2001 - StEstrop - Created
*
\**************************************************************************/
STDMETHODIMP
CVideoMixer::SetMixingPrefs(
    DWORD dwMixerPrefs
    )
{
    AMTRACE((TEXT("CVideoMixer::SetMixingPrefs")));
    CAutoLock Lock(&m_ObjectLock);

    //
    // validate the decimation flags
    //
    DWORD dwFlags = (dwMixerPrefs & MixerPref_DecimateMask);
    switch (dwFlags) {
    case MixerPref_NoDecimation:
    case MixerPref_DecimateOutput:
        break;

    default:
        DbgLog((LOG_ERROR, 1,
                TEXT("CVideoMixer::SetMixingPrefs - invalid decimation flags")));
        return E_INVALIDARG;
    }


    //
    // validate the filtering flags
    //
    dwFlags = (dwMixerPrefs & MixerPref_FilteringMask);
    switch (dwFlags) {
    case MixerPref_BiLinearFiltering:
    case MixerPref_PointFiltering:
        break;

    default:
        DbgLog((LOG_ERROR, 1,
                TEXT("CVideoMixer::SetMixingPrefs - invalid filtering flags")));
        return E_INVALIDARG;
    }


    //
    // validate the render target flags
    //
    dwFlags = (dwMixerPrefs & MixerPref_RenderTargetMask);
    switch (dwFlags) {
    case MixerPref_RenderTargetRGB:
    case MixerPref_RenderTargetYUV420:
    case MixerPref_RenderTargetYUV422:
    case MixerPref_RenderTargetYUV444:
    case MixerPref_RenderTargetIntelIMC3:
        break;

    default:
        DbgLog((LOG_ERROR, 1,
                TEXT("CVideoMixer::SetMixingPrefs - invalid filtering flags")));
        return E_INVALIDARG;
    }

    //
    // We are good to go !!
    //

    m_MixingPrefs = dwMixerPrefs;
    return S_OK;
}


/******************************Public*Routine******************************\
* GetMixingPrefs
*
*
*
* History:
* Fri 03/02/2001 - StEstrop - Created
*
\**************************************************************************/
STDMETHODIMP
CVideoMixer::GetMixingPrefs(
    DWORD* pdwMixerPrefs
    )
{
    AMTRACE((TEXT("CVideoMixer::GetMixingPrefs")));
    CAutoLock Lock(&m_ObjectLock);

    *pdwMixerPrefs = m_MixingPrefs;
    return S_OK;
}
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\multimedia\dshow\filters\image2\inc\vmrwinctrl.h ===
//==========================================================================;
//
//  THIS CODE AND INFORMATION IS PROVIDED "AS IS" WITHOUT WARRANTY OF ANY
//  KIND, EITHER EXPRESSED OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE
//  IMPLIED WARRANTIES OF MERCHANTABILITY AND/OR FITNESS FOR A PARTICULAR
//  PURPOSE.
//
//  Copyright (c) 1992 - 1998  Microsoft Corporation.  All Rights Reserved.
//
//--------------------------------------------------------------------------;

// Video control interface base classes, December 1995

#ifndef __VMRWINCTRL__
#define __VMRWINCTRL__

#define ABSOL(x) (x < 0 ? -x : x)
#define NEGAT(x) (x > 0 ? -x : x)

class CVMRFilter;

//  Helper
BOOL WINAPI VMRPossiblyEatMessage(HWND hwnd, UINT uMsg, WPARAM wParam, LPARAM lParam);

class CVMRBaseControlWindow : public CBaseVideoWindow, public CBaseWindow
{
protected:

    CVMRFilter  *m_pFilter;            // Pointer to owning media filter
    CCritSec *m_pInterfaceLock;        // Externally defined critical section
    COLORREF m_BorderColour;           // Current window border colour
    BOOL m_bAutoShow;                  // What happens when the state changes
    HWND m_hwndOwner;                  // Owner window that we optionally have
    HWND m_hwndDrain;                  // HWND to post any messages received
    BOOL m_bCursorHidden;              // Should we hide the window cursor

public:

    // Internal methods for other objects to get information out

    HRESULT DoSetWindowStyle(long Style,long WindowLong);
    HRESULT DoGetWindowStyle(long *pStyle,long WindowLong);
    BOOL IsAutoShowEnabled() { return m_bAutoShow; };
    COLORREF GetBorderColour() { return m_BorderColour; };
    HWND GetOwnerWindow() { return m_hwndOwner; };
    BOOL IsCursorHidden() { return m_bCursorHidden; };

    inline BOOL PossiblyEatMessage(UINT uMsg, WPARAM wParam, LPARAM lParam)
    {
        return ::VMRPossiblyEatMessage(m_hwndDrain, uMsg, wParam, lParam);
    }

public:

    CVMRBaseControlWindow(CVMRFilter *pFilter,   // Owning media filter
                       CCritSec *pInterfaceLock,    // Locking object
                       TCHAR *pName,                // Object description
                       LPUNKNOWN pUnk,              // Normal COM ownership
                       HRESULT *phr);               // OLE return code

    // These are the properties we support

    STDMETHODIMP put_Caption(BSTR strCaption);
    STDMETHODIMP get_Caption(BSTR *pstrCaption);
    STDMETHODIMP put_AutoShow(long AutoShow);
    STDMETHODIMP get_AutoShow(long *AutoShow);
    STDMETHODIMP put_WindowStyle(long WindowStyle);
    STDMETHODIMP get_WindowStyle(long *pWindowStyle);
    STDMETHODIMP put_WindowStyleEx(long WindowStyleEx);
    STDMETHODIMP get_WindowStyleEx(long *pWindowStyleEx);
    STDMETHODIMP put_WindowState(long WindowState);
    STDMETHODIMP get_WindowState(long *pWindowState);
    STDMETHODIMP put_BackgroundPalette(long BackgroundPalette);
    STDMETHODIMP get_BackgroundPalette(long *pBackgroundPalette);
    STDMETHODIMP put_Visible(long Visible);
    STDMETHODIMP get_Visible(long *pVisible);
    STDMETHODIMP put_Left(long Left);
    STDMETHODIMP get_Left(long *pLeft);
    STDMETHODIMP put_Width(long Width);
    STDMETHODIMP get_Width(long *pWidth);
    STDMETHODIMP put_Top(long Top);
    STDMETHODIMP get_Top(long *pTop);
    STDMETHODIMP put_Height(long Height);
    STDMETHODIMP get_Height(long *pHeight);
    STDMETHODIMP put_Owner(OAHWND Owner);
    STDMETHODIMP get_Owner(OAHWND *Owner);
    STDMETHODIMP put_MessageDrain(OAHWND Drain);
    STDMETHODIMP get_MessageDrain(OAHWND *Drain);
    STDMETHODIMP get_BorderColor(long *Color);
    STDMETHODIMP put_BorderColor(long Color);
    STDMETHODIMP get_FullScreenMode(long *FullScreenMode);
    STDMETHODIMP put_FullScreenMode(long FullScreenMode);

    // And these are the methods

    STDMETHODIMP SetWindowForeground(long Focus);
    STDMETHODIMP NotifyOwnerMessage(OAHWND hwnd,long uMsg,LONG_PTR wParam,LONG_PTR lParam);
    STDMETHODIMP GetMinIdealImageSize(long *pWidth,long *pHeight);
    STDMETHODIMP GetMaxIdealImageSize(long *pWidth,long *pHeight);
    STDMETHODIMP SetWindowPosition(long Left,long Top,long Width,long Height);
    STDMETHODIMP GetWindowPosition(long *pLeft,long *pTop,long *pWidth,long *pHeight);
    STDMETHODIMP GetRestorePosition(long *pLeft,long *pTop,long *pWidth,long *pHeight);
    STDMETHODIMP HideCursor(long HideCursor);
    STDMETHODIMP IsCursorHidden(long *CursorHidden);
};

// This class implements the IBasicVideo interface

class CVMRBaseControlVideo : public CBaseBasicVideo
{
protected:

    CVMRFilter  *m_pFilter;   // Pointer to owning media filter
    CCritSec *m_pInterfaceLock;         // Externally defined critical section

public:

    // Derived classes must provide these for the implementation

    virtual HRESULT IsDefaultTargetRect() PURE;
    virtual HRESULT SetDefaultTargetRect() PURE;
    virtual HRESULT SetTargetRect(RECT *pTargetRect) PURE;
    virtual HRESULT GetTargetRect(RECT *pTargetRect) PURE;
    virtual HRESULT IsDefaultSourceRect() PURE;
    virtual HRESULT SetDefaultSourceRect() PURE;
    virtual HRESULT SetSourceRect(RECT *pSourceRect) PURE;
    virtual HRESULT GetSourceRect(RECT *pSourceRect) PURE;
    virtual HRESULT GetStaticImage(long *pBufferSize,long *pDIBImage) PURE;

    // Derived classes must override this to return a VIDEOINFO representing
    // the video format. We cannot call IPin ConnectionMediaType to get this
    // format because various filters dynamically change the type when using
    // DirectDraw such that the format shows the position of the logical
    // bitmap in a frame buffer surface, so the size might be returned as
    // 1024x768 pixels instead of 320x240 which is the real video dimensions

    virtual VIDEOINFOHEADER *GetVideoFormat() PURE;

    // Helper functions for creating memory renderings of a DIB image

    HRESULT GetImageSize(VIDEOINFOHEADER *pVideoInfo,
                         LONG *pBufferSize,
                         RECT *pSourceRect);

    HRESULT CopyImage(IMediaSample *pMediaSample,
                      VIDEOINFOHEADER *pVideoInfo,
                      LONG *pBufferSize,
                      BYTE *pVideoImage,
                      RECT *pSourceRect);

    // Override this if you want notifying when the rectangles change
    virtual HRESULT OnUpdateRectangles() { return NOERROR; };
    virtual HRESULT OnVideoSizeChange();

    // Helper methods for checking rectangles
    virtual HRESULT CheckSourceRect(RECT *pSourceRect);
    virtual HRESULT CheckTargetRect(RECT *pTargetRect);

public:

    CVMRBaseControlVideo(CVMRFilter *pFilter,    // Owning media filter
                      CCritSec *pInterfaceLock,     // Serialise interface
                      TCHAR *pName,                 // Object description
                      LPUNKNOWN pUnk,               // Normal COM ownership
                      HRESULT *phr);                // OLE return code

    // These are the properties we support

    STDMETHODIMP get_AvgTimePerFrame(REFTIME *pAvgTimePerFrame);
    STDMETHODIMP get_BitRate(long *pBitRate);
    STDMETHODIMP get_BitErrorRate(long *pBitErrorRate);
    STDMETHODIMP get_VideoWidth(long *pVideoWidth);
    STDMETHODIMP get_VideoHeight(long *pVideoHeight);
    STDMETHODIMP put_SourceLeft(long SourceLeft);
    STDMETHODIMP get_SourceLeft(long *pSourceLeft);
    STDMETHODIMP put_SourceWidth(long SourceWidth);
    STDMETHODIMP get_SourceWidth(long *pSourceWidth);
    STDMETHODIMP put_SourceTop(long SourceTop);
    STDMETHODIMP get_SourceTop(long *pSourceTop);
    STDMETHODIMP put_SourceHeight(long SourceHeight);
    STDMETHODIMP get_SourceHeight(long *pSourceHeight);
    STDMETHODIMP put_DestinationLeft(long DestinationLeft);
    STDMETHODIMP get_DestinationLeft(long *pDestinationLeft);
    STDMETHODIMP put_DestinationWidth(long DestinationWidth);
    STDMETHODIMP get_DestinationWidth(long *pDestinationWidth);
    STDMETHODIMP put_DestinationTop(long DestinationTop);
    STDMETHODIMP get_DestinationTop(long *pDestinationTop);
    STDMETHODIMP put_DestinationHeight(long DestinationHeight);
    STDMETHODIMP get_DestinationHeight(long *pDestinationHeight);

    // And these are the methods

    STDMETHODIMP GetVideoSize(long *pWidth,long *pHeight);
    STDMETHODIMP SetSourcePosition(long Left,long Top,long Width,long Height);
    STDMETHODIMP GetSourcePosition(long *pLeft,long *pTop,long *pWidth,long *pHeight);
    STDMETHODIMP GetVideoPaletteEntries(long StartIndex,long Entries,long *pRetrieved,long *pPalette);
    STDMETHODIMP SetDefaultSourcePosition();
    STDMETHODIMP IsUsingDefaultSource();
    STDMETHODIMP SetDestinationPosition(long Left,long Top,long Width,long Height);
    STDMETHODIMP GetDestinationPosition(long *pLeft,long *pTop,long *pWidth,long *pHeight);
    STDMETHODIMP SetDefaultDestinationPosition();
    STDMETHODIMP IsUsingDefaultDestination();
    STDMETHODIMP GetCurrentImage(long *pBufferSize,long *pVideoImage);
};

#endif // __WINCTRL__
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\multimedia\dshow\filters\image2\mixer\mixerstream.cpp ===
/******************************Module*Header*******************************\
* Module Name: MixerStream.cpp
*
*
*
*
* Created: Thu 03/09/2000
* Author:  Stephen Estrop [StEstrop]
*
* Copyright (c) 2000 Microsoft Corporation
\**************************************************************************/
#include <streams.h>
#include <dvdmedia.h>
#include <windowsx.h>
#include <limits.h>

#include "mixerobj.h"



/******************************Public*Routine******************************\
* CVideoMixerStream
*
*
*
* History:
* Thu 03/09/2000 - StEstrop - Created
*
\**************************************************************************/
CVideoMixerStream::CVideoMixerStream(
    DWORD dwID,
    HRESULT* phr
    ) :
    m_SampleQueue(phr),
    m_dwID(dwID),
    m_fStreamConnected(FALSE),
    m_fActive(false),
    m_bWasActive(false),
    m_bFlushing(false),
    m_fAlpha(1.0f),
    m_dwZOrder(0),
    m_hNotActive(NULL),
    m_hActive(NULL),
    m_dwSurfaceFlags(0),
    m_pDeinterlaceDev(NULL),
    m_pddsDeinterlaceDst(NULL),
    m_fDeinterlaceDstTexture(FALSE),
    m_rtDeinterlacedFrameStart(MAX_REFERENCE_TIME),
    m_rtDeinterlacedFrameEnd(MAX_REFERENCE_TIME)
{
    AMTRACE((TEXT("CVideoMixerStream::CVideoMixerStream")));
    ZeroStruct(m_mt);
    ZeroStruct(m_DeinterlaceDevGUID);
    ZeroStruct(m_DeinterlaceCaps);
    ZeroStruct(m_rcSurface);

    m_ClrKey.dwColorSpaceLowValue = 0xFFFFFFFF;
    m_ClrKey.dwColorSpaceHighValue = 0xFFFFFFFF;

    m_rOutputRect.left = 0.0f;
    m_rOutputRect.right = 1.0f;
    m_rOutputRect.top = 0.0f;
    m_rOutputRect.bottom = 1.0f;

    m_hActive = CreateEvent(NULL, TRUE, FALSE, NULL);
    if (!m_hActive) {
        DWORD dwErr = GetLastError();
        *phr = HRESULT_FROM_WIN32(dwErr);
        return;
    }

    m_hNotActive = CreateEvent(NULL, TRUE, TRUE, NULL);
    if (!m_hActive) {
        DWORD dwErr = GetLastError();
        *phr = HRESULT_FROM_WIN32(dwErr);
        return;
    }
}

/******************************Public*Routine******************************\
* ~CVideoMixerStream()
*
*
*
* History:
* Thu 03/09/2000 - StEstrop - Created
*
\**************************************************************************/
CVideoMixerStream::~CVideoMixerStream()
{
    AMTRACE((TEXT("CVideoMixerStream::~CVideoMixerStream")));

    FreeMediaType(m_mt);

    if (m_hActive) {
        CloseHandle(m_hActive);
    }

    if (m_hNotActive) {
        CloseHandle(m_hNotActive);
    }

}

/******************************Public*Routine******************************\
* SetStreamSample
*
*
*
* History:
* Thu 03/09/2000 - StEstrop - Created
*
\**************************************************************************/
HRESULT
CVideoMixerStream::SetStreamSample(
    IMediaSample* lpSample
    )
{
    AMTRACE((TEXT("CVideoMixerStream::SetStreamSample")));
    CAutoLock Lock(&m_ObjectLock);
    HRESULT hr = S_OK;

    if (m_fActive) {
        lpSample->AddRef();
        if (0 != m_SampleQueue.PutSampleOntoQueue(lpSample)) {
            hr = E_FAIL;
        }
    }
    else {
        hr = E_FAIL;
    }

    return hr;
}

/******************************Public*Routine******************************\
* BeginFlush
*
*
*
* History:
* Tue 03/28/2000 - StEstrop - Created
*
\**************************************************************************/
HRESULT
CVideoMixerStream::BeginFlush()
{
    AMTRACE((TEXT("CVideoMixerStream::BeginFlush")));
    CAutoLock Lock(&m_ObjectLock);

    ASSERT(!m_bFlushing);
    m_bFlushing = TRUE;
    return S_OK;
}

/******************************Public*Routine******************************\
* EndFlush
*
*
*
* History:
* Tue 03/28/2000 - StEstrop - Created
*
\**************************************************************************/
HRESULT
CVideoMixerStream::EndFlush()
{
    AMTRACE((TEXT("CVideoMixerStream::EndFlush")));
    CAutoLock Lock(&m_ObjectLock);

    ASSERT(m_bFlushing);
    m_bFlushing = FALSE;
    return S_OK;
}


/******************************Public*Routine******************************\
* SetStreamMediaType
*
*
*
* History:
* Tue 03/14/2000 - StEstrop - Created
*
\**************************************************************************/
HRESULT
CVideoMixerStream::SetStreamMediaType(
    AM_MEDIA_TYPE* pmt,
    DWORD dwSurfaceFlags
    )
{
    AMTRACE((TEXT("CVideoMixerStream::SetStreamMediaType")));
    CAutoLock Lock(&m_ObjectLock);

    FreeMediaType(m_mt);
    if (pmt) {
        CopyMediaType(&m_mt, pmt);
        FixupMediaType(&m_mt);
    }
    else {
        ZeroMemory(&m_mt, sizeof(m_mt));
    }

    m_fStreamConnected = (pmt != NULL);
    m_dwSurfaceFlags = dwSurfaceFlags;

    return S_OK;
}

/******************************Public*Routine******************************\
* GetStreamMediaType
*
*
*
* History:
* Tue 03/14/2000 - StEstrop - Created
*
\**************************************************************************/
HRESULT
CVideoMixerStream::GetStreamMediaType(
    AM_MEDIA_TYPE* pmt,
    DWORD* pdwSurfaceFlags
    )
{
    AMTRACE((TEXT("CVideoMixerStream::GetStreamMediaType")));
    CAutoLock Lock(&m_ObjectLock);

    if (pmt) {
        CopyMediaType(pmt, &m_mt);
    }

    if (pdwSurfaceFlags) {
        *pdwSurfaceFlags = m_dwSurfaceFlags;
    }

    return S_OK;
}


/******************************Public*Routine******************************\
* SetStreamActiveState
*
*
*
* History:
* Thu 03/09/2000 - StEstrop - Created
*
\**************************************************************************/
HRESULT
CVideoMixerStream::SetStreamActiveState(
    BOOL fActive
    )
{
    AMTRACE((TEXT("CVideoMixerStream::SetStreamActiveState")));
    CAutoLock Lock(&m_ObjectLock);

    HRESULT hr = S_OK;

    if (m_fActive != fActive) {

        if (fActive) {
            ResetEvent(m_hNotActive);
            SetEvent(m_hActive);
        }
        else {
            SetEvent(m_hNotActive);
            ResetEvent(m_hActive);
        }

        m_fActive = fActive;
    }

    return hr;
}

/******************************Public*Routine******************************\
* GetStreamActiveState
*
*
*
* History:
* Thu 03/09/2000 - StEstrop - Created
*
\**************************************************************************/
HRESULT
CVideoMixerStream::GetStreamActiveState(
    BOOL* lpfActive
    )
{
    AMTRACE((TEXT("CVideoMixerStream::GetStreamActiveState")));
    CAutoLock Lock(&m_ObjectLock);

    HRESULT hr = S_OK;
    *lpfActive = m_fActive;
    return hr;
}

/******************************Public*Routine******************************\
* SetStreamColorKey
*
*
*
* History:
* Thu 03/09/2000 - StEstrop - Created
*
\**************************************************************************/
HRESULT
CVideoMixerStream::SetStreamColorKey(
    LPDDCOLORKEY lpClr
    )
{
    AMTRACE((TEXT("CVideoMixerStream::SetStreamColorKey")));
    CAutoLock Lock(&m_ObjectLock);

    HRESULT hr = S_OK;
    m_ClrKey = *lpClr;
    return hr;
}


/******************************Public*Routine******************************\
* GetStreamColorKey
*
*
*
* History:
* Thu 03/09/2000 - StEstrop - Created
*
\**************************************************************************/
HRESULT
CVideoMixerStream::GetStreamColorKey(
    LPDDCOLORKEY lpClr
    )
{
    AMTRACE((TEXT("CVideoMixerStream::GetStreamColorKey")));
    CAutoLock Lock(&m_ObjectLock);

    HRESULT hr = S_OK;
    *lpClr = m_ClrKey;
    return hr;
}

/******************************Public*Routine******************************\
* SetStreamAlpha
*
*
*
* History:
* Thu 03/09/2000 - StEstrop - Created
*
\**************************************************************************/
HRESULT
CVideoMixerStream::SetStreamAlpha(
    float Alpha
    )
{
    AMTRACE((TEXT("CVideoMixerStream::SetStreamAlpha")));
    CAutoLock Lock(&m_ObjectLock);

    HRESULT hr = S_OK;
    m_fAlpha = Alpha;
    return hr;
}


/******************************Public*Routine******************************\
* GetStreamAlpha
*
*
*
* History:
* Thu 03/09/2000 - StEstrop - Created
*
\**************************************************************************/
HRESULT
CVideoMixerStream::GetStreamAlpha(
    float* pAlpha
    )
{
    AMTRACE((TEXT("CVideoMixerStream::GetStreamAlpha")));
    CAutoLock Lock(&m_ObjectLock);

    HRESULT hr = S_OK;
    *pAlpha = m_fAlpha;
    return hr;
}


/******************************Public*Routine******************************\
* SetStreamZOrder
*
*
*
* History:
* Thu 03/09/2000 - StEstrop - Created
*
\**************************************************************************/
HRESULT
CVideoMixerStream::SetStreamZOrder(
    DWORD dwZOrder
    )
{
    AMTRACE((TEXT("CVideoMixerStream::SetStreamZOrder")));
    CAutoLock Lock(&m_ObjectLock);

    HRESULT hr = S_OK;
    m_dwZOrder = dwZOrder;
    return hr;
}


/******************************Public*Routine******************************\
* GetStreamZOrder
*
*
*
* History:
* Thu 03/09/2000 - StEstrop - Created
*
\**************************************************************************/
HRESULT
CVideoMixerStream::GetStreamZOrder(
    DWORD* pdwZOrder
    )
{
    AMTRACE((TEXT("CVideoMixerStream::GetStreamZOrder")));
    CAutoLock Lock(&m_ObjectLock);

    HRESULT hr = S_OK;
    *pdwZOrder = m_dwZOrder;
    return hr;
}


/******************************Public*Routine******************************\
* SetStreamOutputRect (was SetStreamRelativeOutputRect)
*
*
*
* History:
* Thu 03/09/2000 - StEstrop - Created
* Tue 05/16/2000 - nwilt - renamed to SetStreamOutputRect
*
\**************************************************************************/
HRESULT
CVideoMixerStream::SetStreamOutputRect(
    const NORMALIZEDRECT* prDest
    )
{
    AMTRACE((TEXT("CVideoMixerStream::SetStreamOutputRect")));
    CAutoLock Lock(&m_ObjectLock);

    if (ISBADREADPTR(prDest))
    {
        DbgLog((LOG_ERROR, 1, TEXT("Invalid pointer")));
        return E_POINTER;
    }

    HRESULT hr = S_OK;
    m_rOutputRect = *prDest;
    return hr;
}

/******************************Public*Routine******************************\
* GetStreamOutputRect (was GetStreamRelativeOutputRect)
*
*
*
* History:
* Thu 03/09/2000 - StEstrop - Created
*
\**************************************************************************/
HRESULT
CVideoMixerStream::GetStreamOutputRect(
    NORMALIZEDRECT* pOut
    )
{
    AMTRACE((TEXT("CVideoMixerStream::GetStreamOutputRect")));
    CAutoLock Lock(&m_ObjectLock);

    HRESULT hr = S_OK;
    *pOut = m_rOutputRect;
    return hr;
}

/******************************Public*Routine******************************\
* CreateDeinterlaceDevice
*
*
*
* History:
* Mon 03/18/2002 - StEstrop - Created
*
\**************************************************************************/
HRESULT
CVideoMixerStream::CreateDeinterlaceDevice(
    LPDIRECTDRAW7 pDD,
    LPGUID lpGuid,
    DXVA_DeinterlaceCaps* pCaps,
    DWORD dwTexCaps
    )
{
    AMTRACE((TEXT("CVideoMixerStream::CreateDeinterlaceDevice")));
    CAutoLock Lock(&m_ObjectLock);

    extern UINT NextPow2(UINT i);
    HRESULT hr = S_OK;

    __try {

        DestroyDeinterlaceDevice();

        CopyMemory(&m_DeinterlaceCaps, pCaps, sizeof(DXVA_DeinterlaceCaps));
        m_DeinterlaceDevGUID = *lpGuid;

        //
        // Start by trying to allocate the Deinterlace destination surfaces
        // as texture - if this fails try regular offscreen plain.
        //

        DXVA_VideoDesc VideoDesc;
        CHECK_HR(GetVideoDescFromMT(&VideoDesc, &m_mt));
        CHECK_HR(GetInterlaceFlagsFromMediaType(&m_mt, &m_dwInterlaceFlags));

        DDSURFACEDESC2 ddsd;
        INITDDSTRUCT(ddsd);
        BITMAPINFOHEADER *pHdr = GetbmiHeader(&m_mt);

        ddsd.dwFlags = DDSD_CAPS | DDSD_WIDTH | DDSD_HEIGHT | DDSD_PIXELFORMAT;
        ddsd.dwWidth = abs(pHdr->biWidth);
        ddsd.dwHeight = abs(pHdr->biHeight);
        ddsd.ddsCaps.dwCaps = DDSCAPS_VIDEOMEMORY | DDSCAPS_LOCALVIDMEM |
                              DDSCAPS_TEXTURE;

        //
        // if we can color space convert we should allocate an RGB
        // destination surface
        //
        if (pCaps->VideoProcessingCaps & DXVA_VideoProcess_YUV2RGB) {

            ddsd.ddpfPixelFormat.dwFourCC = BI_RGB;
            ddsd.ddpfPixelFormat.dwFlags = DDPF_RGB;
            ddsd.ddpfPixelFormat.dwRGBBitCount = 32;
            ddsd.ddpfPixelFormat.dwRBitMask = 0xff0000;
            ddsd.ddpfPixelFormat.dwGBitMask = 0x00ff00;
            ddsd.ddpfPixelFormat.dwBBitMask = 0x0000ff;

        }
        else {

            ddsd.ddpfPixelFormat.dwFourCC = pCaps->d3dOutputFormat;
            ddsd.ddpfPixelFormat.dwFlags = DDPF_FOURCC;
            ddsd.ddpfPixelFormat.dwYUVBitCount = pHdr->biBitCount;
        }


        if (dwTexCaps & TXTR_POWER2) {

            ddsd.dwWidth = NextPow2(ddsd.dwWidth);
            ddsd.dwHeight = NextPow2(ddsd.dwHeight);
        }

        //
        // we only try to create an offscreen plain surface if
        // we failed to create a YUV texture surface.
        //
        hr = pDD->CreateSurface(&ddsd, &m_pddsDeinterlaceDst, NULL);
        if (hr != DD_OK) {

            if (!(pCaps->VideoProcessingCaps & DXVA_VideoProcess_YUV2RGB)) {

                ddsd.dwWidth = abs(pHdr->biWidth);
                ddsd.dwHeight = abs(pHdr->biHeight);
                ddsd.ddsCaps.dwCaps = DDSCAPS_VIDEOMEMORY | DDSCAPS_LOCALVIDMEM |
                                      DDSCAPS_OFFSCREENPLAIN;

                CHECK_HR(hr = pDD->CreateSurface(&ddsd, &m_pddsDeinterlaceDst, NULL));
                m_fDeinterlaceDstTexture = FALSE;
            }
        }
        else {

            m_fDeinterlaceDstTexture = TRUE;
        }

        //
        // Next create the deinterlacing device.
        //

        m_pDeinterlaceDev = new CDeinterlaceDevice(pDD, lpGuid, &VideoDesc, &hr);
        if (!m_pDeinterlaceDev || hr != DD_OK) {

            if (!m_pDeinterlaceDev) {

                hr = E_OUTOFMEMORY;
            }
            __leave;
        }

        m_rtDeinterlacedFrameStart = MAX_REFERENCE_TIME;
        m_rtDeinterlacedFrameEnd = MAX_REFERENCE_TIME;

        SetRect(&m_rcSurface, 0, 0, abs(pHdr->biWidth), abs(pHdr->biHeight));

    }
    __finally {

        if (FAILED(hr)) {

            DestroyDeinterlaceDevice();
        }

    }
    return hr;
}

/******************************Public*Routine******************************\
* DestroyDeinterlaceDevice
*
*
*
* History:
* Mon 03/18/2002 - StEstrop - Created
*
\**************************************************************************/
HRESULT
CVideoMixerStream::DestroyDeinterlaceDevice()
{
    AMTRACE((TEXT("CVideoMixerStream::DestroyDeinterlaceDevice")));
    CAutoLock Lock(&m_ObjectLock);

    RELEASE(m_pddsDeinterlaceDst);
    delete m_pDeinterlaceDev;
    m_pDeinterlaceDev = NULL;

    ZeroStruct(m_DeinterlaceDevGUID);
    ZeroStruct(m_DeinterlaceCaps);
    ZeroStruct(m_rcSurface);

    m_rtDeinterlacedFrameStart = MAX_REFERENCE_TIME;
    m_rtDeinterlacedFrameEnd = MAX_REFERENCE_TIME;

    return S_OK;
}

/******************************Public*Routine******************************\
* IsStreamInterlaced
*
*
*
* History:
* Wed 03/20/2002 - StEstrop - Created
*
\**************************************************************************/
BOOL
CVideoMixerStream::IsStreamInterlaced()
{
    AMTRACE((TEXT("CVideoMixerStream::IsStreamInterlaced")));
    CAutoLock Lock(&m_ObjectLock);

    DWORD dwInterlaceFlags = 0;

    GetInterlaceFlagsFromMediaType(&m_mt, &dwInterlaceFlags);

    if (dwInterlaceFlags) {

        if (IsSingleFieldPerSample(dwInterlaceFlags)) {
            return TRUE;
        }

        ASSERT(m_pSample);

        CVMRMediaSample* lpVMR = (CVMRMediaSample*)m_pSample;
        DWORD dwTypeSpecificFlags = lpVMR->GetTypeSpecificFlags();

        return NeedToFlipOddEven(dwInterlaceFlags, dwTypeSpecificFlags,
                                 NULL, TRUE);
    }
    return FALSE;
}

/******************************Public*Routine******************************\
* IsStreamTwoInterlacedFields
*
*
*
* History:
* Sat 04/13/2002 - StEstrop - Created
*
\**************************************************************************/
BOOL
CVideoMixerStream::IsStreamTwoInterlacedFields()
{
    AMTRACE((TEXT("CVideoMixerStream::IsStreamTwoInterlacedFields")));
    CAutoLock Lock(&m_ObjectLock);

    DWORD dwInterlaceFlags;
    GetInterlaceFlagsFromMediaType(&m_mt, &dwInterlaceFlags);

    CVMRMediaSample* lpVMR = (CVMRMediaSample*)m_pSample;
    DWORD dwTypeSpecificFlags = lpVMR->GetTypeSpecificFlags();

    const DWORD dwBobOrWeave = (AMINTERLACE_IsInterlaced |
                                AMINTERLACE_DisplayModeBobOrWeave);

    if ((dwInterlaceFlags & dwBobOrWeave) == dwBobOrWeave) {
        if (dwTypeSpecificFlags & AM_VIDEO_FLAG_WEAVE) {
            return FALSE;
        }
        return TRUE;
    }


    const DWORD dwBobOnly = (AMINTERLACE_IsInterlaced |
                             AMINTERLACE_DisplayModeBobOnly);
    if ((dwInterlaceFlags & dwBobOnly) == dwBobOnly) {
        if (!(AMINTERLACE_1FieldPerSample & dwInterlaceFlags)) {
            return TRUE;
        }
    }

    return FALSE;

}

/******************************Public*Routine******************************\
* IsDeinterlaceDestATexture
*
*
*
* History:
* Wed 03/20/2002 - StEstrop - Created
*
\**************************************************************************/
BOOL
CVideoMixerStream::IsDeinterlaceDestATexture()
{
    AMTRACE((TEXT("CVideoMixerStream::IsDeinterlaceDestATexture")));
    CAutoLock Lock(&m_ObjectLock);
    return m_fDeinterlaceDstTexture;
}

/******************************Public*Routine******************************\
* CanBeDeinterlaced
*
*
*
* History:
* Thu 03/21/2002 - StEstrop - Created
*
\**************************************************************************/
BOOL
CVideoMixerStream::CanBeDeinterlaced()
{
    AMTRACE((TEXT("CVideoMixerStream::CanBeDeinterlaced")));
    CAutoLock Lock(&m_ObjectLock);
    return m_pDeinterlaceDev != NULL;
}

/******************************Public*Routine******************************\
* GetDeinterlaceDestSurface
*
*
*
* History:
* Wed 03/20/2002 - StEstrop - Created
*
\**************************************************************************/
LPDIRECTDRAWSURFACE7
CVideoMixerStream::GetDeinterlaceDestSurface()
{
    return m_pddsDeinterlaceDst;
}


/******************************Public*Routine******************************\
* DeinterlaceStreamWorker
*
*
* work out the start and end time for this frame
* extract the reference surfaces from the saved media sample
* get the de-interlacing device to perform the Blt
* update the frame start and end times.
*
* History:
* Mon 03/25/2002 - StEstrop - Created
*
\**************************************************************************/
HRESULT
CVideoMixerStream::DeinterlaceStreamWorker(
    REFERENCE_TIME rtStart,
    LPRECT lprcDst,
    LPDIRECTDRAWSURFACE7 pddDst,
    LPRECT lprcSrc,
    bool fUpdateTimes
    )
{
    AMTRACE((TEXT("CVideoMixerStream::DeinterlaceStreamWorker")));


    //
    // work out the start and end time for this frame
    // extract the reference surfaces from the saved media sample
    // get the de-interlacing device to perform the Blt
    //
    CVMRMediaSample* lpVMR = (CVMRMediaSample*)m_pSample;
    ASSERT(lpVMR);

    DWORD& NumBackRefSamples = m_DeinterlaceCaps.NumBackwardRefSamples;

    DWORD dwNumInSamples = lpVMR->GetNumInputSamples();
    DXVA_VideoSample* pSrcSurf = lpVMR->GetInputSamples();

    REFERENCE_TIME rtF1 = pSrcSurf[NumBackRefSamples].rtStart;
    REFERENCE_TIME rtF2 = pSrcSurf[NumBackRefSamples].rtStart +
                          pSrcSurf[NumBackRefSamples].rtEnd;
    ASSERT(rtF2 != 0);
    rtF2 /= 2;

    if (rtStart >= rtF2) {
        rtStart = rtF2;
    }
    else {
        rtStart = rtF1;
    }


    HRESULT hr = m_pDeinterlaceDev->Blt(rtStart, lprcDst, pddDst,
                                        lprcSrc, pSrcSurf, dwNumInSamples,
                                        1.0F);
#ifdef DEBUG
    if (hr != DD_OK) {
        DbgLog((LOG_ERROR, 1, TEXT("m_pDeinterlaceDev->Blt failed hr=%#X"), hr));
    }
#endif

    if (hr == DD_OK && fUpdateTimes) {

        m_rtDeinterlacedFrameStart = rtStart;
        if (rtStart == rtF2) {
            m_rtDeinterlacedFrameEnd = pSrcSurf[NumBackRefSamples].rtEnd;
        }
        else {
            m_rtDeinterlacedFrameEnd = rtF2;
        }
    }

    return hr;
}



/******************************Public*Routine******************************\
* DeinterlaceStream
*
*
*
* History:
* Wed 03/20/2002 - StEstrop - Created
*
\**************************************************************************/
HRESULT
CVideoMixerStream::DeinterlaceStream(
    REFERENCE_TIME rtStart,
    LPRECT lprcDst,
    LPDIRECTDRAWSURFACE7 pddDst,
    LPRECT lprcSrc,
    BOOL fDestRGB
    )
{
    AMTRACE((TEXT("CVideoMixerStream::DeinterlaceStream")));
    CAutoLock Lock(&m_ObjectLock);

    HRESULT hr = S_OK;

    if (lprcDst == NULL) {
        lprcDst = &m_rcSurface;
    }

    if (lprcSrc == NULL) {
        lprcSrc = &m_rcSurface;
    }

    //
    // Have we been given a destination surface to copy the
    // de-interlaced frame too?
    //

    if (pddDst) {

        BOOL fBltOK = TRUE;

        //
        // can we de-interlace directly into the destination surface?
        // there are stretching and color space conversion issues to
        // deal with.
        //
        DXVA_VideoProcessCaps& dwCaps = m_DeinterlaceCaps.VideoProcessingCaps;

        if (fDestRGB) {
            fBltOK &= !!(dwCaps & DXVA_VideoProcess_YUV2RGB);
        }

        if (WIDTH(lprcDst) != WIDTH(lprcSrc)) {
            fBltOK &= !!(dwCaps & DXVA_VideoProcess_StretchX);
        }

        if (HEIGHT(lprcDst) != HEIGHT(lprcSrc)) {

            if (!IsSingleFieldPerSample(m_dwInterlaceFlags) ||
                (HEIGHT(lprcDst) != (2 * HEIGHT(lprcSrc)))) {

                fBltOK &= !!(dwCaps & DXVA_VideoProcess_StretchY);
            }
        }

        if (fBltOK) {

            return DeinterlaceStreamWorker(rtStart, lprcDst, pddDst,
                                           lprcSrc, false);
        }
        else {

            //
            // if the de-interlace frame store is a texture
            // we don't want to be blt'ing from it so fail the
            // call here.
            //
            if (m_fDeinterlaceDstTexture) {
                return E_FAIL;
            }
        }
    }


    //
    // do we need to create a new de-interlaced frame?
    //

    if (rtStart <  m_rtDeinterlacedFrameStart ||
        rtStart >= m_rtDeinterlacedFrameEnd) {

        hr = DeinterlaceStreamWorker(rtStart, &m_rcSurface,
                                     m_pddsDeinterlaceDst, &m_rcSurface, true);
    }


    if (pddDst && SUCCEEDED(hr)) {

        hr = pddDst->Blt(lprcDst, m_pddsDeinterlaceDst,
                         lprcSrc, DDBLT_WAIT, NULL);
    }

    return hr;
}
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\multimedia\dshow\filters\image2\mixer\mixerqueue.cpp ===
/******************************Module*Header*******************************\
* Module Name: mixerQueue.cpp
*
*
*
*
* Created: Thu 03/23/2000
* Author:  Stephen Estrop [StEstrop]
*
* Copyright (c) 2000 Microsoft Corporation
\**************************************************************************/
#include <streams.h>
#include <windowsx.h>
#include <limits.h>

#include "mixerobj.h"


int
CVMRMixerQueue::CSampleList::GetCount() const
{
    return m_nOnList;
};

void
CVMRMixerQueue::CSampleList::AddTail(
    CVMRMediaSample *pSample
    )
{
    CVMRMediaSample **ppTail = &m_List;

    while (*ppTail) {
        ppTail = &(CVMRMixerQueue::NextSample(*ppTail));
    }

    *ppTail = (CVMRMediaSample *)pSample;
    CVMRMixerQueue::NextSample(pSample) = NULL;
    m_nOnList++;
};


CVMRMediaSample*
CVMRMixerQueue::CSampleList::RemoveHead()
{
    CVMRMediaSample *pSample = m_List;
    if (pSample != NULL) {
        m_List = CVMRMixerQueue::NextSample(m_List);
        m_nOnList--;
    }
    return pSample;
};


CVMRMediaSample*
CVMRMixerQueue::CSampleList::PeekHead()
{
    return m_List;
};


CVMRMixerQueue::CVMRMixerQueue(
    HRESULT *phr
    ) :
    m_lWaiting(0)
{
    AMTRACE((TEXT("CVMRMixerQueue::CVMRMixerQueue")));

    m_hSem = CreateSemaphore(NULL, 0, 0x7FFFFFFF, NULL);
    if (m_hSem == NULL) {
        DWORD dwErr = GetLastError();
        *phr = HRESULT_FROM_WIN32(dwErr);
        return;
    }

}

CVMRMixerQueue::~CVMRMixerQueue()
{
    AMTRACE((TEXT("CVMRMixerQueue::~CVMRMixerQueue")));

    if (m_hSem) {
        CloseHandle(m_hSem);
    }
}

DWORD
CVMRMixerQueue::GetSampleFromQueueNoWait(
    IMediaSample** lplpMediaSample
    )
{
    AMTRACE((TEXT("CVMRMixerQueue::GetSampleFromQueueNoWait")));

    CAutoLock lck(&m_CritSect);
    *lplpMediaSample = (CVMRMediaSample *)m_lFree.PeekHead();

    return *lplpMediaSample != NULL;
}


DWORD
CVMRMixerQueue::GetSampleFromQueueNoRemove(
    HANDLE hNotActive,
    IMediaSample** lplpMediaSample
    )
{
    AMTRACE((TEXT("CVMRMixerQueue::GetSampleFromQueueNoRemove")));

    CVMRMediaSample *pSample = NULL;
    *lplpMediaSample = NULL;
    DWORD dwRet = 0;

    for ( ;; )
    {
        {
            // scope for lock
            CAutoLock lck(&m_CritSect);

            pSample = (CVMRMediaSample *)m_lFree.PeekHead();
            if (pSample == NULL) {
                m_lWaiting++;
            }
        }

        /* If we didn't get a sample then wait for the list to signal */

        if (pSample) {
            break;
        }

        ASSERT(m_hSem != NULL);
        ASSERT(hNotActive != NULL);

        HANDLE h[2];
        h[0] = hNotActive;
        h[1] = m_hSem;

        dwRet = WaitForMultipleObjects(2, h, FALSE, INFINITE);
        if (dwRet == WAIT_OBJECT_0) {
            break;
        }
    }

    *lplpMediaSample = pSample;
    return dwRet;
}


BOOL
CVMRMixerQueue::RemoveSampleFromQueue()
{
    AMTRACE((TEXT("CVMRMixerQueue::RemoveSampleFromQueue")));

    CAutoLock lck(&m_CritSect);
    CVMRMediaSample*pSample = m_lFree.RemoveHead();
    return pSample != NULL;
}


DWORD
CVMRMixerQueue::PutSampleOntoQueue(
    IMediaSample* lpSample
    )
{
    AMTRACE((TEXT("CVMRMixerQueue::PutSampleOntoQueue")));

    CAutoLock lck(&m_CritSect);
    DWORD dwRet = 0;

    //
    // Put this sample onto the end of the mixer queue
    //

    m_lFree.AddTail((CVMRMediaSample *)lpSample);
    if (m_lWaiting != 0) {

        ASSERT(m_hSem != NULL);
        if (!ReleaseSemaphore(m_hSem, m_lWaiting, 0)) {
            dwRet = GetLastError();
        }
        m_lWaiting = 0;
    }

    return dwRet;
}
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\multimedia\dshow\filters\image2\rndless\app.h ===
/******************************Module*Header*******************************\
* Module Name: app.h
*
* Function prototype for the Video CD Player application.
*
*
* Created: dd-mm-94
* Author:  Stephen Estrop [StephenE]
*
* Copyright (c) 1994 - 1999  Microsoft Corporation.  All Rights Reserved.
\**************************************************************************/




/* -------------------------------------------------------------------------
** Functions prototypes
** -------------------------------------------------------------------------
*/
int
DoMainLoop(
    void
    );

BOOL
InitApplication(
    HINSTANCE hInstance
    );

BOOL
InitInstance(
    HINSTANCE hInstance,
    int nCmdShow
    );


void
UpdateMpegMovieRect(
    void
    );

void
GetAdjustedClientRect(
    RECT *prc
    );

BOOL
DrawStats(
    HDC hdc
    );

void
CalcMovieRect(
    LPRECT lprc
    );

LPCTSTR
IdStr(
    int idResource
    );

void
UpdateSystemColors(
    void
    );



/* -------------------------------------------------------------------------
** Message crackers
** -------------------------------------------------------------------------
*/
/* void Cls_OnUser(HWND hwnd, WPARAM wParam, LPARAM lParam ) */
#define HANDLE_WM_USER(hwnd, wParam, lParam, fn) \
    ((fn)(hwnd, wParam, lParam), 0L)

#ifndef HANDLE_WM_NOTIFY
/* LRESULT Cls_OnNotify(HWND hwnd, int idFrom, NMHDR FAR* pnmhdr); */
#define HANDLE_WM_NOTIFY(hwnd, wParam, lParam, fn) \
    (fn)((hwnd), (int)(wParam), (NMHDR FAR*)(lParam))
#endif



/* -------------------------------------------------------------------------
** VideoCd window class prototypes
** -------------------------------------------------------------------------
*/
extern "C" LRESULT CALLBACK
VideoCdWndProc(
    HWND hwnd,
    UINT message,
    WPARAM wParam,
    LPARAM lParam
    );

void
VideoCd_OnClose(
    HWND hwnd
    );

BOOL
VideoCd_OnQueryEndSession(
    HWND hwnd
    );

void
VideoCd_OnDestroy(
    HWND hwnd
    );

void
VideoCd_OnCommand(
    HWND hwnd,
    int id,
    HWND hwndCtl,
    UINT codeNotify
    );

void
VideoCd_OnPaint(
    HWND hwnd
    );

void
VideoCd_OnTimer(
    HWND hwnd,
    UINT id
    );

BOOL
VideoCd_OnCreate(
    HWND hwnd,
    LPCREATESTRUCT lpCreateStruct
    );

void
VideoCd_OnSize(
    HWND hwnd,
    UINT state,
    int cx,
    int cy
    );

void
VideoCd_OnKeyUp(
    HWND hwnd,
    UINT vk,
    BOOL fDown,
    int cRepeat,
    UINT flags
    );

void
VideoCd_OnHScroll(
    HWND hwnd,
    HWND hwndCtl,
    UINT code,
    int pos
    );

void
VideoCd_OnUser(
    HWND hwnd,
    WPARAM wParam,
    LPARAM lParam
    );

void
VideoCd_OnSysColorChange(
    HWND hwnd
    );

void
VideoCd_OnMenuSelect(
    HWND hwnd,
    HMENU hmenu,
    int item,
    HMENU hmenuPopup,
    UINT flags
    );

void
VideoCd_OnInitMenuPopup(
    HWND hwnd,
    HMENU hMenu,
    UINT item,
    BOOL fSystemMenu
    );

#ifdef WM_NOTIFY
LRESULT
VideoCd_OnNotify(
    HWND hwnd,
    int idFrom,
    NMHDR FAR* pnmhdr
    );
#endif


void
VideoCd_OnGraphNotify(
    int stream
    );

void
VideoCd_OnDropFiles(
    HWND hwnd,
    HDROP hdrop);

void
SetPlayButtonsEnableState(
    void
    );



/* -------------------------------------------------------------------------
** Command processing functions
** -------------------------------------------------------------------------
*/

BOOL
VcdPlayerSetLog(
    void
    );

BOOL
VcdPlayerSetPerfLogFile(
    void
    );

BOOL
VcdPlayerOpenCmd(
    void
    );

BOOL
VcdPlayerCloseCmd(
    void
    );

BOOL
VcdPlayerPlayCmd(
    void
    );

BOOL
VcdPlayerStopCmd(
    void
    );

BOOL
VcdPlayerPauseCmd(
    void
    );

BOOL
VcdPlayerPauseCmd(
    void
    );

void
VcdPlayerSeekCmd(
    REFTIME rtSeekBy
    );

void
ProcessOpen(
    TCHAR *achFileName,
    BOOL bPlay = FALSE
    );

/* -------------------------------------------------------------------------
** Recent filename stuff
** -------------------------------------------------------------------------
*/
typedef TCHAR RECENTFILES[MAX_PATH];
#define MAX_RECENT_FILES    5
#define ID_RECENT_FILE_BASE 500

int
GetRecentFiles(
    int LastCount
    );

int
SetRecentFiles(
    TCHAR *FileName,
    int iCount
    );


/* -------------------------------------------------------------------------
** Global Variables
** -------------------------------------------------------------------------
*/
extern int              cxMovie;
extern int              cyMovie;
extern HWND             hwndApp;

extern int              cx;
extern int              cy;
extern int              xOffset;
extern int              yOffset;
extern DWORD            g_State;
extern TCHAR            g_szPerfLog[];
extern int              g_TimeFormat;
extern BOOL             g_bUseThreadedGraph;




/* -------------------------------------------------------------------------
** Constants
** -------------------------------------------------------------------------
*/
#define LEFT_MARGIN 0



/* -------------------------------------------------------------------------
** Video CD Player states
**
**  These are bit flags
** -------------------------------------------------------------------------
*/

#define VCD_PLAYING          0x0001
#define VCD_STOPPED          0x0002
#define VCD_PAUSED           0x0004
#define VCD_SKIP_F           0x0008
#define VCD_SKIP_B           0x0010
#define VCD_FF               0x0020
#define VCD_RW               0x0040
#define VCD_SEEKING          (VCD_FF | VCD_RW)
#define VCD_LOADED           0x0080
#define VCD_NO_CD            0x0100
#define VCD_DATA_CD_LOADED   0x0200
#define VCD_EDITING          0x0400
#define VCD_PAUSED_AND_MOVED 0x0800
#define VCD_PLAY_PENDING     0x1000
#define VCD_WAS_PLAYING      0x2000
#define VCD_IN_USE           0x4000

enum {PerformanceTimer = 32, StatusTimer = 33};
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\multimedia\dshow\filters\image2\rndless\project.h ===
/******************************Module*Header*******************************\
* Module Name: project.h
*
*  Master header file that includes all the other header files used by the
* project.  This enables compiled headers to work using build.
*
*
* Created: dd-mm-94
* Author:  Stephen Estrop [StephenE]
*
* Copyright (c) 1994 - 1996  Microsoft Corporation.  All Rights Reserved.
\**************************************************************************/

#include "app.h"
#include "vcdplyer.h"
#include "resource.h"


#ifndef __RELEASE_DEFINED
#define __RELEASE_DEFINED
template<typename T>
__inline void RELEASE( T* &p )
{
    if( p ) {
        p->Release();
        p = NULL;
    }
}
#endif

#ifndef CHECK_HR
    #define CHECK_HR(expr) do { if (FAILED(expr)) __leave; } while(0);
#endif



DEFINE_GUID(IID_IDirectDraw7,
            0x15e65ec0,0x3b9c,0x11d2,0xb9,0x2f,0x00,0x60,0x97,0x97,0xea,0x5b);
#if 0
DEFINE_GUID( IID_IDirect3D7,            0xf5049e77,0x4861,0x11d2,0xa4,0x7,0x0,0xa0,0xc9,0x6,0x29,0xa8);
DEFINE_GUID( IID_IDirect3DRGBDevice,    0xA4665C60,0x2673,0x11CF,0xA3,0x1A,0x00,0xAA,0x00,0xB9,0x33,0x56 );
DEFINE_GUID( IID_IDirect3DHALDevice,    0x84E63dE0,0x46AA,0x11CF,0x81,0x6F,0x00,0x00,0xC0,0x20,0x15,0x6E );
#endif


// {B87BEB7B-8D29-423f-AE4D-6582C10175AC}
DEFINE_GUID(CLSID_VideoMixingRenderer,
0xb87beb7b, 0x8d29, 0x423f, 0xae, 0x4d, 0x65, 0x82, 0xc1, 0x1, 0x75, 0xac);


// { fd501041-8ebe-11ce-8183-00aa00577da1 }
DEFINE_GUID(CLSID_BouncingBall,
0xfd501041, 0x8ebe, 0x11ce, 0x81, 0x83, 0x00, 0xaa, 0x00, 0x57, 0x7d, 0xa1);
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\multimedia\dshow\filters\image2\rndless\bltalpha.h ===
#ifndef __INITDDSTRUCT_DEFINED
#define __INITDDSTRUCT_DEFINED
template <typename T>
__inline void INITDDSTRUCT(T& dd)
{
    ZeroMemory(&dd, sizeof(dd));
    dd.dwSize = sizeof(dd);
}
#endif

#ifndef __RELEASE_DEFINED
#define __RELEASE_DEFINED
template<typename T>
__inline void RELEASE( T* &p )
{
    if( p ) {
        p->Release();
        p = NULL;
    }
}
#endif

#ifndef CHECK_HR
    #define CHECK_HR(expr) do { if (FAILED(expr)) __leave; } while(0);
#endif


class CAlphaBlt
{
private:

    LPDIRECTDRAW7               m_pDD;
    LPDIRECT3D7                 m_pD3D;
    LPDIRECT3DDEVICE7           m_pD3DDevice;
    LPDIRECTDRAWSURFACE7        m_lpDDBackBuffer;

    LPDIRECTDRAWSURFACE7        m_lpDDMirror;
    LPDIRECTDRAWSURFACE7        m_lpDDM32;
    LPDIRECTDRAWSURFACE7        m_lpDDM16;
    DDSURFACEDESC2              m_ddsdM32;
    DDSURFACEDESC2              m_ddsdM16;

    bool                        m_fPowerOf2;
    bool                        m_fSquare;

    //
    // IsSurfaceBlendable
    //
    // Checks the DD surface description and the given
    // alpha value to determine if this surface is
    // blendable.
    //
    bool
    IsSurfaceBlendable(
        DDSURFACEDESC2& ddsd,
        BYTE fAlpha
        )
    {
        //
        // Is the blend really a blend ?
        //

        //if (fAlpha == 0 || fAlpha == 255) {
        //    return true;
        //}

        //
        // Is the surface already a D3D texture ?
        //
        if (ddsd.ddsCaps.dwCaps & DDSCAPS_TEXTURE) {
            return true;
        }

        //
        // OK we have to mirror the surface
        //

        return false;
    }

    //
    // MirrorSourceSurface
    //
    // The mirror surface cab be either 16 or 32 bit RGB depending
    // upon the format of the source surface.
    //
    // Of course it should have the "texture" flag
    // set and should be in VRAM.  If we can't create the
    // surface then the AlphaBlt should fail
    //
    HRESULT MirrorSourceSurface(
        LPDIRECTDRAWSURFACE7 lpDDS,
        DDSURFACEDESC2& ddsd
        )
    {
        HRESULT hr = DD_OK;
        DWORD dwMirrorBitDepth = 0;
        DDSURFACEDESC2 ddsdMirror;


        //
        // OK - is it suitable for our needs.
        //
        // I use the following rules:
        //  if ddsd is a FOURCC surface the mirror should be 32 bit
        //  if ddsd is RGB then the mirror's bit depth should match
        //      that of ddsd.
        //
        // Also, the mirror must be large enough to actually hold
        // the surface to be blended
        //

        m_lpDDMirror = NULL;

        if (ddsd.ddpfPixelFormat.dwFlags == DDPF_FOURCC ||
            ddsd.ddpfPixelFormat.dwRGBBitCount == 32) {

            if (ddsd.dwWidth > m_ddsdM32.dwWidth ||
                ddsd.dwHeight > m_ddsdM32.dwHeight) {

                RELEASE(m_lpDDM32);
            }

            if (!m_lpDDM32) {
                dwMirrorBitDepth = 32;
            }
            else {
                m_lpDDMirror = m_lpDDM32;
                ddsdMirror = m_ddsdM32;
            }
        }
        else if (ddsd.ddpfPixelFormat.dwRGBBitCount == 16) {

            if (ddsd.dwWidth > m_ddsdM16.dwWidth ||
                ddsd.dwHeight > m_ddsdM16.dwHeight) {

                RELEASE(m_lpDDM16);
            }

            if (!m_lpDDM16) {
                dwMirrorBitDepth = 16;
            }
            else {
                m_lpDDMirror = m_lpDDM16;
                ddsdMirror = m_ddsdM16;
            }
        }
        else {

            // I'm not supporting RGB24 or RGB8 !
            return E_INVALIDARG;
        }

        if (!m_lpDDMirror) {

            INITDDSTRUCT(ddsdMirror);
            ddsdMirror.ddpfPixelFormat.dwSize = sizeof(DDPIXELFORMAT);
            ddsdMirror.ddpfPixelFormat.dwFlags = DDPF_RGB;
            ddsdMirror.ddpfPixelFormat.dwRGBBitCount = dwMirrorBitDepth;

            switch (dwMirrorBitDepth) {
            case 16:
                ddsdMirror.ddpfPixelFormat.dwRBitMask = 0x0000F800;
                ddsdMirror.ddpfPixelFormat.dwGBitMask = 0x000007E0;
                ddsdMirror.ddpfPixelFormat.dwBBitMask = 0x0000001F;
                break;

            case 32:
                ddsdMirror.ddpfPixelFormat.dwRBitMask = 0x00FF0000;
                ddsdMirror.ddpfPixelFormat.dwGBitMask = 0x0000FF00;
                ddsdMirror.ddpfPixelFormat.dwBBitMask = 0x000000FF;
                break;
            }

            ddsdMirror.ddsCaps.dwCaps = DDSCAPS_VIDEOMEMORY | DDSCAPS_TEXTURE;
            ddsdMirror.dwFlags = DDSD_WIDTH | DDSD_HEIGHT | DDSD_CAPS | DDSD_PIXELFORMAT;

            if (m_fPowerOf2) {

                for (ddsdMirror.dwWidth = 1;
                     ddsd.dwWidth > ddsdMirror.dwWidth;
                     ddsdMirror.dwWidth <<= 1);

                for (ddsdMirror.dwHeight = 1;
                     ddsd.dwHeight > ddsdMirror.dwHeight;
                     ddsdMirror.dwHeight <<= 1);
            }
            else {
                ddsdMirror.dwWidth = ddsd.dwWidth;
                ddsdMirror.dwHeight = ddsd.dwHeight;
            }

            if (m_fSquare) {

                if (ddsdMirror.dwHeight > ddsdMirror.dwWidth) {
                    ddsdMirror.dwWidth = ddsdMirror.dwHeight;
                }

                if (ddsdMirror.dwWidth > ddsdMirror.dwHeight) {
                    ddsdMirror.dwHeight = ddsdMirror.dwWidth;
                }
            }

            __try {

                // Attempt to create the surface with theses settings
                CHECK_HR(hr = m_pDD->CreateSurface(&ddsdMirror, &m_lpDDMirror, NULL));

                INITDDSTRUCT(ddsdMirror);
                CHECK_HR(hr =  m_lpDDMirror->GetSurfaceDesc(&ddsdMirror));

                switch (dwMirrorBitDepth) {
                case 16:
                    m_ddsdM16 = ddsdMirror;
                    m_lpDDM16 = m_lpDDMirror;
                    break;

                case 32:
                    m_ddsdM32 = ddsdMirror;
                    m_lpDDM32 = m_lpDDMirror;
                    break;
                }

            } __finally {}
        }

        if (hr == DD_OK) {

            //ASSERT(m_lpDDMirror != NULL);

            __try {
                RECT rc = {0, 0, ddsd.dwWidth, ddsd.dwHeight};
                CHECK_HR(hr = m_lpDDMirror->Blt(&rc, lpDDS, &rc, DDBLT_WAIT, NULL));
                ddsd = ddsdMirror;
            } __finally {}
        }

        return hr;
    }

public:

    ~CAlphaBlt()
    {
        RELEASE(m_lpDDBackBuffer);
        RELEASE(m_lpDDM32);
        RELEASE(m_lpDDM16);

        RELEASE(m_pD3DDevice);
        RELEASE(m_pD3D);
        RELEASE(m_pDD);
    }

    CAlphaBlt(LPDIRECTDRAWSURFACE7 lpDDSDst, HRESULT* phr) :
        m_pDD(NULL),
        m_pD3D(NULL),
        m_pD3DDevice(NULL),
        m_lpDDBackBuffer(NULL),
        m_lpDDMirror(NULL),
        m_lpDDM32(NULL),
        m_lpDDM16(NULL),
        m_fPowerOf2(false),
        m_fSquare(false)
    {

        ZeroMemory(&m_ddsdM32, sizeof(m_ddsdM32));
        ZeroMemory(&m_ddsdM16, sizeof(m_ddsdM16));

        HRESULT hr;
        hr = lpDDSDst->GetDDInterface((LPVOID *)&m_pDD);
        if (FAILED(hr)) {
            m_pDD = NULL;
            *phr = hr;
        }

        if (SUCCEEDED(hr)) {
            hr = m_pDD->QueryInterface(IID_IDirect3D7, (LPVOID *)&m_pD3D);
            if (FAILED(hr)) {
                m_pD3D = NULL;
                *phr = hr;
            }
        }

        if (SUCCEEDED(hr)) {
            hr = m_pD3D->CreateDevice(IID_IDirect3DHALDevice,
                                      lpDDSDst,
                                      &m_pD3DDevice);
            if (FAILED(hr)) {
                m_pD3DDevice = NULL;
                *phr = hr;
            }
            else {
                m_lpDDBackBuffer = lpDDSDst;
                m_lpDDBackBuffer->AddRef();
            }
        }

        if (SUCCEEDED(hr)) {

            D3DDEVICEDESC7 ddDesc;
            if (DD_OK == m_pD3DDevice->GetCaps(&ddDesc)) {

                if (ddDesc.dpcTriCaps.dwTextureCaps & D3DPTEXTURECAPS_POW2) {
                    m_fPowerOf2 = true;
                }

                if (ddDesc.dpcTriCaps.dwTextureCaps & D3DPTEXTURECAPS_SQUAREONLY) {
                    m_fSquare = true;
                }
            }
            else {
                *phr = hr;
            }
        }
    }

    HRESULT
    AlphaBlt(RECT* lpDst,
             LPDIRECTDRAWSURFACE7 lpDDSSrc,
             RECT* lpSrc,
             BYTE  bAlpha
             )
    {
        HRESULT hr;
        DDSURFACEDESC2 ddsd;

        struct {
            float x, y, z, rhw;
            D3DCOLOR clr;
            float tu, tv;
        } pVertices[4];

        __try {

            INITDDSTRUCT(ddsd);
            CHECK_HR(hr = lpDDSSrc->GetSurfaceDesc(&ddsd));

            if (!IsSurfaceBlendable(ddsd, bAlpha)) {
                CHECK_HR(hr = MirrorSourceSurface(lpDDSSrc, ddsd));
                lpDDSSrc = m_lpDDMirror;
            }

            float fWid = (float)ddsd.dwWidth;
            float fHgt = (float)ddsd.dwHeight;

            BYTE alpha = bAlpha;

            //
            // Setup the DST info
            //
            pVertices[0].x = (float)lpDst->left;
            pVertices[0].y = (float)lpDst->top;
            pVertices[0].z = 0.5f;
            pVertices[0].rhw = 2.0f;
            pVertices[0].clr = RGBA_MAKE(0xff, 0xff, 0xff, alpha);

            pVertices[1].x = (float)lpDst->right;
            pVertices[1].y = (float)lpDst->top;
            pVertices[1].z = 0.5f;
            pVertices[1].rhw = 2.0f;
            pVertices[1].clr = RGBA_MAKE(0xff, 0xff, 0xff, alpha);

            pVertices[2].x = (float)lpDst->left;
            pVertices[2].y = (float)lpDst->bottom;
            pVertices[2].z = 0.5f;
            pVertices[2].rhw = 2.0f;
            pVertices[2].clr = RGBA_MAKE(0xff, 0xff, 0xff, alpha);

            pVertices[3].x = (float)lpDst->right;
            pVertices[3].y = (float)lpDst->bottom;
            pVertices[3].z = 0.5f;
            pVertices[3].rhw = 2.0f;
            pVertices[3].clr = RGBA_MAKE(0xff, 0xff, 0xff, alpha);

            //
            // Setup the SRC info
            //
            pVertices[0].tu = (float)lpSrc->left / fWid;
            pVertices[0].tv = (float)lpSrc->top / fHgt;

            pVertices[1].tu = (float)lpSrc->right / fWid;
            pVertices[1].tv = (float)lpSrc->top / fHgt;

            pVertices[2].tu = (float)lpSrc->left / fWid;
            pVertices[2].tv = (float)lpSrc->bottom / fHgt;

            pVertices[3].tu = (float)lpSrc->right / fWid;
            pVertices[3].tv = (float)lpSrc->bottom / fHgt;

            //
            // Setup some random D3D stuff
            //
            m_pD3DDevice->SetTexture(0, lpDDSSrc);
            m_pD3DDevice->SetRenderState(D3DRENDERSTATE_CULLMODE, D3DCULL_NONE);
            m_pD3DDevice->SetRenderState(D3DRENDERSTATE_LIGHTING, FALSE);
            m_pD3DDevice->SetRenderState(D3DRENDERSTATE_BLENDENABLE, TRUE);
            m_pD3DDevice->SetRenderState(D3DRENDERSTATE_SRCBLEND, D3DBLEND_SRCALPHA);
            m_pD3DDevice->SetRenderState(D3DRENDERSTATE_DESTBLEND, D3DBLEND_INVSRCALPHA);

            // use diffuse alpha from vertices, not texture alpha
            // m_pD3DDevice->SetTextureStageState(0, D3DTSS_ALPHAARG1, D3DTA_DIFFUSE);
            m_pD3DDevice->SetTextureStageState(0, D3DTSS_ALPHAARG1, D3DTA_TEXTURE);

            //
            // Do the alpha BLT
            //
            CHECK_HR(hr = m_pD3DDevice->BeginScene());
            CHECK_HR(hr = m_pD3DDevice->DrawPrimitive(D3DPT_TRIANGLESTRIP,
                                                    D3DFVF_XYZRHW | D3DFVF_DIFFUSE | D3DFVF_TEX1,
                                                    pVertices, 4, D3DDP_WAIT));
            CHECK_HR(hr = m_pD3DDevice->EndScene());

        } __finally {
            m_pD3DDevice->SetTexture(0, NULL);
        }

        return hr;
    }

    bool TextureSquare() {
        return  m_fSquare;
    }

    bool TexturePower2() {
        return  m_fPowerOf2;
    }
};
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\multimedia\dshow\filters\image2\rndless\allocpresenter.cpp ===
/******************************Module*Header*******************************\
* Module Name: ap.cpp
*
*
* Custom allocator Presenter
*
* Created: Sat 04/08/2000
* Author:  Stephen Estrop [StEstrop]
*
* Copyright (c) 2000 Microsoft Corporation
\**************************************************************************/
#include <streams.h>
#include <mmreg.h>
#include "project.h"
#include <stdarg.h>
#include <stdio.h>
#include <math.h>
#include <initguid.h>


// {99d54f63-1a69-41ae-aa4d-c976eb3f0713}
DEFINE_GUID(CLSID_AllocPresenter,
            0x99d54f63, 0x1a69, 0x41ae,
            0xaa, 0x4d, 0xc9, 0x76, 0xeb, 0x3f, 0x07, 0x13);

template <typename T>
__inline void INITDDSTRUCT(T& dd)
{
    ZeroMemory(&dd, sizeof(dd));
    dd.dwSize = sizeof(dd);
}


/*****************************Private*Routine******************************\
* CreateDefaultAllocatorPresenter
*
*
*
* History:
* Wed 08/30/2000 - StEstrop - Created
*
\**************************************************************************/
HRESULT
CMpegMovie::CreateDefaultAllocatorPresenter()
{
    HRESULT hr = S_OK;

    __try {
        CHECK_HR(hr = CoCreateInstance(CLSID_AllocPresenter, NULL,
                              CLSCTX_INPROC_SERVER,
                              IID_IVMRSurfaceAllocator,
                              (LPVOID*)&m_lpDefSA));

        CHECK_HR(hr = m_lpDefSA->QueryInterface(IID_IVMRImagePresenter,
                                                (LPVOID*)&m_lpDefIP));

        CHECK_HR(hr = m_lpDefSA->QueryInterface(IID_IVMRWindowlessControl,
                                                (LPVOID*)&m_lpDefWC));

        CHECK_HR(hr = m_lpDefWC->SetVideoClippingWindow(m_hwndApp));
        CHECK_HR(hr = m_lpDefSA->AdviseNotify(this));
    }
    __finally {

        if (FAILED(hr)) {
            RELEASE(m_lpDefWC);
            RELEASE(m_lpDefIP);
            RELEASE(m_lpDefSA);
        }
    }

    return hr;
}



/******************************Public*Routine******************************\
* NonDelegatingQueryInterface
*
*
*
* History:
* Sat 04/08/2000 - StEstrop - Created
*
\**************************************************************************/
STDMETHODIMP
CMpegMovie::NonDelegatingQueryInterface(
    REFIID riid,
    void** ppv
    )
{
    if (riid == IID_IVMRSurfaceAllocator) {
        return GetInterface((IVMRSurfaceAllocator*)this, ppv);
    }
    else if (riid == IID_IVMRImagePresenter) {
        return GetInterface((IVMRImagePresenter*)this, ppv);
    }

    return CUnknown::NonDelegatingQueryInterface(riid,ppv);
}




//////////////////////////////////////////////////////////////////////////////
//
// IVMRSurfaceAllocator
//
//////////////////////////////////////////////////////////////////////////////

/******************************Public*Routine******************************\
* AllocateSurfaces
*
*
*
* History:
* Sat 04/08/2000 - StEstrop - Created
*
\**************************************************************************/
STDMETHODIMP
CMpegMovie::AllocateSurface(
    DWORD_PTR dwUserID,
    VMRALLOCATIONINFO* lpAllocInfo,
    DWORD* lpdwBuffer,
    LPDIRECTDRAWSURFACE7* lplpSurface
    )
{
    return m_lpDefSA->AllocateSurface(dwUserID, lpAllocInfo,
                                      lpdwBuffer, lplpSurface);
}


/******************************Public*Routine******************************\
* FreeSurfaces()
*
*
*
* History:
* Sat 04/08/2000 - StEstrop - Created
*
\**************************************************************************/
STDMETHODIMP
CMpegMovie::FreeSurface(
    DWORD_PTR dwUserID
    )
{
    return m_lpDefSA->FreeSurface(dwUserID);
}



/******************************Public*Routine******************************\
* PrepareSurface
*
*
*
* History:
* Sat 04/08/2000 - StEstrop - Created
*
\**************************************************************************/
STDMETHODIMP
CMpegMovie::PrepareSurface(
    DWORD_PTR dwUserID,
    LPDIRECTDRAWSURFACE7 lplpSurface,
    DWORD dwSurfaceFlags
    )
{
    return m_lpDefSA->PrepareSurface(dwUserID, lplpSurface, dwSurfaceFlags);
}



/******************************Public*Routine******************************\
* AdviseNotify
*
*
*
* History:
* Mon 06/05/2000 - StEstrop - Created
*
\**************************************************************************/
STDMETHODIMP
CMpegMovie::AdviseNotify(
    IVMRSurfaceAllocatorNotify* lpIVMRSurfAllocNotify
    )
{
    return m_lpDefSA->AdviseNotify(lpIVMRSurfAllocNotify);
}


//////////////////////////////////////////////////////////////////////////////
//
// IVMRSurfaceAllocatorNotify
//
//////////////////////////////////////////////////////////////////////////////

/******************************Public*Routine******************************\
* AdviseSurfaceAllocator
*
*
*
* History:
* Thu 08/31/2000 - StEstrop - Created
*
\**************************************************************************/
STDMETHODIMP
CMpegMovie::AdviseSurfaceAllocator(
    DWORD_PTR dwUserID,
    IVMRSurfaceAllocator* lpIVRMSurfaceAllocator
    )
{
    return m_lpDefSAN->AdviseSurfaceAllocator(dwUserID, lpIVRMSurfaceAllocator);
}


/******************************Public*Routine******************************\
* SetDDrawDevice
*
*
*
* History:
* Thu 08/31/2000 - StEstrop - Created
*
\**************************************************************************/
STDMETHODIMP
CMpegMovie::SetDDrawDevice(LPDIRECTDRAW7 lpDDrawDevice,HMONITOR hMonitor)
{
//  HRESULT hr = OnSetDDrawDevice(lpDDrawDevice, hMonitor);
//  m_bFullScreenPoss = SUCCEEDED(hr);

    return m_lpDefSAN->SetDDrawDevice(lpDDrawDevice, hMonitor);
}


/******************************Public*Routine******************************\
* ChangeDDrawDevice
*
*
*
* History:
* Thu 08/31/2000 - StEstrop - Created
*
\**************************************************************************/
STDMETHODIMP
CMpegMovie::ChangeDDrawDevice(LPDIRECTDRAW7 lpDDrawDevice,HMONITOR hMonitor)
{
//  HRESULT hr = OnSetDDrawDevice(lpDDrawDevice, hMonitor);
//  m_bFullScreenPoss = SUCCEEDED(hr);

    return m_lpDefSAN->ChangeDDrawDevice(lpDDrawDevice, hMonitor);
}

/*****************************Private*Routine******************************\
* DDSurfEnumFunc
*
*
*
* History:
* Wed 09/13/2000 - StEstrop - Created
*
\**************************************************************************/
HRESULT WINAPI
DDSurfEnumFunc(
    LPDIRECTDRAWSURFACE7 pdds,
    DDSURFACEDESC2* pddsd,
    void* lpContext
    )
{
    LPDIRECTDRAWSURFACE7* ppdds = (LPDIRECTDRAWSURFACE7*)lpContext;

    DDSURFACEDESC2 ddsd;
    INITDDSTRUCT(ddsd);

    HRESULT hr = pdds->GetSurfaceDesc(&ddsd);
    if (SUCCEEDED(hr)) {

        if (ddsd.ddsCaps.dwCaps & DDSCAPS_PRIMARYSURFACE) {
            *ppdds = pdds;
            return DDENUMRET_CANCEL;

        }
    }

    pdds->Release();
    return DDENUMRET_OK;
}

/*****************************Private*Routine******************************\
* OnSetDDrawDevice
*
*
*
* History:
* Wed 10/04/2000 - StEstrop - Created
*
\**************************************************************************/
HRESULT
CMpegMovie::OnSetDDrawDevice(
    LPDIRECTDRAW7 pDD,
    HMONITOR hMon
    )
{
    HRESULT hr = S_OK;

    RELEASE(m_pddsRenderT);
    RELEASE(m_pddsPriText);
    RELEASE(m_pddsPrimary);

    __try {

        DDSURFACEDESC2 ddsd;  // A surface description structure
        INITDDSTRUCT(ddsd);
        ddsd.dwFlags = DDSD_CAPS;
        ddsd.ddsCaps.dwCaps = DDSCAPS_PRIMARYSURFACE;

        CHECK_HR(hr = pDD->EnumSurfaces(DDENUMSURFACES_DOESEXIST |
                                        DDENUMSURFACES_ALL,
                                        &ddsd,
                                        &m_pddsPrimary,
                                        DDSurfEnumFunc));
        if (!m_pddsPrimary) {
            hr = E_FAIL;
            __leave;
        }

        MONITORINFOEX miInfoEx;
        miInfoEx.cbSize = sizeof(miInfoEx);
        GetMonitorInfo(hMon, &miInfoEx);

        INITDDSTRUCT(ddsd);
        ddsd.dwFlags = DDSD_CAPS | DDSD_HEIGHT | DDSD_WIDTH;
        ddsd.ddsCaps.dwCaps = DDSCAPS_OFFSCREENPLAIN;
        ddsd.dwWidth = (miInfoEx.rcMonitor.right - miInfoEx.rcMonitor.left);
        ddsd.dwHeight = (miInfoEx.rcMonitor.bottom - miInfoEx.rcMonitor.top);

        CHECK_HR(hr = pDD->CreateSurface(&ddsd, &m_pddsPriText, NULL));
        CHECK_HR(hr = pDD->CreateSurface(&ddsd, &m_pddsRenderT, NULL));

    }
    __finally {

        if (FAILED(hr)) {
            RELEASE(m_pddsRenderT);
            RELEASE(m_pddsPriText);
            RELEASE(m_pddsPrimary);
        }
    }

    return hr;
}

/******************************Public*Routine******************************\
* RestoreDDrawSurfaces
*
*
*
* History:
* Thu 11/02/2000 - StEstrop - Created
*
\**************************************************************************/
STDMETHODIMP CMpegMovie::RestoreDDrawSurfaces()
{
    return m_lpDefSAN->RestoreDDrawSurfaces();
}

/******************************Public*Routine******************************\
* RestoreDDrawSurfaces
*
*
*
* History:
* Thu 08/31/2000 - StEstrop - Created
*
\**************************************************************************/
STDMETHODIMP
CMpegMovie::NotifyEvent(LONG EventCode, LONG_PTR lp1, LONG_PTR lp2)
{
    return m_lpDefSAN->NotifyEvent(EventCode, lp1, lp2);
}


/******************************Public*Routine******************************\
* SetBorderColor
*
*
*
* History:
* Thu 11/02/2000 - StEstrop - Created
*
\**************************************************************************/
STDMETHODIMP
CMpegMovie::SetBorderColor(
    COLORREF clr
    )
{
    return m_lpDefSAN->SetBorderColor(clr);
}



//////////////////////////////////////////////////////////////////////////////
//
// IVMRImagePresenter
//
//////////////////////////////////////////////////////////////////////////////

/******************************Public*Routine******************************\
* StartPresenting()
*
*
*
* History:
* Sat 04/08/2000 - StEstrop - Created
*
\**************************************************************************/
STDMETHODIMP
CMpegMovie::StartPresenting(DWORD_PTR dwUserID)
{
    return m_lpDefIP->StartPresenting(dwUserID);
}


/******************************Public*Routine******************************\
* StopPresenting()
*
*
*
* History:
* Sat 04/08/2000 - StEstrop - Created
*
\**************************************************************************/
STDMETHODIMP
CMpegMovie::StopPresenting(DWORD_PTR dwUserID)
{
    return m_lpDefIP->StopPresenting(dwUserID);
}


/******************************Public*Routine******************************\
* PresentImage
*
*
*
* History:
* Sat 04/08/2000 - StEstrop - Created
*
\**************************************************************************/
STDMETHODIMP
CMpegMovie::PresentImage(
    DWORD_PTR dwUserID,
    VMRPRESENTATIONINFO* lpPresInfo
    )
{
#if 0
    LPDIRECTDRAWSURFACE7 lpSurface = lpPresInfo->lpSurf;
    const REFERENCE_TIME rtNow = lpPresInfo->rtStart;
    const DWORD dwSurfaceFlags = lpPresInfo->dwFlags;

    if (m_iDuration > 0) {

        HRESULT hr;

        RECT rs, rd;

        DDSURFACEDESC2 ddsdV;
        INITDDSTRUCT(ddsdV);
        hr = lpSurface->GetSurfaceDesc(&ddsdV);


        DDSURFACEDESC2 ddsdP;
        INITDDSTRUCT(ddsdP);
        hr = m_pddsPriText->GetSurfaceDesc(&ddsdP);

        FLOAT fPos = (FLOAT)m_iDuration / 30.0F;
        FLOAT fPosInv = 1.0F - fPos;

        SetRect(&rs, 0, 0,
                MulDiv((int)ddsdV.dwWidth, 30 - m_iDuration, 30),
                ddsdV.dwHeight);

        SetRect(&rd, 0, 0,
                MulDiv((int)ddsdP.dwWidth, 30 - m_iDuration, 30),
                ddsdP.dwHeight);

        hr = m_pddsRenderT->Blt(&rd, lpSurface,
                                &rs, DDBLT_WAIT, NULL);

        SetRect(&rs, 0, 0,
                MulDiv((int)ddsdP.dwWidth, m_iDuration, 30),
                ddsdP.dwHeight);

        SetRect(&rd,
                (int)ddsdP.dwWidth - MulDiv((int)ddsdP.dwWidth, m_iDuration, 30),
                0,
                ddsdP.dwWidth,
                ddsdP.dwHeight);

        hr = m_pddsRenderT->Blt(&rd, m_pddsPriText,
                                &rs, DDBLT_WAIT, NULL);

        //
        // need to wait for VBlank before blt-ing
        //
        {
            LPDIRECTDRAW lpdd;
            hr = m_pddsPrimary->GetDDInterface((LPVOID*)&lpdd);
            if (SUCCEEDED(hr)) {

                DWORD dwScanLine;
                for (; ; ) {

                    hr = lpdd->GetScanLine(&dwScanLine);

                    if (hr ==  DDERR_VERTICALBLANKINPROGRESS) {
                        break;
                    }

                    if (FAILED(hr)) {
                        break;
                    }

                    if ((LONG)dwScanLine>= rd.top) {
                        if ((LONG)dwScanLine <= rd.bottom) {
                            continue;
                        }
                    }

                    break;
                }

                RELEASE(lpdd);
            }
        }

        hr = m_pddsPrimary->Blt(NULL, m_pddsRenderT,
                                NULL, DDBLT_WAIT, NULL);

        m_iDuration--;
        if (m_iDuration == 0 && (ddsdV.ddsCaps.dwCaps & DDSCAPS_OVERLAY))
        {
            // need to get the color key visible again.
            InvalidateRect(m_hwndApp, NULL, FALSE);
        }
        return hr;
    }
    else
    {
        return m_lpDefIP->PresentImage(dwUserID, lpPresInfo);
    }
#endif

    return m_lpDefIP->PresentImage(dwUserID, lpPresInfo);
}
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\multimedia\dshow\filters\image2\rndless\commands.cpp ===
/******************************Module*Header*******************************\
* Module Name: commands.cpp
*
*  Processes commands from the user.
*
*
* Created: dd-mm-94
* Author:  Stephen Estrop [StephenE]
*
* Copyright (c) 1994 - 1999  Microsoft Corporation.  All Rights Reserved.
\**************************************************************************/
#include <streams.h>
#include <mmreg.h>
#include <commctrl.h>

#include "project.h"
#include <stdio.h>


void RepositionMovie(HWND hwnd);

extern TCHAR       g_achFileName[];
extern CMpegMovie  *pMpegMovie;


/******************************Public*Routine******************************\
* ProcessOpen
*
*
*
* History:
* dd-mm-95 - StephenE - Created
*
\**************************************************************************/
void
ProcessOpen(
    TCHAR *achFileName,
    BOOL bPlay
    )
{
    /*
    ** If we currently have a video loaded we need to discard it here.
    */
    if ( g_State & VCD_LOADED) {
        VcdPlayerCloseCmd();
    }

    lstrcpy(g_achFileName, achFileName);

    pMpegMovie = new CMpegMovie(hwndApp);
    if (pMpegMovie) {

        HRESULT hr = pMpegMovie->OpenMovie(g_achFileName);
        if (SUCCEEDED(hr)) {

            TCHAR achTmp[MAX_PATH];
            LONG  x, y, cx, cy;

            wsprintf(achTmp, IdStr(STR_APP_TITLE_LOADED), g_achFileName );
            g_State = (VCD_LOADED | VCD_STOPPED);

            RepositionMovie(hwndApp);
            InvalidateRect(hwndApp, NULL, TRUE);

            if (bPlay) {
                pMpegMovie->PlayMovie();
            }
        }
        else {
            MessageBox(hwndApp,
                       TEXT("Failed to open the movie; "),
                       IdStr(STR_APP_TITLE), MB_OK );

            pMpegMovie->CloseMovie();
            delete pMpegMovie;
            pMpegMovie = NULL;
        }
    }

    InvalidateRect( hwndApp, NULL, FALSE );
    UpdateWindow( hwndApp );
}


/******************************Public*Routine******************************\
* VcdPlayerOpenCmd
*
*
*
* History:
* dd-mm-94 - StephenE - Created
*
\**************************************************************************/
BOOL
VcdPlayerOpenCmd(
    void
    )
{
    static OPENFILENAME ofn;
    static BOOL fFirstTime = TRUE;
    BOOL fRet;
    TCHAR achFileName[MAX_PATH];
    TCHAR achFilter[MAX_PATH];
    LPTSTR lp;

    if (fFirstTime) {

        ofn.lStructSize = sizeof(ofn);
        ofn.hwndOwner = hwndApp;
        ofn.Flags = OFN_HIDEREADONLY | OFN_FILEMUSTEXIST |
                    OFN_SHAREAWARE | OFN_PATHMUSTEXIST;
    }

    lstrcpy(achFilter, IdStr(STR_FILE_FILTER) );
    ofn.lpstrFilter = achFilter;

    /*
    ** Convert the resource string into to something suitable for
    ** GetOpenFileName ie.  replace '#' characters with '\0' characters.
    */
    for (lp = achFilter; *lp; lp++ ) {
        if (*lp == TEXT('#')) {
            *lp = TEXT('\0');
        }
    }

    ofn.lpstrFile = achFileName;
    ofn.nMaxFile = sizeof(achFileName) / sizeof(TCHAR);
    ZeroMemory(achFileName, sizeof(achFileName));

    fRet = GetOpenFileName(&ofn);
    if ( fRet ) {

        fFirstTime = FALSE;
        ProcessOpen(achFileName);

    }

    return fRet;
}


/******************************Public*Routine******************************\
* VcdPlayerCloseCmd
*
*
*
* History:
* dd-mm-94 - StephenE - Created
*
\**************************************************************************/
BOOL
VcdPlayerCloseCmd(
    void
    )
{
    if (pMpegMovie) {

        LONG cx, cy;

        g_State = VCD_NO_CD;
        pMpegMovie->StopMovie();
        pMpegMovie->CloseMovie();

        delete pMpegMovie;
        pMpegMovie = NULL;
    }
    InvalidateRect( hwndApp, NULL, FALSE );
    UpdateWindow( hwndApp );
    return TRUE;
}

/******************************Public*Routine******************************\
* VcdPlayerPlayCmd
*
*
*
* History:
* dd-mm-94 - StephenE - Created
*
\**************************************************************************/
BOOL
VcdPlayerPlayCmd(
    void
    )
{
    BOOL fStopped = (g_State & VCD_STOPPED);
    BOOL fPaused  = (g_State & VCD_PAUSED);

    if ( (fStopped || fPaused) ) {

        if (pMpegMovie) {
            pMpegMovie->PlayMovie();
        }

        g_State &= ~(fStopped ? VCD_STOPPED : VCD_PAUSED);
        g_State |= VCD_PLAYING;
    }

    return TRUE;
}


/******************************Public*Routine******************************\
* VcdPlayerStopCmd
*
*
*
* History:
* dd-mm-94 - StephenE - Created
*
\**************************************************************************/
BOOL
VcdPlayerStopCmd(
    void
    )
{
    BOOL fPlaying = (g_State & VCD_PLAYING);
    BOOL fPaused  = (g_State & VCD_PAUSED);

    if ( (fPlaying || fPaused) ) {

        if (pMpegMovie) {
            pMpegMovie->StopMovie();
        }

        g_State &= ~(fPlaying ? VCD_PLAYING : VCD_PAUSED);
        g_State |= VCD_STOPPED;
    }
    return TRUE;
}


/******************************Public*Routine******************************\
* VcdPlayerPauseCmd
*
*
*
* History:
* dd-mm-94 - StephenE - Created
*
\**************************************************************************/
BOOL
VcdPlayerPauseCmd(
    void
    )
{
    BOOL fPlaying = (g_State & VCD_PLAYING);
    BOOL fPaused  = (g_State & VCD_PAUSED);

    if (fPlaying) {

        if (pMpegMovie) {
            pMpegMovie->PauseMovie();
        }

        g_State &= ~VCD_PLAYING;
        g_State |= VCD_PAUSED;
    }
    else if (fPaused) {

        if (pMpegMovie) {
            pMpegMovie->PlayMovie();
        }

        g_State &= ~VCD_PAUSED;
        g_State |= VCD_PLAYING;
    }

    return TRUE;
}
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\multimedia\dshow\filters\image2\rndless\app.cpp ===
/******************************Module*Header*******************************\
* Module Name: app.cpp
*
* A simple Video CD player
*
*
* Created: dd-mm-94
* Author:  Stephen Estrop [StephenE]
*
* Copyright (c) 1994 - 1999  Microsoft Corporation.  All Rights Reserved.
\**************************************************************************/
#include <streams.h>
#include <atlbase.h>
#include <atlconv.cpp>
#include <mmreg.h>
#include <commctrl.h>

#include <initguid.h>
#include "project.h"

#include <stdarg.h>
#include <stdio.h>

#include <initguid.h>

/* -------------------------------------------------------------------------
** Global variables that are initialized at run time and then stay constant.
** -------------------------------------------------------------------------
*/
HINSTANCE           hInst;
HICON               hIconVideoCd;
HWND                hwndApp;
HWND                g_hwndToolbar;
CMpegMovie          *pMpegMovie;



/* -------------------------------------------------------------------------
** True Globals - these may change during execution of the program.
** -------------------------------------------------------------------------
*/
TCHAR               g_achFileName[MAX_PATH];
DWORD               g_State = VCD_NO_CD;



/* -------------------------------------------------------------------------
** Constants
** -------------------------------------------------------------------------
*/
const TCHAR szClassName[] = TEXT("SJE_VCDPlayer_CLASS");
const TCHAR g_szNULL[]    = TEXT("\0");
const TCHAR g_szEmpty[]   = TEXT("");


/*
** these values are defined by the UI gods...
*/
      int   dyToolbar;
const int   dxBitmap        = 16;
const int   dyBitmap        = 15;
const int   dxButtonSep     = 8;
const TCHAR g_chNULL        = TEXT('\0');
const LONG  g_Style         = WS_THICKFRAME | WS_POPUP | WS_CAPTION  |
                              WS_SYSMENU | WS_MINIMIZEBOX | WS_MAXIMIZEBOX |
                              WS_CLIPCHILDREN;


const TBBUTTON tbButtons[DEFAULT_TBAR_SIZE] = {
    { IDX_SEPARATOR,    1,                    0,               TBSTYLE_SEP           },
    { IDX_1,            IDM_MOVIE_PLAY,       TBSTATE_ENABLED, TBSTYLE_BUTTON, 0, 0, 0, -1 },
    { IDX_2,            IDM_MOVIE_PAUSE,      TBSTATE_ENABLED, TBSTYLE_BUTTON, 0, 0, 0, -1 },
    { IDX_3,            IDM_MOVIE_STOP,       TBSTATE_ENABLED, TBSTYLE_BUTTON, 0, 0, 0, -1 },
    { IDX_SEPARATOR,    1,                    0,               TBSTYLE_SEP           },
    { IDX_4,            IDM_FULL_SCREEN,      TBSTATE_ENABLED, TBSTYLE_CHECK,  0, 0, 0, -1 }
};


void
SetFullScreenMode(BOOL bMode);

BOOL
IsFullScreenMode();


/******************************Public*Routine******************************\
* WinMain
*
*
* Windows recognizes this function by name as the initial entry point
* for the program.  This function calls the application initialization
* routine, if no other instance of the program is running, and always
* calls the instance initialization routine.  It then executes a message
* retrieval and dispatch loop that is the top-level control structure
* for the remainder of execution.  The loop is terminated when a WM_QUIT
* message is received, at which time this function exits the application
* instance by returning the value passed by PostQuitMessage().
*
* If this function must abort before entering the message loop, it
* returns the conventional value NULL.
*
*
*
* History:
* dd-mm-94 - StephenE - Created
*
\**************************************************************************/
int PASCAL
WinMain(
    HINSTANCE hInstance,
    HINSTANCE hPrevInstance,
    LPSTR lpCmdLineOld,
    int nCmdShow
    )
{
    USES_CONVERSION;
    LPTSTR lpCmdLine = A2T(lpCmdLineOld);

    HRESULT hres = CoInitialize(NULL);
    if (hres == S_FALSE) {
        CoUninitialize();
    }

    if ( !hPrevInstance ) {
        if ( !InitApplication( hInstance ) ) {
            return FALSE;
        }
    }

    /*
    ** Perform initializations that apply to a specific instance
    */
    if ( !InitInstance( hInstance, nCmdShow ) ) {
        return FALSE;
    }


    /*
    ** Acquire and dispatch messages until a WM_QUIT message is received.
    */
    int iRet = DoMainLoop();
    QzUninitialize();
    return iRet;
}


/*****************************Private*Routine******************************\
* DoMainLoop
*
* Process the main message loop
*
* History:
* dd-mm-94 - StephenE - Created
*
\**************************************************************************/
int
DoMainLoop(
    void
    )
{
    MSG         msg;
    HANDLE      ahObjects[8];;
    int         cObjects;
    HACCEL      haccel = LoadAccelerators(hInst, MAKEINTRESOURCE(IDR_ACCELERATOR));

    //
    // message loop lasts until we get a WM_QUIT message
    // upon which we shall return from the function
    //

    for ( ;; ) {

        if (pMpegMovie != NULL) {
            cObjects = 1;
            ahObjects[0] = pMpegMovie->GetMovieEventHandle();
        }
        else {
            ahObjects[0] = NULL;
            cObjects = 0;
        }

        if (ahObjects[0] == NULL) {
            WaitMessage();
        }
        else {

            //
            // wait for any message sent or posted to this queue
            // or for a graph notification
            //
            DWORD result;

            result = MsgWaitForMultipleObjects(cObjects, ahObjects, FALSE,
                                               INFINITE, QS_ALLINPUT);
            if (result != (WAIT_OBJECT_0 + cObjects)) {

                VideoCd_OnGraphNotify(result - WAIT_OBJECT_0);

                continue;
            }
        }

        //
        // When here, we either have a message or no event handle
        // has been created yet.
        //
        // read all of the messages in this next loop
        // removing each message as we read it
        //

        while (PeekMessage(&msg, NULL, 0, 0, PM_REMOVE)) {

            if (msg.message == WM_QUIT) {
                return (int) msg.wParam;
            }

            if (!TranslateAccelerator(hwndApp, haccel, &msg)) {
                TranslateMessage(&msg);
                DispatchMessage(&msg);
            }
        }
    }

} // DoMainLoop




/*****************************Private*Routine******************************\
* InitApplication(HANDLE)
*
* This function is called at initialization time only if no other
* instances of the application are running.  This function performs
* initialization tasks that can be done once for any number of running
* instances.
*
* In this case, we initialize a window class by filling out a data
* structure of type WNDCLASS and calling the Windows RegisterClass()
* function.  Since all instances of this application use the same window
* class, we only need to do this when the first instance is initialized.
*
* History:
* dd-mm-94 - StephenE - Created
*
\**************************************************************************/
BOOL
InitApplication(
    HINSTANCE hInstance
    )
{
    WNDCLASS  wc;

    /*
    ** Fill in window class structure with parameters that describe the
    ** main window.
    */
    hIconVideoCd     = LoadIcon( hInstance, MAKEINTRESOURCE(IDR_VIDEOCD_ICON) );

    wc.style         = CS_VREDRAW | CS_HREDRAW;
    wc.lpfnWndProc   = VideoCdWndProc;
    wc.cbClsExtra    = 0;
    wc.cbWndExtra    = 0;
    wc.hInstance     = hInstance;
    wc.hIcon         = hIconVideoCd;
    wc.hCursor       = LoadCursor( NULL, IDC_ARROW );
    wc.hbrBackground = (HBRUSH)NULL; // (COLOR_BTNFACE + 1);
    wc.lpszMenuName  = MAKEINTRESOURCE( IDR_MAIN_MENU);
    wc.lpszClassName = szClassName;

    /*
    ** Register the window class and return success/failure code.
    */
    return RegisterClass( &wc );

}


/*****************************Private*Routine******************************\
* InitInstance
*
*
* This function is called at initialization time for every instance of
* this application.  This function performs initialization tasks that
* cannot be shared by multiple instances.
*
* In this case, we save the instance handle in a static variable and
* create and display the main program window.
*
*
* History:
* dd-mm-94 - StephenE - Created
*
\**************************************************************************/
BOOL
InitInstance(
    HINSTANCE hInstance,
    int nCmdShow
    )
{
    HWND    hwnd;
    RECT    rc;
    POINT   pt;

    /*
    ** Save the instance handle in static variable, which will be used in
    ** many subsequence calls from this application to Windows.
    */
    hInst = hInstance;
    rc.left = rc.top = 100;
    rc.bottom = 500;
    rc.right  = 450;

    /*
    ** Create a main window for this application instance.
    */
    hwnd = CreateWindow( szClassName, IdStr(STR_APP_TITLE), g_Style,
                         rc.left, rc.top,
                         rc.right, rc.bottom,
                         NULL, NULL, hInstance, NULL );

    /*
    ** If window could not be created, return "failure"
    */
    if ( NULL == hwnd ) {
        return FALSE;
    }
    hwndApp = hwnd;


    /*
    ** Make the window visible; update its client area; and return "success"
    */
    SetPlayButtonsEnableState();
    ShowWindow( hwnd, nCmdShow );
    UpdateWindow( hwnd );

    return TRUE;
}

/*****************************Private*Routine******************************\
* GetMoviePosition
*
* Place the movie in the centre of the client window.  We do not stretch the
* the movie yet !
*
* History:
* Fri 03/03/2000 - StEstrop - Created
*
\**************************************************************************/
void
GetMoviePosition(
    HWND hwnd,
    long* xPos,
    long* yPos,
    long* pcx,
    long* pcy
    )
{

    RECT rc;

    //GetClientRect(hwnd, &rc);
    GetAdjustedClientRect(&rc);

    *xPos = rc.left;
    *yPos = rc.top;

    *pcx = rc.right - rc.left;
    *pcy = rc.bottom - rc.top;
}


/******************************Public*Routine******************************\
* RepositionMovie
*
*
*
* History:
* Thu 08/31/2000 - StEstrop - Created
*
\**************************************************************************/
void
RepositionMovie(HWND hwnd)
{
    if (pMpegMovie) {
        long xPos, yPos, cx, cy;
        GetMoviePosition(hwnd, &xPos, &yPos, &cx, &cy);
        pMpegMovie->PutMoviePosition(xPos, yPos, cx, cy);
        InvalidateRect(hwnd, NULL, false);
        UpdateWindow(hwnd);
    }
}

/*****************************Private*Routine******************************\
* VideoCd_OnMove
*
*
*
* History:
* Thu 08/31/2000 - StEstrop - Created
*
\**************************************************************************/
void
VideoCd_OnMove(
    HWND hwnd,
    int x,
    int y
    )
{
    if (pMpegMovie) {
        if (pMpegMovie->GetStateMovie() != State_Running) {
            RepositionMovie(hwnd);
        }
    }
}


/******************************Public*Routine******************************\
* VideoCdWndProc
*
*
*
* History:
* dd-mm-94 - StephenE - Created
*
\**************************************************************************/
LRESULT CALLBACK
VideoCdWndProc(
    HWND hwnd,
    UINT message,
    WPARAM wParam,
    LPARAM lParam
    )
{
    switch ( message ) {

    HANDLE_MSG( hwnd, WM_CREATE,            VideoCd_OnCreate );
    HANDLE_MSG( hwnd, WM_PAINT,             VideoCd_OnPaint );
    HANDLE_MSG( hwnd, WM_COMMAND,           VideoCd_OnCommand );
    HANDLE_MSG( hwnd, WM_CLOSE,             VideoCd_OnClose );
    HANDLE_MSG( hwnd, WM_DESTROY,           VideoCd_OnDestroy );
    HANDLE_MSG( hwnd, WM_SIZE,              VideoCd_OnSize );
    HANDLE_MSG( hwnd, WM_SYSCOLORCHANGE,    VideoCd_OnSysColorChange );
    HANDLE_MSG( hwnd, WM_INITMENUPOPUP,     VideoCd_OnInitMenuPopup );
    HANDLE_MSG( hwnd, WM_NOTIFY,            VideoCd_OnNotify );
    HANDLE_MSG( hwnd, WM_KEYUP,             VideoCd_OnKeyUp);
    HANDLE_MSG( hwnd, WM_MOVE,              VideoCd_OnMove );

    case WM_DISPLAYCHANGE:
        {
            if (pMpegMovie) {
                pMpegMovie->DisplayModeChanged();
            }
        }
        break;

    default:
        return DefWindowProc(hwnd, message, wParam, lParam);
    }

    return 0L;
}


/*****************************Private*Routine******************************\
* VideoCd_OnCreate
*
*
*
* History:
* 18-11-93 - StephenE - Created
*
\**************************************************************************/
BOOL
VideoCd_OnCreate(
    HWND hwnd,
    LPCREATESTRUCT lpCreateStruct
    )
{
    RECT rc;
    int Pane[2];

    InitCommonControls();

    /*
    ** Create the toolbar and statusbar.
    */
    g_hwndToolbar = CreateToolbarEx( hwnd,
                                     WS_VISIBLE | WS_CHILD |
                                     TBSTYLE_TOOLTIPS | CCS_NODIVIDER,
                                     ID_TOOLBAR, NUMBER_OF_BITMAPS,
                                     hInst, IDR_TOOLBAR, tbButtons,
                                     DEFAULT_TBAR_SIZE, dxBitmap, dyBitmap,
                                     dxBitmap, dyBitmap, sizeof(TBBUTTON) );

    if ( g_hwndToolbar == NULL ) {
        return FALSE;
    }

    return TRUE;
}

/*****************************Private*Routine******************************\
* VideoCd_OnKeyUp
*
*
*
* History:
* 23/3/1996 - AnthonyP - Created
*
\**************************************************************************/
void
VideoCd_OnKeyUp(
    HWND hwnd,
    UINT vk,
    BOOL fDown,
    int cRepeat,
    UINT flags
    )
{
    // Catch escape sequences to stop fullscreen mode

    if (vk == VK_ESCAPE) {
        if (pMpegMovie) {
            SetFullScreenMode(FALSE);
            SetPlayButtonsEnableState();
        }
    }
}



/*****************************Private*Routine******************************\
* VideoCd_OnPaint
*
*
*
* History:
* 18-11-93 - StephenE - Created
*
\**************************************************************************/
void
VideoCd_OnPaint(
    HWND hwnd
    )
{
    PAINTSTRUCT ps;
    HDC         hdc;
    RECT        rc1;
    RECT        rc2;

    /*
    ** Draw a frame around the movie playback area.
    */
    GetClientRect(hwnd, &rc2);


    hdc = BeginPaint( hwnd, &ps );

    if (pMpegMovie) {

        long xPos, yPos, cx, cy;
        GetMoviePosition(hwnd, &xPos, &yPos, &cx, &cy);
        SetRect(&rc1, xPos, yPos, xPos + cx, yPos + cy);

        HRGN rgnClient = CreateRectRgnIndirect(&rc2);
        HRGN rgnVideo  = CreateRectRgnIndirect(&rc1);
        CombineRgn(rgnClient, rgnClient, rgnVideo, RGN_DIFF);

        HBRUSH hbr = GetSysColorBrush(COLOR_BTNFACE);
        FillRgn(hdc, rgnClient, hbr);
        DeleteObject(hbr);
        DeleteObject(rgnClient);
        DeleteObject(rgnVideo);

        pMpegMovie->RepaintVideo(hwnd, hdc);
    }
    else {
        FillRect(hdc, &rc2, (HBRUSH)(COLOR_BTNFACE + 1));
    }

    EndPaint( hwnd, &ps );
}


/*****************************Private*Routine******************************\
* VideoCd_OnCommand
*
*
*
* History:
* 18-11-93 - StephenE - Created
*
\**************************************************************************/
void
VideoCd_OnCommand(
    HWND hwnd,
    int id,
    HWND hwndCtl,
    UINT codeNotify
    )
{
    switch (id) {

    case IDM_FILE_OPEN:
        VcdPlayerOpenCmd();
        break;

    case IDM_FILE_CLOSE:
        VcdPlayerCloseCmd();
        QzFreeUnusedLibraries();
        break;

    case IDM_FILE_EXIT:
        PostMessage( hwnd, WM_CLOSE, 0, 0L );
        break;

    case IDM_MOVIE_PLAY:
        VcdPlayerPlayCmd();
        break;

    case IDM_MOVIE_STOP:
        VcdPlayerStopCmd();
        break;

    case IDM_MOVIE_PAUSE:
        VcdPlayerPauseCmd();
        break;

    case IDM_FULL_SCREEN:
        if (pMpegMovie) {
            BOOL bFullScreen = (BOOL)SendMessage(g_hwndToolbar,
                                        TB_ISBUTTONCHECKED, IDM_FULL_SCREEN, 0);
            SetFullScreenMode(bFullScreen);
        }
        break;
    }

    SetPlayButtonsEnableState();
}




/******************************Public*Routine******************************\
* VideoCd_OnDestroy
*
*
*
* History:
* dd-mm-93 - StephenE - Created
*
\**************************************************************************/
void
VideoCd_OnDestroy(
    HWND hwnd
    )
{
    PostQuitMessage( 0 );
}




/******************************Public*Routine******************************\
* VideoCd_OnClose
*
*
*
* History:
* dd-mm-93 - StephenE - Created
*
\**************************************************************************/
void
VideoCd_OnClose(
    HWND hwnd
    )
{
    VcdPlayerCloseCmd();
    DestroyWindow( hwnd );
}


/******************************Public*Routine******************************\
* VideoCd_OnSize
*
*
*
* History:
* dd-mm-93 - StephenE - Created
*
\**************************************************************************/
void
VideoCd_OnSize(
    HWND hwnd,
    UINT state,
    int dx,
    int dy
    )
{
    if (IsWindow(g_hwndToolbar)) {
        SendMessage( g_hwndToolbar, WM_SIZE, 0, 0L );
    }

    RepositionMovie(hwnd);
}


/*****************************Private*Routine******************************\
* VideoCd_OnSysColorChange
*
*
*
* History:
* 18-11-93 - StephenE - Created
*
\**************************************************************************/
void
VideoCd_OnSysColorChange(
    HWND hwnd
    )
{
    FORWARD_WM_SYSCOLORCHANGE(g_hwndToolbar, SendMessage);
}




/*****************************Private*Routine******************************\
* VideoCd_OnInitMenuPopup
*
*
*
* History:
* dd-mm-94 - StephenE - Created
*
\**************************************************************************/
void
VideoCd_OnInitMenuPopup(
    HWND hwnd,
    HMENU hMenu,
    UINT item,
    BOOL fSystemMenu
    )
{
    UINT uFlags;

    if (item == 0) { // File menu

        if (g_State & (VCD_IN_USE | VCD_NO_CD | VCD_DATA_CD_LOADED)) {
            uFlags = (MF_BYCOMMAND | MF_GRAYED);
        }
        else {
            uFlags = (MF_BYCOMMAND | MF_ENABLED);
        }
        EnableMenuItem(hMenu, IDM_FILE_CLOSE, uFlags );
    }
}


/*****************************Private*Routine******************************\
* VideoCd_OnGraphNotify
*
* This is where we get any notifications from the filter graph.
*
* History:
* dd-mm-94 - StephenE - Created
*
\**************************************************************************/
void
VideoCd_OnGraphNotify(
    int stream
    )
{
    long    lEventCode;
    HDC     hdc;

    lEventCode = pMpegMovie->GetMovieEventCode();
    switch (lEventCode) {
    case EC_FULLSCREEN_LOST:
        SetPlayButtonsEnableState();
        break;

    case EC_COMPLETE:
    case EC_USERABORT:
    case EC_ERRORABORT:
        VcdPlayerStopCmd();
        SetPlayButtonsEnableState();
        break;

    default:
        break;
    }
}


/*****************************Private*Routine******************************\
* VideoCd_OnNotify
*
* This is where we get the text for the little tooltips
*
* History:
* dd-mm-94 - StephenE - Created
*
\**************************************************************************/
LRESULT
VideoCd_OnNotify(
    HWND hwnd,
    int idFrom,
    NMHDR FAR* pnmhdr
    )
{
    switch (pnmhdr->code) {

    case TTN_NEEDTEXT:
        {
            LPTOOLTIPTEXT   lpTt;

            lpTt = (LPTOOLTIPTEXT)pnmhdr;
            LoadString( hInst, (UINT) lpTt->hdr.idFrom, lpTt->szText,
                        sizeof(lpTt->szText) );
        }
        break;
    }

    return 0;
}


/******************************Public*Routine******************************\
* SetPlayButtonsEnableState
*
* Sets the play buttons enable state to match the state of the current
* cdrom device.  See below...
*
*
*                 VCD Player buttons enable state table
* 
* E=Enabled D=Disabled       Play  Pause  Eject  Stop   Other 
* 
* Disk in use                 D     D      D       D      D   
* 
* No video cd or data cdrom   D     D      E       D      D   
* 
* Video cd (playing)          D     E      E       E      E   
* 
* Video cd (paused)           E     D      E       E      E   
* 
* Video cd (stopped)          E     D      E       D      E   
* 
*
*
* History:
* 18-11-93 - StephenE - Created
*
\**************************************************************************/
void
SetPlayButtonsEnableState(
    void
    )
{
    BOOL    fEnable, fPress;
    BOOL    fVideoCdLoaded;

    /*
    ** Do we have a video cd loaded.
    */
    if (g_State & (VCD_NO_CD | VCD_DATA_CD_LOADED | VCD_IN_USE)) {
        fVideoCdLoaded = FALSE;
    }
    else {
        fVideoCdLoaded = TRUE;
    }


    /*
    ** Do the play button
    */
    if ( fVideoCdLoaded
      && ((g_State & VCD_STOPPED) || (g_State & VCD_PAUSED))) {

        fEnable = TRUE;
    }
    else {
        fEnable = FALSE;
    }
    SendMessage( g_hwndToolbar, TB_ENABLEBUTTON, IDM_MOVIE_PLAY, fEnable );


    /*
    ** Do the stop button
    */
    if ( fVideoCdLoaded
      && ((g_State & VCD_PLAYING) || (g_State & VCD_PAUSED))) {

        fEnable = TRUE;
    }
    else {
        fEnable = FALSE;
    }
    SendMessage( g_hwndToolbar, TB_ENABLEBUTTON, IDM_MOVIE_STOP, fEnable );


    /*
    ** Do the pause button
    */
    if ( fVideoCdLoaded && (g_State & VCD_PLAYING) ) {
        fEnable = TRUE;
    }
    else {
        fEnable = FALSE;
    }
    SendMessage( g_hwndToolbar, TB_ENABLEBUTTON, IDM_MOVIE_PAUSE, fEnable );


    /*
    ** Do the remaining buttons
    */
    /*
    ** Do the fullscreen button
    */
    fPress = (fVideoCdLoaded && IsFullScreenMode());

    SendMessage( g_hwndToolbar, TB_CHECKBUTTON, IDM_FULL_SCREEN, MAKELONG(fPress,0) );
    SendMessage( g_hwndToolbar, TB_ENABLEBUTTON, IDM_FULL_SCREEN, fVideoCdLoaded );

}


/*****************************Private*Routine******************************\
* GetAdjustedClientRect
*
* Calculate the size of the client rect and then adjusts it to take into
* account the space taken by the toolbar and status bar.
*
* History:
* dd-mm-95 - StephenE - Created
*
\**************************************************************************/
void
GetAdjustedClientRect(
    RECT *prc
    )
{
    RECT    rcTool;

    GetClientRect(hwndApp, prc);

    if (IsWindowVisible(g_hwndToolbar)) {
        GetWindowRect(g_hwndToolbar, &rcTool);
        prc->top += (rcTool.bottom - rcTool.top);
    }
}


/******************************Public*Routine******************************\
* IdStr
*
* Loads the given string resource ID into the passed storage.
*
* History:
* 18-11-93 - StephenE - Created
*
\**************************************************************************/
LPCTSTR
IdStr(
    int idResource
    )
{
    static TCHAR    chBuffer[ STR_MAX_STRING_LEN ];

    if (LoadString(hInst, idResource, chBuffer, STR_MAX_STRING_LEN) == 0) {
        return g_szEmpty;
    }

    return chBuffer;

}




BOOL m_bFullScreen = FALSE;
/******************************Public*Routine******************************\
* SetFullScreenMode
*
*
*
* History:
* Thu 08/31/2000 - StEstrop - Created
*
\**************************************************************************/
void
SetFullScreenMode(BOOL bMode)
{
    m_bFullScreen = bMode;

    // Defer until we activate the movie

    if (pMpegMovie->GetStateMovie() != State_Running) {
        if (bMode == TRUE) {
            return;
        }
    }
    static HMENU hMenu;
    static LONG  lStyle;
    static int xs, ys, cxs, cys;

    HDC hdcScreen = GetDC(NULL);
    int cx = GetDeviceCaps(hdcScreen,HORZRES);
    int cy = GetDeviceCaps(hdcScreen,VERTRES);
    ReleaseDC(NULL, hdcScreen);

    pMpegMovie->SetFullScreenMode(bMode);

    if (bMode) {

        hMenu = GetMenu(hwndApp);
        lStyle = GetWindowStyle(hwndApp);

        WINDOWPLACEMENT wp;
        GetWindowPlacement(hwndApp, &wp);
        xs = wp.rcNormalPosition.left;
        ys = wp.rcNormalPosition.top;
        cxs = wp.rcNormalPosition.right - xs;
        cys = wp.rcNormalPosition.bottom - ys;
        ShowWindow(g_hwndToolbar, SW_HIDE);
        SetMenu(hwndApp, NULL);
        SetWindowLong(hwndApp, GWL_STYLE, WS_POPUP | WS_VISIBLE);
        SetWindowPos(hwndApp, HWND_TOP, 0, 0, cx, cy, SWP_NOACTIVATE);
        ShowCursor(FALSE);

    }
    else {
        ShowCursor(TRUE);
        ShowWindow(g_hwndToolbar, SW_SHOW);
        SetMenu(hwndApp, hMenu);
        SetWindowLong(hwndApp, GWL_STYLE, lStyle);
        SetWindowPos(hwndApp, HWND_TOP, xs, ys, cxs, cys, SWP_NOACTIVATE);
    }

}


/******************************Public*Routine******************************\
* IsFullScreenMode()
*
*
*
* History:
* Thu 08/31/2000 - StEstrop - Created
*
\**************************************************************************/
BOOL
IsFullScreenMode()
{
    return m_bFullScreen;
}
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\multimedia\dshow\filters\image2\rndless\vcdplyer.h ===
/******************************Module*Header*******************************\
* Module Name: vcdplyer.h
*
* Function prototype for the Video CD Player application.
*
*
* Created: 15-05-94
* Author:  Stephen Estrop [StephenE]
*
* Copyright (c) 1994 - 1997  Microsoft Corporation.  All Rights Reserved.
\**************************************************************************/
#include <ddraw.h>
#define D3D_OVERLOADS
#include <d3d.h>


/* -------------------------------------------------------------------------
** CMpegMovie - an Mpeg movie playback class.
** -------------------------------------------------------------------------
*/
enum EMpegMovieMode { MOVIE_NOTOPENED = 0x00,
                      MOVIE_OPENED = 0x01,
                      MOVIE_PLAYING = 0x02,
                      MOVIE_STOPPED = 0x03,
                      MOVIE_PAUSED = 0x04 };



#define NUM_CUBE_VERTICES (4*6)

class CMpegMovie :
    public CUnknown,
    public IVMRSurfaceAllocator,
    public IVMRImagePresenter,
    public IVMRSurfaceAllocatorNotify
{

private:
    // Our state variable - records whether we are opened, playing etc.
    EMpegMovieMode  m_Mode;
    HANDLE          m_MediaEvent;
    HWND            m_hwndApp;
    BOOL            m_bFullScreen;
    BOOL            m_bFullScreenPoss;
    int             m_iDuration;
    GUID            m_TimeFormat;

    LPDIRECTDRAWSURFACE7    m_pddsPrimary;
    LPDIRECTDRAWSURFACE7    m_pddsPriText;
    LPDIRECTDRAWSURFACE7    m_pddsRenderT;

    IFilterGraph*               m_Fg;
    IGraphBuilder*              m_Gb;
    IMediaControl*              m_Mc;
    IMediaSeeking*              m_Ms;
    IMediaEvent*                m_Me;


    IVMRSurfaceAllocator*       m_lpDefSA;
    IVMRImagePresenter*         m_lpDefIP;
    IVMRWindowlessControl*      m_lpDefWC;
    IVMRSurfaceAllocatorNotify* m_lpDefSAN;


    HRESULT CreateDefaultAllocatorPresenter();
    HRESULT AddVideoMixingRendererToFG();
    HRESULT OnSetDDrawDevice(LPDIRECTDRAW7 pDD, HMONITOR hMon);

public:
     CMpegMovie(HWND hwndApplication);
    ~CMpegMovie();

    DECLARE_IUNKNOWN
    STDMETHODIMP NonDelegatingQueryInterface(REFIID, void**);

// IVMRSurfaceAllocator
    STDMETHODIMP AllocateSurface(DWORD_PTR dwUserID,
                                VMRALLOCATIONINFO* lpAllocInfo,
                                 DWORD* lpdwActualBackBuffers,
                                 LPDIRECTDRAWSURFACE7* lplpSurface);
    STDMETHODIMP FreeSurface(DWORD_PTR dwUserID);
    STDMETHODIMP PrepareSurface(DWORD_PTR dwUserID,
                                LPDIRECTDRAWSURFACE7 lplpSurface,
                                DWORD dwSurfaceFlags);
    STDMETHODIMP AdviseNotify(IVMRSurfaceAllocatorNotify* lpIVMRSurfAllocNotify);

// IVMRSurfaceAllocatorNotify
    STDMETHODIMP AdviseSurfaceAllocator(DWORD_PTR dwUserID,
                                        IVMRSurfaceAllocator* lpIVRMSurfaceAllocator);
    STDMETHODIMP SetDDrawDevice(LPDIRECTDRAW7 lpDDrawDevice,HMONITOR hMonitor);
    STDMETHODIMP ChangeDDrawDevice(LPDIRECTDRAW7 lpDDrawDevice,HMONITOR hMonitor);
    STDMETHODIMP RestoreDDrawSurfaces();
    STDMETHODIMP NotifyEvent(LONG EventCode, LONG_PTR lp1, LONG_PTR lp2);
    STDMETHODIMP SetBorderColor(COLORREF clr);


// IVMRImagePresenter
    STDMETHODIMP StartPresenting(DWORD_PTR dwUserID);
    STDMETHODIMP StopPresenting(DWORD_PTR dwUserID);
    STDMETHODIMP PresentImage(DWORD_PTR dwUserID,
                              VMRPRESENTATIONINFO* lpPresInfo);


    HRESULT         OpenMovie(TCHAR *lpFileName);
    DWORD           CloseMovie();

    BOOL            PlayMovie();
    BOOL            PauseMovie();
    BOOL            StopMovie();

    OAFilterState   GetStateMovie();

    HANDLE          GetMovieEventHandle();
    long            GetMovieEventCode();

    BOOL            PutMoviePosition(LONG x, LONG y, LONG cx, LONG cy);

    REFTIME         GetDuration();
    REFTIME         GetCurrentPosition();
    BOOL            SeekToPosition(REFTIME rt,BOOL bFlushData);

    BOOL            RepaintVideo(HWND hwnd, HDC hdc);

    void            SetFullScreenMode(BOOL bMode);
    BOOL            IsFullScreenMode();

    void            DisplayModeChanged() {
        if (m_lpDefWC) {
            m_lpDefWC->DisplayModeChanged();
        }
    }

};
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\multimedia\dshow\filters\image2\rndless\vcdplyer.cpp ===
/******************************Module*Header*******************************\
* Module Name: vcdplyer.cpp
*
* A simple Video CD player
*
*
* Created: 30-10-95
* Author:  Stephen Estrop [StephenE]
*
* Copyright (c) 1994 - 1999  Microsoft Corporation.  All Rights Reserved.
\**************************************************************************/
#include <streams.h>
#include <mmreg.h>
#include <commctrl.h>

#include "project.h"

#include <stdarg.h>
#include <stdio.h>

#define MY_USER_ID 0x1234ACDE

/******************************Public*Routine******************************\
* CMpegMovie
*
* Constructors and destructors
*
* History:
* 30-10-95 - StephenE - Created
*
\**************************************************************************/
CMpegMovie::CMpegMovie(HWND hwndApplication)
    : CUnknown(NAME("Allocator Presenter"), NULL),
      m_hwndApp(hwndApplication),
      m_MediaEvent(NULL),
      m_Mode(MOVIE_NOTOPENED),
      m_Fg(NULL),
      m_Gb(NULL),
      m_Mc(NULL),
      m_Ms(NULL),
      m_Me(NULL),
      m_lpDefSAN(NULL),
      m_bFullScreen(FALSE),
      m_bFullScreenPoss(FALSE),
      m_pddsRenderT(NULL),
      m_pddsPriText(NULL),
      m_pddsPrimary(NULL),
      m_iDuration(-1),
      m_TimeFormat(TIME_FORMAT_MEDIA_TIME)
{
    AddRef();
}

CMpegMovie::~CMpegMovie() {
    ;
}

/*****************************Private*Routine******************************\
* SetRenderingMode
*
*
*
* History:
* Wed 08/30/2000 - StEstrop - Created
*
\**************************************************************************/
HRESULT
SetRenderingMode(
    IBaseFilter* pBaseFilter,
    VMRMode mode
    )
{
    IVMRFilterConfig* pConfig;
    HRESULT hr = pBaseFilter->QueryInterface(IID_IVMRFilterConfig,
                                             (LPVOID *)&pConfig);

    if( SUCCEEDED( hr )) {
        pConfig->SetRenderingMode( mode );
        pConfig->Release();
    }
    return hr;
}


/*****************************Private*Routine******************************\
* AddVideoMixingRendererToFG()
*
*
*
* History:
* Sat 04/08/2000 - StEstrop - Created
*
\**************************************************************************/
HRESULT
CMpegMovie::AddVideoMixingRendererToFG()
{
    IBaseFilter* pBF = NULL;
    HRESULT hRes = S_OK;

    __try {
        CHECK_HR(hRes = CoCreateInstance(CLSID_VideoMixingRenderer,
                                NULL, CLSCTX_INPROC,IID_IBaseFilter,
                                (LPVOID *)&pBF));

        CHECK_HR(hRes = m_Fg->AddFilter(pBF, L"Video Mixing Renderer"));
        CHECK_HR(hRes = SetRenderingMode(pBF, VMRMode_Renderless));

        CHECK_HR(hRes = pBF->QueryInterface(IID_IVMRSurfaceAllocatorNotify,
                                (LPVOID *)&m_lpDefSAN));

        CHECK_HR(hRes = CreateDefaultAllocatorPresenter());
        CHECK_HR(hRes = m_lpDefSAN->AdviseSurfaceAllocator(MY_USER_ID, this));
    }
    __finally {
        RELEASE(pBF);
    }

    return hRes;
}



/******************************Public*Routine******************************\
* OpenMovie
*
*
*
* History:
* 30-10-95 - StephenE - Created
*
\**************************************************************************/
HRESULT
CMpegMovie::OpenMovie(
    TCHAR *lpFileName
    )
{
    IUnknown        *pUnk = NULL;
    HRESULT         hres = S_OK;

    WCHAR           FileName[MAX_PATH];

#ifdef UNICODE
    lstrcpy(FileName, lpFileName);
#else
    wsprintfA(FileName, "%hs", lpFileName);
#endif

    __try {
        CHECK_HR(hres = CoCreateInstance(CLSID_FilterGraphNoThread,
                                         NULL, CLSCTX_INPROC,
                                         IID_IUnknown, (LPVOID *)&pUnk));
        m_Mode = MOVIE_OPENED;
        CHECK_HR(hres = pUnk->QueryInterface(IID_IFilterGraph, (LPVOID *)&m_Fg));
        CHECK_HR(hres = AddVideoMixingRendererToFG());
        CHECK_HR(hres = pUnk->QueryInterface(IID_IGraphBuilder, (LPVOID *)&m_Gb));
        CHECK_HR(hres = m_Gb->RenderFile(FileName, NULL));
        CHECK_HR(hres = pUnk->QueryInterface(IID_IMediaControl, (LPVOID *)&m_Mc));

        //
        // Not being able to get the IMediaEvent interface does
        // necessarly mean that we can't play the graph.
        //
        pUnk->QueryInterface(IID_IMediaEvent, (LPVOID *)&m_Me);
        GetMovieEventHandle();
        pUnk->QueryInterface(IID_IMediaSeeking, (LPVOID *)&m_Ms);
    }
    __finally {

        if (FAILED(hres)) {
            RELEASE(m_Ms);
            RELEASE(m_Me);
            RELEASE(m_Mc);
            RELEASE(m_Gb);
            RELEASE(m_Fg);
        }

        RELEASE(pUnk);
    }

    return hres;
}


/******************************Public*Routine******************************\
* CloseMovie
*
*
*
* History:
* 30-10-95 - StephenE - Created
*
\**************************************************************************/
DWORD
CMpegMovie::CloseMovie(
    )
{
    m_Mode = MOVIE_NOTOPENED;
    m_bFullScreen = FALSE;

    RELEASE(m_Mc);
    RELEASE(m_Me);
    RELEASE(m_Ms);
    RELEASE(m_Gb);
    RELEASE(m_Fg);
    RELEASE(m_lpDefWC);
    RELEASE(m_lpDefSA);
    RELEASE(m_lpDefIP);

    return 0L;
}


/******************************Public*Routine******************************\
* RepaintVideo
*
*
*
* History:
* Wed 08/30/2000 - StEstrop - Created
*
\**************************************************************************/
BOOL
CMpegMovie::RepaintVideo(
    HWND hwnd,
    HDC hdc
    )
{
    BOOL bRet = FALSE;
    if (m_lpDefWC) {
        bRet = (m_lpDefWC->RepaintVideo(hwnd, hdc) == S_OK);
    }
    return bRet;
}


/******************************Public*Routine******************************\
* PutMoviePosition
*
*
*
* History:
* dd-mm-95 - StephenE - Created
*
\**************************************************************************/
BOOL
CMpegMovie::PutMoviePosition(
    LONG x,
    LONG y,
    LONG cx,
    LONG cy
    )
{
    RECT rc;
    SetRect(&rc, x, y, x + cx, y + cy);
    BOOL bRet = (m_lpDefWC->SetVideoPosition(NULL, &rc) == S_OK);
    return bRet;
}



/******************************Public*Routine******************************\
* PlayMovie
*
*
*
* History:
* 30-10-95 - StephenE - Created
*
\**************************************************************************/
BOOL
CMpegMovie::PlayMovie(
    )
{
    REFTIME rt;
    REFTIME rtAbs;
    REFTIME rtDur;

    rt = GetCurrentPosition();
    rtDur = GetDuration();

    //
    // If we are near the end of the movie seek to the start, otherwise
    // stay where we are.
    //
    rtAbs = rt - rtDur;
    if (rtAbs < (REFTIME)0) {
        rtAbs = -rtAbs;
    }

    if (rtAbs <= (REFTIME)1) {
        SeekToPosition((REFTIME)0,FALSE);
    }

    //
    // Change mode after setting m_Mode but before starting the graph
    //
    m_Mode = MOVIE_PLAYING;
    m_Mc->Run();
    return TRUE;
}


/******************************Public*Routine******************************\
* PauseMovie
*
*
*
* History:
* 30-10-95 - StephenE - Created
*
\**************************************************************************/
BOOL
CMpegMovie::PauseMovie(
    )
{
    m_Mode = MOVIE_PAUSED;
    m_Mc->Pause();
    return TRUE;
}


/******************************Public*Routine******************************\
* GetStateMovie
*
*
*
* History:
* 15-04-96 - AnthonyP - Created
*
\**************************************************************************/

OAFilterState
CMpegMovie::GetStateMovie(
    )
{
    OAFilterState State;
    m_Mc->GetState(INFINITE,&State);
    return State;
}


/******************************Public*Routine******************************\
* StopMovie
*
*
*
* History:
* dd-mm-95 - StephenE - Created
*
\**************************************************************************/
BOOL
CMpegMovie::StopMovie(
    )
{
    m_Mode = MOVIE_STOPPED;
    m_Mc->Stop();
    return TRUE;
}


/******************************Public*Routine******************************\
* GetMediaEventHandle
*
* Returns the IMediaEvent event hamdle for the filter graph iff the
* filter graph exists.
*
* History:
* 30-10-95 - StephenE - Created
*
\**************************************************************************/
HANDLE
CMpegMovie::GetMovieEventHandle(
    )
{
    HRESULT     hr;

    if (m_Me != NULL) {

        if ( m_MediaEvent == NULL) {
            hr = m_Me->GetEventHandle((OAEVENT *)&m_MediaEvent);
        }
    }
    else {
        m_MediaEvent = NULL;
    }

    return m_MediaEvent;
}


/******************************Public*Routine******************************\
* GetMovieEventCode
*
*
*
* History:
* 30-10-95 - StephenE - Created
*
\**************************************************************************/
long
CMpegMovie::GetMovieEventCode()
{
    HRESULT hr;
    long    lEventCode;
	LONG_PTR	lParam1, lParam2;

    if (m_Me != NULL) {
        hr = m_Me->GetEvent(&lEventCode, &lParam1, &lParam2, 0);
        if (SUCCEEDED(hr)) {
            return lEventCode;
        }
    }

    return 0L;
}


/******************************Public*Routine******************************\
* GetDuration
*
* Returns the duration of the current movie
*
* History:
* 30-10-95 - StephenE - Created
*
\**************************************************************************/
REFTIME
CMpegMovie::GetDuration()
{
    HRESULT hr;
    LONGLONG Duration;

    // Should we seek using IMediaSelection

    if (m_Ms != NULL && m_TimeFormat != TIME_FORMAT_MEDIA_TIME) {
        hr = m_Ms->GetDuration(&Duration);
        if (SUCCEEDED(hr)) {
            return double(Duration);
        }
    } else if (m_Ms != NULL) {
        hr = m_Ms->GetDuration(&Duration);
        if (SUCCEEDED(hr)) {
            return double(Duration) / UNITS;
        }
    }
    return 0;
}


/******************************Public*Routine******************************\
* GetCurrentPosition
*
* Returns the duration of the current movie
*
* History:
* 30-10-95 - StephenE - Created
*
\**************************************************************************/
REFTIME
CMpegMovie::GetCurrentPosition()
{
    REFTIME rt = (REFTIME)0;
    HRESULT hr;
    LONGLONG Position;

    // Should we return a media position

    if (m_Ms != NULL && m_TimeFormat != TIME_FORMAT_MEDIA_TIME) {
        hr = m_Ms->GetPositions(&Position, NULL);
        if (SUCCEEDED(hr)) {
            return double(Position);
        }
    } else if (m_Ms != NULL) {
        hr = m_Ms->GetPositions(&Position, NULL);
        if (SUCCEEDED(hr)) {
            return double(Position) / UNITS;
        }
    }
    return rt;
}


/*****************************Private*Routine******************************\
* SeekToPosition
*
*
*
* History:
* 30-10-95 - StephenE - Created
*
\**************************************************************************/
BOOL
CMpegMovie::SeekToPosition(
    REFTIME rt,
    BOOL bFlushData
    )
{
    HRESULT hr;
    LONGLONG llTime =
        LONGLONG(m_TimeFormat == TIME_FORMAT_MEDIA_TIME ? rt * double(UNITS) : rt);

    if (m_Ms != NULL) {

        FILTER_STATE fs;
        m_Mc->GetState(100, (OAFilterState *)&fs);

        m_Ms->SetPositions(&llTime, AM_SEEKING_AbsolutePositioning, NULL, 0);

        // This gets new data through to the renderers

        if (fs == State_Stopped && bFlushData){
            m_Mc->Pause();
            hr = m_Mc->GetState(INFINITE, (OAFilterState *)&fs);
            m_Mc->Stop();
        }

        if (SUCCEEDED(hr)) {
            return TRUE;
        }
    }
    return FALSE;
}

/******************************Public*Routine******************************\
* SetFullScreenMode
*
*
*
* History:
*  - StEstrop - Created
*
\**************************************************************************/
void
CMpegMovie::SetFullScreenMode(
    BOOL bMode
    )
{
    if (bMode && m_bFullScreenPoss) {
        HRESULT hr = m_pddsPriText->Blt(NULL, m_pddsPrimary,
                                        NULL, DDBLT_WAIT, NULL);
        if (SUCCEEDED(hr)) {
            m_iDuration = 30;
        }
    }
}
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\multimedia\dshow\filters\image2\rndless\resource.h ===
// Copyright (c) 1995 - 1996  Microsoft Corporation.  All Rights Reserved.
//
// These are indexes used by the toolbar.
//
#define IDC_ADEFAULT2                   4013
#define IDC_STATIC                      -1

#define STR_MAX_STRING_LEN      256

#define IDX_SEPARATOR                   -1
#define IDX_1                           0
#define IDX_2                           1
#define IDX_3                           2
#define IDX_4                           3
#define IDX_5                           4
#define IDX_6                           5
#define IDX_7                           6
#define IDX_8                           7
#define IDX_9                           8
#define IDX_10                          9
#define IDX_11                          10
#define DEFAULT_TBAR_SIZE               6
#define NUMBER_OF_BITMAPS               11


#define ID_TOOLBAR                      9
#define ID_TRACKBAR                     10

#define IDR_MAIN_MENU                   101
#define IDR_TOOLBAR                     102
#define IDR_VIDEOCD_ICON                103
#define IDR_ACCELERATOR                 104

#define IDM_FILE_OPEN                   40001
#define IDM_FILE_CLOSE                  40002
#define IDM_FILE_EXIT                   40003



// Toolbar commands
#define IDM_MOVIE_STOP                  40010
#define IDM_MOVIE_PLAY                  40011
#define IDM_MOVIE_PAUSE                 40013
#define IDM_FULL_SCREEN                 40019

#define IDM_MOVIE_ALIGN                 40020



#define MENU_STRING_BASE                1000

        // File
#define STR_FILE_OPEN           IDM_FILE_OPEN  + MENU_STRING_BASE
#define STR_FILE_CLOSE          IDM_FILE_CLOSE + MENU_STRING_BASE
#define STR_FILE_EXIT           IDM_FILE_EXIT  + MENU_STRING_BASE


        // System Menu
#define STR_SYSMENU_RESTORE     1800
#define STR_SYSMENU_MOVE        1801
#define STR_SYSMENU_MINIMIZE    1802
#define STR_SYSMENU_CLOSE       1803
#define STR_SYSMENU_MAXIMIZE    1804
#define STR_SYSMENU_TASK_LIST   1805



#define STR_FILE_FILTER         2000
#define STR_APP_TITLE           2001
#define STR_APP_TITLE_LOADED    2002
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\multimedia\dshow\filters\image2\rndlessplayer\app.h ===
/******************************Module*Header*******************************\
* Module Name: app.h
*
* Function prototype for the Video CD Player application.
*
*
* Created: dd-mm-94
* Author:  Stephen Estrop [StephenE]
*
* Copyright (c) 1994 - 1999  Microsoft Corporation.  All Rights Reserved.
\**************************************************************************/




/* -------------------------------------------------------------------------
** Functions prototypes
** -------------------------------------------------------------------------
*/
int
DoMainLoop(
    void
    );

BOOL
InitApplication(
    HINSTANCE hInstance
    );

BOOL
InitInstance(
    HINSTANCE hInstance,
    int nCmdShow
    );

BOOL
LoadWindowPos(
    LPRECT lprc
    );

BOOL
SaveWindowPos(
    HWND hwnd
    );

void
PatB(
    HDC hdc,
    int x,
    int y,
    int dx,
    int dy,
    DWORD rgb
    );

void
UpdateMpegMovieRect(
    void
    );

void
GetAdjustedClientRect(
    RECT *prc
    );

BOOL
DrawStats(
    HDC hdc
    );

void
CalcMovieRect(
    LPRECT lprc
    );

LPCTSTR
IdStr(
    int idResource
    );

void
UpdateSystemColors(
    void
    );

TCHAR *
FormatRefTime(
    TCHAR *sz,
    REFTIME rt
    );

/* -------------------------------------------------------------------------
** Registry stuff
** -------------------------------------------------------------------------
*/
int
ProfileIntIn(
   const TCHAR *szKey,
   int iDefault
   );

BOOL
ProfileIntOut(
   const TCHAR *szKey,
   int iDefault
   );

void
ProfileStringOut (
    LPTSTR  szKey,
    LPTSTR  sz
    );

UINT
ProfileStringIn (
    LPTSTR  szKey,
    LPTSTR  szDef,
    LPTSTR  sz,
    DWORD   cb
    );

BOOL
LoadWindowPos(
    LPRECT lprc
    );

BOOL
SaveWindowPos(
    HWND hwnd
    );

HKEY
GetAppKey(
    BOOL fCreate
    );


/* -------------------------------------------------------------------------
** Message crackers
** -------------------------------------------------------------------------
*/
/* void Cls_OnUser(HWND hwnd, WPARAM wParam, LPARAM lParam ) */
#define HANDLE_WM_USER(hwnd, wParam, lParam, fn) \
    ((fn)(hwnd, wParam, lParam), 0L)

/* LRESULT Cls_OnNotify(HWND hwnd, int idFrom, NMHDR FAR* pnmhdr); */
#define HANDLE_WM_NOTIFY(hwnd, wParam, lParam, fn) \
    (fn)((hwnd), (int)(wParam), (NMHDR FAR*)(lParam))



/* -------------------------------------------------------------------------
** VideoCd window class prototypes
** -------------------------------------------------------------------------
*/
extern "C" LRESULT CALLBACK
VideoCdWndProc(
    HWND hwnd,
    UINT message,
    WPARAM wParam,
    LPARAM lParam
    );

void
VideoCd_OnClose(
    HWND hwnd
    );

BOOL
VideoCd_OnQueryEndSession(
    HWND hwnd
    );

void
VideoCd_OnDestroy(
    HWND hwnd
    );

void
VideoCd_OnCommand(
    HWND hwnd,
    int id,
    HWND hwndCtl,
    UINT codeNotify
    );

void
VideoCd_OnPaint(
    HWND hwnd
    );

void
VideoCd_OnTimer(
    HWND hwnd,
    UINT id
    );

BOOL
VideoCd_OnCreate(
    HWND hwnd,
    LPCREATESTRUCT lpCreateStruct
    );

void
VideoCd_OnSize(
    HWND hwnd,
    UINT state,
    int cx,
    int cy
    );

void
VideoCd_OnKeyUp(
    HWND hwnd,
    UINT vk,
    BOOL fDown,
    int cRepeat,
    UINT flags
    );

void
VideoCd_OnHScroll(
    HWND hwnd,
    HWND hwndCtl,
    UINT code,
    int pos
    );

void
VideoCd_OnUser(
    HWND hwnd,
    WPARAM wParam,
    LPARAM lParam
    );

void
VideoCd_OnSysColorChange(
    HWND hwnd
    );

void
VideoCd_OnMenuSelect(
    HWND hwnd,
    HMENU hmenu,
    int item,
    HMENU hmenuPopup,
    UINT flags
    );

void
VideoCd_OnInitMenuPopup(
    HWND hwnd,
    HMENU hMenu,
    UINT item,
    BOOL fSystemMenu
    );

#ifdef WM_NOTIFY
LRESULT
VideoCd_OnNotify(
    HWND hwnd,
    int idFrom,
    NMHDR FAR* pnmhdr
    );
#endif


void
VideoCd_OnGraphNotify(
    int stream
    );

void
VideoCd_OnDropFiles(
    HWND hwnd,
    HDROP hdrop);

void
SetPlayButtonsEnableState(
    void
    );



/* -------------------------------------------------------------------------
** Command processing functions
** -------------------------------------------------------------------------
*/

BOOL
VcdPlayerSetLog(
    void
    );

BOOL
VcdPlayerSetPerfLogFile(
    void
    );

BOOL
VcdPlayerOpenCmd(
    void
    );

BOOL
VcdPlayerCloseCmd(
    void
    );

BOOL
VcdPlayerPlayCmd(
    void
    );

BOOL
VcdPlayerStopCmd(
    void
    );

BOOL
VcdPlayerPauseCmd(
    void
    );

BOOL
VcdPlayerPauseCmd(
    void
    );

void
VcdPlayerSeekCmd(
    REFTIME rtSeekBy
    );

void
ProcessOpen(
    TCHAR *achFileName,
    BOOL bPlay = FALSE
    );

/* -------------------------------------------------------------------------
** Recent filename stuff
** -------------------------------------------------------------------------
*/
typedef TCHAR RECENTFILES[MAX_PATH];
#define MAX_RECENT_FILES    5
#define ID_RECENT_FILE_BASE 500

int
GetRecentFiles(
    int LastCount
    );

int
SetRecentFiles(
    TCHAR *FileName,
    int iCount
    );


/* -------------------------------------------------------------------------
** Global Variables
** -------------------------------------------------------------------------
*/
extern int              cxMovie;
extern int              cyMovie;
extern HWND             hwndApp;

extern int              cx;
extern int              cy;
extern int              xOffset;
extern int              yOffset;
extern DWORD            g_State;
extern HANDLE           hRenderLog;
extern LONG             lMovieOrgX, lMovieOrgY;
extern TCHAR            g_szPerfLog[];
extern int              g_TimeFormat;
extern BOOL             g_bUseThreadedGraph;




/* -------------------------------------------------------------------------
** Constants
** -------------------------------------------------------------------------
*/
#define LEFT_MARGIN 0



/* -------------------------------------------------------------------------
** Video CD Player states
**
**  These are bit flags
** -------------------------------------------------------------------------
*/

#define VCD_PLAYING          0x0001
#define VCD_STOPPED          0x0002
#define VCD_PAUSED           0x0004
#define VCD_SKIP_F           0x0008
#define VCD_SKIP_B           0x0010
#define VCD_FF               0x0020
#define VCD_RW               0x0040
#define VCD_SEEKING          (VCD_FF | VCD_RW)
#define VCD_LOADED           0x0080
#define VCD_NO_CD            0x0100
#define VCD_DATA_CD_LOADED   0x0200
#define VCD_EDITING          0x0400
#define VCD_PAUSED_AND_MOVED 0x0800
#define VCD_PLAY_PENDING     0x1000
#define VCD_WAS_PLAYING      0x2000
#define VCD_IN_USE           0x4000

enum {PerformanceTimer = 32, StatusTimer = 33};
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\multimedia\dshow\filters\image2\rndlessplayer\compositor.cpp ===
/******************************Module*Header*******************************\
* Module Name: Compositor.cpp
*
* Creates and manages the composition of 3 DShow FG's.
* The 1st movie is used as a background and must use a H/W overlay, not that
* we draw the color key.
* The other 2 movies are used as textures onto the faces of a rotating cube,
* which is then stretch Blt'ed to opposite corners of the playback window.
*
* Created: Mon 04/17/2000
* Author:  Stephen Estrop [StEstrop]
*
* Copyright (c) 2000 Microsoft Corporation
\**************************************************************************/
#include <streams.h>
#include <mmreg.h>
#include <commctrl.h>

#include "project.h"
#include "mpgcodec.h"

#include <stdarg.h>
#include <stdio.h>


LONG
CCompositor::GetMovieEventCode(int stream)
{
    long code = 0;
    LONG_PTR lParam1, lParam2;

    switch (stream) {
    case 0:
        code = m_pBackground->GetMovieEventCode();
        break;
    case 1:
        code = m_pCube1->GetMovieEventCode();
        break;
    case 2:
        code = m_pCube2->GetMovieEventCode();
        break;
    }

    return code;
}

int
CCompositor::GetNumMovieEventHandle()
{
    return 3;
}

HANDLE*
CCompositor::GetMovieEventHandle()
{
    m_Handles[0] = m_pBackground->GetMovieEventHandle();
    m_Handles[1] = m_pCube1->GetMovieEventHandle();
    m_Handles[2] = m_pCube2->GetMovieEventHandle();
    return m_Handles;
}

HRESULT
CCompositor::PlayMovie()
{
    HRESULT hr = S_OK;
    if (m_pBackground) {
        m_pBackground->PlayMovie();
    }
    else hr = E_FAIL;

    if (SUCCEEDED(hr) && m_pCube1) {
        m_pCube1->PlayMovie();
    }
    else hr = E_FAIL;

    if (SUCCEEDED(hr) && m_pCube2) {
        m_pCube2->PlayMovie();
    }
    else hr = E_FAIL;

    return hr;
}

HRESULT
CCompositor::PauseMovie()
{
    HRESULT hr = S_OK;
    if (m_pBackground) {
        m_pBackground->PauseMovie();
    }
    else hr = E_FAIL;

    if (SUCCEEDED(hr) && m_pCube1) {
        m_pCube1->PauseMovie();
    }
    else hr = E_FAIL;

    if (SUCCEEDED(hr) && m_pCube2) {
        m_pCube2->PauseMovie();
    }
    else hr = E_FAIL;

    return hr;
}

HRESULT
CCompositor::StopMovie()
{
    HRESULT hr = S_OK;
    if (m_pBackground) {
        m_pBackground->StopMovie();
    }
    else hr = E_FAIL;

    if (SUCCEEDED(hr) && m_pCube1) {
        m_pCube1->StopMovie();
    }
    else hr = E_FAIL;

    if (SUCCEEDED(hr) && m_pCube2) {
        m_pCube2->StopMovie();
    }
    else hr = E_FAIL;

    return hr;
}

HRESULT
CCompositor::PutMoviePosition(int xPos, int yPos, int cx, int cy)
{
    HRESULT hr = S_OK;
    if (m_pBackground) {
        m_pBackground->PutMoviePosition(xPos, yPos, cx, cy);
    }
    else hr = E_FAIL;

    if (SUCCEEDED(hr) && m_pCube1) {
        m_pCube1->PutMoviePosition(xPos, yPos, cx, cy);
    }
    else hr = E_FAIL;

    if (SUCCEEDED(hr) && m_pCube2) {
        m_pCube2->PutMoviePosition(xPos, yPos, cx, cy);
    }
    else hr = E_FAIL;

    return hr;
}

HRESULT
CCompositor::OpenComposition()
{
    HRESULT hr = S_OK;
    TCHAR   szMovie[MAX_PATH];

    m_pBackground = new CMpegMovie(m_hwnd, 0);
    if (m_pBackground) {
        GetPrivateProfileString(TEXT("Movies"),
                                TEXT("BkMovie"),
                                TEXT("c:\\movies\\beverly.mpg"),
                                szMovie,
                                MAX_PATH,
                                TEXT("C:\\RndLess.ini"));
        hr = m_pBackground->OpenMovie(szMovie);
    }
    else hr = E_FAIL;

    if (SUCCEEDED(hr)) {
        m_pCube1 = new CMpegMovie(m_hwnd, 1);
        if (m_pCube1) {
            GetPrivateProfileString(TEXT("Movies"),
                                TEXT("Cube1"),
                                TEXT("c:\\movies\\U_MONEY.MPG"),
                                szMovie,
                                MAX_PATH,
                                TEXT("C:\\RndLess.ini"));
            hr = m_pCube1->OpenMovie(szMovie);
        }
        else hr = E_FAIL;
    }

    if (SUCCEEDED(hr)) {
        m_pCube2 = new CMpegMovie(m_hwnd, 2);
        if (m_pCube2) {
            GetPrivateProfileString(TEXT("Movies"),
                                TEXT("Cube2"),
                                TEXT("c:\\movies\\cstr.MPG"),
                                szMovie,
                                MAX_PATH,
                                TEXT("C:\\RndLess.ini"));
            hr = m_pCube2->OpenMovie(szMovie);
        }
        else hr = E_FAIL;
    }

    if (FAILED(hr)) {
        CloseComposition();
    }

    return hr;
}

HRESULT
CCompositor::CloseComposition()
{
    if (m_pBackground) {
        m_pBackground->CloseMovie();
        m_pBackground->Release();
        m_pBackground = NULL;
    }

    if (m_pCube1) {
        m_pCube1->CloseMovie();
        m_pCube1->Release();
        m_pCube1 = NULL;
    }

    if (m_pCube2) {
        m_pCube2->CloseMovie();
        m_pCube2->Release();
        m_pCube2 = NULL;
    }

    return S_OK;
}


HRESULT
CCompositor::RestartStream(
    int stream
    )
{
    switch (stream) {
    case 0:
        m_pBackground->StopMovie();
        m_pBackground->SeekToPosition((REFTIME)0,FALSE);
        m_pBackground->PlayMovie();
        break;
    case 1:
        m_pCube1->StopMovie();
        m_pCube1->SeekToPosition((REFTIME)0,FALSE);
        m_pCube1->PlayMovie();
        break;
    case 2:
        m_pCube2->StopMovie();
        m_pCube2->SeekToPosition((REFTIME)0,FALSE);
        m_pCube2->PlayMovie();
        break;
    }

    return S_OK;
}
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\multimedia\dshow\filters\image2\rndlessplayer\allocpresenter.cpp ===
/******************************Module*Header*******************************\
* Module Name: ap.cpp
*
*
* Custom allocator Presenter
*
* Created: Sat 04/08/2000
* Author:  Stephen Estrop [StEstrop]
*
* Copyright (c) 2000 Microsoft Corporation
\**************************************************************************/
#include <streams.h>
#include <mmreg.h>
#include "project.h"
#include <stdarg.h>
#include <stdio.h>
#include <math.h>


/******************************Public*Routine******************************\
* NonDelegatingQueryInterface
*
*
*
* History:
* Sat 04/08/2000 - StEstrop - Created
*
\**************************************************************************/
STDMETHODIMP
CMpegMovie::NonDelegatingQueryInterface(
    REFIID riid,
    void** ppv
    )
{
    if (riid == IID_IVMRSurfaceAllocator) {

        return GetInterface((IVMRSurfaceAllocator*)this, ppv);
    }
    else if (riid == IID_IVMRImagePresenter) {

        return GetInterface((IVMRImagePresenter*)this, ppv);
    }

    return CUnknown::NonDelegatingQueryInterface(riid,ppv);
}




//////////////////////////////////////////////////////////////////////////////
//
// IVMRSurfaceAllocator
//
//////////////////////////////////////////////////////////////////////////////

/******************************Public*Routine******************************\
* AllocateSurfaces
*
*
*
* History:
* Sat 04/08/2000 - StEstrop - Created
*
\**************************************************************************/
STDMETHODIMP
CMpegMovie::AllocateSurface(
    DWORD dwFlags,
    LPBITMAPINFOHEADER lpHdr,
    LPDDPIXELFORMAT lpPixFmt,
    LPSIZE lpAspectRatio,
    DWORD dwMinBuffers,
    DWORD dwMaxBuffers,
    DWORD* lpdwBuffer,
    LPDIRECTDRAWSURFACE7* lplpSurface
    )
{
    if (!lpHdr) {
        return E_POINTER;
    }

    if (!lpAspectRatio) {
        return E_POINTER;
    }

    if (dwFlags & AMAP_PIXELFORMAT_VALID) {
        if (!lpPixFmt) {
            return E_INVALIDARG;
        }
    }

    if (dwFlags & AMAP_3D_TARGET) {

        lpHdr->biBitCount = m_DispInfo.bmiHeader.biBitCount;
        lpHdr->biCompression = m_DispInfo.bmiHeader.biCompression;

        if (lpHdr->biCompression == BI_BITFIELDS) {

            const DWORD *pMonMasks = GetBitMasks(&m_DispInfo.bmiHeader);
            DWORD *pBitMasks = (DWORD *)((LPBYTE)lpHdr + lpHdr->biSize);
            pBitMasks[0] = pMonMasks[0];
            pBitMasks[1] = pMonMasks[1];
            pBitMasks[2] = pMonMasks[2];
        }
    }

    HRESULT hr = AllocateSurfaceWorker(dwFlags, lpHdr, lpPixFmt,
                                      lpAspectRatio,
                                      dwMinBuffers, dwMaxBuffers,
                                      lpdwBuffer, lplpSurface);
    return hr;
}

/******************************Public*Routine******************************\
* FreeSurfaces()
*
*
*
* History:
* Sat 04/08/2000 - StEstrop - Created
*
\**************************************************************************/
STDMETHODIMP
CMpegMovie::FreeSurface()
{
    if (m_lpDDTexture) {
        m_lpDDTexture->Release();
        m_lpDDTexture = NULL;
    }

    return S_OK;
}


/******************************Public*Routine******************************\
* PrepareSurface
*
*
*
* History:
* Sat 04/08/2000 - StEstrop - Created
*
\**************************************************************************/
STDMETHODIMP
CMpegMovie::PrepareSurface(
    LPDIRECTDRAWSURFACE7 lplpSurface,
    DWORD dwSurfaceFlags
    )
{
    return S_OK;
}

/******************************Public*Routine******************************\
* AdviseNotify
*
*
*
* History:
* Mon 06/05/2000 - StEstrop - Created
*
\**************************************************************************/
STDMETHODIMP
CMpegMovie::AdviseNotify(
    IVMRSurfaceAllocatorNotify* lpIVMRSurfAllocNotify
    )
{
    return E_NOTIMPL;
}


//////////////////////////////////////////////////////////////////////////////
//
// IVMRImagePresenter
//
//////////////////////////////////////////////////////////////////////////////

/******************************Public*Routine******************************\
* StartPresenting()
*
*
*
* History:
* Sat 04/08/2000 - StEstrop - Created
*
\**************************************************************************/
STDMETHODIMP
CMpegMovie::StartPresenting()
{
    return S_OK;
}

/******************************Public*Routine******************************\
* StopPresenting()
*
*
*
* History:
* Sat 04/08/2000 - StEstrop - Created
*
\**************************************************************************/
STDMETHODIMP
CMpegMovie::StopPresenting()
{
    return S_OK;
}

/******************************Public*Routine******************************\
* PresentImage
*
*
*
* History:
* Sat 04/08/2000 - StEstrop - Created
*
\**************************************************************************/
STDMETHODIMP
CMpegMovie::PresentImage(
    LPDIRECTDRAWSURFACE7 lpSurface,
    const REFERENCE_TIME rtNow,
    const DWORD dwSurfaceFlags
    )
{
    //
    // FrameMove (animate) the scene
    //

    FrameMove(m_pD3DDevice, timeGetTime() * 0.0005f);


    //
    // Call the app specific function to render the scene
    //

    Render(m_pD3DDevice);

    RECT rc = {0, 0, 640, 480};

    if (m_bRndLess & 1) {

        int r = m_rcDst.right;
        int b = m_rcDst.bottom;

        rc.left = m_rcDst.left;
        rc.right = (m_rcDst.left + m_rcDst.right) / 2;

        rc.top = m_rcDst.top;
        rc.bottom = (m_rcDst.top + m_rcDst.bottom) / 2;

        m_lpPriSurf->Blt(&rc, m_lpBackBuffer,
                         NULL, DDBLT_WAIT, NULL);

        rc.left = rc.right;
        rc.right = r;

        rc.top = rc.bottom;
        rc.bottom = b;

        m_lpPriSurf->Blt(&rc, m_lpBackBuffer,
                         NULL, DDBLT_WAIT, NULL);
    }
    else {
        int l = m_rcDst.left;
        int b = m_rcDst.bottom;

        rc.left = (m_rcDst.left + m_rcDst.right) / 2;
        rc.right = m_rcDst.right;

        rc.top = m_rcDst.top;
        rc.bottom = (m_rcDst.top + m_rcDst.bottom) / 2;

        m_lpPriSurf->Blt(&rc, m_lpBackBuffer,
                         NULL, DDBLT_WAIT, NULL);

        rc.right = rc.left;
        rc.left = l;

        rc.top = rc.bottom;
        rc.bottom = b;

        m_lpPriSurf->Blt(&rc, m_lpBackBuffer,
                         NULL, DDBLT_WAIT, NULL);
    }

    return S_OK;

}



//////////////////////////////////////////////////////////////////////////////
//
// Allocator Presenter helper functions
//
//////////////////////////////////////////////////////////////////////////////


/*****************************Private*Routine******************************\
* InitDisplayInfo
*
*
*
* History:
* Sat 04/08/2000 - StEstrop - Created
*
\**************************************************************************/
BOOL
InitDisplayInfo(
    AMDISPLAYINFO* lpDispInfo
    )
{
    static char szDisplay[] = "DISPLAY";
    ZeroMemory(lpDispInfo, sizeof(*lpDispInfo));

    HDC hdcDisplay = CreateDCA(szDisplay, NULL, NULL, NULL);
    HBITMAP hbm = CreateCompatibleBitmap(hdcDisplay, 1, 1);

    lpDispInfo->bmiHeader.biSize = sizeof(BITMAPINFOHEADER);
    GetDIBits(hdcDisplay, hbm, 0, 1, NULL, (BITMAPINFO *)lpDispInfo, DIB_RGB_COLORS);
    GetDIBits(hdcDisplay, hbm, 0, 1, NULL, (BITMAPINFO *)lpDispInfo, DIB_RGB_COLORS);

    DeleteObject(hbm);
    DeleteDC(hdcDisplay);

    return TRUE;
}


/*****************************Private*Routine******************************\
* Initialize3DEnvironment
*
*
*
* History:
* Sat 04/08/2000 - StEstrop - Created
*
\**************************************************************************/
HRESULT
CMpegMovie::Initialize3DEnvironment(
    HWND hWnd
    )
{
    HRESULT hr;

    //
    // Create the IDirectDraw interface. The first parameter is the GUID,
    // which is allowed to be NULL. If there are more than one DirectDraw
    // drivers on the system, a NULL guid requests the primary driver. For
    // non-GDI hardware cards like the 3DFX and PowerVR, the guid would need
    // to be explicity specified . (Note: these guids are normally obtained
    // from enumeration, which is convered in a subsequent tutorial.)
    //

    m_hMonitor = MonitorFromWindow(hWnd, MONITOR_DEFAULTTOPRIMARY);

    hr = DirectDrawCreateEx( NULL, (VOID**)&m_lpDDObj, IID_IDirectDraw7, NULL );
    if( FAILED( hr ) )
        return hr;

    {
        // grotesque hack in anticipation of publish/subscribe
        HANDLE hFileMapping = CreateFileMapping( INVALID_HANDLE_VALUE,
            NULL, // security
            PAGE_READWRITE, // protection
            0,
            4096,
            L"nwilt" );
        LPVOID lpv = MapViewOfFile( hFileMapping, FILE_MAP_WRITE, 0, 0, 4 );
        *(LPDIRECTDRAW7 *) lpv = m_lpDDObj;
        UnmapViewOfFile( lpv );
//        CloseHandle( hFileMapping );
    }

    //
    // Query DirectDraw for access to Direct3D
    //
    m_lpDDObj->QueryInterface( IID_IDirect3D7, (VOID**)&m_pD3D );
    if( FAILED( hr) )
        return hr;

    //
    // get the h/w caps for this device
    //
    INITDDSTRUCT(m_ddHWCaps);
    hr = m_lpDDObj->GetCaps(&m_ddHWCaps, NULL);
    if( FAILED( hr) )
        return hr;
    InitDisplayInfo(&m_DispInfo);

    //
    // Set the Windows cooperative level. This is where we tell the system
    // whether wew will be rendering in fullscreen mode or in a window. Note
    // that some hardware (non-GDI) may not be able to render into a window.
    // The flag DDSCL_NORMAL specifies windowed mode. Using fullscreen mode
    // is the topic of a subsequent tutorial. The DDSCL_FPUSETUP flag is a
    // hint to DirectX to optomize floating points calculations. See the docs
    // for more info on this. Note: this call could fail if another application
    // already controls a fu