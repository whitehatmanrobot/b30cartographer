endIO);

 bail:
    RtcpSendIOFree(pRtcpSendIO);

    return((RtcpSendIO_t *)NULL);
}

/*
 * Deinitilize and frees a RtcpSendIO_t structure
 * */
void RtcpSendIOFree(RtcpSendIO_t *pRtcpSendIO)
{
    TraceFunctionName("RtcpSendIOFree");

    if (!pRtcpSendIO)
    {
        /* TODO may be log */
        return;
    }
    
    if (pRtcpSendIO->dwObjectID != OBJECTID_RTCPSENDIO)
    {
        TraceRetail((
                CLASS_ERROR, GROUP_RTCP, S_RTCP_ALLOC,
                _T("%s: pRtcpSendIO[0x%p] Invalid object ID 0x%X != 0x%X"),
                _fname, pRtcpSendIO,
                pRtcpSendIO->dwObjectID, OBJECTID_RTCPSENDIO
            ));
        
        return;
    }

    /* Invalidate object */
    INVALIDATE_OBJECTID(pRtcpSendIO->dwObjectID);
    
    RtpHeapFree(g_pRtcpSendIOHeap, pRtcpSendIO);  
}

/* Update the average RTCP packet size sent and received, the packets
 * size is in bytes but the average is kept in bits */
double RtcpUpdateAvgPacketSize(RtpAddr_t *pRtpAddr, DWORD dwPacketSize)
{
    BOOL             bOk;
    
    /* Packet size for average includes the UDP/IP headers as per
     * draft-ietf-avt-rtp-new-05 */
    dwPacketSize += SIZEOF_UDP_IP_HDR;

    /* We are going to keep the average RTCP packet size in bits */
    dwPacketSize *= 8;
    
    /* Compute average RTCP packet size, the weight is according to
     * draft-ietf-avt-rtp-new-05 */
    if (pRtpAddr->RtpNetSState.avg_rtcp_size)
    {
        pRtpAddr->RtpNetSState.avg_rtcp_size =
            ( 1.0/16.0) * dwPacketSize +
            (15.0/16.0) * pRtpAddr->RtpNetSState.avg_rtcp_size;
    }
    else
    {
        pRtpAddr->RtpNetSState.avg_rtcp_size = dwPacketSize;
    }
    
    return(pRtpAddr->RtpNetSState.avg_rtcp_size);
}

void RtpSetBandEstFromRegistry(void)
{
    DWORD           *pDWORD;
    DWORD            i;
    
    if (IsDWValueSet(g_RtpReg.dwBandEstModulo) && g_RtpReg.dwBandEstModulo)
    {
        if (g_RtpReg.dwBandEstModulo & 0xff)
        {
            g_dwRtcpBandEstModNormal = g_RtpReg.dwBandEstModulo & 0xff;
        }

        if ((g_RtpReg.dwBandEstModulo >> 8) & 0xff)
        {
            g_dwRtcpBandEstModInitial = (g_RtpReg.dwBandEstModulo >> 8) & 0xff;
        }

        if ((g_RtpReg.dwBandEstModulo >> 16) & 0xff)
        {
            g_dwRtcpBandEstInitialCount =
                (g_RtpReg.dwBandEstModulo >> 16) & 0xff;
        }

        if ((g_RtpReg.dwBandEstModulo >> 24) & 0xff)
        {
            g_dwRtcpBandEstMinReports =
                (g_RtpReg.dwBandEstModulo >> 24) & 0xff;
        }
    }

    if (IsDWValueSet(g_RtpReg.dwBandEstTTL) && g_RtpReg.dwBandEstTTL)
    {
        g_dRtcpBandEstTTL = (double) g_RtpReg.dwBandEstTTL;
    }

    if (IsDWValueSet(g_RtpReg.dwBandEstWait) && g_RtpReg.dwBandEstWait)
    {
        g_dRtcpBandEstWait = (double) g_RtpReg.dwBandEstWait;
    }

    if (IsDWValueSet(g_RtpReg.dwBandEstMaxGap) && g_RtpReg.dwBandEstMaxGap)
    {
        /* Convert milliseconds to seconds */
        g_dRtcpBandEstMaxGap = (double) g_RtpReg.dwBandEstMaxGap / 1000;
    }

    pDWORD = &g_RtpReg.dwBandEstBin0;

    for(i = 0; i <= RTCP_BANDESTIMATION_MAXBINS; i++)
    {
        if (IsDWValueSet(pDWORD[i]) && pDWORD[i])
        {
            g_dRtcpBandEstBin[i] = (double)pDWORD[i];
        }
    }
}
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\net\tapi\skywalker\filters\rtp\msrtp\rtcp\rtcpsdes.c ===
/**********************************************************************
 *
 *  Copyright (C) 1999 Microsoft Corporation
 *
 *  File name:
 *
 *    rtcpsdes.c
 *
 *  Abstract:
 *
 *    SDES support functions
 *
 *  Author:
 *
 *    Andres Vega-Garcia (andresvg)
 *
 *  Revision:
 *
 *    1999/07/13 created
 *
 **********************************************************************/

#include "rtpmisc.h"
#include "rtpglobs.h"
#include "rtpheap.h"
#include "rtpmisc.h"
#include "rtpreg.h"
#include "lookup.h"
#include "rtpevent.h"

#include "rtcpsdes.h"

#define MAX_HOST_NAME 128
#define MAX_USER_NAME 128

/* Default BYE reason to send */
const TCHAR_t   *g_sByeReason = _T("Session terminated");

RtpSdes_t        g_RtpSdesDefault;

BOOL RtpCopySdesItem(
        WCHAR           *psSdesData,
        DWORD           *pdwSdesDataLen,
        RtpSdesItem_t   *pRtpSdesItem
    );

/**********************************************************************
 * Local SDES information
 **********************************************************************

/* Initialize to zero and compute the data pointers */
void RtcpSdesInit(RtpSdes_t *pRtpSdes)
{
    DWORD            i;
    DWORD            dwOffset;
    char            *ptr;
    
    ZeroMemory(pRtpSdes, sizeof(RtpSdes_t));

    pRtpSdes->dwObjectID = OBJECTID_RTPSDES;
    
    for(i = RTCP_SDES_FIRST + 1, ptr = pRtpSdes->SDESData;
        i < RTCP_SDES_LAST;
        i++, ptr += RTCP_MAX_SDES_SIZE)
    {
        /* Set buffer size to 255 (RTP) instead of 256 (allocated) */
        pRtpSdes->RtpSdesItem[i].dwBfrLen = RTCP_MAX_SDES_SIZE - 1;
        
        pRtpSdes->RtpSdesItem[i].pBuffer = (TCHAR_t *)ptr;
    }
}

/*
 * Sets a specific SDES item, expects a NULL terminated UNICODE string
 * no bigger than 255 bytes when converted to UTF-8 (including the
 * NULL terminating character). The string is converted to UTF-8 to be
 * stored and used in RTCP reports.
 *
 * Returns the mask of the item set or 0 if none
 * */
DWORD RtcpSdesSetItem(
        RtpSdes_t       *pRtpSdes,
        DWORD            dwItem,
        WCHAR           *pData
    )
{
    DWORD            dwDataLen;
    DWORD            dwWasSet;

    dwWasSet = 0;
    
    if (dwItem > RTCP_SDES_FIRST && dwItem < RTCP_SDES_LAST)
    {
#if 1
        /* UNICODE */
        
        /*
         * NOTE WideCharToMultiByte will convert also the null
         * terminating character which will be included in the length
         * returned
         * */
        dwDataLen = WideCharToMultiByte(
                CP_UTF8, /* UINT code page */
                0,       /* DWORD performance and mapping flags */
                pData,   /* LPCWSTR address of wide-character string */
                -1,      /* int number of characters in string */
                (char *)pRtpSdes->RtpSdesItem[dwItem].pBuffer,
                /* LPSTR address of buffer for new string */
                pRtpSdes->RtpSdesItem[dwItem].dwBfrLen,
                /* int size of buffer */
                NULL,    /* LPCSTR lpDefaultChar */
                NULL     /* LPBOOL lpUsedDefaultChar */
            );

        if (dwDataLen > 0)
        {
            pRtpSdes->RtpSdesItem[dwItem].dwDataLen = dwDataLen;
                
            RtpBitSet(dwWasSet, dwItem);
        }
#else
        /* ASCII */
        
        /* Add NULL to string length */
        dwDataLen = lstrlen(pData);

        if (dwDataLen > 0)
        {
            dwDataLen++;
        }

        dwDataLen *= sizeof(TCHAR_t);
        
        if (dwDataLen > 0 &&
            dwDataLen <= pRtpSdes->RtpSdesItem[dwItem].dwBfrLen)
        {
            /* If UNICODE is not defined, string is already UTF-8
             * (ASCII is a subset of UTF-8) */
            CopyMemory((char *)pRtpSdes->RtpSdesItem[dwItem].pBuffer,
                       (char *)pData,
                       dwDataLen);
                
            pRtpSdes->RtpSdesItem[dwItem].dwDataLen = dwDataLen;
                
            RtpBitSet(dwWasSet, dwItem);
        }
#endif
    }

    return(dwWasSet);
}

/* Obtain default values for the RTCP SDES items. This function
 * assumes the structure was initialized, i.e. zeroed and the data
 * pointers properly initialized.
 *
 * Data was first read from the registry and then defaults are set for
 * some items that don't have value yet.
 *
 * Return the mask of items that were set */
DWORD RtcpSdesSetDefault(RtpSdes_t *pRtpSdes)
{
    BOOL             bOk;
    DWORD            dwDataSize;
    DWORD            dwIndex;
    DWORD            dwSdesItemsSet;
    TCHAR_t        **ppsSdesItem;
    /* MAYDO instead, may be allocate memory from global heap */
    TCHAR_t         *pBuffer;

    dwSdesItemsSet = 0;
    
    pBuffer = RtpHeapAlloc(g_pRtpGlobalHeap,
                          RTCP_MAX_SDES_SIZE * sizeof(TCHAR_t));

    if (!pBuffer)
    { 
        return(0);
    }
    
    if ( IsRegValueSet(g_RtpReg.dwSdesEnable) &&
         ((g_RtpReg.dwSdesEnable & 0x3) == 0x3) )
    {
        ppsSdesItem = &g_RtpReg.psCNAME;
        
        for(dwIndex = RTCP_SDES_FIRST + 1, ppsSdesItem = &g_RtpReg.psCNAME;
            dwIndex < RTCP_SDES_LAST;      /* BYE */
            dwIndex++, ppsSdesItem++)
        {
            if (*ppsSdesItem)
            {
                /* Disable this parameter if first char is '-',
                 * otherwise set it */
                if (**ppsSdesItem == _T('-'))
                {
                    pRtpSdes->RtpSdesItem[dwIndex].pBuffer[0] = _T('\0');
                }
                else
                {
                    dwSdesItemsSet |= RtcpSdesSetItem(pRtpSdes,
                                                      dwIndex,
                                                      *ppsSdesItem);
                }
            }
        }
    }

    /* Now assign default values for some empty items */

    /* NAME */
    pBuffer[0] = _T('\0');

    bOk = RtpGetUserName(pBuffer, RTCP_MAX_SDES_SIZE);
    
    if (!RtpBitTest(dwSdesItemsSet, RTCP_SDES_NAME)) {
            
        if (bOk)
        {
            dwSdesItemsSet |=
                RtcpSdesSetItem(pRtpSdes, RTCP_SDES_NAME, pBuffer);
        }
        else
        {
            dwSdesItemsSet |=
                RtcpSdesSetItem(pRtpSdes, RTCP_SDES_NAME, _T("Unknown user"));
        }
    }
    
    /* CNAME: always machine generated */
    dwDataSize = lstrlen(pBuffer);

    bOk = RtpGetHostName(&pBuffer[dwDataSize + 1],
                         (RTCP_MAX_SDES_SIZE - dwDataSize -1));

    if (bOk)
    {
        pBuffer[dwDataSize] = _T('@');
    }

    dwSdesItemsSet |= RtcpSdesSetItem(pRtpSdes, RTCP_SDES_CNAME, pBuffer);

    /* TOOL */
    if (!RtpBitTest(dwSdesItemsSet, RTCP_SDES_TOOL)) {
        
        bOk = RtpGetPlatform(pBuffer);
    
        if (bOk) {
            dwSdesItemsSet |=
                RtcpSdesSetItem(pRtpSdes, RTCP_SDES_TOOL, pBuffer);
        }
    }

    /* BYE reason */
    if (!RtpBitTest(dwSdesItemsSet, RTCP_SDES_BYE)) {
        
        dwSdesItemsSet |=
            RtcpSdesSetItem(pRtpSdes, RTCP_SDES_BYE, (TCHAR_t *)g_sByeReason);
    }

    RtpHeapFree(g_pRtpGlobalHeap, pBuffer);
    
    return(dwSdesItemsSet);
}

/* Creates and initializes a RtpSdes_t structure */
RtpSdes_t *RtcpSdesAlloc(void)
{
    RtpSdes_t       *pRtpSdes;

    
    pRtpSdes = (RtpSdes_t *)
        RtpHeapAlloc(g_pRtpSdesHeap, sizeof(RtpSdes_t));

    if (pRtpSdes)
    {
        /* This function will initialize the dwObjectID */
        RtcpSdesInit(pRtpSdes);
    }
    
    return(pRtpSdes);
}

/* Frees a RtpSdes_t structure */
void RtcpSdesFree(RtpSdes_t *pRtpSdes)
{
    TraceFunctionName("RtcpSdesFree");

    /* verify object ID */
    if (pRtpSdes->dwObjectID != OBJECTID_RTPSDES)
    {
        TraceRetail((
                CLASS_ERROR, GROUP_RTCP, S_RTCP_SDES,
                _T("%s: pRtpSdes[0x%p] Invalid object ID 0x%X != 0x%X"),
                _fname, pRtpSdes,
                pRtpSdes->dwObjectID, OBJECTID_RTPSDES
            ));

        return;
    }

    /* Invalidate object */
    INVALIDATE_OBJECTID(pRtpSdes->dwObjectID);
    
    RtpHeapFree(g_pRtpSdesHeap, pRtpSdes);
}

/* Set the local SDES info for item dwSdesItem (e.g RTPSDES_CNAME,
 * RTPSDES_EMAIL), psSdesData contains the NUL terminated UNICODE
 * string to be assigned to the item */
HRESULT RtpSetSdesInfo(
        RtpAddr_t       *pRtpAddr,
        DWORD            dwSdesItem,
        WCHAR           *psSdesData
    )
{
    HRESULT          hr;
    DWORD            dwWasSet;
    RtpSess_t       *pRtpSess;

    TraceFunctionName("RtpSetSdesInfo");

    if (!pRtpAddr)
    {
        /* Having this as a NULL pointer means Init hasn't been
         * called, return this error instead of RTPERR_POINTER to be
         * consistent */
        hr = RTPERR_INVALIDSTATE;

        goto end;
    }

    /* verify object ID */
    if (pRtpAddr->dwObjectID != OBJECTID_RTPADDR)
    {
        TraceRetail((
                CLASS_ERROR, GROUP_RTCP, S_RTCP_SDES,
                _T("%s: pRtpAddr[0x%p] Invalid object ID 0x%X != 0x%X"),
                _fname, pRtpAddr,
                pRtpAddr->dwObjectID, OBJECTID_RTPADDR
            ));

        hr = RTPERR_INVALIDRTPADDR;

        goto end;
    }

    if (dwSdesItem <= RTCP_SDES_FIRST || dwSdesItem >= RTCP_SDES_LAST)
    {
        hr = RTPERR_INVALIDARG;

        goto end;
    }

    if (!psSdesData)
    {
        hr = RTPERR_POINTER;
        
        goto end;
    }

    hr = NOERROR;
    
    pRtpSess = pRtpAddr->pRtpSess;
    
    if (pRtpSess->pRtpSdes)
    {
        dwWasSet =
            RtcpSdesSetItem(pRtpSess->pRtpSdes, dwSdesItem, psSdesData);

        if (dwWasSet)
        {
            pRtpSess->dwSdesPresent |= dwWasSet;
        }
        else
        {
            hr = RTPERR_INVALIDARG;
        }
    }
    else
    {
        hr = RTPERR_INVALIDSTATE;
    }

 end:
    if (SUCCEEDED(hr))
    {
        TraceDebug((
                CLASS_INFO, GROUP_RTCP, S_RTCP_SDES,
                _T("%s: pRtpSess[0x%p] pRtpAddr[0x%p] Sdes:[%s:%ls]"),
                _fname, pRtpSess, pRtpAddr,
                g_psRtpSdesEvents[dwSdesItem],
                psSdesData
            ));
    }
    else
    {
        TraceRetail((
                CLASS_ERROR, GROUP_RTCP, S_RTCP_SDES,
                _T("%s: pRtpSess[0x%p] failed: %u (0x%X)"),
                _fname, pRtpSess, hr, hr
            ));
    }
    
    return(hr);
}

/* Get a local SDES item if dwSSRC=0, otherwise gets the SDES item
 * from the participant whose SSRC was specified.
 *
 * dwSdesItem is the item to get (e.g. RTPSDES_CNAME, RTPSDES_EMAIL),
 * psSdesData is the memory place where the item's value will be
 * copied, pdwSdesDataLen contains the initial size in UNICODE chars,
 * and returns the actual UNICODE chars copied (including the NULL
 * terminating char), dwSSRC specify which participant to retrieve the
 * information from. If the SDES item is not available, dwSdesDataLen
 * is set to 0 and the call doesn't fail */
HRESULT RtpGetSdesInfo(
        RtpAddr_t       *pRtpAddr,
        DWORD            dwSdesItem,
        WCHAR           *psSdesData,
        DWORD           *pdwSdesDataLen,
        DWORD            dwSSRC
    )
{
    HRESULT          hr;
    BOOL             bOk;
    BOOL             bCreate;
    int              DoCase;
    RtpSess_t       *pRtpSess;
    RtpUser_t       *pRtpUser;
    RtpSdesItem_t   *pRtpSdesItem;

    TraceFunctionName("RtpGetSdesInfo");

    pRtpSess = (RtpSess_t *)NULL;
    
    /* Check item validity */
    if (dwSdesItem <= RTCP_SDES_FIRST || dwSdesItem >= RTCP_SDES_LAST)
    {
        hr = RTPERR_INVALIDARG;

        goto end;
    }

    /* Check data pointers */
    if (!psSdesData || !pdwSdesDataLen)
    {
        hr = RTPERR_POINTER;

        goto end;
    }

    /* Decide case */
    if (!pRtpAddr && !dwSSRC)
    {
        /* We just want default values */
        DoCase = 2;
        
        goto doit;
    }
    else if (dwSSRC)
    {
        /* Remote */
        DoCase = 0;
    }
    else
    {
        /* Local */
        DoCase = 1;
    }

    /* More tests for cases local & remote */
    if (!pRtpAddr)
    {
        /* Having this as a NULL pointer means Init hasn't been
         * called, return this error instead of RTPERR_POINTER to be
         * consistent */
        hr = RTPERR_INVALIDSTATE;

        goto end;
    }

    /* verify object ID */
    if (pRtpAddr->dwObjectID != OBJECTID_RTPADDR)
    {
        TraceRetail((
                CLASS_ERROR, GROUP_RTCP, S_RTCP_SDES,
                _T("%s: pRtpAddr[0x%p] Invalid object ID 0x%X != 0x%X"),
                _fname, pRtpAddr,
                pRtpAddr->dwObjectID, OBJECTID_RTPADDR
            ));

        hr = RTPERR_INVALIDRTPADDR;

        goto end;
    }

    pRtpSess = pRtpAddr->pRtpSess;

 doit:
    pRtpSdesItem = (RtpSdesItem_t *)NULL;

    switch(DoCase)
    {
    case 0:
        /* Remote */
        bCreate = FALSE;
        pRtpUser = LookupSSRC(pRtpAddr, dwSSRC, &bCreate);

        if (pRtpUser)
        {
            if (!pRtpUser->pRtpSdes)
            {
                hr = RTPERR_INVALIDSTATE;
            
                goto end;
            }

            if (RtpBitTest(pRtpUser->dwSdesPresent, dwSdesItem))
            {
                pRtpSdesItem = &pRtpUser->pRtpSdes->RtpSdesItem[dwSdesItem];
            }
        }
        else
        {
            hr = RTPERR_NOTFOUND;

            goto end;
        }

        break;
        
    case 1:
        /* Local */
        if (!pRtpSess->pRtpSdes)
        {
            hr = RTPERR_INVALIDSTATE;
            
            goto end;
        }

        if (RtpBitTest(pRtpSess->dwSdesPresent, dwSdesItem))
        {
            pRtpSdesItem = &pRtpSess->pRtpSdes->RtpSdesItem[dwSdesItem];
        }

        break;

    default:
        /* Default */
        if (g_RtpSdesDefault.RtpSdesItem[dwSdesItem].dwDataLen > 0)
        {
            pRtpSdesItem = &g_RtpSdesDefault.RtpSdesItem[dwSdesItem];
        }
    } /* switch() */

    hr = NOERROR;
    
    if (pRtpSdesItem)
    {
        bOk = RtpCopySdesItem(psSdesData, pdwSdesDataLen, pRtpSdesItem);
            
        if (!bOk)
        {
            hr = RTPERR_FAIL;
        }
    }
    else
    {
        /* Make the string empty */
        *psSdesData = _T('\0');
    }

 end:

    if (SUCCEEDED(hr))
    {
        TraceDebug((
                CLASS_INFO, GROUP_RTCP, S_RTCP_SDES,
                _T("%s: pRtpSess[0x%p] pRtpAddr[0x%p] ")
                _T("SSRC:0x%X Sdes:[%s:%s]"),
                _fname, pRtpSess, pRtpAddr,
                ntohl(dwSSRC), g_psRtpSdesEvents[dwSdesItem],
                psSdesData
            ));
    }
    else
    {
        TraceRetail((
                CLASS_ERROR, GROUP_RTCP, S_RTCP_SDES,
                _T("%s: pRtpAddr[0x%p] SSRC:0x%X failed: %u (0x%X)"),
                _fname, pRtpAddr, ntohl(dwSSRC),
                hr, hr
            ));
    }
    
    return(hr);
}

BOOL RtpCopySdesItem(
        WCHAR           *psSdesData,
        DWORD           *pdwSdesDataLen,
        RtpSdesItem_t   *pRtpSdesItem
    )
{
    BOOL             bOk;
    DWORD            dwError;
    int              iStatus;

    TraceFunctionName("RtpCopySdesItem");  

    /* Covert from UTF-8 to UNICODE */
    iStatus = MultiByteToWideChar(CP_UTF8,
                                  0,
                                  (char *)pRtpSdesItem->pBuffer,
                                  pRtpSdesItem->dwDataLen,
                                  psSdesData,
                                  *pdwSdesDataLen);

    if (iStatus > 0)
    {
        bOk = TRUE;

        /* Update the number of UNICODE chars converted */
        *pdwSdesDataLen = iStatus;
    }
    else
    {
        TraceRetailGetError(dwError);
        
        TraceRetail((
                CLASS_ERROR, GROUP_RTCP, S_RTCP_SDES,
                _T("%s: MultiByteToWideChar src[0x%p]:%u dst[0x%p]:%u ")
                _T("failed: %u (0x%X)"),
                _fname, pRtpSdesItem->pBuffer, pRtpSdesItem->dwDataLen,
                psSdesData, *pdwSdesDataLen,
                dwError, dwError
            ));
        
        bOk = FALSE;
    }
    
    return(bOk);
}
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\net\tapi\skywalker\filters\rtp\msrtp\rtcp\rtcpthrd.c ===
/**********************************************************************
 *
 *  Copyright (C) Microsoft Corporation, 1999
 *
 *  File name:
 *
 *    rtcpthrd.c
 *
 *  Abstract:
 *
 *    RTCP thread
 *
 *  Author:
 *
 *    Andres Vega-Garcia (andresvg)
 *
 *  Revision:
 *
 *    1999/07/07 created
 *
 **********************************************************************/

#include "rtpheap.h"
#include "rtpglobs.h"
#include "rtpcrit.h"
#include "rtpchan.h"
#include "rtcprecv.h"
#include "rtcpsend.h"
#include "rtpqos.h"
#include "rtppinfo.h"
#include "rtcpint.h"
#include "rtpncnt.h"
#include "rtpevent.h"

#include <mmsystem.h> /* timeGetTime() */

#include "rtcpthrd.h"

HRESULT ConsumeRtcpCmdChannel(
        RtcpContext_t   *pRtcpContext,
        DWORD           *pdwCommand
    );

#if USE_RTCP_THREAD_POOL > 0
HRESULT ConsumeRtcpIoChannel(RtcpContext_t *pRtcpContext);
#endif /* USE_RTCP_THREAD_POOL > 0 */

HRESULT RtcpThreadAddrAdd(RtcpContext_t *pRtcpContext, RtpAddr_t *pRtpAddr);

HRESULT RtcpThreadAddrDel(RtcpContext_t *pRtcpContext, RtpAddr_t *pRtpAddr);

HRESULT RtcpThreadReserve(
        RtcpContext_t   *pRtcpContext,
        RtpAddr_t       *pRtpAddr,
        DWORD            dwCommand,
        DWORD            dwRecvSend
    );

HRESULT RtcpThreadAddrSendBye(
        RtcpContext_t   *pRtcpContext,
        RtpAddr_t       *pRtpAddr,
        BOOL             bShutDown
    );

HRESULT RtcpThreadAddrCleanup(RtcpContext_t *pRtcpContext);

double RtcpOnTimeout(RtcpContext_t *pRtcpContext);

double RtpAddrTimeout(RtcpContext_t *pRtcpContext);

double RtpUserTimeout(RtpAddr_t *pRtpAddr);

double RtcpSendReports(RtcpContext_t *pRtcpContext);

RtcpAddrDesc_t *RtcpAddrDescAlloc(
        RtpAddr_t       *pRtpAddr
    );

void RtcpAddrDescFree(RtcpAddrDesc_t *pRtcpAddrDesc);

RtcpAddrDesc_t *RtcpAddrDescGetFree(
        RtcpContext_t  *pRtcpContext,
        RtpAddr_t       *pRtpAddr
    );

RtcpAddrDesc_t *RtcpAddrDescPutFree(
        RtcpContext_t   *pRtcpContext,
        RtcpAddrDesc_t  *pRtcpAddrDesc
    );

HRESULT RtcpAddToVector(
        RtcpContext_t   *pRtcpContext,
        RtcpAddrDesc_t  *pRtcpAddrDesc
    );

HRESULT RtcpRemoveFromVector(
        RtcpContext_t   *pRtcpContext,
        RtcpAddrDesc_t  *pRtcpAddrDesc
    );

RtcpContext_t g_RtcpContext;

long g_lCountRtcpRecvThread = 0; /* Current number */
long g_lNumRtcpRecvThread = 0;   /* Cumulative number */

TCHAR *g_psRtcpThreadCommands[] =
{
    _T("invalid"),
    
    _T("ADDADDR"),
    _T("DELADDR"),
    _T("RESERVE"),
    _T("UNRESERVE"),
    _T("SENDBYE"),
    _T("EXIT"),

    _T("invalid"),
};

#define RtcpThreadCommandName(c) (g_psRtcpThreadCommands[c-RTCPTHRD_FIRST])

#if USE_RTCP_THREAD_POOL > 0
void CALLBACK RtcpRecvCallback(
        void        *pParameter,
        BOOLEAN      bTimerOrWaitFired
    )
{
    TraceFunctionName("RtcpRecvCallback");
    
    if (bTimerOrWaitFired)
    {
        return;
    }

    TraceDebugAdvanced((
            0, GROUP_RTCP, S_RTCP_CALLBACK,
            _T("%s: pRtcpAddrDesc[0x%p] enters"),
            _fname, pParameter
        ));
    
    RtpChannelSend(&g_RtcpContext.RtcpThreadIoChannel,
                   RTCPPOOL_RTCPRECV,
                   (DWORD_PTR)pParameter,
                   (DWORD_PTR)NULL,
                   0);

    TraceDebugAdvanced((
            0, GROUP_RTCP, S_RTCP_CALLBACK,
            _T("%s: pRtcpAddrDesc[0x%p] leaves"),
            _fname, pParameter
        ));
}

void CALLBACK RtcpQosCallback(
        void        *pParameter,
        BOOLEAN      bTimerOrWaitFired
    )
{
    TraceFunctionName("RtcpQosCallback");
    
    if (bTimerOrWaitFired)
    {
        return;
    }

    TraceDebugAdvanced((
            0, GROUP_RTCP, S_RTCP_CALLBACK,
            _T("%s: pRtcpAddrDesc[0x%p] enters"),
            _fname, pParameter
        ));
    
    RtpChannelSend(&g_RtcpContext.RtcpThreadIoChannel,
                   RTCPPOOL_QOSNOTIFY,
                   (DWORD_PTR)pParameter,
                   (DWORD_PTR)NULL,
                   0);

    TraceDebugAdvanced((
            0, GROUP_RTCP, S_RTCP_CALLBACK,
            _T("%s: pRtcpAddrDesc[0x%p] leaves"),
            _fname, pParameter
        ));
}
#endif /* USE_RTCP_THREAD_POOL > 0 */

/*
 * Do minimal initialization for RTCP
 * */
HRESULT RtcpInit(void)
{
    BOOL             bStatus;
    HRESULT          hr;

    TraceFunctionName("RtcpInit");

    /* Initialize RtcpContext */
    ZeroMemory(&g_RtcpContext, sizeof(g_RtcpContext));

    g_RtcpContext.dwObjectID = OBJECTID_RTCPCONTEXT;
    
    bStatus =
        RtpInitializeCriticalSection(&g_RtcpContext.RtcpContextCritSect,
                                     (void *)&g_RtcpContext,
                                     _T("RtcpContextCritSect"));

    hr = NOERROR;
    
    if (!bStatus) {

        TraceRetail((
                CLASS_ERROR, GROUP_RTCP, S_RTCP_INIT,
                _T("%s: pRtcpContext[0x%p] critical section ")
                _T("failed to initialize"),
                _fname, &g_RtcpContext
            ));

        hr = RTPERR_CRITSECT;
    }

    return(hr);
}

/*
 * Do last de-initialization for RTCP
 * */
HRESULT RtcpDelete(void)
{
    HRESULT          hr;

    TraceFunctionName("RtcpDelete");

    hr = NOERROR;

    /* RtcpContext de-initialization */
    RtpDeleteCriticalSection(&g_RtcpContext.RtcpContextCritSect);

    if (g_RtcpContext.lRtcpUsers > 0)
    {
        TraceRetail((
                CLASS_ERROR, GROUP_RTCP, S_RTCP_INIT,
                _T("%s: pRtcpContext[0x%p] ")
                _T("pRtcpContext->lRtcpUsers > 0: %d"),
                _fname, &g_RtcpContext,
                g_RtcpContext.lRtcpUsers
            ));

        hr = RTPERR_INVALIDSTATE;
    }

    if (g_RtcpContext.hRtcpContextThread)
    {
        TraceRetail((
                CLASS_ERROR, GROUP_RTCP, S_RTCP_INIT,
                _T("%s: pRtcpContext[0x%p] ")
                _T("Thread 0x%X still active"),
                _fname, &g_RtcpContext,
                g_RtcpContext.dwRtcpContextThreadID
            ));
        
        hr = RTPERR_INVALIDSTATE;
    }

    if (SUCCEEDED(hr))
    {
        INVALIDATE_OBJECTID(g_RtcpContext.dwObjectID);
    }
        
    return(hr);
}

/* RTCP worker thread */
DWORD WINAPI RtcpWorkerThreadProc(LPVOID lpParameter)
{
    DWORD            dwError;
    HRESULT          hr;
    DWORD            dwStatus;
    DWORD            dwCommand;
    DWORD            dwIndex;
    DWORD            dwDescIndex;
    DWORD            dwNumHandles;
    DWORD            dwWaitTime;
    RtcpContext_t   *pRtcpContext;
    RtpChannelCmd_t *pRtpChannelCmd;

    HANDLE           hThread;
    DWORD            dwThreadID;
    HANDLE          *pHandle;

    
#if USE_RTCP_THREAD_POOL <= 0
    RtcpAddrDesc_t  *pRtcpAddrDesc;
    RtcpAddrDesc_t **ppRtcpAddrDesc;
#endif /* USE_RTCP_THREAD_POOL <= 0 */

    TraceFunctionName("RtcpWorkerThreadProc");

    InterlockedIncrement(&g_lCountRtcpRecvThread);
    InterlockedIncrement(&g_lNumRtcpRecvThread);
    
    pRtcpContext = (RtcpContext_t *)lpParameter;

    hThread = 0;
    dwThreadID = -1;
    
    if (!pRtcpContext)
    {
        dwError = RTPERR_POINTER;
        goto exit;
    }

    if (pRtcpContext->dwObjectID != OBJECTID_RTCPCONTEXT)
    {
        TraceRetail((
                CLASS_ERROR, GROUP_RTCP, S_RTCP_THREAD,
                _T("%s: pRtcpContext[0x%p] Invalid object ID 0x%X != 0x%X"),
                _fname, pRtcpContext,
                pRtcpContext->dwObjectID, OBJECTID_RTCPCONTEXT
            ));

        dwError = RTPERR_INVALIDRTCPCONTEXT;
        
        goto exit;
    }

    dwError = NOERROR;
    hThread = pRtcpContext->hRtcpContextThread;
    dwThreadID = pRtcpContext->dwRtcpContextThreadID;
    
    pHandle = pRtcpContext->pHandle;
    
#if USE_RTCP_THREAD_POOL <= 0
    ppRtcpAddrDesc = pRtcpContext->ppRtcpAddrDesc;
#endif /* USE_RTCP_THREAD_POOL <= 0 */
    
    pHandle[0] = pRtcpContext->RtcpThreadCmdChannel.hWaitEvent;

#if USE_RTCP_THREAD_POOL > 0
    pHandle[1] = pRtcpContext->RtcpThreadIoChannel.hWaitEvent;
#endif /* USE_RTCP_THREAD_POOL > 0 */

    dwWaitTime = 5000;
    dwCommand = 0;

    TraceRetail((
            CLASS_INFO, GROUP_RTCP, S_RTCP_THREAD,
            _T("%s: pRtcpContext[0x%p] thread:%u (0x%X) ID:%u (0x%X) ")
            _T("has started"),
            _fname, pRtcpContext,
            hThread, hThread,
            dwThreadID, dwThreadID
        ));
    
    do
    {
        dwNumHandles =
            (pRtcpContext->dwMaxDesc * RTCP_HANDLE_SIZE) + RTCP_HANDLE_OFFSET;
        
        dwStatus = WaitForMultipleObjectsEx(
                dwNumHandles, /* DWORD nCount */
                pHandle,      /* CONST HANDLE *lpHandles */
                FALSE,        /* BOOL fWaitAll */
                dwWaitTime,   /* DWORD dwMilliseconds */
                TRUE          /* BOOL bAlertable */
            );

        if (dwStatus == WAIT_OBJECT_0)
        {
            ConsumeRtcpCmdChannel(pRtcpContext, &dwCommand);
        }
#if USE_RTCP_THREAD_POOL > 0
        else if (dwStatus == (WAIT_OBJECT_0 + 1))
        {
            ConsumeRtcpIoChannel(pRtcpContext);
        }
#else /* USE_RTCP_THREAD_POOL > 0 */
        else if ( (dwStatus >= (WAIT_OBJECT_0 + RTCP_HANDLE_OFFSET)) &&
                  (dwStatus < (WAIT_OBJECT_0 + RTCP_HANDLE_OFFSET +
                               (RTCP_HANDLE_SIZE * RTCP_MAX_DESC))) )
        {
            /* Asynchronous reception events start at index
             * RTCP_HANDLE_OFFSET, but descriptors start at index 0
             * */
            dwIndex = dwStatus - WAIT_OBJECT_0 - RTCP_HANDLE_OFFSET;
            
            dwDescIndex = dwIndex / RTCP_HANDLE_SIZE;

            pRtcpAddrDesc = ppRtcpAddrDesc[dwDescIndex];

            switch(dwIndex % RTCP_HANDLE_SIZE) {
                /* Asynchronous activity is restarted inside each
                 * function */
            case 0: /* I/O completion signaled */
                ConsumeRtcpRecvFrom(pRtcpContext, pRtcpAddrDesc);
                break;
            case 1: /* QOS notification */
                ConsumeRtcpQosNotify(pRtcpContext, pRtcpAddrDesc);
                break;
            default:
                ; /* TODO log error */
            }

            /* If we just had asynchronous I/O, that means the
             * RtcpAddrDesc hasn't been removed from vector, do it now
             * if there are no more pending I/Os (structure is moved
             * to AddrDescFreeQ by RtcpRemoveFromVector()) */
            if (RtpBitTest(pRtcpAddrDesc->dwAddrDescFlags,
                           FGADDRD_SHUTDOWN2))
            {
                if ( (pRtcpAddrDesc->lRtcpPending <= 0) &&
                     (pRtcpAddrDesc->lQosPending <= 0) )
                {
                    RtcpRemoveFromVector(pRtcpContext, pRtcpAddrDesc);
                }
            }
        }
#endif /* USE_RTCP_THREAD_POOL > 0 */

        if (dwCommand != RTCPTHRD_EXIT)
        {
            dwWaitTime = (DWORD) (RtcpOnTimeout(pRtcpContext) * 1000.0);
        }
        
    } while(dwCommand != RTCPTHRD_EXIT);

 exit:
    TraceRetail((
            CLASS_INFO, GROUP_RTCP, S_RTCP_THREAD,
            _T("%s: pRtcpContext[0x%p] thread:%u (0x%X) ID:%u (0x%X) ")
            _T("exit with code: %u (0x%X)"),
            _fname, pRtcpContext,
            hThread, hThread,
            dwThreadID, dwThreadID,
            dwError, dwError
        ));
  
    InterlockedDecrement(&g_lCountRtcpRecvThread);
    
    return(dwError);
}

HRESULT ConsumeRtcpCmdChannel(
        RtcpContext_t   *pRtcpContext,
        DWORD           *pdwCommand
    )
{
    HRESULT          hr;
    RtpChannelCmd_t *pRtpChannelCmd;
    DWORD            dwCommand;

    hr = NOERROR;
    dwCommand = 0;
    
    while( (pRtpChannelCmd =
            RtpChannelGetCmd(&pRtcpContext->RtcpThreadCmdChannel)) )
    {
        dwCommand = pRtpChannelCmd->dwCommand;

        switch(dwCommand) {
        case RTCPTHRD_ADDADDR:
            hr = RtcpThreadAddrAdd(
                    pRtcpContext,
                    (RtpAddr_t *)pRtpChannelCmd->dwPar1);
            break;
        case RTCPTHRD_DELADDR:
            hr = RtcpThreadAddrDel(
                    pRtcpContext,
                    (RtpAddr_t *)pRtpChannelCmd->dwPar1);
            break;
        case RTCPTHRD_RESERVE:
        case RTCPTHRD_UNRESERVE:
            hr = RtcpThreadReserve(
                    pRtcpContext,
                    (RtpAddr_t *)pRtpChannelCmd->dwPar1,
                    dwCommand,
                    (DWORD)pRtpChannelCmd->dwPar2);
            break;
        case RTCPTHRD_SENDBYE:
            hr = RtcpThreadAddrSendBye(
                    pRtcpContext,
                    (RtpAddr_t *)pRtpChannelCmd->dwPar1,
                    (BOOL)pRtpChannelCmd->dwPar2);
            break;
        case RTCPTHRD_EXIT:
            /* Release resources (overlapped I/O if there is
             * any. That can happen if the overlapped I/O
             * takes longer to complete and the EXIT command
             * sent after last DELADDR completed also before
             * the I/O completes) */
            hr = RtcpThreadAddrCleanup(pRtcpContext);
            break;
        default:
            hr = NOERROR; /* TODO Should be an error */
        }
            
        RtpChannelAck(&pRtcpContext->RtcpThreadCmdChannel,
                      pRtpChannelCmd,
                      hr);
    }

    *pdwCommand = dwCommand;
    
    return(hr);
}

#if USE_RTCP_THREAD_POOL > 0
HRESULT ConsumeRtcpIoChannel(RtcpContext_t *pRtcpContext)
{
    HRESULT          hr;
    RtpChannelCmd_t *pRtpChannelCmd;
    RtcpAddrDesc_t  *pRtcpAddrDesc;
    DWORD            dwCommand;

    TraceFunctionName("ConsumeRtcpIoChannel");

    hr = NOERROR;
    
    while( (pRtpChannelCmd =
            RtpChannelGetCmd(&pRtcpContext->RtcpThreadIoChannel)) )
    {
        dwCommand = pRtpChannelCmd->dwCommand;

        pRtcpAddrDesc = (RtcpAddrDesc_t *)pRtpChannelCmd->dwPar1;

        if (pRtcpAddrDesc->dwObjectID != OBJECTID_RTCPADDRDESC)
        {
            TraceRetail((
                    CLASS_ERROR, GROUP_RTCP, S_RTCP_THREAD,
                    _T("%s: pRtcpAddrDesc[0x%p] Invalid object ID ")
                    _T("0x%X != 0x%X"),
                    _fname, pRtcpAddrDesc,
                    pRtcpAddrDesc->dwObjectID, OBJECTID_RTCPADDRDESC
                ));
        }
        else
        {
            switch(dwCommand)
            {
            case RTCPPOOL_RTCPRECV:
                hr = ConsumeRtcpRecvFrom(pRtcpContext, pRtcpAddrDesc);
                break;
            case RTCPPOOL_QOSNOTIFY:
                hr = ConsumeRtcpQosNotify(pRtcpContext, pRtcpAddrDesc);
                break;
            default:
                hr = NOERROR; /* TODO This is an error */
            }
        }
        
        RtpChannelAck(&pRtcpContext->RtcpThreadIoChannel,
                      pRtpChannelCmd,
                      hr);
        
        if (pRtcpAddrDesc->dwObjectID == OBJECTID_RTCPADDRDESC)
        {
            /* If we just had asynchronous I/O, that means the
             * RtcpAddrDesc hasn't been removed from vector, do it now
             * if there are no more pending I/Os (structure is moved
             * to AddrDescFreeQ by RtcpRemoveFromVector()) */
            if (RtpBitTest(pRtcpAddrDesc->dwAddrDescFlags,
                           FGADDRD_SHUTDOWN2))
            {
                if ( (pRtcpAddrDesc->lRtcpPending <= 0) &&
                     (pRtcpAddrDesc->lQosPending <= 0) )
                {
                    RtcpRemoveFromVector(pRtcpContext, pRtcpAddrDesc);
                }
            }
        }
    }

    return(hr);
}
#endif /* USE_RTCP_THREAD_POOL > 0 */

/* Create (if not yet created) the RTCP worker thread */
HRESULT RtcpCreateThread(RtcpContext_t *pRtcpContext)
{
    HRESULT         hr;
    DWORD           dwError;
    BOOL            bOk;

    TraceFunctionName("RtcpCreateThread");

    bOk = RtpEnterCriticalSection(&pRtcpContext->RtcpContextCritSect);

    if (!bOk)
    {
        hr = RTPERR_CRITSECT;
        goto bail;
    }

    hr = NOERROR;
    
    /* If RTCP thread is not started yet, create it and start it */
    if (!pRtcpContext->hRtcpContextThread)
    {
        /* First time, initializa channel */
        hr = RtpChannelInit(&pRtcpContext->RtcpThreadCmdChannel,
                            pRtcpContext);

        if (FAILED(hr))
        {
            TraceRetail((
                    CLASS_ERROR, GROUP_RTCP, S_RTCP_THREAD,
                    _T("%s: pRtcpContext[0x%p] ")
                    _T("Failed to initialize cmd channel: %u (0x%X)"),
                    _fname, pRtcpContext,
                    hr, hr
                ));
            
            goto bail;
        }
        
#if USE_RTCP_THREAD_POOL > 0
        hr = RtpChannelInit(&pRtcpContext->RtcpThreadIoChannel,
                            pRtcpContext);

        if (FAILED(hr))
        {
            TraceRetail((
                    CLASS_ERROR, GROUP_RTCP, S_RTCP_THREAD,
                    _T("%s: pRtcpContext[0x%p] ")
                    _T("Failed to initialize IO channel: %u (0x%X)"),
                    _fname, pRtcpContext,
                    hr, hr
                ));
            
            goto bail;
        }
#endif /* USE_RTCP_THREAD_POOL > 0 */
        
        /* Create thread */
        pRtcpContext->hRtcpContextThread = CreateThread(
                NULL,                 /* LPSECURITY_ATTRIBUTES lpThrdAttrib */
                0,                    /* DWORD dwStackSize */
                RtcpWorkerThreadProc, /* LPTHREAD_START_ROUTINE lpStartProc */
                pRtcpContext,         /* LPVOID  lpParameter */
                0,                    /* DWORD dwCreationFlags */
                &pRtcpContext->dwRtcpContextThreadID /* LPDWORD lpThreadId */
        );

        if (!pRtcpContext->hRtcpContextThread)
        {
            TraceRetailGetError(dwError);
            
            TraceRetail((
                    CLASS_ERROR, GROUP_RTCP, S_RTCP_THREAD,
                    _T("%s: pRtcpContext[0x%p] ")
                    _T("Thread creation failed: %u (0x%X)"),
                    _fname, pRtcpContext,
                    dwError, dwError
                ));
            
            hr = RTPERR_THREAD;
            
            goto bail;
        }
        
        pRtcpContext->lRtcpUsers = 0;
        pRtcpContext->dwMaxDesc = 0;
    }
    
    pRtcpContext->lRtcpUsers++;
    
    RtpLeaveCriticalSection(&pRtcpContext->RtcpContextCritSect);
    
    return(hr);

bail:
    if (bOk)
    {
        if (IsRtpChannelInitialized(&pRtcpContext->RtcpThreadCmdChannel))
        {
            RtpChannelDelete(&pRtcpContext->RtcpThreadCmdChannel);
        }

    #if USE_RTCP_THREAD_POOL > 0
        if (IsRtpChannelInitialized(&pRtcpContext->RtcpThreadIoChannel))
        {
            RtpChannelDelete(&pRtcpContext->RtcpThreadIoChannel);
        }
    #endif /* USE_RTCP_THREAD_POOL > 0 */
    
        RtpLeaveCriticalSection(&pRtcpContext->RtcpContextCritSect);
    }

    return(hr);
}

/* Delete thread when there are no more RTCP users */
HRESULT RtcpDeleteThread(RtcpContext_t *pRtcpContext)
{
    HRESULT          hr;
    BOOL             bOk;
    
    TraceFunctionName("RtcpDeleteThread");
    
    bOk = RtpEnterCriticalSection(&pRtcpContext->RtcpContextCritSect);

    if (!bOk)
    {
        hr = RTPERR_CRITSECT;
        goto bail;
    }

    hr = NOERROR;

    /* If RTCP thread is not started yet, do nothing */
    if (pRtcpContext->hRtcpContextThread)
    {
        /* Everything fine, see if thread needs to be stoped */
        pRtcpContext->lRtcpUsers--;
            
        if (pRtcpContext->lRtcpUsers <= 0)
        {
            /* Really terminate thread */
            
            /* Direct thread to stop, synchronize ack */
            hr = RtpChannelSend(&pRtcpContext->RtcpThreadCmdChannel,
                                RTCPTHRD_EXIT,
                                0,
                                0,
                                60*60*1000); /* TODO update */
            
            if (SUCCEEDED(hr))
            {
                /* TODO I may modify to loop until object is
                 * signaled or get a timeout */
                WaitForSingleObject(pRtcpContext->hRtcpContextThread,
                                    INFINITE);
            }
            else
            {
                /* Force ungraceful thread termination */
                
                TraceRetail((
                        CLASS_ERROR, GROUP_RTCP, S_RTCP_THREAD,
                        _T("%s: Force ungraceful ")
                        _T("thread termination: %u (0x%X)"),
                        _fname, hr, hr
                    ));
                
                TerminateThread(pRtcpContext->hRtcpContextThread, -1);
            }

            CloseHandle(pRtcpContext->hRtcpContextThread);
            
            pRtcpContext->hRtcpContextThread = NULL;
            
            /* ...thread stoped, now delete channel */
            RtpChannelDelete(&pRtcpContext->RtcpThreadCmdChannel);
            
#if USE_RTCP_THREAD_POOL > 0
            RtpChannelDelete(&pRtcpContext->RtcpThreadIoChannel);
#endif /* USE_RTCP_THREAD_POOL > 0 */
        }
    }

    RtpLeaveCriticalSection(&pRtcpContext->RtcpContextCritSect);

 bail:
    
    return(hr);
}

/*
 * Start the RTCP thread
 * */
HRESULT RtcpStart(RtcpContext_t *pRtcpContext)
{
    HRESULT          hr;

    TraceFunctionName("RtcpStart");

    hr = RtcpCreateThread(pRtcpContext);

    if (FAILED(hr))
    {
        TraceRetail((
                CLASS_ERROR, GROUP_RTCP, S_RTCP_THREAD,
                _T("%s: pRtcpContext[0x%p] ")
                _T("thread creation failed: %u (0x%X)"),
                _fname, pRtcpContext,
                hr, hr
            ));
    }
    else
    {
        TraceDebug((
                CLASS_INFO, GROUP_RTCP, S_RTCP_THREAD,
                _T("%s: pRtcpContext[0x%p] ")
                _T("thread creation succeeded"),
                _fname, pRtcpContext
            ));
    }

    return(hr);
}

/*
 * Stop the RTCP thread
 * */
HRESULT RtcpStop(RtcpContext_t *pRtcpContext)
{
    HRESULT          hr;

    TraceFunctionName("RtcpStop");

    hr = RtcpDeleteThread(pRtcpContext);

    if (FAILED(hr))
    {
        TraceRetail((
                CLASS_ERROR, GROUP_RTCP, S_RTCP_THREAD,
                _T("%s: pRtcpContext[0x%p] ")
                _T("thread termination failed: %u (0x%X)"),
                _fname, pRtcpContext,
                hr, hr
            ));
    }
    else
    {
        TraceDebug((
                CLASS_INFO, GROUP_RTCP, S_RTCP_THREAD,
                _T("%s: pRtcpContext[0x%p] ")
                _T("thread deletion succeeded"),
                _fname, pRtcpContext
            ));
    }

    return (hr);
}

/**********************************************************************
 * Function called to send commands to the RTCP thread
 **********************************************************************/

/*
 * RTCPTHRD_ADDADDR: Add an address so the RTCP worker thread can
 * start receiving/sending RTCP reports on its behalf.
 *
 * RTCPTHRD_DELADDR: Remove an address so the RTCP stops
 * receiving/sending RTCP reports on its behalf.
 *
 * RTCPTHRD_RESERVE: Directs the RTCP thread to do a QOS reservation
 * (do a reservation if a receiver or start sending PATH messages if a
 * sender).
 *
 * RTCPTHRD_UNRESERVE: Directs the RTCP thread to undo a QOS
 * reservation (remove the reservation if a receiver or stop sending
 * PATH messages if a sender).
 *
 * RTCPTHRD_SENDBYE: Shutdown an address so the RTCP thread sends a
 * RTCP BYE
 * */

HRESULT RtcpThreadCmd(
        RtcpContext_t   *pRtcpContext,
        RtpAddr_t       *pRtpAddr,
        RTCPTHRD_e       eCommand,
        DWORD            dwParam,
        DWORD            dwWaitTime
    )
{
    HRESULT          hr;
    
    TraceFunctionName("RtcpThreadCmd");

    TraceDebug((
            CLASS_INFO, GROUP_RTCP, S_RTCP_CHANNEL,
            _T("%s: pRtcpContext[0x%p] pRtpAddr[0x%p] ")
            _T("Cmd:%s Par:0x%X Wait:%u"),
            _fname, pRtcpContext, pRtpAddr,
            RtcpThreadCommandName(eCommand), dwParam, dwWaitTime
        ));

    /* Send command to RTCP worker thread, synchronize */
    hr = RtpChannelSend(&pRtcpContext->RtcpThreadCmdChannel,
                        eCommand,
                        (DWORD_PTR)pRtpAddr,
                        (DWORD_PTR)dwParam,
                        dwWaitTime);
        
    if (FAILED(hr))
    {
        TraceRetail((
                CLASS_ERROR, GROUP_RTCP, S_RTCP_CHANNEL,
                _T("%s: pRtcpContext[0x%p] pRtpAddr[0x%p] ")
                _T("Cmd:%s Par:0x%X Wait:%u failed: %u (0x%X)"),
                _fname, pRtcpContext, pRtpAddr,
                RtcpThreadCommandName(eCommand), dwParam, dwWaitTime,
                hr, hr
            ));
    }
    
    return(hr);

}

/**********************************************************************
 * Functions called inside the RTCP thread
 **********************************************************************/

/* Called from the RTCP worker thread whenever a RTCPTHRD_ADDADDR
 * command is received */
HRESULT RtcpThreadAddrAdd(RtcpContext_t *pRtcpContext, RtpAddr_t *pRtpAddr)
{
    HRESULT          hr;
    DWORD            s;
    RtcpAddrDesc_t  *pRtcpAddrDesc;
    double           dTime;
    double           dTimeToNextReport;

    TraceFunctionName("RtcpThreadAddrAdd");

    hr = RTPERR_RESOURCES;
    
    /* Check if we can handle another address */
    if (pRtcpContext->dwMaxDesc >= RTCP_MAX_DESC)
    {
        TraceRetail((
                CLASS_WARNING, GROUP_RTCP, S_RTCP_CMD,
                _T("%s: pRtcpContext[0x%p] pRtpAddr[0x%p] ")
                _T("failed: max entries in vector reached:%u"),
                _fname, pRtcpContext, pRtpAddr,
                pRtcpContext->dwMaxDesc
            ));
        
        return(hr);
    }
    
    /* Allocate a new RtcpAddrDesc_t structure */
    pRtcpAddrDesc = RtcpAddrDescGetFree(pRtcpContext, pRtpAddr);

    if (pRtcpAddrDesc)
    {
        pRtcpAddrDesc->pRtpAddr = pRtpAddr;

        for(s = SOCK_RECV_IDX; s <= SOCK_RTCP_IDX; s++)
        {
            /* Keep a copy of sockets to avoid access to pRtpAddr */
            pRtcpAddrDesc->Socket[s] = pRtpAddr->Socket[s]; 
        }

        pRtcpAddrDesc->AddrDescQItem.pvOther = (void *)pRtpAddr;
        
        /* Add pRtcpAddrDesc to the address queue */
        enqueuef(&pRtcpContext->AddrDescBusyQ,
                 NULL,
                 &pRtcpAddrDesc->AddrDescQItem);
        
        dTime = RtpGetTimeOfDay((RtpTime_t *)NULL);

        /* Schedule first RTCP report to be sent */
        dTimeToNextReport = dTime + RtcpNextReportInterval(pRtpAddr);

        /* Add pRtcpAddrDesc to the reports queue */
        /* Insert in ascending order using the dTimeToNextReport
         * as a Key (used to schedule sending RTCP reports) */
        enqueuedK(&pRtcpContext->SendReportQ,
                  NULL,
                  &pRtcpAddrDesc->SendQItem,
                  dTimeToNextReport);

        /* NOTE Add systematically pRtcpAddrDesc to the QOS
         * notifications queue (regardless if the session is or not
         * QOS enabled).  This will add a small overhead, but is
         * comparable to testing for the need or not to add/remove
         * from QOS queues, with the advantage that the code is
         * simpler */
        enqueuedK(&pRtcpContext->QosStartQ,
                  NULL,
                  &pRtcpAddrDesc->QosQItem,
                  dTime + 0.100); /* +100ms from now */

        /*
         * Update the events vector for asynchronous reception
         * */
        RtcpAddToVector(pRtcpContext, pRtcpAddrDesc);
        
        /* Start asynchronous RTCP reception */
        StartRtcpRecvFrom(pRtcpContext, pRtcpAddrDesc);

        /* Start asynchronous QOS notifications */
        if ( RtpBitTest(pRtpAddr->dwAddrFlags, FGADDR_QOSRECVON) ||
             RtpBitTest(pRtpAddr->dwAddrFlags, FGADDR_QOSSENDON) )
        {
            /* ... only if QOS is enabled */
            StartRtcpQosNotify(pRtcpContext, pRtcpAddrDesc);
        }

        hr = NOERROR;
    }
    else
    {
        TraceRetail((
                CLASS_ERROR, GROUP_RTCP, S_RTCP_CMD,
                _T("%s: pRtcpContext[0x%p] pRtpAddr[0x%p] ")
                _T("failed to create pRtcpAddrDesc"),
                _fname, pRtcpContext, pRtpAddr
            ));
    }

    return(hr);
}

/* Called from the RTCP worker thread whenever a RTCPTHRD_DELADDR
 * command is received */
HRESULT RtcpThreadAddrDel(RtcpContext_t *pRtcpContext, RtpAddr_t *pRtpAddr)
{
    HRESULT          hr;
    RtcpAddrDesc_t  *pRtcpAddrDesc;
    RtpQueueItem_t  *pRtpQueueItem;

    TraceFunctionName("RtcpThreadAddrDel");

    hr = RTPERR_NOTFOUND;
    
    pRtpQueueItem = findQO(&pRtcpContext->AddrDescBusyQ,
                           NULL,
                           (void *)pRtpAddr);

    if (pRtpQueueItem)
    {
        pRtcpAddrDesc =
            CONTAINING_RECORD(pRtpQueueItem, RtcpAddrDesc_t, AddrDescQItem);

        /* Remove from the reports queue */
        dequeue(&pRtcpContext->SendReportQ, NULL, &pRtcpAddrDesc->SendQItem);

        /* Reset key */
        pRtcpAddrDesc->SendQItem.dwKey = 0;

        /* This RtcpAddrDesc is shutting down */
        RtpBitSet(pRtcpAddrDesc->dwAddrDescFlags, FGADDRD_SHUTDOWN2);

        if (RtpBitTest(pRtcpAddrDesc->dwAddrDescFlags, FGADDRD_NOTIFYBUSY))
        {
            /* A QOS notification can be still in BusyQ, and yet not
             * be pending, if it completed after FGADDRD_SHUTDOWN1 was
             * set, but before having set FGADDRD_SHUTDOWN2. */

            if (pRtcpAddrDesc->lQosPending > 0)
            {
                /* Move from QosBusyQ to QosStopQ */
                move2ql(&pRtcpContext->QosStopQ, /* ToQ */
                        &pRtcpContext->QosBusyQ, /* FromQ */
                        NULL,
                        &pRtcpAddrDesc->QosQItem);

                /* When notification completes, the RtcpAddrDesc will
                 * be removed from QosStopQ */
            }
            else
            {
                /* Just remove from QosBusyQ */
                dequeue(&pRtcpContext->QosBusyQ,
                        NULL,
                        &pRtcpAddrDesc->QosQItem);
            }
            
            RtpBitReset(pRtcpAddrDesc->dwAddrDescFlags, FGADDRD_NOTIFYBUSY);
        }
        else
        {
            /* NOTE the pRtcpAddrDesc was added to the QosStartQ
             * during RtcpThreadAddrAdd regardless if QOS was enabled
             * or not, if it wasn't, it would have remained in
             * QosStartQ.  */
            
            /* If QOS notification is not in BusyQ, item must be in
             * QosStartQ, and there must not be a QOS notification
             * pending, just remove from QosStartQ */

            dequeue(&pRtcpContext->QosStartQ,
                    NULL,
                    &pRtcpAddrDesc->QosQItem);
        }

        if (pRtcpAddrDesc->lRtcpPending > 0)
        {
            /* Reception pending, move pRtcpAddrDesc from
             * AddrDescBusyQ to AddrDescStopQ */

            move2ql(&pRtcpContext->AddrDescStopQ,
                    &pRtcpContext->AddrDescBusyQ,
                    NULL,
                    &pRtcpAddrDesc->AddrDescQItem);
            
            /* When reception completes, the RtcpAddrDesc will be
             * removed from AddrDescStopQ */

            TraceDebug((
                    CLASS_INFO, GROUP_RTCP, S_RTCP_CMD,
                    _T("%s: pRtcpContext[0x%p] ")
                    _T("pRtcpAddrDesc[0x%p] pRtpAddr[0x%p] ")
                    _T("Shutting down, I/O:%d ")
                    _T("AddrDescBusyQ->AddrDescStopQ"),
                    _fname, pRtcpContext, pRtcpAddrDesc, pRtpAddr,
                    pRtcpAddrDesc->lRtcpPending
                ));
        }
        else
        {
            /* RtcpAddrDesc is in AddrDescBusyQ regardless there is
             * a pending I/O or not */
            dequeue(&pRtcpContext->AddrDescBusyQ,
                    NULL,
                    &pRtcpAddrDesc->AddrDescQItem);

            pRtcpAddrDesc->AddrDescQItem.pvOther = NULL;

            TraceDebug((
                    CLASS_INFO, GROUP_RTCP, S_RTCP_CMD,
                    _T("%s: pRtcpContext[0x%p] ")
                    _T("pRtcpAddrDesc[0x%p] pRtpAddr[0x%p] ")
                    _T("Shutting down, I/O:%d ")
                    _T("AddrDescBusyQ->"),
                    _fname, pRtcpContext, pRtcpAddrDesc, pRtpAddr,
                    pRtcpAddrDesc->lRtcpPending
                ));
        }
        
        if ( (pRtcpAddrDesc->lRtcpPending <= 0) &&
             (pRtcpAddrDesc->lQosPending <= 0) )
        {
            /* If no pending I/Os, remove from event vector and move
             * descriptor to AddrDescFreeQ */
            
            RtcpRemoveFromVector(pRtcpContext, pRtcpAddrDesc);

            /* If there is no pending I/O, the RtcpAddrDesc will not
             * be in any queue when we get to this point (removed in
             * the ConsumeRtcp* functions)
             * */
        }

        hr = NOERROR;
    }
    else
    {
        TraceRetail((
                CLASS_ERROR, GROUP_RTCP, S_RTCP_CMD,
                _T("%s: pRtcpContext[0x%p] pRtpAddr[0x%p] ")
                _T("failed: address not found in context"),
                _fname, pRtcpContext, pRtpAddr
            ));
    }

    return(hr);
}

/* Called from the RTCP thread whenever a RTCPTHRD_RESERVE command is
 * received. Does a reservation/unreservation on behalf of the
 * RtpAddr_t */
HRESULT RtcpThreadReserve(
        RtcpContext_t   *pRtcpContext,
        RtpAddr_t       *pRtpAddr,
        DWORD            dwCommand,
        DWORD            dwRecvSend
    )
{
    HRESULT          hr;
    DWORD            dwFlag;
    RtcpAddrDesc_t  *pRtcpAddrDesc;
    RtpQueueItem_t  *pRtpQueueItem;

    hr = NOERROR;

    pRtpQueueItem = findQO(&pRtcpContext->AddrDescBusyQ,
                           NULL,
                           (void *)pRtpAddr);

    dwFlag = dwRecvSend? FGADDRQ_QOSSENDON : FGADDRQ_QOSRECVON;
    
    if (dwCommand == RTCPTHRD_RESERVE)
    {
        /* Reserve */
        hr = RtpReserve(pRtpAddr, dwRecvSend);

        if (SUCCEEDED(hr))
        {
            RtpBitSet(pRtpAddr->dwAddrFlagsQ, dwFlag);

            if (dwRecvSend == SEND_IDX)
            {
                /* Ask for permission to send and update state if
                 * needed. Later in this same thread, when the
                 * RECEIVERS notification comes (that notification
                 * must not happen if we have not enabled QOS), the
                 * send state will be updated again */
                RtcpUpdateSendState(pRtpAddr, RTPQOS_NO_RECEIVERS);
            }
            
            if (pRtpQueueItem)
            {
                pRtcpAddrDesc =
                    CONTAINING_RECORD(pRtpQueueItem,
                                      RtcpAddrDesc_t,
                                      AddrDescQItem);

                /* Start asynchronous QOS notifications */
                StartRtcpQosNotify(pRtcpContext, pRtcpAddrDesc);
            }
        }
    }
    else
    {
        /* Unreserve */
        if (RtpBitTest(pRtpAddr->dwAddrFlagsQ, dwFlag))
        {
            hr = RtpUnreserve(pRtpAddr, dwRecvSend);

            RtpBitReset(pRtpAddr->dwAddrFlagsQ, dwFlag);

            if (dwRecvSend)
            {
                /* Sender only */
                RtpBitReset(pRtpAddr->dwAddrFlagsQ, FGADDRQ_QOSREDSENDON);
            }
       }
    }
    
    return(hr);
}

/* Called from the RTCP worker thread whenever a RTCPTHRD_SENDBYE
 * command is received */
HRESULT RtcpThreadAddrSendBye(
        RtcpContext_t   *pRtcpContext,
        RtpAddr_t       *pRtpAddr,
        BOOL             bShutDown
    )
{
    HRESULT          hr;
    RtcpAddrDesc_t  *pRtcpAddrDesc;
    RtpQueueItem_t  *pRtpQueueItem;

    TraceFunctionName("RtcpThreadAddrSendBye");

    hr = RTPERR_NOTFOUND;
    
    pRtpQueueItem = findQO(&pRtcpContext->AddrDescBusyQ,
                           NULL,
                           (void *)pRtpAddr);

    if (pRtpQueueItem)
    {
        pRtcpAddrDesc =
            CONTAINING_RECORD(pRtpQueueItem, RtcpAddrDesc_t, AddrDescQItem);

        TraceDebug((
                CLASS_INFO, GROUP_RTCP, S_RTCP_CMD,
                _T("%s: pRtcpContext[0x%p] ")
                _T("pRtcpAddrDesc[0x%p] pRtpAddr[0x%p] ")
                _T("About to send BYE"),
                _fname, pRtcpContext, pRtcpAddrDesc, pRtpAddr
            ));

        RtcpSendBye(pRtcpAddrDesc);

        if (bShutDown)
        {
            TraceDebug((
                    CLASS_INFO, GROUP_RTCP, S_RTCP_CMD,
                    _T("%s: pRtcpContext[0x%p] ")
                    _T("pRtcpAddrDesc[0x%p] pRtpAddr[0x%p] ")
                    _T("About to shutdown"),
                    _fname, pRtcpContext, pRtcpAddrDesc, pRtpAddr
                ));
            
            /* This RtcpAddrDesc is about to shut down */
            RtpBitSet(pRtcpAddrDesc->dwAddrDescFlags, FGADDRD_SHUTDOWN1);
        }
        
        hr = NOERROR;
    }
    else
    {
        TraceRetail((
                CLASS_ERROR, GROUP_RTCP, S_RTCP_CMD,
                _T("%s: pRtcpContext[0x%p] pRtpAddr[0x%p] ")
                _T("failed: address not found in context"),
                _fname, pRtcpContext, pRtpAddr
            ));
    }

    return(hr);
}


/* Called from the RTCP worker thread whenever a RTCPTHRD_EXIT command
 * is received */
HRESULT RtcpThreadAddrCleanup(RtcpContext_t *pRtcpContext)
{
    RtcpAddrDesc_t  *pRtcpAddrDesc;
    RtpQueueItem_t  *pRtpQueueItem;
    RtpAddr_t       *pRtpAddr;

    TraceFunctionName("RtcpThreadAddrCleanup");

    TraceDebug((
            CLASS_INFO, GROUP_RTCP, S_RTCP_CMD,
            _T("%s: pRtcpContext[0x%p]"),
            _fname, pRtcpContext
        ));

    /* NOTE dequeing from *StopQ shouldn't be needed if all the
     * pending I/Os had completed when the sockets were closed. In
     * practice, some times execution makes that the sequence of: 1)
     * delete sockets; then 2) send EXIT command to the thread,
     * happens fast enough that the I/O completions don't have a
     * chance to run before the thread exits (they must have been
     * ready to complete with error WSA_OPERATION_ABORTED after the
     * sockets are closed) */

#if USE_RTCP_THREAD_POOL > 0
    /* Consume any pending IO commands */
    ConsumeRtcpIoChannel(pRtcpContext);
#endif /* USE_RTCP_THREAD_POOL > 0 */
   
    /* Visit the AddrDescStopQ */
    do
    {
        pRtpQueueItem = dequeuef(&pRtcpContext->AddrDescStopQ, NULL);

        if (pRtpQueueItem)
        {
            pRtcpAddrDesc =
                CONTAINING_RECORD(pRtpQueueItem, RtcpAddrDesc_t, AddrDescQItem);

            pRtpAddr = pRtcpAddrDesc->pRtpAddr;

            if (pRtcpAddrDesc->lRtcpPending > 0)
            {
                TraceRetail((
                        CLASS_WARNING, GROUP_RTCP, S_RTCP_CMD,
                        _T("%s: pRtcpContext[0x%p] ")
                        _T("pRtcpAddrDesc[0x%p] pRtpAddr[0x%p] ")
                        _T("RTCP I/O:%d"),
                        _fname, pRtcpContext, pRtcpAddrDesc, pRtpAddr,
                        pRtcpAddrDesc->lRtcpPending
                    ));
                
                /* Enqueue again for the benefit of ConsumeRtcpRecvFrom */
                enqueuef(&pRtcpContext->AddrDescStopQ, NULL, pRtpQueueItem);
                
                ConsumeRtcpRecvFrom(pRtcpContext, pRtcpAddrDesc);

                if (pRtcpAddrDesc->lRtcpPending > 0)
                {
                    TraceRetail((
                            CLASS_ERROR, GROUP_RTCP, S_RTCP_CMD,
                            _T("%s: pRtcpContext[0x%p] ")
                            _T("pRtcpAddrDesc[0x%p] pRtpAddr[0x%p] ")
                            _T("still RTCP I/O:%d"),
                            _fname, pRtcpContext, pRtcpAddrDesc, pRtpAddr,
                            pRtcpAddrDesc->lRtcpPending
                        ));

                    pRtcpAddrDesc->lRtcpPending = 0;

                    pRtpQueueItem = dequeue(&pRtcpContext->AddrDescStopQ,
                                            NULL,
                                            &pRtcpAddrDesc->AddrDescQItem);
                    if (!pRtpQueueItem)
                    {
                        TraceRetail((
                                CLASS_ERROR, GROUP_RTCP, S_RTCP_CMD,
                                _T("%s: pRtcpContext[0x%p] ")
                                _T("pRtcpAddrDesc[0x%p] pRtpAddr[0x%p] ")
                                _T("item not found in AddrDescStopQ"),
                                _fname, pRtcpContext, pRtcpAddrDesc, pRtpAddr
                            ));
                    }

                    pRtcpAddrDesc->AddrDescQItem.pvOther = NULL;
                }
            }
            
            if (pRtcpAddrDesc->lQosPending <= 0)
            {
                RtcpRemoveFromVector(pRtcpContext, pRtcpAddrDesc);

                /* RtcpAddrDesc will be put in the AddrDescFreeQ */
            }
        }
    } while(pRtpQueueItem);

    /* Visit the QosStopQ */
    do
    {
        pRtpQueueItem = dequeuef(&pRtcpContext->QosStopQ, NULL);

        if (pRtpQueueItem)
        {
            pRtcpAddrDesc =
                CONTAINING_RECORD(pRtpQueueItem, RtcpAddrDesc_t, QosQItem);

            pRtpAddr = pRtcpAddrDesc->pRtpAddr;

            if (pRtcpAddrDesc->lQosPending > 0)
            {
                TraceRetail((
                        CLASS_WARNING, GROUP_RTCP, S_RTCP_CMD,
                        _T("%s: pRtcpContext[0x%p] ")
                        _T("pRtcpAddrDesc[0x%p] pRtpAddr[0x%p] ")
                        _T("QOS I/O:%d"),
                        _fname, pRtcpContext, pRtcpAddrDesc, pRtpAddr,
                        pRtcpAddrDesc->lQosPending
                    ));

                /* Enqueue again for the benefit of ConsumeRtcpQosNotify */
                enqueuef(&pRtcpContext->QosStopQ, NULL, pRtpQueueItem);
                
                ConsumeRtcpQosNotify(pRtcpContext, pRtcpAddrDesc);

                if (pRtcpAddrDesc->lQosPending > 0)
                {
                    TraceRetail((
                            CLASS_ERROR, GROUP_RTCP, S_RTCP_CMD,
                            _T("%s: pRtcpContext[0x%p] ")
                            _T("pRtcpAddrDesc[0x%p] pRtpAddr[0x%p] ")
                            _T("still QOS I/O:%d"),
                            _fname, pRtcpContext, pRtcpAddrDesc, pRtpAddr,
                            pRtcpAddrDesc->lQosPending
                        ));

                    pRtcpAddrDesc->lQosPending = 0;
                }
                
                RtcpRemoveFromVector(pRtcpContext, pRtcpAddrDesc);

                /* RtcpAddrDesc will be put in the AddrDescFreeQ */
            }
        }
    } while(pRtpQueueItem);

    /* NOTE we DO need to make sure we call once RtcpAddrDescFree for
     * every pRtcpAddrDesc left in AddrDescFreeQ after doing the
     * above, we need it because it is here where the Event handles
     * for asynchronous I/O (QOS, Recv) will be closed */
    do
    {
        pRtpQueueItem = dequeuef(&pRtcpContext->AddrDescFreeQ, NULL);

        if (pRtpQueueItem)
        {
            pRtcpAddrDesc =
                CONTAINING_RECORD(pRtpQueueItem, RtcpAddrDesc_t,AddrDescQItem);

            RtcpAddrDescFree(pRtcpAddrDesc);
        }
    } while(pRtpQueueItem);

    return(NOERROR);
}

/* Return the interval time (in seconds) to wait before next timeout
 * will expire */
double RtcpOnTimeout(RtcpContext_t *pRtcpContext)
{
    double           dNextTime;
    double           dNextTime2;
    double           dCurrentTime;
    double           dDelta;

    TraceFunctionName("RtcpOnTimeout");

    /* Check Users that need to timeout */
    dNextTime = RtpAddrTimeout(pRtcpContext);
    
    /* Send RTCP reports if necesary */
    dNextTime2 = RtcpSendReports(pRtcpContext);

    if (dNextTime2 < dNextTime)
    {
        dNextTime = dNextTime2;
    }
    
    /* MAYDO check for asyncrhronous reception that needs to be
     * started and asynchronous QOS notifications (right now,
     * asynchronous QOS notifications are started once or in every
     * Reserve, if they fail, they will no be re-started later) */

    dCurrentTime = RtpGetTimeOfDay((RtpTime_t *)NULL);

    if (dNextTime > dCurrentTime)
    {
        dDelta = dNextTime - dCurrentTime;
    }
    else
    {
        dDelta = 0.01; /* 10 ms */
    }
    
    TraceDebugAdvanced((
            0, GROUP_RTCP, S_RTCP_TIMING,
            _T("%s: Wait time: %0.3f s (Next:%0.3f, Curr:%0.3f Delta:%0.3f)"),
            _fname, dNextTime - dCurrentTime,
            dNextTime, dCurrentTime, dNextTime - dCurrentTime
        ));
   
    return(dDelta);
}

/* Timeout users in all addresses, do that periodically (e.g. every
 * second). Return the moment time (in seconds from the RTP start) at
 * which a new test is required */
double RtpAddrTimeout(RtcpContext_t *pRtcpContext)
{
    RtcpAddrDesc_t  *pRtcpAddrDesc;
    RtpQueueItem_t  *pRtpQueueItem;
    RtpAddr_t       *pRtpAddr;
    long             lCount;
    double           dDelta;
    double           dCurrentTime;
    double           dTimeToNextTest;
    double           dTimeToNextTest2;
   
    TraceFunctionName("RtpAddrTimeout");

    lCount = GetQueueSize(&pRtcpContext->AddrDescBusyQ);

    dCurrentTime = 0;
    
    for(dTimeToNextTest = BIG_TIME; lCount > 0; lCount--)
    {
        dCurrentTime = RtpGetTimeOfDay((RtpTime_t *)NULL);
        
        /* Start with the last one */
        pRtpQueueItem = pRtcpContext->AddrDescBusyQ.pFirst->pPrev;

        pRtcpAddrDesc =
            CONTAINING_RECORD(pRtpQueueItem, RtcpAddrDesc_t, AddrDescQItem);

        pRtpAddr = pRtcpAddrDesc->pRtpAddr;

        if (!RtpBitTest(pRtcpAddrDesc->dwAddrDescFlags, FGADDRD_SHUTDOWN1))
        {
            /* Age users in this RtpAddr (only if not shutting down) */
            dTimeToNextTest2 = RtpUserTimeout(pRtpAddr);

            if (dTimeToNextTest2 < dTimeToNextTest)
            {
                dTimeToNextTest = dTimeToNextTest2;
            }
        }
        
        /* Move item to the first place and prepare to check what
         * is left at the end... */
        move2first(&pRtcpContext->AddrDescBusyQ, NULL, pRtpQueueItem);
    }

    TraceDebug((
            0, GROUP_RTCP, S_RTCP_TIMING,
            _T("%s:  Time for next addr timeout test: %0.3f (+%0.3f)"),
            _fname, dTimeToNextTest, dTimeToNextTest-dCurrentTime
        ));
   
    return(dTimeToNextTest);
}

/* These are the offsets from RtpAddr_t to the queues to visit */
const DWORD g_dwRtpQueueOffset[] = {CACHE1Q, CACHE2Q, ALIVEQ, BYEQ};

#define ITEMS (sizeof(g_dwRtpQueueOffset)/sizeof(DWORD))

#define HEADQ(_addr, _off) ((RtpQueue_t *)((char *)_addr + (_off)))

const TCHAR *g_psAddrQNames[] = {
    _T("Cache1Q"),
    _T("Cache2Q"),
    _T("AliveQ"),
    _T("ByeQ")
};

/* Return the moment in time (seconds) for the next test */
double RtpUserTimeout(RtpAddr_t *pRtpAddr)
{
    BOOL             bOk;
    RtpUser_t       *pRtpUser;
    RtpQueueItem_t  *pRtpQueueItem;
    RtpNetCount_t   *pRtpNetCount;
    long             lCount;
    DWORD            dwCurrentState;
    double           dDelta;
    double           dCurrentTime;
    double           dLastPacket;
    double           dTimeToNextTest;
    double           dTimeToNextTest2;
    double           dTimer;
    DWORD            i;
    RtpQueue_t      *pRtpQueue;

    TraceFunctionName("RtpUserTimeout");

    dCurrentTime = RtpGetTimeOfDay((RtpTime_t *)NULL);
    dTimeToNextTest = BIG_TIME;
    
    bOk = RtpEnterCriticalSection(&pRtpAddr->PartCritSect);

    if (bOk)
    {
        for(i = 0; i < ITEMS; i++)
        {
            pRtpQueue = HEADQ(pRtpAddr, g_dwRtpQueueOffset[i]);
            
            lCount = GetQueueSize(pRtpQueue);

            if (lCount <= 0)
            {
                continue;
            }
            
            pRtpQueueItem = pRtpQueue->pFirst->pPrev;

            pRtpUser =
                CONTAINING_RECORD(pRtpQueueItem, RtpUser_t, UserQItem);

            pRtpNetCount = &pRtpUser->RtpUserCount;

            do
            {
                pRtpQueueItem = pRtpQueue->pFirst->pPrev;

                pRtpUser = CONTAINING_RECORD(pRtpQueueItem,
                                             RtpUser_t,
                                             UserQItem);

                pRtpNetCount = &pRtpUser->RtpUserCount;
                
                /* Use the right timer according to the user's state */
                dwCurrentState = pRtpUser->dwUserState;

                if (dwCurrentState == RTPPARINFO_TALKING)
                {
                    dTimer = RTPPARINFO_TIMER1;
                }
                else
                {
                    dTimer =
                        g_dwTimesRtcpInterval[dwCurrentState] *
                        pRtpAddr->RtpNetSState.dRtcpInterval;
                }

                /* Use last RTP packet for states TALKING and
                 * WAS_TALKING but use the most recent of RTP or RTCP
                 * for the other states */
                dLastPacket = pRtpNetCount->dRTPLastTime;
                
                if (!( (dwCurrentState == RTPPARINFO_TALKING) ||
                       (dwCurrentState == RTPPARINFO_WAS_TALKING) ))
                {
                    if (pRtpNetCount->dRTCPLastTime > dLastPacket)
                    {
                        dLastPacket = pRtpNetCount->dRTCPLastTime;
                    }
                }

                /* Consider a timeout if we are already 50ms close */
                dDelta = dCurrentTime - dLastPacket + 0.05;
                    
                if (dDelta >= dTimer)
                {
                    /* We have a timeout */
                    
                    TraceDebugAdvanced((
                            0, GROUP_RTCP, S_RTCP_TIMEOUT,
                            _T("%s: pRtpAddr[0x%p] pRtpUser[0x%p] SSRC:0x%X ")
                            _T("%s timeout: Last[%s]:%0.3f (%0.3f) ")
                            _T("Timer[%s]:%0.3f Delta:%0.3f"),
                            _fname,
                            pRtpAddr, pRtpUser, ntohl(pRtpUser->dwSSRC),
                            g_psAddrQNames[i],
                            (pRtpNetCount->dRTPLastTime == dLastPacket)?
                            _T("RTP") : _T("RTCP"),
                            dLastPacket, dLastPacket-dCurrentTime,
                            g_psRtpUserStates[dwCurrentState], dTimer,
                            dDelta-0.05
                        ));

                    /* Obtain the next state now as this event may
                     * cause the RtpUser_t structure to be deleted,
                     * next state is dependent only on the current
                     * state and the user event (states machine) */
                    dwCurrentState = RtpGetNextUserState(dwCurrentState,
                                                         USER_EVENT_TIMEOUT);
                    
                    RtpUpdateUserState(pRtpAddr, pRtpUser, USER_EVENT_TIMEOUT);

                    /* Set the timer to be the value for the timer in
                     * the (new) current state if that is not
                     * RTPPARINFO_DEL */
                    if (dwCurrentState != RTPPARINFO_DEL)
                    {
                        if (dwCurrentState == RTPPARINFO_TALKING)
                        {
                            dTimeToNextTest2 = RTPPARINFO_TIMER1;
                        }
                        else
                        {
                            dTimeToNextTest2 =
                                g_dwTimesRtcpInterval[dwCurrentState] *
                                pRtpAddr->RtpNetSState.dRtcpInterval;
                        }
                    
                        dTimeToNextTest2 += dLastPacket;
                    }
                }
                else
                {
                    /* This user hasn't timeout, as active users are
                     * always moved to the first place, inactive ones
                     * move automatically to the end as a side effect
                     * and hence finding a non timeout user, while
                     * searching from end to begining, guarantee that
                     * there are no more users that have timeout */
                    dTimeToNextTest2 = dLastPacket + dTimer;

                    TraceDebugAdvanced((
                            0, GROUP_RTCP, S_RTCP_TIMING,
                            _T("%s: pRtpAddr[0x%p] pRtpUser[0x%p] SSRC:0x%X ")
                            _T("%s Timer[%s]:%0.3f ")
                            _T("Time at next timeout: %0.3f (+%0.3f)"),
                            _fname,
                            pRtpAddr, pRtpUser, ntohl(pRtpUser->dwSSRC),
                            g_psAddrQNames[i],
                            g_psRtpUserStates[dwCurrentState], dTimer,
                            dTimeToNextTest2, dTimeToNextTest2-dCurrentTime
                        ));
                }

                if (dTimeToNextTest2 < dTimeToNextTest)
                {
                    dTimeToNextTest = dTimeToNextTest2;
                }

                lCount--;
                
            } while(lCount && (dDelta >= dTimer));
        }
        
        RtpLeaveCriticalSection(&pRtpAddr->PartCritSect);
    }
    
    return(dTimeToNextTest);
}

/* Return the moment in time (seconds) for the next report */
double RtcpSendReports(RtcpContext_t *pRtcpContext)
{
    RtcpAddrDesc_t  *pRtcpAddrDesc;
    RtpQueueItem_t  *pRtcpSendQItem;
    double           dCurrentTime;
    double           dTimeToNextReport;
    double           dTimeToNextReport2;
    double           dDelta;
    BOOL             bSendReport;

    TraceFunctionName("RtcpSendReports");
    
    dTimeToNextReport = BIG_TIME;
    
    /* Check if there are RTCP reports to be sent */
    do {
        bSendReport = FALSE;
    
        dCurrentTime = RtpGetTimeOfDay((RtpTime_t *)NULL);
        
        pRtcpSendQItem = pRtcpContext->SendReportQ.pFirst;

        if (pRtcpSendQItem) {
        
            pRtcpAddrDesc =
                CONTAINING_RECORD(pRtcpSendQItem, RtcpAddrDesc_t, SendQItem);

            if (RtpBitTest(pRtcpAddrDesc->dwAddrDescFlags, FGADDRD_SHUTDOWN1))
            {
                /* If shutting down, just move to the end */
                dequeue(&pRtcpContext->SendReportQ,
                        NULL,
                        pRtcpSendQItem);

                enqueuedK(&pRtcpContext->SendReportQ,
                          NULL,
                          pRtcpSendQItem,
                          BIG_TIME);

                continue;
            }
            
            if (pRtcpAddrDesc->SendQItem.dKey <= dCurrentTime) {

                /* Send RTCP report */
                bSendReport = TRUE;
                
            } else {
                dDelta = pRtcpAddrDesc->SendQItem.dKey - dCurrentTime;

                if (dDelta < 0.1 /* 100 ms */) {
                    
                    /* Send RTCP report now before its due time */
                    bSendReport = TRUE;
                    
                } else {
                    /* Sleep until the time for next report is due */
                    bSendReport = FALSE;

                    dTimeToNextReport = dCurrentTime + dDelta;
                }
            }

            if (bSendReport) {
                /* Send RTCP report */

                dequeue(&pRtcpContext->SendReportQ,
                        NULL,
                        pRtcpSendQItem);

                /* Obtain the time to next report. Do it before
                 * actually sending the report so we know if we are a
                 * receiver or a sender (send RR or SR) */
                dTimeToNextReport2 =
                    dCurrentTime +
                    RtcpNextReportInterval(pRtcpAddrDesc->pRtpAddr);

                if (!RtpBitTest(pRtcpAddrDesc->dwAddrDescFlags,
                                FGADDRD_SHUTDOWN1))
                {
                    /* Send report only if not shutting down */
                    RtcpSendReport(pRtcpAddrDesc);
                }

                if (dTimeToNextReport2 < dTimeToNextReport)
                {
                    dTimeToNextReport = dTimeToNextReport2;
                }
                
                /* Insert in ascending order using the
                 * dTimeToNextReport2 as a Key */
                enqueuedK(&pRtcpContext->SendReportQ,
                          NULL,
                          pRtcpSendQItem,
                          dTimeToNextReport2);

                TraceDebugAdvanced((
                        0, GROUP_RTCP, S_RTCP_TIMING,
                        _T("%s: pRtpAddr[0x%p] Time to next RTCP report: ")
                        _T("%0.3f (+%0.3f)"),
                        _fname, pRtcpAddrDesc->pRtpAddr,
                        dTimeToNextReport2, dTimeToNextReport2-dCurrentTime
                    ));
            }
        }
    } while(bSendReport);

    TraceDebug((
            0, GROUP_RTCP, S_RTCP_TIMING,
            _T("%s: pRtcpContext[0x%p] Time to next RTCP report: ")
            _T("%0.3f (+%0.3f)"),
            _fname, pRtcpContext,
            dTimeToNextReport, dTimeToNextReport-dCurrentTime
        ));
    

    return(dTimeToNextReport);
}

/**********************************************************************
 * RtcpAddrDesc_t handling
 **********************************************************************/

/* Creates and initializes a ready to use RtcpAddrDesc_t structure */
RtcpAddrDesc_t *RtcpAddrDescAlloc(
        RtpAddr_t       *pRtpAddr
    )
{
    DWORD            dwError;
    RtcpAddrDesc_t  *pRtcpAddrDesc;

    TraceFunctionName("RtcpAddrDescAlloc");

    pRtcpAddrDesc =
        RtpHeapAlloc(g_pRtcpAddrDescHeap, sizeof(RtcpAddrDesc_t));

    if (!pRtcpAddrDesc)
    {
        TraceRetail((
                CLASS_ERROR, GROUP_ADDRDESC, S_ADDRDESC_ALLOC,
                _T("%s: failed to allocate memory"),
                _fname
            ));

        goto bail;
    }

    ZeroMemory(pRtcpAddrDesc, sizeof(RtcpAddrDesc_t));
        
    pRtcpAddrDesc->dwObjectID = OBJECTID_RTCPADDRDESC;

    /* Overlapped RTCP reception */
    pRtcpAddrDesc->pRtcpRecvIO = RtcpRecvIOAlloc(pRtcpAddrDesc);

    if (!pRtcpAddrDesc->pRtcpRecvIO)
    {
        goto bail;
    }

    /* RTCP send */
    pRtcpAddrDesc->pRtcpSendIO = RtcpSendIOAlloc(pRtcpAddrDesc);
    
    if (!pRtcpAddrDesc->pRtcpSendIO)
    {
        goto bail;
    }
    
    /* Asynchronous QOS notifications */
#if USE_RTCP_THREAD_POOL > 0
    /* If using thread pool, create RtpQosNotify_t structure
     * conditionally */
    if (RtpBitTest(pRtpAddr->dwIRtpFlags, FGADDR_IRTP_QOS))
    {
        pRtcpAddrDesc->pRtpQosNotify = RtpQosNotifyAlloc(pRtcpAddrDesc);

        if (!pRtcpAddrDesc->pRtpQosNotify)
        {
            goto bail;
        }
    }
#else /* USE_RTCP_THREAD_POOL > 0 */
    /* If NOT using thread pool, ALWAYS create RtpQosNotify_t
     * structure */
    pRtcpAddrDesc->pRtpQosNotify = RtpQosNotifyAlloc(pRtcpAddrDesc);

    if (!pRtcpAddrDesc->pRtpQosNotify)
    {
        goto bail;
    }
#endif /* USE_RTCP_THREAD_POOL > 0 */
    
    return(pRtcpAddrDesc);
    
 bail:

    RtcpAddrDescFree(pRtcpAddrDesc);
    
    return((RtcpAddrDesc_t *)NULL);
}

/* Frees a RtcpAddrDesc_t structure */
void RtcpAddrDescFree(RtcpAddrDesc_t *pRtcpAddrDesc)
{
    TraceFunctionName("RtcpAddrDescFree");

    if (!pRtcpAddrDesc)
    {
        /* TODO may be log */
        return;
    }

    if (pRtcpAddrDesc->dwObjectID != OBJECTID_RTCPADDRDESC)
    {
        TraceRetail((
                CLASS_ERROR, GROUP_RTCP, S_RTCP_ALLOC,
                _T("%s: pRtcpAddrDesc[0x%p] Invalid object ID 0x%X != 0x%X"),
                _fname, pRtcpAddrDesc,
                pRtcpAddrDesc->dwObjectID, OBJECTID_RTCPADDRDESC
            ));

        return;
    }

    /* Asynchronous reception */
    if (pRtcpAddrDesc->pRtcpRecvIO)
    {
        RtcpRecvIOFree(pRtcpAddrDesc->pRtcpRecvIO);
        
        pRtcpAddrDesc->pRtcpRecvIO = (RtcpRecvIO_t *)NULL;
    }

    /* Sender */
    if (pRtcpAddrDesc->pRtcpSendIO)
    {
        RtcpSendIOFree(pRtcpAddrDesc->pRtcpSendIO);
        
        pRtcpAddrDesc->pRtcpSendIO = (RtcpSendIO_t *)NULL;
    }

    /* Asynchronous QOS notifications */
    if (pRtcpAddrDesc->pRtpQosNotify)
    {
        RtpQosNotifyFree(pRtcpAddrDesc->pRtpQosNotify);

        pRtcpAddrDesc->pRtpQosNotify = (RtpQosNotify_t *)NULL;
    }

    /* Invalidate object */
    INVALIDATE_OBJECTID(pRtcpAddrDesc->dwObjectID);
    
    RtpHeapFree(g_pRtcpAddrDescHeap, pRtcpAddrDesc);
}

/* Get a ready to use RtcpAddrDesc_t from the AddrDescFreeQ, if empty
 * create a new one */
RtcpAddrDesc_t *RtcpAddrDescGetFree(
        RtcpContext_t   *pRtcpContext,
        RtpAddr_t       *pRtpAddr
    )
{
    RtcpAddrDesc_t  *pRtcpAddrDesc;
    RtpQueueItem_t  *pRtpQueueItem;

    RtpQosNotify_t  *pRtpQosNotify;
    RtcpRecvIO_t    *pRtcpRecvIO;
    RtcpSendIO_t    *pRtcpSendIO;
    
    pRtcpAddrDesc = (RtcpAddrDesc_t *)NULL;

    /* Don't need a critical section as this function is ONLY called
     * by the RTCP thread */
    pRtpQueueItem = dequeuef(&pRtcpContext->AddrDescFreeQ, NULL);

    if (pRtpQueueItem)
    {
        pRtcpAddrDesc =
            CONTAINING_RECORD(pRtpQueueItem, RtcpAddrDesc_t, AddrDescQItem);

        if ( (RtpBitTest(pRtpAddr->dwIRtpFlags, FGADDR_IRTP_QOS) &&
              !pRtcpAddrDesc->pRtpQosNotify) ||
             (!RtpBitTest(pRtpAddr->dwIRtpFlags, FGADDR_IRTP_QOS) &&
              pRtcpAddrDesc->pRtpQosNotify) )
        {
            /* Not the kind we need, return it to the free queue */
            enqueuel(&pRtcpContext->AddrDescFreeQ, NULL, pRtpQueueItem);

            pRtcpAddrDesc = (RtcpAddrDesc_t *)NULL;
        }
        else
        {
            /* Save some pointers */
            pRtpQosNotify = pRtcpAddrDesc->pRtpQosNotify;
            pRtcpRecvIO = pRtcpAddrDesc->pRtcpRecvIO;
            pRtcpSendIO = pRtcpAddrDesc->pRtcpSendIO;

            ZeroMemory(pRtcpAddrDesc, sizeof(RtcpAddrDesc_t));
        
            pRtcpAddrDesc->dwObjectID = OBJECTID_RTCPADDRDESC;

            /* Restore saved pointers */
            pRtcpAddrDesc->pRtpQosNotify = pRtpQosNotify;
            pRtcpAddrDesc->pRtcpRecvIO = pRtcpRecvIO;
            pRtcpAddrDesc->pRtcpSendIO = pRtcpSendIO;
        }
    }

    if (!pRtcpAddrDesc)
    {
        pRtcpAddrDesc = RtcpAddrDescAlloc(pRtpAddr);
    }

    return(pRtcpAddrDesc);
}

/* Returns an address descriptor to the FreeQ to be reused later */
RtcpAddrDesc_t *RtcpAddrDescPutFree(
        RtcpContext_t   *pRtcpContext,
        RtcpAddrDesc_t  *pRtcpAddrDesc
    )
{
    TraceFunctionName("RtcpAddrDescPutFree");  

    /* Do some sanity tests */
    if ( InQueue(&pRtcpAddrDesc->AddrDescQItem) ||
         InQueue(&pRtcpAddrDesc->QosQItem)      ||
         InQueue(&pRtcpAddrDesc->RecvQItem)     ||
         InQueue(&pRtcpAddrDesc->SendQItem) )
    {
        TraceRetail((
                CLASS_ERROR, GROUP_RTCP, S_RTCP_ALLOC,
                _T("%s: pRtcpContext[0x%p] pRtcpAddrDesc[0x%p] ")
                _T("still in a queue"),
                _fname, pRtcpContext, pRtcpAddrDesc
            ));
        
        pRtcpAddrDesc = (RtcpAddrDesc_t *)NULL;
    }
    else
    {
        if (IsSetDebugOption(OPTDBG_FREEMEMORY))
        {
            RtcpAddrDescFree(pRtcpAddrDesc);
        }
        else
        {
            enqueuef(&pRtcpContext->AddrDescFreeQ,
                     NULL,
                     &pRtcpAddrDesc->AddrDescQItem);
        }
    }
    
    return(pRtcpAddrDesc);
}

#if USE_RTCP_THREAD_POOL > 0
HRESULT RtcpAddToVector(
        RtcpContext_t   *pRtcpContext,
        RtcpAddrDesc_t  *pRtcpAddrDesc
    )
{
    BOOL             bOk;
    DWORD            dwError;
    
    TraceFunctionName("RtcpAddToVector");

    TraceDebug((
            CLASS_INFO, GROUP_RTCP, S_RTCP_CMD,
            _T("%s: pRtcpContext[0x%p] pRtcpAddrDesc[0x%p] "),
            _fname, pRtcpContext, pRtcpAddrDesc
        ));

    bOk = RegisterWaitForSingleObject( 
            &pRtcpAddrDesc->hRecvWaitObject,/* PHANDLE phNewWaitObject */
            pRtcpAddrDesc->pRtcpRecvIO->
            hRtcpCompletedEvent,         /* HANDLE hObject */
            RtcpRecvCallback,            /* WAITORTIMERCALLBACK Callback */
            (void *)pRtcpAddrDesc,       /* PVOID Context */
            INFINITE,                    /* ULONG dwMilliseconds */
            WT_EXECUTEINWAITTHREAD       /* ULONG dwFlags */
        );

    if (!bOk)
    {
        TraceRetailGetError(dwError);
        
        TraceRetail((
                CLASS_ERROR, GROUP_RTCP, S_RTCP_CMD,
                _T("%s: pRtcpContext[0x%p] pRtcpAddrDesc[0x%p] ")
                _T("RegisterWaitForSingleObject(Recv:0x%X) failed: %u (0x%X)"),
                _fname, pRtcpContext, pRtcpAddrDesc,
                pRtcpAddrDesc->pRtcpRecvIO->hRtcpCompletedEvent,
                dwError, dwError
            ));
        
        goto bail;
    }

    RtpBitSet(pRtcpAddrDesc->dwAddrDescFlags, FGADDRD_INVECTORRECV);

    if (RtpBitTest(pRtcpAddrDesc->pRtpAddr->dwIRtpFlags, FGADDR_IRTP_QOS))
    {
        bOk = RegisterWaitForSingleObject( 
                &pRtcpAddrDesc->hQosWaitObject,/* PHANDLE phNewWaitObject */
                pRtcpAddrDesc->pRtpQosNotify->
                hQosNotifyEvent,             /* HANDLE hObject */
                RtcpQosCallback,             /* WAITORTIMERCALLBACK Callback */
                (void *)pRtcpAddrDesc,       /* PVOID Context */
                INFINITE,                    /* ULONG dwMilliseconds */
                WT_EXECUTEINWAITTHREAD       /* ULONG dwFlags */
            );

        if (!bOk)
        {
            TraceRetailGetError(dwError);
            
            TraceRetail((
                    CLASS_ERROR, GROUP_RTCP, S_RTCP_CMD,
                    _T("%s: pRtcpContext[0x%p] pRtcpAddrDesc[0x%p] ")
                    _T("RegisterWaitForSingleObject(Qos:0x%X) failed: %u (0x%X)"),
                    _fname, pRtcpContext,
                    pRtcpAddrDesc->pRtpQosNotify->hQosNotifyEvent,
                    pRtcpAddrDesc, dwError, dwError
                ));
        
            goto bail;
        }

        RtpBitSet(pRtcpAddrDesc->dwAddrDescFlags, FGADDRD_INVECTORQOS);
    }

    pRtcpContext->dwMaxDesc++;

    return(NOERROR);

 bail:
    RtcpRemoveFromVector(pRtcpContext, pRtcpAddrDesc);

    return(RTPERR_RESOURCES);
}

HRESULT RtcpRemoveFromVector(
        RtcpContext_t   *pRtcpContext,
        RtcpAddrDesc_t  *pRtcpAddrDesc
    )
{
    BOOL             bOk;
    DWORD            dwError;
    HANDLE           hEvent;
    DWORD            dwFlags;
    
    TraceFunctionName("RtcpRemoveFromVector");

    TraceDebug((
            CLASS_INFO, GROUP_RTCP, S_RTCP_CMD,
            _T("%s: pRtcpContext[0x%p] pRtcpAddrDesc[0x%p] "),
            _fname, pRtcpContext, pRtcpAddrDesc
        ));
    
    hEvent = NULL;
    dwFlags = 0;

    if (pRtcpAddrDesc->pRtcpRecvIO)
    {
        hEvent = pRtcpAddrDesc->pRtcpRecvIO->hRtcpCompletedEvent;
    }
            
    if (RtpBitTest(pRtcpAddrDesc->dwAddrDescFlags, FGADDRD_INVECTORRECV))
    {
        RtpBitSet(dwFlags, FGADDRD_INVECTORRECV);
        
        bOk = UnregisterWaitEx(
                pRtcpAddrDesc->hRecvWaitObject,  /* HANDLE WaitHandle */
                INVALID_HANDLE_VALUE             /* HANDLE CompletionEvent */
            );

        if (bOk)
        {
            pRtcpAddrDesc->hRecvWaitObject = NULL; 
        }
        else
        {
            TraceRetailGetError(dwError);
        
            /* Save the error */
            pRtcpAddrDesc->hRecvWaitObject = (HANDLE)UIntToPtr(dwError);

            TraceRetail((
                    CLASS_ERROR, GROUP_RTCP, S_RTCP_CMD,
                    _T("%s: pRtcpContext[0x%p] pRtcpAddrDesc[0x%p] ")
                    _T("UnregisterWaitEx(Recv:0x%X) failed: %u (0x%X)"),
                    _fname, pRtcpContext, pRtcpAddrDesc, hEvent,
                    dwError, dwError
                ));
        }

        RtpBitReset(pRtcpAddrDesc->dwAddrDescFlags, FGADDRD_INVECTORRECV);
    }
    else
    {
        TraceRetail((
                CLASS_WARNING, GROUP_RTCP, S_RTCP_CMD,
                _T("%s: pRtcpContext[0x%X] pRtcpAddrDesc[0x%p] ")
                _T("handle[0x%p] is not in vector"),
                _fname, pRtcpContext, pRtcpAddrDesc,
                hEvent
            ));
    }
    
    hEvent = NULL;
    
    if (pRtcpAddrDesc->pRtpQosNotify)
    {
        hEvent = pRtcpAddrDesc->pRtpQosNotify->hQosNotifyEvent;
    }
    
    if (RtpBitTest(pRtcpAddrDesc->dwAddrDescFlags, FGADDRD_INVECTORQOS))
    {
        RtpBitSet(dwFlags, FGADDRD_INVECTORQOS);
        
        bOk = UnregisterWaitEx(
                pRtcpAddrDesc->hQosWaitObject,   /* HANDLE WaitHandle */
                INVALID_HANDLE_VALUE             /* HANDLE CompletionEvent */
            );

        if (bOk)
        {
            pRtcpAddrDesc->hQosWaitObject = NULL;
        }
        else
        {
            TraceRetailGetError(dwError);

            /* Save the error */
            pRtcpAddrDesc->hQosWaitObject = (HANDLE)UIntToPtr(dwError);
            
            TraceRetail((
                    CLASS_ERROR, GROUP_RTCP, S_RTCP_CMD,
                    _T("%s: pRtcpContext[0x%p] pRtcpAddrDesc[0x%p] ")
                    _T("UnregisterWaitEx(Qos:0x%X) failed: %u (0x%X)"),
                    _fname, pRtcpContext, pRtcpAddrDesc, hEvent,
                    dwError, dwError
                ));
        }

        RtpBitReset(pRtcpAddrDesc->dwAddrDescFlags, FGADDRD_INVECTORQOS);
    }
    else
    {
        if (!RtpBitTest(pRtcpAddrDesc->pRtpAddr->dwIRtpFlags, FGADDR_IRTP_QOS))
        {
            /* Session was not QOS enabled */
            RtpBitSet(dwFlags, FGADDRD_INVECTORQOS);
        }
        else
        {
            TraceRetail((
                    CLASS_WARNING, GROUP_RTCP, S_RTCP_CMD,
                    _T("%s: pRtcpContext[0x%X] pRtcpAddrDesc[0x%p] ")
                    _T("handle[0x%p] is not in vector"),
                    _fname, pRtcpContext, pRtcpAddrDesc,
                    hEvent
                ));
        }
    }

    if (RtpBitTest2(dwFlags, FGADDRD_INVECTORRECV, FGADDRD_INVECTORQOS) ==
        RtpBitPar2(FGADDRD_INVECTORRECV, FGADDRD_INVECTORQOS))
    {
        /* Only do this if this is a valid removal, i.e. both wait
         * objects were successfully registered before */
        
        pRtcpContext->dwMaxDesc--;

        /* Return RtcpAddrDesc to the free pool */
        RtcpAddrDescPutFree(pRtcpContext, pRtcpAddrDesc);
    }
    else
    {
        TraceRetail((
                CLASS_ERROR, GROUP_RTCP, S_RTCP_CMD,
                _T("%s: pRtcpContext[0x%p] pRtcpAddrDesc[0x%p] ")
                _T("Invalid attempt to remove, flags:0x%X"),
                _fname, pRtcpContext, pRtcpAddrDesc,
                dwFlags
            ));
    }
    
    return(NOERROR);
}

#else /* USE_RTCP_THREAD_POOL > 0 */

HRESULT RtcpAddToVector(
        RtcpContext_t   *pRtcpContext,
        RtcpAddrDesc_t  *pRtcpAddrDesc
    )
{
    DWORD            dwIndex;
    
    TraceFunctionName("RtcpAddToVector");

    pRtcpAddrDesc->dwDescIndex = pRtcpContext->dwMaxDesc;

    /* Find absolute index to use in handles vector */
    dwIndex = (pRtcpContext->dwMaxDesc * RTCP_HANDLE_SIZE) +
        RTCP_HANDLE_OFFSET;

    /* Event handles... */
    pRtcpContext->pHandle[dwIndex] =
        pRtcpAddrDesc->pRtcpRecvIO->hRtcpCompletedEvent;

    pRtcpContext->pHandle[dwIndex + 1] =
        pRtcpAddrDesc->pRtpQosNotify->hQosNotifyEvent;
        
    /* ...and matching RtcpAddrDesc */
    pRtcpContext->ppRtcpAddrDesc[pRtcpContext->dwMaxDesc] = pRtcpAddrDesc;

    pRtcpContext->dwMaxDesc++;

    /* Placed in vector */
    RtpBitSet2(pRtcpAddrDesc->dwAddrDescFlags,
               FGADDRD_INVECTORRECV, FGADDRD_INVECTORQOS);
        
    TraceDebug((
            CLASS_INFO, GROUP_RTCP, S_RTCP_CMD,
            _T("%s: pRtcpContext[0x%p] ")
            _T("pRtcpAddrDesc[0x%p] pRtpAddr[0x%p]"),
            _fname, pRtcpContext, pRtcpAddrDesc, pRtcpAddrDesc->pRtpAddr
        ));

    return(NOERROR);
}

/* Remove from event vector */
HRESULT RtcpRemoveFromVector(
        RtcpContext_t   *pRtcpContext,
        RtcpAddrDesc_t  *pRtcpAddrDesc
    )
{
    DWORD     dwDescIndex; /* descriptor index */
    DWORD     dwCount; /* number of logical items to move */
    DWORD     n;
    DWORD     srcH;    /* source handle */
    DWORD     dstH;    /* destination handle */
    DWORD     srcD;    /* source descriptor */
    DWORD     dstD;    /* destination descriptor */

    TraceFunctionName("RtcpRemoveFromVector");  

    if (!RtpBitTest(pRtcpAddrDesc->dwAddrDescFlags, FGADDRD_INVECTORRECV))
    {
        TraceRetail((
                CLASS_WARNING, GROUP_RTCP, S_RTCP_CMD,
                _T("%s: pRtcpContext[0x%p] pRtcpAddrDesc[0x%p] ")
                _T("is not in vector"),
                _fname, pRtcpContext, pRtcpAddrDesc
            ));

        return(NOERROR);
    }
    
    dwDescIndex = pRtcpAddrDesc->dwDescIndex;
    dwCount = pRtcpContext->dwMaxDesc - dwDescIndex - 1;

    if (dwCount > 0) {
        
        dstD = dwDescIndex;
        srcD = dwDescIndex + 1;

        dstH = RTCP_HANDLE_OFFSET + (dwDescIndex * RTCP_HANDLE_SIZE);
        srcH = dstH + RTCP_HANDLE_SIZE;

        while(dwCount > 0) {
            
            /* shift event handle(s) in vector */
            for(n = RTCP_HANDLE_SIZE; n > 0; n--, srcH++, dstH++) {
                pRtcpContext->pHandle[dstH] = pRtcpContext->pHandle[srcH];
            }
            
            /* shift matching address descriptor in vector */
            pRtcpContext->ppRtcpAddrDesc[dstD] =
                pRtcpContext->ppRtcpAddrDesc[srcD];

            /* now update new position in vector */
            pRtcpContext->ppRtcpAddrDesc[dstD]->dwDescIndex = dstD;

            srcD++;
            dstD++;
            dwCount--;
        }
    }

    /* Removed from events vector */
    RtpBitReset2(pRtcpAddrDesc->dwAddrDescFlags,
                 FGADDRD_INVECTORRECV, FGADDRD_INVECTORQOS);
    
    pRtcpContext->dwMaxDesc--;

    /* Return RtcpAddrDesc to the free pool */
    RtcpAddrDescPutFree(pRtcpContext, pRtcpAddrDesc);

    return(NOERROR);
}
#endif /* USE_RTCP_THREAD_POOL > 0 */

/*
 * Decide if we need to drop this packet or we have a collision */
BOOL RtpDropCollision(
        RtpAddr_t       *pRtpAddr,
        SOCKADDR_IN     *pSockAddrIn,
        BOOL             bRtp
    )
{
    BOOL             bCollision;
    BOOL             bDiscard;
    DWORD            dwOldSSRC;
    WORD            *pwPort;

    bCollision = FALSE;
    bDiscard = FALSE;

    if (bRtp)
    {
        pwPort = &pRtpAddr->wRtpPort[LOCAL_IDX];
    }
    else
    {
        pwPort = &pRtpAddr->wRtcpPort[LOCAL_IDX];
    }
    
    /* Find out if this is a collision or our own packet that we need
     * to discard */
                            
    if (RtpBitTest(pRtpAddr->dwAddrFlags, FGADDR_LOOPBACK_WS2))
    {
        /* Loopback is enabled in Winsock, detect collision only
         * between us and participants with different source
         * address/port */
                                
        if ((pRtpAddr->dwAddr[LOCAL_IDX] == pSockAddrIn->sin_addr.s_addr) &&
            (*pwPort == pSockAddrIn->sin_port))
        {
            /* Discard this packet, is ours */
            bDiscard = TRUE;
        }
        else
        {
            /* Collision detected */
            bCollision = TRUE;
        }
    }
    else
    {
        /* Loopback is disabled in Winsock, this must be a
         * collision */
        
        /* Collision detected */
        bCollision = TRUE;
    }

    if (bCollision)
    {
        /* Send BYE and get new random variables (including new SSRC) */

        /* Send BYE, need to do it asynchronously by sending a command
         * to the RTCP thread if the caller is a reception thread, or
         * directly calling the function if in the context of the RTCP
         * thread */
        
        if (bRtp)
        {
            /* Send command to RTCP thread to do it */
            RtcpThreadCmd(&g_RtcpContext,
                          pRtpAddr,
                          RTCPTHRD_SENDBYE,
                          FALSE,
                          60*60*1000); /* TODO update */
        }
        else
        {
            /* Just do it */
            RtcpThreadAddrSendBye(&g_RtcpContext, pRtpAddr, FALSE);
        }
        
        /* Reset counters and obtain new random values */
        
        /* Reset counters */
        RtpResetNetCount(&pRtpAddr->RtpAddrCount[RECV_IDX],
                         &pRtpAddr->NetSCritSect);
        RtpResetNetCount(&pRtpAddr->RtpAddrCount[SEND_IDX],
                         &pRtpAddr->NetSCritSect);
        
        /* Reset sender's network state */
        RtpResetNetSState(&pRtpAddr->RtpNetSState,
                          &pRtpAddr->NetSCritSect);
        
        dwOldSSRC = pRtpAddr->RtpNetSState.dwSendSSRC;

        /* Need to set it to zero to bypass the Init option
         * RTPINITFG_PERSISTSSRC (if in use) */
        pRtpAddr->RtpNetSState.dwSendSSRC = 0;
        
        /* Obtain new SSRC, random sequence number and timestamp */
        RtpGetRandomInit(pRtpAddr);

        /* Post event */
        RtpPostEvent(pRtpAddr,
                     NULL,
                     RTPEVENTKIND_RTP,
                     RTPRTP_LOCAL_COLLISION,
                     pRtpAddr->RtpNetSState.dwSendSSRC /* Par1: new SSRC */,
                     dwOldSSRC);
    }
    
    return(bDiscard);
}
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\net\tapi\skywalker\filters\rtp\msrtp\rtp\rtpchan.c ===
/**********************************************************************
 *
 *  Copyright (C) Microsoft Corporation, 1999
 *
 *  File name:
 *
 *    rtpchan.c
 *
 *  Abstract:
 *
 *    Implements a communication channel between the RTCP thread
 *
 *  Author:
 *
 *    Andres Vega-Garcia (andresvg)
 *
 *  Revision:
 *
 *    1999/07/08 created
 *
 **********************************************************************/

#include "rtpheap.h"
#include "rtpglobs.h"

#include "rtpchan.h"

RtpChannelCmd_t *RtpChannelCmdAlloc(
        RtpChannel_t    *pRtpChannel
    );

void RtpChannelCmdFree(
        RtpChannelCmd_t *pRtpChannelCmd
    );

RtpChannelCmd_t *RtpChannelCmdGetFree(
        RtpChannel_t    *pRtpChannel
    );

RtpChannelCmd_t *RtpChannelCmdPutFree(
        RtpChannel_t    *pRtpChannel,
        RtpChannelCmd_t *pRtpChannelCmd
    );


/* Initializes a channel
 *
 * WARNING: must be called before the channel can be used
 * */
HRESULT RtpChannelInit(
        RtpChannel_t    *pRtpChannel,
        void            *pvOwner
    )
{
    BOOL             bStatus;
    DWORD            dwError;
    RtpChannelCmd_t *pRtpChannelCmd;
    TCHAR            Name[128];
    
    TraceFunctionName("RtpChannelInit");

    ZeroMemory(pRtpChannel, sizeof(RtpChannel_t));

    bStatus =
        RtpInitializeCriticalSection(&pRtpChannel->ChannelCritSect,
                                     (void *)pRtpChannel,
                                     _T("ChannelCritSec"));

    if (!bStatus)
    {
        TraceRetail((
                CLASS_ERROR, GROUP_CHANNEL, S_CHANNEL_INIT,
                _T("%s: pRtpChannel[0x%p] ")
                _T("failed to initialize critical section"),
                _fname, pRtpChannel
            ));

        return(RTPERR_CRITSECT);
    }

    /* Create wait event */
    _stprintf(Name, _T("%X:pvOwner[0x%p] pRtpChannel[0x%p]->hWaitEvent"),
              GetCurrentProcessId(), pvOwner, pRtpChannel);

    pRtpChannel->hWaitEvent = CreateEvent(
            NULL,  /* LPSECURITY_ATTRIBUTES lpEventAttributes */
            FALSE, /* BOOL bManualReset */
            FALSE, /* BOOL bInitialState */
            Name   /* LPCTSTR lpName */
        );
    
    if (!pRtpChannel->hWaitEvent)
    {
        TraceRetailGetError(dwError);
            
        TraceRetail((
                CLASS_ERROR, GROUP_CHANNEL, S_CHANNEL_INIT,
                _T("%s: pRtpChannel[0x%p] failed to create ")
                _T("wait event: %u (0x%X)"),
                _fname, pRtpChannel, dwError, dwError
            ));

        RtpDeleteCriticalSection(&pRtpChannel->ChannelCritSect);

        return(RTPERR_EVENT);
    }
    
    /* Prepare one cmd */
    pRtpChannelCmd = RtpChannelCmdAlloc(pRtpChannel);

    if (pRtpChannelCmd)
    {
        RtpChannelCmdPutFree(pRtpChannel, pRtpChannelCmd);
    }
    
    return(NOERROR);
}

/* De-initializes a channel
 *
 * WARNING: must be called when the channel is not enaymore in use
 * */
HRESULT RtpChannelDelete(
        RtpChannel_t    *pRtpChannel
    )
{
    RtpQueueItem_t  *pRtpQueueItem;
    RtpChannelCmd_t *pRtpChannelCmd;
    long             lCount;
    
    TraceFunctionName("RtpChannelDelete");

    if ( !IsQueueEmpty(&pRtpChannel->CommandQ) )
    {
        lCount = GetQueueSize(&pRtpChannel->CommandQ);
        
        while( !IsQueueEmpty(&pRtpChannel->CommandQ) )
        {
            pRtpQueueItem = dequeuef(&pRtpChannel->CommandQ, NULL);
            
            if (pRtpQueueItem)
            {
                pRtpChannelCmd =
                    CONTAINING_RECORD(pRtpQueueItem,
                                      RtpChannelCmd_t,
                                      QueueItem);
                
                TraceDebug((
                        CLASS_WARNING, GROUP_CHANNEL, S_CHANNEL_INIT,
                        _T("%s: pRtpChannel[0x%p] pRtpChannelCmd[0x%p] ")
                        _T("not consumed: cmd:%u p1:0x%p p2:0x%p flags:0x%X"),
                        _fname, pRtpChannel, pRtpChannelCmd,
                        pRtpChannelCmd->dwCommand,
                        pRtpChannelCmd->dwPar1,
                        pRtpChannelCmd->dwPar2,
                        pRtpChannelCmd->dwFlags 
                    ));
                
                RtpChannelCmdFree(pRtpChannelCmd);
            }
        }

        TraceRetail((
                CLASS_WARNING, GROUP_CHANNEL, S_CHANNEL_INIT,
                _T("%s: pRtpChannel[0x%p] CommandQ was not empty: %d"),
                _fname, pRtpChannel, lCount
            ));
    }
    
    /* Scan FreeQ and free all not used commands */
    while( !IsQueueEmpty(&pRtpChannel->FreeQ) )
    {
        pRtpQueueItem = dequeuef(&pRtpChannel->FreeQ, NULL);

        if (pRtpQueueItem)
        {
            pRtpChannelCmd =
                CONTAINING_RECORD(pRtpQueueItem, RtpChannelCmd_t, QueueItem);
            
            RtpChannelCmdFree(pRtpChannelCmd);
        }
    }

    /* Close wait event handle */
    if (pRtpChannel->hWaitEvent)
    {
        CloseHandle(pRtpChannel->hWaitEvent);

        pRtpChannel->hWaitEvent = NULL;
    }
    
    RtpDeleteCriticalSection(&pRtpChannel->ChannelCritSect);

    return(NOERROR);
}

/* Creates and initializes a ready to use RtpChannelCmd_t structure */
RtpChannelCmd_t *RtpChannelCmdAlloc(
        RtpChannel_t    *pRtpChannel
    )
{
    DWORD            dwError;
    RtpChannelCmd_t *pRtpChannelCmd;
    TCHAR            Name[128];

    TraceFunctionName("RtpChannelCmdAlloc");

    pRtpChannelCmd =
        RtpHeapAlloc(g_pRtpChannelCmdHeap, sizeof(RtpChannelCmd_t));

    if (pRtpChannelCmd)
    {
        ZeroMemory(pRtpChannelCmd, sizeof(RtpChannelCmd_t));
        
        /* Create event for the answer */
        _stprintf(Name,
                  _T("%X:pRtpChannel[0x%p] pRtpChannelCmd[0x%X]->hSyncEvent"),
                  GetCurrentProcessId(), pRtpChannel, pRtpChannelCmd);
        
        pRtpChannelCmd->hSyncEvent = CreateEvent(
                NULL,  /* LPSECURITY_ATTRIBUTES lpEventAttributes */
                FALSE, /* BOOL bManualReset */
                FALSE, /* BOOL bInitialState */
                Name   /* LPCTSTR lpName */
            );

        if (!pRtpChannelCmd->hSyncEvent)
        {
            TraceRetailGetError(dwError);
            
            TraceRetail((
                    CLASS_ERROR, GROUP_CHANNEL, S_CHANNEL_CMD,
                    _T("%s: pRtpChannel[0x%p] failed to create ")
                    _T("synchronization event: %u (0x%X)"),
                    _fname, pRtpChannel, dwError, dwError
                ));

            RtpHeapFree(g_pRtpChannelCmdHeap, pRtpChannelCmd);

            pRtpChannelCmd = (RtpChannelCmd_t *)NULL;
        }
    }
    else
    {
        TraceRetail((
                CLASS_ERROR, GROUP_CHANNEL, S_CHANNEL_CMD,
                _T("%s: pRtpChannel[0x%p] failed to allocate memory"),
                _fname, pRtpChannel
            ));
    }

    if (pRtpChannelCmd)
    {
        pRtpChannelCmd->dwObjectID = OBJECTID_RTPCHANCMD;
    }
    
    return(pRtpChannelCmd);
}

/* Frees a RtpChannelCmd_t structure */
void RtpChannelCmdFree(RtpChannelCmd_t *pRtpChannelCmd)
{
    if (pRtpChannelCmd->dwObjectID != OBJECTID_RTPCHANCMD)
    {
        /* TODO log error */
        return;
    }
    
    if (pRtpChannelCmd->hSyncEvent)
    {
        CloseHandle(pRtpChannelCmd->hSyncEvent);
        pRtpChannelCmd->hSyncEvent = NULL;
    }

    RtpHeapFree(g_pRtpChannelCmdHeap, pRtpChannelCmd);
}

/* Get a ready to use command from the FreeQ, if empty create a new
 * one */
RtpChannelCmd_t *RtpChannelCmdGetFree(
        RtpChannel_t    *pRtpChannel
    )
{
    RtpChannelCmd_t *pRtpChannelCmd;
    RtpQueueItem_t  *pRtpQueueItem;

    pRtpChannelCmd = (RtpChannelCmd_t *)NULL;
    
    pRtpQueueItem = dequeuef(&pRtpChannel->FreeQ,
                             &pRtpChannel->ChannelCritSect);

    if (pRtpQueueItem)
    {
        pRtpChannelCmd =
            CONTAINING_RECORD(pRtpQueueItem, RtpChannelCmd_t, QueueItem);
    }

    if (!pRtpChannelCmd)
    {
        pRtpChannelCmd = RtpChannelCmdAlloc(pRtpChannel);
    }

    return(pRtpChannelCmd);
}

/* Returns a command to the FreeQ to be reused later */
RtpChannelCmd_t *RtpChannelCmdPutFree(
        RtpChannel_t    *pRtpChannel,
        RtpChannelCmd_t *pRtpChannelCmd
    )
{
    if (IsSetDebugOption(OPTDBG_FREEMEMORY))
    {
        RtpChannelCmdFree(pRtpChannelCmd);
    }
    else
    {
        enqueuef(&pRtpChannel->FreeQ,
                 &pRtpChannel->ChannelCritSect,
                 &pRtpChannelCmd->QueueItem);
    }
    
    return(pRtpChannelCmd);
}
        
        
/* Send a command to the specified channel. Wait for completion if
 * requested */
HRESULT RtpChannelSend(
        RtpChannel_t    *pRtpChannel,
        DWORD            dwCommand,
        DWORD_PTR        dwPar1,
        DWORD_PTR        dwPar2,
        DWORD            dwWaitTime
    )
{
    HRESULT          hr;
    DWORD            dwStatus;
    RtpChannelCmd_t *pRtpChannelCmd;

    TraceFunctionName("RtpChannelSend");

    /* Get a cmd */
    pRtpChannelCmd = RtpChannelCmdGetFree(pRtpChannel);

    if (pRtpChannelCmd)
    {
        TraceDebugAdvanced((
                0, GROUP_CHANNEL, S_CHANNEL_CMD,
                _T("%s: pRtpChannel[0x%p] pRtpChannelCmd[0x%p] ")
                _T("Sending %s cmd:%u p1:0x%p p2:0x%p"),
                _fname, pRtpChannel, pRtpChannelCmd,
                dwWaitTime? _T("synchronous") : _T("asynchronous"), dwCommand,
                dwPar1, dwPar2
            ));
        
        /* Fill in command */
        pRtpChannelCmd->dwCommand = dwCommand;
        pRtpChannelCmd->dwPar1 = dwPar1;
        pRtpChannelCmd->dwPar2 = dwPar2;
        pRtpChannelCmd->dwFlags = 0;
        pRtpChannelCmd->hr = 0;
        
        if (dwWaitTime)
        {
            RtpBitSet(pRtpChannelCmd->dwFlags, FGCHAN_SYNC);
        }

        /* Commands are consumed FIFO, enqueue at the end */
        enqueuel(&pRtpChannel->CommandQ,
                 &pRtpChannel->ChannelCritSect,
                 &pRtpChannelCmd->QueueItem);

        /* Awaken thread */
        SetEvent(pRtpChannel->hWaitEvent);

        if (dwWaitTime)
        {
            /*
             * WARNING:
             *
             * If the thread is having I/O completions, the wait will
             * be reset, then I would require to decrease the waiting
             * time each time I enter the wait again */
            
            do
            {
                dwStatus =
                    WaitForSingleObjectEx(pRtpChannelCmd->hSyncEvent,
                                          dwWaitTime,
                                          TRUE);

            } while (dwStatus == WAIT_IO_COMPLETION);

            if (dwStatus == WAIT_OBJECT_0)
            {
                hr = pRtpChannelCmd->hr;
            }
            else if (dwStatus == WAIT_TIMEOUT)
            {
                hr = RTPERR_WAITTIMEOUT;
            }
            else
            {
                hr = RTPERR_FAIL;
            }

            if (dwStatus != WAIT_OBJECT_0)
            {
                TraceRetail((
                        CLASS_ERROR, GROUP_CHANNEL, S_CHANNEL_CMD,
                        _T("%s: pRtpChannel[0x%p] Leaving waiting for ")
                        _T("syncronization object: %s (0x%X)"),
                        _fname, pRtpChannel, RTPERR_TEXT(hr), hr
                    ));
            }
            
            /* On synchronous commands the cmd is returned to the free
             * pool here. Yet the command is always removed from the
             * CommandQ when consumed */
            RtpChannelCmdPutFree(pRtpChannel, pRtpChannelCmd);
            
        }
        else
        {
            /* On asynchronous commands, return no error */
            hr = NOERROR;

            /* On asynchronous commands the cmd is returned during the
             * Ack (by the consumer thread) */
        }
    }
    else
    {
        hr = RTPERR_RESOURCES;
    }

    if (FAILED(hr))
    {
        TraceRetail((
                CLASS_ERROR, GROUP_CHANNEL, S_CHANNEL_CMD,
                _T("%s: pRtpChannel[0x%p] failed: %s (0x%X)"),
                _fname, pRtpChannel, RTPERR_TEXT(hr), hr
            ));
    }
    else
    {
        TraceDebugAdvanced((
                0, GROUP_CHANNEL, S_CHANNEL_CMD,
                _T("%s: pRtpChannel[0x%p] pRtpChannelCmd[0x%p] ")
                _T("Command sent"),
                _fname, pRtpChannel, pRtpChannelCmd
            ));
    }
    
    return(hr);
}

/* Once a waiting thread is awakened, it get the sent comman(s) with
 * this function */
RtpChannelCmd_t *RtpChannelGetCmd(
        RtpChannel_t    *pRtpChannel
    )
{
    BOOL             bOk;
    RtpQueueItem_t  *pRtpQueueItem;
    RtpChannelCmd_t *pRtpChannelCmd;

    TraceFunctionName("RtpChannelGetCmd");

    pRtpQueueItem = (RtpQueueItem_t *)NULL;
    pRtpChannelCmd = (RtpChannelCmd_t *)NULL;

    bOk = RtpEnterCriticalSection(&pRtpChannel->ChannelCritSect);

    if (bOk)
    {
        if (GetQueueSize(&pRtpChannel->CommandQ) > 0)
        {
            pRtpQueueItem = dequeuef(&pRtpChannel->CommandQ, NULL);
        }

        RtpLeaveCriticalSection(&pRtpChannel->ChannelCritSect);

        if (pRtpQueueItem)
        {
            pRtpChannelCmd =
                CONTAINING_RECORD(pRtpQueueItem, RtpChannelCmd_t, QueueItem);

            TraceDebugAdvanced((
                    0, GROUP_CHANNEL, S_CHANNEL_CMD,
                    _T("%s: pRtpChannel[0x%p] pRtpChannelCmd[0x%p] ")
                    _T("Receiving cmd:%u p1:0x%p p2:0x%p"),
                    _fname, pRtpChannel, pRtpChannelCmd,
                    pRtpChannelCmd->dwCommand,
                    pRtpChannelCmd->dwPar1,
                    pRtpChannelCmd->dwPar2
                ));
        }
    }

    return(pRtpChannelCmd);
}

/* Used by the consumer thread to acknowledge received commands */
HRESULT RtpChannelAck(
        RtpChannel_t    *pRtpChannel,
        RtpChannelCmd_t *pRtpChannelCmd,
        HRESULT          hr
    )
{
    TraceFunctionName("RtpChannelAck");

    if (RtpBitTest(pRtpChannelCmd->dwFlags, FGCHAN_SYNC))
    {
        /* On synchronous commands, the cmd is returned to the free
         * pool after the synchronization point by the producer
         * thread */

        /* Pass back the result */
        pRtpChannelCmd->hr = hr;
        
        TraceDebugAdvanced((
                0, GROUP_CHANNEL, S_CHANNEL_CMD,
                _T("%s: pRtpChannel[0x%p] pRtpChannelCmd[0x%p] ")
                _T("Synchronous cmd:%u result:0x%X"),
                _fname, pRtpChannel, pRtpChannelCmd,
                pRtpChannelCmd->dwCommand, hr
            ));
        
        SetEvent(pRtpChannelCmd->hSyncEvent);
    }
    else
    {
        TraceDebugAdvanced((
                0, GROUP_CHANNEL, S_CHANNEL_CMD,
                _T("%s: pRtpChannel[0x%p] pRtpChannelCmd[0x%p] ")
                _T("Asynchronous cmd:%u result:0x%X"),
                _fname, pRtpChannel, pRtpChannelCmd,
                pRtpChannelCmd->dwCommand, hr
            ));
        
        /* On asynchronous commands, the cmd is returned to the free
         * pool by the consumer thread */
        RtpChannelCmdPutFree(pRtpChannel, pRtpChannelCmd);
    }
    
    return(NOERROR);
}
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\net\tapi\skywalker\filters\rtp\msrtp\rtcp\rtcpint.c ===
/**********************************************************************
 *
 *  Copyright (C) Microsoft Corporation, 1999
 *
 *  File name:
 *
 *    rtcpint.c
 *
 *  Abstract:
 *
 *    Computes the RTCP report interval time
 *
 *  Author:
 *
 *    Andres Vega-Garcia (andresvg)
 *
 *  Revision:
 *
 *    1999/12/07 created
 *
 **********************************************************************/

#include "stdlib.h" /* rand() */
#include "rtpglobs.h"
#include "rtprand.h"

#include "rtcpint.h"

double rtcp_interval(RtpAddr_t *pRtpAddr, int initial);

/* Return the interval time (in seconds) for the next report */
double RtcpNextReportInterval(RtpAddr_t *pRtpAddr)
{
    double           interval;
    
    if (pRtpAddr->RtpAddrCount[SEND_IDX].dRTCPLastTime)
    {
        interval = rtcp_interval(pRtpAddr, 0);
    }
    else
    {
        /* We haven't sent any  RTCP packet */
        interval = rtcp_interval(pRtpAddr, 1);
    }

    return(interval);
}

double rtcp_interval(RtpAddr_t *pRtpAddr, int initial)
{
    BOOL             bOk;
    double           rtcp_bw;
    int              members;
    int              senders;
    BOOL             we_sent;
    double           avg_rtcp_size;
    RtpNetSState_t  *pRtpNetSState;
    double           rtcp_min_time;
    double           t;   /* interval */
    int              n;   /* no. of members for computation */
    double           dCurrTime;   /* current time */

    TraceFunctionName("rtcp_interval");

    pRtpNetSState = &pRtpAddr->RtpNetSState;

    if (initial)
    {
        t = DEFAULT_RTCP_MIN_INTERVAL / 2.0;

        /* Save the estimated interval rather than the randomized */
        pRtpNetSState->dRtcpInterval = t;

        t = t * ( ((double)rand() / RAND_MAX) + 0.5);
        t = t / (2.71828182846 - 1.5); /* divide by COMPENSATION */
        
        pRtpNetSState->bWeSent = FALSE;

        return(t);
    }
    
    dCurrTime = RtpGetTimeOfDay((RtpTime_t *)NULL);

    bOk = RtpEnterCriticalSection(&pRtpAddr->PartCritSect);

    if (bOk)
    {
        members =
            GetHashCount(&pRtpAddr->Hash) -
            GetQueueSize(&pRtpAddr->ByeQ) + 1;
    
        senders =
            GetQueueSize(&pRtpAddr->Cache1Q) +
            GetQueueSize(&pRtpAddr->Cache2Q);

        RtpLeaveCriticalSection(&pRtpAddr->PartCritSect);

        members -= InterlockedExchangeAdd(&pRtpAddr->lInvalid, 0);
    }
    else
    {
        /* Use the last computed interval time */
        t = pRtpNetSState->dRtcpInterval;

        goto randomize;
    }

    we_sent = FALSE;
    
    bOk = RtpEnterCriticalSection(&pRtpAddr->NetSCritSect);

    if (bOk)
    {
        we_sent = ( pRtpAddr->RtpNetSState.dTimeLastRtpSent >=
                    (dCurrTime - (2 * pRtpNetSState->dRtcpInterval)) );

        RtpLeaveCriticalSection(&pRtpAddr->NetSCritSect);
    }

    pRtpNetSState->bWeSent = we_sent;
    
    if (we_sent)
    {
        senders++;
    }
    
    /*
     * Minimum average time between RTCP packets from this site (in
     * seconds).  This time prevents the reports from `clumping' when
     * sessions are small and the law of large numbers isn't helping
     * to smooth out the traffic.  It also keeps the report interval
     * from becoming ridiculously small during transient outages like
     * a network partition.
     */
    /* double const RTCP_MIN_TIME = 5.; */
    /* Use pRtpNetSState->RtcpMinInterval */
    
    /*
     * Fraction of the RTCP bandwidth to be shared among active
     * senders.  (This fraction was chosen so that in a typical
     * session with one or two active senders, the computed report
     * time would be roughly equal to the minimum report time so that
     * we don't unnecessarily slow down receiver reports.) The
     * receiver fraction must be 1 - the sender fraction.  */
    /* double const RTCP_SENDER_BW_FRACTION = 0.25; */
    /* Use pRtpNetSState->RtcpBwReceivers */
    /* double const RTCP_RCVR_BW_FRACTION = (1-RTCP_SENDER_BW_FRACTION); */
    /* Use pRtpNetSState->RtcpBwSenders */
    
    /* To compensate for "unconditional reconsideration" converging to a
     * value below the intended average.
     */
    /* double const COMPENSATION = 2.71828182846 - 1.5; */

    rtcp_min_time = pRtpNetSState->dRtcpMinInterval;

    /*
     * Very first call at application start-up uses half the min
     * delay for quicker notification while still allowing some time
     * before reporting for randomization and to learn about other
     * sources so the report interval will converge to the correct
     * interval more quickly.
     */
    if (initial) {
        rtcp_min_time /= 2;
    }

    /*
     * If there were active senders, give them at least a minimum
     * share of the RTCP bandwidth.  Otherwise all participants share
     * the RTCP bandwidth equally.
     * */
    n = members;
    if ((senders > 0) && (senders < (members * 0.25))) {
        if (we_sent) {
            rtcp_bw = pRtpNetSState->dwRtcpBwSenders;
            n = senders;
        } else {
            rtcp_bw = pRtpNetSState->dwRtcpBwReceivers;
            n -= senders;
        }
    } else {
        rtcp_bw =
            pRtpNetSState->dwRtcpBwReceivers + pRtpNetSState->dwRtcpBwSenders;
    }
    
    /*
     * The effective number of sites times the average packet size is
     * the total number of octets sent when each site sends a report.
     * Dividing this by the effective bandwidth gives the time
     * interval over which those packets must be sent in order to
     * meet the bandwidth target, with a minimum enforced.  In that
     * time interval we send one report so this time is also our
     * average time between reports.
     */
    t = pRtpNetSState->avg_rtcp_size * n / rtcp_bw;
    if (t < rtcp_min_time) t = rtcp_min_time;

    /* Save the estimated interval rather than the randomized */
    pRtpNetSState->dRtcpInterval = t;
    
    /*
     * To avoid traffic bursts from unintended synchronization with
     * other sites, we then pick our actual next report interval as a
     * random number uniformly distributed between 0.5*t and 1.5*t.
     */
 randomize:
    t *= ( ((double)RtpRandom32((DWORD_PTR)&t) /
            (unsigned int)0xffffffff) + 0.5);
    t /= (2.71828182846 - 1.5); /* divide by COMPENSATION */

    if (t < 0.102)
    {
        /* I will send RTCP reports if within 100ms, so don't schedule
         * closer than 100ms as that would produce consecutive RTCP
         * reports */
        t = 0.102;
    }
    else if (t > (10*60.0))
    {
        TraceRetail((
                CLASS_ERROR, GROUP_RTCP, S_RTCP_RAND,
                _T("%s: pRtpAddr[0x%p] interval:%0.3f"),
                _fname, pRtpAddr, t
            ));
    }
    
    return t;
}
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\net\tapi\skywalker\filters\rtp\msrtp\rtp\rtpdtmf.c ===
/**********************************************************************
 *
 *  Copyright (C) Microsoft Corporation, 1999
 *
 *  File name:
 *
 *    rtpdtmf.c
 *
 *  Abstract:
 *
 *    Implements functionality to partially support rfc2833
 *
 *  Author:
 *
 *    Andres Vega-Garcia (andresvg)
 *
 *  Revision:
 *
 *    2000/08/17 created
 *
 **********************************************************************/

#include "gtypes.h"
#include "rtphdr.h"
#include "struct.h"
#include "rtpsend.h"

#include "rtpdtmf.h"

/* Configures DTMF parameters */
DWORD RtpSetDtmfParameters(
        RtpAddr_t       *pRtpAddr,
        DWORD            dwPT_Dtmf
    )
{
    DWORD            dwError;
    
    TraceFunctionName("RtpSetDtmfParameters");

    dwError = NOERROR;
    
    if ((dwPT_Dtmf & 0x7f) == dwPT_Dtmf)
    {
        pRtpAddr->RtpNetSState.bPT_Dtmf = (BYTE)dwPT_Dtmf;
    }
    else
    {
        dwError = RTPERR_INVALIDARG;
    }

    if (dwError == NOERROR)
    {
        TraceRetail((
                CLASS_INFO, GROUP_RTP, S_RTP_DTMF,
                _T("%s: pRtpAddr[0x%p] DTMF PT:%u"),
                _fname, pRtpAddr, dwPT_Dtmf
            ));
    }
    else
    {
        TraceRetail((
                CLASS_ERROR, GROUP_RTP, S_RTP_DTMF,
                _T("%s: pRtpAddr[0x%p] DTMF invalid PT:%u"),
                _fname, pRtpAddr, dwPT_Dtmf
            ));
    }

    return(dwError);
}

/* Directs an RTP render filter to send a packet formatted according
 * to rfc2833 containing the specified event, specified volume level,
 * duration in timestamp units, and some flags (including END flag) */
DWORD RtpSendDtmfEvent(
        RtpAddr_t       *pRtpAddr,
        DWORD            dwTimeStamp,
        DWORD            dwEvent,
        DWORD            dwVolume,
        DWORD            dwDuration, /* timestamp units */
        DWORD            dwDtmfFlags
    )
{
    DWORD            dwError;
    DWORD            dwSendFlags;
    WSABUF           WSABuf[2];
    RtpDtmfEvent_t   RtpDtmfEvent;

    TraceFunctionName("RtpSendDtmfEvent");

    /* Check parameters */
    if ( (dwEvent >= RTPDTMF_LAST) ||
         ((dwVolume & 0x3f) != dwVolume) ||
         ((dwDuration & 0xffff) != dwDuration) )
    {
        dwError = RTPERR_INVALIDARG;

        goto end;
    }

    if (pRtpAddr->RtpNetSState.bPT_Dtmf == NO_PAYLOADTYPE)
    {
        /* DTMF payload type hasn't been set yet */

        dwError = RTPERR_INVALIDSTATE;

        goto end;
    }

    dwSendFlags = RtpBitPar(FGSEND_DTMF);
    
    if (RtpBitTest(dwDtmfFlags, FGDTMF_MARKER))
    {
        dwSendFlags |= RtpBitPar(FGSEND_FORCEMARKER);
    }
    
    /* Format packet */
    RtpDtmfEvent.event = (BYTE)dwEvent;
    RtpDtmfEvent.e = RtpBitTest(dwDtmfFlags, FGDTMF_END)? 1:0;
    RtpDtmfEvent.r = 0;
    RtpDtmfEvent.volume = (BYTE)dwVolume;
    RtpDtmfEvent.duration = htons((WORD)dwDuration);

    /* Fill up WSABUFs */
    WSABuf[0].len = 0;
    WSABuf[0].buf = NULL;
    WSABuf[1].len = sizeof(RtpDtmfEvent);
    WSABuf[1].buf = (char *)&RtpDtmfEvent;

    /* Send packet */
    dwError = RtpSendTo_(pRtpAddr, WSABuf, 2, dwTimeStamp, dwSendFlags);

 end:
    if (dwError == NOERROR)
    {
        TraceRetail((
                CLASS_INFO, GROUP_RTP, S_RTP_DTMF,
                _T("%s: pRtpAddr[0x%p] Event sent: ")
                _T("Event:%u Volume:%u Duration:%u, End:%u"),
                _fname, pRtpAddr,
                dwEvent, dwVolume, dwDuration,
                RtpBitTest(dwDtmfFlags, FGDTMF_END)? 1:0
            ));
    }
    else
    {
        TraceRetail((
                CLASS_ERROR, GROUP_RTP, S_RTP_DTMF,
                _T("%s: pRtpAddr[0x%p] ")
                _T("Event:%u Volume:%u Duration:%u, End:%u ")
                _T("failed: %s (0x%X)"),
                _fname, pRtpAddr,
                dwEvent, dwVolume, dwDuration,
                RtpBitTest(dwDtmfFlags, FGDTMF_END)? 1:0,
                RTPERR_TEXT(dwError), dwError
            ));
    }
    
    return(dwError);
}
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\net\tapi\skywalker\filters\rtp\tools\common.inc ===
#**********************************************************************
#*
#*  Copyright (c) 2001 Microsoft Corporation
#*
#*  File name:
#*
#*    rtp\tools\common.inc
#*
#*  Abstract:
#*
#*    Common file included in all sources files
#*
#*  Author:
#*
#*    Andres Vega-Garcia (andresvg)
#*
#*  Revision:
#*
#*    2001/01/17 created
#*
#**********************************************************************
# MSVCRT.LIB Import library for MSVCRT.DLL, retail version
USE_CRTDLL=1

# Generate map file
USE_MAPSYM=1
BROWSER_INFO=1
USE_ICECAP4=1

INCLUDES=\
    $(BASEDIR)\public\oak\inc;\
    $(BASEDIR)\public\sdk\inc;\
    $(BASEDIR)\public\sdk\inc\crt;\
    $(TOOLS)\inc;\
    .

LINKLIBS=\
    $(TARGETPATH)\*\common.lib \
    $(SDK_LIB_PATH)\libc.lib \
    $(SDK_LIB_PATH)\msvcrt.lib \
    $(SDK_LIB_PATH)\ws2_32.lib   \
    $(SDK_LIB_PATH)\winmm.lib
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\net\tapi\skywalker\filters\rtp\msrtp\rtp\rtprecv.c ===
/**********************************************************************
 *
 *  Copyright (C) Microsoft Corporation, 1999
 *
 *  File name:
 *
 *    rtprecv.c
 *
 *  Abstract:
 *
 *    RTP packet reception and decoding
 *
 *  Author:
 *
 *    Andres Vega-Garcia (andresvg)
 *
 *  Revision:
 *
 *    1999/06/17 created
 *
 **********************************************************************/

#include "gtypes.h"
#include "rtphdr.h"
#include "struct.h"
#include "rtpncnt.h"
#include "lookup.h"
#include "rtpglobs.h"
#include "rtppinfo.h"
#include "rtpdejit.h"
#include "rtpcrypt.h"
#include "rtpqos.h"
#include "rtcpthrd.h"
#include "rtpdemux.h"
#include "rtpevent.h"
#include "rtpred.h"

#include <mmsystem.h>

#include "rtprecv.h"

DWORD RtpValidatePacket(
        RtpAddr_t       *pRtpAddr,
        RtpRecvIO_t     *pRtpRecvIO
    );

DWORD RtpPreProcessPacket(
        RtpAddr_t       *pRtpAddr,
        RtpUser_t       *pRtpUser,
        RtpRecvIO_t     *pRtpRecvIO,
        RtpHdr_t        *pRtpHdr
    );

DWORD RtpProcessPacket(
        RtpAddr_t       *pRtpAddr,
        RtpUser_t       *pRtpUser,
        RtpRecvIO_t     *pRtpRecvIO,
        RtpHdr_t        *pRtpHdr
    );

DWORD RtpPostUserBuffer(
        RtpAddr_t       *pRtpAddr,
        RtpUser_t       *pRtpUser,
        RtpRecvIO_t     *pRtpRecvIO,
        RtpHdr_t        *pRtpHdr
    );

BOOL RtpReadyToPost(
        RtpAddr_t       *pRtpAddr,
        RtpUser_t       *pRtpUser,
        RtpRecvIO_t     *pRtpRecvIO
    );

DWORD RtpScheduleToPost(
        RtpAddr_t       *pRtpAddr,
        RtpRecvIO_t     *pRtpRecvIO
    );

BOOL RtpUpdateRSeq(RtpUser_t *pRtpUser, RtpHdr_t *pRtpHdr);

void RtpForceFrameSizeDetection(
        RtpUser_t        *pRtpUser,
        RtpHdr_t         *pRtpHdr
    );

void RtpInitRSeq(RtpUser_t *pRtpUser, RtpHdr_t *pRtpHdr);

RtpRecvIO_t *RtpRecvIOGetFree(
        RtpAddr_t       *pRtpAddr
    );

RtpRecvIO_t *RtpRecvIOGetFree2(
        RtpAddr_t       *pRtpAddr,
        RtpRecvIO_t     *pRtpRecvIO
    );

RtpRecvIO_t *RtpRecvIOPutFree(
        RtpAddr_t       *pRtpAddr,
        RtpRecvIO_t     *pRtpRecvIO
    );

void RtpRecvIOFreeAll(RtpAddr_t *pRtpAddr);

HRESULT RtpRecvFrom_(
        RtpAddr_t        *pRtpAddr,
        WSABUF           *pWSABuf,
        void             *pvUserInfo1,
        void             *pvUserInfo2
    )
{
    HRESULT          hr;
    RtpRecvIO_t     *pRtpRecvIO;
    RtpQueueItem_t  *pRtpQueueItem;
        
    TraceFunctionName("RtpRecvFrom_");

    /* allocate context */
    pRtpRecvIO = RtpRecvIOGetFree(pRtpAddr);
    
    if (!pRtpRecvIO)
    {
        TraceRetail((
                CLASS_ERROR, GROUP_RTP, S_RTP_RECV,
                _T("%s: pRtpAddr[0x%p] ")
                _T("No more RtpRecvIO_t structures"),
                _fname, pRtpAddr
            ));
        
        return(RTPERR_RESOURCES);
    }

    pRtpRecvIO->dwObjectID    = OBJECTID_RTPRECVIO;

    pRtpRecvIO->WSABuf.len    = pWSABuf->len;
    pRtpRecvIO->WSABuf.buf    = pWSABuf->buf;

    pRtpRecvIO->pvUserInfo1   = pvUserInfo1;
    pRtpRecvIO->pvUserInfo2   = pvUserInfo2;
    
    /* put buffer in thread's queue */

    pRtpQueueItem = enqueuel(&pRtpAddr->RecvIOReadyQ,
                             &pRtpAddr->RecvQueueCritSect,
                             &pRtpRecvIO->RtpRecvIOQItem);

    if (!pRtpQueueItem)
    {
        TraceRetail((
                CLASS_ERROR, GROUP_RTP, S_RTP_RECV,
                _T("%s: pRtpAddr[0x%p] ")
                _T("enqueuel failed to enqueue to RecvIOReadyQ"),
                _fname, pRtpAddr
            ));
    }
        
    return(NOERROR);
}

/* Initiates asynchronous reception for all the buffers in
 * RtpReadyQ queue */
DWORD StartRtpRecvFrom(RtpAddr_t *pRtpAddr)
{
    RtpRecvIO_t     *pRtpRecvIO;
    RtpQueueItem_t  *pRtpQueueItem;
    DWORD            dwStarted;
    DWORD            dwStatus;
    DWORD            dwError;

    TraceFunctionName("StartRtpRecvFrom");

    dwStarted = 0;
    
    while(pRtpAddr->RecvIOReadyQ.lCount > 0)
    {
        pRtpQueueItem = dequeuef(&pRtpAddr->RecvIOReadyQ,
                                 &pRtpAddr->RecvQueueCritSect);

        if (!pRtpQueueItem)
        {
            break;
        }

        pRtpRecvIO =
            CONTAINING_RECORD(pRtpQueueItem, RtpRecvIO_t, RtpRecvIOQItem);

        /* Overlapped structure */
        pRtpRecvIO->Overlapped.hEvent = pRtpAddr->hRecvCompletedEvent;

        do
        {
            pRtpRecvIO->Overlapped.Internal = 0;
            
            pRtpRecvIO->Fromlen = sizeof(pRtpRecvIO->From);

            pRtpRecvIO->dwRtpWSFlags = 0;

            pRtpRecvIO->dwRtpIOFlags = RtpBitPar(FGRECV_MAIN);
            
            dwStatus = WSARecvFrom(
                    pRtpAddr->Socket[SOCK_RECV_IDX],/* SOCKET s */
                    &pRtpRecvIO->WSABuf,    /* LPWSABUF lpBuffers */
                    1,                      /* DWORD dwBufferCount */
                    &pRtpRecvIO->dwTransfered,/*LPDWORD lpNumberOfBytesRecvd*/
                    &pRtpRecvIO->dwRtpWSFlags,/* LPDWORD lpFlags */
                    &pRtpRecvIO->From,      /* struct sockaddr FAR *lpFrom */
                    &pRtpRecvIO->Fromlen,   /* LPINT lpFromlen */
                    &pRtpRecvIO->Overlapped,/* LPWSAOVERLAPPED lpOverlapped */
                    NULL              /* LPWSAOVERLAPPED_COMPLETION_ROUTINE */
                );
            
            /* WARNING note that the len field in the WSABUF passed is
             * not updated to reflect the amount of bytes received
             * (or transfered) */
            
            if (dwStatus)
            {
                dwError = WSAGetLastError();
            }
        } while(dwStatus &&
                ( (dwError == WSAECONNRESET) ||
                  (dwError == WSAEMSGSIZE) )   );

        if (!dwStatus || (dwError == WSA_IO_PENDING))
        {
            dwStarted++;
            
            enqueuel(&pRtpAddr->RecvIOPendingQ,
                     &pRtpAddr->RecvQueueCritSect,
                     &pRtpRecvIO->RtpRecvIOQItem);
      
        }
        else
        {
            /* move back to Ready */
                
            TraceRetail((
                    CLASS_ERROR, GROUP_RTP, S_RTP_RECV,
                    _T("%s: pRtpAddr[0x%p] ")
                    _T("Overlapped reception failed: %u (0x%X)"),
                    _fname, pRtpAddr,
                    dwError, dwError
                ));

            enqueuef(&pRtpAddr->RecvIOReadyQ,
                     &pRtpAddr->RecvQueueCritSect,
                     &pRtpRecvIO->RtpRecvIOQItem);

            RtpPostEvent(pRtpAddr,
                         NULL,
                         RTPEVENTKIND_RTP,
                         RTPRTP_WS_RECV_ERROR,
                         RTP_IDX,
                         dwError);
            break;
        }
    }

    if (dwStarted == 0 &&
        !GetQueueSize(&pRtpAddr->RecvIOPendingQ) &&
        !GetQueueSize(&pRtpAddr->RecvIOWaitRedQ) &&
        RtpBitTest(pRtpAddr->dwAddrFlags, FGADDR_RUNRECV))
    {
        TraceRetail((
                CLASS_ERROR, GROUP_RTP, S_RTP_RECV,
                _T("%s: pRtpAddr[0x%p] ")
                _T("Number of RTP RECV started:0"),
                _fname, pRtpAddr
            ));
    }
    
    return(dwStarted);
}

/* Consumes all the buffers that have completed I/O
 *
 * WARNING
 *
 * timestamp, and sequence number are left in host order
 * */
DWORD ConsumeRtpRecvFrom(RtpAddr_t *pRtpAddr)
{
    BOOL             bStatus;
    BOOL             bCreate;
    DWORD            dwSendSSRC;

    RtpUser_t       *pRtpUser;
    RtpRecvIO_t     *pRtpRecvIO;
    RtpHdr_t        *pRtpHdr;
    RtpQueueItem_t  *pRtpQueueItem;
    SOCKADDR_IN     *pFromIn;

    DWORD            dwConsumed;
    
    TraceFunctionName("ConsumeRtpRecvFrom");

    dwConsumed = 0;
    
    do
    {
        pRtpUser    = (RtpUser_t *)NULL;
    
        pRtpQueueItem = pRtpAddr->RecvIOPendingQ.pFirst;
        
        if (pRtpQueueItem)
        {
            pRtpRecvIO =
                CONTAINING_RECORD(pRtpQueueItem, RtpRecvIO_t, RtpRecvIOQItem);
            
            bStatus = WSAGetOverlappedResult(
                    pRtpAddr->Socket[SOCK_RECV_IDX], /* SOCKET s */
                    &pRtpRecvIO->Overlapped,   /*LPWSAOVERLAPPED lpOverlapped*/
                    &pRtpRecvIO->dwWSTransfered,/* LPDWORD lpcbTransfer */
                    FALSE,                     /* BOOL fWait */
                    &pRtpRecvIO->dwRtpWSFlags  /* LPDWORD lpdwFlags */
                );

            if (!bStatus)
            {
                pRtpRecvIO->dwWSError = WSAGetLastError();
                
                if (pRtpRecvIO->dwWSError == WSA_IO_INCOMPLETE)
                {
                    /* just quit as this means there are no more
                     * completed I/Os */
                    /* Also need to clear the error from this buffer */
                    pRtpRecvIO->dwWSError = NOERROR;
                    break;
                }
            }

            /* I/O completed */

            pRtpRecvIO->dRtpRecvTime = RtpGetTimeOfDay((RtpTime_t *)NULL);
            
            dequeue(&pRtpAddr->RecvIOPendingQ,
                    &pRtpAddr->RecvQueueCritSect,
                    pRtpQueueItem);
            
            pRtpRecvIO->pRtpUser = (RtpUser_t *)NULL;
            
            pRtpHdr = (RtpHdr_t *)pRtpRecvIO->WSABuf.buf;
            
            pRtpRecvIO->dwTransfered = pRtpRecvIO->dwWSTransfered;

            /*
             * NOTE about dwTransfered and pRtpRecvIO->dwTransfered
             *
             * dwTransfered retains the WS2 value, while
             * RtpRecvIO->dwTransfered may be modified because of
             * decryption and/or padding removal during
             * RtpValidatePacket().
             *
             * Once the final number of bytes to pass up to the app is
             * obtained (when returning from RtpValidatePacket()),
             * dwTransfered is still used to update counters, but will
             * be readjusted after that
             * */

            /* Test if reception is muted */
            if (RtpBitTest(pRtpAddr->dwAddrFlags, FGADDR_MUTERTPRECV))
            {
                pRtpRecvIO->dwError = RTPERR_PACKETDROPPED;
                
                RtpBitSet2(pRtpRecvIO->dwRtpIOFlags,
                           FGRECV_DROPPED, FGRECV_MUTED);
            }
#if USE_GEN_LOSSES > 0
            else if (RtpRandomLoss(RECV_IDX))
            {
                pRtpRecvIO->dwError = RTPERR_PACKETDROPPED;
                
                RtpBitSet2(pRtpRecvIO->dwRtpIOFlags,
                           FGRECV_DROPPED, FGRECV_RANDLOSS);
            }
#endif
            else
            {
                if (pRtpRecvIO->dwWSError == NOERROR)
                {
                    /* packet succeesfully received, scan header */
                    RtpValidatePacket(pRtpAddr, pRtpRecvIO);
                    /* NOTE the above function may have modified
                     * pRtpRecvIO->dwTransfered (because of
                     * decryption/padding), error code is returned in
                     * pRtpRecvIO->dwError */

                    if (pRtpRecvIO->dwError == NOERROR)
                    {
                        /* MAYDO may need to look at the contributing
                         * sources and create new participants for each
                         * contributing source, need also to send an event
                         * NEW_SOURCE for each new participant created */

                        pFromIn = (SOCKADDR_IN *)&pRtpRecvIO->From;

                        /* Filter explicitly loopback packets if needed */
                        /* Decide if we need to detect collisions */
                        if ( RtpBitTest2(pRtpAddr->dwAddrFlags,
                                         FGADDR_COLLISION, FGADDR_ISMCAST) ==
                             RtpBitPar2(FGADDR_COLLISION, FGADDR_ISMCAST) )
                        {
                            dwSendSSRC = pRtpAddr->RtpNetSState.dwSendSSRC;
                        
                            if (pRtpHdr->ssrc == dwSendSSRC)
                            {
                                if (RtpDropCollision(pRtpAddr, pFromIn, TRUE))
                                {
                                    RtpBitSet2(pRtpRecvIO->dwRtpIOFlags,
                                               FGRECV_DROPPED, FGRECV_LOOP);
                                }
                            }
                        }

                        /* If packet is not comming from the registered
                         * source address, discard it. This is enabled by
                         * flag FGADDR_IRTP_MATCHRADDR */
                        if (RtpBitTest(pRtpAddr->dwIRtpFlags,
                                       FGADDR_IRTP_MATCHRADDR))
                        {
                            if (pFromIn->sin_addr.s_addr !=
                                pRtpAddr->dwAddr[REMOTE_IDX])
                            {
                                RtpBitSet2(pRtpRecvIO->dwRtpIOFlags,
                                           FGRECV_DROPPED, FGRECV_MISMATCH);
                            }
                        }

                        if (RtpBitTest(pRtpRecvIO->dwRtpIOFlags,
                                       FGRECV_DROPPED))
                        {
                            pRtpRecvIO->dwError = RTPERR_PACKETDROPPED;
                        }
                        else
                        {
                            /*
                             * Look up SSRC, create new one if not
                             * exist yet */
                            bCreate = TRUE;
                            pRtpUser = LookupSSRC(pRtpAddr,
                                                  pRtpHdr->ssrc,
                                                  &bCreate);

                            if (pRtpUser)
                            {
                                pRtpRecvIO->pRtpUser = pRtpUser;
                                
                                if (bCreate)
                                {
                                    /* Increase the number of not yet
                                     * validated participants, the bit
                                     * FGUSER_VALIDATED is reset when the
                                     * RtpUser_t structure is just created
                                     * */
                                    InterlockedIncrement(&pRtpAddr->lInvalid);
                                
                                    TraceDebug((
                                            CLASS_INFO, GROUP_RTP, S_RTP_RECV,
                                            _T("%s: pRtpAddr[0x%p] ")
                                            _T("SSRC:0x%X new user"),
                                            _fname, pRtpAddr,
                                            ntohl(pRtpUser->dwSSRC)
                                        ));
                                }

                                /* Store RTP source address/port */
                                if (!RtpBitTest(pRtpUser->dwUserFlags,
                                                FGUSER_RTPADDR))
                                {
                                    pRtpUser->dwAddr[RTP_IDX] =
                                        (DWORD) pFromIn->sin_addr.s_addr;
                                
                                    pRtpUser->wPort[RTP_IDX] =
                                        pFromIn->sin_port;

                                    RtpBitSet(pRtpUser->dwUserFlags,
                                              FGUSER_RTPADDR);
#if 0
                                    /* This code used to test shared
                                     * explicit mode, add automatically
                                     * each user to the shared explicit
                                     * list */
                                    RtpSetQosState(pRtpAddr,
                                                   pRtpUser->dwSSRC,
                                                   TRUE);
#endif
                                }



                                /* Preprocess the packet, this is some
                                 * processig needed for every valid
                                 * packet received, regardless it
                                 * contains redundancy or not */
                                pRtpRecvIO->dwError =
                                    RtpPreProcessPacket(pRtpAddr,
                                                        pRtpUser,
                                                        pRtpRecvIO,
                                                        pRtpHdr);

                                if (pRtpRecvIO->dwError == NOERROR)
                                {
                                    /* Buffer will be posted from the
                                     * following function, so do not
                                     * post it from here */

                                    /* Process packet, it may contain
                                     * redundancy */
                                    RtpProcessPacket(pRtpAddr,
                                                     pRtpUser,
                                                     pRtpRecvIO,
                                                     pRtpHdr);
                                }
                                else
                                {
                                    /* Packet preprocess failed */
                                    RtpBitSet2(pRtpRecvIO->dwRtpIOFlags,
                                               FGRECV_DROPPED, FGRECV_PREPROC);

                                    TraceRetail((
                                            CLASS_WARNING,GROUP_RTP,S_RTP_RECV,
                                            _T("%s: pRtpAddr[0x%p] ")
                                            _T("pRtpUser[0x%p] ")
                                            _T("pRtpRecvIO[0x%p] ")
                                            _T("preprocess failed:%u (0x%X)"),
                                            _fname, pRtpAddr, pRtpUser,
                                            pRtpRecvIO, pRtpRecvIO->dwError,
                                            pRtpRecvIO->dwError
                                        ));
                                }
                            }
                            else
                            {
                                /* Either there were no resources to create
                                 * the new user structure, or it was found in
                                 * the BYE queue and thus was reported as not
                                 * found */
                                pRtpRecvIO->dwError = RTPERR_NOTFOUND;

                                RtpBitSet2(pRtpRecvIO->dwRtpIOFlags,
                                           FGRECV_DROPPED, FGRECV_NOTFOUND);
                            }
                        }
                    }
                    else
                    {
                        /* Buffer validation failed, packet is being
                         * dropped, dwError has the reason */
                        RtpBitSet2(pRtpRecvIO->dwRtpIOFlags,
                                   FGRECV_DROPPED, FGRECV_INVALID);
                    }
                }
                else
                {
                    /* WSAGetOverlappedResult reported an error */
                    RtpBitSet2(pRtpRecvIO->dwRtpIOFlags,
                               FGRECV_ERROR, FGRECV_WS2);
                    
                    pRtpRecvIO->dwError = pRtpRecvIO->dwWSError;
                }
            }

            if (pRtpRecvIO->dwError != NOERROR)
            {
                /* In case of error, post buffer to user layer
                 * (e.g. DShow).
                 *
                 * NOTE in this code path, pRtpRecvIO->dwError always
                 * reports an error */
                RtpPostUserBuffer(pRtpAddr, pRtpUser, pRtpRecvIO, pRtpHdr);
            }

            dwConsumed++;
        }
    } while (pRtpQueueItem);

    /* Now reset event */
    ResetEvent(pRtpAddr->hRecvCompletedEvent);
    
    return(dwConsumed);
}

DWORD RtpPreProcessPacket(
        RtpAddr_t       *pRtpAddr,
        RtpUser_t       *pRtpUser,   /* Always valid */
        RtpRecvIO_t     *pRtpRecvIO,
        RtpHdr_t        *pRtpHdr
    )
{
    BOOL             bOk;
    BOOL             bValid;
    DWORD            dwOldFreq;
    double           dDelta;
    RtpNetRState_t  *pRtpNetRState;
    
    TraceFunctionName("RtpPreProcessPacket");  

    pRtpNetRState = &pRtpUser->RtpNetRState;

    bOk = RtpEnterCriticalSection(&pRtpUser->UserCritSect);

    if (bOk)
    {
        if (pRtpRecvIO->lRedHdrSize > 0)
        {
            /* Packet containing redundancy, use the main PT */
            pRtpHdr->pt = pRtpRecvIO->bPT_Block;
        }
        
        if (pRtpHdr->pt != pRtpNetRState->dwPt)
        {
            /* Save the current sampling frequency as it will be
             * updated in RtpMapPt2Frequency */
            dwOldFreq = pRtpNetRState->dwRecvSamplingFreq;
            
            /* Obtain the sampling frequency to use, can not do this
             * when the user is created as it may be created in RTCP.
             *
             * MUST be before RtpOnFirstPacket as it uses the sampling
             * frequency set by this function. This function will
             * update pRtpNetRState->dwPt and
             * pRtpNetRState->dwRecvSamplingFreq */
            pRtpRecvIO->dwError =
                RtpMapPt2Frequency(pRtpAddr, pRtpUser, pRtpHdr->pt, RECV_IDX);

            if (pRtpRecvIO->dwError == NOERROR)
            {
                TraceRetail((
                        CLASS_INFO, GROUP_RTP, S_RTP_RECV,
                        _T("%s: pRtpAddr[0x%p] pRtpUser[0x%p] SSRC:0x%X ")
                        _T("Receiving PT:%u Frequency:%u"),
                        _fname, pRtpAddr, pRtpUser,
                        ntohl(pRtpUser->dwSSRC),
                        pRtpNetRState->dwPt,
                        pRtpNetRState->dwRecvSamplingFreq
                    ));

                if (!RtpBitTest(pRtpUser->dwUserFlags, FGUSER_FIRST_RTP))
                {
                    /* Do some initialization required only when the
                     * first RTP packet is received */
                    RtpOnFirstPacket(pRtpUser, pRtpHdr,
                                     pRtpRecvIO->dRtpRecvTime);

                    /* Modify some variables so a marker bit will be
                     * generated regardless of the marker bit in the
                     * original packet */
                    RtpPrepareForMarker(pRtpUser, pRtpHdr,
                                        pRtpRecvIO->dRtpRecvTime);
                    
                    /* Init variables used to keep track of sequence
                     * number, lost fraction and cycles */
                    RtpInitRSeq(pRtpUser, pRtpHdr);

                    /* First packet is considered in sequence, for
                     * RtpUdateRSeq to find so, decrement max_seq */
                    pRtpNetRState->max_seq--;
                    pRtpNetRState->red_max_seq--;

                    /* Need to set this to a value on the first packet */
                    pRtpNetRState->dwLastPacketSize = pRtpRecvIO->dwTransfered;
                    
                    RtpBitSet(pRtpUser->dwUserFlags, FGUSER_FIRST_RTP);
                }
                else if (pRtpNetRState->dwRecvSamplingFreq != dwOldFreq)
                {
                    /* A sampling frequency change has just happened,
                     * need to update my reference time to compute
                     * delay, variance and jitter */
                    RtpOnFirstPacket(pRtpUser, pRtpHdr,
                                     pRtpRecvIO->dRtpRecvTime);

                    /* Frequency change implies the audio capture
                     * device might go through perturbations that will
                     * make delay to be unstable for several packets,
                     * to better converge I need to span the
                     * adjustment to cover more packets (twice as
                     * much) */
                    RtpPrepareForShortDelay(pRtpUser, SHORTDELAYCOUNT * 2);

                    /* Also need to modify the timestamp for the
                     * begining of the talkspurt as if in the whole
                     * talksput we had been using the new sampling
                     * frequency, otherwise I would get a wrong play
                     * time */
                    if (pRtpNetRState->dwRecvSamplingFreq > dwOldFreq)
                    {
                        pRtpNetRState->dwBeginTalkspurtTs -= (DWORD)
                            ( ((ntohl(pRtpHdr->ts) -
                                pRtpNetRState->dwBeginTalkspurtTs) *
                               (pRtpNetRState->dwRecvSamplingFreq - dwOldFreq))
                              /
                              dwOldFreq );
                    }
                    else
                    {
                        pRtpNetRState->dwBeginTalkspurtTs += (DWORD)
                            ( ((ntohl(pRtpHdr->ts) -
                                pRtpNetRState->dwBeginTalkspurtTs) *
                               (dwOldFreq - pRtpNetRState->dwRecvSamplingFreq))
                              /
                              dwOldFreq );
                    }

                    TraceRetail((
                            CLASS_INFO, GROUP_RTP, S_RTP_RECV,
                            _T("%s: pRtpAddr[0x%p] pRtpUser[0x%p] SSRC:0x%X ")
                            _T("frequency change: %u to %u"),
                            _fname, pRtpAddr, pRtpUser,
                            ntohl(pRtpUser->dwSSRC),
                            dwOldFreq,
                            pRtpNetRState->dwRecvSamplingFreq
                        ));
                }

                if (RtpBitTest(pRtpAddr->dwAddrFlags, FGADDR_QOSRECVON))
                {
                    /* Set QOS update flag as we just started receiving
                     * a new known valid PT.
                     *
                     * WARNING this scheme works well in unicast or in
                     * multicast if everybody uses the same codec,
                     * otherwise, the last one to experience a change will
                     * dictate what basic QOS flowspec is used */
                    RtpSetQosByNameOrPT(pRtpAddr,
                                        RECV_IDX,
                                        NULL,
                                        pRtpNetRState->dwPt,
                                        NO_DW_VALUESET,
                                        NO_DW_VALUESET,
                                        NO_DW_VALUESET,
                                        NO_DW_VALUESET,
                                        TRUE);

                    /* Force frame size to be computed again, this
                     * might have changed together with the new PT,
                     * QOS will be updated only after the new frame
                     * size has been computed */
                    if (RtpGetClass(pRtpAddr->dwIRtpFlags) == RTPCLASS_AUDIO)
                    {
                        RtpForceFrameSizeDetection(pRtpUser, pRtpHdr);

                        /* Set frame size as not valid */
                        pRtpAddr->pRtpQosReserve->
                            ReserveFlags.RecvFrameSizeValid = 0;

                        /* When a new frame size is detected, this
                         * flag set to 1 will indicate that QOS needs
                         * to be updated */
                        pRtpAddr->pRtpQosReserve->
                            ReserveFlags.RecvFrameSizeWaiting = 1;
                    }
                }
            }
            else
            {
                RtpBitSet2(pRtpRecvIO->dwRtpIOFlags,
                           FGRECV_DROPPED, FGRECV_BADPT);

                /* NOTE Bad PT packets will not be used to initialize
                 * the sequence number nor to validate the participant
                 * (probation) */
            }
        }

        if (pRtpRecvIO->dwError == NOERROR)
        {            
            /* Update the sequence number and some counters for this
             * user (SSRC) */
            bValid = RtpUpdateRSeq(pRtpUser, pRtpHdr);

            /* Obtain the extended sequence number for this buffer. NOTE:
             * this needs to be done after RtpUpdateRSeq as the
             * pRtpNetRState->cycles might have been updated */
            pRtpRecvIO->dwExtSeq = pRtpNetRState->cycles + pRtpRecvIO->wSeq;

            /* Check if need to make participant valid */
            if (bValid == TRUE &&
                !RtpBitTest(pRtpUser->dwUserFlags, FGUSER_VALIDATED))
            {
                /* The participant has been validated and was invalid */
                InterlockedDecrement(&pRtpAddr->lInvalid);

                RtpBitSet(pRtpUser->dwUserFlags, FGUSER_VALIDATED);
            }
        }
        
        RtpLeaveCriticalSection(&pRtpUser->UserCritSect);
    }
    else
    {
        pRtpRecvIO->dwError = RTPERR_CRITSECT;

        RtpBitSet2(pRtpRecvIO->dwRtpIOFlags, FGRECV_DROPPED, FGRECV_CRITSECT);
    }
                        
    if (pRtpRecvIO->dwError == NOERROR)
    {
        if (RtpBitTest(pRtpAddr->dwIRtpFlags, FGADDR_IRTP_USEPLAYOUT))
        {
            if (pRtpNetRState->dwLastPacketSize != pRtpRecvIO->dwTransfered)
            {
                /* WARNING: The packet size change to detect frame
                 * size change works only for constant bit rate codecs
                 * (as opposed to variable as in video), currently all
                 * our audio codecs are in that category. */
                
                /* A frame size change just happened, need to update
                 * my reference time to compute delay, variance and
                 * jitter as otherwise a false delay jump will be
                 * detected. E.g. if we change 8KHz frames at 20ms to
                 * 90ms, the timestamp is that of the first sample,
                 * and the packet is sent 20ms later in the first
                 * case, and 90ms later in the second case, as the
                 * relative delay was set while receiving 20ms frames,
                 * when I start receiving 90ms frames I will perceive
                 * an apparent delay increase of 70ms, this will cause
                 * an un-needed jitter and playout delay increase */
                RtpPrepareForShortDelay(pRtpUser, SHORTDELAYCOUNT);

                /* Store the last audio packet size so the next change
                 * will be detected to resync again relative delay
                 * computation */
                pRtpNetRState->dwLastPacketSize = pRtpRecvIO->dwTransfered;
            }
            
            /* See if the playout bounds need to be updated */
            RtpUpdatePlayoutBounds(pRtpAddr, pRtpUser, pRtpRecvIO);
        }
        
        /* Compute delay, variance and jitter for good packets */
        RtpUpdateNetRState(pRtpAddr, pRtpUser, pRtpHdr, pRtpRecvIO);

        /* Compute the time at which the frame should be played back and
         * hence need to be posted by that time */
        if (RtpBitTest(pRtpAddr->dwIRtpFlags, FGADDR_IRTP_USEPLAYOUT))
        {
            pRtpRecvIO->dPostTime =
                pRtpNetRState->dBeginTalkspurtTime +
                pRtpRecvIO->dPlayTime;

            /* Make sure that the PlayTime is not too far ahead, this
             * could happen because of bogus timestamps */
            dDelta = pRtpRecvIO->dPostTime - pRtpRecvIO->dRtpRecvTime;
            
            if (dDelta > ((double)(MAX_PLAYOUT * 2) / 1000))
            {
                TraceRetail((
                        CLASS_WARNING, GROUP_RTP, S_RTP_RECV,
                        _T("%s: pRtpAddr[0x%p] pRtpRecvIO[0x%p] ")
                        _T("post:%0.3f/%+0.3f post time too far ahead"),
                        _fname, pRtpAddr, pRtpRecvIO,
                        pRtpRecvIO->dPostTime, dDelta
                    ));
                
                pRtpRecvIO->dPostTime = pRtpRecvIO->dRtpRecvTime +
                    ((double)(MAX_PLAYOUT * 2) / 1000);
            }

            /* Check if marker bit is set (audio) and force frame size
             * detection to be done again. Frame size can change any
             * time, if it grows the reservation should still be
             * enough, but if it decreses, we may need to redo it */
            if (RtpBitTest(pRtpRecvIO->dwRtpIOFlags, FGRECV_MARKER))
            {
                RtpForceFrameSizeDetection(pRtpUser, pRtpHdr);
            }
        }
        else
        {
            pRtpRecvIO->dPostTime = pRtpRecvIO->dRtpRecvTime;
        }
    }
    
    /* Update receive counters for this user (SSRC) */
    RtpUpdateNetCount(&pRtpUser->RtpUserCount,
                      &pRtpUser->UserCritSect,
                      RTP_IDX,
                      pRtpRecvIO->dwWSTransfered,
                      pRtpRecvIO->dwRtpIOFlags,
                      pRtpRecvIO->dRtpRecvTime);
        
    /* If user was just created, move it from AliveQ to Cache1Q, if it
     * already existed, it may have been in Cache1Q, Cache2Q, or
     * AliveQ, in either case move it to the head of Cache1Q. An event
     * might be posted result of this function call */
    RtpUpdateUserState(pRtpAddr, pRtpUser, USER_EVENT_RTP_PACKET); 

    /* Update RtpAddr and RtpSess receive stats */
                
    RtpUpdateNetCount(&pRtpAddr->RtpAddrCount[RECV_IDX],
                      &pRtpAddr->NetSCritSect,
                      RTP_IDX,
                      pRtpRecvIO->dwWSTransfered,
                      pRtpRecvIO->dwRtpIOFlags,
                      pRtpRecvIO->dRtpRecvTime);

    /* TODO right now there is only 1 RtpAddr_t per RtpSess_t, so the
     * session stats are not used because they are the same as those
     * from the address, but when support for multiple addresses per
     * session be added, we will need to update the session stats
     * also, but as they can be updated by more than 1 address, the
     * update will be a critical section. In that case, DON'T USE the
     * SessCritSect to avoid the deadlock described next. The stop
     * function will try to stop the Recv thread (having locked using
     * SessCritSect), then, if the Recv thread gets a RTP packet
     * before processing the exit command, it will consume it and
     * update stats blocking in SessCritSect, none will be able to
     * continue. The code that follows deadlocks if SessCritSect is
     * used but is right if a different lock is used */
#if 0
    RtpUpdateNetCount(&pRtpAddr->pRtpSess->
                      RtpSessCount[RECV_IDX],
                      pRtpSess->SessCritSect???,
                      RTP_IDX,
                      pRtpRecvIO->dwWSTransfered,
                      pRtpRecvIO->dRtpRecvTime);
#endif

    return(pRtpRecvIO->dwError);
}

DWORD RtpProcessPacket(
        RtpAddr_t       *pRtpAddr,
        RtpUser_t       *pRtpUser,
        RtpRecvIO_t     *pRtpRecvIO,
        RtpHdr_t        *pRtpHdr
    )
{
    long             lPosted;
    DWORD            dwDataOffset;
    DWORD            dwBlockSize;
    DWORD            dwTimeStampOffset;
    BOOL             bPostNow;
    RtpRecvIO_t     *pRtpRecvIO2;
    RtpRedHdr_t     *pRtpRedHdr;
    RtpNetRState_t  *pRtpNetRState;
    
    TraceFunctionName("RtpProcessPacket");  

    /* Will create a separate RtpRecvIO structure for each redundant
     * block */

    /* MAYDO compute the samples per packet (based on timestamp
     * differences) and disable redundancy use until that value has
     * been obtained, the same can be done for the sender */

    pRtpNetRState = &pRtpUser->RtpNetRState;

    lPosted = 0;
    
    if (RtpBitTest(pRtpAddr->dwAddrFlags, FGADDR_REDRECV) &&
        (pRtpRecvIO->lRedDataSize > 0) &&
        (pRtpNetRState->iAvgLossRateR >= RED_LT_1) &&
        !RtpBitTest(pRtpRecvIO->dwRtpIOFlags, FGRECV_MARKER) &&
        pRtpNetRState->dwRecvSamplesPerPacket > 0)
    {
        /* We have redundancy -and- redundancy is enabled -and- loss
         * rate requires packet reconstruction -and- this is not a
         * begining of a talkspurt (I discard any data preceding the
         * one on which I apply the playout delay) */

        pRtpRedHdr = (RtpRedHdr_t *)
            (pRtpRecvIO->WSABuf.buf + pRtpRecvIO->lHdrSize);

        for(dwDataOffset = 0; pRtpRedHdr->F; pRtpRedHdr++)
        {
            dwTimeStampOffset = RedTs(pRtpRedHdr);

            dwBlockSize = RedLen(pRtpRedHdr);
        
            pRtpRecvIO2 = RtpRecvIOGetFree2(pRtpAddr, pRtpRecvIO);

            if (!pRtpRecvIO2)
            {
                /* Lack of resources prevent the processing of
                 * this redundancy block, try next one (next one
                 * migth be main)
                 * */
                dwDataOffset += dwBlockSize;
                
                continue;
            }

            /* It is redundancy, FGRECV_MAIN must be reset and the
             * redundancy flag set */
            pRtpRecvIO2->dwRtpIOFlags = RtpBitPar(FGRECV_ISRED);

            /* Compute just the parametes in the buffer descriptor
             * needed to determine if this redundant block needs to be
             * posted or not */
            
            pRtpRecvIO2->dwExtSeq = pRtpRecvIO->dwExtSeq -
                (dwTimeStampOffset / pRtpNetRState->dwRecvSamplesPerPacket);

            pRtpRecvIO2->dPostTime -=
                ((double)dwTimeStampOffset/pRtpNetRState->dwRecvSamplingFreq);

            if (!dwBlockSize)
            {
                /* Discard redundant blocks with size 0 */
                pRtpRecvIO2->dwError = RTPERR_PACKETDROPPED;

                RtpBitSet2(pRtpRecvIO2->dwRtpIOFlags,
                           FGRECV_DROPPED, FGRECV_OBSOLETE);

                goto dropit;
            }
                    
            /* Verify the PT carried in the redundant block is known,
             * otherwise drop it */
            pRtpRecvIO2->bPT_Block = pRtpRedHdr->pt;

            /* If this block's PT is different from the one we are
             * currently receiving, find out if it is a known one */
            if ( (pRtpRecvIO2->bPT_Block != pRtpNetRState->dwPt) &&
                 !RtpLookupPT(pRtpAddr, pRtpRecvIO2->bPT_Block) )
            {
                pRtpRecvIO2->dwError = RTPERR_NOTFOUND;

                RtpBitSet2(pRtpRecvIO2->dwRtpIOFlags,
                           FGRECV_DROPPED, FGRECV_BADPT);

                goto dropit;
            }
                
            /* If packet is in sequence, or its post time is close or
             * has passed, post it immediatly, otherwise, schedule it
             * to be posted later or drop it if it contains obsolete
             * data (dwError is set). */
            bPostNow = RtpReadyToPost(pRtpAddr, pRtpUser, pRtpRecvIO2);
    
            if (pRtpRecvIO2->dwError)
            {
                goto dropit;
            }

            /* This redundant block will need to be consumed
             * (i.e. will replace a lost main block, compute remainnig
             * fields in the buffer descriptor */
            pRtpRecvIO2->wSeq = (WORD)(pRtpRecvIO2->dwExtSeq & 0xffff);

            pRtpRecvIO2->dwTimeStamp =
                pRtpRecvIO->dwTimeStamp - dwTimeStampOffset;
            
            pRtpRecvIO2->lHdrSize +=
                pRtpRecvIO2->lRedHdrSize + dwDataOffset;

            pRtpRecvIO2->dwTransfered =
                pRtpRecvIO2->lHdrSize + dwBlockSize;

            pRtpRecvIO2->dPlayTime -=
                ((double)dwTimeStampOffset /
                 pRtpNetRState->dwRecvSamplingFreq);
            
            if (bPostNow)
            {
                /* Post buffer to user layer (e.g. DShow) */
                RtpPostUserBuffer(pRtpAddr,
                                  pRtpUser,
                                  pRtpRecvIO2,
                                  pRtpHdr);
                
                lPosted++;
            }
            else
            {
                RtpScheduleToPost(pRtpAddr, pRtpRecvIO2);
            }

            if (RtpBitTest(pRtpAddr->dwAddrFlagsQ, FGADDRQ_QOSRECVON) &&
                !RtpBitTest(pRtpAddr->dwAddrFlagsR, FGADDRR_QOSREDRECV))
            {
                /* QOS in the receiver is enabled but we haven't
                 * updated the reservation to include the redundancy,
                 * update it now. Set the following flag first as it
                 * is used to let QOS know that redundancy is used and
                 * the flowspec needs to be set accordingly */
                RtpBitSet(pRtpAddr->dwAddrFlagsR, FGADDRR_QOSREDRECV);

                RtpBitSet(pRtpAddr->dwAddrFlagsR, FGADDRR_UPDATEQOS);
            }
            
            dwDataOffset += dwBlockSize;
            
            continue;

        dropit:
            TraceDebugAdvanced((
                    0, GROUP_RTP, S_RTP_PERPKTSTAT5,
                    _T("%s:  pRtpAddr[0x%p] pRtpUser[0x%p] ")
                    _T("pRtpRecvIO[0x%p]: ")
                    _T("p %c%c PT:%u m:%u seq:%u ts:%u post:%0.3f/%+0.3f ")
                    _T("error:0x%X flags:0x%08X"),
                    _fname, pRtpAddr, pRtpRecvIO2->pRtpUser, pRtpRecvIO2,
                    _T('R'), _T('-'),
                    pRtpRecvIO2->bPT_Block, pRtpHdr->m,
                    pRtpRecvIO2->dwExtSeq,
                    pRtpRecvIO2->dwTimeStamp,
                    pRtpRecvIO2->dPostTime,
                    pRtpRecvIO2->dPostTime -
                    RtpGetTimeOfDay((RtpTime_t *)NULL),
                    pRtpRecvIO2->dwError,
                    pRtpRecvIO2->dwRtpIOFlags
                    ));
            
            /* Return structure to Free pool */
            RtpRecvIOPutFree(pRtpAddr, pRtpRecvIO2);
            
            dwDataOffset += dwBlockSize;
        }
    }

    /* Now process main data */

    /* Modify headers to reflect a bigger header plus main data */
    pRtpRecvIO->lHdrSize +=
        pRtpRecvIO->lRedHdrSize + pRtpRecvIO->lRedDataSize;

    bPostNow = RtpReadyToPost(pRtpAddr, pRtpUser, pRtpRecvIO);
    
    if (bPostNow)
    {
        /* Post buffer to user layer (e.g. DShow) */
        RtpPostUserBuffer(pRtpAddr,
                          pRtpUser,
                          pRtpRecvIO,
                          pRtpHdr);

        lPosted++;
    }
    else
    {
        RtpScheduleToPost(pRtpAddr, pRtpRecvIO);
    }

    if ((pRtpUser->lPendingPackets > 0) && (lPosted > 0))
    {
        /* We posted at least 1 buffer, if we had pending buffers
         * waiting for it, they may be postable now, check it now */
        RtpCheckReadyToPostOnRecv(pRtpAddr, pRtpUser);
    }

    /* Check if the flowspec needs to be updated */
    if (RtpBitTest(pRtpAddr->dwAddrFlagsR, FGADDRR_UPDATEQOS))
    {
        if (pRtpAddr->pRtpQosReserve->ReserveFlags.RecvFrameSizeValid)
        {
            /* Redo the reservation until we have detected the
             * samples/packet, otherwise that will have to be done
             * again a few packets later */
            RtpBitReset(pRtpAddr->dwAddrFlagsR, FGADDRR_UPDATEQOS);

            /* Adjust first the flowspec to take into account a
             * possible new frame size or redundancy */
            RtpSetQosFlowSpec(pRtpAddr, RECV_IDX);
            
            /* Either we started getting redundancy or the PT being
             * received has changed and need to redo a new reservation */
            RtcpThreadCmd(&g_RtcpContext,
                          pRtpAddr,
                          RTCPTHRD_RESERVE,
                          RECV_IDX,
                          DO_NOT_WAIT);
        }
    }

    
    return(pRtpRecvIO->dwError);
}

DWORD RtpPostUserBuffer(
        RtpAddr_t       *pRtpAddr,
        RtpUser_t       *pRtpUser,
        RtpRecvIO_t     *pRtpRecvIO,
        RtpHdr_t        *pRtpHdr
    )
{
    DWORD            dwError;
    DWORD            dwTransfered;
    DWORD            dwFlags;
    double           dPlayTime;
    long             lHdrSize;
    void            *pvUserInfo1;
    void            *pvUserInfo2;
    void            *pvUserInfo3;
    RtpOutput_t     *pRtpOutput;
    RtpNetRState_t  *pRtpNetRState;
    RtpRecvIO_t     *pRtpRecvIO2;
    double           dFrameSize;
    
    TraceFunctionName("RtpPostUserBuffer");  

    pvUserInfo1 = pRtpRecvIO->pvUserInfo1;
    pvUserInfo2 = pRtpRecvIO->pvUserInfo2;
    pvUserInfo3 = NULL;
    
    if (!pRtpRecvIO->dwError && pRtpUser)
    {
        pRtpNetRState = &pRtpUser->RtpNetRState;
        
        if (!RtpBitTest(pRtpUser->dwUserFlags2, FGUSER2_MUTED))
        {
            /* If this user is not muted, see if there is an output
             * assigned and if not try to assign one */
        
            pRtpOutput = pRtpUser->pRtpOutput;

            if (!pRtpOutput)
            {
                /* No output assigned yet */
                            
                pRtpOutput = RtpGetOutput(pRtpAddr, pRtpUser);
            }
                        
            if (pRtpOutput)
            {
                /* User is (or was just) mapped */
                            
                /* Parameter used later for user function */
                pvUserInfo3 = pRtpOutput->pvUserInfo;
            }
        }

        if (((pRtpNetRState->red_max_seq + 1) != pRtpRecvIO->dwExtSeq) &&
            (RtpGetClass(pRtpAddr->dwIRtpFlags) == RTPCLASS_AUDIO))
        {
            /* I will use the packet duplication technique to recover
             * a single loss only if the audio frame size is smaller
             * than a certain value. This restriction is needed
             * because big frame sizes are more noticeable and can be
             * annoying */
            dFrameSize =
                (double) pRtpNetRState->dwRecvSamplesPerPacket /
                pRtpNetRState->dwRecvSamplingFreq;

            if (!RtpBitTest2(pRtpRecvIO->dwRtpIOFlags,
                             FGRECV_MARKER, FGRECV_HOLD) &&
                (dFrameSize < RTP_MAXFRAMESIZE_PACKETDUP))
            {
                /* If this buffer is not the one expected, that means
                 * there was a gap (at least 1 packet lost), and if this
                 * is audio and this packet was not the begining of a
                 * talkspurt, nor already a recursive call, then I will
                 * post this same buffer (with some fields updated) twice
                 * to implement a receiver only technique to recover from
                 * single losses by playing twice the same frame */
            
                pRtpRecvIO2 = RtpRecvIOGetFree2(pRtpAddr, pRtpRecvIO);

                if (pRtpRecvIO2)
                {
                    /* Update this to be the previous buffer */

                    pRtpRecvIO2->dwExtSeq--;

                    pRtpRecvIO2->dwTimeStamp -=
                        pRtpNetRState->dwRecvSamplesPerPacket;

                    pRtpRecvIO2->dPlayTime -= dFrameSize;
                
                    pRtpRecvIO2->dPostTime -= dFrameSize;
                
                    RtpBitSet(pRtpRecvIO2->dwRtpIOFlags, FGRECV_HOLD);
                    
                    RtpPostUserBuffer(pRtpAddr,pRtpUser,pRtpRecvIO2,pRtpHdr);
                }
            }
        }
        
        pRtpNetRState->red_received++;

        pRtpNetRState->red_max_seq = pRtpRecvIO->dwExtSeq;
    }

    if (RtpBitTest(pRtpRecvIO->dwRtpIOFlags, FGRECV_MARKER))
    {
        pRtpHdr->m = 1;
    }
    else
    {
        pRtpHdr->m = 0;
    }

    /* This logs all the packets */
    TraceDebugAdvanced((
            0, GROUP_RTP, S_RTP_PERPKTSTAT5,
            _T("%s: pRtpAddr[0x%p] pRtpUser[0x%p] pRtpRecvIO[0x%p]: ")
            _T("p %c%c PT:%u m:%u seq:%u ts:%u post:%0.3f/%+0.3f ")
            _T("error:0x%X flags:0x%08X"),
            _fname, pRtpAddr, pRtpRecvIO->pRtpUser, pRtpRecvIO,
            RtpBitTest(pRtpRecvIO->dwRtpIOFlags, FGRECV_HOLD)?
            _T('D') /* A double packet */ :
            RtpBitTest(pRtpRecvIO->dwRtpIOFlags, FGRECV_MAIN)?
            _T('M') /* Main data */ : _T('R') /* Redundancy */,
            pRtpRecvIO->dwError ?
            _T('-') /* Not consumed */ : _T('+') /* Consumed */,
            pRtpRecvIO->bPT_Block, pRtpHdr->m,
            pRtpRecvIO->dwExtSeq,
            pRtpRecvIO->dwTimeStamp,
            pRtpRecvIO->dPostTime,
            pRtpRecvIO->dPostTime - RtpGetTimeOfDay((RtpTime_t *)NULL),
            pRtpRecvIO->dwError,
            pRtpRecvIO->dwRtpIOFlags
        ));

    pRtpHdr->pt  = pRtpRecvIO->bPT_Block;
    pRtpHdr->seq = htons(pRtpRecvIO->wSeq);
    pRtpHdr->ts  = htonl(pRtpRecvIO->dwTimeStamp);

    dwError      = pRtpRecvIO->dwError;
    dwTransfered = pRtpRecvIO->dwTransfered;
    dwFlags      = pRtpRecvIO->dwRtpIOFlags;
    lHdrSize     = pRtpRecvIO->lHdrSize;
    dPlayTime    = pRtpRecvIO->dPlayTime;


    /* Return structure to Free pool */
    RtpRecvIOPutFree(pRtpAddr, pRtpRecvIO);
    
    /* Call user function even on error, needed for the user to take
     * back its buffer (e.g. for DShow filter to Release the sample)
     * */
    pRtpAddr->pRtpRecvCompletionFunc(pvUserInfo1,
                                     pvUserInfo2,
                                     pvUserInfo3,
                                     pRtpUser,
                                     dPlayTime,
                                     dwError,
                                     lHdrSize,
                                     dwTransfered,
                                     dwFlags);

    return(NOERROR);
}

BOOL RtpPostOldest(
        RtpAddr_t       *pRtpAddr
    )
{
    BOOL             bMainPosted;
    RtpQueueItem_t  *pRtpQueueItem;
    RtpRecvIO_t     *pRtpRecvIO;
    RtpUser_t       *pRtpUser;
    RtpNetRState_t  *pRtpNetRState;

    TraceFunctionName("RtpPostOldest");

    bMainPosted = FALSE;

    do {
        pRtpQueueItem =
            dequeuef(&pRtpAddr->RecvIOWaitRedQ, &pRtpAddr->RecvQueueCritSect);

        if (pRtpQueueItem)
        {
            pRtpRecvIO =
                CONTAINING_RECORD(pRtpQueueItem, RtpRecvIO_t, RtpRecvIOQItem);

            pRtpUser = pRtpRecvIO->pRtpUser;

            pRtpUser->lPendingPackets--;

            if (RtpBitTest(pRtpRecvIO->dwRtpIOFlags, FGRECV_MAIN) &&
                !RtpBitTest(pRtpRecvIO->dwRtpIOFlags, FGRECV_HOLD))
            {
                /* Set this boolean only if by posting it another IO
                 * will be started, i.e. it is a main block that is
                 * not being duplicated */
                bMainPosted = TRUE;
            }

            TraceDebug((
                    CLASS_WARNING, GROUP_RTP, S_RTP_RECV,
                    _T("%s: pRtpAddr[0x%p] pRtpRecvIO[0x%p] seq:%u ")
                    _T("forcefully posted, may be ahead of time"),
                    _fname, pRtpAddr, pRtpRecvIO,
                    pRtpRecvIO->dwExtSeq
                ));

            pRtpNetRState = &pRtpUser->RtpNetRState;
            
            /* Check if this is in fact a block (typically redundancy)
             * that needs to be discarded */
            if ((pRtpNetRState->red_max_seq + 1) != pRtpRecvIO->dwExtSeq)
            {
                if (pRtpRecvIO->dwExtSeq <= pRtpNetRState->red_max_seq)
                {
                    /* Old packet (typically an unused redundant
                     * block, unused because we got the main block),
                     * discard it */
                    pRtpRecvIO->dwError = RTPERR_PACKETDROPPED;

                    RtpBitSet2(pRtpRecvIO->dwRtpIOFlags,
                               FGRECV_DROPPED, FGRECV_OBSOLETE);
                }
            }
            
            /* Post buffer to user layer (e.g. DShow) */
            RtpPostUserBuffer(pRtpAddr,
                              pRtpUser,
                              pRtpRecvIO,
                              (RtpHdr_t *)pRtpRecvIO->WSABuf.buf);

            /* now check if other buffers became postable after this
             * one was forced to be posted */
            RtpCheckReadyToPostOnRecv(pRtpAddr, pRtpUser);
        }
    } while(pRtpQueueItem && !bMainPosted);

    if (!bMainPosted)
    {
        TraceRetail((
                CLASS_WARNING, GROUP_RTP, S_RTP_RECV,
                _T("%s: pRtpAddr[0x%p] couldn't post any main buffer ")
                _T("there might not be I/O for some time"),
                _fname, pRtpAddr
            ));
    }
   
    return(bMainPosted);
}
        
/* Test if a buffer is ready to post immediatly */
BOOL RtpReadyToPost(
        RtpAddr_t       *pRtpAddr,
        RtpUser_t       *pRtpUser,
        RtpRecvIO_t     *pRtpRecvIO
    )
{
    BOOL             bPostNow;
    double           dCurTime;
    double           dDiff;
    RtpNetRState_t  *pRtpNetRState;
    
    TraceFunctionName("RtpReadyToPost");  

    bPostNow = TRUE;
            
    dCurTime = RtpGetTimeOfDay((RtpTime_t *)NULL);

    pRtpNetRState = &pRtpRecvIO->pRtpUser->RtpNetRState;

    /* Decide if this buffer is in sequence */
    if ((pRtpNetRState->red_max_seq + 1) != pRtpRecvIO->dwExtSeq)
    {
        /* Decide if this buffer is a duplicate or outdated packet, or
         * if it is and out of order packet (a packet that is ahead of
         * one or more yet to come) */
        if (pRtpRecvIO->dwExtSeq <= pRtpNetRState->red_max_seq)
        {
            /* Old packet (typically an unused redundant block, unused
             * because we got the main block), discard it */
            pRtpRecvIO->dwError = RTPERR_PACKETDROPPED;

            RtpBitSet2(pRtpRecvIO->dwRtpIOFlags,
                       FGRECV_DROPPED, FGRECV_OBSOLETE);
        }
        else
        {
            /* Out of sequence (ahead), we may need to wait for the
             * redundancy to arrive and fill the gap, -or- if not
             * using redundancy,we may need to wait to avoid letting
             * the gap be closed at the consumer (e.g. DShow audio
             * render filter) */
            dDiff = pRtpRecvIO->dPostTime - dCurTime;
            
            if (dDiff > g_dRtpRedEarlyPost)
            {
                /* The time to post this packet hasn't come yet,
                 * before deciding to schedule for later, make sure
                 * there is going to be at least 1 pending I/O so I
                 * can continue receiving packets */
                if (IsQueueEmpty(&pRtpAddr->RecvIOPendingQ) &&
                    IsQueueEmpty(&pRtpAddr->RecvIOReadyQ))
                {
                    /* Post the oldest one (the one closer to be
                     * posted) */
                    RtpPostOldest(pRtpAddr);
                }
                
                bPostNow = FALSE;
            }
            else
            {
                /* The time to post this packet has come, post
                 * right away */
            }
        }
    }
    else
    {
        /* In sequence, post right away */
    }

    return(bPostNow);
}

/* Schedule a buffer to be posted later */
DWORD RtpScheduleToPost(
        RtpAddr_t       *pRtpAddr,
        RtpRecvIO_t     *pRtpRecvIO
    )
{
    RtpQueueItem_t  *pRtpQueueItem;
    
    TraceFunctionName("RtpScheduleToPost");  

    pRtpQueueItem = enqueuedK(&pRtpAddr->RecvIOWaitRedQ,
                              &pRtpAddr->RecvQueueCritSect,
                              &pRtpRecvIO->RtpRecvIOQItem,
                              pRtpRecvIO->dPostTime);

    if (pRtpQueueItem)
    {
        /* A double frame to do receiver only packet reconstruction
         * will never be scheduled, so don't bother about that in the
         * logs */
        TraceDebugAdvanced((
                0, GROUP_RTP, S_RTP_PERPKTSTAT5,
                _T("%s: pRtpAddr[0x%p] pRtpUser[0x%p] pRtpRecvIO[0x%p]: ")
                _T("s %c%c PT:%u m:%u seq:%u ts:%u post:%0.3f/%+0.3f"),
                _fname, pRtpAddr, pRtpRecvIO->pRtpUser, pRtpRecvIO,
                RtpBitTest(pRtpRecvIO->dwRtpIOFlags, FGRECV_MAIN)?
                _T('M'):_T('R'),
                pRtpRecvIO->dwError ? _T('-'):_T('+'),
                pRtpRecvIO->bPT_Block,
                RtpBitTest(pRtpRecvIO->dwRtpIOFlags, FGRECV_MARKER)? 1:0,
                pRtpRecvIO->dwExtSeq,
                pRtpRecvIO->dwTimeStamp,
                pRtpRecvIO->dPostTime,
                pRtpRecvIO->dPostTime - RtpGetTimeOfDay(NULL)
            ));
        
        pRtpRecvIO->pRtpUser->lPendingPackets++;
        
        return(NOERROR);
    }

    /* If failed, this buffer still needs to be posted */

    TraceRetail((
            CLASS_WARNING, GROUP_RTP, S_RTP_PERPKTSTAT5,
            _T("%s: pRtpAddr[0x%p] pRtpUser[0x%p] pRtpRecvIO[0x%p]: ")
            _T("s %c%c PT:%u m:%u seq:%u ts:%u NOT scheduled, dropped"),
            _fname, pRtpAddr, pRtpRecvIO->pRtpUser, pRtpRecvIO,
            RtpBitTest(pRtpRecvIO->dwRtpIOFlags, FGRECV_MAIN)?
            _T('M'):_T('R'),
            pRtpRecvIO->dwError ? _T('-'):_T('+'),
            pRtpRecvIO->bPT_Block,
            RtpBitTest(pRtpRecvIO->dwRtpIOFlags, FGRECV_MARKER)? 1:0,
            pRtpRecvIO->dwExtSeq,
            pRtpRecvIO->dwTimeStamp
        ));

    /* Post with error */
    pRtpRecvIO->dwError = RTPERR_QUEUE;

    RtpBitSet2(pRtpRecvIO->dwRtpIOFlags, FGRECV_ERROR, FGRECV_FAILSCHED);

    /* Post buffer to user layer (e.g. DShow) */
    RtpPostUserBuffer(pRtpAddr,
                      (RtpUser_t *)NULL,
                      pRtpRecvIO,
                      (RtpHdr_t *)pRtpRecvIO->WSABuf.buf);
     
    return(RTPERR_QUEUE);
}

/* Return the time to wait before a  */
DWORD RtpCheckReadyToPostOnTimeout(
        RtpAddr_t       *pRtpAddr
    )
{
    DWORD            dwWaitTime;
    double           dCurTime;
    double           dDiff;
    RtpQueueItem_t  *pRtpQueueItem;
    RtpRecvIO_t     *pRtpRecvIO;

    TraceFunctionName("RtpCheckReadyToPostOnTimeout");  

    dwWaitTime = INFINITE;
    
    while( (pRtpQueueItem = pRtpAddr->RecvIOWaitRedQ.pFirst) )
    {
        dCurTime = RtpGetTimeOfDay((RtpTime_t *)NULL);
    
        dDiff = pRtpQueueItem->dKey - dCurTime;

        if (dDiff < g_dRtpRedEarlyPost)
        {
            /* At least one block for this user needs to be posted */
            pRtpRecvIO =
                CONTAINING_RECORD(pRtpQueueItem, RtpRecvIO_t, RtpRecvIOQItem);

            RtpCheckReadyToPostOnRecv(pRtpAddr, pRtpRecvIO->pRtpUser);
        }
        else
        {
            /* Stop right after finding the first buffer that is not
             * ready to post */
            break;
        }
    }

    pRtpQueueItem = pRtpAddr->RecvIOWaitRedQ.pFirst;

    if (pRtpQueueItem)
    {
        dCurTime = RtpGetTimeOfDay((RtpTime_t *)NULL);

        dDiff = pRtpQueueItem->dKey - dCurTime;

        if (dDiff < g_dRtpRedEarlyPost)
        {
            dwWaitTime = 0;

            TraceRetail((
                    CLASS_WARNING, GROUP_RTP, S_RTP_RECV,
                    _T("%s: pRtpAddr[0x%p] post time has passed:%1.0fms"),
                    _fname, pRtpAddr, dDiff * 1000
                ));
        }
        else
        {
            /* Decrease the timeout value */
            dwWaitTime = (DWORD) ((dDiff - g_dRtpRedEarlyTimeout) * 1000);

            pRtpRecvIO =
                CONTAINING_RECORD(pRtpQueueItem, RtpRecvIO_t, RtpRecvIOQItem);

            if (dwWaitTime > (MAX_PLAYOUT * RTP_RED_MAXDISTANCE))
            {
                TraceRetail((
                        CLASS_WARNING, GROUP_RTP, S_RTP_RECV,
                        _T("%s: pRtpAddr[0x%p] pRtpRecvIO[0x%p] ")
                        _T("post:%0.3f/%+0.3f wait time too big:%ums"),
                        _fname, pRtpAddr, pRtpRecvIO,
                        pRtpRecvIO->dPostTime, dDiff, dwWaitTime
                    ));

                dwWaitTime = MAX_PLAYOUT * RTP_RED_MAXDISTANCE;
            }
            else
            {
                TraceDebug((
                        CLASS_INFO, GROUP_RTP, S_RTP_RECV,
                        _T("%s: pRtpAddr[0x%p] pRtpRecvIO[0x%p] ")
                        _T("post:%0.3f/%+0.3f wait time %ums"),
                        _fname, pRtpAddr, pRtpRecvIO,
                        pRtpRecvIO->dPostTime, dDiff, dwWaitTime
                    ));
            }
        }
    }
    
    return(dwWaitTime);
}

/* NOTE that there might be in the stack a recursive call with depth 2
 * (no recursion being depth 1); RtpCheckReadyToPostOnRecv will call
 * RtpReadyToPost, which in turn may call RtpPostOldest (this
 * function), which will call again RtpCheckReadyToPostOnRecv, the
 * latter will call again RtpReadyToPost but will never call again
 * RtpPostOldest (the recursion stops there). In unicast, the
 * recursion will be for the same RtpUser_t and could be optimized,
 * but in multicast, that could be a different one. Also, the first
 * call to RtpCheckReadyToPostOnRecv will start visiting the items in
 * RecvIOWaitRedQ, and when the recursion occurs, it will not continue
 * because when RtpPostOldest is called (situation on which the
 * recursion happens) that loop will be terminated, and will be
 * completely started in the second call to RtpCheckReadyToPostOnRecv
 * */

/* Check all the pending buffers (those that were scheduled to be
 * posted later) to find out which ones, among those belonging to this
 * user, are ready to post at this moment */
DWORD RtpCheckReadyToPostOnRecv(
        RtpAddr_t       *pRtpAddr,
        RtpUser_t       *pRtpUser
    )
{
    BOOL             bPostNow;
    long             lCount;
    RtpQueueItem_t  *pRtpQueueItem;
    RtpRecvIO_t     *pRtpRecvIO;
    
    TraceFunctionName("RtpCheckReadyToPostOnRecv");  

    for(lCount = GetQueueSize(&pRtpAddr->RecvIOWaitRedQ),
            pRtpQueueItem = pRtpAddr->RecvIOWaitRedQ.pFirst;
        lCount > 0 && pRtpQueueItem;
        lCount--)
    {
        pRtpRecvIO =
            CONTAINING_RECORD(pRtpQueueItem, RtpRecvIO_t, RtpRecvIOQItem);

        pRtpQueueItem = pRtpQueueItem->pNext;

        if (pRtpRecvIO->pRtpUser == pRtpUser)
        {
            bPostNow = RtpReadyToPost(pRtpAddr, pRtpUser, pRtpRecvIO);
    
            if (bPostNow)
            {
                dequeue(&pRtpAddr->RecvIOWaitRedQ,
                        &pRtpAddr->RecvQueueCritSect,
                        &pRtpRecvIO->RtpRecvIOQItem);

                pRtpUser->lPendingPackets--;
            
                /* Post buffer to user layer (e.g. DShow) */
                RtpPostUserBuffer(pRtpAddr,
                                  pRtpRecvIO->pRtpUser,
                                  pRtpRecvIO,
                                  (RtpHdr_t *)pRtpRecvIO->WSABuf.buf);
            }
            else
            {
                /* I'm checking only buffers pending to be posted to
                 * this user, if one is not ready, then none of those
                 * (if any) that follow it will be, so stop now
                 * */
                break;
            }
        }
    }

    return(NOERROR);
}

/* Call callback function to release all pending buffers when the
 * RTP recv thread is about to exit */
DWORD FlushRtpRecvFrom(RtpAddr_t *pRtpAddr)
{
    RtpRecvIO_t     *pRtpRecvIO;
    RtpQueue_t      *pQueue[2];
    RtpQueueItem_t  *pRtpQueueItem;
    DWORD            i;
    DWORD            dwConsumed;

    TraceFunctionName("FlushRtpRecvFrom");

    pQueue[0] = &pRtpAddr->RecvIOPendingQ;
    pQueue[1] = &pRtpAddr->RecvIOWaitRedQ;
    
    for(dwConsumed = 0, i = 0; i < 2; i++)
    {
        do
        {
            pRtpQueueItem = dequeuef(pQueue[i], &pRtpAddr->RecvQueueCritSect);
        
            if (pRtpQueueItem)
            {
                pRtpRecvIO = CONTAINING_RECORD(pRtpQueueItem,
                                               RtpRecvIO_t,
                                               RtpRecvIOQItem);
                
                pRtpRecvIO->dwError = WSA_OPERATION_ABORTED;
                pRtpRecvIO->dwTransfered = 0;
                RtpBitSet2(pRtpRecvIO->dwRtpIOFlags,
                           FGRECV_DROPPED, FGRECV_SHUTDOWN);

                if (pRtpRecvIO->pRtpUser)
                {
                    /* Only buffers in RecvIOWaitRedQ have a user
                     * associated, the pending ones (in
                     * RecvIOPendingQ) do not */
                    pRtpRecvIO->pRtpUser->lPendingPackets--;
                }
                
                /* Call user function even on error, needed for upper
                 * layer to release resources (e.g. DShow filter to
                 * Release the sample) */
                RtpPostUserBuffer(pRtpAddr,
                                  (RtpUser_t *)NULL,
                                  pRtpRecvIO,
                                  (RtpHdr_t *)pRtpRecvIO->WSABuf.buf);
                
                dwConsumed++;
            }
        } while (pRtpQueueItem);
    }

    if (dwConsumed > 0)
    {
        TraceRetail((
                CLASS_INFO, GROUP_RTP, S_RTP_RECV,
                _T("%s: pRtpAddr[0x%p] RtpRecvIO_t flushed:%u"),
                _fname, pRtpAddr, dwConsumed
            ));
    }

    return(dwConsumed);
}

/* Call the callback function to release all the waiting bufferes
 * belonging to the specific user when he is being deleted */
DWORD FlushRtpRecvUser(RtpAddr_t *pRtpAddr, RtpUser_t *pRtpUser)
{
    long             lCount;
    RtpQueueItem_t  *pRtpQueueItem;
    RtpRecvIO_t     *pRtpRecvIO;
    DWORD            dwConsumed;
    
    TraceFunctionName("FlushRtpRecvUser");  

    dwConsumed = 0;
    
    for(lCount = GetQueueSize(&pRtpAddr->RecvIOWaitRedQ),
            pRtpQueueItem = pRtpAddr->RecvIOWaitRedQ.pFirst;
        lCount > 0 && pRtpQueueItem;
        lCount--)
    {
        pRtpRecvIO =
            CONTAINING_RECORD(pRtpQueueItem, RtpRecvIO_t, RtpRecvIOQItem);

        pRtpQueueItem = pRtpQueueItem->pNext;

        if (pRtpRecvIO->pRtpUser == pRtpUser)
        {
            dequeue(&pRtpAddr->RecvIOWaitRedQ,
                    &pRtpAddr->RecvQueueCritSect,
                    &pRtpRecvIO->RtpRecvIOQItem);

            pRtpUser->lPendingPackets--;

            pRtpRecvIO->dwError = RTPERR_PACKETDROPPED;

            pRtpRecvIO->dwTransfered = 0;

            RtpBitSet2(pRtpRecvIO->dwRtpIOFlags,
                       FGRECV_DROPPED, FGRECV_USERGONE);

            /* Post buffer to user layer (e.g. DShow) */
            RtpPostUserBuffer(pRtpAddr,
                              pRtpRecvIO->pRtpUser,
                              pRtpRecvIO,
                              (RtpHdr_t *)pRtpRecvIO->WSABuf.buf);

            dwConsumed++;
        }
    }

    if (dwConsumed > 0)
    {
        TraceRetail((
                CLASS_INFO, GROUP_RTP, S_RTP_RECV,
                _T("%s: pRtpAddr[0x%p] pRtpUser[0x%p] RtpRecvIO_t flushed:%u"),
                _fname, pRtpAddr, pRtpUser, dwConsumed
            ));
    }
    
    return(NOERROR);
}

/* Validate an RTP packet, decrypt if needed */
DWORD RtpValidatePacket(RtpAddr_t *pRtpAddr, RtpRecvIO_t *pRtpRecvIO)
{
    RtpHdr_t        *pRtpHdr;
    RtpHdrExt_t     *pRtpHdrExt;
    RtpRedHdr_t     *pRtpRedHdr;
    char            *hdr;
    RtpCrypt_t      *pRtpCrypt;
    long             lHdrSize;
    int              len;
    int              pad;
    BOOL             bDecryptPayload;
    DWORD            dwDataLen; /* used for decryption */
    DWORD            dwTimeStampOffset; /* Redundant block's ts offset */

    TraceFunctionName("RtpValidatePacket");

    /* MAYDO update bad packets in RtpAddr, right now don't have
     * counters for bad packets, I may add a flag to RtpUpdateStats()
     * so I know if it is a valid packet, a packet too short, an
     * invalid header, etc */

    /* MAYDO may be generate event to the upper layer whenever N
     * invalid packets are received */
    
   /*
     * If encyption mode is "RTP" or "ALL", apply decryption first to
     * whole packet. Use pRtpAddr->pRtpCrypt[RECV_IDX] encryption
     * descriptor.
     *
     * An alternative is to attempt decription only if the packet
     * fails the validity check */

    pRtpCrypt = pRtpAddr->pRtpCrypt[CRYPT_RECV_IDX];
    
    bDecryptPayload = FALSE;
    
    if ( pRtpCrypt &&
         (RtpBitTest2(pRtpCrypt->dwCryptFlags, FGCRYPT_INIT, FGCRYPT_KEY) ==
          RtpBitPar2(FGCRYPT_INIT, FGCRYPT_KEY)) )
    {
        if ((pRtpAddr->dwCryptMode & 0xffff) >= RTPCRYPTMODE_RTP)
        {
            /* Decrypt whole RTP packet */

            dwDataLen = pRtpRecvIO->dwTransfered;
            
            pRtpRecvIO->dwError = RtpDecrypt(
                    pRtpAddr,
                    pRtpCrypt,
                    pRtpRecvIO->WSABuf.buf,
                    &dwDataLen
                );

            if (pRtpRecvIO->dwError != NOERROR)
            {
                if (!pRtpCrypt->CryptFlags.DecryptionError)
                {
                    /* Post an event only the first time */
                    pRtpCrypt->CryptFlags.DecryptionError = 1;
                
                    RtpPostEvent(pRtpAddr,
                                 NULL,
                                 RTPEVENTKIND_RTP,
                                 RTPRTP_CRYPT_RECV_ERROR,
                                 RTP_IDX,
                                 pRtpCrypt->dwCryptLastError);
                }

                goto bail;
            }

            /* Update dwTransfered to reflect the size after
             * decryption */
            pRtpRecvIO->dwTransfered = dwDataLen;
        }
        else
        {
            /* Decrypt only payload */
            bDecryptPayload = TRUE;
        }
    }

    lHdrSize = sizeof(RtpHdr_t);

    len = (int)pRtpRecvIO->dwTransfered;

    /*
     * Check minimal size
     * */
    if (len < lHdrSize)
    {
        /* packet too short */

        pRtpRecvIO->dwError = RTPERR_MSGSIZE;

        goto bail;
    }

     
    hdr = pRtpRecvIO->WSABuf.buf;
    pRtpHdr = (RtpHdr_t *)hdr;

    /*
     * Check version
     * */
    if (pRtpHdr->version != RTP_VERSION)
    {
        /* invalid version */

        pRtpRecvIO->dwError = RTPERR_INVALIDVERSION;
        
        goto bail;
    }

    /* Test payload type is not SR nor RR */
    if (pRtpHdr->pt >= RTCP_SR)
    {
        pRtpRecvIO->dwError = RTPERR_INVALIDPT;

        goto bail;
    }

    /*
     * Handle the contributing sources
     * */
    if (pRtpHdr->cc > 0)
    {
        /* Add to header size the CSRCs size */
        lHdrSize += (pRtpHdr->cc * sizeof(DWORD));

        /* Check minimal size again */
        if (len < lHdrSize)
        {
            /* packet too short */

            pRtpRecvIO->dwError = RTPERR_MSGSIZE;

            goto bail;
        }
    }
    
    /*
     * Handle extension bit
     * */
    if (pRtpHdr->x)
    {
        /* Extension present */

        /* Get variable header size */
        pRtpHdrExt = (RtpHdrExt_t *)(hdr + lHdrSize);

        /* Add to header size the extension size and extension header */
        lHdrSize += ((ntohs(pRtpHdrExt->length) + 1) * sizeof(DWORD));

        /* Check minimal size again */
        if (len < lHdrSize)
        {
            /* packet too short */

            pRtpRecvIO->dwError = RTPERR_MSGSIZE;

            goto bail;
        }
    }

    /* If decrypting payload only, do it now */
    if (bDecryptPayload)
    {
        dwDataLen = pRtpRecvIO->dwTransfered - (DWORD)lHdrSize;
        
        pRtpRecvIO->dwError = RtpDecrypt(
                pRtpAddr,
                pRtpCrypt,
                pRtpRecvIO->WSABuf.buf + lHdrSize,
                &dwDataLen
            );

        if (pRtpRecvIO->dwError != NOERROR)
        {
            goto bail;
        }

        /* Update dwTransfered to reflect the size after decryption */
        pRtpRecvIO->dwTransfered = dwDataLen + lHdrSize;

        len = (int)pRtpRecvIO->dwTransfered;
    }
    
    /*
     * Test padding looking at last byte of WSABUF.buf
     * */
    if (pRtpHdr->p)
    {
        pad = (int) ((DWORD) pRtpRecvIO->WSABuf.buf[len - 1]);

        if (pad > (len - lHdrSize))
        {
            pRtpRecvIO->dwError = RTPERR_INVALIDPAD;

            goto bail;
        }

        /* Remove pad */
        pRtpRecvIO->dwTransfered -= pad;
    }

    /* Save in the buffer descriptor this packet's timestamp and
     * payload type */
    pRtpRecvIO->bPT_Block   = (BYTE)pRtpHdr->pt;
    pRtpRecvIO->wSeq        = ntohs(pRtpHdr->seq);
    pRtpRecvIO->dwTimeStamp = ntohl(pRtpHdr->ts);
    if (pRtpHdr->m)
    {
        RtpBitSet(pRtpRecvIO->dwRtpIOFlags, FGRECV_MARKER);
    }

    pRtpRecvIO->lRedHdrSize = 0;
    pRtpRecvIO->lRedDataSize= 0;
    pRtpRecvIO->dwMaxTimeStampOffset = 0;
    
    /* If the packet contains redundant encoding, validate it */
    if (pRtpHdr->pt == pRtpAddr->bPT_RedRecv)
    {
        len = pRtpRecvIO->dwTransfered - lHdrSize;

        for(pRtpRedHdr = (RtpRedHdr_t *) ((char *)pRtpHdr + lHdrSize);
            pRtpRedHdr->F && len > 0;
            pRtpRedHdr++)
        {
            len -= sizeof(RtpRedHdr_t); /* Red hdr */

            len -= (int)RedLen(pRtpRedHdr);  /* Red data */

            pRtpRecvIO->lRedDataSize += (int)RedLen(pRtpRedHdr);
            pRtpRecvIO->lRedHdrSize += sizeof(RtpRedHdr_t);

            dwTimeStampOffset = RedTs(pRtpRedHdr);

            if (dwTimeStampOffset > pRtpRecvIO->dwMaxTimeStampOffset)
            {
                pRtpRecvIO->dwMaxTimeStampOffset = dwTimeStampOffset;
            }
        }
        
        /* 1 byte main hdr */
        pRtpRecvIO->lRedHdrSize++;
        len--;

        if (len < 0)
        {
            pRtpRecvIO->dwError = RTPERR_INVALIDRED;

            goto bail;
        }

        /* Update the real PT for this buffer, i.e. that of the main
         * buffer */
        pRtpRecvIO->bPT_Block = pRtpRedHdr->pt;

        /* Keep information about this main buffer also containing
         * redundancy */
        RtpBitSet(pRtpRecvIO->dwRtpIOFlags, FGRECV_HASRED);
    }
    
    pRtpRecvIO->lHdrSize = lHdrSize;

    pRtpRecvIO->dwError = NOERROR;

 bail:
    if (pRtpRecvIO->dwError != NOERROR)
    {
        TraceRetail((
                CLASS_WARNING, GROUP_RTP, S_RTP_RECV,
                _T("%s: pRtpAddr[0x%p] pRtpRecvIO[0x%p] ")
                _T("Invalid packet: %u (0x%X)"),
                _fname, pRtpAddr, pRtpRecvIO,
                pRtpRecvIO->dwError, pRtpRecvIO->dwError
            ));
    }
    
    return(pRtpRecvIO->dwError);
}

void RtpInitRSeq(RtpUser_t *pRtpUser, RtpHdr_t *pRtpHdr)
{
    WORD             seq;
    RtpNetRState_t  *pRtpNetRState;

    seq = ntohs(pRtpHdr->seq);
    pRtpNetRState = &pRtpUser->RtpNetRState;
    
    pRtpNetRState->base_seq = seq;

    pRtpNetRState->max_seq = seq;

    pRtpNetRState->bad_seq = RTP_SEQ_MOD + 1;

    pRtpNetRState->cycles = 0;

    pRtpNetRState->received = 0;

    pRtpNetRState->received_prior = 0;

    pRtpNetRState->expected_prior = 0;

    RtpForceFrameSizeDetection(pRtpUser, pRtpHdr);
    
    pRtpNetRState->red_max_seq = seq;

    pRtpNetRState->red_received = 0;

    pRtpNetRState->red_received_prior = 0;

    pRtpNetRState->red_expected_prior = 0;
}

void RtpForceFrameSizeDetection(
        RtpUser_t       *pRtpUser,
        RtpHdr_t        *pRtpHdr
    )
{
    RtpNetRState_t  *pRtpNetRState;
    
    pRtpNetRState = &pRtpUser->RtpNetRState;

    pRtpNetRState->probation = MIN_SEQUENTIAL;

    pRtpNetRState->dwRecvSamplesPerPacket = 0;

    pRtpNetRState->dwRecvMinSamplesPerPacket = 16000;

    pRtpNetRState->dwPreviousTimeStamp =
        ntohl(pRtpHdr->ts) - 16000;
}

/* Return 1 if validated, 0 otherwise
 *
 * See draft-ietf-avt-rtp-new-05.txt */
BOOL RtpUpdateRSeq(RtpUser_t *pRtpUser, RtpHdr_t *pRtpHdr)
{
    BOOL             bRet;
    BOOL             bOk;
    WORD             seq;
    WORD             udelta;
    DWORD            dwTimeStamp;
    DWORD            dwTimeStampGap;
    DWORD            dwNewFrameSize;
    RtpNetRState_t  *pRtpNetRState;
    RtpAddr_t       *pRtpAddr;
    RtpQosReserve_t *pRtpQosReserve;
    
    TraceFunctionName("RtpUpdateRSeq");

    pRtpNetRState = &pRtpUser->RtpNetRState;
    
    seq = ntohs(pRtpHdr->seq);

    udelta = seq - pRtpNetRState->max_seq;

    bRet = FALSE;
    
    bOk = RtpEnterCriticalSection(&pRtpUser->UserCritSect);
    /* If can not get the critical section, just continue, the only
     * bad effect is the posibility of the introduction of a packet
     * lost in the RTCP report if it is being generated right now for
     * this user. This would happen due to the RTCP using values from
     * max_seq and received that might not be in sync.
     * */

    /*
     * Source is not valid until MIN_SEQUENTIAL packets with
     * sequential sequence numbers have been received.
     */
    if (pRtpNetRState->probation)
    {
        /* packet is in sequence */
        if (seq == pRtpNetRState->max_seq + 1)
        {
            pRtpNetRState->max_seq = seq;
            
            dwTimeStamp = ntohl(pRtpHdr->ts);
            
            dwTimeStampGap = dwTimeStamp - pRtpNetRState->dwPreviousTimeStamp;

            pRtpNetRState->dwPreviousTimeStamp = dwTimeStamp;

            if (dwTimeStampGap < pRtpNetRState->dwRecvMinSamplesPerPacket)
            {
                pRtpNetRState->dwRecvMinSamplesPerPacket = dwTimeStampGap;
            }
                
            pRtpNetRState->probation--;
            
            if (pRtpNetRState->probation == 0)
            {
                pRtpNetRState->received += MIN_SEQUENTIAL;

                /* The number of samples per packet is considered to
                 * be minimum seen during the probation phase */
                pRtpNetRState->dwRecvSamplesPerPacket =
                    pRtpNetRState->dwRecvMinSamplesPerPacket;
                
                TraceRetail((
                        CLASS_INFO, GROUP_RTP, S_RTP_RECV,
                        _T("%s: pRtpAddr[0x%p] pRtpUser[0x%p] ")
                        _T("Receiving samples/packet:%u at %u Hz"),
                        _fname, pRtpUser->pRtpAddr, pRtpUser,
                        pRtpNetRState->dwRecvSamplesPerPacket,
                        pRtpNetRState->dwRecvSamplingFreq
                    ));

                pRtpAddr = pRtpUser->pRtpAddr;

                pRtpQosReserve = pRtpAddr->pRtpQosReserve;
                
                if (pRtpQosReserve)
                {
                    /* Update at this moment the frame size if it was
                     * unknown so the next reservation will be done
                     * with the right QOS flowspec, this might happen
                     * later when we start receiving redundancy and we
                     * pass from non redundancy use to redundancy
                     * use. Note that there is a drawback. If
                     * different participants use a different frame
                     * size, the last size will prevail and will be
                     * used for future reservations */
                    dwNewFrameSize =
                        (pRtpNetRState->dwRecvSamplesPerPacket * 1000) /
                        pRtpNetRState->dwRecvSamplingFreq;

                    /* Set the QOS update flag if the frame size has
                     * changed or we are waiting for a fresh computed
                     * frame size */
                    if ( (pRtpQosReserve->dwFrameSizeMS[RECV_IDX] !=
                          dwNewFrameSize)  ||
                         pRtpQosReserve->ReserveFlags.RecvFrameSizeWaiting )
                    {
                        /* Need to redo the reservation if QOS is ON
                         * (i.e. a flow spec has been defined) */
                        if (RtpBitTest(pRtpAddr->dwAddrFlags,
                                       FGADDR_QOSRECVON))
                        {
                            RtpBitSet(pRtpAddr->dwAddrFlagsR,
                                      FGADDRR_UPDATEQOS);
                        }

                        pRtpQosReserve->dwFrameSizeMS[RECV_IDX] =
                            dwNewFrameSize;
                        
                        pRtpQosReserve->ReserveFlags.RecvFrameSizeWaiting = 0;
                    }

                    /* Set frame size as valid */
                    pRtpQosReserve->ReserveFlags.RecvFrameSizeValid = 1;
                }

                bRet = TRUE;
                goto end;
            }
        }
        else
        {
            pRtpNetRState->probation = MIN_SEQUENTIAL - 1;
            
            pRtpNetRState->max_seq = seq;
        }
        
        goto end;
    }
    else if (udelta < MAX_DROPOUT)
    {
        /* in order, with permissible gap */
        if (seq < pRtpNetRState->max_seq)
        {
            /*
             * Sequence number wrapped - count another 64K cycle.
             */
            pRtpNetRState->cycles += RTP_SEQ_MOD;
        }
        
        pRtpNetRState->max_seq = seq;

        /* Valid */
    }
    else if (udelta <= RTP_SEQ_MOD - MAX_MISORDER)
    {
        /* the sequence number made a very large jump */
        if (seq == pRtpNetRState->bad_seq)
        {
            /*
             * Two sequential packets -- assume that the other side
             * restarted without telling us so just re-sync
             * (i.e., pretend this was the first packet).
             */
            RtpInitRSeq(pRtpUser, pRtpHdr);
        }
        else
        {
            pRtpNetRState->bad_seq = (seq + 1) & (RTP_SEQ_MOD-1);

            goto end;
        }
    }
    else
    {
        /* duplicate or reordered packet */
    }

    pRtpNetRState->received++;

    bRet = TRUE;
    
 end:
    if (bOk)
    {
        RtpLeaveCriticalSection(&pRtpUser->UserCritSect);
    }
    
    return(bRet);
}

RtpRecvIO_t *RtpRecvIOGetFree(
        RtpAddr_t       *pRtpAddr
    )
{
    RtpQueueItem_t  *pRtpQueueItem;
    RtpRecvIO_t     *pRtpRecvIO;

    pRtpRecvIO = (RtpRecvIO_t *)NULL;
    
    pRtpQueueItem = dequeuef(&pRtpAddr->RecvIOFreeQ,
                             &pRtpAddr->RecvQueueCritSect);

    if (pRtpQueueItem)
    {
        pRtpRecvIO =
            CONTAINING_RECORD(pRtpQueueItem, RtpRecvIO_t, RtpRecvIOQItem);
    }
    else
    {
        pRtpRecvIO = (RtpRecvIO_t *)
            RtpHeapAlloc(g_pRtpRecvIOHeap, sizeof(RtpRecvIO_t));
    }

    if (pRtpRecvIO)
    {
        ZeroMemory(pRtpRecvIO, sizeof(RtpRecvIO_t));
    }

    return(pRtpRecvIO);
}

RtpRecvIO_t *RtpRecvIOGetFree2(
        RtpAddr_t       *pRtpAddr,
        RtpRecvIO_t     *pRtpRecvIO
    )
{
    RtpQueueItem_t  *pRtpQueueItem;
    RtpRecvIO_t     *pRtpRecvIO2;

    pRtpRecvIO2 = (RtpRecvIO_t *)NULL;
    
    pRtpQueueItem = dequeuef(&pRtpAddr->RecvIOFreeQ,
                             &pRtpAddr->RecvQueueCritSect);

    if (pRtpQueueItem)
    {
        pRtpRecvIO2 =
            CONTAINING_RECORD(pRtpQueueItem, RtpRecvIO_t, RtpRecvIOQItem);
    }
    else
    {
        pRtpRecvIO2 = (RtpRecvIO_t *)
            RtpHeapAlloc(g_pRtpRecvIOHeap, sizeof(RtpRecvIO_t));
    }

    if (pRtpRecvIO2)
    {
        CopyMemory(pRtpRecvIO2,
                   pRtpRecvIO,
                   sizeof(RtpRecvIO_t) - sizeof(pRtpRecvIO->Overlapped));

        ZeroMemory(&pRtpRecvIO2->Overlapped, sizeof(pRtpRecvIO2->Overlapped));
    }

    return(pRtpRecvIO2);
}

RtpRecvIO_t *RtpRecvIOPutFree(
        RtpAddr_t       *pRtpAddr,
        RtpRecvIO_t     *pRtpRecvIO
    )
{
    INVALIDATE_OBJECTID(pRtpRecvIO->dwObjectID);

#if 0
    if (IsSetDebugOption(OPTDBG_FREEMEMORY))
    {
        if (RtpHeapFree(g_pRtpRecvIOHeap, pRtpRecvIO))
        {
            return(pRtpRecvIO);
        }
    }
    else
#endif
    {
        if (enqueuef(&pRtpAddr->RecvIOFreeQ,
                     &pRtpAddr->RecvQueueCritSect,
                     &pRtpRecvIO->RtpRecvIOQItem))
        {
            return(pRtpRecvIO);
        }
    }

    return((RtpRecvIO_t *)NULL);
}

void RtpRecvIOFreeAll(RtpAddr_t *pRtpAddr)
{
    RtpQueueItem_t  *pRtpQueueItem;
    RtpRecvIO_t     *pRtpRecvIO;
    
    do
    {
        pRtpQueueItem = dequeuef(&pRtpAddr->RecvIOFreeQ,
                                 &pRtpAddr->RecvQueueCritSect);

        if (pRtpQueueItem)
        {
            pRtpRecvIO =
                CONTAINING_RECORD(pRtpQueueItem, RtpRecvIO_t, RtpRecvIOQItem);

            /* Invalidate object */
            INVALIDATE_OBJECTID(pRtpRecvIO->dwObjectID);
            
            RtpHeapFree(g_pRtpRecvIOHeap, pRtpRecvIO);
        }
    } while(pRtpQueueItem);
}
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\net\tapi\skywalker\filters\rtp\msrtp\rtp\rtpsend.c ===
/**********************************************************************
 *
 *  Copyright (C) Microsoft Corporation, 1999
 *
 *  File name:
 *
 *    rtpsend.c
 *
 *  Abstract:
 *
 *    RTP send
 *
 *  Author:
 *
 *    Andres Vega-Garcia (andresvg)
 *
 *  Revision:
 *
 *    1999/06/24 created
 *
 **********************************************************************/

#include "gtypes.h"
#include "rtphdr.h"
#include "struct.h"
#include "rtpglobs.h"
#include "rtpncnt.h"
#include "rtpcrypt.h"
#include "rtpevent.h"
#include "rtpmisc.h"
#include "rtpred.h"
#include "rtpqos.h"
#include "rtpsend.h"

/*
 * Updates the RTP header */
HRESULT UpdateRtpHdr(
        RtpAddr_t       *pRtpAddr,
        RtpHdr_t        *pRtpHdr,
        DWORD            dwTimeStamp,
        DWORD            dwSendFlags
    )
{
    BOOL             bOk;
    RtpNetSState_t  *pRtpNetSState;

    pRtpNetSState = &pRtpAddr->RtpNetSState;

    bOk = RtpEnterCriticalSection(&pRtpAddr->NetSCritSect);
    
    pRtpHdr->cc      = 0; /* No Contributing SSRCs */
    pRtpHdr->x       = 0; /* No extensions */
    pRtpHdr->p       = 0; /* No padding */
    pRtpHdr->version = RTP_VERSION; /* RTP version */

    pRtpHdr->m       = (pRtpNetSState->bMarker)? 1:0;

    pRtpHdr->seq     = htons(pRtpNetSState->wSeq);
    pRtpNetSState->dwSeq++;

    /* add random offset */
    dwTimeStamp     += pRtpNetSState->dwTimeStampOffset;

    pRtpHdr->ts      = htonl(dwTimeStamp);

    pRtpHdr->ssrc    = pRtpNetSState->dwSendSSRC;

    if (!RtpBitTest(dwSendFlags, FGSEND_DTMF))
    {
        pRtpHdr->pt      = pRtpNetSState->bPT;
    }
    else
    {
        pRtpHdr->pt      = pRtpNetSState->bPT_Dtmf;

        /* Do I need to force marker bit set for first DTMF packet? */
        if (RtpBitTest(dwSendFlags, FGSEND_FORCEMARKER))
        {
            pRtpHdr->m = 1; 
        }
    }

    /* Save last timestamp together with the NTP time it corresponds
     * to */
    if (pRtpNetSState->dwSendTimeStamp != dwTimeStamp)
    {
        /* In some cases (e.g. video frames), several packets are sent
         * with the same timestamp, keep the time for the last packet
         * to be the one when the first packet of the serie containing
         * the same timestamp was sent */
        pRtpNetSState->dwSendTimeStamp = dwTimeStamp;
        pRtpNetSState->dTimeLastRtpSent = RtpGetTimeOfDay((RtpTime_t *)NULL);
    }
    
    if (bOk)
    {
        RtpLeaveCriticalSection(&pRtpAddr->NetSCritSect);
    }
    
    return(NOERROR);
}

/*
 * Updates the RTP header using the existing timestamp to generate the
 * new one (i.e. the timestamp is already in a buffer passed, may be
 * because this packet is being passed thru in a bridge like app) */
HRESULT UpdateRtpHdr2(
        RtpAddr_t       *pRtpAddr,
        RtpHdr_t        *pRtpHdr
    )
{
    BOOL             bOk;
    RtpNetSState_t  *pRtpNetSState;
    DWORD            dwTimeStamp;

    pRtpNetSState = &pRtpAddr->RtpNetSState;

    bOk = RtpEnterCriticalSection(&pRtpAddr->NetSCritSect);
    
    pRtpHdr->cc      = 0; /* No Contributing SSRCs */
    pRtpHdr->x       = 0; /* No extensions */
    pRtpHdr->p       = 0; /* No padding */
    pRtpHdr->version = RTP_VERSION; /* RTP version */

    /* remember what we got from the RTP header */
    pRtpNetSState->bMarker = (BOOL)pRtpHdr->m;
    pRtpNetSState->bPT = (BYTE)pRtpHdr->pt;
    pRtpNetSState->dwSeq = (DWORD)(ntohs(pRtpHdr->seq) + 1);
    
    /* Get original timestamp */
    dwTimeStamp      = ntohl(pRtpHdr->ts);
    
    /* add random offset */
    dwTimeStamp     += pRtpNetSState->dwTimeStampOffset;

    pRtpHdr->ts      = htonl(dwTimeStamp);

    pRtpHdr->ssrc    = pRtpNetSState->dwSendSSRC;

    /* Save last timestamp together with the NTP time it corresponds
     * to */
    if (pRtpNetSState->dwSendTimeStamp != dwTimeStamp)
    {
        /* In some cases (e.g. video frames), several packets are sent
         * with the same timestamp, keep the time for the last packet
         * to be the one when the first packet of the serie containing
         * the same timestamp was sent */
        pRtpNetSState->dwSendTimeStamp = dwTimeStamp;
        pRtpNetSState->dTimeLastRtpSent = RtpGetTimeOfDay((RtpTime_t *)NULL);
    }

    if (bOk)
    {
        RtpLeaveCriticalSection(&pRtpAddr->NetSCritSect);
    }
    
    return(NOERROR);
}

/*
 * Updates the RTP header adding the redundant header and reorganizing
 * the WSABUFs to contain the redunadnt data if available */
HRESULT UpdateRtpRedHdr(
        RtpAddr_t       *pRtpAddr,
        RtpHdr_t        *pRtpHdr,
        DWORD            dwTimeStamp,
        WSABUF          *pWSABuf,
        DWORD           *pdwWSABufCount
    )
{
    BOOL             bOk;
    BOOL             bAddRedundancy;
    DWORD            dwIndex;
    DWORD            dwSamplesDistance;
    DWORD            dwCurRedDistance;
    RtpNetSState_t  *pRtpNetSState;
    RtpRedEntry_t    RtpRedEntry;
    RtpRedEntry_t   *pRtpRedEntry;
    RtpRedHdr_t     *pRtpRedHdr;

    TraceFunctionName("UpdateRtpRedHdr");  

    pRtpNetSState = &pRtpAddr->RtpNetSState;

    bOk = RtpEnterCriticalSection(&pRtpAddr->NetSCritSect);
    
    /* Initialize part of the header */
    pRtpHdr->cc      = 0; /* No Contributing SSRCs */
    pRtpHdr->x       = 0; /* No extensions */
    pRtpHdr->p       = 0; /* No padding */
    pRtpHdr->version = RTP_VERSION; /* RTP version */

    pRtpHdr->m       = (pRtpNetSState->bMarker)? 1:0;

    pRtpHdr->seq     = htons(pRtpNetSState->wSeq);
    pRtpNetSState->dwSeq++;

    /* add random offset */
    dwTimeStamp     += pRtpNetSState->dwTimeStampOffset;

    pRtpHdr->ts      = htonl(dwTimeStamp);

    pRtpHdr->ssrc    = pRtpNetSState->dwSendSSRC;

    dwCurRedDistance = pRtpNetSState->dwCurRedDistance;
    
    bAddRedundancy = TRUE;
    
    dwSamplesDistance = 0;
    
    /* Find out if we can actually add redundancy */
    
    dwIndex = (pRtpNetSState->dwRedIndex +
               RTP_RED_MAXDISTANCE -
               dwCurRedDistance) %  RTP_RED_MAXDISTANCE;

    pRtpRedEntry = &pRtpNetSState->pRtpRedEntry[dwIndex];

    if (dwCurRedDistance > 0)
    {
        if (pRtpRedEntry->bValid)
        {
            dwSamplesDistance = pRtpNetSState->dwSendSamplesPerPacket *
                dwCurRedDistance;
        
            /* We have a valid buffer, find out if it is not too old,
             * i.e. its timestamp belongs to the one either 1, 2 or 3
             * frames before */
            if ((dwTimeStamp - dwSamplesDistance) == pRtpRedEntry->dwTimeStamp)
            {
                /* Add redundancy */
                TraceDebugAdvanced((
                        0, GROUP_RTP, S_RTP_REDSENDPERPKT1,
                        _T("%s: pRtpAddr[0x%p] at seq:%u ts:%u ")
                        _T("adding Red[%u] D:%u from seq:%u ts:%u"),
                        _fname, pRtpAddr,
                        pRtpNetSState->dwSeq-1,
                        dwTimeStamp,
                        dwIndex, dwCurRedDistance,
                        pRtpRedEntry->dwSeq,
                        pRtpRedEntry->dwTimeStamp
                ));
            }
            else
            {
                bAddRedundancy = FALSE;
                
                TraceDebugAdvanced((
                        0, GROUP_RTP, S_RTP_REDSENDPERPKT2,
                        _T("%s: pRtpAddr[0x%p] at seq:%u ts:%u ")
                        _T("discarding Red[%u] D:%u from seq:%u ts:%u ")
                        _T("expected:%u"),
                        _fname, pRtpAddr,
                        pRtpNetSState->dwSeq-1,
                        dwTimeStamp,
                        dwIndex, dwCurRedDistance,
                        pRtpRedEntry->dwSeq,
                        pRtpRedEntry->dwTimeStamp,
                        dwTimeStamp - dwSamplesDistance
                    ));
            }
        }
        else
        {
            /* Generate an empty redundancy used only to let the
             * receiver know what is the maximum redundancy distance,
             * this should be done only once the current redundancy
             * has been set bigger than 0 */
            pRtpRedEntry = &RtpRedEntry;
            
            pRtpRedEntry->WSABuf.buf = pWSABuf[1].buf;
            pRtpRedEntry->WSABuf.len = 0;
            pRtpRedEntry->bRedPT = pRtpNetSState->bPT;
            
            dwSamplesDistance = pRtpNetSState->dwSendSamplesPerPacket *
                dwCurRedDistance;

            TraceDebugAdvanced((
                    0, GROUP_RTP, S_RTP_REDSENDPERPKT1,
                    _T("%s: pRtpAddr[0x%p] at seq:%u ts:%u ")
                    _T("adding empty Red[%u] D:%u from seq:%u ts:%u"),
                    _fname, pRtpAddr,
                    pRtpNetSState->dwSeq-1,
                    dwTimeStamp,
                    dwIndex, dwCurRedDistance,
                    pRtpNetSState->dwSeq-1-dwCurRedDistance,
                    dwTimeStamp-dwSamplesDistance
                ));
        }
    }
    else
    {
        bAddRedundancy = FALSE;  
    }

    if (bAddRedundancy)
    {
        /* If sending redundant data, RTP header must indicate so by
         * carrying the redundant PT (pRtpHdr is the first WSABUF) */
        pRtpHdr->pt = pRtpNetSState->bPT_RedSend;

        /* Main data will be the fourth (last) WSABUF */
        pWSABuf[3].buf = pWSABuf[1].buf;
        pWSABuf[3].len = pWSABuf[1].len;

        /* Second WSABUF is the redundant header */
        pRtpRedHdr = (RtpRedHdr_t *)(pRtpHdr + 1);
        pWSABuf[1].buf = (char *)pRtpRedHdr;
        pWSABuf[1].len = sizeof(RtpRedHdr_t) + 1;

        /* Third WSABUF is the redundant data */
        pWSABuf[2].buf = pRtpRedEntry->WSABuf.buf;
        pWSABuf[2].len = pRtpRedEntry->WSABuf.len;

        /* Initialize redundant header, redundant block */
        pRtpRedHdr->pt = pRtpRedEntry->bRedPT;
        pRtpRedHdr->F = 1;
        PutRedLen(pRtpRedHdr, pRtpRedEntry->WSABuf.len);
        PutRedTs(pRtpRedHdr, dwSamplesDistance);

        /* Now initialize redundant header, main block */
        pRtpRedHdr++;
        pRtpRedHdr->pt = pRtpNetSState->bPT;
        pRtpRedHdr->F = 0;

        /* We have now 4 WSABUFs to send */
        *pdwWSABufCount = 4;
    }
    else
    {
        /* If not adding redundancy, RTP header must have the PT of
         * the main encoding */
        pRtpHdr->pt = pRtpNetSState->bPT;
    }
    
    /* Save last timestamp together with the NTP time it corresponds
     * to */
    if (pRtpNetSState->dwSendTimeStamp != dwTimeStamp)
    {
        /* In some cases (e.g. video frames), several packets are sent
         * with the same timestamp, keep the time for the last packet
         * to be the one when the first packet of the serie containing
         * the same timestamp was sent */
        pRtpNetSState->dwSendTimeStamp = dwTimeStamp;
        pRtpNetSState->dTimeLastRtpSent = RtpGetTimeOfDay((RtpTime_t *)NULL);
    }
    
    if (bOk)
    {
        RtpLeaveCriticalSection(&pRtpAddr->NetSCritSect);
    }
    
    return(NOERROR);
}

/* Compute if there is enough tokens to send a packet */
BOOL RtpQosEnoughTokens(
        RtpAddr_t       *pRtpAddr,
        WSABUF          *pWSABuf,
        DWORD            dwWSABufCount
    )
{
    double           dTime;
    RtpQosReserve_t *pRtpQosReserve;
    DWORD            i;
    DWORD            dwLen;
    DWORD            dwTokens;
    DWORD            dwTokenRate;
    DWORD            dwMaxSduSize;
    
    pRtpQosReserve = pRtpAddr->pRtpQosReserve;

    /* Compute overall size */
    for(i = 0, dwLen = 0; i < dwWSABufCount; i++, pWSABuf++)
    {
        dwLen += pWSABuf->len;
    }

    if (pRtpAddr->pRtpCrypt[CRYPT_SEND_IDX])
    {
        /* Add the max padding size for encryption */
        /* MAYDO obtain and keep that value in the RtpCrypt_t
         * structure */
        dwLen += 8;
    }

    /* Update available tokens */
    dTime = RtpGetTimeOfDay((RtpTime_t *)NULL);
    
    dwTokenRate = pRtpQosReserve->qos.SendingFlowspec.TokenRate;

    if (dwTokenRate == QOS_NOT_SPECIFIED)
    {
        /* This shouldn't happen, but if it does, then I will use the
         * PCMU's token rate */
        dwTokenRate = 1000;
    }

    dwMaxSduSize = pRtpQosReserve->qos.SendingFlowspec.MaxSduSize;

    if (dwMaxSduSize == QOS_NOT_SPECIFIED)
    {
        /* This shouldn't happen, but if it does, then I will use this
         * packet size */
        dwMaxSduSize = dwLen * 2;
    }
    
    dwTokens = (DWORD)
        ((dTime - pRtpQosReserve->dLastAddition) *
         (double)dwTokenRate * 0.1 /* 10% */);

    /* Update last time I made an addition to the bucket */
    pRtpQosReserve->dLastAddition = dTime;
    
    pRtpQosReserve->dwTokens += dwTokens;

    if (pRtpQosReserve->dwTokens > dwMaxSduSize)
    {
        /* Bucket size is limited by the SduSize */
        pRtpQosReserve->dwTokens = dwMaxSduSize;
    }
    
    if (pRtpQosReserve->dwTokens >= dwLen)
    {
        /* Consume the tokens when we have enough for current packet */
        pRtpQosReserve->dwTokens -= dwLen;

        return(TRUE);
    }

    /* Don't have enough tokens to send this packet */
    return(FALSE);
}

/* IMPORTANT NOTE
 *
 * This function assumes that the first WSABUF is reserved for RTP
 * header and the buffer count received as a parameter includes that
 * header. Note also that the number of buffers is in fact fix
 * depending if it is audio or video, it will be further changed is it
 * is audio and redundancy is used, and/or encryption is used, having
 * an expolicit parameter doesn't imply that the caller can pass more
 * than 1 buffer woth of payload.
 *
 * WARNING
 *
 * If using encryption, the array of WSABUFs passed can be modified */
HRESULT RtpSendTo_(
        RtpAddr_t       *pRtpAddr,
        WSABUF          *pWSABuf,
        DWORD            dwWSABufCount,
        DWORD            dwTimeStamp,
        DWORD            dwSendFlags
    )
{
    BOOL             bOk;
    BOOL             bUsingRedundancy;
    DWORD            dwEvent;
    char             cHdr[RTP_PLUS_RED_HDR_SIZE];
    WSABUF           MainWSABuf;
    RtpHdr_t        *pRtpHdr;
    RtpCrypt_t      *pRtpCrypt;
    SOCKADDR_IN      saddr;
    DWORD            dwStatus;
    DWORD            dwError;
    DWORD            dwNumBytesSent;
    DWORD            dwCount;
    double           dTime;
    TCHAR_t          sAddr[16];

    TraceFunctionName("RtpSendTo_");  

    if (!RtpBitTest(pRtpAddr->dwAddrFlags, FGADDR_RUNSEND))
    {
        return(RTPERR_INVALIDSTATE);
    }

    if (!RtpBitTest(pRtpAddr->dwAddrFlags, FGADDR_RADDR) ||
        !pRtpAddr->wRtpPort[REMOTE_IDX])
    {
        /* Do not send packet if remote address is not specified or
         * remote port is zero */
        TraceRetail((
                CLASS_WARNING, GROUP_RTP, S_RTP_SEND,
                _T("%s: pRtpAddr[0x%p] WSASendTo(%s/%u) ")
                _T("failed: no destination address/port"),
                _fname, pRtpAddr,
                RtpNtoA(pRtpAddr->dwAddr[REMOTE_IDX], sAddr),
                ntohs(pRtpAddr->wRtpPort[REMOTE_IDX])
            ));
        
        return(RTPERR_INVALIDSTATE);
    }
                                                                 
    /* Test if sender is muted */
    if (RtpBitTest(pRtpAddr->dwAddrFlags, FGADDR_MUTERTPSEND))
    {
        return(NOERROR);
    }

    /* Getting the current time here will make me include in the send
     * time also encryption and redundancy handling (if used), as well
     * as the time spent in WSASendTo */
    dTime = RtpGetTimeOfDay((RtpTime_t *)NULL);

    if (!RtpBitTest(pRtpAddr->dwAddrFlagsS, FGADDRS_FRAMESIZE))
    {
        if (!RtpBitTest(pRtpAddr->dwAddrFlagsS, FGADDRS_FIRSTSENT))
        {
            RtpBitSet(pRtpAddr->dwAddrFlagsS, FGADDRS_FIRSTSENT);

            pRtpAddr->RtpNetSState.dwPreviousTimeStamp = dwTimeStamp;
        }
        else if (!pRtpAddr->RtpNetSState.dwSendSamplesPerPacket)
        {
            pRtpAddr->RtpNetSState.dwSendSamplesPerPacket =
                dwTimeStamp - pRtpAddr->RtpNetSState.dwPreviousTimeStamp;

            RtpBitSet(pRtpAddr->dwAddrFlagsS, FGADDRS_FRAMESIZE);

            TraceRetail((
                    CLASS_INFO, GROUP_RTP, S_RTP_SEND,
                    _T("%s: pRtpAddr[0x%p] ")
                    _T("Sending samples/packet:%u"),
                    _fname, pRtpAddr,
                    pRtpAddr->RtpNetSState.dwSendSamplesPerPacket
                ));

            if (pRtpAddr->pRtpQosReserve)
            {
                /* Update at this moment the frame size if it was
                 * unknown so the next reservation will be done with
                 * the right QOS flowspec, this might happen later
                 * when we pass from non redundancy use to redundancy
                 * use or viceversa. This is a last resource as the
                 * frame size for a sender is always known at the time
                 * the session is configured */
                if (!pRtpAddr->pRtpQosReserve->dwFrameSizeMS[SEND_IDX])
                {
                    pRtpAddr->pRtpQosReserve->dwFrameSizeMS[SEND_IDX] =
                        pRtpAddr->RtpNetSState.dwSendSamplesPerPacket /
                        pRtpAddr->RtpNetSState.dwSendSamplingFreq;
                }
            }
        }
    }

    dwError = NOERROR;
    bUsingRedundancy = FALSE;
    
    if (!RtpBitTest(pRtpAddr->pRtpSess->dwFeatureMask, RTPFEAT_PASSHEADER))
    {
        /* RTP header */

        pRtpHdr = (RtpHdr_t *)cHdr;
        pWSABuf[0].len = sizeof(*pRtpHdr);
        pWSABuf[0].buf = (char *)pRtpHdr;

        if (RtpBitTest(dwSendFlags, FGSEND_USERED) &&
            pRtpAddr->RtpNetSState.dwNxtRedDistance &&
            pRtpAddr->RtpNetSState.dwSendSamplesPerPacket)
        {
            /* Use dwNxtRedDistance instead of dwCurRedDistance for
             * the above condition because I need to enter this path
             * to eventually update dwCurRedDistance from the value in
             * dwNxtRedDistance, that's only done at the begining of a
             * talkspurt */
            
            bUsingRedundancy = TRUE;

            MainWSABuf.buf = pWSABuf[1].buf;
            MainWSABuf.len = pWSABuf[1].len;
            
            if (pRtpAddr->RtpNetSState.bMarker)
            {
                RtpClearRedundantBuffs(pRtpAddr);

                TraceRetail((
                        CLASS_INFO, GROUP_RTP, S_RTP_REDSEND,
                        _T("%s: pRtpAddr[0x%p] update (if needed) ")
                        _T("current red distance from %u to %u"),
                        _fname, pRtpAddr,
                        pRtpAddr->RtpNetSState.dwCurRedDistance,
                        pRtpAddr->RtpNetSState.dwNxtRedDistance
                    ));
                
                pRtpAddr->RtpNetSState.dwCurRedDistance =
                    pRtpAddr->RtpNetSState.dwNxtRedDistance;
            }
            
            UpdateRtpRedHdr(pRtpAddr, pRtpHdr, dwTimeStamp,
                            pWSABuf, &dwWSABufCount);
        }
        else
        {
            UpdateRtpHdr(pRtpAddr, pRtpHdr, dwTimeStamp, dwSendFlags);
        }
    }
    else
    {
        /* RTP header and payload are in pWSABuf[1], don't modify the
         * RTP header except the SSRC */

        pRtpHdr = (RtpHdr_t *)pWSABuf[1].buf;
        
        pWSABuf[0].buf = pWSABuf[1].buf;
        pWSABuf[0].len = sizeof(RtpHdr_t) + pRtpHdr->cc * sizeof(DWORD);

        pWSABuf[1].buf += pWSABuf[0].len;
        pWSABuf[1].len -= pWSABuf[0].len;

        pWSABuf[0].len = sizeof(RtpHdr_t);
        
        UpdateRtpHdr2(pRtpAddr, pRtpHdr);
    }
    
    if (!RtpBitTest2(pRtpAddr->dwAddrFlagsQ,
                     FGADDRQ_QOSUNCONDSEND, FGADDRQ_QOSSEND))
    {
        /* NOTE FGADDRQ_QOSSEND is set when QOS is NOT used, so in the
         * absence of QOS I never enter this if */
        
        if (RtpBitTest(pRtpAddr->dwAddrFlagsQ, FGADDRQ_QOSCONDSEND))
        {
            /* Cheack if we have enough tokens to send */
            if (!RtpQosEnoughTokens(pRtpAddr, pWSABuf, dwWSABufCount))
            {
                goto skipsend;
            }
        }
        else
        {
            goto skipsend;
        }
    }

    pRtpCrypt = pRtpAddr->pRtpCrypt[CRYPT_SEND_IDX];

    if ( pRtpCrypt &&
         (RtpBitTest2(pRtpCrypt->dwCryptFlags, FGCRYPT_INIT, FGCRYPT_KEY) ==
          RtpBitPar2(FGCRYPT_INIT, FGCRYPT_KEY)) )
    {
        /* We know we have to encrypt */

        /* NOTE Be aware that RtpEncrypt will merge all the WSABUFs
         * into one whose private data is left pointing not to the
         * original buffer but to pRtpAddr->CryptBuffer[RTP_IDX] */
            
        if ((pRtpAddr->dwCryptMode & 0xffff) >= RTPCRYPTMODE_RTP)
        {
            /* Encrypt whole packets */

            dwError = RtpEncrypt(
                    pRtpAddr,
                    pRtpCrypt,
                    pWSABuf,
                    dwWSABufCount,
                    pRtpAddr->CryptBuffer[RTP_IDX],
                    pRtpAddr->dwCryptBufferLen[RTP_IDX]
                );
            
            dwWSABufCount = 1;
        }
        else
        {
            /* Encrypt only payload (this might include redundant
             * header and redundant data) */
                
            dwError = RtpEncrypt(
                    pRtpAddr,
                    pRtpCrypt,
                    pWSABuf + 1,
                    dwWSABufCount - 1,
                    pRtpAddr->CryptBuffer[RTP_IDX],
                    pRtpAddr->dwCryptBufferLen[RTP_IDX]
                );

            dwWSABufCount = 2;

            if (dwError && !pRtpCrypt->CryptFlags.EncryptionError)
            {
                /* Post an event only the first time */
                pRtpCrypt->CryptFlags.EncryptionError = 1;
 
                RtpPostEvent(pRtpAddr,
                             NULL,
                             RTPEVENTKIND_RTP,
                             RTPRTP_CRYPT_SEND_ERROR,
                             RTP_IDX,
                             pRtpCrypt->dwCryptLastError);
            }
        }
    }

    if (dwError == NOERROR)
    {
        /* Initialize destination address */
        /* TODO I shouldn't need to do this for every packet */
        ZeroMemory(&saddr, sizeof(saddr));
    
        saddr.sin_family = AF_INET;
        saddr.sin_addr.s_addr = pRtpAddr->dwAddr[REMOTE_IDX];
        saddr.sin_port = pRtpAddr->wRtpPort[REMOTE_IDX];

#if USE_GEN_LOSSES > 0
        if (RtpRandomLoss(SEND_IDX))
        {
            dwStatus = 0;

            /* I'm simulating network losses, so I still want to print
             * the log as if I had sent the packet */
            for(dwCount = 0, dwNumBytesSent = 0;
                dwCount < dwWSABufCount;
                dwCount++)
            {
                dwNumBytesSent += pWSABuf[dwCount].len;
            }

            /* @ send_at seq# ts m size pt send_time_ms */
            TraceDebugAdvanced((
                    0, GROUP_RTP, S_RTP_PERPKTSTAT9,
                    _T("%s: pRtpAddr[0x%p] @ %0.3f %u %u %u %u %u %0.3f"),
                    _fname, pRtpAddr,
                    dTime, pRtpAddr->RtpNetSState.dwSeq-1,
                    ntohl(((RtpHdr_t *)pWSABuf[0].buf)->ts),
                    ((RtpHdr_t *)pWSABuf[0].buf)->m,
                    dwNumBytesSent,
                    ((RtpHdr_t *)pWSABuf[0].buf)->pt,
                    (RtpGetTimeOfDay((RtpTime_t *)NULL) - dTime)*1000.0
                ));
            
            goto lossit;
        }
#endif /* USE_GEN_LOSSES > 0 */
    
        dwStatus = WSASendTo(
                pRtpAddr->Socket[SOCK_SEND_IDX],/* SOCKET    s */
                pWSABuf,             /* LPWSABUF  lpBuffers */
                dwWSABufCount,       /* DWORD dwBufferCount */    
                &dwNumBytesSent,     /* LPDWORD lpNumberOfBytesSent */    
                0,                   /* DWORD dwFlags*/    
                (SOCKADDR *)&saddr,  /* const struct sockaddr FAR *lpTo */
                sizeof(saddr),       /* int iToLen*/
                NULL,                /* LPWSAOVERLAPPED lpOverlapped */
                NULL /* LPWSAOVERLAPPED_COMPLETION_ROUTINE lpCompletionROUTINE */
            );

        /* @ send_at seq# ts m size pt send_time_ms */
        TraceDebugAdvanced((
                0, GROUP_RTP, S_RTP_PERPKTSTAT9,
                _T("%s: pRtpAddr[0x%p] @ %0.3f %u %u %u %u %u %0.3f"),
                _fname, pRtpAddr,
                dTime, pRtpAddr->RtpNetSState.dwSeq-1,
                ntohl(((RtpHdr_t *)pWSABuf[0].buf)->ts),
                ((RtpHdr_t *)pWSABuf[0].buf)->m,
                dwNumBytesSent,
                ((RtpHdr_t *)pWSABuf[0].buf)->pt,
                (RtpGetTimeOfDay((RtpTime_t *)NULL) - dTime)*1000.0
            ));

#if USE_GEN_LOSSES > 0
    lossit:
#endif /* USE_GEN_LOSSES > 0 */


        /* Once the packet is sent, I need to reorganize the redundant
         * entries if needed */
        if (bUsingRedundancy)
        {
            /* NOTE that the timestamp here doesn't have yet the
             * random offset added */
            RtpAddRedundantBuff(pRtpAddr, &MainWSABuf, dwTimeStamp);
        }
        
        if (dwStatus)
        {
            TraceRetailWSAGetError(dwError);

            if (dwError == WSAEADDRNOTAVAIL)
            {
                dwEvent = RTPRTP_WS_NET_FAILURE;
            }
            else
            {
                dwEvent = RTPRTP_WS_SEND_ERROR;
            }
            
            RtpPostEvent(pRtpAddr,
                         NULL,
                         RTPEVENTKIND_RTP,
                         dwEvent,
                         RTP_IDX,
                         dwError);

            if (IsAdvancedTracingUsed())
            {
                /* Get the total buffer size */
                for(dwCount = 0, dwNumBytesSent = 0;
                    dwCount < dwWSABufCount;
                    dwCount++)
                {
                    dwNumBytesSent += pWSABuf[dwCount].len;
                }
                
                /* Using class error controlled by the
                 * UseAdvancedTracing (normally all errors go through
                 * TraceRetail without any filter other than the
                 * class) flag to prevent, in the case of lots of
                 * errors to flood the log file */
                TraceRetail((
                        CLASS_ERROR, GROUP_RTP, S_RTP_SEND,
                        _T("%s: pRtpAddr[0x%p] seq:%u size:%u ")
                        _T("failed: %u (0x%X)"),
                        _fname, pRtpAddr,
                        pRtpAddr->RtpNetSState.dwSeq-1, dwNumBytesSent,
                        dwError, dwError
                    ));
            }

            return(RTPERR_WS2SEND);
        }
        else
        {
            /* As per draft-ietf-avt-rtp-new-05, keep a count of the
             * number of bytes of payload (not including headers) sent (to
             * be used in SR's sender info) */
            RtpUpdateNetCount(&pRtpAddr->RtpAddrCount[SEND_IDX],
                              &pRtpAddr->NetSCritSect,
                              RTP_IDX,
                              dwNumBytesSent - sizeof(*pRtpHdr),
                              NO_FLAGS,
                              dTime);
        }
    }
    
 skipsend:
            
    return(dwError);
}
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\net\tapi\skywalker\filters\rtp\msrtp\rtp\rtpstart.c ===
/**********************************************************************
 *
 *  Copyright (C) Microsoft Corporation, 1999
 *
 *  File name:
 *
 *    rtpstart.c
 *
 *  Abstract:
 *
 *    Start/Stop RTP session (and allits addresses)
 *
 *  Author:
 *
 *    Andres Vega-Garcia (andresvg)
 *
 *  Revision:
 *
 *    1999/06/24 created
 *
 **********************************************************************/

#include "struct.h"

#include "rtpthrd.h"
#include "rtcpthrd.h"

#include <ws2tcpip.h>

#include "rtpaddr.h"
#include "rtpqos.h"
#include "rtpuser.h"
#include "rtpncnt.h"
#include "rtpcrypt.h"
#include "rtpreg.h"
#include "rtpmisc.h"
#include "rtpglobs.h"
#include "rtpdemux.h"
#include "rtcpband.h"

#include "rtpstart.h"
HRESULT RtpRealStart(
        RtpAddr_t       *pRtpAddr,
        DWORD            dwFlags
    );

HRESULT RtpRealStop(
        RtpAddr_t       *pRtpAddr,
        DWORD            dwFlags
    );

void RtpSetFromRegistry(RtpAddr_t *pRtpAddr, DWORD dwFlags);


HRESULT RtpStart_(
        RtpSess_t       *pRtpSess,
        DWORD            dwFlags
    )
{
    HRESULT          hr;
    BOOL             bOk;
    BOOL             bDoStart;
    DWORD            dwRecvSend;
    RtpQueueItem_t  *pRtpQueueItem;
    RtpAddr_t       *pRtpAddr;

    TraceFunctionName("RtpStart_");

    dwRecvSend = RtpBitTest(dwFlags, FGADDR_ISRECV)? RECV_IDX : SEND_IDX;
    
    bOk = FALSE;
    
    TraceRetail((
            CLASS_INFO, GROUP_RTP, S_RTP_TRACE,
            _T("%s: pRtpSess[0x%p] %s Flags:0x%X +++++++++++++++++"),
            _fname, pRtpSess,
            RTPRECVSENDSTR(dwRecvSend), dwFlags
        ));

    if (!pRtpSess)
    {
        hr = RTPERR_INVALIDSTATE;

        TraceRetail((
                CLASS_ERROR, GROUP_RTP, S_RTP_START,
                _T("%s: pRtpSess[0x%p]: failed invalid state"),
                _fname, pRtpSess
            ));
        
        goto end;
    }

    /* verify object ID in RtpSess_t */
    if (pRtpSess->dwObjectID != OBJECTID_RTPSESS)
    {
        TraceRetail((
                CLASS_ERROR, GROUP_RTP, S_RTP_START,
                _T("%s: pRtpSess[0x%p] Invalid object ID 0x%X != 0x%X"),
                _fname, pRtpSess,
                pRtpSess->dwObjectID, OBJECTID_RTPSESS
            ));

        hr = RTPERR_INVALIDRTPSESS;

        goto end;
    }
   
    /* Serialize Start/Stop for this session */
    bOk = RtpEnterCriticalSection(&pRtpSess->SessCritSect);

    if (!bOk)
    {
        hr = RTPERR_CRITSECT;
        
        TraceRetail((
                CLASS_ERROR, GROUP_RTP, S_RTP_START,
                _T("%s: pRtpSess[0x%p]: failed to enter critical section"),
                _fname, pRtpSess
            ));

        goto end;
    }
    
    /* TODO go through all the address and start all of them */
    pRtpQueueItem = pRtpSess->RtpAddrQ.pFirst;

    /* Initialize SDES scheduler */
    ZeroMemory(&pRtpSess->RtpSdesSched, sizeof(RtpSdesSched_t));

    if (pRtpQueueItem)
    {
        pRtpAddr = CONTAINING_RECORD(pRtpQueueItem, RtpAddr_t, AddrQItem);

        if (RtpBitTest(pRtpAddr->dwIRtpFlags, FGADDR_IRTP_PERSISTSOCKETS))
        {
            /* Using persistent sockets, i.e. sockets and the RTP
             * session remain active after Stop, they are not really
             * stopped. Ports are guaranteed to remain valid */

            /* On the first time really do start */
            bDoStart = FALSE;
            
            if (RtpBitTest(dwFlags, FGADDR_ISRECV) &&
                !RtpBitTest(pRtpAddr->dwAddrFlags, FGADDR_RUNRECV))
            {
                bDoStart = TRUE;
            }
            if (RtpBitTest(dwFlags, FGADDR_ISSEND) &&
                !RtpBitTest(pRtpAddr->dwAddrFlags, FGADDR_RUNSEND))
            {
                bDoStart = TRUE;
            }

            if (bDoStart)
            {
                /* Need to do a real start */
                hr = RtpRealStart(pRtpAddr, dwFlags);
            }
            else
            {
                /* Already started, just unmute session, re-enable
                 * events, and re-do QOS reservation */
                hr = RtpNetUnmute(pRtpAddr, dwFlags);
            }
        }
        else
        {
            /* Using non persistent sockets, i.e. sockets are closed on
             * Stop. Ports may become used by another application and
             * binding to the same ports again after Stop, then Start,
             * could lead to a failure in unicast, and to unexpected
             * behavior in multicast */
            hr = RtpRealStart(pRtpAddr, dwFlags);
        }
    }

 end:
    if (bOk)
    {
        RtpLeaveCriticalSection(&pRtpSess->SessCritSect);
    }

    if (FAILED(hr))
    {
        TraceRetail((
                CLASS_ERROR, GROUP_RTP, S_RTP_START,
                _T("%s: pRtpSess[0x%p]: failed %s (0x%X)"),
                _fname, pRtpSess, RTPERR_TEXT(hr), hr
            ));
    }
    
    TraceRetail((
            CLASS_INFO, GROUP_RTP, S_RTP_TRACE,
            _T("%s: pRtpSess[0x%p] %s Flags:0x%X -----------------"),
            _fname, pRtpSess,
            RTPRECVSENDSTR(dwRecvSend), dwFlags
        ));

    return(hr);
}

HRESULT RtpStop_(
        RtpSess_t       *pRtpSess,
        DWORD            dwFlags
    )
{
    HRESULT          hr;
    BOOL             bOk;
    BOOL             bDoStop;
    DWORD            dwRecvSend;
    RtpQueueItem_t  *pRtpQueueItem;
    RtpAddr_t       *pRtpAddr;

    TraceFunctionName("RtpStop_");

    dwRecvSend = RtpBitTest(dwFlags, FGADDR_ISRECV)? RECV_IDX : SEND_IDX;

    bOk = FALSE;
    
    TraceRetail((
            CLASS_INFO, GROUP_RTP, S_RTP_TRACE,
            _T("%s: pRtpSess[0x%p] %s Flags:0x%X +++++++"),
            _fname, pRtpSess,
            RTPRECVSENDSTR(dwRecvSend), dwFlags
        ));

    if (!pRtpSess)
    {
        hr = RTPERR_INVALIDSTATE;

        TraceRetail((
                CLASS_ERROR, GROUP_RTP, S_RTP_START,
                _T("%s: pRtpSess[0x%p]: failed invalid state"),
                _fname, pRtpSess
            ));
        
        goto end;
    }

    /* verify object ID in RtpSess_t */
    if (pRtpSess->dwObjectID != OBJECTID_RTPSESS)
    {
        TraceRetail((
                CLASS_ERROR, GROUP_RTP, S_RTP_START,
                _T("%s: pRtpSess[0x%p] Invalid object ID 0x%X != 0x%X"),
                _fname, pRtpSess,
                pRtpSess->dwObjectID, OBJECTID_RTPSESS
            ));

        hr = RTPERR_INVALIDRTPSESS;

        goto end;
    }
    
    /* Serialize Start/Stop for this session */
    bOk = RtpEnterCriticalSection(&pRtpSess->SessCritSect);

    if (!bOk)
    { 
        hr = RTPERR_CRITSECT;
        
        TraceRetail((
                CLASS_ERROR, GROUP_RTP, S_RTP_START,
                _T("%s: pRtpSess[0x%p]: failed to enter critical section"),
                _fname, pRtpSess
            ));
        
        goto end;
    }

    /* TODO go trough all the address and start all of them */
    pRtpQueueItem = pRtpSess->RtpAddrQ.pFirst;

    if (pRtpQueueItem)
    {
        pRtpAddr = CONTAINING_RECORD(pRtpQueueItem, RtpAddr_t, AddrQItem);

        if (RtpBitTest(pRtpAddr->dwIRtpFlags, FGADDR_IRTP_PERSISTSOCKETS) &&
            !RtpBitTest(dwFlags, FGADDR_FORCESTOP))
        {
            /* Using persistent sockets, i.e. sockets and the RTP
             * session remain active after Stop, they are not really
             * stopped. Ports are guaranteed to remain valid */

            /* Mute the session, disable events, and unreserve */
            hr = RtpNetMute(pRtpAddr, dwFlags);
        }
        else
        {
            /* Using non persistent sockets, i.e. sockets are closed on
             * Stop. Ports may become used by another application and
             * binding to the same ports again after Stop, then Start,
             * could lead to a failure in unicast, and to unexpected
             * behavior in multicast */
            hr = RtpRealStop(pRtpAddr, dwFlags);
        }
    }

 end:
    if (bOk)
    {
        RtpLeaveCriticalSection(&pRtpSess->SessCritSect);
    }

    if (FAILED(hr))
    {
        TraceRetail((
                CLASS_ERROR, GROUP_RTP, S_RTP_START,
                _T("%s: pRtpSess[0x%p]: failed %S (0x%X)"),
                _fname, pRtpSess, RTPERR_TEXT(hr), hr
            ));
    }

    TraceRetail((
            CLASS_INFO, GROUP_RTP, S_RTP_TRACE,
            _T("%s: pRtpSess[0x%p] %s Flags:0x%X -------"),
            _fname, pRtpSess,
            RTPRECVSENDSTR(dwRecvSend), dwFlags
        ));

    return(hr);
}

HRESULT RtpRealStart(
        RtpAddr_t       *pRtpAddr,
        DWORD            dwFlags
    )
{
    HRESULT          hr;
    HRESULT          hr2;
    WORD             wRtcpPort;
    DWORD            dwRecvSend;
    DWORD            dwClass;
    RtpSess_t       *pRtpSess;
    RtpCrypt_t      *pRtpCrypt;

    TraceFunctionName("RtpRealStart");

    dwRecvSend = RtpBitTest(dwFlags, FGADDR_ISRECV)? RECV_IDX : SEND_IDX;

    dwClass = RtpGetClass(pRtpAddr->dwIRtpFlags);
    
    hr = NOERROR;

    pRtpSess = pRtpAddr->pRtpSess;
    
    TraceRetail((
            CLASS_INFO, GROUP_RTP, S_RTP_TRACE,
            _T("%s: pRtpSess[0x%p] pRtpAddr[0x%p] ")
            _T("%s/%s Flags:0x%X *****************"),
            _fname, pRtpSess, pRtpAddr,
            RTPRECVSENDSTR(dwRecvSend), RTPSTREAMCLASS(dwClass),
            dwFlags
        ));

    /* Set some defaults from registry (if needed) */
    if (RtpBitTest(dwFlags, FGADDR_ISRECV) &&
        !RtpBitTest(pRtpAddr->dwAddrFlags, FGADDR_REGUSEDRECV))
    {
        RtpSetFromRegistry(pRtpAddr, RtpBitPar(FGADDR_ISRECV));

        RtpBitSet(pRtpAddr->dwAddrFlags, FGADDR_REGUSEDRECV);
    }

    if (RtpBitTest(dwFlags, FGADDR_ISSEND) &&
        !RtpBitTest(pRtpAddr->dwAddrFlags, FGADDR_REGUSEDSEND))
    {
        RtpSetFromRegistry(pRtpAddr, RtpBitPar(FGADDR_ISSEND));

        RtpBitSet(pRtpAddr->dwAddrFlags, FGADDR_REGUSEDSEND);
    }
    
    /* Create sockets if they are not yet created */
    if (!RtpBitTest(pRtpAddr->dwAddrFlags, FGADDR_SOCKET))
    {
        /* This function will set FGADDR_SOCKET */
        hr = RtpGetSockets(pRtpAddr);

        if (FAILED(hr))
        {
            TraceRetail((
                    CLASS_ERROR, GROUP_RTP, S_RTP_START,
                    _T("%s: pRtpSess[0x%p] pRtpAddr[0x%p] ")
                    _T("failed to create sockets: %u (0x%X)"),
                    _fname, pRtpSess, pRtpAddr, hr, hr
                ));
            
            goto bail;
        }
    }

    if (!RtpBitTest(pRtpAddr->dwAddrFlags, FGADDR_RUNRECV) &&
        !RtpBitTest(pRtpAddr->dwAddrFlags, FGADDR_RUNSEND) )
    {
        /* Reset counters */
        RtpResetNetCount(&pRtpAddr->RtpAddrCount[RECV_IDX],
                         &pRtpAddr->NetSCritSect);
        RtpResetNetCount(&pRtpAddr->RtpAddrCount[SEND_IDX],
                         &pRtpAddr->NetSCritSect);

        /* Reset sender's network state */
        RtpResetNetSState(&pRtpAddr->RtpNetSState,
                          &pRtpAddr->NetSCritSect);
    }
        
    /* Set TTL and if multicast set multicast loopback and join group */
    if (!RtpBitTest(pRtpAddr->dwAddrFlags, FGADDR_SOCKOPT))
    {
        /* This function will set FGADDR_SOCKOPT */
        RtpSetSockOptions(pRtpAddr);
    }
        
    /* Obtain our own SSRC, random sequence number and timestamp */
    if (!RtpBitTest(pRtpAddr->dwAddrFlags, FGADDR_RANDOMINIT))
    {
        RtpGetRandomInit(pRtpAddr);

        RtpBitSet(pRtpAddr->dwAddrFlags, FGADDR_RANDOMINIT);
    }

    TraceDebug((
            CLASS_INFO, GROUP_RTP, S_RTP_START,
            _T("%s: pRtpSess[0x%p] pRtpAddr[0x%p] local SSRC:0x%X"),
            _fname, pRtpSess, pRtpAddr,
            ntohl(pRtpAddr->RtpNetSState.dwSendSSRC)
        ));

    /* Start RTCP thread for this address */
    if (!RtpBitTest(pRtpAddr->dwAddrFlags, FGADDR_RTCPTHREAD))
    {
        RtpBitReset2(pRtpAddr->RtpNetSState.dwNetSFlags,
                     FGNETS_1STBANDPOSTED, FGNETS_NOBANDPOSTED);

        RtpBitReset(pRtpAddr->RtpNetSState.dwNetSFlags, FGNETS_DONOTSENDPROBE);
        
        hr = RtcpStart(&g_RtcpContext);

        if (SUCCEEDED(hr))
        {
            RtpBitSet(pRtpAddr->dwAddrFlags, FGADDR_RTCPTHREAD);
        }
        else
        {
            goto bail;
        }
    }
        
    /* Initialize receiver */
    if (RtpBitTest(dwFlags, FGADDR_ISRECV))
    {
        if (!RtpBitTest(pRtpAddr->dwAddrFlags, FGADDR_RUNRECV))
        {
            /* Receiver's cryptographic initialization */
            pRtpCrypt = pRtpAddr->pRtpCrypt[CRYPT_RECV_IDX];
            
            if (pRtpCrypt)
            {
                hr = RtpCryptInit(pRtpAddr, pRtpCrypt);
                
                if (FAILED(hr))
                {
                    goto bail;
                }

                RtpBitSet(pRtpAddr->dwAddrFlagsC, FGADDRC_CRYPTRECVON);
            }

            RtpBitSet(pRtpAddr->dwAddrFlags, FGADDR_ISRECV);
            
            if (RtpBitTest(pRtpAddr->dwAddrFlags, FGADDR_QOSRECV) &&
                RtpBitTest(pRtpAddr->dwAddrFlagsQ, FGADDRQ_RECVFSPEC_DEFINED)&&
                !RtpBitTest2(pRtpAddr->dwAddrFlagsQ,
                             FGADDRQ_REGQOSDISABLE, FGADDRQ_QOSNOTALLOWED))
            {
                /* NOTE: the test above is also done in RtpNetUnmute */

                /* Make a QOS reservation */
                hr2 = RtcpThreadCmd(&g_RtcpContext,
                                    pRtpAddr,
                                    RTCPTHRD_RESERVE,
                                    RECV_IDX,
                                    DO_NOT_WAIT);

                if (SUCCEEDED(hr2))
                {
                    RtpBitSet(pRtpAddr->dwAddrFlags, FGADDR_QOSRECVON);
                }
            }

            /* Enable events (provided the mask has some events
             * enabled) */
            RtpBitSet(pRtpSess->dwSessFlags, FGSESS_EVENTRECV);

            /* Set state FGADDR_RUNRECV, it i simportant to do
             * this before starting the RTP thread to allow it to
             * repost packets received */
            RtpBitSet(pRtpAddr->dwAddrFlags, FGADDR_RUNRECV);

            /* Create reception thread and start reception */
            hr = RtpCreateRecvThread(pRtpAddr);

            if (FAILED(hr))
            {
                TraceRetail((
                        CLASS_ERROR, GROUP_RTP, S_RTP_START,
                        _T("%s: pRtpSess[0x%p] pRtpAddr[0x%p] ")
                        _T("RTP thread creation failed: %u (0x%X)"),
                        _fname, pRtpSess, pRtpAddr, hr, hr
                    ));
                
                goto bail;
            }

            RtpBitSet(pRtpAddr->dwAddrFlags, FGADDR_RTPTHREAD);

            InterlockedIncrement(&g_RtpContext.lNumRecvRunning);
        }
    }

    /* Initialize sender */
    if (RtpBitTest(dwFlags, FGADDR_ISSEND))
    {
        if (!RtpBitTest(pRtpAddr->dwAddrFlags, FGADDR_RUNSEND))
        {
            /* Sender's cryptographic initialization */
            pRtpCrypt = pRtpAddr->pRtpCrypt[CRYPT_SEND_IDX];
            
            if (pRtpCrypt)
            {
                hr = RtpCryptInit(pRtpAddr, pRtpCrypt);

                if (FAILED(hr))
                {
                    goto bail;
                }

                RtpBitSet(pRtpAddr->dwAddrFlagsC, FGADDRC_CRYPTSENDON);
            }

            RtpBitSet(pRtpAddr->dwAddrFlags, FGADDR_ISSEND);
            
            /* Enable sending at full rate, QOS may not be used or
             * permission granted, in the mean time, send */
            RtpBitSet(pRtpAddr->dwAddrFlagsQ, FGADDRQ_QOSSEND);

            if (RtpBitTest(pRtpAddr->dwAddrFlags, FGADDR_QOSSEND) &&
                RtpBitTest(pRtpAddr->dwAddrFlagsQ, FGADDRQ_SENDFSPEC_DEFINED)&&
                !RtpBitTest2(pRtpAddr->dwAddrFlagsQ,
                             FGADDRQ_REGQOSDISABLE, FGADDRQ_QOSNOTALLOWED))
            {
                /* NOTE: the test above is also done in RtpNetUnmute */
                
                /* Start sending PATH messages */
                hr2 = RtcpThreadCmd(&g_RtcpContext,
                                    pRtpAddr,
                                    RTCPTHRD_RESERVE,
                                    SEND_IDX,
                                    DO_NOT_WAIT);
                
                if (SUCCEEDED(hr2))
                {
                    RtpBitSet(pRtpAddr->dwAddrFlags, FGADDR_QOSSENDON);
                }
            }

            /* Start with this redundancy distance */
            pRtpAddr->RtpNetSState.dwNxtRedDistance =
                pRtpAddr->RtpNetSState.dwInitialRedDistance;

            /* Bandwidth estimation, set initial module every time we
             * start, also reset the counter */
            pRtpAddr->RtpNetSState.dwBandEstMod = g_dwRtcpBandEstModInitial;
            pRtpAddr->RtpNetSState.dwBandEstCount = 0;
            
            /* Enable events (provided the mask has some events
             * enabled) */
            RtpBitSet(pRtpSess->dwSessFlags, FGSESS_EVENTSEND);

            RtpBitSet(pRtpAddr->dwAddrFlags, FGADDR_RUNSEND);

            InterlockedIncrement(&g_RtpContext.lNumSendRunning);
        }
    }

    /* Start RTCP activity (send/receive reports) for this
     * address */
    if (!RtpBitTest(pRtpAddr->dwAddrFlags, FGADDR_ADDED))
    {
        /* RTCP's cryptographic initialization */
        pRtpCrypt = pRtpAddr->pRtpCrypt[CRYPT_RTCP_IDX];
            
        if (pRtpCrypt)
        {
            hr = RtpCryptInit(pRtpAddr, pRtpCrypt);
            
            if (FAILED(hr))
            {
                goto bail;
            }

            RtpBitSet(pRtpAddr->dwAddrFlagsC, FGADDRC_CRYPTRTCPON);
        }
            
        hr = RtcpThreadCmd(&g_RtcpContext,
                           pRtpAddr,
                           RTCPTHRD_ADDADDR,
                           0,
                           60*60*1000); /* TODO update */
        
        if (SUCCEEDED(hr))
        {
            RtpBitSet(pRtpAddr->dwAddrFlags, FGADDR_ADDED);
        }
        else
        {
            goto bail;
        }
    }

    TraceRetail((
            CLASS_INFO, GROUP_RTP, S_RTP_TRACE,
            _T("%s: pRtpSess[0x%p] pRtpAddr[0x%p] ")
            _T("%s/%s Flags:0x%X ================="),
            _fname, pRtpSess, pRtpAddr,
            RTPRECVSENDSTR(dwRecvSend), RTPSTREAMCLASS(dwClass),
            dwFlags
        ));
    
    return(hr);

 bail:

    RtpRealStop(pRtpAddr, dwFlags);
    
    TraceRetail((
            CLASS_ERROR, GROUP_RTP, S_RTP_START,
            _T("%s: pRtpAddr[0x%p] failed: %s (0x%X)"),
            _fname, pRtpAddr, RTPERR_TEXT(hr), hr
        ));
    
    return(hr);
}

HRESULT RtpRealStop(
        RtpAddr_t       *pRtpAddr,
        DWORD            dwFlags
    )
{
    HRESULT          hr;
    DWORD            dwRecvSend;
    DWORD            dwClass;
    RtpSess_t       *pRtpSess;
    RtpCrypt_t      *pRtpCrypt;

    TraceFunctionName("RtpRealStop");

    dwRecvSend = RtpBitTest(dwFlags, FGADDR_ISRECV)? RECV_IDX : SEND_IDX;

    dwClass = RtpGetClass(pRtpAddr->dwIRtpFlags);

    hr = NOERROR;

    pRtpSess = pRtpAddr->pRtpSess;
    
    TraceRetail((
            CLASS_INFO, GROUP_RTP, S_RTP_TRACE,
            _T("%s: pRtpSess[0x%p] pRtpAddr[0x%p] ")
            _T("%s/%s Flags:0x%X *******"),
            _fname, pRtpSess, pRtpAddr,
            RTPRECVSENDSTR(dwRecvSend), RTPSTREAMCLASS(dwClass),
            dwFlags
        ));
    
    if (RtpBitTest(dwFlags, FGADDR_ISRECV))
    {
        if (RtpBitTest(pRtpAddr->dwAddrFlags, FGADDR_ISRECV))
        {
            /* De-initialize as receiver */

            /* Don't want more events */
            RtpBitReset(pRtpSess->dwSessFlags, FGSESS_EVENTRECV);

            if (RtpBitTest(pRtpAddr->dwAddrFlags, FGADDR_QOSRECVON))
            {
                RtcpThreadCmd(&g_RtcpContext,
                              pRtpAddr,
                              RTCPTHRD_UNRESERVE,
                              RECV_IDX,
                              DO_NOT_WAIT);

                RtpBitReset(pRtpAddr->dwAddrFlags, FGADDR_QOSRECVON);
            }

            /* Reset state FGADDR_RUNRECV, it is important to do
             * this before calling RtpDeleteRecvThread to prevent
             * trying to repost again the completed async I/Os
             * */
            RtpBitReset(pRtpAddr->dwAddrFlags, FGADDR_RUNRECV);
                
            if (RtpBitTest(pRtpAddr->dwAddrFlags, FGADDR_RTPTHREAD))
            {
                RtpBitReset(pRtpAddr->dwAddrFlags, FGADDR_RTPTHREAD);
            
                /* Stop reception thread */
                RtpDeleteRecvThread(pRtpAddr);

                /* Receiver's cryptographic de-initialization */
                pRtpCrypt = pRtpAddr->pRtpCrypt[CRYPT_RECV_IDX];
            
                if (pRtpCrypt)
                {
                    if (RtpBitTest(pRtpAddr->dwAddrFlagsC,
                                   FGADDRC_CRYPTRECVON))
                    {
                        RtpCryptDel(pRtpAddr, pRtpCrypt);

                        RtpBitReset(pRtpAddr->dwAddrFlagsC,
                                    FGADDRC_CRYPTRECVON);
                    }
                }

                InterlockedDecrement(&g_RtpContext.lNumRecvRunning);  
            }

            /* Unmap all the RTP outputs */
            RtpUnmapAllOuts(pRtpSess);

            /* Reset reception in all participants */
            ResetAllRtpUser(pRtpAddr, RtpBitPar(RECV_IDX));
            
            /* NOTE I could move here disabling the events so
             * unmapping the outputs will still have a chance to post
             * events */

            /* If the same receiver session is real started again,
             * start in the unmuted state */
            RtpBitReset(pRtpAddr->dwAddrFlags, FGADDR_MUTERTPRECV);
            
            RtpBitReset(pRtpAddr->dwAddrFlags, FGADDR_ISRECV);

            RtpBitReset(pRtpAddr->dwAddrFlagsR, FGADDRR_QOSREDRECV);
            RtpBitReset(pRtpAddr->dwAddrFlagsR, FGADDRR_UPDATEQOS);
        }
    }
        
    if (RtpBitTest(dwFlags, FGADDR_ISSEND))
    {
        if (RtpBitTest2(pRtpAddr->dwAddrFlags,
                        FGADDR_ISSEND, FGADDR_RUNSEND) ==
            RtpBitPar2(FGADDR_ISSEND, FGADDR_RUNSEND))
        {
            /* De-initialize as sender */
                
            /* Don't want more events */
            RtpBitReset(pRtpSess->dwSessFlags, FGSESS_EVENTSEND);
                
            RtpBitReset(pRtpAddr->dwAddrFlags, FGADDR_RUNSEND);
                
            if (RtpBitTest(pRtpAddr->dwAddrFlags, FGADDR_QOSSENDON))
            {
                RtcpThreadCmd(&g_RtcpContext,
                              pRtpAddr,
                              RTCPTHRD_UNRESERVE,
                              SEND_IDX,
                              DO_NOT_WAIT);

                RtpBitReset(pRtpAddr->dwAddrFlags, FGADDR_QOSSENDON);
            }
  
            /* Sender's cryptographic de-initialization */
            pRtpCrypt = pRtpAddr->pRtpCrypt[CRYPT_SEND_IDX];

            if (pRtpCrypt)
            {
                if (RtpBitTest(pRtpAddr->dwAddrFlagsC,
                               FGADDRC_CRYPTSENDON))
                {
                    RtpCryptDel(pRtpAddr, pRtpCrypt);

                    RtpBitReset(pRtpAddr->dwAddrFlagsC,
                                FGADDRC_CRYPTSENDON);
                }
            }

            /* If the same sender session is real started again, start
             * in the unmuted state */
            RtpBitReset(pRtpAddr->dwAddrFlags, FGADDR_MUTERTPSEND);
            
            RtpBitReset(pRtpAddr->dwAddrFlags, FGADDR_ISSEND);

            InterlockedDecrement(&g_RtpContext.lNumSendRunning);  
        }
    }

    if ( !RtpBitTest2(pRtpAddr->dwAddrFlags,
                      FGADDR_RUNRECV, FGADDR_RUNSEND) )
    {
        if (RtpBitTest(pRtpAddr->dwAddrFlags, FGADDR_ADDED))
        {
            /* Send RTCP BYE and shutdown this address */
            RtcpThreadCmd(&g_RtcpContext,
                          pRtpAddr,
                          RTCPTHRD_SENDBYE,
                          TRUE,
                          60*60*1000); /* TODO update */
        
            /* destroy sockets */
            RtpDelSockets(pRtpAddr);
            
            /* Remove this address from RTCP thread */
            hr = RtcpThreadCmd(&g_RtcpContext,
                               pRtpAddr,
                               RTCPTHRD_DELADDR,
                               0,
                               60*60*1000); /* TODO update */
            RtpBitReset(pRtpAddr->dwAddrFlags, FGADDR_ADDED);
        }
        else
        {
            /* Shouldn't need to delete sockets here, if the address
             * was not added, it would not need to be removed (in
             * other words, if the address was not started, it doesn't
             * need to be stopped). Yet the sockets still need to be
             * deleted even when the address was never
             * started/stopped, as they might have been created
             * because the application queried for the local ports,
             * but that deletion is delegated to DelRtpAddr() */
        }

        /* RTCP's cryptographic de-initialization */
        pRtpCrypt = pRtpAddr->pRtpCrypt[CRYPT_RTCP_IDX];

        if (pRtpCrypt)
        {
            if (RtpBitTest(pRtpAddr->dwAddrFlagsC, FGADDRC_CRYPTRTCPON))
            {
                RtpCryptDel(pRtpAddr, pRtpCrypt);

                RtpBitReset(pRtpAddr->dwAddrFlagsC, FGADDRC_CRYPTRTCPON);
            }
        }
            
        /* Stop the RTCP thread */
        if (RtpBitTest(pRtpAddr->dwAddrFlags, FGADDR_RTCPTHREAD))
        {
            RtcpStop(&g_RtcpContext);

            RtpBitReset(pRtpAddr->dwAddrFlags, FGADDR_RTCPTHREAD);
        }

        /* If later I'm started again, I want to obtain new random
         * values */
        if (RtpBitTest(pRtpAddr->dwAddrFlags, FGADDR_RANDOMINIT))
        {
            RtpBitReset(pRtpAddr->dwAddrFlags, FGADDR_RANDOMINIT);
            
            /* Delete all participants */
            DelAllRtpUser(pRtpAddr);
        }

        RtpBitReset(pRtpAddr->dwAddrFlagsQ, FGADDRQ_QOSEVENTPOSTED);
    }

    TraceDebug((
            CLASS_INFO, GROUP_RTP, S_RTP_TRACE,
            _T("%s: Recv(Free:%u, Ready:%u, Pending:%u)"),
            _fname,
            GetQueueSize(&pRtpAddr->RecvIOFreeQ),
            GetQueueSize(&pRtpAddr->RecvIOReadyQ),
            GetQueueSize(&pRtpAddr->RecvIOPendingQ)
        ));

    TraceRetail((
            CLASS_INFO, GROUP_RTP, S_RTP_TRACE,
            _T("%s: pRtpSess[0x%p] pRtpAddr[0x%p] ")
            _T("%s/%s Flags:0x%X ======="),
            _fname, pRtpSess, pRtpAddr,
            RTPRECVSENDSTR(dwRecvSend), RTPSTREAMCLASS(dwClass),
            dwFlags
        ));

    return(hr);
}

/* Helper function for RtpSetFromRegistry() */
void RtpModifyBit(
        DWORD           *pdwEventMask,
        DWORD            dwMask,
        DWORD            dwFlag,
        BOOL             bEnable)
{
    DWORD            i;
    
    if (dwMask != -1)
    {
        for(i = RECV_IDX; i <= SEND_IDX; i++)
        {
            if (RtpBitTest(dwFlag, i))
            {
                if (bEnable)
                {
                    pdwEventMask[i] |= dwMask;
                }
                else
                {
                    pdwEventMask[i] &= ~dwMask;
                }
            }
        }
    }
}

/*
 * Very important WARNING and TODO
 *
 * Some *disabling* flags here might be dangerous, i.e. to disable
 * encryption. I need either to add a compilation option to remove
 * them in the final product, or provide a mechanism to inform the
 * user about things being disabled */
void RtpSetFromRegistry(RtpAddr_t *pRtpAddr, DWORD dwFlags)
{
    WORD             wPort;
    DWORD            i;
    DWORD            dwFlag;
    DWORD            dwRecvSend;
    DWORD            dwCryptMode;
    DWORD            dwPar1;
    DWORD            dwPar2;
    DWORD            dwPar3;
    RtpSess_t       *pRtpSess;

    TraceFunctionName("RtpSetFromRegistry");

    pRtpSess = pRtpAddr->pRtpSess;
    
    /*
     * Address/port
     */
    if (RtpBitTest(pRtpAddr->dwIRtpFlags, FGADDR_IRTP_AUTO))
    {
        if (!RtpBitTest(pRtpAddr->dwAddrFlags, FGADDR_RADDR))
        {
            pRtpAddr->dwAddr[REMOTE_IDX]    = 0x0a0505e0;/* 224.5.5.10/10000 */
            pRtpAddr->wRtpPort[LOCAL_IDX]   = htons(10000);
            pRtpAddr->wRtpPort[REMOTE_IDX]  = htons(10000);
            pRtpAddr->wRtcpPort[LOCAL_IDX]  = htons(10001);
            pRtpAddr->wRtcpPort[REMOTE_IDX] = htons(10001);
            
            if (g_RtpReg.psDefaultIPAddress)
            {
                pRtpAddr->dwAddr[REMOTE_IDX] =
                    RtpAtoN(g_RtpReg.psDefaultIPAddress);
            }

            if (g_RtpReg.dwDefaultLocalPort <= 0xffff)
            {
                wPort = (WORD)g_RtpReg.dwDefaultLocalPort;
                pRtpAddr->wRtpPort[LOCAL_IDX]  = htons(wPort);
                wPort++;
                pRtpAddr->wRtcpPort[LOCAL_IDX] = htons(wPort);
            }

            if (g_RtpReg.dwDefaultRemotePort <= 0xffff)
            {
                wPort = (WORD)g_RtpReg.dwDefaultRemotePort;
                pRtpAddr->wRtpPort[REMOTE_IDX]  = htons(wPort);
                wPort++;
                pRtpAddr->wRtcpPort[REMOTE_IDX] = htons(wPort);
            }

            /* Needed to set local address */
            RtpSetAddress(pRtpAddr, 0, pRtpAddr->dwAddr[REMOTE_IDX]);
        }
    }

    if (g_RtpReg.dwMcastLoopbackMode < RTPMCAST_LOOPBACKMODE_LAST)
    {
        TraceRetail((
                CLASS_WARNING, GROUP_RTP, S_RTP_REG,
                _T("%s: pRtpAddr[0x%p] multicast mode being forced to:%u"),
                _fname, pRtpAddr, g_RtpReg.dwMcastLoopbackMode
            ));

        RtpSetMcastLoopback(pRtpAddr, g_RtpReg.dwMcastLoopbackMode, 0);
    }
    
    /*
     * QOS
     */
    if (RtpBitTest(pRtpAddr->dwIRtpFlags, FGADDR_IRTP_QOS) &&
        IsRegValueSet(g_RtpReg.dwQosEnable))
    {
        dwRecvSend = RtpBitTest(dwFlags, FGADDR_ISRECV)? RECV_IDX : SEND_IDX;

        if ((g_RtpReg.dwQosEnable & 0x3) == 3)
        {
            dwPar1 = RTPQOS_STYLE_DEFAULT;
            
            if (IsRegValueSet(g_RtpReg.dwQosRsvpStyle) &&
                g_RtpReg.dwQosRsvpStyle < RTPQOS_STYLE_LAST)
            {
                dwPar1 = g_RtpReg.dwQosRsvpStyle;
            }

            dwPar2 = 1;

            if (IsRegValueSet(g_RtpReg.dwQosMaxParticipants) &&
                g_RtpReg.dwQosMaxParticipants < 0x1024)
            {
                dwPar2 = g_RtpReg.dwQosMaxParticipants;
            }

            dwPar3 = RTPQOSSENDMODE_ASK_BUT_SEND;
            
            if (IsRegValueSet(g_RtpReg.dwQosSendMode) &&
                g_RtpReg.dwQosSendMode < RTPQOSSENDMODE_LAST)
            {
                dwPar3 = g_RtpReg.dwQosSendMode;
            }

            TraceRetail((
                    CLASS_WARNING, GROUP_RTP, S_RTP_REG,
                    _T("%s: pRtpAddr[0x%p] QOS being forced enabled"),
                    _fname, pRtpAddr
                ));
            
            if (g_RtpReg.psQosPayloadType)
            {
                RtpSetQosByNameOrPT(pRtpAddr,
                                    dwRecvSend,
                                    g_RtpReg.psQosPayloadType,
                                    NO_DW_VALUESET,
                                    dwPar1,
                                    dwPar2,
                                    dwPar3,
                                    NO_DW_VALUESET,
                                    TRUE);
            }
            else
            {
                RtpSetQosByNameOrPT(pRtpAddr,
                                    dwRecvSend,
                                    _T("H263CIF"),
                                    NO_DW_VALUESET,
                                    dwPar1,
                                    dwPar2,
                                    dwPar3,
                                    NO_DW_VALUESET,
                                    TRUE);
            }

            if (g_RtpReg.psQosAppName ||
                g_RtpReg.psQosAppGUID ||
                g_RtpReg.psQosPolicyLocator)
            {
                RtpSetQosAppId(pRtpAddr,
                               g_RtpReg.psQosAppName,
                               g_RtpReg.psQosAppGUID,
                               g_RtpReg.psQosPolicyLocator);
            }

            RtpBitReset(pRtpAddr->dwAddrFlagsQ, FGADDRQ_REGQOSDISABLE);
        }
        else if ((g_RtpReg.dwQosEnable & 0x3) == 2)
        {
            TraceRetail((
                    CLASS_WARNING, GROUP_RTP, S_RTP_REG,
                    _T("%s: pRtpAddr[0x%p] QOS being forced disabled"),
                    _fname, pRtpAddr
                ));
            
            /* disable QOS */
            RtpBitSet(pRtpAddr->dwAddrFlagsQ, FGADDRQ_REGQOSDISABLE);
        }
    }

    /*
     * Cryptography
     */
    if (!pRtpAddr->pRtpCrypt[CRYPT_RECV_IDX])
    {
        /* Cryptography was not initialized */
        
        if ( IsRegValueSet(g_RtpReg.dwCryptEnable) &&
             ((g_RtpReg.dwCryptEnable & 0x3) == 0x3) )
        {
            dwCryptMode = g_RtpReg.dwCryptMode;
            
            if ((dwCryptMode & 0xffff) >= RTPCRYPTMODE_LAST)
            {
                dwCryptMode = 0;
            }
            
            RtpSetEncryptionMode(pRtpAddr,
                                 dwCryptMode & 0x0000ffff,
                                 dwCryptMode & 0xffff0000);

            if (g_RtpReg.psCryptPassPhrase)
            {
                for(i = CRYPT_RECV_IDX; i <= CRYPT_RTCP_IDX; i++)
                {
                    if (pRtpAddr->pRtpCrypt[i] &&
                        !RtpBitTest(pRtpAddr->pRtpCrypt[i]->dwCryptFlags,
                                    FGCRYPT_KEY))
                    {
                        RtpSetEncryptionKey(pRtpAddr,
                                            g_RtpReg.psCryptPassPhrase,
                                            g_RtpReg.psCryptHashAlg,
                                            g_RtpReg.psCryptDataAlg,
                                            i);
                    }
                }
            }
        }
        else
        {
            /* TODO disable cryptography under conditional compilation */
        }
    }

    /*
     * Events
     */

    /* WARNING If the events are explicitly enabled or disabled in the
     * registry, the masks will be used untested as ALL the values in
     * the DWORD mask are valid, so if they were not set in the
     * registry, its value will be assumed 0xffffffff and will be used
     * */
    
    /* Enable */
    dwFlag = 0;
    if (IsRegValueSet(g_RtpReg.dwEventsReceiver) &&
        (g_RtpReg.dwEventsReceiver & 0x3) == 0x3)
    {
        dwFlag |= RtpBitPar(RECV_IDX);
    }
    if (IsRegValueSet(g_RtpReg.dwEventsSender) &&
        (g_RtpReg.dwEventsSender & 0x3) == 0x3)
    {
        dwFlag |= RtpBitPar(SEND_IDX);
    }
    if (dwFlag)
    {
        RtpModifyBit(pRtpSess->dwEventMask, g_RtpReg.dwEventsRtp,
                     dwFlag, 1);
        RtpModifyBit(pRtpSess->dwPartEventMask, g_RtpReg.dwEventsPInfo,
                     dwFlag, 1);
        RtpModifyBit(pRtpSess->dwQosEventMask, g_RtpReg.dwEventsQos,
                     dwFlag, 1);
        RtpModifyBit(pRtpSess->dwSdesEventMask, g_RtpReg.dwEventsSdes,
                     dwFlag, 1);
    }
    /* Disable */
    dwFlag = 0;
    if (IsRegValueSet(g_RtpReg.dwEventsReceiver) &&
        (g_RtpReg.dwEventsReceiver & 0x3) == 0x2)
    {
        dwFlag |= RtpBitPar(RECV_IDX);
    }
    if (IsRegValueSet(g_RtpReg.dwEventsSender) &&
        (g_RtpReg.dwEventsSender & 0x3) == 0x2)
    {
        dwFlag |= RtpBitPar(SEND_IDX);
    }
    if (dwFlag)
    {
        RtpModifyBit(pRtpSess->dwEventMask, g_RtpReg.dwEventsRtp,
                     dwFlag, 0);
        RtpModifyBit(pRtpSess->dwPartEventMask, g_RtpReg.dwEventsPInfo,
                     dwFlag, 0);
        RtpModifyBit(pRtpSess->dwQosEventMask, g_RtpReg.dwEventsQos,
                     dwFlag, 0);
        RtpModifyBit(pRtpSess->dwSdesEventMask, g_RtpReg.dwEventsSdes,
                     dwFlag, 0);
    }

    /* Bandwidth estimation */
    if (IsRegValueSet(g_RtpReg.dwBandEstEnable))
    {
        if ((g_RtpReg.dwBandEstEnable & 0x3) == 0x3)
        {
            if (!RtpBitTest(pRtpSess->dwFeatureMask, RTPFEAT_BANDESTIMATION))
            {
                TraceRetail((
                        CLASS_WARNING, GROUP_RTP, S_RTP_REG,
                        _T("%s: pRtpAddr[0x%p] badwidth estimation ")
                        _T("being forced anabled"),
                        _fname, pRtpAddr
                    ));
            }
            
            RtpBitSet(pRtpSess->dwFeatureMask, RTPFEAT_BANDESTIMATION);
        }
        else if ((g_RtpReg.dwBandEstEnable & 0x3) == 0x2)
        {
            if (RtpBitTest(pRtpSess->dwFeatureMask, RTPFEAT_BANDESTIMATION))
            {
                TraceRetail((
                        CLASS_WARNING, GROUP_RTP, S_RTP_REG,
                        _T("%s: pRtpAddr[0x%p] badwidth estimation ")
                        _T("being forced disabled"),
                        _fname, pRtpAddr
                    ));
            }

            RtpBitReset(pRtpSess->dwFeatureMask, RTPFEAT_BANDESTIMATION);
        }
    }

    /* Network quality */
    if (IsDWValueSet(g_RtpReg.dwNetQualityEnable))
    {
        if ((g_RtpReg.dwNetQualityEnable & 0x3) == 0x2)
        {
            /* Disable */
            RtpBitSet(pRtpAddr->dwAddrRegFlags, FGADDRREG_NETQFORCED);
            RtpBitReset(pRtpAddr->dwAddrRegFlags, FGADDRREG_NETQFORCEDVALUE);
        }
        else if ((g_RtpReg.dwNetQualityEnable & 0x3) == 0x3)
        {
            /* Enable */
            RtpBitSet(pRtpAddr->dwAddrRegFlags, FGADDRREG_NETQFORCED);
            RtpBitSet(pRtpAddr->dwAddrRegFlags, FGADDRREG_NETQFORCEDVALUE);
        }
    }
}
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\net\tapi\skywalker\filters\rtp\tools\inc\common.h ===
/**********************************************************************
 *
 *  Copyright (C) Microsoft Corporation, 2001
 *
 *  File name:
 *
 *    common.h
 *
 *  Abstract:
 *
 *    This file implements some common functions used by the
 *    udpsend/udpecho/udprecv tool for sending/receiving bursts of UDP
 *    packets with specific network characteristics.
 *
 *  Author:
 *
 *    Andres Vega-Garcia (andresvg)
 *
 *  Revision:
 *
 *    2001/01/17 created
 *
 **********************************************************************/
#ifndef _common_h_
#define _common_h_

/* Packets are send in blocks separated by gaps, each block containing
   N packets also separated by an specific gap, i.e:

        block 1          block gap    block 2           block gap ...
   |--------------------|---------|--------------------|--------- ...
    -- -- -- -- -- -- --
      v
    \-|-------v--------/ \------v/
      |       |                 |
      |       Packets per block |
      |                         Inter block gap
      Inter packet gap
*/

#include <winsock2.h>
#include <stdio.h>
#include <stdlib.h>
#include <windows.h>
#include <mmsystem.h>  /* timeGetTime() */
#include <sys/timeb.h> /* void _ftime( struct _timeb *timeptr ); */
#include <ws2tcpip.h>

#define APP_VERSION      2.0

typedef struct _PcktHdr_t {
    DWORD            dwSeq;
    
    DWORD            SendNTP_sec;
    DWORD            SendNTP_frac;
    
    DWORD            EchoNTP_sec;
    DWORD            EchoNTP_frac;
} PcktHdr_t;

typedef struct _NetAddr_t {
    SOCKET           Socket;

    union {
        SOCKADDR_IN      FromInAddr;
        SOCKADDR         From;
    };

    union {
        SOCKADDR_IN      ToInAddr;
        SOCKADDR         To;
    };

    DWORD            dwRxTransfered;
    DWORD            dwTxTransfered;

    /* NETWORK ORDER */
    DWORD            dwAddr[2]; /* Local, Remote */

    /* NETWORK ORDER */
    union {
        WORD             wPort[2];  /* Local, Remote */
        DWORD            dwPorts;
    };
    
    DWORD            dwTTL;
} NetAddr_t;

#define DEFAULT_PORT         5008
#define DEFAULT_ADDR         0x0a0505e0  /* 224.5.5.10 */
#define DEFAULT_LOC_ADDR     0           /* INADDR_ANY */

#define DEFAULT_UCAST_TTL    127
#define DEFAULT_MCAST_TTL    8

#define RECV_IDX             0
#define SEND_IDX             1

#define LOCAL_IDX            0
#define REMOTE_IDX           1

#define MAX_BYE_PACKETS      4
#define BYE_PACKET_SIZE      4

#define MAX_BUFFER_SIZE  2048

/* A DWORD value is not set */
#define NO_DW_VALUESET    ((DWORD)~0)
#define IsDWValueSet(dw)  ((dw) != NO_DW_VALUESET)

/* builds a mask of bit b */
#define BitPar(b)            (1 << (b))
#define BitPar2(b1, b2)      ((1 << (b1)) | (1 << (b2)))

/* test bit b in f */
#define BitTest(f, b)        (f & (1 << (b)))
#define BitTest2(f, b1, b2)  (f & BitPar2(b1, b2))

/* set bit b in f */
#define BitSet(f, b)         (f |= (1 << (b)))
#define BitSet2(f, b1, b2)   (f |= BitPar2(b1, b2))

/* reset bit b in f */
#define BitReset(f, b)       (f &= ~(1 << (b)))
#define BitReset2(f, b1, b2) (f &= ~BitPar2(b1, b2))

#define IS_MULTICAST(addr) (((long)(addr) & 0x000000f0) == 0x000000e0)
#define IS_UNICAST(addr)   (((long)(addr) & 0x000000f0) != 0x000000e0)

void print_error(char *pFormat, ...);

char *IPNtoA(DWORD dwAddr, char *sAddr);
DWORD IPAtoN(char *sAddr);

void InitReferenceTime(void);
double GetTimeOfDay(void);

DWORD InitWinSock(void);
void DeinitWinSock(void);

DWORD InitNetwork(NetAddr_t *pNetAddr, DWORD dwDirection);
void DeinitNetwork(NetAddr_t *pNetAddr);

DWORD GetNetworkAddress(NetAddr_t *pNetAddr, char *addr);
SOCKET GetSocket(DWORD *pdwAddr, WORD *pwPort, DWORD dwRecvSend);
DWORD SetTTL(SOCKET Socket, DWORD dwTTL, BOOL bMcast);

DWORD JoinLeaf(SOCKET Socket, DWORD dwAddr, WORD wPort, DWORD dwRecvSend);
DWORD SetMcastSendIF(SOCKET Socket, DWORD dwAddr);
DWORD SetWinSockLoopback(SOCKET Socket, BOOL bEnabled);

DWORD ReceivePacket(
        NetAddr_t       *pNetAddr,
        WSABUF          *pWSABuf,
        DWORD            dwBufferCount,
        double          *pAi
    );

DWORD SendPacket(
        NetAddr_t       *pNetAddr,
        WSABUF          *pWSABuf,
        DWORD            dwBufferCount
    );

void PrintPacket(
        FILE            *output,
        PcktHdr_t       *pPcktHdr,
        DWORD            dwTransfered,
        double           Ai
    );

#endif _common_h_
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\net\tapi\skywalker\filters\rtp\tools\common\common.c ===
/**********************************************************************
 *
 *  Copyright (C) Microsoft Corporation, 2001
 *
 *  File name:
 *
 *    common.c
 *
 *  Abstract:
 *
 *    This file implements some common functions used by the
 *    udpsend/udpecho/udprecv tool for sending/receiving bursts of UDP
 *    packets with specific network characteristics.
 *
 *  Author:
 *
 *    Andres Vega-Garcia (andresvg)
 *
 *  Revision:
 *
 *    2001/01/17 created
 *
 **********************************************************************/

#include "common.h"

DWORD            g_dwRefTime;
double           g_dRefTime;

LONGLONG         g_lPerfFrequency = 0;
LONGLONG         g_lRefTime;


void print_error(char *pFormat, ...)
{
    va_list          arglist;

    va_start(arglist, pFormat);

    vfprintf(stderr, pFormat, arglist);
    
    va_end(arglist);
}

char *IPNtoA(DWORD dwAddr, char *sAddr)
{
    sprintf(sAddr, "%u.%u.%u.%u",
            (dwAddr & 0xff),
            (dwAddr >> 8) & 0xff,
            (dwAddr >> 16) & 0xff,
            (dwAddr >> 24) & 0xff);
    
    return(sAddr);
}

DWORD IPAtoN(char *sAddr)
{
    DWORD            b3, b2, b1, b0;
    DWORD            dwAddr;
    
    if (sscanf(sAddr,"%u.%u.%u.%u", &b3, &b2, &b1, &b0) != 4)
    {
        dwAddr = 0;
    }
    else
    {
        dwAddr =
            ((b0 & 0xff) << 24) | ((b1 & 0xff) << 16) |
            ((b2 & 0xff) <<  8) | (b3 & 0xff);
    }
    
    return(dwAddr);
}

void InitReferenceTime(void)
{
    struct _timeb    timeb;
    
    _ftime(&timeb);
    
    g_dRefTime = timeb.time + (double)timeb.millitm/1000.0;

    QueryPerformanceFrequency((LARGE_INTEGER *)&g_lPerfFrequency);
    
    if (g_lPerfFrequency)
    {
        QueryPerformanceCounter((LARGE_INTEGER *)&g_lRefTime);
    }
    else
    {
        g_dwRefTime = timeGetTime();
    }
}

double GetTimeOfDay(void)
{
    double           dTime;
    LONGLONG         lTime;
    
    if (g_lPerfFrequency)
    {
        QueryPerformanceCounter((LARGE_INTEGER *)&lTime);

        dTime = g_dRefTime + (double)(lTime - g_lRefTime)/g_lPerfFrequency;
    }
    else
    {
        dTime = g_dRefTime + (double)(timeGetTime() - g_dwRefTime)/1000.0;
    }

    return(dTime);
}

DWORD InitWinSock(void)
{
    DWORD            dwError;
    WSADATA          WSAData;
    WORD             VersionRequested;

    VersionRequested = MAKEWORD(2,0);

    dwError = WSAStartup(VersionRequested, &WSAData);

    if (dwError)
    {
        dwError = WSAGetLastError();
    }

    return(dwError);
}

void DeinitWinSock(void)
{
    WSACleanup();
}

DWORD InitNetwork(NetAddr_t *pNetAddr, DWORD dwDirection)
{
    DWORD            dwError;
    
    dwError = NOERROR;
    
    pNetAddr->Socket = GetSocket(pNetAddr->dwAddr,
                                 pNetAddr->wPort,
                                 dwDirection);

    if (pNetAddr->Socket != INVALID_SOCKET)
    {
        if (IS_MULTICAST(pNetAddr->dwAddr[REMOTE_IDX]))
        {
            dwError = JoinLeaf(pNetAddr->Socket,
                               pNetAddr->dwAddr[REMOTE_IDX],
                               pNetAddr->wPort[REMOTE_IDX],
                               dwDirection);
        }

        if (BitTest(dwDirection, RECV_IDX))
        {
            /* Receiver */
        }

        if (BitTest(dwDirection, SEND_IDX))
        {
            /* Sender */
            if (!pNetAddr->dwTTL)
            {
                if (IS_MULTICAST(pNetAddr->dwAddr[REMOTE_IDX]))
                {
                    pNetAddr->dwTTL = DEFAULT_MCAST_TTL;
                }
                else
                {
                    pNetAddr->dwTTL = DEFAULT_UCAST_TTL;
                }
                
                SetTTL(pNetAddr->Socket,
                       pNetAddr->dwTTL,
                       IS_MULTICAST(pNetAddr->dwAddr[REMOTE_IDX]));
            }

            /* Set destination address */
            ZeroMemory(&pNetAddr->ToInAddr, sizeof(pNetAddr->ToInAddr));
    
            pNetAddr->ToInAddr.sin_family = AF_INET;
            pNetAddr->ToInAddr.sin_addr.s_addr = pNetAddr->dwAddr[REMOTE_IDX];
            pNetAddr->ToInAddr.sin_port = pNetAddr->wPort[REMOTE_IDX];
        }
    }
    else
    {
        dwError = 1;
    }
    
    return(dwError);
}

void DeinitNetwork(NetAddr_t *pNetAddr)
{
    if (pNetAddr->Socket != INVALID_SOCKET)
    {
        closesocket(pNetAddr->Socket);
    }
}

/* Parse a network address of the form address/port/ttl */
DWORD GetNetworkAddress(NetAddr_t *pNetAddr, char *addr)
{
    char            *str;
    char            *port;
    char            *ttl;
    BOOL             bResolve;
    struct hostent  *he;

    port = ttl = NULL;
    
    /* Split address/port */
    port = strchr(addr, '/');

    if (port)
    {
        *port = 0; /* Null end the address */
        port++;    /* Point to port */

        ttl = strchr(port, '/');

        if (ttl)
        {
            *ttl = 0;
            ttl++;

            str =  strchr(ttl, '/');

            if (str)
            {
                *str = 0;
            }
        }
    }

    if (port)
    {
        pNetAddr->wPort[REMOTE_IDX] = htons((short)atoi(port));
        pNetAddr->wPort[LOCAL_IDX] = pNetAddr->wPort[REMOTE_IDX];
    }

    if (ttl)
    {
        pNetAddr->dwTTL = atoi(ttl);
    }

    bResolve = FALSE;
    
    for(str = addr; *str; str++)
    {
        if (!(isdigit((int)*str) || *str=='.'))
        {
            /* Resolve address */
            bResolve = TRUE;
            break;
        }
    }

    if (bResolve)
    {
        he = gethostbyname(addr);

        if (!he)
        {
            print_error("gethostbyname: failed for host:%s, error=%u\n",
                        addr, WSAGetLastError());
            
            goto fail;
        }

        pNetAddr->dwAddr[REMOTE_IDX] = *((DWORD *)he->h_addr_list[0]);
    }
    else
    {
        /* Address in dot form */
        pNetAddr->dwAddr[REMOTE_IDX] = IPAtoN(addr);

        if (!pNetAddr->dwAddr[REMOTE_IDX])
        {
            print_error("Invalid dot address: %s\n", addr);

            goto fail;;
        }

    }
    
    return(NOERROR);

 fail:
    pNetAddr->dwPorts = 0;
    return(1);
}

SOCKET GetSocket(DWORD *pdwAddr, WORD *pwPort, DWORD dwDirection)
{
    SOCKET           Socket;
    int              iSockFlags;
    DWORD            dwPar;
    DWORD            dwError;
    
    SOCKADDR_IN      LocalAddr;
    int              LocalAddrLen;
    char             sLocalAddr[16];
    
    iSockFlags = 0;

    if (IS_MULTICAST(pdwAddr[REMOTE_IDX]))
    {
        iSockFlags |=
            (WSA_FLAG_MULTIPOINT_C_LEAF |
             WSA_FLAG_MULTIPOINT_D_LEAF);
    }

    Socket = WSASocket(
            AF_INET,    /* int af */
            SOCK_DGRAM, /* int type */
            IPPROTO_IP, /* int protocol */
            NULL,       /* LPWSAPROTOCOL_INFO lpProtocolInfo */
            0,          /* GROUP g */
            iSockFlags  /* DWORD dwFlags */
        );
        
    if (Socket == INVALID_SOCKET)
    {
        dwError = WSAGetLastError();

        print_error("WSAGetSocket failed:%u\n", dwError);

        return(Socket);
    }

    /* Need to do this before binding, otherwise it may fail if the
     * address is already in use.
     *
     * WARNING Note that option SO_REUSEADDR is used regardless of the
     * destination address (multicast or unicast). Who receives data
     * in a unicast session is unpredicted when multiple (more than 1)
     * sockets are bound to the same address and port
     * */
            
    dwPar = 1; /* Reuse */

    /* Reuse address/port */
    dwError = setsockopt(
            Socket,
            SOL_SOCKET,
            SO_REUSEADDR,
            (PCHAR)&dwPar,
            sizeof(dwPar)
        );
        
    if (dwError == SOCKET_ERROR)
    {
        dwError = WSAGetLastError();

        print_error("setsockoption(SO_REUSEADDR) failed: %u (0x%X)\n",
                    dwError, dwError);
    }

    /* bind socket */
    ZeroMemory(&LocalAddr, sizeof(LocalAddr));

    LocalAddr.sin_family = AF_INET;
    LocalAddr.sin_addr = *(struct in_addr *) &pdwAddr[LOCAL_IDX];
    if (BitTest(dwDirection, RECV_IDX))
    {
        LocalAddr.sin_port = pwPort[LOCAL_IDX];
    }
    else
    {
        LocalAddr.sin_port = 0; 
    }
            
    /* bind rtp socket to the local address specified */
    dwError = bind(Socket, (SOCKADDR *)&LocalAddr, sizeof(LocalAddr));

    if (dwError == 0)
    {
        /* Get the port */
        LocalAddrLen = sizeof(LocalAddr);
        dwError =
            getsockname(Socket, (struct sockaddr *)&LocalAddr, &LocalAddrLen);

        if (dwError)
        {
            dwError = WSAGetLastError();
            
            print_error("getsockname failed: %u (0x%X)\n",
                        dwError, dwError);

            closesocket(Socket);

            return(INVALID_SOCKET);
        }
        else
        {
            pwPort[LOCAL_IDX] = LocalAddr.sin_port;
        }
    }
    else
    {
        dwError = WSAGetLastError();

        print_error("bind socket:%u to port:%u failed: %u (0x%X)\n",
                    Socket, ntohs(LocalAddr.sin_port), dwError, dwError);
        closesocket(Socket);

        return(INVALID_SOCKET);
    }

    if (IS_MULTICAST(pdwAddr[REMOTE_IDX]))
    {
        if (pdwAddr[LOCAL_IDX])
        {
            SetMcastSendIF(Socket, pdwAddr[LOCAL_IDX]);
        }

        /* Disable multicast loopback */
        SetWinSockLoopback(Socket, FALSE);
    }

    return(Socket);
}

DWORD SetTTL(SOCKET Socket, DWORD dwTTL, BOOL bMcast)
{
    DWORD            dwError;

    dwError = setsockopt( 
            Socket,
            IPPROTO_IP, 
            bMcast? IP_MULTICAST_TTL : IP_TTL,
            (PCHAR)&dwTTL,
            sizeof(dwTTL)
        );

    if (dwError == SOCKET_ERROR)
    {
        dwError = WSAGetLastError();
            
        print_error("Socket:%u TTL:%d failed: %u (0x%X)\n",
                    Socket, dwTTL, dwError, dwError);
    }

    return(dwError);
}

DWORD JoinLeaf(SOCKET Socket, DWORD dwAddr, WORD wPort, DWORD dwDirection)
{
    DWORD            dwError;
    DWORD            dwFlags;
    SOCKADDR_IN      JoinAddr;
    SOCKET           TmpSocket;
    char             sAddr[16];
                    
    ZeroMemory(&JoinAddr, sizeof(JoinAddr));
        
    JoinAddr.sin_family = AF_INET;
    JoinAddr.sin_addr = *(struct in_addr *) &dwAddr;
    JoinAddr.sin_port = wPort;

    dwFlags = 0;

    /* Join in one direction */

    if (BitTest(dwDirection, RECV_IDX))
    {
        dwFlags |= JL_RECEIVER_ONLY;
    }

    if (BitTest(dwDirection, SEND_IDX))
    {
        dwFlags |= JL_SENDER_ONLY;
    }

    
    TmpSocket = WSAJoinLeaf(Socket,
                            (const struct sockaddr *)&JoinAddr,
                            sizeof(JoinAddr),
                            NULL, NULL, NULL, NULL,
                            dwFlags);

    if (TmpSocket == INVALID_SOCKET)
    {
        dwError = WSAGetLastError();

        print_error("WSAJoinLeaf failed: %u:%s/%u %u (0x%X)\n",
                    Socket, IPNtoA(dwAddr, sAddr), ntohs(wPort),
                    dwError, dwError);
    }
    else
    {
        dwError = NOERROR;
    }

    return(dwError);
}

DWORD SetMcastSendIF(SOCKET Socket, DWORD dwAddr)
{
    DWORD            dwError;
    char             sAddr[16];

    dwError = setsockopt( 
            Socket,
            IPPROTO_IP, 
            IP_MULTICAST_IF,
            (char *)&dwAddr,
            sizeof(dwAddr)
        );

    if (dwError == SOCKET_ERROR)
    {
        dwError = WSAGetLastError();
            
        print_error("Socket:%u IP_MULTICAST_IF(%s) failed: %u (0x%X)\n",
                    Socket, IPNtoA(dwAddr, sAddr), dwError, dwError);
    }
    
    return(dwError);
}

DWORD SetWinSockLoopback(SOCKET Socket, BOOL bEnabled)
{
    DWORD            dwStatus;
    DWORD            dwPar;

    dwPar = bEnabled? 1:0;
    
    /* Allow own packets to come back or not */
    dwStatus = setsockopt(
            Socket,
            IPPROTO_IP,
            IP_MULTICAST_LOOP,
            (PCHAR)&dwPar,
            sizeof(dwPar)
        );
        
    if (dwStatus == SOCKET_ERROR)
    {
        dwStatus = WSAGetLastError();
        
        print_error("Socket:%u Loopback:%d failed: %u (0x%X)",
                    Socket, dwPar, dwStatus, dwStatus);
    }
    else
    {
        dwStatus = NOERROR;
    }
    
    return(dwStatus);
}

DWORD ReceivePacket(
        NetAddr_t       *pNetAddr,
        WSABUF          *pWSABuf,
        DWORD            dwBufferCount,
        double          *pAi
    )
{
    DWORD            dwStatus;
    DWORD            dwFlags;
    DWORD            dwFromLen;

    dwFlags = 0;
    
    dwFromLen = sizeof(pNetAddr->From);
    
    pNetAddr->dwRxTransfered = 0;
    
    dwStatus = WSARecvFrom(
            pNetAddr->Socket,       /* SOCKET s */
            pWSABuf,                /* LPWSABUF lpBuffers */
            dwBufferCount,          /* DWORD dwBufferCount */
            &pNetAddr->dwRxTransfered,/* LPDWORD lpNumberOfBytesRecvd */
            &dwFlags,               /* LPDWORD lpFlags */
            &pNetAddr->From,        /* struct sockaddr FAR *lpFrom */
            &dwFromLen,             /* LPINT lpFromlen */
            NULL,                   /* LPWSAOVERLAPPED lpOverlapped */
            NULL                    /* LPWSAOVERLAPPED_COMPLETION_ROUTINE */
        );

    if (pAi)
    {
        *pAi = GetTimeOfDay();
    }
    
    if (dwStatus)
    {
        dwStatus = WSAGetLastError();
        
        if (dwStatus != WSAECONNRESET)
        {
            print_error("WSARecvFrom failed: %u (0x%X)\n", dwStatus, dwStatus);
        }
        
        pNetAddr->dwRxTransfered = 0;
    }
    
    
    return(pNetAddr->dwRxTransfered);
}

DWORD SendPacket(
        NetAddr_t       *pNetAddr,
        WSABUF          *pWSABuf,
        DWORD            dwBufferCount
    )
{
    DWORD            dwStatus;
    DWORD            dwBytesTransfered;

    dwBytesTransfered = 0;
    
    dwStatus = WSASendTo(
            pNetAddr->Socket,    /* SOCKET    s */
            pWSABuf,             /* LPWSABUF  lpBuffers */
            dwBufferCount,       /* DWORD dwBufferCount */    
            &pNetAddr->dwTxTransfered,/* LPDWORD lpNumberOfBytesSent */    
            0,                   /* DWORD dwFlags*/    
            &pNetAddr->To,       /* const struct sockaddr *lpTo */
            sizeof(pNetAddr->To),/* int iToLen*/
            NULL,                /* LPWSAOVERLAPPED lpOverlapped */
            NULL /* LPWSAOVERLAPPED_COMPLETION_ROUTINE lpCompletionROUTINE */
        );

    if (dwStatus)
    {
        dwStatus = WSAGetLastError();
        
        print_error("WSASendTo failed: %u (0x%X)\n", dwStatus, dwStatus);

        pNetAddr->dwTxTransfered = 0;
    }

    return(pNetAddr->dwTxTransfered);
}

void PrintPacket(
        FILE            *output,
        PcktHdr_t       *pPcktHdr,
        DWORD            dwTransfered,
        double           Ai
    )
{
    NetAddr_t       *pNetAddr;
    double           SendTime;
    double           EchoTime;

    if (dwTransfered >= sizeof(PcktHdr_t))
    {
        SendTime = (double)ntohl(pPcktHdr->SendNTP_sec);
        SendTime += ((double)ntohl(pPcktHdr->SendNTP_frac) / 4294967296.0);

        EchoTime = (double)ntohl(pPcktHdr->EchoNTP_sec);
        EchoTime += ((double)ntohl(pPcktHdr->EchoNTP_frac) / 4294967296.0);
        
        fprintf(output,
                "%u %0.6f %0.6f %0.6f %u\n",
                ntohl(pPcktHdr->dwSeq),
                SendTime,
                EchoTime,
                Ai,
                dwTransfered);
    }
}
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\net\tapi\skywalker\filters\rtp\msrtp\rtp\rtpthrd.c ===
/**********************************************************************
 *
 *  Copyright (C) Microsoft Corporation, 1999
 *
 *  File name:
 *
 *    rtpthrd.c
 *
 *  Abstract:
 *
 *    Implement the RTP reception working thread
 *
 *  Author:
 *
 *    Andres Vega-Garcia (andresvg)
 *
 *  Revision:
 *
 *    1999/06/30 created
 *
 **********************************************************************/

#include "rtprecv.h"
#include "rtpchan.h"
#include "rtpaddr.h"

#include "rtpthrd.h"

long g_lCountRtpRecvThread = 0; /* Current number */
long g_lNumRtpRecvThread = 0;   /* Cumulative number */

/* RTP reception worker thread */
DWORD WINAPI RtpWorkerThreadProc(LPVOID lpParameter)
{
    DWORD            dwError;
    BOOL             bAlertable;
    DWORD            dwCommand;
    DWORD            dwStatus;
    DWORD            dwWaitTime;
    HANDLE           hThread;
    DWORD            dwThreadID;
    RtpAddr_t       *pRtpAddr;
    RtpChannelCmd_t *pRtpChannelCmd;
    /* 0:I/O; 1:Channel */
    HANDLE           pHandle[2];
    
    TraceFunctionName("RtpWorkerThreadProc");

    InterlockedIncrement(&g_lCountRtpRecvThread);
    InterlockedIncrement(&g_lNumRtpRecvThread);
    
    /* initialize */
    pRtpAddr = (RtpAddr_t *)lpParameter;

    hThread = (HANDLE)NULL;
    dwThreadID = 0;

    if (!pRtpAddr)
    {
        dwError = RTPERR_POINTER;
        goto exit;
    }

    if (pRtpAddr->dwObjectID != OBJECTID_RTPADDR)
    {
        dwError = RTPERR_INVALIDRTPADDR;
        goto exit;
    }

    dwError = NOERROR;
    
    hThread = pRtpAddr->hRtpRecvThread;
    dwThreadID = pRtpAddr->dwRtpRecvThreadID;
    
    dwCommand = RTPTHRD_FIRST;

    /* Listen to commands send trough the channel */
    pHandle[0] = RtpChannelGetWaitEvent(&pRtpAddr->RtpRecvThreadChan);

    /* I/O completion */
    pHandle[1] = pRtpAddr->hRecvCompletedEvent;
    
    bAlertable = FALSE;

    dwWaitTime = INFINITE;

    TraceRetail((
            CLASS_INFO, GROUP_RTP, S_RTP_THREAD,
            _T("%s: pRtpAddr[0x%p] thread:%u (0x%X) ID:%u (0x%X) has started"),
            _fname, pRtpAddr,
            hThread, hThread,
            dwThreadID, dwThreadID
        ));

    /* Set the receive buffer size to a certain value */
    RtpSetRecvBuffSize(pRtpAddr, pRtpAddr->Socket[SOCK_RECV_IDX], 1024*8);
    
    while(dwCommand != RTPTHRD_STOP)
    {
        dwStatus = WaitForMultipleObjectsEx(
                2,        /* DWORD nCount */
                pHandle,  /* CONST HANDLE *lpHandles */
                FALSE,    /* BOOL fWaitAll */
                dwWaitTime,/* DWORD dwMilliseconds */
                bAlertable/* BOOL bAlertable */
            );

        if (dwStatus == WAIT_IO_COMPLETION)
        {
            /* Do nothing */
        }
        else if (dwStatus == WAIT_OBJECT_0)
        {
            /* Received commannd from channel */
            do
            {
                pRtpChannelCmd =
                    RtpChannelGetCmd(&pRtpAddr->RtpRecvThreadChan);

                if (pRtpChannelCmd)
                {
                    dwCommand = pRtpChannelCmd->dwCommand;
                    
                    if (dwCommand == RTPTHRD_START)
                    {
                        bAlertable = TRUE;
                    }
                    else if (dwCommand == RTPTHRD_STOP)
                    {
                        /* Pending I/O will never complete, move them
                         * back to FreeQ */
                        FlushRtpRecvFrom(pRtpAddr);
                    }
                    else if (dwCommand == RTPTHRD_FLUSHUSER)
                    {
                        /* This used is being deleted, I need to
                         * remove all his pending IO in RecvIOWaitRedQ */
                        FlushRtpRecvUser(pRtpAddr,
                                         (RtpUser_t *)pRtpChannelCmd->dwPar1);
                    }
                    
                    RtpChannelAck(&pRtpAddr->RtpRecvThreadChan,
                                  pRtpChannelCmd,
                                  NOERROR);
                }
            } while(pRtpChannelCmd);
        }
        else if (dwStatus == (WAIT_OBJECT_0 + 1))
        {
            /* Completion event signaled */
            ConsumeRtpRecvFrom(pRtpAddr);
        }
        else if (dwStatus == WAIT_TIMEOUT)
        {
            /* Do nothing */;
        }
        else
        {
            TraceRetail((
                    CLASS_ERROR, GROUP_RTP, S_RTP_THREAD,
                    _T("%s: pRtpAddr[0x%p] ThreadID: %u (0x%X) ")
                    _T("Unexpected status: %u (0x%X)"),
                    _fname, pRtpAddr, dwThreadID, dwThreadID,
                    dwStatus, dwStatus
                ));
        }

        if (dwCommand != RTPTHRD_STOP)
        {
            dwWaitTime = RtpCheckReadyToPostOnTimeout(pRtpAddr);

            /* Re-start more async reception */
            StartRtpRecvFrom(pRtpAddr);
        }
    }

 exit:
    /* Reset the receive buffer size to 0 */
    RtpSetRecvBuffSize(pRtpAddr, pRtpAddr->Socket[SOCK_RECV_IDX], 0);

    TraceRetail((
            CLASS_INFO, GROUP_RTP, S_RTP_THREAD,
            _T("%s: pRtpAddr[0x%p] thread:%u (0x%X) ID:%u (0x%X) ")
            _T("exit with code: %u (0x%X)"),
            _fname, pRtpAddr,
            hThread, hThread,
            dwThreadID, dwThreadID,
            dwError, dwError
        ));

    InterlockedDecrement(&g_lCountRtpRecvThread);

    return(dwError);
}

/* Create a RTP reception thread, and initialize the communication
 * channel */
HRESULT RtpCreateRecvThread(RtpAddr_t *pRtpAddr)
{
    HRESULT          hr;
    DWORD            dwError;

    TraceFunctionName("RtpCreateRecvThread");

    TraceDebug((
            CLASS_INFO, GROUP_RTP, S_RTP_THREAD,
            _T("%s"),
            _fname
        ));
    
    /* First make sure we don't have anything left */
    if (pRtpAddr->hRtpRecvThread)
    {
        hr = RTPERR_INVALIDSTATE;

        TraceRetail((
                CLASS_ERROR, GROUP_RTP, S_RTP_THREAD,
                _T("%s: thread is already initialized: %s (0x%X)"),
                _fname, RTPERR_TEXT(hr), hr
            ));
        
        goto bail;
    }

    if (IsRtpChannelInitialized(&pRtpAddr->RtpRecvThreadChan))
    {
        hr = RTPERR_INVALIDSTATE;

        TraceRetail((
                CLASS_ERROR, GROUP_RTP, S_RTP_THREAD,
                _T("%s: channel is already initialized: %s (0x%X)"),
                _fname, RTPERR_TEXT(hr), hr
            ));
        
        goto bail;
    }
   
    /* Initialize channel */
    hr = RtpChannelInit(&pRtpAddr->RtpRecvThreadChan, pRtpAddr);

    if (FAILED(hr))
    {
        TraceRetail((
                CLASS_ERROR, GROUP_RTP, S_RTP_THREAD,
                _T("%s: Channel initialization failed: %s (0x%X)"),
                _fname, RTPERR_TEXT(hr), hr
            ));

        goto bail;
    }
    
    /* Create thread */
    pRtpAddr->hRtpRecvThread = CreateThread(
            NULL,                 /* LPSECURITY_ATTRIBUTES lpThrdAttrib */
            0,                    /* DWORD dwStackSize */
            RtpWorkerThreadProc,  /* LPTHREAD_START_ROUTINE lpStartProc */
            (void *)pRtpAddr,     /* LPVOID  lpParameter */
            0,                    /* DWORD dwCreationFlags */
            &pRtpAddr->dwRtpRecvThreadID /* LPDWORD lpThreadId */
        );

    if (!pRtpAddr->hRtpRecvThread)
    {
        TraceRetailGetError(dwError);
        
        TraceRetail((
                CLASS_ERROR, GROUP_RTP, S_RTP_THREAD,
                _T("%s: failed to create thread: %u (0x%X)"),
                _fname, dwError, dwError
            ));

        hr = RTPERR_THREAD;
        
        goto bail;
    }

    /* For class audio RTP threads, raise priority */
    if (RtpGetClass(pRtpAddr->dwIRtpFlags) == RTPCLASS_AUDIO)
    {
        SetThreadPriority(pRtpAddr->hRtpRecvThread,
                          THREAD_PRIORITY_TIME_CRITICAL);
    }
    
    /* Direct thread to start, synchronize ack */
    hr = RtpChannelSend(&pRtpAddr->RtpRecvThreadChan,
                        RTPTHRD_START,
                        0,
                        0,
                        60*60*1000); /* TODO update */

    if (FAILED(hr))
    {
        TraceRetail((
                CLASS_ERROR, GROUP_RTP, S_RTP_THREAD,
                _T("%s: start command ")
                _T("sent to thread failed: %u (0x%X)"),
                _fname, hr, hr
            ));

        goto bail;
    }
    
    return(hr);
 bail:
    
    RtpDeleteRecvThread(pRtpAddr);

    return(hr);
}

/* Shut down a RTP reception thread and deletes the communication
 * channel */
HRESULT RtpDeleteRecvThread(RtpAddr_t *pRtpAddr)
{
    HRESULT          hr;

    TraceFunctionName("RtpDeleteRecvThread");

    hr = RTPERR_NOERROR;

    TraceDebug((
            CLASS_INFO, GROUP_RTP, S_RTP_THREAD,
            _T("%s"),
            _fname
        ));
    
    /* Shut down thread */
    if (pRtpAddr->hRtpRecvThread)
    {
        if (IsRtpChannelInitialized(&pRtpAddr->RtpRecvThreadChan))
        {
            /* Direct thread to stop, synchronize ack */
            hr = RtpChannelSend(&pRtpAddr->RtpRecvThreadChan,
                                RTPTHRD_STOP,
                                0,
                                0,
                                60*60*1000); /* TODO update */

        }
        else
        {
            /* If no channel, force ungraceful termination */
            hr = RTPERR_CHANNEL;
        }

        if (SUCCEEDED(hr))
        {
            /* TODO I may modify to loop until object is
             * signaled or get a timeout */
            WaitForSingleObject(pRtpAddr->hRtpRecvThread, INFINITE);
        } else {
            
            /* Do ungraceful thread termination */
            
            TraceRetail((
                    CLASS_ERROR, GROUP_RTP, S_RTP_THREAD,
                    _T("%s: Unable to send ")
                    _T("command to thread: ")
                    _T(" %u (0x%X)"),
                    _fname, hr, hr
                ));

            TerminateThread(pRtpAddr->hRtpRecvThread, -1);
        }

        CloseHandle(pRtpAddr->hRtpRecvThread);
        
        pRtpAddr->hRtpRecvThread = NULL;
    }

    /* Delete channel */
    if (IsRtpChannelInitialized(&pRtpAddr->RtpRecvThreadChan))
    {
        RtpChannelDelete(&pRtpAddr->RtpRecvThreadChan);
    }

    return(hr);
}

/* Send a command to the RTP thread to flush all the waiting IOs
 * belonging to the specified RtpUser_t */
HRESULT RtpThreadFlushUser(RtpAddr_t *pRtpAddr, RtpUser_t *pRtpUser)
{
    HRESULT          hr;
    
    hr = RtpChannelSend(&pRtpAddr->RtpRecvThreadChan,
                        RTPTHRD_FLUSHUSER,
                        (DWORD_PTR)pRtpUser,
                        0,
                        60*60*1000); /* TODO update */

    return(hr);
}
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\net\tapi\skywalker\filters\rtp\tools\inc\udprecv.h ===
/**********************************************************************
 *
 *  Copyright (C) Microsoft Corporation, 2001
 *
 *  File name:
 *
 *    udprecv.h
 *
 *  Abstract:
 *
 *    udprecv structures
 *
 *  Author:
 *
 *    Andres Vega-Garcia (andresvg)
 *
 *  Revision:
 *
 *    2001/01/18 created
 *
 **********************************************************************/
#ifndef _udprecv_h_
#define _udprecv_h_

enum {
    OP_FIRST,

    OP_DISCARD,    /* Discard received data, i.e. don't print it */
    
    OP_LAST
};

typedef struct _RecvStream_t {
    DWORD            dwBytesRecv;
    DWORD            dwPacketsRecv;

    DWORD            dwOptions;
    
    FILE            *output;
    char             FileName[128];
    NetAddr_t        NetAddr;

    double           Ai;
    WSABUF           WSABuf;
    char             buffer[MAX_BUFFER_SIZE];
   
} RecvStream_t;

#endif
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\net\tapi\skywalker\filters\rtp\tools\udprecv\udprecv.c ===
/**********************************************************************
 *
 *  Copyright (C) Microsoft Corporation, 2001
 *
 *  File name:
 *
 *    udpsend.c
 *
 *  Abstract:
 *
 *    This file implements a tool for receiving UDP packets with
 *    specific network characteristics.
 *
 *  Author:
 *
 *    Andres Vega-Garcia (andresvg)
 *
 *  Revision:
 *
 *    2001/01/18 created
 *
 **********************************************************************/

#include "common.h"
#include "udprecv.h"

void print_help(char *prog)
{
    char             sLocal[16];
    char             sAddr[16];
    
    fprintf(stderr,
            "Windows Real-Time Communications %s v%2.1f\n"
            "receive packets in unicast or from a multicast address\n"
            "usage: %s [<options>] [address[/port]]\n"
            "options are:\n"
            "    -h, -?           : this help\n"
            "    -i addr          : select local interface [%s]\n"
            "    -o file          : send output to file [stdout]\n"
            "                     : if file equal null, don't output\n"
            "    address/port     : address/port [%s/%u]\n",
            prog, APP_VERSION, prog,
            IPNtoA(DEFAULT_LOC_ADDR, sLocal),
            IPNtoA(DEFAULT_ADDR, sAddr),
            DEFAULT_PORT
        );
}

void InitPacketStream(RecvStream_t *pRecvStream)
{
    NetAddr_t       *pNetAddr;
    
    ZeroMemory(pRecvStream, sizeof(*pRecvStream));

    pNetAddr = &pRecvStream->NetAddr;

    pRecvStream->output = stdout;
    
    pNetAddr->wPort[LOCAL_IDX] = htons(DEFAULT_PORT);
    pNetAddr->wPort[REMOTE_IDX] = htons(DEFAULT_PORT);
    pNetAddr->dwAddr[REMOTE_IDX] = DEFAULT_ADDR;
}

DWORD UdpReceivePacket(RecvStream_t *pRecvStream)
{
    DWORD            dwStatus;
    DWORD            dwError;
    DWORD            dwFlags;
    DWORD            dwFromLen;
    NetAddr_t       *pNetAddr;

    pNetAddr = &pRecvStream->NetAddr;

    dwFlags = 0;

    pRecvStream->WSABuf.buf = pRecvStream->buffer;

    pRecvStream->WSABuf.len = MAX_BUFFER_SIZE;

    dwFromLen = sizeof(pNetAddr->From);

    ReceivePacket(pNetAddr,
                  &pRecvStream->WSABuf,
                  1,
                  &pRecvStream->Ai);
    
    return(pNetAddr->dwRxTransfered);
}

void UdpPrintPacket(RecvStream_t *pRecvStream)
{
    NetAddr_t       *pNetAddr;
    PcktHdr_t       *pPcktHdr;

    pNetAddr = &pRecvStream->NetAddr;
    
    PrintPacket(pRecvStream->output,
                (PcktHdr_t *)pRecvStream->buffer,
                pNetAddr->dwRxTransfered,
                pRecvStream->Ai);
    
    pRecvStream->dwBytesRecv += pNetAddr->dwRxTransfered;
    pRecvStream->dwPacketsRecv++;
}

DWORD ProcessParameters(RecvStream_t *pRecvStream, int argc, char **argv)
{
    int              p;
    DWORD            dwError;
    NetAddr_t       *pNetAddr;

    dwError = NOERROR;
    pNetAddr = &pRecvStream->NetAddr;

    for(p = 1; p < argc && dwError == NOERROR; p++)
    {
        if (*argv[p] == '-' || *argv[p] == '/')
        {
            switch(argv[p][1])
            {
            case 'h':
            case 'H':
            case '?':
                print_help(argv[0]);
                dwError = 1;
                break;
            case 'i':
                p++;
                pNetAddr->dwAddr[LOCAL_IDX] = IPAtoN(argv[p]);
                break;
            case 'o':
                p++;
                strcpy(pRecvStream->FileName, argv[p]);
                if (!_stricmp(pRecvStream->FileName, "null"))
                {
                    BitSet(pRecvStream->dwOptions, OP_DISCARD);
                }
                break;
            default:
                print_error("unknown option:>>> %s <<<\n", argv[p]);
                dwError = 1;
            }
        }
        else
        {
            /* Must be a and address/port */
            dwError = GetNetworkAddress(pNetAddr, argv[p]);
        }
    }

    return(dwError);
}

void __cdecl main(int argc, char **argv)
{
    DWORD            dwError;
    DWORD            dwSize;
    RecvStream_t     RecvStream;
    
    /* Initialize stream's structure */
    InitPacketStream(&RecvStream);

    InitReferenceTime();
    
    /* initialize winsock */
    dwError = InitWinSock();

    if (dwError)
    {
        print_error("WSAStartup failed to initialize:%u\n", dwError);

        return;
    }
    
    /* Read parameters */
    if (argc > 1)
    {
        dwError = ProcessParameters(&RecvStream, argc, argv);

        if (dwError != NOERROR)
        {
            goto end;
        }
    }

    /* Init Network */
    dwError = InitNetwork(&RecvStream.NetAddr, BitPar(RECV_IDX));

    if (dwError != NOERROR)
    {
        goto end;
    }

    /* Open output file if needed */
    if (strlen(RecvStream.FileName) > 0 &&
        !BitTest(RecvStream.dwOptions, OP_DISCARD))
    {
        RecvStream.output = fopen(RecvStream.FileName, "w");

        if (!RecvStream.output)
        {
            print_error("fopen failed to create file: %s\n",
                        RecvStream.FileName);

            dwError = 1;
            
            goto end;
        }
    }
    
    /* Receive packets */
    do {
        dwSize = UdpReceivePacket(&RecvStream);

        if (!BitTest(RecvStream.dwOptions, OP_DISCARD))
        {
            UdpPrintPacket(&RecvStream);
        }
    } while (dwSize > BYE_PACKET_SIZE);

    /* Close output file if needed */
    if (RecvStream.output && RecvStream.output != stdout)
    {
        fclose(RecvStream.output);
    }
    
 end:
    DeinitNetwork(&RecvStream.NetAddr);

    DeinitWinSock();
}
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\net\tapi\skywalker\filters\rtp\tools\inc\udpsend.h ===
/**********************************************************************
 *
 *  Copyright (C) Microsoft Corporation, 2001
 *
 *  File name:
 *
 *    udpsend.h
 *
 *  Abstract:
 *
 *    udpsend structures
 *
 *  Author:
 *
 *    Andres Vega-Garcia (andresvg)
 *
 *  Revision:
 *
 *    2001/01/18 created
 *
 **********************************************************************/
#ifndef _udpsend_h_
#define _udpsend_h_

typedef struct _SendStream_t {
    DWORD            dwBlocks;
    DWORD            dwPackets;
    DWORD            dwBlockGap;   /* millisecs */
    DWORD            dwPacketGap;  /* millisecs */
    DWORD            dwBlockCount;
    DWORD            dwPacketCount;
    DWORD            dwPacketSize;

    DWORD            dwAdvanceTimeout;
    
    DWORD            dwBytesSent;
    DWORD            dwPacketsSent;
    
    DWORD            dwOptions;
    double           dNextPacket;

    NetAddr_t        NetAddr;

    /* Used to receive */
    struct timeval   timeval;
    fd_set           fdReceivers;

    FILE            *output;
    char             FileName[128];

    WSABUF           WSABuf;
    char             buffer[MAX_BUFFER_SIZE];
} SendStream_t;

enum {
    OP_FIRST,

    OP_RANDOMDATA,

    OP_SENDANDRECEIVE,
    
    OP_DISCARD,    /* Discard received data, i.e. don't print it */

    OP_LAST
};

#define DEFAULT_BLOCKS       1
#define DEFAULT_PACKETS      (1000*10/30) /* 10 secs of 30ms packets */
#define DEFAULT_BLOCKGAP     (3*1000)
#define DEFAULT_PACKETGAP    30
#define DEFAULT_PACKETSIZE   (240+12)

/* Do not sleep but do an active wait if target time is this close */
#define DEFAULT_TIMEOUT      5  /* millisecs */

#endif
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\net\tapi\skywalker\filters\utils\tpdbg.c ===
/**********************************************************************
 *
 *  Copyright (C) Microsoft Corporation, 1999
 *
 *  File name:
 *
 *    tpdbg.c
 *
 *  Abstract:
 *
 *    Some debuging support for TAPI filters
 *
 *  Author:
 *
 *    Andres Vega-Garcia (andresvg)
 *
 *  Revision:
 *
 *    2000/08/31 created
 *
 **********************************************************************/

#include <windows.h>
#include <tpdbg.h>

AudCritSect_t     g_AudCritSect;
Queue_t           g_AudObjectsQ;
const TCHAR      *g_psAudIds[] = {
    TEXT("unknown"),
    
    TEXT("AUDENCHANDLER"),
    TEXT("AUDCAPINPIN"),
    TEXT("AUDCAPOUTPIN"),
    TEXT("AUDCAPFILTER"),
    TEXT("AUDDECINPIN"),
    TEXT("AUDDECOUTPIN"),
    TEXT("AUDDECFILTER"),
    TEXT("AUDENCINPIN"),
    TEXT("AUDENCOUTPIN"),
    TEXT("AUDENCFILTER"),
    TEXT("AUDMIXINPIN"),
    TEXT("AUDMIXOUTPIN"),
    TEXT("AUDMIXFILTER"),
    TEXT("AUDRENINPIN"),
    TEXT("AUDRENFILTER"),
    NULL
};

QueueItem_t *AudEnqueue(
        Queue_t         *pHead,
        CRITICAL_SECTION *pCritSect,
        QueueItem_t     *pItem
    );

QueueItem_t *AudDequeue(
        Queue_t         *pHead,
        CRITICAL_SECTION *pCritSect,
        QueueItem_t     *pItem
    );

void AudInit()
{
    DWORD            SpinCount;

    ZeroMemory(&g_AudObjectsQ, sizeof(g_AudObjectsQ));
    
    g_AudCritSect.bInitOk = FALSE;
    
    /* Set bit 31 to 1 to preallocate the event object, and set
     * the spin count that is used in multiprocessor environments
     * */
    SpinCount = 0x80000000 | 1000;
    
    if (InitializeCriticalSectionAndSpinCount(&g_AudCritSect.CritSect,
                                              SpinCount))
    {
        g_AudCritSect.bInitOk = TRUE;
    }
}

void AudDeinit()
{
    if (g_AudCritSect.bInitOk)
    {
        DeleteCriticalSection(&g_AudCritSect.CritSect);

        g_AudCritSect.bInitOk = FALSE;
    }
}

void AudObjEnqueue(QueueItem_t *pQueueItem, DWORD dwObjectID)
{
    if (g_AudCritSect.bInitOk)
    {
        AudEnqueue(&g_AudObjectsQ, &g_AudCritSect.CritSect, pQueueItem);

        pQueueItem->dwKey =  dwObjectID;
    }
}

void AudObjDequeue(QueueItem_t *pQueueItem)
{
    if (g_AudCritSect.bInitOk)
    {
        AudDequeue(&g_AudObjectsQ, &g_AudCritSect.CritSect, pQueueItem);
    }
}

/* enqueue at the end */
QueueItem_t *AudEnqueue(
        Queue_t         *pHead,
        CRITICAL_SECTION  *pCritSect,
        QueueItem_t     *pItem
    )
{
    BOOL             bOk;
    DWORD            dwError;
    QueueItem_t     *pQueueItem;
    Queue_t         *pItempHead;

    pQueueItem = (QueueItem_t *)NULL;
    
    EnterCriticalSection(pCritSect);
    
    if (pItem->pHead)
    {
        goto error;
    }
    
    if (pHead->pFirst)
    {
        /* not empty */
        pItem->pNext = pHead->pFirst;
        pItem->pPrev = pHead->pFirst->pPrev;
        pItem->pPrev->pNext = pItem;
        pItem->pNext->pPrev = pItem;
        pHead->lCount++;
    }
    else
    {
        /* empty */
        pHead->lCount = 1;
        pHead->pFirst = pItem;
        pItem->pNext  = pItem;
        pItem->pPrev  = pItem;
    }

    pItem->pHead = pHead;
    
    LeaveCriticalSection(pCritSect);

    pQueueItem = pItem;
    
    return(pQueueItem);

 error:
    LeaveCriticalSection(pCritSect);

    return(pQueueItem);
}

/* dequeue item pItem */
QueueItem_t *AudDequeue(
        Queue_t         *pHead,
        CRITICAL_SECTION *pCritSect,
        QueueItem_t     *pItem
    )
{
    BOOL             bOk;
    DWORD            dwError;
    QueueItem_t     *pQueueItem;
    Queue_t         *pItempHead;

    pQueueItem = (QueueItem_t *)NULL;
    
    EnterCriticalSection(pCritSect);
    
    if (pItem->pHead != pHead)
    {
        goto error;
    }

    if (pHead->lCount > 1)
    {
        /* 2 or more items */
        if (pHead->pFirst == pItem)
        {
            pHead->pFirst = pItem->pNext;
        }
        pItem->pPrev->pNext = pItem->pNext;
        pItem->pNext->pPrev = pItem->pPrev;
        pHead->lCount--;
    }
    else
    {
        /* just 1 item */
        pHead->pFirst = (QueueItem_t *)NULL;
        pHead->lCount = 0;
    }

    LeaveCriticalSection(pCritSect);
    
    pItem->pNext = (QueueItem_t *)NULL;
    pItem->pPrev = (QueueItem_t *)NULL;
    pItem->pHead = NULL;

    pQueueItem = pItem;
    
    return(pQueueItem);

 error:
    LeaveCriticalSection(pCritSect);

    return(pQueueItem);
}
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\net\tapi\skywalker\filters\rtp\tools\udpsend\udpsend.c ===
/**********************************************************************
 *
 *  Copyright (C) Microsoft Corporation, 2001
 *
 *  File name:
 *
 *    udpsend.c
 *
 *  Abstract:
 *
 *    This file implements a tool for sending UDP packets with
 *    specific network characteristics.
 *
 *  Author:
 *
 *    Andres Vega-Garcia (andresvg)
 *
 *  Revision:
 *
 *    2001/01/16 created
 *
 **********************************************************************/

#include "common.h"
#include "udpsend.h"

/* Packets are send in blocks separated by gaps, each block containing
   N packets also separated by an specific gap, i.e:

        block 1          block gap    block 2           block gap ...
   |--------------------|---------|--------------------|--------- ...
    -- -- -- -- -- -- --
      v
    \-|-------v--------/ \------v/
      |       |                 |
      |  Packets per block      |
      |                         Inter block gap
      Inter packet gap
*/

/*
  TODO list

  1. Add support for QOS in unicast/multicast
  
*/

void print_help(char *prog)
{
    char             sLocal[16];
    char             sAddr[16];

    fprintf(stderr,
            "Windows Real-Time Communications %s v%2.1f\n"
            "send packets to a unicast or multicast address\n"
            "usage: %s [<options>] [address[/port[/ttl]]]\n"
            "options are:\n"
            "    -h, -?           : this help\n"
            "    -p packets       : number of packets [%u]\n"
            "    -b blocks        : number of blocks [%u]\n"
            "    -g gap           : inter packet gap (ms) [%u]\n"
            "    -G gap           : inter block gap (ms) [%u]\n"
            "    -s size          : packet size (bytes) [%u]\n"
            "    -i addr          : select local interface [%s]\n"
            "    -t timeout       : time to do active wait (ms) [%u]\n"
            "    -o file          : send output to file (implies -R) [stdout]\n"
            "    -R               : send and receive (used with udpecho)\n"
            "    -dr              : fill with random data (minimize compression)\n"
            "    address/port/ttl : address/port [%s/%u/u:%u|m:%u]\n",
            prog, APP_VERSION, prog,
            DEFAULT_PACKETS,
            DEFAULT_BLOCKS,
            DEFAULT_PACKETGAP,
            DEFAULT_BLOCKGAP,
            DEFAULT_PACKETSIZE,
            IPNtoA(DEFAULT_LOC_ADDR, sLocal),
            DEFAULT_TIMEOUT,
            IPNtoA(DEFAULT_ADDR, sAddr),
            DEFAULT_PORT,
            DEFAULT_UCAST_TTL, DEFAULT_MCAST_TTL
        );
}

void InitPacketStream(SendStream_t *pSendStream)
{
    NetAddr_t       *pNetAddr;
    
    ZeroMemory(pSendStream, sizeof(*pSendStream));

    pSendStream->output = stdout;

    /* Prepare for asynchronous IO */
    FD_ZERO(&pSendStream->fdReceivers);
   
    pNetAddr = &pSendStream->NetAddr;
    
    pSendStream->dwBlocks = DEFAULT_BLOCKS;
    pSendStream->dwPackets = DEFAULT_PACKETS;
    pSendStream->dwBlockGap = DEFAULT_BLOCKGAP;
    pSendStream->dwPacketGap= DEFAULT_PACKETGAP;
    pSendStream->dwPacketSize = DEFAULT_PACKETSIZE;
    pSendStream->dwAdvanceTimeout = DEFAULT_TIMEOUT;
    
    pNetAddr->Socket = INVALID_SOCKET;
    pNetAddr->wPort[REMOTE_IDX] = htons(DEFAULT_PORT);
    pNetAddr->wPort[LOCAL_IDX] = htons(DEFAULT_PORT);
    pNetAddr->dwAddr[REMOTE_IDX] = DEFAULT_ADDR;
}

void FillBuffer(SendStream_t *pSendStream)
{
    double           dTime;
    DWORD            dwSecs;
    PcktHdr_t       *pHdr;
    DWORD            i;

    dTime = GetTimeOfDay();

    pHdr = (PcktHdr_t *)pSendStream->buffer;
    ZeroMemory(pHdr, sizeof(PcktHdr_t));
    
    pHdr->dwSeq = htonl(pSendStream->dwPacketsSent);

    pHdr->SendNTP_sec = (DWORD) dTime;

    pHdr->SendNTP_frac = (DWORD)
        ( (dTime - (double) pHdr->SendNTP_sec) * 4294967296.0 );

    pHdr->SendNTP_sec = htonl(pHdr->SendNTP_sec);

    pHdr->SendNTP_frac = htonl(pHdr->SendNTP_frac);

    /* Optionally may fill remaining buffer with something */
    if (BitTest(pSendStream->dwOptions, OP_RANDOMDATA))
    {
        for(i = sizeof(PcktHdr_t); i < pSendStream->dwPacketSize; i++)
        {
            pSendStream->buffer[i] = rand() ^ rand();
        }
    }
}

void UdpSendPacket(SendStream_t *pSendStream)
{
    /* Optionally fill buffer with something */
    FillBuffer(pSendStream);

    SendPacket(&pSendStream->NetAddr, &pSendStream->WSABuf, 1);
            
    if (pSendStream->NetAddr.dwTxTransfered >= sizeof(PcktHdr_t))
    {
        /* Count normal (valid) packets but not the shorter bye
         * packets */
        pSendStream->dwBytesSent += pSendStream->NetAddr.dwTxTransfered;
        pSendStream->dwPacketsSent++;
    }
}

/* Send packets with size shorter than valid to signal the receiver
 * the end of the sequence */
void SendBye(SendStream_t *pSendStream)
{
    DWORD            i;
    DWORD            OldLen;

    OldLen = pSendStream->WSABuf.len;
    pSendStream->WSABuf.len = BYE_PACKET_SIZE;
    
    for(i = 0; i < MAX_BYE_PACKETS; i++)
    {
        UdpSendPacket(pSendStream);
    }

    pSendStream->WSABuf.len = OldLen;
}

DWORD ProcessParameters(SendStream_t *pSendStream, int argc, char **argv)
{
    int              p;
    DWORD            dwError;
    NetAddr_t       *pNetAddr;

    dwError = NOERROR;
    pNetAddr = &pSendStream->NetAddr;

    for(p = 1; p < argc && dwError == NOERROR; p++)
    {
        if (*argv[p] == '-' || *argv[p] == '/')
        {
            switch(argv[p][1])
            {
            case 'h':
            case 'H':
            case '?':
                print_help(argv[0]);
                dwError = 1;
                break;
            case 'p':
                p++;
                pSendStream->dwPackets = atoi(argv[p]);
                break;
            case 'b':
                p++;
                pSendStream->dwBlocks = atoi(argv[p]);
                break;
            case 'g':
                p++;
                pSendStream->dwPacketGap = atoi(argv[p]);
                break;
            case 'G':
                p++;
                pSendStream->dwBlockGap = atoi(argv[p]);
                break;
            case 'i':
                p++;
                pNetAddr->dwAddr[LOCAL_IDX] = IPAtoN(argv[p]);
                break;
            case 's':
                p++;
                pSendStream->dwPacketSize = atoi(argv[p]);
                if (pSendStream->dwPacketSize > MAX_BUFFER_SIZE)
                {
                    pSendStream->dwPacketSize = MAX_BUFFER_SIZE;
                }
                else if (pSendStream->dwPacketSize < sizeof(PcktHdr_t))
                {
                    pSendStream->dwPacketSize = sizeof(PcktHdr_t);
                }
                break;
            case 't':
                p++;
                pSendStream->dwAdvanceTimeout = atoi(argv[p]);
                break;
            case 'o':
                p++;
                strcpy(pSendStream->FileName, argv[p]);
                if (!_stricmp(pSendStream->FileName, "null"))
                {
                    BitSet(pSendStream->dwOptions, OP_DISCARD);
                }
            case 'R':
                BitSet(pSendStream->dwOptions, OP_SENDANDRECEIVE);
                break;
            case 'd':
                switch(argv[p][2])
                {
                case 'r':
                    BitSet(pSendStream->dwOptions, OP_RANDOMDATA);
                    break;
                }
                break;
            default:
                print_error("unknown option:>>> %s <<<\n", argv[p]);
                dwError = 1;
            }
        }
        else
        {
            /* Must be an address/port/ttl */
            dwError = GetNetworkAddress(pNetAddr, argv[p]);
        }
    }

    return(dwError);
}

void ProcessPacket(SendStream_t *pSendStream)
{
    DWORD            dwError;
    WSABUF           WSABuf;
    double           Ai;
    PcktHdr_t       *pHdr;
    NetAddr_t       *pNetAddr;
    
    WSABuf.len = MAX_BUFFER_SIZE;
    WSABuf.buf = pSendStream->buffer;

    pNetAddr = &pSendStream->NetAddr;
    
    ReceivePacket(pNetAddr,
                  &WSABuf,
                  1,
                  &Ai);

    if ((pNetAddr->dwRxTransfered > 0) &&
        !BitTest(pSendStream->dwOptions, OP_DISCARD))
    {
        PrintPacket(pSendStream->output,
                    (PcktHdr_t *)pSendStream->buffer,
                    pNetAddr->dwRxTransfered,
                    Ai);
    }
}

void WaitForNextTime(SendStream_t *pSendStream, double dNextPacket)
{
    int              iStatus;
    DWORD            dwError;
    double           dCurrTime;
    double           dDelta;
    DWORD            dwMillisecs;

    dCurrTime = GetTimeOfDay();

    dDelta = dNextPacket - dCurrTime;

    while(dDelta > 0)
    {
        pSendStream->timeval.tv_sec = (DWORD)dDelta;

        pSendStream->timeval.tv_usec = (DWORD)
            ((dDelta - pSendStream->timeval.tv_sec) * 1e6);

        if (BitTest(pSendStream->dwOptions, OP_SENDANDRECEIVE))
        {
            FD_SET(pSendStream->NetAddr.Socket, &pSendStream->fdReceivers);
        
            iStatus = select(0,
                             &pSendStream->fdReceivers,
                             NULL, NULL,
                             &pSendStream->timeval);
            
            switch(iStatus)
            {
            case SOCKET_ERROR:
                dwError = WSAGetLastError();
            
                print_error("select: %u (0x%X)", dwError, dwError);
                
                break;
            case 0:
                /* Timer expired */
                break;
            default:
                /* We received a packet */
                if (FD_ISSET(pSendStream->NetAddr.Socket,
                             &pSendStream->fdReceivers))
                {
                    ProcessPacket(pSendStream);
                }
            }
        }
        else
        {
            SleepEx((DWORD)(dDelta * 1000), FALSE);
        }

        dCurrTime = GetTimeOfDay();

        dDelta = dNextPacket - dCurrTime;
    }
}


void __cdecl main(int argc, char **argv)
{
    DWORD            dwError;
    DWORD            dwDirection;
    SendStream_t     SendStream;
    
    DWORD            dwNBlocks;
    DWORD            dwPacketsPerBlock;
    DWORD            dwInterBlockGap;   /* millisecs */
    DWORD            dwInterpacketGap;  /* millisecs */
    
    /* Initialize stream's structure */
    InitPacketStream(&SendStream);

    InitReferenceTime();
    
    /* initialize winsock */
    dwError = InitWinSock();

    if (dwError)
    {
        print_error("WSAStartup failed to initialize:%u\n", dwError);

        return;
    }
    
    /* Read parameters */
    if (argc > 1)
    {
        dwError = ProcessParameters(&SendStream, argc, argv);

        if (dwError != NOERROR)
        {
            goto end;
        }
    }

    /* Open output file if needed */
    if (strlen(SendStream.FileName) > 0 &&
        !BitTest(SendStream.dwOptions, OP_DISCARD))
    {
        SendStream.output = fopen(SendStream.FileName, "w");

        if (!SendStream.output)
        {
            print_error("fopen failed to create file: %s\n",
                        SendStream.FileName);

            dwError = 1;
            
            goto end;
        }
    }

    /* Init Network */
    dwDirection = BitPar(SEND_IDX);

    if (BitTest(SendStream.dwOptions, OP_SENDANDRECEIVE))
    {
        dwDirection |= BitPar(RECV_IDX); 
    }
    
    dwError = InitNetwork(&SendStream.NetAddr, dwDirection);

    if (dwError != NOERROR)
    {
        goto end;
    }

    /* Initialize sender's data buffer */
    SendStream.WSABuf.buf = SendStream.buffer;
    SendStream.WSABuf.len = SendStream.dwPacketSize;
    
    /* Send packets */
    SendStream.dNextPacket = GetTimeOfDay();

    for(SendStream.dwBlockCount = SendStream.dwBlocks;
        SendStream.dwBlockCount > 0;
        SendStream.dwBlockCount--)
    {
        for(SendStream.dwPacketCount = SendStream.dwPackets;
            SendStream.dwPacketCount > 0;
            SendStream.dwPacketCount--)
        {
            UdpSendPacket(&SendStream);

            if (SendStream.dwPacketCount > 1)
            {
                SendStream.dNextPacket +=
                    (double)SendStream.dwPacketGap/1000.0;

                /* Set time to wait until next packet is due to be
                 * send, listen for packets in the mean time */
                WaitForNextTime(&SendStream, SendStream.dNextPacket);
            }
        }

        if (SendStream.dwBlockCount > 1)
        {
            SendStream.dNextPacket +=
                (double)SendStream.dwBlockGap/1000.0;
            
            /* Wait until the time to send next block comes */
            WaitForNextTime(&SendStream, SendStream.dNextPacket);
        }
    }

    if (BitTest(SendStream.dwOptions, OP_SENDANDRECEIVE))
    {
        /* Wait until the time to send next block comes */
        WaitForNextTime(&SendStream, GetTimeOfDay() + 1.0);
    }

    /* Send bye packets */
    SendBye(&SendStream);
    
#if 0
    fprintf(stdout, "Packets sent: %u\nBytes Sent: %u\n",
            SendStream.dwPacketsSent,
            SendStream.dwBytesSent);
#endif       
 end:
    DeinitNetwork(&SendStream.NetAddr);
    
    DeinitWinSock();
}
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\net\tapi\skywalker\filters\rtp\tools\udpecho\udpecho.c ===
/**********************************************************************
 *
 *  Copyright (C) Microsoft Corporation, 2001
 *
 *  File name:
 *
 *    udpecho.c
 *
 *  Abstract:
 *
 *    This file implements a tool for echoing UDP packets
 *
 *  Author:
 *
 *    Andres Vega-Garcia (andresvg)
 *
 *  Revision:
 *
 *    2001/05/18 created
 *
 **********************************************************************/

#include "common.h"
#include <signal.h>

#include "udpecho.h"

/* Packets are send in blocks separated by gaps, each block containing
   N packets also separated by an specific gap, i.e:

        block 1          block gap    block 2           block gap ...
   |--------------------|---------|--------------------|--------- ...
    -- -- -- -- -- -- --
      v
    \-|-------v--------/ \------v/
      |       |                 |
      |  Packets per block      |
      |                         Inter block gap
      Inter packet gap
*/

/*
  TODO list

  1. Add support for QOS in unicast/multicast
  
*/

void print_help(char *prog)
{
    char             sLocal[16];
    char             sAddr[16];

    fprintf(stderr,
            "Windows Real-Time Communications %s v%2.1f\n"
            "echo packets from/to a unicast or multicast address\n"
            "to/from another unicast or multicast address\n"
            "usage: %s "
            "[-i addr] address[/port[/ttl]] "
            "[[-i addr] address[/port[/ttl]]]\n"
            "options are:\n"
            "    -h, -?           : this help\n"
            "    -i addr          : select local interface "
            "(must preceed address)\n"
            "    address/port/ttl : address, port and ttl\n",
            prog, APP_VERSION, prog
        );
}

void InitEchoStream(EchoStream_t *pEchoStream)
{
    NetAddr_t       *pNetAddr;
    int              i;
    
    ZeroMemory(pEchoStream, sizeof(*pEchoStream));

    for(i = 0; i < 2; i++)
    {
        pEchoStream->NetAddr[i].Socket = INVALID_SOCKET;
        
        pEchoStream->NetAddr[i].wPort[REMOTE_IDX] = htons(DEFAULT_PORT);
        pEchoStream->NetAddr[i].wPort[LOCAL_IDX] = htons(DEFAULT_PORT);
    }
}

DWORD ProcessParameters(EchoStream_t *pEchoStream, int argc, char **argv)
{
    int              p;
    DWORD            dwError;
    NetAddr_t       *pNetAddr;

    dwError = NOERROR;

    for(p = 1; p < argc && dwError == NOERROR; p++)
    {
        if (*argv[p] == '-' || *argv[p] == '/')
        {
            switch(argv[p][1])
            {
            case 'h':
            case 'H':
            case '?':
                print_help(argv[0]);
                dwError = 1;
                break;
            case 'i':
                p++;
                pNetAddr = &pEchoStream->NetAddr[pEchoStream->dwAddrCount % 2];
                pNetAddr->dwAddr[LOCAL_IDX] = IPAtoN(argv[p]);
                break;
            default:
                print_error("unknown option:>>> %s <<<\n", argv[p]);
                dwError = 1;
            }
        }
        else
        {
            /* Must be an address/port/ttl */
            
            dwError = GetNetworkAddress(
                    &pEchoStream->NetAddr[pEchoStream->dwAddrCount % 2],
                    argv[p]);

            if (dwError == NOERROR)
            {
                pEchoStream->dwAddrCount++;
            }
        }
    }

    if (pEchoStream->dwAddrCount < 1)
    {
        dwError = 1;
    }

    return(dwError);
}


void ProcessPacket(EchoStream_t *pEchoStream, int Entry)
{
    DWORD            dwError;
    double           Ai;
    PcktHdr_t       *pHdr;
    NetAddr_t       *pNetAddr;
    
    pEchoStream->WSABuf.len = MAX_BUFFER_SIZE;
    pEchoStream->WSABuf.buf = pEchoStream->buffer;

    pNetAddr = &pEchoStream->NetAddr[Entry];
    
    ReceivePacket(pNetAddr,
                  &pEchoStream->WSABuf,
                  1,
                  &Ai);

    if (pNetAddr->dwRxTransfered > 0)
    {
        pHdr = (PcktHdr_t *)pEchoStream->buffer;

        /* Set the echo time */
        pHdr->EchoNTP_sec = (DWORD) Ai;

        pHdr->EchoNTP_frac = (DWORD)
            ( (Ai - (double) pHdr->EchoNTP_sec) * 4294967296.0 );

        pHdr->EchoNTP_sec = htonl(pHdr->EchoNTP_sec);

        pHdr->EchoNTP_frac = htonl(pHdr->EchoNTP_frac);

        /* Send packet back */

        pEchoStream->WSABuf.len = pNetAddr->dwRxTransfered;
        
        pNetAddr = &pEchoStream->NetAddr[1 - Entry];
        
        SendPacket(pNetAddr,
                   &pEchoStream->WSABuf,
                   1);
    }
}

BOOL             g_bExit = FALSE;

void __cdecl Signal_Ctrl_C(int sig)
{
    g_bExit = TRUE;
}

void __cdecl main(int argc, char **argv)
{
    DWORD            dwError;
    int              iStatus;
    EchoStream_t     EchoStream;
    struct timeval   timeval;
    fd_set           fdReceivers;
    
    DWORD            i;

    /* Initialize stream's structure */
    InitEchoStream(&EchoStream);
    
    InitReferenceTime();
    
    /* initialize winsock */
    dwError = InitWinSock();

    if (dwError)
    {
        print_error("WSAStartup failed to initialize:%u\n", dwError);

        return;
    }
    
    /* Read parameters */
    if (argc > 1)
    {
        dwError = ProcessParameters(&EchoStream, argc, argv);

        if (dwError != NOERROR)
        {
            goto end;
        }
    }
    else
    {
        print_help(argv[0]);

        goto end;
    }

    /* Init Network */
    for(i = 0; i < EchoStream.dwAddrCount; i++)
    {
        dwError = InitNetwork(&EchoStream.NetAddr[i],
                              BitPar2(RECV_IDX, SEND_IDX));

        if (dwError != NOERROR)
        {
            goto end;
        }
    }

    /* If only 1 address was given, use it to receive and echo */
    if (EchoStream.dwAddrCount == 1)
    {
        /* Echo to the same */
        EchoStream.NetAddr[1] = EchoStream.NetAddr[0];
    }
    
    /* Prepare for asynchronous IO */
    FD_ZERO(&fdReceivers);

    timeval.tv_sec = 0;
    timeval.tv_usec = 250000;

    /* Handle Ctrl-C */
    signal(SIGINT, Signal_Ctrl_C);

    /* Start listening */
    do {
        /* Prepare for asynchronous IO */
        for(i = 0; i < EchoStream.dwAddrCount; i++)
        {
            FD_SET(EchoStream.NetAddr[i].Socket, &fdReceivers);
        }

        iStatus = select(0, &fdReceivers, NULL, NULL, &timeval);

        switch(iStatus)
        {
        case SOCKET_ERROR:
            dwError = WSAGetLastError();
           
            print_error("select: %u (0x%X)", dwError, dwError);

            break;
        case 0:
            /* Timer expired */
            break;
        default:
            /* We received a packet */
            for(i = 0; i < EchoStream.dwAddrCount; i++)
            {
                if (FD_ISSET(EchoStream.NetAddr[i].Socket, &fdReceivers))
                {
                    ProcessPacket(&EchoStream, i);
                }
            }
         }
    } while(!g_bExit);

    dwError = NOERROR;      

 end:
    for(i = 0; i < EchoStream.dwAddrCount; i++)
    {
        DeinitNetwork(&EchoStream.NetAddr[i]);
    }
    
    DeinitWinSock();
}
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\net\tapi\skywalker\filters\utils\tptrace.cpp ===
/*++

    Copyright (c) 1997 Microsoft Corporation

Module Name:

    tptrace.cpp

Abstract:

    This file contains the function that implements a basic tracing for
    all the filters.

Author:

    Mu Han (muhan) April-17-2000

--*/
#include <windows.h>
#include <mmsystem.h>
#include <tptrace.h>

#if DBG

const char * TraceLevels[] = 
{
    "ERROR", 
    "WARNING", 
    "INFO", 
    "TRACE", 
    "ELSE",
    "INVALID TRACE LEVEL"
};

void DBGPrint(DWORD dwTraceID, DWORD dwDbgLevel, LPCSTR lpszFormat, IN ...)
/*++

Routine Description:

    Formats the incoming debug message & calls TraceVprintfEx to print it.

Arguments:

    dwDbgLevel   - The type of the message.

    lpszFormat - printf-style format string, followed by appropriate
                 list of arguments

Return Value:

--*/
{
    #define MAXDEBUGSTRINGLENGTH 512
    char  szTraceBuf[MAXDEBUGSTRINGLENGTH + 1];
    
    DWORD dwIndex;
    double dTime;
    DWORD  dwSecs;

    switch(dwDbgLevel)
    {
    case FAIL: dwIndex = 0; break;
    case WARN: dwIndex = 1; break;
    case INFO: dwIndex = 2; break;
    case TRCE: dwIndex = 3; break;
    case ELSE: dwIndex = 4; break;
    default:   dwIndex = 5; break;
    }

    dTime = RtpGetTimeOfDay(NULL);
    dwSecs = (DWORD)dTime;
    
    wsprintfA(szTraceBuf, "%u.%03u[%s] %s",
              dwSecs, (DWORD)((dTime - dwSecs) * 1000),
              TraceLevels[dwIndex], lpszFormat);

    va_list arglist;
    va_start(arglist, lpszFormat);
    TraceVprintfExA(dwTraceID, dwDbgLevel, szTraceBuf, arglist);
    va_end(arglist);
}

#endif
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\net\tapi\skywalker\filters\video\sources.inc ===
!IF 0

Copyright (c) 1996  Microsoft Corporation

Module Name:

    sources.inc

Abstract:

    Common makefile for ActiveMovie filters.

Revision History:

    06-Nov-1996 DonRyan
        Created.

!ENDIF

###############################################################################
#                                                                             #
#  Private Definitions                                                        #
#                                                                             #
###############################################################################

TARGETEXT=dll

###############################################################################
#                                                                             #
#  Debug Support                                                              #
#                                                                             #
###############################################################################

!if !$(FREEBUILD)
C_DEFINES=$(C_DEFINES) -DDEBUG
!endif


###############################################################################
#                                                                             #
#  Profile Support                                                            #
#                                                                             #
###############################################################################

!IF "$(NTPROFILE)" == ""
STRM_PROFILE_FLAG=
STRM_PROFILE_LIB=
!ELSE
!    IF "($NTPROFILE)" == "cap"
STRM_PROFILE_FLAG=-Gp
STRM_PROFILE_LIB=$(SDK_LIB_PATH)\cap.lib
!    ELSE
!        IF "$(NTPROFILE)" == "wst"
STRM_PROFILE_FLAG=-Gp
STRM_PROFILE_LIB=$(SDK_LIB_PATH)\wst.lib
!        ELSE
!            error NTPROFILE macro can be either "", "cap", or "wst"
!        ENDIF
!    ENDIF
!ENDIF

###############################################################################
#                                                                             #
#  Global Definitions                                                         #
#                                                                             #
###############################################################################

DLLENTRY=DllEntryPoint
MSC_WARNING_LEVEL=/W3 /WX
NOT_LEAN_AND_MEAN=1
USE_CRTDLL=1
386_FLAGS=$(STRM_PROFILE_FLAG)

#Compatibility with Memphis
SUBSYSTEM_VERSION=4.00

!IF defined (USE_DYNGRAPH)
C_DEFINES=$(C_DEFINES) -DDYNGRAPH
!endif

###############################################################################
#                                                                             #
#  Includes                                                                   #
#                                                                             #
###############################################################################

INCLUDES=\
    $(BASEDIR)\public\sdk\amovie\inc; \
    ..\inc; \
    ..\..\inc; \
    ..\..\..\inc; \
    ..\..\..\..\inc; \

###############################################################################
#                                                                             #
#  Link Libraries                                                             #
#                                                                             #
###############################################################################

!if defined (USE_DYNGRAPH)
LINKLIBS=\
    $(BASEDIR)\public\sdk\amovie\lib\*\strmbase.lib
!else

!if $(FREEBUILD)
LINKLIBS=\
    $(SDK_LIB_PATH)\strmbase.lib
!else
C_DEFINES=$(C_DEFINES) -DDEBUG
LINKLIBS=\
    $(SDK_LIB_PATH)\strmbasd.lib
!endif

!endif

###############################################################################
#                                                                             #
#  Target Libraries                                                           #
#                                                                             #
###############################################################################

TARGETLIBS=\
    $(SDK_LIB_PATH)\vfw32.lib    \
    $(SDK_LIB_PATH)\comctl32.lib \
    $(SDK_LIB_PATH)\winmm.lib    \
    $(SDK_LIB_PATH)\kernel32.lib \
    $(SDK_LIB_PATH)\advapi32.lib \
    $(SDK_LIB_PATH)\user32.lib   \
    $(SDK_LIB_PATH)\version.lib  \
    $(SDK_LIB_PATH)\gdi32.lib    \
    $(SDK_LIB_PATH)\ole32.lib    \
    $(SDK_LIB_PATH)\oleaut32.lib \
    $(SDK_LIB_PATH)\uuid.lib     \
    $(STRM_PROFILE_LIB)
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\net\tapi\skywalker\filters\video\inc\h245vid.h ===
/****************************************************************************
 *  @doc INTERNAL H245VID
 *
 *  @module h245vid.h | Header file for the <c CTAPIVCap> class and
 *  <c CTAPIVDec> methods used to implement the <i IH245Capability>
 *  TAPI inteface.
 *
 *  @comm For now, use the NM heuristics.
 ***************************************************************************/
#ifndef _h245vid_h_
#define _h245vid_h_

// Define four classes of CPU
#define SLOW_CPU_MHZ 110
#define FAST_CPU_MHZ 200
#define VERYFAST_CPU_MHZ 400

// Define maximum receive frame rates for CPUs < 110MHZ
#define CIF_RATE_VERYSLOW 3L
#define SQCIF_RATE_VERYSLOW 7L
#define QCIF_RATE_VERYSLOW 7L

// Define maximum receive frame rates for 110MHz < CPUs < 200MhZ
#define CIF_RATE_SLOW 7L
#define SQCIF_RATE_SLOW 15L
#define QCIF_RATE_SLOW 15L

// Define maximum receive frame rates for 200MHz < CPUs < 400MhZ
#define CIF_RATE_FAST 15L
#define SQCIF_RATE_FAST 30L
#define QCIF_RATE_FAST 30L

// Define maximum receive frame rates for CPUs > 400MHz
#define CIF_RATE_VERYFAST 30L
#define SQCIF_RATE_VERYFAST 30L
#define QCIF_RATE_VERYFAST 30L

// Define max CPU usage for decoding
#define MAX_CPU_USAGE 50UL

/*****************************************************************************
 *  @doc INTERNAL H245VIDCSTRUCTENUM
 *
 *  @struct VideoResourceBounds | The <t VideoResourceBounds> structure is used
 *    to specify the estimated maximum continuous resource requirements of the
 *    TAPI MSP Video Capture filter at a specific frame rate.
 *
 *  @field LONG | lPicturesPerSecond | Specifies an INTEGER value that
 *    indicates the video frame rate, in frames per second, for which the
 *    resource bounds are being specified. Frame rates of less than 1 frame
 *    per second are indicated by a negative value in units of seconds per
 *    frame.
 *
 *  @field DWORD | dwBitsPerPicture | Specifies a DWORD value that indicates
 *    the approximate average number of bits per video frame at an average
 *    frame rate of iPicturesPerSecond.
 ***************************************************************************/
typedef struct tag_VideoResourceBounds
{
    LONG  lPicturesPerSecond;
    DWORD dwBitsPerPicture;
} VideoResourceBounds;

#endif /* _h245vid_h_ */
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\net\tapi\skywalker\filters\video\tapivcap\bitrate.cpp ===
/****************************************************************************
 *  @doc INTERNAL BITRATE
 *
 *  @module Bitrate.cpp | Source file for the <c CTAPIBasePin> class methods
 *    used to implement the output pin bitrate control.
 ***************************************************************************/

#include "Precomp.h"

/****************************************************************************
 *  @doc INTERNAL CBITRATECMETHOD
 *
 *  @mfunc HRESULT | CTAPIBasePin | Set | This method is used to set the
 *    the value of the maximum output bitrate.
 *
 *  @parm BitrateControlProperty | Property | Used to specifiy the property
 *    to set the value of.
 *
 *  @parm long | lValue | Used to specify the value to set on the property.
 *
 *  @parm TAPIControlFlags | lFlags | Used to specify the flags to set on
 *    the property.
 *
 *  @rdesc This method returns an HRESULT value that depends on the
 *    implementation of the interface. HRESULT can include one of the
 *    following standard constants, or other values not listed:
 *
 *  @flag E_PROP_ID_UNSUPPORTED | The specified property ID is not supported
 *    for the specified property set
 *  @flag E_INVALIDARG | Invalid argument
 *  @flag NOERROR | No error
 ***************************************************************************/
STDMETHODIMP CTAPIBasePin::Set(IN BitrateControlProperty Property, IN long lValue, IN TAPIControlFlags lFlags, IN DWORD dwLayerId)
{
        HRESULT Hr = NOERROR;

        FX_ENTRY("CTAPIBasePin::Set (BitrateControlProperty)")

        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: begin", _fx_));

        // Validate input parameters
        ASSERT(lValue >= m_lBitrateRangeMin);
        ASSERT(lValue <= m_lBitrateRangeMax);
        ASSERT(dwLayerId == 0);
        if (dwLayerId)
        {
                // We don't implement multi-layered encoding in this filter
                DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: Invalid argument", _fx_));
                Hr = E_INVALIDARG;
                goto MyExit;
        }

        ASSERT(Property >= BitrateControl_Maximum && Property <= BitrateControl_Current);

        // Set relevant values
        if (Property == BitrateControl_Maximum)
        {
                if (lValue < m_lBitrateRangeMin || lValue > m_lBitrateRangeMax)
                {
                        DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: Invalid argument", _fx_));
                        Hr = E_INVALIDARG;
                        goto MyExit;
                }
                m_lTargetBitrate = lValue;
                DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s:   New target bitrate: %ld", _fx_, m_lTargetBitrate));
        }
        else
        {
                DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: Invalid argument", _fx_));
                Hr = E_PROP_ID_UNSUPPORTED;
        }

MyExit:
        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: end", _fx_));
        return Hr;
}

/****************************************************************************
 *  @doc INTERNAL CBITRATECMETHOD
 *
 *  @mfunc HRESULT | CTAPIBasePin | Get | This method is used to retrieve
 *    the current or maximum limit in bandwidth transmission advertized.
 *
 *  @parm BitrateControlProperty | Property | Used to specifiy the property
 *    to retrieve the value of.
 *
 *  @parm long* | plValue | Used to receive the value of the property, in bps.
 *
 *  @parm TAPIControlFlags* | plFlags | Used to receive the value of the flag
 *    associated to the property.
 *
 *  @parm DWORD | dwLayerId | Specifies the ID of the encoding layer the
 *    call applies to. For standard audio and video encoders, this field is
 *    always set to 0. In the case of multi-layered encoders, this field
 *    shall be set to 0 for the base layer, 1 for the first enhancement
 *    layer, 2 for the next enhancement layer, etc
 *
 *  @rdesc This method returns an HRESULT value that depends on the
 *    implementation of the interface. HRESULT can include one of the
 *    following standard constants, or other values not listed:
 *
 *  @flag E_POINTER | Null pointer argument
 *  @flag E_INVALIDARG | Invalid argument
 *  @flag E_PROP_ID_UNSUPPORTED | The specified property ID is not supported
 *    for the specified property set
 *  @flag NOERROR | No error
 ***************************************************************************/
STDMETHODIMP CTAPIBasePin::Get(IN BitrateControlProperty Property, OUT long *plValue, OUT TAPIControlFlags *plFlags, IN DWORD dwLayerId)
{
        HRESULT Hr = NOERROR;

        FX_ENTRY("CTAPIBasePin::Get (BitrateControlProperty)")

        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: begin", _fx_));

        // Validate input parameters
        ASSERT(plValue);
        ASSERT(plFlags);
        if (!plValue || !plFlags)
        {
                DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: Null pointer argument", _fx_));
                Hr = E_POINTER;
                goto MyExit;
        }
        ASSERT(dwLayerId == 0);
        if (dwLayerId)
        {
                // We don't support multi-layered decoding in this filter
                DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: Invalid argument", _fx_));
                Hr = E_INVALIDARG;
                goto MyExit;
        }
        ASSERT(Property >= BitrateControl_Maximum && Property <= BitrateControl_Current);

        // Return relevant values
        *plFlags = TAPIControl_Flags_None;
        if (Property == BitrateControl_Maximum)
                *plValue = m_lTargetBitrate;
        else if (Property == BitrateControl_Current)
                *plValue = m_lCurrentBitrate;
        else
        {
                DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: Invalid Property argument", _fx_));
                Hr = E_PROP_ID_UNSUPPORTED;
        }

MyExit:
        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: end", _fx_));
        return Hr;
}

/****************************************************************************
 *  @doc INTERNAL CBITRATECMETHOD
 *
 *  @mfunc HRESULT | CTAPIBasePin | GetRange | This
 *    method is used to retrieve support, minimum, maximum, and default
 *    values for the upper limit in bandwidth transmission the an output pin
 *    may be setup for.
 *
 *  @parm long* | plMin | Used to retrieve the minimum value of the
 *    property, in bps.
 *
 *  @parm long* | plMax | Used to retrieve the maximum value of the
 *    property, in bps.
 *
 *  @parm long* | plSteppingDelta | Used to retrieve the stepping delta
 *    of the property, in bps.
 *
 *  @parm long* | plDefault | Used to retrieve the default value of the
 *    property, in bps.
 *
 *  @parm TAPIControlFlags* | plCapsFlags | Used to receive the flags
 *    suppported by the property.
 *
 *  @parm DWORD | dwLayerId | Specifies the ID of the encoding layer the
 *    call applies to. For standard audio and video encoders, this field is
 *    always set to 0. In the case of multi-layered encoders, this field
 *    shall be set to 0 for the base layer, 1 for the first enhancement
 *    layer, 2 for the next enhancement layer, etc
 *
 *  @rdesc This method returns an HRESULT value that depends on the
 *    implementation of the interface. HRESULT can include one of the
 *    following standard constants, or other values not listed:
 *
 *  @flag E_POINTER | Null pointer argument
 *  @flag E_INVALIDARG | Invalid argument
 *  @flag E_PROP_ID_UNSUPPORTED | The specified property ID is not supported
 *    for the specified property set
 *  @flag NOERROR | No error
 ***************************************************************************/
STDMETHODIMP CTAPIBasePin::GetRange(IN BitrateControlProperty Property, OUT long *plMin, OUT long *plMax, OUT long *plSteppingDelta, OUT long *plDefault, OUT TAPIControlFlags *plCapsFlags, IN DWORD dwLayerId)
{
        HRESULT Hr = NOERROR;

        FX_ENTRY("CTAPIBasePin::GetRange (BitrateControlProperty)")

        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: begin", _fx_));

        // Validate input parameters
        ASSERT(plMin);
        ASSERT(plMax);
        ASSERT(plSteppingDelta);
        ASSERT(plDefault);
        ASSERT(plCapsFlags);
        if (!plMin || !plMax || !plSteppingDelta || !plDefault || !plCapsFlags)
        {
                DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: Null pointer argument", _fx_));
                Hr = E_POINTER;
                goto MyExit;
        }
        ASSERT(dwLayerId == 0);
        if (dwLayerId)
        {
                // We don't implement multi-layered encoding in this filter
                DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: Invalid argument", _fx_));
                Hr = E_INVALIDARG;
                goto MyExit;
        }
        ASSERT(Property >= BitrateControl_Maximum && Property <= BitrateControl_Current);
        if (Property != BitrateControl_Maximum && Property != BitrateControl_Current)
        {
                DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: Invalid Property argument", _fx_));
                Hr = E_PROP_ID_UNSUPPORTED;
                goto MyExit;
        }

        // Return relevant values
        *plCapsFlags = TAPIControl_Flags_None;
        *plMin = m_lBitrateRangeMin;
        *plMax = m_lBitrateRangeMax;
        *plSteppingDelta = m_lBitrateRangeSteppingDelta;
        *plDefault = m_lBitrateRangeDefault;

MyExit:
        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: end", _fx_));
        return Hr;
}
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\net\tapi\skywalker\filters\video\tapivcap\cameracp.h ===
/****************************************************************************
 *  @doc INTERNAL CAMERACP
 *
 *  @module CameraCP.h | Header file for the <c CCameraControlProperty>
 *    class used to implement a property page to test the TAPI interface
 *    <i ICameraControl>.
 *
 *  @comm This code tests the TAPI Video Decoder Filter <i ICameraControl>
 *    implementation. This code is only compiled if USE_PROPERTY_PAGES is
 *    defined.
 ***************************************************************************/

#ifndef _CAMERACP_H_
#define _CAMERACP_H_

#ifdef USE_PROPERTY_PAGES

#ifdef USE_SOFTWARE_CAMERA_CONTROL

#define NUM_CAMERA_CONTROLS 9

/****************************************************************************
 *  @doc INTERNAL CCAMERACPCLASS
 *
 *  @class CCameraControlProperty | This class implements handling of a
 *    single camera control property in a property page.
 *
 *  @mdata int | CCameraControlProperty | m_NumProperties | Keeps
 *    track of the number of properties.
 *
 *  @mdata ICameraControl * | CCameraControlProperty | m_pInterface | Pointer
 *    to the <i ICameraControl> interface.
 *
 *  @comm This code tests the TAPI Video Decoder Filter <i ICameraControl>
 *    implementation. This code is only compiled if USE_PROPERTY_PAGES is
 *    defined.
***************************************************************************/
class CCameraControlProperty : public CPropertyEditor 
{
	public:
	CCameraControlProperty(HWND hDlg, ULONG IDLabel, ULONG IDMinControl, ULONG IDMaxControl, ULONG IDDefaultControl, ULONG IDStepControl, ULONG IDEditControl, ULONG IDTrackbarControl, ULONG IDProgressControl, ULONG IDProperty, ULONG IDAutoControl, ICameraControl *pInterface);
	~CCameraControlProperty ();

	// CPropertyEditor base class pure virtual overrides
	HRESULT GetValue();
	HRESULT SetValue();
	HRESULT GetRange();
	BOOL CanAutoControl(void);
	BOOL GetAuto(void);
	BOOL SetAuto(BOOL fAuto);

	private:
	ICameraControl *m_pInterface;
};

/****************************************************************************
 *  @doc INTERNAL CCAMERACPCLASS
 *
 *  @class CCameraControlProperties | This class runs a property page to test
 *    the TAPI Capture Filter <i ICameraControl> implementation.
 *
 *  @mdata int | CCameraControlProperties | m_NumProperties | Keeps
 *    track of the number of properties.
 *
 *  @mdata ICameraControl * | CCameraControlProperties | m_pICameraControl | Pointer
 *    to the <i ICameraControl> interface.
 *
 *  @mdata CCameraControlProperty * | CCameraControlProperties | m_Controls[NUM_CAMERA_CONTROLS] | Array
 *    of camera control properties.
 *
 *  @comm This code tests the TAPI Capture Filter <i ICameraControl>
 *    implementation. This code is only compiled if USE_PROPERTY_PAGES is
 *    defined.
***************************************************************************/
class CCameraControlProperties : public CBasePropertyPage
{
	public:
	CCameraControlProperties(LPUNKNOWN pUnk, HRESULT *pHr);
	~CCameraControlProperties();

	HRESULT OnConnect(IUnknown *pUnk);
	HRESULT OnDisconnect();
	HRESULT OnActivate();
	HRESULT OnDeactivate();
	HRESULT OnApplyChanges();
	BOOL    OnReceiveMessage(HWND hWnd, UINT uMsg, WPARAM wParam, LPARAM lParam);

	private:
	void SetDirty();

	int m_NumProperties;
	ICameraControl *m_pICameraControl;
	BOOL m_fActivated;
	CCameraControlProperty *m_Controls[NUM_CAMERA_CONTROLS];
};

#endif // USE_SOFTWARE_CAMERA_CONTROL

#endif // USE_PROPERTY_PAGES

#endif // _CAMERACP_H_
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\net\tapi\skywalker\filters\video\tapivcap\basepin.h ===
/****************************************************************************
 *  @doc INTERNAL BASEPIN
 *
 *  @module BasePin.h | Header file for the <c CTAPIBasePin> class methods
 *    used to implement the TAPI base output pin.
 ***************************************************************************/

#ifndef _BASEPIN_H_
#define _BASEPIN_H_

/*****************************************************************************
 * @doc EXTERNAL CONSTANTS
 *
 * @const 0x00000000 | CONVERSIONTYPE_NONE | No conversion operation necessary.
 *
 * @const 0x00000001 | CONVERSIONTYPE_ENCODE | Specifies an encoding operation.
 *
 * @const 0x00000002 | CONVERSIONTYPE_DECODE | Specifies a decoding operation.
 *
 * @const 0x00000004 | CONVERSIONTYPE_SCALER | Specifies an image size change.
 *
 * @const 0x00000008 | CONVERSIONTYPE_PRESCALER | Specifies an image size change will occur before a format change.
 ****************************************************************************/
#define CONVERSIONTYPE_NONE                                     0x00000000
#define CONVERSIONTYPE_ENCODE                           0x00000001
#define CONVERSIONTYPE_DECODE                           0x00000002
#define CONVERSIONTYPE_SCALER                           0x00000004
#define CONVERSIONTYPE_PRESCALER                        0x00000008

/****************************************************************************
 *  @doc INTERNAL CBASEPINCLASS
 *
 *  @class CTAPIBasePin | This class implements the TAPI base output pin.
 *
 *  @mdata CTAPIVCap* | CTAPIBasePin | m_pCaptureFilter | Pointer to the
 *    filter that owns us.
 *
 *  @mdata ALLOCATOR_PROPERTIES | CTAPIBasePin | m_parms | Out allocator
 *    properties.
 *
 *  @mdata REFERENCE_TIME | CTAPIBasePin | m_MaxProcessingTime | Maximum
 *    processing time.
 *
 *  @mdata REFERENCE_TIME | CTAPIBasePin | m_CurrentProcessingTime | Current
 *    processing time.
 *
 *  @mdata DWORD | CTAPIBasePin | m_dwMaxCPULoad | Maximum CPU load.
 *
 *  @mdata DWORD | CTAPIBasePin | m_dwCurrentCPULoad | Current CPU load.
 *
 *  @mdata REFERENCE_TIME | CTAPIBasePin | m_AvgTimePerFrameRangeMin | Minimum
 *    target frame rate.
 *
 *  @mdata REFERENCE_TIME | CTAPIBasePin | m_AvgTimePerFrameRangeMax | Maximum
 *    target frame rate.
 *
 *  @mdata REFERENCE_TIME | CTAPIBasePin | m_AvgTimePerFrameRangeSteppingDelta | Target
 *    frame rate stepping delta.
 *
 *  @mdata REFERENCE_TIME | CTAPIBasePin | m_AvgTimePerFrameRangeDefault | Target
 *    frame rate default.
 *
 *  @mdata REFERENCE_TIME | CTAPIBasePin | m_MaxAvgTimePerFrame | Target
 *    frame rate.
 *
 *  @mdata REFERENCE_TIME | CTAPIBasePin | m_CurrentAvgTimePerFrame | Current
 *    frame rate.
 *
 *  @mdata DWORD | CTAPIBasePin | m_dwBitrateRangeMin | Minimum target bitrate.
 *
 *  @mdata DWORD | CTAPIBasePin | m_dwBitrateRangeMax | Maximum target bitrate.
 *
 *  @mdata DWORD | CTAPIBasePin | m_dwBitrateRangeSteppingDelta | Target
 *    bitrate stepping delta.
 *
 *  @mdata DWORD | CTAPIBasePin | m_dwBitrateRangeDefault | Default target bitrate.
 *
 *  @mdata DWORD | CTAPIBasePin | m_dwMaxBitrate | Target bitrate.
 *
 *  @mdata DWORD | CTAPIBasePin | m_dwCurrentBitrate | Current bitrate.
 *
 *  @mdata BOOL | CTAPIBasePin | m_fFlipHorizontal | Set to TRUE if image is
 *    to be flipped horizontally.
 *
 *  @mdata BOOL | CTAPIBasePin | m_fFlipVertical | Set to TRUE if image is
 *    to be flipped vertically.
 *
 *  @mdata BOOL | CTAPIBasePin | m_fFlipVertical | Affects the quality of
 *    en encoded video stream.
 *
 *  @mdata DWORD  | CTAPIBasePin | m_dwConversionType | Specifies the format
 *    conversion operation necessary to go from the format of the captured
 *    video frames to the format of the data actually generated by the pin.
 *    It can be any combination of the following constants:
 *
 *  @flag CONVERSIONTYPE_NONE | No conversion operation necessary
 *  @flag CONVERSIONTYPE_ENCODE | Specifies an encoding operation
 *  @flag CONVERSIONTYPE_DECODE | Specifies a decoding operation
 *  @flag CONVERSIONTYPE_SCALER | Specifies an image size change
 *
 *  @mdata PBYTE | CTAPIBasePin | m_pbyOut | Pointer to the output buffer
 *    used in a conversion operation.
 *
 *  @mdata DWORD | CTAPIBasePin | m_dwLastTimestamp | Timestamps of the last
 *    frame generated, normalized to 29.97Hz.
 *
 *  @mdata DWORD | CTAPIBasePin | m_dwLastIFrameTime | Remembers the last
 *    time we sent an I-frame downstream.
 *
 *  @mdata DWORD | CTAPIBasePin | m_dwFrame | Current frame number.
 *
 *  @mdata HIC | CTAPIBasePin | m_hIC | Handle to the ICM image converter.
 *
 *  @mdata BOOL | CTAPIBasePin | m_fPeriodicIFrames | Set to TRUE to generate
 *    I-frame periodically.
 *
 *  @mdata PBITMAPINFOHEADER | CTAPIBasePin | m_pbiOut | Pointer to the output
 *    format.
 *
 *  @mdata PBITMAPINFOHEADER | CTAPIBasePin | m_pbiIn | Pointer to the input
 *    format.
 *
 *  @mdata PBITMAPINFOHEADER | CTAPIBasePin | m_pbiInt | Pointer to the intermediate
 *    format.
 *
 *  @mdata BOOL | CTAPIBasePin | m_fConvert | Set to TRUE after an ICM converter
 *    has been open successfully.
 *
 *  @mdata PBITMAPINFOHEADER | CTAPIBasePin | m_pbiSCCOut | Pointer to the output
 *    format of a software-only camera controlled operation.
 *
 *  @mdata PBITMAPINFOHEADER | CTAPIBasePin | m_pbiSCCIn | Pointer to the input
 *    format of a software-only camera controlled operation.
 *
 *  @mdata PBYTE | CTAPIBasePin | m_pbyCamCtrl | Intermediate buffer used in
 *    a software-only camera controlled operation.
 *
 *  @mdata BOOL | CTAPIBasePin | m_fSoftCamCtrl | Set to TRUE after a
 *    software-only camera controller has been opened.
 ***************************************************************************/
class CTAPIBasePin : public CBaseOutputPin, public CBaseStreamControl, public IAMStreamConfig, public IFrameRateControl, public IVideoControl, public IBitrateControl, public IMemAllocator
#ifdef USE_CPU_CONTROL
, public ICPUControl
#endif
{
        public:
        DECLARE_IUNKNOWN
        STDMETHODIMP NonDelegatingQueryInterface(IN REFIID riid, OUT PVOID *ppv);
        CTAPIBasePin(IN TCHAR *pObjectName, IN CTAPIVCap *pCaptureFilter, IN HRESULT *pHr, IN LPCWSTR pName);
        virtual ~CTAPIBasePin();

        // Override CBasePin base class methods
        virtual HRESULT GetMediaType(IN int iPosition, OUT CMediaType *pMediaType);
        virtual HRESULT CheckMediaType(IN const CMediaType *pMediaType);
        virtual HRESULT SetMediaType(IN CMediaType *pMediaType);

        // Implement IAMStreamConfig
        STDMETHODIMP SetFormat(IN AM_MEDIA_TYPE *pmt);
        STDMETHODIMP GetFormat(OUT AM_MEDIA_TYPE **ppmt);
        STDMETHODIMP GetNumberOfCapabilities(OUT int *piCount, OUT int *piSize);
        STDMETHODIMP GetStreamCaps(IN int iIndex, OUT AM_MEDIA_TYPE **ppmt, OUT LPBYTE pSCC);

#ifdef USE_CPU_CONTROL
        // Implement ICPUControl
        STDMETHODIMP SetMaxProcessingTime(IN REFERENCE_TIME MaxProcessingTime);
        STDMETHODIMP GetMaxProcessingTime(OUT REFERENCE_TIME *pMaxProcessingTime, IN DWORD dwMaxCPULoad);
        STDMETHODIMP GetCurrentProcessingTime(OUT REFERENCE_TIME *pCurrentProcessingTime);
        STDMETHODIMP GetMaxProcessingTimeRange(OUT REFERENCE_TIME *pMin, OUT REFERENCE_TIME *pMax, OUT REFERENCE_TIME *pSteppingDelta, OUT REFERENCE_TIME *pDefault, IN DWORD dwMaxCPULoad);
        STDMETHODIMP SetMaxCPULoad(IN DWORD dwMaxCPULoad);
        STDMETHODIMP GetMaxCPULoad(OUT DWORD *pdwMaxCPULoad, IN REFERENCE_TIME MaxProcessingTime);
        STDMETHODIMP GetCurrentCPULoad(OUT DWORD *pdwCurrentCPULoad);
        STDMETHODIMP GetMaxCPULoadRange(OUT DWORD *pMin, OUT DWORD *pMax, OUT DWORD *pSteppingDelta, OUT DWORD *pDefault, IN REFERENCE_TIME MaxProcessingTime);
#endif

        // Implement IFrameRateControl
        STDMETHODIMP GetRange(IN FrameRateControlProperty Property, OUT long *plMin, OUT long *plMax, OUT long *plSteppingDelta, OUT long *plDefault, OUT TAPIControlFlags *plCapsFlags);
        STDMETHODIMP Set(IN FrameRateControlProperty Property, IN long lValue, IN TAPIControlFlags lFlags);
        STDMETHODIMP Get(IN FrameRateControlProperty Property, OUT long *plValue, OUT TAPIControlFlags *plFlags);

        // Implement IBitrateControl
        STDMETHODIMP GetRange(IN BitrateControlProperty Property, OUT long *plMin, OUT long *plMax, OUT long *plSteppingDelta, OUT long *plDefault, OUT TAPIControlFlags *plCapsFlags, IN DWORD dwLayerId);
        STDMETHODIMP Set(IN BitrateControlProperty Property, IN long lValue, IN TAPIControlFlags lFlags, IN DWORD dwLayerId);
        STDMETHODIMP Get(IN BitrateControlProperty Property, OUT long *plValue, OUT TAPIControlFlags *plFlags, IN DWORD dwLayerId);

        // Implement IVideoControl
        STDMETHODIMP GetCaps(OUT LONG *pCapsFlags);
        STDMETHODIMP SetMode(IN LONG Mode);
        STDMETHODIMP GetMode(OUT LONG *Mode);
        STDMETHODIMP GetCurrentActualFrameRate(OUT LONGLONG *ActualFrameRate);
        STDMETHODIMP GetMaxAvailableFrameRate(IN LONG iIndex, IN SIZE Dimensions, OUT LONGLONG *MaxAvailableFrameRate);
        STDMETHODIMP GetFrameRateList(IN LONG iIndex, IN SIZE Dimensions, IN LONG *ListSize, OUT LONGLONG **FrameRates);

        // Implement IMemAllocator
        STDMETHODIMP SetProperties(IN ALLOCATOR_PROPERTIES *pRequest, OUT ALLOCATOR_PROPERTIES *pActual);
        STDMETHODIMP GetProperties(OUT ALLOCATOR_PROPERTIES *pProps);
        STDMETHODIMP Commit();
        STDMETHODIMP Decommit();
        STDMETHODIMP GetBuffer(OUT IMediaSample **ppBuffer, IN REFERENCE_TIME *pStartTime, IN REFERENCE_TIME *pEndTime, IN DWORD dwFlags);
        STDMETHODIMP ReleaseBuffer(IN IMediaSample *pBuffer);

        // Override CBaseOutputPin base class methods
        HRESULT DecideBufferSize(IN IMemAllocator *pAlloc, OUT ALLOCATOR_PROPERTIES *ppropInputRequest);
        HRESULT DecideAllocator(IN IMemInputPin *pPin, OUT IMemAllocator **ppAlloc);

        // Override IQualityControl interface method to receive Notification messages
        STDMETHODIMP Notify(IN IBaseFilter *pSelf, IN Quality q) {return E_NOTIMPL;};

        HRESULT Active();
        HRESULT Inactive();
        HRESULT ActiveRun(IN REFERENCE_TIME tStart);
        HRESULT ActivePause();
    HRESULT ChangeFormatHelper();
    HRESULT NotifyDeviceFormatChange(IN CMediaType *pMediaType);
        HRESULT Reconnect();

        protected:

        friend class CVfWCapDev;
        friend class CWDMCapDev;
        friend class CICMConverter;
        friend class CH26XEncoder;
        friend class CRtpPdPin;
        friend class CConverter;

        CTAPIVCap               *m_pCaptureFilter;

        // Allocator properties
        ALLOCATOR_PROPERTIES m_parms;

#ifdef USE_CPU_CONTROL
        // CPU control
        REFERENCE_TIME  m_MaxProcessingTime;
        REFERENCE_TIME  m_CurrentProcessingTime;
        DWORD                   m_dwMaxCPULoad;
        DWORD                   m_dwCurrentCPULoad;
#endif

        // Frame rate control
        LONG m_lAvgTimePerFrameRangeMin;
        LONG m_lAvgTimePerFrameRangeMax;
        LONG m_lAvgTimePerFrameRangeSteppingDelta;
        LONG m_lAvgTimePerFrameRangeDefault;
        LONG m_lMaxAvgTimePerFrame;
        LONG m_lCurrentAvgTimePerFrame;

        // Bitrate control
        LONG m_lBitrateRangeMin;
        LONG m_lBitrateRangeMax;
        LONG m_lBitrateRangeSteppingDelta;
        LONG m_lBitrateRangeDefault;
        LONG m_lTargetBitrate;
        LONG m_lCurrentBitrate;

        // Video mode control
        BOOL m_fFlipHorizontal;
        BOOL m_fFlipVertical;

        // Formats
        AM_MEDIA_TYPE*                                  *m_aFormats;
        DWORD                                                   m_dwNumFormats;
        const VIDEO_STREAM_CONFIG_CAPS* const *m_aCapabilities;
        int                                                             m_iCurrFormat;
        BOOL                                                    m_fFormatChanged;

        // Fast updates, this really only belongs to the capture pin, but it is
    // not worth while to override SendFrame just to read this flag.
        BOOL                            m_fFastUpdatePicture;

        // Format conversion
        CConverter *m_pConverter;
        HRESULT OpenConverter(IN PBITMAPINFOHEADER pbiIn, IN PBITMAPINFOHEADER pbiOut);
        HRESULT CloseConverter();

        // Blackbanding and cropping vs stretching
        BOOL m_fNoImageStretch;

        // ScaleDIB8 helpers
        DWORD m_dwBlackEntry;

#ifdef USE_SOFTWARE_CAMERA_CONTROL
        // Software-only camera control
        PBITMAPINFOHEADER m_pbiSCCOut;
        PBITMAPINFOHEADER m_pbiSCCIn;
        PBYTE m_pbyCamCtrl;
        BOOL m_fSoftCamCtrl;
        HRESULT CloseSoftCamCtrl();
        BOOL    IsSoftCamCtrlNeeded();
        BOOL    IsSoftCamCtrlOpen();
        HRESULT ApplySoftCamCtrl(PBYTE pbyInput, DWORD dwInBytes, PBYTE pbyOutput, PDWORD pdwBytesUsed, PDWORD pdwBytesExtent);
        HRESULT OpenSoftCamCtrl(IN PBITMAPINFOHEADER pbiIn, IN PBITMAPINFOHEADER pbiOut);
#endif

        // Video capture buffer queue management
    BOOL        Committed() {return m_pCaptureFilter->m_cs.paHdr != NULL;};
    HRESULT     Flush();
    HRESULT     ReleaseFrame(IN LPTHKVIDEOHDR ptvh);
    HRESULT     SendFrame(IN CFrameSample *pSample, IN PBYTE pbyInBuff, IN DWORD dwInBytes, OUT PDWORD pdwBytesUsed, OUT PDWORD pdwBytesExtent, IN BOOL bDiscon);
};

#endif // _BASEPIN_H_
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\net\tapi\skywalker\filters\video\tapivcap\camerac.cpp ===
/****************************************************************************
 *  @doc INTERNAL CAMERAC
 *
 *  @module CameraC.cpp | Source file for the <c CCapDev> and <c CWDMCapDev>
 *    class methods used to implement the <i ICameraControl> interface.
 *
 *  @todo The <c CCapDev> class does everything in software. When the same
 *    kind of services are supported by a WDM capture device, we use those
 *    instead.
 ***************************************************************************/

#include "Precomp.h"

#define PAN_TILT_MIN -180
#define PAN_TILT_MAX 180
#define PAN_TILT_DELTA 1
#define PAN_TILT_DEFAULT 0
#define ZOOM_MIN 10
#define ZOOM_MAX 600
#define ZOOM_DELTA 10
#define ZOOM_DEFAULT 10

/****************************************************************************
 *  @doc INTERNAL CCAMERACMETHOD
 *
 *  @mfunc HRESULT | CCapDev | Set | This method is used to set the value
 *    of a camera control setting.
 *
 *  @parm TAPICameraControlProperty | Property | Used to specify the camera
 *    control setting to set the value of. Use a member of the
 *    <t TAPICameraControlProperty> enumerated type.
 *
 *  @parm long | lValue | Used to specify the new value of the camera control
 *    setting.
 *
 *  @parm long | Flags | A member of the <t TAPIControlFlags> enumerated
 *    type.
 *
 *  @rdesc This method returns an HRESULT value that depends on the
 *    implementation of the interface. HRESULT can include one of the
 *    following standard constants, or other values not listed:
 *
 *  @flag E_FAIL | Failure
 *  @flag E_NOTIMPL | Method is not supported
 *  @flag E_INVALIDARG | Invalid argument
 *  @flag E_PROP_ID_UNSUPPORTED | The specified property ID is not supported
 *    for the specified property set
 *  @flag NOERROR | No error
 ***************************************************************************/
STDMETHODIMP CCapDev::Set(IN TAPICameraControlProperty Property, IN long lValue, IN TAPIControlFlags lFlags)
{
	HRESULT Hr = NOERROR;

	FX_ENTRY("CCapDev::Set (CameraControl)")

	DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: begin", _fx_));

	// Validate input parameters
	ASSERT((Property >= TAPICameraControl_Pan && Property <= TAPICameraControl_Focus) || Property == TAPICameraControl_FlipVertical || Property == TAPICameraControl_FlipHorizontal);

	// Update the property and flags
	switch (Property)
	{
		case TAPICameraControl_Pan:
			ASSERT(lValue >= PAN_TILT_MIN && lValue <= PAN_TILT_MAX);
			if (lValue >= PAN_TILT_MIN && lValue <= PAN_TILT_MAX)
				m_lCCPan = lValue;
			else
				Hr = E_INVALIDARG;
			break;
		case TAPICameraControl_Tilt:
			ASSERT(lValue >= PAN_TILT_MIN && lValue <= PAN_TILT_MAX);
			if (lValue >= PAN_TILT_MIN && lValue <= PAN_TILT_MAX)
				m_lCCTilt = lValue;
			else
				Hr = E_INVALIDARG;
			break;
		case TAPICameraControl_Zoom:
			ASSERT(lValue >= ZOOM_MIN && lValue <= ZOOM_MAX);
			if (lValue >= ZOOM_MIN && lValue <= ZOOM_MAX)
				m_lCCZoom = lValue;
			else
				Hr = E_INVALIDARG;
			break;
		case TAPICameraControl_FlipVertical:
			m_pCaptureFilter->m_pPreviewPin->m_fFlipVertical = lValue;
			break;
		case TAPICameraControl_FlipHorizontal:
			m_pCaptureFilter->m_pPreviewPin->m_fFlipHorizontal = lValue;
			break;
		default:
			Hr = E_PROP_ID_UNSUPPORTED;
	}

	DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: end", _fx_));
	return Hr;
}

/****************************************************************************
 *  @doc INTERNAL CCAMERACMETHOD
 *
 *  @mfunc HRESULT | CCapDev | Get | This method is used to retrieve the
 *    value of a camera control setting.
 *
 *  @parm TAPICameraControlProperty | Property | Used to specify the camera
 *    control setting to get the value of. Use a member of the
 *    <t TAPICameraControlProperty> enumerated type.
 *
 *  @parm long* | plValue | Used to retrieve the current value of the
 *    camera control setting.
 *
 *  @parm long* | plFlags | Pointer to a member of the <t TAPIControlFlags>
 *    enumerated type.
 *
 *  @rdesc This method returns an HRESULT value that depends on the
 *    implementation of the interface. HRESULT can include one of the
 *    following standard constants, or other values not listed:
 *
 *  @flag E_POINTER | Null pointer argument
 *  @flag E_PROP_ID_UNSUPPORTED | The specified property ID is not supported
 *    for the specified property set
 *  @flag NOERROR | No error
 ***************************************************************************/
STDMETHODIMP CCapDev::Get(IN TAPICameraControlProperty Property, OUT long *plValue, OUT TAPIControlFlags *plFlags)
{
	HRESULT Hr = NOERROR;

	FX_ENTRY("CCapDev::Get (CameraControl)")

	DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: begin", _fx_));

	// Validate input parameters
	ASSERT(plValue);
	ASSERT(plFlags);
	if (!plValue || !plFlags)
	{
		DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: Null pointer argument", _fx_));
		Hr = E_POINTER;
		goto MyExit;
	}
	ASSERT((Property >= TAPICameraControl_Pan && Property <= TAPICameraControl_Focus) || Property == TAPICameraControl_FlipVertical || Property == TAPICameraControl_FlipHorizontal);

	// Update the property and flags
	*plFlags = TAPIControl_Flags_Manual;
	switch (Property)
	{
		case TAPICameraControl_Pan:
			*plValue = m_lCCPan;
			break;
		case TAPICameraControl_Tilt:
			*plValue = m_lCCTilt;
			break;
		case TAPICameraControl_Zoom:
			*plValue = m_lCCZoom;
			break;
		case TAPICameraControl_FlipVertical:
			*plValue = m_pCaptureFilter->m_pPreviewPin->m_fFlipVertical;
			break;
		case TAPICameraControl_FlipHorizontal:
			*plValue = m_pCaptureFilter->m_pPreviewPin->m_fFlipHorizontal;
			break;
		default:
			Hr = E_PROP_ID_UNSUPPORTED;
	}

MyExit:
	DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: end", _fx_));
	return Hr;
}

/****************************************************************************
 *  @doc INTERNAL CCAMERACMETHOD
 *
 *  @mfunc HRESULT | CCapDev | GetRange | This method is used to retrieve
 *    the minimum, maximum, and default values for specific camera control
 *    settings.
 *
 *  @parm CameraControlProperty | Property | Used to specify the camera
 *    control setting to determine the range of. Use a member of the
 *    <t CameraControlProperty> enumerated type.
 *
 *  @parm long* | plMin | Used to retrieve the minimum value of the camera
 *    control setting range.
 *
 *  @parm long* | plMax | Used to retrieve the maximum value of the camera
 *    control setting range.
 *
 *  @parm long* | plSteppingDelta | Used to retrieve the stepping delta of
 *    the camera control setting range.
 *
 *  @parm long* | plDefault | Used to retrieve the default value of the
 *    camera control setting range.
 *
 *  @parm long* | plCapsFlags | Used to retrieve the capabilities of the
 *    camera control setting. Pointer to a member of the
 *    <t TAPIControlFlags> enumerated type.
 *
 *  @rdesc This method returns an HRESULT value that depends on the
 *    implementation of the interface. HRESULT can include one of the
 *    following standard constants, or other values not listed:
 *
 *  @flag E_POINTER | Null pointer argument
 *  @flag E_PROP_ID_UNSUPPORTED | The specified property ID is not supported
 *    for the specified property set
 *  @flag NOERROR | No error
 ***************************************************************************/
STDMETHODIMP CCapDev::GetRange(IN TAPICameraControlProperty Property, OUT long *plMin, OUT long *plMax, OUT long *plSteppingDelta, OUT long *plDefault, OUT TAPIControlFlags *plCapsFlags)
{
	HRESULT Hr = NOERROR;

	FX_ENTRY("CCapDev::GetRange (CameraControl)")

	DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: begin", _fx_));

	// Validate input parameters
	ASSERT(plMin);
	ASSERT(plMax);
	ASSERT(plSteppingDelta);
	ASSERT(plDefault);
	ASSERT(plCapsFlags);
	if (!plMin || !plMax || !plSteppingDelta || !plDefault || !plCapsFlags)
	{
		DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: Null pointer argument", _fx_));
		Hr = E_POINTER;
		goto MyExit;
	}
	ASSERT((Property >= TAPICameraControl_Pan && Property <= TAPICameraControl_Focus) || Property == TAPICameraControl_FlipVertical || Property == TAPICameraControl_FlipHorizontal);

	// Update the property and flags
	*plCapsFlags = TAPIControl_Flags_Manual;
	switch (Property)
	{
		case TAPICameraControl_Pan:
		case TAPICameraControl_Tilt:
			*plMin = PAN_TILT_MIN;
			*plMax = PAN_TILT_MAX;
			*plSteppingDelta = PAN_TILT_DELTA;
			*plDefault = PAN_TILT_DEFAULT;
			break;
		case TAPICameraControl_Zoom:
			*plMin = ZOOM_MIN;
			*plMax = ZOOM_MAX;
			*plSteppingDelta = ZOOM_DELTA;
			*plDefault = ZOOM_DEFAULT;
			break;
		case TAPICameraControl_FlipVertical:
		case TAPICameraControl_FlipHorizontal:
			*plMin = 0;
			*plMax = 1;
			*plSteppingDelta = 1;
			*plDefault = 0;
			break;
		default:
			Hr = E_PROP_ID_UNSUPPORTED;
	}

MyExit:
	DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: end", _fx_));
	return Hr;
}

#ifndef USE_SOFTWARE_CAMERA_CONTROL
/****************************************************************************
 *  @doc INTERNAL CCAMERACMETHOD
 *
 *  @mfunc HRESULT | CWDMCapDev | Set | This method is used to set the value
 *    of a camera control setting.
 *
 *  @parm TAPICameraControlProperty | Property | Used to specify the camera
 *    control setting to set the value of. Use a member of the
 *    <t TAPICameraControlProperty> enumerated type.
 *
 *  @parm long | lValue | Used to specify the new value of the camera control
 *    setting.
 *
 *  @parm long | Flags | A member of the <t TAPIControlFlags> enumerated
 *    type.
 *
 *  @rdesc This method returns an HRESULT value that depends on the
 *    implementation of the interface. HRESULT can include one of the
 *    following standard constants, or other values not listed:
 *
 *  @flag E_PROP_ID_UNSUPPORTED | The specified property ID is not supported
 *    for the specified property set
 *  @flag E_INVALIDARG | Invalid argument
 *  @flag NOERROR | No error
 *
 *  @todo Check the range of <p lValue> before remembering it - return
 *    E_INVALIDARG on error in this case
 ***************************************************************************/
STDMETHODIMP CWDMCapDev::Set(IN TAPICameraControlProperty Property, IN long lValue, IN TAPIControlFlags lFlags)
{
	HRESULT Hr = NOERROR;

	FX_ENTRY("CWDMCapDev::Set (CameraControl)")

	DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: begin", _fx_));

	// Validate input parameters
	ASSERT((Property >= TAPICameraControl_Pan && Property <= TAPICameraControl_Focus) || Property == TAPICameraControl_FlipVertical || Property == TAPICameraControl_FlipHorizontal);
	if (!((Property >= TAPICameraControl_Pan && Property <= TAPICameraControl_Focus) || Property == TAPICameraControl_FlipVertical || Property == TAPICameraControl_FlipHorizontal))
	{
		DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: Invalid property argument", _fx_));
		Hr = E_PROP_ID_UNSUPPORTED;
		goto MyExit;
	}
	ASSERT(lFlags == TAPIControl_Flags_Manual || lFlags == TAPIControl_Flags_Auto);
	if (lFlags != TAPIControl_Flags_Manual && lFlags != TAPIControl_Flags_Auto)
	{
		DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: Invalid flag argument", _fx_));
		Hr = E_INVALIDARG;
		goto MyExit;
	}

	// Set the property on the driver
	if (Property >= TAPICameraControl_Pan && Property <= TAPICameraControl_Focus)
	{
		if (FAILED(Hr = SetPropertyValue(PROPSETID_VIDCAP_CAMERACONTROL, (ULONG)Property, lValue, (ULONG)lFlags, (ULONG)lFlags)))
		{
			DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: SetPropertyValue failed", _fx_));
		}
		else
		{
			DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s:   SUCCESS: SetPropertyValue succeeded", _fx_));
		}
	}
	else
	{
		// @todo Put some code here for the flip vertical/horizontal property
		Hr = E_PROP_ID_UNSUPPORTED;
	}

MyExit:
	DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: end", _fx_));
	return Hr;
}

/****************************************************************************
 *  @doc INTERNAL CCAMERACMETHOD
 *
 *  @mfunc HRESULT | CWDMCapDev | Get | This method is used to retrieve the
 *    value of a camera control setting.
 *
 *  @parm TAPICameraControlProperty | Property | Used to specify the camera
 *    control setting to set the value of. Use a member of the
 *    <t TAPICameraControlProperty> enumerated type.
 *
 *  @parm long* | plValue | Used to retrieve the current value of the
 *    camera control setting.
 *
 *  @parm long* | plFlags | Pointer to a member of the <t TAPIControlFlags>
 *    enumerated type.
 *
 *  @rdesc This method returns an HRESULT value that depends on the
 *    implementation of the interface. HRESULT can include one of the
 *    following standard constants, or other values not listed:
 *
 *  @flag E_FAIL | Failure
 *  @flag E_POINTER | Null pointer argument
 *  @flag E_INVALIDARG | Invalid argument
 *  @flag E_PROP_ID_UNSUPPORTED | The specified property ID is not supported
 *    for the specified property set
 *  @flag NOERROR | No error
 ***************************************************************************/
STDMETHODIMP CWDMCapDev::Get(IN TAPICameraControlProperty Property, OUT long *plValue, OUT TAPIControlFlags *plFlags)
{
	HRESULT Hr = NOERROR;
	ULONG ulCapabilities;

	FX_ENTRY("CWDMCapDev::Get (CameraControl)")

	DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: begin", _fx_));

	// Validate input parameters
	ASSERT(plValue);
	ASSERT(plFlags);
	if (!plValue || !plFlags)
	{
		DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: invalid input parameter", _fx_));
		Hr = E_POINTER;
		goto MyExit;
	}
	ASSERT((Property >= TAPICameraControl_Pan && Property <= TAPICameraControl_Focus) || Property == TAPICameraControl_FlipVertical || Property == TAPICameraControl_FlipHorizontal);

	// Get the property from the driver
	if (Property >= TAPICameraControl_Pan && Property <= TAPICameraControl_Focus)
	{
		if (FAILED(Hr = GetPropertyValue(PROPSETID_VIDCAP_CAMERACONTROL, (ULONG)Property, plValue, (PULONG)plFlags, &ulCapabilities)))
		{
			DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: GetPropertyValue failed", _fx_));
		}
		else
		{
			DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s:   SUCCESS: GetPropertyValue succeeded", _fx_));
		}
	}
	else
	{
		// @todo Put some code here for the flip vertical/horizontal property
		Hr = E_PROP_ID_UNSUPPORTED;
	}

MyExit:
	DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: end", _fx_));
	return Hr;
}

/****************************************************************************
 *  @doc INTERNAL CCAMERACMETHOD
 *
 *  @mfunc HRESULT | CWDMCapDev | GetRange | This method is used to retrieve
 *    the minimum, maximum, and default values for specific camera control
 *    settings.
 *
 *  @parm TAPICameraControlProperty | Property | Used to specify the camera
 *    control setting to set the value of. Use a member of the
 *    <t TAPICameraControlProperty> enumerated type.
 *
 *  @parm long* | plMin | Used to retrieve the minimum value of the camera
 *    control setting range.
 *
 *  @parm long* | plMax | Used to retrieve the maximum value of the camera
 *    control setting range.
 *
 *  @parm long* | plSteppingDelta | Used to retrieve the stepping delta of
 *    the camera control setting range.
 *
 *  @parm long* | plDefault | Used to retrieve the default value of the
 *    camera control setting range.
 *
 *  @parm long* | plCapsFlags | Used to retrieve the capabilities of the
 *    camera control setting. Pointer to a member of the
 *    <t TAPIControlFlags> enumerated type.
 *
 *  @rdesc This method returns an HRESULT value that depends on the
 *    implementation of the interface. HRESULT can include one of the
 *    following standard constants, or other values not listed:
 *
 *  @flag E_FAIL | Failure
 *  @flag E_POINTER | Null pointer argument
 *  @flag E_INVALIDARG | Invalid argument
 *  @flag E_PROP_ID_UNSUPPORTED | The specified property ID is not supported
 *    for the specified property set
 *  @flag E_NOTIMPL | Method is not supported
 *  @flag NOERROR | No error
 ***************************************************************************/
STDMETHODIMP CWDMCapDev::GetRange(IN TAPICameraControlProperty Property, OUT long *plMin, OUT long *plMax, OUT long *plSteppingDelta, OUT long *plDefault, OUT TAPIControlFlags *plCapsFlags)
{
	HRESULT Hr = NOERROR;
	LONG  lCurrentValue;
	ULONG ulCurrentFlags;

	FX_ENTRY("CWDMCapDev::GetRange (CameraControl)")

	DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: begin", _fx_));

	// Validate input parameters
	ASSERT(plMin);
	ASSERT(plMax);
	ASSERT(plSteppingDelta);
	ASSERT(plDefault);
	ASSERT(plCapsFlags);
	if (!plMin || !plMax || !plSteppingDelta || !plDefault || !plCapsFlags)
	{
		DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: invalid input parameter", _fx_));
		Hr = E_POINTER;
		goto MyExit;
	}
	ASSERT((Property >= TAPICameraControl_Pan && Property <= TAPICameraControl_Focus) || Property == TAPICameraControl_FlipVertical || Property == TAPICameraControl_FlipHorizontal);

	// Get the range values from the driver
	if (Property >= TAPICameraControl_Pan && Property <= TAPICameraControl_Focus)
	{
		if (FAILED(Hr = GetRangeValues(PROPSETID_VIDCAP_CAMERACONTROL, (ULONG)Property, plMin, plMax, plSteppingDelta)))
		{
			DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: GetRangeValues failed", _fx_));
			goto MyExit;
		}
		else
		{
			DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s:   SUCCESS: GetRangeValues succeeded", _fx_));
		}

		// Get the capability flags from the driver
		if (FAILED(Hr = GetPropertyValue(PROPSETID_VIDCAP_VIDEOPROCAMP, (ULONG)Property, &lCurrentValue, &ulCurrentFlags, (PULONG)plCapsFlags)))
		{
			DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: GetRangeValues failed", _fx_));
			goto MyExit;
		}
		else
		{
			DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s:   SUCCESS: GetRangeValues succeeded", _fx_));
		}

		// Get the default value from the driver
		if (FAILED(Hr = GetDefaultValue(PROPSETID_VIDCAP_CAMERACONTROL, (ULONG)Property, plDefault)))
		{
			DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: GetDefaultValue failed", _fx_));
		}
		else
		{
			DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s:   SUCCESS: GetDefaultValue succeeded", _fx_));
		}
	}
	else
	{
		// @todo Put some code here for the flip vertical/horizontal property
		Hr = E_PROP_ID_UNSUPPORTED;
	}

MyExit:
	DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: end", _fx_));
	return Hr;
}

#endif // USE_SOFTWARE_CAMERA_CONTROL
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\net\tapi\skywalker\filters\video\tapivcap\basepin.cpp ===
/****************************************************************************
 *  @doc INTERNAL BASEPIN
 *
 *  @module BasePin.cpp | Source file for the <c CTAPIBasePin> class methods
 *    used to implement the TAPI base output pin.
 ***************************************************************************/

#include "Precomp.h"

/****************************************************************************
 *  @doc INTERNAL CBASEPINMETHOD
 *
 *  @mfunc HRESULT | CTAPIBasePin | CTAPIBasePin | This method is the
 *  constructorfor the <c CTAPIBasePin> object
 *
 *  @rdesc Nada.
 ***************************************************************************/
CTAPIBasePin::CTAPIBasePin(IN TCHAR *pObjectName, IN CTAPIVCap *pCaptureFilter, IN HRESULT *pHr, IN LPCWSTR pName) : CBaseOutputPin(pObjectName, pCaptureFilter, &pCaptureFilter->m_lock, pHr, pName)
{
        FX_ENTRY("CTAPIBasePin::CTAPIBasePin")

        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: begin", _fx_));

        // Initialize stuff
        m_pCaptureFilter = pCaptureFilter;
        ZeroMemory(&m_parms, sizeof(m_parms));

#ifdef USE_CPU_CONTROL
        // CPU control
        m_MaxProcessingTime = 0;
        m_CurrentProcessingTime = 0;
        m_dwMaxCPULoad = 0;
        m_dwCurrentCPULoad = 0;
#endif

        // Frame rate control
        // Those default values will be fixed up later when we have
        // set a format on a capture device... unless it's a VfW
        // device since we have no programmatic way to get those values
        // from VfW drivers.
        m_lMaxAvgTimePerFrame = 333333L;
        m_lCurrentAvgTimePerFrame       = 333333L;
        m_lAvgTimePerFrameRangeMin = 333333L;
        m_lAvgTimePerFrameRangeMax = 10000000L;
        m_lAvgTimePerFrameRangeSteppingDelta = 333333L;
        m_lAvgTimePerFrameRangeDefault = 333333L;

        // Bitrate control
        m_lTargetBitrate = 0L;
        m_lCurrentBitrate = 0L;
        m_lBitrateRangeMin = 0L;
        m_lBitrateRangeMax = 0L;
        m_lBitrateRangeSteppingDelta = 0L;
        m_lBitrateRangeDefault = 0L;

        // Video mode control
        // @todo This may be fine for VfW devices but not with WDM devices.
        // WDM devices may support this in hardware. You need to query
        // the device to know if it supports this feature. If it doesn't
        // you can still provide a software only implementation for it.
        m_fFlipHorizontal = FALSE;
        m_fFlipVertical = FALSE;

        // Formats
        m_aFormats              = NULL;
        m_aCapabilities = NULL;
        m_dwNumFormats  = 0;
        m_iCurrFormat   = -1L;
        m_fFormatChanged = TRUE;

        // Fast updates - Start with an I-frame
        m_fFastUpdatePicture = TRUE;

        // Format conversion
        m_pConverter = NULL;

        // Blackbanding and cropping vs stretching
        m_fNoImageStretch = FALSE;
        m_dwBlackEntry = 0L;

#ifdef USE_SOFTWARE_CAMERA_CONTROL
        // Software-only camera control
        m_pbyCamCtrl = NULL;
        m_fSoftCamCtrl = FALSE;
        m_pbiSCCOut = NULL;
        m_pbiSCCIn = NULL;
#endif

        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: end", _fx_));
}

/****************************************************************************
 *  @doc INTERNAL CBASEPINMETHOD
 *
 *  @mfunc void | CTAPIBasePin | ~CTAPIBasePin | This method is the destructor
 *    for the <c CTAPIBasePin> object.
 *
 *  @rdesc Nada.
 ***************************************************************************/
CTAPIBasePin::~CTAPIBasePin()
{
        FX_ENTRY("CTAPIBasePin::~CTAPIBasePin")

        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: begin", _fx_));

        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: end", _fx_));
}

/****************************************************************************
 *  @doc INTERNAL CBASEPINMETHOD
 *
 *  @mfunc HRESULT | CTAPIBasePin | NonDelegatingQueryInterface | This
 *    method is the nondelegating interface query function. It returns a
 *    pointer to the specified interface if supported. The only interfaces
 *    explicitly supported being <i IAMStreamConfig>, <i IAMStreamControl>,
 *    <i ICPUControl>, <i IFrameRateControl> and <i IBitrateControl>.
 *
 *  @parm REFIID | riid | Specifies the identifier of the interface to return.
 *
 *  @parm PVOID* | ppv | Specifies the place in which to put the interface
 *    pointer.
 *
 *  @rdesc This method returns an HRESULT value that depends on the
 *    implementation of the interface. HRESULT can include one of the
 *    following standard constants, or other values not listed:
 *
 *  @flag E_FAIL | Failure
 *  @flag E_POINTER | Null pointer argument
 *  @flag NOERROR | No error
 ***************************************************************************/
STDMETHODIMP CTAPIBasePin::NonDelegatingQueryInterface(IN REFIID riid, OUT void **ppv)
{
        HRESULT Hr = NOERROR;

        FX_ENTRY("CTAPIBasePin::NonDelegatingQueryInterface")

        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: begin", _fx_));

        // Validate input parameters
        ASSERT(ppv);
        if (!ppv)
        {
                DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: invalid input parameter", _fx_));
                Hr = E_POINTER;
                goto MyExit;
        }

        // Retrieve interface pointer
        if (riid == __uuidof(IAMStreamConfig))
        {
                if (FAILED(Hr = GetInterface(static_cast<IAMStreamConfig*>(this), ppv)))
                {
                        DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: NDQI for IAMStreamConfig failed Hr=0x%08lX", _fx_, Hr));
                }
                else
                {
                        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s:   SUCCESS: IAMStreamConfig*=0x%08lX", _fx_, *ppv));
                }

                goto MyExit;
        }
#ifdef USE_CPU_CONTROL
        else if (riid == __uuidof(ICPUControl))
        {
                if (FAILED(Hr = GetInterface(static_cast<ICPUControl*>(this), ppv)))
                {
                        DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: NDQI for ICPUControl failed Hr=0x%08lX", _fx_, Hr));
                }
                else
                {
                        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s:   SUCCESS: ICPUControl*=0x%08lX", _fx_, *ppv));
                }

                goto MyExit;
        }
#endif
        else if (riid == __uuidof(IFrameRateControl))
        {
                if (FAILED(Hr = GetInterface(static_cast<IFrameRateControl*>(this), ppv)))
                {
                        DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: NDQI for IFrameRateControl failed Hr=0x%08lX", _fx_, Hr));
                }
                else
                {
                        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s:   SUCCESS: IFrameRateControl*=0x%08lX", _fx_, *ppv));
                }

                goto MyExit;
        }
        else if (riid == __uuidof(IBitrateControl))
        {
                if (FAILED(Hr = GetInterface(static_cast<IBitrateControl*>(this), ppv)))
                {
                        DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: NDQI for IBitrateControl failed Hr=0x%08lX", _fx_, Hr));
                }
                else
                {
                        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s:   SUCCESS: IBitrateControl*=0x%08lX", _fx_, *ppv));
                }

                goto MyExit;
        }
        else if (riid == __uuidof(IVideoControl))
        {
                if (FAILED(Hr = GetInterface(static_cast<IVideoControl*>(this), ppv)))
                {
                        DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: NDQI for IVideoControl failed Hr=0x%08lX", _fx_, Hr));
                }
                else
                {
                        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s:   SUCCESS: IVideoControl*=0x%08lX", _fx_, *ppv));
                }

                goto MyExit;
        }

        if (FAILED(Hr = CBaseOutputPin::NonDelegatingQueryInterface(riid, ppv)))
        {
                DBGOUT((g_dwVideoCaptureTraceID, WARN, "%s:   WARNING: NDQI for {%08lX-%04lX-%04lX-%02lX%02lX-%02lX%02lX%02lX%02lX%02lX%02lX} failed Hr=0x%08lX", _fx_, riid.Data1, riid.Data2, riid.Data3, riid.Data4[0], riid.Data4[1], riid.Data4[2], riid.Data4[3], riid.Data4[4], riid.Data4[5], riid.Data4[6], riid.Data4[7], Hr));
        }
        else
        {
                DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s:   SUCCESS: {%08lX-%04lX-%04lX-%02lX%02lX-%02lX%02lX%02lX%02lX%02lX%02lX}*=0x%08lX", _fx_, riid.Data1, riid.Data2, riid.Data3, riid.Data4[0], riid.Data4[1], riid.Data4[2], riid.Data4[3], riid.Data4[4], riid.Data4[5], riid.Data4[6], riid.Data4[7], *ppv));
        }

MyExit:
        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: end", _fx_));
        return Hr;
}

/****************************************************************************
 *  @doc INTERNAL CBASEPINMETHOD
 *
 *  @mfunc HRESULT | CTAPIBasePin | DecideBufferSize | This method is
 *    used to retrieve the number and size of buffers required for transfer.
 *
 *  @parm IMemAllocator* | pAlloc | Specifies a pointer to the allocator
 *    assigned to the transfer.
 *
 *  @parm ALLOCATOR_PROPERTIES* | ppropInputRequest | Specifies a pointer to an
 *    <t ALLOCATOR_PROPERTIES> structure.
 *
 *  @rdesc This method returns an HRESULT value that depends on the
 *    implementation of the interface. HRESULT can include one of the
 *    following standard constants, or other values not listed:
 *
 *  @flag E_FAIL | Failure
 *  @flag E_POINTER | Null pointer argument
 *  @flag NOERROR | No error
 ***************************************************************************/
HRESULT CTAPIBasePin::DecideBufferSize(IN IMemAllocator *pAlloc, OUT ALLOCATOR_PROPERTIES *ppropInputRequest)
{
        HRESULT Hr = NOERROR;
        ALLOCATOR_PROPERTIES Actual;

        FX_ENTRY("CPreviewPin::DecideBufferSize")

        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: begin", _fx_));

        // Validate input parameters
        ASSERT(pAlloc);
        ASSERT(ppropInputRequest);
        if (!pAlloc || !ppropInputRequest)
        {
                DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: Invalid input parameter!", _fx_));
                Hr = E_POINTER;
                goto MyExit;
        }

        // @todo We shouldn't need that many compressed buffers and you probably need a different number
        // of buffers if you are capturing in streaming mode of frame grabbing mode
        // You also need to decouple this number from the number of video capture buffers: only
        // if you need to ship the video capture buffer downstream (possible on the preview pin)
        // should you make those number equal.
        ppropInputRequest->cBuffers = MAX_VIDEO_BUFFERS;
        ppropInputRequest->cbPrefix = 0;
        ppropInputRequest->cbAlign  = 1;
        ppropInputRequest->cbBuffer = HEADER(m_mt.pbFormat)->biSizeImage;
        ppropInputRequest->cbBuffer = (long)ALIGNUP(ppropInputRequest->cbBuffer + ppropInputRequest->cbPrefix, ppropInputRequest->cbAlign) - ppropInputRequest->cbPrefix;

        ASSERT(ppropInputRequest->cbBuffer);
        if (!ppropInputRequest->cbBuffer)
        {
                DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: Buffer size is 0!", _fx_));
                Hr = E_FAIL;
                goto MyExit;
        }

        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s:   Using %d buffers, prefix %d size %d align %d", _fx_, ppropInputRequest->cBuffers, ppropInputRequest->cbPrefix, ppropInputRequest->cbBuffer, ppropInputRequest->cbAlign));

        Hr = pAlloc->SetProperties(ppropInputRequest,&Actual);

MyExit:
        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: end", _fx_));
        return Hr;
}

/****************************************************************************
 *  @doc INTERNAL CBASEPINMETHOD
 *
 *  @mfunc HRESULT | CTAPIBasePin | DecideAllocator | This method is
 *    used to negotiate the allocator to use.
 *
 *  @parm IMemInputPin* | pPin | Specifies a pointer to the IPin interface
 *    of the connecting pin.
 *
 *  @parm IMemAllocator** | ppAlloc | Specifies a pointer to the negotiated
 *    IMemAllocator interface.
 *
 *  @rdesc This method returns an HRESULT value that depends on the
 *    implementation of the interface. HRESULT can include one of the
 *    following standard constants, or other values not listed:
 *
 *  @flag E_FAIL | Failure
 *  @flag E_POINTER | Null pointer argument
 *  @flag NOERROR | No error
 ***************************************************************************/
HRESULT CTAPIBasePin::DecideAllocator(IN IMemInputPin *pPin, OUT IMemAllocator **ppAlloc)
{
        HRESULT Hr = NOERROR;
        ALLOCATOR_PROPERTIES prop;

        FX_ENTRY("CTAPIBasePin::DecideAllocator")

        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: begin", _fx_));

        // Validate input parameters
        ASSERT(pPin);
        ASSERT(ppAlloc);
        if (!pPin || !ppAlloc)
        {
                DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: Invalid input parameter!", _fx_));
                Hr = E_POINTER;
                goto MyExit;
        }

        if (FAILED(GetInterface(static_cast<IMemAllocator*>(this), (void **)ppAlloc)))
        {
                DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: GetInterface failed!", _fx_));
                Hr = E_FAIL;
                goto MyExit;
        }

        // Get downstream allocator property requirement
        ZeroMemory(&prop, sizeof(prop));

        if (SUCCEEDED(Hr = DecideBufferSize(*ppAlloc, &prop)))
        {
                // Our buffers are not read only
                if (SUCCEEDED(Hr = pPin->NotifyAllocator(*ppAlloc, FALSE)))
                        goto MyExit;
        }

        (*ppAlloc)->Release();
        *ppAlloc = NULL;

MyExit:
        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: end", _fx_));
        return Hr;
}

/****************************************************************************
 *  @doc INTERNAL CBASEPINMETHOD
 *
 *  @mfunc HRESULT | CTAPIBasePin | Active | This method is called by the
 *    <c CBaseFilter> implementation when the state changes from stopped to
 *    either paused or running.
 *
 *  @rdesc This method returns an HRESULT value that depends on the
 *    implementation of the interface. HRESULT can include one of the
 *    following standard constants, or other values not listed:
 *
 *  @flag E_FAIL | Failure
 *  @flag NOERROR | No error
 ***************************************************************************/
HRESULT CTAPIBasePin::Active()
{
        HRESULT Hr = NOERROR;

        FX_ENTRY("CTAPIBasePin::Active")

        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: begin", _fx_));

        // Do nothing if not connected -- but don't fail
        if (!IsConnected())
        {
                DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s:   WARNING: Capture pin isn't connected yet", _fx_));
                goto MyExit;
        }

        // Let the base class know we're going from STOP->PAUSE
        if (FAILED(Hr = CBaseOutputPin::Active()))
        {
                DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: CBaseOutputPin::Active failed!", _fx_));
                goto MyExit;
        }

        // Check if we're already running
        if (m_pCaptureFilter->ThdExists())
        {
                DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s:   WARNING: We're already running", _fx_));
                goto MyExit;
        }

        // Create the capture thread
        if (!m_pCaptureFilter->CreateThd())
        {
                DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: Coutdn't create the capture thread!", _fx_));
                Hr = E_FAIL;
                goto MyExit;
        }

        // Wait until the worker thread is done with initialization and has entered the paused state
        if (!m_pCaptureFilter->PauseThd())
        {
                // Something went wrong. Destroy thread before we get confused
                DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: Capture thread failed to enter Paused state!", _fx_));
                Hr = E_FAIL;
                m_pCaptureFilter->StopThd();            
                m_pCaptureFilter->DestroyThd();
                goto MyExit;
        }

        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s:   SUCCESS: We're going from STOP->PAUSE", _fx_));

MyExit:
        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: end", _fx_));
        return Hr;
}

/****************************************************************************
 *  @doc INTERNAL CBASEPINMETHOD
 *
 *  @mfunc HRESULT | CTAPIBasePin | Inactive | This method is called by the
 *    <c CBaseFilter> implementation when the state changes from either
 *    paused or running to stopped.
 *
 *  @rdesc This method returns an HRESULT value that depends on the
 *    implementation of the interface. HRESULT can include one of the
 *    following standard constants, or other values not listed:
 *
 *  @flag E_FAIL | Failure
 *  @flag NOERROR | No error
 ***************************************************************************/
HRESULT CTAPIBasePin::Inactive()
{
        HRESULT Hr = NOERROR;

        FX_ENTRY("CTAPIBasePin::Inactive")

        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: begin", _fx_));

        // Do nothing if not connected -- but don't fail
        if (!IsConnected())
        {
                DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s:   WARNING: Capture pin isn't connected yet", _fx_));
                goto MyExit;
        }

        // Tell the worker thread to stop and begin cleaning up
        m_pCaptureFilter->StopThd();

        // Need to do this before trying to stop the thread, because
        // we may be stuck waiting for our own allocator!!
        // Call this first to Decommit the allocator
        if (FAILED(Hr = CBaseOutputPin::Inactive()))
        {
                DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: CBaseOutputPin::Inactive failed!", _fx_));
                goto MyExit;
        }

        // Wait for the worker thread to die
        m_pCaptureFilter->DestroyThd();

        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s:   SUCCESS: We're going from PAUSE->STOP", _fx_));

MyExit:
        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: end", _fx_));
        return Hr;
}

/****************************************************************************
 *  @doc INTERNAL CBASEPINMETHOD
 *
 *  @mfunc HRESULT | CTAPIBasePin | ActiveRun | This method is called by the
 *    <c CBaseFilter> implementation when the state changes from paused to
 *    running mode.
 *
 *  @parm REFERENCE_TIME | tStart | Who cares.
 *
 *  @rdesc This method returns an HRESULT value that depends on the
 *    implementation of the interface. HRESULT can include one of the
 *    following standard constants, or other values not listed:
 *
 *  @flag E_FAIL | Failure
 *  @flag NOERROR | No error
 ***************************************************************************/
HRESULT CTAPIBasePin::ActiveRun(IN REFERENCE_TIME tStart)
{
        HRESULT Hr = NOERROR;

        FX_ENTRY("CTAPIBasePin::ActiveRun")

        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: begin", _fx_));

        // Make sure we're connected and our capture thread is up
        ASSERT(IsConnected());
        ASSERT(m_pCaptureFilter->ThdExists());
        if (!IsConnected() || !m_pCaptureFilter->ThdExists())
        {
                DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: Pin isn't connected or capture thread hasn't been created!", _fx_));
                Hr = E_FAIL;
                goto MyExit;
        }

        // Let the fun begin
        if (!m_pCaptureFilter->RunThd() || m_pCaptureFilter->m_state != TS_Run)
        {
                DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: Couldn't run the capture thread!", _fx_));
                Hr = E_FAIL;
                goto MyExit;
        }

        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s:   SUCCESS: We're going from PAUSE->RUN", _fx_));

        // Fast updates - Start with an I-frame
        m_fFastUpdatePicture = TRUE;

MyExit:
        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: end", _fx_));
        return Hr;
}

/****************************************************************************
 *  @doc INTERNAL CBASEPINMETHOD
 *
 *  @mfunc HRESULT | CTAPIBasePin | ActivePause | This method is called by the
 *    <c CBaseFilter> implementation when the state changes from running to
 *    paused mode.
 *
 *  @rdesc This method returns an HRESULT value that depends on the
 *    implementation of the interface. HRESULT can include one of the
 *    following standard constants, or other values not listed:
 *
 *  @flag E_FAIL | Failure
 *  @flag NOERROR | No error
 ***************************************************************************/
HRESULT CTAPIBasePin::ActivePause()
{
        HRESULT Hr = NOERROR;

        FX_ENTRY("CTAPIBasePin::ActivePause")

        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: begin", _fx_));

        // Make sure we're connected and our worker thread is up
        ASSERT(IsConnected());
        ASSERT(m_pCaptureFilter->ThdExists());
        if (!IsConnected() || !m_pCaptureFilter->ThdExists())
        {
                DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: Pin isn't connected or capture thread hasn't been created!", _fx_));
                Hr = E_FAIL;
                goto MyExit;
        }

        // Pause the fun
        if (!m_pCaptureFilter->PauseThd() || m_pCaptureFilter->m_state != TS_Pause)
        {
                DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: Couldn't pause the capture thread!", _fx_));
                Hr = E_FAIL;
                goto MyExit;
        }

        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s:   SUCCESS: We're going from RUN->PAUSE", _fx_));

MyExit:
        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: end", _fx_));
        return Hr;
}

/****************************************************************************
 *  @doc INTERNAL CBASEPINMETHOD
 *
 *  @mfunc HRESULT | CTAPIBasePin | SetProperties | This method is used to
 *    specify the size, number, and alignment of blocks.
 *
 *  @parm ALLOCATOR_PROPERTIES* | pRequest | Specifies a pointer to the
 *    requested allocator properties.
 *
 *  @parm ALLOCATOR_PROPERTIES* | pActual | Specifies a pointer to the
 *    allocator properties actually set.
 *
 *  @rdesc This method returns an HRESULT value that depends on the
 *    implementation of the interface. HRESULT can include one of the
 *    following standard constants, or other values not listed:
 *
 *  @flag E_FAIL | Failure
 *  @flag E_POINTER | Null pointer argument
 *  @flag NOERROR | No error
 ***************************************************************************/
STDMETHODIMP CTAPIBasePin::SetProperties(IN ALLOCATOR_PROPERTIES *pRequest, OUT ALLOCATOR_PROPERTIES *pActual)
{
        HRESULT Hr = NOERROR;

        FX_ENTRY("CTAPIBasePin::SetProperties")

        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: begin", _fx_));

        // Validate input parameters
        ASSERT(pRequest);
        ASSERT(pActual);
        if (!pRequest || !pActual)
        {
                DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: Null pointer argument!", _fx_));
                Hr = E_POINTER;
                goto MyExit;
        }

        // If we have already allocated headers & buffers ignore the
        // requested and return the actual numbers. Otherwise, make a
        // note of the requested so that we can honour it later.
        if (!Committed())
        {
                m_parms.cBuffers  = pRequest->cBuffers;
                m_parms.cbBuffer  = pRequest->cbBuffer;
                m_parms.cbAlign   = pRequest->cbAlign;
                m_parms.cbPrefix  = pRequest->cbPrefix;
        }

        pActual->cBuffers   = (long)m_parms.cBuffers;
        pActual->cbBuffer   = (long)m_parms.cbBuffer;
        pActual->cbAlign    = (long)m_parms.cbAlign;
        pActual->cbPrefix   = (long)m_parms.cbPrefix;

MyExit:
        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: end", _fx_));
        return Hr;
}

/****************************************************************************
 *  @doc INTERNAL CBASEPINMETHOD
 *
 *  @mfunc HRESULT | CTAPIBasePin | GetProperties | This method is used to
 *    retrieve the properties being used on this allocator.
 *
 *  @parm ALLOCATOR_PROPERTIES* | pProps | Specifies a pointer to the
 *    requested allocator properties.
 *
 *  @rdesc This method returns an HRESULT value that depends on the
 *    implementation of the interface. HRESULT can include one of the
 *    following standard constants, or other values not listed:
 *
 *  @flag E_FAIL | Failure
 *  @flag E_POINTER | Null pointer argument
 *  @flag NOERROR | No error
 ***************************************************************************/
STDMETHODIMP CTAPIBasePin::GetProperties(ALLOCATOR_PROPERTIES *pProps)
{
        HRESULT Hr = NOERROR;

        FX_ENTRY("CTAPIBasePin::GetProperties")

        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: begin", _fx_));

        // Validate input parameters
        ASSERT(pProps);
        if (!pProps)
        {
                DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: Null pointer argument!", _fx_));
                Hr = E_POINTER;
                goto MyExit;
        }

        pProps->cBuffers = (long)m_parms.cBuffers;
        pProps->cbBuffer = (long)m_parms.cbBuffer;
        pProps->cbAlign  = (long)m_parms.cbAlign;
        pProps->cbPrefix = (long)m_parms.cbPrefix;

MyExit:
        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: end", _fx_));
        return Hr;
}

/****************************************************************************
 *  @doc INTERNAL CBASEPINMETHOD
 *
 *  @mfunc HRESULT | CTAPIBasePin | Commit | This method is used to
 *    commit the memory for the specified buffers.
 *
 *  @rdesc This method returns S_OK.
 ***************************************************************************/
STDMETHODIMP CTAPIBasePin::Commit()
{
        FX_ENTRY("CTAPIBasePin::Commit")

        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: begin", _fx_));

        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: end", _fx_));

        return S_OK;
}

/****************************************************************************
 *  @doc INTERNAL CBASEPINMETHOD
 *
 *  @mfunc HRESULT | CTAPIBasePin | Decommit | This method is used to
 *    release the memory for the specified buffers.
 *
 *  @rdesc This method returns S_OK.
 ***************************************************************************/
STDMETHODIMP CTAPIBasePin::Decommit()
{
        FX_ENTRY("CTAPIBasePin::Decommit")

        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: begin", _fx_));

        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: end", _fx_));

        return S_OK;
}

/****************************************************************************
 *  @doc INTERNAL CBASEPINMETHOD
 *
 *  @mfunc HRESULT | CTAPIBasePin | GetBuffer | This method is used to
 *    retrieve a container for a sample.
 *
 *  @rdesc This method returns E_FAIL.
 ***************************************************************************/
STDMETHODIMP CTAPIBasePin::GetBuffer(IMediaSample **ppBuffer, REFERENCE_TIME *pStartTime, REFERENCE_TIME *pEndTime, DWORD dwFlags)
{
        FX_ENTRY("CTAPIBasePin::GetBuffer")

        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: begin", _fx_));

        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: end", _fx_));

        return E_FAIL;
}

/****************************************************************************
 *  @doc INTERNAL CBASEPINMETHOD
 *
 *  @mfunc HRESULT | CTAPIBasePin | ReleaseBuffer | This method is used to
 *    release the <c CMediaSample> object. The final call to Release() on
 *    <i IMediaSample> will call this method.
 *
 *  @parm IMediaSample* | pSample | Specifies a pointer to the buffer to
 *    release.
 *
 *  @rdesc This method returns an HRESULT value that depends on the
 *    implementation of the interface. HRESULT can include one of the
 *    following standard constants, or other values not listed:
 *
 *  @flag E_FAIL | Failure
 *  @flag E_POINTER | Null pointer argument
 *  @flag S_OK | No error
 ***************************************************************************/
STDMETHODIMP CTAPIBasePin::ReleaseBuffer(IMediaSample *pSample)
{
        HRESULT Hr = S_OK;
        LPTHKVIDEOHDR ptvh;

        FX_ENTRY("CTAPIBasePin::ReleaseBuffer")

        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: begin", _fx_));

        // Validate input parameters
        ASSERT(pSample);
        if (!pSample)
        {
                DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: Null pointer argument!", _fx_));
                Hr = E_POINTER;
                goto MyExit;
        }

        if (ptvh = ((CFrameSample *)pSample)->GetFrameHeader())
                Hr = m_pCaptureFilter->ReleaseFrame(ptvh);

MyExit:
        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: end", _fx_));
        return Hr;
}

/****************************************************************************
 *  @doc INTERNAL CBASEPINMETHOD
 *
 *  @mfunc DWORD | CTAPIBasePin | Flush | Called when stopping. Flush any
 *    buffers that may be still downstream.
 *
 *  @rdesc Returns NOERROR
 ***************************************************************************/
HRESULT CTAPIBasePin::Flush()
{
        FX_ENTRY("CTAPIBasePin::Flush")

        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: begin", _fx_));

        BeginFlush();
        EndFlush();

        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: end", _fx_));
        return NOERROR;
}

/****************************************************************************
 *  @doc INTERNAL CBASEPINMETHOD
 *
 *  @mfunc HRESULT | CTAPIBasePin | SendFrame | This method is used to
 *    send a a media sample downstream.
 *
 *  @parm CFrameSample | pSample | Specifies a pointer to the media sample
 *    to send downstream.
 *
 *  @parm LPTHKVIDEOHDR | ptvh | Specifies a pointer to the video header
 *    of the video capture buffer associated to this sample.
 *
 *  @parm PDWORD | pdwBytesUsed | Specifies a pointer to a DWORD to receive
 *    the size of the frame that has been delivered downstream.
 *
 *  @parm BOOL | bDiscon | Set to TRUE if this is the first frame we ever
 *    sent downstream.
 *
 *  @rdesc This method returns an HRESULT value that depends on the
 *    implementation of the interface. HRESULT can include one of the
 *    following standard constants, or other values not listed:
 *
 *  @flag E_FAIL | Failure
 *  @flag E_POINTER | Null pointer argument
 *  @flag S_OK | No error
 *  @flag S_FALSE | If the pin is off (IAMStreamControl)
 *  @flag NOERROR | No error
 ***************************************************************************/
HRESULT CTAPIBasePin::SendFrame(IN CFrameSample *pSample, IN PBYTE pbyInBuff, IN DWORD dwInBytes, OUT PDWORD pdwBytesUsed, OUT PDWORD pdwBytesExtent, IN BOOL bDiscon)
{
        HRESULT Hr = NOERROR;
        DWORD dwBytesUsed;
    LPBYTE lp;

        FX_ENTRY("CTAPIBasePin::SendFrame")

        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: begin", _fx_));

        // Validate input parameters
        ASSERT(pSample);
        ASSERT(pbyInBuff);
        ASSERT(pdwBytesUsed);
        if (!pSample || !pbyInBuff || !pdwBytesUsed)
        {
                DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: Null pointer argument!", _fx_));
                Hr = E_POINTER;
                goto MyExit;
        }

        // Process the video capture buffer before sending it downstream, if necessary
        if (m_pConverter)
        {
                dwBytesUsed = 0;

                if (SUCCEEDED(Hr = pSample->GetPointer(&lp)))
                {
                        Hr = m_pConverter->ConvertFrame(pbyInBuff, dwInBytes, lp, &dwBytesUsed, pdwBytesExtent, NULL, NULL, m_fFastUpdatePicture);
                        m_fFastUpdatePicture = FALSE;

            if (FAILED(Hr))
            {
                                goto MyExit;
                        }
                }
        }
        else
        {
                dwBytesUsed = dwInBytes;

#ifdef USE_SOFTWARE_CAMERA_CONTROL
                // Do we need to apply any software-only camera control operations?
                if (IsSoftCamCtrlNeeded())
                {
                        // If the software-only camera controller isn't opened yet, open it
                        if (!IsSoftCamCtrlOpen())
                        {
                                // OpenConverter(HEADER(m_user.pvi), HEADER(m_pPreviewPin->m_mt.pbFormat)));
                                OpenSoftCamCtrl(HEADER(m_pCaptureFilter->m_user.pvi), HEADER(m_mt.pbFormat));
                        }
                        
                        if (IsSoftCamCtrlOpen())
                        {
                                // In this case, the input is RGB24 and the output is RGB24. The sample
                                // pointer has already been initialized to the video capture buffer.
                                // We need to apply the transform to the capture buffer and copy
                                // back the result on this buffer.
                                ApplySoftCamCtrl(pbyInBuff, dwInBytes, m_pbyCamCtrl, &dwBytesUsed, pdwBytesExtent);

                                // Remember the current data pointer
                                pSample->GetPointer(&lp);

                                // Set a new pointer
                                pSample->SetPointer(m_pbyCamCtrl, dwBytesUsed);
                        }
                }
                else
                {
                        // If we had a software-only camera controller but we don't
                        // need it anymore, just close it
                        if (IsSoftCamCtrlOpen())
                                CloseSoftCamCtrl();
                }
#endif
        }

        if (dwBytesUsed)
        {
                // It isn't necessarily a keyframe, but who cares?
                pSample->SetSyncPoint(TRUE);
                pSample->SetActualDataLength(dwBytesUsed);
                pSample->SetDiscontinuity(bDiscon);
                pSample->SetPreroll(FALSE);

                // Let the downstream pin know about the format change
                if (m_fFormatChanged)
                {
                        pSample->SetMediaType(&m_mt);
                        m_fFormatChanged = FALSE;
                }

                // Use the clock's graph to mark the times for the samples.  The video
                // capture card's clock is going to drift from the graph clock, so you'll
                // think we're dropping frames or sending too many frames if you look at
                // the time stamps, so we have an agreement to mark the MediaTime with the
                // frame number so you can tell if any frames are dropped.
                // Use the time we got in Run() to determine the stream time.  Also add
                // a latency (HACK!) to prevent preview renderers from thinking we're
                // late.
                // If we are RUN, PAUSED, RUN, we won't send stuff smoothly where we
                // left off because of the async nature of pause.
                CRefTime rtSample;
                CRefTime rtEnd;
                if (m_pCaptureFilter->m_pClock)
                {
                        rtSample = m_pCaptureFilter->m_cs.rtThisFrameTime - m_pCaptureFilter->m_tStart;
                        rtEnd = rtSample + m_lMaxAvgTimePerFrame;
                        pSample->SetTime((REFERENCE_TIME *)&rtSample, (REFERENCE_TIME *)&rtEnd);
                        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s:   Stream time is %d", _fx_, (LONG)rtSample.Millisecs()));
                }
                else
                {
                        // No clock, use our driver time stamps
                        rtSample = m_pCaptureFilter->m_cs.rtThisFrameTime - m_pCaptureFilter->m_tStart;
                        rtEnd    = rtSample + m_pCaptureFilter->m_user.pvi->AvgTimePerFrame;
                        pSample->SetTime((REFERENCE_TIME *)&rtSample, (REFERENCE_TIME *)&rtEnd);
                        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s:   No graph clock! Stream time is %d (based on driver time)", _fx_, (LONG)rtSample.Millisecs()));
                }

                // Don't deliver it if the stream is off for now
                int iStreamState = CheckStreamState(pSample);
                if (iStreamState == STREAM_FLOWING)
                {
                        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s:   Sending frame: Stamps(%u): Time(%d,%d)", _fx_, m_pCaptureFilter->m_pBufferQueue[m_pCaptureFilter->m_uiQueueTail], (LONG)rtSample.Millisecs(), (LONG)rtEnd.Millisecs()));
                        if ((Hr = Deliver (pSample)) == S_FALSE)
                                Hr = E_FAIL;    // stop delivering anymore, this is serious
                }
                else
                {
                        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s:   Discarding frame", _fx_));
                        Hr = S_FALSE;           // discarding
                }

#ifdef USE_SOFTWARE_CAMERA_CONTROL
                // Restore the sample pointers if necessary
                if (IsSoftCamCtrlOpen())
                {
                        pSample->SetPointer(lp, dwInBytes);
                }
#endif
        }
        else
        {
                DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: BUFFER (%08lX %ld %lu) returned EMPTY!", _fx_, pSample));
        }

        *pdwBytesUsed = dwBytesUsed;

MyExit:
        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: end", _fx_));
        return Hr;
}

/****************************************************************************
 *  @doc INTERNAL CCONVERTMETHOD
 *
 *  @mfunc HRESULT | CTAPIBasePin | OpenConverter | This method opens a format
 *    converter.
 *
 *  @parm PBITMAPINFOHEADER | pbiIn | Pointer to the input format.
 *
 *  @parm PBITMAPINFOHEADER | pbiOut | Pointer to the output format.
 *
 *  @rdesc This method returns an HRESULT value that depends on the
 *    implementation of the interface. HRESULT can include one of the
 *    following standard constants, or other values not listed:
 *
 *  @flag E_FAIL | Failure
 *  @flag E_POINTER | Null pointer argument
 *  @flag NOERROR | No error
 ***************************************************************************/
HRESULT CTAPIBasePin::OpenConverter(IN PBITMAPINFOHEADER pbiIn, IN PBITMAPINFOHEADER pbiOut)
{
        HRESULT Hr = NOERROR;

        FX_ENTRY("CTAPIBasePin::OpenConverter")

        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: begin", _fx_));

        ASSERT(!m_pConverter);

        // Create converter
        if ((pbiOut->biCompression == FOURCC_M263) || (pbiOut->biCompression == FOURCC_M261))
                Hr = CH26XEncoder::CreateH26XEncoder(this, pbiIn, pbiOut, &m_pConverter);
        else
                Hr = CICMConverter::CreateICMConverter(this, pbiIn, pbiOut, &m_pConverter);
        if (FAILED(Hr))
        {
                DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: Format converter object couldn't be created", _fx_));
                m_pConverter = NULL;
                goto MyExit;
        }

        // Open converter
        if (FAILED(Hr = m_pConverter->OpenConverter()))
        {
                DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: Format converter object couldn't be opened", _fx_));
                delete m_pConverter, m_pConverter = NULL;
        }

MyExit:
        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: end", _fx_));
        return Hr;
}

/****************************************************************************
 *  @doc INTERNAL CCONVERTMETHOD
 *
 *  @mfunc HRESULT | CTAPIBasePin | CloseConverter | This method closes a
 *    format converter.

 *  @rdesc This method returns NOERROR.
 ***************************************************************************/
HRESULT CTAPIBasePin::CloseConverter()
{
        FX_ENTRY("CTAPIBasePin::CloseConverter")

        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: begin", _fx_));

        // Destroy converter
        if (m_pConverter)
        {
                m_pConverter->CloseConverter();
                delete m_pConverter, m_pConverter = NULL;
        }

        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: end", _fx_));

        return NOERROR;
}
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\net\tapi\skywalker\filters\video\tapivcap\cameracp.cpp ===
/****************************************************************************
 *  @doc INTERNAL CAMERACP
 *
 *  @module CameraCP.cpp | Source file for the <c CCameraControlProperty>
 *    class used to implement a property page to test the TAPI interface
 *    <i ICameraControl>.
 *
 *  @comm This code tests the TAPI Video Capture filter <i ICameraControl>
 *    implementation. This code is only compiled if USE_PROPERTY_PAGES is
 *    defined.
 ***************************************************************************/

#include "Precomp.h"

#ifdef USE_PROPERTY_PAGES

#ifdef USE_SOFTWARE_CAMERA_CONTROL

/****************************************************************************
 *  @doc INTERNAL CCAMERACPMETHOD
 *
 *  @mfunc void | CCameraControlProperty | CCameraControlProperty | This
 *    method is the constructor for camera control property objects. It
 *    calls the base class constructor, calls InitCommonControlsEx, and saves
 *    a pointer to the <i ICameraControl> interface.
 *
 *  @parm HWND | hDlg | Specifies a handle to the parent property page.
 *
 *  @parm ULONG | IDLabel | Specifies a label ID for the property.
 *
 *  @parm ULONG | IDMinControl | Specifies a label ID for the associated
 *    property edit control where the Minimum value of the property appears.
 *
 *  @parm ULONG | IDMaxControl | Specifies a label ID for the associated
 *    property edit control where the Maximum value of the property appears.
 *
 *  @parm ULONG | IDDefaultControl | Specifies a label ID for the associated
 *    property edit control where the Default value of the property appears.
 *
 *  @parm ULONG | IDStepControl | Specifies a label ID for the associated
 *    property edit control where the Stepping Delta value of the property appears.
 *
 *  @parm ULONG | IDEditControl | Specifies a label ID for the associated
 *    property edit control where the value of the property appears.
 *
 *  @parm ULONG | IDTrackbarControl | Specifies a label ID for the associated
 *    property slide bar.
 *
 *  @parm ULONG | IDProgressControl | Specifies a label ID for the associated
 *    property progress bar.
 *
 *  @parm ULONG | IDProperty | Specifies the ID of the Ks property.
 *
 *  @parm ICameraControl* | pInterface | Specifies a pointer to the
 *    <i ICameraControl> interface.
 *
 *  @rdesc Nada.
 ***************************************************************************/
CCameraControlProperty::CCameraControlProperty(HWND hDlg, ULONG IDLabel, ULONG IDMinControl, ULONG IDMaxControl, ULONG IDDefaultControl, ULONG IDStepControl, ULONG IDEditControl, ULONG IDTrackbarControl, ULONG IDProgressControl, ULONG IDProperty, ULONG IDAutoControl, ICameraControl *pInterface)
: CPropertyEditor(hDlg, IDLabel, IDMinControl, IDMaxControl, IDDefaultControl, IDStepControl, IDEditControl, IDTrackbarControl, IDProgressControl, IDProperty, IDAutoControl)
{
	INITCOMMONCONTROLSEX cc;

	FX_ENTRY("CCameraControlProperty::CCameraControlProperty")

	DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: begin", _fx_));

	cc.dwSize = sizeof (INITCOMMONCONTROLSEX);
	cc.dwICC  = ICC_UPDOWN_CLASS | ICC_BAR_CLASSES;

	InitCommonControlsEx(&cc);

	// It's fine if the interface pointer is NULL, we'll grey the
	// associated items in the property page
	m_pInterface = pInterface;

	DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: end", _fx_));
}

/****************************************************************************
 *  @doc INTERNAL CCAMERACPMETHOD
 *
 *  @mfunc void | CCameraControlProperty | ~CCameraControlProperty | This
 *    method is the destructor for camera control property objects. It
 *    simply calls the base class destructor.
 *
 *  @rdesc Nada.
 ***************************************************************************/
CCameraControlProperty::~CCameraControlProperty()
{
	FX_ENTRY("CCameraControlProperty::~CCameraControlProperty")

	DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: begin", _fx_));

	DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: end", _fx_));
}

/****************************************************************************
 *  @doc INTERNAL CCAMERACPMETHOD
 *
 *  @mfunc HRESULT | CCameraControlProperty | GetValue | This method queries for
 *    the value of a property.
 *
 *  @rdesc This method returns an HRESULT value that depends on the
 *    implementation of the interface. HRESULT can include one of the
 *    following standard constants, or other values not listed:
 *
 *  @flag E_FAIL | Failure
 *  @flag E_POINTER | Null pointer argument
 *  @flag E_NOTIMPL | Method is not supported
 *  @flag NOERROR | No error
 ***************************************************************************/
HRESULT CCameraControlProperty::GetValue()
{
	HRESULT Hr = NOERROR;

	FX_ENTRY("CCameraControlProperty::GetValue")

	DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: begin", _fx_));

	// Validate input parameters
	if (!m_pInterface)
	{
		DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: invalid input parameter", _fx_));
		Hr = E_FAIL;
		goto MyExit;
	}

	if (SUCCEEDED (Hr = m_pInterface->Get((TAPICameraControlProperty)m_IDProperty, &m_CurrentValue, (TAPIControlFlags *)&m_CurrentFlags)))
	{
		DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s:   SUCCESS: m_CurrentValue=%ld, m_CurrentFlags=%ld", _fx_, m_CurrentValue, m_CurrentFlags));
	}
	else
	{
		DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: m_pICameraControl->Get failed Hr=0x%08lX", _fx_, Hr));
	}

MyExit:
	DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: end", _fx_));
	return Hr;
}

/****************************************************************************
 *  @doc INTERNAL CCAMERACPMETHOD
 *
 *  @mfunc HRESULT | CCameraControlProperty | SetValue | This method sets the
 *    value of a property.
 *
 *  @rdesc This method returns an HRESULT value that depends on the
 *    implementation of the interface. HRESULT can include one of the
 *    following standard constants, or other values not listed:
 *
 *  @flag E_FAIL | Failure
 *  @flag E_POINTER | Null pointer argument
 *  @flag E_NOTIMPL | Method is not supported
 *  @flag NOERROR | No error
 ***************************************************************************/
HRESULT CCameraControlProperty::SetValue()
{
	HRESULT Hr = NOERROR;

	FX_ENTRY("CCameraControlProperty::SetValue")

	DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: begin", _fx_));

	// Validate input parameters
	if (!m_pInterface)
	{
		DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: invalid input parameter", _fx_));
		Hr = E_FAIL;
		goto MyExit;
	}

	if (SUCCEEDED (Hr = m_pInterface->Set((TAPICameraControlProperty)m_IDProperty, m_CurrentValue, (TAPIControlFlags)m_CurrentFlags)))
	{
		DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s:   SUCCESS: m_CurrentValue=%ld, m_CurrentFlags=%ld", _fx_, m_CurrentValue, m_CurrentFlags));
	}
	else
	{
		DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: m_pICameraControl->Set failed Hr=0x%08lX", _fx_, Hr));
	}

MyExit:
	DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: end", _fx_));
	return Hr;
}

/****************************************************************************
 *  @doc INTERNAL CCAMERACPMETHOD
 *
 *  @mfunc HRESULT | CCameraControlProperty | GetRange | This method retrieves
 *    the range information of a property.
 *
 *  @rdesc This method returns an HRESULT value that depends on the
 *    implementation of the interface. HRESULT can include one of the
 *    following standard constants, or other values not listed:
 *
 *  @flag E_FAIL | Failure
 *  @flag E_POINTER | Null pointer argument
 *  @flag E_NOTIMPL | Method is not supported
 *  @flag NOERROR | No error
 ***************************************************************************/
HRESULT CCameraControlProperty::GetRange()
{
	HRESULT Hr = NOERROR;

	FX_ENTRY("CCameraControlProperty::GetRange")

	DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: begin", _fx_));

	// Validate input parameters
	if (!m_pInterface)
	{
		DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: invalid input parameter", _fx_));
		Hr = E_FAIL;
		goto MyExit;
	}

	if (SUCCEEDED (Hr = m_pInterface->GetRange((TAPICameraControlProperty)m_IDProperty, &m_Min, &m_Max, &m_SteppingDelta, &m_DefaultValue, (TAPIControlFlags *)&m_CapsFlags)))
	{
		DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s:   SUCCESS: m_Min=%ld, m_Max=%ld, m_SteppingDelta=%ld, m_DefaultValue=%ld, m_CapsFlags=%ld", _fx_, m_Min, m_Max, m_SteppingDelta, m_DefaultValue, m_CapsFlags));
	}
	else
	{
		DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: m_pICameraControl->GetRange failed Hr=0x%08lX", _fx_, Hr));
	}
	m_DefaultFlags = m_CapsFlags;

MyExit:
	DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: end", _fx_));
	return Hr;
}

/****************************************************************************
 *  @doc INTERNAL CCAMERACPMETHOD
 *
 *  @mfunc CUnknown* | CCameraControlProperties | CreateInstance | This
 *    method is called by DShow to create an instance of a
 *    Property Page. It is referred to in the global structure <t g_Templates>.
 *
 *  @parm LPUNKNOWN | pUnkOuter | Specifies the outer unknown, if any.
 *
 *  @parm HRESULT* | pHr | Specifies the place in which to put any error return.
 *
 *  @rdesc Returns a pointer to the nondelegating CUnknown portion of the
 *    object, or NULL otherwise.
 ***************************************************************************/
CUnknown* CALLBACK CCameraControlPropertiesCreateInstance(LPUNKNOWN pUnkOuter, HRESULT *pHr) 
{
	CUnknown *pUnknown = (CUnknown *)NULL;

	FX_ENTRY("CCameraControlPropertiesCreateInstance")

	DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: begin", _fx_));

	// Validate input parameters
	ASSERT(pHr);
	if (!pHr)
	{
		DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: invalid input parameter", _fx_));
		goto MyExit;
	}

	if (!(pUnknown = new CCameraControlProperties(pUnkOuter, pHr)))
	{
		*pHr = E_OUTOFMEMORY;
		DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: new CCameraControlProperties failed", _fx_));
	}
	else
	{
		DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s:   SUCCESS: new CCameraControlProperties created", _fx_));
	}

MyExit:
	DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: end", _fx_));
	return pUnknown;
}

/****************************************************************************
 *  @doc INTERNAL CCAMERACPMETHOD
 *
 *  @mfunc void | CCameraControlProperties | CCameraControlProperties | This
 *    method is the constructor for the property page object. It simply
 *    calls the constructor of the property page base class.
 *
 *  @parm LPUNKNOWN | pUnkOuter | Specifies the outer unknown, if any.
 *
 *  @parm HRESULT* | pHr | Specifies the place in which to put any error return.
 *
 *  @rdesc Nada.
 ***************************************************************************/
CCameraControlProperties::CCameraControlProperties(LPUNKNOWN pUnk, HRESULT *pHr) : CBasePropertyPage(NAME("Camera Control Property Page"), pUnk, IDD_CameraControlProperties, IDS_CAMERACONTROLPROPNAME)
{
	FX_ENTRY("CCameraControlProperties::CCameraControlProperties")

	DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: begin", _fx_));

	m_pICameraControl = NULL;
	m_NumProperties = NUM_CAMERA_CONTROLS;
	m_fActivated = FALSE;

	for (int i = 0; i < m_NumProperties; i++)
		m_Controls[i] = NULL;

	DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: end", _fx_));
}

/****************************************************************************
 *  @doc INTERNAL CCAMERACPMETHOD
 *
 *  @mfunc void | CCameraControlProperties | ~CCameraControlProperties | This
 *    method is the destructor for camera control property page. It
 *    simply calls the base class destructor after deleting all the controls.
 *
 *  @rdesc Nada.
 ***************************************************************************/
CCameraControlProperties::~CCameraControlProperties()
{
	int		j;

	FX_ENTRY("CCameraControlProperties::~CCameraControlProperties")

	DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: begin", _fx_));

	// Free the controls
	for (j = 0; j < m_NumProperties; j++)
	{
		if (m_Controls[j])
		{
			DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s:   SUCCESS: deleting m_Controls[%ld]=0x%08lX", _fx_, j, m_Controls[j]));
			delete m_Controls[j], m_Controls[j] = NULL;
		}
		else
		{
			DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   WARNING: control already freed", _fx_));
		}
	}

	DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: end", _fx_));
}

/****************************************************************************
 *  @doc INTERNAL CCAMERACPMETHOD
 *
 *  @mfunc HRESULT | CCameraControlProperties | OnConnect | This
 *    method is called when the property page is connected to the filter.
 *
 *  @parm LPUNKNOWN | pUnknown | Specifies the outer unknown, if any.
 *
 *  @parm HRESULT* | pHr | Specifies the place in which to put any error return.
 *
 *  @rdesc This method returns an HRESULT value that depends on the
 *    implementation of the interface. HRESULT can include one of the
 *    following standard constants, or other values not listed:
 *
 *  @flag E_FAIL | Failure
 *  @flag E_POINTER | Null pointer argument
 *  @flag E_NOTIMPL | Method is not supported
 *  @flag NOERROR | No error
 ***************************************************************************/
HRESULT CCameraControlProperties::OnConnect(IUnknown *pUnk)
{
	HRESULT Hr = NOERROR;

	FX_ENTRY("CCameraControlProperties::OnConnect")

	DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: begin", _fx_));

	// Validate input parameters
	ASSERT(pUnk);
	if (!pUnk)
	{
		DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: invalid input parameter", _fx_));
		Hr = E_POINTER;
		goto MyExit;
	}

	// Get the camera control interface
	if (SUCCEEDED (Hr = pUnk->QueryInterface(__uuidof(ICameraControl),(void **)&m_pICameraControl)))
	{
		DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s:   SUCCESS: m_pICameraControl=0x%08lX", _fx_, m_pICameraControl));
	}
	else
	{
		m_pICameraControl = NULL;
		DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: IOCTL failed Hr=0x%08lX", _fx_, Hr));
	}

	// It's Ok if we couldn't get interface pointers. We'll just grey the controls in the property page
	// to make it clear to the user that they can't control those properties on the device
	Hr = NOERROR;

MyExit:
	DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: end", _fx_));
	return Hr;
}

/****************************************************************************
 *  @doc INTERNAL CCAMERACPMETHOD
 *
 *  @mfunc HRESULT | CCameraControlProperties | OnDisconnect | This
 *    method is called when the property page is disconnected from the owning
 *    filter.
 *
 *  @rdesc This method returns an HRESULT value that depends on the
 *    implementation of the interface. HRESULT can include one of the
 *    following standard constants, or other values not listed:
 *
 *  @flag NOERROR | No error
 ***************************************************************************/
HRESULT CCameraControlProperties::OnDisconnect()
{
	FX_ENTRY("CCameraControlProperties::OnDisconnect")

	DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: begin", _fx_));

	// Validate input parameters: we seem to get called several times here
	// Make sure the interface pointer is still valid
	if (!m_pICameraControl)
	{
		DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   WARNING: already disconnected!", _fx_));
	}
	else
	{
		// Release the interface
		m_pICameraControl->Release();
		m_pICameraControl = NULL;
		DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s:   SUCCESS: releasing m_pICameraControl", _fx_));
	}

	DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: end", _fx_));
	return NOERROR;
}

/****************************************************************************
 *  @doc INTERNAL CCAMERACPMETHOD
 *
 *  @mfunc HRESULT | CCameraControlProperties | OnActivate | This
 *    method is called when the property page is activated.
 *
 *  @rdesc This method returns an HRESULT value that depends on the
 *    implementation of the interface. HRESULT can include one of the
 *    following standard constants, or other values not listed:
 *
 *  @flag E_FAIL | Failure
 *  @flag E_POINTER | Null pointer argument
 *  @flag E_NOTIMPL | Method is not supported
 *  @flag NOERROR | No error
 ***************************************************************************/
HRESULT CCameraControlProperties::OnActivate()
{
	HRESULT	Hr = E_OUTOFMEMORY;
	int		j;

	FX_ENTRY("CCameraControlProperties::OnActivate")

	DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: begin", _fx_));

	// Create the controls for the properties
	if (!(m_Controls[0] = new CCameraControlProperty(m_hwnd, IDC_Pan_Label, IDC_Pan_Minimum, IDC_Pan_Maximum, IDC_Pan_Default, IDC_Pan_Stepping, IDC_Pan_Edit, IDC_Pan_Slider, 0, TAPICameraControl_Pan, IDC_Pan_Auto, m_pICameraControl)))
	{
		DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: mew m_Controls[TAPICameraControl_Pan] failed - Out of memory", _fx_));
		goto MyExit;
	}
	else
	{
		DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s:   SUCCESS: m_Controls[TAPICameraControl_Pan]=0x%08lX", _fx_, m_Controls[0]));
	}

	if (!(m_Controls[1] = new CCameraControlProperty(m_hwnd, IDC_Tilt_Label, IDC_Tilt_Minimum, IDC_Tilt_Maximum, IDC_Tilt_Default, IDC_Tilt_Stepping, IDC_Tilt_Edit, IDC_Tilt_Slider, 0, TAPICameraControl_Tilt, IDC_Tilt_Auto, m_pICameraControl)))
	{
		DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: mew m_Controls[TAPICameraControl_Tilt] failed - Out of memory", _fx_));
		goto MyError0;
	}
	else
	{
		DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s:   SUCCESS: m_Controls[TAPICameraControl_Tilt]=0x%08lX", _fx_, m_Controls[1]));
	}

	if (!(m_Controls[2] = new CCameraControlProperty(m_hwnd, IDC_Roll_Label, IDC_Roll_Minimum, IDC_Roll_Maximum, IDC_Roll_Default, IDC_Roll_Stepping, IDC_Roll_Edit, IDC_Roll_Slider, 0, TAPICameraControl_Roll, IDC_Roll_Auto, m_pICameraControl)))
	{
		DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: mew m_Controls[TAPICameraControl_Roll] failed - Out of memory", _fx_));
		goto MyError1;
	}
	else
	{
		DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s:   SUCCESS: m_Controls[TAPICameraControl_Roll]=0x%08lX", _fx_, m_Controls[2]));
	}

	if (!(m_Controls[3] = new CCameraControlProperty(m_hwnd, IDC_Zoom_Label, IDC_Zoom_Minimum, IDC_Zoom_Maximum, IDC_Zoom_Default, IDC_Zoom_Stepping, IDC_Zoom_Edit, IDC_Zoom_Slider, 0, TAPICameraControl_Zoom, IDC_Zoom_Auto, m_pICameraControl)))
	{
		DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: mew m_Controls[TAPICameraControl_Zoom] failed - Out of memory", _fx_));
		goto MyError2;
	}
	else
	{
		DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s:   SUCCESS: m_Controls[TAPICameraControl_Zoom]=0x%08lX", _fx_, m_Controls[3]));
	}

	if (!(m_Controls[4] = new CCameraControlProperty(m_hwnd, IDC_Exposure_Label, IDC_Exposure_Minimum, IDC_Exposure_Maximum, IDC_Exposure_Default, IDC_Exposure_Stepping, IDC_Exposure_Edit, IDC_Exposure_Slider, 0, TAPICameraControl_Exposure, IDC_Exposure_Auto, m_pICameraControl)))
	{
		DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: mew m_Controls[TAPICameraControl_Exposure] failed - Out of memory", _fx_));
		goto MyError3;
	}
	else
	{
		DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s:   SUCCESS: m_Controls[TAPICameraControl_Exposure]=0x%08lX", _fx_, m_Controls[4]));
	}

	if (!(m_Controls[5] = new CCameraControlProperty(m_hwnd, IDC_Iris_Label, IDC_Iris_Minimum, IDC_Iris_Maximum, IDC_Iris_Default, IDC_Iris_Stepping, IDC_Iris_Edit, IDC_Iris_Slider, 0, TAPICameraControl_Iris, IDC_Iris_Auto, m_pICameraControl)))
	{
		DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: mew m_Controls[TAPICameraControl_Iris] failed - Out of memory", _fx_));
		goto MyError4;
	}
	else
	{
		DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s:   SUCCESS: m_Controls[TAPICameraControl_Iris]=0x%08lX", _fx_, m_Controls[5]));
	}

	if (!(m_Controls[6] = new CCameraControlProperty(m_hwnd, IDC_Focus_Label, IDC_Focus_Minimum, IDC_Focus_Maximum, IDC_Focus_Default, IDC_Focus_Stepping, IDC_Focus_Edit, IDC_Focus_Slider, 0, TAPICameraControl_Focus, 0, m_pICameraControl)))
	{
		DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: mew m_Controls[TAPICameraControl_Focus] failed - Out of memory", _fx_));
		goto MyError5;
	}
	else
	{
		DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s:   SUCCESS: m_Controls[TAPICameraControl_Focus]=0x%08lX", _fx_, m_Controls[6]));
	}

	if (!(m_Controls[7] = new CCameraControlProperty(m_hwnd, 0, 0, 0, 0, 0, IDC_FlipVertical_Edit, 0, 0, TAPICameraControl_FlipVertical, 0, m_pICameraControl)))
	{
		DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: mew m_Controls[TAPICameraControl_FlipVertical] failed - Out of memory", _fx_));
		goto MyError6;
	}
	else
	{
		DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s:   SUCCESS: m_Controls[TAPICameraControl_FlipVertical]=0x%08lX", _fx_, m_Controls[7]));
	}

	if (!(m_Controls[8] = new CCameraControlProperty(m_hwnd, 0, 0, 0, 0, 0, IDC_FlipHorizontal_Edit, 0, 0, TAPICameraControl_FlipHorizontal, 0, m_pICameraControl)))
	{
		DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: mew m_Controls[TAPICameraControl_FlipHorizontal] failed - Out of memory", _fx_));
		goto MyError7;
	}
	else
	{
		DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s:   SUCCESS: m_Controls[TAPICameraControl_FlipHorizontal]=0x%08lX", _fx_, m_Controls[8]));
	}


	// Initialize all the controls. If the initialization fails, it's Ok. It just means
	// that the TAPI control interface isn't implemented by the device. The dialog item
	// in the property page will be greyed, showing this to the user.
	for (j = 0; j < m_NumProperties; j++)
	{
		if (m_Controls[j]->Init())
		{
			DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s:   SUCCESS: m_Controls[%ld]->Init()", _fx_, j));
		}
		else
		{
			DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   WARNING: m_Controls[%ld]->Init() failed", _fx_, j));
		}
	}

	Hr = NOERROR;
	goto MyExit;

MyError7:
	if (m_Controls[7])
		delete m_Controls[7], m_Controls[7] = NULL;
MyError6:
	if (m_Controls[6])
		delete m_Controls[6], m_Controls[6] = NULL;
MyError5:
	if (m_Controls[5])
		delete m_Controls[5], m_Controls[5] = NULL;
MyError4:
	if (m_Controls[4])
		delete m_Controls[4], m_Controls[4] = NULL;
MyError3:
	if (m_Controls[3])
		delete m_Controls[3], m_Controls[3] = NULL;
MyError2:
	if (m_Controls[2])
		delete m_Controls[2], m_Controls[2] = NULL;
MyError1:
	if (m_Controls[1])
		delete m_Controls[1], m_Controls[1] = NULL;
MyError0:
	if (m_Controls[0])
		delete m_Controls[0], m_Controls[0] = NULL;
MyExit:
	m_fActivated = TRUE;
	DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: end", _fx_));
	return Hr;
}

/****************************************************************************
 *  @doc INTERNAL CCAMERACPMETHOD
 *
 *  @mfunc HRESULT | CCameraControlProperties | OnDeactivate | This
 *    method is called when the property page is dismissed.
 *
 *  @rdesc This method returns an HRESULT value that depends on the
 *    implementation of the interface. HRESULT can include one of the
 *    following standard constants, or other values not listed:
 *
 *  @flag NOERROR | No error
 ***************************************************************************/
HRESULT CCameraControlProperties::OnDeactivate()
{
	int		j;

	FX_ENTRY("CCameraControlProperties::OnDeactivate")

	DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: begin", _fx_));

	// Free the controls
	for (j = 0; j < m_NumProperties; j++)
	{
		if (m_Controls[j])
		{
			DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s:   SUCCESS: deleting m_Controls[%ld]=0x%08lX", _fx_, j, m_Controls[j]));
			delete m_Controls[j], m_Controls[j] = NULL;
		}
		else
		{
			DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   WARNING: control already freed", _fx_));
		}
	}

	DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: end", _fx_));
	m_fActivated = FALSE;
	return NOERROR;
}

/****************************************************************************
 *  @doc INTERNAL CCAMERACPMETHOD
 *
 *  @mfunc HRESULT | CCameraControlProperties | OnApplyChanges | This
 *    method is called when the user applies changes to the property page.
 *
 *  @rdesc This method returns an HRESULT value that depends on the
 *    implementation of the interface. HRESULT can include one of the
 *    following standard constants, or other values not listed:
 *
 *  @flag E_FAIL | Failure
 *  @flag E_POINTER | Null pointer argument
 *  @flag E_NOTIMPL | Method is not supported
 *  @flag NOERROR | No error
 ***************************************************************************/
HRESULT CCameraControlProperties::OnApplyChanges()
{
	HRESULT	Hr = NOERROR;

	FX_ENTRY("CCameraControlProperties::OnApplyChanges")

	DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: begin", _fx_));

	for (int j = 0; j < m_NumProperties; j++)
	{
		if (m_Controls[j])
		{
			if (m_Controls[j]->HasChanged())
			{
				DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s:   SUCCESS: calling m_Controls[%ld]=0x%08lX->OnApply", _fx_, j, m_Controls[j]));
				m_Controls[j]->OnApply();
			}
		}
		else
		{
			DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: can't call m_Controls[%ld]=NULL->OnApply", _fx_, j));
			Hr = E_UNEXPECTED;
			break;
		}
	}

	DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: end", _fx_));
	return Hr;
}

/****************************************************************************
 *  @doc INTERNAL CCAMERACPMETHOD
 *
 *  @mfunc BOOL | CCameraControlProperties | OnReceiveMessage | This
 *    method is called when a message is sent to the property page dialog box.
 *
 *  @rdesc By default, returns the value returned by the Win32 DefWindowProc function.
 ***************************************************************************/
BOOL CCameraControlProperties::OnReceiveMessage(HWND hWnd, UINT uMsg, WPARAM wParam, LPARAM lParam) 
{
	int iNotify = HIWORD (wParam);
	int j;

	switch (uMsg)
	{
		case WM_INITDIALOG:
			return TRUE; // Don't call setfocus

		case WM_HSCROLL:
		case WM_VSCROLL:
			if (m_fActivated)
			{
				// Process all of the Trackbar messages
				for (j = 0; j < m_NumProperties; j++)
				{
					ASSERT(m_Controls[j]);
					if (m_Controls[j]->GetTrackbarHWnd() == (HWND)lParam)
					{
						m_Controls[j]->OnScroll(uMsg, wParam, lParam);
						SetDirty();
					}
				}
				OnApplyChanges();
			}
			break;

		case WM_COMMAND:

			// This message gets sent even before OnActivate() has been
			// called(!). We need to test and make sure the controls have
			// beeen initialized before we can use them.

			if (m_fActivated)
			{
				// Process all of the auto checkbox messages
				for (j = 0; j < m_NumProperties; j++)
				{
					if (m_Controls[j] && m_Controls[j]->GetAutoHWnd() == (HWND)lParam)
					{
						m_Controls[j]->OnAuto(uMsg, wParam, lParam);
						SetDirty();
						break;
					}
				}

				// Process all of the edit box messages
				for (j = 0; j < m_NumProperties; j++)
				{
					if (m_Controls[j] && m_Controls[j]->GetEditHWnd() == (HWND)lParam)
					{
						m_Controls[j]->OnEdit(uMsg, wParam, lParam);
						SetDirty();
						break;
					}
				}

				switch (LOWORD(wParam))
				{
					case IDC_CONTROL_DEFAULT:
						for (j = 0; j < m_NumProperties; j++)
						{
							if (m_Controls[j])
								m_Controls[j]->OnDefault();
						}
						break;

					default:
						break;
				}

			OnApplyChanges();
			}
			break;

		default:
			return FALSE;
	}

	return TRUE;
}

/****************************************************************************
 *  @doc INTERNAL CCAMERACPMETHOD
 *
 *  @mfunc BOOL | CCameraControlProperties | SetDirty | This
 *    method notifies the property page site of changes.
 *
 *  @rdesc Nada.
 ***************************************************************************/
void CCameraControlProperties::SetDirty()
{
	m_bDirty = TRUE;
	if (m_pPageSite)
		m_pPageSite->OnStatusChange(PROPPAGESTATUS_DIRTY);
}

#endif // USE_SOFTWARE_CAMERA_CONTROL

#endif // USE_PROPERTY_PAGES
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\net\tapi\skywalker\filters\video\tapivcap\cameracs.cpp ===
/****************************************************************************
 *  @doc INTERNAL CAMERACS
 *
 *  @module CameraCS.cpp | Source file for the <c CTAPIBasePin> class methods
 *    used to implement the software-only camera control functions.
 ***************************************************************************/

#include "Precomp.h"

#ifdef USE_SOFTWARE_CAMERA_CONTROL

/****************************************************************************
 *  @doc INTERNAL CCONVERTMETHOD
 *
 *  @mfunc void | CConverter | InsertSoftCamCtrl | This method inserts a
 *    software-only camera controller.
 *
 *  @todo Verify error management
 ***************************************************************************/
HRESULT CConverter::InsertSoftCamCtrl() 
{
	HRESULT	Hr;
	DWORD	dwBmiSize;

	FX_ENTRY("CConverter::InsertSoftCamCtrl")

	DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: begin", _fx_));

	if (m_dwConversionType == CONVERSIONTYPE_NONE)
	{
		// We already have an input and output buffer (e.g. 160x120 RGB24 -> Processed RGB24)
		// This doesn't require any temporary buffer
		m_dwConversionType |= CONVERSIONTYPE_SCALER;
	}
	else if (!(m_dwConversionType & CONVERSIONTYPE_SCALER))
	{
		// Backup input format bitmap info header
		dwBmiSize = m_pbiIn->biSize;

		// Copy the palette if necessary
		if (m_pbiIn->biCompression == BI_RGB)
		{
			if (m_pbiIn->biBitCount == 8)
			{
				dwBmiSize += (DWORD)(m_pbiIn->biClrImportant ? m_pbiIn->biClrImportant * sizeof(RGBQUAD) : 256 * sizeof(RGBQUAD));
			}
			else if (m_pbiIn->biBitCount == 4)
			{
				dwBmiSize += (DWORD)(m_pbiIn->biClrImportant ? m_pbiIn->biClrImportant * sizeof(RGBQUAD) : 16 * sizeof(RGBQUAD));
			}
		}

		// We already have an input, output, AND intermediary buffer  (e.g. 160x120 RGB24 -> 176x144 Processed RGB24 -> 176x144 Processed H.26X or 160x120 YVU9 -> 160x120 Processed RGB24 -> 176x144 H.26X)
		// Use this intermediary buffer to apply the camera control operations
		m_dwConversionType |= CONVERSIONTYPE_SCALER;

		if (m_pbiIn->biCompression == BI_RGB || m_pbiIn->biCompression == VIDEO_FORMAT_YVU9 || m_pbiIn->biCompression == VIDEO_FORMAT_YUY2 || m_pbiIn->biCompression == VIDEO_FORMAT_UYVY || m_pbiIn->biCompression == VIDEO_FORMAT_I420 || m_pbiIn->biCompression == VIDEO_FORMAT_IYUV)
		{
			// The camera control operations will occur before the format conversion
			m_dwConversionType |= CONVERSIONTYPE_PRESCALER;

			// The input and intermediary buffers are both RGB (e.g. 160x120 RGB24 -> 176x144 Processed RGB24 -> 176x144 H.26X)
			if (!(m_pbiInt = (PBITMAPINFOHEADER)(new BYTE[(m_pbiIn->biBitCount == 4) ? m_pbiIn->biSize + 256 * sizeof(RGBQUAD) : dwBmiSize])))
			{
				DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: Out of memory", _fx_));
				Hr = E_OUTOFMEMORY;
				goto MyError;
			}

			CopyMemory(m_pbiInt, m_pbiIn, dwBmiSize);

			// If the input is 4bpp, we'll use a RGB8 intermediate format
			if (m_pbiIn->biBitCount == 4)
			{
				m_pbiInt->biBitCount = 8;
				m_pbiInt->biClrImportant = 256;
			}
			m_pbiInt->biWidth = m_pbiOut->biWidth;
			m_pbiInt->biHeight = m_pbiOut->biHeight;
			m_pbiInt->biSizeImage = DIBSIZE(*m_pbiInt);

			// Allocate intermediary buffer
			if (!(m_pbyOut = (PBYTE)(new BYTE[m_pbiInt->biSizeImage])))
			{
				DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: Out of memory", _fx_));
				Hr = E_OUTOFMEMORY;
				goto MyError;
			}
		}
		else
		{
			// We will need to decompress to an intermediary format if a camera control operation is necessary (e.g. 160x120 MJPEG -> 160x120 RGB24 -> 176x144 Processed RGB24)
			if (!(m_pbiInt = (PBITMAPINFOHEADER)(new BYTE[m_pbiOut->biSize])))
			{
				DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: Out of memory", _fx_));
				Hr = E_OUTOFMEMORY;
				goto MyError;
			}
			CopyMemory(m_pbiInt, m_pbiOut, m_pbiOut->biSize);
			m_pbiInt->biWidth = m_pbiIn->biWidth;
			m_pbiInt->biHeight = m_pbiIn->biHeight;
			m_pbiInt->biSizeImage = DIBSIZE(*m_pbiInt);

			// Allocate intermediary buffer
			if (!(m_pbyOut = (PBYTE)(new BYTE[m_pbiInt->biSizeImage])))
			{
				DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: Out of memory", _fx_));
				Hr = E_OUTOFMEMORY;
				goto MyError;
			}
		}
	}

	// Mark success
	m_fSoftCamCtrl = TRUE;

	DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s:   SUCCESS: Software-only camera controller insterted", _fx_));

	Hr = NOERROR;

	goto MyExit;

MyError:
	if (m_pbiInt)
		delete m_pbiInt, m_pbiInt = NULL;
MyExit:
	DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: end", _fx_));
	return Hr;
}


/****************************************************************************
 *  @doc INTERNAL CBASEPINMETHOD
 *
 *  @mfunc HRESULT | CTAPIBasePin | OpenSoftCamCtrl | This method opens a
 *    software-only camera controller.
 *
 *  @todo Verify error management
 ***************************************************************************/
HRESULT CTAPIBasePin::OpenSoftCamCtrl(PBITMAPINFOHEADER pbiIn, PBITMAPINFOHEADER pbiOut)
{
	HRESULT	Hr = NOERROR;
	DWORD dwBmiSize, dwOutBmiSize;

	FX_ENTRY("CTAPIBasePin::OpenSoftCamCtrl")

	DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: begin", _fx_));

	// Default to failure
	m_fSoftCamCtrl = FALSE;

	// Validate input parameters
	ASSERT(pbiIn);
	ASSERT(pbiOut);
	if (!pbiIn || !pbiOut)
	{
		DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: invalid input parameter", _fx_));
		Hr = E_POINTER;
		goto MyExit;
	}

	ASSERT(!m_pbiSCCIn);
	ASSERT(!m_pbiSCCOut);
	if (m_pbiSCCIn || m_pbiSCCOut)
	{
		DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: invalid state", _fx_));
		Hr = E_UNEXPECTED;
		goto MyExit;
	}

	// Backup input format bitmap info header
	dwBmiSize = pbiIn->biSize;

	// Copy the palette if necessary
	if (pbiIn->biCompression == BI_RGB)
	{
		if (pbiIn->biBitCount == 8)
		{
			dwBmiSize += (DWORD)(pbiIn->biClrImportant ? pbiIn->biClrImportant * sizeof(RGBQUAD) : 256 * sizeof(RGBQUAD));
		}
		else if (pbiIn->biBitCount == 4)
		{
			dwBmiSize += (DWORD)(pbiIn->biClrImportant ? pbiIn->biClrImportant * sizeof(RGBQUAD) : 16 * sizeof(RGBQUAD));
		}
	}

	if (!(m_pbiSCCIn = (PBITMAPINFOHEADER)(new BYTE[dwBmiSize])))
	{
		DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: Out of memory", _fx_));
		Hr = E_OUTOFMEMORY;
		goto MyExit;
	}

	// @todo Why are we making a copy exactly?
	CopyMemory(m_pbiSCCIn, pbiIn, dwBmiSize);

	// Backup output format bitmap info header
	// @todo Why do we make copy of this instead of keeping a reference to the bitmap infoheader?
	dwOutBmiSize = pbiOut->biSize;

	// Copy the palette if necessary
	if (pbiOut->biCompression == BI_RGB)
	{
		if (pbiOut->biBitCount == 8)
		{
			dwOutBmiSize += (DWORD)(pbiOut->biClrImportant ? pbiOut->biClrImportant * sizeof(RGBQUAD) : 256 * sizeof(RGBQUAD));
		}
		else if (pbiOut->biBitCount == 4)
		{
			dwOutBmiSize += (DWORD)(pbiOut->biClrImportant ? pbiOut->biClrImportant * sizeof(RGBQUAD) : 16 * sizeof(RGBQUAD));
		}
	}

	if (!(m_pbiSCCOut = (PBITMAPINFOHEADER)(new BYTE[dwOutBmiSize])))
	{
		DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: Out of memory", _fx_));
		Hr = E_OUTOFMEMORY;
		goto MyError0;
	}
	CopyMemory(m_pbiSCCOut, pbiOut, dwOutBmiSize);

	// We only need to allocate one intermediary buffer that will contain
	// the result of the operation. This buffer will then be compressed to H.26X
	// or copied to the output buffer for preview.
	// @todo Find a way to go around this extra memory copy in the preview case
	if (!(m_pbyCamCtrl = (PBYTE)(new BYTE[m_pbiSCCIn->biSizeImage])))
	{
		DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: Out of memory", _fx_));
		Hr = E_OUTOFMEMORY;
		goto MyError1;
	}

	// Mark success
	m_fSoftCamCtrl = TRUE;

	DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s:   SUCCESS: Software-only camera controller ready", _fx_));

	goto MyExit;

MyError1:
	if (m_pbiSCCOut)
		delete m_pbiSCCOut, m_pbiSCCOut = NULL;
MyError0:
	if (m_pbiSCCIn)
		delete m_pbiSCCIn, m_pbiSCCIn = NULL;
MyExit:
	DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: end", _fx_));
	return Hr;
}

/****************************************************************************
 *  @doc INTERNAL CBASEPINMETHOD
 *
 *  @mfunc BOOL | CTAPIBasePin | IsSoftCamCtrlOpen | This method checks if
 *    a software-only camera controller has already been opened.
 *
 *  @rdesc Returns TRUE if a software-only camera controller has already been opened
 ***************************************************************************/
BOOL CTAPIBasePin::IsSoftCamCtrlOpen()
{
	FX_ENTRY("CTAPIBasePin::IsSoftCamCtrlOpen")

	DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: begin", _fx_));

	DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: end", _fx_));

	return m_fSoftCamCtrl;
}

/****************************************************************************
 *  @doc INTERNAL CCONVERTMETHOD
 *
 *  @mfunc BOOL | CConverter | IsSoftCamCtrlInserted | This method checks if
 *    a software-only camera controller has already been inserted.
 *
 *  @rdesc Returns TRUE if a software-only camera controller has already
 *    been inserted
 ***************************************************************************/
BOOL CConverter::IsSoftCamCtrlInserted()
{
	FX_ENTRY("CConverter::IsSoftCamCtrlInserted")

	DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: begin", _fx_));

	DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: end", _fx_));

	return m_fSoftCamCtrl;
}

/****************************************************************************
 *  @doc INTERNAL CPREVIEWPINMETHOD
 *
 *  @mfunc HRESULT | CPreviewPin | IsSoftCamCtrlNeeded | This method verifies
 *    if a software-only camera controller is needed.
 *
 *  @todo You'll need a function like this one for RGB16 and RGB8
 *    too. In RGB8, make sure you use the Indeo palette, like NM.
 ***************************************************************************/
BOOL CTAPIBasePin::IsSoftCamCtrlNeeded()
{
	BOOL fRes;

	FX_ENTRY("CTAPIBasePin::IsSoftCamCtrlNeeded")

	DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: begin", _fx_));

	fRes = m_pCaptureFilter && (m_fFlipHorizontal || m_fFlipVertical || (m_pCaptureFilter->m_pCapDev->m_lCCZoom > 10 && m_pCaptureFilter->m_pCapDev->m_lCCZoom <= 600) || m_pCaptureFilter->m_pCapDev->m_lCCPan != 0 || m_pCaptureFilter->m_pCapDev->m_lCCTilt != 0);

	DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: end", _fx_));

	return fRes;
}

/****************************************************************************
 *  @doc INTERNAL CPREVIEWPINMETHOD
 *
 *  @mfunc HRESULT | CConverter | IsSoftCamCtrlNeeded | This method verifies
 *    if a software-only camera controller is needed.
 *
 *  @rdesc Returns TRUE if a software-only camera controller is needed
 ***************************************************************************/
BOOL CConverter::IsSoftCamCtrlNeeded()
{
	BOOL fRes;

	FX_ENTRY("CConverter::IsSoftCamCtrlNeeded")

	DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: begin", _fx_));

	fRes = m_pBasePin->m_pCaptureFilter && (m_pBasePin->m_fFlipHorizontal || m_pBasePin->m_fFlipVertical || (m_pBasePin->m_pCaptureFilter->m_pCapDev->m_lCCZoom > 10 && m_pBasePin->m_pCaptureFilter->m_pCapDev->m_lCCZoom <= 600) || m_pBasePin->m_pCaptureFilter->m_pCapDev->m_lCCPan != 0 || m_pBasePin->m_pCaptureFilter->m_pCapDev->m_lCCTilt != 0);

	DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: end", _fx_));

	return fRes;
}

/****************************************************************************
 *  @doc INTERNAL CPREVIEWPINMETHOD
 *
 *  @mfunc HRESULT | CPreviewPin | ApplySoftCamCtrl | This method applies
 *    software-only camera control operators.
 *
 *  @todo You'll need a function like this one for RGB16 and RGB8
 *    too. In RGB8, make sure you use the Indeo palette, like NM.
 ***************************************************************************/
HRESULT CTAPIBasePin::ApplySoftCamCtrl(PBYTE pbyInput, DWORD dwInBytes, PBYTE pbyOutput, PDWORD pdwBytesUsed, PDWORD pdwBytesExtent)
{
	HRESULT Hr = NOERROR;
	RECT	rcRect;

	FX_ENTRY("CTAPIBasePin::ApplySoftCamCtrl")

	DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: begin", _fx_));

	// Validate input parameters
	ASSERT(m_pbiSCCIn);
	ASSERT(m_pbiSCCOut);
	ASSERT(pbyInput);
	ASSERT(pbyOutput);
	if (!m_pbiSCCIn || !m_pbiSCCOut || !pbyInput || !pbyOutput)
	{
		DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: invalid input parameter", _fx_));
		Hr = E_POINTER;
		goto MyExit;
	}

	// Get the input rectangle
	ComputeRectangle(m_pbiSCCIn, m_pbiSCCOut, m_pCaptureFilter->m_pCapDev->m_lCCZoom, m_pCaptureFilter->m_pCapDev->m_lCCPan, m_pCaptureFilter->m_pCapDev->m_lCCTilt, &rcRect, m_fFlipHorizontal, m_fFlipVertical);

	// Scale DIB
	ScaleDIB(m_pbiSCCIn, pbyInput, m_pbiSCCOut, pbyOutput, &rcRect, m_fFlipHorizontal, m_fFlipVertical, m_fNoImageStretch, m_dwBlackEntry);

MyExit:
	DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: end", _fx_));
	return Hr;
}

/****************************************************************************
 *  @doc INTERNAL CBASEPINMETHOD
 *
 *  @mfunc HRESULT | CTAPIBasePin | CloseSoftCamCtrl | This method closes a
 *    software-only camera controller.
 ***************************************************************************/
HRESULT CTAPIBasePin::CloseSoftCamCtrl()
{
	FX_ENTRY("CTAPIBasePin::CloseSoftCamCtrl")

	DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: begin", _fx_));

	// Free memory
	if (m_pbyCamCtrl)
		delete m_pbyCamCtrl, m_pbyCamCtrl = NULL;

	if (m_pbiSCCOut)
		delete m_pbiSCCOut, m_pbiSCCOut = NULL;

	if (m_pbiSCCIn)
		delete m_pbiSCCIn, m_pbiSCCIn = NULL;

	m_fSoftCamCtrl = FALSE;

	DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: end", _fx_));

	return NOERROR;
}

/****************************************************************************
 *  @doc INTERNAL CCONVERTMETHOD
 *
 *  @mfunc BOOL | CConverter | RemoveSoftCamCtrl | This method disables
 *    a software-only camera controller that has already been inserted.
 *
 *  @rdesc Returns NOERROR
 ***************************************************************************/
HRESULT CConverter::RemoveSoftCamCtrl()
{
	FX_ENTRY("CConverter::RemoveSoftCamCtrl")

	DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: begin", _fx_));

	// Restore flags and release memory if necessary
	m_dwConversionType = m_dwConversionType & ~(CONVERSIONTYPE_SCALER | CONVERSIONTYPE_PRESCALER);

	if ((m_pbiIn->biWidth == m_pbiOut->biWidth && m_pbiIn->biHeight == m_pbiOut->biHeight))
	{
		if (m_pbyOut)
			delete m_pbyOut, m_pbyOut = NULL;
		if (m_pbiInt)
			delete m_pbiInt, m_pbiInt = NULL;
	}
	else
	{
		// We need a size change
		m_dwConversionType |= CONVERSIONTYPE_SCALER;

		if (m_pbiIn->biCompression == BI_RGB || m_pbiIn->biCompression == VIDEO_FORMAT_YVU9 || m_pbiIn->biCompression == VIDEO_FORMAT_YUY2 || m_pbiIn->biCompression == VIDEO_FORMAT_UYVY || m_pbiIn->biCompression == VIDEO_FORMAT_I420 || m_pbiIn->biCompression == VIDEO_FORMAT_IYUV)
		{
			// The scaling will occur before the format conversion
			m_dwConversionType |= CONVERSIONTYPE_PRESCALER;
		}
	}

	m_fSoftCamCtrl = FALSE;

	DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: end", _fx_));

	return NOERROR;
}

#endif // USE_SOFTWARE_CAMERA_CONTROL
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\net\tapi\skywalker\filters\video\tapivcap\capture.cpp ===
/****************************************************************************
 *  @doc INTERNAL CAPTURE
 *
 *  @module Capture.cpp | Source file for the <c CCapturePin> class methods
 *    used to implement the video capture output pin.
 ***************************************************************************/

#include "Precomp.h"

/****************************************************************************
 *  @doc INTERNAL CCAPTUREPINMETHOD
 *
 *  @mfunc CCapturePin* | CCapturePin | CreateCapturePin | This helper
 *    function creates a video output pin for capture.
 *
 *  @parm CTAPIVCap* | pCaptureFilter | Specifies a pointer to the owner
 *    filter.
 *
 *  @parm CCapturePin** | ppCapturePin | Specifies that address of a pointer
 *    to a <c CCapturePin> object to receive the a pointer to the newly
 *    created pin.
 *
 *  @rdesc This method returns an HRESULT value that depends on the
 *    implementation of the interface. HRESULT can include one of the
 *    following standard constants, or other values not listed:
 *
 *  @flag E_FAIL | Failure
 *  @flag E_POINTER | Null pointer argument
 *  @flag NOERROR | No error
 ***************************************************************************/
HRESULT CALLBACK CCapturePin::CreateCapturePin(CTAPIVCap *pCaptureFilter, CCapturePin **ppCapturePin)
{
        HRESULT Hr = NOERROR;

        FX_ENTRY("CCapturePin::CreateCapturePin")

        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: begin", _fx_));

        // Validate input parameters
        ASSERT(pCaptureFilter);
        ASSERT(ppCapturePin);
        if (!pCaptureFilter || !ppCapturePin)
        {
                DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: Null pointer argument", _fx_));
                Hr = E_POINTER;
                goto MyExit;
        }

        if (!(*ppCapturePin = (CCapturePin *) new CCapturePin(NAME("Video Capture Stream"), pCaptureFilter, &Hr, PNAME_CAPTURE)))
        {
                DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: Out of memory", _fx_));
                Hr = E_OUTOFMEMORY;
                goto MyExit;
        }

        // If initialization failed, delete the stream array and return the error
        if (FAILED(Hr) && *ppCapturePin)
        {
                DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: Initialization failed", _fx_));
                Hr = E_FAIL;
                delete *ppCapturePin, *ppCapturePin = NULL;
        }

MyExit:
        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: end", _fx_));
        return Hr;
}

/****************************************************************************
 *  @doc INTERNAL CCAPTUREPINMETHOD
 *
 *  @mfunc HRESULT | CCapturePin | CCapturePin | This method is the
 *  constructorfor the <c CCapturePin> object
 *
 *  @rdesc Nada.
 ***************************************************************************/
#pragma warning(disable:4355)
CCapturePin::CCapturePin(IN TCHAR *pObjectName, IN CTAPIVCap *pCaptureFilter, IN HRESULT *pHr, IN LPCWSTR pName) : CTAPIBasePin(pObjectName, pCaptureFilter, pHr, pName)
{
        FX_ENTRY("CCapturePin::CCapturePin")

        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: begin", _fx_));

        // Validate input parameters
        ASSERT(pHr);
        ASSERT(pCaptureFilter);
        if (!pCaptureFilter || !pHr)
        {
                DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: invalid input parameter", _fx_));
                if (pHr)
                        *pHr = E_POINTER;
        }

        if (pHr && FAILED(*pHr))
        {
                DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: Base class error or invalid input parameter", _fx_));
                goto MyExit;
        }

#ifdef USE_NETWORK_STATISTICS
        // Networks stats
        m_dwPacketLossRate = m_dwPacketLossRateMin = m_dwPacketLossRateMax = m_dwPacketLossRateSteppingDelta = m_dwPacketLossRateDefault = 0UL;
        m_ChannelErrors.dwRandomBitErrorRate = 0; m_ChannelErrors.dwBurstErrorDuration = 0; m_ChannelErrors.dwBurstErrorMaxFrequency = 0;
        m_ChannelErrorsMin.dwRandomBitErrorRate = 0; m_ChannelErrorsMin.dwBurstErrorDuration = 0; m_ChannelErrorsMin.dwBurstErrorMaxFrequency = 0;
        m_ChannelErrorsMax.dwRandomBitErrorRate = 0; m_ChannelErrorsMax.dwBurstErrorDuration = 0; m_ChannelErrorsMax.dwBurstErrorMaxFrequency = 0;
        m_ChannelErrorsSteppingDelta.dwRandomBitErrorRate = 0; m_ChannelErrorsSteppingDelta.dwBurstErrorDuration = 0; m_ChannelErrorsSteppingDelta.dwBurstErrorMaxFrequency = 0;
        m_ChannelErrorsDefault.dwRandomBitErrorRate = 0; m_ChannelErrorsDefault.dwBurstErrorDuration = 0; m_ChannelErrorsDefault.dwBurstErrorMaxFrequency = 0;
#endif

        // Initialize to default format: H.263 176x144 at 30 fps
        m_mt = *CaptureFormats[0];
        m_aFormats = (AM_MEDIA_TYPE**)CaptureFormats;
        m_aCapabilities = CaptureCaps;
        m_dwNumFormats = NUM_CAPTURE_FORMATS;
        m_dwRTPPayloadType = RTPPayloadTypes[0];

        // Update bitrate controls
        // MaxBitsPerSecond value too big; use the 10th part of it for the m_lTargetBitrate
        m_lTargetBitrate = CaptureCaps[0]->MaxBitsPerSecond / 10; // theoretically should be   max(CaptureCaps[0]->MinBitsPerSecond, CaptureCaps[0]->MaxBitsPerSecond / 10);
        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: m_lTargetBitrate set to %ld", _fx_, m_lTargetBitrate));
        m_lCurrentBitrate = 0;
        m_lBitrateRangeMin = CaptureCaps[0]->MinBitsPerSecond;
        m_lBitrateRangeMax = CaptureCaps[0]->MaxBitsPerSecond;
        m_lBitrateRangeSteppingDelta = 100;
        m_lBitrateRangeDefault = CaptureCaps[0]->MaxBitsPerSecond / 10;

        // Update frame rate controls
        // @todo With WDM, these numbers need to come from the device
        m_lMaxAvgTimePerFrame = (LONG)CaptureCaps[0]->MinFrameInterval;
        // We need to do the following because our bitrate control assumes
        // that m_lCurrentAvgTimePerFrame is valid to compute the size of
        // each target output frame. If we start at 0, it's doing a poor
        // job until this field is updated (1s later). So, instead, let's
        // assume that the current average time per frame IS close to the
        // target average time per frame.
        m_lCurrentAvgTimePerFrame = m_lMaxAvgTimePerFrame;
        m_lAvgTimePerFrameRangeMin = (LONG)CaptureCaps[0]->MinFrameInterval;
        m_lAvgTimePerFrameRangeMax = (LONG)CaptureCaps[0]->MaxFrameInterval;
        m_lAvgTimePerFrameRangeSteppingDelta = (LONG)(CaptureCaps[0]->MaxFrameInterval - CaptureCaps[0]->MinFrameInterval) / 100;
        m_lAvgTimePerFrameRangeDefault = (LONG)CaptureCaps[0]->MinFrameInterval;

        // H.245 video capabilities
        m_pH245MediaCapabilityMap = NULL;
        m_pVideoResourceBounds = NULL;
        m_pFormatResourceBounds = NULL;

MyExit:
        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: end", _fx_));
}

/****************************************************************************
 *  @doc INTERNAL CCAPTUREPINMETHOD
 *
 *  @mfunc void | CCapturePin | ~CCapturePin | This method is the destructor
 *    for the <c CCapturePin> object.
 *
 *  @rdesc Nada.
 ***************************************************************************/
CCapturePin::~CCapturePin()
{
        FX_ENTRY("CCapturePin::~CCapturePin")

        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: begin", _fx_));

        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: end", _fx_));
}

/****************************************************************************
 *  @doc INTERNAL CCAPTUREPINMETHOD
 *
 *  @mfunc HRESULT | CCapturePin | NonDelegatingQueryInterface | This
 *    method is the nondelegating interface query function. It returns a pointer
 *    to the specified interface if supported. The only interfaces explicitly
 *    supported being <i IAMStreamConfig>,
 *    <i IAMStreamControl>, <i ICPUControl>, <i IFrameRateControl>,
 *    <i IBitrateControl>, <i INetworkStats>, <i IH245EncoderCommand>
 *    and <i IProgressiveRefinement>.
 *
 *  @parm REFIID | riid | Specifies the identifier of the interface to return.
 *
 *  @parm PVOID* | ppv | Specifies the place in which to put the interface
 *    pointer.
 *
 *  @rdesc This method returns an HRESULT value that depends on the
 *    implementation of the interface. HRESULT can include one of the
 *    following standard constants, or other values not listed:
 *
 *  @flag E_FAIL | Failure
 *  @flag E_POINTER | Null pointer argument
 *  @flag NOERROR | No error
 ***************************************************************************/
STDMETHODIMP CCapturePin::NonDelegatingQueryInterface(IN REFIID riid, OUT void **ppv)
{
        HRESULT Hr = NOERROR;

        FX_ENTRY("CCapturePin::NonDelegatingQueryInterface")

        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: begin", _fx_));

        // Validate input parameters
        ASSERT(ppv);
        if (!ppv)
        {
                DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: Null pointer argument", _fx_));
                Hr = E_POINTER;
                goto MyExit;
        }

        if (riid == __uuidof(IAMStreamControl))
        {
                if (FAILED(Hr = GetInterface(static_cast<IAMStreamControl*>(this), ppv)))
                {
                        DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: NDQI for IAMStreamControl failed Hr=0x%08lX", _fx_, Hr));
                }
                else
                {
                        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s:   SUCCESS: IAMStreamControl*=0x%08lX", _fx_, *ppv));
                }

                goto MyExit;
        }
        else if (riid == __uuidof(IStreamConfig))
        {
                if (FAILED(Hr = GetInterface(static_cast<IStreamConfig*>(this), ppv)))
                {
                        DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: NDQI for IStreamConfig failed Hr=0x%08lX", _fx_, Hr));
                }
                else
                {
                        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s:   SUCCESS: IStreamConfig*=0x%08lX", _fx_, *ppv));
                }

                goto MyExit;
        }
#ifdef USE_PROPERTY_PAGES
        else if (riid == IID_ISpecifyPropertyPages)
        {
                if (FAILED(Hr = GetInterface(static_cast<ISpecifyPropertyPages*>(this), ppv)))
                {
                        DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: NDQI for ISpecifyPropertyPages failed Hr=0x%08lX", _fx_, Hr));
                }
                else
                {
                        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s:   SUCCESS: ISpecifyPropertyPages*=0x%08lX", _fx_, *ppv));
                }

                goto MyExit;
        }
#endif
#ifdef USE_NETWORK_STATISTICS
        else if (riid == __uuidof(INetworkStats))
        {
                if (FAILED(Hr = GetInterface(static_cast<INetworkStats*>(this), ppv)))
                {
                        DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: NDQI for INetworkStats failed Hr=0x%08lX", _fx_, Hr));
                }
                else
                {
                        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s:   SUCCESS: INetworkStats*=0x%08lX", _fx_, *ppv));
                }

                goto MyExit;
        }
#endif
        else if (riid == __uuidof(IH245Capability))
        {
                if (FAILED(Hr = GetInterface(static_cast<IH245Capability*>(this), ppv)))
                {
                        DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: NDQI for IH245Capability failed Hr=0x%08lX", _fx_, Hr));
                }
                else
                {
                        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s:   SUCCESS: IH245Capability*=0x%08lX", _fx_, *ppv));
                }

                goto MyExit;
        }
        else if (riid == __uuidof(IH245EncoderCommand))
        {
                if (FAILED(Hr = GetInterface(static_cast<IH245EncoderCommand*>(this), ppv)))
                {
                        DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: NDQI for IH245EncoderCommand failed Hr=0x%08lX", _fx_, Hr));
                }
                else
                {
                        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s:   SUCCESS: IH245EncoderCommand*=0x%08lX", _fx_, *ppv));
                }

                goto MyExit;
        }
#ifdef USE_PROGRESSIVE_REFINEMENT
        else if (riid == __uuidof(IProgressiveRefinement))
        {
                if (FAILED(Hr = GetInterface(static_cast<IProgressiveRefinement*>(this), ppv)))
                {
                        DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: NDQI for IProgressiveRefinement failed Hr=0x%08lX", _fx_, Hr));
                }
                else
                {
                        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s:   SUCCESS: IProgressiveRefinement*=0x%08lX", _fx_, *ppv));
                }

                goto MyExit;
        }
#endif

        if (FAILED(Hr = CTAPIBasePin::NonDelegatingQueryInterface(riid, ppv)))
        {
                DBGOUT((g_dwVideoCaptureTraceID, WARN, "%s:   WARNING: NDQI for {%08lX-%04lX-%04lX-%02lX%02lX-%02lX%02lX%02lX%02lX%02lX%02lX} failed Hr=0x%08lX", _fx_, riid.Data1, riid.Data2, riid.Data3, riid.Data4[0], riid.Data4[1], riid.Data4[2], riid.Data4[3], riid.Data4[4], riid.Data4[5], riid.Data4[6], riid.Data4[7], Hr));
        }
        else
        {
                DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s:   SUCCESS: {%08lX-%04lX-%04lX-%02lX%02lX-%02lX%02lX%02lX%02lX%02lX%02lX}*=0x%08lX", _fx_, riid.Data1, riid.Data2, riid.Data3, riid.Data4[0], riid.Data4[1], riid.Data4[2], riid.Data4[3], riid.Data4[4], riid.Data4[5], riid.Data4[6], riid.Data4[7], *ppv));
        }

MyExit:
        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: end", _fx_));
        return Hr;
}

#ifdef USE_PROPERTY_PAGES
/****************************************************************************
 *  @doc INTERNAL CCAPTUREPINMETHOD
 *
 *  @mfunc HRESULT | CCapturePin | GetPages | This method Fills a counted
 *    array of GUID values where each GUID specifies the CLSID of each
 *    property page that can be displayed in the property sheet for this
 *    object.
 *
 *  @parm CAUUID* | pPages | Specifies a pointer to a caller-allocated CAUUID
 *    structure that must be initialized and filled before returning. The
 *    pElems field in the CAUUID structure is allocated by the callee with
 *    CoTaskMemAlloc and freed by the caller with CoTaskMemFree.
 *
 *  @rdesc This method returns an HRESULT value that depends on the
 *    implementation of the interface. HRESULT can include one of the
 *    following standard constants, or other values not listed:
 *
 *  @flag E_FAIL | Failure
 *  @flag E_POINTER | Null pointer argument
 *  @flag E_OUTOFMEMORY | Allocation failed
 *  @flag NOERROR | No error
 ***************************************************************************/
STDMETHODIMP CCapturePin::GetPages(OUT CAUUID *pPages)
{
        HRESULT Hr = NOERROR;

        FX_ENTRY("CCapturePin::GetPages")

        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: begin", _fx_));

        // Validate input parameters
        ASSERT(pPages);
        if (!pPages)
        {
                DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: Null pointer argument", _fx_));
                Hr = E_POINTER;
                goto MyExit;
        }

#ifdef USE_CPU_CONTROL
#ifdef USE_PROGRESSIVE_REFINEMENT
#ifdef USE_NETWORK_STATISTICS
        pPages->cElems = 4;
#else
        pPages->cElems = 3;
#endif
#else
#ifdef USE_NETWORK_STATISTICS
        pPages->cElems = 3;
#else
        pPages->cElems = 2;
#endif
#endif
#else
#ifdef USE_PROGRESSIVE_REFINEMENT
#ifdef USE_NETWORK_STATISTICS
        pPages->cElems = 3;
#else
        pPages->cElems = 2;
#endif
#else
#ifdef USE_NETWORK_STATISTICS
        pPages->cElems = 2;
#else
        pPages->cElems = 1;
#endif
#endif
#endif

        // Alloc memory for the page stuff
        if (!(pPages->pElems = (GUID *) QzTaskMemAlloc(sizeof(GUID) * pPages->cElems)))
        {
                DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: invalid input parameter", _fx_));
                Hr = E_OUTOFMEMORY;
        }
        else
        {
                pPages->pElems[0] = _uuidof(CapturePropertyPage);
#ifdef USE_CPU_CONTROL
                pPages->pElems[1] = _uuidof(CPUCPropertyPage);
#ifdef USE_NETWORK_STATISTICS
                pPages->pElems[2] = _uuidof(NetworkStatsPropertyPage);
#ifdef USE_PROGRESSIVE_REFINEMENT
                pPages->pElems[3] = _uuidof(ProgRefPropertyPage);
#endif
#else
#ifdef USE_PROGRESSIVE_REFINEMENT
                pPages->pElems[2] = _uuidof(ProgRefPropertyPage);
#endif
#endif
#else
#ifdef USE_NETWORK_STATISTICS
                pPages->pElems[1] = _uuidof(NetworkStatsPropertyPage);
#ifdef USE_PROGRESSIVE_REFINEMENT
                pPages->pElems[2] = _uuidof(ProgRefPropertyPage);
#endif
#else
#ifdef USE_PROGRESSIVE_REFINEMENT
                pPages->pElems[1] = _uuidof(ProgRefPropertyPage);
#endif
#endif
#endif
        }

MyExit:
        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: end", _fx_));
        return Hr;
}
#endif

/****************************************************************************
 *  @doc INTERNAL CCAPTUREPINMETHOD
 *
 *  @mfunc HRESULT | CCapturePin | SendFrames | This method is used to
 *    send a a media sample downstream.
 *
 *  @parm CFrameSample | pCapSample | Specifies a pointer to the capture
 *    video sample to send downstream.
 *
 *  @parm CFrameSample | pPrevSample | Specifies a pointer to the preview
 *    video sample to send downstream.
 *
 *  @parm LPTHKVIDEOHDR | ptvh | Specifies a pointer to the video header
 *    of the video capture buffer associated to this sample.
 *
 *  @parm PDWORD | pdwBytesUsed | Specifies a pointer to a DWORD to receive
 *    the size of the frame that has been delivered downstream.
 *
 *  @parm BOOL | bDiscon | Set to TRUE if this is the first frame we ever
 *    sent downstream.
 *
 *  @rdesc This method returns an HRESULT value that depends on the
 *    implementation of the interface. HRESULT can include one of the
 *    following standard constants, or other values not listed:
 *
 *  @flag E_FAIL | Failure
 *  @flag E_POINTER | Null pointer argument
 *  @flag S_OK | No error
 *  @flag S_FALSE | If the pin is off (IAMStreamControl)
 *  @flag NOERROR | No error
 ***************************************************************************/
HRESULT CCapturePin::SendFrames(IN CFrameSample *pCapSample, IN CFrameSample *pPrevSample, IN PBYTE pbyInBuff, IN DWORD dwInBytes, OUT PDWORD pdwBytesUsed, OUT PDWORD pdwBytesExtent, IN BOOL bDiscon)
{
        HRESULT Hr = NOERROR;
        DWORD   dwBytesUsed;
        int             iStreamState;
    LPBYTE      lpbyCap;
    LPBYTE      lpbyPrev;
        DWORD   dwBytesPrev;

        FX_ENTRY("CCapturePin::SendFrames")

        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: begin", _fx_));

        // Validate input parameters
        ASSERT(pCapSample);
        ASSERT(pPrevSample);
        ASSERT(pbyInBuff);
        ASSERT(pdwBytesUsed);
        ASSERT(m_pConverter);
        if (!pCapSample || !pPrevSample || !pbyInBuff || !pdwBytesUsed || !m_pConverter)
        {
                DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: Null pointer argument!", _fx_));
                Hr = E_POINTER;
                goto MyExit;
        }

        // Get a pointer to the preview buffer
        if (FAILED(Hr = pPrevSample->GetPointer(&lpbyPrev)))
        {
                DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: Couldn't get preview buffer", _fx_));
                goto MyExit;
        }

        // Process the video capture buffer before sending it downstream, if necessary
        dwBytesUsed = 0UL;
        dwBytesPrev = 0UL;

        if (SUCCEEDED(Hr = pCapSample->GetPointer(&lpbyCap)))
        {
                Hr = m_pConverter->ConvertFrame(pbyInBuff, dwInBytes, lpbyCap, &dwBytesUsed, pdwBytesExtent, lpbyPrev, &dwBytesPrev, m_fFastUpdatePicture);
        m_fFastUpdatePicture = FALSE;

        if (FAILED(Hr))
        {
                        goto MyExit;
                }
        }

        if (dwBytesUsed && dwBytesPrev)
        {
                // It isn't necessarily a keyframe, but who cares?
                pCapSample->SetSyncPoint(TRUE);
                pCapSample->SetActualDataLength(dwBytesUsed);
                pCapSample->SetDiscontinuity(bDiscon);
                pCapSample->SetPreroll(FALSE);

                pPrevSample->SetSyncPoint(TRUE);
                pPrevSample->SetActualDataLength(dwBytesUsed);
                pPrevSample->SetDiscontinuity(bDiscon);
                pPrevSample->SetPreroll(FALSE);

                // Let the downstream pin know about the format change: [Cristi: see also inside CTAPIBasePin::SendFrame (7 Dec 2000 16:37:06)]
                if (m_fFormatChanged)
                {
                        pCapSample->SetMediaType(&m_mt);
                        //pPrevSample->SetMediaType(&m_mt); //no need to do for this one...
                        m_fFormatChanged = FALSE;
                }
                // Use the clock's graph to mark the times for the samples.  The video
                // capture card's clock is going to drift from the graph clock, so you'll
                // think we're dropping frames or sending too many frames if you look at
                // the time stamps, so we have an agreement to mark the MediaTime with the
                // frame number so you can tell if any frames are dropped.
                // Use the time we got in Run() to determine the stream time.  Also add
                // a latency (HACK!) to prevent preview renderers from thinking we're
                // late.
                // If we are RUN, PAUSED, RUN, we won't send stuff smoothly where we
                // left off because of the async nature of pause.
                CRefTime rtSample;
                CRefTime rtEnd;
                if (m_pCaptureFilter->m_pClock)
                {
                        rtSample = m_pCaptureFilter->m_cs.rtThisFrameTime - m_pCaptureFilter->m_tStart;
                        rtEnd = rtSample + m_lMaxAvgTimePerFrame;
                        pCapSample->SetTime((REFERENCE_TIME *)&rtSample, (REFERENCE_TIME *)&rtEnd);
                        pPrevSample->SetTime(NULL, NULL);
                        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s:   Stream time is %d", _fx_, (LONG)rtSample.Millisecs()));
                }
                else
                {
                        // No clock, use our driver time stamps
                        rtSample = m_pCaptureFilter->m_cs.rtThisFrameTime - m_pCaptureFilter->m_tStart;
                        rtEnd    = rtSample + m_pCaptureFilter->m_user.pvi->AvgTimePerFrame;
                        pCapSample->SetTime((REFERENCE_TIME *)&rtSample, (REFERENCE_TIME *)&rtEnd);
                        pPrevSample->SetTime(NULL, NULL);
                        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s:   No graph clock! Stream time is %d (based on driver time)", _fx_, (LONG)rtSample.Millisecs()));
                }

                // Don't deliver capture sample if the capture stream is off for now
                iStreamState = CheckStreamState(pCapSample);
                if (iStreamState == STREAM_FLOWING)
                {
                        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s:   Sending frame: Stamps(%u): Time(%d,%d)", _fx_, m_pCaptureFilter->m_pBufferQueue[m_pCaptureFilter->m_uiQueueTail], (LONG)rtSample.Millisecs(), (LONG)rtEnd.Millisecs()));
                        if ((Hr = Deliver (pCapSample)) == S_FALSE)
                                Hr = E_FAIL;    // stop delivering anymore, this is serious
                }
                else
                {
                        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s:   Discarding frame", _fx_));
                        Hr = S_FALSE;           // discarding
                }

                // Don't deliver preview sample if the preview stream is off for now
                iStreamState = m_pCaptureFilter->m_pPreviewPin->CheckStreamState(pPrevSample);
                if (iStreamState == STREAM_FLOWING)
                {
                        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s:   Sending frame: Stamps(%u): Time(%d,%d)", _fx_, m_pCaptureFilter->m_pBufferQueue[m_pCaptureFilter->m_uiQueueTail], (LONG)rtSample.Millisecs(), (LONG)rtEnd.Millisecs()));
                        if ((Hr = m_pCaptureFilter->m_pPreviewPin->Deliver (pPrevSample)) == S_FALSE)
                                Hr = E_FAIL;    // stop delivering anymore, this is serious
                }
                else
                {
                        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s:   Discarding frame", _fx_));
                        Hr = S_FALSE;           // discarding
                }
        }
        else
        {
                DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: BUFFER (%08lX %ld %lu) returned EMPTY!", _fx_, pCapSample));
        }

        *pdwBytesUsed = dwBytesUsed;

MyExit:
        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: end", _fx_));
        return Hr;
}
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\net\tapi\skywalker\filters\video\tapivcap\capturep.h ===
/****************************************************************************
 *  @doc INTERNAL CAPTUREP
 *
 *  @module CaptureP.h | Header file for the <c CCaptureProperty>
 *    class used to implement a property page to test the new TAPI internal
 *    interfaces <i IBitrateControl>, <i IFrameRateControl>, and dynamic
 *    format changes.
 *
 *  @comm This code tests the TAPI Capture Pin <i IBitrateControl>,
 *    <i IFrameRateControl>, and dynamic format change implementation. This
 *    code is only compiled if USE_PROPERTY_PAGES is defined.
 ***************************************************************************/

#ifndef _CAPTUREP_H_
#define _CAPTUREP_H_

#ifdef USE_PROPERTY_PAGES

#define NUM_CAPTURE_CONTROLS			6
#define IDC_Capture_Bitrate				0
#define IDC_Capture_CurrentBitrate		1
#define IDC_Capture_FrameRate			2
#define IDC_Capture_CurrentFrameRate	3
#define IDC_Capture_FlipVertical		4
#define IDC_Capture_FlipHorizontal		5

/****************************************************************************
 *  @doc INTERNAL CCAPTUREPCLASS
 *
 *  @class CCaptureProperty | This class implements handling of a
 *    single capture property in a property page.
 *
 *  @mdata int | CCaptureProperty | m_NumProperties | Keeps
 *    track of the number of properties.
 *
 *  @mdata IBitrateControl* | CCaptureProperty | m_pIBitrateControl | Pointer
 *    to the <i IBitrateControl> interface.
 *
 *  @mdata IFrameRateControl* | CCaptureProperty | m_pIFrameRateControl | Pointer
 *    to the <i IFrameRateControl> interface.
 *
 *  @comm This code tests the TAPI Capture Pin <i IBitrateControl>,
 *    <i IFrameRateControl>, and dynamic format change implementation. This
 *    code is only compiled if USE_PROPERTY_PAGES is defined.
***************************************************************************/
class CCaptureProperty : public CPropertyEditor 
{
	public:
	CCaptureProperty(HWND hDlg, ULONG IDLabel, ULONG IDMinControl, ULONG IDMaxControl, ULONG IDDefaultControl, ULONG IDStepControl, ULONG IDEditControl, ULONG IDTrackbarControl, ULONG IDProgressControl, ULONG IDProperty, IBitrateControl *pIBitrateControl, IFrameRateControl *pIFrameRateControl, IVideoControl *pIVideoControl);
	~CCaptureProperty ();

	// CPropertyEditor base class pure virtual overrides
	HRESULT GetValue();
	HRESULT SetValue();
	HRESULT GetRange();
	BOOL CanAutoControl(void);
	BOOL GetAuto(void);
	BOOL SetAuto(BOOL fAuto);

	private:
	IBitrateControl *m_pIBitrateControl;
	IFrameRateControl *m_pIFrameRateControl;
	IVideoControl *m_pIVideoControl;
};

/****************************************************************************
 *  @doc INTERNAL CCAPTUREPCLASS
 *
 *  @class CCaptureProperties | This class implements a property page
 *    to test the new TAPI internal interfaces <i IBitrateControl> and
 *    <i IFrameRateControl>.
 *
 *  @mdata int | CCaptureProperties | m_NumProperties | Keeps
 *    track of the number of properties.
 *
 *  @mdata IBitrateControl* | CCaptureProperties | m_pInterface | Pointer
 *    to the <i IBitrateControl> interface.
 *
 *  @mdata IFrameRateControl* | CCaptureProperties | m_pInterface | Pointer
 *    to the <i IFrameRateControl> interface.
 *
 *  @mdata CCaptureProperty* | CCaptureProperties | m_Controls[NUM_CAPTURE_CONTROLS] | Array
 *    of capture properties.
 *
 *  @comm This code tests the TAPI Capture Pin <i IBitrateControl>,
 *    <i IFrameRateControl>, and dynamic format change implementation. This
 *    code is only compiled if USE_PROPERTY_PAGES is defined.
***************************************************************************/
class CCaptureProperties : public CBasePropertyPage
{
	public:
	CCaptureProperties(LPUNKNOWN pUnk, HRESULT *pHr);
	~CCaptureProperties();


	// Implement CBasePropertyPage virtual methods
	HRESULT OnConnect(IUnknown *pUnk);
	HRESULT OnDisconnect();
	HRESULT OnActivate();
	HRESULT OnDeactivate();
	HRESULT OnApplyChanges();
	BOOL    OnReceiveMessage(HWND hWnd, UINT uMsg, WPARAM wParam, LPARAM lParam);

	private:
	void SetDirty();

	// Format manipulation methods
	HRESULT InitialRangeScan();
	HRESULT OnFormatChanged();
	HRESULT GetCurrentMediaType(void);

	HWND						m_hWnd;
	int							m_NumProperties;
	IBitrateControl				*m_pIBitrateControl;
	IFrameRateControl			*m_pIFrameRateControl;
	IAMStreamConfig				*m_pIAMStreamConfig;
	IVideoControl				*m_pIVideoControl;
	int							m_RangeCount;
	VIDEO_STREAM_CONFIG_CAPS	m_RangeCaps;
	GUID						*m_SubTypeList;
	SIZE						*m_FrameSizeList;
	GUID						m_SubTypeCurrent;
	SIZE						m_FrameSizeCurrent;
	AM_MEDIA_TYPE				*m_CurrentMediaType;
	HWND						m_hWndFormat;
	BOOL						m_fActivated;
	int							m_CurrentFormat;
	int							m_OriginalFormat;

	CCaptureProperty *m_Controls[NUM_CAPTURE_CONTROLS];
};

#endif

#endif // _CAPTUREP_H_
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\net\tapi\skywalker\filters\video\tapivcap\capture.h ===
/****************************************************************************
 *  @doc INTERNAL CAPTURE
 *
 *  @module Capture.h | Header file for the <c CCapturePin> class methods
 *    used to implement the video capture output pin.
 ***************************************************************************/

#ifndef _CAPTURE_H_
#define _CAPTURE_H_

#define MAX_VIDEO_BUFFERS 6
#define MIN_VIDEO_BUFFERS 2

#define ALIGNUP(dw,align) ((LONG_PTR)(((LONG_PTR)(dw)+(align)-1) / (align)) * (align))

class CFrameSample : public CMediaSample
{
	public:
	CFrameSample(IMemAllocator *pAllocator, HRESULT *phr, LPTHKVIDEOHDR ptvh, LPBYTE pBuffer, LONG length) : m_ptvh(ptvh), CMediaSample(NAME("Video Frame"), (CBaseAllocator *)pAllocator, phr, pBuffer, length){};
	LPTHKVIDEOHDR GetFrameHeader() {return m_ptvh;};

	private:
	const LPTHKVIDEOHDR m_ptvh;
};

/****************************************************************************
 *  @doc INTERNAL CCAPTUREPINCLASS
 *
 *  @class CCapturePin | This class implements the video capture output pin.
 *
 *  @mdata CTAPIVCap* | CCapturePin | m_pCaptureFilter | Reference to the
 *    parent capture filter.
 *
 *  @comm Supports IPin. Never created by COM, so no CreateInstance or entry
 *    in global FactoryTemplate table. Only ever created by a <c CTAPIVCap>
 *    object and returned via the EnumPins interface
 ***************************************************************************/
class CCapturePin : public CTAPIBasePin, public IStreamConfig, public IH245Capability, public IH245EncoderCommand
#ifdef USE_NETWORK_STATISTICS
, public INetworkStats
#endif
#ifdef USE_PROGRESSIVE_REFINEMENT
, public IProgressiveRefinement
#endif
#ifdef USE_PROPERTY_PAGES
, public ISpecifyPropertyPages
#endif
{
	public:
	DECLARE_IUNKNOWN
	CCapturePin(IN TCHAR *pObjectName, IN CTAPIVCap *pCaptureFilter, IN HRESULT *pHr, IN LPCWSTR pName);
	~CCapturePin();
	STDMETHODIMP NonDelegatingQueryInterface(IN REFIID riid, OUT PVOID *ppv);
	static HRESULT CALLBACK CreateCapturePin(CTAPIVCap *pCaptureFilter, CCapturePin **ppCapturePin);

	// Override CBasePin base class methods
	HRESULT SetMediaType(IN CMediaType *pMediaType);

	// Implement IStreamConfig
	STDMETHODIMP SetFormat(IN DWORD dwRTPPayLoadType, IN AM_MEDIA_TYPE *pMediaType);
	STDMETHODIMP GetFormat(OUT DWORD *pdwRTPPayLoadType, OUT AM_MEDIA_TYPE **ppMediaType);
	STDMETHODIMP GetNumberOfCapabilities(OUT DWORD *pdwCount);
	STDMETHODIMP GetStreamCaps(IN DWORD dwIndex, OUT AM_MEDIA_TYPE **ppMediaType, OUT TAPI_STREAM_CONFIG_CAPS *pTSCC, OUT DWORD *pdwRTPPayLoadType);
#ifdef TEST_ISTREAMCONFIG
	STDMETHODIMP TestIStreamConfig();
#endif

#ifdef USE_PROPERTY_PAGES
	// ISpecifyPropertyPages methods
	STDMETHODIMP GetPages(OUT CAUUID *pPages);
#endif

#ifdef USE_NETWORK_STATISTICS
	// Implement INetworkStats
	STDMETHODIMP SetChannelErrors(IN CHANNELERRORS_S *pChannelErrors, IN DWORD dwLayerId);
	STDMETHODIMP GetChannelErrors(OUT CHANNELERRORS_S *pChannelErrors, IN WORD dwLayerId);
	STDMETHODIMP GetChannelErrorsRange(OUT CHANNELERRORS_S *pMin, OUT CHANNELERRORS_S *pMax, OUT CHANNELERRORS_S *pSteppingDelta, OUT CHANNELERRORS_S *pDefault, IN DWORD dwLayerId);
	STDMETHODIMP SetPacketLossRate(IN DWORD dwPacketLossRate, IN DWORD dwLayerId);
	STDMETHODIMP GetPacketLossRate(OUT LPDWORD pdwPacketLossRate, IN DWORD dwLayerId);
	STDMETHODIMP GetPacketLossRateRange(OUT LPDWORD pdwMin, OUT LPDWORD pdwMax, OUT LPDWORD pdwSteppingDelta, OUT LPDWORD pdwDefault, IN DWORD dwLayerId);
#endif

	// Implement IH245Capability
	STDMETHODIMP GetH245VersionID(OUT DWORD *pdwVersionID);
	STDMETHODIMP GetFormatTable(OUT H245MediaCapabilityTable *pTable);
	STDMETHODIMP ReleaseFormatTable(IN H245MediaCapabilityTable *pTable);
	STDMETHODIMP IntersectFormats(
        IN DWORD dwUniqueID, 
        IN const H245MediaCapability *pLocalCapability, 
        IN const H245MediaCapability *pRemoteCapability, 
        OUT H245MediaCapability **ppIntersectedCapability,
        OUT  DWORD *pdwPayloadType
        );
	STDMETHODIMP Refine(IN OUT H245MediaCapability *pLocalCapability, IN DWORD dwUniqueID, IN DWORD dwResourceBoundIndex);
	STDMETHODIMP GetLocalFormat(IN DWORD dwUniqueID, IN const H245MediaCapability *pIntersectedCapability, OUT AM_MEDIA_TYPE **ppAMMediaType);
	STDMETHODIMP ReleaseNegotiatedCapability(IN H245MediaCapability *pIntersectedCapability);
	STDMETHODIMP FindIDByRange(IN const AM_MEDIA_TYPE *pAMMediaType, OUT DWORD *pdwID);
#ifdef TEST_H245_VID_CAPS
	STDMETHODIMP TestH245VidC();
#endif

	// Implement H245EncoderCommand
	STDMETHODIMP videoFastUpdatePicture();
	STDMETHODIMP videoFastUpdateGOB(IN DWORD dwFirstGOB, IN DWORD dwNumberOfGOBs);
	STDMETHODIMP videoFastUpdateMB(IN DWORD dwFirstGOB, IN DWORD dwFirstMB, IN DWORD dwNumberOfMBs);
	STDMETHODIMP videoSendSyncEveryGOB(IN BOOL fEnable);
	STDMETHODIMP videoNotDecodedMBs(IN DWORD dwFirstMB, IN DWORD dwNumberOfMBs, IN DWORD dwTemporalReference);

#ifdef USE_PROGRESSIVE_REFINEMENT
	// Implement IProgressiveRefinement
	STDMETHODIMP doOneProgression();
	STDMETHODIMP doContinuousProgressions();
	STDMETHODIMP doOneIndependentProgression();
	STDMETHODIMP doContinuousIndependentProgressions();
	STDMETHODIMP progressiveRefinementAbortOne();
	STDMETHODIMP progressiveRefinementAbortContinuous();
#endif

	private:

	friend class CTAPIVCap;
	// friend class CPreviewPin;
	friend class CRtpPdPin;
	friend class CAlloc;
	friend class CCapDev;

#ifdef USE_NETWORK_STATISTICS
	// Network statistics
	CHANNELERRORS_S m_ChannelErrors;
	CHANNELERRORS_S m_ChannelErrorsMin;
	CHANNELERRORS_S m_ChannelErrorsMax;
	CHANNELERRORS_S m_ChannelErrorsSteppingDelta;
	CHANNELERRORS_S m_ChannelErrorsDefault;
	DWORD m_dwPacketLossRate;
	DWORD m_dwPacketLossRateMin;
	DWORD m_dwPacketLossRateMax;
	DWORD m_dwPacketLossRateSteppingDelta;
	DWORD m_dwPacketLossRateDefault;
#endif

	// H.245 Video Capabilities
	H245MediaCapabilityMap	*m_pH245MediaCapabilityMap;
	VideoResourceBounds		*m_pVideoResourceBounds;
	FormatResourceBounds	*m_pFormatResourceBounds;

	// Payload type
	DWORD m_dwRTPPayloadType;

	// Format helper
	STDMETHODIMP GetStringFromStringTable(IN UINT uStringID, OUT WCHAR* pwchDescription);

	// Delivery method
    HRESULT	SendFrames(IN CFrameSample *pCapSample, IN CFrameSample *pPrevSample, IN PBYTE pbyInBuff, IN DWORD dwInBytes, OUT PDWORD pdwBytesUsed, OUT PDWORD pdwBytesExtent, IN BOOL bDiscon);
};

#endif // _CAPTURE_H_
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\net\tapi\skywalker\filters\video\tapivcap\convert.cpp ===
/****************************************************************************
 *  @doc INTERNAL CONVERT
 *
 *  @module Convert.cpp | Source file for the <c CConverter> class methods
 *    used to implement the video capture and preview pin format conversion
 *    routines.
 *
 *  @todo Merge the two ScaleDIB methods + fix method comments + by the end
 *    of the H.263 work, you should never have to open an ICM encoder for
 *    encoding, only decode or scaling -> clean code at that point
 ***************************************************************************/

#include "Precomp.h"

#ifdef DEBUG
#define DBGUTIL_ENABLE
#endif
#define CONVERT_DEBUG
//--//#include "dbgutil.h" // this defines the __DBGUTIL_H__ below
#if defined(DBGUTIL_ENABLE) && defined(__DBGUTIL_H__)

  #ifdef CONVERT_DEBUG
    DEFINE_DBG_VARS(Convert, (NTSD_OUT | LOG_OUT), 0x0);
  #else
    DEFINE_DBG_VARS(Convert, 0, 0);
  #endif
  #define D(f) if(g_dbg_Convert & (f))

#else
  #undef CONVERT_DEBUG

  #define D(f) ; / ## /
  #define dprintf ; / ## /
  #define dout ; / ## /
#endif


#define MIN_IFRAME_REQUEST_INTERVAL 15000

BYTE g_rmap[256];
BYTE g_gmap[256];
BYTE g_bmap[256];

enum yuvstartpos_e { Y_POS=0, U_POS, V_POS };
int UYVYplanestart[3]={ 1, 0, 2};
int YUY2planestart[3]={ 0, 1, 3};

/****************************************************************************
 *  @doc INTERNAL CCONVERTMETHOD
 *
 *  @mfunc void | CConverter | CConverter | This method is the constructor
 *    for the <c CConverter> object.
 *
 *  @rdesc Nada.
 ***************************************************************************/
CConverter::CConverter(IN TCHAR *pObjectName, IN CTAPIBasePin *pBasePin, IN PBITMAPINFOHEADER pbiIn, IN PBITMAPINFOHEADER pbiOut, IN HRESULT *pHr) : CUnknown(pObjectName, NULL, pHr)
{
        DWORD dwBmiSize, dwOutBmiSize;

        FX_ENTRY("CConverter::CConverter")

        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: begin", _fx_));

        // Validate input parameters
        ASSERT(pHr);
        ASSERT(pBasePin);
        ASSERT(pbiIn);
        ASSERT(pbiOut);
        if (!pBasePin || !pbiIn || !pbiOut || !pHr)
        {
                DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: Null pointer argument", _fx_));
                if (pHr)
                        *pHr = E_POINTER;
                goto MyExit;
        }

        // Default inits
        m_pBasePin      = pBasePin;
        m_fConvert      = FALSE;
        m_pbiInt        = NULL;
        m_pbyOut        = NULL;

        // Quality control
        m_dwImageQuality = 0UL; // Highest quality

        // Backup input format bitmap info header
        dwBmiSize = pbiIn->biSize;

        // Copy the palette if necessary
        if (pbiIn->biCompression == BI_RGB)
        {
                if (pbiIn->biBitCount == 8)
                {
                        dwBmiSize += (DWORD)(pbiIn->biClrImportant ? pbiIn->biClrImportant * sizeof(RGBQUAD) : 256 * sizeof(RGBQUAD));
                }
                else if (pbiIn->biBitCount == 4)
                {
                        dwBmiSize += (DWORD)(pbiIn->biClrImportant ? pbiIn->biClrImportant * sizeof(RGBQUAD) : 16 * sizeof(RGBQUAD));
                }
        }

        if (!(m_pbiIn = (PBITMAPINFOHEADER)(new BYTE[dwBmiSize])))
        {
                DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: Out of memory", _fx_));
                *pHr = E_OUTOFMEMORY;
                goto MyExit;
        }

        // @todo Why are we making a copy exactly?
        CopyMemory(m_pbiIn, pbiIn, dwBmiSize);

        // Backup output format bitmap info header
        // @todo Why do we make copy of this instead of keeping a reference to the bitmap infoheader?
        dwOutBmiSize = pbiOut->biSize;

        // Copy the palette if necessary
        if (pbiOut->biCompression == BI_RGB)
        {
                if (pbiOut->biBitCount == 8)
                {
                        dwOutBmiSize += (DWORD)(pbiOut->biClrImportant ? pbiOut->biClrImportant * sizeof(RGBQUAD) : 256 * sizeof(RGBQUAD));
                }
                else if (pbiOut->biBitCount == 4)
                {
                        dwOutBmiSize += (DWORD)(pbiOut->biClrImportant ? pbiOut->biClrImportant * sizeof(RGBQUAD) : 16 * sizeof(RGBQUAD));
                }
        }

        if (!(m_pbiOut = (PBITMAPINFOHEADER)(new BYTE[dwOutBmiSize])))
        {
                DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: Out of memory", _fx_));
                *pHr = E_OUTOFMEMORY;
                goto MyError1;
        }
        CopyMemory(m_pbiOut, pbiOut, dwOutBmiSize);

        // Figure out the type of conversion needed
        m_dwConversionType = CONVERSIONTYPE_NONE;
        if (m_pbiIn->biCompression == BI_RGB)
        {
                // This can only be an encoding and maybe size change
                if (m_pbiOut->biCompression != BI_RGB)
                {
                        // This can only be an encoding and maybe a size change (e.g. 176x144 RGB24 -> 176x144 H.26X)
                        m_dwConversionType |= CONVERSIONTYPE_ENCODE;
                }
        }
        else
        {
                // This can still be an encoding or decoding operation
                if (m_pbiOut->biCompression != BI_RGB)
                {
                        // This can only be an encoding and maybe a size change (e.g. 176x144 YVU9 -> 176x144 H.26X)
                        m_dwConversionType |= CONVERSIONTYPE_ENCODE;
                }
                else
                {
                        // This can only be an encoding and maybe a size change (e.g. 176x144 YVU9 -> 176x144 RGB24)
                        m_dwConversionType |= CONVERSIONTYPE_DECODE;
                }
        }

        // Do we also need a size change? or a V or H flip ?
        if (m_pbiIn->biWidth != m_pbiOut->biWidth || m_pbiIn->biHeight != m_pbiOut->biHeight || pBasePin->m_fFlipVertical || pBasePin->m_fFlipHorizontal)
        {
                if (m_dwConversionType == CONVERSIONTYPE_NONE)
                {
                        // We only need a size change  (e.g. 160x120 RGB24 -> 176x144 RGB24)
                        // This doesn't require any temporary buffer
                        m_dwConversionType |= CONVERSIONTYPE_SCALER;
                }
                else
                {
                        // We also need a size change  (e.g. 160x120 RGB24 -> 176x144 RGB24 -> 176x144 H.26X or 160x120 YVU9 -> 160x120 RGB24 -> 176x144 H.26X)
                        m_dwConversionType |= CONVERSIONTYPE_SCALER;

                        if (m_pbiIn->biCompression == BI_RGB || m_pbiIn->biCompression == VIDEO_FORMAT_YVU9 || m_pbiIn->biCompression == VIDEO_FORMAT_YUY2 || m_pbiIn->biCompression == VIDEO_FORMAT_UYVY || m_pbiIn->biCompression == VIDEO_FORMAT_I420 || m_pbiIn->biCompression == VIDEO_FORMAT_IYUV)
                        {
                                // The scaling will occur before the format conversion
                                m_dwConversionType |= CONVERSIONTYPE_PRESCALER;

                                // The input and intermediary buffers are both RGB (e.g. 160x120 RGB24 -> 176x144 RGB24 -> 176x144 H.26X)
                                if (!(m_pbiInt = (PBITMAPINFOHEADER)(new BYTE[(pbiIn->biBitCount == 4) ? pbiIn->biSize + 256 * sizeof(RGBQUAD) : dwBmiSize])))
                                {
                                        DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: Out of memory", _fx_));
                                        *pHr = E_OUTOFMEMORY;
                                        goto MyError2;
                                }

                                CopyMemory(m_pbiInt, pbiIn, dwBmiSize);

                                // If the input is 4bpp, we'll use a RGB8 intermediate format
                                if (pbiIn->biBitCount == 4)
                                {
                                        m_pbiInt->biBitCount = 8;
                                        m_pbiInt->biClrImportant = 256;
                                }
                                m_pbiInt->biWidth = m_pbiOut->biWidth;
                                m_pbiInt->biHeight = m_pbiOut->biHeight;
                                m_pbiInt->biSizeImage = DIBSIZE(*m_pbiInt);

                                // Allocate intermediary buffer
                                if (!(m_pbyOut = (PBYTE)(new BYTE[m_pbiInt->biSizeImage])))
                                {
                                        DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: Out of memory", _fx_));
                                        *pHr = E_OUTOFMEMORY;
                                        goto MyError3;
                                }
                        }
                        else
                        {
                                // We will need to decompress to an intermediary format if a size change is necessary (e.g. 160x120 MJPEG -> 160x120 RGB24 -> 176x144 RGB24)
                                if (!(m_pbiInt = (PBITMAPINFOHEADER)(new BYTE[pbiOut->biSize])))
                                {
                                        DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: Out of memory", _fx_));
                                        *pHr = E_OUTOFMEMORY;
                                        goto MyError2;
                                }
                                CopyMemory(m_pbiInt, pbiOut, pbiOut->biSize);
                                m_pbiInt->biWidth = m_pbiIn->biWidth;
                                m_pbiInt->biHeight = m_pbiIn->biHeight;
                                m_pbiInt->biSizeImage = DIBSIZE(*m_pbiInt);

                                // Allocate intermediary buffer
                                if (!(m_pbyOut = (PBYTE)(new BYTE[m_pbiInt->biSizeImage])))
                                {
                                        DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: Out of memory", _fx_));
                                        *pHr = E_OUTOFMEMORY;
                                        goto MyError3;
                                }
                        }
                }
        }

#ifdef USE_SOFTWARE_CAMERA_CONTROL
        // Soft Cam Control
        m_fSoftCamCtrl = FALSE;
#endif

        *pHr = NOERROR;

        goto MyExit;

MyError3:
        if (m_pbiInt)
                delete m_pbiInt, m_pbiInt = NULL;
MyError2:
        if (m_pbiOut)
                delete m_pbiOut, m_pbiOut = NULL;
MyError1:
        if (m_pbiIn)
                delete m_pbiIn, m_pbiIn = NULL;
MyExit:
        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: end", _fx_));
}

/****************************************************************************
 *  @doc INTERNAL CCONVERTMETHOD
 *
 *  @mfunc void | CConverter | ~CConverter | This method is the destructor
 *    for the <c CConverter> object.
 *
 *  @rdesc Nada.
 ***************************************************************************/
CConverter::~CConverter()
{
        FX_ENTRY("CConverter::~CConverter")

        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: begin", _fx_));

        if (m_pbiIn)
                delete m_pbiIn, m_pbiIn = NULL;

        if (m_pbiOut)
                delete m_pbiOut, m_pbiOut = NULL;

        if (m_pbiInt)
                delete m_pbiInt, m_pbiInt = NULL;

        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: end", _fx_));
}

/****************************************************************************
 *  @doc INTERNAL CCONVERTMETHOD
 *
 *  @mfunc HRESULT | CConverter | NonDelegatingQueryInterface | This
 *    method is the nondelegating interface query function.
 *
 *  @parm REFIID | riid | Specifies the identifier of the interface to return.
 *
 *  @parm PVOID* | ppv | Specifies the place in which to put the interface
 *    pointer.
 *
 *  @rdesc This method returns an HRESULT value that depends on the
 *    implementation of the interface. HRESULT can include one of the
 *    following standard constants, or other values not listed:
 *
 *  @flag E_FAIL | Failure
 *  @flag E_POINTER | Null pointer argument
 *  @flag NOERROR | No error
 ***************************************************************************/
STDMETHODIMP CConverter::NonDelegatingQueryInterface(IN REFIID riid, OUT void **ppv)
{
        HRESULT Hr = NOERROR;

        FX_ENTRY("CConverter::NonDelegatingQueryInterface")

        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: begin", _fx_));

        // Validate input parameters
        ASSERT(ppv);
        if (!ppv)
        {
                DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: invalid input parameter", _fx_));
                Hr = E_POINTER;
                goto MyExit;
        }

        // Retrieve interface pointer
        if (FAILED(Hr = CUnknown::NonDelegatingQueryInterface(riid, ppv)))
        {
                DBGOUT((g_dwVideoCaptureTraceID, WARN, "%s:   WARNING: NDQI for {%08lX-%04lX-%04lX-%02lX%02lX-%02lX%02lX%02lX%02lX%02lX%02lX} failed Hr=0x%08lX", _fx_, riid.Data1, riid.Data2, riid.Data3, riid.Data4[0], riid.Data4[1], riid.Data4[2], riid.Data4[3], riid.Data4[4], riid.Data4[5], riid.Data4[6], riid.Data4[7], Hr));
        }
        else
        {
                DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s:   SUCCESS: {%08lX-%04lX-%04lX-%02lX%02lX-%02lX%02lX%02lX%02lX%02lX%02lX}*=0x%08lX", _fx_, riid.Data1, riid.Data2, riid.Data3, riid.Data4[0], riid.Data4[1], riid.Data4[2], riid.Data4[3], riid.Data4[4], riid.Data4[5], riid.Data4[6], riid.Data4[7], *ppv));
        }

MyExit:
        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: end", _fx_));
        return Hr;
}

/****************************************************************************
 *  @doc INTERNAL CCONVERTMETHOD
 *
 *  @mfunc HRESULT | CICMConverter | OpenConverter | This method opens an ICM
 *    converter.
 *
 *  @rdesc This method returns an HRESULT value that depends on the
 *    implementation of the interface. HRESULT can include one of the
 *    following standard constants, or other values not listed:
 *
 *  @flag E_FAIL | Failure
 *  @flag E_POINTER | Null pointer argument
 *  @flag NOERROR | No error
 *
 *  @todo Verify error management
 ***************************************************************************/
HRESULT CICMConverter::OpenConverter()
{
        HRESULT                         Hr = NOERROR;
        ICINFO                          icInfo;
        DWORD                           dwStateSize;
        PVOID                           pvState = NULL;
        ICCOMPRESSFRAMES        iccf = {0};
        PMSH26XCOMPINSTINFO     pciMSH26XInfo;
#ifdef USE_MPEG4_SCRUNCH
        PMPEG4COMPINSTINFO      pciMPEG4Info;
#endif
        PBITMAPINFOHEADER       pbiIn, pbiOut;

        FX_ENTRY("CICMConverter::OpenConverter")

        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: begin", _fx_));

        // Validate input parameters
        ASSERT(m_pbiIn);
        ASSERT(m_pbiOut);
        ASSERT(!m_hIC);
        if (!m_pbiIn || !m_pbiOut || m_hIC)
        {
                DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: Previous converter needs to be closed first", _fx_));
                Hr = E_UNEXPECTED;
                goto MyExit;
        }

        // Use a decompressor if necessary
        if (m_dwConversionType & CONVERSIONTYPE_DECODE)
        {
                // Do we need to scale the input first?
                if (m_dwConversionType & CONVERSIONTYPE_SCALER)
                {
                        // This is different if the scaling occurs before or after
                        if (m_dwConversionType & CONVERSIONTYPE_PRESCALER)
                        {
                                pbiIn = m_pbiInt;
                                pbiOut = m_pbiOut;
                        }
                        else
                        {
                                pbiIn = m_pbiIn;
                                pbiOut = m_pbiInt;
                        }
                }
                else
                {
                        pbiIn = m_pbiIn;
                        pbiOut = m_pbiOut;
                }

                // Locate a decompressor
                if ((m_hIC = ICLocate(ICTYPE_VIDEO, 0L, pbiIn, pbiOut, ICMODE_DECOMPRESS)) == NULL)
                {
                        DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: Failed to locate a decompressor", _fx_));
                        Hr = E_FAIL;
                        goto MyError3;
                }

                // Make sure the found compressor can decompress this format at all
                if (ICDecompressQuery(m_hIC, pbiIn, pbiOut) != ICERR_OK)
                {
                        DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: Bogus decompressor", _fx_));
                        Hr = E_FAIL;
                        goto MyError4;
                }

                // Get ready for decompression
                if (ICDecompressBegin(m_hIC, pbiIn, pbiOut) != ICERR_OK)
                {
                        DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: Bogus decompressor", _fx_));
                        Hr = E_FAIL;
                        goto MyError4;
                }

                DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s:   SUCCESS: Decompressor ready", _fx_));
        }
        else if (m_dwConversionType & CONVERSIONTYPE_ENCODE)
        {
                // Locate a compressor
                if ((m_pbiOut->biCompression == FOURCC_M263) || (m_pbiOut->biCompression == FOURCC_M261))
                {
                        #define CUSTOM_ENABLE_CODEC     (ICM_RESERVED_HIGH+201)
                        #define MAGICWORD1                      0xf7329ace
                        #define MAGICWORD2                      0xacdeaea2
                        if (m_hIC = ICOpen(ICTYPE_VIDEO, m_pbiOut->biCompression, ICMODE_COMPRESS))
                                ICSendMessage(m_hIC, CUSTOM_ENABLE_CODEC, MAGICWORD1, MAGICWORD2);
                }
                else
                        m_hIC = ICLocate(ICTYPE_VIDEO, m_pbiOut->biCompression, m_pbiIn, m_pbiOut, ICMODE_COMPRESS);

                if (!m_hIC)
                {
                        DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: Failed to locate a compressor", _fx_));
                        Hr = E_FAIL;
                        goto MyError3;
                }

                // Get info about this compressor
                ICGetInfo(m_hIC, &icInfo, sizeof(ICINFO));
                m_dwFrame = 0L;
                // For now, issue a key frame every 15 seconds
                m_dwLastIFrameTime = GetTickCount();
                m_fPeriodicIFrames = TRUE;
                m_dwLastTimestamp = 0xFFFFFFFF;

                // Get the state of the compressor
                if (dwStateSize = ICGetStateSize(m_hIC))
                {
                        if (!(pvState = (PVOID) new BYTE[dwStateSize]))
                        {
                                DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: Out of memory!", _fx_));
                                Hr = E_OUTOFMEMORY;
                                goto MyError4;
                        }
                        if (((DWORD) ICGetState(m_hIC, pvState, dwStateSize)) != dwStateSize)
                        {
                                DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: ICGetState failed!", _fx_));
                                Hr = E_FAIL;
                                goto MyError5;
                        }
                }

                // Do any of the stuff that is MS H.263 or MS H.261 specific right here
                if ((m_pbiOut->biCompression == FOURCC_M263) || (m_pbiOut->biCompression == FOURCC_M261))
                {
                        pciMSH26XInfo = (PMSH26XCOMPINSTINFO)pvState;

                        // Really configure the codec for compression
                        pciMSH26XInfo->Configuration.bRTPHeader = TRUE;
                        if (m_pBasePin->m_pCaptureFilter->m_pRtpPdPin)
                                pciMSH26XInfo->Configuration.unPacketSize = m_pBasePin->m_pCaptureFilter->m_pRtpPdPin->m_dwMaxRTPPacketSize;
                        else
                                pciMSH26XInfo->Configuration.unPacketSize = DEFAULT_RTP_PACKET_SIZE;
                        pciMSH26XInfo->Configuration.bEncoderResiliency = FALSE;
                        pciMSH26XInfo->Configuration.unPacketLoss = 0;
                        pciMSH26XInfo->Configuration.bBitRateState = TRUE;
                        pciMSH26XInfo->Configuration.unBytesPerSecond = 1664;
                        if (((DWORD) ICSetState(m_hIC, (PVOID)pciMSH26XInfo, dwStateSize)) != dwStateSize)
                        {
                                DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: ICSetState failed!", _fx_));
                                Hr = E_FAIL;
                                goto MyError5;
                        }

                        // Get rid of the state structure
                        delete pvState;
                }
#ifdef USE_MPEG4_SCRUNCH
                else if ((m_pbiOut->biCompression == VIDEO_FORMAT_MPEG4_SCRUNCH))
                {
                        pciMPEG4Info = (PMPEG4COMPINSTINFO)pvState;

                        // Configure the codec for compression
                        pciMPEG4Info->lMagic = MPG4_STATE_MAGIC;
                        pciMPEG4Info->dDataRate = 20;
                        pciMPEG4Info->lCrisp = CRISP_DEF;
                        pciMPEG4Info->lKeydist = 30;
                        pciMPEG4Info->lPScale = MPG4_PSEUDO_SCALE;
                        pciMPEG4Info->lTotalWindowMs = MPG4_TOTAL_WINDOW_DEFAULT;
                        pciMPEG4Info->lVideoWindowMs = MPG4_VIDEO_WINDOW_DEFAULT;
                        pciMPEG4Info->lFramesInfoValid = FALSE;
                        pciMPEG4Info->lBFrameOn = MPG4_B_FRAME_ON;
                        pciMPEG4Info->lLiveEncode = MPG4_LIVE_ENCODE;
                        if (((DWORD) ICSetState(m_hIC, (PVOID)pciMPEG4Info, dwStateSize)) != dwStateSize)
                        {
                                DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: ICSetState failed!", _fx_));
                                Hr = E_FAIL;
                                goto MyError5;
                        }

                        // Get rid of the state structure
                        delete pvState;
                }
#endif

                // Initialize ICCOMPRESSFRAMES structure
                iccf.dwFlags = icInfo.dwFlags;
                iccf.lQuality = 10000UL - (m_dwImageQuality * 322UL);
                iccf.lDataRate = m_dwImageQuality;
                iccf.lKeyRate = 0xFFFFFFFF;
                iccf.dwRate = 1000UL;
#ifdef USE_MPEG4_SCRUNCH
                iccf.dwScale = 142857;
#else
                iccf.dwScale = (LONG)m_pBasePin->m_lMaxAvgTimePerFrame / 1000UL;
#endif

                // Send this guy to the compressor
                if ((ICSendMessage(m_hIC, ICM_COMPRESS_FRAMES_INFO, (DWORD)(LPVOID)&iccf, sizeof(iccf)) != ICERR_OK))
                {
                        DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: Codec failed to handle ICM_COMPRESS_FRAMES_INFO message correctly!", _fx_));
                        Hr = E_FAIL;
                        goto MyError4;
                }

                // Start the compressor/decompressor with the right format
                if ((ICCompressGetFormatSize(m_hIC, m_pbiIn) < sizeof(BITMAPINFOHEADER)))
                {
                        DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: ICCompressGetFormatSize failed!", _fx_));
                        Hr = E_FAIL;
                        goto MyError4;
                }

                // @todo Basd on the result of the previous call, re-allocate if necessary
                if ((ICCompressGetFormat(m_hIC, m_pbiIn, m_pbiOut)) != ICERR_OK)
                {
                        DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: ICCompressGetFormat failed!", _fx_));
                        Hr = E_FAIL;
                        goto MyError4;
                }

                if ((ICCompressBegin(m_hIC, m_pbiIn, m_pbiOut)) != MMSYSERR_NOERROR)
                {
                        DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: ICCompressBegin failed!", _fx_));
                        Hr = E_FAIL;
                        goto MyError4;
                }

                DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s:   SUCCESS: Compressor ready", _fx_));
        }
        else if (m_dwConversionType & CONVERSIONTYPE_SCALER)
        {
                // Do we need to prepare some stuff for the scaler to work?
                if (m_pbiOut->biCompression == BI_RGB && m_pbiOut->biBitCount == 8)
                {
                        if (!m_pBasePin->m_fNoImageStretch)
                        {
                                // Create a temporary palette
                                InitDst8(m_pbiOut);
                        }
                        else
                        {
                                // Look for the palette entry closest to black
                                InitBlack8(m_pbiIn);
                        }
                }
        }

        m_fConvert = TRUE;

        goto MyExit;

MyError5:
        if (pvState)
                delete pvState, pvState = NULL;
MyError4:
        if (m_hIC)
                ICClose(m_hIC), m_hIC = NULL;
MyError3:
        if (m_pbiInt)
                delete m_pbiInt, m_pbiInt = NULL;
        if (m_pbiOut)
                delete m_pbiOut, m_pbiOut = NULL;
        if (m_pbiIn)
                delete m_pbiIn, m_pbiIn = NULL;
MyExit:
        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: end", _fx_));
        return Hr;
}

/****************************************************************************
 *  @doc INTERNAL CCONVERTMETHOD
 *
 *  @mfunc HRESULT | CICMConverter | ConvertFrame | This method converts
 *    a bitmap from one format to another, or scale a bitmap.
 *
 *  @parm PBYTE | pbyInput | Pointer to the input buffer.
 *
 *  @parm DWORD | dwInputSize | Size of the input buffer.
 *
 *  @parm PBYTE | pbyOutput | Pointer to the output buffer.
 *
 *  @parm PDWORD | pdwOutputSize | Pointer to a DWORD to receive the size
 *    of the converted data.
 *
 *  @rdesc This method returns an HRESULT value that depends on the
 *    implementation of the interface. HRESULT can include one of the
 *    following standard constants, or other values not listed:
 *
 *  @flag E_FAIL | Failure
 *  @flag E_POINTER | Null pointer argument
 *  @flag NOERROR | No error
 *
 *  @todo Verify error management
 ***************************************************************************/
HRESULT CICMConverter::ConvertFrame(IN PBYTE pbyInput, IN DWORD dwInputSize, IN PBYTE pbyOutput, OUT PDWORD pdwOutputSize, OUT PDWORD pdwBytesExtent, IN PBYTE pbyPreview, IN OUT PDWORD pdwPreviewSize, IN BOOL fSendKeyFrame)
{
        HRESULT Hr = NOERROR;
        BOOL    fKeyFrame;
    DWORD       dwMaxSizeThisFrame = 0xffffff;
        DWORD   ckid = 0UL;
        DWORD   dwFlags;
        DWORD   dwTimestamp;
        RECT    rcRect;

        FX_ENTRY("CICMConverter::ConvertFrame")

        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: begin", _fx_));

        // Validate input parameters
        ASSERT(pbyInput);
        ASSERT(pbyOutput);
        ASSERT(pdwOutputSize);
        ASSERT(m_pbiIn);
        ASSERT(m_pbiOut);
        ASSERT(m_fConvert);
        if (!pbyInput || !pbyOutput || !pdwOutputSize)
        {
                DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: Null pointer argument", _fx_));
                Hr = E_POINTER;
                goto MyExit;
        }
        if (!m_pbiIn || !m_pbiOut || !m_fConvert)
        {
                DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: Converter needs to be opened first", _fx_));
                Hr = E_UNEXPECTED;
                goto MyExit;
        }

        D(1) dprintf("%s : in m_pBasePin @ %p -> m_fFlipHorizontal = %d , m_fFlipVertical = %d\n", _fx_, m_pBasePin, m_pBasePin->m_fFlipHorizontal, m_pBasePin->m_fFlipVertical);

        if (m_dwConversionType & CONVERSIONTYPE_DECODE)
        {
                ASSERT(m_hIC);

#ifdef USE_SOFTWARE_CAMERA_CONTROL
                if (IsSoftCamCtrlNeeded())
                {
                        if (!IsSoftCamCtrlInserted())
                                InsertSoftCamCtrl();
                }
                else
                {
                        if (IsSoftCamCtrlInserted())
                                RemoveSoftCamCtrl();
                }
#endif
                if (m_dwConversionType & CONVERSIONTYPE_SCALER)
                {
                        // Do we need to scale the input first?
                        if (m_dwConversionType & CONVERSIONTYPE_PRESCALER)
                        {
                                // Get the input rectangle
                                ComputeRectangle(m_pbiIn, m_pbiInt, m_pBasePin->m_pCaptureFilter->m_pCapDev->m_lCCZoom, m_pBasePin->m_pCaptureFilter->m_pCapDev->m_lCCPan, m_pBasePin->m_pCaptureFilter->m_pCapDev->m_lCCTilt, &rcRect, m_pBasePin->m_fFlipHorizontal, m_pBasePin->m_fFlipVertical);

                                // Scale DIB
                                ScaleDIB(m_pbiIn, pbyInput, m_pbiInt, m_pbyOut, &rcRect, m_pBasePin->m_fFlipHorizontal, m_pBasePin->m_fFlipVertical, m_pBasePin->m_fNoImageStretch, m_pBasePin->m_dwBlackEntry);

                                // Decompress the scaled bits to destination buffer
                                if (!m_hIC || (ICDecompress(m_hIC, 0, m_pbiInt, m_pbyOut, m_pbiOut, pbyOutput) != ICERR_OK))
                                {
                                        DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: Decompression failed!", _fx_));
                                        Hr = E_FAIL;
                                        goto MyExit;
                                }

                                // Update output size
                                *pdwOutputSize = m_pbiOut->biSizeImage;
                        }
                        else
                        {
                                // Decompress the compressed bits to temporary buffer before scaling them
                                if (!m_hIC || (ICDecompress(m_hIC, 0, m_pbiIn, pbyInput, m_pbiInt, m_pbyOut) != ICERR_OK))
                                {
                                        DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: Decompression failed!", _fx_));
                                        Hr = E_FAIL;
                                        goto MyExit;
                                }

                                // Get the input rectangle
                                ComputeRectangle(m_pbiInt, m_pbiOut, m_pBasePin->m_pCaptureFilter->m_pCapDev->m_lCCZoom, m_pBasePin->m_pCaptureFilter->m_pCapDev->m_lCCPan, m_pBasePin->m_pCaptureFilter->m_pCapDev->m_lCCTilt, &rcRect, m_pBasePin->m_fFlipHorizontal, m_pBasePin->m_fFlipVertical);

                                // Scale DIB
                                ScaleDIB(m_pbiInt, m_pbyOut, m_pbiOut, pbyOutput, &rcRect, m_pBasePin->m_fFlipHorizontal, m_pBasePin->m_fFlipVertical, m_pBasePin->m_fNoImageStretch, m_pBasePin->m_dwBlackEntry);

                                // Update output size
                                *pdwOutputSize = m_pbiOut->biSizeImage;
                        }
                }
                else
                {
                        // Decompress the compressed bits to destination buffer
                        if (!m_hIC || (ICDecompress(m_hIC, 0, m_pbiIn, pbyInput, m_pbiOut, pbyOutput) != ICERR_OK))
                        {
                                DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: Decompression failed!", _fx_));
                                Hr = E_FAIL;
                                goto MyExit;
                        }

                        // Update output size
                        *pdwOutputSize = m_pbiOut->biSizeImage;
                }
        }
        else if (m_dwConversionType & CONVERSIONTYPE_ENCODE)
        {
                ASSERT(m_hIC);

                // Save the current time
                dwTimestamp = GetTickCount();

                // Compress
                fKeyFrame = fSendKeyFrame || (m_fPeriodicIFrames && (((dwTimestamp > m_dwLastIFrameTime) && ((dwTimestamp - m_dwLastIFrameTime) > MIN_IFRAME_REQUEST_INTERVAL)))) || (m_dwFrame == 0);
                dwFlags = fKeyFrame ? AVIIF_KEYFRAME : 0;
                dwMaxSizeThisFrame = (DWORD)((LONGLONG)m_pBasePin->m_lCurrentAvgTimePerFrame * (LONGLONG)m_pBasePin->m_lTargetBitrate / 80000000);

                // We need to modify the frame number so that the codec can generate
                // a valid TR. TRs use MPIs as their units. So we need to generate a
                // frame number assuming a 29.97Hz capture rate, even though we will be
                // capturing at some other rate.
                if (m_dwLastTimestamp == 0xFFFFFFFF)
                {
                        // This is the first frame
                        m_dwFrame = 0UL;

                        // Save the current time
                        m_dwLastTimestamp = dwTimestamp;
                }
                else
                {
                        // Compare the current timestamp to the last one we saved. The difference
                        // will let us normalize the frame count to 29.97Hz.
                        if (fKeyFrame)
                        {
                                m_dwFrame = 0UL;
                                m_dwLastTimestamp = dwTimestamp;
                        }
                        else
                                m_dwFrame = (dwTimestamp - m_dwLastTimestamp) * 2997 / 100000UL;
                }

                if (fKeyFrame)
                {
                        m_dwLastIFrameTime = dwTimestamp;
                }

                if (!m_hIC || (ICCompress(m_hIC, fKeyFrame ? ICCOMPRESS_KEYFRAME : 0, m_pbiOut, pbyOutput, m_pbiIn, pbyInput, &ckid, &dwFlags, m_dwFrame++, dwMaxSizeThisFrame, 10000UL - (m_dwImageQuality * 322UL), NULL, NULL) != ICERR_OK))
                {
                        DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: Compression failed!", _fx_));
                        Hr = E_FAIL;
                        goto MyExit;
                }

                // Update output size
                if (m_pbiOut->biCompression == FOURCC_M263 || m_pbiOut->biCompression == FOURCC_M261)
                {
                        PH26X_RTP_BSINFO_TRAILER pbsiT;

                        // Look for the bitstream info trailer
                        pbsiT = (PH26X_RTP_BSINFO_TRAILER)(pbyOutput + m_pbiOut->biSizeImage - sizeof(H26X_RTP_BSINFO_TRAILER));

                        // Update output size
                        *pdwOutputSize = pbsiT->dwCompressedSize;
                }
                else
                {
                        *pdwOutputSize = m_pbiOut->biSizeImage;
                }
        }
        else if (m_dwConversionType & CONVERSIONTYPE_SCALER)
        {
#ifdef USE_SOFTWARE_CAMERA_CONTROL
                if (IsSoftCamCtrlNeeded())
                {
                        if (!IsSoftCamCtrlInserted())
                                InsertSoftCamCtrl();
                }
                else
                {
                        if (IsSoftCamCtrlInserted())
                                RemoveSoftCamCtrl();
                }
#endif

                // Get the input rectangle
                ComputeRectangle(m_pbiIn, m_pbiOut, m_pBasePin->m_pCaptureFilter->m_pCapDev->m_lCCZoom, m_pBasePin->m_pCaptureFilter->m_pCapDev->m_lCCPan, m_pBasePin->m_pCaptureFilter->m_pCapDev->m_lCCTilt, &rcRect, m_pBasePin->m_fFlipHorizontal, m_pBasePin->m_fFlipVertical);

                // Scale DIB
                ScaleDIB(m_pbiIn, pbyInput, m_pbiOut, pbyOutput, &rcRect, m_pBasePin->m_fFlipHorizontal, m_pBasePin->m_fFlipVertical, m_pBasePin->m_fNoImageStretch, m_pBasePin->m_dwBlackEntry);

                // Update output size
                *pdwOutputSize = m_pbiOut->biSizeImage;
        }

MyExit:
        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: end", _fx_));
        return Hr;
}

/****************************************************************************
 *  @doc INTERNAL CCONVERTMETHOD
 *
 *  @mfunc HRESULT | CConverter | CloseConverter | This method closes a
 *    format converter.

 *  @rdesc This method returns NOERROR.
 ***************************************************************************/
HRESULT CConverter::CloseConverter()
{
        FX_ENTRY("CConverter::CloseConverter")

        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: begin", _fx_));

        ASSERT(m_fConvert);

        // Free buffers
        if (m_pbyOut)
                delete m_pbyOut, m_pbyOut = NULL;
        if (m_pbiIn)
                delete m_pbiIn, m_pbiIn = NULL;
        if (m_pbiOut)
                delete m_pbiOut, m_pbiOut = NULL;
        if (m_pbiInt)
                delete m_pbiInt, m_pbiInt = NULL;

        m_fConvert = FALSE;

        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: end", _fx_));

        return NOERROR;
}

/****************************************************************************
 *  @doc INTERNAL CCONVERTMETHOD
 *
 *  @mfunc HRESULT | CICMConverter | CloseConverter | This method closes a
 *    format converter.

 *  @rdesc This method returns NOERROR.
 ***************************************************************************/
HRESULT CICMConverter::CloseConverter()
{
        FX_ENTRY("CICMConverter::CloseConverter")

        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: begin", _fx_));

        ASSERT(m_fConvert);

        // Validate input parameters
        if (m_hIC)
        {
                // Terminate conversion process and close convertor
                if (m_dwConversionType == CONVERSIONTYPE_ENCODE)
                        ICCompressEnd(m_hIC);
                else
                        ICDecompressEnd(m_hIC);
                ICClose(m_hIC);
                m_hIC = NULL;
        }

        CConverter::CloseConverter();

        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: end", _fx_));

        return NOERROR;
}

#define FX1     65536           // 1.0 in fixed point

#define Pel24(p,x)  (*(DWORD UNALIGNED *)((BYTE *)(p) + (x) * 3))
#define Pel16(p,x)  (((WORD *)(p))[(x)])
#define Pel8(p,x)   (BYTE)(((BYTE *)(p))[(x)])
#define Pel4(p,x)   (BYTE)(((x) & 1) ? (((BYTE *)(p))[(x) / 2]) & 0x0F : ((((BYTE *)(p))[(x) / 2]) & 0xF0) >> 4)
#define RGBX(rgb)   RGB(GetBValue(rgb), GetGValue(rgb), GetRValue(rgb))
#define RGBQ(r,g,b) RGB(b,g,r)
#define RGBW(r,g,b) ((WORD)((b) | ((g) << 5) | ((r) << 11)))
#define RGBQR(rgb)  ((BYTE)((rgb)>>16))
#define RGBQG(rgb)  ((BYTE)(((WORD)(rgb)) >> 8))
#define RGBQB(rgb)  ((BYTE)(rgb))
#define RGBWR(rgb)  ((BYTE)(((rgb) >> 11) & 31))
#define RGBWG(rgb)  ((BYTE)(((rgb) >> 5) & 31))
#define RGBWB(rgb)  ((BYTE)((rgb) & 31))

/****************************************************************************
 *  @doc INTERNAL CCONVERTMETHOD
 *
 *  @mfunc HRESULT | CTAPIBasePin | ScaleDIB | This method scales/flips
 *    an RGB bitmap.
 *
 *  @parm PBITMAPINFOHEADER | pbiSrc | Pointer to the input bitmap format.
 *
 *  @parm PBYTE | pbySrc | Pointer to the input bitmap.
 *
 *  @parm PBITMAPINFOHEADER | pbiSrc | Pointer to the output bitmap format.
 *
 *  @parm PBYTE | pbyDst | Pointer to the output bitmap.
 *
 *  @rdesc This method returns an HRESULT value that depends on the
 *    implementation of the interface. HRESULT can include one of the
 *    following standard constants, or other values not listed:
 *
 *  @flag E_FAIL | Failure
 *  @flag E_POINTER | Null pointer argument
 *  @flag E_INVALIDARG | Invalid argument
 *  @flag NOERROR | No error
 ***************************************************************************/
HRESULT ScaleDIB(PBITMAPINFOHEADER pbiSrc, PBYTE pbySrc, PBITMAPINFOHEADER pbiDst, PBYTE pbyDst, PRECT     prcRect, BOOL fFlipHorizontal, BOOL fFlipVertical, BOOL fNoImageStretch, DWORD dwBlackEntry)
{
        HRESULT Hr = NOERROR;

        FX_ENTRY("ScaleDIB")

        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: begin", _fx_));

        // Validate input parameters
        ASSERT(pbiSrc);
        ASSERT(pbySrc);
        ASSERT(pbiDst);
        ASSERT(pbyDst);
        if (!pbiSrc || !pbySrc || !pbiDst || !pbyDst)
        {
                DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: Null pointer argument", _fx_));
                Hr = E_POINTER;
                goto MyExit;
        }
        ASSERT(pbiSrc->biCompression == pbiDst->biCompression);
        ASSERT(pbiSrc->biCompression == BI_RGB || pbiSrc->biCompression == VIDEO_FORMAT_YVU9 || pbiSrc->biCompression == VIDEO_FORMAT_YUY2 || pbiSrc->biCompression == VIDEO_FORMAT_UYVY || pbiSrc->biCompression == VIDEO_FORMAT_I420 || pbiSrc->biCompression == VIDEO_FORMAT_IYUV);

        // Chose scaler based on format type
        switch (pbiSrc->biCompression)
        {
                case BI_RGB:
                {
                        // Use one of the RGB scalers
                        switch (pbiSrc->biBitCount)
                        {
                                case 24:
                                        ScaleDIB24(pbiSrc, pbySrc, pbiDst, pbyDst, prcRect, fFlipHorizontal, fFlipVertical, fNoImageStretch);
                                        break;
                                case 16:
                                        ScaleDIB16(pbiSrc, pbySrc, pbiDst, pbyDst, prcRect, fFlipHorizontal, fFlipVertical, fNoImageStretch);
                                        break;
                                case 8:
                                        ScaleDIB8(pbiSrc, pbySrc, pbiDst, pbyDst, prcRect, fFlipHorizontal, fFlipVertical, fNoImageStretch, dwBlackEntry);
                                        break;
                                case 4:
                                        ScaleDIB4(pbiSrc, pbySrc, pbiDst, pbyDst, prcRect, fFlipHorizontal, fFlipVertical, fNoImageStretch, dwBlackEntry);
                                        break;
                        }
                        break;
                }
                case VIDEO_FORMAT_YVU9:
                {
                        // Use the YUV planar scaler
                        ScaleDIBYUVPlanar(pbiSrc, pbySrc, pbiDst, pbyDst, 4, prcRect, fFlipHorizontal, fFlipVertical, fNoImageStretch);
                        break;
                }
                case VIDEO_FORMAT_YUY2:
                {
                        // Use the YUV packed scaler
                        ScaleDIBYUVPacked(pbiSrc, pbySrc, pbiDst, pbyDst, 0x80108010, prcRect, fFlipHorizontal, fFlipVertical, fNoImageStretch, YUY2planestart);
                        break;
                }
                case VIDEO_FORMAT_UYVY:
                {
                        // Use the YUV packed scaler
                        ScaleDIBYUVPacked(pbiSrc, pbySrc, pbiDst, pbyDst, 0x10801080, prcRect, fFlipHorizontal, fFlipVertical, fNoImageStretch, UYVYplanestart);
                        break;
                }
                case VIDEO_FORMAT_I420:
                case VIDEO_FORMAT_IYUV:
                {
                        // Use the YUV packed scaler
                        ScaleDIBYUVPlanar(pbiSrc, pbySrc, pbiDst, pbyDst, 2, prcRect, fFlipHorizontal, fFlipVertical, fNoImageStretch);
                        break;
                }
                default:
                {
                        DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: Only support RGB, YUV packed or planar bitmaps", _fx_));
                        Hr = E_INVALIDARG;
                }
        }

MyExit:
        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: end", _fx_));
        return Hr;
}

void InitDst8(IN OUT PBITMAPINFOHEADER pbiDst)
{
    int r,g,b;
    DWORD *pdw;

    pdw = (DWORD *)(pbiDst+1);
    pbiDst->biClrUsed = 256;
    pbiDst->biClrImportant = 256;

#define NOCOLLAPSEPALETTERGBQ(r,g,b)   (0x04000000 | RGB(b,g,r))

        // This is the palette we use when we do stretching
        for (r=0; r<10; r++)
                *pdw++ = 0UL;
    for (r=0; r<6; r++)
        for (g=0; g<6; g++)
            for (b=0; b<6; b++)
                                *pdw++ = NOCOLLAPSEPALETTERGBQ(r*255/5,g*255/5,b*255/5);
                //*pdw++ = RGBQ(r*255/5,g*255/5,b*255/5);
        for (r=0; r<30; r++)
                *pdw++ = 0UL;

    for (b=0; b<256; b++)
    {
        g_bmap[b] = b*5/255;
        g_gmap[b] = 6  * g_bmap[b];
        g_rmap[b] = 36 * g_bmap[b];
    }
}

void CConverter::InitBlack8(IN PBITMAPINFOHEADER pbiSrc)
{
        DWORD dwDistance;
        DWORD dwMinDistance = 255 + 255 + 255;
        DWORD dwNumEntries;
        DWORD *pal;

        // Look for the palette entry closest to black
        dwNumEntries = pbiSrc->biClrImportant ? pbiSrc->biClrImportant : pbiSrc->biBitCount == 8 ? 256 : 16;
        m_pBasePin->m_dwBlackEntry = 0UL;
        pal = (DWORD *)(m_pbiIn+1);
        for (DWORD dw = 0; dw < dwNumEntries; dw ++)
        {
                dwDistance = (DWORD)((RGBQUAD *)(pal+dw))->rgbBlue + (DWORD)((RGBQUAD *)(pal+dw))->rgbGreen + (DWORD)((RGBQUAD *)(pal+dw))->rgbRed;
                if (dwDistance < dwMinDistance)
                {
                        m_pBasePin->m_dwBlackEntry = dw;
                        dwMinDistance = dwDistance;
                }
        }
}

#ifndef DEBUG
#pragma optimize( "gty", on )
#endif

//int gx0y0 = 0;
//int gx0yn0 = 0;
//int gxn0y0 = 0;
//int gxfx1yfx2 = 0;
//int gall = 0;
COLORREF PASCAL MixRGB(DWORD r0, DWORD r1, DWORD r2, DWORD r3, int x, int y)
{
    int r, g, b;

    if (x == 0 && y == 0)
    {
                //gx0y0++;
        r = RGBQR(r0);
        g = RGBQG(r0);
        b = RGBQB(r0);
    }
    else if (x == 0)
    {
                //gx0yn0++;
        r = ((FX1-y) * RGBQR(r0) + y * RGBQR(r2))/FX1;
        g = ((FX1-y) * RGBQG(r0) + y * RGBQG(r2))/FX1;
        b = ((FX1-y) * RGBQB(r0) + y * RGBQB(r2))/FX1;
    }
    else if (y == 0)
    {
                //gxn0y0++;
        r = ((FX1-x) * RGBQR(r0) + x * RGBQR(r1))/FX1;
        g = ((FX1-x) * RGBQG(r0) + x * RGBQG(r1))/FX1;
        b = ((FX1-x) * RGBQB(r0) + x * RGBQB(r1))/FX1;
    }
    else if (x == FX1/2 && y == FX1/2)
    {
                //gxfx1yfx2++;
        r = (RGBQR(r0) + RGBQR(r1) + RGBQR(r2) + RGBQR(r3))/4;
        g = (RGBQG(r0) + RGBQG(r1) + RGBQG(r2) + RGBQG(r3))/4;
        b = (RGBQB(r0) + RGBQB(r1) + RGBQB(r2) + RGBQB(r3))/4;
    }
    else
    {
                //gall++;
        r =((ULONG)RGBQR(r0) * (FX1-x) / FX1 * (FX1-y) + (ULONG)RGBQR(r1) * x / FX1 * (FX1-y) +
            (ULONG)RGBQR(r2) * (FX1-x) / FX1 * y       + (ULONG)RGBQR(r3) * x / FX1 * y       )/FX1;

        g =((ULONG)RGBQG(r0) * (FX1-x) / FX1 * (FX1-y) + (ULONG)RGBQG(r1) * x / FX1 * (FX1-y) +
            (ULONG)RGBQG(r2) * (FX1-x) / FX1 * y       + (ULONG)RGBQG(r3) * x / FX1 * y       )/FX1;

        b =((ULONG)RGBQB(r0) * (FX1-x) / FX1 * (FX1-y) + (ULONG)RGBQB(r1) * x / FX1 * (FX1-y) +
            (ULONG)RGBQB(r2) * (FX1-x) / FX1 * y       + (ULONG)RGBQB(r3) * x / FX1 * y       )/FX1;
    }

    return RGB(r, g, b);
}

/****************************************************************************
 *  @doc INTERNAL CCONVERTMETHOD
 *
 *  @mfunc HRESULT | CTAPIBasePin | ScaleDIB24 | This method scales/flips
 *    a bitmap. For now, RGB24 only.
 *
 *  @parm PBITMAPINFOHEADER | pbiSrc | Pointer to the input bitmap format.
 *
 *  @parm PBYTE | pbySrc | Pointer to the input bitmap.
 *
 *  @parm PBITMAPINFOHEADER | pbiSrc | Pointer to the output bitmap format.
 *
 *  @parm PBYTE | pbyDst | Pointer to the output bitmap.
 *
 *  @rdesc This method returns an HRESULT value that depends on the
 *    implementation of the interface. HRESULT can include one of the
 *    following standard constants, or other values not listed:
 *
 *  @flag E_FAIL | Failure
 *  @flag E_POINTER | Null pointer argument
 *  @flag E_INVALIDARG | Invalid argument
 *  @flag NOERROR | No error
 *
 *  @comm On a Pentium II, 400 MHz machine, scaling a 320x240 RGB24 image
 *    to 352x288 takes 20ms. Black banding only takes 3ms.
 *
 *    Parameter validation is done in ScaleDIB.
 ***************************************************************************/
HRESULT ScaleDIB24(PBITMAPINFOHEADER pbiSrc, PBYTE pbySrc, PBITMAPINFOHEADER pbiDst, PBYTE pbyDst, PRECT prcRect, BOOL fFlipHorizontal, BOOL fFlipVertical, BOOL fNoImageStretch)
{
        HRESULT         Hr = NOERROR;
        PBYTE           pbSrc;
        PBYTE           pbDst;
        int                     dxSrc, dySrc;
        int                     dxDst, dyDst;
        int                     x0, y0, sdx, sdy;
        long            WidthBytesSrc;
        long            WidthBytesDst;
        long            lOffset;
        long            destDelta;      // it'll be +3 for normal image, -3 for FlipHorizontal (going backwards)
        DWORD           bgr0, bgr1, bgr2, bgr3;
        PBYTE           pb;
        PBYTE           pd;
        int                     x, y;
        UINT            sx, sy;
        int                     xmodfx1, ymodfx1;
        int                     FX1_xmodfx1, FX1_ymodfx1;
    long                extra;
    long                prelines, postlines, prebytes, postbytes, bytes;

        FX_ENTRY("ScaleDIB24")

        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: begin", _fx_));

        dxDst = (int)pbiDst->biWidth;
        dyDst = (int)pbiDst->biHeight;

        WidthBytesDst = DIBWIDTHBYTES(*pbiDst);
        WidthBytesSrc = DIBWIDTHBYTES(*pbiSrc);

        pbiDst->biSizeImage = WidthBytesDst * dyDst;

        if (!fNoImageStretch)
        {
                dxSrc = (int)prcRect->right - prcRect->left;
                dySrc = (int)prcRect->bottom - prcRect->top;

                pbSrc = (BYTE *)pbySrc + prcRect->left * pbiSrc->biBitCount / 8 + prcRect->top * WidthBytesSrc;

                if (fFlipHorizontal)
                {
                        destDelta = -3;
                        if (fFlipVertical)
                        {
                                lOffset = dxDst * 3 - WidthBytesDst ;
                                pbDst = (BYTE *)pbyDst + (dyDst-1) * WidthBytesDst + (dxDst-1) * 3 ;
                        }
                        else
                        {
                                lOffset = WidthBytesDst + dxDst * 3;
                                pbDst = (BYTE *)pbyDst + (dxDst-1) * 3 ;
                        }
                }
                else
                {
                        destDelta = 3;
                        if (fFlipVertical)
                        {
                                lOffset = -WidthBytesDst - dxDst * 3;
                                pbDst = (BYTE *)pbyDst + (dyDst-1) * WidthBytesDst;
                        }
                        else
                        {
                                lOffset = WidthBytesDst - dxDst * 3;
                                pbDst = (BYTE *)pbyDst;
                        }
                }

                sdx = (dxSrc-1) * FX1 / (dxDst-1);
                sdy = (dySrc-1) * FX1 / (dyDst-1);
                y0  = 0;
                x0  = 0;
                //formerly two separate branches, one for fFlipHorizontal... code merged, depending only on the values set in the 3 ifs above ...
                {
                    sy=y0,y=0;
                    pb = pbSrc + WidthBytesSrc * (sy/FX1);
                    sx=x0,x=0;
                    bgr0 = Pel24(pb,sx/FX1);
                    //bgr1 = Pel24(pb,sx/FX1+1);
                    //bgr2 = Pel24(pb+WidthBytesSrc,sx/FX1);
                    //bgr3 = Pel24(pb+WidthBytesSrc,sx/FX1+1);
                    pd = pbDst;
                    *pd++ = RGBQB(bgr0);
                    *pd++ = RGBQG(bgr0);
                    *pd++ = RGBQR(bgr0);
                    pbDst+=destDelta;
                    x++, sx+=sdx;
                    for (; x<dxDst; x++, sx+=sdx)
                    {
                        bgr0 = Pel24(pb,sx/FX1);
                        bgr1 = Pel24(pb,sx/FX1-1);      //1
                        //bgr2 = Pel24(pb+WidthBytesSrc,sx/FX1);
                        //bgr3 = Pel24(pb+WidthBytesSrc,sx/FX1+1);
                        xmodfx1 = sx%FX1;
                        pd = pbDst;
                        *pd++ = ((xmodfx1) * RGBQB(bgr0) + (FX1-xmodfx1) * RGBQB(bgr1))/FX1;
                        *pd++ = ((xmodfx1) * RGBQG(bgr0) + (FX1-xmodfx1) * RGBQG(bgr1))/FX1;
                        *pd++ = ((xmodfx1) * RGBQR(bgr0) + (FX1-xmodfx1) * RGBQR(bgr1))/FX1;
                        pbDst+=destDelta;
                        //*pbDst++ = ((FX1-xmodfx1) * RGBQB(bgr0) + xmodfx1 * RGBQB(bgr1))/FX1;
                        //*pbDst++ = ((FX1-xmodfx1) * RGBQG(bgr0) + xmodfx1 * RGBQG(bgr1))/FX1;
                        //*pbDst++ = ((FX1-xmodfx1) * RGBQR(bgr0) + xmodfx1 * RGBQR(bgr1))/FX1;
                    }
                    pbDst += lOffset; //(WidthBytesDst-dxDst*3);
                    y++,sy+=sdy;
                    for (; y<dyDst; y++,sy+=sdy)
                    {
                        pb = pbSrc + WidthBytesSrc * (sy/FX1);
                        sx=x0,x=0;
                        bgr0 = Pel24(pb,sx/FX1);
                        //bgr1 = Pel24(pb,sx/FX1-1); //1
                        bgr2 = Pel24(pb-WidthBytesSrc,sx/FX1);          //WidthBytesSrc
                        //bgr3 = Pel24(pb-WidthBytesSrc,sx/FX1-1);      //WidthBytesSrc    +1
                        ymodfx1 = sy%FX1;
                        pd = pbDst;
                        *pd++ = ((ymodfx1) * RGBQB(bgr0) + (FX1-ymodfx1) * RGBQB(bgr2))/FX1;
                        *pd++ = ((ymodfx1) * RGBQG(bgr0) + (FX1-ymodfx1) * RGBQG(bgr2))/FX1;
                        *pd++ = ((ymodfx1) * RGBQR(bgr0) + (FX1-ymodfx1) * RGBQR(bgr2))/FX1;
                        pbDst+=destDelta;
                        //*pbDst++ = ((FX1-ymodfx1) * RGBQB(bgr0) + ymodfx1 * RGBQB(bgr2))/FX1;
                        //*pbDst++ = ((FX1-ymodfx1) * RGBQG(bgr0) + ymodfx1 * RGBQG(bgr2))/FX1;
                        //*pbDst++ = ((FX1-ymodfx1) * RGBQR(bgr0) + ymodfx1 * RGBQR(bgr2))/FX1;
                        x++, sx+=sdx;
                        for (; x<dxDst; x++, sx+=sdx)
                        {
                            bgr0 = Pel24(pb,sx/FX1);
                            bgr1 = Pel24(pb,sx/FX1-1);                     //1
                            bgr2 = Pel24(pb-WidthBytesSrc,sx/FX1);         //WidthBytesSrc
                            bgr3 = Pel24(pb-WidthBytesSrc,sx/FX1-1);       //WidthBytesSrc    +1
                            xmodfx1 = sx%FX1;
                            ymodfx1 = sy%FX1;
                            FX1_xmodfx1 = FX1-xmodfx1;
                            FX1_ymodfx1 = FX1-ymodfx1;
                            pd = pbDst;
                            *pd++ =   (BYTE)(((ULONG)RGBQB(bgr0) * xmodfx1     / FX1 * ymodfx1     +
                                              (ULONG)RGBQB(bgr1) * FX1_xmodfx1 / FX1 * ymodfx1     +
                                              (ULONG)RGBQB(bgr2) * xmodfx1     / FX1 * FX1_ymodfx1 +
                                              (ULONG)RGBQB(bgr3) * FX1_xmodfx1 / FX1 * FX1_ymodfx1     )/FX1);
                            //*pbDst++ =(BYTE)(((ULONG)RGBQB(bgr0) * FX1_xmodfx1 / FX1 * FX1_ymodfx1 +
                            //                  (ULONG)RGBQB(bgr1) * xmodfx1     / FX1 * FX1_ymodfx1 +
                            //                  (ULONG)RGBQB(bgr2) * FX1_xmodfx1 / FX1 * ymodfx1     +
                            //                  (ULONG)RGBQB(bgr3) * xmodfx1     / FX1 * ymodfx1         )/FX1);

                            *pd++ =   (BYTE)(((ULONG)RGBQG(bgr0) * xmodfx1     / FX1 * ymodfx1     +
                                              (ULONG)RGBQG(bgr1) * FX1_xmodfx1 / FX1 * ymodfx1     +
                                              (ULONG)RGBQG(bgr2) * xmodfx1     / FX1 * FX1_ymodfx1 +
                                              (ULONG)RGBQG(bgr3) * FX1_xmodfx1 / FX1 * FX1_ymodfx1     )/FX1);
                            //*pbDst++ =(BYTE)(((ULONG)RGBQG(bgr0) * FX1_xmodfx1 / FX1 * FX1_ymodfx1 +
                            //                  (ULONG)RGBQG(bgr1) * xmodfx1     / FX1 * FX1_ymodfx1 +
                            //                  (ULONG)RGBQG(bgr2) * FX1_xmodfx1 / FX1 * ymodfx1     +
                            //                  (ULONG)RGBQG(bgr3) * xmodfx1     / FX1 * ymodfx1         )/FX1);
                            *pd++ =   (BYTE)(((ULONG)RGBQR(bgr0) * xmodfx1     / FX1 * ymodfx1     +
                                              (ULONG)RGBQR(bgr1) * FX1_xmodfx1 / FX1 * ymodfx1     +
                                              (ULONG)RGBQR(bgr2) * xmodfx1     / FX1 * FX1_ymodfx1 +
                                              (ULONG)RGBQR(bgr3) * FX1_xmodfx1 / FX1 * FX1_ymodfx1     )/FX1);
                            //*pbDst++ =(BYTE)(((ULONG)RGBQR(bgr0) * FX1_xmodfx1 / FX1 * FX1_ymodfx1 +
                            //                  (ULONG)RGBQR(bgr1) * xmodfx1     / FX1 * FX1_ymodfx1 +
                            //                  (ULONG)RGBQR(bgr2) * FX1_xmodfx1 / FX1 * ymodfx1     +
                            //                  (ULONG)RGBQR(bgr3) * xmodfx1     / FX1 * ymodfx1         )/FX1);
                            pbDst+=destDelta;
                        }
                    pbDst += lOffset; //(WidthBytesDst-dxDst*3);
                    }
                }
        }
        else
        {
                dxSrc = (int)pbiSrc->biWidth;
                dySrc = (int)pbiSrc->biHeight;

                pbSrc = (BYTE *)pbySrc;
                pbDst = (BYTE *)pbyDst;

        if ((dxSrc >= dxDst) && (dySrc >= dyDst))
                {
                    // starts by skipping half of the height change
                    pbSrc = pbSrc + (dySrc - dyDst) / 2 * WidthBytesSrc;

                    // extra = # of source bytes per scan line that are to be cropped
                    extra = (dxSrc - dxDst) * 3;

                    // advance pIn by half of extra to crop left most pixels
                    pbSrc += extra / 2;

                    // adjust ipitch so we can add it at the end of each scan to get to start of next scan
                    WidthBytesSrc = WidthBytesSrc - (dxSrc * 3) + extra;
                    WidthBytesDst -= dxDst * 3;      // bytes at end of each row

                    for (y = 0; y < dyDst; y++) {
                        for (x = 0; x < dxDst; x++) {
                                    *pbDst++ = *pbSrc++;   // blue
                                    *pbDst++ = *pbSrc++;   // green
                                    *pbDst++ = *pbSrc++;   // red
                        }
                        pbSrc += WidthBytesSrc;          // get to start of next row
                        pbDst += WidthBytesDst;         // get to start of next row
                    }
                }
                else
                {
                    prelines = (dyDst - dySrc) / 2;
                    postlines = dyDst - dySrc - prelines;

                    prebytes = (dxDst - dxSrc) / 2;
                    postbytes = (dxDst - dxSrc - prebytes) * 3;
                    prebytes *= 3;

                    WidthBytesSrc -= dxSrc * 3;        // bytes at end of each src row
                    bytes = dxDst * 3;
                    extra = WidthBytesDst - bytes + postbytes;                    // bytes at end of each dst row

                    // do blank lines at front of destination
                    for (y = 0; y < prelines; y++)
                        {
                        ZeroMemory (pbDst, bytes);
                        pbDst += WidthBytesDst;
                    }

                    // copy source lines with blank space at front and rear
                    for (y = 0; y < dySrc; y++)
                        {
                        ZeroMemory (pbDst, prebytes);
                        pbDst += prebytes;

                        for (x = 0; x < dxSrc; x++)
                                {
                                    *pbDst++ = *pbSrc++;   // blue
                                    *pbDst++ = *pbSrc++;   // green
                                    *pbDst++ = *pbSrc++;   // red
                        }

                        ZeroMemory (pbDst, postbytes);
                        pbSrc += WidthBytesSrc;
                        pbDst += extra;
                    }

                    // do blank lines at end of destination
                    for (y = 0; y < postlines; y++)
                        {
                        ZeroMemory (pbDst, bytes);
                        pbDst += WidthBytesDst;
                    }
                }
        }

        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: end", _fx_));
        return Hr;
}

/****************************************************************************
 *  @doc INTERNAL CCONVERTMETHOD
 *
 *  @mfunc HRESULT | CTAPIBasePin | ScaleDIB16 | This method scales/flips
 *    a bitmap. For now, RGB16 only.
 *
 *  @parm PBITMAPINFOHEADER | pbiSrc | Pointer to the input bitmap format.
 *
 *  @parm PBYTE | pbySrc | Pointer to the input bitmap.
 *
 *  @parm PBITMAPINFOHEADER | pbiSrc | Pointer to the output bitmap format.
 *
 *  @parm PBYTE | pbyDst | Pointer to the output bitmap.
 *
 *  @rdesc This method returns an HRESULT value that depends on the
 *    implementation of the interface. HRESULT can include one of the
 *    following standard constants, or other values not listed:
 *
 *  @flag E_FAIL | Failure
 *  @flag E_POINTER | Null pointer argument
 *  @flag E_INVALIDARG | Invalid argument
 *  @flag NOERROR | No error
 *
 *  @comm Parameter validation is done in ScaleDIB.
 ***************************************************************************/
HRESULT ScaleDIB16(PBITMAPINFOHEADER pbiSrc, PBYTE pbySrc, PBITMAPINFOHEADER pbiDst, PBYTE pbyDst, PRECT prcRect, BOOL fFlipHorizontal, BOOL fFlipVertical, BOOL fNoImageStretch)
{
        HRESULT         Hr = NOERROR;
        PBYTE           pbSrc;
        PWORD           pbDst;
        int                     dxSrc, dySrc;
        int                     dxDst, dyDst;
        int                     x0, y0, sdx, sdy;
        long            WidthBytesSrc;
        long            WidthBytesDst;
        long            lOffset;
        WORD            bgr0, bgr1, bgr2, bgr3;
        PBYTE           pb;
        int                     x, y;
        UINT            sx, sy;
        int                     xmodfx1, ymodfx1;
        int                     FX1_xmodfx1, FX1_ymodfx1;
    long                extra;
    long                prelines, postlines, prebytes, postbytes, bytes;

        FX_ENTRY("ScaleDIB16")

        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: begin", _fx_));

        dxDst = (int)pbiDst->biWidth;
        dyDst = (int)pbiDst->biHeight;

        WidthBytesDst = DIBWIDTHBYTES(*pbiDst);
        WidthBytesSrc = DIBWIDTHBYTES(*pbiSrc);

        pbiDst->biSizeImage = WidthBytesDst * dyDst;

        if (!fNoImageStretch)
        {
                BYTE b, g, r;

                dxSrc = (int)prcRect->right - prcRect->left;
                dySrc = (int)prcRect->bottom - prcRect->top;

                pbSrc = (BYTE *)pbySrc + prcRect->left * pbiSrc->biBitCount / 8 + prcRect->top * WidthBytesSrc;

                if (fFlipHorizontal)
                {
                        if (fFlipVertical)
                        {
                                lOffset = (dxDst * 2 - WidthBytesDst) / 2;
                                pbDst = (PWORD)(pbyDst + (dyDst-1) * WidthBytesDst + dxDst * 2 - 2);
                        }
                        else
                        {
                                lOffset = (WidthBytesDst + dxDst * 2) / 2;
                                pbDst = (PWORD)(pbyDst + dxDst * 2 - 2);
                        }
                }
                else
                {
                        if (fFlipVertical)
                        {
                                lOffset = (-WidthBytesDst - dxDst * 2) / 2;
                                pbDst = (PWORD)(pbyDst + (dyDst-1) * WidthBytesDst);
                        }
                        else
                        {
                                lOffset = (WidthBytesDst - dxDst * 2) / 2;
                                pbDst = (PWORD)pbyDst;
                        }
                }

                // TESTED (both zoom in and out)

                sdx = (dxSrc-1) * FX1 / (dxDst-1);
                sdy = (dySrc-1) * FX1 / (dyDst-1);
                y0  = 0;
                x0  = 0;

                if (fFlipHorizontal)
                {
                        sy=y0,y=0;
                    pb = pbSrc + WidthBytesSrc * (sy/FX1);
                        sx=x0,x=0;
                    bgr0 = Pel16(pb,sx/FX1);
                        r = RGBWR(bgr0);
                        g = RGBWG(bgr0);
                        b = RGBWB(bgr0);
                        *pbDst-- = RGBW(RGBWR(bgr0), RGBWG(bgr0), RGBWB(bgr0));
                        x++, sx+=sdx;
                    for (; x<dxDst; x++, sx+=sdx)
                    {
                        bgr0 = Pel16(pb,sx/FX1);
                        bgr1 = Pel16(pb,sx/FX1+1);
                                xmodfx1 = sx%FX1;
                                *pbDst-- = RGBW(((FX1-xmodfx1) * RGBWR(bgr0) + xmodfx1 * RGBWR(bgr1))/FX1, ((FX1-xmodfx1) * RGBWG(bgr0) + xmodfx1 * RGBWG(bgr1))/FX1, ((FX1-xmodfx1) * RGBWB(bgr0) + xmodfx1 * RGBWB(bgr1))/FX1);
                    }
                        pbDst += lOffset;
                        y++,sy+=sdy;
                        for (; y<dyDst; y++,sy+=sdy)
                    {
                        pb = pbSrc + WidthBytesSrc * (sy/FX1);
                                sx=x0,x=0;
                        bgr0 = Pel16(pb,sx/FX1);
                        bgr2 = Pel16(pb+WidthBytesSrc,sx/FX1);
                                ymodfx1 = sy%FX1;
                                *pbDst-- = RGBW(((FX1-ymodfx1) * RGBWR(bgr0) + ymodfx1 * RGBWR(bgr2))/FX1, ((FX1-ymodfx1) * RGBWG(bgr0) + ymodfx1 * RGBWG(bgr2))/FX1, ((FX1-ymodfx1) * RGBWB(bgr0) + ymodfx1 * RGBWB(bgr2))/FX1);
                                x++, sx+=sdx;
                        for (; x<dxDst; x++, sx+=sdx)
                        {
                            bgr0 = Pel16(pb,sx/FX1);
                            bgr1 = Pel16(pb,sx/FX1+1);
                            bgr2 = Pel16(pb+WidthBytesSrc,sx/FX1);
                            bgr3 = Pel16(pb+WidthBytesSrc,sx/FX1+1);
                                        xmodfx1 = sx%FX1;
                                        ymodfx1 = sy%FX1;
                                        FX1_xmodfx1 = FX1-xmodfx1;
                                        FX1_ymodfx1 = FX1-ymodfx1;
                                        *pbDst-- = RGBW((BYTE)(((ULONG)RGBWR(bgr0) * FX1_xmodfx1 / FX1 * FX1_ymodfx1 + (ULONG)RGBWR(bgr1) * xmodfx1 / FX1 * FX1_ymodfx1 + (ULONG)RGBWR(bgr2) * FX1_xmodfx1 / FX1 * ymodfx1       + (ULONG)RGBWR(bgr3) * xmodfx1 / FX1 * ymodfx1       )/FX1), (BYTE)(((ULONG)RGBWG(bgr0) * FX1_xmodfx1 / FX1 * FX1_ymodfx1 + (ULONG)RGBWG(bgr1) * xmodfx1 / FX1 * FX1_ymodfx1 + (ULONG)RGBWG(bgr2) * FX1_xmodfx1 / FX1 * ymodfx1       + (ULONG)RGBWG(bgr3) * xmodfx1 / FX1 * ymodfx1       )/FX1), (BYTE)(((ULONG)RGBWB(bgr0) * FX1_xmodfx1 / FX1 * FX1_ymodfx1 + (ULONG)RGBWB(bgr1) * xmodfx1 / FX1 * FX1_ymodfx1 + (ULONG)RGBWB(bgr2) * FX1_xmodfx1 / FX1 * ymodfx1       + (ULONG)RGBWB(bgr3) * xmodfx1 / FX1 * ymodfx1       )/FX1));
                        }
                                pbDst += lOffset;
                        }
                }
                else
                {
                        sy=y0,y=0;
                    pb = pbSrc + WidthBytesSrc * (sy/FX1);
                        sx=x0,x=0;
                    bgr0 = Pel16(pb,sx/FX1);
                        r = RGBWR(bgr0);
                        g = RGBWG(bgr0);
                        b = RGBWB(bgr0);
                        *pbDst++ = RGBW(RGBWR(bgr0), RGBWG(bgr0), RGBWB(bgr0));
                        x++, sx+=sdx;
                    for (; x<dxDst; x++, sx+=sdx)
                    {
                        bgr0 = Pel16(pb,sx/FX1);
                        bgr1 = Pel16(pb,sx/FX1+1);
                                xmodfx1 = sx%FX1;
                                *pbDst++ = RGBW(((FX1-xmodfx1) * RGBWR(bgr0) + xmodfx1 * RGBWR(bgr1))/FX1, ((FX1-xmodfx1) * RGBWG(bgr0) + xmodfx1 * RGBWG(bgr1))/FX1, ((FX1-xmodfx1) * RGBWB(bgr0) + xmodfx1 * RGBWB(bgr1))/FX1);
                    }
                        pbDst += lOffset;
                        y++,sy+=sdy;
                        for (; y<dyDst; y++,sy+=sdy)
                    {
                        pb = pbSrc + WidthBytesSrc * (sy/FX1);
                                sx=x0,x=0;
                        bgr0 = Pel16(pb,sx/FX1);
                        bgr2 = Pel16(pb+WidthBytesSrc,sx/FX1);
                                ymodfx1 = sy%FX1;
                                *pbDst++ = RGBW(((FX1-ymodfx1) * RGBWR(bgr0) + ymodfx1 * RGBWR(bgr2))/FX1, ((FX1-ymodfx1) * RGBWG(bgr0) + ymodfx1 * RGBWG(bgr2))/FX1, ((FX1-ymodfx1) * RGBWB(bgr0) + ymodfx1 * RGBWB(bgr2))/FX1);
                                x++, sx+=sdx;
                        for (; x<dxDst; x++, sx+=sdx)
                        {
                            bgr0 = Pel16(pb,sx/FX1);
                            bgr1 = Pel16(pb,sx/FX1+1);
                            bgr2 = Pel16(pb+WidthBytesSrc,sx/FX1);
                            bgr3 = Pel16(pb+WidthBytesSrc,sx/FX1+1);
                                        xmodfx1 = sx%FX1;
                                        ymodfx1 = sy%FX1;
                                        FX1_xmodfx1 = FX1-xmodfx1;
                                        FX1_ymodfx1 = FX1-ymodfx1;
                                        *pbDst++ = RGBW((BYTE)(((ULONG)RGBWR(bgr0) * FX1_xmodfx1 / FX1 * FX1_ymodfx1 + (ULONG)RGBWR(bgr1) * xmodfx1 / FX1 * FX1_ymodfx1 + (ULONG)RGBWR(bgr2) * FX1_xmodfx1 / FX1 * ymodfx1       + (ULONG)RGBWR(bgr3) * xmodfx1 / FX1 * ymodfx1       )/FX1), (BYTE)(((ULONG)RGBWG(bgr0) * FX1_xmodfx1 / FX1 * FX1_ymodfx1 + (ULONG)RGBWG(bgr1) * xmodfx1 / FX1 * FX1_ymodfx1 + (ULONG)RGBWG(bgr2) * FX1_xmodfx1 / FX1 * ymodfx1       + (ULONG)RGBWG(bgr3) * xmodfx1 / FX1 * ymodfx1       )/FX1), (BYTE)(((ULONG)RGBWB(bgr0) * FX1_xmodfx1 / FX1 * FX1_ymodfx1 + (ULONG)RGBWB(bgr1) * xmodfx1 / FX1 * FX1_ymodfx1 + (ULONG)RGBWB(bgr2) * FX1_xmodfx1 / FX1 * ymodfx1       + (ULONG)RGBWB(bgr3) * xmodfx1 / FX1 * ymodfx1       )/FX1));
                        }
                                pbDst += lOffset;
                        }
                }
        }
        else
        {
                dxSrc = (int)pbiSrc->biWidth;
                dySrc = (int)pbiSrc->biHeight;

                pbSrc = (BYTE *)pbySrc;
                pbDst = (WORD *)pbyDst;

        if ((dxSrc >= dxDst) && (dySrc >= dyDst))
                {
                        // TESTED (zoom out)

                    // starts by skipping half of the height change
                    pbSrc = pbSrc + (dySrc - dyDst) / 2 * WidthBytesSrc;

                    // extra = # of source bytes per scan line that are to be cropped
                    extra = (dxSrc - dxDst) * 2;

                    // advance pIn by half of extra to crop left most pixels
                    pbSrc += extra / 2;

                    // adjust ipitch so we can add it at the end of each scan to get to start of next scan
                    WidthBytesSrc = WidthBytesSrc - (dxSrc * 2) + extra;
                    WidthBytesDst -= dxDst * 2;      // bytes at end of each row

                    for (y = 0; y < dyDst; y++) {
                        for (x = 0; x < dxDst; x++) {
                                    *pbDst++ = *pbSrc++;   // blue - green
                                    *pbDst++ = *pbSrc++;   // green     - red
                        }
                        pbSrc += WidthBytesSrc;          // get to start of next row
                        pbDst += WidthBytesDst;         // get to start of next row
                    }
                }
                else
                {
                        // TESTED (zoom in)

                    prelines = (dyDst - dySrc) / 2;
                    postlines = dyDst - dySrc - prelines;

                    prebytes = (dxDst - dxSrc) / 2;
                    postbytes = (dxDst - dxSrc - prebytes) * 2;
                    prebytes *= 2;

                    WidthBytesSrc -= dxSrc * 2;        // bytes at end of each src row
                    bytes = dxDst * 2;
                    extra = WidthBytesDst - bytes + postbytes;                    // bytes at end of each dst row

                    // do blank lines at front of destination
                    for (y = 0; y < prelines; y++)
                        {
                        ZeroMemory (pbDst, bytes);
                        pbDst += WidthBytesDst;
                    }

                    // copy source lines with blank space at front and rear
                    for (y = 0; y < dySrc; y++)
                        {
                        ZeroMemory (pbDst, prebytes);
                        pbDst += prebytes;

                        for (x = 0; x < dxSrc; x++)
                                {
                                    *pbDst++ = *pbSrc++;   // blue - green
                                    *pbDst++ = *pbSrc++;   // green     - red
                        }

                        ZeroMemory (pbDst, postbytes);
                        pbSrc += WidthBytesSrc;
                        pbDst += extra;
                    }

                    // do blank lines at end of destination
                    for (y = 0; y < postlines; y++)
                        {
                        ZeroMemory (pbDst, bytes);
                        pbDst += WidthBytesDst;
                    }
                }
        }

        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: end", _fx_));
        return Hr;
}

/****************************************************************************
 *  @doc INTERNAL CCONVERTMETHOD
 *
 *  @mfunc HRESULT | CTAPIBasePin | ScaleDIB8 | This method scales/flips
 *    a bitmap. For now, RGB8 only.
 *
 *  @parm PBITMAPINFOHEADER | pbiSrc | Pointer to the input bitmap format.
 *
 *  @parm PBYTE | pbySrc | Pointer to the input bitmap.
 *
 *  @parm PBITMAPINFOHEADER | pbiSrc | Pointer to the output bitmap format.
 *
 *  @parm PBYTE | pbyDst | Pointer to the output bitmap.
 *
 *  @rdesc This method returns an HRESULT value that depends on the
 *    implementation of the interface. HRESULT can include one of the
 *    following standard constants, or other values not listed:
 *
 *  @flag E_FAIL | Failure
 *  @flag E_POINTER | Null pointer argument
 *  @flag E_INVALIDARG | Invalid argument
 *  @flag NOERROR | No error
 *
 *  @comm Parameter validation is done in ScaleDIB.
 ***************************************************************************/
HRESULT ScaleDIB8(PBITMAPINFOHEADER pbiSrc, PBYTE pbySrc, PBITMAPINFOHEADER pbiDst, PBYTE pbyDst, PRECT prcRect, BOOL fFlipHorizontal, BOOL fFlipVertical, BOOL fNoImageStretch, DWORD dwBlackEntry)
{
        HRESULT         Hr = NOERROR;
        PBYTE           pbSrc;
        PBYTE           pbDst;
    DWORD               *pal;
        COLORREF        rgb;
        int                     dxSrc, dySrc;
        int                     dxDst, dyDst;
        int                     x0, y0, sdx, sdy;
        long            WidthBytesSrc;
        long            WidthBytesDst;
        BYTE            b0, b1, b2, b3;
        PBYTE           pb;
        int                     x, y;
        UINT            sx, sy;
        int                     xmodfx1, ymodfx1;
    long                extra;
    long                prelines, postlines, prebytes, postbytes, bytes;

        FX_ENTRY("ScaleDIB8")

        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: begin", _fx_));

        dxSrc = (int)pbiSrc->biWidth;
        dySrc = (int)pbiSrc->biHeight;

        dxDst = (int)pbiDst->biWidth;
        dyDst = (int)pbiDst->biHeight;

        WidthBytesDst = DIBWIDTHBYTES(*pbiDst);
        WidthBytesSrc = DIBWIDTHBYTES(*pbiSrc);

        pbiDst->biSizeImage = WidthBytesDst * dyDst;

        pbSrc = (BYTE *)pbySrc;
        pbDst = (BYTE *)pbyDst;

    pal = (DWORD *)(pbiSrc+1);

        if (!fNoImageStretch)
        {
                // TESTED (both zoom in and out)

            if (dxSrc == dxDst*2 && dySrc == dyDst*2)
            {
                sdx = FX1*2;
                sdy = FX1*2;
                y0  = FX1/2;
                x0  = FX1/2;
            }
            else
            {
                sdx = (dxSrc-1) * FX1 / (dxDst-1);
                sdy = (dySrc-1) * FX1 / (dyDst-1);
                y0  = 0;
                x0  = 0;
            }

            for (sy=y0,y=0; y<dyDst; y++,sy+=sdy)
            {
                pb = pbSrc + WidthBytesSrc * (sy/FX1);
                for (sx=x0, x=0; x<dxDst; x++, sx+=sdx)
                {
                    b0 = Pel8(pb, sx/FX1);
                    b1 = Pel8(pb, sx/FX1+1);
                    b2 = Pel8(pb+WidthBytesSrc, sx/FX1);
                    b3 = Pel8(pb+WidthBytesSrc, sx/FX1+1);

                                xmodfx1 = sx%FX1;
                                ymodfx1 = sy%FX1;

                            if ((b0==b1 && b1==b2 && b2==b3) || (xmodfx1==0 && ymodfx1==0))
                                rgb = RGBX(pal[b0]);
                            else
                                rgb = MixRGB(pal[b0], pal[b1], pal[b2], pal[b3], xmodfx1, ymodfx1);

                                pbDst[x] = (BYTE)(g_rmap[GetRValue(rgb)] + g_gmap[GetGValue(rgb)] + g_bmap[GetBValue(rgb)] + 10);
                                //pbDst[x] = (BYTE)(rmap[GetRValue(rgb)] + gmap[GetGValue(rgb)] + bmap[GetBValue(rgb)]);
                }
                pbDst += WidthBytesDst;
            }
        }
        else
        {
        if ((dxSrc >= dxDst) && (dySrc >= dyDst))
                {
                        // TESTED (zoom out)

                    // starts by skipping half of the height change
                    pbSrc = pbSrc + (dySrc - dyDst) / 2 * WidthBytesSrc;

                    // extra = # of source bytes per scan line that are to be cropped
                    extra = dxSrc - dxDst;

                    // advance pIn by half of extra to crop left most pixels
                    pbSrc += extra / 2;

                    // adjust ipitch so we can add it at the end of each scan to get to start of next scan
                    WidthBytesSrc = WidthBytesSrc - dxSrc + extra;
                    WidthBytesDst -= dxDst;      // bytes at end of each row

                    for (y = 0; y < dyDst; y++) {
                        for (x = 0; x < dxDst; x++) {
                                    *pbDst++ = *pbSrc++;
                        }
                        pbSrc += WidthBytesSrc;          // get to start of next row
                        pbDst += WidthBytesDst;         // get to start of next row
                    }
                }
                else
                {
                        // TESTED (zoom in)

                    prelines = (dyDst - dySrc) / 2;
                    postlines = dyDst - dySrc - prelines;

                    prebytes = (dxDst - dxSrc) / 2;
                    postbytes = dxDst - dxSrc - prebytes;

                    WidthBytesSrc -= dxSrc;        // bytes at end of each src row
                    bytes = dxDst;
                    extra = WidthBytesDst - bytes + postbytes;                    // bytes at end of each dst row

                    // do blank lines at front of destination
                    for (y = 0; y < prelines; y++)
                        {
                        FillMemory (pbDst, bytes, (BYTE)dwBlackEntry);
                        pbDst += WidthBytesDst;
                    }

                    // copy source lines with blank space at front and rear
                    for (y = 0; y < dySrc; y++)
                        {
                        FillMemory (pbDst, prebytes, (BYTE)dwBlackEntry);
                        pbDst += prebytes;

                        for (x = 0; x < dxSrc; x++)
                                {
                                    *pbDst++ = *pbSrc++;
                        }

                        FillMemory (pbDst, postbytes, (BYTE)dwBlackEntry);
                        pbSrc += WidthBytesSrc;
                        pbDst += extra;
                    }

                    // do blank lines at end of destination
                    for (y = 0; y < postlines; y++)
                        {
                        FillMemory (pbDst, bytes, (BYTE)dwBlackEntry);
                        pbDst += WidthBytesDst;
                    }
                }
        }

        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: end", _fx_));
        return Hr;
}

/****************************************************************************
 *  @doc INTERNAL CCONVERTMETHOD
 *
 *  @mfunc HRESULT | CTAPIBasePin | ScaleDIB4 | This method scales/flips
 *    a bitmap. For now, RGB4 only.
 *
 *  @parm PBITMAPINFOHEADER | pbiSrc | Pointer to the input bitmap format.
 *
 *  @parm PBYTE | pbySrc | Pointer to the input bitmap.
 *
 *  @parm PBITMAPINFOHEADER | pbiSrc | Pointer to the output bitmap format.
 *
 *  @parm PBYTE | pbyDst | Pointer to the output bitmap.
 *
 *  @rdesc This method returns an HRESULT value that depends on the
 *    implementation of the interface. HRESULT can include one of the
 *    following standard constants, or other values not listed:
 *
 *  @flag E_FAIL | Failure
 *  @flag E_POINTER | Null pointer argument
 *  @flag E_INVALIDARG | Invalid argument
 *  @flag NOERROR | No error
 *
 *  @comm Parameter validation is done in ScaleDIB.
 ***************************************************************************/
HRESULT ScaleDIB4(PBITMAPINFOHEADER pbiSrc, PBYTE pbySrc, PBITMAPINFOHEADER pbiDst, PBYTE pbyDst, PRECT prcRect, BOOL fFlipHorizontal, BOOL fFlipVertical, BOOL fNoImageStretch, DWORD dwBlackEntry)
{
        HRESULT         Hr = NOERROR;
        PBYTE           pbSrc;
        PBYTE           pbDst;
    DWORD               *pal;
        COLORREF        rgb;
        int                     dxSrc, dySrc;
        int                     dxDst, dyDst;
        int                     x0, y0, sdx, sdy;
        long            WidthBytesSrc;
        long            WidthBytesDst;
        long            lOffset;
        BYTE            b0, b1, b2, b3;
        PBYTE           pb;
        int                     x, y;
        UINT            sx, sy;
        int                     xmodfx1, ymodfx1;
    long                extra;
    long                prelines, postlines, prebytes, postbytes, bytes;

        FX_ENTRY("ScaleDIB4")

        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: begin", _fx_));

        dxDst = (int)pbiDst->biWidth;
        dyDst = (int)pbiDst->biHeight;

        WidthBytesDst = DIBWIDTHBYTES(*pbiDst);
        WidthBytesSrc = DIBWIDTHBYTES(*pbiSrc);

        pbiDst->biSizeImage = WidthBytesDst * dyDst;

    pal = (DWORD *)(pbiSrc+1);

        if (!fNoImageStretch)
        {
                dxSrc = (int)prcRect->right - prcRect->left;
                dySrc = (int)prcRect->bottom - prcRect->top;

                pbSrc = (BYTE *)pbySrc + prcRect->left * pbiSrc->biBitCount / 8 + prcRect->top * WidthBytesSrc;

                if (fFlipHorizontal)
                {
                        if (fFlipVertical)
                        {
                                lOffset = dxDst - WidthBytesDst ;
                                pbDst = (BYTE *)pbyDst + (dyDst-1) * WidthBytesDst + dxDst - 1;
                        }
                        else
                        {
                                lOffset = WidthBytesDst + dxDst;
                                pbDst = (BYTE *)pbyDst + dxDst - 1;
                        }
                }
                else
                {
                        if (fFlipVertical)
                        {
                                lOffset = -WidthBytesDst - dxDst;
                                pbDst = (BYTE *)pbyDst + (dyDst-1) * WidthBytesDst;
                        }
                        else
                        {
                                lOffset = WidthBytesDst - dxDst;
                                pbDst = (BYTE *)pbyDst;
                        }
                }

                // TESTED (both zoom in and out)

            if (dxSrc == dxDst*2 && dySrc == dyDst*2)
            {
                sdx = FX1*2;
                sdy = FX1*2;
                y0  = FX1/2;
                x0  = FX1/2;
            }
            else
            {
                sdx = (dxSrc-1) * FX1 / (dxDst-1);
                sdy = (dySrc-1) * FX1 / (dyDst-1);
                y0  = 0;
                x0  = 0;
            }

                if (fFlipHorizontal)
                {
                    for (sy=y0,y=0; y<dyDst; y++,sy+=sdy)
                    {
                        pb = pbSrc + WidthBytesSrc * (sy/FX1);
                        for (sx=x0, x=0; x<dxDst; x++, sx+=sdx)
                        {
                            b0 = Pel4(pb, sx/FX1);
                            b1 = Pel4(pb, sx/FX1+1);
                            b2 = Pel4(pb+WidthBytesSrc, sx/FX1);
                            b3 = Pel4(pb+WidthBytesSrc, sx/FX1+1);

                                        xmodfx1 = sx%FX1;
                                        ymodfx1 = sy%FX1;

                                    if ((b0==b1 && b1==b2 && b2==b3) || (xmodfx1==0 && ymodfx1==0))
                                        rgb = RGBX(pal[b0]);
                                    else
                                        rgb = MixRGB(pal[b0], pal[b1], pal[b2], pal[b3], xmodfx1, ymodfx1);

                                        *pbDst-- = (BYTE)(g_rmap[GetRValue(rgb)] + g_gmap[GetGValue(rgb)] + g_bmap[GetBValue(rgb)] + 10);
                        }
                        pbDst += lOffset;
                    }
                }
                else
                {
                    for (sy=y0,y=0; y<dyDst; y++,sy+=sdy)
                    {
                        pb = pbSrc + WidthBytesSrc * (sy/FX1);
                        for (sx=x0, x=0; x<dxDst; x++, sx+=sdx)
                        {
                            b0 = Pel4(pb, sx/FX1);
                            b1 = Pel4(pb, sx/FX1+1);
                            b2 = Pel4(pb+WidthBytesSrc, sx/FX1);
                            b3 = Pel4(pb+WidthBytesSrc, sx/FX1+1);

                                        xmodfx1 = sx%FX1;
                                        ymodfx1 = sy%FX1;

                                    if ((b0==b1 && b1==b2 && b2==b3) || (xmodfx1==0 && ymodfx1==0))
                                        rgb = RGBX(pal[b0]);
                                    else
                                        rgb = MixRGB(pal[b0], pal[b1], pal[b2], pal[b3], xmodfx1, ymodfx1);

                                        *pbDst++ = (BYTE)(g_rmap[GetRValue(rgb)] + g_gmap[GetGValue(rgb)] + g_bmap[GetBValue(rgb)] + 10);
                        }
                        pbDst += lOffset;
                    }
                }
        }
        else
        {
                dxSrc = (int)pbiSrc->biWidth;
                dySrc = (int)pbiSrc->biHeight;

                pbSrc = (BYTE *)pbySrc;
                pbDst = (BYTE *)pbyDst;

        if ((dxSrc >= dxDst) && (dySrc >= dyDst))
                {
                        // TESTED (zoom out)

                    // starts by skipping half of the height change
                    pbSrc = pbSrc + (dySrc - dyDst) / 2 * WidthBytesSrc;

                    // extra = # of source bytes per scan line that are to be cropped
                    extra = (dxSrc - dxDst) / 2;

                    // advance pIn by half of extra to crop left most pixels
                    pbSrc += extra / 2 ;

                    // adjust ipitch so we can add it at the end of each scan to get to start of next scan
                    WidthBytesSrc = WidthBytesSrc - dxSrc / 2 + extra;
                    WidthBytesDst -= dxDst;      // bytes at end of each row

                    for (y = 0; y < dyDst; y++) {
                        for (x = 0; x < dxDst / 2; x++) {
                                    *pbDst++ = (*pbSrc & 0xF0) >> 4;
                                    *pbDst++ = *pbSrc & 0x0F;
                                        pbSrc++;
                        }
                        pbSrc += WidthBytesSrc;          // get to start of next row
                        pbDst += WidthBytesDst;         // get to start of next row
                    }
                }
                else
                {
                        // TESTED (zoom in)

                    prelines = (dyDst - dySrc) / 2;
                    postlines = dyDst - dySrc - prelines;

                    prebytes = (dxDst - dxSrc) / 2;
                    postbytes = dxDst - dxSrc - prebytes;

                    WidthBytesSrc -= dxSrc / 2;        // bytes at end of each src row
                    bytes = dxDst;
                    extra = WidthBytesDst - bytes + postbytes;                    // bytes at end of each dst row

                    // do blank lines at front of destination
                    for (y = 0; y < prelines; y++)
                        {
                        FillMemory (pbDst, bytes, (BYTE)dwBlackEntry);
                        pbDst += WidthBytesDst;
                    }

                    // copy source lines with blank space at front and rear
                    for (y = 0; y < dySrc; y++)
                        {
                        FillMemory (pbDst, prebytes, (BYTE)dwBlackEntry);
                        pbDst += prebytes;

                        for (x = 0; x < dxSrc / 2; x++)
                                {
                                    *pbDst++ = (*pbSrc & 0xF0) >> 4;
                                    *pbDst++ = *pbSrc & 0x0F;
                                        pbSrc++;
                        }

                        FillMemory (pbDst, postbytes, (BYTE)dwBlackEntry);
                        pbSrc += WidthBytesSrc;
                        pbDst += extra;
                    }

                    // do blank lines at end of destination
                    for (y = 0; y < postlines; y++)
                        {
                        FillMemory (pbDst, bytes, (BYTE)dwBlackEntry);
                        pbDst += WidthBytesDst;
                    }
                }
        }

        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: end", _fx_));
        return Hr;
}

void ScalePlane(IN PBYTE pbySrc, IN PBYTE pbyDst, IN int WidthBytesSrc, IN int dxDst, IN int dyDst, IN long WidthBytesDst, IN LPRECT prcRect, IN BOOL fFlipHorizontal, IN BOOL fFlipVertical)
{
        PBYTE           pbSrc;
        PBYTE           pbDst;
        int                     dxSrc, dySrc;
        int                     x0, y0, sdx, sdy;
        long            lOffset;
        BYTE            by0, by1, by2, by3;
        int                     xmodfx1, ymodfx1;
        int                     FX1_xmodfx1, FX1_ymodfx1;
        PBYTE           pb;
        int                     x, y;
        UINT            sx, sy;

        FX_ENTRY("ScalePlane")

        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: begin", _fx_));

        dxSrc = (int)prcRect->right - prcRect->left;
        dySrc = (int)prcRect->bottom - prcRect->top;

        pbSrc = (BYTE *)pbySrc + prcRect->left + prcRect->top * WidthBytesSrc;

        if (fFlipHorizontal)
        {
                if (fFlipVertical)
                {
                        lOffset = dxDst - WidthBytesDst;
                        pbDst = (BYTE *)pbyDst + (dyDst-1) * WidthBytesDst + dxDst - 1;
                }
                else
                {
                        lOffset = WidthBytesDst + dxDst;
                        pbDst = (BYTE *)pbyDst + dxDst - 1;
                }
        }
        else
        {
                if (fFlipVertical)
                {
                        lOffset = -WidthBytesDst - dxDst;
                        pbDst = (BYTE *)pbyDst + (dyDst-1) * WidthBytesDst;
                }
                else
                {
                        lOffset = WidthBytesDst - dxDst;
                        pbDst = (BYTE *)pbyDst;
                }
        }

        if (dxSrc == dxDst*2 && dySrc == dyDst*2)
        {
                sdx = FX1*2;
                sdy = FX1*2;
                y0  = FX1/2;
                x0  = FX1/2;
        }
        else
        {
                sdx = (dxSrc-1) * FX1 / (dxDst-1);
                sdy = (dySrc-1) * FX1 / (dyDst-1);
                y0  = 0;
                x0  = 0;
        }

        if (fFlipHorizontal)
        {
                sy=y0,y=0;
            pb = pbSrc + WidthBytesSrc * (sy/FX1);
                sx=x0,x=0;
                *pbDst-- = *(pb + sx/FX1);
                x++, sx+=sdx;
            for (; x<dxDst; x++, sx+=sdx)
            {
                        by0 = *(pb + sx/FX1);
                        by1 = *(pb + sx/FX1 + 1);
                        xmodfx1 = sx%FX1;
                        *pbDst-- = (BYTE)(((FX1-xmodfx1) * (ULONG)by0 + xmodfx1 * (ULONG)by1)/FX1);
            }
                pbDst += lOffset;
                y++,sy+=sdy;
                for (; y<dyDst; y++,sy+=sdy)
            {
                pb = pbSrc + WidthBytesSrc * (sy/FX1);
                        sx=x0,x=0;
                        by0 = *(pb + sx/FX1);
                        by2 = *(pb + WidthBytesSrc + sx/FX1);
                        ymodfx1 = sy%FX1;
                    *pbDst-- = (BYTE)(((FX1-ymodfx1) * (ULONG)by0 + ymodfx1 * (ULONG)by2)/FX1);
                        x++, sx+=sdx;
                for (; x<dxDst; x++, sx+=sdx)
                {
                                by0 = *(pb + sx/FX1);
                                by1 = *(pb + sx/FX1 + 1);
                                by2 = *(pb + WidthBytesSrc + sx/FX1);
                                by3 = *(pb + WidthBytesSrc + sx/FX1 + 1);
                                xmodfx1 = sx%FX1;
                                ymodfx1 = sy%FX1;
                                FX1_xmodfx1 = FX1-xmodfx1;
                                FX1_ymodfx1 = FX1-ymodfx1;
                                *pbDst-- =(BYTE)(((ULONG)by0 * FX1_xmodfx1 / FX1 * FX1_ymodfx1 + (ULONG)by1 * xmodfx1 / FX1 * FX1_ymodfx1 +
                            (ULONG)by2 * FX1_xmodfx1 / FX1 * ymodfx1       + (ULONG)by3 * xmodfx1 / FX1 * ymodfx1       )/FX1);
                }
                        pbDst += lOffset;
                }
        }
        else
        {
                sy=y0,y=0;
            pb = pbSrc + WidthBytesSrc * (sy/FX1);
                sx=x0,x=0;
                *pbDst++ = *(pb + sx/FX1);
                x++, sx+=sdx;
            for (; x<dxDst; x++, sx+=sdx)
            {
                        by0 = *(pb + sx/FX1);
                        by1 = *(pb + sx/FX1 + 1);
                        xmodfx1 = sx%FX1;
                        *pbDst++ = (BYTE)(((FX1-xmodfx1) * (ULONG)by0 + xmodfx1 * (ULONG)by1)/FX1);
            }
                pbDst += lOffset;
                y++,sy+=sdy;
                for (; y<dyDst; y++,sy+=sdy)
            {
                pb = pbSrc + WidthBytesSrc * (sy/FX1);
                        sx=x0,x=0;
                        by0 = *(pb + sx/FX1);
                        by2 = *(pb + WidthBytesSrc + sx/FX1);
                        ymodfx1 = sy%FX1;
                    *pbDst++ = (BYTE)(((FX1-ymodfx1) * (ULONG)by0 + ymodfx1 * (ULONG)by2)/FX1);
                        x++, sx+=sdx;
                for (; x<dxDst; x++, sx+=sdx)
                {
                                by0 = *(pb + sx/FX1);
                                by1 = *(pb + sx/FX1 + 1);
                                by2 = *(pb + WidthBytesSrc + sx/FX1);
                                by3 = *(pb + WidthBytesSrc + sx/FX1 + 1);
                                xmodfx1 = sx%FX1;
                                ymodfx1 = sy%FX1;
                                FX1_xmodfx1 = FX1-xmodfx1;
                                FX1_ymodfx1 = FX1-ymodfx1;
                                *pbDst++ =(BYTE)(((ULONG)by0 * FX1_xmodfx1 / FX1 * FX1_ymodfx1 + (ULONG)by1 * xmodfx1 / FX1 * FX1_ymodfx1 +
                            (ULONG)by2 * FX1_xmodfx1 / FX1 * ymodfx1       + (ULONG)by3 * xmodfx1 / FX1 * ymodfx1       )/FX1);
                }
                        pbDst += lOffset;
                }
        }

        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: end", _fx_));
}
void ScalePackedPlane(IN PBYTE pbySrc, IN PBYTE pbyDst, IN int dxDst, IN int dyDst, IN long WidthBytesSrc, IN long WidthBytesDst, IN LPRECT prcRect, IN BOOL fFlipHorizontal, IN BOOL fFlipVertical, IN DWORD dwDelta)
{
        PBYTE           pbSrc;
        PBYTE           pbDst;
        int                     dxSrc, dySrc;
        int                     x0, y0, sdx, sdy;
        long            lOffset;
        BYTE            by0, by1, by2, by3;
        int                     xmodfx1, ymodfx1;
        int                     FX1_xmodfx1, FX1_ymodfx1;
        PBYTE           pb;
        int                     x, y;
        UINT            sx, sy;
        long            lDestDelta;    // destination delta; could be negative if H Flipping is requested


        FX_ENTRY("ScalePackedPlane")

        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: begin", _fx_));

        dxSrc = (int)prcRect->right - prcRect->left;
        dySrc = (int)prcRect->bottom - prcRect->top;

        pbSrc = (BYTE *)pbySrc + prcRect->left * dwDelta + prcRect->top * WidthBytesSrc * dwDelta;

        if (fFlipHorizontal)
        {
                lDestDelta = -(long)dwDelta;
                if (fFlipVertical)
                {
                        lOffset = (dxDst - WidthBytesDst) * dwDelta;
                        pbDst = (BYTE *)pbyDst + (dyDst-1) * WidthBytesDst * dwDelta + (dxDst - 1) * dwDelta;
                }
                else
                {
                        lOffset = (WidthBytesDst + dxDst) * dwDelta;
                        pbDst = (BYTE *)pbyDst + (dxDst - 1) * dwDelta;
                }
        }
        else
        {
                lDestDelta = (long)dwDelta ;
                if (fFlipVertical)
                {
                        lOffset = (-WidthBytesDst - dxDst) * dwDelta;
                        pbDst = (BYTE *)pbyDst + (dyDst-1) * WidthBytesDst * dwDelta;
                }
                else
                {
                        lOffset = (WidthBytesDst - dxDst) * dwDelta;
                        pbDst = (BYTE *)pbyDst;
                }
        }

        if (dxSrc == dxDst*2 && dySrc == dyDst*2)
        {
                sdx = FX1*2;
                sdy = FX1*2;
                y0  = FX1/2;
                x0  = FX1/2;
        }
        else
        {
                sdx = (dxSrc-1) * FX1 / (dxDst-1);
                sdy = (dySrc-1) * FX1 / (dyDst-1);
                y0  = 0;
                x0  = 0;
        }

        // start scaling and/or flipping ...
        D(1) dprintf("WidthBytesSrc, WidthBytesDst %d,%d\n",WidthBytesSrc, WidthBytesDst);
        D(1) dprintf("line step: %d coln step: %d\n", sdy, sdx);

        for ( sy=y0,y=0; sy<FX1 && y<dyDst; y++,sy+=sdy )       // double test condition but for a limited number of lines
        {

            D(1) dprintf("    line : %d\n", sy/FX1);
            pb = pbSrc + WidthBytesSrc * (sy/FX1) * dwDelta;

            for ( sx=x0,x=0; sx<FX1 && x<dxDst; x++, sx+=sdx )       // double test condition but for a limited number of pixels
            {
                D(1) dprintf("    coln : %d\n", sx/FX1);
                D(1) dprintf(" .......    by* %5d\n", sx/FX1);
                *pbDst = *(pb + sx/FX1 * dwDelta);
                pbDst += lDestDelta;
            }
            for (          ;           x<dxDst; x++, sx+=sdx )
            {
                D(1) dprintf("    coln : %d\n", sx/FX1);
                D(1) dprintf("by1 %5d   by0 %5d\n", (sx/FX1 - 1), sx/FX1);
                ASSERT(pb + (sx/FX1 - 1) * dwDelta >= pbSrc);
                by0 = *(pb + sx/FX1 * dwDelta);
                by1 = *(pb + (sx/FX1 - 1) * dwDelta); //1
                xmodfx1 = sx%FX1;
                *pbDst = (BYTE)((xmodfx1 * (ULONG)by0 + (FX1-xmodfx1) * (ULONG)by1)/FX1);
                pbDst += lDestDelta;
            }
            pbDst += lOffset;
        }


        for (; y<dyDst; y++,sy+=sdy)
        {
                D(1) dprintf("sy : %5d line ===> %5d [ %d ]\n", sy, sy/FX1, WidthBytesSrc);
                pb = pbSrc + WidthBytesSrc * (sy/FX1) * dwDelta;
                for ( sx=x0,x=0; sx<FX1 && x<dxDst; x++, sx+=sdx )      // double test condition -- limited number of pixels
                {
                    D(1) dprintf("by2 %5d\n", (sx/FX1 - 1));
                    D(1) dprintf("by0 %5d\n", sx/FX1);
                    D(8) ASSERT(pb + (-WidthBytesSrc + sx/FX1) * dwDelta >= pbSrc);
                    by0 = *(pb + sx/FX1 * dwDelta);
                    by2 = *(pb + (-WidthBytesSrc + sx/FX1) * dwDelta); //+WidthBytesSrc
                    ymodfx1 = sy%FX1;
                    *pbDst = (BYTE)((ymodfx1 * (ULONG)by0 + (FX1-ymodfx1) * (ULONG)by2)/FX1);
                    pbDst += lDestDelta;
                }
                for (               ; x<dxDst; x++, sx+=sdx)
                {
                        D(1) dprintf("sx : %5d coln ---| %5d [ %d ]\n", sx, sx/FX1, WidthBytesSrc);
                        D(1) dprintf("by3 %5d   by2 %5d\n", (-WidthBytesSrc + sx/FX1-1),(-WidthBytesSrc + sx/FX1));
                        D(1) dprintf("by1 %5d   by0 %5d\n", (sx/FX1 - 1), sx/FX1);
                        by0 = *(pb + sx/FX1 * dwDelta);
                        D(8) ASSERT(pb + (sx/FX1 - 1) * dwDelta >= pbSrc);
                        by1 =     *(pb + (sx/FX1 - 1) * dwDelta);                   //1
                        D(8) ASSERT(pb + (-WidthBytesSrc + sx/FX1) * dwDelta >= pbSrc);
                        by2 =     *(pb + (-WidthBytesSrc + sx/FX1) * dwDelta);      //+WidthBytesSrc
                        D(8) ASSERT(pb + (-WidthBytesSrc + sx/FX1 - 1) * dwDelta >= pbSrc);
                        by3 =     *(pb + (-WidthBytesSrc + sx/FX1 - 1) * dwDelta);  //+WidthBytesSrc    +1
                        xmodfx1 = sx%FX1;
                        ymodfx1 = sy%FX1;
                        FX1_xmodfx1 = FX1-xmodfx1;
                        FX1_ymodfx1 = FX1-ymodfx1;
                        *pbDst =(BYTE)(((ULONG)by0 * xmodfx1     / FX1 * ymodfx1     +
                                        (ULONG)by1 * FX1_xmodfx1 / FX1 * ymodfx1     +
                                        (ULONG)by2 * xmodfx1     / FX1 * FX1_ymodfx1 +
                                        (ULONG)by3 * FX1_xmodfx1 / FX1 * FX1_ymodfx1     )/FX1);
                        //*pbDst =(BYTE)(((ULONG)by0 * FX1_xmodfx1 / FX1 * FX1_ymodfx1 +
                        //                (ULONG)by1 * xmodfx1     / FX1 * FX1_ymodfx1 +
                        //                (ULONG)by2 * FX1_xmodfx1 / FX1 * ymodfx1     +
                        //                (ULONG)by3 * xmodfx1     / FX1 * ymodfx1         )/FX1);
                        D(1) dprintf("    xmodfx1 ,     ymodfx1 = %d, %d\n",     xmodfx1 ,     ymodfx1);
                        D(1) dprintf("FX1_xmodfx1 , FX1_ymodfx1 = %d, %d\n", FX1_xmodfx1 , FX1_ymodfx1);
                        pbDst += lDestDelta;
                }
                pbDst += lOffset;
                D(2) DebugBreak();
        }
        D(4) DebugBreak();

        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: end", _fx_));
}

/****************************************************************************
 *  @doc INTERNAL CCONVERTMETHOD
 *
 *  @mfunc HRESULT | CConverter | ScaleDIBYUVPlanar | This method scales/flips
 *    a YUV planar bitmap.
 *
 *  @parm PBITMAPINFOHEADER | pbiSrc | Pointer to the input bitmap format.
 *
 *  @parm PBYTE | pbySrc | Pointer to the input bitmap.
 *
 *  @parm PBITMAPINFOHEADER | pbiSrc | Pointer to the output bitmap format.
 *
 *  @parm PBYTE | pbyDst | Pointer to the output bitmap.
 *
 *  @parm DWORD | dwUVDownSampling | Specifies the U and V plane downsampling.
 *
 *  @rdesc This method returns an HRESULT value that depends on the
 *    implementation of the interface. HRESULT can include one of the
 *    following standard constants, or other values not listed:
 *
 *  @flag E_FAIL | Failure
 *  @flag E_POINTER | Null pointer argument
 *  @flag E_INVALIDARG | Invalid argument
 *  @flag NOERROR | No error
 *
 *  @comm Parameter validation is done in ScaleDIB.
 ***************************************************************************/
HRESULT ScaleDIBYUVPlanar(PBITMAPINFOHEADER pbiSrc, PBYTE pbySrc, PBITMAPINFOHEADER pbiDst, PBYTE pbyDst, DWORD dwUVDownSampling, PRECT prcRect, BOOL fFlipHorizontal, BOOL fFlipVertical, BOOL fNoImageStretch)
{
        HRESULT         Hr = NOERROR;
        PBYTE           pbSrc;
        PBYTE           pbDst;
        int                     dxSrc, dySrc;
        int                     dxDst, dyDst;
        int                     x0, y0, sdx, sdy;
        int                     y;
    long                extra, pitch, prelinebytes, postlinebytes;
    long                prelines, postlines, prebytes, postbytes, bytes;

        FX_ENTRY("ScaleDIBYUVPlanar")

        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: begin", _fx_));

        dxSrc = (int)pbiSrc->biWidth;
        dySrc = (int)pbiSrc->biHeight;

        dxDst = (int)pbiDst->biWidth;
        dyDst = (int)pbiDst->biHeight;

        pbiDst->biSizeImage = dxDst * dyDst + dxDst / dwUVDownSampling * dyDst / dwUVDownSampling + dxDst / dwUVDownSampling * dyDst / dwUVDownSampling;

        pbSrc = (BYTE *)pbySrc;
        pbDst = (BYTE *)pbyDst;

        sdx = (dxSrc-1) * FX1 / (dxDst-1);
        sdy = (dySrc-1) * FX1 / (dyDst-1);
        y0  = 0;
        x0  = 0;

        if (!fNoImageStretch)
        {
                RECT rcRect;

                // TESTED (zoom out & zoom in)

                // Do Y plane first
                rcRect.left = prcRect->left;
                rcRect.top = prcRect->top;
                rcRect.right = prcRect->right;
                rcRect.bottom = prcRect->bottom;
                ScalePlane(pbSrc, pbDst, dxSrc, dxDst, dyDst, dxDst, &rcRect, fFlipHorizontal, fFlipVertical);

                // Do U plane next
                rcRect.left = prcRect->left / dwUVDownSampling;
                rcRect.top = prcRect->top / dwUVDownSampling;
                rcRect.right = prcRect->right / dwUVDownSampling;
                rcRect.bottom = prcRect->bottom / dwUVDownSampling;
                ScalePlane(pbSrc + dxSrc * dySrc, pbDst + dxDst * dyDst, dxSrc / dwUVDownSampling, dxDst / dwUVDownSampling, dyDst / dwUVDownSampling, dxDst / dwUVDownSampling, &rcRect, fFlipHorizontal, fFlipVertical);

                // Do V plane last
                ScalePlane(pbSrc + dxSrc * dySrc + dxSrc * dySrc / (dwUVDownSampling * dwUVDownSampling), pbDst + dxDst * dyDst + dxDst * dyDst / (dwUVDownSampling * dwUVDownSampling), dxSrc / dwUVDownSampling, dxDst / dwUVDownSampling, dyDst / dwUVDownSampling, dxDst / dwUVDownSampling, &rcRect, fFlipHorizontal, fFlipVertical);
        }
        else
        {
        if ((dxSrc >= dxDst) && (dySrc >= dyDst))
                {
                        // TESTED (zoom out)

                        prelines = (dySrc - dyDst) / 2;
                        pbSrc = pbySrc + prelines * dxSrc;

                        // extra = # of source bytes per scan line that are to be cropped
                        extra = dxSrc - dxDst;
                        prebytes = extra / 2;

                        // advance pIn by half of extra to crop left most pixels
                        pbSrc += prebytes;

                        // Do the Y component first
                        pitch = extra + dxDst;
                    for (y = 0; y < dyDst; y++)
                        {
                                CopyMemory (pbDst, pbSrc, dxDst);
                        pbSrc += pitch;          // get to start of next row
                        pbDst += dxDst;         // get to start of next row
                    }

                        // Do the first color component next
                        prelines /= dwUVDownSampling;
                        prebytes /= dwUVDownSampling;
                        pbSrc = pbySrc + (dxSrc * dySrc) +    // skip Y section
                                prelines * dxSrc / dwUVDownSampling +  // skip half of the crop lines
                                prebytes;                                           // skip half of the crop pixels

                        pitch /= dwUVDownSampling;
                        bytes = dxDst / dwUVDownSampling;
                        for (y=0; y < dyDst / (long)dwUVDownSampling; y++)
                        {
                                CopyMemory (pbDst, pbSrc, bytes);
                                pbSrc += pitch;
                                pbDst += bytes;
                        }

                        // Do the second color component next
                        pbSrc = pbySrc + (dxSrc * dySrc) +    // skip Y section
                                (dxSrc * dySrc) / (dwUVDownSampling * dwUVDownSampling) +     // skip first color component section
                                prelines * dxSrc / dwUVDownSampling +                  // skip half of the crop lines
                                prebytes;                                           // skip half of the crop pixels
                        for (y=0; y < dyDst / (long)dwUVDownSampling; y++)
                        {
                                CopyMemory (pbDst, pbSrc, bytes);
                                pbSrc += pitch;
                                pbDst += bytes;
                        }
                }
                else
                {
                        // TESTED (zoom in)

                        // Do the Y component first
                    prelines = (dyDst - dySrc) / 2;
                    postlines = dyDst - dySrc - prelines;

                    prebytes = (dxDst - dxSrc) / 2;
                    postbytes = (dxDst - dxSrc - prebytes);

                    bytes = prelines * dxDst + prebytes;
                    FillMemory (pbDst, bytes, 0x10);
                    pbDst += bytes;

                        bytes = dxSrc;
                    prebytes += postbytes;
                        for (y=0; y < dySrc; y++)
                        {
                        CopyMemory (pbDst, pbSrc, bytes);
                        pbSrc += bytes;
                        pbDst += bytes;
                        FillMemory (pbDst, prebytes, 0x10);
                        pbDst += prebytes;
                        }

                        // already filled the prebytes of the first postline in loop above
                        prebytes -= postbytes;
                        bytes = postlines * dxDst - prebytes;
                        FillMemory (pbDst, bytes, (BYTE)0x10);
                        pbDst += bytes;

                        // Do the first color component next
                    prelines /= dwUVDownSampling;
                    postlines = dyDst / dwUVDownSampling - dySrc / dwUVDownSampling - prelines;

                    prebytes = prebytes / dwUVDownSampling;
                    postbytes = dxDst / dwUVDownSampling - dxSrc / dwUVDownSampling - prebytes;

                    prelinebytes = prelines * dxDst / dwUVDownSampling + prebytes;
                    FillMemory (pbDst, prelinebytes, 0x80);
                    pbDst += prelinebytes;

                        bytes = dxSrc / dwUVDownSampling;
                    prebytes += postbytes;
                        for (y=0; y < dySrc / (long)dwUVDownSampling; y++)
                        {
                        CopyMemory (pbDst, pbSrc, bytes);
                        pbSrc += bytes;
                        pbDst += bytes;
                        FillMemory (pbDst, prebytes, 0x80);
                        pbDst += prebytes;
                        }

                        // already filled the prebytes of the first postline in loop above
                        postlinebytes = postlines * dxDst / dwUVDownSampling - (prebytes - postbytes);
                        FillMemory (pbDst, postlinebytes, 0x80);
                        pbDst += postlinebytes;

                        // Do the second color component next
                    FillMemory (pbDst, prelinebytes, 0x80);
                    pbDst += prelinebytes;
                        for (y=0; y < dySrc / (long)dwUVDownSampling; y++)
                        {
                        MoveMemory (pbDst, pbSrc, bytes);
                        pbSrc += bytes;
                        pbDst += bytes;
                        FillMemory (pbDst, prebytes, 0x80);
                        pbDst += prebytes;
                        }
                        FillMemory (pbDst, postlinebytes, 0x80);
                }
        }

        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: end", _fx_));
        return Hr;
}
/****************************************************************************
 *  @doc INTERNAL CCONVERTMETHOD
 *
 *  @mfunc HRESULT | CTAPIBasePin | ScaleDIBYUVPacked | This method scales/flips
 *    a YUV packed bitmap.
 *
 *  @parm PBITMAPINFOHEADER | pbiSrc | Pointer to the input bitmap format.
 *
 *  @parm PBYTE | pbySrc | Pointer to the input bitmap.
 *
 *  @parm PBITMAPINFOHEADER | pbiSrc | Pointer to the output bitmap format.
 *
 *  @parm PBYTE | pbyDst | Pointer to the output bitmap.
 *
 *  @rdesc This method returns an HRESULT value that depends on the
 *    implementation of the interface. HRESULT can include one of the
 *    following standard constants, or other values not listed:
 *
 *  @flag E_FAIL | Failure
 *  @flag E_POINTER | Null pointer argument
 *  @flag E_INVALIDARG | Invalid argument
 *  @flag NOERROR | No error
 *
 *  @comm Parameter validation is done in ScaleDIB.
 ***************************************************************************/
HRESULT ScaleDIBYUVPacked(PBITMAPINFOHEADER pbiSrc, PBYTE pbySrc, PBITMAPINFOHEADER pbiDst, PBYTE pbyDst, DWORD dwZeroingDWORD, PRECT prcRect, BOOL fFlipHorizontal, BOOL fFlipVertical, BOOL fNoImageStretch, int yuvstartpos[])
{
        HRESULT         Hr = NOERROR;
        PBYTE           pbSrc;
        PBYTE           pbDst;
        int                     dxSrc, dySrc;
        int                     dxDst, dyDst;
        long            WidthBytesSrc;
        long            WidthBytesDst;
        int                     x, y;
    long                extra;
    long                prelines, postlines, prebytes, postbytes;

        FX_ENTRY("ScaleDIBYUVPacked")

        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: begin", _fx_));

        dxSrc = (int)pbiSrc->biWidth;
        dySrc = (int)pbiSrc->biHeight;

        dxDst = (int)pbiDst->biWidth;
        dyDst = (int)pbiDst->biHeight;

        WidthBytesDst = DIBWIDTHBYTES(*pbiDst);
        WidthBytesSrc = dxSrc * 2;

        pbiDst->biSizeImage = WidthBytesDst * dyDst;

        pbSrc = (BYTE *)pbySrc;
        pbDst = (BYTE *)pbyDst;

        if (!fNoImageStretch)
        {
                // TESTED (zoom in & out + all combinations of flipped horizontal & flipped vertical)

                RECT rcRect;

                // Do Y plane first
                rcRect.left = prcRect->left;
                rcRect.top = prcRect->top;
                rcRect.right = prcRect->right;
                rcRect.bottom = prcRect->bottom;
                ScalePackedPlane(pbSrc + yuvstartpos[Y_POS], pbDst + yuvstartpos[Y_POS], dxDst, dyDst, dxSrc, dxDst, &rcRect, fFlipHorizontal, fFlipVertical, 2);

                // Do U plane next
                rcRect.left = prcRect->left / 2;
                rcRect.top = prcRect->top;
                rcRect.right = prcRect->right / 2;
                rcRect.bottom = prcRect->bottom;
                ScalePackedPlane(pbSrc + yuvstartpos[U_POS], pbDst + yuvstartpos[U_POS], dxDst / 2, dyDst, dxSrc / 2, dxDst / 2, &rcRect, fFlipHorizontal, fFlipVertical, 4);

                // Do V plane last
                ScalePackedPlane(pbSrc + yuvstartpos[V_POS], pbDst + yuvstartpos[V_POS], dxDst / 2, dyDst, dxSrc / 2, dxDst / 2, &rcRect, fFlipHorizontal, fFlipVertical, 4);
        }
        else
        {
        if ((dxSrc >= dxDst) && (dySrc >= dyDst))
                {

                        // TESTED (zoom out)

                    // starts by skipping half of the height change
                    pbSrc = pbSrc + (dySrc - dyDst) / 2 * dxSrc * 2;

                    // extra = # of source bytes per scan line that are to be cropped
                    extra = (dxSrc - dxDst) * 2;

                    // advance pIn by half of extra to crop left most pixels
                    pbSrc += extra / 2;

                    // adjust ipitch so we can add it at the end of each scan to get to start of next scan
                    WidthBytesSrc = dxSrc * 2;
                    WidthBytesDst = dxDst * 2;      // bytes at end of each row

                    for (y = 0; y < dyDst; y++) {
                                CopyMemory(pbDst, pbSrc, WidthBytesDst);
                        pbSrc += WidthBytesSrc;          // get to start of next row
                        pbDst += WidthBytesDst;         // get to start of next row
                    }
                }
                else
                {
                        // TESTED (zoom in)

                    prelines = (dyDst - dySrc) / 2;
                    postlines = dyDst - dySrc - prelines;

                    prebytes = (dxDst - dxSrc) / 2;
                    postbytes = (dxDst - dxSrc - prebytes) / 2;
                    prebytes /= 2;

                    WidthBytesSrc = dxSrc * 2;        // bytes at end of each src row
                    WidthBytesDst = dxDst / 2;                    // bytes at end of each dst row

                    // do blank lines at front of destination
                    for (y = 0; y < prelines; y++)
                        {
                            for (x = 0; x < WidthBytesDst; x++)
                                {
                                        *(DWORD *)pbDst = dwZeroingDWORD;
                                        pbDst += sizeof(DWORD);
                                }
                    }

                    // copy source lines with blank space at front and rear
                    for (y = 0; y < dySrc; y++)
                        {
                                for (x = 0; x < prebytes; x++)
                                {
                                        *(DWORD *)pbDst = dwZeroingDWORD;
                                        pbDst += sizeof(DWORD);
                                }

                        CopyMemory(pbDst, pbSrc, WidthBytesSrc);
                                pbDst += WidthBytesSrc;
                                pbSrc += WidthBytesSrc;

                                for (x = 0; x < postbytes; x++)
                                {
                                        *(DWORD *)pbDst = dwZeroingDWORD;
                                        pbDst += sizeof(DWORD);
                                }
                    }

                    // do blank lines at end of destination
                    for (y = 0; y < postlines; y++)
                        {
                                for (x = 0; x < WidthBytesDst; x++)
                                {
                                        *(DWORD *)pbDst = dwZeroingDWORD;
                                        pbDst += sizeof(DWORD);
                                }
                    }
                }
        }

        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: end", _fx_));
        return Hr;
}

HRESULT ComputeRectangle(PBITMAPINFOHEADER pbiSrc, PBITMAPINFOHEADER pbiDst, LONG lZoom, LONG lPan, LONG lTilt, PRECT prcRect, BOOL fFlipHorizontal, BOOL fFlipVertical)
{
        HRESULT Hr = NOERROR;
        LONG    lWidth = 0;
        LONG    lHeight = 0;
        LONG    lLeftPos = 0;
        LONG    lTopPos = 0;
        LONG    lCCPan = 0;
        LONG    lCCTilt = 0;

        FX_ENTRY("ComputeRectangle")

        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: begin", _fx_));

        // Validate input parameters
        ASSERT(pbiSrc);
        ASSERT(pbiDst);
        if (!pbiSrc || !pbiDst)
        {
                DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: Null pointer argument", _fx_));
                Hr = E_POINTER;
                goto MyExit;
        }
        ASSERT(pbiSrc->biCompression == pbiDst->biCompression);
        ASSERT(pbiSrc->biCompression == BI_RGB || pbiSrc->biCompression == VIDEO_FORMAT_YVU9 || pbiSrc->biCompression == VIDEO_FORMAT_YUY2 || pbiSrc->biCompression == VIDEO_FORMAT_UYVY || pbiSrc->biCompression == VIDEO_FORMAT_I420 || pbiSrc->biCompression == VIDEO_FORMAT_IYUV);

        // Compute the source rectangle coordinates - we only care about pan, tilt and zoom
        lWidth = pbiSrc->biWidth;
        lHeight = pbiSrc->biHeight;

        D(1) dprintf("%s : fFlipHorizontal = %d , fFlipVertical = %d\n", _fx_, fFlipHorizontal, fFlipVertical);

        // Compute the size of the rectangle
        if ((lZoom > 10) && (lZoom <= 600))
        {
                lWidth = (8192 + (600 - lZoom) * 42) * lWidth / 32768;
                lHeight = (8192 + (600 - lZoom) * 42) * lHeight / 32768;
                if (lWidth > pbiSrc->biWidth)
                        lWidth = pbiSrc->biWidth;
                if (lHeight > pbiSrc->biHeight)
                        lHeight = pbiSrc->biHeight;
        }
        // Compute x-location of the rectangle
        if ((lPan >= -180)  && (lPan <= 180))
        {
                lCCPan = (LONG)(fFlipHorizontal ? -lPan : lPan);
                lLeftPos = (lCCPan + 180) * (pbiSrc->biWidth - lWidth) / 360;
                if (lLeftPos + lWidth > pbiSrc->biWidth)
                        if (lLeftPos)
                                lLeftPos = lLeftPos - (pbiSrc->biWidth - lWidth - lLeftPos);
        }
        // Compute y-location of the rectangle
        if ((lTilt >= -180)  && (lTilt <= 180))
        {
                lCCTilt = (LONG)(fFlipVertical ? -lTilt : lTilt);
                lTopPos = (lCCTilt + 180) * (pbiSrc->biHeight - lHeight) / 360;
                if (lTopPos + lHeight > pbiSrc->biHeight)
                        if (lTopPos)
                                lTopPos = lTopPos - (pbiSrc->biHeight - lHeight - lTopPos);
        }

        // Do a last check
        if ((lLeftPos + lWidth > pbiSrc->biWidth) || (lTopPos + lHeight > pbiSrc->biHeight))
        {
                DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: invalid input parameter", _fx_));
                Hr = E_INVALIDARG;
                goto MyExit;
        }

        // Set up source rectangle
        prcRect->left = lLeftPos;
        prcRect->top = lTopPos;
        prcRect->right = lLeftPos + lWidth;
        prcRect->bottom = lTopPos + lHeight;

        D(1) dprintf("prcRect @ %p: l,t,r,b = %d , %d , %d , %d\n",prcRect, prcRect->left, prcRect->top, prcRect->right, prcRect->bottom);

MyExit:
        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: end", _fx_));
        return Hr;
}

#ifndef DEBUG
#pragma optimize( "", off )
#endif

/****************************************************************************
 *  @doc INTERNAL CCONVERTMETHOD
 *
 *  @mfunc void | CICMConverter | CICMConverter | This method is the constructor
 *    for the <c CICMConverter> object.
 *
 *  @rdesc Nada.
 ***************************************************************************/
CICMConverter::CICMConverter(IN TCHAR *pObjectName, IN CTAPIBasePin *pBasePin, IN PBITMAPINFOHEADER pbiIn, IN PBITMAPINFOHEADER pbiOut, IN HRESULT *pHr) : CConverter(pObjectName, pBasePin, pbiIn, pbiOut, pHr)
{
        FX_ENTRY("CICMConverter::CICMConverter")

        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: begin", _fx_));

        if (!pHr || FAILED(*pHr))
        {
                DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: Base class error or invalid input parameter", _fx_));
                goto MyExit;
        }

        // Default inits
        m_hIC = NULL;

MyExit:
        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: end", _fx_));
}

/****************************************************************************
 *  @doc INTERNAL CCONVERTMETHOD
 *
 *  @mfunc void | CICMConverter | ~CICMConverter | This method is the destructor
 *    for the <c CICMConverter> object.
 *
 *  @rdesc Nada.
 ***************************************************************************/
CICMConverter::~CICMConverter()
{
        FX_ENTRY("CICMConverter::~CICMConverter")

        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: begin", _fx_));

        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: end", _fx_));
}

/****************************************************************************
 *  @doc INTERNAL CCONVERTMETHOD
 *
 *  @mfunc CICMConverter* | CICMConverter | CreateVfWCapDev | This
 *    helper function creates an object to interact with the VfW capture
 *    device.
 *
 *  @parm CTAPIVCap* | pCaptureFilter | Specifies a pointer to the owner
 *    filter.
 *
 *  @parm CCapDev** | ppCapDev | Specifies the address of a pointer to the
 *    newly created <c CVfWCapDev> object.
 *
 *  @rdesc This method returns an HRESULT value that depends on the
 *    implementation of the interface. HRESULT can include one of the
 *    following standard constants, or other values not listed:
 *
 *  @flag E_FAIL | Failure
 *  @flag E_POINTER | Null pointer argument
 *  @flag E_OUTOFMEMORY | Out of memory
 *  @flag NOERROR | No error
 ***************************************************************************/
HRESULT CALLBACK CICMConverter::CreateICMConverter(IN CTAPIBasePin *pBasePin, IN PBITMAPINFOHEADER pbiIn, IN PBITMAPINFOHEADER pbiOut, OUT CConverter **ppConverter)
{
        HRESULT Hr = NOERROR;

        FX_ENTRY("CICMConverter::CreateICMConverter")

        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: begin", _fx_));

        // Validate input parameters
        ASSERT(pBasePin);
        ASSERT(ppConverter);
        if (!pBasePin || !ppConverter)
        {
                DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: Null pointer argument", _fx_));
                Hr = E_POINTER;
                goto MyExit;
        }

        if (!(*ppConverter = (CConverter *) new CICMConverter(NAME("ICM Converter"), pBasePin, pbiIn, pbiOut, &Hr)))
        {
                DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: Out of memory", _fx_));
                Hr = E_OUTOFMEMORY;
                goto MyExit;
        }

        // If initialization failed, delete the stream array and return the error
        if (FAILED(Hr) && *ppConverter)
        {
                DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: Initialization failed", _fx_));
                Hr = E_FAIL;
                delete *ppConverter, *ppConverter = NULL;
        }

MyExit:
        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: end", _fx_));
        return Hr;
}
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\net\tapi\skywalker\filters\video\tapivcap\convert.h ===
/****************************************************************************
 *  @doc INTERNAL CONVERT
 *
 *  @module Convert.cpp | Source file for the <c CConverter> class methods
 *    used to implement the video capture and preview pin format conversion
 *    routines.
 *
 *  @todo Merge the two ScaleDIB methods + fix method comments + by the end
 *    of the H.362 work, you should never have to open an ICM encoder for
 *    encoding, only decode or scaling -> clean code at that point
 ***************************************************************************/

#ifndef _CONVERT_H_
#define _CONVERT_H_

/****************************************************************************
 *  @doc INTERNAL CCONVERTCLASS
 *
 *  @class CConverter | This base class implements a video encoder or decoder.
 ***************************************************************************/
class CConverter : public CUnknown
{
        public:

        DECLARE_IUNKNOWN
        STDMETHODIMP NonDelegatingQueryInterface(IN REFIID riid, OUT PVOID *ppv);
        CConverter(IN TCHAR *pObjectName, IN CTAPIBasePin *pBasePin, IN PBITMAPINFOHEADER pbiIn, IN PBITMAPINFOHEADER pbiOut, IN HRESULT *pHr);
        virtual ~CConverter();

        // Scaling routines
        void InitBlack8(IN PBITMAPINFOHEADER pbiSrc);
#ifdef USE_SOFTWARE_CAMERA_CONTROL
        HRESULT InsertSoftCamCtrl();
        HRESULT RemoveSoftCamCtrl();
        BOOL IsSoftCamCtrlInserted();
        BOOL IsSoftCamCtrlNeeded();
#endif

        // Format conversion routines
        virtual HRESULT ConvertFrame(IN PBYTE pbyInput, IN DWORD dwInputSize, IN PBYTE pbyOutput, OUT PDWORD pdwOutputSize, OUT PDWORD pdwBytesExtent, IN PBYTE pbyPreview, OUT PDWORD pdwPreviewSize, IN BOOL fSendKeyFrame) PURE;
        virtual HRESULT OpenConverter() PURE;
        virtual HRESULT CloseConverter();

        // Format conversion
        DWORD m_dwConversionType;
        PBYTE m_pbyOut;

        protected:

        CTAPIBasePin *m_pBasePin;

        // Quality control
        // @todo Do we really need this?
        DWORD m_dwImageQuality;

        // Format conversion
        DWORD m_dwLastTimestamp;
        DWORD m_dwLastIFrameTime;
        DWORD m_dwFrame;
        BOOL m_fPeriodicIFrames;
        PBITMAPINFOHEADER m_pbiOut;
        PBITMAPINFOHEADER m_pbiIn;
        PBITMAPINFOHEADER m_pbiInt;
        BOOL m_fConvert;

#ifdef USE_SOFTWARE_CAMERA_CONTROL
        // Soft Cam Control
        BOOL m_fSoftCamCtrl;
#endif
};

/****************************************************************************
 *  @doc INTERNAL CCONVERTCLASS
 *
 *  @class CConverter | This base class implements a converter using ICM.
 ***************************************************************************/
class CICMConverter : public CConverter
{
        public:

        DECLARE_IUNKNOWN
        CICMConverter(IN TCHAR *pObjectName, IN CTAPIBasePin *pBasePin, IN PBITMAPINFOHEADER pbiIn, IN PBITMAPINFOHEADER pbiOut, IN HRESULT *pHr);
        ~CICMConverter();
        static HRESULT CALLBACK CreateICMConverter(IN CTAPIBasePin *pBasePin, IN PBITMAPINFOHEADER pbiIn, IN PBITMAPINFOHEADER pbiOut, OUT CConverter **ppConverter);

        // Format conversion routines
        HRESULT ConvertFrame(IN PBYTE pbyInput, IN DWORD dwInputSize, IN PBYTE pbyOutput, OUT PDWORD pdwOutputSize, OUT PDWORD pdwBytesExtent, IN PBYTE pbyPreview, IN OUT PDWORD pdwPreviewSize, IN BOOL fSendKeyFrame);
        HRESULT OpenConverter();
        HRESULT CloseConverter();

        private:

        HIC m_hIC;
};

HRESULT ScaleDIB(PBITMAPINFOHEADER pbiSrc, PBYTE pbySrc, PBITMAPINFOHEADER pbiDst, PBYTE pbyDst, PRECT prcRect, BOOL fFlipHorizontal, BOOL fFlipVertical, BOOL fNoImageStretch, DWORD dwBlackEntry);
HRESULT ScaleDIB24(IN PBITMAPINFOHEADER pbiSrc, IN PBYTE pbySrc, IN PBITMAPINFOHEADER pbiDst, IN PBYTE pbyDst, IN PRECT prcRect, IN BOOL fFlipHorizontal, IN BOOL fFlipVertical, BOOL fNoImageStretch);
HRESULT ScaleDIB16(IN PBITMAPINFOHEADER pbiSrc, IN PBYTE pbySrc, IN PBITMAPINFOHEADER pbiDst, IN PBYTE pbyDst, IN PRECT prcRect, IN BOOL fFlipHorizontal, IN BOOL fFlipVertical, BOOL fNoImageStretch);
void InitDst8(IN OUT PBITMAPINFOHEADER pbiDst);
void ScalePackedPlane(IN PBYTE pbySrc, IN PBYTE pbyDst, IN int dxDst, IN int dyDst, IN long WidthBytesSrc, IN long WidthBytesDst, IN LPRECT prcRect, IN BOOL fFlipHorizontal, IN BOOL fFlipVertical, IN DWORD dwDelta);
void ScalePlane(IN PBYTE pbySrc, IN PBYTE pbyDst, IN int WidthBytesSrc, IN int dxDst, IN int dyDst, IN long WidthBytesDst, IN LPRECT prcRect, IN BOOL fFlipHorizontal, IN BOOL fFlipVertical);
HRESULT ScaleDIB8(IN PBITMAPINFOHEADER pbiSrc, IN PBYTE pbySrc, IN PBITMAPINFOHEADER pbiDst, IN PBYTE pbyDst, IN PRECT prcRect, IN BOOL fFlipHorizontal, IN BOOL fFlipVertical, BOOL fNoImageStretch, DWORD dwBlackEntry);
HRESULT ScaleDIB4(IN PBITMAPINFOHEADER pbiSrc, IN PBYTE pbySrc, IN PBITMAPINFOHEADER pbiDst, IN PBYTE pbyDst, IN PRECT prcRect, IN BOOL fFlipHorizontal, IN BOOL fFlipVertical, BOOL fNoImageStretch, DWORD dwBlackEntry);
HRESULT ScaleDIBYUVPlanar(PBITMAPINFOHEADER pbiSrc, PBYTE pbySrc, PBITMAPINFOHEADER pbiDst, PBYTE pbyDst, DWORD dwUVDownSampling, IN PRECT prcRect, IN BOOL fFlipHorizontal, IN BOOL fFlipVertical, BOOL fNoImageStretch);
HRESULT ScaleDIBYUVPacked(PBITMAPINFOHEADER pbiSrc, PBYTE pbySrc, PBITMAPINFOHEADER pbiDst, PBYTE pbyDst, DWORD dwZeroingDWORD, IN PRECT prcRect, IN BOOL fFlipHorizontal, IN BOOL fFlipVertical, BOOL fNoImageStretch, int []);
HRESULT ComputeRectangle(PBITMAPINFOHEADER pbiSrc, PBITMAPINFOHEADER pbiDst, LONG lZoom, LONG lPan, LONG lTilt, PRECT prcRect, BOOL fFlipHorizontal, BOOL fFlipVertical);

#endif // _CONVERT_H_
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\net\tapi\skywalker\filters\video\tapivcap\cpuc.cpp ===
/****************************************************************************
 *  @doc INTERNAL CPUC
 *
 *  @module CPUC.cpp | Source file for the <c CTAPIBasePin> class methods
 *    used to implement CPU control.
 ***************************************************************************/

#include "Precomp.h"

#ifdef USE_CPU_CONTROL

/****************************************************************************
 *  @doc INTERNAL CCPUCMETHOD
 *
 *  @mfunc HRESULT | CTAPIBasePin | SetMaxProcessingTime | This
 *    method is used to specify to the compressed video output pin the
 *    maximum encoding time per frame, in 100-nanosecond units.
 *
 *  @parm REFERENCE_TIME | MaxProcessingTime | Used to specify the maximum
 *    encoding time per frame, in 100-nanosecond units.
 *
 *  @rdesc This method returns an HRESULT value that depends on the
 *    implementation of the interface. HRESULT can include one of the
 *    following standard constants, or other values not listed:
 *
 *  @flag E_FAIL | Failure
 *  @flag NOERROR | No error
 ***************************************************************************/
STDMETHODIMP CTAPIBasePin::SetMaxProcessingTime(IN REFERENCE_TIME MaxProcessingTime)
{
	HRESULT Hr = NOERROR;

	FX_ENTRY("CTAPIBasePin::SetMaxProcessingTime")

	DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: begin", _fx_));

	// Validate input parameters - we can't take more than the picture interval
	// if we still want to be working in real time
	ASSERT(MaxProcessingTime < m_MaxAvgTimePerFrame);
	if (!(MaxProcessingTime < m_MaxAvgTimePerFrame))
	{
		DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: Invalid argument - would break real-time!", _fx_));
		Hr = E_INVALIDARG;
		goto MyExit;
	}

	// Remember value passed in 
	m_MaxProcessingTime = MaxProcessingTime;

MyExit:
	DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: end", _fx_));
	return Hr;
}

/****************************************************************************
 *  @doc INTERNAL CCPUCMETHOD
 *
 *  @mfunc HRESULT | CTAPIBasePin | GetMaxProcessingTime | This
 *    method is used to retrieve the maximum encoding time per frame the
 *    compressed video output pin is currently setup for, in 100-nanosecond
 *    units.
 *
 *  @parm REFERENCE_TIME* | pMaxProcessingTime | Used to receive the maximum
 *    encoding time per frame the compressed video output pin is currently
 *    setup for, in 100-nanosecond units.
 *
 *  @parm DWORD | dwMaxCPULoad | Specifies an hypothetical CPU load, in
 *    percentage units. If this parameter is set to -1UL, this method shall
 *    use the value of the CPU load  the compressed video output pin is
 *    currently setup for.
 *
 *  @rdesc This method returns an HRESULT value that depends on the
 *    implementation of the interface. HRESULT can include one of the
 *    following standard constants, or other values not listed:
 *
 *  @flag E_FAIL | Failure
 *  @flag E_POINTER | Null pointer argument
 *  @flag E_INVALIDARG | Invalid argument
 *  @flag NOERROR | No error
 ***************************************************************************/
STDMETHODIMP CTAPIBasePin::GetMaxProcessingTime(OUT REFERENCE_TIME *pMaxProcessingTime, IN DWORD dwMaxCPULoad)
{
	HRESULT Hr = NOERROR;

	FX_ENTRY("CTAPIBasePin::GetMaxProcessingTime")

	DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: begin", _fx_));

	// Validate input parameters
	ASSERT(pMaxProcessingTime);
	if (!pMaxProcessingTime)
	{
		DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: Null pointer argument", _fx_));
		Hr = E_POINTER;
		goto MyExit;
	}
	ASSERT(dwMaxCPULoad == (DWORD)-1L || dwMaxCPULoad <= 100);
	if (dwMaxCPULoad != (DWORD)-1L && dwMaxCPULoad > 100)
	{
		DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: Invalid argument - 0<dwMaxCPULoad<100 or -1 only", _fx_));
		Hr = E_INVALIDARG;
		goto MyExit;
	}

	// Ignore the CPU load information 
	if (m_MaxProcessingTime != -1)
		*pMaxProcessingTime = m_MaxProcessingTime;
	else
		*pMaxProcessingTime = m_MaxAvgTimePerFrame;

MyExit:
	DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: end", _fx_));
	return Hr;
}

/****************************************************************************
 *  @doc INTERNAL CCPUCMETHOD
 *
 *  @mfunc HRESULT | CTAPIBasePin | GetCurrentProcessingTime | This
 *    method is used to retrieve the current encoding time per frame, in
 *    100-nanosecond units.
 *
 *  @parm REFERENCE_TIME* | pCurrentProcessingTime | Used to receive the maximum
 *    encoding time per frame the compressed video output pin is currently
 *    setup for, in 100-nanosecond units.
 *
 *  @rdesc This method returns an HRESULT value that depends on the
 *    implementation of the interface. HRESULT can include one of the
 *    following standard constants, or other values not listed:
 *
 *  @flag E_FAIL | Failure
 *  @flag E_POINTER | Null pointer argument
 *  @flag NOERROR | No error
 ***************************************************************************/
STDMETHODIMP CTAPIBasePin::GetCurrentProcessingTime(OUT REFERENCE_TIME *pCurrentProcessingTime)
{
	HRESULT Hr = NOERROR;

	FX_ENTRY("CTAPIBasePin::GetMaxProcessingTime")

	DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: begin", _fx_));

	// Validate input parameters
	ASSERT(pCurrentProcessingTime);
	if (!pCurrentProcessingTime)
	{
		DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: Null pointer argument", _fx_));
		Hr = E_POINTER;
		goto MyExit;
	}

	// Return the current processing time 
	*pCurrentProcessingTime = m_CurrentProcessingTime;

MyExit:
	DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: end", _fx_));
	return Hr;
}

/****************************************************************************
 *  @doc INTERNAL CCPUCMETHOD
 *
 *  @mfunc HRESULT | CTAPIBasePin | GetMaxProcessingTimeRange | This
 *    method is used to retrieve support, minimum, maximum, and default
 *    values for the maximum encoding time per frame the compressed video
 *    output pin may be setup for, in 100-nanosecond units.
 *
 *  @parm REFERENCE_TIME* | pMin | Used to retrieve the minimum value of
 *    encoding time per frame the compressed video output pin may be setup
 *    for, in 100-nanosecond units.
 *
 *  @parm REFERENCE_TIME* | pMax | Used to retrieve the maximum value of
 *    encoding time per frame the compressed video output pin may be setup
 *    for, in 100-nanosecond units.
 *
 *  @parm REFERENCE_TIME* | pSteppingDelta | Used to retrieve the stepping
 *    delta of encoding time per frame the compressed video output pin may
 *    be setup for, in 100-nanosecond units.
 *
 *  @parm REFERENCE_TIME* | pDefault | Used to retrieve the default value
 *    of encoding time per frame the compressed video output pin is setup
 *    for, in 100-nanosecond units.
 *
 *  @parm DWORD | dwMaxCPULoad | Specifies an hypothetical CPU load, in
 *    percentage units. If this parameter is set to -1UL, this method shall
 *    use the value of the CPU load  the compressed video output pin is
 *    currently setup for.
 *
 *  @rdesc This method returns an HRESULT value that depends on the
 *    implementation of the interface. HRESULT can include one of the
 *    following standard constants, or other values not listed:
 *
 *  @flag E_FAIL | Failure
 *  @flag E_POINTER | Null pointer argument
 *  @flag E_INVALIDARG | Invalid argument
 *  @flag E_NOTIMPL | Method is not supported
 *  @flag NOERROR | No error
 ***************************************************************************/
STDMETHODIMP CTAPIBasePin::GetMaxProcessingTimeRange(OUT REFERENCE_TIME *pMin, OUT REFERENCE_TIME *pMax, OUT REFERENCE_TIME *pSteppingDelta, OUT REFERENCE_TIME *pDefault, IN DWORD dwMaxCPULoad)
{
	HRESULT Hr = NOERROR;

	FX_ENTRY("CTAPIBasePin::GetMaxProcessingTimeRange")

	DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: begin", _fx_));

	// Validate input parameters
	ASSERT(pMin && pMax && pSteppingDelta && pDefault);
	if (!pMin || !pMax || !pSteppingDelta || !pDefault)
	{
		DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: Null pointer argument", _fx_));
		Hr = E_POINTER;
		goto MyExit;
	}
	ASSERT(dwMaxCPULoad == (DWORD)-1L || dwMaxCPULoad <= 100);
	if (dwMaxCPULoad != (DWORD)-1L && dwMaxCPULoad > 100)
	{
		DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: Invalid argument - 0<dwMaxCPULoad<100 or -1 only", _fx_));
		Hr = E_INVALIDARG;
		goto MyExit;
	}

	// Return range information - ignore CPU load 
	*pMin = 0;
	*pMax = m_MaxAvgTimePerFrame;
	*pSteppingDelta = 1;
	*pDefault = 0;

MyExit:
	DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: end", _fx_));
	return Hr;
}

/****************************************************************************
 *  @doc INTERNAL CCPUCMETHOD
 *
 *  @mfunc HRESULT | CTAPIBasePin | SetMaxCPULoad | This method is used to
 *    specify to the compressed video output pin the maximum encoding
 *    algorithm CPU load.
 *
 *  @parm DWORD | dwMaxCPULoad | Used to specify the maximum encoding
 *    algorithm CPU load, in percentage units.
 *
 *  @rdesc This method returns an HRESULT value that depends on the
 *    implementation of the interface. HRESULT can include one of the
 *    following standard constants, or other values not listed:
 *
 *  @flag E_FAIL | Failure
 *  @flag E_INVALIDARG | Invalid argument
 *  @flag NOERROR | No error
 ***************************************************************************/
STDMETHODIMP CTAPIBasePin::SetMaxCPULoad(IN DWORD dwMaxCPULoad)
{
	HRESULT Hr = NOERROR;

	FX_ENTRY("CTAPIBasePin::SetMaxCPULoad")

	DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: begin", _fx_));

	// Validate input parameters
	ASSERT(dwMaxCPULoad >= 0 && dwMaxCPULoad <= 100);
	if (!(dwMaxCPULoad >= 0 && dwMaxCPULoad <= 100))
	{
		DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: Invalid argument - 0<dwMaxCPULoad<100 or -1 only", _fx_));
		Hr = E_INVALIDARG;
		goto MyExit;
	}

	// Remember value passed in
	m_dwMaxCPULoad = dwMaxCPULoad;

MyExit:
	DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: end", _fx_));
	return Hr;
}

/****************************************************************************
 *  @doc INTERNAL CCPUCMETHOD
 *
 *  @mfunc HRESULT | CTAPIBasePin | GetMaxCPULoad | This
 *    method is used to retrieve the maximum encoding algorithm CPU load the
 *    compressed video output pin is currently setup for.
 *
 *  @parm DWORD* | pdwMaxCPULoad | Used to retrieve the maximum encoding
 *    algorithm CPU load the compressed video output pin is currently setup
 *    for, in percentage units.
 *
 *  @parm REFERENCE_TIME | MaxProcessingTime | Specifies an hypothetical
 *    maximum encoding time per frame, in 100-nanosecond units. If this
 *    parameter is set to -1, this method shall use the value of the maximum
 *    encoding time per frame the compressed video output pin is currently
 *    setup for.
 *
 *  @rdesc This method returns an HRESULT value that depends on the
 *    implementation of the interface. HRESULT can include one of the
 *    following standard constants, or other values not listed:
 *
 *  @flag E_FAIL | Failure
 *  @flag E_POINTER | Null pointer argument
 *  @flag NOERROR | No error
 ***************************************************************************/
STDMETHODIMP CTAPIBasePin::GetMaxCPULoad(OUT DWORD *pdwMaxCPULoad, IN REFERENCE_TIME MaxProcessingTime)
{
	HRESULT Hr = NOERROR;

	FX_ENTRY("CTAPIBasePin::GetMaxCPULoad")

	DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: begin", _fx_));

	// Validate input parameters
	ASSERT(pdwMaxCPULoad);
	if (!pdwMaxCPULoad)
	{
		DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: Null pointer argument", _fx_));
		Hr = E_POINTER;
		goto MyExit;
	}

	// Return current value - ignore MaxProcessingTime parameter 
	*pdwMaxCPULoad = m_dwMaxCPULoad;

MyExit:
	DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: end", _fx_));
	return Hr;
}

/****************************************************************************
 *  @doc INTERNAL CCPUCMETHOD
 *
 *  @mfunc HRESULT | CTAPIBasePin | GetCurrentCPULoad | This
 *    method is used to retrieve the current encoding algorithm CPU load.
 *
 *  @parm DWORD* | pdwCurrentCPULoad | Used to retrieve the current encoding
 *    algorithm CPU load, in percentage units.
 *
 *  @rdesc This method returns an HRESULT value that depends on the
 *    implementation of the interface. HRESULT can include one of the
 *    following standard constants, or other values not listed:
 *
 *  @flag E_FAIL | Failure
 *  @flag E_POINTER | Null pointer argument
 *  @flag NOERROR | No error
 ***************************************************************************/
STDMETHODIMP CTAPIBasePin::GetCurrentCPULoad(OUT DWORD *pdwCurrentCPULoad)
{
	HRESULT Hr = NOERROR;

	FX_ENTRY("CTAPIBasePin::GetCurrentCPULoad")

	DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: begin", _fx_));

	// Validate input parameters
	ASSERT(pdwCurrentCPULoad);
	if (!pdwCurrentCPULoad)
	{
		DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: Null pointer argument", _fx_));
		Hr = E_POINTER;
		goto MyExit;
	}

	// Return current value
	*pdwCurrentCPULoad = m_dwCurrentCPULoad;

MyExit:
	DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: end", _fx_));
	return Hr;
}

/****************************************************************************
 *  @doc INTERNAL CCPUCMETHOD
 *
 *  @mfunc HRESULT | CTAPIBasePin | GetMaxCPULoadRange | This
 *    method is used to retrieve support, minimum, maximum, and default
 *    values for the maximum CPU load the compressed video output pin may be
 *    setup for, in percentage.
 *
 *  @parm DWORD* | pdwMin | Used to retrieve the minimum value of encoding
 *    algorithm CPU load the compressed video output pin may be setup for,
 *    in percentage units.
 *
 *  @parm DWORD* | pdwMax | Used to retrieve the maximum value of encoding
 *    algorithm CPU load the compressed video output pin may be setup for, in
 *    percentage units.
 *
 *  @parm DWORD* | pdwSteppingDelta | Used to retrieve the stepping delta of
 *    encoding algorithm CPU load the compressed video output pin may be
 *    setup for, in percentage units.
 *
 *  @parm DWORD* | pdwDefault | Used to retrieve the default value of encoding
 *    algorithm CPU load the compressed video output pin is setup for, in
 *    percentage units.
 *
 *  @parm REFERENCE_TIME | MaxProcessingTime | Specifies an hypothetical
 *    maximum encoding time per frame, in 100-nanosecond units. If this
 *    parameter is set to -1, this method shall use the value of the maximum
 *    encoding time per frame the compressed video output pin is currently
 *    setup for.
 *
 *  @rdesc This method returns an HRESULT value that depends on the
 *    implementation of the interface. HRESULT can include one of the
 *    following standard constants, or other values not listed:
 *
 *  @flag E_FAIL | Failure
 *  @flag E_POINTER | Null pointer argument
 *  @flag NOERROR | No error
 ***************************************************************************/
STDMETHODIMP CTAPIBasePin::GetMaxCPULoadRange(OUT DWORD *pdwMin, OUT DWORD *pdwMax, OUT DWORD *pdwSteppingDelta, OUT DWORD *pdwDefault, IN REFERENCE_TIME MaxProcessingTime)
{
	HRESULT Hr = NOERROR;

	FX_ENTRY("CTAPIBasePin::GetMaxCPULoadRange")

	DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: begin", _fx_));

	// Validate input parameters
	ASSERT(pdwMin && pdwMax && pdwSteppingDelta && pdwDefault);
	if (!pdwMin || !pdwMax || !pdwSteppingDelta || !pdwDefault)
	{
		DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: Null pointer argument", _fx_));
		Hr = E_POINTER;
		goto MyExit;
	}

	// Return range values - ignore MaxProcessingTime parameter 
	*pdwMin = 0;
	*pdwMax = 100;
	*pdwSteppingDelta = 1;
	*pdwDefault = 0;

MyExit:
	DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: end", _fx_));
	return Hr;
}

#endif
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\net\tapi\skywalker\filters\video\tapivcap\capturep.cpp ===
/****************************************************************************
 *  @doc INTERNAL CAPTUREP
 *
 *  @module CaptureP.cpp | Source ile for the <c CCaptureProperty>
 *    class used to implement a property page to test the new TAPI internal
 *    interfaces <i IBitrateControl>, <i IFrameRateControl>, and dynamic
 *    format changes.
 *
 *  @comm This code tests the TAPI Capture Pin <i IBitrateControl>,
 *    <i IFrameRateControl>, and dynamic format change implementation. This
 *    code is only compiled if USE_PROPERTY_PAGES is defined.
 ***************************************************************************/

#include "Precomp.h"

#ifdef USE_PROPERTY_PAGES

#if 0 // remove later.
// Video subtypes
EXTERN_C const GUID MEDIASUBTYPE_H263_V1 = {0x3336324DL, 0x0000, 0x0010, {0x80, 0x00, 0x00, 0xAA, 0x00, 0x38, 0x9B, 0x71}};
EXTERN_C const GUID MEDIASUBTYPE_H261 = {0x3136324DL, 0x0000, 0x0010, {0x80, 0x00, 0x00, 0xAA, 0x00, 0x38, 0x9B, 0x71}};
EXTERN_C const GUID MEDIASUBTYPE_H263_V2 = {0x3336324EL, 0x0000, 0x0010, {0x80, 0x00, 0x00, 0xAA, 0x00, 0x38, 0x9B, 0x71}};
#endif

EXTERN_C const GUID MEDIASUBTYPE_I420 = {0x30323449L, 0x0000, 0x0010, {0x80, 0x00, 0x00, 0xAA, 0x00, 0x38, 0x9B, 0x71}};
EXTERN_C const GUID MEDIASUBTYPE_IYUV = {0x56555949L, 0x0000, 0x0010, {0x80, 0x00, 0x00, 0xAA, 0x00, 0x38, 0x9B, 0x71}};

/****************************************************************************
 *  @doc INTERNAL CCAPTUREPMETHOD
 *
 *  @mfunc void | CCaptureProperty | CCaptureProperty | This
 *    method is the constructor for bitrate and frame rate property objects. It
 *    calls the base class constructor, calls InitCommonControlsEx, and saves
 *    pointers to the <i IBitrateControl> and <i IFrameRateControl> interfaces.
 *
 *  @parm HWND | hDlg | Specifies a handle to the parent property page.
 *
 *  @parm ULONG | IDLabel | Specifies a label ID for the property.
 *
 *  @parm ULONG | IDMinControl | Specifies a label ID for the associated
 *    property edit control where the Minimum value of the property appears.
 *
 *  @parm ULONG | IDMaxControl | Specifies a label ID for the associated
 *    property edit control where the Maximum value of the property appears.
 *
 *  @parm ULONG | IDDefaultControl | Specifies a label ID for the associated
 *    property edit control where the Default value of the property appears.
 *
 *  @parm ULONG | IDStepControl | Specifies a label ID for the associated
 *    property edit control where the Stepping Delta value of the property appears.
 *
 *  @parm ULONG | IDEditControl | Specifies a label ID for the associated
 *    property edit control where the value of the property appears.
 *
 *  @parm ULONG | IDTrackbarControl | Specifies a label ID for the associated
 *    property slide bar.
 *
 *  @parm ULONG | IDProgressControl | Specifies a label ID for the associated
 *    property slide bar.
 *
 *  @parm ULONG | IDProperty | Specifies the ID of the Ks property.
 *
 *  @parm IBitrateControl* | pIBitrateControl | Specifies a pointer to the
 *    <i IBitrateControl> interface.
 *
 *  @parm IFrameRateControl* | pIFrameRateControl | Specifies a pointer to the
 *    <i IFrameRateControl> interface.
 *
 *  @rdesc Nada.
 ***************************************************************************/
CCaptureProperty::CCaptureProperty(HWND hDlg, ULONG IDLabel, ULONG IDMinControl, ULONG IDMaxControl, ULONG IDDefaultControl, ULONG IDStepControl, ULONG IDEditControl, ULONG IDTrackbarControl, ULONG IDProgressControl, ULONG IDProperty, IBitrateControl *pIBitrateControl, IFrameRateControl *pIFrameRateControl, IVideoControl *pIVideoControl)
: CPropertyEditor(hDlg, IDLabel, IDMinControl, IDMaxControl, IDDefaultControl, IDStepControl, IDEditControl, IDTrackbarControl, IDProgressControl, IDProperty, 0)
{
	INITCOMMONCONTROLSEX cc;

	FX_ENTRY("CCaptureProperty::CCaptureProperty")

	DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: begin", _fx_));

	cc.dwSize = sizeof (INITCOMMONCONTROLSEX);
	cc.dwICC  = ICC_UPDOWN_CLASS | ICC_BAR_CLASSES;

	InitCommonControlsEx(&cc);

	// It's fine if the interface pointers are NULL, we'll grey the
	// associated items in the property page
	m_pIBitrateControl = pIBitrateControl;
	m_pIFrameRateControl = pIFrameRateControl;
	m_pIVideoControl = pIVideoControl;

	DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: end", _fx_));
}

/****************************************************************************
 *  @doc INTERNAL CCAPTUREPMETHOD
 *
 *  @mfunc void | CCaptureProperty | ~CCaptureProperty | This
 *    method is the destructor for capture property objects. It
 *    simply calls the base class destructor.
 *
 *  @rdesc Nada.
 ***************************************************************************/
CCaptureProperty::~CCaptureProperty()
{
	FX_ENTRY("CCaptureProperty::~CCaptureProperty")

	DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: begin", _fx_));

	DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: end", _fx_));
}

/****************************************************************************
 *  @doc INTERNAL CCAPTUREPMETHOD
 *
 *  @mfunc HRESULT | CCaptureProperty | GetValue | This method queries for
 *    the value of a property.
 *
 *  @rdesc This method returns an HRESULT value that depends on the
 *    implementation of the interface. HRESULT can include one of the
 *    following standard constants, or other values not listed:
 *
 *  @flag E_FAIL | Failure
 *  @flag E_POINTER | Null pointer argument
 *  @flag E_NOTIMPL | Method is not supported
 *  @flag NOERROR | No error
 ***************************************************************************/
HRESULT CCaptureProperty::GetValue()
{
	HRESULT Hr = E_NOTIMPL;
	LONG CurrentValue;
	LONG Mode;

	FX_ENTRY("CCaptureProperty::GetValue")

	DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: begin", _fx_));

	switch (m_IDProperty)
	{									
		case IDC_Capture_FrameRate:
			if (m_pIFrameRateControl && SUCCEEDED (Hr = m_pIFrameRateControl->Get(FrameRateControl_Maximum, &CurrentValue, (TAPIControlFlags *)&m_CurrentFlags)))
			{
				if (CurrentValue)
					m_CurrentValue = (LONG)(10000000 / CurrentValue);
				else
					m_CurrentValue = 0;
				DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s:   SUCCESS: *pAvgTimePerFrame=%ld", _fx_, CurrentValue));
			}
			else
			{
				DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: Failed Hr=0x%08lX", _fx_, Hr));
			}
			break;
		case IDC_Capture_CurrentFrameRate:
			if (m_pIFrameRateControl && SUCCEEDED (Hr = m_pIFrameRateControl->Get(FrameRateControl_Current, &CurrentValue, (TAPIControlFlags *)&m_CurrentFlags)))
			{
				if (CurrentValue)
					m_CurrentValue = (LONG)(10000000 / CurrentValue);
				else
					m_CurrentValue = 0;
				DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s:   SUCCESS: *pAvgTimePerFrame=%ld", _fx_, CurrentValue));
			}
			else
			{
				DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: Failed Hr=0x%08lX", _fx_, Hr));
			}
			break;
		case IDC_Capture_Bitrate:
			if (m_pIBitrateControl && SUCCEEDED (Hr = m_pIBitrateControl->Get(BitrateControl_Maximum, &m_CurrentValue, (TAPIControlFlags *)&m_CurrentFlags, 0UL)))
			{
				DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s:   SUCCESS: *pdwMaxBitrate=%ld, dwLayerId=0", _fx_, m_CurrentValue));
			}
			else
			{
				DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: Failed Hr=0x%08lX", _fx_, Hr));
			}
			break;
		case IDC_Capture_CurrentBitrate:
			if (m_pIBitrateControl && SUCCEEDED (Hr = m_pIBitrateControl->Get(BitrateControl_Current, &m_CurrentValue, (TAPIControlFlags *)&m_CurrentFlags, 0UL)))
			{
				DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s:   SUCCESS: *pdwCurrentBitrate=%ld, dwLayerId=0", _fx_, m_CurrentValue));
			}
			else
			{
				DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: Failed Hr=0x%08lX", _fx_, Hr));
			}
			break;
		case IDC_Capture_FlipVertical:
			if (m_pIVideoControl && SUCCEEDED (Hr = m_pIVideoControl->GetMode(&Mode)))
			{
				// We have to be between 0 and 1
				m_CurrentValue = Mode & VideoControlFlag_FlipVertical ? TRUE : FALSE;
				DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s:   SUCCESS: Vertical flip is %s"), _fx_, m_CurrentValue ? "ON" : "OFF");
			}
			else
			{
				DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: Failed Hr=0x%08lX", _fx_, Hr));
			}
			break;
		case IDC_Capture_FlipHorizontal:
			if (m_pIVideoControl && SUCCEEDED (Hr = m_pIVideoControl->GetMode(&Mode)))
			{
				// We have to be between 0 and 1
				m_CurrentValue = Mode & VideoControlFlag_FlipHorizontal ? TRUE : FALSE;
				DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s:   SUCCESS: Horizontal flip is %s"), _fx_, m_CurrentValue ? "ON" : "OFF");
			}
			else
			{
				DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: Failed Hr=0x%08lX", _fx_, Hr));
			}
			break;
		default:
			Hr = E_UNEXPECTED;
			DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: Unknown capture property", _fx_));
	}

	DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: end", _fx_));
	return Hr;
}

/****************************************************************************
 *  @doc INTERNAL CCAPTUREPMETHOD
 *
 *  @mfunc HRESULT | CCaptureProperty | SetValue | This method sets the
 *    value of a property.
 *
 *  @rdesc This method returns an HRESULT value that depends on the
 *    implementation of the interface. HRESULT can include one of the
 *    following standard constants, or other values not listed:
 *
 *  @flag E_FAIL | Failure
 *  @flag E_POINTER | Null pointer argument
 *  @flag E_NOTIMPL | Method is not supported
 *  @flag NOERROR | No error
 ***************************************************************************/
HRESULT CCaptureProperty::SetValue()
{
	HRESULT Hr = E_NOTIMPL;
	LONG CurrentValue;
	long Mode;

	FX_ENTRY("CCaptureProperty::SetValue")

	DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: begin", _fx_));

	switch (m_IDProperty)
	{
		case IDC_Capture_FrameRate:
			if (m_CurrentValue)
				CurrentValue = 10000000L / m_CurrentValue;
			if (m_pIFrameRateControl && SUCCEEDED (Hr = m_pIFrameRateControl->Set(FrameRateControl_Maximum, CurrentValue, (TAPIControlFlags)m_CurrentFlags)))
			{
				DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s:   SUCCESS: AvgTimePerFrame=%ld", _fx_, CurrentValue));
			}
			else
			{
				DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: Failed Hr=0x%08lX", _fx_, Hr));
			}
			break;
		case IDC_Capture_Bitrate:
			if (m_pIBitrateControl && SUCCEEDED (Hr = m_pIBitrateControl->Set(BitrateControl_Maximum, m_CurrentValue, (TAPIControlFlags)m_CurrentFlags, 0UL)))
			{
				DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s:   SUCCESS: dwMaxBitrate=%ld, dwLayerId=0", _fx_, m_CurrentValue));
			}
			else
			{
				DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: Failed Hr=0x%08lX", _fx_, Hr));
			}
			break;
		case IDC_Capture_FlipVertical:
			if (m_pIVideoControl && SUCCEEDED (Hr = m_pIVideoControl->GetMode(&Mode)))
			{
				if (m_CurrentValue)
					Mode |= VideoControlFlag_FlipVertical;
				else
					Mode &= !VideoControlFlag_FlipVertical;
				if (SUCCEEDED (Hr = m_pIVideoControl->SetMode(Mode)))
				{
					DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s:   SUCCESS: Vertical flip is %s"), _fx_, m_CurrentValue ? "ON" : "OFF");
				}
				else
				{
					DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: Failed Hr=0x%08lX", _fx_, Hr));
				}
			}
			else
			{
				DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: Failed Hr=0x%08lX", _fx_, Hr));
			}
			break;
		case IDC_Capture_FlipHorizontal:
			if (m_pIVideoControl && SUCCEEDED (Hr = m_pIVideoControl->GetMode(&Mode)))
			{
				if (m_CurrentValue)
					Mode |= VideoControlFlag_FlipHorizontal;
				else
					Mode &= !VideoControlFlag_FlipHorizontal;
				if (SUCCEEDED (Hr = m_pIVideoControl->SetMode(Mode)))
				{
					DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s:   SUCCESS: Horizontal flip is %s"), _fx_, m_CurrentValue ? "ON" : "OFF");
				}
				else
				{
					DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: Failed Hr=0x%08lX", _fx_, Hr));
				}
			}
			else
			{
				DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: Failed Hr=0x%08lX", _fx_, Hr));
			}
			break;
		case IDC_Capture_CurrentBitrate:
		case IDC_Capture_CurrentFrameRate:
			// This is a read-only property. Don't do anything.
			Hr = NOERROR;
			break;
		default:
			Hr = E_UNEXPECTED;
			DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: Unknown capture property", _fx_));
	}

	DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: end", _fx_));
	return Hr;
}

/****************************************************************************
 *  @doc INTERNAL CCAPTUREPMETHOD
 *
 *  @mfunc HRESULT | CCaptureProperty | GetRange | This method retrieves
 *    the range information of a property.
 *
 *  @rdesc This method returns an HRESULT value that depends on the
 *    implementation of the interface. HRESULT can include one of the
 *    following standard constants, or other values not listed:
 *
 *  @flag E_FAIL | Failure
 *  @flag E_POINTER | Null pointer argument
 *  @flag E_NOTIMPL | Method is not supported
 *  @flag NOERROR | No error
 ***************************************************************************/
HRESULT CCaptureProperty::GetRange()
{
	HRESULT Hr = E_NOTIMPL;
	LONG Min;
	LONG Max;
	LONG SteppingDelta;
	LONG Default;

	FX_ENTRY("CCaptureProperty::GetRange")

	DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: begin", _fx_));

	switch (m_IDProperty)
	{
		case IDC_Capture_FrameRate:
			if (m_pIFrameRateControl && SUCCEEDED (Hr = m_pIFrameRateControl->GetRange(FrameRateControl_Maximum, &Min, &Max, &SteppingDelta, &Default, (TAPIControlFlags *)&m_CapsFlags)))
			{
				if (Min)
					m_Max = (LONG)(10000000 / Min);
				else
					m_Max = 0;
				if (Max)
					m_Min = (LONG)(10000000 / Max);
				else
					m_Min = 0;
				if (SteppingDelta)
					m_SteppingDelta = (m_Max - m_Min) / (LONG)((Max - Min) / SteppingDelta);
				else
					m_SteppingDelta = 0;
				if (Default)
					m_DefaultValue = (LONG)(10000000 / Default);
				else
					m_DefaultValue = 0;
				DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s:   SUCCESS: *pMin=%ld, *pMax=%ld, *pSteppingDelta=%ld, *pDefault=%ld", _fx_, Min, Max, SteppingDelta, Default));
			}
			else
			{
				DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: Failed Hr=0x%08lX", _fx_, Hr));
			}
			break;
		case IDC_Capture_CurrentFrameRate:
			if (m_pIFrameRateControl && SUCCEEDED (Hr = m_pIFrameRateControl->GetRange(FrameRateControl_Current, &Min, &Max, &SteppingDelta, &Default, (TAPIControlFlags *)&m_CapsFlags)))
			{
				if (Min)
					m_Max = (LONG)(10000000 / Min);
				else
					m_Max = 0;
				if (Max)
					m_Min = (LONG)(10000000 / Max);
				else
					m_Min = 0;
				if (SteppingDelta)
					m_SteppingDelta = (LONG)(10000000 / SteppingDelta);
				else
					m_SteppingDelta = 0;
				if (Default)
					m_DefaultValue = (LONG)(10000000 / Default);
				else
					m_DefaultValue = 0;
				DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s:   SUCCESS: *pMin=%ld, *pMax=%ld, *pSteppingDelta=%ld, *pDefault=%ld", _fx_, Min, Max, SteppingDelta, Default));
			}
			else
			{
				DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: Failed Hr=0x%08lX", _fx_, Hr));
			}
			break;
		case IDC_Capture_Bitrate:
			if (m_pIBitrateControl && SUCCEEDED (Hr = m_pIBitrateControl->GetRange(BitrateControl_Maximum, &m_Min, &m_Max, &m_SteppingDelta, &m_DefaultValue, (TAPIControlFlags *)&m_CapsFlags, 0UL)))
			{
				DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s:   SUCCESS: *pdwMin=%ld, *pdwMax=%ld, *pdwSteppingDelta=%ld, *pdwDefault=%ld, dwLayerId=0", _fx_, m_Min, m_Max, m_SteppingDelta, m_DefaultValue));
			}
			else
			{
				DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: Failed Hr=0x%08lX", _fx_, Hr));
			}
			break;
		case IDC_Capture_CurrentBitrate:
			if (m_pIBitrateControl && SUCCEEDED (Hr = m_pIBitrateControl->GetRange(BitrateControl_Current, &m_Min, &m_Max, &m_SteppingDelta, &m_DefaultValue, (TAPIControlFlags *)&m_CapsFlags, 0UL)))
			{
				DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s:   SUCCESS: *pdwMin=%ld, *pdwMax=%ld, *pdwSteppingDelta=%ld, *pdwDefault=%ld, dwLayerId=0", _fx_, m_Min, m_Max, m_SteppingDelta, m_DefaultValue));
			}
			else
			{
				DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: Failed Hr=0x%08lX", _fx_, Hr));
			}
			break;
		case IDC_Capture_FlipVertical:
		case IDC_Capture_FlipHorizontal:
			m_DefaultValue = m_CurrentValue;
			m_Min = 0;
			m_Max = 1;
			m_SteppingDelta = 1;
			Hr = NOERROR;
			break;
		default:
			Hr = E_UNEXPECTED;
			DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: Unknown capture property", _fx_));
	}

	DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: end", _fx_));
	return Hr;
}

/****************************************************************************
 *  @doc INTERNAL CCAPTUREPMETHOD
 *
 *  @mfunc CUnknown* | CCaptureProperties | CreateInstance | This
 *    method is called by DShow to create an instance of a TAPI Capture Pin
 *    Property Page. It is referred to in the global structure <t g_Templates>.
 *
 *  @parm LPUNKNOWN | pUnkOuter | Specifies the outer unknown, if any.
 *
 *  @parm HRESULT* | pHr | Specifies the place in which to put any error return.
 *
 *  @rdesc Returns a pointer to the nondelegating CUnknown portion of the
 *    object, or NULL otherwise.
 ***************************************************************************/
CUnknown* CALLBACK CCapturePropertiesCreateInstance(LPUNKNOWN pUnkOuter, HRESULT *pHr) 
{
	CUnknown *pUnknown = (CUnknown *)NULL;

	FX_ENTRY("CCapturePropertiesCreateInstance")

	DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: begin", _fx_));

	// Validate input parameters
	ASSERT(pHr);
	if (!pHr)
	{
		DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: invalid input parameter", _fx_));
		goto MyExit;
	}

	if (!(pUnknown = new CCaptureProperties(pUnkOuter, pHr)))
	{
		*pHr = E_OUTOFMEMORY;
		DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: new CCaptureProperties failed", _fx_));
	}
	else
	{
		DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s:   SUCCESS: new CCaptureProperties created", _fx_));
	}

MyExit:
	DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: end", _fx_));
	return pUnknown;
}

/****************************************************************************
 *  @doc INTERNAL CCAPTUREPMETHOD
 *
 *  @mfunc void | CCaptureProperties | CCaptureProperties | This
 *    method is the constructor for the property page object. It simply
 *    calls the constructor of the property page base class.
 *
 *  @parm LPUNKNOWN | pUnkOuter | Specifies the outer unknown, if any.
 *
 *  @parm HRESULT* | pHr | Specifies the place in which to put any error return.
 *
 *  @rdesc Nada.
 ***************************************************************************/
CCaptureProperties::CCaptureProperties(LPUNKNOWN pUnk, HRESULT *pHr) : CBasePropertyPage(NAME("TAPI Capture Pin Property Page"), pUnk, IDD_CaptureFormatProperties, IDS_CAPTUREFORMATSPROPNAME)
{
	FX_ENTRY("CCaptureProperties::CCaptureProperties")

	DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: begin", _fx_));

	m_pIBitrateControl = NULL;
	m_pIFrameRateControl = NULL;
	m_pIAMStreamConfig = NULL;
	m_pIVideoControl = NULL;
	m_NumProperties = NUM_CAPTURE_CONTROLS;
	m_fActivated = FALSE;
	m_hWndFormat = m_hWnd = NULL;
	m_RangeCount = 0;
	m_SubTypeList = NULL;
	m_FrameSizeList = NULL;
	m_CurrentMediaType = NULL;
	m_CurrentFormat = 0;
	m_OriginalFormat = 0;

	for (int i = 0; i < m_NumProperties; i++)
		m_Controls[i] = NULL;

	DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: end", _fx_));
}

/****************************************************************************
 *  @doc INTERNAL CCAPTUREPMETHOD
 *
 *  @mfunc void | CCaptureProperties | ~CCaptureProperties | This
 *    method is the destructor for the capture pin property page. It
 *    simply calls the base class destructor after deleting all the controls.
 *
 *  @rdesc Nada.
 ***************************************************************************/
CCaptureProperties::~CCaptureProperties()
{
	int		j;

	FX_ENTRY("CCaptureProperties::~CCaptureProperties")

	DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: begin", _fx_));

	// Free the controls
	for (j = 0; j < m_NumProperties; j++)
	{
		if (m_Controls[j])
		{
			DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s:   SUCCESS: deleting m_Controls[%ld]=0x%08lX", _fx_, j, m_Controls[j]));
			delete m_Controls[j], m_Controls[j] = NULL;
		}
		else
		{
			DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   WARNING: control already freed", _fx_));
		}
	}

	if (m_SubTypeList)
		delete[] m_SubTypeList, m_SubTypeList = NULL;

	if (m_FrameSizeList)
		delete[] m_FrameSizeList, m_FrameSizeList = NULL;

	DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: end", _fx_));
}

/****************************************************************************
 *  @doc INTERNAL CCAPTUREPMETHOD
 *
 *  @mfunc HRESULT | CCaptureProperties | OnConnect | This
 *    method is called when the property page is connected to the filter.
 *
 *  @parm LPUNKNOWN | pUnknown | Specifies the outer unknown, if any.
 *
 *  @parm HRESULT* | pHr | Specifies the place in which to put any error return.
 *
 *  @rdesc This method returns an HRESULT value that depends on the
 *    implementation of the interface. HRESULT can include one of the
 *    following standard constants, or other values not listed:
 *
 *  @flag E_FAIL | Failure
 *  @flag E_POINTER | Null pointer argument
 *  @flag E_NOTIMPL | Method is not supported
 *  @flag NOERROR | No error
 ***************************************************************************/
HRESULT CCaptureProperties::OnConnect(IUnknown *pUnk)
{
	HRESULT Hr = NOERROR;

	FX_ENTRY("CCaptureProperties::OnConnect")

	DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: begin", _fx_));

	// Validate input parameters
	ASSERT(pUnk);
	if (!pUnk)
	{
		DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: invalid input parameter", _fx_));
		Hr = E_POINTER;
		goto MyExit;
	}

	// Get the bitrate control interface
	if (SUCCEEDED (Hr = pUnk->QueryInterface(__uuidof(IBitrateControl), (void **)&m_pIBitrateControl)))
	{
		DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s:   SUCCESS: m_pIBitrateControl=0x%08lX", _fx_, m_pIBitrateControl));
	}
	else
	{
		m_pIBitrateControl = NULL;
		DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: Failed Hr=0x%08lX", _fx_, Hr));
	}

	// Get the frame rate control interface
	if (SUCCEEDED (Hr = pUnk->QueryInterface(__uuidof(IFrameRateControl), (void **)&m_pIFrameRateControl)))
	{
		DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s:   SUCCESS: m_pIFrameRateControl=0x%08lX", _fx_, m_pIFrameRateControl));
	}
	else
	{
		m_pIFrameRateControl = NULL;
		DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: Failed Hr=0x%08lX", _fx_, Hr));
	}

	// Get the format control interface
	if (SUCCEEDED (Hr = pUnk->QueryInterface(IID_IAMStreamConfig, (void **)&m_pIAMStreamConfig)))
	{
		DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s:   SUCCESS: m_pIAMStreamConfig=0x%08lX", _fx_, m_pIAMStreamConfig));
	}
	else
	{
		m_pIAMStreamConfig = NULL;
		DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: Failed Hr=0x%08lX", _fx_, Hr));
	}

	// Get the video control interface
	if (SUCCEEDED (Hr = pUnk->QueryInterface(__uuidof(IVideoControl), (void **)&m_pIVideoControl)))
	{
		DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s:   SUCCESS: m_pIVideoControl=0x%08lX", _fx_, m_pIVideoControl));
	}
	else
	{
		m_pIVideoControl = NULL;
		DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: Failed Hr=0x%08lX", _fx_, Hr));
	}

	// It's Ok if we couldn't get interface pointers
	// We'll just grey the controls in the property page
	// to make it clear to the user that they can't
	// control those properties on the capture device
	Hr = NOERROR;

MyExit:
	DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: end", _fx_));
	return Hr;
}

/****************************************************************************
 *  @doc INTERNAL CCAPTUREPMETHOD
 *
 *  @mfunc HRESULT | CCaptureProperties | OnDisconnect | This
 *    method is called when the property page is disconnected from the owning
 *    filter.
 *
 *  @rdesc This method returns an HRESULT value that depends on the
 *    implementation of the interface. HRESULT can include one of the
 *    following standard constants, or other values not listed:
 *
 *  @flag NOERROR | No error
 ***************************************************************************/
HRESULT CCaptureProperties::OnDisconnect()
{
	FX_ENTRY("CCaptureProperties::OnDisconnect")

	DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: begin", _fx_));

	// Validate input parameters: we seem to get called several times here
	// Make sure the interface pointer is still valid
	if (!m_pIBitrateControl)
	{
		DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   WARNING: already disconnected!", _fx_));
	}
	else
	{
		// Release the interface
		m_pIBitrateControl->Release();
		m_pIBitrateControl = NULL;
		DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s:   SUCCESS: releasing m_pIBitrateControl", _fx_));
	}

	if (!m_pIFrameRateControl)
	{
		DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   WARNING: already disconnected!", _fx_));
	}
	else
	{
		// Release the interface
		m_pIFrameRateControl->Release();
		m_pIFrameRateControl = NULL;
		DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s:   SUCCESS: releasing m_pIFrameRateControl", _fx_));
	}

	if (!m_pIAMStreamConfig)
	{
		DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   WARNING: already disconnected!", _fx_));
	}
	else
	{
		// Release the interface
		m_pIAMStreamConfig->Release();
		m_pIAMStreamConfig = NULL;
		DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s:   SUCCESS: releasing m_pIAMStreamConfig", _fx_));
	}

	if (!m_pIVideoControl)
	{
		DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   WARNING: already disconnected!", _fx_));
	}
	else
	{
		// Release the interface
		m_pIVideoControl->Release();
		m_pIVideoControl = NULL;
		DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s:   SUCCESS: releasing m_pIVideoControl", _fx_));
	}

	// Release format memory
	if (m_CurrentMediaType)
	{
		DeleteMediaType(m_CurrentMediaType);
		m_CurrentMediaType = NULL;
	}

	if (m_SubTypeList)
		delete[] m_SubTypeList, m_SubTypeList = NULL;

	if (m_FrameSizeList)
		delete[] m_FrameSizeList, m_FrameSizeList = NULL;

	DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: end", _fx_));
	return NOERROR;
}

/****************************************************************************
 *  @doc INTERNAL CCAPTUREPMETHOD
 *
 *  @mfunc HRESULT | CCaptureProperties | OnActivate | This
 *    method is called when the property page is activated.
 *
 *  @rdesc This method returns an HRESULT value that depends on the
 *    implementation of the interface. HRESULT can include one of the
 *    following standard constants, or other values not listed:
 *
 *  @flag E_FAIL | Failure
 *  @flag E_POINTER | Null pointer argument
 *  @flag E_NOTIMPL | Method is not supported
 *  @flag NOERROR | No error
 ***************************************************************************/
HRESULT CCaptureProperties::OnActivate()
{
	HRESULT	Hr = NOERROR;
	int		j;
	TCHAR	buf[32];

	FX_ENTRY("CCaptureProperties::OnActivate")

	DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: begin", _fx_));

	// Initialize format control structures
	m_hWndFormat = GetDlgItem(m_hWnd, IDC_FORMAT_Compression);

	// Disable everything if we didn't initialize correctly
	if (!m_pIAMStreamConfig || (FAILED (Hr = InitialRangeScan())))
	{
		EnableWindow(m_hWndFormat, FALSE);
	}
	else
	{
		// Update the content of the format combo box
		ComboBox_ResetContent(m_hWndFormat);
		for (j = 0; j < m_RangeCount; j++)
		{
			if (IsEqualGUID(m_SubTypeList[j], MEDIASUBTYPE_H263_V1))
				wsprintf (buf, "%s %ldx%ld", "H.263", m_FrameSizeList[j].cx, m_FrameSizeList[j].cy);
			else if (IsEqualGUID (m_SubTypeList[j], MEDIASUBTYPE_H263_V2))
				wsprintf (buf, "%s %ldx%ld", "H.263+", m_FrameSizeList[j].cx, m_FrameSizeList[j].cy);
			else if (IsEqualGUID (m_SubTypeList[j], MEDIASUBTYPE_H261))
				wsprintf (buf, "%s %ldx%ld", "H.261", m_FrameSizeList[j].cx, m_FrameSizeList[j].cy);
			else if (IsEqualGUID (m_SubTypeList[j], MEDIASUBTYPE_YVU9))
				wsprintf (buf, "%s %ldx%ld", "YVU9", m_FrameSizeList[j].cx, m_FrameSizeList[j].cy);
			else if (IsEqualGUID (m_SubTypeList[j], MEDIASUBTYPE_YUY2))
				wsprintf (buf, "%s %ldx%ld", "YUY2", m_FrameSizeList[j].cx, m_FrameSizeList[j].cy);
			else if (IsEqualGUID (m_SubTypeList[j], MEDIASUBTYPE_YVYU))
				wsprintf (buf, "%s %ldx%ld", "YVYU", m_FrameSizeList[j].cx, m_FrameSizeList[j].cy);
			else if (IsEqualGUID (m_SubTypeList[j], MEDIASUBTYPE_UYVY))
				wsprintf (buf, "%s %ldx%ld", "UYVY", m_FrameSizeList[j].cx, m_FrameSizeList[j].cy);
			else if (IsEqualGUID (m_SubTypeList[j], MEDIASUBTYPE_YV12))
				wsprintf (buf, "%s %ldx%ld", "YV12", m_FrameSizeList[j].cx, m_FrameSizeList[j].cy);
			else if (IsEqualGUID (m_SubTypeList[j], MEDIASUBTYPE_I420))
				wsprintf (buf, "%s %ldx%ld", "I420", m_FrameSizeList[j].cx, m_FrameSizeList[j].cy);
			else if (IsEqualGUID (m_SubTypeList[j], MEDIASUBTYPE_IYUV))
				wsprintf (buf, "%s %ldx%ld", "IYUV", m_FrameSizeList[j].cx, m_FrameSizeList[j].cy);
			else if (IsEqualGUID (m_SubTypeList[j], MEDIASUBTYPE_YV12))
				wsprintf (buf, "%s %ldx%ld", "YV12", m_FrameSizeList[j].cx, m_FrameSizeList[j].cy);
			else if (IsEqualGUID (m_SubTypeList[j], MEDIASUBTYPE_RGB4))
				wsprintf (buf, "%s %ldx%ld", "RGB4", m_FrameSizeList[j].cx, m_FrameSizeList[j].cy);
			else if (IsEqualGUID (m_SubTypeList[j], MEDIASUBTYPE_RGB8))
				wsprintf (buf, "%s %ldx%ld", "RGB8", m_FrameSizeList[j].cx, m_FrameSizeList[j].cy);
			else if (IsEqualGUID (m_SubTypeList[j], MEDIASUBTYPE_RGB555))
				wsprintf (buf, "%s %ldx%ld", "RGB16", m_FrameSizeList[j].cx, m_FrameSizeList[j].cy);
			else if (IsEqualGUID (m_SubTypeList[j], MEDIASUBTYPE_RGB565))
				wsprintf (buf, "%s %ldx%ld", "RGB16", m_FrameSizeList[j].cx, m_FrameSizeList[j].cy);
			else if (IsEqualGUID (m_SubTypeList[j], MEDIASUBTYPE_RGB24))
				wsprintf (buf, "%s %ldx%ld", "RGB24", m_FrameSizeList[j].cx, m_FrameSizeList[j].cy);
			else if (IsEqualGUID (m_SubTypeList[j], MEDIASUBTYPE_UYVY))
				wsprintf (buf, "%s %ldx%ld", "UYVY", m_FrameSizeList[j].cx, m_FrameSizeList[j].cy);
			else
				wsprintf (buf, "%s %ldx%ld", "Unknown", m_FrameSizeList[j].cx, m_FrameSizeList[j].cy);

			ComboBox_AddString(m_hWndFormat, buf);

			if (m_CurrentMediaType->subtype == m_SubTypeList[j] && HEADER(m_CurrentMediaType->pbFormat)->biWidth == m_FrameSizeList[j].cx  && HEADER(m_CurrentMediaType->pbFormat)->biHeight == m_FrameSizeList[j].cy)
			{
				ComboBox_SetCurSel(m_hWndFormat, j);
				m_SubTypeCurrent = m_SubTypeList[j];
				m_FrameSizeCurrent = m_FrameSizeList[j];
			}
		}

		// Update current format
		OnFormatChanged();

		// Remember the original format
		m_OriginalFormat = m_CurrentFormat;
	}

	// Create the controls for the properties
	if (m_Controls[0] = new CCaptureProperty(m_hwnd, IDC_BitrateControl_Label, IDC_BitrateControl_Minimum, IDC_BitrateControl_Maximum, IDC_BitrateControl_Default, IDC_BitrateControl_Stepping, IDC_BitrateControl_Edit, IDC_BitrateControl_Slider, 0, IDC_Capture_Bitrate, m_pIBitrateControl, m_pIFrameRateControl, m_pIVideoControl))
	{
		DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s:   SUCCESS: m_Controls[0]=0x%08lX", _fx_, m_Controls[0]));

		if (m_Controls[1] = new CCaptureProperty(m_hwnd, IDC_FrameRateControl_Label, IDC_FrameRateControl_Minimum, IDC_FrameRateControl_Maximum, IDC_FrameRateControl_Default, IDC_FrameRateControl_Stepping, IDC_FrameRateControl_Edit, IDC_FrameRateControl_Slider, 0, IDC_Capture_FrameRate, m_pIBitrateControl, m_pIFrameRateControl, m_pIVideoControl))
		{
			DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s:   SUCCESS: m_Controls[1]=0x%08lX", _fx_, m_Controls[1]));

			if (m_Controls[2] = new CCaptureProperty(m_hwnd, 0, 0, 0, 0, 0, IDC_FORMAT_FlipVertical, 0, 0, IDC_Capture_FlipVertical, m_pIBitrateControl, m_pIFrameRateControl, m_pIVideoControl))
			{
				DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s:   SUCCESS: m_Controls[2]=0x%08lX", _fx_, m_Controls[2]));

				if (m_Controls[3] = new CCaptureProperty(m_hwnd, 0, 0, 0, 0, 0, IDC_FORMAT_FlipHorizontal, 0, 0, IDC_Capture_FlipHorizontal, m_pIBitrateControl, m_pIFrameRateControl, m_pIVideoControl))
				{
					DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s:   SUCCESS: m_Controls[3]=0x%08lX", _fx_, m_Controls[3]));

					if (m_Controls[4] = new CCaptureProperty(m_hwnd, 0, 0, 0, 0, 0, IDC_FrameRateControl_Actual, 0, IDC_FrameRateControl_Meter, IDC_Capture_CurrentFrameRate, m_pIBitrateControl, m_pIFrameRateControl, m_pIVideoControl))
					{
						DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s:   SUCCESS: m_Controls[4]=0x%08lX", _fx_, m_Controls[4]));

						if (m_Controls[5] = new CCaptureProperty(m_hwnd, 0, 0, 0, 0, 0, IDC_BitrateControl_Actual, 0, IDC_BitrateControl_Meter, IDC_Capture_CurrentBitrate, m_pIBitrateControl, m_pIFrameRateControl, m_pIVideoControl))
						{
							DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s:   SUCCESS: m_Controls[5]=0x%08lX", _fx_, m_Controls[5]));
						}
						else
						{
							DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: Out of memory", _fx_));
							delete m_Controls[0], m_Controls[0] = NULL;
							delete m_Controls[1], m_Controls[1] = NULL;
							delete m_Controls[2], m_Controls[2] = NULL;
							delete m_Controls[3], m_Controls[3] = NULL;
							delete m_Controls[4], m_Controls[4] = NULL;
							Hr = E_OUTOFMEMORY;
							goto MyExit;
						}
					}
					else
					{
						DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: Out of memory", _fx_));
						delete m_Controls[0], m_Controls[0] = NULL;
						delete m_Controls[1], m_Controls[1] = NULL;
						delete m_Controls[2], m_Controls[2] = NULL;
						delete m_Controls[3], m_Controls[3] = NULL;
						Hr = E_OUTOFMEMORY;
						goto MyExit;
					}
				}
				else
				{
					DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: Out of memory", _fx_));
					delete m_Controls[0], m_Controls[0] = NULL;
					delete m_Controls[1], m_Controls[1] = NULL;
					delete m_Controls[2], m_Controls[2] = NULL;
					Hr = E_OUTOFMEMORY;
					goto MyExit;
				}
			}
			else
			{
				DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: Out of memory", _fx_));
				delete m_Controls[0], m_Controls[0] = NULL;
				delete m_Controls[1], m_Controls[1] = NULL;
				Hr = E_OUTOFMEMORY;
				goto MyExit;
			}
		}
		else
		{
			DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: Out of memory", _fx_));
			delete m_Controls[0], m_Controls[0] = NULL;
			Hr = E_OUTOFMEMORY;
			goto MyExit;
		}
	}
	else
	{
		DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: Out of memory", _fx_));
		Hr = E_OUTOFMEMORY;
		goto MyExit;
	}

	// Initialize all the controls. If the initialization fails, it's Ok. It just means
	// that the TAPI control interface isn't implemented by the device. The dialog item
	// in the property page will be greyed, showing this to the user.
	for (j = 0; j < m_NumProperties; j++)
	{
		if (m_Controls[j]->Init())
		{
			DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s:   SUCCESS: m_Controls[%ld]->Init()", _fx_, j));
		}
		else
		{
			DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   WARNING: m_Controls[%ld]->Init() failed", _fx_, j));
		}
	}

MyExit:
	DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: end", _fx_));
	m_fActivated = TRUE;
	return Hr;
}

/****************************************************************************
 *  @doc INTERNAL CCAPTUREPMETHOD
 *
 *  @mfunc HRESULT | CCaptureProperties | OnDeactivate | This
 *    method is called when the property page is dismissed.
 *
 *  @rdesc This method returns an HRESULT value that depends on the
 *    implementation of the interface. HRESULT can include one of the
 *    following standard constants, or other values not listed:
 *
 *  @flag NOERROR | No error
 ***************************************************************************/
HRESULT CCaptureProperties::OnDeactivate()
{
	int	j;

	FX_ENTRY("CCaptureProperties::OnDeactivate")

	DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: begin", _fx_));

	// Free the controls
	for (j = 0; j < m_NumProperties; j++)
	{
		if (m_Controls[j])
		{
			DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s:   SUCCESS: deleting m_Controls[%ld]=0x%08lX", _fx_, j, m_Controls[j]));
			delete m_Controls[j], m_Controls[j] = NULL;
		}
		else
		{
			DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   WARNING: control already freed", _fx_));
		}
	}

	DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: end", _fx_));
	return NOERROR;
}

/****************************************************************************
 *  @doc INTERNAL CCAPTUREPMETHOD
 *
 *  @mfunc HRESULT | CCaptureProperties | GetCurrentMediaType | This
 *    method is used to retrieve the current media format used by the pin.
 *
 *  @rdesc This method returns an HRESULT value that depends on the
 *    implementation of the interface. HRESULT can include one of the
 *    following standard constants, or other values not listed:
 *
 *  @flag NOERROR | No error
 ***************************************************************************/
HRESULT CCaptureProperties::GetCurrentMediaType(void)
{
	HRESULT Hr = NOERROR;

	FX_ENTRY("CCaptureProperties::GetCurrentMediaType")

	DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: begin", _fx_));

	if (m_CurrentMediaType)
	{
		DeleteMediaType (m_CurrentMediaType);
		m_CurrentMediaType = NULL;
	}

	if (FAILED (Hr = m_pIAMStreamConfig->GetFormat((AM_MEDIA_TYPE **)&m_CurrentMediaType)))
	{
		// Otherwise, just get the first enumerated media type
		VIDEO_STREAM_CONFIG_CAPS RangeCaps;

		if (FAILED (Hr = m_pIAMStreamConfig->GetStreamCaps(0, (AM_MEDIA_TYPE **)&m_CurrentMediaType, (BYTE *)&RangeCaps)))
		{
			m_CurrentMediaType = NULL;
		}
	}

	DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: end", _fx_));

	return Hr;
}

/****************************************************************************
 *  @doc INTERNAL CCAPTUREPMETHOD
 *
 *  @mfunc HRESULT | CCaptureProperties | OnFormatChanged | This
 *    method is used to retrieve the format selected by the user.
 *
 *  @rdesc This method returns an HRESULT value that depends on the
 *    implementation of the interface. HRESULT can include one of the
 *    following standard constants, or other values not listed:
 *
 *  @flag NOERROR | No error
 ***************************************************************************/
HRESULT CCaptureProperties::OnFormatChanged()
{
	HRESULT	Hr = E_UNEXPECTED;
	int		j;

	FX_ENTRY("CCaptureProperties::OnFormatChanged")

	DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: begin", _fx_));

	if (!m_pIAMStreamConfig)
	{
		Hr = E_INVALIDARG;
		goto MyExit;
	}

	// Associate the current compression index with the right range index
	m_CurrentFormat = ComboBox_GetCurSel(m_hWndFormat);
	ASSERT (m_CurrentFormat >= 0 && m_CurrentFormat < m_RangeCount);
	if (m_CurrentFormat >= 0 && m_CurrentFormat < m_RangeCount)
	{
		m_SubTypeCurrent = m_SubTypeList[m_CurrentFormat];
		m_FrameSizeCurrent = m_FrameSizeList[m_CurrentFormat];

		for (j = 0; j < m_RangeCount; j++)
		{
			if (m_SubTypeList[j] == m_SubTypeCurrent)
			{
				CMediaType *pmt = NULL;

				Hr = m_pIAMStreamConfig->GetStreamCaps(j, (AM_MEDIA_TYPE **)&pmt, (BYTE *)&m_RangeCaps);

				DeleteMediaType (pmt);
			}
		}
	}

MyExit:
	DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: end", _fx_));
	return Hr;
}

/****************************************************************************
 *  @doc INTERNAL CCAPTUREPMETHOD
 *
 *  @mfunc HRESULT | CCaptureProperties | InitialRangeScan | This
 *    method is used to retrieve the list of supported formats on the pin.
 *
 *  @rdesc This method returns an HRESULT value that depends on the
 *    implementation of the interface. HRESULT can include one of the
 *    following standard constants, or other values not listed:
 *
 *  @flag NOERROR | No error
 ***************************************************************************/
HRESULT CCaptureProperties::InitialRangeScan()
{
	HRESULT			Hr = NOERROR;
	int				lSize;
	int				j;
	AM_MEDIA_TYPE	*pmt = NULL;

	FX_ENTRY("CCaptureProperties::InitialRangeScan")

	DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: begin", _fx_));

	if (!m_pIAMStreamConfig)
	{
		Hr = E_INVALIDARG;
		goto MyExit;
	}

	Hr = m_pIAMStreamConfig->GetNumberOfCapabilities(&m_RangeCount, &lSize);
	ASSERT (lSize >= sizeof (VIDEO_STREAM_CONFIG_CAPS) && SUCCEEDED (Hr));
	if (lSize < sizeof (VIDEO_STREAM_CONFIG_CAPS) || !SUCCEEDED(Hr))
	{
		Hr = E_FAIL;
		goto MyExit;
	}

	DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s:   NumberOfRanges=%d", _fx_, m_RangeCount));

	if (!(m_SubTypeList = new GUID [m_RangeCount]))
	{
		DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s: ERROR: new failed", _fx_));
		Hr = E_OUTOFMEMORY;
		goto MyExit;
	}

	if (!(m_FrameSizeList = new SIZE [m_RangeCount]))
	{
		DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s: ERROR: new failed", _fx_));
		Hr = E_OUTOFMEMORY;
		goto MyExit;
	}

	for (j = 0; j < m_RangeCount; j++)
	{
		pmt = NULL;

		Hr = m_pIAMStreamConfig->GetStreamCaps(j, (AM_MEDIA_TYPE **)&pmt, (BYTE *)&m_RangeCaps);

		ASSERT(SUCCEEDED (Hr));
		ASSERT(pmt);
		ASSERT(pmt->majortype == MEDIATYPE_Video);
		ASSERT(pmt->formattype == FORMAT_VideoInfo);

		m_SubTypeList[j] = pmt->subtype;
		m_FrameSizeList[j].cx = HEADER(pmt->pbFormat)->biWidth;
		m_FrameSizeList[j].cy = HEADER(pmt->pbFormat)->biHeight;

		DeleteMediaType(pmt);
	}

	// Get default format
	Hr = GetCurrentMediaType();

MyExit:
	DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: end", _fx_));
	return Hr;
}

/****************************************************************************
 *  @doc INTERNAL CCAPTUREPMETHOD
 *
 *  @mfunc HRESULT | CCaptureProperties | OnApplyChanges | This
 *    method is called when the user applies changes to the property page.
 *
 *  @rdesc This method returns an HRESULT value that depends on the
 *    implementation of the interface. HRESULT can include one of the
 *    following standard constants, or other values not listed:
 *
 *  @flag E_FAIL | Failure
 *  @flag E_POINTER | Null pointer argument
 *  @flag E_NOTIMPL | Method is not supported
 *  @flag NOERROR | No error
 ***************************************************************************/
HRESULT CCaptureProperties::OnApplyChanges()
{
	HRESULT	Hr = NOERROR;
	int		j;
	CMediaType *pmt = NULL;

	FX_ENTRY("CCaptureProperties::OnApplyChanges")

	DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: begin", _fx_));

	// Apply format changes on video stream
	m_CurrentFormat = ComboBox_GetCurSel(m_hWndFormat);
	
	// Only apply change if the format is different
	if (m_CurrentFormat != m_OriginalFormat)
	{
		if (SUCCEEDED (Hr = m_pIAMStreamConfig->GetStreamCaps(m_CurrentFormat, (AM_MEDIA_TYPE **) &pmt, (BYTE *)&m_RangeCaps)))
		{
			ASSERT(pmt && *pmt->FormatType() == FORMAT_VideoInfo);

			if (pmt && *pmt->FormatType() == FORMAT_VideoInfo)
			{
				if (FAILED(Hr = m_pIAMStreamConfig->SetFormat(pmt)))
				{
					TCHAR TitleBuf[80];
					TCHAR TextBuf[80];

					LoadString(g_hInst, IDS_ERROR_CONNECTING_TITLE, TitleBuf, sizeof (TitleBuf));
					LoadString(g_hInst, IDS_ERROR_CONNECTING, TextBuf, sizeof (TextBuf));
					MessageBox (NULL, TextBuf, TitleBuf, MB_OK);
				}
			}

			// Free some memory that was allocated by GetStreamCaps
			if (pmt)
				DeleteMediaType(pmt);

			// Update our copy of the current format
			GetCurrentMediaType();
		}
	}

	// Apply target bitrate and target frame rate changes on video stream
	for (j = 0; j < m_NumProperties; j++)
	{
		ASSERT(m_Controls[j]);
		if (m_Controls[j])
		{
			DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s:   SUCCESS: calling m_Controls[%ld]=0x%08lX->OnApply", _fx_, j, m_Controls[j]));
			if (m_Controls[j]->HasChanged())
				m_Controls[j]->OnApply();
			Hr = NOERROR;
		}
		else
		{
			DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: can't calling m_Controls[%ld]=NULL->OnApply", _fx_, j));
			Hr = E_UNEXPECTED;
		}
	}

	DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: end", _fx_));
	return Hr;
}

/****************************************************************************
 *  @doc INTERNAL CCAPTUREPMETHOD
 *
 *  @mfunc BOOL | CCaptureProperties | OnReceiveMessage | This
 *    method is called when a message is sent to the property page dialog box.
 *
 *  @rdesc By default, returns the value returned by the Win32 DefWindowProc function.
 ***************************************************************************/
BOOL CCaptureProperties::OnReceiveMessage(HWND hWnd, UINT uMsg, WPARAM wParam, LPARAM lParam) 
{
	int iNotify = HIWORD (wParam);
	int j;

	switch (uMsg)
	{
		case WM_INITDIALOG:
			// This is called before Activate...
			m_hWnd = hWnd;
			return TRUE; // Don't call setfocus

		case WM_TIMER:
			if (m_fActivated)
			{
				// Update the Vu-Meters
				for (j = 0; j < m_NumProperties; j++)
				{
					ASSERT(m_Controls[j]);
					if (m_Controls[j]->GetProgressHWnd())
					{
						m_Controls[j]->UpdateProgress();
						SetDirty();
					}
				}
			}
			break;

		case WM_HSCROLL:
		case WM_VSCROLL:
			if (m_fActivated)
			{
				// Process all of the Trackbar messages
				for (j = 0; j < m_NumProperties; j++)
				{
					ASSERT(m_Controls[j]);
					if (m_Controls[j]->GetTrackbarHWnd() == (HWND)lParam)
					{
						m_Controls[j]->OnScroll(uMsg, wParam, lParam);
						SetDirty();
					}
				}
			}
			break;

		case WM_COMMAND:

			// This message gets sent even before OnActivate() has been
			// called(!). We need to test and make sure the controls have
			// beeen initialized before we can use them.
			if (m_fActivated)
			{
				// Process all of the edit box messages
				for (j = 0; j < m_NumProperties; j++)
				{
					if (m_Controls[j] && m_Controls[j]->GetEditHWnd() == (HWND)lParam)
					{
						m_Controls[j]->OnEdit(uMsg, wParam, lParam);
						SetDirty();
						break;
					}
				}

				switch (LOWORD(wParam))
				{
					case IDC_CONTROL_DEFAULT:
						for (j = 0; j < m_NumProperties; j++)
						{
							if (m_Controls[j])
								m_Controls[j]->OnDefault();
						}
						break;

					case IDC_FORMAT_Compression:
						if (HIWORD(wParam) == CBN_SELCHANGE)
						{
							OnFormatChanged();
						}
						break;

					default:
						break;
				}
			}
			break;

		default:
			return FALSE;
	}

	return TRUE;
}

/****************************************************************************
 *  @doc INTERNAL CCAPTUREPMETHOD
 *
 *  @mfunc BOOL | CCaptureProperties | SetDirty | This
 *    method notifies the property page site of changes.
 *
 *  @rdesc Nada.
 ***************************************************************************/
void CCaptureProperties::SetDirty()
{
	m_bDirty = TRUE;
	if (m_pPageSite)
		m_pPageSite->OnStatusChange(PROPPAGESTATUS_DIRTY);
}

#endif
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\net\tapi\skywalker\filters\video\tapivcap\cpucp.cpp ===
/****************************************************************************
 *  @doc INTERNAL CPUCP
 *
 *  @module CPUCP.cpp | Source ile for the <c CCPUCProperty>
 *    class used to implement a property page to test the new TAPI internal
 *    interface <i ICPUControl>.
 *
 *  @comm This code tests the TAPI VfW Output Pins <i ICPUControl>
 *    implementation. This code is only compiled if USE_PROPERTY_PAGES is
 *    defined.
 ***************************************************************************/

#include "Precomp.h"

#ifdef USE_PROPERTY_PAGES

#ifdef USE_CPU_CONTROL

/****************************************************************************
 *  @doc INTERNAL CCPUCPMETHOD
 *
 *  @mfunc void | CCPUCProperty | CCPUCProperty | This
 *    method is the constructor for bitrate and frame rate property objects. It
 *    calls the base class constructor, calls InitCommonControlsEx, and saves
 *    pointers to the <i ICPUControl> and <i IFrameRateControl> interfaces.
 *
 *  @parm HWND | hDlg | Specifies a handle to the parent property page.
 *
 *  @parm ULONG | IDLabel | Specifies a label ID for the property.
 *
 *  @parm ULONG | IDMinControl | Specifies a label ID for the associated
 *    property edit control where the Minimum value of the property appears.
 *
 *  @parm ULONG | IDMaxControl | Specifies a label ID for the associated
 *    property edit control where the Maximum value of the property appears.
 *
 *  @parm ULONG | IDDefaultControl | Specifies a label ID for the associated
 *    property edit control where the Default value of the property appears.
 *
 *  @parm ULONG | IDStepControl | Specifies a label ID for the associated
 *    property edit control where the Stepping Delta value of the property appears.
 *
 *  @parm ULONG | IDEditControl | Specifies a label ID for the associated
 *    property edit control where the value of the property appears.
 *
 *  @parm ULONG | IDTrackbarControl | Specifies a label ID for the associated
 *    property slide bar.
 *
 *  @parm ULONG | IDProgressControl | Specifies a label ID for the associated
 *    property slide bar.
 *
 *  @parm ULONG | IDProperty | Specifies the ID of the Ks property.
 *
 *  @parm ICPUControl* | pICPUControl | Specifies a pointer to the
 *    <i ICPUControl> interface.
 *
 *  @parm IFrameRateControl* | pIFrameRateControl | Specifies a pointer to the
 *    <i IFrameRateControl> interface.
 *
 *  @rdesc Nada.
 ***************************************************************************/
CCPUCProperty::CCPUCProperty(HWND hDlg, ULONG IDLabel, ULONG IDMinControl, ULONG IDMaxControl, ULONG IDDefaultControl, ULONG IDStepControl, ULONG IDEditControl, ULONG IDTrackbarControl, ULONG IDProgressControl, ULONG IDProperty, ICPUControl *pICPUControl)
: CKSPropertyEditor(hDlg, IDLabel, IDMinControl, IDMaxControl, IDDefaultControl, IDStepControl, IDEditControl, IDTrackbarControl, IDProgressControl, IDProperty, 0)
{
	INITCOMMONCONTROLSEX cc;

	FX_ENTRY("CCPUCProperty::CCPUCProperty")

	DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: begin", _fx_));

	cc.dwSize = sizeof (INITCOMMONCONTROLSEX);
	cc.dwICC  = ICC_UPDOWN_CLASS | ICC_BAR_CLASSES;

	InitCommonControlsEx(&cc);

	// It's fine if the interface pointer is NULL, we'll grey the
	// associated items in the property page
	m_pICPUControl = pICPUControl;

	DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: end", _fx_));
}

/****************************************************************************
 *  @doc INTERNAL CCPUCPMETHOD
 *
 *  @mfunc void | CCPUCProperty | ~CCPUCProperty | This
 *    method is the destructor for CPU control property objects. It
 *    simply calls the base class destructor.
 *
 *  @rdesc Nada.
 ***************************************************************************/
CCPUCProperty::~CCPUCProperty()
{
	FX_ENTRY("CCPUCProperty::~CCPUCProperty")

	DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: begin", _fx_));

	DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: end", _fx_));
}

/****************************************************************************
 *  @doc INTERNAL CCPUCPMETHOD
 *
 *  @mfunc HRESULT | CCPUCProperty | GetValue | This method queries for
 *    the value of a property.
 *
 *  @rdesc This method returns an HRESULT value that depends on the
 *    implementation of the interface. HRESULT can include one of the
 *    following standard constants, or other values not listed:
 *
 *  @flag E_FAIL | Failure
 *  @flag E_POINTER | Null pointer argument
 *  @flag E_NOTIMPL | Method is not supported
 *  @flag NOERROR | No error
 ***************************************************************************/
HRESULT CCPUCProperty::GetValue()
{
	HRESULT Hr = E_NOTIMPL;
	REFERENCE_TIME CurrentValue;

	FX_ENTRY("CCPUCProperty::GetValue")

	DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: begin", _fx_));

	switch (m_IDProperty)
	{									
		case IDC_CPUC_MaxCPULoad:
			if (m_pICPUControl && SUCCEEDED (Hr = m_pICPUControl->GetMaxCPULoad((LPDWORD)&m_CurrentValue, 0)))
			{
				DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s:   SUCCESS: *pdwMaxCPULoad=%ld", _fx_, m_CurrentValue));
			}
			else
			{
				DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: Failed Hr=0x%08lX", _fx_, Hr));
			}
			break;
		case IDC_CPUC_MaxProcessingTime:
			if (m_pICPUControl && SUCCEEDED (Hr = m_pICPUControl->GetMaxProcessingTime(&CurrentValue, 0)))
			{
				m_CurrentValue = (LONG)CurrentValue;
				DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s:   SUCCESS: *pMaxProcessingTime=%ld", _fx_, CurrentValue));
			}
			else
			{
				DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: Failed Hr=0x%08lX", _fx_, Hr));
			}
			break;
		case IDC_CPUC_CurrentCPULoad:
			if (m_pICPUControl && SUCCEEDED (Hr = m_pICPUControl->GetCurrentCPULoad((LPDWORD)&m_CurrentValue)))
			{
				DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s:   SUCCESS: *pdwCurrentCPULoad=%ld", _fx_, m_CurrentValue));
			}
			else
			{
				DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: Failed Hr=0x%08lX", _fx_, Hr));
			}
			break;
		case IDC_CPUC_CurrentProcessingTime:
			if (m_pICPUControl && SUCCEEDED (Hr = m_pICPUControl->GetCurrentProcessingTime(&CurrentValue)))
			{
				m_CurrentValue = (LONG)CurrentValue;
				DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s:   SUCCESS: *pCurrentProcessingTime=%ld", _fx_, CurrentValue));
			}
			else
			{
				DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: Failed Hr=0x%08lX", _fx_, Hr));
			}
			break;
		default:
			Hr = E_UNEXPECTED;
			DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: Unknown CPU control property", _fx_));
	}

	DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: end", _fx_));
	return Hr;
}

/****************************************************************************
 *  @doc INTERNAL CCPUCPMETHOD
 *
 *  @mfunc HRESULT | CCPUCProperty | SetValue | This method sets the
 *    value of a property.
 *
 *  @rdesc This method returns an HRESULT value that depends on the
 *    implementation of the interface. HRESULT can include one of the
 *    following standard constants, or other values not listed:
 *
 *  @flag E_FAIL | Failure
 *  @flag E_POINTER | Null pointer argument
 *  @flag E_NOTIMPL | Method is not supported
 *  @flag NOERROR | No error
 ***************************************************************************/
HRESULT CCPUCProperty::SetValue()
{
	HRESULT Hr = E_NOTIMPL;

	FX_ENTRY("CCPUCProperty::SetValue")

	DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: begin", _fx_));

	switch (m_IDProperty)
	{
		case IDC_CPUC_MaxCPULoad:
			if (m_pICPUControl && SUCCEEDED (Hr = m_pICPUControl->SetMaxCPULoad((DWORD)m_CurrentValue)))
			{
				DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s:   SUCCESS: dwMaxCPULoad=%ld", _fx_, m_CurrentValue));
			}
			else
			{
				DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: Failed Hr=0x%08lX", _fx_, Hr));
			}
			break;
		case IDC_CPUC_MaxProcessingTime:
			if (m_pICPUControl && SUCCEEDED (Hr = m_pICPUControl->SetMaxProcessingTime((REFERENCE_TIME)m_CurrentValue)))
			{
				DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s:   SUCCESS: MaxProcessingTime=%ld", _fx_, m_CurrentValue));
			}
			else
			{
				DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: Failed Hr=0x%08lX", _fx_, Hr));
			}
			break;
		case IDC_CPUC_CurrentCPULoad:
		case IDC_CPUC_CurrentProcessingTime:
			// This is a read-only property. Don't do anything.
			Hr = NOERROR;
			break;
		default:
			Hr = E_UNEXPECTED;
			DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: Unknown CPU control property", _fx_));
	}

	DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: end", _fx_));
	return Hr;
}

/****************************************************************************
 *  @doc INTERNAL CCPUCPMETHOD
 *
 *  @mfunc HRESULT | CCPUCProperty | GetRange | This method retrieves
 *    the range information of a property.
 *
 *  @rdesc This method returns an HRESULT value that depends on the
 *    implementation of the interface. HRESULT can include one of the
 *    following standard constants, or other values not listed:
 *
 *  @flag E_FAIL | Failure
 *  @flag E_POINTER | Null pointer argument
 *  @flag E_NOTIMPL | Method is not supported
 *  @flag NOERROR | No error
 ***************************************************************************/
HRESULT CCPUCProperty::GetRange()
{
	HRESULT Hr = E_NOTIMPL;
	REFERENCE_TIME Min;
	REFERENCE_TIME Max;
	REFERENCE_TIME SteppingDelta;
	REFERENCE_TIME Default;

	FX_ENTRY("CCPUCProperty::GetRange")

	DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: begin", _fx_));

	switch (m_IDProperty)
	{
		case IDC_CPUC_CurrentCPULoad:
		case IDC_CPUC_MaxCPULoad:
			if (m_pICPUControl && SUCCEEDED (Hr = m_pICPUControl->GetMaxCPULoadRange((LPDWORD)&m_Min, (LPDWORD)&m_Max, (LPDWORD)&m_SteppingDelta, (LPDWORD)&m_DefaultValue, 0UL)))
			{
				DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s:   SUCCESS: *pdwMin=%ld, *pdwMax=%ld, *pdwSteppingDelta=%ld, *pdwDefault=%ld", _fx_, m_Min, m_Max, m_SteppingDelta, m_DefaultValue));
			}
			else
			{
				DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: Failed Hr=0x%08lX", _fx_, Hr));
			}
			break;
		case IDC_CPUC_CurrentProcessingTime:
		case IDC_CPUC_MaxProcessingTime:
			if (m_pICPUControl && SUCCEEDED (Hr = m_pICPUControl->GetMaxProcessingTimeRange(&Min, &Max, &SteppingDelta, &Default, 0UL)))
			{
				m_Min = (LONG)Min;
				m_Max = (LONG)Max;
				m_SteppingDelta = (LONG)SteppingDelta;
				m_DefaultValue = (LONG)Default;
				DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s:   SUCCESS: *pMin=%ld, *pMax=%ld, *pSteppingDelta=%ld, *pDefault=%ld", _fx_, Min, Max, SteppingDelta, Default));
			}
			else
			{
				DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: Failed Hr=0x%08lX", _fx_, Hr));
			}
			break;
		default:
			Hr = E_UNEXPECTED;
			DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: Unknown CPU control property", _fx_));
	}

	DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: end", _fx_));
	return Hr;
}

/****************************************************************************
 *  @doc INTERNAL CCPUCPMETHOD
 *
 *  @mfunc HRESULT | CCPUCProperty | CanAutoControl | This method
 *    retrieves the automatic control capabilities for a property.
 *
 *  @rdesc This method returns TRUE if automatic control is supported, FALSE
 *    otherwise.
 ***************************************************************************/
BOOL CCPUCProperty::CanAutoControl(void)
{
	FX_ENTRY("CCPUCProperty::CanAutoControl")

	DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: begin", _fx_));

	DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: end", _fx_));

	return FALSE;
}

/****************************************************************************
 *  @doc INTERNAL CCPUCPMETHOD
 *
 *  @mfunc HRESULT | CCPUCProperty | GetAuto | This method
 *    retrieves the current automatic control mode of a property.
 *
 *  @rdesc This method returns TRUE if automatic control is supported, FALSE
 *    otherwise.
 ***************************************************************************/
BOOL CCPUCProperty::GetAuto(void)
{
	FX_ENTRY("CCPUCProperty::GetAuto")

	DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: begin", _fx_));

	DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: end", _fx_));

	return FALSE; 
}

/****************************************************************************
 *  @doc INTERNAL CCPUCPMETHOD
 *
 *  @mfunc HRESULT | CCPUCProperty | SetAuto | This method
 *    sets the automatic control mode of a property.
 *
 *  @parm BOOL | fAuto | Specifies the automatic control mode.
 *
 *  @rdesc This method returns TRUE.
 ***************************************************************************/
BOOL CCPUCProperty::SetAuto(BOOL fAuto)
{
	FX_ENTRY("CCPUCProperty::SetAuto")

	DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: begin", _fx_));

	DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: end", _fx_));

	return TRUE; 
}

/****************************************************************************
 *  @doc INTERNAL CCPUCPMETHOD
 *
 *  @mfunc CUnknown* | CCPUCProperties | CreateInstance | This
 *    method is called by DShow to create an instance of a TAPI CPU Control
 *    Property Page. It is referred to in the global structure <t g_Templates>.
 *
 *  @parm LPUNKNOWN | pUnkOuter | Specifies the outer unknown, if any.
 *
 *  @parm HRESULT* | pHr | Specifies the place in which to put any error return.
 *
 *  @rdesc Returns a pointer to the nondelegating CUnknown portion of the
 *    object, or NULL otherwise.
 ***************************************************************************/
CUnknown* CALLBACK CCPUCPropertiesCreateInstance(LPUNKNOWN pUnkOuter, HRESULT *pHr) 
{
	CUnknown *pUnknown = (CUnknown *)NULL;

	FX_ENTRY("CCPUCPropertiesCreateInstance")

	DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: begin", _fx_));

	// Validate input parameters
	ASSERT(pHr);
	if (!pHr)
	{
		DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: invalid input parameter", _fx_));
		goto MyExit;
	}

	if (!(pUnknown = new CCPUCProperties(pUnkOuter, pHr)))
	{
		*pHr = E_OUTOFMEMORY;
		DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: new CCPUCProperties failed", _fx_));
	}
	else
	{
		DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s:   SUCCESS: new CCPUCProperties created", _fx_));
	}

MyExit:
	DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: end", _fx_));
	return pUnknown;
}

/****************************************************************************
 *  @doc INTERNAL CCPUCPMETHOD
 *
 *  @mfunc void | CCPUCProperties | CCPUCProperties | This
 *    method is the constructor for the property page object. It simply
 *    calls the constructor of the property page base class.
 *
 *  @parm LPUNKNOWN | pUnkOuter | Specifies the outer unknown, if any.
 *
 *  @parm HRESULT* | pHr | Specifies the place in which to put any error return.
 *
 *  @rdesc Nada.
 ***************************************************************************/
CCPUCProperties::CCPUCProperties(LPUNKNOWN pUnk, HRESULT *pHr) : CBasePropertyPage(NAME("TAPI CPU Control Property Page"), pUnk, IDD_CPUControlProperties, IDS_CPUCPROPNAME)
{
	FX_ENTRY("CCPUCProperties::CCPUCProperties")

	DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: begin", _fx_));

	m_pICPUControl = NULL;
	m_NumProperties = NUM_CPUC_CONTROLS;

	for (int i = 0; i < m_NumProperties; i++)
		m_Controls[i] = NULL;

	DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: end", _fx_));
}

/****************************************************************************
 *  @doc INTERNAL CCPUCPMETHOD
 *
 *  @mfunc void | CCPUCProperties | ~CCPUCProperties | This
 *    method is the destructor for the capture pin property page. It
 *    simply calls the base class destructor after deleting all the controls.
 *
 *  @rdesc Nada.
 ***************************************************************************/
CCPUCProperties::~CCPUCProperties()
{
	int		j;

	FX_ENTRY("CCPUCProperties::~CCPUCProperties")

	DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: begin", _fx_));

	// Free the controls
	for (j = 0; j < m_NumProperties; j++)
	{
		if (m_Controls[j])
		{
			DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s:   SUCCESS: deleting m_Controls[%ld]=0x%08lX", _fx_, j, m_Controls[j]));
			delete m_Controls[j], m_Controls[j] = NULL;
		}
		else
		{
			DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   WARNING: control already freed", _fx_));
		}
	}

	DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: end", _fx_));
}

/****************************************************************************
 *  @doc INTERNAL CCPUCPMETHOD
 *
 *  @mfunc HRESULT | CCPUCProperties | OnConnect | This
 *    method is called when the property page is connected to the filter.
 *
 *  @parm LPUNKNOWN | pUnknown | Specifies the outer unknown, if any.
 *
 *  @parm HRESULT* | pHr | Specifies the place in which to put any error return.
 *
 *  @rdesc This method returns an HRESULT value that depends on the
 *    implementation of the interface. HRESULT can include one of the
 *    following standard constants, or other values not listed:
 *
 *  @flag E_FAIL | Failure
 *  @flag E_POINTER | Null pointer argument
 *  @flag E_NOTIMPL | Method is not supported
 *  @flag NOERROR | No error
 ***************************************************************************/
HRESULT CCPUCProperties::OnConnect(IUnknown *pUnk)
{
	HRESULT Hr = NOERROR;

	FX_ENTRY("CCPUCProperties::OnConnect")

	DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: begin", _fx_));

	// Validate input parameters
	ASSERT(pUnk);
	if (!pUnk)
	{
		DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: invalid input parameter", _fx_));
		Hr = E_POINTER;
		goto MyExit;
	}

	// Get the CPU control interface
	if (SUCCEEDED (Hr = pUnk->QueryInterface(__uuidof(ICPUControl), (void **)&m_pICPUControl)))
	{
		DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s:   SUCCESS: m_pICPUControl=0x%08lX", _fx_, m_pICPUControl));
	}
	else
	{
		m_pICPUControl = NULL;
		DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: Failed Hr=0x%08lX", _fx_, Hr));
	}

	// It's Ok if we couldn't get interface pointers
	// We'll just grey the controls in the property page
	// to make it clear to the user that they can't
	// control those properties on the capture device
	Hr = NOERROR;

MyExit:
	DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: end", _fx_));
	return Hr;
}

/****************************************************************************
 *  @doc INTERNAL CCPUCPMETHOD
 *
 *  @mfunc HRESULT | CCPUCProperties | OnDisconnect | This
 *    method is called when the property page is disconnected from the owning
 *    filter.
 *
 *  @rdesc This method returns an HRESULT value that depends on the
 *    implementation of the interface. HRESULT can include one of the
 *    following standard constants, or other values not listed:
 *
 *  @flag NOERROR | No error
 ***************************************************************************/
HRESULT CCPUCProperties::OnDisconnect()
{
	FX_ENTRY("CCPUCProperties::OnDisconnect")

	DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: begin", _fx_));

	// Validate input parameters: we seem to get called several times here
	// Make sure the interface pointer is still valid
	if (!m_pICPUControl)
	{
		DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   WARNING: already disconnected!", _fx_));
	}
	else
	{
		// Release the interface
		m_pICPUControl->Release();
		m_pICPUControl = NULL;
		DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s:   SUCCESS: releasing m_pICPUControl", _fx_));
	}

	DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: end", _fx_));
	return NOERROR;
}

/****************************************************************************
 *  @doc INTERNAL CCPUCPMETHOD
 *
 *  @mfunc HRESULT | CCPUCProperties | OnActivate | This
 *    method is called when the property page is activated.
 *
 *  @rdesc This method returns an HRESULT value that depends on the
 *    implementation of the interface. HRESULT can include one of the
 *    following standard constants, or other values not listed:
 *
 *  @flag E_FAIL | Failure
 *  @flag E_POINTER | Null pointer argument
 *  @flag E_NOTIMPL | Method is not supported
 *  @flag NOERROR | No error
 ***************************************************************************/
HRESULT CCPUCProperties::OnActivate()
{
	HRESULT	Hr = NOERROR;
	int		j;

	FX_ENTRY("CCPUCProperties::OnActivate")

	DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: begin", _fx_));

	// Create the controls for the properties
	if (m_Controls[0] = new CCPUCProperty(m_hwnd, IDC_MaxProcessingTime_Label, IDC_MaxProcessingTime_Minimum, IDC_MaxProcessingTime_Maximum, IDC_MaxProcessingTime_Default, IDC_MaxProcessingTime_Stepping, IDC_MaxProcessingTime_Edit, IDC_MaxProcessingTime_Slider, 0, IDC_CPUC_MaxProcessingTime, m_pICPUControl))
	{
		DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s:   SUCCESS: m_Controls[0]=0x%08lX", _fx_, m_Controls[0]));

		if (m_Controls[1] = new CCPUCProperty(m_hwnd, IDC_CPULoad_Label, IDC_CPULoad_Minimum, IDC_CPULoad_Maximum, IDC_CPULoad_Default, IDC_CPULoad_Stepping, IDC_CPULoad_Edit, IDC_CPULoad_Slider, 0, IDC_CPUC_MaxCPULoad, m_pICPUControl))
		{
			DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s:   SUCCESS: m_Controls[1]=0x%08lX", _fx_, m_Controls[1]));

			if (m_Controls[2] = new CCPUCProperty(m_hwnd, 0, 0, 0, 0, 0, IDC_FORMAT_FlipVertical, 0, 0, IDC_CPUC_CurrentCPULoad, m_pICPUControl))
			{
				DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s:   SUCCESS: m_Controls[2]=0x%08lX", _fx_, m_Controls[2]));

				if (m_Controls[3] = new CCPUCProperty(m_hwnd, 0, 0, 0, 0, 0, IDC_FORMAT_FlipHorizontal, 0, 0, IDC_CPUC_CurrentProcessingTime, m_pICPUControl))
				{
					DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s:   SUCCESS: m_Controls[3]=0x%08lX", _fx_, m_Controls[3]));
				}
				else
				{
					DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: Out of memory", _fx_));
					delete m_Controls[0], m_Controls[0] = NULL;
					delete m_Controls[1], m_Controls[1] = NULL;
					delete m_Controls[2], m_Controls[2] = NULL;
					Hr = E_OUTOFMEMORY;
					goto MyExit;
				}
			}
			else
			{
				DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: Out of memory", _fx_));
				delete m_Controls[0], m_Controls[0] = NULL;
				delete m_Controls[1], m_Controls[1] = NULL;
				Hr = E_OUTOFMEMORY;
				goto MyExit;
			}
		}
		else
		{
			DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: Out of memory", _fx_));
			delete m_Controls[0], m_Controls[0] = NULL;
			Hr = E_OUTOFMEMORY;
			goto MyExit;
		}
	}
	else
	{
		DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: Out of memory", _fx_));
		Hr = E_OUTOFMEMORY;
		goto MyExit;
	}

	// Initialize all the controls. If the initialization fails, it's Ok. It just means
	// that the TAPI control interface isn't implemented by the device. The dialog item
	// in the property page will be greyed, showing this to the user.
	for (j = 0; j < m_NumProperties; j++)
	{
		if (m_Controls[j]->Init())
		{
			DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s:   SUCCESS: m_Controls[%ld]->Init()", _fx_, j));
		}
		else
		{
			DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   WARNING: m_Controls[%ld]->Init() failed", _fx_, j));
		}
	}

MyExit:
	DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: end", _fx_));
	m_fActivated = TRUE;
	return Hr;
}

/****************************************************************************
 *  @doc INTERNAL CCPUCPMETHOD
 *
 *  @mfunc HRESULT | CCPUCProperties | OnDeactivate | This
 *    method is called when the property page is dismissed.
 *
 *  @rdesc This method returns an HRESULT value that depends on the
 *    implementation of the interface. HRESULT can include one of the
 *    following standard constants, or other values not listed:
 *
 *  @flag NOERROR | No error
 ***************************************************************************/
HRESULT CCPUCProperties::OnDeactivate()
{
	int	j;

	FX_ENTRY("CCPUCProperties::OnDeactivate")

	DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: begin", _fx_));

	// Free the controls
	for (j = 0; j < m_NumProperties; j++)
	{
		if (m_Controls[j])
		{
			DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s:   SUCCESS: deleting m_Controls[%ld]=0x%08lX", _fx_, j, m_Controls[j]));
			delete m_Controls[j], m_Controls[j] = NULL;
		}
		else
		{
			DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   WARNING: control already freed", _fx_));
		}
	}

	DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: end", _fx_));
	return NOERROR;
}

/****************************************************************************
 *  @doc INTERNAL CCPUCPMETHOD
 *
 *  @mfunc HRESULT | CCPUCProperties | OnApplyChanges | This
 *    method is called when the user applies changes to the property page.
 *
 *  @rdesc This method returns an HRESULT value that depends on the
 *    implementation of the interface. HRESULT can include one of the
 *    following standard constants, or other values not listed:
 *
 *  @flag E_FAIL | Failure
 *  @flag E_POINTER | Null pointer argument
 *  @flag E_NOTIMPL | Method is not supported
 *  @flag NOERROR | No error
 ***************************************************************************/
HRESULT CCPUCProperties::OnApplyChanges()
{
	HRESULT	Hr = NOERROR;
	int		j;
	CMediaType *pmt = NULL;

	FX_ENTRY("CCPUCProperties::OnApplyChanges")

	DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: begin", _fx_));

	// Apply new targets on video stream
	for (j = 0; j < m_NumProperties; j++)
	{
		ASSERT(m_Controls[j]);
		if (m_Controls[j])
		{
			DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s:   SUCCESS: calling m_Controls[%ld]=0x%08lX->OnApply", _fx_, j, m_Controls[j]));
			if (m_Controls[j]->HasChanged())
				m_Controls[j]->OnApply();
			Hr = NOERROR;
		}
		else
		{
			DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: can't calling m_Controls[%ld]=NULL->OnApply", _fx_, j));
			Hr = E_UNEXPECTED;
		}
	}

	DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: end", _fx_));
	return Hr;
}

/****************************************************************************
 *  @doc INTERNAL CCPUCPMETHOD
 *
 *  @mfunc BOOL | CCPUCProperties | OnReceiveMessage | This
 *    method is called when a message is sent to the property page dialog box.
 *
 *  @rdesc By default, returns the value returned by the Win32 DefWindowProc function.
 ***************************************************************************/
BOOL CCPUCProperties::OnReceiveMessage(HWND hWnd, UINT uMsg, WPARAM wParam, LPARAM lParam) 
{
	int iNotify = HIWORD (wParam);
	int j;

	switch (uMsg)
	{
		case WM_INITDIALOG:
			// This is called before Activate...
			m_hWnd = hWnd;
			return TRUE; // Don't call setfocus

		case WM_TIMER:
			if (m_fActivated)
			{
				// Update the Vu-Meters
				for (j = 0; j < m_NumProperties; j++)
				{
					ASSERT(m_Controls[j]);
					if (m_Controls[j]->GetProgressHWnd())
					{
						m_Controls[j]->UpdateProgress();
						SetDirty();
					}
				}
			}
			break;

		case WM_HSCROLL:
		case WM_VSCROLL:
			if (m_fActivated)
			{
				// Process all of the Trackbar messages
				for (j = 0; j < m_NumProperties; j++)
				{
					ASSERT(m_Controls[j]);
					if (m_Controls[j]->GetTrackbarHWnd() == (HWND)lParam)
					{
						m_Controls[j]->OnScroll(uMsg, wParam, lParam);
						SetDirty();
					}
				}
			}
			break;

		case WM_COMMAND:

			// This message gets sent even before OnActivate() has been
			// called(!). We need to test and make sure the controls have
			// beeen initialized before we can use them.
			if (m_fActivated)
			{
				// Process all of the edit box messages
				for (j = 0; j < m_NumProperties; j++)
				{
					if (m_Controls[j] && m_Controls[j]->GetEditHWnd() == (HWND)lParam)
					{
						m_Controls[j]->OnEdit(uMsg, wParam, lParam);
						SetDirty();
						break;
					}
				}

				switch (LOWORD(wParam))
				{
					case IDC_CONTROL_DEFAULT:
						for (j = 0; j < m_NumProperties; j++)
						{
							if (m_Controls[j])
								m_Controls[j]->OnDefault();
						}
						break;
					default:
						break;
				}
			}
			break;

		default:
			return FALSE;
	}

	return TRUE;
}

/****************************************************************************
 *  @doc INTERNAL CCPUCPMETHOD
 *
 *  @mfunc BOOL | CCPUCProperties | SetDirty | This
 *    method notifies the property page site of changes.
 *
 *  @rdesc Nada.
 ***************************************************************************/
void CCPUCProperties::SetDirty()
{
	m_bDirty = TRUE;
	if (m_pPageSite)
		m_pPageSite->OnStatusChange(PROPPAGESTATUS_DIRTY);
}

#endif

#endif
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\net\tapi\skywalker\filters\video\tapivcap\cpucp.h ===
/****************************************************************************
 *  @doc INTERNAL CPUCP
 *
 *  @module CPUCP.h | Header file for the <c CCPUCProperty>
 *    class used to implement a property page to test the new TAPI internal
 *    interfaces <i ICPUControl>.
 *
 *  @comm This code tests the TAPI VfW Output Pins <i ICPUControl>
 *    implementation. This code is only compiled if USE_PROPERTY_PAGES is
 *    defined.
 ***************************************************************************/

#ifndef _CPUCP_H_
#define _CPUCP_H_

#ifdef USE_PROPERTY_PAGES

#ifdef USE_CPU_CONTROL

#define NUM_CPUC_CONTROLS				4
#define IDC_CPUC_MaxCPULoad				0
#define IDC_CPUC_MaxProcessingTime		1
#define IDC_CPUC_CurrentCPULoad			2
#define IDC_CPUC_CurrentProcessingTime	3

/****************************************************************************
 *  @doc INTERNAL CCPUCPCLASS
 *
 *  @class CCPUCProperty | This class implements handling of a
 *    single CPU control property in a property page.
 *
 *  @mdata int | CCPUCProperty | m_NumProperties | Keeps
 *    track of the number of properties.
 *
 *  @mdata ICPUControl* | CCPUCProperty | m_pICPUControl | Pointer
 *    to the <i ICPUControl> interface.
 *
 *  @comm This code tests the TAPI VfW Output Pins <i ICPUControl>
 *    implementation. This code is only compiled if USE_PROPERTY_PAGES is
 *    defined.
***************************************************************************/
class CCPUCProperty : public CKSPropertyEditor 
{
	public:
	CCPUCProperty(HWND hDlg, ULONG IDLabel, ULONG IDMinControl, ULONG IDMaxControl, ULONG IDDefaultControl, ULONG IDStepControl, ULONG IDEditControl, ULONG IDTrackbarControl, ULONG IDProgressControl, ULONG IDProperty, ICPUControl *pICPUControl);
	~CCPUCProperty ();

	// CKSPropertyEditor base class pure virtual overrides
	HRESULT GetValue();
	HRESULT SetValue();
	HRESULT GetRange();
	BOOL CanAutoControl(void);
	BOOL GetAuto(void);
	BOOL SetAuto(BOOL fAuto);

	private:
	ICPUControl *m_pICPUControl;
};

/****************************************************************************
 *  @doc INTERNAL CCPUCPCLASS
 *
 *  @class CCPUCProperties | This class implements a property page
 *    to test the new TAPI internal interfaces <i ICPUControl>.
 *
 *  @mdata int | CCPUCProperties | m_NumProperties | Keeps
 *    track of the number of properties.
 *
 *  @mdata ICPUControl* | CCPUCProperties | m_pInterface | Pointer
 *    to the <i ICPUControl> interface.
 *
 *  @mdata CCPUCProperty* | CCPUCProperties | m_Controls[NUM_CPUC_CONTROLS] | Array
 *    of CPU control properties.
 *
 *  @comm This code tests the TAPI VfW Output Pins <i ICPUControl>
 *    implementation. This code is only compiled if USE_PROPERTY_PAGES is
 *    defined.
***************************************************************************/
class CCPUCProperties : public CBasePropertyPage
{
	public:
	CCPUCProperties(LPUNKNOWN pUnk, HRESULT *pHr);
	~CCPUCProperties();

	// Implement CBasePropertyPage virtual methods
	HRESULT OnConnect(IUnknown *pUnk);
	HRESULT OnDisconnect();
	HRESULT OnActivate();
	HRESULT OnDeactivate();
	HRESULT OnApplyChanges();
	BOOL    OnReceiveMessage(HWND hWnd, UINT uMsg, WPARAM wParam, LPARAM lParam);

	private:

	void SetDirty();

	HWND			m_hWnd;
	int				m_NumProperties;
	BOOL			m_fActivated;
	ICPUControl		*m_pICPUControl;
	CCPUCProperty	*m_Controls[NUM_CPUC_CONTROLS];
};

#endif // USE_CPU_CONTROL

#endif // USE_PROPERTY_PAGES

#endif // _CPUCP_H_
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\net\tapi\skywalker\filters\video\tapivcap\critsec.h ===
#ifndef _CRITSEC_H_
#define _CRITSEC_H_

EXTERN_C CRITICAL_SECTION g_CritSec;

#endif
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\net\tapi\skywalker\filters\video\tapivcap\dbgxtra.c ===
#ifdef XTRA_TRACE

#include <windows.h>

#include <stdio.h>          //this is only for the _vsnprintf ....
#include <rtutils.h>    //this is for the TraceVprintf ....
#include <process.h>    //for the _getpid

#include "dbgxtra.h"


//==============================================================================================
DWORD MyTraceId;

int MyDbgPrint(LPCSTR lpszFormat, IN ...)
{       int ret;

    va_list arglist;
    va_start(arglist, lpszFormat);

    ret=TraceVprintf(MyTraceId, lpszFormat, arglist);
    va_end(arglist);
    return(ret);
}

int MyDbgPuts(LPCSTR lpszMsg)
{       //this should be even faster than the xxxprintf above...
    return(TracePuts(MyTraceId, lpszMsg));
}


//------------------------
HANDLE h_mut1=NULL;
//------------------------

LARGE_INTEGER g_liFreq;
LARGE_INTEGER g_liTicks;

inline int ClockDiff(
    LARGE_INTEGER &liNewTick, 
    LARGE_INTEGER &liOldTick
    )
{
    return (DWORD)((liNewTick.QuadPart - liOldTick.QuadPart) 
        * 1e6 / g_liFreq.QuadPart);
}

typedef struct LOGITEM
{
    TCHAR * pszMessage;
    DWORD   dw;
    DWORD   p;
    DWORD   s;

} LOGITEM;

const DWORD LOG_BUFFER_MASK = 0x3ff;
const DWORD LOG_BUFFER_SIZE = LOG_BUFFER_MASK + 1;

LOGITEM g_LogBuffer[LOG_BUFFER_SIZE];
DWORD g_dwCurrentLogItem = LOG_BUFFER_SIZE; //this will be decr. before use
                                            //start from top and go down
DWORD g_dwTotalItems = 0;

void Log(
    TCHAR * pszMessage,
    DWORD dw,
    DWORD p,
    DWORD s
)
{       DWORD ret;

        //5 min. timeout, just in case
        if((h_mut1==NULL) || (ret=WaitForSingleObject(h_mut1, 300000))==WAIT_TIMEOUT || ret==WAIT_FAILED) {
        MyDbgPrint("Log:   ERROR: Wait on Log mutex: h_mut1=0x%x, ret=0x%x", h_mut1, ret);
        return;
                }

    // Access the shared resource.
    if (g_dwTotalItems < LOG_BUFFER_SIZE) 
        g_dwTotalItems ++;

    g_dwCurrentLogItem = ((g_dwCurrentLogItem - 1) & LOG_BUFFER_MASK);

    g_LogBuffer[g_dwCurrentLogItem].pszMessage = pszMessage;
    g_LogBuffer[g_dwCurrentLogItem].dw = dw;
    g_LogBuffer[g_dwCurrentLogItem].p  = p;
    g_LogBuffer[g_dwCurrentLogItem].s  = s;

        MyDbgPrint("%d,%p,%x:%s\n",dw,p,s,pszMessage);

        ReleaseMutex(h_mut1);

}

void DumpLog()
{
        DWORD ret;


        //5 min. timeout, just in case
        if((h_mut1==NULL) || (ret=WaitForSingleObject(h_mut1, 300000))==WAIT_TIMEOUT || ret==WAIT_FAILED) {
        MyDbgPrint("Log:   ERROR: Wait on Log mutex: h_mut1=0x%x, ret=0x%x", h_mut1, ret);
        return;
                }
    // Access the shared resource.

    for (DWORD i = g_dwCurrentLogItem; i < g_dwTotalItems; i ++)
    {
        MyDbgPrint("%40ws%14d %p %x\n", 
            g_LogBuffer[i].pszMessage,
            g_LogBuffer[i].dw,
            g_LogBuffer[i].p,
            g_LogBuffer[i].s
            );
    }

    for (i = 0; i < g_dwCurrentLogItem; i ++)
    {
        MyDbgPrint("%40ws%14d %p %x\n", 
            g_LogBuffer[i].pszMessage,
            g_LogBuffer[i].dw,
            g_LogBuffer[i].p,
            g_LogBuffer[i].s
            );
    }

        ReleaseMutex(h_mut1);
}

void SimpleHeapCheck(char *pszMsg)
{       char *p, *res="Ok";
        int sz;

    //FX_ENTRY("SimpleHeapCheck");
    sz=128+(rand()%10)*1024;
        if((p=new char[sz])==NULL)
        {
        MyDbgPrint("SimpleHeapCheck:   ERROR: Memory full\n");
        res="Er";
        }
        else {
                memset(p, '#', sz);
                delete[] p;
        }
        if(pszMsg==NULL) {
                pszMsg="";
                }
        MyDbgPrint("%s: %s",res,pszMsg);
        Log("HeapCheck",(DWORD)pszMsg,(DWORD)p,sz);
}

//int _vsnprintf( char *buffer, size_t count, const char *format, va_list argptr );
#define MAXFILLPATL      (1<<6)
#define DEFFILLPOW2     6
//#define FILLPATL      (1<<FILLPOW2)
//#define FILLMASK      FILLPATL-1

int FillPattern(char *Area, DWORD size, DWORD FillPow2, LPCSTR lpszFormat, IN ...)
{       DWORD ret, rem=0,quot,i;
        char *p;
        char buf[MAXFILLPATL];
        int patl;
        int fillmask;

    va_list arglist;
    va_start(arglist, lpszFormat);

        if(FillPow2>6 || FillPow2==0) FillPow2=DEFFILLPOW2;     //default
        else
        if(FillPow2<4) FillPow2=4;

        patl=(1<<FillPow2);
        fillmask=patl-1;
        
        memset(buf,'.',patl);
        _vsnprintf(buf,patl,lpszFormat,arglist);
        rem = size >>FillPow2;  //rem= size/patl;
        quot= size & fillmask;  //quot = size%patl;

    //-- just in case, guard the filling operation against concurency ...
        //5 min. timeout, just in case
        if((h_mut1==NULL) || (ret=WaitForSingleObject(h_mut1, 300000))==WAIT_TIMEOUT || ret==WAIT_FAILED) {
        MyDbgPrint("Log:   ERROR: Wait on Log mutex: h_mut1=0x%x, ret=0x%x", h_mut1, ret);
        return(0);
                }
    // Access the shared resource.

        for(p=Area, i=0;i<rem;p+=patl, i++)
                memcpy(p,buf,patl);
        memcpy(p,buf,quot);

        ReleaseMutex(h_mut1);

        return(rem);
}


//CRC32 table (polynomial 04c11db7)
unsigned long crc32_table[256]={
0x00000000,0x77073096,0xee0e612c,0x990951ba,0x076dc419,0x706af48f,0xe963a535,0x9e6495a3,
0x0edb8832,0x79dcb8a4,0xe0d5e91e,0x97d2d988,0x09b64c2b,0x7eb17cbd,0xe7b82d07,0x90bf1d91,
0x1db71064,0x6ab020f2,0xf3b97148,0x84be41de,0x1adad47d,0x6ddde4eb,0xf4d4b551,0x83d385c7,
0x136c9856,0x646ba8c0,0xfd62f97a,0x8a65c9ec,0x14015c4f,0x63066cd9,0xfa0f3d63,0x8d080df5,
0x3b6e20c8,0x4c69105e,0xd56041e4,0xa2677172,0x3c03e4d1,0x4b04d447,0xd20d85fd,0xa50ab56b,
0x35b5a8fa,0x42b2986c,0xdbbbc9d6,0xacbcf940,0x32d86ce3,0x45df5c75,0xdcd60dcf,0xabd13d59,
0x26d930ac,0x51de003a,0xc8d75180,0xbfd06116,0x21b4f4b5,0x56b3c423,0xcfba9599,0xb8bda50f,
0x2802b89e,0x5f058808,0xc60cd9b2,0xb10be924,0x2f6f7c87,0x58684c11,0xc1611dab,0xb6662d3d,
0x76dc4190,0x01db7106,0x98d220bc,0xefd5102a,0x71b18589,0x06b6b51f,0x9fbfe4a5,0xe8b8d433,
0x7807c9a2,0x0f00f934,0x9609a88e,0xe10e9818,0x7f6a0dbb,0x086d3d2d,0x91646c97,0xe6635c01,
0x6b6b51f4,0x1c6c6162,0x856530d8,0xf262004e,0x6c0695ed,0x1b01a57b,0x8208f4c1,0xf50fc457,
0x65b0d9c6,0x12b7e950,0x8bbeb8ea,0xfcb9887c,0x62dd1ddf,0x15da2d49,0x8cd37cf3,0xfbd44c65,
0x4db26158,0x3ab551ce,0xa3bc0074,0xd4bb30e2,0x4adfa541,0x3dd895d7,0xa4d1c46d,0xd3d6f4fb,
0x4369e96a,0x346ed9fc,0xad678846,0xda60b8d0,0x44042d73,0x33031de5,0xaa0a4c5f,0xdd0d7cc9,
0x5005713c,0x270241aa,0xbe0b1010,0xc90c2086,0x5768b525,0x206f85b3,0xb966d409,0xce61e49f,
0x5edef90e,0x29d9c998,0xb0d09822,0xc7d7a8b4,0x59b33d17,0x2eb40d81,0xb7bd5c3b,0xc0ba6cad,
0xedb88320,0x9abfb3b6,0x03b6e20c,0x74b1d29a,0xead54739,0x9dd277af,0x04db2615,0x73dc1683,
0xe3630b12,0x94643b84,0x0d6d6a3e,0x7a6a5aa8,0xe40ecf0b,0x9309ff9d,0x0a00ae27,0x7d079eb1,
0xf00f9344,0x8708a3d2,0x1e01f268,0x6906c2fe,0xf762575d,0x806567cb,0x196c3671,0x6e6b06e7,
0xfed41b76,0x89d32be0,0x10da7a5a,0x67dd4acc,0xf9b9df6f,0x8ebeeff9,0x17b7be43,0x60b08ed5,
0xd6d6a3e8,0xa1d1937e,0x38d8c2c4,0x4fdff252,0xd1bb67f1,0xa6bc5767,0x3fb506dd,0x48b2364b,
0xd80d2bda,0xaf0a1b4c,0x36034af6,0x41047a60,0xdf60efc3,0xa867df55,0x316e8eef,0x4669be79,
0xcb61b38c,0xbc66831a,0x256fd2a0,0x5268e236,0xcc0c7795,0xbb0b4703,0x220216b9,0x5505262f,
0xc5ba3bbe,0xb2bd0b28,0x2bb45a92,0x5cb36a04,0xc2d7ffa7,0xb5d0cf31,0x2cd99e8b,0x5bdeae1d,
0x9b64c2b0,0xec63f226,0x756aa39c,0x026d930a,0x9c0906a9,0xeb0e363f,0x72076785,0x05005713,
0x95bf4a82,0xe2b87a14,0x7bb12bae,0x0cb61b38,0x92d28e9b,0xe5d5be0d,0x7cdcefb7,0x0bdbdf21,
0x86d3d2d4,0xf1d4e242,0x68ddb3f8,0x1fda836e,0x81be16cd,0xf6b9265b,0x6fb077e1,0x18b74777,
0x88085ae6,0xff0f6a70,0x66063bca,0x11010b5c,0x8f659eff,0xf862ae69,0x616bffd3,0x166ccf45,
0xa00ae278,0xd70dd2ee,0x4e048354,0x3903b3c2,0xa7672661,0xd06016f7,0x4969474d,0x3e6e77db,
0xaed16a4a,0xd9d65adc,0x40df0b66,0x37d83bf0,0xa9bcae53,0xdebb9ec5,0x47b2cf7f,0x30b5ffe9,
0xbdbdf21c,0xcabac28a,0x53b39330,0x24b4a3a6,0xbad03605,0xcdd70693,0x54de5729,0x23d967bf,
0xb3667a2e,0xc4614ab8,0x5d681b02,0x2a6f2b94,0xb40bbe37,0xc30c8ea1,0x5a05df1b,0x2d02ef8d,
};

// This function uses the above crc32_table lookup table
// to generate a CRC for a buffer
DWORD Buf_CRC32(unsigned char *buffer, DWORD dwSize)
{
        unsigned long crc=0xffffffff;

        while(dwSize--)
                crc = (crc >> 8) ^ crc32_table[(crc & 0xFF) ^ *buffer++];
        return crc^0xffffffff;
}



#endif  //XTRA_TRACE
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\net\tapi\skywalker\filters\video\tapivcap\devenum.h ===
/****************************************************************************
 *  @doc INTERNAL DEVENUM
 *
 *  @module DevEnum.h | Our Devenum exports.
 ***************************************************************************/

#ifndef _DEVENUM_H_
#define _DEVENUM_H_

#define VIDEOAPI EXTERN_C __declspec (dllexport) HRESULT WINAPI

VIDEOAPI GetVideoCapDeviceInfo(IN DWORD dwDeviceIndex, OUT PDEVICEINFO pDeviceInfo);
VIDEOAPI GetNumVideoCapDevices(OUT PDWORD pdwNumDevices);
EXTERN_C HRESULT WINAPI GetNumVideoCapDevicesInternal(OUT PDWORD pdwNumDevices, IN bool bRecount);
#endif // _DEVENUM_H_
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\net\tapi\skywalker\filters\video\tapivcap\devenum.cpp ===
/****************************************************************************
 *  @doc INTERNAL DEVENUM
 *
 *  @module DevEnum.cpp | Source file for the <c CTAPIVCap> class methods
 *    used to implement the <i IVideoDeviceControl> interface.
 ***************************************************************************/

#include "Precomp.h"
#include "CritSec.h"
#include <atlbase.h>
#include <streams.h>
#include "..\..\audio\tpaudcap\crossbar.h"
#include <initguid.h>

#ifdef DEBUG
  #include <stdio.h>
  #include <stdarg.h>

  static int dprintf( char * format, ... )
  {
      char out[1024];
      int r;
      va_list marker;
      va_start(marker, format);
      r=_vsnprintf(out, 1022, format, marker);
      va_end(marker);
      OutputDebugString( out );
      return r;
  }

  static int dout( int console, DWORD id, DWORD code, char * format, ... )
  {
      char out[1024];
      int r;
      va_list marker;
      va_start(marker, format);
      r=_vsnprintf(out, 1022, format, marker);
      va_end(marker);
      if(console) {
        OutputDebugString( out );
        OutputDebugString("\n");
      }
      DBGOUT((id, code, "%s", out));
      return r;
  }


#else
  #define dprintf ; / ## /
  #define dout ; / ## /
#endif


static const char g_szVfWToWDMMapperDescription[] = "VfW MM 16bit Driver for WDM V. Cap. Devices";
static const char g_szVfWToWDMMapperDescription2[] = "Microsoft WDM Image Capture";
static const char g_szVfWToWDMMapperDescription3[] = "Microsoft WDM Image Capture (Win32)";
static const char g_szVfWToWDMMapperDescription4[] = "WDM Video For Windows Capture Driver (Win32)";
static const char g_szVfWToWDMMapperDescription5[] = "VfWWDM32.dll";
static const char g_szMSOfficeCamcorderDescription[] = "Screen Capture Device Driver for AVI";
static const char g_szHauppaugeDll[] = "o100vc.dll";

// documented name for DV cameras. won't be changed/localized
static const char g_szDVCameraFriendlyName[] = "Microsoft DV Camera and VCR";

static const TCHAR sznSVideo[] = TEXT("nSVideo");
static const TCHAR sznComposite[] = TEXT("nComposite");

/****************************************************************************
 *  @doc INTERNAL CDEVENUMFUNCTION
 *
 *  @func HRESULT | GetNumCapDevices | This method is used to
 *    compute the number of installed capture devices. This is
 * just a wrapper around the GetNumCapDevicesInternal version,
 * calling it with bRecount TRUE to force a device recount
 *****************************************************************************/
VIDEOAPI GetNumVideoCapDevices(OUT PDWORD pdwNumDevices)
{
        HRESULT Hr = NOERROR;

        FX_ENTRY("GetNumVideoCapDevices")
        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: begin", _fx_));

        Hr = GetNumVideoCapDevicesInternal(pdwNumDevices,  TRUE);

        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: end", _fx_));
        return Hr;
}


// !!! this function is duplicated in audio code
//
HRESULT FindAPin(IBaseFilter *pf, PIN_DIRECTION dir, int iIndex, IPin **ppPin)
{
    IPin *pP, *pTo = NULL;
    DWORD dw;
    IEnumPins *pins = NULL;
    PIN_DIRECTION pindir;
    BOOL fFound = FALSE;
    HRESULT hr = pf->EnumPins(&pins);

    while (hr == NOERROR) {
        hr = pins->Next(1, &pP, &dw);
        if (hr == S_OK && dw == 1) {
            hr = pP->QueryDirection(&pindir);
            if (hr == S_OK && pindir == dir && (iIndex-- == 0)) {
                fFound = TRUE;
                break;
            } else  {
                pP->Release();
            }
        } else {
            break;
        }
    }
    if (pins)
        pins->Release();

    if (fFound) {
        *ppPin = pP;
        return NOERROR;
    } else {
        return E_FAIL;
    }
}

DEFINE_GUID(IID_IAMFilterData, 0x97f7c4d4, 0x547b, 0x4a5f, 0x83, 0x32, 0x53, 0x64, 0x30, 0xad, 0x2e, 0x4d);

MIDL_INTERFACE("97f7c4d4-547b-4a5f-8332-536430ad2e4d")
IAMFilterData : public IUnknown
{
public:
    virtual HRESULT STDMETHODCALLTYPE ParseFilterData(
        /* [size_is][in] */ BYTE __RPC_FAR *rgbFilterData,
        /* [in] */ ULONG cb,
        /* [out] */ BYTE __RPC_FAR *__RPC_FAR *prgbRegFilter2) = 0;

    virtual HRESULT STDMETHODCALLTYPE CreateFilterData(
        /* [in] */ REGFILTER2 __RPC_FAR *prf2,
        /* [out] */ BYTE __RPC_FAR *__RPC_FAR *prgbFilterData,
        /* [out] */ ULONG __RPC_FAR *pcb) = 0;

};

// the next 4 functions create/open the camera reg key and return the handle;
// make sure the handle is RegClose'ed when not needed anymore
HKEY MakeRegKeyAndReturnHandle(char *szDeviceDescription, char *szDeviceVersion, HKEY root_key, char *base_key)
{

    HKEY    hDeviceKey = NULL;
    HKEY    hKey = NULL;
    DWORD   dwSize;
    char    szKey[MAX_PATH + MAX_VERSION + 2];
    DWORD   dwDisposition;

    FX_ENTRY("MakeRegKeyAndReturnHandle")

    DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: begin", _fx_));

    // Open the main capture devices key, or create it if it doesn't exist
    if (RegCreateKeyEx(root_key, base_key, 0, 0, REG_OPTION_NON_VOLATILE, KEY_WRITE, NULL, &hDeviceKey, &dwDisposition) == ERROR_SUCCESS)
    {
        // If we have version info use that to build the key name
        // @todo VCMSTRM.cpp does some weird things with the name - probably due to bogus device
        // Repro this code
        ASSERT(lstrlen(szDeviceDescription)+1<MAX_CAPDEV_DESCRIPTION); // actually #define MAX_CAPDEV_DESCRIPTION MAX_PATH
        ASSERT(lstrlen(szDeviceVersion)+1<MAX_VERSION);
        // in the only case where this function is used, it is called with the 2 strings above that are limited at retrieval time
        // (see GetNumVideoCapDevicesInternal), but just in case, since this could be called with any strings
        if (szDeviceVersion && *szDeviceVersion != '\0')
            wsprintf(szKey, "%s, %s", szDeviceDescription, szDeviceVersion);
        else
            wsprintf(szKey, "%s", szDeviceDescription);

        // Check if there is already a key for the current device
        // Open the key for the current device, or create the key if it doesn't exist
        if (RegCreateKeyEx(hDeviceKey, szKey, 0, 0, REG_OPTION_NON_VOLATILE, KEY_READ|KEY_WRITE, NULL, &hKey, &dwDisposition) != ERROR_SUCCESS)
        {
            DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: Can't create registry key!", _fx_));
        }

    }

    if (hDeviceKey)
        RegCloseKey(hDeviceKey);

    DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: end (returning %lx)", _fx_, (DWORD)hKey));
    //if something failed, hKey would be still NULL at this point
    return hKey;
}

HKEY MakeRegKeyAndReturnHandleByIndex(DWORD dwDeviceIndex, HKEY root_key, char *base_key)
{
    return MakeRegKeyAndReturnHandle(g_aDeviceInfo[dwDeviceIndex].szDeviceDescription,g_aDeviceInfo[dwDeviceIndex].szDeviceVersion,root_key,base_key);
}


HKEY GetRegKeyHandle(char *szDeviceDescription, char *szDeviceVersion, HKEY root_key, char *base_key)
{
    char    szKey[MAX_PATH + MAX_VERSION + 2];
    HKEY    hRTCDeviceKey  = NULL;
    HKEY    hKey = NULL;


    FX_ENTRY("GetRegKeyHandle")

    DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: begin", _fx_));

    // Check if the RTC  key is there
    if (RegOpenKey(root_key, base_key, &hRTCDeviceKey) == ERROR_SUCCESS)
    {

        ASSERT(lstrlen(szDeviceDescription)+1<MAX_CAPDEV_DESCRIPTION); // actually #define MAX_CAPDEV_DESCRIPTION MAX_PATH
        ASSERT(lstrlen(szDeviceVersion)+1<MAX_VERSION);
        // in the only case where this function is used, it is called with the 2 strings above that are limited at retrieval time
        // (see GetNumVideoCapDevicesInternal), but just in case, since this could be called with any strings
        if (szDeviceVersion && *szDeviceVersion != '\0')
            wsprintf(szKey, "%s, %s", szDeviceDescription, szDeviceVersion);
        else
            wsprintf(szKey, "%s", szDeviceDescription);

        // Check if there is already an RTC key for our device
        if (RegOpenKey(hRTCDeviceKey, szKey, &hKey) != ERROR_SUCCESS)
        {
            // Try again without the version information
            if (szDeviceVersion && *szDeviceVersion != '\0')
            {
                wsprintf(szKey, "%s", szDeviceDescription);
                RegOpenKey(hRTCDeviceKey, szKey, &hKey);
            }
        }
    }


    if (hRTCDeviceKey)
        RegCloseKey(hRTCDeviceKey);

    DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: end (returning %lx)", _fx_, (DWORD)hKey));

    //if something failed, hKey would be still NULL at this point
    return hKey;

}


HKEY GetRegKeyHandleByIndex(DWORD dwDeviceIndex, HKEY root_key, char *base_key)
{
    return GetRegKeyHandle(g_aDeviceInfo[dwDeviceIndex].szDeviceDescription,g_aDeviceInfo[dwDeviceIndex].szDeviceVersion,root_key,base_key);
}


// should this device be handled by the new DShow video capture object?  DV and devices with crossbars do not work with
// the old handlers.
//
// returns 1 for TV device
// returns 2 for DV device
// returns 0 for neither
//
BOOL IsDShowDevice(IMoniker *pM, IPropertyBag *pPropBag, DWORD dwDeviceIndex)
{
    HRESULT hr;
    VARIANT var;
    CComPtr<IBaseFilter> pFilter;
    CComPtr<IPin> pPin;
    CComPtr<IBindCtx> pBC;
    ULONG ul;
    var.vt = VT_BSTR;

    HKEY hKey=NULL;
    DWORD dwSize = sizeof(DWORD);
    DWORD  dwDoNotUseDShow=0;

    FX_ENTRY("IsDShowDevice")

    // easy way to tell if it's a DV device

    if(lstrcmp(g_aDeviceInfo[dwDeviceIndex].szDeviceDescription, g_szDVCameraFriendlyName) == 0)
    {
      // Description string (e.g., Panasonic DV Device) preferred if available (WinXP)
        if ((hr = pPropBag->Read(L"Description", &var, 0)) == S_OK)
        {
            WideCharToMultiByte(CP_ACP, 0, var.bstrVal, -1, g_aDeviceInfo[dwDeviceIndex].szDeviceDescription, MAX_PATH, 0, 0);
            SysFreeString(var.bstrVal);
        }

        return 2;
    }

    // WinSE #28804, regarding Sony MPEG2 R-Engine devices
    // the code below looks for the SOFTWARE\Microsoft\RTC\VideoCapture\Sony MPEG2 R-Engine\DoNotUseDShow key
    // (the 'Sony MPEG2 R-Engine' component of the name path above could have version numbers appended)

    //hard-coded name: SONY_MOTIONEYE_CAM_NAME
    dprintf("%s: Comparing %s : %s ...\n", _fx_,g_aDeviceInfo[dwDeviceIndex].szDeviceDescription,SONY_MOTIONEYE_CAM_NAME);
    if(lstrcmp(g_aDeviceInfo[dwDeviceIndex].szDeviceDescription,SONY_MOTIONEYE_CAM_NAME)==0)    // for a SONY Motion Eye camera ...
    {

        if((hKey = MakeRegKeyAndReturnHandleByIndex(dwDeviceIndex, RTCKEYROOT, szRegRTCKey)) != NULL)     // after creating camera key ...
        {                                                                                                 // ... (or if already existed)
              LONG err;
              if((err=RegQueryValueEx(hKey, (LPTSTR)szRegdwDoNotUseDShow, NULL, NULL, (LPBYTE)&dwDoNotUseDShow, &dwSize)) != ERROR_SUCCESS)
              {                                                                                           // if the value does not exist ...
                  dprintf("%s: RegQueryValueEx err = %#08x\n", _fx_,err);
                  dwSize = sizeof(DWORD);
                  dwDoNotUseDShow=1;                                                                      // set it on 1
                  RegSetValueEx(hKey, (LPTSTR)szRegdwDoNotUseDShow, (DWORD)NULL, REG_DWORD, (LPBYTE)&dwDoNotUseDShow, dwSize);
                  //don't care if it fails; in that case the default will be used (1 if we got to this point anyway...)
                  dprintf("%s: MOTION EYE CAM detected: REG Key %s set to %d ...\n", _fx_,szRegdwDoNotUseDShow,dwDoNotUseDShow);
              }
              RegCloseKey(hKey); hKey = NULL;
        }
    }
    else
    // now, independently of the code above, for any other cameras, check the DoNotUseDShow value, if any
    // (so the value path is: SOFTWARE\Microsoft\RTC\VideoCapture\<camera_name>\DoNotUseDShow)
    {

        if((hKey = GetRegKeyHandleByIndex(dwDeviceIndex, RTCKEYROOT, szRegRTCKey)) != NULL)
        {
              dwSize = sizeof(DWORD);
              RegQueryValueEx(hKey, (LPTSTR)szRegdwDoNotUseDShow, NULL, NULL, (LPBYTE)&dwDoNotUseDShow, &dwSize);
              //don't care if it fails; in that case the default will be used (1 if is a SONY Mot.Eye, 0 otherwise)
              RegCloseKey(hKey); hKey = NULL;
        }
    }
    // if the above code managed to set something non-zero for this, do not use DShow -- simply return 0
    if(dwDoNotUseDShow!=0)
        return 0;

    // END FIX WinSE #28804

    // See if it has an input pin.  That is only true for TV/DV devices.
    // Anything else will use the old code path for safety.


    IAMFilterData *pfd;
    hr = CoCreateInstance(CLSID_FilterMapper, NULL, CLSCTX_INPROC_SERVER,
                        IID_IAMFilterData, (void **)&pfd);
    if (FAILED(hr))
        return FALSE;   // OOM

    BOOL fDShow = FALSE;
    VARIANT varFilData;
    varFilData.vt = VT_UI1 | VT_ARRAY;
    varFilData.parray = 0; // docs say zero this
    BYTE *pbFilterData = NULL;
    DWORD dwcbFilterData = 0;

    hr = pPropBag->Read(L"FilterData", &varFilData, 0);
    if(SUCCEEDED(hr))
    {
        ASSERT(varFilData.vt == (VT_UI1 | VT_ARRAY));
        dwcbFilterData = varFilData.parray->rgsabound[0].cElements;

        hr = SafeArrayAccessData(varFilData.parray, (void **)&pbFilterData);
        ASSERT(hr == S_OK);
        ASSERT(pbFilterData);

        if(SUCCEEDED(hr))
        {
            BYTE *pb;
            hr = pfd->ParseFilterData(pbFilterData, dwcbFilterData, &pb);
            if(SUCCEEDED(hr))
            {
                REGFILTER2 *pFil = ((REGFILTER2 **)pb)[0];
                if (pFil->dwVersion == 2) {
                    for (ULONG zz=0; zz<pFil->cPins2; zz++) {
                        const REGFILTERPINS2 *pPin = pFil->rgPins2 + zz;

                        // a capture filter with an input pin that isn't
                        // rendered has extra goo, like crossbars or tv tuners
                        // so we need to talk to it with the DShow class
                        if (!(pPin->dwFlags & REG_PINFLAG_B_OUTPUT) &&
                            !(pPin->dwFlags & REG_PINFLAG_B_RENDERER)) {
                            fDShow = TRUE;
                            break;
                        }
                    }
                }
            }
        }

        if(pbFilterData)
        {
            hr = SafeArrayUnaccessData(varFilData.parray);
            ASSERT(hr == S_OK);
        }
        hr = VariantClear(&varFilData);
        ASSERT(hr == S_OK);
    }

    pfd->Release();
    return fDShow;
}



// for a TV tuner device, return how many SVideo and Composite inputs there are
//
HRESULT GetInputTypes(IMoniker *pM, DWORD dwIndex, DWORD *pnSVideo, DWORD *pnComposite)
{
    CheckPointer(pnSVideo, E_POINTER);
    CheckPointer(pnComposite, E_POINTER);
    *pnSVideo = *pnComposite = 0;

    HKEY    hDeviceKey  = NULL;
    HKEY    hKey = NULL;
    char    szKey[MAX_PATH + MAX_VERSION + 2];
    BOOL fNotFound = TRUE;
    DWORD dwSize;

    // If we have version info use that to build the key name
    if (g_aDeviceInfo[dwIndex].szDeviceVersion &&
            g_aDeviceInfo[dwIndex].szDeviceVersion[0] != '\0') {
        wsprintf(szKey, "%s, %s",
                g_aDeviceInfo[dwIndex].szDeviceDescription,
                g_aDeviceInfo[dwIndex].szDeviceVersion);
    } else {
        wsprintf(szKey, "%s", g_aDeviceInfo[dwIndex].szDeviceDescription);
    }

    // Open the RTC key
    DWORD dwDisp;
    RegOpenKey(RTCKEYROOT, szRegRTCKey, &hDeviceKey);

    // Check if there already is an RTC key for the current device
    if (hDeviceKey) {
        if (RegOpenKey(hDeviceKey, szKey, &hKey) != ERROR_SUCCESS) {

            // Try again without the version information
            wsprintf(szKey, "%s", g_aDeviceInfo[dwIndex].szDeviceDescription);
            RegOpenKey(hDeviceKey, szKey, &hKey);
        }
    }

    if (hKey) {
        dwSize = sizeof(DWORD);
        LONG l = RegQueryValueEx(hKey, sznSVideo, NULL, NULL, (LPBYTE)pnSVideo, &dwSize);
        if (l == 0) {
            l = RegQueryValueEx(hKey, sznComposite, NULL, NULL, (LPBYTE)pnComposite, &dwSize);
        }
        if (l == 0) {
            fNotFound = FALSE;  // found it in the registry
        }
    }

    // This info is not in the registry.  Take the time to figure it out and
    // put it in the registry.  There may not be a place yet to put it in
    // the registry.  If not, don't make a place for it, you'll mess up
    // other code that reads the registry and assumes the key existing means
    // it's filled with other useful info
    if (fNotFound) {
        CComPtr<IBindCtx> pBC;
        CComPtr<IBaseFilter> pFilter;
        CComPtr<IPin> pPin;
        CComPtr<ICaptureGraphBuilder2> pCGB;
        CComPtr<IAMStreamConfig> pSC;
        CComPtr<IGraphBuilder> pGB;
        if (SUCCEEDED(CreateBindCtx(0, &pBC))) {
            if (SUCCEEDED(pM->BindToObject(pBC, NULL, IID_IBaseFilter,
                                                    (void **)&pFilter))) {
                CoCreateInstance(CLSID_CaptureGraphBuilder2, NULL, CLSCTX_INPROC_SERVER,
                              IID_ICaptureGraphBuilder2, (void **)&pCGB);
                CoCreateInstance(CLSID_FilterGraph, NULL, CLSCTX_INPROC_SERVER,
                              IID_IGraphBuilder, (void **)&pGB);
                if (pGB && pCGB && SUCCEEDED(pCGB->FindPin(pFilter, PINDIR_INPUT,
                            &PIN_CATEGORY_ANALOGVIDEOIN, NULL, FALSE, 0, &pPin))) {

                    // force building the upstream graph for crossbar to work
                    pGB->AddFilter(pFilter, DBGNAME("capture"));
                    pCGB->SetFiltergraph(pGB);
                    pCGB->FindInterface(&PIN_CATEGORY_CAPTURE, NULL, pFilter,
                                        IID_IAMStreamConfig, (void **)&pSC);

                    LONG cInputs = 0;
                    CCrossbar *pCrossbar = new CCrossbar(pPin);
                    if (pCrossbar) {
                        pCrossbar->GetInputCount(&cInputs);
                        LONG  PhysicalType;
                        for (LONG j = 0; j < cInputs; j++) {
                            EXECUTE_ASSERT(S_OK == pCrossbar->GetInputType(j, &PhysicalType));

                            if (PhysicalType == PhysConn_Video_Composite) {
                                (*pnComposite)++;
                            } else if (PhysicalType == PhysConn_Video_SVideo) {
                                (*pnSVideo)++;
                            }
                        }
                        delete pCrossbar;
                    }
                }
            }
        }

        // If there are NO inputs, this is hopefully a device that the old code could handle.
        // Return S_FALSE to not use the DShow handler.  For the Sony EyeCam it had worse
        // perf anyway for some mysterious reason
        if (*pnSVideo + *pnComposite == 0) {
            if (hKey) {
                RegCloseKey(hKey);
            }
            if (hDeviceKey) {
                RegCloseKey(hDeviceKey);
            }
            return S_FALSE;
        }

        if (hKey) {
            dwSize = sizeof(DWORD);
            RegSetValueEx(hKey, sznSVideo, (DWORD)NULL, REG_DWORD,
                                    (LPBYTE)pnSVideo, dwSize);
            RegSetValueEx(hKey, sznComposite, (DWORD)NULL, REG_DWORD,
                                    (LPBYTE)pnComposite, dwSize);
        }
    }

    if (hKey) {
        RegCloseKey(hKey);
    }
    if (hDeviceKey) {
        RegCloseKey(hDeviceKey);
    }

    return S_OK;
}


// duplicate this capture device entry several times, once for each input it has
// (eg 2 SVideo inputs and 3 Comp inputs)
HRESULT CloneDevice(DWORD dwIndex, DWORD nSVideo, DWORD nComposite)
{
    char c[4];

    // !!! run out of array space in g_aDeviceInfo?

    // if there's only 1 input on this card, we don't need to clone it
    if (nSVideo + nComposite <= 1)
        return S_OK;

    // start by modifying the suffix on the entry that already exists
    DWORD dw = dwIndex;
    int len = lstrlenA(g_aDeviceInfo[dw].szDeviceDescription);
    for (DWORD j = 0; j < nSVideo + nComposite; j++) {
        if (dw != dwIndex) {
            g_aDeviceInfo[dw].nDeviceType = g_aDeviceInfo[dwIndex].nDeviceType;
            g_aDeviceInfo[dw].nCaptureMode = g_aDeviceInfo[dwIndex].nCaptureMode;
            g_aDeviceInfo[dw].dwVfWIndex = g_aDeviceInfo[dwIndex].dwVfWIndex;
            g_aDeviceInfo[dw].fHasOverlay = g_aDeviceInfo[dwIndex].fHasOverlay;
            g_aDeviceInfo[dw].fInUse = g_aDeviceInfo[dwIndex].fInUse;
            lstrcpyA(g_aDeviceInfo[dw].szDeviceVersion,
                        g_aDeviceInfo[dwIndex].szDeviceVersion);
            lstrcpyA(g_aDeviceInfo[dw].szDevicePath,
                        g_aDeviceInfo[dwIndex].szDevicePath);
            lstrcpynA(g_aDeviceInfo[dw].szDeviceDescription,
                    g_aDeviceInfo[dwIndex].szDeviceDescription, len + 1);
            dwIndex++;
        }
        if (j < nSVideo) {
            lstrcatA(g_aDeviceInfo[dw].szDeviceDescription, g_szSVideo);
            if (nSVideo > 1) {
                wsprintf(c, "%n", j+1);
                lstrcatA(g_aDeviceInfo[dw].szDeviceDescription, c);
            }
        } else {
            lstrcatA(g_aDeviceInfo[dw].szDeviceDescription, g_szComposite);
            if (nComposite > 1) {
                wsprintf(c, "%n", j-nSVideo+1);
                lstrcatA(g_aDeviceInfo[dw].szDeviceDescription, c);
            }
        }
        dw = dwIndex + 1;
    }

    return S_OK;
}



/****************************************************************************
 *  @doc INTERNAL CDEVENUMFUNCTION
 *
 *  @func HRESULT | GetNumCapDevicesInternal | This method is used to
 *    determine the number of installed capture devices. This number includes
 *    only enabled devices.
 *
 *  @parm PDWORD | pdwNumDevices | Specifies a pointer to a DWORD to receive
 *    the number of installed capture devices.
 *
 *  @parm bool | bRecount | Specifies if a device recount is needed
 *
 *  @rdesc This method returns an HRESULT value that depends on the
 *    implementation of the interface. HRESULT can include one of the
 *    following standard constants, or other values not listed:
 *
 *  @flag E_POINTER | Null pointer argument
 *  @flag NOERROR | No error
 *
 *      @devnote MSDN references:
 *    DirectX 5, DirectX Media, DirectShow, Application Developer's Guide
 *    "Enumerate and Access Hardware Devices in DirectShow Applications"
 ***************************************************************************/
EXTERN_C HRESULT WINAPI GetNumVideoCapDevicesInternal(OUT PDWORD pdwNumDevices,  bool bRecount)
{
    HRESULT Hr = NOERROR;
    DWORD dwDeviceIndex;
    DWORD dwVfWIndex;
    ICreateDevEnum *pCreateDevEnum;
    IEnumMoniker *pEm;
    ULONG cFetched;
    DWORD dwNumVfWDevices;
    IMoniker *pM;
    IPropertyBag *pPropBag = NULL;
    VARIANT var;

    FX_ENTRY("GetNumVideoCapDevicesInternal")

    DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: begin", _fx_));

    EnterCriticalSection (&g_CritSec);

    // Validate input parameters
    ASSERT(pdwNumDevices);
    if (!pdwNumDevices)
    {
            DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: Null pointer argument", _fx_));
            Hr = E_POINTER;
            goto MyExit;
    }

    // If a recount has been requested by setting bRecount TRUE (as after a PNP change, see bug 95766),
    // force a recount in the next if

    // Count the number of VfW capture devices
    if (g_dwNumDevices == (DWORD)-1 || bRecount)
    {

        if (videoGetNumDevs(FALSE))     // FALSE means don't free the list after counting ...
        {
            dprintf("%s: MAX_CAPTURE_DEVICES = %d\n", _fx_,MAX_CAPTURE_DEVICES);
            // Remove bogus Camcorder capture device from list of devices shown to the user
            // The Camcorder driver is a fake capture device used by the MS Office Camcorder
            // to capture screen activity to an AVI file. This not a legit capture device driver
            // and is extremely buggy. We also remove the VfW to WDM mapper.
            for (dwDeviceIndex = 0, dwVfWIndex = 0; dwVfWIndex < MAX_CAPTURE_DEVICES; dwVfWIndex++)
            {
                TCHAR   szDllName[MAX_PATH+2];

                dprintf("%s: dwVfWIndex = %d\n", _fx_, dwVfWIndex);
                g_aDeviceInfo[dwDeviceIndex].nDeviceType = DeviceType_VfW;
                g_aDeviceInfo[dwDeviceIndex].nCaptureMode = CaptureMode_FrameGrabbing;
                g_aDeviceInfo[dwDeviceIndex].dwVfWIndex = dwVfWIndex;
                g_aDeviceInfo[dwDeviceIndex].fHasOverlay = FALSE;
                g_aDeviceInfo[dwDeviceIndex].fInUse = FALSE;
                if (videoCapDriverDescAndVer(dwVfWIndex, g_aDeviceInfo[dwDeviceIndex].szDeviceDescription, MAX_CAPDEV_DESCRIPTION, g_aDeviceInfo[dwDeviceIndex].szDeviceVersion, MAX_CAPDEV_VERSION, szDllName, MAX_PATH))
                {
                    dout(3,g_dwVideoCaptureTraceID, TRCE, "%s:   WARNING: videoCapDriverDescAndVer(dwVfWIndex=%lu) failed", _fx_,dwVfWIndex);
                        // We shouldn't use this device if we can't get any info from it
                        continue;
                }
                if (!lstrcmp(g_aDeviceInfo[dwDeviceIndex].szDeviceDescription, g_szMSOfficeCamcorderDescription) ||
                        !lstrcmpi(szDllName,TEXT("vfwwdm32.dll")) ||      // ignore VfWWDM in enumeration
                        !lstrcmp(g_aDeviceInfo[dwDeviceIndex].szDeviceDescription, g_szVfWToWDMMapperDescription) ||
                        !lstrcmp(g_aDeviceInfo[dwDeviceIndex].szDeviceDescription, g_szVfWToWDMMapperDescription2) ||
                        !lstrcmp(g_aDeviceInfo[dwDeviceIndex].szDeviceDescription, g_szVfWToWDMMapperDescription3) ||
                        !lstrcmp(g_aDeviceInfo[dwDeviceIndex].szDeviceDescription, g_szVfWToWDMMapperDescription4) ||
                            !lstrcmp(g_aDeviceInfo[dwDeviceIndex].szDeviceDescription, g_szVfWToWDMMapperDescription5)
                          //!lstrcmpi(g_aDeviceInfo[dwDeviceIndex].szDeviceDescription, g_szHauppaugeDll)
                            )
                {
                        dout(3,g_dwVideoCaptureTraceID, TRCE, "%s:   WARNING: Removed VfW to WDM mapper or MS Office Bogus capture driver!", _fx_);
                        continue;
                }
                dprintf("GetNumVideoCapDevicesInternal: VfW %d %s\n",dwDeviceIndex, g_aDeviceInfo[dwDeviceIndex].szDeviceDescription);
                dwDeviceIndex++;
            }

            g_dwNumDevices = dwDeviceIndex;

            videoFreeDriverList ();
        }
        else
        {
            g_dwNumDevices = 0UL;
        }

        // First, create a system hardware enumerator
        // This call loads the following DLLs - total 1047 KBytes!!!:
        //   'C:\WINDOWS\SYSTEM\DEVENUM.DLL' = 60 KBytes
        //   'C:\WINDOWS\SYSTEM\RPCRT4.DLL' = 316 KBytes
        //   'C:\WINDOWS\SYSTEM\CFGMGR32.DLL' = 44 KBytes
        //   'C:\WINDOWS\SYSTEM\WINSPOOL.DRV' = 23 KBytes
        //   'C:\WINDOWS\SYSTEM\COMDLG32.DLL' = 180 KBytes
        //   'C:\WINDOWS\SYSTEM\LZ32.DLL' = 24 KBytes
        //   'C:\WINDOWS\SYSTEM\SETUPAPI.DLL' = 400 KBytes
        // According to LonnyM, there's no way to go around SETUPAPI.DLL
        // when dealing with PnP device interfaces....
        if (FAILED(Hr = CoCreateInstance(CLSID_SystemDeviceEnum, NULL, CLSCTX_INPROC_SERVER, IID_ICreateDevEnum, (void**)&pCreateDevEnum)))
        {
            DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: Couldn't create DShow enumerator!", _fx_));
            goto MyError;
        }

        // Second, create an enumerator for a specific type of hardware device: video capture cards only
        //the call below was previously using CDEF_BYPASS_CLASS_MANAGER ... (387796)
        if (FAILED(Hr = pCreateDevEnum->CreateClassEnumerator(CLSID_VideoInputDeviceCategory, &pEm, CDEF_DEVMON_PNP_DEVICE)) || !pEm)
        {
            // try again
            if (FAILED(Hr = pCreateDevEnum->CreateClassEnumerator(CLSID_VideoInputDeviceCategory, &pEm, CDEF_CLASS_DEFAULT)) || !pEm)
            {
                            DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: Couldn't create DShow enumerator!", _fx_));
                            goto MyError;
            }
        }

        // Not needed any more
        pCreateDevEnum->Release();
        pCreateDevEnum = NULL;

        // Third, enumerate the list of WDM capture devices itself
        if (FAILED(Hr = pEm->Reset()))
        {
                DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: Couldn't reset enumerator!", _fx_));
                goto MyError;
        }

        // The new index starts at the end of the VfW capture device indices
        dwDeviceIndex = dwNumVfWDevices = g_dwNumDevices;

        while(Hr = pEm->Next(1, &pM, &cFetched), Hr==S_OK)
        {
            pM->BindToStorage(0, 0, IID_IPropertyBag, (void **)&pPropBag);

            if (pPropBag)
            {

                // Not enough room for this device in our array
                ASSERT(dwDeviceIndex < MAX_CAPTURE_DEVICES);
                if (dwDeviceIndex < MAX_CAPTURE_DEVICES)
                {
                    g_aDeviceInfo[dwDeviceIndex].nDeviceType = DeviceType_WDM;
                    g_aDeviceInfo[dwDeviceIndex].nCaptureMode = CaptureMode_FrameGrabbing;
                    g_aDeviceInfo[dwDeviceIndex].dwVfWIndex = (DWORD)-1;
                    g_aDeviceInfo[dwDeviceIndex].fHasOverlay = FALSE;
                    g_aDeviceInfo[dwDeviceIndex].fInUse = FALSE;

                    // Get friendly name of the device
                    var.vt = VT_BSTR;
                    if ((Hr = pPropBag->Read(L"FriendlyName", &var, 0)) == S_OK)
                    {
                        WideCharToMultiByte(CP_ACP, 0, var.bstrVal, -1, g_aDeviceInfo[dwDeviceIndex].szDeviceDescription, MAX_PATH, 0, 0);
                                SysFreeString(var.bstrVal);
                    }
                    else
                    {
                        // No string...
                        g_aDeviceInfo[dwDeviceIndex].szDeviceDescription[0] = '\0';
                    }

                    // 1 = TV, 2 = DV, 0 = neither
                    int fDShow = IsDShowDevice(pM, pPropBag, dwDeviceIndex);
                    if (fDShow) {
                        // either kind
                        g_aDeviceInfo[dwDeviceIndex].nDeviceType = DeviceType_DShow;
                    }

                    // Make sure this isn't one of the VfW capture devices we've already found
                    for (DWORD dwIndex = 0; dwIndex < dwNumVfWDevices; dwIndex++)
                    {
                        if (!lstrcmp(g_aDeviceInfo[dwDeviceIndex].szDeviceDescription, g_aDeviceInfo[dwIndex].szDeviceDescription))
                        {
                                // We already know about this device
                                    break;
                        }
                    }
                    dprintf("GetNumVideoCapDevicesInternal: WDM %d %s\n",dwDeviceIndex, g_aDeviceInfo[dwDeviceIndex].szDeviceDescription);
                    if (dwIndex == dwNumVfWDevices)
                    {

                        // There's no reg key for version information for WDM devices
                        // @todo Could there be another bag property we could use to get version info for WDM devices?
                        g_aDeviceInfo[dwDeviceIndex].szDeviceVersion[0] = '\0';

                        // Get DevicePath of the device
                        if ((Hr = pPropBag->Read(L"DevicePath", &var, 0)) == S_OK)
                        {
                            WideCharToMultiByte(CP_ACP, 0, var.bstrVal, -1, g_aDeviceInfo[dwDeviceIndex].szDevicePath, MAX_PATH, 0, 0);
                            SysFreeString(var.bstrVal);
                        }
                        else
                        {
                            // No string...
                            g_aDeviceInfo[dwDeviceIndex].szDevicePath[0] = '\0';
                        }

                        // TV devices will look like multiple devices for our sake, one
                        // for each input the card has (eg: composite and SVideo) otherwise
                        // how can the user select which input the camera is plugged into?
                        if (fDShow == 1) {
                            DWORD nSVideo, nComposite;
                            HRESULT hrX = GetInputTypes(pM, dwDeviceIndex, &nSVideo, &nComposite);
                            if (hrX == S_OK) {

                                CloneDevice(dwDeviceIndex, nSVideo, nComposite);
                                dwDeviceIndex += nSVideo + nComposite;
                                g_dwNumDevices += nSVideo + nComposite;
                            } else if (hrX == S_FALSE) {
                                // we're being told not use the DShow handler for this device
                                g_aDeviceInfo[dwDeviceIndex].nDeviceType = DeviceType_WDM;
                                dwDeviceIndex++;;
                                g_dwNumDevices++;
                            }
                        } else {
                            dwDeviceIndex++;
                            g_dwNumDevices++;
                        }
                    }
                }
            }

        pPropBag->Release();
        pM->Release();
        }

        pEm->Release();

        // DV users should re-enumerate.
        extern void ResetDVEnumeration();
        ResetDVEnumeration();
    }
#ifdef DEBUG
    else dprintf("g_dwNumDevices = %lu\n",g_dwNumDevices);
#endif

    // Return the number of capture devices
    *pdwNumDevices = g_dwNumDevices;

    // now add (2) at the end of duplicates ... or (3) or (4) if more than 2 ... ! :)
    { unsigned int i,j,k,same_device[MAX_CAPTURE_DEVICES]; char countbuf[32];
        for(i=0; i<g_dwNumDevices; i++)             //initialize
            same_device[i]=1;
        for(i=0,k=1; i<g_dwNumDevices; i++) {
            if(same_device[i]>1)                    // if it was already counted ...
                continue;                       // ...skip it
            for(j=i+1; j<g_dwNumDevices; j++) {     // for the remaining names up, starting with the next one ...
                if(!lstrcmp(g_aDeviceInfo[i].szDeviceDescription, g_aDeviceInfo[j].szDeviceDescription))
                        same_device[j]= ++k;    // increment the count for a duplicate/triplicate/etc. ...
            }                                       // ... and set its rank in that aux. vector
        }
        for(i=0; i<g_dwNumDevices; i++) {           // the final loop for adding the ' (n)' string at the end of each name
            if(same_device[i]>1) {                  // ...this happening only if that n > 1
                wsprintf(countbuf," (%d)",same_device[i]);
                if(lstrlen(g_aDeviceInfo[i].szDeviceDescription) + lstrlen(countbuf) < MAX_CAPDEV_DESCRIPTION-1)
                    lstrcat(g_aDeviceInfo[i].szDeviceDescription,countbuf);
#ifdef DEBUG
                else    dprintf("Buffer overflow for %s + %s ...\n",g_aDeviceInfo[i].szDeviceDescription,countbuf);
#endif
            }
        }
    }

    if (g_dwNumDevices)
    {
        Hr = S_OK;
    }

#ifdef DEBUG
    dout(1,g_dwVideoCaptureTraceID, TRCE, "%s:   SUCCESS: %ld device(s) found", _fx_, *pdwNumDevices);
    if (*pdwNumDevices)
    {
        for (DWORD dwIndex = 0; dwIndex < *pdwNumDevices; dwIndex++)
        {
            dout(1,g_dwVideoCaptureTraceID, TRCE, "%s:   SUCCESS:   Device %ld (%s): %s", _fx_, dwIndex,((g_aDeviceInfo[dwIndex].nDeviceType == DeviceType_WDM)?"WDM":"VfW"),g_aDeviceInfo[dwIndex].szDeviceDescription);
        }
    }
#endif

    goto MyExit;

MyError:
    if (pCreateDevEnum)
        pCreateDevEnum->Release();
MyExit:
    DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: end", _fx_));

    LeaveCriticalSection (&g_CritSec);
    return Hr;
}

/****************************************************************************
 *  @doc INTERNAL CDEVENUMFUNCTION
 *
 *  @func HRESULT | GetCapDeviceInfo | This method is used to
 *    retrieve information about a capture device.
 *
 *  @parm DWORD | dwDeviceIndex | Specifies the device index of the capture
 *    device to return information about.
 *
 *  @parm PDEVICEINFO | pDeviceInfo | Specifies a pointer to a <t VIDEOCAPTUREDEVICEINFO>
 *    structure to receive information about a capture device.
 *
 *  @rdesc This method returns an HRESULT value that depends on the
 *    implementation of the interface. HRESULT can include one of the
 *    following standard constants, or other values not listed:
 *
 *  @flag E_FAIL | Failure
 *  @flag E_INVALIDARG | Invalid argument
 *  @flag VFW_E_NO_CAPTURE_HARDWARE | No Capture hardware is available
 *  @flag E_POINTER | Null pointer argument
 *  @flag NOERROR | No error
 ***************************************************************************/
VIDEOAPI GetVideoCapDeviceInfo(IN DWORD dwDeviceIndex, OUT PDEVICEINFO pDeviceInfo)
{
        HRESULT Hr = NOERROR;
        DWORD dwNumDevices = 0;

        FX_ENTRY("GetVideoCapDeviceInfo")

        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: begin", _fx_));

    EnterCriticalSection (&g_CritSec);

        // Validate input parameters
        ASSERT(pDeviceInfo);
        if (!pDeviceInfo || !pDeviceInfo->szDeviceDescription || !pDeviceInfo->szDeviceVersion)
        {
                DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: Null pointer argument", _fx_));
                Hr = E_POINTER;
                goto MyExit;
        }

        // Get the number of installed and enabled capture devices
        if (FAILED(Hr = GetNumVideoCapDevicesInternal(&dwNumDevices,FALSE)))
        {
                DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: Couldn't get number of installed devices!", _fx_));
                Hr = VFW_E_NO_CAPTURE_HARDWARE;
                goto MyExit;
        }

        // Validate index passed in
        ASSERT(dwDeviceIndex < dwNumDevices);
        if (!(dwDeviceIndex < dwNumDevices))
        {
                DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: Invalid argument", _fx_));
                Hr = E_INVALIDARG;
                goto MyExit;
        }

        // Grab the description and version info
        CopyMemory(pDeviceInfo, &g_aDeviceInfo[dwDeviceIndex], sizeof(VIDEOCAPTUREDEVICEINFO));

        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s:   SUCCESS: Desc: %s - Ver: %s", _fx_, pDeviceInfo->szDeviceDescription, pDeviceInfo->szDeviceVersion[0] != '\0' ? pDeviceInfo->szDeviceVersion : "Unknown"));

MyExit:
        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: end", _fx_));

    LeaveCriticalSection (&g_CritSec);
        return Hr;
}

/****************************************************************************
 *  @doc INTERNAL CDEVENUMMETHOD
 *
 *  @mfunc HRESULT | CTAPIVCap | GetNumDevices | This method is used to
 *    determine the number of installed capture devices. This number includes
 *    only enabled devices.
 *
 *  @parm PDWORD | pdwNumDevices | Specifies a pointer to a DWORD to receive
 *    the number of installed capture devices.
 *
 *  @rdesc This method returns an HRESULT value that depends on the
 *    implementation of the interface. HRESULT can include one of the
 *    following standard constants, or other values not listed:
 *
 *  @flag E_POINTER | Null pointer argument
 *  @flag NOERROR | No error
 ***************************************************************************/
HRESULT CTAPIVCap::GetNumDevices(OUT PDWORD pdwNumDevices)
{
        return GetNumVideoCapDevicesInternal(pdwNumDevices,FALSE);
}

/****************************************************************************
 *  @doc INTERNAL CDEVENUMMETHOD
 *
 *  @mfunc HRESULT | CTAPIVCap | GetDeviceInfo | This method is used to
 *    retrieve information about a capture device.
 *
 *  @parm DWORD | dwDeviceIndex | Specifies the device index of the capture
 *    device to return information about.
 *
 *  @parm PDEVICEINFO | pDeviceInfo | Specifies a pointer to a <t VIDEOCAPTUREDEVICEINFO>
 *    structure to receive information about a capture device.
 *
 *  @rdesc This method returns an HRESULT value that depends on the
 *    implementation of the interface. HRESULT can include one of the
 *    following standard constants, or other values not listed:
 *
 *  @flag E_FAIL | Failure
 *  @flag E_INVALIDARG | Invalid argument
 *  @flag E_POINTER | Null pointer argument
 *  @flag NOERROR | No error
 ***************************************************************************/
HRESULT CTAPIVCap::GetDeviceInfo(IN DWORD dwDeviceIndex, OUT PDEVICEINFO pDeviceInfo)
{
        return GetVideoCapDeviceInfo(dwDeviceIndex, pDeviceInfo);
}

/****************************************************************************
 *  @doc INTERNAL CDEVENUMMETHOD
 *
 *  @mfunc HRESULT | CTAPIVCap | GetCurrentDevice | This method is used to
 *    determine the index of the capture device currently used.
 *
 *  @parm PDWORD | pdwDeviceIndex | Specifies a pointer to a DWORD to receive
 *    the index of the capture device currently used.
 *
 *  @rdesc This method returns an HRESULT value that depends on the
 *    implementation of the interface. HRESULT can include one of the
 *    following standard constants, or other values not listed:
 *
 *  @flag E_FAIL | Failure
 *  @flag E_POINTER | Null pointer argument
 *  @flag VFW_E_NO_CAPTURE_HARDWARE | No Capture hardware is available
 *  @flag NOERROR | No error
 ***************************************************************************/
HRESULT CTAPIVCap::GetCurrentDevice(OUT DWORD *pdwDeviceIndex)
{
        HRESULT Hr = NOERROR;
        DWORD dwNumDevices;

        FX_ENTRY("CTAPIVCap::GetCurrentDevice")

        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: begin", _fx_));

        // Validate input parameters
        ASSERT(pdwDeviceIndex);
        if (!pdwDeviceIndex)
        {
                DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: Null pointer argument", _fx_));
                Hr = E_POINTER;
                goto MyExit;
        }

        // Is there already a current capture device?
        if ((g_dwNumDevices == (DWORD)-1) || (m_dwDeviceIndex == -1))
        {
                // Use default capture devices - make sure we have at least one device first!
                if (FAILED(Hr = GetNumDevices(&dwNumDevices)))
                {
                        DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: Couldn't get number of installed devices", _fx_));
                        Hr = VFW_E_NO_CAPTURE_HARDWARE;
                        goto MyExit;
                }

                // If we have some devices then return the first device enumerated
                if (dwNumDevices)
                        *pdwDeviceIndex = m_dwDeviceIndex = 0;
                else
                {
                        DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: No device installed", _fx_));
                        Hr = E_FAIL;
                }
        }
        else
        {
                // Return the current capture device
                *pdwDeviceIndex = m_dwDeviceIndex;
        }

MyExit:
        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: end", _fx_));
        return Hr;
}

/****************************************************************************
 *  @doc INTERNAL CDEVENUMMETHOD
 *
 *  @mfunc HRESULT | CTAPIVCap | SetCurrentDevice | This method is used to
 *    specify the index of the capture device to use.
 *
 *  @parm DWORD | dwDeviceIndex | Specifies the index of the capture device
 *    to use.
 *
 *  @rdesc This method returns an HRESULT value that depends on the
 *    implementation of the interface. HRESULT can include one of the
 *    following standard constants, or other values not listed:
 *
 *  @flag E_FAIL | Failure
 *  @flag E_INVALIDARG | Invalid argument
 *  @flag VFW_E_NOT_STOPPED | Need to stop this filter first
 *  @flag VFW_E_NO_CAPTURE_HARDWARE | No Capture hardware is available
 *  @flag NOERROR | No error
 ***************************************************************************/
HRESULT CTAPIVCap::SetCurrentDevice(IN DWORD dwDeviceIndex)
{
        HRESULT Hr = NOERROR;
        DWORD dwNumDevices;

        FX_ENTRY("CTAPIVCap::SetCurrentDevice")

        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: begin", _fx_));
        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s:   Setting m_dwDeviceIndex to %d", _fx_, dwDeviceIndex));
        // Validate input parameters
        if (FAILED(Hr = GetNumDevices(&dwNumDevices)))
        {
                DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: Couldn't get number of installed devices", _fx_));
                Hr = VFW_E_NO_CAPTURE_HARDWARE;
                goto MyExit;
        }
        dprintf("dwDeviceIndex = %lu, dwNumDevices = %lu, g_dwNumDevices = %lu\n",dwDeviceIndex , dwNumDevices ,g_dwNumDevices);
        ASSERT(dwDeviceIndex < dwNumDevices);
        if (!(dwDeviceIndex < dwNumDevices))
        {
                DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: Invalid argument", _fx_));
                Hr = E_INVALIDARG;
                goto MyExit;
        }
        ASSERT(m_State == State_Stopped);
        if (m_State != State_Stopped)
        {
                DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: Need to stop this filter first", _fx_));
                Hr = VFW_E_NOT_STOPPED;
                goto MyExit;
        }

        // Set the current device
        m_dwDeviceIndex = dwDeviceIndex;

MyExit:
        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: end", _fx_));
        return Hr;
}
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\net\tapi\skywalker\filters\video\tapivcap\dbgxtra.h ===
//#define XTRA_TRACE -- moved in ...\skywalker\filters\filters.inc

#ifdef XTRA_TRACE

    #define XDBGONLY
    #define XDBG

    #define INIT_TICKS      LARGE_INTEGER liTicks;  \
                            LARGE_INTEGER liTicks1
    #define BEGIN_TICK QueryPerformanceCounter(&liTicks)
    #define END_TICK   QueryPerformanceCounter(&liTicks1)
    #define LOG_TICK(msg)   Log(TEXT(msg), ClockDiff(liTicks1, liTicks),0,0)
    #define END_LOG_TICK(msg)       QueryPerformanceCounter(&liTicks1);     \
                                                            Log(TEXT(msg), ClockDiff(liTicks1, liTicks),0,0)
    #define MARK_LOG_TICK(msg)              QueryPerformanceCounter(&liTicks1);                             \
                                                                    Log(TEXT(msg), ClockDiff(liTicks1, liTicks),0,0);   \
                                                                    QueryPerformanceCounter(&liTicks)
    #define HEAPCHK(msg)            SimpleHeapCheck(msg)
    #define LOG_MSG_VAL(msg,val,p,s)    Log(msg,(val),(p),(s))                                  


#undef ACLASS
#ifdef __WRKRTHD__
#define ACLASS
#else
#define ACLASS extern
#endif

extern "C" {

    ACLASS int MyDbgPrint(LPCSTR lpszFormat, IN ...);
    ACLASS int MyDbgPuts(LPCSTR lpszMsg);

    ACLASS inline int ClockDiff(
        LARGE_INTEGER &liNewTick, 
        LARGE_INTEGER &liOldTick
        );

    ACLASS void Log(
        TCHAR * pszMessage,
        DWORD dw,
        DWORD p,
        DWORD s
    );

    ACLASS void DumpLog();
    ACLASS void SimpleHeapCheck(char *pszMsg);
    ACLASS int FillPattern(char *Area, DWORD size, DWORD FillPow2, LPCSTR lpszFormat, IN ...);

}       // extern "C"


#else
    #define SLSH(a)    a##/
    #define XDBGONLY SLSH(/)
    #define XDBG SLSH(/)

    #define INIT_TICKS
    #define BEGIN_TICK
    #define END_TICK
    #define LOG_TICK(msg)
    #define END_LOG_TICK(msg)
    #define MARK_LOG_TICK(msg)      

    #define HEAPCHK(msg)
    #define LOG_MSG_VAL(msg,val,p,s)
#endif  //XTRA_TRACE
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\net\tapi\skywalker\filters\video\tapivcap\devicep.h ===
/****************************************************************************
 *  @doc INTERNAL DEVICEP
 *
 *  @module DeviceP.h | Header file for the <c CDeviceProperties>
 *    class used to implement a property page to test the <i IAMVfwCaptureDialogs>
 *    and <i IVideoDeviceControl> interfaces.
 *
 *  @comm This code tests the TAPI Capture Filter <i IVideoDeviceControl>
 *    and <i IAMVfwCaptureDialogs> implementations. This code is only compiled
 *    if USE_PROPERTY_PAGES is defined.
 ***************************************************************************/

#ifndef _DEVICEP_H_
#define _DEVICEP_H_

#ifdef USE_PROPERTY_PAGES

/****************************************************************************
 *  @doc INTERNAL CDEVICEPCLASS
 *
 *  @class CDeviceProperties | This class implements a property page
 *    to test the new TAPI internal interface <i IVideoDeviceControl>.
 *
 *  @mdata IVideoDeviceControl* | CDeviceProperties | m_pIVideoDeviceControl | Pointer
 *    to the <i IVideoDeviceControl> interface.
 *
 *  @mdata IAMVfwCaptureDialogs* | CDeviceProperties | m_pIAMVfwCaptureDialogs | Pointer
 *    to the <i IAMVfwCaptureDialogs> interface.
 *
 *  @comm This code tests the TAPI Capture Pin <i IVideoDeviceControl>
 *    implementation. This code is only compiled if USE_PROPERTY_PAGES is
 *    defined.
 ***************************************************************************/
class CDeviceProperties : public CBasePropertyPage
{
	public:
	CDeviceProperties(LPUNKNOWN pUnk, HRESULT *pHr);
	~CDeviceProperties();


	HRESULT OnConnect(IUnknown *pUnk);
	HRESULT OnDisconnect();
	BOOL    OnReceiveMessage(HWND hWnd, UINT uMsg, WPARAM wParam, LPARAM lParam);

	private:
	IVideoDeviceControl *m_pIVideoDeviceControl;
	IAMVfwCaptureDialogs *m_pIAMVfwCaptureDialogs;

	DWORD m_dwOriginalDeviceIndex;
	DWORD m_dwCurrentDeviceIndex;
};

#endif // USE_PROPERTY_PAGES

#endif // _DEVICEP_H_
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\net\tapi\skywalker\filters\video\tapivcap\device.cpp ===
/****************************************************************************
 *  @doc INTERNAL DEVICE
 *
 *  @module Device.cpp | Source file for the <c CCapDev>
 *    base class used to communicate with the capture device.
 ***************************************************************************/

#include "Precomp.h"

#define DEVICE_DEBUG
#if defined(DEBUG) && defined(DEVICE_DEBUG)

  #include <stdio.h>
  #include <stdarg.h>

  static int dprintf( char * format, ... )
  {
      char out[1024];
      int r;
      va_list marker;
      va_start(marker, format);
      r=_vsnprintf(out, 1022, format, marker);
      va_end(marker);
      OutputDebugString( out );
      return r;
  }

#else
  #undef DEVICE_DEBUG

  #define dprintf ; / ## /
#endif



const WORD aiBitDepth[NUM_BITDEPTH_ENTRIES] = {0, 0, 9, 12, 12, 16, 16, 16, 24, 4, 8};
const DWORD aiFormat[NUM_BITDEPTH_ENTRIES] = {  VIDEO_FORMAT_NUM_COLORS_MSH263,
                                                VIDEO_FORMAT_NUM_COLORS_MSH261,
                                                VIDEO_FORMAT_NUM_COLORS_YVU9,
                                                VIDEO_FORMAT_NUM_COLORS_I420,
                                                VIDEO_FORMAT_NUM_COLORS_IYUV,
                                                VIDEO_FORMAT_NUM_COLORS_YUY2,
                                                VIDEO_FORMAT_NUM_COLORS_UYVY,
                                                VIDEO_FORMAT_NUM_COLORS_65536,
                                                VIDEO_FORMAT_NUM_COLORS_16777216,
                                                VIDEO_FORMAT_NUM_COLORS_16,
                                                VIDEO_FORMAT_NUM_COLORS_256};
const DWORD aiFourCCCode[NUM_BITDEPTH_ENTRIES] = {
                                                VIDEO_FORMAT_MSH263,
                                                VIDEO_FORMAT_MSH261,
                                                VIDEO_FORMAT_YVU9,
                                                VIDEO_FORMAT_I420,
                                                VIDEO_FORMAT_IYUV,
                                                VIDEO_FORMAT_YUY2,
                                                VIDEO_FORMAT_UYVY,
                                                VIDEO_FORMAT_BI_RGB,
                                                VIDEO_FORMAT_BI_RGB,
                                                VIDEO_FORMAT_BI_RGB,
                                                VIDEO_FORMAT_BI_RGB};
const DWORD aiClrUsed[NUM_BITDEPTH_ENTRIES] = {0, 0, 0, 0, 0, 0, 0, 0, 0, 16, 256};

const MYFRAMESIZE awResolutions[VIDEO_FORMAT_NUM_RESOLUTIONS] =
{
        { VIDEO_FORMAT_IMAGE_SIZE_176_144, 176, 144 },
        { VIDEO_FORMAT_IMAGE_SIZE_128_96, 128, 96 },
        { VIDEO_FORMAT_IMAGE_SIZE_352_288, 352, 288 },
        { VIDEO_FORMAT_IMAGE_SIZE_160_120, 160, 120 },
        { VIDEO_FORMAT_IMAGE_SIZE_320_240, 320, 240 },
        { VIDEO_FORMAT_IMAGE_SIZE_240_180, 240, 180 }
};

/****************************************************************************
 *  @doc INTERNAL CCAPDEVMETHOD
 *
 *  @mfunc void | CCapDev | CCapDev | This method is the constructor
 *    for the <c CCapDev> object.
 *
 *  @rdesc Nada.
 ***************************************************************************/
CCapDev::CCapDev(IN TCHAR *pObjectName, IN CTAPIVCap *pCaptureFilter, IN LPUNKNOWN pUnkOuter, IN DWORD dwDeviceIndex, IN HRESULT *pHr) : CUnknown(pObjectName, pUnkOuter, pHr)
{
        FX_ENTRY("CCapDev::CCapDev")

        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: begin", _fx_));

        // Validate input parameters
        ASSERT(pHr);
        ASSERT(pCaptureFilter);
        if (!pCaptureFilter || !pHr)
        {
                DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: Null pointer argument", _fx_));
                if (pHr)
                        *pHr = E_POINTER;
                goto MyExit;
        }

        // Capture device caps
        m_dwDialogs = m_dwImageSize = m_dwFormat = 0UL;
        m_dwStreamingMode = FRAME_GRAB_LARGE_SIZE;
        m_pCaptureFilter = pCaptureFilter;

        // Configuration dialogs
        m_fDialogUp = FALSE;

        // Save device index
        m_dwDeviceIndex = dwDeviceIndex;
        ZeroMemory(&m_vcdi, sizeof(m_vcdi));
        m_bCached_vcdi = FALSE;
        // Camera control - for sotware-only implementation
        m_lCCPan = 0;
        m_lCCTilt = 0;
        m_lCCZoom = 10;

MyExit:
        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: end", _fx_));
}

/****************************************************************************
 *  @doc INTERNAL CCAPDEVMETHOD
 *
 *  @mfunc void | CCapDev | ~CCapDev | This method is the destructor
 *    for the <c CCapDev> object.
 *
 *  @rdesc Nada.
 ***************************************************************************/
CCapDev::~CCapDev()
{
        FX_ENTRY("CCapDev::~CCapDev")

        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: begin", _fx_));

        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: end", _fx_));
}

/****************************************************************************
 *  @doc INTERNAL CCAPDEVMETHOD
 *
 *  @mfunc HRESULT | CCapDev | NonDelegatingQueryInterface | This
 *    method is the nondelegating interface query function. It returns a pointer
 *    to the specified interface if supported. The only interfaces explicitly
 *    supported being <i IAMVfWCaptureDialogs>.
 *
 *  @parm REFIID | riid | Specifies the identifier of the interface to return.
 *
 *  @parm PVOID* | ppv | Specifies the place in which to put the interface
 *    pointer.
 *
 *  @rdesc This method returns an HRESULT value that depends on the
 *    implementation of the interface. HRESULT can include one of the
 *    following standard constants, or other values not listed:
 *
 *  @flag E_FAIL | Failure
 *  @flag E_POINTER | Null pointer argument
 *  @flag NOERROR | No error
 ***************************************************************************/
STDMETHODIMP CCapDev::NonDelegatingQueryInterface(IN REFIID riid, OUT void **ppv)
{
        HRESULT Hr = NOERROR;

        FX_ENTRY("CCapDev::NonDelegatingQueryInterface")

        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: begin", _fx_));

        // Validate input parameters
        ASSERT(ppv);
        if (!ppv)
        {
                DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: invalid input parameter", _fx_));
                Hr = E_POINTER;
                goto MyExit;
        }

        // Retrieve interface pointer
        if (riid == __uuidof(IAMVfwCaptureDialogs))
        {
            *ppv = static_cast<IAMVfwCaptureDialogs*>(this);
            GetOwner()->AddRef();
                DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s:   SUCCESS: IAMVfwCaptureDialogs*=0x%08lX", _fx_, *ppv));
                goto MyExit;
        }
        else if (riid == __uuidof(IVideoProcAmp))
        {
            *ppv = static_cast<IVideoProcAmp*>(this);
            GetOwner()->AddRef();
                DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s:   SUCCESS: IVideoProcAmp*=0x%08lX", _fx_, *ppv));
                goto MyExit;
        }
        else if (riid == __uuidof(ICameraControl))
        {
            *ppv = static_cast<ICameraControl*>(this);
            GetOwner()->AddRef();
                DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s:   SUCCESS: ICameraControl*=0x%08lX", _fx_, *ppv));
                goto MyExit;
        }
        else if (FAILED(Hr = CUnknown::NonDelegatingQueryInterface(riid, ppv)))
        {
                DBGOUT((g_dwVideoCaptureTraceID, WARN, "%s:   WARNING: NDQI for {%08lX-%04lX-%04lX-%02lX%02lX-%02lX%02lX%02lX%02lX%02lX%02lX} failed Hr=0x%08lX", _fx_, riid.Data1, riid.Data2, riid.Data3, riid.Data4[0], riid.Data4[1], riid.Data4[2], riid.Data4[3], riid.Data4[4], riid.Data4[5], riid.Data4[6], riid.Data4[7], Hr));
        }
        else
        {
                DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s:   SUCCESS: {%08lX-%04lX-%04lX-%02lX%02lX-%02lX%02lX%02lX%02lX%02lX%02lX}*=0x%08lX", _fx_, riid.Data1, riid.Data2, riid.Data3, riid.Data4[0], riid.Data4[1], riid.Data4[2], riid.Data4[3], riid.Data4[4], riid.Data4[5], riid.Data4[6], riid.Data4[7], *ppv));
        }

MyExit:
        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: end", _fx_));
        return Hr;
}

/*****************************************************************************
 *  @doc INTERNAL CCAPDEVMETHOD
 *
 *  @mfunc HRESULT | CCapDev | GetFormatsFromRegistry | This method is
 *    used to retrieve from the registry the list of formats supported by the
 *    capture device.
 *
 *  @rdesc This method returns an HRESULT value that depends on the
 *    implementation of the interface. HRESULT can include one of the
 *    following standard constants, or other values not listed:
 *
 *  @flag E_FAIL | Failure
 *  @flag E_UNEXPECTED | Unrecoverable error
 *  @flag NOERROR | No error
 ****************************************************************************/
HRESULT CCapDev::GetFormatsFromRegistry()
{
        HRESULT Hr = NOERROR;
        HKEY    hMainDeviceKey = NULL;  // this is the szRegDeviceKey having the database that NM setup creates
        HKEY    hPrivDeviceKey = NULL;  // this is the szRegCaptureDefaultKey that NM uses to store some profile results (the default mode)
        HKEY    hRTCDeviceKey  = NULL;  // this is the newly added szRegRTCKey used by RTCClient to store its profile results
        HKEY    hKey = NULL;
        DWORD   dwSize, dwType;
        char    szKey[MAX_PATH + MAX_VERSION + 2];

        bool bIsKeyUnderPriv = FALSE;

        FX_ENTRY("CCapDev::GetFormatsFromRegistry")

        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: begin", _fx_));

        // Set default values
        m_dwImageSize = m_dwFormat = (DWORD)NULL;
        m_dwStreamingMode = FRAME_GRAB_LARGE_SIZE;
        m_dwDialogs = FORMAT_DLG_OFF | SOURCE_DLG_ON;
        m_dwFormat = 0;

        // Based on the name and version number of the driver, get capabilities.
        // We first try to look them up from the registry. If this is a very popular
        // board/camera, chances are that we have set the key at install time already.
        // If we can't find the key, we'll profile the hardware and save the results
        // to the registry.

    // If we have version info use that to build the key name
    if (g_aDeviceInfo[m_dwDeviceIndex].szDeviceVersion && g_aDeviceInfo[m_dwDeviceIndex].szDeviceVersion[0] != '\0')
    {
        wsprintf(szKey, "%s, %s", g_aDeviceInfo[m_dwDeviceIndex].szDeviceDescription, g_aDeviceInfo[m_dwDeviceIndex].szDeviceVersion);
    }
    else
    {
        wsprintf(szKey, "%s", g_aDeviceInfo[m_dwDeviceIndex].szDeviceDescription);
    }
    dprintf("%s: camera key: %s\n", _fx_,szKey);

    // *** PRIVATE KEY ***
    dprintf("%s: Trying under the Private key %s\n", _fx_,szRegCaptureDefaultKey);

    // Check if the priv key is there
    if (RegOpenKey(HKEY_LOCAL_MACHINE, szRegCaptureDefaultKey, &hPrivDeviceKey) != ERROR_SUCCESS)
    {
            DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: Can't find private key!", _fx_));
    }
    else
    {
        // Check if there is already is an NM profile key for the current device
        if (RegOpenKey(hPrivDeviceKey, szKey, &hKey) != ERROR_SUCCESS)
        {
            // Try again without the version information
            if (g_aDeviceInfo[m_dwDeviceIndex].szDeviceVersion && g_aDeviceInfo[m_dwDeviceIndex].szDeviceVersion[0] != '\0')
                {
                        wsprintf(szKey, "%s", g_aDeviceInfo[m_dwDeviceIndex].szDeviceDescription);
                        if (RegOpenKey(hPrivDeviceKey, szKey, &hKey) != ERROR_SUCCESS)
                        {
                                DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: Can't find priv device reg key!", _fx_));
                        }
                        else
                        {
                                RegCloseKey(hKey),  hKey = NULL;
                                bIsKeyUnderPriv=TRUE;
                        }
                }
        }
        else
        {
            RegCloseKey(hKey),  hKey = NULL;
            bIsKeyUnderPriv=TRUE;
        }
        RegCloseKey(hPrivDeviceKey),  hPrivDeviceKey = NULL;
    }


    if(!bIsKeyUnderPriv)
    {

        // *** MAIN KEY ***
        dprintf("%s: Trying under the Main key %s\n", _fx_,szRegDeviceKey);

        if (g_aDeviceInfo[m_dwDeviceIndex].szDeviceVersion && g_aDeviceInfo[m_dwDeviceIndex].szDeviceVersion[0] != '\0')
        {
            wsprintf(szKey, "%s, %s", g_aDeviceInfo[m_dwDeviceIndex].szDeviceDescription, g_aDeviceInfo[m_dwDeviceIndex].szDeviceVersion);
        }
        else
        {
            wsprintf(szKey, "%s", g_aDeviceInfo[m_dwDeviceIndex].szDeviceDescription);
        }

        // Check if the main capture devices key is there
        if (RegOpenKey(HKEY_LOCAL_MACHINE, szRegDeviceKey, &hMainDeviceKey) != ERROR_SUCCESS)
        {
                DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: Can't find main reg key - trying RTC key!", _fx_));
                goto TryRTCKey;
        }

        // Check if there is already is an official key for the current device
        if (RegOpenKey(hMainDeviceKey, szKey, &hKey) != ERROR_SUCCESS)
        {
            // Try again without the version information
            if (g_aDeviceInfo[m_dwDeviceIndex].szDeviceVersion && g_aDeviceInfo[m_dwDeviceIndex].szDeviceVersion[0] != '\0')
                {
                        wsprintf(szKey, "%s", g_aDeviceInfo[m_dwDeviceIndex].szDeviceDescription);
                        if (RegOpenKey(hMainDeviceKey, szKey, &hKey) != ERROR_SUCCESS)
                        {
                                DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: Can't find main device reg key - trying RTC key!", _fx_));
                                RegCloseKey(hMainDeviceKey), hMainDeviceKey = NULL;
                                goto TryRTCKey;
                        }
                }
                else
                {
                        RegCloseKey(hMainDeviceKey), hMainDeviceKey = NULL;
                        goto TryRTCKey;
                }
        }

        goto GetValuesFromKeys;
    }

TryRTCKey:
    // *** RTC KEY ***
    dprintf("%s: Trying under the RTC key %s\n", _fx_,szRegRTCKey);

    if (g_aDeviceInfo[m_dwDeviceIndex].szDeviceVersion && g_aDeviceInfo[m_dwDeviceIndex].szDeviceVersion[0] != '\0')
    {
        wsprintf(szKey, "%s, %s", g_aDeviceInfo[m_dwDeviceIndex].szDeviceDescription, g_aDeviceInfo[m_dwDeviceIndex].szDeviceVersion);
    }
    else
    {
        wsprintf(szKey, "%s", g_aDeviceInfo[m_dwDeviceIndex].szDeviceDescription);
    }

    // Check if the RTC  key is there
    if (RegOpenKey(RTCKEYROOT, szRegRTCKey, &hRTCDeviceKey) != ERROR_SUCCESS)
    {
            DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: Can't find RTC key!", _fx_));
            Hr = E_FAIL;
            goto MyExit;
    }

    // Check if there already is an RTC key for the current device
    if (RegOpenKey(hRTCDeviceKey, szKey, &hKey) != ERROR_SUCCESS)
    {
        // Try again without the version information
        if (g_aDeviceInfo[m_dwDeviceIndex].szDeviceVersion && g_aDeviceInfo[m_dwDeviceIndex].szDeviceVersion[0] != '\0')
            {
            wsprintf(szKey, "%s", g_aDeviceInfo[m_dwDeviceIndex].szDeviceDescription);
                    if (RegOpenKey(hRTCDeviceKey, szKey, &hKey) != ERROR_SUCCESS)
                    {
                            DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: Can't find RTC device reg key!", _fx_));
                            Hr = E_FAIL;
                            goto MyError0;
                    }
            }
            else
            {
                    Hr = E_FAIL;
                    goto MyError0;
            }
    }

GetValuesFromKeys:

        // Get values from the Main key if the Private key is not there; otherwise try the RTC key
        // Get the values stored in the key choosen above: should be one of Main or RTC
        // if the values below are not found (testing the existence of the 1st would be enough), that means the key has
        // been created, but without the profiled values
        // [ so far this could happen in only one case: the camera is a Sony Motion Eye camera, and the key already stores
        // the DoNotUseDShow value set in DevEnum.cpp = IsDShowDevice function, but nothing else ; see that function for more
        // comments/explanations related to WinSE #28804 ]
        dwSize = sizeof(DWORD);
        if(RegQueryValueEx(hKey, (LPTSTR)szRegdwImageSizeKey, NULL, &dwType, (LPBYTE)&m_dwImageSize, &dwSize) != ERROR_SUCCESS)
        {
                Hr = E_FAIL;
                goto NotFullyProfiledYet;

        }
        dwSize = sizeof(DWORD);
        RegQueryValueEx(hKey, (LPTSTR)szRegdwNumColorsKey, NULL, &dwType, (LPBYTE)&m_dwFormat, &dwSize);
        dwSize = sizeof(DWORD);
        m_dwStreamingMode = FRAME_GRAB_LARGE_SIZE;
        RegQueryValueEx(hKey, (LPTSTR)szRegdwStreamingModeKey, NULL, &dwType, (LPBYTE)&m_dwStreamingMode, &dwSize);
        dwSize = sizeof(DWORD);
        m_dwDialogs = FORMAT_DLG_OFF | SOURCE_DLG_ON;
        RegQueryValueEx(hKey, (LPTSTR)szRegdwDialogsKey, NULL, &dwType, (LPBYTE)&m_dwDialogs, &dwSize);

        // Check dwNumColors to figure out if we need to read the palettes too
        if (m_dwFormat & VIDEO_FORMAT_NUM_COLORS_16)
        {
                // @todo If this is a QuickCam device you may have to use a hardcoded
                // palette instead of the one provided by the device
        }

NotFullyProfiledYet:
        // Close the registry keys
        if (hKey)
                RegCloseKey(hKey);

MyError0:
        if (hRTCDeviceKey)
                RegCloseKey(hRTCDeviceKey);
        if (hMainDeviceKey)
                RegCloseKey(hMainDeviceKey);
MyExit:
        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: end", _fx_));
        return Hr;
}

/****************************************************************************
 *  @doc INTERNAL CCAPDEVMETHOD
 *
 *  @mfunc HRESULT | CCapDev | ProfileCaptureDevice | This method is used to
 *    determine the list of formats supported by the capture device.
 *
 *  @rdesc This method returns an HRESULT value that depends on the
 *    implementation of the interface. HRESULT can include one of the
 *    following standard constants, or other values not listed:
 *
 *  @flag E_FAIL | Failure
 *  @flag E_UNEXPECTED | Unrecoverable error
 *  @flag NOERROR | No error
 *
 *  @comm If there is no entry for the VfW capture device in the list
 *    maintained by the TAPI MSP Video Capture filter, the TAPI MSP Video
 *    Capture filter will first query the capture device for its current
 *    video capture format, and save this information in case the following
 *    steps result in a crash.
 *
 *    Then, the TAPI MSP Video Capture filter applies a set of preferred
 *    formats on the capture device using SendDriverMessage with the
 *    DVM_FORMAT message. For each applied format, the TAPI MSP Video
 *    Capture filter will not only verify the return code of the
 *    SendDriverMessage, but also query back the current format to make
 *    sure the set format operation really succeeded. If the capture device
 *    fails one of the two previous steps, the TAPI MSP Video Capture
 *    filter will assume that the format is not supported. Once the TAPI
 *    MSP Video Capture filter is done with the entire list of preferred
 *    formats and no crash occurred, the list of video formats supported by
 *    the capture device is added to the list maintained by the TAPI MSP
 *    Video Capture filter.
 *
 *    As soon as the enumeration process succeeds for one "small" (128x96
 *    or 160x120), one "medium" (176x144 or 160x120), one "large" (352x288
 *    or 320x240) and one "very large" size (704x576 or 640x480), the TAPI
 *    MSP Video Capture filter stops the enumeration process and adds the
 *    resulting list of formats to its database. The TAPI MSP Video Capture
 *    filter will test the previous sizes for I420, IYUV, YUY2, UYVY, YVU9,
 *    RGB16, RGB24, RGB8, and RGB4 formats, in this described order.
 *
 *    The device will also be marked as a frame-grabbing device in the TAPI
 *    MSP Video Capture filter device database.
 *
 *    If there is an entry for the VfW capture device in the list maintained
 *    by the TAPI MSP Video Capture filter, the TAPI MSP Video Capture
 *    filter first verifies if the information contained is a complete list
 *    of supported formats, or only a default format. The entry will only
 *    contain a default format if the capture device did not support any of
 *    the preferred formats, or a crash occurred during the enumeration process.
 *
 *    If there is only a default format stored for the VfW capture device,
 *    the TAPI MSP Video Capture filter will build a list of media types that
 *    can be built from the default format using black-banding and/or cropping.
 *    If the default format is in a compressed format, the TAPI MSP Video
 *    Capture filter will try and locate and ICM driver that can do the
 *    decompression from the compressed format to RGB.
 *
 *    If the device supports a list of formats from the preferred list of
 *    formats, the TAPI MSP Video Capture filter will use this list to
 *    advertise the capabilities of the capture device.
 *
 *    In all cases (VfW and WDM capture devices, Videoconferencing
 *    Accelerators), the TAPI MSP Video Capture filter won't query the
 *    device for capabilities but always use the list of formats stored in
 *    its database for this capture device.
 ***************************************************************************/
HRESULT CCapDev::ProfileCaptureDevice()
{
        HRESULT Hr = NOERROR;
        HKEY    hDeviceKey = NULL;
        HKEY    hKey = NULL;
        DWORD   dwSize;
        char    szKey[MAX_PATH + MAX_VERSION + 2];
        VIDEOINFOHEADER         *pvi = NULL;
        DWORD   dwDisposition;
        int i, j, nFirstValidFormat;

        FX_ENTRY("CCapDev::ProfileCaptureDevice")

        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: begin", _fx_));

        // Provide defaults
    m_dwImageSize = VIDEO_FORMAT_IMAGE_SIZE_USE_DEFAULT;
    m_dwFormat = 0;

    // Since we don't know anything about this adapter, we just use its default format
    // Get the device's default format
        if (FAILED(GetFormatFromDriver(&pvi)) || !pvi)
        {
                DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: Can't get format from device!", _fx_));
                Hr = E_FAIL;
                goto MyExit;
        }

        // Open the main capture devices key, or create it if it doesn't exist
        if (RegCreateKeyEx(RTCKEYROOT, szRegRTCKey, 0, 0, REG_OPTION_NON_VOLATILE, KEY_WRITE, NULL, &hDeviceKey, &dwDisposition) != ERROR_SUCCESS)
        {
                DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: Can't create registry key!", _fx_));
                Hr = E_FAIL;
                goto MyExit;
        }

        // If we have version info use that to build the key name
        // @todo VCMSTRM.cpp does some weird things with the name - probably due to bogus device
        // Repro this code
        if (g_aDeviceInfo[m_dwDeviceIndex].szDeviceVersion && g_aDeviceInfo[m_dwDeviceIndex].szDeviceVersion[0] != '\0')
        {
            wsprintf(szKey, "%s, %s", g_aDeviceInfo[m_dwDeviceIndex].szDeviceDescription, g_aDeviceInfo[m_dwDeviceIndex].szDeviceVersion);
        }
        else
        {
            wsprintf(szKey, "%s", g_aDeviceInfo[m_dwDeviceIndex].szDeviceDescription);
        }

        // Check if there already is a key for the current device
        // Open the key for the current device, or create the key if it doesn't exist
        if (RegCreateKeyEx(hDeviceKey, szKey, 0, 0, REG_OPTION_NON_VOLATILE, KEY_WRITE, NULL, &hKey, &dwDisposition) != ERROR_SUCCESS)
        {
                DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: Can't create registry key!", _fx_));
                Hr = E_FAIL;
                goto MyExit;
        }

        switch(HEADER(pvi)->biCompression)
        {
                case VIDEO_FORMAT_BI_RGB:
                        switch(HEADER(pvi)->biBitCount)
                        {
                                case 24:
                            m_dwFormat = VIDEO_FORMAT_NUM_COLORS_16777216;
                                        break;
                                case 16:
                            m_dwFormat = VIDEO_FORMAT_NUM_COLORS_65536;
                                        break;
                                case 8:
                            m_dwFormat = VIDEO_FORMAT_NUM_COLORS_256;
                                        break;
                                case 4:
                            m_dwFormat = VIDEO_FORMAT_NUM_COLORS_16;
                                        break;
                        }
                        break;
                case VIDEO_FORMAT_MSH263:
            m_dwFormat = VIDEO_FORMAT_NUM_COLORS_MSH263;
                        break;
                case VIDEO_FORMAT_MSH261:
            m_dwFormat = VIDEO_FORMAT_NUM_COLORS_MSH261;
                        break;
                case VIDEO_FORMAT_YVU9:
            m_dwFormat = VIDEO_FORMAT_NUM_COLORS_YVU9;
                        break;
                case VIDEO_FORMAT_YUY2:
            m_dwFormat = VIDEO_FORMAT_NUM_COLORS_YUY2;
                        break;
                case VIDEO_FORMAT_UYVY:
            m_dwFormat = VIDEO_FORMAT_NUM_COLORS_UYVY;
                        break;
                case VIDEO_FORMAT_I420:
            m_dwFormat = VIDEO_FORMAT_NUM_COLORS_I420;
                        break;
                case VIDEO_FORMAT_IYUV:
            m_dwFormat = VIDEO_FORMAT_NUM_COLORS_IYUV;
                        break;
                default:
                        DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: Unsupported format! value = 0x%08lx '%.4s'", _fx_,(HEADER(pvi)->biCompression),&(HEADER(pvi)->biCompression)));
                        //**Hr = E_FAIL; if NO formats are found, ONLY then return E_FAIL (see if(nFirstValidFormat==0) below...)
                        //**goto MyExit; do not jump out; we continue instead, trying the other formats ... (332920)
                        break;
        }

    // Find the size
        for (j = 0;  j < VIDEO_FORMAT_NUM_RESOLUTIONS; j++)
        {
        if ((HEADER(pvi)->biWidth == (LONG)awResolutions[j].framesize.cx) &&
             (HEADER(pvi)->biHeight == (LONG)awResolutions[j].framesize.cy))
                {
                    m_dwImageSize |= awResolutions[j].dwRes;
                    break;
                }
        }

        // Set the values in the key
        dwSize = sizeof(DWORD);
        RegSetValueEx(hKey, (LPTSTR)szRegdwImageSizeKey, (DWORD)NULL, REG_DWORD, (LPBYTE)&m_dwImageSize, dwSize);
        dwSize = sizeof(DWORD);
        RegSetValueEx(hKey, (LPTSTR)szRegdwNumColorsKey, (DWORD)NULL, REG_DWORD, (LPBYTE)&m_dwFormat, dwSize);
        dwSize = sizeof(DWORD);
        RegSetValueEx(hKey, (LPTSTR)szRegdwStreamingModeKey, (DWORD)NULL, REG_DWORD, (LPBYTE)&m_dwStreamingMode, dwSize);
        dwSize = sizeof(DWORD);
        RegSetValueEx(hKey, (LPTSTR)szRegdwDialogsKey, (DWORD)NULL, REG_DWORD, (LPBYTE)&m_dwDialogs, dwSize);

        // Close the keys
        RegCloseKey(hKey);
        RegCloseKey(hDeviceKey);
        hDeviceKey = NULL;
        hKey = NULL;

        // We're safe. We've backed up the default format of the capture device.
        // Now we can try and apply formats on it to see what else it supports
        // This operation MAY crash - but next time we'll execute this code, we
        // won't try this code again since we'll find out that we have already
        // stored the default format for the capture device in the registry.

        // Let's try 176x144, 128x96 and 352x288 for sure
        // If we don't have both 176x144 and 128x96, try 160x120
        // If we don't have 352x288, try 320x240
        // If we don't have 320x240, try 240x180
        nFirstValidFormat = 0;
    m_dwImageSize = 0;
    m_dwFormat = 0;
        for (i = 0; i < VIDEO_FORMAT_NUM_RESOLUTIONS; i++)
        {
                if (i == 3 && (m_dwImageSize & VIDEO_FORMAT_IMAGE_SIZE_176_144) && (m_dwImageSize & VIDEO_FORMAT_IMAGE_SIZE_128_96))
                        continue;

                if (i == 4 && (m_dwImageSize & VIDEO_FORMAT_IMAGE_SIZE_352_288))
                        continue;

                if (i == 5 && ((m_dwImageSize & VIDEO_FORMAT_IMAGE_SIZE_352_288) || (m_dwImageSize & VIDEO_FORMAT_IMAGE_SIZE_320_240)))
                        continue;

                HEADER(pvi)->biSize = sizeof(BITMAPINFOHEADER);
                HEADER(pvi)->biWidth = awResolutions[i].framesize.cx;
                HEADER(pvi)->biHeight = awResolutions[i].framesize.cy;
                HEADER(pvi)->biPlanes = 1;
                HEADER(pvi)->biXPelsPerMeter = HEADER(pvi)->biYPelsPerMeter = 0;

                // Try MSH263, MSH261, I420, IYUV, YVU9, YUY2, UYVY, RGB16, RGB24, RGB4, RGB8 format.
                for (j = nFirstValidFormat; j < NUM_BITDEPTH_ENTRIES; j++)
                {
                        HEADER(pvi)->biBitCount = aiBitDepth[j];
                        HEADER(pvi)->biCompression = aiFourCCCode[j];
                        HEADER(pvi)->biClrImportant = HEADER(pvi)->biClrUsed = aiClrUsed[j];
                        HEADER(pvi)->biSizeImage = DIBSIZE(*HEADER(pvi));

                        // Ask the device to validate this format
                        if (SUCCEEDED(SendFormatToDriver(HEADER(pvi)->biWidth, HEADER(pvi)->biHeight, HEADER(pvi)->biCompression, HEADER(pvi)->biBitCount, NULL, TRUE)))
                        {
                                DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s:   Adding %s %ldx%ld to capabilities", _fx_, HEADER(pvi)->biCompression == VIDEO_FORMAT_MSH263 ? "H.263" : HEADER(pvi)->biCompression == VIDEO_FORMAT_MSH261 ? "H.261" : HEADER(pvi)->biCompression == VIDEO_FORMAT_YVU9 ? "YVU9" : HEADER(pvi)->biCompression == VIDEO_FORMAT_I420 ? "I420" : HEADER(pvi)->biCompression == VIDEO_FORMAT_IYUV ? "IYUV" : HEADER(pvi)->biCompression == VIDEO_FORMAT_YUY2 ? "YUY2" : HEADER(pvi)->biCompression == VIDEO_FORMAT_UYVY ? "UYVY" : "RGB", HEADER(pvi)->biWidth, HEADER(pvi)->biHeight));
                                m_dwImageSize |= awResolutions[i].dwRes;
                                m_dwFormat |= aiFormat[j];
                                if (!nFirstValidFormat)
                                        nFirstValidFormat = j;
                                // Assumption: A size supported in one format, is also supported with any other
                                // format supported by the capture device.
                                // @todo For now, get all the formats supported
                                // break;
                        }
                }
        }

        if(nFirstValidFormat==0) { // none supported ...
                DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: No format supported !", _fx_));
                Hr = E_FAIL;
                goto MyExit;
        }

        // If we survived the previous set format tests, reopen the keys and save
        // the new result to the registry
        if (RegCreateKeyEx(RTCKEYROOT, szRegRTCKey, 0, 0, REG_OPTION_NON_VOLATILE, KEY_WRITE, NULL, &hDeviceKey, &dwDisposition) != ERROR_SUCCESS)
        {
                DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: Can't reopen registry key!", _fx_));
                Hr = E_FAIL;
                goto MyExit;
        }
        if (RegCreateKeyEx(hDeviceKey, szKey, 0, 0, REG_OPTION_NON_VOLATILE, KEY_WRITE, NULL, &hKey, &dwDisposition) != ERROR_SUCCESS)
        {
                DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: Can't reopen registry key!", _fx_));
                Hr = E_FAIL;
                goto MyExit;
        }

    m_dwImageSize ^= VIDEO_FORMAT_IMAGE_SIZE_USE_DEFAULT;

        // Update the values in the key
        dwSize = sizeof(DWORD);
        RegSetValueEx(hKey, (LPTSTR)szRegdwImageSizeKey, (DWORD)NULL, REG_DWORD, (LPBYTE)&m_dwImageSize, dwSize);
        dwSize = sizeof(DWORD);
        RegSetValueEx(hKey, (LPTSTR)szRegdwNumColorsKey, (DWORD)NULL, REG_DWORD, (LPBYTE)&m_dwFormat, dwSize);

MyExit:
        // Close the keys
        if (hKey)
                RegCloseKey(hKey);
        if (hDeviceKey)
                RegCloseKey(hDeviceKey);
        // Free BMIH + palette space
        if (pvi)
                delete pvi, pvi = NULL;
        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: end", _fx_));
        return Hr;
}
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\net\tapi\skywalker\filters\video\tapivcap\device.h ===
/****************************************************************************
 *  @doc INTERNAL DEVICE
 *
 *  @module Device.h | Header file for the <c CDeviceProperties>
 *    class used to implement a property page to test the <i IAMVfwCaptureDialogs>
 *    and <i IVideoDeviceControl> interfaces.
 ***************************************************************************/

#ifndef _DEVICE_H_
#define _DEVICE_H_

#include "precomp.h"
#include "dbgxtra.h"
#include <qedit.h>
#include <atlbase.h>

#include "../../audio/tpaudcap/dsgraph.h"

/****************************************************************************
 *  @doc INTERNAL CTAPIVCAPCLASS
 *
 *  @class CTAPIVCap | This class implements the TAPI Video Capture Source
 *    filter.
 *
 *  @mdata CCritSec | CTAPIVCap | m_lock | Critical section used for
 *    locking by the <c CBaseFilter> base class.
 *
 *  @mdata CCapturePin | CTAPIVCap | m_pCapturePin | Pointer to the capture pin
 *    object
 *
 *  @mdata COverlayPin | CTAPIVCap | m_pOverlayPin | Pointer to the overlay
 *    pin object
 *
 *  @mdata CPreviewPin | CTAPIVCap | m_pPreviewPin | Pointer to the preview
 *    pin object
 *
 *  @mdata BOOL | CTAPIVCap | m_fDialogUp | Set to TRUE if a VfW driver
 *    dialog box is up
 *
 *  @todo Put some valid comments here!
 ***************************************************************************/
class CCapDev : public CUnknown, public IAMVfwCaptureDialogs, public IVideoProcAmp, public ICameraControl
{
        public:

        DECLARE_IUNKNOWN
        STDMETHODIMP NonDelegatingQueryInterface(IN REFIID riid, OUT PVOID *ppv);
        CCapDev(IN TCHAR *pObjectName, IN CTAPIVCap *pCaptureFilter, IN LPUNKNOWN pUnkOuter, IN DWORD dwDeviceIndex, IN HRESULT *pHr);
        virtual ~CCapDev();

        // Implement IAMVfwCaptureDialogs
        virtual STDMETHODIMP HasDialog(IN int iDialog) PURE;
        virtual STDMETHODIMP ShowDialog(IN int iDialog, IN HWND hwnd) PURE;
        virtual STDMETHODIMP SendDriverMessage(IN int iDialog, IN int uMsg, IN long dw1, IN long dw2) PURE;

        // Implement IAMVideoProcAmp
        virtual STDMETHODIMP Set(IN VideoProcAmpProperty Property, IN long lValue, IN TAPIControlFlags Flags) {return E_NOTIMPL;};
        virtual STDMETHODIMP Get(IN VideoProcAmpProperty Property, OUT long *lValue, OUT TAPIControlFlags *Flags) {return E_NOTIMPL;};
        virtual STDMETHODIMP GetRange(IN VideoProcAmpProperty Property, OUT long *pMin, OUT long *pMax, OUT long *pSteppingDelta, OUT long *pDefault, OUT TAPIControlFlags *pCapsFlags) {return E_NOTIMPL;};

        // Implement ICameraControl
        virtual STDMETHODIMP Set(IN TAPICameraControlProperty Property, IN long lValue, IN TAPIControlFlags Flags);
        virtual STDMETHODIMP Get(IN TAPICameraControlProperty Property, OUT long *lValue, OUT TAPIControlFlags *Flags);
        virtual STDMETHODIMP GetRange(IN TAPICameraControlProperty Property, OUT long *pMin, OUT long *pMax, OUT long *pSteppingDelta, OUT long *pDefault, OUT TAPIControlFlags *pCapsFlags);

        // Device control
        HRESULT GetFormatsFromRegistry();
        virtual HRESULT ProfileCaptureDevice();
        virtual HRESULT ConnectToDriver() PURE;
        virtual HRESULT DisconnectFromDriver() PURE;
        virtual HRESULT SendFormatToDriver(IN LONG biWidth, IN LONG biHeight, IN DWORD biCompression, IN WORD biBitCount, IN REFERENCE_TIME AvgTimePerFrame, BOOL fUseExactFormat) PURE;
        virtual HRESULT GetFormatFromDriver(OUT VIDEOINFOHEADER **ppvi) PURE;

        // Streaming and frame grabbing control
        virtual HRESULT InitializeStreaming(DWORD usPerFrame, DWORD_PTR hEvtBufferDone) PURE;
        virtual HRESULT StartStreaming() PURE;
        virtual HRESULT StopStreaming() PURE;
        virtual HRESULT TerminateStreaming() PURE;
        virtual HRESULT GrabFrame(PVIDEOHDR pVHdr) PURE;
        virtual HRESULT AllocateBuffer(LPTHKVIDEOHDR *pptvh, DWORD dwIndex, DWORD cbBuffer) PURE;
        virtual HRESULT AddBuffer(PVIDEOHDR pVHdr, DWORD cbVHdr) PURE;
        virtual HRESULT FreeBuffer(LPTHKVIDEOHDR pVHdr) PURE; //previously PVIDEOHDR pVHdr
        virtual HRESULT AllocateHeaders(DWORD dwNumHdrs, DWORD cbHdr, LPVOID *ppaHdr) PURE;
        virtual BOOL    IsBufferDone(PVIDEOHDR pVHdr) PURE;

        protected:

        friend class CTAPIVCap;
        friend class CTAPIBasePin;
        friend class CPreviewPin;
        friend class CWDMStreamer;
        friend class CConverter;
        friend class CICMConverter;
        friend class CH26XEncoder;

        // Owner filter
        CTAPIVCap *m_pCaptureFilter;

        // Capture device index
        DWORD m_dwDeviceIndex;

        // cap dev info
        VIDEOCAPTUREDEVICEINFO m_vcdi;
        BOOL m_bCached_vcdi;

        // Capture device caps
        DWORD m_dwDialogs;
        DWORD m_dwImageSize;
        DWORD m_dwFormat;
        DWORD m_dwStreamingMode;

        // Configuration dialogs
        BOOL  m_fDialogUp;

        // Camera control
        LONG m_lCCPan;
        LONG m_lCCTilt;
        LONG m_lCCZoom;
};

/****************************************************************************
 *  @doc INTERNAL CTAPIVCAPCLASS
 *
 *  @class CTAPIVCap | This class implements the TAPI Capture Source
 *    filter.
 *
 *  @mdata CCritSec | CTAPIVCap | m_lock | Critical section used for
 *    locking by the <c CBaseFilter> base class.
 *
 *  @mdata CCapturePin | CTAPIVCap | m_pCapturePin | Pointer to the capture pin
 *    object
 *
 *  @mdata COverlayPin | CTAPIVCap | m_pOverlayPin | Pointer to the overlay
 *    pin object
 *
 *  @mdata CPreviewPin | CTAPIVCap | m_pPreviewPin | Pointer to the preview
 *    pin object
 *
 *  @mdata BOOL | CTAPIVCap | m_fDialogUp | Set to TRUE if a VfW driver
 *    dialog box is up
 ***************************************************************************/
class CVfWCapDev : public CCapDev
{
        public:

        DECLARE_IUNKNOWN
        STDMETHODIMP NonDelegatingQueryInterface(IN REFIID riid, OUT PVOID *ppv);
        CVfWCapDev(IN TCHAR *pObjectName, IN CTAPIVCap *pCaptureFilter, IN LPUNKNOWN pUnkOuter, IN DWORD dwDeviceIndex, IN HRESULT *pHr);
        ~CVfWCapDev();
        static HRESULT CALLBACK CreateVfWCapDev(IN CTAPIVCap *pCaptureFilter, IN DWORD dwDeviceIndex, OUT CCapDev **ppCapDev);

        // Implement IAMVfwCaptureDialogs
        STDMETHODIMP HasDialog(IN int iDialog);
        STDMETHODIMP ShowDialog(IN int iDialog, IN HWND hwnd);
        STDMETHODIMP SendDriverMessage(IN int iDialog, IN int uMsg, IN long dw1, IN long dw2);

        // Device control
        HRESULT ProfileCaptureDevice();
        HRESULT ConnectToDriver();
        HRESULT DisconnectFromDriver();
        HRESULT SendFormatToDriver(IN LONG biWidth, IN LONG biHeight, IN DWORD biCompression, IN WORD biBitCount, IN REFERENCE_TIME AvgTimePerFrame, BOOL fUseExactFormat);
        HRESULT GetFormatFromDriver(OUT VIDEOINFOHEADER **ppvi);

        // Streaming and frame grabbing control
        HRESULT InitializeStreaming(DWORD usPerFrame, DWORD_PTR hEvtBufferDone);
        HRESULT StartStreaming();
        HRESULT StopStreaming();
        HRESULT TerminateStreaming();
        HRESULT GrabFrame(PVIDEOHDR pVHdr);
        HRESULT AllocateBuffer(LPTHKVIDEOHDR *pptvh, DWORD dwIndex, DWORD cbBuffer);
        HRESULT AddBuffer(PVIDEOHDR pVHdr, DWORD cbVHdr);
        HRESULT FreeBuffer(LPTHKVIDEOHDR pVHdr); //previously  PVIDEOHDR pVHdr
        HRESULT AllocateHeaders(DWORD dwNumHdrs, DWORD cbHdr, LPVOID *ppaHdr);
        BOOL    IsBufferDone(PVIDEOHDR pVHdr);

        private:

        UINT    m_dwDeviceID;   // id of VfW video driver to open
        HVIDEO  m_hVideoIn;             // video input
        HVIDEO  m_hVideoExtIn;  // external in (source control)
        HVIDEO  m_hVideoExtOut; // external out (overlay; not required)
        BOOL    m_bHasOverlay;  // TRUE if ExtOut has overlay support
};

// Used to query and set video data ranges of a device
typedef struct _tagVideoDataRanges {
    ULONG   Size;
    ULONG   Count;
    KS_DATARANGE_VIDEO Data;
} VIDEO_DATA_RANGES, * PVIDEO_DATA_RANGES;

/*****************************************************************************
 * @doc INTERNAL VIDEOSTRUCTENUM
 *
 * @struct DATAPINCONNECT | The <t DATAPINCONNECT> structure is used to
 *   connect to a streaming video pin.
 *
 * @field KSPIN_CONNECT | Connect | Describes how the connection is to be
 *   done.
 *
 * @field KS_DATAFORMAT_VIDEOINFOHEADER | Data | Describes the video format
 *   of the video data streaming from a video pin.
 ***************************************************************************/
// Structure used to connect to a streaming video pin
typedef struct _tagStreamConnect
{
        KSPIN_CONNECT                                   Connect;
        KS_DATAFORMAT_VIDEOINFO_PALETTE Data;
} DATAPINCONNECT, *PDATAPINCONNECT;

#define INVALID_PIN_ID (DWORD)-1L

/*****************************************************************************
 * @doc INTERNAL VIDEOSTRUCTENUM
 *
 * @struct KS_HEADER_AND_INFO | The <t KS_HEADER_AND_INFO> structure is used
 *   stream data from a video pin.
 *
 * @field KSSTREAM_HEADER | StreamHeader | Describes how the streaming is to be
 *   done.
 *
 * @field KS_FRAME_INFO | FrameInfo | Describes the video format
 *   of the video data streaming from a video pin.
 ***************************************************************************/
// Video streaming data structure
typedef struct tagKS_HEADER_AND_INFO
{
        KSSTREAM_HEADER StreamHeader;
        KS_FRAME_INFO   FrameInfo;
} KS_HEADER_AND_INFO;

/*****************************************************************************
 * @doc INTERNAL VIDEOSTRUCTENUM
 *
 * @struct BUFSTRUCT | The <t BUFSTRUCT> structure holds the status of each
 *   video streaming buffer.
 *
 * @field LPVIDEOHDR | lpVHdr | Specifies a pointer to the video header of a
 *   video streaming buffer.
 *
 * @field BOOL | fReady | Set to TRUE if the video buffer is available for
 *   video streaming, FALSE if is locked by the application or queued for
 *   an asynchronous read.
 ***************************************************************************/
// Holds status of each video streaming buffer
typedef struct _BUFSTRUCT {
        LPVIDEOHDR lpVHdr;      // Pointer to the video header of the buffer
        BOOL fReady;            // Set to TRUE if the buffer is available for streaming, FALSE otherwise
} BUFSTRUCT, * PBUFSTRUCT;

/*****************************************************************************
 * @doc INTERNAL VIDEOSTRUCTENUM
 *
 * @struct WDMVIDEOBUFF | The <t WDMVIDEOBUFF> structure is used to queue
 *   asynchronous read on a video streaming pin.
 *
 * @field OVERLAPPED | Overlap | Structure used for overlapping IOs.
 *
 * @field BOOL | fBlocking | Set to TRUE if read is going to block.
 *
 * @field KS_HEADER_AND_INFO | SHGetImage | Video streaming structure used
 *   on the video pin to get video data.
 *
 * @field LPVIDEOHDR | pVideoHdr | Pointer to the video header for this WDM
 *   video buffer.
 ***************************************************************************/
// Read buffer structure
typedef struct tagWDMVIDEOBUFF {
        OVERLAPPED                      Overlap;                // Structure used for overlapping IOs
        BOOL                            fBlocking;              // Set to TRUE if the read operation will execute asynchronously
        KS_HEADER_AND_INFO      SHGetImage;             // Video streaming structure used on the video pin
        LPVIDEOHDR                      pVideoHdr;              // Pointer to the video header for this WDM buffer
} WDMVIDEOBUFF, *PWDMVIDEOBUFF;

// For GetProcAddresss on KsCreatePin
typedef DWORD (WINAPI *LPFNKSCREATEPIN)(IN HANDLE FilterHandle, IN PKSPIN_CONNECT Connect, IN ACCESS_MASK DesiredAccess, OUT PHANDLE ConnectionHandle);

/****************************************************************************
 *  @doc INTERNAL CWDMCAPDEVCLASS
 *
 *  @class CWDMCapDev | This class provides access to the streaming class
 *    driver, through which we acess the video capture mini-driver properties
 *    using IOCtls.
 *
 *  @mdata DWORD | CWDMCapDev | m_dwDeviceID | Capture device ID.
 *
 *  @mdata HANDLE | CWDMCapDev | m_hDriver | This member holds the driver
 *    file handle.
 *
 *  @mdata PVIDEO_DATA_RANGES | CWDMCapDev | m_pVideoDataRanges | This member
 *    points to the video data range structure.
 ***************************************************************************/
class CWDMCapDev : public CCapDev
{
        public:

        DECLARE_IUNKNOWN
        STDMETHODIMP NonDelegatingQueryInterface(IN REFIID riid, OUT PVOID *ppv);
        CWDMCapDev(IN TCHAR *pObjectName, IN CTAPIVCap *pCaptureFilter, IN LPUNKNOWN pUnkOuter, IN DWORD dwDeviceIndex, IN HRESULT *pHr);
        ~CWDMCapDev();
        static HRESULT CALLBACK CreateWDMCapDev(IN CTAPIVCap *pCaptureFilter, IN DWORD dwDeviceIndex, OUT CCapDev **ppCapDev);

        // Implement IAMVfwCaptureDialogs
        STDMETHODIMP HasDialog(IN int iDialog);
        STDMETHODIMP ShowDialog(IN int iDialog, IN HWND hwnd);
        STDMETHODIMP SendDriverMessage(IN int iDialog, IN int uMsg, IN long dw1, IN long dw2) {return E_NOTIMPL;};

        // Implement IAMVideoProcAmp
        STDMETHODIMP Set(IN VideoProcAmpProperty Property, IN long lValue, IN TAPIControlFlags Flags);
        STDMETHODIMP Get(IN VideoProcAmpProperty Property, OUT long *lValue, OUT TAPIControlFlags *Flags);
        STDMETHODIMP GetRange(IN VideoProcAmpProperty Property, OUT long *pMin, OUT long *pMax, OUT long *pSteppingDelta, OUT long *pDefault, OUT TAPIControlFlags *pCapsFlags);

#ifndef USE_SOFTWARE_CAMERA_CONTROL
        // Implement ICameraControl
        STDMETHODIMP Set(IN TAPICameraControlProperty Property, IN long lValue, IN TAPIControlFlags Flags);
        STDMETHODIMP Get(IN TAPICameraControlProperty Property, OUT long *lValue, OUT TAPIControlFlags *Flags);
        STDMETHODIMP GetRange(IN TAPICameraControlProperty Property, OUT long *pMin, OUT long *pMax, OUT long *pSteppingDelta, OUT long *pDefault, OUT TAPIControlFlags *pCapsFlags);
#endif

        // Device control
        HRESULT ProfileCaptureDevice();
        HRESULT ConnectToDriver();
        HRESULT DisconnectFromDriver();
        HRESULT SendFormatToDriver(IN LONG biWidth, IN LONG biHeight, IN DWORD biCompression, IN WORD biBitCount, IN REFERENCE_TIME AvgTimePerFrame, BOOL fUseExactFormat);
        HRESULT GetFormatFromDriver(OUT VIDEOINFOHEADER **ppvi);

        // Streaming and frame grabbing control
        HRESULT InitializeStreaming(DWORD usPerFrame, DWORD_PTR hEvtBufferDone);
        HRESULT StartStreaming();
        HRESULT StopStreaming();
        HRESULT TerminateStreaming();
        HRESULT GrabFrame(PVIDEOHDR pVHdr);
        HRESULT AllocateBuffer(LPTHKVIDEOHDR *pptvh, DWORD dwIndex, DWORD cbBuffer);
        HRESULT AddBuffer(PVIDEOHDR pVHdr, DWORD cbVHdr);
        HRESULT FreeBuffer(LPTHKVIDEOHDR pVHdr); // previously PVIDEOHDR pVHdr
        HRESULT AllocateHeaders(DWORD dwNumHdrs, DWORD cbHdr, LPVOID *ppaHdr);
        BOOL    IsBufferDone(PVIDEOHDR pVHdr);

        // Device IO function
    BOOL DeviceIoControl(HANDLE h, DWORD dwIoControlCode, LPVOID lpInBuffer, DWORD nInBufferSize, LPVOID lpOutBuffer, DWORD nOutBufferSize, LPDWORD lpBytesReturned, BOOL bOverlapped=TRUE);

    // Property functions
    HRESULT GetPropertyValue(GUID guidPropertySet, ULONG ulPropertyId, PLONG plValue, PULONG pulFlags, PULONG pulCapabilities);
    HRESULT GetDefaultValue(GUID guidPropertySet, ULONG ulPropertyId, PLONG plDefValue);
    HRESULT GetRangeValues(GUID guidPropertySet, ULONG ulPropertyId, PLONG plMin, PLONG plMax, PLONG plStep);
    HRESULT SetPropertyValue(GUID guidPropertySet, ULONG ulPropertyId, LONG lValue, ULONG ulFlags, ULONG ulCapabilities);

        private:

        friend class CWDMStreamer;

        XDBGONLY DWORD               m_tag;              //magic sequence (e.g. 'LOLA' , 0x414C4F4C ...)
        HANDLE                          m_hDriver;                              // Driver file handle
        PVIDEO_DATA_RANGES      m_pVideoDataRanges;             // Pin video data ranges
        DWORD                           m_dwPreviewPinId;               // Preview pin Id
        DWORD                           m_dwCapturePinId;               // Capture pin Id
        HANDLE                          m_hKSPin;                               // Handle to the kernel streaming pin
        HINSTANCE                       m_hKsUserDLL;                   // DLL Handle to KsUser.dll
        LPFNKSCREATEPIN         m_pKsCreatePin;                 // KsCreatePin() function pointer
        BOOL                            m_fStarted;                             // Streaming state of the kernel streaming video pin

    // Data range functions
        ULONG   CreateDriverSupportedDataRanges();
        HRESULT FindMatchDataRangeVideo(PBITMAPINFOHEADER pbiHdr, DWORD dwAvgTimePerFrame, BOOL *pfValidMatch, PKS_DATARANGE_VIDEO *ppSelDRVideo);
    HRESULT     GetDriverSupportedDataRanges(PVIDEO_DATA_RANGES *ppDataRanges);

        // Kernel streaming pin control functions
        BOOL Stop();
        BOOL Start();
        BOOL SetState(KSSTATE ksState);

        // Streaming control
        ULONG                   m_cntNumVidBuf;
        LPVIDEOHDR              m_lpVHdrFirst;
        LPVIDEOHDR              m_lpVHdrLast;
        BOOL                    m_fVideoOpen;
        WDMVIDEOBUFF    *m_pWDMVideoBuff;

        // Video streaming buffer management functions
        void BufferDone(LPVIDEOHDR lpVHdr);
        LPVIDEOHDR DeQueueHeader();
        void QueueHeader(LPVIDEOHDR lpVHdr);
        BOOL QueueRead(DWORD dwIndex);

        // Dumps the properties of the adapter
#if defined(DUMP_DRIVER_CHARACTERISTICS) && defined(DEBUG)
        void GetDriverDetails();
#endif
};

class CDShowCapDev : public CCapDev
{
        public:

        DECLARE_IUNKNOWN
        STDMETHODIMP NonDelegatingQueryInterface(IN REFIID riid, OUT PVOID *ppv);
        CDShowCapDev(IN TCHAR *pObjectName, IN CTAPIVCap *pCaptureFilter, IN LPUNKNOWN pUnkOuter, IN DWORD dwDeviceIndex, IN HRESULT *pHr);
        ~CDShowCapDev();
        static HRESULT CALLBACK CreateDShowCapDev(IN CTAPIVCap *pCaptureFilter, IN DWORD dwDeviceIndex, OUT CCapDev **ppCapDev);

        // Implement IAMVfwCaptureDialogs
        STDMETHODIMP HasDialog(IN int iDialog) { return E_NOTIMPL; }
        STDMETHODIMP ShowDialog(IN int iDialog, IN HWND hwnd) { return E_NOTIMPL; }
        STDMETHODIMP SendDriverMessage(IN int iDialog, IN int uMsg, IN long dw1, IN long dw2) {return E_NOTIMPL;};

        // Implement IAMVideoProcAmp
        STDMETHODIMP Set(IN VideoProcAmpProperty Property, IN long lValue, IN TAPIControlFlags Flags) { return E_NOTIMPL; }
        STDMETHODIMP Get(IN VideoProcAmpProperty Property, OUT long *lValue, OUT TAPIControlFlags *Flags) { return E_NOTIMPL; }
        STDMETHODIMP GetRange(IN VideoProcAmpProperty Property, OUT long *pMin, OUT long *pMax, OUT long *pSteppingDelta, OUT long *pDefault, OUT TAPIControlFlags *pCapsFlags) { return E_NOTIMPL; }

#ifndef USE_SOFTWARE_CAMERA_CONTROL
        // Implement ICameraControl
        STDMETHODIMP Set(IN TAPICameraControlProperty Property, IN long lValue, IN TAPIControlFlags Flags) { return E_NOTIMPL; }
        STDMETHODIMP Get(IN TAPICameraControlProperty Property, OUT long *lValue, OUT TAPIControlFlags *Flags) { return E_NOTIMPL; }
        STDMETHODIMP GetRange(IN TAPICameraControlProperty Property, OUT long *pMin, OUT long *pMax, OUT long *pSteppingDelta, OUT long *pDefault, OUT TAPIControlFlags *pCapsFlags) { return E_NOTIMPL; }
#endif

        // Device control
        HRESULT ProfileCaptureDevice();
        HRESULT ConnectToDriver();
        HRESULT DisconnectFromDriver();
        HRESULT SendFormatToDriver(IN LONG biWidth, IN LONG biHeight, IN DWORD biCompression, IN WORD biBitCount, IN REFERENCE_TIME AvgTimePerFrame, BOOL fUseExactFormat);
        HRESULT GetFormatFromDriver(OUT VIDEOINFOHEADER **ppvi);

        // Streaming and frame grabbing control
        HRESULT InitializeStreaming(DWORD usPerFrame, DWORD_PTR hEvtBufferDone);
        HRESULT StartStreaming();
        HRESULT StopStreaming();
        HRESULT TerminateStreaming();
        HRESULT GrabFrame(PVIDEOHDR pVHdr);
        HRESULT AllocateBuffer(LPTHKVIDEOHDR *pptvh, DWORD dwIndex, DWORD cbBuffer);
        HRESULT AddBuffer(PVIDEOHDR pVHdr, DWORD cbVHdr);
        HRESULT FreeBuffer(LPTHKVIDEOHDR pVHdr);
        HRESULT AllocateHeaders(DWORD dwNumHdrs, DWORD cbHdr, LPVOID *ppaHdr);
        BOOL    IsBufferDone(PVIDEOHDR pVHdr);

	DWORD m_dwDeviceIndex;
	CComPtr<IGraphBuilder> m_pGraph;
	CComPtr<ICaptureGraphBuilder2> m_pCGB;
	CComPtr<ISampleGrabber> m_pGrab;
	CComPtr<IBaseFilter> m_pCap;
        CComPtr<CSharedGraph> m_psg;

	AM_MEDIA_TYPE m_mt;	    // our current capture format
        HANDLE m_hEvent;	    // signal the app when a frame is captured
        DWORD m_usPerFrame;
	
	// the latest buffer captured by the sample grabber
	int m_cbBuffer;
	BYTE *m_pBuffer;
	int m_cbBufferValid;
	CCritSec m_csBuffer;// don't read and write into it at the same time
	CCritSec m_csStack; // don't muck with variables we're looking at
	BOOL m_fEventMode;   // event fire mode or frame grabbing mode?
	int m_cBuffers;	    // how many buffers we're capturing with

#define MAX_BSTACK 100

	int m_aStack[MAX_BSTACK];	    // the order we're to fill the buffers
	int m_nTop;	    // top of the stack (push)
	int m_nBottom;	    // bottom of the stack (pull)

        HRESULT BuildGraph(AM_MEDIA_TYPE&);
        static void VideoCallback(void *pContext, IMediaSample *pSample);
	static HRESULT MakeMediaType(AM_MEDIA_TYPE *, VIDEOINFOHEADER *);
	HRESULT FixDVSize(DWORD, DWORD, REFERENCE_TIME);
};

#endif // _DEVICE_H_
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\net\tapi\skywalker\filters\video\tapivcap\devicep.cpp ===
/****************************************************************************
 *  @doc INTERNAL DEVICEP
 *
 *  @module DeviceP.cpp | Source file for the <c CDeviceProperties>
 *    class used to implement a property page to test the <i IAMVfwCaptureDialogs>
 *    and <i IVideoDeviceControl> interfaces.
 *
 *  @comm This code tests the TAPI Capture Filter <i IVideoDeviceControl>
 *    and <i IAMVfwCaptureDialogs> implementations. This code is only compiled
 *    if USE_PROPERTY_PAGES is defined.
 ***************************************************************************/

#include "Precomp.h"

#ifdef USE_PROPERTY_PAGES

/****************************************************************************
 *  @doc INTERNAL CDEVICEPMETHOD
 *
 *  @mfunc CUnknown* | CDeviceProperties | CreateInstance | This
 *    method is called by DShow to create an instance of a Capture Device
 *    Property Page. It is referred to in the global structure <t g_Templates>.
 *
 *  @parm LPUNKNOWN | pUnkOuter | Specifies the outer unknown, if any.
 *
 *  @parm HRESULT* | pHr | Specifies the place in which to put any error return.
 *
 *  @rdesc Returns a pointer to the nondelegating CUnknown portion of the
 *    object, or NULL otherwise.
 ***************************************************************************/
CUnknown* CALLBACK CDevicePropertiesCreateInstance(LPUNKNOWN pUnkOuter, HRESULT *pHr) 
{
	CUnknown *pUnknown = (CUnknown *)NULL;

	FX_ENTRY("CDevicePropertiesCreateInstance")

	DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: begin", _fx_));

	// Validate input parameters
	ASSERT(pHr);
	if (!pHr)
	{
		DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: invalid input parameter", _fx_));
		goto MyExit;
	}

	if (!(pUnknown = new CDeviceProperties(pUnkOuter, pHr)))
	{
		*pHr = E_OUTOFMEMORY;
		DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: new CDeviceProperties failed", _fx_));
	}
	else
	{
		DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s:   SUCCESS: new CDeviceProperties created", _fx_));
	}

MyExit:
	DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: end", _fx_));
	return pUnknown;
}

/****************************************************************************
 *  @doc INTERNAL CDEVICEPMETHOD
 *
 *  @mfunc void | CDeviceProperties | CDeviceProperties | This
 *    method is the constructor for the property page object. It simply
 *    calls the constructor of the property page base class.
 *
 *  @parm LPUNKNOWN | pUnkOuter | Specifies the outer unknown, if any.
 *
 *  @parm HRESULT* | pHr | Specifies the place in which to put any error return.
 *
 *  @rdesc Nada.
 ***************************************************************************/
CDeviceProperties::CDeviceProperties(LPUNKNOWN pUnk, HRESULT *pHr) : CBasePropertyPage(NAME("Capture Device Property Page"), pUnk, IDD_CaptureDeviceProperties, IDS_DEVICEPROPNAME)
{
	FX_ENTRY("CDeviceProperties::CDeviceProperties")

	DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: begin", _fx_));

	m_pIVideoDeviceControl = NULL;
	m_pIAMVfwCaptureDialogs = NULL;

	DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: end", _fx_));
}

/****************************************************************************
 *  @doc INTERNAL CDEVICEPMETHOD
 *
 *  @mfunc void | CDeviceProperties | ~CDeviceProperties | This
 *    method is the destructor for capture device property page. It
 *    simply calls the base class destructor.
 *
 *  @rdesc Nada.
 ***************************************************************************/
CDeviceProperties::~CDeviceProperties()
{
	FX_ENTRY("CDeviceProperties::~CDeviceProperties")

	DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: begin", _fx_));

	if (!m_pIVideoDeviceControl)
	{
		DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   WARNING: already released!", _fx_));
	}
	else
	{
		// Release the interface
		m_pIVideoDeviceControl->Release();
		m_pIVideoDeviceControl = NULL;
		DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s:   SUCCESS: releasing m_pIVideoDeviceControl", _fx_));
	}

	if (!m_pIAMVfwCaptureDialogs)
	{
		DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   WARNING: already released!", _fx_));
	}
	else
	{
		// Release the interface
		m_pIAMVfwCaptureDialogs->Release();
		m_pIAMVfwCaptureDialogs = NULL;
		DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s:   SUCCESS: releasing m_pIAMVfwCaptureDialogs", _fx_));
	}

	DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: end", _fx_));
}

/****************************************************************************
 *  @doc INTERNAL CDEVICEPMETHOD
 *
 *  @mfunc HRESULT | CDeviceProperties | OnConnect | This
 *    method is called when the property page is connected to the filter.
 *
 *  @parm LPUNKNOWN | pUnknown | Specifies the outer unknown, if any.
 *
 *  @parm HRESULT* | pHr | Specifies the place in which to put any error return.
 *
 *  @rdesc This method returns an HRESULT value that depends on the
 *    implementation of the interface. HRESULT can include one of the
 *    following standard constants, or other values not listed:
 *
 *  @flag E_FAIL | Failure
 *  @flag E_POINTER | Null pointer argument
 *  @flag E_NOTIMPL | Method is not supported
 *  @flag NOERROR | No error
 ***************************************************************************/
HRESULT CDeviceProperties::OnConnect(IUnknown *pUnk)
{
	HRESULT Hr = NOERROR;

	FX_ENTRY("CDeviceProperties::OnConnect")

	DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: begin", _fx_));

	// Validate input parameters
	ASSERT(pUnk);
	if (!pUnk)
	{
		DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: invalid input parameter", _fx_));
		Hr = E_POINTER;
		goto MyExit;
	}

	// Get the capture device interface
	if (SUCCEEDED (Hr = pUnk->QueryInterface(__uuidof(IVideoDeviceControl),(void **)&m_pIVideoDeviceControl)))
	{
		DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s:   SUCCESS: m_pIVideoDeviceControl=0x%08lX", _fx_, m_pIVideoDeviceControl));
	}
	else
	{
		m_pIVideoDeviceControl = NULL;
		DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: IOCTL failed Hr=0x%08lX", _fx_, Hr));
	}

	// Get the VfW capture device dialogs interface
	if (SUCCEEDED (Hr = pUnk->QueryInterface(__uuidof(IAMVfwCaptureDialogs),(void **)&m_pIAMVfwCaptureDialogs)))
	{
		DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s:   SUCCESS: m_pIAMVfwCaptureDialogs=0x%08lX", _fx_, m_pIAMVfwCaptureDialogs));
	}
	else
	{
		m_pIAMVfwCaptureDialogs = NULL;
		DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: IOCTL failed Hr=0x%08lX", _fx_, Hr));
	}

	// It's Ok if we couldn't get interface pointers
	// We'll just grey the controls in the property page
	// to make it clear to the user that they can't
	// control those properties on the device
	Hr = NOERROR;

MyExit:
	DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: end", _fx_));
	return Hr;
}

/****************************************************************************
 *  @doc INTERNAL CDEVICEPMETHOD
 *
 *  @mfunc HRESULT | CDeviceProperties | OnDisconnect | This
 *    method is called when the property page is disconnected from the owning
 *    filter.
 *
 *  @rdesc This method returns an HRESULT value that depends on the
 *    implementation of the interface. HRESULT can include one of the
 *    following standard constants, or other values not listed:
 *
 *  @flag NOERROR | No error
 ***************************************************************************/
HRESULT CDeviceProperties::OnDisconnect()
{
	FX_ENTRY("CDeviceProperties::OnDisconnect")

	DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: begin", _fx_));

	// Validate input parameters: we seem to get called several times here
	// Make sure the interface pointer is still valid
	if (!m_pIVideoDeviceControl)
	{
		DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   WARNING: already disconnected!", _fx_));
	}
	else
	{
		// Release the interface
		m_pIVideoDeviceControl->Release();
		m_pIVideoDeviceControl = NULL;
		DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s:   SUCCESS: releasing m_pIVideoDeviceControl", _fx_));
	}

	// Make sure the interface pointer is still valid
	if (!m_pIAMVfwCaptureDialogs)
	{
		DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   WARNING: already disconnected!", _fx_));
	}
	else
	{
		// Release the interface
		m_pIAMVfwCaptureDialogs->Release();
		m_pIAMVfwCaptureDialogs = NULL;
		DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s:   SUCCESS: releasing m_pIAMVfwCaptureDialogs", _fx_));
	}

	DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: end", _fx_));
	return NOERROR;
}

/****************************************************************************
 *  @doc INTERNAL CDEVICEPMETHOD
 *
 *  @mfunc BOOL | CDeviceProperties | OnReceiveMessage | This
 *    method is called when a message is sent to the property page dialog box.
 *
 *  @rdesc By default, returns the value returned by the Win32 DefWindowProc function.
 ***************************************************************************/
BOOL CDeviceProperties::OnReceiveMessage(HWND hWnd, UINT uMsg, WPARAM wParam, LPARAM lParam) 
{
	VIDEOCAPTUREDEVICEINFO	DeviceInfo;
	DWORD		dwDeviceIndex;
	DWORD		dwNumDevices;

	switch (uMsg)
	{
		case WM_INITDIALOG:
			EnableWindow(GetDlgItem(hWnd, IDC_Device_SourceDlg), (BOOL)(m_pIAMVfwCaptureDialogs && m_pIAMVfwCaptureDialogs->HasDialog(VfwCaptureDialog_Source) == S_OK));
			EnableWindow(GetDlgItem(hWnd, IDC_Device_FormatDlg), (BOOL)(m_pIAMVfwCaptureDialogs && m_pIAMVfwCaptureDialogs->HasDialog(VfwCaptureDialog_Format) == S_OK));
			EnableWindow(GetDlgItem(hWnd, IDC_Device_DisplayDlg), (BOOL)(m_pIAMVfwCaptureDialogs && m_pIAMVfwCaptureDialogs->HasDialog(VfwCaptureDialog_Display) == S_OK));
			if (m_pIVideoDeviceControl && SUCCEEDED(m_pIVideoDeviceControl->GetNumDevices(&dwNumDevices)) && dwNumDevices && SUCCEEDED(m_pIVideoDeviceControl->GetCurrentDevice(&dwDeviceIndex)))
			{
				m_dwOriginalDeviceIndex = dwDeviceIndex;

				// Populate the combo box
				ComboBox_ResetContent(GetDlgItem(hWnd, IDC_Device_Selection));
				for (dwDeviceIndex = 0; dwDeviceIndex < dwNumDevices; dwDeviceIndex++)
				{
					if (SUCCEEDED(m_pIVideoDeviceControl->GetDeviceInfo(dwDeviceIndex, &DeviceInfo)))
					{
						ComboBox_AddString(GetDlgItem(hWnd, IDC_Device_Selection), DeviceInfo.szDeviceDescription);

						// Update current device information
						if (dwDeviceIndex == m_dwOriginalDeviceIndex)
						{
							ComboBox_SetCurSel(GetDlgItem(hWnd, IDC_Device_Selection), m_dwOriginalDeviceIndex);
							SetDlgItemText(hWnd, IDC_Overlay_Support, DeviceInfo.fHasOverlay ? "Available" : "Not Available");
							SetDlgItemText(hWnd, IDC_Capture_Mode, DeviceInfo.nCaptureMode == CaptureMode_FrameGrabbing ? "Frame Grabbing" : "Streaming");
							SetDlgItemText(hWnd, IDC_Device_Type,
                                                                       DeviceInfo.nDeviceType ==  DeviceType_VfW ? "VfW Driver" :
                                                                       (DeviceInfo.nDeviceType ==  DeviceType_DShow ? "DShow Special" :
                                                                        "WDM Driver"));
							SetDlgItemText(hWnd, IDC_Device_Version, DeviceInfo.szDeviceVersion);
						}
					}
				}
			}
			else
			{
				EnableWindow(GetDlgItem(hWnd, IDC_Device_Selection), FALSE);
				EnableWindow(GetDlgItem(hWnd, IDC_CONTROL_DEFAULT), FALSE);
			}
			return TRUE; // Don't call setfocus

		case WM_COMMAND:

			// This message gets sent even before OnActivate() has been
			// called(!). We need to test and make sure the controls have
			// beeen initialized before we can use them.

			switch (LOWORD(wParam))
			{
				case IDC_Device_SourceDlg:
					if (m_pIAMVfwCaptureDialogs)
						m_pIAMVfwCaptureDialogs->ShowDialog(VfwCaptureDialog_Source, hWnd);
					break;

				case IDC_Device_FormatDlg:
					if (m_pIAMVfwCaptureDialogs)
						m_pIAMVfwCaptureDialogs->ShowDialog(VfwCaptureDialog_Format, hWnd);
					break;

				case IDC_Device_DisplayDlg:
					if (m_pIAMVfwCaptureDialogs)
						m_pIAMVfwCaptureDialogs->ShowDialog(VfwCaptureDialog_Display, hWnd);
					break;

				case IDC_Device_Selection:
					if (HIWORD(wParam) == CBN_SELCHANGE)
					{
						// Get the index of the selected device
						m_dwCurrentDeviceIndex = ComboBox_GetCurSel(GetDlgItem(hWnd, IDC_Device_Selection));
						if (SUCCEEDED(m_pIVideoDeviceControl->GetDeviceInfo(m_dwCurrentDeviceIndex, &DeviceInfo)))
						{
							// Update current device information
							SetDlgItemText(hWnd, IDC_Overlay_Support, DeviceInfo.fHasOverlay ? "Available" : "Not Available");
							SetDlgItemText(hWnd, IDC_Capture_Mode, DeviceInfo.nCaptureMode == CaptureMode_FrameGrabbing ? "Frame Grabbing" : "Streaming");
							SetDlgItemText(hWnd, IDC_Device_Type, DeviceInfo.nDeviceType ==  DeviceType_VfW ? "VfW Driver" :
                                                                       (DeviceInfo.nDeviceType ==  DeviceType_DShow ? "DShow Special" :
                                                                        "WDM Driver"));
							SetDlgItemText(hWnd, IDC_Device_Version, DeviceInfo.szDeviceVersion);
						}
					}
					break;

				default:
					break;
			}
			break;

		default:
			return FALSE;
	}

	return TRUE;
}

#endif
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\net\tapi\skywalker\filters\video\tapivcap\devices.cpp ===
#include "Precomp.h"
#include "dbgxtra.h"
#include <qedit.h>
#include <atlbase.h>

#define ABS(x) (((x) > 0) ? (x) : -(x))

HRESULT CALLBACK CDShowCapDev::CreateDShowCapDev(IN CTAPIVCap *pCaptureFilter, IN DWORD dwDeviceIndex, OUT CCapDev **ppCapDev)
{
    HRESULT Hr = NOERROR;
    IUnknown *pUnkOuter;

    FX_ENTRY("CDShowCapDev::CreateDShowCapDev")

    DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: begin", _fx_));

    ASSERT(pCaptureFilter);
    ASSERT(ppCapDev);
    if (!pCaptureFilter || !ppCapDev)
    {
        DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: Null pointer argument", _fx_));
        Hr = E_POINTER;
        goto MyExit;
    }

    // Get the outer unknown
    pCaptureFilter->QueryInterface(IID_IUnknown, (void **)&pUnkOuter);

    // Only keep the pUnkOuter reference
    pCaptureFilter->Release();

    // Create an instance of the capture device
    if (!(*ppCapDev = (CCapDev *) new CDShowCapDev(NAME("DShow Capture Device"), pCaptureFilter, pUnkOuter, dwDeviceIndex, &Hr)))
    {
        DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: Out of memory", _fx_));
        Hr = E_OUTOFMEMORY;
        goto MyExit;
    }

    // If initialization failed, delete the stream array and return the error
    if (FAILED(Hr) && *ppCapDev)
    {
        DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: Initialization failed", _fx_));
        Hr = E_FAIL;
        delete *ppCapDev, *ppCapDev = NULL;
    }

MyExit:
    DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: end", _fx_));
    return Hr;
}

CDShowCapDev::CDShowCapDev(
    IN TCHAR *pObjectName, IN CTAPIVCap *pCaptureFilter, IN LPUNKNOWN pUnkOuter,
    IN DWORD dwDeviceIndex, IN HRESULT *pHr) :
        CCapDev(pObjectName, pCaptureFilter, pUnkOuter, dwDeviceIndex, pHr)
{
    // which device we're talking to
    m_dwDeviceIndex = dwDeviceIndex;

    ZeroMemory(&m_mt, sizeof(AM_MEDIA_TYPE));

    m_hEvent = NULL;
    m_pBuffer = NULL;
    m_cbBuffer = 0;
    m_cbBufferValid = 0;
    m_fEventMode = FALSE;
    m_cBuffers = 0;
    m_nTop = 0;
    m_nBottom = 0;
}

/****************************************************************************
 *  @doc INTERNAL CDShowCAPDEVMETHOD
 *
 *  @mfunc void | CDShowCapDev | ~CDShowCapDev | This method is the destructor
 *    for the <c CDShowCapDev> object. Closes the driver file handle and
 *    releases the video data range memory
 *
 *  @rdesc Nada.
 ***************************************************************************/
CDShowCapDev::~CDShowCapDev()
{
    DisconnectFromDriver();
    FreeMediaType(m_mt);
    delete [] m_pBuffer;
}


STDMETHODIMP CDShowCapDev::NonDelegatingQueryInterface(IN REFIID riid, OUT void **ppv)
{
        HRESULT Hr = NOERROR;

        FX_ENTRY("CDShowCapDev::NonDelegatingQueryInterface")

        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: begin", _fx_));

        // Retrieve interface pointer
        if (riid == __uuidof(IVideoProcAmp))
        {
            *ppv = static_cast<IVideoProcAmp*>(this);
            GetOwner()->AddRef();
                DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s:   SUCCESS: IAMVideoProcAmp*=0x%08lX", _fx_, *ppv));
                goto MyExit;
        }
#ifndef USE_SOFTWARE_CAMERA_CONTROL
        else if (riid == __uuidof(ICameraControl))
        {
            *ppv = static_cast<ICameraControl*>(this);
            GetOwner()->AddRef();
                DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s:   SUCCESS: ICameraControl*=0x%08lX", _fx_, *ppv));
                goto MyExit;
        }
#endif
        else if (FAILED(Hr = CCapDev::NonDelegatingQueryInterface(riid, ppv)))
        {
                DBGOUT((g_dwVideoCaptureTraceID, WARN, "%s:   WARNING: NDQI for {%08lX-%04lX-%04lX-%02lX%02lX-%02lX%02lX%02lX%02lX%02lX%02lX} failed Hr=0x%08lX", _fx_, riid.Data1, riid.Data2, riid.Data3, riid.Data4[0], riid.Data4[1], riid.Data4[2], riid.Data4[3], riid.Data4[4], riid.Data4[5], riid.Data4[6], riid.Data4[7], Hr));
        }
        else
        {
                DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s:   SUCCESS: {%08lX-%04lX-%04lX-%02lX%02lX-%02lX%02lX%02lX%02lX%02lX%02lX}*=0x%08lX", _fx_, riid.Data1, riid.Data2, riid.Data3, riid.Data4[0], riid.Data4[1], riid.Data4[2], riid.Data4[3], riid.Data4[4], riid.Data4[5], riid.Data4[6], riid.Data4[7], *ppv));
        }

MyExit:
        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: end", _fx_));
        return Hr;
}

// Device control


//
HRESULT CDShowCapDev::ProfileCaptureDevice()
{
    // no dialogs for now
    m_dwDialogs = FORMAT_DLG_OFF | SOURCE_DLG_OFF | DISPLAY_DLG_OFF;

    // Frame grab has an extra memory copy, so never do it (WDM grabs for
    // large sizes)
    // m_dwStreamingMode = FRAME_GRAB_LARGE_SIZE;
    m_dwStreamingMode = STREAM_ALL_SIZES;

    // Let the base class complete the profiling
    return CCapDev::ProfileCaptureDevice();
}


// set up everything
//
HRESULT CDShowCapDev::ConnectToDriver()
{
    HRESULT hr;

    WCHAR wchar[MAX_PATH];
    char chDesc[MAX_PATH];
    lstrcpyW(wchar, L"@device:pnp:");	// must be prefixed with this
    MultiByteToWideChar(CP_ACP, 0, g_aDeviceInfo[m_dwDeviceIndex].szDevicePath, -1,
                        wchar + lstrlenW(wchar), MAX_PATH);

    // this will strip the "-SVideo" suffix off the description so the profile
    // code won't get confused by it.  Remember the original
    lstrcpyA(chDesc, g_aDeviceInfo[m_dwDeviceIndex].szDeviceDescription);
    
    hr = CSharedGraph::CreateInstance(wchar, g_aDeviceInfo[m_dwDeviceIndex].szDeviceDescription, &m_psg);
    if (FAILED(hr))
        return hr;

    // Don't build a graph yet, we'll just have to tear it down and build a
    // new one when we find out what format to use anyway

    // Get the formats from the registry - if this fails we profile the device
    if (FAILED(hr = GetFormatsFromRegistry())) {
        if (FAILED(hr = ProfileCaptureDevice())) {
            hr = VFW_E_NO_CAPTURE_HARDWARE;
        }
    }

    // now put the suffix back on the description so we'll know next time we
    // choose the device which input to use
    lstrcpyA(g_aDeviceInfo[m_dwDeviceIndex].szDeviceDescription, chDesc);

    return hr;
}


HRESULT CDShowCapDev::BuildGraph(AM_MEDIA_TYPE& mt)
{
    if (m_psg)
        return m_psg->BuildGraph(&mt, 0);
    else
        return E_UNEXPECTED;
}


HRESULT CDShowCapDev::DisconnectFromDriver()
{
    StopStreaming();    // just in case
    m_psg.Release();
    return S_OK;
}


//
HRESULT CDShowCapDev::SendFormatToDriver(
    IN LONG biWidth, IN LONG biHeight, IN DWORD biCompression, IN WORD biBitCount,
    IN REFERENCE_TIME AvgTimePerFrame, BOOL fUseExactFormat)
{
    VIDEOINFOHEADER viNew;
    
    if (m_psg == NULL)
        return E_UNEXPECTED;

    // don't attempt > 15fps, that's probably a waste of time
    if (AvgTimePerFrame && AvgTimePerFrame < 666667)
        AvgTimePerFrame = 666667;

    HRESULT hr = m_psg->SetVideoFormat(biWidth, biHeight, biCompression,
                biBitCount, AvgTimePerFrame,  fUseExactFormat, &viNew);
    if(SUCCEEDED(hr))
    {
        delete m_pCaptureFilter->m_user.pvi;
        m_pCaptureFilter->m_user.pvi = (VIDEOINFOHEADER *)new VIDEOINFOHEADER;
        if(m_pCaptureFilter->m_user.pvi == 0) {
            return E_OUTOFMEMORY;
        }
        CopyMemory(m_pCaptureFilter->m_user.pvi, &viNew, sizeof(VIDEOINFOHEADER));
        // this is our new fps to use
        m_usPerFrame = (DWORD)(AvgTimePerFrame / 10);

        // new fmt may need a new size 
        m_cbBuffer = 0;
    
    }

    return hr;
}


// we must use NEW to allocate it
// caller must "delete pvi"
//
HRESULT CDShowCapDev::GetFormatFromDriver(OUT VIDEOINFOHEADER **ppvi)
{
    if (m_psg == NULL)
        return E_UNEXPECTED;

    // this will only be called if we don't have a graph built yet from the
    // profiling code, which needs this to succeed, so FORCE a graph to be
    // built.
    return m_psg->GetVideoFormat(ppvi, TRUE);
}

// Streaming and frame grabbing control

HRESULT CDShowCapDev::InitializeStreaming(DWORD usPerFrame, DWORD_PTR hEvtBufferDone)
{
    ASSERT(!m_fEventMode);
    HRESULT hr = S_OK;

    // we shouldn't ever close this handle, right?
    m_hEvent = (HANDLE)hEvtBufferDone;

    m_fEventMode = TRUE;    // this is event fire mode (not grab mode)

    // don't attempt > 15fps, that's probably a waste of time
    if (usPerFrame && usPerFrame < 66667)
        usPerFrame = 66667;

    m_usPerFrame = usPerFrame; // remember this

    return hr;
}


HRESULT CDShowCapDev::StartStreaming()
{
    if (m_psg == NULL)
        return E_UNEXPECTED;

    // note the buffer is empty
    m_cbBufferValid = 0;

    ASSERT(m_pBuffer == NULL);
    ASSERT(m_cbBuffer);

    // make a new buffer
    m_pBuffer = new BYTE[m_cbBuffer];
    if (m_pBuffer == NULL)
	return E_OUTOFMEMORY;

    return m_psg->RunVideo(this, CDShowCapDev::VideoCallback, m_usPerFrame);
}


HRESULT CDShowCapDev::StopStreaming()
{
    if (m_psg == NULL)
        return E_UNEXPECTED;

    m_psg->StopVideo();
    
    delete [] m_pBuffer;
    m_pBuffer = NULL;
    
    return S_OK;
}


// What should we do here?
//
HRESULT CDShowCapDev::TerminateStreaming()
{
    ASSERT(m_fEventMode);
    m_fEventMode = FALSE;   // exit event mode

    return S_OK;
}


HRESULT CDShowCapDev::GrabFrame(PVIDEOHDR pVHdr)
{
    HRESULT hr = NOERROR;

    // Validate input parameters
    ASSERT(pVHdr);
    if (!pVHdr || !pVHdr->lpData) {
        return E_INVALIDARG;
    }

    // timeout after no less than 10sec instead of hanging
    int x=0;
    while (!m_cbBufferValid && x++ < 1000) {
	Sleep(10);
    }
    if (!m_cbBufferValid)
        return E_UNEXPECTED;

    // don't read and write here at the same time
    CAutoLock foo(&m_csBuffer);
    
    ASSERT((int)pVHdr->dwBufferLength >= m_cbBuffer);

    // !!! I do 2 memory copies in frame grab mode
    CopyMemory(pVHdr->lpData, m_pBuffer, m_cbBuffer);
        
    pVHdr->dwTimeCaptured = timeGetTime();  // !!! not right
    pVHdr->dwBytesUsed = m_cbBufferValid;
    pVHdr->dwFlags |= VHDR_KEYFRAME;	    // !!! can't be sure

    return hr;
}


HRESULT CDShowCapDev::AllocateBuffer(LPTHKVIDEOHDR *pptvh, DWORD dwIndex, DWORD cbBuffer)
{
    HRESULT Hr = NOERROR;

    // Validate input parameters
    ASSERT(pptvh);
    ASSERT(cbBuffer);
    if (!pptvh || !cbBuffer)
    {
        return E_INVALIDARG;
    }

    // note how big buffers need to be
    ASSERT(m_cbBuffer == 0 || m_cbBuffer == cbBuffer);
    m_cbBuffer = cbBuffer;

    *pptvh = &m_pCaptureFilter->m_cs.paHdr[dwIndex].tvh;
    (*pptvh)->vh.dwBufferLength = cbBuffer;
    if (!((*pptvh)->vh.lpData = new BYTE[cbBuffer]))
    {
            return E_OUTOFMEMORY;
    }
    (*pptvh)->p32Buff = (*pptvh)->vh.lpData;

    ASSERT (!IsBadWritePtr((*pptvh)->p32Buff, cbBuffer));
    ZeroMemory((*pptvh)->p32Buff,cbBuffer);

    ASSERT(m_cBuffers == dwIndex);
    m_cBuffers++;   // keep track of how many buffers there are
    
    // add this buffer to the initial list (we don't get add buffers the 1st time through)
    m_aStack[m_nTop++] = dwIndex;

    return Hr;
}


HRESULT CDShowCapDev::AddBuffer(PVIDEOHDR pVHdr, DWORD cbVHdr)
{
    // Which buffer is this?  (Stupid thing doesn't know!)
    DWORD dwIndex;    
    for (dwIndex=0; dwIndex < m_pCaptureFilter->m_cs.nHeaders; dwIndex++) {
        if (&m_pCaptureFilter->m_cs.paHdr[dwIndex].tvh.vh == pVHdr)
            break;
    }

    // Can't find it!
    if (dwIndex == m_pCaptureFilter->m_cs.nHeaders) {
        ASSERT(FALSE);
	return E_INVALIDARG;
    }
			       
    // IsBufferDone might be looking at m_nTop - don't let it be MAX
    CAutoLock foo(&m_csStack);

    // add this to our list
    m_aStack[m_nTop++] = dwIndex;
    if (m_nTop == MAX_BSTACK)
	m_nTop = 0;
        
    return S_OK;
}


HRESULT CDShowCapDev::FreeBuffer(LPTHKVIDEOHDR pVHdr)
{
    HRESULT Hr = NOERROR;

    // Validate input parameters
    ASSERT(pVHdr);
    if (!pVHdr || !pVHdr->vh.lpData)
    {
        return E_POINTER;
    }

    delete pVHdr->vh.lpData, pVHdr->vh.lpData = NULL;
    pVHdr->p32Buff = NULL;

    m_cBuffers--;

    m_nTop = m_nBottom = 0; // back to empty stack

    return Hr;
}


HRESULT CDShowCapDev::AllocateHeaders(DWORD dwNumHdrs, DWORD cbHdr, LPVOID *ppaHdr)
{
    HRESULT Hr = NOERROR;
    CheckPointer(ppaHdr, E_POINTER);
    ASSERT(cbHdr);
    if (!cbHdr) {
        return E_INVALIDARG;
    }

    // MUST use NEW
    if (!(*ppaHdr = new BYTE[cbHdr * dwNumHdrs])) {
        return E_OUTOFMEMORY;
    }

    ZeroMemory(*ppaHdr, cbHdr * dwNumHdrs);

    m_nTop = m_nBottom = 0; // start with empty stack

    return Hr;
}


BOOL CDShowCapDev::IsBufferDone(PVIDEOHDR pVHdr)
{
    // don't let anybody mess up m_nTop or m_nBottom
    CAutoLock foo(&m_csStack);

    // walk the list of things not done
    BOOL fDone = TRUE;
    int iTop = m_nTop >= m_nBottom ? m_nTop : m_nTop + MAX_BSTACK;
    for (int z = m_nBottom; z < iTop; z++) {
	PVIDEOHDR pv = &m_pCaptureFilter->m_cs.paHdr[m_aStack[z % MAX_BSTACK]].tvh.vh;
        if (pv == pVHdr) {
            fDone = FALSE;
            break;
        }
    }

    return fDone;
}


// sample grabber stuff
//
void CDShowCapDev::VideoCallback(void *pContext, IMediaSample *pSample)
{
    CDShowCapDev *pThis = (CDShowCapDev *)pContext;
    int cbSrc = pSample->GetActualDataLength();

    // oh uh, this frame is too big
    ASSERT(cbSrc <= pThis->m_cbBuffer);

    // oh uh, this frame is too small
    if (cbSrc <= 0)
        return;

    BYTE *pSrc;
    pSample->GetPointer(&pSrc);
				   
    // GRAB FRAME MODE - save it away
    if (!pThis->m_fEventMode) {
	// don't read and write here at the same time
	CAutoLock foo(&pThis->m_csBuffer);

	// !!! I do 2 memory copies in frame grab mode
	CopyMemory(pThis->m_pBuffer, pSrc, cbSrc);
	pThis->m_cbBufferValid = cbSrc;

    // STREAMING MODE - send it off
    } else {

	// no place to put this frame, drop it
	if (pThis->m_nTop == pThis->m_nBottom) {
	    return;
	}

        // IsBufferDone might be looking at m_nBottom - don't let it be MAX
        pThis->m_csStack.Lock();

	PVIDEOHDR pv = &pThis->m_pCaptureFilter->m_cs.paHdr[pThis->m_aStack[pThis->m_nBottom++]].tvh.vh;
	if (pThis->m_nBottom == MAX_BSTACK)
	    pThis->m_nBottom = 0;
        pThis->m_csStack.Unlock();

	CopyMemory(pv->lpData, pSrc, cbSrc);
        
	pv->dwTimeCaptured = timeGetTime();  // !!! not right
	pv->dwBytesUsed = cbSrc;
	pv->dwFlags |= VHDR_KEYFRAME;	     // !!! can't be sure

        

	SetEvent(pThis->m_hEvent);

    }
    return;
}
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\net\tapi\skywalker\filters\video\tapivcap\devicev.cpp ===
/****************************************************************************
 *  @doc INTERNAL DEVICEV
 *
 *  @module DeviceV.cpp | Source file for the <c CVfWCapDev>
 *    base class used to communicate with a VfW capture device.
 ***************************************************************************/

#include "Precomp.h"

#ifdef DEBUG
#define DBGUTIL_ENABLE
#endif

#define DEVICEV_DEBUG

  //the define below signales the dbgutil.cpp folowing after that the .cpp it is actually *included*
  //and not compiled standalone
  #define __DBGUTIL_INCLUDED__
  //hack to avoid adding the file below in sources;
  //all other files using dbgutil functions should include dbgutil.h instead
  //--//#include "dbgutil.cpp"
  //the above includes dbgutil.h that defines the __DBGUTIL_H__

#if defined(DBGUTIL_ENABLE) && defined(__DBGUTIL_H__)

  #ifdef DEVICEV_DEBUG
    DEFINE_DBG_VARS(DeviceV, (NTSD_OUT | LOG_OUT), 0x0);
  #else
    DEFINE_DBG_VARS(DeviceV, 0, 0);
  #endif
  #define D(f) if(g_dbg_DeviceV & (f))

#else
  #undef DEVICEV_DEBUG

  #define D(f) ; / ## /
  #define dprintf ; / ## /
  #define dout ; / ## /
#endif


/****************************************************************************
 *  @doc INTERNAL CFWCAPDEVMETHOD
 *
 *  @mfunc void | CVfWCapDev | CVfWCapDev | This method is the constructor
 *    for the <c CVfWCapDev> object.
 *
 *  @rdesc Nada.
 ***************************************************************************/
CVfWCapDev::CVfWCapDev(IN TCHAR *pObjectName, IN CTAPIVCap *pCaptureFilter, IN LPUNKNOWN pUnkOuter, IN DWORD dwDeviceIndex, IN HRESULT *pHr) : CCapDev(pObjectName, pCaptureFilter, pUnkOuter, dwDeviceIndex, pHr)
{
        FX_ENTRY("CVfWCapDev::CVfWCapDev")

        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: begin", _fx_));

        if (!pHr || FAILED(*pHr))
        {
                DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: Base class error or invalid input parameter", _fx_));
                goto MyExit;
        }

        // Default inits
        m_dwDeviceID = g_aDeviceInfo[m_dwDeviceIndex].dwVfWIndex;
        m_hVideoIn = NULL;
        m_hVideoExtIn = NULL;
        m_hVideoExtOut = NULL;
        m_bHasOverlay = FALSE;

MyExit:
        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: end", _fx_));
}

/****************************************************************************
 *  @doc INTERNAL CVFWCAPDEVMETHOD
 *
 *  @mfunc void | CVfWCapDev | ~CVfWCapDev | This method is the destructor
 *    for the <c CVfWCapDev> object.
 *
 *  @rdesc Nada.
 ***************************************************************************/
CVfWCapDev::~CVfWCapDev()
{
        FX_ENTRY("CVfWCapDev::~CVfWCapDev")

        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: begin", _fx_));

        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: end", _fx_));
}

/****************************************************************************
 *  @doc INTERNAL CVFWCAPDEVMETHOD
 *
 *  @mfunc CVfWCapDev* | CVfWCapDev | CreateVfWCapDev | This
 *    helper function creates an object to interact with the VfW capture
 *    device.
 *
 *  @parm CTAPIVCap* | pCaptureFilter | Specifies a pointer to the owner
 *    filter.
 *
 *  @parm CCapDev** | ppCapDev | Specifies the address of a pointer to the
 *    newly created <c CVfWCapDev> object.
 *
 *  @rdesc This method returns an HRESULT value that depends on the
 *    implementation of the interface. HRESULT can include one of the
 *    following standard constants, or other values not listed:
 *
 *  @flag E_FAIL | Failure
 *  @flag E_POINTER | Null pointer argument
 *  @flag E_OUTOFMEMORY | Out of memory
 *  @flag NOERROR | No error
 ***************************************************************************/
HRESULT CALLBACK CVfWCapDev::CreateVfWCapDev(IN CTAPIVCap *pCaptureFilter, IN DWORD dwDeviceIndex, OUT CCapDev **ppCapDev)
{
        HRESULT Hr = NOERROR;
        IUnknown *pUnkOuter;

        FX_ENTRY("CVfWCapDev::CreateVfWCapDev")

        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: begin", _fx_));

        // Validate input parameters
        ASSERT(pCaptureFilter);
        ASSERT(ppCapDev);
        if (!pCaptureFilter || !ppCapDev)
        {
                DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: Null pointer argument", _fx_));
                Hr = E_POINTER;
                goto MyExit;
        }

        // Get the outer unknown
        pCaptureFilter->QueryInterface(IID_IUnknown, (void **)&pUnkOuter);

        // Only keep the pUnkOuter reference
        pCaptureFilter->Release();

        // Create an instance of the capture device
        if (!(*ppCapDev = (CCapDev *) new CVfWCapDev(NAME("VfW Capture Device"), pCaptureFilter, pUnkOuter, dwDeviceIndex, &Hr)))
        {
                DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: Out of memory", _fx_));
                Hr = E_OUTOFMEMORY;
                goto MyExit;
        }

        // If initialization failed, delete the stream array and return the error
        if (FAILED(Hr) && *ppCapDev)
        {
                DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: Initialization failed", _fx_));
                Hr = E_FAIL;
                delete *ppCapDev, *ppCapDev = NULL;
        }

MyExit:
        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: end", _fx_));
        return Hr;
}

/****************************************************************************
 *  @doc INTERNAL CVFWCAPDEVMETHOD
 *
 *  @mfunc HRESULT | CVfWCapDev | NonDelegatingQueryInterface | This
 *    method is the nondelegating interface query function. It returns a pointer
 *    to the specified interface if supported. The only interfaces explicitly
 *    supported being <i IAMVfWCaptureDialogs>.
 *
 *  @parm REFIID | riid | Specifies the identifier of the interface to return.
 *
 *  @parm PVOID* | ppv | Specifies the place in which to put the interface
 *    pointer.
 *
 *  @rdesc This method returns an HRESULT value that depends on the
 *    implementation of the interface. HRESULT can include one of the
 *    following standard constants, or other values not listed:
 *
 *  @flag E_FAIL | Failure
 *  @flag E_POINTER | Null pointer argument
 *  @flag NOERROR | No error
 *
 *  @todo Add interfaces specific to this derived class or remove this code
 *    and let the base class do the work.
 ***************************************************************************/
STDMETHODIMP CVfWCapDev::NonDelegatingQueryInterface(IN REFIID riid, OUT void **ppv)
{
        HRESULT Hr = NOERROR;

        FX_ENTRY("CVfWCapDev::NonDelegatingQueryInterface")

        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: begin", _fx_));

        if (FAILED(Hr = CCapDev::NonDelegatingQueryInterface(riid, ppv)))
        {
                DBGOUT((g_dwVideoCaptureTraceID, WARN, "%s:   WARNING: NDQI for {%08lX-%04lX-%04lX-%02lX%02lX-%02lX%02lX%02lX%02lX%02lX%02lX} failed Hr=0x%08lX", _fx_, riid.Data1, riid.Data2, riid.Data3, riid.Data4[0], riid.Data4[1], riid.Data4[2], riid.Data4[3], riid.Data4[4], riid.Data4[5], riid.Data4[6], riid.Data4[7], Hr));
        }
        else
        {
                DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s:   SUCCESS: {%08lX-%04lX-%04lX-%02lX%02lX-%02lX%02lX%02lX%02lX%02lX%02lX}*=0x%08lX", _fx_, riid.Data1, riid.Data2, riid.Data3, riid.Data4[0], riid.Data4[1], riid.Data4[2], riid.Data4[3], riid.Data4[4], riid.Data4[5], riid.Data4[6], riid.Data4[7], *ppv));
        }

        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: end", _fx_));
        return Hr;
}

/****************************************************************************
 *  @doc INTERNAL CVFWCAPDEVMETHOD
 *
 *  @mfunc HRESULT | CVfWCapDev | ConnectToDriver | This method is used to
 *    open a VfW capture device, get its format capibilities, and set a default
 *    format.
 *
 *  @rdesc This method returns an HRESULT value that depends on the
 *    implementation of the interface. HRESULT can include one of the
 *    following standard constants, or other values not listed:
 *
 *  @flag E_FAIL | Failure
 *  @flag NOERROR | No error
 ***************************************************************************/
HRESULT CVfWCapDev::ConnectToDriver()
{
        HRESULT Hr = NOERROR;
        MMRESULT mmr;

        FX_ENTRY("CVfWCapDev::ConnectToDriver")

        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: begin", _fx_));

        // Open and initialize all the channels in the SAME ORDER that AVICap did,
        // for compatability with buggy drivers like Broadway and BT848.

        // Open the VIDEO_IN driver, the one we mostly talk to, and who provides
        // the video FORMAT dialog
        m_hVideoIn = NULL;
        if (mmr = videoOpen(&m_hVideoIn, m_dwDeviceID, VIDEO_IN))
        {
                DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: Failed VIDEO_IN videoOpen - Aborting!", _fx_));
                Hr = VFW_E_NO_CAPTURE_HARDWARE;
                goto MyExit;
        }

        // Now open the EXTERNALIN device. It's only good for providing the video
        // SOURCE dialog, so it doesn't really matter if we can't get it
        m_hVideoExtIn = NULL;
        if (mmr = videoOpen(&m_hVideoExtIn, m_dwDeviceID, VIDEO_EXTERNALIN))
        {
                DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   WARNING: Failed VIDEO_EXTERNALIN videoOpen", _fx_));
                dprintf("V ! %s:   WARNING: Failed VIDEO_EXTERNALIN videoOpen", _fx_);
        }

        // Now open the EXTERNALOUT device. It's only good for providing the video
        // DISPLAY dialog, and for overlay, so it doesn't really matter if we can't
        // get it
        m_bHasOverlay = FALSE;
        m_hVideoExtOut = NULL;
#ifdef USE_OVERLAY
        if (videoOpen(&m_hVideoExtOut, m_dwDeviceID, VIDEO_EXTERNALOUT) == DV_ERR_OK)
        {
                CHANNEL_CAPS VideoCapsExternalOut;
                if (m_hVideoExtOut && videoGetChannelCaps(m_hVideoExtOut, &VideoCapsExternalOut, sizeof(CHANNEL_CAPS)) == DV_ERR_OK)
                {
                        m_bHasOverlay = (BOOL)(VideoCapsExternalOut.dwFlags & (DWORD)VCAPS_OVERLAY);
                }
                else
                {
                        DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   WARNING:  videoGetChannelCaps failed", _fx_));
                }
        }
        else
        {
                DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   WARNING:  Failed VIDEO_EXTERNALOUT videoOpen", _fx_));
        }
#endif

        // VidCap does this, so I better too or some cards will refuse to preview
        if (mmr == 0)
                videoStreamInit(m_hVideoExtIn, 0, 0, 0, 0);

        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: Driver %s OVERLAY", _fx_, m_bHasOverlay ? "supports" : "doesn't support"));

        // Get the formats from the registry - if this fail we'll profile the device
        if (FAILED(Hr = CCapDev::GetFormatsFromRegistry()))
        {
                if (FAILED(Hr = CCapDev::ProfileCaptureDevice()))
                {
                        DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: ProfileCaptureDevice failed!", _fx_));
                        Hr = VFW_E_NO_CAPTURE_HARDWARE;
                        goto MyExit;
                }
#ifdef DEVICEV_DEBUG
                else    dout(3, g_dwVideoCaptureTraceID, TRCE,"%s:    ProfileCaptureDevice", _fx_);
#endif
        }
#ifdef DEVICEV_DEBUG
        else    dout(3, g_dwVideoCaptureTraceID, TRCE,"%s:    GetFormatsFromRegistry", _fx_);

        dump_video_format_image_size(m_dwImageSize);
        dump_video_format_num_colors(m_dwFormat);
#endif




MyExit:
        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: end", _fx_));
        return Hr;
}

/****************************************************************************
 *  @doc INTERNAL CVFWCAPDEVMETHOD
 *
 *  @mfunc HRESULT | CVfWCapDev | DisconnectFromDriver | This method is used to
 *    release the capture device.
 *
 *  @rdesc This method returns an HRESULT value that depends on the
 *    implementation of the interface. HRESULT can include one of the
 *    following standard constants, or other values not listed:
 *
 *  @flag E_FAIL | Failure
 *  @flag NOERROR | No error
 ***************************************************************************/
HRESULT CVfWCapDev::DisconnectFromDriver()
{
        HRESULT Hr = NOERROR;

        FX_ENTRY("CVfWCapDev::DisconnectFromDriver")

        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: begin", _fx_));
        if (m_hVideoIn)
        {
                Hr = videoClose (m_hVideoIn);
                ASSERT(Hr == NOERROR);
                m_hVideoIn=NULL;
        }


        ASSERT(Hr ==  NOERROR);
        if (m_hVideoExtIn)
        {
                Hr = videoStreamFini(m_hVideoExtIn); // this one was streaming
                ASSERT(Hr ==  NOERROR);
                Hr = videoClose (m_hVideoExtIn);
                ASSERT(Hr == NOERROR);
                m_hVideoExtIn=NULL;
        }

        ASSERT(Hr ==  NOERROR);
        if (m_hVideoExtOut) {
                Hr = videoClose (m_hVideoExtOut);
                ASSERT(Hr == NOERROR);
                m_hVideoExtOut=NULL;
        }
        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: end", _fx_));
        return Hr;
}

/****************************************************************************
 *  @doc INTERNAL CVFWCAPDEVMETHOD
 *
 *  @mfunc HRESULT | CVfWCapDev | ProfileCaptureDevice | This method is used to
 *    determine the list of formats supported by a VfW capture device.
 *
 *  @rdesc This method returns an HRESULT value that depends on the
 *    implementation of the interface. HRESULT can include one of the
 *    following standard constants, or other values not listed:
 *
 *  @flag E_FAIL | Failure
 *  @flag E_UNEXPECTED | Unrecoverable error
 *  @flag NOERROR | No error
 ***************************************************************************/
HRESULT CVfWCapDev::ProfileCaptureDevice()
{
        FX_ENTRY("CVfWCapDev::ProfileCaptureDevice")

        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: begin", _fx_));

        // Provide defaults
        m_dwDialogs = FORMAT_DLG_OFF | SOURCE_DLG_OFF | DISPLAY_DLG_OFF;

        // Ask the driver what dialogs it supports.
        if (m_hVideoExtIn && videoDialog(m_hVideoExtIn, GetDesktopWindow(), VIDEO_DLG_QUERY) == 0)
                m_dwDialogs |= SOURCE_DLG_ON;
        if (m_hVideoIn && videoDialog(m_hVideoIn, GetDesktopWindow(), VIDEO_DLG_QUERY) == 0)
                m_dwDialogs |= FORMAT_DLG_ON;
        if (m_hVideoExtOut && videoDialog(m_hVideoExtOut, GetDesktopWindow(), VIDEO_DLG_QUERY) == 0)
                m_dwDialogs |= DISPLAY_DLG_ON;

        // Disable streaming of large size by default on VfW devices
        m_dwStreamingMode = FRAME_GRAB_LARGE_SIZE;

    // Let the base class complete the profiling
        return CCapDev::ProfileCaptureDevice();
}

/****************************************************************************
 *  @doc INTERNAL CVFWCAPDEVMETHOD
 *
 *  @mfunc HRESULT | CVfWCapDev | SendFormatToDriver | This method is used to
 *    tell the VfW capture device what format to use.
 *
 *  @parm LONG | biWidth | Specifies the image width.
 *
 *  @parm LONG | biHeight | Specifies the image height.
 *
 *  @parm DWORD | biCompression | Specifies the format type.
 *
 *  @parm WORD | biBitCount | Specifies the number of bits per pixel.
 *
 *  @parm REFERENCE_TIME | AvgTimePerFrame | Specifies the frame rate.
 *
 *  @rdesc This method returns an HRESULT value that depends on the
 *    implementation of the interface. HRESULT can include one of the
 *    following standard constants, or other values not listed:
 *
 *  @flag E_FAIL | Failure
 *  @flag NOERROR | No error
 ***************************************************************************/
HRESULT CVfWCapDev::SendFormatToDriver(IN LONG biWidth, IN LONG biHeight, IN DWORD biCompression, IN WORD biBitCount, IN REFERENCE_TIME AvgTimePerFrame, BOOL fUseExactFormat)
{
        HRESULT Hr = NOERROR;
        BITMAPINFOHEADER bmih;
        int nFormat, nBestFormat;
        int     i, delta, best, tmp;

        FX_ENTRY("CVfWCapDev::SendFormatToDriver")

        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: begin", _fx_));
        dprintf("+ %s\n",_fx_);

        // Validate input parameters
        ASSERT(m_hVideoIn);
        if (!m_hVideoIn)
        {
                DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: Invalid input parameter!", _fx_));
                Hr = E_POINTER;
                goto MyExit;
        }

        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s:   Trying to set %dx%d at %ld fps", _fx_, biWidth, biHeight, AvgTimePerFrame != 0 ? (LONG)(10000000 / AvgTimePerFrame) : 0));

        // Common to all formats
        bmih.biSize = sizeof(BITMAPINFOHEADER);
        bmih.biPlanes = 1;
        bmih.biXPelsPerMeter = bmih.biYPelsPerMeter = bmih.biClrUsed = bmih.biClrImportant = 0;

        if (!fUseExactFormat)
        {
                D(1) dprintf("V Not using 'fUseExactFormat' .... m_dwFormat = 0x%08lx\n", m_dwFormat);
                D(1) dprintf("V Looking for 4cc %lX : '%.4s'\n", biCompression, &biCompression);
                // Can we directly capture data in this format?
                for (nFormat=0, nBestFormat=-1; nFormat<NUM_BITDEPTH_ENTRIES; nFormat++)
                {
                        // Try a format supported by the device
                        // @todo Rename those variables - it's the format, not the number of colors...
                        if (aiFormat[nFormat] & m_dwFormat)
                        {
                                // Remember the device supports this format
                                if (nBestFormat == -1)
                                        nBestFormat = nFormat;

                                // Is this the format we're being asked to use?
                                if (aiFourCCCode[nFormat] == biCompression)
                                        break;
                        }
                }

                // If we found a match, use this format. Otherwise, pick
                // whatever else this device can do
                if (nFormat == NUM_BITDEPTH_ENTRIES)
                {
                        nFormat = nBestFormat;
                }
                D(1) dprintf("V nFormat = %d\n", nFormat);

                bmih.biBitCount = aiBitDepth[nFormat];
                bmih.biCompression = aiFourCCCode[nFormat];

                // Find the best image size to capture at
                // Assume the next resolution will be correctly truncated to the output size
                best = -1;
                delta = 999999;
                dprintf("V biWidth, biHeight = %ld, %ld\n",biWidth, biHeight);
                for (i=0; i<VIDEO_FORMAT_NUM_RESOLUTIONS; i++)
                {
                        if (awResolutions[i].dwRes & m_dwImageSize)
                        {
                                tmp = awResolutions[i].framesize.cx - biWidth;
                                if (tmp < 0) tmp = -tmp;
                                if (tmp < delta)
                                {
                                        delta = tmp;
                                        best = i;
                                }
                                tmp = awResolutions[i].framesize.cy - biHeight;
                                if (tmp < 0) tmp = -tmp;
                                if (tmp < delta)
                                {
                                        delta = tmp;
                                        best = i;
                                }
                        }
                }

                if (best < 0)
                {
                        DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: Can't find appropriate format!", _fx_));
                        Hr = E_FAIL;
                        goto MyExit;
                }

                bmih.biWidth = awResolutions[best].framesize.cx;
                bmih.biHeight = awResolutions[best].framesize.cy;
        }
        else
        {
                bmih.biWidth = biWidth;
                bmih.biHeight = biHeight;
                bmih.biBitCount = biBitCount;
                bmih.biCompression = biCompression;
        }
#ifdef DEVICEV_DEBUG
        dprintf("V 4CC used = %lX : '%.4s'\n", bmih.biCompression, &bmih.biCompression);
        g_dbg_4cc=bmih.biCompression;
        g_dbg_bc =bmih.biBitCount;
        g_dbg_w  =bmih.biWidth;
        g_dbg_h = bmih.biHeight;
#endif
        bmih.biSizeImage = DIBSIZE(bmih);

        // @todo Copy the palette if there is one

        // Update last format fields
        if (biCompression == BI_RGB)
        {
                if (biBitCount == 4)
                {
                        bmih.biClrUsed = 0;     //WDM version says 16 here...
                        bmih.biClrImportant = 16;
                }
                else if (biBitCount == 8)
                {
                        bmih.biClrUsed = 0;     //WDM version says 256 here...
                        bmih.biClrImportant = 256;
                }
        }

        dprintf("V >>>>>> Asking for: (bmih.) biWidth = %ld, biHeight = %ld, biCompression = '%.4s'\n", bmih.biWidth, bmih.biHeight, &bmih.biCompression);
        D(1) dprintf("V bmih Before:\n");
        D(1) DumpBMIH(&bmih);
        // Do a final check of this format with the capture device
        if (videoConfigure(m_hVideoIn, DVM_FORMAT, VIDEO_CONFIGURE_SET, NULL, &bmih, bmih.biSize, NULL, 0))
        {
                DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: Invalid input format!", _fx_));
                Hr = VFW_E_INVALIDMEDIATYPE;
                goto MyExit;
        }

        D(1) dprintf("V bmih After:\n");
        D(1) DumpBMIH(&bmih);
        // @todo Do I need to set a palette too?  Do I care?

        // Allocate space for a videoinfo that will hold current format
        if (m_pCaptureFilter->m_user.pvi)
                delete m_pCaptureFilter->m_user.pvi, m_pCaptureFilter->m_user.pvi = NULL;

        //VFWCAPTUREOPTIONS
        D(1) dprintf("V The m_pCaptureFilter->m_user.pvi Before:\n");
        D(1) dprintf("V  m_pCaptureFilter->m_user.pvi = %p\n",m_pCaptureFilter->m_user.pvi);

        GetFormatFromDriver(&m_pCaptureFilter->m_user.pvi);
        D(1) dprintf("V The m_pCaptureFilter->m_user.pvi After:\n");
        D(1) DumpVIH(m_pCaptureFilter->m_user.pvi);
        D(1) DumpBMIH(&m_pCaptureFilter->m_user.pvi->bmiHeader);


        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s:   SUCCESS: Setting %dx%d at %ld fps", _fx_, biWidth, biHeight, (LONG)AvgTimePerFrame));

MyExit:
        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: end", _fx_));
        dprintf("- %s : returning 0x%08x\n",_fx_,(DWORD)Hr);
        return Hr;
}

/****************************************************************************
 *  @doc INTERNAL CVFWCAPDEVMETHOD
 *
 *  @mfunc HRESULT | CVfWCapDev | GetFormatFromDriver | This method is used to
 *    retrieve the VfW capture device format in use.
 *
 *  @parm VIDEOINFOHEADER ** | ppvi | Specifies the address of a pointer to
 *    a video info header structure to receive the video format description.
 *
 *  @rdesc This method returns an HRESULT value that depends on the
 *    implementation of the interface. HRESULT can include one of the
 *    following standard constants, or other values not listed:
 *
 *  @flag E_FAIL | Failure
 *  @flag NOERROR | No error
 ***************************************************************************/
HRESULT CVfWCapDev::GetFormatFromDriver(VIDEOINFOHEADER **ppvi)
{
        HRESULT                         Hr = NOERROR;
        DWORD                           biSize = 0;
        UINT                            cb;
        VIDEOINFOHEADER         *pvi = NULL;
        LPBITMAPINFOHEADER      pbih = NULL;
        struct
        {
                WORD         wVersion;
                WORD         wNumEntries;
                PALETTEENTRY aEntry[256];
        } Palette;

        FX_ENTRY("CVfWCapDev::GetFormatFromDriver")

        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: begin", _fx_));

        // Validate input parameters
        ASSERT(m_hVideoIn);
        if (!m_hVideoIn)
        {
                DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: Invalid input parameter!", _fx_));
                Hr = E_UNEXPECTED;
                goto MyExit;
        }

        // How large is the BITMAPINFOHEADER?
        videoConfigure(m_hVideoIn, DVM_FORMAT, VIDEO_CONFIGURE_GET | VIDEO_CONFIGURE_QUERYSIZE, &biSize, 0, 0, NULL, 0);
        if (!biSize)
                biSize = sizeof(BITMAPINFOHEADER);

        // Allocate space for a videoinfo that will hold it
        cb = sizeof(VIDEOINFOHEADER) + biSize - sizeof(BITMAPINFOHEADER) + sizeof(RGBQUAD) * 256;       // space for PALETTE or BITFIELDS
        pvi = (VIDEOINFOHEADER *)(new BYTE[cb]);
        pbih = &pvi->bmiHeader;
        if (!(*ppvi = pvi))
        {
                DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: Out of memory!", _fx_));
                Hr = E_OUTOFMEMORY;
                goto MyExit;
        }

        // Get the current format
        if (videoConfigure(m_hVideoIn, DVM_FORMAT, VIDEO_CONFIGURE_GET | VIDEO_CONFIGURE_CURRENT, NULL, pbih, biSize, NULL, 0))
        {
                DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: Can't get current format from driver!", _fx_));
                Hr = E_FAIL;
                goto MyExit;
        }

        // Get the palette if necessary
        if (pvi->bmiHeader.biCompression == BI_RGB && pvi->bmiHeader.biBitCount <= 8)
        {
                RGBQUAD *pRGB;
                PALETTEENTRY *pe;

                Palette.wVersion = 0x0300;
                Palette.wNumEntries = pvi->bmiHeader.biBitCount == 8 ? 256 : 16;
                videoConfigure(m_hVideoIn, DVM_PALETTE, VIDEO_CONFIGURE_GET | VIDEO_CONFIGURE_CURRENT, NULL, &Palette, sizeof(Palette), NULL, 0);

                // Convert the palette into a bitmapinfo set of RGBQUAD's
                pRGB = ((LPBITMAPINFO)&pvi->bmiHeader)->bmiColors;
                pe   = Palette.aEntry;
                for (UINT ii = 0; ii < (UINT)Palette.wNumEntries; ++ii, ++pRGB, ++pe)
                {
                        pRGB->rgbBlue  = pe->peBlue;
                        pRGB->rgbGreen = pe->peGreen;
                        pRGB->rgbRed   = pe->peRed;
                        pRGB->rgbReserved = pe->peFlags;
                }

                pvi->bmiHeader.biClrUsed = Palette.wNumEntries;
        }

        // Fix broken bitmap info headers
        if (pvi->bmiHeader.biSizeImage == 0 && (pvi->bmiHeader.biCompression == BI_RGB || pvi->bmiHeader.biCompression == BI_BITFIELDS))
        {
                DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s:   WARNING: Fixing broken bitmap info header!", _fx_));
                pvi->bmiHeader.biSizeImage = DIBSIZE(pvi->bmiHeader);
        }
        if (pvi->bmiHeader.biCompression == VIDEO_FORMAT_YVU9 && pvi->bmiHeader.biBitCount != 9)
        {
                DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s:   WARNING: Fixing broken bitmap info header!", _fx_));
                pvi->bmiHeader.biBitCount = 9;
                pvi->bmiHeader.biSizeImage = DIBSIZE(pvi->bmiHeader);
        }
        if (pvi->bmiHeader.biBitCount > 8 && pvi->bmiHeader.biClrUsed)
        {
                // BOGUS cap is broken and doesn't reset num colours
                // WINNOV reports 256 colours of 24 bit YUV8 - scary!
                DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s:   WARNING: Fixing broken bitmap info header!", _fx_));
                pvi->bmiHeader.biClrUsed = 0;
        }

        // Start with no funky rectangles
        pvi->rcSource.top = 0; pvi->rcSource.left = 0;
        pvi->rcSource.right = 0; pvi->rcSource.bottom = 0;
        pvi->rcTarget.top = 0; pvi->rcTarget.left = 0;
        pvi->rcTarget.right = 0; pvi->rcTarget.bottom = 0;
        pvi->dwBitRate = 0;
        pvi->dwBitErrorRate = 0;
        pvi->AvgTimePerFrame = 333333L;

MyExit:
        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: end", _fx_));
        return Hr;
}

/****************************************************************************
 *  @doc INTERNAL CVFWCAPDEVMETHOD
 *
 *  @mfunc HRESULT | CVfWCapDev | InitializeStreaming | This method is used to
 *    initialize a VfW capture device for streaming.
 *
 *  @parm DWORD | usPerFrame | Specifies the frame rate to be used.
 *
 *  @parm DWORD_PTR | hEvtBufferDone | Specifies a handle to the event to be
 *    signaled whenever a frame is available.
 *
 *  @rdesc This method returns an HRESULT value that depends on the
 *    implementation of the interface. HRESULT can include one of the
 *    following standard constants, or other values not listed:
 *
 *  @flag E_FAIL | Failure
 *  @flag NOERROR | No error
 ***************************************************************************/
HRESULT CVfWCapDev::InitializeStreaming(DWORD usPerFrame, DWORD_PTR hEvtBufferDone)
{
        HRESULT Hr = NOERROR;

        FX_ENTRY("CVfWCapDev::InitializeStreaming")

        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: begin", _fx_));

        // Validate input parameters
        ASSERT(m_hVideoIn);
        if (!m_hVideoIn)
        {
                DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: Invalid m_hVideoIn!", _fx_));
                Hr = E_UNEXPECTED;
                goto MyExit;
        }

        if (!m_dwStreamingMode || (m_dwStreamingMode == FRAME_GRAB_LARGE_SIZE && m_pCaptureFilter->m_user.pvi->bmiHeader.biHeight < 240 && m_pCaptureFilter->m_user.pvi->bmiHeader.biWidth < 320))
                if (videoStreamInit(m_hVideoIn, usPerFrame, hEvtBufferDone, 0, CALLBACK_EVENT))
                {
                        DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: videoStreamInit failed", _fx_));
                        Hr = E_FAIL;
                }

MyExit:
        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: end", _fx_));
        return Hr;
}

/****************************************************************************
 *  @doc INTERNAL CVFWCAPDEVMETHOD
 *
 *  @mfunc HRESULT | CVfWCapDev | StartStreaming | This method is used to
 *    start streaming from a VfW capture device.
 *
 *  @rdesc This method returns an HRESULT value that depends on the
 *    implementation of the interface. HRESULT can include one of the
 *    following standard constants, or other values not listed:
 *
 *  @flag E_FAIL | Failure
 *  @flag NOERROR | No error
 ***************************************************************************/
HRESULT CVfWCapDev::StartStreaming()
{
        HRESULT Hr = NOERROR;

        FX_ENTRY("CVfWCapDev::StartStreaming")

        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: begin", _fx_));

        // Validate input parameters
        ASSERT(m_hVideoIn);
        if (!m_hVideoIn)
        {
                DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: Invalid m_hVideoIn!", _fx_));
                Hr = E_UNEXPECTED;
                goto MyExit;
        }

        if (!m_dwStreamingMode || (m_dwStreamingMode == FRAME_GRAB_LARGE_SIZE && m_pCaptureFilter->m_user.pvi->bmiHeader.biHeight < 240 && m_pCaptureFilter->m_user.pvi->bmiHeader.biWidth < 320))
                videoStreamStart(m_hVideoIn);

MyExit:
        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: end", _fx_));
        return Hr;
}

/****************************************************************************
 *  @doc INTERNAL CVFWCAPDEVMETHOD
 *
 *  @mfunc HRESULT | CVfWCapDev | StopStreaming | This method is used to
 *    stop streaming from a VfW capture device.
 *
 *  @rdesc This method returns an HRESULT value that depends on the
 *    implementation of the interface. HRESULT can include one of the
 *    following standard constants, or other values not listed:
 *
 *  @flag E_FAIL | Failure
 *  @flag NOERROR | No error
 ***************************************************************************/
HRESULT CVfWCapDev::StopStreaming()
{
        HRESULT Hr = NOERROR;

        FX_ENTRY("CVfWCapDev::StopStreaming")

        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: begin", _fx_));

        // Validate input parameters
        ASSERT(m_hVideoIn);
        if (!m_hVideoIn)
        {
                DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: Invalid m_hVideoIn!", _fx_));
                Hr = E_UNEXPECTED;
                goto MyExit;
        }

        if (!m_dwStreamingMode || (m_dwStreamingMode == FRAME_GRAB_LARGE_SIZE && m_pCaptureFilter->m_user.pvi->bmiHeader.biHeight < 240 && m_pCaptureFilter->m_user.pvi->bmiHeader.biWidth < 320))
                Hr = videoStreamStop(m_hVideoIn);
                ASSERT(Hr == NOERROR);

MyExit:
        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: end", _fx_));
        return Hr;
}

/****************************************************************************
 *  @doc INTERNAL CVFWCAPDEVMETHOD
 *
 *  @mfunc HRESULT | CVfWCapDev | TerminateStreaming | This method is used to
 *    tell a VfW capture device to terminate streaming.
 *
 *  @rdesc This method returns an HRESULT value that depends on the
 *    implementation of the interface. HRESULT can include one of the
 *    following standard constants, or other values not listed:
 *
 *  @flag E_FAIL | Failure
 *  @flag NOERROR | No error
 ***************************************************************************/
HRESULT CVfWCapDev::TerminateStreaming()
{
        HRESULT Hr = NOERROR;

        FX_ENTRY("CVfWCapDev::TerminateStreaming")

        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: begin", _fx_));

        // Validate input parameters
        ASSERT(m_hVideoIn);
        if (!m_hVideoIn)
        {
                DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: Invalid m_hVideoIn!", _fx_));
                Hr = E_UNEXPECTED;
                goto MyExit;
        }

        if (!m_dwStreamingMode || (m_dwStreamingMode == FRAME_GRAB_LARGE_SIZE && m_pCaptureFilter->m_user.pvi->bmiHeader.biHeight < 240 && m_pCaptureFilter->m_user.pvi->bmiHeader.biWidth < 320))
        {
                Hr = videoStreamReset (m_hVideoIn);
                ASSERT(Hr ==  NOERROR);
                Hr = vidxFreeHeaders (m_hVideoIn);
                ASSERT(Hr ==  NOERROR);
                Hr = videoStreamFini (m_hVideoIn);
                ASSERT(Hr ==  NOERROR);
        }

MyExit:
        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: end", _fx_));
        return Hr;
}

/****************************************************************************
 *  @doc INTERNAL CVFWCAPDEVMETHOD
 *
 *  @mfunc HRESULT | CVfWCapDev | GrabFrame | This method is used to
 *    grab a video frame from a VfW capture device.
 *
 *  @parm PVIDEOHDR | pVHdr | Specifies a pointer to a VIDEOHDR structure to
 *    receive the video frame.
 *
 *  @rdesc This method returns an HRESULT value that depends on the
 *    implementation of the interface. HRESULT can include one of the
 *    following standard constants, or other values not listed:
 *
 *  @flag E_FAIL | Failure
 *  @flag NOERROR | No error
 ***************************************************************************/
HRESULT CVfWCapDev::GrabFrame(PVIDEOHDR pVHdr)
{
        HRESULT Hr = NOERROR;

        FX_ENTRY("CVfWCapDev::GrabFrame")

        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: begin", _fx_));

        // Validate input parameters
        ASSERT(m_hVideoIn);
        ASSERT(pVHdr);
        if (!m_hVideoIn || !pVHdr || !pVHdr->lpData)
        {
                DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: Invalid m_hVideoIn, pVHdr, pVHdr->lpData", _fx_));
                Hr = E_UNEXPECTED;
                goto MyExit;
        }

        if (vidxFrame(m_hVideoIn, pVHdr))
                Hr = E_FAIL;

MyExit:
        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: end", _fx_));
        return Hr;
}

/****************************************************************************
 *  @doc INTERNAL CVFWCAPDEVMETHOD
 *
 *  @mfunc HRESULT | CVfWCapDev | AllocateBuffer | This method is used to allocate
 *    a data buffer when video streaming from a VfW capture device.
 *
 *  @parm LPTHKVIDEOHDR * | pptvh | Specifies the address of a pointer to a
 *    THKVIDEOHDR structure to receive the video buffer.
 *
 *  @parm DWORD | dwIndex | Specifies the positional index of the video buffer.
 *
 *  @parm DWORD | cbBuffer | Specifies the size of the video buffer.
 *
 *  @rdesc This method returns an HRESULT value that depends on the
 *    implementation of the interface. HRESULT can include one of the
 *    following standard constants, or other values not listed:
 *
 *  @flag E_FAIL | Failure
 *  @flag NOERROR | No error
 ***************************************************************************/
HRESULT CVfWCapDev::AllocateBuffer(LPTHKVIDEOHDR *pptvh, DWORD dwIndex, DWORD cbBuffer)
{
        HRESULT Hr = NOERROR;
        DWORD vidxErr = 0;

        FX_ENTRY("CVfWCapDev::AllocateBuffer")

        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: begin", _fx_));

        // Validate input parameters
        ASSERT(m_hVideoIn);
        ASSERT(pptvh);
        ASSERT(cbBuffer);
        if (!m_hVideoIn || !pptvh || !cbBuffer)
        {
                DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: Invalid m_hVideoIn, pptvh, cbVHdr or cbBuffer!", _fx_));
                Hr = E_UNEXPECTED;
                goto MyExit;
        }
        if (!m_dwStreamingMode || (m_dwStreamingMode == FRAME_GRAB_LARGE_SIZE && m_pCaptureFilter->m_user.pvi->bmiHeader.biHeight < 240 && m_pCaptureFilter->m_user.pvi->bmiHeader.biWidth < 320))
        {
                if (vidxErr = vidxAllocBuffer (m_hVideoIn, dwIndex, (LPVOID *)pptvh, cbBuffer)) {
                        Hr = E_FAIL;
                        goto MyExit;
                }

        }
        else
        {
                (*pptvh)->vh.dwBufferLength = cbBuffer;
                if (vidxErr = vidxAllocPreviewBuffer(m_hVideoIn, (LPVOID *)&((*pptvh)->vh.lpData), sizeof(VIDEOHDR), cbBuffer)) {
                        Hr = E_FAIL;
                        goto MyExit;
                }
                (*pptvh)->p32Buff = (*pptvh)->vh.lpData;
                (*pptvh)->pStart  = (*pptvh)->vh.lpData; //chg:1
        }

        ASSERT (!IsBadWritePtr((*pptvh)->p32Buff, cbBuffer));

MyExit:
        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: end", _fx_));
        return Hr;
}

/****************************************************************************
 *  @doc INTERNAL CVFWCAPDEVMETHOD
 *
 *  @mfunc HRESULT | CVfWCapDev | AddBuffer | This method is used to
 *    post a data buffer to a VfW capture device when video streaming.
 *
 *  @parm PVIDEOHDR | pVHdr | Specifies a pointer to a
 *    PVIDEOHDR structure identifying the video buffer.
 *
 *  @parm DWORD | cbVHdr | Specifies the size of the structure pointed to by
 *    the <p pVHdr> parameter.
 *
 *  @rdesc This method returns an HRESULT value that depends on the
 *    implementation of the interface. HRESULT can include one of the
 *    following standard constants, or other values not listed:
 *
 *  @flag E_FAIL | Failure
 *  @flag NOERROR | No error
 ***************************************************************************/
HRESULT CVfWCapDev::AddBuffer(PVIDEOHDR pVHdr, DWORD cbVHdr)
{
        HRESULT Hr = NOERROR;

        FX_ENTRY("CVfWCapDev::AddBuffer")

        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: begin", _fx_));

        // Validate input parameters
        ASSERT(m_hVideoIn);
        ASSERT(pVHdr);
        ASSERT(cbVHdr);
        if (!m_hVideoIn || !pVHdr || !cbVHdr)
        {
                DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: Invalid m_hVideoIn, pVHdr, cbVHdr", _fx_));
                Hr = E_UNEXPECTED;
                goto MyExit;
        }

        if (vidxAddBuffer(m_hVideoIn, pVHdr, cbVHdr))
                Hr = E_FAIL;

MyExit:
        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: end", _fx_));
        return Hr;
}

/****************************************************************************
 *  @doc INTERNAL CVFWCAPDEVMETHOD
 *
 *  @mfunc HRESULT | CVfWCapDev | FreeBuffer | This method is used to
 *    free a data buffer that was used with a VfW capture device in streaming
 *    mode.
 *
 *  @parm PVIDEOHDR | pVHdr | Specifies a pointer to a
 *    PVIDEOHDR structure identifying the video buffer.
 *
 *  @rdesc This method returns an HRESULT value that depends on the
 *    implementation of the interface. HRESULT can include one of the
 *    following standard constants, or other values not listed:
 *
 *  @flag E_FAIL | Failure
 *  @flag NOERROR | No error
 ***************************************************************************/
HRESULT CVfWCapDev::FreeBuffer(LPTHKVIDEOHDR pVHdr) //PVIDEOHDR pVHdr)
{
        HRESULT Hr = NOERROR;

        FX_ENTRY("CVfWCapDev::FreeBuffer")

        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: begin", _fx_));

        // Validate input parameters
        ASSERT(m_hVideoIn);
        ASSERT(pVHdr);
        if (!m_hVideoIn || !pVHdr)
        {
                DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: Invalid m_hVideoIn or pVHdr!", _fx_));
                Hr = E_UNEXPECTED;
                goto MyExit;
        }

        if (!m_dwStreamingMode || (m_dwStreamingMode == FRAME_GRAB_LARGE_SIZE && m_pCaptureFilter->m_user.pvi->bmiHeader.biHeight < 240 && m_pCaptureFilter->m_user.pvi->bmiHeader.biWidth < 320))
                vidxFreeBuffer(m_hVideoIn, (DWORD)pVHdr);
        else
                //vidxFreePreviewBuffer(m_hVideoIn, (LPVOID *)&pVHdr->vh.lpData);       // this is definitely wrong: lpData might ALIGNED
                //*vidxFreePreviewBuffer(m_hVideoIn, (LPVOID *)&pVHdr->p32Buff);
                vidxFreePreviewBuffer(m_hVideoIn, (LPVOID *)&pVHdr->pStart);


MyExit:
        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: end", _fx_));
        return Hr;
}

/****************************************************************************
 *  @doc INTERNAL CVFWCAPDEVMETHOD
 *
 *  @mfunc HRESULT | CVfWCapDev | AllocateHeaders | This method is used to
 *    video headers for data buffers used with a VfW capture device in streaming
 *    mode.
 *
 *  @parm DWORD | dwNumHdrs | Specifies the number of video headers to allocate.
 *
 *  @parm DWORD | cbHdr | Specifies the size of the video headers to allocate.
 *
 *  @parm LPVOID* | ppaHdr | Specifies the address of a pointer to receive
 *    the video headers allocated.
 *
 *  @rdesc This method returns an HRESULT value that depends on the
 *    implementation of the interface. HRESULT can include one of the
 *    following standard constants, or other values not listed:
 *
 *  @flag E_FAIL | Failure
 *  @flag NOERROR | No error
 ***************************************************************************/
HRESULT CVfWCapDev::AllocateHeaders(DWORD dwNumHdrs, DWORD cbHdr, LPVOID *ppaHdr)
{
        HRESULT Hr = NOERROR;

        FX_ENTRY("CVfWCapDev::AllocateHeaders")

        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: begin", _fx_));

        // Validate input parameters
        ASSERT(m_hVideoIn);
        ASSERT(ppaHdr);
        ASSERT(cbHdr);
        if (!m_hVideoIn || !ppaHdr || !cbHdr)
        {
                DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: Invalid m_hVideoIn, cbHdr or pVHdr!", _fx_));
                Hr = E_UNEXPECTED;
                goto MyExit;
        }

        if (!m_dwStreamingMode || (m_dwStreamingMode == FRAME_GRAB_LARGE_SIZE && m_pCaptureFilter->m_user.pvi->bmiHeader.biHeight < 240 && m_pCaptureFilter->m_user.pvi->bmiHeader.biWidth < 320))
        {
                if (vidxAllocHeaders(m_hVideoIn, dwNumHdrs, sizeof(THKVIDEOHDR) + sizeof(DWORD), ppaHdr))
                {
                        DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: Out of memory!", _fx_));
                        Hr = E_OUTOFMEMORY;
                }
        }
        else
        {
                if (!(*ppaHdr = (struct CTAPIVCap::_cap_parms::_cap_hdr *)new BYTE[(sizeof(THKVIDEOHDR) + sizeof(DWORD)) * dwNumHdrs]))
                {
                        DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: Out of memory!", _fx_));
                        Hr = E_OUTOFMEMORY;
                }
        }

MyExit:
        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: end", _fx_));
        return Hr;
}

/****************************************************************************
 *  @doc INTERNAL CVFWCAPDEVMETHOD
 *
 *  @mfunc BOOL | CVfWCapDev | IsBufferDone | This method is used to
 *    check the DONE status of a video streaming buffer.
 *
 *  @parm PVIDEOHDR | pVHdr | Specifies a pointer to a
 *    PVIDEOHDR structure identifying the video buffer.
 *
 *  @rdesc This method returns TRUE if the buffer is DONE, FALSE otherwise.
 ***************************************************************************/
BOOL CVfWCapDev::IsBufferDone(PVIDEOHDR pVHdr)
{
        ASSERT(pVHdr);

        if (!pVHdr || !(pVHdr->dwFlags & VHDR_DONE))
                return FALSE;
        else
        return TRUE;
}
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\net\tapi\skywalker\filters\video\tapivcap\h245vidc.cpp ===
/****************************************************************************
 *  @doc INTERNAL H245VIDC
 *
 *  @module H245VidC.cpp | Source file for the <c CCapturePin> class methods
 *    used to implement the <i IH245Capability> TAPI inteface.
 *
 *  @comm For now, use the NM heuristics.
 ***************************************************************************/

#include "Precomp.h"

/****************************************************************************
 *  @doc INTERNAL CH245VIDCMETHOD
 *
 *  @mfunc HRESULT | CCapturePin | GetH245VersionID | This method is used to
 *    retrieve a DWORD value that identifies the platform version that the
 *    TAPI MSP Video Capture filter was designed for. The platform version is
 *    defined as TAPI_H245_VERSION_ID.
 *
 *  @rdesc This method returns an HRESULT value that depends on the
 *    implementation of the interface. HRESULT can include one of the
 *    following standard constants, or other values not listed:
 *
 *  @flag E_POINTER | Null pointer argument
 *  @flag NOERROR | No error
 ***************************************************************************/
STDMETHODIMP CCapturePin::GetH245VersionID(OUT DWORD *pdwVersionID)
{
        HRESULT Hr = NOERROR;

        FX_ENTRY("CCapturePin::GetH245VersionID")

        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: begin", _fx_));

        // Validate input parameter
        ASSERT(pdwVersionID);
        if (!pdwVersionID)
        {
                DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: Null pointer argument!", _fx_));
                Hr = E_POINTER;
        }
        else
        {
                *pdwVersionID = TAPI_H245_VERSION_ID;
                Hr = NOERROR;
        }

        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: end", _fx_));
        return Hr;
}

/****************************************************************************
 *  @doc INTERNAL CH245VIDCMETHOD
 *
 *  @mfunc HRESULT | CCapturePin | GetFormatTable | This method is used to
 *    obtain <t H245MediaCapabilityMap> structures for all formats and format
 *    options that the TAPI MSP Video Capture filter supports. The content of
 *    the capability information that the TAPI MSP Capability module obtains
 *    via this method is a two dimensional table that relates every supported
 *    receive format to steady-state resource requirements of that format.
 *
 *  @parm H245MediaCapabilityTable* | pTable | Specifies a pointer to an
 *    <t H245MediaCapabilityTable> structure.
 *
 *  @rdesc This method returns an HRESULT value that depends on the
 *    implementation of the interface. HRESULT can include one of the
 *    following standard constants, or other values not listed:
 *
 *  @flag E_POINTER | Null pointer argument
 *  @flag E_INVALIDARG | Invalid argument
 *  @flag NOERROR | No error
 *
 *  @comm The memory allocated by <mf CCapturePin.GetFormatTable> is released
 *    by calling <mf CCapturePin.ReleaseFormatTable>
 ***************************************************************************/
STDMETHODIMP CCapturePin::GetFormatTable(OUT H245MediaCapabilityTable *pTable)
{
        HRESULT                                 Hr = NOERROR;
        int                                             nNormalizedSpeed;
        LONG                                    lRate, lRateCIF, lRateQCIF, lRateSQCIF;
        DWORD                                   dwNumQCIFBounds, dwNumCIFBounds, dwNumSQCIFBounds;
        DWORD                                   dwCPUUsage;
        DWORD                                   dwBitsPerSec;

        FX_ENTRY("CCapturePin::GetFormatTable")

        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: begin", _fx_));

        // Validate input parameters
        ASSERT(pTable);
        if (!pTable)
        {
                DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: Null pointer argument", _fx_));
                Hr = E_POINTER;
                goto MyExit;
        }

        // We support H.261 QCIF and CIF, as well as H.263 SQCIF, QCIF, and CIF

        // Allocate memory to describe the capabilities of these formats
        if (!(m_pH245MediaCapabilityMap = new H245MediaCapabilityMap[NUM_H245VIDEOCAPABILITYMAPS]))
        {
                DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: Out of memory", _fx_));
                Hr = E_POINTER;
                goto MyExit;
        }

        // Initialize the array of capabilities
        ZeroMemory(m_pH245MediaCapabilityMap, NUM_H245VIDEOCAPABILITYMAPS * sizeof(H245MediaCapabilityMap));

        // Allocate memory to describe the resource bounds of our capabilities
        if (!(m_pVideoResourceBounds = new VideoResourceBounds[NUM_ITU_SIZES * NUM_RATES_PER_RESOURCE]))
        {
                DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: Out of memory", _fx_));
                Hr = E_POINTER;
                goto MyError1;
        }

        // Initialize the array of resource bounds
        ZeroMemory(m_pVideoResourceBounds, NUM_ITU_SIZES * NUM_RATES_PER_RESOURCE * sizeof(FormatResourceBounds));

        // Allocate memory to describe the format bounds of our capabilities
        if (!(m_pFormatResourceBounds = new FormatResourceBounds[NUM_ITU_SIZES * NUM_RATES_PER_RESOURCE]))
        {
                DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: Out of memory", _fx_));
                Hr = E_POINTER;
                goto MyError2;
        }

        // Initialize the array of resource bounds
        ZeroMemory(m_pFormatResourceBounds, NUM_ITU_SIZES * NUM_RATES_PER_RESOURCE * sizeof(FormatResourceBounds));

        // Get the CPU properties
        GetNormalizedCPUSpeed(&nNormalizedSpeed);

        // Initialize frame rate limits
        if (nNormalizedSpeed > SLOW_CPU_MHZ && nNormalizedSpeed < FAST_CPU_MHZ)
        {
                // 110MHz < CPUs < 200MhZ
                lRateCIF   = CIF_RATE_SLOW;
                lRateQCIF  = QCIF_RATE_SLOW;
                lRateSQCIF = SQCIF_RATE_SLOW;
        }
        else if (nNormalizedSpeed >= FAST_CPU_MHZ && nNormalizedSpeed < VERYFAST_CPU_MHZ)
        {
                // 200MHz < CPUs < 400MhZ
                lRateCIF   = CIF_RATE_FAST;
                lRateQCIF  = QCIF_RATE_FAST;
                lRateSQCIF = SQCIF_RATE_FAST;
        }
        else if (nNormalizedSpeed >= VERYFAST_CPU_MHZ)
        {
                // CPUs > 400MhZ
                // It would be better if we could scale between 15 and 30 frames/sec
                // depending on the CPU speed. But H.245 doesn't have any values
                // between 15 and 30. (See definition of Minimum Picture Interval)
                // So for now, 30 frames per sec CIF for all 400mhz and faster machines
                lRateCIF = CIF_RATE_VERYFAST;
                lRateQCIF = QCIF_RATE_FAST;
                lRateSQCIF = SQCIF_RATE_FAST;
        }
        else
        {
                // CPUs < 110MHZ
                lRateCIF   = CIF_RATE_VERYSLOW;
                lRateQCIF  = QCIF_RATE_VERYSLOW;
                lRateSQCIF = SQCIF_RATE_VERYSLOW;
        }
        //it was #define HUNDREDSBITSPERPIC 640
        //#define BITSPERPIC (64*1024)
        #define BITSPERPIC (8*1024)
        // Compute resources bounds
        for (lRate = lRateQCIF, dwNumQCIFBounds = 0, dwCPUUsage = MAX_CPU_USAGE; lRate; lRate >>= 1, dwCPUUsage >>= 1)
        {
                dwBitsPerSec = lRate * BITSPERPIC;
                if(dwBitsPerSec < (DWORD)m_lBitrateRangeMin || dwBitsPerSec > (DWORD)m_lBitrateRangeMax ) {
                //if(dwBitsPerSec > (DWORD)m_lTargetBitrate) {
                        DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   QCIF: At lRate=%ld, dwBitsPerSec(%lu) > m_lTargetBitrate(%ld). Skipped...", _fx_,lRate,dwBitsPerSec,m_lTargetBitrate));
                        continue;
                }
                m_pVideoResourceBounds[QCIF_SIZE * NUM_RATES_PER_RESOURCE + dwNumQCIFBounds].dwBitsPerPicture = BITSPERPIC;
                m_pVideoResourceBounds[QCIF_SIZE * NUM_RATES_PER_RESOURCE + dwNumQCIFBounds].lPicturesPerSecond = lRate;
                m_pFormatResourceBounds[QCIF_SIZE * NUM_RATES_PER_RESOURCE + dwNumQCIFBounds].dwCPUUtilization = dwCPUUsage;
                m_pFormatResourceBounds[QCIF_SIZE * NUM_RATES_PER_RESOURCE + dwNumQCIFBounds].dwBitsPerSecond = dwBitsPerSec;
                DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s:   QCIF: lRate=%ld, dwBitsPerSec(%lu) [%lu]", _fx_,lRate,dwBitsPerSec,dwNumQCIFBounds));
                dwNumQCIFBounds++ ;
        }
        for (lRate = lRateCIF, dwNumCIFBounds = 0, dwCPUUsage = MAX_CPU_USAGE; lRate; lRate >>= 1, dwCPUUsage >>= 1)
        {
                dwBitsPerSec = lRate * BITSPERPIC;
                if(dwBitsPerSec < (DWORD)m_lBitrateRangeMin || dwBitsPerSec > (DWORD)m_lBitrateRangeMax ) {
                //if(dwBitsPerSec > (DWORD)m_lTargetBitrate) {
                        DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:    CIF: At lRate=%ld, dwBitsPerSec(%lu) > m_lTargetBitrate(%ld). Skipped...", _fx_,lRate,dwBitsPerSec,m_lTargetBitrate));
                        continue;
                }
                m_pVideoResourceBounds[CIF_SIZE * NUM_RATES_PER_RESOURCE + dwNumCIFBounds].dwBitsPerPicture = BITSPERPIC;
                m_pVideoResourceBounds[CIF_SIZE * NUM_RATES_PER_RESOURCE + dwNumCIFBounds].lPicturesPerSecond = lRate;
                m_pFormatResourceBounds[CIF_SIZE * NUM_RATES_PER_RESOURCE + dwNumCIFBounds].dwCPUUtilization = dwCPUUsage;
                m_pFormatResourceBounds[CIF_SIZE * NUM_RATES_PER_RESOURCE + dwNumCIFBounds].dwBitsPerSecond = dwBitsPerSec;
                DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s:    CIF: lRate=%ld, dwBitsPerSec(%lu) [%lu]", _fx_,lRate,dwBitsPerSec,dwNumCIFBounds));
                dwNumCIFBounds++;
        }
        for (lRate = lRateSQCIF, dwNumSQCIFBounds = 0, dwCPUUsage = MAX_CPU_USAGE; lRate; lRate >>= 1, dwCPUUsage >>= 1)
        {
                dwBitsPerSec = lRate * BITSPERPIC;
                if(dwBitsPerSec < (DWORD)m_lBitrateRangeMin || dwBitsPerSec > (DWORD)m_lBitrateRangeMax ) {
                //if(dwBitsPerSec > (DWORD)m_lTargetBitrate) {
                        DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:  SQCIF: At lRate=%ld, dwBitsPerSec(%lu) > m_lTargetBitrate(%ld). Skipped...", _fx_,lRate,dwBitsPerSec,m_lTargetBitrate));
                        continue;
                }
                m_pVideoResourceBounds[SQCIF_SIZE * NUM_RATES_PER_RESOURCE + dwNumSQCIFBounds].dwBitsPerPicture = BITSPERPIC;
                m_pVideoResourceBounds[SQCIF_SIZE * NUM_RATES_PER_RESOURCE + dwNumSQCIFBounds].lPicturesPerSecond = lRate;
                m_pFormatResourceBounds[SQCIF_SIZE * NUM_RATES_PER_RESOURCE + dwNumSQCIFBounds].dwCPUUtilization = dwCPUUsage;
                m_pFormatResourceBounds[SQCIF_SIZE * NUM_RATES_PER_RESOURCE + dwNumSQCIFBounds].dwBitsPerSecond = dwBitsPerSec;
                DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s:  SQCIF: lRate=%ld, dwBitsPerSec(%lu) [%lu]", _fx_,lRate,dwBitsPerSec,dwNumSQCIFBounds));
                dwNumSQCIFBounds++;
        }

        // Initialise H.263 QCIF H245MediaCapabilityMap
        m_pH245MediaCapabilityMap[R263_QCIF_H245_CAPID].dwUniqueID = R263_QCIF_H245_CAPID;
        m_pH245MediaCapabilityMap[R263_QCIF_H245_CAPID].filterGuid = __uuidof(TAPIVideoCapture);
        m_pH245MediaCapabilityMap[R263_QCIF_H245_CAPID].uNumEntries = dwNumQCIFBounds;
        m_pH245MediaCapabilityMap[R263_QCIF_H245_CAPID].pResourceBoundArray = &m_pFormatResourceBounds[QCIF_SIZE * NUM_RATES_PER_RESOURCE];
        m_pH245MediaCapabilityMap[R263_QCIF_H245_CAPID].h245MediaCapability.media_type = H245MediaType_Video;
        m_pH245MediaCapabilityMap[R263_QCIF_H245_CAPID].h245MediaCapability.capability.video_cap.choice = h263VideoCapability_chosen;
        m_pH245MediaCapabilityMap[R263_QCIF_H245_CAPID].h245MediaCapability.capability.video_cap.u.h263VideoCapability.bit_mask = H263VideoCapability_qcifMPI_present;
        m_pH245MediaCapabilityMap[R263_QCIF_H245_CAPID].h245MediaCapability.capability.video_cap.u.h263VideoCapability.qcifMPI = (WORD)(30 / lRateQCIF);
        m_pH245MediaCapabilityMap[R263_QCIF_H245_CAPID].h245MediaCapability.capability.video_cap.u.h263VideoCapability.maxBitRate =
        min((WORD)(8192 * 8 * lRateQCIF / 100), MAX_BITRATE_H263); // The max frame size we can decode is 8192 bytes
        m_pH245MediaCapabilityMap[R263_QCIF_H245_CAPID].h245MediaCapability.capability.video_cap.u.h263VideoCapability.bppMaxKb = 64; // The max frame size we can decode is 8192 = 64 * 1024 bytes

        // Initialise H.263 CIF H245MediaCapabilityMap
        m_pH245MediaCapabilityMap[R263_CIF_H245_CAPID].dwUniqueID = R263_CIF_H245_CAPID;
        m_pH245MediaCapabilityMap[R263_CIF_H245_CAPID].filterGuid = __uuidof(TAPIVideoCapture);
        m_pH245MediaCapabilityMap[R263_CIF_H245_CAPID].uNumEntries = dwNumCIFBounds;
        m_pH245MediaCapabilityMap[R263_CIF_H245_CAPID].pResourceBoundArray = &m_pFormatResourceBounds[CIF_SIZE * NUM_RATES_PER_RESOURCE];
        m_pH245MediaCapabilityMap[R263_CIF_H245_CAPID].h245MediaCapability.media_type = H245MediaType_Video;
        m_pH245MediaCapabilityMap[R263_CIF_H245_CAPID].h245MediaCapability.capability.video_cap.choice = h263VideoCapability_chosen;
        m_pH245MediaCapabilityMap[R263_CIF_H245_CAPID].h245MediaCapability.capability.video_cap.u.h263VideoCapability.bit_mask = H263VideoCapability_cifMPI_present;
        m_pH245MediaCapabilityMap[R263_CIF_H245_CAPID].h245MediaCapability.capability.video_cap.u.h263VideoCapability.cifMPI = (WORD)(30 / lRateCIF);
        m_pH245MediaCapabilityMap[R263_CIF_H245_CAPID].h245MediaCapability.capability.video_cap.u.h263VideoCapability.maxBitRate =
        min((WORD)(32768 * 8 * lRateCIF / 100), MAX_BITRATE_H263); // The max frame size we can decode is 32768 bytes
        m_pH245MediaCapabilityMap[R263_CIF_H245_CAPID].h245MediaCapability.capability.video_cap.u.h263VideoCapability.bppMaxKb = 256; // The max frame size we can decode is 32768 = 256 * 1024 bytes

        // Initialise H.263 SQCIF H245MediaCapabilityMap
        m_pH245MediaCapabilityMap[R263_SQCIF_H245_CAPID].dwUniqueID = R263_SQCIF_H245_CAPID;
        m_pH245MediaCapabilityMap[R263_SQCIF_H245_CAPID].filterGuid = __uuidof(TAPIVideoCapture);
        m_pH245MediaCapabilityMap[R263_SQCIF_H245_CAPID].uNumEntries = dwNumSQCIFBounds;
        m_pH245MediaCapabilityMap[R263_SQCIF_H245_CAPID].pResourceBoundArray = &m_pFormatResourceBounds[SQCIF_SIZE * NUM_RATES_PER_RESOURCE];
        m_pH245MediaCapabilityMap[R263_SQCIF_H245_CAPID].h245MediaCapability.media_type = H245MediaType_Video;
        m_pH245MediaCapabilityMap[R263_SQCIF_H245_CAPID].h245MediaCapability.capability.video_cap.choice = h263VideoCapability_chosen;
        m_pH245MediaCapabilityMap[R263_SQCIF_H245_CAPID].h245MediaCapability.capability.video_cap.u.h263VideoCapability.bit_mask = H263VideoCapability_sqcifMPI_present;
        m_pH245MediaCapabilityMap[R263_SQCIF_H245_CAPID].h245MediaCapability.capability.video_cap.u.h263VideoCapability.sqcifMPI = (WORD)(30 / lRateSQCIF);
        m_pH245MediaCapabilityMap[R263_SQCIF_H245_CAPID].h245MediaCapability.capability.video_cap.u.h263VideoCapability.maxBitRate =
        min((WORD)(32768 * 8 * lRateSQCIF / 100), MAX_BITRATE_H263); // The max frame size we can decode is 32768 bytes
        m_pH245MediaCapabilityMap[R263_SQCIF_H245_CAPID].h245MediaCapability.capability.video_cap.u.h263VideoCapability.bppMaxKb = 64; // The max frame size we can decode is 8192 = 64 * 1024 bytes

        // Initialise H.261 QCIF H245MediaCapabilityMap
        m_pH245MediaCapabilityMap[R261_QCIF_H245_CAPID].dwUniqueID = R261_QCIF_H245_CAPID;
        m_pH245MediaCapabilityMap[R261_QCIF_H245_CAPID].filterGuid = __uuidof(TAPIVideoCapture);
        m_pH245MediaCapabilityMap[R261_QCIF_H245_CAPID].uNumEntries = dwNumQCIFBounds;
        m_pH245MediaCapabilityMap[R261_QCIF_H245_CAPID].pResourceBoundArray = &m_pFormatResourceBounds[QCIF_SIZE * NUM_RATES_PER_RESOURCE];
        m_pH245MediaCapabilityMap[R261_QCIF_H245_CAPID].h245MediaCapability.media_type = H245MediaType_Video;
        m_pH245MediaCapabilityMap[R261_QCIF_H245_CAPID].h245MediaCapability.capability.video_cap.choice = h261VideoCapability_chosen;
        m_pH245MediaCapabilityMap[R261_QCIF_H245_CAPID].h245MediaCapability.capability.video_cap.u.h261VideoCapability.bit_mask = H261VideoCapability_qcifMPI_present;
        m_pH245MediaCapabilityMap[R261_QCIF_H245_CAPID].h245MediaCapability.capability.video_cap.u.h261VideoCapability.qcifMPI = (WORD)(30 / lRateQCIF);
        m_pH245MediaCapabilityMap[R261_QCIF_H245_CAPID].h245MediaCapability.capability.video_cap.u.h261VideoCapability.maxBitRate =
        min((WORD)(8192 * 8 * lRateQCIF / 100), MAX_BITRATE_H261); // The max frame size we can decode is 8192 bytes

        // Initialise H.261 CIF H245MediaCapabilityMap
        m_pH245MediaCapabilityMap[R261_CIF_H245_CAPID].dwUniqueID = R261_CIF_H245_CAPID;
        m_pH245MediaCapabilityMap[R261_CIF_H245_CAPID].filterGuid = __uuidof(TAPIVideoCapture);
        m_pH245MediaCapabilityMap[R261_CIF_H245_CAPID].uNumEntries = dwNumCIFBounds;
        m_pH245MediaCapabilityMap[R261_CIF_H245_CAPID].pResourceBoundArray = &m_pFormatResourceBounds[CIF_SIZE * NUM_RATES_PER_RESOURCE];
        m_pH245MediaCapabilityMap[R261_CIF_H245_CAPID].h245MediaCapability.media_type = H245MediaType_Video;
        m_pH245MediaCapabilityMap[R261_CIF_H245_CAPID].h245MediaCapability.capability.video_cap.choice = h261VideoCapability_chosen;
        m_pH245MediaCapabilityMap[R261_CIF_H245_CAPID].h245MediaCapability.capability.video_cap.u.h261VideoCapability.bit_mask = H261VideoCapability_cifMPI_present;
        m_pH245MediaCapabilityMap[R261_CIF_H245_CAPID].h245MediaCapability.capability.video_cap.u.h261VideoCapability.cifMPI = (WORD)(30 / lRateCIF);
        m_pH245MediaCapabilityMap[R261_CIF_H245_CAPID].h245MediaCapability.capability.video_cap.u.h261VideoCapability.maxBitRate =
        min((WORD)(32768 * 8 * lRateCIF / 100), MAX_BITRATE_H261); // The max frame size we can decode is 32768 bytes

        // Return our H245MediaCapabilityTable
        pTable->uMappedCapabilities = NUM_H245VIDEOCAPABILITYMAPS;
        pTable->pCapabilityArray = m_pH245MediaCapabilityMap;

        goto MyExit;

MyError2:
        if (m_pVideoResourceBounds)
                delete[] m_pVideoResourceBounds, m_pVideoResourceBounds = NULL;
MyError1:
        if (m_pH245MediaCapabilityMap)
                delete[] m_pH245MediaCapabilityMap, m_pH245MediaCapabilityMap = NULL;
MyExit:
        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: end", _fx_));
        return Hr;
}

/****************************************************************************
 *  @doc INTERNAL CH245VIDCMETHOD
 *
 *  @mfunc HRESULT | CCapturePin | ReleaseFormatTable | This method is used to
 *    to release memory allocated by the <mf CCapturePin.GetFormatTable> method.
 *
 *  @parm H245MediaCapabilityTable* | pTable | Specifies a pointer to an
 *    <t H245MediaCapabilityTable> structure.
 *
 *  @rdesc This method returns an HRESULT value that depends on the
 *    implementation of the interface. HRESULT can include one of the
 *    following standard constants, or other values not listed:
 *
 *  @flag E_POINTER | Null pointer argument
 *  @flag E_INVALIDARG | Invalid argument
 *  @flag NOERROR | No error
 *
 *  @xref <mf CCapturePin.GetFormatTable>
 ***************************************************************************/
STDMETHODIMP CCapturePin::ReleaseFormatTable(IN H245MediaCapabilityTable *pTable)
{
        HRESULT Hr = NOERROR;

        FX_ENTRY("CCapturePin::ReleaseFormatTable")

        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: begin", _fx_));

        // Validate input parameters - if it is our table, it should have NUM_H245VIDEOCAPABILITYMAPS entries
        ASSERT(pTable);
        if (!pTable || !pTable->pCapabilityArray)
        {
                DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: Null pointer argument", _fx_));
                Hr = E_POINTER;
                goto MyExit;
        }
        ASSERT(pTable->uMappedCapabilities == NUM_H245VIDEOCAPABILITYMAPS && pTable->pCapabilityArray == m_pH245MediaCapabilityMap);
        if (pTable->uMappedCapabilities != NUM_H245VIDEOCAPABILITYMAPS || pTable->pCapabilityArray != m_pH245MediaCapabilityMap)
        {
                DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: Invalid argument", _fx_));
                Hr = E_INVALIDARG;
                goto MyExit;
        }

        // Release the table of H245MediaCapabilityMap structures
        if (m_pH245MediaCapabilityMap)
                delete[] m_pH245MediaCapabilityMap, m_pH245MediaCapabilityMap = NULL;
        if (m_pVideoResourceBounds)
                delete[] m_pVideoResourceBounds, m_pVideoResourceBounds = NULL;
        if (m_pFormatResourceBounds)
                delete[] m_pFormatResourceBounds, m_pFormatResourceBounds = NULL;

MyExit:
        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: end", _fx_));
        return Hr;
}

/****************************************************************************
 *  @doc INTERNAL CH245VIDCMETHOD
 *
 *  @mfunc HRESULT | CCapturePin | Refine | This method is used to
 *    refine the content of an <t H245MediaCapability> structure based on the
 *    CPU and bandwidth limitations passed in.
 *
 *  @parm H245MediaCapability* | pLocalCapability | Specifies the H.245 video
 *    format, including all parameters and options defined by H.245, of a
 *    local video capability.
 *
 *  @parm DWORD | dwUniqueID | Specifies the unique ID of the local capability
 *    structure passed in.
 *
 *  @parm DWORD | dwResourceBoundIndex | Specifies the resource limitations to
 *    be applied on the local capability structure passed in.
 *
 *  @rdesc This method returns an HRESULT value that depends on the
 *    implementation of the interface. HRESULT can include one of the
 *    following standard constants, or other values not listed:
 *
 *  @flag E_POINTER | Null pointer argument
 *  @flag E_INVALIDARG | Invalid argument
 *  @flag E_FAIL | Unsupported format
 *  @flag NOERROR | No error
 *
 *  @xref <mf CCapturePin.GetNegotiatedLimitProperty>
 ***************************************************************************/
STDMETHODIMP CCapturePin::Refine(IN OUT H245MediaCapability *pLocalCapability, IN DWORD dwUniqueID, IN DWORD dwResourceBoundIndex)
{
        HRESULT Hr = NOERROR;

        FX_ENTRY("CCapturePin::Refine")

        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: begin", _fx_));

        // Validate input parameters
        ASSERT(pLocalCapability);
        if (!pLocalCapability)
        {
                DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: Null pointer argument", _fx_));
                Hr = E_POINTER;
                goto MyExit;
        }
        ASSERT(pLocalCapability->media_type == H245MediaType_Video);
        if (pLocalCapability->media_type != H245MediaType_Video)
        {
                DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: Invalid argument", _fx_));
                Hr = E_INVALIDARG;
                goto MyExit;
        }

        // Update the relevant fields
        ASSERT(dwUniqueID <= R261_CIF_H245_CAPID);
        switch (dwUniqueID)
        {
                case R263_QCIF_H245_CAPID:
                        ASSERT(dwResourceBoundIndex < m_pH245MediaCapabilityMap[R263_QCIF_H245_CAPID].uNumEntries);
                        if (m_pVideoResourceBounds[QCIF_SIZE * NUM_RATES_PER_RESOURCE + dwResourceBoundIndex].lPicturesPerSecond)
                        {
                                pLocalCapability->capability.video_cap.u.h263VideoCapability.qcifMPI = (WORD)(30 / m_pVideoResourceBounds[QCIF_SIZE * NUM_RATES_PER_RESOURCE + dwResourceBoundIndex].lPicturesPerSecond);
                                pLocalCapability->capability.video_cap.u.h263VideoCapability.maxBitRate = (WORD)(8192 * 8 * m_pVideoResourceBounds[QCIF_SIZE * NUM_RATES_PER_RESOURCE + dwResourceBoundIndex].lPicturesPerSecond / 100); // The max frame size we can decode is 8192 bytes
                                pLocalCapability->capability.video_cap.u.h263VideoCapability.maxBitRate = min(pLocalCapability->capability.video_cap.u.h263VideoCapability.maxBitRate, MAX_BITRATE_H263);
                                pLocalCapability->capability.video_cap.u.h263VideoCapability.bppMaxKb = 64; // The max frame size we can decode is 8192 = 64 * 1024 bytes
                        }
                        else
                        {
                                DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: Invalid argument", _fx_));
                                Hr = E_INVALIDARG;
                        }
                        break;
                case R263_CIF_H245_CAPID:
                        ASSERT(dwResourceBoundIndex < m_pH245MediaCapabilityMap[R263_CIF_H245_CAPID].uNumEntries);
                        if (m_pVideoResourceBounds[CIF_SIZE * NUM_RATES_PER_RESOURCE + dwResourceBoundIndex].lPicturesPerSecond)
                        {
                                pLocalCapability->capability.video_cap.u.h263VideoCapability.cifMPI = (WORD)(30 / m_pVideoResourceBounds[CIF_SIZE * NUM_RATES_PER_RESOURCE + dwResourceBoundIndex].lPicturesPerSecond);
                                pLocalCapability->capability.video_cap.u.h263VideoCapability.maxBitRate = (WORD)(32768 * 8 * m_pVideoResourceBounds[CIF_SIZE * NUM_RATES_PER_RESOURCE + dwResourceBoundIndex].lPicturesPerSecond / 100); // The max frame size we can decode is 32768 bytes
                                pLocalCapability->capability.video_cap.u.h263VideoCapability.maxBitRate = min(pLocalCapability->capability.video_cap.u.h263VideoCapability.maxBitRate, MAX_BITRATE_H263);
                                pLocalCapability->capability.video_cap.u.h263VideoCapability.bppMaxKb = 256; // The max frame size we can decode is 32768 = 256 * 1024 bytes
                        }
                        else
                        {
                                DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: Invalid argument", _fx_));
                                Hr = E_INVALIDARG;
                        }
                        break;
                case R263_SQCIF_H245_CAPID:
                        ASSERT(dwResourceBoundIndex < m_pH245MediaCapabilityMap[R263_SQCIF_H245_CAPID].uNumEntries);
                        if (m_pVideoResourceBounds[SQCIF_SIZE * NUM_RATES_PER_RESOURCE + dwResourceBoundIndex].lPicturesPerSecond)
                        {
                                pLocalCapability->capability.video_cap.u.h263VideoCapability.sqcifMPI = (WORD)(30 / m_pVideoResourceBounds[SQCIF_SIZE * NUM_RATES_PER_RESOURCE + dwResourceBoundIndex].lPicturesPerSecond);
                                pLocalCapability->capability.video_cap.u.h263VideoCapability.maxBitRate = (WORD)(8192 * 8 * m_pVideoResourceBounds[SQCIF_SIZE * NUM_RATES_PER_RESOURCE + dwResourceBoundIndex].lPicturesPerSecond / 100); // The max frame size we can decode is 8192 bytes
                                pLocalCapability->capability.video_cap.u.h263VideoCapability.maxBitRate = min(pLocalCapability->capability.video_cap.u.h263VideoCapability.maxBitRate, MAX_BITRATE_H263);
                                pLocalCapability->capability.video_cap.u.h263VideoCapability.bppMaxKb = 64; // The max frame size we can decode is 8192 = 64 * 1024 bytes
                        }
                        else
                        {
                                DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: Invalid argument", _fx_));
                                Hr = E_INVALIDARG;
                        }
                        break;
                case R261_QCIF_H245_CAPID:
                        ASSERT(dwResourceBoundIndex < m_pH245MediaCapabilityMap[R261_QCIF_H245_CAPID].uNumEntries);
                        if (m_pVideoResourceBounds[QCIF_SIZE * NUM_RATES_PER_RESOURCE + dwResourceBoundIndex].lPicturesPerSecond)
                        {
                                pLocalCapability->capability.video_cap.u.h261VideoCapability.qcifMPI = (WORD)(30 / m_pVideoResourceBounds[QCIF_SIZE * NUM_RATES_PER_RESOURCE + dwResourceBoundIndex].lPicturesPerSecond);
                                pLocalCapability->capability.video_cap.u.h261VideoCapability.maxBitRate = (WORD)(8192 * 8 * m_pVideoResourceBounds[QCIF_SIZE * NUM_RATES_PER_RESOURCE + dwResourceBoundIndex].lPicturesPerSecond / 100); // The max frame size we can decode is 8192 bytes
                                pLocalCapability->capability.video_cap.u.h261VideoCapability.maxBitRate = min(pLocalCapability->capability.video_cap.u.h261VideoCapability.maxBitRate, MAX_BITRATE_H261);
                        }
                        else
                        {
                                DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: Invalid argument", _fx_));
                                Hr = E_INVALIDARG;
                        }
                        break;
                case R261_CIF_H245_CAPID:
                        ASSERT(dwResourceBoundIndex < m_pH245MediaCapabilityMap[R261_CIF_H245_CAPID].uNumEntries);
                        if (m_pVideoResourceBounds[CIF_SIZE * NUM_RATES_PER_RESOURCE + dwResourceBoundIndex].lPicturesPerSecond)
                        {
                                pLocalCapability->capability.video_cap.u.h261VideoCapability.cifMPI = (WORD)(30 / m_pVideoResourceBounds[CIF_SIZE * NUM_RATES_PER_RESOURCE + dwResourceBoundIndex].lPicturesPerSecond);
                                pLocalCapability->capability.video_cap.u.h261VideoCapability.maxBitRate = (WORD)(32768 * 8 * m_pVideoResourceBounds[CIF_SIZE * NUM_RATES_PER_RESOURCE + dwResourceBoundIndex].lPicturesPerSecond / 100); // The max frame size we can decode is 32768 bytes
                                pLocalCapability->capability.video_cap.u.h261VideoCapability.maxBitRate = min(pLocalCapability->capability.video_cap.u.h261VideoCapability.maxBitRate, MAX_BITRATE_H261);
                        }
                        else
                        {
                                DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: Invalid argument", _fx_));
                                Hr = E_INVALIDARG;
                        }
                        break;
                default:
                        DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: Invalid argument", _fx_));
                        Hr = E_INVALIDARG;
        }

MyExit:
        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: end", _fx_));
        return Hr;
}

/****************************************************************************
 *  @doc INTERNAL CH245VIDCMETHOD
 *
 *  @mfunc HRESULT | CCapturePin | IntersectFormats | This method is used to
 *    compare and intersect one local capability and one remote capability
 *    and to obtain configuration parameters.
 *
 *  @parm DWORD | dwUniqueID | Specifies the unique idea for the local H.245
 *    video capability passed in.
 *
 *  @parm H245MediaCapability* | pLocalCapability | Specifies the H.245 video
 *    format, including all parameters and options defined by H.245, of a
 *    local video capability.
 *
 *  @parm H245MediaCapability* | pRemoteCapability | Specifies the H.245
 *    video format, including all parameters and options defined by H.245, of
 *    a remote video capability.
 *
 *  @parm H245MediaCapability* | pIntersectedCapability | Specifies the H.245
 *    video format, of the resolved common local and remote capability
 *    options and limits.
 *
 *  @parm DWORD* | pdwPayloadType | Specifies RTP payload type to be used.
 *
 *  @rdesc This method returns an HRESULT value that depends on the
 *    implementation of the interface. HRESULT can include one of the
 *    following standard constants, or other values not listed:
 *
 *  @flag E_POINTER | Null pointer argument
 *  @flag E_FAIL | Unsupported format
 *  @flag NOERROR | No error
 *
 *  @xref <mf CCapturePin.GetNegotiatedLimitProperty>
 ***************************************************************************/
STDMETHODIMP CCapturePin::IntersectFormats(
    IN DWORD dwUniqueID,
    IN const H245MediaCapability *pLocalCapability,
    IN const H245MediaCapability *pRemoteCapability,
    OUT H245MediaCapability **ppIntersectedCapability,
    OUT  DWORD *pdwPayloadType
    )
{
        HRESULT Hr = NOERROR;

        FX_ENTRY("CCapturePin::IntersectFormats")

        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: begin", _fx_));

        // Validate input parameters
        ASSERT(pLocalCapability);
    ASSERT(pdwPayloadType);

        if (!pLocalCapability || !pdwPayloadType)
        {
                DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: Null pointer argument", _fx_));
        return E_POINTER;
        }

    *pdwPayloadType = RTPPayloadTypes[dwUniqueID];

    // initialize intersected cap
    if (ppIntersectedCapability) *ppIntersectedCapability = NULL;

    if (pRemoteCapability == NULL)
    {
        // if this is NULL, the caller just want a copy of the local caps.

        // Allocate memory to describe the capabilities of these formats
            if (!(*ppIntersectedCapability = new H245MediaCapability))
            {
                    DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: Out of memory", _fx_));
                    Hr = E_OUTOFMEMORY;
                    goto MyExit;
            }

        *(*ppIntersectedCapability) = *pLocalCapability;

                Hr = S_OK;
                goto MyExit;
    }

 // First: test for basic similarity between local and remote format.
        if(pLocalCapability->capability.audio_cap.choice != pRemoteCapability->
                capability.audio_cap.choice)
        {
                Hr = E_INVALIDARG; // E_NO_INTERSECTION ?
                goto MyExit;
        }

    ASSERT (ppIntersectedCapability != NULL);

#if 0 // we will never hit this condition on the transmit side.
    if (ppIntersectedCapability == NULL)
    {
        // just test to see if we like it.
            if (pRemoteCapability->media_type == H245MediaType_Video
            && pRemoteCapability->capability.video_cap.choice == h263VideoCapability_chosen)
        {
            if (!(pLocalCapability->capability.video_cap.u.h263VideoCapability.bit_mask
                & pRemoteCapability->capability.video_cap.u.h263VideoCapability.bit_mask))
            {
                return E_FAIL;
            }

            if (pLocalCapability->capability.video_cap.u.h263VideoCapability.bppMaxKb <
                pRemoteCapability->capability.video_cap.u.h263VideoCapability.bppMaxKb)
            {
                return E_FAIL;
            }

            if (pLocalCapability->capability.video_cap.u.h263VideoCapability.maxBitRate <
                pRemoteCapability->capability.video_cap.u.h263VideoCapability.maxBitRate)
            {
                return E_FAIL;
            }

            if (pLocalCapability->capability.video_cap.u.h263VideoCapability.qcifMPI >
                pRemoteCapability->capability.video_cap.u.h263VideoCapability.qcifMPI)
            {
                return E_FAIL;
            }

            if (pLocalCapability->capability.video_cap.u.h263VideoCapability.cifMPI >
                pRemoteCapability->capability.video_cap.u.h263VideoCapability.cifMPI)
            {
                return E_FAIL;
            }

            if (pLocalCapability->capability.video_cap.u.h263VideoCapability.sqcifMPI >
                pRemoteCapability->capability.video_cap.u.h263VideoCapability.sqcifMPI)
            {
                return E_FAIL;
            }
        }
            else if (pRemoteCapability->media_type == H245MediaType_Video
            && pRemoteCapability->capability.video_cap.choice == h261VideoCapability_chosen)
        {
            if (!(pLocalCapability->capability.video_cap.u.h261VideoCapability.bit_mask
                & pRemoteCapability->capability.video_cap.u.h261VideoCapability.bit_mask))
            {
                return E_FAIL;
            }

            if (pLocalCapability->capability.video_cap.u.h261VideoCapability.maxBitRate <
                pRemoteCapability->capability.video_cap.u.h261VideoCapability.maxBitRate)
            {
                return E_FAIL;
            }

            if (pLocalCapability->capability.video_cap.u.h261VideoCapability.qcifMPI >
                pRemoteCapability->capability.video_cap.u.h261VideoCapability.qcifMPI)
            {
                return E_FAIL;
            }

            if (pLocalCapability->capability.video_cap.u.h261VideoCapability.cifMPI >
                pRemoteCapability->capability.video_cap.u.h261VideoCapability.cifMPI)
            {
                return E_FAIL;
            }
        }
        else
        {
            return E_UNEXPECTED;
        }
        return S_OK;
    }
#endif

        // Allocate memory to describe the capabilities of these formats
        if (!(*ppIntersectedCapability = new H245MediaCapability))
        {
                DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: Out of memory", _fx_));
                Hr = E_OUTOFMEMORY;
                goto MyExit;
        }

        // Initialize the intersected capability
        ZeroMemory(*ppIntersectedCapability, sizeof(H245MediaCapability));

        // Resolve the capabilities
        if (pRemoteCapability->media_type == H245MediaType_Video
        && pRemoteCapability->capability.video_cap.choice == h263VideoCapability_chosen)
        {
                (*ppIntersectedCapability)->media_type = H245MediaType_Video;

                (*ppIntersectedCapability)->capability.video_cap.choice = h263VideoCapability_chosen;

                (*ppIntersectedCapability)->capability.video_cap.u.h263VideoCapability.bit_mask =
                    pLocalCapability->capability.video_cap.u.h263VideoCapability.bit_mask
                    & pRemoteCapability->capability.video_cap.u.h263VideoCapability.bit_mask;

                if (!(*ppIntersectedCapability)->capability.video_cap.u.h263VideoCapability.bit_mask)
                {
                        DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: Unsupported format", _fx_));
                        Hr = E_FAIL;
                        goto MyExit;
                }

                if (pRemoteCapability->capability.video_cap.u.h263VideoCapability.bppMaxKb)
                {
                            (*ppIntersectedCapability)->capability.video_cap.u.h263VideoCapability.bppMaxKb =
                        min(pLocalCapability->capability.video_cap.u.h263VideoCapability.bppMaxKb,
                        pRemoteCapability->capability.video_cap.u.h263VideoCapability.bppMaxKb);
                }

                (*ppIntersectedCapability)->capability.video_cap.u.h263VideoCapability.maxBitRate =
                    min(pLocalCapability->capability.video_cap.u.h263VideoCapability.maxBitRate,
                    pRemoteCapability->capability.video_cap.u.h263VideoCapability.maxBitRate);

                (*ppIntersectedCapability)->capability.video_cap.u.h263VideoCapability.qcifMPI =
                    max(pLocalCapability->capability.video_cap.u.h263VideoCapability.qcifMPI,
                    pRemoteCapability->capability.video_cap.u.h263VideoCapability.qcifMPI);

                (*ppIntersectedCapability)->capability.video_cap.u.h263VideoCapability.cifMPI =
                    max(pLocalCapability->capability.video_cap.u.h263VideoCapability.cifMPI,
                    pRemoteCapability->capability.video_cap.u.h263VideoCapability.cifMPI);

                (*ppIntersectedCapability)->capability.video_cap.u.h263VideoCapability.sqcifMPI =
                    max(pLocalCapability->capability.video_cap.u.h263VideoCapability.sqcifMPI,
                    pRemoteCapability->capability.video_cap.u.h263VideoCapability.sqcifMPI);
        }
        else if (pRemoteCapability->media_type == H245MediaType_Video
        && pRemoteCapability->capability.video_cap.choice == h261VideoCapability_chosen)
        {
                (*ppIntersectedCapability)->media_type = H245MediaType_Video;

                (*ppIntersectedCapability)->capability.video_cap.choice = h261VideoCapability_chosen;

                (*ppIntersectedCapability)->capability.video_cap.u.h261VideoCapability.bit_mask =
                    pLocalCapability->capability.video_cap.u.h261VideoCapability.bit_mask
                    & pRemoteCapability->capability.video_cap.u.h261VideoCapability.bit_mask;

                if (!(*ppIntersectedCapability)->capability.video_cap.u.h261VideoCapability.bit_mask)
                {
                        DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: Unsupported format", _fx_));
                        Hr = E_FAIL;
                        goto MyExit;
                }
                (*ppIntersectedCapability)->capability.video_cap.u.h261VideoCapability.maxBitRate =
                    min(pLocalCapability->capability.video_cap.u.h261VideoCapability.maxBitRate,
                    pRemoteCapability->capability.video_cap.u.h261VideoCapability.maxBitRate);

                (*ppIntersectedCapability)->capability.video_cap.u.h261VideoCapability.qcifMPI =
                    max(pLocalCapability->capability.video_cap.u.h261VideoCapability.qcifMPI,
                    pRemoteCapability->capability.video_cap.u.h261VideoCapability.qcifMPI);

                (*ppIntersectedCapability)->capability.video_cap.u.h261VideoCapability.cifMPI =
                    max(pLocalCapability->capability.video_cap.u.h261VideoCapability.cifMPI,
                    pRemoteCapability->capability.video_cap.u.h261VideoCapability.cifMPI);
        }
        else
        {
                DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: Unsupported format", _fx_));
                Hr = E_FAIL;
                goto MyExit;
        }

MyExit:

    if (FAILED (Hr))
    {
        if (ppIntersectedCapability && *ppIntersectedCapability)
        {
            // clear allocated memory if we failed
            delete (*ppIntersectedCapability);
            *ppIntersectedCapability = NULL;
        }
    }

        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: end", _fx_));
        return Hr;
}

/****************************************************************************
 *  @doc INTERNAL CH245VIDCMETHOD
 *
 *  @mfunc HRESULT | CCapturePin | GetLocalFormat | This method is used to
 *    obtain the local TAPI MSP Video Capture filter configuration
 *    parameters that are compatible with a remote capability.
 *
 *  @parm DWORD | dwUniqueID | Specifies the unique idea for the intersected
 *    H.245 video capability passed in.
 *
 *  @parm H245MediaCapability* | pIntersectedCapability | Specifies the H.245
 *    video format, of the resolved common local and remote capability
 *    options and limits.
 *
 *  @parm AM_MEDIA_TYPE** | ppAMMediaType | Specifies the address of a pointer
 *    to an <t AM_MEDIA_TYPE> structure to be been initialized with regards
 *    to negotiated options.
 *
 *  @rdesc This method returns an HRESULT value that depends on the
 *    implementation of the interface. HRESULT can include one of the
 *    following standard constants, or other values not listed:
 *
 *  @flag E_POINTER | Null pointer argument
 *  @flag E_INVALIDARG | Invalid argument argument
 *  @flag NOERROR | No error
 *
 *  @xref <mf CCapturePin.GetNegotiatedLimitProperty>
 ***************************************************************************/
STDMETHODIMP CCapturePin::GetLocalFormat(IN DWORD dwUniqueID, IN const H245MediaCapability *pIntersectedCapability, OUT AM_MEDIA_TYPE **ppAMMediaType)
{
        HRESULT Hr = NOERROR;

        FX_ENTRY("CCapturePin::GetLocalFormat")

        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: begin", _fx_));

        // Validate input parameters
        ASSERT(pIntersectedCapability);
        ASSERT(ppAMMediaType);
        if (!pIntersectedCapability || !ppAMMediaType)
        {
                DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: Null pointer argument", _fx_));
                Hr = E_POINTER;
                goto MyExit;
        }

        // Find the DShow format the passed in capability structure matches
        ASSERT(pIntersectedCapability->media_type == H245MediaType_Video);
        ASSERT(dwUniqueID <= R261_CIF_H245_CAPID);
        if (!(dwUniqueID <= R261_CIF_H245_CAPID) || pIntersectedCapability->media_type != H245MediaType_Video)
        {
                DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: Unsupported format", _fx_));
                Hr = E_INVALIDARG;
                goto MyExit;
        }

        // Return a copy of the format that matches the capability negociated
        if (!(*ppAMMediaType = CreateMediaType(CaptureFormats[dwUniqueID])))
        {
                DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: Out of memory", _fx_));
                Hr = E_OUTOFMEMORY;
                goto MyExit;
        }

        // Doctor the AM_MEDIA_TYPE fields to show the changes in frame
        // rate, bitrate, and max frame size in the negotiated capability
        switch (dwUniqueID)
        {
                case R263_QCIF_H245_CAPID:
                        ((VIDEOINFOHEADER *)((*ppAMMediaType)->pbFormat))->AvgTimePerFrame =  pIntersectedCapability->capability.video_cap.u.h263VideoCapability.qcifMPI * MIN_FRAME_INTERVAL;
                        ((VIDEOINFOHEADER *)((*ppAMMediaType)->pbFormat))->dwBitRate = pIntersectedCapability->capability.video_cap.u.h263VideoCapability.maxBitRate * 100L;
            if (pIntersectedCapability->capability.video_cap.u.h263VideoCapability.bppMaxKb)
            {
                ASSERT(((VIDEOINFOHEADER_H263 *)((*ppAMMediaType)->pbFormat))->bmiHeader.bmi.biSize == sizeof (BITMAPINFOHEADER_H263));
                ((VIDEOINFOHEADER_H263 *)((*ppAMMediaType)->pbFormat))->bmiHeader.dwBppMaxKb = pIntersectedCapability->capability.video_cap.u.h263VideoCapability.bppMaxKb;
            }
                        break;
                case R263_CIF_H245_CAPID:
                        ((VIDEOINFOHEADER *)((*ppAMMediaType)->pbFormat))->AvgTimePerFrame =  pIntersectedCapability->capability.video_cap.u.h263VideoCapability.cifMPI * MIN_FRAME_INTERVAL;
                        ((VIDEOINFOHEADER *)((*ppAMMediaType)->pbFormat))->dwBitRate = pIntersectedCapability->capability.video_cap.u.h263VideoCapability.maxBitRate * 100L;
            if (pIntersectedCapability->capability.video_cap.u.h263VideoCapability.bppMaxKb)
            {
                ASSERT(((VIDEOINFOHEADER_H263 *)((*ppAMMediaType)->pbFormat))->bmiHeader.bmi.biSize == sizeof (BITMAPINFOHEADER_H263));
                ((VIDEOINFOHEADER_H263 *)((*ppAMMediaType)->pbFormat))->bmiHeader.dwBppMaxKb = pIntersectedCapability->capability.video_cap.u.h263VideoCapability.bppMaxKb;
            }
                        break;
                case R263_SQCIF_H245_CAPID:
                        ((VIDEOINFOHEADER *)((*ppAMMediaType)->pbFormat))->AvgTimePerFrame =  pIntersectedCapability->capability.video_cap.u.h263VideoCapability.sqcifMPI * MIN_FRAME_INTERVAL;
                        ((VIDEOINFOHEADER *)((*ppAMMediaType)->pbFormat))->dwBitRate = pIntersectedCapability->capability.video_cap.u.h263VideoCapability.maxBitRate * 100L;
            if (pIntersectedCapability->capability.video_cap.u.h263VideoCapability.bppMaxKb)
            {
                ASSERT(((VIDEOINFOHEADER_H263 *)((*ppAMMediaType)->pbFormat))->bmiHeader.bmi.biSize == sizeof (BITMAPINFOHEADER_H263));
                ((VIDEOINFOHEADER_H263 *)((*ppAMMediaType)->pbFormat))->bmiHeader.dwBppMaxKb = pIntersectedCapability->capability.video_cap.u.h263VideoCapability.bppMaxKb;
            }
                        break;
                case R261_QCIF_H245_CAPID:
                        ((VIDEOINFOHEADER *)((*ppAMMediaType)->pbFormat))->AvgTimePerFrame =  pIntersectedCapability->capability.video_cap.u.h261VideoCapability.qcifMPI * MIN_FRAME_INTERVAL;
                        ((VIDEOINFOHEADER *)((*ppAMMediaType)->pbFormat))->dwBitRate = pIntersectedCapability->capability.video_cap.u.h261VideoCapability.maxBitRate * 100L;
                        break;
                case R261_CIF_H245_CAPID:
                default:
                        ((VIDEOINFOHEADER *)((*ppAMMediaType)->pbFormat))->AvgTimePerFrame =  pIntersectedCapability->capability.video_cap.u.h261VideoCapability.cifMPI * MIN_FRAME_INTERVAL;
                        ((VIDEOINFOHEADER *)((*ppAMMediaType)->pbFormat))->dwBitRate = pIntersectedCapability->capability.video_cap.u.h261VideoCapability.maxBitRate * 100L;
                        break;
        }

MyExit:
        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: end", _fx_));
        return Hr;
}

/****************************************************************************
 *  @doc INTERNAL CH245VIDCMETHOD
 *
 *  @mfunc HRESULT | CCapturePin | ReleaseNegotiatedCapability | This method
 *    is used to release the TAPI MSP Video Capture filter internal memory
 *    allocated by either the <mf CCapturePin.IntersectFormats> or
 *    <mf CCapturePin.GetLocalFormat> method.
 *
 *  @parm H245MediaCapability* | pIntersectedCapability | Specifies the H.245
 *    video format, of the resolved common local and remote capability
 *    options and limits.
 *
 *  @rdesc This method returns an HRESULT value that depends on the
 *    implementation of the interface. HRESULT can include one of the
 *    following standard constants, or other values not listed:
 *
 *  @flag E_POINTER | Null pointer argument
 *  @flag NOERROR | No error
 *
 *  @xref <mf CCapturePin.IntersectFormats>, <mf CCapturePin.GetLocalFormat>
 ***************************************************************************/
STDMETHODIMP CCapturePin::ReleaseNegotiatedCapability(IN H245MediaCapability *pIntersectedCapability)
{
        HRESULT Hr = NOERROR;

        FX_ENTRY("CCapturePin::ReleaseNegotiatedCapability")

        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: begin", _fx_));

        // Validate input parameters
        ASSERT(pIntersectedCapability);
        if (!pIntersectedCapability)
        {
                DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: Null pointer argument", _fx_));
                Hr = E_POINTER;
                goto MyExit;
        }

        // Release the memory
        delete pIntersectedCapability;

MyExit:
        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: end", _fx_));
        return Hr;
}

/****************************************************************************
 *  @doc INTERNAL CH245VIDCMETHOD
 *
 *  @mfunc HRESULT | CCapturePin | FindIDByRange | This method is used to
 *    obtain the unique format ID of a capability that corresponds to an
 *    <t AM_MEDIA_TYPE>.
 *
 *  @parm AM_MEDIA_TYPE* | pAMMediaType | Specifies a pointer to an
 *    <t AM_MEDIA_TYPE> structure that has been initialized with a
 *    specific format.
 *
 *  @parm DWORD* | pdwID | Specifies a pointer to a DWORD output parameter
 *    that will contain the unique format ID.
 *
 *  @rdesc This method returns an HRESULT value that depends on the
 *    implementation of the interface. HRESULT can include one of the
 *    following standard constants, or other values not listed:
 *
 *  @flag E_POINTER | Null pointer argument
 *  @flag E_INVALIDARG | Invalid argument
 *  @flag NOERROR | No error
 ***************************************************************************/
STDMETHODIMP CCapturePin::FindIDByRange(IN const AM_MEDIA_TYPE *pAMMediaType, OUT DWORD *pdwUniqueID)
{
        HRESULT Hr = NOERROR;

        FX_ENTRY("CCapturePin::FindIDByRange")

        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: begin", _fx_));

        // Validate input parameters
        ASSERT(pAMMediaType);
        ASSERT(pdwUniqueID);
        if (!pAMMediaType || !pdwUniqueID)
        {
                DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: Null pointer argument", _fx_));
                Hr = E_POINTER;
                goto MyExit;
        }
        ASSERT(pAMMediaType->majortype == MEDIATYPE_Video && pAMMediaType->formattype == FORMAT_VideoInfo && pAMMediaType->pbFormat);
        if (!pAMMediaType || !pdwUniqueID || pAMMediaType->majortype != MEDIATYPE_Video || pAMMediaType->formattype != FORMAT_VideoInfo || !pAMMediaType->pbFormat)
        {
                DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: Invalid argument", _fx_));
                Hr = E_INVALIDARG;
                goto MyExit;
        }

        // Which media type is this?
        if (HEADER(pAMMediaType->pbFormat)->biCompression == FOURCC_M263)
        {
                if (HEADER(pAMMediaType->pbFormat)->biWidth == 176 && HEADER(pAMMediaType->pbFormat)->biHeight == 144)
                {
                        *pdwUniqueID = R263_QCIF_H245_CAPID;
                }
                else if (HEADER(pAMMediaType->pbFormat)->biWidth == 352 && HEADER(pAMMediaType->pbFormat)->biHeight == 288)
                {
                        *pdwUniqueID = R263_CIF_H245_CAPID;
                }
                else if (HEADER(pAMMediaType->pbFormat)->biWidth == 128 && HEADER(pAMMediaType->pbFormat)->biHeight == 96)
                {
                        *pdwUniqueID = R263_SQCIF_H245_CAPID;
                }
                else
                {
                        DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: Invalid argument", _fx_));
                        Hr = E_INVALIDARG;
                }
        }
        else if (HEADER(pAMMediaType->pbFormat)->biCompression == FOURCC_M261)
        {
                if (HEADER(pAMMediaType->pbFormat)->biWidth == 176 && HEADER(pAMMediaType->pbFormat)->biHeight == 144)
                {
                        *pdwUniqueID = R261_QCIF_H245_CAPID;
                }
                else if (HEADER(pAMMediaType->pbFormat)->biWidth == 352 && HEADER(pAMMediaType->pbFormat)->biHeight == 288)
                {
                        *pdwUniqueID = R261_CIF_H245_CAPID;
                }
                else
                {
                        DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: Invalid argument", _fx_));
                        Hr = E_INVALIDARG;
                }
        }
        else
        {
                DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: Invalid argument", _fx_));
                Hr = E_INVALIDARG;
        }

MyExit:
        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: end", _fx_));
        return Hr;
}

#ifdef TEST_H245_VID_CAPS
STDMETHODIMP CCapturePin::TestH245VidC()
{
        HRESULT Hr = NOERROR;
        DWORD   dw;
        H245MediaCapabilityTable Table;
        H245MediaCapability *pIntersectedCapability;
        AM_MEDIA_TYPE *pAMMediaType;

        FX_ENTRY("CCapturePin::TestH245VidC")

        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: begin", _fx_));

        // Test GetH245VersionID
        GetH245VersionID(&dw);

        // Test GetFormatTable
        GetFormatTable(&Table);

        for (DWORD i=0; i < Table.uMappedCapabilities; i++)
        {
                // Test Refine
                for (DWORD j=0; j < Table.pCapabilityArray[i].uNumEntries; j++)
                        Refine(&Table.pCapabilityArray[i].h245MediaCapability, Table.pCapabilityArray[i].dwUniqueID, j);

                // Test IntersectFormats
                IntersectFormats(Table.pCapabilityArray[i].dwUniqueID, &Table.pCapabilityArray[i].h245MediaCapability, &Table.pCapabilityArray[i].h245MediaCapability, &pIntersectedCapability);

                // Test GetLocalFormat
                GetLocalFormat(Table.pCapabilityArray[i].dwUniqueID, pIntersectedCapability, &pAMMediaType);

                // Test FindIDByRange
                FindIDByRange(pAMMediaType, &dw);

                // Test ReleaseNegotiatedCapability
                ReleaseNegotiatedCapability(pIntersectedCapability);
        }

        // Test ReleaseFormatTable
        ReleaseFormatTable(&Table);

        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: end", _fx_));
        return Hr;
}
#endif
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\net\tapi\skywalker\filters\video\tapivcap\fpsrate.cpp ===
/****************************************************************************
 *  @doc INTERNAL FPSRATE
 *
 *  @module FpsRate.cpp | Source file for the <c CTAPIBasePin> and <c CPreviewPin>
 *    class methods used to implement the video capture and preview output
 *    pins frame rate control methods.
 ***************************************************************************/

#include "Precomp.h"

/****************************************************************************
 *  @doc INTERNAL CFPSCMETHOD
 *
 *  @mfunc HRESULT | CTAPIBasePin | Set | This method is used to set the
 *    value of a frame rate control property.
 *
 *  @parm FrameRateControlProperty | Property | Used to specifiy the property
 *    to set the value of.
 *
 *  @parm long | lValue | Used to specify the value to set on the property.
 *
 *  @parm TAPIControlFlags | lFlags | Used to specify the flags to set on
 *    the property.
 *
 *  @rdesc This method returns an HRESULT value that depends on the
 *    implementation of the interface. HRESULT can include one of the
 *    following standard constants, or other values not listed:
 *
 *  @flag E_FAIL | Failure
 *  @flag E_INVALIDARG | Invalid argument
 *  @flag NOERROR | No error
 ***************************************************************************/
STDMETHODIMP CTAPIBasePin::Set(IN FrameRateControlProperty Property, IN long lValue, IN TAPIControlFlags lFlags)
{
	HRESULT Hr = NOERROR;

	FX_ENTRY("CTAPIOutputPin::Set (FrameRateControlProperty)")

	DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: begin", _fx_));

	// Validate input parameters
	ASSERT(lValue >= m_lAvgTimePerFrameRangeMin);
	ASSERT(lValue <= m_lAvgTimePerFrameRangeMax);
	ASSERT(Property >= FrameRateControl_Maximum && Property <= FrameRateControl_Current);

	// Set relevant values
	if (Property == FrameRateControl_Maximum)
	{
		if (!lValue || lValue < m_lAvgTimePerFrameRangeMin || lValue > m_lAvgTimePerFrameRangeMax)
		{
			DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: Invalid argument", _fx_));
			Hr = E_INVALIDARG;
			goto MyExit;
		}
		m_lMaxAvgTimePerFrame = lValue;
		DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s:   New target frame rate: %ld.%ld fps", _fx_, 10000000/m_lMaxAvgTimePerFrame, 1000000000/m_lMaxAvgTimePerFrame - (10000000/m_lMaxAvgTimePerFrame) * 100));
	}
	else
	{
		DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: Invalid argument", _fx_));
		Hr = E_PROP_ID_UNSUPPORTED;
	}

MyExit:
	DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: end", _fx_));
	return Hr;
}

/****************************************************************************
 *  @doc INTERNAL CFPSCMETHOD
 *
 *  @mfunc HRESULT | CTAPIBasePin | Get | This method is used to retrieve
 *    the value of the current or maximum frame rate advertized.
 *
 *  @parm FrameRateControlProperty | Property | Used to specifiy the property
 *    to retrieve the value of.
 *
 *  @parm long* | plValue | Used to receive the value of the property, in
 *    100-nanosecond units.
 *
 *  @parm TAPIControlFlags* | plFlags | Used to receive the value of the flag
 *    associated to the property.
 *
 *  @rdesc This method returns an HRESULT value that depends on the
 *    implementation of the interface. HRESULT can include one of the
 *    following standard constants, or other values not listed:
 *
 *  @flag E_POINTER | Null pointer argument
 *  @flag E_PROP_ID_UNSUPPORTED | The specified property ID is not supported
 *    for the specified property set
 *  @flag NOERROR | No error
 ***************************************************************************/
STDMETHODIMP CTAPIBasePin::Get(IN FrameRateControlProperty Property, OUT long *plValue, OUT TAPIControlFlags *plFlags)
{
	HRESULT Hr = NOERROR;

	FX_ENTRY("CTAPIOutputPin::Get (FrameRateControlProperty)")

	DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: begin", _fx_));

	// Validate input parameters
	ASSERT(plValue);
	ASSERT(plFlags);
	if (!plValue || !plFlags)
	{
		DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: Null pointer argument", _fx_));
		Hr = E_POINTER;
		goto MyExit;
	}
	ASSERT(Property >= FrameRateControl_Maximum && Property <= FrameRateControl_Current);

	// Return relevant values
	*plFlags = TAPIControl_Flags_None;
	if (Property == FrameRateControl_Maximum)
		*plValue = m_lMaxAvgTimePerFrame;
	else if (Property == FrameRateControl_Current)
		*plValue = m_lCurrentAvgTimePerFrame;
	else
	{
		DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: Invalid Property argument", _fx_));
		Hr = E_PROP_ID_UNSUPPORTED;
	}

MyExit:
	DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: end", _fx_));
	return Hr;
}

/****************************************************************************
 *  @doc INTERNAL CFPSCMETHOD
 *
 *  @mfunc HRESULT | CTAPIBasePin | GetRange | This method is used to
 *    retrieve support, minimum, maximum, and default values of the current
 *    or maximum frame rate advertized.
 *
 *  @parm FrameRateControlProperty | Property | Used to specifiy the property
 *    to retrieve the range values of.
 *
 *  @parm long* | plMin | Used to retrieve the minimum value of the
 *    property, in 100-nanosecond units.
 *
 *  @parm long* | plMax | Used to retrieve the maximum value of the
 *    property, in 100-nanosecond units.
 *
 *  @parm long* | plSteppingDelta | Used to retrieve the stepping delta
 *    of the property, in 100-nanosecond units.
 *
 *  @parm long* | plDefault | Used to retrieve the default value of the
 *    property, in 100-nanosecond units.
 *
 *  @parm TAPIControlFlags* | plCApsFlags | Used to receive the flags
 *    suppported by the property.
 *
 *  @rdesc This method returns an HRESULT value that depends on the
 *    implementation of the interface. HRESULT can include one of the
 *    following standard constants, or other values not listed:
 *
 *  @flag E_POINTER | Null pointer argument
 *  @flag E_PROP_ID_UNSUPPORTED | The specified property ID is not supported
 *    for the specified property set
 *  @flag NOERROR | No error
 ***************************************************************************/
STDMETHODIMP CTAPIBasePin::GetRange(IN FrameRateControlProperty Property, OUT long *plMin, OUT long *plMax, OUT long *plSteppingDelta, OUT long *plDefault, OUT TAPIControlFlags *plCapsFlags)
{
	HRESULT Hr = NOERROR;

	FX_ENTRY("CTAPIOutputPin::GetRange (FrameRateControlProperty)")

	DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: begin", _fx_));

	// Validate input parameters
	ASSERT(plMin);
	ASSERT(plMax);
	ASSERT(plSteppingDelta);
	ASSERT(plDefault);
	ASSERT(plCapsFlags);
	if (!plMin || !plMax || !plSteppingDelta || !plDefault || !plCapsFlags)
	{
		DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: Null pointer argument", _fx_));
		Hr = E_POINTER;
		goto MyExit;
	}
	ASSERT(Property >= FrameRateControl_Maximum && Property <= FrameRateControl_Current);
	if (Property != FrameRateControl_Maximum && Property != FrameRateControl_Current)
	{
		DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: Invalid Property argument", _fx_));
		Hr = E_PROP_ID_UNSUPPORTED;
		goto MyExit;
	}

	// Return relevant values
	*plCapsFlags = TAPIControl_Flags_None;
	*plMin = m_lAvgTimePerFrameRangeMin;
	*plMax = m_lAvgTimePerFrameRangeMax;
	*plSteppingDelta = m_lAvgTimePerFrameRangeSteppingDelta;
	*plDefault = m_lAvgTimePerFrameRangeDefault;

	DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s:   Ranges: Min=%ld, Max=%ld, Step=%ld, Default=%ld", _fx_, m_lAvgTimePerFrameRangeMin, m_lAvgTimePerFrameRangeMax, m_lAvgTimePerFrameRangeSteppingDelta, m_lAvgTimePerFrameRangeDefault));

MyExit:
	DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: end", _fx_));
	return Hr;
}
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\net\tapi\skywalker\filters\video\tapivcap\devicew.cpp ===
/****************************************************************************
 *  @doc INTERNAL DEVICEW
 *
 *  @module DeviceW.cpp | Source file for the <c CWDMCapDev>
 *    base class used to communicate with a WDM capture device.
 ***************************************************************************/

#include "Precomp.h"

// @todo Remove this before checkin!
//#define DUMP_DRIVER_CHARACTERISTICS 1
//#define DEBUG_STREAMING

//#define XTRA_TRACE -- moved into ...\skywalker\filters\filters.inc
#include "dbgxtra.h"

#ifdef XTRA_TRACE

#define LOLA 0x414C4F4C  //LOLA
#define BOLA 0x414C4F42  //BOLA
#define MAGIC_TAG_SET(a)   m_tag=a
UINT savi;
DWORD GetOvResErr[6];

#define CLEAR_GetOvResErr   memset(GetOvResErr,0,sizeof(GetOvResErr))
#define SET_GetOvResErr(i,value)        GetOvResErr[(i)]=(value);
#define SET_I(sav,i)    sav=(i)


#else

#define MAGIC_TAG_SET(a)
#define CLEAR_GetOvResErr
#define SET_GetOvResErr(i,value)
#define SET_I(sav,i)
#endif //XTRA_TRACE

#ifdef DEBUG
#define DBGUTIL_ENABLE
#endif

#define DEVICEW_DEBUG
//--//#include "dbgutil.h" // this defines the __DBGUTIL_H__ below
#if defined(DBGUTIL_ENABLE) && defined(__DBGUTIL_H__)

  #ifdef DEVICEW_DEBUG
    DEFINE_DBG_VARS(DeviceW, (NTSD_OUT | LOG_OUT), 0x0);
  #else
    DEFINE_DBG_VARS(DeviceW, 0, 0);
  #endif
  #define D(f) if(g_dbg_DeviceW & (f))

#else
  #undef DEVICEW_DEBUG

  #define D(f) ; / ## /
  #define dprintf ; / ## /
  #define dout ; / ## /
#endif



/****************************************************************************
 *  @doc INTERNAL CWDMCAPDEVMETHOD
 *
 *  @mfunc void | CWDMCapDev | CWDMCapDev | This method is the constructor
 *    for the <c CWDMCapDev> object.
 *
 *  @rdesc Nada.
 ***************************************************************************/
CWDMCapDev::CWDMCapDev(IN TCHAR *pObjectName, IN CTAPIVCap *pCaptureFilter, IN LPUNKNOWN pUnkOuter, IN DWORD dwDeviceIndex, IN HRESULT *pHr) : CCapDev(pObjectName, pCaptureFilter, pUnkOuter, dwDeviceIndex, pHr)
{
        FX_ENTRY("CWDMCapDev::CWDMCapDev")

        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: begin", _fx_));

        if (!pHr || FAILED(*pHr))
        {
                DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: Base class error or invalid input parameter", _fx_));
                goto MyExit;
        }

    MAGIC_TAG_SET(LOLA);   //magic seq. set 2 string LOLA
        // Default inits
        m_hDriver                       = NULL;
        m_pVideoDataRanges      = NULL;
        m_dwCapturePinId        = INVALID_PIN_ID;
        m_dwPreviewPinId        = INVALID_PIN_ID;
        m_hKSPin                        = NULL;
        m_hKsUserDLL            = NULL;
        m_pKsCreatePin          = NULL;
        m_fStarted                      = FALSE;
    m_pWDMVideoBuff     = NULL;
        m_cntNumVidBuf  = 0;
MyExit:
        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: end", _fx_));
}

/****************************************************************************
 *  @doc INTERNAL CWDMCAPDEVMETHOD
 *
 *  @mfunc void | CWDMCapDev | ~CWDMCapDev | This method is the destructor
 *    for the <c CWDMCapDev> object. Closes the driver file handle and
 *    releases the video data range memory
 *
 *  @rdesc Nada.
 ***************************************************************************/
CWDMCapDev::~CWDMCapDev()
{
        FX_ENTRY("CWDMCapDev::~CWDMCapDev")

        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: begin", _fx_));

        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s:   Closing the WDM driver, m_hDriver=0x%08lX", _fx_, m_hDriver));

        if (m_hDriver)
                DisconnectFromDriver();

    if (m_pWDMVideoBuff) delete [] m_pWDMVideoBuff;

        if (m_pVideoDataRanges)
        {
                delete [] m_pVideoDataRanges;
                m_pVideoDataRanges = (PVIDEO_DATA_RANGES)NULL;
        }

        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: end", _fx_));
}

/****************************************************************************
 *  @doc INTERNAL CWDMCAPDEVMETHOD
 *
 *  @mfunc CWDMCapDev* | CWDMCapDev | CreateWDMCapDev | This
 *    helper function creates an object to interact with the WDM capture
 *    device.
 *
 *  @parm CTAPIVCap* | pCaptureFilter | Specifies a pointer to the owner
 *    filter.
 *
 *  @parm CCapDev** | ppCapDev | Specifies the address of a pointer to the
 *    newly created <c CWDMCapDev> object.
 *
 *  @rdesc This method returns an HRESULT value that depends on the
 *    implementation of the interface. HRESULT can include one of the
 *    following standard constants, or other values not listed:
 *
 *  @flag E_FAIL | Failure
 *  @flag E_POINTER | Null pointer argument
 *  @flag E_OUTOFMEMORY | Out of memory
 *  @flag NOERROR | No error
 ***************************************************************************/
HRESULT CALLBACK CWDMCapDev::CreateWDMCapDev(IN CTAPIVCap *pCaptureFilter, IN DWORD dwDeviceIndex, OUT CCapDev **ppCapDev)
{
        HRESULT Hr = NOERROR;
        IUnknown *pUnkOuter;

        FX_ENTRY("CWDMCapDev::CreateWDMCapDev")

        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: begin", _fx_));

        //LOG_MSG_VAL(_fx_,0,0,0);
        // Validate input parameters
        ASSERT(pCaptureFilter);
        ASSERT(ppCapDev);
        if (!pCaptureFilter || !ppCapDev)
        {
                DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: Null pointer argument", _fx_));
                Hr = E_POINTER;
                goto MyExit;
        }

        // Get the outer unknown
        pCaptureFilter->QueryInterface(IID_IUnknown, (void **)&pUnkOuter);

        // Only keep the pUnkOuter reference
        pCaptureFilter->Release();

        // Create an instance of the capture device
        if (!(*ppCapDev = (CCapDev *) new CWDMCapDev(NAME("WDM Capture Device"), pCaptureFilter, pUnkOuter, dwDeviceIndex, &Hr)))
        {
                DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: Out of memory", _fx_));
                Hr = E_OUTOFMEMORY;
                goto MyExit;
        }

        // If initialization failed, delete the stream array and return the error
        if (FAILED(Hr) && *ppCapDev)
        {
                DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: Initialization failed", _fx_));
                Hr = E_FAIL;
                delete *ppCapDev, *ppCapDev = NULL;
        }

        //LOG_MSG_VAL(_fx_,0,0,1);
MyExit:
        //LOG_MSG_VAL(_fx_,0,0,0xffff);
        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: end", _fx_));
        return Hr;
}

/****************************************************************************
 *  @doc INTERNAL CWDMCAPDEVMETHOD
 *
 *  @mfunc HRESULT | CWDMCapDev | NonDelegatingQueryInterface | This
 *    method is the nondelegating interface query function. It returns a pointer
 *    to the specified interface if supported. The only interfaces explicitly
 *    supported being <i IAMVfWCaptureDialogs>.
 *
 *  @parm REFIID | riid | Specifies the identifier of the interface to return.
 *
 *  @parm PVOID* | ppv | Specifies the place in which to put the interface
 *    pointer.
 *
 *  @rdesc This method returns an HRESULT value that depends on the
 *    implementation of the interface. HRESULT can include one of the
 *    following standard constants, or other values not listed:
 *
 *  @flag E_FAIL | Failure
 *  @flag E_POINTER | Null pointer argument
 *  @flag NOERROR | No error
 *
 *  @todo Add interfaces specific to this derived class or remove this code
 *    and let the base class do the work.
 ***************************************************************************/
STDMETHODIMP CWDMCapDev::NonDelegatingQueryInterface(IN REFIID riid, OUT void **ppv)
{
        HRESULT Hr = NOERROR;

        FX_ENTRY("CWDMCapDev::NonDelegatingQueryInterface")

        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: begin", _fx_));

        // Retrieve interface pointer
        if (riid == __uuidof(IVideoProcAmp))
        {
            *ppv = static_cast<IVideoProcAmp*>(this);
            GetOwner()->AddRef();
                DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s:   SUCCESS: IAMVideoProcAmp*=0x%08lX", _fx_, *ppv));
                goto MyExit;
        }
#ifndef USE_SOFTWARE_CAMERA_CONTROL
        else if (riid == __uuidof(ICameraControl))
        {
            *ppv = static_cast<ICameraControl*>(this);
            GetOwner()->AddRef();
                DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s:   SUCCESS: ICameraControl*=0x%08lX", _fx_, *ppv));
                goto MyExit;
        }
#endif
        else if (FAILED(Hr = CCapDev::NonDelegatingQueryInterface(riid, ppv)))
        {
                DBGOUT((g_dwVideoCaptureTraceID, WARN, "%s:   WARNING: NDQI for {%08lX-%04lX-%04lX-%02lX%02lX-%02lX%02lX%02lX%02lX%02lX%02lX} failed Hr=0x%08lX", _fx_, riid.Data1, riid.Data2, riid.Data3, riid.Data4[0], riid.Data4[1], riid.Data4[2], riid.Data4[3], riid.Data4[4], riid.Data4[5], riid.Data4[6], riid.Data4[7], Hr));
        }
        else
        {
                DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s:   SUCCESS: {%08lX-%04lX-%04lX-%02lX%02lX-%02lX%02lX%02lX%02lX%02lX%02lX}*=0x%08lX", _fx_, riid.Data1, riid.Data2, riid.Data3, riid.Data4[0], riid.Data4[1], riid.Data4[2], riid.Data4[3], riid.Data4[4], riid.Data4[5], riid.Data4[6], riid.Data4[7], *ppv));
        }

MyExit:
        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: end", _fx_));
        return Hr;
}

/****************************************************************************
 *  @doc INTERNAL CWDMCAPDEVMETHOD
 *
 *  @mfunc HRESULT | CWDMCapDev | ConnectToDriver | This method is used to
 *    open a WDM capture device, get its format capibilities, and set a default
 *    format.
 *
 *  @rdesc This method returns an HRESULT value that depends on the
 *    implementation of the interface. HRESULT can include one of the
 *    following standard constants, or other values not listed:
 *
 *  @flag E_FAIL | Failure
 *  @flag NOERROR | No error
 *
 *  @todo Verify error management
 ***************************************************************************/
HRESULT CWDMCapDev::ConnectToDriver()
{
        HRESULT Hr = NOERROR;
        KSP_PIN KsProperty;
        DWORD dwPinCount = 0UL;
        DWORD cbReturned;
        DWORD dwPinId;
        GUID guidCategory;

        FX_ENTRY("CWDMCapDev::ConnectToDriver")

        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: begin", _fx_));

        // Don't re-open the driver
        if (m_hDriver)
        {
                DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s:   Class driver already opened", _fx_));
                goto MyExit;
        }

        // Validate driver path
        if (lstrlen(g_aDeviceInfo[m_dwDeviceIndex].szDevicePath) == 0)
        {
                DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   Invalid driver path", _fx_));
                Hr = E_FAIL;
                goto MyError;
        }
        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s:   Using m_dwDeviceIndex %d", _fx_, m_dwDeviceIndex));
        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s:   Opening class driver '%s'", _fx_, g_aDeviceInfo[m_dwDeviceIndex].szDevicePath));

        // All we care is to wet the hInheritHanle = TRUE;
        SECURITY_ATTRIBUTES SecurityAttributes;
        SecurityAttributes.nLength = sizeof(SECURITY_ATTRIBUTES);  // use pointers
        SecurityAttributes.bInheritHandle = TRUE;
        SecurityAttributes.lpSecurityDescriptor = NULL; // GetInitializedSecurityDescriptor();

        // Really open the driver
        if ((m_hDriver = CreateFile(g_aDeviceInfo[m_dwDeviceIndex].szDevicePath, GENERIC_READ | GENERIC_WRITE, FILE_SHARE_READ | FILE_SHARE_WRITE, &SecurityAttributes, OPEN_EXISTING, FILE_FLAG_OVERLAPPED, NULL)) == INVALID_HANDLE_VALUE)
        {
                DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   CreateFile failed with Path=%s GetLastError()=%d", _fx_, g_aDeviceInfo[m_dwDeviceIndex].szDevicePath, GetLastError()));
                m_hDriver = NULL;
                Hr = E_FAIL;
                goto MyError;
        }

        // Get the number of pins
        KsProperty.PinId                        = 0;
        KsProperty.Reserved                     = 0;
        KsProperty.Property.Set         = KSPROPSETID_Pin;
        KsProperty.Property.Id          = KSPROPERTY_PIN_CTYPES;
        KsProperty.Property.Flags       = KSPROPERTY_TYPE_GET;

        if (DeviceIoControl(m_hDriver, IOCTL_KS_PROPERTY, &KsProperty, sizeof(KsProperty), &dwPinCount, sizeof(dwPinCount), &cbReturned) == FALSE)
        {
                DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   Couldn't get the number of pins supported by the device", _fx_));
                Hr = E_FAIL;
                goto MyError;
        }
        else
        {
                DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s:   Number of pins: %ld", _fx_, dwPinCount));
        }

        // Look for the capture, preview and RTP pins
        // Get the properties of each pin
    for (dwPinId = 0; dwPinId < dwPinCount; dwPinId++)
        {
                // Get the pin category
                KsProperty.PinId                        = dwPinId;
                KsProperty.Reserved                     = 0;
                KsProperty.Property.Set         = KSPROPSETID_Pin;
                KsProperty.Property.Id          = KSPROPERTY_PIN_CATEGORY;
                KsProperty.Property.Flags       = KSPROPERTY_TYPE_GET;

                if (DeviceIoControl(m_hDriver, IOCTL_KS_PROPERTY, &KsProperty, sizeof(KsProperty), &guidCategory, sizeof(guidCategory), &cbReturned) == FALSE)
                {
                        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s:   Couldn't get the GUID category", _fx_));
                }
                else
                {
                        if (guidCategory == PINNAME_VIDEO_PREVIEW)
                        {
                                DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s:   Found a PINNAME_VIDEO_PREVIEW pin. Id=#%ld", _fx_, dwPinId));
                                m_dwPreviewPinId = dwPinId;
                        }
                        else if (guidCategory == PINNAME_VIDEO_CAPTURE)
                        {
                                DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s:   Found a PINNAME_VIDEO_CAPTURE pin. Id=#%ld", _fx_, dwPinId));
                                m_dwCapturePinId = dwPinId;
                        }
                        else
                        {
                                DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: Pin has unknown GUID category", _fx_));
                        }
                }
        }

        // If there is no capture or preview pin, just bail
        if ((m_dwPreviewPinId == INVALID_PIN_ID) && (m_dwCapturePinId == INVALID_PIN_ID))
        {
                DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s: No capture of preview pin supported by this device. Just bail", _fx_));
                Hr = E_FAIL;
                goto MyError;
        }

#if defined(DUMP_DRIVER_CHARACTERISTICS) && defined(DEBUG)
        GetDriverDetails();
#endif

        // If there is no valid data range, we cannot stream
        if (!CreateDriverSupportedDataRanges())
        {
                DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s: No capture of preview pin supported by this device. Just bail", _fx_));
                Hr = E_FAIL;
                goto MyError;
        }

        // Load KSUSER.DLL and get a proc address
        if (!(m_hKsUserDLL = LoadLibrary("KSUSER")))
        {
                DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s: KsUser.dll load failed!", _fx_));
                Hr = E_FAIL;
                goto MyError;
        }
        if (!(m_pKsCreatePin = (LPFNKSCREATEPIN)GetProcAddress(m_hKsUserDLL, "KsCreatePin")))
        {
                DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s: Couldn't find KsCreatePin on KsUser.dll!", _fx_));
                Hr = E_FAIL;
                goto MyError;
        }

        // Get the formats from the registry - if this fail we'll profile the device
        if (FAILED(Hr = GetFormatsFromRegistry()))
        {
                if (FAILED(Hr = ProfileCaptureDevice()))
                {
                        DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: ProfileCaptureDevice failed!", _fx_));
                        Hr = VFW_E_NO_CAPTURE_HARDWARE;
                        goto MyExit;
                }
#ifdef DEVICEW_DEBUG
                else    dout(3, g_dwVideoCaptureTraceID, TRCE,"%s:    ProfileCaptureDevice", _fx_);
#endif
        }
#ifdef DEVICEW_DEBUG
        else    dout(3, g_dwVideoCaptureTraceID, TRCE,"%s:    GetFormatsFromRegistry", _fx_);

        dump_video_format_image_size(m_dwImageSize);
        dump_video_format_num_colors(m_dwFormat);
#endif

        goto MyExit;

MyError:
        DisconnectFromDriver();
MyExit:
        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: end", _fx_));
        return Hr;
}

/****************************************************************************
 *  @doc INTERNAL CWDMCAPDEVMETHOD
 *
 *  @mfunc HRESULT | CWDMCapDev | DisconnectFromDriver | This method is used to
 *    release the capture device.
 *
 *  @rdesc This method returns an HRESULT value that depends on the
 *    implementation of the interface. HRESULT can include one of the
 *    following standard constants, or other values not listed:
 *
 *  @flag E_FAIL | Failure
 *  @flag NOERROR | No error
 ***************************************************************************/
HRESULT CWDMCapDev::DisconnectFromDriver()
{
        HRESULT Hr = NOERROR;

        FX_ENTRY("CWDMCapDev::DisconnectFromDriver")

        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: begin", _fx_));

        // Close the underlying video kernel streaming pin
        if (m_hKSPin)
        {
                if (!(CloseHandle(m_hKSPin)))
                {
                        DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   CloseHandle(m_hKSPin=0x%08lX) failed with GetLastError()=0x%08lX", _fx_, m_hKSPin, GetLastError()));
                }

                m_hKSPin = NULL;
        }

        // Release kernel streaming DLL (KSUSER.DLL)
        if (m_hKsUserDLL)
                FreeLibrary(m_hKsUserDLL);

        // Close drivere handle
        if (m_hDriver && (m_hDriver != INVALID_HANDLE_VALUE))
        {
                if (!CloseHandle(m_hDriver))
                {
                        DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   CloseHandle(m_hDriver=0x%08lX) failed with GetLastError()=0x%08lX", _fx_, m_hDriver, GetLastError()));
                }
        }
        else
        {
                DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s:   Nothing to close", _fx_));
        }

        m_hDriver = NULL;

        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: end", _fx_));
        return NOERROR;
}

/****************************************************************************
 *  @doc INTERNAL CWDMCAPDEVMETHOD
 *
 *  @mfunc HRESULT | CWDMCapDev | ProfileCaptureDevice | This method is used to
 *    determine the list of formats supported by a WDM capture device.
 *
 *  @rdesc This method returns an HRESULT value that depends on the
 *    implementation of the interface. HRESULT can include one of the
 *    following standard constants, or other values not listed:
 *
 *  @flag E_FAIL | Failure
 *  @flag E_UNEXPECTED | Unrecoverable error
 *  @flag NOERROR | No error
 ***************************************************************************/
HRESULT CWDMCapDev::ProfileCaptureDevice()
{
        FX_ENTRY("CWDMCapDev::ProfileCaptureDevice")

        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: begin", _fx_));

        // We'll always provide a source dialog for WDM devices in order to
        // make it easy for apps that don't want to call IAMVideoProcAmp. They
        // will still be able to allow users to mess with brigthness and other
        // video settings with this simulation of the VfW source dialog.
        m_dwDialogs = FORMAT_DLG_OFF | SOURCE_DLG_ON | DISPLAY_DLG_OFF;

        // Disable streaming of large size by default on WDM devices
        m_dwStreamingMode = FRAME_GRAB_LARGE_SIZE;

    // Let the base class complete the profiling
        return CCapDev::ProfileCaptureDevice();
}

/****************************************************************************
 *  @doc INTERNAL CWDMCAPDEVMETHOD
 *
 *  @mfunc HRESULT | CWDMCapDev | SendFormatToDriver | This method is used to
 *    tell the VfW capture device what format to use.
 *
 *  @parm LONG | biWidth | Specifies the image width.
 *
 *  @parm LONG | biHeight | Specifies the image height.
 *
 *  @parm DWORD | biCompression | Specifies the format type.
 *
 *  @parm WORD | biBitCount | Specifies the number of bits per pixel.
 *
 *  @parm REFERENCE_TIME | AvgTimePerFrame | Specifies the frame rate.
 *
 *  @rdesc This method returns an HRESULT value that depends on the
 *    implementation of the interface. HRESULT can include one of the
 *    following standard constants, or other values not listed:
 *
 *  @flag E_FAIL | Failure
 *  @flag NOERROR | No error
 ***************************************************************************/
HRESULT CWDMCapDev::SendFormatToDriver(IN LONG biWidth, IN LONG biHeight, IN DWORD biCompression, IN WORD biBitCount, IN REFERENCE_TIME AvgTimePerFrame, BOOL fUseExactFormat)
{
        HRESULT Hr = NOERROR;
        BITMAPINFOHEADER bmih;
        int nFormat, nBestFormat;
        int     i, delta, best, tmp;
        DWORD dwPinId;
        BOOL fValidMatch;
        DATAPINCONNECT DataConnect;
        PKS_DATARANGE_VIDEO pSelDRVideo;
#ifdef DEBUG
        char szFourCC[5] = {0};
#endif
        DWORD dwErr;
        DWORD cb;

        FX_ENTRY("CWDMCapDev::SendFormatToDriver")

        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: begin", _fx_));

        // Validate input parameters
        ASSERT(m_pKsCreatePin);
        if (!m_pKsCreatePin)
        {
                DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: Invalid m_pKsCreatePin!", _fx_));
                Hr = E_UNEXPECTED;
                goto MyExit;
        }

        // @todo Fix units for fps
        dout(g_dbg_DeviceW_log,g_dwVideoCaptureTraceID, FAIL, "%s:   Trying to set %dx%d at %ld fps\n", _fx_, biWidth, biHeight, AvgTimePerFrame != 0 ? (LONG)(10000000 / AvgTimePerFrame) : 0);
        D(1) dprintf("W **** Initial arguments: biWidth = %ld, biHeight = %ld, biCompression = '%.4s', AvgTimePerFrame = %I64u\n", biWidth, biHeight, &biCompression, AvgTimePerFrame);
        // Common to all formats
        bmih.biSize = sizeof(BITMAPINFOHEADER);
        bmih.biPlanes = 1;
        bmih.biXPelsPerMeter = bmih.biYPelsPerMeter = bmih.biClrUsed = bmih.biClrImportant = 0;

        if (!fUseExactFormat)
        {
                D(1) dprintf("W Not using 'fUseExactFormat' .... m_dwFormat = 0x%08lx\n", m_dwFormat);
                D(1) dprintf("W Looking for 4cc %lX : '%.4s'\n", biCompression, &biCompression);
                // Can we directly capture data in this format?
                for (nFormat=0, nBestFormat=-1; nFormat<NUM_BITDEPTH_ENTRIES; nFormat++)
                {
                        // Try a format supported by the device
                        if (aiFormat[nFormat] & m_dwFormat)
                        {
                                // Remember the device supports this format
                                if (nBestFormat == -1)
                                        nBestFormat = nFormat;

                                // Is this the format we're being asked to use?
                                if (aiFourCCCode[nFormat] == biCompression) {
                                        D(1) dprintf("W aiFourCCCode[nFormat] = %lX : '%.4s'\n", aiFourCCCode[nFormat], &aiFourCCCode[nFormat]); // aiFourCCCode[nFormat] & 0xff, (aiFourCCCode[nFormat]>>8) & 0xff, (aiFourCCCode[nFormat]>>16) & 0xff, (aiFourCCCode[nFormat]>>24) & 0xff);
                                        break;
                                }
                        }
                }

                // If we found a match, use this format. Otherwise, pick
                // whatever else this device can do
                if (nFormat == NUM_BITDEPTH_ENTRIES)
                {
                        nFormat = nBestFormat;
                }
                D(1) dprintf("W nFormat = %d\n", nFormat);

                bmih.biBitCount = aiBitDepth[nFormat];
                bmih.biCompression = aiFourCCCode[nFormat];

                // Find the best image size to capture at
                // Assume the next resolution will be correctly truncated to the output size
                best = -1;
                delta = 999999;
                D(1) dprintf("W biWidth, biHeight = %ld, %ld\n",biWidth, biHeight);
                for (i=0; i<VIDEO_FORMAT_NUM_RESOLUTIONS; i++)
                {
                        if (awResolutions[i].dwRes & m_dwImageSize)
                        {
                                //dprintf("Trying awResolutions[%d].dwRes = %lu (%ld,%ld)\n", i, awResolutions[i].dwRes, awResolutions[i].framesize.cx, awResolutions[i].framesize.cy);
                                tmp = awResolutions[i].framesize.cx - biWidth;
                                if (tmp < 0) tmp = -tmp;
                                if (tmp < delta)
                                {       //dprintf("\t... X. i=%d : delta, tmp =  %ld, %ld\n", i, delta, tmp);
                                        delta = tmp;
                                        best = i;
                                }
                                tmp = awResolutions[i].framesize.cy - biHeight;
                                if (tmp < 0) tmp = -tmp;
                                if (tmp < delta)
                                {       //dprintf("\t... Y. i=%d : delta, tmp =  %ld, %ld\n", i, delta, tmp);
                                        delta = tmp;
                                        best = i;
                                }
                        }
                }

                if (best < 0)
                {
                        DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: Can't find appropriate format!", _fx_));
                        Hr = E_FAIL;
                        goto MyExit;
                }

                bmih.biWidth = awResolutions[best].framesize.cx;
                bmih.biHeight = awResolutions[best].framesize.cy;
        }
        else
        {
                bmih.biBitCount = biBitCount;
                bmih.biCompression = biCompression;
                bmih.biWidth = biWidth;
                bmih.biHeight = biHeight;
        }

#ifdef DEVICEW_DEBUG
        dprintf("W 4CC used = %lX : '%.4s'\n", bmih.biCompression, &bmih.biCompression); // aiFourCCCode[nFormat] & 0xff, (aiFourCCCode[nFormat]>>8) & 0xff, (aiFourCCCode[nFormat]>>16) & 0xff, (aiFourCCCode[nFormat]>>24) & 0xff);
        g_dbg_4cc=bmih.biCompression;
        g_dbg_bc =bmih.biBitCount;
        g_dbg_w  =bmih.biWidth;
        g_dbg_h = bmih.biHeight;
#endif
        bmih.biSizeImage = DIBSIZE(bmih);

        // @todo Copy the palette if there is one

        // Update last format fields
        if (biCompression == BI_RGB)
        {
                if (biBitCount == 4)
                {
                        bmih.biClrUsed = 16;
                        bmih.biClrImportant = 16;
                }
                else if (biBitCount == 8)
                {
                        bmih.biClrUsed = 256;
                        bmih.biClrImportant = 256;
                }
        }

        // Get a PinId from the driver
        D(1) dprintf("W ---------- m_dwCapturePinId = 0x%08lx\n", m_dwCapturePinId);
        if (m_dwCapturePinId != INVALID_PIN_ID)
        {
                dwPinId = m_dwCapturePinId;
        }
        else
        {
                if (m_dwPreviewPinId != INVALID_PIN_ID)
                {
                        dwPinId = m_dwPreviewPinId;
                }
                else
                {
                        DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: Can't find appropriate pin to open!", _fx_));
                        Hr = E_FAIL;
                        goto MyExit;
                }
        }

        dprintf("W >>>>>> Asking for: (bmih.) biWidth = %ld, biHeight = %ld, biCompression = '%.4s'\n", bmih.biWidth, bmih.biHeight, &bmih.biCompression);

        // We need to find a video data range that matches the bitmap info header passed in
        fValidMatch = FALSE;
        if (FAILED(Hr = FindMatchDataRangeVideo(&bmih, (DWORD)AvgTimePerFrame, &fValidMatch, &pSelDRVideo)) || !fValidMatch)
        {
                DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: Can't open pin with this format!", _fx_));
                Hr = E_FAIL;
                goto MyExit;
        }

        // Allocate space for a videoinfo that will hold it
        if (m_pCaptureFilter->m_user.pvi)
                delete m_pCaptureFilter->m_user.pvi, m_pCaptureFilter->m_user.pvi = NULL;

        cb = sizeof(VIDEOINFOHEADER) + pSelDRVideo->VideoInfoHeader.bmiHeader.biSize - sizeof(BITMAPINFOHEADER);
        if (pSelDRVideo->VideoInfoHeader.bmiHeader.biBitCount == 8 && pSelDRVideo->VideoInfoHeader.bmiHeader.biCompression == BI_RGB)
                cb += sizeof(RGBQUAD) * 256;    // space for PALETTE or BITFIELDS
        else if (pSelDRVideo->VideoInfoHeader.bmiHeader.biBitCount == 4 && pSelDRVideo->VideoInfoHeader.bmiHeader.biCompression == BI_RGB)
                cb += sizeof(RGBQUAD) * 16;         // space for PALETTE or BITFIELDS
        if (!(m_pCaptureFilter->m_user.pvi = (VIDEOINFOHEADER *)(new BYTE[cb])))
        {
                DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: Out of memory!", _fx_));
                Hr = E_OUTOFMEMORY;
                goto MyExit;
        }

        // Copy the default format
        CopyMemory(m_pCaptureFilter->m_user.pvi, &pSelDRVideo->VideoInfoHeader, cb);
        D(1) dprintf("- - - - Init m_pCaptureFilter->m_user.pvi ... CWDMCapDev this = %p , m_pCaptureFilter = %p\n",this,m_pCaptureFilter);
        D(1) DumpVIH(m_pCaptureFilter->m_user.pvi);

        D(1) dprintf("**** m_pCaptureFilter->m_user.pvi->AvgTimePerFrame                   = %I64u (from pSelDRVideo->VideoInfoHeader)\n",                m_pCaptureFilter->m_user.pvi->AvgTimePerFrame);
#ifdef DEVICEW_DEBUG
        D(1)
        {
            if(m_pCaptureFilter->m_pCapturePin!=NULL)
                    D(1) dprintf("**** m_pCaptureFilter->m_pCapturePin->m_lAvgTimePerFrameRangeDefault = %lu (is this just a DWORD ?!!!?) \n",                        m_pCaptureFilter->m_pCapturePin->m_lAvgTimePerFrameRangeDefault);
            else {
                    D(1) dprintf("**** m_pCaptureFilter->m_pCapturePin == NULL ! ! ! ! !\a\n");
                    D(2) DebugBreak();
            }
        }
#endif
        // Fix broken bitmap info headers
        if (HEADER(m_pCaptureFilter->m_user.pvi)->biSizeImage == 0 && (HEADER(m_pCaptureFilter->m_user.pvi)->biCompression == BI_RGB || HEADER(m_pCaptureFilter->m_user.pvi)->biCompression == BI_BITFIELDS))
        {
                DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s:   WARNING: Fixing broken bitmap info header!", _fx_));
                HEADER(m_pCaptureFilter->m_user.pvi)->biSizeImage = DIBSIZE(*HEADER(m_pCaptureFilter->m_user.pvi));
        }
        if (HEADER(m_pCaptureFilter->m_user.pvi)->biCompression == VIDEO_FORMAT_YVU9 && HEADER(m_pCaptureFilter->m_user.pvi)->biBitCount != 9)
        {
                DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s:   WARNING: Fixing broken bitmap info header!", _fx_));
                HEADER(m_pCaptureFilter->m_user.pvi)->biBitCount = 9;
                HEADER(m_pCaptureFilter->m_user.pvi)->biSizeImage = DIBSIZE(*HEADER(m_pCaptureFilter->m_user.pvi));
        }
        if (HEADER(m_pCaptureFilter->m_user.pvi)->biBitCount > 8 && HEADER(m_pCaptureFilter->m_user.pvi)->biClrUsed != 0)
        {
                // BOGUS cap is broken and doesn't reset num colours
                // WINNOV reports 256 colours of 24 bit YUV8 - scary!
                DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s:   WARNING: Fixing broken bitmap info header!", _fx_));
                HEADER(m_pCaptureFilter->m_user.pvi)->biClrUsed = 0;
        }

        // If we already have a pin, nuke it
        if (m_hKSPin)
                CloseHandle(m_hKSPin), m_hKSPin = NULL;

        // Connect to a new kernel streaming PIN.
        ZeroMemory(&DataConnect, sizeof(DATAPINCONNECT));
        DataConnect.Connect.PinId                                               = dwPinId;
        DataConnect.Connect.PinToHandle                                 = NULL;                                                         // no "connect to"
        DataConnect.Connect.Interface.Set                               = KSINTERFACESETID_Standard;
        DataConnect.Connect.Interface.Id                                = KSINTERFACE_STANDARD_STREAMING;       // STREAMING
        DataConnect.Connect.Medium.Set                                  = KSMEDIUMSETID_Standard;
        DataConnect.Connect.Medium.Id                                   = KSMEDIUM_STANDARD_DEVIO;
        DataConnect.Connect.Priority.PriorityClass              = KSPRIORITY_NORMAL;
        DataConnect.Connect.Priority.PrioritySubClass   = 1;

        // @todo Allocate size for DATAPINCONNECT dynamically
        //dout("%s:   pSelDRVideo->DataRange.FormatSize = %lx \nsizeof(KS_DATARANGE_VIDEO_PALETTE) = %lx \nsizeof(KS_VIDEOINFO) = %lx \nsizeof(KS_DATAFORMAT_VIDEOINFO_PALETTE) = %lx\n",
        //        _fx_, pSelDRVideo->DataRange.FormatSize,sizeof(KS_DATARANGE_VIDEO_PALETTE),sizeof(KS_VIDEOINFO),sizeof(KS_DATAFORMAT_VIDEOINFO_PALETTE));
        ASSERT((pSelDRVideo->DataRange.FormatSize - (sizeof(KS_DATARANGE_VIDEO_PALETTE) - sizeof(KS_VIDEOINFO))) <= sizeof(KS_DATAFORMAT_VIDEOINFO_PALETTE));
        CopyMemory(&DataConnect.Data.DataFormat, &pSelDRVideo->DataRange, sizeof(KSDATARANGE));
        //dout("%s:   ##############::::::::: count bytes to copy: %ld\n", _fx_, pSelDRVideo->DataRange.FormatSize - (sizeof(KS_DATARANGE_VIDEO_PALETTE) - sizeof(KS_VIDEOINFO)));
        CopyMemory(&DataConnect.Data.VideoInfo, &pSelDRVideo->VideoInfoHeader, pSelDRVideo->DataRange.FormatSize - (sizeof(KS_DATARANGE_VIDEO_PALETTE) - sizeof(KS_VIDEOINFO)));
        DataConnect.Data.DataFormat.FormatSize = sizeof(KSDATARANGE) + pSelDRVideo->DataRange.FormatSize - (sizeof(KS_DATARANGE_VIDEO_PALETTE) - sizeof(KS_VIDEOINFO));
        //dout("%s:   DataConnect.Data.DataFormat.FormatSize = %lx\n", _fx_, DataConnect.Data.DataFormat.FormatSize);
        D(1) dprintf("DataConnect structure at %p\n",&DataConnect);
        D(1) DumpVIH((VIDEOINFOHEADER *)&DataConnect.Data.VideoInfo);
        D(1) DumpBMIH((PBITMAPINFOHEADER)&(((VIDEOINFOHEADER *)&DataConnect.Data.VideoInfo)->bmiHeader));

        D(1) dprintf("*********** initial bmih..... *****************\n");
        D(1) DumpBMIH(&bmih);

        // Adjust the image sizes if necessary
        if (fValidMatch)
        {
                DataConnect.Data.VideoInfo.bmiHeader.biWidth            = bmih.biWidth;
                DataConnect.Data.VideoInfo.bmiHeader.biHeight           = abs(bmih.biHeight); // Support only +biHeight!
                // The Kodak DVC 323 returns a bogus value for the image size
                // in YVU9 mode and won't work with the correct value... so leave
                // it that way.
                // DataConnect.Data.VideoInfo.bmiHeader.biSizeImage     = bmih.biSizeImage;
                m_pCaptureFilter->m_user.pvi->bmiHeader.biWidth     = bmih.biWidth;
                m_pCaptureFilter->m_user.pvi->bmiHeader.biHeight    = abs(bmih.biHeight);
                m_pCaptureFilter->m_user.pvi->bmiHeader.biSizeImage = bmih.biSizeImage;
                dprintf("W > > > > Adjusted : (bmih.) biWidth = %ld, biHeight = %ld, biCompression = '%.4s'\n", bmih.biWidth, bmih.biHeight, &bmih.biCompression);
        }
        // @todo Read this from somewhere
        if (m_pCaptureFilter->m_pCapturePin && m_pCaptureFilter->m_pCapturePin->m_lAvgTimePerFrameRangeDefault) {
                //dprintf("... %s: :max of next 2:\n\t\tDataConnect.Data.VideoInfo.AvgTimePerFrame = %I64u\t\n\nm_pCaptureFilter->m_pCapturePin->m_lAvgTimePerFrameRangeDefault = %lu\n",
                //        _fx_, DataConnect.Data.VideoInfo.AvgTimePerFrame,m_pCaptureFilter->m_pCapturePin->m_lAvgTimePerFrameRangeDefault);

                //** AvgTimePerFrame = max(DataConnect.Data.VideoInfo.AvgTimePerFrame, m_pCaptureFilter->m_pCapturePin->m_lAvgTimePerFrameRangeDefault);

                AvgTimePerFrame = max(DataConnect.Data.VideoInfo.AvgTimePerFrame, AvgTimePerFrame);

                if(AvgTimePerFrame > pSelDRVideo->ConfigCaps.MaxFrameInterval)
                                AvgTimePerFrame = pSelDRVideo->ConfigCaps.MaxFrameInterval;
                if(AvgTimePerFrame < pSelDRVideo->ConfigCaps.MinFrameInterval)
                                AvgTimePerFrame = pSelDRVideo->ConfigCaps.MinFrameInterval;
                m_pCaptureFilter->m_user.pvi->AvgTimePerFrame = DataConnect.Data.VideoInfo.AvgTimePerFrame
                                 = AvgTimePerFrame;
                D(1) dprintf(".... %s:result is     : m_pCaptureFilter->m_user.pvi->AvgTimePerFrame = DataConnect.Data.VideoInfo.AvgTimePerFrame =\n\t\t\t\t\t%I64u\n",        _fx_, DataConnect.Data.VideoInfo.AvgTimePerFrame);
        }
        //if(DataConnect.Data.VideoInfo.AvgTimePerFrame >= 1666665) DebugBreak();
#ifdef DEBUG
    *((DWORD*)&szFourCC) = DataConnect.Data.VideoInfo.bmiHeader.biCompression;
        if (m_pCaptureFilter->m_pCapturePin && m_pCaptureFilter->m_pCapturePin->m_lAvgTimePerFrameRangeDefault)
                DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s:   Requesting format FourCC(%.4s) %d * %d pixels, %d bytes per frame, %ld.%ldfps",
                        _fx_, szFourCC, DataConnect.Data.VideoInfo.bmiHeader.biWidth, DataConnect.Data.VideoInfo.bmiHeader.biHeight,
                        DataConnect.Data.VideoInfo.bmiHeader.biSizeImage,
                        10000000/m_pCaptureFilter->m_pCapturePin->m_lAvgTimePerFrameRangeDefault,
                        1000000000/m_pCaptureFilter->m_pCapturePin->m_lAvgTimePerFrameRangeDefault
                                - (10000000/m_pCaptureFilter->m_pCapturePin->m_lAvgTimePerFrameRangeDefault) * 100));
        else
                DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s:   Requesting format FourCC(%.4s) %d * %d pixels, %d bytes per frame, 0fps", _fx_, szFourCC, DataConnect.Data.VideoInfo.bmiHeader.biWidth, DataConnect.Data.VideoInfo.bmiHeader.biHeight, DataConnect.Data.VideoInfo.bmiHeader.biSizeImage));
        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s:   m_hKSPin was=0x%08lX...", _fx_, m_hKSPin));
#endif

        dwErr = (*m_pKsCreatePin)(m_hDriver, (PKSPIN_CONNECT)&DataConnect, GENERIC_READ | GENERIC_WRITE, &m_hKSPin);

        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s:   ...m_hKSPin is now=0x%08lX", _fx_, m_hKSPin));

        if (dwErr || (m_hKSPin == NULL))
        {
        // dwErr is an NtCreateFile error
                DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s:   ERROR: KsCreatePin returned 0x%08lX failure and m_hKSPin=0x%08lX", _fx_, dwErr, m_hKSPin));

                if (m_hKSPin == INVALID_HANDLE_VALUE)
                {
                        m_hKSPin = NULL;
                }

        // return error
        Hr = E_FAIL;

                goto MyExit;
        }

        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s:   SUCCESS: Setting %dx%d at %ld fps", _fx_, biWidth, biHeight, (LONG)AvgTimePerFrame));

MyExit:
        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: end", _fx_));
        return Hr;
}

/****************************************************************************
 *  @doc INTERNAL CWDMCAPDEVMETHOD
 *
 *  @mfunc HRESULT | CWDMCapDev | GetFormatFromDriver | This method is used to
 *    retrieve the WDM capture device format in use.
 *
 *  @parm VIDEOINFOHEADER ** | ppvi | Specifies the address of a pointer to
 *    a video info header structure to receive the video format description.
 *
 *  @rdesc This method returns an HRESULT value that depends on the
 *    implementation of the interface. HRESULT can include one of the
 *    following standard constants, or other values not listed:
 *
 *  @flag E_FAIL | Failure
 *  @flag NOERROR | No error
 ***************************************************************************/
HRESULT CWDMCapDev::GetFormatFromDriver(VIDEOINFOHEADER **ppvi)
{
        HRESULT                         Hr = NOERROR;
        UINT                            cb;
        BOOL                            fValidMatch;
        PKS_DATARANGE_VIDEO pSelDRVideo;

        FX_ENTRY("CWDMCapDev::GetFormatFromDriver")

        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: begin", _fx_));

        // Validate input parameters
        ASSERT(ppvi);
        if (!ppvi)
        {
                DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: Invalid input parameter!", _fx_));
                Hr = E_INVALIDARG;
                goto MyExit;
        }

        if (m_pCaptureFilter->m_user.pvi)
        {
                // Allocate space for a videoinfo that will hold it
                cb = sizeof(VIDEOINFOHEADER) + HEADER(m_pCaptureFilter->m_user.pvi)->biSize - sizeof(BITMAPINFOHEADER);
                if (HEADER(m_pCaptureFilter->m_user.pvi)->biBitCount == 8 && HEADER(m_pCaptureFilter->m_user.pvi)->biCompression == BI_RGB)
                        cb += sizeof(RGBQUAD) * 256;    // space for PALETTE or BITFIELDS
                else if (HEADER(m_pCaptureFilter->m_user.pvi)->biBitCount == 4 && HEADER(m_pCaptureFilter->m_user.pvi)->biCompression == BI_RGB)
                        cb += sizeof(RGBQUAD) * 16;         // space for PALETTE or BITFIELDS
                if (!(*ppvi = (VIDEOINFOHEADER *)(new BYTE[cb])))
                {
                        DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: Out of memory!", _fx_));
                        Hr = E_OUTOFMEMORY;
                        goto MyExit;
                }

                // Copy the current format
                CopyMemory(*ppvi, m_pCaptureFilter->m_user.pvi, cb);
                D(1) dprintf("W existing from m_pCaptureFilter->m_user.pvi:\n");
                D(1) DumpVIH(*ppvi);
        }
        else
        {
                // Get the default format from the driver
                if (FAILED(Hr = FindMatchDataRangeVideo(NULL, 0L, &fValidMatch, &pSelDRVideo)))
                {
                        DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: FindMatchDataRangeVideo failed!", _fx_));
                        goto MyExit;
                }

                // Allocate space for a videoinfo that will hold it
                cb = sizeof(VIDEOINFOHEADER) + pSelDRVideo->VideoInfoHeader.bmiHeader.biSize - sizeof(BITMAPINFOHEADER);
                if (pSelDRVideo->VideoInfoHeader.bmiHeader.biBitCount == 8 && pSelDRVideo->VideoInfoHeader.bmiHeader.biCompression == BI_RGB)
                        cb += sizeof(RGBQUAD) * 256;    // space for PALETTE or BITFIELDS
                else if (pSelDRVideo->VideoInfoHeader.bmiHeader.biBitCount == 4 && pSelDRVideo->VideoInfoHeader.bmiHeader.biCompression == BI_RGB)
                        cb += sizeof(RGBQUAD) * 16;     // space for PALETTE or BITFIELDS
                if (!(*ppvi = (VIDEOINFOHEADER *)(new BYTE[cb])))
                {
                        DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: Out of memory!", _fx_));
                        Hr = E_OUTOFMEMORY;
                        goto MyExit;
                }

                // Copy the default foramt
                CopyMemory(*ppvi, &pSelDRVideo->VideoInfoHeader, cb);
#ifdef DEVICEW_DEBUG
                {
                    PBITMAPINFOHEADER pbInfo;
                    D(1) dprintf("W FindMatchDataRangeVideo:\n");
                    D(1) DumpVIH(*ppvi);
                    D(1) pbInfo = &((*ppvi)->bmiHeader);
                    D(1) dprintf("%s :\n", _fx_);
                    D(1) dumpfield(BITMAPINFOHEADER,pbInfo, biHeight,      "%ld");
                    D(1) dprintf("\t+0x%03x %-17s : %08x '%.4s'\n", FIELDOFFSET(BITMAPINFOHEADER, biCompression), "biCompression", (pbInfo)->biCompression, &((pbInfo)->biCompression));
                    D(1) ASSERT(pbInfo->biHeight > 0);
                }
#endif
                // Fix broken bitmap info headers
                if ((*ppvi)->bmiHeader.biSizeImage == 0 && ((*ppvi)->bmiHeader.biCompression == BI_RGB || (*ppvi)->bmiHeader.biCompression == BI_BITFIELDS))
                {
                        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s:   WARNING: Fixing broken bitmap info header!", _fx_));
                        (*ppvi)->bmiHeader.biSizeImage = DIBSIZE((*ppvi)->bmiHeader);
                }
                if ((*ppvi)->bmiHeader.biCompression == VIDEO_FORMAT_YVU9 && (*ppvi)->bmiHeader.biBitCount != 9)
                {
                        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s:   WARNING: Fixing broken bitmap info header!", _fx_));
                        (*ppvi)->bmiHeader.biBitCount = 9;
                        (*ppvi)->bmiHeader.biSizeImage = DIBSIZE((*ppvi)->bmiHeader);
                }
                if ((*ppvi)->bmiHeader.biBitCount > 8 && (*ppvi)->bmiHeader.biClrUsed != 0)
                {
                        // BOGUS cap is broken and doesn't reset num colours
                        // WINNOV reports 256 colours of 24 bit YUV8 - scary!
                        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s:   WARNING: Fixing broken bitmap info header!", _fx_));
                        (*ppvi)->bmiHeader.biClrUsed = 0;
                }
        }


MyExit:
        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: end", _fx_));
        return Hr;
}

/****************************************************************************
 *  @doc INTERNAL CWDMCAPDEVMETHOD
 *
 *  @mfunc HRESULT | CWDMCapDev | InitializeStreaming | This method is used to
 *    initialize a WDM capture device for streaming.
 *
 *  @parm DWORD | usPerFrame | Specifies the frame rate to be used.
 *
 *  @parm DWORD_PTR | hEvtBufferDone | Specifies a handle to the event to be
 *    signaled whenever a frame is available.
 *
 *  @rdesc This method returns an HRESULT value that depends on the
 *    implementation of the interface. HRESULT can include one of the
 *    following standard constants, or other values not listed:
 *
 *  @flag E_FAIL | Failure
 *  @flag E_INVALIDARG | Invalid argument
 *  @flag NOERROR | No error
 ***************************************************************************/
HRESULT CWDMCapDev::InitializeStreaming(DWORD usPerFrame, DWORD_PTR hEvtBufferDone)
{
        HRESULT Hr = NOERROR;
    ULONG       i;

        FX_ENTRY("CWDMCapDev::InitializeStreaming")

        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: begin", _fx_));

        // Initialize data memmbers
        if (!m_dwStreamingMode || (m_dwStreamingMode == FRAME_GRAB_LARGE_SIZE && m_pCaptureFilter->m_user.pvi->bmiHeader.biHeight < 240 && m_pCaptureFilter->m_user.pvi->bmiHeader.biWidth < 320))
        {
                // Validate input parameters
                ASSERT(hEvtBufferDone);
                if (!hEvtBufferDone)
                {
                        DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: Invalid hEvtBufferDone!", _fx_));
                        Hr = E_INVALIDARG;
                        goto MyExit;
                }

                m_fVideoOpen            = TRUE;
                DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: Creating %d read video buffers", _fx_, m_cntNumVidBuf));

        if (m_pWDMVideoBuff) delete [] m_pWDMVideoBuff;

                if (!(m_pWDMVideoBuff = (WDMVIDEOBUFF *) new WDMVIDEOBUFF[m_cntNumVidBuf]))
                {
                        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: m_pWDMVideoBuff allocation failed!", _fx_));
                        Hr = E_OUTOFMEMORY;
                        goto MyError;
                }

                for(i=0; i<m_cntNumVidBuf; i++)
                {
                        // Create the overlapped structures
                        ZeroMemory(&(m_pWDMVideoBuff[i].Overlap), sizeof(OVERLAPPED));
                        m_pWDMVideoBuff[i].Overlap.hEvent = (HANDLE)hEvtBufferDone;
                        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: Event %d is handle 0x%08lX", _fx_, i, m_pWDMVideoBuff[i].Overlap.hEvent));
                }
        }

        goto MyExit;

MyError:
        m_fVideoOpen = FALSE;
MyExit:
        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: end", _fx_));
        return Hr;
}

/****************************************************************************
 *  @doc INTERNAL CWDMCAPDEVMETHOD
 *
 *  @mfunc LPVIDEOHDR | CWDMCapDev | DeQueueHeader | This function dequeues a
 *    video buffer from the list of video buffers used for streaming.
 *
 *  @rdesc Returns a valid pointer if successful, or NULL otherwise.
 ***************************************************************************/
LPVIDEOHDR CWDMCapDev::DeQueueHeader()
{
    LPVIDEOHDR lpVHdr;

        FX_ENTRY("CWDMCapDev::DeQueueHeader");

    lpVHdr = m_lpVHdrFirst;

    if (lpVHdr)
        {
        lpVHdr->dwFlags &= ~VHDR_INQUEUE;

        m_lpVHdrFirst = (LPVIDEOHDR)(lpVHdr->dwReserved[0]);

        if (m_lpVHdrFirst == NULL)
            m_lpVHdrLast = NULL;
    }

    return lpVHdr;
}

/****************************************************************************
 *  @doc INTERNAL CWDMCAPDEVMETHOD
 *
 *  @mfunc void | CWDMCapDev | QueueHeader | This function actually adds the
 *    video buffer to the list of video buffers used for streaming.
 *
 *  @parm LPVIDEOHDR | lpVHdr | Pointer to a <t VIDEOHDR> structure describing
 *    a video buffer to add to the list of streaming buffers.
 ***************************************************************************/
void CWDMCapDev::QueueHeader(LPVIDEOHDR lpVHdr)
{
        FX_ENTRY("CWDMCapDev::QueueHeader");
        // Initialize status flags
    lpVHdr->dwFlags &= ~VHDR_DONE;
    lpVHdr->dwFlags |= VHDR_INQUEUE;
    lpVHdr->dwBytesUsed = 0;

        *(lpVHdr->dwReserved) = NULL;

        if (m_lpVHdrLast)
                *(m_lpVHdrLast->dwReserved) = (DWORD)(LPVOID)lpVHdr;
        else
                m_lpVHdrFirst = lpVHdr;

        m_lpVHdrLast = lpVHdr;
}

/****************************************************************************
 *  @doc INTERNAL CWDMCAPDEVMETHOD
 *
 *  @mfunc BOOL | CWDMCapDev | QueueRead | This function queues a read
 *    operation on a video streaming pin.
 *
 *  @parm DWORD | dwIndex | Index of the video structure in read buffer.
 *
 *  @rdesc Returns TRUE if successful, or FALSE otherwise.
 ***************************************************************************/
BOOL CWDMCapDev::QueueRead(DWORD dwIndex)
{
        FX_ENTRY("CWDMCapDev::QueueRead");

        DWORD cbReturned;
        BOOL  bShouldBlock = FALSE;
#if defined(DEBUG) && defined(DEBUG_STREAMING)
        // @todo Remove this before checkin!
        char szDebug[512];
#endif

        //DBGOUT((g_dwVideoCaptureTraceID, TRCE, TEXT("%s: Queue read buffer %d on pin handle 0x%08lX"), _fx_, dwIndex, m_hKSPin));

        // Get a buffer from the queue of video buffers
        m_pWDMVideoBuff[dwIndex].pVideoHdr = DeQueueHeader();
#if defined(DEBUG) && defined(DEBUG_STREAMING)
        wsprintf(szDebug, "Queueing m_pWDMVideoBuff[%ld].pVideoHdr=0x%08lX\n", dwIndex, m_pWDMVideoBuff[dwIndex].pVideoHdr);
        OutputDebugString(szDebug);
#endif

        if (m_pWDMVideoBuff[dwIndex].pVideoHdr)
        {
                ZeroMemory(&m_pWDMVideoBuff[dwIndex].SHGetImage, sizeof(m_pWDMVideoBuff[dwIndex].SHGetImage));
                m_pWDMVideoBuff[dwIndex].SHGetImage.StreamHeader.Size                   = sizeof (KS_HEADER_AND_INFO);
                m_pWDMVideoBuff[dwIndex].SHGetImage.FrameInfo.ExtendedHeaderSize        = sizeof (KS_FRAME_INFO);
                m_pWDMVideoBuff[dwIndex].SHGetImage.StreamHeader.Data                   = m_pWDMVideoBuff[dwIndex].pVideoHdr->lpData;
                m_pWDMVideoBuff[dwIndex].SHGetImage.StreamHeader.FrameExtent            = m_pWDMVideoBuff[dwIndex].pVideoHdr->dwBufferLength;

                // Submit the read
                BOOL bRet = ::DeviceIoControl(m_hKSPin, IOCTL_KS_READ_STREAM,  &m_pWDMVideoBuff[dwIndex].SHGetImage,
                                                                                sizeof(m_pWDMVideoBuff[dwIndex].SHGetImage),
                                                                               &m_pWDMVideoBuff[dwIndex].SHGetImage,
                                                                                sizeof(m_pWDMVideoBuff[dwIndex].SHGetImage),
                                                                               &cbReturned,
                                                                               &m_pWDMVideoBuff[dwIndex].Overlap);

                if (!bRet)
                {
                        DWORD dwErr = GetLastError();
                        switch(dwErr)
                        {
                                case ERROR_IO_PENDING:
                                        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: An overlapped IO is going to take place", _fx_));
#if defined(DEBUG) && defined(DEBUG_STREAMING)
                                        OutputDebugString("An overlapped IO is going to take place\n");
#endif
                                        bShouldBlock = TRUE;
                                        break;

                                // Something bad happened
                                default:
                                        DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s: DeviceIoControl() failed badly dwErr=%d", _fx_, dwErr));
#if defined(DEBUG) && defined(DEBUG_STREAMING)
                                        wsprintf(szDebug, "DeviceIoControl() failed badly dwErr=%d\n",dwErr);
                                        OutputDebugString(szDebug);
#endif
                                        break;
                        }
                }
                else
                {
                        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: Overlapped IO won't take place - no need to wait", _fx_));
#if defined(DEBUG) && defined(DEBUG_STREAMING)
                        OutputDebugString("Overlapped IO won't take place - no need to wait\n");
#endif
                        SetEvent(m_pWDMVideoBuff[dwIndex].Overlap.hEvent);
                }
        }
        else
        {
                DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: We won't queue the read - no buffer available", _fx_));
#if defined(DEBUG) && defined(DEBUG_STREAMING)
                OutputDebugString("We won't queue the read - no buffer available\n");
#endif
        }

        m_pWDMVideoBuff[dwIndex].fBlocking = bShouldBlock;

        return bShouldBlock;
}

/****************************************************************************
 *  @doc INTERNAL CWDMCAPDEVMETHOD
 *
 *  @mfunc HRESULT | CWDMCapDev | StartStreaming | This method is used to
 *    start streaming from a VfW capture device.
 *
 *  @rdesc This method returns an HRESULT value that depends on the
 *    implementation of the interface. HRESULT can include one of the
 *    following standard constants, or other values not listed:
 *
 *  @flag E_FAIL | Failure
 *  @flag NOERROR | No error
 ***************************************************************************/
HRESULT CWDMCapDev::StartStreaming()
{
        HRESULT Hr = NOERROR;

        FX_ENTRY("CWDMCapDev::StartStreaming")

        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: begin", _fx_));

        //LOG_MSG_VAL(_fx_,(DWORD)this,0,0);

        if (!m_dwStreamingMode || (m_dwStreamingMode == FRAME_GRAB_LARGE_SIZE && m_pCaptureFilter->m_user.pvi->bmiHeader.biHeight < 240 && m_pCaptureFilter->m_user.pvi->bmiHeader.biWidth < 320))
        {
                // Validate input parameters
                ASSERT(m_fVideoOpen);
                if (!m_fVideoOpen)
                {
                        DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: InitializeStreaming() needs to be called first!", _fx_));
                        Hr = E_UNEXPECTED;
                        goto MyExit;
                }

                DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: Streaming in %d video buffers", _fx_, m_cntNumVidBuf));

                // Put the pin in streaming mode
                if (!Start())
            {
                    DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: Cannot set kernel streaming state to KSSTATE_RUN!", _fx_));
                    Hr = E_FAIL;
                    goto MyExit;
            }

                // Send the buffers to the driver
                for (DWORD i = 0; i < m_pCaptureFilter->m_cs.nHeaders; ++i)
                {
                        ASSERT (m_pCaptureFilter->m_cs.cbVidHdr >= sizeof(VIDEOHDR));
                        if (FAILED(AddBuffer(&m_pCaptureFilter->m_cs.paHdr[i].tvh.vh, m_pCaptureFilter->m_cs.cbVidHdr)))
                        {
                                DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: AddBuffer failed", _fx_));
                                Hr = E_FAIL;
                                goto MyExit;
                        }
                }
        }
        //LOG_MSG_VAL(_fx_,(DWORD)this,0,1);

MyExit:
        //LOG_MSG_VAL(_fx_,(DWORD)this,0,0xffff);

        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: end", _fx_));
        return Hr;
}

/****************************************************************************
 *  @doc INTERNAL CWDMCAPDEVMETHOD
 *
 *  @mfunc HRESULT | CWDMCapDev | StopStreaming | This method is used to
 *    stop streaming from a VfW capture device.
 *
 *  @rdesc This method returns an HRESULT value that depends on the
 *    implementation of the interface. HRESULT can include one of the
 *    following standard constants, or other values not listed:
 *
 *  @flag E_FAIL | Failure
 *  @flag NOERROR | No error
 ***************************************************************************/
HRESULT CWDMCapDev::StopStreaming()
{
        HRESULT Hr = NOERROR;

        FX_ENTRY("CWDMCapDev::StopStreaming")

        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: begin", _fx_));

        if (!m_dwStreamingMode || (m_dwStreamingMode == FRAME_GRAB_LARGE_SIZE && m_pCaptureFilter->m_user.pvi->bmiHeader.biHeight < 240 && m_pCaptureFilter->m_user.pvi->bmiHeader.biWidth < 320))
        {
                // Validate input parameters
                ASSERT(m_fVideoOpen);
                if (!m_fVideoOpen)
                {
                        DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: Stream is not even open!", _fx_));
                        Hr = E_UNEXPECTED;
                        goto MyExit;
                }
        }

        if (!Stop())
    {
            DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: Cannot set kernel streaming state to KSSTATE_PAUSE/KSSTATE_STOP!", _fx_));
            Hr = E_FAIL;
    }





MyExit:
        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: end", _fx_));
        return Hr;
}

/****************************************************************************
 *  @doc INTERNAL CWDMCAPDEVMETHOD
 *
 *  @mfunc HRESULT | CWDMCapDev | TerminateStreaming | This method is used to
 *    tell a WDM capture device to terminate streaming.
 *
 *  @rdesc This method returns an HRESULT value that depends on the
 *    implementation of the interface. HRESULT can include one of the
 *    following standard constants, or other values not listed:
 *
 *  @flag E_FAIL | Failure
 *  @flag NOERROR | No error
 ***************************************************************************/
HRESULT CWDMCapDev::TerminateStreaming()
{
        HRESULT Hr = NOERROR;

        FX_ENTRY("CWDMCapDev::TerminateStreaming")

        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: begin", _fx_));

        //LOG_MSG_VAL(_fx_,(DWORD)this,0,0);

        if (!m_dwStreamingMode || (m_dwStreamingMode == FRAME_GRAB_LARGE_SIZE && m_pCaptureFilter->m_user.pvi->bmiHeader.biHeight < 240 && m_pCaptureFilter->m_user.pvi->bmiHeader.biWidth < 320))
        {
                // Validate input parameters
                ASSERT(m_fVideoOpen);
                if (!m_fVideoOpen)
                {
                        DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: Stream is not even open!", _fx_));
                        Hr = E_UNEXPECTED;
                        goto MyExit;
                }

                // Ask the pin to stop streaming.
                if (!Stop())
            {
                    DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: Cannot set kernel streaming state to KSSTATE_PAUSE/KSSTATE_STOP!", _fx_));
                    Hr = E_FAIL;
                    goto MyExit;
            }

        CLEAR_GetOvResErr;

        DWORD dwNum;
        DWORD dwErr;

                for (UINT i=0; i<m_cntNumVidBuf; i++)
                {
                SET_GetOvResErr(i,0);
                SET_I(savi,i);
                if (m_pWDMVideoBuff!=NULL && m_pWDMVideoBuff[i].Overlap.hEvent)
                {
                        DWORD dwStartTime = timeGetTime();
                        SET_GetOvResErr(i,0x30787878);
                        //LOG_MSG_VAL(_fx_,(DWORD)this,i,0x10);

                        // we don't want to wait for the event, 'cause it has been shared.
                        while (!GetOverlappedResult (
                                m_hDriver,
                                &m_pWDMVideoBuff[i].Overlap,
                                &dwNum,
                                FALSE))
                              {
                                  dwErr = GetLastError ();
                                  SET_GetOvResErr(i,dwErr);

                                  if (dwErr == ERROR_OPERATION_ABORTED)
                                  {
                                      // expected
                                      break;
                                  }
                                  else if (dwErr == ERROR_IO_INCOMPLETE)
                                  {
                                      SleepEx (10, TRUE);
                                  }
                                  else if (dwErr == ERROR_IO_PENDING)
                                  {
                                      // should not happen
                                      DBGOUT((g_dwVideoCaptureTraceID, FAIL,
                                              "%s: failed to get overlapped result. error: io pending", _fx_));

                                      SleepEx (10, TRUE);
                                  }
                                  else
                                  {
                                      DBGOUT((g_dwVideoCaptureTraceID, FAIL,
                                              "%s: failed to get overlapped result. error: %d",
                                              _fx_, dwErr));

                                      SleepEx (10, TRUE);

                                      // should we break? [YES (cristiai; 09/15/2000; see bug 183855)]
                                      break;
                                  }

                                  // issue: this is a temporary solution to make sure we won't loop infinitely
                                  // we don't trust SDK documents all possible return values from
                                  // GetOverlappedResult
                                  //
                                  if (timeGetTime() - dwStartTime > 10000)
                                  {
                                          SET_GetOvResErr(i,0x31787878);
#if defined(DBG)
                                          DebugBreak();          // The driver has a problem.
#else
                                          break;
#endif
                                  }
                        }

                        // WaitForSingleObject (m_pWDMVideoBuff[i].Overlap.hEvent, INFINITE);
                                        SetEvent(m_pWDMVideoBuff[i].Overlap.hEvent);
                                        // CloseHandle(m_pWDMVideoBuff[i].Overlap.hEvent);
                                        m_pWDMVideoBuff[i].Overlap.hEvent = NULL;
                        }
                }

#if EARLYDELETE
        if (m_pWDMVideoBuff)
                {
                        delete []m_pWDMVideoBuff;
                        m_pWDMVideoBuff = (WDMVIDEOBUFF *)NULL;
                }
#endif

                //LOG_MSG_VAL("CWDMCapDev::TerminateStreaming m_lpVHdr... are made NULL",(DWORD)this,0,0);
                m_lpVHdrFirst = NULL;
                m_lpVHdrLast = NULL;
        }
        //LOG_MSG_VAL(_fx_,(DWORD)this,0,1);

MyExit:
        //LOG_MSG_VAL(_fx_,(DWORD)this,0,0xffff);

        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: end", _fx_));
        return Hr;
}

#if defined(DBG)
void DumpDataRangeVideo(PKS_DATARANGE_VIDEO     pDRVideo)
{
        FX_ENTRY("DumpDataRangeVideo");

        dout(1,g_dwVideoCaptureTraceID, TRCE, "%s: begin", _fx_);

        dout(1,g_dwVideoCaptureTraceID, TRCE, "%s: Video datarange pDRVideo %p:", _fx_, pDRVideo);
        dout(1,g_dwVideoCaptureTraceID, TRCE, "%s:   pDRVideo->DataRange.FormatSize=%ld", _fx_, pDRVideo->DataRange.FormatSize);
        dout(1,g_dwVideoCaptureTraceID, TRCE, "%s:   pDRVideo->DataRange.Flags=%ld", _fx_, pDRVideo->DataRange.Flags);
        dout(1,g_dwVideoCaptureTraceID, TRCE, "%s:   pDRVideo->DataRange.SampleSize=%ld", _fx_, pDRVideo->DataRange.SampleSize);
        dout(1,g_dwVideoCaptureTraceID, TRCE, "%s:   pDRVideo->DataRange.Reserved=%ld", _fx_, pDRVideo->DataRange.Reserved);
        dout(1,g_dwVideoCaptureTraceID, TRCE, "%s:   pDRVideo->DataRange.MajorFormat=0x%lX", _fx_, pDRVideo->DataRange.MajorFormat);
        dout(1,g_dwVideoCaptureTraceID, TRCE, "%s:   pDRVideo->DataRange.SubFormat=0x%lX", _fx_, pDRVideo->DataRange.SubFormat);
        dout(1,g_dwVideoCaptureTraceID, TRCE, "%s:   pDRVideo->DataRange.Specifier=KSDATAFORMAT_SPECIFIER_VIDEOINFO", _fx_);
        dout(1,g_dwVideoCaptureTraceID, TRCE, "%s:   pDRVideo->bFixedSizeSamples=%ld", _fx_, pDRVideo->bFixedSizeSamples);
        dout(1,g_dwVideoCaptureTraceID, TRCE, "%s:   pDRVideo->bTemporalCompression=%ld", _fx_, pDRVideo->bTemporalCompression);
        dout(1,g_dwVideoCaptureTraceID, TRCE, "%s:   pDRVideo->StreamDescriptionFlags=0x%lX", _fx_, pDRVideo->StreamDescriptionFlags);
        dout(1,g_dwVideoCaptureTraceID, TRCE, "%s:   pDRVideo->MemoryAllocationFlags=0x%lX", _fx_, pDRVideo->MemoryAllocationFlags);
        dout(1,g_dwVideoCaptureTraceID, TRCE, "%s:   pDRVideo->ConfigCaps.VideoStandard=KS_AnalogVideo_None", _fx_);
        dout(1,g_dwVideoCaptureTraceID, TRCE, "%s:   pDRVideo->ConfigCaps.InputSize(cx=%ld, cy=%ld)", _fx_, pDRVideo->ConfigCaps.InputSize.cx, pDRVideo->ConfigCaps.InputSize.cy);
        dout(1,g_dwVideoCaptureTraceID, TRCE, "%s:   pDRVideo->ConfigCaps.MinCroppingSize(cx=%ld, cy=%ld)", _fx_, pDRVideo->ConfigCaps.MinCroppingSize.cx, pDRVideo->ConfigCaps.MinCroppingSize.cy);
        dout(1,g_dwVideoCaptureTraceID, TRCE, "%s:   pDRVideo->ConfigCaps.MaxCroppingSize(cx=%ld, cy=%ld)", _fx_, pDRVideo->ConfigCaps.MaxCroppingSize.cx, pDRVideo->ConfigCaps.MaxCroppingSize.cy);
        dout(1,g_dwVideoCaptureTraceID, TRCE, "%s:   pDRVideo->ConfigCaps.CropGranularityX=%ld", _fx_, pDRVideo->ConfigCaps.CropGranularityY);
        dout(1,g_dwVideoCaptureTraceID, TRCE, "%s:   pDRVideo->ConfigCaps.CropGranularityY=%ld", _fx_, pDRVideo->ConfigCaps.CropGranularityY);
        dout(1,g_dwVideoCaptureTraceID, TRCE, "%s:   pDRVideo->ConfigCaps.CropAlignX=%ld", _fx_, pDRVideo->ConfigCaps.CropAlignX);
        dout(1,g_dwVideoCaptureTraceID, TRCE, "%s:   pDRVideo->ConfigCaps.CropAlignY=%ld", _fx_, pDRVideo->ConfigCaps.CropAlignY);
        dout(1,g_dwVideoCaptureTraceID, TRCE, "%s:   pDRVideo->ConfigCaps.MinOutputSize(cx=%ld, cy=%ld)", _fx_, pDRVideo->ConfigCaps.MinOutputSize.cx, pDRVideo->ConfigCaps.MinOutputSize.cy);
        dout(1,g_dwVideoCaptureTraceID, TRCE, "%s:   pDRVideo->ConfigCaps.MaxOutputSize(cx=%ld, cy=%ld)", _fx_, pDRVideo->ConfigCaps.MaxOutputSize.cx, pDRVideo->ConfigCaps.MaxOutputSize.cy);
        dout(1,g_dwVideoCaptureTraceID, TRCE, "%s:   pDRVideo->ConfigCaps.OutputGranularityX=%ld", _fx_, pDRVideo->ConfigCaps.OutputGranularityX);
        dout(1,g_dwVideoCaptureTraceID, TRCE, "%s:   pDRVideo->ConfigCaps.OutputGranularityY=%ld", _fx_, pDRVideo->ConfigCaps.OutputGranularityY);
        dout(1,g_dwVideoCaptureTraceID, TRCE, "%s:   pDRVideo->ConfigCaps.StretchTapsX=%ld", _fx_, pDRVideo->ConfigCaps.StretchTapsX);
        dout(1,g_dwVideoCaptureTraceID, TRCE, "%s:   pDRVideo->ConfigCaps.StretchTapsY=%ld", _fx_, pDRVideo->ConfigCaps.StretchTapsY);
        dout(1,g_dwVideoCaptureTraceID, TRCE, "%s:   pDRVideo->ConfigCaps.ShrinkTapsX=%ld", _fx_, pDRVideo->ConfigCaps.ShrinkTapsX);
        dout(1,g_dwVideoCaptureTraceID, TRCE, "%s:   pDRVideo->ConfigCaps.ShrinkTapsY=%ld", _fx_, pDRVideo->ConfigCaps.ShrinkTapsY);
        dout(1,g_dwVideoCaptureTraceID, TRCE, "%s:   pDRVideo->ConfigCaps.MinFrameInterval=%ld", _fx_, (DWORD)pDRVideo->ConfigCaps.MinFrameInterval);
        dout(1,g_dwVideoCaptureTraceID, TRCE, "%s:   pDRVideo->ConfigCaps.MaxFrameInterval=%ld", _fx_, (DWORD)pDRVideo->ConfigCaps.MaxFrameInterval);
        dout(1,g_dwVideoCaptureTraceID, TRCE, "%s:   pDRVideo->ConfigCaps.MinBitsPerSecond=%ld", _fx_, pDRVideo->ConfigCaps.MinBitsPerSecond);
        dout(1,g_dwVideoCaptureTraceID, TRCE, "%s:   pDRVideo->ConfigCaps.MaxBitsPerSecond=%ld", _fx_, pDRVideo->ConfigCaps.MaxBitsPerSecond);
        dout(1,g_dwVideoCaptureTraceID, TRCE, "%s:   pDRVideo->VideoInfoHeader.rcSource(left=%ld, top=%ld, right=%ld, bottom=%ld)", _fx_, pDRVideo->VideoInfoHeader.rcSource.left, pDRVideo->VideoInfoHeader.rcSource.top, pDRVideo->VideoInfoHeader.rcSource.right, pDRVideo->VideoInfoHeader.rcSource.bottom);
        dout(1,g_dwVideoCaptureTraceID, TRCE, "%s:   pDRVideo->VideoInfoHeader.rcTarget(left=%ld, top=%ld, right=%ld, bottom=%ld)", _fx_, pDRVideo->VideoInfoHeader.rcTarget.left, pDRVideo->VideoInfoHeader.rcTarget.top, pDRVideo->VideoInfoHeader.rcTarget.right, pDRVideo->VideoInfoHeader.rcTarget.bottom);
        dout(1,g_dwVideoCaptureTraceID, TRCE, "%s:   pDRVideo->VideoInfoHeader.dwBitRate=%ld", _fx_, pDRVideo->VideoInfoHeader.dwBitRate);
        dout(1,g_dwVideoCaptureTraceID, TRCE, "%s:   pDRVideo->VideoInfoHeader.dwBitErrorRate=%ld", _fx_, pDRVideo->VideoInfoHeader.dwBitErrorRate);
        dout(1,g_dwVideoCaptureTraceID, TRCE, "%s:   pDRVideo->VideoInfoHeader.AvgTimePerFrame=%ld", _fx_, (DWORD)pDRVideo->VideoInfoHeader.AvgTimePerFrame);
        dout(1,g_dwVideoCaptureTraceID, TRCE, "%s:   pDRVideo->VideoInfoHeader.bmiHeader.biSize=%ld", _fx_, (DWORD)pDRVideo->VideoInfoHeader.bmiHeader.biSize);
        dout(1,g_dwVideoCaptureTraceID, TRCE, "%s:   pDRVideo->VideoInfoHeader.bmiHeader.biWidth=%ld", _fx_, (DWORD)pDRVideo->VideoInfoHeader.bmiHeader.biWidth);
        dout(1,g_dwVideoCaptureTraceID, TRCE, "%s:   pDRVideo->VideoInfoHeader.bmiHeader.biHeight=%ld", _fx_, (DWORD)pDRVideo->VideoInfoHeader.bmiHeader.biHeight);
        dout(1,g_dwVideoCaptureTraceID, TRCE, "%s:   pDRVideo->VideoInfoHeader.bmiHeader.biPlanes=%ld", _fx_, (DWORD)pDRVideo->VideoInfoHeader.bmiHeader.biPlanes);
        dout(1,g_dwVideoCaptureTraceID, TRCE, "%s:   pDRVideo->VideoInfoHeader.bmiHeader.biBitCount=%ld", _fx_, (DWORD)pDRVideo->VideoInfoHeader.bmiHeader.biBitCount);
        dout(1,g_dwVideoCaptureTraceID, TRCE, "%s:   pDRVideo->VideoInfoHeader.bmiHeader.biCompression=%ld", _fx_, (DWORD)pDRVideo->VideoInfoHeader.bmiHeader.biCompression);
        dout(1,g_dwVideoCaptureTraceID, TRCE, "%s:   pDRVideo->VideoInfoHeader.bmiHeader.biSizeImage=%ld", _fx_, (DWORD)pDRVideo->VideoInfoHeader.bmiHeader.biSizeImage);
        dout(1,g_dwVideoCaptureTraceID, TRCE, "%s:   pDRVideo->VideoInfoHeader.bmiHeader.biClrUsed=%ld", _fx_, (DWORD)pDRVideo->VideoInfoHeader.bmiHeader.biClrUsed);
        dout(1,g_dwVideoCaptureTraceID, TRCE, "%s:   pDRVideo->VideoInfoHeader.bmiHeader.biClrImportant=%ld", _fx_, (DWORD)pDRVideo->VideoInfoHeader.bmiHeader.biClrImportant);

        dout(1,g_dwVideoCaptureTraceID, TRCE, "%s: end", _fx_);
        D(2) DebugBreak();
}
#endif


/****************************************************************************
 *  @doc INTERNAL CWDMCAPDEVMETHOD
 *
 *  @mfunc BOOL | CWDMCapDev | FindMatchDataRangeVideo | This method either
 *    finds a video data range compatible with the bitamp info header passed
 *    in, or the prefered video data range.
 *
 *  @parm PBITMAPINFOHEADER | pbiHdr | Bitmap info header to match.
 *
 *  @parm BOOL | pfValidMatch | Set to TRUE if a match was found, FALSE
 *    otherwise.
 *
 *  @rdesc Returns a valid pointer to a <t KS_DATARANGE_VIDEO> structure if
 *    successful, or a NULL pointer otherwise.
 *
 *  @comm \\redrum\slmro\proj\wdm10\src\dvd\amovie\proxy\filter\ksutil.cpp(207):KsGetMediaTypes(
 ***************************************************************************/
HRESULT CWDMCapDev::FindMatchDataRangeVideo(PBITMAPINFOHEADER pbiHdr, DWORD dwAvgTimePerFrame, BOOL *pfValidMatch, PKS_DATARANGE_VIDEO *ppSelDRVideo)
{
        HRESULT                         Hr = NOERROR;
        PVIDEO_DATA_RANGES      pDataRanges;
        PKS_DATARANGE_VIDEO     pDRVideo;
        PKS_DATARANGE_VIDEO     pFirstDRVideo;          // 1st usable data range
        PKS_DATARANGE_VIDEO     pFirstMatchDRVideo;     // 1st data range that fits requests
        PKS_DATARANGE_VIDEO     pMatchDRVideo;          // data range that matches requests *including* framerate (average time per frame)
        KS_BITMAPINFOHEADER     *pbInfo;
        DWORD                           i;
        long            deltamin=0x7fffffff;
        long            deltamax=0x7fffffff;

        FX_ENTRY("CWDMCapDev::FindMatchDataRangeVideo");

        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: begin", _fx_));

        // Validate input parameters
        ASSERT(pfValidMatch);
        ASSERT(ppSelDRVideo);
        if (!pfValidMatch || !ppSelDRVideo)
        {
                DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: Invalid input parameter!", _fx_));
                Hr = E_POINTER;
                goto MyExit;
        }

        // Defaults
        *pfValidMatch = FALSE;
        *ppSelDRVideo = NULL;

        // Get the list of formats supported by the device
        if (FAILED(Hr = GetDriverSupportedDataRanges(&pDataRanges)) || !pDataRanges)
        {
                DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: GetDriverSupportedDataRanges failed!", _fx_));
                goto MyExit;
        }

        // Walk the list of data ranges and find a match
        pDRVideo = &pDataRanges->Data;
        pFirstDRVideo = pFirstMatchDRVideo = pMatchDRVideo = NULL;
        for (i = 0; i < pDataRanges->Count; i++)
        {
                // Meaningless unless it is *_VIDEOINFO
                if (pDRVideo->DataRange.Specifier == KSDATAFORMAT_SPECIFIER_VIDEOINFO)
                {
                        // We don't care about TV Tuner like devices
                        if (pDRVideo->ConfigCaps.VideoStandard == KS_AnalogVideo_None)
                        {

                                DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s: data range #%ld (pbiHdr %p pDRVideo %p) .....", _fx_,i, pbiHdr, pDRVideo));
                                // Save first useable data range
                                if (!pFirstDRVideo)
                                {
                                        pFirstDRVideo = pDRVideo;
                                        if (!pbiHdr && dwAvgTimePerFrame == 0L) {
                                                pFirstMatchDRVideo = pMatchDRVideo = pDRVideo;
                                                dout(3,g_dwVideoCaptureTraceID, FAIL, "%s:   1st data range saved (pbiHdr %p)", _fx_,pbiHdr);
                                                D(2) DebugBreak();
                                                break;
                                                }
                                }

                                pbInfo = &((pDRVideo->VideoInfoHeader).bmiHeader);

                                D(1) dprintf("%s : pbInfo\n", _fx_);
                                D(1) dumpfield(BITMAPINFOHEADER,pbInfo, biHeight,      "%ld");
                                D(1) dprintf("\t+0x%03x %-17s : %08x '%.4s'\n", FIELDOFFSET(BITMAPINFOHEADER, biCompression), "biCompression", (pbInfo)->biCompression, &((pbInfo)->biCompression));
                                D(1) ASSERT(pbInfo->biHeight >0);
                                if (   (pbInfo->biBitCount == pbiHdr->biBitCount)
                                    && (pbInfo->biCompression == pbiHdr->biCompression)
                                    && (
                                         (
                                            ((pDRVideo->ConfigCaps.OutputGranularityX == 0) || (pDRVideo->ConfigCaps.OutputGranularityY == 0))
                                         && (pDRVideo->ConfigCaps.InputSize.cx == pbiHdr->biWidth)
                                         && (pDRVideo->ConfigCaps.InputSize.cy == pbiHdr->biHeight)
                                         ) ||
                                         (
                                            (pDRVideo->ConfigCaps.MinOutputSize.cx <= pbiHdr->biWidth)
                                         && (pbiHdr->biWidth <= pDRVideo->ConfigCaps.MaxOutputSize.cx)
                                         && (pDRVideo->ConfigCaps.MinOutputSize.cy <= pbiHdr->biHeight)
                                         && (pbiHdr->biHeight <= pDRVideo->ConfigCaps.MaxOutputSize.cy)
                                         && ((pbiHdr->biWidth % pDRVideo->ConfigCaps.OutputGranularityX) == 0)
                                         && ((pbiHdr->biHeight % pDRVideo->ConfigCaps.OutputGranularityY) == 0)
                                         )
                                       )
                                   )
                                {
                                        pFirstMatchDRVideo = pDRVideo;
                                        *pfValidMatch = TRUE;
                                        if(dwAvgTimePerFrame == 0L) {
                                                D(2) DumpDataRangeVideo(pDRVideo);
                                                break;
                                        }
                                        if((LONG)pDRVideo->ConfigCaps.MinFrameInterval <= (LONG)dwAvgTimePerFrame) {
                                           if((LONG)pDRVideo->ConfigCaps.MaxFrameInterval >= (LONG)dwAvgTimePerFrame) {
                                                pMatchDRVideo = pDRVideo;
                                                deltamin=deltamax=0;
                                           }
                                           else {
                                                if((LONG)dwAvgTimePerFrame - (LONG)pDRVideo->ConfigCaps.MaxFrameInterval < deltamax) {
                                                        deltamax = (LONG)dwAvgTimePerFrame - (LONG)pDRVideo->ConfigCaps.MaxFrameInterval;
                                                        if(deltamax < deltamin)
                                                                pMatchDRVideo = pDRVideo;
                                                        }
                                           }
                                        }
                                        else {
                                                if((LONG)pDRVideo->ConfigCaps.MinFrameInterval - (LONG)dwAvgTimePerFrame < deltamin) {
                                                        deltamin = (LONG)pDRVideo->ConfigCaps.MinFrameInterval - (LONG)dwAvgTimePerFrame;
                                                        if(deltamin < deltamax)
                                                                pMatchDRVideo = pDRVideo;
                                                        }
                                        }
                                        if(deltamin == 0 || deltamax == 0) {    // if we already found smth. good enough ...
                                                //*ppSelDRVideo = pDRVideo;
                                                DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: Match found #%d pDRVideo %p:", _fx_, i, pDRVideo));
                                                break;
                                        }
                                        // else keep lookin' ...
                                }
#if defined(ZZZ) // temporary no debug here ... lower noise
                                else {
                                        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: Video datarange #%ld: no match: below are conditions that failed", _fx_, i));
                                        if(!(pbInfo->biBitCount == pbiHdr->biBitCount))                          DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: %s", _fx_, "pbInfo->biBitCount == pbiHdr->biBitCount"));
                                        if(!(pbInfo->biCompression == pbiHdr->biCompression))                    DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: %s", _fx_, "pbInfo->biCompression == pbiHdr->biCompression"));
                                        if(!((pDRVideo->ConfigCaps.OutputGranularityX == 0) || (pDRVideo->ConfigCaps.OutputGranularityY == 0)))
                                                                                                                 DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: %s", _fx_, "(pDRVideo->ConfigCaps.OutputGranularityX == 0) || (pDRVideo->ConfigCaps.OutputGranularityY == 0)"));
                                        if(!(pDRVideo->ConfigCaps.InputSize.cx == pbiHdr->biWidth))              DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: %s", _fx_, "pDRVideo->ConfigCaps.InputSize.cx == pbiHdr->biWidth"));
                                        if(!(pDRVideo->ConfigCaps.InputSize.cy == pbiHdr->biHeight))             DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: %s", _fx_, "pDRVideo->ConfigCaps.InputSize.cy == pbiHdr->biHeight"));
                                        if(!(pDRVideo->ConfigCaps.MinOutputSize.cx <= pbiHdr->biWidth))          DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: %s", _fx_, "pDRVideo->ConfigCaps.MinOutputSize.cx <= pbiHdr->biWidth"));
                                        if(!(pbiHdr->biWidth <= pDRVideo->ConfigCaps.MaxOutputSize.cx))          DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: %s", _fx_, "pbiHdr->biWidth <= pDRVideo->ConfigCaps.MaxOutputSize.cx"));
                                        if(!(pDRVideo->ConfigCaps.MinOutputSize.cy <= pbiHdr->biHeight))         DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: %s", _fx_, "pDRVideo->ConfigCaps.MinOutputSize.cy <= pbiHdr->biHeight"));
                                        if(!(pbiHdr->biHeight <= pDRVideo->ConfigCaps.MaxOutputSize.cy))         DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: %s", _fx_, "pbiHdr->biHeight <= pDRVideo->ConfigCaps.MaxOutputSize.cy"));
                                        if(!((pbiHdr->biWidth % pDRVideo->ConfigCaps.OutputGranularityX) == 0))  DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: %s", _fx_, "(pbiHdr->biWidth % pDRVideo->ConfigCaps.OutputGranularityX) == 0"));
                                        if(!((pbiHdr->biHeight % pDRVideo->ConfigCaps.OutputGranularityY) == 0)) DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: %s", _fx_, "(pbiHdr->biHeight % pDRVideo->ConfigCaps.OutputGranularityY) == 0"));
                                }
#endif
                        } // VideoStandard
                } // Specifier

                pDRVideo = (PKS_DATARANGE_VIDEO)((PBYTE)pDRVideo + ((pDRVideo->DataRange.FormatSize + 7) & ~7));  // Next KS_DATARANGE_VIDEO
        }


        *ppSelDRVideo = pMatchDRVideo;
        if (!*ppSelDRVideo) {
                DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   1st data range that fits requests used -- framerate might need adjustment in caller (*pfValidMatch %d)", _fx_,*pfValidMatch));
                *ppSelDRVideo = pFirstMatchDRVideo;
                }


        // If no valid match, use the first range found
        if (!*pfValidMatch) {
                DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   1st data range used (*pfValidMatch %d)", _fx_,*pfValidMatch));
                *ppSelDRVideo = pFirstDRVideo;
                }

        // Have we found anything?
        if (!*ppSelDRVideo) {
                DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   nothing found", _fx_));
                Hr = E_FAIL;
                }

MyExit:
        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: end", _fx_));
        return Hr;
}


/****************************************************************************
 *  @doc INTERNAL CWDMCAPDEVMETHOD
 *
 *  @mfunc BOOL | CWDMCapDev | DeviceIoControl | This function wraps around
 *    ::DeviceIOControl.
 *
 *  @parm HANDLE | hFile | Handle to the device that is to perform the
 *    operation.
 *
 *  @parm DWORD | dwIoControlCode | Specifies the control code for the
 *    operation.
 *
 *  @parm LPVOID | lpInBuffer | Pointer to a buffer that contains the data
 *    required to perform the operation.
 *
 *  @parm DWORD | nInBufferSize | Specifies the size, in bytes, of the buffer
 *    pointed to by <p lpInBuffer>.
 *
 *  @parm LPVOID | lpOutBuffer | Pointer to a buffer that receives the
 *    operation's output data.
 *
 *  @parm DWORD | nOutBufferSize | Specifies the size, in bytes, of the
 *    buffer pointed to by <p lpOutBuffer>.
 *
 *  @parm LPDWORD | lpBytesReturned | Pointer to a variable that receives the
 *    size, in bytes, of the data stored into the buffer pointed to by
 *    <p lpOutBuffer>.
 *
 *  @parm BOOL | bOverlapped | If TRUE, the operation is performed
 *    asynchronously, if FALSE, the operation is synchronous.
 *
 *  @rdesc Returns TRUE if successful, or FALSE otherwise.
 ***************************************************************************/
BOOL CWDMCapDev::DeviceIoControl(HANDLE hFile, DWORD dwIoControlCode, LPVOID lpInBuffer, DWORD nInBufferSize, LPVOID lpOutBuffer, DWORD nOutBufferSize, LPDWORD lpBytesReturned, BOOL bOverlapped)
{
        FX_ENTRY("CWDMCapDev::DeviceIoControl");

        if (hFile && (hFile != INVALID_HANDLE_VALUE))
        {
                LPOVERLAPPED lpOverlapped=NULL;
                BOOL bRet;
                OVERLAPPED ov;
                DWORD dwErr;

                if (bOverlapped)
                {
                        ov.Offset            = 0;
                        ov.OffsetHigh        = 0;
                        ov.hEvent            = CreateEvent( NULL, FALSE, FALSE, NULL );
                        if (ov.hEvent == (HANDLE) 0)
                        {
                                DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s: CreateEvent has failed", _fx_));
                        }
                        lpOverlapped        =&ov;
                }

                bRet = ::DeviceIoControl(hFile, dwIoControlCode, lpInBuffer, nInBufferSize, lpOutBuffer, nOutBufferSize, lpBytesReturned, lpOverlapped);

                if (bOverlapped)
                {
                        BOOL bShouldBlock=FALSE;

                        if (!bRet)
                        {
                                dwErr=GetLastError();
                                switch (dwErr)
                                {
                                        case ERROR_IO_PENDING:    // the overlapped IO is going to take place.
                                                bShouldBlock=TRUE;
                                                break;

                                        default:    // some other strange error has happened.
                                                DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s: DevIoControl failed with GetLastError=%d", _fx_, dwErr));
                                                break;
                                }
                        }

                        if (bShouldBlock)
                        {
                                DWORD    tmStart, tmEnd, tmDelta;
                                tmStart = timeGetTime();

                                DWORD dwRtn = WaitForSingleObject( ov.hEvent, 1000 * 10);  // USB has a max of 5 SEC bus reset

                                tmEnd = timeGetTime();
                                tmDelta = tmEnd - tmStart;
#ifdef DEBUG
                                if (tmDelta >= 1000)
                                {
                                        DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s: WaitObj waited %d msec", _fx_, tmDelta));
                                }
#endif

                                switch (dwRtn)
                                {
                                        case WAIT_ABANDONED:
                                                DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s: WaitObj: non-signaled ! WAIT_ABANDONED!", _fx_));
                                                bRet = FALSE;
                                                break;

                                        case WAIT_OBJECT_0:
                                                bRet = TRUE;
                                                break;

                                        case WAIT_TIMEOUT:
                                                DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s: WaitObj: TIMEOUT after %d msec! rtn FALSE", _fx_, tmDelta));
                                                bRet = FALSE;
                                                break;

                                        default:
                                                DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s: WaitObj: unknown return ! rtn FALSE", _fx_));
                                                bRet = FALSE;
                                                break;
                                }
                        }

                        CloseHandle(ov.hEvent);
                }

                return bRet;
        }

        return FALSE;
}

/****************************************************************************
 *  @doc INTERNAL CWDMCAPDEVMETHOD
 *
 *  @mfunc DWORD | CWDMCapDev | CreateDriverSupportedDataRanges | This method
 *    builds the list of video data ranges supported by the capture device.
 *
 *  @rdesc Returns the number of valid data ranges in the list.
 ***************************************************************************/
DWORD CWDMCapDev::CreateDriverSupportedDataRanges()
{
        DWORD dwCount = 0UL;

        FX_ENTRY("CWDMCapDev::CreateDriverSupportedDataRanges");

        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: begin", _fx_));

        DWORD cbReturned;
        DWORD dwSize = 0UL;

        // Initialize property structure to get video data ranges
        KSP_PIN KsProperty = {0};

        KsProperty.PinId                        = (m_dwCapturePinId != INVALID_PIN_ID) ? m_dwCapturePinId : m_dwPreviewPinId;
        KsProperty.Property.Set         = KSPROPSETID_Pin;
        KsProperty.Property.Id          = KSPROPERTY_PIN_DATARANGES ;
        KsProperty.Property.Flags       = KSPROPERTY_TYPE_GET;

        // Get the size of the video data range structure
        if (DeviceIoControl(m_hDriver, IOCTL_KS_PROPERTY, &KsProperty, sizeof(KsProperty), &dwSize, sizeof(dwSize), &cbReturned) == FALSE)
        {
                DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: Couldn't get the size for the video data ranges", _fx_));
                goto MyExit;
        }

        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: Get video data ranges needs %d bytes", _fx_, dwSize));

        // Allocate memory to hold video data ranges
        if (m_pVideoDataRanges)
                delete [] m_pVideoDataRanges;
        m_pVideoDataRanges = (PVIDEO_DATA_RANGES) new BYTE[dwSize];

        if (!m_pVideoDataRanges)
        {
                DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: Couldn't allocate memory for the video data ranges", _fx_));
                goto MyExit;
        }

        // Really get the video data ranges
        if (DeviceIoControl(m_hDriver, IOCTL_KS_PROPERTY, &KsProperty, sizeof(KsProperty), m_pVideoDataRanges, dwSize, &cbReturned) == 0)
        {
                DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: Problem getting the data ranges themselves", _fx_));
                goto MyError;
        }

        // Sanity check
        if (cbReturned < m_pVideoDataRanges->Size || m_pVideoDataRanges->Count == 0)
        {
                DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: cbReturned < m_pDataRanges->Size || m_pDataRanges->Count == 0", _fx_));
                goto MyError;
        }

        dwCount = m_pVideoDataRanges->Count;

#ifdef DEBUG
        // Dump dataranges
        PKS_DATARANGE_VIDEO     pDRVideo;
        ULONG i;
        // Walk the list of data ranges
        for (i = 0, pDRVideo = &m_pVideoDataRanges->Data; i < m_pVideoDataRanges->Count; i++)
        {
                // Meaningless unless it is *_VIDEOINFO
                if (pDRVideo->DataRange.Specifier == KSDATAFORMAT_SPECIFIER_VIDEOINFO)
                {
                        // We don't care about TV Tuner like devices
                        if (pDRVideo->ConfigCaps.VideoStandard == KS_AnalogVideo_None)
                        {
                                // Dump useable data range
                                DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: Video datarange #%ld:", _fx_, i));
                                DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s:   pDRVideo->DataRange.FormatSize=%ld", _fx_, pDRVideo->DataRange.FormatSize));
                                DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s:   pDRVideo->DataRange.Flags=%ld", _fx_, pDRVideo->DataRange.Flags));
                                DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s:   pDRVideo->DataRange.SampleSize=%ld", _fx_, pDRVideo->DataRange.SampleSize));
                                DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s:   pDRVideo->DataRange.Reserved=%ld", _fx_, pDRVideo->DataRange.Reserved));
                                DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s:   pDRVideo->DataRange.MajorFormat=0x%lX", _fx_, pDRVideo->DataRange.MajorFormat));
                                DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s:   pDRVideo->DataRange.SubFormat=0x%lX", _fx_, pDRVideo->DataRange.SubFormat));
                                DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s:   pDRVideo->DataRange.Specifier=KSDATAFORMAT_SPECIFIER_VIDEOINFO", _fx_));
                                DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s:   pDRVideo->bFixedSizeSamples=%ld", _fx_, pDRVideo->bFixedSizeSamples));
                                DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s:   pDRVideo->bTemporalCompression=%ld", _fx_, pDRVideo->bTemporalCompression));
                                DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s:   pDRVideo->StreamDescriptionFlags=0x%lX", _fx_, pDRVideo->StreamDescriptionFlags));
                                DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s:   pDRVideo->MemoryAllocationFlags=0x%lX", _fx_, pDRVideo->MemoryAllocationFlags));
                                DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s:   pDRVideo->ConfigCaps.VideoStandard=KS_AnalogVideo_None", _fx_));
                                DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s:   pDRVideo->ConfigCaps.InputSize(cx=%ld, cy=%ld)", _fx_, pDRVideo->ConfigCaps.InputSize.cx, pDRVideo->ConfigCaps.InputSize.cy));
                                DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s:   pDRVideo->ConfigCaps.MinCroppingSize(cx=%ld, cy=%ld)", _fx_, pDRVideo->ConfigCaps.MinCroppingSize.cx, pDRVideo->ConfigCaps.MinCroppingSize.cy));
                                DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s:   pDRVideo->ConfigCaps.MaxCroppingSize(cx=%ld, cy=%ld)", _fx_, pDRVideo->ConfigCaps.MaxCroppingSize.cx, pDRVideo->ConfigCaps.MaxCroppingSize.cy));
                                DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s:   pDRVideo->ConfigCaps.CropGranularityX=%ld", _fx_, pDRVideo->ConfigCaps.CropGranularityY));
                                DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s:   pDRVideo->ConfigCaps.CropGranularityY=%ld", _fx_, pDRVideo->ConfigCaps.CropGranularityY));
                                DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s:   pDRVideo->ConfigCaps.CropAlignX=%ld", _fx_, pDRVideo->ConfigCaps.CropAlignX));
                                DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s:   pDRVideo->ConfigCaps.CropAlignY=%ld", _fx_, pDRVideo->ConfigCaps.CropAlignY));
                                DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s:   pDRVideo->ConfigCaps.MinOutputSize(cx=%ld, cy=%ld)", _fx_, pDRVideo->ConfigCaps.MinOutputSize.cx, pDRVideo->ConfigCaps.MinOutputSize.cy));
                                DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s:   pDRVideo->ConfigCaps.MaxOutputSize(cx=%ld, cy=%ld)", _fx_, pDRVideo->ConfigCaps.MaxOutputSize.cx, pDRVideo->ConfigCaps.MaxOutputSize.cy));
                                DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s:   pDRVideo->ConfigCaps.OutputGranularityX=%ld", _fx_, pDRVideo->ConfigCaps.OutputGranularityX));
                                DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s:   pDRVideo->ConfigCaps.OutputGranularityY=%ld", _fx_, pDRVideo->ConfigCaps.OutputGranularityY));
                                DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s:   pDRVideo->ConfigCaps.StretchTapsX=%ld", _fx_, pDRVideo->ConfigCaps.StretchTapsX));
                                DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s:   pDRVideo->ConfigCaps.StretchTapsY=%ld", _fx_, pDRVideo->ConfigCaps.StretchTapsY));
                                DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s:   pDRVideo->ConfigCaps.ShrinkTapsX=%ld", _fx_, pDRVideo->ConfigCaps.ShrinkTapsX));
                                DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s:   pDRVideo->ConfigCaps.ShrinkTapsY=%ld", _fx_, pDRVideo->ConfigCaps.ShrinkTapsY));
                                DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s:   pDRVideo->ConfigCaps.MinFrameInterval=%ld", _fx_, (DWORD)pDRVideo->ConfigCaps.MinFrameInterval));
                                DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s:   pDRVideo->ConfigCaps.MaxFrameInterval=%ld", _fx_, (DWORD)pDRVideo->ConfigCaps.MaxFrameInterval));
                                DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s:   pDRVideo->ConfigCaps.MinBitsPerSecond=%ld", _fx_, pDRVideo->ConfigCaps.MinBitsPerSecond));
                                DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s:   pDRVideo->ConfigCaps.MaxBitsPerSecond=%ld", _fx_, pDRVideo->ConfigCaps.MaxBitsPerSecond));
                                DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s:   pDRVideo->VideoInfoHeader.rcSource(left=%ld, top=%ld, right=%ld, bottom=%ld)", _fx_, pDRVideo->VideoInfoHeader.rcSource.left, pDRVideo->VideoInfoHeader.rcSource.top, pDRVideo->VideoInfoHeader.rcSource.right, pDRVideo->VideoInfoHeader.rcSource.bottom));
                                DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s:   pDRVideo->VideoInfoHeader.rcTarget(left=%ld, top=%ld, right=%ld, bottom=%ld)", _fx_, pDRVideo->VideoInfoHeader.rcTarget.left, pDRVideo->VideoInfoHeader.rcTarget.top, pDRVideo->VideoInfoHeader.rcTarget.right, pDRVideo->VideoInfoHeader.rcTarget.bottom));
                                DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s:   pDRVideo->VideoInfoHeader.dwBitRate=%ld", _fx_, pDRVideo->VideoInfoHeader.dwBitRate));
                                DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s:   pDRVideo->VideoInfoHeader.dwBitErrorRate=%ld", _fx_, pDRVideo->VideoInfoHeader.dwBitErrorRate));
                                DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s:   pDRVideo->VideoInfoHeader.AvgTimePerFrame=%ld", _fx_, (DWORD)pDRVideo->VideoInfoHeader.AvgTimePerFrame));
                                DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s:   pDRVideo->VideoInfoHeader.bmiHeader.biSize=%ld", _fx_, (DWORD)pDRVideo->VideoInfoHeader.bmiHeader.biSize));
                                DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s:   pDRVideo->VideoInfoHeader.bmiHeader.biWidth=%ld", _fx_, (DWORD)pDRVideo->VideoInfoHeader.bmiHeader.biWidth));
                                DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s:   pDRVideo->VideoInfoHeader.bmiHeader.biHeight=%ld", _fx_, (DWORD)pDRVideo->VideoInfoHeader.bmiHeader.biHeight));
                                DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s:   pDRVideo->VideoInfoHeader.bmiHeader.biPlanes=%ld", _fx_, (DWORD)pDRVideo->VideoInfoHeader.bmiHeader.biPlanes));
                                DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s:   pDRVideo->VideoInfoHeader.bmiHeader.biBitCount=%ld", _fx_, (DWORD)pDRVideo->VideoInfoHeader.bmiHeader.biBitCount));
                                DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s:   pDRVideo->VideoInfoHeader.bmiHeader.biCompression=%ld", _fx_, (DWORD)pDRVideo->VideoInfoHeader.bmiHeader.biCompression));
                                DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s:   pDRVideo->VideoInfoHeader.bmiHeader.biSizeImage=%ld", _fx_, (DWORD)pDRVideo->VideoInfoHeader.bmiHeader.biSizeImage));
                                DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s:   pDRVideo->VideoInfoHeader.bmiHeader.biClrUsed=%ld", _fx_, (DWORD)pDRVideo->VideoInfoHeader.bmiHeader.biClrUsed));
                                DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s:   pDRVideo->VideoInfoHeader.bmiHeader.biClrImportant=%ld", _fx_, (DWORD)pDRVideo->VideoInfoHeader.bmiHeader.biClrImportant));
                        } // VideoStandard
                        else
                        {
                                DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: Video datarange's VideoStandard != KS_AnalogVideo_None", _fx_));
                        }
                } // Specifier
                else
                {
                        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: Video datarange's Specifier != KSDATAFORMAT_SPECIFIER_VIDEOINFO", _fx_));
                }

                pDRVideo = (PKS_DATARANGE_VIDEO)((PBYTE)pDRVideo + ((pDRVideo->DataRange.FormatSize + 7) & ~7));  // Next KS_DATARANGE_VIDEO
        }
#endif

        goto MyExit;

MyError:
        delete [] m_pVideoDataRanges;
        m_pVideoDataRanges = (PVIDEO_DATA_RANGES)NULL;
MyExit:
        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: end", _fx_));
        return dwCount;
}

/****************************************************************************
 *  @doc INTERNAL CWDMCAPDEVMETHOD
 *
 *  @mfunc DWORD | CWDMCapDev | GetDriverSupportedDataRanges | This method
 *    returns the list of video data ranges supported by the capture device.
 *
 *  @rdesc Returns the number of valid data ranges in the list.
 ***************************************************************************/
HRESULT CWDMCapDev::GetDriverSupportedDataRanges(PVIDEO_DATA_RANGES *ppDataRanges)
{
        HRESULT Hr = NOERROR;

        FX_ENTRY("CWDMCapDev::GetDriverSupportedDataRanges");

        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: begin", _fx_));

        // Validate input parameters
        ASSERT(ppDataRanges);
        if (!ppDataRanges)
        {
                DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: invalid input parameter", _fx_));
                Hr = E_POINTER;
                goto MyExit;
        }

        // Return pointer to our data range array
        *ppDataRanges = m_pVideoDataRanges;

MyExit:
        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: end", _fx_));
        return Hr;
}

#if defined(DUMP_DRIVER_CHARACTERISTICS) && defined(DEBUG)

typedef struct identifiers : public KSMULTIPLE_ITEM {
    KSIDENTIFIER aIdentifiers[1];
} IDENTIFIERS, *PIDENTIFIERS;

/****************************************************************************
 *  @doc INTERNAL CWDMCAPDEVMETHOD
 *
 *  @mfunc HRESULT | CWDMCapDev | GetDriverDetails | This method is used to
 *    dump the list of capabilities of a WDM capture device. This code should
 *    used in DEBUG mode only!
 *
 *  @rdesc Nade
 ***************************************************************************/
void CWDMCapDev::GetDriverDetails()
{
        KSP_PIN KsProperty;
        DWORD dwPinCount = 0UL;
        DWORD dwSize = 0UL;
    PKSMULTIPLE_ITEM pCategories = NULL;
    PIDENTIFIERS pInterfaces = NULL;
    PIDENTIFIERS pMediums = NULL;
    PIDENTIFIERS pNodes = NULL;
    KSTOPOLOGY Topology;
        KSPIN_CINSTANCES Instances;
        DWORD cbReturned;
        DWORD dwFlowDirection;
        DWORD dwCommunication;
        DWORD dwPinId;
        WCHAR wstrPinName[256];
        GUID guidCategory;

        FX_ENTRY("CWDMCapDev::GetDriverDetails");

        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: Device properties:", _fx_));

        // Get the topology
        KsProperty.PinId                        = 0;
        KsProperty.Reserved                     = 0;
        KsProperty.Property.Set         = KSPROPSETID_Topology;
        KsProperty.Property.Id          = KSPROPERTY_TOPOLOGY_CATEGORIES;
        KsProperty.Property.Flags       = KSPROPERTY_TYPE_GET;

        // Get the size of the topology
        if (DeviceIoControl(m_hDriver, IOCTL_KS_PROPERTY, &KsProperty, sizeof(KsProperty), &dwSize, sizeof(dwSize), &cbReturned) == FALSE)
        {
                DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s:   Couldn't get the size for the topology", _fx_));
        }
        else
        {
                // Allocate memory to hold the topology
                if (!(pCategories = (PKSMULTIPLE_ITEM) new BYTE[dwSize]))
                {
                        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s:   Couldn't allocate memory for the topology", _fx_));
                }
                else
                {
                        // Really get the topology structures
                        if (DeviceIoControl(m_hDriver, IOCTL_KS_PROPERTY, &KsProperty, sizeof(KsProperty), pCategories, dwSize, &cbReturned) == 0)
                        {
                                DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s:   Couldn't get the topology", _fx_));
                        }
                        else
                        {
                                if (pCategories)
                                {
                                        Topology.CategoriesCount = pCategories->Count;
                                        Topology.Categories = (GUID*)(pCategories + 1);

                                        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s:   Supported categories: %ld", _fx_, pCategories->Count));

                                        for (DWORD i = 0; i < pCategories->Count; i++)
                                        {
                                                if (Topology.Categories[i] == KSCATEGORY_BRIDGE)
                                                {
                                                        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s:     KSCATEGORY_BRIDGE", _fx_));
                                                }
                                                else if (Topology.Categories[i] == KSCATEGORY_CAPTURE)
                                                {
                                                        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s:     KSCATEGORY_CAPTURE", _fx_));
                                                }
                                                else if (Topology.Categories[i] == KSCATEGORY_TVTUNER)
                                                {
                                                        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s:     KSCATEGORY_TVTUNER", _fx_));
                                                }
                                                else if (Topology.Categories[i] == KSCATEGORY_TVAUDIO)
                                                {
                                                        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s:     KSCATEGORY_TVAUDIO", _fx_));
                                                }
                                                else if (Topology.Categories[i] == KSCATEGORY_CROSSBAR)
                                                {
                                                        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s:     KSCATEGORY_CROSSBAR", _fx_));
                                                }
                                                else if (Topology.Categories[i] == KSCATEGORY_VIDEO)
                                                {
                                                        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s:     KSCATEGORY_VIDEO", _fx_));
                                                }
                                                else if (Topology.Categories[i] == KSCATEGORY_RENDER)
                                                {
                                                        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s:     KSCATEGORY_RENDER", _fx_));
                                                }
                                                else if (Topology.Categories[i] == KSCATEGORY_MIXER)
                                                {
                                                        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s:     KSCATEGORY_MIXER", _fx_));
                                                }
                                                else if (Topology.Categories[i] == KSCATEGORY_SPLITTER)
                                                {
                                                        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s:     KSCATEGORY_SPLITTER", _fx_));
                                                }
                                                else if (Topology.Categories[i] == KSCATEGORY_DATACOMPRESSOR)
                                                {
                                                        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s:     KSCATEGORY_DATACOMPRESSOR", _fx_));
                                                }
                                                else if (Topology.Categories[i] == KSCATEGORY_DATADECOMPRESSOR)
                                                {
                                                        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s:     KSCATEGORY_DATADECOMPRESSOR", _fx_));
                                                }
                                                else if (Topology.Categories[i] == KSCATEGORY_DATATRANSFORM)
                                                {
                                                        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s:     KSCATEGORY_DATATRANSFORM", _fx_));
                                                }
                                                else if (Topology.Categories[i] == KSCATEGORY_COMMUNICATIONSTRANSFORM)
                                                {
                                                        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s:     KSCATEGORY_COMMUNICATIONSTRANSFORM", _fx_));
                                                }
                                                else if (Topology.Categories[i] == KSCATEGORY_INTERFACETRANSFORM)
                                                {
                                                        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s:     KSCATEGORY_INTERFACETRANSFORM", _fx_));
                                                }
                                                else if (Topology.Categories[i] == KSCATEGORY_MEDIUMTRANSFORM)
                                                {
                                                        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s:     KSCATEGORY_MEDIUMTRANSFORM", _fx_));
                                                }
                                                else if (Topology.Categories[i] == PINNAME_VIDEO_STILL)
                                                {
                                                        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s:     PINNAME_VIDEO_STILL", _fx_));
                                                }
                                                else
                                                {
                                                        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s:     Unknown category", _fx_));
                                                }
                                        }
                                }
                        }

                        delete pCategories;
                }
        }

        // Get the topology nodes
        KsProperty.PinId                        = 0;
        KsProperty.Reserved                     = 0;
        KsProperty.Property.Set         = KSPROPSETID_Topology;
        KsProperty.Property.Id          = KSPROPERTY_TOPOLOGY_NODES;
        KsProperty.Property.Flags       = KSPROPERTY_TYPE_GET;

        // Get the size of the topology node structures
        dwSize = 0UL;
        if (DeviceIoControl(m_hDriver, IOCTL_KS_PROPERTY, &KsProperty, sizeof(KsProperty), &dwSize, sizeof(dwSize), &cbReturned) == FALSE)
        {
                DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s:   Couldn't get the size for the topology nodes", _fx_));
        }
        else
        {
                // Allocate memory to hold the topology node structures
                if (!(pNodes = (PIDENTIFIERS) new BYTE[dwSize]))
                {
                        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s:   Couldn't allocate memory for the topology nodes", _fx_));
                }
                else
                {
                        // Really get the topology nodes
                        if (DeviceIoControl(m_hDriver, IOCTL_KS_PROPERTY, &KsProperty, sizeof(KsProperty), pNodes, dwSize, &cbReturned) == 0)
                        {
                                DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s:   Couldn't get the topology nodes", _fx_));
                        }
                        else
                        {
                                if (pNodes)
                                {
                                        Topology.TopologyNodesCount = pNodes->Count;
                                        Topology.TopologyNodes = (GUID*)(pNodes + 1);

                                        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s:   Number of topology nodes: %ld", _fx_, pNodes->Count));

                                        for (DWORD i = 0; i < pNodes->Count; i++)
                                        {
                                                DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s:     Node #%ld: {%08lX-%04lX-%04lX-%02lX%02lX-%02lX%02lX%02lX%02lX%02lX%02lX}", _fx_, i, Topology.TopologyNodes[i].Data1, Topology.TopologyNodes[i].Data2, Topology.TopologyNodes[i].Data3, Topology.TopologyNodes[i].Data4[0], Topology.TopologyNodes[i].Data4[1], Topology.TopologyNodes[i].Data4[2], Topology.TopologyNodes[i].Data4[3], Topology.TopologyNodes[i].Data4[4], Topology.TopologyNodes[i].Data4[5], Topology.TopologyNodes[i].Data4[6], Topology.TopologyNodes
[i].Data4[7]));
                                        }
                                }
                        }

                        delete pNodes;
                }
        }

        // Get the topology node connections
        KsProperty.PinId                        = 0;
        KsProperty.Reserved                     = 0;
        KsProperty.Property.Set         = KSPROPSETID_Topology;
        KsProperty.Property.Id          = KSPROPERTY_TOPOLOGY_CONNECTIONS;
        KsProperty.Property.Flags       = KSPROPERTY_TYPE_GET;

        // Get the size of the topology node connection structures
        dwSize = 0UL;
        if (DeviceIoControl(m_hDriver, IOCTL_KS_PROPERTY, &KsProperty, sizeof(KsProperty), &dwSize, sizeof(dwSize), &cbReturned) == FALSE)
        {
                DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s:   Couldn't get the size for the topology node connections", _fx_));
        }
        else
        {
                // Allocate memory to hold the topology node connection structures
                if (!(pNodes = (PIDENTIFIERS) new BYTE[dwSize]))
                {
                        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s:   Couldn't allocate memory for the topology node connections", _fx_));
                }
                else
                {
                        // Really get the topology node connections
                        if (DeviceIoControl(m_hDriver, IOCTL_KS_PROPERTY, &KsProperty, sizeof(KsProperty), pNodes, dwSize, &cbReturned) == 0)
                        {
                                DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s:   Couldn't get the topology node connections", _fx_));
                        }
                        else
                        {
                                if (pNodes)
                                {
                                        Topology.TopologyConnectionsCount = pNodes->Count;
                                        Topology.TopologyConnections = (KSTOPOLOGY_CONNECTION*)(pNodes + 1);

                                        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s:   Number of topology node connections: %ld", _fx_, pNodes->Count));

                                        for (DWORD i = 0; i < pNodes->Count; i++)
                                        {
                                                DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s:     Connection #%ld: From node #%ld, from node pin #%ld, to node #%ld, to node pin #%ld", _fx_, i, Topology.TopologyConnections[i].FromNode, Topology.TopologyConnections[i].FromNodePin, Topology.TopologyConnections[i].ToNode, Topology.TopologyConnections[i].ToNodePin));
                                        }
                                }
                        }

                        delete pNodes;
                }
        }

        // Get the number of pins
        KsProperty.PinId                        = 0;
        KsProperty.Reserved                     = 0;
        KsProperty.Property.Set         = KSPROPSETID_Pin;
        KsProperty.Property.Id          = KSPROPERTY_PIN_CTYPES;
        KsProperty.Property.Flags       = KSPROPERTY_TYPE_GET;

        if (DeviceIoControl(m_hDriver, IOCTL_KS_PROPERTY, &KsProperty, sizeof(KsProperty), &dwPinCount, sizeof(dwPinCount), &cbReturned) == FALSE)
        {
                DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s:   Couldn't get the number of pin types supported by the device", _fx_));
        }
        else
        {
                DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s:   Number of pin types: %ld", _fx_, dwPinCount));
        }

        // Get the properties of each pin
    for (dwPinId = 0; dwPinId < dwPinCount; dwPinId++)
        {
                DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s:   Properties of pin type #%ld:", _fx_, dwPinId));

                // Get the number of instances
                KsProperty.PinId                        = dwPinId;
                KsProperty.Reserved                     = 0;
                KsProperty.Property.Set         = KSPROPSETID_Pin;
                KsProperty.Property.Id          = KSPROPERTY_PIN_CINSTANCES;
                KsProperty.Property.Flags       = KSPROPERTY_TYPE_GET;

                if (DeviceIoControl(m_hDriver, IOCTL_KS_PROPERTY, &KsProperty, sizeof(KsProperty), &Instances, sizeof(KSPIN_CINSTANCES), &cbReturned) == FALSE)
                {
                        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s:     Couldn't get the number of available instances", _fx_));
                }
                else
                {
                        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s:     Number of available instances: %ld", _fx_, Instances.PossibleCount));
                        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s:     Number of used instances: %ld", _fx_, Instances.CurrentCount));
                }

                // Get the flow direction
                KsProperty.PinId                        = dwPinId;
                KsProperty.Reserved                     = 0;
                KsProperty.Property.Set         = KSPROPSETID_Pin;
                KsProperty.Property.Id          = KSPROPERTY_PIN_DATAFLOW;
                KsProperty.Property.Flags       = KSPROPERTY_TYPE_GET;

                dwFlowDirection = 0UL;

                if (DeviceIoControl(m_hDriver, IOCTL_KS_PROPERTY, &KsProperty, sizeof(KsProperty), &dwFlowDirection, sizeof(dwFlowDirection), &cbReturned) == FALSE)
                {
                        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s:     Couldn't get the flow direction", _fx_));
                }
                else
                {
                        if (dwFlowDirection == KSPIN_DATAFLOW_IN)
                                DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s:     Flow direction is KSPIN_DATAFLOW_IN", _fx_));
                        else if (dwFlowDirection == KSPIN_DATAFLOW_OUT)
                                DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s:     Flow direction is KSPIN_DATAFLOW_OUT", _fx_));
                        else
                                DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s:     Flow direction is unknown", _fx_));
                }

                // Get the communication requirements
                KsProperty.PinId                        = dwPinId;
                KsProperty.Reserved                     = 0;
                KsProperty.Property.Set         = KSPROPSETID_Pin;
                KsProperty.Property.Id          = KSPROPERTY_PIN_COMMUNICATION;
                KsProperty.Property.Flags       = KSPROPERTY_TYPE_GET;

                dwCommunication = 0UL;

                if (DeviceIoControl(m_hDriver, IOCTL_KS_PROPERTY, &KsProperty, sizeof(KsProperty), &dwCommunication, sizeof(dwCommunication), &cbReturned) == FALSE)
                {
                        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s:     Couldn't get the communication requirements", _fx_));
                }
                else
                {
                        if (dwCommunication & KSPIN_COMMUNICATION_NONE)
                                DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s:     Communication requirements: KSPIN_COMMUNICATION_NONE", _fx_));
                        if (dwCommunication & KSPIN_COMMUNICATION_SINK)
                                DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s:     Communication requirements: KSPIN_COMMUNICATION_SINK", _fx_));
                        if (dwCommunication & KSPIN_COMMUNICATION_SOURCE)
                                DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s:     Communication requirements: KSPIN_COMMUNICATION_SOURCE", _fx_));
                        if (dwCommunication & KSPIN_COMMUNICATION_BOTH)
                                DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s:     Communication requirements: KSPIN_COMMUNICATION_BOTH", _fx_));
                        if (dwCommunication & KSPIN_COMMUNICATION_BRIDGE)
                                DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s:     Communication requirements: KSPIN_COMMUNICATION_BRIDGE", _fx_));
                }

                // Get the pin category
                KsProperty.PinId                        = dwPinId;
                KsProperty.Reserved                     = 0;
                KsProperty.Property.Set         = KSPROPSETID_Pin;
                KsProperty.Property.Id          = KSPROPERTY_PIN_CATEGORY;
                KsProperty.Property.Flags       = KSPROPERTY_TYPE_GET;

                if (DeviceIoControl(m_hDriver, IOCTL_KS_PROPERTY, &KsProperty, sizeof(KsProperty), &guidCategory, sizeof(guidCategory), &cbReturned) == FALSE)
                {
                        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s:     Couldn't get the GUID category", _fx_));
                }
                else
                {
                        if (guidCategory == PINNAME_VIDEO_PREVIEW)
                                DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s:     GUID category: PINNAME_VIDEO_PREVIEW", _fx_));
                        else if (guidCategory == PINNAME_VIDEO_CAPTURE)
                                DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s:     GUID category: PINNAME_VIDEO_CAPTURE", _fx_));
                        else
                                DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s:   Unknown GUID category", _fx_));
                }

                // Get pin name
                KsProperty.PinId                        = dwPinId;
                KsProperty.Reserved                     = 0;
                KsProperty.Property.Set         = KSPROPSETID_Pin;
                KsProperty.Property.Id          = KSPROPERTY_PIN_NAME;
                KsProperty.Property.Flags       = KSPROPERTY_TYPE_GET;

                if (DeviceIoControl(m_hDriver, IOCTL_KS_PROPERTY, &KsProperty, sizeof(KsProperty), &wstrPinName[0], sizeof(wstrPinName), &cbReturned) == 0)
                {
                        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s:   Couldn't get the pin name", _fx_));
                }
                else
                {
                        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s:     Pin name: %S", _fx_, &wstrPinName[0]));
                }

                // Get pin interfaces
                KsProperty.PinId                        = dwPinId;
                KsProperty.Reserved                     = 0;
                KsProperty.Property.Set         = KSPROPSETID_Pin;
                KsProperty.Property.Id          = KSPROPERTY_PIN_INTERFACES;
                KsProperty.Property.Flags       = KSPROPERTY_TYPE_GET;

                // Get the size of the interface structures
                dwSize = 0UL;
                if (DeviceIoControl(m_hDriver, IOCTL_KS_PROPERTY, &KsProperty, sizeof(KsProperty), &dwSize, sizeof(dwSize), &cbReturned) == FALSE)
                {
                        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s:   Couldn't get the size for the interfaces", _fx_));
                }
                else
                {
                        // Allocate memory to hold the interface structures
                        if (!(pInterfaces = (PIDENTIFIERS) new BYTE[dwSize]))
                        {
                                DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s:   Couldn't allocate memory for the interfaces", _fx_));
                        }
                        else
                        {
                                // Really get the list of interfaces
                                if (DeviceIoControl(m_hDriver, IOCTL_KS_PROPERTY, &KsProperty, sizeof(KsProperty), pInterfaces, dwSize, &cbReturned) == 0)
                                {
                                        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s:   Couldn't get the interfaces", _fx_));
                                }
                                else
                                {
                                        // Dump list of supported interfaces
                                        for (DWORD i = 0; i < pInterfaces->Count; i++)
                                        {
                                                DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s:     Interface #%ld", _fx_, i));
                                                if (pInterfaces->aIdentifiers[i].Set == KSINTERFACESETID_Standard)
                                                {
                                                        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s:       Set: KSINTERFACESETID_Standard", _fx_));
                                                        if (pInterfaces->aIdentifiers[i].Id == KSINTERFACE_STANDARD_STREAMING)
                                                                DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s:       Id: KSINTERFACE_STANDARD_STREAMING", _fx_));
                                                        else if (pInterfaces->aIdentifiers[i].Id == KSINTERFACE_STANDARD_LOOPED_STREAMING)
                                                                DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s:       Id: KSINTERFACE_STANDARD_LOOPED_STREAMING", _fx_));
                                                        else if (pInterfaces->aIdentifiers[i].Id == KSINTERFACE_STANDARD_CONTROL)
                                                                DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s:       Id: KSINTERFACE_STANDARD_CONTROL", _fx_));
                                                        else
                                                                DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s:       Id: %ld", _fx_, pInterfaces->aIdentifiers[i].Id));
                                                }
                                                else
                                                {
                                                        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s:       Set: {%08lX-%04lX-%04lX-%02lX%02lX-%02lX%02lX%02lX%02lX%02lX%02lX}", _fx_, pInterfaces->aIdentifiers[i].Set.Data1, pInterfaces->aIdentifiers[i].Set.Data2, pInterfaces->aIdentifiers[i].Set.Data3, pInterfaces->aIdentifiers[i].Set.Data4[0], pInterfaces->aIdentifiers[i].Set.Data4[1], pInterfaces->aIdentifiers[i].Set.Data4[2], pInterfaces->aIdentifiers[i].Set.Data4[3], pInterfaces->aIdentifiers[i].Set.Data4[4], pInterfaces->aIdentifiers[i].Set.Data4[5], p
Interfaces->aIdentifiers[i].Set.Data4[6], pInterfaces->aIdentifiers[i].Set.Data4[7]));
                                                        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s:       Id: %ld", _fx_, pInterfaces->aIdentifiers[i].Id));
                                                }
                                                DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s:       Flags: %ld", _fx_, pInterfaces->aIdentifiers[i].Flags));
                                        }
                                }

                                delete pInterfaces;
                        }
                }

                // Get pin mediums
                KsProperty.PinId                        = dwPinId;
                KsProperty.Reserved                     = 0;
                KsProperty.Property.Set         = KSPROPSETID_Pin;
                KsProperty.Property.Id          = KSPROPERTY_PIN_MEDIUMS;
                KsProperty.Property.Flags       = KSPROPERTY_TYPE_GET;

                // Get the size of the medium structures
                dwSize = 0UL;
                if (DeviceIoControl(m_hDriver, IOCTL_KS_PROPERTY, &KsProperty, sizeof(KsProperty), &dwSize, sizeof(dwSize), &cbReturned) == FALSE)
                {
                        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s:   Couldn't get the size for the mediums", _fx_));
                }
                else
                {
                        // Allocate memory to hold the medium structures
                        if (!(pMediums = (PIDENTIFIERS) new BYTE[dwSize]))
                        {
                                DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s:   Couldn't allocate memory for the mediums", _fx_));
                        }
                        else
                        {
                                // Really get the list of mediums
                                if (DeviceIoControl(m_hDriver, IOCTL_KS_PROPERTY, &KsProperty, sizeof(KsProperty), pMediums, dwSize, &cbReturned) == 0)
                                {
                                        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s:   Couldn't get the mediums", _fx_));
                                }
                                else
                                {
                                        // Dump list of supported mediums
                                        for (DWORD i = 0; i < pMediums->Count; i++)
                                        {
                                                DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s:     Medium #%ld", _fx_, i));
                                                if (pMediums->aIdentifiers[i].Set == KSMEDIUMSETID_Standard)
                                                        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s:       Set: KSMEDIUMSETID_Standard", _fx_));
                                                else if (pMediums->aIdentifiers[i].Set == KSMEDIUMSETID_FileIo)
                                                        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s:       Set: KSMEDIUMSETID_FileIo", _fx_));
                                                else
                                                        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s:       Set: {%08lX-%04lX-%04lX-%02lX%02lX-%02lX%02lX%02lX%02lX%02lX%02lX}", _fx_, pMediums->aIdentifiers[i].Set.Data1, pMediums->aIdentifiers[i].Set.Data2, pMediums->aIdentifiers[i].Set.Data3, pMediums->aIdentifiers[i].Set.Data4[0], pMediums->aIdentifiers[i].Set.Data4[1], pMediums->aIdentifiers[i].Set.Data4[2], pMediums->aIdentifiers[i].Set.Data4[3], pMediums->aIdentifiers[i].Set.Data4[4], pMediums->aIdentifiers[i].Set.Data4[5], pMediums->aIdentifiers[i].Se
t.Data4[6], pMediums->aIdentifiers[i].Set.Data4[7]));
                                                DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s:       Id: %ld", _fx_, pMediums->aIdentifiers[i].Id));
                                                DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s:       Flags: %ld", _fx_, pMediums->aIdentifiers[i].Flags));
                                        }
                                }

                                delete pMediums;
                        }
                }
        }
}
#endif

// Used to query/set video property values and ranges
typedef struct {
    KSPROPERTY_DESCRIPTION      proDesc;
    KSPROPERTY_MEMBERSHEADER  proHdr;
    union {
        KSPROPERTY_STEPPING_LONG  proData;
        ULONG ulData;
    };
    union {
        KSPROPERTY_STEPPING_LONG  proData2;
        ULONG ulData2;
    };
} PROCAMP_MEMBERSLIST;

/****************************************************************************
 *  @doc INTERNAL CWDMCAPDEVMETHOD
 *
 *  @mfunc HRESULT | CWDMCapDev | GetPropertyValue | This function gets the
 *    current value of a video property of a capture device.
 *
 *  @parm GUID | guidPropertySet | GUID of the KS property set we are touching. It
 *    is either PROPSETID_VIDCAP_VIDEOPROCAMP or PROPSETID_VIDCAP_CAMERACONTROL.
 *
 *  @parm ULONG | ulPropertyId | ID of the property we are touching. It is
 *    either KSPROPERTY_VIDEOPROCAMP_* or KSPROPERTY_CAMERACONTROL_*.
 *
 *  @parm PLONG | plValue | Pointer to a LONG to receive the current value.
 *
 *  @parm PULONG | pulFlags | Pointer to a ULONG to receive the current
 *    flags. We only care about KSPROPERTY_*_FLAGS_MANUAL or
 *    KSPROPERTY_*_FLAGS_AUTO.
 *
 *  @parm PULONG | pulCapabilities | Pointer to a ULONG to receive the
 *    capabilities. We only care about KSPROPERTY_*_FLAGS_MANUAL or
 *    KSPROPERTY_*_FLAGS_AUTO.
 *
 *  @devnote KSPROPERTY_VIDEOPROCAMP_S == KSPROPERTY_CAMERACONTROL_S.
 ***************************************************************************/
HRESULT CWDMCapDev::GetPropertyValue(GUID guidPropertySet, ULONG ulPropertyId, PLONG plValue, PULONG pulFlags, PULONG pulCapabilities)
{
        HRESULT                                         Hr = NOERROR;
        ULONG                                           cbReturned;
        KSPROPERTY_VIDEOPROCAMP_S       VideoProperty;

        FX_ENTRY("CWDMCapDev::GetPropertyValue")

        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: begin", _fx_));

        // Inititalize video property structure
        ZeroMemory(&VideoProperty, sizeof(KSPROPERTY_VIDEOPROCAMP_S));

        VideoProperty.Property.Set   = guidPropertySet;      // KSPROPERTY_VIDEOPROCAMP_S/CAMERACONTRO_S
        VideoProperty.Property.Id    = ulPropertyId;         // KSPROPERTY_VIDEOPROCAMP_BRIGHTNESS
        VideoProperty.Property.Flags = KSPROPERTY_TYPE_GET;
        VideoProperty.Flags          = 0;

        // Get property value from driver
        if (DeviceIoControl(m_hDriver, IOCTL_KS_PROPERTY, &VideoProperty, sizeof(VideoProperty), &VideoProperty, sizeof(VideoProperty), &cbReturned, TRUE) == 0)
        {
                DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: This property is not supported by this minidriver/device", _fx_));
                Hr = E_FAIL;
                goto MyExit;
        }

        *plValue         = VideoProperty.Value;
        *pulFlags        = VideoProperty.Flags;
        *pulCapabilities = VideoProperty.Capabilities;

MyExit:
        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: end", _fx_));
        return Hr;
}


/****************************************************************************
 *  @doc INTERNAL CWDMCAPDEVMETHOD
 *
 *  @mfunc HRESULT | CWDMCapDev | GetDefaultValue | This function gets the
 *    default value of a video property of a capture device.
 *
 *  @parm GUID | guidPropertySet | GUID of the KS property set we are touching. It
 *    is either PROPSETID_VIDCAP_VIDEOPROCAMP or PROPSETID_VIDCAP_CAMERACONTROL.
 *
 *  @parm ULONG | ulPropertyId | ID of the property we are touching. It is
 *    either KSPROPERTY_VIDEOPROCAMP_* or KSPROPERTY_CAMERACONTROL_*.
 *
 *  @parm PLONG | plDefValue | Pointer to a LONG to receive the default value.
 ***************************************************************************/
HRESULT CWDMCapDev::GetDefaultValue(GUID guidPropertySet, ULONG ulPropertyId, PLONG plDefValue)
{
        HRESULT                         Hr = NOERROR;
        ULONG                           cbReturned;
        KSPROPERTY                      Property;
        PROCAMP_MEMBERSLIST     proList;

        FX_ENTRY("CWDMCapDev::GetDefaultValue")

        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: begin", _fx_));

        // Initialize property structures
        ZeroMemory(&Property, sizeof(KSPROPERTY));
        ZeroMemory(&proList, sizeof(PROCAMP_MEMBERSLIST));

        Property.Set   = guidPropertySet;
        Property.Id    = ulPropertyId;  // e.g. KSPROPERTY_VIDEOPROCAMP_BRIGHTNESS
        Property.Flags = KSPROPERTY_TYPE_DEFAULTVALUES;

        // Get the default values from the driver
        if (DeviceIoControl(m_hDriver, IOCTL_KS_PROPERTY, &(Property), sizeof(Property), &proList, sizeof(proList), &cbReturned, TRUE) == 0)
        {
                DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: Couldn't *get* the current property of the control", _fx_));
                Hr = E_FAIL;
                goto MyExit;
        }

        // Sanity check
        if (proList.proDesc.DescriptionSize < sizeof(KSPROPERTY_DESCRIPTION))
        {
                Hr = E_FAIL;
        }
        else
        {
                *plDefValue = proList.ulData;
        }

MyExit:
        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: end", _fx_));
        return Hr;
}


/****************************************************************************
 *  @doc INTERNAL CWDMCAPDEVMETHOD
 *
 *  @mfunc HRESULT | CWDMCapDev | GetRangeValues | This function gets the
 *    range values of a video property of a capture device.
 *
 *  @parm GUID | guidPropertySet | GUID of the KS property set we are touching. It
 *    is either PROPSETID_VIDCAP_VIDEOPROCAMP or PROPSETID_VIDCAP_CAMERACONTROL.
 *
 *  @parm ULONG | ulPropertyId | ID of the property we are touching. It is
 *    either KSPROPERTY_VIDEOPROCAMP_* or KSPROPERTY_CAMERACONTROL_*.
 *
 *  @parm PLONG | plMin | Pointer to a LONG to receive the minimum value.
 *
 *  @parm PLONG | plMax | Pointer to a LONG to receive the maximum value.
 *
 *  @parm PLONG | plStep | Pointer to a LONG to receive the step value.
 ***************************************************************************/
HRESULT CWDMCapDev::GetRangeValues(GUID guidPropertySet, ULONG ulPropertyId, PLONG plMin, PLONG plMax, PLONG plStep)
{
        HRESULT                                 Hr = NOERROR;
        ULONG                                   cbReturned;
        KSPROPERTY                              Property;
        PROCAMP_MEMBERSLIST             proList;

        FX_ENTRY("CWDMCapDev::GetRangeValues")

        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: begin", _fx_));

        // Initialize property structures
        ZeroMemory(&Property, sizeof(KSPROPERTY));
        ZeroMemory(&proList, sizeof(PROCAMP_MEMBERSLIST));

        Property.Set   = guidPropertySet;
        Property.Id    = ulPropertyId;  // e.g. KSPROPERTY_VIDEOPROCAMP_BRIGHTNESS
        Property.Flags = KSPROPERTY_TYPE_BASICSUPPORT;

        // Get range values from the driver
        if (DeviceIoControl(m_hDriver, IOCTL_KS_PROPERTY, &(Property), sizeof(Property), &proList, sizeof(proList), &cbReturned, TRUE) == 0)
        {
                DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: Couldn't *get* the range valuesof the control", _fx_));
                Hr = E_FAIL;
                goto MyExit;
        }

        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: proList.proData.Bounds.SignedMinimum = %ld\r\n", _fx_, proList.proData.Bounds.SignedMinimum));
        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: proList.proData.Bounds.SignedMaximum = %ld\r\n", _fx_, proList.proData.Bounds.SignedMaximum));
        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: proList.proData.SteppingDelta = %ld\r\n", _fx_, proList.proData.SteppingDelta));
        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: proList.proData2.Bounds.SignedMinimum = %ld\r\n", _fx_, proList.proData2.Bounds.SignedMinimum));
        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: proList.proData2.Bounds.SignedMaximum = %ld\r\n", _fx_, proList.proData2.Bounds.SignedMaximum));
        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: proList.proData2.SteppingDelta = %ld\r\n", _fx_, proList.proData2.SteppingDelta));

        *plMin  = proList.proData.Bounds.SignedMinimum;
        *plMax  = proList.proData.Bounds.SignedMaximum;
        *plStep = proList.proData.SteppingDelta;

MyExit:
        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: end", _fx_));
        return Hr;
}

/****************************************************************************
 *  @doc INTERNAL CWDMCAPDEVMETHOD
 *
 *  @mfunc HRESULT | CWDMCapDev | SetPropertyValue | This function sets the
 *    current value of a video property of a capture device.
 *
 *  @parm GUID | guidPropertySet | GUID of the KS property set we are touching. It
 *    is either PROPSETID_VIDCAP_VIDEOPROCAMP or PROPSETID_VIDCAP_CAMERACONTROL.
 *
 *  @parm ULONG | ulPropertyId | ID of the property we are touching. It is
 *    either KSPROPERTY_VIDEOPROCAMP_* or KSPROPERTY_CAMERACONTROL_*.
 *
 *  @parm LONG | lValue | New value.
 *
 *  @parm ULONG | ulFlags | New flags. We only care about KSPROPERTY_*_FLAGS_MANUAL
 *    or KSPROPERTY_*_FLAGS_AUTO.
 *
 *  @parm ULONG | ulCapabilities | New capabilities. We only care about
 *    KSPROPERTY_*_FLAGS_MANUAL or KSPROPERTY_*_FLAGS_AUTO.
 *
 *  @devnote KSPROPERTY_VIDEOPROCAMP_S == KSPROPERTY_CAMERACONTROL_S.
 ***************************************************************************/
HRESULT CWDMCapDev::SetPropertyValue(GUID guidPropertySet, ULONG ulPropertyId, LONG lValue, ULONG ulFlags, ULONG ulCapabilities)
{
        HRESULT                                         Hr = NOERROR;
        ULONG                                           cbReturned;
        KSPROPERTY_VIDEOPROCAMP_S       VideoProperty;

        FX_ENTRY("CWDMCapDev::SetPropertyValue")

        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: begin", _fx_));

        // Initialize property structure
        ZeroMemory(&VideoProperty, sizeof(KSPROPERTY_VIDEOPROCAMP_S) );

        VideoProperty.Property.Set   = guidPropertySet;      // KSPROPERTY_VIDEOPROCAMP_S/CAMERACONTRO_S
        VideoProperty.Property.Id    = ulPropertyId;         // KSPROPERTY_VIDEOPROCAMP_BRIGHTNESS
        VideoProperty.Property.Flags = KSPROPERTY_TYPE_SET;

        VideoProperty.Flags        = ulFlags;
        VideoProperty.Value        = lValue;
        VideoProperty.Capabilities = ulCapabilities;

        // Set the property value on the driver
        if (DeviceIoControl(m_hDriver, IOCTL_KS_PROPERTY, &VideoProperty, sizeof(VideoProperty), &VideoProperty, sizeof(VideoProperty), &cbReturned, TRUE) == 0)
        {
                DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: Couldn't *set* the value of the control", _fx_));
                Hr = E_FAIL;
        }

        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: end", _fx_));
        return Hr;
}

/****************************************************************************
 *  @doc INTERNAL CWDMCAPDEVMETHOD
 *
 *  @mfunc HRESULT | CWDMCapDev | GrabFrame | This method is used to
 *    grab a video frame from a VfW capture device.
 *
 *  @parm PVIDEOHDR | pVHdr | Specifies a pointer to a VIDEOHDR structure to
 *    receive the video frame.
 *
 *  @rdesc This method returns an HRESULT value that depends on the
 *    implementation of the interface. HRESULT can include one of the
 *    following standard constants, or other values not listed:
 *
 *  @flag E_FAIL | Failure
 *  @flag NOERROR | No error
 ***************************************************************************/
HRESULT CWDMCapDev::GrabFrame(PVIDEOHDR pVHdr)
{
        HRESULT                         Hr = NOERROR;
        DWORD                           bRtn;
        DWORD                           cbBytesReturned;
        KS_HEADER_AND_INFO      SHGetImage;

        FX_ENTRY("CWDMCapDev::GrabFrame")

        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: begin", _fx_));

        // Validate input parameters
        ASSERT(pVHdr);
        if (!pVHdr || !pVHdr->lpData)
        {
                DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: Invalid pVHdr, pVHdr->lpData", _fx_));
                Hr = E_UNEXPECTED;
                goto MyExit;
        }

        // Defaults
        pVHdr->dwBytesUsed = 0UL;

        // Put the kernel streaming pin in streaming mode
        if (!Start())
        {
                DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: Cannot set kernel streaming state to KSSTATE_RUN!", _fx_));
                Hr = E_FAIL;
                goto MyExit;
        }

        // Initialize structure to do a read on the kernel streaming video pin
        ZeroMemory(&SHGetImage,sizeof(SHGetImage));
        SHGetImage.StreamHeader.Data = (LPDWORD)pVHdr->lpData;
        SHGetImage.StreamHeader.Size = sizeof (KS_HEADER_AND_INFO);
        SHGetImage.StreamHeader.FrameExtent = pVHdr->dwBufferLength;
        SHGetImage.FrameInfo.ExtendedHeaderSize = sizeof (KS_FRAME_INFO);

        // Grab a frame from the kernel streaming video pin
        bRtn = DeviceIoControl(m_hKSPin, IOCTL_KS_READ_STREAM, &SHGetImage, sizeof(SHGetImage), &SHGetImage, sizeof(SHGetImage), &cbBytesReturned);
        if (!(bRtn))
        {
            DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: DevIo rtn (%d), GetLastError=%d. StreamState->STOP", _fx_, bRtn, GetLastError()));

            // Stop streaming on the video pin
            if (!Stop())
            {
                    DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: Cannot set kernel streaming state to KSSTATE_PAUSE/KSSTATE_STOP!", _fx_));
            }
            Hr = E_FAIL;
            goto MyExit;
        }

        // Sanity check
        ASSERT(SHGetImage.StreamHeader.FrameExtent >= SHGetImage.StreamHeader.DataUsed);
        if (SHGetImage.StreamHeader.FrameExtent < SHGetImage.StreamHeader.DataUsed)
        {
                DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: We've corrupted memory!", _fx_));
                Hr = E_FAIL;
                goto MyExit;
        }

        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: Extended info for video buffer:", _fx_));
        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s:   ExtendedHeaderSize=%ld", _fx_, SHGetImage.FrameInfo.ExtendedHeaderSize));
        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s:   dwFrameFlags=0x%lX", _fx_, SHGetImage.FrameInfo.dwFrameFlags));
        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s:   PictureNumber=%ld", _fx_, SHGetImage.FrameInfo.PictureNumber));
        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s:   DropCount=%ld", _fx_, SHGetImage.FrameInfo.DropCount));
        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s:   Duration=%ld", _fx_, (DWORD)SHGetImage.StreamHeader.Duration));
        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s:   Presentation time:", _fx_));
        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s:     Time=%ld", _fx_, (DWORD)SHGetImage.StreamHeader.PresentationTime.Time));
        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s:     Numerator=%ld", _fx_, (DWORD)SHGetImage.StreamHeader.PresentationTime.Numerator));
        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s:     Denominator=%ld", _fx_, (DWORD)SHGetImage.StreamHeader.PresentationTime.Denominator));

        pVHdr->dwTimeCaptured = timeGetTime();
        pVHdr->dwBytesUsed  = SHGetImage.StreamHeader.DataUsed;
        pVHdr->dwFlags |= VHDR_KEYFRAME;

MyExit:
        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: end", _fx_));
        return Hr;
}

#define BUF_PADDING 512 // required for 1394 allocations alignment

/****************************************************************************
 *  @doc INTERNAL CWDMCAPDEVMETHOD
 *
 *  @mfunc HRESULT | CWDMCapDev | AllocateBuffer | This method is used to allocate
 *    a data buffer when video streaming from a VfW capture device.
 *
 *  @parm LPTHKVIDEOHDR * | pptvh | Specifies the address of a pointer to a
 *    THKVIDEOHDR structure to receive the video buffer.
 *
 *  @parm DWORD | dwIndex | Specifies the positional index of the video buffer.
 *
 *  @parm DWORD | cbBuffer | Specifies the size of the video buffer.
 *
 *  @rdesc This method returns an HRESULT value that depends on the
 *    implementation of the interface. HRESULT can include one of the
 *    following standard constants, or other values not listed:
 *
 *  @flag E_FAIL | Failure
 *  @flag NOERROR | No error
 ***************************************************************************/
HRESULT CWDMCapDev::AllocateBuffer(LPTHKVIDEOHDR *pptvh, DWORD dwIndex, DWORD cbBuffer)
{
        HRESULT Hr = NOERROR;

        FX_ENTRY("CWDMCapDev::AllocateBuffer")

        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: begin", _fx_));

        // Validate input parameters
        ASSERT(pptvh);
        ASSERT(cbBuffer);
        if (!pptvh || !cbBuffer)
        {
                DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: Invalid m_hVideoIn, pptvh, cbVHdr or cbBuffer!", _fx_));
                Hr = E_FAIL;
                goto MyExit;
        }

        *pptvh = &m_pCaptureFilter->m_cs.paHdr[dwIndex].tvh;
        (*pptvh)->vh.dwBufferLength = cbBuffer;
        if (!((*pptvh)->vh.lpData = new BYTE[cbBuffer + BUF_PADDING]))
        {
                Hr = E_FAIL;
                goto MyExit;
        }
        (*pptvh)->p32Buff = (*pptvh)->vh.lpData;

        ASSERT (!IsBadWritePtr((*pptvh)->p32Buff, cbBuffer + BUF_PADDING));
        ZeroMemory((*pptvh)->p32Buff,cbBuffer + BUF_PADDING);
        //save the start in the pStart member ...
        (*pptvh)->pStart  = (*pptvh)->vh.lpData;        //chg:1
        // now align to 512 both p32Buff and vh.lpData
        (*pptvh)->vh.lpData = (LPBYTE)ALIGNUP((*pptvh)->vh.lpData, BUF_PADDING);
        (*pptvh)->p32Buff   = (LPBYTE)ALIGNUP((*pptvh)->p32Buff, BUF_PADDING);

MyExit:
        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: end", _fx_));
        return Hr;
}

/****************************************************************************
 *  @doc INTERNAL CWDMCAPDEVMETHOD
 *
 *  @mfunc HRESULT | CWDMCapDev | AddBuffer | This method is used to
 *    post a data buffer to a VfW capture device when video streaming.
 *
 *  @parm PVIDEOHDR | pVHdr | Specifies a pointer to a
 *    PVIDEOHDR structure identifying the video buffer.
 *
 *  @parm DWORD | cbVHdr | Specifies the size of the structure pointed to by
 *    the <p pVHdr> parameter.
 *
 *  @rdesc This method returns an HRESULT value that depends on the
 *    implementation of the interface. HRESULT can include one of the
 *    following standard constants, or other values not listed:
 *
 *  @flag E_FAIL | Failure
 *  @flag NOERROR | No error
 ***************************************************************************/
HRESULT CWDMCapDev::AddBuffer(PVIDEOHDR pVHdr, DWORD cbVHdr)
{
        HRESULT Hr = NOERROR;
        DWORD dwIndex;

        FX_ENTRY("CWDMCapDev::AddBuffer")

        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: begin", _fx_));

        // Validate input parameters
        ASSERT(pVHdr);
        ASSERT(cbVHdr);
        ASSERT(m_fVideoOpen);
        if (!pVHdr || !cbVHdr || !m_fVideoOpen)
        {
                DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: Invalid pVHdr, cbVHdr, m_fVideoOpen", _fx_));
                Hr = E_UNEXPECTED;
                goto MyExit;
        }

    QueueHeader(pVHdr);

        // Which video streaming buffer are we talking about here?
        for (dwIndex=0; dwIndex < m_pCaptureFilter->m_cs.nHeaders; dwIndex++)
        {
                if (&m_pCaptureFilter->m_cs.paHdr[dwIndex].tvh.vh == pVHdr)
                        break;
        }

        // The video streaming buffer is done if .DataUsed has been initialized
        if (dwIndex != m_pCaptureFilter->m_cs.nHeaders)
        {
                QueueRead(m_pCaptureFilter->m_cs.paHdr[dwIndex].tvh.dwIndex);
        }

MyExit:
        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: end", _fx_));

        return Hr;
}

/****************************************************************************
 *  @doc INTERNAL CWDMCAPDEVMETHOD
 *
 *  @mfunc HRESULT | CWDMCapDev | FreeBuffer | This method is used to
 *    free a data buffer that was used with a VfW capture device in streaming
 *    mode.
 *
 *  @parm PVIDEOHDR | pVHdr | Specifies a pointer to a
 *    PVIDEOHDR structure identifying the video buffer.
 *
 *  @rdesc This method returns an HRESULT value that depends on the
 *    implementation of the interface. HRESULT can include one of the
 *    following standard constants, or other values not listed:
 *
 *  @flag E_FAIL | Failure
 *  @flag NOERROR | No error
 ***************************************************************************/
HRESULT CWDMCapDev::FreeBuffer(LPTHKVIDEOHDR pVHdr) // PVIDEOHDR pVHdr)
{
        HRESULT Hr = NOERROR;

        FX_ENTRY("CWDMCapDev::FreeBuffer")

        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: begin", _fx_));

        // Validate input parameters
        ASSERT(pVHdr);
        if (!pVHdr || !pVHdr->vh.lpData || !pVHdr->p32Buff || !pVHdr->pStart)
        {
                DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: Invalid pVHdr or pVHdr->vh.lpData or pVHdr->pStart!", _fx_));
                Hr = E_POINTER;
                goto MyExit;
        }

        //dprintf("pVHdr->lpData = %p , pVHdr->p32Buff = %p , pVHdr->pStart = %p\n",pVHdr->vh.lpData , pVHdr->p32Buff , pVHdr->pStart);
        //the original code is bad anyway:
        //delete pVHdr->lpData, pVHdr->lpData = NULL; //wrong: lpData might be aligned

        delete pVHdr->pStart, pVHdr->pStart = pVHdr->p32Buff = pVHdr->vh.lpData = NULL;

MyExit:
        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: end", _fx_));
        return Hr;
}

/****************************************************************************
 *  @doc INTERNAL CWDMCAPDEVMETHOD
 *
 *  @mfunc HRESULT | CWDMCapDev | AllocateHeaders | This method is used to
 *    video headers for data buffers used with a WDM capture device in streaming
 *    mode.
 *
 *  @parm DWORD | dwNumHdrs | Specifies the number of video headers to allocate.
 *
 *  @parm DWORD | cbHdr | Specifies the size of the video headers to allocate.
 *
 *  @parm LPVOID* | ppaHdr | Specifies the address of a pointer to receive
 *    the video headers allocated.
 *
 *  @rdesc This method returns an HRESULT value that depends on the
 *    implementation of the interface. HRESULT can include one of the
 *    following standard constants, or other values not listed:
 *
 *  @flag E_FAIL | Failure
 *  @flag NOERROR | No error
 ***************************************************************************/
HRESULT CWDMCapDev::AllocateHeaders(DWORD dwNumHdrs, DWORD cbHdr, LPVOID *ppaHdr)
{
        HRESULT Hr = NOERROR;
        CaptureMode cm;
#if defined(DEBUG) && defined(DEBUG_STREAMING)
        // @todo Remove this before checkin!
        char szDebug[128];
#endif

        FX_ENTRY("CWDMCapDev::AllocateHeaders")

        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: begin", _fx_));

        // Validate input parameters
        ASSERT(ppaHdr);
        ASSERT(cbHdr);
        if (!ppaHdr || !cbHdr)
        {
                DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: Invalid m_hVideoIn, cbHdr or ppaHdr!", _fx_));
                Hr = E_FAIL;
                goto MyExit;
        }

        if (!(*ppaHdr = new BYTE[cbHdr * dwNumHdrs]))
        {
                DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: Out of memory!", _fx_));
                Hr = E_OUTOFMEMORY;
        goto MyExit;
        }

        m_cntNumVidBuf = dwNumHdrs;
        m_lpVHdrFirst = NULL;
        m_lpVHdrLast  = NULL;

        ZeroMemory(*ppaHdr, cbHdr * dwNumHdrs);
        if(m_bCached_vcdi)
                cm = m_vcdi.nCaptureMode;
        else
                cm = g_aDeviceInfo[m_dwDeviceIndex].nCaptureMode;

        if ( cm == CaptureMode_Streaming)
        {
                for (dwNumHdrs = 0; dwNumHdrs < m_cntNumVidBuf; dwNumHdrs++)
                {
                        QueueHeader((LPVIDEOHDR)((LPBYTE)*ppaHdr + cbHdr * dwNumHdrs));
#if defined(DEBUG) && defined(DEBUG_STREAMING)
                        wsprintf(szDebug, "Allocating and queueing pVideoHdr=0x%08lX\n", (LPVIDEOHDR)((LPBYTE)*ppaHdr + cbHdr * dwNumHdrs));
                        OutputDebugString(szDebug);
#endif
                }
        }

MyExit:
        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: end", _fx_));
        return Hr;
}

/****************************************************************************
 *  @doc INTERNAL CWDMCAPDEVMETHOD
 *
 *  @mfunc BOOL | CWDMCapDev | Start | This function puts the kernel streaming
 *    video pin in streaming mode.
 *
 *  @rdesc Returns TRUE if successful, or FALSE otherwise.
 ***************************************************************************/
BOOL CWDMCapDev::Start()
{
        ASSERT(m_hKSPin);

        if (m_fStarted)
                return TRUE;

        if (SetState(KSSTATE_PAUSE))
                m_fStarted = SetState(KSSTATE_RUN);

        return m_fStarted;
}

/****************************************************************************
 *  @doc INTERNAL CWDMCAPDEVMETHOD
 *
 *  @mfunc BOOL | CWDMCapDev | Stop | This function stops streaming on the
 *    kernel streaming video pin.
 *
 *  @rdesc Returns TRUE if successful, or FALSE otherwise.
 ***************************************************************************/
BOOL CWDMCapDev::Stop()
{
        ASSERT(m_hKSPin);

        if (m_fStarted)
        {
                if (SetState(KSSTATE_PAUSE))
                        if (SetState(KSSTATE_STOP))
                                m_fStarted = FALSE;
        }

        return (BOOL)(m_fStarted == FALSE);
}

/****************************************************************************
 *  @doc INTERNAL CWDMCAPDEVMETHOD
 *
 *  @mfunc BOOL | CWDMCapDev | SetState | This function sets the state of the
 *    kernel streaming video pin.
 *
 *  @parm KSSTATE | ksState | New state.
 *
 *  @rdesc Returns TRUE if successful, or FALSE otherwise.
 ***************************************************************************/
BOOL CWDMCapDev::SetState(KSSTATE ksState)
{
        KSPROPERTY      ksProp = {0};
        DWORD           cbRet;

        ASSERT(m_hKSPin);

        ksProp.Set              = KSPROPSETID_Connection;
        ksProp.Id               = KSPROPERTY_CONNECTION_STATE;
        ksProp.Flags    = KSPROPERTY_TYPE_SET;

        return DeviceIoControl(m_hKSPin, IOCTL_KS_PROPERTY, &ksProp, sizeof(ksProp), &ksState, sizeof(KSSTATE), &cbRet);
}

/****************************************************************************
 *  @doc INTERNAL CWDMCAPDEVMETHOD
 *
 *  @mfunc BOOL | CWDMCapDev | IsBufferDone | This method is used to
 *    check the DONE status of a video streaming buffer.
 *
 *  @parm PVIDEOHDR | pVHdr | Specifies a pointer to a
 *    PVIDEOHDR structure identifying the video buffer.
 *
 *  @rdesc This method returns TRUE if the buffer is DONE, FALSE otherwise.
 ***************************************************************************/
BOOL CWDMCapDev::IsBufferDone(PVIDEOHDR pVHdr)
{
        DWORD dwIndex;

        FX_ENTRY("CWDMCapDev::IsBufferDone")

        // Validate input parameter
        ASSERT(pVHdr);
        if (!pVHdr)
                return FALSE;

        // Which video streaming buffer are we talking about here?
        for (dwIndex=0; dwIndex < m_cntNumVidBuf; dwIndex++)
        {
                if (m_pWDMVideoBuff[dwIndex].pVideoHdr == pVHdr)
                        break;
        }


        if(dwIndex == m_cntNumVidBuf) { DWORD i;
                DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: pVHdr %p not found among m_pWDMVideoBuff[0..%d].pVideoHdr values", _fx_,pVHdr,m_cntNumVidBuf));
                for(i=0; i<m_cntNumVidBuf; i++)
                        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: m_pWDMVideoBuff[%d].pVideoHdr %p", _fx_,i,m_pWDMVideoBuff[i].pVideoHdr));
#if defined(DEBUG) && defined(DEBUG_STREAMING)
                ASSERT(dwIndex < m_cntNumVidBuf);
#endif
        }

        // The video streaming buffer is done if .DataUsed has been initialized
        if ((dwIndex != m_cntNumVidBuf) && m_pWDMVideoBuff[dwIndex].SHGetImage.StreamHeader.DataUsed)
        {
            pVHdr->dwFlags |= VHDR_DONE;
                pVHdr->dwBytesUsed = m_pWDMVideoBuff[dwIndex].SHGetImage.StreamHeader.DataUsed;
                if ((m_pWDMVideoBuff[dwIndex].SHGetImage.FrameInfo.dwFrameFlags & 0x00f0) == KS_VIDEO_FLAG_I_FRAME)
                        pVHdr->dwFlags |= VHDR_KEYFRAME;
                return TRUE;
        }
        else
        {
                return FALSE;
        }
}
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\net\tapi\skywalker\filters\video\tapivcap\formats.h ===
/****************************************************************************
 *  @doc INTERNAL FORMATS
 *
 *  @module Formats.h | Header file for the <c CCapturePin> and <c CPreviewPin>
 *    class methods used to implement the video capture and preview output
 *    pin format manipulations. This includes the <i IAMStreamConfig>
 *    interface methods.
 *
 *  @todo That'a whole lot of const data. Do this dynamically whenever
 *    appropriate.
 ***************************************************************************/

#ifndef _FORMATS_H_
#define _FORMATS_H_

// #define USE_OLD_FORMAT_DEFINITION 1

// Video subtypes
#define STATIC_MEDIASUBTYPE_H263_V1 0x3336324DL, 0x0000, 0x0010, 0x80, 0x00, 0x00, 0xAA, 0x00, 0x38, 0x9B, 0x71
#define STATIC_MEDIASUBTYPE_H261 0x3136324DL, 0x0000, 0x0010, 0x80, 0x00, 0x00, 0xAA, 0x00, 0x38, 0x9B, 0x71
#define STATIC_MEDIASUBTYPE_H263_V2 0x3336324EL, 0x0000, 0x0010, 0x80, 0x00, 0x00, 0xAA, 0x00, 0x38, 0x9B, 0x71
#define STATIC_MEDIASUBTYPE_RGB24 0xe436eb7d, 0x524f, 0x11ce, 0x9f, 0x53, 0x00, 0x20, 0xaf, 0x0b, 0xa7, 0x70
#define STATIC_MEDIASUBTYPE_RGB16 0xe436eb7c, 0x524f, 0x11ce, 0x9f, 0x53, 0x00, 0x20, 0xaf, 0x0b, 0xa7, 0x70
#define STATIC_MEDIASUBTYPE_RGB8 0xe436eb7a, 0x524f, 0x11ce, 0x9f, 0x53, 0x00, 0x20, 0xaf, 0x0b, 0xa7, 0x70
#define STATIC_MEDIASUBTYPE_RGB4 0xe436eb79, 0x524f, 0x11ce, 0x9f, 0x53, 0x00, 0x20, 0xaf, 0x0b, 0xa7, 0x70

// Video FourCCs
#ifndef mmioFOURCC
#define mmioFOURCC( ch0, ch1, ch2, ch3 )                                \
                ( (DWORD)(BYTE)(ch0) | ( (DWORD)(BYTE)(ch1) << 8 ) |    \
                ( (DWORD)(BYTE)(ch2) << 16 ) | ( (DWORD)(BYTE)(ch3) << 24 ) )
#endif
#define FOURCC_M263     mmioFOURCC('M', '2', '6', '3')
#define FOURCC_M261     mmioFOURCC('M', '2', '6', '1')
#define FOURCC_N263     mmioFOURCC('N', '2', '6', '3')

// List of capture formats supported
#define MAX_FRAME_INTERVAL 10000000L
#define MIN_FRAME_INTERVAL 333333L
#define STILL_FRAME_INTERVAL 10000000

#define NUM_H245VIDEOCAPABILITYMAPS 5
#define NUM_RATES_PER_RESOURCE 5
#define NUM_ITU_SIZES 3
#define QCIF_SIZE 0
#define CIF_SIZE 1
#define SQCIF_SIZE 2

#define R263_QCIF_H245_CAPID 0UL
#define R263_CIF_H245_CAPID 1UL
#define R263_SQCIF_H245_CAPID 2UL
#define R261_QCIF_H245_CAPID 3UL
#define R261_CIF_H245_CAPID 4UL

/*****************************************************************************
 * @doc EXTERNAL CONSTANTS
 *
 * @const WAVE_FORMAT_UNKNOWN | VIDEO_FORMAT_UNKNOWN | Constant for unknown video format.
 *
 * @const BI_RGB | VIDEO_FORMAT_BI_RGB | RGB video format.
 *
 * @const BI_RLE8 | VIDEO_FORMAT_BI_RLE8 | RLE 8 video format.
 *
 * @const BI_RLE4 | VIDEO_FORMAT_BI_RLE4 | RLE 4 video format.
 *
 * @const BI_BITFIELDS | VIDEO_FORMAT_BI_BITFIELDS | RGB Bit Fields video format.
 *
 * @const MAKEFOURCC('c','v','i','d') | VIDEO_FORMAT_CVID | Cinepack video format.
 *
 * @const MAKEFOURCC('I','V','3','2') | VIDEO_FORMAT_IV32 | Intel Indeo IV32 video format.
 *
 * @const MAKEFOURCC('Y','V','U','9') | VIDEO_FORMAT_YVU9 | Intel Indeo YVU9 video format.
 *
 * @const MAKEFOURCC('M','S','V','C') | VIDEO_FORMAT_MSVC | Microsoft CRAM video format.
 *
 * @const MAKEFOURCC('M','R','L','E') | VIDEO_FORMAT_MRLE | Microsoft RLE video format.
 *
 * @const MAKEFOURCC('h','2','6','3') | VIDEO_FORMAT_INTELH263 | Intel H.263 video format.
 *
 * @const MAKEFOURCC('h','2','6','1') | VIDEO_FORMAT_INTELH261 | Intel H.261 video format.
 *
 * @const MAKEFOURCC('M','2','6','3') | VIDEO_FORMAT_MSH263 | Microsoft H.263 video format.
 *
 * @const MAKEFOURCC('M','2','6','1') | VIDEO_FORMAT_MSH261 | Microsoft H.261 video format.
 *
 * @const MAKEFOURCC('V','D','E','C') | VIDEO_FORMAT_VDEC | Color QuickCam video format.
 *
 ****************************************************************************/
#define VIDEO_FORMAT_UNKNOWN            WAVE_FORMAT_UNKNOWN

#define VIDEO_FORMAT_BI_RGB                     BI_RGB
#define VIDEO_FORMAT_BI_RLE8            BI_RLE8
#define VIDEO_FORMAT_BI_RLE4            BI_RLE4
#define VIDEO_FORMAT_BI_BITFIELDS       BI_BITFIELDS
#define VIDEO_FORMAT_CVID                       MAKEFOURCC('C','V','I','D')     // hex: 0x44495643
#define VIDEO_FORMAT_IV31                       MAKEFOURCC('I','V','3','1')     // hex: 0x31335649
#define VIDEO_FORMAT_IV32                       MAKEFOURCC('I','V','3','2')     // hex: 0x32335649
#define VIDEO_FORMAT_YVU9                       MAKEFOURCC('Y','V','U','9')     // hex: 0x39555659
#define VIDEO_FORMAT_I420                       MAKEFOURCC('I','4','2','0')
#define VIDEO_FORMAT_IYUV                       MAKEFOURCC('I','Y','U','V')
#define VIDEO_FORMAT_MSVC                       MAKEFOURCC('M','S','V','C')     // hex: 0x4356534d
#define VIDEO_FORMAT_MRLE                       MAKEFOURCC('M','R','L','E')     // hex: 0x454c524d
#define VIDEO_FORMAT_INTELH263          MAKEFOURCC('H','2','6','3')     // hex: 0x33363248
#define VIDEO_FORMAT_INTELH261          MAKEFOURCC('H','2','6','1')     // hex: 0x31363248
#define VIDEO_FORMAT_INTELI420          MAKEFOURCC('I','4','2','0')     // hex: 0x30323449
#define VIDEO_FORMAT_INTELRT21          MAKEFOURCC('R','T','2','1')     // hex: 0x31325452
#define VIDEO_FORMAT_MSH263                     MAKEFOURCC('M','2','6','3')     // hex: 0x3336324d
#define VIDEO_FORMAT_MSH261                     MAKEFOURCC('M','2','6','1')     // hex: 0x3136324d
#if !defined(_ALPHA_) && defined(USE_BILINEAR_MSH26X)
#define VIDEO_FORMAT_MSH26X                     MAKEFOURCC('M','2','6','X')     // hex: 0x5836324d
#endif
#define VIDEO_FORMAT_Y411                       MAKEFOURCC('Y','4','1','1')     // hex:
#define VIDEO_FORMAT_YUY2                       MAKEFOURCC('Y','U','Y','2')     // hex:
#define VIDEO_FORMAT_YVYU                       MAKEFOURCC('Y','V','Y','U')     // hex:
#define VIDEO_FORMAT_UYVY                       MAKEFOURCC('U','Y','V','Y')     // hex:
#define VIDEO_FORMAT_Y211                       MAKEFOURCC('Y','2','1','1')     // hex:
// VDOnet VDOWave codec
#define VIDEO_FORMAT_VDOWAVE            MAKEFOURCC('V','D','O','W')     // hex:
// Color QuickCam video codec
#define VIDEO_FORMAT_VDEC                       MAKEFOURCC('V','D','E','C')     // hex: 0x43454456
// Dec Alpha
#define VIDEO_FORMAT_DECH263            MAKEFOURCC('D','2','6','3')     // hex: 0x33363248
#define VIDEO_FORMAT_DECH261            MAKEFOURCC('D','2','6','1')     // hex: 0x31363248
// MPEG4 Scrunch codec
#ifdef USE_MPEG4_SCRUNCH
#define VIDEO_FORMAT_MPEG4_SCRUNCH      MAKEFOURCC('M','P','G','4')     // hex:
#endif

/*****************************************************************************
 * @doc EXTERNAL CONSTANTS
 *
 * @const 16 | NUM_4BIT_ENTRIES | Number of entries in a 4bit palette.
 *
 * @const 256 | NUM_8BIT_ENTRIES | Number of entries in an 8bit palette.
 *
 ****************************************************************************/
#define NUM_4BIT_ENTRIES 16
#define NUM_8BIT_ENTRIES 256

// dwImageSize of VIDEOINCAPS
/*****************************************************************************
 * @doc EXTERNAL CONSTANTS
 *
 * @const 27 | VIDEO_FORMAT_NUM_IMAGE_SIZE | Number of video input sizes used by the device.
 *
 * @const 0x00000001 | VIDEO_FORMAT_IMAGE_SIZE_40_30 | Video input device uses 40x30 pixel frames.
 *
 * @const 0x00000002 | VIDEO_FORMAT_IMAGE_SIZE_64_48 | Video input device uses 64x48 pixel frames.
 *
 * @const 0x00000004 | VIDEO_FORMAT_IMAGE_SIZE_80_60 | Video input device uses 80x60 pixel frames.
 *
 * @const 0x00000008 | VIDEO_FORMAT_IMAGE_SIZE_96_64 | Video input device uses 96x64 pixel frames.
 *
 * @const 0x00000010 | VIDEO_FORMAT_IMAGE_SIZE_112_80 | Video input device uses 112x80 pixel frames.
 *
 * @const 0x00000020 | VIDEO_FORMAT_IMAGE_SIZE_120_90 | Video input device uses 120x90 pixel frames.
 *
 * @const 0x00000040 | VIDEO_FORMAT_IMAGE_SIZE_128_96 | Video input device uses 128x96 (SQCIF) pixel frames.
 *
 * @const 0x00000080 | VIDEO_FORMAT_IMAGE_SIZE_144_112 | Video input device uses 144x112 pixel frames.
 *
 * @const 0x00000100 | VIDEO_FORMAT_IMAGE_SIZE_160_120 | Video input device uses 160x120 pixel frames.
 *
 * @const 0x00000200 | VIDEO_FORMAT_IMAGE_SIZE_160_128 | Video input device uses 160x128 pixel frames.
 *
 * @const 0x00000400 | VIDEO_FORMAT_IMAGE_SIZE_176_144 | Video input device uses 176x144 (QCIF) pixel frames.
 *
 * @const 0x00000800 | VIDEO_FORMAT_IMAGE_SIZE_192_160 | Video input device uses 192x160 pixel frames.
 *
 * @const 0x00001000 | VIDEO_FORMAT_IMAGE_SIZE_200_150 | Video input device uses 200x150 pixel frames.
 *
 * @const 0x00002000 | VIDEO_FORMAT_IMAGE_SIZE_208_176 | Video input device uses 208x176 pixel frames.
 *
 * @const 0x00004000 | VIDEO_FORMAT_IMAGE_SIZE_224_192 | Video input device uses 224x192 pixel frames.
 *
 * @const 0x00008000 | VIDEO_FORMAT_IMAGE_SIZE_240_180 | Video input device uses 240x180 pixel frames.
 *
 * @const 0x00010000 | VIDEO_FORMAT_IMAGE_SIZE_240_208 | Video input device uses 240x208 pixel frames.
 *
 * @const 0x00020000 | VIDEO_FORMAT_IMAGE_SIZE_256_224 | Video input device uses 256x224 pixel frames.
 *
 * @const 0x00040000 | VIDEO_FORMAT_IMAGE_SIZE_272_240 | Video input device uses 272x240 pixel frames.
 *
 * @const 0x00080000 | VIDEO_FORMAT_IMAGE_SIZE_280_210 | Video input device uses 280x210 pixel frames.
 *
 * @const 0x00100000 | VIDEO_FORMAT_IMAGE_SIZE_288_256 | Video input device uses 288x256 pixel frames.
 *
 * @const 0x00200000 | VIDEO_FORMAT_IMAGE_SIZE_304_272 | Video input device uses 304x272 pixel frames.
 *
 * @const 0x00400000 | VIDEO_FORMAT_IMAGE_SIZE_320_240 | Video input device uses 320x240 pixel frames.
 *
 * @const 0x00800000 | VIDEO_FORMAT_IMAGE_SIZE_320_288 | Video input device uses 320x288 pixel frames.
 *
 * @const 0x01000000 | VIDEO_FORMAT_IMAGE_SIZE_336_288 | Video input device uses 336x288 pixel frames.
 *
 * @const 0x02000000 | VIDEO_FORMAT_IMAGE_SIZE_352_288 | Video input device uses 352x288 (CIF) pixel frames.
 *
 * @const 0x04000000 | VIDEO_FORMAT_IMAGE_SIZE_640_480 | Video input device uses 640x480 pixel frames.
 *
 ****************************************************************************/
#define VIDEO_FORMAT_NUM_IMAGE_SIZE     27

#define VIDEO_FORMAT_IMAGE_SIZE_40_30   0x00000001
#define VIDEO_FORMAT_IMAGE_SIZE_64_48   0x00000002
#define VIDEO_FORMAT_IMAGE_SIZE_80_60   0x00000004
#if !defined(_ALPHA_) && defined(USE_BILINEAR_MSH26X)
#define VIDEO_FORMAT_IMAGE_SIZE_80_64   0x00000008
#else
#define VIDEO_FORMAT_IMAGE_SIZE_96_64   0x00000008
#endif
#define VIDEO_FORMAT_IMAGE_SIZE_112_80  0x00000010
#define VIDEO_FORMAT_IMAGE_SIZE_120_90  0x00000020
#define VIDEO_FORMAT_IMAGE_SIZE_128_96  0x00000040
#define VIDEO_FORMAT_IMAGE_SIZE_144_112 0x00000080
#define VIDEO_FORMAT_IMAGE_SIZE_160_120 0x00000100
#define VIDEO_FORMAT_IMAGE_SIZE_160_128 0x00000200
#define VIDEO_FORMAT_IMAGE_SIZE_176_144 0x00000400
#define VIDEO_FORMAT_IMAGE_SIZE_192_160 0x00000800
#define VIDEO_FORMAT_IMAGE_SIZE_200_150 0x00001000
#define VIDEO_FORMAT_IMAGE_SIZE_208_176 0x00002000
#define VIDEO_FORMAT_IMAGE_SIZE_224_192 0x00004000
#define VIDEO_FORMAT_IMAGE_SIZE_240_180 0x00008000
#define VIDEO_FORMAT_IMAGE_SIZE_240_208 0x00010000
#define VIDEO_FORMAT_IMAGE_SIZE_256_224 0x00020000
#define VIDEO_FORMAT_IMAGE_SIZE_272_240 0x00040000
#define VIDEO_FORMAT_IMAGE_SIZE_280_210 0x00080000
#define VIDEO_FORMAT_IMAGE_SIZE_288_256 0x00100000
#define VIDEO_FORMAT_IMAGE_SIZE_304_272 0x00200000
#define VIDEO_FORMAT_IMAGE_SIZE_320_240 0x00400000
#define VIDEO_FORMAT_IMAGE_SIZE_320_288 0x00800000
#define VIDEO_FORMAT_IMAGE_SIZE_336_288 0x01000000
#define VIDEO_FORMAT_IMAGE_SIZE_352_288 0x02000000
#define VIDEO_FORMAT_IMAGE_SIZE_640_480 0x04000000

#define VIDEO_FORMAT_IMAGE_SIZE_USE_DEFAULT 0x80000000

// dwNumColors of VIDEOINCAPS
/*****************************************************************************
 * @doc EXTERNAL CONSTANTS
 *
 * @const 0x00000001 | VIDEO_FORMAT_NUM_COLORS_16 | Video input device uses 16 colors.
 *
 * @const 0x00000002 | VIDEO_FORMAT_NUM_COLORS_256 | Video input device uses 256 colors.
 *
 * @const 0x00000004 | VIDEO_FORMAT_NUM_COLORS_65536 | Video input device uses 65536 colors.
 *
 * @const 0x00000008 | VIDEO_FORMAT_NUM_COLORS_16777216 | Video input device uses 16777216 colors.
 *
 * @const 0x00000010 | VIDEO_FORMAT_NUM_COLORS_YVU9 | Video input device uses the YVU9 compressed format.
 *
 * @const 0x00000020 | VIDEO_FORMAT_NUM_COLORS_I420 | Video input device uses the I420 compressed format.
 *
 * @const 0x00000040 | VIDEO_FORMAT_NUM_COLORS_IYUV | Video input device uses the IYUV compressed format.
 *
 * @const 0x00000080 | VIDEO_FORMAT_NUM_COLORS_YUY2 | Video input device uses the YUY2 compressed format.
 *
 * @const 0x00000100 | VIDEO_FORMAT_NUM_COLORS_UYVY | Video input device uses the UYVY compressed format.
 *
 * @const 0x00000200 | VIDEO_FORMAT_NUM_COLORS_M261 | Video input device uses the M261 compressed format.
 *
 * @const 0x00000400 | VIDEO_FORMAT_NUM_COLORS_M263 | Video input device uses the M263 compressed format.
 ****************************************************************************/
#define VIDEO_FORMAT_NUM_COLORS_16                      0x00000001
#define VIDEO_FORMAT_NUM_COLORS_256                     0x00000002
#define VIDEO_FORMAT_NUM_COLORS_65536           0x00000004
#define VIDEO_FORMAT_NUM_COLORS_16777216        0x00000008
#define VIDEO_FORMAT_NUM_COLORS_YVU9            0x00000010
#define VIDEO_FORMAT_NUM_COLORS_I420            0x00000020
#define VIDEO_FORMAT_NUM_COLORS_IYUV            0x00000040
#define VIDEO_FORMAT_NUM_COLORS_YUY2            0x00000080
#define VIDEO_FORMAT_NUM_COLORS_UYVY            0x00000100
#define VIDEO_FORMAT_NUM_COLORS_MSH261          0x00000200
#define VIDEO_FORMAT_NUM_COLORS_MSH263          0x00000400

// dwDialogs of VIDEOINCAPS
/*****************************************************************************
 * @doc EXTERNAL CONSTANTS
 *
 * @const 0x00000000 | FORMAT_DLG_OFF | Disable video format dialog.
 *
 * @const 0x00000000 | SOURCE_DLG_OFF | Disable source dialog.
 *
 * @const 0x00000000 | DISPLAY_DLG_OFF | Disable display dialog.
 *
 * @const 0x00000001 | FORMAT_DLG_ON | Enable video format dialog.
 *
 * @const 0x00000002 | SOURCE_DLG_ON | Enable source dialog.
 *
 * @const 0x00000002 | DISPLAY_DLG_ON | Enable display dialog.
 ****************************************************************************/
#define FORMAT_DLG_OFF  0x00000000
#define SOURCE_DLG_OFF  0x00000000
#define DISPLAY_DLG_OFF 0x00000000
#define FORMAT_DLG_ON   0x00000001
#define SOURCE_DLG_ON   0x00000002
#define DISPLAY_DLG_ON  0x00000004

// dwStreamingMode of VIDEOINCAPS
/*****************************************************************************
 * @doc EXTERNAL CONSTANTS
 *
 * @const 0x00000000 | STREAM_ALL_SIZES | Use streaming mode at all sizes.
 *
 * @const 0x00000001 | FRAME_GRAB_LARGE_SIZE | Use streaming mode at all but large size (>= 320x240).
 *
 * @const 0x00000002 | FRAME_GRAB_ALL_SIZES | Use frame grabbing mode at all sizes.
 ****************************************************************************/
#define STREAM_ALL_SIZES                0x00000000
#define FRAME_GRAB_LARGE_SIZE   0x00000001
#define FRAME_GRAB_ALL_SIZES    0x00000002

// TAPI Reg keys for capture device formats
#define RTCKEYROOT      HKEY_CURRENT_USER
#define szRegDeviceKey          TEXT("SOFTWARE\\Microsoft\\Conferencing\\CaptureDevices")
#define szRegCaptureDefaultKey  TEXT("SOFTWARE\\Microsoft\\Conferencing\\CaptureDefaultFormats")
#define szRegRTCKey             TEXT("SOFTWARE\\Microsoft\\RTC\\VideoCapture")
#define szRegConferencingKey    TEXT("SOFTWARE\\Microsoft\\Conferencing")
#define szRegdwImageSizeKey       TEXT("dwImageSize")
#define szRegdwNumColorsKey       TEXT("dwNumColors")
#define szRegdwStreamingModeKey   TEXT("dwStreamingMode")
#define szRegdwDialogsKey         TEXT("dwDialogs")
// WinSE #28804, regarding Sony MPEG2 R-Engine
#define szRegdwDoNotUseDShow    TEXT("DoNotUseDShow")
#define SONY_MOTIONEYE_CAM_NAME TEXT("Sony MPEG2 R-Engine")
// @todo Use the two following keys or get rid of them
#define szRegbmi4bitColorsKey   TEXT("bmi4bitColors")
#define szRegbmi8bitColorsKey   TEXT("bmi8bitColors")

#define szDisableYUY2VFlipKey   TEXT("dwDisableYUY2VFlip")

// The order of the bit depths matches what I think is the
// preferred format if more than one is supported.
// For color, 16bit is almost as good as 24 but uses less memory
// and is faster for color QuickCam.
// For greyscale, 16 greyscale levels is Ok, not as good as 64,
// but Greyscale QuickCam is too slow at 64 levels.
#define NUM_BITDEPTH_ENTRIES 11
#define VIDEO_FORMAT_NUM_RESOLUTIONS 6
#define MAX_VERSION 80
extern const WORD aiBitDepth[NUM_BITDEPTH_ENTRIES];
extern const DWORD aiFormat[NUM_BITDEPTH_ENTRIES];
extern const DWORD aiFourCCCode[NUM_BITDEPTH_ENTRIES];
extern const DWORD aiClrUsed[NUM_BITDEPTH_ENTRIES];

typedef struct
{
    DWORD dwRes;
    SIZE framesize;
} MYFRAMESIZE;

extern const MYFRAMESIZE awResolutions[VIDEO_FORMAT_NUM_RESOLUTIONS];

extern const AM_MEDIA_TYPE* const CaptureFormats[];
extern const VIDEO_STREAM_CONFIG_CAPS* const CaptureCaps[];
extern const AM_MEDIA_TYPE* const Preview_RGB24_Formats[];
extern const VIDEO_STREAM_CONFIG_CAPS* const Preview_RGB24_Caps[];
extern const AM_MEDIA_TYPE* const Preview_RGB16_Formats[];
extern const VIDEO_STREAM_CONFIG_CAPS* const Preview_RGB16_Caps[];
extern AM_MEDIA_TYPE* Preview_RGB8_Formats[];
extern const VIDEO_STREAM_CONFIG_CAPS* const Preview_RGB8_Caps[];
extern AM_MEDIA_TYPE* Preview_RGB4_Formats[];
extern const VIDEO_STREAM_CONFIG_CAPS* const Preview_RGB4_Caps[];
extern const AM_MEDIA_TYPE* const Rtp_Pd_Formats[];
extern const RTP_PD_CONFIG_CAPS* const Rtp_Pd_Caps[];
extern const DWORD RTPPayloadTypes[];

#define NUM_RGB24_PREVIEW_FORMATS       3
#define NUM_RGB16_PREVIEW_FORMATS       3
#define NUM_RGB8_PREVIEW_FORMATS        3
#define NUM_RGB4_PREVIEW_FORMATS        3
#define NUM_CAPTURE_FORMATS                     5
#define NUM_RTP_PD_FORMATS                      4

// RTP packetization descriptor formats
#define VERSION_1 1UL
#define H263_PAYLOAD_TYPE 34UL
#define H261_PAYLOAD_TYPE 31UL

#endif // _FORMATS_H_
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\net\tapi\skywalker\filters\video\tapivcap\h245vide.cpp ===
/****************************************************************************
 *  @doc INTERNAL H245VIDE
 *
 *  @module H245VidE.cpp | Source file for the <c CCapturePin> class methods
 *    used to implement the video capture output pin H.245 encoder command
 *    methods.
 ***************************************************************************/

#include "Precomp.h"

/*****************************************************************************
 *  @doc INTERNAL CCAPTUREH245VIDCSTRUCTENUM
 *
 *  @struct VIDEOFASTUPDATEGOB_S | The <t VIDEOFASTUPDATEGOB_S> structure is
 *    used with the KSPROPERTY_H245VIDENCCOMMAND_VIDEOFASTUPDATEGOB property.
 *
 *  @field DWORD | dwFirstGOB | Specifies the number of the first GOB to be
 *    updated. This value is only valid between 0 and 17.
 *
 *  @field DWORD | dwNumberOfGOBs | Specifies the number of GOBs to be
 *    updated. This value is only valid between 1 and 18.
 ***************************************************************************/
typedef struct {
	DWORD dwFirstGOB;
	DWORD dwNumberOfGOBs;
} VIDEOFASTUPDATEGOB_S;

/*****************************************************************************
 *  @doc INTERNAL CCAPTUREH245VIDCSTRUCTENUM
 *
 *  @struct VIDEOFASTUPDATEMB_S | The <t VIDEOFASTUPDATEMB_S> structure is
 *    used with the KSPROPERTY_H245VIDENCCOMMAND_VIDEOFASTUPDATEMB property.
 *
 *  @field DWORD | dwFirstGOB | Specifies the number of the first GOB to be
 *    updated and is only relative to H.263. This value is only valid between
 *    0 and 255.
 *
 *  @field DWORD | dwFirstMB | Specifies the number of the first MB to be
 *    updated and is only relative to H.261. This value is only valid
 *    between 1 and 8192.
 *
 *  @field DWORD | dwNumberOfMBs | Specifies the number of MBs to be
 *    updated. This value is only valid between 1 and 8192.
 ***************************************************************************/
typedef struct {
	DWORD dwFirstGOB;
	DWORD dwFirstMB;
	DWORD dwNumberOfMBs;
} VIDEOFASTUPDATEMB_S;

/*****************************************************************************
 *  @doc INTERNAL CCAPTUREH245VIDCSTRUCTENUM
 *
 *  @struct VIDEONOTDECODEDMBS_S | The <t VIDEONOTDECODEDMBS_S> structure is
 *    used with the KSPROPERTY_H245VIDENCINDICATION_VIDEONOTDECODEDMBS property.
 *
 *  @field DWORD | dwFirstMB | Specifies the number of the first MB treated
 *    as not coded. This value is only valid between 1 and 8192.
 *
 *  @field DWORD | dwNumberOfMBs | Specifies the number of MBs treated as not
 *    coded. This value is only valid between 1 and 8192.
 *
 *  @field DWORD | dwTemporalReference | Specifies the temporal reference of
 *    the picture containing not decoded MBs. This value is only valid
 *    between 0 and 255.
 ***************************************************************************/
typedef struct {
	DWORD dwFirstMB;
	DWORD dwNumberOfMBs;
	DWORD dwTemporalReference;
} VIDEONOTDECODEDMBS_S;

/****************************************************************************
 *  @doc INTERNAL CCAPTUREPINMETHOD
 *
 *  @mfunc HRESULT | CCapturePin | videoFastUpdatePicture | This
 *    method is used to specify to the compressed video output pin to enter
 *    the fast-update picture mode at its earliest opportunity.
 *
 *  @rdesc This method returns an HRESULT value that depends on the
 *    implementation of the interface. HRESULT can include one of the
 *    following standard constants, or other values not listed:
 *
 *  @flag E_FAIL | Failure
 *  @flag E_NOTIMPL | Method is not supported
 *  @flag NOERROR | No error
 ***************************************************************************/
STDMETHODIMP CCapturePin::videoFastUpdatePicture()
{
	HRESULT Hr = NOERROR;

	FX_ENTRY("CCapturePin::videoFastUpdatePicture")

	DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: begin", _fx_));

	// Remember to generate an I-frame 
	m_fFastUpdatePicture = TRUE;

	DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: end", _fx_));
	return Hr;
}

/****************************************************************************
 *  @doc INTERNAL CCAPTUREPINMETHOD
 *
 *  @mfunc HRESULT | CCapturePin | videoFastUpdateGOB | This
 *    method is used to specify to the compressed video output pin to
 *    perform a fast update of one or more GOBs.
 *
 *  @parm DWORD | dwFirstGOB | Specifies the number of the first GOB to be
 *    updated. This value is only valid between 0 and 17.
 *
 *  @parm DWORD | dwNumberOfGOBs | Specifies the number of GOBs to be
 *    updated. This value is only valid between 1 and 18.
 *
 *  @rdesc This method returns an HRESULT value that depends on the
 *    implementation of the interface. HRESULT can include one of the
 *    following standard constants, or other values not listed:
 *
 *  @flag E_FAIL | Failure
 *  @flag E_INVALIDARG | Invalid argument
 *  @flag E_NOTIMPL | Method is not supported
 *  @flag NOERROR | No error
 ***************************************************************************/
STDMETHODIMP CCapturePin::videoFastUpdateGOB(IN DWORD dwFirstGOB, IN DWORD dwNumberOfGOBs)
{
	HRESULT Hr = NOERROR;

	FX_ENTRY("CCapturePin::videoFastUpdateGOB")

	DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: begin", _fx_));

	// Validate input parameters
	ASSERT(dwFirstGOB <= 17);
	ASSERT(dwNumberOfGOBs >= 1 && dwNumberOfGOBs <= 18);
	if (dwFirstGOB > 17 || dwNumberOfGOBs > 18 || dwNumberOfGOBs == 0)
	{
		DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: invalid input parameter", _fx_));
		Hr = E_INVALIDARG;
		goto MyExit;
	}

	// Our encoder does not support this command 
	Hr = E_NOTIMPL;

MyExit:
	DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: end", _fx_));
	return Hr;
}

/****************************************************************************
 *  @doc INTERNAL CCAPTUREPINMETHOD
 *
 *  @mfunc HRESULT | CCapturePin | videoFastUpdateMB | This
 *    method is used to specify to the compressed video output pin to
 *    perform a fast update of one or more GOBs.
 *
 *  @parm DWORD | dwFirstGOB | Specifies the number of the first GOB to be
 *    updated and is only relative to H.263. This value is only valid
 *    between 0 and 255.
 *
 *  @parm DWORD | dwFirstMB | Specifies the number of the first MB to be
 *    updated and is only relative to H.261. This value is only valid
 *    between 1 and 8192.
 *
 *  @parm DWORD | dwNumberOfMBs | Specifies the number of MBs to be updated.
 *    This value is only valid between 1 and 8192.
 *
 *  @rdesc This method returns an HRESULT value that depends on the
 *    implementation of the interface. HRESULT can include one of the
 *    following standard constants, or other values not listed:
 *
 *  @flag E_FAIL | Failure
 *  @flag E_INVALIDARG | Invalid argument
 *  @flag E_NOTIMPL | Method is not supported
 *  @flag NOERROR | No error
 ***************************************************************************/
STDMETHODIMP CCapturePin::videoFastUpdateMB(IN DWORD dwFirstGOB, IN DWORD dwFirstMB, IN DWORD dwNumberOfMBs)
{
	HRESULT Hr = NOERROR;

	FX_ENTRY("CCapturePin::videoFastUpdateMB")

	DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: begin", _fx_));

	// Validate input parameters
	ASSERT(dwFirstGOB <= 255);
	ASSERT(dwFirstMB >= 1 && dwFirstMB <= 8192);
	ASSERT(dwNumberOfMBs >= 1 && dwNumberOfMBs <= 8192);
	if (dwFirstGOB > 255 || dwFirstMB == 0 || dwFirstMB > 8192 || dwNumberOfMBs == 0 || dwNumberOfMBs > 8192)
	{
		DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: invalid input parameter", _fx_));
		Hr = E_INVALIDARG;
		goto MyExit;
	}

	// Our encoder does not support this command 
	Hr = E_NOTIMPL;

MyExit:
	DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: end", _fx_));
	return Hr;
}

/****************************************************************************
 *  @doc INTERNAL CCAPTUREPINMETHOD
 *
 *  @mfunc HRESULT | CCapturePin | videoSendSyncEveryGOB | This
 *    method is used to specify to the compressed video output pin to use
 *    sync for every GOB as defined in H.263.
 *
 *  @parm BOOL | fEnable | If set to TRUE, specifies that the video
 *    output pin should use sync for every GOB; if set to FALSE, specifies
 *    that the video output pin should decide the frequency of GOB syncs on
 *    its own.
 *
 *  @rdesc This method returns an HRESULT value that depends on the
 *    implementation of the interface. HRESULT can include one of the
 *    following standard constants, or other values not listed:
 *
 *  @flag E_FAIL | Failure
 *  @flag E_NOTIMPL | Method is not supported
 *  @flag NOERROR | No error
 ***************************************************************************/
STDMETHODIMP CCapturePin::videoSendSyncEveryGOB(IN BOOL fEnable)
{
	HRESULT Hr = NOERROR;

	FX_ENTRY("CCapturePin::videoSendSyncEveryGOB")

	DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: begin", _fx_));

	// Our encoder does not support this command 
	Hr = E_NOTIMPL;

	DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: end", _fx_));
	return Hr;
}

/****************************************************************************
 *  @doc INTERNAL CCAPTUREPINMETHOD
 *
 *  @mfunc HRESULT | CCapturePin | videoNotDecodedMBs | This
 *    method is used to indicate to the compressed video output pin that a
 *    set of MBs has been received with errors and that any MB in the
 *    specified set has been treated as not coded.
 *
 *  @parm DWORD | dwFirstMB | Specifies the number of the first MB
 *    treated as not coded. This value is only valid between 1 and 8192.
 *
 *  @parm DWORD | dwNumberOfMBs | Specifies the number of MBs treated as not
 *    coded. This value is only valid between 1 and 8192.
 *
 *  @parm DWORD | dwTemporalReference | Specifies the temporal reference of
 *    the picture containing not decoded MBs. This value is only valid
 *    between 0 and 255.
 *
 *  @rdesc This method returns an HRESULT value that depends on the
 *    implementation of the interface. HRESULT can include one of the
 *    following standard constants, or other values not listed:
 *
 *  @flag E_FAIL | Failure
 *  @flag E_INVALIDARG | Invalid argument
 *  @flag E_NOTIMPL | Method is not supported
 *  @flag NOERROR | No error
 ***************************************************************************/
STDMETHODIMP CCapturePin::videoNotDecodedMBs(IN DWORD dwFirstMB, IN DWORD dwNumberOfMBs, IN DWORD dwTemporalReference)
{
	HRESULT Hr = NOERROR;

	FX_ENTRY("CCapturePin::videoNotDecodedMBs")

	DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: begin", _fx_));

	// Validate input parameters
	ASSERT(dwFirstMB >= 1 && dwFirstMB <= 8192);
	ASSERT(dwNumberOfMBs >= 1 && dwNumberOfMBs <= 8192);
	ASSERT(dwTemporalReference <= 255);
	if (dwTemporalReference > 255 || dwFirstMB == 0 || dwFirstMB > 8192 || dwNumberOfMBs == 0 || dwNumberOfMBs > 8192)
	{
		DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: invalid input parameter", _fx_));
		Hr = E_INVALIDARG;
		goto MyExit;
	}

	// Our encoder does not handle this indication
	Hr = E_NOTIMPL;

MyExit:
	DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: end", _fx_));
	return Hr;
}
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\net\tapi\skywalker\filters\video\tapivcap\formats.cpp ===
/****************************************************************************
 *  @doc INTERNAL FORMATS
 *
 *  @module Formats.cpp | Source file for the <c CTAPIBasePin>
 *    class methods used to implement the video capture and preview output
 *    pin format manipulation methods. This includes the <i IAMStreamConfig>
 *    interface methods.
 ***************************************************************************/

#include "Precomp.h"

// H.263 Version 1 CIF size
#define CIF_BUFFER_SIZE 32768
#define D_X_CIF 352
#define D_Y_CIF 288

const VIDEO_STREAM_CONFIG_CAPS VSCC_M26X_Capture_CIF =
{
    STATIC_KSDATAFORMAT_TYPE_VIDEO,                     // GUID
    AnalogVideo_None,                                           // VideoStandard
    D_X_CIF, D_Y_CIF,                                           // InputSize, (the inherent size of the incoming signal with every digitized pixel unique)
    D_X_CIF, D_Y_CIF,                                           // MinCroppingSize, smallest rcSrc cropping rect allowed
    D_X_CIF, D_Y_CIF,                                           // MaxCroppingSize, largest  rcSrc cropping rect allowed
    1,                                                                          // CropGranularityX, granularity of cropping size
    1,                                                                          // CropGranularityY
    1,                                                                          // CropAlignX, alignment of cropping rect
    1,                                                                          // CropAlignY;
    D_X_CIF, D_Y_CIF,                                           // MinOutputSize, smallest bitmap stream can produce
    D_X_CIF, D_Y_CIF,                                           // MaxOutputSize, largest  bitmap stream can produce
    1,                                                                          // OutputGranularityX, granularity of output bitmap size
    1,                                                                          // OutputGranularityY;
    0,                                                                          // StretchTapsX
    0,                                                                          // StretchTapsY
    0,                                                                          // ShrinkTapsX
    0,                                                                          // ShrinkTapsY
    MIN_FRAME_INTERVAL,                                         // MinFrameInterval, 100 nS units
    MAX_FRAME_INTERVAL,                                         // MaxFrameInterval, 100 nS units
    0,                                                                          // MinBitsPerSecond
    CIF_BUFFER_SIZE * 30 * 8                            // MaxBitsPerSecond;
};

const VIDEOINFOHEADER_H263 VIH_M263_Capture_CIF =
{
    0,0,0,0,                                                            // RECT  rcSource;
    0,0,0,0,                                                            // RECT  rcTarget;
    CIF_BUFFER_SIZE * 30 * 8,                           // DWORD dwBitRate;
    0L,                                                                         // DWORD dwBitErrorRate;
    MIN_FRAME_INTERVAL,                                         // REFERENCE_TIME  AvgTimePerFrame;

        {
                sizeof (BITMAPINFOHEADER_H263),         // DWORD biSize;
                D_X_CIF,                                                        // LONG  biWidth;
                D_Y_CIF,                                                        // LONG  biHeight;
                1,                                                                      // WORD  biPlanes;
#ifdef USE_OLD_FORMAT_DEFINITION
                24,                                                                     // WORD  biBitCount;
#else
                0,                                                                      // WORD  biBitCount;
#endif
                FOURCC_M263,                                            // DWORD biCompression;
                CIF_BUFFER_SIZE,                                        // DWORD biSizeImage;
                0,                                                                      // LONG  biXPelsPerMeter;
                0,                                                                      // LONG  biYPelsPerMeter;
                0,                                                                      // DWORD biClrUsed;
                0,                                                                      // DWORD biClrImportant;

#ifndef USE_OLD_FORMAT_DEFINITION
                // H.263 specific fields
                CIF_BUFFER_SIZE * 30 * 8 / 100,     // dwMaxBitrate
                CIF_BUFFER_SIZE * 8 / 1024,                     // dwBppMaxKb
                0,                                                                      // dwHRD_B

                //Options
                0,                                                                      // fUnrestrictedVector
                0,                                                                      // fArithmeticCoding
                0,                                                                      // fAdvancedPrediction
                0,                                                                      // fPBFrames
                0,                                                                      // fErrorCompensation
                0,                                                                      // fAdvancedIntraCodingMode
                0,                                                                      // fDeblockingFilterMode
                0,                                                                      // fImprovedPBFrameMode
                0,                                                                      // fUnlimitedMotionVectors
                0,                                                                      // fFullPictureFreeze
                0,                                                                      // fPartialPictureFreezeAndRelease
                0,                                                                      // fResizingPartPicFreezeAndRelease
                0,                                                                      // fFullPictureSnapshot
                0,                                                                      // fPartialPictureSnapshot
                0,                                                                      // fVideoSegmentTagging
                0,                                                                      // fProgressiveRefinement
                0,                                                                      // fDynamicPictureResizingByFour
                0,                                                                      // fDynamicPictureResizingSixteenthPel
                0,                                                                      // fDynamicWarpingHalfPel
                0,                                                                      // fDynamicWarpingSixteenthPel
                0,                                                                      // fIndependentSegmentDecoding
                0,                                                                      // fSlicesInOrder-NonRect
                0,                                                                      // fSlicesInOrder-Rect
                0,                                                                      // fSlicesNoOrder-NonRect
                0,                                                                      // fSlicesNoOrder-NonRect
                0,                                                                      // fAlternateInterVLCMode
                0,                                                                      // fModifiedQuantizationMode
                0,                                                                      // fReducedResolutionUpdate
                0,                                                                      // fReserved

                // Reserved
                0, 0, 0, 0                                                      // dwReserved[4]
#endif
        }
};

const AM_MEDIA_TYPE AMMT_M263_Capture_CIF =
{
    STATIC_KSDATAFORMAT_TYPE_VIDEO,                     // majortype
    STATIC_MEDIASUBTYPE_H263_V1,                        // subtype
    FALSE,                                                                      // bFixedSizeSamples (all samples same size?)
    TRUE,                                                                       // bTemporalCompression (uses prediction?)
    0,                                                                          // lSampleSize => VBR
    STATIC_KSDATAFORMAT_SPECIFIER_VIDEOINFO,// formattype
        NULL,                                                                   // pUnk
        sizeof (VIH_M263_Capture_CIF),                  // cbFormat
        (LPBYTE)&VIH_M263_Capture_CIF,                  // pbFormat
};

// H.263 Version 1 QCIF size
#define QCIF_BUFFER_SIZE 8192
#define D_X_QCIF 176
#define D_Y_QCIF 144

const VIDEO_STREAM_CONFIG_CAPS VSCC_M26X_Capture_QCIF =
{
    STATIC_KSDATAFORMAT_TYPE_VIDEO,                                             // GUID
    AnalogVideo_None,                                           // VideoStandard
    D_X_QCIF, D_Y_QCIF,                                         // InputSize, (the inherent size of the incoming signal with every digitized pixel unique)
    D_X_QCIF, D_Y_QCIF,                                         // MinCroppingSize, smallest rcSrc cropping rect allowed
    D_X_QCIF, D_Y_QCIF,                                         // MaxCroppingSize, largest  rcSrc cropping rect allowed
    1,                                                                          // CropGranularityX, granularity of cropping size
    1,                                                                          // CropGranularityY
    1,                                                                          // CropAlignX, alignment of cropping rect
    1,                                                                          // CropAlignY;
    D_X_QCIF, D_Y_QCIF,                                         // MinOutputSize, smallest bitmap stream can produce
    D_X_QCIF, D_Y_QCIF,                                         // MaxOutputSize, largest  bitmap stream can produce
    1,                                                                          // OutputGranularityX, granularity of output bitmap size
    1,                                                                          // OutputGranularityY;
    0,                                                                          // StretchTapsX
    0,                                                                          // StretchTapsY
    0,                                                                          // ShrinkTapsX
    0,                                                                          // ShrinkTapsY
    MIN_FRAME_INTERVAL,                                         // MinFrameInterval, 100 nS units
    MAX_FRAME_INTERVAL,                                         // MaxFrameInterval, 100 nS units
    0,                                                                          // MinBitsPerSecond
    QCIF_BUFFER_SIZE * 30 * 8                           // MaxBitsPerSecond;
};

const VIDEOINFOHEADER_H263 VIH_M263_Capture_QCIF =
{
    0,0,0,0,                                                            // RECT  rcSource;
    0,0,0,0,                                                            // RECT  rcTarget;
    QCIF_BUFFER_SIZE * 30 * 8,                          // DWORD dwBitRate;
    0L,                                                                         // DWORD dwBitErrorRate;
    MIN_FRAME_INTERVAL,                                         // REFERENCE_TIME  AvgTimePerFrame;

        {
                sizeof (BITMAPINFOHEADER_H263),         // DWORD biSize;
                D_X_QCIF,                                                       // LONG  biWidth;
                D_Y_QCIF,                                                       // LONG  biHeight;
                1,                                                                      // WORD  biPlanes;
#ifdef USE_OLD_FORMAT_DEFINITION
                24,                                                                     // WORD  biBitCount;
#else
                0,                                                                      // WORD  biBitCount;
#endif
                FOURCC_M263,                                            // DWORD biCompression;
                QCIF_BUFFER_SIZE,                                       // DWORD biSizeImage;
                0,                                                                      // LONG  biXPelsPerMeter;
                0,                                                                      // LONG  biYPelsPerMeter;
                0,                                                                      // DWORD biClrUsed;
                0,                                                                      // DWORD biClrImportant;

#ifndef USE_OLD_FORMAT_DEFINITION
                // H.263 specific fields
                QCIF_BUFFER_SIZE * 30 * 8 / 100,        // dwMaxBitrate
                QCIF_BUFFER_SIZE * 8 / 1024,            // dwBppMaxKb
                0,                                                                      // dwHRD_B

                //Options
                0,                                                                      // fUnrestrictedVector
                0,                                                                      // fArithmeticCoding
                0,                                                                      // fAdvancedPrediction
                0,                                                                      // fPBFrames
                0,                                                                      // fErrorCompensation
                0,                                                                      // fAdvancedIntraCodingMode
                0,                                                                      // fDeblockingFilterMode
                0,                                                                      // fImprovedPBFrameMode
                0,                                                                      // fUnlimitedMotionVectors
                0,                                                                      // fFullPictureFreeze
                0,                                                                      // fPartialPictureFreezeAndRelease
                0,                                                                      // fResizingPartPicFreezeAndRelease
                0,                                                                      // fFullPictureSnapshot
                0,                                                                      // fPartialPictureSnapshot
                0,                                                                      // fVideoSegmentTagging
                0,                                                                      // fProgressiveRefinement
                0,                                                                      // fDynamicPictureResizingByFour
                0,                                                                      // fDynamicPictureResizingSixteenthPel
                0,                                                                      // fDynamicWarpingHalfPel
                0,                                                                      // fDynamicWarpingSixteenthPel
                0,                                                                      // fIndependentSegmentDecoding
                0,                                                                      // fSlicesInOrder-NonRect
                0,                                                                      // fSlicesInOrder-Rect
                0,                                                                      // fSlicesNoOrder-NonRect
                0,                                                                      // fSlicesNoOrder-NonRect
                0,                                                                      // fAlternateInterVLCMode
                0,                                                                      // fModifiedQuantizationMode
                0,                                                                      // fReducedResolutionUpdate
                0,                                                                      // fReserved

                // Reserved
                0, 0, 0, 0                                                      // dwReserved[4]
#endif
        }
};

const AM_MEDIA_TYPE AMMT_M263_Capture_QCIF =
{
    STATIC_KSDATAFORMAT_TYPE_VIDEO,                     // majortype
    STATIC_MEDIASUBTYPE_H263_V1,                        // subtype
    FALSE,                                                                      // bFixedSizeSamples (all samples same size?)
    TRUE,                                                                       // bTemporalCompression (uses prediction?)
    0,                                                                          // lSampleSize => VBR
    STATIC_KSDATAFORMAT_SPECIFIER_VIDEOINFO,// formattype
        NULL,                                                                   // pUnk
        sizeof (VIH_M263_Capture_QCIF),                 // cbFormat
        (LPBYTE)&VIH_M263_Capture_QCIF,                 // pbFormat
};

// H.263 Versions 1 SQCIF size
#define SQCIF_BUFFER_SIZE 8192
#define D_X_SQCIF 128
#define D_Y_SQCIF 96

const VIDEO_STREAM_CONFIG_CAPS VSCC_M263_Capture_SQCIF =
{
    STATIC_KSDATAFORMAT_TYPE_VIDEO,                                             // GUID
    AnalogVideo_None,                                           // VideoStandard
    D_X_SQCIF, D_Y_SQCIF,                                       // InputSize, (the inherent size of the incoming signal with every digitized pixel unique)
    D_X_SQCIF, D_Y_SQCIF,                                       // MinCroppingSize, smallest rcSrc cropping rect allowed
    D_X_SQCIF, D_Y_SQCIF,                                       // MaxCroppingSize, largest  rcSrc cropping rect allowed
    1,                                                                          // CropGranularityX, granularity of cropping size
    1,                                                                          // CropGranularityY
    1,                                                                          // CropAlignX, alignment of cropping rect
    1,                                                                          // CropAlignY;
    D_X_SQCIF, D_Y_SQCIF,                                       // MinOutputSize, smallest bitmap stream can produce
    D_X_SQCIF, D_Y_SQCIF,                                       // MaxOutputSize, largest  bitmap stream can produce
    1,                                                                          // OutputGranularityX, granularity of output bitmap size
    1,                                                                          // OutputGranularityY;
    0,                                                                          // StretchTapsX
    0,                                                                          // StretchTapsY
    0,                                                                          // ShrinkTapsX
    0,                                                                          // ShrinkTapsY
    MIN_FRAME_INTERVAL,                                         // MinFrameInterval, 100 nS units
    MAX_FRAME_INTERVAL,                                         // MaxFrameInterval, 100 nS units
    0,                                                                          // MinBitsPerSecond
    SQCIF_BUFFER_SIZE * 30 * 8                          // MaxBitsPerSecond;
};

const VIDEOINFOHEADER_H263 VIH_M263_Capture_SQCIF =
{
    0,0,0,0,                                                            // RECT  rcSource;
    0,0,0,0,                                                            // RECT  rcTarget;
    SQCIF_BUFFER_SIZE * 30 * 8,                         // DWORD dwBitRate;
    0L,                                                                         // DWORD dwBitErrorRate;
    MIN_FRAME_INTERVAL,                                         // REFERENCE_TIME  AvgTimePerFrame;

        {
                sizeof (BITMAPINFOHEADER_H263),         // DWORD biSize;
                D_X_SQCIF,                                                      // LONG  biWidth;
                D_Y_SQCIF,                                                      // LONG  biHeight;
                1,                                                                      // WORD  biPlanes;
#ifdef USE_OLD_FORMAT_DEFINITION
                24,                                                                     // WORD  biBitCount;
#else
                0,                                                                      // WORD  biBitCount;
#endif
                FOURCC_M263,                                            // DWORD biCompression;
                SQCIF_BUFFER_SIZE,                                      // DWORD biSizeImage;
                0,                                                                      // LONG  biXPelsPerMeter;
                0,                                                                      // LONG  biYPelsPerMeter;
                0,                                                                      // DWORD biClrUsed;
                0,                                                                      // DWORD biClrImportant;

#ifndef USE_OLD_FORMAT_DEFINITION
                // H.263 specific fields
                SQCIF_BUFFER_SIZE * 30 * 8 / 100,       // dwMaxBitrate
                SQCIF_BUFFER_SIZE * 8 / 1024,           // dwBppMaxKb
                0,                                                                      // dwHRD_B

                //Options
                0,                                                                      // fUnrestrictedVector
                0,                                                                      // fArithmeticCoding
                0,                                                                      // fAdvancedPrediction
                0,                                                                      // fPBFrames
                0,                                                                      // fErrorCompensation
                0,                                                                      // fAdvancedIntraCodingMode
                0,                                                                      // fDeblockingFilterMode
                0,                                                                      // fImprovedPBFrameMode
                0,                                                                      // fUnlimitedMotionVectors
                0,                                                                      // fFullPictureFreeze
                0,                                                                      // fPartialPictureFreezeAndRelease
                0,                                                                      // fResizingPartPicFreezeAndRelease
                0,                                                                      // fFullPictureSnapshot
                0,                                                                      // fPartialPictureSnapshot
                0,                                                                      // fVideoSegmentTagging
                0,                                                                      // fProgressiveRefinement
                0,                                                                      // fDynamicPictureResizingByFour
                0,                                                                      // fDynamicPictureResizingSixteenthPel
                0,                                                                      // fDynamicWarpingHalfPel
                0,                                                                      // fDynamicWarpingSixteenthPel
                0,                                                                      // fIndependentSegmentDecoding
                0,                                                                      // fSlicesInOrder-NonRect
                0,                                                                      // fSlicesInOrder-Rect
                0,                                                                      // fSlicesNoOrder-NonRect
                0,                                                                      // fSlicesNoOrder-NonRect
                0,                                                                      // fAlternateInterVLCMode
                0,                                                                      // fModifiedQuantizationMode
                0,                                                                      // fReducedResolutionUpdate
                0,                                                                      // fReserved

                // Reserved
                0, 0, 0, 0                                                      // dwReserved[4]
#endif
        }
};

const AM_MEDIA_TYPE AMMT_M263_Capture_SQCIF =
{
    STATIC_KSDATAFORMAT_TYPE_VIDEO,                     // majortype
    STATIC_MEDIASUBTYPE_H263_V1,                        // subtype
    FALSE,                                                                      // bFixedSizeSamples (all samples same size?)
    TRUE,                                                                       // bTemporalCompression (uses prediction?)
    0,                                                                          // lSampleSize => VBR
    STATIC_KSDATAFORMAT_SPECIFIER_VIDEOINFO,// formattype
        NULL,                                                                   // pUnk
        sizeof (VIH_M263_Capture_SQCIF),                // cbFormat
        (LPBYTE)&VIH_M263_Capture_SQCIF,                // pbFormat
};

// H.261 CIF size
const VIDEOINFOHEADER_H261 VIH_M261_Capture_CIF =
{
    0,0,0,0,                                                            // RECT  rcSource;
    0,0,0,0,                                                            // RECT  rcTarget;
    CIF_BUFFER_SIZE * 30 * 8,                           // DWORD dwBitRate;
    0L,                                                                         // DWORD dwBitErrorRate;
    MIN_FRAME_INTERVAL,                                         // REFERENCE_TIME  AvgTimePerFrame;

        {
                sizeof (BITMAPINFOHEADER_H261),         // DWORD biSize;
                D_X_CIF,                                                        // LONG  biWidth;
                D_Y_CIF,                                                        // LONG  biHeight;
                1,                                                                      // WORD  biPlanes;
#ifdef USE_OLD_FORMAT_DEFINITION
                24,                                                                     // WORD  biBitCount;
#else
                0,                                                                      // WORD  biBitCount;
#endif
                FOURCC_M261,                                            // DWORD biCompression;
                CIF_BUFFER_SIZE,                                        // DWORD biSizeImage;
                0,                                                                      // LONG  biXPelsPerMeter;
                0,                                                                      // LONG  biYPelsPerMeter;
                0,                                                                      // DWORD biClrUsed;
                0,                                                                      // DWORD biClrImportant;

#ifndef USE_OLD_FORMAT_DEFINITION
                // H.261 specific fields
                CIF_BUFFER_SIZE * 30 * 8 / 100,     // dwMaxBitrate
                0,                                                                      // fStillImageTransmission

                // Reserved
                0, 0, 0, 0                                                      // dwReserved[4]
#endif
        }
};

const AM_MEDIA_TYPE AMMT_M261_Capture_CIF =
{
    STATIC_KSDATAFORMAT_TYPE_VIDEO,                     // majortype
    STATIC_MEDIASUBTYPE_H261,                           // subtype
    FALSE,                                                                      // bFixedSizeSamples (all samples same size?)
    TRUE,                                                                       // bTemporalCompression (uses prediction?)
    0,                                                                          // lSampleSize => VBR
    STATIC_KSDATAFORMAT_SPECIFIER_VIDEOINFO,// formattype
        NULL,                                                                   // pUnk
        sizeof (VIH_M261_Capture_CIF),                  // cbFormat
        (LPBYTE)&VIH_M261_Capture_CIF,                  // pbFormat
};

// H.261 QCIF size
const VIDEOINFOHEADER_H261 VIH_M261_Capture_QCIF =
{
    0,0,0,0,                                                            // RECT  rcSource;
    0,0,0,0,                                                            // RECT  rcTarget;
    QCIF_BUFFER_SIZE * 30 * 8,                          // DWORD dwBitRate;
    0L,                                                                         // DWORD dwBitErrorRate;
    MIN_FRAME_INTERVAL,                                         // REFERENCE_TIME  AvgTimePerFrame;

        {
                sizeof (BITMAPINFOHEADER_H261),         // DWORD biSize;
                D_X_QCIF,                                                       // LONG  biWidth;
                D_Y_QCIF,                                                       // LONG  biHeight;
                1,                                                                      // WORD  biPlanes;
#ifdef USE_OLD_FORMAT_DEFINITION
                24,                                                                     // WORD  biBitCount;
#else
                0,                                                                      // WORD  biBitCount;
#endif
                FOURCC_M261,                                            // DWORD biCompression;
                QCIF_BUFFER_SIZE,                                       // DWORD biSizeImage;
                0,                                                                      // LONG  biXPelsPerMeter;
                0,                                                                      // LONG  biYPelsPerMeter;
                0,                                                                      // DWORD biClrUsed;
                0,                                                                      // DWORD biClrImportant;

#ifndef USE_OLD_FORMAT_DEFINITION
                // H.261 specific fields
                QCIF_BUFFER_SIZE * 30 * 8 / 100,        // dwMaxBitrate
                0,                                                                      // fStillImageTransmission

                // Reserved
                0, 0, 0, 0                                                      // dwReserved[4]
#endif
        }
};

const AM_MEDIA_TYPE AMMT_M261_Capture_QCIF =
{
    STATIC_KSDATAFORMAT_TYPE_VIDEO,                     // majortype
    STATIC_MEDIASUBTYPE_H261,                           // subtype
    FALSE,                                                                      // bFixedSizeSamples (all samples same size?)
    TRUE,                                                                       // bTemporalCompression (uses prediction?)
    0,                                                                          // lSampleSize => VBR
    STATIC_KSDATAFORMAT_SPECIFIER_VIDEOINFO,// formattype
        NULL,                                                                   // pUnk
        sizeof (VIH_M261_Capture_QCIF),                 // cbFormat
        (LPBYTE)&VIH_M261_Capture_QCIF,                 // pbFormat
};

// Array of all capture formats
const AM_MEDIA_TYPE* const CaptureFormats[] =
{
    (AM_MEDIA_TYPE*) &AMMT_M263_Capture_QCIF,
    (AM_MEDIA_TYPE*) &AMMT_M263_Capture_CIF,
    (AM_MEDIA_TYPE*) &AMMT_M263_Capture_SQCIF,
    (AM_MEDIA_TYPE*) &AMMT_M261_Capture_QCIF,
    (AM_MEDIA_TYPE*) &AMMT_M261_Capture_CIF
};
const VIDEO_STREAM_CONFIG_CAPS* const CaptureCaps[] =
{
        (VIDEO_STREAM_CONFIG_CAPS*) &VSCC_M26X_Capture_QCIF,
        (VIDEO_STREAM_CONFIG_CAPS*) &VSCC_M26X_Capture_CIF,
        (VIDEO_STREAM_CONFIG_CAPS*) &VSCC_M263_Capture_SQCIF,
        (VIDEO_STREAM_CONFIG_CAPS*) &VSCC_M26X_Capture_QCIF,
        (VIDEO_STREAM_CONFIG_CAPS*) &VSCC_M26X_Capture_CIF
};
const DWORD CaptureCapsStringIDs[] =
{
        (DWORD)IDS_M263_Capture_QCIF,
        (DWORD)IDS_M263_Capture_CIF,
        (DWORD)IDS_M263_Capture_SQCIF,
        (DWORD)IDS_M261_Capture_QCIF,
        (DWORD)IDS_M261_Capture_CIF
};
//165048: accessing the string array below replaces the usage of the string table IDs above (resources not linked in when building common dll)
const WCHAR *CaptureCapsStrings[] =
{
    L"H.263 v.1 QCIF",
    L"H.263 v.1 CIF",
    L"H.263 v.1 SQCIF",
    L"H.261 QCIF",
    L"H.261 CIF"
};


const DWORD RTPPayloadTypes[] =
{
        (DWORD)H263_PAYLOAD_TYPE,
        (DWORD)H263_PAYLOAD_TYPE,
        (DWORD)H263_PAYLOAD_TYPE,
        (DWORD)H261_PAYLOAD_TYPE,
        (DWORD)H261_PAYLOAD_TYPE
};

// RGBx CIF size
#define D_X_CIF 352
#define D_Y_CIF 288
#define RGB24_CIF_BUFFER_SIZE WIDTHBYTES(D_X_CIF * 24) * D_Y_CIF
#define RGB16_CIF_BUFFER_SIZE WIDTHBYTES(D_X_CIF * 16) * D_Y_CIF
#define RGB8_CIF_BUFFER_SIZE WIDTHBYTES(D_X_CIF * 8) * D_Y_CIF
#define RGB4_CIF_BUFFER_SIZE WIDTHBYTES(D_X_CIF * 4) * D_Y_CIF

const VIDEO_STREAM_CONFIG_CAPS VSCC_RGB24_Preview_CIF =
{
    STATIC_KSDATAFORMAT_TYPE_VIDEO,                     // GUID
    AnalogVideo_None,                                           // VideoStandard
    D_X_CIF, D_Y_CIF,                                           // InputSize, (the inherent size of the incoming signal with every digitized pixel unique)
    D_X_CIF, D_Y_CIF,                                           // MinCroppingSize, smallest rcSrc cropping rect allowed
    D_X_CIF, D_Y_CIF,                                           // MaxCroppingSize, largest  rcSrc cropping rect allowed
    1,                                                                          // CropGranularityX, granularity of cropping size
    1,                                                                          // CropGranularityY
    1,                                                                          // CropAlignX, alignment of cropping rect
    1,                                                                          // CropAlignY;
    D_X_CIF, D_Y_CIF,                                           // MinOutputSize, smallest bitmap stream can produce
    D_X_CIF, D_Y_CIF,                                           // MaxOutputSize, largest  bitmap stream can produce
    1,                                                                          // OutputGranularityX, granularity of output bitmap size
    1,                                                                          // OutputGranularityY;
    0,                                                                          // StretchTapsX
    0,                                                                          // StretchTapsY
    0,                                                                          // ShrinkTapsX
    0,                                                                          // ShrinkTapsY
    MIN_FRAME_INTERVAL,                                         // MinFrameInterval, 100 nS units
    MAX_FRAME_INTERVAL,                                         // MaxFrameInterval, 100 nS units
    0,                                                                          // MinBitsPerSecond
    RGB24_CIF_BUFFER_SIZE * 30 * 8                      // MaxBitsPerSecond;
};

const VIDEO_STREAM_CONFIG_CAPS VSCC_RGB16_Preview_CIF =
{
    STATIC_KSDATAFORMAT_TYPE_VIDEO,                     // GUID
    AnalogVideo_None,                                           // VideoStandard
    D_X_CIF, D_Y_CIF,                                           // InputSize, (the inherent size of the incoming signal with every digitized pixel unique)
    D_X_CIF, D_Y_CIF,                                           // MinCroppingSize, smallest rcSrc cropping rect allowed
    D_X_CIF, D_Y_CIF,                                           // MaxCroppingSize, largest  rcSrc cropping rect allowed
    1,                                                                          // CropGranularityX, granularity of cropping size
    1,                                                                          // CropGranularityY
    1,                                                                          // CropAlignX, alignment of cropping rect
    1,                                                                          // CropAlignY;
    D_X_CIF, D_Y_CIF,                                           // MinOutputSize, smallest bitmap stream can produce
    D_X_CIF, D_Y_CIF,                                           // MaxOutputSize, largest  bitmap stream can produce
    1,                                                                          // OutputGranularityX, granularity of output bitmap size
    1,                                                                          // OutputGranularityY;
    0,                                                                          // StretchTapsX
    0,                                                                          // StretchTapsY
    0,                                                                          // ShrinkTapsX
    0,                                                                          // ShrinkTapsY
    MIN_FRAME_INTERVAL,                                         // MinFrameInterval, 100 nS units
    MAX_FRAME_INTERVAL,                                         // MaxFrameInterval, 100 nS units
    0,                                                                          // MinBitsPerSecond
    RGB16_CIF_BUFFER_SIZE * 30 * 8                      // MaxBitsPerSecond;
};

const VIDEO_STREAM_CONFIG_CAPS VSCC_RGB8_Preview_CIF =
{
    STATIC_KSDATAFORMAT_TYPE_VIDEO,                     // GUID
    AnalogVideo_None,                                           // VideoStandard
    D_X_CIF, D_Y_CIF,                                           // InputSize, (the inherent size of the incoming signal with every digitized pixel unique)
    D_X_CIF, D_Y_CIF,                                           // MinCroppingSize, smallest rcSrc cropping rect allowed
    D_X_CIF, D_Y_CIF,                                           // MaxCroppingSize, largest  rcSrc cropping rect allowed
    1,                                                                          // CropGranularityX, granularity of cropping size
    1,                                                                          // CropGranularityY
    1,                                                                          // CropAlignX, alignment of cropping rect
    1,                                                                          // CropAlignY;
    D_X_CIF, D_Y_CIF,                                           // MinOutputSize, smallest bitmap stream can produce
    D_X_CIF, D_Y_CIF,                                           // MaxOutputSize, largest  bitmap stream can produce
    1,                                                                          // OutputGranularityX, granularity of output bitmap size
    1,                                                                          // OutputGranularityY;
    0,                                                                          // StretchTapsX
    0,                                                                          // StretchTapsY
    0,                                                                          // ShrinkTapsX
    0,                                                                          // ShrinkTapsY
    MIN_FRAME_INTERVAL,                                         // MinFrameInterval, 100 nS units
    MAX_FRAME_INTERVAL,                                         // MaxFrameInterval, 100 nS units
    0,                                                                          // MinBitsPerSecond
    RGB8_CIF_BUFFER_SIZE * 30 * 8                       // MaxBitsPerSecond;
};

const VIDEO_STREAM_CONFIG_CAPS VSCC_RGB4_Preview_CIF =
{
    STATIC_KSDATAFORMAT_TYPE_VIDEO,                     // GUID
    AnalogVideo_None,                                           // VideoStandard
    D_X_CIF, D_Y_CIF,                                           // InputSize, (the inherent size of the incoming signal with every digitized pixel unique)
    D_X_CIF, D_Y_CIF,                                           // MinCroppingSize, smallest rcSrc cropping rect allowed
    D_X_CIF, D_Y_CIF,                                           // MaxCroppingSize, largest  rcSrc cropping rect allowed
    1,                                                                          // CropGranularityX, granularity of cropping size
    1,                                                                          // CropGranularityY
    1,                                                                          // CropAlignX, alignment of cropping rect
    1,                                                                          // CropAlignY;
    D_X_CIF, D_Y_CIF,                                           // MinOutputSize, smallest bitmap stream can produce
    D_X_CIF, D_Y_CIF,                                           // MaxOutputSize, largest  bitmap stream can produce
    1,                                                                          // OutputGranularityX, granularity of output bitmap size
    1,                                                                          // OutputGranularityY;
    0,                                                                          // StretchTapsX
    0,                                                                          // StretchTapsY
    0,                                                                          // ShrinkTapsX
    0,                                                                          // ShrinkTapsY
    MIN_FRAME_INTERVAL,                                         // MinFrameInterval, 100 nS units
    MAX_FRAME_INTERVAL,                                         // MaxFrameInterval, 100 nS units
    0,                                                                          // MinBitsPerSecond
    RGB4_CIF_BUFFER_SIZE * 30 * 8                       // MaxBitsPerSecond;
};

const VIDEOINFOHEADER VIH_RGB24_Preview_CIF =
{
    0,0,0,0,                                                            // RECT  rcSource;
    0,0,0,0,                                                            // RECT  rcTarget;
    RGB24_CIF_BUFFER_SIZE * 30 * 8,                     // DWORD dwBitRate;
    0L,                                                                         // DWORD dwBitErrorRate;
    MIN_FRAME_INTERVAL,                                         // REFERENCE_TIME  AvgTimePerFrame;

        {
                sizeof (BITMAPINFOHEADER),                      // DWORD biSize;
                D_X_CIF,                                                        // LONG  biWidth;
                D_Y_CIF,                                                        // LONG  biHeight;
                1,                                                                      // WORD  biPlanes;
                24,                                                                     // WORD  biBitCount;
                0,                                                                      // DWORD biCompression;
                RGB24_CIF_BUFFER_SIZE,                          // DWORD biSizeImage;
                0,                                                                      // LONG  biXPelsPerMeter;
                0,                                                                      // LONG  biYPelsPerMeter;
                0,                                                                      // DWORD biClrUsed;
                0                                                                       // DWORD biClrImportant;
        }
};

const AM_MEDIA_TYPE AMMT_RGB24_Preview_CIF =
{
    STATIC_KSDATAFORMAT_TYPE_VIDEO,                     // majortype
    STATIC_MEDIASUBTYPE_RGB24,                          // subtype
    TRUE,                                                                       // bFixedSizeSamples (all samples same size?)
    FALSE,                                                                      // bTemporalCompression (uses prediction?)
    RGB24_CIF_BUFFER_SIZE,                                      // lSampleSize => !VBR
    STATIC_KSDATAFORMAT_SPECIFIER_VIDEOINFO,// formattype
        NULL,                                                                   // pUnk
        sizeof (VIH_RGB24_Preview_CIF),                 // cbFormat
        (LPBYTE)&VIH_RGB24_Preview_CIF,                 // pbFormat
};

const VIDEOINFOHEADER VIH_RGB16_Preview_CIF =
{
    0,0,0,0,                                                            // RECT  rcSource;
    0,0,0,0,                                                            // RECT  rcTarget;
    RGB16_CIF_BUFFER_SIZE * 30 * 8,                     // DWORD dwBitRate;
    0L,                                                                         // DWORD dwBitErrorRate;
    MIN_FRAME_INTERVAL,                                         // REFERENCE_TIME  AvgTimePerFrame;

        {
                sizeof (BITMAPINFOHEADER),                      // DWORD biSize;
                D_X_CIF,                                                        // LONG  biWidth;
                D_Y_CIF,                                                        // LONG  biHeight;
                1,                                                                      // WORD  biPlanes;
                16,                                                                     // WORD  biBitCount;
                0,                                                                      // DWORD biCompression;
                RGB16_CIF_BUFFER_SIZE,                          // DWORD biSizeImage;
                0,                                                                      // LONG  biXPelsPerMeter;
                0,                                                                      // LONG  biYPelsPerMeter;
                0,                                                                      // DWORD biClrUsed;
                0                                                                       // DWORD biClrImportant;
        }
};

const AM_MEDIA_TYPE AMMT_RGB16_Preview_CIF =
{
    STATIC_KSDATAFORMAT_TYPE_VIDEO,                     // majortype
    STATIC_MEDIASUBTYPE_RGB16,                          // subtype
    TRUE,                                                                       // bFixedSizeSamples (all samples same size?)
    FALSE,                                                                      // bTemporalCompression (uses prediction?)
    RGB16_CIF_BUFFER_SIZE,                                      // lSampleSize => !VBR
    STATIC_KSDATAFORMAT_SPECIFIER_VIDEOINFO,// formattype
        NULL,                                                                   // pUnk
        sizeof (VIH_RGB16_Preview_CIF),                 // cbFormat
        (LPBYTE)&VIH_RGB16_Preview_CIF,                 // pbFormat
};

VIDEOINFO VIH_RGB8_Preview_CIF =
{
    0,0,0,0,                                                            // RECT  rcSource;
    0,0,0,0,                                                            // RECT  rcTarget;
    RGB8_CIF_BUFFER_SIZE * 30 * 8,                      // DWORD dwBitRate;
    0L,                                                                         // DWORD dwBitErrorRate;
    MIN_FRAME_INTERVAL,                                         // REFERENCE_TIME  AvgTimePerFrame;

        {
                sizeof (BITMAPINFOHEADER),                      // DWORD biSize;
                D_X_CIF,                                                        // LONG  biWidth;
                D_Y_CIF,                                                        // LONG  biHeight;
                1,                                                                      // WORD  biPlanes;
                8,                                                                      // WORD  biBitCount;
                0,                                                                      // DWORD biCompression;
                RGB8_CIF_BUFFER_SIZE,                           // DWORD biSizeImage;
                0,                                                                      // LONG  biXPelsPerMeter;
                0,                                                                      // LONG  biYPelsPerMeter;
                256,                                                            // DWORD biClrUsed;
                256                                                                     // DWORD biClrImportant;
        },

        // Palette
        {0}
};

AM_MEDIA_TYPE AMMT_RGB8_Preview_CIF =
{
    STATIC_KSDATAFORMAT_TYPE_VIDEO,                     // majortype
    STATIC_MEDIASUBTYPE_RGB8,                           // subtype
    TRUE,                                                                       // bFixedSizeSamples (all samples same size?)
    FALSE,                                                                      // bTemporalCompression (uses prediction?)
    RGB8_CIF_BUFFER_SIZE,                                       // lSampleSize => !VBR
    STATIC_KSDATAFORMAT_SPECIFIER_VIDEOINFO,// formattype
        NULL,                                                                   // pUnk
        sizeof (VIH_RGB8_Preview_CIF),                  // cbFormat
        (LPBYTE)&VIH_RGB8_Preview_CIF,                  // pbFormat
};

VIDEOINFO VIH_RGB4_Preview_CIF =
{
    0,0,0,0,                                                            // RECT  rcSource;
    0,0,0,0,                                                            // RECT  rcTarget;
    RGB4_CIF_BUFFER_SIZE * 30 * 8,                      // DWORD dwBitRate;
    0L,                                                                         // DWORD dwBitErrorRate;
    MIN_FRAME_INTERVAL,                                         // REFERENCE_TIME  AvgTimePerFrame;

        {
                sizeof (BITMAPINFOHEADER),                      // DWORD biSize;
                D_X_CIF,                                                        // LONG  biWidth;
                D_Y_CIF,                                                        // LONG  biHeight;
                1,                                                                      // WORD  biPlanes;
                4,                                                                      // WORD  biBitCount;
                0,                                                                      // DWORD biCompression;
                RGB4_CIF_BUFFER_SIZE,                           // DWORD biSizeImage;
                0,                                                                      // LONG  biXPelsPerMeter;
                0,                                                                      // LONG  biYPelsPerMeter;
                16,                                                                     // DWORD biClrUsed;
                16                                                                      // DWORD biClrImportant;
        },

        // Palette
        {0}
};

AM_MEDIA_TYPE AMMT_RGB4_Preview_CIF =
{
    STATIC_KSDATAFORMAT_TYPE_VIDEO,                     // majortype
    STATIC_MEDIASUBTYPE_RGB4,                           // subtype
    TRUE,                                                                       // bFixedSizeSamples (all samples same size?)
    FALSE,                                                                      // bTemporalCompression (uses prediction?)
    RGB4_CIF_BUFFER_SIZE,                                       // lSampleSize => !VBR
    STATIC_KSDATAFORMAT_SPECIFIER_VIDEOINFO,// formattype
        NULL,                                                                   // pUnk
        sizeof (VIH_RGB4_Preview_CIF),                  // cbFormat
        (LPBYTE)&VIH_RGB4_Preview_CIF,                  // pbFormat
};

// RGBx QCIF size
#define RGB24_QCIF_BUFFER_SIZE WIDTHBYTES(D_X_QCIF * 24) * D_Y_QCIF
#define RGB16_QCIF_BUFFER_SIZE WIDTHBYTES(D_X_QCIF * 16) * D_Y_QCIF
#define RGB8_QCIF_BUFFER_SIZE WIDTHBYTES(D_X_QCIF * 8) * D_Y_QCIF
#define RGB4_QCIF_BUFFER_SIZE WIDTHBYTES(D_X_QCIF * 4) * D_Y_QCIF

const VIDEO_STREAM_CONFIG_CAPS VSCC_RGB24_Preview_QCIF =
{
    STATIC_KSDATAFORMAT_TYPE_VIDEO,                     // GUID
    AnalogVideo_None,                                           // VideoStandard
    D_X_QCIF, D_Y_QCIF,                                         // InputSize, (the inherent size of the incoming signal with every digitized pixel unique)
    D_X_QCIF, D_Y_QCIF,                                         // MinCroppingSize, smallest rcSrc cropping rect allowed
    D_X_QCIF, D_Y_QCIF,                                         // MaxCroppingSize, largest  rcSrc cropping rect allowed
    1,                                                                          // CropGranularityX, granularity of cropping size
    1,                                                                          // CropGranularityY
    1,                                                                          // CropAlignX, alignment of cropping rect
    1,                                                                          // CropAlignY;
    D_X_QCIF, D_Y_QCIF,                                         // MinOutputSize, smallest bitmap stream can produce
    D_X_QCIF, D_Y_QCIF,                                         // MaxOutputSize, largest  bitmap stream can produce
    1,                                                                          // OutputGranularityX, granularity of output bitmap size
    1,                                                                          // OutputGranularityY;
    0,                                                                          // StretchTapsX
    0,                                                                          // StretchTapsY
    0,                                                                          // ShrinkTapsX
    0,                                                                          // ShrinkTapsY
    MIN_FRAME_INTERVAL,                                         // MinFrameInterval, 100 nS units
    MAX_FRAME_INTERVAL,                                         // MaxFrameInterval, 100 nS units
    0,                                                                          // MinBitsPerSecond
    RGB24_QCIF_BUFFER_SIZE * 30 * 8                     // MaxBitsPerSecond;
};

const VIDEO_STREAM_CONFIG_CAPS VSCC_RGB16_Preview_QCIF =
{
    STATIC_KSDATAFORMAT_TYPE_VIDEO,                     // GUID
    AnalogVideo_None,                                           // VideoStandard
    D_X_QCIF, D_Y_QCIF,                                         // InputSize, (the inherent size of the incoming signal with every digitized pixel unique)
    D_X_QCIF, D_Y_QCIF,                                         // MinCroppingSize, smallest rcSrc cropping rect allowed
    D_X_QCIF, D_Y_QCIF,                                         // MaxCroppingSize, largest  rcSrc cropping rect allowed
    1,                                                                          // CropGranularityX, granularity of cropping size
    1,                                                                          // CropGranularityY
    1,                                                                          // CropAlignX, alignment of cropping rect
    1,                                                                          // CropAlignY;
    D_X_QCIF, D_Y_QCIF,                                         // MinOutputSize, smallest bitmap stream can produce
    D_X_QCIF, D_Y_QCIF,                                         // MaxOutputSize, largest  bitmap stream can produce
    1,                                                                          // OutputGranularityX, granularity of output bitmap size
    1,                                                                          // OutputGranularityY;
    0,                                                                          // StretchTapsX
    0,                                                                          // StretchTapsY
    0,                                                                          // ShrinkTapsX
    0,                                                                          // ShrinkTapsY
    MIN_FRAME_INTERVAL,                                         // MinFrameInterval, 100 nS units
    MAX_FRAME_INTERVAL,                                         // MaxFrameInterval, 100 nS units
    0,                                                                          // MinBitsPerSecond
    RGB16_QCIF_BUFFER_SIZE * 30 * 8                     // MaxBitsPerSecond;
};

const VIDEO_STREAM_CONFIG_CAPS VSCC_RGB8_Preview_QCIF =
{
    STATIC_KSDATAFORMAT_TYPE_VIDEO,                     // GUID
    AnalogVideo_None,                                           // VideoStandard
    D_X_QCIF, D_Y_QCIF,                                         // InputSize, (the inherent size of the incoming signal with every digitized pixel unique)
    D_X_QCIF, D_Y_QCIF,                                         // MinCroppingSize, smallest rcSrc cropping rect allowed
    D_X_QCIF, D_Y_QCIF,                                         // MaxCroppingSize, largest  rcSrc cropping rect allowed
    1,                                                                          // CropGranularityX, granularity of cropping size
    1,                                                                          // CropGranularityY
    1,                                                                          // CropAlignX, alignment of cropping rect
    1,                                                                          // CropAlignY;
    D_X_QCIF, D_Y_QCIF,                                         // MinOutputSize, smallest bitmap stream can produce
    D_X_QCIF, D_Y_QCIF,                                         // MaxOutputSize, largest  bitmap stream can produce
    1,                                                                          // OutputGranularityX, granularity of output bitmap size
    1,                                                                          // OutputGranularityY;
    0,                                                                          // StretchTapsX
    0,                                                                          // StretchTapsY
    0,                                                                          // ShrinkTapsX
    0,                                                                          // ShrinkTapsY
    MIN_FRAME_INTERVAL,                                         // MinFrameInterval, 100 nS units
    MAX_FRAME_INTERVAL,                                         // MaxFrameInterval, 100 nS units
    0,                                                                          // MinBitsPerSecond
    RGB8_QCIF_BUFFER_SIZE * 30 * 8                      // MaxBitsPerSecond;
};

const VIDEO_STREAM_CONFIG_CAPS VSCC_RGB4_Preview_QCIF =
{
    STATIC_KSDATAFORMAT_TYPE_VIDEO,                     // GUID
    AnalogVideo_None,                                           // VideoStandard
    D_X_QCIF, D_Y_QCIF,                                         // InputSize, (the inherent size of the incoming signal with every digitized pixel unique)
    D_X_QCIF, D_Y_QCIF,                                         // MinCroppingSize, smallest rcSrc cropping rect allowed
    D_X_QCIF, D_Y_QCIF,                                         // MaxCroppingSize, largest  rcSrc cropping rect allowed
    1,                                                                          // CropGranularityX, granularity of cropping size
    1,                                                                          // CropGranularityY
    1,                                                                          // CropAlignX, alignment of cropping rect
    1,                                                                          // CropAlignY;
    D_X_QCIF, D_Y_QCIF,                                         // MinOutputSize, smallest bitmap stream can produce
    D_X_QCIF, D_Y_QCIF,                                         // MaxOutputSize, largest  bitmap stream can produce
    1,                                                                          // OutputGranularityX, granularity of output bitmap size
    1,                                                                          // OutputGranularityY;
    0,                                                                          // StretchTapsX
    0,                                                                          // StretchTapsY
    0,                                                                          // ShrinkTapsX
    0,                                                                          // ShrinkTapsY
    MIN_FRAME_INTERVAL,                                         // MinFrameInterval, 100 nS units
    MAX_FRAME_INTERVAL,                                         // MaxFrameInterval, 100 nS units
    0,                                                                          // MinBitsPerSecond
    RGB4_QCIF_BUFFER_SIZE * 30 * 8                      // MaxBitsPerSecond;
};

const VIDEOINFOHEADER VIH_RGB24_Preview_QCIF =
{
    0,0,0,0,                                                            // RECT  rcSource;
    0,0,0,0,                                                            // RECT  rcTarget;
    RGB24_QCIF_BUFFER_SIZE * 30 * 8,            // DWORD dwBitRate;
    0L,                                                                         // DWORD dwBitErrorRate;
    MIN_FRAME_INTERVAL,                                         // REFERENCE_TIME  AvgTimePerFrame;

        {
                sizeof (BITMAPINFOHEADER),                      // DWORD biSize;
                D_X_QCIF,                                                       // LONG  biWidth;
                D_Y_QCIF,                                                       // LONG  biHeight;
                1,                                                                      // WORD  biPlanes;
                24,                                                                     // WORD  biBitCount;
                0,                                                                      // DWORD biCompression;
                RGB24_QCIF_BUFFER_SIZE,                         // DWORD biSizeImage;
                0,                                                                      // LONG  biXPelsPerMeter;
                0,                                                                      // LONG  biYPelsPerMeter;
                0,                                                                      // DWORD biClrUsed;
                0                                                                       // DWORD biClrImportant;
        }
};

const AM_MEDIA_TYPE AMMT_RGB24_Preview_QCIF =
{
    STATIC_KSDATAFORMAT_TYPE_VIDEO,                     // majortype
    STATIC_MEDIASUBTYPE_RGB24,                          // subtype
    TRUE,                                                                       // bFixedSizeSamples (all samples same size?)
    FALSE,                                                                      // bTemporalCompression (uses prediction?)
    RGB24_QCIF_BUFFER_SIZE,                                     // lSampleSize => !VBR
    STATIC_KSDATAFORMAT_SPECIFIER_VIDEOINFO,// formattype
        NULL,                                                                   // pUnk
        sizeof (VIH_RGB24_Preview_QCIF),                // cbFormat
        (LPBYTE)&VIH_RGB24_Preview_QCIF,                // pbFormat
};

const VIDEOINFOHEADER VIH_RGB16_Preview_QCIF =
{
    0,0,0,0,                                                            // RECT  rcSource;
    0,0,0,0,                                                            // RECT  rcTarget;
    RGB16_QCIF_BUFFER_SIZE * 30 * 8,                    // DWORD dwBitRate;
    0L,                                                                         // DWORD dwBitErrorRate;
    MIN_FRAME_INTERVAL,                                         // REFERENCE_TIME  AvgTimePerFrame;

        {
                sizeof (BITMAPINFOHEADER),                      // DWORD biSize;
                D_X_QCIF,                                                       // LONG  biWidth;
                D_Y_QCIF,                                                       // LONG  biHeight;
                1,                                                                      // WORD  biPlanes;
                16,                                                                     // WORD  biBitCount;
                0,                                                                      // DWORD biCompression;
                RGB16_QCIF_BUFFER_SIZE,                         // DWORD biSizeImage;
                0,                                                                      // LONG  biXPelsPerMeter;
                0,                                                                      // LONG  biYPelsPerMeter;
                0,                                                                      // DWORD biClrUsed;
                0                                                                       // DWORD biClrImportant;
        }
};

const AM_MEDIA_TYPE AMMT_RGB16_Preview_QCIF =
{
    STATIC_KSDATAFORMAT_TYPE_VIDEO,                     // majortype
    STATIC_MEDIASUBTYPE_RGB16,                          // subtype
    TRUE,                                                                       // bFixedSizeSamples (all samples same size?)
    FALSE,                                                                      // bTemporalCompression (uses prediction?)
    RGB16_QCIF_BUFFER_SIZE,                                     // lSampleSize => !VBR
    STATIC_KSDATAFORMAT_SPECIFIER_VIDEOINFO,// formattype
        NULL,                                                                   // pUnk
        sizeof (VIH_RGB16_Preview_QCIF),                // cbFormat
        (LPBYTE)&VIH_RGB16_Preview_QCIF,                // pbFormat
};

VIDEOINFO VIH_RGB8_Preview_QCIF =
{
    0,0,0,0,                                                            // RECT  rcSource;
    0,0,0,0,                                                            // RECT  rcTarget;
    RGB8_QCIF_BUFFER_SIZE * 30 * 8,                     // DWORD dwBitRate;
    0L,                                                                         // DWORD dwBitErrorRate;
    MIN_FRAME_INTERVAL,                                         // REFERENCE_TIME  AvgTimePerFrame;

        {
                sizeof (BITMAPINFOHEADER),                      // DWORD biSize;
                D_X_QCIF,                                                       // LONG  biWidth;
                D_Y_QCIF,                                                       // LONG  biHeight;
                1,                                                                      // WORD  biPlanes;
                8,                                                                      // WORD  biBitCount;
                0,                                                                      // DWORD biCompression;
                RGB8_QCIF_BUFFER_SIZE,                          // DWORD biSizeImage;
                0,                                                                      // LONG  biXPelsPerMeter;
                0,                                                                      // LONG  biYPelsPerMeter;
                256,                                                            // DWORD biClrUsed;
                256                                                                     // DWORD biClrImportant;
        },

        // Palette
        {0}
};

AM_MEDIA_TYPE AMMT_RGB8_Preview_QCIF =
{
    STATIC_KSDATAFORMAT_TYPE_VIDEO,                     // majortype
    STATIC_MEDIASUBTYPE_RGB8,                           // subtype
    TRUE,                                                                       // bFixedSizeSamples (all samples same size?)
    FALSE,                                                                      // bTemporalCompression (uses prediction?)
    RGB8_QCIF_BUFFER_SIZE,                                      // lSampleSize => !VBR
    STATIC_KSDATAFORMAT_SPECIFIER_VIDEOINFO,// formattype
        NULL,                                                                   // pUnk
        sizeof (VIH_RGB8_Preview_QCIF),                 // cbFormat
        (LPBYTE)&VIH_RGB8_Preview_QCIF,                 // pbFormat
};

VIDEOINFO VIH_RGB4_Preview_QCIF =
{
    0,0,0,0,                                                            // RECT  rcSource;
    0,0,0,0,                                                            // RECT  rcTarget;
    RGB4_QCIF_BUFFER_SIZE * 30 * 8,                     // DWORD dwBitRate;
    0L,                                                                         // DWORD dwBitErrorRate;
    MIN_FRAME_INTERVAL,                                         // REFERENCE_TIME  AvgTimePerFrame;

        {
                sizeof (BITMAPINFOHEADER),                      // DWORD biSize;
                D_X_QCIF,                                                       // LONG  biWidth;
                D_Y_QCIF,                                                       // LONG  biHeight;
                1,                                                                      // WORD  biPlanes;
                4,                                                                      // WORD  biBitCount;
                0,                                                                      // DWORD biCompression;
                RGB4_QCIF_BUFFER_SIZE,                          // DWORD biSizeImage;
                0,                                                                      // LONG  biXPelsPerMeter;
                0,                                                                      // LONG  biYPelsPerMeter;
                16,                                                                     // DWORD biClrUsed;
                16                                                                      // DWORD biClrImportant;
        },

        // Palette
        {0}
};

AM_MEDIA_TYPE AMMT_RGB4_Preview_QCIF =
{
    STATIC_KSDATAFORMAT_TYPE_VIDEO,                     // majortype
    STATIC_MEDIASUBTYPE_RGB4,                           // subtype
    TRUE,                                                                       // bFixedSizeSamples (all samples same size?)
    FALSE,                                                                      // bTemporalCompression (uses prediction?)
    RGB4_QCIF_BUFFER_SIZE,                                      // lSampleSize => !VBR
    STATIC_KSDATAFORMAT_SPECIFIER_VIDEOINFO,// formattype
        NULL,                                                                   // pUnk
        sizeof (VIH_RGB4_Preview_QCIF),                 // cbFormat
        (LPBYTE)&VIH_RGB4_Preview_QCIF,                 // pbFormat
};

// RGBx SQCIF size
#define RGB24_SQCIF_BUFFER_SIZE WIDTHBYTES(D_X_SQCIF * 24) * D_Y_SQCIF
#define RGB16_SQCIF_BUFFER_SIZE WIDTHBYTES(D_X_SQCIF * 16) * D_Y_SQCIF
#define RGB8_SQCIF_BUFFER_SIZE WIDTHBYTES(D_X_SQCIF * 8) * D_Y_SQCIF
#define RGB4_SQCIF_BUFFER_SIZE WIDTHBYTES(D_X_SQCIF * 4) * D_Y_SQCIF

const VIDEO_STREAM_CONFIG_CAPS VSCC_RGB24_Preview_SQCIF =
{
    STATIC_KSDATAFORMAT_TYPE_VIDEO,                     // GUID
    AnalogVideo_None,                                           // VideoStandard
    D_X_SQCIF, D_Y_SQCIF,                                       // InputSize, (the inherent size of the incoming signal with every digitized pixel unique)
    D_X_SQCIF, D_Y_SQCIF,                                       // MinCroppingSize, smallest rcSrc cropping rect allowed
    D_X_SQCIF, D_Y_SQCIF,                                       // MaxCroppingSize, largest  rcSrc cropping rect allowed
    1,                                                                          // CropGranularityX, granularity of cropping size
    1,                                                                          // CropGranularityY
    1,                                                                          // CropAlignX, alignment of cropping rect
    1,                                                                          // CropAlignY;
    D_X_SQCIF, D_Y_SQCIF,                                       // MinOutputSize, smallest bitmap stream can produce
    D_X_SQCIF, D_Y_SQCIF,                                       // MaxOutputSize, largest  bitmap stream can produce
    1,                                                                          // OutputGranularityX, granularity of output bitmap size
    1,                                                                          // OutputGranularityY;
    0,                                                                          // StretchTapsX
    0,                                                                          // StretchTapsY
    0,                                                                          // ShrinkTapsX
    0,                                                                          // ShrinkTapsY
    MIN_FRAME_INTERVAL,                                         // MinFrameInterval, 100 nS units
    MAX_FRAME_INTERVAL,                                         // MaxFrameInterval, 100 nS units
    0,                                                                          // MinBitsPerSecond
    RGB24_SQCIF_BUFFER_SIZE * 30 * 8            // MaxBitsPerSecond;
};

const VIDEO_STREAM_CONFIG_CAPS VSCC_RGB16_Preview_SQCIF =
{
    STATIC_KSDATAFORMAT_TYPE_VIDEO,                     // GUID
    AnalogVideo_None,                                           // VideoStandard
    D_X_SQCIF, D_Y_SQCIF,                                       // InputSize, (the inherent size of the incoming signal with every digitized pixel unique)
    D_X_SQCIF, D_Y_SQCIF,                                       // MinCroppingSize, smallest rcSrc cropping rect allowed
    D_X_SQCIF, D_Y_SQCIF,                                       // MaxCroppingSize, largest  rcSrc cropping rect allowed
    1,                                                                          // CropGranularityX, granularity of cropping size
    1,                                                                          // CropGranularityY
    1,                                                                          // CropAlignX, alignment of cropping rect
    1,                                                                          // CropAlignY;
    D_X_SQCIF, D_Y_SQCIF,                                       // MinOutputSize, smallest bitmap stream can produce
    D_X_SQCIF, D_Y_SQCIF,                                       // MaxOutputSize, largest  bitmap stream can produce
    1,                                                                          // OutputGranularityX, granularity of output bitmap size
    1,                                                                          // OutputGranularityY;
    0,                                                                          // StretchTapsX
    0,                                                                          // StretchTapsY
    0,                                                                          // ShrinkTapsX
    0,                                                                          // ShrinkTapsY
    MIN_FRAME_INTERVAL,                                         // MinFrameInterval, 100 nS units
    MAX_FRAME_INTERVAL,                                         // MaxFrameInterval, 100 nS units
    0,                                                                          // MinBitsPerSecond
    RGB16_SQCIF_BUFFER_SIZE * 30 * 8            // MaxBitsPerSecond;
};

const VIDEO_STREAM_CONFIG_CAPS VSCC_RGB8_Preview_SQCIF =
{
    STATIC_KSDATAFORMAT_TYPE_VIDEO,                     // GUID
    AnalogVideo_None,                                           // VideoStandard
    D_X_SQCIF, D_Y_SQCIF,                                       // InputSize, (the inherent size of the incoming signal with every digitized pixel unique)
    D_X_SQCIF, D_Y_SQCIF,                                       // MinCroppingSize, smallest rcSrc cropping rect allowed
    D_X_SQCIF, D_Y_SQCIF,                                       // MaxCroppingSize, largest  rcSrc cropping rect allowed
    1,                                                                          // CropGranularityX, granularity of cropping size
    1,                                                                          // CropGranularityY
    1,                                                                          // CropAlignX, alignment of cropping rect
    1,                                                                          // CropAlignY;
    D_X_SQCIF, D_Y_SQCIF,                                       // MinOutputSize, smallest bitmap stream can produce
    D_X_SQCIF, D_Y_SQCIF,                                       // MaxOutputSize, largest  bitmap stream can produce
    1,                                                                          // OutputGranularityX, granularity of output bitmap size
    1,                                                                          // OutputGranularityY;
    0,                                                                          // StretchTapsX
    0,                                                                          // StretchTapsY
    0,                                                                          // ShrinkTapsX
    0,                                                                          // ShrinkTapsY
    MIN_FRAME_INTERVAL,                                         // MinFrameInterval, 100 nS units
    MAX_FRAME_INTERVAL,                                         // MaxFrameInterval, 100 nS units
    0,                                                                          // MinBitsPerSecond
    RGB8_SQCIF_BUFFER_SIZE * 30 * 8                     // MaxBitsPerSecond;
};

const VIDEO_STREAM_CONFIG_CAPS VSCC_RGB4_Preview_SQCIF =
{
    STATIC_KSDATAFORMAT_TYPE_VIDEO,                     // GUID
    AnalogVideo_None,                                           // VideoStandard
    D_X_SQCIF, D_Y_SQCIF,                                       // InputSize, (the inherent size of the incoming signal with every digitized pixel unique)
    D_X_SQCIF, D_Y_SQCIF,                                       // MinCroppingSize, smallest rcSrc cropping rect allowed
    D_X_SQCIF, D_Y_SQCIF,                                       // MaxCroppingSize, largest  rcSrc cropping rect allowed
    1,                                                                          // CropGranularityX, granularity of cropping size
    1,                                                                          // CropGranularityY
    1,                                                                          // CropAlignX, alignment of cropping rect
    1,                                                                          // CropAlignY;
    D_X_SQCIF, D_Y_SQCIF,                                       // MinOutputSize, smallest bitmap stream can produce
    D_X_SQCIF, D_Y_SQCIF,                                       // MaxOutputSize, largest  bitmap stream can produce
    1,                                                                          // OutputGranularityX, granularity of output bitmap size
    1,                                                                          // OutputGranularityY;
    0,                                                                          // StretchTapsX
    0,                                                                          // StretchTapsY
    0,                                                                          // ShrinkTapsX
    0,                                                                          // ShrinkTapsY
    MIN_FRAME_INTERVAL,                                         // MinFrameInterval, 100 nS units
    MAX_FRAME_INTERVAL,                                         // MaxFrameInterval, 100 nS units
    0,                                                                          // MinBitsPerSecond
    RGB4_SQCIF_BUFFER_SIZE * 30 * 8                     // MaxBitsPerSecond;
};

const VIDEOINFOHEADER VIH_RGB24_Preview_SQCIF =
{
    0,0,0,0,                                                            // RECT  rcSource;
    0,0,0,0,                                                            // RECT  rcTarget;
    RGB24_SQCIF_BUFFER_SIZE * 30 * 8,           // DWORD dwBitRate;
    0L,                                                                         // DWORD dwBitErrorRate;
    MIN_FRAME_INTERVAL,                                         // REFERENCE_TIME  AvgTimePerFrame;

        {
                sizeof (BITMAPINFOHEADER),                      // DWORD biSize;
                D_X_SQCIF,                                                      // LONG  biWidth;
                D_Y_SQCIF,                                                      // LONG  biHeight;
                1,                                                                      // WORD  biPlanes;
                24,                                                                     // WORD  biBitCount;
                0,                                                                      // DWORD biCompression;
                RGB24_SQCIF_BUFFER_SIZE,                        // DWORD biSizeImage;
                0,                                                                      // LONG  biXPelsPerMeter;
                0,                                                                      // LONG  biYPelsPerMeter;
                0,                                                                      // DWORD biClrUsed;
                0                                                                       // DWORD biClrImportant;
        }
};

const AM_MEDIA_TYPE AMMT_RGB24_Preview_SQCIF =
{
    STATIC_KSDATAFORMAT_TYPE_VIDEO,                     // majortype
    STATIC_MEDIASUBTYPE_RGB24,                          // subtype
    TRUE,                                                                       // bFixedSizeSamples (all samples same size?)
    FALSE,                                                                      // bTemporalCompression (uses prediction?)
    RGB24_SQCIF_BUFFER_SIZE,                            // lSampleSize => !VBR
    STATIC_KSDATAFORMAT_SPECIFIER_VIDEOINFO,// formattype
        NULL,                                                                   // pUnk
        sizeof (VIH_RGB24_Preview_SQCIF),               // cbFormat
        (LPBYTE)&VIH_RGB24_Preview_SQCIF,               // pbFormat
};

const VIDEOINFOHEADER VIH_RGB16_Preview_SQCIF =
{
    0,0,0,0,                                                            // RECT  rcSource;
    0,0,0,0,                                                            // RECT  rcTarget;
    RGB16_SQCIF_BUFFER_SIZE * 30 * 8,           // DWORD dwBitRate;
    0L,                                                                         // DWORD dwBitErrorRate;
    MIN_FRAME_INTERVAL,                                         // REFERENCE_TIME  AvgTimePerFrame;

        {
                sizeof (BITMAPINFOHEADER),                      // DWORD biSize;
                D_X_SQCIF,                                                      // LONG  biWidth;
                D_Y_SQCIF,                                                      // LONG  biHeight;
                1,                                                                      // WORD  biPlanes;
                16,                                                                     // WORD  biBitCount;
                0,                                                                      // DWORD biCompression;
                RGB16_SQCIF_BUFFER_SIZE,                        // DWORD biSizeImage;
                0,                                                                      // LONG  biXPelsPerMeter;
                0,                                                                      // LONG  biYPelsPerMeter;
                0,                                                                      // DWORD biClrUsed;
                0                                                                       // DWORD biClrImportant;
        }
};

const AM_MEDIA_TYPE AMMT_RGB16_Preview_SQCIF =
{
    STATIC_KSDATAFORMAT_TYPE_VIDEO,                     // majortype
    STATIC_MEDIASUBTYPE_RGB16,                          // subtype
    TRUE,                                                                       // bFixedSizeSamples (all samples same size?)
    FALSE,                                                                      // bTemporalCompression (uses prediction?)
    RGB16_SQCIF_BUFFER_SIZE,                            // lSampleSize => !VBR
    STATIC_KSDATAFORMAT_SPECIFIER_VIDEOINFO,// formattype
        NULL,                                                                   // pUnk
        sizeof (VIH_RGB16_Preview_SQCIF),               // cbFormat
        (LPBYTE)&VIH_RGB16_Preview_SQCIF,               // pbFormat
};

VIDEOINFO VIH_RGB8_Preview_SQCIF =
{
    0,0,0,0,                                                            // RECT  rcSource;
    0,0,0,0,                                                            // RECT  rcTarget;
    RGB8_SQCIF_BUFFER_SIZE * 30 * 8,                    // DWORD dwBitRate;
    0L,                                                                         // DWORD dwBitErrorRate;
    MIN_FRAME_INTERVAL,                                         // REFERENCE_TIME  AvgTimePerFrame;

        {
                sizeof (BITMAPINFOHEADER),                      // DWORD biSize;
                D_X_SQCIF,                                                      // LONG  biWidth;
                D_Y_SQCIF,                                                      // LONG  biHeight;
                1,                                                                      // WORD  biPlanes;
                8,                                                                      // WORD  biBitCount;
                0,                                                                      // DWORD biCompression;
                RGB8_SQCIF_BUFFER_SIZE,                         // DWORD biSizeImage;
                0,                                                                      // LONG  biXPelsPerMeter;
                0,                                                                      // LONG  biYPelsPerMeter;
                256,                                                            // DWORD biClrUsed;
                256                                                                     // DWORD biClrImportant;
        },

        // Palette
        {0}
};

AM_MEDIA_TYPE AMMT_RGB8_Preview_SQCIF =
{
    STATIC_KSDATAFORMAT_TYPE_VIDEO,                     // majortype
    STATIC_MEDIASUBTYPE_RGB8,                           // subtype
    TRUE,                                                                       // bFixedSizeSamples (all samples same size?)
    FALSE,                                                                      // bTemporalCompression (uses prediction?)
    RGB8_SQCIF_BUFFER_SIZE,                                     // lSampleSize => !VBR
    STATIC_KSDATAFORMAT_SPECIFIER_VIDEOINFO,// formattype
        NULL,                                                                   // pUnk
        sizeof (VIH_RGB8_Preview_SQCIF),                // cbFormat
        (LPBYTE)&VIH_RGB8_Preview_SQCIF,                // pbFormat
};

VIDEOINFO VIH_RGB4_Preview_SQCIF =
{
    0,0,0,0,                                                            // RECT  rcSource;
    0,0,0,0,                                                            // RECT  rcTarget;
    RGB4_SQCIF_BUFFER_SIZE * 30 * 8,            // DWORD dwBitRate;
    0L,                                                                         // DWORD dwBitErrorRate;
    MIN_FRAME_INTERVAL,                                         // REFERENCE_TIME  AvgTimePerFrame;

        {
                sizeof (BITMAPINFOHEADER),                      // DWORD biSize;
                D_X_SQCIF,                                                      // LONG  biWidth;
                D_Y_SQCIF,                                                      // LONG  biHeight;
                1,                                                                      // WORD  biPlanes;
                4,                                                                      // WORD  biBitCount;
                0,                                                                      // DWORD biCompression;
                RGB4_SQCIF_BUFFER_SIZE,                         // DWORD biSizeImage;
                0,                                                                      // LONG  biXPelsPerMeter;
                0,                                                                      // LONG  biYPelsPerMeter;
                16,                                                                     // DWORD biClrUsed;
                16                                                                      // DWORD biClrImportant;
        },

        // Palette
        {0}
};

const AM_MEDIA_TYPE AMMT_RGB4_Preview_SQCIF =
{
    STATIC_KSDATAFORMAT_TYPE_VIDEO,                     // majortype
    STATIC_MEDIASUBTYPE_RGB4,                           // subtype
    TRUE,                                                                       // bFixedSizeSamples (all samples same size?)
    FALSE,                                                                      // bTemporalCompression (uses prediction?)
    RGB4_SQCIF_BUFFER_SIZE,                                     // lSampleSize => !VBR
    STATIC_KSDATAFORMAT_SPECIFIER_VIDEOINFO,// formattype
        NULL,                                                                   // pUnk
        sizeof (VIH_RGB4_Preview_SQCIF),                // cbFormat
        (LPBYTE)&VIH_RGB4_Preview_SQCIF,                // pbFormat
};

// Array of all preview formats
const AM_MEDIA_TYPE* const Preview_RGB24_Formats[] =
{
    (AM_MEDIA_TYPE*) &AMMT_RGB24_Preview_QCIF,
    (AM_MEDIA_TYPE*) &AMMT_RGB24_Preview_CIF,
    (AM_MEDIA_TYPE*) &AMMT_RGB24_Preview_SQCIF
};

const AM_MEDIA_TYPE* const Preview_RGB16_Formats[] =
{
    (AM_MEDIA_TYPE*) &AMMT_RGB16_Preview_QCIF,
    (AM_MEDIA_TYPE*) &AMMT_RGB16_Preview_CIF,
    (AM_MEDIA_TYPE*) &AMMT_RGB16_Preview_SQCIF
};

AM_MEDIA_TYPE* Preview_RGB8_Formats[] =
{
    (AM_MEDIA_TYPE*) &AMMT_RGB8_Preview_QCIF,
    (AM_MEDIA_TYPE*) &AMMT_RGB8_Preview_CIF,
    (AM_MEDIA_TYPE*) &AMMT_RGB8_Preview_SQCIF
};

AM_MEDIA_TYPE* Preview_RGB4_Formats[] =
{
    (AM_MEDIA_TYPE*) &AMMT_RGB4_Preview_QCIF,
    (AM_MEDIA_TYPE*) &AMMT_RGB4_Preview_CIF,
    (AM_MEDIA_TYPE*) &AMMT_RGB4_Preview_SQCIF
};

// Array of all preview caps
const VIDEO_STREAM_CONFIG_CAPS* const Preview_RGB24_Caps[] =
{
        (VIDEO_STREAM_CONFIG_CAPS*) &VSCC_RGB24_Preview_QCIF,
        (VIDEO_STREAM_CONFIG_CAPS*) &VSCC_RGB24_Preview_CIF,
        (VIDEO_STREAM_CONFIG_CAPS*) &VSCC_RGB24_Preview_SQCIF
};

const VIDEO_STREAM_CONFIG_CAPS* const Preview_RGB16_Caps[] =
{
        (VIDEO_STREAM_CONFIG_CAPS*) &VSCC_RGB16_Preview_QCIF,
        (VIDEO_STREAM_CONFIG_CAPS*) &VSCC_RGB16_Preview_CIF,
        (VIDEO_STREAM_CONFIG_CAPS*) &VSCC_RGB16_Preview_SQCIF
};

const VIDEO_STREAM_CONFIG_CAPS* const Preview_RGB8_Caps[] =
{
        (VIDEO_STREAM_CONFIG_CAPS*) &VSCC_RGB8_Preview_QCIF,
        (VIDEO_STREAM_CONFIG_CAPS*) &VSCC_RGB8_Preview_CIF,
        (VIDEO_STREAM_CONFIG_CAPS*) &VSCC_RGB8_Preview_SQCIF
};

const VIDEO_STREAM_CONFIG_CAPS* const Preview_RGB4_Caps[] =
{
        (VIDEO_STREAM_CONFIG_CAPS*) &VSCC_RGB4_Preview_QCIF,
        (VIDEO_STREAM_CONFIG_CAPS*) &VSCC_RGB4_Preview_CIF,
        (VIDEO_STREAM_CONFIG_CAPS*) &VSCC_RGB4_Preview_SQCIF
};

// RTP packetization descriptor formats
#define STATIC_KSDATAFORMAT_TYPE_RTP_PD 0x9e2fb490L, 0x2051, 0x46cd, 0xb9, 0xf0, 0x06, 0x33, 0x07, 0x99, 0x69, 0x35

const RTP_PD_CONFIG_CAPS Rtp_Pd_Cap_H263 =
{
                MIN_RTP_PACKET_SIZE,                            // dwSmallestRTPPacketSize
                MAX_RTP_PACKET_SIZE,                            // dwLargestRTPPacketSize
                1,                                                                      // dwRTPPacketSizeGranularity
                1,                                                                      // dwSmallestNumLayers
                1,                                                                      // dwLargestNumLayers
                0,                                                                      // dwNumLayersGranularity
                1,                                                                      // dwNumStaticPayloadTypes
                H263_PAYLOAD_TYPE, 0, 0, 0,                     // dwStaticPayloadTypes[4]
                1,                                                                      // dwNumDescriptorVersions
                VERSION_1, 0, 0, 0,                                     // dwDescriptorVersions[4]
                0, 0, 0, 0                                                      // dwReserved[4]
};

const RTP_PD_CONFIG_CAPS Rtp_Pd_Cap_H261 =
{
                MIN_RTP_PACKET_SIZE,                            // dwSmallestRTPPacketSize
                MAX_RTP_PACKET_SIZE,                            // dwLargestRTPPacketSize
                1,                                                                      // dwRTPPacketSizeGranularity
                1,                                                                      // dwSmallestNumLayers
                1,                                                                      // dwLargestNumLayers
                0,                                                                      // dwNumLayersGranularity
                1,                                                                      // dwNumStaticPayloadTypes
                H261_PAYLOAD_TYPE, 0, 0, 0,                     // dwStaticPayloadTypes[4]
                1,                                                                      // dwNumDescriptorVersions
                VERSION_1, 0, 0, 0,                                     // dwDescriptorVersions[4]
                0, 0, 0, 0                                                      // dwReserved[4]
};

const RTP_PD_INFO Rtp_Pd_Info_H263_LAN =
{
    MIN_FRAME_INTERVAL,                                 // AvgTimePerFrameDescriptors
    MAX_RTP_PD_BUFFER_SIZE,                             // dwMaxRTPPacketizationDescriptorBufferSize
    12,                                                                 // dwMaxRTPPayloadHeaderSize (Mode C Payload Header)
    DEFAULT_RTP_PACKET_SIZE,                    // dwMaxRTPPacketSize
    1,                                                                  // dwNumLayers
        H263_PAYLOAD_TYPE,                                      // dwPayloadType
        VERSION_1,                                                      // dwDescriptorVersion
        0, 0, 0, 0                                                      // dwReserved[4]
};

const RTP_PD_INFO Rtp_Pd_Info_H263_Internet =
{
    MIN_FRAME_INTERVAL,                                 // AvgTimePerFrameDescriptors
    MAX_RTP_PD_BUFFER_SIZE,                             // dwMaxRTPPacketizationDescriptorBufferSize
    12,                                                                 // dwMaxRTPPayloadHeaderSize (Mode C Payload Header)
    MIN_RTP_PACKET_SIZE,                                // dwMaxRTPPacketSize
    1,                                                                  // dwNumLayers
        H263_PAYLOAD_TYPE,                                      // dwPayloadType
        VERSION_1,                                                      // dwDescriptorVersion
        0, 0, 0, 0                                                      // dwReserved[4]
};

const RTP_PD_INFO Rtp_Pd_Info_H261_LAN =
{
    MIN_FRAME_INTERVAL,                                 // AvgTimePerFrameDescriptors
    MAX_RTP_PD_BUFFER_SIZE,                             // dwMaxRTPPacketizationDescriptorBufferSize
    12,                                                                 // dwMaxRTPPayloadHeaderSize (Mode C Payload Header)
    DEFAULT_RTP_PACKET_SIZE,                    // dwMaxRTPPacketSize
    1,                                                                  // dwNumLayers
        H261_PAYLOAD_TYPE,                                      // dwPayloadType
        VERSION_1,                                                      // dwDescriptorVersion
        0, 0, 0, 0                                                      // dwReserved[4]
};

const RTP_PD_INFO Rtp_Pd_Info_H261_Internet =
{
    MIN_FRAME_INTERVAL,                                 // AvgTimePerFrameDescriptors
    MAX_RTP_PD_BUFFER_SIZE,                             // dwMaxRTPPacketizationDescriptorBufferSize
    12,                                                                 // dwMaxRTPPayloadHeaderSize (Mode C Payload Header)
    MIN_RTP_PACKET_SIZE,                                // dwMaxRTPPacketSize
    1,                                                                  // dwNumLayers
        H261_PAYLOAD_TYPE,                                      // dwPayloadType
        VERSION_1,                                                      // dwDescriptorVersion
        0, 0, 0, 0                                                      // dwReserved[4]
};

const AM_MEDIA_TYPE AMMT_Rtp_Pd_H263_LAN =
{
    STATIC_KSDATAFORMAT_TYPE_RTP_PD,            // majortype
    STATIC_KSDATAFORMAT_SUBTYPE_NONE,           // subtype
    TRUE,                                                                       // bFixedSizeSamples (all samples same size?)
    FALSE,                                                                      // bTemporalCompression (uses prediction?)
    MAX_RTP_PD_BUFFER_SIZE,                                     // lSampleSize => !VBR
    STATIC_KSDATAFORMAT_SPECIFIER_NONE,         // formattype
        NULL,                                                                   // pUnk
        sizeof (Rtp_Pd_Info_H263_LAN),                  // cbFormat
        (LPBYTE)&Rtp_Pd_Info_H263_LAN                   // pbFormat
};

const AM_MEDIA_TYPE AMMT_Rtp_Pd_H263_Internet =
{
    STATIC_KSDATAFORMAT_TYPE_RTP_PD,            // majortype
    STATIC_KSDATAFORMAT_SUBTYPE_NONE,           // subtype
    TRUE,                                                                       // bFixedSizeSamples (all samples same size?)
    FALSE,                                                                      // bTemporalCompression (uses prediction?)
    MAX_RTP_PD_BUFFER_SIZE,                                     // lSampleSize => !VBR
    STATIC_KSDATAFORMAT_SPECIFIER_NONE,         // formattype
        NULL,                                                                   // pUnk
        sizeof (Rtp_Pd_Info_H263_Internet),             // cbFormat
        (LPBYTE)&Rtp_Pd_Info_H263_Internet              // pbFormat
};

const AM_MEDIA_TYPE AMMT_Rtp_Pd_H261_LAN =
{
    STATIC_KSDATAFORMAT_TYPE_RTP_PD,            // majortype
    STATIC_KSDATAFORMAT_SUBTYPE_NONE,           // subtype
    TRUE,                                                                       // bFixedSizeSamples (all samples same size?)
    FALSE,                                                                      // bTemporalCompression (uses prediction?)
    MAX_RTP_PD_BUFFER_SIZE,                                     // lSampleSize => !VBR
    STATIC_KSDATAFORMAT_SPECIFIER_NONE,         // formattype
        NULL,                                                                   // pUnk
        sizeof (Rtp_Pd_Info_H261_LAN),                  // cbFormat
        (LPBYTE)&Rtp_Pd_Info_H261_LAN                   // pbFormat
};

const AM_MEDIA_TYPE AMMT_Rtp_Pd_H261_Internet =
{
    STATIC_KSDATAFORMAT_TYPE_RTP_PD,            // majortype
    STATIC_KSDATAFORMAT_SUBTYPE_NONE,           // subtype
    TRUE,                                                                       // bFixedSizeSamples (all samples same size?)
    FALSE,                                                                      // bTemporalCompression (uses prediction?)
    MAX_RTP_PD_BUFFER_SIZE,                                     // lSampleSize => !VBR
    STATIC_KSDATAFORMAT_SPECIFIER_NONE,         // formattype
        NULL,                                                                   // pUnk
        sizeof (Rtp_Pd_Info_H261_Internet),             // cbFormat
        (LPBYTE)&Rtp_Pd_Info_H261_Internet              // pbFormat
};

// Array of all RTP packetization descriptor formats
const AM_MEDIA_TYPE* const Rtp_Pd_Formats[] =
{
    (AM_MEDIA_TYPE*) &AMMT_Rtp_Pd_H263_LAN,
    (AM_MEDIA_TYPE*) &AMMT_Rtp_Pd_H263_Internet,
    (AM_MEDIA_TYPE*) &AMMT_Rtp_Pd_H261_LAN,
    (AM_MEDIA_TYPE*) &AMMT_Rtp_Pd_H261_Internet
};

// Array of all RTP packetization descriptor caps
const RTP_PD_CONFIG_CAPS* const Rtp_Pd_Caps[] =
{
        (RTP_PD_CONFIG_CAPS*) &Rtp_Pd_Cap_H263,
        (RTP_PD_CONFIG_CAPS*) &Rtp_Pd_Cap_H263,
        (RTP_PD_CONFIG_CAPS*) &Rtp_Pd_Cap_H261,
        (RTP_PD_CONFIG_CAPS*) &Rtp_Pd_Cap_H261
};

/****************************************************************************
 *  @doc INTERNAL CBASEPINMETHOD
 *
 *  @mfunc HRESULT | CTAPIBasePin | Reconnect | This method is used to
 *    reconnect a pin to a downstream pin with a new format.
 *
 *  @rdesc This method returns an HRESULT value that depends on the
 *    implementation of the interface. HRESULT can include one of the
 *    following standard constants, or other values not listed:
 *
 *  @flag E_FAIL | Failure
 *  @flag NOERROR | No error
 ***************************************************************************/
HRESULT CTAPIBasePin::Reconnect()
{
        HRESULT hr = NOERROR;

        FX_ENTRY("CTAPIBasePin::Reconnect")

        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: begin", _fx_));

    hr = SetFormat(&m_mt);

        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: end, hr=%x", _fx_, hr));

        return hr;
}

/****************************************************************************
 *  @doc INTERNAL CBASEPINMETHOD
 *
 *  @mfunc HRESULT | CTAPIBasePin | SetFormat | This method is used to
 *    set a specific media type on a pin.
 *
 *  @parm AM_MEDIA_TYPE* | pmt | Specifies a pointer to an <t AM_MEDIA_TYPE>
 *    structure.
 *
 *  @rdesc This method returns an HRESULT value that depends on the
 *    implementation of the interface. HRESULT can include one of the
 *    following standard constants, or other values not listed:
 *
 *  @flag E_FAIL | Failure
 *  @flag E_POINTER | Null pointer argument
 *  @flag E_INVALIDARG | Invalid argument
 *  @flag NOERROR | No error
 ***************************************************************************/
STDMETHODIMP CTAPIBasePin::SetFormat(IN AM_MEDIA_TYPE *pmt)
{
        HRESULT hr = NOERROR;
        BOOL    fWasStreaming = FALSE;

        FX_ENTRY("CTAPIBasePin::SetFormat")

        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: begin", _fx_));

    // To make sure we're not in the middle of start/stop streaming
    CAutoLock cObjectLock(m_pCaptureFilter->m_pLock);

        // Validate input parameters
        ASSERT(pmt);
        if (!pmt)
        {
                DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: Invalid input parameter!", _fx_));
                hr = E_POINTER;
                goto MyExit;
        }

        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s:   Trying to set %s %dx%d", _fx_, HEADER(pmt->pbFormat)->biCompression == FOURCC_M263 ? "H.263" : HEADER(pmt->pbFormat)->biCompression == FOURCC_M261 ? "H.261" : "????", HEADER(pmt->pbFormat)->biWidth, HEADER(pmt->pbFormat)->biHeight));

        // If this is the same format as we already are using, don't bother
    if (m_mt == *pmt)
                goto MyExit;

        // See if we like this type
        if (FAILED(hr = CheckMediaType((CMediaType *)pmt)))
        {
                DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: Format rejected!", _fx_));
                goto MyExit;
        }

        // If we are currently capturing data, stop this process before changing the format
        if (m_pCaptureFilter->ThdExists() && m_pCaptureFilter->m_state != TS_Stop)
        {
                // Remember that we were streaming
                fWasStreaming = TRUE;

                // Tell the worker thread to stop and begin cleaning up
                m_pCaptureFilter->StopThd();

                // Wait for the worker thread to die
                m_pCaptureFilter->DestroyThd();
        }

        if (FAILED(hr = SetMediaType((CMediaType *)pmt)))
    {
                DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s: SetMediaType failed! hr = ", _fx_, hr));
                goto MyExit;
    }

        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s:   Format set successfully", _fx_));

    // Let the fun restart
        if (fWasStreaming)
        {
                // Re-create the capture thread
                if (!m_pCaptureFilter->CreateThd())
                {
                        DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: Coutdn't create the capture thread!", _fx_));
                        hr = E_FAIL;
                        goto MyExit;
                }

                // Wait until the worker thread is done with initialization and has entered the paused state
                if (!m_pCaptureFilter->PauseThd())
                {
                        // Something went wrong. Destroy thread before we get confused
                        DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: Capture thread failed to enter Paused state!", _fx_));
                        hr = E_FAIL;
                        m_pCaptureFilter->StopThd();
                        m_pCaptureFilter->DestroyThd();
                }

                // Let the fun begin
                if (!m_pCaptureFilter->RunThd() || m_pCaptureFilter->m_state != TS_Run)
                {
                        DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: Couldn't run the capture thread!", _fx_));
                        hr = E_FAIL;
                        goto MyExit;
                }
        }

MyExit:
        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: end", _fx_));
        return hr;
}

/****************************************************************************
 *  @doc INTERNAL CBASEPINMETHOD
 *
 *  @mfunc HRESULT | CTAPIBasePin | GetFormat | This method is used to
 *    retrieve the current media type on a pin.
 *
 *  @parm AM_MEDIA_TYPE** | ppmt | Specifies the address of a pointer to an
 *    <t AM_MEDIA_TYPE> structure.
 *
 *  @rdesc This method returns an HRESULT value that depends on the
 *    implementation of the interface. HRESULT can include one of the
 *    following standard constants, or other values not listed:
 *
 *  @flag E_FAIL | Failure
 *  @flag E_POINTER | Null pointer argument
 *  @flag NOERROR | No error
 *
 *  @comm Note that we return the output type, not the format at which
 *    we are capturing. Only the filter really cares about how the data is
 *    being captured.
 ***************************************************************************/
STDMETHODIMP CTAPIBasePin::GetFormat(OUT AM_MEDIA_TYPE **ppmt)
{
        HRESULT Hr = NOERROR;

        FX_ENTRY("CTAPIBasePin::GetFormat")

        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: begin", _fx_));

        // Validate input parameters
        ASSERT(ppmt);
        if (!ppmt)
        {
                DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: Null pointer argument", _fx_));
                Hr = E_POINTER;
                goto MyExit;
        }

        // Return a copy of our current format
        *ppmt = CreateMediaType(&m_mt);

MyExit:
        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: end", _fx_));
        return Hr;
}

/****************************************************************************
 *  @doc INTERNAL CBASEPINMETHOD
 *
 *  @mfunc HRESULT | CTAPIBasePin | GetNumberOfCapabilities | This method is
 *    used to retrieve the number of stream capabilities structures.
 *
 *  @parm int* | piCount | Specifies a pointer to an int to receive the
 *    number of <t VIDEO_STREAM_CONFIG_CAPS> structures supported.
 *
 *  @parm int* | piSize | Specifies a pointer to an int to receive the
 *    size of the <t VIDEO_STREAM_CONFIG_CAPS> configuration structure.
 *
 *  @rdesc This method returns an HRESULT value that depends on the
 *    implementation of the interface. HRESULT can include one of the
 *    following standard constants, or other values not listed:
 *
 *  @flag E_FAIL | Failure
 *  @flag E_POINTER | Null pointer argument
 *  @flag NOERROR | No error
 ***************************************************************************/
STDMETHODIMP CTAPIBasePin::GetNumberOfCapabilities(OUT int *piCount, OUT int *piSize)
{
        HRESULT Hr = NOERROR;

        FX_ENTRY("CTAPIBasePin::GetNumberOfCapabilities")

        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: begin", _fx_));

        // Validate input parameters
        ASSERT(piCount);
        ASSERT(piSize);
        if (!piCount || !piSize)
        {
                DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: Null pointer argument", _fx_));
                Hr = E_POINTER;
                goto MyExit;
        }

        // Return releavant info
        *piCount = m_dwNumFormats;
        *piSize = sizeof(VIDEO_STREAM_CONFIG_CAPS);

        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s:   Returning %ld formats of max size %ld bytes", _fx_, *piCount, *piSize));

MyExit:
        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: end", _fx_));
        return Hr;
}

/****************************************************************************
 *  @doc INTERNAL CBASEPINMETHOD
 *
 *  @mfunc HRESULT | CTAPIBasePin | GetStreamCaps | This method is
 *    used to retrieve a video stream capability pair.
 *
 *  @parm int | iIndex | Specifies the index to the desired media type
 *    and capability pair.
 *
 *  @parm AM_MEDIA_TYPE** | ppmt | Specifies the address of a pointer to an
 *    <t AM_MEDIA_TYPE> structure.
 *
 *  @parm LPBYTE | pSCC | Specifies a pointer to a
 *    <t VIDEO_STREAM_CONFIG_CAPS> configuration structure.
 *
 *  @rdesc This method returns an HRESULT value that depends on the
 *    implementation of the interface. HRESULT can include one of the
 *    following standard constants, or other values not listed:
 *
 *  @flag E_FAIL | Failure
 *  @flag E_POINTER | Null pointer argument
 *  @flag E_INVALIDARG | Invalid argument
 *  @flag NOERROR | No error
 ***************************************************************************/
STDMETHODIMP CTAPIBasePin::GetStreamCaps(IN int iIndex, OUT AM_MEDIA_TYPE **ppmt, OUT LPBYTE pSCC)
{
        HRESULT Hr = NOERROR;

        FX_ENTRY("CTAPIBasePin::GetStreamCaps")

        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: begin", _fx_));

        // Validate input parameters
        ASSERT(iIndex < (int)m_dwNumFormats);
        if (!(iIndex < (int)m_dwNumFormats))
        {
                DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: Invalid iIndex argument!", _fx_));
                Hr = E_INVALIDARG;
                goto MyExit;
        }

        // Return a copy of the requested AM_MEDIA_TYPE structure
    if (ppmt)
    {
            if (!(*ppmt = CreateMediaType(m_aFormats[iIndex])))
            {
                    DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: Out of memory!", _fx_));
                    Hr = E_OUTOFMEMORY;
                    goto MyExit;
            }
    }

        // Return a copy of the requested VIDEO_STREAM_CONFIG_CAPS structure
    if (pSCC)
    {
            CopyMemory(pSCC, m_aCapabilities[iIndex], sizeof(VIDEO_STREAM_CONFIG_CAPS));
    }

        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s:   Returning format index %ld: %s %ld bpp %ldx%ld", _fx_, iIndex, HEADER(m_aFormats[iIndex]->pbFormat)->biCompression == FOURCC_M263 ? "H.263" : HEADER(m_aFormats[iIndex]->pbFormat)->biCompression == FOURCC_M261 ? "H.261" : HEADER(m_aFormats[iIndex]->pbFormat)->biCompression == BI_RGB ? "RGB" : "????", HEADER(m_aFormats[iIndex]->pbFormat)->biBitCount, HEADER(m_aFormats[iIndex]->pbFormat)->biWidth, HEADER(m_aFormats[iIndex]->pbFormat)->biHeight));

MyExit:
        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: end", _fx_));
        return Hr;
}

/****************************************************************************
 *  @doc INTERNAL CBASEPINMETHOD
 *
 *  @mfunc HRESULT | CTAPIBasePin | GetMediaType | This method retrieves one
 *    of the media types supported by the pin, which is used by enumerators.
 *
 *  @parm int | iPosition | Specifies a position in the media type list.
 *
 *  @parm CMediaType* | pMediaType | Specifies a pointer to the media type at
 *    the <p iPosition> position in the list of supported media types.
 *
 *  @rdesc This method returns an HRESULT value that depends on the
 *    implementation of the interface. HRESULT can include one of the
 *    following standard constants, or other values not listed:
 *
 *  @flag E_FAIL | Failure
 *  @flag E_POINTER | Null pointer argument
 *  @flag E_INVALIDARG | Invalid argument
 *  @flag VFW_S_NO_MORE_ITEMS | End of the list of media types has been reached
 *  @flag NOERROR | No error
 ***************************************************************************/
HRESULT CTAPIBasePin::GetMediaType(IN int iPosition, OUT CMediaType *pMediaType)
{
        HRESULT Hr = NOERROR;

        FX_ENTRY("CTAPIBasePin::GetMediaType")

        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: begin", _fx_));

        // Validate input parameters
        ASSERT(iPosition >= 0);
        ASSERT(pMediaType);
        if (iPosition < 0)
        {
                DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: Invalid iPosition argument", _fx_));
                Hr = E_INVALIDARG;
                goto MyExit;
        }
        if (iPosition >= (int)m_dwNumFormats)
        {
                DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   WARNING: End of the list of media types has been reached", _fx_));
                Hr = VFW_S_NO_MORE_ITEMS;
                goto MyExit;
        }
        if (!pMediaType)
        {
                DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: Null pointer argument", _fx_));
                Hr = E_POINTER;
                goto MyExit;
        }

        // Return our media type
        if (m_iCurrFormat == -1L)
                *pMediaType = *m_aFormats[iPosition];
        else
        {
                if (iPosition == 0L)
                        *pMediaType = *m_aFormats[m_iCurrFormat];
                else
                        Hr = VFW_S_NO_MORE_ITEMS;
        }

MyExit:
        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: end", _fx_));
        return Hr;
}

/****************************************************************************
 *  @doc INTERNAL CBASEPINMETHOD
 *
 *  @mfunc HRESULT | CTAPIBasePin | CheckMediaType | This method is used to
 *    determine if the pin can support a specific media type.
 *
 *  @parm CMediaType* | pMediaType | Specifies a pointer to the media type.
 *
 *  @rdesc This method returns an HRESULT value that depends on the
 *    implementation of the interface. HRESULT can include one of the
 *    following standard constants, or other values not listed:
 *
 *  @flag E_FAIL | Failure
 *  @flag E_POINTER | Null pointer argument
 *  @flag E_INVALIDARG | Invalid argument
 *  @flag VFW_E_INVALIDMEDIATYPE | An invalid media type was specified
 *  @flag NOERROR | No error
 ***************************************************************************/
HRESULT CTAPIBasePin::CheckMediaType(IN const CMediaType *pMediaType)
{
        HRESULT Hr = NOERROR;
        BOOL fFormatMatch = FALSE;
        DWORD dwIndex;

        FX_ENTRY("CTAPIBasePin::CheckMediaType")

        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: begin", _fx_));

        // Validate input parameters
        ASSERT(pMediaType);
        if (!pMediaType || !pMediaType->pbFormat)
        {
                DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: Null pointer argument", _fx_));
                Hr = E_POINTER;
                goto MyExit;
        }


        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s:   Checking %s (%x) %dbpp %dx%d", _fx_,
            HEADER(pMediaType->pbFormat)->biCompression == FOURCC_M263 ? "H.263" :
            HEADER(pMediaType->pbFormat)->biCompression == FOURCC_M261 ? "H.261" :
            HEADER(pMediaType->pbFormat)->biCompression == BI_RGB ? "RGB" :
            "????",
            HEADER(pMediaType->pbFormat)->biCompression,
            HEADER(pMediaType->pbFormat)->biBitCount, HEADER(pMediaType->pbFormat)->biWidth,
            HEADER(pMediaType->pbFormat)->biHeight));

        // We only support MEDIATYPE_Video and FORMAT_VideoInfo
        if (*pMediaType->Type() != MEDIATYPE_Video || *pMediaType->FormatType() != FORMAT_VideoInfo)
        {
                DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: Media type or format type not recognized!", _fx_));
                Hr = VFW_E_INVALIDMEDIATYPE;
                goto MyExit;
        }

    // Quickly test to see if this is the current format (what we provide in GetMediaType). We accept that
    if (m_mt == *pMediaType)
        {
                DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s:   SUCCESS: Identical to current format", _fx_));
                goto MyExit;
    }

        // Check the media subtype and image resolution
        for (dwIndex = 0; dwIndex < m_dwNumFormats && !fFormatMatch;  dwIndex++)
        {
                if ((HEADER(pMediaType->pbFormat)->biCompression == HEADER(m_aFormats[dwIndex]->pbFormat)->biCompression)
                        && (HEADER(pMediaType->pbFormat)->biWidth == HEADER(m_aFormats[dwIndex]->pbFormat)->biWidth)
                        && (HEADER(pMediaType->pbFormat)->biHeight == HEADER(m_aFormats[dwIndex]->pbFormat)->biHeight))
                        fFormatMatch = TRUE;
        }

        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s:   %s", _fx_, fFormatMatch ? "SUCCESS: Format supported" : "ERROR: Format notsupported"));

        if (!fFormatMatch)
                Hr = E_FAIL;

MyExit:
        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: end", _fx_));
        return Hr;
}

HRESULT CTAPIBasePin::ChangeFormatHelper()
{
        FX_ENTRY("CTAPIBasePin::ChangeFormatHelper")

        // If we are connected to somebody, make sure they like it too
        if (!IsConnected())
        {
        return S_OK;
    }

    HRESULT hr;

    hr = m_Connected->ReceiveConnection(this, &m_mt);
    if(FAILED(hr))
    {
        DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s: ReceiveConnection failed hr=%x", _fx_, hr));
                return hr;
    }

    // Does this pin use the local memory transport?
    if(NULL != m_pInputPin) {
        // This function assumes that m_pInputPin and m_Connected are
        // two different interfaces to the same object.
        ASSERT(::IsEqualObject(m_Connected, m_pInputPin));

        ALLOCATOR_PROPERTIES apInputPinRequirements;
        apInputPinRequirements.cbAlign = 0;
        apInputPinRequirements.cbBuffer = 0;
        apInputPinRequirements.cbPrefix = 0;
        apInputPinRequirements.cBuffers = 0;

        m_pInputPin->GetAllocatorRequirements(&apInputPinRequirements);

        // A zero allignment does not make any sense.
        if(0 == apInputPinRequirements.cbAlign) {
            apInputPinRequirements.cbAlign = 1;
        }

        hr = m_pAllocator->Decommit();
        if(FAILED(hr)) {
            DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s: Decommit failed hr=%x", _fx_, hr));
            return hr;
        }

        hr = DecideBufferSize(m_pAllocator,  &apInputPinRequirements);
        if(FAILED(hr)) {
            DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s: DecideBufferSize failed hr=%x", _fx_, hr));
            return hr;
        }

        hr = m_pAllocator->Commit();
        if(FAILED(hr)) {
            DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s: Commit failed hr=%x", _fx_, hr));
            return hr;
        }

        hr = m_pInputPin->NotifyAllocator(m_pAllocator, 0);
        if(FAILED(hr)) {
            DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s: NotifyAllocator failed hr=%x", _fx_, hr));
            return hr;
        }
    }
    return S_OK;
}


HRESULT CTAPIBasePin::NotifyDeviceFormatChange(IN CMediaType *pMediaType)
{
        FX_ENTRY("CTAPIBasePin::NotifyDeviceFormatChange")

    // make sure our image size is the same as new size.
    if (HEADER(pMediaType->pbFormat)->biHeight == HEADER(m_mt.pbFormat)->biHeight
        && HEADER(pMediaType->pbFormat)->biWidth == HEADER(m_mt.pbFormat)->biWidth)
    {
        // we are in sync with the driver.
        return S_OK;
    }

        // Which one of our formats is this exactly?
        for (DWORD dwIndex=0; dwIndex < m_dwNumFormats;  dwIndex++)
        {
                        if ((HEADER(pMediaType->pbFormat)->biWidth == HEADER(m_aFormats[dwIndex]->pbFormat)->biWidth)
                        && (HEADER(pMediaType->pbFormat)->biHeight == HEADER(m_aFormats[dwIndex]->pbFormat)->biHeight))
                        break;
        }

        if (dwIndex >= m_dwNumFormats)
    {
                DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:Invalid size, (%d, %d)",
            _fx_, HEADER(pMediaType->pbFormat)->biWidth, HEADER(pMediaType->pbFormat)->biHeight));
                return E_FAIL;
    }

    HRESULT Hr;
    if (FAILED(Hr = CBasePin::SetMediaType((CMediaType*)m_aFormats[dwIndex])))
        {
                DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:SetMediaType failed, hr=%x)", _fx_, Hr));
                return E_FAIL;
    }

    if (FAILED(Hr = ChangeFormatHelper()))
        {
                DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:ChangeFormatHelper failed, hr=%x)", _fx_, Hr));
                return E_FAIL;
    }

        // Update current format
        m_iCurrFormat = (int)dwIndex;

        // Update bitrate controls
        m_lTargetBitrate = m_aCapabilities[dwIndex]->MaxBitsPerSecond / 10;
        m_lCurrentBitrate = 0;
        m_lBitrateRangeMin = m_aCapabilities[dwIndex]->MinBitsPerSecond;
        m_lBitrateRangeMax = m_aCapabilities[dwIndex]->MaxBitsPerSecond;
        m_lBitrateRangeSteppingDelta = (m_aCapabilities[dwIndex]->MaxBitsPerSecond - m_aCapabilities[dwIndex]->MinBitsPerSecond) / 100;
        m_lBitrateRangeDefault = m_aCapabilities[dwIndex]->MaxBitsPerSecond / 10;

        // Update frame rate controls
        m_lMaxAvgTimePerFrame = (LONG)m_aCapabilities[dwIndex]->MinFrameInterval;
        m_lCurrentAvgTimePerFrame = m_lMaxAvgTimePerFrame;
        m_lAvgTimePerFrameRangeMin = (LONG)m_aCapabilities[dwIndex]->MinFrameInterval;
        m_lAvgTimePerFrameRangeMax = (LONG)m_aCapabilities[dwIndex]->MaxFrameInterval;
        m_lAvgTimePerFrameRangeSteppingDelta = (LONG)(m_aCapabilities[dwIndex]->MaxFrameInterval - m_aCapabilities[dwIndex]->MinFrameInterval) / 100;
        m_lAvgTimePerFrameRangeDefault = (LONG)m_aCapabilities[dwIndex]->MinFrameInterval;

    return S_OK;
}

/****************************************************************************
 *  @doc INTERNAL CBASEPINMETHOD
 *
 *  @mfunc HRESULT | CTAPIBasePin | SetMediaType | This method is used to
 *    set a specific media type on a pin.
 *
 *  @parm CMediaType* | pMediaType | Specifies a pointer to the media type.
 *
 *  @rdesc This method returns an HRESULT value that depends on the
 *    implementation of the interface. HRESULT can include one of the
 *    following standard constants, or other values not listed:
 *
 *  @flag E_FAIL | Failure
 *  @flag E_POINTER | Null pointer argument
 *  @flag E_INVALIDARG | Invalid argument
 *  @flag NOERROR | No error
 ***************************************************************************/
HRESULT CTAPIBasePin::SetMediaType(IN CMediaType *pMediaType)
{
        HRESULT Hr = NOERROR;
        DWORD   dwIndex;

        FX_ENTRY("CTAPIBasePin::SetMediaType")

        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: begin", _fx_));

        // Let the capture device decide how to capture to generate
        // video frames of the same resolution and frame rate
        // @todo Beware if you are previewing at the same time!
        if (FAILED(Hr = m_pCaptureFilter->m_pCapDev->SendFormatToDriver(
        HEADER(pMediaType->pbFormat)->biWidth,
        HEADER(pMediaType->pbFormat)->biHeight,
        HEADER(pMediaType->pbFormat)->biCompression,
        HEADER(pMediaType->pbFormat)->biBitCount,
        ((VIDEOINFOHEADER *)(pMediaType->pbFormat))->AvgTimePerFrame,
        FALSE
        )))
        {
                DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: SendFormatToDriver() failed!", _fx_));
                goto MyExit;
        }

        // Update the capture mode field for this device
        if (!m_pCaptureFilter->m_pCapDev->m_dwStreamingMode
        || (m_pCaptureFilter->m_pCapDev->m_dwStreamingMode == FRAME_GRAB_LARGE_SIZE
            && m_pCaptureFilter->m_user.pvi->bmiHeader.biHeight < 240
            && m_pCaptureFilter->m_user.pvi->bmiHeader.biWidth < 320))
    {
                g_aDeviceInfo[m_pCaptureFilter->m_dwDeviceIndex].nCaptureMode = CaptureMode_Streaming;
    }
        else
    {
                g_aDeviceInfo[m_pCaptureFilter->m_dwDeviceIndex].nCaptureMode = CaptureMode_FrameGrabbing;
    }

    if(m_pCaptureFilter->m_pCapDev->m_bCached_vcdi)
        m_pCaptureFilter->m_pCapDev->m_vcdi.nCaptureMode=g_aDeviceInfo[m_pCaptureFilter->m_dwDeviceIndex].nCaptureMode;


    if (SUCCEEDED(Hr = CBasePin::SetMediaType(pMediaType)))
        {
        Hr = ChangeFormatHelper();
        if (FAILED(Hr))
        {
                DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:Reconnect CapturePin failed", _fx_));
            goto MyExit;
        }

                // Which one of our formats is this exactly?
                for (dwIndex=0; dwIndex < m_dwNumFormats;  dwIndex++)
                {
                        if ((HEADER(pMediaType->pbFormat)->biCompression == HEADER(m_aFormats[dwIndex]->pbFormat)->biCompression)
                                && (HEADER(pMediaType->pbFormat)->biWidth == HEADER(m_aFormats[dwIndex]->pbFormat)->biWidth)
                                && (HEADER(pMediaType->pbFormat)->biHeight == HEADER(m_aFormats[dwIndex]->pbFormat)->biHeight))
                                break;
                }

                if (dwIndex < m_dwNumFormats)
                {
                        // Update current format
                        m_iCurrFormat = (int)dwIndex;

                        // Update bitrate controls
                        m_lTargetBitrate = m_aCapabilities[dwIndex]->MaxBitsPerSecond / 10;
                        m_lCurrentBitrate = 0;
                        m_lBitrateRangeMin = m_aCapabilities[dwIndex]->MinBitsPerSecond;
                        m_lBitrateRangeMax = m_aCapabilities[dwIndex]->MaxBitsPerSecond;
                        m_lBitrateRangeSteppingDelta = (m_aCapabilities[dwIndex]->MaxBitsPerSecond - m_aCapabilities[dwIndex]->MinBitsPerSecond) / 100;
                        m_lBitrateRangeDefault = m_aCapabilities[dwIndex]->MaxBitsPerSecond / 10;

                        // Update frame rate controls
                        m_lMaxAvgTimePerFrame = (LONG)m_aCapabilities[dwIndex]->MinFrameInterval;
                        m_lCurrentAvgTimePerFrame = m_lMaxAvgTimePerFrame;
                        m_lAvgTimePerFrameRangeMin = (LONG)m_aCapabilities[dwIndex]->MinFrameInterval;
                        m_lAvgTimePerFrameRangeMax = (LONG)m_aCapabilities[dwIndex]->MaxFrameInterval;
                        m_lAvgTimePerFrameRangeSteppingDelta = (LONG)(m_aCapabilities[dwIndex]->MaxFrameInterval - m_aCapabilities[dwIndex]->MinFrameInterval) / 100;
                        m_lAvgTimePerFrameRangeDefault = (LONG)m_aCapabilities[dwIndex]->MinFrameInterval;

                        if (m_pCaptureFilter->m_pCapturePin)
                        {
                Hr = m_pCaptureFilter->m_pCapturePin->NotifyDeviceFormatChange(pMediaType);
                if (FAILED(Hr))
                {
                    goto MyExit;
                }

                                ((VIDEOINFOHEADER *)m_pCaptureFilter->m_pCapturePin->m_mt.pbFormat)->AvgTimePerFrame = max(((VIDEOINFOHEADER *)m_pCaptureFilter->m_pCapturePin->m_mt.pbFormat)->AvgTimePerFrame, m_pCaptureFilter->m_user.pvi->AvgTimePerFrame);
                                m_pCaptureFilter->m_pCapturePin->m_lAvgTimePerFrameRangeMin = max(m_pCaptureFilter->m_pCapturePin->m_lAvgTimePerFrameRangeMin, (long)m_pCaptureFilter->m_user.pvi->AvgTimePerFrame);
                                m_pCaptureFilter->m_pCapturePin->m_lMaxAvgTimePerFrame = max(m_pCaptureFilter->m_pCapturePin->m_lMaxAvgTimePerFrame, (long)m_pCaptureFilter->m_user.pvi->AvgTimePerFrame);
                                m_pCaptureFilter->m_pCapturePin->m_lAvgTimePerFrameRangeDefault = m_pCaptureFilter->m_pCapturePin->m_lCurrentAvgTimePerFrame = m_pCaptureFilter->m_pCapturePin->m_lMaxAvgTimePerFrame;
                        }
                        if (m_pCaptureFilter->m_pPreviewPin)
                        {
                Hr = m_pCaptureFilter->m_pPreviewPin->NotifyDeviceFormatChange(pMediaType);
                if (FAILED(Hr))
                {
                    goto MyExit;
                }

                                ((VIDEOINFOHEADER *)m_pCaptureFilter->m_pPreviewPin->m_mt.pbFormat)->AvgTimePerFrame = max(((VIDEOINFOHEADER *)m_pCaptureFilter->m_pPreviewPin->m_mt.pbFormat)->AvgTimePerFrame, m_pCaptureFilter->m_user.pvi->AvgTimePerFrame);
                                m_pCaptureFilter->m_pPreviewPin->m_lAvgTimePerFrameRangeMin = max(m_pCaptureFilter->m_pPreviewPin->m_lAvgTimePerFrameRangeMin, (long)m_pCaptureFilter->m_user.pvi->AvgTimePerFrame);
                                m_pCaptureFilter->m_pPreviewPin->m_lMaxAvgTimePerFrame = max(m_pCaptureFilter->m_pPreviewPin->m_lMaxAvgTimePerFrame, (long)m_pCaptureFilter->m_user.pvi->AvgTimePerFrame);
                                m_pCaptureFilter->m_pPreviewPin->m_lAvgTimePerFrameRangeDefault = m_pCaptureFilter->m_pPreviewPin->m_lCurrentAvgTimePerFrame = m_pCaptureFilter->m_pPreviewPin->m_lMaxAvgTimePerFrame;
                        }
                }
                else
                {
                        DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: Invalid input format!", _fx_));
                        Hr = E_FAIL;
                        goto MyExit;
                }

        // Remember to send a sample with a new format attached to it
            m_fFormatChanged = TRUE;
        }

MyExit:
        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: end", _fx_));
        return Hr;
}

/****************************************************************************
 *  @doc INTERNAL CCAPTUREPINMETHOD
 *
 *  @mfunc HRESULT | CCapturePin | SetMediaType | This method is used to
 *    set a specific media type on a pin.
 *
 *  @parm CMediaType* | pMediaType | Specifies a pointer to the media type.
 *
 *  @rdesc This method returns an HRESULT value that depends on the
 *    implementation of the interface. HRESULT can include one of the
 *    following standard constants, or other values not listed:
 *
 *  @flag E_FAIL | Failure
 *  @flag E_POINTER | Null pointer argument
 *  @flag E_INVALIDARG | Invalid argument
 *  @flag NOERROR | No error
 ***************************************************************************/
HRESULT CCapturePin::SetMediaType(IN CMediaType *pMediaType)
{
        HRESULT Hr;

        FX_ENTRY("CCapturePin::SetMediaType")

        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: begin", _fx_));

        if (SUCCEEDED(Hr = CTAPIBasePin::SetMediaType(pMediaType)))
        {
                if (m_iCurrFormat == -1L)
                        m_dwRTPPayloadType = RTPPayloadTypes[0];
                else
                        m_dwRTPPayloadType = RTPPayloadTypes[m_iCurrFormat];
                if (m_pCaptureFilter->m_pRtpPdPin)
                        m_pCaptureFilter->m_pRtpPdPin->m_dwRTPPayloadType = m_dwRTPPayloadType;
        }
#ifdef DEBUG
        else if (pMediaType && pMediaType->pbFormat)
        {
                DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: Failed to set %s %dx%d", _fx_, HEADER(pMediaType->pbFormat)->biCompression == FOURCC_M263 ? "H.263" : HEADER(pMediaType->pbFormat)->biCompression == FOURCC_M261 ? "H.261" : "????", HEADER(pMediaType->pbFormat)->biWidth, HEADER(pMediaType->pbFormat)->biHeight));
        }
        else
        {
                DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: Invalid format", _fx_));
        }
#endif

        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: end", _fx_));

        return Hr;
}

/****************************************************************************
 *  @doc INTERNAL CCAPTUREPINMETHOD
 *
 *  @mfunc HRESULT | CCapturePin | SetFormat | This method is used to
 *    set a specific media type on a pin. It is only implemented by the
 *    output pin of video encoders.
 *
 *  @parm DWORD | dwRTPPayloadType | Specifies the payload type associated
 *    to the pointer to the <t AM_MEDIA_TYPE> structure passed in.
 *
 *  @parm AM_MEDIA_TYPE* | pMediaType | Specifies a pointer to an
 *    <t AM_MEDIA_TYPE> structure.
 *
 *  @rdesc This method returns an HRESULT value that depends on the
 *    implementation of the interface. HRESULT can include one of the
 *    following standard constants, or other values not listed:
 *
 *  @flag E_FAIL | Failure
 *  @flag E_POINTER | Null pointer argument
 *  @flag E_INVALIDARG | Invalid argument
 *  @flag NOERROR | No error
 ***************************************************************************/
STDMETHODIMP CCapturePin::SetFormat(IN DWORD dwRTPPayloadType, IN AM_MEDIA_TYPE *pMediaType)
{
        HRESULT Hr;

        FX_ENTRY("CCapturePin::SetFormat")

        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: begin", _fx_));

        if (SUCCEEDED(Hr = CTAPIBasePin::SetFormat(pMediaType)))
        {
                m_dwRTPPayloadType = dwRTPPayloadType;
                DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s:   SUCCESS: Setting %s %dx%d", _fx_, HEADER(pMediaType->pbFormat)->biCompression == FOURCC_M263 ? "H.263" : HEADER(pMediaType->pbFormat)->biCompression == FOURCC_M261 ? "H.261" : "????", HEADER(pMediaType->pbFormat)->biWidth, HEADER(pMediaType->pbFormat)->biHeight));
        }
#ifdef DEBUG
        else if (pMediaType && pMediaType->pbFormat)
        {
                DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: Failed to set %s %dx%d", _fx_, HEADER(pMediaType->pbFormat)->biCompression == FOURCC_M263 ? "H.263" : HEADER(pMediaType->pbFormat)->biCompression == FOURCC_M261 ? "H.261" : "????", HEADER(pMediaType->pbFormat)->biWidth, HEADER(pMediaType->pbFormat)->biHeight));
        }
        else
        {
                DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: Invalid format", _fx_));
        }
#endif

    //

        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: end", _fx_));

        return Hr;
}

/****************************************************************************
 *  @doc INTERNAL CCAPTUREPINMETHOD
 *
 *  @mfunc HRESULT | CCapturePin | GetFormat | This method is used to
 *    retrieve the current media type on a pin.
 *
 *  @parm DWORD* | pdwRTPPayloadType | Specifies the address of a DWORD
 *    to receive the payload type associated to an <t AM_MEDIA_TYPE> structure.
 *
 *  @parm AM_MEDIA_TYPE** | ppMediaType | Specifies the address of a pointer
 *    to an <t AM_MEDIA_TYPE> structure.
 *
 *  @rdesc This method returns an HRESULT value that depends on the
 *    implementation of the interface. HRESULT can include one of the
 *    following standard constants, or other values not listed:
 *
 *  @flag E_FAIL | Failure
 *  @flag E_POINTER | Null pointer argument
 *  @flag NOERROR | No error
 *
 *  @comm Note that we return the output type, not the format at which
 *    we are capturing. Only the filter really cares about how the data is
 *    being captured.
 ***************************************************************************/
STDMETHODIMP CCapturePin::GetFormat(OUT DWORD *pdwRTPPayloadType, OUT AM_MEDIA_TYPE **ppMediaType)
{
        HRESULT Hr = NOERROR;

        FX_ENTRY("CCapturePin::GetFormat")

        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: begin", _fx_));

        // Validate input parameters
        ASSERT(pdwRTPPayloadType);
        ASSERT(ppMediaType);
        if (!pdwRTPPayloadType || !ppMediaType)
        {
                DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: Null pointer argument", _fx_));
                Hr = E_POINTER;
                goto MyExit;
        }

        // Return a copy of our current format
        Hr = CTAPIBasePin::GetFormat(ppMediaType);

        // Return the payload type associated to the current format
        *pdwRTPPayloadType = m_dwRTPPayloadType;

MyExit:
        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: end", _fx_));
        return Hr;
}

/****************************************************************************
 *  @doc INTERNAL CCAPTUREPINMETHOD
 *
 *  @mfunc HRESULT | CCapturePin | GetNumberOfCapabilities | This method is
 *    used to retrieve the number of stream capabilities structures.
 *
 *  @parm DWORD* | pdwCount | Specifies a pointer to a DWORD to receive the
 *    number of <t TAPI_STREAM_CONFIG_CAPS> structures supported.
 *
 *  @rdesc This method returns an HRESULT value that depends on the
 *    implementation of the interface. HRESULT can include one of the
 *    following standard constants, or other values not listed:
 *
 *  @flag E_FAIL | Failure
 *  @flag E_POINTER | Null pointer argument
 *  @flag NOERROR | No error
 ***************************************************************************/
STDMETHODIMP CCapturePin::GetNumberOfCapabilities(OUT DWORD *pdwCount)
{
        HRESULT Hr = NOERROR;

        FX_ENTRY("CCapturePin::GetNumberOfCapabilities")

        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: begin", _fx_));

        // Validate input parameters
        ASSERT(pdwCount);
        if (!pdwCount)
        {
                DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: Null pointer argument", _fx_));
                Hr = E_POINTER;
                goto MyExit;
        }

        // Return relevant info
        *pdwCount = m_dwNumFormats;

        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s:   Returning %ld formats", _fx_, *pdwCount));

MyExit:
        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: end", _fx_));
        return Hr;
}

/****************************************************************************
 *  @doc INTERNAL CCAPTUREPINMETHOD
 *
 *  @mfunc HRESULT | CCapturePin | GetStreamCaps | This method is
 *    used to retrieve a video stream capability pair.
 *
 *  @parm DWORD | dwIndex | Specifies the index to the desired media type
 *    and capability pair.
 *
 *  @parm AM_MEDIA_TYPE** | ppMediaType | Specifies the address of a pointer
 *    to an <t AM_MEDIA_TYPE> structure.
 *
 *  @parm TAPI_STREAM_CONFIG_CAPS* | pTSCC | Specifies a pointer to a
 *    <t TAPI_STREAM_CONFIG_CAPS> configuration structure.
 *
 *  @rdesc This method returns an HRESULT value that depends on the
 *    implementation of the interface. HRESULT can include one of the
 *    following standard constants, or other values not listed:
 *
 *  @flag E_FAIL | Failure
 *  @flag E_POINTER | Null pointer argument
 *  @flag E_INVALIDARG | Invalid argument
 *  @flag NOERROR | No error
 ***************************************************************************/
STDMETHODIMP CCapturePin::GetStreamCaps(IN DWORD dwIndex, OUT AM_MEDIA_TYPE **ppMediaType, OUT TAPI_STREAM_CONFIG_CAPS *pTSCC, OUT DWORD *pdwRTPPayLoadType)
{
        HRESULT Hr = NOERROR;

        FX_ENTRY("CCapturePin::GetStreamCaps")

        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: begin", _fx_));

        // Validate input parameters
        ASSERT(dwIndex < m_dwNumFormats);
        ASSERT(ppMediaType);
        if (!ppMediaType)
        {
                DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: Null pointer argument", _fx_));
                Hr = E_POINTER;
                goto MyExit;
        }
        if (!(dwIndex < m_dwNumFormats))
        {
                DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: Invalid dwIndex argument!", _fx_));
                Hr = E_INVALIDARG;
                goto MyExit;
        }

        // Return a copy of the requested AM_MEDIA_TYPE structure
        if (!(*ppMediaType = CreateMediaType(m_aFormats[dwIndex])))
        {
                DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: Out of memory!", _fx_));
                Hr = E_OUTOFMEMORY;
                goto MyExit;
        }

        // Return a copy of the requested TAPI_STREAM_CONFIG_CAPS structure
        if (pTSCC)
    {
                pTSCC->CapsType = VideoStreamConfigCaps;
                lstrcpynW(pTSCC->VideoCap.Description, CaptureCapsStrings[dwIndex], MAX_DESCRIPTION_LEN); //this replaces the line below: see 165048
                //GetStringFromStringTable(CaptureCapsStringIDs[dwIndex], pTSCC->VideoCap.Description);
        CopyMemory(&pTSCC->VideoCap.VideoStandard, &m_aCapabilities[dwIndex]->VideoStandard, sizeof(VIDEO_STREAM_CONFIG_CAPS) - sizeof(GUID));
    }

        if (pdwRTPPayLoadType)
        {
                *pdwRTPPayLoadType = RTPPayloadTypes[dwIndex];
        }

        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s:   Returning format index %ld: %s %ld bpp %ldx%ld", _fx_, dwIndex, HEADER(m_aFormats[dwIndex]->pbFormat)->biCompression == FOURCC_M263 ? "H.263" : HEADER(m_aFormats[dwIndex]->pbFormat)->biCompression == FOURCC_M261 ? "H.261" : HEADER(m_aFormats[dwIndex]->pbFormat)->biCompression == BI_RGB ? "RGB" : "????", HEADER(m_aFormats[dwIndex]->pbFormat)->biBitCount, HEADER(m_aFormats[dwIndex]->pbFormat)->biWidth, HEADER(m_aFormats[dwIndex]->pbFormat)->biHeight))
;

MyExit:
        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: end", _fx_));
        return Hr;
}

/****************************************************************************
 *  @doc INTERNAL CCAPTUREPINMETHOD
 *
 *  @mfunc HRESULT | CCapturePin | GetStringFromStringTable | This method is
 *    used to retrieve the description string of a video format.
 *
 *  @parm UINT | uStringID | Specifies the string resource ID.
 *
 *  @parm WCHAR* | pwchDescription | Specifies the address of a string to
 *    receive the video format description.
 *  @rdesc This method returns an HRESULT value that depends on the
 *    implementation of the interface. HRESULT can include one of the
 *    following standard constants, or other values not listed:
 *
 *  @flag E_FAIL | Failure
 *  @flag E_POINTER | Null pointer argument
 *  @flag E_INVALIDARG | Invalid argument
 *  @flag NOERROR | No error
 *
 *  @comm Based on Article ID: Q200893
 *
 *  If an application has a string localized to multiple languages and
 *  mapped to the same ID in each language, the correct version of the
 *  string might not be loaded on Windows 95 or Windows 98 using the
 *  Win32 function ::LoadString. To load the correct version of the string
 *  you need to load the string using the Win32 functions FindResourceEx
 *  and LoadResource.
 ***************************************************************************/
STDMETHODIMP CCapturePin::GetStringFromStringTable(IN UINT uStringID, OUT WCHAR* pwchDescription)
{
        HRESULT         Hr = NOERROR;
        WCHAR           *pwchCur;
        UINT            idRsrcBlk = uStringID / 16UL + 1;
        DWORD           dwStrIndex  = uStringID % 16UL;
        HINSTANCE       hModule = NULL;
        HRSRC           hResource = NULL;
        DWORD           dwIndex;

        FX_ENTRY("CCapturePin::GetStringFromStringTable")

        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: begin", _fx_));

        // Validate input parameters
        ASSERT(IDS_M263_Capture_QCIF <= uStringID && uStringID <= IDS_M261_Capture_CIF);
        ASSERT(pwchDescription);
        if (!pwchDescription)
        {
                DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: Null pointer argument", _fx_));
                Hr = E_POINTER;
                goto MyExit;
        }

        if (!(hResource = FindResourceEx(g_hInst, RT_STRING, MAKEINTRESOURCE(idRsrcBlk), MAKELANGID(LANG_NEUTRAL, SUBLANG_DEFAULT))))
        {
                DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: FindResourceEx failed", _fx_));
                Hr = E_INVALIDARG;
                goto MyExit;
        }

        if (!(pwchCur = (WCHAR *)LoadResource(g_hInst, hResource)))
        {
                DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: LoadResource failed", _fx_));
                Hr = E_FAIL;
                goto MyExit;
        }

        // Get the description string
        for (dwIndex = 0; dwIndex<16UL; dwIndex++)
        {
                if (*pwchCur)
                {
                        int cchString = *pwchCur;  // String size in characters.

                        pwchCur++;

                        if (dwIndex == dwStrIndex)
                        {
                                // The string has been found in the string table.
                                lstrcpynW(pwchDescription, pwchCur, min(cchString + 1, MAX_DESCRIPTION_LEN));
                        }
                        pwchCur += cchString;
                }
                else
                        pwchCur++;
        }

MyExit:
        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: end", _fx_));
        return Hr;
}

#ifdef TEST_ISTREAMCONFIG
STDMETHODIMP CCapturePin::TestIStreamConfig()
{
        HRESULT Hr = NOERROR;
        DWORD   dw, dwCount, dwRTPPayLoadType;
        AM_MEDIA_TYPE *pAMMediaType;
        TAPI_STREAM_CONFIG_CAPS TSCC;

        FX_ENTRY("CCapturePin::TestIStreamConfig")

        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: begin", _fx_));

        // Test GetNumberOfCapabilities
        GetNumberOfCapabilities(&dwCount);

        for (dw=0; dw < dwCount; dw++)
        {
                // Test GetStreamCaps
                GetStreamCaps(dw, &pAMMediaType, &TSCC);

                // Test SetFormat
                SetFormat(96, pAMMediaType);
                DeleteMediaType(pAMMediaType);

                // Test GetFormat
                GetFormat(&dwRTPPayLoadType, &pAMMediaType);
                DeleteMediaType(pAMMediaType);
        }

        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: end", _fx_));
        return Hr;
}
#endif
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\net\tapi\skywalker\filters\video\tapivcap\h26xenc.cpp ===
/****************************************************************************
 *  @doc INTERNAL H26XENC
 *
 *  @module H26XEnc.cpp | Source file for the <c CH26XEncoder> class methods
 *    used to implement the H.26X video encoder.
 ***************************************************************************/

#include "Precomp.h"

#define MIN_IFRAME_REQUEST_INTERVAL 15000

//#define DEBUG_BITRATE
// ... && defined(DEBUG_BITRATE)
#undef D
#if defined(DEBUG)
  #include <stdio.h>
  #include <stdarg.h>

  static int dprintf( char * format, ... )
  {
      char out[1024];
      int r;
      va_list marker;
      va_start(marker, format);
      r=_vsnprintf(out, 1022, format, marker);
      va_end(marker);
      OutputDebugString( out );
      return r;
  }

  #ifdef DEBUG_BITRATE
    int g_dbg_H26XEnc=1;
  #else
    int g_dbg_H26XEnc=0;
  #endif

  #define D(f) if(g_dbg_H26XEnc & (f))

#else
  #define D(f)
  #define dprintf ; / ## /
#endif


/****************************************************************************
 *  @doc INTERNAL CH26XENCMETHOD
 *
 *  @mfunc void | CH26XEncoder | CH26XEncoder | This method is the constructor
 *    for the <c CH26XEncoder> object.
 *
 *  @rdesc Nada.
 ***************************************************************************/
CH26XEncoder::CH26XEncoder(IN TCHAR *pObjectName, IN CTAPIBasePin *pBasePin, IN PBITMAPINFOHEADER pbiIn, IN PBITMAPINFOHEADER pbiOut, IN HRESULT *pHr) : CConverter(pObjectName, pBasePin, pbiIn, pbiOut, pHr)
{
        FX_ENTRY("CH26XEncoder::CH26XEncoder")

        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: begin", _fx_));

        if (!pHr || FAILED(*pHr))
        {
                DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: Null input pointer", _fx_));
                goto MyExit;
        }

        // Default inits
        m_pInstInfo             = NULL;
#if DXMRTP <= 0
        m_hTAPIH26XDLL  = NULL;
#endif
        m_pDriverProc   = NULL;

MyExit:
        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: end", _fx_));
}

/****************************************************************************
 *  @doc INTERNAL CH26XENCMETHOD
 *
 *  @mfunc void | CH26XEncoder | ~CH26XEncoder | This method is the destructor
 *    for the <c CH26XEncoder> object
 *
 *  @rdesc Nada.
 ***************************************************************************/
CH26XEncoder::~CH26XEncoder()
{
        FX_ENTRY("CH26XEncoder::~CH26XEncoder")

        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: begin", _fx_));

        // Default cleanup

        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: end", _fx_));
}

/****************************************************************************
 *  @doc INTERNAL CH26XENCMETHOD
 *
 *  @mfunc CH26XEncoder* | CH26XEncoder | CreateCH26XEncoder | This
 *    helper function creates an object to interact with the H.26X encoder.
 *
 *  @parm CH26XEncoder** | ppCH26XEncoder | Specifies the address of a pointer to the
 *    newly created <c CH26XEncoder> object.
 *
 *  @rdesc This method returns an HRESULT value that depends on the
 *    implementation of the interface. HRESULT can include one of the
 *    following standard constants, or other values not listed:
 *
 *  @flag E_FAIL | Failure
 *  @flag E_POINTER | Null pointer argument
 *  @flag E_OUTOFMEMORY | Out of memory
 *  @flag NOERROR | No error
 ***************************************************************************/
HRESULT CALLBACK CH26XEncoder::CreateH26XEncoder(IN CTAPIBasePin *pBasePin, IN PBITMAPINFOHEADER pbiIn, IN PBITMAPINFOHEADER pbiOut, OUT CConverter **ppH26XEncoder)
{
        HRESULT Hr = NOERROR;

        FX_ENTRY("CH26XEncoder::CreateH26XEncoder")

        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: begin", _fx_));

        // Validate input parameters
        ASSERT(pBasePin);
        ASSERT(ppH26XEncoder);
        if (!pBasePin || !ppH26XEncoder)
        {
                DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: Null pointer argument", _fx_));
                Hr = E_POINTER;
                goto MyExit;
        }

        if (pbiOut->biCompression == FOURCC_M263)
        {
                if (!(*ppH26XEncoder = (CConverter *) new CH26XEncoder(NAME("H.263 Encoder"), pBasePin, pbiIn, pbiOut, &Hr)))
                {
                        DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: Out of memory", _fx_));
                        Hr = E_OUTOFMEMORY;
                        goto MyExit;
                }
        }
        else if (pbiOut->biCompression == FOURCC_M261)
        {
                if (!(*ppH26XEncoder = (CConverter *) new CH26XEncoder(NAME("H.261 Encoder"), pBasePin, pbiIn, pbiOut, &Hr)))
                {
                        DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: Out of memory", _fx_));
                        Hr = E_OUTOFMEMORY;
                        goto MyExit;
                }
        }
        else
        {
                DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: Not an H.26x encoder", _fx_));
                Hr = E_UNEXPECTED;
                goto MyExit;
        }

        // If initialization failed, delete the stream array and return the error
        if (FAILED(Hr) && *ppH26XEncoder)
        {
                DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: Initialization failed", _fx_));
                Hr = E_FAIL;
                delete *ppH26XEncoder, *ppH26XEncoder = NULL;
        }

MyExit:
        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: end", _fx_));
        return Hr;
}


/****************************************************************************
 *  @doc INTERNAL CCONVERTMETHOD
 *
 *  @mfunc HRESULT | CH26XEncoder | OpenConverter | This method opens an H.26X
 *    encoder.
 *
 *  @rdesc This method returns an HRESULT value that depends on the
 *    implementation of the interface. HRESULT can include one of the
 *    following standard constants, or other values not listed:
 *
 *  @flag E_FAIL | Failure
 *  @flag E_POINTER | Null pointer argument
 *  @flag NOERROR | No error
 ***************************************************************************/
HRESULT CH26XEncoder::OpenConverter()
{
        HRESULT                         Hr = NOERROR;
        LRESULT                         lRes;
        ICOPEN                          icOpen;
        ICCOMPRESSFRAMES        iccf = {0};
        PMSH26XCOMPINSTINFO     pciMSH26XInfo;
        PBITMAPINFOHEADER       pbiIn;

        FX_ENTRY("CH26XEncoder::OpenConverter")

        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: begin", _fx_));

        // Validate input parameters
        ASSERT(m_pbiIn);
        ASSERT(m_pbiOut);
        ASSERT(!m_pInstInfo);
        ASSERT(m_dwConversionType & CONVERSIONTYPE_ENCODE);
        if (m_pInstInfo || !m_pbiIn || !m_pbiOut || !(m_dwConversionType & CONVERSIONTYPE_ENCODE))
        {
                DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: Previous converter needs to be closed first", _fx_));
                Hr = E_UNEXPECTED;
                goto MyExit;
        }

#if DXMRTP > 0
    m_pDriverProc = H26XDriverProc;
#else
        // Load TAPIH26X.DLL and get a proc address
        if (!(m_hTAPIH26XDLL = LoadLibrary("TAPIH26X")))
        {
                DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s: TAPIH26X.dll load failed!", _fx_));
                Hr = E_FAIL;
                goto MyError3;
        }
        if (!(m_pDriverProc = (LPFNDRIVERPROC)GetProcAddress(m_hTAPIH26XDLL, "DriverProc")))
        {
                DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s: Couldn't find DriverProc on TAPIH26X.dll!", _fx_));
                Hr = E_FAIL;
                goto MyError3;
        }
#endif
        // Load encoder
        if (!(lRes = (*m_pDriverProc)(NULL, NULL, DRV_LOAD, 0L, 0L)))
        {
                DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: Failed to load encoder", _fx_));
                Hr = E_FAIL;
                goto MyError3;
        }

        // Open encoder
        icOpen.fccHandler = m_pbiOut->biCompression;
        icOpen.dwFlags = ICMODE_COMPRESS;
        if (!(m_pInstInfo = (LPINST)(*m_pDriverProc)(NULL, NULL, DRV_OPEN, 0L, (LPARAM)&icOpen)))
        {
                DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: Failed to open encoder", _fx_));
                Hr = E_FAIL;
                goto MyError3;
        }

        // Get info about this encoder
        m_dwFrame = 0L;
        // For now, issue a key frame every 15 seconds
        m_dwLastIFrameTime = GetTickCount();
        m_fPeriodicIFrames = TRUE;
        m_dwLastTimestamp = 0xFFFFFFFF;

        // Do any of the stuff that is MS H.263 or MS H.261 specific right here
        if (!(pciMSH26XInfo = (PMSH26XCOMPINSTINFO) new BYTE[sizeof(COMPINSTINFO)]))
        {
                DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: Out of memory!", _fx_));
                Hr = E_OUTOFMEMORY;
                goto MyError4;
        }
        ZeroMemory(pciMSH26XInfo, sizeof(COMPINSTINFO));

        // Really configure the codec for compression
        pciMSH26XInfo->Configuration.bRTPHeader = TRUE;
        if (m_pBasePin->m_pCaptureFilter->m_pRtpPdPin)
                pciMSH26XInfo->Configuration.unPacketSize = m_pBasePin->m_pCaptureFilter->m_pRtpPdPin->m_dwMaxRTPPacketSize;
        else
                pciMSH26XInfo->Configuration.unPacketSize = DEFAULT_RTP_PACKET_SIZE;
        pciMSH26XInfo->Configuration.bEncoderResiliency = FALSE;
        pciMSH26XInfo->Configuration.unPacketLoss = 0;
        pciMSH26XInfo->Configuration.bBitRateState = TRUE;
        pciMSH26XInfo->Configuration.unBytesPerSecond = 1664;
        if (((DWORD) (*m_pDriverProc)((DWORD)m_pInstInfo, NULL, ICM_SETSTATE, (LPARAM)pciMSH26XInfo, sizeof(COMPINSTINFO))) != sizeof(COMPINSTINFO))
        {
                DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: ICSetState failed!", _fx_));
                Hr = E_FAIL;
                goto MyError5;
        }

        // Get rid of the state structure
        delete pciMSH26XInfo;

        // Initialize ICCOMPRESSFRAMES structure
        iccf.dwFlags = VIDCF_TEMPORAL | VIDCF_FASTTEMPORALC | VIDCF_CRUNCH | VIDCF_QUALITY;
        iccf.lQuality = 10000UL - (m_dwImageQuality * 322UL);
        iccf.lDataRate = m_dwImageQuality;
        iccf.lKeyRate = 0xFFFFFFFF;
        iccf.dwRate = 1000UL;
        iccf.dwScale = (LONG)m_pBasePin->m_lMaxAvgTimePerFrame / 1000UL;

        // Send this guy to the encoder
        if (((*m_pDriverProc)((DWORD)m_pInstInfo, NULL, ICM_COMPRESS_FRAMES_INFO, (DWORD)(LPVOID)&iccf, sizeof(iccf)) != ICERR_OK))
        {
                DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: Codec failed to handle ICM_COMPRESS_FRAMES_INFO message correctly!", _fx_));
                Hr = E_FAIL;
                goto MyError4;
        }

        // Do we need to scale the input first?
        if (m_dwConversionType & CONVERSIONTYPE_SCALER)
        {
                pbiIn = m_pbiInt;

                // Do we need to prepare some stuff for the scaler to work?
                if (m_pbiInt->biCompression == BI_RGB && m_pbiInt->biBitCount == 8)
                {
                        if (!m_pBasePin->m_fNoImageStretch)
                        {
                                // Create a temporary palette
                                InitDst8(m_pbiInt);
                        }
                        else
                        {
                                // Look for the palette entry closest to black
                                InitBlack8(m_pbiIn);
                        }
                }
        }
        else
                pbiIn = m_pbiIn;

        // Start the encoder
        if (((*m_pDriverProc)((DWORD)m_pInstInfo, NULL, ICM_COMPRESS_BEGIN, (LPARAM)pbiIn, (LPARAM)m_pbiOut)) != MMSYSERR_NOERROR)
        {
                DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: ICCompressBegin failed!", _fx_));
                Hr = E_FAIL;
                goto MyError4;
        }

        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s:   SUCCESS: Compressor ready", _fx_));

        m_fConvert = TRUE;

        goto MyExit;

MyError5:
        if (pciMSH26XInfo)
                delete pciMSH26XInfo, pciMSH26XInfo = NULL;
MyError4:
        if (m_pInstInfo)
        {
                (*m_pDriverProc)((DWORD)m_pInstInfo, NULL, DRV_CLOSE, 0L, 0L);
                (*m_pDriverProc)((DWORD)m_pInstInfo, NULL, DRV_FREE, 0L, 0L);
                m_pInstInfo = NULL;
        }
MyError3:
        if (m_pbiInt)
                delete m_pbiInt, m_pbiInt = NULL;
        if (m_pbiOut)
                delete m_pbiOut, m_pbiOut = NULL;
        if (m_pbiIn)
                delete m_pbiIn, m_pbiIn = NULL;
MyExit:
        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: end", _fx_));
        return Hr;
}

#define TARGETBITRATE m_pBasePin->m_pCaptureFilter->m_pCapturePin->m_lTargetBitrate
// below is in bps
#define BITRATE_LOWLIMIT        (25*1024)
#define LOWFRAMESIZE            5

#ifdef DEBUG
int g_skip_f = 0 ;
int g_skip_q = 0 ;
#endif

/****************************************************************************
 *  @doc INTERNAL CCONVERTMETHOD
 *
 *  @mfunc HRESULT | CH26XEncoder | ConvertFrame | This method converts
 *    a bitmap to H.26X.
 *
 *  @parm PBYTE | pbyInput | Pointer to the input buffer.
 *
 *  @parm DWORD | dwInputSize | Size of the input buffer.
 *
 *  @parm PBYTE | pbyOutput | Pointer to the output buffer.
 *
 *  @parm PDWORD | pdwOutputSize | Pointer to a DWORD to receive the size
 *    of the converted data.
 *
 *  @rdesc This method returns an HRESULT value that depends on the
 *    implementation of the interface. HRESULT can include one of the
 *    following standard constants, or other values not listed:
 *
 *  @flag E_FAIL | Failure
 *  @flag E_POINTER | Null pointer argument
 *  @flag NOERROR | No error
 ***************************************************************************/
HRESULT CH26XEncoder::ConvertFrame(IN PBYTE pbyInput, IN DWORD dwInputSize, IN PBYTE pbyOutput, OUT PDWORD pdwOutputSize, OUT PDWORD pdwBytesExtent, IN PBYTE pbyPreview, IN OUT PDWORD pdwPreviewSize, IN BOOL fSendKeyFrame)
{
        HRESULT         Hr = NOERROR;
        BOOL            fKeyFrame;
    DWORD               dwMaxSizeThisFrame = 0xffffff;
        DWORD           ckid = 0UL;
        DWORD           dwFlags;
        DWORD           dwTimestamp;
        ICCOMPRESS      icCompress;
        PH26X_RTP_BSINFO_TRAILER pbsiT;
        RECT            rcRect;

        DWORD Min1;     // 1st term in the min operation performed to compute the dwMaxSizeThisFrame
        DWORD Min2;     // 2nd term in the min operation performed to compute the dwMaxSizeThisFrame
        DWORD aux;      // tmp var to adjust the above added for clarity (also debug print purposes)
#if defined(DEBUG) && defined(DEBUG_ENCODING)
        char szDebug[128];
#endif

        FX_ENTRY("CH26XEncoder::ConvertFrame")

        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: begin", _fx_));

        // Validate input parameters
        ASSERT(pbyInput);
        ASSERT(pbyOutput);
        ASSERT(pdwOutputSize);
        ASSERT(m_pbiIn);
        ASSERT(m_pbiOut);
        ASSERT(m_fConvert);
        ASSERT(m_pInstInfo);
        if (!pbyInput || !pbyOutput || !pdwOutputSize)
        {
                DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: Null pointer argument", _fx_));
                Hr = E_POINTER;
                goto MyExit;
        }
        if (!m_pbiIn || !m_pbiOut || !m_fConvert || !m_pInstInfo)
        {
                DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: Converter needs to be opened first", _fx_));
                Hr = E_UNEXPECTED;
                goto MyExit;
        }

        // Save the current time
        dwTimestamp = GetTickCount();

        // Compress
        fKeyFrame = fSendKeyFrame || (m_fPeriodicIFrames && (((dwTimestamp > m_dwLastIFrameTime) && ((dwTimestamp - m_dwLastIFrameTime) > MIN_IFRAME_REQUEST_INTERVAL)))) || (m_dwFrame == 0);
        dwFlags = fKeyFrame ? AVIIF_KEYFRAME : 0;

        Min1 = (DWORD)((LONGLONG)m_pBasePin->m_lCurrentAvgTimePerFrame * m_pBasePin->m_lTargetBitrate / 80000000);
        Min2 = ((VIDEOINFOHEADER_H263 *)(m_pBasePin->m_mt.pbFormat))->bmiHeader.dwBppMaxKb * 1024 / 8;

        D(1) dprintf("%s: dwMaxSizeThisFrame = min( %8lu , %8lu )\n",_fx_, Min1, Min2);

        dwMaxSizeThisFrame =
        min (
            Min1, // original 1st term : (DWORD)((LONGLONG)m_pBasePin->m_lCurrentAvgTimePerFrame * m_pBasePin->m_lTargetBitrate / 80000000),
            Min2  // original 2nd term : ((VIDEOINFOHEADER_H263 *)(m_pBasePin->m_mt.pbFormat))->bmiHeader.dwBppMaxKb * 1024 / 8
            );

#ifdef DEBUG
        if(!g_skip_f)
#endif
        { DWORD dwTargetBitrate=0;
          //now scale dwMaxSizeThisFrame between LOWFRAMESIZE .. dwMaxSizeThisFrame for values of the TARGETBITRATE between 0 .. BITRATE_LOWLIMIT
          //for a TARGETBITRATE 0 we want to have LOWFRAMESIZE, and for a bitrate BITRATE_LOWLIMIT the normal value that we started with
          // (that is dwMaxSizeThisFrame will be left untouched basically)
          // between these 2 limits, the scale is liniar; the formula below is computed from the equation of the straight line passing
          // through those coordinates
          // see above: #define TARGETBITRATE m_pBasePin->m_pCaptureFilter->m_pCapturePin->m_lTargetBitrate
          D(1) dprintf("%s: Initial Frame  = %8lu (CapturePin target bitrate = %lu )\n",_fx_,dwMaxSizeThisFrame,TARGETBITRATE);
          if (  m_pBasePin->m_pCaptureFilter->m_pCapturePin
             && (dwTargetBitrate=TARGETBITRATE) <= BITRATE_LOWLIMIT
             && dwMaxSizeThisFrame >= LOWFRAMESIZE) {
                  aux = ((dwMaxSizeThisFrame - LOWFRAMESIZE) * dwTargetBitrate) / BITRATE_LOWLIMIT + LOWFRAMESIZE ;
                  ASSERT(aux <= dwMaxSizeThisFrame && aux>=LOWFRAMESIZE);
                  dwMaxSizeThisFrame=aux;
                  D(1) dprintf("%s: Adjusted Frame = %8lu (CapturePin target bitrate = %lu )\n",_fx_,dwMaxSizeThisFrame,dwTargetBitrate);
          }
        }


#ifdef DEBUG
        if(!g_skip_q)
#endif
        { DWORD dwTargetBitrate=0;
          // see above: #define TARGETBITRATE m_pBasePin->m_pCaptureFilter->m_pCapturePin->m_lTargetBitrate
          // the value 31 is computed from 10000UL / 322UL
          if (  m_pBasePin->m_pCaptureFilter->m_pCapturePin
             && (dwTargetBitrate=TARGETBITRATE) <= BITRATE_LOWLIMIT) {
                  D(1) dprintf("%s: [2] Initial m_dwImageQuality = %lu (CapturePin target bitrate = %lu )\n",_fx_,m_dwImageQuality,dwTargetBitrate);
                  m_dwImageQuality = ((BITRATE_LOWLIMIT - dwTargetBitrate) * 31) / BITRATE_LOWLIMIT ;
                  ASSERT(m_dwImageQuality<=31);   // m_dwImageQuality >=0 anyway (DWORD)
                  D(1) dprintf("%s: [2] Using m_dwImageQuality = %lu (CapturePin target bitrate = %lu )\n",_fx_,m_dwImageQuality,dwTargetBitrate);
                  //D(1) dprintf("%s: [2] Using m_dwImageQuality = %lu (CapturePin target bitrate = %lu )\n",_fx_,m_dwImageQuality,dwTargetBitrate);
          }
        }


        // We need to modify the frame number so that the codec can generate
        // a valid TR. TRs use MPIs as their units. So we need to generate a
        // frame number assuming a 29.97Hz capture rate, even though we will be
        // capturing at some other rate.
        if (m_dwLastTimestamp == 0xFFFFFFFF)
        {
                // This is the first frame
                m_dwFrame = 0UL;

                // Save the current time
                m_dwLastTimestamp = dwTimestamp;
        }
        else
        {
                // Compare the current timestamp to the last one we saved. The difference
                // will let us normalize the frame count to 29.97Hz.
                if (fKeyFrame)
                {
                        m_dwFrame = 0UL;
                        m_dwLastTimestamp = dwTimestamp;
                }
                else
                        m_dwFrame = (dwTimestamp - m_dwLastTimestamp) * 2997 / 100000UL;
        }

        if (fKeyFrame)
        {
                m_dwLastIFrameTime = dwTimestamp;
        }

#ifdef USE_SOFTWARE_CAMERA_CONTROL
        // Do we need to apply camera control operators first?
        if (IsSoftCamCtrlNeeded())
        {
                if (!IsSoftCamCtrlInserted())
                        InsertSoftCamCtrl();
        }
        else
        {
                if (IsSoftCamCtrlInserted())
                        RemoveSoftCamCtrl();
        }
#endif
        // Do we need to scale the input first?
        if (m_dwConversionType & CONVERSIONTYPE_SCALER)
        {
                // Get the input rectangle
                ComputeRectangle(m_pbiIn, m_pbiInt, m_pBasePin->m_pCaptureFilter->m_pCapDev->m_lCCZoom, m_pBasePin->m_pCaptureFilter->m_pCapDev->m_lCCPan, m_pBasePin->m_pCaptureFilter->m_pCapDev->m_lCCTilt, &rcRect, m_pBasePin->m_fFlipHorizontal, m_pBasePin->m_fFlipVertical);

                // Scale DIB
                ScaleDIB(m_pbiIn, pbyInput, m_pbiInt, m_pbyOut, &rcRect, m_pBasePin->m_fFlipHorizontal, m_pBasePin->m_fFlipVertical, m_pBasePin->m_fNoImageStretch, m_pBasePin->m_dwBlackEntry);

                icCompress.lpbiInput = m_pbiInt;
                icCompress.lpInput = m_pbyOut;
        }
        else
        {
                icCompress.lpbiInput = m_pbiIn;
                icCompress.lpInput = pbyInput;
        }

        // Do we preview the compressed data?
        if (m_pBasePin->m_pCaptureFilter->m_fPreviewCompressedData && m_pBasePin->m_pCaptureFilter->m_pPreviewPin && pdwPreviewSize)
        {
                // Hey! You can only do this if you have connected the preview pin...
                ASSERT(m_pBasePin->m_pCaptureFilter->m_pPreviewPin->IsConnected());

                icCompress.lpbiPrev = HEADER(m_pBasePin->m_pCaptureFilter->m_pPreviewPin->m_mt.pbFormat);
                icCompress.lpPrev = pbyPreview;
                *pdwPreviewSize = HEADER(m_pBasePin->m_pCaptureFilter->m_pPreviewPin->m_mt.pbFormat)->biSizeImage;
        }
        else
        {
                icCompress.lpbiPrev = NULL;
                icCompress.lpPrev = NULL;
        }

        icCompress.dwFlags = fKeyFrame ? ICCOMPRESS_KEYFRAME : 0;
        icCompress.lpbiOutput = m_pbiOut;
        icCompress.lpOutput = pbyOutput;
        icCompress.dwFrameSize = dwMaxSizeThisFrame;
        icCompress.dwQuality = 10000UL - (m_dwImageQuality * 322UL);
        icCompress.lFrameNum = m_dwFrame++;
        // The following was referenced by the H.26x encoders -> references to this pointer to a flag are gone from encoders
        icCompress.lpdwFlags = NULL;
        icCompress.lpckid = NULL;
        if (!m_pInstInfo || ((*m_pDriverProc)((DWORD)m_pInstInfo, NULL, ICM_COMPRESS, (LPARAM)&icCompress, sizeof(icCompress)) != ICERR_OK))
        {
                DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: Compression failed!", _fx_));
                Hr = E_FAIL;
                goto MyExit;
        }

        // Look for the bitstream info trailer
        pbsiT = (PH26X_RTP_BSINFO_TRAILER)(pbyOutput + m_pbiOut->biSizeImage - sizeof(H26X_RTP_BSINFO_TRAILER));

        // Update output size
        *pdwOutputSize = pbsiT->dwCompressedSize;
        *pdwBytesExtent = m_pbiOut->biSizeImage;

#if defined(DEBUG) && defined(DEBUG_ENCODING)
        wsprintf(szDebug, "Target: %ld bytes, Actual: %ld bytes\n", dwMaxSizeThisFrame, *pdwOutputSize);
        OutputDebugString(szDebug);
#endif

MyExit:
        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: end", _fx_));
        return Hr;
}

/****************************************************************************
 *  @doc INTERNAL CCONVERTMETHOD
 *
 *  @mfunc HRESULT | CH26XEncoder | CloseConverter | This method closes a
 *    H.26X encoder.

 *  @rdesc This method returns NOERROR.
 ***************************************************************************/
HRESULT CH26XEncoder::CloseConverter()
{
        FX_ENTRY("CH26XEncoder::CloseConverter")

        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: begin", _fx_));

        ASSERT(m_fConvert);

        // Validate input parameters
        if (m_pInstInfo)
        {
                // Terminate H.26X compression
                (*m_pDriverProc)((DWORD)m_pInstInfo, NULL, ICM_COMPRESS_END, 0L, 0L);

                // Terminate H.26X encoder
                (*m_pDriverProc)((DWORD)m_pInstInfo, NULL, DRV_CLOSE, 0L, 0L);
                (*m_pDriverProc)((DWORD)m_pInstInfo, NULL, DRV_FREE, 0L, 0L);
                m_pInstInfo = NULL;
        }

#if DXMRTP <= 0
        // Release TAPIH26X.DLL
        if (m_hTAPIH26XDLL)
                FreeLibrary(m_hTAPIH26XDLL);
#endif

        CConverter::CloseConverter();

        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: end", _fx_));

        return NOERROR;
}
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\net\tapi\skywalker\filters\video\tapivcap\h26xenc.h ===
/****************************************************************************
 *  @doc INTERNAL H26XENC
 *
 *  @module H26XEnc.h | Header file for the <c CH26XEncoder> class methods
 *    used to implement the H.26X video encoder.
 ***************************************************************************/

#ifndef _H26XENC_H_
#define _H26XENC_H_

/****************************************************************************
 *  @doc INTERNAL CH26XENCCLASS
 *
 *  @class CH26XEncoder | This class implement the H.263 video encoder.
 ***************************************************************************/
class CH26XEncoder : public CConverter
{
	public:

	DECLARE_IUNKNOWN
	CH26XEncoder(IN TCHAR *pObjectName, IN CTAPIBasePin *pBasePin, IN PBITMAPINFOHEADER pbiIn, IN PBITMAPINFOHEADER pbiOut, IN HRESULT *pHr);
	~CH26XEncoder();
	static HRESULT CALLBACK CreateH26XEncoder(IN CTAPIBasePin *pBasePin, IN PBITMAPINFOHEADER pbiIn, IN PBITMAPINFOHEADER pbiOut, OUT CConverter **ppConverter);

	// Format conversion routines
	HRESULT ConvertFrame(IN PBYTE pbyInput, IN DWORD dwInputSize, IN PBYTE pbyOutput, OUT PDWORD pdwOutputSize, OUT PDWORD pdwBytesExtent, IN PBYTE pbyPreview, OUT PDWORD pdwPreviewSize, IN BOOL fSendKeyFrame);
	HRESULT OpenConverter();
	HRESULT CloseConverter();

	protected:

	LPFNDRIVERPROC	m_pDriverProc;	// DriverProc() function pointer
#if DXMRTP <= 0
	HINSTANCE		m_hTAPIH26XDLL;	// DLL Handle to TAPIH263.dll or TAPIH261.dll
#endif
	LPINST			m_pInstInfo;
};

#endif // _H26XENC_H_
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\net\tapi\skywalker\filters\video\tapivcap\netstatp.h ===
/****************************************************************************
 *  @doc INTERNAL NETSTATP
 *
 *  @module NetStatP.h | Header file for the <c CNetworkStatsProperty>
 *    class used to implement a property page to test the new TAPI internal
 *    interface <i INetworkStats>.
 *
 *  @comm This code tests the TAPI Capture Pin <i INetworkStats>
 *    implementation. This code is only compiled if USE_PROPERTY_PAGES is
 *    defined.
 ***************************************************************************/

#ifndef _NETSTATP_H_
#define _NETSTATP_H_

#ifdef USE_PROPERTY_PAGES

#ifdef USE_NETWORK_STATISTICS

#define NUM_NETWORKSTATS_CONTROLS	4
#define IDC_RandomBitErrorRate		2
#define IDC_BurstErrorDuration		3
#define IDC_BurstErrorMaxFrequency	4
#define IDC_PacketLossRate			5

/****************************************************************************
 *  @doc INTERNAL CNETSTATPCLASS
 *
 *  @class CNetworkStatsProperty | This class implements handling of a
 *    single network statistics property in a property page.
 *
 *  @mdata int | CNetworkStatsProperty | m_NumProperties | Keeps
 *    track of the number of properties.
 *
 *  @mdata INetworkStats * | CNetworkStatsProperty | m_pInterface | Pointer
 *    to the <i INetworkStats> interface.
 *
 *  @comm This code tests the <i INetworkStats> Ks interface handler. This
 *    code is only compiled if USE_PROPERTY_PAGES is defined.
***************************************************************************/
class CNetworkStatsProperty : public CKSPropertyEditor 
{
	public:
	CNetworkStatsProperty(HWND hDlg, ULONG IDLabel, ULONG IDMinControl, ULONG IDMaxControl, ULONG IDDefaultControl, ULONG IDStepControl, ULONG IDEditControl, ULONG IDTrackbarControl, ULONG IDProgressControl, ULONG IDProperty, ULONG IDAutoControl, INetworkStats *pInterface);
	~CNetworkStatsProperty ();

	// CKSPropertyEditor base class pure virtual overrides
	HRESULT GetValue();
	HRESULT SetValue();
	HRESULT GetRange();
	BOOL CanAutoControl(void);
	BOOL GetAuto(void);
	BOOL SetAuto(BOOL fAuto);

	private:
	INetworkStats *m_pInterface;
};

/****************************************************************************
 *  @doc INTERNAL CNETSTATPCLASS
 *
 *  @class CNetworkStatsProperties | This class implements a property page
 *    to test the new TAPI internal interface <i INetworkStats>.
 *
 *  @mdata int | CNetworkStatsProperties | m_NumProperties | Keeps
 *    track of the number of properties.
 *
 *  @mdata INetworkStats * | CNetworkStatsProperties | m_pINetworkStats | Pointer
 *    to the <i INetworkStats> interface.
 *
 *  @mdata CNetworkStatsProperty * | CNetworkStatsProperties | m_Controls[NUM_NETWORKSTATS_CONTROLS] | Array
 *    of network statistics properties.
 *
 *  @comm This code tests the <i INetworkStats> Ks interface handler. This
 *    code is only compiled if USE_PROPERTY_PAGES is defined.
***************************************************************************/
class CNetworkStatsProperties : public CBasePropertyPage
{
	public:
	CNetworkStatsProperties(LPUNKNOWN pUnk, HRESULT *pHr);
	~CNetworkStatsProperties();

	HRESULT OnConnect(IUnknown *pUnk);
	HRESULT OnDisconnect();
	HRESULT OnActivate();
	HRESULT OnDeactivate();
	HRESULT OnApplyChanges();
	BOOL    OnReceiveMessage(HWND hWnd, UINT uMsg, WPARAM wParam, LPARAM lParam);

	private:

	void SetDirty();

	int m_NumProperties;
	INetworkStats *m_pINetworkStats;
	CNetworkStatsProperty *m_Controls[NUM_NETWORKSTATS_CONTROLS];
};

#endif // USE_NETWORK_STATISTICS

#endif // USE_PROPERTY_PAGES

#endif // _NETSTATP_H_
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\net\tapi\skywalker\filters\video\tapivcap\ivideo32.h ===
/****************************************************************************/
/*                                                                          */
/*  THIS CODE AND INFORMATION IS PROVIDED "AS IS" WITHOUT WARRANTY OF ANY   */
/*  KIND, EITHER EXPRESSED OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE     */
/*  IMPLIED WARRANTIES OF MERCHANTABILITY AND/OR FITNESS FOR A PARTICULAR   */
/*  PURPOSE.                                                                */
/*        MSVIDEO.H - Include file for Video APIs                           */
/*                                                                          */
/*        Note: You must include WINDOWS.H before including this file.      */
/*                                                                          */
/*        Copyright (c) 1990-1993, Microsoft Corp.  All rights reserved.    */
/*                                                                          */
/****************************************************************************/

#ifdef __cplusplus
extern "C" {            /* Assume C declarations for C++ */
#endif  /* __cplusplus */

#include <vfw.h>

// unicode conversions
int Iwcstombs(LPSTR lpstr, LPCWSTR lpwstr, int len);
int Imbstowcs(LPWSTR lpwstr, LPCSTR lpstr, int len);

typedef unsigned __int64 QUADWORD;
#define HVIDEOX HVIDEO
#define PTR32   LPVOID
#define PTR16   LPVOID
#ifndef DWORD_PTR
#define DWORD_PTR unsigned long
#endif
#ifndef INT_PTR
#define INT_PTR int
#endif
#ifndef LONG_PTR
#define LONG_PTR long
#endif
#ifndef UINT_PTR
#define UINT_PTR unsigned int
#endif

// 'cooked' SMPTE timecode.  this is organized so that
// timecode values can be compared as a single QUAD operation
// so long as frame rates match.
//
// it is treated as a fixed point 48bit binary real number
// with the decimal point always at 32.16
//
// the only non-integral frame rate is 29.97 (NTSC) which is
// indicated by 0 in the frame rate field.
//
typedef union _vidxtimecode {
   struct {
      WORD  wFrameRate;  // 0 == 29.97 frame rate
      WORD  wFrameFract; // fractional frames. range 0-FFFF
      DWORD dwFrames;    // frame count.
      };
   QUADWORD qw;          // for copy/compare operations.
   } VIDXTIMECODE;

// timecode + userdata
//
typedef struct _vidxtimecodedata {
   VIDXTIMECODE time;
   DWORD    dwSMPTEFlags;
   DWORD    dwUser;
   } VIDXTIMECODEDATA;

// structure of memory shared between driver and quartz
// capture. used to allow Quartz to slave a clock to
// the vsync interrupt.
//
// This memory region will be locked down prior to being
// passed to the driver in Win95 so that it may be accessed at
// interrupt time. Because of the way the thunking layer works,
// it is not advisable for the driver to attempt to lock this
// memory. The memory will be visible in all process contexts.
//
// The driver is responsible for updating nVsyncCount on each VSYNC
// or as often as possible.  Whenever nVsyncCount is updated, qwSystemTime
// should be updated also, and if SMPTE timecode corresponding to this VSYNC
// is available, tcdata should be updated also.  If SMPTE timecode for this
// VSYNC is NOT available, dwFlags should be changed to indicate there is no
// timecode infomation (clear the VSYNCMEM_FLAGS_SMPTE bit of dwFlags)
//
// While updating, the driver should set the low bit of the dwInUse flag to 1.
//
// The driver should set the dwFlags field to indicated the presense
// of valid nVsyncCount/qwSystemTime and tcdata.
//
// The driver is allowed to choose between setting qwSystemTime to the return
// value of QueryPerformanceCounter or the value of the Pentium tick.  It is
// recommended to use QPC on NT as the pentium tick is not necessarily available
// to application code in that environment.
//
// When the Quartz capture wrapper reads from this shared memory, it will check
// the dwInUse flag and also read twice comparing results to insure that it reads
// valid, consistent data.
//
typedef struct _vsyncmem {
   DWORD        dwInUse;       // low bit is non-zero when the driver is
                               // updating this struture.  other bits reserved.

   DWORD        nVsyncCount;  // VSYNC count
   QUADWORD     qwSystemTime; // QueryPerformanceCounter value at this VSYNC

   DWORD        dwFlags;      // flags indicate which fields are in use
   #define VSYNCMEM_TIME_MASK    0x0000000F // mask to get type of qwSystemTime
   #define VSYNCMEM_TIME_QPC     0x00000001 // qwSystemTime is QueryPerformanceCounter
   #define VSYNCMEM_TIME_PENTIUM 0x00000002 // qwSystemTime is pentium CPU tick

   #define VSYNCMEM_FLAG_SMPTE   0x00000010  // set if tcdata is valid

   DWORD        dwSpare;      // spare to align the next field on Quad boundary
   VIDXTIMECODEDATA tcdata;   // SMPTE timecode associated with this VSYNC
   } VSYNCMEM;

// DVM_xxx messages are defined in VFW.H
//
#ifndef DVM_CONFIGURE_START
  #define DVM_CONFIGURE_START 0x1000
#endif
#define DVM_CLOCK_BUFFER     (UINT)(DVM_CONFIGURE_START+0x10)
   //
   // dw1 = ptr to VSYNCMEM. ptr is valid until next DVM_CLOCK_BUFFER message
   //       or until driver is closed.
   // dw2 = size of VSYNCMEM buffer
   //
   // driver should return MMSYSERR_NOERROR (0) to indicate that it is
   // capable of keeping the contents of the VSYNCMEM buffer up to date.
   //


// VIDEOHDR + extra fields used by the thunking layer
//
typedef struct _thk_videohdr {
    //VIDEOHDREX vh;
    VIDEOHDR vh;
    PTR32      p32Buff;
    PTR16      p16Alloc;
    DWORD      dwMemHandle;
    DWORD      dwTile;
    DWORD_PTR  dwUser;          // use this instead of dwUser in VIDEOHDR
                                // because some drivers trash it! (Miro DC30)
    DWORD      dwIndex;         // which header is this in our array?
    PTR32      pStart;
} THKVIDEOHDR, FAR *LPTHKVIDEOHDR;

DWORD WINAPI vidxAllocHeaders(
   HVIDEOX     hVideo,
   UINT        nHeaders,
   UINT        cbHeader,
   PTR32 FAR * lpHdrs);
DWORD WINAPI NTvidxAllocHeaders(
   HVIDEOX     hVideo,
   UINT        nHeaders,
   UINT        cbHeader,
   PTR32 FAR * lpHdrs);

DWORD WINAPI vidxFreeHeaders(
   HVIDEOX hv);
DWORD WINAPI NTvidxFreeHeaders(
   HVIDEOX hv);

DWORD WINAPI vidxAllocBuffer (
   HVIDEOX     hv,
   UINT        iHdr,
   PTR32 FAR * pp32Hdr,
   DWORD       dwSize);
DWORD WINAPI NTvidxAllocBuffer (
   HVIDEOX     hv,
   UINT        iHdr,
   PTR32 FAR * pp32Hdr,
   DWORD       dwSize);

DWORD WINAPI vidxFreeBuffer (
   HVIDEOX hv,
   DWORD   p32Hdr);
DWORD WINAPI NTvidxFreeBuffer (
   HVIDEOX hv,
   DWORD_PTR p32Hdr);

DWORD WINAPI vidxFrame (
   HVIDEOX       hVideo,
   //LPVIDEOHDREX lpVHdr);
   LPVIDEOHDR lpVHdr);
DWORD WINAPI NTvidxFrame (
   HVIDEOX       hVideo,
   //LPVIDEOHDREX lpVHdr);
   LPVIDEOHDR lpVHdr);

DWORD WINAPI vidxAddBuffer (
   HVIDEOX       hVideo,
   PTR32         lpVHdr,
   DWORD         cbData);
DWORD WINAPI NTvidxAddBuffer (
   HVIDEOX       hVideo,
   PTR32         lpVHdr,
   DWORD         cbData);

DWORD WINAPI vidxAllocPreviewBuffer (
   HVIDEOX      hVideo,
   PTR32 FAR *  lpBits,
   UINT         cbHdr,
   DWORD        cbData);
DWORD WINAPI NTvidxAllocPreviewBuffer (
   HVIDEOX      hVideo,
   PTR32 FAR *  lpBits,
   UINT         cbHdr,
   DWORD        cbData);

DWORD WINAPI vidxFreePreviewBuffer (
   HVIDEOX     hVideo,
   PTR32       lpBits);
DWORD WINAPI NTvidxFreePreviewBuffer (
   HVIDEOX     hVideo,
   PTR32       lpBits);

// Needed for Win9x thunking
VOID WINAPI OpenMMDEVLDR(void);
VOID WINAPI CloseMMDEVLDR(void);

BOOL NTvideoInitHandleList(void);
void NTvideoDeleteHandleList(void);
DWORD WINAPI videoOpen(LPHVIDEO lphVideo, DWORD dwDevice, DWORD dwFlags);
DWORD WINAPI NTvideoOpen(LPHVIDEO lphVideo, DWORD dwDevice, DWORD dwFlags);
DWORD WINAPI videoClose(HVIDEO hVideo);
DWORD WINAPI NTvideoClose(HVIDEO hVideo);
DWORD WINAPI videoDialog(HVIDEO hVideo, HWND hWndParent, DWORD dwFlags);
DWORD WINAPI NTvideoDialog(HVIDEO hVideo, HWND hWndParent, DWORD dwFlags);
DWORD WINAPI videoGetChannelCaps(HVIDEO hVideo, LPCHANNEL_CAPS lpChannelCaps, DWORD dwSize);
DWORD WINAPI NTvideoGetChannelCaps(HVIDEO hVideo, LPCHANNEL_CAPS lpChannelCaps, DWORD dwSize);
DWORD WINAPI videoConfigure(HVIDEO hVideo, UINT msg, DWORD dwFlags, LPDWORD lpdwReturn, LPVOID lpData1, DWORD dwSize1, LPVOID lpData2, DWORD dwSize2);
DWORD WINAPI NTvideoConfigure(HVIDEO hVideo, UINT msg, DWORD dwFlags, LPDWORD lpdwReturn, LPVOID lpData1, DWORD dwSize1, LPVOID lpData2, DWORD dwSize2);
DWORD WINAPI videoFrame(HVIDEO hVideo, LPVIDEOHDR lpVHdr);
DWORD WINAPI NTvideoFrame(HVIDEO hVideo, LPVIDEOHDR lpVHdr);
DWORD WINAPI videoStreamInit(HVIDEO hVideo, DWORD dwMicroSecPerFrame, DWORD_PTR dwCallback, DWORD_PTR dwCallbackInst, DWORD dwFlags);
DWORD WINAPI NTvideoStreamInit(HVIDEO hVideo, DWORD dwMicroSecPerFrame, DWORD_PTR dwCallback, DWORD_PTR dwCallbackInst, DWORD dwFlags);
DWORD WINAPI videoStreamFini(HVIDEO hVideo);
DWORD WINAPI NTvideoStreamFini(HVIDEO hVideo);
DWORD WINAPI videoStreamReset(HVIDEO hVideo);
DWORD WINAPI NTvideoStreamReset(HVIDEO hVideo);
DWORD WINAPI videoStreamStart(HVIDEO hVideo);
DWORD WINAPI NTvideoStreamStart(HVIDEO hVideo);
DWORD WINAPI videoStreamStop(HVIDEO hVideo);
DWORD WINAPI NTvideoStreamStop(HVIDEO hVideo);
DWORD WINAPI videoCapDriverDescAndVer(DWORD dwDeviceID, LPTSTR lpszDesc, UINT cbDesc, LPTSTR lpszVer, UINT cbVer, LPTSTR lpszDllName, UINT cbDllName);
DWORD WINAPI NTvideoCapDriverDescAndVer(DWORD dwDeviceID, LPTSTR lpszDesc, UINT cbDesc, LPTSTR lpszVer, UINT cbVer, LPTSTR lpszDllName, UINT cbDllName);
LONG  WINAPI videoMessage(HVIDEO hVideo, UINT uMsg, LPARAM dw1, LPARAM dw2);
LONG WINAPI NTvideoMessage(HVIDEO hVideo, UINT uMsg, LPARAM dw1, LPARAM dw2);
DWORD WINAPI videoGetNumDevs(BOOL);
DWORD WINAPI videoFreeDriverList(void);

#ifdef __cplusplus
}                       /* End of extern "C" { */
#endif  /* __cplusplus */
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\net\tapi\skywalker\filters\video\tapivcap\netstats.cpp ===
/****************************************************************************
 *  @doc INTERNAL NETSTATS
 *
 *  @module NetStats.cpp | Source file for the <c CCapturePin> class methods
 *    used to implement the video capture output pin network statistics
 *    methods.
 ***************************************************************************/

#include "Precomp.h"

#ifdef USE_NETWORK_STATISTICS

/****************************************************************************
 *  @doc INTERNAL CCAPTURENETSTATMETHOD
 *
 *  @mfunc HRESULT | CCapturePin | SetChannelErrors | This
 *    method is used to inform the compressed output pin of the error channel
 *    conditions.
 *
 *  @parm CHANNELERRORS_S* | pChannelErrors | Specifies the error channel
 *    conditions.
 *
 *  @parm DWORD | dwLayerId | Specifies the ID of the encoding layer the
 *    call applies to. For standard audio and video encoders, this field is
 *    always set to 0. In the case of multi-layered encoders, this field
 *    shall be set to 0 for the base layer, 1 for the first enhancement
 *    layer, 2 for the next enhancement layer, etc
 *
 *  @rdesc This method returns an HRESULT value that depends on the
 *    implementation of the interface. HRESULT can include one of the
 *    following standard constants, or other values not listed:
 *
 *  @flag E_FAIL | Failure
 *  @flag E_POINTER | Null pointer argument
 *  @flag E_INVALIDARG | Invalid argument
 *  @flag E_NOTIMPL | Method is not supported
 *  @flag VFW_E_NOT_CONNECTED | Pin not connected yet
 *  @flag NOERROR | No error
 ***************************************************************************/
STDMETHODIMP CCapturePin::SetChannelErrors(IN CHANNELERRORS_S *pChannelErrors, IN DWORD dwLayerId)
{
	HRESULT Hr = NOERROR;

	FX_ENTRY("CCapturePin::SetChannelErrors")

	DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: begin", _fx_));

	// Validate input parameters
	ASSERT(pChannelErrors);
	if (!pChannelErrors)
	{
		DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: invalid input parameter", _fx_));
		Hr = E_POINTER;
		goto MyExit;
	}
	ASSERT(dwLayerId == 0);
	if (dwLayerId)
	{
		// We don't implement multi-layered encoding in this filter
		DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: invalid input parameter", _fx_));
		Hr = E_INVALIDARG;
		goto MyExit;
	}

	// Remember channel errors 
	m_ChannelErrors = *pChannelErrors;

MyExit:
	DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: end", _fx_));
	return Hr;
}

/****************************************************************************
 *  @doc INTERNAL CCAPTURENETSTATMETHOD
 *
 *  @mfunc HRESULT | CCapturePin | GetChannelErrors | This
 *    method is used to supply to the network sink filter the error channel
 *    conditions an output pin is currently setup for.
 *
 *  @parm CHANNELERRORS_S* | pChannelErrors | Specifies a pointer to a
 *    structure to receive error channel conditions.
 *
 *  @parm DWORD | dwLayerId | Specifies the ID of the encoding layer the
 *    call applies to. For standard audio and video encoders, this field is
 *    always set to 0. In the case of multi-layered encoders, this field
 *    shall be set to 0 for the base layer, 1 for the first enhancement
 *    layer, 2 for the next enhancement layer, etc
 *
 *  @rdesc This method returns an HRESULT value that depends on the
 *    implementation of the interface. HRESULT can include one of the
 *    following standard constants, or other values not listed:
 *
 *  @flag E_FAIL | Failure
 *  @flag E_POINTER | Null pointer argument
 *  @flag E_INVALIDARG | Invalid argument
 *  @flag E_NOTIMPL | Method is not supported
 *  @flag VFW_E_NOT_CONNECTED | Pin not connected yet
 *  @flag NOERROR | No error
 ***************************************************************************/
STDMETHODIMP CCapturePin::GetChannelErrors(OUT CHANNELERRORS_S *pChannelErrors, IN WORD dwLayerId)
{
	HRESULT Hr = NOERROR;

	FX_ENTRY("CCapturePin::GetChannelErrors")

	DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: begin", _fx_));

	// Validate input parameters
	ASSERT(pChannelErrors);
	if (!pChannelErrors)
	{
		DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: invalid input parameter", _fx_));
		Hr = E_POINTER;
		goto MyExit;
	}
	ASSERT(dwLayerId == 0);
	if (dwLayerId)
	{
		// We don't implement multi-layered encoding in this filter
		DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: invalid input parameter", _fx_));
		Hr = E_INVALIDARG;
		goto MyExit;
	}

	// Return channel errors 
	*pChannelErrors = m_ChannelErrors;

MyExit:
	DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: end", _fx_));
	return Hr;
}

/****************************************************************************
 *  @doc INTERNAL CCAPTURENETSTATMETHOD
 *
 *  @mfunc HRESULT | CCapturePin | GetChannelErrorsRange | This
 *    method is used to retrieve support, minimum, maximum, and default values
 *    for the channel error conditions an output pin may be setup for.
 *
 *  @parm CHANNELERRORS_S* | pMin | Used to retrieve the minimum values of
 *    channel error conditions an output pin maybe setup for.
 *
 *  @parm CHANNELERRORS_S* | pMax | Used to retrieve the maximum values of
 *    channel error conditions an output pin may be setup for.
 *
 *  @parm CHANNELERRORS_S* | pSteppingDelta | Used to retrieve the stepping
 *    delta values of channel error conditions an output pin may be setup for.
 *
 *  @parm CHANNELERRORS_S* | pDefault | Used to retrieve the default values
 *    of channel error conditions an output pin may be setup for.
 *
 *  @parm DWORD | dwLayerId | Specifies the ID of the encoding layer the
 *    call applies to. For standard audio and video encoders, this field is
 *    always set to 0. In the case of multi-layered encoders, this field
 *    shall be set to 0 for the base layer, 1 for the first enhancement
 *    layer, 2 for the next enhancement layer, etc
 *
 *  @rdesc This method returns an HRESULT value that depends on the
 *    implementation of the interface. HRESULT can include one of the
 *    following standard constants, or other values not listed:
 *
 *  @flag E_FAIL | Failure
 *  @flag E_POINTER | Null pointer argument
 *  @flag E_INVALIDARG | Invalid argument
 *  @flag E_NOTIMPL | Method is not supported
 *  @flag VFW_E_NOT_CONNECTED | Pin not connected yet
 *  @flag NOERROR | No error
 ***************************************************************************/
STDMETHODIMP CCapturePin::GetChannelErrorsRange(OUT CHANNELERRORS_S *pMin, OUT CHANNELERRORS_S *pMax, OUT CHANNELERRORS_S *pSteppingDelta, OUT CHANNELERRORS_S *pDefault, IN DWORD dwLayerId)
{
	HRESULT Hr = NOERROR;

	FX_ENTRY("CCapturePin::GetChannelErrorsRange")

	DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: begin", _fx_));

	// Validate input parameters
	ASSERT(pMin);
	ASSERT(pMax);
	ASSERT(pSteppingDelta);
	ASSERT(pDefault);
	if (!pMin || !pMax || !pSteppingDelta || !pDefault)
	{
		DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: invalid input parameter", _fx_));
		Hr = E_POINTER;
		goto MyExit;
	}
	ASSERT(dwLayerId == 0);
	if (dwLayerId)
	{
		// We don't implement multi-layered encoding in this filter
		DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: invalid input parameter", _fx_));
		Hr = E_INVALIDARG;
		goto MyExit;
	}

	// Return channel error ranges 
	*pMin = m_ChannelErrorsMin;
	*pMax = m_ChannelErrorsMax;
	*pSteppingDelta = m_ChannelErrorsSteppingDelta;
	*pDefault = m_ChannelErrorsDefault;

MyExit:
	DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: end", _fx_));
	return Hr;
}

/****************************************************************************
 *  @doc INTERNAL CCAPTURENETSTATMETHOD
 *
 *  @mfunc HRESULT | CCapturePin | SetPacketLossRate | This
 *    method is used to inform an output pin of the channel packet loss rate.
 *
 *  @parm DWORD | dwPacketLossRate | Specifies the packet loss rate of the
 *    channel in multiples of 10-6.
 *
 *  @parm DWORD | dwLayerId | Specifies the ID of the encoding layer the
 *    call applies to. For standard audio and video encoders, this field is
 *    always set to 0. In the case of multi-layered encoders, this field
 *    shall be set to 0 for the base layer, 1 for the first enhancement
 *    layer, 2 for the next enhancement layer, etc
 *
 *  @rdesc This method returns an HRESULT value that depends on the
 *    implementation of the interface. HRESULT can include one of the
 *    following standard constants, or other values not listed:
 *
 *  @flag E_FAIL | Failure
 *  @flag E_INVALIDARG | Invalid argument
 *  @flag E_NOTIMPL | Method is not supported
 *  @flag VFW_E_NOT_CONNECTED | Pin not connected yet
 *  @flag NOERROR | No error
 ***************************************************************************/
STDMETHODIMP CCapturePin::SetPacketLossRate(IN DWORD dwPacketLossRate, IN DWORD dwLayerId)
{
	HRESULT Hr = NOERROR;

	FX_ENTRY("CCapturePin::SetPacketLossRate")

	DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: begin", _fx_));

	// Validate input parameters
	ASSERT(dwLayerId == 0);
	if (dwLayerId)
	{
		// We don't implement multi-layered encoding in this filter
		DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: invalid input parameter", _fx_));
		Hr = E_INVALIDARG;
		goto MyExit;
	}

	// Remember packet loss rate 
	m_dwPacketLossRate = dwPacketLossRate;

MyExit:
	DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: end", _fx_));
	return Hr;
}

/****************************************************************************
 *  @doc INTERNAL CCAPTURENETSTATMETHOD
 *
 *  @mfunc HRESULT | CCapturePin | GetPacketLossRate | This
 *    method is used to supply to the network sink filter the packet loss rate
 *    channel conditions an output pin is currently setup for.
 *
 *  @parm LPDWORD | pdwPacketLossRate | Specifies a pointer to a DWORD to
 *    receive the packet loss rate of the channel an audio output pin is
 *    currently setup for, in multiples of 10-6.
 *
 *  @parm DWORD | dwLayerId | Specifies the ID of the encoding layer the
 *    call applies to. For standard audio and video encoders, this field is
 *    always set to 0. In the case of multi-layered encoders, this field
 *    shall be set to 0 for the base layer, 1 for the first enhancement
 *    layer, 2 for the next enhancement layer, etc
 *
 *  @rdesc This method returns an HRESULT value that depends on the
 *    implementation of the interface. HRESULT can include one of the
 *    following standard constants, or other values not listed:
 *
 *  @flag E_FAIL | Failure
 *  @flag E_POINTER | Null pointer argument
 *  @flag E_INVALIDARG | Invalid argument
 *  @flag E_NOTIMPL | Method is not supported
 *  @flag VFW_E_NOT_CONNECTED | Pin not connected yet
 *  @flag NOERROR | No error
 ***************************************************************************/
STDMETHODIMP CCapturePin::GetPacketLossRate(OUT LPDWORD pdwPacketLossRate, IN DWORD dwLayerId)
{
	HRESULT Hr = NOERROR;

	FX_ENTRY("CCapturePin::GetPacketLossRate")

	DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: begin", _fx_));

	// Validate input parameters
	ASSERT(pdwPacketLossRate);
	if (!pdwPacketLossRate)
	{
		DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: invalid input parameter", _fx_));
		Hr = E_POINTER;
		goto MyExit;
	}
	ASSERT(dwLayerId == 0);
	if (dwLayerId)
	{
		// We don't implement multi-layered encoding in this filter
		DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: invalid input parameter", _fx_));
		Hr = E_INVALIDARG;
		goto MyExit;
	}

	// Return packet loss rate we are setup for
	*pdwPacketLossRate = m_dwPacketLossRate;

MyExit:
	DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: end", _fx_));
	return Hr;
}

/****************************************************************************
 *  @doc INTERNAL CCAPTURENETSTATMETHOD
 *
 *  @mfunc HRESULT | CCapturePin | GetPacketLossRateRange | This
 *    method is used to retrieve support, minimum, maximum, and default values
 *    for the packet loss rate conditions an output pin may be setup for.
 *
 *  @parm LPDWORD | pdwMin | Used to retrieve the minimum packet loss rate
 *    an output pin may be setup for.
 *
 *  @parm LPDWORD | pdwMax | Used to retrieve the maximum packet loss rate
 *    an output pin may be setup for.
 *
 *  @parm LPDWORD | pdwSteppingDelta | Used to retrieve the stepping delta
 *    values of packet loss rate an output pin may be setup for.
 *
 *  @parm LPDWORD | pdwDefault | Used to retrieve the default packet loss
 *    rate an output pin is setup for.
 *
 *  @parm DWORD | dwLayerId | Specifies the ID of the encoding layer the
 *    call applies to. For standard audio and video encoders, this field is
 *    always set to 0. In the case of multi-layered encoders, this field
 *    shall be set to 0 for the base layer, 1 for the first enhancement
 *    layer, 2 for the next enhancement layer, etc
 *
 *  @rdesc This method returns an HRESULT value that depends on the
 *    implementation of the interface. HRESULT can include one of the
 *    following standard constants, or other values not listed:
 *
 *  @flag E_FAIL | Failure
 *  @flag E_POINTER | Null pointer argument
 *  @flag E_INVALIDARG | Invalid argument
 *  @flag E_NOTIMPL | Method is not supported
 *  @flag VFW_E_NOT_CONNECTED | Pin not connected yet
 *  @flag NOERROR | No error
 ***************************************************************************/
STDMETHODIMP CCapturePin::GetPacketLossRateRange(OUT LPDWORD pdwMin, OUT LPDWORD pdwMax, OUT LPDWORD pdwSteppingDelta, OUT LPDWORD pdwDefault, IN DWORD dwLayerId)
{
	HRESULT Hr = NOERROR;

	FX_ENTRY("CCapturePin::GetPacketLossRateRange")

	DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: begin", _fx_));

	// Validate input parameters
	ASSERT(pdwMin);
	ASSERT(pdwMax);
	ASSERT(pdwSteppingDelta);
	ASSERT(pdwDefault);
	if (!pdwMin || !pdwMax || !pdwSteppingDelta || !pdwDefault)
	{
		DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: invalid input parameter", _fx_));
		Hr = E_POINTER;
		goto MyExit;
	}
	ASSERT(dwLayerId == 0);
	if (dwLayerId)
	{
		// We don't implement multi-layered encoding in this filter
		DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: invalid input parameter", _fx_));
		Hr = E_INVALIDARG;
		goto MyExit;
	}

	// Return packet loss rate ranges 
	*pdwMin = m_dwPacketLossRateMin;
	*pdwMax = m_dwPacketLossRateMax;
	*pdwSteppingDelta = m_dwPacketLossRateSteppingDelta;
	*pdwDefault = m_dwPacketLossRateDefault;

MyExit:
	DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: end", _fx_));
	return Hr;
}

#endif
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\net\tapi\skywalker\filters\video\tapivcap\precomp.h ===
/****************************************************************************
 *  @doc INTERNAL PRECOMP
 *
 *  @module Precomp.h | Master header file.
 ***************************************************************************/

#ifndef _PRECOMP_VCAP_H_
#define _PRECOMP_VCAP_H_

#include <windows.h>
#include <windowsx.h>
#include <mmsystem.h>
#include <streams.h>
#include <vfw.h>
#include <stdlib.h>
#if defined (NT_BUILD)
#include "vc50\msviddrv.h"
#else
#include "msviddrv.h"
#endif 
#include "devioctl.h"
#include "ks.h"
#include "ksmedia.h"
#include <commctrl.h>
#include <olectl.h>
#include <memory.h>
#include <ksproxy.h>
#include <TAPIVid.h>
#include <tptrace.h>
#include <filterid.h>
#include <H26XInc.h>
#include <TAPIH26X.h>
#include "DevEnum.h"
#include "IVideo32.h"
#include "PropEdit.h"
#include "Resource.h"
#include "NetStatP.h"
#include "ProgRefP.h"
#include "CPUCP.h"
#include "ProcAmpP.h"
#include "CameraCP.h"
#include "h245vid.h"
#include "TAPIVCap.h"
#include "BasePin.h"
#include "Convert.h"
#include "Device.h"
#include "DeviceP.h"
#include "Capture.h"
#include "CaptureP.h"
#include "Preview.h"
#include "PreviewP.h"
#include "RtpPd.h"
#include "RtpPdP.h"
#include "Formats.h"
#include "Overlay.h"
#include "Thunk.h"
#include "WDMDlgs.h"
#include "H26XEnc.h"
#include "ProcUtil.h"
#include "vidctemp.h"

#endif // _PRECOMP_VCAP_H_
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\net\tapi\skywalker\filters\video\tapivcap\netstatp.cpp ===
/****************************************************************************
 *  @doc INTERNAL NETSTATP
 *
 *  @module NetStatP.cpp | Source file for the <c CNetworkStatsProperty>
 *    class used to implement a property page to test the new TAPI internal
 *    interface <i INetworkStats>.
 *
 *  @comm This code tests the TAPI Capture Pin <i INetworkStats>
 *    implementation. This code is only compiled if USE_PROPERTY_PAGES is
 *    defined.
 ***************************************************************************/

#include "Precomp.h"

#ifdef USE_PROPERTY_PAGES

#ifdef USE_NETWORK_STATISTICS

// Some hack...
CHANNELERRORS_S g_CurrentChannelErrors = {0};
CHANNELERRORS_S g_MinChannelErrors = {0};
CHANNELERRORS_S g_MaxChannelErrors = {0};
CHANNELERRORS_S g_StepChannelErrors = {0};
CHANNELERRORS_S g_DefaultChannelErrors = {0};


/****************************************************************************
 *  @doc INTERNAL CNETSTATPMETHOD
 *
 *  @mfunc void | CNetworkStatsProperty | CNetworkStatsProperty | This
 *    method is the constructor for network statistics property objects. It
 *    calls the base class constructor, calls InitCommonControlsEx, and saves
 *    a pointer to the <i INetworkStats> interface.
 *
 *  @parm HWND | hDlg | Specifies a handle to the parent property page.
 *
 *  @parm ULONG | IDLabel | Specifies a label ID for the property.
 *
 *  @parm ULONG | IDMinControl | Specifies a label ID for the associated
 *    property edit control where the Minimum value of the property appears.
 *
 *  @parm ULONG | IDMaxControl | Specifies a label ID for the associated
 *    property edit control where the Maximum value of the property appears.
 *
 *  @parm ULONG | IDDefaultControl | Specifies a label ID for the associated
 *    property edit control where the Default value of the property appears.
 *
 *  @parm ULONG | IDStepControl | Specifies a label ID for the associated
 *    property edit control where the Stepping Delta value of the property appears.
 *
 *  @parm ULONG | IDEditControl | Specifies a label ID for the associated
 *    property edit control where the value of the property appears.
 *
 *  @parm ULONG | IDTrackbarControl | Specifies a label ID for the associated
 *    property slide bar.
 *
 *  @parm ULONG | IDProgressControl | Specifies a label ID for the associated
 *    property progress bar.
 *
 *  @parm ULONG | IDProperty | Specifies the ID of the Ks property.
 *
 *  @parm INetworkStats* | pInterface | Specifies a pointer to the
 *    <i INetworkStats> interface.
 *
 *  @rdesc Nada.
 ***************************************************************************/
CNetworkStatsProperty::CNetworkStatsProperty(HWND hDlg, ULONG IDLabel, ULONG IDMinControl, ULONG IDMaxControl, ULONG IDDefaultControl, ULONG IDStepControl, ULONG IDEditControl, ULONG IDTrackbarControl, ULONG IDProgressControl, ULONG IDProperty, ULONG IDAutoControl, INetworkStats *pInterface)
: CKSPropertyEditor(hDlg, IDLabel, IDMinControl, IDMaxControl, IDDefaultControl, IDStepControl, IDEditControl, IDTrackbarControl, IDProgressControl, IDProperty, IDAutoControl)
{
	INITCOMMONCONTROLSEX cc;

	FX_ENTRY("CNetworkStatsProperty::CNetworkStatsProperty")

	DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: begin", _fx_));

	cc.dwSize = sizeof (INITCOMMONCONTROLSEX);
	cc.dwICC  = ICC_UPDOWN_CLASS | ICC_BAR_CLASSES;

	InitCommonControlsEx(&cc);

	// It's fine if the interface pointer is NULL, we'll grey the
	// associated items in the property page
	m_pInterface = pInterface;

	DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: end", _fx_));
}

/****************************************************************************
 *  @doc INTERNAL CNETSTATPMETHOD
 *
 *  @mfunc void | CNetworkStatsProperty | ~CNetworkStatsProperty | This
 *    method is the destructor for network statistics property objects. It
 *    simply calls the base class destructor.
 *
 *  @rdesc Nada.
 ***************************************************************************/
CNetworkStatsProperty::~CNetworkStatsProperty()
{
	FX_ENTRY("CNetworkStatsProperty::~CNetworkStatsProperty")

	DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: begin", _fx_));

	DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: end", _fx_));
}

/****************************************************************************
 *  @doc INTERNAL CNETSTATPMETHOD
 *
 *  @mfunc HRESULT | CNetworkStatsProperty | GetValue | This method queries for
 *    the value of a property.
 *
 *  @rdesc This method returns an HRESULT value that depends on the
 *    implementation of the interface. HRESULT can include one of the
 *    following standard constants, or other values not listed:
 *
 *  @flag E_FAIL | Failure
 *  @flag E_POINTER | Null pointer argument
 *  @flag E_NOTIMPL | Method is not supported
 *  @flag NOERROR | No error
 ***************************************************************************/
HRESULT CNetworkStatsProperty::GetValue()
{
	HRESULT Hr = E_NOTIMPL;

	FX_ENTRY("CNetworkStatsProperty::GetValue")

	DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: begin", _fx_));

	switch (m_IDProperty)
	{
		case IDC_RandomBitErrorRate:
			if (m_pInterface && SUCCEEDED (Hr = m_pInterface->GetChannelErrors(&g_CurrentChannelErrors, 0UL)))
			{
				m_CurrentValue = g_CurrentChannelErrors.dwRandomBitErrorRate;
				DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s:   SUCCESS: RandomBitErrorRate=%ld", _fx_, m_CurrentValue));
			}
			else
			{
				DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: IOCTL failed Hr=0x%08lX", _fx_, Hr));
			}
			break;
		case IDC_BurstErrorDuration:
			Hr = NOERROR;
			if (m_pInterface)
			{
				m_CurrentValue = g_CurrentChannelErrors.dwBurstErrorDuration;
				DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s:   SUCCESS: BurstErrorDuration=%ld", _fx_, m_CurrentValue));
			}
			else
			{
				DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: IOCTL failed Hr=0x%08lX", _fx_, Hr));
			}
			break;
		case IDC_BurstErrorMaxFrequency:
			Hr = NOERROR;
			if (m_pInterface)
			{
				m_CurrentValue = g_CurrentChannelErrors.dwBurstErrorMaxFrequency;
				DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s:   SUCCESS: BurstErrorMaxFrequency=%ld", _fx_, m_CurrentValue));
			}
			else
			{
				DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: IOCTL failed Hr=0x%08lX", _fx_, Hr));
			}
			break;
		case IDC_PacketLossRate:
			if (m_pInterface && SUCCEEDED (Hr = m_pInterface->GetPacketLossRate((LPDWORD)&m_CurrentValue, 0UL)))
			{
				DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s:   SUCCESS: *pdwPacketLossRate=%ld", _fx_, m_CurrentValue));
			}
			else
			{
				DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: IOCTL failed Hr=0x%08lX", _fx_, Hr));
			}
			break;
		default:
			Hr = E_UNEXPECTED;
			DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: Unknown silence control property", _fx_));
	}

	DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: end", _fx_));
	return Hr;
}

/****************************************************************************
 *  @doc INTERNAL CNETSTATPMETHOD
 *
 *  @mfunc HRESULT | CNetworkStatsProperty | SetValue | This method sets the
 *    value of a property.
 *
 *  @rdesc This method returns an HRESULT value that depends on the
 *    implementation of the interface. HRESULT can include one of the
 *    following standard constants, or other values not listed:
 *
 *  @flag E_FAIL | Failure
 *  @flag E_POINTER | Null pointer argument
 *  @flag E_NOTIMPL | Method is not supported
 *  @flag NOERROR | No error
 ***************************************************************************/
HRESULT CNetworkStatsProperty::SetValue()
{
	HRESULT Hr = E_NOTIMPL;

	FX_ENTRY("CNetworkStatsProperty::SetValue")

	DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: begin", _fx_));

	switch (m_IDProperty)
	{
		case IDC_RandomBitErrorRate:
			// We'll only apply this when we get to KSPROPERTY_NETWORKSTATS_CHANNELERRORS_BurstErrorMaxFrequency
			g_CurrentChannelErrors.dwRandomBitErrorRate = m_CurrentValue;
			Hr = NOERROR;
			if (m_pInterface)
			{
				DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s:   SUCCESS: RandomBitErrorRate=%ld", _fx_, m_CurrentValue));
			}
			else
			{
				DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: IOCTL failed Hr=0x%08lX", _fx_, Hr));
			}
			break;
		case IDC_BurstErrorDuration:
			// We'll only apply this when we get to KSPROPERTY_NETWORKSTATS_CHANNELERRORS_BurstErrorMaxFrequency
			g_CurrentChannelErrors.dwBurstErrorDuration = m_CurrentValue;
			Hr = NOERROR;
			if (m_pInterface)
			{
				DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s:   SUCCESS: BurstErrorDuration=%ld", _fx_, m_CurrentValue));
			}
			else
			{
				DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: IOCTL failed Hr=0x%08lX", _fx_, Hr));
			}
			break;
		case IDC_BurstErrorMaxFrequency:
			g_CurrentChannelErrors.dwBurstErrorMaxFrequency = m_CurrentValue;
			if (m_pInterface && SUCCEEDED (Hr = m_pInterface->SetChannelErrors(&g_CurrentChannelErrors, 0UL)))
			{
				DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s:   SUCCESS: BurstErrorMaxFrequency=%ld", _fx_, m_CurrentValue));
			}
			else
			{
				DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: IOCTL failed Hr=0x%08lX", _fx_, Hr));
			}
			break;
		case IDC_PacketLossRate:
			if (m_pInterface && SUCCEEDED (Hr = m_pInterface->SetPacketLossRate((DWORD)m_CurrentValue, 0UL)))
			{
				DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s:   SUCCESS: dwPacketLossRate=%ld", _fx_, m_CurrentValue));
			}
			else
			{
				DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: IOCTL failed Hr=0x%08lX", _fx_, Hr));
			}
			break;
		default:
			Hr = E_UNEXPECTED;
			DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: Unknown silence control property", _fx_));
	}

	DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: end", _fx_));
	return Hr;
}

/****************************************************************************
 *  @doc INTERNAL CNETSTATPMETHOD
 *
 *  @mfunc HRESULT | CNetworkStatsProperty | GetRange | This method retrieves
 *    the range information of a property.
 *
 *  @rdesc This method returns an HRESULT value that depends on the
 *    implementation of the interface. HRESULT can include one of the
 *    following standard constants, or other values not listed:
 *
 *  @flag E_FAIL | Failure
 *  @flag E_POINTER | Null pointer argument
 *  @flag E_NOTIMPL | Method is not supported
 *  @flag NOERROR | No error
 ***************************************************************************/
HRESULT CNetworkStatsProperty::GetRange()
{
	HRESULT Hr = E_NOTIMPL;

	FX_ENTRY("CNetworkStatsProperty::GetRange")

	DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: begin", _fx_));

	switch (m_IDProperty)
	{
		case IDC_RandomBitErrorRate:
			if (m_pInterface && SUCCEEDED (Hr = m_pInterface->GetChannelErrorsRange(&g_MinChannelErrors, &g_MaxChannelErrors, &g_StepChannelErrors, &g_DefaultChannelErrors, 0UL)))
			{
				m_Min = g_MinChannelErrors.dwRandomBitErrorRate;
				m_Max = g_MaxChannelErrors.dwRandomBitErrorRate;
				m_SteppingDelta = g_StepChannelErrors.dwRandomBitErrorRate;
				m_DefaultValue = g_DefaultChannelErrors.dwRandomBitErrorRate;
				DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s:   SUCCESS: RandomBitErrorRate=%ld %ld %ld %ld", _fx_, m_Min, m_Max, m_SteppingDelta, m_DefaultValue));
			}
			else
			{
				DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: IOCTL failed Hr=0x%08lX", _fx_, Hr));
			}
			break;
		case IDC_BurstErrorDuration:
			if (m_pInterface)
			{
				// We've already queried for the range information
				m_Min = g_MinChannelErrors.dwBurstErrorDuration;
				m_Max = g_MaxChannelErrors.dwBurstErrorDuration;
				m_SteppingDelta = g_StepChannelErrors.dwBurstErrorDuration;
				m_DefaultValue = g_DefaultChannelErrors.dwBurstErrorDuration;
				Hr = NOERROR;
				DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s:   SUCCESS: BurstErrorDuration=%ld %ld %ld %ld", _fx_, m_Min, m_Max, m_SteppingDelta, m_DefaultValue));
			}
			else
			{
				DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: IOCTL failed Hr=0x%08lX", _fx_, Hr));
			}
			break;
		case IDC_BurstErrorMaxFrequency:
			if (m_pInterface)
			{
				// We've already queried for the range information
				m_Min = g_MinChannelErrors.dwBurstErrorMaxFrequency;
				m_Max = g_MaxChannelErrors.dwBurstErrorMaxFrequency;
				m_SteppingDelta = g_StepChannelErrors.dwBurstErrorMaxFrequency;
				m_DefaultValue = g_DefaultChannelErrors.dwBurstErrorMaxFrequency;
				Hr = NOERROR;
				DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s:   SUCCESS: BurstErrorMaxFrequency=%ld %ld %ld %ld", _fx_, m_Min, m_Max, m_SteppingDelta, m_DefaultValue));
			}
			else
			{
				DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: IOCTL failed Hr=0x%08lX", _fx_, Hr));
			}
			break;
		case IDC_PacketLossRate:
			if (m_pInterface && SUCCEEDED (Hr = m_pInterface->GetPacketLossRateRange((LPDWORD)&m_Min, (LPDWORD)&m_Max, (LPDWORD)&m_SteppingDelta, (LPDWORD)&m_DefaultValue, 0UL)))
			{
				DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s:   SUCCESS: *plMin=%ld, *plMax=%ld, *plSteppingDelta=%ld, *plDefault", _fx_, m_Min, m_Max, m_SteppingDelta, m_DefaultValue));
			}
			else
			{
				DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: IOCTL failed Hr=0x%08lX", _fx_, Hr));
			}
			break;
		default:
			Hr = E_UNEXPECTED;
			DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: Unknown network statistics property", _fx_));
	}

	DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: end", _fx_));
	return Hr;
}

/****************************************************************************
 *  @doc INTERNAL CNETSTATPMETHOD
 *
 *  @mfunc HRESULT | CNetworkStatsProperty | CanAutoControl | This method
 *    retrieves the automatic control capabilities for a property.
 *
 *  @rdesc This method returns TRUE if automatic control is supported, FALSE
 *    otherwise.
 ***************************************************************************/
BOOL CNetworkStatsProperty::CanAutoControl(void)
{
	FX_ENTRY("CNetworkStatsProperty::CanAutoControl")

	DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: begin", _fx_));

	DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: end", _fx_));

	return FALSE;
}

/****************************************************************************
 *  @doc INTERNAL CNETSTATPMETHOD
 *
 *  @mfunc HRESULT | CNetworkStatsProperty | GetAuto | This method
 *    retrieves the current automatic control mode of a property.
 *
 *  @rdesc This method returns TRUE if automatic control is supported, FALSE
 *    otherwise.
 ***************************************************************************/
BOOL CNetworkStatsProperty::GetAuto(void)
{
	FX_ENTRY("CNetworkStatsProperty::GetAuto")

	DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: begin", _fx_));

	DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: end", _fx_));

	return FALSE; 
}

/****************************************************************************
 *  @doc INTERNAL CNETSTATPMETHOD
 *
 *  @mfunc HRESULT | CNetworkStatsProperty | SetAuto | This method
 *    sets the automatic control mode of a property.
 *
 *  @parm BOOL | fAuto | Specifies the automatic control mode.
 *
 *  @rdesc This method returns TRUE.
 ***************************************************************************/
BOOL CNetworkStatsProperty::SetAuto(BOOL fAuto)
{
	FX_ENTRY("CNetworkStatsProperty::SetAuto")

	DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: begin", _fx_));

	DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: end", _fx_));

	return TRUE; 
}

/****************************************************************************
 *  @doc INTERNAL CNETSTATPMETHOD
 *
 *  @mfunc CUnknown* | CNetworkStatsProperties | CreateInstance | This
 *    method is called by DShow to create an instance of a Network Statistics
 *    Property Page. It is referred to in the global structure <t g_Templates>.
 *
 *  @parm LPUNKNOWN | pUnkOuter | Specifies the outer unknown, if any.
 *
 *  @parm HRESULT* | pHr | Specifies the place in which to put any error return.
 *
 *  @rdesc Returns a pointer to the nondelegating CUnknown portion of the
 *    object, or NULL otherwise.
 ***************************************************************************/
CUnknown* CALLBACK CNetworkStatsPropertiesCreateInstance(LPUNKNOWN pUnkOuter, HRESULT *pHr) 
{
	CUnknown *pUnknown = (CUnknown *)NULL;

	FX_ENTRY("CNetworkStatsPropertiesCreateInstance")

	DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: begin", _fx_));

	// Validate input parameters
	ASSERT(pHr);
	if (!pHr)
	{
		DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: invalid input parameter", _fx_));
		goto MyExit;
	}

	if (!(pUnknown = new CNetworkStatsProperties(pUnkOuter, pHr)))
	{
		*pHr = E_OUTOFMEMORY;
		DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: new CNetworkStatsProperties failed", _fx_));
	}
	else
	{
		DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s:   SUCCESS: new CNetworkStatsProperties created", _fx_));
	}

MyExit:
	DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: end", _fx_));
	return pUnknown;
}

/****************************************************************************
 *  @doc INTERNAL CNETSTATPMETHOD
 *
 *  @mfunc void | CNetworkStatsProperties | CNetworkStatsProperties | This
 *    method is the constructor for the property page object. It simply
 *    calls the constructor of the property page base class.
 *
 *  @parm LPUNKNOWN | pUnkOuter | Specifies the outer unknown, if any.
 *
 *  @parm HRESULT* | pHr | Specifies the place in which to put any error return.
 *
 *  @rdesc Nada.
 ***************************************************************************/
CNetworkStatsProperties::CNetworkStatsProperties(LPUNKNOWN pUnk, HRESULT *pHr) : CBasePropertyPage(NAME("NetworkStats Property Page"), pUnk, IDD_NetworkStatsProperties, IDS_NETWORKSTATSPROPNAME)
{
	FX_ENTRY("CNetworkStatsProperties::CNetworkStatsProperties")

	DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: begin", _fx_));

	m_pINetworkStats = NULL;
	m_NumProperties = NUM_NETWORKSTATS_CONTROLS;

	for (int i = 0; i < m_NumProperties; i++)
		m_Controls[i] = NULL;

	DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: end", _fx_));
}

/****************************************************************************
 *  @doc INTERNAL CNETSTATPMETHOD
 *
 *  @mfunc void | CNetworkStatsProperties | ~CNetworkStatsProperties | This
 *    method is the destructor for network statistics property page. It
 *    simply calls the base class destructor after deleting all the controls.
 *
 *  @rdesc Nada.
 ***************************************************************************/
CNetworkStatsProperties::~CNetworkStatsProperties()
{
	int		j;

	FX_ENTRY("CNetworkStatsProperties::~CNetworkStatsProperties")

	DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: begin", _fx_));

	// Free the controls
	for (j = 0; j < m_NumProperties; j++)
	{
		if (m_Controls[j])
		{
			DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s:   SUCCESS: deleting m_Controls[%ld]=0x%08lX", _fx_, j, m_Controls[j]));
			delete m_Controls[j], m_Controls[j] = NULL;
		}
		else
		{
			DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   WARNING: control already freed", _fx_));
		}
	}

	DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: end", _fx_));
}

/****************************************************************************
 *  @doc INTERNAL CNETSTATPMETHOD
 *
 *  @mfunc HRESULT | CNetworkStatsProperties | OnConnect | This
 *    method is called when the property page is connected to the filter.
 *
 *  @parm LPUNKNOWN | pUnknown | Specifies the outer unknown, if any.
 *
 *  @parm HRESULT* | pHr | Specifies the place in which to put any error return.
 *
 *  @rdesc This method returns an HRESULT value that depends on the
 *    implementation of the interface. HRESULT can include one of the
 *    following standard constants, or other values not listed:
 *
 *  @flag E_FAIL | Failure
 *  @flag E_POINTER | Null pointer argument
 *  @flag E_NOTIMPL | Method is not supported
 *  @flag NOERROR | No error
 ***************************************************************************/
HRESULT CNetworkStatsProperties::OnConnect(IUnknown *pUnk)
{
	HRESULT Hr = NOERROR;

	FX_ENTRY("CNetworkStatsProperties::OnConnect")

	DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: begin", _fx_));

	// Validate input parameters
	ASSERT(pUnk);
	if (!pUnk)
	{
		DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: invalid input parameter", _fx_));
		Hr = E_POINTER;
		goto MyExit;
	}

	// Get the network statistics interface
	if (SUCCEEDED (Hr = pUnk->QueryInterface(__uuidof(INetworkStats),(void **)&m_pINetworkStats)))
	{
		DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s:   SUCCESS: m_pINetworkStats=0x%08lX", _fx_, m_pINetworkStats));
	}
	else
	{
		m_pINetworkStats = NULL;
		DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: IOCTL failed Hr=0x%08lX", _fx_, Hr));
	}

	// It's Ok if we couldn't get interface pointers
	// We'll just grey the controls in the property page
	// to make it clear to the user that they can't
	// control those properties on the audio device
	Hr = NOERROR;

MyExit:
	DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: end", _fx_));
	return Hr;
}

/****************************************************************************
 *  @doc INTERNAL CNETSTATPMETHOD
 *
 *  @mfunc HRESULT | CNetworkStatsProperties | OnDisconnect | This
 *    method is called when the property page is disconnected from the owning
 *    filter.
 *
 *  @rdesc This method returns an HRESULT value that depends on the
 *    implementation of the interface. HRESULT can include one of the
 *    following standard constants, or other values not listed:
 *
 *  @flag NOERROR | No error
 ***************************************************************************/
HRESULT CNetworkStatsProperties::OnDisconnect()
{
	FX_ENTRY("CNetworkStatsProperties::OnDisconnect")

	DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: begin", _fx_));

	// Validate input parameters: we seem to get called several times here
	// Make sure the interface pointer is still valid
	if (!m_pINetworkStats)
	{
		DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   WARNING: already disconnected!", _fx_));
	}
	else
	{
		// Release the interface
		m_pINetworkStats->Release();
		m_pINetworkStats = NULL;
		DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s:   SUCCESS: releasing m_pINetworkStats", _fx_));
	}

	DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: end", _fx_));
	return NOERROR;
}

/****************************************************************************
 *  @doc INTERNAL CNETSTATPMETHOD
 *
 *  @mfunc HRESULT | CNetworkStatsProperties | OnActivate | This
 *    method is called when the property page is activated.
 *
 *  @rdesc This method returns an HRESULT value that depends on the
 *    implementation of the interface. HRESULT can include one of the
 *    following standard constants, or other values not listed:
 *
 *  @flag E_FAIL | Failure
 *  @flag E_POINTER | Null pointer argument
 *  @flag E_NOTIMPL | Method is not supported
 *  @flag NOERROR | No error
 ***************************************************************************/
HRESULT CNetworkStatsProperties::OnActivate()
{
	HRESULT	Hr = NOERROR;
	int		j;

	FX_ENTRY("CNetworkStatsProperties::OnActivate")

	DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: begin", _fx_));

	// Create the controls for the properties
	if (m_Controls[0] = new CNetworkStatsProperty(m_hwnd, IDC_RandomBitErrorRate_Label, IDC_RandomBitErrorRate_Minimum, IDC_RandomBitErrorRate_Maximum, IDC_RandomBitErrorRate_Default, IDC_RandomBitErrorRate_Stepping, IDC_RandomBitErrorRate_Edit, IDC_RandomBitErrorRate_Slider, 0, IDC_RandomBitErrorRate, 0, m_pINetworkStats))
	{
		DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s:   SUCCESS: m_Controls[0]=0x%08lX", _fx_, m_Controls[0]));

		if (m_Controls[1] = new CNetworkStatsProperty(m_hwnd, IDC_BurstErrorDuration_Label, IDC_BurstErrorDuration_Minimum, IDC_BurstErrorDuration_Maximum, IDC_BurstErrorDuration_Default, IDC_BurstErrorDuration_Stepping, IDC_BurstErrorDuration_Edit, IDC_BurstErrorDuration_Slider, 0, IDC_BurstErrorDuration, 0, m_pINetworkStats))
		{
			DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s:   SUCCESS: m_Controls[1]=0x%08lX", _fx_, m_Controls[1]));

			if (m_Controls[2] = new CNetworkStatsProperty(m_hwnd, IDC_BurstErrorMaxFrequency_Label, IDC_BurstErrorMaxFrequency_Minimum, IDC_BurstErrorMaxFrequency_Maximum, IDC_BurstErrorMaxFrequency_Default, IDC_BurstErrorMaxFrequency_Stepping, IDC_BurstErrorMaxFrequency_Edit, IDC_BurstErrorMaxFrequency_Slider, 0, IDC_BurstErrorMaxFrequency, 0, m_pINetworkStats))
			{
				DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s:   SUCCESS: m_Controls[2]=0x%08lX", _fx_, m_Controls[2]));

				if (m_Controls[3] = new CNetworkStatsProperty(m_hwnd, IDC_PacketLossRate_Label, IDC_PacketLossRate_Minimum, IDC_PacketLossRate_Maximum, IDC_PacketLossRate_Default, IDC_PacketLossRate_Stepping, IDC_PacketLossRate_Edit, IDC_PacketLossRate_Slider, 0, IDC_PacketLossRate, 0, m_pINetworkStats))
				{
					DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s:   SUCCESS: m_Controls[3]=0x%08lX", _fx_, m_Controls[3]));
					Hr = NOERROR;
				}
				else
				{
					DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: Out of memory", _fx_));
					delete m_Controls[0], m_Controls[0] = NULL;
					delete m_Controls[1], m_Controls[1] = NULL;
					delete m_Controls[2], m_Controls[2] = NULL;
					Hr = E_OUTOFMEMORY;
					goto MyExit;
				}
			}
			else
			{
				DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: Out of memory", _fx_));
				delete m_Controls[0], m_Controls[0] = NULL;
				delete m_Controls[1], m_Controls[1] = NULL;
				Hr = E_OUTOFMEMORY;
				goto MyExit;
			}
		}
		else
		{
			DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: Out of memory", _fx_));
			delete m_Controls[0], m_Controls[0] = NULL;
			Hr = E_OUTOFMEMORY;
			goto MyExit;
		}
	}
	else
	{
		DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: Out of memory", _fx_));
		Hr = E_OUTOFMEMORY;
		goto MyExit;
	}

	// Initialize all the controls. If the initialization fails, it's Ok. It just means
	// that the TAPI control interface isn't implemented by the device. The dialog item
	// in the property page will be greyed, showing this to the user.
	for (j = 0; j < m_NumProperties; j++)
	{
		if (m_Controls[j]->Init())
		{
			DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s:   SUCCESS: m_Controls[%ld]->Init()", _fx_, j));
		}
		else
		{
			DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   WARNING: m_Controls[%ld]->Init() failed", _fx_, j));
		}
	}

MyExit:
	DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: end", _fx_));
	return Hr;
}

/****************************************************************************
 *  @doc INTERNAL CNETSTATPMETHOD
 *
 *  @mfunc HRESULT | CNetworkStatsProperties | OnDeactivate | This
 *    method is called when the property page is dismissed.
 *
 *  @rdesc This method returns an HRESULT value that depends on the
 *    implementation of the interface. HRESULT can include one of the
 *    following standard constants, or other values not listed:
 *
 *  @flag NOERROR | No error
 ***************************************************************************/
HRESULT CNetworkStatsProperties::OnDeactivate()
{
	int		j;

	FX_ENTRY("CNetworkStatsProperties::OnDeactivate")

	DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: begin", _fx_));

	// Free the controls
	for (j = 0; j < m_NumProperties; j++)
	{
		if (m_Controls[j])
		{
			DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s:   SUCCESS: deleting m_Controls[%ld]=0x%08lX", _fx_, j, m_Controls[j]));
			delete m_Controls[j], m_Controls[j] = NULL;
		}
		else
		{
			DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   WARNING: control already freed", _fx_));
		}
	}

	DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: end", _fx_));
	return NOERROR;
}

/****************************************************************************
 *  @doc INTERNAL CNETSTATPMETHOD
 *
 *  @mfunc HRESULT | CNetworkStatsProperties | OnApplyChanges | This
 *    method is called when the user applies changes to the property page.
 *
 *  @rdesc This method returns an HRESULT value that depends on the
 *    implementation of the interface. HRESULT can include one of the
 *    following standard constants, or other values not listed:
 *
 *  @flag E_FAIL | Failure
 *  @flag E_POINTER | Null pointer argument
 *  @flag E_NOTIMPL | Method is not supported
 *  @flag NOERROR | No error
 ***************************************************************************/
HRESULT CNetworkStatsProperties::OnApplyChanges()
{
	HRESULT	Hr = NOERROR;

	FX_ENTRY("CNetworkStatsProperties::OnApplyChanges")

	DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: begin", _fx_));

	// Update packet loss rate
	ASSERT(m_Controls[3]);
	if (m_Controls[3])
	{
		DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s:   SUCCESS: calling m_Controls[3]=0x%08lX->OnApply", _fx_, m_Controls[3]));
		if (m_Controls[3]->HasChanged())
			m_Controls[3]->OnApply();
		Hr = NOERROR;
	}
	else
	{
		DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: can't call m_Controls[3]=NULL->OnApply", _fx_));
		Hr = E_UNEXPECTED;
	}
	// Handle other network statistics in one shot
	ASSERT(m_Controls[0] && m_Controls[1] && m_Controls[2]);
	if (m_Controls[0] && m_Controls[1] && m_Controls[2])
	{
		DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s:   SUCCESS: calling m_Controls[0 - 2]=->OnApply", _fx_));
		if (m_Controls[0]->HasChanged() || m_Controls[1]->HasChanged() || m_Controls[2]->HasChanged())
		{
			m_Controls[0]->OnApply();
			m_Controls[1]->OnApply();
			m_Controls[2]->OnApply();
		}
		Hr = NOERROR;
	}
	else
	{
		DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: can't call m_Controls[1 - 3]=NULL->OnApply", _fx_));
		Hr = E_UNEXPECTED;
	}

	DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: end", _fx_));
	return Hr;
}

/****************************************************************************
 *  @doc INTERNAL CNETSTATPMETHOD
 *
 *  @mfunc BOOL | CNetworkStatsProperties | OnReceiveMessage | This
 *    method is called when a message is sent to the property page dialog box.
 *
 *  @rdesc By default, returns the value returned by the Win32 DefWindowProc function.
 ***************************************************************************/
BOOL CNetworkStatsProperties::OnReceiveMessage(HWND hWnd, UINT uMsg, WPARAM wParam, LPARAM lParam) 
{
	int iNotify = HIWORD (wParam);
	int j;

	switch (uMsg)
	{
		case WM_INITDIALOG:
			return TRUE; // Don't call setfocus

		case WM_HSCROLL:
		case WM_VSCROLL:
			// Process all of the Trackbar messages
			for (j = 0; j < m_NumProperties; j++)
			{
				ASSERT(m_Controls[j]);
				if (m_Controls[j]->GetTrackbarHWnd() == (HWND)lParam)
				{
					m_Controls[j]->OnScroll(uMsg, wParam, lParam);
					SetDirty();
				}
			}
			break;

		case WM_COMMAND:

			// This message gets sent even before OnActivate() has been
			// called(!). We need to test and make sure the controls have
			// beeen initialized before we can use them.

			// Process all of the edit box messages
			for (j = 0; j < m_NumProperties; j++)
			{
				if (m_Controls[j] && m_Controls[j]->GetEditHWnd() == (HWND)lParam)
				{
					m_Controls[j]->OnEdit(uMsg, wParam, lParam);
					SetDirty();
					break;
				}
			}

			switch (LOWORD(wParam))
			{
				case IDC_CONTROL_DEFAULT:
					for (j = 0; j < m_NumProperties; j++)
					{
						if (m_Controls[j])
							m_Controls[j]->OnDefault();
					}
					break;

				default:
					break;
			}
			break;

		default:
			return FALSE;
	}

	return TRUE;
}

/****************************************************************************
 *  @doc INTERNAL CNETSTATPMETHOD
 *
 *  @mfunc BOOL | CNetworkStatsProperties | SetDirty | This
 *    method notifies the property page site of changes.
 *
 *  @rdesc Nada.
 ***************************************************************************/
void CNetworkStatsProperties::SetDirty()
{
	m_bDirty = TRUE;
	if (m_pPageSite)
		m_pPageSite->OnStatusChange(PROPPAGESTATUS_DIRTY);
}

#endif

#endif
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\net\tapi\skywalker\filters\video\tapivcap\overlay.h ===
/****************************************************************************
 *  @doc INTERNAL OVERLAY
 *
 *  @module Overlay.h | Header file for the <c COverlayPin> class methods
 *    used to implement the video overlay output pin.
 ***************************************************************************/

#ifndef _OVERLAY_H_
#define _OVERLAY_H_

#ifdef USE_OVERLAY

/****************************************************************************
 *  @doc INTERNAL COVERLAYPINCLASS
 *
 *  @class COverlayPin | This class implements the video overlay output pin.
 *
 *  @mdata CTAPIVCap* | COverlayPin | m_pCaptureFilter | Reference to the
 *    parent capture filter.
 *
 *  @comm Supports IPin. Never created by COM, so no CreateInstance or entry
 *    in global FactoryTemplate table. Only ever created by a <c CTAPIVCap>
 *    object and returned via the EnumPins interface
 ***************************************************************************/
class COverlayPin : public CBaseOutputPin, public IAMStreamConfig, public CBaseStreamControl
{
	public:
	DECLARE_IUNKNOWN
	COverlayPin(IN TCHAR *pObjectName, IN CTAPIVCap *pCapture, IN HRESULT *pHr, IN LPCWSTR pName);
	virtual ~COverlayPin();
	STDMETHODIMP NonDelegatingQueryInterface(IN REFIID riid, OUT PVOID *ppv);
	static HRESULT CALLBACK CreateOverlayPin(CTAPIVCap *pCaptureFilter, COverlayPin **ppOverlayPin);

	// Override CBasePin base class methods
	HRESULT GetMediaType(IN int iPosition, OUT CMediaType *pMediaType);
	HRESULT CheckMediaType(IN const CMediaType *pMediaType);
	HRESULT SetMediaType(IN CMediaType *pMediaType);

	// Implement IAMStreamConfig
	STDMETHODIMP SetFormat(IN AM_MEDIA_TYPE *pmt);
	STDMETHODIMP GetFormat(OUT AM_MEDIA_TYPE **ppmt);
	STDMETHODIMP GetNumberOfCapabilities(OUT int *piCount, OUT int *piSize);
	STDMETHODIMP GetStreamCaps(IN int iIndex, OUT AM_MEDIA_TYPE **ppmt, OUT LPBYTE pSCC);

	// Override CBaseOutputPin base class methods
	HRESULT DecideBufferSize(IN IMemAllocator *pAlloc, OUT ALLOCATOR_PROPERTIES *ppropInputRequest);
	HRESULT DecideAllocator(IN IMemInputPin *pPin, OUT IMemAllocator **ppAlloc);
	HRESULT Active();
	HRESULT Inactive();
	HRESULT ActiveRun(IN REFERENCE_TIME tStart);
	HRESULT ActivePause();

	// Override IQualityControl interface method to receive Notification messages
	STDMETHODIMP Notify(IN IBaseFilter *pSelf, IN Quality q);

	private:
	CTAPIVCap *m_pCaptureFilter;
};

#endif // USE_OVERLAY

#endif // _OVERLAY_H_
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\net\tapi\skywalker\filters\video\tapivcap\overlay.cpp ===
/****************************************************************************
 *  @doc INTERNAL OVERLAY
 *
 *  @module Overlay.cpp | Source file for the <c COverlayPin> class methods
 *    used to implement the video overlay pin.
 ***************************************************************************/

#include "Precomp.h"

#ifdef USE_OVERLAY

/****************************************************************************
 *  @doc INTERNAL COVERLAYPINMETHOD
 *
 *  @mfunc COverlayPin* | COverlayPin | CreateOverlayPin | This
 *    helper function creates an output pin for overlay preview.
 *
 *  @parm CTAPIVCap* | pCaptureFilter | Specifies a pointer to the owner
 *    filter.
 *
 *  @parm HRESULT * | pHr | Specifies a pointer to the return error code.
 *
 *  @rdesc Returns a pointer to the preview pin.
 ***************************************************************************/
HRESULT CALLBACK COverlayPin::CreateOverlayPin(CTAPIVCap *pCaptureFilter, COverlayPin **ppOverlayPin)
{
	HRESULT Hr = NOERROR;

	FX_ENTRY("COverlayPin::CreateOverlayPin")

	DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: begin", _fx_));

	// Validate input parameters
	ASSERT(pCaptureFilter);
	ASSERT(ppOverlayPin);
	if (!pCaptureFilter || !ppOverlayPin)
	{
		DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: invalid input parameter", _fx_));
		goto MyExit;
	}

	if (!(*ppOverlayPin = (COverlayPin *) new COverlayPin(NAME("Video Overlay Stream"), pCaptureFilter, &Hr, L"Overlay")))
	{
		DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: Out of memory", _fx_));
		Hr = E_OUTOFMEMORY;
		goto MyExit;
	}

	// If initialization failed, delete the stream array and return the error
	if (FAILED(Hr) && *ppOverlayPin)
	{
		DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: Initialization failed", _fx_));
		Hr = E_FAIL;
		delete *ppOverlayPin;
		*ppOverlayPin = NULL;
	}

MyExit:
	DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: end", _fx_));
	return Hr;
}

/****************************************************************************
 *  @doc INTERNAL COVERLAYPINMETHOD
 *
 *  @mfunc HRESULT | COverlayPin | COverlayPin | This method is the
 *  constructorfor the <c COverlayPin> object
 *
 *  @rdesc Nada.
 ***************************************************************************/
COverlayPin::COverlayPin(IN TCHAR *pObjectName, IN CTAPIVCap *pCapture, IN HRESULT *pHr, IN LPCWSTR pName) : CBaseOutputPin(pObjectName, pCapture, &pCapture->m_lock, pHr, pName), m_pCaptureFilter(pCapture)
{
	FX_ENTRY("COverlayPin::COverlayPin")

	DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: begin", _fx_));

	DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: end", _fx_));
}

/****************************************************************************
 *  @doc INTERNAL COVERLAYPINMETHOD
 *
 *  @mfunc void | COverlayPin | ~COverlayPin | This method is the destructor
 *    for the <c COverlayPin> object.
 *
 *  @rdesc Nada.
 ***************************************************************************/
COverlayPin::~COverlayPin()
{
	FX_ENTRY("COverlayPin::~COverlayPin")

	DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: begin", _fx_));

	DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: end", _fx_));
}

/****************************************************************************
 *  @doc INTERNAL COVERLAYPINMETHOD
 *
 *  @mfunc HRESULT | COverlayPin | NonDelegatingQueryInterface | This
 *    method is the nondelegating interface query function. It returns a pointer
 *    to the specified interface if supported. The only interfaces explicitly
 *    supported being <i IAMStreamConfig>,
 *    <i IAMStreamControl>, <i ICPUControl>, <i IFrameRateControl>,
 *    <i IBitrateControl>, <i INetworkStats>, <i IH245EncoderCommand>
 *    and <i IProgressiveRefinement>.
 *
 *  @parm REFIID | riid | Specifies the identifier of the interface to return.
 *
 *  @parm PVOID* | ppv | Specifies the place in which to put the interface
 *    pointer.
 *
 *  @rdesc This method returns an HRESULT value that depends on the
 *    implementation of the interface. HRESULT can include one of the
 *    following standard constants, or other values not listed:
 *
 *  @flag E_FAIL | Failure
 *  @flag E_POINTER | Null pointer argument
 *  @flag NOERROR | No error
 ***************************************************************************/
STDMETHODIMP COverlayPin::NonDelegatingQueryInterface(IN REFIID riid, OUT void **ppv)
{
	HRESULT Hr = NOERROR;

	FX_ENTRY("COverlayPin::NonDelegatingQueryInterface")

	DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: begin", _fx_));

	// Validate input parameters
	ASSERT(ppv);
	if (!ppv)
	{
		DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: invalid input parameter", _fx_));
		Hr = E_POINTER;
		goto MyExit;
	}

	// Retrieve interface pointer
	if (riid == __uuidof(IAMStreamConfig))
	{
		if (FAILED(Hr = GetInterface(static_cast<IAMStreamConfig*>(this), ppv)))
		{
			DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: NDQI for IAMStreamConfig failed Hr=0x%08lX", _fx_, Hr));
		}
		else
		{
			DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s:   SUCCESS: IAMStreamConfig*=0x%08lX", _fx_, *ppv));
		}

		goto MyExit;
	}
	else if (riid == __uuidof(IAMStreamControl))
	{
		if (FAILED(Hr = GetInterface(static_cast<IAMStreamControl*>(this), ppv)))
		{
			DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: NDQI for IAMStreamControl failed Hr=0x%08lX", _fx_, Hr));
		}
		else
		{
			DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s:   SUCCESS: IAMStreamControl*=0x%08lX", _fx_, *ppv));
		}

		goto MyExit;
	}

	if (FAILED(Hr = CBaseOutputPin::NonDelegatingQueryInterface(riid, ppv)))
	{
		DBGOUT((g_dwVideoCaptureTraceID, WARN, "%s:   WARNING: NDQI for {%08lX-%04lX-%04lX-%02lX%02lX-%02lX%02lX%02lX%02lX%02lX%02lX} failed Hr=0x%08lX", _fx_, riid.Data1, riid.Data2, riid.Data3, riid.Data4[0], riid.Data4[1], riid.Data4[2], riid.Data4[3], riid.Data4[4], riid.Data4[5], riid.Data4[6], riid.Data4[7], Hr));
	}
	else
	{
		DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s:   SUCCESS: {%08lX-%04lX-%04lX-%02lX%02lX-%02lX%02lX%02lX%02lX%02lX%02lX}*=0x%08lX", _fx_, riid.Data1, riid.Data2, riid.Data3, riid.Data4[0], riid.Data4[1], riid.Data4[2], riid.Data4[3], riid.Data4[4], riid.Data4[5], riid.Data4[6], riid.Data4[7], *ppv));
	}

MyExit:
	DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: end", _fx_));
	return Hr;
}

/****************************************************************************
 *  @doc INTERNAL COVERLAYPINMETHOD
 *
 *  @mfunc HRESULT | COverlayPin | GetMediaType | This method retrieves one
 *    of the media types supported by the pin, which is used by enumerators.
 *
 *  @parm int | iPosition | Specifies a position in the media type list.
 *
 *  @parm CMediaType* | pMediaType | Specifies a pointer to the media type at
 *    the <p iPosition> position in the list of supported media types.
 *
 *  @rdesc This method returns an HRESULT value that depends on the
 *    implementation of the interface. HRESULT can include one of the
 *    following standard constants, or other values not listed:
 *
 *  @flag E_FAIL | Failure
 *  @flag E_POINTER | Null pointer argument
 *  @flag E_INVALIDARG | Invalid argument
 *  @flag VFW_S_NO_MORE_ITEMS | End of the list of media types has been reached
 *  @flag NOERROR | No error
 ***************************************************************************/
HRESULT COverlayPin::GetMediaType(IN int iPosition, OUT CMediaType *pMediaType)
{
	HRESULT Hr = NOERROR;

	FX_ENTRY("COverlayPin::GetMediaType")

	DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: begin", _fx_));

	// Validate input parameters
	ASSERT(iPosition >= 0);
	ASSERT(pMediaType);
	if (iPosition < 0)
	{
		DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: Invalid input parameter!", _fx_));
		Hr = E_INVALIDARG;
		goto MyExit;
	}
	if (!pMediaType)
	{
		DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: Invalid input parameter!", _fx_));
		Hr = E_POINTER;
		goto MyExit;
	}

	// @comm Put some real code here! 
	Hr = E_NOTIMPL;

MyExit:
	DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: end", _fx_));
	return Hr;
}

/****************************************************************************
 *  @doc INTERNAL COVERLAYPINMETHOD
 *
 *  @mfunc HRESULT | COverlayPin | CheckMediaType | This method is used to
 *    determine if the pin can support a specific media type.
 *
 *  @parm CMediaType* | pMediaType | Specifies a pointer to the media type.
 *
 *  @rdesc This method returns an HRESULT value that depends on the
 *    implementation of the interface. HRESULT can include one of the
 *    following standard constants, or other values not listed:
 *
 *  @flag E_FAIL | Failure
 *  @flag E_POINTER | Null pointer argument
 *  @flag E_INVALIDARG | Invalid argument
 *  @flag NOERROR | No error
 ***************************************************************************/
HRESULT COverlayPin::CheckMediaType(IN const CMediaType *pMediaType)
{
	HRESULT Hr = NOERROR;

	FX_ENTRY("COverlayPin::CheckMediaType")

	DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: begin", _fx_));

	// Validate input parameters
	ASSERT(pMediaType);
	if (!pMediaType)
	{
		DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: Invalid input parameter!", _fx_));
		Hr = E_POINTER;
		goto MyExit;
	}

	// @comm Put some real code here! 
	Hr = E_NOTIMPL;

MyExit:
	DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: end", _fx_));
	return Hr;
}

/****************************************************************************
 *  @doc INTERNAL COVERLAYPINMETHOD
 *
 *  @mfunc HRESULT | COverlayPin | SetMediaType | This method is used to
 *    set a specific media type on a pin.
 *
 *  @parm CMediaType* | pMediaType | Specifies a pointer to the media type.
 *
 *  @rdesc This method returns an HRESULT value that depends on the
 *    implementation of the interface. HRESULT can include one of the
 *    following standard constants, or other values not listed:
 *
 *  @flag E_FAIL | Failure
 *  @flag E_POINTER | Null pointer argument
 *  @flag E_INVALIDARG | Invalid argument
 *  @flag NOERROR | No error
 ***************************************************************************/
HRESULT COverlayPin::SetMediaType(IN CMediaType *pMediaType)
{
	HRESULT Hr = NOERROR;

	FX_ENTRY("COverlayPin::SetMediaType")

	DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: begin", _fx_));

	// Validate input parameters
	ASSERT(pMediaType);
	if (!pMediaType)
	{
		DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: Invalid input parameter!", _fx_));
		Hr = E_POINTER;
		goto MyExit;
	}

	// @comm Put some real code here! 
	Hr = E_NOTIMPL;

MyExit:
	DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: end", _fx_));
	return Hr;
}

/****************************************************************************
 *  @doc INTERNAL COVERLAYPINMETHOD
 *
 *  @mfunc HRESULT | COverlayPin | SetFormat | This method is used to
 *    set a specific media type on a pin.
 *
 *  @parm AM_MEDIA_TYPE* | pmt | Specifies a pointer to an <t AM_MEDIA_TYPE>
 *    structure.
 *
 *  @rdesc This method returns an HRESULT value that depends on the
 *    implementation of the interface. HRESULT can include one of the
 *    following standard constants, or other values not listed:
 *
 *  @flag E_FAIL | Failure
 *  @flag E_POINTER | Null pointer argument
 *  @flag E_INVALIDARG | Invalid argument
 *  @flag NOERROR | No error
 ***************************************************************************/
STDMETHODIMP COverlayPin::SetFormat(AM_MEDIA_TYPE *pmt)
{
	HRESULT Hr = NOERROR;

	FX_ENTRY("COverlayPin::SetFormat")

	DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: begin", _fx_));

	// Validate input parameters
	ASSERT(pmt);
	if (!pmt)
	{
		DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: Invalid input parameter!", _fx_));
		Hr = E_POINTER;
		goto MyExit;
	}

	// @comm Put some real code here! 
	Hr = E_NOTIMPL;

MyExit:
	DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: end", _fx_));
	return Hr;
}

/****************************************************************************
 *  @doc INTERNAL COVERLAYPINMETHOD
 *
 *  @mfunc HRESULT | COverlayPin | GetFormat | This method is used to
 *    retrieve the current media type on a pin.
 *
 *  @parm AM_MEDIA_TYPE** | ppmt | Specifies the address of a pointer to an
 *    <t AM_MEDIA_TYPE> structure.
 *
 *  @rdesc This method returns an HRESULT value that depends on the
 *    implementation of the interface. HRESULT can include one of the
 *    following standard constants, or other values not listed:
 *
 *  @flag E_FAIL | Failure
 *  @flag E_POINTER | Null pointer argument
 *  @flag NOERROR | No error
 ***************************************************************************/
STDMETHODIMP COverlayPin::GetFormat(OUT AM_MEDIA_TYPE **ppmt)
{
	HRESULT Hr = NOERROR;

	FX_ENTRY("COverlayPin::GetFormat")

	DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: begin", _fx_));

	// Validate input parameters
	ASSERT(ppmt);
	if (!ppmt)
	{
		DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: Invalid input parameter!", _fx_));
		Hr = E_POINTER;
		goto MyExit;
	}

	// @comm Put some real code here! 
	Hr = E_NOTIMPL;

MyExit:
	DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: end", _fx_));
	return Hr;
}

/****************************************************************************
 *  @doc INTERNAL COVERLAYPINMETHOD
 *
 *  @mfunc HRESULT | COverlayPin | GetNumberOfCapabilities | This method is
 *    used to retrieve the number of stream capabilities structures.
 *
 *  @parm int* | piCount | Specifies a pointer to an int to receive the
 *    number of <t VIDEO_STREAM_CONFIG_CAPS> structures supported.
 *
 *  @parm int* | piSize | Specifies a pointer to an int to receive the
 *    size of the <t VIDEO_STREAM_CONFIG_CAPS> configuration structure.
 *
 *  @rdesc This method returns an HRESULT value that depends on the
 *    implementation of the interface. HRESULT can include one of the
 *    following standard constants, or other values not listed:
 *
 *  @flag E_FAIL | Failure
 *  @flag E_POINTER | Null pointer argument
 *  @flag NOERROR | No error
 ***************************************************************************/
STDMETHODIMP COverlayPin::GetNumberOfCapabilities(OUT int *piCount, OUT int *piSize)
{
	HRESULT Hr = NOERROR;

	FX_ENTRY("COverlayPin::GetNumberOfCapabilities")

	DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: begin", _fx_));

	// Validate input parameters
	ASSERT(piCount);
	ASSERT(piSize);
	if (!piCount || !piSize)
	{
		DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: Invalid input parameter!", _fx_));
		Hr = E_POINTER;
		goto MyExit;
	}

	// @comm Put some real code here! 
	Hr = E_NOTIMPL;

MyExit:
	DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: end", _fx_));
	return Hr;
}

/****************************************************************************
 *  @doc INTERNAL COVERLAYPINMETHOD
 *
 *  @mfunc HRESULT | COverlayPin | GetStreamCaps | This method is
 *    used to retrieve a video stream capability pair.
 *
 *  @parm int | iIndex | Specifies the index to the desired media type
 *    and capability pair.
 *
 *  @parm AM_MEDIA_TYPE** | ppmt | Specifies the address of a pointer to an
 *    <t AM_MEDIA_TYPE> structure.
 *
 *  @parm LPBYTE | pSCC | Specifies a pointer to a
 *    <t VIDEO_STREAM_CONFIG_CAPS> configuration structure.
 *
 *  @rdesc This method returns an HRESULT value that depends on the
 *    implementation of the interface. HRESULT can include one of the
 *    following standard constants, or other values not listed:
 *
 *  @flag E_FAIL | Failure
 *  @flag E_POINTER | Null pointer argument
 *  @flag NOERROR | No error
 ***************************************************************************/
STDMETHODIMP COverlayPin::GetStreamCaps(IN int iIndex, OUT AM_MEDIA_TYPE **ppmt, OUT LPBYTE pSCC)
{
	HRESULT Hr = NOERROR;

	FX_ENTRY("COverlayPin::GetStreamCaps")

	DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: begin", _fx_));

	// Validate input parameters
	// @comm Validate iIndex too
	ASSERT(ppmt);
	ASSERT(pSCC);
	if (!ppmt || !pSCC)
	{
		DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: Invalid input parameter!", _fx_));
		Hr = E_POINTER;
		goto MyExit;
	}

	// @comm Put some real code here! 
	Hr = E_NOTIMPL;

MyExit:
	DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: end", _fx_));
	return Hr;
}

/****************************************************************************
 *  @doc INTERNAL COVERLAYPINMETHOD
 *
 *  @mfunc HRESULT | COverlayPin | DecideBufferSize | This method is
 *    used to retrieve the number and size of buffers required for transfer.
 *
 *  @parm IMemAllocator* | pAlloc | Specifies a pointer to the allocator
 *    assigned to the transfer.
 *
 *  @parm ALLOCATOR_PROPERTIES* | ppropInputRequest | Specifies a pointer to an
 *    <t ALLOCATOR_PROPERTIES> structure.
 *
 *  @rdesc This method returns an HRESULT value that depends on the
 *    implementation of the interface. HRESULT can include one of the
 *    following standard constants, or other values not listed:
 *
 *  @flag E_FAIL | Failure
 *  @flag E_POINTER | Null pointer argument
 *  @flag NOERROR | No error
 ***************************************************************************/
HRESULT COverlayPin::DecideBufferSize(IN IMemAllocator *pAlloc, OUT ALLOCATOR_PROPERTIES *ppropInputRequest)
{
	HRESULT Hr = NOERROR;

	FX_ENTRY("COverlayPin::DecideBufferSize")

	DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: begin", _fx_));

	// Validate input parameters
	// @comm Validate iIndex too
	ASSERT(pAlloc);
	ASSERT(ppropInputRequest);
	if (!pAlloc || !ppropInputRequest)
	{
		DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: Invalid input parameter!", _fx_));
		Hr = E_POINTER;
		goto MyExit;
	}

	// @comm Put some real code here! 
	Hr = E_NOTIMPL;

MyExit:
	DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: end", _fx_));
	return Hr;
}

/****************************************************************************
 *  @doc INTERNAL COVERLAYPINMETHOD
 *
 *  @mfunc HRESULT | COverlayPin | DecideAllocator | This method is
 *    used to negotiate the allocator to use.
 *
 *  @parm IMemInputPin* | pPin | Specifies a pointer to the IPin interface
 *    of the connecting pin.
 *
 *  @parm IMemAllocator** | ppAlloc | Specifies a pointer to the negotiated
 *    IMemAllocator interface.
 *
 *  @rdesc This method returns an HRESULT value that depends on the
 *    implementation of the interface. HRESULT can include one of the
 *    following standard constants, or other values not listed:
 *
 *  @flag E_FAIL | Failure
 *  @flag E_POINTER | Null pointer argument
 *  @flag NOERROR | No error
 ***************************************************************************/
HRESULT COverlayPin::DecideAllocator(IN IMemInputPin *pPin, OUT IMemAllocator **ppAlloc)
{
	HRESULT Hr = NOERROR;

	FX_ENTRY("COverlayPin::DecideAllocator")

	DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: begin", _fx_));

	// Validate input parameters
	// @comm Validate iIndex too
	ASSERT(pPin);
	ASSERT(ppAlloc);
	if (!pPin || !ppAlloc)
	{
		DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: Invalid input parameter!", _fx_));
		Hr = E_POINTER;
		goto MyExit;
	}

	// @comm Put some real code here! 
	Hr = E_NOTIMPL;

MyExit:
	DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: end", _fx_));
	return Hr;
}

/****************************************************************************
 *  @doc INTERNAL COVERLAYPINMETHOD
 *
 *  @mfunc HRESULT | COverlayPin | Active | This method is called by the
 *    <c CBaseFilter> implementation when the state changes from stopped to
 *    either paused or running.
 *
 *  @rdesc This method returns an HRESULT value that depends on the
 *    implementation of the interface. HRESULT can include one of the
 *    following standard constants, or other values not listed:
 *
 *  @flag E_FAIL | Failure
 *  @flag NOERROR | No error
 ***************************************************************************/
HRESULT COverlayPin::Active()
{
	HRESULT Hr = NOERROR;

	FX_ENTRY("COverlayPin::Active")

	DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: begin", _fx_));

	// @comm Put some real code here! 
	Hr = E_NOTIMPL;

	DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: end", _fx_));
	return Hr;
}

/****************************************************************************
 *  @doc INTERNAL COVERLAYPINMETHOD
 *
 *  @mfunc HRESULT | COverlayPin | Inactive | This method is called by the
 *    <c CBaseFilter> implementation when the state changes from either
 *    paused or running to stopped.
 *
 *  @rdesc This method returns an HRESULT value that depends on the
 *    implementation of the interface. HRESULT can include one of the
 *    following standard constants, or other values not listed:
 *
 *  @flag E_FAIL | Failure
 *  @flag NOERROR | No error
 ***************************************************************************/
HRESULT COverlayPin::Inactive()
{
	HRESULT Hr = NOERROR;

	FX_ENTRY("COverlayPin::Inactive")

	DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: begin", _fx_));

	// @comm Put some real code here! 
	Hr = E_NOTIMPL;

	DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: end", _fx_));
	return Hr;
}

/****************************************************************************
 *  @doc INTERNAL COVERLAYPINMETHOD
 *
 *  @mfunc HRESULT | COverlayPin | ActiveRun | This method is called by the
 *    <c CBaseFilter> implementation when the state changes from paused to
 *    running mode.
 *
 *  @parm REFERENCE_TIME | tStart | ???.
 *
 *  @rdesc This method returns an HRESULT value that depends on the
 *    implementation of the interface. HRESULT can include one of the
 *    following standard constants, or other values not listed:
 *
 *  @flag E_FAIL | Failure
 *  @flag NOERROR | No error
 ***************************************************************************/
HRESULT COverlayPin::ActiveRun(IN REFERENCE_TIME tStart)
{
	HRESULT Hr = NOERROR;

	FX_ENTRY("COverlayPin::ActiveRun")

	DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: begin", _fx_));

	// @comm Put some real code here! 
	Hr = E_NOTIMPL;

	DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: end", _fx_));
	return Hr;
}

/****************************************************************************
 *  @doc INTERNAL COVERLAYPINMETHOD
 *
 *  @mfunc HRESULT | COverlayPin | ActivePause | This method is called by the
 *    <c CBaseFilter> implementation when the state changes from running to
 *    paused mode.
 *
 *  @rdesc This method returns an HRESULT value that depends on the
 *    implementation of the interface. HRESULT can include one of the
 *    following standard constants, or other values not listed:
 *
 *  @flag E_FAIL | Failure
 *  @flag NOERROR | No error
 ***************************************************************************/
HRESULT COverlayPin::ActivePause()
{
	HRESULT Hr = NOERROR;

	FX_ENTRY("COverlayPin::ActivePause")

	DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: begin", _fx_));

	// @comm Put some real code here! 
	Hr = E_NOTIMPL;

	DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: end", _fx_));
	return Hr;
}

/****************************************************************************
 *  @doc INTERNAL COVERLAYPINMETHOD
 *
 *  @mfunc HRESULT | COverlayPin | Notify | This method is called by the
 *    <c CBaseFilter> implementation when the state changes from paused to
 *    running mode.
 *
 *  @parm IBaseFilter* | pSelf | Specifies a pointer to the filter that is
 *    sending the quality notification.
 *
 *  @parm Quality | q | Specifies a Quality notification structure.
 *
 *  @rdesc This method returns an HRESULT value that depends on the
 *    implementation of the interface. HRESULT can include one of the
 *    following standard constants, or other values not listed:
 *
 *  @flag E_FAIL | Failure
 *  @flag NOERROR | No error
 ***************************************************************************/
STDMETHODIMP COverlayPin::Notify(IN IBaseFilter *pSelf, IN Quality q)
{
	HRESULT Hr = NOERROR;

	FX_ENTRY("COverlayPin::Notify")

	DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: begin", _fx_));

	// Validate input parameters
	ASSERT(pSelf);
	if (!pSelf)
	{
		DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: Invalid input parameter!", _fx_));
		Hr = E_POINTER;
		goto MyExit;
	}

	// @comm Put some real code here! 
	Hr = E_NOTIMPL;

MyExit:
	DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: end", _fx_));
	return Hr;
}
#endif
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\net\tapi\skywalker\filters\video\tapivcap\preview.cpp ===
/****************************************************************************
 *  @doc INTERNAL PREVIEW
 *
 *  @module Preview.cpp | Source file for the <c CPreviewPin> class methods
 *    used to implement the video capture preview pin.
 ***************************************************************************/

#include "Precomp.h"

const RGBQUAD g_IndeoPalette[256] =
{
                   0,       0,       0,              0,
                   0,       0,       0,              0,
                   0,       0,       0,              0,
                   0,       0,       0,              0,
                   0,       0,       0,              0,
                   0,       0,       0,              0,
                   0,       0,       0,              0,
                   0,       0,       0,              0,
                   0,       0,       0,              0,
                   0,       0,       0,              0,
                   0,  39+ 15,       0,  PC_NOCOLLAPSE,
                   0,  39+ 24,       0,  PC_NOCOLLAPSE,
                   0,  39+ 33,       0,  PC_NOCOLLAPSE,
                   0,  39+ 42,       0,  PC_NOCOLLAPSE,
                   0,  39+ 51, -44+ 51,  PC_NOCOLLAPSE,
         -55+ 60,  39+ 60, -44+ 60,  PC_NOCOLLAPSE,
         -55+ 69,  39+ 69, -44+ 69,  PC_NOCOLLAPSE,
         -55+ 78,  39+ 78, -44+ 78,  PC_NOCOLLAPSE,
         -55+ 87,  39+ 87, -44+ 87,  PC_NOCOLLAPSE,
         -55+ 96,  39+ 96, -44+ 96,  PC_NOCOLLAPSE,
         -55+105,  39+105, -44+105,  PC_NOCOLLAPSE,
         -55+114,  39+114, -44+114,  PC_NOCOLLAPSE,
         -55+123,  39+123, -44+123,  PC_NOCOLLAPSE,
         -55+132,  39+132, -44+132,  PC_NOCOLLAPSE,
         -55+141,  39+141, -44+141,  PC_NOCOLLAPSE,
         -55+150,  39+150, -44+150,  PC_NOCOLLAPSE,
         -55+159,  39+159, -44+159,  PC_NOCOLLAPSE,
         -55+168,  39+168, -44+168,  PC_NOCOLLAPSE,
         -55+177,  39+177, -44+177,  PC_NOCOLLAPSE,
         -55+186,  39+186, -44+186,  PC_NOCOLLAPSE,
         -55+195,  39+195, -44+195,  PC_NOCOLLAPSE,
         -55+204,  39+204, -44+204,  PC_NOCOLLAPSE,
         -55+213,  39+213, -44+213,  PC_NOCOLLAPSE,
         -55+222,     255, -44+222,  PC_NOCOLLAPSE,
         -55+231,     255, -44+231,  PC_NOCOLLAPSE,
         -55+240,     255, -44+240,  PC_NOCOLLAPSE,
                                                                        
           0+ 15,  26+ 15,       0,  PC_NOCOLLAPSE,
           0+ 24,  26+ 24,       0,  PC_NOCOLLAPSE,
           0+ 33,  26+ 33,       0,  PC_NOCOLLAPSE,
           0+ 42,  26+ 42,       0,  PC_NOCOLLAPSE,
           0+ 51,  26+ 51, -44+ 51,  PC_NOCOLLAPSE,
           0+ 60,  26+ 60, -44+ 60,  PC_NOCOLLAPSE,
           0+ 69,  26+ 69, -44+ 69,  PC_NOCOLLAPSE,
           0+ 78,  26+ 78, -44+ 78,  PC_NOCOLLAPSE,
           0+ 87,  26+ 87, -44+ 87,  PC_NOCOLLAPSE,
           0+ 96,  26+ 96, -44+ 96,  PC_NOCOLLAPSE,
           0+105,  26+105, -44+105,  PC_NOCOLLAPSE,
           0+114,  26+114, -44+114,  PC_NOCOLLAPSE,
           0+123,  26+123, -44+123,  PC_NOCOLLAPSE,
           0+132,  26+132, -44+132,  PC_NOCOLLAPSE,
           0+141,  26+141, -44+141,  PC_NOCOLLAPSE,
           0+150,  26+150, -44+150,  PC_NOCOLLAPSE,
           0+159,  26+159, -44+159,  PC_NOCOLLAPSE,
           0+168,  26+168, -44+168,  PC_NOCOLLAPSE,
           0+177,  26+177, -44+177,  PC_NOCOLLAPSE,
           0+186,  26+186, -44+186,  PC_NOCOLLAPSE,
           0+195,  26+195, -44+195,  PC_NOCOLLAPSE,
           0+204,  26+204, -44+204,  PC_NOCOLLAPSE,
           0+213,  26+213, -44+213,  PC_NOCOLLAPSE,
           0+222,  26+222, -44+222,  PC_NOCOLLAPSE,
           0+231,     255, -44+231,  PC_NOCOLLAPSE,
           0+240,     255, -44+240,  PC_NOCOLLAPSE,
                                                                        
          55+ 15,  14+ 15,       0,  PC_NOCOLLAPSE,
          55+ 24,  14+ 24,       0,  PC_NOCOLLAPSE,
          55+ 33,  14+ 33,       0,  PC_NOCOLLAPSE,
          55+ 42,  14+ 42,       0,  PC_NOCOLLAPSE,
          55+ 51,  14+ 51, -44+ 51,  PC_NOCOLLAPSE,
          55+ 60,  14+ 60, -44+ 60,  PC_NOCOLLAPSE,
          55+ 69,  14+ 69, -44+ 69,  PC_NOCOLLAPSE,
          55+ 78,  14+ 78, -44+ 78,  PC_NOCOLLAPSE,
          55+ 87,  14+ 87, -44+ 87,  PC_NOCOLLAPSE,
          55+ 96,  14+ 96, -44+ 96,  PC_NOCOLLAPSE,
          55+105,  14+105, -44+105,  PC_NOCOLLAPSE,
          55+114,  14+114, -44+114,  PC_NOCOLLAPSE,
          55+123,  14+123, -44+123,  PC_NOCOLLAPSE,
          55+132,  14+132, -44+132,  PC_NOCOLLAPSE,
                 255,     153,      51,  PC_NOCOLLAPSE,
                                                                        
          55+150,  14+150, -44+150,  PC_NOCOLLAPSE,
          55+159,  14+159, -44+159,  PC_NOCOLLAPSE,
          55+168,  14+168, -44+168,  PC_NOCOLLAPSE,
          55+177,  14+177, -44+177,  PC_NOCOLLAPSE,
          55+186,  14+186, -44+186,  PC_NOCOLLAPSE,
          55+195,  14+195, -44+195,  PC_NOCOLLAPSE,
                 255,  14+204, -44+204,  PC_NOCOLLAPSE,
                 255,  14+213, -44+213,  PC_NOCOLLAPSE,
                 255,     255, -44+222,  PC_NOCOLLAPSE,
                 255,     255, -44+231,  PC_NOCOLLAPSE,
                 255,     255, -44+240,  PC_NOCOLLAPSE,
                                                                        
                   0,  13+ 15,   0+ 15,  PC_NOCOLLAPSE,
                   0,  13+ 24,   0+ 24,  PC_NOCOLLAPSE,
                   0,  13+ 33,   0+ 33,  PC_NOCOLLAPSE,
                   0,  13+ 42,   0+ 42,  PC_NOCOLLAPSE,
                   0,  13+ 51,   0+ 51,  PC_NOCOLLAPSE,
         -55+ 60,  13+ 60,   0+ 60,  PC_NOCOLLAPSE,
         -55+ 69,  13+ 69,   0+ 69,  PC_NOCOLLAPSE,
         -55+ 78,  13+ 78,   0+ 78,  PC_NOCOLLAPSE,
         -55+ 87,  13+ 87,   0+ 87,  PC_NOCOLLAPSE,
         -55+ 96,  13+ 96,   0+ 96,  PC_NOCOLLAPSE,
         -55+105,  13+105,   0+105,  PC_NOCOLLAPSE,
         -55+114,  13+114,   0+114,  PC_NOCOLLAPSE,
         -55+123,  13+123,   0+123,  PC_NOCOLLAPSE,
         -55+132,  13+132,   0+132,  PC_NOCOLLAPSE,
         -55+141,  13+141,   0+141,  PC_NOCOLLAPSE,
         -55+150,  13+150,   0+150,  PC_NOCOLLAPSE,
         -55+159,  13+159,   0+159,  PC_NOCOLLAPSE,
         -55+168,  13+168,   0+168,  PC_NOCOLLAPSE,
         -55+177,  13+177,   0+177,  PC_NOCOLLAPSE,
         -55+186,  13+186,   0+186,  PC_NOCOLLAPSE,
         -55+195,  13+195,   0+195,  PC_NOCOLLAPSE,
         -55+204,  13+204,   0+204,  PC_NOCOLLAPSE,
         -55+213,  13+213,   0+213,  PC_NOCOLLAPSE,
         -55+222,  13+222,   0+222,  PC_NOCOLLAPSE,
         -55+231,  13+231,   0+231,  PC_NOCOLLAPSE,
         -55+240,  13+242,   0+240,  PC_NOCOLLAPSE,
                                                                        
           0+ 15,   0+ 15,   0+ 15,  PC_NOCOLLAPSE,
           0+ 24,   0+ 24,   0+ 24,  PC_NOCOLLAPSE,
           0+ 33,   0+ 33,   0+ 33,  PC_NOCOLLAPSE,
           0+ 42,   0+ 42,   0+ 42,  PC_NOCOLLAPSE,
           0+ 51,   0+ 51,   0+ 51,  PC_NOCOLLAPSE,
           0+ 60,   0+ 60,   0+ 60,  PC_NOCOLLAPSE,
           0+ 69,   0+ 69,   0+ 69,  PC_NOCOLLAPSE,
           0+ 78,   0+ 78,   0+ 78,  PC_NOCOLLAPSE,
           0+ 87,   0+ 87,   0+ 87,  PC_NOCOLLAPSE,
           0+ 96,   0+ 96,   0+ 96,  PC_NOCOLLAPSE,
           0+105,   0+105,   0+105,  PC_NOCOLLAPSE,
           0+114,   0+114,   0+114,  PC_NOCOLLAPSE,
           0+123,   0+123,   0+123,  PC_NOCOLLAPSE,
           0+132,   0+132,   0+132,  PC_NOCOLLAPSE,
           0+141,   0+141,   0+141,  PC_NOCOLLAPSE,
           0+150,   0+150,   0+150,  PC_NOCOLLAPSE,
           0+159,   0+159,   0+159,  PC_NOCOLLAPSE,
           0+168,   0+168,   0+168,  PC_NOCOLLAPSE,
           0+177,   0+177,   0+177,  PC_NOCOLLAPSE,
           0+186,   0+186,   0+186,  PC_NOCOLLAPSE,
           0+195,   0+195,   0+195,  PC_NOCOLLAPSE,
           0+204,   0+204,   0+204,  PC_NOCOLLAPSE,
           0+213,   0+213,   0+213,  PC_NOCOLLAPSE,
           0+222,   0+222,   0+222,  PC_NOCOLLAPSE,
           0+231,   0+231,   0+231,  PC_NOCOLLAPSE,
           0+240,   0+240,   0+240,  PC_NOCOLLAPSE,
                                                                        
          55+ 15, -13+ 15,   0+ 15,  PC_NOCOLLAPSE,
          55+ 24, -13+ 24,   0+ 24,  PC_NOCOLLAPSE,
          55+ 33, -13+ 33,   0+ 33,  PC_NOCOLLAPSE,
          55+ 42, -13+ 42,   0+ 42,  PC_NOCOLLAPSE,
          55+ 51, -13+ 51,   0+ 51,  PC_NOCOLLAPSE,
          55+ 60, -13+ 60,   0+ 60,  PC_NOCOLLAPSE,
          55+ 69, -13+ 69,   0+ 69,  PC_NOCOLLAPSE,
          55+ 78, -13+ 78,   0+ 78,  PC_NOCOLLAPSE,
          55+ 87, -13+ 87,   0+ 87,  PC_NOCOLLAPSE,
          55+ 96, -13+ 96,   0+ 96,  PC_NOCOLLAPSE,
          55+105, -13+105,   0+105,  PC_NOCOLLAPSE,
          55+114, -13+114,   0+114,  PC_NOCOLLAPSE,
          55+123, -13+123,   0+123,  PC_NOCOLLAPSE,
          55+132, -13+132,   0+132,  PC_NOCOLLAPSE,
          55+141, -13+141,   0+141,  PC_NOCOLLAPSE,
          55+150, -13+150,   0+150,  PC_NOCOLLAPSE,
          55+159, -13+159,   0+159,  PC_NOCOLLAPSE,
          55+168, -13+168,   0+168,  PC_NOCOLLAPSE,
          55+177, -13+177,   0+177,  PC_NOCOLLAPSE,
          55+186, -13+186,   0+186,  PC_NOCOLLAPSE,
          55+195, -13+195,   0+195,  PC_NOCOLLAPSE,
                 255, -13+204,   0+204,  PC_NOCOLLAPSE,
                 255, -13+213,   0+213,  PC_NOCOLLAPSE,
                 255, -13+222,   0+222,  PC_NOCOLLAPSE,
                 255, -13+231,   0+231,  PC_NOCOLLAPSE,
                 255, -13+240,   0+240,  PC_NOCOLLAPSE,
                                                                        
                   0, -14+ 15,  44+ 15,  PC_NOCOLLAPSE,
                   0, -14+ 24,  44+ 24,  PC_NOCOLLAPSE,
                   0, -14+ 33,  44+ 33,  PC_NOCOLLAPSE,
                   0, -14+ 42,  44+ 42,  PC_NOCOLLAPSE,
                   0, -14+ 51,  44+ 51,  PC_NOCOLLAPSE,
         -55+ 60, -14+ 60,  44+ 60,  PC_NOCOLLAPSE,
         -55+ 69, -14+ 69,  44+ 69,  PC_NOCOLLAPSE,
         -55+ 78, -14+ 78,  44+ 78,  PC_NOCOLLAPSE,
         -55+ 87, -14+ 87,  44+ 87,  PC_NOCOLLAPSE,
         -55+ 96, -14+ 96,  44+ 96,  PC_NOCOLLAPSE,
         -55+105, -14+105,  44+105,  PC_NOCOLLAPSE,
         -55+114, -14+114,  44+114,  PC_NOCOLLAPSE,
         -55+123, -14+123,  44+123,  PC_NOCOLLAPSE,
         -55+132, -14+132,  44+132,  PC_NOCOLLAPSE,
         -55+141, -14+141,  44+141,  PC_NOCOLLAPSE,
         -55+150, -14+150,  44+150,  PC_NOCOLLAPSE,
         -55+159, -14+159,  44+159,  PC_NOCOLLAPSE,
         -55+168, -14+168,  44+168,  PC_NOCOLLAPSE,
         -55+177, -14+177,  44+177,  PC_NOCOLLAPSE,
         -55+186, -14+186,  44+186,  PC_NOCOLLAPSE,
         -55+195, -14+195,  44+195,  PC_NOCOLLAPSE,
         -55+204, -14+204,  44+204,  PC_NOCOLLAPSE,
         -55+213, -14+213,     255,  PC_NOCOLLAPSE,
         -55+222, -14+222,     255,  PC_NOCOLLAPSE,
         -55+231, -14+231,     255,  PC_NOCOLLAPSE,
         -55+240, -14+242,     255,  PC_NOCOLLAPSE,
                                                                        
           0+ 15,       0,  44+ 15,  PC_NOCOLLAPSE,
           0+ 24,       0,  44+ 24,  PC_NOCOLLAPSE,
           0+ 33, -26+ 33,  44+ 33,  PC_NOCOLLAPSE,
           0+ 42, -26+ 42,  44+ 42,  PC_NOCOLLAPSE,
           0+ 51, -26+ 51,  44+ 51,  PC_NOCOLLAPSE,
           0+ 60, -26+ 60,  44+ 60,  PC_NOCOLLAPSE,
           0+ 69, -26+ 69,  44+ 69,  PC_NOCOLLAPSE,
           0+ 78, -26+ 78,  44+ 78,  PC_NOCOLLAPSE,
           0+ 87, -26+ 87,  44+ 87,  PC_NOCOLLAPSE,
           0+ 96, -26+ 96,  44+ 96,  PC_NOCOLLAPSE,
           0+105, -26+105,  44+105,  PC_NOCOLLAPSE,
           0+114, -26+114,  44+114,  PC_NOCOLLAPSE,
           0+123, -26+123,  44+123,  PC_NOCOLLAPSE,
           0+132, -26+132,  44+132,  PC_NOCOLLAPSE,
           0+141, -26+141,  44+141,  PC_NOCOLLAPSE,
           0+150, -26+150,  44+150,  PC_NOCOLLAPSE,
           0+159, -26+159,  44+159,  PC_NOCOLLAPSE,
           0+168, -26+168,  44+168,  PC_NOCOLLAPSE,
           0+177, -26+177,  44+177,  PC_NOCOLLAPSE,
           0+186, -26+186,  44+186,  PC_NOCOLLAPSE,
           0+195, -26+195,  44+195,  PC_NOCOLLAPSE,
           0+204, -26+204,  44+204,  PC_NOCOLLAPSE,
           0+213, -26+213,     255,  PC_NOCOLLAPSE,
           0+222, -26+222,     255,  PC_NOCOLLAPSE,
           0+231, -26+231,     255,  PC_NOCOLLAPSE,
           0+240, -26+240,     255,  PC_NOCOLLAPSE,
                                                                        
          55+ 15,       0,  44+ 15,  PC_NOCOLLAPSE,
          55+ 24,       0,  44+ 24,  PC_NOCOLLAPSE,
          55+ 33,       0,  44+ 33,  PC_NOCOLLAPSE,
          55+ 42, -39+ 42,  44+ 42,  PC_NOCOLLAPSE,
          55+ 51, -39+ 51,  44+ 51,  PC_NOCOLLAPSE,
          55+ 60, -39+ 60,  44+ 60,  PC_NOCOLLAPSE,
          55+ 69, -39+ 69,  44+ 69,  PC_NOCOLLAPSE,
          55+ 78, -39+ 78,  44+ 78,  PC_NOCOLLAPSE,
          55+ 87, -39+ 87,  44+ 87,  PC_NOCOLLAPSE,
          55+ 96, -39+ 96,  44+ 96,  PC_NOCOLLAPSE,
          55+105, -39+105,  44+105,  PC_NOCOLLAPSE,
          55+114, -39+114,  44+114,  PC_NOCOLLAPSE,
          55+123, -39+123,  44+123,  PC_NOCOLLAPSE,
          55+132, -39+132,  44+132,  PC_NOCOLLAPSE,
          55+141, -39+141,  44+141,  PC_NOCOLLAPSE,
          55+150, -39+150,  44+150,  PC_NOCOLLAPSE,
          55+159, -39+159,  44+159,  PC_NOCOLLAPSE,
          55+168, -39+168,  44+168,  PC_NOCOLLAPSE,
          55+177, -39+177,  44+177,  PC_NOCOLLAPSE,
          55+186, -39+186,  44+186,  PC_NOCOLLAPSE,
          55+195, -39+195,  44+195,  PC_NOCOLLAPSE,
                 255, -39+204,  44+204,  PC_NOCOLLAPSE,
                 255, -39+213,     255,  PC_NOCOLLAPSE,
                 255, -39+222,     255,  PC_NOCOLLAPSE,
                 255, -39+231,     255,  PC_NOCOLLAPSE,
                 255, -39+240,     255,  PC_NOCOLLAPSE,
                                                                        
                0x83,    0x81,    0x81,  PC_NOCOLLAPSE,
                0x84,    0x81,    0x81,  PC_NOCOLLAPSE,
                                                                        
                   0,       0,       0,              0,
                   0,       0,       0,              0,
                   0,       0,       0,              0,
                   0,       0,       0,              0,
                   0,       0,       0,              0,
                   0,       0,       0,              0,
                   0,       0,       0,              0,
                   0,       0,       0,              0,
                   0,       0,       0,              0,
                 255,     255,     255,              0
};

/****************************************************************************
 *  @doc INTERNAL CPREVIEWPINMETHOD
 *
 *  @mfunc CPreviewPin* | CPreviewPin | CreatePreviewPin | This helper
 *    function creates a video output pin for preview.
 *
 *  @parm CTAPIVCap* | pCaptureFilter | Specifies a pointer to the owner
 *    filter.
 *
 *  @parm CPreviewPin** | ppPreviewPin | Specifies that address of a pointer
 *    to a <c CPreviewPin> object to receive the a pointer to the newly
 *    created pin.
 *
 *  @rdesc This method returns an HRESULT value that depends on the
 *    implementation of the interface. HRESULT can include one of the
 *    following standard constants, or other values not listed:
 *
 *  @flag E_FAIL | Failure
 *  @flag E_POINTER | Null pointer argument
 *  @flag NOERROR | No error
 ***************************************************************************/
HRESULT CALLBACK CPreviewPin::CreatePreviewPin(CTAPIVCap *pCaptureFilter, CPreviewPin **ppPreviewPin)
{
        HRESULT Hr = NOERROR;

        FX_ENTRY("CPreviewPin::CreatePreviewPin")

        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: begin", _fx_));

        // Validate input parameters
        ASSERT(pCaptureFilter);
        ASSERT(ppPreviewPin);
        if (!pCaptureFilter || !ppPreviewPin)
        {
                DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: Null pointer argument", _fx_));
                Hr = E_POINTER;
                goto MyExit;
        }

        if (!(*ppPreviewPin = (CPreviewPin *) new CPreviewPin(NAME("Video Preview Stream"), pCaptureFilter, &Hr, L"Preview")))
        {
                DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: Out of memory", _fx_));
                Hr = E_OUTOFMEMORY;
                goto MyExit;
        }

        // If initialization failed, delete the stream array and return the error
        if (FAILED(Hr) && *ppPreviewPin)
        {
                DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: Initialization failed", _fx_));
                Hr = E_FAIL;
                delete *ppPreviewPin, *ppPreviewPin = NULL;
        }

MyExit:
        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: end", _fx_));
        return Hr;
}

/****************************************************************************
 *  @doc INTERNAL CPREVIEWPINMETHOD
 *
 *  @mfunc HRESULT | CPreviewPin | CPreviewPin | This method is the
 *  constructor for the <c CPreviewPin> object
 *
 *  @rdesc Nada.
 ***************************************************************************/
CPreviewPin::CPreviewPin(IN TCHAR *pObjectName, IN CTAPIVCap *pCaptureFilter, IN HRESULT *pHr, IN LPCWSTR pName) : CTAPIBasePin(pObjectName, pCaptureFilter, pHr, pName)
{
        VIDEOINFO       *ppvi = NULL;
        HDC                     hDC;
        int                     nBPP;

        FX_ENTRY("CPreviewPin::CPreviewPin")

        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: begin", _fx_));

        // Validate input parameters
        ASSERT(pHr);
        ASSERT(pCaptureFilter);
        if (!pCaptureFilter || !pHr)
        {
                DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: Null pointer argument", _fx_));
                if (pHr)
                        *pHr = E_POINTER;
        }

        if (pHr && FAILED(*pHr))
        {
                DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: Base class error or invalid input parameter", _fx_));
                goto MyExit;
        }

        // Initialize to default format: RG24 176x144 at 30 fps... but
        // this really depends on the capabilities of the device.
        // If the device can capture in a YUV mode, then we'll use
        // this mode and convert from YUV to RGB24 using the appropriate
        // ICM decoder for the YUV mode. If the device is a RGB device,
        // then we will try to open it, preferrably, in 16, 24, 8 then 4
        // bit mode. The following code looks at the capabilities of the
        // device to build the list of preview formats supported by this
        // pin.
        //
        // If we are previewing the compressed data, we don't really care
        // about the format used to capture the data. We match the format
        // to the output bit depth of the screen.
        if (m_pCaptureFilter->m_fPreviewCompressedData)
        {
                // Get the current bitdepth
                hDC = GetDC(NULL);
                nBPP = GetDeviceCaps(hDC, BITSPIXEL) * GetDeviceCaps(hDC, PLANES);
                ReleaseDC(NULL, hDC);

                // Pick up the appropriate formats
                if (nBPP >= 24)
                {
                        m_mt = *Preview_RGB24_Formats[0];
                        m_aFormats = (AM_MEDIA_TYPE**)Preview_RGB24_Formats;
                        m_aCapabilities = Preview_RGB24_Caps;
                        m_dwNumFormats = NUM_RGB24_PREVIEW_FORMATS;
                }
                else if (nBPP == 16)
                {
                        m_mt = *Preview_RGB16_Formats[0];
                        m_aFormats = (AM_MEDIA_TYPE**)Preview_RGB16_Formats;
                        m_aCapabilities = Preview_RGB16_Caps;
                        m_dwNumFormats = NUM_RGB16_PREVIEW_FORMATS;
                }
                else if (nBPP < 16)
                {
                        m_mt = *Preview_RGB8_Formats[0];        //Assume 256 colors: [added: Cristiai (4 Dec 2000 21:54:12)]
                        m_aFormats = Preview_RGB8_Formats;
                        m_aCapabilities = Preview_RGB8_Caps;
                        m_dwNumFormats = NUM_RGB8_PREVIEW_FORMATS;
                        for (DWORD dw = 0; dw < m_dwNumFormats; dw++)
                        {
                                // Our video decoder uses the Indeo Palette
                                CopyMemory(((VIDEOINFO *)(m_aFormats[dw]->pbFormat))->bmiColors, g_IndeoPalette, 256 * sizeof(RGBQUAD));
                        }
                }
        }
        else if (m_pCaptureFilter->m_pCapDev->m_dwFormat & 0xFFFFFFF0)
        {
                // We'll use a YUV mode -> advertize RGB24
                m_mt = *Preview_RGB24_Formats[0];
                m_aFormats = (AM_MEDIA_TYPE**)Preview_RGB24_Formats;
                m_aCapabilities = Preview_RGB24_Caps;
                m_dwNumFormats = NUM_RGB24_PREVIEW_FORMATS;
        }
        else if (m_pCaptureFilter->m_pCapDev->m_dwFormat & VIDEO_FORMAT_NUM_COLORS_65536)
        {
                // We'll use RGB16
                m_mt = *Preview_RGB16_Formats[0];
                m_aFormats = (AM_MEDIA_TYPE**)Preview_RGB16_Formats;
                m_aCapabilities = Preview_RGB16_Caps;
                m_dwNumFormats = NUM_RGB16_PREVIEW_FORMATS;
        }
        else if (m_pCaptureFilter->m_pCapDev->m_dwFormat & VIDEO_FORMAT_NUM_COLORS_16777216)
        {
                // We'll use RGB24
                m_mt = *Preview_RGB24_Formats[0];
                m_aFormats = (AM_MEDIA_TYPE**)Preview_RGB24_Formats;
                m_aCapabilities = Preview_RGB24_Caps;
                m_dwNumFormats = NUM_RGB24_PREVIEW_FORMATS;
        }
        else if (m_pCaptureFilter->m_pCapDev->m_dwFormat & VIDEO_FORMAT_NUM_COLORS_256)
        {
                // We'll use RGB8
                m_aFormats = Preview_RGB8_Formats;
                m_aCapabilities = Preview_RGB8_Caps;
                m_dwNumFormats = NUM_RGB8_PREVIEW_FORMATS;

                // Now get the palette from the device
                if (SUCCEEDED(m_pCaptureFilter->m_pCapDev->GetFormatFromDriver((VIDEOINFOHEADER **)&ppvi)))
                {
                        // Copy the palette bits in all our formats
                        // The reason we only copy the palette is the size of the captured
                        // image maybe 160x120 for instance, from which we can generate a
                        // QCIF image through stretching/black banding. We only care about
                        // advertizing the stretched formats, not the captured one at this
                        // point.

                        // Another issue is the palette used. When we stretch from 160x120
                        // (or whatever VfW size) to one of the ITU-T size, we use a different
                        // palette in stretched mode. In black banding mode, we always use
                        // the palette of the capture device.
                        if (m_fNoImageStretch)
                        {
                                for (DWORD dw = 0; dw < m_dwNumFormats; dw++)
                                {
                                        CopyMemory(((VIDEOINFO *)(m_aFormats[dw]->pbFormat))->bmiColors, ppvi->bmiColors, ppvi->bmiHeader.biClrImportant ? ppvi->bmiHeader.biClrImportant * sizeof(RGBQUAD) : 256 * sizeof(RGBQUAD));
                                }
                        }
                        else
                        {
                                // Look for the palette to use
                                for (DWORD dw = 0; dw < m_dwNumFormats; dw++)
                                {
                                        // Is this size directly supported by the device?
                                        for (DWORD dw2 = 0; dw2 < VIDEO_FORMAT_NUM_RESOLUTIONS; dw2++)
                                        {
                                                if (((VIDEOINFOHEADER *)(m_aFormats[dw]->pbFormat))->bmiHeader.biHeight == awResolutions[dw2].framesize.cy && ((VIDEOINFOHEADER *)(m_aFormats[dw]->pbFormat))->bmiHeader.biWidth == awResolutions[dw2].framesize.cx)
                                                        break;
                                        }

                                        // If it is supported by the device, use the capture device palette
                                        if (dw2 < VIDEO_FORMAT_NUM_RESOLUTIONS && (m_pCaptureFilter->m_pCapDev->m_dwImageSize & awResolutions[dw2].dwRes))
                                        {
                                                CopyMemory(((VIDEOINFO *)(m_aFormats[dw]->pbFormat))->bmiColors, ppvi->bmiColors, ppvi->bmiHeader.biClrImportant ? ppvi->bmiHeader.biClrImportant * sizeof(RGBQUAD) : 256 * sizeof(RGBQUAD));
                                        }
                                        else
                                        {
                                            int r,g,b;
                                            DWORD *pdw;
                                            
                                            pdw = (DWORD *)(((VIDEOINFO *)(m_aFormats[dw]->pbFormat))->bmiColors);
                                            ((VIDEOINFOHEADER *)(m_aFormats[dw]->pbFormat))->bmiHeader.biClrUsed = 256;
                                            ((VIDEOINFOHEADER *)(m_aFormats[dw]->pbFormat))->bmiHeader.biClrImportant = 256;

#define NOCOLLAPSEPALETTERGBQ(r,g,b)   (0x04000000 | RGB(b,g,r))

                                                // This is the palette we use when we do stretching
                                            for (r=0; r<10; r++)
                                                        *pdw++ = 0UL;
                                            for (r=0; r<6; r++)
                                                for (g=0; g<6; g++)
                                                    for (b=0; b<6; b++)
                                                        *pdw++ = NOCOLLAPSEPALETTERGBQ(r*255/5,g*255/5,b*255/5);
                                                        //*pdw++ = RGB(b*255/5,g*255/5,r*255/5);
                                            for (r=0; r<30; r++)
                                                        *pdw++ = 0UL;
                                        }
                                }
                        }

                        delete ppvi;
                }

                // Now set the current format
                m_mt = *Preview_RGB8_Formats[0];
        }
        else
        {
                // Now get the palette from the device
                if (SUCCEEDED(m_pCaptureFilter->m_pCapDev->GetFormatFromDriver((VIDEOINFOHEADER **)&ppvi)))
                {
                        // Copy the palette bits in all our formats
                        // The reason we only copy the palette is the size of the captured
                        // image maybe 160x120 for instance, from which we can generate a
                        // QCIF image through stretching/black banding. We only care about
                        // advertizing the stretched formats, not the captured one at this
                        // point.

                        // Another issue is the palette used. When we stretch from 160x120
                        // (or whatever VfW size) to one of the ITU-T size, we use a different
                        // palette in stretched mode. In black banding mode, we always use
                        // the palette of the capture device.
                        if (m_fNoImageStretch)
                        {
                                // We'll use RGB4
                                m_aFormats = Preview_RGB4_Formats;
                                m_aCapabilities = Preview_RGB4_Caps;
                                m_dwNumFormats = NUM_RGB4_PREVIEW_FORMATS;

                                for (DWORD dw = 0; dw < m_dwNumFormats; dw++)
                                {
                                        CopyMemory(((VIDEOINFO *)(m_aFormats[dw]->pbFormat))->bmiColors, ppvi->bmiColors, ppvi->bmiHeader.biClrImportant ? ppvi->bmiHeader.biClrImportant * sizeof(RGBQUAD) : 16 * sizeof(RGBQUAD));
                                }

                                // Now set the current format
                                m_mt = *Preview_RGB4_Formats[0];
                        }
                        else
                        {

                                // When we stretch RGB4 data, we output to an RGB8 image.
                                m_aFormats = Preview_RGB8_Formats;
                                m_aCapabilities = Preview_RGB8_Caps;
                                m_dwNumFormats = NUM_RGB8_PREVIEW_FORMATS;

                                // Look for the palette to use
                                for (DWORD dw = 0; dw < m_dwNumFormats; dw++)
                                {
                                        // Is this size directly supported by the device?
                                        for (DWORD dw2 = 0; dw2 < VIDEO_FORMAT_NUM_RESOLUTIONS; dw2++)
                                        {
                                                if (((VIDEOINFOHEADER *)(m_aFormats[dw]->pbFormat))->bmiHeader.biHeight == awResolutions[dw2].framesize.cy && ((VIDEOINFOHEADER *)(m_aFormats[dw]->pbFormat))->bmiHeader.biWidth == awResolutions[dw2].framesize.cx)
                                                        break;
                                        }

                                        // If it is supported by the device, use the capture device palette
                                        if (dw2 < VIDEO_FORMAT_NUM_RESOLUTIONS && (m_pCaptureFilter->m_pCapDev->m_dwImageSize & awResolutions[dw2].dwRes))
                                        {
                                                m_aFormats[dw] = Preview_RGB4_Formats[dw];
                                                CopyMemory(((VIDEOINFO *)(m_aFormats[dw]->pbFormat))->bmiColors, ppvi->bmiColors, ppvi->bmiHeader.biClrImportant ? ppvi->bmiHeader.biClrImportant * sizeof(RGBQUAD) : 16 * sizeof(RGBQUAD));
                                        }
                                        else
                                        {
                                            int r,g,b;
                                            DWORD *pdw;
                                            
                                            pdw = (DWORD *)(((VIDEOINFO *)(m_aFormats[dw]->pbFormat))->bmiColors);
                                            ((VIDEOINFOHEADER *)(m_aFormats[dw]->pbFormat))->bmiHeader.biClrUsed = 256;
                                            ((VIDEOINFOHEADER *)(m_aFormats[dw]->pbFormat))->bmiHeader.biClrImportant = 256;

#define NOCOLLAPSEPALETTERGBQ(r,g,b)   (0x04000000 | RGB(b,g,r))

                                                // This is the palette we use when we do stretching
                                            for (r=0; r<10; r++)
                                                        *pdw++ = 0UL;
                                            for (r=0; r<6; r++)
                                                for (g=0; g<6; g++)
                                                    for (b=0; b<6; b++)
                                                        *pdw++ = NOCOLLAPSEPALETTERGBQ(r*255/5,g*255/5,b*255/5);
                                                        //*pdw++ = RGB(b*255/5,g*255/5,r*255/5);
                                            for (r=0; r<30; r++)
                                                        *pdw++ = 0UL;
                                        }
                                }

                                // Now set the current format
                                m_mt = *Preview_RGB8_Formats[0];
                        }

                        delete ppvi;
                }
        }

        // Update frame rate controls
        m_lMaxAvgTimePerFrame = (LONG)Preview_RGB24_Caps[0]->MinFrameInterval;
        m_lCurrentAvgTimePerFrame = m_lMaxAvgTimePerFrame;
        m_lAvgTimePerFrameRangeMin = (LONG)Preview_RGB24_Caps[0]->MinFrameInterval;
        m_lAvgTimePerFrameRangeMax = (LONG)Preview_RGB24_Caps[0]->MaxFrameInterval;
        m_lAvgTimePerFrameRangeSteppingDelta = (LONG)(Preview_RGB24_Caps[0]->MaxFrameInterval - Preview_RGB24_Caps[0]->MinFrameInterval) / 100;
        m_lAvgTimePerFrameRangeDefault = (LONG)Preview_RGB24_Caps[0]->MinFrameInterval;

MyExit:
        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: end", _fx_));
}

/****************************************************************************
 *  @doc INTERNAL CPREVIEWPINMETHOD
 *
 *  @mfunc void | CPreviewPin | ~CPreviewPin | This method is the destructor
 *    for the <c CPreviewPin> object.
 *
 *  @rdesc Nada.
 ***************************************************************************/
CPreviewPin::~CPreviewPin()
{
        FX_ENTRY("CPreviewPin::~CPreviewPin")

        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: begin", _fx_));

        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: end", _fx_));
}

/****************************************************************************
 *  @doc INTERNAL CPREVIEWPINMETHOD
 *
 *  @mfunc HRESULT | CPreviewPin | NonDelegatingQueryInterface | This
 *    method is the nondelegating interface query function. It returns a pointer
 *    to the specified interface if supported. The only interfaces explicitly
 *    supported being <i IAMStreamConfig>,
 *    <i IAMStreamControl>, <i ICPUControl>, <i IFrameRateControl>,
 *    <i IBitrateControl>, <i INetworkStats>, <i IH245EncoderCommand>
 *    and <i IProgressiveRefinement>.
 *
 *  @parm REFIID | riid | Specifies the identifier of the interface to return.
 *
 *  @parm PVOID* | ppv | Specifies the place in which to put the interface
 *    pointer.
 *
 *  @rdesc This method returns an HRESULT value that depends on the
 *    implementation of the interface. HRESULT can include one of the
 *    following standard constants, or other values not listed:
 *
 *  @flag E_FAIL | Failure
 *  @flag E_POINTER | Null pointer argument
 *  @flag NOERROR | No error
 ***************************************************************************/
STDMETHODIMP CPreviewPin::NonDelegatingQueryInterface(IN REFIID riid, OUT void **ppv)
{
        HRESULT Hr = NOERROR;

        FX_ENTRY("CPreviewPin::NonDelegatingQueryInterface")

        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: begin", _fx_));

        // Validate input parameters
        ASSERT(ppv);
        if (!ppv)
        {
                DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: Null pointer argument", _fx_));
                Hr = E_POINTER;
                goto MyExit;
        }

        if (riid == __uuidof(IAMStreamControl))
        {
                if (FAILED(Hr = GetInterface(static_cast<IAMStreamControl*>(this), ppv)))
                {
                        DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: NDQI for IAMStreamControl failed Hr=0x%08lX", _fx_, Hr));
                }
                else
                {
                        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s:   SUCCESS: IAMStreamControl*=0x%08lX", _fx_, *ppv));
                }

                goto MyExit;
        }
#ifdef USE_PROPERTY_PAGES
        else if (riid == IID_ISpecifyPropertyPages)
        {
                if (FAILED(Hr = GetInterface(static_cast<ISpecifyPropertyPages*>(this), ppv)))
                {
                        DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: NDQI for ISpecifyPropertyPages failed Hr=0x%08lX", _fx_, Hr));
                }
                else
                {
                        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s:   SUCCESS: ISpecifyPropertyPages*=0x%08lX", _fx_, *ppv));
                }

                goto MyExit;
        }
#endif

        if (FAILED(Hr = CTAPIBasePin::NonDelegatingQueryInterface(riid, ppv)))
        {
                DBGOUT((g_dwVideoCaptureTraceID, WARN, "%s:   WARNING: NDQI for {%08lX-%04lX-%04lX-%02lX%02lX-%02lX%02lX%02lX%02lX%02lX%02lX} failed Hr=0x%08lX", _fx_, riid.Data1, riid.Data2, riid.Data3, riid.Data4[0], riid.Data4[1], riid.Data4[2], riid.Data4[3], riid.Data4[4], riid.Data4[5], riid.Data4[6], riid.Data4[7], Hr));
        }
        else
        {
                DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s:   SUCCESS: {%08lX-%04lX-%04lX-%02lX%02lX-%02lX%02lX%02lX%02lX%02lX%02lX}*=0x%08lX", _fx_, riid.Data1, riid.Data2, riid.Data3, riid.Data4[0], riid.Data4[1], riid.Data4[2], riid.Data4[3], riid.Data4[4], riid.Data4[5], riid.Data4[6], riid.Data4[7], *ppv));
        }

MyExit:
        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: end", _fx_));
        return Hr;
}

#ifdef USE_PROPERTY_PAGES
/****************************************************************************
 *  @doc INTERNAL CPREVIEWPINMETHOD
 *
 *  @mfunc HRESULT | CPreviewPin | GetPages | This method Fills a counted
 *    array of GUID values where each GUID specifies the CLSID of each
 *    property page that can be displayed in the property sheet for this
 *    object.
 *
 *  @parm CAUUID* | pPages | Specifies a pointer to a caller-allocated CAUUID
 *    structure that must be initialized and filled before returning. The
 *    pElems field in the CAUUID structure is allocated by the callee with
 *    CoTaskMemAlloc and freed by the caller with CoTaskMemFree.
 *
 *  @rdesc This method returns an HRESULT value that depends on the
 *    implementation of the interface. HRESULT can include one of the
 *    following standard constants, or other values not listed:
 *
 *  @flag E_FAIL | Failure
 *  @flag E_POINTER | Null pointer argument
 *  @flag E_OUTOFMEMORY | Allocation failed
 *  @flag NOERROR | No error
 ***************************************************************************/
STDMETHODIMP CPreviewPin::GetPages(OUT CAUUID *pPages)
{
        HRESULT Hr = NOERROR;

        FX_ENTRY("CPreviewPin::GetPages")

        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: begin", _fx_));

        // Validate input parameters
        ASSERT(pPages);
        if (!pPages)
        {
                DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: Null pointer argument", _fx_));
                Hr = E_POINTER;
                goto MyExit;
        }

#ifdef USE_CPU_CONTROL
        pPages->cElems = 2;
#else
        pPages->cElems = 1;
#endif

        // Alloc memory for the page stuff
        if (!(pPages->pElems = (GUID *) QzTaskMemAlloc(sizeof(GUID) * pPages->cElems)))
        {
                DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: invalid input parameter", _fx_));
                Hr = E_OUTOFMEMORY;
        }
        else
        {
                pPages->pElems[0] = __uuidof(PreviewPropertyPage);
#ifdef USE_CPU_CONTROL
                pPages->pElems[1] = __uuidof(CPUCPropertyPage);
#endif
        }

MyExit:
        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: end", _fx_));
        return Hr;
}
#endif
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\net\tapi\skywalker\filters\video\tapivcap\previewp.h ===
/****************************************************************************
 *  @doc INTERNAL PREVIEWP
 *
 *  @module PreviewP.h | Header file for the <c CPreviewProperty>
 *    class used to implement a property page to test the new TAPI internal
 *    interface <i IFrameRateControl> and dynamic format changes.
 *
 *  @comm This code tests the TAPI VfW Preview Pin <i IFrameRateControl>,
 *    and dynamic format change implementation. This code is only compiled
 *    if USE_PROPERTY_PAGES is defined.
 ***************************************************************************/

#ifndef _PREVIEWP_H_
#define _PREVIEWP_H_

#ifdef USE_PROPERTY_PAGES

#define NUM_PREVIEW_CONTROLS			4
#define IDC_Preview_FrameRate			0
#define IDC_Preview_CurrentFrameRate	1
#define IDC_Preview_FlipVertical		2
#define IDC_Preview_FlipHorizontal		3

/****************************************************************************
 *  @doc INTERNAL CPREVIEWPCLASS
 *
 *  @class CPreviewProperty | This class implements handling of a
 *    single preview property in a property page.
 *
 *  @mdata int | CPreviewProperty | m_NumProperties | Keeps
 *    track of the number of properties.
 *
 *  @mdata IFrameRateControl* | CPreviewProperty | m_pIFrameRateControl | Pointer
 *    to the <i IFrameRateControl> interface.
 *
 *  @comm This code tests the TAPI VfW Preview Pin <i IFrameRateControl>,
 *    and dynamic format change implementation. This code is only compiled
 *    if USE_PROPERTY_PAGES is defined.
***************************************************************************/
class CPreviewProperty : public CPropertyEditor 
{
	public:
	CPreviewProperty(HWND hDlg, ULONG IDLabel, ULONG IDMinControl, ULONG IDMaxControl, ULONG IDDefaultControl, ULONG IDStepControl, ULONG IDEditControl, ULONG IDTrackbarControl, ULONG IDProgressControl, ULONG IDProperty, IFrameRateControl *pIFrameRateControl, IVideoControl *pIVideoControl);
	~CPreviewProperty ();

	// CPropertyEditor base class pure virtual overrides
	HRESULT GetValue();
	HRESULT SetValue();
	HRESULT GetRange();
	BOOL CanAutoControl(void);
	BOOL GetAuto(void);
	BOOL SetAuto(BOOL fAuto);

	private:
	IFrameRateControl *m_pIFrameRateControl;
	IVideoControl *m_pIVideoControl;
};

/****************************************************************************
 *  @doc INTERNAL CPREVIEWPCLASS
 *
 *  @class CPreviewProperties | This class implements a property page
 *    to test the new TAPI internal interfaces <i IBitrateControl> and
 *    <i IFrameRateControl>.
 *
 *  @mdata int | CPreviewProperties | m_NumProperties | Keeps
 *    track of the number of properties.
 *
 *  @mdata IFrameRateControl* | CPreviewProperties | m_pInterface | Pointer
 *    to the <i IFrameRateControl> interface.
 *
 *  @mdata CPreviewProperty* | CPreviewProperties | m_Controls[NUM_PREVIEW_CONTROLS] | Array
 *    of capture properties.
 *
 *  @comm This code tests the TAPI VfW Preview Pin <i IFrameRateControl>,
 *    and dynamic format change implementation. This code is only compiled
 *    if USE_PROPERTY_PAGES is defined.
***************************************************************************/
class CPreviewProperties : public CBasePropertyPage
{
	public:
	CPreviewProperties(LPUNKNOWN pUnk, HRESULT *pHr);
	~CPreviewProperties();

	// Implement CBasePropertyPage virtual methods
	HRESULT OnConnect(IUnknown *pUnk);
	HRESULT OnDisconnect();
	HRESULT OnActivate();
	HRESULT OnDeactivate();
	HRESULT OnApplyChanges();
	BOOL    OnReceiveMessage(HWND hWnd, UINT uMsg, WPARAM wParam, LPARAM lParam);

	private:

	void SetDirty();

	// Format manipulation methods
	HRESULT InitialRangeScan();
	HRESULT OnFormatChanged();
	HRESULT GetCurrentMediaType(void);

	HWND						m_hWnd;
	int							m_NumProperties;
	IFrameRateControl			*m_pIFrameRateControl;
	IAMStreamConfig				*m_pIAMStreamConfig;
	IVideoControl				*m_pIVideoControl;
	int							m_RangeCount;
	VIDEO_STREAM_CONFIG_CAPS	m_RangeCaps;
	GUID						*m_SubTypeList;
	SIZE						*m_FrameSizeList;
	GUID						m_SubTypeCurrent;
	SIZE						m_FrameSizeCurrent;
	AM_MEDIA_TYPE				*m_CurrentMediaType;
	HWND						m_hWndFormat;
	BOOL						m_fActivated;
	int							m_CurrentFormat;
	int							m_OriginalFormat;

	CPreviewProperty *m_Controls[NUM_PREVIEW_CONTROLS];
};

#endif // USE_PROPERTY_PAGES

#endif // _PREVIEWP_H_
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\net\tapi\skywalker\filters\video\tapivcap\procamp.cpp ===
/****************************************************************************
 *  @doc INTERNAL PROCAMP
 *
 *  @module ProcAmp.cpp | Source file for the <c CWDMCapDev>
 *    class methods used to implement the <i IAMVideoProcAmp> interface.
 ***************************************************************************/

#include "Precomp.h"

/****************************************************************************
 *  @doc INTERNAL CPROCAMPMETHOD
 *
 *  @mfunc HRESULT | CWDMCapDev | Set | This method is used to set the value
 *    of a video quality setting.
 *
 *  @parm VideoProcAmpProperty | Property | Used to specify the video
 *    quality setting to set the value of. Use a member of the
 *    <t VideoProcAmpProperty> enumerated type.
 *
 *  @parm long | lValue | Used to specify the new value of the video quality
 *    setting.
 *
 *  @parm TAPIControlFlags | Flags | A member of the <t TAPIControlFlags> enumerated
 *    type.
 *
 *  @rdesc This method returns an HRESULT value that depends on the
 *    implementation of the interface. HRESULT can include one of the
 *    following standard constants, or other values not listed:
 *
 *  @flag E_FAIL | Failure
 *  @flag E_NOTIMPL | Method is not supported
 *  @flag E_INVALIDARG | Invalid argument
 *  @flag E_PROP_ID_UNSUPPORTED | The specified property ID is not supported
 *    for the specified property set
 *  @flag NOERROR | No error
 ***************************************************************************/
STDMETHODIMP CWDMCapDev::Set(IN VideoProcAmpProperty Property, IN long lValue, IN TAPIControlFlags lFlags)
{
	HRESULT Hr = NOERROR;
	LONG lMin,lMax,lStep,lDefault;
	TAPIControlFlags lCtrlFlags;

	FX_ENTRY("CWDMCapDev::Set (VideoProcAmp)")

	DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: begin", _fx_));

	// Validate input parameters
	ASSERT(Property >= VideoProcAmp_Brightness && Property <= VideoProcAmp_BacklightCompensation);
	if (Property < VideoProcAmp_Brightness || Property > VideoProcAmp_BacklightCompensation)
	{
		DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: Invalid Property argument", _fx_));
		Hr = E_INVALIDARG;
		goto MyExit;
	}
	ASSERT(lFlags == TAPIControl_Flags_Manual || lFlags == TAPIControl_Flags_Auto);
	if (lFlags != TAPIControl_Flags_Manual)
	{
		DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: invalid input parameter", _fx_));
		Hr = E_INVALIDARG;
		goto MyExit;
	}

	//Get range (min/max/...)
	if(FAILED(Hr=GetRange(Property, &lMin, &lMax, &lStep, &lDefault, &lCtrlFlags))) {
		DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: Couldn't get the range of values from driver", _fx_));
		goto MyExit;
	}
		
	if(lValue<lMin || lValue>lMax) {
		DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: Invalid Value: Out of range", _fx_));
		Hr = E_INVALIDARG;
		goto MyExit;
	}

	// Set the property on the driver
	if (FAILED(Hr = SetPropertyValue(PROPSETID_VIDCAP_VIDEOPROCAMP, (ULONG)Property, lValue, (ULONG)lFlags, (ULONG)lFlags)))
	{
		DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: SetPropertyValue failed", _fx_));
	}
	else
	{
		DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s:   SUCCESS: SetPropertyValue succeeded", _fx_));
	}

MyExit:
	DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: end", _fx_));
	return Hr;
}

/****************************************************************************
 *  @doc INTERNAL CPROCAMPMETHOD
 *
 *  @mfunc HRESULT | CWDMCapDev | Get | This method is used to retrieve the
 *    value of a video quality setting.
 *
 *  @parm VideoProcAmpProperty | Property | Used to specify the video
 *    quality setting to get the value of. Use a member of the
 *    <t VideoProcAmpProperty> enumerated type.
 *
 *  @parm long* | plValue | Used to retrieve the current value of the
 *    video quality setting.
 *
 *  @parm TAPIControlFlags* | plFlags | Pointer to a member of the <t TAPIControlFlags>
 *    enumerated type.
 *
 *  @rdesc This method returns an HRESULT value that depends on the
 *    implementation of the interface. HRESULT can include one of the
 *    following standard constants, or other values not listed:
 *
 *  @flag E_FAIL | Failure
 *  @flag E_POINTER | Null pointer argument
 *  @flag E_INVALIDARG | Invalid argument
 *  @flag E_PROP_ID_UNSUPPORTED | The specified property ID is not supported
 *    for the specified property set
 *  @flag E_NOTIMPL | Method is not supported
 *  @flag NOERROR | No error
 ***************************************************************************/
STDMETHODIMP CWDMCapDev::Get(IN VideoProcAmpProperty Property, OUT long *plValue, OUT TAPIControlFlags *plFlags)
{
	HRESULT Hr = NOERROR;
	ULONG ulCapabilities;

	FX_ENTRY("CWDMCapDev::Get (VideoProcAmp)")

	DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: begin", _fx_));

	// Validate input parameters
	ASSERT(plValue);
	ASSERT(plFlags);
	if (!plValue || !plFlags)
	{
		DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: Null pointer argument", _fx_));
		Hr = E_POINTER;
		goto MyExit;
	}
	ASSERT(Property >= VideoProcAmp_Brightness && Property <= VideoProcAmp_BacklightCompensation);
	if (Property < VideoProcAmp_Brightness || Property > VideoProcAmp_BacklightCompensation)
	{
		DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: Invalid Property argument", _fx_));
		Hr = E_INVALIDARG;
		goto MyExit;
	}

	// Get the property from the driver
	if (FAILED(Hr = GetPropertyValue(PROPSETID_VIDCAP_VIDEOPROCAMP, (ULONG)Property, plValue, (PULONG)plFlags, &ulCapabilities)))
	{
		DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: GetPropertyValue failed", _fx_));
	}
	else
	{
		DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s:   SUCCESS: GetPropertyValue succeeded", _fx_));
	}

MyExit:
	DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: end", _fx_));
	return Hr;
}

/****************************************************************************
 *  @doc INTERNAL CPROCAMPMETHOD
 *
 *  @mfunc HRESULT | CWDMCapDev | GetRange | This method is used to retrieve
 *    the minimum, maximum, and default values for specific video quality
 *    settings.
 *
 *  @parm VideoProcAmpProperty | Property | Used to specify the video
 *    quality setting to determine the range of. Use a member of the
 *    <t VideoProcAmpProperty> enumerated type.
 *
 *  @parm long* | plMin | Used to retrieve the minimum value of the video
 *    quality setting range.
 *
 *  @parm long* | plMax | Used to retrieve the maximum value of the video
 *    quality setting range.
 *
 *  @parm long* | plSteppingDelta | Used to retrieve the stepping delta of
 *    the video quality setting range.
 *
 *  @parm long* | plDefault | Used to retrieve the default value of the
 *    video quality setting range.
 *
 *  @parm TAPIControlFlags* | plCapsFlags | Used to retrieve the capabilities of the
 *    video quality setting. Pointer to a member of the
 *    <t TAPIControlFlags> enumerated type.
 *
 *  @rdesc This method returns an HRESULT value that depends on the
 *    implementation of the interface. HRESULT can include one of the
 *    following standard constants, or other values not listed:
 *
 *  @flag E_FAIL | Failure
 *  @flag E_POINTER | Null pointer argument
 *  @flag E_INVALIDARG | Invalid argument
 *  @flag E_PROP_ID_UNSUPPORTED | The specified property ID is not supported
 *    for the specified property set
 *  @flag E_NOTIMPL | Method is not supported
 *  @flag NOERROR | No error
 ***************************************************************************/
STDMETHODIMP CWDMCapDev::GetRange(IN VideoProcAmpProperty Property, OUT long *plMin, OUT long *plMax, OUT long *plSteppingDelta, OUT long *plDefault, OUT TAPIControlFlags *plCapsFlags)
{
	HRESULT Hr = NOERROR;
	LONG  lCurrentValue;
	ULONG ulCurrentFlags;

	FX_ENTRY("CWDMCapDev::GetRange (VideoProcAmp)")

	DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: begin", _fx_));

	// Validate input parameters
	ASSERT(plMin);
	ASSERT(plMax);
	ASSERT(plSteppingDelta);
	ASSERT(plDefault);
	ASSERT(plCapsFlags);
	if (!plMin || !plMax || !plSteppingDelta || !plDefault || !plCapsFlags)
	{
		DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: Null pointer argument", _fx_));
		Hr = E_POINTER;
		goto MyExit;
	}
	ASSERT(Property >= VideoProcAmp_Brightness && Property <= VideoProcAmp_BacklightCompensation);
	if (Property < VideoProcAmp_Brightness || Property > VideoProcAmp_BacklightCompensation)
	{
		DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: Invalid Property argument", _fx_));
		Hr = E_INVALIDARG;
		goto MyExit;
	}

	// Get the range values from the driver
	if (FAILED(Hr = GetRangeValues(PROPSETID_VIDCAP_VIDEOPROCAMP, (ULONG)Property, plMin, plMax, plSteppingDelta)))
	{
		DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: GetRangeValues failed", _fx_));
		goto MyExit;
	}
	else
	{
		DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s:   SUCCESS: GetRangeValues succeeded", _fx_));
	}

	// Get the capability flags from the driver
	if (FAILED(Hr = GetPropertyValue(PROPSETID_VIDCAP_VIDEOPROCAMP, (ULONG)Property, &lCurrentValue, &ulCurrentFlags, (PULONG)plCapsFlags)))
	{
		DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: GetRangeValues failed", _fx_));
		goto MyExit;
	}
	else
	{
		DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s:   SUCCESS: GetRangeValues succeeded", _fx_));
	}

	// Get the default value from the driver
	if (FAILED(Hr = GetDefaultValue(PROPSETID_VIDCAP_VIDEOPROCAMP, (ULONG)Property, plDefault)))
	{
		DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: GetDefaultValue failed", _fx_));
	}
	else
	{
		DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s:   SUCCESS: GetDefaultValue succeeded", _fx_));
	}

MyExit:
	DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: end", _fx_));
	return Hr;
}
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\net\tapi\skywalker\filters\video\tapivcap\procampp.h ===
/****************************************************************************
 *  @doc INTERNAL PROCAMPP
 *
 *  @module ProcAmpP.h | Header file for the <c CProcAmpProperty>
 *    class used to implement a property page to test the DShow interface
 *    <i IAMVideoProcAmp>.
 *
 *  @comm This code tests the TAPI Capture Filter <i IAMVideoProcAmp>
 *    implementation. This code is only compiled if USE_PROPERTY_PAGES is
 *    defined.
 ***************************************************************************/

#ifndef _PROCAMPP_H_
#define _PROCAMPP_H_

#ifdef USE_PROPERTY_PAGES

#define NUM_PROCAMP_CONTROLS (VideoProcAmp_BacklightCompensation + 1)

/****************************************************************************
 *  @doc INTERNAL CPROCAMPPCLASS
 *
 *  @class CProcAmpProperty | This class implements handling of a
 *    single video proc amp control property in a property page.
 *
 *  @mdata int | CProcAmpProperty | m_NumProperties | Keeps
 *    track of the number of properties.
 *
 *  @mdata IAMVideoProcAmp * | CProcAmpProperty | m_pInterface | Pointer
 *    to the <i IAMVideoProcAmp> interface.
 *
 *  @comm This code tests the TAPI Capture Filter <i IAMVideoProcAmp>
 *    implementation. This code is only compiled if USE_PROPERTY_PAGES is
 *    defined.
***************************************************************************/
class CProcAmpProperty : public CPropertyEditor 
{
	public:
	CProcAmpProperty(HWND hDlg, ULONG IDLabel, ULONG IDMinControl, ULONG IDMaxControl, ULONG IDDefaultControl, ULONG IDStepControl, ULONG IDEditControl, ULONG IDTrackbarControl, ULONG IDProgressControl, ULONG IDProperty, ULONG IDAutoControl, IAMVideoProcAmp *pInterface);
	~CProcAmpProperty ();

	// CPropertyEditor base class pure virtual overrides
	HRESULT GetValue();
	HRESULT SetValue();
	HRESULT GetRange();
	BOOL CanAutoControl(void);
	BOOL GetAuto(void);
	BOOL SetAuto(BOOL fAuto);

	private:
	IAMVideoProcAmp *m_pInterface;
};

/****************************************************************************
 *  @doc INTERNAL CPROCAMPPCLASS
 *
 *  @class CProcAmpProperties | This class runs a property page to test
 *    the TAPI Capture Filter <i IAMVideoProcAmp> implementation.
 *
 *  @mdata int | CProcAmpProperties | m_NumProperties | Keeps
 *    track of the number of properties.
 *
 *  @mdata IAMVideoProcAmp * | CProcAmpProperties | m_pIAMVideoProcAmp | Pointer
 *    to the <i IAMVideoProcAmp> interface.
 *
 *  @mdata CProcAmpProperty * | CProcAmpProperties | m_Controls[NUM_PROCAMP_CONTROLS] | Array
 *    of video proc amp properties.
 *
 *  @comm This code tests the TAPI Capture Filter <i IAMVideoProcAmp>
 *    implementation. This code is only compiled if USE_PROPERTY_PAGES is
 *    defined.
***************************************************************************/
class CProcAmpProperties : public CBasePropertyPage
{
	public:
	CProcAmpProperties(LPUNKNOWN pUnk, HRESULT *pHr);
	~CProcAmpProperties();

	HRESULT OnConnect(IUnknown *pUnk);
	HRESULT OnDisconnect();
	HRESULT OnActivate();
	HRESULT OnDeactivate();
	HRESULT OnApplyChanges();
	BOOL    OnReceiveMessage(HWND hWnd, UINT uMsg, WPARAM wParam, LPARAM lParam);

	private:

	void SetDirty();

	int m_NumProperties;
	IAMVideoProcAmp *m_pIAMVideoProcAmp;
	CProcAmpProperty *m_Controls[NUM_PROCAMP_CONTROLS];
};

#endif // USE_PROPERTY_PAGES

#endif // _PROCAMPP_H_
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\net\tapi\skywalker\filters\video\tapivcap\procampp.cpp ===
/****************************************************************************
 *  @doc INTERNAL PROCAMPP
 *
 *  @module ProcAmpP.cpp | Source file for the <c CProcAmpProperty>
 *    class used to implement a property page to test the DShow interface
 *    <i IAMVideoProcAmp>.
 *
 *  @comm This code tests the TAPI Capture Filter <i IAMVideoProcAmp>
 *    implementation. This code is only compiled if USE_PROPERTY_PAGES is
 *    defined.
 ***************************************************************************/

#include "Precomp.h"

#ifdef USE_PROPERTY_PAGES

/****************************************************************************
 *  @doc INTERNAL CPROCAMPPMETHOD
 *
 *  @mfunc void | CProcAmpProperty | CProcAmpProperty | This
 *    method is the constructor for video proc amp control property objects. It
 *    calls the base class constructor, calls InitCommonControlsEx, and saves
 *    a pointer to the <i IAMVideoProcAmp> interface.
 *
 *  @parm HWND | hDlg | Specifies a handle to the parent property page.
 *
 *  @parm ULONG | IDLabel | Specifies a label ID for the property.
 *
 *  @parm ULONG | IDMinControl | Specifies a label ID for the associated
 *    property edit control where the Minimum value of the property appears.
 *
 *  @parm ULONG | IDMaxControl | Specifies a label ID for the associated
 *    property edit control where the Maximum value of the property appears.
 *
 *  @parm ULONG | IDDefaultControl | Specifies a label ID for the associated
 *    property edit control where the Default value of the property appears.
 *
 *  @parm ULONG | IDStepControl | Specifies a label ID for the associated
 *    property edit control where the Stepping Delta value of the property appears.
 *
 *  @parm ULONG | IDEditControl | Specifies a label ID for the associated
 *    property edit control where the value of the property appears.
 *
 *  @parm ULONG | IDTrackbarControl | Specifies a label ID for the associated
 *    property slide bar.
 *
 *  @parm ULONG | IDProgressControl | Specifies a label ID for the associated
 *    property progress bar.
 *
 *  @parm ULONG | IDProperty | Specifies the ID of the Ks property.
 *
 *  @parm IAMVideoProcAmp* | pInterface | Specifies a pointer to the
 *    <i IAMVideoProcAmp> interface.
 *
 *  @rdesc Nada.
 ***************************************************************************/
CProcAmpProperty::CProcAmpProperty(HWND hDlg, ULONG IDLabel, ULONG IDMinControl, ULONG IDMaxControl, ULONG IDDefaultControl, ULONG IDStepControl, ULONG IDEditControl, ULONG IDTrackbarControl, ULONG IDProgressControl, ULONG IDProperty, ULONG IDAutoControl, IAMVideoProcAmp *pInterface)
: CPropertyEditor(hDlg, IDLabel, IDMinControl, IDMaxControl, IDDefaultControl, IDStepControl, IDEditControl, IDTrackbarControl, IDProgressControl, IDProperty, IDAutoControl)
{
	INITCOMMONCONTROLSEX cc;

	FX_ENTRY("CProcAmpProperty::CProcAmpProperty")

	DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: begin", _fx_));

	cc.dwSize = sizeof (INITCOMMONCONTROLSEX);
	cc.dwICC  = ICC_UPDOWN_CLASS | ICC_BAR_CLASSES;

	InitCommonControlsEx(&cc);

	// It's fine if the interface pointer is NULL, we'll grey the
	// associated items in the property page
	m_pInterface = pInterface;

	DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: end", _fx_));
}

/****************************************************************************
 *  @doc INTERNAL CPROCAMPPMETHOD
 *
 *  @mfunc void | CProcAmpProperty | ~CProcAmpProperty | This
 *    method is the destructor for video proc amp control property objects. It
 *    simply calls the base class destructor.
 *
 *  @rdesc Nada.
 ***************************************************************************/
CProcAmpProperty::~CProcAmpProperty()
{
	FX_ENTRY("CProcAmpProperty::~CProcAmpProperty")

	DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: begin", _fx_));

	DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: end", _fx_));
}

/****************************************************************************
 *  @doc INTERNAL CPROCAMPPMETHOD
 *
 *  @mfunc HRESULT | CProcAmpProperty | GetValue | This method queries for
 *    the value of a property.
 *
 *  @rdesc This method returns an HRESULT value that depends on the
 *    implementation of the interface. HRESULT can include one of the
 *    following standard constants, or other values not listed:
 *
 *  @flag E_FAIL | Failure
 *  @flag E_POINTER | Null pointer argument
 *  @flag E_NOTIMPL | Method is not supported
 *  @flag NOERROR | No error
 ***************************************************************************/
HRESULT CProcAmpProperty::GetValue()
{
	HRESULT Hr = NOERROR;

	FX_ENTRY("CProcAmpProperty::GetValue")

	DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: begin", _fx_));

	// Validate input parameters
	if (!m_pInterface)
	{
		DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: invalid input parameter", _fx_));
		Hr = E_FAIL;
		goto MyExit;
	}

	if (SUCCEEDED (Hr = m_pInterface->Get(m_IDProperty, &m_CurrentValue, &m_CurrentFlags)))
	{
		DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s:   SUCCESS: m_CurrentValue=%ld, m_CurrentFlags=%ld", _fx_, m_CurrentValue, m_CurrentFlags));
	}
	else
	{
		DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: m_pIAMVideoProcAmp->Get failed Hr=0x%08lX", _fx_, Hr));
	}

MyExit:
	DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: end", _fx_));
	return Hr;
}

/****************************************************************************
 *  @doc INTERNAL CPROCAMPPMETHOD
 *
 *  @mfunc HRESULT | CProcAmpProperty | SetValue | This method sets the
 *    value of a property.
 *
 *  @rdesc This method returns an HRESULT value that depends on the
 *    implementation of the interface. HRESULT can include one of the
 *    following standard constants, or other values not listed:
 *
 *  @flag E_FAIL | Failure
 *  @flag E_POINTER | Null pointer argument
 *  @flag E_NOTIMPL | Method is not supported
 *  @flag NOERROR | No error
 ***************************************************************************/
HRESULT CProcAmpProperty::SetValue()
{
	HRESULT Hr = NOERROR;

	FX_ENTRY("CProcAmpProperty::SetValue")

	DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: begin", _fx_));

	// Validate input parameters
	if (!m_pInterface)
	{
		DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: invalid input parameter", _fx_));
		Hr = E_FAIL;
		goto MyExit;
	}

	if (SUCCEEDED (Hr = m_pInterface->Set(m_IDProperty, m_CurrentValue, m_CurrentFlags)))
	{
		DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s:   SUCCESS: m_CurrentValue=%ld, m_CurrentFlags=%ld", _fx_, m_CurrentValue, m_CurrentFlags));
	}
	else
	{
		DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: m_pIAMVideoProcAmp->Set failed Hr=0x%08lX", _fx_, Hr));
	}

MyExit:
	DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: end", _fx_));
	return Hr;
}

/****************************************************************************
 *  @doc INTERNAL CPROCAMPPMETHOD
 *
 *  @mfunc HRESULT | CProcAmpProperty | GetRange | This method retrieves
 *    the range information of a property.
 *
 *  @rdesc This method returns an HRESULT value that depends on the
 *    implementation of the interface. HRESULT can include one of the
 *    following standard constants, or other values not listed:
 *
 *  @flag E_FAIL | Failure
 *  @flag E_POINTER | Null pointer argument
 *  @flag E_NOTIMPL | Method is not supported
 *  @flag NOERROR | No error
 ***************************************************************************/
HRESULT CProcAmpProperty::GetRange()
{
	HRESULT Hr = NOERROR;

	FX_ENTRY("CProcAmpProperty::GetRange")

	DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: begin", _fx_));

	// Validate input parameters
	if (!m_pInterface)
	{
		DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: invalid input parameter", _fx_));
		Hr = E_FAIL;
		goto MyExit;
	}

	if (SUCCEEDED (Hr = m_pInterface->GetRange(m_IDProperty, &m_Min, &m_Max, &m_SteppingDelta, &m_DefaultValue, &m_CapsFlags)))
	{
		DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s:   SUCCESS: m_Min=%ld, m_Max=%ld, m_SteppingDelta=%ld, m_DefaultValue=%ld, m_CapsFlags=%ld", _fx_, m_Min, m_Max, m_SteppingDelta, m_DefaultValue, m_CapsFlags));
	}
	else
	{
		DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: m_pIAMVideoProcAmp->GetRange failed Hr=0x%08lX", _fx_, Hr));
	}
	m_DefaultFlags = m_CapsFlags;

MyExit:
	DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: end", _fx_));
	return Hr;
}

/****************************************************************************
 *  @doc INTERNAL CPROCAMPPMETHOD
 *
 *  @mfunc HRESULT | CProcAmpProperty | CanAutoControl | This method
 *    retrieves the automatic control capabilities for a property.
 *
 *  @rdesc This method returns TRUE if automatic control is supported, FALSE
 *    otherwise.
 ***************************************************************************/
BOOL CProcAmpProperty::CanAutoControl(void)
{
	FX_ENTRY("CProcAmpProperty::CanAutoControl")

	DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: begin", _fx_));

	DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: end", _fx_));

	return m_CapsFlags & VideoProcAmp_Flags_Auto;
}

/****************************************************************************
 *  @doc INTERNAL CPROCAMPPMETHOD
 *
 *  @mfunc HRESULT | CProcAmpProperty | CanAutoControl | This method
 *    retrieves the current automatic control mode of a property.
 *
 *  @rdesc This method returns TRUE if automatic control is supported, FALSE
 *    otherwise.
 ***************************************************************************/
BOOL CProcAmpProperty::GetAuto(void)
{
	FX_ENTRY("CProcAmpProperty::GetAuto")

	DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: begin", _fx_));

	GetValue();

	DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: end", _fx_));

	return m_CurrentFlags & VideoProcAmp_Flags_Auto; 
}

/****************************************************************************
 *  @doc INTERNAL CPROCAMPPMETHOD
 *
 *  @mfunc HRESULT | CProcAmpProperty | SetAuto | This method
 *    sets the automatic control mode of a property.
 *
 *  @parm BOOL | fAuto | Specifies the automatic control mode.
 *
 *  @rdesc This method returns TRUE.
 ***************************************************************************/
BOOL CProcAmpProperty::SetAuto(BOOL fAuto)
{
	FX_ENTRY("CProcAmpProperty::SetAuto")

	DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: begin", _fx_));

	m_CurrentFlags = (fAuto ? VideoProcAmp_Flags_Auto : 0);
	SetValue();

	DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: end", _fx_));

	return TRUE; 
}

/****************************************************************************
 *  @doc INTERNAL CPROCAMPPMETHOD
 *
 *  @mfunc CUnknown* | CProcAmpProperties | CreateInstance | This
 *    method is called by DShow to create an instance of a Network Statistics
 *    Property Page. It is referred to in the global structure <t g_Templates>.
 *
 *  @parm LPUNKNOWN | pUnkOuter | Specifies the outer unknown, if any.
 *
 *  @parm HRESULT* | pHr | Specifies the place in which to put any error return.
 *
 *  @rdesc Returns a pointer to the nondelegating CUnknown portion of the
 *    object, or NULL otherwise.
 ***************************************************************************/
CUnknown* CALLBACK CProcAmpPropertiesCreateInstance(LPUNKNOWN pUnkOuter, HRESULT *pHr) 
{
	CUnknown *pUnknown = (CUnknown *)NULL;

	FX_ENTRY("CProcAmpPropertiesCreateInstance")

	DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: begin", _fx_));

	// Validate input parameters
	ASSERT(pHr);
	if (!pHr)
	{
		DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: invalid input parameter", _fx_));
		goto MyExit;
	}

	if (!(pUnknown = new CProcAmpProperties(pUnkOuter, pHr)))
	{
		*pHr = E_OUTOFMEMORY;
		DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: new CProcAmpProperties failed", _fx_));
	}
	else
	{
		DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s:   SUCCESS: new CProcAmpProperties created", _fx_));
	}

MyExit:
	DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: end", _fx_));
	return pUnknown;
}

/****************************************************************************
 *  @doc INTERNAL CPROCAMPPMETHOD
 *
 *  @mfunc void | CProcAmpProperties | CProcAmpProperties | This
 *    method is the constructor for the property page object. It simply
 *    calls the constructor of the property page base class.
 *
 *  @parm LPUNKNOWN | pUnkOuter | Specifies the outer unknown, if any.
 *
 *  @parm HRESULT* | pHr | Specifies the place in which to put any error return.
 *
 *  @rdesc Nada.
 ***************************************************************************/
CProcAmpProperties::CProcAmpProperties(LPUNKNOWN pUnk, HRESULT *pHr) : CBasePropertyPage(NAME("Video Proc Amp Property Page"), pUnk, IDD_VideoProcAmpProperties, IDS_PROCAMPPROPNAME)
{
	FX_ENTRY("CProcAmpProperties::CProcAmpProperties")

	DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: begin", _fx_));

	m_pIAMVideoProcAmp = NULL;
	m_NumProperties = NUM_PROCAMP_CONTROLS;

	for (int i = 0; i < m_NumProperties; i++)
		m_Controls[i] = NULL;

	DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: end", _fx_));
}

/****************************************************************************
 *  @doc INTERNAL CPROCAMPPMETHOD
 *
 *  @mfunc void | CProcAmpProperties | ~CProcAmpProperties | This
 *    method is the destructor for the video proc amp control property page. It
 *    simply calls the base class destructor after deleting all the controls.
 *
 *  @rdesc Nada.
 ***************************************************************************/
CProcAmpProperties::~CProcAmpProperties()
{
	int		j;

	FX_ENTRY("CProcAmpProperties::~CProcAmpProperties")

	DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: begin", _fx_));

	// Free the controls
	for (j = 0; j < m_NumProperties; j++)
	{
		if (m_Controls[j])
		{
			DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s:   SUCCESS: deleting m_Controls[%ld]=0x%08lX", _fx_, j, m_Controls[j]));
			delete m_Controls[j], m_Controls[j] = NULL;
		}
		else
		{
			DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   WARNING: control already freed", _fx_));
		}
	}

	DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: end", _fx_));
}

/****************************************************************************
 *  @doc INTERNAL CPROCAMPPMETHOD
 *
 *  @mfunc HRESULT | CProcAmpProperties | OnConnect | This
 *    method is called when the property page is connected to the filter.
 *
 *  @parm LPUNKNOWN | pUnknown | Specifies the outer unknown, if any.
 *
 *  @parm HRESULT* | pHr | Specifies the place in which to put any error return.
 *
 *  @rdesc This method returns an HRESULT value that depends on the
 *    implementation of the interface. HRESULT can include one of the
 *    following standard constants, or other values not listed:
 *
 *  @flag E_FAIL | Failure
 *  @flag E_POINTER | Null pointer argument
 *  @flag E_NOTIMPL | Method is not supported
 *  @flag NOERROR | No error
 ***************************************************************************/
HRESULT CProcAmpProperties::OnConnect(IUnknown *pUnk)
{
	HRESULT Hr = NOERROR;

	FX_ENTRY("CProcAmpProperties::OnConnect")

	DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: begin", _fx_));

	// Validate input parameters
	ASSERT(pUnk);
	if (!pUnk)
	{
		DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: invalid input parameter", _fx_));
		Hr = E_POINTER;
		goto MyExit;
	}

	// Get the video proc amp interface
	if (SUCCEEDED (Hr = pUnk->QueryInterface(IID_IAMVideoProcAmp,(void **)&m_pIAMVideoProcAmp)))
	{
		DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s:   SUCCESS: m_pIAMVideoProcAmp=0x%08lX", _fx_, m_pIAMVideoProcAmp));
	}
	else
	{
		m_pIAMVideoProcAmp = NULL;
		DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: IOCTL failed Hr=0x%08lX", _fx_, Hr));
	}

	// It's Ok if we couldn't get interface pointers. We'll just grey the controls in the property page
	// to make it clear to the user that they can't control those properties on the device
	Hr = NOERROR;

MyExit:
	DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: end", _fx_));
	return Hr;
}

/****************************************************************************
 *  @doc INTERNAL CPROCAMPPMETHOD
 *
 *  @mfunc HRESULT | CProcAmpProperties | OnDisconnect | This
 *    method is called when the property page is disconnected from the owning
 *    filter.
 *
 *  @rdesc This method returns an HRESULT value that depends on the
 *    implementation of the interface. HRESULT can include one of the
 *    following standard constants, or other values not listed:
 *
 *  @flag NOERROR | No error
 ***************************************************************************/
HRESULT CProcAmpProperties::OnDisconnect()
{
	FX_ENTRY("CProcAmpProperties::OnDisconnect")

	DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: begin", _fx_));

	// Validate input parameters: we seem to get called several times here
	// Make sure the interface pointer is still valid
	if (!m_pIAMVideoProcAmp)
	{
		DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   WARNING: already disconnected!", _fx_));
	}
	else
	{
		// Release the interface
		m_pIAMVideoProcAmp->Release();
		m_pIAMVideoProcAmp = NULL;
		DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s:   SUCCESS: releasing m_pIAMVideoProcAmp", _fx_));
	}

	DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: end", _fx_));
	return NOERROR;
}

/****************************************************************************
 *  @doc INTERNAL CPROCAMPPMETHOD
 *
 *  @mfunc HRESULT | CProcAmpProperties | OnActivate | This
 *    method is called when the property page is activated.
 *
 *  @rdesc This method returns an HRESULT value that depends on the
 *    implementation of the interface. HRESULT can include one of the
 *    following standard constants, or other values not listed:
 *
 *  @flag E_FAIL | Failure
 *  @flag E_POINTER | Null pointer argument
 *  @flag E_NOTIMPL | Method is not supported
 *  @flag NOERROR | No error
 ***************************************************************************/
HRESULT CProcAmpProperties::OnActivate()
{
	HRESULT	Hr = E_OUTOFMEMORY;
	int		j;

	FX_ENTRY("CProcAmpProperties::OnActivate")

	DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: begin", _fx_));

	// Create the controls for the properties
	if (!(m_Controls[0] = new CProcAmpProperty(m_hwnd, IDC_Brightness_Label, IDC_Brightness_Minimum, IDC_Brightness_Maximum, IDC_Brightness_Default, IDC_Brightness_Stepping, IDC_Brightness_Edit, IDC_Brightness_Slider, 0, VideoProcAmp_Brightness, IDC_Brightness_Auto, m_pIAMVideoProcAmp)))
	{
		DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: mew m_Controls[VideoProcAmp_Brightness] failed - Out of memory", _fx_));
		goto MyExit;
	}
	else
	{
		DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s:   SUCCESS: m_Controls[VideoProcAmp_Brightness]=0x%08lX", _fx_, m_Controls[0]));
	}

	if (!(m_Controls[1] = new CProcAmpProperty(m_hwnd, IDC_Contrast_Label, IDC_Contrast_Minimum, IDC_Contrast_Maximum, IDC_Contrast_Default, IDC_Contrast_Stepping, IDC_Contrast_Edit, IDC_Contrast_Slider, 0, VideoProcAmp_Contrast, IDC_Contrast_Auto, m_pIAMVideoProcAmp)))
	{
		DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: mew m_Controls[VideoProcAmp_Contrast] failed - Out of memory", _fx_));
		goto MyError0;
	}
	else
	{
		DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s:   SUCCESS: m_Controls[VideoProcAmp_Contrast]=0x%08lX", _fx_, m_Controls[1]));
	}

	if (!(m_Controls[2] = new CProcAmpProperty(m_hwnd, IDC_Hue_Label, IDC_Hue_Minimum, IDC_Hue_Maximum, IDC_Hue_Default, IDC_Hue_Stepping, IDC_Hue_Edit, IDC_Hue_Slider, 0, VideoProcAmp_Hue, IDC_Hue_Auto, m_pIAMVideoProcAmp)))
	{
		DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: mew m_Controls[VideoProcAmp_Hue] failed - Out of memory", _fx_));
		goto MyError1;
	}
	else
	{
		DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s:   SUCCESS: m_Controls[VideoProcAmp_Hue]=0x%08lX", _fx_, m_Controls[2]));
	}

	if (!(m_Controls[3] = new CProcAmpProperty(m_hwnd, IDC_Saturation_Label, IDC_Saturation_Minimum, IDC_Saturation_Maximum, IDC_Saturation_Default, IDC_Saturation_Stepping, IDC_Saturation_Edit, IDC_Saturation_Slider, 0, VideoProcAmp_Saturation, IDC_Saturation_Auto, m_pIAMVideoProcAmp)))
	{
		DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: mew m_Controls[VideoProcAmp_Saturation] failed - Out of memory", _fx_));
		goto MyError2;
	}
	else
	{
		DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s:   SUCCESS: m_Controls[VideoProcAmp_Saturation]=0x%08lX", _fx_, m_Controls[3]));
	}

	if (!(m_Controls[4] = new CProcAmpProperty(m_hwnd, IDC_Sharpness_Label, IDC_Sharpness_Minimum, IDC_Sharpness_Maximum, IDC_Sharpness_Default, IDC_Sharpness_Stepping, IDC_Sharpness_Edit, IDC_Sharpness_Slider, 0, VideoProcAmp_Sharpness, IDC_Sharpness_Auto, m_pIAMVideoProcAmp)))
	{
		DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: mew m_Controls[VideoProcAmp_Sharpness] failed - Out of memory", _fx_));
		goto MyError3;
	}
	else
	{
		DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s:   SUCCESS: m_Controls[VideoProcAmp_Sharpness]=0x%08lX", _fx_, m_Controls[4]));
	}

	if (!(m_Controls[5] = new CProcAmpProperty(m_hwnd, IDC_Gamma_Label, IDC_Gamma_Minimum, IDC_Gamma_Maximum, IDC_Gamma_Default, IDC_Gamma_Stepping, IDC_Gamma_Edit, IDC_Gamma_Slider, 0, VideoProcAmp_Gamma, IDC_Gamma_Auto, m_pIAMVideoProcAmp)))
	{
		DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: mew m_Controls[VideoProcAmp_Gamma] failed - Out of memory", _fx_));
		goto MyError4;
	}
	else
	{
		DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s:   SUCCESS: m_Controls[VideoProcAmp_Gamma]=0x%08lX", _fx_, m_Controls[5]));
	}

	if (!(m_Controls[6] = new CProcAmpProperty(m_hwnd, IDC_ColorEnable_Label, IDC_ColorEnable_Minimum, IDC_ColorEnable_Maximum, IDC_ColorEnable_Default, IDC_ColorEnable_Stepping, IDC_ColorEnable_Edit, IDC_ColorEnable_Slider, 0, VideoProcAmp_ColorEnable, IDC_ColorEnable_Auto, m_pIAMVideoProcAmp)))
	{
		DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: mew m_Controls[VideoProcAmp_ColorEnable] failed - Out of memory", _fx_));
		goto MyError5;
	}
	else
	{
		DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s:   SUCCESS: m_Controls[VideoProcAmp_ColorEnable]=0x%08lX", _fx_, m_Controls[6]));
	}

	if (!(m_Controls[7] = new CProcAmpProperty(m_hwnd, IDC_WhiteBalance_Label, IDC_WhiteBalance_Minimum, IDC_WhiteBalance_Maximum, IDC_WhiteBalance_Default, IDC_WhiteBalance_Stepping, IDC_WhiteBalance_Edit, IDC_WhiteBalance_Slider, 0, VideoProcAmp_WhiteBalance, IDC_WhiteBalance_Auto, m_pIAMVideoProcAmp)))
	{
		DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: mew m_Controls[VideoProcAmp_WhiteBalance] failed - Out of memory", _fx_));
		goto MyError5;
	}
	else
	{
		DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s:   SUCCESS: m_Controls[VideoProcAmp_WhiteBalance]=0x%08lX", _fx_, m_Controls[6]));
	}

	if (!(m_Controls[8] = new CProcAmpProperty(m_hwnd, IDC_BacklightComp_Label, IDC_BacklightComp_Minimum, IDC_BacklightComp_Maximum, IDC_BacklightComp_Default, IDC_BacklightComp_Stepping, IDC_BacklightComp_Edit, IDC_BacklightComp_Slider, 0, VideoProcAmp_BacklightCompensation, IDC_BacklightComp_Auto, m_pIAMVideoProcAmp)))
	{
		DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: mew m_Controls[VideoProcAmp_BacklightComp] failed - Out of memory", _fx_));
		goto MyError5;
	}
	else
	{
		DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s:   SUCCESS: m_Controls[VideoProcAmp_BacklightComp]=0x%08lX", _fx_, m_Controls[6]));
	}

	// Initialize all the controls. If the initialization fails, it's Ok. It just means
	// that the TAPI control interface isn't implemented by the device. The dialog item
	// in the property page will be greyed, showing this to the user.
	for (j = 0; j < m_NumProperties; j++)
	{
		if (m_Controls[j]->Init())
		{
			DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s:   SUCCESS: m_Controls[%ld]->Init()", _fx_, j));
		}
		else
		{
			DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   WARNING: m_Controls[%ld]->Init() failed", _fx_, j));
		}
	}

	Hr = NOERROR;
	goto MyExit;

MyError5:
	if (m_Controls[5])
		delete m_Controls[5], m_Controls[5] = NULL;
MyError4:
	if (m_Controls[4])
		delete m_Controls[4], m_Controls[4] = NULL;
MyError3:
	if (m_Controls[3])
		delete m_Controls[3], m_Controls[3] = NULL;
MyError2:
	if (m_Controls[2])
		delete m_Controls[2], m_Controls[2] = NULL;
MyError1:
	if (m_Controls[1])
		delete m_Controls[1], m_Controls[1] = NULL;
MyError0:
	if (m_Controls[0])
		delete m_Controls[0], m_Controls[0] = NULL;
MyExit:
	DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: end", _fx_));
	return Hr;
}

/****************************************************************************
 *  @doc INTERNAL CPROCAMPPMETHOD
 *
 *  @mfunc HRESULT | CProcAmpProperties | OnDeactivate | This
 *    method is called when the property page is dismissed.
 *
 *  @rdesc This method returns an HRESULT value that depends on the
 *    implementation of the interface. HRESULT can include one of the
 *    following standard constants, or other values not listed:
 *
 *  @flag NOERROR | No error
 ***************************************************************************/
HRESULT CProcAmpProperties::OnDeactivate()
{
	int		j;

	FX_ENTRY("CProcAmpProperties::OnDeactivate")

	DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: begin", _fx_));

	// Free the controls
	for (j = 0; j < m_NumProperties; j++)
	{
		if (m_Controls[j])
		{
			DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s:   SUCCESS: deleting m_Controls[%ld]=0x%08lX", _fx_, j, m_Controls[j]));
			delete m_Controls[j], m_Controls[j] = NULL;
		}
		else
		{
			DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   WARNING: control already freed", _fx_));
		}
	}

	DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: end", _fx_));
	return NOERROR;
}

/****************************************************************************
 *  @doc INTERNAL CPROCAMPPMETHOD
 *
 *  @mfunc HRESULT | CProcAmpProperties | OnApplyChanges | This
 *    method is called when the user applies changes to the property page.
 *
 *  @rdesc This method returns an HRESULT value that depends on the
 *    implementation of the interface. HRESULT can include one of the
 *    following standard constants, or other values not listed:
 *
 *  @flag E_FAIL | Failure
 *  @flag E_POINTER | Null pointer argument
 *  @flag E_NOTIMPL | Method is not supported
 *  @flag NOERROR | No error
 ***************************************************************************/
HRESULT CProcAmpProperties::OnApplyChanges()
{
	HRESULT	Hr = NOERROR;

	FX_ENTRY("CProcAmpProperties::OnApplyChanges")

	DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: begin", _fx_));

	for (int j = 0; j < m_NumProperties; j++)
	{
		ASSERT(m_Controls[j]);
		if (m_Controls[j])
		{
			if (m_Controls[j]->HasChanged())
			{
				DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s:   SUCCESS: calling m_Controls[%ld]=0x%08lX->OnApply", _fx_, j, m_Controls[j]));
				m_Controls[j]->OnApply();
			}
		}
		else
		{
			DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: can't call m_Controls[%ld]=NULL->OnApply", _fx_, j));
			Hr = E_UNEXPECTED;
			break;
		}
	}

	DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: end", _fx_));
	return Hr;
}

/****************************************************************************
 *  @doc INTERNAL CPROCAMPPMETHOD
 *
 *  @mfunc BOOL | CProcAmpProperties | OnReceiveMessage | This
 *    method is called when a message is sent to the property page dialog box.
 *
 *  @rdesc By default, returns the value returned by the Win32 DefWindowProc function.
 ***************************************************************************/
BOOL CProcAmpProperties::OnReceiveMessage(HWND hWnd, UINT uMsg, WPARAM wParam, LPARAM lParam) 
{
	int iNotify = HIWORD (wParam);
	int j;

	switch (uMsg)
	{
		case WM_INITDIALOG:
			return TRUE; // Don't call setfocus

		case WM_HSCROLL:
		case WM_VSCROLL:
			// Process all of the Trackbar messages
			for (j = 0; j < m_NumProperties; j++)
			{
				ASSERT(m_Controls[j]);
				if (m_Controls[j]->GetTrackbarHWnd() == (HWND)lParam)
				{
					m_Controls[j]->OnScroll(uMsg, wParam, lParam);
					SetDirty();
				}
			}
			OnApplyChanges();
			break;

		case WM_COMMAND:

			// This message gets sent even before OnActivate() has been
			// called(!). We need to test and make sure the controls have
			// beeen initialized before we can use them.

			// Process all of the auto checkbox messages
			for (j = 0; j < m_NumProperties; j++)
			{
				if (m_Controls[j] && m_Controls[j]->GetAutoHWnd() == (HWND)lParam)
				{
					m_Controls[j]->OnAuto(uMsg, wParam, lParam);
					SetDirty();
					break;
				}
			}

			// Process all of the edit box messages
			for (j = 0; j < m_NumProperties; j++)
			{
				if (m_Controls[j] && m_Controls[j]->GetEditHWnd() == (HWND)lParam)
				{
					m_Controls[j]->OnEdit(uMsg, wParam, lParam);
					SetDirty();
					break;
				}
			}

			switch (LOWORD(wParam))
			{
				case IDC_CONTROL_DEFAULT:
					for (j = 0; j < m_NumProperties; j++)
					{
						if (m_Controls[j])
							m_Controls[j]->OnDefault();
					}
					break;

				default:
					break;
			}

			OnApplyChanges();
			break;

		default:
			return FALSE;
	}

	return TRUE;
}

/****************************************************************************
 *  @doc INTERNAL CPROCAMPPMETHOD
 *
 *  @mfunc BOOL | CProcAmpProperties | SetDirty | This
 *    method notifies the property page site of changes.
 *
 *  @rdesc Nada.
 ***************************************************************************/
void CProcAmpProperties::SetDirty()
{
	m_bDirty = TRUE;
	if (m_pPageSite)
		m_pPageSite->OnStatusChange(PROPPAGESTATUS_DIRTY);
}

#endif
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\net\tapi\skywalker\filters\video\tapivcap\previewp.cpp ===
/****************************************************************************
 *  @doc INTERNAL PREVIEWP
 *
 *  @module PreviewP.cpp | Source file for the <c CPreviewProperty>
 *    class used to implement a property page to test the new TAPI internal
 *    interface <i IFrameRateControl> and dynamic format changes.
 *
 *  @comm This code tests the TAPI VfW Preview Pin <i IFrameRateControl>,
 *    and dynamic format change implementation. This code is only compiled
 *    if USE_PROPERTY_PAGES is defined.
 ***************************************************************************/

#include "Precomp.h"

#if 0 // remove later.
// Video subtypes
EXTERN_C const GUID MEDIASUBTYPE_H263_V1;
EXTERN_C const GUID MEDIASUBTYPE_H263_V2;
EXTERN_C const GUID MEDIASUBTYPE_H261;
EXTERN_C const GUID MEDIASUBTYPE_I420;
EXTERN_C const GUID MEDIASUBTYPE_IYUV;
#endif

#ifdef USE_PROPERTY_PAGES

/****************************************************************************
 *  @doc INTERNAL CPREVIEWPMETHOD
 *
 *  @mfunc void | CPreviewProperty | CPreviewProperty | This
 *    method is the constructor for frame rate property objects. It
 *    calls the base class constructor, calls InitCommonControlsEx, and saves
 *    pointers to the <i IFrameRateControl> and <i IVideoControl> interfaces.
 *
 *  @parm HWND | hDlg | Specifies a handle to the parent property page.
 *
 *  @parm ULONG | IDLabel | Specifies a label ID for the property.
 *
 *  @parm ULONG | IDMinControl | Specifies a label ID for the associated
 *    property edit control where the Minimum value of the property appears.
 *
 *  @parm ULONG | IDMaxControl | Specifies a label ID for the associated
 *    property edit control where the Maximum value of the property appears.
 *
 *  @parm ULONG | IDDefaultControl | Specifies a label ID for the associated
 *    property edit control where the Default value of the property appears.
 *
 *  @parm ULONG | IDStepControl | Specifies a label ID for the associated
 *    property edit control where the Stepping Delta value of the property appears.
 *
 *  @parm ULONG | IDEditControl | Specifies a label ID for the associated
 *    property edit control where the value of the property appears.
 *
 *  @parm ULONG | IDTrackbarControl | Specifies a label ID for the associated
 *    property slide bar.
 *
 *  @parm ULONG | IDProgressControl | Specifies a label ID for the associated
 *    property slide bar.
 *
 *  @parm ULONG | IDProperty | Specifies the ID of the Ks property.
 *
 *  @parm IFrameRateControl* | pIFrameRateControl | Specifies a pointer to the
 *    <i IFrameRateControl> interface.
 *
 *  @rdesc Nada.
 ***************************************************************************/
CPreviewProperty::CPreviewProperty(HWND hDlg, ULONG IDLabel, ULONG IDMinControl, ULONG IDMaxControl, ULONG IDDefaultControl, ULONG IDStepControl, ULONG IDEditControl, ULONG IDTrackbarControl, ULONG IDProgressControl, ULONG IDProperty, IFrameRateControl *pIFrameRateControl, IVideoControl *pIVideoControl)
: CPropertyEditor(hDlg, IDLabel, IDMinControl, IDMaxControl, IDDefaultControl, IDStepControl, IDEditControl, IDTrackbarControl, IDProgressControl, IDProperty, 0)
{
	INITCOMMONCONTROLSEX cc;

	FX_ENTRY("CPreviewProperty::CPreviewProperty")

	DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: begin", _fx_));

	cc.dwSize = sizeof (INITCOMMONCONTROLSEX);
	cc.dwICC  = ICC_UPDOWN_CLASS | ICC_BAR_CLASSES;

	InitCommonControlsEx(&cc);

	// It's fine if the interface pointers are NULL, we'll grey the
	// associated items in the property page
	m_pIFrameRateControl = pIFrameRateControl;
	m_pIVideoControl = pIVideoControl;

	DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: end", _fx_));
}

/****************************************************************************
 *  @doc INTERNAL CPREVIEWPMETHOD
 *
 *  @mfunc void | CPreviewProperty | ~CPreviewProperty | This
 *    method is the destructor for preview property objects. It
 *    simply calls the base class destructor.
 *
 *  @rdesc Nada.
 ***************************************************************************/
CPreviewProperty::~CPreviewProperty()
{
	FX_ENTRY("CPreviewProperty::~CPreviewProperty")

	DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: begin", _fx_));

	DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: end", _fx_));
}

/****************************************************************************
 *  @doc INTERNAL CPREVIEWPMETHOD
 *
 *  @mfunc HRESULT | CPreviewProperty | GetValue | This method queries for
 *    the value of a property.
 *
 *  @rdesc This method returns an HRESULT value that depends on the
 *    implementation of the interface. HRESULT can include one of the
 *    following standard constants, or other values not listed:
 *
 *  @flag E_FAIL | Failure
 *  @flag E_POINTER | Null pointer argument
 *  @flag E_NOTIMPL | Method is not supported
 *  @flag NOERROR | No error
 ***************************************************************************/
HRESULT CPreviewProperty::GetValue()
{
	HRESULT Hr = E_NOTIMPL;
	LONG CurrentValue;
	LONG Mode;

	FX_ENTRY("CPreviewProperty::GetValue")

	DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: begin", _fx_));

	switch (m_IDProperty)
	{									
		case IDC_Preview_FrameRate:
			if (m_pIFrameRateControl && SUCCEEDED (Hr = m_pIFrameRateControl->Get(FrameRateControl_Maximum, &CurrentValue, (TAPIControlFlags *)&m_CurrentFlags)))
			{
				if (CurrentValue)
					m_CurrentValue = (LONG)(10000000 / CurrentValue);
				else
					m_CurrentValue = 0;
				DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s:   SUCCESS: *pAvgTimePerFrame=%ld", _fx_, CurrentValue));
			}
			else
			{
				DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: Failed Hr=0x%08lX", _fx_, Hr));
			}
			break;
		case IDC_Preview_CurrentFrameRate:
			if (m_pIFrameRateControl && SUCCEEDED (Hr = m_pIFrameRateControl->Get(FrameRateControl_Current, &CurrentValue, (TAPIControlFlags *)&m_CurrentFlags)))
			{
				if (CurrentValue)
					m_CurrentValue = (LONG)((10000000 + (CurrentValue / 2)) / CurrentValue);
				else
					m_CurrentValue = 0;
				DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s:   SUCCESS: *pAvgTimePerFrame=%ld", _fx_, CurrentValue));
			}
			else
			{
				DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: Failed Hr=0x%08lX", _fx_, Hr));
			}
			break;
		case IDC_Preview_FlipVertical:
			if (m_pIVideoControl && SUCCEEDED (Hr = m_pIVideoControl->GetMode(&Mode)))
			{
				// We have to be between 0 and 1
				m_CurrentValue = Mode & VideoControlFlag_FlipVertical ? TRUE : FALSE;
				DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s:   SUCCESS: Vertical flip is %s"), _fx_, m_CurrentValue ? "ON" : "OFF");
			}
			else
			{
				DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: Failed Hr=0x%08lX", _fx_, Hr));
			}
			break;
		case IDC_Preview_FlipHorizontal:
			if (m_pIVideoControl && SUCCEEDED (Hr = m_pIVideoControl->GetMode(&Mode)))
			{
				// We have to be between 0 and 1
				m_CurrentValue = Mode & VideoControlFlag_FlipHorizontal ? TRUE : FALSE;
				DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s:   SUCCESS: Horizontal flip is %s"), _fx_, m_CurrentValue ? "ON" : "OFF");
			}
			else
			{
				DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: Failed Hr=0x%08lX", _fx_, Hr));
			}
			break;
		default:
			Hr = E_UNEXPECTED;
			DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: Unknown preview property", _fx_));
	}

	DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: end", _fx_));
	return Hr;
}

/****************************************************************************
 *  @doc INTERNAL CPREVIEWPMETHOD
 *
 *  @mfunc HRESULT | CPreviewProperty | SetValue | This method sets the
 *    value of a property.
 *
 *  @rdesc This method returns an HRESULT value that depends on the
 *    implementation of the interface. HRESULT can include one of the
 *    following standard constants, or other values not listed:
 *
 *  @flag E_FAIL | Failure
 *  @flag E_POINTER | Null pointer argument
 *  @flag E_NOTIMPL | Method is not supported
 *  @flag NOERROR | No error
 ***************************************************************************/
HRESULT CPreviewProperty::SetValue()
{
	HRESULT Hr = E_NOTIMPL;
	LONG CurrentValue;
	LONG Mode;

	FX_ENTRY("CPreviewProperty::SetValue")

	DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: begin", _fx_));

	switch (m_IDProperty)
	{
		case IDC_Preview_FrameRate:
			if (m_CurrentValue)
				CurrentValue = 10000000L / m_CurrentValue;
			if (m_pIFrameRateControl && SUCCEEDED (Hr = m_pIFrameRateControl->Set(FrameRateControl_Maximum, CurrentValue, (TAPIControlFlags)m_CurrentFlags)))
			{
				DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s:   SUCCESS: AvgTimePerFrame=%ld", _fx_, CurrentValue));
			}
			else
			{
				DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: Failed Hr=0x%08lX", _fx_, Hr));
			}
			break;
		case IDC_Preview_FlipVertical:
			if (m_pIVideoControl && SUCCEEDED (Hr = m_pIVideoControl->GetMode(&Mode)))
			{
				if (m_CurrentValue)
					Mode |= VideoControlFlag_FlipVertical;
				else
					Mode &= !VideoControlFlag_FlipVertical;
				if (SUCCEEDED (Hr = m_pIVideoControl->SetMode(Mode)))
				{
					DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s:   SUCCESS: Vertical flip is %s"), _fx_, m_CurrentValue ? "ON" : "OFF");
				}
				else
				{
					DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: Failed Hr=0x%08lX", _fx_, Hr));
				}
			}
			else
			{
				DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: Failed Hr=0x%08lX", _fx_, Hr));
			}
			break;
		case IDC_Preview_FlipHorizontal:
			if (m_pIVideoControl && SUCCEEDED (Hr = m_pIVideoControl->GetMode(&Mode)))
			{
				if (m_CurrentValue)
					Mode |= VideoControlFlag_FlipHorizontal;
				else
					Mode &= !VideoControlFlag_FlipHorizontal;
				if (SUCCEEDED (Hr = m_pIVideoControl->SetMode(Mode)))
				{
					DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s:   SUCCESS: Horizontal flip is %s"), _fx_, m_CurrentValue ? "ON" : "OFF");
				}
				else
				{
					DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: Failed Hr=0x%08lX", _fx_, Hr));
				}
			}
			else
			{
				DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: Failed Hr=0x%08lX", _fx_, Hr));
			}
			break;
		case IDC_Preview_CurrentFrameRate:
			// This is a read-only property. Don't do anything.
			Hr = NOERROR;
			break;
		default:
			Hr = E_UNEXPECTED;
			DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: Unknown preview property", _fx_));
	}

	DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: end", _fx_));
	return Hr;
}

/****************************************************************************
 *  @doc INTERNAL CPREVIEWPMETHOD
 *
 *  @mfunc HRESULT | CPreviewProperty | GetRange | This method retrieves
 *    the range information of a property.
 *
 *  @rdesc This method returns an HRESULT value that depends on the
 *    implementation of the interface. HRESULT can include one of the
 *    following standard constants, or other values not listed:
 *
 *  @flag E_FAIL | Failure
 *  @flag E_POINTER | Null pointer argument
 *  @flag E_NOTIMPL | Method is not supported
 *  @flag NOERROR | No error
 ***************************************************************************/
HRESULT CPreviewProperty::GetRange()
{
	HRESULT Hr = E_NOTIMPL;
	LONG Min;
	LONG Max;
	LONG SteppingDelta;
	LONG Default;

	FX_ENTRY("CPreviewProperty::GetRange")

	DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: begin", _fx_));

	switch (m_IDProperty)
	{
		case IDC_Preview_FrameRate:
			if (m_pIFrameRateControl && SUCCEEDED (Hr = m_pIFrameRateControl->GetRange(FrameRateControl_Maximum, &Min, &Max, &SteppingDelta, &Default, (TAPIControlFlags *)&m_CapsFlags)))
			{
				if (Min)
					m_Max = (LONG)(10000000 / Min);
				else
					m_Max = 0;
				if (Max)
					m_Min = (LONG)(10000000 / Max);
				else
					m_Min = 0;
				if (SteppingDelta)
					m_SteppingDelta = (m_Max - m_Min) / (LONG)((Max - Min) / SteppingDelta);
				else
					m_SteppingDelta = 0;
				if (Default)
					m_DefaultValue = (LONG)(10000000 / Default);
				else
					m_DefaultValue = 0;
				DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s:   SUCCESS: *pMin=%ld, *pMax=%ld, *pSteppingDelta=%ld, *pDefault=%ld", _fx_, Min, Max, SteppingDelta, Default));
			}
			else
			{
				DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: Failed Hr=0x%08lX", _fx_, Hr));
			}
			break;
		case IDC_Preview_CurrentFrameRate:
			if (m_pIFrameRateControl && SUCCEEDED (Hr = m_pIFrameRateControl->GetRange(FrameRateControl_Current, &Min, &Max, &SteppingDelta, &Default, (TAPIControlFlags *)&m_CapsFlags)))
			{
				if (Min)
					m_Max = (LONG)(10000000 / Min);
				else
					m_Max = 0;
				if (Max)
					m_Min = (LONG)(10000000 / Max);
				else
					m_Min = 0;
				if (SteppingDelta)
					m_SteppingDelta = (LONG)(10000000 / SteppingDelta);
				else
					m_SteppingDelta = 0;
				if (Default)
					m_DefaultValue = (LONG)(10000000 / Default);
				else
					m_DefaultValue = 0;
				DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s:   SUCCESS: *pMin=%ld, *pMax=%ld, *pSteppingDelta=%ld, *pDefault=%ld", _fx_, Min, Max, SteppingDelta, Default));
			}
			else
			{
				DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: Failed Hr=0x%08lX", _fx_, Hr));
			}
			break;
		case IDC_Preview_FlipVertical:
		case IDC_Preview_FlipHorizontal:
			m_DefaultValue = m_CurrentValue;
			m_Min = 0;
			m_Max = 1;
			m_SteppingDelta = 1;
			Hr = NOERROR;
			break;
		default:
			Hr = E_UNEXPECTED;
			DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: Unknown preview property", _fx_));
	}

	DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: end", _fx_));
	return Hr;
}

/****************************************************************************
 *  @doc INTERNAL CPREVIEWPMETHOD
 *
 *  @mfunc HRESULT | CPreviewProperty | CanAutoControl | This method
 *    retrieves the automatic control capabilities for a property.
 *
 *  @rdesc This method returns TRUE if automatic control is supported, FALSE
 *    otherwise.
 ***************************************************************************/
BOOL CPreviewProperty::CanAutoControl(void)
{
	FX_ENTRY("CPreviewProperty::CanAutoControl")

	DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: begin", _fx_));

	DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: end", _fx_));

	return FALSE;
}

/****************************************************************************
 *  @doc INTERNAL CPREVIEWPMETHOD
 *
 *  @mfunc HRESULT | CPreviewProperty | GetAuto | This method
 *    retrieves the current automatic control mode of a property.
 *
 *  @rdesc This method returns TRUE if automatic control is supported, FALSE
 *    otherwise.
 ***************************************************************************/
BOOL CPreviewProperty::GetAuto(void)
{
	FX_ENTRY("CPreviewProperty::GetAuto")

	DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: begin", _fx_));

	DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: end", _fx_));

	return FALSE; 
}

/****************************************************************************
 *  @doc INTERNAL CPREVIEWPMETHOD
 *
 *  @mfunc HRESULT | CPreviewProperty | SetAuto | This method
 *    sets the automatic control mode of a property.
 *
 *  @parm BOOL | fAuto | Specifies the automatic control mode.
 *
 *  @rdesc This method returns TRUE.
 ***************************************************************************/
BOOL CPreviewProperty::SetAuto(BOOL fAuto)
{
	FX_ENTRY("CPreviewProperty::SetAuto")

	DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: begin", _fx_));

	DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: end", _fx_));

	return TRUE; 
}

/****************************************************************************
 *  @doc INTERNAL CPREVIEWPMETHOD
 *
 *  @mfunc CUnknown* | CPreviewProperties | CreateInstance | This
 *    method is called by DShow to create an instance of a TAPI Preview Pin
 *    Property Page. It is referred to in the global structure <t g_Templates>.
 *
 *  @parm LPUNKNOWN | pUnkOuter | Specifies the outer unknown, if any.
 *
 *  @parm HRESULT* | pHr | Specifies the place in which to put any error return.
 *
 *  @rdesc Returns a pointer to the nondelegating CUnknown portion of the
 *    object, or NULL otherwise.
 ***************************************************************************/
CUnknown* CALLBACK CPreviewPropertiesCreateInstance(LPUNKNOWN pUnkOuter, HRESULT *pHr) 
{
	CUnknown *pUnknown = (CUnknown *)NULL;

	FX_ENTRY("CPreviewPropertiesCreateInstance")

	DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: begin", _fx_));

	// Validate input parameters
	ASSERT(pHr);
	if (!pHr)
	{
		DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: invalid input parameter", _fx_));
		goto MyExit;
	}

	if (!(pUnknown = new CPreviewProperties(pUnkOuter, pHr)))
	{
		*pHr = E_OUTOFMEMORY;
		DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: new CPreviewProperties failed", _fx_));
	}
	else
	{
		DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s:   SUCCESS: new CPreviewProperties created", _fx_));
	}

MyExit:
	DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: end", _fx_));
	return pUnknown;
}

/****************************************************************************
 *  @doc INTERNAL CPREVIEWPMETHOD
 *
 *  @mfunc void | CPreviewProperties | CPreviewProperties | This
 *    method is the constructor for the property page object. It simply
 *    calls the constructor of the property page base class.
 *
 *  @parm LPUNKNOWN | pUnkOuter | Specifies the outer unknown, if any.
 *
 *  @parm HRESULT* | pHr | Specifies the place in which to put any error return.
 *
 *  @rdesc Nada.
 ***************************************************************************/
CPreviewProperties::CPreviewProperties(LPUNKNOWN pUnk, HRESULT *pHr) : CBasePropertyPage(NAME("TAPI Preview Pin Property Page"), pUnk, IDD_PreviewFormatProperties, IDS_PREVIEWFORMATSPROPNAME)
{
	FX_ENTRY("CPreviewProperties::CPreviewProperties")

	DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: begin", _fx_));

	m_pIFrameRateControl = NULL;
	m_pIAMStreamConfig = NULL;
	m_pIVideoControl = NULL;
	m_NumProperties = NUM_PREVIEW_CONTROLS;
	m_fActivated = FALSE;
	m_hWndFormat = m_hWnd = NULL;
	m_RangeCount = 0;
	m_SubTypeList = NULL;
	m_FrameSizeList = NULL;
	m_CurrentMediaType = NULL;
	m_CurrentFormat = 0;
	m_OriginalFormat = 0;

	for (int i = 0; i < m_NumProperties; i++)
		m_Controls[i] = NULL;

	DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: end", _fx_));
}

/****************************************************************************
 *  @doc INTERNAL CPREVIEWPMETHOD
 *
 *  @mfunc void | CPreviewProperties | ~CPreviewProperties | This
 *    method is the destructor for the preview pin property page. It
 *    simply calls the base class destructor after deleting all the controls.
 *
 *  @rdesc Nada.
 ***************************************************************************/
CPreviewProperties::~CPreviewProperties()
{
	int		j;

	FX_ENTRY("CPreviewProperties::~CPreviewProperties")

	DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: begin", _fx_));

	// Free the controls
	for (j = 0; j < m_NumProperties; j++)
	{
		if (m_Controls[j])
		{
			DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s:   SUCCESS: deleting m_Controls[%ld]=0x%08lX", _fx_, j, m_Controls[j]));
			delete m_Controls[j], m_Controls[j] = NULL;
		}
		else
		{
			DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   WARNING: control already freed", _fx_));
		}
	}

	DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: end", _fx_));
}

/****************************************************************************
 *  @doc INTERNAL CPREVIEWPMETHOD
 *
 *  @mfunc HRESULT | CPreviewProperties | OnConnect | This
 *    method is called when the property page is connected to the filter.
 *
 *  @parm LPUNKNOWN | pUnknown | Specifies the outer unknown, if any.
 *
 *  @parm HRESULT* | pHr | Specifies the place in which to put any error return.
 *
 *  @rdesc This method returns an HRESULT value that depends on the
 *    implementation of the interface. HRESULT can include one of the
 *    following standard constants, or other values not listed:
 *
 *  @flag E_FAIL | Failure
 *  @flag E_POINTER | Null pointer argument
 *  @flag E_NOTIMPL | Method is not supported
 *  @flag NOERROR | No error
 ***************************************************************************/
HRESULT CPreviewProperties::OnConnect(IUnknown *pUnk)
{
	HRESULT Hr = NOERROR;

	FX_ENTRY("CPreviewProperties::OnConnect")

	DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: begin", _fx_));

	// Validate input parameters
	ASSERT(pUnk);
	if (!pUnk)
	{
		DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: invalid input parameter", _fx_));
		Hr = E_POINTER;
		goto MyExit;
	}

	// Get the frame rate control interface
	if (SUCCEEDED (Hr = pUnk->QueryInterface(__uuidof(IFrameRateControl), (void **)&m_pIFrameRateControl)))
	{
		DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s:   SUCCESS: m_pIFrameRateControl=0x%08lX", _fx_, m_pIFrameRateControl));
	}
	else
	{
		m_pIFrameRateControl = NULL;
		DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: Failed Hr=0x%08lX", _fx_, Hr));
	}

	// Get the format control interface
	if (SUCCEEDED (Hr = pUnk->QueryInterface(IID_IAMStreamConfig, (void **)&m_pIAMStreamConfig)))
	{
		DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s:   SUCCESS: m_pIAMStreamConfig=0x%08lX", _fx_, m_pIAMStreamConfig));
	}
	else
	{
		m_pIAMStreamConfig = NULL;
		DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: Failed Hr=0x%08lX", _fx_, Hr));
	}

	// Get the video control interface
	if (SUCCEEDED (Hr = pUnk->QueryInterface(__uuidof(IVideoControl), (void **)&m_pIVideoControl)))
	{
		DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s:   SUCCESS: m_pIVideoControl=0x%08lX", _fx_, m_pIVideoControl));
	}
	else
	{
		m_pIVideoControl = NULL;
		DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: Failed Hr=0x%08lX", _fx_, Hr));
	}

	// It's Ok if we couldn't get interface pointers
	// We'll just grey the controls in the property page
	// to make it clear to the user that they can't
	// control those properties on the capture device
	Hr = NOERROR;

MyExit:
	DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: end", _fx_));
	return Hr;
}

/****************************************************************************
 *  @doc INTERNAL CPREVIEWPMETHOD
 *
 *  @mfunc HRESULT | CPreviewProperties | OnDisconnect | This
 *    method is called when the property page is disconnected from the owning
 *    filter.
 *
 *  @rdesc This method returns an HRESULT value that depends on the
 *    implementation of the interface. HRESULT can include one of the
 *    following standard constants, or other values not listed:
 *
 *  @flag NOERROR | No error
 ***************************************************************************/
HRESULT CPreviewProperties::OnDisconnect()
{
	FX_ENTRY("CPreviewProperties::OnDisconnect")

	DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: begin", _fx_));

	// Validate input parameters: we seem to get called several times here
	// Make sure the interface pointer is still valid
	if (!m_pIFrameRateControl)
	{
		DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   WARNING: already disconnected!", _fx_));
	}
	else
	{
		// Release the interface
		m_pIFrameRateControl->Release();
		m_pIFrameRateControl = NULL;
		DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s:   SUCCESS: releasing m_pIFrameRateControl", _fx_));
	}

	if (!m_pIAMStreamConfig)
	{
		DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   WARNING: already disconnected!", _fx_));
	}
	else
	{
		// Release the interface
		m_pIAMStreamConfig->Release();
		m_pIAMStreamConfig = NULL;
		DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s:   SUCCESS: releasing m_pIAMStreamConfig", _fx_));
	}

	if (!m_pIVideoControl)
	{
		DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   WARNING: already disconnected!", _fx_));
	}
	else
	{
		// Release the interface
		m_pIVideoControl->Release();
		m_pIVideoControl = NULL;
		DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s:   SUCCESS: releasing m_pIVideoControl", _fx_));
	}

	// Release format memory
	if (m_CurrentMediaType)
	{
		DeleteMediaType(m_CurrentMediaType);
		m_CurrentMediaType = NULL;
	}

	DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: end", _fx_));
	return NOERROR;
}

/****************************************************************************
 *  @doc INTERNAL CPREVIEWPMETHOD
 *
 *  @mfunc HRESULT | CPreviewProperties | OnActivate | This
 *    method is called when the property page is activated.
 *
 *  @rdesc This method returns an HRESULT value that depends on the
 *    implementation of the interface. HRESULT can include one of the
 *    following standard constants, or other values not listed:
 *
 *  @flag E_FAIL | Failure
 *  @flag E_POINTER | Null pointer argument
 *  @flag E_NOTIMPL | Method is not supported
 *  @flag NOERROR | No error
 ***************************************************************************/
HRESULT CPreviewProperties::OnActivate()
{
	HRESULT	Hr = NOERROR;
	int		j;
	TCHAR	buf[32];

	FX_ENTRY("CPreviewProperties::OnActivate")

	DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: begin", _fx_));

	// Initialize format control structures
	m_hWndFormat = GetDlgItem(m_hWnd, IDC_FORMAT_Compression);

	// Disable everything if we didn't initialize correctly
	if (!m_pIAMStreamConfig || (FAILED (Hr = InitialRangeScan())))
	{
		EnableWindow(m_hWndFormat, FALSE);
	}
	else
	{
		// Update the content of the format combo box
		ComboBox_ResetContent(m_hWndFormat);
		for (j = 0; j < m_RangeCount; j++)
		{
			if (IsEqualGUID(m_SubTypeList[j], MEDIASUBTYPE_H263_V1))
				wsprintf (buf, "%s %ldx%ld", "H.263", m_FrameSizeList[j].cx, m_FrameSizeList[j].cy);
			else if (IsEqualGUID (m_SubTypeList[j], MEDIASUBTYPE_H263_V2))
				wsprintf (buf, "%s %ldx%ld", "H.263+", m_FrameSizeList[j].cx, m_FrameSizeList[j].cy);
			else if (IsEqualGUID (m_SubTypeList[j], MEDIASUBTYPE_H261))
				wsprintf (buf, "%s %ldx%ld", "H.261", m_FrameSizeList[j].cx, m_FrameSizeList[j].cy);
			else if (IsEqualGUID (m_SubTypeList[j], MEDIASUBTYPE_YVU9))
				wsprintf (buf, "%s %ldx%ld", "YVU9", m_FrameSizeList[j].cx, m_FrameSizeList[j].cy);
			else if (IsEqualGUID (m_SubTypeList[j], MEDIASUBTYPE_YUY2))
				wsprintf (buf, "%s %ldx%ld", "YUY2", m_FrameSizeList[j].cx, m_FrameSizeList[j].cy);
			else if (IsEqualGUID (m_SubTypeList[j], MEDIASUBTYPE_YVYU))
				wsprintf (buf, "%s %ldx%ld", "YVYU", m_FrameSizeList[j].cx, m_FrameSizeList[j].cy);
			else if (IsEqualGUID (m_SubTypeList[j], MEDIASUBTYPE_UYVY))
				wsprintf (buf, "%s %ldx%ld", "UYVY", m_FrameSizeList[j].cx, m_FrameSizeList[j].cy);
			else if (IsEqualGUID (m_SubTypeList[j], MEDIASUBTYPE_YV12))
				wsprintf (buf, "%s %ldx%ld", "YV12", m_FrameSizeList[j].cx, m_FrameSizeList[j].cy);
			else if (IsEqualGUID (m_SubTypeList[j], MEDIASUBTYPE_I420))
				wsprintf (buf, "%s %ldx%ld", "I420", m_FrameSizeList[j].cx, m_FrameSizeList[j].cy);
			else if (IsEqualGUID (m_SubTypeList[j], MEDIASUBTYPE_IYUV))
				wsprintf (buf, "%s %ldx%ld", "IYUV", m_FrameSizeList[j].cx, m_FrameSizeList[j].cy);
			else if (IsEqualGUID (m_SubTypeList[j], MEDIASUBTYPE_YV12))
				wsprintf (buf, "%s %ldx%ld", "YV12", m_FrameSizeList[j].cx, m_FrameSizeList[j].cy);
			else if (IsEqualGUID (m_SubTypeList[j], MEDIASUBTYPE_RGB4))
				wsprintf (buf, "%s %ldx%ld", "RGB4", m_FrameSizeList[j].cx, m_FrameSizeList[j].cy);
			else if (IsEqualGUID (m_SubTypeList[j], MEDIASUBTYPE_RGB8))
				wsprintf (buf, "%s %ldx%ld", "RGB8", m_FrameSizeList[j].cx, m_FrameSizeList[j].cy);
			else if (IsEqualGUID (m_SubTypeList[j], MEDIASUBTYPE_RGB555))
				wsprintf (buf, "%s %ldx%ld", "RGB16", m_FrameSizeList[j].cx, m_FrameSizeList[j].cy);
			else if (IsEqualGUID (m_SubTypeList[j], MEDIASUBTYPE_RGB565))
				wsprintf (buf, "%s %ldx%ld", "RGB16", m_FrameSizeList[j].cx, m_FrameSizeList[j].cy);
			else if (IsEqualGUID (m_SubTypeList[j], MEDIASUBTYPE_RGB24))
				wsprintf (buf, "%s %ldx%ld", "RGB24", m_FrameSizeList[j].cx, m_FrameSizeList[j].cy);
			else if (IsEqualGUID (m_SubTypeList[j], MEDIASUBTYPE_UYVY))
				wsprintf (buf, "%s %ldx%ld", "UYVY", m_FrameSizeList[j].cx, m_FrameSizeList[j].cy);
			else
				wsprintf (buf, "%s %ldx%ld", "Unknown", m_FrameSizeList[j].cx, m_FrameSizeList[j].cy);

			ComboBox_AddString(m_hWndFormat, buf);

			if (m_CurrentMediaType->subtype == m_SubTypeList[j] && HEADER(m_CurrentMediaType->pbFormat)->biWidth == m_FrameSizeList[j].cx  && HEADER(m_CurrentMediaType->pbFormat)->biHeight == m_FrameSizeList[j].cy)
			{
				ComboBox_SetCurSel(m_hWndFormat, j);
				m_SubTypeCurrent = m_SubTypeList[j];
				m_FrameSizeCurrent = m_FrameSizeList[j];
			}
		}

		// Update current format
		OnFormatChanged();

		// Remember the original format
		m_OriginalFormat = m_CurrentFormat;
	}

	// Create the controls for the properties
	if (m_Controls[0] = new CPreviewProperty(m_hwnd, IDC_FrameRateControl_Label, IDC_FrameRateControl_Minimum, IDC_FrameRateControl_Maximum, IDC_FrameRateControl_Default, IDC_FrameRateControl_Stepping, IDC_FrameRateControl_Edit, IDC_FrameRateControl_Slider, 0, IDC_Preview_FrameRate, m_pIFrameRateControl, m_pIVideoControl))
	{
		DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s:   SUCCESS: m_Controls[0]=0x%08lX", _fx_, m_Controls[0]));

		if (m_Controls[1] = new CPreviewProperty(m_hwnd, 0, 0, 0, 0, 0, IDC_FORMAT_FlipVertical, 0, 0, IDC_Preview_FlipVertical, m_pIFrameRateControl, m_pIVideoControl))
		{
			DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s:   SUCCESS: m_Controls[1]=0x%08lX", _fx_, m_Controls[1]));

			if (m_Controls[2] = new CPreviewProperty(m_hwnd, 0, 0, 0, 0, 0, IDC_FORMAT_FlipHorizontal, 0, 0, IDC_Preview_FlipHorizontal, m_pIFrameRateControl, m_pIVideoControl))
			{
				DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s:   SUCCESS: m_Controls[2]=0x%08lX", _fx_, m_Controls[2]));

				if (m_Controls[3] = new CPreviewProperty(m_hwnd, 0, 0, 0, 0, 0, IDC_FrameRateControl_Actual, 0, IDC_FrameRateControl_Meter, IDC_Preview_CurrentFrameRate, m_pIFrameRateControl, m_pIVideoControl))
				{
					DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s:   SUCCESS: m_Controls[2]=0x%08lX", _fx_, m_Controls[2]));
				}
				else
				{
					DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: Out of memory", _fx_));
					delete m_Controls[0], m_Controls[0] = NULL;
					delete m_Controls[1], m_Controls[1] = NULL;
					delete m_Controls[2], m_Controls[2] = NULL;
					Hr = E_OUTOFMEMORY;
					goto MyExit;
				}
			}
			else
			{
				DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: Out of memory", _fx_));
				delete m_Controls[0], m_Controls[0] = NULL;
				delete m_Controls[1], m_Controls[1] = NULL;
				Hr = E_OUTOFMEMORY;
				goto MyExit;
			}
		}
		else
		{
			DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: Out of memory", _fx_));
			delete m_Controls[0], m_Controls[0] = NULL;
			Hr = E_OUTOFMEMORY;
			goto MyExit;
		}
	}
	else
	{
		DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: Out of memory", _fx_));
		Hr = E_OUTOFMEMORY;
		goto MyExit;
	}

	// Initialize all the controls. If the initialization fails, it's Ok. It just means
	// that the TAPI control interface isn't implemented by the device. The dialog item
	// in the property page will be greyed, showing this to the user.
	for (j = 0; j < m_NumProperties; j++)
	{
		if (m_Controls[j]->Init())
		{
			DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s:   SUCCESS: m_Controls[%ld]->Init()", _fx_, j));
		}
		else
		{
			DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   WARNING: m_Controls[%ld]->Init() failed", _fx_, j));
		}
	}

MyExit:
	DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: end", _fx_));
	m_fActivated = TRUE;
	return Hr;
}

/****************************************************************************
 *  @doc INTERNAL CPREVIEWPMETHOD
 *
 *  @mfunc HRESULT | CPreviewProperties | OnDeactivate | This
 *    method is called when the property page is dismissed.
 *
 *  @rdesc This method returns an HRESULT value that depends on the
 *    implementation of the interface. HRESULT can include one of the
 *    following standard constants, or other values not listed:
 *
 *  @flag NOERROR | No error
 ***************************************************************************/
HRESULT CPreviewProperties::OnDeactivate()
{
	int	j;

	FX_ENTRY("CPreviewProperties::OnDeactivate")

	DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: begin", _fx_));

	// Free the controls
	for (j = 0; j < m_NumProperties; j++)
	{
		if (m_Controls[j])
		{
			DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s:   SUCCESS: deleting m_Controls[%ld]=0x%08lX", _fx_, j, m_Controls[j]));
			delete m_Controls[j], m_Controls[j] = NULL;
		}
		else
		{
			DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   WARNING: control already freed", _fx_));
		}
	}

	DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: end", _fx_));
	return NOERROR;
}

/****************************************************************************
 *  @doc INTERNAL CPREVIEWPMETHOD
 *
 *  @mfunc HRESULT | CPreviewProperties | OnDeactivate | This
 *    method is used to retrieve the current media format used by the pin.
 *
 *  @rdesc This method returns an HRESULT value that depends on the
 *    implementation of the interface. HRESULT can include one of the
 *    following standard constants, or other values not listed:
 *
 *  @flag NOERROR | No error
 ***************************************************************************/
HRESULT CPreviewProperties::GetCurrentMediaType(void)
{
	HRESULT Hr = NOERROR;

	FX_ENTRY("CPreviewProperties::GetCurrentMediaType")

	DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: begin", _fx_));

	if (m_CurrentMediaType)
	{
		DeleteMediaType (m_CurrentMediaType);
		m_CurrentMediaType = NULL;
	}

	if (FAILED (Hr = m_pIAMStreamConfig->GetFormat((AM_MEDIA_TYPE **)&m_CurrentMediaType)))
	{
		// Otherwise, just get the first enumerated media type
		VIDEO_STREAM_CONFIG_CAPS RangeCaps;

		if (FAILED (Hr = m_pIAMStreamConfig->GetStreamCaps(0, (AM_MEDIA_TYPE **)&m_CurrentMediaType, (BYTE *)&RangeCaps)))
		{
			m_CurrentMediaType = NULL;
		}
	}

	DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: end", _fx_));

	return Hr;
}

/****************************************************************************
 *  @doc INTERNAL CPREVIEWPMETHOD
 *
 *  @mfunc HRESULT | CPreviewProperties | OnFormatChanged | This
 *    method is used to retrieve the format selected by the user.
 *
 *  @rdesc This method returns an HRESULT value that depends on the
 *    implementation of the interface. HRESULT can include one of the
 *    following standard constants, or other values not listed:
 *
 *  @flag NOERROR | No error
 ***************************************************************************/
HRESULT CPreviewProperties::OnFormatChanged()
{
	HRESULT	Hr = E_UNEXPECTED;
	int		j;

	FX_ENTRY("CPreviewProperties::OnFormatChanged")

	DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: begin", _fx_));

	if (!m_pIAMStreamConfig)
	{
		Hr = E_INVALIDARG;
		goto MyExit;
	}

	// Associate the current compression index with the right range index
	m_CurrentFormat = ComboBox_GetCurSel(m_hWndFormat);
	ASSERT (m_CurrentFormat >= 0 && m_CurrentFormat < m_RangeCount);
	if (m_CurrentFormat >= 0 && m_CurrentFormat < m_RangeCount)
	{
		m_SubTypeCurrent = m_SubTypeList[m_CurrentFormat];
		m_FrameSizeCurrent = m_FrameSizeList[m_CurrentFormat];

		for (j = 0; j < m_RangeCount; j++)
		{
			if (m_SubTypeList[j] == m_SubTypeCurrent)
			{
				CMediaType *pmt = NULL;

				Hr = m_pIAMStreamConfig->GetStreamCaps(j, (AM_MEDIA_TYPE **)&pmt, (BYTE *)&m_RangeCaps);

				DeleteMediaType (pmt);
			}
		}
	}

MyExit:
	DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: end", _fx_));
	return Hr;
}

/****************************************************************************
 *  @doc INTERNAL CPREVIEWPMETHOD
 *
 *  @mfunc HRESULT | CPreviewProperties | InitialRangeScan | This
 *    method is used to retrieve the list of supported formats on the pin.
 *
 *  @rdesc This method returns an HRESULT value that depends on the
 *    implementation of the interface. HRESULT can include one of the
 *    following standard constants, or other values not listed:
 *
 *  @flag NOERROR | No error
 ***************************************************************************/
HRESULT CPreviewProperties::InitialRangeScan()
{
	HRESULT			Hr = NOERROR;
	int				lSize;
	int				j;
	AM_MEDIA_TYPE	*pmt = NULL;

	FX_ENTRY("CPreviewProperties::InitialRangeScan")

	DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: begin", _fx_));

	if (!m_pIAMStreamConfig)
	{
		Hr = E_INVALIDARG;
		goto MyExit;
	}

	Hr = m_pIAMStreamConfig->GetNumberOfCapabilities(&m_RangeCount, &lSize);
	ASSERT (lSize >= sizeof (VIDEO_STREAM_CONFIG_CAPS) && SUCCEEDED (Hr));
	if (lSize < sizeof (VIDEO_STREAM_CONFIG_CAPS) || !SUCCEEDED(Hr))
	{
		Hr = E_FAIL;
		goto MyExit;
	}

	DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s:   NumberOfRanges=%d", _fx_, m_RangeCount));

	if (!(m_SubTypeList = new GUID [m_RangeCount]))
	{
		DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s: ERROR: new failed", _fx_));
		Hr = E_OUTOFMEMORY;
		goto MyExit;
	}

	if (!(m_FrameSizeList = new SIZE [m_RangeCount]))
	{
		DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s: ERROR: new failed", _fx_));
		Hr = E_OUTOFMEMORY;
		goto MyExit;
	}

	for (j = 0; j < m_RangeCount; j++)
	{
		pmt = NULL;

		Hr = m_pIAMStreamConfig->GetStreamCaps(j, (AM_MEDIA_TYPE **)&pmt, (BYTE *)&m_RangeCaps);

		ASSERT(SUCCEEDED (Hr));
		ASSERT(pmt);
		ASSERT(pmt->majortype == MEDIATYPE_Video);
		ASSERT(pmt->formattype == FORMAT_VideoInfo);

		m_SubTypeList[j] = pmt->subtype;
		m_FrameSizeList[j].cx = HEADER(pmt->pbFormat)->biWidth;
		m_FrameSizeList[j].cy = HEADER(pmt->pbFormat)->biHeight;

		DeleteMediaType(pmt);
	}

	// Get default format
	Hr = GetCurrentMediaType();

MyExit:
	DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: end", _fx_));
	return Hr;
}

/****************************************************************************
 *  @doc INTERNAL CPREVIEWPMETHOD
 *
 *  @mfunc HRESULT | CPreviewProperties | OnApplyChanges | This
 *    method is called when the user applies changes to the property page.
 *
 *  @rdesc This method returns an HRESULT value that depends on the
 *    implementation of the interface. HRESULT can include one of the
 *    following standard constants, or other values not listed:
 *
 *  @flag E_FAIL | Failure
 *  @flag E_POINTER | Null pointer argument
 *  @flag E_NOTIMPL | Method is not supported
 *  @flag NOERROR | No error
 ***************************************************************************/
HRESULT CPreviewProperties::OnApplyChanges()
{
	HRESULT	Hr = NOERROR;
	int		j;
	CMediaType *pmt = NULL;

	FX_ENTRY("CPreviewProperties::OnApplyChanges")

	DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: begin", _fx_));

	// Apply format changes on video stream
	m_CurrentFormat = ComboBox_GetCurSel(m_hWndFormat);
	
	// Only apply change if the format is different
	if (m_CurrentFormat != m_OriginalFormat)
	{
		if (SUCCEEDED (Hr = m_pIAMStreamConfig->GetStreamCaps(m_CurrentFormat, (AM_MEDIA_TYPE **) &pmt, (BYTE *)&m_RangeCaps)))
		{
			ASSERT(pmt && *pmt->FormatType() == FORMAT_VideoInfo);

			if (pmt && *pmt->FormatType() == FORMAT_VideoInfo)
			{
				if (FAILED(Hr = m_pIAMStreamConfig->SetFormat(pmt)))
				{
					TCHAR TitleBuf[80];
					TCHAR TextBuf[80];

					LoadString(g_hInst, IDS_ERROR_CONNECTING_TITLE, TitleBuf, sizeof (TitleBuf));
					LoadString(g_hInst, IDS_ERROR_CONNECTING, TextBuf, sizeof (TextBuf));
					MessageBox (NULL, TextBuf, TitleBuf, MB_OK);
				}
			}

			// Free some memory that was allocated by GetStreamCaps
			if (pmt)
				DeleteMediaType(pmt);

			// Update our copy of the current format
			GetCurrentMediaType();

			// Update original format
			m_OriginalFormat = m_CurrentFormat;
		}
	}

	// Apply target frame rate changes on video stream
	for (j = 0; j < m_NumProperties; j++)
	{
		ASSERT(m_Controls[j]);
		if (m_Controls[j])
		{
			DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s:   SUCCESS: calling m_Controls[%ld]=0x%08lX->OnApply", _fx_, j, m_Controls[j]));
			if (m_Controls[j]->HasChanged())
				m_Controls[j]->OnApply();
			Hr = NOERROR;
		}
		else
		{
			DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: can't calling m_Controls[%ld]=NULL->OnApply", _fx_, j));
			Hr = E_UNEXPECTED;
		}
	}

	DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: end", _fx_));
	return Hr;
}

/****************************************************************************
 *  @doc INTERNAL CPREVIEWPMETHOD
 *
 *  @mfunc BOOL | CPreviewProperties | OnReceiveMessage | This
 *    method is called when a message is sent to the property page dialog box.
 *
 *  @rdesc By default, returns the value returned by the Win32 DefWindowProc function.
 ***************************************************************************/
BOOL CPreviewProperties::OnReceiveMessage(HWND hWnd, UINT uMsg, WPARAM wParam, LPARAM lParam) 
{
	int iNotify = HIWORD (wParam);
	int j;

	switch (uMsg)
	{
		case WM_INITDIALOG:
			// This is called before Activate...
			m_hWnd = hWnd;
			return TRUE; // Don't call setfocus

		case WM_TIMER:
			if (m_fActivated)
			{
				// Update the Vu-Meters
				for (j = 0; j < m_NumProperties; j++)
				{
					ASSERT(m_Controls[j]);
					if (m_Controls[j]->GetProgressHWnd())
					{
						m_Controls[j]->UpdateProgress();
						SetDirty();
					}
				}
			}
			break;

		case WM_HSCROLL:
		case WM_VSCROLL:
			if (m_fActivated)
			{
				// Process all of the Trackbar messages
				for (j = 0; j < m_NumProperties; j++)
				{
					ASSERT(m_Controls[j]);
					if (m_Controls[j]->GetTrackbarHWnd() == (HWND)lParam)
					{
						m_Controls[j]->OnScroll(uMsg, wParam, lParam);
						SetDirty();
					}
				}
			}
			break;

		case WM_COMMAND:

			// This message gets sent even before OnActivate() has been
			// called(!). We need to test and make sure the controls have
			// beeen initialized before we can use them.
			if (m_fActivated)
			{
				// Process all of the edit box messages
				for (j = 0; j < m_NumProperties; j++)
				{
					if (m_Controls[j] && m_Controls[j]->GetEditHWnd() == (HWND)lParam)
					{
						m_Controls[j]->OnEdit(uMsg, wParam, lParam);
						SetDirty();
						break;
					}
				}

				switch (LOWORD(wParam))
				{
					case IDC_CONTROL_DEFAULT:
						for (j = 0; j < m_NumProperties; j++)
						{
							if (m_Controls[j])
								m_Controls[j]->OnDefault();
						}
						break;

					case IDC_FORMAT_Compression:
						if (HIWORD(wParam) == CBN_SELCHANGE)
						{
							OnFormatChanged();
						}
						break;

					default:
						break;
				}
			}
			break;

		default:
			return FALSE;
	}

	return TRUE;
}

/****************************************************************************
 *  @doc INTERNAL CPREVIEWPMETHOD
 *
 *  @mfunc BOOL | CPreviewProperties | SetDirty | This
 *    method notifies the property page site of changes.
 *
 *  @rdesc Nada.
 ***************************************************************************/
void CPreviewProperties::SetDirty()
{
	m_bDirty = TRUE;
	if (m_pPageSite)
		m_pPageSite->OnStatusChange(PROPPAGESTATUS_DIRTY);
}

#endif
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\net\tapi\skywalker\filters\video\tapivcap\preview.h ===
/****************************************************************************
 *  @doc INTERNAL PREVIEW
 *
 *  @module Preview.h | Header file for the <c CPreviewPin> class methods
 *    used to implement the video preview output pin.
 ***************************************************************************/

#ifndef _PREVIEW_H_
#define _PREVIEW_H_

/****************************************************************************
 *  @doc INTERNAL CPREVIEWPINCLASS
 *
 *  @class CPreviewPin | This class implements the video preview output pin.
 *
 *  @mdata CTAPIVCap* | CPreviewPin | m_pCaptureFilter | Reference to the
 *    parent capture filter.
 *
 *  @comm Supports IPin. Never created by COM, so no CreateInstance or entry
 *    in global FactoryTemplate table. Only ever created by a <c CTAPIVCap>
 *    object and returned via the EnumPins interface
 ***************************************************************************/
#ifdef USE_PROPERTY_PAGES
class CPreviewPin : public CTAPIBasePin, public ISpecifyPropertyPages
#else
class CPreviewPin : public CTAPIBasePin
#endif
{
	public:
	DECLARE_IUNKNOWN
	CPreviewPin(IN TCHAR *pObjectName, IN CTAPIVCap *pCaptureFilter, IN HRESULT *pHr, IN LPCWSTR pName);
	~CPreviewPin();
	STDMETHODIMP NonDelegatingQueryInterface(IN REFIID riid, OUT PVOID *ppv);
	static HRESULT CALLBACK CreatePreviewPin(CTAPIVCap *pCaptureFilter, CPreviewPin **ppPreviewPin);

#ifdef USE_PROPERTY_PAGES
	// ISpecifyPropertyPages methods
	STDMETHODIMP GetPages(OUT CAUUID *pPages);
#endif

	private:

	friend class CTAPIVCap;
	// friend class CCapturePin;
	friend class CAlloc;
	friend class CCapDev;
};

#endif // _PREVIEW_H_
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\net\tapi\skywalker\filters\video\tapivcap\procutil.cpp ===
/****************************************************************************
 *  @doc INTERNAL PROCUTIL
 *
 *  @module ProcUtil.cpp | Source file for the Processor ID and Speed routines.
 *
 *  @comm Comes from the NM code base.
 ***************************************************************************/

#include "Precomp.h"

#define LEGACY_DIVISOR	8

DWORD __stdcall FindTSC (LPVOID pvRefData)
{
	   _asm
	   {
		   mov     eax,1
		   _emit   00Fh     ;; CPUID
		   _emit   0A2h

    // The ref data is 2 DWORDS, the first is the flags,
    // the second the family
		   mov     ecx,pvRefData
		   mov     [ecx],edx
		   mov	   [ecx][4],eax
	   }

	   return 1;
}

DWORD __stdcall NoCPUID (LPEXCEPTION_RECORD per,PCONTEXT pctx)
{
    return 0;
}
//
//  GetProcessorSpeed(dwFamily)
//
//  get the processor speed in MHz, only works on Pentium or better
//  machines.
//
//  Will put 3, or 4 in dwFamily for 386/486, but no speed.
//  returns speed and family for 586+
//
//  - thanks to toddla, modified by mikeg
//

int __stdcall GetProcessorSpeed(int *pdwFamily)
{
    SYSTEM_INFO si;
    __int64	start, end, freq;
    int 	flags,family;
    int 	time;
    int 	clocks;
    DWORD	oldclass;
    HANDLE      hprocess;
    int     pRef[2];

    ZeroMemory(&si, sizeof(si));
    GetSystemInfo(&si);

    //Set the family. If wProcessorLevel is not specified, dig it out of dwProcessorType
    //Because wProcessor level is not implemented on Win95
    if (si.wProcessorLevel) {
	*pdwFamily=si.wProcessorLevel;
    }else {
    	//Ok, we're on Win95
    	switch (si.dwProcessorType) {
    	       case PROCESSOR_INTEL_386:
    		   *pdwFamily=3;
    		   break;

    	       case PROCESSOR_INTEL_486:
    		   *pdwFamily=4;
    		   break;
    	       default:
    		   *pdwFamily=0;
    		   break;
    	}
    }

    // make sure this is a INTEL Pentium (or clone) or higher.
    if (si.wProcessorArchitecture != PROCESSOR_ARCHITECTURE_INTEL)
        return 0;

    if (si.dwProcessorType < PROCESSOR_INTEL_PENTIUM)
        return 0;

    // see if this chip supports rdtsc before using it.
    if (!CallWithSEH (FindTSC,&pRef,NoCPUID))     {
        flags=0;
    } else {
    // The ref data is 2 DWORDS, the first is the flags,
    // the second the family. Pull them out and use them
        flags=pRef[0];
        family=pRef[1];
    }

    if (!(flags & 0x10))
        return 0;

    //If we don't have a family, set it now
    //Family is bits 11:8 of eax from CPU, with eax=1
    if (!(*pdwFamily)) {
       *pdwFamily=(family& 0x0F00) >> 8;
    }

    hprocess = GetCurrentProcess();
    oldclass = GetPriorityClass(hprocess);
    SetPriorityClass(hprocess, REALTIME_PRIORITY_CLASS);
    Sleep(10);

    QueryPerformanceFrequency((LARGE_INTEGER*)&freq);
    QueryPerformanceCounter((LARGE_INTEGER*)&start);
    _asm
    {
        _emit   0Fh     ;; RDTSC
        _emit   31h
        mov     ecx,100000
x:      dec     ecx
        jnz     x
        mov     ebx,eax
        _emit   0Fh     ;; RDTSC
        _emit   31h
        sub     eax,ebx
        mov     dword ptr clocks[0],eax
    }
    QueryPerformanceCounter((LARGE_INTEGER*)&end);
    SetPriorityClass(hprocess, oldclass);

    time = MulDiv((int)(end-start),1000000,(int)freq);

    return (clocks + time/2) / time;
}

HRESULT __stdcall GetNormalizedCPUSpeed (int *pdwNormalizedSpeed)
{
	int dwProcessorSpeed;
	int dwFamily;

	dwProcessorSpeed=GetProcessorSpeed(&dwFamily);

	*pdwNormalizedSpeed=dwProcessorSpeed;

	if (dwFamily > 5) {
	   //Ok, TWO things.
	   // ONE DO NOT DO FP!
	   // Two for the same Mhz assume a 686 is 1.3 times as fast as a 586 and a 786 is 1.6 times, etc.
	   *pdwNormalizedSpeed=(ULONG) (((10+3*(dwFamily-5))*dwProcessorSpeed)/10);
	}

	if (dwFamily < 5) {
	  //until we have 386/486 timing code, assume 486=50,386=37
	  //11/17/2000(Fri): 386/486 anyway not supported anymore at the OS level
	  if (dwFamily > 3) {
           //Cyrix, (5x86)? check before making default assignment
           if (is_cyrix()) {
               if (*pdwNormalizedSpeed==0) {
                   dwFamily=5;
                   *pdwNormalizedSpeed=100;
                   return NOERROR;
               }
           }
      }

	  *pdwNormalizedSpeed= (dwFamily*100)/LEGACY_DIVISOR;

      if (get_nxcpu_type ()) {
        //Double the perceived value on a NexGen
        *pdwNormalizedSpeed *=2;
      }
   }
   return NOERROR;
}
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\net\tapi\skywalker\filters\video\tapivcap\procutil.h ===
/****************************************************************************
 *  @doc INTERNAL PROCUTIL
 *
 *  @module ProcUtil.h | Header file for the Processor ID and Speed routines.
 *
 *  @comm Comes from the NM code base.
 ***************************************************************************/

#ifndef _PROCUTIL_H_
#define _PROCUTIL_H_

HRESULT __stdcall GetNormalizedCPUSpeed (int *pdwNormalizedSpeed);

typedef DWORD (CALLBACK *INEXCEPTION)(LPEXCEPTION_RECORD per, PCONTEXT pctx);
typedef DWORD (CALLBACK *EXCEPTPROC)(void* pv);

// CallWithSEH is a utility function to call a function with structured exception handling
extern "C" DWORD WINAPI CallWithSEH(EXCEPTPROC pfn, void* pv, INEXCEPTION InException);
extern "C" WORD _cdecl is_cyrix(void);
extern "C" DWORD _cdecl get_nxcpu_type(void);

#endif // _PROCUTIL_H_
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\net\tapi\skywalker\filters\video\tapivcap\propedit.h ===
/****************************************************************************
 *  @doc INTERNAL PROPEDIT
 *
 *  @module PropEdit.h | Header file for the <c CPropertyEditor>
 *    class used to implement behavior of a single property to be displayed
 *    in a property page.
 *
 *  @comm This code tests the Ks interface handlers. This code is only
 *    compiled if USE_PROPERTY_PAGES is defined.
 ***************************************************************************/

#ifndef _PROPEDIT_H_
#define _PROPEDIT_H_

#ifdef USE_PROPERTY_PAGES

/****************************************************************************
 *  @doc INTERNAL CPROPEDITCLASS
 *
 *  @class CPropertyEditor | This class implements behavior of a single
 *    property to be displayed in a property page.
 *
 *  @mdata ULONG | CPropertyEditor | m_IDProperty | Property ID
 *
 *  @mdata LONG | CPropertyEditor | m_CurrentValue | Property current value
 *
 *  @mdata LONG | CPropertyEditor | m_Min | Property minimum value
 *
 *  @mdata LONG | CPropertyEditor | m_Max | Property maximum value
 *
 *  @mdata LONG | CPropertyEditor | m_SteppingDelta | Property stepping delta
 *
 *  @mdata LONG | CPropertyEditor | m_DefaultValue | Property default value
 *
 *  @mdata BOOL | CPropertyEditor | m_Active | Set to TRUE after all property values have been initialized
 *
 *  @mdata LONG | CPropertyEditor | m_OriginalValue | Backup of the original value
 *
 *  @mdata HWND | CPropertyEditor | m_hDlg | Window handle to the Parent dialog
 *
 *  @mdata HWND | CPropertyEditor | m_hWndMin | Window handle to the Minimum dialog item
 *
 *  @mdata HWND | CPropertyEditor | m_hWndMax | Window handle to the Maximum dialog item
 *
 *  @mdata HWND | CPropertyEditor | m_hWndDefault | Window handle to the Default dialog item
 *
 *  @mdata HWND | CPropertyEditor | m_hWndStep | Window handle to the Stepping Delta dialog item
 *
 *  @mdata HWND | CPropertyEditor | m_hWndEdit | Window handle to the Target dialog item
 *
 *  @mdata HWND | CPropertyEditor | m_hWndTrackbar | Window handle to the slide bar
 *
 *  @mdata HWND | CPropertyEditor | m_hWndProgress | Window handle to the progress bar
 *
 *  @mdata ULONG | CPropertyEditor | m_IDLabel | Resource ID of the property label
 *
 *  @mdata ULONG | CPropertyEditor | m_IDMinControl | Resource ID of the Minimum dialog item
 *
 *  @mdata ULONG | CPropertyEditor | m_IDMaxControl | Resource ID of the Maximum dialog item
 *
 *  @mdata ULONG | CPropertyEditor | m_IDStepControl | Resource ID of the Stepping Delta dialog item
 *
 *  @mdata ULONG | CPropertyEditor | m_IDDefaultControl | Resource ID of the Default dialog item
 *
 *  @mdata ULONG | CPropertyEditor | m_IDEditControl | Resource ID of the Target dialog item
 *
 *  @mdata ULONG | CPropertyEditor | m_IDTrackbarControl | Resource ID of the slide bar
 *
 *  @mdata ULONG | CPropertyEditor | m_IDProgressControl | Resource ID of the progress bar
 ***************************************************************************/
class CPropertyEditor
{
	public:
	CPropertyEditor(HWND hDlg, ULONG IDLabel, ULONG IDMinControl, ULONG IDMaxControl, ULONG IDDefaultControl, ULONG IDStepControl, ULONG IDEditControl, ULONG IDTrackbarControl, ULONG IDProgressControl, ULONG IDProperty, ULONG IDAutoControl);
	virtual ~CPropertyEditor();

	BOOL Init();

	HWND GetTrackbarHWnd();
	HWND GetProgressHWnd();
	HWND GetEditHWnd();
	HWND GetAutoHWnd();

	BOOL UpdateEditBox();
	BOOL UpdateTrackbar();
	BOOL UpdateProgress();
	BOOL UpdateAuto();

	BOOL OnApply();
	BOOL OnDefault();
	BOOL OnScroll(ULONG nCommand, WPARAM wParam, LPARAM lParam);
	BOOL OnEdit(ULONG nCommand, WPARAM wParam, LPARAM lParam);
	BOOL OnAuto(ULONG nCommand, WPARAM wParam, LPARAM lParam);
	BOOL HasChanged();

	protected:

	BOOL CanAutoControl(void);
	BOOL GetAuto(void);
	BOOL SetAuto(BOOL fAuto);

	// Pure virtual functions to set/get actual property values, and the ranges
	virtual HRESULT GetValue(void) PURE;
	virtual HRESULT SetValue(void) PURE;
	virtual HRESULT GetRange(void) PURE; 

	ULONG	m_IDProperty;	// Property ID

	// The following are used by GetValue and SetValue
	LONG	m_CurrentValue;
	LONG	m_CurrentFlags;

	// The following must be set by GetRange
	LONG	m_Min;
	LONG	m_Max;
	LONG	m_SteppingDelta;
	LONG	m_DefaultValue;
	LONG	m_DefaultFlags;
	LONG	m_CapsFlags;

	private:
	BOOL	m_Active;
	BOOL	m_fCheckBox;
	LONG	m_OriginalValue;
	LONG	m_OriginalFlags;
	HWND	m_hDlg;				// Parent
	HWND	m_hWndMin;			// Min window
	HWND	m_hWndMax;			// Max window
	HWND	m_hWndDefault;		// Default window
	HWND	m_hWndStep;			// Step window
	HWND	m_hWndEdit;			// Edit window
	HWND	m_hWndTrackbar;		// Slider
	HWND	m_hWndProgress;		// Progress
	HWND	m_hWndAuto;			// Auto checkbox
	ULONG	m_IDLabel;			// ID of label
	ULONG	m_IDMinControl;		// ID of min control
	ULONG	m_IDMaxControl;		// ID of max control
	ULONG	m_IDStepControl;	// ID of step control
	ULONG	m_IDDefaultControl;	// ID of default control
	ULONG	m_IDEditControl;	// ID of edit control
	ULONG	m_IDTrackbarControl;// ID of trackbar
	ULONG	m_IDProgressControl;// ID of trackbar
	ULONG	m_IDAutoControl;	// ID of auto checkbox
	LONG	m_TrackbarOffset;	// Handles negative trackbar offsets
	LONG	m_ProgressOffset;	// Handles negative trackbar offsets
	BOOL	m_CanAutoControl;

};

#endif // USE_PROPERTY_PAGES

#endif // _PROPEDIT_H_
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\net\tapi\skywalker\filters\video\tapivcap\rtppd.cpp ===
/****************************************************************************
 *  @doc INTERNAL RTPPD
 *
 *  @module RtpPd.cpp | Source file for the <c CRtpPdPin> class methods
 *    used to implement the RTP packetization descriptor pin.
 ***************************************************************************/

#include "Precomp.h"

/****************************************************************************
 *  @doc INTERNAL CRTPPDPINMETHOD
 *
 *  @mfunc CRtpPdPin* | CRtpPdPin | CreateRtpPdPin | This helper
 *    function creates an output pin for RTP packetization descriptors.
 *
 *  @parm CTAPIVCap* | pCaptureFilter | Specifies a pointer to the owner
 *    filter.
 *
 *  @parm CRtpPdPin** | ppRtpPdPin | Specifies that address of a pointer
 *    to a <c CRtpPdPin> object to receive the a pointer to the newly
 *    created pin.
 *
 *  @rdesc This method returns an HRESULT value that depends on the
 *    implementation of the interface. HRESULT can include one of the
 *    following standard constants, or other values not listed:
 *
 *  @flag E_FAIL | Failure
 *  @flag E_POINTER | Null pointer argument
 *  @flag NOERROR | No error
 ***************************************************************************/
HRESULT CALLBACK CRtpPdPin::CreateRtpPdPin(CTAPIVCap *pCaptureFilter, CRtpPdPin **ppRtpPdPin)
{
        HRESULT Hr = NOERROR;

        FX_ENTRY("CRtpPdPin::CreateRtpPdPin")

        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: begin", _fx_));

        // Validate input parameters
        ASSERT(pCaptureFilter);
        ASSERT(ppRtpPdPin);
        if (!pCaptureFilter || !ppRtpPdPin)
        {
                DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: Null pointer argument", _fx_));
                Hr = E_POINTER;
                goto MyExit;
        }

        if (!(*ppRtpPdPin = (CRtpPdPin *) new CRtpPdPin(NAME("RTP Packetization Descriptor Stream"), pCaptureFilter, &Hr, PNAME_RTPPD)))
        {
                DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: Out of memory", _fx_));
                Hr = E_OUTOFMEMORY;
                goto MyExit;
        }

        // If initialization failed, delete the stream array and return the error
        if (FAILED(Hr) && *ppRtpPdPin)
        {
                DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: Initialization failed", _fx_));
                Hr = E_FAIL;
                delete *ppRtpPdPin, *ppRtpPdPin = NULL;
        }

MyExit:
        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: end", _fx_));
        return Hr;
}

/****************************************************************************
 *  @doc INTERNAL CRTPPDPINMETHOD
 *
 *  @mfunc HRESULT | CRtpPdPin | CRtpPdPin | This method is the
 *  constructor for the <c CRtpPdPin> object
 *
 *  @rdesc Nada.
 ***************************************************************************/
CRtpPdPin::CRtpPdPin(IN TCHAR *pObjectName, IN CTAPIVCap *pCaptureFilter, IN HRESULT *pHr, IN LPCWSTR pName) : CBaseOutputPin(pObjectName, pCaptureFilter, &pCaptureFilter->m_lock, pHr, pName), m_pCaptureFilter(pCaptureFilter)
{
        FX_ENTRY("CRtpPdPin::CRtpPdPin")

        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: begin", _fx_));

        // Validate input parameters
        ASSERT(pHr);
        ASSERT(pCaptureFilter);
        if (!pCaptureFilter || !pHr)
        {
                DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: Null pointer argument", _fx_));
                if (pHr)
                        *pHr = E_POINTER;
        }

        if (pHr && FAILED(*pHr))
        {
                DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: Base class error or invalid input parameter", _fx_));
                goto MyExit;
        }

        // Default inits
        m_dwMaxRTPPacketSize = DEFAULT_RTP_PACKET_SIZE;
        if (m_pCaptureFilter->m_pCapturePin)
                m_dwRTPPayloadType = m_pCaptureFilter->m_pCapturePin->m_dwRTPPayloadType;
        else
                m_dwRTPPayloadType = H263_PAYLOAD_TYPE;
        m_fRunning = FALSE;
        m_fCapturing = FALSE;
        ZeroMemory(&m_parms, sizeof(m_parms));

MyExit:
        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: end", _fx_));
}

/****************************************************************************
 *  @doc INTERNAL CRTPPDPINMETHOD
 *
 *  @mfunc void | CRtpPdPin | ~CRtpPdPin | This method is the destructor
 *    for the <c CRtpPdPin> object.
 *
 *  @rdesc Nada.
 ***************************************************************************/
CRtpPdPin::~CRtpPdPin()
{
        FX_ENTRY("CRtpPdPin::~CRtpPdPin")

        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: begin", _fx_));

        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: end", _fx_));
}

/****************************************************************************
 *  @doc INTERNAL CRTPPDPINMETHOD
 *
 *  @mfunc HRESULT | CRtpPdPin | NonDelegatingQueryInterface | This
 *    method is the nondelegating interface query function. It returns a pointer
 *    to the specified interface if supported. The only interfaces explicitly
 *    supported being <i IRTPPDControl>.
 *
 *  @parm REFIID | riid | Specifies the identifier of the interface to return.
 *
 *  @parm PVOID* | ppv | Specifies the place in which to put the interface
 *    pointer.
 *
 *  @rdesc This method returns an HRESULT value that depends on the
 *    implementation of the interface. HRESULT can include one of the
 *    following standard constants, or other values not listed:
 *
 *  @flag E_FAIL | Failure
 *  @flag E_POINTER | Null pointer argument
 *  @flag NOERROR | No error
 ***************************************************************************/
STDMETHODIMP CRtpPdPin::NonDelegatingQueryInterface(IN REFIID riid, OUT void **ppv)
{
        HRESULT Hr = NOERROR;

        FX_ENTRY("CRtpPdPin::NonDelegatingQueryInterface")

        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: begin", _fx_));

        // Validate input parameters
        ASSERT(ppv);
        if (!ppv)
        {
                DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: Null pointer argument", _fx_));
                Hr = E_POINTER;
                goto MyExit;
        }

        // Retrieve interface pointer
        if (riid == __uuidof(IRTPPDControl))
        {
                if (FAILED(Hr = GetInterface(static_cast<IRTPPDControl*>(this), ppv)))
                {
                        DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: NDQI for IRTPPDControl failed Hr=0x%08lX", _fx_, Hr));
                }
                else
                {
                        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s:   SUCCESS: IRTPPDControl*=0x%08lX", _fx_, *ppv));
                }

                goto MyExit;
        }
#ifdef USE_PROPERTY_PAGES
        else if (riid == IID_ISpecifyPropertyPages)
        {
                if (FAILED(Hr = GetInterface(static_cast<ISpecifyPropertyPages*>(this), ppv)))
                {
                        DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: NDQI for ISpecifyPropertyPages failed Hr=0x%08lX", _fx_, Hr));
                }
                else
                {
                        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s:   SUCCESS: ISpecifyPropertyPages*=0x%08lX", _fx_, *ppv));
                }

                goto MyExit;
        }
#endif

        if (FAILED(Hr = CBaseOutputPin::NonDelegatingQueryInterface(riid, ppv)))
        {
                DBGOUT((g_dwVideoCaptureTraceID, WARN, "%s:   WARNING: NDQI for {%08lX-%04lX-%04lX-%02lX%02lX-%02lX%02lX%02lX%02lX%02lX%02lX} failed Hr=0x%08lX", _fx_, riid.Data1, riid.Data2, riid.Data3, riid.Data4[0], riid.Data4[1], riid.Data4[2], riid.Data4[3], riid.Data4[4], riid.Data4[5], riid.Data4[6], riid.Data4[7], Hr));
        }
        else
        {
                DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s:   SUCCESS: {%08lX-%04lX-%04lX-%02lX%02lX-%02lX%02lX%02lX%02lX%02lX%02lX}*=0x%08lX", _fx_, riid.Data1, riid.Data2, riid.Data3, riid.Data4[0], riid.Data4[1], riid.Data4[2], riid.Data4[3], riid.Data4[4], riid.Data4[5], riid.Data4[6], riid.Data4[7], *ppv));
        }

MyExit:
        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: end", _fx_));
        return Hr;
}

#ifdef USE_PROPERTY_PAGES
/****************************************************************************
 *  @doc INTERNAL CRTPPDPINMETHOD
 *
 *  @mfunc HRESULT | CRtpPdPin | GetPages | This method Fills a counted
 *    array of GUID values where each GUID specifies the CLSID of each
 *    property page that can be displayed in the property sheet for this
 *    object.
 *
 *  @parm CAUUID* | pPages | Specifies a pointer to a caller-allocated CAUUID
 *    structure that must be initialized and filled before returning. The
 *    pElems field in the CAUUID structure is allocated by the callee with
 *    CoTaskMemAlloc and freed by the caller with CoTaskMemFree.
 *
 *  @rdesc This method returns an HRESULT value that depends on the
 *    implementation of the interface. HRESULT can include one of the
 *    following standard constants, or other values not listed:
 *
 *  @flag E_FAIL | Failure
 *  @flag E_POINTER | Null pointer argument
 *  @flag E_OUTOFMEMORY | Allocation failed
 *  @flag NOERROR | No error
 ***************************************************************************/
STDMETHODIMP CRtpPdPin::GetPages(OUT CAUUID *pPages)
{
        HRESULT Hr = NOERROR;

        FX_ENTRY("CRtpPdPin::GetPages")

        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: begin", _fx_));

        // Validate input parameters
        ASSERT(pPages);
        if (!pPages)
        {
                DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: Null pointer argument", _fx_));
                Hr = E_POINTER;
                goto MyExit;
        }

        pPages->cElems = 1;
        if (!(pPages->pElems = (GUID *) QzTaskMemAlloc(sizeof(GUID) * pPages->cElems)))
        {
                DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: Out of memory", _fx_));
                Hr = E_OUTOFMEMORY;
        }
        else
        {
                pPages->pElems[0] = __uuidof(RtpPdPropertyPage);
        }

MyExit:
        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: end", _fx_));
        return Hr;
}
#endif

/****************************************************************************
 *  @doc INTERNAL CRTPPDPINMETHOD
 *
 *  @mfunc HRESULT | CRtpPdPin | GetMediaType | This method retrieves one
 *    of the media types supported by the pin, which is used by enumerators.
 *
 *  @parm int | iPosition | Specifies a position in the media type list.
 *
 *  @parm CMediaType* | pMediaType | Specifies a pointer to the media type at
 *    the <p iPosition> position in the list of supported media types.
 *
 *  @rdesc This method returns an HRESULT value that depends on the
 *    implementation of the interface. HRESULT can include one of the
 *    following standard constants, or other values not listed:
 *
 *  @flag E_FAIL | Failure
 *  @flag E_POINTER | Null pointer argument
 *  @flag E_INVALIDARG | Invalid argument
 *  @flag VFW_S_NO_MORE_ITEMS | End of the list of media types has been reached
 *  @flag NOERROR | No error
 ***************************************************************************/
HRESULT CRtpPdPin::GetMediaType(IN int iPosition, OUT CMediaType *pMediaType)
{
        HRESULT Hr = NOERROR;

        FX_ENTRY("CRtpPdPin::GetMediaType")

        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: begin", _fx_));

        // Validate input parameters
        ASSERT(iPosition >= 0);
        ASSERT(pMediaType);
        if (iPosition < 0)
        {
                DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: Invalid iPosition argument", _fx_));
                Hr = E_INVALIDARG;
                goto MyExit;
        }
        if (iPosition >= NUM_RTP_PD_FORMATS)
        {
                DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   WARNING: End of the list of media types has been reached", _fx_));
                Hr = VFW_S_NO_MORE_ITEMS;
                goto MyExit;
        }
        if (!pMediaType)
        {
                DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: Null pointer argument", _fx_));
                Hr = E_POINTER;
                goto MyExit;
        }

        // Return our media type
        *pMediaType = *Rtp_Pd_Formats[iPosition];

MyExit:
        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: end", _fx_));
        return Hr;
}

/****************************************************************************
 *  @doc INTERNAL CRTPPDPINMETHOD
 *
 *  @mfunc HRESULT | CRtpPdPin | CheckMediaType | This method is used to
 *    determine if the pin can support a specific media type.
 *
 *  @parm CMediaType* | pMediaType | Specifies a pointer to the media type.
 *
 *  @rdesc This method returns an HRESULT value that depends on the
 *    implementation of the interface. HRESULT can include one of the
 *    following standard constants, or other values not listed:
 *
 *  @flag E_FAIL | Failure
 *  @flag E_POINTER | Null pointer argument
 *  @flag E_INVALIDARG | Invalid argument
 *  @flag VFW_E_INVALIDMEDIATYPE | An invalid media type was specified
 *  @flag NOERROR | No error
 ***************************************************************************/
HRESULT CRtpPdPin::CheckMediaType(IN const CMediaType *pMediaType)
{
        HRESULT Hr = NOERROR;
    CMediaType mt;
        BOOL fFormatMatch = FALSE;
        DWORD dwIndex;

        FX_ENTRY("CRtpPdPin::CheckMediaType")

        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: begin", _fx_));

        // Validate input parameters
        ASSERT(pMediaType);
        if (!pMediaType || !pMediaType->pbFormat)
        {
                DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: Null pointer argument", _fx_));
                Hr = E_POINTER;
                goto MyExit;
        }

        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s:   Checking Max RTP packet size %d", _fx_, ((RTP_PD_INFO *)pMediaType->pbFormat)->dwMaxRTPPacketSize));

        // We only support KSDATAFORMAT_TYPE_RTP_PD and KSDATAFORMAT_SPECIFIER_NONE
        if (*pMediaType->Type() != KSDATAFORMAT_TYPE_RTP_PD || *pMediaType->FormatType() != KSDATAFORMAT_SPECIFIER_NONE)
        {
                DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: Media type or format type not recognized!", _fx_));
                Hr = VFW_E_INVALIDMEDIATYPE;
                goto MyExit;
        }

    // Quickly test to see if this is the current format (what we provide in GetMediaType). We accept that
    GetMediaType(0,&mt);
    if (mt == *pMediaType)
        {
                DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s:   SUCCESS: Identical to current format", _fx_));
                goto MyExit;
    }

        // Check the media subtype and image resolution
        // Don't test the payload type: we may be asked to use a dynamic payload type
        for (dwIndex=0; dwIndex < NUM_RTP_PD_FORMATS && !fFormatMatch;  dwIndex++)
        {
                if ((((RTP_PD_INFO *)pMediaType->pbFormat)->dwMaxRTPPacketizationDescriptorBufferSize == ((RTP_PD_INFO *)Rtp_Pd_Formats[dwIndex]->pbFormat)->dwMaxRTPPacketizationDescriptorBufferSize)
                && (((RTP_PD_INFO *)pMediaType->pbFormat)->dwMaxRTPPacketSize >= Rtp_Pd_Caps[dwIndex]->dwSmallestRTPPacketSize)
                && (((RTP_PD_INFO *)pMediaType->pbFormat)->dwMaxRTPPacketSize <= Rtp_Pd_Caps[dwIndex]->dwLargestRTPPacketSize)
                && (((RTP_PD_INFO *)pMediaType->pbFormat)->dwNumLayers >= Rtp_Pd_Caps[dwIndex]->dwSmallestNumLayers)
                && (((RTP_PD_INFO *)pMediaType->pbFormat)->dwNumLayers <= Rtp_Pd_Caps[dwIndex]->dwSmallestNumLayers)
                && (((RTP_PD_INFO *)pMediaType->pbFormat)->dwDescriptorVersion == VERSION_1))
                        fFormatMatch = TRUE;
        }

        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s:   %s", _fx_, fFormatMatch ? "SUCCESS: Format supported" : "ERROR: Format notsupported"));

        if (!fFormatMatch)
                Hr = E_FAIL;

MyExit:
        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: end", _fx_));
        return Hr;
}

/****************************************************************************
 *  @doc INTERNAL CRTPPDPINMETHOD
 *
 *  @mfunc HRESULT | CRtpPdPin | SetMediaType | This method is used to
 *    set a specific media type on a pin.
 *
 *  @parm CMediaType* | pMediaType | Specifies a pointer to the media type.
 *
 *  @rdesc This method returns an HRESULT value that depends on the
 *    implementation of the interface. HRESULT can include one of the
 *    following standard constants, or other values not listed:
 *
 *  @flag E_FAIL | Failure
 *  @flag E_POINTER | Null pointer argument
 *  @flag E_INVALIDARG | Invalid argument
 *  @flag NOERROR | No error
 ***************************************************************************/
HRESULT CRtpPdPin::SetMediaType(IN CMediaType *pMediaType)
{
        HRESULT Hr = NOERROR;

        FX_ENTRY("CRtpPdPin::SetMediaType")

        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: begin", _fx_));

        Hr = E_NOTIMPL;

        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: end", _fx_));
        return Hr;
}

/****************************************************************************
 *  @doc INTERNAL CRTPPDPINMETHOD
 *
 *  @mfunc HRESULT | CRtpPdPin | ActiveRun | This method is called by the
 *    <c CBaseFilter> implementation when the state changes from paused to
 *    running mode.
 *
 *  @parm REFERENCE_TIME | tStart | ???.
 *
 *  @rdesc This method returns an HRESULT value that depends on the
 *    implementation of the interface. HRESULT can include one of the
 *    following standard constants, or other values not listed:
 *
 *  @flag E_FAIL | Failure
 *  @flag NOERROR | No error
 ***************************************************************************/
HRESULT CRtpPdPin::ActiveRun(IN REFERENCE_TIME tStart)
{
        HRESULT Hr = NOERROR;

        FX_ENTRY("CRtpPdPin::ActiveRun")

        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: begin", _fx_));

    ASSERT(IsConnected());
        if (!IsConnected())
        {
                DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: Pin not connected yet!", _fx_));
                Hr = E_UNEXPECTED;
                goto MyExit;
        }

    m_fRunning = TRUE;

MyExit:
        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: end", _fx_));
        return Hr;
}

/****************************************************************************
 *  @doc INTERNAL CRTPPDPINMETHOD
 *
 *  @mfunc HRESULT | CRtpPdPin | ActivePause | This method is called by the
 *    <c CBaseFilter> implementation when the state changes from running to
 *    paused mode.
 *
 *  @rdesc This method returns an HRESULT value that depends on the
 *    implementation of the interface. HRESULT can include one of the
 *    following standard constants, or other values not listed:
 *
 *  @flag E_FAIL | Failure
 *  @flag NOERROR | No error
 ***************************************************************************/
HRESULT CRtpPdPin::ActivePause()
{
        FX_ENTRY("CRtpPdPin::ActivePause")

        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: begin", _fx_));

    m_fRunning = FALSE;

        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: end", _fx_));

        return NOERROR;
}

/****************************************************************************
 *  @doc INTERNAL CRTPPDPINMETHOD
 *
 *  @mfunc HRESULT | CRtpPdPin | SetMaxRTPPacketSize | This method is used to
 *    dynamically adjust the maximum RTP packet size (in bytes) to be
 *    described by the list of packetization descriptor. Typically, this
 *    number is just below the MTU size of the network.
 *
 *  @parm DWORD | dwMaxRTPPacketSize | Specifies the maximum RTP packet size
 *    (in bytes) to be described by the list of packetization descriptors.
 *
 *  @parm DWORD | dwLayerId | Specifies the ID of the encoding layer the
 *    call applies to. For standard audio and video encoders, this field is
 *    always set to 0. In the case of multi-layered encoders, this field
 *    shall be set to 0 for the base layer, 1 for the first enhancement
 *    layer, 2 for the next enhancement layer, etc
 *
 *  @rdesc This method returns an HRESULT value that depends on the
 *    implementation of the interface. HRESULT can include one of the
 *    following standard constants, or other values not listed:
 *
 *  @flag E_FAIL | Failure
 *  @flag E_INVALIDARG | Invalid argument
 *  @flag E_NOTIMPL | Method is not supported
 *  @flag NOERROR | No error
 ***************************************************************************/
STDMETHODIMP CRtpPdPin::SetMaxRTPPacketSize(IN DWORD dwMaxRTPPacketSize, IN DWORD dwLayerId)
{
        HRESULT Hr = NOERROR;

        FX_ENTRY("CRtpPdPin::SetMaxRTPPacketSize")

        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: begin", _fx_));

        // Validate input parameters
        ASSERT(dwMaxRTPPacketSize > 0);
        ASSERT(dwMaxRTPPacketSize <= 2048);
        ASSERT(dwLayerId == 0);
        if (dwLayerId || dwMaxRTPPacketSize == 0 || dwMaxRTPPacketSize > 2048)
        {
                // We don't implement multi-layered encoding in this filter
                DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: invalid input parameter", _fx_));
                Hr = E_INVALIDARG;
                goto MyExit;
        }

        // Save new target packet size
        m_dwMaxRTPPacketSize = dwMaxRTPPacketSize;

        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s:   New target RTP packet size: %ld", _fx_, m_dwMaxRTPPacketSize));

MyExit:
        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: end", _fx_));
        return Hr;
}

/****************************************************************************
 *  @doc INTERNAL CRTPPDPINMETHOD
 *
 *  @mfunc HRESULT | CRtpPdPin | GetMaxRTPPacketSize | This method is used to
 *    supply to the network sink filter the maximum RTP packet size (in bytes)
 *    described by the list of packetization descriptors.
 *
 *  @parm LPDWORD | pdwMaxRTPPacketSize | Specifies a pointer to a DWORD to
 *    receive the maximum RTP packet size (in bytes) described by the list of
 *    packetization descriptors.
 *
 *  @parm DWORD | dwLayerId | Specifies the ID of the encoding layer the
 *    call applies to. For standard audio and video encoders, this field is
 *    always set to 0. In the case of multi-layered encoders, this field
 *    shall be set to 0 for the base layer, 1 for the first enhancement
 *    layer, 2 for the next enhancement layer, etc
 *
 *  @rdesc This method returns an HRESULT value that depends on the
 *    implementation of the interface. HRESULT can include one of the
 *    following standard constants, or other values not listed:
 *
 *  @flag E_FAIL | Failure
 *  @flag E_POINTER | Null pointer argument
 *  @flag E_INVALIDARG | Invalid argument
 *  @flag E_NOTIMPL | Method is not supported
 *  @flag NOERROR | No error
 ***************************************************************************/
STDMETHODIMP CRtpPdPin::GetMaxRTPPacketSize(OUT LPDWORD pdwMaxRTPPacketSize, IN DWORD dwLayerId)
{
        HRESULT Hr = NOERROR;

        FX_ENTRY("CRtpPdPin::GetMaxRTPPacketSize")

        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: begin", _fx_));

        // Validate input parameters
        ASSERT(pdwMaxRTPPacketSize);
        if (!pdwMaxRTPPacketSize)
        {
                DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: Null pointer argument", _fx_));
                Hr = E_POINTER;
                goto MyExit;
        }
        ASSERT(dwLayerId == 0);
        if (dwLayerId)
        {
                // We don't implement multi-layered encoding in this filter
                DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: invalid input parameter", _fx_));
                Hr = E_INVALIDARG;
                goto MyExit;
        }

        // Return maximum packet size
        *pdwMaxRTPPacketSize = m_dwMaxRTPPacketSize;

        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s:   Current target RTP packet size: %ld", _fx_, m_dwMaxRTPPacketSize));

MyExit:
        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: end", _fx_));
        return Hr;
}

/****************************************************************************
 *  @doc INTERNAL CRTPPDPINMETHOD
 *
 *  @mfunc HRESULT | CRtpPdPin | GetMaxRTPPacketSizeRange | This method is
 *    used to supply to the network sink filter the minimum, maximum, and
 *    default values for the RTP packet size (in bytes) described by the list
 *    of packetization descriptors.
 *
 *  @parm LPDWORD | pdwMin | Used to retrieve the minimum RTP packet size (in
 *    bytes) described by the list of packetization descriptors.
 *
 *  @parm LPDWORD | pdwMax | Used to retrieve the maximum RTP packet size (in
 *    bytes) described by the list of packetization descriptors.
 *
 *  @parm LPDWORD | pdwSteppingDelta | Used to retrieve the stepping delta in
 *    RTP packet size (in bytes) described by the list of packetization
 *    descriptors.
 *
 *  @parm LPDWORD | pdwDefault | Used to retrieve the default RTP packet size
 *    (in bytes) described by the list of packetization descriptors.
 *
 *  @parm DWORD | dwLayerId | Specifies the ID of the encoding layer the
 *    call applies to. For standard audio and video encoders, this field is
 *    always set to 0. In the case of multi-layered encoders, this field
 *    shall be set to 0 for the base layer, 1 for the first enhancement
 *    layer, 2 for the next enhancement layer, etc
 *
 *  @rdesc This method returns an HRESULT value that depends on the
 *    implementation of the interface. HRESULT can include one of the
 *    following standard constants, or other values not listed:
 *
 *  @flag E_FAIL | Failure
 *  @flag E_POINTER | Null pointer argument
 *  @flag E_INVALIDARG | Invalid argument
 *  @flag E_NOTIMPL | Method is not supported
 *  @flag NOERROR | No error
 ***************************************************************************/
STDMETHODIMP CRtpPdPin::GetMaxRTPPacketSizeRange(OUT LPDWORD pdwMin, OUT LPDWORD pdwMax, OUT LPDWORD pdwSteppingDelta, OUT LPDWORD pdwDefault, IN DWORD dwLayerId)
{
        HRESULT Hr = NOERROR;

        FX_ENTRY("CRtpPdPin::GetMaxRTPPacketSizeRange")

        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: begin", _fx_));

        // Validate input parameters
        ASSERT(pdwMin);
        ASSERT(pdwMax);
        ASSERT(pdwSteppingDelta);
        ASSERT(pdwDefault);
        if (!pdwMin || !pdwMax || !pdwSteppingDelta || !pdwDefault)
        {
                DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: Null pointer argument", _fx_));
                Hr = E_POINTER;
                goto MyExit;
        }
        ASSERT(dwLayerId == 0);
        if (dwLayerId)
        {
                // We don't implement multi-layered encoding in this filter
                DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: invalid input parameter", _fx_));
                Hr = E_INVALIDARG;
                goto MyExit;
        }

        // Return relevant values
        *pdwMin = 0;
        *pdwMax = MAX_RTP_PACKET_SIZE;
        *pdwSteppingDelta = 1;
        *pdwDefault = DEFAULT_RTP_PACKET_SIZE;

        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s:   Ranges: Min=%ld, Max=%ld, Step=%ld, Default=%ld", _fx_, *pdwMin, *pdwMax, *pdwSteppingDelta, *pdwDefault));

MyExit:
        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: end", _fx_));
        return Hr;
}

/****************************************************************************
 *  @doc INTERNAL CRTPPDPINMETHOD
 *
 *  @mfunc HRESULT | CRtpPdPin | CapturePinActive | This method is called by the
 *    capture pin to let the RTPPD pin know that the capture pin is active.
 *
 *  @parm BOOL | fActive | Specifies the status of the capture pin.
 *
 *  @rdesc This method returns an HRESULT value that depends on the
 *    implementation of the interface. HRESULT can include one of the
 *    following standard constants, or other values not listed:
 *
 *  @flag E_FAIL | Failure
 *  @flag NOERROR | No error
 ***************************************************************************/
HRESULT CRtpPdPin::CapturePinActive(BOOL fActive)
{
        FX_ENTRY("CRtpPdPin::CapturePinActive")

        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: begin", _fx_));

        if (fActive == m_fCapturing)
                goto MyExit;

        m_fCapturing = fActive;

        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s:   Capture pin says Active=%s", _fx_, fActive ? "TRUE" : "FALSE"));

MyExit:
        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: end", _fx_));
        return NOERROR;
}

/****************************************************************************
 *  @doc INTERNAL CRTPPDPINMETHOD
 *
 *  @mfunc DWORD | CRtpPdPin | Flush | Called when stopping. Flush any
 *    buffers that may be still downstream.
 *
 *  @rdesc Returns NOERROR
 ***************************************************************************/
HRESULT CRtpPdPin::Flush()
{
        FX_ENTRY("CRtpPdPin::Flush")

        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: begin", _fx_));

        BeginFlush();
        EndFlush();

        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: end", _fx_));
        return NOERROR;
}


#ifdef DEBUG
//#define LOGPAYLOAD_ON 1
//#define LOGPAYLOAD_TOFILE 1
#endif
#ifdef LOGPAYLOAD_ON
int g_dbg_LOGPAYLOAD_RtpPd=-1;
#endif


/****************************************************************************
 *  @doc INTERNAL CRTPPDPINMETHOD
 *
 *  @mfunc HRESULT | CRtpPdPin | SendFrame | This method is used to
 *    send a a media sample downstream.
 *
 *  @parm CFrameSample | pSample | Specifies a pointer to the video media
 *    sample associated to the current Rtp Pd media sample.
 *
 *  @parm CRtpPdSample | pRSample | Specifies a pointer to the media sample
 *    to send downstream.
 *
 *  @parm BOOL | bDiscon | Set to TRUE if this is the first frame we ever
 *    sent downstream.
 *
 *  @rdesc This method returns an HRESULT value that depends on the
 *    implementation of the interface. HRESULT can include one of the
 *    following standard constants, or other values not listed:
 *
 *  @flag E_FAIL | Failure
 *  @flag E_POINTER | Null pointer argument
 *  @flag S_OK | No error
 *  @flag S_FALSE | If the pin is off (IAMStreamControl)
 *  @flag NOERROR | No error
 ***************************************************************************/
HRESULT CRtpPdPin::SendFrame(IN CFrameSample *pSample, IN CRtpPdSample *pRSample, IN DWORD dwBytesExtent, IN BOOL bDiscon)
{
        HRESULT                                         Hr = NOERROR;
    LPBYTE                                              pbySrc = NULL;
    LPBYTE                                              pbyDst;
    DWORD                                               dwDstBufferSize;
        int                                                     iStreamState;
        PH26X_RTP_BSINFO_TRAILER        pbsiT;
        PRTP_H263_BSINFO                        pbsi263;
        PRTP_H261_BSINFO                        pbsi261;
        BOOL                                            bOneFrameOnePacket = FALSE;
        DWORD                                           dwPktCount = 0;
        DWORD                                           dwHeaderHigh; // most significant
        DWORD                                           dwHeaderLow; // least significant
        PRTP_PD_HEADER                          pRtpPdHeader;
        PRTP_PD                                         pRtpPd;
        PBYTE                                           pbyPayloadHeader;
        REFERENCE_TIME                          rtSample;
        REFERENCE_TIME                          rtEnd;
        int                                                     i;
#if defined(LOGPAYLOAD_ON) || defined(LOGPAYLOAD_TOFILE)
        DWORD                                           dwPktSize;
        char                                            szDebug[256];
        HANDLE                                          g_DebugFile = (HANDLE)NULL;
        HANDLE                                          g_TDebugFile = (HANDLE)NULL;
        PBYTE                                           p;
        DWORD                                           d, GOBn;
        int                                                     wPrevOffset;
#endif

        FX_ENTRY("CRtpPdPin::SendFrame")

        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: begin", _fx_));

        RTPPayloadHeaderMode RTPPayloadHeaderModeValue=m_pCaptureFilter->m_RTPPayloadHeaderMode; //initial this is RTPPayloadHeaderMode_Draft;


        // Validate input parameters
        ASSERT(pSample);
        ASSERT(pRSample);
        if (!pSample || !pRSample)
        {
                DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: Null pointer argument!", _fx_));
                Hr = E_POINTER;
                goto MyExit;
        }

        // The information we need is at the end of the compressed video buffer
        if (!(SUCCEEDED(Hr = pSample->GetPointer(&pbySrc)) && pbySrc && SUCCEEDED(Hr = pRSample->GetPointer(&pbyDst)) && pbyDst && dwBytesExtent && (dwDstBufferSize = pRSample->GetSize())))
        {
                DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: Null pointer argument!", _fx_));
                Hr = E_POINTER;
                goto MyExit;
        }

        // Point to the output buffer
        pRtpPdHeader = (PRTP_PD_HEADER)pbyDst;
        pRtpPdHeader->dwThisHeaderLength = sizeof(RTP_PD_HEADER);
        pRtpPdHeader->dwReserved = 0;
        pRtpPdHeader->dwNumHeaders = 0;
        pRtpPd = (PRTP_PD)(pbyDst + sizeof(RTP_PD_HEADER));

        // Let's break up that H.263 frame...
        if (HEADER(m_pCaptureFilter->m_pCapturePin->m_mt.pbFormat)->biCompression == FOURCC_M263)
        {
                // Look for the bitstream info trailer
                pbsiT = (PH26X_RTP_BSINFO_TRAILER)(pbySrc + dwBytesExtent - sizeof(H26X_RTP_BSINFO_TRAILER));

                // Point in the buffer for the worst case
                pbyPayloadHeader = pbyDst + sizeof(RTP_PD_HEADER) + sizeof(RTP_PD) * pbsiT->dwNumOfPackets;

                // If the whole frame can fit in m_dwMaxRTPPacketSize, send it non fragmented
                if ((pbsiT->dwCompressedSize + 4) < m_dwMaxRTPPacketSize)
                        bOneFrameOnePacket = TRUE;

                // Look for the packet to receive a H.263 payload header
                while ((dwPktCount < pbsiT->dwNumOfPackets) && !(bOneFrameOnePacket && dwPktCount))
                {
                        pRtpPd->dwThisHeaderLength = sizeof(RTP_PD);
                        pRtpPd->dwLayerId = 0;
                        pRtpPd->dwVideoAttributes = 0;
                        pRtpPd->dwReserved = 0;
                        // @todo Update the timestamp field!
                        pRtpPd->dwTimestamp = 0xFFFFFFFF;
                        pRtpPd->dwPayloadHeaderOffset = pbyPayloadHeader - pbyDst;
                        pRtpPd->fEndMarkerBit = TRUE;

#ifdef LOGPAYLOAD_TOFILE
                        // Dump the whole frame in the debug window for comparison with receive side
                        if (!dwPktCount)
                        {
                                g_DebugFile = CreateFile("C:\\SendLog.txt", GENERIC_WRITE, 0, NULL, OPEN_ALWAYS, FILE_ATTRIBUTE_NORMAL, (HANDLE)NULL);
                                SetFilePointer(g_DebugFile, 0, NULL, FILE_END);
                                wsprintf(szDebug, "Frame #%03ld\r\n", (DWORD)pbsiT->byTR);
                                WriteFile(g_DebugFile, szDebug, strlen(szDebug), &d, NULL);
                                wsprintf(szDebug, "Frame #%03ld has %1ld packets of size ", (DWORD)pbsiT->byTR, (DWORD)pbsiT->dwNumOfPackets);
                                OutputDebugString(szDebug);
                                pbsi263 = (PRTP_H263_BSINFO)((PBYTE)pbsiT - pbsiT->dwNumOfPackets * sizeof(RTP_H263_BSINFO));
                                for (wPrevOffset=0, i=1; i<(long)pbsiT->dwNumOfPackets; i++)
                                {
                                        wPrevOffset = pbsi263->dwBitOffset;
                                        pbsi263++;
                                        wsprintf(szDebug, "%04ld (S: %ld E: %ld), ", (DWORD)(pbsi263->dwBitOffset - wPrevOffset) >> 3, wPrevOffset, pbsi263->dwBitOffset);
                                        OutputDebugString(szDebug);
                                }
                                wsprintf(szDebug, "%04ld (S: %ld E: %ld)\r\n", (DWORD)(pbsiT->dwCompressedSize * 8 - pbsi263->dwBitOffset) >> 3, pbsi263->dwBitOffset, pbsiT->dwCompressedSize * 8);
                                OutputDebugString(szDebug);
                                for (i=pbsiT->dwCompressedSize, p=pbySrc; i>0; i-=4, p+=4)
                                {
                                        wsprintf(szDebug, "%02lX %02lX %02lX %02lX\r\n", *((BYTE *)p), *((BYTE *)p+1), *((BYTE *)p+2), *((BYTE *)p+3));
                                        WriteFile(g_DebugFile, szDebug, strlen(szDebug), &d, NULL);
                                }
                                CloseHandle(g_DebugFile);
                        }
#endif

                        // Look for the bitstream info structure
                        pbsi263 = (PRTP_H263_BSINFO)((PBYTE)pbsiT - (pbsiT->dwNumOfPackets - dwPktCount) * sizeof(RTP_H263_BSINFO));

                        // Set the marker bit: as long as this is not the last packet of the frame
                        // this bit needs to be set to 0
                        if (!bOneFrameOnePacket)
                        {
                                // Count the number of GOBS that could fit in m_dwMaxRTPPacketSize
                                for (i=1; (i<(long)(pbsiT->dwNumOfPackets - dwPktCount)) && (pbsi263->byMode != RTP_H263_MODE_B); i++)
                                {
                                        // Don't try to add a Mode B packet to the end of another Mode A or Mode B packet
                                        if (((pbsi263+i)->dwBitOffset - pbsi263->dwBitOffset > (m_dwMaxRTPPacketSize * 8)) || ((pbsi263+i)->byMode == RTP_H263_MODE_B))
                                                break;
                                }

                                if (i < (long)(pbsiT->dwNumOfPackets - dwPktCount))
                                {
                                        pRtpPd->fEndMarkerBit = FALSE;
                                        if (i>1)
                                                i--;
                                }
                                else
                                {
                                        // Hey! You 're forgetting the last GOB! It could make the total
                                        // size of the last packet larger than m_dwMaxRTPPacketSize... Imbecile!
                                        if ((pbsiT->dwCompressedSize * 8 - pbsi263->dwBitOffset > (m_dwMaxRTPPacketSize * 8)) && (i>1))
                                        {
                                                pRtpPd->fEndMarkerBit = FALSE;
                                                i--;
                                        }
                                }
                        }

                        // Go to the beginning of the data
                        pRtpPd->dwPayloadStartBitOffset = pbsi263->dwBitOffset;

                        // Look for the kind of header to be built
                        if (pbsi263->byMode == RTP_H263_MODE_A)
                        {
                                // Build a header in mode A

                                // Header in mode A (!!! DRAFT VERSION !!!)
                                // 0                   1                   2                   3
                                // 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1
                                //+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
                                //|F|P|SBIT |EBIT | SRC | R       |I|A|S|DBQ| TRB |    TR         |
                                //+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
                                // But that's the network byte order...

                                // Header in mode A (*** RFC 2190 VERSION ***)
                                // 0                   1                   2                   3
                                // 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1
                                //+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
                                //|F|P|SBIT |EBIT | SRC |I|U|S|A|R      |DBQ| TRB |    TR         |
                                //+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+

                                // F bit set to 0
                                dwHeaderHigh = 0x00000000;

                                // Set the SRC bits
                                dwHeaderHigh |= ((DWORD)(pbsiT->bySrc)) << 21;

                                // R bits already set to 0

                                // Set the P bit
                                dwHeaderHigh |= (pbsiT->dwFlags & RTP_H263_PB) << 29;

                                if(RTPPayloadHeaderModeValue==RTPPayloadHeaderMode_Draft) {  // 0 is the default mode
                                    // Set the I bit
                                    dwHeaderHigh |= (pbsiT->dwFlags & RTP_H26X_INTRA_CODED) << 15;

                                    // Set the A bit
                                    dwHeaderHigh |= (pbsiT->dwFlags & RTP_H263_AP) << 12;

                                    // Set the S bit
                                    dwHeaderHigh |= (pbsiT->dwFlags & RTP_H263_SAC) << 10;
                                } else {
                                    // Set the I bit
                                    dwHeaderHigh |= (pbsiT->dwFlags & RTP_H26X_INTRA_CODED) << 20;

                                    // Set the U bit
                                    dwHeaderHigh |= (pbsiT->dwFlags & RTP_H263_UMV) << 15;

                                    // Set the S bit
                                    dwHeaderHigh |= (pbsiT->dwFlags & RTP_H263_SAC) << 15;

                                    // Set the A bit
                                    dwHeaderHigh |= (pbsiT->dwFlags & RTP_H263_AP) << 15;
                                }

                                // Set the DBQ bits
                                dwHeaderHigh |= ((DWORD)(pbsiT->byDBQ)) << 11;

                                // Set the TRB bits
                                dwHeaderHigh |= ((DWORD)(pbsiT->byTRB)) << 8;

                                // Set the TR bits
                                dwHeaderHigh |= ((DWORD)(pbsiT->byTR));

                                // Special case: 1 frame = 1 packet
                                if (bOneFrameOnePacket)
                                {
                                        // SBIT is already set to 0

                                        // EBIT is already set to 0

                                        // Update the packet size
#ifdef LOGPAYLOAD_ON
                                        dwPktSize = pbsiT->dwCompressedSize + 4;
#endif
                                        pRtpPd->dwPayloadEndBitOffset = pbsiT->dwCompressedSize * 8 - 1;

                                        // Update the packet count
                                        dwPktCount = pbsiT->dwNumOfPackets;
                                }
                                else
                                {
                                        // Set the SBIT bits
                                        dwHeaderHigh |= (pbsi263->dwBitOffset % 8) << 27;

                                        // Set the EBIT bits
                                        if ((pbsiT->dwNumOfPackets - dwPktCount - i) >= 1)
                                        {
                                                dwHeaderHigh |= (DWORD)((8UL - ((pbsi263+i)->dwBitOffset % 8)) & 0x00000007) << 24;
                                                pRtpPd->dwPayloadEndBitOffset = (pbsi263+i)->dwBitOffset - 1;
                                        }
                                        else
                                        {
                                                pRtpPd->dwPayloadEndBitOffset = pbsiT->dwCompressedSize * 8 - 1;
                                        }

#ifdef LOGPAYLOAD_ON
                                        // Update the packet size
                                        if ((pbsiT->dwNumOfPackets - dwPktCount - i) >= 1)
                                                dwPktSize = (((pbsi263+i)->dwBitOffset - 1) / 8) - (pbsi263->dwBitOffset / 8) + 1 + 4;
                                        else
                                                dwPktSize = pbsiT->dwCompressedSize - pbsi263->dwBitOffset / 8 + 4;
#endif
                                        // Update the packet count
                                        dwPktCount += i;
                                }

                                // Save the payload header
                                pRtpPd->dwPayloadHeaderLength = 4;

                if ((DWORD)(pbyPayloadHeader - pbyDst) + pRtpPd->dwPayloadHeaderLength > dwDstBufferSize)
                {
                            DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s: buffer too small. size:%d", _fx_, dwDstBufferSize));
                            Hr = S_FALSE;
                            goto MyExit;
                }

                                // Convert to network byte order
                                *(pbyPayloadHeader+3) = (BYTE)(dwHeaderHigh & 0x000000FF);
                                *(pbyPayloadHeader+2) = (BYTE)((dwHeaderHigh >> 8) & 0x000000FF);
                                *(pbyPayloadHeader+1) = (BYTE)((dwHeaderHigh >> 16) & 0x000000FF);
                                *(pbyPayloadHeader) = (BYTE)((dwHeaderHigh >> 24) & 0x000000FF);

#ifdef LOGPAYLOAD_ON
                                // Output some debug stuff
                                wsprintf(szDebug, "Header content:\r\n");
                                OutputDebugString(szDebug);
                                wsprintf(szDebug, (*pbyPayloadHeader & 0x80) ? "     F:   '1' => Mode B or C\r\n" : "     F:   '0' => Mode A\r\n");
                                OutputDebugString(szDebug);
                                wsprintf(szDebug, (*pbyPayloadHeader & 0x40) ? "     P:   '1' => PB-frame\r\n" : "     P:   '0' => I or P frame\r\n");
                                OutputDebugString(szDebug);
                                wsprintf(szDebug, "  SBIT:    %01ld\r\n", (DWORD)((*pbyPayloadHeader & 0x38) >> 3));
                                OutputDebugString(szDebug);
                                wsprintf(szDebug, "  EBIT:    %01ld\r\n", (DWORD)(*pbyPayloadHeader & 0x07));
                                OutputDebugString(szDebug);
                                switch ((DWORD)(*(pbyPayloadHeader+1) >> 5))
                                {
                                        case 0:
                                                wsprintf(szDebug, "   SRC: '000' => Source format forbidden!\r\n");
                                                break;
                                        case 1:
                                                wsprintf(szDebug, "   SRC: '001' => Source format sub-QCIF\r\n");
                                                break;
                                        case 2:
                                                wsprintf(szDebug, "   SRC: '010' => Source format QCIF\r\n");
                                                break;
                                        case 3:
                                                wsprintf(szDebug, "   SRC: '011' => Source format CIF\r\n");
                                                break;
                                        case 4:
                                                wsprintf(szDebug, "   SRC: '100' => Source format 4CIF\r\n");
                                                break;
                                        case 5:
                                                wsprintf(szDebug, "   SRC: '101' => Source format 16CIF\r\n");
                                                break;
                                        case 6:
                                                wsprintf(szDebug, "   SRC: '110' => Source format reserved\r\n");
                                                break;
                                        case 7:
                                                wsprintf(szDebug, "   SRC: '111' => Source format reserved\r\n");
                                                break;
                                        default:
                                                wsprintf(szDebug, "   SRC: %ld => Source format unknown!\r\n", (DWORD)(*(pbyPayloadHeader+1) >> 5));
                                                break;
                                }
                                OutputDebugString(szDebug);

                                if(RTPPayloadHeaderModeValue==RTPPayloadHeaderMode_Draft) {
                                    OutputDebugString("Draft Style Payload Header flags (MODE A):\r\n");
                                    wsprintf(szDebug, "     R:   %02ld  => Reserved, must be 0\r\n", (DWORD)(pbyPayloadHeader[1] & 0x1F)); // no need for ">> 5"
                                    OutputDebugString(szDebug);
                                    wsprintf(szDebug, (pbyPayloadHeader[2] & 0x80) ? "     I:   '1' => Intra-coded\r\n" : "     I:   '0' => Not Intra-coded\r\n");
                                    OutputDebugString(szDebug);
                                    wsprintf(szDebug, (pbyPayloadHeader[2] & 0x40) ? "     A:   '1' => Optional Advanced Prediction mode ON\r\n" : "     A:   '0' => Optional Advanced Prediction mode OFF\r\n");
                                    OutputDebugString(szDebug);
                                    wsprintf(szDebug, (pbyPayloadHeader[2] & 0x20) ? "     S:   '1' => Optional Syntax-based Arithmetic Code mode ON\r\n" : "     S:   '0' => Optional Syntax-based Arithmetic Code mode OFF\r\n");
                                    OutputDebugString(szDebug);
                                } else {
                                    OutputDebugString("RFC 2190 Style Payload Header flags (MODE A):\r\n");
                                    wsprintf(szDebug, "     R:   %02ld  => Reserved, must be 0\r\n", (DWORD)((pbyPayloadHeader[1] & 0x01) << 3) | (DWORD)((pbyPayloadHeader[2] & 0xE0) >> 5));
                                    OutputDebugString(szDebug);
                                    wsprintf(szDebug, (pbyPayloadHeader[1] & 0x10) ? "     I:   '1' => Intra-coded\r\n" : "     I:   '0' => Not Intra-coded\r\n");
                                    OutputDebugString(szDebug);
                                    wsprintf(szDebug, (pbyPayloadHeader[1] & 0x08) ? "     U:   '1' => Unrestricted Motion Vector (bit10) was set in crt.pic.hdr.\r\n" : "     U:   '0' => Unrestricted Motion Vector (bit10) was 0 in crt.pic.hdr.\r\n");
                                    OutputDebugString(szDebug);
                                    wsprintf(szDebug, (pbyPayloadHeader[1] & 0x04) ? "     S:   '1' => Optional Syntax-based Arithmetic Code mode ON\r\n" : "     S:   '0' => Optional Syntax-based Arithmetic Code mode OFF\r\n");
                                    OutputDebugString(szDebug);
                                    wsprintf(szDebug, (pbyPayloadHeader[1] & 0x02) ? "     A:   '1' => Optional Advanced Prediction mode ON\r\n" : "     A:   '0' => Optional Advanced Prediction mode OFF\r\n");
                                    OutputDebugString(szDebug);
                                }

                                wsprintf(szDebug, "   DBQ:    %01ld  => Should be 0\r\n", (DWORD)((*(pbyPayloadHeader+2) & 0x18) >> 3));
                                OutputDebugString(szDebug);
                                wsprintf(szDebug, "   TRB:    %01ld  => Should be 0\r\n", (DWORD)(*(pbyPayloadHeader+2) & 0x07));
                                OutputDebugString(szDebug);
                                wsprintf(szDebug, "    TR:  %03ld\r\n", (DWORD)(*(pbyPayloadHeader+3)));
                                OutputDebugString(szDebug);
                                wsprintf(szDebug, "Packet: %02lX\r\n Header: %02lX %02lX %02lX %02lX\r\n", dwPktCount, *(pbyPayloadHeader), *(pbyPayloadHeader+1), *(pbyPayloadHeader+2), *(pbyPayloadHeader+3));
                                OutputDebugString(szDebug);
                                if (pRtpPd->fEndMarkerBit == TRUE)
                                        wsprintf(szDebug, " Marker: ON\r\n");
                                else
                                        wsprintf(szDebug, " Marker: OFF\r\n");
                                OutputDebugString(szDebug);
                                wsprintf(szDebug, "Frame #%03ld, Packet of size %04ld\r\n", (DWORD)pbsiT->byTR, dwPktSize);
                                OutputDebugString(szDebug);
                                if(g_dbg_LOGPAYLOAD_RtpPd > 0)
                                        g_dbg_LOGPAYLOAD_RtpPd--;
                                else if(g_dbg_LOGPAYLOAD_RtpPd == 0)
                                        DebugBreak();
#endif
                        }
                        else if (pbsi263->byMode == RTP_H263_MODE_B)
                        {
                                // Build a header in mode B

                                // Header in mode B (!!! DRAFT VERSION !!!)
                                // 0                   1                   2                   3
                                // 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1
                                //+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
                                //|F|P|SBIT |EBIT | SRC | QUANT   |I|A|S|  GOBN   |   MBA         |
                                //+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
                                //| HMV1          |  VMV1         |  HMV2         |   VMV2        |
                                //+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+

                                // But that's the network byte order...

                                // Header in mode B (*** RFC 2190 VERSION ***)
                                // 0                   1                   2                   3
                                // 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1
                                //+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
                                //|F|P|SBIT |EBIT | SRC | QUANT   |  GOBN   |   MBA           | R |
                                //+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
                                //|I|U|S|A| HMV1        |  VMV1       |  HMV2       |   VMV2      |
                                //+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+


                                // Set the F bit to 1
                                dwHeaderHigh = 0x80000000;
                                dwHeaderLow  = 0x00000000;

                                // Set the SRC bits
                                dwHeaderHigh |= ((DWORD)(pbsiT->bySrc)) << 21;

                                // Set the QUANT bits
                                dwHeaderHigh |= ((DWORD)(pbsi263->byQuant)) << 16;

                                // Set the P bit
                                dwHeaderHigh |= (pbsiT->dwFlags & RTP_H263_PB) << 29;

                                if(RTPPayloadHeaderModeValue==RTPPayloadHeaderMode_Draft) {
                                    // Set the I bit
                                    dwHeaderHigh |= (pbsiT->dwFlags & RTP_H26X_INTRA_CODED) << 15;

                                    // Set the A bit
                                    dwHeaderHigh |= (pbsiT->dwFlags & RTP_H263_AP) << 12;

                                    // Set the S bit
                                    dwHeaderHigh |= (pbsiT->dwFlags & RTP_H263_SAC) << 10;

                                    // Set the GOBN bits
                                    dwHeaderHigh |= ((DWORD)(pbsi263->byGOBN)) << 8;

                                    // Set the TR bits
                                    dwHeaderHigh |= ((DWORD)(pbsi263->byMBA));

                                    // Set the HMV1 bits
                                    dwHeaderLow |= ((DWORD)(BYTE)(pbsi263->cHMV1)) << 24;

                                    // Set the VMV1 bits
                                    dwHeaderLow |= ((DWORD)(BYTE)(pbsi263->cVMV1)) << 16;

                                    // Set the HMV2 bits
                                    dwHeaderLow |= ((DWORD)(BYTE)(pbsi263->cHMV2)) << 8;

                                    // Set the VMV2 bits
                                    dwHeaderLow |= ((DWORD)(BYTE)(pbsi263->cVMV2));
                                } else {
                                    // Set the I bit
                                    dwHeaderLow |= (pbsiT->dwFlags & RTP_H26X_INTRA_CODED) << 31;

                                    // Set the U bit
                                    dwHeaderHigh |= (pbsiT->dwFlags & RTP_H263_UMV) << 26;

                                    // Set the S bit
                                    dwHeaderHigh |= (pbsiT->dwFlags & RTP_H263_SAC) << 26;

                                    // Set the A bit
                                    dwHeaderHigh |= (pbsiT->dwFlags & RTP_H263_AP) << 26;

                                    // Set the GOBN bits
                                    dwHeaderHigh |= ((DWORD)(pbsi263->byGOBN)) << 11;

                                    // Set the TR bits
                                    dwHeaderHigh |= ((DWORD)(pbsi263->byMBA)) << 2;

                                    // Set the HMV1 bits
                                    dwHeaderLow |= ((DWORD)(BYTE)(pbsi263->cHMV1) & 0x7F) << 21;

                                    // Set the VMV1 bits
                                    dwHeaderLow |= ((DWORD)(BYTE)(pbsi263->cVMV1) & 0x7F) << 14;

                                    // Set the HMV2 bits
                                    dwHeaderLow |= ((DWORD)(BYTE)(pbsi263->cHMV2) & 0x7F) << 7;

                                    // Set the VMV2 bits
                                    dwHeaderLow |= ((DWORD)(BYTE)(pbsi263->cVMV2) & 0x7F);
                                }

                                // Special case: 1 frame = 1 packet
                                if (bOneFrameOnePacket)
                                {
                                        // SBIT is already set to 0

                                        // EBIT is already set to 0

                                        // Update the packet size
#ifdef LOGPAYLOAD_ON
                                        dwPktSize = pbsiT->dwCompressedSize + 8;
#endif
                                        pRtpPd->dwPayloadEndBitOffset = pbsiT->dwCompressedSize * 8 - 1;

                                        // Update the packet count
                                        dwPktCount = pbsiT->dwNumOfPackets;
                                }
                                else
                                {
                                        // Set the SBIT bits
                                        dwHeaderHigh |= (pbsi263->dwBitOffset % 8) << 27;

                                        // Set the EBIT bits
                                        if ((pbsiT->dwNumOfPackets - dwPktCount - i) >= 1)
                                        {
                                                dwHeaderHigh |= (DWORD)((8UL - ((pbsi263+i)->dwBitOffset % 8)) & 0x00000007) << 24;
                                                pRtpPd->dwPayloadEndBitOffset = (pbsi263+i)->dwBitOffset - 1;
                                        }
                                        else
                                        {
                                                pRtpPd->dwPayloadEndBitOffset = pbsiT->dwCompressedSize * 8 - 1;
                                        }

#ifdef LOGPAYLOAD_ON
                                        // Update the packet size
                                        if ((pbsiT->dwNumOfPackets - dwPktCount - i) >= 1)
                                                dwPktSize = (((pbsi263+i)->dwBitOffset - 1) / 8) - (pbsi263->dwBitOffset / 8) + 1 + 8;
                                        else
                                                dwPktSize = pbsiT->dwCompressedSize - pbsi263->dwBitOffset / 8 + 8;
#endif
                                        // Update the packet count
                                        dwPktCount += i;
                                }

                                // Save the payload header
                                pRtpPd->dwPayloadHeaderLength = 8;

                if ((DWORD)(pbyPayloadHeader - pbyDst) + pRtpPd->dwPayloadHeaderLength > dwDstBufferSize)
                {
                            DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s: buffer too small. size:%d", _fx_, dwDstBufferSize));
                            Hr = S_FALSE;
                            goto MyExit;
                }

                                // Convert to network byte order
                                *(pbyPayloadHeader+3) = (BYTE)(dwHeaderHigh & 0x000000FF);
                                *(pbyPayloadHeader+2) = (BYTE)((dwHeaderHigh >> 8) & 0x000000FF);
                                *(pbyPayloadHeader+1) = (BYTE)((dwHeaderHigh >> 16) & 0x000000FF);
                                *(pbyPayloadHeader) = (BYTE)((dwHeaderHigh >> 24) & 0x000000FF);
                                *(pbyPayloadHeader+7) = (BYTE)(dwHeaderLow & 0x000000FF);
                                *(pbyPayloadHeader+6) = (BYTE)((dwHeaderLow >> 8) & 0x000000FF);
                                *(pbyPayloadHeader+5) = (BYTE)((dwHeaderLow >> 16) & 0x000000FF);
                                *(pbyPayloadHeader+4) = (BYTE)((dwHeaderLow >> 24) & 0x000000FF);

#ifdef LOGPAYLOAD_ON
                                // Output some info
                                wsprintf(szDebug, "Header content:\r\n");
                                OutputDebugString(szDebug);
                                wsprintf(szDebug, (*pbyPayloadHeader & 0x80) ? "     F:   '1' => Mode B or C\r\n" : "     F:   '0' => Mode A\r\n");
                                OutputDebugString(szDebug);
                                wsprintf(szDebug, (*pbyPayloadHeader & 0x40) ? "     P:   '1' => PB-frame\r\n" : "     P:   '0' => I or P frame\r\n");
                                OutputDebugString(szDebug);
                                wsprintf(szDebug, "  SBIT:    %01ld\r\n", (DWORD)((*pbyPayloadHeader & 0x38) >> 3));
                                OutputDebugString(szDebug);
                                wsprintf(szDebug, "  EBIT:    %01ld\r\n", (DWORD)(*pbyPayloadHeader & 0x07));
                                OutputDebugString(szDebug);
                                switch ((DWORD)(*(pbyPayloadHeader+1) >> 5))
                                {
                                        case 0:
                                                wsprintf(szDebug, "   SRC: '000' => Source format forbidden!\r\n");
                                                break;
                                        case 1:
                                                wsprintf(szDebug, "   SRC: '001' => Source format sub-QCIF\r\n");
                                                break;
                                        case 2:
                                                wsprintf(szDebug, "   SRC: '010' => Source format QCIF\r\n");
                                                break;
                                        case 3:
                                                wsprintf(szDebug, "   SRC: '011' => Source format CIF\r\n");
                                                break;
                                        case 4:
                                                wsprintf(szDebug, "   SRC: '100' => Source format 4CIF\r\n");
                                                break;
                                        case 5:
                                                wsprintf(szDebug, "   SRC: '101' => Source format 16CIF\r\n");
                                                break;
                                        case 6:
                                                wsprintf(szDebug, "   SRC: '110' => Source format reserved\r\n");
                                                break;
                                        case 7:
                                                wsprintf(szDebug, "   SRC: '111' => Source format reserved\r\n");
                                                break;
                                        default:
                                                wsprintf(szDebug, "   SRC: %ld => Source format unknown!\r\n", (DWORD)(*(pbyPayloadHeader+1) >> 5));
                                                break;
                                }
                                OutputDebugString(szDebug);
                                wsprintf(szDebug, " QUANT:   %02ld\r\n", (DWORD)((*(pbyPayloadHeader+1) & 0x1F) >> 5));
                                OutputDebugString(szDebug);

                                if(RTPPayloadHeaderModeValue==RTPPayloadHeaderMode_Draft) {
                                    wsprintf(szDebug, (pbyPayloadHeader[2] & 0x80) ? "     I:   '1' => Intra-coded\r\n" : "     I:   '0' => Not Intra-coded\r\n");
                                    OutputDebugString(szDebug);
                                    wsprintf(szDebug, (pbyPayloadHeader[2] & 0x40) ? "     A:   '1' => Optional Advanced Prediction mode ON\r\n" : "     A:   '0' => Optional Advanced Prediction mode OFF\r\n");
                                    OutputDebugString(szDebug);
                                    wsprintf(szDebug, (pbyPayloadHeader[2] & 0x20) ? "     S:   '1' => Optional Syntax-based Arithmetic Code mode ON\r\n" : "     S:   '0' => Optional Syntax-based Arithmetic Code mode OFF\r\n");
                                    OutputDebugString(szDebug);
                                    wsprintf(szDebug, "  GOBN:  %03ld\r\n", (DWORD)(pbyPayloadHeader[2] & 0x1F));
                                    OutputDebugString(szDebug);
                                    wsprintf(szDebug, "   MBA:  %03ld\r\n", (DWORD)(pbyPayloadHeader[3]));
                                    OutputDebugString(szDebug);
                                    wsprintf(szDebug, "  HMV1:  %03ld\r\n", (DWORD)(pbyPayloadHeader[7]));
                                    OutputDebugString(szDebug);
                                    wsprintf(szDebug, "  VMV1:  %03ld\r\n", (DWORD)(pbyPayloadHeader[6]));
                                    OutputDebugString(szDebug);
                                    wsprintf(szDebug, "  HMV2:  %03ld\r\n", (DWORD)(pbyPayloadHeader[5]));
                                    OutputDebugString(szDebug);
                                    wsprintf(szDebug, "  VMV2:  %03ld\r\n", (DWORD)(pbyPayloadHeader[4]));
                                    OutputDebugString(szDebug);
                                } else {
                                    wsprintf(szDebug, (pbyPayloadHeader[4] & 0x80) ? "     I:   '1' => Intra-coded\r\n" : "     I:   '0' => Not Intra-coded\r\n");
                                    OutputDebugString(szDebug);
                                    wsprintf(szDebug, (pbyPayloadHeader[4] & 0x40) ? "     U:   '1' => Unrestricted Motion Vector (bit10) was set in crt.pic.hdr.\r\n" : "     U:   '0' => Unrestricted Motion Vector (bit10) was 0 in crt.pic.hdr.\r\n");
                                    OutputDebugString(szDebug);
                                    wsprintf(szDebug, (pbyPayloadHeader[4] & 0x20) ? "     S:   '1' => Optional Syntax-based Arithmetic Code mode ON\r\n" : "     S:   '0' => Optional Syntax-based Arithmetic Code mode OFF\r\n");
                                    OutputDebugString(szDebug);
                                    wsprintf(szDebug, (pbyPayloadHeader[4] & 0x10) ? "     A:   '1' => Optional Advanced Prediction mode ON\r\n" : "     A:   '0' => Optional Advanced Prediction mode OFF\r\n");
                                    OutputDebugString(szDebug);
                                    wsprintf(szDebug, "  GOBN:  %03ld\r\n", (DWORD)(pbyPayloadHeader[2] & 0xF8) >>3);
                                    OutputDebugString(szDebug);
                                    wsprintf(szDebug, "   MBA:  %03ld\r\n", (DWORD)((pbyPayloadHeader[2] & 0x07) << 6) | (DWORD)((pbyPayloadHeader[3] & 0xFC) >> 2));
                                    OutputDebugString(szDebug);
                                    wsprintf(szDebug, "     R:   %02ld  => Reserved, must be 0\r\n", (DWORD)(pbyPayloadHeader[3] & 0x03));
                                    OutputDebugString(szDebug);
                                    wsprintf(szDebug, "  HMV1:  %03ld\r\n", (DWORD)((pbyPayloadHeader[4] & 0x0F) << 3) | (DWORD)((pbyPayloadHeader[5] & 0xE0) >> 5));
                                    OutputDebugString(szDebug);
                                    wsprintf(szDebug, "  VMV1:  %03ld\r\n", (DWORD)((pbyPayloadHeader[5] & 0x1F) << 2) | (DWORD)((pbyPayloadHeader[6] & 0xC0) >> 6));
                                    OutputDebugString(szDebug);
                                    wsprintf(szDebug, "  HMV2:  %03ld\r\n", (DWORD)((pbyPayloadHeader[6] & 0x3F) << 1) | (DWORD)((pbyPayloadHeader[7] & 0x80) >> 7));
                                    OutputDebugString(szDebug);
                                    wsprintf(szDebug, "  VMV2:  %03ld\r\n", (DWORD)(pbyPayloadHeader[7] & 0x7F));
                                    OutputDebugString(szDebug);
                                }

                                wsprintf(szDebug, "Packet: %02lX\r\n Header: %02lX %02lX %02lX %02lX %02lX %02lX %02lX %02lX\r\n", dwPktCount, *(pbyPayloadHeader), *(pbyPayloadHeader+1), *(pbyPayloadHeader+2), *(pbyPayloadHeader+3), *(pbyPayloadHeader+4), *(pbyPayloadHeader+5), *(pbyPayloadHeader+6), *(pbyPayloadHeader+7));
                                OutputDebugString(szDebug);

                                if (pRtpPd->fEndMarkerBit == TRUE)
                                        wsprintf(szDebug, " Marker: ON\r\n");
                                else
                                        wsprintf(szDebug, " Marker: OFF\r\n");
                                OutputDebugString(szDebug);
                                wsprintf(szDebug, "Frame #%03ld, Packet of size %04ld\r\n", (DWORD)pbsiT->byTR, dwPktSize);
                                OutputDebugString(szDebug);
#endif
                        }

                        // Move to the next potential header position
                        pbyPayloadHeader += pRtpPd->dwPayloadHeaderLength;
                        pRtpPd++;
                }

                // Update the number of headers
                pRtpPdHeader->dwNumHeaders = ((long)((PBYTE)pRtpPd - pbyDst) + sizeof(RTP_PD_HEADER)) / sizeof(RTP_PD);
                pRtpPdHeader->dwTotalByteLength = (DWORD)(pbyPayloadHeader - pbyDst);
        }
        else // Let's break up that H.261 frame...
        {
                // Look for the bitstream info trailer
                pbsiT = (PH26X_RTP_BSINFO_TRAILER)(pbySrc + dwBytesExtent - sizeof(H26X_RTP_BSINFO_TRAILER));

                // Point in the buffer for the worst case
                pbyPayloadHeader = pbyDst + sizeof(RTP_PD_HEADER) + sizeof(RTP_PD) * pbsiT->dwNumOfPackets;

                // If the whole frame can fit in m_dwMaxRTPPacketSize, send it non fragmented
                if ((pbsiT->dwCompressedSize + 4) < m_dwMaxRTPPacketSize)
                        bOneFrameOnePacket = TRUE;

                // Look for the packet to receive a H.263 payload header
                while ((dwPktCount < pbsiT->dwNumOfPackets) && !(bOneFrameOnePacket && dwPktCount))
                {
                        pRtpPd->dwThisHeaderLength = sizeof(RTP_PD);
                        pRtpPd->dwLayerId = 0;
                        pRtpPd->dwVideoAttributes = 0;
                        pRtpPd->dwReserved = 0;
                        // @todo Update the timestamp field!
                        pRtpPd->dwTimestamp = 0xFFFFFFFF;
                        pRtpPd->dwPayloadHeaderOffset = pbyPayloadHeader - pbyDst;
                        pRtpPd->fEndMarkerBit = TRUE;

#ifdef LOGPAYLOAD_ON
                        // Dump the whole frame in the debug window for comparison with receive side
                        if (!dwPktCount)
                        {
                                g_DebugFile = CreateFile("C:\\SendLog.txt", GENERIC_WRITE, 0, NULL, OPEN_ALWAYS, FILE_ATTRIBUTE_NORMAL, (HANDLE)NULL);
                                SetFilePointer(g_DebugFile, 0, NULL, FILE_END);
                                wsprintf(szDebug, "Frame #%03ld\r\n", (DWORD)pbsiT->byTR);
                                WriteFile(g_DebugFile, szDebug, strlen(szDebug), &d, NULL);
                                wsprintf(szDebug, "Frame #%03ld has %1ld GOBs of size ", (DWORD)pbsiT->byTR, (DWORD)pbsiT->dwNumOfPackets);
                                OutputDebugString(szDebug);
                                pbsi261 = (PRTP_H261_BSINFO)((PBYTE)pbsiT - pbsiT->dwNumOfPackets * sizeof(RTP_H261_BSINFO));
                                for (wPrevOffset=0, i=1; i<(long)pbsiT->dwNumOfPackets; i++)
                                {
                                        wPrevOffset = pbsi261->dwBitOffset;
                                        pbsi261++;
                                        wsprintf(szDebug, "%04ld, ", (DWORD)(pbsi261->dwBitOffset - wPrevOffset) >> 3);
                                        OutputDebugString(szDebug);
                                }
                                wsprintf(szDebug, "%04ld\r\n", (DWORD)(pbsiT->dwCompressedSize * 8 - pbsi261->dwBitOffset) >> 3);
                                OutputDebugString(szDebug);
                                for (i=pbsiT->dwCompressedSize, p=pbySrc; i>0; i-=4, p+=4)
                                {
                                        wsprintf(szDebug, "%02lX %02lX %02lX %02lX\r\n", *((BYTE *)p), *((BYTE *)p+1), *((BYTE *)p+2), *((BYTE *)p+3));
                                        WriteFile(g_DebugFile, szDebug, strlen(szDebug), &d, NULL);
                                }
                                CloseHandle(g_DebugFile);
                        }
#endif

                        // Look for the bitstream info structure
                        pbsi261 = (PRTP_H261_BSINFO)((PBYTE)pbsiT - (pbsiT->dwNumOfPackets - dwPktCount) * sizeof(RTP_H261_BSINFO));

                        // Set the marker bit: as long as this is not the last packet of the frame
                        // this bit needs to be set to 0
                        if (!bOneFrameOnePacket)
                        {
                                // Count the number of GOBS that could fit in m_dwMaxRTPPacketSize
                                for (i=1; i<(long)(pbsiT->dwNumOfPackets - dwPktCount); i++)
                                {
                                        if ((pbsi261+i)->dwBitOffset - pbsi261->dwBitOffset > (m_dwMaxRTPPacketSize * 8))
                                                break;
                                }

                                if (i < (long)(pbsiT->dwNumOfPackets - dwPktCount))
                                {
                                        pRtpPd->fEndMarkerBit = FALSE;
                                        if (i>1)
                                                i--;
                                }
                                else
                                {
                                        // Hey! You 're forgetting the last GOB! It could make the total
                                        // size of the last packet larger than dwMaxFragSize... Imbecile!
                                        if ((pbsiT->dwCompressedSize * 8 - pbsi261->dwBitOffset > (m_dwMaxRTPPacketSize * 8)) && (i>1))
                                        {
                                                pRtpPd->fEndMarkerBit = FALSE;
                                                i--;
                                        }
                                }
                        }

                        // Go to the beginning of the data
                        pRtpPd->dwPayloadStartBitOffset = pbsi261->dwBitOffset;

                        // Build a header to this thing!

                        // 0                   1                   2                   3
                        // 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1
                        //+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
                        //|SBIT |EBIT |I|V| GOBN  |   MBAP  |  QUANT  |  HMVD   |  VMVD   |
                        //+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
                        // But that's the network byte order...

                        // Set the V bit to 1
                        dwHeaderHigh = 0x01000000;

                        // Set the I bit
                        dwHeaderHigh |= (pbsiT->dwFlags & RTP_H26X_INTRA_CODED) << 25;

                        // Set the GOBn bits
                        dwHeaderHigh |= ((DWORD)(pbsi261->byGOBN)) << 20;

                        // Set the MBAP bits
                        dwHeaderHigh |= ((DWORD)(pbsi261->byMBA)) << 15;

                        // Set the QUANT bits
                        dwHeaderHigh |= ((DWORD)(pbsi261->byQuant)) << 10;

                        // Set the HMVD bits
                        dwHeaderHigh |= ((DWORD)(BYTE)(pbsi261->cHMV)) << 5;

                        // Set the VMVD bits
                        dwHeaderHigh |= ((DWORD)(BYTE)(pbsi261->cVMV));

                        // Special case: 1 frame = 1 packet
                        if (bOneFrameOnePacket)
                        {
                                // SBIT is already set to 0

                                // EBIT is already set to 0

                                // Update the packet size
#ifdef LOGPAYLOAD_ON
                                dwPktSize = pbsiT->dwCompressedSize + 4;
#endif
                                pRtpPd->dwPayloadEndBitOffset = pbsiT->dwCompressedSize * 8 - 1;

                                // Update the packet count
                                dwPktCount = pbsiT->dwNumOfPackets;
                        }
                        else
                        {
                                // Set the SBIT bits
                                dwHeaderHigh |= (pbsi261->dwBitOffset % 8) << 29;

                                // Set the EBIT bits
                                if ((pbsiT->dwNumOfPackets - dwPktCount - i) >= 1)
                                {
                                        dwHeaderHigh |= (DWORD)((8UL - ((pbsi261+i)->dwBitOffset % 8)) & 0x00000007) << 26;
                                        pRtpPd->dwPayloadEndBitOffset = (pbsi261+i)->dwBitOffset - 1;
                                }
                                else
                                {
                                        pRtpPd->dwPayloadEndBitOffset = pbsiT->dwCompressedSize * 8 - 1;
                                }

#ifdef LOGPAYLOAD_ON
                                // Update the packet size
                                if ((pbsiT->dwNumOfPackets - dwPktCount - i) >= 1)
                                        dwPktSize = (((pbsi261+i)->dwBitOffset - 1) / 8) - (pbsi261->dwBitOffset / 8) + 1 + 4;
                                else
                                        dwPktSize = pbsiT->dwCompressedSize - pbsi261->dwBitOffset / 8 + 4;
#endif
                                // Update the packet count
                                dwPktCount += i;
                        }

                        // Save the payload header
                        pRtpPd->dwPayloadHeaderLength = 4;

            if ((DWORD)(pbyPayloadHeader - pbyDst) + pRtpPd->dwPayloadHeaderLength > dwDstBufferSize)
            {
                        DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s: buffer too small. size:%d", _fx_, dwDstBufferSize));
                        Hr = S_FALSE;
                        goto MyExit;
            }

                        // Convert to network byte order
                        *(pbyPayloadHeader+3) = (BYTE)(dwHeaderHigh & 0x000000FF);
                        *(pbyPayloadHeader+2) = (BYTE)((dwHeaderHigh >> 8) & 0x000000FF);
                        *(pbyPayloadHeader+1) = (BYTE)((dwHeaderHigh >> 16) & 0x000000FF);
                        *(pbyPayloadHeader) = (BYTE)((dwHeaderHigh >> 24) & 0x000000FF);

#ifdef LOGPAYLOAD_ON
                        // Output some debug stuff
                        wsprintf(szDebug, "Packet: %02lX\r\n Header: %02lX %02lX %02lX %02lX\r\n", dwPktCount, *(pbyPayloadHeader), *(pbyPayloadHeader+1), *(pbyPayloadHeader+2), *(pbyPayloadHeader+3));
                        OutputDebugString(szDebug);
                        if (pRtpPd->fEndMarkerBit == TRUE)
                                wsprintf(szDebug, " Marker: ON\r\n");
                        else
                                wsprintf(szDebug, " Marker: OFF\r\n");
                        OutputDebugString(szDebug);
                        wsprintf(szDebug, "Frame #%03ld, Packet of size %04ld\r\n", (DWORD)pbsiT->byTR, dwPktSize);
                        OutputDebugString(szDebug);
#endif

                        // Move to the next potential header position
                        pbyPayloadHeader += pRtpPd->dwPayloadHeaderLength;
                        pRtpPd++;
                }

                // Update the number of headers
                pRtpPdHeader->dwNumHeaders = ((long)((PBYTE)pRtpPd - pbyDst) + sizeof(RTP_PD_HEADER)) / sizeof(RTP_PD);
                pRtpPdHeader->dwTotalByteLength = (DWORD)(pbyPayloadHeader - pbyDst);
        }

        pRSample->SetSyncPoint (TRUE);
        pRSample->SetActualDataLength (pbyPayloadHeader - pbyDst);
        pRSample->SetDiscontinuity(bDiscon);
        pRSample->SetPreroll(FALSE);

        // Get the timestamps from the video sample.
        pSample->GetTime(&rtSample, &rtEnd);
        pRSample->SetTime(&rtSample, &rtEnd);

        // IAMStreamControl stuff. Has somebody turned us off for now?
        iStreamState = CheckStreamState(pRSample);
        if (iStreamState == STREAM_FLOWING)
        {
                DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s:   Sending frame", _fx_));
                if (m_pCaptureFilter->m_cs.fLastRtpPdSampleDiscarded)
                        pRSample->SetDiscontinuity(TRUE);
                m_pCaptureFilter->m_cs.fLastRtpPdSampleDiscarded = FALSE;
        }
        else
        {
                DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s:   Discarding frame", _fx_));
                m_pCaptureFilter->m_cs.fLastRtpPdSampleDiscarded = TRUE;
                Hr = S_FALSE;           // discarding
        }

        // Don't deliver it if the stream is off for now
        if (iStreamState == STREAM_FLOWING)
        {
                if ((Hr = Deliver (pRSample)) == S_FALSE)
                        Hr = E_FAIL;    // stop delivering anymore, this is serious
        }
#ifdef DEBUG
        else
        {
                DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: Frame wasn't delivered!", _fx_));
        }
#endif

MyExit:
        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: end", _fx_));
        return Hr;
}

/****************************************************************************
 *  @doc INTERNAL CRTPPDPINMETHOD
 *
 *  @mfunc HRESULT | CRtpPdPin | SetProperties | This method is used to
 *    specify the size, number, and alignment of blocks.
 *
 *  @parm ALLOCATOR_PROPERTIES* | pRequest | Specifies a pointer to the
 *    requested allocator properties.
 *
 *  @parm ALLOCATOR_PROPERTIES* | pActual | Specifies a pointer to the
 *    allocator properties actually set.
 *
 *  @rdesc This method returns an HRESULT value that depends on the
 *    implementation of the interface. HRESULT can include one of the
 *    following standard constants, or other values not listed:
 *
 *  @flag E_FAIL | Failure
 *  @flag E_POINTER | Null pointer argument
 *  @flag NOERROR | No error
 ***************************************************************************/
STDMETHODIMP CRtpPdPin::SetProperties(IN ALLOCATOR_PROPERTIES *pRequest, OUT ALLOCATOR_PROPERTIES *pActual)
{
        HRESULT Hr = NOERROR;

        FX_ENTRY("CRtpPdPin::SetProperties")

        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: begin", _fx_));

        // Validate input parameters
        ASSERT(pRequest);
        ASSERT(pActual);
        if (!pRequest || !pActual)
        {
                DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: Null pointer argument!", _fx_));
                Hr = E_POINTER;
                goto MyExit;
        }

        // If we have already allocated headers & buffers ignore the
        // requested and return the actual numbers. Otherwise, make a
        // note of the requested so that we can honour it later.
        if (!Committed())
        {
                m_parms.cBuffers  = pRequest->cBuffers;
                m_parms.cbBuffer  = pRequest->cbBuffer;
                m_parms.cbAlign   = pRequest->cbAlign;
                m_parms.cbPrefix  = pRequest->cbPrefix;
        }

        pActual->cBuffers   = (long)m_parms.cBuffers;
        pActual->cbBuffer   = (long)m_parms.cbBuffer;
        pActual->cbAlign    = (long)m_parms.cbAlign;
        pActual->cbPrefix   = (long)m_parms.cbPrefix;

MyExit:
        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: end", _fx_));
        return Hr;
}

/****************************************************************************
 *  @doc INTERNAL CRTPPDPINMETHOD
 *
 *  @mfunc HRESULT | CRtpPdPin | GetProperties | This method is used to
 *    retrieve the properties being used on this allocator.
 *
 *  @parm ALLOCATOR_PROPERTIES* | pProps | Specifies a pointer to the
 *    requested allocator properties.
 *
 *  @rdesc This method returns an HRESULT value that depends on the
 *    implementation of the interface. HRESULT can include one of the
 *    following standard constants, or other values not listed:
 *
 *  @flag E_FAIL | Failure
 *  @flag E_POINTER | Null pointer argument
 *  @flag NOERROR | No error
 ***************************************************************************/
STDMETHODIMP CRtpPdPin::GetProperties(ALLOCATOR_PROPERTIES *pProps)
{
        HRESULT Hr = NOERROR;

        FX_ENTRY("CRtpPdPin::GetProperties")

        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: begin", _fx_));

        // Validate input parameters
        ASSERT(pProps);
        if (!pProps)
        {
                DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: Null pointer argument!", _fx_));
                Hr = E_POINTER;
                goto MyExit;
        }

        pProps->cBuffers = (long)m_parms.cBuffers;
        pProps->cbBuffer = (long)m_parms.cbBuffer;
        pProps->cbAlign  = (long)m_parms.cbAlign;
        pProps->cbPrefix = (long)m_parms.cbPrefix;

MyExit:
        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: end", _fx_));
        return Hr;
}

/****************************************************************************
 *  @doc INTERNAL CRTPPDPINMETHOD
 *
 *  @mfunc HRESULT | CRtpPdPin | Commit | This method is used to
 *    commit the memory for the specified buffers.
 *
 *  @rdesc This method returns S_OK.
 ***************************************************************************/
STDMETHODIMP CRtpPdPin::Commit()
{
        FX_ENTRY("CRtpPdPin::Commit")

        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: begin", _fx_));

        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: end", _fx_));

        return S_OK;
}

/****************************************************************************
 *  @doc INTERNAL CRTPPDPINMETHOD
 *
 *  @mfunc HRESULT | CRtpPdPin | Decommit | This method is used to
 *    release the memory for the specified buffers.
 *
 *  @rdesc This method returns S_OK.
 ***************************************************************************/
STDMETHODIMP CRtpPdPin::Decommit()
{
        FX_ENTRY("CRtpPdPin::Decommit")

        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: begin", _fx_));

        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: end", _fx_));

        return S_OK;
}

/****************************************************************************
 *  @doc INTERNAL CRTPPDPINMETHOD
 *
 *  @mfunc HRESULT | CRtpPdPin | GetBuffer | This method is used to
 *    retrieve a container for a sample.
 *
 *  @rdesc This method returns E_FAIL.
 ***************************************************************************/
STDMETHODIMP CRtpPdPin::GetBuffer(IMediaSample **ppBuffer, REFERENCE_TIME *pStartTime, REFERENCE_TIME *pEndTime, DWORD dwFlags)
{
        FX_ENTRY("CRtpPdPin::GetBuffer")

        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: begin", _fx_));

        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: end", _fx_));

        return E_FAIL;
}

/****************************************************************************
 *  @doc INTERNAL CRTPPDPINMETHOD
 *
 *  @mfunc HRESULT | CRtpPdPin | ReleaseBuffer | This method is used to
 *    release the <c CMediaSample> object. The final call to Release() on
 *    <i IMediaSample> will call this method.
 *
 *  @parm IMediaSample* | pSample | Specifies a pointer to the buffer to
 *    release.
 *
 *  @rdesc This method returns an HRESULT value that depends on the
 *    implementation of the interface. HRESULT can include one of the
 *    following standard constants, or other values not listed:
 *
 *  @flag E_FAIL | Failure
 *  @flag E_POINTER | Null pointer argument
 *  @flag S_OK | No error
 ***************************************************************************/
STDMETHODIMP CRtpPdPin::ReleaseBuffer(IMediaSample *pSample)
{
        HRESULT Hr = S_OK;
        LPTHKVIDEOHDR ptvh;

        FX_ENTRY("CRtpPdPin::ReleaseBuffer")

        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: begin", _fx_));

        // Validate input parameters
        ASSERT(pSample);
        if (!pSample)
        {
                DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: Null pointer argument!", _fx_));
                Hr = E_POINTER;
                goto MyExit;
        }

        if (ptvh = ((CRtpPdSample *)pSample)->GetFrameHeader())
                Hr = m_pCaptureFilter->ReleaseFrame(ptvh);

MyExit:
        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: end", _fx_));
        return Hr;
}

/****************************************************************************
 *  @doc INTERNAL CRTPPDPINMETHOD
 *
 *  @mfunc HRESULT | CRtpPdPin | DecideBufferSize | This method is
 *    used to retrieve the number and size of buffers required for transfer.
 *
 *  @parm IMemAllocator* | pAlloc | Specifies a pointer to the allocator
 *    assigned to the transfer.
 *
 *  @parm ALLOCATOR_PROPERTIES* | ppropInputRequest | Specifies a pointer to an
 *    <t ALLOCATOR_PROPERTIES> structure.
 *
 *  @rdesc This method returns an HRESULT value that depends on the
 *    implementation of the interface. HRESULT can include one of the
 *    following standard constants, or other values not listed:
 *
 *  @flag E_FAIL | Failure
 *  @flag E_POINTER | Null pointer argument
 *  @flag NOERROR | No error
 ***************************************************************************/
HRESULT CRtpPdPin::DecideBufferSize(IN IMemAllocator *pAlloc, OUT ALLOCATOR_PROPERTIES *ppropInputRequest)
{
        HRESULT Hr = NOERROR;
        ALLOCATOR_PROPERTIES Actual;

        FX_ENTRY("CRtpPdPin::DecideBufferSize")

        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: begin", _fx_));

        // Validate input parameters
        ASSERT(pAlloc);
        ASSERT(ppropInputRequest);
        if (!pAlloc || !ppropInputRequest)
        {
                DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: Null pointer argument!", _fx_));
                Hr = E_POINTER;
                goto MyExit;
        }

        // @todo We shouldn't need that many buffers and you probably need a different number
        // of buffers if you are capturing in streaming mode of frame grabbing mode
        // You also need to decouple this number from the number of video capture buffers: only
        // if you need to ship the video capture buffer downstream (possible on the preview pin)
        // should you make those number equal.
        ppropInputRequest->cBuffers = MAX_VIDEO_BUFFERS;
        ppropInputRequest->cbPrefix = 0;
        ppropInputRequest->cbAlign  = 1;
        ppropInputRequest->cbBuffer = MAX_RTP_PD_BUFFER_SIZE;

        // Validate alignment
        ppropInputRequest->cbBuffer = (long)ALIGNUP(ppropInputRequest->cbBuffer + ppropInputRequest->cbPrefix, ppropInputRequest->cbAlign) - ppropInputRequest->cbPrefix;

        ASSERT(ppropInputRequest->cbBuffer);
        if (!ppropInputRequest->cbBuffer)
        {
                DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: Buffer size is 0!", _fx_));
                Hr = E_FAIL;
                goto MyExit;
        }

        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s:   Using %d buffers, prefix %d size %d align %d", _fx_, ppropInputRequest->cBuffers, ppropInputRequest->cbPrefix, ppropInputRequest->cbBuffer, ppropInputRequest->cbAlign));

        Hr = pAlloc->SetProperties(ppropInputRequest,&Actual);

        // It's our allocator, we know we'll be happy with what it decided

MyExit:
        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: end", _fx_));
        return Hr;
}

/****************************************************************************
 *  @doc INTERNAL CRTPPDPINMETHOD
 *
 *  @mfunc HRESULT | CRtpPdPin | DecideAllocator | This method is
 *    used to negotiate the allocator to use.
 *
 *  @parm IMemInputPin* | pPin | Specifies a pointer to the IPin interface
 *    of the connecting pin.
 *
 *  @parm IMemAllocator** | ppAlloc | Specifies a pointer to the negotiated
 *    IMemAllocator interface.
 *
 *  @rdesc This method returns an HRESULT value that depends on the
 *    implementation of the interface. HRESULT can include one of the
 *    following standard constants, or other values not listed:
 *
 *  @flag E_FAIL | Failure
 *  @flag E_POINTER | Null pointer argument
 *  @flag NOERROR | No error
 ***************************************************************************/
HRESULT CRtpPdPin::DecideAllocator(IN IMemInputPin *pPin, OUT IMemAllocator **ppAlloc)
{
        HRESULT Hr = NOERROR;
        ALLOCATOR_PROPERTIES prop;

        FX_ENTRY("CRtpPdPin::DecideAllocator")

        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: begin", _fx_));

        // Validate input parameters
        ASSERT(pPin);
        ASSERT(ppAlloc);
        if (!pPin || !ppAlloc)
        {
                DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: Invalid input parameter!", _fx_));
                Hr = E_POINTER;
                goto MyExit;
        }

        if (FAILED(GetInterface(static_cast<IMemAllocator*>(this), (void **)ppAlloc)))
        {
                DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: GetInterface failed!", _fx_));
                Hr = E_FAIL;
                goto MyExit;
        }

        // Get downstream allocator property requirement
        ZeroMemory(&prop, sizeof(prop));

        if (SUCCEEDED(Hr = DecideBufferSize(*ppAlloc, &prop)))
        {
                // Our buffers are not read only
                if (SUCCEEDED(Hr = pPin->NotifyAllocator(*ppAlloc, FALSE)))
                        goto MyExit;
        }

        (*ppAlloc)->Release();
        *ppAlloc = NULL;

MyExit:
        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: end", _fx_));
        return Hr;
}
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\net\tapi\skywalker\filters\video\tapivcap\progref.cpp ===
/****************************************************************************
 *  @doc INTERNAL PROGREF
 *
 *  @module ProgRef.cpp | Source file for the <c CCapturePin> class methods
 *    used to implement the video capture output pin progressive refinement
 *    methods.
 *
 *  @comm Understand how to make this work on a still-pin
 ***************************************************************************/

#include "Precomp.h"

#ifdef USE_PROGRESSIVE_REFINEMENT

/****************************************************************************
 *  @doc INTERNAL CCAPTUREPROGREFMETHOD
 *
 *  @mfunc HRESULT | CCapturePin | doOneProgression | This
 *    method is used to command the compressed still-image output pin to
 *    begin producing a progressive refinement sequence for one picture.
 *
 *  @rdesc This method returns an HRESULT value that depends on the
 *    implementation of the interface. HRESULT can include one of the
 *    following standard constants, or other values not listed:
 *
 *  @flag E_FAIL | Failure
 *  @flag E_NOTIMPL | Method is not supported
 *  @flag VFW_E_NOT_CONNECTED | Pin not connected yet
 *  @flag NOERROR | No error
 ***************************************************************************/
STDMETHODIMP CCapturePin::doOneProgression()
{
	HRESULT Hr = NOERROR;

	FX_ENTRY("CCapturePin::doOneProgression")

	DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: begin", _fx_));

	// @comm Put some real code here! 
	Hr = E_NOTIMPL;

	DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: end", _fx_));
	return Hr;
}

/****************************************************************************
 *  @doc INTERNAL CCAPTUREPROGREFMETHOD
 *
 *  @mfunc HRESULT | CCapturePin | doContinuousProgressions | This
 *    method is used to command the compressed still-image output pin to
 *    begin producing progressive refinement sequences for several pictures.
 *
 *  @rdesc This method returns an HRESULT value that depends on the
 *    implementation of the interface. HRESULT can include one of the
 *    following standard constants, or other values not listed:
 *
 *  @flag E_FAIL | Failure
 *  @flag E_NOTIMPL | Method is not supported
 *  @flag VFW_E_NOT_CONNECTED | Pin not connected yet
 *  @flag NOERROR | No error
 ***************************************************************************/
STDMETHODIMP CCapturePin::doContinuousProgressions()
{
	HRESULT Hr = NOERROR;

	FX_ENTRY("CCapturePin::doContinuousProgressions")

	DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: begin", _fx_));

	// @comm Put some real code here! 
	Hr = E_NOTIMPL;

	DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: end", _fx_));
	return Hr;
}

/****************************************************************************
 *  @doc INTERNAL CCAPTUREPROGREFMETHOD
 *
 *  @mfunc HRESULT | CCapturePin | doOneIndependentProgression | This
 *    method is used to command the compressed still-image output pin to begin
 *    an independent progressive refinement sequence for one Intra picture.
 *
 *  @rdesc This method returns an HRESULT value that depends on the
 *    implementation of the interface. HRESULT can include one of the
 *    following standard constants, or other values not listed:
 *
 *  @flag E_FAIL | Failure
 *  @flag E_NOTIMPL | Method is not supported
 *  @flag VFW_E_NOT_CONNECTED | Pin not connected yet
 *  @flag NOERROR | No error
 ***************************************************************************/
STDMETHODIMP CCapturePin::doOneIndependentProgression()
{
	HRESULT Hr = NOERROR;

	FX_ENTRY("CCapturePin::doOneIndependentProgression")

	DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: begin", _fx_));

	// @comm Put some real code here! 
	Hr = E_NOTIMPL;

	DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: end", _fx_));
	return Hr;
}

/****************************************************************************
 *  @doc INTERNAL CCAPTUREPROGREFMETHOD
 *
 *  @mfunc HRESULT | CCapturePin | doContinuousIndependentProgressions | This
 *    method is used to command the compressed still-image output pin to
 *    begin an independent progressive refinement sequence several Intra
 *    pictures.
 *
 *  @rdesc This method returns an HRESULT value that depends on the
 *    implementation of the interface. HRESULT can include one of the
 *    following standard constants, or other values not listed:
 *
 *  @flag E_FAIL | Failure
 *  @flag E_NOTIMPL | Method is not supported
 *  @flag VFW_E_NOT_CONNECTED | Pin not connected yet
 *  @flag NOERROR | No error
 ***************************************************************************/
STDMETHODIMP CCapturePin::doContinuousIndependentProgressions()
{
	HRESULT Hr = NOERROR;

	FX_ENTRY("CCapturePin::doContinuousIndependentProgressions")

	DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: begin", _fx_));

	// @comm Put some real code here! 
	Hr = E_NOTIMPL;

	DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: end", _fx_));
	return Hr;
}

/****************************************************************************
 *  @doc INTERNAL CCAPTUREPROGREFMETHOD
 *
 *  @mfunc HRESULT | CCapturePin | progressiveRefinementAbortOne | This
 *    method is used to command the compressed still-image output pin to
 *    terminate a progressive refinement sequence for the current picture.
 *
 *  @rdesc This method returns an HRESULT value that depends on the
 *    implementation of the interface. HRESULT can include one of the
 *    following standard constants, or other values not listed:
 *
 *  @flag E_FAIL | Failure
 *  @flag E_NOTIMPL | Method is not supported
 *  @flag VFW_E_NOT_CONNECTED | Pin not connected yet
 *  @flag NOERROR | No error
 ***************************************************************************/
STDMETHODIMP CCapturePin::progressiveRefinementAbortOne()
{
	HRESULT Hr = NOERROR;

	FX_ENTRY("CCapturePin::progressiveRefinementAbortOne")

	DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: begin", _fx_));

	// @comm Put some real code here! 
	Hr = E_NOTIMPL;

	DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: end", _fx_));
	return Hr;
}

/****************************************************************************
 *  @doc INTERNAL CCAPTUREPROGREFMETHOD
 *
 *  @mfunc HRESULT | CCapturePin | progressiveRefinementAbortContinuous | This
 *    method is used to command the compressed still-image output pin to
 *    terminate a progressive refinement sequence for all pictures.
 *
 *  @rdesc This method returns an HRESULT value that depends on the
 *    implementation of the interface. HRESULT can include one of the
 *    following standard constants, or other values not listed:
 *
 *  @flag E_FAIL | Failure
 *  @flag E_NOTIMPL | Method is not supported
 *  @flag VFW_E_NOT_CONNECTED | Pin not connected yet
 *  @flag NOERROR | No error
 ***************************************************************************/
STDMETHODIMP CCapturePin::progressiveRefinementAbortContinuous()
{
	HRESULT Hr = NOERROR;

	FX_ENTRY("CCapturePin::progressiveRefinementAbortContinuous")

	DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: begin", _fx_));

	// @comm Put some real code here! 
	Hr = E_NOTIMPL;

	DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: end", _fx_));
	return Hr;
}

#endif
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\net\tapi\skywalker\filters\video\tapivcap\progrefp.cpp ===
/****************************************************************************
 *  @doc INTERNAL PROGREFP
 *
 *  @module ProgRefP.cpp | Source file for the <c CProgRefProperties>
 *    class used to implement a property page to test the new TAPI internal
 *    interface <i IProgressiveRefinement>.
 *
 *  @comm This code tests the TAPI Capture Pin <i IProgressiveRefinement>
 *    implementation. This code is only compiled if USE_PROPERTY_PAGES is
 *    defined.
 ***************************************************************************/

#include "Precomp.h"

#ifdef USE_PROPERTY_PAGES

#ifdef USE_PROGRESSIVE_REFINEMENT

/****************************************************************************
 *  @doc INTERNAL CPROGREFPMETHOD
 *
 *  @mfunc CUnknown* | CProgRefProperties | CreateInstance | This
 *    method is called by DShow to create an instance of a Progressive Refinement
 *    Property Page. It is referred to in the global structure <t g_Templates>.
 *
 *  @parm LPUNKNOWN | pUnkOuter | Specifies the outer unknown, if any.
 *
 *  @parm HRESULT* | pHr | Specifies the place in which to put any error return.
 *
 *  @rdesc Returns a pointer to the nondelegating CUnknown portion of the
 *    object, or NULL otherwise.
 ***************************************************************************/
CUnknown* CALLBACK CProgRefPropertiesCreateInstance(LPUNKNOWN pUnkOuter, HRESULT *pHr) 
{
	CUnknown *pUnknown = (CUnknown *)NULL;

	FX_ENTRY("CProgRefPropertiesCreateInstance")

	DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: begin", _fx_));

	// Validate input parameters
	ASSERT(pHr);
	if (!pHr)
	{
		DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: invalid input parameter", _fx_));
		goto MyExit;
	}

	if (!(pUnknown = new CProgRefProperties(pUnkOuter, pHr)))
	{
		*pHr = E_OUTOFMEMORY;
		DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: new CProgRefProperties failed", _fx_));
	}
	else
	{
		DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s:   SUCCESS: new CProgRefProperties created", _fx_));
	}

MyExit:
	DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: end", _fx_));
	return pUnknown;
}

/****************************************************************************
 *  @doc INTERNAL CPROGREFPMETHOD
 *
 *  @mfunc void | CProgRefProperties | CProgRefProperties | This
 *    method is the constructor for the property page object. It simply
 *    calls the constructor of the property page base class.
 *
 *  @parm LPUNKNOWN | pUnkOuter | Specifies the outer unknown, if any.
 *
 *  @parm HRESULT* | pHr | Specifies the place in which to put any error return.
 *
 *  @rdesc Nada.
 ***************************************************************************/
CProgRefProperties::CProgRefProperties(LPUNKNOWN pUnk, HRESULT *pHr) : CBasePropertyPage(NAME("Progressive Refinement Property Page"), pUnk, IDD_ProgRefinemntProperties, IDS_PROGREFPROPNAME)
{
	FX_ENTRY("CProgRefProperties::CProgRefProperties")

	DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: begin", _fx_));

	m_pIProgRef = NULL;

	DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: end", _fx_));
}

/****************************************************************************
 *  @doc INTERNAL CPROGREFPMETHOD
 *
 *  @mfunc void | CProgRefProperties | ~CProgRefProperties | This
 *    method is the destructor for progressive refinement property page. It
 *    simply calls the base class destructor.
 *
 *  @rdesc Nada.
 ***************************************************************************/
CProgRefProperties::~CProgRefProperties()
{
	FX_ENTRY("CProgRefProperties::~CProgRefProperties")

	DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: begin", _fx_));

	if (!m_pIProgRef)
	{
		DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   WARNING: already released!", _fx_));
	}
	else
	{
		// Release the interface
		m_pIProgRef->Release();
		m_pIProgRef = NULL;
		DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s:   SUCCESS: releasing m_pIProgRef", _fx_));
	}

	DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: end", _fx_));
}

/****************************************************************************
 *  @doc INTERNAL CPROGREFPMETHOD
 *
 *  @mfunc HRESULT | CProgRefProperties | OnConnect | This
 *    method is called when the property page is connected to the filter.
 *
 *  @parm LPUNKNOWN | pUnknown | Specifies the outer unknown, if any.
 *
 *  @parm HRESULT* | pHr | Specifies the place in which to put any error return.
 *
 *  @rdesc This method returns an HRESULT value that depends on the
 *    implementation of the interface. HRESULT can include one of the
 *    following standard constants, or other values not listed:
 *
 *  @flag E_FAIL | Failure
 *  @flag E_POINTER | Null pointer argument
 *  @flag E_NOTIMPL | Method is not supported
 *  @flag NOERROR | No error
 ***************************************************************************/
HRESULT CProgRefProperties::OnConnect(IUnknown *pUnk)
{
	HRESULT Hr = NOERROR;

	FX_ENTRY("CProgRefProperties::OnConnect")

	DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: begin", _fx_));

	// Validate input parameters
	ASSERT(pUnk);
	if (!pUnk)
	{
		DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: invalid input parameter", _fx_));
		Hr = E_POINTER;
		goto MyExit;
	}

	// Get the progressive refinement interface
	if (SUCCEEDED (Hr = pUnk->QueryInterface(__uuidof(IProgressiveRefinement),(void **)&m_pIProgRef)))
	{
		DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s:   SUCCESS: m_pIProgRef=0x%08lX", _fx_, m_pIProgRef));
	}
	else
	{
		m_pIProgRef = NULL;
		DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: IOCTL failed Hr=0x%08lX", _fx_, Hr));
	}

	// It's Ok if we couldn't get interface pointers
	// We'll just grey the controls in the property page
	// to make it clear to the user that they can't
	// control those properties on the device
	Hr = NOERROR;

MyExit:
	DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: end", _fx_));
	return Hr;
}

/****************************************************************************
 *  @doc INTERNAL CPROGREFPMETHOD
 *
 *  @mfunc HRESULT | CProgRefProperties | OnDisconnect | This
 *    method is called when the property page is disconnected from the owning
 *    filter.
 *
 *  @rdesc This method returns an HRESULT value that depends on the
 *    implementation of the interface. HRESULT can include one of the
 *    following standard constants, or other values not listed:
 *
 *  @flag NOERROR | No error
 ***************************************************************************/
HRESULT CProgRefProperties::OnDisconnect()
{
	FX_ENTRY("CProgRefProperties::OnDisconnect")

	DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: begin", _fx_));

	// Validate input parameters: we seem to get called several times here
	// Make sure the interface pointer is still valid
	if (!m_pIProgRef)
	{
		DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   WARNING: already disconnected!", _fx_));
	}
	else
	{
		// Release the interface
		m_pIProgRef->Release();
		m_pIProgRef = NULL;
		DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s:   SUCCESS: releasing m_pIProgRef", _fx_));
	}

	DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: end", _fx_));
	return NOERROR;
}

/****************************************************************************
 *  @doc INTERNAL CPROGREFPMETHOD
 *
 *  @mfunc BOOL | CProgRefProperties | OnReceiveMessage | This
 *    method is called when a message is sent to the property page dialog box.
 *
 *  @rdesc By default, returns the value returned by the Win32 DefWindowProc function.
 ***************************************************************************/
BOOL CProgRefProperties::OnReceiveMessage(HWND hWnd, UINT uMsg, WPARAM wParam, LPARAM lParam) 
{
	switch (uMsg)
	{
		case WM_INITDIALOG:
			EnableWindow(GetDlgItem(hWnd, IDC_ProgRef_OneProg), (BOOL)m_pIProgRef);
			EnableWindow(GetDlgItem(hWnd, IDC_ProgRef_ContProg), (BOOL)m_pIProgRef);
			EnableWindow(GetDlgItem(hWnd, IDC_ProgRef_IndProg), (BOOL)m_pIProgRef);
			EnableWindow(GetDlgItem(hWnd, IDC_ProgRef_ContIndProg), (BOOL)m_pIProgRef);
			EnableWindow(GetDlgItem(hWnd, IDC_ProgRef_AbortOne), (BOOL)m_pIProgRef);
			EnableWindow(GetDlgItem(hWnd, IDC_ProgRef_AbortCont), (BOOL)m_pIProgRef);
			return TRUE; // Don't call setfocus

		case WM_COMMAND:

			// This message gets sent even before OnActivate() has been
			// called(!). We need to test and make sure the controls have
			// beeen initialized before we can use them.

			switch (LOWORD(wParam))
			{
				case IDC_ProgRef_OneProg:
					if (m_pIProgRef)
						m_pIProgRef->doOneProgression();
					break;

				case IDC_ProgRef_ContProg:
					if (m_pIProgRef)
						m_pIProgRef->doContinuousProgressions();
					break;

				case IDC_ProgRef_IndProg:
					if (m_pIProgRef)
						m_pIProgRef->doOneIndependentProgression();
					break;

				case IDC_ProgRef_ContIndProg:
					if (m_pIProgRef)
						m_pIProgRef->doContinuousIndependentProgressions();
					break;

				case IDC_ProgRef_AbortOne:
					if (m_pIProgRef)
						m_pIProgRef->progressiveRefinementAbortOne();
					break;

				case IDC_ProgRef_AbortCont:
					if (m_pIProgRef)
						m_pIProgRef->progressiveRefinementAbortContinuous();
					break;

				default:
					break;
			}
			break;

		default:
			return FALSE;
	}

	return TRUE;
}

#endif

#endif
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\net\tapi\skywalker\filters\video\tapivcap\progrefp.h ===
/****************************************************************************
 *  @doc INTERNAL PROGREFP
 *
 *  @module ProgRefP.h | Header file for the <c CProgRefProperties>
 *    class used to implement a property page to test the new TAPI internal
 *    interface <i IProgressiveRefinement>.
 *
 *  @comm This code tests the TAPI Capture Pin <i IProgressiveRefinement>
 *    implementation. This code is only compiled if USE_PROPERTY_PAGES is
 *    defined.
 ***************************************************************************/

#ifndef _PROGREFP_H_
#define _PROGREFP_H_

#ifdef USE_PROPERTY_PAGES

#ifdef USE_PROGRESSIVE_REFINEMENT

/****************************************************************************
 *  @doc INTERNAL CPROGREFPCLASS
 *
 *  @class CProgRefProperties | This class implements a property page
 *    to test the new TAPI internal interface <i IProgressiveRefinement>.
 *
 *  @mdata IProgressiveRefinement* | CProgRefProperties | m_pIProgRef | Pointer
 *    to the <i IProgressiveRefinement> interface.
 *
 *  @comm This code tests the TAPI Capture Pin <i IProgressiveRefinement>
 *    implementation. This code is only compiled if USE_PROPERTY_PAGES is
 *    defined.
 ***************************************************************************/
class CProgRefProperties : public CBasePropertyPage
{
	public:
	CProgRefProperties(LPUNKNOWN pUnk, HRESULT *pHr);
	~CProgRefProperties();

	HRESULT OnConnect(IUnknown *pUnk);
	HRESULT OnDisconnect();
	BOOL    OnReceiveMessage(HWND hWnd, UINT uMsg, WPARAM wParam, LPARAM lParam);

	private:

	IProgressiveRefinement *m_pIProgRef;
};

#endif // USE_PROGRESSIVE_REFINEMENT

#endif // USE_PROPERTY_PAGES

#endif // _PROGREFP_H_
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\net\tapi\skywalker\filters\video\tapivcap\propedit.cpp ===
/****************************************************************************
 *  @doc INTERNAL PROPEDIT
 *
 *  @module PropEdit.cpp | Source file for the <c CPropertyEditor>
 *    class used to implement behavior of a single property to be displayed
 *    in a property page.
 *
 *  @comm This code is only compiled if USE_PROPERTY_PAGES is defined.
 ***************************************************************************/

#include "Precomp.h"

#ifdef USE_PROPERTY_PAGES

/****************************************************************************
 *  @doc INTERNAL CPROPEDITMETHOD
 *
 *  @mfunc void | CPropertyEditor | CPropertyEditor | This
 *    method is the constructor for property objects.
 *
 *  @parm HWND | hDlg | Specifies a handle to the parent property page.
 *
 *  @parm ULONG | IDLabel | Specifies a label ID for the property.
 *
 *  @parm ULONG | IDMinControl | Specifies a label ID for the associated
 *    property edit control where the Minimum value of the property appears.
 *
 *  @parm ULONG | IDMaxControl | Specifies a label ID for the associated
 *    property edit control where the Maximum value of the property appears.
 *
 *  @parm ULONG | IDDefaultControl | Specifies a label ID for the associated
 *    property edit control where the Default value of the property appears.
 *
 *  @parm ULONG | IDStepControl | Specifies a label ID for the associated
 *    property edit control where the Stepping Delta value of the property appears.
 *
 *  @parm ULONG | IDEditControl | Specifies a label ID for the associated
 *    property edit control where the value of the property appears.
 *
 *  @parm ULONG | IDTrackbarControl | Specifies a label ID for the associated
 *    property slide bar.
 *
 *  @parm ULONG | IDProgressControl | Specifies a label ID for the associated
 *    progress bar.
 *
 *  @parm ULONG | IDProperty | Specifies the ID of the property.
 *
 *  @rdesc Nada.
 ***************************************************************************/
CPropertyEditor::CPropertyEditor(HWND hDlg, ULONG IDLabel, ULONG IDMinControl, ULONG IDMaxControl, ULONG IDDefaultControl, ULONG IDStepControl, ULONG IDEditControl, ULONG IDTrackbarControl, ULONG IDProgressControl, ULONG IDProperty, ULONG IDAutoControl)
: m_hDlg (hDlg), m_hWndMin (NULL), m_hWndMax (NULL), m_hWndDefault (NULL), m_hWndStep (NULL), m_hWndEdit (NULL), m_hWndTrackbar (NULL), m_hWndProgress (NULL), m_IDLabel (IDLabel), m_hWndAuto (NULL), m_IDAutoControl (IDAutoControl)
, m_IDMinControl (IDMinControl), m_IDMaxControl (IDMaxControl), m_IDDefaultControl (IDDefaultControl), m_IDStepControl (IDStepControl), m_IDTrackbarControl (IDTrackbarControl), m_IDProgressControl (IDProgressControl)
, m_IDEditControl (IDEditControl), m_IDProperty (IDProperty), m_Active (FALSE), m_Min (0), m_Max (0), m_DefaultValue (0), m_DefaultFlags (0), m_SteppingDelta (0), m_CurrentValue (0), m_TrackbarOffset (0), m_ProgressOffset (0), m_fCheckBox (0)
, m_CurrentFlags (0), m_CanAutoControl (FALSE)

{
	FX_ENTRY("CPropertyEditor::CPropertyEditor")

	DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: begin", _fx_));

	DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: end", _fx_));
}

/****************************************************************************
 *  @doc INTERNAL CPROPEDITMETHOD
 *
 *  @mfunc BOOL | CPropertyEditor | Init | This initializes the controls.
 *
 *  @rdesc TRUE on success, FALSE otherwise.
 ***************************************************************************/
BOOL CPropertyEditor::Init()
{
	HRESULT Hr = NOERROR;
	BOOL	fRes = TRUE;

	FX_ENTRY("CPropertyEditor::Init")

	DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: begin", _fx_));

	// For now disable all controls, and re-enable only the ones that make sense
	// at the end of this initialization function

	// Those GetDlgItem calls 'd better not fail ;)
	if (m_IDLabel)
		EnableWindow(GetDlgItem(m_hDlg, m_IDLabel), FALSE);
	if (m_IDMinControl)
		EnableWindow(m_hWndMin = GetDlgItem(m_hDlg, m_IDMinControl), FALSE);
	if (m_IDMaxControl)
		EnableWindow(m_hWndMax = GetDlgItem(m_hDlg, m_IDMaxControl), FALSE);
	if (m_IDDefaultControl)
		EnableWindow(m_hWndDefault = GetDlgItem(m_hDlg, m_IDDefaultControl), FALSE);
	if (m_IDStepControl)
		EnableWindow(m_hWndStep = GetDlgItem(m_hDlg, m_IDStepControl), FALSE);
	if (m_IDEditControl)
		EnableWindow(m_hWndEdit = GetDlgItem(m_hDlg, m_IDEditControl), FALSE);
	if (m_IDTrackbarControl)
		EnableWindow(m_hWndTrackbar = GetDlgItem(m_hDlg, m_IDTrackbarControl), FALSE);
	if (m_IDProgressControl)
		EnableWindow(m_hWndProgress = GetDlgItem(m_hDlg, m_IDProgressControl), FALSE);
	if (m_IDAutoControl)
		EnableWindow(m_hWndAuto = GetDlgItem(m_hDlg, m_IDAutoControl), FALSE);

	// Only enable the control if we can read the current value
	if (FAILED(Hr = GetValue()))
	{
		fRes = FALSE;
		goto MyExit;
	}

	// Save original value in case user clicks Cancel
	m_OriginalValue = m_CurrentValue;
	m_OriginalFlags = m_CurrentFlags;

	// Get the range, stepping, default, and capabilities
	if (FAILED(Hr = GetRange()))
	{
		// Special case, if no trackbar and no edit box, treat the
		// autocheck box as a boolean to control the property
		if (m_hWndTrackbar || m_hWndEdit || m_hWndProgress)
		{
			fRes = FALSE;
			goto MyExit;
		}
	}
	else
	{
		ASSERT(!(m_Min > m_Max || m_CurrentValue > m_Max || m_CurrentValue < m_Min || m_DefaultValue > m_Max || m_DefaultValue < m_Min));
		if (m_Min > m_Max || m_CurrentValue > m_Max || m_CurrentValue < m_Min || m_DefaultValue > m_Max || m_DefaultValue < m_Min)
		{
			DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s: ERROR: Invalid range or current value", _fx_));
			fRes = FALSE;
			goto MyExit;
		}

		if (m_Min == 0 && m_Max == 1 && m_SteppingDelta == 1)
			m_fCheckBox = TRUE;
	}

	// We're ready to rock & roll
	m_Active = TRUE;

	// Re-enable appropriate controls
	if (m_IDLabel)
	{
		EnableWindow(GetDlgItem(m_hDlg, m_IDLabel), TRUE);
	}
	if (m_hWndMin)
	{
		SetDlgItemInt(m_hDlg, m_IDMinControl, m_Min, TRUE);
		EnableWindow(m_hWndMin, TRUE);
	}
	if (m_hWndMax)
	{
		SetDlgItemInt(m_hDlg, m_IDMaxControl, m_Max, TRUE);
		EnableWindow(m_hWndMax, TRUE);
	}
	if (m_hWndDefault)
	{
		SetDlgItemInt(m_hDlg, m_IDDefaultControl, m_DefaultValue, TRUE);
		EnableWindow(m_hWndDefault, TRUE);
	}
	if (m_hWndStep)
	{
		SetDlgItemInt(m_hDlg, m_IDStepControl, m_SteppingDelta, TRUE);
		EnableWindow(m_hWndStep, TRUE);
	}
	if (m_hWndEdit)
	{
		UpdateEditBox();
		EnableWindow(m_hWndEdit, TRUE);
	}
	if (m_hWndTrackbar)
	{
		EnableWindow(m_hWndTrackbar, TRUE);

		// Trackbars don't handle negative values, so slide everything positive
		if (m_Min < 0)
			m_TrackbarOffset = -m_Min;

		SendMessage(m_hWndTrackbar, TBM_SETRANGEMAX, FALSE, m_Max + m_TrackbarOffset);
		SendMessage(m_hWndTrackbar, TBM_SETRANGEMIN, FALSE, m_Min + m_TrackbarOffset);

		// Have fun with the keyboards Page Up, Page Down, and arrows
		SendMessage(m_hWndTrackbar, TBM_SETLINESIZE, FALSE, (LPARAM) m_SteppingDelta);
		SendMessage(m_hWndTrackbar, TBM_SETPAGESIZE, FALSE, (LPARAM) m_SteppingDelta);

		UpdateTrackbar();
	}
	if (m_hWndProgress)
	{
		EnableWindow(m_hWndProgress, TRUE);

		// Progress controls don't handle negative values, so slide everything positive
		if (m_Min < 0)
			m_ProgressOffset = -m_Min;

		SendMessage(m_hWndProgress, PBM_SETRANGE32, m_Min + m_ProgressOffset, m_Max + m_ProgressOffset);

		UpdateProgress();

		// Set a timer to update the progress regularly
		SetTimer(m_hDlg, 123456, 250, NULL);
	}
	if (m_hWndAuto)
	{
		// If the control has an auto setting, enable the auto checkbox
		m_CanAutoControl = CanAutoControl();
		EnableWindow (m_hWndAuto, m_CanAutoControl);
		if (m_CanAutoControl)
		{
			Button_SetCheck (m_hWndAuto, GetAuto ());
		}
	}

MyExit:
	DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: end", _fx_));
	return fRes;
}

/****************************************************************************
 *  @doc INTERNAL CPROPEDITMETHOD
 *
 *  @mfunc void | CPropertyEditor | ~CPropertyEditor | Destructor for this class.
 *
 *  @rdesc Nada.
 ***************************************************************************/
CPropertyEditor::~CPropertyEditor()
{
	FX_ENTRY("CPropertyEditor::~CPropertyEditor")

	DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: begin", _fx_));

	// Kill timer if we have a progress bar
	if (m_hWndProgress)
		KillTimer(m_hDlg, 123456);

	DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: end", _fx_));
}

/****************************************************************************
 *  @doc INTERNAL CPROPEDITMETHOD
 *
 *  @mfunc void | CPropertyEditor | OnApply | This member function is
 *    called by the framework when the user chooses the OK or the Apply Now
 *    button. When the framework calls this member function, changes made on
 *    all property pages in the property sheet are accepted, the property
 *    sheet retains focus.
 *
 *  @rdesc Returns TRUE.
 ***************************************************************************/
BOOL CPropertyEditor::OnApply()
{
	int nCurrentValue;

	FX_ENTRY("CPropertyEditor::OnApply")

	DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: begin", _fx_));

	// Make sure the value is a multiple of the stepping delta
	if (m_SteppingDelta)
	{
		nCurrentValue = m_CurrentValue;
		m_CurrentValue = m_CurrentValue / m_SteppingDelta * m_SteppingDelta;
		if (m_CurrentValue != nCurrentValue)
		{
			UpdateEditBox();
			UpdateTrackbar();
		}
	}

	// Backup current value in order to only apply changes if something has really changed
	m_OriginalValue = m_CurrentValue;
	m_OriginalFlags = m_CurrentFlags;

	// Set the value on the device
	SetValue();

	DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: end", _fx_));
	return TRUE;
}

/****************************************************************************
 *  @doc INTERNAL CPROPEDITMETHOD
 *
 *  @mfunc void | CPropertyEditor | HasChanged | This member tests for a
 *    change in value.
 *
 *  @rdesc Returns TRUE if value has changed.
 ***************************************************************************/
BOOL CPropertyEditor::HasChanged()
{
	FX_ENTRY("CPropertyEditor::HasChanged")

	DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: begin", _fx_));
	DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: end", _fx_));

	return (m_CurrentValue != m_OriginalValue);
}

/****************************************************************************
 *  @doc INTERNAL CPROPEDITMETHOD
 *
 *  @mfunc BOOL | CPropertyEditor | OnDefault | Resets the position of the
 *    slide bar and updates the content of the Target windows after the user
 *    pressed the Default button.
 *
 *  @rdesc Returns TRUE if Active, FALSE otherwise.
 ***************************************************************************/
BOOL CPropertyEditor::OnDefault()
{
	BOOL fRes = TRUE;

	FX_ENTRY("CPropertyEditor::OnDefault")

	DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: begin", _fx_));

	if (!m_Active)
	{
		DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s: WARNING: Control not active yet!", _fx_));
		fRes = FALSE;
		goto MyExit;
	}

	// Backup value in case user goes for the Cancel button
	m_CurrentValue = m_DefaultValue;
    m_CurrentFlags = m_DefaultFlags;

	// Update appropriate controls
	UpdateEditBox();
	UpdateTrackbar();
	UpdateAuto();

MyExit:
	DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: end", _fx_));
	return fRes;
}

/****************************************************************************
 *  @doc INTERNAL CPROPEDITMETHOD
 *
 *  @mfunc BOOL | CPropertyEditor | OnScroll | Reads the position of the
 *    slide bar and updates the content of the Target windows after the user
 *    has messed with the slide bar.
 *
 *  @rdesc Returns TRUE if Active, FALSE otherwise.
 ***************************************************************************/
BOOL CPropertyEditor::OnScroll(ULONG nCommand, WPARAM wParam, LPARAM lParam)
{
	int pos;
	int command = LOWORD(wParam);
	BOOL fRes = TRUE;

	FX_ENTRY("CPropertyEditor::OnScroll")

	DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: begin", _fx_));

	// Validate input params
	if (command != TB_ENDTRACK && command != TB_THUMBTRACK && command != TB_LINEDOWN && command != TB_LINEUP && command != TB_PAGEUP && command != TB_PAGEDOWN)
	{
		DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s: ERROR: Invalid input parameter!", _fx_));
		fRes = FALSE;
		goto MyExit;
	}
	ASSERT (IsWindow((HWND) lParam));
	if (!m_Active)
	{
		DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s: WARNING: Control not active yet!", _fx_));
		fRes = FALSE;
		goto MyExit;
	}

	// Retrieve position in slide bar
	pos = (int)SendMessage((HWND) lParam, TBM_GETPOS, 0, 0L);

	// Make sure the value is a multiple of the stepping delta
	if (m_SteppingDelta)
		m_CurrentValue = (pos - m_TrackbarOffset) / m_SteppingDelta * m_SteppingDelta;
	else
		m_CurrentValue = pos - m_TrackbarOffset;

	// Sync edit box to the slide bar
	UpdateEditBox();

MyExit:
	DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: end", _fx_));
	return fRes;
}

/****************************************************************************
 *  @doc INTERNAL CPROPEDITMETHOD
 *
 *  @mfunc BOOL | CPropertyEditor | OnEdit | Reads the content of the
 *    Target window and updates the postion of the slider after the user
 *    has messed with the Target edit control.
 *
 *  @rdesc Returns TRUE.
 ***************************************************************************/
BOOL CPropertyEditor::OnEdit(ULONG nCommand, WPARAM wParam, LPARAM lParam)
{
	BOOL fTranslated;
	int nCurrentValue;

	FX_ENTRY("CPropertyEditor::OnEdit")

	DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: begin", _fx_));

	// We get called even before init has been done -> test for m_Active
	if (m_Active)
	{
		if (!m_fCheckBox)
		{
			// Read the value from the control
			if (m_hWndEdit)
				nCurrentValue = GetDlgItemInt(m_hDlg, m_IDEditControl, &fTranslated, TRUE);

			// Is the value garbage?
			if (fTranslated)
			{
				if (nCurrentValue > m_Max)
				{
					// The value is already large than its max -> clamp it and update the control
					m_CurrentValue = m_Max;
					UpdateEditBox();
				}
				else if (nCurrentValue < m_Min)
				{
					// The value is already smaller than its min -> clamp it and update the control
					m_CurrentValue = m_Min;
					UpdateEditBox();
				}
				else
					m_CurrentValue = nCurrentValue;
			}
			else
			{
				// It's garbage -> Reset the control to its minimum value
				m_CurrentValue = m_Min;
				UpdateEditBox();
			}

			// Sync slide bar to edit box
			UpdateTrackbar();
		}
		else
		{
			// Read the value from the control
			if (m_hWndEdit)
				m_CurrentValue = Button_GetCheck(m_hWndEdit);
		}
	}

	DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: end", _fx_));
	return TRUE;
}

/****************************************************************************
 *  @doc INTERNAL CPROPEDITMETHOD
 *
 *  @mfunc BOOL | CPropertyEditor | OnAuto | Gets the status of the
 *    checkbox.
 *
 *  @rdesc Returns TRUE.
 ***************************************************************************/
BOOL CPropertyEditor::OnAuto(ULONG nCommand, WPARAM wParam, LPARAM lParam)
{
	SetAuto(Button_GetCheck(m_hWndAuto));

	return TRUE;
}

/****************************************************************************
 *  @doc INTERNAL CPROPEDITMETHOD
 *
 *  @mfunc HWND | CPropertyEditor | GetTrackbarHWnd | Helper method to allow
 *    the property page code to access the slide bar window (private member) of
 *    a property.
 *
 *  @rdesc Returns a handle to the slide bar window.
 ***************************************************************************/
HWND CPropertyEditor::GetTrackbarHWnd()
{
	return m_hWndTrackbar;
};

/****************************************************************************
 *  @doc INTERNAL CPROPEDITMETHOD
 *
 *  @mfunc HWND | CPropertyEditor | GetProgressHWnd | Helper method to allow
 *    the property page code to access the progress bar window (private member) of
 *    a property.
 *
 *  @rdesc Returns a handle to the progress window.
 ***************************************************************************/
HWND CPropertyEditor::GetProgressHWnd()
{
	return m_hWndProgress;
};

/****************************************************************************
 *  @doc INTERNAL CPROPEDITMETHOD
 *
 *  @mfunc HWND | CPropertyEditor | GetEditHWnd | Helper method to allow
 *    the property page code to access the Target window (private member) of
 *    a property.
 *
 *  @rdesc Returns a handle to the Target window.
 ***************************************************************************/
HWND CPropertyEditor::GetEditHWnd()
{
	return m_hWndEdit;
};

/****************************************************************************
 *  @doc INTERNAL CPROPEDITMETHOD
 *
 *  @mfunc HWND | CPropertyEditor | GetAutoHWnd | Helper method to allow
 *    the property page code to access the auto window (private member) of
 *    a property.
 *
 *  @rdesc Returns a handle to the auto window.
 ***************************************************************************/
HWND CPropertyEditor::GetAutoHWnd()
{
	return m_hWndAuto;
};

/****************************************************************************
 *  @doc INTERNAL CPROPEDITMETHOD
 *
 *  @mfunc BOOL | CPropertyEditor | UpdateEditBox | Updates the content of
 *    the Target window after user has moved the slide bar.
 *
 *  @rdesc Returns TRUE.
 ***************************************************************************/
BOOL CPropertyEditor::UpdateEditBox()
{
	if (m_hWndEdit)
	{
		if (!m_fCheckBox)
			SetDlgItemInt(m_hDlg, m_IDEditControl, m_CurrentValue, TRUE);
		else
			Button_SetCheck(m_hWndEdit, m_CurrentValue);
	}

	return TRUE;
}

/****************************************************************************
 *  @doc INTERNAL CPROPEDITMETHOD
 *
 *  @mfunc BOOL | CPropertyEditor | UpdateTrackbar | Updates the position of
 *    the slide bar after user has messed with the Target window.
 *
 *  @rdesc Returns TRUE.
 ***************************************************************************/
BOOL CPropertyEditor::UpdateTrackbar()
{
	if (m_hWndTrackbar)
		SendMessage(m_hWndTrackbar, TBM_SETPOS, TRUE, (LPARAM) m_CurrentValue + m_TrackbarOffset);

	return TRUE;
}

/****************************************************************************
 *  @doc INTERNAL CPROPEDITMETHOD
 *
 *  @mfunc BOOL | CPropertyEditor | UpdateProgress | Updates the position of
 *    the progress bar.
 *
 *  @rdesc Returns TRUE.
 ***************************************************************************/
BOOL CPropertyEditor::UpdateProgress()
{
	// Get current value from the device
	GetValue();

	if (m_hWndProgress)
		SendMessage(m_hWndProgress, PBM_SETPOS, (WPARAM) m_CurrentValue + m_ProgressOffset, 0);

	UpdateEditBox();

	return TRUE;
}

/****************************************************************************
 *  @doc INTERNAL CPROPEDITMETHOD
 *
 *  @mfunc BOOL | CPropertyEditor | UpdateAuto | Updates the auto checkbox
 *
 *  @rdesc Returns TRUE.
 ***************************************************************************/
BOOL CPropertyEditor::UpdateAuto()
{
	if (m_hWndAuto && CanAutoControl())
	{
		m_CanAutoControl = GetAuto();
	}

	return TRUE;
}

/****************************************************************************
 *  @doc INTERNAL CPROPEDITMETHOD
 *
 *  @mfunc HRESULT | CPropertyEditor | CanAutoControl | This method
 *    retrieves the automatic control capabilities for a property.
 *
 *  @rdesc This method returns TRUE if automatic control is supported, FALSE
 *    otherwise.
 ***************************************************************************/
BOOL CPropertyEditor::CanAutoControl(void)
{
	FX_ENTRY("CPropertyEditor::CanAutoControl")

	DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: begin", _fx_));

	DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: end", _fx_));

	return m_CapsFlags & TAPIControl_Flags_Auto;
}

/****************************************************************************
 *  @doc INTERNAL CPROPEDITMETHOD
 *
 *  @mfunc HRESULT | CPropertyEditor | GetAuto | This method
 *    retrieves the current automatic control mode of a property.
 *
 *  @rdesc This method returns TRUE if automatic control is supported, FALSE
 *    otherwise.
 ***************************************************************************/
BOOL CPropertyEditor::GetAuto(void)
{
	FX_ENTRY("CPropertyEditor::GetAuto")

	DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: begin", _fx_));

	GetValue();

	DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: end", _fx_));

	return m_CurrentFlags & TAPIControl_Flags_Auto; 
}

/****************************************************************************
 *  @doc INTERNAL CPROPEDITMETHOD
 *
 *  @mfunc HRESULT | CPropertyEditor | SetAuto | This method
 *    sets the automatic control mode of a property.
 *
 *  @parm BOOL | fAuto | Specifies the automatic control mode.
 *
 *  @rdesc This method returns TRUE.
 ***************************************************************************/
BOOL CPropertyEditor::SetAuto(BOOL fAuto)
{
	FX_ENTRY("CPropertyEditor::SetAuto")

	DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: begin", _fx_));

	m_CurrentFlags = (fAuto ? TAPIControl_Flags_Auto : (m_CapsFlags & TAPIControl_Flags_Manual) ? TAPIControl_Flags_Manual : TAPIControl_Flags_None);

	SetValue();

	DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: end", _fx_));

	return TRUE; 
}

#endif
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\net\tapi\skywalker\filters\video\tapivcap\resource.h ===
//{{NO_DEPENDENCIES}}
// Microsoft Developer Studio generated include file.
// Used by TAPIVCap.rc
//
#define IDD_CAMERA_CONTROL             1000
#define IDD_VIDEO_SETTINGS             1001
#define IDD_TEST_CAPTURE_PIN_PROPERTIES	102
#define IDD_TEST_PREVIEW_PIN_PROPERTIES	103
#define IDD_TEST_STILL_IMAGE_PIN_PROPERTIES 104
#define IDD_TEST_RTPPD_PIN_PROPERTIES	105
#define IDC_DEFAULT                     106
#define IDC_DEVICE_SETTINGS             107
#define IDC_CAMERA_CONTROLS             108
#define IDC_BRIGHTNESS                  110
#define IDC_CONTRAST                    111
#define IDC_HUE                         112
#define IDC_SATURATION                  113
#define IDC_SHARPNESS                   114
#define IDC_WHITE                       115
#define IDC_PAN                         116
#define IDC_TILT                        117
#define IDC_ROLL                        118
#define IDC_HUE_STATIC                  120
#define IDC_BRIGHTNESS_STATIC           121
#define IDC_CONTRAST_STATIC             122
#define IDC_SATURATION_STATIC           123
#define IDC_SHARPNESS_STATIC            124
#define IDC_WHITE_STATIC                125
#define IDC_GAMMA_STATIC                126
#define IDC_BACKLIGHT_STATIC            127
#define IDC_ZOOM_STATIC                 128
#define IDC_FOCUS_STATIC                129
#define IDC_TILT_STATIC                 130
#define IDC_EXPOSURE_STATIC             131
#define IDC_IRIS_STATIC                 132
#define IDC_PAN_STATIC                  133
#define IDC_ROLL_STATIC                 134
#define IDC_SLIDER_WHITEBAL             140
#define IDC_SLIDER_BRIGHTNESS           141
#define IDC_SLIDER_CONTRAST             142
#define IDC_SLIDER_HUE                  143
#define IDC_SLIDER_SATURATION           144
#define IDC_SLIDER_SHARPNESS            145
#define IDC_SLIDER_FOCUS                146
#define IDC_SLIDER_GAMMA                147
#define IDC_SLIDER_BACKLIGHT            148
#define IDC_SLIDER_ZOOM                 149
#define IDC_SLIDER_TILT                 150
#define IDC_SLIDER_EXPOSURE             151
#define IDC_SLIDER_IRIS                 152
#define IDC_SLIDER_PAN                  153
#define IDC_SLIDER_ROLL                 154
#define IDC_TXT_HUE_CURRENT             160
#define IDC_TXT_BRIGHTNESS_CURRENT      161
#define IDC_TXT_CONTRAST_CURRENT        162
#define IDC_TXT_SATURATION_CURRENT      163
#define IDC_TXT_SHARPNESS_CURRENT       164
#define IDC_TXT_ZOOM_CURRENT            165
#define IDC_TXT_WHITE_CURRENT           166
#define IDC_TXT_FOCUS_CURRENT           167
#define IDC_TXT_GAMMA_CURRENT           168
#define IDC_TXT_BACKLIGHT_CURRENT       169
#define IDC_TXT_TILT_CURRENT            170
#define IDC_TXT_EXPOSURE_CURRENT        171
#define IDC_TXT_IRIS_CURRENT            172
#define IDC_TXT_PAN_CURRENT             173
#define IDC_TXT_ROLL_CURRENT            174
#define IDC_CB_AUTO_BRIGHTNESS          180
#define IDC_CB_AUTO_CONTRAST            181
#define IDC_CB_AUTO_HUE                 182
#define IDC_CB_AUTO_SATURATION          183
#define IDC_CB_AUTO_SHARPNESS           184
#define IDC_CB_AUTO_WHITEBAL            185
#define IDC_CB_AUTO_GAMMA               186
#define IDC_CB_AUTO_BACKLIGHT           187
#define IDC_CB_AUTO_ZOOM                188
#define IDC_CB_AUTO_FOCUS               189
#define IDC_CB_AUTO_TILT                190
#define IDC_CB_AUTO_EXPOSURE            191
#define IDC_CB_AUTO_IRIS                192
#define IDC_CB_AUTO_PAN                 193
#define IDC_CB_AUTO_ROLL                194
#define IDS_ZOOM                        200
#define IDS_FOCUS                       201
#define IDS_TILT                        202
#define IDS_EXPOSURE                    203
#define IDS_IRIS                        204
#define IDS_PAN                         205
#define IDS_ROLL                        206
#define IDS_BRIGHTNESS                  207
#define IDS_CONTRAST                    208
#define IDS_HUE                         209
#define IDS_SATURATION                  210
#define IDS_SHARPNESS                   211
#define IDS_WHITEBAL                    212
#define IDS_GAMMA                       213
#define IDS_BACKLIGHT                   214
#define IDS_UNKNOWN_DEVICE_NAME         215

#define IDC_STATIC                      -1

#define IDS_M263_Capture_QCIF			20
#define IDS_M263_Capture_CIF			21
#define IDS_M263_Capture_SQCIF			22
#define IDS_M261_Capture_QCIF			23
#define IDS_M261_Capture_CIF			24

#ifdef USE_PROPERTY_PAGES

#define IDS_BITRATECONTROLPROPNAME      1
#define IDS_NETWORKSTATSPROPNAME        2
#define IDS_PROGREFPROPNAME             3
#define IDS_CAMERACONTROLPROPNAME       4
#define IDS_CAPTUREFORMATSPROPNAME      5
#define IDS_PREVIEWFORMATSPROPNAME      6
#define IDS_DEVICEPROPNAME              7
#define IDS_CPUCPROPNAME                8
#define IDS_PROCAMPPROPNAME				9
#define IDS_RTPPDPROPNAME				10
#define IDS_ERROR_CONNECTING_TITLE      11
#define IDS_ERROR_CONNECTING            12

#ifdef USE_NETWORK_STATISTICS
#define IDD_NetworkStatsProperties      100
#endif
#define IDD_CaptureFormatProperties     101
#define IDD_PreviewFormatProperties     102
#define IDD_CameraControlProperties     103
#ifdef USE_PROGRESSIVE_REFINEMENT
#define IDD_ProgRefinemntProperties     104
#endif
#define IDD_CaptureDeviceProperties     105
#ifdef USE_CPU_CONTROL
#define IDD_CPUControlProperties        106
#endif
#define IDD_VideoProcAmpProperties      107
#define IDD_RtpPdControlProperties      108

#define IDC_BitrateControl_Label        200
#define IDC_BitrateControl_Minimum      201
#define IDC_BitrateControl_Maximum      202
#define IDC_BitrateControl_Default      203
#define IDC_BitrateControl_Stepping     204
#define IDC_BitrateControl_Edit         205
#define IDC_BitrateControl_Slider       206
#define IDC_BitrateControl_Meter        207
#define IDC_BitrateControl_Actual       208

#define IDC_FrameRateControl_Label      210
#define IDC_FrameRateControl_Minimum    211
#define IDC_FrameRateControl_Maximum    212
#define IDC_FrameRateControl_Default    213
#define IDC_FrameRateControl_Stepping   214
#define IDC_FrameRateControl_Edit       215
#define IDC_FrameRateControl_Slider     216
#define IDC_FrameRateControl_Meter      217
#define IDC_FrameRateControl_Actual     218

#define IDC_CONTROL_DEFAULT             230

#define IDC_FORMAT_Compression          240
#define IDC_FORMAT_FlipVertical         241
#define IDC_FORMAT_FlipHorizontal       242

#define IDC_PacketLossRate_Label        300
#define IDC_PacketLossRate_Minimum      301
#define IDC_PacketLossRate_Maximum      302
#define IDC_PacketLossRate_Default      303
#define IDC_PacketLossRate_Stepping     304
#define IDC_PacketLossRate_Edit         305
#define IDC_PacketLossRate_Slider       306

#define IDC_RandomBitErrorRate_Label    310
#define IDC_RandomBitErrorRate_Minimum  311
#define IDC_RandomBitErrorRate_Maximum  312
#define IDC_RandomBitErrorRate_Default  313
#define IDC_RandomBitErrorRate_Stepping 314
#define IDC_RandomBitErrorRate_Edit     315
#define IDC_RandomBitErrorRate_Slider   316

#define IDC_BurstErrorDuration_Label    320
#define IDC_BurstErrorDuration_Minimum  321
#define IDC_BurstErrorDuration_Maximum  322
#define IDC_BurstErrorDuration_Default  323
#define IDC_BurstErrorDuration_Stepping 324
#define IDC_BurstErrorDuration_Edit     325
#define IDC_BurstErrorDuration_Slider   326

#define IDC_BurstErrorMaxFrequency_Label 330
#define IDC_BurstErrorMaxFrequency_Minimum 331
#define IDC_BurstErrorMaxFrequency_Maximum 332
#define IDC_BurstErrorMaxFrequency_Default 333
#define IDC_BurstErrorMaxFrequency_Stepping 334
#define IDC_BurstErrorMaxFrequency_Edit 335
#define IDC_BurstErrorMaxFrequency_Slider 336

#define IDC_Pan_Label                   400
#define IDC_Pan_Minimum                 0
#define IDC_Pan_Maximum                 0
#define IDC_Pan_Default                 0
#define IDC_Pan_Stepping                0
#define IDC_Pan_Edit                    405
#define IDC_Pan_Slider                  406
#define IDC_Pan_Auto                    407

#define IDC_Tilt_Label                  410
#define IDC_Tilt_Minimum                0
#define IDC_Tilt_Maximum                0
#define IDC_Tilt_Default                0
#define IDC_Tilt_Stepping               0
#define IDC_Tilt_Edit                   415
#define IDC_Tilt_Slider                 416
#define IDC_Tilt_Auto                   417

#define IDC_Roll_Label                  420
#define IDC_Roll_Minimum                0
#define IDC_Roll_Maximum                0
#define IDC_Roll_Default                0
#define IDC_Roll_Stepping               0
#define IDC_Roll_Edit                   425
#define IDC_Roll_Slider                 426
#define IDC_Roll_Auto                   427

#define IDC_Zoom_Label                  430
#define IDC_Zoom_Minimum                0
#define IDC_Zoom_Maximum                0
#define IDC_Zoom_Default                0
#define IDC_Zoom_Stepping               0
#define IDC_Zoom_Edit                   435
#define IDC_Zoom_Slider                 436
#define IDC_Zoom_Auto                   437

#define IDC_Exposure_Label              440
#define IDC_Exposure_Minimum            0
#define IDC_Exposure_Maximum            0
#define IDC_Exposure_Default            0
#define IDC_Exposure_Stepping           0
#define IDC_Exposure_Edit               445
#define IDC_Exposure_Slider             446
#define IDC_Exposure_Auto               447

#define IDC_Iris_Label                  450
#define IDC_Iris_Minimum                0
#define IDC_Iris_Maximum                0
#define IDC_Iris_Default                0
#define IDC_Iris_Stepping               0
#define IDC_Iris_Edit                   455
#define IDC_Iris_Slider                 456
#define IDC_Iris_Auto                   457

#define IDC_Focus_Label                 460
#define IDC_Focus_Minimum               0
#define IDC_Focus_Maximum               0
#define IDC_Focus_Default               0
#define IDC_Focus_Stepping              0
#define IDC_Focus_Edit                  465
#define IDC_Focus_Slider                466
#define IDC_Focus_Auto                  467

#define IDC_FlipVertical_Edit           470

#define IDC_FlipHorizontal_Edit         480

#define IDC_Brightness_Label            500
#define IDC_Brightness_Minimum          0
#define IDC_Brightness_Maximum          0
#define IDC_Brightness_Default          0
#define IDC_Brightness_Stepping         0
#define IDC_Brightness_Edit             505
#define IDC_Brightness_Slider           506
#define IDC_Brightness_Auto             507

#define IDC_Contrast_Label              510
#define IDC_Contrast_Minimum            0
#define IDC_Contrast_Maximum            0
#define IDC_Contrast_Default            0
#define IDC_Contrast_Stepping           0
#define IDC_Contrast_Edit               515
#define IDC_Contrast_Slider             516
#define IDC_Contrast_Auto               517

#define IDC_Hue_Label                   520
#define IDC_Hue_Minimum                 0
#define IDC_Hue_Maximum                 0
#define IDC_Hue_Default                 0
#define IDC_Hue_Stepping                0
#define IDC_Hue_Edit                    525
#define IDC_Hue_Slider                  526
#define IDC_Hue_Auto                    527

#define IDC_Saturation_Label            530
#define IDC_Saturation_Minimum          0
#define IDC_Saturation_Maximum          0
#define IDC_Saturation_Default          0
#define IDC_Saturation_Stepping         0
#define IDC_Saturation_Edit             535
#define IDC_Saturation_Slider           536
#define IDC_Saturation_Auto             537

#define IDC_Sharpness_Label             540
#define IDC_Sharpness_Minimum           0
#define IDC_Sharpness_Maximum           0
#define IDC_Sharpness_Default           0
#define IDC_Sharpness_Stepping          0
#define IDC_Sharpness_Edit              545
#define IDC_Sharpness_Slider            546
#define IDC_Sharpness_Auto              547

#define IDC_Gamma_Label                 550
#define IDC_Gamma_Minimum               0
#define IDC_Gamma_Maximum               0
#define IDC_Gamma_Default               0
#define IDC_Gamma_Stepping              0
#define IDC_Gamma_Edit                  555
#define IDC_Gamma_Slider                556
#define IDC_Gamma_Auto                  557

#define IDC_ColorEnable_Label           560
#define IDC_ColorEnable_Minimum         0
#define IDC_ColorEnable_Maximum         0
#define IDC_ColorEnable_Default         0
#define IDC_ColorEnable_Stepping        0
#define IDC_ColorEnable_Edit            565
#define IDC_ColorEnable_Slider          566
#define IDC_ColorEnable_Auto            567

#define IDC_WhiteBalance_Label          570
#define IDC_WhiteBalance_Minimum        0
#define IDC_WhiteBalance_Maximum        0
#define IDC_WhiteBalance_Default        0
#define IDC_WhiteBalance_Stepping       0
#define IDC_WhiteBalance_Edit           575
#define IDC_WhiteBalance_Slider         576
#define IDC_WhiteBalance_Auto           577

#define IDC_BacklightComp_Label         580
#define IDC_BacklightComp_Minimum       0
#define IDC_BacklightComp_Maximum       0
#define IDC_BacklightComp_Default       0
#define IDC_BacklightComp_Stepping      0
#define IDC_BacklightComp_Edit          585
#define IDC_BacklightComp_Slider        586
#define IDC_BacklightComp_Auto          587

#define IDC_Device_SourceDlg            600
#define IDC_Device_FormatDlg            601
#define IDC_Device_DisplayDlg           602
#define IDC_Capture_Mode                603
#define IDC_Overlay_Support             604
#define IDC_Device_Version              605
#define IDC_Device_Type                 606
#define IDC_Device_Selection            607

#define IDC_CPULoad_Label               700
#define IDC_CPULoad_Minimum             701
#define IDC_CPULoad_Maximum             702
#define IDC_CPULoad_Default             703
#define IDC_CPULoad_Stepping            704
#define IDC_CPULoad_Edit                705
#define IDC_CPULoad_Slider              706
#define IDC_CPULoad_Meter               707
#define IDC_CPULoad_Actual              708

#define IDC_MaxProcessingTime_Label     710
#define IDC_MaxProcessingTime_Minimum   711
#define IDC_MaxProcessingTime_Maximum   712
#define IDC_MaxProcessingTime_Default   713
#define IDC_MaxProcessingTime_Stepping  714
#define IDC_MaxProcessingTime_Edit      715
#define IDC_MaxProcessingTime_Slider    716
#define IDC_MaxProcessingTime_Meter     717
#define IDC_MaxProcessingTime_Actual    718

#define IDC_ProgRef_OneProg             801
#define IDC_ProgRef_ContProg            802
#define IDC_ProgRef_IndProg             803
#define IDC_ProgRef_ContIndProg         804
#define IDC_ProgRef_AbortOne            805
#define IDC_ProgRef_AbortCont           806

#define IDC_RtpPd_Label                 900
#define IDC_RtpPd_Minimum               901
#define IDC_RtpPd_Maximum               902
#define IDC_RtpPd_Default               903
#define IDC_RtpPd_Stepping              904
#define IDC_RtpPd_Edit                  905
#define IDC_RtpPd_Slider                906

// Next default values for new objects
// 
#ifdef APSTUDIO_INVOKED
#ifndef APSTUDIO_READONLY_SYMBOLS
#define _APS_NO_MFC                     1
#define _APS_NEXT_RESOURCE_VALUE        105
#define _APS_NEXT_COMMAND_VALUE         40001
#define _APS_NEXT_CONTROL_VALUE         341
#define _APS_NEXT_SYMED_VALUE           116
#endif
#endif

#endif
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\net\tapi\skywalker\filters\video\tapivcap\rtppd.h ===
/****************************************************************************
 *  @doc INTERNAL RTPPD
 *
 *  @module RtpPd.h | Header file for the <c CRtpPdPin> class methods
 *    used to implement the RTP packetization descriptor output pin.
 ***************************************************************************/

#ifndef _RTPPD_H_
#define _RTPPD_H_

/*****************************************************************************
 * @doc EXTERNAL CONSTANTS
 *
 * @const 1350 | MAX_RTP_PACKET_SIZE | Maximum RTP packet size.
 *
 * @const 512 | MIN_RTP_PACKET_SIZE | Minimum RTP packet size.
 *
 * @const 1350 | DEFAULT_RTP_PACKET_SIZE | Default RTP packet size.
 *
 * @const 4096 | MAX_RTP_PD_BUFFER_SIZE | Maximum RTP packetization descriptor
 *    buffer size.
 ****************************************************************************/
#define MAX_RTP_PACKET_SIZE 1350
#define MIN_RTP_PACKET_SIZE 512
#define DEFAULT_RTP_PACKET_SIZE MAX_RTP_PACKET_SIZE
#define MAX_RTP_PD_BUFFER_SIZE 4096

/*****************************************************************************
 *  @doc INTERNAL CRTPPDSTRUCTENUM
 *
 *  @struct RTP_PD | The <t RTP_PD> structure is used
 *    to specify the details of the RTP Pd format.
 *
 *  @field DWORD | dwThisHeaderLength | Specifies the length, in bytes, of
 *    this structure. This field is the offset to the next <t RTP_PD>
 *    structure, if there is one, or the start of the payload headers.
 *
 *  @field DWORD | dwPayloadHeaderOffset | Specifies the offset from the start
 *    of the RTP packetization descriptor data to the first byte of the payload
 *    header.
 *
 *  @field DWORD | dwPayloadHeaderLength | Specifies the length, in bytes, of
 *    the payload header.
 *
 *  @field DWORD | dwPayloadStartBitOffset | Specifies the offset from the
 *    start of the corresponding compressed video buffer to the first bit of
 *    the payload data associated with this <t RTP_PD> structure.
 *
 *  @field DWORD | dwPayloadEndBitOffset | Specifies the offset from the start
 *    of the corresponding compressed video buffer to the last bit of the
 *    payload data associated with this <t RTP_PD> structure.
 *
 *  @field DWORD | fEndMarkerBit | If set to TRUE, this flag signals that
 *    this structure applies to the last chunk of a video frame. Typically,
 *    only the last packet descriptor in a series of descriptors would have
 *    this flag turned on. However, this may not be the case for devices
 *    that do not respect frame boundaries and fill video capture buffers
 *    with truncated or multiple video frames.
 *
 *  @field DWORD | dwLayerId | Specifies the ID of the encoding layer this
 *    descriptor applies to. For standard video encoders, this field is
 *    always set to 0. In the case of multi-layered encoders, this field
 *    shall be set to 0 for the base layer, 1 for the first enhancement
 *    layer, 2 for the next enhancement layer, etc.
 *
 *  @field DWORD | dwTimestamp | Specifies the value of the timestamp field
 *    to be set by the downstream filter when creating the RTP header for
 *    this packet. The units and ranges for this field shall adhere to the
 *    definition of timestamp given in section 5.1 of RFC 1889.
 *
 *  @field DWORD | dwAudioAttributes | Specifies some bitfield attributes
 *    used to characterize the sample in the audio stream associated to this
 *    RTP packetization descriptor. This field shall always be set to 0,
 *    unless the audio sample described by this RTP packetization descriptor
 *    structure is a silent frame, in which case, this field shall be set
 *    to AUDIO_SILENT (defined as 1).
 *
 *  @field DWORD | dwVideoAttributes | Specifies some bitfield attributes
 *    used to characterize the sample in the video stream associated to this
 *    RTP packetization descriptor. There are no video attributes defined at
 *    this time. Therefore, this field shall always be set to 0.
 *
 *  @field DWORD | dwReserved | Reserved. Shall all be set to 0.
 ***************************************************************************/
typedef struct tagRTP_PD
{
    DWORD dwThisHeaderLength;
    DWORD dwPayloadHeaderOffset;
    DWORD dwPayloadHeaderLength;
    DWORD dwPayloadStartBitOffset;
    DWORD dwPayloadEndBitOffset;
	BOOL  fEndMarkerBit;
    DWORD dwLayerId;
    DWORD dwTimestamp;
	union {
	DWORD dwAudioAttributes;
	DWORD dwVideoAttributes;
	};
    DWORD dwReserved;
} RTP_PD, *PRTP_PD;

/*****************************************************************************
 *  @doc INTERNAL CRTPPDSTRUCTENUM
 *
 *  @struct RTP_PD_HEADER | The <t RTP_PD_HEADER> structure is used
 *    to specify the details of the RTP Pd format.
 *
 *  @field DWORD | dwThisHeaderLength | Specifies the length, in bytes, of
 *    this structure. This field is the offset to the first <t RTP_PD>
 *    structure.
 *
 *  @field DWORD | dwTotalByteLength | Specifies the length, in bytes, of the
 *    entire data. This includes this structure, the <t RTP_PD> structures,
 *    and the payload information.
 *
 *  @field DWORD | dwNumHeaders | Specifies the number of <t RTP_PD>
 *    structures.
 *
 *  @field DWORD | dwReserved | Reserved. Shall be set to 0.
 ***************************************************************************/
typedef struct tagRTP_PD_HEADER
{
    DWORD dwThisHeaderLength;
    DWORD dwTotalByteLength;
    DWORD dwNumHeaders;
    DWORD dwReserved;
} RTP_PD_HEADER, *PRTP_PD_HEADER;

/*****************************************************************************
 *  @doc INTERNAL CRTPPDSTRUCTENUM
 *
 *  @struct RTP_PD_INFO | The <t RTP_PD_INFO> structure is used
 *    to specify the details of the RTP Pd format.
 *
 *  @field REFERENCE_TIME | AvgTimePerSample | Specifies the average time per
 *    list of RTP packet descriptor, in 100ns units. This value shall be
 *    identical to the value of the <p AvgTimePerFrame> field of the video
 *    info header of the related compressed video stream format.
 *
 *  @field DWORD | dwMaxRTPPacketizationDescriptorBufferSize | Specifies the
 *    maximum size in bytes of the entire RTP packetization descriptor buffer.
 *    The format of this buffer is described in the following section. The
 *    maximum size of the entire RTP packetization descriptor buffer rarely
 *    needs to exceed a few hundred bytes.
 *
 *  @field DWORD | dwMaxRTPPayloadHeaderSize | Specifies the maximum size in
 *    bytes of the payload header data for one RTP packet. For example, the
 *    maximum size of a payload header for H.263 version 1 is 12 bytes (Mode
 *    C header).
 *
 *  @field DWORD | dwMaxRTPPacketSize | Specifies the maximum RTP packet
 *    size in bytes to be described by the list of packetization descriptor.
 *    Typically, this number is just below the MTU size of the network.
 *
 *  @field DWORD | dwNumLayers | Specifies the number of encoding layers to
 *    be described by the list of packetization descriptor. Typically, this
 *    number is equal to 1. Only in the case of multi-layered encoders would
 *    this number be higher than 1.
 *
 *  @field DWORD | dwPayloadType | Specifies the static payload type the
 *    stream describes. If the RTP packetization descriptors do not apply to
 *    an existing static payload type but a dynamic payload type, this field
 *    shall be set to DYNAMIC_PAYLOAD_TYPE (defined as MAXDWORD).
 *
 *  @field DWORD | dwDescriptorVersion | Specifies a version identifier
 *    qualifying the format of packetization descriptors. This field shall
 *    be set to VERSION_1 (defined as 1UL) to identify the packetization
 *    descriptor structures described in the next section.
 *
 *  @field DWORD | dwReserved[4] | Reserved. Shall all be set to 0.
 ***************************************************************************/
typedef struct tagRTP_PD_INFO {
	REFERENCE_TIME	AvgTimePerSample;
	DWORD			dwMaxRTPPacketizationDescriptorBufferSize;
	DWORD			dwMaxRTPPayloadHeaderSize;
	DWORD			dwMaxRTPPacketSize;
	DWORD			dwNumLayers;
	DWORD			dwPayloadType;
	DWORD			dwDescriptorVersion;
    DWORD			dwReserved[4];
} RTP_PD_INFO, *PRTP_PD_INFO;

/*****************************************************************************
 *  @doc INTERNAL CRTPPDSTRUCTENUM
 *
 *  @struct RTP_PD_CONFIG_CAPS | The <t RTP_PD_CONFIG_CAPS> structure is used
 *    to store the RTP packetization descriptor configuration capabilities.
 *
 *  @field DWORD | dwSmallestRTPPacketSize | Specifies the size in bytes of the
 *    smallest RTP packet the stream can describe (typically, 512 bytes on Modem).
 *
 *  @field DWORD | dwLargestRTPPacketSize | Specifies the size in bytes of the
 *    largest packet the stream can describe (typically, 1350 bytes on LAN).
 *
 *  @field DWORD | dwRTPPacketSizeGranularity | Specifies the granularity of
 *    the increments between the smallest and largest packet size the stream
 *    supports (ex. 1).
 *
 *  @field DWORD | dwSmallestNumLayers | Specifies the smallest number of
 *    encoding layers the stream can describe (typically 1).
 *
 *  @field DWORD | dwLargestNumLayers | Specifies the largest number of
 *    encoding layers the stream can describe (typically 1).
 *
 *  @field DWORD | dwNumLayersGranularity | Specifies the granularity of the
 *    increments between the smallest and largest number of encoding layers
 *    the stream supports (ex. 0).
 *
 *  @field DWORD | dwNumStaticPayloadTypes | Specifies the number of static
 *    payload types the stream supports. This value is valid between 0 and
 *    4  (ex. 2 if it supports RFC 2190 and 2429 with H.263, but typically
 *    only 1).
 *
 *  @field DWORD | dwStaticPayloadTypes[4] | Specifies an array of static
 *    payload types the stream supports. A stream can support at most 4
 *    static payload types. The number of valid entries in this array is
 *    indicated by the <p dwNumStaticPayloadTypes> field (ex. 34 for H.263).
 *
 *  @field DWORD | dwNumDescriptorVersions | Specifies the number of
 *    packetization descriptor versions the stream supports. This value is
 *    valid between 1 and 4 (typically 1).
 *
 *  @field DWORD | dwDescriptorVersions[4] | Specifies an array of version
 *    identifiers qualifying the format of packetization descriptors. A
 *    stream can support at most 4 packetization descriptor versions. The
 *    number of valid entries in this array is indicated by the
 *    <p dwNumDescriptorVersions> field (ex. VERION_1).
 *
 *  @field DWORD | dwReserved[4] | Reserved. Shall all be set to 0.
 ***************************************************************************/
typedef struct tagRTP_PD_CONFIG_CAPS  {
	DWORD dwSmallestRTPPacketSize;
	DWORD dwLargestRTPPacketSize;
    DWORD dwRTPPacketSizeGranularity;
	DWORD dwSmallestNumLayers;
	DWORD dwLargestNumLayers;
    DWORD dwNumLayersGranularity;
	DWORD dwNumStaticPayloadTypes;
	DWORD dwStaticPayloadTypes[4];
	DWORD dwNumDescriptorVersions;
	DWORD dwDescriptorVersions[4];
    DWORD dwReserved[4];
} RTP_PD_CONFIG_CAPS, *PRTP_PD_CONFIG_CAPS;

class CRtpPdSample : public CMediaSample
{
	public:
	CRtpPdSample(IMemAllocator *pAllocator, HRESULT *phr, LPTHKVIDEOHDR ptvh, LPBYTE pBuffer, LONG length) : m_ptvh(ptvh), CMediaSample(NAME("Video Frame"), (CBaseAllocator *)pAllocator, phr, pBuffer, length){};
	LPTHKVIDEOHDR GetFrameHeader() {return m_ptvh;};

	private:
	const LPTHKVIDEOHDR m_ptvh;
};

/****************************************************************************
 *  @doc INTERNAL CRTPPDPINCLASS
 *
 *  @class CRtpPdPin | This class implements the RTP packetization descriptor
 *    output pin.
 *
 *  @mdata CTAPIVCap* | CRtpPdPin | m_pCaptureFilter | Reference to the
 *    parent capture filter.
 *
 *  @mdata ALLOCATOR_PROPERTIES | CTAPIBasePin | m_parms | Out allocator
 *    properties.
 *
 *  @comm Supports IPin. Never created by COM, so no CreateInstance or entry
 *    in global FactoryTemplate table. Only ever created by a <c CTAPIVCap>
 *    object and returned via the EnumPins interface
 ***************************************************************************/
class CRtpPdPin : public CBaseOutputPin, public CBaseStreamControl, public IRTPPDControl, public IMemAllocator
#ifdef USE_PROPERTY_PAGES
, public ISpecifyPropertyPages
#endif
{
	public:
	DECLARE_IUNKNOWN
	CRtpPdPin(IN TCHAR *pObjectName, IN CTAPIVCap *pCaptureFilter, IN HRESULT *pHr, IN LPCWSTR pName);
	virtual ~CRtpPdPin();
	STDMETHODIMP NonDelegatingQueryInterface(IN REFIID riid, OUT PVOID *ppv);
	static HRESULT CALLBACK CreateRtpPdPin(CTAPIVCap *pCaptureFilter, CRtpPdPin **ppRtpPdPin);

#ifdef USE_PROPERTY_PAGES
	// ISpecifyPropertyPages methods
	STDMETHODIMP GetPages(OUT CAUUID *pPages);
#endif

	// Override CBasePin base class methods
	HRESULT GetMediaType(IN int iPosition, OUT CMediaType *pMediaType);
	HRESULT CheckMediaType(IN const CMediaType *pMediaType);
	HRESULT SetMediaType(IN CMediaType *pMediaType);

	// Implement IMemAllocator
	STDMETHODIMP SetProperties(IN ALLOCATOR_PROPERTIES *pRequest, OUT ALLOCATOR_PROPERTIES *pActual);
	STDMETHODIMP GetProperties(OUT ALLOCATOR_PROPERTIES *pProps);
	STDMETHODIMP Commit();
	STDMETHODIMP Decommit();
	STDMETHODIMP GetBuffer(OUT IMediaSample **ppBuffer, IN REFERENCE_TIME *pStartTime, IN REFERENCE_TIME *pEndTime, IN DWORD dwFlags);
	STDMETHODIMP ReleaseBuffer(IN IMediaSample *pBuffer);

	// Override CBaseOutputPin base class methods
	HRESULT DecideBufferSize(IN IMemAllocator *pAlloc, OUT ALLOCATOR_PROPERTIES *ppropInputRequest);
	HRESULT DecideAllocator(IN IMemInputPin *pPin, OUT IMemAllocator **ppAlloc);

	// Override IQualityControl interface method to receive Notification messages
	STDMETHODIMP Notify(IN IBaseFilter *pSelf, IN Quality q) {return E_NOTIMPL;};

	HRESULT ActiveRun(IN REFERENCE_TIME tStart);
	HRESULT ActivePause();
	HRESULT Flush();
	HRESULT SendFrame(IN CFrameSample *pSample, IN CRtpPdSample *pRSample, IN DWORD dwBytesExtent, IN BOOL bDiscon);

	// Implement IRTPPDControl
	STDMETHODIMP SetMaxRTPPacketSize(IN DWORD dwMaxRTPPacketSize, IN DWORD dwLayerId);
	STDMETHODIMP GetMaxRTPPacketSize(OUT LPDWORD pdwMaxRTPPacketSize, IN DWORD dwLayerId);
	STDMETHODIMP GetMaxRTPPacketSizeRange(OUT LPDWORD pdwMin, OUT LPDWORD pdwMax, OUT LPDWORD pdwSteppingDelta, OUT LPDWORD pdwDefault, IN DWORD dwLayerId);

	private:

	friend class CTAPIVCap;
	friend class CCapturePin;
	friend class CTAPIBasePin;
	friend class CICMConverter;
	friend class CH26XEncoder;

	HRESULT CapturePinActive(BOOL fActive);
	BOOL			m_fCapturing;	// Is the streaming pin active?

	CTAPIVCap *m_pCaptureFilter;

	// Allocator properties
	ALLOCATOR_PROPERTIES m_parms;

	// Target RTP packet size
	DWORD	m_dwMaxRTPPacketSize;
	BOOL	m_fRunning;

	// Payload type
	DWORD	m_dwRTPPayloadType;

    BOOL	Committed() {return m_pCaptureFilter->m_cs.paHdr != NULL;};
};

#endif // _RTPPD_H_
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\net\tapi\skywalker\filters\video\tapivcap\rtppdp.cpp ===
/****************************************************************************
 *  @doc INTERNAL RTPPDP
 *
 *  @module RtpPdP.cpp | Source file for the <c CRtpPdProperty>
 *    class used to implement a property page to test the new TAPI internal
 *    interfaces <i IRTPPDControl>.
 *
 *  @comm This code tests the TAPI Rtp Pd Output Pins <i IRTPPDControl>
 *    implementation. This code is only compiled if USE_PROPERTY_PAGES is
 *    defined.
 ***************************************************************************/

#include "Precomp.h"

#ifdef USE_PROPERTY_PAGES

/****************************************************************************
 *  @doc INTERNAL CRTPPDPMETHOD
 *
 *  @mfunc void | CRtpPdProperty | CRtpPdProperty | This
 *    method is the constructor for Rtp Pd property objects. It
 *    calls the base class constructor, calls InitCommonControlsEx, and saves
 *    a pointer to the <i IRTPPDControl> interface.
 *
 *  @parm HWND | hDlg | Specifies a handle to the parent property page.
 *
 *  @parm ULONG | IDLabel | Specifies a label ID for the property.
 *
 *  @parm ULONG | IDMinControl | Specifies a label ID for the associated
 *    property edit control where the Minimum value of the property appears.
 *
 *  @parm ULONG | IDMaxControl | Specifies a label ID for the associated
 *    property edit control where the Maximum value of the property appears.
 *
 *  @parm ULONG | IDDefaultControl | Specifies a label ID for the associated
 *    property edit control where the Default value of the property appears.
 *
 *  @parm ULONG | IDStepControl | Specifies a label ID for the associated
 *    property edit control where the Stepping Delta value of the property appears.
 *
 *  @parm ULONG | IDEditControl | Specifies a label ID for the associated
 *    property edit control where the value of the property appears.
 *
 *  @parm ULONG | IDTrackbarControl | Specifies a label ID for the associated
 *    property slide bar.
 *
 *  @parm ULONG | IDProgressControl | Specifies a label ID for the associated
 *    property slide bar.
 *
 *  @parm ULONG | IDProperty | Specifies the ID of the Ks property.
 *
 *  @parm IRTPPDControl* | pIRTPPDControl | Specifies a pointer to the
 *    <i IRTPPDControl> interface.
 *
 *  @rdesc Nada.
 ***************************************************************************/
CRtpPdProperty::CRtpPdProperty(HWND hDlg, ULONG IDLabel, ULONG IDMinControl, ULONG IDMaxControl, ULONG IDDefaultControl, ULONG IDStepControl, ULONG IDEditControl, ULONG IDTrackbarControl, ULONG IDProgressControl, ULONG IDProperty, IRTPPDControl *pIRTPPDControl)
: CPropertyEditor(hDlg, IDLabel, IDMinControl, IDMaxControl, IDDefaultControl, IDStepControl, IDEditControl, IDTrackbarControl, IDProgressControl, IDProperty, 0)
{
	INITCOMMONCONTROLSEX cc;

	FX_ENTRY("CRtpPdProperty::CRtpPdProperty")

	DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: begin", _fx_));

	cc.dwSize = sizeof (INITCOMMONCONTROLSEX);
	cc.dwICC  = ICC_UPDOWN_CLASS | ICC_BAR_CLASSES;

	InitCommonControlsEx(&cc);

	// It's fine if the interface pointer is NULL, we'll grey the
	// associated items in the property page
	m_pIRTPPDControl = pIRTPPDControl;

	DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: end", _fx_));
}

/****************************************************************************
 *  @doc INTERNAL CRTPPDPMETHOD
 *
 *  @mfunc void | CRtpPdProperty | ~CRtpPdProperty | This
 *    method is the destructor for Rtp Pd control property objects. It
 *    simply calls the base class destructor.
 *
 *  @rdesc Nada.
 ***************************************************************************/
CRtpPdProperty::~CRtpPdProperty()
{
	FX_ENTRY("CRtpPdProperty::~CRtpPdProperty")

	DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: begin", _fx_));

	DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: end", _fx_));
}

/****************************************************************************
 *  @doc INTERNAL CRTPPDPMETHOD
 *
 *  @mfunc HRESULT | CRtpPdProperty | GetValue | This method queries for
 *    the value of a property.
 *
 *  @rdesc This method returns an HRESULT value that depends on the
 *    implementation of the interface. HRESULT can include one of the
 *    following standard constants, or other values not listed:
 *
 *  @flag E_FAIL | Failure
 *  @flag E_POINTER | Null pointer argument
 *  @flag E_NOTIMPL | Method is not supported
 *  @flag NOERROR | No error
 ***************************************************************************/
HRESULT CRtpPdProperty::GetValue()
{
	HRESULT Hr = E_NOTIMPL;

	FX_ENTRY("CRtpPdProperty::GetValue")

	DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: begin", _fx_));

	switch (m_IDProperty)
	{									
		case IDC_RtpPd_MaxPacketSize:
			if (m_pIRTPPDControl && SUCCEEDED (Hr = m_pIRTPPDControl->GetMaxRTPPacketSize((LPDWORD)&m_CurrentValue, 0)))
			{
				DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s:   SUCCESS: *pdwMaxRTPPacketSize=%ld", _fx_, m_CurrentValue));
			}
			else
			{
				DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: Failed Hr=0x%08lX", _fx_, Hr));
			}
			break;
		default:
			Hr = E_UNEXPECTED;
			DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: Unknown Rtp Pd control property", _fx_));
	}

	DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: end", _fx_));
	return Hr;
}

/****************************************************************************
 *  @doc INTERNAL CRTPPDPMETHOD
 *
 *  @mfunc HRESULT | CRtpPdProperty | SetValue | This method sets the
 *    value of a property.
 *
 *  @rdesc This method returns an HRESULT value that depends on the
 *    implementation of the interface. HRESULT can include one of the
 *    following standard constants, or other values not listed:
 *
 *  @flag E_FAIL | Failure
 *  @flag E_POINTER | Null pointer argument
 *  @flag E_NOTIMPL | Method is not supported
 *  @flag NOERROR | No error
 ***************************************************************************/
HRESULT CRtpPdProperty::SetValue()
{
	HRESULT Hr = E_NOTIMPL;

	FX_ENTRY("CRtpPdProperty::SetValue")

	DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: begin", _fx_));

	switch (m_IDProperty)
	{
		case IDC_RtpPd_MaxPacketSize:
			if (m_pIRTPPDControl && SUCCEEDED (Hr = m_pIRTPPDControl->SetMaxRTPPacketSize((DWORD)m_CurrentValue, 0UL)))
			{
				DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s:   SUCCESS: dwMaxRTPPacketSize=%ld", _fx_, m_CurrentValue));
			}
			else
			{
				DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: Failed Hr=0x%08lX", _fx_, Hr));
			}
			break;
		default:
			Hr = E_UNEXPECTED;
			DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: Unknown Rtp Pd control property", _fx_));
	}

	DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: end", _fx_));
	return Hr;
}

/****************************************************************************
 *  @doc INTERNAL CRTPPDPMETHOD
 *
 *  @mfunc HRESULT | CRtpPdProperty | GetRange | This method retrieves
 *    the range information of a property.
 *
 *  @rdesc This method returns an HRESULT value that depends on the
 *    implementation of the interface. HRESULT can include one of the
 *    following standard constants, or other values not listed:
 *
 *  @flag E_FAIL | Failure
 *  @flag E_POINTER | Null pointer argument
 *  @flag E_NOTIMPL | Method is not supported
 *  @flag NOERROR | No error
 ***************************************************************************/
HRESULT CRtpPdProperty::GetRange()
{
	HRESULT Hr = E_NOTIMPL;

	FX_ENTRY("CRtpPdProperty::GetRange")

	DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: begin", _fx_));

	switch (m_IDProperty)
	{
		case IDC_RtpPd_MaxPacketSize:
			if (m_pIRTPPDControl && SUCCEEDED (Hr = m_pIRTPPDControl->GetMaxRTPPacketSizeRange((LPDWORD)&m_Min, (LPDWORD)&m_Max, (LPDWORD)&m_SteppingDelta, (LPDWORD)&m_DefaultValue, 0UL)))
			{
				DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s:   SUCCESS: *pdwMin=%ld, *pdwMax=%ld, *pdwSteppingDelta=%ld, *pdwDefault=%ld", _fx_, m_Min, m_Max, m_SteppingDelta, m_DefaultValue));
			}
			else
			{
				DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: Failed Hr=0x%08lX", _fx_, Hr));
			}
			break;
		default:
			Hr = E_UNEXPECTED;
			DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: Unknown Rtp Pd control property", _fx_));
	}

	DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: end", _fx_));
	return Hr;
}

/****************************************************************************
 *  @doc INTERNAL CRTPPDPMETHOD
 *
 *  @mfunc HRESULT | CRtpPdProperty | CanAutoControl | This method
 *    retrieves the automatic control capabilities for a property.
 *
 *  @rdesc This method returns TRUE if automatic control is supported, FALSE
 *    otherwise.
 ***************************************************************************/
BOOL CRtpPdProperty::CanAutoControl(void)
{
	FX_ENTRY("CRtpPdProperty::CanAutoControl")

	DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: begin", _fx_));

	DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: end", _fx_));

	return FALSE;
}

/****************************************************************************
 *  @doc INTERNAL CRTPPDPMETHOD
 *
 *  @mfunc HRESULT | CRtpPdProperty | GetAuto | This method
 *    retrieves the current automatic control mode of a property.
 *
 *  @rdesc This method returns TRUE if automatic control is supported, FALSE
 *    otherwise.
 ***************************************************************************/
BOOL CRtpPdProperty::GetAuto(void)
{
	FX_ENTRY("CRtpPdProperty::GetAuto")

	DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: begin", _fx_));

	DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: end", _fx_));

	return FALSE; 
}

/****************************************************************************
 *  @doc INTERNAL CRTPPDPMETHOD
 *
 *  @mfunc HRESULT | CRtpPdProperty | SetAuto | This method
 *    sets the automatic control mode of a property.
 *
 *  @parm BOOL | fAuto | Specifies the automatic control mode.
 *
 *  @rdesc This method returns TRUE.
 ***************************************************************************/
BOOL CRtpPdProperty::SetAuto(BOOL fAuto)
{
	FX_ENTRY("CRtpPdProperty::SetAuto")

	DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: begin", _fx_));

	DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: end", _fx_));

	return TRUE; 
}

/****************************************************************************
 *  @doc INTERNAL CRTPPDPMETHOD
 *
 *  @mfunc CUnknown* | CRtpPdProperties | CreateInstance | This
 *    method is called by DShow to create an instance of a TAPI Rtp Pd Control
 *    Property Page. It is referred to in the global structure <t g_Templates>.
 *
 *  @parm LPUNKNOWN | pUnkOuter | Specifies the outer unknown, if any.
 *
 *  @parm HRESULT* | pHr | Specifies the place in which to put any error return.
 *
 *  @rdesc Returns a pointer to the nondelegating CUnknown portion of the
 *    object, or NULL otherwise.
 ***************************************************************************/
CUnknown* CALLBACK CRtpPdPropertiesCreateInstance(LPUNKNOWN pUnkOuter, HRESULT *pHr) 
{
	CUnknown *pUnknown = (CUnknown *)NULL;

	FX_ENTRY("CRtpPdPropertiesCreateInstance")

	DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: begin", _fx_));

	// Validate input parameters
	ASSERT(pHr);
	if (!pHr)
	{
		DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: invalid input parameter", _fx_));
		goto MyExit;
	}

	if (!(pUnknown = new CRtpPdProperties(pUnkOuter, pHr)))
	{
		*pHr = E_OUTOFMEMORY;
		DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: new CRtpPdProperties failed", _fx_));
	}
	else
	{
		DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s:   SUCCESS: new CRtpPdProperties created", _fx_));
	}

MyExit:
	DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: end", _fx_));
	return pUnknown;
}

/****************************************************************************
 *  @doc INTERNAL CRTPPDPMETHOD
 *
 *  @mfunc void | CRtpPdProperties | CRtpPdProperties | This
 *    method is the constructor for the property page object. It simply
 *    calls the constructor of the property page base class.
 *
 *  @parm LPUNKNOWN | pUnkOuter | Specifies the outer unknown, if any.
 *
 *  @parm HRESULT* | pHr | Specifies the place in which to put any error return.
 *
 *  @rdesc Nada.
 ***************************************************************************/
CRtpPdProperties::CRtpPdProperties(LPUNKNOWN pUnk, HRESULT *pHr) : CBasePropertyPage(NAME("TAPI Rtp Pd Control Property Page"), pUnk, IDD_RtpPdControlProperties, IDS_RTPPDPROPNAME)
{
	FX_ENTRY("CRtpPdProperties::CRtpPdProperties")

	DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: begin", _fx_));

	m_pIRTPPDControl = NULL;
	m_NumProperties = NUM_RTPPD_CONTROLS;

	for (int i = 0; i < m_NumProperties; i++)
		m_Controls[i] = NULL;

	DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: end", _fx_));
}

/****************************************************************************
 *  @doc INTERNAL CRTPPDPMETHOD
 *
 *  @mfunc void | CRtpPdProperties | ~CRtpPdProperties | This
 *    method is the destructor for the capture pin property page. It
 *    simply calls the base class destructor after deleting all the controls.
 *
 *  @rdesc Nada.
 ***************************************************************************/
CRtpPdProperties::~CRtpPdProperties()
{
	int		j;

	FX_ENTRY("CRtpPdProperties::~CRtpPdProperties")

	DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: begin", _fx_));

	// Free the controls
	for (j = 0; j < m_NumProperties; j++)
	{
		if (m_Controls[j])
		{
			DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s:   SUCCESS: deleting m_Controls[%ld]=0x%08lX", _fx_, j, m_Controls[j]));
			delete m_Controls[j], m_Controls[j] = NULL;
		}
		else
		{
			DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   WARNING: control already freed", _fx_));
		}
	}

	DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: end", _fx_));
}

/****************************************************************************
 *  @doc INTERNAL CRTPPDPMETHOD
 *
 *  @mfunc HRESULT | CRtpPdProperties | OnConnect | This
 *    method is called when the property page is connected to the filter.
 *
 *  @parm LPUNKNOWN | pUnknown | Specifies the outer unknown, if any.
 *
 *  @parm HRESULT* | pHr | Specifies the place in which to put any error return.
 *
 *  @rdesc This method returns an HRESULT value that depends on the
 *    implementation of the interface. HRESULT can include one of the
 *    following standard constants, or other values not listed:
 *
 *  @flag E_FAIL | Failure
 *  @flag E_POINTER | Null pointer argument
 *  @flag E_NOTIMPL | Method is not supported
 *  @flag NOERROR | No error
 ***************************************************************************/
HRESULT CRtpPdProperties::OnConnect(IUnknown *pUnk)
{
	HRESULT Hr = NOERROR;

	FX_ENTRY("CRtpPdProperties::OnConnect")

	DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: begin", _fx_));

	// Validate input parameters
	ASSERT(pUnk);
	if (!pUnk)
	{
		DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: invalid input parameter", _fx_));
		Hr = E_POINTER;
		goto MyExit;
	}

	// Get the CPU control interface
	if (SUCCEEDED (Hr = pUnk->QueryInterface(__uuidof(IRTPPDControl), (void **)&m_pIRTPPDControl)))
	{
		DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s:   SUCCESS: m_pIRTPPDControl=0x%08lX", _fx_, m_pIRTPPDControl));
	}
	else
	{
		m_pIRTPPDControl = NULL;
		DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: Failed Hr=0x%08lX", _fx_, Hr));
	}

	// It's Ok if we couldn't get interface pointers
	// We'll just grey the controls in the property page
	// to make it clear to the user that they can't
	// control those properties on the capture device
	Hr = NOERROR;

MyExit:
	DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: end", _fx_));
	return Hr;
}

/****************************************************************************
 *  @doc INTERNAL CRTPPDPMETHOD
 *
 *  @mfunc HRESULT | CRtpPdProperties | OnDisconnect | This
 *    method is called when the property page is disconnected from the owning
 *    filter.
 *
 *  @rdesc This method returns an HRESULT value that depends on the
 *    implementation of the interface. HRESULT can include one of the
 *    following standard constants, or other values not listed:
 *
 *  @flag NOERROR | No error
 ***************************************************************************/
HRESULT CRtpPdProperties::OnDisconnect()
{
	FX_ENTRY("CRtpPdProperties::OnDisconnect")

	DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: begin", _fx_));

	// Validate input parameters: we seem to get called several times here
	// Make sure the interface pointer is still valid
	if (!m_pIRTPPDControl)
	{
		DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   WARNING: already disconnected!", _fx_));
	}
	else
	{
		// Release the interface
		m_pIRTPPDControl->Release();
		m_pIRTPPDControl = NULL;
		DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s:   SUCCESS: releasing m_pIRTPPDControl", _fx_));
	}

	DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: end", _fx_));
	return NOERROR;
}

/****************************************************************************
 *  @doc INTERNAL CRTPPDPMETHOD
 *
 *  @mfunc HRESULT | CRtpPdProperties | OnActivate | This
 *    method is called when the property page is activated.
 *
 *  @rdesc This method returns an HRESULT value that depends on the
 *    implementation of the interface. HRESULT can include one of the
 *    following standard constants, or other values not listed:
 *
 *  @flag E_FAIL | Failure
 *  @flag E_POINTER | Null pointer argument
 *  @flag E_NOTIMPL | Method is not supported
 *  @flag NOERROR | No error
 ***************************************************************************/
HRESULT CRtpPdProperties::OnActivate()
{
	HRESULT	Hr = NOERROR;
	int		j;

	FX_ENTRY("CRtpPdProperties::OnActivate")

	DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: begin", _fx_));

	// Create the controls for the properties
	if (m_Controls[0] = new CRtpPdProperty(m_hwnd, IDC_RtpPd_Label, IDC_RtpPd_Minimum, IDC_RtpPd_Maximum, IDC_RtpPd_Default, IDC_RtpPd_Stepping, IDC_RtpPd_Edit, IDC_RtpPd_Slider, 0, IDC_RtpPd_MaxPacketSize, m_pIRTPPDControl))
	{
		DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s:   SUCCESS: m_Controls[0]=0x%08lX", _fx_, m_Controls[0]));
	}
	else
	{
		DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: Out of memory", _fx_));
		goto MyExit;
		Hr = E_OUTOFMEMORY;
	}

	// Initialize all the controls. If the initialization fails, it's Ok. It just means
	// that the TAPI control interface isn't implemented by the device. The dialog item
	// in the property page will be greyed, showing this to the user.
	for (j = 0; j < m_NumProperties; j++)
	{
		if (m_Controls[j]->Init())
		{
			DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s:   SUCCESS: m_Controls[%ld]->Init()", _fx_, j));
		}
		else
		{
			DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   WARNING: m_Controls[%ld]->Init() failed", _fx_, j));
		}
	}

MyExit:
	DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: end", _fx_));
	m_fActivated = TRUE;
	return Hr;
}

/****************************************************************************
 *  @doc INTERNAL CRTPPDPMETHOD
 *
 *  @mfunc HRESULT | CRtpPdProperties | OnDeactivate | This
 *    method is called when the property page is dismissed.
 *
 *  @rdesc This method returns an HRESULT value that depends on the
 *    implementation of the interface. HRESULT can include one of the
 *    following standard constants, or other values not listed:
 *
 *  @flag NOERROR | No error
 ***************************************************************************/
HRESULT CRtpPdProperties::OnDeactivate()
{
	int	j;

	FX_ENTRY("CRtpPdProperties::OnDeactivate")

	DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: begin", _fx_));

	// Free the controls
	for (j = 0; j < m_NumProperties; j++)
	{
		if (m_Controls[j])
		{
			DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s:   SUCCESS: deleting m_Controls[%ld]=0x%08lX", _fx_, j, m_Controls[j]));
			delete m_Controls[j], m_Controls[j] = NULL;
		}
		else
		{
			DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   WARNING: control already freed", _fx_));
		}
	}

	DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: end", _fx_));
	return NOERROR;
}

/****************************************************************************
 *  @doc INTERNAL CRTPPDPMETHOD
 *
 *  @mfunc HRESULT | CRtpPdProperties | OnApplyChanges | This
 *    method is called when the user applies changes to the property page.
 *
 *  @rdesc This method returns an HRESULT value that depends on the
 *    implementation of the interface. HRESULT can include one of the
 *    following standard constants, or other values not listed:
 *
 *  @flag E_FAIL | Failure
 *  @flag E_POINTER | Null pointer argument
 *  @flag E_NOTIMPL | Method is not supported
 *  @flag NOERROR | No error
 ***************************************************************************/
HRESULT CRtpPdProperties::OnApplyChanges()
{
	HRESULT	Hr = NOERROR;
	int		j;
	CMediaType *pmt = NULL;

	FX_ENTRY("CRtpPdProperties::OnApplyChanges")

	DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: begin", _fx_));

	// Apply new targets on video stream
	for (j = 0; j < m_NumProperties; j++)
	{
		ASSERT(m_Controls[j]);
		if (m_Controls[j])
		{
			DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s:   SUCCESS: calling m_Controls[%ld]=0x%08lX->OnApply", _fx_, j, m_Controls[j]));
			if (m_Controls[j]->HasChanged())
				m_Controls[j]->OnApply();
			Hr = NOERROR;
		}
		else
		{
			DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: can't calling m_Controls[%ld]=NULL->OnApply", _fx_, j));
			Hr = E_UNEXPECTED;
		}
	}

	DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: end", _fx_));
	return Hr;
}

/****************************************************************************
 *  @doc INTERNAL CRTPPDPMETHOD
 *
 *  @mfunc BOOL | CRtpPdProperties | OnReceiveMessage | This
 *    method is called when a message is sent to the property page dialog box.
 *
 *  @rdesc By default, returns the value returned by the Win32 DefWindowProc function.
 ***************************************************************************/
BOOL CRtpPdProperties::OnReceiveMessage(HWND hWnd, UINT uMsg, WPARAM wParam, LPARAM lParam) 
{
	int iNotify = HIWORD (wParam);
	int j;

	switch (uMsg)
	{
		case WM_INITDIALOG:
			// This is called before Activate...
			m_hWnd = hWnd;
			return TRUE; // Don't call setfocus

		case WM_HSCROLL:
		case WM_VSCROLL:
			if (m_fActivated)
			{
				// Process all of the Trackbar messages
				for (j = 0; j < m_NumProperties; j++)
				{
					ASSERT(m_Controls[j]);
					if (m_Controls[j]->GetTrackbarHWnd() == (HWND)lParam)
					{
						m_Controls[j]->OnScroll(uMsg, wParam, lParam);
						SetDirty();
					}
				}
			}
			break;

		case WM_COMMAND:

			// This message gets sent even before OnActivate() has been
			// called(!). We need to test and make sure the controls have
			// beeen initialized before we can use them.
			if (m_fActivated)
			{
				// Process all of the edit box messages
				for (j = 0; j < m_NumProperties; j++)
				{
					if (m_Controls[j] && m_Controls[j]->GetEditHWnd() == (HWND)lParam)
					{
						m_Controls[j]->OnEdit(uMsg, wParam, lParam);
						SetDirty();
						break;
					}
				}

				switch (LOWORD(wParam))
				{
					case IDC_CONTROL_DEFAULT:
						for (j = 0; j < m_NumProperties; j++)
						{
							if (m_Controls[j])
								m_Controls[j]->OnDefault();
						}
						break;
					default:
						break;
				}
			}
			break;

		default:
			return FALSE;
	}

	return TRUE;
}

/****************************************************************************
 *  @doc INTERNAL CRTPPDPMETHOD
 *
 *  @mfunc BOOL | CRtpPdProperties | SetDirty | This
 *    method notifies the property page site of changes.
 *
 *  @rdesc Nada.
 ***************************************************************************/
void CRtpPdProperties::SetDirty()
{
	m_bDirty = TRUE;
	if (m_pPageSite)
		m_pPageSite->OnStatusChange(PROPPAGESTATUS_DIRTY);
}

#endif
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\net\tapi\skywalker\filters\video\tapivcap\tapivcap.cpp ===
/****************************************************************************
 *  @doc INTERNAL TAPIVCAP
 *
 *  @module TAPIVCap.cpp | Source file for the <c VCfWCapture>
 *    class used to implement the TAPI Capture Source filter.
 ***************************************************************************/

#include "Precomp.h"

#if DEBUG_MULTIPROCESS
#include <process.h>
#endif //DEBUG_MULTIPROCESS


#ifdef DEBUG
#define DBGUTIL_ENABLE
#endif
#define TAPIVCAP_DEBUG
//#include "dbgutil.h" // this defines the __DBGUTIL_H__ below
#if defined(DBGUTIL_ENABLE) && defined(__DBGUTIL_H__)

  #ifdef TAPIVCAP_DEBUG
    DEFINE_DBG_VARS(tapivcap, (NTSD_OUT | LOG_OUT), 0x0);
  #else
    DEFINE_DBG_VARS(tapivcap, 0, 0);
  #endif
  #define D(f) if(g_dbg_tapivcap & (f))

#else
  #undef TAPIVCAP_DEBUG

  #define D(f) ; / ## /
  #define dprintf ; / ## /
  #define dout ; / ## /
#endif


#ifdef DEBUG
// Setup data
const AMOVIESETUP_MEDIATYPE sudCaptureType[] =
{
        {
                &MEDIATYPE_Video,       // Major type
                &MEDIASUBTYPE_NULL      // Minor type
        }
};

const AMOVIESETUP_MEDIATYPE sudRTPPDType[] =
{
        {
                &KSDATAFORMAT_TYPE_RTP_PD,      // Major type
                &MEDIASUBTYPE_NULL                      // Minor type
        }
};

const AMOVIESETUP_PIN sudCapturePins[] =
{
        {
                L"Capture",                     // Pin string name
                FALSE,                          // Is it rendered
                TRUE,                           // Is it an output
                FALSE,                          // Can we have none
                FALSE,                          // Can we have many
                &CLSID_NULL,            // Connects to filter
                NULL,                           // Connects to pin
                1,                                      // Number of types
                sudCaptureType  // Pin details
        },
        {
                L"Preview",                     // Pin string name
                FALSE,                          // Is it rendered
                TRUE,                           // Is it an output
                FALSE,                          // Can we have none
                FALSE,                          // Can we have many
                &CLSID_NULL,            // Connects to filter
                NULL,                           // Connects to pin
                1,                                      // Number of types
                sudCaptureType  // Pin details
        },
#ifdef USE_OVERLAY
        {
                L"Overlay",                     // Pin string name
                FALSE,                          // Is it rendered
                TRUE,                           // Is it an output
                FALSE,                          // Can we have none
                FALSE,                          // Can we have many
                &CLSID_NULL,            // Connects to filter
                NULL,                           // Connects to pin
                1,                                      // Number of types
                sudCaptureType  // Pin details
        },
#endif
        {
                L"RTP PD",                      // Pin string name
                FALSE,                          // Is it rendered
                TRUE,                           // Is it an output
                FALSE,                          // Can we have none
                FALSE,                          // Can we have many
                &CLSID_NULL,            // Connects to filter
                NULL,                           // Connects to pin
                1,                                      // Number of types
                sudRTPPDType            // Pin details
        }
};

const AMOVIESETUP_FILTER sudVideoCapture =
{
        &__uuidof(TAPIVideoCapture),// Filter CLSID
        L"TAPI Video Capture",  // String name
        MERIT_DO_NOT_USE,               // Filter merit
#ifdef USE_OVERLAY
        4,                                              // Number pins
#else
        3,                                              // Number pins
#endif
        sudCapturePins                  // Pin details
};
#endif



#include "CritSec.h"

extern "C" {
int                     g_IsNT = FALSE;

// we don't want to share out any global var
// #pragma data_seg(".shared")
VIDEOCAPTUREDEVICEINFO  g_aDeviceInfo[MAX_CAPTURE_DEVICES] = {0};
DWORD           g_dwNumDevices = (DWORD)-1L;
// #pragma data_seg()


//------ xtra debug activated if XTRA_TRACE is defined
#include "dbgxtra.h"
//----------------------------------------------------
}

// critical section to protect global var
CRITICAL_SECTION g_CritSec;

#if DXMRTP <= 0

// COM global table of objects in this dll
CFactoryTemplate g_Templates[] =
{
    VIDEO_CAPTURE_TEMPLATE

#ifdef USE_PROPERTY_PAGES
    /* Begin properties */

#ifdef USE_SOFTWARE_CAMERA_CONTROL
    ,CAPCAMERA_CONTROL_TEMPLATE
#endif

#ifdef USE_NETWORK_STATISTICS
    ,NETWORK_STATISTICS_TEMPLATE
#endif

#ifdef USE_PROGRESSIVE_REFINEMENT
    .CAPTURE_PIN_TEMPLATE
#endif

    ,CAPTURE_PIN_PROP_TEMPLATE
    ,PREVIEW_PIN_TEMPLATE
    ,CAPTURE_DEV_PROP_TEMPLATE

#ifdef USE_CPU_CONTROL
    ,CPU_CONTROL_TEMPLATE
#endif

    ,RTP_PD_PROP_TEMPLATE

    /* End properties */
#endif /* USE_PROPERTY_PAGES */
};
int g_cTemplates = SIZEOF_ARRAY(g_Templates);

STDAPI DllRegisterServer()
{
        return AMovieDllRegisterServer2(TRUE);
}

STDAPI DllUnregisterServer()
{
        return AMovieDllRegisterServer2(FALSE);
}

EXTERN_C BOOL WINAPI DllEntryPoint(HANDLE hInst, ULONG lReason, LPVOID lpReserved);

BOOL WINAPI DllMain(HANDLE hInst, DWORD dwReason, LPVOID lpReserved)
{
        switch (dwReason)
        {
                case DLL_PROCESS_ATTACH:
                {
                        OSVERSIONINFO OSVer;

                        OSVer.dwOSVersionInfoSize = sizeof(OSVERSIONINFO);

                        GetVersionEx((LPOSVERSIONINFO)&OSVer);

                        g_IsNT = (OSVer.dwPlatformId == VER_PLATFORM_WIN32_NT);

            __try
            {
                InitializeCriticalSection (&g_CritSec);
            }
            __except (EXCEPTION_EXECUTE_HANDLER)
            {
                return FALSE;
            }

                        if (!g_IsNT)
                        {
                                ThunkInit();
                        }
                        else
                        {
                                if (!NTvideoInitHandleList())
                {
                    return FALSE;
                }
                        }
                        break;
                }

                case DLL_PROCESS_DETACH:
                {
                        if (!g_IsNT)
                        {
                                // We're going away - Disconnect the thunking stuff
                                ThunkTerm();
                        }
                        else
                        {
                                NTvideoDeleteHandleList();
                        }

            DeleteCriticalSection (&g_CritSec);

                        break;
                }
        }

        // Pass the call onto the DShow SDK initialization
        return DllEntryPoint(hInst, dwReason, lpReserved);
}
#else /* DXMRTP <= 0 */
BOOL VideoInit(DWORD dwReason)
{
        switch (dwReason)
        {
                case DLL_PROCESS_ATTACH:
                {
                        OSVERSIONINFO OSVer;

                        OSVer.dwOSVersionInfoSize = sizeof(OSVERSIONINFO);

                        GetVersionEx((LPOSVERSIONINFO)&OSVer);

                        g_IsNT = (OSVer.dwPlatformId == VER_PLATFORM_WIN32_NT);

            __try
            {
                InitializeCriticalSection (&g_CritSec);
            }
            __except (EXCEPTION_EXECUTE_HANDLER)
            {
                return FALSE;
            }

                        if (!g_IsNT)
                        {
                                ThunkInit();
                        }
                        else
                        {
                                if (!NTvideoInitHandleList())
                {
                    return FALSE;
                }
                        }
                        break;
                }

                case DLL_PROCESS_DETACH:
                {
                        if (!g_IsNT)
                        {
                                // We're going away - Disconnect the thunking stuff
                                ThunkTerm();
                        }
                        else
                        {
                                NTvideoDeleteHandleList();
                        }

            DeleteCriticalSection (&g_CritSec);

                        break;
                }
        }
    return TRUE;
}
#endif /* DXMRTP <= 0 */

#if DBG
DWORD g_dwVideoCaptureTraceID = INVALID_TRACEID;
#endif

/****************************************************************************
 *  @doc INTERNAL CTAPIVCAPMETHOD
 *
 *  @mfunc void | CTAPIVCap | CTAPIVCap | This method is the constructor
 *    for the <c CTAPIVCap> object.
 *
 *  @rdesc Nada.
 ***************************************************************************/
CTAPIVCap::CTAPIVCap(IN LPUNKNOWN pUnkOuter, IN TCHAR *pName, OUT HRESULT *pHr)
: m_lock(), CBaseFilter(pName, pUnkOuter, &m_lock, __uuidof(TAPIVideoCapture))
{
        FX_ENTRY("CTAPIVCap::CTAPIVCap")

        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: begin", _fx_));

        // Provide defaults
        m_pCapturePin = NULL;
#ifdef USE_OVERLAY
        m_pOverlayPin = NULL;
#endif
        m_pPreviewPin = NULL;
        m_pRtpPdPin = NULL;
        m_pCapDev = NULL;
        m_fAvoidOverlay = TRUE;
        m_fPreviewCompressedData = TRUE;
        m_dwDeviceIndex = -1;

        // Capture thread management
        m_hThread = NULL;
        m_state = TS_Not;
        m_tid = 0;
        m_hEvtPause = NULL;
        m_hEvtRun = NULL;
        m_pBufferQueue = NULL;
        ZeroMemory(&m_user, sizeof(m_user));
        ZeroMemory(&m_cs, sizeof(m_cs));

        //for the RTP Payload Header Mode (0=draft, 1=RFC2190)
        m_RTPPayloadHeaderMode = RTPPayloadHeaderMode_Draft;

        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: end", _fx_));
}

/****************************************************************************
 *  @doc INTERNAL CTAPIVCAPMETHOD
 *
 *  @mfunc void | CTAPIVCap | ~CTAPIVCap | This method is the destructor
 *    for the <c CTAPIVCap> object.
 *
 *  @rdesc Nada.
 ***************************************************************************/
CTAPIVCap::~CTAPIVCap()
{
        FX_ENTRY("CTAPIVCap::~CTAPIVCap")

        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: begin", _fx_));

        // Ensure that all streams are inactive
        Stop();

        // Release the pins
        if (m_pCapturePin)
                delete m_pCapturePin, m_pCapturePin = NULL;
        if (m_pPreviewPin)
                delete m_pPreviewPin, m_pPreviewPin = NULL;
#ifdef USE_OVERLAY
        if (m_pOverlayPin)
                delete m_pOverlayPin, m_pOverlayPin = NULL;
#endif
        if (m_pRtpPdPin)
                delete m_pRtpPdPin, m_pRtpPdPin = NULL;

        // Release the capture device
        if (m_pCapDev)
                delete m_pCapDev, m_pCapDev = NULL;
        if (m_dwDeviceIndex != -1)
                g_aDeviceInfo[m_dwDeviceIndex].fInUse = FALSE;

        if (m_hThread)
                CloseHandle (m_hThread);
        m_hThread = NULL;

        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: end", _fx_));
}

/****************************************************************************
 *  @doc INTERNAL CTAPIVCAPMETHOD
 *
 *  @mfunc CUnknown* | CTAPIVCap | CreateInstance | This
 *    method is called by DShow to create an instance of the TAPI Video Capture
 *    Source filter referred to in the global structure <t g_Templates>.
 *
 *  @parm LPUNKNOWN | pUnkOuter | Specifies the outer unknown, if any.
 *
 *  @parm HRESULT* | pHr | Specifies the place in which to put any error return.
 *
 *  @rdesc Returns a pointer to the nondelegating CUnknown portion of the
 *    object, or NULL otherwise.
 ***************************************************************************/
CUnknown *CALLBACK CreateTAPIVCapInstance(IN LPUNKNOWN pUnkOuter, OUT HRESULT *pHr)
{
#if DBG
    if (g_dwVideoCaptureTraceID == INVALID_TRACEID)
    {
        // if two threads happen to call this method at the same time, it is
        // serialized inside TraceRegister.
        g_dwVideoCaptureTraceID = TraceRegister(TEXT("dxmrtp_VideoCapture"));
    }
#endif

    CUnknown *pUnknown = NULL;
        DWORD dwNumDevices = 0UL;

        FX_ENTRY("CTAPIVCap::CreateInstance")

        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: begin", _fx_));

        // Validate input parameters
        ASSERT(pHr);
        if (!pHr)
        {
                DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: invalid input parameter", _fx_));
                goto MyExit;
        }

        if (!(pUnknown = new CTAPIVCap(pUnkOuter, NAME("TAPI Video Capture"), pHr)))
        {
                *pHr = E_OUTOFMEMORY;
                DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: new CTAPIVCap failed", _fx_));
        }
        else
        {
                DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s:   SUCCESS: new CTAPIVCap created", _fx_));
        }

        // Make sure that there is at least one capture device installed before creating this filter
        if (FAILED(GetNumVideoCapDevicesInternal(&dwNumDevices,FALSE)) || !dwNumDevices)
        {
                delete pUnknown, pUnknown = NULL;
        }

MyExit:
        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: end", _fx_));
        return pUnknown;
}

/****************************************************************************
 *  @doc INTERNAL CTAPIVCAPMETHOD
 *
 *  @mfunc HRESULT | CTAPIVCap | NonDelegatingQueryInterface | This
 *    method is the nondelegating interface query function. It returns a pointer
 *    to the specified interface if supported. The only interfaces explicitly
 *    supported being <i IAMVfwCaptureDialogs>, <i IAMVideoProcAmp>,
 *    <i ICameraControl>, <i IH245VideoCapability>.
 *
 *  @parm REFIID | riid | Specifies the identifier of the interface to return.
 *
 *  @parm PVOID* | ppv | Specifies the place in which to put the interface
 *    pointer.
 *
 *  @rdesc This method returns an HRESULT value that depends on the
 *    implementation of the interface. HRESULT can include one of the
 *    following standard constants, or other values not listed:
 *
 *  @flag E_FAIL | Failure
 *  @flag E_POINTER | Null pointer argument
 *  @flag NOERROR | No error
 ***************************************************************************/
STDMETHODIMP CTAPIVCap::NonDelegatingQueryInterface(IN REFIID riid, OUT void **ppv)
{
        HRESULT Hr = NOERROR;

        FX_ENTRY("CTAPIVCap::NonDelegatingQueryInterface")

        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: begin", _fx_));

        // Validate input parameters
        ASSERT(ppv);
        if (!ppv)
        {
                DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: invalid input parameter", _fx_));
                Hr = E_POINTER;
                goto MyExit;
        }

        // Retrieve interface pointer
        if (riid == __uuidof(IAMVfwCaptureDialogs))
        {
                if (m_pCapDev)
                        Hr = m_pCapDev->NonDelegatingQueryInterface(riid, ppv);
                else
                {
                        Hr = E_FAIL;
                        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s:   ERROR: NDQI for IAMVfwCaptureDialogs failed Hr=0x%08lX because device hasn't been opened yet or it is not a VfW device", _fx_, Hr));
                }

                goto MyExit;
        }
        else if (riid == __uuidof(IAMVideoControl))
        {
                if (FAILED(Hr = GetInterface(static_cast<IAMVideoControl*>(this), ppv)))
                {
                        DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: NDQI for IAMVideoControl failed Hr=0x%08lX", _fx_, Hr));
                }
                else
                {
                        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s:   SUCCESS: IAMVideoControl*=0x%08lX", _fx_, *ppv));
                }

                goto MyExit;
        }
#ifdef USE_PROPERTY_PAGES
        else if (riid == IID_ISpecifyPropertyPages)
        {
                if (FAILED(Hr = GetInterface(static_cast<ISpecifyPropertyPages*>(this), ppv)))
                {
                        DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: NDQI for ISpecifyPropertyPages failed Hr=0x%08lX", _fx_, Hr));
                }
                else
                {
                        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s:   SUCCESS: ISpecifyPropertyPages*=0x%08lX", _fx_, *ppv));
                }

                goto MyExit;
        }
#endif
        else if (riid == __uuidof(IVideoProcAmp))
        {
                if (m_pCapDev)
                        Hr = m_pCapDev->NonDelegatingQueryInterface(riid, ppv);
                else
                {
                        Hr = E_FAIL;
                        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s:   ERROR: NDQI for IAMVideoProcAmp failed Hr=0x%08lX because device hasn't been opened yet or it is not a WDM device", _fx_, Hr));
                }

                goto MyExit;
        }
        else if (riid == __uuidof(ICameraControl))
        {
                if (m_pCapDev)
                        Hr = m_pCapDev->NonDelegatingQueryInterface(riid, ppv);
                else
                {
                        Hr = E_FAIL;
                        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s:   ERROR: NDQI for ICameraControl failed Hr=0x%08lX because device hasn't been opened yet or it is not a WDM device", _fx_, Hr));
                }

                goto MyExit;
        }
        else if (riid == __uuidof(IVideoDeviceControl))
        {
                if (FAILED(Hr = GetInterface(static_cast<IVideoDeviceControl*>(this), ppv)))
                {
                        DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: NDQI for IVideoDeviceControl failed Hr=0x%08lX", _fx_, Hr));
                }
                else
                {
                        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s:   SUCCESS: IVideoDeviceControl*=0x%08lX", _fx_, *ppv));
                }

                goto MyExit;
        }
        // Retrieve interface pointer
        else if (riid == __uuidof(IRTPPayloadHeaderMode))
        {
                if (FAILED(Hr = GetInterface(static_cast<IRTPPayloadHeaderMode*>(this), ppv)))
                {
                        DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: NDQI for IRTPPayloadHeaderMode failed Hr=0x%08lX", _fx_, Hr));
                }
                else
                {
                        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s:   SUCCESS: IRTPPayloadHeaderMode*=0x%08lX", _fx_, *ppv));
                }

                goto MyExit;
        }

        if (FAILED(Hr = CBaseFilter::NonDelegatingQueryInterface(riid, ppv)))
        {
                if (FAILED(Hr = CUnknown::NonDelegatingQueryInterface(riid, ppv)))
                {
                        DBGOUT((g_dwVideoCaptureTraceID, WARN, "%s:   WARNING: NDQI for {%08lX-%04lX-%04lX-%02lX%02lX-%02lX%02lX%02lX%02lX%02lX%02lX} failed Hr=0x%08lX", _fx_, riid.Data1, riid.Data2, riid.Data3, riid.Data4[0], riid.Data4[1], riid.Data4[2], riid.Data4[3], riid.Data4[4], riid.Data4[5], riid.Data4[6], riid.Data4[7], Hr));
                }
                else
                {
                        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s:   SUCCESS: {%08lX-%04lX-%04lX-%02lX%02lX-%02lX%02lX%02lX%02lX%02lX%02lX}*=0x%08lX", _fx_, riid.Data1, riid.Data2, riid.Data3, riid.Data4[0], riid.Data4[1], riid.Data4[2], riid.Data4[3], riid.Data4[4], riid.Data4[5], riid.Data4[6], riid.Data4[7], *ppv));
                }
        }
        else
        {
                DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s:   SUCCESS: {%08lX-%04lX-%04lX-%02lX%02lX-%02lX%02lX%02lX%02lX%02lX%02lX}*=0x%08lX", _fx_, riid.Data1, riid.Data2, riid.Data3, riid.Data4[0], riid.Data4[1], riid.Data4[2], riid.Data4[3], riid.Data4[4], riid.Data4[5], riid.Data4[6], riid.Data4[7], *ppv));
        }

MyExit:
        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: end", _fx_));
        return Hr;
}

#ifdef USE_PROPERTY_PAGES
/****************************************************************************
 *  @doc INTERNAL CTAPIVCAPMETHOD
 *
 *  @mfunc HRESULT | CTAPIVCap | GetPages | This method Fills a counted
 *    array of GUID values where each GUID specifies the CLSID of each
 *    property page that can be displayed in the property sheet for this
 *    object.
 *
 *  @parm CAUUID* | pPages | Specifies a pointer to a caller-allocated CAUUID
 *    structure that must be initialized and filled before returning. The
 *    pElems field in the CAUUID structure is allocated by the callee with
 *    CoTaskMemAlloc and freed by the caller with CoTaskMemFree.
 *
 *  @rdesc This method returns an HRESULT value that depends on the
 *    implementation of the interface. HRESULT can include one of the
 *    following standard constants, or other values not listed:
 *
 *  @flag E_FAIL | Failure
 *  @flag E_POINTER | Null pointer argument
 *  @flag E_OUTOFMEMORY | Allocation failed
 *  @flag NOERROR | No error
 ***************************************************************************/
STDMETHODIMP CTAPIVCap::GetPages(OUT CAUUID *pPages)
{
        HRESULT Hr = NOERROR;

        FX_ENTRY("CTAPIVCap::GetPages")

        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: begin", _fx_));

        // Validate input parameters
        ASSERT(pPages);
        if (!pPages)
        {
                DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: invalid input parameter", _fx_));
                Hr = E_POINTER;
                goto MyExit;
        }

#ifdef USE_SOFTWARE_CAMERA_CONTROL
        pPages->cElems = 2;
#else
        pPages->cElems = 1;
#endif
        if (!(pPages->pElems = (GUID *) QzTaskMemAlloc(sizeof(GUID) * pPages->cElems)))
        {
                DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: invalid input parameter", _fx_));
                Hr = E_OUTOFMEMORY;
        }
        else
        {
                pPages->pElems[0] = __uuidof(CaptureDevicePropertyPage);
#ifdef USE_SOFTWARE_CAMERA_CONTROL
                pPages->pElems[1] = __uuidof(TAPICameraControlPropertyPage);
#endif
        }

MyExit:
        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: end", _fx_));
        return Hr;
}
#endif

/****************************************************************************
 *  @doc INTERNAL CTAPIVCAPMETHOD
 *
 *  @mfunc HRESULT | CTAPIVCap | GetPinCount | This method returns the pin
 *    count. There is typically a Capture Pin, a Preview pin, and sometimes
 *    an Overlay pin.
 *
 *  @rdesc This method returns the number of pins.
 ***************************************************************************/
int CTAPIVCap::GetPinCount()
{
        DWORD dwNumPins = 0;

        FX_ENTRY("CTAPIVCap::GetPinCount")

        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: begin", _fx_));

        // Count the number of active pins
        if (m_pCapturePin)
                dwNumPins++;
        if (m_pPreviewPin)
                dwNumPins++;
        if (m_pRtpPdPin)
                dwNumPins++;
#ifdef USE_OVERLAY
        if (m_pOverlayPin)
                dwNumPins++;
#endif

        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s:   SUCCESS: dwNumPins=%ld", _fx_, dwNumPins));

        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: end", _fx_));

        return dwNumPins;
}

/****************************************************************************
 *  @doc INTERNAL CTAPIVCAPMETHOD
 *
 *  @mfunc HRESULT | CTAPIVCap | GetPin | This method returns a non-addrefed
 *    pointer to the <c cBasePin> of a pin.
 *
 *  @parm int | n | Specifies the number of the pin.
 *
 *  @rdesc This method returns NULL or a pointer to a <c CBasePin> object.
 ***************************************************************************/
CBasePin *CTAPIVCap::GetPin(IN int n)
{
        CBasePin *pCBasePin;

        FX_ENTRY("CTAPIVCap::GetPin")

        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: begin", _fx_));

        switch(n)
        {
                case 0:
                        pCBasePin = m_pCapturePin;
                        break;

                case 1:
                        pCBasePin = m_pPreviewPin;
                        break;

                case 2:
                        pCBasePin = m_pRtpPdPin;
                        break;

#ifdef USE_OVERLAY
                case 3:
                        pCBasePin = m_pOverlayPin;
                        break;
#endif
                default:
                        DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: Invalid pin number n=%ld", _fx_, n));
                        pCBasePin = NULL;
        }

        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s:   SUCCESS: pCBasePin=0x%08lX", _fx_, pCBasePin));

        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: end", _fx_));

        return pCBasePin;
}

/****************************************************************************
 *  @doc INTERNAL CTAPIVCAPMETHOD
 *
 *  @mfunc HRESULT | CTAPIVCap | Run | This method transitions the filter
 *    from paused to running state if it is not in this state already.
 *
 *  @parm REFERENCE_TIME | tStart | Specifies the reference time value
 *    corresponding to stream time 0.
 *
 *  @rdesc This method returns an HRESULT value that depends on the
 *    implementation of the interface. HRESULT can include one of the
 *    following standard constants, or other values not listed:
 *
 *  @flag E_FAIL | Failure
 *  @flag NOERROR | No error
 ***************************************************************************/
STDMETHODIMP CTAPIVCap::Run(IN REFERENCE_TIME tStart)
{
        HRESULT Hr = NOERROR;

        FX_ENTRY("CTAPIVCap::Run")

        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: begin (tStart=%ld)", _fx_, (LONG)((CRefTime)tStart).Millisecs()));

        CAutoLock cObjectLock(m_pLock);

        // Remember the stream time offset before notifying the pins
        m_tStart = tStart;

        // If we are in the stopped state, first pause the filter.
        if (m_State == State_Stopped)
        {
                // If the real Pause got an error, this will try a second time
                if (FAILED(Hr = Pause()))
                {
                        DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: Pause failed Hr=0x%08lX", _fx_, Hr));
                        goto MyExit;
                }
        }

        // Tell the Stream Control stuff what's going on
        if (m_pPreviewPin)
                m_pPreviewPin->NotifyFilterState(State_Running, tStart);
        if (m_pCapturePin)
                m_pCapturePin->NotifyFilterState(State_Running, tStart);
        if (m_pRtpPdPin)
                m_pRtpPdPin->NotifyFilterState(State_Running, tStart);

        // Now put our streaming video pin into the Run state
        if (m_State == State_Paused)
        {
                int cPins = GetPinCount();

                // Do we have at least a pin?
                if (cPins > 0)
                {
                        if (m_pCapturePin && m_pCapturePin->IsConnected())
                        {
                                if (FAILED(Hr = m_pCapturePin->ActiveRun(tStart)))
                                {
                                        DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: ActiveRun failed Hr=0x%08lX", _fx_, Hr));
                                        goto MyExit;
                                }
                        }

                        if (m_pRtpPdPin && m_pRtpPdPin->IsConnected())
                        {
                                if (FAILED(Hr = m_pRtpPdPin->ActiveRun(tStart)))
                                {
                                        DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: ActiveRun failed Hr=0x%08lX", _fx_, Hr));
                                        goto MyExit;
                                }
                        }

#ifdef USE_OVERLAY
                        if (m_pOverlayPin && m_pOverlayPin->IsConnected())
                        {
                                if (FAILED(Hr = m_pOverlayPin->ActiveRun(tStart)))
                                {
                                        DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: ActiveRun failed Hr=0x%08lX", _fx_, Hr));
                                        goto MyExit;
                                }
                        }
#endif
                        if (m_pPreviewPin && m_pPreviewPin->IsConnected())
                        {
                                if (FAILED(Hr = m_pPreviewPin->ActiveRun(tStart)))
                                {
                                        DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: ActiveRun failed Hr=0x%08lX", _fx_, Hr));
                                        goto MyExit;
                                }
                        }
                }
        }

        m_State = State_Running;

MyExit:
        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: end", _fx_));
        return Hr;
}

/****************************************************************************
 *  @doc INTERNAL CTAPIVCAPMETHOD
 *
 *  @mfunc HRESULT | CTAPIVCap | Pause | This method transitions the filter
 *    the filter to State_Paused state if it is not in this state already.
 *
 *  @rdesc This method returns an HRESULT value that depends on the
 *    implementation of the interface. HRESULT can include one of the
 *    following standard constants, or other values not listed:
 *
 *  @flag E_FAIL | Failure
 *  @flag NOERROR | No error
 ***************************************************************************/
STDMETHODIMP CTAPIVCap::Pause()
{
        HRESULT Hr = NOERROR;

        FX_ENTRY("CTAPIVCap::Pause")

        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: begin", _fx_));

        CAutoLock cObjectLock(m_pLock);

        // We have a driver dialog up that is about to change the capture settings.
        // Now is NOT a good time to start streaming.
        if (m_State == State_Stopped && m_pCapDev->m_fDialogUp)
        {
                DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: Dialog up. SORRY!", _fx_));
                Hr = E_UNEXPECTED;
                goto MyExit;
        }

        // Tell the Stream Control stuff what's going on
        if (m_pPreviewPin)
                m_pPreviewPin->NotifyFilterState(State_Paused, 0);
        if (m_pCapturePin)
                m_pCapturePin->NotifyFilterState(State_Paused, 0);
        if (m_pRtpPdPin)
                m_pRtpPdPin->NotifyFilterState(State_Paused, 0);

        // Notify the pins of the change from Run-->Pause
        if (m_State == State_Running)
        {
                int cPins = GetPinCount();

                // Make sure we have pins
                if (cPins > 0)
                {
                        if (m_pCapturePin && m_pCapturePin->IsConnected())
                        {
                                if (FAILED(Hr = m_pCapturePin->ActivePause()))
                                {
                                        DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: ActivePause failed Hr=0x%08lX", _fx_, Hr));
                                        goto MyExit;
                                }
                        }

                        if (m_pRtpPdPin && m_pRtpPdPin->IsConnected())
                        {
                                if (FAILED(Hr = m_pRtpPdPin->ActivePause()))
                                {
                                        DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: ActivePause failed Hr=0x%08lX", _fx_, Hr));
                                        goto MyExit;
                                }
                        }

#ifdef USE_OVERLAY
                        if (m_pOverlayPin && m_pOverlayPin->IsConnected())
                        {
                                if (FAILED(Hr = m_pOverlayPin->ActivePause()))
                                {
                                        DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: ActivePause failed Hr=0x%08lX", _fx_, Hr));
                                        goto MyExit;
                                }
                        }
#endif
                        if (m_pPreviewPin && m_pPreviewPin->IsConnected())
                        {
                                if (FAILED(Hr = m_pPreviewPin->ActivePause()))
                                {
                                        DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: ActivePause failed Hr=0x%08lX", _fx_, Hr));
                                        goto MyExit;
                                }
                        }
                }
        }

        // notify all pins BACKWARDS! so the overlay pin is started first, so the
        // overlay channel is intitialized before the capture channel (this is the
        // order AVICap did things in and we have to do the same thing or buggy
        // drivers like the Broadway or BT848 based drivers won't preview while
        // capturing.
        if (m_State == State_Stopped)
        {
                int cPins = GetPinCount();
                for (int c = cPins - 1; c >=  0; c--)
                {
                        CBasePin *pPin = GetPin(c);

                        // Disconnected pins are not activated - this saves pins
                        // worrying about this state themselves
                        if (pPin->IsConnected())
                        {
                                if (FAILED(Hr = pPin->Active()))
                                {
                                        DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: Active failed Hr=0x%08lX", _fx_, Hr));
                                        goto MyExit;
                                }
                        }
                }
        }

        m_State = State_Paused;

MyExit:
        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: end", _fx_));
        return Hr;
}

/****************************************************************************
 *  @doc INTERNAL CTAPIVCAPMETHOD
 *
 *  @mfunc HRESULT | CTAPIVCap | Stop | This method transitions the filter
 *    the filter to State_Stopped state if it is not in this state already.
 *
 *  @rdesc This method returns an HRESULT value that depends on the
 *    implementation of the interface. HRESULT can include one of the
 *    following standard constants, or other values not listed:
 *
 *  @flag E_FAIL | Failure
 *  @flag NOERROR | No error
 ***************************************************************************/
STDMETHODIMP CTAPIVCap::Stop()
{
        HRESULT Hr = NOERROR, Hr2;

        FX_ENTRY("CTAPIVCap::Stop")

        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: begin", _fx_));

        CAutoLock cObjectLock(m_pLock);

        // Shame on the base classes
        if (m_State == State_Running)
        {
                if (FAILED(Hr = Pause()))
                {
                        DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: Pause failed Hr=0x%08lX", _fx_, Hr));
                        goto MyExit;
                }
        }

        // Tell the Stream Control stuff what's going on
        if (m_pPreviewPin)
                m_pPreviewPin->NotifyFilterState(State_Stopped, 0);
        if (m_pCapturePin)
                m_pCapturePin->NotifyFilterState(State_Stopped, 0);
        if (m_pRtpPdPin)
                m_pRtpPdPin->NotifyFilterState(State_Stopped, 0);

MyExit:
    Hr2 = CBaseFilter::Stop();

    if (SUCCEEDED(Hr))
    {
        Hr = Hr2;
    }

        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: end", _fx_));
        return Hr;
}

/****************************************************************************
 *  @doc INTERNAL CTAPIVCAPMETHOD
 *
 *  @mfunc HRESULT | CTAPIVCap | SetSyncSource | This method identifies the
 *    reference clock to which the filter should synchronize activity.
 *
 *  @rdesc This method returns an HRESULT value that depends on the
 *    implementation of the interface. HRESULT can include one of the
 *    following standard constants, or other values not listed:
 *
 *  @flag E_FAIL | Failure
 *  @flag E_POINTER | Null pointer argument
 *  @flag NOERROR | No error
 *
 *  @comm The <p pClock> parameter can be NULL, meaning that the filter
 *    should run as fast as possible at its current quality settings
 *    without any attempt to synchronize...
***************************************************************************/
STDMETHODIMP CTAPIVCap::SetSyncSource(IN IReferenceClock *pClock)
{
        HRESULT Hr = NOERROR;

        FX_ENTRY("CTAPIVCap::SetSyncSource")

        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: begin", _fx_));

        // Validate input parameters
        if (!pClock)
        {
                DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   WARNING: Null pointer argument", _fx_));
                Hr = E_POINTER;
                goto MyExit;
        }

        if (m_pCapturePin)
                m_pCapturePin->SetSyncSource(pClock);
        if (m_pPreviewPin)
                m_pPreviewPin->SetSyncSource(pClock);
        if (m_pRtpPdPin)
                m_pRtpPdPin->SetSyncSource(pClock);

        Hr = CBaseFilter::SetSyncSource(pClock);

MyExit:
        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: end", _fx_));
        return Hr;
}

/****************************************************************************
 *  @doc INTERNAL CTAPIVDECMETHOD
 ***************************************************************************/
STDMETHODIMP CTAPIVCap::SetMode(IN RTPPayloadHeaderMode rtpphmMode)
{
        HRESULT Hr = NOERROR;

        FX_ENTRY("CTAPIVCap::SetMode")

        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: begin", _fx_));

        // Validate input parameters
        ASSERT(rtpphmMode == RTPPayloadHeaderMode_Draft || rtpphmMode == RTPPayloadHeaderMode_RFC2190);
        if (!(rtpphmMode == RTPPayloadHeaderMode_Draft || rtpphmMode == RTPPayloadHeaderMode_RFC2190))
        {
                DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: invalid input parameter", _fx_));
                Hr = E_INVALIDARG;
                goto MyExit;
        }

        // Save new target packet size
        m_RTPPayloadHeaderMode = rtpphmMode;

        dout(1, g_dwVideoCaptureTraceID, TRCE, "%s:   New RTP Payload Header mode: %s\n", _fx_, (rtpphmMode == RTPPayloadHeaderMode_RFC2190)?"RFC2190":"Draft");
        //DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s:   New RTP Payload Header mode: %s", _fx_, (rtpphmMode == RTPPayloadHeaderMode_RFC2190)?"RFC2190":"Draft"));

MyExit:
        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: end", _fx_));
        return Hr;
}

/****************************************************************************
 *  @doc INTERNAL CTAPIVCAPMETHOD
 *
 *  @mfunc HRESULT | CTAPIVCap | JoinFilterGraph | This method is used to
 *    inform a filter that it has joined a filter graph.
 *
 *  @parm IFilterGraph | pGraph | Specifies a pointer to the filter graph to
 *    join.
 *
 *  @parm LPCWSTR | pName | Specifies the name of the filter being added.
 *
 *  @rdesc This method returns an HRESULT value that depends on the
 *    implementation of the interface. HRESULT can include one of the
 *    following standard constants, or other values not listed:
 *
 *  @flag E_FAIL | Failure
 *  @flag E_POINTER | Null pointer argument
 *  @flag NOERROR | No error
 *
 *  @comm We don't validate input parameters as both pointers can be
 *    NULL when we leave the graph.
 ***************************************************************************/
STDMETHODIMP CTAPIVCap::JoinFilterGraph(IN IFilterGraph *pGraph, IN LPCWSTR pName)
{
        HRESULT Hr = NOERROR;
        DWORD dwNumDevices = 0UL;

        FX_ENTRY("CTAPIVCap::JoinFilterGraph")

        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: begin", _fx_));

    EnterCriticalSection (&g_CritSec);

#if DEBUG_MULTIPROCESS
    char Buf[100];
    wsprintfA(Buf, "\nPID:%x, %p entered\n", _getpid(), this);
    OutputDebugStringA(Buf);
#endif //DEBUG_MULTIPROCESS


        if(pGraph != NULL) { // only for a true join operation we are interested in having any devices to join to ...
                // Get the number of installed capture devices
                if (FAILED(Hr = GetNumDevices(&dwNumDevices)))          // || !dwNumDevices) <--- this is tested below anyway
                {
                        DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: Couldn't get number of installed devices!", _fx_));
                        Hr = E_FAIL;
                        goto MyExit;
                }

                // Make sure that there is at least one capture device installed before proceeding
                if (!dwNumDevices)
                {
                        DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: There are not capture device installed!", _fx_));
                        Hr = E_FAIL;
                        goto MyExit;
                }
        }

        // Only grab capture device and create the pins when in a graph
        if (m_pCapturePin == NULL && pGraph != NULL)
        {
                dprintf("JoinFilterGraph : ........... m_pCapturePin == NULL && pGraph != NULL\n");
                if (m_dwDeviceIndex == -1)
                {
                        // Use the default capture device
                        if (FAILED(Hr = GetCurrentDevice(&m_dwDeviceIndex)))
                        {
                                DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: Couldn't get current device ID", _fx_, Hr));
                                goto MyExit;
                        }
                }

                // Only open the capture device if it isn't in use
                if (g_aDeviceInfo[m_dwDeviceIndex].fInUse)
                {
                        DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: Device already in use", _fx_, Hr));
                        Hr = E_FAIL;
                        goto MyExit;
                }

                // Reserve the device
                g_aDeviceInfo[m_dwDeviceIndex].fInUse = TRUE;
                DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s:   Reserving device with index m_dwDeviceIndex = %d", _fx_, m_dwDeviceIndex));
                // What's the VfW device Id for this device?
                m_user.uVideoID = g_aDeviceInfo[m_dwDeviceIndex].dwVfWIndex;

                // Create the capture device object
                if (g_aDeviceInfo[m_dwDeviceIndex].nDeviceType == DeviceType_VfW)
                {
                        if (FAILED(Hr = CVfWCapDev::CreateVfWCapDev(this, m_dwDeviceIndex, &m_pCapDev)))
                        {
                                DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: Capture device object couldn't be created!", _fx_));
                                goto MyExit;
                        }
                }
                else if (g_aDeviceInfo[m_dwDeviceIndex].nDeviceType == DeviceType_WDM)
                {
                        if (FAILED(Hr = CWDMCapDev::CreateWDMCapDev(this, m_dwDeviceIndex, &m_pCapDev)))
                        {
                                DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: Capture device object couldn't be created!", _fx_));
                                goto MyExit;
                        }
                }
                else
                {
                    ASSERT(g_aDeviceInfo[m_dwDeviceIndex].nDeviceType == DeviceType_DShow);
                    if (FAILED(Hr = CDShowCapDev::CreateDShowCapDev(this, m_dwDeviceIndex, &m_pCapDev)))
                    {
                        DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: Capture device object couldn't be created!", _fx_));
                        goto MyExit;
                    }
                }


                // Open the device and get the capabilities of the device
                if (FAILED(Hr = m_pCapDev->ConnectToDriver()))
                {
                        DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: ConnectToDriver failed!", _fx_));
                        goto MyExit;
                }


                // Create compressed output pin
                if (FAILED(Hr = CCapturePin::CreateCapturePin(this, &m_pCapturePin)))
                {
                        DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: Capture pin couldn't be created!", _fx_));
                        goto MyError;
                }



                // If we can do h/w preview with overlay, great, otherwise we'll do a non-overlay preview
#ifdef USE_OVERLAY
                if (m_fAvoidOverlay || !m_cs.bHasOverlay || FAILED(Hr = COverlayPin::CreateOverlayPin(this, &m_pOverlayPin)))
                {
                        // We'll use regular preview if we don't get overlay
                        if (FAILED(Hr = CPreviewPin::CreatePreviewPin(this, &m_pPreviewPin)))
                        {
                                DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: Preview pin couldn't be created!", _fx_));
                                goto MyError;
                        }
                }
#else
                if (FAILED(Hr = CPreviewPin::CreatePreviewPin(this, &m_pPreviewPin)))
                {
                        DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: Preview pin couldn't be created!", _fx_));
                        goto MyError;
                }
#endif

                // Create the RTP packetization descriptor pin
                if (FAILED(Hr = CRtpPdPin::CreateRtpPdPin(this, &m_pRtpPdPin)))
                {
                        DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: Rtp Pd pin couldn't be created!", _fx_));
                        goto MyError;
                }

                D(1) dprintf("%s : m_pPreviewPin @ %p -> m_fFlipHorizontal = %d , m_fFlipVertical = %d\n", _fx_, m_pPreviewPin, m_pPreviewPin->m_fFlipHorizontal, m_pPreviewPin->m_fFlipVertical);
                D(1) dprintf("%s : m_pCapturePin @ %p -> m_fFlipHorizontal = %d , m_fFlipVertical = %d\n", _fx_, m_pCapturePin, m_pCapturePin->m_fFlipHorizontal, m_pCapturePin->m_fFlipVertical);
                D(2) DebugBreak();

#ifdef TEST_H245_VID_CAPS
                m_pCapturePin->TestH245VidC();
#endif
#ifdef TEST_ISTREAMCONFIG
                m_pCapturePin->TestIStreamConfig();
#endif

                // Initialize the driver format with the capture pin information
                if (FAILED(Hr = m_pCapDev->SendFormatToDriver(
                     HEADER(m_pCapturePin->m_mt.pbFormat)->biWidth,
                     HEADER(m_pCapturePin->m_mt.pbFormat)->biHeight,
                     HEADER(m_pCapturePin->m_mt.pbFormat)->biCompression,
                     HEADER(m_pCapturePin->m_mt.pbFormat)->biBitCount,
                     ((VIDEOINFOHEADER *)m_pCapturePin->m_mt.pbFormat)->AvgTimePerFrame,
                     FALSE
                     )))
                           {
                                   DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: SendFormatToDriver failed! (1)", _fx_));
                                   goto MyExit;
                           }

                // Update the capture mode field for this device
                if (!m_pCapDev->m_dwStreamingMode || (m_pCapDev->m_dwStreamingMode == FRAME_GRAB_LARGE_SIZE && m_user.pvi->bmiHeader.biHeight < 240 && m_user.pvi->bmiHeader.biWidth < 320))
                        g_aDeviceInfo[m_dwDeviceIndex].nCaptureMode = CaptureMode_Streaming;
                else
                        g_aDeviceInfo[m_dwDeviceIndex].nCaptureMode = CaptureMode_FrameGrabbing;

                // If the frame rate is lower than expected, remember this
                ((VIDEOINFOHEADER *)m_pCapturePin->m_mt.pbFormat)->AvgTimePerFrame = max(((VIDEOINFOHEADER *)m_pCapturePin->m_mt.pbFormat)->AvgTimePerFrame, (long)m_user.pvi->AvgTimePerFrame);
                m_pCapturePin->m_lAvgTimePerFrameRangeMin = max(m_pCapturePin->m_lAvgTimePerFrameRangeMin, (long)m_user.pvi->AvgTimePerFrame);
                m_pCapturePin->m_lMaxAvgTimePerFrame = max(m_pCapturePin->m_lMaxAvgTimePerFrame, (long)m_user.pvi->AvgTimePerFrame);
                m_pCapturePin->m_lAvgTimePerFrameRangeDefault = max(m_pCapturePin->m_lAvgTimePerFrameRangeDefault, (long)m_user.pvi->AvgTimePerFrame);
                m_pCapturePin->m_lCurrentAvgTimePerFrame = max(m_pCapturePin->m_lCurrentAvgTimePerFrame, (long)m_user.pvi->AvgTimePerFrame);

                if (m_user.pvi!=NULL && HEADER(m_user.pvi)->biCompression == VIDEO_FORMAT_YUY2) {
                        HKEY    hRTCDeviceKey  = NULL;
                        DWORD   dwSize, dwType, dwDisableYUY2VFlip=0;

                        dprintf("dwDisableYUY2VFlip check...\n");
                        // Check if the RTC key is there
                        if (RegOpenKey(RTCKEYROOT, szRegRTCKey, &hRTCDeviceKey) == ERROR_SUCCESS)
                        {
                                dwSize = sizeof(DWORD);
                                RegQueryValueEx(hRTCDeviceKey, (LPTSTR)szDisableYUY2VFlipKey, NULL, &dwType, (LPBYTE)&dwDisableYUY2VFlip, &dwSize);
                                //if above fails, just do nothing, we'll use the initialized value for dwDisableYUY2VFlip, that is 0
                                RegCloseKey(hRTCDeviceKey);
                        }
                        if(!dwDisableYUY2VFlip) {
                                dprintf("------------------------- Enable Vertical FLIP ...\a\n");
                                m_pCapturePin->m_fFlipVertical = TRUE;
                        }
                }


                if ((VIDEOINFOHEADER *)m_pPreviewPin->m_mt.pbFormat)
                        {
                                    ((VIDEOINFOHEADER *)m_pPreviewPin->m_mt.pbFormat)->AvgTimePerFrame = max(((VIDEOINFOHEADER *)m_pPreviewPin->m_mt.pbFormat)->AvgTimePerFrame, (long)m_user.pvi->AvgTimePerFrame);
                        }
                m_pPreviewPin->m_lAvgTimePerFrameRangeMin = max(m_pPreviewPin->m_lAvgTimePerFrameRangeMin, (long)m_user.pvi->AvgTimePerFrame);
                m_pPreviewPin->m_lMaxAvgTimePerFrame = max(m_pPreviewPin->m_lMaxAvgTimePerFrame, (long)m_user.pvi->AvgTimePerFrame);
                m_pPreviewPin->m_lAvgTimePerFrameRangeDefault = max(m_pPreviewPin->m_lAvgTimePerFrameRangeDefault, (long)m_user.pvi->AvgTimePerFrame);
                m_pPreviewPin->m_lCurrentAvgTimePerFrame = max(m_pPreviewPin->m_lCurrentAvgTimePerFrame, (long)m_user.pvi->AvgTimePerFrame);

                // Set the size of the VIDEOINFOHEADER to the size of valid data for this format.
                m_user.cbFormat = GetBitmapFormatSize(&m_user.pvi->bmiHeader);

                // Set number of buffers
                // @todo This should be adjusted on the available memory and the
                // type of capture (streaming 4 buffs vs. frame grabbing 1 buff)
                m_user.nMinBuffers = MIN_VIDEO_BUFFERS;
                if (g_aDeviceInfo[m_dwDeviceIndex].nDeviceType == DeviceType_DShow) {
                    // this device type doesn't need more than 2 (save memory)
                    m_user.nMaxBuffers = 2;
                } else {
                    m_user.nMaxBuffers = MAX_VIDEO_BUFFERS;
                }
                m_user.dwTickScale = 10000UL;
                m_user.dwTickRate = (DWORD)m_pCapturePin->m_lAvgTimePerFrameRangeDefault;

                IncrementPinVersion();

                DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: Creating pins", _fx_));

                //** cache in the CCapDev instance the chosen VIDEOCAPTUREDEVICEINFO from the global array
                if (FAILED(Hr = GetVideoCapDeviceInfo(m_dwDeviceIndex, &(m_pCapDev->m_vcdi))))
                {
                        DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: Cannot cache the global VIDEOCAPTUREDEVICEINFO !", _fx_));
                        goto MyExit;
                }
                m_pCapDev->m_bCached_vcdi = TRUE;
        }
        else if (pGraph != NULL)
        {
                dprintf("JoinFilterGraph : ........... pGraph != NULL\n");
                // Take resources only when in the filter graph
                if (!m_pCapDev || FAILED(Hr = m_pCapDev->ConnectToDriver()))
                {
                        DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: ConnectToDriver failed Hr=0x%08lX", _fx_, Hr));
                        goto MyExit;
                }

                // Initialize the driver format with the capture pin information
                if (FAILED(Hr = m_pCapDev->SendFormatToDriver(
            HEADER(m_pCapturePin->m_mt.pbFormat)->biWidth,
            HEADER(m_pCapturePin->m_mt.pbFormat)->biHeight,
            HEADER(m_pCapturePin->m_mt.pbFormat)->biCompression,
            HEADER(m_pCapturePin->m_mt.pbFormat)->biBitCount,
            ((VIDEOINFOHEADER *)m_pCapturePin->m_mt.pbFormat)->AvgTimePerFrame,
            FALSE
            )))
                {
                        DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: SendFormatToDriver failed! (2)", _fx_));
                        goto MyExit;
                }

#if DEBUG_MULTIPROCESS
        wsprintfA(Buf, "\nPID:%x, %p, PreviewPin:%p\n", _getpid(), this, m_pPreviewPin);
        OutputDebugStringA(Buf);
#endif // DEBUG_MULTIPROCESS

        // If the frame rate is lower than expected, remember this
                ((VIDEOINFOHEADER *)m_pCapturePin->m_mt.pbFormat)->AvgTimePerFrame = max(((VIDEOINFOHEADER *)m_pCapturePin->m_mt.pbFormat)->AvgTimePerFrame, (long)m_user.pvi->AvgTimePerFrame);
                m_pCapturePin->m_lAvgTimePerFrameRangeMin = max(m_pCapturePin->m_lAvgTimePerFrameRangeMin, (long)m_user.pvi->AvgTimePerFrame);
                m_pCapturePin->m_lMaxAvgTimePerFrame = max(m_pCapturePin->m_lMaxAvgTimePerFrame, (long)m_user.pvi->AvgTimePerFrame);
                m_pCapturePin->m_lAvgTimePerFrameRangeDefault = max(m_pCapturePin->m_lAvgTimePerFrameRangeDefault, (long)m_user.pvi->AvgTimePerFrame);
                m_pCapturePin->m_lCurrentAvgTimePerFrame = max(m_pCapturePin->m_lCurrentAvgTimePerFrame, (long)m_user.pvi->AvgTimePerFrame);
                ((VIDEOINFOHEADER *)m_pPreviewPin->m_mt.pbFormat)->AvgTimePerFrame = max(((VIDEOINFOHEADER *)m_pPreviewPin->m_mt.pbFormat)->AvgTimePerFrame, (long)m_user.pvi->AvgTimePerFrame);
                m_pPreviewPin->m_lAvgTimePerFrameRangeMin = max(m_pPreviewPin->m_lAvgTimePerFrameRangeMin, (long)m_user.pvi->AvgTimePerFrame);
                m_pPreviewPin->m_lMaxAvgTimePerFrame = max(m_pPreviewPin->m_lMaxAvgTimePerFrame, (long)m_user.pvi->AvgTimePerFrame);
                m_pPreviewPin->m_lAvgTimePerFrameRangeDefault = max(m_pPreviewPin->m_lAvgTimePerFrameRangeDefault, (long)m_user.pvi->AvgTimePerFrame);
                m_pPreviewPin->m_lCurrentAvgTimePerFrame = max(m_pPreviewPin->m_lCurrentAvgTimePerFrame, (long)m_user.pvi->AvgTimePerFrame);

                // Set the size of the VIDEOINFOHEADER to the size of valid data for this format.
                m_user.cbFormat = GetBitmapFormatSize(&m_user.pvi->bmiHeader);

                // Set number of buffers
                // @todo This should be adjusted on the available memory and the
                // type of capture (streaming 4 buffs vs. frame grabbing 1 buff)
                m_user.nMinBuffers = MIN_VIDEO_BUFFERS;
                if (g_aDeviceInfo[m_dwDeviceIndex].nDeviceType == DeviceType_DShow) {
                    // this device type doesn't need more than 2 (save memory)
                    m_user.nMaxBuffers = 2;
                } else {
                    m_user.nMaxBuffers = MAX_VIDEO_BUFFERS;
                }
                m_user.dwTickScale = 10000UL;
                m_user.dwTickRate = (DWORD)m_pCapturePin->m_lAvgTimePerFrameRangeDefault;

                DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: Reconnecting pins", _fx_));
        }
        else if (m_pCapturePin)
        {
                dprintf("JoinFilterGraph : ........... m_pCapturePin (!= NULL) .... unjoin...\n");
                // Give back resources when not in graph
                if (m_pCapDev)
                        m_pCapDev->DisconnectFromDriver();

                // Release format structure
                if (m_user.pvi)
                        delete m_user.pvi, m_user.pvi = NULL;

                DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: Disconnecting pins", _fx_));
        }

        if (FAILED(Hr = CBaseFilter::JoinFilterGraph(pGraph, pName)))
        {
                DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: Base class JoinFilterGraph failed Hr=0x%08lX", _fx_, Hr));
                goto MyExit;
        }

        if (m_pCapturePin)
                m_pCapturePin->SetFilterGraph(m_pSink);
        if (m_pRtpPdPin)
                m_pRtpPdPin->SetFilterGraph(m_pSink);
        if (m_pPreviewPin)
                m_pPreviewPin->SetFilterGraph(m_pSink);

        goto MyExit;

MyError:
        // Release the pins
        if (m_pCapturePin)
                delete m_pCapturePin, m_pCapturePin = NULL;
        if (m_pPreviewPin)
                delete m_pPreviewPin, m_pPreviewPin = NULL;
#ifdef USE_OVERLAY
        if (m_pOverlayPin)
                delete m_pOverlayPin, m_pOverlayPin = NULL;
#endif
        if (m_pRtpPdPin)
                delete m_pRtpPdPin, m_pRtpPdPin = NULL;
MyExit:
        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: end", _fx_));

#if DEBUG_MULTIPROCESS
    wsprintfA(Buf, "\nPID:%x, %p left, hr=%x\n", _getpid(), this, Hr);
    OutputDebugStringA(Buf);
#endif  // DEBUG_MULTIPROCESS

    LeaveCriticalSection (&g_CritSec);

        return Hr;
}

/****************************************************************************
 *  @doc INTERNAL CTAPIVCAPMETHOD
 *
 *  @mfunc HRESULT | CTAPIVCap | GetState | This method is used to
 *    retrieve the current state of the filter. We don't send any data during
 *    PAUSE, so to avoid hanging renderers, we need to return VFW_S_CANT_CUE
 *    when paused.
 *
 *  @parm DWORD | dwMilliSecsTimeout | Specifies the duration of the time-out,
 *    in milliseconds.
 *
 *  @parm FILTER_STATE* | State | Specifies the name of the filter being added.
 *
 *  @rdesc This method returns an HRESULT value that depends on the
 *    implementation of the interface. HRESULT can include one of the
 *    following standard constants, or other values not listed:
 *
 *  @flag E_FAIL | Failure
 *  @flag E_POINTER | Null pointer argument
 *  @flag NOERROR | No error
 ***************************************************************************/
STDMETHODIMP CTAPIVCap::GetState(IN DWORD dwMilliSecsTimeout, OUT FILTER_STATE *State)
{
        HRESULT Hr = NOERROR;

        FX_ENTRY("CTAPIVCap::GetState")

        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: begin", _fx_));

        // Validate input parameters
        ASSERT(State);
        if (!State)
        {
                DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: invalid input parameter", _fx_));
                Hr = E_POINTER;
                goto MyExit;
        }

        *State = m_State;

        if (m_State == State_Paused)
                Hr = VFW_S_CANT_CUE;

MyExit:
        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: end", _fx_));
        return Hr;
}

/****************************************************************************
 *  @doc INTERNAL CTAPIVCAPMETHOD
 *
 *  @mfunc HRESULT | CTAPIVCap | CreatePins | This method is used to
 *    retrieve the current state of the filter. We don't send any data during
 *    PAUSE, so to avoid hanging renderers, we need to return VFW_S_CANT_CUE
 *    when paused.
 *
 *  @parm DWORD | dwMilliSecsTimeout | Specifies the duration of the time-out,
 *    in milliseconds.
 *
 *  @parm FILTER_STATE* | State | Specifies the name of the filter being added.
 *
 *  @rdesc This method returns an HRESULT value that depends on the
 *    implementation of the interface. HRESULT can include one of the
 *    following standard constants, or other values not listed:
 *
 *  @flag E_FAIL | Failure
 *  @flag E_POINTER | Null pointer argument
 *  @flag NOERROR | No error
 ***************************************************************************/
HRESULT CTAPIVCap::CreatePins()
{
        HRESULT Hr = NOERROR;

        FX_ENTRY("CTAPIVCap::CreatePins")

        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: begin", _fx_));

        CAutoLock cObjectLock(m_pLock);

        // Validate input parameters
        ASSERT(!m_pCapturePin);
        ASSERT(!m_pRtpPdPin);
        ASSERT(!m_pPreviewPin);
#ifdef USE_OVERLAY
        ASSERT(!m_pOverlayPin);
        if (m_pCapturePin || m_pRtpPdPin || m_pPreviewPin || m_pOverlayPin)
#else
        if (m_pCapturePin || m_pRtpPdPin || m_pPreviewPin)
#endif
{
                DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: Pins already exist!", _fx_));
                Hr = HRESULT_FROM_WIN32(ERROR_ALREADY_INITIALIZED);
                goto MyExit;
        }

        // Create our output pins for the video data stream, RTP packetization descriptor data stream, and maybe overlay
        if (FAILED(Hr = CCapturePin::CreateCapturePin(this, &m_pCapturePin)))
        {
                DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: Capture pin couldn't be created!", _fx_));
                goto MyError;
        }

#ifdef TEST_H245_VID_CAPS
        m_pCapturePin->TestH245VidC();
#endif
#ifdef TEST_ISTREAMCONFIG
                m_pCapturePin->TestIStreamConfig();
#endif

        // If we can do h/w preview with overlay, great, otherwise we'll do a non-overlay preview
#ifdef USE_OVERLAY
        if (m_fAvoidOverlay || !m_cs.bHasOverlay || FAILED(Hr = COverlayPin::CreateOverlayPin(this, &m_pOverlayPin)))
        {
                // We'll use regular preview if we don't get overlay
                if (FAILED(Hr = CPreviewPin::CreatePreviewPin(this, &m_pPreviewPin)))
                {
                        DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: Preview pin couldn't be created!", _fx_));
                        goto MyError;
                }
        }
#else
        if (FAILED(Hr = CPreviewPin::CreatePreviewPin(this, &m_pPreviewPin)))
        {
                DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: Preview pin couldn't be created!", _fx_));
                goto MyError;
        }
#endif

        if (FAILED(Hr = CRtpPdPin::CreateRtpPdPin(this, &m_pRtpPdPin)))
        {
                DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: Rtp Pd pin couldn't be created!", _fx_));
                goto MyError;
        }

        goto MyExit;

MyError:
        // Release the pins
        if (m_pCapturePin)
                delete m_pCapturePin, m_pCapturePin = NULL;
        if (m_pPreviewPin)
                delete m_pPreviewPin, m_pPreviewPin = NULL;
#ifdef USE_OVERLAY
        if (m_pOverlayPin)
                delete m_pOverlayPin, m_pOverlayPin = NULL;
#endif
        if (m_pRtpPdPin)
                delete m_pRtpPdPin, m_pRtpPdPin = NULL;
MyExit:
        DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: end", _fx_));
        return Hr;
}
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\net\tapi\skywalker\filters\video\tapivcap\thunk.h ===
/****************************************************************************
 *
 *   thunk.h
 * 
 *   macros, defines, prototypes for avicap 16:32 thunks
 *
 *   Copyright (c) 1994 Microsoft Corporation.  All Rights Reserved.
 *
 ***************************************************************************/

#ifndef _THUNK_H_
#define _THUNK_H_

typedef LPVOID P16VOID;
typedef DWORD  P32VOID;
//#define P16VOID LPVOID
//#define P32VOID DWORD

//#include "common.h"

// thunk helpers exported from the kernel
//
DWORD WINAPI GetCurrentProcessID(void);  // KERNEL
DWORD WINAPI SetWin32Event(DWORD hEvent); // KERNEL

P16VOID  WINAPI MapLS(P32VOID);
P16VOID  WINAPI UnMapLS(P16VOID);
P32VOID  WINAPI MapSL(P16VOID);

// thunk helpers in thunka.asm
//
DWORD FAR PASCAL capTileBuffer (
    DWORD dwLinear,
    DWORD dwSize);

#define PTR_FROM_TILE(dwTile) (LPVOID)(dwTile & 0xFFFF0000)

void  FAR PASCAL capUnTileBuffer (
    DWORD dwTileInfo);

BOOL  FAR PASCAL capPageFree (
    DWORD dwMemHandle);

typedef struct _cpa_data {
    DWORD dwMemHandle;
    DWORD dwPhysAddr;
    } CPA_DATA, FAR * LPCPA_DATA;

DWORD FAR PASCAL capPageAllocate (  // returns ptr to allocated memory
    DWORD   dwFlags,
    DWORD   dwPageCount,
    DWORD   dwMaxPhysPageMask,
    LPCPA_DATA pcpad);   // returned mem handle & phys address

// flags for capPageAllocate, same as flags from vmm.inc
//
#define PageUseAlign    0x00000002
#define PageContig      0x00000004
#define PageFixed       0x00000008

#ifdef WIN32
#ifdef __cplusplus
extern "C" {            /* Assume C declarations for C++ */
#endif	/* __cplusplus */
void NTAPI ThunkTerm(void);
BOOL NTAPI ThunkInit(void);
#ifdef __cplusplus
}
#endif	/* __cplusplus */
#endif

#endif // _THUNK_H_
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\net\tapi\skywalker\filters\video\tapivcap\thunk.c ===
/****************************************************************************
 *  @doc INTERNAL THUNK
 *
 *  @module Thunk.c | Source file for thunking to 16-bit code without using
 *    the thunk compiler.
 ***************************************************************************/

#pragma warning(disable:4054)           /* cannot cast to function ptr */
#pragma warning(disable:4055)           /* cannot cast from function ptr */

#pragma warning(disable:4115)           /* rpcndr.h: parenthesized type */
#pragma warning(disable:4201)           /* winnt.h: nameless union */
#pragma warning(disable:4214)           /* winnt.h: unsigned bitfields */
#pragma warning(disable:4514)           /* winnt.h: fiber goo */

#ifndef STRICT
#define STRICT
#endif

#include <windows.h>
#include <pshpack1.h>                   /* Byte packing, please */

#define BEGIN_CONST_DATA data_seg(".text", "CODE")
#define END_CONST_DATA data_seg(".data", "DATA")

#ifdef WIN32
#ifndef DWORD_PTR
#define DWORD_PTR unsigned long
#endif
#ifndef INT_PTR
#define INT_PTR int
#endif
#ifndef LONG_PTR
#define LONG_PTR long
#endif
#ifndef UINT_PTR
#define UINT_PTR unsigned int
#endif
#endif

/***************************************************************************
 *
 *  @doc    INTERNAL
 *
 *  @func   FARPROC | GetProcOrd |
 *
 *          GetProcAddress on a DLL by ordinal.
 *
 *          Win95 does not let you GetProcAddress on KERNEL32 by ordinal,
 *          so we need to do it the evil way.
 *
 *  @parm   HINSTANCE | hinstDll |
 *
 *          The instance handle of the DLL we want to get the ordinal
 *          from.  The only DLL you need to use this function for is
 *          KERNEL32.
 *
 *  @parm   UINT | ord |
 *
 *          The ordinal you want to retrieve.
 *
 ***************************************************************************/

#define pvAdd(pv, cb) ((LPVOID)((LPSTR)(pv) + (DWORD)(cb)))
#define pvSub(pv1, pv2) (DWORD)((LPSTR)(pv1) - (LPSTR)(pv2))

#define poteExp(pinth) (&(pinth)->OptionalHeader. \
                          DataDirectory[IMAGE_DIRECTORY_ENTRY_EXPORT])

FARPROC NTAPI
GetProcOrd(HINSTANCE hinstDll, UINT_PTR ord)
{
    FARPROC fp;

    /*
     *  Make sure the MZ header is good.
     */

    PIMAGE_DOS_HEADER pidh = (LPVOID)hinstDll;
    if (!IsBadReadPtr(pidh, sizeof(*pidh)) &&
        pidh->e_magic == IMAGE_DOS_SIGNATURE) {

        /*
         *  Make sure the PE header is good.
         */
        PIMAGE_NT_HEADERS pinth = pvAdd(pidh, pidh->e_lfanew);
        if (!IsBadReadPtr(pinth, sizeof(*pinth)) &&
            pinth->Signature == IMAGE_NT_SIGNATURE) {

            /*
             *  Make sure the export table is good and the ordinal
             *  is within range.
             */
            PIMAGE_EXPORT_DIRECTORY pedt =
                                pvAdd(pidh, poteExp(pinth)->VirtualAddress);
            if (!IsBadReadPtr(pedt, sizeof(*pedt)) &&
                (ord - pedt->Base) < pedt->NumberOfFunctions) {

                PDWORD peat = pvAdd(pidh, pedt->AddressOfFunctions);
                fp = (FARPROC)pvAdd(pidh, peat[ord - pedt->Base]);
                if (pvSub(fp, peat) >= poteExp(pinth)->Size) {
                    /* fp is valid */
                } else {                /* Note: We don't support forwarding */
                    fp = 0;
                }
            } else {
                fp = 0;
            }
        } else {
            fp = 0;
        }
    } else {
        fp = 0;
    }

    return fp;
}

/***************************************************************************
 *
 *  This structure starts out life as the things that we will GetProcAddress
 *  for.  And then it turns into pointers to functions.
 *
 ***************************************************************************/

#pragma BEGIN_CONST_DATA

static TCHAR c_tszKernel32[] = TEXT("KERNEL32");

static LPCSTR c_rgpszKernel32[] = {
    (LPVOID) 35,            /* LoadLibrary16 */
    (LPVOID) 36,            /* FreeLibrary16 */
    (LPVOID) 37,            /* GetProcAddress16 */

    "QT_Thunk",
    "MapLS",
    "UnMapLS",
    "MapSL",
    "MapSLFix",
};

#pragma END_CONST_DATA

typedef struct MANUALIMPORTTABLE {  /* mit */

    /* By ordinal */
    HINSTANCE   (NTAPI *LoadLibrary16)(LPCSTR);
    BOOL        (NTAPI *FreeLibrary16)(HINSTANCE);
    FARPROC     (NTAPI *GetProcAddress16)(HINSTANCE, LPCSTR);

    /* By name */
    void        (__cdecl *QT_Thunk)(void);
    LPVOID      (NTAPI   *MapLS)(LPVOID);
    void        (NTAPI   *UnMapLS)(LPVOID);
    LPVOID      (NTAPI   *MapSL)(LPVOID);
    LPVOID      (NTAPI   *MapSLFix)(LPVOID);

} MIT;

static MIT s_mit;

/***************************************************************************
 *
 *  @doc    INTERNAL
 *
 *  @func   DWORD | TemplateThunk |
 *
 *          Call down, passing all sorts of random parameters.
 *
 *          Parameter signature is as follows:
 *
 *          p = 0:32 pointer to convert to 16:16 pointer
 *          l = a 32-bit integer
 *          s = a 16-bit integer
 *
 *          P = returns a pointer
 *          L = returns a 32-bit integer
 *          S = returns a 16-bit signed integer
 *          U = returns a 16-bit unsigned integer
 *
 *  @parm   FARPROC | fp |
 *
 *          16:16 function to call.
 *
 *  @parm   PCSTR | pszSig |
 *
 *          Function signature.
 *
 ***************************************************************************/

#pragma warning(disable:4035)           /* no return value (duh) */

#ifndef NON_X86
__declspec(naked) DWORD
TemplateThunk(FARPROC fp, PCSTR pszSig, ...)
{
    __asm {

        /* Function prologue */
        push    ebp;
        mov     ebp, esp;
        sub     esp, 60;                /* QT_Thunk needs 60 bytes */
        push    ebx;
        push    edi;
        push    esi;

        /* Thunk all the parameters according to the signature */

        lea     esi, pszSig+4;          /* esi -> next arg */
        mov     ebx, pszSig;            /* ebx -> signature string */
thunkLoop:;
        mov     al, [ebx];
        inc     ebx;                    /* al = pszSig++ */
        cmp     al, 'p';                /* Q: Pointer? */
        jz      thunkPtr;               /* Y: Do the pointer */
        cmp     al, 'l';                /* Q: Long? */
        jz      thunkLong;              /* Y: Do the long */
        cmp     al, 's';                /* Q: Short? */
        jnz     thunkDone;              /* N: Done */

                                        /* Y: Do the short */
        lodsd;                          /* eax = *ppvArg++ */
        push    ax;                     /* Push the short */
        jmp     thunkLoop;

thunkPtr:
        lodsd;                          /* eax = *ppvArg++ */
        push    eax;
        call    s_mit.MapLS;            /* Map it */
        mov     [esi][-4], eax;         /* Save it for unmapping */
        push    eax;
        jmp     thunkLoop;

thunkLong:
        lodsd;                          /* eax = *ppvArg++ */
        push    eax;
        jmp     thunkLoop;
thunkDone:

        /* Call the 16:16 procedure */

        mov     edx, fp;
        call    s_mit.QT_Thunk;
        shl     eax, 16;                /* Convert DX:AX to EDX */
        shld    edx, eax, 16;

        /* Translate the return code according to the signature */

        mov     al, [ebx][-1];          /* Get return code type */
        cmp     al, 'P';                /* Pointer? */
        jz      retvalPtr;              /* Y: Do the pointer */
        cmp     al, 'S';                /* Signed? */
        jz      retvalSigned;           /* Y: Do the signed short */
        cmp     al, 'U';                /* Unsigned? */
        mov     edi, edx;               /* Assume long or void */
        jnz     retvalOk;               /* N: Then long or void */

        movzx   edi, dx;                /* Sign-extend short */
        jmp     retvalOk;

retvalPtr:
        push    edx;                    /* Pointer */
        call    s_mit.MapSL;            /* Map it up */
        jmp     retvalOk;

retvalSigned:                           /* Signed */
        movsx   edi, dx;                /* Sign-extend short */
        jmp     retvalOk;

retvalOk:                               /* Return value in EDI */

        /* Now unthunk the parameters */

        lea     esi, pszSig+4;          /* esi -> next arg */
        mov     ebx, pszSig;            /* ebx -> signature string */
unthunkLoop:;
        mov     al, [ebx];
        inc     ebx;                    /* al = pszSig++ */
        cmp     al, 'p';                /* Pointer? */
        jz      unthunkPtr;             /* Y: Do the pointer */
        cmp     al, 'l';                /* Long? */
        jz      unthunkSkip;            /* Y: Skip it */
        cmp     al, 's';                /* Short? */
        jnz     unthunkDone;            /* N: Done */
unthunkSkip:
        lodsd;                          /* eax = *ppvArg++ */
        jmp     unthunkLoop;

unthunkPtr:
        lodsd;                          /* eax = *ppvArg++ */
        push    eax;
        call    s_mit.UnMapLS;          /* Unmap it */
        jmp     unthunkLoop;

unthunkDone:

        /* Done */

        mov     eax, edi;
        pop     esi;
        pop     edi;
        pop     ebx;
        mov     esp, ebp;
        pop     ebp;
        ret;
    }
}
#else
TemplateThunk(FARPROC fp, PCSTR pszSig, ...)
{
        return  0;
}
#endif

#pragma warning(default:4035)

/***************************************************************************
 *
 *  @doc    INTERNAL
 *
 *  @func   void | ThunkInit |
 *
 *          Initialize the various goo we need in KERNEL32.
 *
 *          Returns FALSE if we cannot initialize the thunks.
 *          (For example, if the platform doesn't support flat thunks.)
 *
 *          Note that you must never ever call this function more
 *          than once.
 *
 ***************************************************************************/

#ifndef ARRAYSIZE
#define ARRAYSIZE(a)        (sizeof(a) / sizeof(a[0]))
#endif

#pragma BEGIN_CONST_DATA

static char c_szVidx16[] = "VIDX16.DLL";

static LPCSTR c_rgpszVidx16[] = {
    (LPCSTR)6,      /* vidxAllocHeaders             */
    (LPCSTR)7,      /* vidxFreeHeaders              */
    (LPCSTR)8,      /* vidxAllocBuffer              */
    (LPCSTR)9,      /* vidxAllocPreviewBuffer       */
    (LPCSTR)10,     /* vidxFreeBuffer               */
    (LPCSTR)11,     /* vidxSetRect                  */
    (LPCSTR)12,     /* vidxFrame                    */
    (LPCSTR)13,     /* vidxAddBuffer                */
    (LPCSTR)14,     /* vidxGetErrorText             */
    (LPCSTR)15,     /* vidxUpdate                   */
    (LPCSTR)16,     /* vidxDialog                   */
    (LPCSTR)17,     /* vidxStreamInit               */
    (LPCSTR)18,     /* vidxStreamFini               */
    (LPCSTR)19,     /* vidxConfigure                */
    (LPCSTR)20,     /* vidxOpen                     */
    (LPCSTR)21,     /* vidxClose                    */
    (LPCSTR)22,     /* vidxGetChannelCaps           */
    (LPCSTR)23,     /* vidxStreamReset              */
    (LPCSTR)24,     /* vidxStreamStart              */
    (LPCSTR)25,     /* vidxStreamStop               */
    (LPCSTR)26,     /* vidxStreamUnprepareHeader    */
    (LPCSTR)27,     /* vidxCapDriverDescAndVer      */
    (LPCSTR)28,     /* vidxMessage                  */
    (LPCSTR)29,     /* vidxFreePreviewBuffer        */
};

#pragma END_CONST_DATA

static HINSTANCE s_hinstVidx16;

static FARPROC s_rgfpVidx16[ARRAYSIZE(c_rgpszVidx16)];

#define s_fpvidxAllocHeaders            s_rgfpVidx16[0]
#define s_fpvidxFreeHeaders             s_rgfpVidx16[1]
#define s_fpvidxAllocBuffer             s_rgfpVidx16[2]
#define s_fpvidxAllocPreviewBuffer      s_rgfpVidx16[3]
#define s_fpvidxFreeBuffer              s_rgfpVidx16[4]
#define s_fpvidxFrame                   s_rgfpVidx16[6]
#define s_fpvidxAddBuffer               s_rgfpVidx16[7]

/*****************************************************************************
 * @doc EXTERNAL  VIDEO
 *
 * @func DWORD | videoDialog | This function displays a channel-specific
 *     dialog box used to set configuration parameters.
 *
 * @parm HVIDEO | hVideo | Specifies a handle to the video device channel.
 *
 * @parm HWND | hWndParent | Specifies the parent window handle.
 *
 * @parm DWORD | dwFlags | Specifies flags for the dialog box. The
 *   following flag is defined:
 *   @flag VIDEO_DLG_QUERY | If this flag is set, the driver immediately
 *           returns zero if it supplies a dialog box for the channel,
 *           or DV_ERR_NOTSUPPORTED if it does not.
 *
 * @rdesc Returns zero if the function was successful. Otherwise, it returns
 *   an error number. The following errors are defined:
 *   @flag DV_ERR_INVALHANDLE | Specified device handle is invalid.
 *   @flag DV_ERR_NOTSUPPORTED | Function is not supported.
 *
 * @comm Typically, each dialog box displayed by this
 *      function lets the user select options appropriate for the channel.
 *      For example, a VIDEO_IN channel dialog box lets the user select
 *      the image dimensions and bit depth.
 *
 * @xref <f videoOpen> <f videoConfigureStorage>
 ****************************************************************************/
#define s_fpvideoDialog                 s_rgfpVidx16[10]

/*****************************************************************************
 * @doc EXTERNAL  VIDEO
 *
 * @func DWORD | videoStreamInit | This function initializes a video
 *     device channel for streaming.
 *
 * @parm HVIDEO | hVideo | Specifies a handle to the video device channel.
 *
 * @parm DWORD | dwMicroSecPerFrame | Specifies the number of microseconds
 *     between frames.
 *
 * @parm DWORD_PTR | dwCallback | Specifies the address of a callback
 *   function or a handle to a window called during video
 *   streaming. The callback function or window processes
 *  messages related to the progress of streaming.
 *
 * @parm DWORD_PTR | dwCallbackInstance | Specifies user
 *  instance data passed to the callback function. This parameter is not
 *  used with window callbacks.
 *
 * @parm DWORD | dwFlags | Specifies flags for opening the device channel.
 *   The following flags are defined:
 *   @flag CALLBACK_WINDOW | If this flag is specified, <p dwCallback> is
 *      a window handle.
 *   @flag CALLBACK_FUNCTION | If this flag is specified, <p dwCallback> is
 *      a callback procedure address.
 *
 * @rdesc Returns zero if the function was successful. Otherwise, it returns
 *   an error number. The following errors are defined:
 *   @flag DV_ERR_BADDEVICEID | Indicates the device ID specified in
 *         <p hVideo> is not valid.
 *   @flag DV_ERR_ALLOCATED | Indicates the resource specified is already allocated.
 *   @flag DV_ERR_NOMEM | Indicates the device is unable to allocate or lock memory.
 *
 * @comm If a window or function is chosen to receive callback information, the following
 *   messages are sent to it to indicate the
 *   progress of video input:
 *
 *   <m MM_DRVM_OPEN> is sent at the time of <f videoStreamInit>
 *
 *   <m MM_DRVM_CLOSE> is sent at the time of <f videoStreamFini>
 *
 *   <m MM_DRVM_DATA> is sent when a buffer of image data is available
 *
 *   <m MM_DRVM_ERROR> is sent when an error occurs
 *
 *   Callback functions must reside in a DLL.
 *   You do not have to use <f MakeProcInstance> to get
 *   a procedure-instance address for the callback function.
 *
 * @cb void CALLBACK | videoFunc | <f videoFunc> is a placeholder for an
 *   application-supplied function name. The actual name must be exported by
 *   including it in an EXPORTS statement in the DLL's module-definition file.
 *   This is used only when a callback function is specified in
 *   <f videoStreamInit>.
 *
 * @parm HVIDEO | hVideo | Specifies a handle to the video device channel
 *   associated with the callback.
 *
 * @parm DWORD | wMsg | Specifies the <m MM_DRVM_> messages. Messages indicate
 *       errors and when image data is available. For information on
 *       these messages, see <f videoStreamInit>.
 *
 * @parm DWORD | dwInstance | Specifies the user instance
 *   data specified with <f videoStreamInit>.
 *
 * @parm DWORD | dwParam1 | Specifies a parameter for the message.
 *
 * @parm DWORD | dwParam2 | Specifies a parameter for the message.
 *
 * @comm Because the callback is accessed at interrupt time, it must reside
 *   in a DLL and its code segment must be specified as FIXED in the
 *   module-definition file for the DLL. Any data the callback accesses
 *   must be in a FIXED data segment as well. The callback may not make any
 *   system calls except for <f PostMessage>, <f timeGetSystemTime>,
 *   <f timeGetTime>, <f timeSetEvent>, <f timeKillEvent>,
 *   <f midiOutShortMsg>, <f midiOutLongMsg>, and <f OutputDebugStr>.
 *
 * @xref <f videoOpen> <f videoStreamFini> <f videoClose>
 ****************************************************************************/
#define s_fpvideoStreamInit             s_rgfpVidx16[11]

/*****************************************************************************
 * @doc EXTERNAL  VIDEO
 *
 * @func DWORD | videoStreamFini | This function terminates streaming
 *     from the specified device channel.
 *
 * @parm HVIDEO | hVideo | Specifies a handle to the video device channel.
 *
 * @rdesc Returns zero if the function was successful. Otherwise, it returns
 *   an error number. The following errors are defined:
 *   @flag DV_ERR_INVALHANDLE | Indicates the device handle specified is invalid.
 *   @flag DV_ERR_STILLPLAYING | Indicates there are still buffers in the queue.
 *
 * @comm If there are buffers that have been sent with
 *   <f videoStreamAddBuffer> that haven't been returned to the application,
 *   this operation will fail. Use <f videoStreamReset> to return all
 *   pending buffers.
 *
 *   Each call to <f videoStreamInit> must be matched with a call to
 *   <f videoStreamFini>.
 *
 *   For VIDEO_EXTERNALIN channels, this function is used to
 *   halt capturing of data to the frame buffer.
 *
 *   For VIDEO_EXTERNALOUT channels supporting overlay,
 *   this function is used to disable the overlay.
 *
 * @xref <f videoStreamInit>
 ****************************************************************************/
#define s_fpvideoStreamFini             s_rgfpVidx16[12]

/*****************************************************************************
 * @doc EXTERNAL  VIDEO
 *
 * @func DWORD | videoConfigure | This function sets or retrieves
 *      the options for a configurable driver.
 *
 * @parm HVIDEO | hVideo | Specifies a handle to the video device channel.
 *
 * @parm UINT | msg  | Specifies the option to set or retrieve. The
 *       following options are defined:
 *
 *   @flag DVM_PALETTE | Indicates a palette is being sent to the driver
 *         or retrieved from the driver.
 *
 *   @flag DVM_PALETTERGB555 | Indicates an RGB555 palette is being
 *         sent to the driver.
 *
 *   @flag DVM_FORMAT | Indicates format information is being sent to
 *         the driver or retrieved from the driver.
 *
 * @parm DWORD | dwFlags | Specifies flags for configuring or
 *   interrogating the device driver. The following flags are defined:
 *
 *   @flag VIDEO_CONFIGURE_SET | Indicates values are being sent to the driver.
 *
 *   @flag VIDEO_CONFIGURE_GET | Indicates values are being obtained from the driver.
 *
 *   @flag VIDEO_CONFIGURE_QUERY | Determines if the
 *      driver supports the option specified by <p msg>. This flag
 *      should be combined with either the VIDEO_CONFIGURE_SET or
 *      VIDEO_CONFIGURE_GET flag. If this flag is
 *      set, the <p lpData1>, <p dwSize1>, <p lpData2>, and <p dwSize2>
 *      parameters are ignored.
 *
 *   @flag VIDEO_CONFIGURE_QUERYSIZE | Returns the size, in bytes,
 *      of the configuration option in <p lpdwReturn>. This flag is only valid if
 *      the VIDEO_CONFIGURE_GET flag is also set.
 *
 *   @flag VIDEO_CONFIGURE_CURRENT | Requests the current value.
 *      This flag is valid only if  the VIDEO_CONFIGURE_GET flag is also set.
 *   @flag VIDEO_CONFIGURE_NOMINAL | Requests the nominal value.
 *      This flag is valid only if  the VIDEO_CONFIGURE_GET flag is also set.
 *   @flag VIDEO_CONFIGURE_MIN | Requests the minimum value.
 *      This flag is valid only if  the VIDEO_CONFIGURE_GET flag is also set.
 *   @flag VIDEO_CONFIGURE_MAX | Get the maximum value.
 *      This flag is valid only if  the VIDEO_CONFIGURE_GET flag is also set.
 *
 * @parm LPDWORD | lpdwReturn  | Points to a DWORD used for returning information
 *      from the driver.  If
 *      the VIDEO_CONFIGURE_QUERYSIZE flag is set, <p lpdwReturn> is
 *      filled with the size of the configuration option.
 *
 * @parm LPVOID | lpData1  |Specifies a pointer to message specific data.
 *
 * @parm DWORD | dwSize1  | Specifies the size, in bytes, of the <p lpData1>
 *       buffer.
 *
 * @parm LPVOID | lpData2  | Specifies a pointer to message specific data.
 *
 * @parm DWORD | dwSize2  | Specifies the size, in bytes, of the <p lpData2>
 *       buffer.
 *
 * @rdesc Returns zero if the function was successful. Otherwise, it returns
 *   an error number. The following errors are defined:
 *   @flag DV_ERR_INVALHANDLE | Specified device handle is invalid.
 *   @flag DV_ERR_NOTSUPPORTED | Function is not supported.
 *
 * @xref <f videoOpen> <f videoMessage>
 *
 ****************************************************************************/
#define s_fpvideoConfigure              s_rgfpVidx16[13]

/*****************************************************************************
 * @doc EXTERNAL  VIDEO
 *
 * @func DWORD | videoOpen | This function opens a channel on the
 *  specified video device.
 *
 * @parm LPHVIDEO | lphvideo | Specifies a far pointer to a buffer
 *   used to return an <t HVIDEO> handle. The video capture driver
 *   uses this location to return
 *   a handle that uniquely identifies the opened video device channel.
 *   Use the returned handle to identify the device channel when
 *   calling other video functions.
 *
 * @parm DWORD | dwDeviceID | Identifies the video device to open.
 *      The value of <p dwDeviceID> varies from zero to one less
 *      than the number of video capture devices installed in the system.
 *
 * @parm DWORD | dwFlags | Specifies flags for opening the device.
 *      The following flags are defined:
 *
 *   @flag VIDEO_EXTERNALIN| Specifies the channel is opened
 *           for external input. Typically, external input channels
 *      capture images into a frame buffer.
 *
 *   @flag VIDEO_EXTERNALOUT| Specifies the channel is opened
 *      for external output. Typically, external output channels
 *      display images stored in a frame buffer on an auxilary monitor
 *      or overlay.
 *
 *   @flag VIDEO_IN| Specifies the channel is opened
 *      for video input. Video input channels transfer images
 *      from a frame buffer to system memory buffers.
 *
 *   @flag VIDEO_OUT| Specifies the channel is opened
 *      for video output. Video output channels transfer images
 *      from system memory buffers to a frame buffer.
 *
 * @rdesc Returns zero if the function was successful. Otherwise, it returns
 *   an error number. The following errors are defined:
 *   @flag DV_ERR_BADDEVICEID | Indicates the specified device ID is out of range.
 *   @flag DV_ERR_ALLOCATED | Indicates the specified resource is already allocated.
 *   @flag DV_ERR_NOMEM | Indicates the device is unable to allocate or lock memory.
 *
 * @comm
 *   At a minimum, all capture drivers support a VIDEO_EXTERNALIN
 *   and a VIDEO_IN channel.
 *   Use <f videoGetNumDevs> to determine the number of video
 *   devices present in the system.
 *
 * @xref <f videoClose>
 ****************************************************************************/
#define s_fpvideoOpen                   s_rgfpVidx16[14]

/*****************************************************************************
 * @doc EXTERNAL  VIDEO
 *
 * @func DWORD | videoClose | This function closes the specified video
 *   device channel.
 *
 * @parm HVIDEO | hVideo | Specifies a handle to the video device channel.
 *  If this function is successful, the handle is invalid
 *   after this call.
 *
 * @rdesc Returns zero if the function was successful. Otherwise, it returns
 *   an error number. The following errors are defined:
 *   @flag DV_ERR_INVALHANDLE | Specified device handle is invalid.
 *   @flag DV_ERR_NONSPECIFIC | The driver failed to close the channel.
 *
 * @comm If buffers have been sent with <f videoStreamAddBuffer> and
 *   they haven't been returned to the application,
 *   the close operation fails. You can use <f videoStreamReset> to mark all
 *   pending buffers as done.
 *
 * @xref <f videoOpen> <f videoStreamInit> <f videoStreamFini> <f videoStreamReset>
 ****************************************************************************/
#define s_fpvideoClose                  s_rgfpVidx16[15]

/*****************************************************************************
 * @doc EXTERNAL VIDEO
 *
 * @func DWORD | videoGetChannelCaps | This function retrieves a
 *   description of the capabilities of a channel.
 *
 * @parm HVIDEO | hVideo | Specifies a handle to the video device channel.
 *
 * @parm LPCHANNEL_CAPS | lpChannelCaps | Specifies a far pointer to a
 *      <t CHANNEL_CAPS> structure.
 *
 * @parm DWORD | dwSize | Specifies the size, in bytes, of the
 *       <t CHANNEL_CAPS> structure.
 *
 * @rdesc Returns zero if the function is successful. Otherwise, it returns
 *   an error number. The following errors are defined:
 *   @flag DV_ERR_INVALHANDLE | Specified device handle is invalid.
 *   @flag DV_ERR_UNSUPPORTED | Function is not supported.
 *
 * @comm The <t CHANNEL_CAPS> structure returns the capability
 *   information. For example, capability information might
 *   include whether or not the channel can crop and scale images,
 *   or show overlay.
 ****************************************************************************/
#define s_fpvideoGetChannelCaps         s_rgfpVidx16[16]

/*****************************************************************************
 * @doc EXTERNAL  VIDEO
 *
 * @func DWORD | videoStreamReset | This function stops streaming
 *           on the specified video device channel and resets the current position
 *      to zero.  All pending buffers are marked as done and
 *      are returned to the application.
 *
 * @parm HVIDEO | hVideo | Specifies a handle to the video device channel.
 *
 * @rdesc Returns zero if the function was successful. Otherwise, it returns
 *   an error number. The following errors are defined:
 *
 *   @flag DV_ERR_INVALHANDLE | Indicates the device handle specified is invalid.
 *
 *   @flag DV_ERR_NOTSUPPORTED | Indicates the device does not support this
 *         function.
 *
 * @xref <f videoStreamReset> <f videoStreamStop> <f videoStreamAddBuffer> <f videoStreamClose>
/****************************************************************************/
#define s_fpvideoStreamReset            s_rgfpVidx16[17]

/*****************************************************************************
 * @doc EXTERNAL  VIDEO
 *
 * @func DWORD | videoStreamStart | This function starts streaming on the
 *   specified video device channel.
 *
 * @parm HVIDEO | hVideo | Specifies a handle to the video device channel.
 *
 * @rdesc Returns zero if the function was successful. Otherwise, it returns
 *   an error number. The following errors are defined:
 *   @flag DV_ERR_INVALHANDLE | Indicates the device handle specified is invalid.
 *
 *   @flag DV_ERR_NOTSUPPORTED | Indicates the device does not support this
 *         function.
 *
 * @xref <f videoStreamReset> <f videoStreamStop> <f videoStreamAddBuffer> <f videoStreamClose>
/****************************************************************************/
#define s_fpvideoStreamStart            s_rgfpVidx16[18]

/*****************************************************************************
 * @doc EXTERNAL  VIDEO
 *
 * @func DWORD | videoStreamStop | This function stops streaming on a video channel.
 *
 * @parm HVIDEO | hVideo | Specifies a handle to the video
 *   device channel.
 *
 * @rdesc Returns zero if the function was successful. Otherwise, it returns
 *   an error number. The following error is defined:
 *   @flag DV_ERR_INVALHANDLE | Indicates the specified device handle is invalid.
 *
 *   @flag DV_ERR_NOTSUPPORTED | Indicates the device does not support this
 *         function.
 * @comm If there are any buffers in the queue, the current buffer will be
 *   marked as done (the <e VIDEOHDR.dwBytesRecorded> member in
 *   the <t VIDEOHDR> header will contain the actual length of data), but any
 *   empty buffers in the queue will remain there. Calling this
 *   function when the channel is not started has no effect, and the
 *   function returns zero.
 *
 * @xref <f videoStreamStart> <f videoStreamReset>
 ****************************************************************************/
#define s_fpvideoStreamStop             s_rgfpVidx16[19]

/*****************************************************************************
 * @doc EXTERNAL  VIDEO
 *
 * @func DWORD | videoCapDriverDescAndVer | This function gets strings
 *   for the description and version of a video capture driver
 *
 * @parm DWORD | dwDeviceID | Specifies the index of which video driver to get
 *      information about.
 *
 * @parm LPTSTR | lpszDesc | Specifies a place to return the description
 *
 * @parm UINT | cbDesc | Specifies the length of the description string
 *
 * @parm LPTSTR | lpszVer | Specifies a place to return the version
 *
 * @parm UINT | cbVer | Specifies the length of the version string
 *
 * @rdesc Returns zero if the function was successful. Otherwise, it returns
 *   an error number.
 *
 * @comm Use this function to get strings describing the driver and its version
 *
/****************************************************************************/
#define s_fpvideoCapDriverDescAndVer    s_rgfpVidx16[21]

/*****************************************************************************
 * @doc EXTERNAL  VIDEO
 *
 * @func DWORD | videoMessage | This function sends messages to a
 *   video device channel.
 *
 * @parm HVIDEO | hVideo | Specifies the handle to the video device channel.
 *
 * @parm UINT | wMsg | Specifies the message to send.
 *
 * @parm DWORD | dwP1 | Specifies the first parameter for the message.
 *
 * @parm DWORD | dwP2 | Specifies the second parameter for the message.
 *
 * @rdesc Returns the message specific value returned from the driver.
 *
 * @comm This function is used for configuration messages such as
 *      <m DVM_SRC_RECT> and <m DVM_DST_RECT>, and
 *      device specific messages.
 *
 * @xref <f videoConfigure>
 *
 ****************************************************************************/
#define s_fpvideoMessage                s_rgfpVidx16[22]
#define s_fpvidxFreePreviewBuffer       s_rgfpVidx16[23]

/***************************************************************************
 *
 *  @doc    INTERNAL
 *
 *  @func   void | ThunkTerm |
 *
 *          Free it.
 *
 ***************************************************************************/

void NTAPI
ThunkTerm(void)
{
    if (s_hinstVidx16) {
        s_mit.FreeLibrary16(s_hinstVidx16);
        s_hinstVidx16 = 0;
    }
}

/***************************************************************************
 *
 *  @doc    INTERNAL
 *
 *  @func   void | ThunkGetProcAddresses |
 *
 *          Get all the necessary proc addresses.
 *
 ***************************************************************************/

HINSTANCE NTAPI
ThunkGetProcAddresses(FARPROC rgfp[], LPCSTR rgpsz[], UINT cfp,
                      LPCSTR pszLibrary)
{
    HINSTANCE hinst;

    hinst = s_mit.LoadLibrary16(pszLibrary);
    if (hinst >= (HINSTANCE)32) {
        UINT ifp;
        for (ifp = 0; ifp < cfp; ifp++) {
            rgfp[ifp] = s_mit.GetProcAddress16(hinst, rgpsz[ifp]);
            if (!rgfp[ifp]) {
                s_mit.FreeLibrary16(hinst);
                hinst = 0;
                break;
            }
        }
    } else {
        hinst = 0;
    }

    return hinst;

}

/***************************************************************************
 *
 *  @doc    INTERNAL
 *
 *  @func   void | ThunkInit |
 *
 *          GetProcAddress16 our brains out.
 *
 ***************************************************************************/

BOOL NTAPI
ThunkInit(void)
{
    HINSTANCE hinstK32 = GetModuleHandle(c_tszKernel32);
    BOOL fRc;

    if (hinstK32) {
        int i;
        FARPROC *rgfpMit = (LPVOID)&s_mit;

        for (i = 0; i < ARRAYSIZE(c_rgpszKernel32); i++) {
            if ((LONG_PTR)(c_rgpszKernel32[i]) & ~(LONG_PTR)65535) {
                rgfpMit[i] = GetProcAddress(hinstK32, c_rgpszKernel32[i]);
            } else {
                rgfpMit[i] = GetProcOrd(hinstK32, (UINT_PTR)c_rgpszKernel32[i]);
            }
            if (!rgfpMit[i]) return FALSE;  /* Aigh! */
        }

        s_hinstVidx16 =
            ThunkGetProcAddresses(s_rgfpVidx16, c_rgpszVidx16,
                                  ARRAYSIZE(s_rgfpVidx16),
                                  c_szVidx16);

        if (!s_hinstVidx16) {
            goto failed;
        }

        fRc = 1;

    } else {
    failed:;
        ThunkTerm();

        fRc = 0;
    }

    return fRc;
}


/***************************************************************************
 *
 *  Now come the actual thunklets.
 *
 ***************************************************************************/

// typedef DWORD   HDR32;
// typedef DWORD   HVIDEO;
// typedef DWORD  *LPHVIDEO;
typedef struct channel_caps_tag CHANNEL_CAPS, *LPCHANNEL_CAPS;


#include "ivideo32.h"

typedef PTR32 FAR * PPTR32;

extern int g_IsNT;

#define tHVIDEO                 "l"
#define tUINT                   "s"
#define tHWND                   "s"
#define tHDC                    "s"
#define tint                    "s"
#define tDWORD                  "l"
#define tLPARAM                 "l"
#define tDWORD_PTR              "l"     // exactly like DWORD, or we'll blow up
#define tHDR32                  "l"
#define tPTR32                  "l"
#define tLPVIDEOHDR             "p"     // was l
#define tLPVOID                 "p"
#define tLPDWORD                "p"
#define tPPTR32                 "p"
#define tLPSTR                  "p"
#define tLPTSTR                 "p"
#define tLPHVIDEO               "p"
#define tLPCHANNEL_CAPS         "p"
#define rDWORD                  "L"
#define rLRESULT                "L"

#pragma BEGIN_CONST_DATA


#define MAKETHUNK1(rT, fn, t1, a1)                                          \
rT NTAPI                                                                    \
fn(t1 a1)                                                                   \
{                                                                           \
    if (g_IsNT)                                                             \
        return NT##fn(a1);                                                  \
    else                                                                    \
        return (rT)TemplateThunk(s_fp##fn,                                  \
                t##t1                                                       \
        r##rT,     a1);                                                     \
}                                                                           \

#define MAKETHUNK2(rT, fn, t1, a1, t2, a2)                                  \
rT NTAPI                                                                    \
fn(t1 a1, t2 a2)                                                            \
{                                                                           \
    if (g_IsNT)                                                             \
        return NT##fn(a1,a2);                                               \
    else                                                                    \
        return (rT)TemplateThunk(s_fp##fn,                                  \
                t##t1 t##t2                                                 \
        r##rT,   a1,     a2);                                               \
}                                                                           \

#define MAKETHUNK3(rT, fn, t1, a1, t2, a2, t3, a3)                          \
rT NTAPI                                                                    \
fn(t1 a1, t2 a2, t3 a3)                                                     \
{                                                                           \
    if (g_IsNT)                                                             \
        return NT##fn(a1,a2,a3);                                            \
    else                                                                    \
        return (rT)TemplateThunk(s_fp##fn,                                  \
                t##t1 t##t2 t##t3                                           \
        r##rT,   a1,     a2,   a3);                                         \
}                                                                           \

#define MAKETHUNK4(rT, fn, t1, a1, t2, a2, t3, a3, t4, a4)                  \
rT NTAPI                                                                    \
fn(t1 a1, t2 a2, t3 a3, t4 a4)                                              \
{                                                                           \
    if (g_IsNT)                                                             \
        return NT##fn(a1,a2,a3,a4);                                         \
    else                                                                    \
        return (rT)TemplateThunk(s_fp##fn,                                  \
                t##t1 t##t2 t##t3 t##t4                                     \
        r##rT,     a1,   a2,   a3,   a4);                                   \
}                                                                           \

#define MAKETHUNK5(rT, fn, t1, a1, t2, a2, t3, a3, t4, a4, t5, a5)          \
rT NTAPI                                                                    \
fn(t1 a1, t2 a2, t3 a3, t4 a4, t5 a5)                                       \
{                                                                           \
    if (g_IsNT)                                                             \
        return NT##fn(a1,a2,a3,a4,a5);                                      \
    else                                                                    \
        return (rT)TemplateThunk(s_fp##fn,                                  \
                t##t1 t##t2 t##t3 t##t4 t##t5                               \
        r##rT,     a1,   a2,   a3,   a4,   a5);                             \
}                                                                           \

#define MAKETHUNK6(rT, fn, t1, a1, t2, a2, t3, a3, t4, a4, t5, a5, t6, a6)  \
rT NTAPI                                                                    \
fn(t1 a1, t2 a2, t3 a3, t4 a4, t5 a5, t6 a6)                                \
{                                                                           \
    if (g_IsNT)                                                             \
        return NT##fn(a1,a2,a3,a4,a5,a6);                                   \
    else                                                                    \
        return (rT)TemplateThunk(s_fp##fn,                                  \
                t##t1 t##t2 t##t3 t##t4 t##t5 t##t6                         \
        r##rT,     a1,   a2,   a3,   a4,   a5,   a6);                       \
}                                                                           \

#define MAKETHUNK7(rT, fn, t1, a1, t2, a2, t3, a3, t4, a4, t5, a5, t6, a6,  \
                           t7, a7)                                          \
rT NTAPI                                                                    \
fn(t1 a1, t2 a2, t3 a3, t4 a4, t5 a5, t6 a6, t7 a7)                         \
{                                                                           \
    if (g_IsNT)                                                             \
        return NT##fn(a1,a2,a3,a4,a5,a6,a7);                                \
    else                                                                    \
        return (rT)TemplateThunk(s_fp##fn,                                  \
                t##t1 t##t2 t##t3 t##t4 t##t5 t##t6 t##t7                   \
        r##rT,     a1,   a2,   a3,   a4,   a5,   a6,   a7);                 \
}                                                                           \

#define MAKETHUNK8(rT, fn, t1, a1, t2, a2, t3, a3, t4, a4, t5, a5, t6, a6,  \
                           t7, a7, t8, a8)                                  \
rT NTAPI                                                                    \
fn(t1 a1, t2 a2, t3 a3, t4 a4, t5 a5, t6 a6, t7 a7, t8 a8)                  \
{                                                                           \
    if (g_IsNT)                                                             \
        return NT##fn(a1,a2,a3,a4,a5,a6,a7,a8);                             \
    else                                                                    \
        return (rT)TemplateThunk(s_fp##fn,                                  \
                t##t1 t##t2 t##t3 t##t4 t##t5 t##t6 t##t7 t##t8             \
        r##rT,     a1,   a2,   a3,   a4,   a5,   a6,   a7,   a8);           \
}                                                                           \

MAKETHUNK4(DWORD,   vidxAllocHeaders,
           HVIDEO,  hv,
           UINT,    nHeaders,
           UINT,    cbHeader,
           PPTR32,  lp32Hdrs)

MAKETHUNK1(DWORD,   vidxFreeHeaders,
           HVIDEO,  hv)

MAKETHUNK4(DWORD,   vidxAllocBuffer,
           HVIDEO,  hv,
           UINT,    iHdr,
           PPTR32,  pp32Hdr,
           DWORD,   dwSize)

MAKETHUNK4(DWORD,   vidxAllocPreviewBuffer,
           HVIDEO,  hv,
           PPTR32,  pp32Hdr,
           UINT,    cbHdr,
           DWORD,   cbData)

MAKETHUNK2(DWORD,   vidxFreePreviewBuffer,
           HVIDEO,  hv,
           PPTR32,  pp32Hdr)

MAKETHUNK2(DWORD,   vidxFreeBuffer,
           HVIDEO,  hv,
           DWORD,   p32Hdr)

MAKETHUNK3(DWORD,   videoDialog,
           HVIDEO,  hv,
           HWND,    hWndParent,
           DWORD,   dwFlags)

MAKETHUNK5(DWORD,   videoStreamInit,
           HVIDEO,  hvideo,
           DWORD,   dwMicroSecPerFrame,
           DWORD_PTR,   dwCallback,
           DWORD_PTR,   dwCallbackInst,
           DWORD,   dwFlags)

MAKETHUNK1(DWORD,   videoStreamFini,
           HVIDEO,  hvideo)

MAKETHUNK2(DWORD,   vidxFrame,
           HVIDEO,  hvideo,
           LPVIDEOHDR, p32hdr)

MAKETHUNK8(DWORD,   videoConfigure,
           HVIDEO,  hvideo,
           UINT,    msg,
           DWORD,   dwFlags,
           LPDWORD, lpdwReturn,
           LPVOID,  lpData1,
           DWORD,   dwSize1,
           LPVOID,  lpData2,
           DWORD,   dwSize2)

MAKETHUNK3(DWORD,   videoOpen,
           LPHVIDEO,phv,
           DWORD,   dwDevice,
           DWORD,   dwFlags)

MAKETHUNK1(DWORD,   videoClose,
           HVIDEO,  hv)

MAKETHUNK3(DWORD,   videoGetChannelCaps,
           HVIDEO,  hv,
           LPCHANNEL_CAPS, lpcc,
           DWORD,  dwSize)

MAKETHUNK3(DWORD,   vidxAddBuffer,
           HVIDEO,  hvideo,
           PTR32,   p32Hdr,
           DWORD,   dwSize)

MAKETHUNK1(DWORD,   videoStreamReset,
           HVIDEO,  hvideo)

MAKETHUNK1(DWORD,   videoStreamStart,
           HVIDEO,  hvideo)

MAKETHUNK1(DWORD,   videoStreamStop,
           HVIDEO,  hvideo)

MAKETHUNK7(DWORD,   videoCapDriverDescAndVer,
           DWORD,  dwDeviceID,
           LPTSTR, lpszDesc,
           UINT,   cbDesc,
           LPTSTR, lpszVer,
           UINT,   cbVer,
           LPTSTR, lpszDllName,
           UINT,   cbDllName)

MAKETHUNK4(LRESULT,   videoMessage,
           HVIDEO,  hVideo,
           UINT,    uMsg,
           LPARAM,   dw1,
           LPARAM,   dw2)
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\net\tapi\skywalker\filters\video\tapivcap\rtppdp.h ===
/****************************************************************************
 *  @doc INTERNAL RTPPDP
 *
 *  @module RtpPdP.h | Header file for the <c CRtpPdProperty>
 *    class used to implement a property page to test the new TAPI internal
 *    interfaces <i IRTPPDControl>.
 *
 *  @comm This code tests the TAPI Rtp Pd Output Pins <i IRTPPDControl>
 *    implementation. This code is only compiled if USE_PROPERTY_PAGES is
 *    defined.
 ***************************************************************************/

#ifndef _RTPPDP_H_
#define _RTPPDP_H_

#ifdef USE_PROPERTY_PAGES

#define NUM_RTPPD_CONTROLS				1
#define IDC_RtpPd_MaxPacketSize			0

/****************************************************************************
 *  @doc INTERNAL CRTPPDPCLASS
 *
 *  @class CRtpPdProperty | This class implements handling of a
 *    single Rtp Pd control property in a property page.
 *
 *  @mdata int | CRtpPdProperty | m_NumProperties | Keeps
 *    track of the number of properties.
 *
 *  @mdata IRTPPDControl* | CRtpPdProperty | m_pIRTPPDControl | Pointer
 *    to the <i IRTPPDControl> interface.
 *
 *  @comm This code tests the TAPI Rtp Pd Output Pins <i IRTPPDControl>
 *    implementation. This code is only compiled if USE_PROPERTY_PAGES is
 *    defined.
***************************************************************************/
class CRtpPdProperty : public CPropertyEditor 
{
	public:
	CRtpPdProperty(HWND hDlg, ULONG IDLabel, ULONG IDMinControl, ULONG IDMaxControl, ULONG IDDefaultControl, ULONG IDStepControl, ULONG IDEditControl, ULONG IDTrackbarControl, ULONG IDProgressControl, ULONG IDProperty, IRTPPDControl *pIRTPPDControl);
	~CRtpPdProperty ();

	// CPropertyEditor base class pure virtual overrides
	HRESULT GetValue();
	HRESULT SetValue();
	HRESULT GetRange();
	BOOL CanAutoControl(void);
	BOOL GetAuto(void);
	BOOL SetAuto(BOOL fAuto);

	private:
	IRTPPDControl *m_pIRTPPDControl;
};

/****************************************************************************
 *  @doc INTERNAL CRTPPDPCLASS
 *
 *  @class CRtpPdProperties | This class implements a property page
 *    to test the new TAPI internal interfaces <i IRTPPDControl>.
 *
 *  @mdata int | CRtpPdProperties | m_NumProperties | Keeps
 *    track of the number of properties.
 *
 *  @mdata IRTPPDControl* | CRtpPdProperties | m_pInterface | Pointer
 *    to the <i IRTPPDControl> interface.
 *
 *  @mdata CRtpPdProperty* | CRtpPdProperties | m_Controls[NUM_RTPPD_CONTROLS] | Array
 *    of Rtp Pd control properties.
 *
 *  @comm This code tests the TAPI Rtp Pd Output Pins <i IRTPPDControl>
 *    implementation. This code is only compiled if USE_PROPERTY_PAGES is
 *    defined.
***************************************************************************/
class CRtpPdProperties : public CBasePropertyPage
{
	public:
	CRtpPdProperties(LPUNKNOWN pUnk, HRESULT *pHr);
	~CRtpPdProperties();

	// Implement CBasePropertyPage virtual methods
	HRESULT OnConnect(IUnknown *pUnk);
	HRESULT OnDisconnect();
	HRESULT OnActivate();
	HRESULT OnDeactivate();
	HRESULT OnApplyChanges();
	BOOL    OnReceiveMessage(HWND hWnd, UINT uMsg, WPARAM wParam, LPARAM lParam);

	private:

	void SetDirty();

	HWND			m_hWnd;
	int				m_NumProperties;
	BOOL			m_fActivated;
	IRTPPDControl	*m_pIRTPPDControl;
	CRtpPdProperty	*m_Controls[NUM_RTPPD_CONTROLS];
};

#endif // USE_PROPERTY_PAGES

#endif // _RTPPDP_H_
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\net\tapi\skywalker\filters\video\tapivcap\tapivcap.h ===
/****************************************************************************
 *  @doc INTERNAL TAPIVCAP
 *
 *  @module TAPIVCap.h | Header file for the <c CTAPIVCap>
 *    class used to implement the TAPI Capture Source filter.
 ***************************************************************************/

/****************************************************************************
                                                                Table Of Contents
****************************************************************************/
/****************************************************************************
@doc INTERNAL

@contents1 Contents | To display a list of topics by category, click any
of the contents entries below. To display an alphabetical list of
topics, choose the Index button.

@head2 Introduction |
This DLL implements the TAPI MSP Video Capture filter. This filter reuses
some of the code that has been developed for the off-the-shelf VfW (QCAP) and
WDM (KSProxy) video capture filters, but adds a significant amount of
powerful processing functions to the capture process to meet all the
requirements discussed in section 4 of "Microsoft Video Capture Filter.doc".

This DLL adds support for  extended bitmap info headers for H.261 and H.263
video streams to communicate to the TAPI MSP Video Capture filter a list of
media types supported by the remote endpoint. Still, the decision to use
optional compression modes is left to the TAPI MSP Video Capture filter. The
current VfW off-the-shelf capture filter does not have a way to expose all
the capabilities of the capture device. We create our own media type
enumeration process to compensate for this limitation.

The TAPI MSP Video Capture filter also supports a number of DirectShow
interfaces (IAMVfwCaptureDialogs, IAMCrossbar, IAMVideoProcAmp,
ICameraControl, IAMVideoControl) to provide better control over the capture
process to TAPI applications.

It implements a new H.245 Video Capability interface (IH245VideoCapability)
to be used by the MSP in order to provide the TAPI MSP Capability module with
a table of estimated steady-state resource requirements as related to each
format that the capture device supports.

A new H.245 command interface (IH245EncoderCommand) is implemented to
communicate to the TAPI MSP Video Capture filter requests for I-frame, group
of blocks, or macro-block updates due to packet loss or multi-point switching.
We implement a network statistics interface (INetworkStats), to allow the
network to provide feedback on the channel conditions to the compressed video
output pin of the TAPI MSP Video Capture filter. The TAPI MSP Video Capture
filter is responsible for taking appropriate actions, if needed. The TAPI MSP
Video Capture filter also implements three control interfaces (ICPUControl,
IFrameRateControl, IBitrateControl) to be used by the TAPI MSP Quality
Controller to provide the best user experience.

The TAPI MSP Video Capture filter also exposes a preview output pin that can
be controlled independently of the capture output pin.

The TAPI MSP Video Capture filter exposes an interface (IProgressiveRefinement)
on its compressed video output pin to allow for transmission of
high-resolution stills that are continuously improved on the remote endpoint
as more data is received and decompressed. The TAPI MSP Video Capture filter
may also elect to implement this same interface on an optional separate and
dedicated still-image output pin.

Finally, the TAPI MSP Video Capture filter exposes an RTP packetization
descriptor output pin synchronized to the compressed capture output pin. The
downstream RTP Network Sink filter uses this second pin to understand how to
better fragment the compressed video data into network RTP packets.


@head2 Implementation |

@head3 VfW capture devices |
The TAPI MSP Video Capture filter talks directly to the VfW capture driver
using SendDriverMessage. This filter uses the existing DShow code
implemented in QCAP but adds the necessary functions to perform smart
teeing of the capture data to the preview pin. It replaces the
streaming-only code used by QCAP with frame grabbing code whenever
necessary. It controls the rate at which frames are being captured by
adjusting the rate at which DVM_FRAME message are being sent to the driver
in frame grabbing mode, or only returning a fraction of the frames being
captured in streaming mode. It performs format and Vfw to ITU-T size
conversions to bring the format of the captured video data to a format that
can easily be used for rendering, and directly encoded by the downstream
TAPI MSP Video Encoder filter if an installable codecs is registered with
the TAPI MSP. If there is no installable codec registered, the TAPI MSP
Video Capture filter also performs H.26x encoding, generating a compressed
video capture output stream in H.26x format, as well as an RTP packetization
descriptor output data stream. Finally, the TAPI MSP Video Capture filter
does all the necessary sequencing to pause the existing video streams
whenever it is being asked to generate still-image data, grab a
high-resolution snapshot, deliver it in progressively rendered form, and
restart the video streams.

@head3 WDM capture devices |
The TAPI MSP Video Capture filter talks directly to the WDM capture driver
using IOCTLs. This filter uses the existing code implemented in KSProxy
but adds the necessary functions to perform smart teeing of the capture
data to the preview pin, if necessary. It controls the rate at which frames
are being captured by adjusting the rate at which buffers are being
submitted to the driver in frame grabbing mode, or only returning a fraction
of the frames being captured in streaming mode using overlapped IOs. It
performs format and Vfw to ITU-T size conversions to bring the format of the
captured video data to a format that can easily be used for rendering, and
directly encoded by the downstream TAPI MSP Video Encoder filter if an
installable codecs is registered with the TAPI MSP. If there is no
installable codec registered, the TAPI MSP Video Capture filter also performs
H.26x encoding, generating a compressed video capture output stream in H.26x
format, as well as an RTP packetization descriptor output data stream.
Finally, the TAPI MSP Video Capture filter does all the necessary sequencing
to pause the existing video streams whenever it is being asked to generate
still-image data, grab a high-resolution snapshot, deliver it in
progressively rendered form, and restart the video streams.

@head2 Video capture filter application interfaces |

@head3 IAMVfwCaptureDialogs application interface|
@subindex IAMVfwCaptureDialogs methods
@subindex IAMVfwCaptureDialogs structures and enums

@head3 IAMCrossbar application interface|
@subindex IAMCrossbar methods
@subindex IAMCrossbar structures and enums

@head3 IAMVideoProcAmp application interface|
@subindex IAMVideoProcAmp methods
@subindex IAMVideoProcAmp structures and enums

@head3 ICameraControl application interface|
@subindex ICameraControl methods
@subindex ICameraControl structures and enums

@head3 IAMVideoControl application interface|
@subindex IAMVideoControl methods
@subindex IAMVideoControl structures and enums

@head3 IVideoDeviceControl application interface|
@subindex IVideoDeviceControl methods
@subindex IVideoDeviceControl structures and enums

@head2 Video capture filter MSP interfaces |

@head3 IH245VideoCapability application interface|
@subindex IH245VideoCapability methods
@subindex IH245VideoCapability structures and enums

@head2 Video capture filter output pin TAPI interfaces |

@head3 ICPUControl interface|
@subindex ICPUControl methods
@subindex ICPUControl structures and enums

@head3 IFrameRateControl interface|
@subindex IFrameRateControl methods
@subindex IFrameRateControl structures and enums

@head3 IBitrateControl interface|
@subindex IBitrateControl methods
@subindex IBitrateControl structures and enums

@head3 INetworkStats interface|
@subindex INetworkStats methods
@subindex INetworkStats structures and enums

@head3 IH245EncoderCommand interface|
@subindex IH245EncoderCommand methods
@subindex IH245EncoderCommand structures and enums

@head3 IProgressiveRefinement interface|
@subindex IProgressiveRefinement methods
@subindex IProgressiveRefinement structures and enums

@head3 IRTPPDControl interface|
@subindex IRTPPDControl methods
@subindex IRTPPDControl structures and enums

@head3 Common control structures and enums |
@subindex Common control structures
@subindex Common control enums

@head2 Classes |
@subindex Classes

@head2 Modules |
@subindex Modules
@subindex Constants

@head2 Code information |

The only libraries necessary in retail mode (w/o property pages) are ..\..\..\..\dev\tools\amovsdk.20\lib\strmbase.lib ..\..\..\ddk\lib\i386\ksuser.lib ..\..\..\ddk\lib\i386\ksguid.lib kernel32.lib ole32.lib uuid.lib msvcrt.lib

@head3 Exports |
DllCanUnloadNow
DllGetClassObject

@head3 Imports |
KERNEL32.DLL:
CloseHandle
CreateEventA
DeviceIoControl
DisableThreadLibraryCalls
FreeLibrary
GetLastError
GetOverlappedResult
GetVersionExA
InterlockedDecrement
InterlockedIncrement
RtlZeroMemory

MSVCRT.DLL:
??2@YAPAXI@Z
??3@YAXPAX@Z
_EH_prolog
__CxxFrameHandler
_purecall
memcmp

@head3 Code size |
Compile options: /nologo /MDd /W3 /GX /O1 /X /I "..\..\inc" /I "..\..\..\ddk\inc" /I "..\..\..\..\dev\tools\amovsdk.20\include" /I "..\..\..\..\dev\tools\amovsdk.20\classes\base" /I "..\..\..\..\dev\ntddk\inc" /I "..\..\..\..\dev\inc" /I "..\..\..\..\dev\tools\c32\inc" /D "NDEBUG" /D "WIN32" /D "_WINDOWS" /D "DLL" /D "STRICT" /FR"Release/" /Fp"Release/TAPIKsIf.pch" /YX /Fo"Release/" /Fd"Release/" /FD /c

Link options: ..\..\..\..\dev\tools\amovsdk.20\lib\strmbase.lib ..\..\..\ddk\lib\i386\ksuser.lib ..\..\..\ddk\lib\i386\ksguid.lib comctl32.lib msvcrt.lib winmm.lib kernel32.lib user32.lib gdi32.lib winspool.lib comdlg32.lib advapi32.lib shell32.lib ole32.lib oleaut32.lib uuid.lib odbc32.lib odbccp32.lib /nologo /base:"0x1e180000" /entry:"DllEntryPoint" /dll /incremental:no /pdb:"Release/TAPIKsIf.pdb" /map:"Release/TAPIKsIf.map" /machine:I386 /nodefaultlib /def:".\TAPIKsIf.def" /out:"Release/TAPIKsIf.ax" /i mplib:"Release/TAPIKsIf.lib"

Resulting size: 28KB


***********************************************************************
@contents2 IAMVfwCaptureDialogs methods |
@index mfunc | CVFWDLGSMETHOD

***********************************************************************
@contents2 IAMVfwCaptureDialogs structures and enums |
@index struct,enum | CVFWDLGSSTRUCTENUM

***********************************************************************
@contents2 IAMCrossbar methods |
@index mfunc | CXBARMETHOD

***********************************************************************
@contents2 IAMCrossbar structures and enums |
@index struct,enum | CXBARSTRUCTENUM

***********************************************************************
@contents2 IAMVideoProcAmp methods |
@index mfunc | CPROCAMPMETHOD

***********************************************************************
@contents2 IAMVideoProcAmp structures and enums |
@index struct,enum | CPROCAMPSTRUCTENUM

***********************************************************************
@contents2 ICameraControl methods |
@index mfunc | CCAMERACMETHOD

***********************************************************************
@contents2 ICameraControl structures and enums |
@index struct,enum | CCAMERACSTRUCTENUM

***********************************************************************
@contents2 IAMVideoControl methods |
@index mfunc | CVIDEOCMETHOD

***********************************************************************
@contents2 IAMVideoControl structures and enums |
@index struct,enum | CVIDEOCSTRUCTENUM

***********************************************************************
@contents2 IVideoDeviceControl methods |
@index mfunc | CDEVENUMMETHOD

***********************************************************************
@contents2 IVideoDeviceControl structures and enums |
@index struct,enum | CDEVENUMSTRUCTENUM

***********************************************************************
@contents2 IH245VideoCapability methods |
@index mfunc | CH245VIDCMETHOD

***********************************************************************
@contents2 IH245VideoCapability structures and enums |
@index struct,enum | H245VIDCSTRUCTENUM

***********************************************************************
@contents2 ICPUControl methods |
@index mfunc | CCPUCMETHOD

***********************************************************************
@contents2 ICPUControl structures and enums |
@index struct,enum | CCAPTURECPUCSTRUCTENUM

***********************************************************************
@contents2 IFrameRateControl methods |
@index mfunc | CFPSCMETHOD

***********************************************************************
@contents2 IFrameRateControl structures and enums |
@index struct,enum | CCAPTUREFPSCSTRUCTENUM

***********************************************************************
@contents2 IBitrateControl methods |
@index mfunc | CCAPTUREBITRATECMETHOD

***********************************************************************
@contents2 IBitrateControl structures and enums |
@index struct,enum | CCAPTUREBITRATECSTRUCTENUM

***********************************************************************
@contents2 INetworkStats methods |
@index mfunc | CCAPTURENETSTATMETHOD

***********************************************************************
@contents2 INetworkStats structures and enums |
@index struct,enum | CNETSTATSSTRUCTENUM

***********************************************************************
@contents2 IH245EncoderCommand methods |
@index mfunc | CCAPTUREH245VIDCMETHOD

***********************************************************************
@contents2 IH245EncoderCommand structures and enums |
@index struct,enum | CCAPTUREH245VIDCSTRUCTENUM

***********************************************************************
@contents2 IProgressiveRefinement methods |
@index mfunc | CCAPTUREPROGREFMETHOD

***********************************************************************
@contents2 IProgressiveRefinement structures and enums |
@index struct,enum | CCAPTUREPROGREFSTRUCTENUM

***********************************************************************
@contents2 IRTPPDControl methods |
@index mfunc | CRTPPDMETHOD

***********************************************************************
@contents2 IRTPPDControl structures and enums |
@index struct,enum | CRTPPDSTRUCTENUM

***********************************************************************
@contents2 Common control structures |
@index struct | STRUCT

***********************************************************************
@contents2 Common control enums |
@index enum | ENUM

***********************************************************************
@contents2 Modules |
@index module |

***********************************************************************
@contents2 Classes |
@index class |
@index mdata, mfunc | CCAPTUREPINCLASS,CCAPTUREPINMETHOD,CCAPTUREBITRATECMETHOD
@index mdata, mfunc | CBASEPINCLASS,CBASEPINMETHOD,CCPUCMETHOD,CFPSCMETHOD
@index mdata, mfunc | CTAPIVCAPCLASS,CCAMERACMETHOD,CDEVENUMMETHOD

***********************************************************************
@contents2 Constants |
@index const |
****************************************************************************/

#ifndef _TAPIVCAP_H_
#define _TAPIVCAP_H_

//these must be kept in synch with the ones in Capture.h @ 12
#ifndef MAX_VIDEO_BUFFERS
#define MAX_VIDEO_BUFFERS 6
#endif
#ifndef MIN_VIDEO_BUFFERS
#define MIN_VIDEO_BUFFERS 2
#endif

//#define M_EVENTS

#ifdef DBG
extern DWORD g_dwVideoCaptureTraceID;

#ifndef FX_ENTRY
#define FX_ENTRY(s) static TCHAR _this_fx_ [] = TEXT(s);
#define _fx_ ((LPTSTR) _this_fx_)
#endif
#else
#ifndef FX_ENTRY
#define FX_ENTRY(s)
#endif
#define _fx_
#endif

// Forward declarations
class CCapturePin;      // Filter's video stream output pin
#ifdef USE_OVERLAY
class COverlayPin;      // Filter's overlay preview pin
#endif
class CPreviewPin;      // Filter's non-overlay preview pin
class CRtpPdPin;        // Filter's RTP packetization descriptor pin
class CTAPIVCap;        // Filter class
class CFrameSample;     // Video media sample class
class CRtpPdSample;     // Rtp pd media sample class
class CCapDev;          // Capture device base class
class CVfWCapDev;       // VfW capture device class
class CWDMCapDev;       // WDM capture device class
class CConverter;       // Format converter base class
class CICMConverter;// ICM format converter class

// Globals
EXTERN_C VIDEOCAPTUREDEVICEINFO g_aDeviceInfo[];
EXTERN_C DWORD          g_dwNumDevices;

/*****************************************************************************
 *  @doc INTERNAL CTAPIVCAPCLASSSTRUCTENUM
 *
 *  @enum ThdState | The <t ThdState> enum is used to change and keep track of
 *    that capture worker thread state.
 *
 *  @emem TS_Not | Worker thread hasn't been created yet.
 *
 *  @emem TS_Create | Worker thread has been created.
 *
 *  @emem TS_Init | Worker thread hasn't been initialized.
 *
 *  @emem TS_Pause | Worker thread is in the Pause state.
 *
 *  @emem TS_Run | Worker thread is in the Run state.
 *
 *  @emem TS_Stop | Worker thread is in the Stop state.
 *
 *  @emem TS_Destroy | Worker thread hasn't been destroyed.
 *
 *  @emem TS_Exit | Worker thread hasn't been asked to exit.
 *
 ****************************************************************************/
enum ThdState {TS_Not, TS_Create, TS_Init, TS_Pause, TS_Run, TS_Stop, TS_Destroy, TS_Exit};

// this structure contains all settings of the capture
// filter that are user settable
//
typedef struct _vfwcaptureoptions {

   UINT  uVideoID;      // id of video driver to open
   DWORD dwTimeLimit;   // stop capturing at this time???

   DWORD dwTickScale;   // frame rate rational
   DWORD dwTickRate;    // frame rate = dwRate/dwScale in ticks/sec
   DWORD usPerFrame;    // frame rate expressed in microseconds per frame
   DWORD dwLatency;     // time added for latency, in 100ns units

   UINT  nMinBuffers;   // number of buffers to use for capture
   UINT  nMaxBuffers;   // number of buffers to use for capture

   UINT  cbFormat;      // sizeof VIDEOINFO stuff
   VIDEOINFOHEADER * pvi;     // pointer to VIDEOINFOHEADER (media type)

} VFWCAPTUREOPTIONS;

/****************************************************************************
 *  @doc INTERNAL CTAPIVCAPCLASS
 *
 *  @class CTAPIVCap | This class implements the TAPI Capture Source
 *    filter.
 *
 *  @mdata CCritSec | CTAPIVCap | m_lock | Critical section used for
 *    locking by the <c CBaseFilter> base class.
 *
 *  @mdata CCapturePin | CTAPIVCap | m_pCapturePin | Pointer to the capture pin
 *    object
 *
 *  @mdata COverlayPin | CTAPIVCap | m_pOverlayPin | Pointer to the overlay
 *    pin object
 *
 *  @mdata CPreviewPin | CTAPIVCap | m_pPreviewPin | Pointer to the preview
 *    pin object
 *
 *  @mdata CPreviewPin | CTAPIVCap | m_pRtpPdPin | Pointer to the Rtp Pd
 *    pin object
 *
 *  @mdata BOOL | CTAPIVCap | m_fDialogUp | Set to TRUE if a VfW driver
 *    dialog box is up
 *
 *  @todo Describe and clean up other members
 ***************************************************************************/
class CTAPIVCap : public CBaseFilter, public IAMVideoControl
#ifdef USE_PROPERTY_PAGES
,public ISpecifyPropertyPages
#endif
,public IVideoDeviceControl
,public IRTPPayloadHeaderMode
{
        public:
        DECLARE_IUNKNOWN

        CTAPIVCap(IN LPUNKNOWN pUnkOuter, IN TCHAR *pName, OUT HRESULT *pHr);
        ~CTAPIVCap();
        STDMETHODIMP NonDelegatingQueryInterface(IN REFIID riid, OUT PVOID *ppv);

#ifdef USE_PROPERTY_PAGES
        // ISpecifyPropertyPages methods
        STDMETHODIMP GetPages(OUT CAUUID *pPages);
#endif

        // Implement IAMVideoControl
        STDMETHODIMP GetCaps(IN IPin *pPin, OUT long *pCapsFlags);
        STDMETHODIMP GetCurrentActualFrameRate(IN IPin *pPin, OUT LONGLONG *ActualFrameRate);
        STDMETHODIMP GetFrameRateList(IN IPin *pPin, IN long iIndex, IN SIZE Dimensions, OUT long *ListSize, OUT LONGLONG **FrameRates);
        STDMETHODIMP GetMaxAvailableFrameRate(IN IPin *pPin, IN long iIndex,IN SIZE Dimensions, OUT LONGLONG *MaxAvailableFrameRate);
        STDMETHODIMP GetMode(IN IPin *pPin, OUT long *Mode);
        STDMETHODIMP SetMode(IN IPin *pPin, IN long Mode);

        // Implement IVideoDeviceControl
        STDMETHODIMP GetNumDevices(OUT PDWORD pdwNumDevices);
        STDMETHODIMP GetDeviceInfo(IN DWORD dwDeviceIndex, OUT VIDEOCAPTUREDEVICEINFO *pDeviceInfo);
        STDMETHODIMP GetCurrentDevice(OUT DWORD *pdwDeviceIndex);
        STDMETHODIMP SetCurrentDevice(IN DWORD dwDeviceIndex);

        // Implement CBaseFilter pure virtual member functions
        int GetPinCount();
        CBasePin *GetPin(IN int n);

        // Implement IMediaFilter
        STDMETHODIMP Run(IN REFERENCE_TIME tStart);
        STDMETHODIMP Pause();
        STDMETHODIMP Stop();
        STDMETHODIMP GetState(IN DWORD dwMilliSecsTimeout, OUT FILTER_STATE *State);
        STDMETHODIMP SetSyncSource(IN IReferenceClock *pClock);
        STDMETHODIMP JoinFilterGraph(IN IFilterGraph *pGraph, IN LPCWSTR pName);

        // Implement IRTPPayloadHeaderMode
        STDMETHODIMP SetMode(IN RTPPayloadHeaderMode rtpphmMode);

        private:

        friend class CTAPIBasePin;
        friend class CCapturePin;
        friend class CPreviewPin;
#ifdef USE_OVERLAY
        friend class COverlayPin;
#endif
        friend class CRtpPdPin;
        friend class CCapDev;
        friend class CVfWCapDev;
        friend class CWDMCapDev;
        friend class CDShowCapDev;
        friend class CWDMDialog;
        friend class CConverter;
        friend class CICMConverter;
        friend class CH26XEncoder;

        HRESULT CreatePins();
        HRESULT GetWDMDevices();
        CCritSec        m_lock;
        CCapturePin     *m_pCapturePin;
#ifdef USE_OVERLAY
        COverlayPin     *m_pOverlayPin;
#endif
        CPreviewPin     *m_pPreviewPin;
        CRtpPdPin       *m_pRtpPdPin;
        CCapDev         *m_pCapDev;
        DWORD           m_dwDeviceIndex;
        BOOL            m_fAvoidOverlay;
        BOOL            m_fPreviewCompressedData;

    // Capture worker thread management
    HANDLE              m_hThread;
    DWORD               m_tid;
    ThdState    m_state;     // used to communicate state changes between worker thread and main
                          // Worker thread can make
                          //    Init->Pause, Stop->Destroy, Destroy->Exit transitions
                          // main thread(s) can make
                          //    Pause->Run, Pause->Stop, Run->Pause, Run->Stop transitions
                          // other transitions are invalid
        HANDLE          m_hEvtPause; // Signalled when the worker is in the pause state
    HANDLE              m_hEvtRun;   // Signalled when the worker is in the run state
        CAMEvent        m_EventAdvise;
    static DWORD WINAPI ThreadProcInit(void *pv);
    DWORD               ThreadProc();
        ThdState        ChangeThdState(ThdState state);
    BOOL                CreateThd();
    BOOL                PauseThd();
    BOOL                RunThd();
    BOOL                StopThd();
    BOOL                DestroyThd();
    BOOL                ThdExists() {return (m_hThread != NULL);};
    HRESULT             Prepare();
    HRESULT             Capture();
    HRESULT             Unprepare();

        // Video capture buffer queue management
    UINT        *m_pBufferQueue; // what order we sent the buffers to the driver in
    UINT        m_uiQueueHead;   // next buffer going to driver goes here
    UINT        m_uiQueueTail;   // next buffer coming from driver is here
        HRESULT ReleaseFrame(LPTHKVIDEOHDR ptvh);

    // return the time of a given tick
    //
    REFERENCE_TIME TickToRefTime (DWORD nTick) {
       const DWORD dw100ns = 10 * 1000 * 1000;
       REFERENCE_TIME time =
          UInt32x32To64(dw100ns, m_user.dwTickScale)
          * nTick
          / m_user.dwTickRate;
       return time;
       };

        struct _cap_parms
        {
#if 0
                // video driver stuff
                //
                HVIDEO         hVideoIn;     // video input
                HVIDEO         hVideoExtIn;  // external in (source control)
                HVIDEO         hVideoExtOut; // external out (overlay; not required)
                MMRESULT       mmr;          // open fail/success code
                BOOL           bHasOverlay;  // TRUE if ExtOut has overlay support
#endif
                // the preview buffer.  once created it persists until
                // the stream destructor because the renderer assumes
                // that it can keep a pointer to this and not crash
                // if it uses it after stopping the stream.
                // (no longer a problem)
                // !!! can we remove all this Preview still frame stuff?
                //
                UINT           cbVidHdr;       // size of a videohdr (or videohdrex)
#if 0
                THKVIDEOHDR    tvhPreview;     // preview video header
                CFrameSample * pSamplePreview; // CMediaSample for preview buffer
#endif
                CFrameSample **paPreviewSamples;
                CFrameSample **paCaptureSamples;
                CRtpPdSample **paRtpPdSamples;
                UINT           cCaptureSamples;// number of capture samples
                UINT           cPreviewSamples;// number of preview samples
                UINT           cRtpPdSamples;// number of rtp pd samples

                // video header & buffer stuff
                //
                UINT           cbBuffer;           // max size of video frame data
                UINT           nHeaders;           // number of video headers
                struct _cap_hdr {
                THKVIDEOHDR  tvh;
                long  lLock;
                //long  nUsedDownstream;
                } * paHdr;
                BOOL           fCaptureNeedConverter; // TRUE if capture pin generates compressed data
                BOOL           fPreviewNeedConverter; // TRUE if preview pin generates compressed data

#ifdef M_EVENTS
                HANDLE         h_aEvtBufferDone[MAX_VIDEO_BUFFERS];     //**cristiai: each event for a buffer
                HANDLE         h_aEvtCapWait[MAX_VIDEO_BUFFERS+1];      //**cristiai: WaitMultiple on this array
#endif
                HANDLE         hEvtBufferDone;     // this event signalled when a buffer is ready
                DWORD_PTR      h0EvtBufferDone;    // on Win95 this is a Ring0 alias of the above event

                LONGLONG       tTick;              // duration of a single tick
                LONGLONG       llLastTick;        // the last frame sent downstream
                DWORDLONG      dwlLastTimeCaptured;// the last driver time stamp
                DWORDLONG      dwlTimeCapturedOffset;// wraparound compensation
                UINT           uiLastAdded;       // the last buffer AddBuffer'd
                DWORD         dwFirstFrameOffset; // when 1st frame was captured
                LONGLONG       llFrameCountOffset; // add this to frame number
                BOOL          fReRun;             // went from Run->Pause->Run
                BOOL          fLastRtpPdSampleDiscarded; // due to IAMStreamControl
                CRefTime       rtThisFrameTime;  // clock time when frame was captured
                CRefTime              rtDriverStarted;  // when videoStreamStart was called
                CRefTime              rtDriverLatency;  // how long it takes captured frame to
                // get noticed by ring 3
        } m_cs;

        VFWCAPTUREOPTIONS m_user;

        //for the RTP Payload Header Mode (0=draft, 1=RFC2190)
        RTPPayloadHeaderMode m_RTPPayloadHeaderMode;
};

#endif // _TAPIVCAP_H_
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\net\tapi\skywalker\filters\video\tapivcap\vfwdlgs.cpp ===
/****************************************************************************
 *  @doc INTERNAL VFWDLGS
 *
 *  @module VfWDlgs.cpp | Source file for the <c CVfWCapDev> 
 *    class methods used to implement the <i IAMVfwCaptureDialogs> interface.
 ***************************************************************************/

#include "Precomp.h"

/****************************************************************************
 *  @doc INTERNAL CVFWDLGSMETHOD
 *
 *  @mfunc HRESULT | CVfWCapDev | HasDialog | This method is used to
 *    determine if the specified dialog box exists in the driver.
 *
 *  @parm int | iDialog | Specifies the desired dialog box. This is a member
 *    of the <t VfwCaptureDialogs> enumerated data type.
 *
 *  @rdesc This method returns an HRESULT value that depends on the
 *    implementation of the interface. HRESULT can include one of the
 *    following standard constants, or other values not listed:
 *
 *  @flag E_FAIL | Failure
 *  @flag E_INVALIDARG | Invalid argument
 *  @flag E_UNEXPECTED | Unrecoverable error
 *  @flag S_OK | If the driver contains the dialog box 
 *  @flag S_FALSE | If the driver doesn't contain the dialog box 
 ***************************************************************************/
HRESULT CVfWCapDev::HasDialog(IN int iDialog)
{
	HRESULT	Hr = NOERROR;
	HVIDEO	hVideo;

	FX_ENTRY("CVfWCapDev::HasDialog")

	DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: begin", _fx_));

	// Validate input parameters
	ASSERT((iDialog == VfwCaptureDialog_Source) || (iDialog == VfwCaptureDialog_Format) || (iDialog == VfwCaptureDialog_Display));
	if (iDialog == VfwCaptureDialog_Source)
		hVideo = m_hVideoExtIn;
	else if (iDialog == VfwCaptureDialog_Format)
		hVideo = m_hVideoIn;
	else if (iDialog == VfwCaptureDialog_Display)
		hVideo = m_hVideoExtOut;
	else
	{
		DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: Invalid argument", _fx_));
		Hr = E_INVALIDARG;
		goto MyExit;
	}

	if (videoDialog(hVideo, GetDesktopWindow(), VIDEO_DLG_QUERY) == 0)
	{
		Hr = S_OK;
		DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s:   SUCCESS: Yes, %s dialog is supported", _fx_, iDialog == VfwCaptureDialog_Source ? "Source" : iDialog == VfwCaptureDialog_Format ? "Format" : "Display"));
	}
	else
	{
		Hr = S_FALSE;
		DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s:   SUCCESS: Nope, %s dialog is not supported", _fx_, iDialog == VfwCaptureDialog_Source ? "Source" : iDialog == VfwCaptureDialog_Format ? "Format" : "Display"));
	}

MyExit:
	DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: end", _fx_));
	return Hr;
}

/****************************************************************************
 *  @doc INTERNAL CVFWDLGSMETHOD
 *
 *  @mfunc HRESULT | CVfWCapDev | ShowDialog | This method is used to
 *    displaay the specified dialog box.
 *
 *  @parm int | iDialog | Specifies the desired dialog box. This is a member
 *    of the <t VfwCaptureDialogs> enumerated data type.
 *
 *  @parm HWND | hwnd | Specifies the handle of the dialog box's parent
 *    window.
 *
 *  @rdesc This method returns an HRESULT value that depends on the
 *    implementation of the interface. HRESULT can include one of the
 *    following standard constants, or other values not listed:
 *
 *  @flag E_FAIL | Failure
 *  @flag E_INVALIDARG | Invalid argument
 *  @flag E_UNEXPECTED | Unrecoverable error
 *  @flag VFW_E_NOT_STOPPED | The operation could not be performed because the filter is not stopped 
 *  @flag VFW_E_CANNOT_CONNECT | No combination of intermediate filters could be found to make the connection 
 ***************************************************************************/
HRESULT CVfWCapDev::ShowDialog(IN int iDialog, IN HWND hwnd)
{
	HRESULT	Hr = NOERROR;
	HVIDEO	hVideo;
	DWORD	dw;

	FX_ENTRY("CVfWCapDev::ShowDialog")

	DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: begin", _fx_));

	// Before we bring the format dialog up, make sure we're not streaming, or about to
	// Also make sure another dialog isn't already up (I'm paranoid)
	if ((iDialog == VfwCaptureDialog_Format && m_pCaptureFilter->m_State != State_Stopped) || m_fDialogUp)
	{
		DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: Can't put format dialog up while streaming!", _fx_));
		Hr = VFW_E_NOT_STOPPED;
		goto MyExit;
	}

	m_fDialogUp = TRUE;

	ASSERT((iDialog == VfwCaptureDialog_Source) || (iDialog == VfwCaptureDialog_Format) || (iDialog == VfwCaptureDialog_Display));

	if (iDialog == VfwCaptureDialog_Source)
		hVideo = m_hVideoExtIn;
	else if (iDialog == VfwCaptureDialog_Format)
		hVideo = m_hVideoIn;
	else if (iDialog == VfwCaptureDialog_Display)
		hVideo = m_hVideoExtOut;
	else
	{
		DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: Invalid argument", _fx_));
		m_fDialogUp = FALSE;
		Hr = E_INVALIDARG;
		goto MyExit;
	}

	if (hwnd == NULL)
		hwnd = GetDesktopWindow();

	DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s:   SUCCESS: Putting up %s dialog...", _fx_, iDialog == VfwCaptureDialog_Source ? "Source" : iDialog == VfwCaptureDialog_Format ? "Format" : "Display"));

	// This changed our output format!
	if ((dw = videoDialog(hVideo, hwnd, 0)) == 0)
	{
		DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s:   SUCCESS: ...videoDialog succeeded", _fx_));

		if (iDialog == VfwCaptureDialog_Format)
		{
			DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s:   WARNING: Output format may have changed", _fx_));

			// The dialog changed the driver's internal format.  Get it again.
			if (m_pCaptureFilter->m_user.pvi)
				delete m_pCaptureFilter->m_user.pvi;
			GetFormatFromDriver(&m_pCaptureFilter->m_user.pvi);

			// Reconnect the capture pin
			if ((Hr = m_pCaptureFilter->m_pCapturePin->Reconnect()) != S_OK)
			{
				DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: Couldn't reconnect capture pin", _fx_));
				Hr = VFW_E_CANNOT_CONNECT;
				goto MyExit;
			}

			// Reconnect the preview pin
			if ((Hr = m_pCaptureFilter->m_pPreviewPin->Reconnect()) != S_OK)
			{
				DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: Couldn't reconnect preview pin", _fx_));
				Hr = VFW_E_CANNOT_CONNECT;
				goto MyExit;
			}

/* The RTP pin doesn't need to be reconnected because it will not be affected by capture format change.
			// Reconnect the Rtp Pd pin
			if ((Hr = m_pCaptureFilter->m_pRtpPdPin->Reconnect()) != S_OK)
			{
				DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: Couldn't reconnect Rtp Pd pin", _fx_));
				Hr = VFW_E_CANNOT_CONNECT;
				goto MyExit;
			}
*/
		}
	}
	else
	{
		DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: ...videoDialog failed!", _fx_));
		Hr = E_FAIL;
	}

	m_fDialogUp = FALSE;

MyExit:
	DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: end", _fx_));
	return Hr;
}

/****************************************************************************
 *  @doc INTERNAL CVFWDLGSMETHOD
 *
 *  @mfunc HRESULT | CVfWCapDev | SendDriverMessage | This method is used to
 *    send a driver-specific message.
 *
 *  @parm int | iDialog | Specifies the desired dialog box. This is a member
 *    of the <t VfwCaptureDialogs> enumerated data type.
 *
 *  @parm int | uMsg | Specifies the message to send to the driver.
 *
 *  @parm long | dw1 | Specifies message data.
 *
 *  @parm long | dw2 | Specifies message data.
 *
 *  @rdesc This method returns an HRESULT value that depends on the
 *    implementation of the interface. HRESULT can include one of the
 *    following standard constants, or other values not listed:
 *
 *  @flag E_FAIL | Failure
 *  @flag E_INVALIDARG | Invalid argument
 *  @flag E_UNEXPECTED | Unrecoverable error
 ***************************************************************************/
HRESULT CVfWCapDev::SendDriverMessage(IN int iDialog, IN int uMsg, IN long dw1, IN long dw2)
{
	HRESULT	Hr = NOERROR;
	HVIDEO	hVideo;

	FX_ENTRY("CVfWCapDev::SendDriverMessage")

	DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: begin", _fx_));

	// This could do anything!  Bring up a dialog, who knows.
	// Don't take any crit sect or do any kind of protection.
	// They're on their own

	// Validate input parameters
	ASSERT((iDialog == VfwCaptureDialog_Source) || (iDialog == VfwCaptureDialog_Format) || (iDialog == VfwCaptureDialog_Display));

	if (iDialog == VfwCaptureDialog_Source)
		hVideo = m_hVideoExtIn;
	else if (iDialog == VfwCaptureDialog_Format)
		hVideo = m_hVideoIn;
	else if (iDialog == VfwCaptureDialog_Display)
		hVideo = m_hVideoExtOut;
	else
	{
		DBGOUT((g_dwVideoCaptureTraceID, FAIL, "%s:   ERROR: Invalid argument", _fx_));
		Hr = E_INVALIDARG;
		goto MyExit;
	}

	Hr = videoMessage(hVideo, uMsg, dw1, dw2);

MyExit:
	DBGOUT((g_dwVideoCaptureTraceID, TRCE, "%s: end", _fx_));
	return Hr;
}
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\net\tapi\skywalker\filters\video\tapivcap\video.c ===
/****************************************************************************
 *  @doc INTERNAL THUNK
 *
 *  @module Thunk.c | Source file for the VfW video API.
 ***************************************************************************/

#ifndef DRIVERS_SECTION
#define DRIVERS_SECTION  TEXT("DRIVERS32")
#endif

#include <windows.h>
#include <windowsx.h>
#include <mmsystem.h>

#ifdef WIN32
//#include <mmddk.h>
#include <stdlib.h>
#endif

#include <vfw.h>
//#include "win32.h"
#if defined (NT_BUILD)
#include "vc50\msviddrv.h"
#else
#include "msviddrv.h"
#endif
//#include "msvideo.h"
#include "ivideo32.h"
// #include "msvideoi.h"

#define DBGUTIL_ENABLE
#ifdef DBGUTIL_ENABLE
  #include <stdio.h>
  #include <stdarg.h>

  static int dprintf( char * format, ... )
  {
      char out[1024];
      int r;
      va_list marker;
      va_start(marker, format);
      r=_vsnprintf(out, 1022, format, marker);
      va_end(marker);
      OutputDebugString( out );
      return r;
  }


#else
  #define dprintf ; / ## /
#endif


#ifdef DBGUTIL_ENABLE // DEBUG

#ifndef FX_ENTRY
#define FX_ENTRY(s) static char _this_fx_ [] = TEXT(s);
#define _fx_ ((LPTSTR) _this_fx_)
#endif
#else
#ifndef FX_ENTRY
#define FX_ENTRY(s)
#endif
#define _fx_
#endif




#ifndef DVM_STREAM_FREEBUFFER
  #define DVM_STREAM_ALLOCBUFFER    (DVM_START + 312)
  #define DVM_STREAM_FREEBUFFER    (DVM_START + 313)
#endif

#define SZCODE const TCHAR
#define STATICDT static
#define STATICFN static

/*
 * don't lock pages in NT
 */
#define HugePageLock(x, y)              (TRUE)
#define HugePageUnlock(x, y)

#define MapSL(x)        x

#define GetCurrentTask() GetCurrentThread()
#define MAXVIDEODRIVERS 10

#define DebugErr(this, that)

#pragma warning(disable:4002)
#define AuxDebugEx()
#define assert()

/*****************************************************************************
 * Variables
 *
 ****************************************************************************/

SZCODE  szNull[]        = TEXT("");
SZCODE  szVideo[]       = TEXT("msvideo");

#ifndef WIN32
SZCODE  szDrivers[]     = "Drivers";
#else
STATICDT SZCODE  szDrivers[]     = DRIVERS_SECTION;
#endif

STATICDT SZCODE  szSystemIni[]   = TEXT("system.ini");

SZCODE szDriversDescRegKey[] = TEXT("Software\\Microsoft\\Windows NT\\CurrentVersion\\drivers.desc");

UINT    wTotalVideoDevs;                  // total video devices
extern HINSTANCE ghInstDll;               // our module handle

#include "CritSec.h"


// -----------------------------------------------------------
// If the following structure changes, update AVICAP and AVICAP.32 also!!!

typedef struct tCapDriverInfo {
   TCHAR szKeyEnumName[MAX_PATH];
   TCHAR szDriverName[MAX_PATH];
   TCHAR szDriverDescription[MAX_PATH];
   TCHAR szDriverVersion[80];
   TCHAR szSoftwareKey[MAX_PATH];
   DWORD dnDevNode;         // Set if this is a PnP device
   BOOL  fOnlySystemIni;    // If the [path]drivername is only in system.ini
   BOOL  fDisabled;         // User has disabled driver in the control panel
   BOOL  fActive;           // Reserved
   DWORD dwMsVideoIndex;    // msvideo# slot number in system.ini
} CAPDRIVERINFO, FAR *LPCAPDRIVERINFO;

#ifndef DEVNODE
typedef DWORD      DEVNODE;     // Devnode.
#endif

#ifndef LPHKEY
typedef HKEY FAR * LPHKEY;
#endif

// Registry settings of interest to capture drivers
SZCODE  szRegKey[]          = TEXT("SYSTEM\\CurrentControlSet\\Control\\MediaResources\\msvideo");
SZCODE  szRegActive[]       = TEXT("Active");
SZCODE  szRegDisabled[]     = TEXT("Disabled");
SZCODE  szRegDescription[]  = TEXT("Description");
SZCODE  szRegDevNode[]      = TEXT("DevNode");
SZCODE  szRegDriver[]       = TEXT("Driver");
SZCODE  szRegSoftwareKey[]  = TEXT("SOFTWAREKEY");

LPCAPDRIVERINFO aCapDriverList[MAXVIDEODRIVERS]; // Array of all capture drivers


#ifdef DBGUTIL_ENABLE //DEBUG
  void dbg_Dump_aCapDriverList(char *msg)
  {
    int i;
    dprintf("%s: DeviceList contains %d Video Device(s).\n", msg, wTotalVideoDevs);

    for (i = 0; i < (int) wTotalVideoDevs; i++) {
        dprintf("%s: aCapDriverList[%d]:  DriverName %s, Desc %s\n", msg, i, aCapDriverList[i]->szDriverName, aCapDriverList[i]->szDriverDescription);
    }
  }

#else
  #define dbg_Dump_aCapDriverList(a)
#endif

/*****************************************************************************
 * @doc INTERNAL  VIDEO
 *
 * @api BOOL | videoRegOpenMSVideoKey | This function returns a key
 *      for the msvideo node in the registry.
 *      If the key does not exist it will be created,
 *      and the default entries made.
 *
 * @rdesc Returns Key on success, else NULL.
 ****************************************************************************/
HKEY videoRegOpenMSVideoKey (void)
{
    HKEY hKey = NULL;

    // Get the key if it already exists
    if (RegOpenKey (
                HKEY_LOCAL_MACHINE,
                szRegKey,
                &hKey) != ERROR_SUCCESS) {

        // Otherwise make a new key
        if (RegCreateKey (
                        HKEY_LOCAL_MACHINE,
                        szRegKey,
                        &hKey) == ERROR_SUCCESS) {
            // Add the default entries to the msvideo node?

        }
    }
    return hKey;
}

/*****************************************************************************
 * @doc INTERNAL  VIDEO
 *
 * @api BOOL | videoRegGetDriverByIndex | This function returns information
 *      about a capture driver by index from the registry.
 *
 * @parm DWORD | dwDeviceID | Identifies the video device to open.
 *      The value of <p dwDeviceID> varies from zero to one less
 *      than the number of video capture devices installed in the system.
 *
 * @parm LPDEVNODE | lpDevnode | Specifies a far pointer to a buffer
 *   used to return an <t DEVNODE> handle.  For non Plug-and-Play devices,
 *   this return value will be NULL.
 *
 * @parm LPBOOL | lpEnabled | Specifies a far pointer to a buffer
 *   used to return a <t BOOL> flag.  If this value is TRUE, the driver is
 *   enabled, if FALSE, the corresponding device is disabled.
 *
 * @rdesc Returns TRUE if successful, or FALSE if a driver was not found
 *  with the <p dwDeviceID> index.
 *
 * @comm Because the indexes of the MSVIDEO devices in the SYSTEM.INI
 *       file can be non-contiguous, applications should not assume
 *       the indexes range between zero and the number of devices minus
 *       one.
 *
 ****************************************************************************/


BOOL videoRegGetKeyByIndex (
        HKEY            hKeyMSVideoRoot,
        DWORD           dwDeviceID,
        LPCAPDRIVERINFO lpCapDriverInfo,
        LPHKEY          phKeyChild)
{
    BOOL fOK = FALSE;
    HKEY hKeyEnum;
    int i;

    *phKeyChild = (HKEY) 0;

    for (i=0; i < MAXVIDEODRIVERS; i++) {       //

        if (RegEnumKey (
                hKeyMSVideoRoot,
                i,
                lpCapDriverInfo-> szKeyEnumName,
                sizeof(lpCapDriverInfo->szKeyEnumName)/sizeof(TCHAR)) != ERROR_SUCCESS)
            break;

        // Found a subkey, does it match the requested index?
        if (i == (int) dwDeviceID) {

            if (RegOpenKey (
                        hKeyMSVideoRoot,
                        lpCapDriverInfo-> szKeyEnumName,
                        &hKeyEnum) == ERROR_SUCCESS) {

                *phKeyChild = hKeyEnum;  // Found it!!!
                fOK = TRUE;

            }
            break;
        }
    } // endof all driver indices
    return fOK;
}

// Fetches driver info listed in the registry.
// Returns: TRUE if the index was valid, FALSE if no driver at that index
// Note: Registry entry ordering is random.

BOOL videoRegGetDriverByIndex (
        DWORD           dwDeviceID,
        LPCAPDRIVERINFO lpCapDriverInfo)
{
    DWORD dwType;
    DWORD dwSize;
    BOOL fOK;
    HKEY hKeyChild;
    HKEY hKeyMSVideoRoot;

    // Always start clean since the entry may be recycled
    _fmemset (lpCapDriverInfo, 0, sizeof (CAPDRIVERINFO));

    if (!(hKeyMSVideoRoot = videoRegOpenMSVideoKey()))
        return FALSE;

    if (fOK = videoRegGetKeyByIndex (
                hKeyMSVideoRoot,
                dwDeviceID,
                lpCapDriverInfo,
                &hKeyChild)) {

        // Fetch the values:
        //      Active
        //      Disabled
        //      Description
        //      DEVNODE
        //      Driver
        //      SOFTWAREKEY

        dwSize = sizeof(BOOL);          // Active
        RegQueryValueEx(
                   hKeyChild,
                   szRegActive,
                   NULL,
                   &dwType,
                   (LPBYTE) &lpCapDriverInfo->fActive,
                   &dwSize);

        dwSize = sizeof(BOOL);          // Enabled
        RegQueryValueEx(
                   hKeyChild,
                   szRegDisabled,
                   NULL,
                   &dwType,
                   (LPBYTE) &lpCapDriverInfo->fDisabled,
                   &dwSize);
        // Convert this thing to a bool
        lpCapDriverInfo->fDisabled = (lpCapDriverInfo->fDisabled == '1');

        // DriverDescription
        dwSize = sizeof (lpCapDriverInfo->szDriverDescription) / sizeof (TCHAR);
        RegQueryValueEx(
                   hKeyChild,
                   szRegDescription,
                   NULL,
                   &dwType,
                   (LPBYTE) lpCapDriverInfo->szDriverDescription,
                   &dwSize);

        // DEVNODE
        dwSize = sizeof(DEVNODE);
        RegQueryValueEx(
                   hKeyChild,
                   szRegDevNode,
                   NULL,
                   &dwType,
                   (LPBYTE) &lpCapDriverInfo->dnDevNode,
                   &dwSize);

        // DriverName
        dwSize = sizeof (lpCapDriverInfo->szDriverName) / sizeof (TCHAR);
        RegQueryValueEx(
                   hKeyChild,
                   szRegDriver,
                   NULL,
                   &dwType,
                   (LPBYTE) lpCapDriverInfo->szDriverName,
                   &dwSize);

        // SoftwareKey
        dwSize = sizeof (lpCapDriverInfo->szSoftwareKey) / sizeof (TCHAR);
        RegQueryValueEx(
                   hKeyChild,
                   szRegSoftwareKey,
                   NULL,
                   &dwType,
                   (LPBYTE) lpCapDriverInfo->szSoftwareKey,
                   &dwSize);

        RegCloseKey (hKeyChild);

    } // if the subkey could be opened

    RegCloseKey (hKeyMSVideoRoot);

    return fOK;
}

// Fetches driver info listed in system.ini
// Returns: TRUE if the index was valid, FALSE if no driver at that index

BOOL videoIniGetDriverByIndex (
        DWORD           dwDeviceID,
        LPCAPDRIVERINFO lpCapDriverInfo)
{
    TCHAR szKey[sizeof(szVideo)/sizeof(TCHAR) + 2];
    int w = (int) dwDeviceID;
    BOOL fOK = FALSE;

    // Always start clean since the entry may be recycled
    _fmemset (lpCapDriverInfo, 0, sizeof (CAPDRIVERINFO));

    lstrcpy(szKey, szVideo);    //
    szKey[(sizeof(szVideo)/sizeof(TCHAR)) - 1] = (TCHAR)0;
    if( w > 0 ) {
        szKey[(sizeof(szVideo)/sizeof(TCHAR))] = (TCHAR)0;
        szKey[(sizeof(szVideo)/sizeof(TCHAR))-1] = (TCHAR) TEXT('1' + (w-1) );  // driver ordinal
    }

    // Only get its driver name
    if (GetPrivateProfileString(szDrivers, szKey, szNull,       //
                lpCapDriverInfo->szDriverName,
                sizeof(lpCapDriverInfo->szDriverName)/sizeof(TCHAR),
                szSystemIni)) {

        HKEY hKey = NULL;
        DWORD dwSize, dwType;

        // Get the key if it already exists

        // Get Drivers.Desc from its Drivers32 driver name
        if (ERROR_SUCCESS == RegOpenKey (
                HKEY_LOCAL_MACHINE,
                szDriversDescRegKey,
                &hKey) != ERROR_SUCCESS) {
            // DriverDescription
            dwSize = sizeof (lpCapDriverInfo->szDriverDescription) / sizeof (TCHAR);
            // [drivers.desc]
            //   DriverName = DriverDescription
            dwType = REG_SZ;
            RegQueryValueEx(
                   hKey,
                   lpCapDriverInfo->szDriverName,
                   NULL,
                   &dwType,
                   (LPBYTE) lpCapDriverInfo->szDriverDescription,
                   &dwSize);

            RegCloseKey (hKey);
        }  else {
            dprintf("videoIniGetDriverByIndex: RegOpenKey of Drivers.Desc failed !!\n");
        }





        // Found an entry at the requested index
        // The description and version info will be inserted as
        // requested by the client app.

        lpCapDriverInfo-> fOnlySystemIni = TRUE;
        lpCapDriverInfo-> dwMsVideoIndex = w;

        fOK = TRUE;
    }

    return fOK;
}

DWORD WINAPI videoFreeDriverList (void)

{
    int i;

    EnterCriticalSection (&g_CritSec);

    dprintf("+ videoFreeDriverList\n");

    // Free the driver list
    for (i = 0; i < MAXVIDEODRIVERS; i++) {
        if (aCapDriverList[i])
            GlobalFreePtr (aCapDriverList[i]);
        aCapDriverList[i] = NULL;
    }

    wTotalVideoDevs = 0;

    dprintf("- videoFreeDriverList\n");

    LeaveCriticalSection (&g_CritSec);

    return DV_ERR_OK;
}

// This function may be called a number of times to create the
// current driver array.  Since Capscrn assumes it can throw a
// driver into system.ini on the fly and have it immediately accessible,
// this routine is called on videoGetNumDevs() and when AVICapx.dll
// tries to get the driver description and version.
//
// Drivers in the registry will be the first entries in the list.
//
// If a driver is listed in the registry AND in system.ini AND
// the full path to the drivers match, the system.ini entry will NOT
// be in the resulting list.

// The variable wTotalVideoDevs is set as a byproduct of this function.

// Returns DV_ERR_OK on success, even if no drivers are installed.
//
DWORD videoCreateDriverList (void)

{
    int i, j, k;

    EnterCriticalSection (&g_CritSec);

    dprintf("+ videoCreateDriverList\n");
    // Delete the existing list
    videoFreeDriverList ();

    // Allocate an array of pointers to all possible capture drivers
    for (i = 0; i < MAXVIDEODRIVERS; i++) {
        aCapDriverList[i] = (LPCAPDRIVERINFO) GlobalAllocPtr (
                GMEM_MOVEABLE |
                GMEM_SHARE |
                GMEM_ZEROINIT,
                sizeof (CAPDRIVERINFO));
        if (aCapDriverList[i] == NULL) {
            videoFreeDriverList ();
            LeaveCriticalSection (&g_CritSec);
            return DV_ERR_NOMEM;
        }
    }

//actually the next #ifdef...#endif block is a comment; we should not count the vfwwdm which is the only one found in this reg section
#ifdef COMMENT_COUNT_VFW
    // Walk the list of Registry drivers and get each entry
    // Get VFW drivers from MediaResource\MsVideo
    for (i = 0; i < MAXVIDEODRIVERS; i++) {
        if (videoRegGetDriverByIndex (
                    (DWORD) i, aCapDriverList[wTotalVideoDevs])) {

            dprintf("MediaResource: idx %d, DriverName %x, Desc %x\n", wTotalVideoDevs, aCapDriverList[wTotalVideoDevs]->szDriverName, aCapDriverList[wTotalVideoDevs]->szDriverDescription);

            wTotalVideoDevs++;  //
        }
        else
            break;
    }

    if (wTotalVideoDevs == MAXVIDEODRIVERS)
        goto AllDone;
#endif
    // Now add the entries listed in system.ini, [Drivers#2] section, (msvideo[0-9] = driver.drv)
    // to the driver array, ONLY if the entry doesn't exactly match
    // an existing registry entry.

    for (j = 0; j < MAXVIDEODRIVERS; j++) {
        // Get driver name such as *.dll
        if (videoIniGetDriverByIndex ((DWORD) j,
                        aCapDriverList[wTotalVideoDevs])) {

            // Found an entry, now see if it is a duplicate of an existing
            // registry entry

            for (k = 0; k < (int) wTotalVideoDevs; k++) {

                if (lstrcmpi (aCapDriverList[k]->szDriverName,
                    aCapDriverList[wTotalVideoDevs]->szDriverName) == 0) {

                    // Found an exact match, so skip it!
                    goto SkipThisEntry;
                }
            }

            if (wTotalVideoDevs >= MAXVIDEODRIVERS - 1)
                break;

            dprintf("Drivers32: idx %d, DriverName %s ( %x )\n", wTotalVideoDevs, aCapDriverList[wTotalVideoDevs]->szDriverName, aCapDriverList[wTotalVideoDevs]->szDriverName);

            wTotalVideoDevs++;

SkipThisEntry:
            ;
        } // If sytem.ini entry was found
    } // For all system.ini possibilities

#ifdef COMMENT_COUNT_VFW        //see explanation above
AllDone:
#endif

    // Decrement wTotalVideoDevs for any entries which are marked as disabled
    // And remove disabled entries from the list
    for (i = 0; i < MAXVIDEODRIVERS; ) {

        if (aCapDriverList[i] && aCapDriverList[i]->fDisabled) {

            GlobalFreePtr (aCapDriverList[i]);

            // Shift down the remaining drivers
            for (j = i; j < MAXVIDEODRIVERS - 1; j++) {
                aCapDriverList[j] = aCapDriverList[j + 1];
            }
            aCapDriverList[MAXVIDEODRIVERS - 1] = NULL;

            wTotalVideoDevs--;
        }
        else
            i++;
    }

    // Free the unused pointers
    for (i = wTotalVideoDevs; i < MAXVIDEODRIVERS; i++) {
        if (aCapDriverList[i])
            GlobalFreePtr (aCapDriverList[i]);
        aCapDriverList[i] = NULL;
    }

    // Put PnP drivers first in the list
    // These are the only entries that have a DevNode
    for (k = i = 0; i < (int) wTotalVideoDevs; i++) {
        if (aCapDriverList[i]-> dnDevNode) {
            LPCAPDRIVERINFO lpCDTemp;

            if (k != i) {
                // Swap the entries
                lpCDTemp = aCapDriverList[k];
                aCapDriverList[k] = aCapDriverList[i];
                aCapDriverList[i] = lpCDTemp;
            }
            k++;   // Index of first non-PnP driver
        }
    }

    dbg_Dump_aCapDriverList("videoCreateDriverList");
    dprintf("- videoCreateDriverList\n");

    LeaveCriticalSection (&g_CritSec);
    return DV_ERR_OK;
}





// ----------------------------------------------------------------------
//
// To clean up when a WOW app exits, we need to maintain a list of
// open devices. A list of HANDLEINFO structs is hung off g_pHandles.
// An item is added to the head of this list in videoOpen, and removed
// in videoClose. When a WOW app exits, winmm will call our WOWAppExit
// function: for each entry in the list that is owned by the exiting thread,
// we call videoClose to close the device and remove the handle entry.
//

// one of these per open handle
typedef struct _HANDLEINFO {
    HVIDEO hv;
    HANDLE hThread;
    struct _HANDLEINFO * pNext;
} HANDLEINFO, * PHANDLEINFO;

// head of global list of open handles
PHANDLEINFO g_pHandles;

// critical section that protects global list
CRITICAL_SECTION csHandles;

// init list and critsec
BOOL
NTvideoInitHandleList()
{
    g_pHandles = NULL;

    __try
    {
        InitializeCriticalSection(&csHandles);
    }
    __except (EXCEPTION_EXECUTE_HANDLER)
    {
        return FALSE;
    }
    return TRUE;
}

// finished with critsec list
void
NTvideoDeleteHandleList()
{
    // don't need critical section as no-one else can be using
    // it now (we are about to delete the critsec)

    // empty everything out of the list
    while (g_pHandles) {
        videoClose(g_pHandles->hv);
    }

    DeleteCriticalSection(&csHandles);
}



// add a handle to the list
void
NTvideoAddHandle(HVIDEO hv)
{
    PHANDLEINFO pinfo = HeapAlloc(GetProcessHeap(), 0, sizeof(HANDLEINFO));

    if (!pinfo) {
        // couldn't allocate the memory - best thing to do is
        // forget it - nothing bad will happen except that we
        // might possibly fail to clean up if this is a wow app and
        // it exits without closing the capture device.
        return;
    }

    pinfo->hv = hv;
    pinfo->hThread = GetCurrentTask();

    EnterCriticalSection(&csHandles);

    pinfo->pNext = g_pHandles;
    g_pHandles = pinfo;

    LeaveCriticalSection(&csHandles);
}

// delete an entry from the handle list given the HVIDEO.
// caller must close the HVIDEO
// should be called before closing (in case the HVIDEO is reassigned after
// closing and before removing from the list
void
NTvideoDelete(HVIDEO hv)
{
    PHANDLEINFO * ppNext;
    PHANDLEINFO pinfo;

    EnterCriticalSection(&csHandles);

    ppNext = &g_pHandles;
    while (*ppNext) {
        if ((*ppNext)->hv == hv) {
            pinfo = *ppNext;
            *ppNext = pinfo->pNext;
            HeapFree(GetProcessHeap(), 0, pinfo);
            break;

        } else {
            ppNext = &(*ppNext)->pNext;
        }
    }

    LeaveCriticalSection(&csHandles);
}

// close any handles open by this task
void
AppCleanup(HANDLE hTask)
{
    PHANDLEINFO pinfo;

    EnterCriticalSection(&csHandles);

    pinfo = g_pHandles;
    while (pinfo) {

        if (pinfo->hThread == hTask) {

            // get the next pointer before videoClose deletes the entry
            HVIDEO hv = pinfo->hv;
            pinfo = pinfo->pNext;

            videoClose(hv);
        } else {
            pinfo = pinfo->pNext;
        }
    }

    LeaveCriticalSection(&csHandles);
}


// ----------------------------------------------------------------------




/*****************************************************************************
 * @doc INTERNAL  VIDEO validation code for VIDEOHDRs
 ****************************************************************************/

#define IsVideoHeaderPrepared(hVideo, lpwh)      ((lpwh)->dwFlags &  VHDR_PREPARED)
#define MarkVideoHeaderPrepared(hVideo, lpwh)    ((lpwh)->dwFlags |= VHDR_PREPARED)
#define MarkVideoHeaderUnprepared(hVideo, lpwh)  ((lpwh)->dwFlags &=~VHDR_PREPARED)



/*****************************************************************************
 * @doc EXTERNAL  VIDEO
 *
 * @func DWORD | videoMessage | This function sends messages to a
 *   video device channel.
 *
 * @parm HVIDEO | hVideo | Specifies the handle to the video device channel.
 *
 * @parm UINT | wMsg | Specifies the message to send.
 *
 * @parm DWORD | dwP1 | Specifies the first parameter for the message.
 *
 * @parm DWORD | dwP2 | Specifies the second parameter for the message.
 *
 * @rdesc Returns the message specific value returned from the driver.
 *
 * @comm This function is used for configuration messages such as
 *      <m DVM_SRC_RECT> and <m DVM_DST_RECT>, and
 *      device specific messages.
 *
 * @xref <f videoConfigure>
 *
 ****************************************************************************/
LONG WINAPI NTvideoMessage(HVIDEO hVideo, UINT msg, LPARAM dwP1, LPARAM dwP2)
{
    if (!hVideo)
        return DV_ERR_INVALHANDLE;

    return SendDriverMessage ((HDRVR)hVideo, msg, dwP1, dwP2);
}

/*****************************************************************************
 * @doc EXTERNAL  VIDEO
 *
 * @api DWORD | videoGetNumDevs | This function returns the number of MSVIDEO
 *   devices installed.
 *
 * @rdesc Returns the number of MSVIDEO devices listed in the
 *  [drivers] (or [drivers32] for NT) section of the SYSTEM.INI file.
 *
 * @comm Because the indexes of the MSVIDEO devices in the SYSTEM.INI
 *       file can be non-contiguous, applications should not assume
 *       the indexes range between zero and the number of devices minus
 *       one.
 *
 * @xref <f videoOpen>
 ****************************************************************************/
DWORD WINAPI videoGetNumDevs(BOOL bFreeList)
{
    DWORD dwNumDevs = 0;

    if(DV_ERR_OK == videoCreateDriverList ()) {

       dwNumDevs = wTotalVideoDevs;  // Save it before (possibly) reseting to 0 in videoFreeDriverList.
       if(bFreeList)
                videoFreeDriverList ();
    }

    return dwNumDevs;
}

/*****************************************************************************
 * @doc EXTERNAL VIDEO
 *
 * @func DWORD | videoGetChannelCaps | This function retrieves a
 *   description of the capabilities of a channel.
 *
 * @parm HVIDEO | hVideo | Specifies a handle to the video device channel.
 *
 * @parm LPCHANNEL_CAPS | lpChannelCaps | Specifies a far pointer to a
 *      <t CHANNEL_CAPS> structure.
 *
 * @parm DWORD | dwSize | Specifies the size, in bytes, of the
 *       <t CHANNEL_CAPS> structure.
 *
 * @rdesc Returns zero if the function is successful. Otherwise, it returns
 *   an error number. The following errors are defined:
 *   @flag DV_ERR_INVALHANDLE | Specified device handle is invalid.
 *   @flag DV_ERR_UNSUPPORTED | Function is not supported.
 *
 * @comm The <t CHANNEL_CAPS> structure returns the capability
 *   information. For example, capability information might
 *   include whether or not the channel can crop and scale images,
 *   or show overlay.
 ****************************************************************************/
DWORD WINAPI NTvideoGetChannelCaps(HVIDEO hVideo, LPCHANNEL_CAPS lpChannelCaps,
                        DWORD dwSize)
{
    if (!hVideo)
        return DV_ERR_INVALHANDLE;

    if (IsBadWritePtr (lpChannelCaps, sizeof (CHANNEL_CAPS)))
        return DV_ERR_PARAM1;

    // _fmemset (lpChannelCaps, 0, sizeof (CHANNEL_CAPS));

    lpChannelCaps->dwFlags = 0;
    lpChannelCaps->dwSrcRectXMod = 0;
    lpChannelCaps->dwSrcRectYMod = 0;
    lpChannelCaps->dwSrcRectWidthMod = 0;
    lpChannelCaps->dwSrcRectHeightMod = 0;
    lpChannelCaps->dwDstRectXMod = 0;
    lpChannelCaps->dwDstRectYMod = 0;
    lpChannelCaps->dwDstRectWidthMod = 0;
    lpChannelCaps->dwDstRectHeightMod = 0;

    return (DWORD)NTvideoMessage(hVideo, DVM_GET_CHANNEL_CAPS, (LPARAM)lpChannelCaps,
                dwSize);
}


/*****************************************************************************
 * @doc EXTERNAL  VIDEO
 *
 * @api DWORD | videoOpen | This function opens a channel on the
 *  specified video device.
 *
 * @parm LPHVIDEO | lphvideo | Specifies a far pointer to a buffer
 *   used to return an <t HVIDEO> handle. The video capture driver
 *   uses this location to return
 *   a handle that uniquely identifies the opened video device channel.
 *   Use the returned handle to identify the device channel when
 *   calling other video functions.
 *
 * @parm DWORD | dwDeviceID | Identifies the video device to open.
 *      The value of <p dwDeviceID> varies from zero to one less
 *      than the number of video capture devices installed in the system.
 *
 * @parm DWORD | dwFlags | Specifies flags for opening the device.
 *      The following flags are defined:
 *
 *   @flag VIDEO_EXTERNALIN| Specifies the channel is opened
 *           for external input. Typically, external input channels
 *      capture images into a frame buffer.
 *
 *   @flag VIDEO_EXTERNALOUT| Specifies the channel is opened
 *      for external output. Typically, external output channels
 *      display images stored in a frame buffer on an auxilary monitor
 *      or overlay.
 *
 *   @flag VIDEO_IN| Specifies the channel is opened
 *      for video input. Video input channels transfer images
 *      from a frame buffer to system memory buffers.
 *
 *   @flag VIDEO_OUT| Specifies the channel is opened
 *      for video output. Video output channels transfer images
 *      from system memory buffers to a frame buffer.
 *
 * @rdesc Returns zero if the function was successful. Otherwise, it returns
 *   an error number. The following errors are defined:
 *   @flag DV_ERR_BADDEVICEID | Indicates the specified device ID is out of range.
 *   @flag DV_ERR_ALLOCATED | Indicates the specified resource is already allocated.
 *   @flag DV_ERR_NOMEM | Indicates the device is unable to allocate or lock memory.
 *
 * @comm
 *   At a minimum, all capture drivers support a VIDEO_EXTERNALIN
 *   and a VIDEO_IN channel.
 *   Use <f videoGetNumDevs> to determine the number of video
 *   devices present in the system.
 *
 * @xref <f videoClose>
 ****************************************************************************/
DWORD WINAPI NTvideoOpen (LPHVIDEO lphVideo, DWORD dwDeviceID, DWORD dwFlags)
{
    WCHAR szKey[MAX_PATH];
    WCHAR szbuf[MAX_PATH];
    UINT w;
    VIDEO_OPEN_PARMS vop;       // Same as IC_OPEN struct!!!
    DWORD dwVersion = VIDEOAPIVERSION;
    DWORD dwErr=DV_ERR_OK;
    DWORD dwNumDevs = 0;

    int i;


    dprintf("*************************************** NTvideoOpen ******************************************\n");
    dprintf("+ NTvideoOpen\n");

    if (IsBadWritePtr ((LPVOID) lphVideo, sizeof (HVIDEO)) )
        return DV_ERR_PARAM1;

    EnterCriticalSection (&g_CritSec);

    vop.dwSize = sizeof (VIDEO_OPEN_PARMS);
    vop.fccType = OPEN_TYPE_VCAP;       // "vcap"
    vop.fccComp = 0L;
    vop.dwVersion = VIDEOAPIVERSION;
    vop.dwFlags = dwFlags;      // In, Out, External In, External Out
    vop.dwError = DV_ERR_OK;

    //w = (UINT)dwDeviceID;
    *lphVideo = NULL;

    dwNumDevs = videoGetNumDevs(TRUE);  // TRUE = free the list after counting

    // No drivers installed
    if (dwNumDevs == 0)
    {
        dwErr = DV_ERR_BADINSTALL;
        goto MyExit;
    }

    if (dwDeviceID >= MAXVIDEODRIVERS)
    {
        dwErr = DV_ERR_BADDEVICEID;
        goto MyExit;
    }

    dwErr = videoCreateDriverList ();
    if(DV_ERR_OK != dwErr)
    {
        goto My_Err1;
    }

    for (i = 0; i < (int) wTotalVideoDevs; i++)
    {
        if (dwDeviceID == aCapDriverList[i]->dwMsVideoIndex)
        {
            w = i;
            break;
        }
    }

    //if(w < dwNumDevs)
    if(w < wTotalVideoDevs)
    {
        MultiByteToWideChar(GetACP(), MB_PRECOMPOSED, aCapDriverList[w]->szDriverName, -1, szKey, MAX_PATH);
        MultiByteToWideChar(GetACP(), MB_PRECOMPOSED, aCapDriverList[w]->szDriverName, -1, szbuf, MAX_PATH);

        dprintf("* NTvideoOpen: OpenDriver(%s,%s,...)\n", aCapDriverList[w]->szDriverName, szDrivers);
        //*lphVideo = (HVIDEO)OpenDriver((LPCWSTR)szKey, (LPCWSTR)szDrivers, (LPARAM) (LPVOID) &vop);
        *lphVideo = (HVIDEO)OpenDriver((LPCWSTR)szKey, NULL, (LPARAM) (LPVOID) &vop);
        dprintf("* NTvideoOpen: OpenDriver returned %x\n", *lphVideo);
        if( ! *lphVideo ) {
            if (vop.dwError)    // if driver returned an error code...
            {
                dprintf("? NTvideoOpen: vop.dwError = 0x%08lx\n", vop.dwError);
                dwErr = vop.dwError;
            }
            else {
#ifdef WIN32
                if (GetFileAttributes(aCapDriverList[w]->szDriverName) == (DWORD) -1)
#else
                OFSTRUCT of;

                if (OpenFile (szbuf, &of, OF_EXIST) == HFILE_ERROR)
#endif
                {
                    dprintf("? NTvideoOpen: DV_ERR_BADINSTALL: %s\n", aCapDriverList[w]->szDriverName);
                    dwErr = DV_ERR_BADINSTALL;
                }
                else
                {
                    dprintf("? NTvideoOpen: DV_ERR_NOTDETECTED: %s\n", aCapDriverList[w]->szDriverName);
                    dwErr = DV_ERR_NOTDETECTED;
                }
            }
            goto My_Err1;
        }
        // here is the only SUCCESSFUL way to get out of this 'if' ...
    } else {
        dwErr = DV_ERR_BADINSTALL;
        goto My_Err1;
    }

    NTvideoAddHandle(*lphVideo);

My_Err1:
    videoFreeDriverList ();

MyExit:
    dprintf("- NTvideoOpen\n");

    LeaveCriticalSection (&g_CritSec);
    return dwErr;

}

/*****************************************************************************
 * @doc EXTERNAL  VIDEO
 *
 * @api DWORD | videoClose | This function closes the specified video
 *   device channel.
 *
 * @parm HVIDEO | hVideo | Specifies a handle to the video device channel.
 *  If this function is successful, the handle is invalid
 *   after this call.
 *
 * @rdesc Returns zero if the function was successful. Otherwise, it returns
 *   an error number. The following errors are defined:
 *   @flag DV_ERR_INVALHANDLE | Specified device handle is invalid.
 *   @flag DV_ERR_NONSPECIFIC | The driver failed to close the channel.
 *
 * @comm If buffers have been sent with <f videoStreamAddBuffer> and
 *   they haven't been returned to the application,
 *   the close operation fails. You can use <f videoStreamReset> to mark all
 *   pending buffers as done.
 *
 * @xref <f videoOpen> <f videoStreamInit> <f videoStreamFini> <f videoStreamReset>
 ****************************************************************************/
DWORD WINAPI NTvideoClose (HVIDEO hVideo)
{
    DWORD dwErr=DV_ERR_OK;

    dprintf("+ NTvideoClose closing handle %x\n" , (DWORD)hVideo);

    if (!hVideo) {
        dwErr = DV_ERR_INVALHANDLE;
        goto MyExit;
    }

    NTvideoDelete(hVideo);

    dwErr = CloseDriver((HDRVR)hVideo, 0L, 0L ) ? DV_ERR_OK : DV_ERR_NONSPECIFIC;
MyExit:
    dprintf("- NTvideoClose returning %x\n" , dwErr);

    return (dwErr);
}

/*****************************************************************************
 * @doc EXTERNAL  VIDEO
 *
 * @api DWORD | videoConfigure | This function sets or retrieves
 *      the options for a configurable driver.
 *
 * @parm HVIDEO | hVideo | Specifies a handle to the video device channel.
 *
 * @parm UINT | msg  | Specifies the option to set or retrieve. The
 *       following options are defined:
 *
 *   @flag DVM_PALETTE | Indicates a palette is being sent to the driver
 *         or retrieved from the driver.
 *
 *   @flag DVM_PALETTERGB555 | Indicates an RGB555 palette is being
 *         sent to the driver.
 *
 *   @flag DVM_FORMAT | Indicates format information is being sent to
 *         the driver or retrieved from the driver.
 *
 * @parm DWORD | dwFlags | Specifies flags for configuring or
 *   interrogating the device driver. The following flags are defined:
 *
 *   @flag VIDEO_CONFIGURE_SET | Indicates values are being sent to the driver.
 *
 *   @flag VIDEO_CONFIGURE_GET | Indicates values are being obtained from the driver.
 *
 *   @flag VIDEO_CONFIGURE_QUERY | Determines if the
 *      driver supports the option specified by <p msg>. This flag
 *      should be combined with either the VIDEO_CONFIGURE_SET or
 *      VIDEO_CONFIGURE_GET flag. If this flag is
 *      set, the <p lpData1>, <p dwSize1>, <p lpData2>, and <p dwSize2>
 *      parameters are ignored.
 *
 *   @flag VIDEO_CONFIGURE_QUERYSIZE | Returns the size, in bytes,
 *      of the configuration option in <p lpdwReturn>. This flag is only valid if
 *      the VIDEO_CONFIGURE_GET flag is also set.
 *
 *   @flag VIDEO_CONFIGURE_CURRENT | Requests the current value.
 *      This flag is valid only if  the VIDEO_CONFIGURE_GET flag is also set.
 *   @flag VIDEO_CONFIGURE_NOMINAL | Requests the nominal value.
 *      This flag is valid only if  the VIDEO_CONFIGURE_GET flag is also set.
 *   @flag VIDEO_CONFIGURE_MIN | Requests the minimum value.
 *      This flag is valid only if  the VIDEO_CONFIGURE_GET flag is also set.
 *   @flag VIDEO_CONFIGURE_MAX | Get the maximum value.
 *      This flag is valid only if  the VIDEO_CONFIGURE_GET flag is also set.
 *
 * @parm LPDWORD | lpdwReturn  | Points to a DWORD used for returning information
 *      from the driver.  If
 *      the VIDEO_CONFIGURE_QUERYSIZE flag is set, <p lpdwReturn> is
 *      filled with the size of the configuration option.
 *
 * @parm LPVOID | lpData1  |Specifies a pointer to message specific data.
 *
 * @parm DWORD | dwSize1  | Specifies the size, in bytes, of the <p lpData1>
 *       buffer.
 *
 * @parm LPVOID | lpData2  | Specifies a pointer to message specific data.
 *
 * @parm DWORD | dwSize2  | Specifies the size, in bytes, of the <p lpData2>
 *       buffer.
 *
 * @rdesc Returns zero if the function was successful. Otherwise, it returns
 *   an error number. The following errors are defined:
 *   @flag DV_ERR_INVALHANDLE | Specified device handle is invalid.
 *   @flag DV_ERR_NOTSUPPORTED | Function is not supported.
 *
 * @xref <f videoOpen> <f videoMessage>
 *
 ****************************************************************************/
DWORD WINAPI NTvideoConfigure (HVIDEO hVideo, UINT msg, DWORD dwFlags,
                LPDWORD lpdwReturn, LPVOID lpData1, DWORD dwSize1,
                LPVOID lpData2, DWORD dwSize2)
{
    VIDEOCONFIGPARMS    vcp;

    if (!hVideo)
        return DV_ERR_INVALHANDLE;

    if (lpData1)
        if (IsBadHugeReadPtr (lpData1, dwSize1))
            return DV_ERR_CONFIG1;

    if (lpData2)
        if (IsBadHugeReadPtr (lpData2, dwSize2))
            return DV_ERR_CONFIG2;

    if (dwFlags & VIDEO_CONFIGURE_QUERYSIZE) {
        if (!lpdwReturn)
            return DV_ERR_NONSPECIFIC;
        if (IsBadWritePtr (lpdwReturn, sizeof (*lpdwReturn)) )
            return DV_ERR_NONSPECIFIC;
    }

    vcp.lpdwReturn = lpdwReturn;
    vcp.lpData1 = lpData1;
    vcp.dwSize1 = dwSize1;
    vcp.lpData2 = lpData2;
    vcp.dwSize2 = dwSize2;

    return (DWORD)NTvideoMessage(hVideo, msg, dwFlags,
            (LPARAM)(LPVIDEOCONFIGPARMS)&vcp );
}

/*****************************************************************************
 * @doc EXTERNAL  VIDEO
 *
 * @api DWORD | videoDialog | This function displays a channel-specific
 *     dialog box used to set configuration parameters.
 *
 * @parm HVIDEO | hVideo | Specifies a handle to the video device channel.
 *
 * @parm HWND | hWndParent | Specifies the parent window handle.
 *
 * @parm DWORD | dwFlags | Specifies flags for the dialog box. The
 *   following flag is defined:
 *   @flag VIDEO_DLG_QUERY | If this flag is set, the driver immediately
 *           returns zero if it supplies a dialog box for the channel,
 *           or DV_ERR_NOTSUPPORTED if it does not.
 *
 * @rdesc Returns zero if the function was successful. Otherwise, it returns
 *   an error number. The following errors are defined:
 *   @flag DV_ERR_INVALHANDLE | Specified device handle is invalid.
 *   @flag DV_ERR_NOTSUPPORTED | Function is not supported.
 *
 * @comm Typically, each dialog box displayed by this
 *      function lets the user select options appropriate for the channel.
 *      For example, a VIDEO_IN channel dialog box lets the user select
 *      the image dimensions and bit depth.
 *
 * @xref <f videoOpen> <f videoConfigureStorage>
 ****************************************************************************/
DWORD WINAPI NTvideoDialog (HVIDEO hVideo, HWND hWndParent, DWORD dwFlags)
{
    if (!hVideo)
        return DV_ERR_INVALHANDLE;

    if ((!hWndParent) || (!IsWindow (hWndParent)) )
        return DV_ERR_INVALHANDLE;

    return (DWORD)NTvideoMessage(hVideo, DVM_DIALOG, (LPARAM)hWndParent, dwFlags);
}

//////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////


/*****************************************************************************
 * @doc INTERNAL  VIDEO
 *
 * @api DWORD | videoPrepareHeader | This function prepares the
 *      header and data
 *      by performing a <f GlobalPageLock>.
 *
 * @rdesc Returns zero if the function was successful. Otherwise, it
 *   specifies an error number.
 ****************************************************************************/
DWORD WINAPI NTvideoPrepareHeader(LPVIDEOHDR lpVideoHdr, DWORD dwSize)
{
    if (!HugePageLock(lpVideoHdr, (DWORD_PTR)sizeof(VIDEOHDR)))
        return DV_ERR_NOMEM;

    if (!HugePageLock(lpVideoHdr->lpData, lpVideoHdr->dwBufferLength)) {
        HugePageUnlock(lpVideoHdr, (DWORD_PTR)sizeof(VIDEOHDR));
        return DV_ERR_NOMEM;
    }

    lpVideoHdr->dwFlags |= VHDR_PREPARED;

    return DV_ERR_OK;
}

/*****************************************************************************
 * @doc INTERNAL  VIDEO
 *
 * @api DWORD | videoUnprepareHeader | This function unprepares the header and
 *   data if the driver returns DV_ERR_NOTSUPPORTED.
 *
 * @rdesc Currently always returns DV_ERR_OK.
 ****************************************************************************/
DWORD WINAPI NTvideoUnprepareHeader(LPVIDEOHDR lpVideoHdr, DWORD dwSize)
{

    HugePageUnlock(lpVideoHdr->lpData, lpVideoHdr->dwBufferLength);
    HugePageUnlock(lpVideoHdr, (DWORD_PTR)sizeof(VIDEOHDR));

    lpVideoHdr->dwFlags &= ~VHDR_PREPARED;

    return DV_ERR_OK;
}

//////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////

/*****************************************************************************
 * @doc EXTERNAL  VIDEO
 *
 * @api DWORD | videoStreamPrepareHeader | This function prepares a buffer
 *   for video streaming.
 *
 * @parm HVIDEO | hVideo | Specifies a handle to the video
 *   device channel.
 *
 * @parm LPVIDEOHDR | lpvideoHdr | Specifies a pointer to a
 *   <t VIDEOHDR> structure identifying the buffer to be prepared.
 *
 * @parm DWORD | dwSize | Specifies the size of the <t VIDEOHDR> structure in bytes.
 *
 * @rdesc Returns zero if the function was successful. Otherwise, it returns
 *   an error number. The following errors are defined:
 *   @flag DV_ERR_INVALHANDLE | Indicates the specified device handle is invalid.
 *   @flag DV_ERR_NOMEM | Indicates the device is unable to allocate or lock memory.
 *
 * @comm Use this function after <f videoStreamInit> or
 *   after <f videoStreamReset> to prepare the data buffers
 *   for streaming data.
 *
 *   The <t VIDEOHDR> data structure and the data block pointed to by its
 *   <e VIDEOHDR.lpData> member must be allocated with <f GlobalAlloc> using the
 *   GMEM_MOVEABLE and GMEM_SHARE flags, and locked with <f GlobalLock>.
 *   Preparing a header that has already been prepared will have no effect
 *   and the function will return zero. Typically, this function is used
 *   to ensure that the buffer will be available for use at interrupt time.
 *
 * @xref <f videoStreamUnprepareHeader>
 ****************************************************************************/
DWORD WINAPI NTvideoStreamPrepareHeader(HVIDEO hVideo,
                LPVIDEOHDR lpvideoHdr, DWORD dwSize)
{
    DWORD         wRet;

    if (!hVideo)
        return DV_ERR_INVALHANDLE;

    if (IsBadWritePtr (lpvideoHdr, sizeof (VIDEOHDR)) )
        return DV_ERR_PARAM1;

    if (IsVideoHeaderPrepared(HVIDEO, lpvideoHdr))
    {
        DebugErr(DBF_WARNING,"videoStreamPrepareHeader: header is already prepared.");
        return DV_ERR_OK;
    }

    lpvideoHdr->dwFlags = 0;

    wRet = (DWORD)NTvideoMessage((HVIDEO)hVideo, DVM_STREAM_PREPAREHEADER,
            (LPARAM)lpvideoHdr, dwSize);

    if (wRet == DV_ERR_NOTSUPPORTED)
        wRet = NTvideoPrepareHeader(lpvideoHdr, dwSize);

    if (wRet == DV_ERR_OK)
        MarkVideoHeaderPrepared(hVideo, lpvideoHdr);

    return wRet;
}

/*****************************************************************************
 * @doc EXTERNAL  VIDEO
 *
 * @api DWORD | videoStreamUnprepareHeader | This function clears the
 *  preparation performed by <f videoStreamPrepareHeader>.
 *
 * @parm HVIDEO | hVideo | Specifies a handle to the video
 *   device channel.
 *
 * @parm LPVIDEOHDR | lpvideoHdr |  Specifies a pointer to a <t VIDEOHDR>
 *   structure identifying the data buffer to be unprepared.
 *
 * @parm DWORD | dwSize | Specifies the size of the <t VIDEOHDR> structure in bytes.
 *
 * @rdesc Returns zero if the function was successful. Otherwise, it returns
 *   an error number. The following errors are defined:
 *   @flag DV_ERR_INVALHANDLE | Indicates the device handle specified is invalid.
 *   @flag DV_ERR_STILLPLAYING | Indicates the structure identified by <p lpvideoHdr>
 *   is still in the queue.
 *
 * @comm This function is the complementary function to <f videoStreamPrepareHeader>.
 *   You must call this function before freeing the data buffer with <f GlobalFree>.
 *   After passing a buffer to the device driver with <f videoStreamAddBuffer>, you
 *   must wait until the driver is finished with the buffer before calling
 *   <f videoStreamUnprepareHeader>. Unpreparing a buffer that has not been
 *   prepared or has been already unprepared has no effect,
 *   and the function returns zero.
 *
 * @xref <f videoStreamPrepareHeader>
 ****************************************************************************/
DWORD WINAPI NTvideoStreamUnprepareHeader(HVIDEO hVideo, LPVIDEOHDR lpvideoHdr, DWORD dwSize)
{
    DWORD         wRet;

    if (!hVideo)
        return DV_ERR_INVALHANDLE;

    if (IsBadWritePtr (lpvideoHdr, sizeof (VIDEOHDR)) )
        return DV_ERR_PARAM1;

    if (lpvideoHdr->dwFlags & VHDR_INQUEUE)
    {
        DebugErr(DBF_WARNING, "videoStreamUnprepareHeader: buffer still in queue.");
        return DV_ERR_STILLPLAYING;
    }

    if (!IsVideoHeaderPrepared(hVideo, lpvideoHdr))
    {
        DebugErr(DBF_WARNING,"videoStreamUnprepareHeader: header is not prepared.");
        return DV_ERR_OK;
    }

    wRet = (DWORD)NTvideoMessage((HVIDEO)hVideo, DVM_STREAM_UNPREPAREHEADER,
            (LPARAM)lpvideoHdr, dwSize);

    if (wRet == DV_ERR_NOTSUPPORTED)
        wRet = NTvideoUnprepareHeader(lpvideoHdr, dwSize);

    if (wRet == DV_ERR_OK)
        MarkVideoHeaderUnprepared(hVideo, lpvideoHdr);

    return wRet;
}

/*****************************************************************************
 * @doc EXTERNAL  VIDEO
 *
 * @api DWORD | videoStreamAddBuffer | This function sends a buffer to a
 *   video-capture device. After the buffer is filled by the device,
 *   the device sends it back to the application.
 *
 * @parm HVIDEO | hVideo | Specifies a handle to the video device channel.
 *
 * @parm LPVIDEOHDR | lpvideoHdr | Specifies a far pointer to a <t VIDEOHDR>
 *   structure that identifies the buffer.
 *
 * @parm DWORD | dwSize | Specifies the size of the <t VIDEOHDR> structure in bytes.
 *
 * @rdesc Returns zero if the function was successful. Otherwise, it returns
 *   an error number. The following errors are defined:
 *   @flag DV_ERR_INVALHANDLE | Indicates the device handle specified is invalid.
 *   @flag DV_ERR_UNPREPARED | Indicates the <p lpvideoHdr> structure hasn't been prepared.
 *   @flag DV_ERR_STILLPLAYING | Indicates a buffer is still in the queue.
 *   @flag DV_ERR_PARAM1 | The <p lpvideoHdr> parameter is invalid or
 *       the <e VIDEOHDR.dwBufferLength> member of the <t VIDEOHDR>
 *       structure is not set to the proper value.
 *
 * @comm The data buffer must be prepared with <f videoStreamPrepareHeader>
 *   before it is passed to <f videoStreamAddBuffer>. The <t VIDEOHDR> data
 *   structure and the data buffer referenced by its <e VIDEOHDR.lpData>
 *   member must be allocated with <f GlobalAlloc> using the GMEM_MOVEABLE
 *   and GMEM_SHARE flags, and locked with <f GlobalLock>. Set the
 *   <e VIDEOHDR.dwBufferLength> member to the size of the header.
 *
 * @xref <f videoStreamPrepareHeader>
 ****************************************************************************/
DWORD WINAPI NTvideoStreamAddBuffer(HVIDEO hVideo, LPVIDEOHDR lpvideoHdr, DWORD dwSize)
{
    if (!hVideo)
        return DV_ERR_INVALHANDLE;

    if (IsBadWritePtr (lpvideoHdr, sizeof (VIDEOHDR)) )
        return DV_ERR_PARAM1;

    if (!IsVideoHeaderPrepared(hVideo, lpvideoHdr))
    {
        DebugErr(DBF_WARNING, "videoStreamAddBuffer: buffer not prepared.");
        return DV_ERR_UNPREPARED;
    }

    if (lpvideoHdr->dwFlags & VHDR_INQUEUE)
    {
        DebugErr(DBF_WARNING, "videoStreamAddBuffer: buffer already in queue.");
        return DV_ERR_STILLPLAYING;
    }

    return (DWORD)NTvideoMessage((HVIDEO)hVideo, DVM_STREAM_ADDBUFFER, (LPARAM)lpvideoHdr, dwSize);
}



/*****************************************************************************
 * @doc EXTERNAL  VIDEO
 *
 * @api DWORD | videoStreamStop | This function stops streaming on a video channel.
 *
 * @parm HVIDEO | hVideo | Specifies a handle to the video
 *   device channel.
 *
 * @rdesc Returns zero if the function was successful. Otherwise, it returns
 *   an error number. The following error is defined:
 *   @flag DV_ERR_INVALHANDLE | Indicates the specified device handle is invalid.
 *
 *   @flag DV_ERR_NOTSUPPORTED | Indicates the device does not support this
 *         function.
 * @comm If there are any buffers in the queue, the current buffer will be
 *   marked as done (the <e VIDEOHDR.dwBytesRecorded> member in
 *   the <t VIDEOHDR> header will contain the actual length of data), but any
 *   empty buffers in the queue will remain there. Calling this
 *   function when the channel is not started has no effect, and the
 *   function returns zero.
 *
 * @xref <f videoStreamStart> <f videoStreamReset>
 ****************************************************************************/
DWORD WINAPI NTvideoStreamStop(HVIDEO hVideo)
{
    if (!hVideo)
        return DV_ERR_INVALHANDLE;
    dprintf("* NTvideoStreamStop\n");
    return (DWORD)NTvideoMessage((HVIDEO)hVideo, DVM_STREAM_STOP, 0L, 0L);
}

/*****************************************************************************
 * @doc EXTERNAL  VIDEO
 *
 * @api DWORD | videoStreamReset | This function stops streaming
 *           on the specified video device channel and resets the current position
 *      to zero.  All pending buffers are marked as done and
 *      are returned to the application.
 *
 * @parm HVIDEO | hVideo | Specifies a handle to the video device channel.
 *
 * @rdesc Returns zero if the function was successful. Otherwise, it returns
 *   an error number. The following errors are defined:
 *
 *   @flag DV_ERR_INVALHANDLE | Indicates the device handle specified is invalid.
 *
 *   @flag DV_ERR_NOTSUPPORTED | Indicates the device does not support this
 *         function.
 *
 * @xref <f videoStreamReset> <f videoStreamStop> <f videoStreamAddBuffer> <f videoStreamClose>
/****************************************************************************/
DWORD WINAPI NTvideoStreamReset(HVIDEO hVideo)
{
    if (!hVideo)
        return DV_ERR_INVALHANDLE;
    dprintf("* NTvideoStreamReset\n");
    return (DWORD)NTvideoMessage((HVIDEO)hVideo, DVM_STREAM_RESET, 0L, 0L);
}

// ============================================

/*****************************************************************************
 * @doc EXTERNAL  VIDEO
 *
 * @api DWORD | videoStreamInit | This function initializes a video
 *     device channel for streaming.
 *
 * @parm HVIDEO | hVideo | Specifies a handle to the video device channel.
 *
 * @parm DWORD | dwMicroSecPerFrame | Specifies the number of microseconds
 *     between frames.
 *
 * @parm DWORD_PTR | dwCallback | Specifies the address of a callback
 *   function or a handle to a window called during video
 *   streaming. The callback function or window processes
 *  messages related to the progress of streaming.
 *
 * @parm DWORD_PTR | dwCallbackInstance | Specifies user
 *  instance data passed to the callback function. This parameter is not
 *  used with window callbacks.
 *
 * @parm DWORD | dwFlags | Specifies flags for opening the device channel.
 *   The following flags are defined:
 *   @flag CALLBACK_WINDOW | If this flag is specified, <p dwCallback> is
 *      a window handle.
 *   @flag CALLBACK_FUNCTION | If this flag is specified, <p dwCallback> is
 *      a callback procedure address.
 *
 * @rdesc Returns zero if the function was successful. Otherwise, it returns
 *   an error number. The following errors are defined:
 *   @flag DV_ERR_BADDEVICEID | Indicates the device ID specified in
 *         <p hVideo> is not valid.
 *   @flag DV_ERR_ALLOCATED | Indicates the resource specified is already allocated.
 *   @flag DV_ERR_NOMEM | Indicates the device is unable to allocate or lock memory.
 *
 * @comm If a window or function is chosen to receive callback information, the following
 *   messages are sent to it to indicate the
 *   progress of video input:
 *
 *   <m MM_DRVM_OPEN> is sent at the time of <f videoStreamInit>
 *
 *   <m MM_DRVM_CLOSE> is sent at the time of <f videoStreamFini>
 *
 *   <m MM_DRVM_DATA> is sent when a buffer of image data is available
 *
 *   <m MM_DRVM_ERROR> is sent when an error occurs
 *
 *   Callback functions must reside in a DLL.
 *   You do not have to use <f MakeProcInstance> to get
 *   a procedure-instance address for the callback function.
 *
 * @cb void CALLBACK | videoFunc | <f videoFunc> is a placeholder for an
 *   application-supplied function name. The actual name must be exported by
 *   including it in an EXPORTS statement in the DLL's module-definition file.
 *   This is used only when a callback function is specified in
 *   <f videoStreamInit>.
 *
 * @parm HVIDEO | hVideo | Specifies a handle to the video device channel
 *   associated with the callback.
 *
 * @parm DWORD | wMsg | Specifies the <m MM_DRVM_> messages. Messages indicate
 *       errors and when image data is available. For information on
 *       these messages, see <f videoStreamInit>.
 *
 * @parm DWORD | dwInstance | Specifies the user instance
 *   data specified with <f videoStreamInit>.
 *
 * @parm DWORD | dwParam1 | Specifies a parameter for the message.
 *
 * @parm DWORD | dwParam2 | Specifies a parameter for the message.
 *
 * @comm Because the callback is accessed at interrupt time, it must reside
 *   in a DLL and its code segment must be specified as FIXED in the
 *   module-definition file for the DLL. Any data the callback accesses
 *   must be in a FIXED data segment as well. The callback may not make any
 *   system calls except for <f PostMessage>, <f timeGetSystemTime>,
 *   <f timeGetTime>, <f timeSetEvent>, <f timeKillEvent>,
 *   <f midiOutShortMsg>, <f midiOutLongMsg>, and <f OutputDebugStr>.
 *
 * @xref <f videoOpen> <f videoStreamFini> <f videoClose>
 ****************************************************************************/
DWORD WINAPI NTvideoStreamInit(HVIDEO hVideo,
              DWORD dwMicroSecPerFrame, DWORD_PTR dwCallback,
              DWORD_PTR dwCallbackInst, DWORD dwFlags)
{
    VIDEO_STREAM_INIT_PARMS vsip;
    DWORD ret=0L;

    dprintf("+ NTvideoStreamInit (hVideo = %x)\n", hVideo);
    if (!hVideo) {
        ret = DV_ERR_INVALHANDLE;
        goto MyExit;
    }

    if (dwCallback && ((dwFlags & CALLBACK_TYPEMASK) == CALLBACK_FUNCTION) ) {
        if (IsBadCodePtr ((FARPROC) dwCallback) ) {
            ret = DV_ERR_PARAM2;
            goto MyExit;
        }
        if (!dwCallbackInst) {
            ret = DV_ERR_PARAM2;
            goto MyExit;
        }
    }

    if (dwCallback && ((dwFlags & CALLBACK_TYPEMASK) == CALLBACK_WINDOW) ) {
        if (!IsWindow((HWND)(dwCallback)) ) {
            ret = DV_ERR_PARAM2;
            goto MyExit;
        }
    }

    vsip.dwMicroSecPerFrame = dwMicroSecPerFrame;
    vsip.dwCallback = dwCallback;
    vsip.dwCallbackInst = dwCallbackInst;
    vsip.dwFlags = dwFlags;
    vsip.hVideo = hVideo;

    ret = (DWORD)NTvideoMessage(hVideo, DVM_STREAM_INIT,
                (LPARAM) (LPVIDEO_STREAM_INIT_PARMS) &vsip,
                sizeof (VIDEO_STREAM_INIT_PARMS));
MyExit:
    dprintf("- NTvideoStreamInit returning %d\n",ret);
    return ret;
}

/*****************************************************************************
 * @doc EXTERNAL  VIDEO
 *
 * @api DWORD | videoStreamFini | This function terminates streaming
 *     from the specified device channel.
 *
 * @parm HVIDEO | hVideo | Specifies a handle to the video device channel.
 *
 * @rdesc Returns zero if the function was successful. Otherwise, it returns
 *   an error number. The following errors are defined:
 *   @flag DV_ERR_INVALHANDLE | Indicates the device handle specified is invalid.
 *   @flag DV_ERR_STILLPLAYING | Indicates there are still buffers in the queue.
 *
 * @comm If there are buffers that have been sent with
 *   <f videoStreamAddBuffer> that haven't been returned to the application,
 *   this operation will fail. Use <f videoStreamReset> to return all
 *   pending buffers.
 *
 *   Each call to <f videoStreamInit> must be matched with a call to
 *   <f videoStreamFini>.
 *
 *   For VIDEO_EXTERNALIN channels, this function is used to
 *   halt capturing of data to the frame buffer.
 *
 *   For VIDEO_EXTERNALOUT channels supporting overlay,
 *   this function is used to disable the overlay.
 *
 * @xref <f videoStreamInit>
 ****************************************************************************/
DWORD WINAPI NTvideoStreamFini(HVIDEO hVideo)
{
    if (!hVideo)
        return DV_ERR_INVALHANDLE;

    return (DWORD)NTvideoMessage(hVideo, DVM_STREAM_FINI, 0L, 0L);
}

/*****************************************************************************
 * @doc EXTERNAL  VIDEO
 *
 * @api DWORD | videoStreamStart | This function starts streaming on the
 *   specified video device channel.
 *
 * @parm HVIDEO | hVideo | Specifies a handle to the video device channel.
 *
 * @rdesc Returns zero if the function was successful. Otherwise, it returns
 *   an error number. The following errors are defined:
 *   @flag DV_ERR_INVALHANDLE | Indicates the device handle specified is invalid.
 *
 *   @flag DV_ERR_NOTSUPPORTED | Indicates the device does not support this
 *         function.
 *
 * @xref <f videoStreamReset> <f videoStreamStop> <f videoStreamAddBuffer> <f videoStreamClose>
/****************************************************************************/
DWORD WINAPI NTvideoStreamStart(HVIDEO hVideo)
{
    if (!hVideo)
        return DV_ERR_INVALHANDLE;

    return (DWORD)NTvideoMessage(hVideo, DVM_STREAM_START, 0L, 0L);
}

/*****************************************************************************
 * @doc EXTERNAL  VIDEO
 *
 * @api DWORD | videoFrame | This function transfers a single frame
 *   to or from a video device channel.
 *
 * @parm HVIDEO | hVideo | Specifies a handle to the video device channel.
 *      The channel must be of type VIDEO_IN or VIDEO_OUT.
 *
 * @parm LPVIDEOHDR | lpVHdr | Specifies a far pointer to an <t VIDEOHDR>
 *      structure.
 *
 * @rdesc Returns zero if the function was successful. Otherwise, it returns
 *   an error number. The following errors are defined:
 *   @flag DV_ERR_INVALHANDLE | Specified device handle is invalid.
 *   @flag DV_ERR_PARAM1 | The <p lpVDHdr> parameter is invalid or
 *       the <e VIDEOHDR.dwBufferLength> member of the <t VIDEOHDR>
 *       structure is not set to the proper value.
 *
 * @comm Use this function with a VIDEO_IN channel to transfer a single
 *      image from the frame buffer.
 *      Use this function with a VIDEO_OUT channel to transfer a single
 *      image to the frame buffer.
 *
 * @xref <f videoOpen>
/****************************************************************************/
DWORD WINAPI NTvideoFrame (HVIDEO hVideo, LPVIDEOHDR lpVHdr)
{
    if (!hVideo)
        return DV_ERR_INVALHANDLE;

    if (!lpVHdr)
        return DV_ERR_PARAM1;

    if (IsBadWritePtr (lpVHdr, sizeof (VIDEOHDR)) )
        return DV_ERR_PARAM1;

    return (DWORD)NTvideoMessage(hVideo, DVM_FRAME, (LPARAM) lpVHdr,
                        sizeof(VIDEOHDR));
}


// NEW STUFF //





typedef struct tagVS_VERSION
{
      WORD wTotLen;
      WORD wValLen;
      TCHAR szSig[16];
      VS_FIXEDFILEINFO vffInfo;
} VS_VERSION;



/*****************************************************************************
 * @doc EXTERNAL  VIDEO
 *
 * @api DWORD | videoCapDriverDescAndVer | This function gets strings
 *   for the description and version of a video capture driver
 *
 * @parm DWORD | dwDeviceID | Specifies the index of which video driver to get
 *      information about.
 *
 * @parm LPTSTR | lpszDesc | Specifies a place to return the description
 *
 * @parm UINT | cbDesc | Specifies the length of the description string
 *
 * @parm LPTSTR | lpszVer | Specifies a place to return the version
 *
 * @parm UINT | cbVer | Specifies the length of the version string
 *
 * @rdesc Returns zero if the function was successful. Otherwise, it returns
 *   an error number.
 *
 * @comm Use this function to get strings describing the driver and its version
 *
/****************************************************************************/
DWORD WINAPI NTvideoCapDriverDescAndVer(DWORD dwDeviceID, LPTSTR lpszDesc, UINT cbDesc, LPTSTR lpszVer, UINT cbVer, LPTSTR lpszDllName, UINT cbDllName)
{
    LPTSTR  lpStr;
    UINT    wLen;
    BOOL    bRetCode;
    TCHAR   szGetName[MAX_PATH];
    DWORD   dwVerInfoSize;
    DWORD   dwVerHnd;
    TCHAR   szBuf[MAX_PATH];
    BOOL    fGetName;
    BOOL    fGetDllName;
    BOOL    fGetVersion;

    BOOL    bDescSet = FALSE;
    int i;

    // Structure used to store enumerated languages and code pages.

    VS_FIXEDFILEINFO * p_vsFixedFileInfo;

    struct LANGANDCODEPAGE {
      WORD wLanguage;
      WORD wCodePage;
    } *lpTranslate;

    UINT cbTranslate;
    WORD wLanguage, wCodePage;
    TCHAR SubBLock[_MAX_PATH];



    //const static TCHAR szNull[]        = TEXT("");
    //const static TCHAR szVideo[]       = TEXT("msvideo");
    //const static TCHAR szSystemIni[]   = TEXT("system.ini");
    //const static TCHAR szDrivers[]     = TEXT("Drivers32");
          static TCHAR szKey[sizeof(szVideo)/sizeof(TCHAR) + 2];

    fGetName = lpszDesc != NULL && cbDesc != 0;
    fGetDllName = lpszDllName != NULL && cbDllName != 0;
    fGetVersion = lpszVer != NULL && cbVer != 0;

    if (fGetName)
        lpszDesc[0] = TEXT('\0');
    if (fGetDllName)
        lpszDllName[0] = TEXT('\0');
    if (fGetVersion)
        lpszVer [0] = TEXT('\0');

    lstrcpy(szKey, szVideo);
    szKey[sizeof(szVideo)/sizeof(TCHAR) - 1] = TEXT('\0');
    if( dwDeviceID > 0 ) {
        szKey[sizeof(szVideo)/sizeof(TCHAR)] = TEXT('\0');
        szKey[(sizeof(szVideo)/sizeof(TCHAR))-1] = (TCHAR)(TEXT('1') + (dwDeviceID-1) );  // driver ordinal
    }

    if (GetPrivateProfileString(szDrivers, szKey, szNull,
                szBuf, sizeof(szBuf)/sizeof(TCHAR), szSystemIni) < 2)
        return DV_ERR_BADDEVICEID;
    //after the above, szBuf should be less than sizeof(szBuf)/sizeof(TCHAR) which is MAX_PATH... so later copy operation are safe
    if (fGetDllName) {
        lstrcpyn(lpszDllName, szBuf, cbDllName);
    }

    if (fGetName)
    {
        // Copy in the driver name initially, just in case the driver has omitted a description field.
        lstrcpyn(lpszDesc, szBuf, cbDesc);
        // now get the description from previously set aCapDriverList array (filled during the videoCreateDriverList call)
        for (i = 0; i < (int) wTotalVideoDevs; i++)
        {
            if (lstrcmpi (szBuf, aCapDriverList[i]->szDriverName) == 0)
            {
                lstrcpyn (lpszDesc, aCapDriverList[i]->szDriverDescription, cbDesc);
                bDescSet = TRU