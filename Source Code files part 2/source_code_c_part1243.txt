 Event
    )
{
    ENTER("IrpSynchCR");

    KeSetEvent(Event, 0, FALSE);
    return STATUS_MORE_PROCESSING_REQUIRED;
} // IrpSynchCR


NTSTATUS
SubmitIrpSynch(
    IN PDEVICE_OBJECT  DeviceObject,
    IN PIRP  pIrp,
    IN PAV_61883_REQUEST pAVReq
    )
{
    NTSTATUS  Status;
    KEVENT   Event;
    PIO_STACK_LOCATION  NextIrpStack;
  
    ENTER("SubmitIrpSynch");
    Status = STATUS_SUCCESS;;

    NextIrpStack = IoGetNextIrpStackLocation(pIrp);
    NextIrpStack->MajorFunction = IRP_MJ_INTERNAL_DEVICE_CONTROL;
    NextIrpStack->Parameters.DeviceIoControl.IoControlCode = IOCTL_61883_CLASS;
    NextIrpStack->Parameters.Others.Argument1 = pAVReq;

    KeInitializeEvent(&Event, NotificationEvent, FALSE);

    IoSetCompletionRoutine( 
        pIrp,
        IrpSynchCR,
        &Event,
        TRUE,
        TRUE,
        TRUE
        );

    Status = 
        IoCallDriver(
            DeviceObject,
            pIrp
            );

    if (Status == STATUS_PENDING) {
        
        TRACE(TL_PNP_INFO,("Irp is pending...\n"));
                
        if(KeGetCurrentIrql() < DISPATCH_LEVEL) {
            KeWaitForSingleObject( 
                &Event,
                Executive,
                KernelMode,
                FALSE,
                NULL
                );
            TRACE(TL_PNP_TRACE,("Irp returned; IoStatus.Status %x\n", pIrp->IoStatus.Status));
            Status = pIrp->IoStatus.Status;  // Final status
  
        }
        else {
            ASSERT(FALSE && "Pending but in DISPATCH_LEVEL!");
            return Status;
        }
    }

    EXIT("SubmitIrpSynch", Status);
    return Status;
} // SubmitIrpSynchAV




/****************************
 * Control utility functions
 ****************************/

NTSTATUS
AVCStrmGetPlugHandle(
    IN PDEVICE_OBJECT  DeviceObject,
    IN PAVC_STREAM_EXTENSION  pAVCStrmExt
    )
{
    NTSTATUS Status;
    PAV_61883_REQUEST  pAVReq;

    PAGED_CODE();
    ENTER("AVCStrmGetPlugHandle");

    Status = STATUS_SUCCESS;

    // Claim ownership of hMutexAVReqIsoch
    KeWaitForMutexObject(&pAVCStrmExt->hMutexAVReq, Executive, KernelMode, FALSE, NULL);

    pAVReq = &pAVCStrmExt->AVReq;
    RtlZeroMemory(pAVReq, sizeof(AV_61883_REQUEST));
    INIT_61883_HEADER(pAVReq, Av61883_GetPlugHandle);
    pAVReq->GetPlugHandle.PlugNum = 0;
    pAVReq->GetPlugHandle.hPlug   = 0;
    pAVReq->GetPlugHandle.Type    = pAVCStrmExt->DataFlow == KSPIN_DATAFLOW_OUT ? CMP_PlugOut : CMP_PlugIn;

    Status = SubmitIrpSynch(DeviceObject, pAVCStrmExt->pIrpAVReq, pAVReq);

    if(!NT_SUCCESS(Status)) {
        TRACE(TL_61883_ERROR,("GetPlugHandle: Failed:%x\n", Status));
        ASSERT(NT_SUCCESS(Status));
        pAVCStrmExt->hPlugRemote = NULL;               
    }
    else {
        TRACE(TL_61883_TRACE,("GetPlugHandle:hPlug:%x\n", pAVReq->GetPlugHandle.hPlug));
        pAVCStrmExt->hPlugRemote = pAVReq->GetPlugHandle.hPlug;          
    }

    KeReleaseMutex(&pAVCStrmExt->hMutexAVReq, FALSE);


    EXIT("AVCStrmGetPlugHandle", Status);
    return Status;
}

NTSTATUS
AVCStrmGetPlugState(
    IN PDEVICE_OBJECT  DeviceObject,
    IN PAVC_STREAM_EXTENSION  pAVCStrmExt
    )
/*++

Routine Description:

    Ask 61883.sys for the plug state.
 
Arguments:

Return Value:

    Nothing

--*/
{
    NTSTATUS Status;
    PAV_61883_REQUEST  pAVReq;

    PAGED_CODE();
    ENTER("AVCStrmGetPlugState");

    Status = STATUS_SUCCESS;

    //
    // Check only requirement: hConnect
    //
    if(pAVCStrmExt->hPlugRemote == NULL) {
        TRACE(TL_STRM_ERROR,("GetPlugState: hPlugRemote is NULL.\n")); 
        ASSERT(pAVCStrmExt->hPlugRemote != NULL);
        return STATUS_UNSUCCESSFUL;
    }

    // Claim ownership of hMutexAVReqIsoch
    KeWaitForMutexObject(&pAVCStrmExt->hMutexAVReq, Executive, KernelMode, FALSE, NULL);

    pAVReq = &pAVCStrmExt->AVReq;
    RtlZeroMemory(pAVReq, sizeof(AV_61883_REQUEST));
    INIT_61883_HEADER(pAVReq, Av61883_GetPlugState);
    pAVReq->GetPlugState.hPlug = pAVCStrmExt->hPlugRemote;

    Status = 
        SubmitIrpSynch( 
            DeviceObject,
            pAVCStrmExt->pIrpAVReq,
            pAVReq
            );

    if(!NT_SUCCESS(Status)) {
        TRACE(TL_61883_ERROR,("GetPlugState Failed %x\n", Status));
    }
    else {
        // Cache plug state (note: these are dynamic values)
        pAVCStrmExt->RemotePlugState = pAVReq->GetPlugState;

        TRACE(TL_61883_TRACE,("GetPlugState: ST %x; State %x; DRate %d; Payld %d; BCCnt %d; PPCnt %d\n", 
            pAVReq->Flags ,
            pAVReq->GetPlugState.State,
            pAVReq->GetPlugState.DataRate,
            pAVReq->GetPlugState.Payload,
            pAVReq->GetPlugState.BC_Connections,
            pAVReq->GetPlugState.PP_Connections
            ));
    }

    KeReleaseMutex(&pAVCStrmExt->hMutexAVReq, FALSE);

    EXIT("AVCStrmGetPlugState", Status);
    return Status;
}



NTSTATUS
AVCStrmMakeConnection(
    IN PDEVICE_OBJECT  DeviceObject,
    IN PAVC_STREAM_EXTENSION  pAVCStrmExt
    )
/*++

Routine Description:

    Make an isoch connection.

--*/
{
    NTSTATUS Status;
    PAV_61883_REQUEST  pAVReq;
    PAVCSTRM_FORMAT_INFO  pAVCStrmFormatInfo;

    PAGED_CODE();
    ENTER("AVCStrmMakeConnection");

    // Claim ownership of hMutexAVReqIsoch
    KeWaitForMutexObject(&pAVCStrmExt->hMutexAVReq, Executive, KernelMode, FALSE, NULL);

    TRACE(TL_61883_TRACE,("MakeConnect: State:%d; hConnect:%x\n", pAVCStrmExt->StreamState, pAVCStrmExt->hConnect));
    if(pAVCStrmExt->hConnect) {
        KeReleaseMutex(&pAVCStrmExt->hMutexAVReq, FALSE);
        return STATUS_SUCCESS;
    }

    Status = STATUS_SUCCESS;

    pAVCStrmFormatInfo = pAVCStrmExt->pAVCStrmFormatInfo;
    pAVReq = &pAVCStrmExt->AVReq;
    INIT_61883_HEADER(pAVReq, Av61883_Connect);
    pAVReq->Connect.Type = CMP_PointToPoint;  // !!

    // see which way we the data will flow...
    if(pAVCStrmExt->DataFlow == KSPIN_DATAFLOW_OUT) {
        // Remote(oPCR)->Local(iPCR)
        pAVReq->Connect.hOutputPlug      = pAVCStrmExt->hPlugRemote;
        pAVReq->Connect.hInputPlug       = pAVCStrmExt->hPlugLocal;
        // Other parameters !!

    } else {
        // Remote(iPCR)<-Local(oPCR)
        pAVReq->Connect.hOutputPlug      = pAVCStrmExt->hPlugLocal;
        pAVReq->Connect.hInputPlug       = pAVCStrmExt->hPlugRemote;

        pAVReq->Connect.Format.FMT       = (UCHAR) pAVCStrmFormatInfo->cipHdr2.FMT;  // From AV/C in/outpug plug signal format status cmd
        // 00 for NTSC, 80 for PAL; set the 50/60 bit  
        // From AV/C in/outpug plug signal format status cmd         
        pAVReq->Connect.Format.FDF_hi    = 
            ((UCHAR) pAVCStrmFormatInfo->cipHdr2.F5060_OR_TSF << 7) |
            ((UCHAR) pAVCStrmFormatInfo->cipHdr2.STYPE << 2) |
            ((UCHAR) pAVCStrmFormatInfo->cipHdr2.RSV);

        //
        // 16bit SYT field = 4BitCycleCount:12BitCycleOffset;
        // Will be set by 61883
        //
        pAVReq->Connect.Format.FDF_mid   = 0;  
        pAVReq->Connect.Format.FDF_lo    = 0;
    
        //
        // Constants depend on the A/V data format (in or out plug format)
        //
        pAVReq->Connect.Format.bHeader   = (BOOL)  pAVCStrmFormatInfo->cipHdr1.SPH;
        pAVReq->Connect.Format.Padding   = (UCHAR) pAVCStrmFormatInfo->cipHdr1.QPC;
        pAVReq->Connect.Format.BlockSize = (UCHAR) pAVCStrmFormatInfo->cipHdr1.DBS; 
        pAVReq->Connect.Format.Fraction  = (UCHAR) pAVCStrmFormatInfo->cipHdr1.FN;
    }

    pAVReq->Connect.Format.BlockPeriod = pAVCStrmFormatInfo->BlockPeriod;

    TRACE(TL_61883_TRACE,("Connect:hOutPlg:%x<->hInPlug:%x; cipQuad2[%.2x:%.2x:%.2x:%.2x]; BlkSz %d; SrcPkt %d; AvgTm %d, BlkPrd %d\n", 
        pAVReq->Connect.hOutputPlug,
        pAVReq->Connect.hInputPlug,
        pAVReq->Connect.Format.FMT,
        pAVReq->Connect.Format.FDF_hi,
        pAVReq->Connect.Format.FDF_mid,
        pAVReq->Connect.Format.FDF_lo,
        pAVReq->Connect.Format.BlockSize,
        pAVCStrmFormatInfo->SrcPacketsPerFrame,
        pAVCStrmFormatInfo->AvgTimePerFrame,
        pAVReq->Connect.Format.BlockPeriod
        ));

    Status = 
        SubmitIrpSynch( 
            DeviceObject,
            pAVCStrmExt->pIrpAVReq,
            pAVReq
            );

    if(!NT_SUCCESS(Status)) {
        TRACE(TL_61883_ERROR,("Connect Failed = 0x%x\n", Status));     
        pAVCStrmExt->hConnect = NULL;
    }
    else {
        TRACE(TL_61883_TRACE,("hConnect = 0x%x\n", pAVReq->Connect.hConnect));
        pAVCStrmExt->hConnect = pAVReq->Connect.hConnect;
    }

    KeReleaseMutex(&pAVCStrmExt->hMutexAVReq, FALSE);

    EXIT("AVCStrmMakeConnection", Status);
    return Status;
}

NTSTATUS
AVCStrmBreakConnection(
    IN PDEVICE_OBJECT  DeviceObject,
    IN PAVC_STREAM_EXTENSION  pAVCStrmExt
    )
/*++

Routine Description:

    Break the isoch connection.

--*/
{
    NTSTATUS Status;
    PAV_61883_REQUEST  pAVReq;
#if DBG
    PAVC_STREAM_DATA_STRUCT pDataStruc;
#endif
    PAGED_CODE();
    ENTER("AVCStrmBreakConnection");

    // Claim ownership of hMutexAVReqIsoch
    KeWaitForMutexObject(&pAVCStrmExt->hMutexAVReq, Executive, KernelMode, FALSE, NULL);

    TRACE(TL_STRM_TRACE,("BreakConnect: State:%d; hConnect:%x\n", pAVCStrmExt->StreamState, pAVCStrmExt->hConnect));
    if(!pAVCStrmExt->hConnect) {
        KeReleaseMutex(&pAVCStrmExt->hMutexAVReq, FALSE);
        return STATUS_SUCCESS;
    }

    Status = STATUS_SUCCESS;

#if DBG
    pDataStruc = pAVCStrmExt->pAVCStrmDataStruc;
#endif
    pAVReq = &pAVCStrmExt->AVReq;
    RtlZeroMemory(pAVReq, sizeof(AV_61883_REQUEST));
    INIT_61883_HEADER(pAVReq, Av61883_Disconnect);
    pAVReq->Disconnect.hConnect = pAVCStrmExt->hConnect;
    
    Status = 
        SubmitIrpSynch( 
            DeviceObject,
            pAVCStrmExt->pIrpAVReq,
            pAVReq
            );

    // This could be caused that the connection was not P2P, and 
    // it tried to disconnect.
    if(!NT_SUCCESS(Status) || Status == STATUS_NO_SUCH_DEVICE) {
        TRACE(TL_61883_ERROR,("Disconnect Failed:%x; AvReq->ST %x\n", Status, pAVReq->Flags  ));
    } else {
        TRACE(TL_61883_TRACE,("Disconnect suceeded; ST %x; AvReq->ST %x\n", Status, pAVReq->Flags  ));
    }

    TRACE(TL_STRM_WARNING,("*** DisConn St:%x; Stat: DataRcved:%d; [Pic# =? Prcs:Drp:Cncl] [%d ?=%d+%d+%d]\n", 
        Status, 
        (DWORD) pDataStruc->cntDataReceived,
        (DWORD) pDataStruc->PictureNumber,
        (DWORD) pDataStruc->FramesProcessed, 
        (DWORD) pDataStruc->FramesDropped,
        (DWORD) pDataStruc->cntFrameCancelled
        ));

    // We will not have another chance to reconnect it so we assume it is disconnected.
    pAVCStrmExt->hConnect = NULL;    

    KeReleaseMutex(&pAVCStrmExt->hMutexAVReq, FALSE);


    EXIT("AVCStrmBreakConnection", Status);
    return Status;
}

NTSTATUS
AVCStrmStartIsoch(
    IN PDEVICE_OBJECT  DeviceObject,
    IN PAVC_STREAM_EXTENSION  pAVCStrmExt
    )
/*++

Routine Description:

    Start streaming.

--*/
{
    NTSTATUS Status;
    PAVC_STREAM_DATA_STRUCT pDataStruc;
    PAGED_CODE();
    ENTER("AVCStrmStartIsoch");


    // Claim ownership of hMutexAVReqIsoch
    KeWaitForMutexObject(&pAVCStrmExt->hMutexAVReq, Executive, KernelMode, FALSE, NULL);

    if(pAVCStrmExt->IsochIsActive) {
        TRACE(TL_STRM_WARNING,("Isoch already active!"));
        KeReleaseMutex(&pAVCStrmExt->hMutexAVReq, FALSE);
        return STATUS_SUCCESS;
    }

    if(!pAVCStrmExt->hConnect) {
        ASSERT(pAVCStrmExt->hConnect && "Cannot start isoch while graph is not connected!\n");
        KeReleaseMutex(&pAVCStrmExt->hMutexAVReq, FALSE);
        return STATUS_INVALID_PARAMETER;
    }

    Status = STATUS_SUCCESS;
    pDataStruc = pAVCStrmExt->pAVCStrmDataStruc;

    TRACE(TL_61883_TRACE,("StartIsoch: flow %d; AQD [%d:%d:%d]\n", pAVCStrmExt->DataFlow, pDataStruc->cntDataAttached, pDataStruc->cntDataQueued, pDataStruc->cntDataDetached));


    RtlZeroMemory(&pAVCStrmExt->AVReq, sizeof(AV_61883_REQUEST));
    if(pAVCStrmExt->DataFlow == KSPIN_DATAFLOW_OUT) {
        INIT_61883_HEADER(&pAVCStrmExt->AVReq, Av61883_Listen);
        pAVCStrmExt->AVReq.Listen.hConnect = pAVCStrmExt->hConnect;
    } else {
        INIT_61883_HEADER(&pAVCStrmExt->AVReq, Av61883_Talk);
        pAVCStrmExt->AVReq.Talk.hConnect = pAVCStrmExt->hConnect;
        if(pAVCStrmExt->pAVCStrmFormatInfo->AVCStrmFormat == AVCSTRM_FORMAT_MPEG2TS) 
            pAVCStrmExt->AVReq.Flags = CIP_TALK_DOUBLE_BUFFER | CIP_TALK_USE_SPH_TIMESTAMP;
    }

    Status = 
        SubmitIrpSynch( 
            DeviceObject,
            pAVCStrmExt->pIrpAVReq,
            &pAVCStrmExt->AVReq
            );

    if (NT_SUCCESS(Status)) {
        pAVCStrmExt->IsochIsActive = TRUE;
        TRACE(TL_61883_TRACE,("Av61883_%s; Status %x; Streaming...\n", (pAVCStrmExt->DataFlow == KSPIN_DATAFLOW_OUT ? "Listen" : "Talk"), Status));
    }
    else {
        TRACE(TL_61883_ERROR,("Av61883_%s; failed %x\n", (pAVCStrmExt->DataFlow == KSPIN_DATAFLOW_OUT ? "Listen" : "Talk"), Status));
        ASSERT(NT_SUCCESS(Status) && "Start isoch failed!");
    }

    KeReleaseMutex(&pAVCStrmExt->hMutexAVReq, FALSE);

    
    EXIT("AVCStrmStartIsoch", Status);
    return Status;
}


//
// This wait is based on testing transmitting MPEG2TS data with up to 32 date request.
// Each data request has 256 MPEG2TS data packets.  There is a slow motion mode,
// and it may take longer for video to be transmitted in the slow motion mode.
//
#define MAX_ATTACH_WAIT  50000000   // max wait time in seconds

VOID
AVCStrmWaitUntilAttachedAreCompleted(
    IN PAVC_STREAM_EXTENSION  pAVCStrmExt
    )
{
    KIRQL oldIrql;
    PAVC_STREAM_DATA_STRUCT pDataStruc;

    pDataStruc = pAVCStrmExt->pAVCStrmDataStruc;

    //
    // Wait until attached data to complete transmission before aborting (cancel) them
    //
    KeAcquireSpinLock(&pDataStruc->DataListLock, &oldIrql);
    if(   pAVCStrmExt->DataFlow == KSPIN_DATAFLOW_IN 
       && pDataStruc->cntDataAttached > 0
        ) {
        LARGE_INTEGER tmMaxWait;
        NTSTATUS StatusWait;
#if DBG
        ULONGLONG tmStart;
#endif
        TRACE(TL_STRM_TRACE,("StopIsoch: MaxWait %d (msec) for %d data buffer to finished transmitting!\n", 
            MAX_ATTACH_WAIT/10000, pDataStruc->cntDataAttached));
        //
        // This event will be signalled when all attach buffers are returned.
        // It is protected by Spinlock for common data pDataStruc->cntDataAttached.
        //
        KeClearEvent(&pDataStruc->hNoAttachEvent);
#if DBG        
        tmStart = GetSystemTime();
#endif
        KeReleaseSpinLock(&pDataStruc->DataListLock, oldIrql);

        tmMaxWait = RtlConvertLongToLargeInteger(-(MAX_ATTACH_WAIT));
        StatusWait = 
            KeWaitForSingleObject( 
                &pDataStruc->hNoAttachEvent,
                Executive,
                KernelMode,
                FALSE,
                &tmMaxWait
                );
               
        if(StatusWait == STATUS_TIMEOUT) {
            TRACE(TL_STRM_ERROR,("TIMEOUT (%d msec) on hNoAttachEvent! DataRcv:%d; AQD [%d:%d:%d]\n", 
                (DWORD) (GetSystemTime()-tmStart)/10000,
                (DWORD) pDataStruc->cntDataReceived,
                pAVCStrmExt->pAVCStrmDataStruc->cntDataAttached,
                pAVCStrmExt->pAVCStrmDataStruc->cntDataQueued,
                pAVCStrmExt->pAVCStrmDataStruc->cntDataDetached
                ));
        } else {
            TRACE(TL_STRM_WARNING,("Status:%x; (%d msec) on hNoAttachEvent. DataRcv:%d; AQD [%d:%d:%d]\n", 
                StatusWait, 
                (DWORD) (GetSystemTime()-tmStart)/10000,
                (DWORD) pDataStruc->cntDataReceived,
                pAVCStrmExt->pAVCStrmDataStruc->cntDataAttached,
                pAVCStrmExt->pAVCStrmDataStruc->cntDataQueued,
                pAVCStrmExt->pAVCStrmDataStruc->cntDataDetached
                ));
        }
        
    } else {
        KeReleaseSpinLock(&pDataStruc->DataListLock, oldIrql);
    }
}


NTSTATUS
AVCStrmStopIsoch(
    IN PDEVICE_OBJECT  DeviceObject,
    IN PAVC_STREAM_EXTENSION  pAVCStrmExt
    )
/*++

Routine Description:

    Stop streaming.

--*/
{
    NTSTATUS Status;
    PAVC_STREAM_DATA_STRUCT pDataStruc;


    PAGED_CODE();
    ENTER("AVCStrmStopIsoch");


    // Claim ownership of hMutexAVReqIsoch
    KeWaitForMutexObject(&pAVCStrmExt->hMutexAVReq, Executive, KernelMode, FALSE, NULL);

    if(!pAVCStrmExt->IsochIsActive) {
        TRACE(TL_STRM_WARNING|TL_61883_WARNING,("Isoch already not active!"));
        KeReleaseMutex(&pAVCStrmExt->hMutexAVReq, FALSE);
        return STATUS_SUCCESS;
    }

    if(!pAVCStrmExt->hConnect) {
        ASSERT(pAVCStrmExt->hConnect && "Cannot stop isoch while graph is not connected!\n");
        KeReleaseMutex(&pAVCStrmExt->hMutexAVReq, FALSE);
        return STATUS_INVALID_PARAMETER;
    }

    Status = STATUS_SUCCESS;
    pDataStruc = pAVCStrmExt->pAVCStrmDataStruc;

    TRACE(TL_STRM_TRACE,("IsochSTOP; flow %d; AQD [%d:%d:%d]\n", pAVCStrmExt->DataFlow, pDataStruc->cntDataAttached, pDataStruc->cntDataQueued, pDataStruc->cntDataDetached));

    RtlZeroMemory(&pAVCStrmExt->AVReq, sizeof(AV_61883_REQUEST));
    INIT_61883_HEADER(&pAVCStrmExt->AVReq, Av61883_Stop);
    pAVCStrmExt->AVReq.Listen.hConnect = pAVCStrmExt->hConnect;

    Status = 
        SubmitIrpSynch( 
            DeviceObject,
            pAVCStrmExt->pIrpAVReq,
            &pAVCStrmExt->AVReq
            );

    if (NT_SUCCESS(Status) || Status == STATUS_NO_SUCH_DEVICE) {
        TRACE(TL_61883_TRACE,("Av61883_%s; Status %x; Stopped...\n", (pAVCStrmExt->DataFlow == KSPIN_DATAFLOW_OUT ? "Listen" : "Talk"), Status));
    } else {
        TRACE(TL_61883_ERROR,("Av61883_%s; failed %x\n", (pAVCStrmExt->DataFlow == KSPIN_DATAFLOW_OUT ? "Listen" : "Talk"), Status));
        ASSERT(NT_SUCCESS(Status) && "Stop isoch failed!");
    }

    // Assume isoch is stopped regardless of the return status.
    pAVCStrmExt->IsochIsActive = FALSE;

    KeReleaseMutex(&pAVCStrmExt->hMutexAVReq, FALSE);

    EXIT("AVCStrmStopIsoch", Status);
    return Status;
}


/******************************
 * Streaming utility funcrtions
 *******************************/

//
// GetSystemTime in 100 nS units
//

ULONGLONG GetSystemTime()
{

    LARGE_INTEGER rate, ticks;

    ticks = KeQueryPerformanceCounter(&rate);

    return (KSCONVERT_PERFORMANCE_TIME(rate.QuadPart, ticks));
}


///
// The "signature" of the header section of Seq0 of incoming source packets:
//
// "Blue" book, Part2, 11.4 (page 50); Figure 66, table 36 (page 111)
//
// ID0 = {SCT2,SCT1,SCT0,RSV,Seq3,Seq2,Seq1,Seq0} 
//
//     SCT2-0 = {0,0,0} = Header Section Type
//     RSV    = {1}
//     Seq3-0 = {1,1,1,1} for NoInfo or {0,0,0,} for Sequence 0
//
// ID1 = {DSeq3-0, 0, RSV, RSV, RSV} 
//     DSeq3-0 = {0, 0, 0, 0} = Beginning of a DV frame
//
// ID2 = {DBN7,DBN6,DBN5,DBN4,DBN3,DBN2,DBN1,DBN0}
//     DBB7-0 = {0,0,0,0,0,0,0,0,0} = Beginning of a DV frame
//

#define DIF_BLK_ID0_SCT_MASK       0xe0 // 11100000b; Section Type (SCT)2-0 are all 0's for the Header section
#define DIF_BLK_ID1_DSEQ_MASK      0xf0 // 11110000b; DIF Sequence Number(DSEQ)3-0 are all 0's 
#define DIF_BLK_ID2_DBN_MASK       0xff // 11111111b; Data Block Number (DBN)7-0 are all 0's 

#define DIF_HEADER_DSF             0x80 // 10000000b; DSF=0; 10 DIF Sequences (525-60)
                                        //            DSF=1; 12 DIF Sequences (625-50)

#define DIF_HEADER_TFn             0x80 // 10000000b; TFn=0; DIF bloick of area N are transmitted in the current DIF sequence.
                                        //            TFn=1; DIF bloick of area N are NOT transmitted in the current DIF sequence.


ULONG
AVCStrmDVReadFrameValidate(           
    IN PCIP_VALIDATE_INFO  pInfo
    )
/*++

Routine Description:

   Used to validate the header section of a frame. so 61883 will start filling data for a DVFrame.
   Note: This routine apply only to DV ONLY.

Return

    0  verified
    1: invallid

--*/
{
    if(pInfo->Packet) {        

        //
        // Detect header 0 signature.
        //
        if(
             (pInfo->Packet[0] & DIF_BLK_ID0_SCT_MASK)  == 0 
          && (pInfo->Packet[1] & DIF_BLK_ID1_DSEQ_MASK) == 0 
          && (pInfo->Packet[2] & DIF_BLK_ID2_DBN_MASK)  == 0 
          ) {
                
            // Check TF1, TF2, and  TF3:  1: not transmitted; 0:transmitted
            // TF1:Audio; TF2:Video; TF3:Subcode; they all need to be 0 to be valid.
            if((pInfo->Packet[5] & 0x80) ||
               (pInfo->Packet[6] & 0x80) ||
               (pInfo->Packet[7] & 0x80) 
               ) {
                TRACE(TL_CIP_TRACE,("inv src pkts; [%x %x %d %x], [%x   %x %x %x]\n", 
                    pInfo->Packet[0],
                    pInfo->Packet[1],
                    pInfo->Packet[2],
                    pInfo->Packet[3],
                    pInfo->Packet[4],
                    pInfo->Packet[5],
                    pInfo->Packet[6],
                    pInfo->Packet[7]
                    ));
                // Valid header but DIF block for this area is not transmitted.
                // Some DV (such as DVCPro) may wait untill its "mecha and servo" to be stable to make these valid.
                // This should happen if a graph is in run state before a tape is played (and stablized).
                return 1;
            }
            return 0;
        }
        else {
            return 1;
        }
    }
    else {
        TRACE(TL_CIP_ERROR,("Validate: invalid SrcPktSeq; Packet %x\n", pInfo->Packet)); 
        return 1;
    }
} // DVReadFrameValidate

NTSTATUS
AVCStrmProcessReadComplete(
    PAVCSTRM_DATA_ENTRY  pDataEntry,
    PAVC_STREAM_EXTENSION  pAVCStrmExt,
    PAVC_STREAM_DATA_STRUCT  pDataStruc
    )
/*++

Routine Description:

    Process the data read completion.   

--*/
{
    PKSSTREAM_HEADER  pStrmHeader;
    LONGLONG  LastPictureNumber;
    NTSTATUS Status = STATUS_SUCCESS;

    pStrmHeader = pDataEntry->StreamHeader;
    ASSERT(pStrmHeader->Size >= sizeof(KSSTREAM_HEADER));


    // Check CIP_STATUS from 61883
    // CIP_STATUS_CORRUPT_FRAME (0x00000001)
    if(pDataEntry->Frame->Status & CIP_STATUS_CORRUPT_FRAME) {
        TRACE(TL_STRM_WARNING|TL_CIP_WARNING,("CIP_STATUS_CORRUPT_FRAME\n"));
        pStrmHeader->OptionsFlags = 0;
        Status = STATUS_SUCCESS; // Success but no data !
        pStrmHeader->DataUsed = 0;
        pDataStruc->PictureNumber++;  pDataStruc->FramesProcessed++;
    }
    else
    // CIP_STATUS_SUCCESS       (0x00000000)
    // CIP_STATUS_FIRST_FRAME   (0x00000002)
    if(pDataEntry->Frame->Status == CIP_STATUS_SUCCESS ||
       pDataEntry->Frame->Status & CIP_STATUS_FIRST_FRAME)   {

        // Only increment FramesProcessed if it is a valid frame;
        pDataStruc->FramesProcessed++;
        Status = STATUS_SUCCESS;

        pStrmHeader->OptionsFlags = KSSTREAM_HEADER_OPTIONSF_SPLICEPOINT;

#ifdef NT51_61883
        pStrmHeader->DataUsed     = pDataEntry->Frame->CompletedBytes; 
#else
        pStrmHeader->DataUsed     = pAVCStrmExt->pAVCStrmDataStruc->FrameSize;               
#endif

        // This subunit driver is a Master clock
       if (pDataEntry->ClockProvider) {
#ifdef NT51_61883
            ULONG  ulDeltaCycleCounts;

            // If not the first frame. we will calculate the drop frame information.
            if(pAVCStrmExt->b1stNewFrameFromPauseState) { 
                // Default number of packets for a DV frame
                if(pDataStruc->FramesProcessed > 1)  // PAUSE->RUN->PAUSE->RUN case; no increase for the 1st frame.
                    pDataStruc->CurrentStreamTime += pAVCStrmExt->pAVCStrmFormatInfo->AvgTimePerFrame;
                pAVCStrmExt->b1stNewFrameFromPauseState = FALSE;                

            } else {           
                ULONG ulCycleCount16bits;

                // Calculate skipped 1394 cycle from the returned CycleTime
                VALIDATE_CYCLE_COUNTS(pDataEntry->Frame->Timestamp);
                ulCycleCount16bits = CALCULATE_CYCLE_COUNTS(pDataEntry->Frame->Timestamp);
                ulDeltaCycleCounts = CALCULATE_DELTA_CYCLE_COUNT(pAVCStrmExt->CycleCount16bits, ulCycleCount16bits); 

                // Adjust to max allowable gap to the max elapsed time of the CycleTime returned by OHCI 1394.
                if(ulDeltaCycleCounts > MAX_CYCLES)
                    ulDeltaCycleCounts = MAX_CYCLES;
    
                // There are two cases for drop frames: (1) Starve of buffer; (2) no data
                // If there is starving, status will be CIP_STATUS_FIRST_FRAME.  
                if(pDataEntry->Frame->Status & CIP_STATUS_FIRST_FRAME)   {
                    // Convert packets (cycles) to time in 100 nanosecond unit; (one cycle = 1250 * 100 nsec)
                    // We could use the skip frame, but CycleCount is more accurate.
                    pDataStruc->CurrentStreamTime += ulDeltaCycleCounts * TIME_PER_CYCLE;   // Use cycle count to be precise.                 
                } else {
                    // Ignore all "drop frames" in the "no data" case
                    if(ulDeltaCycleCounts * TIME_PER_CYCLE > pAVCStrmExt->pAVCStrmFormatInfo->AvgTimePerFrame)
                        // There might be some frame(s) skipped due to no data or tape stopped playing, we skip this skipped data.
                        pDataStruc->CurrentStreamTime += pAVCStrmExt->pAVCStrmFormatInfo->AvgTimePerFrame;
                    else 
                        pDataStruc->CurrentStreamTime += ulDeltaCycleCounts * TIME_PER_CYCLE;   // Use cycle count to be precise.                 
                } 
            }

            // StreamTime start with 0; 
            pStrmHeader->PresentationTime.Time = pDataStruc->CurrentStreamTime;

            // Use to adjust the queried stream time
            pAVCStrmExt->LastSystemTime = GetSystemTime();

            // Cache current CycleCount
            pAVCStrmExt->CycleCount16bits = CALCULATE_CYCLE_COUNTS(pDataEntry->Frame->Timestamp);

#else   // NT51_61883
            // This is the old way when 61883 was not returning the correct CycleTime.
            // This is the old way when 61883 was not returning the correct CycleTime.
            pStrmHeader->PresentationTime.Time = pDataStruc->CurrentStreamTime;            
            pAVCStrmExt->LastSystemTime = GetSystemTime();  // Use to adjust the queried stream time
            pDataStruc->CurrentStreamTime += pAVCStrmExt->pAVCStrmFormatInfo->AvgTimePerFrame;
#endif  // NT51_61883

        // no Clock so "free flowing!"
        } else {
            pStrmHeader->PresentationTime.Time = 0;
        }

        // Put in Timestamp info depending on clock provider            
        pStrmHeader->PresentationTime.Numerator   = 1;
        pStrmHeader->PresentationTime.Denominator = 1;

        // Only if there is a clock, presentation time and drop frames information are set.
        //  Acoording to DDK:
        //  The PictureNumber member count represents the idealized count of the current picture, 
        //  which is calculated in one of two ways: 
        // ("Other" clock) Measure the time since the stream was started and divide by the frame duration. 
        // (MasterClock) Add together the count of frames captured and the count of frame dropped. 
        //
        // Here, we know the current stream time, and the picture number is calculated from that.
        //
       
        if(pDataEntry->ClockProvider) {

            pStrmHeader->Duration = 
                pAVCStrmExt->pAVCStrmFormatInfo->AvgTimePerFrame;

            pStrmHeader->OptionsFlags |= 
                (KSSTREAM_HEADER_OPTIONSF_TIMEVALID |     // pStrmHeader->PresentationTime.Time is valid
                 KSSTREAM_HEADER_OPTIONSF_DURATIONVALID); 

            if(pDataEntry->Frame->Status & CIP_STATUS_FIRST_FRAME) 
                pStrmHeader->OptionsFlags |= KSSTREAM_HEADER_OPTIONSF_DATADISCONTINUITY;            

            // Calculate picture number and dropped frame;
            // For NTSC, it could be 267 or 266 packet time per frame. Since integer calculation will round, 
            // we will add a packet time (TIME_PER_CYCLE = 125 us = 1250 100nsec) to that.This is only used for calculation.
            LastPictureNumber = pDataStruc->PictureNumber;  
            pDataStruc->PictureNumber = 
                1 +   // Picture number start with 1.but PresetationTime start with 0.
                (pStrmHeader->PresentationTime.Time + TIME_PER_CYCLE)
                * (LONGLONG) GET_AVG_TIME_PER_FRAME_DENOM(pAVCStrmExt->pAVCStrmFormatInfo->AVCStrmFormat) 
                / (LONGLONG) GET_AVG_TIME_PER_FRAME_NUM(pAVCStrmExt->pAVCStrmFormatInfo->AVCStrmFormat);

            if(pDataStruc->PictureNumber > LastPictureNumber+1) {
                pStrmHeader->OptionsFlags |= KSSTREAM_HEADER_OPTIONSF_DATADISCONTINUITY;  // If there is a skipped frame, set the discontinuity flag
                TRACE(TL_CIP_WARNING,("Discontinuity: LastPic#:%d; Pic#%d; PresTime:%d;\n", (DWORD) LastPictureNumber, (DWORD) pDataStruc->PictureNumber, (DWORD) pStrmHeader->PresentationTime.Time));
            }

            if(pDataStruc->PictureNumber <= LastPictureNumber) {
                TRACE(TL_STRM_TRACE|TL_CIP_TRACE,("Same pic #:%d; LastPic:%d; tmPres:%d; OptionFlags:%x\n", 
                    (DWORD) pDataStruc->PictureNumber, 
                    (DWORD) LastPictureNumber, 
                    (DWORD) pStrmHeader->PresentationTime.Time,
                    pStrmHeader->OptionsFlags));
                pDataStruc->PictureNumber = LastPictureNumber + 1;  // Picture number must progress !!!!
            }

            pDataStruc->FramesDropped = pDataStruc->PictureNumber - pDataStruc->FramesProcessed;

        // no Clock so "free flowing!"
        } else {
            pStrmHeader->Duration = 0;  // No clock so not valid.
            pDataStruc->PictureNumber++;
            TRACE(TL_STRM_TRACE,("No clock: PicNum:%d\n", (DWORD) pDataStruc->PictureNumber));
        }
    }
    else {
        // 61883 has not defined this yet!         
        pStrmHeader->OptionsFlags = 0;
        Status = STATUS_SUCCESS;
        pStrmHeader->DataUsed = 0;
        pDataStruc->PictureNumber++;  pDataStruc->FramesProcessed++;
        TRACE(TL_STRM_ERROR|TL_CIP_ERROR,("Unexpected Frame->Status %x\n", pDataEntry->Frame->Status));
        ASSERT(FALSE && "Unknown pDataEntry->Frame->Status");
    }

#if 0
    // For VidOnly which uses VideoInfoHeader and has 
    // an extended frame information (KS_FRAME_INFO) appended to KSSTREAM_HEADER
    if(pStrmHeader->Size >= (sizeof(KSSTREAM_HEADER) + sizeof(PKS_FRAME_INFO)) ) {
        pFrameInfo = (PKS_FRAME_INFO) (pStrmHeader + 1);
        pFrameInfo->ExtendedHeaderSize = sizeof(KS_FRAME_INFO);
        pFrameInfo->PictureNumber = pDataStruc->PictureNumber;
        pFrameInfo->DropCount     = pDataStruc->FramesDropped;
        pFrameInfo->dwFrameFlags  = 
            KS_VIDEO_FLAG_FRAME |     // Complete frame
            KS_VIDEO_FLAG_I_FRAME;    // Every DV frame is an I frame
    }
#endif

#if DBG
    // Validate that the data is return in the right sequence
    if(pDataEntry->FrameNumber != pDataStruc->FramesProcessed) {
        TRACE(TL_STRM_ERROR|TL_CIP_ERROR,("ProcessRead: OOSequence %d != %d\n",  (DWORD) pDataEntry->FrameNumber, (DWORD) pDataStruc->FramesProcessed));
    };
#endif

    return Status;
}

ULONG
AVCStrmCompleteRead(
    PCIP_NOTIFY_INFO     pInfo
    )
/*++

Routine Description:

    61883 has completed receiving data and callback to us to complete.   

--*/
{
    PAVCSTRM_DATA_ENTRY  pDataEntry;
    PAVC_STREAM_EXTENSION  pAVCStrmExt;
    PAVC_STREAM_DATA_STRUCT  pDataStruc;
    KIRQL oldIrql;


    // Callback and in DISPATCH_LEVEL
    // The called might have acquired spinlock as well!

    TRACE(TL_STRM_INFO,("CompleteRead: pInfo:%x\n", pInfo));

    pDataEntry = pInfo->Context;

    if(!pDataEntry) {     
        ASSERT(pDataEntry && "Context is NULL!\n");
        return 1;
    }
    pAVCStrmExt = pDataEntry->pAVCStrmExt;
    if(!pAVCStrmExt) {
        ASSERT(pAVCStrmExt && "pAVCStrmExt is NULL\n");
        return 1;
    }    
    pDataStruc = pAVCStrmExt->pAVCStrmDataStruc;
    if(!pDataStruc) {
        ASSERT(pDataStruc && "pDataStruc is NULL\n");
        return 1;
    }

    KeAcquireSpinLock(&pDataStruc->DataListLock, &oldIrql);

#if DBG
    // It is possible that a buffer is completed before it is return from IoCallDriver to attach this buffer.
    if(!IsStateSet(pDataEntry->State, DE_IRP_LOWER_ATTACHED_COMPLETED)) {

        TRACE(TL_STRM_WARNING,("AVCStrmCompleteRead: pDataEntry:%x not yet attached but completed.\n", pDataEntry));
        
        //
        // This irp will be completed from its IoCallDriver to attach this frame.
        //
     } 
#endif

    // Can the cancel routione is ahead of us? Error condition.
    if(pDataStruc->cntDataAttached <= 0) {
        TRACE(TL_STRM_ERROR|TL_CIP_ERROR,("AVCStrmCompleteRead:pAVCStrmExt:%x, pDataEntry:%x, AQD[%d:%d:%d]\n", 
            pAVCStrmExt, pDataEntry, pDataStruc->cntDataAttached, pDataStruc->cntDataQueued,pDataStruc->cntDataDetached));
        KeReleaseSpinLock(&pDataStruc->DataListLock, oldIrql); 
        return 1;  
    }

    //
    // Process this completion based on the return status from 61883
    //
    pDataEntry->pIrpUpper->IoStatus.Status = 
        AVCStrmProcessReadComplete(
            pDataEntry,
            pAVCStrmExt,
            pDataStruc
            );

    //
    // There are two possible ways to complete the data request:
    //
    // (A) Normal case:       attach data request (pIrpLower), attached completed, notify callback (here), and completion (pIrpUpper)
    // (B) Rare/stress case:  attach data request (pIrpLower), notify callback (here), attach complete (pIrpLower), and complete (pIrpUpper)
    //

    pDataEntry->State |= DE_IRP_LOWER_CALLBACK_COMPLETED;

    //
    // Case (A): If DE_IRP_LOWER_CALLBACK_COMPLETED is set and pIrpUpper is marked pending, complete the UpperIrp.
    //
  
    if(IsStateSet(pDataEntry->State, DE_IRP_LOWER_ATTACHED_COMPLETED)) {

        if(IsStateSet(pDataEntry->State, DE_IRP_UPPER_PENDING_COMPLETED)) {

            //
            // This is the normal case: attached, IoMarkPending, then complete in the callback routine.
            //

            IoCompleteRequest( pDataEntry->pIrpUpper, IO_NO_INCREMENT );  pDataEntry->State |= DE_IRP_UPPER_COMPLETED;

            //
            // Transfer from attach to detach list
            //

            RemoveEntryList(&pDataEntry->ListEntry); InterlockedDecrement(&pDataStruc->cntDataAttached); 
#if DBG
            if(pDataStruc->cntDataAttached < 0) {
                TRACE(TL_STRM_ERROR|TL_CIP_ERROR,("pDataStruc:%x; pDataEntry:%x\n", pDataStruc, pDataEntry));        
                ASSERT(pDataStruc->cntDataAttached >= 0);  
            }
#endif
            InsertTailList(&pDataStruc->DataDetachedListHead, &pDataEntry->ListEntry);  InterlockedIncrement(&pDataStruc->cntDataDetached);

            //
            // pDataEntry should not be referenced after this.
            //

        } else {

            TRACE(TL_STRM_TRACE,("Watch out! pDataEntry:%x in between attach complete and IoMarkIrpPending!\n", pDataEntry));        

            //
            // Case (B): Complete IrpUpper when return to IoCallDriver(IrpLower)            
            // Note: The IrpLower has not called IoMarkIrpPending().  (Protected with spinlock)
            //
        }

    } else {

        //
        // Case (B): Complete IrpUpper when return to IoCallDriver(IrpLower) 
        //
    }
 
    KeReleaseSpinLock(&pDataStruc->DataListLock, oldIrql); 

    return 0;
} // AVCStrmCompleteRead

#if DBG
PAVCSTRM_DATA_ENTRY  pLastDataEntry;
LONGLONG  LastFrameNumber;
#endif

ULONG
AVCStrmCompleteWrite(
    PCIP_NOTIFY_INFO     pInfo
    )
/*++

Routine Description:

    61883 has completed receiving data and callback to us to complete.   

--*/
{
    PAVCSTRM_DATA_ENTRY  pDataEntry;
    PAVC_STREAM_EXTENSION  pAVCStrmExt;
    PAVC_STREAM_DATA_STRUCT  pDataStruc;
    NTSTATUS  irpStatus;
    KIRQL oldIrql;


    // Callback and in DISPATCH_LEVEL
    // The called might have acquired spinlock as well!

    TRACE(TL_STRM_INFO,("CompleteWrite: pInfo:%x\n", pInfo));

    pDataEntry = pInfo->Context;

    if(!pDataEntry) {     
        ASSERT(pDataEntry && "Context is NULL!\n");
        return 1;
    }
    pAVCStrmExt = pDataEntry->pAVCStrmExt;
    if(!pAVCStrmExt) {
        ASSERT(pAVCStrmExt && "pAVCStrmExt is NULL\n");
        return 1;
    }    
    pDataStruc = pAVCStrmExt->pAVCStrmDataStruc;
    if(!pDataStruc) {
        ASSERT(pDataStruc && "pDataStruc is NULL\n");
        return 1;
    }

#if 0  // Must complete it!
    // If isoch is not active, then we are in the process of stopping; Let this be cancellable.
    if(!pAVCStrmExt->IsochIsActive) {   
        TRACE(TL_STRM_ERROR,("AVCStrmCompleteRead: IsochActive:%d; pDataEntry:%x\n", pAVCStrmExt->IsochIsActive, pDataEntry));        
        ASSERT(pAVCStrmExt->IsochIsActive);
        return 1;
    }
#endif

    irpStatus = STATUS_SUCCESS;
    KeAcquireSpinLock(&pDataStruc->DataListLock, &oldIrql);

#if DBG
    // It is possible that a buffer is completed before it is return from IoCallDriver to attach this buffer.
    if(!IsStateSet(pDataEntry->State, DE_IRP_LOWER_ATTACHED_COMPLETED)) {

        TRACE(TL_STRM_WARNING,("CompleteWrite: pDataEntry:%x not yet attached but completed.\n", pDataEntry));

        //
        // This irp will be completed from its IoCallDriver to attach this frame.
        //
    } 
#endif

    // Can the cancel routione is ahead of us? Error condition.
    if(pDataStruc->cntDataAttached <= 0) {
        TRACE(TL_STRM_ERROR|TL_CIP_ERROR,("AVCStrmCompleteWrite:pAVCStrmExt:%x, pDataEntry:%x, AQD[%d:%d:%d]\n", 
            pAVCStrmExt, pDataEntry, pDataStruc->cntDataAttached, pDataStruc->cntDataQueued,pDataStruc->cntDataDetached));
        KeReleaseSpinLock(&pDataStruc->DataListLock, oldIrql); 
        return 1;  
    }


    //
    // Process according to status for the frame 
    //
    if(pDataEntry->Frame->Status & CIP_STATUS_CORRUPT_FRAME) {
        pDataStruc->FramesProcessed++;
        TRACE(TL_CIP_ERROR,("CIP_STATUS_CORRUPT_FRAME; pIrpUpper:%x; pIrpLower:%x\n", pDataEntry->pIrpUpper, pDataEntry->pIrpLower));
    } else 
    if(pDataEntry->Frame->Status == CIP_STATUS_SUCCESS ||
       pDataEntry->Frame->Status &  CIP_STATUS_FIRST_FRAME) {
#if DBG
        if(pDataEntry->Frame->Status & CIP_STATUS_FIRST_FRAME)
            TRACE(TL_CIP_TRACE,("CIP_STATUS_FIRST_FRAME; pIrpUpper:%x; pIrpLower:%x\n", pDataEntry->pIrpUpper, pDataEntry->pIrpLower));
#endif
        pDataStruc->FramesProcessed++;
    } else {
        pDataStruc->FramesProcessed++;
        TRACE(TL_CIP_ERROR,("Unknown Status:%x\n", pDataEntry->Frame->Status));      
    }

    pDataStruc->PictureNumber++;


#if DBG
    //
    // Validate that the data is return in the right sequence
    //
    if(pDataEntry->FrameNumber != pDataStruc->FramesProcessed) {
        TRACE(TL_STRM_WARNING|TL_CIP_WARNING,("CompleteWrite: OOSequence FrameNum:%d != FrameProcessed:%d;  pIrpUpper:%x; pIrpLower:%x; Last(%d:%x,%x)\n",  
            (DWORD) pDataEntry->FrameNumber, (DWORD) pDataStruc->FramesProcessed,
            pDataEntry->pIrpUpper, pDataEntry->pIrpLower,
            (DWORD) pLastDataEntry->FrameNumber, pLastDataEntry->pIrpUpper, pLastDataEntry->pIrpLower
            ));
        // ASSERT(pDataEntry->FrameNumber == pDataStruc->FramesProcessed);
    };
    pLastDataEntry = pDataEntry;
    LastFrameNumber = pDataEntry->FrameNumber;
#endif

    //
    // There are two possible ways to complete the data request:
    //
    // (A) Normal case:       attach data request (pIrpLower), attached completed, notify callback (here), and completion (pIrpUpper)
    // (B) Rare/stress case:  attach data request (pIrpLower), notify callback (here), attach complete (pIrpLower), and complete (pIrpUpper)
    //

    pDataEntry->pIrpUpper->IoStatus.Status = irpStatus;     

    pDataEntry->State |= DE_IRP_LOWER_CALLBACK_COMPLETED;

    //
    // Case (A): If DE_IRP_LOWER_CALLBACK_COMPLETED is set and pIrpUpper is marked pending, complete the UpperIrp.
    //
  
    if(IsStateSet(pDataEntry->State, DE_IRP_LOWER_ATTACHED_COMPLETED)) {

        if(IsStateSet(pDataEntry->State, DE_IRP_UPPER_PENDING_COMPLETED)) {

            //
            // This is the normal case: attached, IoMarkPending, then complete in the callback routine.
            //

            IoCompleteRequest( pDataEntry->pIrpUpper, IO_NO_INCREMENT );  pDataEntry->State |= DE_IRP_UPPER_COMPLETED;

            //
            // Transfer from attach to detach list
            //

            RemoveEntryList(&pDataEntry->ListEntry); InterlockedDecrement(&pDataStruc->cntDataAttached);        

            //
            // Signal when there is no more data buffer attached.
            //
            if(pDataStruc->cntDataAttached == 0) 
                KeSetEvent(&pDataStruc->hNoAttachEvent, 0, FALSE);  

#if DBG
            if(pDataStruc->cntDataAttached < 0) {
                TRACE(TL_STRM_ERROR|TL_CIP_ERROR,("pDataStruc:%x; pDataEntry:%x\n", pDataStruc, pDataEntry));        
                ASSERT(pDataStruc->cntDataAttached >= 0);  
            }
#endif
            InsertTailList(&pDataStruc->DataDetachedListHead, &pDataEntry->ListEntry);  InterlockedIncrement(&pDataStruc->cntDataDetached);

            //
            // pDataEntry should not be referenced after this.
            //

        } else {

            TRACE(TL_STRM_TRACE,("Watch out! pDataEntry:%x in between attach complete and IoMarkIrpPending!\n", pDataEntry));        

            //
            // Case (B): Complete IrpUpper when return to IoCallDriver(IrpLower);
            // Note: The IrpLower has not called IoMarkIrpPending().  (Protected with spinlock)
            //
        }

    } else {

        //
        // Case (B): Complete IrpUpper when return to IoCallDriver(IrpLower) 
        //
    }

    KeReleaseSpinLock(&pDataStruc->DataListLock, oldIrql); 

    return 0;
} // AVCStrmCompleteWrite



NTSTATUS
AVCStrmAttachFrameCR(
    IN PDEVICE_OBJECT DeviceObject,
    IN PIRP pIrp,
    IN PAVCSTRM_DATA_ENTRY  pDataEntry
    )
/*++

Routine Description:

    Completion routine for attaching a data request to 61883.

--*/
{
    PAVC_STREAM_EXTENSION  pAVCStrmExt;
    PAVC_STREAM_DATA_STRUCT  pDataStruc;
    KIRQL oldIrql;

    PAGED_CODE();

    pAVCStrmExt = pDataEntry->pAVCStrmExt;
    pDataStruc = pAVCStrmExt->pAVCStrmDataStruc;

    KeAcquireSpinLock(&pDataStruc->DataListLock, &oldIrql);

    //
    // Check for possible attaching data request error
    //

    if(!NT_SUCCESS(pIrp->IoStatus.Status)) {

        TRACE(TL_STRM_ERROR|TL_CIP_ERROR,("AttachFrameCR: pDataEntry:%x; pIrp->IoStatus.Status:%x (Error!)\n", pDataEntry, pIrp->IoStatus.Status));
        ASSERT(NT_SUCCESS(pIrp->IoStatus.Status)); 
        
        pDataEntry->State |= DE_IRP_ERROR;

        //
        // If attach data request has failed, we complete the pIrpUpper with this error.
        //
        pDataEntry->pIrpUpper->IoStatus.Status = pIrp->IoStatus.Status; // or should we cancel (STATUS_CANCELLED) it?
        IoCompleteRequest( pDataEntry->pIrpUpper, IO_NO_INCREMENT );   pDataEntry->State |= DE_IRP_UPPER_COMPLETED;

        //
        // Transfer from attach to detach list 
        //
        RemoveEntryList(&pDataEntry->ListEntry); InterlockedDecrement(&pDataStruc->cntDataAttached); 

        //
        // Signal completion event when all attached are completed.
        //
        if(pAVCStrmExt->DataFlow != KSPIN_DATAFLOW_IN && pDataStruc->cntDataAttached == 0) 
            KeSetEvent(&pDataStruc->hNoAttachEvent, 0, FALSE); 
       
        ASSERT(pDataStruc->cntDataAttached >= 0);  
        InsertTailList(&pDataStruc->DataDetachedListHead, &pDataEntry->ListEntry); InterlockedIncrement(&pDataStruc->cntDataDetached);

        //
        // No additional processing when return to IoCallDriver() with the error pIrp->IoStatus.Status.
        //
        
        KeReleaseSpinLock(&pDataStruc->DataListLock, oldIrql);   
        return STATUS_MORE_PROCESSING_REQUIRED;        
    }

#if DBG
    //
    // Validate that the data is attached in the right sequence
    //
    pDataStruc->FramesAttached++;
    if(pDataEntry->FrameNumber != pDataStruc->FramesAttached) {
        TRACE(TL_STRM_WARNING|TL_CIP_WARNING,("Attached completed OOSequence FrameNum:%d != FrameAttached:%d;  pIrpUpper:%x; pIrpLower:%x; Last(%d:%x,%x)\n",  
            (DWORD) pDataEntry->FrameNumber, (DWORD) pDataStruc->FramesAttached
            ));
        // ASSERT(pDataEntry->FrameNumber == pDataStruc->FramesAttached);
    };
#endif

    //
    // Attached data reuqest to 61883 is completed (note: however, we do not know if callback is called.)
    //
    pDataEntry->State |= DE_IRP_LOWER_ATTACHED_COMPLETED;

    KeReleaseSpinLock(&pDataStruc->DataListLock, oldIrql); 

    return STATUS_MORE_PROCESSING_REQUIRED;
}


VOID
AVCStrmFormatAttachFrame(
    IN KSPIN_DATAFLOW  DataFlow,
    IN PAVC_STREAM_EXTENSION  pAVCStrmExt,
    IN AVCSTRM_FORMAT AVCStrmFormat,
    IN PAV_61883_REQUEST  pAVReq,
    IN PAVCSTRM_DATA_ENTRY  pDataEntry,
    IN ULONG  ulSourcePacketSize,    // Packet length in bytes
    IN ULONG  ulFrameSize,           // Buffer size; may contain one or multiple source packets
    IN PIRP  pIrpUpper,
    IN PKSSTREAM_HEADER  StreamHeader,
    IN PVOID  FrameBuffer
    )
/*++

Routine Description:

    Format an attach frame request.

--*/
{
    InitializeListHead(&pDataEntry->ListEntry);

    // A DataEntry must be previously completed!
    ASSERT(IsStateSet(pDataEntry->State, DE_IRP_UPPER_COMPLETED) && "Reusing a data entry that was not completed!");

    pDataEntry->State        = DE_PREPARED;   // Initial state of a resued DataEntry (start over!)

    pDataEntry->pAVCStrmExt  = pAVCStrmExt;
    pDataEntry->pIrpUpper    = pIrpUpper;
    pDataEntry->StreamHeader = StreamHeader;
    pDataEntry->FrameBuffer  = FrameBuffer;

    ASSERT(pDataEntry->FrameBuffer != NULL);

    pDataEntry->Frame->pNext   = NULL;
    pDataEntry->Frame->Status  = 0;
    pDataEntry->Frame->Packet  = (PUCHAR) FrameBuffer;

#if DBG
    pDataEntry->FrameNumber    = pAVCStrmExt->pAVCStrmDataStruc->cntDataReceived;
#endif

    pDataEntry->Frame->Flags   = 0;

    if(DataFlow == KSPIN_DATAFLOW_OUT) {

        // DV needs validation to determine the header section as the start of a DV frame
        if(AVCStrmFormat == AVCSTRM_FORMAT_SDDV_NTSC  ||
           AVCStrmFormat == AVCSTRM_FORMAT_SDDV_PAL   ||
           AVCStrmFormat == AVCSTRM_FORMAT_HDDV_NTSC  ||
           AVCStrmFormat == AVCSTRM_FORMAT_HDDV_PAL   ||
           AVCStrmFormat == AVCSTRM_FORMAT_SDLDV_NTSC ||
           AVCStrmFormat == AVCSTRM_FORMAT_SDLDV_PAL ) {
            pDataEntry->Frame->pfnValidate = AVCStrmDVReadFrameValidate;   // use to validate the 1st source packet

#ifdef NT51_61883
            //
            // Set CIP_USE_SOURCE_HEADER_TIMESTAMP to get 25 bit CycleTime from source packet header 
            // (13CycleCount:12CycleOffset)
            // Do not set this to get 16 bit CycleTime from isoch packet (3 SecondCount:13CycleCount)
            // 
            pDataEntry->Frame->Flags       |= ( CIP_VALIDATE_FIRST_SOURCE  
                                              | CIP_RESET_FRAME_ON_DISCONTINUITY);  // Reset buffer pointer when encounter discontinuity
#endif
        } else {
            // MPEG2 specific flags
            pDataEntry->Frame->pfnValidate = NULL;

            if(pAVCStrmExt->pAVCStrmFormatInfo->OptionFlags & AVCSTRM_FORMAT_OPTION_STRIP_SPH)
                pDataEntry->Frame->Flags   |= CIP_STRIP_SOURCE_HEADER;
        }

        pDataEntry->Frame->ValidateContext = pDataEntry;  
        pDataEntry->Frame->pfnNotify       = AVCStrmCompleteRead;
    } 
    else {
        // DV needs validation to determine the header section as the start of a DV frame
        if(AVCStrmFormat == AVCSTRM_FORMAT_SDDV_NTSC  ||
           AVCStrmFormat == AVCSTRM_FORMAT_SDDV_PAL   ||
           AVCStrmFormat == AVCSTRM_FORMAT_HDDV_NTSC  ||
           AVCStrmFormat == AVCSTRM_FORMAT_HDDV_PAL   ||
           AVCStrmFormat == AVCSTRM_FORMAT_SDLDV_NTSC ||
           AVCStrmFormat == AVCSTRM_FORMAT_SDLDV_PAL ) {

            pDataEntry->Frame->Flags   |= CIP_DV_STYLE_SYT;
        } 
        else {
            // MPEG2 specific flag
        }

        pDataEntry->Frame->pfnValidate     = NULL;
        pDataEntry->Frame->ValidateContext = NULL;
        pDataEntry->Frame->pfnNotify       = AVCStrmCompleteWrite;
    }
    pDataEntry->Frame->NotifyContext       = pDataEntry;

    //
    // Av61883_AttachFrames
    //
    RtlZeroMemory(pAVReq, sizeof(AV_61883_REQUEST));
    INIT_61883_HEADER(pAVReq, Av61883_AttachFrame);
    pAVReq->AttachFrame.hConnect     = pAVCStrmExt->hConnect;
    pAVReq->AttachFrame.FrameLength  = ulFrameSize;
    pAVReq->AttachFrame.SourceLength = ulSourcePacketSize;
    pAVReq->AttachFrame.Frame        = pDataEntry->Frame;

    TRACE(TL_STRM_TRACE,("DataFlow:%d; pDataEntry:%x; pIrpUp:%x; hConnect:%x; FrameSz:%d; SrcPktSz:%d; Frame:%x;\n pfnVldt:(%x, %x); pfnNtfy:(%x, %x) \n", DataFlow, 
        pDataEntry, pIrpUpper, pAVCStrmExt->hConnect, ulFrameSize, ulSourcePacketSize, pDataEntry->Frame,
        pAVReq->AttachFrame.Frame->pfnValidate, pAVReq->AttachFrame.Frame->ValidateContext,
        pAVReq->AttachFrame.Frame->pfnNotify,   pAVReq->AttachFrame.Frame->NotifyContext));

    ASSERT(pAVCStrmExt->hConnect);
}


NTSTATUS
AVCStrmCancelOnePacketCR(
    IN PDEVICE_OBJECT DeviceObject,
    IN PIRP pIrpLower,
    IN PAVCSTRM_DATA_ENTRY pDataEntry
    )
/*++

Routine Description:

    Completion routine for detach an isoch descriptor associate with a pending IO.
    Will cancel the pending IO here if detaching descriptor has suceeded.

--*/
{
    PAVC_STREAM_EXTENSION  pAVCStrmExt;
    PAVC_STREAM_DATA_STRUCT  pDataStruc;
    KIRQL  oldIrql;

    ENTER("AVCStrmCancelOnePacketCR");

    if(!pDataEntry) {
        ASSERT(pDataEntry);
        return STATUS_MORE_PROCESSING_REQUIRED;
    }

    pAVCStrmExt = pDataEntry->pAVCStrmExt;
    ASSERT(pAVCStrmExt);
    pDataStruc = pAVCStrmExt->pAVCStrmDataStruc;
    ASSERT(pDataStruc);

    KeAcquireSpinLock(&pDataStruc->DataListLock, &oldIrql);

    if(!NT_SUCCESS(pIrpLower->IoStatus.Status)) {

        TRACE(TL_STRM_ERROR|TL_CIP_ERROR,("CancelOnePacketCR: pIrpLower->IoStatus.Status %x (Error!)\n", pIrpLower->IoStatus.Status));
        ASSERT(pIrpLower->IoStatus.Status != STATUS_NOT_FOUND);  // Catch lost packet!

        pDataEntry->State |= DE_IRP_ERROR;

        //
        // Even though there is an error, but we have a valid DataEntry.
        // Go ahead complete and cancel it.
        //
    }

#ifdef NT51_61883

    //
    // Special case for MPEG2TS data since a data buffer contains multiple data packets 
    // (188*N or 192*N) in one data buffer.  The first cancelled buffer may contain valid 
    // data packet that an application will need to completely present a video frame.
    // So instead of cancelling it, it will be completed.
    //
    if(   pAVCStrmExt->pAVCStrmFormatInfo->AVCStrmFormat == AVCSTRM_FORMAT_MPEG2TS 
       && pDataEntry->Frame->CompletedBytes) {   

        pDataEntry->pIrpUpper->IoStatus.Status = 
            AVCStrmProcessReadComplete(
                pDataEntry,
                pAVCStrmExt,
                pDataStruc
                ); 

        //
        // CompletedBytes should be multiple of 188 or 192 bytes
        //
        ASSERT(pDataEntry->Frame->CompletedBytes % \
            ((pAVCStrmExt->pAVCStrmFormatInfo->OptionFlags & AVCSTRM_FORMAT_OPTION_STRIP_SPH) ? 188 : 192) == 0);
        
        TRACE(TL_PNP_ERROR,("pDataEntry:%x; Cancelled buffer (MPEG2TS) has %d bytes; Status:%x\n",
            pDataEntry, pDataEntry->Frame->CompletedBytes, pIrpLower->IoStatus.Status, pDataEntry->pIrpUpper->IoStatus.Status));        

    } else {
        pDataStruc->cntFrameCancelled++;
        pDataEntry->pIrpUpper->IoStatus.Status = STATUS_CANCELLED;

        TRACE(TL_CIP_TRACE,("pDataEntry:%x; Cancelled buffer (MPEG2TS) has %d bytes; Status:%x\n",
            pDataEntry, pDataEntry->Frame->CompletedBytes, pIrpLower->IoStatus.Status, pDataEntry->pIrpUpper->IoStatus.Status));        
    }

#else 

    pDataStruc->cntFrameCancelled++;
    pDataEntry->pIrpUpper->IoStatus.Status = STATUS_CANCELLED;

#endif 

    IoCompleteRequest(pDataEntry->pIrpUpper, IO_NO_INCREMENT);  pDataEntry->State |= DE_IRP_UPPER_COMPLETED;
    pDataEntry->State |= DE_IRP_CANCELLED;

    pDataEntry->pIrpUpper = NULL;  // No more access of this!
 
    //
    // Note: pDataEntry is already dequed from DataAttachList
    //
    InsertTailList(&pDataStruc->DataDetachedListHead, &pDataEntry->ListEntry); InterlockedIncrement(&pDataStruc->cntDataDetached);
    KeReleaseSpinLock(&pDataStruc->DataListLock, oldIrql); 

    EXIT("AVCStrmCancelOnePacketCR", STATUS_MORE_PROCESSING_REQUIRED);
    return STATUS_MORE_PROCESSING_REQUIRED;
}


NTSTATUS
AVCStrmCancelIO(
    IN PDEVICE_OBJECT  DeviceObject,
    IN PAVC_STREAM_EXTENSION  pAVCStrmExt
    )
/*++

Routine Description:

    Cancel all pending IOs

--*/
{
    NTSTATUS  Status;
    PAVC_STREAM_DATA_STRUCT  pDataStruc;
    KIRQL  oldIrql;
    PAVCSTRM_DATA_ENTRY  pDataEntry;
    PAV_61883_REQUEST  pAVReq;
    PIO_STACK_LOCATION  NextIrpStack;

   
    PAGED_CODE();
    ENTER("AVCStrmCancelIO");

    Status = STATUS_SUCCESS;

    if(pAVCStrmExt->IsochIsActive) {

        TRACE(TL_STRM_WARNING,("Isoch is active while trying to cancel IO!\n"));
        // Try stop isoch and continue if success!
        Status = AVCStrmStopIsoch(DeviceObject, pAVCStrmExt);
        if(!NT_SUCCESS(Status) && Status != STATUS_NO_SUCH_DEVICE) {
            TRACE(TL_STRM_ERROR,("Isoch stop failed! Cannnot cancelIO while isoch active.\n"));
            return Status;
        }
    }

    //
    // Guard againt data attach completion
    //
    KeWaitForMutexObject(&pAVCStrmExt->hMutexControl, Executive, KernelMode, FALSE, NULL);


    //
    // Cancel all pending IOs
    //
    pDataStruc = pAVCStrmExt->pAVCStrmDataStruc;
    TRACE(TL_STRM_WARNING,("CancelIO Starting: pDataStruc:%x; AQD [%d:%d:%d]\n", pDataStruc,
        pDataStruc->cntDataAttached, pDataStruc->cntDataQueued, pDataStruc->cntDataDetached));

    KeAcquireSpinLock(&pDataStruc->DataListLock, &oldIrql);
    while (!IsListEmpty(&pDataStruc->DataAttachedListHead)) {
        pDataEntry = (PAVCSTRM_DATA_ENTRY) \
            RemoveHeadList(&pDataStruc->DataAttachedListHead); InterlockedDecrement(&pDataStruc->cntDataAttached);
#if DBG
        if(!IsStateSet(pDataEntry->State, DE_IRP_LOWER_ATTACHED_COMPLETED)) {
            TRACE(TL_STRM_ERROR|TL_CIP_ERROR,("CancelIO: pDataEntry:%x\n", pDataEntry));
            // Must be already attached in order to cancel it.
            ASSERT(IsStateSet(pDataEntry->State, DE_IRP_LOWER_ATTACHED_COMPLETED));
        }
#endif
        KeReleaseSpinLock(&pDataStruc->DataListLock, oldIrql);

        // Issue 61883 request to cancel this attach
        pAVReq = &pDataEntry->AVReq;
        RtlZeroMemory(pAVReq, sizeof(AV_61883_REQUEST));
        INIT_61883_HEADER(pAVReq, Av61883_CancelFrame);

        pAVReq->CancelFrame.hConnect = pAVCStrmExt->hConnect;
        pAVReq->CancelFrame.Frame    = pDataEntry->Frame;
        TRACE(TL_STRM_TRACE,("Canceling AttachList: pAvReq %x; pDataEntry:%x\n", pAVReq, pDataEntry));

        NextIrpStack = IoGetNextIrpStackLocation(pDataEntry->pIrpLower);
        NextIrpStack->MajorFunction = IRP_MJ_INTERNAL_DEVICE_CONTROL;
        NextIrpStack->Parameters.DeviceIoControl.IoControlCode = IOCTL_61883_CLASS;
        NextIrpStack->Parameters.Others.Argument1 = pAVReq;

        IoSetCompletionRoutine( 
            pDataEntry->pIrpLower,
            AVCStrmCancelOnePacketCR,
            pDataEntry,
            TRUE,
            TRUE,
            TRUE
            );

        Status = 
            IoCallDriver(
                DeviceObject,
                pDataEntry->pIrpLower
                );

        ASSERT(Status == STATUS_PENDING || Status == STATUS_SUCCESS || Status == STATUS_NO_SUCH_DEVICE); 

        KeAcquireSpinLock(&pDataStruc->DataListLock, &oldIrql);
    } // while
    KeReleaseSpinLock(&pDataStruc->DataListLock, oldIrql);

    TRACE(TL_61883_TRACE,("CancelIO complete: pDataStruc:%x; AQD [%d:%d:%d]\n", pDataStruc,
        pDataStruc->cntDataAttached, pDataStruc->cntDataQueued, pDataStruc->cntDataDetached));

    //
    // Guard against data attach completion
    //
    KeReleaseMutex(&pAVCStrmExt->hMutexControl, FALSE);


    EXIT("AVCStrmCancelIO", Status);
    return Status;
}

NTSTATUS
AVCStrmValidateFormat(
    PAVCSTRM_FORMAT_INFO  pAVCFormatInfo
    )
/*++

Routine Description:

    Validate AVC format information.

--*/
{
    NTSTATUS Status;
    PAGED_CODE();

    Status = STATUS_SUCCESS;

    if(pAVCFormatInfo->SizeOfThisBlock != sizeof(AVCSTRM_FORMAT_INFO)) {
        TRACE(TL_STRM_ERROR,("pAVCFormatInfo:%x; SizeOfThisBlock:%d != %d\n", pAVCFormatInfo, pAVCFormatInfo->SizeOfThisBlock, sizeof(AVCSTRM_FORMAT_INFO)));
        ASSERT((pAVCFormatInfo->SizeOfThisBlock == sizeof(AVCSTRM_FORMAT_INFO)) && "Invalid format info parameter!");
        return STATUS_INVALID_PARAMETER;
    }

    TRACE(TL_STRM_TRACE|TL_CIP_TRACE,("ValidateFormat: pAVCFormatInfo:%x; idx:%d; SrcPkt:%d; RcvBuf:%d; XmtBuf:%d; Strip:%d; AvgTm:%d; BlkPeriod:%d\n",
        pAVCFormatInfo,
        pAVCFormatInfo->AVCStrmFormat,
        pAVCFormatInfo->SrcPacketsPerFrame,
        pAVCFormatInfo->NumOfRcvBuffers,
        pAVCFormatInfo->NumOfXmtBuffers,
        pAVCFormatInfo->OptionFlags,
        pAVCFormatInfo->AvgTimePerFrame,
        pAVCFormatInfo->BlockPeriod
        ));

    TRACE(TL_STRM_TRACE|TL_CIP_TRACE,("ValidateFormat: cip1(DBS:%d, FN:%x); cip2(FMT:%x, 50_60:%x, STYPE:%x, SYT:%x)\n",
        pAVCFormatInfo->cipHdr1.DBS,
        pAVCFormatInfo->cipHdr1.FN,
        pAVCFormatInfo->cipHdr2.FMT,
        pAVCFormatInfo->cipHdr2.F5060_OR_TSF,
        pAVCFormatInfo->cipHdr2.STYPE,
        pAVCFormatInfo->cipHdr2.SYT
        ));

    if(pAVCFormatInfo->SrcPacketsPerFrame == 0 ||
       (pAVCFormatInfo->NumOfRcvBuffers == 0 && pAVCFormatInfo->NumOfXmtBuffers == 0) ||
       // pAVCFormatInfo->AvgTimePerFrame == 0 ||
       pAVCFormatInfo->BlockPeriod == 0 ||
       pAVCFormatInfo->cipHdr1.DBS == 0 
       ) {
        TRACE(TL_STRM_ERROR,("ValidateFormat: Invalid parametert!\n"));
        return STATUS_INVALID_PARAMETER;
    }

    return Status;
}

NTSTATUS
AVCStrmAllocateQueues(
    IN struct DEVICE_EXTENSION * pDevExt,
    IN PAVC_STREAM_EXTENSION  pAVCStrmExt,
    IN KSPIN_DATAFLOW  DataFlow,
    IN PAVC_STREAM_DATA_STRUCT pDataStruc,
    PAVCSTRM_FORMAT_INFO  pAVCStrmFormatInfo
    )
/*++

Routine Description:

    Preallocated all nodes for the data queuding.

--*/
{
    ULONG ulNumberOfNodes;
    ULONG ulSizeOfOneNode;  // Might combine multiple structures
    ULONG ulSizeAllocated;
    PBYTE pMemoryBlock;
    PAVCSTRM_DATA_ENTRY pDataEntry;
    ULONG  i;
    PCIP_HDR1 pCipHdr1;

    PAGED_CODE();
    ENTER("AVCStrmAllocateQueues");

    //
    // Pre-allcoate PC resource
    //
    ulNumberOfNodes = DataFlow == KSPIN_DATAFLOW_OUT ? \
        pAVCStrmFormatInfo->NumOfRcvBuffers : pAVCStrmFormatInfo->NumOfXmtBuffers;
    ASSERT(ulNumberOfNodes > 0);
    ulSizeOfOneNode = sizeof(AVCSTRM_DATA_ENTRY) + sizeof(struct _CIP_FRAME);
    ulSizeAllocated = ulNumberOfNodes * ulSizeOfOneNode;

    pMemoryBlock = ExAllocatePool(NonPagedPool, ulSizeAllocated);
    if(!pMemoryBlock) {
        return STATUS_NO_MEMORY;
    }

    RtlZeroMemory(pMemoryBlock, ulSizeAllocated);

    // Initialize data IO structure

    InitializeListHead(&pDataStruc->DataAttachedListHead);
    InitializeListHead(&pDataStruc->DataQueuedListHead);
    InitializeListHead(&pDataStruc->DataDetachedListHead);
    KeInitializeSpinLock(&pDataStruc->DataListLock);

    KeInitializeEvent(&pDataStruc->hNoAttachEvent, NotificationEvent, FALSE);

    // Cache it for freeing purpose;
    pDataStruc->pMemoryBlock = pMemoryBlock;

    pDataEntry = (PAVCSTRM_DATA_ENTRY) pMemoryBlock;

    for (i=0; i < ulNumberOfNodes; i++) {
        ((PBYTE) pDataEntry->Frame) = ((PBYTE) pDataEntry) + sizeof(AVCSTRM_DATA_ENTRY);
        pDataEntry->pIrpLower = IoAllocateIrp(pDevExt->physicalDevObj->StackSize, FALSE);
        if(!pDataEntry->pIrpLower) {
            while(!IsListEmpty(&pDataStruc->DataDetachedListHead)) {
                pDataEntry = (PAVCSTRM_DATA_ENTRY) \
                    RemoveHeadList(&pDataStruc->DataDetachedListHead); InterlockedDecrement(&pDataStruc->cntDataDetached);
                if(pDataEntry->pIrpLower) {
                    IoFreeIrp(pDataEntry->pIrpLower);  pDataEntry->pIrpLower = NULL;
                }
            }
            ExFreePool(pMemoryBlock); pMemoryBlock = NULL;
            return STATUS_INSUFFICIENT_RESOURCES;
        }
        pDataEntry->State = DE_IRP_UPPER_COMPLETED;  // Inital state
        InsertTailList(&pDataStruc->DataDetachedListHead, &pDataEntry->ListEntry); InterlockedIncrement(&pDataStruc->cntDataDetached);
        ((PBYTE) pDataEntry) += ulSizeOfOneNode;
    }

    pCipHdr1 = &pAVCStrmFormatInfo->cipHdr1;
    // Calculate source packet size (if strip header, 4 bytes less).
    pDataStruc->SourcePacketSize = \
        pCipHdr1->DBS * 4 * (1 << pCipHdr1->FN) - \
        ((pAVCStrmFormatInfo->OptionFlags & AVCSTRM_FORMAT_OPTION_STRIP_SPH) ? 4 : 0);

    pDataStruc->FrameSize = \
        pDataStruc->SourcePacketSize * pAVCStrmFormatInfo->SrcPacketsPerFrame; 

    TRACE(TL_STRM_TRACE,("DBS:%d; FN:%d; SrcPktSz:%d; SrcPktPerFrame:%d; FrameSize:%d\n", 
        pCipHdr1->DBS, pCipHdr1->FN, 
        pDataStruc->SourcePacketSize, pAVCStrmFormatInfo->SrcPacketsPerFrame,
        pDataStruc->FrameSize
        ));

    TRACE(TL_STRM_TRACE,("pDataStruc:%x; A(%d,%x); Q(%d,%x); D(%d,%x)\n", pDataStruc, 
        pDataStruc->cntDataAttached, &pDataStruc->DataAttachedListHead,
        pDataStruc->cntDataQueued,   &pDataStruc->DataQueuedListHead,
        pDataStruc->cntDataDetached, &pDataStruc->DataDetachedListHead
        ));

    return STATUS_SUCCESS;
}


NTSTATUS
AVCStrmFreeQueues(
    IN PAVC_STREAM_DATA_STRUCT pDataStruc
    )
/*++

Routine Description:

    Free nodes preallocated.

--*/
{
    PAVCSTRM_DATA_ENTRY pDataEntry;

    PAGED_CODE();
    ENTER("AVCStrmFreeQueues");

    while(!IsListEmpty(&pDataStruc->DataAttachedListHead)) {
        pDataEntry = (PAVCSTRM_DATA_ENTRY) \
            RemoveHeadList(&pDataStruc->DataAttachedListHead); InterlockedDecrement(&pDataStruc->cntDataAttached);
        if(pDataEntry->pIrpLower) {
            IoFreeIrp(pDataEntry->pIrpLower);  pDataEntry->pIrpLower = NULL;
        }
    }

    if(pDataStruc->cntDataAttached == 0) {
        ExFreePool(pDataStruc->pMemoryBlock); pDataStruc->pMemoryBlock = NULL;
        return STATUS_SUCCESS;
    } else {
        TRACE(TL_STRM_ERROR,("FreeQueue: pDataStruc:%x, cntDataAttached:%x\n", pDataStruc, pDataStruc->cntDataAttached));
        ASSERT(pDataStruc->cntDataAttached == 0);
        return STATUS_UNSUCCESSFUL;
    }
}

void
AVCStrmAbortStreamingWorkItemRoutine(
#ifdef USE_WDM110  // Win2000 code base
    // Extra parameter if using WDM10
    PDEVICE_OBJECT DeviceObject,
#endif
    IN PAVC_STREAM_EXTENSION  pAVCStrmExt
    )
/*++

Routine Description:

   This work item routine will stop streaming and cancel all IOs while running at PASSIVE level.

--*/
{
    PAGED_CODE();
    ENTER("AVCStrmAbortStreamingWorkItemRoutine");


    TRACE(TL_STRM_WARNING,("CancelWorkItem: StreamState:%d; lCancel:%d\n", pAVCStrmExt->StreamState, pAVCStrmExt->lAbortToken));
    ASSERT(pAVCStrmExt->lAbortToken == 1);
#ifdef USE_WDM110  // Win2000 code base
    ASSERT(pAVCStrmExt->pIoWorkItem);
#endif

    if(pAVCStrmExt->StreamState == KSSTATE_STOP) {
        ASSERT(pAVCStrmExt->StreamState == KSSTATE_STOP && "CancelWorkItem: Stream is already stopped!\n");
        goto Done;
    }

    // Cancel all pending IOs
    AVCStrmCancelIO(pAVCStrmExt->pDevExt->physicalDevObj, pAVCStrmExt);

Done:

#ifdef USE_WDM110  // Win2000 code base
    // Release work item and release the cancel token
    IoFreeWorkItem(pAVCStrmExt->pIoWorkItem);  pAVCStrmExt->pIoWorkItem = NULL; 
#endif

    // Release token and indicate abort has completed.
    InterlockedExchange(&pAVCStrmExt->lAbortToken, 0);
    KeSetEvent(&pAVCStrmExt->hAbortDoneEvent, 0, FALSE);
}


/*****************************
 * Property utility funcrtions
 *****************************/

NTSTATUS 
AVCStrmGetConnectionProperty(
    IN struct DEVICE_EXTENSION * pDevExt,
    IN PAVC_STREAM_EXTENSION  pAVCStrmExt,
    PSTREAM_PROPERTY_DESCRIPTOR pSPD,
    PULONG pulActualBytesTransferred
    )
/*++

Routine Description:

    Handles KS_PROPERTY_CONNECTION* request.  For now, only ALLOCATORFRAMING and
    CONNECTION_STATE are supported.

--*/
{
    NTSTATUS Status = STATUS_SUCCESS;

    PAGED_CODE();
    ENTER("AVCStrmGetConnectionProperty");


    TRACE(TL_STRM_TRACE,("GetConnectionProperty:  entered ...\n"));

    switch (pSPD->Property->Id) {

    case KSPROPERTY_CONNECTION_ALLOCATORFRAMING:
        if (pDevExt != NULL && pDevExt->NumberOfStreams)  {
            PKSALLOCATOR_FRAMING pFraming = (PKSALLOCATOR_FRAMING) pSPD->PropertyInfo;
            
            pFraming->RequirementsFlags =
                KSALLOCATOR_REQUIREMENTF_SYSTEM_MEMORY |
                KSALLOCATOR_REQUIREMENTF_INPLACE_MODIFIER |
                KSALLOCATOR_REQUIREMENTF_PREFERENCES_ONLY;
            pFraming->PoolType = NonPagedPool;

            pFraming->Frames = \
                pAVCStrmExt->DataFlow == KSPIN_DATAFLOW_OUT ? \
                pAVCStrmExt->pAVCStrmFormatInfo->NumOfRcvBuffers : \
                pAVCStrmExt->pAVCStrmFormatInfo->NumOfXmtBuffers;

            // Note:  we'll allocate the biggest frame.  We need to make sure when we're
            // passing the frame back up we also set the number of bytes in the frame.
            pFraming->FrameSize = pAVCStrmExt->pAVCStrmDataStruc->FrameSize;
            pFraming->FileAlignment = 0; // FILE_LONG_ALIGNMENT;
            pFraming->Reserved = 0;
            *pulActualBytesTransferred = sizeof (KSALLOCATOR_FRAMING);

            TRACE(TL_STRM_TRACE,("*** AllocFraming: cntStrmOpen:%d; Frames %d; size:%d\n", \
                pDevExt->NumberOfStreams, pFraming->Frames, pFraming->FrameSize));
        } else {
            TRACE(TL_STRM_ERROR,("*** AllocFraming: pDevExt:%x; cntStrmOpen:%d\n", pDevExt, pDevExt->NumberOfStreams));
            Status = STATUS_INVALID_PARAMETER;
        }
        break;
        
    default:
        *pulActualBytesTransferred = 0;
        Status = STATUS_NOT_SUPPORTED;
        ASSERT(pSPD->Property->Id == KSPROPERTY_CONNECTION_ALLOCATORFRAMING);
        break;
    }

    TRACE(TL_STRM_TRACE,("GetConnectionProperty:  exit.\n"));
    return Status;
}


NTSTATUS
AVCStrmGetDroppedFramesProperty(  
    IN struct DEVICE_EXTENSION  * pDevExt,
    IN PAVC_STREAM_EXTENSION  pAVCStrmExt,
    PSTREAM_PROPERTY_DESCRIPTOR pSPD,
    PULONG pulBytesTransferred
    )
/*++

Routine Description:

    Return the dropped frame information while captureing.

--*/
{
    NTSTATUS Status = STATUS_SUCCESS;
  
    PAGED_CODE();
    ENTER("AVCStrmGetDroppedFramesProperty");

    switch (pSPD->Property->Id) {

    case KSPROPERTY_DROPPEDFRAMES_CURRENT:
         {

         PKSPROPERTY_DROPPEDFRAMES_CURRENT_S pDroppedFrames = 
                     (PKSPROPERTY_DROPPEDFRAMES_CURRENT_S) pSPD->PropertyInfo;
         
         pDroppedFrames->AverageFrameSize = pAVCStrmExt->pAVCStrmDataStruc->FrameSize;
         pDroppedFrames->PictureNumber    = pAVCStrmExt->pAVCStrmDataStruc->PictureNumber;         
         pDroppedFrames->DropCount        = pAVCStrmExt->pAVCStrmDataStruc->FramesDropped;    // For transmit, this value includes both dropped and repeated.
         TRACE(TL_STRM_TRACE,("*DroppedFP: Pic#(%d), Drp(%d)\n", (LONG) pDroppedFrames->PictureNumber, (LONG) pDroppedFrames->DropCount));
               
         *pulBytesTransferred = sizeof (KSPROPERTY_DROPPEDFRAMES_CURRENT_S);
         Status = STATUS_SUCCESS;
         }
         break;

    default:
        *pulBytesTransferred = 0;
        Status = STATUS_NOT_SUPPORTED;
        ASSERT(pSPD->Property->Id == KSPROPERTY_DROPPEDFRAMES_CURRENT);
        break;
    }

    return Status;
}
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\drivers\wdm\capture\mini\avcstrm\power.c ===
/*++

Copyright (c) 1996  Microsoft Corporation

Module Name:

    power.c

Abstract: NULL filter driver -- boilerplate code

Author:

    ervinp

Environment:

    Kernel mode

Revision History:


--*/

#include <WDM.H>

#include "filter.h"


#ifdef ALLOC_PRAGMA
    #ifdef HANDLE_DEVICE_USAGE
        #pragma alloc_text(PAGEPOWR, VA_Power)
    #endif // HANDLE_DEVICE_USAGE
#endif


NTSTATUS VA_Power(struct DEVICE_EXTENSION *devExt, PIRP irp)
/*++

Routine Description:

    Dispatch routine for Power IRPs (MajorFunction == IRP_MJ_Power)


    Note:
        If HANDLE_DEVICE_USAGE is defined     
     
           This function may or may not be locked down, depending on the lower
           device object and if the device is in the paging path, so we can't
           use the PAGED_CODE() macro.  Furthermore, we can't use PagedPool. 
           
        Otherwise

            This function is left locked down.        

Arguments:

    devExt - device extension for targetted device object
    irp - Io Request Packet

Return Value:

    NT status code

--*/
{
    PIO_STACK_LOCATION irpSp;
    NTSTATUS status;

    irpSp = IoGetCurrentIrpStackLocation(irp);

    TRACE(TL_PNP_WARNING,("VA_Power, minorFunc = %d ", (ULONG)irpSp->MinorFunction)); 


    switch (irpSp->MinorFunction){

        case IRP_MN_SET_POWER:

            switch (irpSp->Parameters.Power.Type) {

                case SystemPowerState:
                    /*
                     *  For system power states, just pass the IRP down.
                     */
                    break;

                case DevicePowerState:

                    switch (irpSp->Parameters.Power.State.DeviceState) {

                        case PowerDeviceD0:
                            /*
                             *  Resume from APM Suspend
                             *
                             *  Do nothing here; 
                             *  Send down the read IRPs in the completion
                             *  routine for this (the power) IRP.
                             */
                            break;

                        case PowerDeviceD1:
                        case PowerDeviceD2:
                        case PowerDeviceD3:
                            /*
                             *  Suspend
                             */
                            if (devExt->state == STATE_STARTED){
                                devExt->state = STATE_SUSPENDED;
                            }
                            break;

                    }
                    break;

            }
            break;

    }


    /*
     *  Send the IRP down the driver stack,
     *  using PoCallDriver (not IoCallDriver, as for non-power irps).
     */
    IncrementPendingActionCount(devExt);
    IoCopyCurrentIrpStackLocationToNext(irp);
    IoSetCompletionRoutine( irp, 
                            VA_PowerComplete, 
                            (PVOID)devExt,  // context
                            TRUE, 
                            TRUE, 
                            TRUE);
    status = PoCallDriver(devExt->topDevObj, irp);



    return status;
}


NTSTATUS VA_PowerComplete(
                            IN PDEVICE_OBJECT devObj, 
                            IN PIRP irp, 
                            IN PVOID context)
/*++

Routine Description:

      Completion routine for Power IRPs (MajorFunction == IRP_MJ_Power)

Arguments:

    devObj - targetted device object
    irp - Io Request Packet
    context - context value passed to IoSetCompletionRoutine by VA_Power

Return Value:

    NT status code

--*/
{
    PIO_STACK_LOCATION irpSp;
    struct DEVICE_EXTENSION *devExt = (struct DEVICE_EXTENSION *)context;

    ASSERT(devExt);
    ASSERT(devExt->signature == DEVICE_EXTENSION_SIGNATURE); 

    /*
     *  If the lower driver returned PENDING, mark our stack location as
     *  pending also.
     */
    if (irp->PendingReturned){
        IoMarkIrpPending(irp);
    }

    irpSp = IoGetCurrentIrpStackLocation(irp);
    ASSERT(irpSp->MajorFunction == IRP_MJ_POWER);

    if (NT_SUCCESS(irp->IoStatus.Status)){
        switch (irpSp->MinorFunction){

            case IRP_MN_SET_POWER:

                switch (irpSp->Parameters.Power.Type){

                    case DevicePowerState:
                        switch (irpSp->Parameters.Power.State.DeviceState){
                            case PowerDeviceD0:
                                if (devExt->state == STATE_SUSPENDED){
                                    devExt->state = STATE_STARTED;
                                }
                                break;
                        }
                        break;

                }
                break;
        }

    }
    
    
    /*
     *  Whether we are completing or relaying this power IRP,
     *  we must call PoStartNextPowerIrp.
     */
    PoStartNextPowerIrp(irp);

    /*
     *  Decrement the pendingActionCount, which we incremented in VA_Power.
     */
    DecrementPendingActionCount(devExt);

    return STATUS_SUCCESS;
}
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\drivers\wdm\capture\mini\bt848\audio.h ===
// $Header: G:/SwDev/WDM/Video/bt848/rcs/Audio.h 1.3 1998/04/29 22:43:26 tomz Exp $

#ifndef __AUDIO_H
#define __AUDIO_H

//---------------------------------------- 
// Audio Source Value definitions
//---------------------------------------- 
#define AUDIO_SOURCE_CDROM            0x00
#define AUDIO_SOURCE_EXTAUDIO         0x01
#define AUDIO_SOURCE_TVTUNER          0x02
#define AUDIO_SOURCE_MUTE             0x03

#endif // __AUDIO_H
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\drivers\wdm\capture\mini\bt848\bt848api.h ===
// $Header: G:/SwDev/WDM/Video/bt848/rcs/Bt848api.h 1.2 1998/04/29 22:43:26 tomz Exp $

#ifndef __BT848API_H
#define __BT848API_H


#ifndef BYTE
   typedef unsigned char       BYTE;
#endif

#include "viddefs.h"
#include "retcode.h"


//===========================================================================
// BT848 DLL API Header File
//===========================================================================

#ifdef __cplusplus
extern "C"
{
#endif

//---------------------------------------------------------------------------
// I2C DATA/CONTROL REGISTER API
//---------------------------------------------------------------------------

/////////////////////////////////////////////////////////////////////////////
//  Method:  bool I2CIsInitOK( void )
//  Purpose: Check if I2C is initialized successfully
//  Input:   None
//  Output:  None
//  Return:  true or false
/////////////////////////////////////////////////////////////////////////////
bool      I2CIsInitOK( void );

/////////////////////////////////////////////////////////////////////////////
//  Method:  ErrorCode I2CInitHWMode( long freq )
//  Purpose: Initialize I2C for hardware control of SCL and SDA
//  Input:   long freq - frequency (hz) to run SCL at
//  Output:  None
//  Return:  None
/////////////////////////////////////////////////////////////////////////////
ErrorCode I2CInitHWMode( long freq );

/////////////////////////////////////////////////////////////////////////////
//  Method:  ErrorCode I2CInitSWMode( long freq )
//  Purpose: Initialize I2C for software control of SCL and SDA
//  Input:   long freq - frequency (hz) to run SCL at
//  Output:  None
//  Return:  None
/////////////////////////////////////////////////////////////////////////////
ErrorCode I2CInitSWMode( long freq );

/////////////////////////////////////////////////////////////////////////////
//  Method:  void I2CSetFreq( long freq )
//  Purpose: Set frequency for SCL
//  Input:   long freq - frequency (hz) to run SCL at. (137.5khz to 2.0625Mhz)
//             PCI frequency 33Mhz: SCL = (412.50Khz to 33.81Khz)
//                           25Mhz: SCL = (312.50Khz to 25.61Khz)
//  Output:  None
//  Return:  None
/////////////////////////////////////////////////////////////////////////////
void      I2CSetFreq( long freq );

/////////////////////////////////////////////////////////////////////////////
//  Method:  int I2CReadDiv( void )
//  Purpose: Obtain value of programmable divider
//  Input:   None
//  Output:  None
//  Return:  Value of programmable divider
/////////////////////////////////////////////////////////////////////////////
int       I2CReadDiv( void );

/////////////////////////////////////////////////////////////////////////////
//  Method:  ErrorCode I2CHWRead( BYTE address, BYTE *value )
//  Purpose: Perform a hardware read from the I2C
//  Input:   int address - address to be read from
//  Output:  int *value  - retrieved value
//  Return:  Success or Fail
/////////////////////////////////////////////////////////////////////////////
ErrorCode I2CHWRead( BYTE address, BYTE *value );

/////////////////////////////////////////////////////////////////////////////
//  Method:  ErrorCode I2CHWWrite2( BYTE address, BYTE value1 )
//  Purpose:  Perform a hardware write of two bytes to the I2C
//  Input:   int address - address to be written to
//           int value1  - value of 2nd byte to be written
//  Output:  None
//  Return:  Success or Fail
/////////////////////////////////////////////////////////////////////////////
ErrorCode I2CHWWrite2( BYTE address, BYTE value1 );

/////////////////////////////////////////////////////////////////////////////
//  Method:  ErrorCode I2CHWWrite3( BYTE address, BYTE value1, BYTE value2 )
//  Purpose: Perform a hardware write of three bytes to the I2C
//  Input:   int address - address to be written to
//           int value1  - value of 2nd byte to be written
//           int value2  - value of 3rd byte to be written
//  Output:  None
//  Return:  Success or Fail
/////////////////////////////////////////////////////////////////////////////
ErrorCode I2CHWWrite3( BYTE address, BYTE value1, BYTE value2 );

/////////////////////////////////////////////////////////////////////////////
//  Method:  ErrorCode I2CSetSync( State sync )
//  Purpose: Set I2C sync value
//  Input:   sync: On  - allow slave to insert wait states
//                 Off - slave cannot insert wait states
//  Output:  None
//  Return:  Success or Fail
/////////////////////////////////////////////////////////////////////////////
ErrorCode I2CSetSync( State sync );

/////////////////////////////////////////////////////////////////////////////
//  Method:  int I2CReadSync( void )
//  Purpose: Read I2C sync value
//  Input:   None
//  Output:  None
//  Return:  Sync value
/////////////////////////////////////////////////////////////////////////////
int       I2CReadSync( void );

/////////////////////////////////////////////////////////////////////////////
//  Method:  int I2CGetLastError( void )
//  Purpose: Obtain last error number
//  Input:   None
//  Output:  None
//  Return:  Last error number
/////////////////////////////////////////////////////////////////////////////
int       I2CGetLastError( void );


#ifdef __cplusplus
}
#endif

#endif // __BT848API_H
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\drivers\wdm\capture\mini\bt848\capdebug.h ===
// $Header: G:/SwDev/WDM/Video/bt848/rcs/Capdebug.h 1.9 1998/05/07 15:23:25 tomz Exp $

//==========================================================================;
//
//  THIS CODE AND INFORMATION IS PROVIDED "AS IS" WITHOUT WARRANTY OF ANY
//  KIND, EITHER EXPRESSED OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE
//  IMPLIED WARRANTIES OF MERCHANTABILITY AND/OR FITNESS FOR A PARTICULAR
//  PURPOSE.
//
//  Copyright (c) 1992 - 1996  Microsoft Corporation.  All Rights Reserved.
//
//==========================================================================;


#ifndef __CAPDEBUG_H
#define __CAPDEBUG_H

#ifdef __cplusplus
extern "C" {
#endif

   #include <stdio.h>

#ifdef __cplusplus
}
#endif

#if DBG
   extern "C" void MyDebugPrint(long DebugPrintLevel, char * DebugMessage, ... );
   #define  DebugOut(x) MyDebugPrint x
   #define TRACE_CALLS  0
#else
   #define  DebugOut(x)
   #define TRACE_CALLS  0
#endif

#define DUMP(v) DebugOut((0, "--- " #v " = %d\n", v));
#define DUMPX(v) DebugOut((0, "--- " #v " = 0x%x\n", v));
   
#if TRACE_CALLS
   class Trace {
   public:
      char    *psz;       // string to be printed
      Trace(char *pszFunc);
      ~Trace();
   };
#else
   class Trace {
   public:
      Trace(char *pszFunc) {};
      ~Trace() {};
   };
#endif

#endif // __CAPDEBUG_H
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\drivers\wdm\capture\mini\bt848\bti2c.h ===
// $Header: G:/SwDev/WDM/Video/bt848/rcs/Bti2c.h 1.4 1998/04/29 22:43:27 tomz Exp $

#ifndef __I2C_H
#define __I2C_H

#include "regField.h"
#include "viddefs.h"
#include "retcode.h"
#include "i2cerr.h"


//#define HAUPPAUGEI2CPROVIDER


#ifdef HAUPPAUGEI2CPROVIDER
//	#include "hcwWDM.h"

// Need to define for brooktree i2c calls
/* Type: Level
 * Purpose: used to define a pin state
 */
typedef enum { LevelLow, LevelHi } Level;

#endif

/////////////////////////////////////////////////////////////////////////////
// CLASS I2C
//
// Description:
//    This class encapsulates the register fields in the I2C register of the
//    Bt848. A complete set of functions are developed to manipulate all the
//    register fields in the I2C for the Bt848.
//
/////////////////////////////////////////////////////////////////////////////

class I2C
{
private:
   // define which mode the I2C is selected
   enum I2CMode { I2CMode_None, I2CMode_HW, I2CMode_SW };
   
   bool    initOK;      // initialization is successful?
   DWORD   cycle;       // software control of frequency
   int     errNum;      // error number
   I2CMode mode;        // which mode the I2C is running in

//**************************************************************************
//	Structures
//**************************************************************************
union shadow
{
   struct _i2c_reg    // I2C register structure
   {
      unsigned int sda:1;
      unsigned int scl:1;
      unsigned int w3b:1;
      unsigned int sync:1;
      unsigned int div:4;
      unsigned int byte2:8;
      unsigned int byte1:8;
      unsigned int addr_rw:8;
   } i2cShadow;
   DWORD Initer;
} sh;

protected:
   RegisterDW decRegINT_STAT;
   RegField decFieldI2CDONE;
   RegField decFieldRACK;
   RegisterDW decRegI2C;
   RegField decFieldI2CDB0;
   RegField decFieldI2CDB1;
   RegField decFieldI2CDB2;
   RegField decFieldI2CDIV;
   RegField decFieldSYNC;
   RegField decFieldW3B;
   RegField decFieldSCL;
   RegField decFieldSDA;

public:
   // constructor and destructor
	I2C( void );
	~I2C();

   // member functions
   bool      IsInitOK( void );
#ifdef	HARDWAREI2C
   ErrorCode I2CInitHWMode( long freq );
   int       I2CReadDiv( void );
   ErrorCode I2CHWRead( BYTE address, BYTE *value );
   ErrorCode I2CHWWrite2( BYTE address, BYTE value1 );
   ErrorCode I2CHWWrite3( BYTE address, BYTE value1, BYTE value2 );
   ErrorCode I2CSetSync( State );
   int       I2CReadSync( void );
#endif
   void      I2CSetFreq( long freq );
   int       I2CGetLastError( void );
#ifdef HAUPPAUGEI2CPROVIDER
   ErrorCode I2CInitSWMode( long freq );
   ErrorCode I2CSWStart( void );
   ErrorCode I2CSWStop( void );
   ErrorCode I2CSWRead( BYTE * value );
   ErrorCode I2CSWWrite( BYTE value );
   ErrorCode I2CSWSendACK( void );
   ErrorCode I2CSWSendNACK( void );
   ErrorCode I2CSWSetSCL( Level );
   int       I2CSWReadSCL( void );
   ErrorCode I2CSWSetSDA( Level );
   int       I2CSWReadSDA( void );
#endif

private:
   void      I2CResetShadow( void );      // reset register shadow
   ErrorCode I2CHWWaitUntilDone( int );   // wait until I2C completes operation
   bool      I2CHWIsDone( void );         // check interrupt bit for operation done
   bool      I2CHWReceivedACK( void );    // check interrupt bit for received ACK
   void      I2CSWBitDelay( void );       // insert delay to simulate frequency
   ErrorCode I2CSWWaitForACK( void );     // wait for ACK from receiver using software
};


#endif // __I2C_H
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\drivers\wdm\capture\mini\bt848\bt848api.cpp ===
// $Header: G:/SwDev/WDM/Video/bt848/rcs/Bt848api.cpp 1.2 1998/04/29 22:43:26 tomz Exp $

#include "device.h"
#include "audio.h"


void PsDevice::EnableAudio( State s )
{
   SetGPOE( 0x0000000FL );
   if ( s == On )
      SetGPDATABits( 0, 1, AUDIO_SOURCE_TVTUNER, 0 );
   else
      SetGPDATABits( 0, 1, AUDIO_SOURCE_EXTAUDIO, 0 );
}      

/////////////////////////////////////////////////////////////////////////////
// I2C DATA/CONTROL REGISTER API
/////////////////////////////////////////////////////////////////////////////

bool PsDevice::I2CIsInitOK( void )
{
   return i2c.IsInitOK();
}

#ifdef	HARDWAREI2C
//---------------------------------------------------------------------------
ErrorCode PsDevice::I2CInitHWMode( long freq )
{
   return i2c.I2CInitHWMode( freq );
}

//---------------------------------------------------------------------------
void PsDevice::I2CSetFreq( long freq )
{
   i2c.I2CSetFreq( freq );
}

//---------------------------------------------------------------------------
int PsDevice::I2CReadDiv( void )
{
   return i2c.I2CReadDiv();
}

//---------------------------------------------------------------------------
ErrorCode PsDevice::I2CHWRead( BYTE address, BYTE *value )
{
   return i2c.I2CHWRead( address, value );
}

//---------------------------------------------------------------------------
ErrorCode PsDevice::I2CHWWrite2( BYTE address, BYTE value1 )
{
   return i2c.I2CHWWrite2( address, value1 );
}

//---------------------------------------------------------------------------
ErrorCode PsDevice::I2CHWWrite3( BYTE address, BYTE value1, BYTE value2 )
{
   return i2c.I2CHWWrite3( address, value1, value2 );
}

//---------------------------------------------------------------------------
int PsDevice::I2CReadSync( void )
{
   return i2c.I2CReadSync();
}

#endif

//---------------------------------------------------------------------------
int PsDevice::I2CGetLastError( void )
{
   return i2c.I2CGetLastError();
}

#ifdef HAUPPAUGEI2CPROVIDER
ErrorCode PsDevice::I2CInitSWMode( long freq )
{
   return i2c.I2CInitSWMode( freq );
}

ErrorCode PsDevice::I2CSWStart( void )
{
   return i2c.I2CSWStart();
}

ErrorCode PsDevice::I2CSWStop( void )
{
   return i2c.I2CSWStop();
}
 
ErrorCode PsDevice::I2CSWRead( BYTE * value )
{
   return i2c.I2CSWRead( value );
}

ErrorCode PsDevice::I2CSWWrite( BYTE value )
{
   return i2c.I2CSWWrite( value );
}

ErrorCode PsDevice::I2CSWSendACK( void )
{
   return i2c.I2CSWSendACK();
}

ErrorCode PsDevice::I2CSWSendNACK( void )
{
   return i2c.I2CSWSendNACK();
}

//   ErrorCode PsDevice::I2CSWSetSCL( Level );
//   int       PsDevice::I2CSWReadSCL( void );
//   ErrorCode PsDevice::I2CSWSetSDA( Level );
//   int       PsDevice::I2CSWReadSDA( void );

#endif

/////////////////////////////////////////////////////////////////////////////
// GPIO, GPOE, GPIE, and GPDATA REGISTER API
/////////////////////////////////////////////////////////////////////////////

bool PsDevice::GPIOIsInitOK( void )
{
   return gpio.IsInitOK();
}

//---------------------------------------------------------------------------
void PsDevice::SetGPCLKMODE( State s )
{
   gpio.SetGPCLKMODE( s );
}

//---------------------------------------------------------------------------
int PsDevice::GetGPCLKMODE( void )
{
   return gpio.GetGPCLKMODE();
}

//---------------------------------------------------------------------------
void PsDevice::SetGPIOMODE( GPIOMode mode )
{
   gpio.SetGPIOMODE( mode );
}

//---------------------------------------------------------------------------
int PsDevice::GetGPIOMODE( void )
{
   return gpio.GetGPIOMODE();
}

//---------------------------------------------------------------------------
void PsDevice::SetGPWEC( State s )
{
   gpio.SetGPWEC( s );
}

//---------------------------------------------------------------------------
int PsDevice::GetGPWEC( void )
{
   return gpio.GetGPWEC();
}

//---------------------------------------------------------------------------
void PsDevice::SetGPINTI( State s )
{
   gpio.SetGPINTI( s );
}

//---------------------------------------------------------------------------
int PsDevice::GetGPINTI( void )
{
   return gpio.GetGPINTI();
}

//---------------------------------------------------------------------------
void PsDevice::SetGPINTC( State s )
{
   gpio.SetGPINTC( s );
}

//---------------------------------------------------------------------------
int PsDevice::GetGPINTC( void )
{
   return gpio.GetGPINTC();
}

//---------------------------------------------------------------------------
ErrorCode PsDevice::SetGPOEBit( int bit, State s )
{
   return gpio.SetGPOE( bit, s );
}

//---------------------------------------------------------------------------
void PsDevice::SetGPOE( DWORD value )
{
   gpio.SetGPOE( value );
}

//---------------------------------------------------------------------------
int PsDevice::GetGPOEBit( int bit )
{
   return gpio.GetGPOE( bit );
}

//---------------------------------------------------------------------------
DWORD PsDevice::GetGPOE( void )
{
   return gpio.GetGPOE();
}

//---------------------------------------------------------------------------
ErrorCode PsDevice::SetGPIEBit( int bit , State s )
{
   return gpio.SetGPIE( bit, s );
}

//---------------------------------------------------------------------------
void PsDevice::SetGPIE( DWORD value )
{
   gpio.SetGPIE( value );
}

//---------------------------------------------------------------------------
int PsDevice::GetGPIEBit( int bit )
{
   return gpio.GetGPIE( bit );
}

//---------------------------------------------------------------------------
DWORD PsDevice::GetGPIE( void )
{
   return gpio.GetGPIE();
}

//---------------------------------------------------------------------------
ErrorCode PsDevice::SetGPDATA( GPIOReg *data, int size, int offset )
{
   return gpio.SetGPDATA( data, size, offset );
}

//---------------------------------------------------------------------------
ErrorCode PsDevice::GetGPDATA( GPIOReg *data, int size, int offset )
{
   return gpio.GetGPDATA( data, size, offset );
}

//---------------------------------------------------------------------------
ErrorCode PsDevice::SetGPDATABits( int fromBit, int toBit, DWORD value, int offset )
{
   return gpio.SetGPDATA( fromBit, toBit, value, offset );
}

//---------------------------------------------------------------------------
ErrorCode PsDevice::GetGPDATABits( int fromBit, int toBit, DWORD *value, int offset )
{
   return gpio.GetGPDATA( fromBit, toBit, value, offset );
}
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\drivers\wdm\capture\mini\bt848\capmain.c ===
// $Header: G:/SwDev/WDM/Video/bt848/rcs/Capmain.c 1.19 1998/05/11 23:59:54 tomz Exp $

//==========================================================================;
//
//  THIS CODE AND INFORMATION IS PROVIDED "AS IS" WITHOUT WARRANTY OF ANY
//  KIND, EITHER EXPRESSED OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE
//  IMPLIED WARRANTIES OF MERCHANTABILITY AND/OR FITNESS FOR A PARTICULAR
//  PURPOSE.
//
//  Copyright (c) 1992 - 1996  Microsoft Corporation.  All Rights Reserved.
//
//==========================================================================;

#define INITGUID
#define BT848_MEDIUMS

#ifdef __cplusplus
extern "C" {
#endif
#include "strmini.h"
#include "ksmedia.h"
#ifdef __cplusplus
}
#endif

#include "device.h"
#include "capmain.h"
#include "capstrm.h"
#include "capdebug.h"
#include "capprop.h"

LONG  PinTypes_ [MaxInpPins]; // just allocate maximum possible
DWORD xtals_ [2]; // no more than 2 xtals

extern PsDevice *gpPsDevice;
extern BYTE     *gpjBaseAddr;
extern VOID     *gpHwDeviceExtension;

void AdapterFormatFromRange( IN PHW_STREAM_REQUEST_BLOCK pSrb );
VOID ReadRegistryValues( IN PDEVICE_OBJECT PhysicalDeviceObject );
inline void CompleteDeviceSRB( IN OUT PHW_STREAM_REQUEST_BLOCK pSrb );

extern DWORD GetSizeHwDeviceExtension( );
extern DWORD GetSizeStreamEx( );
extern PsDevice *GetCurrentDevice( );
extern void SetCurrentDevice( PsDevice *dev );

extern BYTE *GetBase();
extern void SetBase(BYTE *base);

PHW_STREAM_REQUEST_BLOCK StreamIdxToSrb[4];

void CheckSrbStatus( PHW_STREAM_REQUEST_BLOCK pSrb )
{
   VideoStream StreamNumber = (VideoStream)pSrb->StreamObject->StreamNumber;

   DebugOut((1, "  *** completing pSrb(%x) strm(%d) status(%x)\n", pSrb, StreamNumber, pSrb->Status ));

   switch ( pSrb->Status )
   {
   case STATUS_SUCCESS:
   case STATUS_CANCELLED:
      break;
   default:
      DebugOut((0, "*** pSrb->Status = %x\n", pSrb->Status ));
      DEBUG_BREAKPOINT();
   }
}

/* Function: GetRequestedSize
 * Purpose: Figures out what the image size should be
 * Input: vidHdr: KS_VIDEOINFOHEADER &
 *   size: MSize &
 * Output: None
*/
void GetRequestedSize2( const KS_VIDEOINFOHEADER2 &vidHdr, MSize &size )
{
   Trace t("GetRequestedSize()");

   size.Set( vidHdr.bmiHeader.biWidth, abs(vidHdr.bmiHeader.biHeight) );

   MRect dst( vidHdr.rcTarget );
   // if writing to a DD surface maybe ?
   if ( !dst.IsNull() && !dst.IsEmpty() )
      size.Set( dst.Width(), dst.Height() );
}

void GetRequestedSize( const KS_VIDEOINFOHEADER &vidHdr, MSize &size )
{
   Trace t("GetRequestedSize()");

   size.Set( vidHdr.bmiHeader.biWidth, abs(vidHdr.bmiHeader.biHeight) );

   MRect dst( vidHdr.rcTarget );
   // if writing to a DD surface maybe ?
   if ( !dst.IsNull() && !dst.IsEmpty() )
      size.Set( dst.Width(), dst.Height() );
}

/* Function: VerifyVideoStream
 * Purpose: Checks the paramaters passed in for opening steam
 * Input: vidHDR: KS_DATAFORMAT_VIDEOINFOHEADER
 * Output: Success or Fail
 */
ErrorCode VerifyVideoStream( const KS_DATAFORMAT_VIDEOINFOHEADER &vidHDR )
{
   Trace t("VerifyVideoStream()");

   // [WRK] - add guid for VideoInfoHeader2

   // simply verify that major and format are of video nature...
   if ( IsEqualGUID( vidHDR.DataFormat.MajorFormat, KSDATAFORMAT_TYPE_VIDEO ) &&
        IsEqualGUID( vidHDR.DataFormat.Specifier, KSDATAFORMAT_SPECIFIER_VIDEOINFO ) ) {

      MSize size;
      GetRequestedSize( vidHDR.VideoInfoHeader, size );
      // ... and here see if the subtype is one of those supported by us
      ColorSpace tmpCol( vidHDR.DataFormat.SubFormat );
      MRect dst( vidHDR.VideoInfoHeader.rcTarget );

      // make sure the dimentions are acceptable
      if ( tmpCol.IsValid() && tmpCol.CheckDimentions( size ) &&
         tmpCol.CheckLeftTop( dst.TopLeft() ) ) {
         DebugOut((1, "VerifyVideoStream succeeded\n"));
         return Success;
      }
   }
   DebugOut((0, "VerifyVideoStream failed\n"));
   return Fail;
}

ErrorCode VerifyVideoStream2( const KS_DATAFORMAT_VIDEOINFOHEADER2 &vidHDR )
{
   Trace t("VerifyVideoStream2()");

   // [WRK] - add guid for VideoInfoHeader2

   // simply verify that major and format are of video nature...
   if ( IsEqualGUID( vidHDR.DataFormat.MajorFormat, KSDATAFORMAT_TYPE_VIDEO ) &&
        IsEqualGUID( vidHDR.DataFormat.Specifier, KSDATAFORMAT_SPECIFIER_VIDEOINFO2 ) ) {

      MSize size;
      GetRequestedSize2( vidHDR.VideoInfoHeader2, size );
      // ... and here see if the subtype is one of those supported by us
      ColorSpace tmpCol( vidHDR.DataFormat.SubFormat );
      MRect dst( vidHDR.VideoInfoHeader2.rcTarget );

      // make sure the dimentions are acceptable
      if ( tmpCol.IsValid() && tmpCol.CheckDimentions( size ) &&
         tmpCol.CheckLeftTop( dst.TopLeft() ) ) {
         DebugOut((1, "VerifyVideoStream2 succeeded\n"));
         return Success;
      }
   }
   DebugOut((0, "VerifyVideoStream2 failed\n"));
   return Fail;
}

/* Function: VerifyVBIStream
 * Purpose: Checks that VBI stream info during open is correct
 * Input: rKSDataFormat: KS_DATAFORMAT &
 * Output: ErrorCode
 */
ErrorCode VerifyVBIStream( const KS_DATAFORMAT_VBIINFOHEADER &rKSDataFormat )
{
   Trace t("VerifyVBIStream()");

   if ( IsEqualGUID( rKSDataFormat.DataFormat.MajorFormat, KSDATAFORMAT_TYPE_VBI ) &&
        IsEqualGUID( rKSDataFormat.DataFormat.Specifier,
        KSDATAFORMAT_SPECIFIER_VBI ) &&
        rKSDataFormat.VBIInfoHeader.StartLine == VBIStart &&
        rKSDataFormat.VBIInfoHeader.EndLine   == VBIEnd   &&
        rKSDataFormat.VBIInfoHeader.SamplesPerLine == VBISamples )
      return Success;
   return Fail;
}

/*
** DriverEntry()
**
**   This routine is called when an SRB_INITIALIZE_DEVICE request is received
**
** Arguments:
**
**   Context1 and Context2
**
** Returns:
**
**   Results of StreamClassRegisterAdapter()
**
** Side Effects:  none
*/

extern "C" ULONG DriverEntry( PVOID Arg1, PVOID Arg2 )
{
   Trace t("DriverEntry()");

   //
   // Entry points for Port Driver
   //
   HW_INITIALIZATION_DATA  HwInitData;
   RtlZeroMemory( &HwInitData, sizeof( HwInitData ));
   HwInitData.HwInitializationDataSize = sizeof( HwInitData );

   HwInitData.HwInterrupt              = (PHW_INTERRUPT)&HwInterrupt;

   HwInitData.HwReceivePacket          = &AdapterReceivePacket;
   HwInitData.HwCancelPacket           = &AdapterCancelPacket;
   HwInitData.HwRequestTimeoutHandler  = &AdapterTimeoutPacket;

   HwInitData.DeviceExtensionSize      = GetSizeHwDeviceExtension( );
   HwInitData.PerRequestExtensionSize  = sizeof(SRB_EXTENSION);
   HwInitData.FilterInstanceExtensionSize = 0;
   // double to support alternating/interleaved
   HwInitData.PerStreamExtensionSize   = GetSizeStreamEx( );
   HwInitData.BusMasterDMA             = true;
   HwInitData.Dma24BitAddresses        = FALSE;
   HwInitData.BufferAlignment          = 4;
   HwInitData.TurnOffSynchronization   = FALSE;
   HwInitData.DmaBufferSize            = RISCProgramsSize;

   return (StreamClassRegisterAdapter(Arg1, Arg2,&HwInitData));
}

/******************************************************************************

                   Adapter Based Request Handling Routines

******************************************************************************/
/*
** HwInitialize()
**
**   This routine is called when an SRB_INITIALIZE_DEVICE request is received
**
** Arguments:
**
**   pSrb - pointer to stream request block for the Initialize command
**
** Returns:
**
** Side Effects:  none
*/
BOOLEAN HwInitialize( IN OUT PHW_STREAM_REQUEST_BLOCK pSrb )
{
   Trace t("HwInitialize()");

   DebugOut((1, "HwInitialize()\n"));

   // initialize ourselves

   PPORT_CONFIGURATION_INFORMATION ConfigInfo = 
      pSrb->CommandData.ConfigInfo;

   gpHwDeviceExtension = ConfigInfo->HwDeviceExtension;
   DebugOut((0, "*** gpHwDeviceExtension = %x\n", gpHwDeviceExtension));

   PHW_DEVICE_EXTENSION HwDeviceExtension =
      (PHW_DEVICE_EXTENSION) gpHwDeviceExtension;

   DWORD dwBase = ConfigInfo->AccessRanges[0].RangeStart.LowPart;
   SetBase((BYTE *)dwBase);

   if ( ConfigInfo->NumberOfAccessRanges != 1 ) {
      DebugOut((1, "illegal config info\n"));
      pSrb->Status = STATUS_NO_SUCH_DEVICE;
   }

   // read info from the registry
   ReadXBarRegistryValues( ConfigInfo->PhysicalDeviceObject );
   ReadXTalRegistryValues( ConfigInfo->PhysicalDeviceObject );
   ReadTunerRegistryValues( ConfigInfo->PhysicalDeviceObject );

   HwDeviceExtension->psdevice =
      new ( &(HwDeviceExtension->psdevicemem) ) PsDevice( dwBase );

   DebugOut((0, "psdevice = %x\n", HwDeviceExtension->psdevice ));
   DebugOut((0, "&psdevicemem = %x\n", &HwDeviceExtension->psdevicemem ));

   PsDevice *adapter = HwDeviceExtension->psdevice;

   // save for later use when phys address if obtained
   SetCurrentDevice( adapter );

   // make sure initialization is successful
   if ( !adapter->InitOK() ) {
      DebugOut((1, "Error initializing\n"));
      pSrb->Status = STATUS_INSUFFICIENT_RESOURCES;
   }

   // save our PDO
   adapter->PDO = ConfigInfo->PhysicalDeviceObject;

   ConfigInfo->StreamDescriptorSize = sizeof( HW_STREAM_HEADER ) +
      DRIVER_STREAM_COUNT * sizeof( HW_STREAM_INFORMATION );

   DebugOut((1, "Exit : HwInitialize()\n"));

   // go to usual priority, completing the SRB at the same time
   StreamClassCallAtNewPriority( pSrb->StreamObject, HwDeviceExtension, LowToHigh,
      PHW_PRIORITY_ROUTINE( CompleteDeviceSRB ), pSrb );

   return (TRUE);
}

/*
** HwUnInitialize()
**
**   This routine is called when an SRB_UNINITIALIZE_DEVICE request is received
**
** Arguments:
**
**   pSrb - pointer to stream request block for the UnInitialize command
**
** Returns:
**
** Side Effects:  none
*/
void HwUnInitialize( IN PHW_STREAM_REQUEST_BLOCK pSrb )
{
   Trace t("HwUnInitialize()");

   PHW_DEVICE_EXTENSION HwDeviceExtension =
      (PHW_DEVICE_EXTENSION) pSrb->HwDeviceExtension;

   DebugOut((0, "HwUnInitialize - pSrb(%x)\n", pSrb));

   PsDevice *adapter = HwDeviceExtension->psdevice;
   adapter->~PsDevice();
}

/*
** AdapterOpenStream()
**
**   This routine is called when an OpenStream SRB request is received
**
** Arguments:
**
**   pSrb - pointer to stream request block for the Open command
**
** Returns:
**
** Side Effects:  none
*/

VOID AdapterOpenStream( IN PHW_STREAM_REQUEST_BLOCK pSrb )
{
   Trace t("AdapterOpenStream()");

   //
   // the stream extension structure is allocated by the stream class driver
   //

   // retrieve the device object pointer
   PHW_DEVICE_EXTENSION HwDeviceExtension =
      (PHW_DEVICE_EXTENSION) pSrb->HwDeviceExtension;

   PsDevice *adapter = HwDeviceExtension->psdevice;

   VideoStream StreamNumber = (VideoStream)pSrb->StreamObject->StreamNumber;
   StreamIdxToSrb[StreamNumber] = pSrb;

   DebugOut((1, "AdapterOpenStream(%d) - pSrb(%x)\n", StreamNumber, pSrb));

   // [STRM] [!!!]
   //if ( !( StreamNumber >= VS_Field1 && StreamNumber <= DRIVER_STREAM_COUNT ) ) {
   //   pSrb->Status = STATUS_INVALID_PARAMETER; // ?change to the proper error code?
   //   return;
   //}
   
   if ( StreamNumber == STREAM_IDX_ANALOG )   // [TMZ] [!!] was 3
   {
      pSrb->StreamObject->ReceiveDataPacket    = AnalogReceiveDataPacket;
      pSrb->StreamObject->ReceiveControlPacket = AnalogReceiveCtrlPacket;
      return; // nothing to do for the analog stream
   }
   PSTREAMEX pStrmEx = (PSTREAMEX)pSrb->StreamObject->HwStreamExtension;
   RtlZeroMemory( &pStrmEx->FrameInfo, sizeof( pStrmEx->FrameInfo ) );
   pStrmEx->StreamNumber = StreamNumber;

   // size of the media specific data
   UINT MediaSpecific = sizeof( KS_FRAME_INFO );

   // Always open VBI stream as Alternating fields
   if ( StreamNumber == STREAM_IDX_VBI ) 
	{
      const KS_DATAFORMAT_VBIINFOHEADER &rKSVBIDataFormat =
         *(PKS_DATAFORMAT_VBIINFOHEADER) pSrb->CommandData.OpenFormat;

      if ( VerifyVBIStream( rKSVBIDataFormat ) != Success )
		{
         DebugOut((0, "*** VerifyVBIStream failed - aborting\n"));
         pSrb->Status = STATUS_INVALID_PARAMETER; // ?change to the proper error code?
         return;
      }
      if ( adapter->OpenVBIChannel( pStrmEx ) != Success )
      {
         DebugOut((0, "*** OpenVBIChannel failed - aborting\n"));
         pSrb->Status = STATUS_INVALID_PARAMETER; // ?change to the proper error code?
         return;
      }

      VBIAlterChannel *chan = (VBIAlterChannel *)pStrmEx->videochannel;
      //chan->pStrmEx = pStrmEx;
      chan->SetVidHdr( rKSVBIDataFormat );

      MediaSpecific = sizeof( KS_VBI_FRAME_INFO );

   } 
	else 
	{

      // is it where the size, fourcc, etc. are specified ? they should be settable
      // via properies sets
      const KS_DATAFORMAT_VIDEOINFOHEADER &rKSDataFormat = *(PKS_DATAFORMAT_VIDEOINFOHEADER) pSrb->CommandData.OpenFormat;
      const KS_VIDEOINFOHEADER &rVideoInfoHdrRequested = rKSDataFormat.VideoInfoHeader;
      const KS_DATAFORMAT_VIDEOINFOHEADER2 &rKSDataFormat2 = *(PKS_DATAFORMAT_VIDEOINFOHEADER2) pSrb->CommandData.OpenFormat;
      const KS_VIDEOINFOHEADER2 &rVideoInfoHdrRequested2 = rKSDataFormat2.VideoInfoHeader2;

      DebugOut((1, "AdapterOpenStream\n"));
      if ( IsEqualGUID( rKSDataFormat.DataFormat.Specifier, KSDATAFORMAT_SPECIFIER_VIDEOINFO ) ) 
		{
			DebugOut((1, "StreamNumber=%d\n", pSrb->StreamObject->StreamNumber));
			DebugOut((1, "FormatSize=%d\n", rKSDataFormat.DataFormat.FormatSize));
			DebugOut((1, "MajorFormat=%x\n", rKSDataFormat.DataFormat.MajorFormat));
			DebugOut((1, "pVideoInfoHdrRequested=%x\n", &rVideoInfoHdrRequested));
			DebugOut((1, "Bpp =%d\n", rVideoInfoHdrRequested.bmiHeader.biBitCount ) );
			DebugOut((1, "Width =%d\n", rVideoInfoHdrRequested.bmiHeader.biWidth));
			DebugOut((1, "Height =%d\n", rVideoInfoHdrRequested.bmiHeader.biHeight));
			DebugOut((1, "biSizeImage =%d\n", rVideoInfoHdrRequested.bmiHeader.biSizeImage));
			if ( VerifyVideoStream( rKSDataFormat ) != Success ) 
			{
				pSrb->Status = STATUS_INVALID_PARAMETER; // ?change to the proper error code?
				return;
			}
		}
		else
		{
			DebugOut((1, "StreamNumber=%d\n", pSrb->StreamObject->StreamNumber));
			DebugOut((1, "FormatSize=%d\n", rKSDataFormat2.DataFormat.FormatSize));
			DebugOut((1, "MajorFormat=%x\n", rKSDataFormat2.DataFormat.MajorFormat));
			DebugOut((1, "pVideoInfoHdrRequested2=%x\n", &rVideoInfoHdrRequested2));
			DebugOut((1, "Bpp =%d\n", rVideoInfoHdrRequested2.bmiHeader.biBitCount ) );
			DebugOut((1, "Width =%d\n", rVideoInfoHdrRequested2.bmiHeader.biWidth));
			DebugOut((1, "Height =%d\n", rVideoInfoHdrRequested2.bmiHeader.biHeight));
			DebugOut((1, "biSizeImage =%d\n", rVideoInfoHdrRequested2.bmiHeader.biSizeImage));
			if ( VerifyVideoStream2( rKSDataFormat2 ) != Success ) 
			{
				pSrb->Status = STATUS_INVALID_PARAMETER; // ?change to the proper error code?
				return;
			}
		}

      // at this point have to see what type of channel is to be opened:
      // single field, alternating or interleaved
      // algorithm is like this:
      // 1. look at the video format Specifier guid. If it's a infoheader2, it
      //    will tell us type of stream to open.
      // 2. else look at the vertical size to decide single field vs. interleaved

      if ( IsEqualGUID( rKSDataFormat.DataFormat.Specifier, KSDATAFORMAT_SPECIFIER_VIDEOINFO ) ) 
		{

         MSize size;

         GetRequestedSize( rVideoInfoHdrRequested, size );

         // different video standards have different vertical sizes
         int threshold = adapter->GetFormat() == VFormat_NTSC ? 240 : 288;

         if ( size.cy > threshold ) 
			{
            if ( adapter->OpenInterChannel( pStrmEx, StreamNumber ) != Success ) 
				{
               pSrb->Status = STATUS_INVALID_PARAMETER; // ?change to the proper error code?
               return;
            }
         } 
			else 
			{
            if ( adapter->OpenChannel( pStrmEx, StreamNumber ) != Success ) 
				{
               pSrb->Status = STATUS_INVALID_PARAMETER; // ?change to the proper error code?
               return;
            }
         }
			VideoChannel *chan = (VideoChannel *)pStrmEx->videochannel;
         //chan->pStrmEx = pStrmEx;
			chan->SetVidHdr( rVideoInfoHdrRequested );
      }
      else if ( IsEqualGUID( rKSDataFormat2.DataFormat.Specifier, KSDATAFORMAT_SPECIFIER_VIDEOINFO2 ) ) 
		{
         MSize size;
         GetRequestedSize2( rVideoInfoHdrRequested2, size );

         // different video standards have different vertical sizes
         int threshold = adapter->GetFormat() == VFormat_NTSC ? 240 : 288;

         if ( size.cy > threshold ) 
			{
            if ( adapter->OpenInterChannel( pStrmEx, StreamNumber ) != Success ) 
				{
               pSrb->Status = STATUS_INVALID_PARAMETER; // ?change to the proper error code?
               return;
            }
         } 
			else 
			{
            if ( adapter->OpenChannel( pStrmEx, StreamNumber ) != Success ) 
				{
               pSrb->Status = STATUS_INVALID_PARAMETER; // ?change to the proper error code?
               return;
            }
         }
			VideoChannel *chan = (VideoChannel *)pStrmEx->videochannel;
         //chan->pStrmEx = pStrmEx;
			chan->SetVidHdr2( rVideoInfoHdrRequested2 );
      } 
		else 
		{
         if ( adapter->OpenInterChannel( pStrmEx, StreamNumber ) != Success ) 
			{
            pSrb->Status = STATUS_INVALID_PARAMETER; // ?change to the proper error code?
            return;
         }
         if ( adapter->OpenAlterChannel( pStrmEx, StreamNumber ) != Success ) 
			{
            pSrb->Status = STATUS_INVALID_PARAMETER; // ?change to the proper error code?
            return;
         }
         // [WRK] - check the height of the image for alter channel !> threshold
			VideoChannel *chan = (VideoChannel *)pStrmEx->videochannel;
         //chan->pStrmEx = pStrmEx;
			chan->SetVidHdr( rVideoInfoHdrRequested );
      }
   }

#ifdef ENABLE_DDRAW_STUFF
	//TODO: should we check to see what kind of stream type this is?
	if( OpenKernelDirectDraw( pSrb ) )
	{
		OpenKernelDDrawSurfaceHandle( pSrb );
		RegisterForDirectDrawEvents( pSrb ); 
	}
#endif

   // the structure of the driver is such that a single callback could be used
   // for all stream requests. But the code below could be used to supply
   // different entry points for different streams
   pSrb->StreamObject->ReceiveDataPacket    = VideoReceiveDataPacket;
   pSrb->StreamObject->ReceiveControlPacket = VideoReceiveCtrlPacket;

   pSrb->StreamObject->Dma = true;

   pSrb->StreamObject->Allocator = Streams[StreamNumber].hwStreamObject.Allocator;

   //
   // The PIO flag must be set when the mini driver will be accessing the data
   // buffers passed in using logical addressing
   //

   pSrb->StreamObject->Pio = true;
   pSrb->StreamObject->StreamHeaderMediaSpecific = MediaSpecific;
   pSrb->StreamObject->HwClockObject.ClockSupportFlags = 0;
   pSrb->StreamObject->HwClockObject.HwClockFunction = 0;

   DebugOut((1, "AdapterOpenStream Exit\n"));
}

/*
** AdapterCloseStream()
**
**   Close the requested data stream
**
** Arguments:
**
**   pSrb the request block requesting to close the stream
**
** Returns:
**
** Side Effects:  none
*/

VOID AdapterCloseStream( PHW_STREAM_REQUEST_BLOCK pSrb )
{
   Trace t("AdapterCloseStream()");

   PHW_DEVICE_EXTENSION HwDeviceExtension =
      (PHW_DEVICE_EXTENSION) pSrb->HwDeviceExtension;

   PsDevice *adapter = HwDeviceExtension->psdevice;
   VideoChannel *chan = (VideoChannel *)((PSTREAMEX)pSrb->StreamObject->HwStreamExtension)->videochannel;
   VideoStream StreamNumber = (VideoStream)pSrb->StreamObject->StreamNumber;

   DebugOut((1, "AdapterCloseStream(%d) - pSrb(%x)\n", StreamNumber, pSrb));

   if ( !( StreamNumber >= 0 && StreamNumber < DRIVER_STREAM_COUNT ) ) {
      DebugOut((0, "   AdapterCloseStream - failed to close stream %d\n", StreamNumber));
      DEBUG_BREAKPOINT();
      pSrb->Status = STATUS_INVALID_PARAMETER; // ?change to the proper error code?
      return;
   }
   if ( StreamNumber == STREAM_IDX_ANALOG ) // nothing to close for analog
   {
      DebugOut((1, "   AdapterCloseStream - doing nothing, stream (%d) was assumed to be analog\n", StreamNumber));
      return;
   }
#ifdef ENABLE_DDRAW_STUFF
	//TODO: should we check to see what kind of stream type this is?
	UnregisterForDirectDrawEvents( pSrb );
	CloseKernelDDrawSurfaceHandle( pSrb );
	CloseKernelDirectDraw( pSrb );
#endif

   // CloseChannel() has a bit of ugly code to take care of paired channels
   adapter->CloseChannel( chan );
}

/*
** AdapterStreamInfo()
**
**   Returns the information of all streams that are supported by the
**   mini-driver
**
** Arguments:
**
**   pSrb - Pointer to the STREAM_REQUEST_BLOCK
**        pSrb->HwDeviceExtension - will be the hardware device extension for
**                                  as initialised in HwInitialise
**
** Returns:
**
** Side Effects:  none
*/

VOID AdapterStreamInfo( PHW_STREAM_REQUEST_BLOCK pSrb )
{
   Trace t("AdapterStreamInfo()");

   //
   // pick up the pointer to header which preceeds the stream info structs
   //

   PHW_STREAM_HEADER pstrhdr =
      (PHW_STREAM_HEADER)&(pSrb->CommandData.StreamBuffer->StreamHeader);

   //
   // pick up the pointer to the stream information data structure
   //

   PHW_STREAM_INFORMATION pstrinfo =
       (PHW_STREAM_INFORMATION)&(pSrb->CommandData.StreamBuffer->StreamInfo);

   //
   // verify that the buffer is large enough to hold our return data
   //
   DEBUG_ASSERT( pSrb->NumberOfBytesToTransfer >=
      sizeof( HW_STREAM_HEADER ) +
      sizeof( HW_STREAM_INFORMATION ) * DRIVER_STREAM_COUNT );


     //
     // Set the header
     //
   StreamHeader.NumDevPropArrayEntries = NUMBER_OF_ADAPTER_PROPERTY_SETS;
   StreamHeader.DevicePropertiesArray  = (PKSPROPERTY_SET) AdapterPropertyTable;
   *pstrhdr = StreamHeader;

   //
   // stuff the contents of each HW_STREAM_INFORMATION struct
   //

   for ( int j = 0; j < DRIVER_STREAM_COUNT; j++ ) {
      *pstrinfo++ = Streams[j].hwStreamInfo;
   }

}
#ifdef HAUPPAUGEI2CPROVIDER

// new private members of PsDevice for Hauppauge I2C Provider:
//    LARGE_INTEGER LastI2CAccessTime;
//    DWORD       dwExpiredCookie = 0;
//
//

/* Method: PsDevice::I2COpen
 * Purpose: Tries to allocate I2C port to the caller
 */
NTSTATUS STDMETHODCALLTYPE PsDevice::I2COpen( PDEVICE_OBJECT pdo, ULONG ToOpen, PI2CControl ctrl )
{
   Trace t("PsDevice::I2COpen()");

   DebugOut((1, "*** pdo->DeviceExtension = %x\n", pdo->DeviceExtension));
   
   LARGE_INTEGER CurTime;

   // need a way to obtain the device pointer
   PsDevice *adapter = GetCurrentDevice();

   KeQuerySystemTime( &CurTime );

   ctrl->Status = I2C_STATUS_NOERROR;

   // cookie is not NULL if I2C is open
   if ( ToOpen && adapter->dwCurCookie_ ) {
//   Check time stamp against current time to detect if current Cookie has timed out.
//    If it has remember the last timed out cookie and grant the new requestor access.
      if ( ( adapter->dwI2CClientTimeout != 0 ) && ( (CurTime - adapter->LastI2CAccessTime) >  adapter->dwI2CClientTimeout ) ) {
         adapter->dwExpiredCookie = adapter->dwCurCookie_;
      } else {
         ctrl->dwCookie = 0;
         return STATUS_INVALID_HANDLE;
     }
   }

   // want to close ?
   if ( !ToOpen ) {
      if ( adapter->dwCurCookie_ == ctrl->dwCookie ) {
         adapter->dwCurCookie_ = 0;
         ctrl->dwCookie = 0;
         return STATUS_SUCCESS;
      } else {
         if ( (adapter->dwExpiredCookie != 0 ) && (adapter->dwExpiredCookie == ctrl->dwCookie ) ) {
            ctrl->Status = I2C_STATUS_ERROR;
         } else {
            ctrl->dwCookie = 0;
            ctrl->Status = I2C_STATUS_NOERROR;
         }
         return STATUS_INVALID_HANDLE;
      }
   }

   adapter->dwCurCookie_ = CurTime.LowPart;
   adapter->LastI2CAccessTime = CurTime;
   ctrl->dwCookie = adapter->dwCurCookie_;
   ctrl->ClockRate = 100000;

   return STATUS_SUCCESS;
}

NTSTATUS STDMETHODCALLTYPE PsDevice::I2CAccess( PDEVICE_OBJECT pdo, PI2CControl ctrl )
{
   Trace t("PsDevice::I2CAccess()");

   DebugOut((1, "*** pdo->DeviceExtension = %x\n", pdo->DeviceExtension));
   
   ErrorCode error;
   PsDevice *adapter = GetCurrentDevice();

   ctrl->Status = I2C_STATUS_NOERROR;

   if ( ctrl->dwCookie != adapter->dwCurCookie_ ) {
      if ( (adapter->dwExpiredCookie != 0 ) && (adapter->dwExpiredCookie == ctrl->dwCookie ) )
         ctrl->Status = I2C_STATUS_ERROR;
      else
         ctrl->Status = I2C_STATUS_NOERROR;
      return STATUS_INVALID_HANDLE;
   }

// Record time of this transaction to enable checking for timeout
   KeQuerySystemTime( &adapter->LastI2CAccessTime );

// Check for valid combinations of I2C command & flags

   switch( ctrl->Command ) {
   case I2C_COMMAND_NULL:
     if ( ( ctrl->Flags & ~(I2C_FLAGS_START | I2C_FLAGS_STOP) ) ||
           ( ( ctrl->Flags & (I2C_FLAGS_START | I2C_FLAGS_STOP) ) == (I2C_FLAGS_START | I2C_FLAGS_STOP) ) ) {
        // Illegal combination of Command & Flags
        return STATUS_INVALID_PARAMETER;
     }
     if ( ctrl->Flags & I2C_FLAGS_START ) {
         if ( adapter->I2CSWStart() ) {
            ctrl->Status = I2C_STATUS_ERROR;
           return STATUS_SUCCESS;
         }
      }
     if ( ctrl->Flags & I2C_FLAGS_STOP ) {
         if ( adapter->I2CSWStop() ) {
            ctrl->Status = I2C_STATUS_ERROR;
           return STATUS_SUCCESS;
         }
      }
      break;

   case I2C_COMMAND_READ:
     if ( ctrl->Flags & ~(I2C_FLAGS_STOP | I2C_FLAGS_ACK) ) {
        // Illegal combination of Command & Flags
        return STATUS_INVALID_PARAMETER;
     }
      if ( adapter->I2CSWRead( &ctrl->Data ) ) {
            ctrl->Status = I2C_STATUS_ERROR;
           return STATUS_SUCCESS;
      }
     if ( ctrl->Flags & I2C_FLAGS_ACK ) {
         if ( adapter->I2CSWSendACK() ) {
            ctrl->Status = I2C_STATUS_ERROR;
           return STATUS_SUCCESS;
         }
     } else {
         if ( adapter->I2CSWSendNACK() ) {
            ctrl->Status = I2C_STATUS_ERROR;
           return STATUS_SUCCESS;
         }
      }
     if ( ctrl->Flags & I2C_FLAGS_STOP ) {
         if ( adapter->I2CSWStop() ) {
            ctrl->Status = I2C_STATUS_ERROR;
           return STATUS_SUCCESS;
         }
      }
     break;

   case I2C_COMMAND_WRITE:
     if ( ctrl->Flags & ~(I2C_FLAGS_START | I2C_FLAGS_STOP | I2C_FLAGS_ACK | I2C_FLAGS_DATACHAINING) ) {
        // Illegal combination of Command & Flags
        return STATUS_INVALID_PARAMETER;
     }
     if ( ctrl->Flags & I2C_FLAGS_DATACHAINING ) {
         if ( adapter->I2CSWStop() ) {
            ctrl->Status = I2C_STATUS_ERROR;
           return STATUS_SUCCESS;
         }
         if ( adapter->I2CSWStart() ) {
            ctrl->Status = I2C_STATUS_ERROR;
           return STATUS_SUCCESS;
         }
      }
     if ( ctrl->Flags & I2C_FLAGS_START ) {
         if ( adapter->I2CSWStart() ) {
            ctrl->Status = I2C_STATUS_ERROR;
           return STATUS_SUCCESS;
         }
      }
      error = adapter->I2CSWWrite(ctrl->Data);

      switch ( error ) {

     case I2CERR_NOACK:
         if ( ctrl->Flags & I2C_FLAGS_ACK ) {
            ctrl->Status = I2C_STATUS_ERROR;
           return STATUS_SUCCESS;
         }
       break;

     case I2CERR_OK:
         if ( ( ctrl->Flags & I2C_FLAGS_ACK ) == 0 ) {
            ctrl->Status = I2C_STATUS_ERROR;
           return STATUS_SUCCESS;
         }
       break;

      default:
         ctrl->Status = I2C_STATUS_ERROR;
         return STATUS_SUCCESS;
      }

     if ( ctrl->Flags & I2C_FLAGS_STOP ) {
         if ( adapter->I2CSWStop() ) {
            ctrl->Status = I2C_STATUS_ERROR;
           return STATUS_SUCCESS;
         }
      }
     break;

   case I2C_COMMAND_STATUS:
     // Flags are ignored
     return STATUS_NOT_IMPLEMENTED;

   case I2C_COMMAND_RESET:
        // Flags are ignored
      if ( adapter->I2CSWStart() ) {
         ctrl->Status = I2C_STATUS_ERROR;
        return STATUS_SUCCESS;
      }
      if ( adapter->I2CSWStop() ) {
         ctrl->Status = I2C_STATUS_ERROR;
        return STATUS_SUCCESS;
      }
     break;

   default:
     return STATUS_INVALID_PARAMETER;
   }
   return STATUS_SUCCESS;
}

#else


/* Method: PsDevice::I2COpen
 * Purpose: Tries to allocate I2C port to the caller
 */
NTSTATUS STDMETHODCALLTYPE PsDevice::I2COpen( PDEVICE_OBJECT pdo, ULONG ToOpen,
   PI2CControl ctrl )
{
   Trace t("PsDevice::I2COpen()");

   DebugOut((1, "*** pdo->DeviceExtension = %x\n", pdo->DeviceExtension));
   
   // need a way to obtain the device pointer
   PsDevice *adapter = GetCurrentDevice();

   // cookie is not NULL if I2C is open
   if ( ToOpen && adapter->dwCurCookie_ ) {
      ctrl->Flags = I2C_STATUS_BUSY;
      return STATUS_DEVICE_BUSY;
   }

   // want to close ?
   if ( !ToOpen )
      if ( adapter->dwCurCookie_ == ctrl->dwCookie ) {
         adapter->dwCurCookie_ = 0;
         return STATUS_SUCCESS;
      } else {
         ctrl->Flags = I2C_STATUS_BUSY;
         return STATUS_DEVICE_BUSY;
      }

   // now we are opening
   LARGE_INTEGER CurTime;
   KeQuerySystemTime( &CurTime );

   adapter->dwCurCookie_ = CurTime.LowPart;
   ctrl->dwCookie = adapter->dwCurCookie_;
   ctrl->ClockRate = 100000;

   return STATUS_SUCCESS;
}

NTSTATUS STDMETHODCALLTYPE PsDevice::I2CAccess( PDEVICE_OBJECT pdo , PI2CControl ctrl )
{
   Trace t("PsDevice::I2CAccess()");

   DebugOut((1, "*** pdo->DeviceExtension = %x\n", pdo->DeviceExtension));
   
   PsDevice *adapter = GetCurrentDevice();

   if ( ctrl->dwCookie != adapter->dwCurCookie_ ) {
      ctrl->Flags = I2C_STATUS_BUSY;
      return I2C_STATUS_BUSY;
   }

   ctrl->Flags = I2C_STATUS_NOERROR;

  // 848 I2C API currently needs to have an address for both write and read
  // commands. So, if START flag is set an address is passed. Cache it and use
  // later
   switch ( ctrl->Command ) {
   case I2C_COMMAND_READ:
      // got 'write' command first ( with the address )
      if ( adapter->I2CHWRead( adapter->GetI2CAddress(), &ctrl->Data ) != Success )
         ctrl->Flags = I2C_STATUS_ERROR;
      break;
   case I2C_COMMAND_WRITE:
      if ( ctrl->Flags & I2C_FLAGS_START ) {
         adapter->StoreI2CAddress( ctrl->Data );
      } else
         adapter->I2CHWWrite2( adapter->GetI2CAddress(), ctrl->Data );
      break;
   case I2C_COMMAND_STATUS:
      if ( adapter->I2CGetLastError() != I2CERR_OK )
         ctrl->Flags = I2C_STATUS_ERROR;
      break;
   case I2C_COMMAND_RESET:
      adapter->I2CInitHWMode( 100000 );    // assume frequency = 100Khz
      break;
   }
   return STATUS_SUCCESS;
}

#endif

void  HandleIRP( IN PHW_STREAM_REQUEST_BLOCK pSrb )
{
   Trace t("HandleIRP()");

   DebugOut((1, "HandleIRP(%x)\n", pSrb));

   PHW_DEVICE_EXTENSION HwDeviceExtension =
      (PHW_DEVICE_EXTENSION) pSrb->HwDeviceExtension;

   PsDevice *adapter = HwDeviceExtension->psdevice;

   PIRP Irp = pSrb->Irp;
   PIO_STACK_LOCATION IrpStack = IoGetCurrentIrpStackLocation( Irp );
   switch ( IrpStack->MajorFunction ) {
   case IRP_MJ_PNP:
      if ( IrpStack->MinorFunction == IRP_MN_QUERY_INTERFACE ) {

         if ( IsEqualGUID( *IrpStack->Parameters.QueryInterface.InterfaceType,
              GUID_I2C_INTERFACE ) &&
              IrpStack->Parameters.QueryInterface.Size >= sizeof( I2CINTERFACE ) ) {

            IrpStack->Parameters.QueryInterface.InterfaceType = &GUID_I2C_INTERFACE;
            IrpStack->Parameters.QueryInterface.Size = sizeof( I2CINTERFACE );
            IrpStack->Parameters.QueryInterface.Version = 1;
            I2CINTERFACE *i2ciface =
            (I2CINTERFACE *)IrpStack->Parameters.QueryInterface.Interface;
            i2ciface->i2cOpen   = &PsDevice::I2COpen;
            i2ciface->i2cAccess = &PsDevice::I2CAccess;
            IrpStack->Parameters.QueryInterface.InterfaceSpecificData = 0;

            // complete the irp
            Irp->IoStatus.Status = STATUS_SUCCESS;
            IoCompleteRequest( Irp, IO_NO_INCREMENT );

            break;
         } else {
            Irp->IoStatus.Status = STATUS_INVALID_PARAMETER_1;
            IoCompleteRequest( Irp, IO_NO_INCREMENT );
         }
      }
   default:
       pSrb->Status = STATUS_NOT_SUPPORTED;
   }
}

/** CompleteInitialization()
**
**   This routine is called when an SRB_COMPLETE_INITIALIZATION request is received
**
** Arguments:
**
**   pSrb - pointer to stream request block
**
** Returns:
**
** Side Effects:  none
*/
void STDMETHODCALLTYPE CompleteInitialization( IN OUT PHW_STREAM_REQUEST_BLOCK pSrb )
{
   Trace t("CompleteInitialization()");

   NTSTATUS                Status;
   
   PHW_DEVICE_EXTENSION HwDeviceExtension =
      (PHW_DEVICE_EXTENSION) pSrb->HwDeviceExtension;

   PsDevice *adapter = HwDeviceExtension->psdevice;

    // Create the Registry blobs that DShow uses to create
    // graphs via Mediums

    Status = StreamClassRegisterFilterWithNoKSPins (
                    adapter->PDO,                   // IN PDEVICE_OBJECT   DeviceObject,
                    &KSCATEGORY_TVTUNER,            // IN GUID           * InterfaceClassGUID,
                    SIZEOF_ARRAY (TVTunerMediums),  // IN ULONG            PinCount,
                    TVTunerPinDirection,            // IN ULONG          * Flags,
                    TVTunerMediums,                 // IN KSPIN_MEDIUM   * MediumList,
                    NULL                            // IN GUID           * CategoryList
            );

    Status = StreamClassRegisterFilterWithNoKSPins (
                    adapter->PDO,                   // IN PDEVICE_OBJECT   DeviceObject,
                    &KSCATEGORY_CROSSBAR,           // IN GUID           * InterfaceClassGUID,
                    SIZEOF_ARRAY (CrossbarMediums), // IN ULONG            PinCount,
                    CrossbarPinDirection,           // IN ULONG          * Flags,
                    CrossbarMediums,                // IN KSPIN_MEDIUM   * MediumList,
                    NULL                            // IN GUID           * CategoryList
            );

    // Register the TVAudio decoder

    Status = StreamClassRegisterFilterWithNoKSPins (
                    adapter->PDO,                   // IN PDEVICE_OBJECT   DeviceObject,
                    &KSCATEGORY_TVAUDIO,            // IN GUID           * InterfaceClassGUID,
                    SIZEOF_ARRAY (TVAudioMediums),  // IN ULONG            PinCount,
                    TVAudioPinDirection,            // IN ULONG          * Flags,
                    TVAudioMediums,                 // IN KSPIN_MEDIUM   * MediumList,
                    NULL                            // IN GUID           * CategoryList
            );

    // Register the Capture filter
    // Note:  This should be done automatically be MSKsSrv.sys,
    // when that component comes on line (if ever) ...

    Status = StreamClassRegisterFilterWithNoKSPins (
                    adapter->PDO,                   // IN PDEVICE_OBJECT   DeviceObject,
                    &KSCATEGORY_CAPTURE,            // IN GUID           * InterfaceClassGUID,
                    SIZEOF_ARRAY (CaptureMediums),  // IN ULONG            PinCount,
                    CapturePinDirection,            // IN ULONG          * Flags,
                    CaptureMediums,                 // IN KSPIN_MEDIUM   * MediumList,
                    CaptureCategories               // IN GUID           * CategoryList
            );


   // go to usual priority, completing the SRB at the same time
   StreamClassCallAtNewPriority( pSrb->StreamObject, HwDeviceExtension, LowToHigh,
      PHW_PRIORITY_ROUTINE( CompleteDeviceSRB ), pSrb );
}


/*
** AdapterReceivePacket()
**
**   Main entry point for receiving adapter based request SRBs.  This routine
**   will always be called at High Priority.
**
**   Note: This is an asyncronous entry point.  The request does not complete
**         on return from this function, the request only completes when a
**         StreamClassDeviceNotification on this request block, of type
**         DeviceRequestComplete, is issued.
**
** Arguments:
**
**   pSrb - Pointer to the STREAM_REQUEST_BLOCK
**        pSrb->HwDeviceExtension - will be the hardware device extension for
**                                  as initialised in HwInitialise
**
** Returns:
**
** Side Effects:  none
*/

VOID STREAMAPI AdapterReceivePacket( IN PHW_STREAM_REQUEST_BLOCK pSrb )
{

      Trace t("AdapterReceivePacket()");

   BOOL CompleteRequestSynchronously = TRUE;

   //default to success
   pSrb->Status = STATUS_SUCCESS;

   PHW_DEVICE_EXTENSION HwDeviceExtension =
      (PHW_DEVICE_EXTENSION) pSrb->HwDeviceExtension;

   PsDevice *adapter = HwDeviceExtension->psdevice;
   
   //
   // determine the type of packet.
   //

   DebugOut((1, "'AdapterReceivePacket(%x) cmd(%x)\n", pSrb, pSrb->Command));

   switch ( pSrb->Command )  {
   case SRB_INITIALIZE_DEVICE:
      DebugOut((1, "   SRB_INITIALIZE_DEVICE\n"));

      CompleteRequestSynchronously = FALSE;
      // have to schedule a low priority call to open the device because
      // registry functions are used during initialization

      StreamClassCallAtNewPriority( pSrb->StreamObject, pSrb->HwDeviceExtension,
         Low, PHW_PRIORITY_ROUTINE( HwInitialize ), pSrb );

      break;

   case SRB_UNINITIALIZE_DEVICE:
      DebugOut((1, "   SRB_UNINITIALIZE_DEVICE\n"));

      // close the device.

      HwUnInitialize(pSrb);

      break;

   case SRB_OPEN_STREAM:
      DebugOut((1, "   SRB_OPEN_STREAM\n"));

      // open a stream

      AdapterOpenStream( pSrb );

      break;

   case SRB_CLOSE_STREAM:
      DebugOut((1, "   SRB_CLOSE_STREAM\n"));

      // close a stream

      AdapterCloseStream( pSrb );

      break;

   case SRB_GET_STREAM_INFO:
      DebugOut((1, "   SRB_GET_STREAM_INFO\n"));

      //
      // return a block describing all the streams
      //

      AdapterStreamInfo(pSrb);

      break;

   case SRB_GET_DEVICE_PROPERTY:
      DebugOut((1, "   SRB_GET_DEVICE_PROPERTY\n"));
      AdapterGetProperty( pSrb );
      break;

   case SRB_SET_DEVICE_PROPERTY:
      DebugOut((1, "   SRB_SET_DEVICE_PROPERTY\n"));
      AdapterSetProperty( pSrb );
      break;

   case SRB_GET_DATA_INTERSECTION:
      DebugOut((1, "   SRB_GET_DATA_INTERSECTION\n"));

      //
      // Return a format, given a range
      //

      AdapterFormatFromRange( pSrb );

      break;
    case SRB_INITIALIZATION_COMPLETE:
      DebugOut((1, "   SRB_INITIALIZATION_COMPLETE\n"));

        //
        // Stream class has finished initialization.
        // Now create DShow Medium interface BLOBs.
        // This needs to be done at low priority since it uses the registry, so use a callback
        //
        CompleteRequestSynchronously = FALSE;

        StreamClassCallAtNewPriority( NULL /*pSrb->StreamObject*/, pSrb->HwDeviceExtension,
            Low, PHW_PRIORITY_ROUTINE( CompleteInitialization), pSrb );

        break;

   case SRB_PAGING_OUT_DRIVER:
      if ( (*(DWORD*)(gpjBaseAddr+0x10c) & 3) || (*(DWORD*)(gpjBaseAddr+0x104)) )
      {
         DebugOut((0,  "   ****** SRB_PAGING_OUT_DRIVER ENB(%x) MSK(%x)\n",
                     *(DWORD*)(gpjBaseAddr+0x10c) & 3,
                     *(DWORD*)(gpjBaseAddr+0x104)
         ));

         *(DWORD*)(gpjBaseAddr+0x10c) &= ~3;    // disable interrupts   [TMZ] [!!!]
         *(DWORD*)(gpjBaseAddr+0x104) = 0;      // disable interrupts   [TMZ] [!!!]
      }
      break;

   case SRB_UNKNOWN_DEVICE_COMMAND:
      DebugOut((1, "   SRB_UNKNOWN_DEVICE_COMMAND\n"));
      HandleIRP( pSrb );
      break;

    // We should never get the following 2 since this is a single instance
    // device
   case SRB_OPEN_DEVICE_INSTANCE:
   case SRB_CLOSE_DEVICE_INSTANCE:
   default:
       //
       // this is a request that we do not understand.  Indicate invalid
       // command and complete the request
       //

       DebugOut((0, "SRB(%x) not recognized by this driver\n", pSrb->Command));
       pSrb->Status = STATUS_NOT_IMPLEMENTED;
   }

   //
   // Most, but not all SRBs are handled synchronously here
   //

   if ( CompleteRequestSynchronously )  {
      CompleteDeviceSRB( pSrb );
   }
}

/*
** AdapterCancelPacket()
**
**   Request to cancel a packet that is currently in process in the minidriver
**
** Arguments:
**
**   pSrb - pointer to request packet to cancel
**
** Returns:
**
** Side Effects:  none
*/

VOID STREAMAPI AdapterCancelPacket( PHW_STREAM_REQUEST_BLOCK pSrb )
{
   Trace t("AdapterCancelPacket()");

   VideoStream StreamNumber = (VideoStream)pSrb->StreamObject->StreamNumber;

   DebugOut((1, "AdapterCancelPacket - pSrb(%x) strm(%d)\n", pSrb, StreamNumber));

   VideoChannel *chan = (VideoChannel *)((PSTREAMEX)pSrb->StreamObject->HwStreamExtension)->videochannel;

   pSrb->Status = STATUS_CANCELLED;
   
   //
   // it is necessary to call the request back correctly.  Determine which
   // type of command it is
   //

   switch ( pSrb->Flags & (SRB_HW_FLAGS_DATA_TRANSFER | SRB_HW_FLAGS_STREAM_REQUEST ) ) {
   //
   // find all stream commands, and do stream notifications
   //

   case SRB_HW_FLAGS_STREAM_REQUEST | SRB_HW_FLAGS_DATA_TRANSFER:
      DebugOut((1, "   Canceling data SRB\n" ) );
//      adapter->Stop( *chan );  [!!!] [TMZ] [???] why is this commented out???
      
      if (!chan->RemoveSRB( pSrb ))
      {
         DebugOut((0, "   Canceling data SRB failed\n"));
         DEBUG_BREAKPOINT();
      }
      break;
   case SRB_HW_FLAGS_STREAM_REQUEST:
      DebugOut((1, "   Canceling control SRB\n" ) );
      CheckSrbStatus( pSrb );
      StreamClassStreamNotification( ReadyForNextStreamControlRequest,
         pSrb->StreamObject );
      StreamClassStreamNotification( StreamRequestComplete,
         pSrb->StreamObject, pSrb );
      break;
   default:
      //
      // this must be a device request.  Use device notifications
      //
      DebugOut((1, "   Canceling SRB per device request\n" ) );
      StreamClassDeviceNotification( ReadyForNextDeviceRequest,
         pSrb->HwDeviceExtension );

      StreamClassDeviceNotification( DeviceRequestComplete,
         pSrb->HwDeviceExtension, pSrb );
   }
}

/*
** AdapterTimeoutPacket()
**
**   This routine is called when a packet has been in the minidriver for
**   too long.  The adapter must decide what to do with the packet
**
** Arguments:
**
**   pSrb - pointer to the request packet that timed out
**
** Returns:
**
** Side Effects:  none
*/

VOID STREAMAPI AdapterTimeoutPacket( PHW_STREAM_REQUEST_BLOCK pSrb )
{
   Trace t("AdapterTimeoutPacket()");

   DebugOut((0, "AdapterTimeoutPacket (incomplete) - pSrb(%x)\n", pSrb));

   // [TMZ] Fix this
   #if SHOW_BUILD_MSGS
      #pragma message("*** AdapterTimeoutPacket needs to be completed")
   #endif

   DebugOut((0, "   pSrb->Flags = %x\n", pSrb->Flags));

   if ( pSrb->Flags & SRB_HW_FLAGS_STREAM_REQUEST )
   {
      DebugOut((0, "                 SRB_HW_FLAGS_STREAM_REQUEST\n"));
   }
   if ( pSrb->Flags & SRB_HW_FLAGS_DATA_TRANSFER )
   {
      DebugOut((0, "                 SRB_HW_FLAGS_DATA_TRANSFER\n"));
   }

   //
   // if we timeout while playing, then we need to consider this
   // condition an error, and reset the hardware, and reset everything
   // as well as cancelling this and all requests
   //


   //
   // if we are not playing, and this is a CTRL request, we still
   // need to reset everything as well as cancelling this and all requests
   //

   //
   // if this is a data request, and the device is paused, we probably have
   // run out of data buffer, and need more time, so just reset the timer,
   // and let the packet continue
   //

   pSrb->TimeoutCounter = pSrb->TimeoutOriginal;
}

/*
** HwInterrupt()
**
**   Routine is called when an interrupt at the IRQ level specified by the
**   ConfigInfo structure passed to the HwInitialize routine is received.
**
**   Note: IRQs may be shared, so the device should ensure the IRQ received
**         was expected
**
** Arguments:
**
**  pHwDevEx - the device extension for the hardware interrupt
**
** Returns:
**
** Side Effects:  none
*/

BOOLEAN HwInterrupt( IN PHW_DEVICE_EXTENSION HwDeviceExtension )
{
   Trace t("HwInterrupt()");
   DebugOut((1, "HwInterrupt called by system\n"));
   PsDevice *adapter = (PsDevice *)(HwDeviceExtension->psdevice);
   BOOLEAN b = adapter->Interrupt();
   return( b );
}

/* Function: CompleteDeviceSRB
 * Purpose: Called to complete a device SRB
 * Input: pSrb
 */
inline void CompleteDeviceSRB( IN OUT PHW_STREAM_REQUEST_BLOCK pSrb )
{
   Trace t("CompleteDeviceSRB()");
   StreamClassDeviceNotification( DeviceRequestComplete, pSrb->HwDeviceExtension, pSrb );
   StreamClassDeviceNotification( ReadyForNextDeviceRequest, pSrb->HwDeviceExtension );
}

/*
** AdapterCompareGUIDsAndFormatSize()
**
**   Checks for a match on the three GUIDs and FormatSize
**
** Arguments:
**
**         IN DataRange1
**         IN DataRange2
**
** Returns:
**
**   TRUE if all elements match
**   FALSE if any are different
**
** Side Effects:  none
*/

bool AdapterCompareGUIDsAndFormatSize( IN const PKSDATARANGE DataRange1,
   IN const PKSDATARANGE DataRange2 )
{
   Trace t("AdapterCompareGUIDsAndFormatSize()");

   bool bCheckSize = false;

#if 1 // use old guid verify
   return (
      IsEqualGUID( DataRange1->MajorFormat, DataRange2->MajorFormat ) &&
      IsEqualGUID( DataRange1->SubFormat,   DataRange2->SubFormat   ) &&
      IsEqualGUID( DataRange1->Specifier,   DataRange2->Specifier   ) &&
      ( DataRange1->FormatSize == DataRange2->FormatSize ) );
#else // use new guid verify from cc decoder
   bool rval = false;

   if ( IsEqualGUID(DataRange1->MajorFormat, KSDATAFORMAT_TYPE_WILDCARD)
     || IsEqualGUID(DataRange2->MajorFormat, KSDATAFORMAT_TYPE_WILDCARD)
     || IsEqualGUID(DataRange1->MajorFormat, DataRange2->MajorFormat) )
   {
      if ( !IsEqualGUID(DataRange1->MajorFormat, DataRange2->MajorFormat) )
      {
         DebugOut((0, "Match 1\n" ));
      }

      if ( IsEqualGUID(DataRange1->SubFormat, KSDATAFORMAT_SUBTYPE_WILDCARD)
        || IsEqualGUID(DataRange2->SubFormat, KSDATAFORMAT_SUBTYPE_WILDCARD)
        || IsEqualGUID(DataRange1->SubFormat, DataRange2->SubFormat) )
      {
         if ( !IsEqualGUID(DataRange1->SubFormat, DataRange2->SubFormat) )
         {
            DebugOut((0, "Match 2\n" ));
         }

         if ( IsEqualGUID(DataRange1->Specifier, KSDATAFORMAT_SPECIFIER_WILDCARD)
           || IsEqualGUID(DataRange2->Specifier, KSDATAFORMAT_SPECIFIER_WILDCARD)
           || IsEqualGUID(DataRange1->Specifier, DataRange2->Specifier) )
         {
            if ( !IsEqualGUID(DataRange1->Specifier, DataRange2->Specifier) )
            {
               DebugOut((0, "Match 3\n" ));
            }

            if ( !bCheckSize || DataRange1->FormatSize == DataRange2->FormatSize)
            {
               DebugOut((0, "Victory !!!\n" ));
               rval = true;
            }
            else
            {
               DebugOut((0, "FormatSize Mismatch\n" ));
            }
         }
         else
         {
            DebugOut((0, "Specifier Mismatch\n" ));
         }
      }
      else
      {
         DebugOut((0, "SubFormat Mismatch\n" ));
      }
   }
   else
   {
      DebugOut((0, "MajorFormat Mismatch\n" ));
   }

   DebugOut((0, "CompareGUIDsAndFormatSize(\n"));
   DebugOut((0, "   DataRange1=%x\n", DataRange1));
   DebugOut((0, "   DataRange2=%x\n", DataRange2));
   DebugOut((0, "   bCheckSize=%s\n", bCheckSize ? "TRUE":"FALSE"));
   DebugOut((0, ")\n"));
   DebugOut((0, "returning %s\n", rval? "TRUE":"FALSE"));

   return rval;
#endif
}

/*
** AdapterFormatFromRange()
**
**   Returns a DATAFORMAT from a DATARANGE
**
** Arguments:
**
**         IN PHW_STREAM_REQUEST_BLOCK pSrb
**
** Returns:
**
**   TRUE if the format is supported
**   FALSE if the format cannot be suppored
**
** Side Effects:  none
*/
void AdapterFormatFromRange( IN PHW_STREAM_REQUEST_BLOCK pSrb )
{
   Trace t("AdapterFormatFromRange()");

   PSTREAM_DATA_INTERSECT_INFO IntersectInfo;
   PKSDATARANGE                DataRange;
   ULONG                       FormatSize=0;
   ULONG                       StreamNumber;
   ULONG                       j;
   ULONG                       NumberOfFormatArrayEntries;
   PKSDATAFORMAT               *pAvailableFormats;

   IntersectInfo = pSrb->CommandData.IntersectInfo;
   StreamNumber = IntersectInfo->StreamNumber;
   DataRange = IntersectInfo->DataRange;

   //
   // Check that the stream number is valid
   //

   if( StreamNumber >= DRIVER_STREAM_COUNT ) 
	{
      pSrb->Status = STATUS_NOT_IMPLEMENTED;
      return;
   }

   NumberOfFormatArrayEntries =
           Streams[StreamNumber].hwStreamInfo.NumberOfFormatArrayEntries;

   //
   // Get the pointer to the array of available formats
   //

   pAvailableFormats = Streams[StreamNumber].hwStreamInfo.StreamFormatsArray;

   //
   // Is the caller trying to get the format, or the size of the format?
   //

   bool OnlyWantsSize = (IntersectInfo->SizeOfDataFormatBuffer == sizeof( ULONG ) );

   //
   // Walk the formats supported by the stream searching for a match
   // of the three GUIDs which together define a DATARANGE
   //

   for ( j = 0; j < NumberOfFormatArrayEntries; j++, pAvailableFormats++ ) 
	{

      if ( !AdapterCompareGUIDsAndFormatSize( DataRange, *pAvailableFormats ) ) 
		{
          continue;
      }

      //
      // Now that the three GUIDs match, switch on the Specifier
      // to do a further type specific check
      //

      // -------------------------------------------------------------------
      // Specifier FORMAT_VideoInfo for VIDEOINFOHEADER
      // -------------------------------------------------------------------

      if ( IsEqualGUID( DataRange->Specifier, KSDATAFORMAT_SPECIFIER_VIDEOINFO ) ) 
		{

         PKS_DATARANGE_VIDEO DataRangeVideoToVerify = (PKS_DATARANGE_VIDEO)DataRange;
         PKS_DATARANGE_VIDEO DataRangeVideo = (PKS_DATARANGE_VIDEO)*pAvailableFormats;

         //
         // Check that the other fields match
         //
         if ( (DataRangeVideoToVerify->bFixedSizeSamples      != DataRangeVideo->bFixedSizeSamples)      ||
              (DataRangeVideoToVerify->bTemporalCompression   != DataRangeVideo->bTemporalCompression)   ||
              (DataRangeVideoToVerify->StreamDescriptionFlags != DataRangeVideo->StreamDescriptionFlags) ||
              (DataRangeVideoToVerify->MemoryAllocationFlags  != DataRangeVideo->MemoryAllocationFlags)  ||
              (RtlCompareMemory( &DataRangeVideoToVerify->ConfigCaps,
                 &DataRangeVideo->ConfigCaps,
                 sizeof( KS_VIDEO_STREAM_CONFIG_CAPS ) ) !=
                 sizeof( KS_VIDEO_STREAM_CONFIG_CAPS ) ) ) 
			{
            DebugOut(( 1, "AdapterFormatFromRange(): at least one field does not match\n" ));
            continue;
         }

         // MATCH FOUND!
         FormatSize = sizeof( KSDATAFORMAT ) +
            KS_SIZE_VIDEOHEADER( &DataRangeVideoToVerify->VideoInfoHeader );

         if ( OnlyWantsSize )
			{
            break;
			}

         // Caller wants the full data format
         if ( IntersectInfo->SizeOfDataFormatBuffer < FormatSize ) 
			{
            DebugOut(( 1, "AdapterFormatFromRange(): STATUS_BUFFER_TOO_SMALL\n" ));
            pSrb->Status = STATUS_BUFFER_TOO_SMALL;
            return;
         }

         // Copy over the KSDATAFORMAT, followed by the
         // actual VideoInfoHeader
         PKS_DATAFORMAT_VIDEOINFOHEADER InterVidHdr =
            (PKS_DATAFORMAT_VIDEOINFOHEADER)IntersectInfo->DataFormatBuffer;

         RtlCopyMemory( &InterVidHdr->DataFormat,
            &DataRangeVideoToVerify->DataRange, sizeof( KSDATARANGE ) );

         ((PKSDATAFORMAT)IntersectInfo->DataFormatBuffer)->FormatSize = FormatSize;

         RtlCopyMemory( &InterVidHdr->VideoInfoHeader,
            &DataRangeVideoToVerify->VideoInfoHeader,
            KS_SIZE_VIDEOHEADER( &DataRangeVideoToVerify->VideoInfoHeader ) );


         // report back the omage size as we know it
         KS_VIDEOINFOHEADER &vidHDR = DataRangeVideoToVerify->VideoInfoHeader;

         #ifdef HACK_FUDGE_RECTANGLES
            // [!!!] [TMZ] - hack
            if( vidHDR.rcTarget.bottom == 0 ) 
				{
               vidHDR.rcTarget.left    = 0;
               vidHDR.rcTarget.top     = 0;
               vidHDR.rcTarget.right   = vidHDR.bmiHeader.biWidth;
               vidHDR.rcTarget.bottom  = abs(vidHDR.bmiHeader.biHeight);
            }
            if( InterVidHdr->VideoInfoHeader.rcTarget.bottom == 0 ) 
				{
               InterVidHdr->VideoInfoHeader.rcTarget.left    = 0;
               InterVidHdr->VideoInfoHeader.rcTarget.top     = 0;
               InterVidHdr->VideoInfoHeader.rcTarget.right   = vidHDR.bmiHeader.biWidth;
               InterVidHdr->VideoInfoHeader.rcTarget.bottom  = abs(vidHDR.bmiHeader.biHeight);
            }
         #endif

         MSize			size;
         GetRequestedSize( vidHDR, size );

         ColorSpace	tmpCol( DataRange->SubFormat );
         MRect			dst( vidHDR.rcTarget );

         // make sure the dimentions are acceptable
         if ( tmpCol.IsValid() && tmpCol.CheckDimentions( size ) &&
              tmpCol.CheckLeftTop( dst.TopLeft() ) ) 
			{
            // if width is different, use it ( in bytes ) to calculate the size
            if ( vidHDR.bmiHeader.biWidth != size.cx )
				{
               InterVidHdr->VideoInfoHeader.bmiHeader.biSizeImage =
                  vidHDR.bmiHeader.biWidth * abs(vidHDR.bmiHeader.biHeight);
				}
            else
				{
               InterVidHdr->VideoInfoHeader.bmiHeader.biSizeImage = size.cx *
                  tmpCol.GetBitCount() * abs(vidHDR.bmiHeader.biHeight) / 8;
				}

            DebugOut((1, "InterVidHdr->VideoInfoHeader.bmiHeader.biSizeImage = %d\n", InterVidHdr->VideoInfoHeader.bmiHeader.biSizeImage));
            break;
         } 
			else 
			{
            pSrb->Status = STATUS_BUFFER_TOO_SMALL;
            DebugOut((1, "AdapterFormatFromRange: Buffer too small\n"));
            return;
         }
      } // End of VIDEOINFOHEADER specifier

      // -------------------------------------------------------------------
      // Specifier FORMAT_VideoInfo2 for VIDEOINFOHEADER2
      // -------------------------------------------------------------------
      else if ( IsEqualGUID( DataRange->Specifier, KSDATAFORMAT_SPECIFIER_VIDEOINFO2 ) ) 
		{

         PKS_DATARANGE_VIDEO2 DataRangeVideoToVerify = (PKS_DATARANGE_VIDEO2) DataRange;
         PKS_DATARANGE_VIDEO2 DataRangeVideo = (PKS_DATARANGE_VIDEO2) *pAvailableFormats;

         //
         // Check that the other fields match
         //
         if ( (DataRangeVideoToVerify->bFixedSizeSamples      != DataRangeVideo->bFixedSizeSamples)      ||
              (DataRangeVideoToVerify->bTemporalCompression   != DataRangeVideo->bTemporalCompression)   ||
              (DataRangeVideoToVerify->StreamDescriptionFlags != DataRangeVideo->StreamDescriptionFlags) ||
              (DataRangeVideoToVerify->MemoryAllocationFlags  != DataRangeVideo->MemoryAllocationFlags)  ||
              (RtlCompareMemory( &DataRangeVideoToVerify->ConfigCaps,
                 &DataRangeVideo->ConfigCaps,
                 sizeof( KS_VIDEO_STREAM_CONFIG_CAPS ) ) !=
                 sizeof( KS_VIDEO_STREAM_CONFIG_CAPS ) ) ) 
			{
            DebugOut(( 1, "AdapterFormatFromRange(): at least one field does not match\n" ));
            continue;
         }

         // MATCH FOUND!
         FormatSize = sizeof( KSDATAFORMAT ) +
            KS_SIZE_VIDEOHEADER2( &DataRangeVideoToVerify->VideoInfoHeader );

         if ( OnlyWantsSize )
			{
            break;
			}

         // Caller wants the full data format
         if ( IntersectInfo->SizeOfDataFormatBuffer < FormatSize ) 
			{
            DebugOut(( 1, "AdapterFormatFromRange(): STATUS_BUFFER_TOO_SMALL\n" ));
            pSrb->Status = STATUS_BUFFER_TOO_SMALL;
            return;
         }

         // Copy over the KSDATAFORMAT, followed by the
         // actual VideoInfoHeader
         PKS_DATAFORMAT_VIDEOINFOHEADER2 InterVidHdr =
            (PKS_DATAFORMAT_VIDEOINFOHEADER2)IntersectInfo->DataFormatBuffer;

         RtlCopyMemory( &InterVidHdr->DataFormat,
            &DataRangeVideoToVerify->DataRange, sizeof( KSDATARANGE ) );

         ((PKSDATAFORMAT)IntersectInfo->DataFormatBuffer)->FormatSize = FormatSize;

         RtlCopyMemory( &InterVidHdr->VideoInfoHeader2,
            &DataRangeVideoToVerify->VideoInfoHeader,
            KS_SIZE_VIDEOHEADER2( &DataRangeVideoToVerify->VideoInfoHeader ) );


         // report back the omage size as we know it
         KS_VIDEOINFOHEADER2 &vidHDR = DataRangeVideoToVerify->VideoInfoHeader;

         #ifdef HACK_FUDGE_RECTANGLES
            // [!!!] [TMZ] - hack
            if( vidHDR.rcTarget.bottom == 0 ) 
				{
               vidHDR.rcTarget.left    = 0;
               vidHDR.rcTarget.top     = 0;
               vidHDR.rcTarget.right   = vidHDR.bmiHeader.biWidth;
               vidHDR.rcTarget.bottom  = abs(vidHDR.bmiHeader.biHeight);
            }
            if( InterVidHdr->VideoInfoHeader.rcTarget.bottom == 0 ) 
				{
               InterVidHdr->VideoInfoHeader.rcTarget.left    = 0;
               InterVidHdr->VideoInfoHeader.rcTarget.top     = 0;
               InterVidHdr->VideoInfoHeader.rcTarget.right   = vidHDR.bmiHeader.biWidth;
               InterVidHdr->VideoInfoHeader.rcTarget.bottom  = abs(vidHDR.bmiHeader.biHeight);
            }
         #endif

         MSize			size;
         GetRequestedSize2( vidHDR, size );

         ColorSpace	tmpCol( DataRange->SubFormat );
         MRect			dst( vidHDR.rcTarget );

         // make sure the dimentions are acceptable
         if ( tmpCol.IsValid() && tmpCol.CheckDimentions( size ) &&
              tmpCol.CheckLeftTop( dst.TopLeft() ) ) 
			{
            // if width is different, use it ( in bytes ) to calculate the size
            if ( vidHDR.bmiHeader.biWidth != size.cx )
				{
               InterVidHdr->VideoInfoHeader2.bmiHeader.biSizeImage =
                  vidHDR.bmiHeader.biWidth * abs(vidHDR.bmiHeader.biHeight);
				}
            else
				{
               InterVidHdr->VideoInfoHeader2.bmiHeader.biSizeImage = size.cx *
                  tmpCol.GetBitCount() * abs(vidHDR.bmiHeader.biHeight) / 8;
				}

            DebugOut((1, "InterVidHdr->VideoInfoHeader2.bmiHeader.biSizeImage = %d\n", InterVidHdr->VideoInfoHeader2.bmiHeader.biSizeImage));
            break;
         } 
			else 
			{
            pSrb->Status = STATUS_BUFFER_TOO_SMALL;
            DebugOut((1, "AdapterFormatFromRange: Buffer too small\n"));
            return;
         }
      } // End of VIDEOINFOHEADER2 specifier

      // -------------------------------------------------------------------
      // Specifier FORMAT_AnalogVideo for KS_ANALOGVIDEOINFO
      // -------------------------------------------------------------------

      else if ( IsEqualGUID( DataRange->Specifier, KSDATAFORMAT_SPECIFIER_ANALOGVIDEO ) ) 
		{

            //
            // For analog video, the DataRange and DataFormat
            // are identical, so just copy the whole structure
            //

            PKS_DATARANGE_ANALOGVIDEO pDataRangeVideo =
               (PKS_DATARANGE_ANALOGVIDEO) *pAvailableFormats;

            // MATCH FOUND!
            FormatSize = sizeof( KS_DATARANGE_ANALOGVIDEO );

            if ( OnlyWantsSize )
				{
               break;
				}

            // Caller wants the full data format
            if ( IntersectInfo->SizeOfDataFormatBuffer < FormatSize ) 
				{
               pSrb->Status = STATUS_BUFFER_TOO_SMALL;
					DebugOut((1, "AdapterFormatFromRange: Buffer too small\n"));
               return;
            }
            RtlCopyMemory( IntersectInfo->DataFormatBuffer,
               pDataRangeVideo, sizeof( KS_DATARANGE_ANALOGVIDEO ) );

            ((PKSDATAFORMAT)IntersectInfo->DataFormatBuffer)->FormatSize = FormatSize;

            break;

      } 
		else 
		{
			if ( IsEqualGUID( DataRange->Specifier, KSDATAFORMAT_SPECIFIER_VBI ) ) 
			{
				PKS_DATARANGE_VIDEO_VBI pDataRangeVBI =
				(PKS_DATARANGE_VIDEO_VBI)*pAvailableFormats;

				FormatSize = sizeof( KS_DATAFORMAT_VBIINFOHEADER );

				if ( OnlyWantsSize )
				{
					break;
				}

				// Caller wants the full data format
				if ( IntersectInfo->SizeOfDataFormatBuffer < FormatSize ) 
				{
					pSrb->Status = STATUS_BUFFER_TOO_SMALL;
					DebugOut((1, "AdapterFormatFromRange: Buffer too small\n"));
					return;
				}
				// Copy over the KSDATAFORMAT, followed by the
				// actual VideoInfoHeader
				PKS_DATAFORMAT_VBIINFOHEADER InterVBIHdr =
					(PKS_DATAFORMAT_VBIINFOHEADER)IntersectInfo->DataFormatBuffer;

				RtlCopyMemory( &InterVBIHdr->DataFormat,
					&pDataRangeVBI->DataRange, sizeof( KSDATARANGE ) );

				((PKSDATAFORMAT)IntersectInfo->DataFormatBuffer)->FormatSize = FormatSize;

				RtlCopyMemory( &InterVBIHdr->VBIInfoHeader,
					&pDataRangeVBI->VBIInfoHeader, sizeof( KS_VBIINFOHEADER ) );

				break;
			} 
			else 
			{
				DebugOut(( 0, "AdapterFormatFromRange: STATUS_NO_MATCH\n" ));
				pSrb->Status = STATUS_NO_MATCH;
				return;
			}
		}

   } // End of loop on all formats for this stream

   if ( OnlyWantsSize ) 
	{
		DebugOut(( 2, "AdapterFormatFromRange: only wants size\n" ));
		*(PULONG) IntersectInfo->DataFormatBuffer = FormatSize;
		pSrb->ActualBytesTransferred = sizeof( ULONG );
		return;
   }
   pSrb->ActualBytesTransferred = FormatSize;
	DebugOut(( 2, "AdapterFormatFromRange: done\n" ));

   return;
}
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\drivers\wdm\capture\mini\bt848\capprop.c ===
// $Header: G:/SwDev/WDM/Video/bt848/rcs/Capprop.c 1.14 1998/05/13 14:44:20 tomz Exp $

//==========================================================================;
//
//  THIS CODE AND INFORMATION IS PROVIDED "AS IS" WITHOUT WARRANTY OF ANY
//  KIND, EITHER EXPRESSED OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE
//  IMPLIED WARRANTIES OF MERCHANTABILITY AND/OR FITNESS FOR A PARTICULAR
//  PURPOSE.
//
//  Copyright (c) 1992 - 1996  Microsoft Corporation.  All Rights Reserved.
//
//==========================================================================;


#ifdef __cplusplus
extern "C" {
#endif

#include "strmini.h"
#include "ksmedia.h"

#ifdef __cplusplus
}
#endif

#include "device.h"

#include "capdebug.h"
#include "capprop.h"
#include "capmain.h"

extern PsDevice *gpPsDevice;

bool CrossBar::TestRoute( int InPin, int OutPin )
{
   Trace t("CrossBar::TestRoute()");

   // JBC 4/1/98 Handle Input Pin = -1 for Audio Mute case
   if ( InPin == -1 && (OutputPins [OutPin].PinType >= KS_PhysConn_Audio_Tuner)) {	// JBC 4/1/98
      return true;
   }
   if ((InputPins [InPin].PinType >= KS_PhysConn_Audio_Tuner) &&  // 0x1000 first audio pin // JBC 4/1/98
       (OutputPins [OutPin].PinType >= KS_PhysConn_Audio_Tuner)) {					// JBC 4/1/98
      return true;
   }
   else {
      if ((InputPins [InPin].PinType >= KS_PhysConn_Video_Tuner) &&
		  (InputPins [InPin].PinType < KS_PhysConn_Audio_Tuner) &&		// JBC 4/1/98
          (OutputPins [OutPin].PinType < KS_PhysConn_Audio_Tuner)) {
         DebugOut((1, "TestRoute(%d,%d) = true\n", InPin, OutPin));
		 return true;
      } else {
		 return false;
      }
   }
}

// -------------------------------------------------------------------
// XBar Property Set functions
// -------------------------------------------------------------------

//
// The only property to set on the XBar selects the input to use
//

/* Method: AdapterGetCrossbarProperty
 * Purpose:
 */
VOID AdapterSetCrossbarProperty( PHW_STREAM_REQUEST_BLOCK pSrb )
{
   Trace t("AdapterSetCrossbarProperty()");

   PHW_DEVICE_EXTENSION HwDeviceExtension =
      (PHW_DEVICE_EXTENSION) pSrb->HwDeviceExtension;

   PsDevice *adapter = HwDeviceExtension->psdevice;

   PSTREAM_PROPERTY_DESCRIPTOR pSPD = pSrb->CommandData.PropertyInfo;
   ULONG Id  = pSPD->Property->Id;              // index of the property
   ULONG nS  = pSPD->PropertyOutputSize;        // size of data supplied

   switch ( Id ) {
   case KSPROPERTY_CROSSBAR_ROUTE:
      {
		  PKSPROPERTY_CROSSBAR_ROUTE_S  pRoute =
            (PKSPROPERTY_CROSSBAR_ROUTE_S)pSPD->PropertyInfo;

         ASSERT (nS >= sizeof (KSPROPERTY_CROSSBAR_ROUTE_S));

         // Copy the input property info to the output property info
         RtlCopyMemory( pRoute, pSPD->Property,
           sizeof( KSPROPERTY_CROSSBAR_ROUTE_S ) );

         int InPin, OutPin;
         InPin  = pRoute->IndexInputPin;
         OutPin = pRoute->IndexOutputPin;

         DebugOut((1, "*** KSPROPERTY_CROSSBAR_ROUTE(%d,%d)\n", InPin, OutPin));

         if ( adapter->xBar.GoodPins( InPin, OutPin ) ) {
            
            DebugOut((1, "*** xBar.GoodPins succeeded\n"));

            if ( adapter->xBar.TestRoute( InPin, OutPin ) ) {
               DebugOut((1, "*** xBar.TestRoute succeeded\n"));
               pRoute->CanRoute = true;
               // JBC 4/1/98 What happens when we call setconnector for audio pins?
			      if (OutPin == 0 )	// JBC 4/1/98 Check for Video Vs Audio pins settings
               {
                  // Video out
				      adapter->SetConnector( adapter->xBar.GetPinNo( InPin ) + 1 ); // our connectors are 1-based
               }
               else
               {
                  // Audio out
                  if ( InPin == -1 ) // then mute
                  {
                     gpPsDevice->EnableAudio( Off );
                  }
                  else
                  {
                     gpPsDevice->EnableAudio( On );
                  }
               }
			      // this just sets the association
               adapter->xBar.Route( OutPin, InPin );
            } else {											// JBC 3/31/98 add curly braces
               DebugOut((1, "*** xBar.TestRoute failed\n"));
               pRoute->CanRoute = false;
			}
		} else {												// JBC 3/31/98 add curly braces
            DebugOut((1, "*** xBar.GoodPins failed\n"));
            pRoute->CanRoute = 0;
		}
	  }
      pSrb->ActualBytesTransferred = sizeof( KSPROPERTY_CROSSBAR_ROUTE_S );
      break;
   default:
      break;
   }
   pSrb->Status = STATUS_SUCCESS;
}

/* Method: AdapterGetCrossbarProperty
 * Purpose:
 */
VOID AdapterGetCrossbarProperty( PHW_STREAM_REQUEST_BLOCK pSrb )
{
   Trace t("AdapterGetCrossbarProperty()");

   PHW_DEVICE_EXTENSION HwDeviceExtension =
      (PHW_DEVICE_EXTENSION) pSrb->HwDeviceExtension;

   PsDevice *adapter = HwDeviceExtension->psdevice;

   PSTREAM_PROPERTY_DESCRIPTOR pSPD = pSrb->CommandData.PropertyInfo;
   ULONG Id = pSPD->Property->Id;              // index of the property
//   PLONG pL = (PLONG) pSPD->PropertyInfo;     // pointer to the data
   ULONG nS = pSPD->PropertyOutputSize;        // size of data supplied

   // Property set specific structure

   switch ( Id ) {
   case KSPROPERTY_CROSSBAR_CAPS:                  // R
      if ( nS >= sizeof( KSPROPERTY_CROSSBAR_CAPS_S ) ) {

         PKSPROPERTY_CROSSBAR_CAPS_S  pCaps =
            (PKSPROPERTY_CROSSBAR_CAPS_S)pSPD->PropertyInfo;

         // Copy the input property info to the output property info
         RtlCopyMemory( pCaps, pSPD->Property,
            sizeof( KSPROPERTY_CROSSBAR_CAPS_S ) );

         pCaps->NumberOfInputs  = adapter->xBar.GetNoInputs();
         pCaps->NumberOfOutputs = adapter->xBar.GetNoOutputs();

         pSrb->ActualBytesTransferred = sizeof( KSPROPERTY_CROSSBAR_CAPS_S );
      }
      break;
   case KSPROPERTY_CROSSBAR_CAN_ROUTE:
      DebugOut((1, "*** KSPROPERTY_CROSSBAR_CAN_ROUTE\n"));

      if ( nS >= sizeof( KSPROPERTY_CROSSBAR_ROUTE_S ) ) {

         PKSPROPERTY_CROSSBAR_ROUTE_S  pRoute =
            (PKSPROPERTY_CROSSBAR_ROUTE_S)pSPD->PropertyInfo;

         // Copy the input property info to the output property info
         RtlCopyMemory( pRoute, pSPD->Property,
            sizeof( KSPROPERTY_CROSSBAR_ROUTE_S ) );

         int InPin, OutPin;
         InPin  = pRoute->IndexInputPin;
         OutPin = pRoute->IndexOutputPin;

         if ( adapter->xBar.GoodPins( InPin, OutPin ) ) {
            DebugOut((1, "*** xBar.GoodPins succeeded\n"));
            pRoute->CanRoute = adapter->xBar.TestRoute( InPin, OutPin );
         } else {
            DebugOut((1, "*** xBar.GoodPins failed\n"));
            pRoute->CanRoute = FALSE;
         }
         pSrb->ActualBytesTransferred = sizeof( KSPROPERTY_CROSSBAR_ROUTE_S );
      }
      break;
   case KSPROPERTY_CROSSBAR_ROUTE:
      DebugOut((1, "*** KSPROPERTY_CROSSBAR_ROUTE\n"));

      if ( nS >= sizeof( KSPROPERTY_CROSSBAR_ROUTE_S ) ) {

         PKSPROPERTY_CROSSBAR_ROUTE_S  pRoute =
            (PKSPROPERTY_CROSSBAR_ROUTE_S)pSPD->PropertyInfo;

         // Copy the input property info to the output property info
         RtlCopyMemory( pRoute, pSPD->Property,
            sizeof( KSPROPERTY_CROSSBAR_ROUTE_S ) );

         int OutPin = pRoute->IndexOutputPin;

         if ( OutPin < adapter->xBar.GetNoOutputs() ) {
            DebugOut((1, "*** xBar.GetRoute(%d) called\n", OutPin));
            pRoute->IndexInputPin = adapter->xBar.GetRoute( OutPin );
         }
         else {
            pRoute->IndexInputPin = (DWORD) -1;
         }

         DebugOut((1, "*** pRoute->IndexInputPin = %d\n", pRoute->IndexInputPin));

         pSrb->ActualBytesTransferred = sizeof( KSPROPERTY_CROSSBAR_ROUTE_S );
      }
      break;
   case KSPROPERTY_CROSSBAR_PININFO:                     // R
      if ( nS >= sizeof( KSPROPERTY_CROSSBAR_PININFO_S ) ) {

         PKSPROPERTY_CROSSBAR_PININFO_S  pPinInfo =
            (PKSPROPERTY_CROSSBAR_PININFO_S)pSPD->PropertyInfo;

         // Copy the input property info to the output property info
         RtlCopyMemory( pPinInfo, pSPD->Property,
            sizeof( KSPROPERTY_CROSSBAR_PININFO_S ) );

         pPinInfo->PinType = adapter->xBar.GetPinInfo( pPinInfo->Direction,
            pPinInfo->Index,
            pPinInfo->RelatedPinIndex,
            &(pPinInfo->Medium));

         pSrb->ActualBytesTransferred = sizeof( KSPROPERTY_CROSSBAR_PININFO_S );
      }
   break;
   default:
       pSrb->ActualBytesTransferred = 0;
       break;
   }
   pSrb->Status = STATUS_SUCCESS;
}

// -------------------------------------------------------------------
// TVTuner Property Set functions
// -------------------------------------------------------------------
void AdapterSetTunerProperty( PHW_STREAM_REQUEST_BLOCK pSrb )
{
   Trace t("AdapterSetTunerProperty()");

   PHW_DEVICE_EXTENSION HwDeviceExtension =
      (PHW_DEVICE_EXTENSION) pSrb->HwDeviceExtension;

   PsDevice *adapter = HwDeviceExtension->psdevice;

   PSTREAM_PROPERTY_DESCRIPTOR pSPD = pSrb->CommandData.PropertyInfo;
   ULONG Id = pSPD->Property->Id;       // index of the property
   PVOID pV = pSPD->PropertyInfo;       // pointer to the data
   ULONG nS = pSPD->PropertyOutputSize; // size of data returned

   ASSERT( nS >= sizeof( ULONG ) );

   switch ( Id ) {
   case KSPROPERTY_TUNER_FREQUENCY:
      {
         PKSPROPERTY_TUNER_FREQUENCY_S pFreq =
            (PKSPROPERTY_TUNER_FREQUENCY_S)pV;
         adapter->SetChannel( pFreq->Frequency );
      }
      break;
   case KSPROPERTY_TUNER_MODE:
      {
         PKSPROPERTY_TUNER_MODE_S pMode =
            (PKSPROPERTY_TUNER_MODE_S)pV;
         ASSERT (pMode->Mode == KSPROPERTY_TUNER_MODE_TV);
      }
      break;
   default:
      // do not process input and standard as we don't have a choice of them
      break;
   }
   pSrb->Status = STATUS_SUCCESS;
}

void AdapterGetTunerProperty( PHW_STREAM_REQUEST_BLOCK pSrb )
{
   Trace t("AdapterGetTunerProperty()");

   PHW_DEVICE_EXTENSION HwDeviceExtension =
      (PHW_DEVICE_EXTENSION) pSrb->HwDeviceExtension;

   PsDevice *adapter = HwDeviceExtension->psdevice;

   PSTREAM_PROPERTY_DESCRIPTOR pSPD = pSrb->CommandData.PropertyInfo;
   ULONG Id = pSPD->Property->Id;        // index of the property
   PVOID pV = pSPD->PropertyInfo;        // pointer to the data
   ULONG nS = pSPD->PropertyOutputSize;  // size of data supplied

   ASSERT (nS >= sizeof (LONG));
   pSrb->ActualBytesTransferred = 0;

   switch ( Id ) {
   case KSPROPERTY_TUNER_CAPS:
      {
         PKSPROPERTY_TUNER_CAPS_S pCaps =
            (PKSPROPERTY_TUNER_CAPS_S)pSPD->Property;
         ASSERT (nS >= sizeof( KSPROPERTY_TUNER_CAPS_S ) );

         // now work with the output buffer
         pCaps =(PKSPROPERTY_TUNER_CAPS_S)pV;

         pCaps->ModesSupported = KSPROPERTY_TUNER_MODE_TV;
         pCaps->VideoMedium = TVTunerMediums[0];
         pCaps->TVAudioMedium = TVTunerMediums[1];
         pCaps->RadioAudioMedium.Set = GUID_NULL;   // No separate radio audio pin
         pCaps->RadioAudioMedium.Id = 0;
         pCaps->RadioAudioMedium.Flags = 0;

         pSrb->ActualBytesTransferred = sizeof( KSPROPERTY_TUNER_CAPS_S );
      }
      break;
   case KSPROPERTY_TUNER_MODE:
      {
         PKSPROPERTY_TUNER_MODE_S pMode =
            (PKSPROPERTY_TUNER_MODE_S)pV;
         ASSERT (nS >= sizeof( KSPROPERTY_TUNER_MODE_S ) );
         pMode->Mode = KSPROPERTY_TUNER_MODE_TV;

         pSrb->ActualBytesTransferred = sizeof( KSPROPERTY_TUNER_MODE_S);
      }
      break;
   case KSPROPERTY_TUNER_MODE_CAPS:
      {
         PKSPROPERTY_TUNER_MODE_CAPS_S pCaps =
            (PKSPROPERTY_TUNER_MODE_CAPS_S)pSPD->Property;
         ASSERT (nS >= sizeof( KSPROPERTY_TUNER_MODE_CAPS_S ) );

         ASSERT (pCaps->Mode == KSPROPERTY_TUNER_MODE_TV);

         // now work with the output buffer
         pCaps =(PKSPROPERTY_TUNER_MODE_CAPS_S)pV;

         //
         // List the formats actually supported by this tuner
         //

         pCaps->StandardsSupported = adapter->GetSupportedStandards();

         //
         // Get the min and max frequencies supported
         //

         pCaps->MinFrequency =  55250000L;
         pCaps->MaxFrequency = 997250000L;

         //
         // What is the frequency step size?
         //

         pCaps->TuningGranularity = 62500L;

         //
         // How many inputs are on the tuner?
         //

         pCaps->NumberOfInputs = 1;

         //
         // What is the maximum settling time in milliseconds?
         //

         pCaps->SettlingTime = 150;

         //
         // Strategy defines how the tuner knows when it is in tune:
         //
         // KS_TUNER_STRATEGY_PLL (Has PLL offset information)
         // KS_TUNER_STRATEGY_SIGNAL_STRENGTH (has signal strength info)
         // KS_TUNER_STRATEGY_DRIVER_TUNES (driver handles all fine tuning)
         //

         pCaps->Strategy = KS_TUNER_STRATEGY_PLL;

         pSrb->ActualBytesTransferred = sizeof( KSPROPERTY_TUNER_MODE_CAPS_S );
      }
      break;
   case KSPROPERTY_TUNER_STATUS:
      // Return the status of the tuner

      // PLLOffset is in units of TuningGranularity 
      // SignalStrength is 0 to 100
      // Set Busy to 1 if tuning is still in process

      {
         PKSPROPERTY_TUNER_STATUS_S pStat =
            (PKSPROPERTY_TUNER_STATUS_S)pSPD->Property;
         ASSERT( nS >= sizeof( KSPROPERTY_TUNER_STATUS_S ) );

         // typedef struct {
         //     KSPROPERTY Property;
         //     ULONG  CurrentFrequency;            // Hz
         //     ULONG  PLLOffset;                   // if Strategy.KS_TUNER_STRATEGY_PLL
         //     ULONG  SignalStrength;              // if Stretegy.KS_TUNER_STRATEGY_SIGNAL_STRENGTH
         //     ULONG  Busy;                        // TRUE if in the process of tuning
         // } KSPROPERTY_TUNER_STATUS_S, *PKSPROPERTY_TUNER_STATUS_S;

         // now work with the output buffer
         pStat = PKSPROPERTY_TUNER_STATUS_S( pV );
         pStat->PLLOffset = adapter->GetPllOffset( &pStat->Busy,
            pStat->CurrentFrequency );

         pSrb->ActualBytesTransferred = sizeof( KSPROPERTY_TUNER_STATUS_S );
      }
      break;
   case KSPROPERTY_TUNER_STANDARD:
      {
         PKSPROPERTY_TUNER_STANDARD_S pStd =
            (PKSPROPERTY_TUNER_STANDARD_S)pSPD->Property;
         ASSERT( nS >= sizeof( KSPROPERTY_TUNER_STANDARD_S ) );

         // now work with the output buffer
         pStd = PKSPROPERTY_TUNER_STANDARD_S( pV );

         pStd->Standard = KS_AnalogVideo_NTSC_M; // our TEMIC tuner supports this only
         pSrb->ActualBytesTransferred = sizeof( KSPROPERTY_TUNER_STANDARD_S );
      }
      break;
   case KSPROPERTY_TUNER_INPUT:
      {
         PKSPROPERTY_TUNER_INPUT_S pIn =
            (PKSPROPERTY_TUNER_INPUT_S)pSPD->Property;
         ASSERT( nS >= sizeof( KSPROPERTY_TUNER_INPUT_S ) );

         // now work with the output buffer
         pIn = PKSPROPERTY_TUNER_INPUT_S( pV );

         // What is the currently selected input?
         pIn->InputIndex = 0;
         pSrb->ActualBytesTransferred = sizeof( KSPROPERTY_TUNER_INPUT_S );
      }
      break;
   default:
       break;
   }
   pSrb->Status = STATUS_SUCCESS;
}

// -------------------------------------------------------------------
// VideoProcAmp functions
// -------------------------------------------------------------------

VOID AdapterSetVideoProcAmpProperty( PHW_STREAM_REQUEST_BLOCK pSrb )
{
   Trace t("AdapterSetVideoProcAmpProperty()");

   PHW_DEVICE_EXTENSION HwDeviceExtension =
      (PHW_DEVICE_EXTENSION) pSrb->HwDeviceExtension;

   PsDevice *adapter = HwDeviceExtension->psdevice;

   PSTREAM_PROPERTY_DESCRIPTOR pSPD = pSrb->CommandData.PropertyInfo;
   ULONG Id = pSPD->Property->Id;              // index of the property
   PKSPROPERTY_VIDEOPROCAMP_S pS = (PKSPROPERTY_VIDEOPROCAMP_S) pSPD->PropertyInfo;    // pointer to the data

   ASSERT (pSPD->PropertyOutputSize >= sizeof (KSPROPERTY_VIDEOPROCAMP_S));

   switch ( Id ) {
   case KSPROPERTY_VIDEOPROCAMP_BRIGHTNESS:
      adapter->SetBrightness( pS->Value );
      break;
   case KSPROPERTY_VIDEOPROCAMP_CONTRAST:
      adapter->SetContrast( pS->Value );
      break;
   case KSPROPERTY_VIDEOPROCAMP_HUE:
      adapter->SetHue( pS->Value );
      break;
   case KSPROPERTY_VIDEOPROCAMP_SATURATION:
      adapter->SetSaturation( pS->Value );
      break;
   default:
      break;
   }
   pSrb->Status = STATUS_SUCCESS;
}

/* Method: AdapterGetVideoProcAmpProperty
 * Purpose: Gets various video procamp properties
 */
VOID AdapterGetVideoProcAmpProperty( PHW_STREAM_REQUEST_BLOCK pSrb )
{
   Trace t("AdapterGetVideoProcAmpProperty()");

   PHW_DEVICE_EXTENSION HwDeviceExtension =
      (PHW_DEVICE_EXTENSION) pSrb->HwDeviceExtension;

   PsDevice *adapter = HwDeviceExtension->psdevice;

   PSTREAM_PROPERTY_DESCRIPTOR pSPD = pSrb->CommandData.PropertyInfo;
   ULONG Id = pSPD->Property->Id;              // index of the property
   PKSPROPERTY_VIDEOPROCAMP_S pS = (PKSPROPERTY_VIDEOPROCAMP_S) pSPD->PropertyInfo;    // pointer to the data

   ASSERT( pSPD->PropertyOutputSize >= sizeof( KSPROPERTY_VIDEOPROCAMP_S ) );

   switch ( Id ) {
   case KSPROPERTY_VIDEOPROCAMP_BRIGHTNESS:
      pS->Value = adapter->GetBrightness();
		pS->Flags = pS->Capabilities = KSPROPERTY_VIDEOPROCAMP_FLAGS_MANUAL;
      break;
   case KSPROPERTY_VIDEOPROCAMP_CONTRAST:
      pS->Value = adapter->GetContrast();
		pS->Flags = pS->Capabilities = KSPROPERTY_VIDEOPROCAMP_FLAGS_MANUAL;
      break;
   case KSPROPERTY_VIDEOPROCAMP_HUE:
      pS->Value = adapter->GetHue();
		pS->Flags = pS->Capabilities = KSPROPERTY_VIDEOPROCAMP_FLAGS_MANUAL;
      break;
   case KSPROPERTY_VIDEOPROCAMP_SATURATION:
      pS->Value = adapter->GetSaturation();
		pS->Flags = pS->Capabilities = KSPROPERTY_VIDEOPROCAMP_FLAGS_MANUAL;
      break;
   default:
      DebugOut((1, "*** AdapterGetVideoProcAmpProperty - KSPROPERTY_??? (%d) ***\n", Id));
   }
   pSrb->ActualBytesTransferred = sizeof( KSPROPERTY_VIDEOPROCAMP_S );
   pSrb->Status = STATUS_SUCCESS;
}

/* Method: AdapterSetVideoDecProperty
 * Purpose: Manipulates various video decoder properties
 * Input: SRB
 * Output: None
 */
void AdapterSetVideoDecProperty( PHW_STREAM_REQUEST_BLOCK pSrb )
{
   Trace t("AdapterSetVideoDecProperty()");

   PHW_DEVICE_EXTENSION HwDeviceExtension =
      (PHW_DEVICE_EXTENSION) pSrb->HwDeviceExtension;

   PsDevice *adapter = HwDeviceExtension->psdevice;

   PSTREAM_PROPERTY_DESCRIPTOR pSPD = pSrb->CommandData.PropertyInfo;
   ULONG Id = pSPD->Property->Id;              // index of the property

   switch ( Id ) {
   case KSPROPERTY_VIDEODECODER_STANDARD: {
         PKSPROPERTY_VIDEODECODER_S pVDecStd =
            (PKSPROPERTY_VIDEODECODER_S)pSPD->PropertyInfo;
         adapter->SetFormat( pVDecStd->Value );
      }
      break;
   case KSPROPERTY_VIDEODECODER_STATUS:
      break;
   }
}

/* Method: AdapterGetVideoDecProperty
 * Purpose: Obtains various video decoder properties
 * Input: SRB
 * Output: None
 */
void AdapterGetVideoDecProperty( PHW_STREAM_REQUEST_BLOCK pSrb )
{
   Trace t("AdapterGetVideoDecProperty()");
   
   PHW_DEVICE_EXTENSION HwDeviceExtension =
      (PHW_DEVICE_EXTENSION) pSrb->HwDeviceExtension;

   PsDevice *adapter = HwDeviceExtension->psdevice;

   PSTREAM_PROPERTY_DESCRIPTOR pSPD = pSrb->CommandData.PropertyInfo;
   ULONG Id = pSPD->Property->Id;              // index of the property

   switch ( Id ) {
   case KSPROPERTY_VIDEODECODER_CAPS: {
         PKSPROPERTY_VIDEODECODER_CAPS_S pVDecCaps =
            (PKSPROPERTY_VIDEODECODER_CAPS_S)pSPD->PropertyInfo;
         pVDecCaps->StandardsSupported = KS_AnalogVideo_NTSC_M;
         pVDecCaps->Capabilities = 
             // KS_VIDEODECODER_FLAGS_CAN_DISABLE_OUTPUT | 
                KS_VIDEODECODER_FLAGS_CAN_USE_VCR_LOCKING |
                KS_VIDEODECODER_FLAGS_CAN_INDICATE_LOCKED;
         pVDecCaps->SettlingTime = 10;    // How long to delay after tuning
                                          // before locked indicator is valid
         pVDecCaps-> HSyncPerVSync = 6;   // HSync per VSync
         pSrb->ActualBytesTransferred = sizeof (KSPROPERTY_VIDEODECODER_CAPS_S);
      }
      break;
   case KSPROPERTY_VIDEODECODER_STANDARD: {
         // Return the currently active analog video mode
         PKSPROPERTY_VIDEODECODER_S pVDecStd =
            (PKSPROPERTY_VIDEODECODER_S)pSPD->PropertyInfo;
         //pVDecStd->Value = GetSupportedStandards();
         pVDecStd->Value = KS_AnalogVideo_NTSC_M;
         pSrb->ActualBytesTransferred = sizeof (KSPROPERTY_VIDEODECODER_S);
      }
      break;
   case KSPROPERTY_VIDEODECODER_STATUS: {
         PKSPROPERTY_VIDEODECODER_STATUS_S pVDecStat =
            (PKSPROPERTY_VIDEODECODER_STATUS_S)pSPD->PropertyInfo;
         pVDecStat->NumberOfLines = adapter->GetFormat() == VFormat_NTSC ? 525 : 625;
         pVDecStat->SignalLocked = adapter->CaptureContrll_.PsDecoder_.IsDeviceInHLock();
         pSrb->ActualBytesTransferred = sizeof (KSPROPERTY_VIDEODECODER_S);
      }
      break;
   default:
      DebugOut((1, "*** AdapterGetVideoDecProperty - KSPROPERTY_??? (%d) ***\n", Id));
   }
}
// -------------------------------------------------------------------
// TVAudio functions
// -------------------------------------------------------------------

/*
** AdapterSetTVAudioProperty ()
**
**    Handles Set operations on the TVAudio property set.
**      Testcap uses this for demo purposes only.
**
** Arguments:
**
**      pSRB -
**          Pointer to the HW_STREAM_REQUEST_BLOCK 
**
** Returns:
**
** Side Effects:  none
*/

ULONG gTVAudioMode = 0;
VOID 
AdapterSetTVAudioProperty(
    PHW_STREAM_REQUEST_BLOCK pSrb
    )
{
    PSTREAM_PROPERTY_DESCRIPTOR pSPD = pSrb->CommandData.PropertyInfo;
    ULONG Id = pSPD->Property->Id;              // index of the property

    switch (Id) {

    case KSPROPERTY_TVAUDIO_MODE:
    {
        PKSPROPERTY_TVAUDIO_S pS = (PKSPROPERTY_TVAUDIO_S) pSPD->PropertyInfo;    
        gTVAudioMode = pS->Mode;
    }
    break;

    default:
        break;
    }
}

/*
** AdapterGetTVAudioProperty ()
**
**    Handles Get operations on the TVAudio property set.
**      Testcap uses this for demo purposes only.
**
** Arguments:
**
**      pSRB -
**          Pointer to the HW_STREAM_REQUEST_BLOCK 
**
** Returns:
**
** Side Effects:  none
*/

VOID 
AdapterGetTVAudioProperty(
    PHW_STREAM_REQUEST_BLOCK pSrb
    )
{
    PSTREAM_PROPERTY_DESCRIPTOR pSPD = pSrb->CommandData.PropertyInfo;
    ULONG Id = pSPD->Property->Id;              // index of the property

    switch (Id) {

    case KSPROPERTY_TVAUDIO_CAPS:
    {
        DebugOut((1, "KSPROPERTY_TVAUDIO_CAPS\n"));

        PKSPROPERTY_TVAUDIO_CAPS_S pS = (PKSPROPERTY_TVAUDIO_CAPS_S) pSPD->PropertyInfo;    // pointer to the data

        ASSERT (pSPD->PropertyOutputSize >= sizeof (KSPROPERTY_TVAUDIO_CAPS_S));
        
        pS->InputMedium  = TVAudioMediums[0];
        pS->InputMedium.Id = 0; //(ULONG) pHwDevExt;  // Multiple instance support
        pS->OutputMedium = TVAudioMediums[1];
        pS->OutputMedium.Id = 0; //(ULONG) pHwDevExt;  // Multiple instance support

        // Report all of the possible audio decoding modes the hardware is capabable of
        pS->Capabilities = KS_TVAUDIO_MODE_MONO   |
                           KS_TVAUDIO_MODE_STEREO |
                           KS_TVAUDIO_MODE_LANG_A |
                           KS_TVAUDIO_MODE_LANG_B ;

        pSrb->ActualBytesTransferred = sizeof (KSPROPERTY_TVAUDIO_CAPS_S);
    }
    break;
        
    case KSPROPERTY_TVAUDIO_MODE:
    {
        DebugOut((1, "KSPROPERTY_TVAUDIO_MODE\n"));
        PKSPROPERTY_TVAUDIO_S pS = (PKSPROPERTY_TVAUDIO_S) pSPD->PropertyInfo;    // pointer to the data

        ASSERT (pSPD->PropertyOutputSize >= sizeof (KSPROPERTY_TVAUDIO_S));
        // Report the currently selected mode
        pS->Mode = gTVAudioMode;

        pSrb->ActualBytesTransferred = sizeof (KSPROPERTY_TVAUDIO_S);
    }
    break;

    case KSPROPERTY_TVAUDIO_CURRENTLY_AVAILABLE_MODES:
    {
        DebugOut((1, "KSPROPERTY_TVAUDIO_CURRENTLY_AVAILABLE_MODES\n"));
        PKSPROPERTY_TVAUDIO_S pS = (PKSPROPERTY_TVAUDIO_S) pSPD->PropertyInfo;    // pointer to the data

        ASSERT (pSPD->PropertyOutputSize >= sizeof (KSPROPERTY_TVAUDIO_S));
        // Report which audio modes could potentially be selected right now
        pS->Mode = KS_TVAUDIO_MODE_MONO   |
                   KS_TVAUDIO_MODE_STEREO |
                   KS_TVAUDIO_MODE_LANG_A ;

        pSrb->ActualBytesTransferred = sizeof (KSPROPERTY_TVAUDIO_S);
    }
    break;
    
    default:
        DebugOut((0, "default - unrecognized (%x)\n", Id));
        break;
    }
}

/* Method: AdapterSetProperty
 * Purpose: Selects which adapter property to set
 */
VOID AdapterSetProperty( PHW_STREAM_REQUEST_BLOCK pSrb )
{
   Trace t("AdapterSetProperty()");

   PHW_DEVICE_EXTENSION HwDeviceExtension =
      (PHW_DEVICE_EXTENSION) pSrb->HwDeviceExtension;

   PsDevice *adapter = HwDeviceExtension->psdevice;

   PSTREAM_PROPERTY_DESCRIPTOR pSPD = pSrb->CommandData.PropertyInfo;

   if ( IsEqualGUID( PROPSETID_VIDCAP_CROSSBAR, pSPD->Property->Set ) )  {
      AdapterSetCrossbarProperty( pSrb );
   } else if ( IsEqualGUID( PROPSETID_TUNER, pSPD->Property->Set ) )  {
      AdapterSetTunerProperty( pSrb );
   } else if ( IsEqualGUID( PROPSETID_VIDCAP_VIDEOPROCAMP, pSPD->Property->Set ) )  {
      AdapterSetVideoProcAmpProperty( pSrb );
   } else if ( IsEqualGUID( PROPSETID_VIDCAP_VIDEODECODER, pSPD->Property->Set ) )  {
      AdapterSetVideoDecProperty( pSrb );
   } else if (IsEqualGUID( PROPSETID_VIDCAP_TVAUDIO, pSPD->Property->Set))  {
      AdapterSetTVAudioProperty( pSrb );
   } else {
      DebugOut((0, "AdapterSetProperty unrecognized GUID: pSrb(%x), pSPD->Property->Set(%x)\n", pSrb, pSPD->Property->Set));
   }
}

/* Method: AdapterGetProperty
 * Purpose: Selects which adapter property to get
 */
VOID AdapterGetProperty( PHW_STREAM_REQUEST_BLOCK pSrb )

{
   Trace t("AdapterGetProperty()");

   PHW_DEVICE_EXTENSION HwDeviceExtension =
      (PHW_DEVICE_EXTENSION) pSrb->HwDeviceExtension;

   PsDevice *adapter = HwDeviceExtension->psdevice;

   PSTREAM_PROPERTY_DESCRIPTOR pSPD = pSrb->CommandData.PropertyInfo;

   if ( IsEqualGUID( PROPSETID_VIDCAP_CROSSBAR, pSPD->Property->Set ) )  {
      AdapterGetCrossbarProperty( pSrb );
   } else if ( IsEqualGUID( PROPSETID_TUNER, pSPD->Property->Set ) )  {
      AdapterGetTunerProperty( pSrb );
   } else if ( IsEqualGUID( PROPSETID_VIDCAP_VIDEOPROCAMP, pSPD->Property->Set ) )  {
      AdapterGetVideoProcAmpProperty( pSrb );
   } else if ( IsEqualGUID( PROPSETID_VIDCAP_VIDEODECODER, pSPD->Property->Set ) )  {
      AdapterGetVideoDecProperty( pSrb );
   } else if (IsEqualGUID( PROPSETID_VIDCAP_TVAUDIO, pSPD->Property->Set))  {
      AdapterGetTVAudioProperty( pSrb );
   } else {
      DebugOut((0, "AdapterGetProperty unrecognized GUID: pSrb(%x), pSPD->Property->Set(%x)\n", pSrb, pSPD->Property->Set));
   }
}
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\drivers\wdm\capture\mini\bt848\capmain.h ===
// $Header: G:/SwDev/WDM/Video/bt848/rcs/Capmain.h 1.9 1998/05/11 23:59:56 tomz Exp $

//==========================================================================;
//
//  THIS CODE AND INFORMATION IS PROVIDED "AS IS" WITHOUT WARRANTY OF ANY
//  KIND, EITHER EXPRESSED OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE
//  IMPLIED WARRANTIES OF MERCHANTABILITY AND/OR FITNESS FOR A PARTICULAR
//  PURPOSE.
//
//  Copyright (c) 1992 - 1996  Microsoft Corporation.  All Rights Reserved.
//
//==========================================================================;

#ifndef __CAPMAIN_H__
#define __CAPMAIN_H__

#ifdef __cplusplus
extern "C" {
#endif // __cplusplus

#include "device.h"

//	adapted from ksmedia.h
#define KS_SIZE_PREHEADER2 (FIELD_OFFSET(KS_VIDEOINFOHEADER2,bmiHeader))
#define KS_SIZE_VIDEOHEADER2(pbmi) ((pbmi)->bmiHeader.biSize + KS_SIZE_PREHEADER2)


/*****************************************************************************
*
* The following structures are samples of information that could be used in
* a device extension structure
*
*****************************************************************************/

//
// definition of the full HW device extension structure This is the structure
// that will be allocated in HW_INITIALIZATION by the stream class driver
// Any information that is used in processing a device request (as opposed to
// a STREAM based request) should be in this structure.  A pointer to this
// structure will be passed in all requests to the minidriver. (See
// HW_STREAM_REQUEST_BLOCK in STRMINI.H)
//

typedef struct _HW_DEVICE_EXTENSION {
   PsDevice *psdevice;
   //PULONG                   ioBaseLocal;                // board base address
   //USHORT                   Irq;                        // irq level
   //PHW_STREAM_REQUEST_BLOCK pCurSrb;       // current device request in progress

   // The following will be the memory where we store or PsDevice class instance
   // This must be last
   DWORD psdevicemem[1];
} HW_DEVICE_EXTENSION, *PHW_DEVICE_EXTENSION;

//
// this structure is our per stream extension structure.  This stores
// information that is relevant on a per stream basis.  Whenever a new stream
// is opened, the stream class driver will allocate whatever extension size
// is specified in the HwInitData.PerStreamExtensionSize.
//

typedef union {
   KS_FRAME_INFO     VideoFrameInfo;
   KS_VBI_FRAME_INFO VbiFrameInfo;
} ALL_FRAME_INFO;

typedef struct _STREAMEX {

   PVOID          videochannel;
   ALL_FRAME_INFO FrameInfo;
   ULONG          StreamNumber;
   //KS_VIDEOINFOHEADER         *pVideoInfoHeader;  // format (variable size!)
   //KSSTATE                     KSState;        // Run, Stop, Pause
   //BOOLEAN                     fStreamOpen;    // TRUE if stream is open
   //STREAM_SYSTEM_TIME          videoSTC;       // current video presentation time
   //PHW_STREAM_REQUEST_BLOCK    pCurrentSRB;    // video request in progress
   //PVOID                       pDMABuf;        // pointer to the video DMA buffer
   //STREAM_PHYSICAL_ADDRESS     pPhysDmaBuf;    // physical address of DMA buffer
   //ULONG                       cDmaBuf;        // size of DMA buffer
   //KSSTATE                     DeviceState;    // current device state
   //BOOLEAN                     IRQExpected;    // IRQ expected

   // The following will be the memory where we store or PsDevice class instance
   // This must be last
   DWORD    videochannelmem[1];
} STREAMEX, *PSTREAMEX;

 
//
// this structure defines the per request extension.  It defines any storage
// space that the min driver may need in each request packet.
//

typedef struct _SRB_EXTENSION {
    LIST_ENTRY                  ListEntry;
    PHW_STREAM_REQUEST_BLOCK    pSrb;
    HANDLE                      hUserSurfaceHandle;      // DDraw
    HANDLE                      hKernelSurfaceHandle;    // DDraw
} SRB_EXTENSION, * PSRB_EXTENSION;


/*****************************************************************************
*
* the following section defines prototypes for the minidriver initialization
* routines
*
******************************************************************************/

//
// DriverEntry:
//
// This routine is called when the mini driver is first loaded.  The driver
// should then call the StreamClassRegisterAdapter function to register with
// the stream class driver
//

ULONG DriverEntry (PVOID Context1, PVOID Context2);

//
// This routine is called by the stream class driver with configuration
// information for an adapter that the mini driver should load on.  The mini
// driver should still perform a small verification to determine that the
// adapter is present at the specified addresses, but should not attempt to
// find an adapter as it would have with previous NT miniports.
//
// All initialization of the adapter should also be performed at this time.
//

BOOLEAN HwInitialize (IN OUT PHW_STREAM_REQUEST_BLOCK pSrb);

//
// This routine is called when the system is going to remove or disable the
// device.
//
// The mini-driver should free any system resources that it allocated at this
// time.  Note that system resources allocated for the mini-driver by the
// stream class driver will be free'd by the stream driver, and should not be
// free'd in this routine.  (Such as the HW_DEVICE_EXTENSION)
//

BOOLEAN HwUnInitialize ( IN PVOID DeviceExtension);


BOOLEAN HwQueryUnload ( IN PVOID DeviceExtension);


//
// This is the prototype for the Hardware Interrupt Handler.  This routine
// will be called whenever the minidriver receives an interrupt
//

BOOLEAN HwInterrupt ( IN PHW_DEVICE_EXTENSION pDeviceExtension );

//
// This is the prototype for the stream enumeration function.  This routine
// provides the stream class driver with the information on data stream types
// supported
//

VOID AdapterStreamInfo(PHW_STREAM_REQUEST_BLOCK pSrb);

//
// This is the prototype for the stream open function
//

VOID AdapterOpenStream(PHW_STREAM_REQUEST_BLOCK pSrb);

//
// This is the prototype for the stream close function
//

VOID AdapterCloseStream(PHW_STREAM_REQUEST_BLOCK pSrb);

//
// This is the prototype for the AdapterReceivePacket routine.  This is the
// entry point for command packets that are sent to the adapter (not to a
// specific open stream)
//

VOID STREAMAPI AdapterReceivePacket(IN PHW_STREAM_REQUEST_BLOCK Srb);

//
// This is the protoype for the cancel packet routine.  This routine enables
// the stream class driver to cancel an outstanding packet.
//

VOID STREAMAPI AdapterCancelPacket(IN PHW_STREAM_REQUEST_BLOCK Srb);

//
// This is the packet timeout function.  The adapter may choose to ignore a
// packet timeout, or rest the adapter and cancel the requests, as required.
//

VOID STREAMAPI AdapterTimeoutPacket(IN PHW_STREAM_REQUEST_BLOCK Srb);

//
// prototypes for data handling routines
//

VOID STREAMAPI VideoReceiveDataPacket(IN PHW_STREAM_REQUEST_BLOCK pSrb);
VOID STREAMAPI VideoReceiveCtrlPacket(IN PHW_STREAM_REQUEST_BLOCK pSrb);
VOID STREAMAPI AnalogReceiveDataPacket(IN PHW_STREAM_REQUEST_BLOCK pSrb);
VOID STREAMAPI AnalogReceiveCtrlPacket(IN PHW_STREAM_REQUEST_BLOCK pSrb);
void EnableIRQ(PHW_STREAM_OBJECT pstrm);
void DisableIRQ(PHW_STREAM_OBJECT pstrm);

//
// prototypes for properties and states
//

//VOID SetVideoState(PHW_STREAM_REQUEST_BLOCK pSrb);
void GetVidLvl(PHW_STREAM_REQUEST_BLOCK pSrb);
VOID GetVideoProperty(PHW_STREAM_REQUEST_BLOCK pSrb);


#ifdef ENABLE_DDRAW_STUFF
   DWORD FAR PASCAL DirectDrawEventCallback( DWORD, PVOID, DWORD, DWORD );
   BOOL RegisterForDirectDrawEvents( PHW_STREAM_REQUEST_BLOCK );
   BOOL UnregisterForDirectDrawEvents( PHW_STREAM_REQUEST_BLOCK );
   BOOL OpenKernelDirectDraw( PHW_STREAM_REQUEST_BLOCK );
   BOOL CloseKernelDirectDraw( PHW_STREAM_REQUEST_BLOCK );
   BOOL IsKernelLockAndFlipAvailable( PHW_STREAM_REQUEST_BLOCK );
   BOOL OpenKernelDDrawSurfaceHandle( IN PHW_STREAM_REQUEST_BLOCK );
   BOOL CloseKernelDDrawSurfaceHandle( IN PHW_STREAM_REQUEST_BLOCK );
   BOOL FlipOverlay( HANDLE, HANDLE, HANDLE );
#endif


#ifdef    __cplusplus
}
#endif // __cplusplus

#endif //__CAPMAIN_H__
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\drivers\wdm\capture\mini\bt848\capstrm.h ===
// $Header: G:/SwDev/WDM/Video/bt848/rcs/Capstrm.h 1.14 1998/05/01 05:05:10 tomz Exp $

//==========================================================================;
//
//  THIS CODE AND INFORMATION IS PROVIDED "AS IS" WITHOUT WARRANTY OF ANY
//  KIND, EITHER EXPRESSED OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE
//  IMPLIED WARRANTIES OF MERCHANTABILITY AND/OR FITNESS FOR A PARTICULAR
//  PURPOSE.
//
//  Copyright (c) 1992 - 1996  Microsoft Corporation.  All Rights Reserved.
//
//==========================================================================;

#ifndef __CAPSTRM_H__
#define __CAPSTRM_H__

#ifdef __cplusplus
extern "C" {
#endif // __cplusplus


//---------------------------------------------------------------------------
// All of the data formats we might use
//---------------------------------------------------------------------------

#include "rgb24fmt.h"
#include "rgb16fmt.h"
#include "yuvfmt.h"
#include "vbifmt.h"

//---------------------------------------------------------------------------
//  Stream 0 (Capture) Formats
//---------------------------------------------------------------------------

PKSDATAFORMAT Stream0Formats[] =
{
   // prefer RGB first for capture
   
   (PKSDATAFORMAT) &StreamFormatRGB555,
   //(PKSDATAFORMAT) &StreamFormatRGB565,
   (PKSDATAFORMAT) &StreamFormatRGB24Bpp,

   (PKSDATAFORMAT) &StreamFormatYUY2
   //(PKSDATAFORMAT) &StreamFormatYVYU,
   //(PKSDATAFORMAT) &StreamFormatUYVY,
   //(PKSDATAFORMAT) &StreamFormatYVU9
};
#define NUM_STREAM_0_FORMATS (sizeof (Stream0Formats) / sizeof (PKSDATAFORMAT))

//---------------------------------------------------------------------------
//  Stream 1 (Preview) Formats
//---------------------------------------------------------------------------

PKSDATAFORMAT Stream1Formats[] =
{
   // prefer YUV first for preview
#if 0
	//TODO: leave VIDEOINFOHEADER2 out for now
   (PKSDATAFORMAT) &StreamFormat2YUY2,
   (PKSDATAFORMAT) &StreamFormat2RGB555,
   (PKSDATAFORMAT) &StreamFormat2RGB24Bpp,
#else
   (PKSDATAFORMAT) &StreamFormatYUY2,
   (PKSDATAFORMAT) &StreamFormatRGB555,
   (PKSDATAFORMAT) &StreamFormatRGB24Bpp
#endif
   //(PKSDATAFORMAT) &StreamFormatYVYU,
   //(PKSDATAFORMAT) &StreamFormatUYVY,
   //(PKSDATAFORMAT) &StreamFormatYVU9,
   //(PKSDATAFORMAT) &StreamFormatRGB565,
};
#define NUM_STREAM_1_FORMATS (sizeof (Stream1Formats) / sizeof (PKSDATAFORMAT))

//---------------------------------------------------------------------------
//  VBI Stream Formats
//---------------------------------------------------------------------------

PKSDATAFORMAT VBIStreamFormats[] =
{
   (PKSDATAFORMAT) &StreamFormatVBI
};

#define NUM_VBI_FORMATS (sizeof (VBIStreamFormats) / sizeof (PKSDATAFORMAT))

//---------------------------------------------------------------------------
//  Analog Video Stream Formats
//---------------------------------------------------------------------------

static KS_DATARANGE_ANALOGVIDEO StreamFormatAnalogVideo =
{
   // KS_DATARANGE_ANALOGVIDEO
   {
      {
         sizeof( KS_DATARANGE_ANALOGVIDEO ),
         0,
         sizeof (KS_TVTUNER_CHANGE_INFO),        // SampleSize
         0,
         { 0x482dde1, 0x7817, 0x11cf, { 0x8a, 0x3, 0x0, 0xaa, 0x0, 0x6e, 0xcb, 0x65 } },  // MEDIATYPE_AnalogVideo
         { 0x482dde2, 0x7817, 0x11cf, { 0x8a, 0x3, 0x0, 0xaa, 0x0, 0x6e, 0xcb, 0x65 } },  // WILDCARD
         { 0x482dde0, 0x7817, 0x11cf, { 0x8a, 0x3, 0x0, 0xaa, 0x0, 0x6e, 0xcb, 0x65 } }  // FORMAT_AnalogVideo
      }
   },
   // KS_ANALOGVIDEOINFO
   {
      { 0, 0, 720, 480 },         // rcSource;
      { 0, 0, 720, 480 },         // rcTarget;
      720,                    // dwActiveWidth;
      480,                    // dwActiveHeight;
      0,                      // REFERENCE_TIME  AvgTimePerFrame;
   }
};

static PKSDATAFORMAT AnalogVideoFormats[] =
{
   (PKSDATAFORMAT) &StreamFormatAnalogVideo,
};
#define NUM_ANALOG_VIDEO_FORMATS SIZEOF_ARRAY( AnalogVideoFormats )

// ------------------------------------------------------------------------
// Property set for all video capture streams
// ------------------------------------------------------------------------

DEFINE_KSPROPERTY_TABLE( VideoStreamConnectionProperties )
{
   DEFINE_KSPROPERTY_ITEM
   (
      KSPROPERTY_CONNECTION_ALLOCATORFRAMING,
      TRUE,                                   // GetSupported or Handler
      sizeof( KSPROPERTY ),                   // MinProperty
      sizeof( KSALLOCATOR_FRAMING ),          // MinData
      FALSE,                                  // SetSupported or Handler
      NULL,                                   // Values
      0,                                      // RelationsCount
      NULL,                                   // Relations
      NULL,                                   // SupportHandler
      sizeof( ULONG )                         // SerializedSize
   )
};


// ------------------------------------------------------------------------
// Array of all of the property sets supported by video streams
// ------------------------------------------------------------------------

DEFINE_KSPROPERTY_SET_TABLE( VideoStreamProperties )
{
    DEFINE_KSPROPERTY_SET
    (
        &KSPROPSETID_Connection,                          // Set
        SIZEOF_ARRAY( VideoStreamConnectionProperties ),  // PropertiesCount
        VideoStreamConnectionProperties,                  // PropertyItem
        0,                                                // FastIoCount
        NULL                                              // FastIoTable
    )
};

#define NUMBER_VIDEO_STREAM_PROPERTIES (SIZEOF_ARRAY(VideoStreamProperties))


//---------------------------------------------------------------------------
// Create an array that holds the list of all of the streams supported
//---------------------------------------------------------------------------

typedef struct _ALL_STREAM_INFO {
    HW_STREAM_INFORMATION   hwStreamInfo;
    HW_STREAM_OBJECT        hwStreamObject;
} ALL_STREAM_INFO, *PALL_STREAM_INFO;

ALL_STREAM_INFO Streams [] =
{
   // -----------------------------------------------------------------
   // Stream 0
   // -----------------------------------------------------------------

   // HW_STREAM_INFORMATION -------------------------------------------
   {
      {
         1,                                              // NumberOfPossibleInstances
         KSPIN_DATAFLOW_OUT,                             // DataFlow
         TRUE,                                           // DataAccessible
         NUM_STREAM_0_FORMATS,                           // NumberOfFormatArrayEntries
         Stream0Formats,                                 // StreamFormatsArray
         {
            0,                                              // ClassReserved[0]
            0,                                              // ClassReserved[1]
            0,                                              // ClassReserved[2]
            0                                               // ClassReserved[3]
         },
         NUMBER_VIDEO_STREAM_PROPERTIES,                 // NumStreamPropArrayEntries
         (PKSPROPERTY_SET)VideoStreamProperties,         // StreamPropertiesArray
         0,                                              // NumStreamEventArrayEntries;
         0,                                              // StreamEventsArray;
         (GUID *) &PINNAME_VIDEO_CAPTURE,                // Category
         (GUID *) &PINNAME_VIDEO_CAPTURE,                // Name
         1,                                              // MediumsCount
         &CaptureMediums[0],                             // Mediums
      },
		// HW_STREAM_OBJECT ------------------------------------------------
		{
			sizeof (HW_STREAM_OBJECT),              // SizeOfThisPacket
			0,                                      // StreamNumber
			0,                                      // HwStreamExtension
			VideoReceiveDataPacket,                 // HwReceiveDataPacket
			VideoReceiveCtrlPacket,                 // HwReceiveControlPacket
			{ NULL, 0 },                            // HW_CLOCK_OBJECT
			FALSE,                                  // Dma
			TRUE,                                   // Pio
			NULL,                                   // HwDeviceExtension
			sizeof (KS_FRAME_INFO),                 // StreamHeaderMediaSpecific
			0,                                      // StreamHeaderWorkspace 
			TRUE,                                  // Allocator 
			NULL,                                   // HwEventRoutine
			{ 0, 0 },                               // Reserved[2]
		},            
   },

   // -----------------------------------------------------------------
   // Stream 1
   // -----------------------------------------------------------------

   // HW_STREAM_INFORMATION -------------------------------------------
   {
      {
         1,                                              // NumberOfPossibleInstances
         KSPIN_DATAFLOW_OUT,                             // DataFlow
         TRUE,                                           // DataAccessible
         NUM_STREAM_1_FORMATS,                           // NumberOfFormatArrayEntries
         Stream1Formats,                                 // StreamFormatsArray
         {
            0,                                              // ClassReserved[0]
            0,                                              // ClassReserved[1]
            0,                                              // ClassReserved[2]
            0                                               // ClassReserved[3]
         },
         NUMBER_VIDEO_STREAM_PROPERTIES,                 // NumStreamPropArrayEntries
         (PKSPROPERTY_SET)VideoStreamProperties,         // StreamPropertiesArray
         0,                                              // NumStreamEventArrayEntries;
         0,                                              // StreamEventsArray;
         //(GUID *) &PINNAME_VIDEO_VIDEOPORT,                // Category
         //(GUID *) &PINNAME_VIDEO_VIDEOPORT,                // Name
         (GUID *) &PINNAME_VIDEO_PREVIEW,                // Category
         (GUID *) &PINNAME_VIDEO_PREVIEW,                // Name
         1,                                              // MediumsCount
         &CaptureMediums[1],                             // Mediums
      },
		// HW_STREAM_OBJECT ------------------------------------------------
		{
			sizeof (HW_STREAM_OBJECT),              // SizeOfThisPacket
			1,                                      // StreamNumber
			0,                                      // HwStreamExtension
			VideoReceiveDataPacket,                 // HwReceiveDataPacket
			VideoReceiveCtrlPacket,                 // HwReceiveControlPacket
			{ NULL, 0 },                            // HW_CLOCK_OBJECT
			FALSE,                                  // Dma
			TRUE,                                   // Pio
			0,                                      // HwDeviceExtension
			sizeof (KS_FRAME_INFO),                 // StreamHeaderMediaSpecific
			0,                                      // StreamHeaderWorkspace 
			TRUE,                                  // Allocator 
			NULL,                                   // HwEventRoutine
			{ 0, 0 },                               // Reserved[2]
		},

   },
   // -----------------------------------------------------------------
   // VBI Stream 
   // -----------------------------------------------------------------

   // HW_STREAM_INFORMATION -------------------------------------------
   {
      {
         1,                                              // NumberOfPossibleInstances
         KSPIN_DATAFLOW_OUT,                             // DataFlow
         TRUE,                                           // DataAccessible
         NUM_VBI_FORMATS,                                // NumberOfFormatArrayEntries
         VBIStreamFormats,                               // StreamFormatsArray
         {
            0,                                           // ClassReserved[0]
            0,                                           // ClassReserved[1]
            0,                                           // ClassReserved[2]
            0                                            // ClassReserved[3]
         },
/*[TMZ]*/         NUMBER_VIDEO_STREAM_PROPERTIES,                 // NumStreamPropArrayEntries
/*[TMZ]*/         (PKSPROPERTY_SET)VideoStreamProperties,         // StreamPropertiesArray
         0,                                              // NumStreamEventArrayEntries;
         0,                                              // StreamEventsArray;
#if 1 // [TMZ] [!!!] [HACK] - ALLOW_VBI_PIN
         (GUID *) &PINNAME_VIDEO_VBI,                    // Category
         (GUID *) &PINNAME_VIDEO_VBI,                    // Name
#else
         (GUID *) &PINNAME_VIDEO_STILL,                // Category
         (GUID *) &PINNAME_VIDEO_STILL,                // Name
#endif
         0, //1,                                              // MediumsCount
         NULL, //&CaptureMediums[2],                             // Mediums
      },
		// HW_STREAM_OBJECT ------------------------------------------------
		{
			sizeof (HW_STREAM_OBJECT),              // SizeOfThisPacket
			2,                                      // StreamNumber
			0,                                      // HwStreamExtension
			VideoReceiveDataPacket,                 // HwReceiveDataPacket
			VideoReceiveCtrlPacket,                 // HwReceiveControlPacket
			{ NULL, 0 },                            // HW_CLOCK_OBJECT
			FALSE,                                  // Dma
			TRUE,                                   // Pio
			0,                                      // HwDeviceExtension
			sizeof (KS_VBI_FRAME_INFO),             // StreamHeaderMediaSpecific
			0,                                      // StreamHeaderWorkspace 
			TRUE,                                   // Allocator 
			NULL,                                   // HwEventRoutine
			{ 0, 0 },                               // Reserved[2]
		}

   },
   // -----------------------------------------------------------------
   // Analog Video Input Stream
   // -----------------------------------------------------------------

   // HW_STREAM_INFORMATION -------------------------------------------
   {
      {
         1,                                      // NumberOfPossibleInstances
         KSPIN_DATAFLOW_IN,                      // DataFlow
         TRUE,                                   // DataAccessible
         NUM_ANALOG_VIDEO_FORMATS,               // NumberOfFormatArrayEntries
         AnalogVideoFormats,                     // StreamFormatsArray
         {
            0,                                   // ClassReserved[0]
            0,                                   // ClassReserved[1]
            0,                                   // ClassReserved[2]
            0                                    // ClassReserved[3]
         },
         0,                                      // NumStreamPropArrayEntries
         0,                                      // StreamPropertiesArray
         0,                                      // NumStreamEventArrayEntries;
         0,                                      // StreamEventsArray;
         (GUID *) &PINNAME_VIDEO_ANALOGVIDEOIN,  // Category
         (GUID *) &PINNAME_VIDEO_ANALOGVIDEOIN,  // Name
         1,                                      // MediumsCount
         &CaptureMediums[3],                     // Mediums
      },
		// HW_STREAM_OBJECT ------------------------------------------------
		{
			sizeof (HW_STREAM_OBJECT),              // SizeOfThisPacket
			3,                                      // StreamNumber
			0,                                      // HwStreamExtension
			VideoReceiveDataPacket,				       // HwReceiveDataPacket
			VideoReceiveCtrlPacket,			          // HwReceiveControlPacket
			{ NULL, 0 },                            // HW_CLOCK_OBJECT
			FALSE,                                  // Dma
			TRUE,                                   // Pio
			0,                                      // HwDeviceExtension
			0,                                      // StreamHeaderMediaSpecific
			0,                                      // StreamHeaderWorkspace 
			TRUE,                                   // Allocator 
			NULL,                                   // HwEventRoutine
			{ 0, 0 },                               // Reserved[2]
		}
   }

};


#define DRIVER_STREAM_COUNT (sizeof (Streams) / sizeof (ALL_STREAM_INFO))


//---------------------------------------------------------------------------
// Topology
//---------------------------------------------------------------------------

// Categories define what the device does.

static GUID Categories[] = {
    { STATIC_KSCATEGORY_VIDEO },
    { STATIC_KSCATEGORY_CAPTURE },
    { STATIC_KSCATEGORY_TVTUNER },
    { STATIC_KSCATEGORY_CROSSBAR },
    { STATIC_KSCATEGORY_TVAUDIO }
};

#define NUMBER_OF_CATEGORIES  SIZEOF_ARRAY (Categories)

static KSTOPOLOGY Topology = {
   NUMBER_OF_CATEGORIES,
   (GUID*) &Categories,
   0,
   NULL,
   0,
   NULL
};

//---------------------------------------------------------------------------
// The Main stream header
//---------------------------------------------------------------------------

static HW_STREAM_HEADER StreamHeader = 
{
   DRIVER_STREAM_COUNT,                // NumberOfStreams
   sizeof( HW_STREAM_INFORMATION ),    // Future proofing
   0,                                  // NumDevPropArrayEntries set at init time
   NULL,                               // DevicePropertiesArray  set at init time
   0,                                  // NumDevEventArrayEntries;
   NULL,                               // DeviceEventsArray;
   &Topology                           // Pointer to Device Topology
};


#ifdef    __cplusplus
}
#endif // __cplusplus

#endif // __CAPSTRM_H__
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\drivers\wdm\capture\mini\bt848\chanifac.h ===
// $Header: G:/SwDev/WDM/Video/bt848/rcs/Chanifac.h 1.3 1998/04/29 22:43:30 tomz Exp $

#ifndef __CHANIFACE_H
#define __CHANIFACE_H


/* Class: ChanIface
 * Purpose: Defines interface between CaptureChip class and VxDVideoChannel class
 * Attributes:
 * Operations:
 *   virtual void Notify() - called by CaptureChip to report an interrupt
 */
class ChanIface
{
   public:
      virtual void Notify( PVOID, bool skipped ) {}
};



#endif
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\drivers\wdm\capture\mini\bt848\capvideo.c ===
// $Header: G:/SwDev/WDM/Video/bt848/rcs/Capvideo.c 1.11 1998/05/08 00:11:02 tomz Exp $

//==========================================================================;
//
//  THIS CODE AND INFORMATION IS PROVIDED "AS IS" WITHOUT WARRANTY OF ANY
//  KIND, EITHER EXPRESSED OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE
//  IMPLIED WARRANTIES OF MERCHANTABILITY AND/OR FITNESS FOR A PARTICULAR
//  PURPOSE.
//
//  Copyright (c) 1992 - 1996  Microsoft Corporation.  All Rights Reserved.
//
//==========================================================================;

extern "C" {
#include "strmini.h"
#include "ksmedia.h"
#include "ddkmapi.h"
}

#include "capdebug.h"
#include "device.h"
#include "capmain.h"

#define DD_OK 0

ErrorCode VerifyVideoStream( const KS_DATAFORMAT_VIDEOINFOHEADER &vidHDR );
ErrorCode VerifyVideoStream2( const KS_DATAFORMAT_VIDEOINFOHEADER2 &vidHDR );
ErrorCode VerifyVBIStream( const KS_DATAFORMAT_VBIINFOHEADER &rKSDataFormat );

void CheckSrbStatus( PHW_STREAM_REQUEST_BLOCK pSrb );

// notify class we are ready to rock
void STREAMAPI StreamCompleterData( PHW_STREAM_REQUEST_BLOCK pSrb )
{
   Trace t("StreamCompleterData()");

   DebugOut((1, "*** 1 *** completing SRB %x\n", pSrb));
   CheckSrbStatus( pSrb );
   StreamClassStreamNotification( StreamRequestComplete, pSrb->StreamObject, pSrb );
   StreamClassStreamNotification( ReadyForNextStreamDataRequest, pSrb->StreamObject );
}

// notify class we are ready to rock
void STREAMAPI StreamCompleterControl( PHW_STREAM_REQUEST_BLOCK pSrb )
{
   Trace t("StreamCompleterControl()");

   CheckSrbStatus( pSrb );
   StreamClassStreamNotification( StreamRequestComplete, pSrb->StreamObject, pSrb );
   StreamClassStreamNotification( ReadyForNextStreamControlRequest, pSrb->StreamObject );
}

/* Function: ProposeDataFormat
 * Purpose: Verifies that data format can be supported
 * Input: SRB
 */
void ProposeDataFormat( PHW_STREAM_REQUEST_BLOCK pSrb )
{
   Trace t("ProposeDataFormat()");

   PHW_DEVICE_EXTENSION HwDeviceExtension =
      (PHW_DEVICE_EXTENSION) pSrb->HwDeviceExtension;

   PsDevice *adapter = HwDeviceExtension->psdevice;

   VideoStream StreamNumber = (VideoStream)pSrb->StreamObject->StreamNumber;

   if ( StreamNumber == STREAM_IDX_VBI ) {
      const KS_DATAFORMAT_VBIINFOHEADER &rKSVBIDataFormat =
         *(PKS_DATAFORMAT_VBIINFOHEADER) pSrb->CommandData.OpenFormat;
      if ( VerifyVBIStream( rKSVBIDataFormat ) != Success )
         pSrb->Status = STATUS_INVALID_PARAMETER;
      return;
   }
   const KS_DATAFORMAT_VIDEOINFOHEADER &rKSDataFormat =
      *(PKS_DATAFORMAT_VIDEOINFOHEADER) pSrb->CommandData.OpenFormat;
   const KS_DATAFORMAT_VIDEOINFOHEADER2 &rKSDataFormat2 =
      *(PKS_DATAFORMAT_VIDEOINFOHEADER2) pSrb->CommandData.OpenFormat;

   DebugOut((1, "Proposed Data format\n"));
   if ( VerifyVideoStream( rKSDataFormat ) != Success )
	{
	   if ( VerifyVideoStream2( rKSDataFormat2 ) != Success )
		{
			pSrb->Status = STATUS_INVALID_PARAMETER;
		}
		else
		{
	      pSrb->ActualBytesTransferred = sizeof( KS_DATAFORMAT_VIDEOINFOHEADER2 );
		}
	}
   else
	{
      pSrb->ActualBytesTransferred = sizeof( KS_DATAFORMAT_VIDEOINFOHEADER );
	}
}

/***************************************************************************

                    Data Packet Handling Routines

***************************************************************************/

/*
** VideoReceiveDataPacket()
**
**   Receives Video data packet commands
**
** Arguments:
**
**   pSrb - Stream request block for the Video device
**
** Returns:
**
** Side Effects:  none
*/

void MockStampVBI( PHW_STREAM_REQUEST_BLOCK pSrb )
{
   PKSSTREAM_HEADER  pDataPacket = pSrb->CommandData.DataBufferArray;

   pDataPacket->PresentationTime.Numerator = 1;
   pDataPacket->PresentationTime.Denominator = 1;
   
   pDataPacket->OptionsFlags &= ~KSSTREAM_HEADER_OPTIONSF_DURATIONVALID;
   pDataPacket->OptionsFlags &= ~KSSTREAM_HEADER_OPTIONSF_TIMEVALID;
   pDataPacket->OptionsFlags &= ~KS_VBI_FLAG_TVTUNER_CHANGE;
   pDataPacket->OptionsFlags &= ~KS_VBI_FLAG_VBIINFOHEADER_CHANGE;
   pDataPacket->PresentationTime.Time = 0;
   pDataPacket->OptionsFlags |= KSSTREAM_HEADER_OPTIONSF_SPLICEPOINT;
   pSrb->Status = STATUS_SUCCESS;

   CheckSrbStatus( pSrb );
   StreamClassStreamNotification( StreamRequestComplete, pSrb->StreamObject, pSrb );
}

VOID STREAMAPI VideoReceiveDataPacket( IN PHW_STREAM_REQUEST_BLOCK pSrb )
{
   Trace t("VideoReceiveDataPacket()");

   VideoChannel *chan = (VideoChannel *)((PSTREAMEX)pSrb->StreamObject->HwStreamExtension)->videochannel;
   PHW_DEVICE_EXTENSION HwDeviceExtension =
      (PHW_DEVICE_EXTENSION) pSrb->HwDeviceExtension;

   PsDevice *adapter = HwDeviceExtension->psdevice;
   VideoStream StreamNumber = (VideoStream)pSrb->StreamObject->StreamNumber;

   //
   // make sure we have a device extension
   //
   DEBUG_ASSERT((ULONG)adapter);

   // default to success
   pSrb->Status = STATUS_SUCCESS;

   //
   // determine the type of packet.
   //

   DebugOut((1, "VideoReceiveDataPacket(%x) cmd(%x)\n", pSrb, pSrb->Command));

   switch ( pSrb->Command ) {
   case SRB_READ_DATA:
      //
      // remember the current srb
      //
      DebugOut((1, "PsDevice::VideoReceiveDataPacket - SRB_READ_DATA\n"));
      chan->SetSRB( pSrb );
      adapter->AddBuffer( *chan, pSrb );
      break;
   default:
      //
      // invalid / unsupported command. Fail it as such
      //
      DebugOut((1, "PsDevice::VideoReceiveDataPacket - unknown command(%x)\n", pSrb->Command));
      pSrb->Status = STATUS_NOT_IMPLEMENTED;
      StreamCompleterData( pSrb );
   }
}

/*
** VideoReceiveCtrlPacket()
**
**   Receives packet commands that control the Video stream
**
** Arguments:
**
**   pSrb - The stream request block for the Video stream
**
** Returns:
**
** Side Effects:  none
*/

VOID STREAMAPI VideoReceiveCtrlPacket( IN PHW_STREAM_REQUEST_BLOCK pSrb )
{
   Trace t("VideoReceiveCtrlPacket()");

   PHW_DEVICE_EXTENSION HwDeviceExtension =
      (PHW_DEVICE_EXTENSION) pSrb->HwDeviceExtension;

   PsDevice *adapter = HwDeviceExtension->psdevice;

   DEBUG_ASSERT((ULONG)adapter);

   // default to success
   pSrb->Status = STATUS_SUCCESS;
   //
   // determine the type of packet.
   //

   DebugOut((1, "VideoReceiveCtrlPacket(%x) cmd(%x)\n", pSrb, pSrb->Command));

   int Command = pSrb->Command;
   switch ( Command ) {
   case SRB_SET_STREAM_STATE:
     adapter->SetVideoState( pSrb );
     break;
   case SRB_GET_STREAM_STATE:
     adapter->GetVideoState( pSrb );
     break;
   case SRB_PROPOSE_DATA_FORMAT:
      DebugOut((1, "Propose Data Format\n"));
      ProposeDataFormat( pSrb );
      break;

   case SRB_SET_DATA_FORMAT:
      DebugOut((1, "Set Data Format\n"));
      // should re-validate just in case ?
      adapter->ProcessSetDataFormat( pSrb );
      break;

   case SRB_GET_STREAM_PROPERTY:
      adapter->GetStreamProperty( pSrb );
      break;
   case SRB_SET_STREAM_PROPERTY:
      DebugOut(( 0, "SRB_SET_STREAM_PROPERTY\n" ));
      break;
/*
   case SRB_OPEN_MASTER_CLOCK:
   case SRB_CLOSE_MASTER_CLOCK:
      //
      // This stream is being selected to provide a Master clock
      //
      adapter->SetClockMaster( pSrb );
      break;
*/
   case SRB_INDICATE_MASTER_CLOCK:
      //
      // Assigns a clock to a stream
      //
      adapter->SetClockMaster( pSrb );
      break;
   default:

     //
     // invalid / unsupported command. Fail it as such
     //

     pSrb->Status = STATUS_NOT_IMPLEMENTED;
     break;
   }
   if ( Command != SRB_SET_STREAM_STATE && 
        Command != SRB_SET_STREAM_PROPERTY &&
        Command != SRB_SET_DATA_FORMAT )
      StreamCompleterControl( pSrb );
}

/*
** GetVideoState()
**
**    Gets the current state of the requested stream
**
** Arguments:
**
**    pSrb - pointer to the stream request block for properties
**
** Returns:
**
** Side Effects:  none
*/

VOID PsDevice::GetVideoState( PHW_STREAM_REQUEST_BLOCK pSrb )
{
   Trace t("PsDevice::GetVideoState()");

   VideoChannel *chan = (VideoChannel *)((PSTREAMEX)pSrb->StreamObject->HwStreamExtension)->videochannel;

   pSrb->Status = STATUS_SUCCESS;

   pSrb->CommandData.StreamState = chan->GetKSState();
   pSrb->ActualBytesTransferred = sizeof (KSSTATE);

   // A very odd rule:
   // When transitioning from stop to pause, DShow tries to preroll
   // the graph.  Capture sources can't preroll, and indicate this
   // by returning VFW_S_CANT_CUE in user mode.  To indicate this
   // condition from drivers, they must return ERROR_NO_DATA_DETECTED
   //
   // [TMZ] JayBo says KSSTATE_ACQUIRE should return success 

   if (pSrb->CommandData.StreamState == KSSTATE_PAUSE) {
      pSrb->Status = STATUS_NO_DATA_DETECTED;
   }
}

/*
** SetVideoState()
**
**    Sets the current state of the requested stream
**
** Arguments:
**
**    pSrb - pointer to the stream request block for properties
**
** Returns:
**
** Side Effects:  none
*/

VOID PrintState(StreamState st)
{
   switch( st ) {
      case Started:
         DebugOut((1, "*** Streamstate was STARTED\n"));
         break;
      case Created:
         DebugOut((1, "*** Streamstate was CREATED\n"));
         break;
      case Paused:
         DebugOut((1, "*** Streamstate was PAUSED\n"));
         break;
      case Open:
         DebugOut((1, "*** Streamstate was OPEN\n"));
         break;
      default:
         DebugOut((1, "*** Streamstate was ??? (%x)\n", st));
         break;
   }
}   

VOID PsDevice::SetVideoState( PHW_STREAM_REQUEST_BLOCK pSrb )
{
   Trace t("PsDevice::SetVideoState()");

   PHW_DEVICE_EXTENSION HwDeviceExtension =
      (PHW_DEVICE_EXTENSION) pSrb->HwDeviceExtension;

   PsDevice *adapter = HwDeviceExtension->psdevice;

   VideoChannel *chan = (VideoChannel *)((PSTREAMEX)pSrb->StreamObject->HwStreamExtension)->videochannel;
   VideoStream StreamNumber = (VideoStream)pSrb->StreamObject->StreamNumber;

   //
   // determine which new state is requested
   //
   pSrb->Status = STATUS_SUCCESS;
   chan->SetKSState( pSrb->CommandData.StreamState );
   
   switch ( pSrb->CommandData.StreamState ) {
   case KSSTATE_ACQUIRE:   // Documented as "same as pause for most minidrivers"
      DebugOut((1, "*** KSSTATE_ACQUIRE(%d) state(%d) falling through to PAUSE\n", StreamNumber, chan->GetState()));
   case KSSTATE_PAUSE:
      // PrintState(chan->GetState());

      DebugOut((1, "*** KSSTATE_PAUSE(%d) state(%d)\n", StreamNumber, chan->GetState()));

      switch ( chan->GetState() ) {
      case Started:
         if ( StreamNumber == 2 )
         {
            DebugOut((1, "#############################################################\n"));
            DebugOut((1, "About to pause channel %d\n", StreamNumber ));
            //adapter->CaptureContrll_.DumpRiscPrograms();
         }

         Pause( *chan ); // intentional fall-through
         
         if ( StreamNumber == 2 )
         {
            DebugOut((1, "Done pausing channel %d\n", StreamNumber ));
            DebugOut((1, "#############################################################\n"));
            //adapter->CaptureContrll_.DumpRiscPrograms();
         }
      case Created:
      case Paused:          // 2 PAUSE in a row; ignore
         StreamCompleterControl( pSrb );
         break;
      case Open:
         StreamClassCallAtNewPriority( pSrb->StreamObject, HwDeviceExtension, Low,
            PHW_PRIORITY_ROUTINE( CreateVideo ), pSrb );
         break;
      }
      break;

   case KSSTATE_STOP:
      // PrintState(chan->GetState());

      DebugOut((1, "*** KSSTATE_STOP(%d) state(%d)\n", StreamNumber, chan->GetState()));

      //
      // stop the video
      //
      switch ( chan->GetState() ) {
      default:
         if ( StreamNumber == 2 )
         {
            DebugOut((1, "'#############################################################\n"));
            DebugOut((1, "'About to pause channel %d\n", StreamNumber ));
            //adapter->CaptureContrll_.DumpRiscPrograms();
         }

         Pause( *chan ); // intentional fall-through
         
         if ( StreamNumber == 2 )
         {
            DebugOut((1, "'Done pausing channel %d\n", StreamNumber ));
            DebugOut((1, "'#############################################################\n"));
            //adapter->CaptureContrll_.DumpRiscPrograms();
         }
      case Paused:
      case Created:
         StreamClassCallAtNewPriority( pSrb->StreamObject, HwDeviceExtension, Low,
            PHW_PRIORITY_ROUTINE( DestroyVideo ), pSrb );
         break;
      }
      break;

   case KSSTATE_RUN: {
         // PrintState(chan->GetState());
      {
      VideoStream nStreamNumber = (VideoStream)pSrb->StreamObject->StreamNumber;
      DebugOut((1, "*** KSSTATE_RUN(%d)\n", nStreamNumber));
      }

         //
         // play the video
         //
         StreamState st = chan->GetState();
         if ( st != Created && st != Paused ) {
            DebugOut((1, "*** KSSTATE_RUN Error (st == %d)\n", st));
            pSrb->Status = STATUS_IO_DEVICE_ERROR;
         } else {
            Start( *chan );
         }

         StreamCompleterControl( pSrb );
      }
      break;
   default:
      DebugOut((0, "*** KSSTATE_??? (%x)\n", pSrb->CommandData.StreamState));

      pSrb->Status = STATUS_SUCCESS;
      StreamCompleterControl( pSrb );
      break;
   }
   // when going to paused mode from open and stopping, notification is done in callback
}

/* Method: PsDevice::StartVideo
 * Purpose: Starts a stream
 * Input: pSrb
 */
void STREAMAPI PsDevice::StartVideo( PHW_STREAM_REQUEST_BLOCK pSrb )
{
   Trace t("PsDevice::StartVideo()");

   PHW_DEVICE_EXTENSION HwDeviceExtension =
      (PHW_DEVICE_EXTENSION) pSrb->HwDeviceExtension;

   PsDevice *adapter = HwDeviceExtension->psdevice;

   VideoChannel *chan = (VideoChannel *)((PSTREAMEX)pSrb->StreamObject->HwStreamExtension)->videochannel;

   // restart the stream
   adapter->Start( *chan );
   adapter->Pause( *chan );
   
   // finally, can complete the SET dataformat SRB
   // StreamCompleterControl( pSrb );

   // cannot call any other class' services; have to schedule a callback
   StreamClassCallAtNewPriority( pSrb->StreamObject, HwDeviceExtension, LowToHigh,
      PHW_PRIORITY_ROUTINE( StreamCompleterControl ), pSrb );
}

/* Method: PsDevice::CreateVideo
 * Purpose: Starts a stream
 * Input: pSrb
 */
void STREAMAPI PsDevice::CreateVideo( PHW_STREAM_REQUEST_BLOCK pSrb )
{
   Trace t("PsDevice::CreateVideo()");

   PHW_DEVICE_EXTENSION HwDeviceExtension =
      (PHW_DEVICE_EXTENSION) pSrb->HwDeviceExtension;

   PsDevice *adapter = HwDeviceExtension->psdevice;

   VideoChannel *chan = (VideoChannel *)((PSTREAMEX)pSrb->StreamObject->HwStreamExtension)->videochannel;

   if ( adapter->Create( *chan ) != Success )
      pSrb->Status = STATUS_IO_DEVICE_ERROR;

   // cannot call any other class' services; have to schedule a callback
   StreamClassCallAtNewPriority( pSrb->StreamObject, HwDeviceExtension, LowToHigh,
      PHW_PRIORITY_ROUTINE( StreamCompleterControl ), pSrb );
}

/* Method: PsDevice::DestroyVideo
 * Purpose: Called at low priority to stop video and free the resources
 */
void STREAMAPI PsDevice::DestroyVideoNoComplete( PHW_STREAM_REQUEST_BLOCK pSrb )
{
   Trace t("PsDevice::DestroyVideoNoComplete()");

   PHW_DEVICE_EXTENSION HwDeviceExtension =
      (PHW_DEVICE_EXTENSION) pSrb->HwDeviceExtension;

   PsDevice *adapter = HwDeviceExtension->psdevice;

   VideoChannel *chan = (VideoChannel *)((PSTREAMEX)pSrb->StreamObject->HwStreamExtension)->videochannel;

   // have all resources freed
   adapter->Stop( *chan );

   // set new format
   KS_DATAFORMAT_VIDEOINFOHEADER &rDataVideoInfHdr =
      *(PKS_DATAFORMAT_VIDEOINFOHEADER) pSrb->CommandData.OpenFormat;
   KS_DATAFORMAT_VIDEOINFOHEADER2 &rDataVideoInfHdr2 =
      *(PKS_DATAFORMAT_VIDEOINFOHEADER2) pSrb->CommandData.OpenFormat;

   if ( IsEqualGUID( rDataVideoInfHdr.DataFormat.Specifier, KSDATAFORMAT_SPECIFIER_VIDEOINFO ) ) 
	{
	   chan->SetVidHdr( rDataVideoInfHdr.VideoInfoHeader );
	}
	else
	{
	   chan->SetVidHdr2( rDataVideoInfHdr2.VideoInfoHeader2 );
	}

   // re-create the stream
   if ( adapter->Create( *chan ) != Success ) {
      pSrb->Status = STATUS_IO_DEVICE_ERROR;
      StreamCompleterControl( pSrb );
   } else  {

      DebugOut((1, "1 pSrb = %lx\n", pSrb));
      DebugOut((1, "1 pSrb->StreamObject = %lx\n", pSrb->StreamObject));
      DebugOut((1, "1 chan = %lx\n", chan));
      DebugOut((1, "1 HwStreamExtension = %lx\n", pSrb->StreamObject->HwStreamExtension));

      // we're already at low priority ???
      //   StreamClassCallAtNewPriority( pSrb->StreamObject, HwDeviceExtension, Low,
      //      PHW_PRIORITY_ROUTINE( StartVideo ), pSrb );
      // StartVideo( pSrb);

      // cannot call any other class' services; have to schedule a callback
      StreamClassCallAtNewPriority( pSrb->StreamObject, HwDeviceExtension, LowToHigh,
         PHW_PRIORITY_ROUTINE( StreamCompleterControl ), pSrb );
   }
}

/* Method: PsDevice::DestroyVideo
 * Purpose: Called at low priority to stop video and free the resources
 */
void STREAMAPI PsDevice::DestroyVideo( PHW_STREAM_REQUEST_BLOCK pSrb )
{
   Trace t("PsDevice::DestroyVideo()");

   PHW_DEVICE_EXTENSION HwDeviceExtension =
      (PHW_DEVICE_EXTENSION) pSrb->HwDeviceExtension;

   PsDevice *adapter = HwDeviceExtension->psdevice;

   VideoChannel *chan = (VideoChannel *)((PSTREAMEX)pSrb->StreamObject->HwStreamExtension)->videochannel;

   adapter->Stop( *chan );

   // cannot call any other class' services; have to schedule a callback
   StreamClassCallAtNewPriority( pSrb->StreamObject, HwDeviceExtension, LowToHigh,
      PHW_PRIORITY_ROUTINE( StreamCompleterControl ), pSrb );
}

/*
** VideoGetProperty()
**
**    Routine to process video property requests
**
** Arguments:
**
**    pSrb - pointer to the stream request block for properties
**
** Returns:
**
** Side Effects:  none
*/
void PsDevice::GetStreamProperty( PHW_STREAM_REQUEST_BLOCK pSrb )
{
   Trace t("PsDevice::GetStreamProperty()");

   PSTREAM_PROPERTY_DESCRIPTOR pSPD = pSrb->CommandData.PropertyInfo;

   if ( IsEqualGUID( KSPROPSETID_Connection, pSPD->Property->Set ) ) {
      GetStreamConnectionProperty( pSrb );
   } else {
      pSrb->Status = STATUS_NOT_IMPLEMENTED;
   }
}

/* Method: PsDevice::ProcessSetDataFormat
 * Purpose: Implements SET KSPROPERTY_CONNECTION_DATAFORMAT
 * Input: chan: VideoChannel &
 *   VidInfHdr: KS_VIDEOINFOHEADER &
 */
void PsDevice::ProcessSetDataFormat( PHW_STREAM_REQUEST_BLOCK pSrb )
{
   Trace t("PsDevice::ProcessSetDataFormat()");
   
   VideoChannel *chan = (VideoChannel *)((PSTREAMEX)pSrb->StreamObject->HwStreamExtension)->videochannel;

   // have to stop first
   Pause( *chan );

   // destroy at low prioriy
   StreamClassCallAtNewPriority( pSrb->StreamObject, pSrb->HwDeviceExtension, Low,
      PHW_PRIORITY_ROUTINE( DestroyVideoNoComplete ), pSrb );
}

/* Method: PsDevice::GetStreamConnectionProperty
 * Purpose: Obtains allocator and state properties
 */
void PsDevice::GetStreamConnectionProperty( PHW_STREAM_REQUEST_BLOCK pSrb )
{
   Trace t("PsDevice::GetStreamConnectionProperty()");

   VideoChannel *chan = (VideoChannel *)((PSTREAMEX)pSrb->StreamObject->HwStreamExtension)->videochannel;
   PSTREAM_PROPERTY_DESCRIPTOR pSPD = pSrb->CommandData.PropertyInfo;
   ULONG Id = pSPD->Property->Id;              // index of the property

   switch ( Id ) {
   case KSPROPERTY_CONNECTION_ALLOCATORFRAMING: {


		   //KdPrint(( "KSPROPERTY_CONNECTION_ALLOCATORFRAMING\n" ));


         PKSALLOCATOR_FRAMING Framing = (PKSALLOCATOR_FRAMING) pSPD->PropertyInfo;
         Framing->RequirementsFlags   =
            KSALLOCATOR_REQUIREMENTF_PREFERENCES_ONLY |
            KSALLOCATOR_REQUIREMENTF_INPLACE_MODIFIER |
            KSALLOCATOR_REQUIREMENTF_SYSTEM_MEMORY;
         Framing->PoolType = NonPagedPool;

			//KdPrint(( "Framing->Frames == 0x%08X\n", Framing->Frames ));
			if( (VideoStream)pSrb->StreamObject->StreamNumber == STREAM_IDX_VBI ) 
			{
	         Framing->Frames = 8;
			}
			else
			{
				//if( Framing->Frames == 0 )
				//{
		      //   Framing->Frames = 1;
				//}
				//else
				//{
		         Framing->Frames = 3;
				//}
			}
			if( chan->IsVideoInfo2() )
			{
				Framing->FrameSize = chan->GetVidHdr2()->bmiHeader.biSizeImage;
			}
			else
			{
				Framing->FrameSize = chan->GetVidHdr()->bmiHeader.biSizeImage;
			}
         Framing->FileAlignment = 0;//FILE_QUAD_ALIGNMENT;// PAGE_SIZE - 1;
         Framing->Reserved = 0;
         pSrb->ActualBytesTransferred = sizeof( KSALLOCATOR_FRAMING );
      }
      break;
   default:
      break;
   }
}

void PsDevice::SetClockMaster( PHW_STREAM_REQUEST_BLOCK pSrb )
{
   Trace t("PsDevice::SetClockMaster()");

   VideoChannel *chan = (VideoChannel *)((PSTREAMEX)pSrb->StreamObject->HwStreamExtension)->videochannel;
   chan->SetClockMaster( pSrb->CommandData.MasterClockHandle );
}

/* Method: AnalogReceiveDataPacket
 * Purpose: Receives data packets for analog stream ( tuner change notifications )
 * Input: SRB
 */
VOID STREAMAPI AnalogReceiveDataPacket( IN PHW_STREAM_REQUEST_BLOCK pSrb )
{
   Trace t("AnalogReceiveDataPacket()");

   pSrb->Status = STATUS_SUCCESS;

   PHW_DEVICE_EXTENSION HwDeviceExtension =
      (PHW_DEVICE_EXTENSION) pSrb->HwDeviceExtension;

   PsDevice *adapter = HwDeviceExtension->psdevice;
   
   DebugOut((1, "AnalogReceiveDataPacket(%x) cmd(%x)\n", pSrb, pSrb->Command));

   switch ( pSrb->Command ) {
   case SRB_READ_DATA:
      break;
   case SRB_WRITE_DATA:
      //
      // This data packet contains the channel change information
      // passed on the AnalogVideoIn
      //
      if ( pSrb->CommandData.DataBufferArray->FrameExtent ==
           sizeof( KS_TVTUNER_CHANGE_INFO ) )
         adapter->ChangeNotifyChannels( pSrb );
      break;
    default:
      //
      // invalid / unsupported command. Fail it as such
      //
      pSrb->Status = STATUS_NOT_IMPLEMENTED;
   }
   StreamCompleterData( pSrb );
}

/* Method: AnalogReceiveCtrlPacket
 * Purpose: Receives control packets for analog stream ( are there any ? )
 * Input: SRB
 */
VOID STREAMAPI AnalogReceiveCtrlPacket( IN PHW_STREAM_REQUEST_BLOCK pSrb )
{
   Trace t("AnalogReceiveCtrlPacket()");

   DebugOut((1, "AnalogReceiveCtrlPacket(%x) cmd(%x)\n", pSrb, pSrb->Command));

   pSrb->Status = STATUS_SUCCESS;
   StreamCompleterControl( pSrb );
}


#ifdef ENABLE_DDRAW_STUFF

DWORD FAR PASCAL 
DirectDrawEventCallback( DWORD dwEvent, PVOID pContext, DWORD dwParam1, DWORD dwParam2 )
{
	switch( dwEvent )
	{
		case DDNOTIFY_PRERESCHANGE:
			{
			VideoChannel*			pChan = (VideoChannel*)pContext;
			KdPrint(( "DDNOTIFY_PRERESCHANGE; stream = %d\n", pChan->pSRB_->StreamObject->StreamNumber ));
			pChan->bPreEventOccurred = TRUE;
			}
			break;
		case DDNOTIFY_POSTRESCHANGE:
			{
			VideoChannel*			pChan = (VideoChannel*)pContext;
			KdPrint(( "DDNOTIFY_POSTRESCHANGE; stream = %d\n", pChan->pSRB_->StreamObject->StreamNumber ));
			pChan->bPostEventOccurred = TRUE;
			KdPrint(( "before Attempted Renegotiation due to DDNOTIFY_POSTRESCHANGE\n" ));
			//               AttemptRenegotiation(pStrmEx);
			KdPrint(( "after Attempted Renegotiation due to DDNOTIFY_POSTRESCHANGE\n" ));
			}
			break;
		case DDNOTIFY_PREDOSBOX:
			{
			VideoChannel*			pChan = (VideoChannel*)pContext;
			KdPrint(( "DDNOTIFY_PREDOSBOX; stream = %d\n", pChan->pSRB_->StreamObject->StreamNumber ));
			pChan->bPreEventOccurred = TRUE;
			}
			break;
		case DDNOTIFY_POSTDOSBOX:
			{
			VideoChannel*			pChan = (VideoChannel*)pContext;
			KdPrint(( "DDNOTIFY_POSTDOSBOX; stream = %d\n", pChan->pSRB_->StreamObject->StreamNumber ));
			pChan->bPostEventOccurred = TRUE;
			KdPrint(( "before Attempted Renegotiation due to DDNOTIFY_POSTDOSBOX\n" ));
			//               AttemptRenegotiation(pStrmEx);
			KdPrint(( "after Attempted Renegotiation due to DDNOTIFY_POSTDOSBOX\n" ));
			}
			break;
		case DDNOTIFY_CLOSEDIRECTDRAW:
			{
			VideoChannel*			pChan = (VideoChannel*)pContext;
			KdPrint(( "DDNOTIFY_CLOSEDIRECTDRAW\n" ));
			pChan->hKernelDirectDrawHandle = 0;
			pChan->hUserDirectDrawHandle = 0;
			}
			break;
		case DDNOTIFY_CLOSESURFACE:
			{
			VideoChannel*			pChan = (VideoChannel*)pContext;
			PSRB_EXTENSION			pSrbExt = (PSRB_EXTENSION)pChan->pSRB_->SRBExtension;
			KdPrint(( "DDNOTIFY_CLOSESURFACE\n" ));
			pSrbExt->hKernelSurfaceHandle = 0;
			}
			break;
		default:
			KdPrint(( "unknown/unhandled ddraw event\n" ));
			break;
	}
	return 0;
}

BOOL RegisterForDirectDrawEvents( PHW_STREAM_REQUEST_BLOCK pSrb )
{
	PHW_DEVICE_EXTENSION	pHwDevExt = (PHW_DEVICE_EXTENSION)pSrb->HwDeviceExtension;
	DDREGISTERCALLBACK	ddRegisterCallback;
	DWORD						ddOut;
   VideoChannel*        pChan = (VideoChannel *)((PSTREAMEX)pSrb->StreamObject->HwStreamExtension)->videochannel;

	KdPrint(( "stream %d registering for DirectDraw events\n", pSrb->StreamObject->StreamNumber ));

	// =============== DDEVENT_PRERESCHANGE ===============
	RtlZeroMemory( &ddRegisterCallback, sizeof(ddRegisterCallback) );
	RtlZeroMemory( &ddOut, sizeof(ddOut) );

	ddRegisterCallback.hDirectDraw = pChan->hKernelDirectDrawHandle;
	ddRegisterCallback.dwEvents = DDEVENT_PRERESCHANGE;
	ddRegisterCallback.pfnCallback = DirectDrawEventCallback;
	ddRegisterCallback.pContext = pChan;

	DxApi( DD_DXAPI_REGISTER_CALLBACK, (DWORD) &ddRegisterCallback, sizeof(ddRegisterCallback), (DWORD)&ddOut, sizeof(ddOut) );

	if( ddOut != DD_OK ) 
	{
		KdPrint(( "DD_DXAPI_REGISTER_CALLBACK failed.\n" ));
		return FALSE;
	}

	// =============== DDEVENT_POSTRESCHANGE ==============
	RtlZeroMemory( &ddRegisterCallback, sizeof(ddRegisterCallback) );
	RtlZeroMemory( &ddOut, sizeof(ddOut) );

	ddRegisterCallback.hDirectDraw = pChan->hKernelDirectDrawHandle;
	ddRegisterCallback.dwEvents = DDEVENT_POSTRESCHANGE;
	ddRegisterCallback.pfnCallback = DirectDrawEventCallback;
	ddRegisterCallback.pContext = pChan;

	DxApi(DD_DXAPI_REGISTER_CALLBACK, (DWORD) &ddRegisterCallback, sizeof(ddRegisterCallback), (DWORD)&ddOut, sizeof(ddOut) );

	if( ddOut != DD_OK ) 
	{
		KdPrint(( "DD_DXAPI_REGISTER_CALLBACK failed.\n" ));
		return FALSE;
	}

	// =============== DDEVENT_PREDOSBOX =================
	RtlZeroMemory( &ddRegisterCallback, sizeof(ddRegisterCallback) );
	RtlZeroMemory( &ddOut, sizeof(ddOut) );

	ddRegisterCallback.hDirectDraw = pChan->hKernelDirectDrawHandle;
	ddRegisterCallback.dwEvents = DDEVENT_PREDOSBOX;
	ddRegisterCallback.pfnCallback = DirectDrawEventCallback;
	ddRegisterCallback.pContext = pChan;

	DxApi( DD_DXAPI_REGISTER_CALLBACK, (DWORD) &ddRegisterCallback, sizeof(ddRegisterCallback), (DWORD)&ddOut, sizeof(ddOut) );

	if( ddOut != DD_OK ) 
	{
		KdPrint(( "DD_DXAPI_REGISTER_CALLBACK failed.\n" ));
		return FALSE;
	}

	// =============== DDEVENT_POSTDOSBOX ================
	RtlZeroMemory( &ddRegisterCallback, sizeof(ddRegisterCallback) );
	RtlZeroMemory( &ddOut, sizeof(ddOut) );

	ddRegisterCallback.hDirectDraw = pChan->hKernelDirectDrawHandle;
	ddRegisterCallback.dwEvents = DDEVENT_POSTDOSBOX;
	ddRegisterCallback.pfnCallback = DirectDrawEventCallback;
	ddRegisterCallback.pContext = pChan;

	DxApi( DD_DXAPI_REGISTER_CALLBACK, (DWORD) &ddRegisterCallback, sizeof(ddRegisterCallback), (DWORD)&ddOut, sizeof(ddOut) );

	if( ddOut != DD_OK ) 
	{
		KdPrint(( "DD_DXAPI_REGISTER_CALLBACK failed.\n" ));
		return FALSE;
	}
	pChan->bKernelDirectDrawRegistered = TRUE;

	return TRUE;
}

BOOL UnregisterForDirectDrawEvents( PHW_STREAM_REQUEST_BLOCK pSrb )
{
	PHW_DEVICE_EXTENSION	pHwDevExt = (PHW_DEVICE_EXTENSION)pSrb->HwDeviceExtension;
	DDREGISTERCALLBACK	ddRegisterCallback;
	DWORD						ddOut;
   VideoChannel*        pChan = (VideoChannel *)((PSTREAMEX)pSrb->StreamObject->HwStreamExtension)->videochannel;

	KdPrint(( "stream %d un-registering for DirectDraw events\n", pSrb->StreamObject->StreamNumber ));

	// =============== DDEVENT_PRERESCHANGE ===============
	RtlZeroMemory( &ddRegisterCallback, sizeof(ddRegisterCallback) );
	RtlZeroMemory( &ddOut, sizeof(ddOut) );

	ddRegisterCallback.hDirectDraw = pChan->hKernelDirectDrawHandle;
	ddRegisterCallback.dwEvents = DDEVENT_PRERESCHANGE;
	ddRegisterCallback.pfnCallback = DirectDrawEventCallback;
	ddRegisterCallback.pContext = pChan;

	DxApi( DD_DXAPI_UNREGISTER_CALLBACK, (DWORD) &ddRegisterCallback, sizeof(ddRegisterCallback), (DWORD)&ddOut, sizeof(ddOut));

	if( ddOut != DD_OK ) 
	{
		KdPrint(( "DD_DXAPI_UNREGISTER_CALLBACK failed.\n" ));
		return FALSE;
	}

	// =============== DDEVENT_POSTRESCHANGE ==============
	RtlZeroMemory( &ddRegisterCallback, sizeof(ddRegisterCallback) );
	RtlZeroMemory( &ddOut, sizeof(ddOut) );

	ddRegisterCallback.hDirectDraw = pChan->hKernelDirectDrawHandle;
	ddRegisterCallback.dwEvents = DDEVENT_POSTRESCHANGE;
	ddRegisterCallback.pfnCallback = DirectDrawEventCallback;
	ddRegisterCallback.pContext = pChan;

	DxApi( DD_DXAPI_UNREGISTER_CALLBACK, (DWORD) &ddRegisterCallback, sizeof(ddRegisterCallback), (DWORD)&ddOut, sizeof(ddOut) );

	if( ddOut != DD_OK ) 
	{
		KdPrint(( "DD_DXAPI_UNREGISTER_CALLBACK failed.\n" ));
		return FALSE;
	}

	// =============== DDEVENT_PREDOSBOX ==================
	RtlZeroMemory( &ddRegisterCallback, sizeof(ddRegisterCallback) );
	RtlZeroMemory( &ddOut, sizeof(ddOut) );

	ddRegisterCallback.hDirectDraw = pChan->hKernelDirectDrawHandle;
	ddRegisterCallback.dwEvents = DDEVENT_PREDOSBOX;
	ddRegisterCallback.pfnCallback = DirectDrawEventCallback;
	ddRegisterCallback.pContext = pChan;

	DxApi( DD_DXAPI_UNREGISTER_CALLBACK, (DWORD) &ddRegisterCallback, sizeof(ddRegisterCallback), (DWORD)&ddOut, sizeof(ddOut) );

	if( ddOut != DD_OK ) 
	{
		KdPrint(( "DD_DXAPI_UNREGISTER_CALLBACK failed.\n" ));
		return FALSE;
	}

	// =============== DDEVENT_POSTDOSBOX =================
	RtlZeroMemory( &ddRegisterCallback, sizeof(ddRegisterCallback) );
	RtlZeroMemory( &ddOut, sizeof(ddOut) );

	ddRegisterCallback.hDirectDraw = pChan->hKernelDirectDrawHandle;
	ddRegisterCallback.dwEvents = DDEVENT_POSTDOSBOX;
	ddRegisterCallback.pfnCallback = DirectDrawEventCallback;
	ddRegisterCallback.pContext = pChan;

	DxApi( DD_DXAPI_UNREGISTER_CALLBACK, (DWORD) &ddRegisterCallback, sizeof(ddRegisterCallback), (DWORD)&ddOut, sizeof(ddOut) );

	if( ddOut != DD_OK ) 
	{
		KdPrint(( "DD_DXAPI_UNREGISTER_CALLBACK failed.\n" ));
		return FALSE;
	}
	pChan->bKernelDirectDrawRegistered = FALSE;

	return TRUE;
}


BOOL OpenKernelDirectDraw( PHW_STREAM_REQUEST_BLOCK pSrb )
{
	/*
   VideoChannel*        pChan = (VideoChannel *)((PSTREAMEX)pSrb->StreamObject->HwStreamExtension)->videochannel;

	if( pChan->hUserDirectDrawHandle != 0 ) 
	{
		DDOPENDIRECTDRAWIN  ddOpenIn;
		DDOPENDIRECTDRAWOUT ddOpenOut;

		ASSERT( pChan->hKernelDirectDrawHandle == 0 );

		KdPrint(( "stream %d getting kernel ddraw handle\n", pSrb->StreamObject->StreamNumber ));

		RtlZeroMemory( &ddOpenIn, sizeof(ddOpenIn) );
		RtlZeroMemory( &ddOpenOut, sizeof(ddOpenOut) );

		ddOpenIn.dwDirectDrawHandle = (DWORD)pChan->hUserDirectDrawHandle;
		ddOpenIn.pfnDirectDrawClose = DirectDrawEventCallback;
		ddOpenIn.pContext = pChan;

		DxApi( DD_DXAPI_OPENDIRECTDRAW, (DWORD)&ddOpenIn, sizeof(ddOpenIn), (DWORD)&ddOpenOut, sizeof(ddOpenOut) );

		if( ddOpenOut.ddRVal != DD_OK ) 
		{
			KdPrint(( "DD_DXAPI_OPENDIRECTDRAW failed.\n" ));
		}
		else 
		{
			pChan->hKernelDirectDrawHandle = ddOpenOut.hDirectDraw;
			return TRUE;
		}
	}
	*/
	return FALSE;
}
    

BOOL CloseKernelDirectDraw( PHW_STREAM_REQUEST_BLOCK pSrb )
{
   VideoChannel*        pChan = (VideoChannel *)((PSTREAMEX)pSrb->StreamObject->HwStreamExtension)->videochannel;
	/*
	if( pChan->hKernelDirectDrawHandle != 0 ) 
	{
		DWORD				ddOut;
		DDCLOSEHANDLE	ddClose;
		KdPrint(( "stream %d CloseKernelDirectDraw\n", pSrb->StreamObject->StreamNumber ));
		ddClose.hHandle = pChan->hKernelDirectDrawHandle;

		DxApi( DD_DXAPI_CLOSEHANDLE, (DWORD)&ddClose, sizeof(ddClose), (DWORD) &ddOut, sizeof(ddOut) );

		pChan->hKernelDirectDrawHandle = 0;

		if( ddOut != DD_OK ) 
		{
			KdPrint(( "CloseKernelDirectDraw FAILED.\n" ));
			return FALSE;
		}
	}
	*/
	return TRUE;
}

BOOL IsKernelLockAndFlipAvailable( PHW_STREAM_REQUEST_BLOCK pSrb )
{
   VideoChannel*        pChan = (VideoChannel *)((PSTREAMEX)pSrb->StreamObject->HwStreamExtension)->videochannel;
	if( pChan->hKernelDirectDrawHandle != 0 ) 
	{
		DDGETKERNELCAPSOUT ddGetKernelCapsOut;
		KdPrint(( "stream %d getting Kernel Caps\n", pSrb->StreamObject->StreamNumber ));

		RtlZeroMemory( &ddGetKernelCapsOut, sizeof(ddGetKernelCapsOut) );

		DxApi( 
				DD_DXAPI_GETKERNELCAPS, 
				(DWORD) &pChan->hKernelDirectDrawHandle, 
				sizeof(pChan->hKernelDirectDrawHandle), 
				(DWORD)&ddGetKernelCapsOut, 
				sizeof(ddGetKernelCapsOut)
				);

		if( ddGetKernelCapsOut.ddRVal != DD_OK ) 
		{
			//KdPrint(( "DDGETKERNELCAPSOUT failed.\n" ));
		}
		else 
		{
			//KdPrint(( "stream %d KernelCaps = %x\n", pSrb->StreamObject->StreamNumber, ddGetKernelCapsOut.dwCaps ));
			// TODO:, check the flags here
			// if (ddGetKernelCapsOut.dwCaps & ???)
			return TRUE;
		}
	}
	return FALSE;
}


BOOL OpenKernelDDrawSurfaceHandle( IN PHW_STREAM_REQUEST_BLOCK pSrb )
{    
   VideoChannel*        pChan = (VideoChannel *)((PSTREAMEX)pSrb->StreamObject->HwStreamExtension)->videochannel;
	PSRB_EXTENSION		pSrbExt = (PSRB_EXTENSION)pSrb->SRBExtension;

	ASSERT( pChan->hKernelDirectDrawHandle != 0 );
	ASSERT( pSrbExt->hUserSurfaceHandle != 0 );

	if( pSrbExt->hUserSurfaceHandle == 0 ) 
	{
		DDOPENSURFACEIN	ddOpenSurfaceIn;
		DDOPENSURFACEOUT	ddOpenSurfaceOut;

		//KdPrint(( "stream %d getting Kernel surface handle\n", pSrb->StreamObject->StreamNumber ));

		RtlZeroMemory( &ddOpenSurfaceIn, sizeof(ddOpenSurfaceIn) );
		RtlZeroMemory( &ddOpenSurfaceOut, sizeof(ddOpenSurfaceOut) );

		ddOpenSurfaceIn.hDirectDraw = pChan->hUserDirectDrawHandle;
		ddOpenSurfaceIn.pfnSurfaceClose = DirectDrawEventCallback;
		ddOpenSurfaceIn.pContext = pSrb;

		ddOpenSurfaceIn.dwSurfaceHandle = (DWORD)pSrbExt->hUserSurfaceHandle;

		DxApi( DD_DXAPI_OPENSURFACE, (DWORD)&ddOpenSurfaceIn, sizeof(ddOpenSurfaceIn), (DWORD)&ddOpenSurfaceOut, sizeof(ddOpenSurfaceOut) );

		if( ddOpenSurfaceOut.ddRVal != DD_OK ) 
		{
			pSrbExt->hKernelSurfaceHandle = 0;
			//KdPrint(( "DD_DXAPI_OPENSURFACE failed.\n" ));
		}
		else 
		{
			pSrbExt->hKernelSurfaceHandle = ddOpenSurfaceOut.hSurface;
			return TRUE;
		}
	}
	return FALSE;
}


BOOL CloseKernelDDrawSurfaceHandle( IN PHW_STREAM_REQUEST_BLOCK pSrb )
{
   VideoChannel*     pChan = (VideoChannel *)((PSTREAMEX)pSrb->StreamObject->HwStreamExtension)->videochannel;
	PSRB_EXTENSION		pSrbExt = (PSRB_EXTENSION)pSrb->SRBExtension;

	ASSERT( pChan->hKernelDirectDrawHandle != 0 );
	ASSERT( pSrbExt->hUserSurfaceHandle != 0 );
	ASSERT( pSrbExt->hKernelSurfaceHandle != 0 );

	if( pSrbExt->hKernelSurfaceHandle != 0 ) 
	{
		DWORD				ddOut;
		DDCLOSEHANDLE	ddClose;

		//KdPrint(( "stream %d ReleaseKernelDDrawSurfaceHandle\n", pSrb->StreamObject->StreamNumber ));

		ddClose.hHandle = pSrbExt->hKernelSurfaceHandle;

		DxApi( DD_DXAPI_CLOSEHANDLE, (DWORD)&ddClose, sizeof(ddClose), (DWORD) &ddOut, sizeof(ddOut) );

		pSrbExt->hKernelSurfaceHandle = 0;  // what else can we do?

		if( ddOut != DD_OK ) 
		{
			//KdPrint(( "ReleaseKernelDDrawSurfaceHandle() FAILED.\n" ));
			return FALSE;
		}
		else 
		{
			return TRUE;
		}
	}
	return FALSE;
}

BOOL FlipOverlay( HANDLE hDirectDraw, HANDLE hCurrentSurface, HANDLE hTargetSurface )
{
	DDFLIPOVERLAY		ddFlipOverlay;
	DWORD					ddOut;

	RtlZeroMemory( &ddFlipOverlay, sizeof(ddFlipOverlay) );
	ddFlipOverlay.hDirectDraw = hDirectDraw;
	ddFlipOverlay.hCurrentSurface = hCurrentSurface;
	ddFlipOverlay.hTargetSurface = hTargetSurface;
	ddFlipOverlay.dwFlags = 0;

	DxApi( DD_DXAPI_FLIP_OVERLAY, (DWORD)&ddFlipOverlay, sizeof(ddFlipOverlay), (DWORD)&ddOut, sizeof(ddOut) );

	if( ddOut != DD_OK ) 
	{
		//KdPrint(( "FlipOverlay() FAILED.\n" ));
		return FALSE;
	}
	else 
	{
		return TRUE;
	}
}

#endif
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\drivers\wdm\capture\mini\bt848\capprop.h ===
// $Header: G:/SwDev/WDM/Video/bt848/rcs/Capprop.h 1.5 1998/04/29 22:43:29 tomz Exp $

//==========================================================================;
//
//  THIS CODE AND INFORMATION IS PROVIDED "AS IS" WITHOUT WARRANTY OF ANY
//  KIND, EITHER EXPRESSED OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE
//  IMPLIED WARRANTIES OF MERCHANTABILITY AND/OR FITNESS FOR A PARTICULAR
//  PURPOSE.
//
//  Copyright (c) 1992 - 1996  Microsoft Corporation.  All Rights Reserved.
//
//==========================================================================;

//
// Property set for the Video Crossbar
//

#include "mytypes.h"

DEFINE_KSPROPERTY_TABLE(XBarProperties)
{
    DEFINE_KSPROPERTY_ITEM
    (
        KSPROPERTY_CROSSBAR_CAPS,   // PropertyId
        TRUE,                                   // GetSupported or Handler
        sizeof(KSPROPERTY_CROSSBAR_CAPS_S),    // MinProperty
        sizeof(KSPROPERTY_CROSSBAR_CAPS_S),    // MinData
        FALSE,                                  // SetSupported or Handler
        NULL,                                   // Values
        0,                                      // RelationsCount
        NULL,                                   // Relations
        NULL,                                   // SupportHandler
        sizeof(ULONG)                           // SerializedSize
    ),
    DEFINE_KSPROPERTY_ITEM
    (
        KSPROPERTY_CROSSBAR_CAN_ROUTE,
        TRUE,                                   // GetSupported or Handler
        sizeof(KSPROPERTY_CROSSBAR_ROUTE_S),    // MinProperty
        sizeof(KSPROPERTY_CROSSBAR_ROUTE_S),    // MinData
        FALSE,                                  // SetSupported or Handler
        NULL,                                   // Values
        0,                                      // RelationsCount
        NULL,                                   // Relations
        NULL,                                   // SupportHandler
        sizeof(ULONG)                           // SerializedSize
    ),
    DEFINE_KSPROPERTY_ITEM
    (
        KSPROPERTY_CROSSBAR_ROUTE,
        true,                                   // GetSupported or Handler
        sizeof(KSPROPERTY_CROSSBAR_ROUTE_S),    // MinProperty
        sizeof(KSPROPERTY_CROSSBAR_ROUTE_S),    // MinData
        true,                                   // SetSupported or Handler
        NULL,                                   // Values
        0,                                      // RelationsCount
        NULL,                                   // Relations
        NULL,                                   // SupportHandler
        sizeof(ULONG)                           // SerializedSize
    ),
    DEFINE_KSPROPERTY_ITEM
    (
        KSPROPERTY_CROSSBAR_PININFO,
        TRUE,                                   // GetSupported or Handler
        sizeof(KSPROPERTY_CROSSBAR_PININFO_S),    // MinProperty
        sizeof(KSPROPERTY_CROSSBAR_PININFO_S),    // MinData
        FALSE,                                  // SetSupported or Handler
        NULL,                                   // Values
        0,                                      // RelationsCount
        NULL,                                   // Relations
        NULL,                                   // SupportHandler
        0                                       // SerializedSize
    )
};

#if 1
//
// Property set for the TVTuner
//

DEFINE_KSPROPERTY_TABLE(TVTunerProperties)
{
    DEFINE_KSPROPERTY_ITEM
    (
        KSPROPERTY_TUNER_CAPS,
        TRUE,                                   // GetSupported or Handler
        sizeof(KSPROPERTY_TUNER_CAPS_S),        // MinProperty
        sizeof(KSPROPERTY_TUNER_CAPS_S),        // MinData
        FALSE,                                  // SetSupported or Handler
        NULL,                                   // Values
        0,                                      // RelationsCount
        NULL,                                   // Relations
        NULL,                                   // SupportHandler
        0                                       // SerializedSize
    ),
    DEFINE_KSPROPERTY_ITEM
    (
        KSPROPERTY_TUNER_MODE,
        TRUE,                                   // GetSupported or Handler
        sizeof(KSPROPERTY_TUNER_MODE_S),        // MinProperty
        sizeof(KSPROPERTY_TUNER_MODE_S),        // MinData
        TRUE,                                   // SetSupported or Handler
        NULL,                                   // Values
        0,                                      // RelationsCount
        NULL,                                   // Relations
        NULL,                                   // SupportHandler
        0                                       // SerializedSize
    ),
    DEFINE_KSPROPERTY_ITEM
    (
        KSPROPERTY_TUNER_MODE_CAPS,
        TRUE,                                   // GetSupported or Handler
        sizeof(KSPROPERTY_TUNER_MODE_CAPS_S),   // MinProperty
        sizeof(KSPROPERTY_TUNER_MODE_CAPS_S),   // MinData
        FALSE,                                  // SetSupported or Handler
        NULL,                                   // Values
        0,                                      // RelationsCount
        NULL,                                   // Relations
        NULL,                                   // SupportHandler
        0                                       // SerializedSize
    ),
    DEFINE_KSPROPERTY_ITEM
    (
        KSPROPERTY_TUNER_STANDARD,
        TRUE,                                   // GetSupported or Handler
        sizeof(KSPROPERTY_TUNER_STANDARD_S),    // MinProperty
        sizeof(KSPROPERTY_TUNER_STANDARD_S),    // MinData
        FALSE,                                  // SetSupported or Handler
        NULL,                                   // Values
        0,                                      // RelationsCount
        NULL,                                   // Relations
        NULL,                                   // SupportHandler
        0                                       // SerializedSize
    ),
    DEFINE_KSPROPERTY_ITEM
    (
        KSPROPERTY_TUNER_FREQUENCY,
        FALSE,                                  // GetSupported or Handler
        sizeof(KSPROPERTY_TUNER_FREQUENCY_S),   // MinProperty
        sizeof(KSPROPERTY_TUNER_FREQUENCY_S),   // MinData
        TRUE,                                   // SetSupported or Handler
        NULL,                                   // Values
        0,                                      // RelationsCount
        NULL,                                   // Relations
        NULL,                                   // SupportHandler
        0                                       // SerializedSize
    ),
    DEFINE_KSPROPERTY_ITEM
    (
        KSPROPERTY_TUNER_INPUT,
        TRUE,                                   // GetSupported or Handler
        sizeof(KSPROPERTY_TUNER_INPUT_S),       // MinProperty
        sizeof(KSPROPERTY_TUNER_INPUT_S),       // MinData
        TRUE,                                   // SetSupported or Handler
        NULL,                                   // Values
        0,                                      // RelationsCount
        NULL,                                   // Relations
        NULL,                                   // SupportHandler
        0                                       // SerializedSize
    ),
    DEFINE_KSPROPERTY_ITEM
    (
        KSPROPERTY_TUNER_STATUS,
        TRUE,                                   // GetSupported or Handler
        sizeof(KSPROPERTY_TUNER_STATUS_S),      // MinProperty
        sizeof(KSPROPERTY_TUNER_STATUS_S),      // MinData
        FALSE,                                  // SetSupported or Handler
        NULL,                                   // Values
        0,                                      // RelationsCount
        NULL,                                   // Relations
        NULL,                                   // SupportHandler
        0                                       // SerializedSize
    )
};
#endif

// ------------------------------------------------------------------------
// Property set for the TVAudio
// ------------------------------------------------------------------------

DEFINE_KSPROPERTY_TABLE(TVAudioProperties)
{
    DEFINE_KSPROPERTY_ITEM
    (
        KSPROPERTY_TVAUDIO_CAPS,
        TRUE,                                   // GetSupported or Handler
        sizeof(KSPROPERTY_TVAUDIO_CAPS_S),      // MinProperty
        sizeof(KSPROPERTY_TVAUDIO_CAPS_S),      // MinData
        FALSE,                                  // SetSupported or Handler
        NULL,                                   // Values
        0,                                      // RelationsCount
        NULL,                                   // Relations
        NULL,                                   // SupportHandler
        0                                       // SerializedSize
    ),
    DEFINE_KSPROPERTY_ITEM
    (
        KSPROPERTY_TVAUDIO_MODE,
        TRUE,                                   // GetSupported or Handler
        sizeof(KSPROPERTY_TVAUDIO_S),           // MinProperty
        sizeof(KSPROPERTY_TVAUDIO_S),           // MinData
        TRUE,                                   // SetSupported or Handler
        NULL,                                   // Values
        0,                                      // RelationsCount
        NULL,                                   // Relations
        NULL,                                   // SupportHandler
        0                                       // SerializedSize
    ),
    DEFINE_KSPROPERTY_ITEM
    (
        KSPROPERTY_TVAUDIO_CURRENTLY_AVAILABLE_MODES,
        TRUE,                                   // GetSupported or Handler
        sizeof(KSPROPERTY_TVAUDIO_S),           // MinProperty
        sizeof(KSPROPERTY_TVAUDIO_S),           // MinData
        FALSE,                                   // SetSupported or Handler
        NULL,                                   // Values
        0,                                      // RelationsCount
        NULL,                                   // Relations
        NULL,                                   // SupportHandler
        0                                       // SerializedSize
    ),
};

// ------------------------------------------------------------------------
// Property set for VideoProcAmp
// ------------------------------------------------------------------------

//
// First define all of the ranges and stepping values
//

// ------------------------------------------------------------------------
static KSPROPERTY_STEPPING_LONG BrightnessRangeAndStep [] =
{
   {
      10000 / 10,         // SteppingDelta (range / steps)
      0,                  // Reserved
      {
         {
            0,                  // Minimum in (IRE * 100) units
            10000               // Maximum in (IRE * 100) units
         }
      }
   }
};

static const ULONG BrightnessDefault = 5000;

static KSPROPERTY_MEMBERSLIST BrightnessMembersList [] =
{
   {
      {
          KSPROPERTY_MEMBER_RANGES,
          sizeof (BrightnessRangeAndStep),
          SIZEOF_ARRAY (BrightnessRangeAndStep),
          0
      },
      (PVOID) BrightnessRangeAndStep
   },
   {
     {
         KSPROPERTY_MEMBER_VALUES,
         sizeof( BrightnessDefault ),
         sizeof( BrightnessDefault ),
         KSPROPERTY_MEMBER_FLAG_DEFAULT
     },
     (PVOID) &BrightnessDefault
   }
};

static KSPROPERTY_VALUES BrightnessValues =
{
   {
      {
         STATICGUIDOF( KSPROPTYPESETID_General ),
         VT_I4,
         0
      }
   },
   SIZEOF_ARRAY( BrightnessMembersList ),
   BrightnessMembersList
};

// ------------------------------------------------------------------------
static KSPROPERTY_STEPPING_LONG ContrastRangeAndStep [] =
{
   {
      10000 / 256,        // SteppingDelta (range / steps)
      0,                  // Reserved
      {
         {
            0,                  // Minimum in (gain * 100) units
            10000               // Maximum in (gain * 100) units
         }
      }
   }
};

static const ULONG ContrastDefault = 5000;

static KSPROPERTY_MEMBERSLIST ContrastMembersList [] =
{
   {
      {
         KSPROPERTY_MEMBER_RANGES,
         sizeof( ContrastRangeAndStep ),
         SIZEOF_ARRAY( ContrastRangeAndStep ),
         0
      },
      (PVOID) ContrastRangeAndStep
   },
   {
     {
         KSPROPERTY_MEMBER_VALUES,
         sizeof( ContrastDefault ),
         sizeof( ContrastDefault ),
         KSPROPERTY_MEMBER_FLAG_DEFAULT
     },
     (PVOID) &ContrastDefault
   }
};

static KSPROPERTY_VALUES ContrastValues =
{
   {
      {
         STATICGUIDOF( KSPROPTYPESETID_General ),
         VT_I4,
         0
      }
   },
   SIZEOF_ARRAY( ContrastMembersList ),
   ContrastMembersList
};

// ------------------------------------------------------------------------
static KSPROPERTY_STEPPING_LONG HueRangeAndStep [] =
{
   {
      10000 / 256,        // SteppingDelta (range / steps)
      0,                  // Reserved
      {
         {
            0,                  // Minimum in (gain * 100) units
            10000               // Maximum in (gain * 100) units
         }
      }
   }
};

static const ULONG HueDefault = 5000;

static KSPROPERTY_MEMBERSLIST HueMembersList [] =
{
   {
      {
         KSPROPERTY_MEMBER_RANGES,
         sizeof( HueRangeAndStep ),
         SIZEOF_ARRAY( HueRangeAndStep ),
         0
      },
      (PVOID) HueRangeAndStep
   },
   {
     {
         KSPROPERTY_MEMBER_VALUES,
         sizeof( HueDefault ),
         sizeof( HueDefault ),
         KSPROPERTY_MEMBER_FLAG_DEFAULT
     },
     (PVOID) &HueDefault
   }
};

static KSPROPERTY_VALUES HueValues =
{
   {
      {
         STATICGUIDOF( KSPROPTYPESETID_General ),
         VT_I4,
         0
      }
   },
   SIZEOF_ARRAY( HueMembersList ),
   HueMembersList
};

static KSPROPERTY_STEPPING_LONG SaturationRangeAndStep [] =
{
   {
      10000 / 256,        // SteppingDelta (range / steps)
      0,                  // Reserved
      {
         {
            0,                  // Minimum in (gain * 100) units
            10000               // Maximum in (gain * 100) units
         }
      }
   }
};

static const ULONG SaturationDefault = 5000;

static KSPROPERTY_MEMBERSLIST SaturationMembersList [] =
{
   {
      {
         KSPROPERTY_MEMBER_RANGES,
         sizeof( SaturationRangeAndStep ),
         SIZEOF_ARRAY( SaturationRangeAndStep ),
         0
      },
      (PVOID) SaturationRangeAndStep
   },
   {
     {
         KSPROPERTY_MEMBER_VALUES,
         sizeof( SaturationDefault ),
         sizeof( SaturationDefault ),
         KSPROPERTY_MEMBER_FLAG_DEFAULT
     },
     (PVOID) &SaturationDefault
   }
};

static KSPROPERTY_VALUES SaturationValues =
{
   {
      {
         STATICGUIDOF( KSPROPTYPESETID_General ),
         VT_I4,
         0
      }
   },
   SIZEOF_ARRAY( SaturationMembersList ),
   SaturationMembersList
};


// ------------------------------------------------------------------------
DEFINE_KSPROPERTY_TABLE(VideoProcAmpProperties)
{
   DEFINE_KSPROPERTY_ITEM
   (
      KSPROPERTY_VIDEOPROCAMP_CONTRAST,
      TRUE,                                   // GetSupported or Handler
      sizeof(KSPROPERTY_VIDEOPROCAMP_S),      // MinProperty
      sizeof(KSPROPERTY_VIDEOPROCAMP_S),      // MinData
      TRUE,                                   // SetSupported or Handler
      &ContrastValues,                        // Values
      0,                                      // RelationsCount
      NULL,                                   // Relations
      NULL,                                   // SupportHandler
      sizeof(ULONG)                           // SerializedSize
   ),
   DEFINE_KSPROPERTY_ITEM
   (
      KSPROPERTY_VIDEOPROCAMP_BRIGHTNESS,
      TRUE,                                   // GetSupported or Handler
      sizeof(KSPROPERTY_VIDEOPROCAMP_S),      // MinProperty
      sizeof(KSPROPERTY_VIDEOPROCAMP_S),      // MinData
      TRUE,                                   // SetSupported or Handler
      &BrightnessValues,                      // Values
      0,                                      // RelationsCount
      NULL,                                   // Relations
      NULL,                                   // SupportHandler
      sizeof(ULONG)                           // SerializedSize
   ),
   DEFINE_KSPROPERTY_ITEM
   (
      KSPROPERTY_VIDEOPROCAMP_HUE,
      TRUE,                                   // GetSupported or Handler
      sizeof(KSPROPERTY_VIDEOPROCAMP_S),      // MinProperty
      sizeof(KSPROPERTY_VIDEOPROCAMP_S),      // MinData
      TRUE,                                   // SetSupported or Handler
      &HueValues,                             // Values
      0,                                      // RelationsCount
      NULL,                                   // Relations
      NULL,                                   // SupportHandler
      sizeof( ULONG )                         // SerializedSize
   ),
   DEFINE_KSPROPERTY_ITEM
   (
      KSPROPERTY_VIDEOPROCAMP_SATURATION,
      TRUE,                                   // GetSupported or Handler
      sizeof(KSPROPERTY_VIDEOPROCAMP_S),      // MinProperty
      sizeof(KSPROPERTY_VIDEOPROCAMP_S),      // MinData
      TRUE,                                   // SetSupported or Handler
      &SaturationValues,                      // Values
      0,                                      // RelationsCount
      NULL,                                   // Relations
      NULL,                                   // SupportHandler
      sizeof( ULONG )                         // SerializedSize
   )
};

// Analog Video Decoder Properties
DEFINE_KSPROPERTY_TABLE( VideoDecProperties )
{
   DEFINE_KSPROPERTY_ITEM
   (
      KSPROPERTY_VIDEODECODER_CAPS,
      true,                                   // GetSupported or Handler
      sizeof(KSPROPERTY_VIDEODECODER_CAPS_S), // MinProperty
      sizeof(KSPROPERTY_VIDEODECODER_CAPS_S), // MinData
      false,                                   // SetSupported or Handler
      NULL,                                   // Values
      0,                                      // RelationsCount
      NULL,                                   // Relations
      NULL,                                   // SupportHandler
      sizeof( ULONG )                         // SerializedSize
   ),
   DEFINE_KSPROPERTY_ITEM
   (
      KSPROPERTY_VIDEODECODER_STANDARD,
      true,                                   // GetSupported or Handler
      sizeof(KSPROPERTY_VIDEODECODER_S), // MinProperty
      sizeof(KSPROPERTY_VIDEODECODER_S), // MinData
      true,                                   // SetSupported or Handler
      NULL,                                   // Values
      0,                                      // RelationsCount
      NULL,                                   // Relations
      NULL,                                   // SupportHandler
      sizeof( ULONG )                         // SerializedSize
   ),
   DEFINE_KSPROPERTY_ITEM
   (
      KSPROPERTY_VIDEODECODER_STATUS,
      true,                                   // GetSupported or Handler
      sizeof(KSPROPERTY_VIDEODECODER_STATUS_S), // MinProperty
      sizeof(KSPROPERTY_VIDEODECODER_STATUS_S), // MinData
      true,                                   // SetSupported or Handler
      NULL,                                   // Values
      0,                                      // RelationsCount
      NULL,                                   // Relations
      NULL,                                   // SupportHandler
      sizeof( ULONG )                         // SerializedSize
   )
};

//
// All of the property sets supported by the adapter
//

DEFINE_KSPROPERTY_SET_TABLE(AdapterPropertyTable)
{
    DEFINE_KSPROPERTY_SET
    (
        &PROPSETID_VIDCAP_CROSSBAR,               // Set
        SIZEOF_ARRAY(XBarProperties),                   // PropertiesCount
        XBarProperties,                                 // PropertyItem
        0,                                              // FastIoCount
        NULL                                            // FastIoTable
    ),
    DEFINE_KSPROPERTY_SET
    (
        &PROPSETID_TUNER,
        SIZEOF_ARRAY(TVTunerProperties),
        TVTunerProperties,
        0,
        NULL
    ),
    DEFINE_KSPROPERTY_SET
    ( 
        &PROPSETID_VIDCAP_TVAUDIO,
        SIZEOF_ARRAY(TVAudioProperties),
        TVAudioProperties,
        0, 
        NULL,
    ),
    DEFINE_KSPROPERTY_SET
    (
        &PROPSETID_VIDCAP_VIDEOPROCAMP,
        SIZEOF_ARRAY(VideoProcAmpProperties),
        VideoProcAmpProperties,
        0,
        NULL
    ),
    DEFINE_KSPROPERTY_SET
    (
        &PROPSETID_VIDCAP_VIDEODECODER,
        SIZEOF_ARRAY(VideoDecProperties),
        VideoDecProperties,
        0,
        NULL
    )
};

#define NUMBER_OF_ADAPTER_PROPERTY_SETS (SIZEOF_ARRAY (AdapterPropertyTable))



VOID AdapterSetProperty(PHW_STREAM_REQUEST_BLOCK pSrb);
VOID AdapterGetProperty(PHW_STREAM_REQUEST_BLOCK pSrb);
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\drivers\wdm\capture\mini\bt848\colfrmat.h ===
// $Header: G:/SwDev/WDM/Video/bt848/rcs/Colfrmat.h 1.4 1998/04/29 22:43:30 tomz Exp $

#ifndef __COLFRMAT_H
#define __COLFRMAT_H


/* Type: ColorFormat
 * Purpose: Enumerates all possible color formats that BtPisces can produce
 */

#ifdef DOCUMENTATION
   Color Format Register Settings

   0000 = RGB32
   0001 = RGB24
   0010 = RGB16
   0011 = RGB15
   0100 = YUY2 4:2:2
   0101 = BtYUV 4:1:1
   0110 = Y8
   0111 = RGB8 (Dithered)
   1000 = YCrCb 4:2:2 Planar
   1001 = YCrCb 4:1:1 Planar
   1010 = Reserved
   1011 = Reserved
   1100 = Reserved
   1101 = Reserved
   1110 = Raw 8X Data
   1111 = Reserved
#endif

typedef enum
{
   CF_BelowRange = -1, CF_RGB32, CF_RGB24, CF_RGB16, CF_RGB15, CF_YUY2,
   CF_BTYUV, CF_Y8, CF_RGB8, CF_PL_422, CF_PL_411, CF_YUV9, CF_YUV12, CF_VBI,
   CF_UYVY, CF_RAW = 0x0E, CF_I420, CF_AboveRange
} ColFmt;


#endif // __COLFRMAT_H
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\drivers\wdm\capture\mini\bt848\command.cpp ===
// $Header: G:/SwDev/WDM/Video/bt848/rcs/Command.cpp 1.4 1998/04/29 22:43:30 tomz Exp $

#include "command.h"
#ifndef __PHYSADDR_H
#include "physaddr.h"
#endif

BYTE Command::InstrSize_ [] =
{
   2, 1, 1, 2, 2, 5, 2, 3, 0xFF
};

BYTE Command::InstrNumber_ [] =
{
 8, 0, 1, 8, 8, 2, 8, 3, 4, 5, 6, 7
};

/* Method: Command::CreateCommand
 * Purpose: Compiles an instruction based on the input
 * Input: lpDst: PVOID - pointer to the instruction
 *   Instr: Instruction - opcode
 *   awByteCnt: WORD [] - array of byte counts for various instructions
 *   adwAddress: DWORD [] - array of addresses for various instructions
 *   SOL: bool - value of the SOL bit
 *   EOL: bool - value of the EOL bit
 *   Intr: bool - value of the interrupt bit
 */
LPVOID Command::Create(
   LPVOID lpDst, Instruction Instr, WORD awByteCnt [], DWORD adwAddress [],
    bool, bool SOL, bool EOL, bool Intr )
{
   // this is to be retrieved later to set EOL bit when instructions are split
   // due to the non-contiguous physical memory
   pdwInstrAddr_ = (PDWORD)lpDst;

   ThisInstr_ = Instr;

   DWORD dwAssembly [5]; // maximum instruction size

   // get pointer to the first dword of a command
   LPFIRSTDWORD lpFD = (LPFIRSTDWORD)dwAssembly;

   lpFD->Initer = 0; // virgin out the command

   // bingo - started new command
   lpFD->Gen.OpCode = Instr;

   // set all the flags
   lpFD->Gen.SOL = SOL;
   lpFD->Gen.EOL = EOL;
   lpFD->Gen.IRQ = Intr;

   switch ( Instr ) {
   case WRIT:  // this command needs target address and byte count
      dwAssembly [1] = adwAddress [0]; // next DWORD is an address
      lpFD->Gen.ByteCount = awByteCnt [0];
      break;
   case SKIP: // these pair is interested in byte count only
   case WRITEC:
      lpFD->Gen.ByteCount = awByteCnt [0];
      break;
   case JUMP: // this command cares about target address only
      dwAssembly [1] = adwAddress [0];
      break;
   case SYNC:
      break;
   case WRITE123: // need everything here...
      lpFD->Gen.ByteCount = awByteCnt [0];
      LPFIRSTDWORD( &dwAssembly [1] )->CRByteCounts.ByteCountCb = awByteCnt [1];
      LPFIRSTDWORD( &dwAssembly [1] )->CRByteCounts.ByteCountCr = awByteCnt [2];
      dwAssembly [2] = adwAddress [0]; // third DWORD is an Y address
      dwAssembly [3] = adwAddress [1]; // third DWORD is an Cb address
      dwAssembly [4] = adwAddress [2]; // third DWORD is an Cr address
      break;
   case SKIP123:
      lpFD->Gen.ByteCount = awByteCnt [0];
      LPFIRSTDWORD( &dwAssembly [1] )->Gen.ByteCount = awByteCnt [1]; // second byte count is in DWORD #2
      break;
   case WRITE1S23: // this command needs Y byte count and dest. address
      lpFD->Gen.ByteCount = awByteCnt [0];
      LPFIRSTDWORD( &dwAssembly [1] )->CRByteCounts.ByteCountCb = awByteCnt [1];
      LPFIRSTDWORD( &dwAssembly [1] )->CRByteCounts.ByteCountCr = awByteCnt [2];
      dwAssembly [2] = adwAddress [0]; // third DWORD is an address
      break;
   default:
      return (LPVOID)-1;
   }
   RtlCopyMemory( lpDst, dwAssembly, GetInstrSize() * sizeof( DWORD ) );
   
   PDWORD pdwRet = (PDWORD)lpDst + GetInstrSize();
   *pdwRet = PROGRAM_TERMINATOR;
   return pdwRet;
}
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\drivers\wdm\capture\mini\bt848\colspace.cpp ===
// $Header: G:/SwDev/WDM/Video/bt848/rcs/Colspace.cpp 1.7 1998/04/29 22:43:30 tomz Exp $

#define INITGUID
#include "colspace.h"
#include "fourcc.h"
#include "defaults.h"
#include "uuids.h"


BYTE const ColorSpace::BitCount_ [] =
{
// RGB32 RGB24 RGB16 RGB15 YUY2 BTYUV Y8 RGB8 PL_422 PL_411 YUV9 YUV12 VBI UYVY RAW I420
   32,   24,   16,   16,   16,  12,   8, 8,   16,    12,    9,   12,    8, 16,  8,  12
};

BYTE const ColorSpace::YPlaneBitCount_ [] =
{
// RGB32 RGB24 RGB16 RGB15 YUY2 BTYUV Y8 RGB8 PL_422 PL_411 YUV9 YUV12 VBI UYVY RAW I420
   32,   24,   16,   16,   16,  12,   8, 8,   8,     8,     8,   8,     8, 16,  8,  8
};

BYTE const ColorSpace::XRestriction_ [] =
{
   1,    1,    1,    1,   2,    4,    1, 1,   8,     16,    16,  8,    2,  4,   1,  8
};

BYTE const ColorSpace::YRestriction_ [] =
{
   2,    2,    2,    2,   2,    2,    2, 2,   2,     2,     4,    2,   2,  2,   2,  2
};

FOURCC const ColorSpace::FourccArr_ [] =
{
// 32      24      16            15
   BI_RGB, BI_RGB, BI_RGB, BI_RGB, FCC_YUY2, FCC_Y41P, FCC_Y8, BI_RGB,
   FCC_422, FCC_411, FCC_YVU9, FCC_YV12, FCC_VBI, FCC_UYVY, FCC_RAW, FCC_I420
};

const GUID *ColorSpace::VideoGUIDs [] =
{
   &MEDIASUBTYPE_RGB32, &MEDIASUBTYPE_RGB24, &MEDIASUBTYPE_RGB565,   &MEDIASUBTYPE_RGB555,
   &MEDIASUBTYPE_YUY2,  &MEDIASUBTYPE_Y41P,  NULL,                   NULL,
   NULL,                &MEDIASUBTYPE_Y411,  &MEDIASUBTYPE_YVU9,     NULL,
   NULL,                &MEDIASUBTYPE_UYVY,  NULL,                   NULL
};

void DumpGUID(const GUID guid)
{
   DebugOut(( 1, "Guid = %08x-%04x-%04x-%02x-%02x-%02x-%02x-%02x-%02x-%02x-%02x\n",
         guid.Data1, guid.Data2, guid.Data3,
         guid.Data4[0], guid.Data4[1], guid.Data4[2], guid.Data4[3],
         guid.Data4[4], guid.Data4[5], guid.Data4[6], guid.Data4[7]
   ));
}

/* Constructor: ColorSpace::ColorSpace
 * Input: fcc: FOURCC
 */
ColorSpace::ColorSpace( FOURCC fcc, int bitCount ) : CurColor_( CF_BelowRange )
{
   DebugOut((1, "ColorSpace(%x, %d, ('%c%c%c%c'))\n", 
      fcc, 
      bitCount,
      fcc & 0xff,
      (fcc >> 8) & 0xff,
      (fcc >> 16) & 0xff,
      (fcc >> 24) & 0xff
   ));

   switch( fcc ) {
   case BI_RGB:
      switch ( bitCount ) {
      default: 
      case 8:  CurColor_ = CF_RGB8;    break;
      case 16: CurColor_ = CF_RGB15;   break;
      case 24: CurColor_ = CF_RGB24;   break;
      case 32: CurColor_ = CF_RGB32;   break;
      }
      break;
   case BI_RLE8:
   case BI_RLE4:
   case BI_BITFIELDS:
   case 0xe436eb7b:// ???
   case FCC_YUY2:
   case FCC_Y41P:
   case FCC_Y8:
   case FCC_422:
   case FCC_411:
   case FCC_YVU9:
   case FCC_YV12:
   case FCC_VBI:
   case FCC_UYVY:
   case FCC_RAW:
   case FCC_I420:
   default:
         for ( int fccArrIdx = CF_RGB32; fccArrIdx < CF_AboveRange; fccArrIdx++ )
            if ( fcc == FourccArr_ [fccArrIdx] ) {
               CurColor_ = (ColFmt)fccArrIdx;
               break;
            }
         break;
   }
   DebugOut((1, "*** CurColor_ set to %d\n", CurColor_));
}

/* Constructor: ColorSpace::ColorSpace
 * Input: guid: const GUID &
 */
ColorSpace::ColorSpace( const GUID &guid ) : CurColor_( CF_BelowRange )
{
   DebugOut((1, "**************************************\n"));
   DebugOut((1, "Looking for the following guid\n"));
   DumpGUID(guid);
   DebugOut((1, "---\n"));

   for ( int idx = CF_RGB32; idx < CF_AboveRange; idx++ ) {
      DumpGUID(*VideoGUIDs [idx]);
      if ( VideoGUIDs [idx] && IsEqualGUID( guid, *VideoGUIDs [idx] ) ) {
         CurColor_ = (ColFmt)idx;
         break;
      }
   }
}

/* Method: ColorSpace::CheckDimentions
 * Purpose: This functions checks that the size of a buffer corresponds to the
 *   restrictions imposed by a color format
 * Input: size: reference to SIZE structure
 * Output: bool: True or False
 */
bool ColorSpace::CheckDimentions( const SIZE &size ) const
{
   return  bool( CurColor_ > CF_BelowRange && CurColor_ < CF_AboveRange &&
                 IsDivisible( size.cx, XRestriction_ [CurColor_] ) &&
                 IsDivisible( size.cy, YRestriction_ [CurColor_] )  );//&&
//                 size.cx >= MinOutWidth && size.cx <= MaxOutWidth &&
//                 size.cy >= MinOutHeight && size.cy <= MaxOutHeight );
}

/* Method: ColorSpace::CheckLeftTop
 * Purpose: This functions checks that the left top corner of a buffer
 * corresponds to the restrictions imposed by a color format
 * Input: lt: const reference to MPoint structure
 * Output: bool: true or false
 */
bool ColorSpace::CheckLeftTop( const MPoint &lt ) const
{
   return bool( !( lt.x & 3 ) && !( lt.y & 1 ) );
}
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\drivers\wdm\capture\mini\bt848\colspace.h ===
// $Header: G:/SwDev/WDM/Video/bt848/rcs/Colspace.h 1.3 1998/04/29 22:43:30 tomz Exp $

#ifndef __COLSPACE_H
#define __COLSPACE_H

#ifndef __MYTYPES_H
#include "mytypes.h"
#endif

typedef DWORD           FOURCC;          /*a four character code */
   /* constants for the biCompression field from windows.h*/
   #define BI_RGB        0L
   #define BI_RLE8       1L
   #define BI_RLE4       2L
   #define BI_BITFIELDS  3L

#ifndef __COLFRMAT_H
#include "colfrmat.h"
#endif


/* Class: ColorSpace:
 * Purpose: This class provides the functionality of the BtPisces color
 *   space converter
 * Attributes: CurColor_: ColFmt - current color format
 * Operations:
      SetColorFormat( ColFmt aColor ): - this method sets the color format
      ColFmt GetColorFormat(): - this method returns the current color format
      BYTE GetBitCount(): - this method returns number of bpp for the current
         color format.
 */
class ColorSpace
{
   private:
      ColFmt CurColor_;
      static const BYTE BitCount_ [];
      static const BYTE XRestriction_ [];
      static const BYTE YRestriction_ [];
      static const BYTE YPlaneBitCount_ [];
      static const FOURCC FourccArr_ [];
      static const GUID *VideoGUIDs [];
      ColorSpace();
   public:
      void   SetColorFormat( ColFmt aColor ) { CurColor_ = aColor; }
      DWORD  GetBitCount() const;
      DWORD  GetPitchBpp() const;
      FOURCC GetFourcc() const;
      bool   CheckDimentions( const SIZE &aSize ) const;
      bool   CheckLeftTop( const MPoint &aSize ) const;        

      ColorSpace( ColFmt aColForm ) : CurColor_( aColForm ) {}
      ColorSpace( FOURCC fcc, int bitCount );
      ColorSpace( const GUID &guid );

      ColFmt GetColorFormat() const;

      bool IsValid()
      { return bool( CurColor_ > CF_BelowRange && CurColor_ < CF_AboveRange ); }
};

/* Method: ColorSpace::GetBitCount
 * Purpose: Returns number of bpp for a given color
 */
inline DWORD ColorSpace::GetBitCount() const { return BitCount_ [CurColor_]; }

/* Method: ColorSpace::GetPitchBpp
 * Purpose: Used to calculate pitch of data buffers. Most useful for planar modes
 *   where bpp used for pitch calculation is different from 'real' bpp of a
 *   data format
 */
inline DWORD ColorSpace::GetPitchBpp() const { return YPlaneBitCount_ [CurColor_]; }

/* Method: ColorSpace::GetColorFormat
 * Purpose: a query function
 */
inline ColFmt ColorSpace::GetColorFormat() const { return CurColor_; }

/* Method: ColorSpace::GetFourcc
 * Purpose: returns a FOURCC corresponding to the current color format
 */
inline FOURCC ColorSpace::GetFourcc() const { return FourccArr_ [CurColor_]; }


/* Function: IsDivisible
 * Purpose: This function checks that the first value passed in is
 *   evenly divisible by the second
 * Input: ToCheck: int - value to be checked
 *        Divisor: int
 * Output: bool
 * Note: The function assumes Divisor is a power of 2
 */
inline bool IsDivisible( int ToCheck, int Divisor )
{
   return bool( !( ToCheck & ( Divisor - 1 ) ) );
}

#endif __COLSPACE_H
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\drivers\wdm\capture\mini\bt848\command.h ===
// $Header: G:/SwDev/WDM/Video/bt848/rcs/Command.h 1.4 1998/04/29 22:43:31 tomz Exp $

#ifndef __COMMAND_H
#define __COMMAND_H

#ifndef __MEM_H
#include <memory.h>
#endif

#include "mytypes.h"

#define PROGRAM_TERMINATOR 0xa5a5a5a5

/* Type: Instruction
 * Purpose: enumerates all RISC commands
 */
typedef enum
{
   WRIT    = 0x01, SKIP = 0x02, WRITEC   = 0x05,
   JUMP    = 0x07, SYNC = 0x08, WRITE123 = 0x09,
   SKIP123 = 0x0A, WRITE1S23 = 0x0B, Reserved = 0xFF
} Instruction;

/* Type: SyncCode
 * Purpose: enumerates all sync codes coming out of decoder
*/
typedef enum
{
   SC_FM1 = 0x6, SC_FM3 = 0xE, SC_VRE = 0x4,
   SC_VRO = 0xC, SC_RESYNC = 1, SC_Reserved = 0xFF
} SyncCode;

/* Class: Command
 * Purpose: This class represents a RISC instruction in a more convenient form
 * Attributes:
 * Operations:
 */
class Command
{
   public:
      typedef union tag {
         struct {
            unsigned int   ByteCount   : 12;
            unsigned int   BE_Res      : 4;
            unsigned int   StatusSet   : 4;
            unsigned int   StatusReset : 4;
            unsigned int   IRQ         : 1;
            unsigned int   Reserved    : 1;
            unsigned int   EOL         : 1;
            unsigned int   SOL         : 1;
            unsigned int   OpCode      : 4;
         } Gen;
         struct {
            unsigned int   Status      : 4;
            unsigned int   Res1        : 11;
            unsigned int   Resync      : 1;
            unsigned int   StatusSet   : 4;
            unsigned int   StatusReset : 4;
            unsigned int   IRQ         : 1;
            unsigned int   Res2        : 1;
            unsigned int   EOL         : 1;
            unsigned int   SOL         : 1;
            unsigned int   OpCode      : 4;
         } Sync;

         struct {
            unsigned int   ByteCountCb : 12;
            unsigned int   skip        :  4;
            unsigned int   ByteCountCr : 12;
         } CRByteCounts;

         DWORD            Initer; // used to zero out all the fields

      } FIRSTDWORD, *LPFIRSTDWORD;

   private:
      Instruction ThisInstr_;

      static BYTE InstrSize_   [];
      static BYTE InstrNumber_ [];

      PDWORD      pdwInstrAddr_;

   public:
      Instruction GetInstr() { return ThisInstr_; }
      PDWORD GetInstrAddr() { return pdwInstrAddr_; }

      BYTE GetInstrSize() { return InstrSize_ [InstrNumber_ [ThisInstr_] ]; }

      BYTE GetInstrSize( Instruction inst )
      { return InstrSize_ [InstrNumber_ [inst] ]; }

      LPVOID Create( LPVOID lpDst, Instruction Instr, WORD wByteCnt [],
         DWORD dwAddress [], bool SafetyDevice = true,
         bool SOL = true, bool EOL = true, bool Intr = false );

      // start/end of line control
      void SetSOL( PVOID lpFD ) { ((LPFIRSTDWORD)lpFD)->Gen.SOL = 1; }
      void ResetSOL( PVOID lpFD ) { ((LPFIRSTDWORD)lpFD)->Gen.SOL = 0; }

      void SetEOL( PVOID lpFD ) { ((LPFIRSTDWORD)lpFD)->Gen.EOL = 1; }
      void ResetEOL( PVOID lpFD ) { ((LPFIRSTDWORD)lpFD)->Gen.EOL = 0; }

      void SetIRQ( PVOID lpFD ) { ((LPFIRSTDWORD)lpFD)->Gen.IRQ = 1; }
      void ResetIRQ( PVOID lpFD ) { ((LPFIRSTDWORD)lpFD)->Gen.IRQ = 0; }

      void SetStatus( PVOID lpFD, int s )
      {
       ((LPFIRSTDWORD)lpFD)->Gen.StatusSet = s;
       ((LPFIRSTDWORD)lpFD)->Gen.StatusReset = 0;
      }

      void ResetStatus( PVOID lpFD, int s )
      {
       ((LPFIRSTDWORD)lpFD)->Gen.StatusReset = s;
       ((LPFIRSTDWORD)lpFD)->Gen.StatusSet = 0;
      }

      void SetToCount( PVOID lpFD )
      {
       ((LPFIRSTDWORD)lpFD)->Gen.StatusReset = 0xF;
       ((LPFIRSTDWORD)lpFD)->Gen.StatusSet   = 0xF;
      }

      // eol/sol query
      bool IsEOL( PVOID lpFD ) { return bool( ((LPFIRSTDWORD)lpFD)->Gen.EOL ); }
      bool IsSOL( PVOID lpFD ) { return bool( ((LPFIRSTDWORD)lpFD)->Gen.SOL ); }
      bool IsIRQ( PVOID lpFD ) { return bool( ((LPFIRSTDWORD)lpFD)->Gen.IRQ ); }
      WORD GetStatus( PVOID lpFD )
      {
         return WORD( ( ((LPFIRSTDWORD)lpFD)->Gen.StatusSet << 4 ) |
                  ((LPFIRSTDWORD)lpFD)->Gen.StatusReset );
      }

      WORD GetSyncStatus( PVOID lpFD )
      { return (WORD)((LPFIRSTDWORD)lpFD)->Sync.Status; }

      void SetSync( PVOID lpFD, SyncCode eACode, bool Resync = false ) {
         ((LPFIRSTDWORD)lpFD)->Sync.Status = eACode;
         ((LPFIRSTDWORD)lpFD)->Sync.Resync = Resync;
      }
      void SetResync( PVOID lpFD, bool val )
      { ((LPFIRSTDWORD)lpFD)->Sync.Resync = val; }

      bool GetResync( PVOID lpFD )
      { return bool( ((LPFIRSTDWORD)lpFD)->Sync.Resync ); }

      Command(){}//  { Init();  }
      Command( Instruction instr ) : ThisInstr_( instr ) {}
};

#endif __COMMAND_H
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\drivers\wdm\capture\mini\bt848\compreg.h ===
// $Header: G:/SwDev/WDM/Video/bt848/rcs/Compreg.h 1.3 1998/04/29 22:43:31 tomz Exp $

#ifndef __COMPREG_H
#define __COMPREG_H

#ifndef __REGFIELD_H
#include "regfield.h"
#endif

/* Class: CompositeReg
 * Purpose: This class encapsulates the registers that have their bits in two
 *          different places ( registers )
 * Attributes:
 *   LSBPart_:  Register & - least significant bits part of a composite register
 *   HighPart_: RegField & - most significant bits part of a composite register
 *   LowPartWidth_: BYTE - width of the low portion in bits
 * Operations:
 *   operator DWORD(): data access method. Returns a value of the register
 *   DWORD operator=( DWORD ): assignment operator. Used to set the register
 * Note: the error handling provided by the class is minimal. It is a responibility
 *   of the user to pass correct parameters to the constructor. The class has
 *   no way of knowing if the correct low and high registers passed in are correct,
 *   for example. If low part size in bits passed in is not less then MaxWidth ( 32 )
 *   the mask used to isolate the low portion will be 0xFFFFFFFF
 */
class CompositeReg : public RegBase
{
   private:
      Register &LSBPart_;
      RegField &MSBPart_;
      BYTE      LowPartWidth_;
      CompositeReg();
   public:
      virtual operator DWORD();
      virtual DWORD operator=( DWORD dwValue );
      CompositeReg( Register &LowReg, BYTE LowWidth, RegField &HighReg, RegisterType aType ) :
         RegBase( aType ), LSBPart_( LowReg ), MSBPart_( HighReg ),
         LowPartWidth_( LowWidth ) {}
};

#endif
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\drivers\wdm\capture\mini\bt848\compreg.cpp ===
// $Header: G:/SwDev/WDM/Video/bt848/rcs/Compreg.cpp 1.3 1998/04/29 22:43:31 tomz Exp $

#include "compreg.h"

/* Method: CompositeReg::operator DWORD()
 * Purpose: Performs the read from a composite register
*/
CompositeReg::operator DWORD()
{
   // if write-only return the shadow
   if ( GetRegisterType() == WO )
      return GetShadow();

// obtain the low and high values
   DWORD dwLowBits  = (DWORD)LSBPart_;
   DWORD dwHighBits = (DWORD)MSBPart_;

   // put high part to the proper place
   dwHighBits <<= LowPartWidth_;

   // done !
   return dwHighBits | dwLowBits;
}


/* Method: CompositeReg::operator=
 * Purpose: performs the assignment to a composite register
*/
DWORD CompositeReg::operator=( DWORD dwValue )
{
// if a register is read-only nothing is done. This is an error
   if ( GetRegisterType() == RO )
      return ReturnAllFs();

   // keep a shadow around
   SetShadow( dwValue );
 // compute the mask to apply to the passed value, so it can be...
   DWORD dwMask = ::MakeAMask( LowPartWidth_ );

 // ... assigned to the low portion register
   LSBPart_ = dwValue & dwMask;

   // shift is enough to get the high part
   MSBPart_ = ( dwValue >> LowPartWidth_ );
   return dwValue;
}
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\drivers\wdm\capture\mini\bt848\decoder.cpp ===
// $Header: G:/SwDev/WDM/Video/bt848/rcs/Decoder.cpp 1.5 1998/04/29 22:43:31 tomz Exp $

#include "mytypes.h"
#include "Scaler.h"
#include "decoder.h"
#include "constr.h"
#include "dcdrvals.h"

#define CON_vs_BRI   // HW does contrast incorrectly, try to adjust in SW


//===========================================================================
// Bt848 Decoder Class Implementation
//===========================================================================

/////////////////////////////////////////////////////////////////////////////
// Constructor
/////////////////////////////////////////////////////////////////////////////
Decoder::Decoder( DWORD *xtals ) :
   // init register min, max, default
   m_regHue( HueMin, HueMax, HueDef ),
   m_regSaturationNTSC( SatMinNTSC, SatMaxNTSC, SatDefNTSC ),
   m_regSaturationSECAM( SatMinSECAM, SatMaxSECAM, SatDefSECAM ),
   m_regContrast( ConMin, ConMax, ConDef ),
   m_regBrightness( BrtMin, BrtMax, BrtDef ),
   m_param( ParamMin, ParamMax, ParamDef ),
   CONSTRUCT_REGISTERS
{
   Xtals_ [0] = *xtals;
   Xtals_ [1] = *(xtals + 1 );

   // need to set this to 0x4F
   decRegWC_UP = 0x4F;
   // and this one to 0x7F to make sure CRUSH bit works
   decRegWC_DN = 0x7F;

   // HACTIVE should always be 0
   decFieldHACTIVE = 0;

   // HSFMT (odd and even) should always be 0
   decFieldHSFMT = decFieldODD_HSFMT = 0;

   // Instead of using default values, set some registers fields to optimum values
   SetLumaDecimation( true );
   SetChromaAGC( true );
   SetLowColorAutoRemoval( true );
   SetAdaptiveAGC( false );

   // for contrast adjustment purpose
   regBright = 0x00;     // brightness register value before adjustment
   regContrast = 0xD8;   // contrast register value before adjustment

   // Initialize these Values so we can Get the correct property values		jbc 3/13/98
   // Perhaps get should read the actual values set in the decoder but this is quick and works for now
   // [!!!] 
   m_briParam = 5000;				// jbc 3/13/98
   m_satParam = 5000;				// jbc 3/13/98
   m_conParam = 5000;				// jbc 3/13/98
   m_hueParam = 5000;				// jbc 3/13/98
};

/////////////////////////////////////////////////////////////////////////////
// Destructor
/////////////////////////////////////////////////////////////////////////////
Decoder::~Decoder()
{
}


//===== Device Status register ==============================================

/////////////////////////////////////////////////////////////////////////////
// Method:  BYTE Decoder::GetDeviceStatusReg( void )
// Purpose: Obtain device status register value
// Input:   None
// Output:  None
// Return:  value of status register in BYTE
/////////////////////////////////////////////////////////////////////////////
BYTE Decoder::GetDeviceStatusReg( void )
{
	BYTE status = (BYTE)decRegSTATUS;
	decRegSTATUS = 0x00;
   return status;
}

/////////////////////////////////////////////////////////////////////////////
// Method:  bool Decoder::IsVideoPresent( void )
// Purpose: Detect if video is present
// Input:   None
// Output:  None
// Return:  true if video present; else false
/////////////////////////////////////////////////////////////////////////////
bool Decoder::IsVideoPresent( void )
{
  return (bool) (decFieldPRES == 1);
}


/////////////////////////////////////////////////////////////////////////////
// Method:  bool Decoder::IsDeviceInHLock( void )
// Purpose: Detect if device is in H-lock
// Input:   None
// Output:  None
// Return:  true if device in H-lock; else false
/////////////////////////////////////////////////////////////////////////////
bool Decoder::IsDeviceInHLock( void )
{
  return (bool) (decFieldHLOC == 1);
}


/////////////////////////////////////////////////////////////////////////////
// Method:  bool Decoder::IsEvenField( void )
// Purpose: Reflect whether an even or odd field is being decoded
// Input:   None
// Output:  None
// Return:  true if even field; else false
/////////////////////////////////////////////////////////////////////////////
bool Decoder::IsEvenField( void )
{
  return (bool) (decFieldEVENFIELD == 1);
}


/////////////////////////////////////////////////////////////////////////////
// Method:  bool Decoder::Is525LinesVideo( void )
// Purpose: Check to see if we are dealing with 525 lines video signal
// Input:   None
// Output:  None
// Return:  true if 525 lines detected; else false (assume 625 lines)
/////////////////////////////////////////////////////////////////////////////
bool Decoder::Is525LinesVideo( void )
{
  return (bool) (decFieldNUML == 0);  //525
}

/////////////////////////////////////////////////////////////////////////////
// Method:  bool Decoder::IsCrystal0Selected( void )
// Purpose: Reflect whether XTAL0 or XTAL1 is selected
// Input:   None
// Output:  None
// Return:  true if XTAL0 selected; else false (XTAL1 selected)
/////////////////////////////////////////////////////////////////////////////
bool Decoder::IsCrystal0Selected( void )
{
  return (bool) (decFieldCSEL == 0);
}

/////////////////////////////////////////////////////////////////////////////
// Method:  bool Decoder::IsLumaOverflow( void )
// Purpose: Indicates if luma ADC overflow
// Input:   None
// Output:  None
// Return:  true if luma ADC overflow; else false
/////////////////////////////////////////////////////////////////////////////
bool Decoder::IsLumaOverflow( void )
{
  return (bool) (decFieldLOF == 1);
}


/////////////////////////////////////////////////////////////////////////////
// Method:  void Decoder::ResetLumaOverflow( void )
// Purpose: Reset luma ADC overflow bit
// Input:   None
// Output:  None
// Return:  None
/////////////////////////////////////////////////////////////////////////////
void Decoder::ResetLumaOverflow( void )
{
  decFieldLOF = 0;  // write to it will reset the bit
}

/////////////////////////////////////////////////////////////////////////////
// Method:  bool Decoder::IsChromaOverflow( void )
// Purpose: Indicates if chroma ADC overflow
// Input:   None
// Output:  None
// Return:  true if chroma ADC overflow; else false
/////////////////////////////////////////////////////////////////////////////
bool Decoder::IsChromaOverflow( void )
{
  return (bool) (decFieldCOF == 1);
}

/////////////////////////////////////////////////////////////////////////////
// Method:  void Decoder::ResetChromaOverflow( void )
// Purpose: Reset chroma ADC overflow bit
// Input:   None
// Output:  None
// Return:  None
/////////////////////////////////////////////////////////////////////////////
void Decoder::ResetChromaOverflow( void )
{
  decFieldCOF = 0;  // write to it will reset the bit
}


//===== Input Format register ===============================================

/////////////////////////////////////////////////////////////////////////////
// Method:  ErrorCode Decoder::SetVideoInput( Connector source )
// Purpose: Select which connector as input
// Input:   Connector source - SVideo, Tuner, Composite
// Output:  None
// Return:  Fail if error in parameter, else Success
/////////////////////////////////////////////////////////////////////////////
ErrorCode Decoder::SetVideoInput( Connector source )
{
  if ( ( source != ConSVideo ) &&
       ( source != ConTuner ) &&
       ( source != ConComposite ) )
    return Fail;

  decFieldMUXSEL = source;

  // set to composite or Y/C component video depends on video source
  SetCompositeVideo( ( source == ConSVideo ) ? false : true );
  return Success;
}


/////////////////////////////////////////////////////////////////////////////
// Method:  int Decoder::GetVideoInput( void )
// Purpose: Get which connector is input
// Input:   None
// Output:  None
// Return:  Video source - SVideo, Tuner, Composite
/////////////////////////////////////////////////////////////////////////////
int Decoder::GetVideoInput( void )
{
  return ((int)decFieldMUXSEL);
}

/////////////////////////////////////////////////////////////////////////////
// Method:  ErrorCode Decoder::SetCrystal( Crystal crystalNo )
// Purpose: Select which crystal as input
// Input:   Crystal crystalNo:
//            XT0         - Crystal_XT0
//            XT1         - Crystal_XT1
//            Auto select - Crystal_AutoSelect
// Output:  None
// Return:  Fail if error in parameter, else Success
/////////////////////////////////////////////////////////////////////////////
ErrorCode Decoder::SetCrystal( Crystal crystalNo )
{
  if ( ( crystalNo < Crystal_XT0 ) || ( crystalNo >  Crystal_AutoSelect ) )
    return Fail;

  decFieldXTSEL = crystalNo;
  return Success;
}


/////////////////////////////////////////////////////////////////////////////
// Method:  int Decoder::GetCrystal( void )
// Purpose: Get which crystal is input
// Input:   None
// Output:  None
// Return:   Crystal Number:
//            XT0         - Crystal_XT0
//            XT1         - Crystal_XT1
//            Auto select - Crystal_AutoSelect
/////////////////////////////////////////////////////////////////////////////
int Decoder::GetCrystal( void )
{
  return ((int)decFieldXTSEL);
}


/////////////////////////////////////////////////////////////////////////////
// Method:  ErrorCode Decoder::SetVideoFormat( VideoFormat format )
// Purpose: Set video format
// Input:   Video format -
//            Auto format:          VFormat_AutoDetect
//            NTSC (M):             VFormat_NTSC
//            PAL (B, D, G, H, I):  VFormat_PAL_BDGHI
//            PAL (M):              VFormat_PAL_M
//            PAL(N):               VFormat_PAL_N
//            SECAM:                VFormat_SECAM
// Output:  None
// Return:  Fail if error in parameter, else Success
// Notes:   Available video formats are: NTSC, PAL(B, D, G, H, I), PAL(M),
//                                       PAL(N), SECAM
//          This function also sets the AGCDelay (ADELAY) and BrustDelay
//          (BDELAY) registers
/////////////////////////////////////////////////////////////////////////////
ErrorCode Decoder::SetVideoFormat( VideoFormat format )
{
  if ( (format <  VFormat_AutoDetect)  ||
       (format >  VFormat_SECAM)       ||
       (format == VFormat_Reserved2) )
    return Fail;

  switch (format)
  {
    case VFormat_NTSC:
      decFieldFORMAT = format;
  		decRegADELAY = 0x68;
  		decRegBDELAY = 0x5D;
      SetChromaComb( true );        // enable chroma comb
      SelectCrystal( NTSC_xtal );         // select NTSC crystal
      break;
    case VFormat_PAL_BDGHI:
    case VFormat_PAL_M:
    case VFormat_PAL_N:
      decFieldFORMAT = format;
      decRegADELAY = 0x7F;
      decRegBDELAY = 0x72;
      SetChromaComb( true );        // enable chroma comb
      SelectCrystal( PAL_xtal );         // select PAL crystal
      break;
    case VFormat_SECAM:
      decFieldFORMAT = format;
      decRegADELAY = 0x7F;
      decRegBDELAY = 0xA0;
      SetChromaComb( false );       // disable chroma comb
      SelectCrystal( PAL_xtal );         // select PAL crystal
      break;
    default: // VFormat_AutoDetect
      // auto format detect by examining the number of lines
      if ( Decoder::Is525LinesVideo() ) // lines == 525 -> NTSC
        Decoder::SetVideoFormat( VFormat_NTSC );
      else  // lines == 625 -> PAL/SECAM
        Decoder::SetVideoFormat( VFormat_PAL_BDGHI );    // PAL_BDGHI covers most areas 
  }

  SetSaturation( m_satParam );
  return Success;
}


/////////////////////////////////////////////////////////////////////////////
// Method:  int Decoder::GetVideoFormat( void )
// Purpose: Obtain video format
// Input:   None
// Output:  None
// Return:  Video format
//            Auto format:          VFormat_AutoDetect
//            NTSC (M):             VFormat_NTSC
//            PAL (B, D, G, H, I):  VFormat_PAL_BDGHI
//            PAL (M):              VFormat_PAL_M
//            PAL(N):               VFormat_PAL_N
//            SECAM:                VFormat_SECAM
/////////////////////////////////////////////////////////////////////////////
int Decoder::GetVideoFormat( void )
{
   BYTE bFormat = (BYTE)decFieldFORMAT;
   if ( !bFormat ) // autodetection enabled
      return Is525LinesVideo() ? VFormat_NTSC : VFormat_SECAM;
   else
     return bFormat;
}


//===== Temporal Decimation register ========================================

/////////////////////////////////////////////////////////////////////////////
// Method:  ErrorCode Decoder::SetRate( bool fields, VidField even, int rate )
// Purpose: Set frames or fields rate
// Input:   bool fields   - true for fields, false for frames
//          VidField even - true to start decimation with even field, false odd
//          int  rate     - decimation rate: frames (1-50/60); fields(1-25/30)
// Output:  None
// Return:  Fail if error in parameter, else Success
/////////////////////////////////////////////////////////////////////////////
ErrorCode Decoder::SetRate( bool fields, VidField vf, int rate )
{
  int nMax;
  if ( Is525LinesVideo() == true )
    nMax = 30;  // NTSC
  else
    nMax = 25;  // PAL/SECAM

  // if setting frame rate, double the max value
  if ( fields == false )
    nMax *= 2;

  if ( rate < 0 || rate > nMax )
    return Fail;

  decFieldDEC_FIELD = (fields == false) ? Off : On;
  decFieldDEC_FIELDALIGN = (vf == VF_Even) ? On : Off;
  int nDrop = (BYTE) nMax - rate;
  decFieldDEC_RAT = (BYTE) (fields == false) ? nDrop : nDrop * 2;

  return Success;
}


//===== Brightness Control register =========================================

/////////////////////////////////////////////////////////////////////////////
// Method:  ErrorCode Decoder::SetBrightness( int param )
// Purpose: Set video brightness
// Input:   int param - parameter value (0-255; default 128)
// Output:  None
// Return:  Fail if error in parameter, else Success
// Note:    See IsAdjustContrast() for detailed description of the contrast
//          adjustment calculation
/////////////////////////////////////////////////////////////////////////////
ErrorCode Decoder::SetBrightness( int param )
{
  if( m_param.OutOfRange( param ) )
    return Fail;

  // perform mapping to our range
  int mapped;
  if ( Mapping( param, m_param, &mapped, m_regBrightness ) == Fail )
    return Fail;

  m_briParam = (WORD)param;

  // calculate brightness value
  int value = (128 * mapped) / m_regBrightness.Max() ;

  // need to limit the value to 0x7F (+50%) because 0x80 is -50%!
  if (( mapped > 0 ) && ( value == 0x80 ))
    value = 0x7F;

  // perform adjustment of brightness register if adjustment is needed
  if ( IsAdjustContrast() )
  {
    regBright = value;   // brightness value before adjustment

    long A = (long)regBright * (long)0xD8;
    long B = 64 * ( (long)0xD8 - (long)regContrast );
    long temp = 0x00;
    if ( regContrast != 0 )  // already limit contrast > zero; just in case here
       temp = ( ( A + B ) / (long)regContrast );
    temp = ( temp < -128 ) ? -128 : ( ( temp > 127 ) ? 127 : temp );
    value = (BYTE)temp;

  }

  decRegBRIGHT = (BYTE)value;

  return Success;
}


/////////////////////////////////////////////////////////////////////////////
// Method:  int Decoder::GetBrightness( void )
// Purpose: Obtain brightness value
// Input:   None
// Output:  None
// Return:  Brightness parameter (0-255)
/////////////////////////////////////////////////////////////////////////////
int Decoder::GetBrightness( void )
{
  return m_briParam;
}


//===== Miscellaneous Control register (E_CONTROL, O_CONTROL) ===============

/////////////////////////////////////////////////////////////////////////////
// Method:  void Decoder::SetLumaNotchFilter( bool mode )
// Purpose: Enable/Disable luma notch filter
// Input:   bool mode - true = Enable; false = Disable
// Output:  None
// Return:  None
/////////////////////////////////////////////////////////////////////////////
void Decoder::SetLumaNotchFilter( bool mode )
{
  decFieldLNOTCH = decFieldODD_LNOTCH = (mode == false) ? On : Off;  // reverse
}


/////////////////////////////////////////////////////////////////////////////
// Method:  bool Decoder::IsLumaNotchFilter( void )
// Purpose: Check if luma notch filter is enable or disable
// Input:   None
// Output:  None
// Return:  true = Enable; false = Disable
/////////////////////////////////////////////////////////////////////////////
bool Decoder::IsLumaNotchFilter( void )
{
  return (decFieldLNOTCH == Off) ? true : false;  // reverse
}


/////////////////////////////////////////////////////////////////////////////
// Method:  void Decoder::SetCompositeVideo( bool mode )
// Purpose: Select composite or Y/C component video
// Input:   bool mode - true = Composite; false = Y/C Component
// Output:  None
// Return:  None
/////////////////////////////////////////////////////////////////////////////
void Decoder::SetCompositeVideo( bool mode )
{
  if ( mode == true )
  {
    // composite video
    decFieldCOMP = decFieldODD_COMP = Off;
    Decoder::SetChromaADC( false );  // disable chroma ADC
    Decoder::SetLumaNotchFilter( true );  // enable luma notch filter
  }
  else
  {
    // Y/C Component video
    decFieldCOMP = decFieldODD_COMP = On;
    Decoder::SetChromaADC( true );  // enable chroma ADC
    Decoder::SetLumaNotchFilter( false );  // disable luma notch filter
  }
}


/////////////////////////////////////////////////////////////////////////////
// Method:  bool Decoder::IsCompositeVideo( void )
// Purpose: Check if selected composite or Y/C component video
// Input:   None
// Output:  None
// Return:  true = Composite; false = Y/C Component
/////////////////////////////////////////////////////////////////////////////
bool Decoder::IsCompositeVideo( void )
{
  return (decFieldCOMP == Off) ? true : false;  // reverse
}

/////////////////////////////////////////////////////////////////////////////
// Method:  void Decoder::SetLumaDecimation( bool mode )
// Purpose: Enable/Disable luma decimation filter
// Input:   bool mode - true = Enable; false = Disable
// Output:  None
// Return:  None
/////////////////////////////////////////////////////////////////////////////
void Decoder::SetLumaDecimation( bool mode )
{
   // value of 0 turns the decimation on
   decFieldLDEC = decFieldODD_LDEC = (mode == true) ? 0 : 1;
}


/////////////////////////////////////////////////////////////////////////////
// Method:  bool Decoder::IsLumaDecimation( void )
// Purpose: Check if luma decimation filter is enable or disable
// Input:   None
// Output:  None
// Return:  true = Enable; false = Disable
/////////////////////////////////////////////////////////////////////////////
bool Decoder::IsLumaDecimation( void )
{
  return (decFieldLDEC == Off) ? true : false;  // reverse
}


/////////////////////////////////////////////////////////////////////////////
// Method:  void Decoder::SetCbFirst( bool mode )
// Purpose: Control whether the first pixel of a line is a Cb or Cr pixel
// Input:   bool mode - true = Normal Cb, Cr order, false = Invert Cb, Cr order
// Output:  None
// Return:  None
/////////////////////////////////////////////////////////////////////////////
void Decoder::SetCbFirst( bool mode )
{
  decFieldCBSENSE = decFieldODD_CBSENSE = (mode == false) ? On : Off;  // reverse
}


/////////////////////////////////////////////////////////////////////////////
// Method:  bool Decoder::IsCbFirst( void )
// Purpose: Check if the first pixel of a line is a Cb or Cr pixel
// Input:   None
// Output:  None
// Return:  true = Normal Cb, Cr order, false = Invert Cb, Cr order
/////////////////////////////////////////////////////////////////////////////
bool Decoder::IsCbFirst( void )
{
  return (decFieldCBSENSE == Off) ? true : false;  // reverse
}


//===== Luma Gain register (CON_MSB, CONTRAST_LO) ===========================

/////////////////////////////////////////////////////////////////////////////
// Method:  ErrorCode Decoder::SetContrast( int param )
// Purpose: Set video contrast
// Input:   int param - parameter value (0-255; default 128)
// Output:  None
// Return:  Fail if error in parameter, else Success
// Note:    See IsAdjustContrast() for detailed description of the contrast
//          adjustment calculation
/////////////////////////////////////////////////////////////////////////////
ErrorCode Decoder::SetContrast( int param )
{
  if( m_param.OutOfRange( param ) )
    return Fail;

  bool adjustContrast = IsAdjustContrast(); // is contrast need to be adjusted

  // if adjust contrast is needed, make sure contrast reg value != 0
  if ( adjustContrast )
    m_regContrast = CRegInfo( 1, ConMax, ConDef );

  // perform mapping to our range
  int mapped;
  if ( Mapping( param, m_param, &mapped, m_regContrast ) == Fail )
    return Fail;

  m_conParam = (WORD)param;

  // calculate contrast
  DWORD value =  (DWORD)0x1FF * (DWORD)mapped;
  value /= (DWORD)m_regContrast.Max();
  if ( value > 0x1FF )
    value = 0x1FF;

  // contrast is set by a 9 bit value; set LSB first
  decRegCONTRAST_LO = value;

  // now set the Miscellaneous Control Register CON_V_MSB to the 9th bit value
  decFieldCON_MSB = decFieldODD_CON_MSB = ( (value & 0x0100) ? On : Off );

  // perform adjustment of brightness register if adjustment is needed
  if ( adjustContrast )
  {
    regContrast = (WORD)value;    // contrast value

    long A = (long)regBright * (long)0xD8;
    long B = 64 * ( (long)0xD8 - (long)regContrast );
    long temp = 0x00;
    if ( regContrast != 0 )  // already limit contrast > zero; just in case here
       temp = ( ( A + B ) / (long)regContrast );
    temp = ( temp < -128 ) ? -128 : ( ( temp > 127 ) ? 127 : temp );
    decRegBRIGHT = (BYTE)temp;

  }

  return Success;
}


/////////////////////////////////////////////////////////////////////////////
// Method:  int Decoder::GetContrast( void )
// Purpose: Obtain contrast value
// Input:   None
// Output:  None
// Return:  Contrast parameter (0-255)
/////////////////////////////////////////////////////////////////////////////
int Decoder::GetContrast( void )
{
  return m_conParam;
}


//===== Chroma Gain register (SAT_U_MSB, SAT_V_MSB, SAT_U_LO, SAT_V_LO) =====

/////////////////////////////////////////////////////////////////////////////
// Method:  ErrorCode Decoder::SetSaturation( int param )
// Purpose: Set color saturation by modifying U and V values
// Input:   int param - parameter value (0-255; default 128)
// Output:  None
// Return:  Fail if error in parameter, else Success
/////////////////////////////////////////////////////////////////////////////
ErrorCode Decoder::SetSaturation( int param )
{
  if( m_param.OutOfRange( param ) )
    return Fail;

  // color saturation is controlled by two nine bit values:
  // ChromaU & ChromaV
  // To maintain normal color balance, the ratio between the 2 register
  // values should be kept at the power-up default ratio

  // Note that U & V values for NTSC and PAL are the same, SECAM is different

  WORD nominalNTSC_U = 0xFE;     // nominal value (i.e. 100%) for NTSC/PAL
  WORD nominalNTSC_V = 0xB4;
  WORD nominalSECAM_U = 0x87;    // nominal value (i.e. 100%) for SECAM
  WORD nominalSECAM_V = 0x85;

  CRegInfo regSat;               // selected saturation register; NTSC/PAL or SECAM
  WORD nominal_U, nominal_V;     // selected nominal U and V value; NTSC/PAL or SECAM

  // select U & V values of either NTSC/PAL or SECAM to be used for calculation
  if ( GetVideoFormat() == VFormat_SECAM )
  {
    nominal_U = nominalSECAM_U;
    nominal_V = nominalSECAM_V;
    regSat = m_regSaturationSECAM;
  }
  else
  {
    nominal_U = nominalNTSC_U;
    nominal_V = nominalNTSC_V;
    regSat = m_regSaturationNTSC;
  }

  // perform mapping to our range
  int mapped;
  if ( Mapping( param, m_param, &mapped, regSat ) == Fail )
    return Fail;

  m_satParam = (WORD)param;

  WORD max_nominal = max( nominal_U, nominal_V );

  // calculate U and V values
  WORD Uvalue = (WORD) ( (DWORD)mapped * (DWORD)nominal_U / (DWORD)max_nominal );
  WORD Vvalue = (WORD) ( (DWORD)mapped * (DWORD)nominal_V / (DWORD)max_nominal );

  // set U
  decRegSAT_U_LO = Uvalue;

  // now set the Miscellaneous Control Register SAT_U_MSB to the 9th bit value
  decFieldSAT_U_MSB = decFieldODD_SAT_U_MSB = ( (Uvalue & 0x0100) ? On : Off );

  // set V
  decRegSAT_V_LO = Vvalue;

  // now set the Miscellaneous Control Register SAT_V_MSB to the 9th bit value
  decFieldSAT_V_MSB = decFieldODD_SAT_V_MSB = ( (Vvalue & 0x0100) ? On : Off );

  return Success;
}


/////////////////////////////////////////////////////////////////////////////
// Method:  int Decoder::GetSaturation( void )
// Purpose: Obtain saturation value
// Input:   None
// Output:  None
// Return:  Saturation parameter (0-255)
/////////////////////////////////////////////////////////////////////////////
int Decoder::GetSaturation( void )
{
  return m_satParam;
}


//===== Hue Control register (HUE) ==========================================

/////////////////////////////////////////////////////////////////////////////
// Method:  ErrorCode Decoder::SetHue( int param )
// Purpose: Set video hue
// Input:   int param - parameter value (0-255; default 128)
// Output:  None
// Return:  Fail if error in parameter, else Success
/////////////////////////////////////////////////////////////////////////////
ErrorCode Decoder::SetHue( int param )
{
  if( m_param.OutOfRange( param ) )
    return Fail;

  // perform mapping to our range
  int mapped;
  if ( Mapping( param, m_param, &mapped, m_regHue ) == Fail )
    return Fail;

  m_hueParam = (WORD)param;

  int value = (-128 * mapped) / m_regHue.Max();

  if (value > 127)
    value = 127;
  else if (value < -128)
    value = -128;

  decRegHUE = value;

  return Success;
}


/////////////////////////////////////////////////////////////////////////////
// Method:  int Decoder::GetHue( void )
// Purpose: Obtain hue value
// Input:   None
// Output:  None
// Return:  Hue parameter (0-255)
/////////////////////////////////////////////////////////////////////////////
int Decoder::GetHue( void )
{
  return m_hueParam;
}


//===== SC Loop Control register (E_SCLOOP, O_SCLOOP) =======================

/////////////////////////////////////////////////////////////////////////////
// Method:  void Decoder::SetChromaAGC( bool mode )
// Purpose: Enable/Disable Chroma AGC compensation
// Input:   bool mode - true = Enable, false = Disable
// Output:  None
// Return:  None
/////////////////////////////////////////////////////////////////////////////
void Decoder::SetChromaAGC( bool mode )
{
  decFieldCAGC = decFieldODD_CAGC = (mode == false) ? Off : On;
}


/////////////////////////////////////////////////////////////////////////////
// Method:  bool Decoder::IsChromaAGC( void )
// Purpose: Check if Chroma AGC compensation is enable or disable
// Input:   None
// Output:  None
// Return:  true = Enable, false = Disable
/////////////////////////////////////////////////////////////////////////////
bool Decoder::IsChromaAGC( void )
{
  return (decFieldCAGC == On) ? true : false;
}


/////////////////////////////////////////////////////////////////////////////
// Method:  void Decoder::SetLowColorAutoRemoval( bool mode )
// Purpose: Enable/Disable low color detection and removal
// Input:   bool mode - true = Enable, false = Disable
// Output:  None
// Return:  None
/////////////////////////////////////////////////////////////////////////////
void Decoder::SetLowColorAutoRemoval( bool mode )
{
  decFieldCKILL = decFieldODD_CKILL = (mode == false) ? Off : On;
}


/////////////////////////////////////////////////////////////////////////////
// Method:  bool Decoder::IsLowColorAutoRemoval( void )
// Purpose: Check if low color detection and removal is enable or disable
// Input:   None
// Output:  None
// Return:  true = Enable, false = Disable
/////////////////////////////////////////////////////////////////////////////
bool Decoder::IsLowColorAutoRemoval( void )
{
  return (decFieldCKILL == On) ? true : false;
}


/////////////////////////////////////////////////////////////////////////////
// Method:  ErrorCode Decoder::SetHorizontalFilter( HorizFilter hFilter )
// Purpose: Control the configuration of the optional 6-tap Horizontal Low-Pass filter
// Input:   HoriFilter hFilter:
//            Auto Format - HFilter_AutoFormat
//            CIF         - HFilter_CIF
//            QCIF        - HFilter_QCIF
//            ICON        - HFilter_ICON
// Output:  None
// Return:  Fail if error in parameter, else Success
/////////////////////////////////////////////////////////////////////////////
ErrorCode Decoder::SetHorizontalFilter( HorizFilter hFilter )
{
  if ( (hFilter < HFilter_AutoFormat) ||
       (hFilter > HFilter_ICON) )
    return Fail;

  decFieldHFILT = decFieldODD_HFILT = hFilter;
  return Success;
}


/////////////////////////////////////////////////////////////////////////////
// Method:  int Decoder::GetHorizontalFilter( void )
// Purpose: Get the configuration of the optional 6-tap Horizontal Low-Pass filter
// Input:   None
// Output:  None
// Return:  Which filter is using:
//            Auto Format - HFilter_AutoFormat
//            CIF         - HFilter_CIF
//            QCIF        - HFilter_QCIF
//            ICON        - HFilter_ICON
/////////////////////////////////////////////////////////////////////////////
int Decoder::GetHorizontalFilter( void )
{
  return ((int)decFieldHFILT);
}


//===== Output Format register (OFORM) ======================================

/////////////////////////////////////////////////////////////////////////////
// Method:  void Decoder::SetFullOutputRange( bool mode )
// Purpose: Enable/Disable full output range
// Input:   bool mode - true = Enable, false = Disable
// Output:  None
// Return:  None
/////////////////////////////////////////////////////////////////////////////
void Decoder::SetFullOutputRange( bool mode )
{
  decFieldRANGE = (mode == false) ? Off : On;
}


/////////////////////////////////////////////////////////////////////////////
// Method:  bool Decoder::IsFullOutputRange( void )
// Purpose: Check if full output range is enable or disable
// Input:   None
// Output:  None
// Return:  true = Enable, false = Disable
/////////////////////////////////////////////////////////////////////////////
bool Decoder::IsFullOutputRange( void )
{
  return (decFieldRANGE == On) ? true : false;
}


/////////////////////////////////////////////////////////////////////////////
// Method:  ErrorCode Decoder::SetLumaCoring( CoringLevel cLevel )
// Purpose: Set luminance level such that luminance signal is truncated to zero
//          if below this level
// Input:   CoringLevel cLevel -
//            Coring_None: no coring
//            Coring_8:    8
//            Coring_16:   16
//            Coring_32:   32
// Output:  None
// Return:  Fail if error in parameter, else Success
/////////////////////////////////////////////////////////////////////////////
ErrorCode Decoder::SetLumaCoring( CoringLevel cLevel )
{
  if ( ( cLevel < Coring_None) || ( cLevel > Coring_32 ) )
    return Fail;

  decFieldCORE = cLevel;
  return Success;
}


/////////////////////////////////////////////////////////////////////////////
// Method:  int Decoder::GetLumaCoring( void )
// Purpose: Get luminance level such that luminance signal is truncated to zero
//          if below this level
// Input:   None
// Output:  None
// Return:  Luma coring level -
//            Coring_None: no coring
//            Coring_8:    8
//            Coring_16:   16
//            Coring_32:   32
/////////////////////////////////////////////////////////////////////////////
int Decoder::GetLumaCoring( void )
{
  return ((int)decFieldCORE);
}


//===== Vertical Scaling register (E_VSCALE_HI, O_VSCALE_HI) ================

/////////////////////////////////////////////////////////////////////////////
// Method:  void Decoder::SetChromaComb( bool mode )
// Purpose: Enable/Disable chroma comb
// Input:   bool mode - true = Enable, false = Disable
// Output:  None
// Return:  None
/////////////////////////////////////////////////////////////////////////////
void Decoder::SetChromaComb( bool mode )
{
  decFieldCOMB = (mode == false) ? Off : On;
}

/////////////////////////////////////////////////////////////////////////////
// Method:  bool Decoder::IsChromaComb( void )
// Purpose: Check if chroma comb is enable or disable
// Input:   None
// Output:  None
// Return:  true = Enable, false = Disable
/////////////////////////////////////////////////////////////////////////////
bool Decoder::IsChromaComb( void )
{
  return (decFieldCOMB == On) ? true : false;
}
   
//===== AGC Delay register (ADELAY) =========================================

/////////////////////////////////////////////////////////////////////////////
// Method:  void Decoder::SetAGCDelay( BYTE value )
// Purpose: Set AGC Delay register
// Input:   Value to be set to
// Output:  None
// Return:  None
// NOTE:    This function set the AGC Delay register to the specified value.
//          No calculation is involved.
/////////////////////////////////////////////////////////////////////////////
void Decoder::SetAGCDelay( BYTE value )
{
  // [!!!] this was considered suspicious by someone...
  //#pragma message ("IS THIS GOOD?? ")
  decRegADELAY = value;
}


/////////////////////////////////////////////////////////////////////////////
// Method:  int Decoder::GetAGCDelay( void )
// Purpose: Get AGC Delay register
// Input:   None
// Output:  None
// Return:  Register value
/////////////////////////////////////////////////////////////////////////////
int Decoder::GetAGCDelay( void )
{
  return ((int)decRegADELAY);
}


//===== Burst Delay register (BDELAY) =========================================

/////////////////////////////////////////////////////////////////////////////
// Method:  void Decoder::SetBurstDelay( BYTE value )
// Purpose: Set Burst Delay register
// Input:   Value to be set to
// Output:  None
// Return:  None
// NOTE:    This function set the Burst Delay register to the specified value.
//          No calculation is involved.
/////////////////////////////////////////////////////////////////////////////
void Decoder::SetBurstDelay( BYTE value )
{
  // [!!!] this was considered suspicious by someone...
  //#pragma message ("IS THIS GOOD?? ")
  decRegBDELAY = value;
}


/////////////////////////////////////////////////////////////////////////////
// Method:  int Decoder::GetBurstDelay( void )
// Purpose: Get Burst Delay register
// Input:   None
// Output:  None
// Return:  Register value
/////////////////////////////////////////////////////////////////////////////
int Decoder::GetBurstDelay( void )
{
  return ((int)decRegBDELAY);
}


//===== ADC Interface register (ADC) =========================================

/////////////////////////////////////////////////////////////////////////////
// Method:  void Decoder::SetAnalogThresholdLow( bool mode )
// Purpose: Define high/low threshold level below which SYNC signal can be detected
// Input:   bool mode - true = low threshold (~75mV), false = high threshold (~125mV)
// Output:  None
// Return:  None
/////////////////////////////////////////////////////////////////////////////
void Decoder::SetAnalogThresholdLow( bool mode )
{
  decFieldSYNC_T = (mode == false) ? Off : On;
}


/////////////////////////////////////////////////////////////////////////////
// Method:  bool Decoder::IsAnalogThresholdLow( void )
// Purpose: Check if high or low threshold level below which SYNC signal can be detected
// Input:   None
// Output:  None
// Return:  true = low threshold (~75mV), false = high threshold (~125mV)
/////////////////////////////////////////////////////////////////////////////
bool Decoder::IsAnalogThresholdLow( void )
{
  return (decFieldSYNC_T == On) ? true : false;
}


/////////////////////////////////////////////////////////////////////////////
// Method:  void Decoder::SetAGCFunction( bool mode )
// Purpose: Enable/Disable AGC function
// Input:   bool mode - true = Enable, false = Disable
// Output:  None
// Return:  None
/////////////////////////////////////////////////////////////////////////////
void Decoder::SetAGCFunction( bool mode )
{
  decFieldAGC_EN = (mode == false) ? On : Off; // reverse
}


/////////////////////////////////////////////////////////////////////////////
// Method:  bool Decoder::IsAGCFunction( void )
// Purpose: Check if AGC function is enable or disable
// Input:   None
// Output:  None
// Return:  true = Enable, false = Disable
/////////////////////////////////////////////////////////////////////////////
bool Decoder::IsAGCFunction( void )
{
  return (decFieldAGC_EN == Off) ? true : false;   // reverse
}


/////////////////////////////////////////////////////////////////////////////
// Method:  void Decoder::PowerDown( bool mode )
// Purpose: Select normal or shut down clock operation
// Input:   bool mode - true = shut down, false = normal operation
// Output:  None
// Return:  None
/////////////////////////////////////////////////////////////////////////////
void Decoder::PowerDown( bool mode )
{
  decFieldCLK_SLEEP = (mode == false) ? Off : On;
}


/////////////////////////////////////////////////////////////////////////////
// Method:  bool Decoder::IsPowerDown( void )
// Purpose: Check if clock operation has been shut down
// Input:   None
// Output:  None
// Return:  true = shut down, false = normal operation
/////////////////////////////////////////////////////////////////////////////
bool Decoder::IsPowerDown( void )
{
  return (decFieldCLK_SLEEP == On) ? true : false;
}


/////////////////////////////////////////////////////////////////////////////
// Method:  void Decoder::SetLumaADC( bool mode )
// Purpose: Select normal or sleep Y ADC operation
// Input:   bool mode - true = normal, false = sleep
// Output:  None
// Return:  None
/////////////////////////////////////////////////////////////////////////////
void Decoder::SetLumaADC( bool mode )
{
  decFieldY_SLEEP = (mode == false) ? On : Off; // reverse
}


/////////////////////////////////////////////////////////////////////////////
// Method:  bool Decoder::IsLumaADC( void )
// Purpose: Check if Y ADC operation is in normal operation or sleeping
// Input:   None
// Output:  None
// Return:  true = normal, false = sleep
/////////////////////////////////////////////////////////////////////////////
bool Decoder::IsLumaADC( void )
{
  return (decFieldY_SLEEP == Off) ? true : false;  // reverse
}


/////////////////////////////////////////////////////////////////////////////
// Method:  void Decoder::SetChromaADC( bool mode )
// Purpose: Select normal or sleep C ADC operation
// Input:   bool mode - true = normal, false = sleep
// Output:  None
// Return:  None
/////////////////////////////////////////////////////////////////////////////
void Decoder::SetChromaADC( bool mode )
{
  decFieldC_SLEEP = (mode == false) ? On : Off; // reverse
}


/////////////////////////////////////////////////////////////////////////////
// Method:  bool Decoder::IsChromaADC( void )
// Purpose: Check if C ADC operation is in normal operation or sleeping
// Input:   None
// Output:  None
// Return:  true = normal, false = sleep
/////////////////////////////////////////////////////////////////////////////
bool Decoder::IsChromaADC( void )
{
  return (decFieldC_SLEEP == Off) ? true : false; // reverse
}


/*^^////////////////////////////////////////////////////////////////////////////
// Method:  void Decoder::SetAdaptiveAGC( bool mode )
// Purpose: Set adaptive or non-adaptive AGC operation
// Input:   bool mode - true = Adaptive, false = Non-adaptive
// Output:  None
// Return:  None
*////////////////////////////////////////////////////////////////////////////
void Decoder::SetAdaptiveAGC( bool mode )
{
   decFieldCRUSH = (mode == false) ? Off : On;
}


/////////////////////////////////////////////////////////////////////////////
// Method:  bool Decoder::IsAdaptiveAGC( void )
// Purpose: Check if adaptive or non-adaptive AGC operation is selected
// Input:   None
// Output:  None
// Return:  true = Adaptive, false = Non-adaptive
/////////////////////////////////////////////////////////////////////////////
bool Decoder::IsAdaptiveAGC( void )
{
  return (decFieldCRUSH == On) ? true : false;
}


//===== Software Reset register (SRESET) ====================================

/////////////////////////////////////////////////////////////////////////////
// Method:  void Decoder::SoftwareReset( void )
// Purpose: Perform software reset; all registers set to default values
// Input:   None
// Output:  None
// Return:  None
/////////////////////////////////////////////////////////////////////////////
void Decoder::SoftwareReset( void )
{
  decRegSRESET = 0x00;  // write any value will do
}

/////////////////////////////////////////////////////////////////////////////
// Method:  void Decoder::SelectCrystal( char useCrystal )
// Purpose: Select correct crystal for NTSC or PAL
// Input:   char useCrystal - 'N' for NTSC; 'P' for PAL
// Output:  None
// Return:  None
// NOTE:    Assume at most 2 crystals installed in hardware. i.e. 1 for NTSC
//          and the other for PAL/SECAM.
//          If there is only 1 crystal exists (which must be crystal XT0),
//          do nothing since it is already selected.
/////////////////////////////////////////////////////////////////////////////
void Decoder::SelectCrystal( int useCrystal )
{
   if ( Xtals_ [0] && Xtals_ [1] ) {           

      // compare with what we want to use
      if ( (  IsCrystal0Selected() && ( Xtals_ [0] != (DWORD) useCrystal ) ) ||
           ( !IsCrystal0Selected() && ( Xtals_ [0] == (DWORD) useCrystal ) ) )
         // need to change crystal
         SetCrystal( IsCrystal0Selected() ? Crystal_XT1 : Crystal_XT0 );
   }
}

/////////////////////////////////////////////////////////////////////////////
// Method:  ErrorCode Decoder::Mapping( int fromValue, CRegInfo fromRange,
//                                           int * toValue, CRegInfo toRange )
// Purpose: Map a value in certain range to a value in another range
// Input:   int fromValue - value to be mapped from
//          CRegInfo fromRange - range of value mapping from
//          CRegInfo toRange   - range of value mapping to
// Output:  int * toValue - mapped value
// Return:  Fail if error in parameter, else Success
// Comment: No range checking is performed here. Assume parameters are in
//          valid ranges.
//          The mapping function does not assume default is always the mid
//          point of the whole range. It only assumes default values of the
//          two ranges correspond to each other.
//
// The mapping formula is:
//
//   For fromRange.Min() <= fromValue <= fromRange.Default():
//
//  fromValue * (toRange.Default() - toRange.Min())
//  ------------------------------------------------ + toRange.Min()
//        fromRange.Default() - fromRange.Min()
//
//   For fromRange.Default() < fromValue <= fromRange.Max():
//
//  (fromValue - fromRange.Default()) * (toRange.Max() - toRange.Default())
//  --------------------------------------------------------------------- + toRange.Default()
//                       fromRange.Max() - fromRange.Default()
//
////////////////////////////////////////////////////////////////////////////
ErrorCode Decoder::Mapping( int fromValue, CRegInfo fromRange,
   int * toValue, CRegInfo toRange )
{
   // calculate intermediate values
   DWORD ToLowRange    = toRange.Default() - toRange.Min();
   DWORD FromLowRange  = fromRange.Default() - fromRange.Min();
   DWORD ToHighRange   = toRange.Max() - toRange.Default();
   DWORD FromHighRange = fromRange.Max() - fromRange.Default();

   // prevent divide by zero
   if ( !FromLowRange || !FromHighRange )
      return ( Fail );

   // perform mapping
   if ( fromValue <= fromRange.Default() )
      *toValue = (int) (DWORD)fromValue * ToLowRange / FromLowRange +
         (DWORD)toRange.Min();
   else
      *toValue = (int) ( (DWORD)fromValue - (DWORD)fromRange.Default() ) *
         ToHighRange / FromHighRange + (DWORD)toRange.Default();

   return ( Success );
}


/////////////////////////////////////////////////////////////////////////////
// Method:  bool Decoder::IsAdjustContrast( void )
// Purpose: Check registry key whether adjust contrast is needed
// Input:   None
// Output:  None
// Return:  true = adjust contrast, false = don't adjust contrast
// Note:    If adjust contrast is turn on, brightness register value will be
//          adjusted such that it remains a constant after the calculation
//          performed by the hardware.
//
//          The formula is:
//             To keep brightness constant (i.e. not affect by changing contrast)
//             set brightness to B/(C/C0)
//             where B is value of brightness before adjustment
//                   C is contrast value
//                   C0 is nominal contrast value (0xD8)
//
//             To adjust the contrast level such that it is at the middle of
//             black and white: set brightness to (B * C0 + 64 * (C0 - C))/C
//             (this is what Intel wants)
//
//             Currently there is still limitation of how much adjustment
//             can be performed. For example, if brightness is already high,
//             (i.e. brightness reg value close to 0x7F), lowering contrast
//             until a certain level will have no adjustment effect on brightness.
//             In fact, it would even bring down brightness to darkness.
//
//             Example 1: if brightness is at nominal value (0x00), contrast can
//                        only go down to 0x47 (brightness adjustment is already
//                        at max of 0x7F) before it starts affecting brightness
//                        which takes it darkness.
//             Example 2: if brightness is at nominal value (0x00), contrast can
//                        go all the way up with brightness adjusted correctly.
//                        However, the max adjustment used is only 0xDC and
//                        the max adjustment we can use is 0x&F.
//             Example 3: if brightness is at max (0x7F), lowering contrast
//                        cannot be compensated by adjusting brightness anymore.
//                        The result is gradually taking brightness to darkness.
//             Example 4: if brightness is at min (0x80), lowering contrast has
//                        no visual effect. Bringing contrast to max is using
//                        0xA5 in brightness for compensation.
//
//             One last note, the center is defined as the middle of the
//             gamma adjusted luminance level. Changing it to use the middle of
//             the linear (RGB) luminance level is possible.
/////////////////////////////////////////////////////////////////////////////
bool Decoder::IsAdjustContrast( void )
{
   return false;
/*
   // locate adjust contrast information in the registry
   // the key to look for in registry is:
   //    Bt848\AdjustContrast - 0 = don't adjust contrast
   //                           1 = adjust contrast

   VRegistryKey vkey( PRK_CLASSES_ROOT, "Bt848" );

   // make sure the key exists
   if ( vkey.lastError() == ERROR_SUCCESS )
   {
      char * adjustContrastKey = "AdjustContrast";
      char   key[3];
      DWORD  keyLen = 2;    // need only first char; '0' or '1'

      // get the registry value and check it, if exist
      if ( ( vkey.getSubkeyValue( adjustContrastKey, key, (DWORD *)&keyLen ) ) &&
           ( key[0] == '1' ) )
         return ( true );
   }
   return ( false );
*/
}

/* Function: SelectFlags
 * Purpose: Selects video standard flags
 * Input: val: DWORD - value to switch on
 *   flags: LONG & - flags fo here
 * Output: None
 */
void SelectFlags( DWORD val, LONG &flags )
{
   switch ( val ) {
   case NTSC_xtal:
      flags |= KS_AnalogVideo_NTSC_M;
      break;
   case PAL_xtal:
      flags |= KS_AnalogVideo_PAL_M   | KS_AnalogVideo_PAL_N    |
               KS_AnalogVideo_PAL_B   | KS_AnalogVideo_PAL_D    |
               KS_AnalogVideo_PAL_H   | KS_AnalogVideo_PAL_I    |
               KS_AnalogVideo_SECAM_B | KS_AnalogVideo_SECAM_D  |
               KS_AnalogVideo_SECAM_G | KS_AnalogVideo_SECAM_H  |
               KS_AnalogVideo_SECAM_K | KS_AnalogVideo_SECAM_K1 |
               KS_AnalogVideo_SECAM_L;
      break;
   }
}

/* Method: Decoder::GetSupportedStandards
 * Purpose: Returns supported standards
 * Input: None
 * Output: LONG: standard flags
 */
LONG Decoder::GetSupportedStandards()
{
   LONG standards =0;

   SelectFlags( Xtals_ [0], standards );
   SelectFlags( Xtals_ [1], standards );
   return standards;
}
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\drivers\wdm\capture\mini\bt848\constr.h ===
// $Header: G:/SwDev/WDM/Video/bt848/rcs/Constr.h 1.3 1998/04/29 22:43:31 tomz Exp $

#ifndef __CONSTR_H
#define __CONSTR_H

#define CONSTRUCT_REGISTERS \
decRegSTATUS ( ( (0x00 + 0) * 4) + 0, RW ) ,\
decFieldPRES( decRegSTATUS, 7, 1, RW) ,\
decFieldHLOC( decRegSTATUS, 6, 1, RW) ,\
decFieldEVENFIELD( decRegSTATUS, 5, 1, RW) ,\
decFieldNUML( decRegSTATUS, 4, 1, RW) ,\
decFieldCSEL( decRegSTATUS, 3, 1, RW) ,\
decFieldSTATUS_RES( decRegSTATUS, 2, 1, RW) ,\
decFieldLOF( decRegSTATUS, 1, 1, RW) ,\
decFieldCOF( decRegSTATUS, 0, 1, RW) ,\
decRegIFORM ( ( (0x01 + 0) * 4) + 0, RW ) ,\
decFieldHACTIVE( decRegIFORM, 7, 1, RW) ,\
decFieldMUXSEL( decRegIFORM, 5, 2, RW) ,\
decFieldXTSEL( decRegIFORM, 3, 2, RW) ,\
decFieldFORMAT( decRegIFORM, 0, 3, RW) ,\
decRegTDEC ( ( (0x02 + 0) * 4) + 0, RW ) ,\
decFieldDEC_FIELD( decRegTDEC, 7, 1, RW) ,\
decFieldDEC_FIELDALIGN( decRegTDEC, 6, 1, RW) ,\
decFieldDEC_RAT( decRegTDEC, 0, 6, RW) ,\
decRegBRIGHT ( ( (0x0A + 0) * 4) + 0, RW ) ,\
decRegMISCCONTROL ( ( (0x0B + 0) * 4) + 0, RW ) ,\
decFieldLNOTCH( decRegMISCCONTROL, 7, 1, RW) ,\
decFieldCOMP( decRegMISCCONTROL, 6, 1, RW) ,\
decFieldLDEC( decRegMISCCONTROL, 5, 1, RW) ,\
decFieldCBSENSE( decRegMISCCONTROL, 4, 1, RW) ,\
decFieldMISCCONTROL_RES( decRegMISCCONTROL, 3, 1, RW) ,\
decFieldCON_MSB( decRegMISCCONTROL, 2, 1, RW) ,\
decFieldSAT_U_MSB( decRegMISCCONTROL, 1, 1, RW) ,\
decFieldSAT_V_MSB( decRegMISCCONTROL, 0, 1, RW) ,\
decRegCONTRAST_LO ( ( (0x0C + 0) * 4) + 0, RW ) ,\
decRegSAT_U_LO ( ( (0x0D + 0) * 4) + 0, RW ) ,\
decRegSAT_V_LO ( ( (0x0E + 0) * 4) + 0, RW ) ,\
decRegHUE ( ( (0x0F + 0) * 4) + 0, RW ) ,\
decRegSCLOOP ( ( (0x10 + 0) * 4) + 0, RW ) ,\
decFieldCAGC( decRegSCLOOP, 6, 1, RW) ,\
decFieldCKILL( decRegSCLOOP, 5, 1, RW) ,\
decFieldHFILT( decRegSCLOOP, 3, 2, RW) ,\
decRegWC_UP( ( (0x11 + 0) * 4) + 0, RW ) ,\
decRegOFORM ( ( (0x12 + 0) * 4) + 0, RW ) ,\
decFieldRANGE( decRegOFORM, 7, 1, RW) ,\
decFieldCORE( decRegOFORM, 5, 2, RW) ,\
decRegVSCALE_HI ( ( (0x13 + 0) * 4) + 0, RW ) ,\
decFieldYCOMB( decRegVSCALE_HI, 7, 1, RW) ,\
decFieldCOMB( decRegVSCALE_HI, 6, 1, RW) ,\
decFieldINT( decRegVSCALE_HI, 5, 1, RW) ,\
decRegTEST ( ( (0x15 + 0) * 4) + 0, RW ) ,\
decRegADELAY ( ( (0x18 + 0) * 4) + 0, RW ) ,\
decRegBDELAY ( ( (0x19 + 0) * 4) + 0, RW ) ,\
decRegADC ( ( (0x1A + 0) * 4) + 0, RW ) ,\
decFieldSYNC_T( decRegADC, 5, 1, RW) ,\
decFieldAGC_EN( decRegADC, 4, 1, RW) ,\
decFieldCLK_SLEEP( decRegADC, 3, 1, RW) ,\
decFieldY_SLEEP( decRegADC, 2, 1, RW) ,\
decFieldC_SLEEP( decRegADC, 1, 1, RW) ,\
decFieldCRUSH( decRegADC, 0, 1, RW), \
decRegVTC ( ( (0x1B + 0) * 4) + 0, RW ) ,\
decFieldHSFMT( decRegVTC, 7, 1, RW) ,\
decRegWC_DN( ( (0x1E + 0) * 4) + 0, RW ) ,\
decRegSRESET ( ( (0x1F + 0) * 4) + 0, RW ) ,\
decRegODD_MISCCONTROL ( ( (0x0B + -0x03) * 4) + 0x8C, RW ) ,\
decFieldODD_LNOTCH( decRegODD_MISCCONTROL, 7, 1, RW) ,\
decFieldODD_COMP( decRegODD_MISCCONTROL, 6, 1, RW) ,\
decFieldODD_LDEC( decRegODD_MISCCONTROL, 5, 1, RW) ,\
decFieldODD_CBSENSE( decRegODD_MISCCONTROL, 4, 1, RW) ,\
decFieldODD_MISCCONTROL_RES( decRegODD_MISCCONTROL, 3, 1, RW) ,\
decFieldODD_CON_MSB( decRegODD_MISCCONTROL, 2, 1, RW) ,\
decFieldODD_SAT_U_MSB( decRegODD_MISCCONTROL, 1, 1, RW) ,\
decFieldODD_SAT_V_MSB( decRegODD_MISCCONTROL, 0, 1, RW) ,\
decRegODD_SCLOOP ( ( (0x10 + -0x03) * 4) + 0x8C, RW ) ,\
decFieldODD_CAGC( decRegODD_SCLOOP, 6, 1, RW) ,\
decFieldODD_CKILL( decRegODD_SCLOOP, 5, 1, RW) ,\
decFieldODD_HFILT( decRegODD_SCLOOP, 3, 2, RW) ,\
decRegODD_VSCALE_HI ( ( (0x13 + -0x03) * 4) + 0x8C, RW ) ,\
decFieldODD_YCOMB( decRegODD_VSCALE_HI, 7, 1, RW) ,\
decFieldODD_COMB( decRegODD_VSCALE_HI, 6, 1, RW) ,\
decFieldODD_INT( decRegODD_VSCALE_HI, 5, 1, RW) ,\
decRegODD_VTC ( ( (0x1B + -0x03) * 4) + 0x8C, RW ) ,\
decFieldODD_HSFMT( decRegODD_VTC, 7, 1, RW)

#endif   // __CONSTR_H
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\drivers\wdm\capture\mini\bt848\decoder.h ===
// $Header: G:/SwDev/WDM/Video/bt848/rcs/Decoder.h 1.2 1998/04/29 22:43:32 tomz Exp $

#ifndef __DECODER_H
#define __DECODER_H

#include "regField.h"
#include "viddefs.h"
#include "retcode.h"

const int PAL_xtal  = 35;
const int NTSC_xtal = 28;

/////////////////////////////////////////////////////////////////////////////
// CLASS CRegInfo
//
// Description:
//    Provides min, max, and default values for a register. To use this class,
//    user will declare an object of this class and provide min, max and default
//    values of the register.
//
// Attributes:
//    int intMin - minumum value
//    int intMax - maximum value
//    int intDefault - default value
//
// Methods:
//    Min() : return minimum value of the register
//    Max() : return maximum value of the register
//    Default(): return default value of the register
//    OutOfRange() : check if an value is out of range
//
/////////////////////////////////////////////////////////////////////////////
class CRegInfo
{
   int intMin;       // minumum value
   int intMax;       // maximum value
   int intDefault;   // default value

public:
   CRegInfo( void )
   {
      intMin = 0;
      intMax = 0;
      intDefault = 0;
   }

   CRegInfo( int min, int max, int def )
   {
      intMin = min;
      intMax = max;
      intDefault = def;
   }

   // return min, max and default value of a register
   inline int Min( void ) const { return intMin; }
   inline int Max( void ) const { return intMax; }
   inline int Default( void ) const { return intDefault; }

   // check if an value is out of range of a register
   inline bool OutOfRange( int x )
   {
      if( (x > intMax) || (x < intMin) )
         return true;
      return false;
   }
};


/////////////////////////////////////////////////////////////////////////////
// CLASS Decoder
//
// Description:
//    This class encapsulates the register fields in the decoder portion of
//    the Bt848.
//    A complete set of functions are developed to manipulate all the
//    register fields in the decoder for the Bt848.
//    For Read-Write register field, "Set..." function is provided to modify
//    the content of the reigster field. And either "Get..." (for more
//    than 1 bit) or "Is..." (for 1 bit) function is provided to obtain the
//    value of the register field.
//    For Read-Only register field, only "Get..." (for more than 1 bit) or
//    "Is..." (for 1 bit) function is provided to obtain the content of the
//    register field.
//    When there are odd-field complements to the even-field register field,
//    same value is set to both odd and even register fields.
//    Several direct register content modifying/retrieval functions are
//    implemented for direct access to the register contents. They were
//    originally developed for testing purpose only. They are retained in the
//    class for convenience only and usage of these functions must be very cautious.
//
// Methods:
//    See below
//
// Note: 1) Scaling registers are not implemented.
//       2) Odd-fields are set to the same value as the even-field registers
/////////////////////////////////////////////////////////////////////////////

class Decoder
{
protected:
	#include "Declare.h"

   // used for checking if parameter out of register's range
	CRegInfo m_regHue, m_regSaturationNTSC, m_regSaturationSECAM,
            m_regContrast,	m_regBrightness;

   // used for checking parameter range
   CRegInfo m_param;

   // value set to after calculations
	WORD m_satParam, m_conParam, m_hueParam, m_briParam;

   // to be used to adjust contrast
   int  regBright;      // brightness register value before adjustment
   WORD regContrast;    // contrast register value before adjustment
   DWORD Xtals_ [2];
public:
   // constructor and destructor
	Decoder( DWORD *xtals );
	~Decoder();

   // Device Status register (DSTATUS)
   virtual BYTE      GetDeviceStatusReg( void );
   virtual bool      IsVideoPresent( void );
   virtual bool      IsDeviceInHLock( void );
   virtual bool      IsEvenField( void );
   virtual bool      Is525LinesVideo( void );
   virtual bool      IsCrystal0Selected( void );
   virtual bool      IsLumaOverflow( void );
   virtual void      ResetLumaOverflow( void );
   virtual bool      IsChromaOverflow( void );
   virtual void      ResetChromaOverflow( void );

   // Input Format register (IFORM)
   virtual ErrorCode SetVideoInput( Connector );
   virtual int       GetVideoInput( void );
   virtual ErrorCode SetCrystal( Crystal );
   virtual int       GetCrystal( void );
   virtual ErrorCode SetVideoFormat( VideoFormat );
   virtual int       GetVideoFormat( void );

   // Temporal Decimation register (TDEC)
   virtual ErrorCode SetRate( bool, VidField, int );

   // Brightness Control register (BRIGHT)
   virtual ErrorCode SetBrightness( int );
   virtual int       GetBrightness( void );

   // Miscellaneous Control register (E_CONTROL, O_CONTROL)
   virtual void      SetLumaNotchFilter( bool );
   virtual bool      IsLumaNotchFilter( void );
   virtual void      SetCompositeVideo( bool );
   virtual bool      IsCompositeVideo( void );
   virtual void      SetLumaDecimation( bool );
   virtual bool      IsLumaDecimation( void );
   virtual void      SetCbFirst( bool );
   virtual bool      IsCbFirst( void );

   // Luma Gain register (CON_MSB, CONTRAST_LO)
   virtual ErrorCode SetContrast( int );
   virtual int       GetContrast( void );

   // Chroma Gain register (SAT_U_MSB, SAT_V_MSB, SAT_U_LO, SAT_V_LO)
   virtual ErrorCode SetSaturation( int );
   virtual int       GetSaturation( void );

   // Hue Control register (HUE)
   virtual ErrorCode SetHue( int );
   virtual int       GetHue( void );

   // SC Loop Control register (E_SCLOOP, O_SCLOOP)
   virtual void      SetChromaAGC( bool );
   virtual bool      IsChromaAGC( void );
   virtual void      SetLowColorAutoRemoval( bool );
   virtual bool      IsLowColorAutoRemoval( void );
   virtual ErrorCode SetHorizontalFilter( HorizFilter );
   virtual int       GetHorizontalFilter( void );

   // Output Format register (OFORM)
   virtual void      SetFullOutputRange( bool );
   virtual bool      IsFullOutputRange( void );
   virtual ErrorCode SetLumaCoring( CoringLevel );
   virtual int       GetLumaCoring( void );

   // Vertical Scaling register (E_VSCALE_HI, O_VSCALE_HI)
   virtual void      SetChromaComb( bool );
   virtual bool      IsChromaComb( void );

   // AGC Delay register (ADELAY)
   virtual void      SetAGCDelay( BYTE );
   virtual int       GetAGCDelay( void );

   // Burst Delay register (BDELAY)
   virtual void      SetBurstDelay( BYTE );
   virtual int       GetBurstDelay( void );

   // ADC Interface register (ADC)
   virtual void      SetAnalogThresholdLow( bool );
   virtual bool      IsAnalogThresholdLow( void );
   virtual void      SetAGCFunction( bool );
   virtual bool      IsAGCFunction( void );
   virtual void      PowerDown( bool );
   virtual bool      IsPowerDown( void );
   virtual void      SetLumaADC( bool );
   virtual bool      IsLumaADC( void );
   virtual void      SetChromaADC( bool );
   virtual bool      IsChromaADC( void );
   virtual void      SetAdaptiveAGC( bool );
   virtual bool      IsAdaptiveAGC( void );

   // Software Reset register (SRESET)
   virtual void      SoftwareReset( void );

   virtual LONG      GetSupportedStandards();

protected:
   // mapping function
   virtual ErrorCode Mapping( int, CRegInfo, int *, CRegInfo );

   // check registry key value to determine if contrast should be adjusted
   virtual bool IsAdjustContrast( void );

private:
   void              SelectCrystal( int );

};

#endif // __DECODER_H
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\drivers\wdm\capture\mini\bt848\declare.h ===
// $Header: G:/SwDev/WDM/Video/bt848/rcs/Declare.h 1.3 1998/04/29 22:43:31 tomz Exp $

#ifndef __DECLARE_H
#define __DECLARE_H

RegisterB decRegSTATUS;
RegField  decFieldPRES;
RegField  decFieldHLOC;
RegField  decFieldEVENFIELD;
RegField  decFieldNUML;
RegField  decFieldCSEL;
RegField  decFieldSTATUS_RES;
RegField  decFieldLOF;
RegField  decFieldCOF;
RegisterB decRegIFORM;
RegField  decFieldHACTIVE;
RegField  decFieldMUXSEL;
RegField  decFieldXTSEL;
RegField  decFieldFORMAT;
RegisterB decRegTDEC;
RegField  decFieldDEC_FIELD;
RegField  decFieldDEC_FIELDALIGN;
RegField  decFieldDEC_RAT;
RegisterB decRegBRIGHT;
RegisterB decRegMISCCONTROL;
RegField  decFieldLNOTCH;
RegField  decFieldCOMP;
RegField  decFieldLDEC;
RegField  decFieldCBSENSE;
RegField  decFieldMISCCONTROL_RES;
RegField  decFieldCON_MSB;
RegField  decFieldSAT_U_MSB;
RegField  decFieldSAT_V_MSB;
RegisterB decRegCONTRAST_LO;
RegisterB decRegSAT_U_LO;
RegisterB decRegSAT_V_LO;
RegisterB decRegHUE;
RegisterB decRegSCLOOP;
RegField  decFieldCAGC;
RegField  decFieldCKILL;
RegField  decFieldHFILT;
RegisterB decRegWC_UP;
RegisterB decRegOFORM;
RegField  decFieldRANGE;
RegField  decFieldCORE;
RegisterB decRegVSCALE_HI;
RegField  decFieldYCOMB;
RegField  decFieldCOMB;
RegField  decFieldINT;
RegisterB decRegTEST;
RegisterB decRegADELAY;
RegisterB decRegBDELAY;
RegisterB decRegADC;
RegField  decFieldSYNC_T;
RegField  decFieldAGC_EN;
RegField  decFieldCLK_SLEEP;
RegField  decFieldY_SLEEP;
RegField  decFieldC_SLEEP;
RegField  decFieldCRUSH;
RegisterB decRegVTC;
RegField  decFieldHSFMT;
RegisterB decRegWC_DN;
RegisterB decRegSRESET;
RegisterB decRegODD_MISCCONTROL;
RegField  decFieldODD_LNOTCH;
RegField  decFieldODD_COMP;
RegField  decFieldODD_LDEC;
RegField  decFieldODD_CBSENSE;
RegField  decFieldODD_MISCCONTROL_RES;
RegField  decFieldODD_CON_MSB;
RegField  decFieldODD_SAT_U_MSB;
RegField  decFieldODD_SAT_V_MSB;
RegisterB decRegODD_SCLOOP;
RegField  decFieldODD_CAGC;
RegField  decFieldODD_CKILL;
RegField  decFieldODD_HFILT;
RegisterB decRegODD_VSCALE_HI;
RegField  decFieldODD_YCOMB;
RegField  decFieldODD_COMB;
RegField  decFieldODD_INT;
RegisterB decRegODD_VTC;
RegField  decFieldODD_HSFMT;

#endif   // __DECLARE_H
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\drivers\wdm\capture\mini\bt848\dcdrvals.h ===
// $Header: G:/SwDev/WDM/Video/bt848/rcs/Dcdrvals.h 1.3 1998/04/29 22:43:31 tomz Exp $

#ifndef __DCDRVALS_H
#define __DCDRVALS_H

#ifdef __cplusplus

const int HueMin = -90;
const int HueMax = 90;
const int HueDef = 0;

const int SatMinNTSC = 0;
const int SatMaxNTSC = 0x1FF;
const int SatDefNTSC = 0xFE;

const int SatMinSECAM = 0;
const int SatMaxSECAM = 0x1FF;
const int SatDefSECAM = 0x87;

const int ConMin = 0;
const int ConMax = 236;
const int ConDef = 100;

const int BrtMin = -50;
const int BrtMax = 50;
const int BrtDef = 0;

const int ParamMin = 0;
const int ParamMax = 10000;
const int ParamDef = 5000;

#else
#define HueMin -90
#define HueMax 90
#define HueDef 0

#define SatMinNTSC 0
#define SatMaxNTSC 0x1FF
#define SatDefNTSC 0xFE

#define SatMinSECAM 0
#define SatMaxSECAM 0x1FF
#define SatDefSECAM 0x87

#define ConMin 0
#define ConMax 236
#define ConDef 100

#define BrtMin -50
#define BrtMax 50
#define BrtDef 0

#define ParamMin 0
#define ParamMax 255
#define ParamDef 128

#endif



#endif
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\drivers\wdm\capture\mini\bt848\defaults.h ===
// $Header: G:/SwDev/WDM/Video/bt848/rcs/Defaults.h 1.4 1998/04/29 22:43:32 tomz Exp $

#ifndef __DEFAULTS_H
#define __DEFAULTS_H

const int DefWidth = 320;
const int DefHeight = 240;

const int MaxInWidth = 720;
const int MinInWidth = 80;

const int MaxInHeight = 480;
const int MinInHeight = 60;

const int MaxOutWidth = 720;
const int MinOutWidth = 80;

const int MaxOutHeight = 480;
const int MinOutHeight = 60;

//--------------------------------------
const int VBISamples  = 800 * 2;
//const int VBISamples  = 768 * 2;
//--------------------------------------

const int VBIStart    =  10;
const int VBIEnd      =  21;
const int VBILines    = VBIEnd - VBIStart + 1;
const int VBISampFreq = 28636363;

const DWORD MaxVidProgSize   = 288 * 5 * sizeof( DWORD );// max size of a planar program
const DWORD MaxVidCrossings  = 720 *  288 * 3 / PAGE_SIZE; // worst case buffer layout
const DWORD MaxVidSize       = MaxVidProgSize + MaxVidCrossings * 5 * sizeof( DWORD );

const DWORD MaxVBIProgSize   = VBILines * 2 * sizeof( DWORD );
const DWORD MaxVBICrossings  = VBISamples * VBILines / PAGE_SIZE;
const DWORD MaxVBISize       = MaxVBIProgSize + MaxVBICrossings * 5 * sizeof( DWORD );

const DWORD MaxHelpers       = 13;
// 2 fields, 2 programs per field + skippers
const DWORD VideoOffset      = MaxVBISize * 2 * 2 + MaxVBISize * MaxHelpers;

const DWORD RISCProgramsSize = // total memory needed for all risc programs
   ( MaxVidSize * 2 + MaxVBISize * 2 ) * 2 + MaxVBISize * MaxHelpers; // skippers
#endif
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\drivers\wdm\capture\mini\bt848\device.h ===
// $Header: G:/SwDev/WDM/Video/bt848/rcs/Device.h 1.10 1998/05/11 20:27:07 tomz Exp $

#ifndef __DEVICE_H
#define __DEVICE_H

#ifdef __cplusplus
extern "C" {
#endif
#ifndef  _STREAM_H
#include "strmini.h"
#endif
#ifdef __cplusplus
}
#endif

#ifndef __PISCES_H
#include "pisces.h"
#endif

#ifndef __MYTYPES_H
#include "mytypes.h"
#endif

#ifndef __VIDCH_H
#include "vidch.h"
#endif

#ifndef __I2C_H
#include "bti2c.h"
#endif

#ifndef __GPIO_H
#include "gpio.h"
#endif

#include "xbar.h"

#ifndef __I2C_H__
#include <i2cgpio.h>
#endif


#define TUNER_BRAND_TEMIC     1
#define TUNER_BRAND_PHILIPS   2
#define TUNER_BRAND_ALPS      3

typedef struct _TUNER_INFO
{
   ULONG TunerBrand;          // Brand of tuner
   BYTE  TunerI2CAddress;     // I2C address for Temic tuner
   WORD  TunerBandCtrlLow;    // Ctrl code for VHF low
   WORD  TunerBandCtrlMid;    // Ctrl code for VHF high
   WORD  TunerBandCtrlHigh;   // Ctrl code for UHF
} TUNER_INFO, *PTUNER_INFO;

extern LONG  PinTypes_ []; // just allocate maximum possible
extern DWORD xtals_ []; // no more than 2 xtals
extern TUNER_INFO TunerInfo;

void ReadXBarRegistryValues( IN PDEVICE_OBJECT PhysicalDeviceObject );
void ReadXTalRegistryValues( IN PDEVICE_OBJECT PhysicalDeviceObject );
void ReadTunerRegistryValues( IN PDEVICE_OBJECT PhysicalDeviceObject );

VOID AdapterSetCrossbarProperty( PHW_STREAM_REQUEST_BLOCK pSrb );
VOID AdapterGetCrossbarProperty( PHW_STREAM_REQUEST_BLOCK pSrb );

void AdapterSetVideoProcAmpProperty( PHW_STREAM_REQUEST_BLOCK pSrb );
void AdapterGetVideoProcAmpProperty( PHW_STREAM_REQUEST_BLOCK pSrb );

void AdapterSetVideoDecProperty( PHW_STREAM_REQUEST_BLOCK pSrb );
void AdapterGetVideoDecProperty( PHW_STREAM_REQUEST_BLOCK pSrb );

void AdapterSetTunerProperty( PHW_STREAM_REQUEST_BLOCK pSrb );
void AdapterGetTunerProperty( PHW_STREAM_REQUEST_BLOCK pSrb );

void AdapterSetTVAudioProperty( PHW_STREAM_REQUEST_BLOCK pSrb );
void AdapterGetTVAudioProperty( PHW_STREAM_REQUEST_BLOCK pSrb );

void HandleIRP( PHW_STREAM_REQUEST_BLOCK pSrb );


// Forward declarations

class PsDevice;

extern void SetCurrentDevice( PsDevice *dev );
extern BYTE *GetBase();
extern void SetBase(BYTE *base);

/* Class: PsDevice
 * Purpose: This is the class that encapsulates the adapter in the WDM model.
*/
class PsDevice
{

public:

   PsDevice( DWORD dwBase );
   ~PsDevice();

   void *operator new( size_t, void *buf ) { return buf; }
   void operator delete( void *, size_t ) {}

   LPBYTE GetBaseAddress() { return BaseAddress_; }
   bool InitOK();

   PDEVICE_OBJECT PDO;   // Physical Device Object
   State Interrupt() { return CaptureContrll_.Interrupt(); }

   ErrorCode OpenChannel( PVOID pStrmEx, VideoStream st );
   void CloseChannel( VideoChannel *ToClose );

   ErrorCode OpenInterChannel( PVOID pStrmEx, VideoStream st );
   ErrorCode OpenAlterChannel( PVOID pStrmEx, VideoStream st );
   ErrorCode OpenVBIChannel( PVOID pStrmEx );
   void      ClosePairedChannel( VideoChannel *ToClose );

   bool IsVideoChannel( VideoChannel &aChan );
   bool IsVBIChannel( VideoChannel &aChan );
   bool IsOurChannel( VideoChannel &aChan );


   ErrorCode DoOpen( VideoStream st );

   void AddBuffer( VideoChannel &aChan, PHW_STREAM_REQUEST_BLOCK );
   ErrorCode Create( VideoChannel &VidChan );
   void Start( VideoChannel &VidChan );
   void Stop( VideoChannel &VidChan );
   void Pause( VideoChannel &VidChan );

   void EnableAudio( State s );

   void SetVideoState( PHW_STREAM_REQUEST_BLOCK pSrb );
   void GetVideoState( PHW_STREAM_REQUEST_BLOCK pSrb );
   void SetClockMaster( PHW_STREAM_REQUEST_BLOCK pSrb );

   // tuner methods
   void SetChannel( long lFreq );
   int GetPllOffset( PULONG busy, ULONG &lastFreq );

   I2C      i2c;
   GPIO     gpio;
   BtPisces CaptureContrll_;
   CrossBar xBar;

   void SetSaturation( LONG Data );
   void SetHue( LONG Data );
   void SetBrightness( LONG Data );
   void SetSVideo( LONG Data );
   void SetContrast( LONG Data );
   void SetFormat( LONG Data );
   void SetConnector( LONG Data );

   LONG GetSaturation();
   LONG GetHue();
   LONG GetBrightness();
   LONG GetSVideo();
   LONG GetContrast();
   LONG GetFormat();
   LONG GetConnector();

public:

      // this should be before the capture controller, as CapCtrl uses the base address
      LPBYTE         BaseAddress_;

      VideoChannel   *videochannels [4];

      long LastFreq_;


      DWORD    dwCurCookie_;

      BYTE     I2CAddr_;

#ifdef	HAUPPAUGEI2CPROVIDER
// new private members of PsDevice for Hauppauge I2C Provider:
      LARGE_INTEGER LastI2CAccessTime;
      DWORD         dwExpiredCookie;
      DWORD         dwI2CClientTimeout;
#endif


   static void STREAMAPI CreateVideo( PHW_STREAM_REQUEST_BLOCK pSrb );
   static void STREAMAPI DestroyVideo( PHW_STREAM_REQUEST_BLOCK pSrb );

   static void STREAMAPI DestroyVideoNoComplete( PHW_STREAM_REQUEST_BLOCK pSrb );
   static void STREAMAPI StartVideo( PHW_STREAM_REQUEST_BLOCK pSrb );

   // tuner and video standard notifications are handled here
   void ChangeNotifyChannels( IN PHW_STREAM_REQUEST_BLOCK pSrb );
   
   static NTSTATUS STDMETHODCALLTYPE I2COpen( PDEVICE_OBJECT, ULONG, PI2CControl );
   static NTSTATUS STDMETHODCALLTYPE I2CAccess( PDEVICE_OBJECT, PI2CControl );

   // callbacks

          LONG GetSupportedStandards();
          
          void GetStreamProperty( PHW_STREAM_REQUEST_BLOCK pSrb );
          void SetStreamProperty( PHW_STREAM_REQUEST_BLOCK pSrb );
          void GetStreamConnectionProperty( PHW_STREAM_REQUEST_BLOCK pSrb );

          void ProcessSetDataFormat( PHW_STREAM_REQUEST_BLOCK pSrb );

      //void *operator new( size_t, void *buf ) { return buf; }
      //void operator delete( void *, size_t ) {}

   // I2C API
   bool I2CIsInitOK( void );

#ifdef	HARDWAREI2C
   ErrorCode I2CInitHWMode( long freq );

   void I2CSetFreq( long freq );

   int I2CReadDiv( void );

   ErrorCode I2CHWRead( BYTE address, BYTE *value );
   ErrorCode I2CHWWrite2( BYTE address, BYTE value1 );
   ErrorCode I2CHWWrite3( BYTE address, BYTE value1, BYTE value2 );
   int I2CReadSync( void );
#else
// tuner.cpp contains code to fake these using Software I2C just
// to make the older tuner code work until it is seperated out
   ErrorCode I2CHWRead( BYTE address, BYTE *value );
   ErrorCode I2CHWWrite3( BYTE address, BYTE value1, BYTE value2 );
#endif	           

   int I2CGetLastError( void );

   void StoreI2CAddress( BYTE addr );
   BYTE GetI2CAddress();

#ifdef HAUPPAUGEI2CPROVIDER
   ErrorCode I2CInitSWMode( long freq );
   ErrorCode I2CSWStart( void );
   ErrorCode I2CSWStop( void );
   ErrorCode I2CSWRead( BYTE * value );
   ErrorCode I2CSWWrite( BYTE value );
   ErrorCode I2CSWSendACK( void );
   ErrorCode I2CSWSendNACK( void );
//   ErrorCode I2CSWSetSCL( Level );
//   int       I2CSWReadSCL( void );
//   ErrorCode I2CSWSetSDA( Level );
//   int       I2CSWReadSDA( void );
#endif

   // GPIO API
   bool GPIOIsInitOK( void );
   void SetGPCLKMODE( State s );
   int GetGPCLKMODE( void );
   void SetGPIOMODE( GPIOMode mode );
   int GetGPIOMODE( void );
   void SetGPWEC( State s );
   int GetGPWEC( void );
   void SetGPINTI( State s );
   int GetGPINTI( void );
   void SetGPINTC( State s );
   int GetGPINTC( void );
   ErrorCode SetGPOEBit( int bit, State s );
   void SetGPOE( DWORD value );
   int GetGPOEBit( int bit );
   DWORD GetGPOE( void );
   ErrorCode SetGPIEBit( int bit , State s );
   void SetGPIE( DWORD value );
   int GetGPIEBit( int bit );
   DWORD GetGPIE( void );
   ErrorCode SetGPDATA( GPIOReg *data, int size, int offset );
   ErrorCode GetGPDATA( GPIOReg *data, int size, int offset );
   ErrorCode SetGPDATABits( int fromBit, int toBit, DWORD value, int offset );
   ErrorCode GetGPDATABits( int fromBit, int toBit, DWORD *value, int offset );
};


inline  void PsDevice::StoreI2CAddress( BYTE addr )
{
   I2CAddr_ = addr;
}

inline BYTE PsDevice::GetI2CAddress()
{
   return I2CAddr_;
}

#endif
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\drivers\wdm\capture\mini\bt848\device.cpp ===
// $Header: G:/SwDev/WDM/Video/bt848/rcs/Device.cpp 1.18 1998/05/13 14:44:33 tomz Exp $

#include "device.h"
#include "capmain.h"

const I2C_Offset = 0x110;
const GPIO_Cntl_Offset  = 0x10D;
const GPIO_OutputOffset = 0x118;
const GPIO_DataOffset   = 0x200;


// Global functions/data exposing public class info to the "C" modules

PsDevice *gpPsDevice = NULL;
BYTE     *gpjBaseAddr = NULL;
VOID     *gpHwDeviceExtension = NULL;

DWORD GetSizeHwDeviceExtension( )
{
   return ( sizeof( HW_DEVICE_EXTENSION ) + sizeof( PsDevice ));
}

DWORD GetSizeStreamEx( )
{
   // return the size of the largest possible channel object

   DWORD dwMax = sizeof( VBIChannel );
   dwMax = max( dwMax, sizeof( AlterVideoChannel<VBIChannel> )); 
   dwMax = max( dwMax, sizeof( InterVideoChannel )); 

   DWORD dwReq = 2 * dwMax;   // paired stuff has two of them together

   dwReq += sizeof( STREAMEX );
   return ( dwReq );
}

/* Function: GetDeviceExt
 * Purpose: Used in creation of risc programs to obtain physical addresses
*/
PsDevice *GetCurrentDevice()
{
   // This is only used for I2C stuff.  Remove this ASAP.
   return gpPsDevice;
}

/* Function: SetCurrentDevice
 * Purpose: Remembers the currently active device
 * Input: PsDevice *
 * Output: None
 */
void SetCurrentDevice( PsDevice *dev )
{
   // This is only used for I2C stuff.  Remove this ASAP.
   gpPsDevice = dev;
}

/* Function: GetBase
 * Purpose: Returns the base address of the currently active device
 * Input: None
 * Output: LPBYTE
 */
BYTE *GetBase()
{
   return gpjBaseAddr;
}

/* Function: SetBase
 * Purpose: Remembers the base address of the currently active device
 * Input: None
 * Output: LPBYTE
 */
void SetBase(BYTE *base)
{
   gpjBaseAddr = base;
}





PsDevice::PsDevice( DWORD dwBase ) : 
   BaseAddress_( (LPBYTE)dwBase ),
   LastFreq_( 0 ),
   dwCurCookie_( 0 ), 
   I2CAddr_( 0 ), 
   xBar( PinTypes_ ), 
   CaptureContrll_( xtals_ )
{
   SetCurrentDevice ( this );

   for ( int i = 0; i < (sizeof(videochannels)/sizeof(videochannels[0])); i++ ) {
      videochannels [i] = 0;
   }
   I2CIsInitOK();
#ifdef   HARDWAREI2C
   I2CInitHWMode( 100000 );    // assume frequency = 100Khz
#else
   I2CInitSWMode( 100000 );    // assume frequency = 100Khz
   I2CSWStart();
   I2CSWStop();
#endif
   GPIOIsInitOK();
   DebugOut((0, "*** Base Address = %x\n", BaseAddress_));
}

PsDevice::~PsDevice()
{
   for ( int i = 0; i < (sizeof(videochannels)/sizeof(videochannels[0])); i++ ) {
      VideoChannel *pvcTemp = videochannels [i];
      videochannels [i] = NULL;
      delete pvcTemp;
   }
}

/* Method: PsDevice::AddBuf
 * Purpose: Adds next buffer to be used to the queue
 * Input: VideoChan: VxDVideoChannel &
 *   pBufAddr: PVOID - address of the next buffer
 * Output: None
 */
void PsDevice::AddBuffer( VideoChannel &VideoChan, PHW_STREAM_REQUEST_BLOCK pSrb )
{
   // bogus channel, bye-bye
   if ( !IsOurChannel( VideoChan ) ) {
      DebugOut((0, "PsDevice::Addbuffer - not our channel (pSrb=%x) (&VideoChan=%x)\n", pSrb, &VideoChan ) );
      return;
   }
   DebugOut((1, "PsDevice::Addbuffer - adding (pSrb=%x) (&VideoChan=%x)\n", pSrb, &VideoChan ) );
   VideoChan.AddSRB( pSrb );
}

void PsDevice::Start( VideoChannel &VidChan )
{
   VidChan.Start();
}

void PsDevice::Pause( VideoChannel &VidChan )
{
   *(DWORD*)(gpjBaseAddr+0x10c) &= ~3;    // disable interrupts   [TMZ] [!!!]

   // [TMZ] [!!!]
   for ( int i = 0; i < (sizeof(videochannels)/sizeof(videochannels[0])); i++ )
   {
      if ( videochannels[i] == &VidChan )
      {
         DebugOut((1, "'PsDevice::Pause called on videochannels[%d]\n", i));
      }
   }
   VidChan.Pause();
}

/* Method: PsDevice::Create
 * Purpose: Calls into the channel ( stream ) to create RISC programs for it.
 * Input: VideoChan: VxDVideoChannel &
 *   Parms: StartParms &, parameters to create stream with
 * Output: ErrorCode
 */
ErrorCode PsDevice::Create( VideoChannel &VidChan )
{
   return VidChan.Create();
}

/* Method: PsDevice::Stop
 * Purpose: Adds next buffer to be used to the queue
 * Input: VideoChan: VxDVideoChannel &
 * Output: None
 */
void PsDevice::Stop( VideoChannel &VidChan )
{
   *(DWORD*)(gpjBaseAddr+0x10c) &= ~3;    // disable interrupts   [TMZ] [!!!]

   VidChan.Stop();
}

#if NEED_CLIPPING
/* Method: PsDevice::SetClipping
 * Purpose: Propagates the call down a video channel
 * Input: VideoChan: VxDVideoChannel & - reference
 *   dwData: DWORD - a pointer to RGNDATA in reality
 * Output: None
 */
void PsDevice::SetClipping( VideoChannel &VidChan, const RGNDATA & rgnData )
{
   if ( !rgnData.rdh.nCount )
      return;

   if ( FullSizeChannel_ ) {
      // have to decrese hight of all rectangles in half and decrease top in half

      unsigned i;
      for ( i = 0; i < rgnData.rdh.nCount; i++ ) {
         TRect *lpR = (TRect *)rgnData.Buffer + i;

         // make all even
         lpR->top++;
         lpR->top &= ~1;

         lpR->bottom++;
         lpR->bottom &= ~1;

         lpR->top    /= 2;
         lpR->bottom /= 2;
      }
      FullSizeChannel_->SetClipping( rgnData );
      SlaveChannel_   ->SetClipping( rgnData );
   } else
      VidChan.SetClipping( rgnData );
}
#endif

/* Method: PsDevice::IsVideoChannel
 * Purpose:
 */
bool PsDevice::IsVideoChannel( VideoChannel &aChan )
{
   return bool( &aChan == videochannels [VS_Field1] || &aChan == videochannels [VS_Field2] );
}

/* Method: PsDevice::IsVBIChannel
 * Purpose:
 */
bool PsDevice::IsVBIChannel( VideoChannel &aChan )
{
   return bool( &aChan == videochannels [VS_VBI1] || &aChan == videochannels [VS_VBI2] );
}

/* Method: PsDevice::IsOurChannel
 * Purpose: Verifies the channel
 * Input: aChan: VideoChannel &, reference to a channel
 * Output: true if our, false otherwise
 */
bool PsDevice::IsOurChannel( VideoChannel &aChan )
{
   return IsVideoChannel( aChan ) || IsVBIChannel( aChan );
}

/* Method: PsDevice::DoOpen
 * Purpose: This function performs opening of a video channel
 * Input: st: VideoStream, stream to open
 * Output: ErrorCode
 */
ErrorCode PsDevice::DoOpen( VideoStream st )
{
   DebugOut((1, "PsDevice::DoOpen(%d)\n", st));

   if ( !videochannels [st] )
   {
      DebugOut((1, "   PsDevice::DoOpen(%d) failed - videochannel not created\n", st));
      return Fail;
   }
   videochannels [st]->Init( &CaptureContrll_ );
   if ( videochannels [st]->OpenChannel() != Success ) {
      DebugOut((1, "   PsDevice::DoOpen(%d) failed - videochannel open failed\n", st));
      VideoChannel *pvcTemp = videochannels [st];
      videochannels [st] = NULL;
      delete pvcTemp;
      return Fail;
   }
   return Success;
}

/* Method: PsDevice::OpenChannel
 * Purpose: This function opens a channel requested by the capture driver
 * Input: hVM: VMHANDLE - handle of the VM making a call
 *   pRegs: CLIENT_STRUCT * - pointer to the structure with VM's registers
 * Output: None
 */
ErrorCode PsDevice::OpenChannel( PVOID pStrmEx, VideoStream st )
{
   PVOID addr = &((PSTREAMEX)pStrmEx)->videochannelmem[0];
   ((PSTREAMEX)pStrmEx)->videochannel = addr;

   DebugOut((1, "PsDevice::OpenChannel(%x,%d)\n", addr, st));
   if ( videochannels [st] )
   {
      DebugOut((1, "   PsDevice::OpenChannel(%x,%d) failed - already open\n", addr, st));
      return Fail;
   }
   videochannels[st] = new( addr ) VideoChannel( st );
   videochannels[st]->SetStrmEx( pStrmEx ) ;

   DebugOut((1, "   PsDevice::OpenChannel(%x,%d), videochannels[%d] = %x\n", addr, st, st, videochannels[st]));

   return DoOpen( st );
}

/* Method: PsDevice::OpenInterChannel
 * Purpose: This function opens video channel that produces interleaved fields
 * Input: addr: PVOID, address for the palcement new
 *   st: VideoStream, stream to open ( VBI or video )
 * Output: None
 */
ErrorCode PsDevice::OpenInterChannel( PVOID pStrmEx, VideoStream st )
{
   PVOID addr = &((PSTREAMEX)pStrmEx)->videochannelmem[0];
   ((PSTREAMEX)pStrmEx)->videochannel = addr;

   DebugOut((1, "PsDevice::OpenInterChannel(%x,%d)\n", addr, st));
   // only odd channel can be paired
   if ( !( st & 1 ) || videochannels [st] || videochannels [st-1] )
   {
      DebugOut((1, "   PsDevice::OpenInterChannel(%x,%d) failed - stream not odd or already open\n", addr, st));
      return Fail;
   }
   if ( OpenChannel( (PBYTE)addr + sizeof( InterVideoChannel ), VideoStream( st - 1 ) ) == Success )
   {
      videochannels[st] = new( addr ) InterVideoChannel( st, *videochannels [st-1] );
      videochannels[st]->SetStrmEx( pStrmEx ) ;

      if ( DoOpen( st ) != Success )
      {
         DebugOut((1, "   PsDevice::OpenInterChannel(%x,%d) failed - DoOpen failed\n", addr, st));
         CloseChannel( videochannels [st-1] );
         return Fail;
      }
   }
   else
   {
      DebugOut((1, "   PsDevice::OpenInterChannel(%x,%d) failed - OpenChannel failed\n", addr, st));
      return Fail;
   }
   return Success;
}

/* Method: PsDevice::OpenAlterChannel
 * Purpose: This function opens video channel that produces alternating fields
 * Input: addr: PVOID, address for the palcement new
 *   st: VideoStream, stream to open ( VBI or video )
 * Output: None
 */
ErrorCode PsDevice::OpenAlterChannel( PVOID pStrmEx, VideoStream st )
{
   PVOID addr = &((PSTREAMEX)pStrmEx)->videochannelmem[0];
   ((PSTREAMEX)pStrmEx)->videochannel = addr;

   DebugOut((1, "PsDevice::OpenAlterChannel(%x,%d)\n", addr, st));
   // only odd channel can be paired
   if ( !( st & 1 ) || videochannels [st] || videochannels [st-1] )
   {
      DebugOut((1, "   PsDevice::OpenAlterChannel(%x,%d) failed - stream not odd or already open\n", addr, st));
      return Fail;
   }
   if ( OpenChannel( (PBYTE)addr + sizeof( AlterVideoChannel<VideoChannel> ), VideoStream( st -1 ) ) == Success )
   {
      videochannels[st] = new( addr ) AlterVideoChannel<VideoChannel>( st, *videochannels [st-1] );
      videochannels[st]->SetStrmEx( pStrmEx ) ;
      videochannels[st-1]->SetStrmEx( pStrmEx ) ;

      if ( DoOpen( st ) != Success )
      {
         DebugOut((1, "   PsDevice::OpenAlterChannel(%x,%d) failed - DoOpen failed\n", addr, st));
         CloseChannel( videochannels [st-1] );
         return Fail;
      }
   }
   else
   {
      DebugOut((1, "   PsDevice::OpenAlterChannel(%x,%d) failed - OpenChannel failed\n", addr, st));
      return Fail;
   }
   return Success;
}

/* Method: PsDevice::OpenVBIChannel
 * Purpose: This function opens video channel that produces alternating fields
 * Input: addr: PVOID, address for the palcement new
 *   st: VideoStream, stream to open ( VBI or video )
 * Output: None
 */
ErrorCode PsDevice::OpenVBIChannel( PVOID pStrmEx )
{
   PVOID addr = &((PSTREAMEX)pStrmEx)->videochannelmem[0];
   ((PSTREAMEX)pStrmEx)->videochannel = addr;

   DebugOut((1, "PsDevice::OpenVBIChannel(%x)\n", addr));
   if ( videochannels [VS_VBI1] || videochannels [VS_VBI2] )
   {
      DebugOut((1, "   PsDevice::OpenVBIChannel(%x) failed - already open\n", addr));
      return Fail;
   }

   VBIChannel *tmp = new( (PBYTE)addr + sizeof( VBIAlterChannel ) ) VBIChannel( VS_VBI1 );
   videochannels [VS_VBI1] = tmp;
   DebugOut((1, "   PsDevice::OpenVBIChannel(%x), videochannels[VS_VBI1(%d)] = %x\n", addr, VS_VBI1, videochannels[VS_VBI1]));

   if ( !tmp )
   {
      DebugOut((1, "   PsDevice::OpenVBIChannel(%x) failed - new VBIChannel failed\n", addr));
      return Fail;
   }

   if ( DoOpen( VS_VBI1 ) != Success )
   {
      DebugOut((1, "   PsDevice::OpenVBIChannel(%x) failed - DoOpen(VS_VBI1) failed\n", addr));
      return Fail;
   }

   videochannels [VS_VBI2] = new( addr ) VBIAlterChannel( VS_VBI2, *tmp );
   DebugOut((1, "   PsDevice::OpenVBIChannel(%x), videochannels[VS_VBI2(%d)] = %x\n", addr, VS_VBI2, videochannels[VS_VBI2]));

   if (!videochannels [VS_VBI2])
   {
      DebugOut((1, "   PsDevice::OpenVBIChannel(%x) failed - new VBIAlterChannel failed\n", addr));
      return Fail;
   }

   if ( DoOpen( VS_VBI2 ) != Success )
   {
     DebugOut((1, "   PsDevice::OpenVBIChannel(%x) failed - DoOpen(VS_VBI1) failed\n", addr));
     CloseChannel( videochannels [VS_VBI1] );
     return Fail;
   }

   videochannels[VS_VBI1]->SetStrmEx( pStrmEx ) ;
   videochannels[VS_VBI2]->SetStrmEx( pStrmEx ) ;

   return Success;
}

/* Method: PsDevice::CloseChannel
 * Purpose: Closes a video channel
 * Input: ToClose: VideoChannel *
 * Output: None
 */
void PsDevice::CloseChannel( VideoChannel *ToClose )
{
   *(DWORD*)(gpjBaseAddr+0x10c) &= ~3;    // disable interrupts   [TMZ] [!!!]

   DebugOut((1, "PsDevice::CloseChannel(%x)\n", ToClose));

   if ( IsOurChannel( *ToClose ) )
   {
      // this is a bit ugly solution to make CLOSE_STREAM SRB clean
      if ( ToClose->GetStreamType() == Single )
      {
         VideoStream st = ToClose->GetStreamID();
         DebugOut((1, "   PsDevice::CloseChannel(%x) - closing single channel (stream == %d)\n", ToClose, st));
         VideoChannel * pvcTemp = videochannels [st];
         videochannels [st] = NULL;
         delete pvcTemp;
      }
      else
      {
         DebugOut((1, "   PsDevice::CloseChannel(%x) - closing paired channel\n", ToClose));
         ClosePairedChannel( ToClose );
      }
   }
   else
   {
      DebugOut((1, "   PsDevice::CloseChannel(%x) ignored - not our channel\n", ToClose));
   }
}

/* Method: PsDevice::ClosePairedChannel
 * Purpose: This function opens a channel requested by the capture driver
 * Input: hVM: VMHANDLE - handle of the VM making a call
 *   pRegs: CLIENT_STRUCT * - pointer to the structure with VM's registers
 * Output: None
 */
void PsDevice::ClosePairedChannel( VideoChannel *ToClose )
{
   *(DWORD*)(gpjBaseAddr+0x10c) &= ~3;    // disable interrupts   [TMZ] [!!!]

   DebugOut((1, "PsDevice::ClosePairedChannel(%x)\n", ToClose));

   if ( IsOurChannel( *ToClose ) )
   {
      VideoStream st = ToClose->GetStreamID();
      DebugOut((1, "   PsDevice::ClosePairedChannel(%x) - closing paired channel (stream == %d)\n", ToClose, st));
      DebugOut((1, "   PsDevice::ClosePairedChannel(%x) - streams[%d] = %x\n", ToClose, st, videochannels[st]));
      DebugOut((1, "   PsDevice::ClosePairedChannel(%x) - streams[%d] = %x\n", ToClose, st-1, videochannels[st-1]));

      VideoChannel *pvcTemp;
      
      pvcTemp = videochannels [st];
      videochannels [st] = NULL;
      delete pvcTemp;

      pvcTemp = videochannels [st-1];
      videochannels [st-1] = NULL;
      delete pvcTemp;
   }
   else
   {
      DebugOut((1, "   PsDevice::ClosePairedChannel(%x) ignored - not our channel\n", ToClose));
   }
}

/* Method: PsDevice::SetSaturation
 * Purpose:
 * Input:
 * Output: None
 */
void PsDevice::SetSaturation( LONG Data )
{
   CaptureContrll_.SetSaturation( Data );
}

/* Method: PsDevice::SetHue
 * Purpose:
 * Input:
 * Output: None
 */
void PsDevice::SetHue( LONG Data )
{
   CaptureContrll_.SetHue( Data );
}

/* Method: PsDevice::SetBrightness
 * Purpose:
 * Input:
 * Output: None
 */
void PsDevice::SetBrightness( LONG Data )
{
   CaptureContrll_.SetBrightness( Data );
}

/* Method: PsDevice::SetSVideo
 * Purpose:
 * Input:
 * Output: None
 */
void PsDevice::SetSVideo( LONG Data )
{
   CaptureContrll_.SetSVideo( Data );
}

/* Method: PsDevice::SetContrast
 * Purpose:
 * Input:
 * Output: None
 */
void PsDevice::SetContrast( LONG Data )
{
   CaptureContrll_.SetContrast( Data );
}

/* Method: PsDevice::SetFormat
 * Purpose:
 * Input:
 * Output: None
 */
void PsDevice::SetFormat( LONG Data )
{
   CaptureContrll_.SetFormat( Data );
   // notify all video channels that video timing has changed
   LONG time = Data == KS_AnalogVideo_NTSC_M ? 333667 : 400000;
   for ( int i = 0; i < (sizeof(videochannels)/sizeof(videochannels[0])); i++ )
   {
      if ( videochannels [i] )
      {
         DebugOut((1, "PsDevice::SetFormat(%d) SetTimePerFrame on videochannels[%d]\n", Data, i));
         videochannels [i]->SetTimePerFrame( time );
      }
   }
}

/* Method: PsDevice::SetConnector
 * Purpose:
 * Input:
 * Output: None
 */
void PsDevice::SetConnector( LONG Data )
{
   CaptureContrll_.SetConnector( Data );
}

/* Method: PsDevice::GetSaturation
 * Purpose:
 * Input: pData: PLONG
 * Output: None
 */
LONG PsDevice::GetSaturation()
{
   return CaptureContrll_.GetSaturation();
}

/* Method: PsDevice::GetHue
 * Purpose:
 * Input: pData: PLONG
 * Output: None
 */
LONG PsDevice::GetHue()
{
   return CaptureContrll_.GetHue();
}

/* Method: PsDevice::GetBrightness
 * Purpose:
 * Input: pData: PLONG
 * Output: None
 */
LONG PsDevice::GetBrightness()
{
   return CaptureContrll_.GetBrightness();
}

/* Method: PsDevice::GetSVideo
 * Purpose:
 * Input: pData: PLONG
 * Output: None
 */
LONG PsDevice::GetSVideo()
{
   return CaptureContrll_.GetSVideo();
}

/* Method: PsDevice::GetContrast
 * Purpose:
 * Input: pData: PLONG
 * Output: None
 */
LONG PsDevice::GetContrast()
{
   return CaptureContrll_.GetContrast();
}

/* Method: PsDevice::GetFormat
 * Purpose:
 * Input: pData: PLONG
 * Output: None
 */
LONG PsDevice::GetFormat()
{
   return CaptureContrll_.GetFormat();
}

/* Method: PsDevice::GetConnector
 * Purpose:
 * Input: pData: PLONG
 * Output: None
 */
LONG PsDevice::GetConnector()
{
   return CaptureContrll_.GetConnector();
}

/* Method: PsDevice::ChangeNotifyChannels
 * Purpose: Invoked to notify channels of some global changes
 */                         
void PsDevice::ChangeNotifyChannels( IN PHW_STREAM_REQUEST_BLOCK pSrb )
{
   // We should only do this once per "system" stream.
   // Video streams don't seem to care.
   // That just leaves one VBI notification required
   
   videochannels [VS_VBI1]->ChangeNotification( pSrb );
}

/* Method: PsDevice::GetSupportedStandards
 * Purpose: Obtains video standards device can support
 * Input: None
 * Output: LONG
 */
LONG PsDevice::GetSupportedStandards()
{
   return CaptureContrll_.GetSupportedStandards();
}

bool PsDevice::InitOK()
{
   return CaptureContrll_.InitOK();
}

#ifndef	HARDWAREI2C

//===========================================================================
// Bt848 software I2C stuff
//===========================================================================

/*
 * If we build with software I2C then these routines fake the Hardware I2C routines
 * so the tuner code keeps working
 */

ErrorCode PsDevice::I2CHWRead( BYTE address, BYTE *value )
{
    ErrorCode error;

    error = I2CSWStart();
    if(error) {
        return error;
    }
    
    error = I2CSWWrite( address | 0x01 );
    if(error) {
        return error;
    }

    error = I2CSWRead( value );
    if(error) {
       return error;
    }
        
   	error = I2CSWSendNACK();
   	if(error) {
       	return error;
    }

   	error = I2CSWStop();

   	return error;
}


ErrorCode PsDevice::I2CHWWrite3( BYTE address, BYTE value1, BYTE value2 )
{
    ErrorCode error;

    error = I2CSWStart();
    if(error) {
        return error;
    }
    
    error = I2CSWWrite( address );
    if(error) {
        return error;
    }

    error = I2CSWWrite( value1 );
    if(error) {
        return error;
    }

    error = I2CSWWrite( value2 );
    if(error) {
        return error;
    }
    
   	error = I2CSWStop();
   	return error;
}

#endif



//////////////////////////////////////////////////////////////////


#ifdef __cplusplus
extern "C" {
#endif

   #include <stdarg.h>

#ifdef __cplusplus
}
#endif

// #include "capdebug.h"

#define  DEBUG_PRINT_PREFIX   "   ---: "
// #define  DEBUG_PRINT_PREFIX   "bt848wdm: "

long DebugLevel = 0;
BOOL bNewLine = TRUE;

extern "C" void MyDebugPrint(long DebugPrintLevel, char * DebugMessage, ... )
{
   if (DebugPrintLevel <= DebugLevel)
   {
       char debugPrintBuffer[256] ;

       va_list marker;
       va_start( marker, DebugMessage );     // Initialize variable arguments.
       vsprintf( debugPrintBuffer,
                 DebugMessage,
                 marker );

       if( bNewLine )
       {
          DbgPrint(("%s", DEBUG_PRINT_PREFIX));
       }
       
       DbgPrint((debugPrintBuffer));

       if( debugPrintBuffer[strlen(debugPrintBuffer)-1] == '\n')
       {
          bNewLine = TRUE;
       }
       else
       {
          bNewLine = FALSE;
       }

       va_end( marker );                     // Reset variable arguments.
   }
}

#if TRACE_CALLS
   #define MAX_TRACE_DEPTH 10
   unsigned long ulTraceDepth = 0;
   char achIndentBuffer[100];

   char * IndentStr( )
   {
      unsigned long ul = ulTraceDepth < MAX_TRACE_DEPTH ? ulTraceDepth : MAX_TRACE_DEPTH;
      unsigned long x;
      char * lpszBuf = achIndentBuffer;
      for( x = 0; x < ul; x++)
      {
         // indent two spaces per depth increment
         *lpszBuf++ = ' ';
         *lpszBuf++ = ' ';
      }
      sprintf (lpszBuf, "[%lu]", ulTraceDepth);
      return( achIndentBuffer );

   }

   Trace::Trace(char *pszFunc)
   {
      psz = pszFunc;
      DebugOut((0, "%s %s\n", IndentStr(), psz));
      ulTraceDepth++;
   }
   Trace::~Trace()
   {
      ulTraceDepth--;
      // DebugOut((0, "%s %s\n", IndentStr(), psz));
   }

#endif
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\drivers\wdm\capture\mini\bt848\distr.cpp ===
// $Header: G:/SwDev/WDM/Video/bt848/rcs/Distr.cpp 1.2 1998/04/29 22:43:33 tomz Exp $

#include "mytypes.h"
#define label( x ) } x: _asm {

void CreateDistribution( WORD OrigFPS, WORD NeededFPS, PWORD lpwDistribution )
{
    _asm {
                push    edi

                mov     edi, dword ptr lpwDistribution
//                mov     es,  word ptr lpwPixWidthMap+2
                mov     ax, NeededFPS
                shl     eax, 16
                movzx   ecx, word ptr OrigFPS
                or      cx, cx
                jz      short end
                xor     edx, edx
                div     ecx
                mov     ebx, eax
                mov     eax, 8000H
label( L1 )     and     eax, 0FFFFh
                add     eax, ebx
                shld    edx, eax, 16
                mov     [edi], dx
                add     edi,2
                dec     cx
                jnz     short L1

label( end )
                pop     edi
    }
}
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\drivers\wdm\capture\mini\bt848\gpio.cpp ===
// $Header: G:/SwDev/WDM/Video/bt848/rcs/Gpio.cpp 1.2 1998/04/29 22:43:33 tomz Exp $

#include "gpio.h"

/////////////////////////////////////////////////////////////////////////////
// Constructor
/////////////////////////////////////////////////////////////////////////////
GPIO::GPIO( void ) :
   // construct all GPIO related register and register fields
   decRegGPIO ( 0x10C, RW ),               // GPIO register
   decFieldGPCLKMODE( decRegGPIO, 10, 1, RW ),
   decFieldGPIOMODE( decRegGPIO, 11, 2, RW ),
   decFieldGPWEC( decRegGPIO, 13, 1, RW ),
   decFieldGPINTI( decRegGPIO, 14, 1, RW ),
   decFieldGPINTC( decRegGPIO, 15, 1, RW ),
   decRegGPOE( 0x118, RW ),                // GPOE register
   decRegGPIE( 0x11C, RW ),                // GPIE register
   decRegGPDATA( 0x200, WO ),            // GPDATA register
   initOK( false )
{
   initOK = true;
}

/////////////////////////////////////////////////////////////////////////////
// Destructor
/////////////////////////////////////////////////////////////////////////////
GPIO::~GPIO()
{
}

/////////////////////////////////////////////////////////////////////////////
// Method:  bool GPIO::IsInitOK( void )
// Purpose: Check if GPIO is initialized successfully
// Input:   None
// Output:  None
// Return:  true or false
/////////////////////////////////////////////////////////////////////////////
bool GPIO::IsInitOK( void )
{
   return( initOK );
}

/////////////////////////////////////////////////////////////////////////////
// Method:  void GPIO::SetGPCLKMODE( State s )
// Purpose: Set or clear GPCLKMODE
// Input:   State s - On to set; Off to clear
// Output:  None
// Return:  None
/////////////////////////////////////////////////////////////////////////////
void GPIO::SetGPCLKMODE( State s )
{
   decFieldGPCLKMODE = s;
}

/////////////////////////////////////////////////////////////////////////////
// Method:  int GPIO::GetGPCLKMODE( void )
// Purpose: Get value of GPCLKMODE
// Input:   None
// Output:  None
// Return:  int - On (1) or Off (0)
/////////////////////////////////////////////////////////////////////////////
int GPIO::GetGPCLKMODE( void )
{
   return ( decFieldGPCLKMODE );
}

/////////////////////////////////////////////////////////////////////////////
// Method:  void GPIO::SetGPIOMODE( GPIOMode mode )
// Purpose: Set GPIO mode
// Input:   GPIOMode mode - GPIO_NORMAL, GPIO_SPI_OUTPUT, GPIO_SPI_INPUT,
//                          GPIO_DEBUG_TEST
// Output:  None
// Return:  None
/////////////////////////////////////////////////////////////////////////////
void GPIO::SetGPIOMODE( GPIOMode mode )
{
   decFieldGPIOMODE = mode;
}

/////////////////////////////////////////////////////////////////////////////
// Method:  int GPIO::GetGPIOMODE( void )
// Purpose: Get GPIO mode
// Input:   None
// Output:  None
// Input:   int - GPIO_NORMAL, GPIO_SPI_OUTPUT, GPIO_SPI_INPUT, GPIO_DEBUG_TEST
/////////////////////////////////////////////////////////////////////////////
int GPIO::GetGPIOMODE( void )
{
   return( decFieldGPIOMODE );
}

/////////////////////////////////////////////////////////////////////////////
// Method:  void GPIO::SetGPWEC( State s )
// Purpose: Set or clear GPWEC
// Input:   State s - On to set; Off to clear
// Output:  None
// Return:  None
/////////////////////////////////////////////////////////////////////////////
void GPIO::SetGPWEC( State s )
{
   decFieldGPWEC = s;
}

/////////////////////////////////////////////////////////////////////////////
// Method:  int GPIO::GetGPWEC( void )
// Purpose: Get value of GPWEC
// Input:   None
// Output:  None
// Return:  int - On (1) or Off (0)
/////////////////////////////////////////////////////////////////////////////
int GPIO::GetGPWEC( void )
{
   return ( decFieldGPWEC );
}

/////////////////////////////////////////////////////////////////////////////
// Method:  void GPIO::SetGPINTI( State s )
// Purpose: Set or clear GPINTI
// Input:   State s - On to set; Off to clear
// Output:  None
// Return:  None
/////////////////////////////////////////////////////////////////////////////
void GPIO::SetGPINTI( State s )
{
   decFieldGPINTI = s;
}

/////////////////////////////////////////////////////////////////////////////
// Method:  int GPIO::GetGPINTI( void )
// Purpose: Get value of GPINTI
// Input:   None
// Output:  None
// Return:  int - On (1) or Off (0)
/////////////////////////////////////////////////////////////////////////////
int GPIO::GetGPINTI( void )
{
   return ( decFieldGPINTI );
}

/////////////////////////////////////////////////////////////////////////////
// Method:  void GPIO::SetGPINTC( State s )
// Purpose: Set or clear GPINTC
// Input:   State s - On to set; Off to clear
// Output:  None
// Return:  None
/////////////////////////////////////////////////////////////////////////////
void GPIO::SetGPINTC( State s )
{
   decFieldGPINTC = s;
}

/////////////////////////////////////////////////////////////////////////////
// Method:  int GPIO::GetGPINTC( void )
// Purpose: Get value of GPINTC
// Input:   None
// Output:  None
// Return:  int - On (1) or Off (0)
/////////////////////////////////////////////////////////////////////////////
int GPIO::GetGPINTC( void )
{
   return ( decFieldGPINTC );
}

/////////////////////////////////////////////////////////////////////////////
// Method:  ErrorCode GPIO::SetGPOE( int bit, State s )
// Purpose: Set or clear a bit in GPOE
// Input:   int bit - bit to be set or clear
//          State s - On to set; Off to clear
// Output:  None
// Return:  Success or Fail
/////////////////////////////////////////////////////////////////////////////
ErrorCode GPIO::SetGPOE( int bit, State s )
{
   // range checking
   if ( ( bit < 0 ) || ( bit > MAX_GPIO_BIT ) )
      return ( Fail );

   RegField decFieldTemp( decRegGPOE, (BYTE)bit, 1, RW );   // create a reg field
   decFieldTemp = s;

   return ( Success );
}

/////////////////////////////////////////////////////////////////////////////
// Method:  void GPIO::SetGPOE( DWORD value )
// Purpose: Set GPOE value
// Input:   DWORD value - value to be set to
// Output:  None
// Return:  None
/////////////////////////////////////////////////////////////////////////////
void GPIO::SetGPOE( DWORD value )
{
   decRegGPOE = ( value & 0x00FFFFFFL );     // bits [23:0]
}

/////////////////////////////////////////////////////////////////////////////
// Method:  int GPIO::GetGPOE( int bit )
// Purpose: Get value of a bit in GPOE
// Input:   int bit - bit to get value from
// Output:  None
// Return:  int - On (1), Off (0), or -1 for parameter error
/////////////////////////////////////////////////////////////////////////////
int GPIO::GetGPOE( int bit )
{
   // range checking
   if ( ( bit < 0 ) || ( bit > MAX_GPIO_BIT ) )
      return ( -1 );

   RegField decFieldTemp( decRegGPOE, (BYTE)bit, 1, RW );   // create a reg field
   return( decFieldTemp );
}

/////////////////////////////////////////////////////////////////////////////
// Method:  DWORD GPIO::GetGPOE( void )
// Purpose: Get value of GPOE
// Input:   None
// Output:  None
// Return:  Content of GPOE (DWORD)
/////////////////////////////////////////////////////////////////////////////
DWORD GPIO::GetGPOE( void )
{
   return ( decRegGPOE & 0x00FFFFFFL );
}

/////////////////////////////////////////////////////////////////////////////
// Method:  ErrorCode GPIO::SetGPIE( int bit, State s )
// Purpose: Set or clear a bit in GPIE
// Input:   int bit - bit to be set or clear
//          State s - On to set; Off to clear
// Output:  None
// Return:  Success or Fail
/////////////////////////////////////////////////////////////////////////////
ErrorCode GPIO::SetGPIE( int bit, State s )
{
   // range checking
   if ( ( bit < 0 ) || ( bit > MAX_GPIO_BIT ) )
      return ( Fail );

   RegField decFieldTemp( decRegGPIE, (BYTE)bit, 1, RW );   // create a reg field
   decFieldTemp = s;

   return ( Success );
}

/////////////////////////////////////////////////////////////////////////////
// Method:  void GPIO::SetGPIE( DWORD value )
// Purpose: Set GPIE value
// Input:   DWORD value - value to be set to
// Output:  None
// Return:  None
/////////////////////////////////////////////////////////////////////////////
void GPIO::SetGPIE( DWORD value )
{
   decRegGPIE = ( value & 0x00FFFFFFL );     // bits [23:0]
}

/////////////////////////////////////////////////////////////////////////////
// Method:  int GPIO::GetGPIE( int bit )
// Purpose: Get value of a bit in GPIE
// Input:   int bit - bit to get value from
// Output:  None
// Return:  int - On (1), Off (0), or -1 for parameter error
/////////////////////////////////////////////////////////////////////////////
int GPIO::GetGPIE( int bit )
{
   // range checking
   if ( ( bit < 0 ) || ( bit > MAX_GPIO_BIT ) )
      return ( -1 );

   RegField decFieldTemp( decRegGPIE, (BYTE)bit, 1, RW );   // create a reg field
   return( decFieldTemp );
}

/////////////////////////////////////////////////////////////////////////////
// Method:  DWORD GPIO::GetGPIE( void )
// Purpose: Get value of GPIE
// Input:   None
// Output:  None
// Return:  Content of GPIE (DWORD)
/////////////////////////////////////////////////////////////////////////////
DWORD GPIO::GetGPIE( void )
{
   return ( decRegGPIE & 0x00FFFFFFL );
}

/////////////////////////////////////////////////////////////////////////////
// Method:  ErrorCode GPIO::SetGPDATA( GPIOReg * data, int size, int offset )
// Purpose: Set GPDATA registers contents
// Input:   GPIOReg * data - ptr to data to be copied from
//          int size       - number of registers to be copied; max is 64
//          int offset     - how many registers to skip (default = 0)
// Output:  None
// Return:  Success or Fail
/////////////////////////////////////////////////////////////////////////////
ErrorCode GPIO::SetGPDATA( GPIOReg * data, int size, int offset )
{
   // check size and offset for out of bound
   if ( ( offset < 0 ) || ( size < 0 ) || ( size + offset > MAX_GPDATA_SIZE ) )
      return ( Fail );

   // point to offseted register
   GPIOReg * p = (GPIOReg *)((char *)decRegGPDATA.GetBaseAddress() +
                             decRegGPDATA.GetOffset() +
                             offset * sizeof( GPIOReg ));   // pts to offseted register
   memcpy( p, data, size * sizeof( GPIOReg ) );
   return ( Success );
}

/////////////////////////////////////////////////////////////////////////////
// Method:  ErrorCode GPIO::GetGPDATA( GPIOReg * data, int size, int offset )
// Purpose: Get GPDATA registers contents
// Input:   GPIOReg * data - ptr to data to be copied to
//          int size       - number of registers to be copied; max is 64
//          int offset     - how many registers to skip (default = 0)
// Output:  None
// Return:  Success or Fail
/////////////////////////////////////////////////////////////////////////////
ErrorCode GPIO::GetGPDATA( GPIOReg * data, int size, int offset )
{
   // check size and offset for out of bound
   if ( ( offset < 0 ) || ( size < 0 ) || ( size + offset > MAX_GPDATA_SIZE ) )
      return ( Fail );

   // point to offseted register
   GPIOReg * p = (GPIOReg *)((char *)decRegGPDATA.GetBaseAddress() +
                             decRegGPDATA.GetOffset() +
                             offset * sizeof( GPIOReg ));   // pts to offseted register
   memcpy( data, p, size * sizeof( GPIOReg ) );
   return ( Success );
}


/////////////////////////////////////////////////////////////////////////////
// Method:  ErrorCode GPIO::SetGPDATA( int fromBit, int toBit,
//                                     DWORD value, int offset )
// Purpose: Set GPDATA contents with specified range of bits
// Input:   int fromBit - starting bit
//          int toBit   - ending bit
//          DWORD value - value to set to
//          int offset  - how many registers to skip (default = 0)
// Output:  None
// Return:  Success or Fail
// Comment: By specifying a range of bits to be set, it allows a portion of
//          the GDATA register to be modified. For example,
//             SetGPDATA( 8, 10, 5, 0 )
//          would set the first GPDATA register's [10:8] to value 0x101
/////////////////////////////////////////////////////////////////////////////
ErrorCode GPIO::SetGPDATA( int fromBit, int toBit, DWORD value, int offset )
{
   // check size and offset for out of bound
   if ( ( fromBit < 0 ) || ( fromBit > MAX_GPIO_BIT ) ||
        ( toBit   < 0 ) || ( toBit   > MAX_GPIO_BIT ) || ( fromBit > toBit ) ||
        ( offset  < 0 ) || ( offset  > MAX_GPDATA_SIZE ) )
      return ( Fail );

   // make sure value can "fit" into range of bits specified
   if ( value >= (DWORD) ( 0x00000001L << ( toBit - fromBit + 1 ) ) )
      return ( Fail );

   RegisterDW reg( decRegGPDATA.GetOffset() + offset * sizeof( GPIOReg ), RW );
   RegField field( reg, (BYTE)fromBit, (BYTE)(toBit - fromBit + 1), RW );
   field = value;

   return ( Success );
}


/////////////////////////////////////////////////////////////////////////////
// Method:  ErrorCode GPIO::GetGPDATA( int fromBit, int toBit,
//                                     DWORD * value, int offset )
// Purpose: Get GPDATA contents with specified range of bits
// Input:   int fromBit - starting bit
//          int toBit   - ending bit
//          int offset  - how many registers to skip (default = 0)
// Output:  DWORD * value - value retrieved
// Return:  Success or Fail
// Comment: By specifying a range of bits to be set, it allows a portion of
//          the GDATA register to be retrieved. For example,
//             GetGPDATA( 8, 10, &data, 0 )
//          would set *data to the first GPDATA register's [10:8] content
/////////////////////////////////////////////////////////////////////////////
ErrorCode GPIO::GetGPDATA( int fromBit, int toBit, DWORD * value, int offset )
{
   // check size and offset for out of bound
   if ( ( fromBit < 0 ) || ( fromBit > MAX_GPIO_BIT ) ||
        ( toBit   < 0 ) || ( toBit   > MAX_GPIO_BIT ) || ( fromBit > toBit ) ||
        ( offset  < 0 ) || ( offset  > MAX_GPDATA_SIZE ) )
      return ( Fail );

   RegisterDW reg( decRegGPDATA.GetOffset() + offset * sizeof( GPIOReg ), RW );
   RegField field( reg, (BYTE)fromBit, (BYTE)(toBit - fromBit + 1), RW );
   *value = field;

   return ( Success );
}
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\drivers\wdm\capture\mini\bt848\fourcc.h ===
// $Header: G:/SwDev/WDM/Video/bt848/rcs/Fourcc.h 1.4 1998/04/29 22:43:33 tomz Exp $

#ifndef __FOURCC_H
#define __FOURCC_H

// copied from mmsystem.h
#define mmioFOURCC( ch0, ch1, ch2, ch3 )                                \
                ( (DWORD)(BYTE)(ch0) | ( (DWORD)(BYTE)(ch1) << 8 ) |    \
                ( (DWORD)(BYTE)(ch2) << 16 ) | ( (DWORD)(BYTE)(ch3) << 24 ) )


#define FCC_YUY2    mmioFOURCC( 'Y', 'U', 'Y', '2' )
#define FCC_Y41P    mmioFOURCC( 'Y', '4', '1', 'P' )
#define FCC_Y8      mmioFOURCC( 'Y', '8', ' ', ' ' )
#define FCC_422     mmioFOURCC( '4', '2', '2', ' ' )
#define FCC_411     mmioFOURCC( '4', '1', '1', ' ' )
#define FCC_YVU9    mmioFOURCC( 'Y', 'V', 'U', '9' )
#define FCC_YV12    mmioFOURCC( 'Y', 'V', '1', '2' )
#define FCC_VBI     0xf72a76e0L  //mmioFOURCC( 'V', 'B', 'I', ' ' )
#define FCC_UYVY    mmioFOURCC( 'U', 'Y', 'V', 'Y' )
#define FCC_RAW     mmioFOURCC( 'R', 'A', 'W', ' ' )
#define FCC_I420    mmioFOURCC( 'I', '4', '2', '0' )

#endif
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\drivers\wdm\capture\mini\bt848\field.h ===
// $Header: G:/SwDev/WDM/Video/bt848/rcs/Field.h 1.12 1998/05/08 18:18:51 tomz Exp $

#ifndef __FIELD_H
#define __FIELD_H

/* Type: VideoStream
 * Purpose: Identifies a video stream channel
 * Note: Not all of these are used today. It should be a fairly minor job to
 *   start using them, though
 */
typedef enum
{
   VS_Below = -1,
   VS_Field1, VS_Field2, VS_VBI1, VS_VBI2, VS_Analog, VS_CC, VS_EDS,
   VS_Raw,
   VS_Above
} VideoStream;

#define STREAM_IDX_CAPTURE 0
#define STREAM_IDX_PREVIEW 1
#define STREAM_IDX_VBI     2
#define STREAM_IDX_ANALOG  3


#include "mytypes.h"
#include "scaler.h"
#include "pscolspc.h"
#include "viddefs.h"
#include "queue.h"
#include "preg.h"
#include "chanifac.h"

const MaxProgsForField  = 2;

typedef Queue<DataBuf> VidBufQueue;

/* Class: Field
 * Purpose: Encapsulates the operation of a single video field provided by BtPisces
 * Attributes:
 * Operations:
 */

extern "C" VOID STREAMAPI AdapterCancelPacket(IN PHW_STREAM_REQUEST_BLOCK Srb);

class Field
{
   private:
      PsColorSpace  LocalColSpace_;
      VidBufQueue   *BufQue_;
      DWORD         dwPitch_;
      bool          Started_;
      int           SkipCount_;
      long          TimePerFrame_;
      LONGLONG      LapsedTime_;
      LONG          FrameTiming_;
      VideoStream   VidStrm_;

      // used to notify video channel
      ChanIface    *callback_;

      bool          Paired_;
      bool          ready_;

      // this is used by the video channel to report timestamps
      LONGLONG      InterruptCounter_;
      LONGLONG      FrameCounter_;

      RegField      &CaptureEnable_;

   public:

      bool         Interrupt_;

      Field( RegField &CapEn, RegBase *ColReg, RegBase *WordSwap,
         RegBase *ByteSwap );
      virtual ~Field() {}

      inline void CancelSrbList( )
      {
         while( !BufQue_->IsEmpty( ) )
         {
            DataBuf buf = BufQue_->Get();
            AdapterCancelPacket( buf.pSrb_ );
         }

         BufQue_->Flush();
      }

      void Notify( PVOID pTag, bool skipped )
         { if ( callback_ ) callback_->Notify( pTag, skipped ); }

      void SetStreamID( VideoStream );
      VideoStream GetStreamID();

      void ResetCounters();

      virtual ErrorCode SetAnalogWindow( MRect &r ) = 0;
      virtual void      GetAnalogWindow( MRect &r ) = 0;

      virtual ErrorCode SetDigitalWindow( MRect &r ) = 0;
      virtual void      GetDigitalWindow( MRect &r ) = 0;

      void  SetBufPitch( DWORD dwP ) { 
         dwPitch_ = dwP;
         DebugOut((1, "SetBufPitch(%d)\n", dwPitch_));
      }
      DWORD GetBufPitch()            { return dwPitch_; }

      virtual void  SetColorFormat( ColFmt aColor )
      { LocalColSpace_.SetColorFormat( aColor ); }

      virtual ColFmt  GetColorFormat()
      { return LocalColSpace_.GetColorFormat(); }

      DataBuf GetNextBuffer();

      void SetFrameRate( long time );
      void SetPaired( bool p );
      bool GetPaired();

      void SetReady( bool flag );
      bool GetReady();

      void SetBufQuePtr( VidBufQueue *pQ ) { BufQue_ = pQ; }
      VidBufQueue &GetCurrentQue() { return *BufQue_; }

      void SetCallback( ChanIface *iface ) { callback_ = iface;}

      State  Start();
      void   Stop();
      bool   IsStarted() { return Started_; }

      State  Skip();

      // called by the BtPiscess::ProcessRISCIntr()
      void GotInterrupt() { InterruptCounter_++; }

      void GetCounters( LONGLONG &FrameNo, LONGLONG &drop );

      void SetStandardTiming( LONG t );
      LONG GetStandardTiming();

};

/* Class: FieldWithScaler
 * Purpose: Adds scaling capability to a field
 * Attributes:
 * Operations:
 */
class FieldWithScaler : public Field
{
   private:
      Scaler LocalScaler_;

   public:
      FieldWithScaler( RegField &CapEn, VidField field, RegBase *ColReg,
         RegBase *WordSwap, RegBase *ByteSwap ) : LocalScaler_( field ),
      Field( CapEn, ColReg, WordSwap, ByteSwap ) {}

      virtual ErrorCode SetAnalogWindow( MRect &r ) { return LocalScaler_.SetAnalogWin( r ); }
      virtual void      GetAnalogWindow( MRect &r ) { LocalScaler_.GetAnalogWin( r ); }

      virtual ErrorCode SetDigitalWindow( MRect &r ) { return LocalScaler_.SetDigitalWin( r ); }
      virtual void      GetDigitalWindow( MRect &r ) { LocalScaler_.GetDigitalWin( r ); }

      void VideoFormatChanged( VideoFormat format );
      void TurnVFilter( State s );
};

/* Class: VBIField
 * Purpose: Encapsulates the operation of a VBI data 'field'
 * Attributes:
 * Operations:
 */
class VBIField : public Field
{
   private:
      DECLARE_VBIPACKETSIZE;
      DECLARE_VBIDELAY;

      MRect AnalogWin_;
      MRect DigitalWin_;

   public:
      VBIField( RegField &CapEn ) : Field( CapEn, NULL, NULL, NULL ),
      CONSTRUCT_VBIPACKETSIZE, CONSTRUCT_VBIDELAY
      {}

      virtual void  SetColorFormat( ColFmt ) {}
      virtual ColFmt  GetColorFormat() { return CF_VBI; };

      virtual ErrorCode SetAnalogWindow( MRect &r ) { AnalogWin_ = r; return Success; }
      virtual void      GetAnalogWindow( MRect &r ) { r = AnalogWin_; }

      virtual ErrorCode SetDigitalWindow( MRect &r )
      {
         DigitalWin_ = r;
         DWORD dwNoOfDWORDs = r.Width() / 4;
//         SetBufPitch( r.Width() * ColorSpace( CF_VBI ).GetBitCount() / 8 );
         VBI_PKT_LO = (BYTE)dwNoOfDWORDs;
         VBI_PKT_HI = dwNoOfDWORDs > 0xff; // set the 9th bit
         VBI_HDELAY = r.left;
         return Success;
      }
      virtual void  GetDigitalWindow( MRect &r ) { r = DigitalWin_; }

      ~VBIField() {}
};

inline Field::Field( RegField &CapEn, RegBase *ColReg, RegBase *WordSwap,
   RegBase *ByteSwap ) : SkipCount_( 0 ), CaptureEnable_( CapEn ),
   LocalColSpace_( CF_RGB32, *ColReg, *WordSwap, *ByteSwap ),
   Started_( false ), callback_( NULL ), BufQue_( NULL ), dwPitch_( 0 ),
   TimePerFrame_( 333667 ), LapsedTime_( 0 ),InterruptCounter_( 0 ),
   FrameCounter_( 0 ), Interrupt_( true ), FrameTiming_( 333667 )
{
   
}

/* Method: Field::SetFrameRate
 * Purpose: Sets frame rate
 * Input: time: long, time in 100s nanoseconds per frame
 */
inline void Field::SetFrameRate( long time )
{
   TimePerFrame_ = time;

   // this is needed to make sure very first get returns a buffer
   LapsedTime_ = time;
}

inline void Field::SetStreamID( VideoStream st )
{
   VidStrm_ = st;
}

inline VideoStream Field::GetStreamID()
{
   return VidStrm_;
}

inline void Field::SetPaired( bool p )
{
   Paired_ = p;
}

inline bool Field::GetPaired()
{
   return Paired_;
}

inline void Field::GetCounters( LONGLONG &FrameNo, LONGLONG &drop )
{
   // Frame number is what frame index we should be on.
   // Use interrupt count, not just frames returned.
   FrameNo = InterruptCounter_;

   // Drop count = number of interrupts - number of completed buffers
   drop = InterruptCounter_ - FrameCounter_;
   
   if ( drop > 0 )
   {
      drop--;

      // We've reported the drops, so show frame count as caught
      // up to interrupt count
      FrameCounter_ += drop;
      DebugOut((1, "%d,", drop));
   }
   else if ( drop < 0 )
   {
     DebugOut((1, "*** %d ***,", drop));
   }
   else
   {
      DebugOut((1, "0,"));
   }
}

inline void Field::ResetCounters()
{
   FrameCounter_ = InterruptCounter_ = 0;
}

inline void Field::SetReady( bool flag )
{
   ready_ = flag;
}

inline bool Field::GetReady()
{
   return ready_;
}

inline void Field::SetStandardTiming( LONG t )
{
   FrameTiming_ = t;
}

inline LONG Field::GetStandardTiming()
{
   return FrameTiming_;
}

/* Method: Field::GetNextBuffer
 * Purpose: Returns next buffer from the queue, if time is correct for it.
 * Input: None
 */
inline DataBuf Field::GetNextBuffer()
{
   // that's how long it takes to capture a frame of video
   LapsedTime_ += GetStandardTiming();
   DataBuf buf;

   // [TMZ] [!!!] - hack, disable wait 'cause it doesn't work

   //if ( LapsedTime_ >= TimePerFrame_ ) {
   if ( 1 ) {

      // have to increment the frame number if we want that frame only
      if ( IsStarted() ) {
         GotInterrupt();
      }

//#define  FORCE_BUFFER_SKIP_TESTING
#ifdef   FORCE_BUFFER_SKIP_TESTING
      static int iTestSkip = 0;
      BOOL bEmpty = BufQue_->IsEmpty();
      DebugOut((0, "Queue(%x) bEmpty = %d\n", BufQue_, bEmpty));
      if ( iTestSkip++ & 1 ) {
         // Every other query should look like the buffer is empty.
         bEmpty = TRUE;
         DebugOut((1, "  [override] set bEmpty = %d\n", bEmpty));
      }
      if ( !bEmpty ) {
         buf = BufQue_->Get();
         DebugOut((1, "  GotBuf addr %X\n", buf.pData_ ) );
         LapsedTime_ = 0;
         FrameCounter_++;
      } else {
         DebugOut((1, "  No buffer in que at %d\n",LapsedTime_));
         if ( !IsStarted() ) {
            InterruptCounter_--;
            FrameCounter_--;
         }
      }
#else
      if ( !BufQue_->IsEmpty() ) {
         buf = BufQue_->Get();
         DebugOut((1, "GotBuf addr %X\n", buf.pData_ ) );
         LapsedTime_ = 0;
         FrameCounter_++;
      } else {
         DebugOut((1, "No buffer in que at %d\n",LapsedTime_));
         if ( !IsStarted() ) {
            InterruptCounter_--;
            FrameCounter_--;
         }
      }
#endif
   }
   DebugOut((1, "returning buf {pSrb=%x, pData=%x}\n", buf.pSrb_, buf.pData_ ) );
   return buf;
}

/* Method: Field::Start
 * Purpose: Initiates the data flow out of decoder into the FIFO
 * Input: None
 * Output: State: Off if channel was off; On if channel was on
 */
inline State Field::Start()
{
   Trace t("Field::Start()");

   Started_ = true;
   State RetVal = SkipCount_ >= MaxProgsForField ? Off : On;
   SkipCount_--;
   if ( SkipCount_ < 0 )
      SkipCount_ = 0;
   CaptureEnable_ = On;
   return RetVal;
}

inline  void  Field::Stop()
{
   Trace t("Field::Stop()");

   Started_ = false;
   CaptureEnable_ = Off;
   LapsedTime_ = TimePerFrame_;
}

/* Method: Field::Skip
 * Purpose: Increments the skip count and stops the data flow if it exceeds the max
 * Input: None
 * Output: State: Off if channel is stopped; On if channel remains running
 */
inline State Field::Skip()
{
   Trace t("Field::Skip()");

   SkipCount_++;
   if ( SkipCount_ >= MaxProgsForField ) {
      Stop();
      return Off;
   }
   return On;
}

inline void FieldWithScaler::VideoFormatChanged( VideoFormat format )
{
   LocalScaler_.VideoFormatChanged( format );
}

inline void FieldWithScaler::TurnVFilter( State s )
{
   LocalScaler_.TurnVFilter( s );
}


#endif
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\drivers\wdm\capture\mini\bt848\gpiotype.h ===
// $Header: G:/SwDev/WDM/Video/bt848/rcs/Gpiotype.h 1.2 1998/04/29 22:43:33 tomz Exp $

#ifndef __GPIOTYPE_H
#define __GPIOTYPE_H


//===========================================================================
// TYPEDEFS for GPIO
//===========================================================================

// GPIO modes
typedef enum { GPIO_NORMAL,
               GPIO_SPI_OUTPUT,
               GPIO_SPI_INPUT,
               GPIO_DEBUG_TEST } GPIOMode;

typedef DWORD GPIOReg;    // GPIO register type

#endif // __GPIOTYPE_H
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\drivers\wdm\capture\mini\bt848\gpio.h ===
// $Header: G:/SwDev/WDM/Video/bt848/rcs/Gpio.h 1.2 1998/04/29 22:43:33 tomz Exp $


#ifndef __GPIO_H
#define __GPIO_H

#include "regField.h"
#include "viddefs.h"
#include "gpiotype.h"
#include "retcode.h"


//===========================================================================
// Constants
//===========================================================================
const int MAX_GPDATA_SIZE = 64;   // maximum number of DWORDs in GPDATA
const int MAX_GPIO_BIT    = 23;   // maximum bit number for GPIO registers


/////////////////////////////////////////////////////////////////////////////
// CLASS GPIO
//
// Description:
//    This class encapsulates the register fields in the GPIO register of the
//    Bt848. A complete set of functions are developed to manipulate all the
//    register fields in the GPIO for the Bt848.
//
/////////////////////////////////////////////////////////////////////////////

class GPIO
{
private:
   bool initOK;

public:
   //  Constructor
   GPIO( void );
   ~GPIO();

   // Member functions
   bool      IsInitOK( void );
   void      SetGPCLKMODE( State );
   int       GetGPCLKMODE( void );
   void      SetGPIOMODE( GPIOMode );
   int       GetGPIOMODE( void );
   void      SetGPWEC( State );
   int       GetGPWEC( void );
   void      SetGPINTI( State );
   int       GetGPINTI( void );
   void      SetGPINTC( State );
   int       GetGPINTC( void );
   ErrorCode SetGPOE( int, State );
   void      SetGPOE( DWORD );
   int       GetGPOE( int );
   DWORD     GetGPOE( void );
   ErrorCode SetGPIE( int, State );
   void      SetGPIE( DWORD );
   int       GetGPIE( int );
   DWORD     GetGPIE( void );
   ErrorCode SetGPDATA( GPIOReg *, int, int offset = 0 );
   ErrorCode GetGPDATA( GPIOReg *, int, int offset = 0 );
   ErrorCode SetGPDATA( int, int, DWORD, int offset = 0 );
   ErrorCode GetGPDATA( int, int, DWORD *, int offset = 0 );

protected:
   RegisterW decRegGPIO;
   RegField decFieldGPCLKMODE;
   RegField decFieldGPIOMODE;
   RegField decFieldGPWEC;
   RegField decFieldGPINTI;
   RegField decFieldGPINTC;
   RegisterDW decRegGPOE;
   RegisterDW decRegGPIE;
   RegisterDW decRegGPDATA;
 
};

#endif  // __GPIO_H
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\drivers\wdm\capture\mini\bt848\i2c.cpp ===
// $Header: G:/SwDev/WDM/Video/bt848/rcs/I2c.cpp 1.6 1998/05/08 18:18:52 tomz Exp $

//===========================================================================
// I2C DATA/CONTROL REGISTER API
//===========================================================================
										     
#include "bti2c.h"	  

//**************************************************************************
//	DEFINES
//**************************************************************************
#define I2C_WRITE         0         // write operation
#define I2C_READ          1         // read operation

#define PCI_FREQ          33000000L // frequency for PCI in hz
#define I2CDIV_MAX        15        // I2C maximum divider

#define TIMEOUT           500       // timeout value (500ms) to wait for an I2C operation
                                    // passing 3 values to I2C takes ~450ms

#ifdef HAUPPAUGEI2CPROVIDER
extern "C" ULONG GetTickCount( void );
#endif

// Let me know at compile time what i2c setup I'm building
#if SHOW_BUILD_MSGS
   #ifdef HAUPPAUGEI2CPROVIDER
      #pragma message("*** using 'Hauppauge' i2c code")
   #else
      #pragma message("*** not using 'Hauppauge' i2c code")
   #endif

   #ifdef HARDWAREI2C
      #pragma message("*** using hardware i2c code")
   #else
      #pragma message("*** not using hardware i2c code")
   #endif
#endif

//===========================================================================
// Bt848 I2C Class Implementation
//===========================================================================

/////////////////////////////////////////////////////////////////////////////
// Constructor
/////////////////////////////////////////////////////////////////////////////
I2C::I2C( void ) :
   // construct I2C register and register fields
   decRegINT_STAT ( 0x100, RW ),    // Interrupt Status register
   decFieldI2CDONE( decRegINT_STAT, 8, 1, RR ),
   decFieldRACK( decRegINT_STAT, 25, 1, RO ),
   decRegI2C ( 0x110, RW ),              // I2C Data/Control register
   decFieldI2CDB0( decRegI2C, 24, 8, RW ),
   decFieldI2CDB1( decRegI2C, 16, 8, RW ),
   decFieldI2CDB2( decRegI2C,  8, 8, RW ),
   decFieldI2CDIV( decRegI2C,  4, 4, RW),
   decFieldSYNC( decRegI2C, 3, 1, RW),
   decFieldW3B( decRegI2C, 2, 1, RW),
   decFieldSCL( decRegI2C, 1, 1, RW),
   decFieldSDA( decRegI2C, 0, 1, RW)
{
   initOK = false;
   cycle  = 0L;
   errNum = I2CERR_OK;
   mode   = I2CMode_None;
}

/////////////////////////////////////////////////////////////////////////////
// Destructor
/////////////////////////////////////////////////////////////////////////////
I2C::~I2C()
{
}


/////////////////////////////////////////////////////////////////////////////
//  Method:  bool I2C::IsInitOK( void )
//  Purpose: Check if I2C is initialized successfully
//  Input:   None
//  Output:  None
//  Return:  true or false
/////////////////////////////////////////////////////////////////////////////
bool I2C::IsInitOK( void )
{
   // initialize I2C register shadow
   I2CResetShadow();

   initOK = true;
   return( initOK );
}

#ifdef	HARDWAREI2C                                                         
/////////////////////////////////////////////////////////////////////////////
//  Method:  ErrorCode I2C::I2CInitHWMode( long freq )
//  Purpose: Initialize I2C for hardware control of SCL and SDA
//  Input:   long freq - frequency (hz) to run SCL at
//  Output:  None
//  Return:  None
/////////////////////////////////////////////////////////////////////////////
ErrorCode I2C::I2CInitHWMode( long freq )
{
   // initialization was successful?
   if ( initOK != true )
   {
      errNum = I2CERR_INIT;
      return Fail;
   }
   
   // initialize I2C register shadow
   I2CResetShadow();

   decFieldSCL = sh.i2cShadow.scl = 1;   // must be 1 for hardware mode
   decFieldSDA = sh.i2cShadow.sda = 1;   // must be 1 for hardware mode

   I2CSetFreq( freq );   // set frequency for hardware control

   // I2C is running hardware mode
   mode = I2CMode_HW;
   return Success;
}
#endif

/////////////////////////////////////////////////////////////////////////////
//  Method:  void I2C::I2CSetFreq( long freq )
//  Purpose: Set frequency for SCL
//  Input:   long freq - frequency (hz) to run SCL at. (137.5khz to 2.0625Mhz)
//             PCI frequency 33Mhz: SCL = (412.50Khz to 33.81Khz)
//                           25Mhz: SCL = (312.50Khz to 25.61Khz)
//  Output:  None
//  Return:  None
/////////////////////////////////////////////////////////////////////////////
void I2C::I2CSetFreq( long freq )
{
	unsigned int i2cdiv;

	// avoid division errors
	if( freq > 1 )
		i2cdiv = (unsigned int) (PCI_FREQ / (64 * freq));
	else
		i2cdiv = 0;

	if( i2cdiv > I2CDIV_MAX )
		i2cdiv = I2CDIV_MAX;

	decFieldI2CDIV = sh.i2cShadow.div = i2cdiv;
}

#ifdef	HARDWAREI2C                                                         

/////////////////////////////////////////////////////////////////////////////
//  Method:  int I2C::I2CReadDiv( void )
//  Purpose: Obtain value of programmable divider
//  Input:   None
//  Output:  None
//  Return:  Value of programmable divider
/////////////////////////////////////////////////////////////////////////////
int I2C::I2CReadDiv( void )
{
	return decFieldI2CDIV;
}

/////////////////////////////////////////////////////////////////////////////
//  Method:  ErrorCode I2C::I2CHWRead( BYTE address, BYTE *value )
//  Purpose: Perform a hardware read from the I2C
//  Input:   int address - address to be read from
//  Output:  int *value  - retrieved value
//  Return:  Success or Fail
/////////////////////////////////////////////////////////////////////////////
ErrorCode I2C::I2CHWRead( BYTE address, BYTE *value )
{
   // check if correct mode is selected
   if ( mode != I2CMode_HW )
   {
      errNum = I2CERR_MODE;
      return Fail;
   }

   shadow::_i2c_reg i2cTemp = sh.i2cShadow;   // obtain previous settings that didn't change

   // see above for reasons of doing all these.
   i2cTemp.addr_rw = address | I2C_READ;
   i2cTemp.byte1   = 0;
   i2cTemp.byte2   = 0;
   i2cTemp.w3b     = 0;

   decRegI2C = *(DWORD *)&i2cTemp;

   if ( I2CHWWaitUntilDone( TIMEOUT ) == Fail )
   {
      errNum = I2CERR_TIMEOUT;
      return Fail;
   }

   *value = (BYTE) decFieldI2CDB2;   // returned value is in 3rd byte

   if ( I2CHWReceivedACK() == true )
      return Success;
   else
   {
      errNum = I2CERR_NOACK;
      return Fail;
   }
}

/////////////////////////////////////////////////////////////////////////////
//  Method:  ErrorCode I2C::I2CHWWrite2( BYTE address, BYTE value1 )
//  Purpose:  Perform a hardware write of two bytes to the I2C
//  Input:   int address - address to be written to
//           int value1  - value of 2nd byte to be written
//  Output:  None
//  Return:  Success or Fail
/////////////////////////////////////////////////////////////////////////////
ErrorCode I2C::I2CHWWrite2( BYTE address, BYTE value1 )
{
   // check if correct mode is selected
   if ( mode != I2CMode_HW )
   {
      errNum = I2CERR_MODE;
      return Fail;
   }
   
   shadow::_i2c_reg i2cTemp = sh.i2cShadow;   // obtain previous settings that didn't change

   // see above for reasons of doing all these.
	i2cTemp.addr_rw = address | I2C_WRITE;
	i2cTemp.byte1   = value1;
	i2cTemp.byte2   = 0;
	i2cTemp.w3b     = 0;

   decRegI2C = *(DWORD *)&i2cTemp;

   if ( I2CHWWaitUntilDone( TIMEOUT ) == Fail )
   {
      errNum = I2CERR_TIMEOUT;
      return Fail;
   }

   if ( I2CHWReceivedACK() == true )
      return Success;
   else
   {
      errNum = I2CERR_NOACK;
      return Fail;
   }
}

/////////////////////////////////////////////////////////////////////////////
//  Method:  ErrorCode I2C::I2CHWWrite3( BYTE address, BYTE value1, BYTE value2 )
//  Purpose: Perform a hardware write of three bytes to the I2C
//  Input:   int address - address to be written to
//           int value1  - value of 2nd byte to be written
//           int value2  - value of 3rd byte to be written
//  Output:  None
//  Return:  Success or Fail
/////////////////////////////////////////////////////////////////////////////
ErrorCode I2C::I2CHWWrite3( BYTE address, BYTE value1, BYTE value2 )
{
   // check if correct mode is selected
   if ( mode != I2CMode_HW )
   {
      errNum = I2CERR_MODE;
      return Fail;
   }
   
   shadow::_i2c_reg i2cTemp = sh.i2cShadow;   // obtain previous settings that didn't change

   // see above for reasons of doing all these.
	i2cTemp.addr_rw = address | I2C_WRITE;
	i2cTemp.byte1   = value1;
	i2cTemp.byte2   = value2;
	i2cTemp.w3b     = 1;

   decRegI2C = *(DWORD *)&i2cTemp;

	if ( I2CHWWaitUntilDone( TIMEOUT ) == Fail )
   {
      errNum = I2CERR_TIMEOUT;
      return Fail;
   }

   if ( I2CHWReceivedACK() == true )
      return Success;
   else
   {
      errNum = I2CERR_NOACK;
      return Fail;
   }
}



/////////////////////////////////////////////////////////////////////////////
//  Method:  int I2C::I2CReadSync( void )
//  Purpose: Read I2C sync value
//  Input:   None
//  Output:  None
//  Return:  Sync value
/////////////////////////////////////////////////////////////////////////////
int I2C::I2CReadSync( void )
{
   return decFieldSYNC;
}

#endif

/////////////////////////////////////////////////////////////////////////////
//  Method:  int I2C::I2CGetLastError( void )
//  Purpose: Obtain last I2C error number
//  Input:   None
//  Output:  None
//  Return:  Last I2C error number
/////////////////////////////////////////////////////////////////////////////
int I2C::I2CGetLastError( void )
{
   return errNum;
}

//============================================================================
// Following functions are used internally
//============================================================================

/////////////////////////////////////////////////////////////////////////////
//  Method:  void I2C::I2CResetShadow( void )
//  Purpose: Reset register shadow
//  Input:   int maxWait - maximum waiting time in milliseconds
//  Output:  None
//  Return:  Success if done; Fail if timeout
/////////////////////////////////////////////////////////////////////////////
void I2C::I2CResetShadow( void )
{
   // initialize I2C register shadow
   sh.Initer = 0;
}
   
/////////////////////////////////////////////////////////////////////////////
//  Method:  ErrorCode I2C::I2CHWWaitUntilDone( int maxWait )
//  Purpose: Wait for hardware I2C to finish
//  Input:   int maxWait - maximum waiting time in milliseconds
//  Output:  None
//  Return:  Success if done; Fail if timeout
/////////////////////////////////////////////////////////////////////////////
ErrorCode I2C::I2CHWWaitUntilDone( int maxWait )
{
//   DWORD startTime = GetTickCount();

   // loop until either I2CDONE is set or timeout
   while (1)
   {
      if ( I2CHWIsDone() == true )
         return Success;
#if 0
      // timeout?
      if ( GetTickCount() - startTime > (DWORD)maxWait )
      {
         errNum = I2CERR_TIMEOUT;
         return Fail;
      }
#endif
   }
}

/////////////////////////////////////////////////////////////////////////////
//  Method:  bool I2C::I2CHWIsDone( void )
//  Purpose: Determine if I2C has finished a read or write operation by
//           checking the I2CDONE bit in the interrupt status register
//  Input:   None
//  Output:  None
//  Return:  true if done; else false
/////////////////////////////////////////////////////////////////////////////
bool I2C::I2CHWIsDone( void )
{
   if ( decFieldI2CDONE != 0 )
   {
      // Need to clear the bit when it is set; don't want to alter any other bits
      // Writing a 1 to the bit clears it.
      decFieldI2CDONE = 1;
      return true;
   }
   else
      return false;
}

/////////////////////////////////////////////////////////////////////////////
//  Method:  bool I2C::I2CHWReceivedACK( void )
//  Purpose: Determine if ACK is receieved
//  Input:   None
//  Output:  None
//  Return:  true if ACK received; else false
/////////////////////////////////////////////////////////////////////////////
bool I2C::I2CHWReceivedACK( void )
{
   return ( ( decFieldRACK != 0 ) ? true : false );
}

#ifdef HAUPPAUGEI2CPROVIDER
/////////////////////////////////////////////////////////////////////////////
//  Method:  ErrorCode I2C::I2CInitSWMode( long freq )
//  Purpose: Initialize I2C for software control of SCL and SDA
//  Input:   long freq - frequency (hz) to run SCL at
//  Output:  None
//  Return:  None
//  Note:    After calling I2CIsInitOK(), application should call this
//           function and check for return value is Success before starting
//           software communication.
/////////////////////////////////////////////////////////////////////////////
ErrorCode I2C::I2CInitSWMode( long freq )
{
   // initialization was successful?
   if ( initOK != true )
   {
      errNum = I2CERR_INIT;
      return Fail;
   }

   // initialize I2C register shadow
   I2CResetShadow();

	decFieldSCL = sh.i2cShadow.scl = 1;
	decFieldSDA = sh.i2cShadow.sda = 1;

	I2CSetFreq( 0 );        // set frequency to 0 for software control

   // need to calibrate in order to generate the correct clock cycle
   // the approach is to calculate how many dummy loop we need in order to
   // generate a cycle that is 2 * freq * 1000 Hz
   cycle  = 10000L;        // use a large number to start
   DWORD elapsed = 0L;
   while ( elapsed < 5 )      // loop until delay is long enough for calculation
   {
      cycle *= 10;
      DWORD start = GetTickCount();
      for ( volatile DWORD i = cycle; i > 0; i-- )
         ;
      elapsed = GetTickCount() - start;
   }
   if ( freq > 1 )
      cycle = cycle / elapsed * 1000L / freq / 2;
      
   // I2C is running software mode
   mode = I2CMode_SW;
   return Success;
}

/////////////////////////////////////////////////////////////////////////////
//  Method:  ErrorCode I2C::I2CSWStart( void )
//  Purpose: Generate START condition using software control
//  Input:   None
//  Output:  None
//  Return:  Success or Fail
/////////////////////////////////////////////////////////////////////////////
ErrorCode I2C::I2CSWStart( void )
{
   // check if correct mode is selected
   if ( mode != I2CMode_SW )
   {
      errNum = I2CERR_MODE;
      return Fail;
   }
   
   // SendStart - send an I2c start
   // i.e. SDA 1 -> 0 with SCL = 1

   if ( I2CSWSetSDA( LevelHi )  != Success ) { errNum = I2CERR_SDA; return Fail; }
   if ( I2CSWSetSCL( LevelHi )  != Success ) { errNum = I2CERR_SCL; return Fail; }
   if ( I2CSWSetSDA( LevelLow ) != Success ) { errNum = I2CERR_SDA; return Fail; }
   if ( I2CSWSetSCL( LevelLow ) != Success ) { errNum = I2CERR_SCL; return Fail; }
   return Success;
}                  

/////////////////////////////////////////////////////////////////////////////
//  Method:  ErrorCode I2C::I2CSWStop( void )
//  Purpose: Generate STOP condition using software control
//  Input:   None
//  Output:  None
//  Return:  Success or Fail
/////////////////////////////////////////////////////////////////////////////
ErrorCode I2C::I2CSWStop( void )
{
   // check if correct mode is selected
   if ( mode != I2CMode_SW )
   {
      errNum = I2CERR_MODE;
      return Fail;
   }
   
   // SendStop - sends an I2C stop, releasing the bus.
   // i.e. SDA 0 -> 1 with SCL = 1

   if ( I2CSWSetSCL( LevelLow ) != Success ) { errNum = I2CERR_SCL; return Fail; }
   if ( I2CSWSetSDA( LevelLow ) != Success ) { errNum = I2CERR_SDA; return Fail; }
   if ( I2CSWSetSCL( LevelHi )  != Success ) { errNum = I2CERR_SCL; return Fail; }
   if ( I2CSWSetSDA( LevelHi )  != Success ) { errNum = I2CERR_SDA; return Fail; }
   return Success;
}

/////////////////////////////////////////////////////////////////////////////
//  Method:  ErrorCode I2C::I2CSWRead( BYTE * value )
//  Purpose: Read a byte from the slave
//  Input:   None
//  Output:  BYTE * value - byte read from slave
//  Return:  Success or Fail
/////////////////////////////////////////////////////////////////////////////
ErrorCode I2C::I2CSWRead( BYTE * value )
{
   // check if correct mode is selected
   if ( mode != I2CMode_SW )
   {
      errNum = I2CERR_MODE;
      return Fail;
   }
   
   *value = 0x00;   

   // read 8 bits from I2c into Accumulator
   for( BYTE mask = 0x80; mask > 0; mask = (BYTE)( mask >> 1 ) )
   {
      if ( I2CSWSetSCL( LevelLow ) != Success ) { errNum = I2CERR_SCL; return Fail; }
      if ( I2CSWSetSCL( LevelHi )  != Success ) { errNum = I2CERR_SCL; return Fail; }
      if ( I2CSWReadSDA() == TRUE )
         *value = (BYTE)( *value | mask ); // set the bit
   }
   return Success;
}

/////////////////////////////////////////////////////////////////////////////
//  Method:  ErrorCode I2C::I2CSWWrite( BYTE value )
//  Purpose: Write a byte to the slave
//  Input:   BYTE value - byte to be written to slave
//  Output:  None
//  Return:  Success or Fail
/////////////////////////////////////////////////////////////////////////////
ErrorCode I2C::I2CSWWrite( BYTE value )
{
   // check if correct mode is selected
   if ( mode != I2CMode_SW )
   {
      errNum = I2CERR_MODE;
      return Fail;
   }

   // generate bit patterns by setting SCL and SDA lines
   for ( BYTE mask = 0x80; mask > 0; mask = (BYTE)(mask >> 1) )
   {                                          
      if ( I2CSWSetSCL( LevelLow ) != Success ) { errNum = I2CERR_SCL; return Fail; }

      // Send one data bit.
      if ( value & mask ) // Put data bit on pin.
      {
         if ( I2CSWSetSDA( LevelHi ) != Success ) { errNum = I2CERR_SDA; return Fail; }
      }
      else 
      {
         if ( I2CSWSetSDA( LevelLow ) != Success ) { errNum = I2CERR_SDA; return Fail; }
      }
          
      if ( I2CSWSetSCL( LevelHi ) != Success ) { errNum = I2CERR_SCL; return Fail; }
   }

   return I2CSWWaitForACK();
}

/////////////////////////////////////////////////////////////////////////////
//  Method:  ErrorCode I2C::I2CSWSendACK( void )
//  Purpose: Send ACK to slave
//  Input:   None
//  Output:  None
//  Return:  Success or Fail
/////////////////////////////////////////////////////////////////////////////
ErrorCode I2C::I2CSWSendACK( void )
{
   // check if correct mode is selected
   if ( mode != I2CMode_SW )
   {
      errNum = I2CERR_MODE;
      return Fail;
   }
   
   // Generate ACK signal
   // i.e. SDA = 0 with SCL = 1

   if ( I2CSWSetSCL( LevelLow ) != Success ) { errNum = I2CERR_SCL; return Fail; }
   if ( I2CSWSetSDA( LevelLow ) != Success ) { errNum = I2CERR_SDA; return Fail; }
   if ( I2CSWSetSCL( LevelHi )  != Success ) { errNum = I2CERR_SCL; return Fail; }
   if ( I2CSWSetSCL( LevelLow ) != Success ) { errNum = I2CERR_SCL; return Fail; }
   if ( I2CSWSetSDA( LevelHi )  != Success ) { errNum = I2CERR_SDA; return Fail; }
   return Success;
}                  

/////////////////////////////////////////////////////////////////////////////
//  Method:  ErrorCode I2C::I2CSWSendNACK( void )
//  Purpose: Send NACK to slave
//  Input:   None
//  Output:  None
//  Return:  Success or Fail
/////////////////////////////////////////////////////////////////////////////
ErrorCode I2C::I2CSWSendNACK( void )
{
   // check if correct mode is selected
   if ( mode != I2CMode_SW )
   {
      errNum = I2CERR_MODE;
      return Fail;
   }
   
   // Generate NACK signal
   // i.e. SDA = 1 with SCL = 1

   if ( I2CSWSetSCL( LevelLow ) != Success ) { errNum = I2CERR_SCL; return Fail; }
   if ( I2CSWSetSDA( LevelHi )  != Success ) { errNum = I2CERR_SDA; return Fail; }
   if ( I2CSWSetSCL( LevelHi )  != Success ) { errNum = I2CERR_SCL; return Fail; }
   if ( I2CSWSetSCL( LevelLow ) != Success ) { errNum = I2CERR_SCL; return Fail; }
   if ( I2CSWSetSDA( LevelLow ) != Success ) { errNum = I2CERR_SDA; return Fail; }
   return Success;
}                  

/////////////////////////////////////////////////////////////////////////////
//  Method:  ErrorCode I2C::I2CSWSetSCL( Level scl )
//  Purpose: Set software SCL value
//  Input:   Level scl - Hi releases the SCL output; Low forces the SCL output low
//  Output:  None
//  Return:  Success or Fail
/////////////////////////////////////////////////////////////////////////////
ErrorCode I2C::I2CSWSetSCL( Level scl )
{
   // check if correct mode is selected
   if ( mode != I2CMode_SW )
   {
      errNum = I2CERR_MODE;
      return Fail;
   }
   
	sh.i2cShadow.scl = scl;
   decRegI2C = *(DWORD *)&(sh.i2cShadow);

   // loop until SCL really changes or timeout
   DWORD maxWait = 500; // 500 mSec
   DWORD startTime = GetTickCount();
  
   while (1)
   {
      // has SCL changed yet?
      if ( I2CSWReadSCL() == scl )
         break;

      // timeout?
      if ( GetTickCount() - startTime > (DWORD)maxWait )
      {
         errNum = I2CERR_TIMEOUT;
         return Fail;
      }
   }

   I2CSWBitDelay();
   return Success;
}

/////////////////////////////////////////////////////////////////////////////
//  Method:  int I2C::I2CSWReadSCL( void )
//  Purpose: Read software SCL value
//  Input:   None
//  Output:  None
//  Return:  SCL value
/////////////////////////////////////////////////////////////////////////////
int I2C::I2CSWReadSCL( void )
{
	return decFieldSCL;
}

/////////////////////////////////////////////////////////////////////////////
//  Method:  ErrorCode I2C::I2CSWSetSDA( Level sda )
//  Purpose: Set software SDA value
//  Input:   Level sda - Hi releases the SDA output; Low forces the SDA output low
//  Output:  None
//  Return:  Success or Fail
/////////////////////////////////////////////////////////////////////////////
ErrorCode I2C::I2CSWSetSDA( Level sda )
{
   // check if correct mode is selected
   if ( mode != I2CMode_SW )
   {
      errNum = I2CERR_MODE;
      return Fail;
   }
   
	sh.i2cShadow.sda = sda;
   decRegI2C = *(DWORD *)&(sh.i2cShadow);

   I2CSWBitDelay();
   return Success;
}

/////////////////////////////////////////////////////////////////////////////
//  Method:  int I2C::I2CSWReadSDA( void )
//  Purpose: Read software SDA value
//  Input:   None
//  Output:  None
//  Return:  SDA value
/////////////////////////////////////////////////////////////////////////////
int I2C::I2CSWReadSDA( void )
{
	return decFieldSDA;
}


/////////////////////////////////////////////////////////////////////////////
//  Method:  void I2C::I2CSWBitDelay( void )
//  Purpose: Insures minimum high and low clock times on I2C bus.
//  Input:   None
//  Output:  None
//  Return:  None
//  Note:    This routine must be tuned for the desired frequency.
/////////////////////////////////////////////////////////////////////////////
void I2C::I2CSWBitDelay( void )
{
  //  unsigned int n;
  volatile DWORD i ;
  for ( i = cycle; i > 0; i-- )
    ;
}

/////////////////////////////////////////////////////////////////////////////
//  Method:  ErrorCode I2C::I2CSWWaitForACK( void )
//  Purpose: Determine if ACK is receieved in software mode
//  Input:   None
//  Output:  None
//  Return:  Success if ACK received; Fail if timeout
/////////////////////////////////////////////////////////////////////////////
ErrorCode I2C::I2CSWWaitForACK( void )
{
   if ( I2CSWSetSCL( LevelLow ) != Success ) { errNum = I2CERR_SCL; return Fail; }
   if ( I2CSWSetSDA( LevelHi )  != Success ) { errNum = I2CERR_SDA; return Fail; }

   // loop until either ACK or timeout
   DWORD maxWait = 500; // 500 mSec
   DWORD startTime = GetTickCount();

   while (1)
   {
      // SDA pin == 0 means the slave ACK'd
      if ( I2CSWReadSDA() == 0 )
      {
         if ( I2CSWSetSCL( LevelHi )  != Success ) { errNum = I2CERR_SCL; return Fail; }
         if ( I2CSWSetSCL( LevelLow ) != Success ) { errNum = I2CERR_SCL; return Fail; }
         return Success;
      }

      // timeout?
      if ( GetTickCount() - startTime > (DWORD)maxWait )
      {
         if ( I2CSWStop() != Success ) return Fail;
         errNum = I2CERR_TIMEOUT;
         return Fail;
      }
   } // while
}


//
// GetSystemTime in 100 nS units
//

ULONGLONG GetSystemTime()
{
    ULONGLONG ticks;
    ULONGLONG rate;

    ticks = (ULONGLONG)KeQueryPerformanceCounter((PLARGE_INTEGER)&rate).QuadPart;

    //
    // convert from ticks to 100ns clock
    //

    ticks = (ticks & 0xFFFFFFFF00000000) / rate * 10000000 +
            (ticks & 0xFFFFFFFF) * 10000000 / rate;

    return(ticks);

}

extern "C" ULONG GetTickCount( void )
{
	return (ULONG)( GetSystemTime() / 10000 );
}

#endif
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\drivers\wdm\capture\mini\bt848\i2cerr.h ===
// $Header: G:/SwDev/WDM/Video/bt848/rcs/I2cerr.h 1.2 1998/04/29 22:43:34 tomz Exp $

#ifndef __I2CERR_H
#define __I2CERR_H

const int I2CERR_OK        = 0;     // no error
const int I2CERR_INIT      = 1;     // error in initialization
const int I2CERR_MODE      = 2;     // invalid I2C mode (must be either HW or SW)
const int I2CERR_NOACK     = 3;     // no ACK received from slave
const int I2CERR_TIMEOUT   = 4;     // timeout error
const int I2CERR_SCL       = 5;     // unable to change SCL line
const int I2CERR_SDA       = 6;     // unable to change SDA line

#endif   // __I2CERR_H
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\drivers\wdm\capture\mini\bt848\ourcrt.cpp ===
// $Header: G:/SwDev/WDM/Video/bt848/rcs/Ourcrt.cpp 1.2 1998/04/29 22:43:34 tomz Exp $

//==========================================================================;
//
//  THIS CODE AND INFORMATION IS PROVIDED "AS IS" WITHOUT WARRANTY OF ANY
//  KIND, EITHER EXPRESSED OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE
//  IMPLIED WARRANTIES OF MERCHANTABILITY AND/OR FITNESS FOR A PARTICULAR
//  PURPOSE.
//
//  Copyright (c) 1992 - 1996  Microsoft Corporation.  All Rights Reserved.
//
//==========================================================================;

#ifdef __cplusplus
extern "C" {

#include "strmini.h"
#include "ksmedia.h"
}
#endif

extern "C" const int _fltused = 0;

/*
 * This function serves to avoid linking CRT code
 */

int __cdecl  _purecall(void)
{
    return(FALSE);
}
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\drivers\wdm\capture\mini\bt848\mytypes.h ===
// $Header: G:/SwDev/WDM/Video/bt848/rcs/Mytypes.h 1.9 1998/04/29 22:43:34 tomz Exp $

#ifndef __MYTYPES_H
#define __MYTYPES_H

#ifdef __cplusplus
extern "C" {

#include "capdebug.h"

#ifndef _STREAM_H
#include "strmini.h"
#endif
#ifndef _KSMEDIA_
#include "ksmedia.h"
#endif
}
#endif


#ifndef __RETCODE_H
#include "retcode.h"
#endif

// Needed for VC4.x compile (_MSC_VER is defined as 1100 for MSVC 5.0) 
#if _MSC_VER < 1100
//  #pragma message  ("***  MSVC 4.x build ***")

  #define bool  BOOL
  #define true  TRUE
  #define false FALSE
  #define VC_4X_BUILD 
#else
//  #pragma message  ("***  MSVC 5.0 or better build ***")
  #undef  VC_4X_BUILD
#endif

inline long abs ( long lval )
{
   return( ( lval < 0 ) ? -lval : lval );
}   

inline void * _cdecl operator new( size_t sz )
{
   PVOID p = ExAllocatePool( NonPagedPool, sz );
   DebugOut((1, "Alloc %x got = %x\n", sz, p ) );
   return p;
}

inline void _cdecl operator delete( void *p )
{
   DebugOut((1, "deleting = %x\n", p ) );
   if ( p ) {
      ExFreePool( p );
   }
}

#ifndef VC_4X_BUILD
// In VC versions below 5.0, the following two cases are covered by the 
// new and delete defined above. The following syntax is invalid in pre-
// 5.0 versions.
inline void * _cdecl operator new[]( size_t sz )  
{
   PVOID p = ExAllocatePool( NonPagedPool, sz );
   DebugOut((1, "Alloc [] %x got = %x\n", sz, p ) );
   return p;
}

inline void _cdecl operator delete []( void *p )
{
   DebugOut((1, "deleting [] = %x\n", p ) );
   if ( p ) {
      ExFreePool( p );
   }
}
#endif

typedef struct tagDataBuf
{
   PHW_STREAM_REQUEST_BLOCK pSrb_;
   PBYTE                    pData_;
   tagDataBuf() : pSrb_( 0 ), pData_( 0 ) {}
   tagDataBuf( PHW_STREAM_REQUEST_BLOCK pSrb, PVOID p )
      : pSrb_( pSrb ), pData_( PBYTE( p ) ) {}
} DataBuf;

class MSize;
class MRect;

class  MPoint : public tagPOINT {
  public:
    // Constructors
};

//
// class MSize
// ----- -----
//
class  MSize : public tagSIZE {
  public:
    // Constructors
    MSize() {}
    MSize(int dx, int dy) {cx = dx; cy = dy;}
    void Set( int dx, int dy ) { cx = dx; cy = dy; }
};


class  MRect : public tagRECT {
  public:
    // Constructors
    MRect() {}
    MRect( int _left, int _top, int _right, int _bottom );
    MRect( const MPoint& origin, const MSize& extent );
    MRect( const struct tagRECT &orgn );

    void Set( int _left, int _top, int _right, int _bottom );

    // Information/access functions(const and non-const)
    const MPoint& TopLeft() const {return *(MPoint*)&left;}
    int          Width() const {return right-left;}
    int          Height() const {return bottom-top;}
    const MSize  Size() const {return MSize(Width(), Height());}
    bool IsEmpty() const;
    bool IsNull() const;

};

//----------------------------------------------------------------------------
// Inlines
//----------------------------------------------------------------------------
inline void MRect::Set(int _left, int _top, int _right, int _bottom) {
  left = _left;
  top = _top;
  right = _right;
  bottom = _bottom;
}

inline MRect::MRect(int _left, int _top, int _right, int _bottom) {
  Set(_left, _top, _right, _bottom);
}
inline MRect::MRect(const MPoint& orgn, const MSize& extent) {
  Set(orgn.x, orgn.y, orgn.x+extent.cx, orgn.y+extent.cy);
}

inline MRect::MRect( const struct tagRECT &orgn )
{
   Set( orgn.left, orgn.top, orgn.right, orgn. bottom );
}

//
// Return true if the rectangle is empty.
//
inline bool MRect::IsEmpty() const
{
  return bool( left >= right || top >= bottom );
}

//
// Return true if all of the points on the rectangle is 0.
//
inline bool MRect::IsNull() const
{
  return bool( !left && !right && !top && !bottom );
}


#endif
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\drivers\wdm\capture\mini\bt848\mediums.h ===
//==========================================================================;
//
//  THIS CODE AND INFORMATION IS PROVIDED "AS IS" WITHOUT WARRANTY OF ANY
//  KIND, EITHER EXPRESSED OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE
//  IMPLIED WARRANTIES OF MERCHANTABILITY AND/OR FITNESS FOR A PARTICULAR
//  PURPOSE.
//
//  Copyright (c) 1992 - 1996  Microsoft Corporation.  All Rights Reserved.
//
//==========================================================================;

//
// This file defines interconnections between components via Mediums
//

#ifdef DEFINE_MEDIUMS
    #define MEDIUM_DECL static const
#else
    #define MEDIUM_DECL extern
#endif
                               
/*  -----------------------------------------------------------

    Topology of all devices:

                            PinDir  FilterPin#    M_GUID#
    TVTuner                 
        TVTunerVideo        out         0            0
    Crossbar
        TVTunerVideo        in          0            0
        AnalogVideoIn       out         3            1
    Capture
        AnalogVideoIn       in          0            1
        

All other pins are marked as promiscuous connections via GUID_NULL
------------------------------------------------------------------ */        
        
// Define the GUIDs which will be used to create the Mediums
#define M_GUID0 0xa19dc0e0, 0x3b39, 0x11d1, 0x90, 0x5f, 0x0, 0x0, 0xc0, 0xcc, 0x16, 0xba
#define M_GUID1 0xa19dc0e1, 0x3b39, 0x11d1, 0x90, 0x5f, 0x0, 0x0, 0xc0, 0xcc, 0x16, 0xba

// Note: To allow multiple instances of the same piece of hardware,
// set the first ULONG after the GUID in the Medium to a unique value.

// -----------------------------------------------

MEDIUM_DECL KSPIN_MEDIUM TVTunerMediums[] = {
    {M_GUID0,           0, 0},  // Pin 0
    {STATIC_GUID_NULL,  0, 0},  // Pin 1
};

MEDIUM_DECL BOOL TVTunerPinDirection [] = {
    TRUE,                       // Output Pin 0
    TRUE,                       // Output Pin 1
};

// -----------------------------------------------

MEDIUM_DECL KSPIN_MEDIUM CrossbarMediums[] = {
    {STATIC_GUID_NULL,  0, 0},  // Pin 0
    {M_GUID0,           0, 0},  // Pin 1
    {STATIC_GUID_NULL,  0, 0},  // Pin 2
    {M_GUID1,           0, 0},  // Pin 3
};

MEDIUM_DECL BOOL CrossbarPinDirection [] = {
    FALSE,                      // Input  Pin 0
    FALSE,                      // Input  Pin 1
    FALSE,                      // Input  Pin 2
    TRUE,                       // Output Pin 3
};

// -----------------------------------------------

MEDIUM_DECL KSPIN_MEDIUM CaptureMediums[] = {
    {STATIC_KSMEDIUMSETID_Standard,  0, 0},  // Pin 0  Capture
    {STATIC_KSMEDIUMSETID_Standard,  0, 0},  // Pin 1  Preview
    {STATIC_KSMEDIUMSETID_Standard,  0, 0},  // Pin 2  VBI
    {M_GUID1,           0, 0},  // Pin 3  Analog Video In
};

MEDIUM_DECL BOOL CapturePinDirection [] = {
    TRUE,                       // Output Pin 0
    TRUE,                       // Output Pin 1
    TRUE,                       // Output Pin 2
    FALSE,                      // Input  Pin 3
};

MEDIUM_DECL GUID CaptureCategories[] = {
    STATIC_PINNAME_VIDEO_CAPTURE,           // Pin 0
    STATIC_PINNAME_VIDEO_PREVIEW,           // Pin 1
    STATIC_PINNAME_VIDEO_VBI                // Pin 2
    STATIC_PINNAME_VIDEO_ANALOGVIDEOIN,     // Pin 3
};
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\drivers\wdm\capture\mini\bt848\physaddr.h ===
// $Header: G:/SwDev/WDM/Video/bt848/rcs/Physaddr.h 1.3 1998/04/29 22:43:34 tomz Exp $

#ifndef __PHYSADDR_H
#define __PHYSADDR_H

inline DWORD GetPhysAddr( DataBuf &buf )
{
   ULONG len = 0;
   return StreamClassGetPhysicalAddress( buf.pSrb_->HwDeviceExtension, buf.pSrb_,
      buf.pData_, SRBDataBuffer, &len ).LowPart;
}

/* Function: IsSumAbovePage
 * Purpose: Sees if sum of 2 numbers is bigger then page
 * Input: first: DWORD
 *   second: DWORD,
 * Output: bool
*/
inline bool IsSumAbovePage( DWORD first, DWORD second )
{
   return bool( BYTE_OFFSET( first ) + BYTE_OFFSET( second ) > ( PAGE_SIZE - 1 ) );
//   return bool( ( first & 0xFFF ) + ( second & 0xFFF ) > 0xFFF );
}


/* Function: Need2Split
 * Purpose: Sees if a scan line needs to be broken into 2 instructions
 * Input: dwAddr: DWORD, address
 *   wCOunt: WORD, byte count
 * Output: bool
*/
inline bool Need2Split( DataBuf &buf, WORD wCount )
{
   DataBuf tmp = buf;
   tmp.pData_ += wCount;
   return bool( IsSumAbovePage( DWORD( buf.pData_ ), wCount ) &&
          ( GetPhysAddr( tmp ) - GetPhysAddr( buf ) != wCount ) );
}

#endif
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\drivers\wdm\capture\mini\bt848\preg.h ===
// $Header: G:/SwDev/WDM/Video/bt848/rcs/Preg.h 1.2 1998/04/29 22:43:35 tomz Exp $

// Header file generated from zzztmp.h 
// use the macro DECLARE_regname to get declarations.
// use the macro CONSTRUCT_regname to get constructor calls.

#define DECLARE_COLORFORMAT RegisterDW ColorFormat; \
	RegField COLOR_EVEN; \
	RegField COLOR_ODD
	
#define CONSTRUCT_COLORFORMAT ColorFormat( 0x00D4, RW), \
	COLOR_EVEN( ColorFormat, 0, 4, RW), \
	COLOR_ODD( ColorFormat, 4, 4, RW)
	
#define DECLARE_COLORCONTROL RegisterDW ColorControl; \
	RegField BSWAP_EVEN; \
	RegField BSWAP_ODD; \
	RegField WSWAP_EVEN; \
	RegField WSWAP_ODD; \
	RegField GAMMA; \
	RegField RGB_DED; \
	RegField COLOR_BARS; \
	RegField EXT_FRMRATE
	
#define CONSTRUCT_COLORCONTROL ColorControl( 0x00D8, RW), \
	BSWAP_EVEN( ColorControl, 0, 1, RW), \
	BSWAP_ODD( ColorControl, 1, 1, RW), \
	WSWAP_EVEN( ColorControl, 2, 1, RW), \
	WSWAP_ODD( ColorControl, 3, 1, RW), \
	GAMMA( ColorControl, 4, 1, RW), \
	RGB_DED( ColorControl, 5, 1, RW), \
	COLOR_BARS( ColorControl, 6, 1, RW), \
	EXT_FRMRATE( ColorControl, 7, 1, RW)
	
#define DECLARE_CAPTURECONTROL RegisterDW CaptureControl; \
	RegField CAPTURE_EVEN; \
	RegField CAPTURE_ODD; \
	RegField CAPTURE_VBI_EVEN; \
	RegField CAPTURE_VBI_ODD; \
	RegField DITH_FRAME; \
	RegField RESERVED0
	
#define CONSTRUCT_CAPTURECONTROL CaptureControl( 0x00DC, RW), \
	CAPTURE_EVEN( CaptureControl, 0, 1, RW), \
	CAPTURE_ODD( CaptureControl, 1, 1, RW), \
	CAPTURE_VBI_EVEN( CaptureControl, 2, 1, RW), \
	CAPTURE_VBI_ODD( CaptureControl, 3, 1, RW), \
	DITH_FRAME( CaptureControl, 4, 1, RW), \
	RESERVED0( CaptureControl, 5, 3, RW)
	
#define DECLARE_VBIPACKETSIZE RegisterDW VBIPacketSize; \
	RegField VBI_PKT_LO
	
#define CONSTRUCT_VBIPACKETSIZE VBIPacketSize( 0x00E0, RW), \
	VBI_PKT_LO( VBIPacketSize, 0, 8, RW)
	
#define DECLARE_VBIDELAY RegisterDW VBIDelay; \
	RegField VBI_PKT_HI; \
	RegField EXT_RAW; \
	RegField VBI_HDELAY
	
#define CONSTRUCT_VBIDELAY VBIDelay( 0x00E4, RW), \
	VBI_PKT_HI( VBIDelay, 0, 1, RW), \
	EXT_RAW( VBIDelay, 1, 1, RW), \
	VBI_HDELAY( VBIDelay, 2, 6, RW)
	
#define DECLARE_INTERRUPTSTATUS RegisterDW InterruptStatus; \
	RegField FMTCHG; \
	RegField VSYNC; \
	RegField HSYNC; \
	RegField OFLOW; \
	RegField HLOCK; \
	RegField VPRES; \
	RegField RESERVED1; \
	RegField RESERVED2; \
	RegField I2CDONE; \
	RegField GPINT; \
	RegField RESERVED3; \
	RegField RISCI; \
	RegField FBUS; \
	RegField FTRGT; \
	RegField FDSR; \
	RegField PPERR; \
	RegField RIPERR; \
	RegField PABORT; \
	RegField OCERR; \
	RegField SCERR; \
	RegField RESERVED4; \
	RegField FIELD; \
	RegField RACK; \
	RegField V5IO; \
	RegField RISC_EN; \
	RegField RISCS
	
#define CONSTRUCT_INTERRUPTSTATUS InterruptStatus( 0x0100, RW), \
	FMTCHG( InterruptStatus, 0, 1, RR), \
	VSYNC( InterruptStatus, 1, 1, RR), \
	HSYNC( InterruptStatus, 2, 1, RR), \
	OFLOW( InterruptStatus, 3, 1, RR), \
	HLOCK( InterruptStatus, 4, 1, RR), \
	VPRES( InterruptStatus, 5, 1, RR), \
	RESERVED1( InterruptStatus, 6, 1, RO), \
	RESERVED2( InterruptStatus, 7, 1, RO), \
	I2CDONE( InterruptStatus, 8, 1, RR), \
	GPINT( InterruptStatus, 9, 1, RR), \
	RESERVED3( InterruptStatus, 10, 1, RO), \
	RISCI( InterruptStatus, 11, 1, RR), \
	FBUS( InterruptStatus, 12, 1, RR), \
	FTRGT( InterruptStatus, 13, 1, RR), \
	FDSR( InterruptStatus, 14, 1, RR), \
	PPERR( InterruptStatus, 15, 1, RR), \
	RIPERR( InterruptStatus, 16, 1, RR), \
	PABORT( InterruptStatus, 17, 1, RR), \
	OCERR( InterruptStatus, 18, 1, RR), \
	SCERR( InterruptStatus, 19, 1, RR), \
	RESERVED4( InterruptStatus, 20, 4, RO), \
	FIELD( InterruptStatus, 24, 1, RO), \
	RACK( InterruptStatus, 25, 1, RO), \
	V5IO( InterruptStatus, 26, 1, RO), \
	RISC_EN( InterruptStatus, 27, 1, RO), \
	RISCS( InterruptStatus, 28, 4, RO)
	
#define DECLARE_INTERRUPTMASK RegisterDW InterruptMask; \
	RegField IMASK_FMTCHG; \
	RegField IMASK_VSYNC; \
	RegField IMASK_HSYNC; \
	RegField IMASK_OFLOW; \
	RegField IMASK_HLOCK; \
	RegField IMASK_VPRES; \
	RegField IMASK_RESERVED6; \
	RegField IMASK_RESERVED7; \
	RegField IMASK_I2CDONE; \
	RegField IMASK_GPINT; \
	RegField IMASK_RESERVED10; \
	RegField IMASK_RISCI; \
	RegField IMASK_FBUS; \
	RegField IMASK_FTRGT; \
	RegField IMASK_FDSR; \
	RegField IMASK_PPERW; \
	RegField IMASK_RIPERW; \
	RegField IMASK_PABORT; \
	RegField IMASK_OCERW; \
	RegField IMASK_SCERW; \
	RegField IMASK_RESERVED23TO20
	
#define CONSTRUCT_INTERRUPTMASK InterruptMask( 0x0104, RW), \
	IMASK_FMTCHG( InterruptMask, 0, 1, RW), \
	IMASK_VSYNC( InterruptMask, 1, 1, RW), \
	IMASK_HSYNC( InterruptMask, 2, 1, RW), \
	IMASK_OFLOW( InterruptMask, 3, 1, RW), \
	IMASK_HLOCK( InterruptMask, 4, 1, RW), \
	IMASK_VPRES( InterruptMask, 5, 1, RW), \
	IMASK_RESERVED6( InterruptMask, 6, 1, RW), \
	IMASK_RESERVED7( InterruptMask, 7, 1, RW), \
	IMASK_I2CDONE( InterruptMask, 8, 1, RW), \
	IMASK_GPINT( InterruptMask, 9, 1, RW), \
	IMASK_RESERVED10( InterruptMask, 10, 1, RW), \
	IMASK_RISCI( InterruptMask, 11, 1, RW), \
	IMASK_FBUS( InterruptMask, 12, 1, RW), \
	IMASK_FTRGT( InterruptMask, 13, 1, RW), \
	IMASK_FDSR( InterruptMask, 14, 1, RW), \
	IMASK_PPERW( InterruptMask, 15, 1, RW), \
	IMASK_RIPERW( InterruptMask, 16, 1, RW), \
	IMASK_PABORT( InterruptMask, 17, 1, RW), \
	IMASK_OCERW( InterruptMask, 18, 1, RW), \
	IMASK_SCERW( InterruptMask, 19, 1, RW), \
	IMASK_RESERVED23TO20( InterruptMask, 20, 4, RW)
	
#define DECLARE_CONTROL RegisterDW Control; \
	RegField FIFO_ENABLE; \
	RegField RISC_ENABLE; \
	RegField PKTP; \
	RegField PLTP1; \
	RegField PLTP23; \
	RegField RESERVED5; \
	RegField GPCLKMODE; \
	RegField GPIOMODE; \
	RegField GPWEC; \
	RegField GPINTI; \
	RegField GPINTC
	
#define CONSTRUCT_CONTROL Control( 0x010C, RW), \
	FIFO_ENABLE( Control, 0, 1, RW), \
	RISC_ENABLE( Control, 1, 1, RW), \
	PKTP( Control, 2, 2, RW), \
	PLTP1( Control, 4, 2, RW), \
	PLTP23( Control, 6, 2, RW), \
	RESERVED5( Control, 8, 2, RW), \
	GPCLKMODE( Control, 10, 1, RW), \
	GPIOMODE( Control, 11, 2, RW), \
	GPWEC( Control, 13, 1, RW), \
	GPINTI( Control, 14, 1, RW), \
	GPINTC( Control, 15, 1, RW)
	
#define DECLARE_RISCPROGRAMSTARTADDRESS RegisterDW RISCProgramStartAddress; \
	RegField RISC_IPC
	
#define CONSTRUCT_RISCPROGRAMSTARTADDRESS RISCProgramStartAddress( 0x0114, RW), \
	RISC_IPC( RISCProgramStartAddress, 0, 32, RW)
	
#define DECLARE_GPIOOUTPUTENABLECONTROL RegisterDW GPIOOutputEnableControl; \
	RegField GPOE
	
#define CONSTRUCT_GPIOOUTPUTENABLECONTROL GPIOOutputEnableControl( 0x0118, RW), \
	GPOE( GPIOOutputEnableControl, 0, 24, RW)
	
#define DECLARE_GPIOREGISTEREDINPUTCONTROL RegisterDW GPIORegisteredInputControl; \
	RegField GPIE
	
#define CONSTRUCT_GPIOREGISTEREDINPUTCONTROL GPIORegisteredInputControl( 0x011C, RW), \
	GPIE( GPIORegisteredInputControl, 0, 24, RW)
	
#define DECLARE_GPIODATAIO RegisterDW GPIODataIO; \
	RegField GPDATA
	
#define CONSTRUCT_GPIODATAIO GPIODataIO( 0x0200, RW), \
	GPDATA( GPIODataIO, 0, 24, RW)
	
#define DECLARE_I2CDATA_CONTROL RegisterDW I2CData_Control; \
	RegField I2CDB0; \
	RegField I2CDB1; \
	RegField I2CDB2; \
	RegField I2CDIV; \
	RegField I2CSYNC; \
	RegField I2CW3B; \
	RegField I2CSCL; \
	RegField I2CSDA
	
#define CONSTRUCT_I2CDATA_CONTROL I2CData_Control( 0x0110, RW), \
	I2CDB0( I2CData_Control, 24, 8, RV), \
	I2CDB1( I2CData_Control, 16, 8, RV), \
	I2CDB2( I2CData_Control, 8, 8, RV), \
	I2CDIV( I2CData_Control, 4, 4, RW), \
	I2CSYNC( I2CData_Control, 3, 1, RW), \
	I2CW3B( I2CData_Control, 2, 1, RW), \
	I2CSCL( I2CData_Control, 1, 1, RV), \
	I2CSDA( I2CData_Control, 0, 1, RV)
	
#define DECLARE_RISCPROGRAMCOUNTER RegisterDW RISCProgramCounter
	
#define CONSTRUCT_RISCPROGRAMCOUNTER RISCProgramCounter( 0x0120, RW)
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\drivers\wdm\capture\mini\bt848\pisces.cpp ===
// $Header: G:/SwDev/WDM/Video/bt848/rcs/Pisces.cpp 1.15 1998/05/04 23:48:53 tomz Exp $

#include "pisces.h"
#include <stdlib.h>

/*
*/
BtPisces::BtPisces( DWORD *xtals ) : Engine_(), Inited_( false ),
   Even_( CAPTURE_EVEN, VF_Even,&COLOR_EVEN, &WSWAP_EVEN, &BSWAP_EVEN ),
   Odd_( CAPTURE_ODD, VF_Odd, &COLOR_ODD, &WSWAP_ODD, &BSWAP_ODD ),
   VBIE_( CAPTURE_VBI_EVEN ), VBIO_( CAPTURE_VBI_ODD ), Update_( false ),
   nSkipped_( 0 ), Paused_( false ), 

   Starter_(       ),
   SyncEvenEnd1_(  ),
   SyncEvenEnd2_(  ),
   SyncOddEnd1_(   ),
   SyncOddEnd2_(   ),
   PsDecoder_( xtals ),
   dwPlanarAdjust_( 0 ),
   CONSTRUCT_COLORCONTROL,
   CONSTRUCT_INTERRUPTSTATUS,
   CONSTRUCT_INTERRUPTMASK,
   CONSTRUCT_CONTROL,
   CONSTRUCT_CAPTURECONTROL,
   CONSTRUCT_COLORFORMAT,
   CONSTRUCT_GPIOOUTPUTENABLECONTROL,
   CONSTRUCT_GPIODATAIO
{
   Trace t("BtPisces::BtPisces()");
   Init();
}

BtPisces::~BtPisces()
{
   Trace t("BtPisces::~BtPisces()");

   Engine_.Stop();
   InterruptMask = 0;
   InterruptStatus = AllFs;

   // prevent risc program destructor from gpf-ing
   SyncEvenEnd1_.SetParent( NULL );
   SyncEvenEnd2_.SetParent( NULL );
   SyncOddEnd1_.SetParent( NULL );
   SyncOddEnd2_.SetParent( NULL );

   // free the association array now
   int ArrSize = sizeof( InterruptToIdx_ ) / sizeof( InterruptToIdx_ [0] );
   while ( --ArrSize >= 0 )
      delete InterruptToIdx_ [ArrSize];
   // now is the Skippers_' turn
   ArrSize = sizeof( Skippers_ ) / sizeof( Skippers_ [0] );
   while ( --ArrSize >= 0 )
      delete Skippers_ [ArrSize];

}


/* Method: BtPisces::GetIdxFromStream
 * Purpose: Returns starting index in the program array for a field
 * Input: aStream: StreamInfo & - reference
 * Output: int : Index
 */
int BtPisces::GetIdxFromStream( Field &aStream )
{
   Trace t("BtPisces::GetIdxFromStream()");

   switch ( aStream.GetStreamID() ) {
   case VS_Field1:
      return OddStartLocation;
   case VS_Field2:
      return EvenStartLocation;
   case VS_VBI1:
      return VBIOStartLocation;
   case VS_VBI2:
      return VBIEStartLocation;
   default:
      return 0;
   }
}

/* Method: BtPisces::CreateSyncCodes
 * Purpose: Creates the risc programs with sync codes needed between data risc
 *   programs
 * Input: None
 * Output: ErrorCode
 */
bool BtPisces::CreateSyncCodes()
{
   Trace t("BtPisces::CreateSyncCodes()");

   bool bRet = SyncEvenEnd1_.Create( SC_VRE ) == Success &&
          SyncEvenEnd2_.Create( SC_VRE ) == Success &&

          SyncOddEnd1_.Create( SC_VRO )  == Success &&
          SyncOddEnd2_.Create( SC_VRO )  == Success &&

          Starter_.Create( SC_VRO ) == Success;

   DebugOut((1, "*** BtPisces::CreateSyncCodes SyncEvenEnd1_(%x)\n", &SyncEvenEnd1_));
   DebugOut((1, "*** BtPisces::CreateSyncCodes SyncEvenEnd2_(%x)\n", &SyncEvenEnd2_));
   DebugOut((1, "*** BtPisces::CreateSyncCodes SyncOddEnd1_(%x)\n", &SyncOddEnd1_));
   DebugOut((1, "*** BtPisces::CreateSyncCodes SyncOddEnd2_(%x)\n", &SyncOddEnd2_));
   DebugOut((1, "*** BtPisces::CreateSyncCodes Starter_(%x)\n", &Starter_));

   return( bRet );
}

/* Method: BtPisces::Init
 * Purpose: Performs all necessary initialization
 * Input: None
 * Output: None
 */
void BtPisces::Init()
{
   Trace t("BtPisces::Init()");

   InterruptStatus = AllFs;
   InterruptStatus = 0;
   GAMMA = 1;

   // initialize the arrays
   CreatedProgs_.Clear() ;
   ActiveProgs_.Clear()  ;

   // fill in the skippers array and make each program a 'skipper'
   DataBuf buf;

   // [!!!] [TMZ] 
   // Engine_.CreateProgram constants look questionable

   for ( int i = 0; i < sizeof( Skippers_ ) / sizeof( Skippers_ [0] ); i++ ) {
      if ( i & 1 ) {
         MSize s( 10, 10 );
         Skippers_ [i] = Engine_.CreateProgram( s, 10 * 2, CF_VBI, buf, true, 0, false );
         DebugOut((1, "Creating Skipper[%d] == %x\n", i, Skippers_[i]));
         Engine_.Skip( Skippers_ [i] );
      } else {
         MSize s( 768, 12 );
         // now create skippers for the VBI streams
         Skippers_ [i] = Engine_.CreateProgram( s, 768 * 2, CF_VBI, buf, true, 0, false );
         DebugOut((1, "Creating Skipper[%d] == %x\n", i, Skippers_[i]));
      }
      if ( !Skippers_ [i] )
         return;
   }
   // create associations between Created and Skippers
   int link = 0;
   for ( i = 0; i < sizeof( SkipperIdxArr_ ) / sizeof( SkipperIdxArr_ [0] ); i++ ) {
      SkipperIdxArr_ [i] = link;
      i += link & 1; // advance past the sync program entry
      link++;
   }
   // fill in constant elements; see the table in the .h file
   CreatedProgs_ [2] = &SyncOddEnd1_;
   CreatedProgs_ [8] = &SyncOddEnd2_;

   CreatedProgs_ [5]  = &SyncEvenEnd1_;
   CreatedProgs_ [11] = &SyncEvenEnd2_;

   // set corresponding sync bits
   if ( !CreateSyncCodes() )
      return;

   // initialize association array now
   int ArrSize = sizeof( InterruptToIdx_ ) / sizeof( InterruptToIdx_ [0] );
   while ( --ArrSize >= 0 ) {
      if ( ( InterruptToIdx_ [ArrSize] = new IntrIdxAss() ) == 0 )
         return;
   }
   Even_.SetFrameRate(  333667 );
   Odd_. SetFrameRate(  333667 );
   VBIE_.SetFrameRate(  333667 );
   VBIO_.SetFrameRate(  333667 );

   Odd_. SetStreamID( VS_Field1 );
   Even_.SetStreamID( VS_Field2 );
   VBIO_.SetStreamID( VS_VBI1   );
   VBIE_.SetStreamID( VS_VBI2   );

   // finally, can wipe out the prespiration from the forehead
   Inited_ = true;
}

/* Method: BtPisces::AssignIntNumbers
 * Purpose: Assigns numbers to RISC programs that generate interrupt
 * Input: None
 * Output: None
 */
void BtPisces::AssignIntNumbers()
{
   Trace t("BtPisces::AssignIntNumbers()");

   int IntrCnt = 0;
   int limit = ActiveProgs_.NumElements() ;
   int idx;

   // initialize InterruptToIdx_ array
   for ( idx = 0; idx < limit; idx++ ) {
      IntrIdxAss item( idx, -1 );
      *InterruptToIdx_ [idx] = item;
   }

   // assign numbers in front of starting program
   bool first = true;
   for ( idx = 0; idx < (int) ActiveProgs_.NumElements() ; idx++ ) {

      RiscPrgHandle pProg = ActiveProgs_ [idx];

      //if not skipped and generates an interrupt assign number
      if ( pProg && pProg->IsInterrupting() ) {
         if ( first == true ) {
            first = false;
            pProg->ResetStatus();
            Skippers_ [SkipperIdxArr_ [idx] ]->ResetStatus();
         } else {
            pProg->SetToCount();
            Skippers_ [SkipperIdxArr_ [idx] ]->SetToCount();
         }
         IntrIdxAss item( IntrCnt, idx );
         *InterruptToIdx_ [IntrCnt] = item;
         IntrCnt++;
      }
   }
}

/* Method: BtPisces::LinkThePrograms
 * Purpose: Creates links between the created programs
 * Input: None
 * Output: None
 */
void BtPisces::LinkThePrograms()
{
   Trace t("BtPisces::LinkThePrograms()");
   DebugOut((1, "*** Linking Programs\n"));
   RiscPrgHandle hParent    = ActiveProgs_.First(),
                 hChild     = NULL,
                 hVeryFirst = NULL,
                 hLastChild = NULL ;

   if (hParent) {

      if ( hParent->IsSkipped() ) {
         int idx = ActiveProgs_.GetIndex(hParent) ;
         hParent = Skippers_ [SkipperIdxArr_ [idx] ] ;
      }

      while (hParent) {

         if (!hVeryFirst)
            hVeryFirst = hParent ;

         if ( hChild = ActiveProgs_.Next()) {
            if ( hChild->IsSkipped() ) {
               int idx = ActiveProgs_.GetIndex(hChild) ;
               hChild = Skippers_ [SkipperIdxArr_ [idx] ] ;
            }

            hLastChild = hChild;
            Engine_.Chain( hParent, hChild ) ;
         }
         hParent = hChild ;
      }

      // initial jump
      Engine_.Chain( &Starter_, hVeryFirst ) ;

      // now create the loop
      Engine_.Chain( hLastChild ? hLastChild : hVeryFirst, hVeryFirst ) ;
   }
}

/* Method: BtPisces::ProcessSyncPrograms()
 * Purpose: This function unlinks the helper sync programs
 * Input: None
 * Output: None
 */
void BtPisces::ProcessSyncPrograms()
{
   Trace t("BtPisces::ProcessSyncPrograms()");

   for ( int i = 0; i < (int) ActiveProgs_.NumElements(); i += ProgsWithinField ) {
      if ( !ActiveProgs_ [i] && !ActiveProgs_ [i+1] )  {
         ActiveProgs_ [i+2] = NULL;
      } else {
         ActiveProgs_ [i+2] = CreatedProgs_ [i+2];
      }
   }
}

/* Method: BtPisces::ProcessPresentPrograms
 * Purpose:
 * Input: None
 * Output: None
 */
void BtPisces::ProcessPresentPrograms()
{
   Trace t("BtPisces::ProcessPresentPrograms()");

   // link in/out helper sync programs
   ProcessSyncPrograms();
   // and now is time to cross link the programs
   LinkThePrograms();
   // and now figure out the numbers programs use for interrupts
   AssignIntNumbers();
}

/* Method: BtPisces::AddProgram
 * Purpose: Creates new RISC program and inserts it in the chain at a proper place
 * Input: aStream: StreamInfo & - reference to the stream to add a program for
 *   NumberToAdd: int - number of programs to add
 * Output:
 * Note:   Basically this internal function performs a loop 2 times
 *   //4. Tries to get another buffer to establish double buffering
 *   //5. If buffer is available it creates another RISC program with it
 *   //6. Then it has to link the program in...
 */
RiscPrgHandle BtPisces::AddProgram( Field &ToStart, int NumberToAdd )
{
   Trace t("BtPisces::AddProgram()");
   DebugOut((1, "BtPisces::AddProgram()\n"));

   int StartIdx = GetIdxFromStream( ToStart );
   SyncCode Sync;
   int SyncIdx;
   bool rsync;
   if ( StartIdx <= OddStartLocation ) {
      Sync = SC_VRO;
      SyncIdx = OddSyncStartLoc;
      rsync = false;
   } else {
      Sync = SC_VRE;
      SyncIdx = EvenSyncStartLoc;
      rsync = bool( StartIdx == EvenStartLocation );
   }
    // have to know what is the size of the image to produce
   MRect r;
   ToStart.GetDigitalWindow( r );
   // RISC engine operates on absolute sizes, not rectangles
   MSize s = r.Size();

   int BufCnt = 0;

   int Idx = StartIdx;
   for ( ; BufCnt < NumberToAdd; BufCnt++ ) {

      // init sync programs with a premise tha no data program exists
      CreatedProgs_ [SyncIdx]->Create( Sync, true );

      // obtain the next buffer from queue ( entry is removed from container )
      DataBuf buf = ToStart.GetNextBuffer();

      // can create a RISC program now.
      RiscPrgHandle hProgram = Engine_.CreateProgram( s, ToStart.GetBufPitch(),
         ToStart.GetColorFormat(), buf, ToStart.Interrupt_, dwPlanarAdjust_, rsync );

      // store this program
      CreatedProgs_ [Idx] = hProgram;
      DebugOut((1, "Creating RiscProgram[%d] == %x\n", Idx, CreatedProgs_ [Idx]));

      if ( !hProgram ) {
         Idx -= DistBetweenProgs;
         if ( Idx >= 0 ) {
            // clean up previous program
            Engine_.DestroyProgram( CreatedProgs_ [Idx] );
            CreatedProgs_ [Idx] = NULL;
         }
         return NULL;
      }
      // make sure we unskip the program when buffer becomes available
      if ( !buf.pData_ ) {
         hProgram->SetSkipped();  // do not have enough buffers to support double buffering
         nSkipped_++;
      }

      // assign stream to program; makes it easy during interrupt
      hProgram->SetTag( &ToStart );
      SyncIdx += DistBetweenProgs;
      Idx     += DistBetweenProgs; // skip the location intended for the other program

   } /* endfor */
   return CreatedProgs_ [StartIdx];
}

/* Method: BtPisces::Create
 * Purpose: This functions starts the stream.
 * Input: aStream: StreamInfo & - reference to a stream to start
 * Output: Address of the Starter_
 * Note: After the Start 2 entries in the CreatedProgs_ are created. Starting
 *   location is 4 for even and 1 for odd. Increment is 6. So if it is the first
 *   invocation and there is enough ( 2 ) buffers present entries [1] and [7]
 *   or [4] and [10] will be filled with newly created RISC programs. When programs
 *   exist for one field only they are doubly linked. When programs exist for
 *   both fields they alternate, i.e. 0->2->1->3->0... When one of the fields
 *   has 1 program only, programs are linked like this: 0->2->1->0->2...(numbers
 *   are indexes in the CreatedProgs_ array ). Alternating programs makes for
 *   maximum frame rate.
 */
ErrorCode BtPisces::Create( Field &ToCreate )
{
   Trace t("BtPisces::Create()");

   // running full-steam, nothing to create
   if ( ToCreate.IsStarted() == true )
      return Success;

   int StartIdx = GetIdxFromStream( ToCreate );
   if ( CreatedProgs_ [StartIdx] )
      return Success; // not running yet, but exists

   // call into internal function that adds new RISC program
   if ( ! AddProgram( ToCreate, MaxProgsForField ) )
      return Fail;
   return Success;
}

/* Method: BtPisces::Start
 * Purpose: Starts given stream ( by putting in in the Active_ array
 * Input: ToStart: Field &
 */
void BtPisces::Start( Field & ToStart )
{
   Trace t("BtPisces::Start()");
   // DebugOut((1, "BtPisces::Start\n"));

   if ( ToStart.IsStarted() == true )
      return;

   // all we need to do at this point is to create a proper starter
   // and link the programs in.
   int idx = GetIdxFromStream( ToStart );
   // this loop will enable LinkThePrograms to see programs for this stream
   for ( int i = 0; i < MaxProgsForField; i++, idx += DistBetweenProgs ) {
      ActiveProgs_ [idx] = CreatedProgs_ [idx];
   }
   // all I want to do at this point is call Restart.
   // do not signal the buffers
   Update_ = false;

   Restart();

   Update_ = true;
}

/* Method: BtPisces::Stop
 * Purpose: This function stops a stream. Called when PAUSE SRB is received
 * Input: aStream: StreamInfo & - reference to a stream to start
 * Output: None
 */
void BtPisces::Stop( Field &ToStop )
{
   Trace t("BtPisces::Stop()");
   // DebugOut((1, "BtPisces::Stop\n"));

   Engine_.Stop();   // no more interrupts

   int StartIdx = GetIdxFromStream( ToStop );

   // prevent unneeded syncronization interrupts
   IMASK_SCERW = 0;
      
   // it is time to pause the stream now
   ToStop.Stop();
   bool Need2Restart = false;
   // go through the array of programs and killing ones for this field (stream)
   for ( int i = 0; i < MaxProgsForField; i++, StartIdx += DistBetweenProgs ) {

      RiscPrgHandle ToDie = CreatedProgs_ [StartIdx];
      if ( !ToDie ) // this should never happen
         continue;
      if ( ToDie->IsSkipped() )
         nSkipped_--;

      DebugOut((1, "about to destroy idx = %d\n", StartIdx ) );
      Engine_.DestroyProgram( ToDie );
      CreatedProgs_ [StartIdx] = NULL;
      ActiveProgs_  [StartIdx] = NULL; // in case Pause wasn't called

      Need2Restart = true;
   } /* endfor */

   // nobody's around anymore
   if ( !CreatedProgs_.CountDMAProgs() ) {
      Engine_.Stop();
      InterruptMask = 0;
      InterruptStatus = AllFs;
      nSkipped_ = 0;
   } else {
      if ( Need2Restart ) {
         Restart();   // relink the programs and start ones that are alive
         IMASK_SCERW = 1; // re-enable the sync error interrupts
      }
   }
}

/* Method: BtPisces::Pause
 * Purpose: This function stops a stream. Called when PAUSE SRB is received
 * Input: aStream: Field & - reference to a stream to start
 * Output: None
 */
void BtPisces::Pause( Field &ToPause )
{
   Trace t("BtPisces::Pause()");
   // DebugOut((1, "BtPisces::Pause\n"));

   Engine_.Stop();   // no more interrupts

   if ( !ToPause.IsStarted() )
      return;

   int StartIdx = GetIdxFromStream( ToPause );

   // prevent unneeded syncronization interrupts
   IMASK_SCERW = 0;

   // it is time to pause the stream now
//   ToPause.Stop(); - done in Restart

   // go through the array of programs and killing ones for this field (stream)
   for ( int i = 0; i < MaxProgsForField; i++, StartIdx += DistBetweenProgs ) {
      ActiveProgs_ [StartIdx] = NULL;
   } /* endfor */

   Restart();   // relink the programs and start ones that are alive
}

/* Method: BtPisces::PairedPause
 * Purpose: This is a hacky function that pauses 2 streams at once
 * Input: idx: index of the second program in the second field
 * Output: None
 */
void BtPisces::PairedPause( int idx )
{
   Trace t("BtPisces::PairedPause()");
   // DebugOut((1, "BtPisces::PairedPause\n"));

   Engine_.Stop();   // no more interrupts

   // go through the array of programs and killing ones for this field (stream)
   for ( int i = 0; i < MaxProgsForField; i++, idx -= DistBetweenProgs ) {
      ActiveProgs_ [idx] = NULL;
      ActiveProgs_ [idx-ProgsWithinField] = NULL;
   } /* endfor */

   Restart();   // relink the programs and start ones that are alive
}

/* Method: BtPisces::GetStarted
 * Purpose: Figures out the channels that are started
 * Input:
 * Output: None
 */
void BtPisces::GetStarted( bool &EvenWasStarted, bool &OddWasStarted,
   bool &VBIEWasStarted, bool &VBIOWasStarted )
{
   Trace t("BtPisces::GetStarted()");

   VBIEWasStarted = ( ActiveProgs_ [VBIEStartLocation]  ? TRUE : FALSE);
   EvenWasStarted = ( ActiveProgs_ [EvenStartLocation] ? TRUE : FALSE);
   VBIOWasStarted = ( ActiveProgs_ [VBIOStartLocation] ? TRUE : FALSE);
   OddWasStarted  = ( ActiveProgs_ [OddStartLocation] ? TRUE : FALSE);
}

/* Method: BtPisces::RestartStreams
 * Purpose: Restarts streams that were started
 * Input:
 * Output: None
 */
void BtPisces::RestartStreams( bool EvenWasStarted, bool OddWasStarted,
   bool VBIEWasStarted, bool VBIOWasStarted )
{
   Trace t("BtPisces::RestartStream()");

   // vbi programs are first to execute, so enable them first
   if ( VBIOWasStarted )
      VBIO_.Start();
   if ( OddWasStarted )
      Odd_.Start();
   if ( VBIEWasStarted )
      VBIE_.Start();
   if ( EvenWasStarted )
      Even_.Start();
}

/* Method: BtPisces::CreateStarter
 * Purpose: Creates proper sync code for the bootstrap program
 * Input: EvenWasStarted: bool
 * Output: None
 */
void BtPisces::CreateStarter( bool EvenWasStarted )
{
   Trace t("BtPisces::CreateStarter()");
   Starter_.Create( EvenWasStarted ? SC_VRE : SC_VRO, true );
   DebugOut((1, "*** BtPisces::CreateStarter(%x) buf(%x)\n", &Starter_ , Starter_.GetPhysProgAddr( )));
}

/* Method: BtPisces::Restart
 * Purpose: Restarts the capture process. Called by ISR and Stop()
 * Input: None
 * Output: None
 */
void BtPisces::Restart()
{
   Trace t("BtPisces::Restart()");

   bool EvenWasStarted, OddWasStarted, VBIEWasStarted, VBIOWasStarted;
   GetStarted( EvenWasStarted, OddWasStarted, VBIEWasStarted, VBIOWasStarted );

   DebugOut((2, "BtPisces::Restart - Even WasStarted (%d)\n", EvenWasStarted));
   DebugOut((2, "BtPisces::Restart - Odd  WasStarted (%d)\n", OddWasStarted));
   DebugOut((2, "BtPisces::Restart - VBIE WasStarted (%d)\n", VBIEWasStarted));
   DebugOut((2, "BtPisces::Restart - VBIO WasStarted (%d)\n", VBIOWasStarted));

   Engine_.Stop();   // No more interrupts!

   Odd_.Stop();
   Even_.Stop();
   VBIE_.Stop();
   VBIO_.Stop();

   Engine_.Stop();   // No more interrupts!

#if 1
   if ( OddWasStarted )
   {
      Odd_.CancelSrbList();
   }
   if ( EvenWasStarted )
   {
      Even_.CancelSrbList();
   }
   if ( VBIEWasStarted )
   {
      VBIE_.CancelSrbList();
   }
   if ( VBIOWasStarted )
   {
      VBIO_.CancelSrbList();
   }
#endif

   // this will never happen, probably
   if ( !EvenWasStarted && !OddWasStarted && !VBIEWasStarted && !VBIOWasStarted )
      return;

   InterruptStatus = AllFs; // clear all the status bits

   CreateStarter( bool( EvenWasStarted || VBIEWasStarted ) );

   ProcessPresentPrograms();
   
   // DumpRiscPrograms();
   Engine_.Start( Starter_ );

   RestartStreams( EvenWasStarted, OddWasStarted, VBIEWasStarted, VBIOWasStarted );

   OldIdx_ = -1;

   InterruptMask = RISC_I | FBUS_I | OCERR_I | SCERR_I | 
                   RIPERR_I | PABORT_I | EN_TRITON1_BUG_FIX;
}

/* Method: BtPisces::Skip
 * Purpose: Forces a given program to be skipped by the RISC engine
 * Input: ToSkip: RiscPrgHandle - program to be skipped
 * Output: None
 * Note: If the number of skipped programs equals total number of programs, the
 *   RISC engine is stopped
*/
void BtPisces::Skip( int idx )
{
   Trace t("BtPisces::Skip()");

   // get the program and skip it
   RiscPrgHandle ToSkip = ActiveProgs_ [idx];
   if ( ToSkip->IsSkipped() )
      return;

   ToSkip->SetSkipped();
   nSkipped_++;

   //skip by linking the Skipper_ in instead of the skippee
   RiscPrgHandle SkipeeParent = ToSkip->GetParent();
   RiscPrgHandle SkipeeChild = ToSkip->GetChild();
   // get the skipper for this program
   RiscPrgHandle pSkipper = Skippers_ [SkipperIdxArr_ [idx] ];
   Engine_.Chain( pSkipper, SkipeeChild );
   Engine_.Chain( SkipeeParent, pSkipper );

   DebugOut((1, "BtPisces::Skipped %d Skipper %d\n", idx, SkipperIdxArr_ [idx] ) );
}

inline bool IsFirst( int idx )
{
   Trace t("BtPisces::IsFirst()");
   return bool( idx == OddStartLocation || idx == VBIOStartLocation ||
      idx - DistBetweenProgs == OddStartLocation ||
      idx - DistBetweenProgs == VBIOStartLocation  );
}

inline bool IsLast( int idx )
{
   Trace t("BtPisces::IsLast()");
   return bool((idx == (VBIEStartLocation + DistBetweenProgs)) ||
               (idx == (EvenStartLocation + DistBetweenProgs)));
}

/* Method: BtPisces::GetPassed
 * Purpose: Calculates number of programs that have executed since last interrupt
 * Input: None
 * Output: int: number of passed
*/
int BtPisces::GetPassed()
{
   Trace t("BtPisces::GetPassed()");

   // figure out which RISC program caused an interrupt
   int ProgCnt = RISCS;
   int numActive = ActiveProgs_.CountDMAProgs() ;

   if ( ProgCnt >= numActive ) {
      DebugOut((1, "ProgCnt = %d, larger than created\n", ProgCnt ) );
   }

   // now see how many programs have interrupted since last time and process them all
   if ( ProgCnt == OldIdx_ ) {
      DebugOut((1, "ProgCnt is the same = %d\n", ProgCnt ) );
   }
   int passed;

   if ( ProgCnt < OldIdx_ ) {
      passed = numActive - OldIdx_ + ProgCnt; // you spin me like a record, baby - round, round...
   } else
      passed = ProgCnt - OldIdx_;

   // The following line of code was VERY bad !!!
   // This caused crashes when the system got busy and had interrupts backed up.

   // if ( ProgCnt == OldIdx_ )
   //    passed = numActive;

   OldIdx_ = ProgCnt;
   return passed;
}

/* Method: BtPisces::GetProgram
 * Purpose: Finds a RISC program based on its position
 * Input: None
 * Output: None
*/
inline RiscPrgHandle BtPisces::GetProgram( int pos, int &idx )
{
   Trace t("BtPisces::GetProgram()");

   int nActiveProgs = ActiveProgs_.CountDMAProgs( );
   
   if ( nActiveProgs == 0 )
   {
      idx = 0;
      return ( NULL );
   }

   IntrIdxAss *item;
   item = InterruptToIdx_ [ pos % nActiveProgs ];
   idx = item->Idx;

   DEBUG_ASSERT( idx != -1 );

   return (idx == -1) ? NULL : ActiveProgs_ [idx];
}

/* Method: BtPisces::ProcessRISCIntr
 * Purpose: Handles interrupts caused by the RISC programs
 * Input: None
 * Output: None
*/

void  BtPisces::ProcessRISCIntr()
{
   PHW_STREAM_REQUEST_BLOCK gpCurSrb = 0;
   Trace t("BtPisces::ProcessRISCIntr()");

// this line must be before GetPassed(), as OldIdx_ is changed by that function
   int pos = OldIdx_ + 1;

   // measure elapsed time
   int passed = GetPassed();

   DebugOut((1, "  passed = %d\n", passed ) );

   while ( passed-- > 0 ) {

      int idx;
      RiscPrgHandle Rspnsbl = GetProgram( pos, idx );
      pos++;

      // last chance to prevent a disaster...
      if ( !Rspnsbl || !Rspnsbl->IsInterrupting() ) {
         DebugOut((1, "  no resp or not intr\n" ) );
         continue;
      }
      // get conveniently saved stream from the program
      Field &Interrupter = *(Field *)Rspnsbl->GetTag();

   gpCurSrb = Rspnsbl->pSrb_;          // [TMZ] [!!!]
   DebugOut((1, "'idx(%d), pSrb(%x)\n", idx, gpCurSrb));

      bool paired = Interrupter.GetPaired();

      if ( Interrupter.IsStarted() != true ) {
         DebugOut((1, "  not started %d\n", idx ) );
         continue;
      }
      if ( IsFirst( idx ) && paired ) {
         DebugOut((1, "  continue pair %d\n", idx ) );
         continue;
      }

      LONGLONG *pL = (LONGLONG *)Rspnsbl->GetDataBuffer();

      if ( !pL )
      {
            DebugOut((1, "null buffer in interrupt, ignore this interrupt\n"));
            //continue;
      }
      else
      {
            DebugOut((1, "good buffer in interrupt\n"));
      }

      // now make sure all buffers are written to
      if ( !pL || Rspnsbl->IsSkipped() ) {
         // want to call notify, so ProcessBufferAtInterrupt is called
         DebugOut((1, "  skipped %d\n", idx ) );
         Interrupter.Notify( (PVOID)idx, true );
         Interrupter.SetReady( true );
      } else  {
         BOOL test1 = FALSE;
         BOOL test2 = FALSE;
         BOOL test3 = FALSE;

         if ( 1
              //*pL != 0xAAAAAAAA33333333 &&         (test1 = TRUE) &&
              //*(pL + 1) != 0xBBBBBBBB22222222 &&   (test2 = TRUE) &&
              //Interrupter.GetReady() &&            (test3 = TRUE)
            ) {
            // here buffer is available
            DebugOut((1, "  notify %d, addr - %x\n", idx,
               Rspnsbl->GetDataBuffer() ) );

            //#pragma message("*** be very carefull zeroing buffers!!!")
            //Rspnsbl->SetDataBuffer( 0 );  // [TMZ] try to fix buffer re-use bug

            Interrupter.Notify( (PVOID)idx, false );
            Interrupter.SetReady( true );
         } else {
            // add code for the paired streams here
            DebugOut((1, "  not time %d (%d, %d, %d)\n", idx , test1, test2, test3));
            // this if/else takes care of this cases:
            // 1. first buffer for a field is not written to
            // 2. second buffer for a field is written to ( this can happen when
            // both programs were updated at the same time, but the timing was
            // such that first did not start executing, but second was );
            // so this if/else prevents sending buffers back out of order
            if ( Interrupter.GetReady() ) // it is always true before it is ever false
               Interrupter.SetReady( false );
            else
            // make sure that things are correct when the loop is entered later
            // the field must be set to 'ready'
               Interrupter.SetReady( true );
         }
      }
      
   } /* endwhile */
}

/* Method: BtPiscess::ProcessBufferAtInterrupt
 * Purpose: Called by a video channel to perform risc program modifications
 *   if needed
 * Input: pTag: PVOID - pointer to some data ( risc program pointer )
 * Output: None
 */
void BtPisces::ProcessBufferAtInterrupt( PVOID pTag )
{
   Trace t("BtPisces::ProcessBufferAtInterrupt()");

   int idx = (int)pTag;

   RiscPrgHandle Rspnsbl = ActiveProgs_ [idx];
   if ( !Rspnsbl ) {
      DebugOut((1, "PBAI: no responsible\n"));
      return;  // can this really happen ??
   }
   // get conveniently saved field from the program
   Field &Interrupter = *(Field *)Rspnsbl->GetTag();

   // see if there is a buffer in the queue and get it
   DataBuf buf = Interrupter.GetNextBuffer();

   DebugOut((1, "Update %d %x\n", idx, buf.pData_ ) );

   // if buffer is not available skip the program

   if ( !buf.pData_ ) {
      DebugOut((1, "Buffer not available, skipping %d\n", idx ) );
      Skip( idx );
   } else {
      if ( Rspnsbl->IsSkipped() )
         nSkipped_--;
      Engine_.ChangeAddress( Rspnsbl, buf );
      LinkThePrograms();
   }
}

/* Method: BtPisces::Interrupt
 * Purpose: Called by ISR to initiate the processing of an interrupt
 * Input: None
 * Output: None
*/

State BtPisces::Interrupt()
{
   Trace t("BtPisces::Interrupt()");

   DebugOut((2, "BtPisces::Interrupt()\n"));

   extern BYTE *gpjBaseAddr;

   DWORD IntrStatus = *(DWORD*)(gpjBaseAddr+0x100);

   State DidWe = Off;

   if ( IntrStatus & RISC_I ) {
      DebugOut((2, "RISC_I\n"));
      ProcessRISCIntr();
      *(DWORD*)(gpjBaseAddr+0x100) = RISC_I;    // reset the status bit
      DidWe = On;
   }
   if ( IntrStatus & FBUS_I ) {
      DebugOut((2, "FBUS\n"));
      *(DWORD*)(gpjBaseAddr+0x100) = FBUS_I;    // reset the status bit
      DidWe = On;
   }
   if ( IntrStatus & FTRGT_I ) {
      DebugOut((2, "FTRGT\n"));
      *(DWORD*)(gpjBaseAddr+0x100) = FTRGT_I;   // reset the status bit
      DidWe = On; //[TMZ]
   }
   if ( IntrStatus & FDSR_I ) {
      DebugOut((2, "FDSR\n"));
      *(DWORD*)(gpjBaseAddr+0x100) = FDSR_I;    // reset the status bit
      DidWe = On; //[TMZ]
   }
   if ( IntrStatus & PPERR_I ) {
      DebugOut((2, "PPERR\n"));
      *(DWORD*)(gpjBaseAddr+0x100) = PPERR_I;   // reset the status bit
      DidWe = On; //[TMZ]
   }
   if ( IntrStatus & RIPERR_I ) {
      DebugOut((2, "RIPERR\n"));
      *(DWORD*)(gpjBaseAddr+0x100) = RIPERR_I;  // reset the status bit
      Restart();
      DidWe = On;
   }
   if ( IntrStatus & PABORT_I ) {
      DebugOut((2, "PABORT\n"));
      *(DWORD*)(gpjBaseAddr+0x100) = PABORT_I;  // reset the status bit
      DidWe = On;
   }
   if ( IntrStatus & OCERR_I ) {
      DebugOut((2, "OCERR\n"));
      DidWe = On;
      DebugOut((0, "Stopping RiscEngine due to OCERR\n"));  // [!!!] [TMZ] why not restart?
      Engine_.Stop();
      *(DWORD*)(gpjBaseAddr+0x100) = OCERR_I; // reset the status bit
   }
   if ( IntrStatus & SCERR_I ) {
      DebugOut((0, "SCERR\n"));
      DidWe = On;
      *(DWORD*)(gpjBaseAddr+0x100) = SCERR_I; // reset the status bit
      Restart();  // [TMZ] [!!!] this royally screws us over sometimes, figure it out.
      *(DWORD*)(gpjBaseAddr+0x100) = SCERR_I; // reset the status bit
   }
   return DidWe;
}

// resource allocation group 

/* Method: BtPisces::AllocateStream
 * Purpose: This function allocates a stream for use by a video channel
 * Input: StrInf: StreamInfo & - reference to the stream information structure
 * Output:
 */
ErrorCode BtPisces::AllocateStream( Field *&ToAllocate, VideoStream st )
{
   Trace t("BtPisces::AllocateStream()");

   switch ( st ) {
   case VS_Field1:
      ToAllocate = &Odd_;
      break;
   case VS_Field2:
      ToAllocate = &Even_;
      break;
   case VS_VBI1:
      ToAllocate = &VBIO_;
      break;
   case VS_VBI2:
      ToAllocate = &VBIE_;
      break;
   }
   return Success;
}

/* Method: BtPisces::SetBrightness
 * Purpose: Changes brightness of the captured image
 * Input:
 * Output:
 */
void BtPisces::SetBrightness( DWORD value )
{
   Trace t("BtPisces::SetBrightness()");
   PsDecoder_.SetBrightness( value );
}

/* Method: BtPisces::SetSaturation
 * Purpose:
 * Input:
 * Output:
 */
void BtPisces::SetSaturation( DWORD value )
{
   Trace t("BtPisces::SetSaturation()");
   PsDecoder_.SetSaturation( value );
}

/* Method: BtPisces::SetConnector
 * Purpose:
 * Input:
 * Output:
 */
void BtPisces::SetConnector( DWORD value )
{
   Trace t("BtPisces::SetConnector()");
   PsDecoder_.SetVideoInput( Connector( value ) );
}

/* Method: BtPisces::SetContrast
 * Purpose:
 * Input:
 * Output:
 */
void BtPisces::SetContrast( DWORD value )
{
   Trace t("BtPisces::SetContrast()");
   PsDecoder_.SetContrast( value );
}

/* Method: BtPisces::SetHue
 * Purpose:
 * Input:
 * Output:
 */
void BtPisces::SetHue( DWORD value )
{
   Trace t("BtPisces::SetHue()");
   PsDecoder_.SetHue( value );
}

/* Method: BtPisces::SetSVideo
 * Purpose:
 * Input:
 * Output:
 */
void BtPisces::SetSVideo( DWORD )
{
   Trace t("BtPisces::SetSVideo()");
}

/* Method: BtPisces::
 * Purpose:
 * Input:   value: DWORD
 * Output:
 */
void BtPisces::SetFormat( DWORD value )
{
   Trace t("BtPisces::SetFormat()");

   PsDecoder_.SetVideoFormat( VideoFormat( value ) );
   // let the scaler know format has changed
   Even_.VideoFormatChanged( VideoFormat( value ) );
   Odd_.VideoFormatChanged( VideoFormat( value ) );
}

/* Method: BtPisces::GetSaturation
 * Purpose:
 * Input:   pData: PLONG
 * Output:
 */
LONG BtPisces::GetSaturation()
{
   Trace t("BtPisces::GetSaturation()");
   return PsDecoder_.GetSaturation();
}

/* Method: BtPisces::GetHue
 * Purpose:
 * Input:   pData: PLONG
 * Output:
 */
LONG BtPisces::GetHue()
{
   Trace t("BtPisces::GetHue()");
   return PsDecoder_.GetHue();
}

/* Method: BtPisces::GetBrightness
 * Purpose:
 * Input:   pData: PLONG
 * Output:
 */
LONG BtPisces::GetBrightness()
{
   Trace t("BtPisces::GetBrightness()");
   return PsDecoder_.GetBrightness();
}

/* Method: BtPisces::GetSVideo
 * Purpose:
 * Input:   pData: PLONG
 * Output:
 */
LONG BtPisces::GetSVideo()
{
   Trace t("BtPisces::GetSVideo()");
   return 0;
}

/* Method: BtPisces::GetContrast
 * Purpose:
 * Input:   pData: PLONG
 * Output:
 */
LONG BtPisces::GetContrast()
{
   Trace t("BtPisces::GetContrast()");
   return PsDecoder_.GetContrast();
}

/* Method: BtPisces::GetFormat
 * Purpose:
 * Input:   pData: PLONG
 * Output:
 */
LONG BtPisces::GetFormat()
{
   Trace t("BtPisces::GetFormat()");
   return PsDecoder_.GetVideoFormat();
}

/* Method: BtPisces::GetConnector
 * Purpose:
 * Input: pData: PLONG
 * Output:
 */
LONG BtPisces::GetConnector()
{
   Trace t("BtPisces::GetConnector()");
   return PsDecoder_.GetVideoInput();
}

// scaler group
/* Method: BtPisces::SetAnalogWindow
 * Purpose:
 * Input:
 * Output:
 */
ErrorCode BtPisces::SetAnalogWindow( MRect &r, Field &aField )
{
   Trace t("BtPisces::SetAnalogWindow()");
   return aField.SetAnalogWindow( r );
}

/* Method: BtPisces::SetDigitalWindow
 * Purpose:
 * Input:
 * Output:
 */
ErrorCode BtPisces::SetDigitalWindow( MRect &r, Field &aField )
{
   Trace t("BtPisces::SetDigitalWindow()");
   return aField.SetDigitalWindow( r );
}

// color space converter group
/* Method: BtPisces::SetPixelFormat
 * Purpose:
 * Input:
 * Output:
 */
void BtPisces::SetPixelFormat( ColFmt aFormat, Field &aField )
{
   Trace t("BtPisces::SetPixelFormat()");
   aField.SetColorFormat( aFormat );
}

/* Method: BtPisces::GetPixelFormat
 * Purpose:
 * Input:
 * Output:
 */
ColFmt BtPisces::GetPixelFormat( Field &aField )
{
   Trace t("BtPisces::GetPixelFormat()");
   return aField.GetColorFormat();
}


void BtPisces::TurnVFilter( State s )
{
   Trace t("BtPisces::TurnVFilter()");
   Even_.TurnVFilter( s );
   Odd_.TurnVFilter( s );
}

/* Method:
 * Purpose: returns video standards supported by the board
 */
LONG BtPisces::GetSupportedStandards()
{
   Trace t("BtPisces::GetSupportedStandards()");
   return PsDecoder_.GetSupportedStandards();
}
                                                                                                                           
void  BtPisces::DumpRiscPrograms()
{
   LONG x;

   // Dump the links

   DebugOut((0, "------------------------------------------------\n"));
   for( x = 0; x < 12; x++ )
   {
      if ( CreatedProgs_[x] )
      {
         DebugOut((0, "Created #%02d addr(%x) paddr(%x) jaddr(%x)\n", x, CreatedProgs_[x], CreatedProgs_[x]->GetPhysProgAddr( ), *(CreatedProgs_[x]->pChainAddress_ + 1)));
      }
   }
   for( x = 0; x < 8; x++ )
   {
      if ( Skippers_[x] )
      {
         DebugOut((0, "Skipper #%02d addr(%x) paddr(%x) jaddr(%x)\n", x, Skippers_[x], Skippers_[x]->GetPhysProgAddr( ), *(Skippers_[x]->pChainAddress_ + 1)));
      }
   }
   DebugOut((0, "------------------------------------------------\n"));

   return ;

   /////////////////////////////////////////////////

   for( x = 0; x < 12; x++ ) {
      DebugOut((0, "Active Program #  %d(%x) buf(%x)\n", x, ActiveProgs_[x], ActiveProgs_[x]?ActiveProgs_[x]->GetPhysProgAddr( ):-1));
   }
   for( x = 0; x < 12; x++ ) {
      DebugOut((0, "Created Program # %d(%x) buf(%x)\n", x, CreatedProgs_[x], CreatedProgs_[x]?CreatedProgs_[x]->GetPhysProgAddr( ):-1));
   }
   for( x = 0; x < 8; x++ ) {                     
      DebugOut((0, "Skipper Program # %d(%x) buf(%x)\n", x, Skippers_[x], Skippers_[x]?Skippers_[x]->GetPhysProgAddr( ):-1));
   }

   DebugOut((2, "---------------------------------\n"));
   DebugOut((2, "Dumping ActiveProgs_\n"));
   DebugOut((2, "---------------------------------\n"));
   for( x = 0; x < 12; x++ ) {
      DebugOut((1, "Active Program #  %d\n", x));
      ActiveProgs_[x]->Dump();
   }
   DebugOut((2, "---------------------------------\n"));
   DebugOut((2, "Dumping CreatedProgs_\n"));
   DebugOut((2, "---------------------------------\n"));
   for( x = 0; x < 12; x++ ) {
      DebugOut((1, "Created Program # %d\n", x));
      CreatedProgs_[x]->Dump();
   }
   DebugOut((2, "---------------------------------\n"));
   DebugOut((2, "Dumping Skippers_\n"));
   DebugOut((2, "---------------------------------\n"));
   for( x = 0; x < 8; x++ ) {                     
      DebugOut((1, "Skipper Program # %d\n", x));
      Skippers_[x]->Dump();
   }
}
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\drivers\wdm\capture\mini\bt848\pscolspc.cpp ===
// $Header: G:/SwDev/WDM/Video/bt848/rcs/Pscolspc.cpp 1.4 1998/04/29 22:43:35 tomz Exp $

extern "C" {
#ifndef _STREAM_H
#include "strmini.h"
#endif
}

#include "pscolspc.h"

/* Method: PsColorSpace::SetColorFormat
 * Purpose: Sets BtPisces color space converter to the given color
 * Input: eaColor: enum of type ColFmt
 * Output: None
 * Note: No error checking is done ( enum is checked by the compiler during compile
 *   The function writes to the XXXX register
*/

BOOL VerifyColorFormat( ColFmt val )
{
   // [WRK] - use constants here for valid formats
   switch( val ) {
      case 0:
      case 1:
      case 2:
      case 3:
      case 4:
      case 5:
      case 6:
      case 7:
      case 8:
      case 9:
      case 0xe:
         return( TRUE );
      default:
         DebugOut((0, "Caught bad write to ColorFormat (0x%x)\n", val));
         return( FALSE );
   }
}   
void PsColorSpace::SetColorFormat( ColFmt eColor )
{
   // save for later use...
   ColorSpace::SetColorFormat( eColor );
   ByteSwap_ = 0;
 
   switch ( eColor ) {
   case CF_YUV9:
      eColor = CF_PL_411;
      break;
   case CF_YUV12:
   case CF_I420:
      eColor = CF_PL_422;
      break;
   case CF_UYVY:
      eColor = CF_YUY2;
      ByteSwap_ = 1;
      break;
   }

   // set the hardware
   if ( VerifyColorFormat(eColor) ) {
      Format_ = eColor;
   } else {
      Format_ = 7;
      DebugOut((0, "Forcing invalid color format to 0x%x\n", Format_));
   }
}
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\drivers\wdm\capture\mini\bt848\pscolspc.h ===
// $Header: G:/SwDev/WDM/Video/bt848/rcs/Pscolspc.h 1.3 1998/04/29 22:43:36 tomz Exp $

#ifndef __PSCOSPC_H
#define __PSCOLSPC_H

#ifndef __COMPREG_H
#include "compreg.h"
#endif

#ifndef __COLSPACE_H
#include "colspace.h"
#endif


/* Class: PsColorSpace
 * Purpose: This class interfaces to the Pisces HW. That is the only difference
 *    from its base class ColorSpace. Such division was created so ring3 capture
 *    driver can utilize ColorSpace's functionality
 * Attributes: Format_: Register & - reference to the color format register
 * Operations:
 *      void SetColorFormat( ColorFormat aColor );
 */
class PsColorSpace : public ColorSpace
{
   private:
      RegBase &Format_;
      RegBase &WordSwap_;
      RegBase &ByteSwap_;
   public:
      void SetColorFormat( ColFmt aColor );

      PsColorSpace( ColFmt aColForm, RegBase &aFormatReg, RegBase &WS,
         RegBase &BS ) :
         ColorSpace( aColForm ), Format_( aFormatReg ), WordSwap_( WS ),
            ByteSwap_( BS ) {}
};

#endif
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\drivers\wdm\capture\mini\bt848\pisces.h ===
// $Header: G:/SwDev/WDM/Video/bt848/rcs/Pisces.h 1.8 1998/05/06 18:25:31 tomz Exp $

#ifndef __PISCES_H
#define __PISCES_H

#include "preg.h"

#ifndef __FIELD_H
#include "field.h"
#endif

#ifndef __DECODER_H
#include "decoder.h"
#endif

#ifndef __RISCENG_H
#include "risceng.h"
#endif

typedef  void  (*EVENTHANDLER)( DWORD dwCB, PVOID pTag );

const PiscesStreams = 4;

#define BIT(x) ((DWORD)1 << (x))

const VSYNC_I     = BIT(1);         // 0x00000001
const I2CDONE_I   = BIT(8);         // 0x00000100
const GPINT_I     = BIT(9);         // 0x00000200
const RISC_I      = BIT(11);        // 0x00000800
const FBUS_I      = BIT(12);        // 0x00001000
const FTRGT_I     = BIT(13);        // 0x00002000
const FDSR_I      = BIT(14);        // 0x00004000
const PPERR_I     = BIT(15);        // 0x00008000
const RIPERR_I    = BIT(16);        // 0x00010000
const PABORT_I    = BIT(17);        // 0x00020000
const OCERR_I     = BIT(18);        // 0x00040000
const SCERR_I     = BIT(19);        // 0x00080000
const DMAERR_I    = BIT(20);        // 0x00100000

const PARITY_I    = (BIT(15)|BIT(16)); // 0x00018000

const EN_TRITON1_BUG_FIX   = BIT(23);  // 0x00800000

/* Class: IntrIdxAss
 * Purpose: Used to assiciate a number program will generate with IRQ and
 *   an index in the array
 */
class IntrIdxAss
{
   public:
      int   IntNo;
      int   Idx;
      IntrIdxAss() : IntNo( 0 ), Idx( 0 ) {}
      IntrIdxAss( int key, int value ) : IntNo( key ), Idx( value ) {}
      int operator ==( const IntrIdxAss &rhs ) { return IntNo == rhs.IntNo; }
};

/* Type: IntrToIdxDict
 * Purpose: Holds values of interrupt number and array index associated
 * Note Use TArrayAsVector instead of TIArrayAsVector ( it contains pointers,
 *   after all ) because compiler insists on calling vector_new which is
 *   non-existent in the VxD libs
 */
typedef IntrIdxAss *IntrToIdxDict [12];

/* Type: ProgramsArray
 * Purpose: Defines an array that holds created programs
 * Note: Elements in the array alternate, i.e. even program, odd, even...
 */
typedef RiscPrgHandle ProgramsArray [12];

// class CProgArray 
//
// assumptions:
//    1. Array size is 12.
//    2. The prog array has fixed locations for specific purposes:
//       0  VBIO
//       1  ODD
//       2  ODD Sync
//       3  VBIE
//       4  EVEN
//       5  EVEN Sync
// --------------------
//       6  VBIO     
//       7  ODD      
//       8  ODD Sync 
//       9  VBIE     
//       10 EVEN     
//       11 EVEN Sync
#define MAX_PROGS 12

class CProgArray {
private:
   DWORD dwCurrNdx_  ;
   RiscPrgHandle rpArray[MAX_PROGS] ;
public:
   CProgArray ()           { Clear() ;}
   virtual ~CProgArray ()  { } 

   // Clear sets all array elements handles to NULL
   void Clear() {
      dwCurrNdx_ = 0 ;
      memset( &rpArray[0], '\0', sizeof( rpArray ) )  ;
   }

   // overload for accessing the array
   inline RiscPrgHandle & operator [] (DWORD n) { 
      n %= MAX_PROGS ; // prevent invalid accesses
      return rpArray[n] ;
   } 

   // Return the index of the given handle. Assumes that the handle
   // was given by this class and is valid and current.
   DWORD GetIndex(RiscPrgHandle hRp)
   {
      for (int i = 0 ; i < MAX_PROGS ; i++)
         if (rpArray[i] == hRp)
            return i ;

      return (DWORD) -1 ;
   }

   //
   // Count Methods
   //

   // Returns the number of elements. Static for now.
   inline DWORD NumElements() { return MAX_PROGS ; }

   // Returns the number of non-null programs
   DWORD Count() {
      DWORD n = 0 ;
      for (int i = 0 ; i < MAX_PROGS ; i++)
         if (rpArray[i])
            n++ ;
      return n ;
   }

   // Returns the number of video programs
   inline DWORD CountVideoProgs() {
      DWORD n = 0 ;
      if (rpArray[1])  n++ ; 
      if (rpArray[4])  n++ ; 
      if (rpArray[7])  n++ ; 
      if (rpArray[10]) n++ ;
      return n ;
   }

   // Returns the number of vbi programs
   inline DWORD CountVbiProgs() {
      DWORD n = 0 ;
      if (rpArray[0]) n++ ;
      if (rpArray[3]) n++ ;
      if (rpArray[6]) n++ ;
      if (rpArray[9]) n++ ;
      return n ;
   }

   // Returns number of programs which actually transfer data
   inline DWORD CountDMAProgs() {
     return CountVideoProgs() + CountVbiProgs() ;
   }

   //
   // Find Methods
   //

   // Returns the first non-null riscprogram. Returns Null if array is empty.
   RiscPrgHandle First() {
      RiscPrgHandle hRp = NULL ;
      for (dwCurrNdx_ = 0 ; dwCurrNdx_ < MAX_PROGS ; dwCurrNdx_++) {
         if (rpArray[dwCurrNdx_]) {
            hRp = rpArray[dwCurrNdx_++] ;
            break ;
         }
      }
      return hRp ;
   }

   // Returns the next non-null riscprogram. Returns null if there are none left.
   RiscPrgHandle Next() {
      RiscPrgHandle hRp = NULL ;
      for ( ; dwCurrNdx_ < MAX_PROGS ; dwCurrNdx_++) {
         if (rpArray[dwCurrNdx_]) {
            hRp = rpArray[dwCurrNdx_++] ;
            break ;
         }
      }
      return hRp ;
   }
} ;

const VBIOStartLocation = 0;
const OddStartLocation  = 1;
const OddSyncStartLoc   = 2;
const VBIEStartLocation = 3;
const EvenStartLocation = 4;
const EvenSyncStartLoc  = 5;

const DistBetweenProgs     = 6;

const ProgsWithinField  = 3;

/* Class: BtPisces
 * Purpose: Controls the BtPisces video capture chip
 * Attributes:
 * Operations:
 * Note: Every time any of the Set functions is called, operation must stop.
 *   After all changes are done execution can resume. This means that all RISC
 *   programs are destroyed ( if they exist ), changes made, new RISC programs
 *   are created ( if needed )
*/
class BtPisces
{
      DECLARE_COLORCONTROL;
      DECLARE_INTERRUPTSTATUS;
      DECLARE_INTERRUPTMASK;
      DECLARE_CONTROL;
      DECLARE_CAPTURECONTROL;
      DECLARE_COLORFORMAT;
      DECLARE_GPIODATAIO;
      DECLARE_GPIOOUTPUTENABLECONTROL;

   public:
         Decoder       PsDecoder_;

   private:

         // all possible data streams
         FieldWithScaler Even_;
         FieldWithScaler Odd_;
         VBIField        VBIE_;
         VBIField        VBIO_;

         RISCEng       Engine_;
         RISCProgram   Starter_;
         RISCProgram   *Skippers_ [PiscesStreams * MaxProgsForField];

         RISCProgram   SyncEvenEnd1_;
         RISCProgram   SyncEvenEnd2_;

         RISCProgram   SyncOddEnd1_;
         RISCProgram   SyncOddEnd2_;

         CProgArray CreatedProgs_;
         CProgArray ActiveProgs_;

         IntrToIdxDict InterruptToIdx_;

         int           nSkipped_;
         int           OldIdx_;

         // this is the indirection array that maps an index from the CreatedProgs_
         // array into the Skippers_ array. It is needed because it is much simpler
         // to assign a strict relationships between a created program and a skipper
         // for it than trying to figure out what skipper program is available
         // when a created program needs to be skipped
         int           SkipperIdxArr_ [ProgsWithinField * 2 * MaxProgsForField];

         bool          Paused_;
         bool          Update_;

         bool          Inited_;
         DWORD         dwPlanarAdjust_;

         void Init();

         bool CreateSyncCodes();
         void ProcessRISCIntr();


   protected:

      // type-unsafe method of getting field associated with a stream
//      Field & GetField( StreamInfo &str ) { return *(Field*)str.tag; }
      int GetIdxFromStream( Field &aField );

      RiscPrgHandle AddProgram( Field &aStream, int NumberToAdd );
      void ProcessPresentPrograms();
      void AssignIntNumbers();
      void ProcessSyncPrograms();
      void LinkThePrograms();
      void Skip( int idx );
      void Restart();
      void GetStarted( bool &EvenWasStarted, bool &OddWasStarted,
         bool &VBIEWasStarted, bool &VBIOWasStarted );
      void RestartStreams( bool EvenWasStarted, bool OddWasStarted,
         bool VBIEWasStarted, bool VBIOWasStarted );
      void CreateStarter( bool EvenWasStarted );

      int  GetPassed();
//      void AdjustTime( LARGE_INTEGER &t, int passed );
      
      RiscPrgHandle GetProgram( int pos, int &idx );


   public:

      void PairedPause( int idx );
      void DumpRiscPrograms();

      // decoder 'set' group
      virtual void SetBrightness( DWORD value );
      virtual void SetSaturation( DWORD value );
      virtual void SetConnector ( DWORD value );
      virtual void SetContrast  ( DWORD value );
      virtual void SetHue       ( DWORD value );
      virtual void SetSVideo    ( DWORD value );
      virtual void SetFormat    ( DWORD value );

      virtual LONG GetSaturation();
      virtual LONG GetHue       ();
      virtual LONG GetBrightness();
      virtual LONG GetSVideo    ();
      virtual LONG GetContrast  ();
      virtual LONG GetFormat    ();
      virtual LONG GetConnector ();
      virtual LONG GetSupportedStandards();

              void SetPlanarAdjust( DWORD val ) { dwPlanarAdjust_ = val; }
              void TurnVFilter( State s );

        // scaler group
      virtual ErrorCode SetAnalogWindow( MRect &r, Field &aField );
      virtual ErrorCode SetDigitalWindow( MRect &r, Field &aField );

      // color space converter group
      virtual void SetPixelFormat( ColFmt, Field &aField );
      ColFmt GetPixelFormat( Field &aField );

      // streaming operation functions
      virtual ErrorCode Create( Field &aField );
      virtual void  Start( Field &aField );
      virtual void  Stop( Field &aField );
              void  Pause( Field &aField );
              void  Continue();
              State Interrupt();
//              void  ProcessAddBuffer( StreamInfo aStream );
              void  ProcessBufferAtInterrupt( PVOID pTag );

              void SetBufPitch( DWORD dwP, Field &aField )
              { aField.SetBufPitch( dwP ); }

       void SetBufQuePtr( Field &aField, VidBufQueue *pQ )
      { aField.SetBufQuePtr( pQ ); }

      VidBufQueue &GetCurrentQue( Field &aField )
      { return aField.GetCurrentQue(); }

      virtual ErrorCode AllocateStream( Field *&Field, VideoStream st );

      DWORD   GetDataBuffer( int idx ) { return CreatedProgs_ [idx]->GetDataBuffer(); }

      bool InitOK();

      BtPisces( DWORD *xtals );
      ~BtPisces();

};

inline bool BtPisces::InitOK()
{
   return Inited_;
}

#endif
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\drivers\wdm\capture\mini\bt848\pspagebl.h ===
// $Header: G:/SwDev/WDM/Video/bt848/rcs/Pspagebl.h 1.7 1998/04/29 22:43:36 tomz Exp $

#ifndef __PSPAGEBL_H
#define __PSPAGEBL_H

#ifndef __MYTYPES_H
#include "mytypes.h"
#endif

#ifndef __PHYSADDR_H
#include "physaddr.h"
#endif

// unlike things in ks.h, this is a real forward declaration
extern PVOID gpHwDeviceExtension;

/* Class: PsPageBlock
 * Purpose: Encapsulates memory allocations for the data buffers and RISC programs
 */
class PsPageBlock
{
   protected:
      DWORD  PhysAddr_;
      PVOID  LinAddr_;

      void AllocateSpace( DWORD dwSize );
      void FreeSpace();
   public:
      PsPageBlock( DWORD dwSize );
      ~PsPageBlock();

      DWORD GetPhysAddr();
      DWORD getLinearBase();
};

inline PsPageBlock::PsPageBlock( DWORD dwSize )
{
   AllocateSpace( dwSize );
}

inline PsPageBlock::~PsPageBlock()
{
   FreeSpace();
}

inline DWORD PsPageBlock::GetPhysAddr()
{
   return PhysAddr_;
}

inline DWORD PsPageBlock::getLinearBase()
{
   return (DWORD)LinAddr_;
}

#endif
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\drivers\wdm\capture\mini\bt848\queue.h ===
// $Header: G:/SwDev/WDM/Video/bt848/rcs/Queue.h 1.5 1998/05/08 18:18:52 tomz Exp $

#ifndef __QUEUE_H
#define __QUEUE_h

const QueSize = 200;
/* Class: VidBufQueue
 * Purpose: Queue of buffers to be sent to BtPisces
 */
template <class T> class Queue
{
   private:
      T  Data [QueSize];
      T	 Dummy;
	   unsigned items;
      unsigned left;
      unsigned right;
      unsigned size;
   public:

      bool IsFull();
      bool IsEmpty();

      unsigned Prev( unsigned index ) const;
      unsigned Next( unsigned index ) const;

      T Get();
      T GetRight();

      void Put( const T& t );
      T PeekLeft();
      T PeekRight();

      void Flush();

      int GetNumOfItems();

      Queue();
      ~Queue();
};

template <class T>  bool Queue<T>::IsFull()
{
   return right == Prev( left );
}

template <class T> bool Queue<T>::IsEmpty()
{
   return !items;
}

template <class T> int Queue<T>::GetNumOfItems()
{
   return items;
}

template <class T> unsigned Queue<T>::Prev( unsigned index ) const
{
   if ( index == 0 )
      index = size;
   return --index;
}

template <class T> unsigned Queue<T>::Next( unsigned index ) const
{
   index++;
   if ( index == size )
      index = 0;
   return index;
}

template <class T> T Queue<T>::Get()
{
	if(!items){
		DebugOut((0, "Queue::Get called on empty queue!!!\n"));
//	 	DEBUG_BREAKPOINT();
		return Dummy;
	}
   T t = Data [left];
   Data [left] = T();
   left = Next( left );
   items--;
   return t;
}

/* Method: Queue::GetRight
 * Purpose: Gets the next element
 * Note: Extreme caution must be used when calling this function. The caller must
 *   make sure the queue is not empty before calling it. Otherwise bogus data
 *   will be returned
 */
template <class T> T Queue<T>::GetRight()
{
	if(!items){
		DebugOut((0, "Queue::GetRight called on empty queue!!!\n"));
//		DEBUG_BREAKPOINT();
		return Dummy;
	}
    right = Prev( right );
    T t = Data [right];
    Data[right] = T();
    items--;
    return t;
}

template <class T> void Queue<T>::Flush()
{
	if(items){
		DebugOut((0, "Queue::Flush called on non-empty queue, %d items lost!!!\n", items));
//		DEBUG_BREAKPOINT();
	}
   items = left = right = 0;
}

template <class T> void Queue<T>::Put( const T& t )
{
	if ( items >= size ){
		DebugOut((0, "Queue::Put called on Full queue!!!\n"));
//		DEBUG_BREAKPOINT();
      return;
	}
   Data [right] = t;
   right = Next( right );
   items++;
}

template <class T> Queue<T>::Queue()
   : Data(), Dummy(), items( 0 ), left( 0 ), right( 0 ), size( QueSize )
{
}

template <class T> T Queue<T>::PeekLeft()
{
	if(!items){
		DebugOut((0, "Queue::PeekLeft called on empty queue!!!\n"));
//		DEBUG_BREAKPOINT();
		return Dummy;
	}
   return Data [left];
}

template <class T> T Queue<T>::PeekRight()
{
	if(!items){
		DebugOut((0, "Queue::PeekRight called on empty queue!!!\n"));
//		DEBUG_BREAKPOINT();
		return Dummy;
	}
   return Data [Prev( right )];
}

template <class T> Queue<T>::~Queue()
{
}

typedef Queue<PHW_STREAM_REQUEST_BLOCK> SRBQueue;


#endif
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\drivers\wdm\capture\mini\bt848\regfield.cpp ===
// $Header: G:/SwDev/WDM/Video/bt848/rcs/Regfield.cpp 1.3 1998/04/29 22:43:36 tomz Exp $

#include "regfield.h"

/* Method: RegField::MakeAMask
 * Purpose: Computes a mask used to isolate a field withing a register based
 *   on the width of a field
 */
inline DWORD RegField::MakeAMask()
{
//   compute the mask to apply to the owner register to reset
//   all bits that are part of a field. Mask is based on the size of a field
   return ::MakeAMask( FieldWidth_ );
}

/* Method: RegField::operator DWORD()
 * Purpose: Performs the read from a field of register
*/
RegField::operator DWORD()
{
   // if write-only, get the shadow
   if ( GetRegisterType() == WO )
      return GetShadow();

   // for RO and RW do the actual read
   // get the register data and move it to the right position
   DWORD dwValue = ( Owner_ >> StartBit_ );

   DWORD dwMask = MakeAMask();

   return dwValue & dwMask;
}


/* Method: RegField::operator=
 * Purpose: performs the assignment to a field of register
 * Note:
   This function computes the mask to apply to the owner register to reset
   all bits that are part of a field. Mask is based on the start position and size
   Then it calculates the proper value from the passed argument ( moves the size
   number of bits to the starting position ) and ORs these bits in the owner register.
*/
DWORD RegField::operator=( DWORD dwValue )
{
// if a register is read-only nothing is done. This is an error
   if ( GetRegisterType() == RO )
      return ReturnAllFs();

   SetShadow( dwValue );

   // get a mask
   DWORD dwMask = MakeAMask();

   // move mask to a proper position
   dwMask = dwMask << StartBit_;

//   calculate the proper value from the passed argument ( move the size
//   number of bits to the starting position )
   DWORD dwFieldValue = dwValue << StartBit_;
   dwFieldValue &= dwMask;

   // do not perform intermediate steps on the owner; rather use a temp and update
   // the owner at once
   DWORD dwRegContent = Owner_;

   // reset the relevant bits
   if ( GetRegisterType() == RR )
      dwRegContent = 0;
   else
      dwRegContent &= ~dwMask;

   // OR these bits in the owner register.
   dwRegContent |= dwFieldValue;

   Owner_ = dwRegContent;
   return dwValue;
}
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\drivers\wdm\capture\mini\bt848\regbase.h ===
// $Header: G:/SwDev/WDM/Video/bt848/rcs/Regbase.h 1.5 1998/05/08 00:11:02 tomz Exp $

#ifndef __REGBASE_H
#define __REGBASE_H

#include "mytypes.h"

/* Type: AllFs
 * Purpose: To be used as an error return value from register accessing
 *   functions. All bits are set to 1.
 */
const DWORD AllFs = (DWORD) ~0L;

/* Function: ReturnAllFs
 * Purpose: This function is used in the register access methods to indicate
 *   that some sort of error has occured. Used for easing the debugging, as
 *   it contains a macro to print the error if DEBUG is #defined
 */
inline DWORD ReturnAllFs()
{
//    OUTPUT_MESS( ALLFS );
    return  AllFs;
}

/*
 * Type: RegisterType
 * Purpose: A type to differentiate between diferent kinds of registers.
 *   Depending on the type register may not peforms certain operations
 *   RW - read/write, RO - read-only, WO - write-only
*/
typedef enum { RW, RO, WO, RR } RegisterType;

/* Class: RegBase
 * Purpose:
 *   Defines the interface and encapsulates the register access.
 * Attributes:
 *   pBaseAddress_: DWORD, static. Holds the base address of the registers. On the
 *   PCI bus it is a 32 bit memory address. On the ISA bus it is a 16 bit I/O address.
 *   type_: RegisterType - defines the access permission for the register.
 *   dwShadow_: DWORD - a local copy of the register. Used for returning a value
 *   of write-only registers
 * Operations:
 *   operator DWORD(): data access method. Pure virtual
 *   DWORD operator=( DWORD ): assignment operator. Pure virtual. This assignment
 *      operator does not return a reference to the class because of the performance reasons
 *   void SetBaseAddress( DWORD )
 *   DWORD GetBaseAddress()
 *   RegisterType GetRegisterType()
 *   void SetShadow( DWORD ): assigns a value of a register to a shadow
 *   DWORD GetShadow( void ): retrieves a value from a shadow
 */
class RegBase
{
    private:
         RegisterType type_;
         DWORD        dwShadow_;

         RegBase();

    protected:
         void  SetShadow( DWORD dwValue );
         DWORD GetShadow();
    public:
         RegBase( RegisterType aType ) :
            type_( aType ), dwShadow_( 0 )
         {}

         static LPBYTE GetBaseAddress() {
            extern BYTE *GetBase();
            return GetBase(); 
         }
         RegisterType GetRegisterType() { return type_; }
         virtual operator DWORD() = 0;
         virtual DWORD operator=( DWORD dwValue ) = 0;
         virtual ~RegBase() {}
};

/* Method: RegBase::SetShadow
 * Purpose: Used to store the value of a register in the shadow
 * Input: dwValue: DWORD - new value of a register
 * Output: None
 * Note: inline
 */
inline void  RegBase::SetShadow( DWORD dwValue ) { dwShadow_ = dwValue; }

/* Method: RegBase::GetShadow
 * Purpose: Used to obtain the last value written to a write-only register
 *    from the shadow
 * Input: None
 * Output: DWORD
 * Note: inline
 */
inline DWORD RegBase::GetShadow() { return dwShadow_; }

#endif __REGBASE_H
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\drivers\wdm\capture\mini\bt848\regfield.h ===
// $Header: G:/SwDev/WDM/Video/bt848/rcs/Regfield.h 1.3 1998/04/29 22:43:36 tomz Exp $

#ifndef __REGFIELD_H
#define __REGFIELD_H

#ifndef __REGISTER_H
#include "register.h"
#endif

// maximum size of a register in bits
const BYTE MaxWidth = 32;

/* Class: RegField
 * Purpose: This class encapsulates the behaviour of a register which is a set
 *   of bits withing a larger register
 * Attributes:
 *   Owner_: Register & - reference to the register that contains this field.
 *   It is a reference to Register class because actual register can be either one of
 *   byte, word or dword registers.
 *   StartBit_: BYTE - starting position of this field
 *   FieldWidth_: BYTE - width of this field in bits
 * Operations:
 *   operator DWORD(): data access method. Returns a value of the register
 *   DWORD operator=( DWORD ): assignment operator. Used to set the register
 *   These operations assume that a parent register has RW attribute set, though
 *   not all register fields of it are read-write. If RW is not used for the parent
 *   this class may be in error.
 * Note: the error handling provided by the class is minimal. It is a responibility
 *   of the user to pass correct parameters to the constructor. The class has
 *   no way of knowing if the correct owning registe passed in is correct,
 *   for example. If starting bit or width is beyond the maximum field width
 *   the mask used to isolate the field will be 0xFFFFFFFF
 */
class RegField : public RegBase
{
   private:
      Register &Owner_;
      BYTE      StartBit_;
      BYTE      FieldWidth_;
      DWORD     MakeAMask();
      RegField();
   public:
      virtual operator DWORD();
      virtual DWORD operator=( DWORD dwValue );
      RegField( Register &AnOwner, BYTE nStart, BYTE nWidth, RegisterType aType ) :
         RegBase( aType ), Owner_( AnOwner ), StartBit_( nStart ),
         FieldWidth_( nWidth ) {}
};

/* Function: MakeAMask
 * Purpose: Creates a bit mask to be used in different register classes
 * Input:
 *   bWidth: BYTE - width of a mask in bits
 * Output:
 *   DWORD
 * Note: This function is inline
 */
inline DWORD MakeAMask( BYTE bWidth )
{
   return ( bWidth >= 32 ? 0 : (DWORD)1 << bWidth ) - 1;
}

#endif __REGFIELD_H
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\drivers\wdm\capture\mini\bt848\register.cpp ===
// $Header: G:/SwDev/WDM/Video/bt848/rcs/Register.cpp 1.3 1998/04/29 22:43:36 tomz Exp $

#include "register.h"

/* Method: Register::operator DWORD()
 * Purpose: a dummy function. Always returns -1
*/
Register::operator DWORD()
{
   return ReturnAllFs();
}


/* Method: Register::operator=
 * Purpose: a dummy function. Does not perform an assignment. Always returns -1
*/
DWORD Register::operator=( DWORD )
{
   return ReturnAllFs();
}

/* Method: RegisterB::operator DWORD()
 * Purpose: Performs the read from a byte register
*/
RegisterB::operator DWORD()
{
   // if write-only return the shadow
   if ( GetRegisterType() == WO )
      return GetShadow();

   // for RO and RW do the actual read
   LPBYTE pRegAddr = GetBaseAddress() + GetOffset();
   return READ_REGISTER_UCHAR( pRegAddr );
}


/* Method: RegisterB::operator=
 * Purpose: performs the assignment to a byte register
*/
DWORD RegisterB::operator=( DWORD dwValue )
{
// if a register is read-only nothing is done. This is an error
   if ( GetRegisterType() == RO )
      return ReturnAllFs();

   // keep a shadow around
   SetShadow( dwValue );

   LPBYTE pRegAddr = GetBaseAddress() + GetOffset();
   WRITE_REGISTER_UCHAR( pRegAddr, (BYTE)dwValue );

   return dwValue;
}

/* Method: RegisterW::operator DWORD()
 * Purpose: Performs the read from a word register
*/
RegisterW::operator DWORD()
{
   // if write-only return the shadow
   if ( GetRegisterType() == WO )
      return GetShadow();

   // for RO and RW do the actual read
   LPWORD pRegAddr = (LPWORD)( GetBaseAddress() + GetOffset() );
   return READ_REGISTER_USHORT( pRegAddr );
}


/* Method: RegisterW::operator=
 * Purpose: performs the assignment to a word register
*/
DWORD RegisterW::operator=( DWORD dwValue )
{
// if a register is read-only nothing is done. This is an error
   if ( GetRegisterType() == RO )
      return ReturnAllFs();

   // keep a shadow around
   SetShadow( dwValue );

   LPWORD pRegAddr = (LPWORD)( GetBaseAddress() + GetOffset() );
   *pRegAddr = (WORD)dwValue;
   WRITE_REGISTER_USHORT( pRegAddr, (WORD)dwValue );

   return dwValue;
}

/* Method: RegisterDW::operator DWORD()
 * Purpose: Performs the read from a dword register
*/
RegisterDW::operator DWORD()
{
   // if write-only return the shadow
   if ( GetRegisterType() == WO )
      return GetShadow();

   // for RO and RW do the actual read
   LPDWORD pRegAddr = (LPDWORD)( GetBaseAddress() + GetOffset() );
   return READ_REGISTER_ULONG( pRegAddr );
}


/* Method: RegisterDW::operator=
 * Purpose: performs the assignment to a dword register
*/
DWORD RegisterDW::operator=( DWORD dwValue )
{
// if a register is read-only nothing is done. This is an error
   if ( GetRegisterType() == RO )
      return ReturnAllFs();

   // keep a shadow around
   SetShadow( dwValue );

   LPDWORD pRegAddr = (LPDWORD)( GetBaseAddress() + GetOffset() );
   WRITE_REGISTER_ULONG( pRegAddr, dwValue );
   return dwValue;
}
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\drivers\wdm\capture\mini\bt848\register.h ===
// $Header: G:/SwDev/WDM/Video/bt848/rcs/Register.h 1.3 1998/04/29 22:43:36 tomz Exp $

#ifndef __REGISTER_H
#define __REGISTER_H



#ifndef __REGBASE_H
#include "regbase.h"
#endif

/* Type: Register
 * Purpose: An intermediate class between the RegBase and actual usable classes.
 *   Actual classes are RegisterB, RegisterW, RegisterDW
 * Attributes:
 *   uOffset_: unsigned int - an offset of the register from the base
 * Operations:
 *   GetOffset(): returns the offset value. Protected
 *   operator DWORD(): data access method. Always returns -1
 *   DWORD operator=( DWORD ): assignment operator. Always returns -1
 * Note:
 *   The reason to have operators in this class is for the register field class
 *   to have a member of type 'reference to Register'. Otherwise RegField is not
 *   able to use access methods.
 */
class Register : public RegBase
{
   private:
      unsigned int uOffset_;
      Register();
    protected:

    public:
         unsigned int GetOffset() { return uOffset_; }

         virtual operator DWORD();
      virtual DWORD operator=( DWORD dwValue );

         Register( unsigned int uOff, RegisterType aType ) :
            RegBase( aType ), uOffset_( uOff ) {}
};

/* Type: RegisterB
 * Purpose: A register that performs the BYTE I/O
 * Note:
 *   This class has no additional data members, it just overloads operators
 */
class RegisterB : public Register
{
    private:
         RegisterB();
    public:
         virtual operator DWORD();
         virtual DWORD operator=( DWORD dwValue );
         RegisterB( unsigned int uOff, RegisterType aType ) :
            Register( uOff, aType ) {};
};

/* Type: RegisterW
 * Purpose: A register that performs the WORD I/O
 * Note:
 *   This class has no additional data members, it just overloads operators
 */
class RegisterW : public Register
{
    private:
         RegisterW();
    public:
         virtual operator DWORD();
         virtual DWORD operator=( DWORD dwValue );
         RegisterW( unsigned int uOff, RegisterType aType ) :
            Register( uOff, aType ) {};

};


/* Type: RegisterDW
 * Purpose: A register that performs the DWORD I/O
 * Note:
 *   This class has no additional data members, it just overloads operators
 */
class RegisterDW : public Register
{
    private:
         RegisterDW();
    public:
         virtual operator DWORD();
         virtual DWORD    operator=( DWORD dwValue );

         RegisterDW( unsigned int uOff, RegisterType aType ) :
            Register( uOff, aType ) {};
};

#endif __REGISTER_H
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\drivers\wdm\capture\mini\bt848\registry.cpp ===
// $Header: G:/SwDev/WDM/Video/bt848/rcs/Registry.cpp 1.7 1998/05/07 15:24:55 tomz Exp $

extern "C" {
#include <strmini.h>
}
#include "device.h"

//LONG  PsDevice::PinTypes_ [MaxInpPins]; // just allocate maximum possible
//DWORD PsDevice::xtals_ [2]; // no more than 2 xtals

/*++

Routine Description:

    Reads the specified registry value

Arguments:

    Handle - handle to the registry key
    KeyNameString - value to read
    KeyNameStringLength - length of string
    Data - buffer to read data into
    DataLength - length of data buffer

Return Value:

    NTSTATUS returned as appropriate

--*/
NTSTATUS GetRegistryValue( IN HANDLE Handle, IN const PUNICODE_STRING KeyName,
   IN PCHAR Data, IN ULONG DataLength )
{
   NTSTATUS        Status = STATUS_INSUFFICIENT_RESOURCES;
   ULONG           Length;
   PKEY_VALUE_FULL_INFORMATION FullInfo;

   Length = sizeof( KEY_VALUE_FULL_INFORMATION ) + DataLength + KeyName->MaximumLength;

   FullInfo = (struct _KEY_VALUE_FULL_INFORMATION *)ExAllocatePool(PagedPool, Length);

   if ( FullInfo ) {
      Status = ZwQueryValueKey( Handle, KeyName, KeyValueFullInformation,
         FullInfo, Length, &Length );

      if ( NT_SUCCESS( Status ) ) {

         if ( DataLength >= FullInfo->DataLength ) {
            RtlCopyMemory( Data, ((PUCHAR) FullInfo) + FullInfo->DataOffset,
               FullInfo->DataLength );

         } else {
            Status = STATUS_BUFFER_TOO_SMALL;
         }                   // buffer right length
     }                       // if success
     ExFreePool( FullInfo );
   }                           // if fullinfo
   return Status;
}

/* Function: OpenDriverKey
 * Purpose: Opens the DriverData key off the main driver key
 * Input: PhysicalDeviceObject : DEVICE_OBJECT *
 * Output: Open key handle or NULL
 */
HANDLE OpenDriverKey( IN PDEVICE_OBJECT PhysicalDeviceObject )
{
   NTSTATUS   Status;
   HANDLE     DevHandle;

   Status = IoOpenDeviceRegistryKey( PhysicalDeviceObject, PLUGPLAY_REGKEY_DRIVER,
      STANDARD_RIGHTS_ALL, &DevHandle );

   HANDLE KeyHandle = NULL;
   if ( NT_SUCCESS( Status ) ) {
      OBJECT_ATTRIBUTES attr;
      UNICODE_STRING UDevDataName;
      PWCHAR WDataName = L"DriverData";

      RtlInitUnicodeString( &UDevDataName, WDataName );
      InitializeObjectAttributes( &attr, &UDevDataName, OBJ_INHERIT, DevHandle,
         NULL );

      ZwOpenKey( &KeyHandle, KEY_QUERY_VALUE, &attr );
      ZwClose( DevHandle );
   }
   return KeyHandle;
}
/* Function: PrepareKeyName
 * Purpose: Creates a UNICODE name for a key
 * Parameters: UKeyName: UNICODE_STRING * - key will be created here
 *   name: PCHAR - regular "C" string
 *   idx: int - number to append to the name
 * Note: this function is useful in creating numbered key names
 */
inline void PrepareKeyName( PUNICODE_STRING UKeyName, PCHAR name, int idx )
{
   char buf [80];
   ANSI_STRING  AKeyName;

   if ( idx == -1 )
   {
      RtlInitAnsiString( &AKeyName, name );
   }
   else
   {
      sprintf( buf, "%s%d", name, idx );
      RtlInitAnsiString( &AKeyName, buf );
   }

   RtlAnsiStringToUnicodeString( UKeyName, &AKeyName, TRUE );
}

/*++

Routine Description:

    Reads the XBAR registry values for the device

Arguments:

    PhysicalDeviceObject - pointer to the PDO

Return Value:

     None.

--*/
void ReadXBarRegistryValues( IN PDEVICE_OBJECT PhysicalDeviceObject )
{
   HANDLE KeyHandle = OpenDriverKey( PhysicalDeviceObject );

   if ( KeyHandle ) {

      for ( int i = 0; i < MaxInpPins; i++ ) {

         UNICODE_STRING  UKeyName;

         PrepareKeyName( &UKeyName, "XBarInPin", i );

         CHAR buf [10];

         NTSTATUS   Status;
         Status = GetRegistryValue( KeyHandle, &UKeyName, buf, sizeof( buf ) );

         RtlFreeUnicodeString( &UKeyName );

         if ( NT_SUCCESS(Status ) ) {
            DebugOut((1, "ReadRegistry %d\n", i ) );
            PinTypes_ [i] = *(PDWORD)buf;
         } else
            PinTypes_ [i] = -1;
     }
     ZwClose( KeyHandle );
   } else { // just use some default to make life eaiser for the xbar code
      PinTypes_ [0] = KS_PhysConn_Video_SVideo;
      PinTypes_ [1] = KS_PhysConn_Video_Tuner;
      PinTypes_ [2] = KS_PhysConn_Video_Composite;
      PinTypes_ [3] = KS_PhysConn_Audio_Tuner;
   }
}

/* Method: ReadXTalRegistryValues
 * Purpose: Obtains number and types of the crystals for this device
 * Input: DEVICE_OBJECT *
 * Output: None
 */
void ReadXTalRegistryValues( IN PDEVICE_OBJECT PhysicalDeviceObject )
{
   HANDLE KeyHandle = OpenDriverKey( PhysicalDeviceObject );

   if ( KeyHandle ) {

      for ( int i = 0; i < 2; i++ ) {

         UNICODE_STRING  UKeyName;

         PrepareKeyName( &UKeyName, "XTal", i );

         CHAR buf [10];

         NTSTATUS   Status;
         Status = GetRegistryValue( KeyHandle, &UKeyName, buf, sizeof( buf ) );

         RtlFreeUnicodeString( &UKeyName );

         if ( NT_SUCCESS(Status ) ) {
            DebugOut((1, "Got Xtal %d\n", i ) );
            xtals_ [i] = *(PDWORD)buf;
         } else
            xtals_ [i] = 28; // is this a good default ? :0)
     }
     ZwClose( KeyHandle );
   } else  // just use some default to make life eaiser for the xbar code
      xtals_ [0] = 28; // default to NTSC only
}

TUNER_INFO TunerInfo;

void DumpTunerInfo( TUNER_INFO * pTunerInfo )
{
   DUMPX( pTunerInfo->TunerBrand );
   DUMPX( pTunerInfo->TunerI2CAddress );
   DUMPX( pTunerInfo->TunerBandCtrlLow );
   DUMPX( pTunerInfo->TunerBandCtrlMid );
   DUMPX( pTunerInfo->TunerBandCtrlHigh );
}

void ReadTunerRegistryValues( IN PDEVICE_OBJECT PhysicalDeviceObject )
{
   HANDLE KeyHandle = OpenDriverKey( PhysicalDeviceObject );

   if ( KeyHandle )
   {

      CHAR buf [10];
      NTSTATUS   Status;
      UNICODE_STRING  UKeyName;
      BOOL bSuccess = TRUE;

      PrepareKeyName( &UKeyName, "TunerBrand", -1 );
      Status = GetRegistryValue( KeyHandle, &UKeyName, buf, sizeof( buf ) );
      if ( bSuccess = NT_SUCCESS(Status ) )
      {
         TunerInfo.TunerBrand = *(PDWORD)buf;

         PrepareKeyName( &UKeyName, "TunerI2CAddress", -1 );
         Status = GetRegistryValue( KeyHandle, &UKeyName, buf, sizeof( buf ) );
         if ( bSuccess = NT_SUCCESS(Status ) ) {
            TunerInfo.TunerI2CAddress = *(PBYTE)buf;
         }
         else
         {
            DebugOut((0, "Failed GetRegistryValue(TunerI2CAddress)\n"));
         }
      }
      else
      {
         DebugOut((0, "Failed GetRegistryValue(TunerBrand)\n"));
      }

      if ( !bSuccess )
      {
         TunerInfo.TunerBrand          = TUNER_BRAND_TEMIC;
         TunerInfo.TunerI2CAddress     = 0xC2;
         DebugOut((0, "Defaulting to Temic tuner at I2C address 0xC2\n"));
      }

      RtlFreeUnicodeString( &UKeyName );
      ZwClose( KeyHandle );
   } 
   else
   {
      TunerInfo.TunerBrand          = TUNER_BRAND_TEMIC;
      TunerInfo.TunerI2CAddress     = 0xC2;
      DebugOut((0, "Failed OpenDriverKey()\n"));
      DebugOut((0, "Defaulting to Temic tuner at I2C address 0xC2\n"));
   }

   switch( TunerInfo.TunerBrand )
   {
   case TUNER_BRAND_PHILIPS:
      TunerInfo.TunerBandCtrlLow  = 0xCEA0;  // Ctrl code for VHF low
      TunerInfo.TunerBandCtrlMid  = 0xCE90;  // Ctrl code for VHF high
      TunerInfo.TunerBandCtrlHigh = 0xCE30;  // Ctrl code for UHF
      break;
   case TUNER_BRAND_ALPS:
      TunerInfo.TunerBandCtrlLow  = 0xC214;  // Ctrl code for VHF low
      TunerInfo.TunerBandCtrlMid  = 0xC212;  // Ctrl code for VHF high
      TunerInfo.TunerBandCtrlHigh = 0xC211;  // Ctrl code for UHF
      break;
   case TUNER_BRAND_TEMIC:
   default:
      TunerInfo.TunerBandCtrlLow  = 0x8E02;  // Ctrl code for VHF low
      TunerInfo.TunerBandCtrlMid  = 0x8E04;  // Ctrl code for VHF high
      TunerInfo.TunerBandCtrlHigh = 0x8E01;  // Ctrl code for UHF
      break;
   }

   DumpTunerInfo( &TunerInfo );
}
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\drivers\wdm\capture\mini\bt848\retcode.h ===
// $Header: G:/SwDev/WDM/Video/bt848/rcs/Retcode.h 1.3 1998/04/29 22:43:37 tomz Exp $

#ifndef __RETCODE_H
#define __RETCODE_H

/* Type: ErrorCode
 * Purpose: Defines the error codes
 */
typedef enum { Success, Fail } ErrorCode;
#define ERROR_CODE_DEFINED



#endif
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\drivers\wdm\capture\mini\bt848\rgb24fmt.h ===
// $Header: G:/SwDev/WDM/Video/bt848/rcs/Rgb24fmt.h 1.5 1998/04/29 22:43:37 tomz Exp $

#ifndef __RGB24FMT_H
#define __RGB24FMT_H

#ifndef __DEFAULTS_H
#include "defaults.h"
#endif


KS_DATARANGE_VIDEO StreamFormatRGB24Bpp =
{
   // KSDATARANGE
   {
      {
         sizeof( KS_DATARANGE_VIDEO ),
         0,
         DefWidth * DefHeight * 3,               // SampleSize
         0,                                      // Reserved
         { STATIC_KSDATAFORMAT_TYPE_VIDEO },
         { 0xe436eb7d, 0x524f, 0x11ce, { 0x9f, 0x53, 0x00, 0x20, 0xaf, 0x0b, 0xa7, 0x70 } }, //MEDIASUBTYPE_RGB24,
         { STATIC_KSDATAFORMAT_SPECIFIER_VIDEOINFO }
      }
   },
   true,
   true,
   KS_VIDEOSTREAM_PREVIEW, // StreamDescriptionFlags  (KS_VIDEO_DESC_*)
   0,       // MemoryAllocationFlags   (KS_VIDEO_ALLOC_*)

   // _KS_VIDEO_STREAM_CONFIG_CAPS
   {
      { STATIC_KSDATAFORMAT_SPECIFIER_VIDEOINFO }, // GUID
      KS_AnalogVideo_NTSC_M,                       // AnalogVideoStandard
      {
         MaxInWidth, MaxInHeight   // SIZE InputSize
      },
      {
         MinInWidth, MinInHeight   // SIZE MinCroppingSize;       smallest rcSrc cropping rect allowed
      },
      {
         MaxInWidth, MaxInHeight   // SIZE MaxCroppingSize;       largest rcSrc cropping rect allowed
      },
      2,           // int CropGranularityX;       // granularity of cropping size
      2,           // int CropGranularityY;
      2,           // int CropAlignX;             // alignment of cropping rect
      2,           // int CropAlignY;
      {
         MinOutWidth, MinOutHeight   // SIZE MinOutputSize;  smallest bitmap stream can produce
      },
      {
         MaxOutWidth, MaxOutHeight   // SIZE MaxOutputSize;  largest  bitmap stream can produce
      },
      2,          // int OutputGranularityX;     // granularity of output bitmap size
      2,          // int OutputGranularityY;
      0,          // StretchTapsX  (0 no stretch, 1 pix dup, 2 interp...)
      0,          // StretchTapsY
      2,          // ShrinkTapsX
      2,          // ShrinkTapsY
      333667,     // LONGLONG MinFrameInterval;  // 100 nS units
      333667,     // LONGLONG MaxFrameInterval;
      3 * 30 * MinOutWidth * MinOutHeight,// LONG MinBitsPerSecond;
      3 * 30 * MaxOutWidth * MaxOutHeight //LONG MaxBitsPerSecond;
   },

   // KS_VIDEOINFOHEADER (default format)
   {
      { 0,0,0,0 },  //    RECT            rcSource;          // The bit we really want to use
      { 0,0,0,0 },  //    RECT            rcTarget;          // Where the video should go
      DefWidth * DefHeight * 3 * 30L,      //    DWORD           dwBitRate;         // Approximate bit data rate
      0L,           //    DWORD           dwBitErrorRate;    // Bit error rate for this stream
      333667,       //    REFERENCE_TIME  AvgTimePerFrame;   // Average time per frame (100ns units)
      {
         sizeof( KS_BITMAPINFOHEADER ), //    DWORD      biSize;
         DefWidth,                   //    LONG       biWidth;
         DefHeight,                  //    LONG       biHeight;
         1,                          //    WORD       biPlanes;
         24,                         //    WORD       biBitCount;
         KS_BI_RGB,                  //    DWORD      biCompression;
         DefWidth * DefHeight * 3,   //    DWORD      biSizeImage;
         0,                          //    LONG       biXPelsPerMeter;
         0,                          //    LONG       biYPelsPerMeter;
         0,                          //    DWORD      biClrUsed;
         0                           //    DWORD      biClrImportant;
      }
   }
};

KS_DATARANGE_VIDEO2 StreamFormat2RGB24Bpp =
{
   // KSDATARANGE
   {
      {
         sizeof( KS_DATARANGE_VIDEO2 ),
         0,
         DefWidth * DefHeight * 3,               // SampleSize
         0,                                      // Reserved
         { STATIC_KSDATAFORMAT_TYPE_VIDEO },
         { 0xe436eb7d, 0x524f, 0x11ce, { 0x9f, 0x53, 0x00, 0x20, 0xaf, 0x0b, 0xa7, 0x70 } }, //MEDIASUBTYPE_RGB24,
         { STATIC_KSDATAFORMAT_SPECIFIER_VIDEOINFO2 }
      }
   },
   true,
   true,
   KS_VIDEOSTREAM_PREVIEW, // StreamDescriptionFlags  (KS_VIDEO_DESC_*)
   0,       // MemoryAllocationFlags   (KS_VIDEO_ALLOC_*)

   // _KS_VIDEO_STREAM_CONFIG_CAPS
   {
      { STATIC_KSDATAFORMAT_SPECIFIER_VIDEOINFO2 }, // GUID
      KS_AnalogVideo_NTSC_M,                       // AnalogVideoStandard
      {
         MaxInWidth, MaxInHeight   // SIZE InputSize
      },
      {
         MinInWidth, MinInHeight   // SIZE MinCroppingSize;       smallest rcSrc cropping rect allowed
      },
      {
         MaxInWidth, MaxInHeight   // SIZE MaxCroppingSize;       largest rcSrc cropping rect allowed
      },
      2,           // int CropGranularityX;       // granularity of cropping size
      2,           // int CropGranularityY;
      2,           // int CropAlignX;             // alignment of cropping rect
      2,           // int CropAlignY;
      {
         MinOutWidth, MinOutHeight   // SIZE MinOutputSize;  smallest bitmap stream can produce
      },
      {
         MaxOutWidth, MaxOutHeight   // SIZE MaxOutputSize;  largest  bitmap stream can produce
      },
      2,          // int OutputGranularityX;     // granularity of output bitmap size
      2,          // int OutputGranularityY;
      0,          // StretchTapsX  (0 no stretch, 1 pix dup, 2 interp...)
      0,          // StretchTapsY
      2,          // ShrinkTapsX
      2,          // ShrinkTapsY
      333667,     // LONGLONG MinFrameInterval;  // 100 nS units
      333667,     // LONGLONG MaxFrameInterval;
      3 * 30 * MinOutWidth * MinOutHeight,// LONG MinBitsPerSecond;
      3 * 30 * MaxOutWidth * MaxOutHeight //LONG MaxBitsPerSecond;
   },

   // KS_VIDEOINFOHEADER2 (default format)
   {
      { 0,0,0,0 },  //    RECT            rcSource;          // The bit we really want to use
      { 0,0,0,0 },  //    RECT            rcTarget;          // Where the video should go
      DefWidth * DefHeight * 3 * 30L,      //    DWORD           dwBitRate;         // Approximate bit data rate
      0L,           //    DWORD           dwBitErrorRate;    // Bit error rate for this stream
      333667,       //    REFERENCE_TIME  AvgTimePerFrame;   // Average time per frame (100ns units)
#if 0
		//TODO: video memory must be available for interlacing to work
		KS_INTERLACE_IsInterlaced |		//		DWORD		dwInterlaceFlags
#else
			KS_INTERLACE_1FieldPerSample 
			//| KS_INTERLACE_Field1First
			//| KS_INTERLACE_FieldPatField1Only
			| KS_INTERLACE_FieldPatBothRegular
			| KS_INTERLACE_DisplayModeBobOnly,
			//| KS_INTERLACE_DisplayModeBobOrWeave,
#endif
											//		use AMINTERLACE_* defines. Reject connection if undefined bits are not 0   		
											//		AMINTERLACE_IsInterlaced            
											//		AMINTERLACE_1FieldPerSample         
											//		AMINTERLACE_Field1First             
											//		AMINTERLACE_UNUSED                  
											//		AMINTERLACE_FieldPatternMask        
											//		AMINTERLACE_FieldPatField1Only      
											//		AMINTERLACE_FieldPatField2Only      
											//		AMINTERLACE_FieldPatBothRegular     
											//		AMINTERLACE_FieldPatBothIrregular   
											//		AMINTERLACE_DisplayModeMask         
											//		AMINTERLACE_DisplayModeBobOnly      
											//		AMINTERLACE_DisplayModeWeaveOnly    
											//		AMINTERLACE_DisplayModeBobOrWeave 
											//
		0,									//		DWORD		dwCopyProtectFlags
											//		use AMCOPYPROTECT_* defines. Reject connection if undefined bits are not 0 
											//		AMCOPYPROTECT_RestrictDuplication
											//
		4,									//		DWORD		dwPictAspectRatioX
											//		X dimension of picture aspect ratio, e.g. 16 for 16x9 display
											//
		3,									//		DWORD		dwPictAspectRatioY
											//		Y dimension of picture aspect ratio, e.g.  9 for 16x9 display
		0,									//		DWORD		dwReserved1
		0,									//		DWORD		dwReserved2


      {
         sizeof( KS_BITMAPINFOHEADER ), //    DWORD      biSize;
         DefWidth,                   //    LONG       biWidth;
         DefHeight,                  //    LONG       biHeight;
         1,                          //    WORD       biPlanes;
         24,                         //    WORD       biBitCount;
         KS_BI_RGB,                  //    DWORD      biCompression;
         DefWidth * DefHeight * 3,   //    DWORD      biSizeImage;
         0,                          //    LONG       biXPelsPerMeter;
         0,                          //    LONG       biYPelsPerMeter;
         0,                          //    DWORD      biClrUsed;
         0                           //    DWORD      biClrImportant;
      }
   }
};

KS_DATARANGE_VIDEO StreamFormatRGB24Bpp_Capture =
{
   // KSDATARANGE
   {
      {
         sizeof( KS_DATARANGE_VIDEO ),
         0,
         DefWidth * DefHeight * 3,               // SampleSize
         0,                                      // Reserved
         { STATIC_KSDATAFORMAT_TYPE_VIDEO },
         { 0xe436eb7d, 0x524f, 0x11ce, { 0x9f, 0x53, 0x00, 0x20, 0xaf, 0x0b, 0xa7, 0x70 } }, //MEDIASUBTYPE_RGB24,
         { STATIC_KSDATAFORMAT_SPECIFIER_VIDEOINFO }
      }
   },
   true,
   true,
   KS_VIDEOSTREAM_CAPTURE, // StreamDescriptionFlags  (KS_VIDEO_DESC_*)
   0,       // MemoryAllocationFlags   (KS_VIDEO_ALLOC_*)

   // _KS_VIDEO_STREAM_CONFIG_CAPS
   {
      { STATIC_KSDATAFORMAT_SPECIFIER_VIDEOINFO }, // GUID
      KS_AnalogVideo_NTSC_M,                       // AnalogVideoStandard
      {
         MaxInWidth, MaxInHeight   // SIZE InputSize
      },
      {
         MinInWidth, MinInHeight   // SIZE MinCroppingSize;       smallest rcSrc cropping rect allowed
      },
      {
         MaxInWidth, MaxInHeight   // SIZE MaxCroppingSize;       largest rcSrc cropping rect allowed
      },
      2,           // int CropGranularityX;       // granularity of cropping size
      2,           // int CropGranularityY;
      2,           // int CropAlignX;             // alignment of cropping rect
      2,           // int CropAlignY;
      {
         MinOutWidth, MinOutHeight   // SIZE MinOutputSize;  smallest bitmap stream can produce
      },
      {
         MaxOutWidth, MaxOutHeight   // SIZE MaxOutputSize;  largest  bitmap stream can produce
      },
      2,          // int OutputGranularityX;     // granularity of output bitmap size
      2,          // int OutputGranularityY;
      0,          // StretchTapsX  (0 no stretch, 1 pix dup, 2 interp...)
      0,          // StretchTapsY
      2,          // ShrinkTapsX
      2,          // ShrinkTapsY
      333667,     // LONGLONG MinFrameInterval;  // 100 nS units
      333667,     // LONGLONG MaxFrameInterval;
      3 * 30 * MinOutWidth * MinOutHeight,// LONG MinBitsPerSecond;
      3 * 30 * MaxOutWidth * MaxOutHeight //LONG MaxBitsPerSecond;
   },

   // KS_VIDEOINFOHEADER (default format)
   {
      { 0,0,0,0 },  //    RECT            rcSource;          // The bit we really want to use
      { 0,0,0,0 },  //    RECT            rcTarget;          // Where the video should go
      DefWidth * DefHeight * 3 * 30L,      //    DWORD           dwBitRate;         // Approximate bit data rate
      0L,           //    DWORD           dwBitErrorRate;    // Bit error rate for this stream
      333667,       //    REFERENCE_TIME  AvgTimePerFrame;   // Average time per frame (100ns units)
      {
         sizeof( KS_BITMAPINFOHEADER ), //    DWORD      biSize;
         DefWidth,                   //    LONG       biWidth;
         DefHeight,                  //    LONG       biHeight;
         1,                          //    WORD       biPlanes;
         24,                         //    WORD       biBitCount;
         KS_BI_RGB,                  //    DWORD      biCompression;
         DefWidth * DefHeight * 3,   //    DWORD      biSizeImage;
         0,                          //    LONG       biXPelsPerMeter;
         0,                          //    LONG       biYPelsPerMeter;
         0,                          //    DWORD      biClrUsed;
         0                           //    DWORD      biClrImportant;
      }
   }
};

#endif
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\drivers\wdm\capture\mini\bt848\risceng.cpp ===
// $Header: G:/SwDev/WDM/Video/bt848/rcs/Risceng.cpp 1.6 1998/04/29 22:43:37 tomz Exp $

#include "risceng.h"


/* Method: RISCEng::CreateProgram
 * Purpose: Creates a first RISC program for a stream (field)
 * Input: aField: VidField - defines what field the program is for
 *   ImageSize: SIZE & - defines dimentions of the image
 *   dwPitch: DWORD - pitch to be used for data buffer . Useful for producing
 *   interlaced images.
 *   aFormat: ColorFormat - defines type of data
 *   dwBufAddr: DWORD - address of the destination buffer
 * Output: RiscPrgHandle
 */
RiscPrgHandle RISCEng::CreateProgram( MSize &ImageSize, DWORD dwPitch,
   ColFmt aFormat, DataBuf &buf, bool Intr, DWORD dwPlanrAdjust, bool rsync )
{
   // create yet another risc program object
   RISCProgram *YAProgram =
      new RISCProgram( ImageSize, dwPitch, aFormat );

   // and make it create the program itself
   if ( YAProgram->Create( Intr, buf, dwPlanrAdjust, rsync ) != Success ) {
      delete YAProgram;
      YAProgram = NULL;
   }

   return YAProgram;
}

/* Method: RISCEng::DestroyProgram
 * Purpose: Removes a program from a chain and destroy it
 * Input: ToDie: RiscPrgHandle - pointer to a program to destroy
 * Output: None
 */
void RISCEng::DestroyProgram( RiscPrgHandle ToDie )
{
   delete ToDie;
}

/* Method: RISCEng::ChangeAddress
 * Purpose:
 * Input:
 * Output:
 */
void RISCEng::ChangeAddress( RiscPrgHandle prog, DataBuf &buf )
{
   prog->ChangeAddress( buf );
}

/* Method: RISCEng::Chain
 * Purpose: Chains two RISC programs together
 * Input: hParent: RiscPrgHandle - pointer in reality
 *   hChild: RiscPrgHandle - pointer in reality
 * Output: None
 */
void RISCEng::Chain( RiscPrgHandle hParent, RiscPrgHandle hChild , int ndxParent, int ndxChild)
{
   DebugOut((2, "*** Linked hParent(%x)(%d) to hChild(%x)(%d)\n", hParent, ndxParent, hChild, ndxChild));
   hParent->SetChain( hChild );
}

/* Method: RISCEng::Skip
 * Purpose: Sets the given program so it is bypassed by DMA
 * Input: hToSkip: RiscPrgHandle - pointer in reality
 * Output: None
 * Note: The way things are right now a program will always have a child and a
 *   parent, even if it is its own parent and child
 */
void RISCEng::Skip( RiscPrgHandle pToSkip )
{
   pToSkip->Skip();
}
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\drivers\wdm\capture\mini\bt848\rgb16fmt.h ===
// $Header: G:/SwDev/WDM/Video/bt848/rcs/Rgb16fmt.h 1.5 1998/04/29 22:43:37 tomz Exp $

#ifndef __RGB16FMT_H
#define __RGB16FMT_H

#ifndef __DEFAULTS_H
#include "defaults.h"
#endif

KS_DATARANGE_VIDEO StreamFormatRGB555 =
{
   // KSDATARANGE
   {
      {
         sizeof( KS_DATARANGE_VIDEO ),
         0,
         DefWidth * DefHeight * 2,               // SampleSize
         0,                                      // Reserved
         { 0x73646976, 0x0000, 0x0010, { 0x80, 0x00, 0x00, 0xaa, 0x00, 0x38, 0x9b, 0x71 } }, //MEDIATYPE_Video
         { 0xe436eb7c, 0x524f, 0x11ce, { 0x9f, 0x53, 0x00, 0x20, 0xaf, 0x0b, 0xa7, 0x70 } }, //MEDIASUBTYPE_RGB555,
         { 0x05589f80, 0xc356, 0x11ce, { 0xbf, 0x01, 0x00, 0xaa, 0x00, 0x55, 0x59, 0x5a } }  //FORMAT_VideoInfo
      }
   },
   true,    // BOOL,  bFixedSizeSamples (all samples same size?)
   true,    // BOOL,  bTemporalCompression (all I frames?)
   KS_VIDEOSTREAM_PREVIEW, // StreamDescriptionFlags  (KS_VIDEO_DESC_*)
   0,       // MemoryAllocationFlags   (KS_VIDEO_ALLOC_*)

   // _KS_VIDEO_STREAM_CONFIG_CAPS
   {
      { STATIC_KSDATAFORMAT_SPECIFIER_VIDEOINFO }, // GUID
      KS_AnalogVideo_NTSC_M,                       // AnalogVideoStandard
      {
         MaxInWidth, MaxInHeight   // SIZE InputSize
      },
      {
         MinInWidth, MinInHeight   // SIZE MinCroppingSize;       smallest rcSrc cropping rect allowed
      },
      {
         MaxInWidth, MaxInHeight   // SIZE MaxCroppingSize;       largest rcSrc cropping rect allowed
      },
      2,           // int CropGranularityX;       // granularity of cropping size
      2,           // int CropGranularityY;
      2,           // int CropAlignX;             // alignment of cropping rect
      2,           // int CropAlignY;
      {
         MinOutWidth, MinOutHeight   // SIZE MinOutputSize;         // smallest bitmap stream can produce
      },
      {
         MaxOutWidth, MaxOutHeight   // SIZE MaxOutputSize;         // largest  bitmap stream can produce
      },
      1,          // int OutputGranularityX;     // granularity of output bitmap size
      1,          // int OutputGranularityY;
      0,          // StretchTapsX  (0 no stretch, 1 pix dup, 2 interp...)
      0,          // StretchTapsY
      2,          // ShrinkTapsX
      2,          // ShrinkTapsY
      333667,     // LONGLONG MinFrameInterval;  // 100 nS units
      333667,     // LONGLONG MaxFrameInterval;
      2 * 30 * MinOutWidth * MinOutHeight,  // LONG MinBitsPerSecond;
      2 * 30 * MaxOutWidth * MaxOutHeight   //LONG MaxBitsPerSecond;
   },

   // KS_VIDEOINFOHEADER (default format)
   {
      { 0,0,0,0 },    //    RECT            rcSource;          // The bit we really want to use
      { 0,0,0,0 },    //    RECT            rcTarget;          // Where the video should go
      DefWidth * DefHeight * 2 * 30L,  //    DWORD     dwBitRate;         // Approximate bit data rate
      0L,                        //    DWORD           dwBitErrorRate;    // Bit error rate for this stream
      333667,                    //    REFERENCE_TIME  AvgTimePerFrame;   // Average time per frame (100ns units)

      {
         sizeof( KS_BITMAPINFOHEADER ), //    DWORD      biSize;
         DefWidth,                   //    LONG       biWidth;
         DefHeight,                  //    LONG       biHeight;
         1,                          //    WORD       biPlanes;
         16,                         //    WORD       biBitCount;
         KS_BI_RGB,                  //    DWORD      biCompression;
         DefWidth * DefHeight * 2,   //    DWORD      biSizeImage;
         0,                          //    LONG       biXPelsPerMeter;
         0,                          //    LONG       biYPelsPerMeter;
         0,                          //    DWORD      biClrUsed;
         0                           //    DWORD      biClrImportant;
      }
   }
};

KS_DATARANGE_VIDEO2 StreamFormat2RGB555 =
{
   // KSDATARANGE
   {
      {
         sizeof( KS_DATARANGE_VIDEO2 ),
         0,
         DefWidth * DefHeight * 2,               // SampleSize
         0,                                      // Reserved
         { 0x73646976, 0x0000, 0x0010, { 0x80, 0x00, 0x00, 0xaa, 0x00, 0x38, 0x9b, 0x71 } }, //MEDIATYPE_Video
         { 0xe436eb7c, 0x524f, 0x11ce, { 0x9f, 0x53, 0x00, 0x20, 0xaf, 0x0b, 0xa7, 0x70 } }, //MEDIASUBTYPE_RGB555,
         { 0xf72a76A0, 0xeb0a, 0x11d0, { 0xac, 0xe4, 0x00, 0x00, 0xc0, 0xcc, 0x16, 0xba } }  //FORMAT_VideoInfo2
      }
   },
   true,    // BOOL,  bFixedSizeSamples (all samples same size?)
   true,    // BOOL,  bTemporalCompression (all I frames?)
   KS_VIDEOSTREAM_PREVIEW, // StreamDescriptionFlags  (KS_VIDEO_DESC_*)
   0,       // MemoryAllocationFlags   (KS_VIDEO_ALLOC_*)

   // _KS_VIDEO_STREAM_CONFIG_CAPS
   {
      { STATIC_KSDATAFORMAT_SPECIFIER_VIDEOINFO2 }, // GUID
      KS_AnalogVideo_NTSC_M,                       // AnalogVideoStandard
      {
         MaxInWidth, MaxInHeight   // SIZE InputSize
      },
      {
         MinInWidth, MinInHeight   // SIZE MinCroppingSize;       smallest rcSrc cropping rect allowed
      },
      {
         MaxInWidth, MaxInHeight   // SIZE MaxCroppingSize;       largest rcSrc cropping rect allowed
      },
      2,           // int CropGranularityX;       // granularity of cropping size
      2,           // int CropGranularityY;
      2,           // int CropAlignX;             // alignment of cropping rect
      2,           // int CropAlignY;
      {
         MinOutWidth, MinOutHeight   // SIZE MinOutputSize;         // smallest bitmap stream can produce
      },
      {
         MaxOutWidth, MaxOutHeight   // SIZE MaxOutputSize;         // largest  bitmap stream can produce
      },
      1,          // int OutputGranularityX;     // granularity of output bitmap size
      1,          // int OutputGranularityY;
      0,          // StretchTapsX  (0 no stretch, 1 pix dup, 2 interp...)
      0,          // StretchTapsY
      2,          // ShrinkTapsX
      2,          // ShrinkTapsY
      333667,     // LONGLONG MinFrameInterval;  // 100 nS units
      333667,     // LONGLONG MaxFrameInterval;
      2 * 30 * MinOutWidth * MinOutHeight,  // LONG MinBitsPerSecond;
      2 * 30 * MaxOutWidth * MaxOutHeight   //LONG MaxBitsPerSecond;
   },

   // KS_VIDEOINFOHEADER2 (default format)
   {
      { 0,0,0,0 },    //    RECT            rcSource;          // The bit we really want to use
      { 0,0,0,0 },    //    RECT            rcTarget;          // Where the video should go
      DefWidth * DefHeight * 2 * 30L,  //    DWORD     dwBitRate;         // Approximate bit data rate
      0L,                        //    DWORD           dwBitErrorRate;    // Bit error rate for this stream
      333667,                    //    REFERENCE_TIME  AvgTimePerFrame;   // Average time per frame (100ns units)
#if 0
		//TODO: video memory must be available for interlacing to work
		KS_INTERLACE_IsInterlaced |		//		DWORD		dwInterlaceFlags
#else
			KS_INTERLACE_1FieldPerSample 
			//| KS_INTERLACE_Field1First
			//| KS_INTERLACE_FieldPatField1Only
			| KS_INTERLACE_FieldPatBothRegular
			| KS_INTERLACE_DisplayModeBobOnly,
			//| KS_INTERLACE_DisplayModeBobOrWeave,
#endif
											//		use AMINTERLACE_* defines. Reject connection if undefined bits are not 0   		
											//		AMINTERLACE_IsInterlaced            
											//		AMINTERLACE_1FieldPerSample         
											//		AMINTERLACE_Field1First             
											//		AMINTERLACE_UNUSED                  
											//		AMINTERLACE_FieldPatternMask        
											//		AMINTERLACE_FieldPatField1Only      
											//		AMINTERLACE_FieldPatField2Only      
											//		AMINTERLACE_FieldPatBothRegular     
											//		AMINTERLACE_FieldPatBothIrregular   
											//		AMINTERLACE_DisplayModeMask         
											//		AMINTERLACE_DisplayModeBobOnly      
											//		AMINTERLACE_DisplayModeWeaveOnly    
											//		AMINTERLACE_DisplayModeBobOrWeave 
											//
		0,									//		DWORD		dwCopyProtectFlags
											//		use AMCOPYPROTECT_* defines. Reject connection if undefined bits are not 0 
											//		AMCOPYPROTECT_RestrictDuplication
											//
		4,									//		DWORD		dwPictAspectRatioX
											//		X dimension of picture aspect ratio, e.g. 16 for 16x9 display
											//
		3,									//		DWORD		dwPictAspectRatioY
											//		Y dimension of picture aspect ratio, e.g.  9 for 16x9 display
		0,									//		DWORD		dwReserved1
		0,									//		DWORD		dwReserved2


      {
         sizeof( KS_BITMAPINFOHEADER ), //    DWORD      biSize;
         DefWidth,                   //    LONG       biWidth;
         DefHeight,                  //    LONG       biHeight;
         1,                          //    WORD       biPlanes;
         16,                         //    WORD       biBitCount;
         KS_BI_RGB,                  //    DWORD      biCompression;
         DefWidth * DefHeight * 2,   //    DWORD      biSizeImage;
         0,                          //    LONG       biXPelsPerMeter;
         0,                          //    LONG       biYPelsPerMeter;
         0,                          //    DWORD      biClrUsed;
         0                           //    DWORD      biClrImportant;
      }
   }
};

KS_DATARANGE_VIDEO StreamFormatRGB555Cap =
{
   // KSDATARANGE
   {
      {
         sizeof( KS_DATARANGE_VIDEO ),
         0,
         DefWidth * DefHeight * 2,               // SampleSize
         0,                                      // Reserved
         { 0x73646976, 0x0000, 0x0010, { 0x80, 0x00, 0x00, 0xaa, 0x00, 0x38, 0x9b, 0x71 } }, //MEDIATYPE_Video
         { 0xe436eb7c, 0x524f, 0x11ce, { 0x9f, 0x53, 0x00, 0x20, 0xaf, 0x0b, 0xa7, 0x70 } }, //MEDIASUBTYPE_RGB555,
         { 0x05589f80, 0xc356, 0x11ce, { 0xbf, 0x01, 0x00, 0xaa, 0x00, 0x55, 0x59, 0x5a } }  //FORMAT_VideoInfo
      }
   },
   true,    // BOOL,  bFixedSizeSamples (all samples same size?)
   true,    // BOOL,  bTemporalCompression (all I frames?)
   KS_VIDEOSTREAM_CAPTURE, // StreamDescriptionFlags  (KS_VIDEO_DESC_*)
   0,       // MemoryAllocationFlags   (KS_VIDEO_ALLOC_*)

   // _KS_VIDEO_STREAM_CONFIG_CAPS
   {
      { STATIC_KSDATAFORMAT_SPECIFIER_VIDEOINFO }, // GUID
      KS_AnalogVideo_NTSC_M,                       // AnalogVideoStandard
      {
         MaxInWidth, MaxInHeight   // SIZE InputSize
      },
      {
         MinInWidth, MinInHeight   // SIZE MinCroppingSize;       smallest rcSrc cropping rect allowed
      },
      {
         MaxInWidth, MaxInHeight   // SIZE MaxCroppingSize;       largest rcSrc cropping rect allowed
      },
      2,           // int CropGranularityX;       // granularity of cropping size
      2,           // int CropGranularityY;
      2,           // int CropAlignX;             // alignment of cropping rect
      2,           // int CropAlignY;
      {
         MinOutWidth, MinOutHeight   // SIZE MinOutputSize;         // smallest bitmap stream can produce
      },
      {
         MaxOutWidth, MaxOutHeight   // SIZE MaxOutputSize;         // largest  bitmap stream can produce
      },
      1,          // int OutputGranularityX;     // granularity of output bitmap size
      1,          // int OutputGranularityY;
      0,          // StretchTapsX  (0 no stretch, 1 pix dup, 2 interp...)
      0,          // StretchTapsY
      2,          // ShrinkTapsX 
      2,          // ShrinkTapsY
      333667,     // LONGLONG MinFrameInterval;  // 100 nS units
      333667,     // LONGLONG MaxFrameInterval;
      2 * 30 * MinOutWidth * MinOutHeight,  // LONG MinBitsPerSecond;
      2 * 30 * MaxOutWidth * MaxOutHeight   //LONG MaxBitsPerSecond;
   },

   // KS_VIDEOINFOHEADER (default format)
   {
      { 0,0,0,0 },    //    RECT            rcSource;          // The bit we really want to use
      { 0,0,0,0 },    //    RECT            rcTarget;          // Where the video should go
      DefWidth * DefHeight * 2 * 30L,  //    DWORD     dwBitRate;         // Approximate bit data rate
      0L,                        //    DWORD           dwBitErrorRate;    // Bit error rate for this stream
      333667,                    //    REFERENCE_TIME  AvgTimePerFrame;   // Average time per frame (100ns units)

      {
         sizeof( KS_BITMAPINFOHEADER ), //    DWORD      biSize;
         640,//DefWidth,                   //    LONG       biWidth;
         480,//DefHeight,                  //    LONG       biHeight;
         1,                          //    WORD       biPlanes;
         16,                         //    WORD       biBitCount;
         KS_BI_RGB,                  //    DWORD      biCompression;
         640 * 480 * 2,   //    DWORD      biSizeImage;
//         DefWidth * DefHeight * 2,   //    DWORD      biSizeImage;
         0,                          //    LONG       biXPelsPerMeter;
         0,                          //    LONG       biYPelsPerMeter;
         0,                          //    DWORD      biClrUsed;
         0                           //    DWORD      biClrImportant;
      }
   }
};

KS_DATARANGE_VIDEO StreamFormatRGB565 =
{
   // KSDATARANGE
   {
      {
         sizeof( KS_DATARANGE_VIDEO ),
         0,
         DefWidth * DefHeight * 2,               // SampleSize
         0,                                      // Reserved
         { 0x73646976, 0x0000, 0x0010, { 0x80, 0x00, 0x00, 0xaa, 0x00, 0x38, 0x9b, 0x71 } }, //MEDIATYPE_Video
         { 0xe436eb7b, 0x524f, 0x11ce, { 0x9f, 0x53, 0x00, 0x20, 0xaf, 0x0b, 0xa7, 0x70 } }, //MEDIASUBTYPE_RGB565,
         { 0x05589f80, 0xc356, 0x11ce, { 0xbf, 0x01, 0x00, 0xaa, 0x00, 0x55, 0x59, 0x5a } }  //FORMAT_VideoInfo
      }
   },
   true,    // BOOL,  bFixedSizeSamples (all samples same size?)
   true,    // BOOL,  bTemporalCompression (all I frames?)
   KS_VIDEOSTREAM_PREVIEW, // StreamDescriptionFlags  (KS_VIDEO_DESC_*)
   0,       // MemoryAllocationFlags   (KS_VIDEO_ALLOC_*)

   // _KS_VIDEO_STREAM_CONFIG_CAPS
   {
      { STATIC_KSDATAFORMAT_SPECIFIER_VIDEOINFO }, // GUID
      KS_AnalogVideo_NTSC_M,                       // AnalogVideoStandard
      {
         MaxInWidth, MaxInHeight   // SIZE InputSize
      },
      {
         MinInWidth, MinInHeight   // SIZE MinCroppingSize;       smallest rcSrc cropping rect allowed
      },
      {
         MaxInWidth, MaxInHeight   // SIZE MaxCroppingSize;       largest rcSrc cropping rect allowed
      },
      2,           // int CropGranularityX;       // granularity of cropping size
      2,           // int CropGranularityY;
      2,           // int CropAlignX;             // alignment of cropping rect
      2,           // int CropAlignY;
      {
         MinOutWidth, MinOutHeight   // SIZE MinOutputSize;         // smallest bitmap stream can produce
      },
      {
         MaxOutWidth, MaxOutHeight   // SIZE MaxOutputSize;         // largest  bitmap stream can produce
      },
      1,          // int OutputGranularityX;     // granularity of output bitmap size
      1,          // int OutputGranularityY;
      0,          // StretchTapsX  (0 no stretch, 1 pix dup, 2 interp...)
      0,          // StretchTapsY
      2,          // ShrinkTapsX
      2,          // ShrinkTapsY
      333667,     // LONGLONG MinFrameInterval;  // 100 nS units
      333667,     // LONGLONG MaxFrameInterval;
      2 * 30 * MinOutWidth * MinOutHeight,  // LONG MinBitsPerSecond;
      2 * 30 * MaxOutWidth * MaxOutHeight   //LONG MaxBitsPerSecond;
   },

   // KS_VIDEOINFOHEADER (default format)
   {
      { 0,0,0,0 },    //    RECT            rcSource;          // The bit we really want to use
      { 0,0,0,0 },    //    RECT            rcTarget;          // Where the video should go
      DefWidth * DefHeight * 2 * 30L,  //    DWORD     dwBitRate;         // Approximate bit data rate
      0L,                        //    DWORD           dwBitErrorRate;    // Bit error rate for this stream
      333667,                    //    REFERENCE_TIME  AvgTimePerFrame;   // Average time per frame (100ns units)

      {
         sizeof( KS_BITMAPINFOHEADER ), //    DWORD      biSize;
         DefWidth,                   //    LONG       biWidth;
         DefHeight,                  //    LONG       biHeight;
         1,                          //    WORD       biPlanes;
         16,                         //    WORD       biBitCount;
         0xe436eb7b,                 //    DWORD      biCompression;
         DefWidth * DefHeight * 2,   //    DWORD      biSizeImage;
         0,                          //    LONG       biXPelsPerMeter;
         0,                          //    LONG       biYPelsPerMeter;
         0,                          //    DWORD      biClrUsed;
         0                           //    DWORD      biClrImportant;
      }
   }
};


#endif
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\drivers\wdm\capture\mini\bt848\riscmem.cpp ===
// $Header: G:/SwDev/WDM/Video/bt848/rcs/Riscmem.cpp 1.5 1998/04/29 22:43:38 tomz Exp $

#include "pspagebl.h"
#include "defaults.h"


typedef struct
{
   DWORD dwSize;
} BT_MEMBLOCK, *PBT_MEMBLOCK;

/* this is a rather simple allocator. It divides entire space into 2 parts:
   1 - for VBI program allocations, 2 - for video program allocations. In addi-
   tion, each VBI program is equal in size ( same goes for video programs ).
   The distinction between video and VBI programs is made based on asked size.
   It is known the VBI programs are always smaller. VBI programs range is from
   zero to MaxVBISize, above memory is for video programs. Total size is big
   enough to hold all risc programs.
*/
void PsPageBlock::AllocateSpace( DWORD dwSize )
{
   PBYTE pBuf = (PBYTE)StreamClassGetDmaBuffer( gpHwDeviceExtension );

   DWORD dwBlockSize = MaxVBISize;
   if ( dwSize > MaxVBISize ) {
      pBuf += VideoOffset;
      dwBlockSize = MaxVidSize;
   }

   // now start searching for the available spot
   while ( 1 ) {

      PBT_MEMBLOCK pMemBlk = PBT_MEMBLOCK( pBuf );
      if ( pMemBlk->dwSize ) // this block is occupied
         pBuf += dwBlockSize;
      else {
         pMemBlk->dwSize = dwBlockSize;
         LinAddr_ = pMemBlk + 1;
         ULONG len;
         PhysAddr_ = StreamClassGetPhysicalAddress( gpHwDeviceExtension, NULL, LinAddr_,
            DmaBuffer, &len ).LowPart;
         break;
      }
   }
}

void PsPageBlock::FreeSpace()
{
   PBT_MEMBLOCK pMemBlk = PBT_MEMBLOCK( (PDWORD)LinAddr_ - 1 );
   pMemBlk->dwSize = 0;
}
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\drivers\wdm\capture\mini\bt848\risceng.h ===
// $Header: G:/SwDev/WDM/Video/bt848/rcs/Risceng.h 1.6 1998/04/29 22:43:38 tomz Exp $

#ifndef __RISCENG_H
#define __RISCENG_H

#ifndef __VIDDEFS_H
#include "viddefs.h"
#endif

#ifndef __RISCPROG_H
#include "riscprog.h"
#endif

#ifndef __COMPREG_H
#include "compreg.h"
#endif

#include "preg.h"

typedef RISCProgram *RiscPrgHandle;

/* Class: RISCEng
 * Purpose: This class provides control over the BtPisces' RISC engine
 * Attributes:
 * Operations:
 */                
class RISCEng
{
   protected:
      DECLARE_RISCPROGRAMSTARTADDRESS;
      DECLARE_CONTROL;
   public:
      virtual RiscPrgHandle CreateProgram( MSize &ImageSize, DWORD dwPitch,
         ColFmt, DataBuf &buf, bool Intr = false, DWORD dwPlanarAdjust = 0, bool rsync = false );

      virtual void DestroyProgram( RiscPrgHandle ToDie );
              void ChangeAddress( RiscPrgHandle prog, DataBuf &buf );
              void Start( RISCProgram &ToStart )
              { 
                  DebugOut((1, "Starting RISC program (%x)\n", &ToStart));
                  //ToStart.Dump();

                  RISC_IPC = ToStart.GetPhysProgAddr() & ~0x3;
                  FIFO_ENABLE = 1; 
                  RISC_ENABLE = 1;  
              }
              void Stop() { RISC_ENABLE = 0; FIFO_ENABLE = 0; };
              void Chain( RiscPrgHandle hParent, RiscPrgHandle hChild , int ndxParent = -1, int ndxChild = -1);
              void Skip( RiscPrgHandle hToSkip );

      RISCEng() : CONSTRUCT_RISCPROGRAMSTARTADDRESS, CONSTRUCT_CONTROL
      { PKTP = 1; }
};

#endif
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\drivers\wdm\capture\mini\bt848\riscprog.cpp ===
// $Header: G:/SwDev/WDM/Video/bt848/rcs/Riscprog.cpp 1.14 1998/05/04 17:53:37 tomz Exp $

#include "riscprog.h"
#include "physaddr.h"

#define ClearMem( a ) memset( &##a, '\0', sizeof( a ) )


DWORD RISCProgram::GetDataBuffer( )
{
   return dwLinBufAddr_;
}

void RISCProgram::SetDataBuffer( DWORD addr )
{
   dwLinBufAddr_ = addr;
}

void RISCProgram::Dump( )
{
   if( bAlreadyDumped_ ) {
      return;
   }

   DebugOut((0, "; RiscProgram(%x) ProgAddr(%x) PhysProgAddr(%x)\n",
                 this,
                 GetProgAddress( ),
                 GetPhysProgAddr( )));

   DebugOut((0, "  RiscProgram(%x) dwBufAddr_(%x) dwLinBufAddr_(%x)\n",
                 this,
                 dwBufAddr_,
                 dwLinBufAddr_));


   return;



   dwSize_ = 0;
   DWORD* pProgLoc = (DWORD*) GetProgAddress( );
   while( *pProgLoc++ != PROGRAM_TERMINATOR ) {
      dwSize_++;
      if( dwSize_ > 1024 ) {
         dwSize_ = 0;
         break;
      }
   }
   DWORD dwTmpSize_ = dwSize_;
   DebugOut((0, ";  size = %d\n", dwSize_));

   if( dwSize_ ) {
      DebugOut((0, "%x    ", GetPhysProgAddr( )));
   }

   PULONG pulProg = (PULONG) (ProgramSpace_->getLinearBase());
   while( dwTmpSize_ >= 4 ) {
      DebugOut((0, "   %08x %08x %08x %08x\n",
                pulProg[0],
                pulProg[1],
                pulProg[2],
                pulProg[3]));
      pulProg += 4;
      dwTmpSize_ -= 4;
   }
   switch( dwTmpSize_ ) {
      case 3:
         DebugOut((0, "   %08x %08x %08x\n",
                   pulProg[0],
                   pulProg[1],
                   pulProg[2]
                   ));
         break;
      case 2:
         DebugOut((0, "   %08x %08x\n",
                   pulProg[0],
                   pulProg[1]
                   ));
         break;
      case 1:
         DebugOut((0, "   %08x\n",
                   pulProg[0]
                   ));
         break;
   }

   bAlreadyDumped_ = TRUE;

#if 0
   if( pChild_ != NULL ) {
      // *** warning - recursion ***
      pChild_->Dump();
   }
#endif

   bAlreadyDumped_ = FALSE;
}

/*
      {
      // Input
      //    DWORD : RiscProg ndx
      //       CreatedProgs : 12 elements     ndx 0..11
      //       ActiveProgs  : 12 elements     ndx 12..23
      //       Skippers     : 8  elements     ndx 24..31
      // Output
      //    Buffer filled with riscprog
        int i = 0;

        if ( !pDIOCParams->dioc_cbOutBuf || (pDIOCParams->dioc_cbInBuf != 4))
          return -1;          // invalid parameters

        // pause
        // CaptureContrll_->Pause() ;

        // dump a prog
        DWORD WhichProg = *((PDWORD) pDIOCParams->dioc_InBuf);

        RiscPrgHandle hProg ;

        if (WhichProg < 12)            // CreatedProgs
        {
          hProg = CaptureContrll_->CreatedProgs_[WhichProg] ;
        }
        else if (WhichProg < 24)       // Active
        {
          hProg = CaptureContrll_->ActiveProgs_[WhichProg % 12] ;
        }
        else                           // Skippers
        {
          hProg =  CaptureContrll_->Skippers_[WhichProg % 12] ;
        }

        if(hProg)
        {
          char * pRetAddr = (char *)pDIOCParams->dioc_OutBuf;
          DWORD physAddr = hProg->GetPhysProgAddr() ;
          DWORD progSize = hProg->GetProgramSize();
          char * linBuf = (char *) MapPhysToLinear((void *)physAddr, progSize, 0) ;

          *((DWORD *) pRetAddr) = physAddr ;
          pRetAddr+=4 ;
          for (i = 0 ; i < progSize && i < pDIOCParams->dioc_cbOutBuf ; i++)
          {
             *pRetAddr++ = linBuf[i] ;
          }
        }
        if ( pDIOCParams->dioc_bytesret )
          *pDIOCParams->dioc_bytesret = i;

        // and resume
        // CaptureContrll_->Continue() ;
      }
*/



/* Method:  RISCProgram::ChangeAddress
 * Purpose: Modifies existing program to use new destination address
 * Input: dwNewAddr: DWORD - new buffer address
 * Output: None
 */
void  RISCProgram::ChangeAddress( DataBuf &buf )
{
   Trace t("RISCProgram::ChangeAddress()");
   //DebugOut((1, "RISCProgram::ChangeAddress(): this(%x), buf.pData_(%x)\n", this, buf.pData_));
   Create( Interrupting_, buf, dwPlanarAdjust_, GenerateResync_, false );
}

/* Function: CreatePrologEpilog
 * Purpose: Called from Create function to put proper sync codes at the beginning
 *   and at the end of a RISC program
 * Input: pProgLoc: PDWORD - pointer to the instruction memory
 *    SyncBits: SyncCode
 *   CurCommand: Command & - reference to a command object
 * Output: PDWORD - address of the next instruction
 */
inline PDWORD RISCProgram::CreatePrologEpilog( PDWORD pProgLoc, SyncCode SyncBits,
   Command &CurCommand, bool Resync )
{
   Trace t("RISCProgram::CreatePrologEpilog()");

   CurCommand.Create( pProgLoc, SYNC, NULL, NULL, false );//, false, false );
   CurCommand.SetSync( pProgLoc, SyncBits, Resync );
   // advance to the next command's position
   return pProgLoc + CurCommand.GetInstrSize();
}

inline bool IsWithin( int coord, int top, int bot )
{
   Trace t("IsWithin()");
   return bool( coord >= top && coord < bot );
}

inline PDWORD FinishWithSkip( int pixels, int bpp, PDWORD pProgLoc, Command &com )
{
   Trace t("FinishWithSkip()");

   WORD awByteCounts [1];
   awByteCounts [0] = WORD( pixels * bpp );
   return (LPDWORD)com.Create( pProgLoc, SKIP, awByteCounts, NULL,
      true, false, true, false ); // safety, SOL, EOL, Intr
}

ErrorCode RISCProgram::GetDataBufPhys( DataBuf &buf )
{
   Trace t("RISCProgram::GetDataBufPhys()");

   dwBufAddr_ = GetPhysAddr( buf );
   if ( dwBufAddr_ == (DWORD)-1 ) {
      return Fail;
   }
   return Success;
}

/* Method: RISCProgram::AllocateStorage
 * Purpose: Allocates a number of pages ( locked and physically contiguous ) to
 *   hold the new program
 * Input: None
 * Output: ErrorCode
 */
ErrorCode RISCProgram::AllocateStorage( bool extra, int )
{
   Trace t("RISCProgram::AllocateStorage()");

   if ( ProgramSpace_ )
      return Success;

   // figure out size of the memory to hold the program
   // at least as many DWORDs as lines
   DWORD dwProgramSize = ImageSize_.cy * sizeof( DWORD );

   // scale up according to the data format
   switch ( BufFormat_.GetColorFormat() ) {
   case CF_RGB32:
   case CF_RGB24:
   case CF_RGB16:
   case CF_RGB15:
   case CF_Y8:
   case CF_YUY2:
   case CF_UYVY:
   case CF_BTYUV:
   case CF_RGB8:
   case CF_RAW:
   case CF_VBI:
      dwProgramSize *= 2; // size of 'Write' command is 2 DWORDs
      if ( extra == true )  // doing clipping
         dwProgramSize *= 3;
      break;
   case CF_PL_422:
   case CF_PL_411:
   case CF_YUV9:
   case CF_YUV12:
   case CF_I420:
      dwProgramSize *= 5; // Planar WRITE is 5 DWORDs
   }
   // add extra for page crossings
   dwProgramSize += ImageSize_.cx * ImageSize_.cy * BufFormat_.GetBitCount() / 8
      / PAGE_SIZE * sizeof( DWORD ) * 5;

   ProgramSpace_ = new PsPageBlock( dwProgramSize );

   if ( ProgramSpace_ && ProgramSpace_->getLinearBase() != 0 )
      return Success;
   return Fail;
}

/* Function: GetAlternateSwitch
 * Purpose: Chooses alternative instruction frequency
 * Input: AlternateSwitch: int
 *    col: ColFmt, color format
 * Output: None
*/
inline void GetAlternateSwitch( int &AlternateSwitch, ColFmt col )
{
   Trace t("GetAlternateSwitch()");

   AlternateSwitch = col == CF_YUV9  ? 4 :
                     col == CF_YUV12 ? 2 : 1;
}

/* Function: GetSplitAddr
 * Purpose: Calculates page-aligned address
 * Input: dwLinBufAddr: DWORD - linear address
 * Output: DWORD
*/
inline DWORD GetSplitAddr( DWORD dwLinBufAddr )
{
   Trace t("GetSplitAddr()");
   return ( dwLinBufAddr + PAGE_SIZE ) & ~( PAGE_SIZE - 1 );//0xFFFFF000L;
//   return ( dwLinBufAddr + 0x1000 ) & 0xFFFFF000L;
}

/* Function: GetSplitByteCount
 * Purpose: Calculates number of bytes before the page boundary
 * Input: dwLinBufAddr: DWORD, address
 * Output: WORD, byte count
*/
inline WORD GetSplitByteCount( DWORD dwLinBufAddr )
{
   Trace t("GetSplitByteCount()");
   return WORD( PAGE_SIZE - BYTE_OFFSET( dwLinBufAddr ) );
//   return WORD( 0x1000 - ( dwLinBufAddr & 0xFFF ) );
}

/* Function: GetSplitNumbers
 * Purpose: Calculates addresses and byte counts when scan line crosses a page boundary
 * Input: dwLinAddr: DWORD, starting linear address
 *   wByteCount: WORD &, number of bytes to move before page crossing
 *   wByteCSplit: WORD &, number of bytes to move after page crossing
 *   SecondAddr: DWORD &, reference to the DWORD contatining address of the starting
 *   address for the second 'write' instruction
 *   FirstAddr: DWORD &,
 */
void GetSplitNumbers( DataBuf buf, WORD &wFirstByteCount, WORD &wSecondByteCount,
   DWORD &SecondAddr, DWORD &FirstAddr )
{
   Trace t("GetSplitNumbers()");

   // maybe can have some optimization here: if within the same page as previous
   // call ( no split ), don't call out for the physical address - just
   // increment the old physical address by difference in virtual addresses
   FirstAddr = GetPhysAddr( buf );

   if ( Need2Split( buf, wFirstByteCount ) ) {

      wSecondByteCount = wFirstByteCount;

      // lin address of the second write command ( page aligned )
      SecondAddr = GetSplitAddr( DWORD( buf.pData_ ) );

      // byte count of first write command
      wFirstByteCount = GetSplitByteCount( DWORD( buf.pData_ ) );
      wSecondByteCount -= wFirstByteCount;

      // get the physical addresses
      buf.pData_ = PBYTE( SecondAddr );
      SecondAddr = GetPhysAddr( buf );
   } else {
      wSecondByteCount = 0;
      SecondAddr = 0;
   }
}

/* Function: AdjustByteCounts
 * Purpose: This function is used to calculate 2 byte counts based on the given ratio
 * Purpose:
 */
void AdjustByteCounts( WORD &smaller, WORD &larger, WORD total, WORD ratio )
{
   Trace t("AdjustByteCounts()");

   if ( ratio <= 1 ) {
      smaller = WORD( total >> 1 );
   } else
      smaller = WORD( total / ratio );
   smaller += (WORD)3;
   smaller &= ~3;
   larger = WORD( total - smaller );
}

/* Method: RISCProgram::Create
 * Purpose: Creates a RISC program
 * Input: NeedInterrupt: bool - flag
 * Output: None
 * Note: It is likely this function is used to simply change dst addresses of
 *   an already existing program. It does not seem to make much sense to write
 *   basically the same function ( or the one that has to parse existing program)
 *   to change addresses
 */
ErrorCode  RISCProgram::Create( bool NeedInterrupt, DataBuf buf, DWORD dwPlanrAdjust,
   bool rsync, bool LoopOnItself )
{
   Trace t("RISCProgram::Create(2)");

   dwPlanarAdjust_ = dwPlanrAdjust;
   Interrupting_   = NeedInterrupt;
   GenerateResync_ = rsync;

   // allocate memory for the program first
   if ( AllocateStorage() != Success )
      return Fail;

   // store the buffer address in case somebody will want to change clipping
   if ( buf.pData_ && GetDataBufPhys( buf ) != Success )
      return Fail;

   // keep the linear address around
   dwLinBufAddr_ = DWORD( buf.pData_ );
   pSrb_ = buf.pSrb_;
   DebugOut((1, "dwLinBufAddr_ = %x\n", dwLinBufAddr_));

   // bad naming ?
   DWORD dwLinBufAddr = dwLinBufAddr_;

   // probably should create a class to handle these arrays
   WORD  awByteCounts [3];
   DWORD adwAddresses [3];

   Instruction MainInstrToUse, AltInstrToUse;

   int AlternateSwitch = 1;

   // used to increment planes' addresses
   LONG PlanePitch1 = dwBufPitch_, ChromaPitch = dwBufPitch_;

   // get size in bytes
   DWORD dwYPlaneSize = ImageSize_.cy * dwBufPitch_;

//   DebugOut((1, "buf addr = %x\n", dwLinBufAddr ) );

   // this is a physical address
   DWORD Plane1 = dwLinBufAddr_ + dwYPlaneSize, Plane2;

   // initialize byte count for all planar modes
   awByteCounts [0] = (WORD)ImageSize_.cx;

   if ( !dwLinBufAddr_ ) { // hack to handle special case of creating a skipper for VBI streams
      MainInstrToUse = SKIP123;
      AltInstrToUse  = SKIP123;
   } else {
      MainInstrToUse = WRITE1S23;
      AltInstrToUse  = WRITE123;
   }
   // handle all planar modes here
   SyncCode  SyncBits = SC_FM3;

   // these guys used for the calculation of addresses
   // for different planar mode combinations ( pitch > witdh, interleaving )
   DWORD dwEqualPitchDivider = 1;
   DWORD dwByteCountDivider  = 1;

   bool flip = false;

   // prepare all the ugly things
   switch ( BufFormat_.GetColorFormat() ) {
   case CF_RGB32:
   case CF_RGB24:
   case CF_RGB16:
   case CF_RGB15:
   case CF_BTYUV:
   case CF_RGB8:
      flip = Interrupting_;
   case CF_Y8:
   case CF_YUY2:
   case CF_UYVY:
   case CF_RAW:
   case CF_VBI:
      if ( !dwLinBufAddr_ ) { // hack to handle special case of creating a skipper for VBI streams
         MainInstrToUse = SKIP;
         AltInstrToUse  = SKIP;
      } else {
         MainInstrToUse = WRIT;
         AltInstrToUse  = WRIT;
      }
      awByteCounts [0] = (WORD)(ImageSize_.cx * BufFormat_.GetBitCount() / 8 );
      // packed data to follow
      SyncBits = SC_FM1;
      break;
   case CF_PL_422:
      dwEqualPitchDivider = 2;
      dwByteCountDivider  = 2;
      break;
   case CF_PL_411:
      dwEqualPitchDivider = 4;
      dwByteCountDivider  = 4;
      break;
   case CF_YUV9:
      AlternateSwitch = 4;
      dwEqualPitchDivider = 16;
      dwByteCountDivider  = 4;
      break;
   case CF_I420:
   case CF_YUV12:
      AlternateSwitch = 2;
      dwEqualPitchDivider = 4;
      dwByteCountDivider  = 2;
   } /*endswitch*/

   awByteCounts [1] = awByteCounts [2] =
      WORD( awByteCounts [0] / dwByteCountDivider );

   Plane2 = Plane1 + dwYPlaneSize / dwEqualPitchDivider;
   ChromaPitch /= dwByteCountDivider;

   // need to adjust if doing a full-size planar capture.
   Plane2 -= dwPlanarAdjust_;
   Plane1 -= dwPlanarAdjust_;
   Plane2 += dwPlanarAdjust_ / dwByteCountDivider;
   Plane1 += dwPlanarAdjust_ / dwByteCountDivider;

   // U goes first for this color format
   if ( BufFormat_.GetColorFormat() == CF_I420 ) {
      DWORD dwTmp = Plane1;
      Plane1 = Plane2;
      Plane2 = dwTmp;
   }
   // that's were the instructions are going
   LPDWORD pProgLoc = (LPDWORD)(DWORD)ProgramSpace_->getLinearBase();
   LPDWORD pProgStart = pProgLoc;

   Command CurCommand;  // this will create every command we need - yahoo !

   // put one of the FM codes here if this program is for image data only
   pProgLoc = CreatePrologEpilog( pProgLoc, SyncBits, CurCommand );

   // init the destination address
   if ( flip ) {
      dwLinBufAddr += dwYPlaneSize;
      PlanePitch1 = -PlanePitch1;
   } else {
      dwLinBufAddr -= PlanePitch1;
      ;
   }
   // initial adjustment of chroma pointers
   Plane1 -= ChromaPitch;
   Plane2 -= ChromaPitch;

   // now go into a loop (up to the hight of the image) and create
   // a command for every line. Commands depend on the data format
   unsigned int i = 0;
   while ( i < (unsigned)ImageSize_.cy ) {

      Instruction CurInstr;

      // now take care of vertically sub-sampled planar modes
      if ( i % AlternateSwitch != 0 ) {
         CurInstr = AltInstrToUse;
      } else {
         CurInstr = MainInstrToUse;
         Plane2 += ChromaPitch;
         Plane1 += ChromaPitch;
      }
      // advance the linear address to the next scan line
      dwLinBufAddr += PlanePitch1;

      // these arrays contain values for the second instruction
      DWORD adwSecondAddr [3];
      WORD  FirstByteCount [3];
      WORD  SecondByteCount [3];

      adwSecondAddr   [0] = adwSecondAddr   [1] = adwSecondAddr   [2] =
      SecondByteCount [0] = SecondByteCount [1] = SecondByteCount [2] = 0;

      // initialize byte counts
      memmove( FirstByteCount, awByteCounts, sizeof( FirstByteCount ) );

      buf.pData_ = PBYTE( dwLinBufAddr );
      if ( dwLinBufAddr_ ) // don't bother with the addresses, if we are SKIPping them !
         GetSplitNumbers( buf, FirstByteCount [0], SecondByteCount [0],
            adwSecondAddr [0], adwAddresses [0] );

      PVOID pEOLLoc; // this is needed to set EOL bit in split instructions

      if ( AlternateSwitch > 1 && dwLinBufAddr_ ) {

         int split = 1;
         // Y plane is already done
         // now check if we better split instructions
         // just make width half of original and create 2 instructions
         if ( ImageSize_.cx > 320 && SecondByteCount [0 ] )
            split = 2;

         // temps for the loop
         DWORD dwYPlane = dwLinBufAddr;
         DWORD dwVPlane = Plane2;
         DWORD dwUPlane = Plane1;

         for ( int k = 0; k < split; k++ ) {

            // initialize byte counts
            memmove( FirstByteCount, awByteCounts, sizeof( FirstByteCount ) );
            // and split them in half
            for ( int l = 0; l < sizeof FirstByteCount / sizeof FirstByteCount [0]; l++ )
               FirstByteCount [l] = WORD (FirstByteCount [l] / split); //create 2 instructions with half the pixels

            // see if any of the planes crosses a page boundary
            // very ugly... must use the bad structure
            buf.pData_ = PBYTE( dwYPlane );
            GetSplitNumbers( buf, FirstByteCount [0], SecondByteCount [0],
               adwSecondAddr [0], adwAddresses [0] );
            // V plane
            buf.pData_ = PBYTE( dwVPlane );
            GetSplitNumbers( buf, FirstByteCount [1], SecondByteCount [1],
               adwSecondAddr [1], adwAddresses [1] );
            // U plane
            buf.pData_ = PBYTE( dwUPlane );
            GetSplitNumbers( buf, FirstByteCount [2], SecondByteCount [2],
               adwSecondAddr [2], adwAddresses [2] );

            // can not have zero Y byte count
            if ( !SecondByteCount [0] && ( SecondByteCount [1] || SecondByteCount [2] ) ) {
               FirstByteCount  [0] -= max( SecondByteCount [1], SecondByteCount [2] );
               FirstByteCount  [0] &= ~3; // need to align for the second address
               SecondByteCount [0] = WORD( awByteCounts [0] / split - FirstByteCount [0] );
               // second addr starts where first ends; no page crossing
               adwSecondAddr [0] = adwAddresses [0] + FirstByteCount [0];
            }
            // now make sure that there are no zero chroma byte counts
            // adjust chroma byte counts in proportion to luma byte counts split
            if ( SecondByteCount [0] )  {
               if ( !SecondByteCount [1] ) {
                  if ( SecondByteCount [0] > FirstByteCount [0] )
                     AdjustByteCounts( FirstByteCount [1], SecondByteCount [1], FirstByteCount [1],
                        WORD( SecondByteCount [0] / FirstByteCount [0] ) );
                  else
                     AdjustByteCounts( SecondByteCount [1], FirstByteCount [1], FirstByteCount [1],
                        WORD( FirstByteCount [0] / SecondByteCount [0] ) );
                  adwSecondAddr [1] = adwAddresses [1] + FirstByteCount [1];
               }
               if ( !SecondByteCount [2] ) {
                  if ( SecondByteCount [0] > FirstByteCount [0] )
                     AdjustByteCounts( FirstByteCount [2], SecondByteCount [2], FirstByteCount [2],
                        WORD( SecondByteCount [0] / FirstByteCount [0] ) );
                  else
                     AdjustByteCounts( SecondByteCount [2], FirstByteCount [2], FirstByteCount [2],
                        WORD( FirstByteCount [0] / SecondByteCount [0] ) );
                  adwSecondAddr   [2] = adwAddresses [2] + FirstByteCount [2];
               }
            }
            // now write out the instructions
            // first command. SOL==true, EOL==false
            pProgLoc = (LPDWORD)CurCommand.Create( pProgLoc, CurInstr,
               FirstByteCount, adwAddresses, LoopOnItself, k == 0, false );
            pEOLLoc = CurCommand.GetInstrAddr();

            if ( SecondByteCount [0] || SecondByteCount [1] || SecondByteCount [2] ) {
               // second command
               pProgLoc = (LPDWORD)CurCommand.Create( pProgLoc, CurInstr,
                  SecondByteCount, adwSecondAddr, LoopOnItself, false, false );
               pEOLLoc = CurCommand.GetInstrAddr();
            }
            // adjust starting addresses
            dwYPlane += awByteCounts [0] / 2;
            dwVPlane += awByteCounts [1] / 2;
            dwUPlane += awByteCounts [2] / 2;
         } /* endfor */
         // do not forget the EOL bit !
         CurCommand.SetEOL( pEOLLoc );

      } else {
         // first command. SOL==true, EOL==false
         pProgLoc = (LPDWORD)CurCommand.Create( pProgLoc, CurInstr,
            FirstByteCount, adwAddresses, LoopOnItself, true, false );
         pEOLLoc = CurCommand.GetInstrAddr();

         if ( SecondByteCount [0] || SecondByteCount [1] || SecondByteCount [2] ) {
            // second command
            pProgLoc = (LPDWORD)CurCommand.Create( pProgLoc, CurInstr,
               SecondByteCount, adwSecondAddr, LoopOnItself, false );
         } else
            CurCommand.SetEOL( pEOLLoc );
      } /* endif */
      i++;
   } /* endwhile */

   pChainAddress_ = pProgLoc;
   pIRQAddress_ = pProgLoc;

   PutInChain();

   Skipped_ = false;
   dwSize_ = (DWORD)pProgLoc - (DWORD)pProgStart;

   return Success;
}

/* Method: RISCProgram::PutInChain
 * Purpose: Restores the chain of programs this program was in.
 * Input: None
 * Output: None
 * Note: The chain is destroyed when clipping is set or buffer address is changed
 */
void RISCProgram::PutInChain()
{
   Trace t("RISCProgram::PutInChain()");

   if ( pChild_ )
      SetChain( pChild_ );

   if ( pParent_ )
      pParent_->SetChain( this );
}

/* Method: RISCProgram::SetChain
 * Purpose: Chains this program to another one
 * Input: dwProgAddr: DWORD - address of a first instruction in the next program
 * Output: None
 */
void  RISCProgram::SetChain( RISCProgram *ChainTo )
{
   Trace t("RISCProgram::SetChain()");

   if ( !ChainTo )
      return;

   // now we know where we are chaining to
   pChild_ = ChainTo;

   // now child knows who chains to it.Does it really want to know its parent?<g>
   pChild_->SetParent( this );

   SetJump( (PDWORD)pChild_->GetPhysProgAddr() );
}

/* Method: RISCProgram::Skip
 * Purpose: Changes first instruction so program jumps over itself and to the child
 * Input: None
 * Output: None
 * Note: This functionality is useful when there are not enough data buffers
 *   to supply for this program
 */
void RISCProgram::Skip()
{
   Trace t("RISCProgram::Skip()");

// change first SYNC into JUMP
   PDWORD pTmpAddr = pChainAddress_;
   pChainAddress_ = (PDWORD)GetProgAddress();
   ULONG len;
   DWORD  PhysAddr = StreamClassGetPhysicalAddress( gpHwDeviceExtension, NULL,
      pTmpAddr, DmaBuffer, &len ).LowPart;

   SetJump( (PDWORD)PhysAddr );
   pChainAddress_ = pTmpAddr;

   Skipped_ = true;
}

/* Method: RISCProgram::SetJump
 * Purpose: Creates a JUMP instruction to chain some place
 * Input: JumpAddr: PDWORD - target address
 * Output: None
 */
void RISCProgram::SetJump( PDWORD JumpAddr )
{
   Trace t("RISCProgram::SetJump()");

   Command JumpCommand;
   DWORD adwAddresses [1];
   adwAddresses [0] = (DWORD)JumpAddr;
   JumpCommand.Create( pChainAddress_, JUMP, NULL, adwAddresses, false );
   // make the last JUMP interrupt
   if ( Interrupting_ ) {
      JumpCommand.SetIRQ( pIRQAddress_ );
      if ( Counting_ )
         SetToCount();
      else
         ResetStatus();
   }
}

/* Method: RISCProgram::CreateLoop
 * Purpose: Creates a closed loop at the end of a RISC program
 * Input:  resync: bool - value of the resync bit
 * Output: None
 */
void RISCProgram::CreateLoop( bool resync )
{
   Trace t("RISCProgram::CreateLoop()");

   Command SyncCommand( SYNC );
   SyncCommand.SetResync( pChainAddress_, resync );
   if ( resync == true ) {
      DWORD adwAddresses [1];
      ULONG len;
      DWORD  PhysAddr = StreamClassGetPhysicalAddress( gpHwDeviceExtension, NULL,
         pChainAddress_, DmaBuffer, &len ).LowPart;

      adwAddresses [0] = PhysAddr;
      SyncCommand.Create( pChainAddress_, JUMP, NULL, adwAddresses );
   }
}

/* Method: RISCProgram::Create
 * Purpose: Creates a simple SYNC and JUMP program
 * Input: SyncBits: SyncCode - defines what code to do resync with
 * Output: None
 */
ErrorCode RISCProgram::Create( SyncCode SyncBits, bool resync )
{
   Trace t("RISCProgram::Create(3)");

   // allocate memory for the program first
   if ( AllocateStorage() != Success )
      return Fail;

   Command CurCommand;  // this will create every command we need - yahoo !

   // that's were the instructions are going
   LPDWORD pProgLoc = (LPDWORD)ProgramSpace_->getLinearBase();
   LPDWORD pProgStart = pProgLoc;

   // put one of the FM or VRx codes here
   pProgLoc = CreatePrologEpilog( pProgLoc, SyncBits, CurCommand, resync );
   pChainAddress_ = pProgLoc;
   CreateLoop( true );

   dwSize_ = (DWORD)pProgLoc - (DWORD)pProgStart;

   return Success;
}

RISCProgram::~RISCProgram()
{
   Trace t("RISCProgram::~RISCProgram(3)");
   delete ProgramSpace_;
   ProgramSpace_ = NULL;
   if ( pParent_ )
      pParent_->SetChild( NULL );
}
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\drivers\wdm\capture\mini\bt848\riscprog.h ===
// $Header: G:/SwDev/WDM/Video/bt848/rcs/Riscprog.h 1.9 1998/04/29 22:43:39 tomz Exp $

#ifndef __RISCPROG_H
#define __RISCPROG_H

#ifndef __MYTYPES_H
#include "mytypes.h"
#endif

#ifndef __VIDDEFS_H
#include "viddefs.h"
#endif

#ifndef __COLSPACE_H
#include "colspace.h"
#endif

#ifndef __PSPAGEBL_H
#include "pspagebl.h"
#endif

#ifndef __COMMAND_H
#include "command.h"
#endif
const Programs = 24;

inline LONGLONG operator-( const LARGE_INTEGER &first, const LARGE_INTEGER &second )
{
   return first.QuadPart - second.QuadPart;
}

inline bool operator>( const LARGE_INTEGER &first, const LARGE_INTEGER &second )
{
   return bool( first.QuadPart > second.QuadPart );
}

inline bool operator>=( const LARGE_INTEGER &first, const LARGE_INTEGER &second )
{
   return bool( first.QuadPart >= second.QuadPart );
}

/* Class: RISCProgram
 * Purpose: Facilitates creation and maintenance of a RISC programs
 * Attributes: ImageSize_: SIZE - structure containing dimentions of the image
 *   dwBufPitch_: DWORD - buffer pitch
 *   Field_: VideoField - which field the program is for
 *   Interrupting_: bool
 *   ProgramSpace_: PsPageBlock * - pointer to the class that manages the memory
 *   occupied by a program ( allocates, deallocates, obtains information )
 *   BufFormat_: ColorSpace - format of the data in the buffer
 * Operations:
 *   void  ChangeAddress( DWORD dwNewAddr )
 *   void  SetClipping( LPRECT pRect )
 *   void  Create( bool NeedInterrupt )
 *   void  SetChain( DWORD dwProgAddr )
 *   DWORD GetProgAddress()
 *   bool  IsInterrupting()
 */
class RISCProgram
{
   public:
      PDWORD       pChainAddress_;

   private:
      MSize        ImageSize_;
      DWORD        dwBufPitch_;

      bool         Interrupting_;
      bool         Counting_;
      
      PsPageBlock *ProgramSpace_;
      ColorSpace   BufFormat_;
      RISCProgram *pChild_;
      RISCProgram *pParent_;
      PDWORD       pIRQAddress_;
      DWORD        dwBufAddr_;
      DWORD        dwLinBufAddr_;
      bool         Skipped_;
      bool         GenerateResync_;

      BOOL          bAlreadyDumped_;
      PVOID         tag_;
      LARGE_INTEGER ExtraTag_;
      LARGE_INTEGER ExpectedExecutionTime_;

      DWORD        dwPlanarAdjust_;
      DWORD        dwSize_;

   protected:
      ErrorCode AllocateStorage( bool extra = false, int cnt = 1 );
      PDWORD CreatePrologEpilog( PDWORD pProgLoc, SyncCode SyncBits,
         Command &CurCommand, bool Resync = false );
      ErrorCode GetDataBufPhys( DataBuf &buf );

      void PutInChain();

   public:

      PHW_STREAM_REQUEST_BLOCK pSrb_;

      DWORD        GetDataBuffer( );
      void         SetDataBuffer( DWORD addr );

      void         ChangeAddress( DataBuf &buf );
      ErrorCode    Create( SyncCode SyncBits, bool resync = false );
      ErrorCode    Create( bool NeedInterrupt, DataBuf buf, DWORD dwPlanAdjust,
         bool resync = false, bool Loop = true );

      void         MakeFault() { *((PDWORD)GetProgAddress()) = (DWORD)-1; }
      DWORD        GetProgAddress();
      void         SetJump( PDWORD JumpAddr );

      // chaining/unchaining group
      RISCProgram *GetParent() { return pParent_; }
      RISCProgram *GetChild() { return pChild_; }
      void         SetParent( RISCProgram *p ) { pParent_ = p; }
      void         SetChild ( RISCProgram *p ) { pChild_  = p; }
      void         CreateLoop( bool );
      void         SetChain( RISCProgram *ChainTo );
      void         Skip();
      void         SetSkipped( bool sk = true );
      void         SetToCount();
      void         ResetStatus();
      void         SetStatus( int val );
      void         SetResync( bool val );

      bool         IsSkipped();
      bool         IsInterrupting();

      void         SetTag( PVOID value );
      PVOID        GetTag();

      void          SetTagEx( LARGE_INTEGER val );
      LARGE_INTEGER GetTagEx();

      LARGE_INTEGER GetExecTime() { return ExpectedExecutionTime_; }

//      static RISCProgram CreateStarter();

      DWORD GetPhysProgAddr();
      void         Dump();

      RISCProgram( MSize &size, DWORD pitch, ColFmt aColor );

      RISCProgram();

      ~RISCProgram();

      friend class RISCEng;
};

/* Method:  RISCProgram::GetProgramAddress
 * Purpose: Obtains address of this program
 * Input: None
 * Output: DWORD: program's address
 */
inline DWORD RISCProgram::GetProgAddress()
{
   return ProgramSpace_->getLinearBase();
}

inline void RISCProgram::SetToCount()
{
   Command IRQCommand;
   IRQCommand.SetToCount( pIRQAddress_ );
   Counting_ = true;
}

inline void RISCProgram::ResetStatus()
{
   Command IRQCommand;
   IRQCommand.ResetStatus( pIRQAddress_, 0xF );
   Counting_ = false;
}

inline void RISCProgram::SetStatus( int val )
{
   Command IRQCommand;
   IRQCommand.SetStatus( pIRQAddress_, val );
}

inline void RISCProgram::SetResync( bool val )
{
   Command SyncCommand;
   SyncCommand.SetResync( (PVOID)GetProgAddress(), val );
}

inline void  RISCProgram::SetSkipped( bool sk )
{
   Skipped_ = sk;
}

inline bool  RISCProgram::IsSkipped()
{
   return Skipped_;
}

inline bool  RISCProgram::IsInterrupting()
{
   return Interrupting_;
}

inline void  RISCProgram::SetTag( PVOID value )
{
   tag_ = value;
}

inline PVOID RISCProgram::GetTag()
{
   return tag_;
}

inline void RISCProgram::SetTagEx( LARGE_INTEGER val )
{
   ExtraTag_ = val;
}

inline LARGE_INTEGER RISCProgram::GetTagEx()
{
   return ExtraTag_;
}

/*
inline RISCProgram RISCProgram::CreateStarter()
{
   return RISCProgram();
}
*/
inline DWORD RISCProgram::GetPhysProgAddr()
{
   return ProgramSpace_->GetPhysAddr();
}

inline RISCProgram::RISCProgram( MSize &size, DWORD pitch, ColFmt aColor ) :
   ImageSize_( size ), dwBufPitch_( pitch ), Interrupting_( false ),
   BufFormat_( aColor ), ProgramSpace_( NULL ), tag_( NULL ), 
   dwPlanarAdjust_( 0 ), pChild_( NULL ), pParent_( NULL ), 
   pChainAddress_( NULL ), GenerateResync_( false ), Skipped_( false ),
   pIRQAddress_( NULL ), dwBufAddr_( 0 ), Counting_( false )
{
   ExtraTag_.QuadPart = 0;
   ExpectedExecutionTime_.QuadPart = 0;
   bAlreadyDumped_ = FALSE;
   dwSize_ = 0xffffffff;
   pSrb_ = 0;
}                                      

inline RISCProgram::RISCProgram() :
   ImageSize_( 10, 10 ), dwBufPitch_( 0 ), Interrupting_( false ),
   Counting_( false ), BufFormat_( CF_RGB32 ), ProgramSpace_( NULL ),
   tag_( NULL ), GenerateResync_( false ), pChild_( NULL ), pParent_( NULL ),
   pChainAddress_( NULL ), Skipped_( false ),
   pIRQAddress_( NULL ), dwBufAddr_( 0 ), dwLinBufAddr_( 0 )
{
   ExtraTag_.QuadPart = 0;
   ExpectedExecutionTime_.QuadPart = 0;
   bAlreadyDumped_ = FALSE;
   dwSize_ = 0xffffffff;
   pSrb_ = 0;
}
#endif
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\drivers\wdm\capture\mini\bt848\scaler.cpp ===
// $Header: G:/SwDev/WDM/Video/bt848/rcs/Scaler.cpp 1.3 1998/04/29 22:43:40 tomz Exp $

#include "Scaler.h"
#include "S_constr.h"


// video information for PAL
VideoInfoStruct NTSCVideoInfo =
{
   730,     // Clkx1_HACTIVE          = 746
   148,     // Clkx1_HDELAY           = 140
   44,      // Min_Pixels             =  44
   240,     // Active_lines_per_field = 240
   144,     // Min_UncroppedPixels    = Min_Pixels + 100
   724,     // Max_Pixels             = ((Clkx1_HACTIVE < 774) ? Clkx1_HACTIVE - 6 : 768)
   32,      // Min_Lines              = (Active_lines_per_field / 16 + 1) * 2
   240,     // Max_Lines              = Active_lines_per_field
   352,     // Max_VFilter1_Pixels    = ((Clkx1_HACTIVE > 796) ? 384 : (Clkx1_HACTIVE * 14 / 29))
   176,     // Max_VFilter2_Pixels    = Clkx1_HACTIVE * 8 / 33
   176,     // Max_VFilter3_Pixels    = Clkx1_HACTIVE * 8 / 33
   240,     // Max_VFilter1_Lines     = Active_lines_per_field
   120,     // Max_VFilter2_Lines     = Active_lines_per_field / 2
   96,      // Max_VFilter3_Lines     = Active_lines_per_field * 2 / 5
};

// video information for PAL
VideoInfoStruct PALVideoInfo = 
{
   914,     // Clkx1_HACTIVE          = 914
   190,     // Clkx1_HDELAY           = 190
   48,      // Min_Pixels             =  48
   284,     // Active_lines_per_field = 284
   148,     // Min_UncroppedPixels    = Min_Pixels + 100
   768,     // Max_Pixels             = ((Clkx1_HACTIVE < 774) ? Clkx1_HACTIVE - 6 : 768)
   36,      // Min_Lines              = (Active_lines_per_field / 16 + 1) * 2
   284,     // Max_Lines              = Active_lines_per_field
   384,     // Max_VFilter1_Pixels    = ((Clkx1_HACTIVE > 796) ? 384 : (Clkx1_HACTIVE * 14 / 29))
   221,     // Max_VFilter2_Pixels    = Clkx1_HACTIVE * 8 / 33
   221,     // Max_VFilter3_Pixels    = Clkx1_HACTIVE * 8 / 33
   284,     // Max_VFilter1_Lines     = Active_lines_per_field
   142,     // Max_VFilter2_Lines     = Active_lines_per_field / 2
   113,     // Max_VFilter3_Lines     = Active_lines_per_field * 2 / 5
};

//===========================================================================
// Bt848 Scaler Class Implementation
//===========================================================================



/////////////////////////////////////////////////////////////////////////////
// Constructor
/////////////////////////////////////////////////////////////////////////////

Scaler::Scaler( VidField field ):
   CONSTRUCT_SCALER_REGISTERS( ( ( field == VF_Even ) ? 0 : 0x80 ) ),

   // Since VDelay in hardware is reversed; i.e. odd reg is really even field
   // and vice versa, construct the opposite here
   regReverse_CROP ( (0x03 * 4) + ( ( field == VF_Even ) ? 0x80 : 0 ), RW ),
   fieldVDELAY_MSB( regReverse_CROP, 6, 2, RW),
   regVDELAY_LO ( (0x04 * 4) + ( ( field == VF_Even ) ? 0x80 : 0 ), RW ),
   regVDelay( regVDELAY_LO, 8, fieldVDELAY_MSB, RW ),
   m_videoFormat( VFormat_NTSC ), VFilterFlag_( On ),
   m_ptrVideoIn( &NTSCVideoInfo ) 
{
   m_HActive = 0;
   m_pixels = 0;
   m_lines = 0;
   m_VFilter = 0;
   // this seems to be the minimum needed for reliable CC capture
   regVDelay = 0x1A;
}


/////////////////////////////////////////////////////////////////////////////
// Destructor
/////////////////////////////////////////////////////////////////////////////
Scaler::~Scaler()
{
}

/////////////////////////////////////////////////////////////////////////////
// Method:  void Scaler::VideoFormatChanged( VideoFormat format )
// Purpose: Set which video format is using
// Input:   Video format -
//            Auto format:          VFormat_AutoDetect
//            NTSC (M):             VFormat_NTSC
//            PAL (B, D, G, H, I):  VFormat_PAL_BDGHI
//            PAL (M):              VFormat_PAL_M
//            PAL(N):               VFormat_PAL_N
//            SECAM:                VFormat_SECAM
// Output:  None
// Return:  None
/////////////////////////////////////////////////////////////////////////////
void Scaler::VideoFormatChanged( VideoFormat format )
{
	m_videoFormat = format;
}


/////////////////////////////////////////////////////////////////////////////
// Method:  void Scaler::Scale( MRect & clientScr )
// Purpose: Perform scaling
// Input:   MRect & clientScr - rectangle to scale to
// Output:  None
// Return:  None
/////////////////////////////////////////////////////////////////////////////
void Scaler::Scale( MRect & clientScr )
{
   if ( m_videoFormat == VFormat_NTSC )
      m_ptrVideoIn = &NTSCVideoInfo;   //  set scaling constants for NTSC
   else
      m_ptrVideoIn = &PALVideoInfo;    // set scaling constants for PAL/SECAM

   // the order of functions calling here is important because some
   // calculations are based on previous results
   SetHActive( clientScr ); 
   SetVActive();
   SetVScale( clientScr );
   SetVFilter();
   SetVDelay();
   SetHDelay();
   SetHScale();
   SetHFilter();

}

/////////////////////////////////////////////////////////////////////////////
// Method:  void Scaler::SetHActive( MRect & clientScr )
// Purpose: Set HActive register
// Input:   MRect & clientScr - rectangle to scale to
// Output:  None
// Return:  None
/////////////////////////////////////////////////////////////////////////////
void Scaler::SetHActive( MRect & clientScr )
{
   m_HActive = min( m_ptrVideoIn->Max_Pixels,
                    max( (WORD)clientScr.Width(), m_ptrVideoIn->Min_Pixels ) );

  regHActive = m_HActive;
}


/////////////////////////////////////////////////////////////////////////////
// Method:  void Scaler::SetHDelay( void )
// Purpose: Set HDelay register
// Input:   None
// Output:  None
// Return:  None
/////////////////////////////////////////////////////////////////////////////
void Scaler::SetHDelay( void )
{
   // calculations here requires calculation of HActive first!
   m_pixels = m_HActive;
   if ( m_pixels < m_ptrVideoIn->Min_UncroppedPixels )
      m_pixels += (WORD) ( ( m_ptrVideoIn->Min_UncroppedPixels - m_pixels + 9 ) / 10 );

   LONG a = (LONG)m_pixels * (LONG)m_ptrVideoIn->Clkx1_HDELAY;
   LONG b = (LONG)m_ptrVideoIn->Clkx1_HACTIVE * 2L;
   WORD HDelay = (WORD) ( ( a + (LONG)m_ptrVideoIn->Clkx1_HACTIVE * 2 - 1) / b * 2L );

   // now add the cropping region into HDelay register; i.e. skip some pixels
   // before we start taking them as real image
   HDelay += (WORD)AnalogWin_.left;

   // HDelay must be even or else color would be wrong
   HDelay &= ~01;

   regHDelay = HDelay;

   // since we increase HDelay, we should decrease HActive by the same amount
   m_HActive -= (WORD)AnalogWin_.left;
   regHActive = m_HActive;
}


/////////////////////////////////////////////////////////////////////////////
// Method:  void Scaler::SetHScale( void )
// Purpose: Set HScale register
// Input:   None
// Output:  None
// Return:  None
/////////////////////////////////////////////////////////////////////////////
void Scaler::SetHScale( void )
{
   regHScale = (WORD) ( ( ( (LONG)m_ptrVideoIn->Clkx1_HACTIVE * 4096L ) /
                                            (LONG)m_pixels ) - 4096L );
}


/////////////////////////////////////////////////////////////////////////////
// Method:  void Scaler::SetHFilter( void )
// Purpose: Set HFilt register field
// Input:   None
// Output:  None
// Return:  None
/////////////////////////////////////////////////////////////////////////////
void Scaler::SetHFilter( void )
{
   if ( m_videoFormat != VFormat_SECAM )
      fieldHFILT = HFilter_AutoFormat;
   else  // SECAM
      if ( m_pixels < m_ptrVideoIn->Clkx1_HACTIVE / 7 )
         fieldHFILT = HFilter_ICON;
      else
         fieldHFILT = HFilter_QCIF;
}         

/////////////////////////////////////////////////////////////////////////////
// Method:  void Scaler::SetVScale( MRect & clientScr )
// Purpose: Set VScale register
// Input:   MRect & clientScr - rectangle to scale to
// Output:  None
// Return:  None
/////////////////////////////////////////////////////////////////////////////
void Scaler::SetVScale( MRect & clientScr )
{
   m_lines = min( m_ptrVideoIn->Max_Lines,
                  max( (WORD)clientScr.Height(), m_ptrVideoIn->Min_Lines ) );

   WORD LPB_VScale_Factor = (WORD) ( 1 + ( m_lines - 1 ) / m_ptrVideoIn->Active_lines_per_field );

   m_lines = (WORD) ( ( m_lines + LPB_VScale_Factor - 1 ) / LPB_VScale_Factor );

   LONG a = (LONG)m_ptrVideoIn->Active_lines_per_field * 512L / (LONG)m_lines;
   WORD VScale = (WORD) ( ( 0x10000L - a + 512L ) & 0x1FFFL );
   regVScale = VScale;
}


/////////////////////////////////////////////////////////////////////////////
// Method:  void Scaler::SetVDelay( void )
// Purpose: Set VDelay register
// Input:   None
// Output:  None
// Return:  None
/////////////////////////////////////////////////////////////////////////////
void Scaler::SetVDelay( void )
{
   WORD VDelay, moreDelay;

   // increase VDelay will eliminate garbage lines at top of image
   switch ( m_VFilter )
   {
      case 3:
         moreDelay = 4;
         break;

      case 2:
         moreDelay = 2;
         break;
             
      case 1:
      case 0:
      default:
         moreDelay = 0;
         break;
   }

   if ( m_videoFormat == VFormat_NTSC )
      VDelay = 0x001A + moreDelay;    // NTSC
   else
      VDelay = 0x0026 + moreDelay;    // PAL/SECAM
                            
   // now add the cropping region into VDelay register; i.e. skip some pixels
   // before we start taking them as real image
   VDelay += (WORD)( ( (LONG)m_ptrVideoIn->Max_Lines * (LONG)AnalogWin_.top + m_lines - 1 ) / (LONG)m_lines * 2 );

   regVDelay = VDelay;
}

/////////////////////////////////////////////////////////////////////////////
// Method:  void Scaler::SetVActive( void )
// Purpose: Set VActive register
// Input:   None
// Output:  None
// Return:  None
/////////////////////////////////////////////////////////////////////////////
void Scaler::SetVActive( void )
{
   // No calculation needed for VActive register since it based on the UNSCALED image
   if ( m_videoFormat == VFormat_NTSC )
      regVActive = 0x1F4;
   else
      regVActive = 0x238;
}


/////////////////////////////////////////////////////////////////////////////
// Method:  void Scaler::SetVFilter( void )
// Purpose: Set VFilt register field
// Input:   None
// Output:  None
// Return:  None
/////////////////////////////////////////////////////////////////////////////
void Scaler::SetVFilter( void )
{
   // this is to remove junk lines at the top of video. flag set to off
   // when image hight is above CIF
   if ( VFilterFlag_ == Off ) {
      fieldVFILT = 0;
      m_VFilter  = 0;
      return;
   }
   if ( ( m_HActive <= m_ptrVideoIn->Max_VFilter3_Pixels ) &&
        ( m_lines   <= m_ptrVideoIn->Max_VFilter3_Lines ) )
      m_VFilter = 3;
   else if ( ( m_HActive <= m_ptrVideoIn->Max_VFilter2_Pixels ) &&
             ( m_lines   <= m_ptrVideoIn->Max_VFilter2_Lines ) )
      m_VFilter = 2;
   else if ( ( m_HActive <= m_ptrVideoIn->Max_VFilter1_Pixels ) &&
             ( m_lines   <= m_ptrVideoIn->Max_VFilter1_Lines ) )
      m_VFilter = 1;
   else
      m_VFilter = 0;

   fieldVFILT = m_VFilter;
}


/////////////////////////////////////////////////////////////////////////////
// Method:  void Scaler::GetDigitalWin( MRect &DigWin ) const
// Purpose: Retreives the size of digital window
// Input:   None
// Output:  MRect &DigWin - retrieved value
// Return:  None
/////////////////////////////////////////////////////////////////////////////
void Scaler::GetDigitalWin( MRect &DigWin ) const
{
   DigWin = DigitalWin_;
}


/////////////////////////////////////////////////////////////////////////////
// Method:  ErrorCode Scaler::SetDigitalWin( const MRect &DigWin )
// Purpose: Sets the size and location of the digital window
// Input:   const MRect &DigWin - window size to set to
// Output:  None
// Return:  Success or Fail if passed rect is bigger then analog window
// Note:    This function can affect the scaling, so Scale() is called
/////////////////////////////////////////////////////////////////////////////
ErrorCode Scaler::SetDigitalWin( const MRect &DigWin )
{
   // we can not scale up
   if ( ( DigWin.Height() > AnalogWin_.Height() ) ||
        ( DigWin.Width() > AnalogWin_.Width() ) )
      return Fail;

   DigitalWin_ = DigWin;

   // every invocation of SetDigitalWin potentially changes the scaling
   Scale( DigitalWin_ );

   return Success;
}


/////////////////////////////////////////////////////////////////////////////
// Method:  void Scaler::GetAnalogWin( MRect &AWin ) const
// Purpose: Retreives the size of analog window
// Input:   None
// Output:  MRect &DigWin - retrieved value
// Return:  None
/////////////////////////////////////////////////////////////////////////////
void Scaler::GetAnalogWin( MRect &AWin ) const
{
   AWin = AnalogWin_;
}

/////////////////////////////////////////////////////////////////////////////
// Method:  ErrorCode Scaler::SetAnalogWin( const MRect &AWin )
// Purpose: Sets the size and location of the analog window
// Input:   const MRect &AWin - window size to set to
// Output:  None
// Return:  Success or Fail if passed rect is bigger then analog window
/////////////////////////////////////////////////////////////////////////////
ErrorCode Scaler::SetAnalogWin( const MRect &AWin )
{
   AnalogWin_ = AWin;
   return Success;
}
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\drivers\wdm\capture\mini\bt848\scaler.h ===
// $Header: G:/SwDev/WDM/Video/bt848/rcs/Scaler.h 1.2 1998/04/29 22:43:41 tomz Exp $


#ifndef __SCALER_H
#define __SCALER_H

#include "mytypes.h"

#ifndef __COMPREG_H
#include "compreg.h"
#endif

#define HDROP       HANDLE

#include "viddefs.h"


// structure contains video information
struct VideoInfoStruct
{
   WORD Clkx1_HACTIVE;
   WORD Clkx1_HDELAY;
   WORD Min_Pixels;
   WORD Active_lines_per_field;
   WORD Min_UncroppedPixels;
   WORD Max_Pixels;
   WORD Min_Lines;
   WORD Max_Lines;
   WORD Max_VFilter1_Pixels;
   WORD Max_VFilter2_Pixels;
   WORD Max_VFilter3_Pixels;
   WORD Max_VFilter1_Lines;
   WORD Max_VFilter2_Lines;
   WORD Max_VFilter3_Lines;
};


/////////////////////////////////////////////////////////////////
//
// for pisces, instantiate as ...
//
// Scaler evenScaler( VF_Even );
// Scaler oddScaler( VF_Odd );
//
/////////////////////////////////////////////////////////////////


/////////////////////////////////////////////////////////////////////////////
// CLASS Scaler
//
// Description:
//    This class encapsulates the register fields in the scaler portion of
//    the Bt848.
//    A complete set of functions are developed to manipulate all the
//    register fields in the scaler registers for the Bt848.
//
// Methods:
//    See below
//
// Note:
//    For Bt848, instantiate as ...
//       Scaler evenScaler( VF_Even );
//       Scaler oddScaler( VF_Odd );
//
/////////////////////////////////////////////////////////////////////////////

class Scaler
{
	public:
		Scaler( VidField );
		~Scaler();

		void VideoFormatChanged( VideoFormat );
      void TurnVFilter( State st ) { VFilterFlag_ = st; }
                             
		void      Scale( MRect & );
      ErrorCode SetAnalogWin( const MRect & );
      void      GetAnalogWin( MRect & ) const;
      ErrorCode SetDigitalWin( const MRect & );
      void      GetDigitalWin( MRect & ) const;

   protected:
      #include "S_declar.h"

		VideoInfoStruct * m_ptrVideoIn;
      MRect AnalogWin_;
      MRect DigitalWin_;

      // member functions to set scaling registers
		virtual void SetHActive( MRect & );
		virtual void SetHDelay( void );
		virtual void SetHScale( void );
      virtual void SetHFilter( void );
		virtual void SetVActive( void );
		virtual void SetVDelay( void );
		virtual void SetVScale( MRect & );
		virtual void SetVFilter( void );

   private:
		VideoFormat  m_videoFormat;   // video format

      // this is to battle junk lines at the top of the video
      State VFilterFlag_;

      WORD  m_HActive;  // calcuated intermediate value
      WORD  m_pixels;   // calcuated intermediate value
      WORD  m_lines;    // calcuated intermediate value
      WORD  m_VFilter;  // calcuated intermediate value

};


#endif __SCALER_H
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\drivers\wdm\capture\mini\bt848\s_constr.h ===
// $Header: G:/SwDev/WDM/Video/bt848/rcs/S_constr.h 1.3 1998/04/29 22:43:40 tomz Exp $

#ifndef __S_CONSTR_H
#define __S_CONSTR_H


#define CONSTRUCT_SCALER_REGISTERS( offset ) \
regCROP ( (0x03 * 4) + (offset), RW ) ,\
fieldVACTIVE_MSB( regCROP, 4, 2, RW) ,\
fieldHDELAY_MSB( regCROP, 2, 2, RW) ,\
fieldHACTIVE_MSB( regCROP, 0, 2, RW) ,\
regVACTIVE_LO ( (0x05 * 4) + (offset), RW ) ,\
regHDELAY_LO ( (0x06 * 4) + (offset), RW ) ,\
regHACTIVE_LO ( (0x07 * 4) + (offset), RW ) ,\
regHSCALE_HI ( (0x08 * 4) + (offset), RW ) ,\
fieldHSCALE_MSB( regHSCALE_HI, 0, 8, RW) ,\
regHSCALE_LO ( (0x09 * 4) + (offset), RW ) ,\
regSCLOOP ( (0x10 * 4) + (offset), RW ) ,\
fieldHFILT( regSCLOOP, 3, 2, RW) ,\
regVSCALE_HI ( (0x13 * 4) + (offset), RW ) ,\
fieldVSCALE_MSB( regVSCALE_HI, 0, 5, RW) ,\
regVSCALE_LO ( (0x14 * 4) + (offset), RW ) ,\
regVActive( regVACTIVE_LO, 8, fieldVACTIVE_MSB, RW ),\
regVScale( regVSCALE_LO, 8, fieldVSCALE_MSB, RW ),\
regHDelay( regHDELAY_LO, 8, fieldHDELAY_MSB, RW ),\
regHActive( regHACTIVE_LO, 8, fieldHACTIVE_MSB, RW ),\
regHScale( regHSCALE_LO, 8, fieldHSCALE_MSB, RW ),\
regVTC ( (0x1B * 4) + (offset), RW ) ,\
fieldVFILT( regVTC, 0, 2, RW)

#endif   // __S_CONSTR_H
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\drivers\wdm\capture\mini\bt848\s_declar.h ===
// $Header: G:/SwDev/WDM/Video/bt848/rcs/S_declar.h 1.3 1998/04/29 22:43:40 tomz Exp $

#ifndef __S_DECLAR_H
#define __S_DECLAR_H

//===========================================================================
// Scaler registers
//===========================================================================
RegisterB regCROP;
RegField  fieldVDELAY_MSB;
RegField  fieldVACTIVE_MSB;
RegField  fieldHDELAY_MSB;
RegField  fieldHACTIVE_MSB;
RegisterB regVDELAY_LO;
RegisterB regVACTIVE_LO;
RegisterB regHDELAY_LO;
RegisterB regHACTIVE_LO;
RegisterB regHSCALE_HI;
RegField  fieldHSCALE_MSB;
RegisterB regHSCALE_LO;
RegisterB regSCLOOP;
RegField  fieldHFILT;
RegisterB regVSCALE_HI;
RegField  fieldVSCALE_MSB;
RegisterB regVSCALE_LO;
RegisterB regVTC;
RegField  fieldVFILT;
CompositeReg regVDelay;
CompositeReg regVActive;
CompositeReg regVScale;
CompositeReg regHDelay;
CompositeReg regHActive;
CompositeReg regHScale;

// Since VDelay register in hardware is reversed;
// i.e. odd reg is really even field and vice versa, need an extra cropping reg
// for the opposite field
RegisterB regReverse_CROP;

#endif   // __S_DECLAR_H
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\drivers\wdm\capture\mini\bt848\tuner.h ===
// $Header: G:/SwDev/WDM/Video/bt848/rcs/Tuner.h 1.2.1.2 1998/04/29 22:43:41 tomz Exp ssm $

/////////////////////////////////////////////////////////////////////////////
//
//  Copyright (c) 1996 Brooktree Corporation
//
//  Module:
//
//    Tuner.h
//
//  Abstract:
//
//    Bt878 Tuner class header file
//
/////////////////////////////////////////////////////////////////////////////

#ifndef __TUNER_H
#define __TUNER_H
/*
#include "retcode.h"

/////////////////////////////////////////////////////////////////////////////
// Constants
/////////////////////////////////////////////////////////////////////////////
// US: 87.5 - 108.0, Japan 76 - 91, Eastern Europe 64 - 72
const int MIN_FREQ = 640;     // no decimal place; i.e. 64.0MHz -> 640
const int MAX_FREQ = 1080;
*/

#define  USE_TEMIC_TUNER
//#define  USE_ALPS_TUNER
//#define  USE_PHILIPS_TUNER

#ifdef USE_TEMIC_TUNER
   const  BYTE  TunerI2CAddress   = 0xC2;    // I2C address for Temic tuner
   const  WORD  TunerBandCtrlLow  = 0x8E02;  // Ctrl code for VHF low
   const  WORD  TunerBandCtrlMid  = 0x8E04;  // Ctrl code for VHF high
   const  WORD  TunerBandCtrlHigh = 0x8E01;  // Ctrl code for UHF
#elif defined(USE_ALPS_TUNER)
   const  BYTE  TunerI2CAddress   = 0xC0;    // I2C address for Alps tuner
   const  WORD  TunerBandCtrlLow  = 0xC214;  // Ctrl code for VHF low
   const  WORD  TunerBandCtrlMid  = 0xC212;  // Ctrl code for VHF high
   const  WORD  TunerBandCtrlHigh = 0xC211;  // Ctrl code for UHF
#elif defined(USE_PHILIPS_TUNER)
   const  BYTE  TunerI2CAddress   = 0xC0;    // I2C address for Philips tuner
   const  WORD  TunerBandCtrlLow  = 0xCEA0;  // Ctrl code for VHF low
   const  WORD  TunerBandCtrlMid  = 0xCE90;  // Ctrl code for VHF high
   const  WORD  TunerBandCtrlHigh = 0xCE30;  // Ctrl code for UHF
#endif

#endif // __TUNER_H
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\drivers\wdm\capture\mini\bt848\tuner.cpp ===
// $Header: G:/SwDev/WDM/Video/bt848/rcs/Tuner.cpp 1.8 1998/05/07 15:24:56 tomz Exp $

extern "C" {
#include <strmini.h>
#include <wdm.h>
#include <windef.h>
}

#include "device.h"

#define PICTURE_INTERMEDIATE_FREQUENCY 45750000L

const BAND_LOW    =  55250000;    //  55.25 MHz
const BAND_LOWMID = 160000000;    // 160.00 MHz
const BAND_MIDHI  = 454000000;    // 454.00 MHz
const BAND_HI     = 801250000;    // 801.25 MHz

int PsDevice::GetPllOffset( PULONG busy, ULONG &lastFreq )
{
   lastFreq = LastFreq_;
   
   BYTE status = 0;
   I2CHWRead( TunerInfo.TunerI2CAddress, &status );
   DebugOut((1, "Tuner - status(%x)\n", status));
   if ( status & 0x40 ) {
      *busy = false;
      switch ( status & 0x07 ) {
      case 0:     // carrier sensed, need to lower frequency
         DebugOut((1, "Tuner: -2 (carrier sensed, need to lower frequency)\n"));
         return -2;
      case 1:     // carrier sensed, need to lower frequency
         DebugOut((1, "Tuner: -1 (carrier sensed, need to lower frequency)\n"));
         return -1;
      case 2:     // carrier sensed, we are on correct frequency
         DebugOut((1, "Tuner: 0 (carrier sensed, we are on correct frequency)\n"));
         return 0;
      case 3:     // carrier sensed, need to raise frequency
         DebugOut((1, "Tuner: 1 (carrier sensed, need to raise frequency)\n"));
         return 1;
      case 4:     // carrier not sensed
      default:
         DebugOut((1, "Tuner: 2 (carrier not sensed)\n"));
         return 2;
      } // switch
   }
   DebugOut((1, "Tuner: busy - return 0\n"));
   *busy = true;
   return 0;
}

void PsDevice::SetChannel( long lFreq )
{
   // Set the video carrier frequency
   // by controlling the programmable divider
   //
   // N = (16 * (FreqRF + FreqIntermediate)) / 1e6
   //

   LastFreq_ = lFreq;

   LONGLONG lTemp = lFreq;
   WORD wCtrl=0;
   lTemp = (lTemp + PICTURE_INTERMEDIATE_FREQUENCY) * 16;
   lTemp /= 1000000;

   // Set the band register
   if ( lFreq >= BAND_LOW && lFreq <= BAND_LOWMID )
   {
      wCtrl = TunerInfo.TunerBandCtrlLow;
   }
   else if ( lFreq > BAND_LOWMID && lFreq <= BAND_MIDHI )
   {
      wCtrl = TunerInfo.TunerBandCtrlMid;
   }
   else if ( lFreq > BAND_MIDHI && lFreq <= BAND_HI)
   {
      wCtrl = TunerInfo.TunerBandCtrlHigh;
   }

   // write HIWORD to I2C
   I2CHWWrite3( TunerInfo.TunerI2CAddress, HIBYTE( WORD( lTemp ) ), LOBYTE( WORD( lTemp ) ) );

   // write LOWORD to I2C
   I2CHWWrite3( TunerInfo.TunerI2CAddress, HIBYTE( wCtrl ), LOBYTE( wCtrl ) );
}
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\drivers\wdm\capture\mini\bt848\vidchifc.h ===
// $Header: G:/SwDev/WDM/Video/bt848/rcs/Vidchifc.h 1.3 1998/04/29 22:43:42 tomz Exp $

#ifndef __VIDCHIFC_H
#define __VIDCHIFC_H


#ifndef __CHANIFACE_H
#include "chanifac.h"
#endif

/* Class: VideoChanIface
 * Purpose: Used to establish a callback mecanism when CaptureChip-derived class
 *   can call VxDVideoChannel class back to notify about an interrupt
 */
class VideoChannel;

class VideoChanIface : public ChanIface
{
   private:
      VideoChannel *ToBeNotified_;
   public:
      virtual void Notify( PVOID pTag, bool skipped );
      VideoChanIface( VideoChannel *aChan ) : ToBeNotified_( aChan ) {}
};

#endif
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\drivers\wdm\capture\mini\bt848\xbar.h ===
// $Header: G:/SwDev/WDM/Video/bt848/rcs/Xbar.h 1.8 1998/04/29 22:43:42 tomz Exp $

#ifndef __XBAR_H
#define __XBAR_H

//
// This file defines interconnections between components via Mediums
//

#ifdef __cplusplus
extern "C" {
#endif

#ifdef BT848_MEDIUMS
    #define MEDIUM_DECL 
#else
    #define MEDIUM_DECL extern
#endif

/*  -----------------------------------------------------------

    Topology of all devices:

                            PinDir  FilterPin#    M_GUID#
    TVTuner                 
        TVTunerVideo        out         0            0
        TVTunerAudio        out         1            1
    TVAudio
        TVTunerAudio        in          0            1
        TVAudio             out         1            3
    Crossbar
        TVTunerVideo        in          0            0
        TVAudio             in          3            3
        AnalogVideoOut      out         4            4
        AnalogAudioOut      out         5            NULL
    Capture
        AnalogVideoIn       in          0            4
        

All other pins are marked as promiscuous connections via GUID_NULL
------------------------------------------------------------------ */        
        
// Define the GUIDs which will be used to create the Mediums
#define M_GUID0 0xa19dc0e0, 0x3b39, 0x11d1, 0x90, 0x5f, 0x0, 0x0, 0xc0, 0xcc, 0x16, 0xba
#define M_GUID1 0xa19dc0e1, 0x3b39, 0x11d1, 0x90, 0x5f, 0x0, 0x0, 0xc0, 0xcc, 0x16, 0xba
#define M_GUID2 0xa19dc0e2, 0x3b39, 0x11d1, 0x90, 0x5f, 0x0, 0x0, 0xc0, 0xcc, 0x16, 0xba
#define M_GUID3 0xa19dc0e3, 0x3b39, 0x11d1, 0x90, 0x5f, 0x0, 0x0, 0xc0, 0xcc, 0x16, 0xba
#define M_GUID4 0xa19dc0e4, 0x3b39, 0x11d1, 0x90, 0x5f, 0x0, 0x0, 0xc0, 0xcc, 0x16, 0xba
#define M_GUID5 0xa19dc0e5, 0x3b39, 0x11d1, 0x90, 0x5f, 0x0, 0x0, 0xc0, 0xcc, 0x16, 0xba
#define M_GUID6 0xa19dc0e6, 0x3b39, 0x11d1, 0x90, 0x5f, 0x0, 0x0, 0xc0, 0xcc, 0x16, 0xba
#define M_GUID7 0xa19dc0e7, 0x3b39, 0x11d1, 0x90, 0x5f, 0x0, 0x0, 0xc0, 0xcc, 0x16, 0xba
#define M_GUID8 0xa19dc0e8, 0x3b39, 0x11d1, 0x90, 0x5f, 0x0, 0x0, 0xc0, 0xcc, 0x16, 0xba
#define M_GUID9 0xa19dc0e9, 0x3b39, 0x11d1, 0x90, 0x5f, 0x0, 0x0, 0xc0, 0xcc, 0x16, 0xba

// Note: To allow multiple instances of the same piece of hardware,
// set the first ULONG after the GUID in the Medium to a unique value.

// ---------------------------------------------------------------

MEDIUM_DECL KSPIN_MEDIUM TVTunerMediums[2]
#ifdef BT848_MEDIUMS
    = {
        {M_GUID0,           0, 0},  // Pin 0
        {M_GUID1,           0, 0},  // Pin 1
    }
#endif
;

MEDIUM_DECL BOOL TVTunerPinDirection [2]
#ifdef BT848_MEDIUMS
     = {
        TRUE,                       // Output Pin 0
        TRUE,                       // Output Pin 1
    }
#endif
;

// -----------------------------------------------

MEDIUM_DECL KSPIN_MEDIUM TVAudioMediums[2]
#ifdef BT848_MEDIUMS
     = {
         {M_GUID1,           0, 0},  // Pin 0
         {M_GUID3,           0, 0},  // Pin 1
       }
#endif
;

MEDIUM_DECL BOOL TVAudioPinDirection [2]
#ifdef BT848_MEDIUMS
    = {
         FALSE,                      // Input  Pin 0
         TRUE,                       // Output Pin 1
      }
#endif
;

// ---------------------------------------------------------------

MEDIUM_DECL KSPIN_MEDIUM CrossbarMediums[6]
#ifdef BT848_MEDIUMS
     = {
        {STATIC_GUID_NULL,  0, 0},  // Input  Pin 0 - SVideoIn
        {M_GUID0,           0, 0},  // Input  Pin 2, KS_PhysConn_Video_Tuner,        
        {STATIC_GUID_NULL,  0, 0},  // Input  Pin 1 - VideoCompositeIn
        {M_GUID3,           0, 0},  // Input  Pin 3  KS_PhysConn_Audio_Tuner,         
        {M_GUID4,           0, 0},  // Output Pin 4 - VideoDecoderOut
        {STATIC_GUID_NULL,  0, 0},  // Output Pin 5  KS_PhysConn_Audio_AudioDecoder,        
}
#endif
;

MEDIUM_DECL BOOL CrossbarPinDirection [6]
#ifdef BT848_MEDIUMS
     = {
        FALSE,                      // Input  Pin 0
        FALSE,                      // Input  Pin 1
        FALSE,                      // Input  Pin 2
        FALSE,                      // Input  Pin 3
        TRUE,                       // Output Pin 4
        TRUE,                       // Output Pin 5
}
#endif
;

// ---------------------------------------------------------------

MEDIUM_DECL KSPIN_MEDIUM CaptureMediums[4]
#ifdef BT848_MEDIUMS
     = {
        // should change STATIC_KSMEDIUMSETID_Standard to
        // STATIC_GUID_NULL when it works
        {STATIC_KSMEDIUMSETID_Standard,  0, 0},  // Pin 0  Capture
        {STATIC_KSMEDIUMSETID_Standard,  0, 0},  // Pin 1  Preview
        {STATIC_KSMEDIUMSETID_Standard,  0, 0},  // Pin 2  VBI
        {M_GUID4,           0, 0},  // Pin 3  Analog Video In
}
#endif
;

MEDIUM_DECL BOOL CapturePinDirection [4]
#ifdef BT848_MEDIUMS
     = {
        TRUE,                       // Output Pin 0
        TRUE,                       // Output Pin 1
        TRUE,                       // Output Pin 2
        FALSE,                      // Input  Pin 3
}
#endif
;

MEDIUM_DECL GUID CaptureCategories [4]
#ifdef BT848_MEDIUMS
     = {
    STATIC_PINNAME_VIDEO_CAPTURE,           // Pin 0
    STATIC_PINNAME_VIDEO_PREVIEW,           // Pin 1
    STATIC_PINNAME_VIDEO_VBI,               // Pin 2
    STATIC_PINNAME_VIDEO_ANALOGVIDEOIN,     // Pin 3
}
#endif
;

#ifdef __cplusplus
}
#endif


// ---------------------------------------------------------------

struct _XBAR_PIN_DESCRIPTION {
    ULONG PinType;
    ULONG RelatedPinIndex;
    ULONG IsRoutedTo;                 // Index of input pin in use
    ULONG PinNo; // pin number as hard-wired; i.e. mux input 1; to be used in calls
                 // into the decoder to select a mux input

    const KSPIN_MEDIUM *Medium;

    _XBAR_PIN_DESCRIPTION( ULONG type, ULONG no, ULONG rel, const KSPIN_MEDIUM *);
    _XBAR_PIN_DESCRIPTION(){}
};

inline _XBAR_PIN_DESCRIPTION::_XBAR_PIN_DESCRIPTION( ULONG type, ULONG no,
   ULONG rel, const KSPIN_MEDIUM *Medium ) : PinType( type ),
   RelatedPinIndex( rel ), IsRoutedTo( 0 ), PinNo( no ), Medium (Medium)
{
}

const int MaxOutPins = 2;
const int MaxInpPins = 4;

class CrossBar
{
   // it is possible to make these into the pointers and allocate dynamically
   // based on info from registry; but this seems like a lot of work - just allocate
   // the maximum possible number and construct each based on the registry settings
   _XBAR_PIN_DESCRIPTION OutputPins [MaxOutPins];
   _XBAR_PIN_DESCRIPTION InputPins [MaxInpPins];

      int InPinsNo_;
   public:
      int GetNoInputs();
      int GetNoOutputs();
      bool TestRoute( int InPin, int OutPin );
      ULONG  GetPinInfo( int dir, int idx, ULONG &related, 
                KSPIN_MEDIUM * Medium);
      ULONG GetPinNo( int no );

      void Route( int OutPin, int InPin );
      bool GoodPins( int InPin, int OutPin );

      int GetRoute( int OutPin );

      CrossBar() : InPinsNo_( 0 ) {};
      CrossBar( LONG *types );
};

inline CrossBar::CrossBar( LONG *types ) : InPinsNo_( 0 )
{
	OutputPins [0] = _XBAR_PIN_DESCRIPTION( KS_PhysConn_Video_VideoDecoder, 
        0, 1, &CrossbarMediums[4]);
   
   // [!!!] The following should be moved into the _XBAR_PIN_DESCRIPTION 
   //       constructor as another parameter
   Route( 0 /*Video OutPin*/, 1 /*Video InPin*/ );

   OutputPins [1] = _XBAR_PIN_DESCRIPTION( KS_PhysConn_Audio_AudioDecoder, 
        0, 1, &CrossbarMediums[5]);

   // [!!!] The following should be moved into the _XBAR_PIN_DESCRIPTION
   //       constructor as another parameter
   Route( 1 /*Audio OutPin*/, 3 /*Audio InPin*/ );

   for ( int i = 0; i < MaxInpPins; i++ ) {
      if ( types [i] != -1 ) {
         InputPins [InPinsNo_] = _XBAR_PIN_DESCRIPTION( types [i], i, (DWORD) -1, &CrossbarMediums[i] );
         InPinsNo_++;
      }
   }

}

inline int CrossBar::GetNoInputs()
{
   return InPinsNo_;
}

inline int CrossBar::GetNoOutputs()
{
   return MaxOutPins;
}

inline bool CrossBar::GoodPins( int InPin, int OutPin )
{
   return InPinsNo_ &&
      bool( InPin >= -1 && InPin < InPinsNo_ && OutPin >= 0 && OutPin < MaxOutPins );	// JBC 4/1/98 Don't allow negative pin numbers
}

inline void CrossBar::Route( int OutPin, int InPin )
{
   OutputPins [OutPin].IsRoutedTo = InPin;
}

inline int CrossBar::GetRoute( int OutPin )
{
   return OutputPins [OutPin].IsRoutedTo;
}

// should be called for input pins only !
inline ULONG CrossBar::GetPinNo( int no )
{
   return InputPins [no].PinNo;
}

inline ULONG CrossBar::GetPinInfo( int dir, int idx, ULONG &related,
        KSPIN_MEDIUM * Medium )
{
   _XBAR_PIN_DESCRIPTION *pPinDesc;

   if ( dir == KSPIN_DATAFLOW_IN ) {
      pPinDesc = InputPins;
      ASSERT( idx < InPinsNo_ );
   } else {
      pPinDesc = OutputPins;
      ASSERT( idx < MaxOutPins );
   }
   related = pPinDesc [idx].RelatedPinIndex;
   *Medium = *pPinDesc[idx].Medium;
   return pPinDesc [idx].PinType;
}

#endif
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\drivers\wdm\capture\mini\bt848\vbifmt.h ===
// $Header: G:/SwDev/WDM/Video/bt848/rcs/Vbifmt.h 1.4 1998/04/29 22:43:41 tomz Exp $

#ifndef __VBIFMT_H
#define __VBIFMT_H

#include "defaults.h"

KS_DATARANGE_VIDEO_VBI StreamFormatVBI =
{
   // KSDATARANGE
   {
      {
         sizeof( KS_DATARANGE_VIDEO_VBI ),
         0,
         VBISamples * 12,            // SampleSize
         0,                          // Reserved
         { STATIC_KSDATAFORMAT_TYPE_VBI },
         { STATIC_KSDATAFORMAT_SUBTYPE_RAW8 },
         { STATIC_KSDATAFORMAT_SPECIFIER_VBI }
      }
   },
   true,    // BOOL,  bFixedSizeSamples (all samples same size?)
   true,    // BOOL,  bTemporalCompression (all I frames?)
   KS_VIDEOSTREAM_VBI, // StreamDescriptionFlags  (KS_VIDEO_DESC_*)
   0,       // MemoryAllocationFlags   (KS_VIDEO_ALLOC_*)

   // _KS_VIDEO_STREAM_CONFIG_CAPS
   {
      { STATIC_KSDATAFORMAT_SPECIFIER_VBI },
      KS_AnalogVideo_NTSC_M,                       // AnalogVideoStandard
      {
         VBISamples, VBILines  // SIZE InputSize
      },
      {
         VBISamples, 12   // SIZE MinCroppingSize;       smallest rcSrc cropping rect allowed
      },
      {
         VBISamples, 12   // SIZE MaxCroppingSize;       largest rcSrc cropping rect allowed
      },
      1,           // int CropGranularityX;       // granularity of cropping size
      1,           // int CropGranularityY;
      1,           // int CropAlignX;             // alignment of cropping rect
      1,           // int CropAlignY;
      {
         VBISamples, 12   // SIZE MinOutputSize;         // smallest bitmap stream can produce
      },
      {
         VBISamples, 12   // SIZE MaxOutputSize;         // largest  bitmap stream can produce
      },
      1,          // int OutputGranularityX;     // granularity of output bitmap size
      2,          // int OutputGranularityY;
      0,          // StretchTapsX  (0 no stretch, 1 pix dup, 2 interp...)
      0,          // StretchTapsY
      0,          // ShrinkTapsX
      0,          // ShrinkTapsY
      333667,     // LONGLONG MinFrameInterval;  // 100 nS units
      333667,     // LONGLONG MaxFrameInterval;
      VBISamples * 30 * VBILines * 2 * 8, // LONG MinBitsPerSecond;
      VBISamples * 30 * VBILines * 2 * 8  // LONG MaxBitsPerSecond;
   },

   // KS_VBIINFOHEADER (default format)
   {
      VBIStart,      // StartLine  -- inclusive
      VBIEnd,        // EndLine    -- inclusive
      VBISampFreq,   // SamplingFrequency
      454,                    // MinLineStartTime;    // (uS past HR LE) * 100
      900,                    // MaxLineStartTime;    // (uS past HR LE) * 100

      // empirically discovered
      780,                    // ActualLineStartTime  // (uS past HR LE) * 100

      5902,                   // ActualLineEndTime;   // (uS past HR LE) * 100
      KS_AnalogVideo_NTSC_M,      // VideoStandard;
      VBISamples,           // SamplesPerLine;
      VBISamples,       // StrideInBytes;
      VBISamples * 12   // BufferSize;
   }
};

#endif
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\drivers\wdm\capture\mini\bt848\vidch.cpp ===
// $Header: G:/SwDev/WDM/Video/bt848/rcs/Vidch.cpp 1.22 1998/05/12 20:39:19 tomz Exp $

#include "vidch.h"
#include "defaults.h"
#include "fourcc.h"
#include "capmain.h"

#ifdef	HAUPPAUGE
#include "HCWDebug.h"
#endif

void CheckSrbStatus( PHW_STREAM_REQUEST_BLOCK pSrb );

BOOL VideoChannel::bIsVBI()
{
   PSTREAMEX pStrmEx = (PSTREAMEX)GetStrmEx( );
   if ( pStrmEx->StreamNumber == STREAM_IDX_VBI )
   {
      return TRUE;
   }
   else
   {
      return FALSE;
   }
}

BOOL VideoChannel::bIsVideo()
{
   PSTREAMEX pStrmEx = (PSTREAMEX)GetStrmEx( );
   if (( pStrmEx->StreamNumber == STREAM_IDX_PREVIEW ) ||
       ( pStrmEx->StreamNumber == STREAM_IDX_CAPTURE ))
   {
      return TRUE;
   }
   else
   {
      return FALSE;
   }
}


/* Method: VideoChannel::SetDigitalWindow
 * Purpose: Sets the output image size
 * Input: r:   MRect &
 * Output:
 */
ErrorCode VideoChannel::SetDigitalWindow( MRect &r )
{
   Trace t("VideoChannel::SetDigitalWindow()");
   return Digitizer_->SetDigitalWindow( r, *OurField_ );
}

/* Method: VideoChannel::SetAnalogWindow
 * Purpose: Sets the analog dimention for this stream
 * Input: r: MRect &
 * Output:
 */
ErrorCode VideoChannel::SetAnalogWindow( MRect &r )
{
   Trace t("VideoChannel::SetAnalogWindow()");
   return Digitizer_->SetAnalogWindow( r, *OurField_ );
}

/* Method: VideoChannel::OpenChannel
 * Purpose: Allocates a stream from a capture chip
 * Input:
 * Output:
 * Note: It is possible that the current implementation does not require an
 *   elaborate stream allocation scheme. Nonetheless it is used as number of
 *   streams can increase in the future and their dynamics can change
 */
ErrorCode VideoChannel::OpenChannel()
{
   Trace t("VideoChannel::OpenChannel()");

   // can not open twice
   if ( IsOpen() == true )
      return Fail;
   if ( Digitizer_->AllocateStream( OurField_, Stream_ ) == Success ) {
      // store information for all subsequent calls

      SetPaired( false );

      OurField_->SetCallback( &Caller_ );
      SetInterrupt( true );

      // flag the state
      SetOpen();

      SetDefaultQue();
      return Success;
   }
   return Fail;
}

/* Method: VideoChannel::CloseChannel
 * Purpose: Closes the channel. Makes sure everything is freed
 * Input:
 * Output:
 */
ErrorCode VideoChannel::CloseChannel()
{
   Trace t("VideoChannel::CloseChannel()");

   if ( !IsOpen() )
      return Fail;
   
   Stop( );

   while( !BufQue_.IsEmpty( ) )
   {
      DataBuf buf = BufQue_.Get();
   }

   BufQue_.Flush();

   while( !Requests_.IsEmpty( ) )
   {
      PHW_STREAM_REQUEST_BLOCK pSrb = Requests_.Get();
      if ( RemoveSRB( pSrb ))
      {
         DebugOut((0, "   RemoveSRB failed\n"));
         DEBUG_BREAKPOINT();
      }
   }

   Requests_.Flush();

   SetClose();
   return Success;
}

/* Method: VideoChannel::SetFormat
 * Purpose:
 * Input:
 * Output:
 */
ErrorCode VideoChannel::SetFormat( ColFmt aFormat )
{
   Trace t("VideoChannel::SetFormat()");
   Digitizer_->SetPixelFormat( aFormat, *OurField_ );
   return Success;
}

/* Method: VideoChannel::GetFormat
 * Purpose:
 * Input:
 * Output:
 */
ColFmt VideoChannel::GetFormat()
{
   Trace t("VideoChannel::GetFormat()");
   return Digitizer_->GetPixelFormat( *OurField_ );
}

/* Method: VideoChannel::AddBuffer
 * Purpose: This function adds a buffer to a queue
 * Input: pNewBuffer: PVOID - pointer to a buffer to add
 * Output: None
 * Note: This function 'does not know' where the queue is located. It just uses
 *   a pointer to it.
 */
void VideoChannel::AddBuffer( PVOID pPacket )
{
   Trace t("VideoChannel::AddBuffer()");
   DataBuf buf( GetSRB(), pPacket );

   BufQue_.Put( buf );
   DebugOut((1, "AddBuf %x\n", pPacket ) );

   LONGLONG *pB1 = (LONGLONG *)pPacket;
   LONGLONG *pB2 = pB1 + 1;
#ifdef DEBUG
   for ( UINT i = 0; i < 640; i++ ) {
#endif
      *pB1 = 0xAAAAAAAA33333333;
      *pB2 = 0xBBBBBBBB22222222;
#ifdef DEBUG
      pB1 += 2;
      pB2 += 2;
   }
#endif
}

/* Method: VideoChannel::ResetCounters
 * Purpose: Reset the frame info counters
 * Input: None
 * Output: None
 */
VOID VideoChannel::ResetCounters( )
{
   ULONG StreamNumber = Stream_;
   if ( StreamNumber == STREAM_IDX_VBI )
   {
      PKS_VBI_FRAME_INFO pSavedFrameInfo = &((PSTREAMEX)GetStrmEx())->FrameInfo.VbiFrameInfo;
      pSavedFrameInfo->ExtendedHeaderSize = sizeof( KS_VBI_FRAME_INFO );
      pSavedFrameInfo->PictureNumber = 0;
      pSavedFrameInfo->DropCount = 0;
   }
   else
   {
      PKS_FRAME_INFO pSavedFrameInfo = &((PSTREAMEX)GetStrmEx())->FrameInfo.VideoFrameInfo;
      pSavedFrameInfo->ExtendedHeaderSize = sizeof( KS_FRAME_INFO );
      pSavedFrameInfo->PictureNumber = 0;
      pSavedFrameInfo->DropCount = 0;
   }
}

/* Method: VideoChannel::TimeStamp
 * Purpose: Performs the standard buffer massaging when it's done
 * Input: pSrb
 * Output: None
 */
void STREAMAPI VideoChannel::TimeStamp( PHW_STREAM_REQUEST_BLOCK pSrb )
{
   Trace t("VideoChannel::TimeStamp()");

   PKSSTREAM_HEADER  pDataPacket = pSrb->CommandData.DataBufferArray;
   VideoChannel *chan = (VideoChannel *)((PSTREAMEX)pSrb->StreamObject->HwStreamExtension)->videochannel;

   pDataPacket->PresentationTime.Numerator = 1;
   pDataPacket->PresentationTime.Denominator = 1;

	if( chan->IsVideoInfo2() )
	{
		pDataPacket->DataUsed = chan->GetVidHdr2()->bmiHeader.biSizeImage;
	}
	else
	{
		pDataPacket->DataUsed = chan->GetVidHdr()->bmiHeader.biSizeImage;
	}

   pDataPacket->Duration = chan->GetTimePerFrame();

   DebugOut((1, "DataUsed = %d\n", pDataPacket->DataUsed));

   // [TMZ] [!!!] - hack, timestamping seems broken
   if( 0 ) {
   //if( hMasterClock ) {
      pDataPacket->OptionsFlags |= KSSTREAM_HEADER_OPTIONSF_DURATIONVALID;
      pDataPacket->OptionsFlags |= KSSTREAM_HEADER_OPTIONSF_TIMEVALID;
      //pDataPacket->OptionsFlags &= ~KSSTREAM_HEADER_OPTIONSF_TIMEVALID;

      HW_TIME_CONTEXT   TimeContext;

      TimeContext.HwDeviceExtension = (struct _HW_DEVICE_EXTENSION *)pSrb->HwDeviceExtension;
      TimeContext.HwStreamObject    = pSrb->StreamObject;
      TimeContext.Function          = TIME_GET_STREAM_TIME;

      StreamClassQueryMasterClockSync (
         chan->hMasterClock,
         &TimeContext
      );

      /*
      LARGE_INTEGER     Delta;

      Delta.QuadPart = TimeContext.Time;
      
      if( TimeContext.Time > (ULONGLONG) Delta.QuadPart )
      {
         pDataPacket->PresentationTime.Time = TimeContext.Time;
      } else {
         pDataPacket->PresentationTime.Time = 0;
      }
      */
      pDataPacket->PresentationTime.Time = TimeContext.Time;

   } else {
      pDataPacket->OptionsFlags &= ~KSSTREAM_HEADER_OPTIONSF_DURATIONVALID;
      pDataPacket->OptionsFlags &= ~KSSTREAM_HEADER_OPTIONSF_TIMEVALID;
      pDataPacket->PresentationTime.Time = 0;
   }

   // now gather the statistics
   PKS_FRAME_INFO pSavedFrameInfo = &((PSTREAMEX)chan->GetStrmEx())->FrameInfo.VideoFrameInfo;
   pSavedFrameInfo->ExtendedHeaderSize = sizeof( KS_FRAME_INFO );
   pSavedFrameInfo->PictureNumber++;
   pSavedFrameInfo->DropCount = 0;

   PKS_FRAME_INFO pFrameInfo =
   (PKS_FRAME_INFO) ( pSrb->CommandData.DataBufferArray + 1 );

   // copy the information to the outbound buffer
   pFrameInfo->ExtendedHeaderSize = pSavedFrameInfo->ExtendedHeaderSize;
   pFrameInfo->PictureNumber =      pSavedFrameInfo->PictureNumber;
   pFrameInfo->DropCount =          pSavedFrameInfo->DropCount;

   if ( pFrameInfo->DropCount ) {
      pSrb->CommandData.DataBufferArray->OptionsFlags |=
         KSSTREAM_HEADER_OPTIONSF_DATADISCONTINUITY;
   }

   // Every frame we generate is a key frame (aka SplicePoint)
   // Delta frames (B or P) should not set this flag

   pDataPacket->OptionsFlags |= KSSTREAM_HEADER_OPTIONSF_SPLICEPOINT;

   // make the stream class driver happy
   pSrb->Status = STATUS_SUCCESS;

   DebugOut((1, "*** 2 *** completing SRB %x\n", pSrb));
   CheckSrbStatus( pSrb );
   StreamClassStreamNotification( StreamRequestComplete, pSrb->StreamObject, pSrb );
   
   DebugOut((1, "Signal SRB - %x\n", pSrb->CommandData.DataBufferArray->Data ) );
   DebugOut((1, "********** NeedNotification_ = %d\n", chan->NeedNotification_ ) );

   if ( chan->NeedNotification_ ) {
      // queue was full; now it has at least one entry 
      StreamClassStreamNotification( ReadyForNextStreamDataRequest, pSrb->StreamObject );
   }
}

/* Method: VideoChannel::Interrupt
 * Purpose: Called by the interface class on behalf of capture chip to let know
 *   an interrupt happened.
 * Input: pTag: PVOID, to be passed to the Digitizer_
 * Output: None
 */
void VideoChannel::Interrupt( PVOID pTag, bool skipped )
{
   Trace t("VideoChannel::Interrupt()");

   Digitizer_->ProcessBufferAtInterrupt( pTag );

   if ( skipped ) {
      DebugOut((1, "VidChan::Interrupt skipped\n" ) );
      return;
   }
   // let the class driver know we are done with this buffer
   if ( !Requests_.IsEmpty() ) {
      PHW_STREAM_REQUEST_BLOCK pSrb = Requests_.Get();
      TimeStamp( pSrb ); // [TMZ] [!!!] [HACK]
   }
}

/* Method: VideoChannel::Create
 * Purpose: Creates the stream
 * Input: None
 * Output: None
 */
ErrorCode VideoChannel::Create()
{
   Trace t("VideoChannel::Create()");

	KS_VIDEOINFOHEADER* pVideoInfoHdr = NULL;
	KS_VIDEOINFOHEADER2* pVideoInfoHdr2 = NULL;

	DWORD				biCompression;
	WORD				biBitCount;
	LONG				biWidth;
	LONG				biHeight;
   LONG				biWidthBytes;

	if( IsVideoInfo2() )
	{
		pVideoInfoHdr2 = GetVidHdr2();
		biCompression = pVideoInfoHdr2->bmiHeader.biCompression;
		biBitCount = pVideoInfoHdr2->bmiHeader.biBitCount;   
		biWidth = pVideoInfoHdr2->bmiHeader.biWidth;      
		biHeight = abs(pVideoInfoHdr2->bmiHeader.biHeight);     
	}
	else
	{
		pVideoInfoHdr = GetVidHdr();
		biCompression = pVideoInfoHdr->bmiHeader.biCompression;
		biBitCount = pVideoInfoHdr->bmiHeader.biBitCount;   
		biWidth = pVideoInfoHdr->bmiHeader.biWidth;      
		biHeight = abs(pVideoInfoHdr->bmiHeader.biHeight);     
	}

   MRect analog( 0, 0, biWidth, biHeight );
   MRect ImageRect( 0, 0, biWidth, biHeight );

   DebugOut((1, "**************************************************************************\n"));
   DebugOut((1, "biCompression = %d\n", biCompression));
   DebugOut((1, "biBitCount = %d\n", biBitCount));

   if ( pVideoInfoHdr->bmiHeader.biCompression == 3)
	{
		if( IsVideoInfo2() )
		{
			pVideoInfoHdr2->bmiHeader.biCompression = FCC_YUY2;
			biCompression = FCC_YUY2;
		}
		else
		{
			pVideoInfoHdr->bmiHeader.biCompression = FCC_YUY2;
			biCompression = FCC_YUY2;
		}
	}

   ColorSpace tmp( biCompression, biBitCount );

   DebugOut((1, "ColorFormat = %d\n", tmp.GetColorFormat()));
   DebugOut((1, "**************************************************************************\n"));

   OurField_->ResetCounters();
   ResetCounters();
      
   // verify that we are not asked to produce a smaller image

   #ifdef HACK_FUDGE_RECTANGLES
	if( IsVideoInfo2() )
	{
      if( pVideoInfoHdr2->rcTarget.bottom == 0 ) 
		{
            // [!!!] [TMZ] - hack
            pVideoInfoHdr2->rcTarget.left    = 0;
            pVideoInfoHdr2->rcTarget.top     = 0;
            pVideoInfoHdr2->rcTarget.right   = biWidth;
            pVideoInfoHdr2->rcTarget.bottom  = biHeight;
      }
	}
	else
	{
      if( pVideoInfoHdr->rcTarget.bottom == 0 ) 
		{
            // [!!!] [TMZ] - hack
            pVideoInfoHdr->rcTarget.left    = 0;
            pVideoInfoHdr->rcTarget.top     = 0;
            pVideoInfoHdr->rcTarget.right   = biWidth;
            pVideoInfoHdr->rcTarget.bottom  = biHeight;
      }
	}
   #endif


   MRect		dst;
   MRect		src;
	if( IsVideoInfo2() )
	{
		dst.Set( pVideoInfoHdr2->rcTarget.left, pVideoInfoHdr2->rcTarget.top, pVideoInfoHdr2->rcTarget.right, pVideoInfoHdr2->rcTarget.bottom );
		src.Set( pVideoInfoHdr2->rcSource.left, pVideoInfoHdr2->rcSource.top, pVideoInfoHdr2->rcSource.right, pVideoInfoHdr2->rcSource.bottom );
	}
	else
	{
		dst.Set( pVideoInfoHdr->rcTarget.left, pVideoInfoHdr->rcTarget.top, pVideoInfoHdr->rcTarget.right, pVideoInfoHdr->rcTarget.bottom );
		src.Set( pVideoInfoHdr->rcSource.left, pVideoInfoHdr->rcSource.top, pVideoInfoHdr->rcSource.right, pVideoInfoHdr->rcSource.bottom );
	}
   if ( !dst.IsEmpty() ) 
	{
      // use the new size                                  
      ImageRect = dst;
      if ( !src.IsEmpty() )
		{
         analog = src;
		}
      else
		{
         analog = dst;
		}
      // calculate the offset for the new beginning of the data
      dwBufferOffset_ = dst.top * biWidth + dst.left * tmp.GetPitchBpp();
      // when rcTarget is non-empty, biWidth is stride of the buffer
      biWidthBytes = biWidth;
   } 
	else
	{
      biWidthBytes = biWidth * tmp.GetPitchBpp() / 8;
	}


	if( IsVideoInfo2() )
	{
		DebugOut((1, "pVideoInfoHdr2->rcTarget(%d, %d, %d, %d)\n", 
						  pVideoInfoHdr2->rcTarget.left, 
						  pVideoInfoHdr2->rcTarget.top, 
						  pVideoInfoHdr2->rcTarget.right, 
						  pVideoInfoHdr2->rcTarget.bottom
						  ));
	}
	else
	{
		DebugOut((1, "pVideoInfoHdr->rcTarget(%d, %d, %d, %d)\n", 
						  pVideoInfoHdr->rcTarget.left, 
						  pVideoInfoHdr->rcTarget.top, 
						  pVideoInfoHdr->rcTarget.right, 
						  pVideoInfoHdr->rcTarget.bottom
						  ));
	}
   DebugOut((1, "dst(%d, %d, %d, %d)\n", 
                 dst.left, 
                 dst.top, 
                 dst.right, 
                 dst.bottom
                 ));
   DebugOut((1, "Pitch =%d, width = %d\n", biWidthBytes, dst.Width() ) );

   SetBufPitch( biWidthBytes );

   if ( SetAnalogWindow ( analog  ) == Success && //<-must be set first !
        SetDigitalWindow( ImageRect ) == Success &&
        SetFormat( tmp.GetColorFormat() ) == Success &&
        Digitizer_->Create( *OurField_ ) == Success ) 
	{
      State_ = Created;
      return Success;
   }
   return Fail;
}

/* Method: VideoChannel::Start
 * Purpose: Starts the stream
 * Input: None
 * Output: None
 */
void VideoChannel::Start()
{
   Trace t("VideoChannel::Start()");
   State_ = Started;
   Digitizer_->Start( *OurField_ );
}

/* Method: VideoChannel::Stop
 * Purpose: Stops the stream
 * Input: None
 * Output: None
 */
ErrorCode VideoChannel::Stop()
{
   Trace t("VideoChannel::Stop()");

   if ( !IsOpen() )
      return Fail;

   Digitizer_->Stop( *OurField_ );
   State_ = Open;

   while( !BufQue_.IsEmpty( ) )
   {
      DataBuf buf = BufQue_.Get();
   }

   BufQue_.Flush();
   return Success;
}

/* Method: VideoChannel::Pause
 * Purpose: Stops the stream
 * Input: None
 * Output: None
 */
ErrorCode VideoChannel::Pause()
{
   Trace t("VideoChannel::Pause()");

   Digitizer_->Pause( *OurField_ );
   State_ = Paused;
   OurField_->ResetCounters();  // jaybo
   ResetCounters();
   return Success;
}

/* Method: VideoChanIface::Notify
 * Purpose:  Notifies the VideoChannel that an interrupt happened
 * Input: None
 * Output: None
 */
void VideoChanIface::Notify( PVOID pTag, bool skipped  )
{
   Trace t("VideoChanIface::Notify()");
   ToBeNotified_->Interrupt( pTag, skipped  );
}

/* Method: VideoChannel::AddSRB
 * Purpose: Adds SRB and buffer to the queues
 * Input: pSrb
 * Output: None
 */
void VideoChannel::AddSRB( PHW_STREAM_REQUEST_BLOCK pSrb )
{
   Trace t("VideoChannel::AddSRB()");

   Requests_.Put( pSrb );
   SetSRB( pSrb );

   PUCHAR pBufAddr = (PUCHAR)pSrb->CommandData.DataBufferArray->Data;
   AddBuffer( pBufAddr + dwBufferOffset_ );

   // don't forget to report our field type !
   // this cast is valid for VBI FRAME as well ( see ksmedia.h )
   PKS_FRAME_INFO pFrameInfo =
   (PKS_FRAME_INFO) ( pSrb->CommandData.DataBufferArray + 1 );
   pFrameInfo->dwFrameFlags = FieldType_;

   // ask for more buffers
   CheckNotificationNeed();
}

/* Method: VideoChannel::RemoveSRB
 * Purpose: Removes SRB from the queue and signals it
 * Input: pSrb
 * Output: None
 */

bool VideoChannel::RemoveSRB( PHW_STREAM_REQUEST_BLOCK pSrb )
{
   Trace t("VideoChannel::RemoveSRB()");

/*
	//FGR - TODO: i guess we should see if there really is a record of this SRB
   if(Requests_.IsEmpty()){
	   pSrb->Status = STATUS_CANCELLED;

      DebugOut((1, "*** 3 *** completing SRB %x\n", pSrb));
      CheckSrbStatus( pSrb );
      StreamClassStreamNotification( StreamRequestComplete, pSrb->StreamObject, pSrb );
      //StreamClassStreamNotification( ReadyForNextStreamDataRequest, pSrb->StreamObject );

	   return( true );
   }
*/

   int n = 0;
   
   n = Requests_.GetNumOfItems();
   DebugOut((1, "VideoChannel::RemoveSRB - Found %d SRBs in queue\n", n));

   bool bFound = false;

   // cycle through the list
   // pull from the head, put to the tail
   // if we find our pSrb during one cycle, pull it out

   while ( n-- > 0 ) // yes it can go negative
   {
      PHW_STREAM_REQUEST_BLOCK pTempSrb = Requests_.Get();
      if ( pTempSrb == pSrb )
      {
         // Pull him out
         if  ( bFound )
         {
            DebugOut((0, "Found pSrb(%x) in the queue more than once\n", pSrb));
            DEBUG_BREAKPOINT();
         }
         else
         {
            bFound = true;
   	      pSrb->Status = STATUS_CANCELLED;

            DebugOut((1, "*** 4 *** completing SRB %x\n", pSrb));
            CheckSrbStatus( pSrb );
            StreamClassStreamNotification( StreamRequestComplete, pSrb->StreamObject, pSrb );
            //StreamClassStreamNotification( ReadyForNextStreamDataRequest, pSrb->StreamObject );
         }
         n--;  // warning: if this is the last, it will go negative
      }
      else
      {
         Requests_.Put( pTempSrb );
      }
   }

   n = Requests_.GetNumOfItems();
   DebugOut((1, "VideoChannel::RemoveSRB - Left %d SRBs in queue, returning %d\n", n, bFound));

/*   
   PHW_STREAM_REQUEST_BLOCK InQueSRB = Requests_.PeekLeft();
   if ( InQueSRB == pSrb ) {

      InQueSRB = Requests_.Get();
      InQueSRB->Status = STATUS_CANCELLED;

      DebugOut((1, "Cancel SRB -%x\n", pSrb ) );

      CheckSrbStatus( pSrb );
      StreamClassStreamNotification( StreamRequestComplete,
         InQueSRB->StreamObject, InQueSRB );

      if ( Requests_.IsEmpty() )
         DebugOut((1, " queue is empty\n" ) );
      else
         DebugOut((1, "queue is not empty\n" ) );

	   return( true );

   } else {
//      DebugOut((1, "Cancelling wrong SRB ! - %x, %x\n", pSrb, InQueSRB ) );
//#ifdef	HAUPPAUGE
//	  TRAP();
//#endif
//   }
	   InQueSRB = Requests_.PeekRight();
	   if ( InQueSRB == pSrb ) {
		   InQueSRB = Requests_.GetRight();
		   InQueSRB->Status = STATUS_CANCELLED;
		   DebugOut((1, "Cancel SRB from right - %x\n", pSrb ) );
         CheckSrbStatus( pSrb );
		   StreamClassStreamNotification( StreamRequestComplete,
			   pSrb->StreamObject, pSrb );
	      return( true );
	   } else {
         DebugOut((0, "Cancelling wrong SRB from right too! - %x, %x\n", pSrb, InQueSRB ) );
	      return( false );
	   }
   }
*/
   return( bFound );
}

VideoChannel::~VideoChannel()
{
   Trace t("VideoChannel::~VideoChannel()");
   CloseChannel();
}

/* Method: VideoChannel::CheckNotificationNeed
 * Purpose: Sees if there is room for more buffers
 * Input: None
 * Output: None
 */
void VideoChannel::CheckNotificationNeed()
{
   Trace t("VideoChannel::CheckNotificationNeed()");

   if ( !BufQue_.IsFull() ) {
      // always hungry for more
      StreamClassStreamNotification( ReadyForNextStreamDataRequest, pSRB_->StreamObject );
      NeedNotification_ = false;
   } else
      NeedNotification_ = true;
}

/* Method: InterVideoChannel::Interrupt
 * Purpose: Processes the interrupt for the interleaved video streams
 * Input: pTag: PVOID - index in reality
 *   skipped: bool - indicates if buffer was written to
 * Output: None
 */
void InterVideoChannel::Interrupt( PVOID pTag, bool skipped )
{
   Trace t("InterVideoChannel::Interrupt()");

   int idx = (int)pTag;
   slave.IntNotify( PVOID( idx - ProgsWithinField ), skipped );
   Parent::Interrupt( pTag, skipped );
}

/* Method: InterVideoChannel::AddSRB
 * Purpose: Adds SRB to itself and dispatches 2 buffer pointers, one to each
 *   channel
 * Input: pSRB
 * Output: None
 */
void InterVideoChannel::AddSRB( PHW_STREAM_REQUEST_BLOCK pSrb )
{
   Trace t("InterVideoChannel::AddSRB()");

   PUCHAR pBufAddr = (PUCHAR)pSrb->CommandData.DataBufferArray->Data;
   // biWidth was set in Create()
   UINT biWidthBytes;
	if( IsVideoInfo2() )
	{
		biWidthBytes = VidHeader2_.bmiHeader.biWidth / 2;
	}
	else
	{
		biWidthBytes = VidHeader_.bmiHeader.biWidth / 2;
	}

   // to be used when adding buffer
   SetSRB( pSrb );
   slave.SetSRB( pSrb );

   // need to swap addresses for even/odd fields for RGB formats due to up-side-down bitmaps
   ColorSpace tmp( GetFormat() );
   if ( !( tmp.GetColorFormat() > CF_RGB8 && tmp.GetColorFormat() < CF_VBI ) ) 
	{
      // put buffer in its place
      // and adjusted address into the other channel
      slave.AddBuffer( pBufAddr + biWidthBytes );
      AddBuffer( pBufAddr );
   } 
	else 
	{
      slave.AddBuffer( pBufAddr );
      AddBuffer( pBufAddr + biWidthBytes );
   }

   // don't forget to add the SRB !
   Requests_.Put( pSrb );

   // set field type to full frame.
   PKS_FRAME_INFO pFrameInfo = (PKS_FRAME_INFO)( pSrb->CommandData.DataBufferArray + 1 );
   pFrameInfo->dwFrameFlags = KS_VIDEO_FLAG_FRAME;

   CheckNotificationNeed();
}

/* Function: SplitFrame
 * Purpose: Halfs the size of the video image so 2 fields can be used to create
 *   the original size
 * Input: VidHdr: KS_VIDEOINFOHEADER &
 * Output: None
 */
inline void  SplitFrame( KS_VIDEOINFOHEADER &VidHdr )
{
   Trace t("SplitFrame()");

   VidHdr.bmiHeader.biHeight /= 2;
   VidHdr.rcSource.top /= 2;
   VidHdr.rcTarget.top /= 2;
   VidHdr.rcSource.bottom /= 2;
   VidHdr.rcTarget.bottom /= 2;
}

inline void  SplitFrame2( KS_VIDEOINFOHEADER2 &VidHdr2 )
{
   Trace t("SplitFrame()");

   VidHdr2.bmiHeader.biHeight /= 2;
   VidHdr2.rcSource.top /= 2;
   VidHdr2.rcTarget.top /= 2;
   VidHdr2.rcSource.bottom /= 2;
   VidHdr2.rcTarget.bottom /= 2;
}


/* Method: InterVideoChannel::Create
 * Purpose: Sets the video parameters for the slave channel and
 *   calls into parent to create both
 * Input: None
 * Output: None
 */
ErrorCode InterVideoChannel::Create()
{
   Trace t("InterVideoChannel::Create()");

//   slave.SetInterrupt( false );
   slave.SetCallback( 0 );
   // restore the original as SplitFrame mangles the parameters

	MRect		dst;
	DWORD				biCompression;
	WORD				biBitCount;
   LONG				biWidthBytes;

	if( IsVideoInfo2() )
	{
		VidHeader2_ = OrigVidHeader2_;
		// split a frame into two fields
		SplitFrame2( VidHeader2_ );
		// double up the pitch, so we can interleave the buffers
		dst.Set( VidHeader2_.rcTarget.left, VidHeader2_.rcTarget.top, VidHeader2_.rcTarget.right, VidHeader2_.rcTarget.bottom );
		biCompression = VidHeader2_.bmiHeader.biCompression;
		biBitCount = VidHeader2_.bmiHeader.biBitCount;
	}
	else
	{
		VidHeader_ = OrigVidHeader_;
		// split a frame into two fields
		SplitFrame( VidHeader_ );
		// double up the pitch, so we can interleave the buffers
		dst.Set( VidHeader_.rcTarget.left, VidHeader_.rcTarget.top, VidHeader_.rcTarget.right, VidHeader_.rcTarget.bottom );
		biCompression = VidHeader_.bmiHeader.biCompression;
		biBitCount = VidHeader_.bmiHeader.biBitCount;
	}


   ColorSpace tmp( biCompression, biBitCount );

   if ( !dst.IsEmpty() ) 
	{
      // biWidth is the stride in bytes
		if( IsVideoInfo2() )
		{
			VidHeader2_.bmiHeader.biWidth *= 2 * 2;
			biWidthBytes = VidHeader2_.bmiHeader.biWidth;
		}
		else
		{
			VidHeader_.bmiHeader.biWidth *= 2 * 2;
			biWidthBytes = VidHeader_.bmiHeader.biWidth;
		}
   } 
	else 
	{
		if( IsVideoInfo2() )
		{
			// calculate the number of bytes per scan line
			biWidthBytes = tmp.GetPitchBpp() * VidHeader2_.bmiHeader.biWidth / 8;
			// can it be non-aligned ??
			biWidthBytes += 3;
			biWidthBytes &= ~3;

			// must be increased two times to interleave the fields;
			biWidthBytes *= 2;

			// the rcTarget uses half the original height and full width
			VidHeader2_.rcTarget = MRect(
				0, 
				0, 
				VidHeader2_.bmiHeader.biWidth,
				abs(VidHeader2_.bmiHeader.biHeight) 
			);

			DebugOut((1, "VidHeader2_.rcTarget(%d, %d, %d, %d)\n", 
							  VidHeader2_.rcTarget.left, 
							  VidHeader2_.rcTarget.top, 
							  VidHeader2_.rcTarget.right, 
							  VidHeader2_.rcTarget.bottom
							  ));

			// have to trick the slave into using correct ( doubled ) pitch
			VidHeader2_.bmiHeader.biWidth = biWidthBytes; // this is the pitch slave uses
		}
		else
		{
			// calculate the number of bytes per scan line
			biWidthBytes = tmp.GetPitchBpp() * VidHeader_.bmiHeader.biWidth / 8;
			// can it be non-aligned ??
			biWidthBytes += 3;
			biWidthBytes &= ~3;

			// must be increased two times to interleave the fields;
			biWidthBytes *= 2;

			// the rcTarget uses half the original height and full width
			VidHeader_.rcTarget = MRect(
				0, 
				0, 
				VidHeader_.bmiHeader.biWidth,
				abs(VidHeader_.bmiHeader.biHeight) 
			);

			DebugOut((1, "VidHeader_.rcTarget(%d, %d, %d, %d)\n", 
							  VidHeader_.rcTarget.left, 
							  VidHeader_.rcTarget.top, 
							  VidHeader_.rcTarget.right, 
							  VidHeader_.rcTarget.bottom
							  ));

			// have to trick the slave into using correct ( doubled ) pitch
			VidHeader_.bmiHeader.biWidth = biWidthBytes; // this is the pitch slave uses
		}
   }
   SetBufPitch( biWidthBytes );

	// at this point slave will have all the members set up properly
	if( IsVideoInfo2() )
	{
		slave.SetVidHdr2( VidHeader2_ );
	}
	else
	{
		slave.SetVidHdr( VidHeader_ );
	}
   slave.SetPaired( true );

   // needed for full-size YUV9 and other planar modes
   Digitizer_->SetPlanarAdjust( biWidthBytes / 2 );

   return Parent::Create();
}

/* Method: VideoChannel::GetStreamType
 * Purpose: reports back type of the stream. Used when destroying channels
 */
StreamType VideoChannel::GetStreamType()
{
   Trace t("VideoChannel::GetStreamType()");
   return Single;
}

/* Method: VideoChannel::TimeStampVBI
 * Purpose: Performs the standard buffer massaging when it's done
 * Input: pSrb
 * Output: None
 */
void STREAMAPI VideoChannel::TimeStampVBI( PHW_STREAM_REQUEST_BLOCK pSrb )
{
   Trace t("VideoChannel::TimeStamp()");

   PKSSTREAM_HEADER  pDataPacket = pSrb->CommandData.DataBufferArray;
   VideoChannel *chan = (VideoChannel *)((PSTREAMEX)pSrb->StreamObject->HwStreamExtension)->videochannel;

   pDataPacket->PresentationTime.Numerator = 1;
   pDataPacket->PresentationTime.Denominator = 1;

	if( chan->IsVideoInfo2() )
	{
		pDataPacket->DataUsed = chan->GetVidHdr2()->bmiHeader.biSizeImage;
	}
	else
	{
		pDataPacket->DataUsed = chan->GetVidHdr()->bmiHeader.biSizeImage;
	}

   pDataPacket->Duration = chan->GetTimePerFrame();

   DebugOut((1, "DataUsed = %d\n", pDataPacket->DataUsed));

   // [TMZ] [!!!] - hack, timestamping seems broken
   if( 0 ) {
   //if( hMasterClock ) {
      pDataPacket->OptionsFlags |= KSSTREAM_HEADER_OPTIONSF_DURATIONVALID;
      pDataPacket->OptionsFlags |= KSSTREAM_HEADER_OPTIONSF_TIMEVALID;
      //pDataPacket->OptionsFlags &= ~KSSTREAM_HEADER_OPTIONSF_TIMEVALID;

      HW_TIME_CONTEXT   TimeContext;

      TimeContext.HwDeviceExtension = (struct _HW_DEVICE_EXTENSION *)pSrb->HwDeviceExtension;
      TimeContext.HwStreamObject    = pSrb->StreamObject;
      TimeContext.Function          = TIME_GET_STREAM_TIME;

      StreamClassQueryMasterClockSync (
         chan->hMasterClock,
         &TimeContext
      );

      /*
      LARGE_INTEGER     Delta;

      Delta.QuadPart = TimeContext.Time;
      
      if( TimeContext.Time > (ULONGLONG) Delta.QuadPart )
      {
         pDataPacket->PresentationTime.Time = TimeContext.Time;
      } else {
         pDataPacket->PresentationTime.Time = 0;
      }
      */
      pDataPacket->PresentationTime.Time = TimeContext.Time;

   } else {
      pDataPacket->OptionsFlags &= ~KSSTREAM_HEADER_OPTIONSF_DURATIONVALID;
      pDataPacket->OptionsFlags &= ~KSSTREAM_HEADER_OPTIONSF_TIMEVALID;
      pDataPacket->PresentationTime.Time = 0;
   }

   PKS_VBI_FRAME_INFO pSavedFrameInfo = &((PSTREAMEX)chan->GetStrmEx())->FrameInfo.VbiFrameInfo;
   pSavedFrameInfo->ExtendedHeaderSize = sizeof( PKS_VBI_FRAME_INFO );
   pSavedFrameInfo->PictureNumber++;
   pSavedFrameInfo->DropCount = 0;

   // now gather the statistics
   PKS_VBI_FRAME_INFO pFrameInfo =
   (PKS_VBI_FRAME_INFO) ( pSrb->CommandData.DataBufferArray + 1 );

   // copy the information to the outbound buffer
   pFrameInfo->ExtendedHeaderSize = pSavedFrameInfo->ExtendedHeaderSize;
   pFrameInfo->PictureNumber =      pSavedFrameInfo->PictureNumber;
   pFrameInfo->DropCount =          pSavedFrameInfo->DropCount;

   pFrameInfo->dwSamplingFrequency = VBISampFreq; // Bug - changes with video format

   if ( ((VBIChannel*)(chan))->Dirty_ ) { // propagate the tv tuner change notification
      ((VBIChannel*)(chan))->Dirty_ = false;
      pFrameInfo->TvTunerChangeInfo = ((VBIChannel*)(chan))->TVTunerChangeInfo_;
      pFrameInfo->dwFrameFlags      |= KS_VBI_FLAG_TVTUNER_CHANGE;
      pFrameInfo->VBIInfoHeader     = ((VBIChannel*)(chan))->VBIInfoHeader_;
      pFrameInfo->dwFrameFlags      |= KS_VBI_FLAG_VBIINFOHEADER_CHANGE ;
   } else {
      pFrameInfo->dwFrameFlags &= ~KS_VBI_FLAG_TVTUNER_CHANGE;
      pFrameInfo->dwFrameFlags &= ~KS_VBI_FLAG_VBIINFOHEADER_CHANGE;
   }

   if ( pFrameInfo->DropCount ) {
      pSrb->CommandData.DataBufferArray->OptionsFlags |=
         KSSTREAM_HEADER_OPTIONSF_DATADISCONTINUITY;
   }

    // Every frame we generate is a key frame (aka SplicePoint)
    // Delta frames (B or P) should not set this flag

    pDataPacket->OptionsFlags |= KSSTREAM_HEADER_OPTIONSF_SPLICEPOINT;

   // make the stream class driver happy
   pSrb->Status = STATUS_SUCCESS;

   DebugOut((1, "*** 5 *** completing SRB %x\n", pSrb));
   CheckSrbStatus( pSrb );
   StreamClassStreamNotification( StreamRequestComplete, pSrb->StreamObject, pSrb );

   DebugOut((1, "Signal SRB - %x\n", pSrb->CommandData.DataBufferArray->Data ) );

   DebugOut((1, "********** NeedNotification_ = %d\n", chan->NeedNotification_ ) );

   if ( chan->NeedNotification_ ) {
      // queue was full; now it has at least one entry 
      StreamClassStreamNotification( ReadyForNextStreamDataRequest,
         pSrb->StreamObject );
   }
}

/* Method: VBIAlterChannel::Interrupt
 * Purpose: Processes the interrupt for the VBI channel
 */
void VBIChannel::Interrupt( PVOID pTag, bool skipped )
{
   Trace t("VBIChannel::Interrupt()");

   if ( Requests_.IsEmpty( ) )
   {
      DebugOut((1, "VBI interrupt, but Requests_ is empty\n"));
      return;
   }

   // save the SRB for further processing ( it is gone from the qu in the Parent::Interrupt
   PHW_STREAM_REQUEST_BLOCK pSrb = Requests_.PeekLeft();

   // Parent::Interrupt( pTag, skipped );
   {
      Digitizer_->ProcessBufferAtInterrupt( pTag );

      if ( skipped ) {
         DebugOut((1, "VidChan::Interrupt skipped\n" ) );
         return;
      }
      // let the class driver know we are done with this buffer
      if ( !Requests_.IsEmpty() ) {
         PHW_STREAM_REQUEST_BLOCK pTimeSrb = Requests_.Get();
         TimeStampVBI( pTimeSrb ); // [TMZ] [!!!]
      }
   }
}

/* Method: VBIChannel::ChangeNotification
 * Purpose: Called to save off the tv tuner change notification
 * Input: pSrb
 */
void VBIChannel::ChangeNotification( PHW_STREAM_REQUEST_BLOCK pSrb )
{
   Trace t("VBIChannel::ChangeNotification()");

   const KSSTREAM_HEADER &DataPacket = *pSrb->CommandData.DataBufferArray;
   RtlCopyMemory( &TVTunerChangeInfo_, DataPacket.Data, sizeof( KS_TVTUNER_CHANGE_INFO ) );
   Dirty_ = true;
}

/* Method: VideoChannel::ChangeNotification
 * Purpose: Noop for the base class.
 */
void VideoChannel::ChangeNotification( PHW_STREAM_REQUEST_BLOCK )
{
   Trace t("VideoChannel::ChangeNotification()");
}

/* Method: VBIAlterChannel::SetVidHdr
 * Purpose: Transforms the VBI parameters ( size ) into regular video header
 * Input:
 */
void VBIAlterChannel::SetVidHdr( const KS_DATAFORMAT_VBIINFOHEADER &df )
{
   Trace t("VBIAlterChannel::SetVidHdr()");

   // save for the history ( for the interrupt, actually )
   SetVBIInfHdr( df.VBIInfoHeader );
   (*(VBIChannel*)&slave).SetVBIInfHdr( df.VBIInfoHeader );
   
   KS_VIDEOINFOHEADER VidInfHdr;
   RtlZeroMemory( &VidInfHdr, sizeof( VidInfHdr ) );

   // create a regular video info header
   VidInfHdr.bmiHeader.biWidth = VBISamples;
   VidInfHdr.bmiHeader.biHeight =
      df.VBIInfoHeader.EndLine - df.VBIInfoHeader.StartLine + 1; // inclusive
   // taken from the VBI GUID
   VidInfHdr.bmiHeader.biCompression = FCC_VBI;
   VidInfHdr.bmiHeader.biBitCount = 8;

   // this is very important too
   VidInfHdr.bmiHeader.biSizeImage =
      VidInfHdr.bmiHeader.biWidth * VidInfHdr.bmiHeader.biHeight;

   // now handle the case when stride is larger than width ( have to set the
   // target rectangle )
   if ( df.VBIInfoHeader.StrideInBytes > VBISamples ) {
      VidInfHdr.rcTarget.right  = df.VBIInfoHeader.StrideInBytes;
      VidInfHdr.rcTarget.bottom = VidInfHdr.bmiHeader.biHeight;
   }

   // the Parent::Create will take care of setting vid header for the slave
   Parent::SetVidHdr( VidInfHdr );
}

//??? TODO: -- is this needed?
void VBIAlterChannel::SetVidHdr2( const KS_DATAFORMAT_VBIINFOHEADER &df )
{
   Trace t("VBIAlterChannel::SetVidHdr2()");

   // save for the history ( for the interrupt, actually )
   SetVBIInfHdr( df.VBIInfoHeader );
   
   KS_VIDEOINFOHEADER2 VidInfHdr;
   RtlZeroMemory( &VidInfHdr, sizeof( VidInfHdr ) );

   // create a regular video info header
   VidInfHdr.bmiHeader.biWidth = VBISamples;
   VidInfHdr.bmiHeader.biHeight =
      df.VBIInfoHeader.EndLine - df.VBIInfoHeader.StartLine + 1; // inclusive
   // taken from the VBI GUID
   VidInfHdr.bmiHeader.biCompression = FCC_VBI;
   VidInfHdr.bmiHeader.biBitCount = 8;

   // this is very important too
   VidInfHdr.bmiHeader.biSizeImage =
      VidInfHdr.bmiHeader.biWidth * VidInfHdr.bmiHeader.biHeight;

   // now handle the case when stride is larger than width ( have to set the
   // target rectangle )
   if ( df.VBIInfoHeader.StrideInBytes > VBISamples ) {
      VidInfHdr.rcTarget.right  = df.VBIInfoHeader.StrideInBytes;
      VidInfHdr.rcTarget.bottom = VidInfHdr.bmiHeader.biHeight;
   }

   // the Parent::Create will take care of setting vid header for the slave
   Parent::SetVidHdr2( VidInfHdr );
}
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\drivers\wdm\capture\mini\bt848\vidch.h ===
// $Header: G:/SwDev/WDM/Video/bt848/rcs/Vidch.h 1.14 1998/05/11 23:59:58 tomz Exp $

#ifndef __VXDVIDCH_H
#define __VXDVIDCH_H

extern "C" {
   #include "strmini.h"
   #include "ksmedia.h"
}

#include "mytypes.h"
#include "pisces.h"
#include "vidchifc.h"

typedef enum  { Closed, Open, Created, Started, Paused } StreamState;
typedef enum { Single, Paired } StreamType;
void GetRequestedSize2( const KS_VIDEOINFOHEADER2 &vidHdr, MSize &size );
void GetRequestedSize( const KS_VIDEOINFOHEADER &vidHdr, MSize &size );

extern PHW_STREAM_REQUEST_BLOCK StreamIdxToSrb[];

/* Class: VideoChannel
 * Purpose: The base class to be used in the BtPisces capture VxD. Used for
 *   processing user requests ( comes from the device class, goes to capture
 *   chip class )
 * Attributes:
 * Methods
 */
class VideoChannel
{
   protected:

      BtPisces  *Digitizer_;

      SRBQueue  Requests_;

      KS_VIDEOINFOHEADER        VidHeader_;
      KS_VIDEOINFOHEADER2        VidHeader2_;
      // this seems to be the most convenient place for the original copy
      // other option is to make SetVidHdr() virtual and move this member into
      // the PairedChannels
      KS_VIDEOINFOHEADER        OrigVidHeader_;
      KS_VIDEOINFOHEADER2        OrigVidHeader2_;

		BOOL					m_bIsVideoInfo2;

      DWORD               FieldType_;
      VidBufQueue         BufQue_;

      VideoChanIface      Caller_;

      DWORD               dwBufferOffset_;

      HANDLE              hMasterClock;

      KSSTATE             KSState_;

      LONG                TimePerFrame_;

      VideoStream         Stream_;
      Field              *OurField_;

      StreamState         State_;
      bool                NeedNotification_;

      virtual  void Interrupt( PVOID pTag, bool skipped );
               void CheckNotificationNeed();

      static void STREAMAPI TimeStamp( PHW_STREAM_REQUEST_BLOCK pSrb );
      static void STREAMAPI TimeStampVBI( PHW_STREAM_REQUEST_BLOCK pSrb );

      PVOID pStrmEx_; 

   public:

      PHW_STREAM_REQUEST_BLOCK  pSRB_;

#ifdef ENABLE_DDRAW_STUFF
	// Kernel DDraw interface
	BOOL                        bKernelDirectDrawRegistered;
	HANDLE                      hUserDirectDrawHandle;       // DD itself
	HANDLE                      hKernelDirectDrawHandle;
	BOOL                        bPreEventOccurred;
	BOOL                        bPostEventOccurred;
#endif


		BOOL	IsVideoInfo2() { return m_bIsVideoInfo2; }
      PVOID GetStrmEx() 
      {
         DEBUG_ASSERT(pStrmEx_ != 0);
         return pStrmEx_;
      }
      VOID SetStrmEx(PVOID pv) 
      {
         DEBUG_ASSERT(pv != 0);
         pStrmEx_ = pv;
      }
      
      BOOL bIsVBI();
      BOOL bIsVideo();

      VOID ResetCounters();

      virtual ErrorCode OpenChannel();
      virtual ErrorCode CloseChannel();
      virtual ErrorCode SetFormat( ColFmt );
              ColFmt    GetFormat();
      virtual ErrorCode SetDigitalWindow( MRect &r );
      virtual ErrorCode SetAnalogWindow( MRect &r );
      virtual ErrorCode Create();
      virtual void      Start();
      virtual ErrorCode Stop();
      virtual ErrorCode Pause();

              StreamState GetState();
              KSSTATE     GetKSState();
              void        SetKSState( KSSTATE st );
                    
              VideoStream GetStreamID();

              void        SetClockMaster( HANDLE h );
              
              //LONGLONG    GetFramesNo();
              
              LONG      GetTimePerFrame();
              void      SetTimePerFrame( LONG time );

              void      SetInterrupt( bool state );
              void      SetCallback( ChanIface *cb );

      virtual StreamType GetStreamType();

      virtual  void AddSRB( PHW_STREAM_REQUEST_BLOCK pSrb );
      virtual  bool RemoveSRB( PHW_STREAM_REQUEST_BLOCK pSrb );
      virtual  void ChangeNotification( PHW_STREAM_REQUEST_BLOCK pSrb );

      virtual void AddBuffer( PVOID );

              void SetSRB( PHW_STREAM_REQUEST_BLOCK srb );
              PHW_STREAM_REQUEST_BLOCK GetSRB();

              void SetVidHdr( const KS_VIDEOINFOHEADER &rVidHdr );
              void SetVidHdr2( const KS_VIDEOINFOHEADER2 &rVidHdr );
              PKS_VIDEOINFOHEADER GetVidHdr();
              KS_VIDEOINFOHEADER2* GetVidHdr2();

              void SetBufPitch( DWORD dwP );

              void  SetDefaultQue()
              { Digitizer_->SetBufQuePtr( *OurField_, &BufQue_ ); }

              void SetPaired( bool p = false );

              void IntNotify( PVOID pTag, bool skipped );

              bool IsOpen();
              void SetOpen();
              void SetClose();

      void Init( BtPisces *const pCapChip );

      VideoChannel( VideoStream aStrm );
      virtual ~VideoChannel();

      friend class VideoChanIface;

      // placement new
      void *operator new( size_t, void *buf ) { return buf; }
      void operator delete( void *, size_t ) {}
};

/* Class: PairedVideoChannels
 * Purpose: Implements basic functionality of paired video channels
 */
template <class ParentChan>
class PairedVideoChannels : public ParentChan
{
   typedef ParentChan Parent;
   public:
      VideoChannel &slave;

      PairedVideoChannels( VideoStream st, VideoChannel &chan );

      virtual ErrorCode Create();
      virtual void      Start();
      virtual ErrorCode Stop();
      virtual ErrorCode Pause();

      virtual StreamType GetStreamType();
};

template <class ParentChan>
inline PairedVideoChannels<ParentChan>::PairedVideoChannels( VideoStream st, VideoChannel &chan )
   : ParentChan( st ), slave( chan )
{}

/* Class: InterVideoChannel
 * Purpose: The base class to be used in the BtPisces capture VxD. Used for
 *   processing user requests ( comes from the device class, goes to capture
 *   chip class )
 * Attributes:
 * Methods
 */
class InterVideoChannel : public PairedVideoChannels<VideoChannel>
{
   typedef PairedVideoChannels<VideoChannel> Parent;

   public:
      virtual ErrorCode Create();
      virtual void      AddSRB( PHW_STREAM_REQUEST_BLOCK pSrb );
      InterVideoChannel( VideoStream aStrm, VideoChannel &chan );
      virtual  void Interrupt( PVOID pTag, bool skipped );
};

inline InterVideoChannel::InterVideoChannel( VideoStream aStrm, VideoChannel &chan )
   : Parent( aStrm, chan )
{}

/* Class: AlterVideoChannel
 * Purpose: The base class to be used in the BtPisces capture VxD. Used for
 *   processing user requests ( comes from the device class, goes to capture
 *   chip class )
 * Attributes:
 * Methods
 */
template <class ParentChan>
class AlterVideoChannel : public PairedVideoChannels<ParentChan>
{
   typedef PairedVideoChannels<ParentChan> Parent;

   int toggle_;

   public:
      virtual ErrorCode Create();
      virtual void      AddSRB( PHW_STREAM_REQUEST_BLOCK pSrb );
      virtual  bool     RemoveSRB( PHW_STREAM_REQUEST_BLOCK pSrb );
      AlterVideoChannel( VideoStream aStrm, VideoChannel &chan );
};

/* Class: VBIChannel
 * Purpose: Implements functionality for the VBI field
 */
class VBIChannel : public VideoChannel
{
   typedef VideoChannel Parent;

   // Channel Change information

   public:
      bool  Dirty_;
      KS_TVTUNER_CHANGE_INFO   TVTunerChangeInfo_;
      KS_VBIINFOHEADER         VBIInfoHeader_;

      virtual  void Interrupt( PVOID pTag, bool skipped );
      virtual  void ChangeNotification( PHW_STREAM_REQUEST_BLOCK pSrb );
      VBIChannel( VideoStream aStrm );
      void SetVBIInfHdr( const KS_VBIINFOHEADER &vbiHdr );
};

/* Class: VBIAlterChannel
 * Purpose: Implements alternating VBI fields
 */

class VBIAlterChannel : public AlterVideoChannel<VBIChannel>
{
   typedef AlterVideoChannel<VBIChannel> Parent;

   public:
      void SetVidHdr( const KS_DATAFORMAT_VBIINFOHEADER &df );
      void SetVidHdr2( const KS_DATAFORMAT_VBIINFOHEADER &df );
      VBIAlterChannel( VideoStream aStrm, VBIChannel &chan );
};

inline VBIChannel::VBIChannel( VideoStream aStrm ) : VideoChannel( aStrm ),
   Dirty_( false )
{}

inline void DumpVbiInfoHeader( const KS_VBIINFOHEADER &vbiHdr )
{
   // typedef struct tagKS_VBIINFOHEADER {
   //     ULONG       StartLine;              // inclusive
   //     ULONG       EndLine;                // inclusive
   //     ULONG       SamplingFrequency;      // Hz.
   //     ULONG       MinLineStartTime;       // microSec * 100 from HSync LE
   //     ULONG       MaxLineStartTime;       // microSec * 100 from HSync LE
   //     ULONG       ActualLineStartTime;    // microSec * 100 from HSync LE
   //     ULONG       ActualLineEndTime;      // microSec * 100 from HSync LE
   //     ULONG       VideoStandard;          // KS_AnalogVideoStandard*
   //     ULONG       SamplesPerLine;
   //     ULONG       StrideInBytes;          // May be > SamplesPerLine
   //     ULONG       BufferSize;             // Bytes
   // } KS_VBIINFOHEADER, *PKS_VBIINFOHEADER;

   DebugOut((0, "KS_VBIINFOHEADER at address %x\n", &vbiHdr));
   DUMP(vbiHdr.StartLine);
   DUMP(vbiHdr.EndLine);
   DUMP(vbiHdr.SamplingFrequency);
   DUMP(vbiHdr.MinLineStartTime);
   DUMP(vbiHdr.MaxLineStartTime);
   DUMP(vbiHdr.ActualLineStartTime);
   DUMP(vbiHdr.ActualLineEndTime);
   DUMP(vbiHdr.VideoStandard);
   DUMP(vbiHdr.SamplesPerLine);
   DUMP(vbiHdr.StrideInBytes);
   DUMP(vbiHdr.BufferSize);
}
inline void VBIChannel::SetVBIInfHdr( const KS_VBIINFOHEADER &vbiHdr )
{
   VBIInfoHeader_ = vbiHdr;
}

inline VBIAlterChannel::VBIAlterChannel( VideoStream aStrm, VBIChannel &chan )
   : AlterVideoChannel<VBIChannel>( aStrm, chan )
{}

template <class ParentChan>
inline AlterVideoChannel<ParentChan>::AlterVideoChannel( VideoStream aStrm, VideoChannel &chan )
   : Parent( aStrm, chan ), toggle_( 0 )
{}

inline void VideoChannel::SetSRB( PHW_STREAM_REQUEST_BLOCK srb )
{
   pSRB_ = srb;
}


/* Method: AlterVideoChannel::AddSRB
 * Purpose: This method dispatches the SRB to the next appropriate channel
 * Input: pSrb:
 */
template <class ParentChan>
void AlterVideoChannel<ParentChan>::AddSRB( PHW_STREAM_REQUEST_BLOCK pSrb )
{
   if ( !toggle_ ) {
      // first buffer goes to the slave channel as it comes out of the
      // decoder first
      DebugOut((1, "slave.AddSRB(%x)\n", pSrb));
      slave.AddSRB( pSrb );
   } else {
      DebugOut((1, "parent.AddSRB(%x)\n", pSrb));
      Parent::AddSRB( pSrb );
   }
   toggle_++;
   toggle_ %= 2;
}

/* Method: AlterVideoChannel::RemoveSRB
 * Purpose: Just calls into each channel in hope one of them will find the SRB
 * Input: pSRB
 * Output: None
 */
template <class ParentChan>
bool AlterVideoChannel<ParentChan>::RemoveSRB( PHW_STREAM_REQUEST_BLOCK pSrb )
{
   // one or the other will pick it up
   
   bool b1 = slave.RemoveSRB( pSrb );
   bool b2 = Parent::RemoveSRB( pSrb );

   if( !b1 && !b2 )
   {
      DebugOut((1, "AlterVideoChannel<ParentChan>::RemoveSRB - RemoveSRB failed\n"));
   }
   return ( b1 || b2 );
}

/* Method: AlterVideoChannel::Create
 * Purpose: Sets the slave video params and calls into parent to do the work
 * Input: pSRB
 * Output: None
 */
template <class ParentChan>
ErrorCode AlterVideoChannel<ParentChan>::Create()
{
   slave.SetVidHdr( VidHeader_ );
   return Parent::Create();
}

inline PHW_STREAM_REQUEST_BLOCK VideoChannel::GetSRB()
{
   return pSRB_;
}

inline void DumpVideoInfoHeader(const KS_VIDEOINFOHEADER &rVidHdr)
{
   DebugOut((0, "-----------------------------------------\n"));
   DebugOut((0, "setting KS_VIDEOINFOHEADER\n"));
   DebugOut((0, "-----------------------------------------\n"));
   DebugOut((0, "rcSource (%d,%d,%d,%d)\n",
      rVidHdr.rcSource.left, 
      rVidHdr.rcSource.top,
      rVidHdr.rcSource.right, 
      rVidHdr.rcSource.bottom));

   DebugOut((0, "rcTarget (%d,%d,%d,%d)\n",
      rVidHdr.rcTarget.left, 
      rVidHdr.rcTarget.top,
      rVidHdr.rcTarget.right, 
      rVidHdr.rcTarget.bottom));

   DebugOut((0, "dwBitRate (%u)\n", rVidHdr.dwBitRate));
   DebugOut((0, "dwBitErrorRate (%u)\n", rVidHdr.dwBitErrorRate));
   DebugOut((0, "bmiHeader\n"));
   DebugOut((0, "   biSize (%d)\n", rVidHdr.bmiHeader.biSize));
   DebugOut((0, "   biWidth (%d)\n", rVidHdr.bmiHeader.biWidth));
   DebugOut((0, "   biHeight (%d)\n", rVidHdr.bmiHeader.biHeight));
   DebugOut((0, "   biPlanes (%d)\n", rVidHdr.bmiHeader.biPlanes));
   DebugOut((0, "   biBitCount (%d)\n", rVidHdr.bmiHeader.biBitCount));
   DebugOut((0, "   biCompression (%d)\n", rVidHdr.bmiHeader.biCompression));
   DebugOut((0, "   biSizeImage (%d)\n", rVidHdr.bmiHeader.biSizeImage));
   DebugOut((0, "   biXPelsPerMeter (%d)\n", rVidHdr.bmiHeader.biXPelsPerMeter));
   DebugOut((0, "   biYPelsPerMeter (%d)\n", rVidHdr.bmiHeader.biYPelsPerMeter));
   DebugOut((0, "   biClrUsed (%d)\n", rVidHdr.bmiHeader.biClrUsed));
   DebugOut((0, "   biClrImportant (%d)\n", rVidHdr.bmiHeader.biClrImportant));
}

inline void VideoChannel::SetVidHdr( const KS_VIDEOINFOHEADER &rVidHdr )
{
   // DumpVideoInfoHeader(rVidHdr);

	m_bIsVideoInfo2 = FALSE;
   VidHeader_ = rVidHdr;
   // save this for paired channels
   OrigVidHeader_ = rVidHdr;
}
                                   
inline void VideoChannel::SetVidHdr2( const KS_VIDEOINFOHEADER2 &rVidHdr )
{
   // DumpVideoInfoHeader(rVidHdr);

	m_bIsVideoInfo2 = TRUE;
   VidHeader2_ = rVidHdr;
   // save this for paired channels
   OrigVidHeader2_ = rVidHdr;
}
                                   
inline PKS_VIDEOINFOHEADER VideoChannel::GetVidHdr()
{
   return &VidHeader_;
}

inline KS_VIDEOINFOHEADER2* VideoChannel::GetVidHdr2()
{
   return &VidHeader2_;
}

inline void VideoChannel::SetBufPitch( DWORD dwP )
{
   Digitizer_->SetBufPitch( dwP, *OurField_ );
}

inline bool VideoChannel::IsOpen()
{
   return State_ >= Open;
}

inline void VideoChannel::SetOpen()
{
   State_ = Open;
}

inline void VideoChannel::SetClose()
{
   State_ = Closed;
}

inline void VideoChannel::Init( BtPisces *const pCapChip )
{
   Digitizer_ = pCapChip;
}

inline StreamState VideoChannel::GetState()
{
    return State_;
}

inline VideoStream VideoChannel::GetStreamID()
{
   return OurField_->GetStreamID();
}

inline void VideoChannel::SetPaired( bool p )
{
   OurField_->SetPaired( p );
}

inline void VideoChannel::SetClockMaster( HANDLE h )
{
   DebugOut((1, "SetClockMaster(%x)\n", h ));
   hMasterClock = h;
}

inline KSSTATE VideoChannel::GetKSState()
{
   return KSState_;
}

inline void    VideoChannel::SetKSState( KSSTATE st )
{
   KSState_ = st;
}

#if 0
inline LONGLONG VideoChannel::GetFramesNo()
{
   LONGLONG PicNumber, DropCnt;
   OurField_->GetCounters( PicNumber, DropCnt );
   return PicNumber;
}
#endif

inline LONG VideoChannel::GetTimePerFrame()
{
   return OurField_->GetStandardTiming();
}

inline void VideoChannel::SetTimePerFrame( LONG time )
{
   TimePerFrame_ = time;
   OurField_->SetStandardTiming( time );
}

inline void VideoChannel::IntNotify( PVOID pTag, bool skipped )
{
   Caller_.Notify( pTag, skipped );
}

inline void VideoChannel::SetInterrupt( bool state )
{
   OurField_->Interrupt_ = state;
}

inline void VideoChannel::SetCallback( ChanIface *cb )
{
   OurField_->SetCallback( cb );
}

#ifdef _MSC_VER
#pragma warning(disable:4355)
#endif
inline VideoChannel::VideoChannel( VideoStream aStrm ) :
   NeedNotification_( false ), BufQue_(), Caller_( this ), Stream_( aStrm ),
   OurField_( NULL ), State_( Closed ), pSRB_( NULL ), VidHeader_(), Requests_(),
   dwBufferOffset_( 0 ), hMasterClock( NULL ), TimePerFrame_( 333667 )
{
	m_bIsVideoInfo2 = FALSE;

#ifdef ENABLE_DDRAW_STUFF
	bKernelDirectDrawRegistered = FALSE;
	hUserDirectDrawHandle = NULL;    
	hKernelDirectDrawHandle = NULL;
	bPreEventOccurred = FALSE;
	bPostEventOccurred = FALSE;
#endif

   // VS_Field1 is defined as 0
   FieldType_ = aStrm & 0x01 ? KS_VIDEO_FLAG_FIELD2 : KS_VIDEO_FLAG_FIELD1;
}

template <class ParentChan>
StreamType PairedVideoChannels<ParentChan>::GetStreamType()
{
   return Paired;
}

/* Method: PairedVideoChannel::Create
 * Purpose: Creates both streams
 * Input: None
 * Output: None
 */
template <class ParentChan>
ErrorCode PairedVideoChannels<ParentChan>::Create()
{
   if ( slave.Create() == Success ) {
      Digitizer_->SetPlanarAdjust( 0 );
      return Parent::Create();
   }
   return Fail;
}

/* Method: PairedVideoChannels::Start
 * Purpose: Starts both channels
 * Input: None
 * Output: None
 */
template <class ParentChan>
void PairedVideoChannels<ParentChan>::Start()
{
   slave.Start();
   Parent::Start();
}

/* Method: PairedVideoChannels::Stop
 * Purpose: Stops both channels
 * Input: None
 * Output: None
 */
template <class ParentChan>
ErrorCode PairedVideoChannels<ParentChan>::Stop()
{
   slave.Stop();
   Parent::Stop();
   return Success;
}

/* Method: PairedVideoChannels::Pause
 * Purpose: Pauses both channels
 * Input: None
 * Output: None
 */
template <class ParentChan>
ErrorCode PairedVideoChannels<ParentChan>::Pause()
{
   if ( bIsVBI() )
   {
      Digitizer_->PairedPause( (VBIEStartLocation + DistBetweenProgs) );
   }
   else
   {
      Digitizer_->PairedPause( (EvenStartLocation + DistBetweenProgs) );
   }
   State_ = Paused;
   return Success;
}

#endif __VXDVIDCH_H
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\drivers\wdm\capture\mini\bt848\viddefs.h ===
// $Header: G:/SwDev/WDM/Video/bt848/rcs/Viddefs.h 1.3 1998/04/29 22:43:42 tomz Exp $

#ifndef __VIDDEFS_H
#define __VIDDEFS_H


/* Type: Connector
 * Purpose: Defines a video source
 */
typedef enum { ConSVideo = 1, ConTuner, ConComposite } Connector;


/* Type: State
 * Purpose: used to define on-off operations
 */
typedef enum { Off, On } State;

/* Type: Field
 * Purpose: defines fields
 */
typedef enum { VF_Both, VF_Even, VF_Odd } VidField;

/* Type: VideoFormat
 * Purpose: Used to define video format
 */
typedef enum {  VFormat_AutoDetect,
                VFormat_NTSC,
                VFormat_Reserved2,
                VFormat_PAL_BDGHI,
                VFormat_PAL_M,
                VFormat_PAL_N,
                VFormat_SECAM } VideoFormat;

/* Type: LumaRange
 * Purpose: Used to define Luma Output Range
 */
typedef enum { LumaNormal, LumaFull } LumaRange;

/* Type: OutputRounding
 * Purpose: Controls the number of bits output
 */
typedef enum { RND_Normal, RND_6Luma4Chroma, RND_7Luma5Chroma } OutputRounding;

/* Type: ClampLevel
 * Purpose: Defines the clamp levels
 */
typedef enum { ClampLow, ClampMiddle, ClampNormal, ClampHi } ClampLevel;


/*
 * Type: Crystal
 * Purpose: Defines which crystal to use
 */
typedef enum { Crystal_XT0 = 1, Crystal_XT1, Crystal_AutoSelect } Crystal;


/*
 * Type: HoriFilter
 * Purpose: Defines horizontal low-pass filter
 */
typedef enum { HFilter_AutoFormat,
               HFilter_CIF,
               HFilter_QCIF,
               HFilter_ICON } HorizFilter;

/*
 * Type: CoringLevel
 * Purpose: Defines Luma coring level
 */
typedef enum { Coring_None,
               Coring_8,
               Coring_16,
               Coring_32 } CoringLevel;

/*
 * Type: ThreeState
 * Purpose: Defines output three-states for the OE pin
 */
typedef enum { TS_Timing_Data,
               TS_Data,
               TS_Timing_Data_Clock,
               TS_Clock_Data } ThreeState;

/*
 * Type: SCLoopGain
 * Purpose: Defines subcarrier loop gain
 */
typedef enum { SC_Normal, SC_DivBy8, SC_DivBy16, SC_DivBy32 } SCLoopGain;

/*
 * Type: ComparePt
 * Purpose: Defines the majority comparison point for the White Crush Up function
 */
typedef enum { CompPt_3Q, CompPt_2Q, CompPt_1Q, CompPt_Auto } ComparePt;


#endif // __VIDDEFS
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\drivers\wdm\capture\mini\bt848\yuvfmt.h ===
// $Header: G:/SwDev/WDM/Video/bt848/rcs/Yuvfmt.h 1.5 1998/04/29 22:43:43 tomz Exp $

#ifndef __YUVFMT_H
#define __YUVFMT_H

#ifndef __DEFAULTS_H
#include "defaults.h"
#endif

KS_DATARANGE_VIDEO StreamFormatYVU9 =
{
   // KSDATARANGE
   {
      {
         sizeof( KS_DATARANGE_VIDEO ),
         0,
         DefWidth * DefHeight * 2,               // SampleSize
         0,                                      // Reserved
         { 0x73646976, 0x0000, 0x0010, { 0x80, 0x00, 0x00, 0xaa, 0x00, 0x38, 0x9b, 0x71 } }, //MEDIATYPE_Video
         { 0x39555659, 0x0000, 0x0010, { 0x80, 0x00, 0x00, 0xaa, 0x00, 0x38, 0x9b, 0x71 } }, //MEDIASUBTYPE_YVU9
         { 0x05589f80, 0xc356, 0x11ce, { 0xbf, 0x01, 0x00, 0xaa, 0x00, 0x55, 0x59, 0x5a } } //FORMAT_VideoInfo
      } 
   },
   true,
   true,
   KS_VIDEOSTREAM_PREVIEW, // StreamDescriptionFlags  (KS_VIDEO_DESC_*)
   0,       // MemoryAllocationFlags   (KS_VIDEO_ALLOC_*)

   // _KS_VIDEO_STREAM_CONFIG_CAPS
   {
      STATIC_KSDATAFORMAT_SPECIFIER_VIDEOINFO, // GUID
      KS_AnalogVideo_NTSC_M,                       // AnalogVideoStandard
      {
         MaxInWidth, MaxInHeight   // SIZE InputSize
      },
      {
         MinInWidth, MinInHeight   // SIZE MinCroppingSize;       smallest rcSrc cropping rect allowed
      },
      {
         MaxInWidth, MaxInHeight   // SIZE MaxCroppingSize;       largest rcSrc cropping rect allowed
      },
      2,           // int CropGranularityX;       // granularity of cropping size
      2,           // int CropGranularityY;
      2,           // int CropAlignX;             // alignment of cropping rect
      2,           // int CropAlignY;
      {
         MinOutWidth, MinOutHeight   // SIZE MinOutputSize;         // smallest bitmap stream can produce
      },
      {
         MaxOutWidth, MaxOutHeight   // SIZE MaxOutputSize;         // largest  bitmap stream can produce
      },
      16,         // int OutputGranularityX;     // granularity of output bitmap size
      4,          // int OutputGranularityY;
      0,          // StretchTapsX  (0 no stretch, 1 pix dup, 2 interp...)
      0,          // StretchTapsY
      2,          // ShrinkTapsX 
      2,          // ShrinkTapsY 
      333667,     // LONGLONG MinFrameInterval;  // 100 nS units
      333667,     // LONGLONG MaxFrameInterval;
      30 * MinOutWidth * MinOutHeight * 9 / 8,  // LONG MinBitsPerSecond;
      30 * MaxOutWidth * MaxOutHeight * 9 / 8 //LONG MaxBitsPerSecond;
   },

   // KS_VIDEOINFOHEADER (default format)
   {
      { 0, 0, 0, 0 },    //    RECT            rcSource;          // The bit we really want to use
      { 0, 0, 0, 0 },    //    RECT            rcTarget;          // Where the video should go
      DefWidth * DefHeight * 9 / 8 * 30L,         //    DWORD           dwBitRate;         // Approximate bit data rate
      0L,         //    DWORD           dwBitErrorRate;    // Bit error rate for this stream
      333667,     //    REFERENCE_TIME  AvgTimePerFrame;   // Average time per frame (100ns units)

      {
         sizeof( KS_BITMAPINFOHEADER ), //    DWORD      biSize;
         DefWidth,                   //    LONG       biWidth;
         DefHeight,                  //    LONG       biHeight;
         1,                          //    WORD       biPlanes;
         9,                          //    WORD       biBitCount;
         0x39555659,                 //    DWORD      biCompression;
         DefWidth * DefHeight * 9 / 8,//    DWORD      biSizeImage;
         0,                          //    LONG       biXPelsPerMeter;
         0,                          //    LONG       biYPelsPerMeter;
         0,                          //    DWORD      biClrUsed;
         0                           //    DWORD      biClrImportant;
      }
   }
};

KS_DATARANGE_VIDEO StreamFormatYUY2 =
{
   // KSDATARANGE
   {
      {
         sizeof( KS_DATARANGE_VIDEO ),
         0,
         DefWidth * DefHeight * 2,               // SampleSize
         0,                                      // Reserved
         { 0x73646976, 0x0000, 0x0010, { 0x80, 0x00, 0x00, 0xaa, 0x00, 0x38, 0x9b, 0x71 } }, //MEDIATYPE_Video
         { 0x32595559, 0x0000, 0x0010, { 0x80, 0x00, 0x00, 0xaa, 0x00, 0x38, 0x9b, 0x71 } }, //MEDIASUBTYPE_YUY2
         { 0x05589f80, 0xc356, 0x11ce, { 0xbf, 0x01, 0x00, 0xaa, 0x00, 0x55, 0x59, 0x5a } }  //FORMAT_VideoInfo
      }
   },
   true,
   true,
   KS_VIDEOSTREAM_PREVIEW, // StreamDescriptionFlags  (KS_VIDEO_DESC_*)
   0,       // MemoryAllocationFlags   (KS_VIDEO_ALLOC_*)

   // _KS_VIDEO_STREAM_CONFIG_CAPS
   {
      { STATIC_KSDATAFORMAT_SPECIFIER_VIDEOINFO }, // GUID
      KS_AnalogVideo_NTSC_M,                       // AnalogVideoStandard
      {
         MaxInWidth, MaxInHeight   // SIZE InputSize
      },
      {
         MinInWidth, MinInHeight   // SIZE MinCroppingSize;       smallest rcSrc cropping rect allowed
      },
      {
         MaxInWidth, MaxInHeight   // SIZE MaxCroppingSize;       largest rcSrc cropping rect allowed
      },
      2,           // int CropGranularityX;       // granularity of cropping size
      2,           // int CropGranularityY;
      2,           // int CropAlignX;             // alignment of cropping rect
      2,           // int CropAlignY;
      {
         MinOutWidth, MinOutHeight   // SIZE MinOutputSize;         // smallest bitmap stream can produce
      },
      {
         MaxOutWidth, MaxOutHeight   // SIZE MaxOutputSize;         // largest  bitmap stream can produce
      },
      4,          // int OutputGranularityX;     // granularity of output bitmap size
      2,          // int OutputGranularityY;
      0,          // StretchTapsX  (0 no stretch, 1 pix dup, 2 interp...)
      0,          // StretchTapsY
      2,          // ShrinkTapsX
      2,          // ShrinkTapsY
      333667,     // LONGLONG MinFrameInterval;  // 100 nS units
      333667,     // LONGLONG MaxFrameInterval;
      30 * MinOutWidth * MinOutHeight * 2,  // LONG MinBitsPerSecond;
      30 * MaxOutWidth * MaxOutHeight * 2 //LONG MaxBitsPerSecond;
   },

   // KS_VIDEOINFOHEADER (default format)
   {
      {0,0,0,0},    //    RECT            rcSource;          // The bit we really want to use
      {0,0,0,0},    //    RECT            rcTarget;          // Where the video should go
      DefWidth * DefHeight * 2 * 30L,  //    DWORD           dwBitRate;         // Approximate bit data rate
      0L,         //    DWORD           dwBitErrorRate;    // Bit error rate for this stream
      333667,     //    REFERENCE_TIME  AvgTimePerFrame;   // Average time per frame (100ns units)

      {
         sizeof( KS_BITMAPINFOHEADER ), //    DWORD      biSize;
         DefWidth,                   //    LONG       biWidth;
         DefHeight,                  //    LONG       biHeight;
         1,                          //    WORD       biPlanes;
         16,                         //    WORD       biBitCount;
         0x32595559,                 //    DWORD      biCompression;
         DefWidth * DefHeight * 2,   //    DWORD      biSizeImage;
         0,                          //    LONG       biXPelsPerMeter;
         0,                          //    LONG       biYPelsPerMeter;
         0,                          //    DWORD      biClrUsed;
         0                           //    DWORD      biClrImportant;
      }
   }
};

KS_DATARANGE_VIDEO2 StreamFormat2YUY2 =
{
   // KSDATARANGE
   {
      {
         sizeof( KS_DATARANGE_VIDEO2 ),
         0,
         DefWidth * DefHeight * 2,               // SampleSize
         0,                                      // Reserved
         { 0x73646976, 0x0000, 0x0010, { 0x80, 0x00, 0x00, 0xaa, 0x00, 0x38, 0x9b, 0x71 } }, //MEDIATYPE_Video
         { 0x32595559, 0x0000, 0x0010, { 0x80, 0x00, 0x00, 0xaa, 0x00, 0x38, 0x9b, 0x71 } }, //MEDIASUBTYPE_YUY2
         { 0xf72a76A0, 0xeb0a, 0x11d0, { 0xac, 0xe4, 0x00, 0x00, 0xc0, 0xcc, 0x16, 0xba } }  //FORMAT_VideoInfo2
      }
   },
   true,
   true,
   KS_VIDEOSTREAM_PREVIEW, // StreamDescriptionFlags  (KS_VIDEO_DESC_*)
   0,       // MemoryAllocationFlags   (KS_VIDEO_ALLOC_*)

   // _KS_VIDEO_STREAM_CONFIG_CAPS
   {
      { STATIC_KSDATAFORMAT_SPECIFIER_VIDEOINFO2 }, // GUID
      KS_AnalogVideo_NTSC_M,                       // AnalogVideoStandard
      {
         MaxInWidth, MaxInHeight   // SIZE InputSize
      },
      {
         MinInWidth, MinInHeight   // SIZE MinCroppingSize;       smallest rcSrc cropping rect allowed
      },
      {
         MaxInWidth, MaxInHeight   // SIZE MaxCroppingSize;       largest rcSrc cropping rect allowed
      },
      2,           // int CropGranularityX;       // granularity of cropping size
      2,           // int CropGranularityY;
      2,           // int CropAlignX;             // alignment of cropping rect
      2,           // int CropAlignY;
      {
         MinOutWidth, MinOutHeight   // SIZE MinOutputSize;         // smallest bitmap stream can produce
      },
      {
         MaxOutWidth, MaxOutHeight   // SIZE MaxOutputSize;         // largest  bitmap stream can produce
      },
      4,          // int OutputGranularityX;     // granularity of output bitmap size
      2,          // int OutputGranularityY;
      0,          // StretchTapsX  (0 no stretch, 1 pix dup, 2 interp...)
      0,          // StretchTapsY
      2,          // ShrinkTapsX
      2,          // ShrinkTapsY
      333667,     // LONGLONG MinFrameInterval;  // 100 nS units
      333667,     // LONGLONG MaxFrameInterval;
      30 * MinOutWidth * MinOutHeight * 2,  // LONG MinBitsPerSecond;
      30 * MaxOutWidth * MaxOutHeight * 2 //LONG MaxBitsPerSecond;
   },

   // KS_VIDEOINFOHEADER2 (default format)
   {
      {0,0,0,0},    //    RECT            rcSource;          // The bit we really want to use
      {0,0,0,0},    //    RECT            rcTarget;          // Where the video should go
      DefWidth * DefHeight * 2 * 30L,  //    DWORD           dwBitRate;         // Approximate bit data rate
      0L,         //    DWORD           dwBitErrorRate;    // Bit error rate for this stream
      333667,     //    REFERENCE_TIME  AvgTimePerFrame;   // Average time per frame (100ns units)
#if 0
		//TODO video memory must be available for interlacing to work
		KS_INTERLACE_IsInterlaced |		//		DWORD		dwInterlaceFlags
#else
			KS_INTERLACE_1FieldPerSample 
			//| KS_INTERLACE_Field1First
			//| KS_INTERLACE_FieldPatField1Only
			| KS_INTERLACE_FieldPatBothRegular
			| KS_INTERLACE_DisplayModeBobOnly,
			//| KS_INTERLACE_DisplayModeBobOrWeave,
#endif
											//		use AMINTERLACE_* defines. Reject connection if undefined bits are not 0   		
											//		AMINTERLACE_IsInterlaced            
											//		AMINTERLACE_1FieldPerSample         
											//		AMINTERLACE_Field1First             
											//		AMINTERLACE_UNUSED                  
											//		AMINTERLACE_FieldPatternMask        
											//		AMINTERLACE_FieldPatField1Only      
											//		AMINTERLACE_FieldPatField2Only      
											//		AMINTERLACE_FieldPatBothRegular     
											//		AMINTERLACE_FieldPatBothIrregular   
											//		AMINTERLACE_DisplayModeMask         
											//		AMINTERLACE_DisplayModeBobOnly      
											//		AMINTERLACE_DisplayModeWeaveOnly    
											//		AMINTERLACE_DisplayModeBobOrWeave 
											//
		0,									//		DWORD		dwCopyProtectFlags
											//		use AMCOPYPROTECT_* defines. Reject connection if undefined bits are not 0 
											//		AMCOPYPROTECT_RestrictDuplication
											//
		4,									//		DWORD		dwPictAspectRatioX
											//		X dimension of picture aspect ratio, e.g. 16 for 16x9 display
											//
		3,									//		DWORD		dwPictAspectRatioY
											//		Y dimension of picture aspect ratio, e.g.  9 for 16x9 display
		0,									//		DWORD		dwReserved1
		0,									//		DWORD		dwReserved2


      {
         sizeof( KS_BITMAPINFOHEADER ), //    DWORD      biSize;
         DefWidth,                   //    LONG       biWidth;
         DefHeight,                  //    LONG       biHeight;
         1,                          //    WORD       biPlanes;
         16,                         //    WORD       biBitCount;
         0x32595559,                 //    DWORD      biCompression;
         DefWidth * DefHeight * 2,   //    DWORD      biSizeImage;
         0,                          //    LONG       biXPelsPerMeter;
         0,                          //    LONG       biYPelsPerMeter;
         0,                          //    DWORD      biClrUsed;
         0                           //    DWORD      biClrImportant;
      }
   }
};

KS_DATARANGE_VIDEO StreamFormatYVYU =
{
   // KSDATARANGE
   {
      {
         sizeof( KS_DATARANGE_VIDEO ),
         0,
         DefWidth * DefHeight * 2,               // SampleSize
         0,                                      // Reserved
         { 0x73646976, 0x0000, 0x0010, { 0x80, 0x00, 0x00, 0xaa, 0x00, 0x38, 0x9b, 0x71 } }, //MEDIATYPE_Video
         { 0x55595659, 0x0000, 0x0010, { 0x80, 0x00, 0x00, 0xaa, 0x00, 0x38, 0x9b, 0x71 } }, //MEDIASUBTYPE_YVYU
         { 0x05589f80, 0xc356, 0x11ce, { 0xbf, 0x01, 0x00, 0xaa, 0x00, 0x55, 0x59, 0x5a } } //FORMAT_VideoInfo
      }
   },
   true,
   true,
   KS_VIDEOSTREAM_PREVIEW, // StreamDescriptionFlags  (KS_VIDEO_DESC_*)
   0,       // MemoryAllocationFlags   (KS_VIDEO_ALLOC_*)

   // _KS_VIDEO_STREAM_CONFIG_CAPS
   {
      STATIC_KSDATAFORMAT_SPECIFIER_VIDEOINFO, // GUID
      KS_AnalogVideo_NTSC_M,                       // AnalogVideoStandard
      {
         MaxInWidth, MaxInHeight   // SIZE InputSize
      },
      {
         MinInWidth, MinInHeight   // SIZE MinCroppingSize;       smallest rcSrc cropping rect allowed
      },
      {
         MaxInWidth, MaxInHeight   // SIZE MaxCroppingSize;       largest rcSrc cropping rect allowed
      },
      2,           // int CropGranularityX;       // granularity of cropping size
      2,           // int CropGranularityY;
      2,           // int CropAlignX;             // alignment of cropping rect
      2,           // int CropAlignY;
      {
         MinOutWidth, MinOutHeight   // SIZE MinOutputSize;         // smallest bitmap stream can produce
      },
      {
         MaxOutWidth, MaxOutHeight   // SIZE MaxOutputSize;         // largest  bitmap stream can produce
      },
      4,          // int OutputGranularityX;     // granularity of output bitmap size
      2,          // int OutputGranularityY;
      0,          // StretchTapsX  (0 no stretch, 1 pix dup, 2 interp...)
      0,          // StretchTapsY
      2,          // ShrinkTapsX
      2,          // ShrinkTapsY
      333667,     // LONGLONG MinFrameInterval;  // 100 nS units
      333667,     // LONGLONG MaxFrameInterval;
      30 * 80 * 40 * 2,  // LONG MinBitsPerSecond;
      30 * 720 * 480 * 2 //LONG MaxBitsPerSecond;
   },

   // KS_VIDEOINFOHEADER (default format)
   {
      { 0,0,0,0 },    //    RECT            rcSource;          // The bit we really want to use
      { 0,0,0,0 },    //    RECT            rcTarget;          // Where the video should go
      DefWidth * DefHeight * 2 * 30L,         //    DWORD           dwBitRate;         // Approximate bit data rate
      0L,         //    DWORD           dwBitErrorRate;    // Bit error rate for this stream
      333667,     //    REFERENCE_TIME  AvgTimePerFrame;   // Average time per frame (100ns units)

      {
         sizeof( KS_BITMAPINFOHEADER ), //    DWORD      biSize;
         DefWidth,                   //    LONG       biWidth;
         DefHeight,                  //    LONG       biHeight;
         1,                          //    WORD       biPlanes;
         16,                         //    WORD       biBitCount;
         0x55595659,                 //    DWORD      biCompression;
         DefWidth * DefHeight * 2,   //    DWORD      biSizeImage;
         0,                          //    LONG       biXPelsPerMeter;
         0,                          //    LONG       biYPelsPerMeter;
         0,                          //    DWORD      biClrUsed;
         0                           //    DWORD      biClrImportant;
      }
   }
};

KS_DATARANGE_VIDEO StreamFormatUYVY =
{
   // KSDATARANGE
   {
      {
         sizeof( KS_DATARANGE_VIDEO ),
         0,
         DefWidth * DefHeight * 2,               // SampleSize
         0,                                      // Reserved
         { 0x73646976, 0x0000, 0x0010, { 0x80, 0x00, 0x00, 0xaa, 0x00, 0x38, 0x9b, 0x71 } }, //MEDIATYPE_Video
         { 0x59565955, 0x0000, 0x0010, { 0x80, 0x00, 0x00, 0xaa, 0x00, 0x38, 0x9b, 0x71 } }, //MEDIASUBTYPE_UYVY
         { 0x05589f80, 0xc356, 0x11ce, { 0xbf, 0x01, 0x00, 0xaa, 0x00, 0x55, 0x59, 0x5a } } //FORMAT_VideoInfo
      }
   },
   true,
   true,
   KS_VIDEOSTREAM_PREVIEW, // StreamDescriptionFlags  (KS_VIDEO_DESC_*)
   0,       // MemoryAllocationFlags   (KS_VIDEO_ALLOC_*)

   // _KS_VIDEO_STREAM_CONFIG_CAPS
   {
      STATIC_KSDATAFORMAT_SPECIFIER_VIDEOINFO, // GUID
      KS_AnalogVideo_NTSC_M,                       // AnalogVideoStandard
      {
         MaxInWidth, MaxInHeight   // SIZE InputSize
      },
      {
         MinInWidth, MinInHeight   // SIZE MinCroppingSize;       smallest rcSrc cropping rect allowed
      },
      {
         MaxInWidth, MaxInHeight   // SIZE MaxCroppingSize;       largest rcSrc cropping rect allowed
      },
      2,           // int CropGranularityX;       // granularity of cropping size
      2,           // int CropGranularityY;
      2,           // int CropAlignX;             // alignment of cropping rect
      2,           // int CropAlignY;
      {
         MinOutWidth, MinOutHeight   // SIZE MinOutputSize;         // smallest bitmap stream can produce
      },
      {
         MaxOutWidth, MaxOutHeight   // SIZE MaxOutputSize;         // largest  bitmap stream can produce
      },
      4,          // int OutputGranularityX;     // granularity of output bitmap size
      2,          // int OutputGranularityY;
      0,          // StretchTapsX  (0 no stretch, 1 pix dup, 2 interp...)
      0,          // StretchTapsY
      2,          // ShrinkTapsX
      2,          // ShrinkTapsY
      333667,     // LONGLONG MinFrameInterval;  // 100 nS units
      333667,     // LONGLONG MaxFrameInterval;
      30 * MinOutWidth * MinOutHeight * 2,  // LONG MinBitsPerSecond;
      30 * MaxOutWidth * MaxOutHeight * 2 //LONG MaxBitsPerSecond;
   },

   // KS_VIDEOINFOHEADER (default format)
   {
      { 0,0,0,0 },    //    RECT            rcSource;          // The bit we really want to use
      { 0,0,0,0 },    //    RECT            rcTarget;          // Where the video should go
      DefWidth * DefHeight * 2 * 30L,  //    DWORD           dwBitRate;         // Approximate bit data rate
      0L,         //    DWORD           dwBitErrorRate;    // Bit error rate for this stream
      333667,     //    REFERENCE_TIME  AvgTimePerFrame;   // Average time per frame (100ns units)

      {
         sizeof( KS_BITMAPINFOHEADER ), //    DWORD      biSize;
         DefWidth,                   //    LONG       biWidth;
         DefHeight,                  //    LONG       biHeight;
         1,                          //    WORD       biPlanes;
         16,                         //    WORD       biBitCount;
         0x59565955,                 //    DWORD      biCompression;
         DefWidth * DefHeight * 2,   //    DWORD      biSizeImage;
         0,                          //    LONG       biXPelsPerMeter;
         0,                          //    LONG       biYPelsPerMeter;
         0,                          //    DWORD      biClrUsed;
         0                           //    DWORD      biClrImportant;
      }
   }
};

#endif
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\drivers\wdm\capture\mini\inc\timebomb.c ===
//+-------------------------------------------------------------------------
//
//  Microsoft Windows
//
//  Copyright (C) Microsoft Corporation, 1996 - 2001
//
//  File:       timebomb.c
//
//--------------------------------------------------------------------------

//
//  -- Add these lines after the #include's in the file that handles DriverEntry:
//
//      #ifdef TIME_BOMB
//      #include "..\..\inc\timebomb.c"
//      #endif
//
//  -- Add the following lines to the beginning of DriverEntry:
//
//      #ifdef TIME_BOMB
//      if (HasEvaluationTimeExpired()) {
//          return STATUS_EVALUATION_EXPIRATION;
//      }
//      #endif
//
//  -- If you want to override the default expiration value of 31 days after
//     compile, define the constant DAYS_UNTIL_EXPIRATION before you include
//     timebomb.c
//
//  -- Add -DTIME_BOMB to the $(C_DEFINES) line in the sources file.  If you haven't
//     already done so, you may also want to add -DDEBUG_LEVEL=DEBUGLVL_TERSE.
//
//  -- "Cleanly" recompile your binary with 'build -cZ'
//
//  -- NOTE: This uses the __DATE__ preprocessor directive which inserts a _very_
//           clear-text string into the binary which is easily modifiable with a
//           hex editor.  Suggestions on making this more secure are welcome.
//


#if !defined(_KSDEBUG_)
#include <ksdebug.h>
#endif

#ifndef DAYS_UNTIL_EXPIRATION
#define DAYS_UNTIL_EXPIRATION   31  // default
#endif

typedef enum {
    Jan=1,
    Feb,
    Mar,
    Apr,
    May,
    Jun,
    Jul,
    Aug,
    Sep,
    Oct,
    Nov,
    Dec
} MONTH;

MONTH GetMonthFromDateString
(
    char *_BuildDate_
)
{
    MONTH BuildMonth = (MONTH)0;

    ASSERT(_BuildDate_);

    switch (_BuildDate_[0]) {
        case 'A':
            if (_BuildDate_[1] == 'u') {
                BuildMonth = Aug;
            }
            else {
                BuildMonth = Apr;
            }
            break;
        case 'D':
            BuildMonth = Dec;
            break;
        case 'F':
            BuildMonth = Feb;
            break;
        case 'J':
            if (_BuildDate_[1] == 'u') {
                if (_BuildDate_[2] == 'l') {
                    BuildMonth = Jul;
                } else {
                    BuildMonth = Jun;
                }
            } else {
                BuildMonth = Jan;
            }
            break;
        case 'M':
            if (_BuildDate_[2] == 'r') {
                BuildMonth = Mar;
            }
            else {
                BuildMonth = May;
            }
            break;
        case 'N':
            BuildMonth = Nov;
            break;
        case 'O':
            BuildMonth = Oct;
            break;
        case 'S':
            BuildMonth = Sep;
            break;
        default:
            ASSERT(0);
            break;
    }

    return BuildMonth;
}

BOOL HasEvaluationTimeExpired()
{
    //  Get the time that this file was compiled
    char            _BuildDate_[] = __DATE__;
    CSHORT          BuildYear,
                    BuildMonth,
                    BuildDay,
                    ThousandsDigit,
                    HundredsDigit,
                    TensDigit,
                    Digit;
    ULONG           BuildDays,
                    CurrentDays;
    LARGE_INTEGER   CurrentSystemTime;
    TIME_FIELDS     CurrentSystemTimeFields;

    //  Convert _BuildDate_ into something a little more palatable
    // TRACE(TL_PNP_WARNING,("Driver Build Date: %s",_BuildDate_));

    BuildMonth = GetMonthFromDateString(_BuildDate_);

    //  Compensate for a ' ' in the tens digit
    if ( (_BuildDate_[4] >= '0') && (_BuildDate_[4] <= '9') ) {
        TensDigit = _BuildDate_[4] - '0';
    } else {
        TensDigit = 0;
    }
    Digit     = _BuildDate_[5] - '0';
    BuildDay  = (TensDigit * 10) + Digit;

    ThousandsDigit = _BuildDate_[7] - '0';
    HundredsDigit  = _BuildDate_[8] - '0';
    TensDigit      = _BuildDate_[9] - '0';
    Digit          = _BuildDate_[10] - '0';
    BuildYear      = (ThousandsDigit * 1000) + (HundredsDigit * 100) + (TensDigit * 10) + Digit;

    //  Get the current system time and convert to local time
    KeQuerySystemTime( &CurrentSystemTime ); // returns GMT
    RtlTimeToTimeFields( &CurrentSystemTime, &CurrentSystemTimeFields );

    //  For now, only let this binary float for 31 days
    BuildDays = (BuildYear * 365) +
                (BuildMonth * 31) +
                 BuildDay;
    CurrentDays = (CurrentSystemTimeFields.Year * 365) +
                  (CurrentSystemTimeFields.Month * 31) +
                   CurrentSystemTimeFields.Day;

    // TRACE(TL_PNP_WARNING, ("CurrentDays: %d  BuildDays: %d",CurrentDays, BuildDays) );
    if (CurrentDays > BuildDays + DAYS_UNTIL_EXPIRATION) {
        // TRACE(TL_PNP_WARNING, ("Evaluation period expired!") );
        return TRUE;
    }
    else {
        // TRACE(TL_PNP_WARNING, ("Evaluation days left: %d", (BuildDays + 31) - CurrentDays) );
        return FALSE;
    }
}
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\drivers\wdm\capture\mini\msdv\dbg.h ===
/*++

Copyright (C) Microsoft Corporation, 1999 - 2000  

Module Name:

    dbg.h

Abstract:

    Debug Code for 1394 drivers.

Environment:

    kernel mode only

Notes:

Revision History:

   

--*/
#ifndef _DBG_INC
#define _DBG_INC


//
// Various definitions
//

#if DBG

#define _DRIVERNAME_        "MSDV"

// PnP: loading, power state, surprise removal, device SRB
#define TL_PNP_MASK         0x0000000F
#define TL_PNP_INFO         0x00000001
#define TL_PNP_TRACE        0x00000002
#define TL_PNP_WARNING      0x00000004
#define TL_PNP_ERROR        0x00000008

// Connection, plug and 61883 info (get/set)
#define TL_61883_MASK       0x000000F0
#define TL_61883_INFO       0x00000010
#define TL_61883_TRACE      0x00000020
#define TL_61883_WARNING    0x00000040
#define TL_61883_ERROR      0x00000080

// Data
#define TL_CIP_MASK         0x00000F00
#define TL_CIP_INFO         0x00000100
#define TL_CIP_TRACE        0x00000200
#define TL_CIP_WARNING      0x00000400
#define TL_CIP_ERROR        0x00000800

// AVC commands
#define TL_FCP_MASK         0x0000F000
#define TL_FCP_INFO         0x00001000
#define TL_FCP_TRACE        0x00002000
#define TL_FCP_WARNING      0x00004000
#define TL_FCP_ERROR        0x00008000

// Stream (data intersection, open/close, stream state (get/set))
#define TL_STRM_MASK        0x000F0000
#define TL_STRM_INFO        0x00010000
#define TL_STRM_TRACE       0x00020000
#define TL_STRM_WARNING     0x00040000
#define TL_STRM_ERROR       0x00080000

// clock and clock event
#define TL_CLK_MASK         0x00F00000
#define TL_CLK_INFO         0x00100000
#define TL_CLK_TRACE        0x00200000
#define TL_CLK_WARNING      0x00400000
#define TL_CLK_ERROR        0x00800000


extern ULONG DVTraceMask;
extern ULONG DVAssertLevel;


#define TRAP                    DbgBreakPoint();

#define TRACE( l, x )                       \
    if( (l) & DVTraceMask ) {              \
        KdPrint( (_DRIVERNAME_ ": ") );     \
        KdPrint( x );                       \
    }

#ifdef ASSERT
#undef ASSERT
#endif
#define ASSERT( exp ) \
    if (DVAssertLevel && !(exp)) \
        RtlAssert( #exp, __FILE__, __LINE__, NULL )

#else  // #if DBG

#define TRAP  

#define TRACE( l, x )

#endif  // #if DBG


#endif
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\drivers\wdm\capture\mini\msdv\msdvavc.c ===
/*++

Copyright (C) Microsoft Corporation, 1999 - 2000  

Module Name:

    MsdvAvc.c

Abstract:

    Interface code with for issuing external device control commands.

Last changed by:
    
    Author:      Yee J. Wu

Environment:

    Kernel mode only

Revision History:

    $Revision::                    $
    $Date::                        $

--*/

#include "strmini.h"
#include "ksmedia.h"
#include "1394.h"
#include "61883.h"
#include "avc.h"
#include "dbg.h"
#include "msdvfmt.h"
#include "msdvdef.h"
#include "MsdvUtil.h"
#include "MsdvAvc.h"

#include "EDevCtrl.h"

#define ALWAYS_SET_N_GET_RAW_AVC


PAVCCmdEntry
DVCRFindCmdEntryCompleted(
    PDVCR_EXTENSION pDevExt,
    DVCR_AVC_COMMAND idxDVCRCmd,
    BYTE OpCodeToMatch,
    AvcCommandType cmdTypeToMatch
    );
NTSTATUS 
DVGetExtDeviceProperty(
    IN PDVCR_EXTENSION pDevExt,
    IN PSTREAM_PROPERTY_DESCRIPTOR pSPD,
    OUT PULONG pulActualBytesTransferred
    );
NTSTATUS 
DVSetExtDeviceProperty(
    IN PDVCR_EXTENSION pDevExt,
    IN PSTREAM_PROPERTY_DESCRIPTOR pSPD,
    OUT ULONG *pulActualBytesTransferred
    );
NTSTATUS 
DVGetExtTransportProperty(    
    IN PDVCR_EXTENSION pDevExt,
    IN PSTREAM_PROPERTY_DESCRIPTOR pSPD,
    OUT ULONG *pulActualBytesTransferred
    );
NTSTATUS 
DVSetExtTransportProperty( 
    IN PDVCR_EXTENSION pDevExt,
    IN PSTREAM_PROPERTY_DESCRIPTOR pSPD,
    OUT ULONG *pulActualBytesTransferred
    );
NTSTATUS 
DVGetTimecodeReaderProperty(
    IN PDVCR_EXTENSION pDevExt,
    IN PSTREAM_PROPERTY_DESCRIPTOR pSPD,
    OUT PULONG pulActualBytesTransferred
    );
NTSTATUS 
DVMediaSeekingProperty(
    IN PDVCR_EXTENSION pDevExt,
    IN PSTREAM_PROPERTY_DESCRIPTOR pSPD,
    OUT PULONG pulActualBytesTransferred
    );

#if 0  // Enable later
#ifdef ALLOC_PRAGMA   
     #pragma alloc_text(PAGE, DVCRFindCmdEntryCompleted)
     // #pragma alloc_text(PAGE, DVIssueAVCCommand)
     #pragma alloc_text(PAGE, DVGetExtDeviceProperty)
     #pragma alloc_text(PAGE, DVSetExtDeviceProperty)
     #pragma alloc_text(PAGE, DVGetExtTransportProperty)
     #pragma alloc_text(PAGE, DVSetExtTransportProperty)
     #pragma alloc_text(PAGE, DVGetTimecodeReaderProperty)
     #pragma alloc_text(PAGE, DVMediaSeekingProperty)
     #pragma alloc_text(PAGE, DVGetDeviceProperty)
     #pragma alloc_text(PAGE, DVSetDeviceProperty)
#endif
#endif

KSFCP_PACKET  DVcrAVCCmdTable[] = {
//                                                      ctype             subunitaddr       opcode    operands
  {  DV_UNIT_INFO,              -1, 0, CMD_STATUS,   5, AVC_CTYPE_STATUS, UNIT_TYPE_ID_DV,  0x30, 0xff, 0xff, 0xff, 0xff, 0xff}
 ,{  DV_SUBUNIT_INFO,           -1, 0, CMD_STATUS,   5, AVC_CTYPE_STATUS, UNIT_TYPE_ID_DV,  0x31, 0x07, 0xff, 0xff, 0xff, 0xff}
 ,{  DV_CONNECT_AV_MODE,        -1, 0, CMD_STATUS,   5, AVC_CTYPE_STATUS, UNIT_TYPE_ID_DV,  0x20, 0xf0, 0xff, 0xff, 0x20, 0x20}
 ,{  DV_VEN_DEP_CANON_MODE,     -1, 0, CMD_STATUS,   7, AVC_CTYPE_STATUS, UNIT_TYPE_ID_VCR, 0x00, 0x00, 0x00, 0x85, 0x00, 0x10, 0x08, 0xff}
 ,{  DV_VEN_DEP_DVCPRO,         -1, 0, CMD_STATUS,   7, AVC_CTYPE_STATUS, UNIT_TYPE_ID_DV,  0x00, 0x00, 0x80, 0x45, 0x82, 0x48, 0xff, 0xff}
 ,{  DV_IN_PLUG_SIGNAL_FMT,     -1, 0, CMD_STATUS,   5, AVC_CTYPE_STATUS, UNIT_TYPE_ID_DV,  0x19, 0x00, 0xff, 0xff, 0xff, 0xff}
 ,{  DV_OUT_PLUG_SIGNAL_FMT,    -1, 0, CMD_STATUS,   5, AVC_CTYPE_STATUS, UNIT_TYPE_ID_DV,  0x18, 0x00, 0xff, 0xff, 0xff, 0xff}

 
 ,{ VCR_TIMECODE_SEARCH,        -1, 0, CMD_CONTROL,  5, AVC_CTYPE_CONTROL,UNIT_TYPE_ID_VCR, 0x51, 0x20, 0x00, 0x00, 0x00, 0x00}
 ,{ VCR_TIMECODE_READ,          -1, 0, CMD_STATUS,   5, AVC_CTYPE_STATUS, UNIT_TYPE_ID_VCR, 0x51, 0x71, 0xff, 0xff, 0xff, 0xff}

 ,{ VCR_ATN_SEARCH,             -1, 0, CMD_CONTROL,  5, AVC_CTYPE_CONTROL,UNIT_TYPE_ID_VCR, 0x52, 0x20, 0x00, 0x00, 0x00, 0x00}
 ,{ VCR_ATN_READ,               -1, 0, CMD_STATUS,   5, AVC_CTYPE_STATUS, UNIT_TYPE_ID_VCR, 0x52, 0x71, 0xff, 0xff, 0xff, 0xff}

 ,{ VCR_RTC_SEARCH,             -1, 0, CMD_CONTROL,  5, AVC_CTYPE_CONTROL,UNIT_TYPE_ID_VCR, 0x57, 0x20, 0x00, 0x00, 0x00, 0x00}
 ,{ VCR_RTC_READ,               -1, 0, CMD_STATUS,   5, AVC_CTYPE_STATUS, UNIT_TYPE_ID_VCR, 0x57, 0x71, 0xff, 0xff, 0xff, 0xff}

 ,{ VCR_OPEN_MIC_CLOSE,         -1, 0, CMD_CONTROL,  1, AVC_CTYPE_CONTROL,UNIT_TYPE_ID_VCR, 0x60, 0x00}
 ,{ VCR_OPEN_MIC_READ,          -1, 0, CMD_CONTROL,  1, AVC_CTYPE_CONTROL,UNIT_TYPE_ID_VCR, 0x60, 0x01}
 ,{ VCR_OPEN_MIC_WRITE,         -1, 0, CMD_CONTROL,  1, AVC_CTYPE_CONTROL,UNIT_TYPE_ID_VCR, 0x60, 0x03}
 ,{ VCR_OPEN_MIC_STATUS,        -1, 0, CMD_STATUS,   1, AVC_CTYPE_STATUS, UNIT_TYPE_ID_VCR, 0x60, 0xff}

 ,{ VCR_READ_MIC,               -1, 0, CMD_CONTROL, -1, AVC_CTYPE_CONTROL,UNIT_TYPE_ID_VCR, 0x61}

 ,{ VCR_WRITE_MIC,              -1, 0, CMD_CONTROL, -1, AVC_CTYPE_CONTROL,UNIT_TYPE_ID_VCR, 0x62}

 ,{ VCR_OUTPUT_SIGNAL_MODE,     -1, 0, CMD_STATUS,   1, AVC_CTYPE_STATUS, UNIT_TYPE_ID_VCR, 0x78, 0xff}
 ,{ VCR_INPUT_SIGNAL_MODE,      -1, 0, CMD_STATUS,   1, AVC_CTYPE_STATUS, UNIT_TYPE_ID_VCR, 0x79, 0xff}

 ,{ VCR_LOAD_MEDIUM_EJECT,      -1, 0, CMD_CONTROL,  1, AVC_CTYPE_CONTROL,UNIT_TYPE_ID_VCR, 0xc1, 0x60}

 ,{ VCR_RECORD,                 -1, 0, CMD_CONTROL,  1, AVC_CTYPE_CONTROL,UNIT_TYPE_ID_VCR, 0xc2, 0x75}
 ,{ VCR_RECORD_PAUSE,           -1, 0, CMD_CONTROL,  1, AVC_CTYPE_CONTROL,UNIT_TYPE_ID_VCR, 0xc2, 0x7d}

 ,{ VCR_PLAY_FORWARD_STEP,      -1, 0, CMD_CONTROL,  1, AVC_CTYPE_CONTROL,UNIT_TYPE_ID_VCR, 0xc3, 0x30}  // 00=AVC, 20=VCR, c3=Opcode, 30=Operand[0]
 ,{ VCR_PLAY_FORWARD_SLOWEST,   -1, 0, CMD_CONTROL,  1, AVC_CTYPE_CONTROL,UNIT_TYPE_ID_VCR, 0xc3, 0x31}  
 ,{ VCR_PLAY_FORWARD_SLOWEST2,  -1, 0, CMD_CONTROL,  1, AVC_CTYPE_CONTROL,UNIT_TYPE_ID_VCR, 0xc3, 0x33}  
 ,{ VCR_PLAY_FORWARD_FASTEST,   -1, 0, CMD_CONTROL,  1, AVC_CTYPE_CONTROL,UNIT_TYPE_ID_VCR, 0xc3, 0x3f}

 ,{ VCR_PLAY_REVERSE_STEP,      -1, 0, CMD_CONTROL,  1, AVC_CTYPE_CONTROL,UNIT_TYPE_ID_VCR, 0xc3, 0x40} 
 ,{ VCR_PLAY_REVERSE_SLOWEST,   -1, 0, CMD_CONTROL,  1, AVC_CTYPE_CONTROL,UNIT_TYPE_ID_VCR, 0xc3, 0x41}
 ,{ VCR_PLAY_REVERSE_SLOWEST2,  -1, 0, CMD_CONTROL,  1, AVC_CTYPE_CONTROL,UNIT_TYPE_ID_VCR, 0xc3, 0x43}
 ,{ VCR_PLAY_REVERSE_FASTEST,   -1, 0, CMD_CONTROL,  1, AVC_CTYPE_CONTROL,UNIT_TYPE_ID_VCR, 0xc3, 0x4f}
 
 ,{ VCR_PLAY_FORWARD,           -1, 0, CMD_CONTROL,  1, AVC_CTYPE_CONTROL,UNIT_TYPE_ID_VCR, 0xc3, 0x75}  
 ,{ VCR_PLAY_FORWARD_PAUSE,     -1, 0, CMD_CONTROL,  1, AVC_CTYPE_CONTROL,UNIT_TYPE_ID_VCR, 0xc3, 0x7d}

 ,{ VCR_WIND_STOP,              -1, 0, CMD_CONTROL,  1, AVC_CTYPE_CONTROL,UNIT_TYPE_ID_VCR, 0xc4, 0x60}
 ,{ VCR_WIND_REWIND,            -1, 0, CMD_CONTROL,  1, AVC_CTYPE_CONTROL,UNIT_TYPE_ID_VCR, 0xc4, 0x65}
 ,{ VCR_WIND_FAST_FORWARD,      -1, 0, CMD_CONTROL,  1, AVC_CTYPE_CONTROL,UNIT_TYPE_ID_VCR, 0xc4, 0x75}

 ,{ VCR_TRANSPORT_STATE,        -1, 0, CMD_STATUS,   1, AVC_CTYPE_STATUS, UNIT_TYPE_ID_VCR, 0xd0, 0x7f}
 ,{ VCR_TRANSPORT_STATE_NOTIFY, -1, 0, CMD_NOTIFY,   1, AVC_CTYPE_NOTIFY, UNIT_TYPE_ID_VCR, 0xd0, 0x7f}


 ,{ VCR_MEDIUM_INFO,            -1, 0, CMD_STATUS,   2, AVC_CTYPE_STATUS, UNIT_TYPE_ID_VCR, 0xda, 0x7f,0x7f}

 ,{ VCR_RAW_AVC,                 1, 0, CMD_CONTROL | CMD_STATUS | CMD_NOTIFY | CMD_SPEC_INQ | CMD_GEN_INQ, 0}

};



void
DVCRXlateGetMediumInfo(
    PMEDIUM_INFO pMediumInfo,
    PBYTE pbOperand0,
    PBYTE pbOperand1
    )
{
    switch(*pbOperand0) {

    // Support for DigitalHi8; if we get this query, we treat DHi8 as a mini DV tape.
    case 0x12:  // DHi8

    case 0x31:// DVCR standard cassette
    case 0x32:// DVCR small cassette
    case 0x33:// DVCR medium cassette
        pMediumInfo->MediaPresent  = TRUE;
        pMediumInfo->MediaType     = ED_MEDIA_DVC;
        pMediumInfo->RecordInhibit = (*pbOperand1 & 0x01) == 0x01;
        break;
    case 0x22: // VHS cassette
        pMediumInfo->MediaPresent  = TRUE;
        pMediumInfo->MediaType     = ED_MEDIA_VHS;
        pMediumInfo->RecordInhibit = (*pbOperand1 & 0x01) == 0x01;
        break;
    case 0x23:
        pMediumInfo->MediaPresent  = TRUE;
        pMediumInfo->MediaType     = ED_MEDIA_VHSC;
        pMediumInfo->RecordInhibit = (*pbOperand1 & 0x01) == 0x01;
        break;
    case 0x60:
        pMediumInfo->MediaPresent  = FALSE;
        pMediumInfo->MediaType     = ED_MEDIA_NOT_PRESENT;
        pMediumInfo->RecordInhibit = TRUE;  // Cannot record if there is no tape.
        break;
    case 0x7e:
        pMediumInfo->MediaPresent  = TRUE;
        pMediumInfo->MediaType     = ED_MEDIA_UNKNOWN;
        pMediumInfo->RecordInhibit = TRUE;  // Actually cannot be determined
    break;
    default:
        pMediumInfo->MediaPresent  = TRUE;
        pMediumInfo->MediaType     = ED_MEDIA_UNKNOWN;
        pMediumInfo->RecordInhibit = TRUE;
        break;
    }

    // Reset command opcode/operands
    *pbOperand0 = 0x7f;
    *pbOperand1 = 0x7f;
}

void
DVCRXlateGetTransportState(
    PTRANSPORT_STATE pXPrtState,
    PBYTE pbOpcode,
    PBYTE pbOperand0
    )
{

    TRACE(TL_FCP_TRACE,("\'DVCRXlateGetTransportState: OpCode %x, Operand %x\n", *pbOpcode, *pbOperand0));

    switch(*pbOpcode) {

    case OPC_LOAD_MEDIUM:
        pXPrtState->Mode = ED_MEDIA_UNLOAD;
        ASSERT(*pbOperand0 == 0x60);
        break;

    case OPC_RECORD:
        pXPrtState->Mode = ED_MODE_RECORD;
        switch(*pbOperand0) {
        case 0x75: // RECORD
            pXPrtState->State = ED_MODE_RECORD;
            break;
        case 0x7d: // RECORD_FREEZE
            pXPrtState->State = ED_MODE_RECORD_FREEZE;
            break;
        default:
            ASSERT(FALSE && "OPC_RECORD: Operand0 undefined!");
            break;
        }
        break;

    case OPC_PLAY:
        pXPrtState->Mode = ED_MODE_PLAY;
        switch(*pbOperand0) {
        case 0x30:  // NEXT FRAME
            pXPrtState->State = ED_MODE_STEP_FWD;
            break;
        case 0x31:  // SLOWEST FORWARD
        case 0x32:  // SLOW FORWARD 6        
        case 0x33:  // SLOW FORWARD 5
        case 0x34:  // SLOW FORWARD 4
        case 0x35:  // SLOW FORWARD 3
        case 0x36:  // SLOW FORWARD 2
        case 0x37:  // SLOW FORWARD 1
            pXPrtState->State = ED_MODE_PLAY_SLOWEST_FWD;
            break;
        case 0x38:  // PLAY FORWARD 1
            pXPrtState->State = ED_MODE_PLAY;
            break;
        case 0x39:  // FAST FORWARD 1
        case 0x3a:  // FAST FORWARD 2
        case 0x3b:  // FAST FORWARD 3
        case 0x3c:  // FAST FORWARD 4
        case 0x3d:  // FAST FORWARD 5
        case 0x3e:  // FAST FORWARD 6
        case 0x3f:  // FASTEST FORWARD
            pXPrtState->State = ED_MODE_PLAY_FASTEST_FWD;
            break;
        case 0x40:  // PREVIOUS FRAME
            pXPrtState->State = ED_MODE_STEP_REV;
            break;
        case 0x41:  // SLOWEST REVERSE
        case 0x42:  // SLOW REVERSE 6
        case 0x43:  // SLOW REVERSE 5 
        case 0x44:  // SLOW REVERSE 4 
        case 0x45:  // SLOW REVERSE 3
        case 0x46:  // SLOW REVERSE 2 
        case 0x47:  // SLOW REVERSE 1 
            pXPrtState->State = ED_MODE_PLAY_SLOWEST_REV;
            break;
        case 0x48:  // X1 REVERSE
        case 0x65:  // REVERSE 
            pXPrtState->State = ED_MODE_REV_PLAY;
            break;
        case 0x49:  // FAST REVERSE 1
        case 0x4a:  // FAST REVERSE 2
        case 0x4b:  // FAST REVERSE 3
        case 0x4c:  // FAST REVERSE 4
        case 0x4d:  // FAST REVERSE 5
        case 0x4e:  // FAST REVERSE 6
        case 0x4f:  // FASTEST REVERSE
            pXPrtState->State = ED_MODE_PLAY_FASTEST_REV;
            break;
        case 0x75:  // FORWARD
            pXPrtState->State = ED_MODE_PLAY;
            break;
        case 0x6d:  // REVERSE PAUSE
        case 0x7d:  // FORWARD PAUSE
            pXPrtState->State = ED_MODE_FREEZE;
            break;
        default:
            pXPrtState->State = 0;
            ASSERT(FALSE && "OPC_PLAY: Operand0 undefined!");
            break;
        }
        break;

    case OPC_WIND:
        //pXPrtState->Mode = ED_MODE_WIND;
        switch(*pbOperand0) {
        case 0x45:  // HIGH SPEED REWIND
            pXPrtState->State = ED_MODE_REW_FASTEST;
            break;
        case 0x60:  // STOP
            pXPrtState->State = ED_MODE_STOP;
            break;
        case 0x65:  // REWIND
            pXPrtState->State = ED_MODE_REW;
            break;
        case 0x75:  // FAST FORWARD
            pXPrtState->State = ED_MODE_FF;
            break;
        default:
            TRACE(TL_FCP_ERROR,("DVCRXlateGetTransportState:  OPC_WIND with unknown operand0 %x\n", *pbOperand0));            
            break;
        }
        // Thre is not a state defined for WIND
        pXPrtState->Mode = pXPrtState->State;
        break;

    case OPC_TRANSPORT_STATE:  // As a result of the notify command
        break;

    default:
        ASSERT(FALSE && "OpCode undefined!");
        break;
    }

    // Reset command opcode/operands
    *pbOpcode   = 0xd0;
    *pbOperand0 = 0x7f;
}


void
DVCRXlateGetIOSignalMode(
    PULONG pIOSignalMode,
    PBYTE pbOperand0
    )
{

    switch(*pbOperand0) {
    // Sony's digital Hi8 can take analog 8MM tape and output DV signal.
    case 0x06:  // Analog 8mm NTSC
    case 0x0e:  // Analog Hi8 NTSC
        TRACE(TL_FCP_WARNING,("\'***** Signal mode:%x (8MM NTSC)\n", *pbOperand0)); 
    case 0x00:  // SD 525-60
        *pIOSignalMode = ED_TRANSBASIC_SIGNAL_525_60_SD;
        break;
    case 0x04:  // SDL 525-60
        *pIOSignalMode = ED_TRANSBASIC_SIGNAL_525_60_SDL;
        break;
    // Sony's digital Hi8 can take analog 8MM tape and output DV signal.
    case 0x86:  // Analog 8mm PAL
    case 0x8e:  // Analog Hi8 PAL
        TRACE(TL_FCP_WARNING,("\'***** Signal mode:%x (8MM PAL)\n", *pbOperand0)); 
    case 0x80:  // SD 625-50
        *pIOSignalMode = ED_TRANSBASIC_SIGNAL_625_50_SD;
        break;
    case 0x84:  // SDL 625-50
        *pIOSignalMode = ED_TRANSBASIC_SIGNAL_625_50_SDL;
        break;
    default:
        // This driver does not understand other format; 
        TRACE(TL_FCP_WARNING,("***** Unknown signal mode:%x\n", *pbOperand0));         
        ASSERT(FALSE && "Unknown IoSignal!");
        break;
    }

    // Reset command opcode/operands
    *pbOperand0 = 0xff;
}

NTSTATUS
DVCRXlateRawAVC(
    PAVCCmdEntry pCmdEntry,
    PVOID     pProperty
    )
{
    PAVC_COMMAND_IRB pAvcIrb = pCmdEntry->pAvcIrb;
    UCHAR ucRespCode = pAvcIrb->ResponseCode;   
    NTSTATUS  Status;
    PUCHAR   pbRtnBuf;
    //PKSPROPERTY_EXTDEVICE_S pExtDeviceProperty;
    PKSPROPERTY_EXTXPORT_S pXPrtProperty;
    PKSPROPERTY_TIMECODE_S pTmCdReaderProperty;

    if(STATUS_SUCCESS != pCmdEntry->Status) {
        TRACE(TL_FCP_ERROR,("\'** DVCRXlateRawAVC: Status:%x ** \n", pCmdEntry->Status));
        return pCmdEntry->Status;
    }


    switch (pCmdEntry->idxDVCRCmd) {
    case DV_UNIT_INFO:       
        pbRtnBuf = (PBYTE) pProperty;        
        memcpy(pbRtnBuf, pAvcIrb->Operands+1, 4);
        break;
    case DV_SUBUNIT_INFO:
    case DV_IN_PLUG_SIGNAL_FMT:
    case DV_OUT_PLUG_SIGNAL_FMT:
        pbRtnBuf = (PBYTE) pProperty;
        memcpy(pbRtnBuf, pAvcIrb->Operands+1, 4);
        break;
     // special case, return the response code in the first byte
    case DV_CONNECT_AV_MODE:
        pbRtnBuf = (PBYTE) pProperty;
        pbRtnBuf[0] = ucRespCode;
        memcpy(&pbRtnBuf[1], pAvcIrb->Operands, 5);        
        break;
     // special case, return the response code in the first byte
    case DV_VEN_DEP_CANON_MODE:
        pbRtnBuf = (PBYTE) pProperty;
        pbRtnBuf[0] = ucRespCode;
        memcpy(&pbRtnBuf[1], pAvcIrb->Operands, 7);        
        break;
    case VCR_TIMECODE_READ:
        pTmCdReaderProperty = (PKSPROPERTY_TIMECODE_S) pProperty;
        if(pAvcIrb->Operands[1] == 0xff || 
           pAvcIrb->Operands[2] == 0xff || 
           pAvcIrb->Operands[3] == 0xff || 
           pAvcIrb->Operands[4] == 0xff )  {
            TRACE(TL_FCP_WARNING,("\'TimeCodeRead: %.2x:%.2x:%.2x,%.2x\n", pAvcIrb->Operands[4], pAvcIrb->Operands[3], pAvcIrb->Operands[2], pAvcIrb->Operands[1]));
            // Even though command succeded, but the data is not valid!
            Status = STATUS_UNSUCCESSFUL;
        } else {
            // bswap them.
            pTmCdReaderProperty->TimecodeSamp.timecode.dwFrames  = 
                (((DWORD) pAvcIrb->Operands[4]) << 24) |
                (((DWORD) pAvcIrb->Operands[3]) << 16) |
                (((DWORD) pAvcIrb->Operands[2]) <<  8) |
                 ((DWORD) pAvcIrb->Operands[1]);
             TRACE(TL_FCP_TRACE,("\'TimeCodeRead: %.2x:%.2x:%.2x,%.2x\n", pAvcIrb->Operands[4], pAvcIrb->Operands[3], pAvcIrb->Operands[2], pAvcIrb->Operands[1]));
        }
        break;
    case VCR_ATN_READ:
        pTmCdReaderProperty = (PKSPROPERTY_TIMECODE_S) pProperty;
          if(pAvcIrb->Operands[1] == 0x00 && 
           pAvcIrb->Operands[2] == 0x00 && 
           pAvcIrb->Operands[3] == 0x00 )  {
            // Even though command succeded, but the data is not valid!
            Status = STATUS_UNSUCCESSFUL;
        } else {
            pTmCdReaderProperty->TimecodeSamp.dwUser = 
                pAvcIrb->Operands[1] & 0x01;  // Get the Blank flag
             // bswap them.
            pTmCdReaderProperty->TimecodeSamp.timecode.dwFrames  = 
                ( (((DWORD) pAvcIrb->Operands[3]) << 16) |
                  (((DWORD) pAvcIrb->Operands[2]) <<  8) |
                  (((DWORD) pAvcIrb->Operands[1]))
                ) >> 1;
        }
        break;
    case VCR_INPUT_SIGNAL_MODE:
    case VCR_OUTPUT_SIGNAL_MODE:
        pXPrtProperty = (PKSPROPERTY_EXTXPORT_S) pProperty;
        DVCRXlateGetIOSignalMode(&pXPrtProperty->u.SignalMode, &pAvcIrb->Operands[0]);
        break;
    case VCR_TRANSPORT_STATE:
    case VCR_TRANSPORT_STATE_NOTIFY:
        pXPrtProperty = (PKSPROPERTY_EXTXPORT_S) pProperty;
        DVCRXlateGetTransportState(&pXPrtProperty->u.XPrtState, &pAvcIrb->Opcode, &pAvcIrb->Operands[0]);
        break;
    case VCR_MEDIUM_INFO:
        pXPrtProperty = (PKSPROPERTY_EXTXPORT_S) pProperty;
        DVCRXlateGetMediumInfo(&pXPrtProperty->u.MediumInfo, &pAvcIrb->Operands[0], &pAvcIrb->Operands[1]);
        break;
    case VCR_RAW_AVC:
        // Do nothing.
        break;
     default:
        // No translation necessary
         TRACE(TL_FCP_TRACE,("\'No tranlsation: pCmdEntry:%x; idx:%d\n", pCmdEntry, pCmdEntry->idxDVCRCmd));
        break;
    }

    return pCmdEntry->Status;
}



PAVCCmdEntry
DVCRFindCmdEntryCompleted(
    PDVCR_EXTENSION pDevExt,
    DVCR_AVC_COMMAND idxDVCRCmd,
    BYTE OpCodeToMatch,
    AvcCommandType cmdTypeToMatch
    )
/*++

Routine Description:

Arguments:

Return Value:

    PLIST_ENTRY

--*/
{
    LIST_ENTRY   *pEntry;
    KIRQL         OldIrql;

    PAGED_CODE();

    //
    // Special case:
    //
    //     ATN:       Status 01 20 52; Control 00 20 52
    //     (resp)            0c 20 52          0f 20 52   (CtrlInterim)
    //
    //     XPrtState: Status 01 20 d0;  Notify 03 20 d0
    //     (resp)            0c 20 xx          0f 20 xx xx (NotifyInterim)      
    //
    // Summary: if we keep cmdType and OpCode, it is unique.
    //
    KeAcquireSpinLock(&pDevExt->AVCCmdLock, &OldIrql);
    pEntry = pDevExt->AVCCmdList.Flink;
    while(pEntry != &pDevExt->AVCCmdList) {       
        PAVCCmdEntry pCmdEntry = (PAVCCmdEntry)pEntry;

        if (pCmdEntry->idxDVCRCmd == idxDVCRCmd) {
            //
            //  We only fetch if it is completed!       
            //
            if(pCmdEntry->cmdState != CMD_STATE_ISSUED) {
                if (pCmdEntry->cmdType == cmdTypeToMatch) {
                    // Control/GenInq/SpecInq: OpCode and Operand[n] remina unchanged.
                    if (pCmdEntry->OpCode == OpCodeToMatch) {
                        TRACE(TL_FCP_TRACE,("\'DVCRFindCmdEntryCompleted: (1) Found pCmdEntry:%x (%x, %x, %x)\n", 
                            pCmdEntry, pCmdEntry->pAvcIrb, cmdTypeToMatch, OpCodeToMatch));

                        RemoveEntryList(&pCmdEntry->ListEntry);  pDevExt->cntCommandQueued--;
                        InitializeListHead(&pCmdEntry->ListEntry);  // used as a flag for ownership

                        // pIrp should be NULL (completed).
                        if(pCmdEntry->pIrp) {
                            TRACE(TL_FCP_ERROR,("\'*** FindCmdEntry: pCmdEntry:%x; pIrp:%x not completed\n", pCmdEntry, pCmdEntry->pIrp));
                        } 

                        KeReleaseSpinLock(&pDevExt->AVCCmdLock, OldIrql);

                        return pCmdEntry;  // Found
                    } 

                } else {
                    TRACE(TL_FCP_TRACE,("\'DVCRFindCmdEntryCompleted: cmdType %x != %x\n", pCmdEntry->cmdType, cmdTypeToMatch));
                }
            }
            else {
                TRACE(TL_FCP_TRACE,("\'DVCRFindCmdEntryCompleted: (0) Skip %x not completed (%x, %x) match entry %x\n", 
                        pCmdEntry, cmdTypeToMatch, OpCodeToMatch));                
            }
        }

        pEntry = pEntry->Flink;
    }

    KeReleaseSpinLock(&pDevExt->AVCCmdLock, OldIrql);

    TRACE(TL_FCP_TRACE,("\'DVCRFindCmdEntryCompleted: (a) No match\n"));                
    return NULL; // No match
}


void
DVAVCCmdResetAfterBusReset(
    PDVCR_EXTENSION pDevExt
    )
/*++

Routine Description:

Arguments:

Return Value:

    Nothing

--*/
{
    KIRQL        OldIrql;

    KeAcquireSpinLock(&pDevExt->AVCCmdLock, &OldIrql);
    TRACE(TL_FCP_TRACE,("\'Flush AVCCmd: <enter> AVCCmd [completed %d]; CmdList:%x\n", pDevExt->cntCommandQueued, pDevExt->AVCCmdList));

    // Clear the command list
    while (!IsListEmpty(&pDevExt->AVCCmdList)) {

        PAVCCmdEntry pCmdEntry = (PAVCCmdEntry)RemoveHeadList(&pDevExt->AVCCmdList); pDevExt->cntCommandQueued--;
        InitializeListHead(&pCmdEntry->ListEntry);
        TRACE(TL_FCP_TRACE,("\'Flush AVCCmd: Completed:%d; pCmdEntry:%x; cmdState:%d; cmdSt:%x\n", 
            pDevExt->cntCommandQueued, pCmdEntry, pCmdEntry->cmdState, pCmdEntry->Status));

        switch(pCmdEntry->cmdState) {
        case CMD_STATE_ISSUED:
        case CMD_STATE_RESP_INTERIM:  // AVC.sys may still has it!
            TRACE(TL_FCP_WARNING,("BusReset: AbortAVC: IoCancelIrp(%x)!\n", pCmdEntry->pIrp));
            ASSERT(pCmdEntry->pIrp != NULL);
            IoCancelIrp(pCmdEntry->pIrp);    // Calls DVIssueAVCCommandCR() with pIrp->Cancel
            break;

        // Completed command
        case CMD_STATE_UNDEFINED:
            TRACE(TL_FCP_ERROR,("DVAVCCmdResetAfterBusReset: Unexpected CMD state %d; pCmdEntry %x\n", pCmdEntry->cmdState, pCmdEntry));
        case CMD_STATE_RESP_ACCEPTED:
        case CMD_STATE_RESP_REJECTED:
        case CMD_STATE_RESP_NOT_IMPL:
        case CMD_STATE_ABORTED:
            break;      

        default:
            TRACE(TL_FCP_ERROR,("DVAVCCmdResetAfterBusReset: Unknown CMD state %d; pCmdEntry %x\n", pCmdEntry->cmdState, pCmdEntry));
            ASSERT(FALSE && "Unknown cmdState\n");
            break;
        }

        // We are guaranteed at this point that no one needs the
        // results anymore so we will free the resources.
        ExFreePool(pCmdEntry->pAvcIrb);
        ExFreePool(pCmdEntry);
    }

    KeReleaseSpinLock(&pDevExt->AVCCmdLock, OldIrql);

#if DBG
    if(pDevExt->cntCommandQueued != 0) {
        TRACE(TL_FCP_ERROR,("\'Flush AVCCmd: <exit> AVCCmd [completed %d]; CmdList:%x\n", pDevExt->cntCommandQueued, pDevExt->AVCCmdList));
        ASSERT(pDevExt->cntCommandQueued == 0 && "All commands should be cancelled or completed.");
    }
#endif
}

NTSTATUS
DVIssueAVCCommandCR(
    IN PDEVICE_OBJECT DeviceObject,
    IN PIRP pIrp,
    IN PAVCCmdEntry pCmdEntry
    )
/*++

Routine Description:

    This is the completion routine for the AVC command when it is completed which imply that 
    the interim response will not be called here.

Arguments:
    Note: pCmdEntry cannot be used if pIrp->Cancel.

Return Value:

    Always STATUS_MORE_PROCESSING_REQUIRED.
    Note: the real return is in pCmdEntry->Status.

--*/
{
    KIRQL oldIrql;

    if (!pIrp->Cancel) {

        PDVCR_EXTENSION pDevExt = pCmdEntry->pDevExt;
        BOOL bSignalInterimCotrolCompleted = FALSE;
        BOOL bSignalInterimNotifyCompleted = FALSE;
        PKSEVENT_ENTRY   pEvent;


        // Serialize AVC command response processing
        KeAcquireSpinLock(&pDevExt->AVCCmdLock, &oldIrql);

        ASSERT(pCmdEntry->pIrp == pIrp);
        pCmdEntry->pIrp = NULL; // don't need this anymore

        // Check if it's worthwhile to examine the response buffer
        if (STATUS_SUCCESS == pIrp->IoStatus.Status) {

            PAVC_COMMAND_IRB pAvcIrb = pCmdEntry->pAvcIrb;

            // Check Opcode for return state
            switch(pAvcIrb->ResponseCode) {
            case AVC_RESPONSE_NOTIMPL:
                pCmdEntry->cmdState = CMD_STATE_RESP_NOT_IMPL;
                pCmdEntry->Status   = STATUS_NOT_SUPPORTED;  // -> ERROR_NOT_SUPPORTED
                break;

            case AVC_RESPONSE_ACCEPTED:
                if(pCmdEntry->cmdState == CMD_STATE_RESP_INTERIM) {
                    if(pCmdEntry->cmdType == AVC_CTYPE_CONTROL) {
                        bSignalInterimCotrolCompleted = TRUE;
                        TRACE(TL_FCP_TRACE,("--> Accept: control interim\n"));
                    } else {
                        TRACE(TL_FCP_ERROR,("\'ACCEPT: Invalid cmdType:%d; pCmdExtry %x\n", pCmdEntry->cmdType, pCmdEntry));
                        ASSERT(pCmdEntry->cmdType == AVC_CTYPE_CONTROL && "Accept+Interim but not control cmd");
                    }
                } 
                pCmdEntry->cmdState = CMD_STATE_RESP_ACCEPTED;
                pCmdEntry->Status   = STATUS_SUCCESS;       // -> NOERROR
                break;

            case AVC_RESPONSE_REJECTED:
                if(pCmdEntry->cmdState == CMD_STATE_RESP_INTERIM) {
                    if(pCmdEntry->cmdType == AVC_CTYPE_CONTROL) {
                        TRACE(TL_FCP_TRACE,("--> Reject: control interim\n"));
                        bSignalInterimCotrolCompleted = TRUE;
                    } else if(pCmdEntry->cmdType == AVC_CTYPE_NOTIFY) {
                        TRACE(TL_FCP_TRACE,("--> Reject: notify interim\n"));
                        bSignalInterimNotifyCompleted = TRUE;                  
                    } else {
                        TRACE(TL_FCP_ERROR,("REJECT: Invalid cmdType:%d; pCmdExtry %x\n", pCmdEntry->cmdType, pCmdEntry));
                        ASSERT((pCmdEntry->cmdType == AVC_CTYPE_CONTROL || pCmdEntry->cmdType == AVC_CTYPE_NOTIFY) && "Reject+Interim but not control or notify cmd");
                    }
                }
                pCmdEntry->cmdState = CMD_STATE_RESP_REJECTED;
                pCmdEntry->Status   = STATUS_REQUEST_NOT_ACCEPTED;  // ERROR_REQ_NOT_ACCEPTED
                break;

            case AVC_RESPONSE_IN_TRANSITION:
                pCmdEntry->cmdState = CMD_STATE_RESP_ACCEPTED;
                pCmdEntry->Status   = STATUS_SUCCESS;       // -> NOERROR
                break;

            case AVC_RESPONSE_STABLE: // == AVC_RESPONSE_IMPLEMENTED:
                pCmdEntry->cmdState = CMD_STATE_RESP_ACCEPTED;
                pCmdEntry->Status   = STATUS_SUCCESS;       // ->  NOERROR
                break;

            case AVC_RESPONSE_CHANGED:
#if DBG
                if(pCmdEntry->cmdState != CMD_STATE_RESP_INTERIM) {
                   TRACE(TL_FCP_ERROR,("Err: Changed; pCmdExtry:%x; cmdState:%d\n", pCmdEntry, pCmdEntry->cmdState));
                   ASSERT(pCmdEntry->cmdState == CMD_STATE_RESP_INTERIM);
                }
#endif
                if(pCmdEntry->cmdType == AVC_CTYPE_NOTIFY) {
                    TRACE(TL_FCP_TRACE,("--> Changed: for notify interim\n"));
                     bSignalInterimNotifyCompleted = TRUE;                  
                } else {
                    TRACE(TL_FCP_ERROR,("pCmdExtry %x\n", pCmdEntry));
                    ASSERT(pCmdEntry->cmdType == AVC_CTYPE_NOTIFY && "Changed but not notify cmd!");
                }
 
                pCmdEntry->cmdState = CMD_STATE_RESP_ACCEPTED;
                pCmdEntry->Status   = STATUS_SUCCESS;       // ->  NOERROR
                break;

            // AVC.sys should never return this response !!
            case AVC_RESPONSE_INTERIM:              
                ASSERT( pAvcIrb->ResponseCode != AVC_RESPONSE_INTERIM && "CmpRoutine should not has this response!");
                pCmdEntry->cmdState = CMD_STATE_RESP_INTERIM;
                pCmdEntry->Status   = STATUS_MORE_ENTRIES;   // ov.Internal 
                break;
        
            default:
                TRACE(TL_FCP_ERROR,("pCmdEntry%x; State:%d; pAvcIrb:%x; RespCode:%x\n", pCmdEntry, pCmdEntry->cmdState, pAvcIrb, pAvcIrb->ResponseCode));
                ASSERT(FALSE && "Undefined cmdState");
                pCmdEntry->cmdState = CMD_STATE_UNDEFINED;
                pCmdEntry->Status   = STATUS_NOT_SUPPORTED;   // ov.Internal 
                break;
            }

#if DBG
            if(pCmdEntry->cmdState != CMD_STATE_UNDEFINED) {
                TRACE(TL_FCP_WARNING,("\'     AVCRsp: %d:[%.2x %.2x %.2x %.2x]:[%.2x %.2x %.2x %.2x]; cmdSt:%d; St:%x\n",
                    pAvcIrb->OperandLength+3,  // Resp+SuID+OpCd+Opr[]
                    pAvcIrb->ResponseCode,
                    pAvcIrb->SubunitAddr[0],
                    pAvcIrb->Opcode,
                    pAvcIrb->Operands[0],
                    pAvcIrb->Operands[1],
                    pAvcIrb->Operands[2],
                    pAvcIrb->Operands[3],
                    pAvcIrb->Operands[4],
                    pCmdEntry->cmdState,
                    pCmdEntry->Status
                    ));
            }
#endif
        } else {

            // Irp returns ERROR !!
            if (STATUS_BUS_RESET == pIrp->IoStatus.Status || STATUS_REQUEST_ABORTED == pIrp->IoStatus.Status) {
                TRACE(TL_FCP_WARNING,("Bus-Reset or abort (IoStatus.St:%x); pDevRemoved:%d; pCmdEntry:%x; OpC:%x\n", pIrp->IoStatus.Status, pDevExt->bDevRemoved, pCmdEntry, pCmdEntry->OpCode));
                // ASSERT only if it was an ABORT while device was NOTt removed.
                // ASSERT((pIrp->IoStatus.Status == STATUS_BUS_RESET || pDevExt->bDevRemoved) && "Device not removed but command was aborting ?");
                // Busreset while there is an interim pending, signal its client to wake up 
                // and get the "final" (busreset) result.
                if(pCmdEntry->cmdState == CMD_STATE_RESP_INTERIM) {
                    if(pCmdEntry->cmdType == AVC_CTYPE_CONTROL) {
                        TRACE(TL_FCP_TRACE,("\'--> BusRest: for control interim\n"));
                        bSignalInterimCotrolCompleted = TRUE;
                    } else if(pCmdEntry->cmdType == AVC_CTYPE_NOTIFY) {
                        TRACE(TL_FCP_TRACE,("\'--> BusRest: for notify interim\n"));
                        bSignalInterimNotifyCompleted = TRUE;                  
                    } 
                }
            }
            else {
                TRACE(TL_FCP_WARNING,("\'IOCTL_AVC_CLASS Failed, pIrp->IoStatus.Status:%x\n", pIrp->IoStatus.Status));
            }

            pCmdEntry->cmdState = CMD_STATE_ABORTED;
            // If the command was timeout, the application may want to try the command again.
            // It is other abort, it might be caused by busreset or dev removal.
            if(pIrp->IoStatus.Status == STATUS_TIMEOUT)
                pCmdEntry->Status = pIrp->IoStatus.Status;
            else if (pIrp->IoStatus.Status == STATUS_DEVICE_DATA_ERROR)  // ERROR_CRC
                pCmdEntry->Status = pIrp->IoStatus.Status;
            else
                pCmdEntry->Status = STATUS_REQUEST_ABORTED;  // -> ERROR_REQUERT_ABORT
        }

        //
        // If suceeded, translate the AVC response to COM property. if not 
        //    interim's final reponse.
        //    raw AVC command response
        //
        if(STATUS_SUCCESS == pCmdEntry->Status &&
           !bSignalInterimNotifyCompleted &&
           !bSignalInterimCotrolCompleted &&
           pCmdEntry->idxDVCRCmd != VCR_RAW_AVC
            )
            DVCRXlateRawAVC(
                pCmdEntry, 
                pCmdEntry->pProperty
                );


        // Signal a KS event to inform its client that the final response 
        // has returned and come and get it.
        if(bSignalInterimNotifyCompleted) {
            pEvent = NULL;

            // There might be multiple instances/threads of IAMExtTransport instance with the same KS event.
            // There is only one device so they all enabled event are singalled.
            do {
                if(pEvent = StreamClassGetNextEvent((PVOID) pDevExt, 0, \
                    (GUID *)&KSEVENTSETID_EXTDEV_Command, KSEVENT_EXTDEV_COMMAND_NOTIFY_INTERIM_READY, pEvent)) {            
                    // Make sure the right event and then signal it
                    if(pEvent->EventItem->EventId == KSEVENT_EXTDEV_COMMAND_NOTIFY_INTERIM_READY) {
                        StreamClassDeviceNotification(SignalDeviceEvent, pDevExt, pEvent);
                        TRACE(TL_FCP_WARNING,("\'->Signal NOTIFY_INTERIM ready; pEvent:%x, EventId %d.\n", pEvent, pEvent->EventItem->EventId));
                    }          
                }  
            } while (pEvent != NULL);

        } else if(bSignalInterimCotrolCompleted) {
            pEvent = NULL;

            // There might be multiple instances/threads of IAMExtTransport instance with the same KS event.
            // There is only one device so they all enabled event are singalled.
            do {
                if(pEvent = StreamClassGetNextEvent((PVOID) pDevExt, 0, \
                    (GUID *)&KSEVENTSETID_EXTDEV_Command, KSEVENT_EXTDEV_COMMAND_CONTROL_INTERIM_READY, pEvent)) {
                    // Make sure the right event and then signal it
                    if(pEvent->EventItem->EventId == KSEVENT_EXTDEV_COMMAND_CONTROL_INTERIM_READY) {
                        StreamClassDeviceNotification(SignalDeviceEvent, pDevExt, pEvent);
                        TRACE(TL_FCP_WARNING,("\'->Signal CONTROL_INTERIM ready; pEvent:%x, EventId %d.\n", pEvent, pEvent->EventItem->EventId));
                    }          
                }
            } while (pEvent != NULL);
        }

        // Check that the command entry is ours only to process 
        // When a command is completed, it will be added to the list and therefore not empty.
        // It is designed to be added to the list in this completino routine.
        if (!IsListEmpty(&pCmdEntry->ListEntry)) {
            if(bSignalInterimNotifyCompleted || bSignalInterimCotrolCompleted) {
                // If final reponse is returned, we need to keep them in the list.
                TRACE(TL_FCP_TRACE,("\'Final response is completed; stay in the list\n"));
                KeReleaseSpinLock(&pDevExt->AVCCmdLock, oldIrql);
            }
            else {
                // This is a undefined path!!!
                // The command entry can only be in the list if it is interim of anykind.
                // If it is an interim, it will not be removed in the completion routine.
                ASSERT(FALSE && "Cannot complete an interim in CR\n");
            }
        }
        else {
            // This means that we have completed, but the code that issued the
            // command is still executing, and hasn't had a chance to look at
            // the results yet. Put this in the command list as a signal that
            // we have completed and updated the command state, but are not
            // planning to free the command resources.
            InsertTailList(&pDevExt->AVCCmdList, &pCmdEntry->ListEntry); pDevExt->cntCommandQueued++;
            TRACE(TL_FCP_TRACE,("\'Command completed and Queued(%d); pCmdEntry:%x.\n", pDevExt->cntCommandQueued, pCmdEntry));
            KeReleaseSpinLock(&pDevExt->AVCCmdLock, oldIrql);    
        }
    }
    else {
        TRACE(TL_FCP_WARNING,("DVIssueAVCCommandCR: pCmdEntry:%x; pIrp:%x cancelled\n", pCmdEntry, pIrp));
    }

    IoFreeIrp(pIrp);

    return STATUS_MORE_PROCESSING_REQUIRED;
} // DVIssueAVCCommandCR

NTSTATUS  
DVIssueAVCCommand (
    IN PDVCR_EXTENSION pDevExt, 
    IN AvcCommandType cType,
    IN DVCR_AVC_COMMAND idxAVCCmd,
    IN PVOID pProperty
    )
/*++

Routine Description:

    Issue a FCP/AVC command.

Arguments:
    

Return Value:

    NTSTATUS

--*/
{
    NTSTATUS      Status; 
    PAVCCmdEntry pCmdEntry;
    PAVC_COMMAND_IRB  pAvcIrb; 
    PIRP pIrp;
    PIO_STACK_LOCATION NextIrpStack;
    ULONGLONG tmStart;
    DWORD dwElapsed;
    KIRQL OldIrql;
    LIST_ENTRY   *pEntry;

    PAGED_CODE();   
 

    if(pDevExt->bDevRemoved)
        return STATUS_DEVICE_NOT_CONNECTED; // ERROR_NOT_READY

    //
    // Validate Command type; the command type that each entry of the command table support.
    //
    switch(cType) {
    case AVC_CTYPE_CONTROL:
        if((DVcrAVCCmdTable[idxAVCCmd].ulCmdSupported & CMD_CONTROL) != CMD_CONTROL)
           return STATUS_NOT_SUPPORTED;
        break;
    case AVC_CTYPE_STATUS:
        if((DVcrAVCCmdTable[idxAVCCmd].ulCmdSupported & CMD_STATUS) != CMD_STATUS)
           return STATUS_NOT_SUPPORTED;
        break;
    case AVC_CTYPE_SPEC_INQ:
        if((DVcrAVCCmdTable[idxAVCCmd].ulCmdSupported & CMD_SPEC_INQ) != CMD_SPEC_INQ) 
           return STATUS_NOT_SUPPORTED;
        break;
    case AVC_CTYPE_GEN_INQ:
        if((DVcrAVCCmdTable[idxAVCCmd].ulCmdSupported & CMD_GEN_INQ) != CMD_GEN_INQ)
           return STATUS_NOT_SUPPORTED;
        break;
    case AVC_CTYPE_NOTIFY:
        if((DVcrAVCCmdTable[idxAVCCmd].ulCmdSupported & CMD_NOTIFY) != CMD_NOTIFY)
           return STATUS_NOT_SUPPORTED;
        break;
    default:
        TRACE(TL_FCP_ERROR,("DVIssueAVCCommand: Unknown or invalid cmdType: idx %d, ctype (%02x) not supported; (%02x %02x %02x) %d:[%.8x]\n",
            idxAVCCmd,
            cType,
            DVcrAVCCmdTable[idxAVCCmd].CType,
            DVcrAVCCmdTable[idxAVCCmd].SubunitAddr,
            DVcrAVCCmdTable[idxAVCCmd].Opcode,
            DVcrAVCCmdTable[idxAVCCmd].OperandLength,
            (DWORD) *(&DVcrAVCCmdTable[idxAVCCmd].Operands[0])
            ));
        return STATUS_NOT_SUPPORTED;
    }

    // Restrict only one command to be active at any time.
    // "Active" mean, it is in the process of issuing the command to the device 
    // and is awaiting its first response.
    // Even though there is only one device but there might be mulitple thread isssuing
    // AVC commands at the same time.  By design, application should serialize their command
    // but they may not know what COM interface will result in an AVC command.  In addition,
    // this driver itsefl may issue command to the device.  So flow control become necessary.

    KeWaitForSingleObject( &pDevExt->hMutexIssueAVCCmd, Executive, KernelMode, FALSE, 0 );    

    // Check one more time for device removal
    if(pDevExt->bDevRemoved) {
        KeReleaseMutex(&pDevExt->hMutexIssueAVCCmd, FALSE); 
        TRACE(TL_FCP_WARNING,("** AVC command but device is removed!\n"));
        return STATUS_DEVICE_NOT_CONNECTED; // ERROR_NOT_READY
    }


    // Most device cannot keep two command of same cmdType and OpCode at the same time
    // Go thru list of queued (already issues) command, and search for a possible conflict.
    KeAcquireSpinLock(&pDevExt->AVCCmdLock, &OldIrql);
    pEntry = pDevExt->AVCCmdList.Flink;

    while(pEntry != &pDevExt->AVCCmdList) {       
        pCmdEntry = (PAVCCmdEntry)pEntry;

        // Skip the one that is already completed (many differnt command state).
        if(pCmdEntry->cmdState == CMD_STATE_RESP_ACCEPTED ||
           pCmdEntry->cmdState == CMD_STATE_RESP_REJECTED ||
           pCmdEntry->cmdState == CMD_STATE_RESP_NOT_IMPL || 
           pCmdEntry->cmdState == CMD_STATE_ABORTED) {           
            TRACE(TL_FCP_WARNING,("\'---- pCmdEntry:%x; cmdType:%x; OpCode:%x; completed.\n", pCmdEntry, pCmdEntry->cmdType, pCmdEntry->OpCode));        
        // Find a matching cmdType and OpCode.
        } else if(pCmdEntry->cmdType == cType && 
            pCmdEntry->OpCode == DVcrAVCCmdTable[idxAVCCmd].Opcode) {
            // Conflict, return error.
            TRACE(TL_FCP_ERROR,("----  Conflict pCmdEntry:%x; Current: cmdType:%x, OpCode:%x; rtn STATUS_DEVICE_NOT_READY\n", 
                pCmdEntry, cType, DVcrAVCCmdTable[idxAVCCmd].Opcode));
            // ASSERT(FALSE && "Conflict: duplicate CMD.");
            KeReleaseSpinLock(&pDevExt->AVCCmdLock, OldIrql);
            KeReleaseMutex(&pDevExt->hMutexIssueAVCCmd, FALSE); 
            // ERROR_NOT_READY; device not ready for another command
            return STATUS_DEVICE_NOT_READY;  
        }
        pEntry = pEntry->Flink;
    }
    KeReleaseSpinLock(&pDevExt->AVCCmdLock, OldIrql);

    // Create an AVC IRB and initialize it -
    if(!(pAvcIrb = (AVC_COMMAND_IRB *) ExAllocatePool(NonPagedPool, sizeof(AVC_COMMAND_IRB)))) {
        KeReleaseMutex(&pDevExt->hMutexIssueAVCCmd, FALSE); 
        return STATUS_INSUFFICIENT_RESOURCES;
    }

    RtlZeroMemory(pAvcIrb, sizeof(AVC_COMMAND_IRB));
    pAvcIrb->Function = AVC_FUNCTION_COMMAND;

    //
    // Set the retry and timeout flag and value.  These are adjusted (tuned) to 
    // some DV device that may not be "semi"-compliant (may take several reteies and 
    // may take more than 100msec)..
    //     
    pAvcIrb->RetryFlag   = 1;   // Set to 1 in order to set Retries.
    pAvcIrb->Retries     = (UCHAR) pDevExt->AVCCmdRetries;

    // - set the AVC command type (Control, Status, Notify, General Inquiry, Specific Inquiry)
    pAvcIrb->CommandType = cType;

    // - override the subunit address in the avc unit driver (if it even has one for us)
    pAvcIrb->SubunitAddrFlag = 1;
    pAvcIrb->SubunitAddr = &DVcrAVCCmdTable[idxAVCCmd].SubunitAddr;
    pAvcIrb->Opcode = DVcrAVCCmdTable[idxAVCCmd].Opcode;

    // - include alternate opcodes for the transport state opcode
    if (pAvcIrb->Opcode == OPC_TRANSPORT_STATE) {
        pAvcIrb->AlternateOpcodesFlag = 1;
        pAvcIrb->AlternateOpcodes = pDevExt->TransportModes;
    }

    // - set up the operand list
    pAvcIrb->OperandLength = DVcrAVCCmdTable[idxAVCCmd].OperandLength;
    ASSERT(pAvcIrb->OperandLength <= MAX_AVC_OPERAND_BYTES);
    RtlCopyMemory(pAvcIrb->Operands, DVcrAVCCmdTable[idxAVCCmd].Operands, pAvcIrb->OperandLength);

    // Create an Irp and initialize it
    if(!(pIrp = IoAllocateIrp(pDevExt->pBusDeviceObject->StackSize, FALSE))) {
        ExFreePool(pAvcIrb);  pAvcIrb = NULL;
        KeReleaseMutex(&pDevExt->hMutexIssueAVCCmd, FALSE);
        return STATUS_INSUFFICIENT_RESOURCES;
    }

    // Create an AVC Command entry and initialize it
    if(!(pCmdEntry = (AVCCmdEntry *) ExAllocatePool(NonPagedPool, sizeof(AVCCmdEntry)))) {
        ExFreePool(pAvcIrb);  pAvcIrb = NULL;
        IoFreeIrp(pIrp);  pIrp = NULL;
        KeReleaseMutex(&pDevExt->hMutexIssueAVCCmd, FALSE); 
        return STATUS_INSUFFICIENT_RESOURCES;
    }

    RtlZeroMemory(pCmdEntry, sizeof(AVCCmdEntry));
    pCmdEntry->pDevExt      = pDevExt;  // So we can access pDevExt->AVCCmdList;
    pCmdEntry->pProperty    = pProperty;
    pCmdEntry->cmdState     = CMD_STATE_ISSUED;
    pCmdEntry->Status       = STATUS_UNSUCCESSFUL;
    pCmdEntry->cmdType      = cType;
    pCmdEntry->OpCode       = DVcrAVCCmdTable[idxAVCCmd].Opcode;
    pCmdEntry->idxDVCRCmd   = idxAVCCmd;
    pCmdEntry->pAvcIrb      = pAvcIrb;
    pCmdEntry->pIrp         = pIrp;
    InitializeListHead(&pCmdEntry->ListEntry);  // used as a flag for ownership

    TRACE(TL_FCP_WARNING,("\'>>>> AVCCmd: %d:[%.2x %.2x %.2x %.2x]:[%.2x %.2x %.2x %.2x]\n",                  
        pAvcIrb->OperandLength+3,  // Resp+SuID+OpCd+Opr[]
        cType,
        pAvcIrb->SubunitAddr[0],
        pAvcIrb->Opcode,
        pAvcIrb->Operands[0],
        pAvcIrb->Operands[1],
        pAvcIrb->Operands[2],
        pAvcIrb->Operands[3],
        pAvcIrb->Operands[4]
        ));

    // Finish initializing the Irp
    NextIrpStack = IoGetNextIrpStackLocation(pIrp);
    NextIrpStack->MajorFunction = IRP_MJ_INTERNAL_DEVICE_CONTROL;
    NextIrpStack->Parameters.DeviceIoControl.IoControlCode = IOCTL_AVC_CLASS;
    NextIrpStack->Parameters.Others.Argument1 = pAvcIrb;

    IoSetCompletionRoutine(pIrp, DVIssueAVCCommandCR, pCmdEntry, TRUE, TRUE, TRUE);

    pIrp->IoStatus.Status = STATUS_NOT_SUPPORTED;

    // Used to monitor response time of an AVC command    
    tmStart = GetSystemTime();

    // Now make the call
    // If encounter an interim response, STATUS_PENDING will be returned.    
    Status = 
        IoCallDriver(
            pDevExt->pBusDeviceObject, 
            pIrp
            );

    dwElapsed = (DWORD) ((GetSystemTime() - tmStart)/10000); // Convert 100nsec unit to msec

#if DBG
    if(dwElapsed > MAX_RESPONSE_TIME_FOR_ALERT) {    
        // NON-compliant behaviour
        TRACE(TL_FCP_WARNING,("** ST:%x; AVC Cmd took %d msec to response; CmdType:%d; OpCd:%x\n", Status, dwElapsed, cType, DVcrAVCCmdTable[idxAVCCmd].Opcode));
    } else {
        TRACE(TL_FCP_TRACE,("** ST:%x; AVC Cmd took %d msec to response; CmdType:%d; OpCd:%x\n", Status, dwElapsed, cType, DVcrAVCCmdTable[idxAVCCmd].Opcode));
    }
#endif
   
#ifdef SUPPORT_OPTIMIZE_AVCCMD_RETRIES
    //
    // Collect statistics of AVC command response time during driver loading phase
    // 
    if(!pDevExt->DrvLoadCompleted) {
        if(dwElapsed > pDevExt->AVCCmdRespTimeMax)
            pDevExt->AVCCmdRespTimeMax = dwElapsed;
        if(dwElapsed < pDevExt->AVCCmdRespTimeMin)
            pDevExt->AVCCmdRespTimeMin = dwElapsed;
        pDevExt->AVCCmdRespTimeSum += dwElapsed;
        pDevExt->AVCCmdCount++;
    }
#endif

    // Interim response...
    if (STATUS_PENDING == Status) {      

        // WORKITEM: control command can be in interim for a while!!!
        // Some DV will return interim but it will completed it with a change quickly.
        if(cType == AVC_CTYPE_CONTROL) {
#define MSDV_WAIT_CONTROL_CMD_INTERIM   300
            TRACE(TL_FCP_WARNING,("\'!!!!!!!!!!!  Control Interim-- Wait %d msec !!!!!!!!\n", MSDV_WAIT_CONTROL_CMD_INTERIM));
            DVDelayExecutionThread(MSDV_WAIT_CONTROL_CMD_INTERIM);
#if DBG
            if(DVTraceMask & TL_FCP_TRACE) {
                ASSERT(!IsListEmpty(&pCmdEntry->ListEntry) && "Control Cmd was interim after wait.");
            }
#endif
        }

        KeAcquireSpinLock(&pDevExt->AVCCmdLock, &OldIrql);

        // Check that the Irp didn't complete between the return of IoCallDriver and now
        if (IsListEmpty(&pCmdEntry->ListEntry)) {
            // Enter INTERIM state
            pCmdEntry->cmdState = CMD_STATE_RESP_INTERIM;
            // Return STATUS_MORE_ENTRIES to inform caller that the command is pending.
            pCmdEntry->Status   = STATUS_MORE_ENTRIES;   // xlate to ERROR_MORE_DATA; No yet done with this command so keep the entry in the list

            // We have submitted a control or notify command, and have gotten
            // an Interim response. Put the command in the list so it can be
            // tracked for possible cancellation, and as an indication to the
            // completion routine that we won't be releasing any resources here.
            InsertTailList(&pDevExt->AVCCmdList, &pCmdEntry->ListEntry); pDevExt->cntCommandQueued++;
            pCmdEntry->pProperty = NULL;    // won't be using this, so get rid of it
            TRACE(TL_FCP_TRACE,("\'->AVC command Irp is pending!\n"));
            KeReleaseSpinLock(&pDevExt->AVCCmdLock, OldIrql);
            KeReleaseMutex(&pDevExt->hMutexIssueAVCCmd, FALSE); 
            return pCmdEntry->Status;

        } else {
            // Although IoCallDriver indicated that the command was pending,
            // it has since been completed. The completion routine saw that
            // the command entry had not yet been added to the command list,
            // so put it there to let us know that we need to retain control
            // and free the resources.
            //
            // Temporarily change the status so the cleanup code path will
            // be followed.
            TRACE(TL_FCP_TRACE,("\'-> Cmd Rtns Pending but completed; treat as non-pending! ST:%x\n", pCmdEntry->Status));
            Status = STATUS_SUCCESS;
        }

        KeReleaseSpinLock(&pDevExt->AVCCmdLock, OldIrql);
    } 

    // Status from IoCallDriver can return:
    //    STATUS_PENDING (process above)  // If control, we wait and see if it get completed (risky!!)
    //    STATUS_TIMEOUT 
    //    STATUS_SUCCESS

    if(STATUS_PENDING != Status) {
        // The completion routine is usually the only one that frees the Irp. Is
        // it possible that the completion routine never got called? This will let
        // us know, since the completion routine will always make sure that the
        // command entry's Irp pointer is cleared.
        if(pCmdEntry->pIrp) {
            // If for some reason the completion routine never got called, free the Irp
            if(pCmdEntry->pIrp)
                IoFreeIrp(pCmdEntry->pIrp);
            pCmdEntry->pIrp = NULL;
        }
    }

    //
    // pCmdEntry->Status is the command response Status set in the completion routine, which can be
    //    STATUS_SUCCESS
    //    STATUS_REQ_NOT_ACCEP
    //    STATUS_NOT_SUPPORTED
    //    STATUS_MORE_ENTRIES    // Should not happen!!
    //    STATUS_REQUEST_ABORTED
    //

    // One possible valid command from IoCallDriver is STATUS_TIMEOUT, and
    // this shoull be returned, anything else we will get the status from pCmdEntry->Status
    // which was set in the completion routine.
    if (Status != STATUS_TIMEOUT) 
        Status = pCmdEntry->Status;  // This Status is being returned from this functino

    // Desiding if leaving the command response (entry) in the command list

#ifndef ALWAYS_SET_N_GET_RAW_AVC
    // Not if it is an (1) interim (all STATUS_MORE_ENTRIES); or (2) suceeded RAW AVC response
    if(STATUS_MORE_ENTRIES == Status ||
       VCR_RAW_AVC == pCmdEntry->idxDVCRCmd && STATUS_SUCCESS == Status) {
#else
    // Do not remove entrim response or any RAW AVC command response
    if(STATUS_MORE_ENTRIES == Status ||
       VCR_RAW_AVC == pCmdEntry->idxDVCRCmd) {
#endif
        TRACE(TL_FCP_WARNING,("\'Status:%x; Do not remove (1) interim response or (2) raw AVC command\n", Status));
    } 
    // Else we are done!
    else {
        // It's time to clean up the command
        KeAcquireSpinLock(&pDevExt->AVCCmdLock, &OldIrql);
        if (!IsListEmpty(&pCmdEntry->ListEntry)) {
            RemoveEntryList(&pCmdEntry->ListEntry); pDevExt->cntCommandQueued--;
            InitializeListHead(&pCmdEntry->ListEntry);  // used as a flag for ownership
        }
        KeReleaseSpinLock(&pDevExt->AVCCmdLock, OldIrql);

        // Free the resources
        ExFreePool(pCmdEntry);
        ExFreePool(pAvcIrb);
    }  // else

#if DBG
    if(!NT_SUCCESS(Status)) {
        TRACE(TL_FCP_WARNING,("\'**** DVIssueAVCCmd (exit): St:%x; pCmdEntry:%x; cmdQueued:%d\n", Status, pCmdEntry, pDevExt->cntCommandQueued));
    }
#endif

    KeReleaseMutex(&pDevExt->hMutexIssueAVCCmd, FALSE); 

    return Status;
}



#ifndef OATRUE
#define OATRUE (-1)
#endif
#ifndef OAFALSE
#define OAFALSE (0)
#endif

NTSTATUS 
DVGetExtDeviceProperty(
    IN PDVCR_EXTENSION pDevExt,
    IN PSTREAM_PROPERTY_DESCRIPTOR pSPD,
    OUT PULONG pulActualBytesTransferred
    )
/*++

Routine Description:

    Handle Get external device property.

Arguments:

    pDevExt - Device's extension
    pSPD - Stream property descriptor
    pulActualBytesTransferred - Number of byte transferred.

Return Value:

    NTSTATUS

--*/
{
    NTSTATUS Status = STATUS_SUCCESS;
    PKSPROPERTY_EXTDEVICE_S pExtDeviceProperty;


    PAGED_CODE();

    ASSERT(pDevExt);    
    ASSERT(pSPD);
    ASSERT (pSPD->PropertyOutputSize >= sizeof (KSPROPERTY_EXTDEVICE_S)); 

    pExtDeviceProperty = (PKSPROPERTY_EXTDEVICE_S) pSPD->PropertyInfo;    // pointer to the data

  
    switch (pSPD->Property->Id) {

    case KSPROPERTY_EXTDEVICE_ID:
        if(pDevExt->ulVendorID) {
            // It was not bswap in the monolithic version so for competibility,
            // we will not bswap this.
            pExtDeviceProperty->u.NodeUniqueID[0] = pDevExt->UniqueID.LowPart; 
            pExtDeviceProperty->u.NodeUniqueID[1] = pDevExt->UniqueID.HighPart;
            // TRACE(TL_FCP_WARNING,("Vid:%x; Mid:%x\n", bswap(pDevExt->ulVendorID) >> 8, pDevExt->ulModelID ));
            TRACE(TL_FCP_WARNING,("\'Low:%x; High:%x of UniqueID\n", pDevExt->UniqueID.LowPart, pDevExt->UniqueID.HighPart ));
            Status = STATUS_SUCCESS;
        } else {
            TRACE(TL_FCP_ERROR,("Failed: Vid:%x; Mid:%x\n", bswap(pDevExt->ulVendorID) >> 8, pDevExt->ulModelID ));
            Status = STATUS_UNSUCCESSFUL;
        }
        break;

    case KSPROPERTY_EXTDEVICE_VERSION:
        // AV/C VCR Subunit Specification 2.0.1
        wcscpy(pExtDeviceProperty->u.pawchString, L"2.0.1");  
        Status = STATUS_SUCCESS;
        break;

    case KSPROPERTY_EXTDEVICE_POWER_STATE:       
        switch(pDevExt->PowerState) {
        case PowerDeviceD3:
            pExtDeviceProperty->u.PowerState  = ED_POWER_OFF; 
            break;
        case PowerDeviceD2:
        case PowerDeviceD1:
            pExtDeviceProperty->u.PowerState  = ED_POWER_STANDBY; 
            break;
        default:
        case PowerDeviceD0:
            pExtDeviceProperty->u.PowerState  = ED_POWER_ON; 
            break;
        }
        Status = STATUS_SUCCESS;        
        break;        


    case KSPROPERTY_EXTDEVICE_PORT:
        pExtDeviceProperty->u.DevPort  = DEV_PORT_1394; 
        Status = STATUS_SUCCESS;        
        break;        

    case KSPROPERTY_EXTDEVICE_CAPABILITIES:


        if((GetSystemTime() - pDevExt->tmLastFormatUpdate) > FORMAT_UPDATE_INTERVAL) {
            // Refresh mode of operation whenever capabilities is queried
            // since the mode of operation might have changed and is returned..
            DVGetDevModeOfOperation(pDevExt);

            // Since format can dynamically change, we will query new format here.
            // Note: during data intersection, we compare FrameSize and that is 
            // format related.

            if(!DVGetDevSignalFormat(pDevExt, KSPIN_DATAFLOW_OUT,0)) {
                // If querying its format has failed, we cannot open this stream.
                TRACE(TL_FCP_WARNING,("SRB_GET_DATA_INTERSECTION:Failed getting signal format.\n"));
            }

            // Update system time to reflect last update
            pDevExt->tmLastFormatUpdate = GetSystemTime();  
        }

        // Can record only in VCR mode and has input plug(s).
        pExtDeviceProperty->u.Capabilities.CanRecord  = ((pDevExt->ulDevType == ED_DEVTYPE_VCR) ? (pDevExt->NumInputPlugs > 0 ? OATRUE : OAFALSE): OAFALSE);
        pExtDeviceProperty->u.Capabilities.CanRecordStrobe  = OAFALSE;        
        pExtDeviceProperty->u.Capabilities.HasAudio   = OATRUE;         
        pExtDeviceProperty->u.Capabilities.HasVideo   = OATRUE;        
        pExtDeviceProperty->u.Capabilities.UsesFiles  = OAFALSE;        
        pExtDeviceProperty->u.Capabilities.CanSave    = OAFALSE;
        pExtDeviceProperty->u.Capabilities.DeviceType = pDevExt->ulDevType;        
        pExtDeviceProperty->u.Capabilities.TCRead     = OATRUE;        
        pExtDeviceProperty->u.Capabilities.TCWrite    = OAFALSE; // DV decided        
        pExtDeviceProperty->u.Capabilities.CTLRead    = OAFALSE;  
        pExtDeviceProperty->u.Capabilities.IndexRead  = OAFALSE;        
        pExtDeviceProperty->u.Capabilities.Preroll    = 0L;      // NOT implemented, supposely can reg in INF and then read from registry       
        pExtDeviceProperty->u.Capabilities.Postroll   = 0L;      // NOT implemented, supposely can reg in INF and then read from registry 
        pExtDeviceProperty->u.Capabilities.SyncAcc    = ED_CAPABILITY_UNKNOWN;       
        pExtDeviceProperty->u.Capabilities.NormRate   = ((pDevExt->VideoFormatIndex == FMT_IDX_SD_DVCR_NTSC || pDevExt->VideoFormatIndex == FMT_IDX_SDL_DVCR_NTSC) ? ED_RATE_2997 : ED_RATE_25);
        pExtDeviceProperty->u.Capabilities.CanPreview = OAFALSE;    // View what is in the bus or tape
        pExtDeviceProperty->u.Capabilities.CanMonitorSrc = OATRUE;  // ViewFinder
        pExtDeviceProperty->u.Capabilities.CanTest    = OAFALSE;    // To see if a function is iplemented
        pExtDeviceProperty->u.Capabilities.VideoIn    = OAFALSE;  
        pExtDeviceProperty->u.Capabilities.AudioIn    = OAFALSE;  
        pExtDeviceProperty->u.Capabilities.Calibrate  = OAFALSE;  
        pExtDeviceProperty->u.Capabilities.SeekType   = ED_CAPABILITY_UNKNOWN;  

        TRACE(TL_FCP_INFO,("\'DVCRGetExtDeviceProperty: DeviceType %x\n", pExtDeviceProperty->u.Capabilities.DeviceType));

        Status = STATUS_SUCCESS;               
        break;
       
    default:
        Status = STATUS_NOT_SUPPORTED;        
        break;
    }

    *pulActualBytesTransferred = (Status == STATUS_SUCCESS ? sizeof (KSPROPERTY_EXTDEVICE_S) : 0);

    return Status;
}




NTSTATUS 
DVSetExtDeviceProperty(
    IN PDVCR_EXTENSION pDevExt,
    IN PSTREAM_PROPERTY_DESCRIPTOR pSPD,
    OUT ULONG *pulActualBytesTransferred
    )
/*++

Routine Description:

    Handle Set external device property.

Arguments:

    pDevExt - Device's extension
    pSPD - Stream property descriptor
    pulActualBytesTransferred - Number of byte transferred.

Return Value:

    NTSTATUS

--*/
{
    NTSTATUS Status = STATUS_SUCCESS;
    PKSPROPERTY_EXTDEVICE_S pExtDeviceProperty;

    PAGED_CODE();

    ASSERT(pDevExt);    
    ASSERT(pSPD);
    ASSERT (pSPD->PropertyOutputSize >= sizeof (KSPROPERTY_EXTDEVICE_S)); 

    pExtDeviceProperty = (PKSPROPERTY_EXTDEVICE_S) pSPD->PropertyInfo;    // pointer to the data

  
    switch (pSPD->Property->Id) {
    default:
        Status = STATUS_NOT_SUPPORTED;        
        break;
    }

    *pulActualBytesTransferred = (Status == STATUS_SUCCESS ? sizeof (KSPROPERTY_EXTDEVICE_S) : 0);
 
    return Status;
}

NTSTATUS 
DVGetExtTransportProperty(    
    IN PDVCR_EXTENSION pDevExt,
    IN PSTREAM_PROPERTY_DESCRIPTOR pSPD,
    OUT ULONG *pulActualBytesTransferred
    )
/*++

Routine Description:

    Handle Get external transport property.

Arguments:

    pDevExt - Device's extension
    pSPD - Stream property descriptor
    pulActualBytesTransferred - Number of byte transferred.

Return Value:

    NTSTATUS 

--*/
{
    NTSTATUS Status = STATUS_NOT_SUPPORTED;
    PKSPROPERTY_EXTXPORT_S pXPrtProperty;
    DVCR_AVC_COMMAND idxDVCRCmd;
    AvcCommandType cType = AVC_CTYPE_STATUS;
    BOOL bHasTape = pDevExt->bHasTape;

    PAVCCmdEntry  pCmdEntry;


    PAGED_CODE();

    ASSERT(pDevExt);    
    ASSERT(pSPD);
    ASSERT (pSPD->PropertyOutputSize >= sizeof (KSPROPERTY_EXTXPORT_S)); 

    pXPrtProperty = (PKSPROPERTY_EXTXPORT_S) pSPD->PropertyInfo;    // pointer to the data
    *pulActualBytesTransferred = 0;


    switch (pSPD->Property->Id) {
    case KSPROPERTY_EXTXPORT_CAPABILITIES:
        return STATUS_NOT_IMPLEMENTED;

    case KSPROPERTY_RAW_AVC_CMD:
        pCmdEntry = DVCRFindCmdEntryCompleted( 
            pDevExt, 
            VCR_RAW_AVC,
            DVcrAVCCmdTable[VCR_RAW_AVC].Opcode,
            DVcrAVCCmdTable[VCR_RAW_AVC].CType
            );

        if(pCmdEntry) {
            PAVC_COMMAND_IRB pAvcIrb;

            pAvcIrb = pCmdEntry->pAvcIrb;
            ASSERT(pAvcIrb);
#ifndef ALWAYS_SET_N_GET_RAW_AVC
            // Only successful response has a valid response to return
            if (pCmdEntry->cmdState == CMD_STATE_RESP_ACCEPTED) {
#else
            // Any of these response codes has a response to return, 
            // include "reject", "not implemented" response code
            if (pCmdEntry->cmdState == CMD_STATE_RESP_ACCEPTED ||
                pCmdEntry->cmdState == CMD_STATE_RESP_REJECTED ||
                pCmdEntry->cmdState == CMD_STATE_RESP_NOT_IMPL ||
                pCmdEntry->cmdState == CMD_STATE_RESP_INTERIM) {
#endif
                // bytes for operands plus response, subunit addr, and opcode
                pXPrtProperty->u.RawAVC.PayloadSize = pAvcIrb->OperandLength + 3;
                pXPrtProperty->u.RawAVC.Payload[0] = pAvcIrb->ResponseCode;
                pXPrtProperty->u.RawAVC.Payload[1] = pAvcIrb->SubunitAddr[0];
                pXPrtProperty->u.RawAVC.Payload[2] = pAvcIrb->Opcode;                
                RtlCopyMemory(&pXPrtProperty->u.RawAVC.Payload[3], pAvcIrb->Operands, pAvcIrb->OperandLength);

                TRACE(TL_FCP_WARNING,("\'RawAVCResp: pEntry:%x; State:%x; Status:%x; Sz:%d; Rsp:%x;SuId:%x;OpCd:%x; Opr:[%x %x %x %x]\n",
                    pCmdEntry, pCmdEntry->cmdState, pCmdEntry->Status,
                    pXPrtProperty->u.RawAVC.PayloadSize,
                    pXPrtProperty->u.RawAVC.Payload[0],
                    pXPrtProperty->u.RawAVC.Payload[1],
                    pXPrtProperty->u.RawAVC.Payload[2],
                    pXPrtProperty->u.RawAVC.Payload[3],
                    pXPrtProperty->u.RawAVC.Payload[4],
                    pXPrtProperty->u.RawAVC.Payload[5],
                    pXPrtProperty->u.RawAVC.Payload[6]
                    )); 

                // Final Status
#ifndef ALWAYS_SET_N_GET_RAW_AVC
                Status = pCmdEntry->Status;
#else           
                // If not success, bytes transferred and data will not returned!
                Status = STATUS_SUCCESS;  
#endif
                *pulActualBytesTransferred = sizeof (KSPROPERTY_EXTXPORT_S);
            } else {
                TRACE(TL_FCP_ERROR,("\'RawAVCResp: Found; but pCmdEntry:%x, unexpected cmdState:%d; ST:%x\n", pCmdEntry, pCmdEntry->cmdState, pCmdEntry->Status));
                //ASSERT(pCmdEntry->cmdState == CMD_STATE_RESP_ACCEPTED && "Unexpected command state\n");
                if(pCmdEntry->Status == STATUS_TIMEOUT)
                    Status = STATUS_TIMEOUT;  // if timeout, application may want to try again.
                else
                    Status = STATUS_REQUEST_ABORTED;
                *pulActualBytesTransferred = 0;
            }

            // pIrp is NULL if it has been completed.
            if(pCmdEntry->pIrp) {
                TRACE(TL_FCP_ERROR,("RawAVCResp: pCmdEntry %x; ->pIrp:%x not completd yet!\n", pCmdEntry, pCmdEntry->pIrp));
                ASSERT(pCmdEntry->pIrp == NULL && "pIrp is not completed!");
                IoCancelIrp(pCmdEntry->pIrp);
            }
            // Not used in the completion routine if pIrp->Cancel
            ExFreePool(pCmdEntry);
            ExFreePool(pAvcIrb);
        }
        else {
            TRACE(TL_FCP_ERROR,("\'RAW_AVC_CMD, did not find a match[%x]!\n", 
                *((DWORD *) &DVcrAVCCmdTable[VCR_RAW_AVC].CType) )); 
            *pulActualBytesTransferred = 0;
            Status = STATUS_NOT_FOUND;  // ERROR_MR_MID_NOT_FOUND
        }
        return Status;

    case KSPROPERTY_EXTXPORT_INPUT_SIGNAL_MODE: // MPEG, D-VHS, Analog VHS etc.
        idxDVCRCmd = VCR_INPUT_SIGNAL_MODE;
        break;
    case KSPROPERTY_EXTXPORT_OUTPUT_SIGNAL_MODE: // MPEG, D-VHS, Analog VHS etc.
        idxDVCRCmd = VCR_OUTPUT_SIGNAL_MODE;
        break;
    case KSPROPERTY_EXTXPORT_MEDIUM_INFO:       // cassettte_type and tape_grade_and_write_protect
        idxDVCRCmd = VCR_MEDIUM_INFO;
        break;  
    case KSPROPERTY_EXTXPORT_STATE: 
        idxDVCRCmd = VCR_TRANSPORT_STATE;        
        break; 

    case KSPROPERTY_EXTXPORT_STATE_NOTIFY: 
        // Get final result from previous set command
        pCmdEntry = DVCRFindCmdEntryCompleted( 
            pDevExt, 
            VCR_TRANSPORT_STATE_NOTIFY,
            DVcrAVCCmdTable[VCR_TRANSPORT_STATE_NOTIFY].Opcode,
            DVcrAVCCmdTable[VCR_TRANSPORT_STATE_NOTIFY].CType
            );

        if(pCmdEntry) {
            PAVC_COMMAND_IRB pAvcIrb;

            pAvcIrb = pCmdEntry->pAvcIrb;
            ASSERT(pCmdEntry->pAvcIrb);

            TRACE(TL_FCP_WARNING,("\'->Notify Resp: pCmdEntry:%x; pIrb:%x; %d:[%.2x %.2x %.2x %.2x]\n",
                pCmdEntry, pAvcIrb,
                pAvcIrb->OperandLength + 3,
                pAvcIrb->ResponseCode,
                pAvcIrb->SubunitAddr[0],
                pAvcIrb->Opcode,
                pAvcIrb->Operands[0]
                )); 

            if(pCmdEntry->cmdState == CMD_STATE_RESP_ACCEPTED)
                Status = 
                    DVCRXlateRawAVC(
                        pCmdEntry, 
                        pXPrtProperty
                        );

            // pIrp is NULL if it has been completed.
            if(pCmdEntry->pIrp) {
                TRACE(TL_FCP_ERROR,("XPrtNotifyResp: pCmdEntry %x; ->pIrp:%x not completed; IoCancelIrp(pIrp)\n", pCmdEntry, pCmdEntry->pIrp));
                IoCancelIrp(pCmdEntry->pIrp);
            }
            // These two are not touched in the CompletionRoutine if pIrp->Cancel
            ExFreePool(pCmdEntry);
            ExFreePool(pAvcIrb);

            *pulActualBytesTransferred = STATUS_SUCCESS == Status ? sizeof (KSPROPERTY_EXTXPORT_S) : 0;
        }
        else {
            TRACE(TL_FCP_ERROR,("EXTXPORT_STATE_NOTIFY: no match!\n"));
            *pulActualBytesTransferred = 0;
            Status = STATUS_NOT_FOUND;  // ERROR_MR_MID_NOT_FOUND
        }
        return Status;

    default:
        TRACE(TL_FCP_ERROR,("DVCRGetExtTransportProperty: NOT_IMPLEMENTED Property->Id %d\n", pSPD->Property->Id));        
        return STATUS_NOT_SUPPORTED;                
    }


    Status = DVIssueAVCCommand(pDevExt, cType, idxDVCRCmd, (PVOID) pXPrtProperty);
    TRACE(TL_FCP_TRACE,("\'DVCRGetExtTransportProperty: idxDVCRCmd %d, cmdType %d, Status %x\n", idxDVCRCmd, cType, Status)); 
    *pulActualBytesTransferred = (Status == STATUS_SUCCESS ? sizeof (KSPROPERTY_EXTXPORT_S) : 0);


    if(STATUS_SUCCESS == Status &&
       idxDVCRCmd == VCR_MEDIUM_INFO) {

        // Update Media info
        pDevExt->bHasTape        = pXPrtProperty->u.MediumInfo.MediaPresent;
        pDevExt->bWriteProtected = pXPrtProperty->u.MediumInfo.RecordInhibit;

        TRACE(TL_FCP_TRACE,("\'bHasTape: IN(%d):OUT(%d), ulDevType %d\n", bHasTape, pDevExt->bHasTape, pDevExt->ulDevType));        
    }
 
    return Status;
}




NTSTATUS 
DVSetExtTransportProperty( 
    IN PDVCR_EXTENSION pDevExt,
    IN PSTREAM_PROPERTY_DESCRIPTOR pSPD,
    OUT ULONG *pulActualBytesTransferred
    )
/*++

Routine Description:

    Handle Set external transport property.

Arguments:

    pDevExt - Device's extension
    pSPD - Stream property descriptor
    pulActualBytesTransferred - Number of byte transferr

Return Value:

    NTSTATUS

--*/
{
    NTSTATUS Status = STATUS_SUCCESS;
    PKSPROPERTY_EXTXPORT_S pXPrtProperty;
    DVCR_AVC_COMMAND idxDVCRCmd;
    AvcCommandType cType = AVC_CTYPE_CONTROL;


    PAGED_CODE();

    ASSERT(pDevExt);    
    ASSERT(pSPD);
    ASSERT (pSPD->PropertyOutputSize >= sizeof (KSPROPERTY_EXTXPORT_S)); 

    pXPrtProperty = (PKSPROPERTY_EXTXPORT_S) pSPD->PropertyInfo;    // pointer to the data    
    *pulActualBytesTransferred = 0;

    switch (pSPD->Property->Id) {

    case KSPROPERTY_EXTXPORT_STATE: 
     
         switch (pXPrtProperty->u.XPrtState.Mode) {
// RECORD
         case ED_MODE_RECORD:
             idxDVCRCmd = VCR_RECORD;
             break;
         case ED_MODE_RECORD_FREEZE:
             idxDVCRCmd = VCR_RECORD_PAUSE;
             break;

// PLAY
         case ED_MODE_STEP_FWD:
             idxDVCRCmd = VCR_PLAY_FORWARD_STEP;
             break;
         case ED_MODE_PLAY_SLOWEST_FWD:
             // DVCPRO does not seem to support the standard play slow fwd so this is an alternate
             if(pDevExt->bDVCPro)
                 idxDVCRCmd = VCR_PLAY_FORWARD_SLOWEST2;
             else
                 idxDVCRCmd = VCR_PLAY_FORWARD_SLOWEST;
             break;
         case ED_MODE_PLAY_FASTEST_FWD:
             idxDVCRCmd = VCR_PLAY_FORWARD_FASTEST;
             break;

         case ED_MODE_STEP_REV:
             idxDVCRCmd = VCR_PLAY_REVERSE_STEP;
             break;
         case ED_MODE_PLAY_SLOWEST_REV:
             // DVCPRO does not seem to support the standard play slow rev so this is an alternate
             if(pDevExt->bDVCPro)
                 idxDVCRCmd = VCR_PLAY_REVERSE_SLOWEST2;
             else
                 idxDVCRCmd = VCR_PLAY_REVERSE_SLOWEST;
             break;
         case ED_MODE_PLAY_FASTEST_REV:
             idxDVCRCmd = VCR_PLAY_REVERSE_FASTEST;
             break;

         case ED_MODE_PLAY:
             idxDVCRCmd = VCR_PLAY_FORWARD;
             break;
         case ED_MODE_FREEZE:
             idxDVCRCmd = VCR_PLAY_FORWARD_PAUSE;
             break;


// WIND
         case ED_MODE_STOP:
             idxDVCRCmd = VCR_WIND_STOP;
             break;
         case ED_MODE_FF:
             idxDVCRCmd = VCR_WIND_FAST_FORWARD;
             break;
         case ED_MODE_REW:
             idxDVCRCmd = VCR_WIND_REWIND;
             break;


         default:
             TRACE(TL_FCP_ERROR,("XPrtState.Mode %d not supported\n", pXPrtProperty->u.XPrtState.Mode));        
             return STATUS_NOT_SUPPORTED; 
         }
         break;

    case KSPROPERTY_EXTXPORT_STATE_NOTIFY: 
        idxDVCRCmd = VCR_TRANSPORT_STATE_NOTIFY;
        cType = AVC_CTYPE_NOTIFY;        
        TRACE(TL_FCP_TRACE,("\'->Notify XPrt State Cmd issued.\n"));
        break; 

    case KSPROPERTY_EXTXPORT_LOAD_MEDIUM:  
        idxDVCRCmd = VCR_LOAD_MEDIUM_EJECT;
        break;

    case KSPROPERTY_EXTXPORT_TIMECODE_SEARCH: 
        idxDVCRCmd = VCR_TIMECODE_SEARCH;
        TRACE(TL_FCP_WARNING,("\'KSPROPERTY_EXTXPORT_TIMECODE_SEARCH NOT_SUPPORTED\n"));        
        *pulActualBytesTransferred = 0;
        return STATUS_NOT_SUPPORTED; 
        
    case KSPROPERTY_EXTXPORT_ATN_SEARCH: 
        idxDVCRCmd = VCR_ATN_SEARCH;
        TRACE(TL_FCP_WARNING,("\'KSPROPERTY_EXTXPORT_ATN_SEARCH NOT_SUPPORTED\n"));        
        *pulActualBytesTransferred = 0;
        return STATUS_NOT_SUPPORTED; 
        
    case KSPROPERTY_EXTXPORT_RTC_SEARCH: 
        idxDVCRCmd = VCR_RTC_SEARCH;
        TRACE(TL_FCP_WARNING,("\'KSPROPERTY_EXTXPORT_RTC_SEARCH NOT_SUPPORTED\n"));        
        *pulActualBytesTransferred = 0;
        return STATUS_NOT_SUPPORTED;         

    case KSPROPERTY_RAW_AVC_CMD:
        idxDVCRCmd = VCR_RAW_AVC;   
        if(pXPrtProperty->u.RawAVC.PayloadSize <= MAX_FCP_PAYLOAD_SIZE) { 

            DVcrAVCCmdTable[idxDVCRCmd].CType = pXPrtProperty->u.RawAVC.Payload[0];
            DVcrAVCCmdTable[idxDVCRCmd].SubunitAddr = pXPrtProperty->u.RawAVC.Payload[1];
            DVcrAVCCmdTable[idxDVCRCmd].Opcode = pXPrtProperty->u.RawAVC.Payload[2];
            DVcrAVCCmdTable[idxDVCRCmd].OperandLength = pXPrtProperty->u.RawAVC.PayloadSize - 3;
            RtlCopyMemory(DVcrAVCCmdTable[idxDVCRCmd].Operands, pXPrtProperty->u.RawAVC.Payload + 3, DVcrAVCCmdTable[idxDVCRCmd].OperandLength);

            // extract command type; for RAW AVC, it can be anything.
            cType = pXPrtProperty->u.RawAVC.Payload[0];

            TRACE(TL_FCP_WARNING,("\'DVCRSetExtTransportProperty: Set*, cType %x, PayLoadSize %d, PayLoad %x %x %x %x\n",
                cType,
                pXPrtProperty->u.RawAVC.PayloadSize,
                pXPrtProperty->u.RawAVC.Payload[0],
                pXPrtProperty->u.RawAVC.Payload[1],
                pXPrtProperty->u.RawAVC.Payload[2],
                pXPrtProperty->u.RawAVC.Payload[3]
                )); 

        } else {
            Status = STATUS_INVALID_PARAMETER;
            *pulActualBytesTransferred = 0;
            return Status;
        }
        break;

    default:
        TRACE(TL_FCP_ERROR,("DVCRSetExtTransportProperty: NOT_IMPLEMENTED Property->Id %d\n", pSPD->Property->Id));        
        return STATUS_NOT_SUPPORTED; 
    }

    Status = DVIssueAVCCommand(pDevExt, cType, idxDVCRCmd, (PVOID) pXPrtProperty);

#ifdef SUPPORT_XPRT_STATE_WAIT_FOR_STABLE
#ifdef READ_CUTOMIZE_REG_VALUES


    // Wait for the transport state change to be stablized.
    // This is only necessary for DV camcorder that reject (or not accept) command following
    // a transport state change.  Most of application will issue a transport state control
    // command follows by a query transport state status command.  The later command usually
    // failed.  A wait will allow some time for the transport mechanism to stablized and therefore
    // accepting command again.  This ought to be done in a registry set in an INF file.
    if(STATUS_SUCCESS == Status &&
          (KSPROPERTY_EXTXPORT_STATE == pSPD->Property->Id ||
             (VCR_RAW_AVC == pSPD->Property->Id && cType == AVC_CTYPE_CONTROL && 
                 (pXPrtProperty->u.RawAVC.Payload[2] == OPC_RECORD ||
                  pXPrtProperty->u.RawAVC.Payload[2] == OPC_PLAY ||
                  pXPrtProperty->u.RawAVC.Payload[2] == OPC_WIND
                 )           
             )
          )
      ) { 

#define MAX_XPRT_WAIT 5000
        if(pDevExt->XprtStateChangeWait > MAX_XPRT_WAIT)
            pDevExt->XprtStateChangeWait = MAX_XPRT_WAIT;

        if(pDevExt->XprtStateChangeWait > 0) {
            TRACE(TL_FCP_WARNING,("^^^^^^ Delay %d msec for Xprt state to stablized!^^^^^^\n", pDevExt->XprtStateChangeWait));
            DVDelayExecutionThread(pDevExt->XprtStateChangeWait);
        }
    }
#endif
#endif

    TRACE(TL_FCP_TRACE,("\'DVCRSetExtTransportProperty: idxDVCRCmd %d, Status %x\n", idxDVCRCmd, Status));
    *pulActualBytesTransferred = (Status == STATUS_SUCCESS ? sizeof (PKSPROPERTY_EXTXPORT_S) : 0);

    return Status;
}

NTSTATUS 
DVGetTimecodeReaderProperty(
    IN PDVCR_EXTENSION pDevExt,
    IN PSTREAM_PROPERTY_DESCRIPTOR pSPD,
    OUT PULONG pulActualBytesTransferred
    )
/*++

Routine Description:

Arguments:

Return Value:

    NTSTATUS

--*/
{
    NTSTATUS Status = STATUS_SUCCESS;
    PKSPROPERTY_TIMECODE_S pTmCdReaderProperty;
    DVCR_AVC_COMMAND idxDVCRCmd;


    PAGED_CODE();

    ASSERT (pSPD->PropertyOutputSize >= sizeof (KSPROPERTY_TIMECODE_S)); 

    pTmCdReaderProperty = (PKSPROPERTY_TIMECODE_S) pSPD->PropertyInfo;    // pointer to the data
    *pulActualBytesTransferred = 0;
  
    switch (pSPD->Property->Id) {

    case KSPROPERTY_TIMECODE_READER:
        idxDVCRCmd = VCR_TIMECODE_READ;
#ifdef MSDV_SUPPORT_EXTRACT_SUBCODE_DATA
        // There can only be one active stream.
        if(pDevExt->cndStrmOpen == 1 &&            
           pDevExt->paStrmExt[pDevExt->idxStreamNumber]->StreamState == KSSTATE_RUN) {

            if(pDevExt->paStrmExt[pDevExt->idxStreamNumber]->bTimecodeUpdated) {
                // Once it is read, it is stale.
                pDevExt->paStrmExt[pDevExt->idxStreamNumber]->bTimecodeUpdated = FALSE;

                pTmCdReaderProperty->TimecodeSamp.timecode.dwFrames = 
                    (((DWORD) pDevExt->paStrmExt[pDevExt->idxStreamNumber]->Timecode[0]) << 24) |
                    (((DWORD) pDevExt->paStrmExt[pDevExt->idxStreamNumber]->Timecode[1]) << 16) |
                    (((DWORD) pDevExt->paStrmExt[pDevExt->idxStreamNumber]->Timecode[2]) <<  8) |
                     ((DWORD) pDevExt->paStrmExt[pDevExt->idxStreamNumber]->Timecode[3]);

                *pulActualBytesTransferred = (Status == STATUS_SUCCESS ? sizeof (KSPROPERTY_TIMECODE_S) : 0);
                return STATUS_SUCCESS;
            }
            else {
                TRACE(TL_FCP_TRACE,("\'bTimecode stale, issue AVC command to read it.\n"));
            }
        }
#endif
        break;

    case KSPROPERTY_ATN_READER:
        idxDVCRCmd = VCR_ATN_READ;
#ifdef MSDV_SUPPORT_EXTRACT_SUBCODE_DATA

        // There can only be one active stream.
        if(pDevExt->cndStrmOpen == 1 && 
           pDevExt->paStrmExt[pDevExt->idxStreamNumber]->StreamState == KSSTATE_RUN) {

            if(pDevExt->paStrmExt[pDevExt->idxStreamNumber]->bATNUpdated) {
                // Once it is read, it is stale.
                pDevExt->paStrmExt[pDevExt->idxStreamNumber]->bATNUpdated = FALSE;

                pTmCdReaderProperty->TimecodeSamp.timecode.dwFrames = 
                    pDevExt->paStrmExt[pDevExt->idxStreamNumber]->AbsTrackNumber >> 1;
                pTmCdReaderProperty->TimecodeSamp.dwUser = 
                    pDevExt->paStrmExt[pDevExt->idxStreamNumber]->AbsTrackNumber & 0x00000001;

                *pulActualBytesTransferred = (Status == STATUS_SUCCESS ? sizeof (KSPROPERTY_TIMECODE_S) : 0);            
                return STATUS_SUCCESS;
            }
            else {
                TRACE(TL_FCP_WARNING,("\'bATN stale, issue AVC command to read it.\n"));
            }
        }
#endif
        break;

    case KSPROPERTY_RTC_READER:
        idxDVCRCmd = VCR_RTC_READ;
        break;

    default:
        TRACE(TL_FCP_ERROR,("DVCRGetTimecodeReaderProperty: NOT_IMPLEMENTED Property->Id %d\n", pSPD->Property->Id));        
        return STATUS_NOT_SUPPORTED; 
    }

    Status = 
        DVIssueAVCCommand(
            pDevExt, 
            AVC_CTYPE_STATUS, 
            idxDVCRCmd, 
            (PVOID) pTmCdReaderProperty
            );  

    TRACE(TL_FCP_TRACE,("\'DVCRGetTimecodeReaderProperty: idxDVCRCmd %d, Status %x\n", idxDVCRCmd, Status));     

    *pulActualBytesTransferred = (Status == STATUS_SUCCESS ? sizeof (KSPROPERTY_TIMECODE_S) : 0);
 
    return Status;
}

NTSTATUS 
DVMediaSeekingProperty(
    IN PDVCR_EXTENSION pDevExt,
    IN PSTREAM_PROPERTY_DESCRIPTOR pSPD,
    OUT PULONG pulActualBytesTransferred
    )
/*++

Routine Description:

Arguments:

Return Value:

    NTSTATUS

--*/
{
    NTSTATUS Status = STATUS_SUCCESS;
    GUID * pTimeFormatGuid;
    KSMULTIPLE_ITEM * pMultipleItem;

    PAGED_CODE();


    *pulActualBytesTransferred = 0;
  
    switch (pSPD->Property->Id) {

    case KSPROPERTY_MEDIASEEKING_FORMATS:
        // Its is KSMULTIPLE_ITEM so it is a two step process to return the data:
        // (1) return size in pActualBytesTransferred with STATUS_BUFFER_OVERFLOW
        // (2) 2nd time to get its actual data.
        if(pSPD->PropertyOutputSize == 0) {
            *pulActualBytesTransferred = sizeof(KSMULTIPLE_ITEM) + sizeof(GUID);
            Status = STATUS_BUFFER_OVERFLOW;
        
        } else if(pSPD->PropertyOutputSize >= (sizeof(KSMULTIPLE_ITEM) + sizeof(GUID))) {
            pMultipleItem = (KSMULTIPLE_ITEM *) pSPD->PropertyInfo;    // pointer to the data
            pMultipleItem->Count = 1;
            pMultipleItem->Size  = sizeof(KSMULTIPLE_ITEM) + sizeof(GUID);
            pTimeFormatGuid = (GUID *) (pMultipleItem + 1);    // pointer to the data
            memcpy(pTimeFormatGuid, &KSTIME_FORMAT_MEDIA_TIME, sizeof(GUID));
            *pulActualBytesTransferred = sizeof(KSMULTIPLE_ITEM) + sizeof(GUID);
            Status = STATUS_SUCCESS;         

        } else {
            TRACE(TL_FCP_ERROR,("DVCRMediaSeekingProperty: KSPROPERTY_MEDIASEEKING_FORMAT; STATUS_INVALID_PARAMETER\n"));
            Status = STATUS_INVALID_PARAMETER;
        }  
        break;

    default:
        TRACE(TL_FCP_ERROR,("\'DVCRMediaSeekingProperty:Not supported ID %d\n", pSPD->Property->Id));
        return STATUS_NOT_SUPPORTED;         
    }

    return Status;
}



NTSTATUS
DVGetDeviceProperty(
    IN PDVCR_EXTENSION     pDevExt,
    IN PSTREAM_PROPERTY_DESCRIPTOR pSPD,
    IN PULONG pulActualBytesTransferred
    )
/*++

Routine Description:

    Handles Get operations for all adapter properties.

Arguments:   

Return Value:

    NTSTATUS

--*/
{
    NTSTATUS Status;

    PAGED_CODE();


    if (IsEqualGUID (&PROPSETID_EXT_DEVICE, &pSPD->Property->Set)) {
        Status = 
            DVGetExtDeviceProperty(              
                pDevExt,
                pSPD,
                pulActualBytesTransferred
                );
    } 
    else 
    if (IsEqualGUID (&PROPSETID_EXT_TRANSPORT, &pSPD->Property->Set)) {
        Status = 
            DVGetExtTransportProperty(
                pDevExt,
                pSPD,
                pulActualBytesTransferred
                );
    } 
    else 
    if (IsEqualGUID (&PROPSETID_TIMECODE_READER, &pSPD->Property->Set)) {
        Status = 
            DVGetTimecodeReaderProperty(
                pDevExt,
                pSPD,
                pulActualBytesTransferred
                );
    } 
    else 
    if (IsEqualGUID (&KSPROPSETID_MediaSeeking, &pSPD->Property->Set)) {

        Status = 
            DVMediaSeekingProperty(                
                pDevExt,
                pSPD, 
                pulActualBytesTransferred
                ); 
        
    } else {
        //
        // We should never get here
        //
        Status = STATUS_NOT_SUPPORTED;
        TRACE(TL_FCP_ERROR,("get unknown property\n"));
        ASSERT(FALSE);
    }

    return Status;
}



NTSTATUS
DVSetDeviceProperty(
    IN PDVCR_EXTENSION     pDevExt,  
    IN PSTREAM_PROPERTY_DESCRIPTOR pSPD,
    IN PULONG pulActualBytetransferred
    )
/*++

Routine Description:

    Handles Set operations for all adapter properties.

Arguments:

Return Value:

    NTSTATUS

--*/

{
    NTSTATUS Status;
    PAGED_CODE();


    if (IsEqualGUID (&PROPSETID_EXT_DEVICE, &pSPD->Property->Set)) {
        Status = 
            DVSetExtDeviceProperty(
                pDevExt,
                pSPD,
                pulActualBytetransferred
                );
    } 
    else 
    if (IsEqualGUID (&PROPSETID_EXT_TRANSPORT, &pSPD->Property->Set)) {
        Status = 
            DVSetExtTransportProperty(
                pDevExt,
                pSPD,
                pulActualBytetransferred
                );
    } 
    else {
        Status = STATUS_NOT_SUPPORTED;

        //
        // We should never get here
        //
        TRACE(TL_FCP_ERROR,("set unknown property\n"));
        ASSERT(FALSE);
    }

    return Status;
}
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\drivers\wdm\capture\mini\msdv\msdvavc.h ===
/*++

Module Name:

    MsdvAvc.h

Abstract:

    Header file for MsdvAvc.c.

Author:   

    Yee J. Wu 27-July-99

Environment:

    Kernel mode only

Revision History:


--*/

#ifndef _MSDVAVC_INC
#define _MSDVAVC_INC

#include "XPrtDefs.h"  // WdmCap directory; derived from DShow's edevdefs.h
#include "EDevCtrl.h"  // External Device COM interface structures




// 
// The index MUST match DVcrAVCCmdTable[]
//
typedef enum {

    DV_UNIT_INFO = 0
    ,DV_SUBUNIT_INFO
    ,DV_CONNECT_AV_MODE

	,DV_VEN_DEP_CANON_MODE    // Vendor denpendent mode of operation for Canon DV that does not support ConnectDV
    ,DV_VEN_DEP_DVCPRO        // Vendor depend cmd to detect DVC PRO tape format

    ,DV_IN_PLUG_SIGNAL_FMT
    ,DV_OUT_PLUG_SIGNAL_FMT   // to determine if it is a PAL or NTSC

    ,VCR_TIMECODE_SEARCH 
    ,VCR_TIMECODE_READ

    ,VCR_ATN_SEARCH 
    ,VCR_ATN_READ

    ,VCR_RTC_SEARCH 
    ,VCR_RTC_READ

    ,VCR_OPEN_MIC_CLOSE
    ,VCR_OPEN_MIC_READ
    ,VCR_OPEN_MIC_WRITE
    ,VCR_OPEN_MIC_STATUS

    ,VCR_READ_MIC

    ,VCR_WRITE_MIC

    ,VCR_OUTPUT_SIGNAL_MODE
    ,VCR_INPUT_SIGNAL_MODE

    ,VCR_LOAD_MEDIUM_EJECT

    ,VCR_RECORD
    ,VCR_RECORD_PAUSE

    ,VCR_PLAY_FORWARD_STEP
    ,VCR_PLAY_FORWARD_SLOWEST
    ,VCR_PLAY_FORWARD_SLOWEST2
    ,VCR_PLAY_FORWARD_FASTEST

    ,VCR_PLAY_REVERSE_STEP
    ,VCR_PLAY_REVERSE_SLOWEST
    ,VCR_PLAY_REVERSE_SLOWEST2
    ,VCR_PLAY_REVERSE_FASTEST

    ,VCR_PLAY_FORWARD
    ,VCR_PLAY_FORWARD_PAUSE

    ,VCR_WIND_STOP
    ,VCR_WIND_REWIND
    ,VCR_WIND_FAST_FORWARD

    ,VCR_TRANSPORT_STATE
    ,VCR_TRANSPORT_STATE_NOTIFY

    ,VCR_MEDIUM_INFO

    ,VCR_RAW_AVC
    
} DVCR_AVC_COMMAND, *PDVCR_AVC_COMMAND;



#define MAX_FCP_PAYLOAD_SIZE 512

//
// CTYPE definitions (in bit-map form... should correlate with AvcCommandType from avc.h)
//
typedef enum {
    CMD_CONTROL  = 0x01
   ,CMD_STATUS   = 0x02
   ,CMD_SPEC_INQ = 0x04
   ,CMD_NOTIFY   = 0x08
   ,CMD_GEN_INQ  = 0x10
} BITMAP_CTYPE;

typedef enum {
    CMD_STATE_UNDEFINED   
   ,CMD_STATE_ISSUED 
   ,CMD_STATE_RESP_ACCEPTED
   ,CMD_STATE_RESP_REJECTED
   ,CMD_STATE_RESP_NOT_IMPL           
   ,CMD_STATE_RESP_INTERIM
   ,CMD_STATE_ABORTED
} AVC_CMD_STATE, *PAVC_CMD_STATE;


// An AVC command entry 
typedef struct _AVC_CMD_ENTRY {
    LIST_ENTRY      ListEntry;
    PDVCR_EXTENSION pDevExt;        
    PIRP            pIrp;           // The Irp associated with this command
    PAVC_COMMAND_IRB pAvcIrb;       // points to the AVC command information
	PVOID           pProperty;      // Data from/to COM interface
    DVCR_AVC_COMMAND idxDVCRCmd;    // Used to check for RAW AVC command, which requires special processing
    AVC_CMD_STATE   cmdState;       // Issuing, interim, completed
    NTSTATUS        Status;         // To save the results of response parsing
    AvcCommandType  cmdType;        // Type of command: Control, Status. Notify, Gen or Spec Inquery
    BYTE            OpCode;         // Since the opcode in response frame of TRANSITION and STABLE can be different from the COMMAND frame
    BYTE            Reserved[3];    // Pack to DWORD
} AVCCmdEntry, *PAVCCmdEntry;



#define CMD_IMPLEMENTED       1
#define CMD_NOT_IMPLEMENTED   0
#define CMD_UNDETERMINED      0xffffffff   // -1


typedef struct {    
    DVCR_AVC_COMMAND command; // VCR_PLAY_FORWARD
    LONG   lCmdImplemented;   // 1:Implemented, 0:NotImpelemnted; -1:UnDetermined

    ULONG  ulRespFlags;       // DVCR_AVC_SEND

    ULONG  ulCmdSupported;    // one or more of constants defined in BITMAP_CTYPE

    LONG   OperandLength;      // -1 = variable length

    BYTE   CType;
    BYTE   SubunitAddr;
    BYTE   Opcode;

    BYTE   Operands[MAX_AVC_OPERAND_BYTES];

} KSFCP_PACKET, *PKSFCP_PACKET;



#define OPC_TIMECODE          0x51
#define OPC_OPEN_MIC          0x60
#define OPC_READ_MIC          0x61
#define OPC_WRITE_MIC         0x62
#define OPC_INPUT_SIGNAL_MODE 0x79
#define OPC_LOAD_MEDIUM       0xc1
#define OPC_RECORD            0xc2
#define OPC_PLAY              0xc3
#define OPC_WIND              0xc4
#define OPC_TRANSPORT_STATE   0xd0
#define OPC_MEDIUM_INFO       0xda




#define UNIT_TYPE_ID_VCR      0x20  // VCR    00100:000; 00100 == 4 == VCR,    000 == instancve number
#define UNIT_TYPE_ID_CAMERA   0x38  // Camera 00111:000; 00111 == 7 == Camera, 000 == instancve number
#define UNIT_TYPE_ID_DV       0xff  // DV UNIT as a whole


// Vendor IDs that require special treatments
#define VENDOR_ID_MASK        0x00ffffff
#define VENDORID_CANON        0x85   //  VEN_85   : Vendor Dependent command for ModeOfOperation
#define VENDORID_PANASONIC    0x8045 //  VEN_8045 : DVCPRO?
#define VENDORID_SAMSUNG      0xf0   //  VEN_f0   : exception for AVC Command Retries




#endif


NTSTATUS  
DVIssueAVCCommand (
    IN PDVCR_EXTENSION pDevExt, 
    IN AvcCommandType cType,
    IN DVCR_AVC_COMMAND idxAVCCmd,
    IN PVOID pProperty
    );


void
DVAVCCmdResetAfterBusReset(
    PDVCR_EXTENSION pDevExt
    );


NTSTATUS
DVGetDeviceProperty(
    IN PDVCR_EXTENSION     pDevExt,
    IN PSTREAM_PROPERTY_DESCRIPTOR pSPDesc,
    OUT PULONG pulActualBytetransferred
    );


NTSTATUS
DVSetDeviceProperty(
    IN PDVCR_EXTENSION     pDevExt,  
    IN PSTREAM_PROPERTY_DESCRIPTOR pSPD,
    IN PULONG pulActualBytetransferred
    );
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\drivers\wdm\capture\mini\inc\winme\61883.h ===
/*++
Copyright (c) 1998-99  Microsoft Corporation

Module Name:

    61883.h

Abstract:

    The public header for clients of the 61883 Class.

Author:

    WGJ
    PSB

--*/

//
// Class GUID
//
// {7EBEFBC0-3200-11d2-B4C2-00A0C9697D07}
DEFINE_GUID(GUID_61883_CLASS, 0x7ebefbc0, 0x3200, 0x11d2, 0xb4, 0xc2, 0x0, 0xa0, 0xc9, 0x69, 0x7d, 0x7);

//
// IOCTL Definitions
//
#define IOCTL_61883_CLASS                       CTL_CODE(            \
                                                FILE_DEVICE_UNKNOWN, \
                                                0x91,                \
                                                METHOD_IN_DIRECT,    \
                                                FILE_ANY_ACCESS      \
                                                )


//
// Current 61883 DDI Version
//
#define CURRENT_61883_DDI_VERSION               0x1

//
// INIT_61883_HEADER Macro
//
#define INIT_61883_HEADER( Av61883, Request )             \
        (Av61883)->Function = Request;                    \
        (Av61883)->Version = CURRENT_61883_DDI_VERSION;

//
// 61883 I/O Request Functions
//
enum {

    Av61883_GetUnitInfo,
    Av61883_SetUnitInfo,

    NotSupported0,
    Av61883_GetPlugHandle,
    Av61883_GetPlugState,
    Av61883_Connect,
    Av61883_Disconnect,

    Av61883_AttachFrame,
    Av61883_CancelFrame,
    Av61883_Talk,
    Av61883_Listen,
    Av61883_Stop,

    Av61883_SendFcpRequest,
    Av61883_GetFcpResponse,

    NotSupported1,

    Av61883_MAX
};

//
// Plug States
//
#define CMP_PLUG_STATE_IDLE                 0
#define CMP_PLUG_STATE_READY                1
#define CMP_PLUG_STATE_SUSPENDED            2
#define CMP_PLUG_STATE_ACTIVE               3

//
// Connect Speeds (not the same as 1394 speed flags!!)
//
#define CMP_SPEED_S100                      0x00
#define CMP_SPEED_S200                      0x01
#define CMP_SPEED_S400                      0x02

//
// CIP Frame Flags
//
#define CIP_VALIDATE_FIRST_SOURCE           0x00000001
#define CIP_VALIDATE_ALL_SOURCE             0x00000002
#define CIP_STRIP_SOURCE_HEADER             0x00000004
#define CIP_USE_SOURCE_HEADER_TIMESTAMP     0x00000008
#define CIP_DV_STYLE_SYT                    0x00000010
#define CIP_AUDIO_STYLE_SYT                 0x00000020

//
// CIP Status Codes
//
#define CIP_STATUS_SUCCESS                  0x00000000
#define CIP_STATUS_CORRUPT_FRAME            0x00000001
#define CIP_STATUS_FIRST_FRAME              0x00000002

//
// Plug Type
//
typedef enum {
    CMP_PlugOut = 0,
    CMP_PlugIn
} CMP_PLUG_TYPE;

//
// Connect Type
//
typedef enum {
    CMP_Broadcast = 0,
    CMP_PointToPoint
} CMP_CONNECT_TYPE;

//
// Client Request Structures
//

//
// GetUnitInfo nLevel's
//
#define GET_UNIT_INFO_IDS               0x00000001      // Retrieves IDs of Unit
#define GET_UNIT_INFO_CAPABILITIES      0x00000002      // Retrieves Capabilities of Unit

typedef struct _GET_UNIT_IDS {

    //
    // UniqueID
    OUT LARGE_INTEGER       UniqueID;
    //
    // VendorID
    //
    OUT ULONG               VendorID;

    //
    // ModelID
    //
    OUT ULONG               ModelID;

    //
    // VendorText Length
    //
    OUT ULONG               ulVendorLength;

    //
    // VendorText String
    //
    OUT PWSTR               VendorText;

    //
    // ModelText Length
    //
    OUT ULONG               ulModelLength;

    //
    // ModelText String
    //
    OUT PWSTR               ModelText;

} GET_UNIT_IDS, *PGET_UNIT_IDS;

typedef struct _GET_UNIT_CAPABILITIES {

    //
    // Number of Output Plugs supported by device
    //
    OUT ULONG               NumOutputPlugs;

    //
    // Number of Input Plugs supported by device
    //
    OUT ULONG               NumInputPlugs;

    //
    // MaxDataRate
    //
    OUT ULONG               MaxDataRate;

    //
    // CTS Flags
    //
    OUT ULONG               CTSFlags;

    //
    // Hardware Flags
    //
    OUT ULONG               HardwareFlags;

} GET_UNIT_CAPABILITIES, *PGET_UNIT_CAPABILITIES;

//
// GetUnitInfo
//
typedef struct _GET_UNIT_INFO {

    IN ULONG                nLevel;

    IN OUT PVOID            Information;

} GET_UNIT_INFO, *PGET_UNIT_INFO;

//
// SetUnitInfo
//
typedef struct _SET_UNIT_INFO {

    IN ULONG                nLevel;

    IN OUT PVOID            Information;

} SET_UNIT_INFO, *PSET_UNIT_INFO;

//
// GetPlugHandle
//
typedef struct _CMP_GET_PLUG_HANDLE {

    //
    // Requested Plug Number
    //
    IN ULONG                PlugNum;

    //
    // Requested Plug Type
    //
    IN CMP_PLUG_TYPE        Type;

    //
    // Returned Plug Handle
    //
    OUT HANDLE              hPlug;

} CMP_GET_PLUG_HANDLE, *PCMP_GET_PLUG_HANDLE;

//
// GetPlugState
//
typedef struct _CMP_GET_PLUG_STATE {

    //
    // Plug Handle
    //
    IN HANDLE               hPlug;

    //
    // Current State
    //
    OUT ULONG               State;

    //
    // Current Data Rate
    //
    OUT ULONG               DataRate;

    //
    // Current Payload Size
    //
    OUT ULONG               Payload;

    //
    // Number of Broadcast Connections
    //
    OUT ULONG               BC_Connections;

    //
    // Number of Point to Point Connections
    //
    OUT ULONG               PP_Connections;

} CMP_GET_PLUG_STATE, *PCMP_GET_PLUG_STATE;

//
// CipDataFormat
//
typedef struct _CIP_DATA_FORMAT {

    //
    // FMT and FDF either known, or discovered
    // via AV/C command
    //
    UCHAR                   FMT;
    UCHAR                   FDF_hi;
    UCHAR                   FDF_mid;
    UCHAR                   FDF_lo;

    //
    // SPH as defined by IEC-61883
    //
    BOOLEAN                 bHeader;

    //
    // QPC as defined by IEC-61883
    //
    UCHAR                   Padding;

    //
    // DBS as defined by IEC-61883
    //
    UCHAR                   BlockSize;

    //
    // FN as defined by IEC-61883
    //
    UCHAR                   Fraction;

    //
    // BlockPeriod - TX Only
    //
    ULONG                   BlockPeriod;

} CIP_DATA_FORMAT, *PCIP_DATA_FORMAT;

//
// Connect
//
typedef struct _CMP_CONNECT {

    //
    // Output Plug Handle
    //
    IN HANDLE               hOutputPlug;

    //
    // Input Plug Handle
    //
    IN HANDLE               hInputPlug;

    //
    // Requested Connect Type
    //
    IN CMP_CONNECT_TYPE     Type;

    //
    // Requested Data Format - TX Only
    //
    IN CIP_DATA_FORMAT      Format;

    //
    // Returned Connect Handle
    //
    OUT HANDLE              hConnect;

} CMP_CONNECT, *PCMP_CONNECT;

//
// Disconnect
//
typedef struct _CMP_DISCONNECT {

    //
    // Connect Handle to Disconnect
    //
    IN HANDLE               hConnect;

} CMP_DISCONNECT, *PCMP_DISCONNECT;

//
// CIP Frame typedef
//
typedef struct _CIP_FRAME CIP_FRAME, *PCIP_FRAME;

//
// ValidateInfo Struct. returned on pfnValidate.
//
typedef struct _CIP_VALIDATE_INFO {

    //
    // Connection Handle
    //
    HANDLE                  hConnect;

    //
    // Validate Context
    //
    PVOID                   Context;

    //
    // TimeStamp for current source packet
    //
    CYCLE_TIME              TimeStamp;

    //
    // Packet offset for current source packet
    //
    PUCHAR                  Packet;

} CIP_VALIDATE_INFO, *PCIP_VALIDATE_INFO;

//
// NotifyInfo Struct. returned on pfnNotify
//
typedef struct _CIP_NOTIFY_INFO {

    //
    // Connection Handle
    //
    HANDLE                  hConnect;

    //
    // Notify Context
    //
    PVOID                   Context;

    //
    // Frame
    //
    PCIP_FRAME              Frame;

} CIP_NOTIFY_INFO, *PCIP_NOTIFY_INFO;

//
// Validate & Notify Routines
//
typedef
ULONG
(*PCIP_VALIDATE_ROUTINE) (
    IN PCIP_VALIDATE_INFO   ValidateInfo
    );

typedef
ULONG
(*PCIP_NOTIFY_ROUTINE) (
    IN PCIP_NOTIFY_INFO     NotifyInfo
    );

//
// CIP Frame Struct
//
struct _CIP_FRAME {

    IN PCIP_FRAME               pNext;              // chain multiple frames together

    IN ULONG                    Flags;              //specify flag options

    IN PCIP_VALIDATE_ROUTINE    pfnValidate;        //backdoor

    IN PVOID                    ValidateContext;

    IN PCIP_NOTIFY_ROUTINE      pfnNotify;          //completion

    IN PVOID                    NotifyContext;

    OUT CYCLE_TIME              Timestamp;

    OUT ULONG                   Status;

    IN OUT PUCHAR               Packet;             //the locked buffer 
};

//
// CIP Attach Frame Structure
//
typedef struct _CIP_ATTACH_FRAME {

    HANDLE                  hConnect;           // Connect Handle

    ULONG                   FrameLength;        // Frame Length

    ULONG                   SourceLength;       // Source Length

    PCIP_FRAME              Frame;              // Frame

} CIP_ATTACH_FRAME, *PCIP_ATTACH_FRAME;

//
// CIP Cancel Frame Structure
//
typedef struct _CIP_CANCEL_FRAME {

    IN HANDLE               hConnect;

    IN PCIP_FRAME           Frame;

} CIP_CANCEL_FRAME, *PCIP_CANCEL_FRAME;

//
// CIP Talk Structure
//
typedef struct _CIP_TALK {

    //
    // Connect Handle
    //
    IN HANDLE               hConnect;

} CIP_TALK, *PCIP_TALK;

//
// CIP Listen Structure
//
typedef struct _CIP_LISTEN {

    //
    // Connect Handle
    //
    IN HANDLE               hConnect;

} CIP_LISTEN, *PCIP_LISTEN;

//
// CIP Stop Structure
//
typedef struct _CIP_STOP {

    //
    // Connect Handle
    //
    IN HANDLE               hConnect;

} CIP_STOP, *PCIP_STOP;

//
// FCP Frame Format
//
typedef struct _FCP_FRAME {
    UCHAR               ctype:4;
    UCHAR               cts:4;
    UCHAR               payload[511];
} FCP_FRAME, *PFCP_FRAME;

//
// FCP Request Structure
//
typedef struct _FCP_Request {
    IN ULONG            Length;
    IN PFCP_FRAME       Frame;
} FCP_REQUEST, *PFCP_REQUEST;

//
// FCP Response Structure
//
typedef struct _FCP_Response {
    IN OUT ULONG        Length;
    IN OUT PFCP_FRAME   Frame;
} FCP_RESPONSE, *PFCP_RESPONSE;

//
// Av61883 Struct
//
typedef struct _AV_61883_REQUEST {

    //
    // Requested Function
    //
    ULONG       Function;

    //
    // Selected DDI Version
    //
    ULONG       Version;

    //
    // Flags
    //
    ULONG       Flags;

    union {

        GET_UNIT_INFO               GetUnitInfo;
        SET_UNIT_INFO               SetUnitInfo;

        CMP_GET_PLUG_HANDLE         GetPlugHandle;
        CMP_GET_PLUG_STATE          GetPlugState;
        CMP_CONNECT                 Connect;
        CMP_DISCONNECT              Disconnect;

        CIP_ATTACH_FRAME            AttachFrame;
        CIP_CANCEL_FRAME            CancelFrame;
        CIP_TALK                    Talk;
        CIP_LISTEN                  Listen;
        CIP_STOP                    Stop;

        FCP_REQUEST                 Request;
        FCP_RESPONSE                Response;
    };
} AV_61883_REQUEST, *PAV_61883_REQUEST;
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\drivers\wdm\capture\mini\msdv\msdvdef.h ===
/*++

Copyright (C) Microsoft Corporation, 1999 - 2000 

Module Name:

    msdvdef.h

Abstract:

    Header file for all of msdv (digital camcorder)

Last changed by:
    
    $Author::                $

Environment:

    Kernel mode only

Revision History:

    $Revision::                    $
    $Date::                        $

--*/

#ifndef _DVCRDEF_INC
#define _DVCRDEF_INC

//
// Allocate memory with 'Msdv' tag
//

#ifdef ExAllocatePool
#undef ExAllocatePool
#endif
#undef ExAllocatePool
#define ExAllocatePool(type, size) ExAllocatePoolWithTag (type, size, 'vdsM')


//
// Need to reference this in PSTRMEX
//
typedef struct _DVCR_EXTENSION;



// 
// The index MUST match 
//
typedef enum {

    FMT_IDX_SD_DVCR_NTSC = 0,
    FMT_IDX_SD_DVCR_PAL,

#ifdef MSDV_SUPPORT_HD_DVCR
    FMT_IDX_HD_DVCR_NTSC,
    FMT_IDX_HD_DVCR_PAL,
#endif

#ifdef MSDV_SUPPORT_SDL_DVCR
    FMT_IDX_SDL_DVCR_NTSC,
    FMT_IDX_SDL_DVCR_PAL,
#endif

} FMT_INDEX, *PFMT_INDEX;



#if DBG
//
// Collect statistic for real time data transmission 
//
#define MAX_STAT_DURATION        60  // Seconds
#define MAX_XMT_FRAMES_TRACED    30 * MAX_STAT_DURATION  // Max number of entries

typedef struct _XMT_FRAME_STAT {
    KSSTATE StreamState;

    LONG cntSRBReceived;             // Accumulative SRVB received.
    LONG cntSRBPending;              // Number of SRB not yet completed.
    LONG cntSRBQueued;               // SRB Queued
    LONG cntDataAttached;            // Data attached

    LONGLONG FrameSlot;              // Real time
    ULONGLONG tmStreamTime;          // Stream time of the "FrameSlot"

    DWORD DropCount;                 // Accumulative drop count

    DWORD FrameNumber;               // Actual frame number transmitted; (==FrameSlot: ontime); (<FrameSlot: late)
    DWORD OptionsFlags;
    ULONGLONG tmPresentation;        // Actual frame's presentation time
    CYCLE_TIME tsTransmitted;        // Frame actually transmitted (1394 CycleTime)

} XMT_FRAME_STAT, *PXMT_FRAME_STAT;

#endif

//
// this structure is our per stream extension structure.  This stores
// information that is relevant on a per stream basis.  Whenever a new stream
// is opened, the stream class driver will allocate whatever extension size
// is specified in the HwInitData.PerStreamExtensionSize.
//
 
typedef struct _STREAMEX {

    //
    // Point to pSrb->HwDeviceExtension
    // 
    struct _DVCR_EXTENSION * pDevExt;

    //
    // Cache pSrb->StreamObject:
    //     ->HwStreamExtension  (pStrmExt)
    //     ->StreamNumber
    //     ->HwDeviceExtension  (pDevExt)
    //
    PHW_STREAM_OBJECT  pStrmObject;      

    //
    //  ->NumberOfPossibleInstances;
    //  ->DataFlow;
    //
    PHW_STREAM_INFORMATION pStrmInfo;
    
    //
    // Holds current stream state
    //
    KSSTATE StreamState;

    //
    // Holds previous stream state; use to determine the state transition.
    //
    KSSTATE StreamStatePrevious;

    //
    // Holds whether or not the dvcr is listening or receiving
    //
    // TRUE:  successful REQUEST_ISOCH_LISTEN and REQUEST_ISOCH_TALK
    // FALSE: successful INIT and REQUEST_ISOCH_STOP
    //
    BOOLEAN bIsochIsActive;  // Close associated with StreamState

    //
    // Set to TRUE when receiving KSSTREAM_HEADER_OPTIONSF_ENDOFSTREAM for SRB_WRITE_DATA
    // For SRB_WRITE_DATA only since then this driver servers as a renderer.
    //
    BOOL      bEOStream;  

    //
    // Count number of SRB_READ/WRITE_DATA received since last transiting to PAUSE state from STOP
    //
    LONGLONG  cntSRBReceived;

    //
    // Statistic of the frame information since last start stream
    // PictureNumber = FramesProcessed + FramesDropped + cndSRBCancelled.
    //    
    LONGLONG  FramesProcessed;   // Frame sent (including repeated)
    LONGLONG  FramesDropped;     // SRB not sent
    LONGLONG  PictureNumber;     // Number of SRB_XXX_DATA made it to or from 1394 bus

    //
    // Count number of SRB_READ/WRITE_DATA that was incompleted and cancelled
    //
    LONGLONG  cntSRBCancelled;

    //
    // Count and list for the detach list
    //
    LONG       cntDataDetached;
    LIST_ENTRY DataDetachedListHead;


#if DBG
    //
    // Count number of SRB awaiting completion
    //
    LONG       cntSRBPending;       
#endif

    //
    // Count and list for the SRB list
    //
    LONG       cntSRBQueued;        // Used only with SRB_WRITE_DATA
    LIST_ENTRY SRBQueuedListHead;   // Used only with SRB_WRITE_DATA


    //
    // Count and list for the attach list
    //
    LONG       cntDataAttached;
    LIST_ENTRY DataAttachedListHead;


    //
    // Lock to serialize attach and detach of list
    //
    KSPIN_LOCK * DataListLock;

#if DBG
    KSPIN_LOCK * DataListLockSave;
#endif


    //
    // The stream time (master clock or not) is "almost" or near 0 
    // when setting to RUN state and start increment.
    //
    ULONGLONG CurrentStreamTime;


    //
    // Keep track of the last system time when the stream time was updated.
    // This is used to calibrate the current stream time when it is queries.
    //
    ULONGLONG LastSystemTime;


    //
    // For isoch talk only:
    //     Signal arrival of a SRB so it can be processed in the case we are repeating frame.
    //
    KEVENT hSrbArriveEvent;

#ifdef SUPPORT_PREROLL_AT_RUN_STATE
    //
    // Support wait in RUN state to "simulate" preroll
    //
    KEVENT hPreRollEvent;
#endif


    //
    // Holds the master clock
    //
    HANDLE hMyClock;       // If set, we can be a clock provider.
    HANDLE hMasterClock;   // If set, we are the master clock.
    HANDLE hClock;         // If set, other device on the same graph is the master clock.


    //
    // Since GetSystemTime() can be called at DISPATCH level so make sure the variable that it used is in nonpaged pool
    //
    HW_TIME_CONTEXT  TimeContext;


    //
    // 2nd CIP Quadlet: 01:Fmt, 50/60:STYPE:RSv, SYT
    //
    BYTE cipQuad2[4];

#ifdef MSDV_SUPPORT_EXTRACT_SUBCODE_DATA
    //
    // Timecode, RecDate and RecTime are all in pack format (4 bytes)
    //
    BOOL bATNUpdated;
    DWORD AbsTrackNumber; // LSB:BlankField   

    BOOL bTimecodeUpdated;
    BYTE Timecode[4];     // hh:mm:ss,ff
#endif

    //
    // This mutex is used to sychronize attaching a frame and cancellation of a frame
    //
    KMUTEX * hStreamMutex;

    //
    // Counter used to indicate starting of an work item to cancel; this is a token and it is either 0 or 1.
    //
    LONG lStartIsochToken;

    //
    // Data ready dispatch thread's object: used to wait for thread to terminate.
    //
    PVOID  pAttachFrameThreadObject; 

    //
    // Set when the system is to be terminated.
    // 
    BOOL   bTerminateThread;

    //
    // Used to signal the termination of a system thread. 
    //
    KEVENT  hThreadEndEvent;     

    //
    // Increment this if there is a critical operation so the 
    // attaching frame thread will stop on the hRunThreadEvent.
    //
    LONG    lNeedService;       // > 0 to indicate needing service (stop thread)

    //
    // Signal to run the attach frame thread
    //
    KEVENT  hRunThreadEvent;    // Signal when thread is running

    //
    // Sign to hal the attach frame thread for critical operation such as
    // power off and surprise removal.
    //
    KEVENT  hStopThreadEvent;   // Signal when thread has stopped.

#ifdef SUPPORT_NEW_AVC
    //
    // Used to indicate a device to device connection
    //
    BOOL  bDV2DVConnect; 
#endif

    //
    // The input and output plug of this stream (point-to-point connection).
    //
    HANDLE  hOutputPcr;   // DV or PC's oPCR[0]
    HANDLE  hInputPcr;    // DV or PC's iPCR[0]

    //
    // The connection handle from 61883.sys.
    //
    HANDLE  hConnect;     // Connect handle

#ifdef NT51_61883 // This is needed starting with 61883.sys in Whistler
    //
    // Cyclic cycle count of last DV frame
    //
    ULONG  CycleCount16bits;
#endif  // NT51_61883


#if DBG
    LONG lPrevCycleCount;
    LONG lTotalCycleCount;
    ULONG lFramesAccumulatedRun;
    ULONG lFramesAccumulatedPaused;
    LONG lDiscontinuityCount;
#endif

    //
    // Discontinuity is introduced when traistioning from RUN->PAUSE->RUN.
    // The stream time will not increment in PAUSE state but system time (1394 CycleTime) does.
    //
    BOOL  b1stNewFrameFromPauseState;

    //
    // Use to mark the tick count when the stream start running.
    // It is later used to calculate current stream time and dropped frames.
    //
    ULONGLONG  tmStreamStart;
#if DBG
    ULONGLONG tmStreamPause;  // When it is set to PAUSE state
#endif

    //
    // Counter used to indicate starting of an work item to cancel; this is a token and it is either 0 or 1.
    //
    LONG lCancelStateWorkItem;

    //
    // Use to indicate aborting a stream.
    //
    BOOL bAbortPending;

    //
    // Hold the work item
    //
#ifdef USE_WDM110  // Win2000 code base
    PIO_WORKITEM       pIoWorkItem;
#else
    WORK_QUEUE_ITEM    IoWorkItem;
#endif

    //
    // TO singal that an work item is completed.
    //
    KEVENT hCancelDoneEvent;

    //
    // A timer and Dpc objects to periodically check for expired clock events.
    //
    KDPC  * DPCTimer;
    KTIMER  * Timer;
    BOOL  bTimerEnabled;


#if DBG
    //
    // Used to keep track of transmission statistics
    //
    PXMT_FRAME_STAT paXmtStat;
    ULONG ulStatEntries;
#endif

#ifdef SUPPORT_QUALITY_CONTROL
    //
    // Use for keeping track of quality control
    //
    KSQUALITY KSQuality;
#endif

} STREAMEX, *PSTREAMEX;



    
//
// Device Extension for our  Desktop Camera Driver
//
typedef struct _DVCR_EXTENSION {  

    LONG cndStrmOpen;
    ULONG idxStreamNumber;  // Index of current stream
    //
    // Can have only 1 Stream active at any time.
    // (Stream Class will allocate the stream extension at SRB_OPENSTREAM)    
    //
    PSTREAMEX    paStrmExt[3]; // We support three pins

    //
    // Holds the video format index; it's either PAL or NTSC.  Default is NTSC.
    //
    FMT_INDEX VideoFormatIndex;

    // 
    // Current Device Power State
    //
    DEVICE_POWER_STATE PowerState;

    //
    // Contain a table for the support formats
    //
    ULONG                 ulNumOfStreamSupported;
    HW_STREAM_INFORMATION * paCurrentStrmInfo;

    // 
    // TRUE only after SRB_SURPRISE_REMOVAL; 
    //
    BOOL bDevRemoved;  

    //
    // The list of AVC commands that have been issued
    //
    LIST_ENTRY AVCCmdList;

    // Number of completed commands waiting to be removed from the list
    // This includes:
    //     Command response has returned and processed in the completion routine
    //     Interim response awaiting final response
    LONG  cntCommandQueued;

    //
    // Protection for command processing
    //
    KSPIN_LOCK AVCCmdLock;

    //
    // The counted list of possible opcode values on response from Transport State status or notify
    //
    UCHAR TransportModes[5];    // 0x4, [0xC1, 0xC2, 0xC3, 0xC4]

    //
    // The device type (and its capabilities) cannot be determined until a tape is in    
    //
    ULONG      ulDevType;    // 0: undetermined, ED_DEVTYPE_CAMERA or ED_DEVTYPE_VCR
    BOOL       bHasTape;
    BOOL       bWriteProtected;
    BOOL       bDVCPro;


    //
    // Save Unit capabilities:
    //    Speed 
    //    Vendor and Model IDs
    //
    ULONG      NumOutputPlugs;
    ULONG      NumInputPlugs;
    ULONG      HardwareFlags;  // detect PAE: AV_HOST_DMA_DOUBLE_BUFFERING_ENABLED 

    ULONG      MaxDataRate;
    ULONG      ulVendorID;
    ULONG      ulModelID;

    LARGE_INTEGER  UniqueID;

    //
    // The DV's plug handles/PCRs (assume [0])
    //
    HANDLE hOPcrDV;
    HANDLE hIPcrDV;

#ifdef NT51_61883
    //
    // PC local oPCR
    //
    HANDLE  hOPcrPC;    // PC's local oPCR
#if 0                   // Not used since DV does not intiate DV to PC connection.
    HANDLE  hIPcrPC;    // PC's local iPCR
#endif

    //
    // Isochronous parameters obtained from 61883;
    // They are used for making isoch connection.
    //
    UNIT_ISOCH_PARAMS  UnitIoschParams;
#endif

    //
    // Holds the Device Object of our parent (1394 bus driver)
    //
    PDEVICE_OBJECT pBusDeviceObject;  // IoCallDriver()

    //
    // Holds my Physical Device Object
    // pass it in PnP API, such as IoOpenDeviceRegistryKey()
    //
    PDEVICE_OBJECT pPhysicalDeviceObject;

    //
    // Serialize in the event of getting two consecutive SRB_OPEN_STREAMs
    //
    KMUTEX hMutex;


#ifdef READ_CUTOMIZE_REG_VALUES
#if 0  // Not used in millennium; needed to do frame accurated recording.
    //
    // Registry values used to achieve frame accurate recording
    //
    BOOL  bATNSearch;        // Support ATN search (or Timecode search)
    BOOL  bSyncRecording;    // Sychronize stream state with record/pause transport state
    DWORD tmMaxDataSync;     // Time it take to sync to DV camcorder
    DWORD fmPlayPs2RecPs;    // Switch from PLAY_PAUSE to RECORD_PAUSE (unit=frames)
    DWORD fmStop2RecPs;      // Switch from STOP to RECORD_PAUSE (unit=frames)
    DWORD tmRecPs2Rec;       // Time to switch from RECORD_PAUSE to RECORD
#endif
    ULONG  XprtStateChangeWait;
#endif


    //
    // Since the signal format can dynamically changing, we will query 
    // the device for the currect format whevever we are asked for doing 
    // data intersection (note doing it in open is not enough!).
    // Instead of doing it always (since there could be a lot of data
    // intersection), we only query current format in a regular interval.
    //
    ULONGLONG tmLastFormatUpdate;

    //
    // Flow control for AVC command
    //
    KMUTEX  hMutexIssueAVCCmd;

#ifdef SUPPORT_OPTIMIZE_AVCCMD_RETRIES
    //
    // AVC Command retry count (default is 9 (avc.sys))
    //
    ULONG AVCCmdRetries;  // This is retry count not the total count

    //
    // Collect statistis of AVC command response time during driver load time.
    //
    BOOL  DrvLoadCompleted;   // Collect statistic until loading of driver is completed.  
    DWORD AVCCmdRespTimeMax;  // msec unit
    DWORD AVCCmdRespTimeMin;  // msec unit
    DWORD AVCCmdRespTimeSum;  // msec unit
    DWORD AVCCmdCount;  
#endif

} DVCR_EXTENSION, *PDVCR_EXTENSION;



//
// Used to queue a SRB
//

typedef struct _SRB_ENTRY {
    LIST_ENTRY                ListEntry;
    PHW_STREAM_REQUEST_BLOCK  pSrb; 
    BOOL                      bStale;  // TRUE if it is marked stale but is the only Srb in the SrbQ
    // Audio Mute indication; a frame could be repeatedly transmitted and its mute flag should be set only once.
    //
    BOOL                      bAudioMute;
#if DBG
    ULONG SrbNum;
#endif
} SRB_ENTRY, *PSRB_ENTRY;



//
// Valid data entry states for a data request and they
// can be Or'ed to show their data path.
//
// Examples of different possible code path: 
//
//    (A) Prepared->Attached->Callback->Completed_SRB 
//    (B) Prepared->Callback->Attached->Completed_SRB
//    (C) Prepared->Attached->Cancelled->Completed_SRB
//

enum DATA_ENTRY_STATE {
    DE_PREPARED               = 0x01,
    DE_IRP_ATTACHED_COMPLETED = 0x02,
    DE_IRP_CALLBACK_COMPLETED = 0x04,  
    DE_IRP_SRB_COMPLETED      = 0x08,
    DE_IRP_ERROR              = 0x10,    
    DE_IRP_CANCELLED          = 0x20,    
};

#define IsStateSet(state, bitmask) ((state & (bitmask)) == bitmask)



//
// This is the context used to attach a frame 
//

typedef struct _SRB_DATA_PACKET {
    // Build list
    LIST_ENTRY                  ListEntry;

    // 
    // Keep track of data entry state
    //
    enum DATA_ENTRY_STATE       State;

    PHW_STREAM_REQUEST_BLOCK    pSrb;  
    KSSTATE                     StreamState;  // StreamState when it was attached
    PSTREAMEX                   pStrmExt;  // Can get this from pSrb, here for convenience only!


    // Used to send 61883 request
    PIRP                        pIrp;     // Use to attach and release.

    PCIP_FRAME                  Frame;
    PVOID                       FrameBuffer;

    //
    // Add debug related info here
    //
    LONGLONG                    FrameNumber;

    // Use to send 61883 AV data request
    AV_61883_REQUEST            AVReq;

} SRB_DATA_PACKET, *PSRB_DATA_PACKET;





#define MASK_AUX_50_60_BIT  0x00200000  // bit 5 of PC3 of both AAuxSrc and VAAuxSrc is the NTSC/PAL bit


//
// Wait time constants
//
#define DV_AVC_CMD_DELAY_STARTUP                       500   // MSec
#define DV_AVC_CMD_DELAY_INTER_CMD                      20   // MSec
#define DV_AVC_CMD_DELAY_DVCPRO                        500   // MSec

#define FORMAT_UPDATE_INTERVAL                   100000000   // 10 seconds

//
// Default AVC Command settings
//
#define MAX_RESPONSE_TIME_FOR_ALERT                    100   // msec

//
// The timeout value is set to give device sufficient time to response
// to an AVC command following a transport state change.  It is based
// on trials of many camcorder (Sharp, Sony, Panasonic, Samsung..etc.)
// to come to this value.  The biggest delay (timeout) is from issuing
// of PLAY command follow by REWIND command.  Some test value:
// 
//     Hitachi
//     JVC DVL9600:      Stop->PLAY: delay is less than 300msec (Known issue: no image if play graph before play tape!)
//     Panasonic MX2000: Stop->PLAY:2339; ->Rewind:3767 msec
//     Samsung VP-D55:   Does not support XPrt State status command and will always
//                       timeout its suqsequent command following XPrtState change
//     Sharp VL-WDW450U: Stop->PLAY:3514; ->Rewind:6120 msec  
//           VL-PD3F:    Stop->PLAY:3293; ->Rewind:6404 msec
//     Sony DCR-TRV10:   Stop->PLAY:3617; ->Rewind:5323 msec 
//          DA1:         Non-compliant (Retry is 0!)
//          DA2:         No transport state change.        
//

#define MAX_AVC_CMD_RETRIES      ((DEFAULT_AVC_RETRIES + 1) * 7 - 1)  // Retries counts 

 
#endif
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\drivers\wdm\capture\mini\msdv\msdvfmt.h ===
/*++

Copyright (C) Microsoft Corporation, 1999 - 2000  

Module Name:

    msdvfmt.h

Abstract:

    Header file for DV format data.

Last changed by:
    
$Author::                $

Environment:

    Kernel mode only

Revision History:

$Revision::                    $
$Date::                        $

--*/




#ifndef _DVFORMAT_INC
#define _DVFORMAT_INC


// ****************
// Support switches
// ****************

//
// Differnt level of WDM supports may use different API
//
// e.g. MmGetSystemAddressForMdl (win9x) 
//          Return NULL for Win9x; bugcheck for Win2000 if NULL would have returned.
//
//      MmGetSystemAddressForMdlSafe (win2000)
//          Not supported in Win9x or Millen
//
// #define USE_WDM110  // Define this if WDM1.10 is used; e.g. Win2000 code base // Define in SOURCES if needed


//
// Turn this on to support HD DVCR 
//#define MSDV_SUPPORT_HD_DVCR

//
// Turn this on to support SDL DVCR 
//
#define MSDV_SUPPORT_SDL_DVCR


//
// Turn on this switch to support bus reset KS event
// #define MSDVDV_SUPPORT_BUSRESET_EVENT


//
// Turn this define to extract timecode from a video frame
// Advantage: faster turn around compare to an AVC status command
// #define MSDV_SUPPORT_EXTRACT_SUBCODE_DATA


//
// To get recorded date and time
// #define MSDV_SUPPORT_EXTRACT_DV_DATE_TIME

//
// Mute audio when in pause state while transmitting to DV
#define MSDV_SUPPORT_MUTE_AUDIO

//
// Support getting regitry value for this device
// WORKITEM: enable this for Whistler
// #define READ_CUTOMIZE_REG_VALUES

//
// Support wait  a little until transport state control command is stabled before return
//
// #define SUPPORT_XPRT_STATE_WAIT_FOR_STABLE


//
// Support IQulityControl for the in pin
//
#define SUPPORT_QUALITY_CONTROL

//
// Suppoprt wait to preroll data at the RUN state
//
#define SUPPORT_PREROLL_AT_RUN_STATE

//
// Support a change in KsProxy to return "not ready" while transmitioning into the PAUSE state
//
#define SUPPORT_KSPROXY_PREROLL_CHANGE

//
// Support using AVC connect info for device to device connection
//
// #define SUPPORT_NEW_AVC

//
// Support Optimizing number of AVC Command retries for non-compliant devices
//
#define SUPPORT_OPTIMIZE_AVCCMD_RETRIES

typedef struct _DV_FORMAT_INFO {
    
    // 2nd quadlet of the CIP header
    //    cipQuad[0]            = 10:[FMT]
    //    cipQuad[1]            = 50/60:STYPE:00
    //    cipQuad[2]+cipQuad[3] = SYT
    UCHAR cipQuad[4];    
    //
    // Holds the number of DIF sequences per vid format
    //
    ULONG ulNumOfDIFSequences;

    //
    // Number of receiving buffers
    //
    ULONG ulNumOfRcvBuffers;

    //
    // Number of transmitting buffers
    //
    ULONG ulNumOfXmtBuffers;

    //
    // Holds DV (audio and video) frame size
    //
    ULONG ulFrameSize;

    //
    // Approximate time per frame
    //
    ULONG ulAvgTimePerFrame;

    //
    // Number of source packet per frame
    //
    ULONG ulSrcPackets;

    //
    // Maximun number of source packets per frame
    //
    ULONG ulMaxSrcPackets;
  
    //
    // Holds the number of quadlets in each data block
    //
    ULONG DataBlockSize;  // 00(256),01(01)...,ff(255) quadlets

    //
    // Holds the number of data blocks into which a source packet is divided.
    //
    ULONG FractionNumber;  // 00(not divided), 01 (2 DataBlks), 10 (4), 11 (8)

    //
    // Quadlet padding count (0..7)
    //
    ULONG QuadPadCount;

    //
    // SourcePacketHeader: 0 (FALSE); else (TRUE)
    //
    ULONG SrcPktHeader; 

} DV_FORMAT_INFO, *PDV_FORMAT_INFO;


//
// DV format tables
//


typedef struct _ALL_STREAM_INFO {
    HW_STREAM_INFORMATION   hwStreamInfo;
    HW_STREAM_OBJECT        hwStreamObject;
} ALL_STREAM_INFO, *PALL_STREAM_INFO;



// All CIP sizes are in quads. The upper third byte is the size.
#define CIP_HDR_FMT_DV                   0x00
#define CIP_HDR_FMT_DVCPRO               0x1e


//
// 1394 stuff
//
#define SPEED_100_INDEX                     0
#define SPEED_200_INDEX                     1
#define SPEED_400_INDEX                     2


#define CIP_DBS_SD_DVCR                   120       // quadlets in a data block of the SD DVCR; BlueBook Part 2
#define CIP_DBS_HD_DVCR                   240       // quadlets in a data block of the HD DVCR; BlueBook Part 3
#define CIP_DBS_SDL_DVCR                   60       // quadlets in a data block of the SDL DVCR; BlueBook Part 5

#define CIP_FN_SD_DVCR                      0       // Data blocks in a source pacaket of SD DVCR; BlueBook Part 2
#define CIP_FN_HD_DVCR                      0       // Data blocks in a source pacaket of HD DVCR; BlueBook Part 3
#define CIP_FN_SDL_DVCR                     0       // Data blocks in a source pacaket of SDL DVCR; BlueBook Part 5


#define MAX_FCP_PAYLOAD_SIZE              512


// CIP header definition:

// FMT: "Blue book" Part 1, page 25, Table 3; DVCR:000000
#define FMT_DVCR             0x80  // 10:FMT(00:0000)
#define FMT_DVCR_CANON       0x20  // 10:FMT(00:0000); but Canon return 00:FMT(10:0000)
#define FMT_MPEG             0xa0  // 10:FMT(10:0000)

// FDF
#define FDF0_50_60_MASK      0x80
#define FDF0_50_60_PAL       0x80
#define FDF0_50_60_NTSC      0x00

#define FDF0_STYPE_MASK      0x7c
#define FDF0_STYPE_SD_DVCR   0x00  // STYPE: 000:00
#define FDF0_STYPE_SDL_DVCR  0x04  // STYPE: 000:01
#define FDF0_STYPE_HD_DVCR   0x08  // STYPE: 000:10
#define FDF0_STYPE_SD_DVCPRO 0x78  // STYPE: 111:10


//
// FCP and AVCC stuff.  Used in conjunction with defs in 1394.h
//

// DVCR:
#define SUBUNIT_TYPE_CAMCORDER           4
#define SUBUNIT_ID_CAMCORDER             0

#define DIF_SEQS_PER_NTSC_FRAME         10   // SDDV
#define DIF_SEQS_PER_PAL_FRAME          12   // SDDV

#define DIF_SEQS_PER_NTSC_FRAME_SDL      5   // SDLDV
#define DIF_SEQS_PER_PAL_FRAME_SDL       6   // SDLDV

#define DIF_SEQS_PER_NTSC_FRAME_HD      10   // HDDV: same as SDDV but source packet is twice as big
#define DIF_SEQS_PER_PAL_FRAME_HD       12   // HDDV: same as SDDV but source packet is twice as big

#define SRC_PACKETS_PER_NTSC_FRAME     250
#define SRC_PACKETS_PER_PAL_FRAME      300

#define MAX_SRC_PACKETS_PER_NTSC_FRAME 267  // packets for a NTSC DV frame; "about" 29.97 FPS
#define MAX_SRC_PACKETS_PER_PAL_FRAME  320  // packets for a PAL DV frame; exactly 25FPS

#define MAX_SRC_PACKETS_PER_NTSC_FRAME_PAE 100  // SRC_PACKETS_PER_NTSC_FRAME/5
#define MAX_SRC_PACKETS_PER_PAL_FRAME_PAE  120  // SRC_PACKETS_PER_PAL_FRAME/5

#define FRAME_SIZE_SD_DVCR_NTSC     120000
#define FRAME_SIZE_SD_DVCR_PAL      144000

#define FRAME_SIZE_HD_DVCR_NTSC     240000
#define FRAME_SIZE_HD_DVCR_PAL      288000

#define FRAME_SIZE_SDL_DVCR_NTSC     60000
#define FRAME_SIZE_SDL_DVCR_PAL      72000

#define FRAME_TIME_NTSC             333667   // "about" 29.97
#define FRAME_TIME_PAL              400000   // exactly 25
 
#define PCR_OVERHEAD_ID_SDDV        0xf      // 480; delays caused by IEEE 1394 bus parmeters
#define PCR_PAYLOAD_SDDV            (CIP_DBS_SD_DVCR + 2)    // 120 * 4 + 2 * 4 = 480 + 8 = 488; 488/4 = 122 quadlet
#define PCR_PAYLOAD_HDDV            (CIP_DBS_HD_DVCR + 2)    // 240 * 4 + 2 * 4 = 960 + 8 = 968; 968/4 = 242 quadlets
#define PCR_PAYLOAD_SDLDV           (CIP_DBS_SDL_DVCR + 2)   //  60 * 4 + 2 * 4 = 240 + 8 = 248; 248/4 =  62 quadlets


//
// These definition and macros are used to calculate the picture numbers.
// With OHCI spec, the data is returned with the 16bit Cycle time, which includes
// 3 bits of SecondCount and 13 bits of the CycleCount.  This "timer" will wrap in 8 seconds.
//
#define TIME_PER_CYCLE     1250   // One 1394 cycle; unit = 100 nsec
#define CYCLES_PER_SECOND  8000
#define MAX_SECOND_COUNTS     7   // The returned CycleTime contains 3 bits of SecondCount; that is 0..7
#define MAX_CYCLES        (MAX_SECOND_COUNTS + 1) * CYCLES_PER_SECOND    // 0..MAX_CYCLES-1
#define MAX_CYCLES_TIME   (MAX_CYCLES * TIME_PER_CYCLE)                  // unit = 100nsec

#define VALIDATE_CYCLE_COUNTS(CT) ASSERT(CT.CL_SecondCount <= 7 && CT.CL_CycleCount < CYCLES_PER_SECOND && CT.CL_CycleOffset == 0);

#define CALCULATE_CYCLE_COUNTS(CT) (CT.CL_SecondCount * CYCLES_PER_SECOND + CT.CL_CycleCount);

#define CALCULATE_DELTA_CYCLE_COUNT(prev, now) ((now > prev) ? now - prev : now + MAX_CYCLES - prev)

//
// Return avg time per frame in the unit of 100 nsec; 
// for calculation accuracy using only integer calculation, 
// we should do do multimplcation before division.
// That is why the application can request to get numerator and denominator separately.
// 
#define GET_AVG_TIME_PER_FRAME(format)       ((format == FMT_IDX_SD_DVCR_NTSC || format == FMT_IDX_SDL_DVCR_NTSC) ? (1001000/3)  : FRAME_TIME_PAL)
#define GET_AVG_TIME_PER_FRAME_NUM(format)   ((format == FMT_IDX_SD_DVCR_NTSC || format == FMT_IDX_SDL_DVCR_NTSC) ? 1001000      : 400000)
#define GET_AVG_TIME_PER_FRAME_DENOM(format) ((format == FMT_IDX_SD_DVCR_NTSC || format == FMT_IDX_SDL_DVCR_NTSC) ? 3            : 1)


#define GET_NUM_PACKETS_PER_FRAME(format)       ((format == FMT_IDX_SD_DVCR_NTSC || format == FMT_IDX_SDL_DVCR_NTSC) ? 4004/15 /* 100100/375 */ : MAX_SRC_PACKETS_PER_PAL_FRAME)
#define GET_NUM_PACKETS_PER_FRAME_NUM(format)   ((format == FMT_IDX_SD_DVCR_NTSC || format == FMT_IDX_SDL_DVCR_NTSC) ? 4004                     : MAX_SRC_PACKETS_PER_PAL_FRAME)
#define GET_NUM_PACKETS_PER_FRAME_DENOM(format) ((format == FMT_IDX_SD_DVCR_NTSC || format == FMT_IDX_SDL_DVCR_NTSC) ? 15                       : 1)


//
// Data buffers
//
#define DV_NUM_OF_RCV_BUFFERS               16  // Same as number of transmit buffer

#define NUM_BUF_ATTACHED_THEN_ISOCH         4   // number of buffers attached before streaming and also as the water mark.
#define NUM_BUFFER_BEFORE_TRANSMIT_BEGIN    (NUM_BUF_ATTACHED_THEN_ISOCH + 1)  // One extra to avoid repeat frame
#define DV_NUM_EXTRA_USER_XMT_BUFFERS      12   // Extra user buffers that the data source can send to us as a read ahead.
#define DV_NUM_OF_XMT_BUFFERS               (NUM_BUF_ATTACHED_THEN_ISOCH + DV_NUM_EXTRA_USER_XMT_BUFFERS)




//
// The "signature" of the header section of Seq0 of incoming source packets:
//
// "Blue" book, Part2, 11.4 (page 50); Figure 66, table 36 (page 111)
//
// ID0 = {SCT2,SCT1,SCT0,RSV,Seq3,Seq2,Seq1,Seq0} 
//
//     SCT2-0 = {0,0,0} = Header Section Type
//     RSV    = {1}
//     Seq3-0 = {1,1,1,1} for NoInfo or {0,0,0,} for Sequence 0
//
// ID1 = {DSeq3-0, 0, RSV, RSV, RSV} 
//     DSeq3-0 = {0, 0, 0, 0} = Beginning of a DV frame
//
// ID2 = {DBN7,DBN6,DBN5,DBN4,DBN3,DBN2,DBN1,DBN0}
//     DBB7-0 = {0,0,0,0,0,0,0,0,0} = Beginning of a DV frame
//

#define DIF_BLK_ID0_SCT_MASK       0xe0 // 11100000b; Section Type (SCT)2-0 are all 0's for the Header section
#define DIF_BLK_ID1_DSEQ_MASK      0xf0 // 11110000b; DIF Sequence Number(DSEQ)3-0 are all 0's 
#define DIF_BLK_ID2_DBN_MASK       0xff // 11111111b; Data Block Number (DBN)7-0 are all 0's 

#define DIF_HEADER_DSF             0x80 // 10000000b; DSF=0; 10 DIF Sequences (525-60)
                                        //            DSF=1; 12 DIF Sequences (625-50)

#define DIF_HEADER_TFn             0x80 // 10000000b; TFn=0; DIF bloick of area N are transmitted in the current DIF sequence.
                                        //            TFn=1; DIF bloick of area N are NOT transmitted in the current DIF sequence.

//
// AV/C command response data definition
//
#define AVC_DEVICE_TAPE_REC 0x20  // 00100:000
#define AVC_DEVICE_CAMERA   0x38  // 00111:000
#define AVC_DEVICE_TUNER    0x28  // 00101:000


//
// GUID definitions for pins and DV format types.
//

// DV vid only output pin
#define STATIC_PINNAME_DV_VID_OUTPUT \
    0x5b21c540L, 0x7aee, 0x11d1, 0x88, 0x3b, 0x00, 0x60, 0x97, 0xf0, 0x5c, 0x70
DEFINE_GUIDSTRUCT("5b21c540-7aee-11d1-883b-006097f05c70", PINNAME_DV_VID_OUTPUT);
#define PINNAME_DV_VID_OUTPUT DEFINE_GUIDNAMED(PINNAME_DV_VID_OUTPUT)
#define PINNAME_VID_OUT PINNAME_DV_VID_OUTPUT

// DV A/V output pin
#define STATIC_PINNAME_DV_AV_OUTPUT \
    0x5b21c541L, 0x7aee, 0x11d1, 0x88, 0x3b, 0x00, 0x60, 0x97, 0xf0, 0x5c, 0x70
DEFINE_GUIDSTRUCT("5b21c540-7aee-11d1-883b-006097f05c70", PINNAME_DV_AV_OUTPUT);
#define PINNAME_DV_AV_OUTPUT DEFINE_GUIDNAMED(PINNAME_DV_AV_OUTPUT)
#define PINNAME_AV_OUTPUT PINNAME_DV_AV_OUTPUT


// DV A/V input pin
#define STATIC_PINNAME_DV_AV_INPUT \
    0x5b21c543L, 0x7aee, 0x11d1, 0x88, 0x3b, 0x00, 0x60, 0x97, 0xf0, 0x5c, 0x70
DEFINE_GUIDSTRUCT("5b21c543-7aee-11d1-883b-006097f05c70", PINNAME_DV_AV_INPUT);
#define PINNAME_DV_AV_INPUT DEFINE_GUIDNAMED(PINNAME_DV_AV_INPUT)
#define PINNAME_AV_INPUT PINNAME_DV_AV_INPUT

#endif
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\drivers\wdm\capture\mini\msdv\msdvguts.c ===
/*++

Copyright (C) Microsoft Corporation, 1999 - 2000  

Module Name:

    MSDVGuts.c

Abstract:

    Main service functions.

Last changed by:
    
    Author:      Yee J. Wu

Environment:

    Kernel mode only

Revision History:

    $Revision::                    $
    $Date::                        $

--*/

#include "strmini.h"
#include "ksmedia.h"

#include "1394.h"
#include "61883.h"
#include "avc.h"
#include "dbg.h"
#include "ksguid.h"

#include "msdvfmt.h"  // Before msdvdefs.h
#include "msdvdef.h"

#include "MSDVGuts.h"
#include "MsdvUtil.h"
#include "MsdvAvc.h"

#include "XPrtDefs.h"
#include "EDevCtrl.h"

//
// Define formats supported
//
#include "avcstrm.h"
#include "strmdata.h"

#if DBG
extern ULONG DVDebugXmt;        // this is defined in msdvuppr.c
#endif

NTSTATUS
DVGetDevInfo(
    IN PDVCR_EXTENSION  pDevExt,
    IN PAV_61883_REQUEST  pAVReq
    );
VOID 
DVIniStrmExt(
    PHW_STREAM_OBJECT  pStrmObject,
    PSTREAMEX          pStrmExt,
    PDVCR_EXTENSION    pDevExt,
    const PALL_STREAM_INFO   pStream
    );
NTSTATUS 
DVStreamGetConnectionProperty (
    PDVCR_EXTENSION pDevExt,
    PSTREAMEX          pStrmExt,
    PSTREAM_PROPERTY_DESCRIPTOR pSPD,
    PULONG pulActualBytesTransferred
    );
NTSTATUS
DVGetDroppedFramesProperty(  
    PDVCR_EXTENSION pDevExt,
    PSTREAMEX       pStrmExt,
    PSTREAM_PROPERTY_DESCRIPTOR pSPD,
    PULONG pulBytesTransferred
    );

#if 0  // Enable later
#ifdef ALLOC_PRAGMA   
     #pragma alloc_text(PAGE, DVGetDevInfo)
     #pragma alloc_text(PAGE, DVInitializeDevice)
     #pragma alloc_text(PAGE, DVGetStreamInfo)
     #pragma alloc_text(PAGE, DVVerifyDataFormat)
     #pragma alloc_text(PAGE, DVGetDataIntersection)
     #pragma alloc_text(PAGE, DVIniStrmExt)
     #pragma alloc_text(PAGE, DVOpenStream)
     #pragma alloc_text(PAGE, DVCloseStream)
     #pragma alloc_text(PAGE, DVChangePower)
     #pragma alloc_text(PAGE, DVSurpriseRemoval)
     #pragma alloc_text(PAGE, DVProcessPnPBusReset)
     #pragma alloc_text(PAGE, DVUninitializeDevice)
     #pragma alloc_text(PAGE, DVGetStreamState)
     #pragma alloc_text(PAGE, DVStreamingStop)
     #pragma alloc_text(PAGE, DVStreamingStart)
     #pragma alloc_text(PAGE, DVSetStreamState)
     #pragma alloc_text(PAGE, DVStreamGetConnectionProperty)
     #pragma alloc_text(PAGE, DVGetDroppedFramesProperty)
     #pragma alloc_text(PAGE, DVGetStreamProperty)
     #pragma alloc_text(PAGE, DVSetStreamProperty)
     #pragma alloc_text(PAGE, DVCancelAllPackets)
     #pragma alloc_text(PAGE, DVOpenCloseMasterClock)
     #pragma alloc_text(PAGE, DVIndicateMasterClock)
#endif
#endif

DV_FORMAT_INFO DVFormatInfoTable[] = {

//
// SD DVCR
//
    { 
        {
            FMT_DVCR,
            FDF0_50_60_NTSC,
            0,
            0
        },
        DIF_SEQS_PER_NTSC_FRAME,
        DV_NUM_OF_RCV_BUFFERS,
        DV_NUM_OF_XMT_BUFFERS,
        FRAME_SIZE_SD_DVCR_NTSC,
        FRAME_TIME_NTSC,
        SRC_PACKETS_PER_NTSC_FRAME,
        MAX_SRC_PACKETS_PER_NTSC_FRAME,
        CIP_DBS_SD_DVCR,
        CIP_FN_SD_DVCR,
        0,
        FALSE,                    // Source packet header
    },
    {
        {
            FMT_DVCR,
            FDF0_50_60_PAL,
            0,
            0
        },
        DIF_SEQS_PER_PAL_FRAME,
        DV_NUM_OF_RCV_BUFFERS,
        DV_NUM_OF_XMT_BUFFERS,
        FRAME_SIZE_SD_DVCR_PAL,
        FRAME_TIME_PAL,
        SRC_PACKETS_PER_PAL_FRAME,
        MAX_SRC_PACKETS_PER_PAL_FRAME,
        CIP_DBS_SD_DVCR,
        CIP_FN_SD_DVCR,
        0,
        FALSE,                   // Source packet header
    },

#ifdef SUPPORT_HD_DVCR

//
// HD DVCR
//
    { 
        {
            FMT_DVCR,
            FDF0_50_60_NTSC,
            0,
            0
        },
        DIF_SEQS_PER_NTSC_FRAME_HD, 
        DV_NUM_OF_RCV_BUFFERS,
        DV_NUM_OF_XMT_BUFFERS,            
        FRAME_SIZE_HD_DVCR_NTSC,
        FRAME_TIME_NTSC,
        SRC_PACKETS_PER_NTSC_FRAME,
        MAX_SRC_PACKETS_PER_NTSC_FRAME,
        CIP_DBS_HD_DVCR,
        CIP_FN_HD_DVCR,
        0,
        FALSE,    // Source packet header
    },
    {
        {
            FMT_DVCR,
            FDF0_50_60_PAL,
            0,
            0
        },
        DIF_SEQS_PER_PAL_FRAME_HD,
        DV_NUM_OF_RCV_BUFFERS,
        DV_NUM_OF_XMT_BUFFERS,
        FRAME_SIZE_HD_DVCR_PAL,
        FRAME_TIME_PAL,
        SRC_PACKETS_PER_PAL_FRAME,
        MAX_SRC_PACKETS_PER_PAL_FRAME,
        CIP_DBS_HD_DVCR,
        CIP_FN_HD_DVCR,
        0,
        FALSE,    // Source packet header
    },
#endif

#ifdef MSDV_SUPPORT_SDL_DVCR
//
// SDL DVCR
//
    { 
        {
            FMT_DVCR,
            FDF0_50_60_NTSC,
            0,
            0
        },
        DIF_SEQS_PER_NTSC_FRAME_SDL,  
        DV_NUM_OF_RCV_BUFFERS,
        DV_NUM_OF_XMT_BUFFERS,            
        FRAME_SIZE_SDL_DVCR_NTSC,
        FRAME_TIME_NTSC,
        SRC_PACKETS_PER_NTSC_FRAME,
        MAX_SRC_PACKETS_PER_NTSC_FRAME,
        CIP_DBS_SDL_DVCR,
        CIP_FN_SDL_DVCR,
        0,
        FALSE,    // Source packet header
    },
    {
        {
            FMT_DVCR,
            FDF0_50_60_PAL,
            0,
            0
        },
        DIF_SEQS_PER_PAL_FRAME_SDL,
        DV_NUM_OF_RCV_BUFFERS,
        DV_NUM_OF_XMT_BUFFERS,
        FRAME_SIZE_SDL_DVCR_PAL,
        FRAME_TIME_PAL,
        SRC_PACKETS_PER_PAL_FRAME,
        MAX_SRC_PACKETS_PER_PAL_FRAME,
        CIP_DBS_SDL_DVCR,
        CIP_FN_SDL_DVCR,
        0,
        FALSE,    // Source packet header
    },

#endif  // Not implemented.
};


#define MSDV_FORMATS_SUPPORTED        (SIZEOF_ARRAY(DVFormatInfoTable))




VOID
DVTerminateAttachFrameThread(
    IN PSTREAMEX  pStrmExt
    );

VOID
DVIniDevExtStruct(
    IN PDVCR_EXTENSION  pDevExt,
    IN PPORT_CONFIGURATION_INFORMATION pConfigInfo    
    )
/*++

Routine Description:

    Initialiaze the device extension structure.

--*/
{
    ULONG            i;


    RtlZeroMemory( pDevExt, sizeof(DVCR_EXTENSION) );

    //
    // Cache what are in ConfigInfo in device extension
    //
    pDevExt->pBusDeviceObject      = pConfigInfo->PhysicalDeviceObject;      // IoCallDriver()
    pDevExt->pPhysicalDeviceObject = pConfigInfo->RealPhysicalDeviceObject;  // Used in PnP API

    //
    // Allow only one stream open at a time to avoid cyclic format
    //
    pDevExt->cndStrmOpen = 0;

    //
    // Serialize in the event of getting two consecutive SRB_OPEN_STREAMs
    //
    KeInitializeMutex( &pDevExt->hMutex, 0);  // Level 0 and in Signal state

    //
    // Initialize our pointer to stream extension
    //
    for (i=0; i<DV_STREAM_COUNT; i++) {
        pDevExt->paStrmExt[i] = NULL;  
    }

    //
    // Bus reset, surprise removal 
    //
    pDevExt->bDevRemoved = FALSE;

    pDevExt->PowerState = PowerDeviceD0;
    
    //
    // External device control (AV/C commands)
    // 
    KeInitializeSpinLock( &pDevExt->AVCCmdLock );  // To guard the count  

    pDevExt->cntCommandQueued   = 0; // Cmd that is completed its life cycle waiting to be read (most for RAW_AVC's Set/Read model)

    InitializeListHead(&pDevExt->AVCCmdList);      

    // Initialize the list of possible opcode values of the response
    // from a Transport State status or notify command. The first item
    // is the number of values that follow.
    ASSERT(sizeof(pDevExt->TransportModes) == 5);
    pDevExt->TransportModes[0] = 4;
    pDevExt->TransportModes[1] = 0xC1;
    pDevExt->TransportModes[2] = 0xC2;
    pDevExt->TransportModes[3] = 0xC3;
    pDevExt->TransportModes[4] = 0xC4;

#ifdef SUPPORT_OPTIMIZE_AVCCMD_RETRIES
    // Set to default values used by avc.sys
    pDevExt->AVCCmdRetries = DEFAULT_AVC_RETRIES;

    pDevExt->DrvLoadCompleted  = FALSE;
    pDevExt->AVCCmdRespTimeMax = 0;
    pDevExt->AVCCmdRespTimeMin = DEFAULT_AVC_TIMEOUT * (DEFAULT_AVC_RETRIES+1) / 10000;
    pDevExt->AVCCmdRespTimeSum = 0;
    pDevExt->AVCCmdCount       = 0;
#endif

    // AVC Command flow control
    KeInitializeMutex(&pDevExt->hMutexIssueAVCCmd, 0);
}


NTSTATUS
DVGetDevInfo(
    IN PDVCR_EXTENSION  pDevExt,
    IN PAV_61883_REQUEST  pAVReq
    )
/*++

Routine Description:

    Issue AVC command to determine basic device information and cache them in the device extension.

--*/
{
    NTSTATUS    Status;
    BYTE                   bAvcBuf[MAX_FCP_PAYLOAD_SIZE];  // For issue AV/C command within this module
    PKSPROPERTY_EXTXPORT_S pXPrtProperty;                  // Point to bAvcBuf;

    PAGED_CODE();

    //
    // Get unit's capabilities such as 
    //     Number of input/output plugs, data rate
    //     UniqueID, VendorID and ModelID
    //

    if(!NT_SUCCESS(
        Status = DVGetUnitCapabilities(
            pDevExt
            ))) {
         TRACE(TL_PNP_ERROR,("Av61883_GetUnitCapabilities Failed = 0x%x\n", Status));
         return Status;
    }

#ifdef NT51_61883
    //
    // Set to create local plug in exclusive address mode:  
    //      This is needed for device that does not support CCM, such as DV.
    //
    // PBinder:  the problem is that you cannot expose a global plug (all nodes on the bus can see it), 
    // since they have no knowledge of what that plug is used for (mpeg2/dv/audio/etc). 
    // so instead, you must create a plug in an exclusive address range. this means that only the device 
    // that you loaded for will see the plug. this means that if you had two pc's and a dv camcorder, 
    // on both pc's, you'll have a plug you created for the dv camcorder, but the pc's will not be able 
    // to see the plug you created, only the dv camcorder.  Keep in mind, this should only be used for 
    // devices that do not support some mechanism of determining what plug to use (such as ccm). 
    // so for any device that just goes out and uses plug #0, this must be enabled.
    //

    if(!NT_SUCCESS(
        Status = DVSetAddressRangeExclusive( 
            pDevExt
            ))) {        
        return Status;
    }
#endif  // NT51_61883

    //
    // Get DV's oPCR[0]
    //
    if(pDevExt->NumOutputPlugs) {
        if(!NT_SUCCESS(
            Status = DVGetDVPlug( 
                pDevExt,
                CMP_PlugOut,
                0,           // Plug [0]
                &pDevExt->hOPcrDV
                ))) {        
            return Status;
        }
    } 
    else {

        pDevExt->hOPcrDV = NULL;  // Redundant since we Zero the whole DeviceExtension


        TRACE(TL_PNP_ERROR,("\'No output plug!\n"));
        // 
        // This is bad!  We cannot even stream from this DV device.
        //
    }

    //
    // Get DV's iPCR
    //
    if(pDevExt->NumInputPlugs) {
        if(!NT_SUCCESS(
            Status = DVGetDVPlug( 
                pDevExt,
                CMP_PlugIn,
                0,           // Plug [0]
                &pDevExt->hIPcrDV
                ))) {        
            return Status;
        }
    }
    else {

        pDevExt->hIPcrDV = NULL;  // Redundant since we Zero the whole DeviceExtension

        TRACE(TL_PNP_ERROR,("\'No input plug!\n"));
        // 
        // Some PAL camcorder has no DVIN plug; we will refuse to make PC->DV connection.
        //
    }

#if 0  // Device control can still work!
    // 
    // Need plug to stream DV (either direction)
    //
    if(   pDevExt->hOPcrDV == NULL
       && pDevExt->hIPcrDV == NULL) {

        TRACE(TL_PNP_ERROR,("\'No input or output plug; return STATUS_INSUFFICIENT_RESOURCES!\n"));
        // 
        // Cannot stream
        //
        return = STATUS_INSUFFICIENT_RESOUCES;
    }
#endif


    // 
    // Subunit_Info : VCR or camera
    //

    DVDelayExecutionThread(DV_AVC_CMD_DELAY_INTER_CMD);
    Status = 
        DVIssueAVCCommand(
            pDevExt, 
            AVC_CTYPE_STATUS, 
            DV_SUBUNIT_INFO, 
            (PVOID) bAvcBuf
            );

    if(STATUS_SUCCESS == Status) {
        TRACE(TL_PNP_WARNING|TL_FCP_WARNING,("\'DVGetDevInfo: Status %x DV_SUBUNIT_INFO (%x %x %x %x)\n", 
            Status, bAvcBuf[0], bAvcBuf[1], bAvcBuf[2], bAvcBuf[3]));

        // Support DV (Camera+DVCR), DVCR, or analog-DV converter
        if(   bAvcBuf[0] != AVC_DEVICE_TAPE_REC 
           && bAvcBuf[1] != AVC_DEVICE_TAPE_REC
           && bAvcBuf[2] != AVC_DEVICE_TAPE_REC
           && bAvcBuf[3] != AVC_DEVICE_TAPE_REC)
        {
            TRACE(TL_PNP_ERROR,("DVGetDevInfo:Device supported: %x, %x; (VCR %x, Camera %x)\n",
                bAvcBuf[0], bAvcBuf[1], AVC_DEVICE_TAPE_REC, AVC_DEVICE_CAMERA));
            
            return STATUS_NOT_SUPPORTED;  // We only support unit with a tape subunit
        }
        else {
            // DVCR..
        }
    } else {
        TRACE(TL_PNP_ERROR,("DVGetDevInfo: DV_SUBUNIT_INFO failed, Status %x\n", Status));
        //
        // Cannot open this device if it does not support manadatory AVC SUBUnit status command.
        // However, we are making an exception for the DV converter box (will return TIMEOUT).
        //

        // Has our device gone away?
        if (   STATUS_IO_DEVICE_ERROR == Status 
            || STATUS_REQUEST_ABORTED == Status)
            return Status;       
    }


    //
    // Medium_Info: MediaPresent, MediaType, RecordInhibit
    //
    pXPrtProperty = (PKSPROPERTY_EXTXPORT_S) bAvcBuf;
    DVDelayExecutionThread(DV_AVC_CMD_DELAY_INTER_CMD);
    Status = 
        DVIssueAVCCommand(
            pDevExt, 
            AVC_CTYPE_STATUS, 
            VCR_MEDIUM_INFO, 
            (PVOID) pXPrtProperty
            );

    if(STATUS_SUCCESS == Status) {
        pDevExt->bHasTape = pXPrtProperty->u.MediumInfo.MediaPresent;
        TRACE(TL_PNP_WARNING|TL_FCP_WARNING,("\'DVGetDevInfo: Status %x HasTape %s, VCR_MEDIUM_INFO (%x %x %x %x)\n", 
            Status, pDevExt->bHasTape ? "Yes" : "No", bAvcBuf[0], bAvcBuf[1], bAvcBuf[2], bAvcBuf[3]));
    } else {
        pDevExt->bHasTape = FALSE;
        TRACE(TL_PNP_ERROR,("DVGetDevInfo: VCR_MEDIUM_INFO failed, Status %x\n", Status));

        // Has our device gone away?
        if (   STATUS_IO_DEVICE_ERROR == Status
            || STATUS_REQUEST_ABORTED == Status)
            return Status;
    }


    //
    // If this is a Panasonic AVC device, we will detect if it is a DVCPro format; 
    // This needs to be called before MediaFormat
    //
    if(pDevExt->ulVendorID == VENDORID_PANASONIC) {
        DVDelayExecutionThread(DV_AVC_CMD_DELAY_INTER_CMD);
        DVGetDevIsItDVCPro(
            pDevExt
            );
    }


    //
    // Medium format: NTSC or PAL
    //
    pDevExt->VideoFormatIndex = FMT_IDX_SD_DVCR_NTSC;  // Default
    DVDelayExecutionThread(DV_AVC_CMD_DELAY_INTER_CMD);
    if(!DVGetDevSignalFormat(
        pDevExt,
        KSPIN_DATAFLOW_OUT,
        0)) {
        TRACE(TL_PNP_ERROR,("\'!!! Cannot determine IN/OUTPUT SIGNAL MODE!!!! Driver abort !!!\n"));
        return STATUS_UNSUCCESSFUL; // STATUS_NOT_SUPPORTED;
    } else {
        if(   pDevExt->VideoFormatIndex != FMT_IDX_SD_DVCR_NTSC 
           && pDevExt->VideoFormatIndex != FMT_IDX_SD_DVCR_PAL
           && pDevExt->VideoFormatIndex != FMT_IDX_SDL_DVCR_NTSC
           && pDevExt->VideoFormatIndex != FMT_IDX_SDL_DVCR_PAL
           ) {
            TRACE(TL_PNP_ERROR,("**** Format idx %d not supported by this driver ***\n", pDevExt->VideoFormatIndex));
            ASSERT(pDevExt->VideoFormatIndex == FMT_IDX_SD_DVCR_NTSC \
                || pDevExt->VideoFormatIndex == FMT_IDX_SD_DVCR_PAL \
                || pDevExt->VideoFormatIndex == FMT_IDX_SDL_DVCR_NTSC \
                || pDevExt->VideoFormatIndex == FMT_IDX_SDL_DVCR_PAL \
                );
            return STATUS_UNSUCCESSFUL; // STATUS_NOT_SUPPORTED;
        }
    }

    //
    // Mode of Operation: 0(Undetermined), Camera or VCR
    //
    DVDelayExecutionThread(DV_AVC_CMD_DELAY_INTER_CMD);
    DVGetDevModeOfOperation(
        pDevExt
        );

         
    return STATUS_SUCCESS; // Status;
}



NTSTATUS
DVInitializeDevice(
    IN PDVCR_EXTENSION  pDevExt,
    IN PPORT_CONFIGURATION_INFORMATION pConfigInfo,
    IN PAV_61883_REQUEST  pAVReq
    )
/*++

Routine Description:

    This where we perform the necessary initialization tasks.

--*/

{
    int i;
    NTSTATUS Status = STATUS_SUCCESS;

    PAGED_CODE();

    //
    // Initialize the device extension structure
    //
    DVIniDevExtStruct(
        pDevExt,
        pConfigInfo
        );

#ifdef READ_CUTOMIZE_REG_VALUES
    //
    // Get values from this device's own registry 
    //
    DVGetPropertyValuesFromRegistry(
        pDevExt
        );
#endif

    //
    // Query device information at the laod time:
    //    Subunit
    //    Unit Info
    //    Mode of operation
    //    NTSC or PAL
    //    Speed
    //    oPCR/iPCR
    //
    Status = 
        DVGetDevInfo(
            pDevExt,
            pAVReq
            );

    if(!NT_SUCCESS(Status)) {
        TRACE(TL_PNP_ERROR,("\'DVGetDevInfo failed %x\n", Status));
        // While driver is loading, the device could be unplug.
        // In this case, the AVC command can return STATUS_REQUEST_ABORTED.
        // In DvGetDevInfo may then return STATUS_NOT_SUPPORTED or STATUS_UNSUCCESSFUL.
        // We will then return this status to indicate loading failure.
#if 0 // DBG
        if(Status != STATUS_REQUEST_ABORTED && !NT_SUCCESS(Status)) {
            ASSERT(NT_SUCCESS(Status) && "DVGetDevInfo failed");
        }
#endif
        return Status;
    }


#ifdef NT51_61883

    //
    // Get Unit isoch parameters
    //
    if(!NT_SUCCESS(
        Status = DVGetUnitIsochParam(
            pDevExt, 
            &pDevExt->UnitIoschParams
            )))
        return Status;


    //
    // Create a local output plug.  This plug is used to updated isoch
    // resource used when connection was made. 
    //
    if(!NT_SUCCESS(
        Status = DVCreateLocalPlug(
            pDevExt, 
            CMP_PlugOut,
            0,                   // Plug number
            &pDevExt->hOPcrPC
            )))
        return Status;

#endif


    //
    // Note: Must do ExAllocatePool after DVIniDevExtStruct() since ->paCurrentStrmInfo is initialized.
    // Since the format that this driver support is known when this driver is known,'
    // the stream information table need to be custonmized.  Make a copy and customized it.
    //

    //
    // Set the size of the stream inforamtion structure that we returned in SRB_GET_STREAM_INFO
    //
        
    pDevExt->paCurrentStrmInfo = (HW_STREAM_INFORMATION *) 
        ExAllocatePool(NonPagedPool, sizeof(HW_STREAM_INFORMATION) * DV_STREAM_COUNT);

    if(!pDevExt->paCurrentStrmInfo) 
        return STATUS_INSUFFICIENT_RESOURCES;   
        
    pConfigInfo->StreamDescriptorSize = 
        (DV_STREAM_COUNT * sizeof(HW_STREAM_INFORMATION)) +      // number of stream descriptors
        sizeof(HW_STREAM_HEADER);                                // and 1 stream header

    // Make a copy of the default stream information
    for(i = 0; i < DV_STREAM_COUNT; i++ ) 
        pDevExt->paCurrentStrmInfo[i] = DVStreams[i].hwStreamInfo;          

    // Set AUDIO AUX to reflect: NTSC/PAL, consumer DV or DVCPRO
    if(pDevExt->bDVCPro) {
        // Note: there is no DVInfo in VideoInfoHeader but there is for the iAV streams.
        SDDV_IavPalStream.DVVideoInfo.dwDVAAuxSrc  = AAUXSRC_SD_PAL_DVCPRO;
        SDDV_IavPalStream.DVVideoInfo.dwDVAAuxSrc1 = AAUXSRC_SD_PAL_DVCPRO | AAUXSRC_AMODE_F;
        SDDV_IavPalStream.DVVideoInfo.dwDVVAuxSrc  = VAUXSRC_DEFAULT | AUXSRC_PAL | AUXSRC_STYPE_SD_DVCPRO;

        SDDV_IavNtscStream.DVVideoInfo.dwDVAAuxSrc = AAUXSRC_SD_NTSC_DVCPRO;
        SDDV_IavNtscStream.DVVideoInfo.dwDVAAuxSrc1= AAUXSRC_SD_NTSC_DVCPRO | AAUXSRC_AMODE_F;
        SDDV_IavNtscStream.DVVideoInfo.dwDVVAuxSrc = VAUXSRC_DEFAULT | AUXSRC_NTSC | AUXSRC_STYPE_SD_DVCPRO;

    } else {
        // This might be necessary for the 2nd instance of MSDV (1st:DVCPRO; 2nd:DVSD)
        SDDV_IavPalStream.DVVideoInfo.dwDVAAuxSrc  = AAUXSRC_SD_PAL;
        SDDV_IavPalStream.DVVideoInfo.dwDVAAuxSrc1 = AAUXSRC_SD_PAL  | AAUXSRC_AMODE_F;
        SDDV_IavPalStream.DVVideoInfo.dwDVVAuxSrc  = VAUXSRC_DEFAULT | AUXSRC_PAL | AUXSRC_STYPE_SD;

        SDDV_IavNtscStream.DVVideoInfo.dwDVAAuxSrc = AAUXSRC_SD_NTSC;
        SDDV_IavNtscStream.DVVideoInfo.dwDVAAuxSrc1= AAUXSRC_SD_NTSC | AAUXSRC_AMODE_F;
        SDDV_IavNtscStream.DVVideoInfo.dwDVVAuxSrc = VAUXSRC_DEFAULT | AUXSRC_NTSC | AUXSRC_STYPE_SD;
    }


    // Initialize last time format was updated
    pDevExt->tmLastFormatUpdate = GetSystemTime(); 


    TRACE(TL_PNP_WARNING,("\'#### %s%s:%s:%s PhyDO %x, BusDO %x, DevExt %x, FrmSz %d; StrmIf %d\n", 
        (pDevExt->ulDevType == ED_DEVTYPE_VCR ? "DVCR" : (pDevExt->ulDevType == ED_DEVTYPE_CAMERA ? "Camera" : "Tuner?")),
        pDevExt->bDVCPro ? "(DVCPRO)":"",
        (pDevExt->VideoFormatIndex == FMT_IDX_SD_DVCR_NTSC || pDevExt->VideoFormatIndex == FMT_IDX_SDL_DVCR_NTSC)? "SD:NTSC" : (pDevExt->VideoFormatIndex == FMT_IDX_SD_DVCR_PAL || pDevExt->VideoFormatIndex == FMT_IDX_SDL_DVCR_PAL) ? "PAL" : "MPEG_TS?",
        (pDevExt->ulDevType == ED_DEVTYPE_VCR && pDevExt->NumInputPlugs > 0) ? "CanRec" : "NotRec",
        pDevExt->pPhysicalDeviceObject, 
        pDevExt->pBusDeviceObject, 
        pDevExt,  
        DVFormatInfoTable[pDevExt->VideoFormatIndex].ulFrameSize,
        pConfigInfo->StreamDescriptorSize
        ));
    
    return STATUS_SUCCESS;
}

NTSTATUS
DVInitializeCompleted(
    IN PDVCR_EXTENSION  pDevExt
    )
/*++

Routine Description:

    This where we perform the necessary initialization tasks.

--*/

{
    PAGED_CODE();


#ifdef SUPPORT_OPTIMIZE_AVCCMD_RETRIES

    //
    // Determine retries 
    //
    pDevExt->DrvLoadCompleted = TRUE;

    if((pDevExt->AVCCmdRespTimeSum / pDevExt->AVCCmdCount) > 
       (DEFAULT_AVC_TIMEOUT * DEFAULT_AVC_RETRIES / 10000)) {
        // If every AVC command was timed out, do not bother to retry.
        pDevExt->AVCCmdRetries = 0;
    } else {

#if 0
        // Some camcorders do not queue up comand so follow a transport
        // state change, it will not accept any AVC command until transport
        // state is in the stable state.  So further delay is needed.

        if(
          // Exception for Samsung; always timeout following XPrt command
          // Or maybe it does not support transport state status command!
          pDevExt->ulVendorID == VENDORID_SAMSUNG                  
          ) {
            TRACE(TL_PNP_ERROR,("Samsung DV device: use default AVC setting.\n"));
        } else {
            pDevExt->AVCCmdRetries = MAX_AVC_CMD_RETRIES;
        }
#endif
    }

    TRACE(TL_PNP_ERROR,("AVCCMd Response Time: pDevExt:%x; Range (%d..%d); Avg %d/%d = %d; Retries:%d\n",
        pDevExt,
        pDevExt->AVCCmdRespTimeMin,
        pDevExt->AVCCmdRespTimeMax,
        pDevExt->AVCCmdRespTimeSum,
        pDevExt->AVCCmdCount,
        pDevExt->AVCCmdRespTimeSum / pDevExt->AVCCmdCount,
        pDevExt->AVCCmdRetries
        ));
#endif

    return STATUS_SUCCESS;
}

NTSTATUS
DVGetStreamInfo(
    IN PDVCR_EXTENSION        pDevExt,
    IN ULONG                  ulBytesToTransfer, 
    IN PHW_STREAM_HEADER      pStreamHeader,       
    IN PHW_STREAM_INFORMATION pStreamInfo
    )

/*++

Routine Description:

    Returns the information of all streams that are supported by the driver

--*/

{
    ULONG i;

    PAGED_CODE();


    //
    // Make sure we have enough space to return our stream informations
    //
    if(ulBytesToTransfer < sizeof (HW_STREAM_HEADER) + sizeof(HW_STREAM_INFORMATION) * DV_STREAM_COUNT ) {
        TRACE(TL_PNP_ERROR,("\'DVGetStrmInfo: ulBytesToTransfer %d ?= %d\n",  
            ulBytesToTransfer, sizeof(HW_STREAM_HEADER) + sizeof(HW_STREAM_INFORMATION) * DV_STREAM_COUNT ));
        return STATUS_INVALID_PARAMETER;
    }

    //
    // Initialize stream header:
    //   Device properties
    //   Streams
    //

    RtlZeroMemory(pStreamHeader, sizeof(HW_STREAM_HEADER));

    pStreamHeader->NumberOfStreams           = DV_STREAM_COUNT;
    pStreamHeader->SizeOfHwStreamInformation = sizeof(HW_STREAM_INFORMATION);

    pStreamHeader->NumDevPropArrayEntries    = NUMBER_VIDEO_DEVICE_PROPERTIES;
    pStreamHeader->DevicePropertiesArray     = (PKSPROPERTY_SET) VideoDeviceProperties;

    pStreamHeader->NumDevEventArrayEntries   = NUMBER_VIDEO_DEVICE_EVENTS;
    pStreamHeader->DeviceEventsArray         = (PKSEVENT_SET) VideoDeviceEvents;


    TRACE(TL_PNP_TRACE,("\'DVGetStreamInfo: StreamPropEntries %d, DevicePropEntries %d\n",
        pStreamHeader->NumberOfStreams, pStreamHeader->NumDevPropArrayEntries));


    //
    // Initialize the stream structure.
    //
    for( i = 0; i < DV_STREAM_COUNT; i++ )
        *pStreamInfo++ = pDevExt->paCurrentStrmInfo[i];

    //
    //
    // store a pointer to the topology for the device
    //        
    pStreamHeader->Topology = &Topology;


    return STATUS_SUCCESS;
}


BOOL 
DVVerifyDataFormat(
    PKSDATAFORMAT  pKSDataFormatToVerify, 
    ULONG          StreamNumber,
    ULONG          ulSupportedFrameSize,
    HW_STREAM_INFORMATION * paCurrentStrmInfo    
    )
/*++

Routine Description:

    Checks the validity of a format request by walking through the array of 
    supported KSDATA_RANGEs for a given stream.

Arguments:

     pKSDataFormat - pointer of a KS_DATAFORMAT_VIDEOINFOHEADER structure.
     StreamNumber - index of the stream being queried / opened.

Return Value:

     TRUE if the format is supported
     FALSE if the format cannot be suppored

--*/
{
    PKSDATAFORMAT  *pAvailableFormats;
    int            NumberOfFormatArrayEntries;
    int            j;
     
    PAGED_CODE();

    //
    // Make sure the stream index is valid (0..DV_STREAM_COUNT-1)
    //
    if(StreamNumber >= DV_STREAM_COUNT) {
        return FALSE;
    }

    //
    // How many formats does this stream support?
    //
    NumberOfFormatArrayEntries = paCurrentStrmInfo[StreamNumber].NumberOfFormatArrayEntries;

    //
    // Get the pointer to the array of available formats
    //
    pAvailableFormats = paCurrentStrmInfo[StreamNumber].StreamFormatsArray;
    
    
    //
    // Walk the array, searching for a match
    //
    for (j = 0; j < NumberOfFormatArrayEntries; j++, pAvailableFormats++) {
        
        //
        // Check supported sample size (== frame size). e.g. SD and SDL have different sample size.
        //
        if( (*pAvailableFormats)->SampleSize != ulSupportedFrameSize) {
            TRACE(TL_STRM_TRACE,("\'  StrmNum %d, %d of %d formats, SizeToVerify %d *!=* SupportedSampleSize %d\n", 
                StreamNumber,
                j+1, NumberOfFormatArrayEntries, 
                (*pAvailableFormats)->SampleSize,  
                ulSupportedFrameSize));
            continue;
        }

        if (!DVCmpGUIDsAndFormatSize(
                 pKSDataFormatToVerify, 
                 *pAvailableFormats,
                 TRUE, // Compare subformat
                 FALSE /* CompareFormatSize */ )) {
            continue;
        }

        //
        // Additional verification test
        //
        if(IsEqualGUID (&pKSDataFormatToVerify->Specifier, &KSDATAFORMAT_SPECIFIER_VIDEOINFO)) {
            // Make sure 
            if( ((PKS_DATAFORMAT_VIDEOINFOHEADER)pKSDataFormatToVerify)->VideoInfoHeader.bmiHeader.biSizeImage !=
                ulSupportedFrameSize) {
                TRACE(TL_STRM_WARNING,("VIDEOINFO: biSizeToVerify %d != Supported %d\n",
                    ((PKS_DATAFORMAT_VIDEOINFOHEADER)pKSDataFormatToVerify)->VideoInfoHeader.bmiHeader.biSizeImage,
                    ulSupportedFrameSize
                    ));
                continue;
            } else {
                TRACE(TL_STRM_TRACE,("VIDOINFO: **** biSizeToVerify %d == Supported %d\n",
                    ((PKS_DATAFORMAT_VIDEOINFOHEADER)pKSDataFormatToVerify)->VideoInfoHeader.bmiHeader.biSizeImage,
                    ulSupportedFrameSize
                    ));
            }
#ifdef SUPPORT_NEW_AVC 
        } else if (IsEqualGUID (&pKSDataFormatToVerify->Specifier, &KSDATAFORMAT_SPECIFIER_DVINFO) ||
                   IsEqualGUID (&pKSDataFormatToVerify->Specifier, &KSDATAFORMAT_SPECIFIER_DV_AVC)
            ) {
#else
        } else if (IsEqualGUID (&pKSDataFormatToVerify->Specifier, &KSDATAFORMAT_SPECIFIER_DVINFO)) {
#endif

            // Test 50/60 bit
            if((((PKS_DATARANGE_DVVIDEO) pKSDataFormatToVerify)->DVVideoInfo.dwDVAAuxSrc & MASK_AUX_50_60_BIT) != 
               (((PKS_DATARANGE_DVVIDEO) *pAvailableFormats)->DVVideoInfo.dwDVAAuxSrc    & MASK_AUX_50_60_BIT)  ||
               (((PKS_DATARANGE_DVVIDEO) pKSDataFormatToVerify)->DVVideoInfo.dwDVVAuxSrc & MASK_AUX_50_60_BIT) != 
               (((PKS_DATARANGE_DVVIDEO) *pAvailableFormats)->DVVideoInfo.dwDVVAuxSrc    & MASK_AUX_50_60_BIT) ) {

                TRACE(TL_STRM_WARNING,("VerifyFormat failed: ASrc: %x!=%x (MSDV);or VSrc: %x!=%x\n",                    
                 ((PKS_DATARANGE_DVVIDEO) pKSDataFormatToVerify)->DVVideoInfo.dwDVAAuxSrc, 
                    ((PKS_DATARANGE_DVVIDEO) *pAvailableFormats)->DVVideoInfo.dwDVAAuxSrc,
                 ((PKS_DATARANGE_DVVIDEO) pKSDataFormatToVerify)->DVVideoInfo.dwDVVAuxSrc,
                    ((PKS_DATARANGE_DVVIDEO) *pAvailableFormats)->DVVideoInfo.dwDVVAuxSrc
                     ));

                continue;

            } 

#if 0
            // Make sure the verified format's sample size is supported by the device
            if(ulSupportedFrameSize != ((PKS_DATARANGE_DVVIDEO) pKSDataFormatToVerify)->DataRange.SampleSize) {
                TRACE(TL_STRM_WARNING,("\'SupportedFrameSize %d != SampleSize:%d\n", 
                    ulSupportedFrameSize, ((PKS_DATARANGE_DVVIDEO)pKSDataFormatToVerify)->DataRange.SampleSize));
                continue;
            }
#endif

            TRACE(TL_STRM_TRACE,("\'DVINFO: dwDVAAuxCtl %x, Supported %x\n", 
                ((PKS_DATARANGE_DVVIDEO) pKSDataFormatToVerify)->DVVideoInfo.dwDVAAuxSrc,
                ((PKS_DATARANGE_DVVIDEO) *pAvailableFormats)->DVVideoInfo.dwDVAAuxSrc
                ));

            TRACE(TL_STRM_TRACE,("\'DVINFO: dwDVVAuxSrc %x, Supported %x\n", 
                ((PKS_DATARANGE_DVVIDEO) pKSDataFormatToVerify)->DVVideoInfo.dwDVVAuxSrc,
                ((PKS_DATARANGE_DVVIDEO) *pAvailableFormats)->DVVideoInfo.dwDVVAuxSrc
                ));

        }
        else {
            continue;
        }


        return TRUE;
    }

    return FALSE;
} 




NTSTATUS
DVGetDataIntersection(
    IN  ULONG          ulStreamNumber,
    IN  PKSDATARANGE   pDataRange,
    OUT PVOID          pDataFormatBuffer,
    IN  ULONG          ulSizeOfDataFormatBuffer,
    IN  ULONG          ulSupportedFrameSize,
    OUT ULONG          *pulActualBytesTransferred,
    HW_STREAM_INFORMATION * paCurrentStrmInfo
#ifdef SUPPORT_NEW_AVC            
    ,IN HANDLE hPlug
#endif
    )
/*++

Routine Description:

    Called to get a DATAFORMAT from a DATARANGE.

--*/
{
    BOOL                        bMatchFound = FALSE;
    ULONG                       ulFormatSize;
    ULONG                       j;
    ULONG                       ulNumberOfFormatArrayEntries;
    PKSDATAFORMAT               *pAvailableFormats;

    PAGED_CODE();

    
    
    //
    // Check that the stream number is valid
    //
    if(ulStreamNumber >= DV_STREAM_COUNT) {
        TRACE(TL_STRM_ERROR,("\'DVCRFormatFromRange: ulStreamNumber %d >= DV_STREAM_COUNT %d\n", ulStreamNumber, DV_STREAM_COUNT)); 
        return STATUS_NOT_SUPPORTED;
    }


    // Number of format this stream supports
    ulNumberOfFormatArrayEntries = paCurrentStrmInfo[ulStreamNumber].NumberOfFormatArrayEntries;

    //
    // Get the pointer to the array of available formats
    //
    pAvailableFormats = paCurrentStrmInfo[ulStreamNumber].StreamFormatsArray;


    //
    // Walk the formats supported by the stream searching for a match
    // Note: DataIntersection is really enumerating supported MediaType only!
    //       SO matter compare format is NTSC or PAL, we need suceeded both;
    //       however, we will copy back only the format is currently supported (NTSC or PAL).
    //
    for(j = 0; j < ulNumberOfFormatArrayEntries; j++, pAvailableFormats++) {

        if(!DVCmpGUIDsAndFormatSize(pDataRange, *pAvailableFormats, FALSE, TRUE)) {
            TRACE(TL_STRM_TRACE,("\'DVCmpGUIDsAndFormatSize failed!\n"));
            continue;
        }

        //
        // Check supported sample size (== frame size).
        //
        if( (*pAvailableFormats)->SampleSize != ulSupportedFrameSize) {
            TRACE(TL_STRM_TRACE,("\'  StrmNum %d, %d of %d formats, SizeToVerify %d *!=* SupportedSampleSize %d\n", 
                ulStreamNumber,
                j+1, ulNumberOfFormatArrayEntries, 
                (*pAvailableFormats)->SampleSize,  
                ulSupportedFrameSize));
            continue;
        }

         
        // -------------------------------------------------------------------
        // Specifier FORMAT_VideoInfo for VIDEOINFOHEADER
        // -------------------------------------------------------------------

        if(IsEqualGUID (&pDataRange->Specifier, &KSDATAFORMAT_SPECIFIER_VIDEOINFO)) {
         
            PKS_DATARANGE_VIDEO pDataRangeVideoToVerify = (PKS_DATARANGE_VIDEO) pDataRange;
            PKS_DATARANGE_VIDEO pDataRangeVideo         = (PKS_DATARANGE_VIDEO) *pAvailableFormats;

#if 0
            //
            // Check that the other fields match
            //
            if ((pDataRangeVideoToVerify->bFixedSizeSamples      != pDataRangeVideo->bFixedSizeSamples)
                || (pDataRangeVideoToVerify->bTemporalCompression   != pDataRangeVideo->bTemporalCompression) 
                || (pDataRangeVideoToVerify->StreamDescriptionFlags != pDataRangeVideo->StreamDescriptionFlags) 
                || (pDataRangeVideoToVerify->MemoryAllocationFlags  != pDataRangeVideo->MemoryAllocationFlags) 
#ifdef COMPARE_CONFIG_CAP
                || (RtlCompareMemory (&pDataRangeVideoToVerify->ConfigCaps,
                    &pDataRangeVideo->ConfigCaps,
                    sizeof (KS_VIDEO_STREAM_CONFIG_CAPS)) != 
                    sizeof (KS_VIDEO_STREAM_CONFIG_CAPS))
#endif
                    )   {

                TRACE(TL_STRM_TRACE,("\'DVFormatFromRange: *!=* bFixSizeSample (%d %d) (%d %d) (%d %d) (%x %x)\n",
                    pDataRangeVideoToVerify->bFixedSizeSamples,      pDataRangeVideo->bFixedSizeSamples,
                    pDataRangeVideoToVerify->bTemporalCompression ,  pDataRangeVideo->bTemporalCompression,
                    pDataRangeVideoToVerify->StreamDescriptionFlags, pDataRangeVideo->StreamDescriptionFlags,
                    pDataRangeVideoToVerify->ConfigCaps.VideoStandard, pDataRangeVideo->ConfigCaps.VideoStandard 
                    ));
                    
                continue;
            } else {
                TRACE(TL_STRM_TRACE,("\'DVFormatFromRange: == bFixSizeSample (%d %d) (%d %d) (%d %d) (%x %x)\n",
                    pDataRangeVideoToVerify->bFixedSizeSamples,      pDataRangeVideo->bFixedSizeSamples,
                    pDataRangeVideoToVerify->bTemporalCompression ,  pDataRangeVideo->bTemporalCompression,
                    pDataRangeVideoToVerify->StreamDescriptionFlags, pDataRangeVideo->StreamDescriptionFlags,
                    pDataRangeVideoToVerify->ConfigCaps.VideoStandard, pDataRangeVideo->ConfigCaps.VideoStandard 
                    ));
            }
           
#endif
            bMatchFound = TRUE;            
            ulFormatSize = sizeof (KSDATAFORMAT) + 
                KS_SIZE_VIDEOHEADER (&pDataRangeVideo->VideoInfoHeader);
            
            if(ulSizeOfDataFormatBuffer == 0) {

                // We actually have not returned this much data,
                // this "size" will be used by Ksproxy to send down 
                // a buffer of that size in next query.
                *pulActualBytesTransferred = ulFormatSize;

                return STATUS_BUFFER_OVERFLOW;
            }


            // Caller wants the full data format
            if(ulSizeOfDataFormatBuffer < ulFormatSize) {
                TRACE(TL_STRM_ERROR,("VIDEOINFO: StreamNum %d, SizeOfDataFormatBuffer %d < ulFormatSize %d\n",ulStreamNumber, ulSizeOfDataFormatBuffer, ulFormatSize));
                return STATUS_BUFFER_TOO_SMALL;
            }

            // KS_DATAFORMAT_VIDEOINFOHEADER
            //    KSDATAFORMAT            DataFormat;
            //    KS_VIDEOINFOHEADER      VideoInfoHeader;                
            RtlCopyMemory(
                &((PKS_DATAFORMAT_VIDEOINFOHEADER)pDataFormatBuffer)->DataFormat,
                &pDataRangeVideo->DataRange, 
                sizeof (KSDATAFORMAT));

            // This size is differnt from our data range size which also contains ConfigCap
            ((PKSDATAFORMAT)pDataFormatBuffer)->FormatSize = ulFormatSize;
            *pulActualBytesTransferred = ulFormatSize;

            RtlCopyMemory(
                &((PKS_DATAFORMAT_VIDEOINFOHEADER) pDataFormatBuffer)->VideoInfoHeader,
                &pDataRangeVideo->VideoInfoHeader,  
                KS_SIZE_VIDEOHEADER (&pDataRangeVideo->VideoInfoHeader));

            TRACE(TL_STRM_TRACE,("\'DVFormatFromRange: Matched, StrmNum %d, FormatSize %d, CopySize %d; FormatBufferSize %d, biSizeImage.\n", 
                ulStreamNumber, (*pAvailableFormats)->FormatSize, ulFormatSize, ulSizeOfDataFormatBuffer,
                ((PKS_DATAFORMAT_VIDEOINFOHEADER) pDataFormatBuffer)->VideoInfoHeader.bmiHeader.biSizeImage));

            return STATUS_SUCCESS;

        } else if (IsEqualGUID (&pDataRange->Specifier, &KSDATAFORMAT_SPECIFIER_DVINFO)) {
            // -------------------------------------------------------------------
            // Specifier FORMAT_DVInfo for KS_DATARANGE_DVVIDEO
            // -------------------------------------------------------------------

            // MATCH FOUND!
            bMatchFound = TRUE;            

            ulFormatSize = sizeof(KS_DATARANGE_DVVIDEO);

            if(ulSizeOfDataFormatBuffer == 0) {
                // We actually have not returned this much data,
                // this "size" will be used by Ksproxy to send down 
                // a buffer of that size in next query.
                *pulActualBytesTransferred = ulFormatSize;
                return STATUS_BUFFER_OVERFLOW;
            }
            
            // Caller wants the full data format
            if (ulSizeOfDataFormatBuffer < ulFormatSize) {
                TRACE(TL_STRM_ERROR,("\'DVINFO: StreamNum %d, SizeOfDataFormatBuffer %d < ulFormatSize %d\n", ulStreamNumber, ulSizeOfDataFormatBuffer, ulFormatSize));
                return STATUS_BUFFER_TOO_SMALL;
            }

            RtlCopyMemory(
                pDataFormatBuffer,
                *pAvailableFormats, 
                (*pAvailableFormats)->FormatSize); 

            
            ((PKSDATAFORMAT)pDataFormatBuffer)->FormatSize = ulFormatSize;
            *pulActualBytesTransferred = ulFormatSize;

            TRACE(TL_STRM_TRACE,("\'** DVFormatFromRange: (DVINFO) Matched, StrmNum %d, FormatSize %d, CopySize %d; FormatBufferSize %d.\n", 
                ulStreamNumber, (*pAvailableFormats)->FormatSize, ulFormatSize, ulSizeOfDataFormatBuffer));

            return STATUS_SUCCESS;

#ifdef SUPPORT_NEW_AVC            
        } else if (IsEqualGUID (&pDataRange->Specifier, &KSDATAFORMAT_SPECIFIER_DV_AVC)) {
            // -------------------------------------------------------------------
            // Specifier FORMAT_DVInfo for KS_DATARANGE_DVVIDEO
            // -------------------------------------------------------------------

            // MATCH FOUND!
            bMatchFound = TRUE;            

            ulFormatSize = sizeof(KS_DATARANGE_DV_AVC);

            if(ulSizeOfDataFormatBuffer == 0) {
                // We actually have not returned this much data,
                // this "size" will be used by Ksproxy to send down 
                // a buffer of that size in next query.
                *pulActualBytesTransferred = ulFormatSize;
                return STATUS_BUFFER_OVERFLOW;
            }
            
            // Caller wants the full data format
            if (ulSizeOfDataFormatBuffer < ulFormatSize) {
                TRACE(TL_STRM_ERROR,("\'** DV_AVC: StreamNum %d, SizeOfDataFormatBuffer %d < ulFormatSize %d\n", ulStreamNumber, ulSizeOfDataFormatBuffer, ulFormatSize));
                return STATUS_BUFFER_TOO_SMALL;
            }

            RtlCopyMemory(
                pDataFormatBuffer,
                *pAvailableFormats, 
                (*pAvailableFormats)->FormatSize); 
            
            ((KS_DATAFORMAT_DV_AVC *)pDataFormatBuffer)->ConnectInfo.hPlug = hPlug;

            ((PKSDATAFORMAT)pDataFormatBuffer)->FormatSize = ulFormatSize;
            *pulActualBytesTransferred = ulFormatSize;

            TRACE(TL_STRM_TRACE,("\'*** DVFormatFromRange: (DV_AVC) Matched, StrmNum %d, FormatSize %d, CopySize %d; FormatBufferSize %d.\n", 
                ulStreamNumber, (*pAvailableFormats)->FormatSize, ulFormatSize, ulSizeOfDataFormatBuffer));

            return STATUS_SUCCESS;

#endif // SUPPORT_NEW_AVC 
        }         
        else {
            TRACE(TL_STRM_ERROR,("\'Invalid Specifier, No match !\n"));
            return STATUS_NO_MATCH;
        }

    } // End of loop on all formats for this stream
    
    if(!bMatchFound) {

        TRACE(TL_STRM_TRACE,("\'DVFormatFromRange: No Match! StrmNum %d, pDataRange %x\n", ulStreamNumber, pDataRange));
    }

    return STATUS_NO_MATCH;         
}



VOID 
DVIniStrmExt(
    PHW_STREAM_OBJECT  pStrmObject,
    PSTREAMEX          pStrmExt,
    PDVCR_EXTENSION    pDevExt,
    const PALL_STREAM_INFO   pStream
    )
/*++

Routine Description:

    Initialize stream extension strcuture.

--*/
{

    PAGED_CODE();


    RtlZeroMemory( pStrmExt, sizeof(STREAMEX) );

    pStrmExt->bEOStream     = TRUE;       // Stream has not started yet!

    pStrmExt->pStrmObject   = pStrmObject;
    pStrmExt->StreamState   = KSSTATE_STOP;
    pStrmExt->pDevExt       = pDevExt;

    pStrmExt->hMyClock      = 0;
    pStrmExt->hMasterClock  = 0;
    pStrmExt->hClock        = 0;


//
// Aplly to both IN/OUT data flow
//
    //
    // Init isoch resources
    //
    pStrmExt->CurrentStreamTime = 0;  

    pStrmExt->cntSRBReceived  = 0;  // number of SRB_READ/WRITE_DATA
    pStrmExt->cntSRBCancelled = 0;  // number of SRB_READ/WRITE_DATA cancelled
    

    pStrmExt->FramesProcessed = 0;
    pStrmExt->PictureNumber   = 0;
    pStrmExt->FramesDropped   = 0;   


#ifdef MSDV_SUPPORT_EXTRACT_SUBCODE_DATA
    //
    // Subcode data that can be extract from a DV frame
    //

    pStrmExt->AbsTrackNumber = 0;
    pStrmExt->bATNUpdated    = FALSE;

    pStrmExt->Timecode[0] = 0;
    pStrmExt->Timecode[1] = 0;
    pStrmExt->Timecode[2] = 0;
    pStrmExt->Timecode[3] = 0;
    pStrmExt->bTimecodeUpdated = FALSE;
#endif

    //
    //  Flow control and queue management
    //

    pStrmExt->lStartIsochToken = 0;

    pStrmExt->pAttachFrameThreadObject = NULL;

    pStrmExt->cntSRBQueued = 0;                        // SRB_WRITE_DATA only
    InitializeListHead(&pStrmExt->SRBQueuedListHead);  // SRB_WRITE_DATA only

    pStrmExt->cntDataDetached = 0;
    InitializeListHead(&pStrmExt->DataDetachedListHead);

    pStrmExt->cntDataAttached = 0;
    InitializeListHead(&pStrmExt->DataAttachedListHead);

    pStrmExt->b1stNewFrameFromPauseState = TRUE;  // STOP State-> RUN will have discontinuity

    //
    // Work item variables use to cancel all SRBs
    //
    pStrmExt->lCancelStateWorkItem = 0;
    pStrmExt->bAbortPending = FALSE;
#ifdef USE_WDM110
    pStrmExt->pIoWorkItem = NULL;
#endif

   
    //
    // Cache the pointer
    // What in DVStreams[] are READONLY
    //
    pStrmExt->pStrmInfo = &pStream->hwStreamInfo;

    pStrmObject->ReceiveDataPacket    = (PVOID) pStream->hwStreamObject.ReceiveDataPacket;
    pStrmObject->ReceiveControlPacket = (PVOID) pStream->hwStreamObject.ReceiveControlPacket;
    pStrmObject->Dma                          = pStream->hwStreamObject.Dma;
    pStrmObject->Pio                          = pStream->hwStreamObject.Pio;
    pStrmObject->StreamHeaderWorkspace        = pStream->hwStreamObject.StreamHeaderWorkspace;
    pStrmObject->StreamHeaderMediaSpecific    = pStream->hwStreamObject.StreamHeaderMediaSpecific;
    pStrmObject->HwClockObject                = pStream->hwStreamObject.HwClockObject;
    pStrmObject->Allocator                    = pStream->hwStreamObject.Allocator;
    pStrmObject->HwEventRoutine               = pStream->hwStreamObject.HwEventRoutine;

}



NTSTATUS
DVOpenStream(
    IN PHW_STREAM_OBJECT pStrmObject,
    IN PKSDATAFORMAT     pOpenFormat,
    IN PAV_61883_REQUEST    pAVReq
    )

/*++

Routine Description:

    Verify the OpenFormat and then allocate PC resource needed for this stream.
    The isoch resource, if needed, is allocated when streaming is transition to PAUSE state.

--*/

{
    NTSTATUS         Status = STATUS_SUCCESS;
    PSTREAMEX        pStrmExt;
    PDVCR_EXTENSION  pDevExt;
    ULONG            idxStreamNumber;
    KSPIN_DATAFLOW   DataFlow;
    PIRP             pIrp;
    FMT_INDEX        VideoFormatIndexLast;  // Last format index; used to detect change.
#ifdef SUPPORT_NEW_AVC
    AVCCONNECTINFO * pAvcConnectInfo;
#endif


    PAGED_CODE();

    
    pDevExt  = (PDVCR_EXTENSION) pStrmObject->HwDeviceExtension;
    pStrmExt = (PSTREAMEX)       pStrmObject->HwStreamExtension;

    idxStreamNumber =            pStrmObject->StreamNumber;

    TRACE(TL_STRM_TRACE,("\'DVOpenStream: pStrmObject %x, pOpenFormat %x, cntOpen %d, idxStream %d\n", pStrmObject, pOpenFormat, pDevExt->cndStrmOpen, idxStreamNumber));

    //
    // Only one string can be open at any time to prevent cyclin connection
    //
    if(pDevExt->cndStrmOpen > 0) {
        TRACE(TL_STRM_WARNING,("\'DVOpenStream: %d stream open already; failed hr %x\n", pDevExt->cndStrmOpen, Status));
        return STATUS_UNSUCCESSFUL;
    }

    if(!(pIrp = IoAllocateIrp(pDevExt->pBusDeviceObject->StackSize, FALSE)))
        return STATUS_INSUFFICIENT_RESOURCES;

    //
    // If a user switch from Camera to VCR mode very quickly (passing the OFF position), 
    // the driver may not be relaoded to detect correct mode of operation.
    // It is safe to redetect here.
    // Note: MSDV does return all the stream info for both input and output pin format.
    //
    DVGetDevModeOfOperation(pDevExt);


    //
    // WARNING: !! we advertise both input and output pin regardless of its mode of operation,
    // but Camera does not support input pin so open should failed!
    // If a VCR does not have input pin should fail as well.
    //
    // Ignore checking for ED_DEVTYOPE_UNKNOWN (most likely a hardware decoder box)
    //
    if((pDevExt->ulDevType == ED_DEVTYPE_CAMERA || 
        (pDevExt->ulDevType == ED_DEVTYPE_VCR && pDevExt->NumInputPlugs == 0))
        && idxStreamNumber == 2) {
        TRACE(TL_STRM_ERROR,("\'OpenStream failed: Camera or VCR (0 inpin).\n"));
        Status =  STATUS_UNSUCCESSFUL;
        goto AbortOpenStream;
    }


    ASSERT(idxStreamNumber < DV_STREAM_COUNT);
    ASSERT(pDevExt->paStrmExt[idxStreamNumber] == NULL);  // Not yet open!

    //
    // Initialize the stream extension structure
    //
    DVIniStrmExt(
         pStrmObject, 
         pStrmExt,
         pDevExt,
         &DVStreams[idxStreamNumber]
         );

    // Sony's NTSC can play PAL tape and its plug will change its supported format accordingly.
    //
    // Query video format (NTSC/PAL) supported.
    // Compare with its default (set at load time or last opensteam),
    // if difference, change our internal video format table.
    //

    DataFlow= pDevExt->paCurrentStrmInfo[idxStreamNumber].DataFlow;

    VideoFormatIndexLast = pDevExt->VideoFormatIndex;
    if(!DVGetDevSignalFormat(
            pDevExt,
            DataFlow,
            pStrmExt
            )) {
            // If querying its format has failed, we cannot open this stream.
            TRACE(TL_STRM_ERROR,("\'OpenStream failed:cannot determine signal mode (NTSC/PAL, SD.SDL).\n"));
            Status = STATUS_UNSUCCESSFUL;
            goto AbortOpenStream;
    }


    //
    // Check the video data format is okay.
    //
    if(!DVVerifyDataFormat(
            pOpenFormat, 
            idxStreamNumber,
            DVFormatInfoTable[pDevExt->VideoFormatIndex].ulFrameSize,
            pDevExt->paCurrentStrmInfo
            ) ) { 
        TRACE(TL_STRM_ERROR,("\'DVOpenStream: AdapterVerifyFormat failed.\n"));        
        Status = STATUS_INVALID_PARAMETER;
        goto AbortOpenStream;
    }

           
    //
    // Initialize events used for synchronization
    //

#ifdef SUPPORT_PREROLL_AT_RUN_STATE
    KeInitializeEvent(&pStrmExt->hPreRollEvent,    NotificationEvent, FALSE);  // Non-signal; Satisfy multple thread; manual reset
#endif
    KeInitializeEvent(&pStrmExt->hSrbArriveEvent,  NotificationEvent, FALSE);  // Non-signal; Satisfy multiple thread; manual reset
    KeInitializeEvent(&pStrmExt->hCancelDoneEvent, NotificationEvent, TRUE);   // Signal!

    //
    // Synchronize attaching frame thread and other critical operations:
    //     (1) power off/on; and 
    //     (2) surprise removal
    //
    if(KSPIN_DATAFLOW_IN == DataFlow) {
        KeInitializeEvent(&pStrmExt->hRunThreadEvent,  SynchronizationEvent /*NotificationEvent*/, FALSE);

        // Def to SIGNAL state
        KeInitializeEvent(&pStrmExt->hStopThreadEvent, /*SynchronizationEvent*/ NotificationEvent, TRUE);  
    }


    //
    // Alloccate synchronization structures for flow control and queue management
    //

    if(!(pStrmExt->hStreamMutex = (KMUTEX *) ExAllocatePool(NonPagedPool, sizeof(KMUTEX)))) {
        Status = STATUS_INSUFFICIENT_RESOURCES;
        goto AbortOpenStream;
    }
    KeInitializeMutex( pStrmExt->hStreamMutex, 0);      // Level 0 and in Signal state

    if(!(pStrmExt->DataListLock = (KSPIN_LOCK *) ExAllocatePool(NonPagedPool, sizeof(KSPIN_LOCK)))) {
        Status = STATUS_INSUFFICIENT_RESOURCES;
        goto AbortOpenStream;
    }
    KeInitializeSpinLock(pStrmExt->DataListLock);
#if DBG
    pStrmExt->DataListLockSave = pStrmExt->DataListLock;
#endif

    //
    // Allocate resource for timer DPC
    //

    if(!(pStrmExt->DPCTimer = (KDPC *) ExAllocatePool(NonPagedPool, sizeof(KDPC)))) {  
        Status = STATUS_INSUFFICIENT_RESOURCES;
        goto AbortOpenStream;
    }

    if(!(pStrmExt->Timer = (KTIMER *) ExAllocatePool(NonPagedPool, sizeof(KTIMER)))) {  
        Status = STATUS_INSUFFICIENT_RESOURCES;
        goto AbortOpenStream;
    }

    //
    // Set a timer to periodically check for expired clock events.
    // This timer is active only in RUN state and if we are the clock provider.
    //
    KeInitializeDpc(
        pStrmExt->DPCTimer,
        DVSignalClockEvent,
        pStrmExt
        );
    KeInitializeTimer(
        pStrmExt->Timer
        );
    pStrmExt->bTimerEnabled = FALSE;


#ifdef SUPPORT_NEW_AVC
    if(IsEqualGUID (&pOpenFormat->Specifier, &KSDATAFORMAT_SPECIFIER_DV_AVC)) {
     
        pAvcConnectInfo = &((KS_DATAFORMAT_DV_AVC *) pOpenFormat)->ConnectInfo;
        if(DataFlow == KSPIN_DATAFLOW_OUT) {
            // DV1(that is us) (oPCR) -> DV2 (iPCR)
            pStrmExt->hOutputPcr = pDevExt->hOPcrDV;         // DV1's oPCR
            pStrmExt->hInputPcr  = pAvcConnectInfo->hPlug;   // DV2's iPCR
            TRACE(TL_STRM_WARNING,("\'!!!!! (pStrmExt:%x) DV1 (oPCR:%x) -> DV2 (iPCR:%x) !!!!!\n\n", pStrmExt, pStrmExt->hOutputPcr, pStrmExt->hInputPcr));
        } else {
            // DV1(that is us) (iPCR) <- DV2 (oPCR)
            pStrmExt->hOutputPcr = pAvcConnectInfo->hPlug;   // DV2's oPCR
            pStrmExt->hInputPcr  = pDevExt->hIPcrDV;         // DV1's iPCR
            TRACE(TL_STRM_WARNING,("\'!!!!! (pStrmExt:%x) DV1 (iPCR:%x) <- DV2 (oPCR:%x) !!!!!\n\n", pStrmExt, pStrmExt->hInputPcr, pStrmExt->hOutputPcr));
        }

        pStrmExt->bDV2DVConnect = TRUE;

    } else {

        if(DataFlow == KSPIN_DATAFLOW_OUT) {
            // DV1(that is us) (oPCR) -> PC (iPCR)
            pStrmExt->hOutputPcr = pDevExt->hOPcrDV;
            pStrmExt->hInputPcr  = 0; // We do not create local iPCR
            TRACE(TL_STRM_WARNING,("\'!!!!! (pStrmExt:%x) DV (oPCR:%x) -> PC (iPCR:%x) !!!!!\n\n", pStrmExt, pStrmExt->hOutputPcr, pStrmExt->hInputPcr));

        } else {
            // DV1(that is us) (iPCR) <- PC (oPCR)
            pStrmExt->hOutputPcr = pDevExt->hOPcrPC;
            pStrmExt->hInputPcr  = pDevExt->hIPcrDV;
            TRACE(TL_STRM_WARNING,("\'!!!!! (pStrmExt:%x) DV (iPCR:%x) <- PC (oPCR:%x) !!!!!\n\n", pStrmExt, pStrmExt->hInputPcr, pStrmExt->hOutputPcr));
        }

        pStrmExt->bDV2DVConnect = FALSE;
    }
#else
    if(DataFlow == KSPIN_DATAFLOW_OUT) {
        // DV1(that is us) (oPCR) -> PC (iPCR)
        pStrmExt->hOutputPcr = pDevExt->hOPcrDV;
        pStrmExt->hInputPcr  = 0; // We do not create local iPCR
        TRACE(TL_STRM_WARNING,("\'!!!!! (pStrmExt:%x) DV (oPCR:%x) -> PC (iPCR:%x) !!!!!\n\n", pStrmExt, pStrmExt->hOutputPcr, pStrmExt->hInputPcr));

    } else {
        // DV1(that is us) (iPCR) <- PC (oPCR)
        pStrmExt->hOutputPcr = pDevExt->hOPcrPC;
        pStrmExt->hInputPcr  = pDevExt->hIPcrDV;
        TRACE(TL_STRM_WARNING,("\'!!!!! (pStrmExt:%x) DV (iPCR:%x) <- PC (oPCR:%x) !!!!!\n\n", pStrmExt, pStrmExt->hInputPcr, pStrmExt->hOutputPcr));
    }
#endif

    IoFreeIrp(pIrp); pIrp = NULL;


#if DBG
    // Allocate buffer to keep statistic of transmitted buffers.
    pStrmExt->paXmtStat = (XMT_FRAME_STAT *) 
        ExAllocatePool(NonPagedPool, sizeof(XMT_FRAME_STAT) * MAX_XMT_FRAMES_TRACED);

    if(!pStrmExt->paXmtStat) {
        Status = STATUS_INSUFFICIENT_RESOURCES;
        goto AbortOpenStream;         
    }
    pStrmExt->ulStatEntries = 0;
#endif

    //
    // Pre-allcoate resource (Lists)
    //
    if(!NT_SUCCESS(
        Status = DvAllocatePCResource(
            DataFlow,
            pStrmExt
            ))) {
        goto AbortOpenStream; 
    }


    //
    //  Cache it and reference when pDevExt is all we have, 
    //  such as BusReset and SurprieseRemoval
    //
    pDevExt->idxStreamNumber = idxStreamNumber;  // index of current active stream; work only if there is only one active stream at any time.
    pDevExt->paStrmExt[idxStreamNumber] = pStrmExt;

    //
    // In the future, a DV can be unplug and plug back in, 
    // and restore its state if the application is not yet closed.
    //
    pDevExt->bDevRemoved    = FALSE;

    //
    // No one else can open another stream (inout or output) unitil this is release.
    // This is done to avoid cyclic graph.
    //
    pDevExt->cndStrmOpen++;    
    ASSERT(pDevExt->cndStrmOpen == 1);  // Only one can be open at any time.
    
    TRACE(TL_STRM_WARNING,("\'OpenStream: %d stream open, idx %d, Status %x, pStrmExt %x, pDevExt %x\n", 
        pDevExt->cndStrmOpen, pDevExt->idxStreamNumber, Status, pStrmExt, pDevExt));     
    TRACE(TL_STRM_WARNING,("\' #OPEN_STREAM#: Status %x, idxStream %d, pDevExt %x, pStrmExt %x\n", 
        Status, idxStreamNumber, pDevExt, pStrmExt));

    return Status;

AbortOpenStream:       

    if(pIrp) {
        IoFreeIrp(pIrp);  pIrp = NULL;        
    }

    if(pStrmExt->DataListLock) {
        ExFreePool(pStrmExt->DataListLock); pStrmExt->DataListLock = NULL;
    }

    if(pStrmExt->hStreamMutex) {
        ExFreePool(pStrmExt->hStreamMutex); pStrmExt->hStreamMutex = NULL;
    }

    if(pStrmExt->DPCTimer) {
        ExFreePool(pStrmExt->DPCTimer); pStrmExt->DPCTimer = NULL;
    }

    if(pStrmExt->Timer) {
        ExFreePool(pStrmExt->Timer); pStrmExt->Timer = NULL;
    }

#if DBG
    if(pStrmExt->paXmtStat) {
        ExFreePool(pStrmExt->paXmtStat); pStrmExt->paXmtStat = NULL;
    }
#endif

    TRACE(TL_STRM_WARNING,("\'#OPEN_STREAM# failed!: Status %x, idxStream %d, pDevExt %x, pStrmExt %x\n", 
        Status, idxStreamNumber, pDevExt, pStrmExt));

    return Status;
}


NTSTATUS
DVCloseStream(
    IN PHW_STREAM_OBJECT pStrmObject,
    IN PKSDATAFORMAT     pOpenFormat,
    IN PAV_61883_REQUEST    pAVReq
    )

/*++

Routine Description:

    Called when an CloseStream Srb request is received

--*/

{
    ULONG             i;
    PSTREAMEX         pStrmExt;
    PDVCR_EXTENSION   pDevExt;
    ULONG             idxStreamNumber;   


    PAGED_CODE();

    
    pDevExt  = (PDVCR_EXTENSION) pStrmObject->HwDeviceExtension;
    pStrmExt = (PSTREAMEX)       pStrmObject->HwStreamExtension;

    idxStreamNumber =            pStrmObject->StreamNumber;


    TRACE(TL_STRM_WARNING,("\'DVCloseStream: >> pStrmExt %x, pDevExt %x\n", pStrmExt, pDevExt));    


    //
    // If the stream isn't open, just return
    //
    if(pStrmExt == NULL) {
        ASSERT(pStrmExt && "CloseStream but pStrmExt is NULL!");   
        return STATUS_SUCCESS;  // ????
    }


    // 
    // If surprise removal, we may get a close stream before surprise is completed.
    //
    if(
          pStrmExt->pAttachFrameThreadObject  // If thread is created!
       && !pStrmExt->bTerminateThread
       && pStrmExt->pStrmInfo->DataFlow == KSPIN_DATAFLOW_IN
      ) {
        NTSTATUS StatusWait;

        TRACE(TL_PNP_WARNING|TL_STRM_WARNING,("\'>>>> CloseStream: Enter WFSO(hStopThreadEvent; lNeedService:%d)\n", pStrmExt->lNeedService));
        StatusWait = 
            KeWaitForSingleObject(
                &pStrmExt->hStopThreadEvent,
                Executive, 
                KernelMode, 
                FALSE, 
                0
                );
        TRACE(TL_PNP_WARNING|TL_STRM_WARNING,("\'<<<< CloseStream: Exit WFSO(hStopThreadEvent; lNeedService:%d)\n", pStrmExt->lNeedService));
    }

    //
    // Wait until the pending work item is completed.  
    //
    TRACE(TL_STRM_WARNING,("\'CloseStream: pStrmExt->lCancelStateWorkItem:%d\n", pStrmExt->lCancelStateWorkItem)); 
    KeWaitForSingleObject( &pStrmExt->hCancelDoneEvent, Executive, KernelMode, FALSE, 0 );


    // Cancel should have been done when we are in PAUSE state.
    // But if an application is close, it might not transtioning into PAUSE state.
    if(pStrmExt->bTimerEnabled) {
         TRACE(TL_STRM_WARNING,("\'*** (CloseStream) CancelTimer *\n"));
         KeCancelTimer(
            pStrmExt->Timer
            );
         pStrmExt->bTimerEnabled = FALSE;
    }


    //
    // If talking or listening (i.e. streaming), stop it!
    // In case of system shutdown while streaming or application crash
    //

    DVStopCancelDisconnect(
        pStrmExt
        );

    //
    // Free all allocated PC resoruce
    //
    DvFreePCResource(
        pStrmExt
        );

    ASSERT(pStrmExt->cntDataDetached == 0 && IsListEmpty(&pStrmExt->DataDetachedListHead) && "Detach List not empty!");
    ASSERT(pStrmExt->cntDataAttached == 0 && IsListEmpty(&pStrmExt->DataAttachedListHead) && "Attach List not empty!");
    ASSERT(pStrmExt->cntSRBQueued    == 0 && IsListEmpty(&pStrmExt->SRBQueuedListHead)    && "SrbQ List not empty!");


    // Terminate the system thread that is used for attaching frame for transmit to DV
    if(
          KSPIN_DATAFLOW_IN == pStrmExt->pStrmInfo->DataFlow
       && !pStrmExt->bTerminateThread
       && pStrmExt->pAttachFrameThreadObject
      ) { 
        DVTerminateAttachFrameThread(pStrmExt);
        pStrmExt->pAttachFrameThreadObject = NULL;
        TRACE(TL_STRM_WARNING,("** DVCloseStream: thread terminated!\n"));
    }



#if DBG
    // Print this only if the debug flag is set.
    if(pStrmExt->paXmtStat) {
        if(DVDebugXmt) {
            TRACE(TL_STRM_WARNING|TL_CIP_WARNING,("Data transmission statistics: (%s %s); (Pause:%d; Run:%d); hMasterClk:%x; hClock:%x\n\n", 
                __DATE__, __TIME__, pStrmExt->lFramesAccumulatedPaused, 
                pStrmExt->lFramesAccumulatedRun, pStrmExt->hMasterClock, pStrmExt->hClock));
            TRACE(TL_STRM_WARNING|TL_CIP_WARNING,("ST \tSrbRcv \tSrbQ \tSrbPend \tAttached \tSlot \ttmStream \tDrop \tSrb# \tFlags \ttmPres \tSCnt \tCyCnt \tCyOfst\n"));
            for(i=0; i < pStrmExt->ulStatEntries; i++) {
                TRACE(TL_STRM_WARNING|TL_CIP_WARNING,("%d \t%d \t%d \t%d \t%d \t%d \t%d \t%d \t%d \t%x \t%d \t%d \t%d \t%d\n",
                    pStrmExt->paXmtStat[i].StreamState,
                    pStrmExt->paXmtStat[i].cntSRBReceived,
                    pStrmExt->paXmtStat[i].cntSRBQueued,
                    pStrmExt->paXmtStat[i].cntSRBPending,
                    pStrmExt->paXmtStat[i].cntDataAttached,
                    (DWORD) pStrmExt->paXmtStat[i].FrameSlot,
                    (DWORD) pStrmExt->paXmtStat[i].tmStreamTime, // /10000,
                    pStrmExt->paXmtStat[i].DropCount,
                    pStrmExt->paXmtStat[i].FrameNumber,
                    (DWORD) pStrmExt->paXmtStat[i].OptionsFlags,
                    (DWORD) pStrmExt->paXmtStat[i].tmPresentation, // /10000,
                    pStrmExt->paXmtStat[i].tsTransmitted.CL_SecondCount,
                    pStrmExt->paXmtStat[i].tsTransmitted.CL_CycleCount,
                    pStrmExt->paXmtStat[i].tsTransmitted.CL_CycleOffset                 
                ));
            }
        }

        ExFreePool(pStrmExt->paXmtStat); pStrmExt->paXmtStat = NULL;
    }
#endif

    //
    //  Find the matching stream extension and invalidate it.
    //
    for (i=0; i<DV_STREAM_COUNT; i++) {

        if(pStrmExt == pDevExt->paStrmExt[i]) {
            ASSERT(!pDevExt->paStrmExt[i]->bAbortPending && "Cannot close a stream when abort is pending"); 
            pDevExt->paStrmExt[i] = NULL;
            break;
        }
    }

    // Release this count so other can open.   
    pDevExt->cndStrmOpen--;
    ASSERT(pDevExt->cndStrmOpen == 0);

    TRACE(TL_STRM_WARNING,("\'DVCloseStream: %d stream; AQD [%d:%d:%d]\n", 
        pDevExt->cndStrmOpen,
        pStrmExt->cntDataAttached,
        pStrmExt->cntSRBQueued,
        pStrmExt->cntDataDetached
        ));

#if DBG
    ASSERT(pStrmExt->DataListLockSave == pStrmExt->DataListLock);
#endif
    if(pStrmExt->DataListLock) {
        ExFreePool(pStrmExt->DataListLock); pStrmExt->DataListLock = NULL;
    }

    if(pStrmExt->hStreamMutex) {
        ExFreePool(pStrmExt->hStreamMutex); pStrmExt->hStreamMutex = NULL;
    }

    if(pStrmExt->DPCTimer) {
        ExFreePool(pStrmExt->DPCTimer); pStrmExt->DPCTimer = NULL;
    }

    if(pStrmExt->Timer) {
        ExFreePool(pStrmExt->Timer); pStrmExt->Timer = NULL;
    }


    //
    // Done with stream extention.  Will be invalid from this point on.
    //
#if 0
    RtlZeroMemory(pStrmExt, sizeof(STREAMEX));
#endif
    return STATUS_SUCCESS;
}


NTSTATUS
DVChangePower(
    PDVCR_EXTENSION  pDevExt,
    PAV_61883_REQUEST pAVReq,
    DEVICE_POWER_STATE NewPowerState
    )
/*++

Routine Description:

    Process changing this device's power state.  

--*/
{
    ULONG i;   
    NTSTATUS Status;

    PAGED_CODE();


    // 
    //    D0: Device is on and can be streaming.
    //    D1,D2: not supported.
    //    D3: Device is off and can not streaming. The context is lost.  
    //        Power can be removed from the device.
    //        When power is back on, we will get a bus reset.
    //

    TRACE(TL_PNP_WARNING,("\'PowrSt: %d->%d; (d0:[1:On],D3[4:off])\n", pDevExt->PowerState, NewPowerState));

    Status = STATUS_SUCCESS;

    if(pDevExt->PowerState == NewPowerState) {
        TRACE(TL_PNP_WARNING,("\'ChangePower: same power state!\n"));
        return STATUS_SUCCESS;
    }

    switch (NewPowerState) {
    case PowerDeviceD3:  // Power OFF   
        // We are at D0 and ask to go to D3: save state, stop streaming and Sleep
        if( pDevExt->PowerState == PowerDeviceD0)  {

            pDevExt->PowerState = NewPowerState;

            // For a supported power state change
            for (i=0; i<DV_STREAM_COUNT; i++) {
                if(pDevExt->paStrmExt[i]) {
                    TRACE(TL_PNP_WARNING,("\'D0->D3 (PowerOff), pStrmExt:%x; StrmSt:%d; IsochActive:%d; SrbQ:%d\n", 
                        pDevExt->paStrmExt[i], pDevExt->paStrmExt[i]->StreamState, pDevExt->paStrmExt[i]->bIsochIsActive, pDevExt->paStrmExt[i]->cntSRBQueued));

                    //
                    // Halt attach frame thread if it is an input pin
                    //
                    if(
                          pDevExt->paStrmExt[i]->pAttachFrameThreadObject  // If thread is created!
                       && !pDevExt->paStrmExt[i]->bTerminateThread         // Not terminated abnormally
                       && pDevExt->paStrmExt[i]->pStrmInfo->DataFlow == KSPIN_DATAFLOW_IN
                      ) {
                        NTSTATUS StatusWait;
#if 1
                        // Will be set in the thread attaching thread.
                        KeClearEvent(&pDevExt->paStrmExt[i]->hStopThreadEvent);
#endif
                        InterlockedIncrement(&pDevExt->paStrmExt[i]->lNeedService);   // Need thread to stop for other service.
                        
                        // In case the attach frame thread is idle! (no data to attach!)
                        KeSetEvent(&pDevExt->paStrmExt[i]->hSrbArriveEvent, 0 ,FALSE);
#ifdef SUPPORT_PREROLL_AT_RUN_STATE
                        KeSetEvent(&pDevExt->paStrmExt[i]->hPreRollEvent, 0 ,FALSE);
#endif

                        TRACE(TL_PNP_WARNING,("\'>>>> DVChangePower: Enter WFSO(hStopThreadEvent; lNeedService:%d)\n", pDevExt->paStrmExt[i]->lNeedService));
                        StatusWait = 
                            KeWaitForSingleObject(
                                &pDevExt->paStrmExt[i]->hStopThreadEvent,  // Signal when thread has stopped. 
                                Executive, 
                                KernelMode, 
                                FALSE, 
                                0  
                                );
                        TRACE(TL_PNP_WARNING,("\'<<<< DVChangePower: Exit WFSO(hStopThreadEvent; lNeedService:%d)\n", pDevExt->paStrmExt[i]->lNeedService));
                    }

                    if(pDevExt->paStrmExt[i]->bIsochIsActive) {
                        // Stop isoch but do not change the streaming state
                        TRACE(TL_PNP_WARNING,("\'ChangePower: Stop isoche; StrmSt:%d\n", pDevExt->paStrmExt[i]->StreamState)); 
                        DVStreamingStop(
                            pDevExt->paStrmExt[i], 
                            pDevExt, 
                            pAVReq
                            ) ;
                    }

                    // Complete all the pending events so that the downstream 
                    // filter (Video render) can release this buffer from AdviseTime() event.
                    // However, not sure why this is necessary since the lower filter 
                    // will get a PAUSE() or STOP() from the filter manager.  In such                    
                    DVSignalClockEvent(0, pDevExt->paStrmExt[i], 0, 0); 
                }
            }
        }
        else {
            TRACE(TL_PNP_WARNING,("\'ChangePower: unsupported %d -> %d; (do nothing!).\n", pDevExt->PowerState, DevicePowerState));           
        }
        break;

    case PowerDeviceD0:  // Powering ON (waking up)
        if( pDevExt->PowerState == PowerDeviceD3) {

            // Set PowerState change and then Signal PowerOn event
            pDevExt->PowerState = NewPowerState; 

            // For a supported power state change
            for (i=0; i<DV_STREAM_COUNT; i++) {
                if(pDevExt->paStrmExt[i]) {
                    TRACE(TL_PNP_WARNING,("\'D3->D0 (PowerOn), pStrmExt:%x; StrmSt:%d; IsochActive:%d; SrbQ:%d\n", 
                        pDevExt->paStrmExt[i], pDevExt->paStrmExt[i]->StreamState, pDevExt->paStrmExt[i]->bIsochIsActive, pDevExt->paStrmExt[i]->cntSRBQueued));
                    if(!pDevExt->paStrmExt[i]->bIsochIsActive) {
                        TRACE(TL_PNP_WARNING,("\'ChangePower: StrmSt:%d; Start isoch\n", pDevExt->paStrmExt[i]->StreamState)); 
                        // Start isoch depending on streaming state for DATAFLOW_IN/OUT
                        if(pDevExt->paStrmExt[i]->pStrmInfo->DataFlow == KSPIN_DATAFLOW_IN) {
                            if(pDevExt->paStrmExt[i]->StreamState == KSSTATE_PAUSE ||
                                pDevExt->paStrmExt[i]->StreamState == KSSTATE_RUN) {                             
                                DVStreamingStart(
                                    pDevExt->paStrmExt[i]->pStrmInfo->DataFlow, 
                                    pDevExt->paStrmExt[i], 
                                    pDevExt
                                    ) ;
                            }
                        }
                        else if(pDevExt->paStrmExt[i]->pStrmInfo->DataFlow == KSPIN_DATAFLOW_OUT) {
                            if(pDevExt->paStrmExt[i]->StreamState == KSSTATE_RUN) {                             
                                DVStreamingStart(
                                    pDevExt->paStrmExt[i]->pStrmInfo->DataFlow, 
                                    pDevExt->paStrmExt[i], 
                                    pDevExt
                                    ) ;
                            }
                        }                    
                    }  // IsochActive
#if 1  // Clear any buffer queued in the downstream.
                    // Complete all the pending events so that the downstream 
                    // filter (Video render) can release this buffer from AdviseTime() event.
                    // However, not sure why this is necessary since the lower filter 
                    // will get a PAUSE() or STOP() from the filter manager.  In such                    
                    DVSignalClockEvent(0, pDevExt->paStrmExt[i], 0, 0); 
#endif

                    //
                    // Resume attaching frame operation
                    //
                    if(
                          pDevExt->paStrmExt[i]->pAttachFrameThreadObject  // If thread is created!
                       && !pDevExt->paStrmExt[i]->bTerminateThread         // Not terminated abnormally
                       && pDevExt->paStrmExt[i]->pStrmInfo->DataFlow == KSPIN_DATAFLOW_IN
                      ) {
                        KeSetEvent(&pDevExt->paStrmExt[i]->hRunThreadEvent, 0 ,FALSE);
                    }
                }
            }
        }
        else {
            TRACE(TL_PNP_WARNING,("\'ChangePower: supported %d -> %d; (do nothing!).\n", pDevExt->PowerState, DevicePowerState));           
        }
        break;

    // These state are not supported.
    case PowerDeviceD1:
    case PowerDeviceD2:               
    default:
        TRACE(TL_PNP_WARNING,("\'ChangePower: unsupported %d to %d (do nothing).\n", pDevExt->PowerState, DevicePowerState));
        Status = STATUS_SUCCESS; // STATUS_INVALID_PARAMETER;
        break;
    }
           

    if(Status == STATUS_SUCCESS) 
        pDevExt->PowerState = NewPowerState;         
    else 
        Status = STATUS_NOT_IMPLEMENTED;

    TRACE(TL_PNP_WARNING,("\'DVChangePower: Exiting; Status:%x\n", Status));

    return STATUS_SUCCESS;     
}


NTSTATUS
DVSurpriseRemoval(
    PDVCR_EXTENSION pDevExt,
    PAV_61883_REQUEST  pAVReq
    )

/*++

Routine Description:

    Response to SRB_SURPRISE_REMOVAL.

--*/

{
    ULONG i;
    KIRQL    oldIrql;
    PKSEVENT_ENTRY   pEvent = NULL;

    PAGED_CODE();

    //
    // ONLY place this flag is set to TRUE.
    // Block incoming read although there might still in the process of being attached
    //
    KeAcquireSpinLock(&pDevExt->AVCCmdLock, &oldIrql);            
    pDevExt->bDevRemoved = TRUE;
    KeReleaseSpinLock(&pDevExt->AVCCmdLock, oldIrql);


    //
    // Now Stop the stream and clean up
    //

    for(i=0; i < DV_STREAM_COUNT; i++) {
        
        if(pDevExt->paStrmExt[i] != NULL) {

            TRACE(TL_PNP_WARNING,("\' #SURPRISE_REMOVAL# StrmNum %d, pStrmExt %x, Attached %d\n", 
                i, pDevExt->paStrmExt[i], pDevExt->paStrmExt[i]->cntDataAttached));

            // Signal this event so SRB can complete.
            if(pDevExt->paStrmExt[i]->pStrmInfo->DataFlow == KSPIN_DATAFLOW_IN ) {

                //
                // Imply EOStream! so the data source will stop sending us data.
                //
                KeAcquireSpinLock( pDevExt->paStrmExt[i]->DataListLock, &oldIrql);             
                if(!pDevExt->paStrmExt[i]->bEOStream)
                    pDevExt->paStrmExt[i]->bEOStream = TRUE;
                //
                // Signal EOStream
                //
                StreamClassStreamNotification(
                    SignalMultipleStreamEvents,
                    pDevExt->paStrmExt[i]->pStrmObject,
                    (GUID *)&KSEVENTSETID_Connection_Local,
                    KSEVENT_CONNECTION_ENDOFSTREAM
                    );
                TRACE(TL_PNP_WARNING,("\'Signal KSEVENT_CONNECTION_ENDOFSTREAM\n"));

                //
                // Stop the attaching frame thread
                //
                if(
                      pDevExt->paStrmExt[i]->pAttachFrameThreadObject  // If thread is created!
                   && !pDevExt->paStrmExt[i]->bTerminateThread
                  ) {
                    NTSTATUS StatusWait;
#if 1
                    // Will be set in the thread attaching thread.
                    KeClearEvent(&pDevExt->paStrmExt[i]->hStopThreadEvent);
#endif
                    InterlockedIncrement(&pDevExt->paStrmExt[i]->lNeedService);   // Request count
                        
                    // In case the attach frame thread is idle! (no data to attach!)
                    KeSetEvent(&pDevExt->paStrmExt[i]->hSrbArriveEvent, 0 ,FALSE);
#ifdef SUPPORT_PREROLL_AT_RUN_STATE
                    KeSetEvent(&pDevExt->paStrmExt[i]->hPreRollEvent,   0 ,FALSE);
#endif
                    KeReleaseSpinLock( pDevExt->paStrmExt[i]->DataListLock, oldIrql);                  

                    TRACE(TL_PNP_WARNING,("\'>>>> DVSurpriseRemoval: Enter WFSO(hStopThreadEvent; lNeedService:%d)\n", pDevExt->paStrmExt[i]->lNeedService));
                    StatusWait = 
                        KeWaitForSingleObject(
                            &pDevExt->paStrmExt[i]->hStopThreadEvent,  // Signal when thread has stopped. 
                            Executive, 
                            KernelMode, 
                            FALSE, 
                            0  
                            );
                    TRACE(TL_PNP_WARNING,("\'<<<< DVSurpriseRemoval: Exit WFSO(hStopThreadEvent; lNeedService:%d)\n", pDevExt->paStrmExt[i]->lNeedService));

                    //
                    // Note:
                    //   Terminate AttachFraameThread: KeSetEvent(&pDevExt->hRunThreadEvent, 0 ,FALSE) 
                    // 
                } else {
                    KeReleaseSpinLock( pDevExt->paStrmExt[i]->DataListLock, oldIrql); 
                }
            }

            //
            // Abort stream; stop and cancel pending data request
            //
            TRACE(TL_PNP_WARNING,("\'DVSurpriseRemoval: AbortStream enter...\n"));
            if(!DVAbortStream(pDevExt, pDevExt->paStrmExt[i])) {
                TRACE(TL_PNP_ERROR,("\'DVSurpriseRemoval: AbortStream failed\n"));
            }

            //
            // Adter surprise removal, all call to lower stack will be returned
            // with error.  Let's disconnect if it is connected.
            //

            //
            // Disable the timer
            //
            if(pDevExt->paStrmExt[i]->bTimerEnabled) {
                KeCancelTimer(
                    pDevExt->paStrmExt[i]->Timer
                    );
                pDevExt->paStrmExt[i]->bTimerEnabled = FALSE;
            }

            //
            // Wait until the pending work item is completed.  
            //
            TRACE(TL_PNP_WARNING,("\'SupriseRemoval: Wait for CancelDoneEvent <entering>; lCancelStateWorkItem:%d\n", pDevExt->paStrmExt[i]->lCancelStateWorkItem));
            KeWaitForSingleObject( &pDevExt->paStrmExt[i]->hCancelDoneEvent, Executive, KernelMode, FALSE, 0 );
            TRACE(TL_PNP_WARNING,("\'SupriseRemoval: Wait for CancelDoneEvent <exited>...\n"));
        }
    }


    // Signal KSEvent that device is removed.
    // After this SRb, there will be no more Set/Get property Srb into this driver.
    // By notifying the COM I/F, it will wither signal application that device is removed and
    // return ERROR_DEVICE_REMOVED error code for subsequent calls.

    // There might be multiple instances/threads of IAMExtTransport instance with the same KS event.
    // There is only one device so they all enabled event are singalled.
    do {
        if(pEvent = StreamClassGetNextEvent((PVOID) pDevExt, 0, \
            (GUID *)&KSEVENTSETID_EXTDEV_Command, KSEVENT_EXTDEV_NOTIFY_REMOVAL, pEvent)) {            
            // Make sure the right event and then signal it
            if(pEvent->EventItem->EventId == KSEVENT_EXTDEV_NOTIFY_REMOVAL) {
                StreamClassDeviceNotification(SignalDeviceEvent, pDevExt, pEvent);
                TRACE(TL_PNP_WARNING,("\'->Signal NOTIFY_REMOVAL; pEvent:%x, EventId %d.\n", pEvent, pEvent->EventItem->EventId));
            }          
        }  
    } while (pEvent != NULL);

    //
    // Since we may not get the busreset, let's go ahead and cancel all pending device control
    //
    DVAVCCmdResetAfterBusReset(pDevExt);

#ifdef NT51_61883
    //
    // Delete plug; 61883 will not accept 61883 request after surprise removal is processed.
    //
    if(pDevExt->hOPcrPC) {
        // Do not care about return status since we are being unloaded.
        DVDeleteLocalPlug( 
            pDevExt,
            pDevExt->hOPcrPC
            );
        pDevExt->hOPcrPC = NULL;
    }
#endif
   
    TRACE(TL_PNP_WARNING,("\'SurpriseRemoval exiting.\n"));
    return STATUS_SUCCESS;
}


// Return code is basically return in pSrb->Status.
NTSTATUS
DVProcessPnPBusReset(
    PDVCR_EXTENSION  pDevExt
    )
/*++

Routine Description:

    Process a bus reset.

Arguments:

    Srb - Pointer to stream request block

Return Value:

    Nothing

--*/
{   
#ifdef MSDVDV_SUPPORT_BUSRESET_EVENT
    PKSEVENT_ENTRY   pEvent;
#endif

    PAGED_CODE();


    TRACE(TL_PNP_WARNING,("\'DVProcessPnPBusReset: >>\n"));
    
#ifdef MSDVDV_SUPPORT_BUSRESET_EVENT
    //
    // Signal (if enabled) busreset event to let upper layer know that a busreset has occurred.
    //
    pEvent = NULL;
    pEvent = 
        StreamClassGetNextEvent(
            (PVOID) pDevExt,
            0, 
            (GUID *)&KSEVENTSETID_EXTDEV_Command,
            KSEVENT_EXTDEV_COMMAND_BUSRESET,
            pEvent
            );

    if(pEvent) {
        //
        // signal the event here
        //    
        if(pEvent->EventItem->EventId == KSEVENT_EXTDEV_COMMAND_BUSRESET) {
            StreamClassDeviceNotification(
                SignalDeviceEvent,
                pDevExt,
                pEvent
                );        

            TRACE(TL_PNP_WARNING,("\'DVProcessPnPBusReset: Signal BUSRESET; EventId %d.\n", pEvent->EventItem->EventId));
        }
    }
#endif   

    //
    // Reset pending count and AVC command that is in Interim
    //
    DVAVCCmdResetAfterBusReset(pDevExt);


    //
    // Can we return anything other than SUCCESS ?
    //
    return STATUS_SUCCESS;
}   


NTSTATUS
DVUninitializeDevice(
    IN PDVCR_EXTENSION  pDevExt
    )
/*++

Routine Description:

    This where we perform the necessary initialization tasks.

Arguments:

    Srb - Pointer to stream request block
'
Return Value:

    Nothing

--*/
{
    PAGED_CODE();

    TRACE(TL_PNP_WARNING,("\'DVUnInitialize: enter with DeviceExtension=0x%8x\n", pDevExt));

    //
    // Clear all pending AVC command entries.
    //
    DVAVCCmdResetAfterBusReset(pDevExt);


    // Free stream information allocated
    if(pDevExt->paCurrentStrmInfo) {
        ExFreePool(pDevExt->paCurrentStrmInfo);
        pDevExt->paCurrentStrmInfo = NULL;
    }

#ifdef NT51_61883
    if(pDevExt->hOPcrPC) {
        // Do not care about return status since we are being unloaded.
        DVDeleteLocalPlug( 
            pDevExt,
            pDevExt->hOPcrPC
            );
        pDevExt->hOPcrPC = NULL;
    }
#endif

    TRACE(TL_PNP_WARNING,("\'DVUnInitialize: Rest of allocated resources freed.\n"));

    return STATUS_SUCCESS;
}


//*****************************************************************************
//*****************************************************************************
// S T R E A M    S R B
//*****************************************************************************
//*****************************************************************************


NTSTATUS
DVGetStreamState(
    PSTREAMEX  pStrmExt,
    PKSSTATE   pStreamState,
    PULONG     pulActualBytesTransferred
    )
/*++

Routine Description:

    Gets the current state of the requested stream

--*/
{

    PAGED_CODE();

    if(!pStrmExt) {
        TRACE(TL_STRM_ERROR,("\'GetStreamState: pStrmExt is NULL; STATUS_UNSUCCESSFUL\n"));
        return STATUS_UNSUCCESSFUL;        
    }

    *pStreamState = pStrmExt->StreamState;
    *pulActualBytesTransferred = sizeof (KSSTATE);

    TRACE(TL_STRM_TRACE,("\'GetStreamState: %d (was %d)\n", pStrmExt->StreamState, pStrmExt->StreamStatePrevious));

    if(pStrmExt->StreamState == KSSTATE_PAUSE) {

        // One way to preroll is to delay when querying getting into the PAUSE state.
        // However, this routine is never executed!  So we move this section of code
        // to the thread.
#ifdef SUPPORT_PREROLL_AT_RUN_STATE
        if(   pStrmExt->pStrmInfo->DataFlow == KSPIN_DATAFLOW_IN
           && pStrmExt->hMasterClock  
           && pStrmExt->CurrentStreamTime == 0
          ) {
            // Simulate preroll at the RUN state
            // We do this only when we are the clock provider to avoid dropping frame
#define PREROLL_WAITTIME 2000000
            NTSTATUS StatusWait;
            LARGE_INTEGER DueTime;                 
            DueTime = RtlConvertLongToLargeInteger(-((LONG) PREROLL_WAITTIME));

            StatusWait =  // Can only return STATUS_SUCCESS (signal) or STATUS_TIMEOUT
                KeWaitForSingleObject( 
                    &pStrmExt->hPreRollEvent,
                    Executive,
                    KernelMode,          // Cannot return STATUS_USER_APC
                    FALSE,               // Cannot be alerted STATUS_ALERTED
                    &DueTime
                    );
             TRACE(TL_STRM_WARNING,("\'GetState: *Preroll*, waited %d msec; waitStatus:%x; srbRcved:%d\n", 
                 (DWORD) ((GetSystemTime() - pStrmExt->tmStreamPause)/10000), StatusWait,
                 (DWORD) pStrmExt->cntSRBReceived));
        }
#endif
        // A very odd rule:
        // When transitioning from stop to pause (and run->pause), DShow tries to preroll
        // the graph.  Capture sources can't preroll (there is no data until 
        // capture begin/run state), and indicate this by returning 
        // VFW_S_CANT_CUE (Map by KsProxy) in user mode.  To indicate this
        // condition from drivers, they must return ERROR_NO_DATA_DETECTED
        if(pStrmExt->pStrmInfo->DataFlow == KSPIN_DATAFLOW_OUT)            
            return STATUS_NO_DATA_DETECTED;        
        else 
            return STATUS_SUCCESS;
    } else 
        return STATUS_SUCCESS;
}

NTSTATUS
DVStreamingStop( 
    PSTREAMEX        pStrmExt,
    PDVCR_EXTENSION  pDevExt,
    PAV_61883_REQUEST   pAVReq
    )
/*++
Routine Description:

    Transitioning from any state to ->STOP state.
    Stops the video stream and cleans up all the descriptors;
    
++*/
{
    NTSTATUS   Status = STATUS_SUCCESS;
    PIRP pIrp;
    KIRQL oldIrql;

    PAGED_CODE();

#ifdef SUPPORT_NEW_AVC
    // No need to do CIP if it is device to device connection
    if(pStrmExt->bDV2DVConnect) {
        if(pStrmExt->bIsochIsActive)
            pStrmExt->bIsochIsActive = FALSE;
        return STATUS_SUCCESS;
    }
#endif

    //
    // Stop isoch listen or talk
    // Note: streaming and stream state can be separate; e.g. SURPRISE_REMOVAL, 
    //       we will stop stream but stream state does note get changed by this SRB.
    //

    if(pStrmExt->bIsochIsActive && pStrmExt->hConnect) {
       
        if(!(pIrp = IoAllocateIrp(pDevExt->pBusDeviceObject->StackSize, FALSE)))
            return STATUS_INSUFFICIENT_RESOURCES;              

        RtlZeroMemory(pAVReq, sizeof(AV_61883_REQUEST));
        INIT_61883_HEADER(pAVReq, Av61883_Stop);
        pAVReq->Stop.hConnect = pStrmExt->hConnect;

        if(!NT_SUCCESS(
            Status = DVSubmitIrpSynch( 
                pDevExt,
                pIrp,
                pAVReq
                ))) {

            TRACE(TL_61883_ERROR|TL_STRM_ERROR,("\'Av61883_Stop Failed; Status:%x\n", Status));
#if 1
            KeAcquireSpinLock(pStrmExt->DataListLock, &oldIrql);
            pStrmExt->bIsochIsActive = FALSE;  // Set it.  If this fail, it is a lower stack problem!
            KeReleaseSpinLock(pStrmExt->DataListLock, oldIrql);
            ASSERT(NT_SUCCESS(Status) && "Av61883_Stop failed!");
            Status = STATUS_SUCCESS;
#endif
        } else {
            KeAcquireSpinLock(pStrmExt->DataListLock, &oldIrql);
            pStrmExt->bIsochIsActive = FALSE;
            KeReleaseSpinLock(pStrmExt->DataListLock, oldIrql);
        }

        IoFreeIrp(pIrp);

        TRACE(TL_STRM_WARNING,("\'StreamingSTOPped; AQD [%d:%d:%d]\n", 
            pStrmExt->cntDataAttached,
            pStrmExt->cntSRBQueued,
            pStrmExt->cntDataDetached
            ));
    }

    return Status;
}


NTSTATUS
DVStreamingStart(
    KSPIN_DATAFLOW  ulDataFlow,
    PSTREAMEX       pStrmExt,
    PDVCR_EXTENSION pDevExt
    )
/*++
Routine Description:

    Tell device to start streaming.

++*/
{  
    PIRP         pIrp;
    NTSTATUS     Status;
    PAV_61883_REQUEST  pAVReq;
#if DBG
    ULONGLONG tmStart = GetSystemTime();
#endif


    PAGED_CODE();

#ifdef SUPPORT_NEW_AVC
    // No need to do CIP if it is device to device connection
    if(pStrmExt->bDV2DVConnect) {
        if(!pStrmExt->bIsochIsActive)
            pStrmExt->bIsochIsActive = TRUE;
        return STATUS_SUCCESS;
    }
#endif


    // NOTE: MUTEX is not needed since we are not staring isoch while attaching data.
    // This call is not reentry!!



    // Since it take time to activate isoch transfer, 
    // this sychronous function might get call again.
    // Need to start streaming only once.
    if(InterlockedExchange(&pStrmExt->lStartIsochToken, 1) == 1) {        
        TRACE(TL_STRM_WARNING,("\'lStartIsochToken taken already; return STATUS_SUCCESS\n"));
        return STATUS_SUCCESS;
    } 

#if DBG
    // Can stream only if in power on state.
    if(pDevExt->PowerState != PowerDeviceD0) {
        TRACE(TL_STRM_ERROR,("\'StreamingStart: PowerSt:%d; StrmSt:%d\n", pDevExt->PowerState, pStrmExt->StreamState));
        ASSERT(pDevExt->PowerState == PowerDeviceD0 && "Power state must be ON to start streaming!");
    }
#endif

    if(pStrmExt->bIsochIsActive) {
        TRACE(TL_STRM_WARNING,("\nIsoch already active!\n"));
        InterlockedExchange(&pStrmExt->lStartIsochToken, 0);
        return STATUS_SUCCESS;
    }
    else 
    if(!pStrmExt->hConnect) {
        TRACE(TL_STRM_WARNING,("hConnect=0, Cannot start isoch!\n"));
        InterlockedExchange(&pStrmExt->lStartIsochToken, 0);
        return STATUS_INVALID_PARAMETER;
    }
    else {
       
        if(!(pAVReq = (AV_61883_REQUEST *) ExAllocatePool(NonPagedPool, sizeof(AV_61883_REQUEST)))) {
            InterlockedExchange(&pStrmExt->lStartIsochToken, 0);
            return STATUS_INSUFFICIENT_RESOURCES;            
        }

        if(!(pIrp = IoAllocateIrp(pDevExt->pBusDeviceObject->StackSize, FALSE))) {
            InterlockedExchange(&pStrmExt->lStartIsochToken, 0);
            ExFreePool(pAVReq);  pAVReq = NULL;
            return STATUS_INSUFFICIENT_RESOURCES;
        }

        RtlZeroMemory(pAVReq, sizeof(AV_61883_REQUEST));
        if(ulDataFlow == KSPIN_DATAFLOW_OUT) {
            INIT_61883_HEADER(pAVReq, Av61883_Listen);
            pAVReq->Listen.hConnect = pStrmExt->hConnect;
        } else {
            INIT_61883_HEADER(pAVReq, Av61883_Talk);
            pAVReq->Talk.hConnect = pStrmExt->hConnect;
        }

        TRACE(TL_STRM_WARNING,("\'StreamingSTART; flow %d; AQD [%d:%d:%d]\n", 
            ulDataFlow, 
            pStrmExt->cntDataAttached,
            pStrmExt->cntSRBQueued,
            pStrmExt->cntDataDetached
            ));

        if(NT_SUCCESS(
            Status = DVSubmitIrpSynch( 
                pDevExt,
                pIrp,
                pAVReq
                ))) {
            pStrmExt->bIsochIsActive = TRUE;
            TRACE(TL_STRM_WARNING,("\'Av61883_%s; Status %x; Streaming...; took:%d (msec)\n", 
                (ulDataFlow == KSPIN_DATAFLOW_OUT ? "Listen" : "Talk"), Status, 
                (DWORD) ((GetSystemTime() - tmStart)/10000) ));
        }
        else {
            TRACE(TL_61883_ERROR|TL_STRM_ERROR,("Av61883_%s; failed %x; pAVReq:%x\n", (ulDataFlow == KSPIN_DATAFLOW_OUT ? "Listen" : "Talk"), Status, pAVReq));
            // ASSERT(NT_SUCCESS(Status) && "Start isoch failed!");
        }

        ExFreePool(pAVReq);  pAVReq = NULL;
        IoFreeIrp(pIrp);  pIrp = NULL;
    }

    InterlockedExchange(&pStrmExt->lStartIsochToken, 0);

    return Status;
}



NTSTATUS
DVSetStreamState(
    PSTREAMEX        pStrmExt,
    PDVCR_EXTENSION  pDevExt,
    PAV_61883_REQUEST   pAVReq,
    KSSTATE          StreamState
    )
/*++

Routine Description:

    Set to a new stream state.

--*/

{
    NTSTATUS Status = STATUS_SUCCESS;
    
    PAGED_CODE();

    if(!pStrmExt)  
        return STATUS_UNSUCCESSFUL;          

    TRACE(TL_STRM_WARNING,("\'** (%x) Set StrmST from %d to %d; PowerSt:%d (1/On;4/Off]); SrbRcved:%d\n",
        pStrmExt, pStrmExt->StreamState, StreamState, pDevExt->PowerState, (DWORD) pStrmExt->cntSRBReceived ));

#if DBG
    if(StreamState == KSSTATE_RUN) {
        ASSERT(pDevExt->PowerState == PowerDeviceD0 && "Cannot set to RUN while power is off!");
    }
#endif
    switch(StreamState) {

    case KSSTATE_STOP:
      
        if(pStrmExt->StreamState != KSSTATE_STOP) { 
     
            KeWaitForSingleObject( pStrmExt->hStreamMutex, Executive, KernelMode, FALSE, 0 );

            // Once this is set, data stream will reject SRB_WRITE/READ_DATA
            pStrmExt->StreamStatePrevious = pStrmExt->StreamState;  // Cache previous stream state.
            pStrmExt->StreamState = KSSTATE_STOP;

            // If stop, must be EOStream; but not vice versa.
            if(!pStrmExt->bEOStream) {
                pStrmExt->bEOStream = TRUE;
            }

            // Stop the IOThread from processing
            if(pStrmExt->pStrmInfo->DataFlow == KSPIN_DATAFLOW_IN) {
                KeClearEvent(&pStrmExt->hSrbArriveEvent);
#ifdef SUPPORT_PREROLL_AT_RUN_STATE
                KeClearEvent(&pStrmExt->hPreRollEvent);
#endif
            }

            KeReleaseMutex(pStrmExt->hStreamMutex, FALSE); 

            //
            // If there is a cancel event, we must wait for it to complete.
            //

            TRACE(TL_STRM_WARNING,("\'KSSTATE_STOP: pStrmExt->lCancelStateWorkItem:%d\n", pStrmExt->lCancelStateWorkItem)); 
            KeWaitForSingleObject( &pStrmExt->hCancelDoneEvent, Executive, KernelMode, FALSE, 0 );
            ASSERT(pStrmExt->lCancelStateWorkItem == 0 && "KSSTATE_STOP while there is an active CancelStateWorkItem");
            
            //
            // Stop stream, cacel data requests, terminate thread and disconnect.
            // This routine must suceeded in setting to STOP state
            //
            if(!NT_SUCCESS(
                Status = DVStopCancelDisconnect(
                    pStrmExt
                    ))) {
                Status = STATUS_SUCCESS;  // Cannot fail setting to stop state.
            }

        }

        break;

    case KSSTATE_ACQUIRE:
        //
        // This is a KS only state, that has no correspondence in DirectShow
        // It is our opportunity to allcoate resoruce (isoch bandwidth and program PCR (make connection)).
        //

        if(pStrmExt->StreamState == KSSTATE_STOP) { 

            //
            // Create a dispatch thread to attach frame to transmit to DV
            // This is create the first time transitioning from STOP->ACQUIRE state
            //

            if(
                  KSPIN_DATAFLOW_IN == pStrmExt->pStrmInfo->DataFlow
               && pStrmExt->pAttachFrameThreadObject == NULL 
              ) {

                //
                // Create a system thread for attaching data (for transmiut to DV only).
                //
                if(!NT_SUCCESS(
                    Status = DVCreateAttachFrameThread(
                        pStrmExt
                        ))) {
                    // Note that intially hConnect is NULL.
                    break;  // Cannot attach frame without this thread.
                }
            }


            //
            // Make connection
            //
            Status = 
                DVConnect(
                    pStrmExt->pStrmInfo->DataFlow,
                    pDevExt,
                    pStrmExt,
                    pAVReq
                    );

            if(!NT_SUCCESS(Status)) {

                TRACE(TL_STRM_ERROR,("\'Acquire failed; ST %x\n", Status));
                // ASSERT(NT_SUCCESS(Status));

                //
                // Change to generic insufficient resource status.
                //
                Status = STATUS_INSUFFICIENT_RESOURCES;

                //
                // Note: even setting to this state failed, KSSTATE_PAUSE will still be called;
                // Since hConnect is NULL, STATUS_INSUFFICIENT_RESOURCES will be returned.
                //
            } else {

                //
                // Verify connection by query the plug state
                //            
                DVGetPlugState(
                    pDevExt,
                    pStrmExt,
                    pAVReq
                    );
            }
        }

        break;

    case KSSTATE_PAUSE:                   

           
        if(pStrmExt->StreamState == KSSTATE_ACQUIRE || 
           pStrmExt->StreamState == KSSTATE_STOP)   {  

#ifdef SUPPORT_NEW_AVC
            if(!pStrmExt->bDV2DVConnect && pStrmExt->hConnect == NULL) {
#else
            if(pStrmExt->hConnect == NULL) {
#endif
                TRACE(TL_STRM_ERROR,("\'hConnect is NULL; STATUS_INSUFFICIENT_RESOURCES\n"));
                // Cannot stream without connection!
                Status = STATUS_INSUFFICIENT_RESOURCES;
                break;
            }

            //
            // Reset when transition from STOP to PAUSE state
            //

            // The system time (1394 CycleTime) will continue while setting
            // from RUN to PAUSE state.  
            pStrmExt->b1stNewFrameFromPauseState = TRUE;

#ifdef SUPPORT_QUALITY_CONTROL
            // +: late; -: early
            pStrmExt->KSQuality.DeltaTime = 0; // On time
            // Percentage * 10 of frame transmitted
            pStrmExt->KSQuality.Proportion = 1000;  // 100% sent
            pStrmExt->KSQuality.Context = /* NOT USED */ 0; 
#endif

            pStrmExt->CurrentStreamTime = 0;

            pStrmExt->FramesProcessed = 0;
            pStrmExt->PictureNumber   = 0;
            pStrmExt->FramesDropped   = 0;

            pStrmExt->cntSRBReceived  = 0;
            pStrmExt->cntSRBCancelled = 0;  // number of SRB_READ/WRITE_DATA cancelled
            pStrmExt->bEOStream       = FALSE;
#if DBG
            //
            // Initialize the debug log structure.
            //
            if(pStrmExt->paXmtStat) {
                pStrmExt->ulStatEntries   = 0;
                pStrmExt->lFramesAccumulatedPaused = 0;
                pStrmExt->lFramesAccumulatedRun    = 0;
                RtlZeroMemory(pStrmExt->paXmtStat, sizeof(XMT_FRAME_STAT) * MAX_XMT_FRAMES_TRACED);
            }
#endif

            //
            // Reset this event in case graph is restarted.
            // This evant will wait for enough buffers before start attaching frame for transmit
            //
            if(pStrmExt->pStrmInfo->DataFlow == KSPIN_DATAFLOW_IN) {
                KeClearEvent(&pStrmExt->hSrbArriveEvent);

#ifdef SUPPORT_PREROLL_AT_RUN_STATE                
                KeClearEvent(&pStrmExt->hPreRollEvent);
#if DBG
                pStrmExt->tmStreamPause = GetSystemTime();
#endif
#ifdef SUPPORT_KSPROXY_PREROLL_CHANGE
                pStrmExt->StreamStatePrevious = pStrmExt->StreamState;  // Cache previous stream state.
                pStrmExt->StreamState = StreamState;
#ifdef SUPPORT_NEW_AVC
                if(pStrmExt->bDV2DVConnect)
                    return STATUS_SUCCESS;
                else {
#endif  // SUPPORT_NEW_AVC
                    TRACE(TL_STRM_WARNING,("\'Set to KSSTATE_PAUSE; return STATUS_ALERTED\n"));
                    // We want to preroll.
                    return STATUS_ALERTED; 
#ifdef SUPPORT_NEW_AVC
                }
#endif  // SUPPORT_NEW_AVC
#endif  // SUPPORT_KSPROXY_PREROLL_CHANGE
#endif  // SUPPORT_PREROLL_AT_RUN_STATE
            }

        } else if (pStrmExt->StreamState == KSSTATE_RUN) {

            // The system time (1394 CycleTime) will continue while setting
            // from RUN to PAUSE state.  
            pStrmExt->b1stNewFrameFromPauseState = TRUE;

            //
            // Stop only if listening; for talking, the "pause" frame will be repeated
            //
            if(pStrmExt->pStrmInfo->DataFlow == KSPIN_DATAFLOW_OUT) {               
                // stop the stream internally inside 1394 stack
                DVStreamingStop(
                    pStrmExt,
                    pDevExt,
                    pAVReq
                    );
            } else {
                // Talk will continue.
                //    Do not stop isoch talk until stop state.
            }

            //
            // StreamTime pauses, so pause checking for expired clock events.
            // Resume if we enter RUN state again.
            //
            if(pStrmExt->bTimerEnabled) {
                TRACE(TL_STRM_TRACE,("\'*** (RUN->PAUSE) CancelTimer *********************************************...\n"));               
                KeCancelTimer(
                    pStrmExt->Timer
                    );
                pStrmExt->bTimerEnabled = FALSE;

                //
                // Complete any pending clock events
                //
                DVSignalClockEvent(0, pStrmExt, 0, 0);
            }
        }
        break;
                    
    case KSSTATE_RUN:

        if(pStrmExt->StreamState != KSSTATE_RUN) { 

            TRACE(TL_STRM_WARNING,("\'*RUN: hClock %x; hMasterClk %x; cntAttached:%d; StrmTm:%d\n", pStrmExt->hClock, pStrmExt->hMasterClock, pStrmExt->cntDataAttached, (DWORD) (pStrmExt->CurrentStreamTime/10000) ));

#if DBG
            if(!pStrmExt->hMasterClock && !pStrmExt->hClock)
                TRACE(TL_STRM_WARNING,("\'KSSTATE_RUN: no clock so free flowing!\n"));
#endif            

            // Use to mark the tick count when the stream start running.
            // It is later used to calculate current stream time and dropped frames.
            pStrmExt->tmStreamStart = GetSystemTime();
            pStrmExt->LastSystemTime = pStrmExt->tmStreamStart;


            // We start the timer to signal clock event only if we are the clock provider.
            // The interval is set to half of a DV frame time.
            if(pStrmExt->hMasterClock) {
                LARGE_INTEGER DueTime;

                DueTime = RtlConvertLongToLargeInteger(-((LONG) DVFormatInfoTable[pDevExt->VideoFormatIndex].ulAvgTimePerFrame/2));
                TRACE(TL_STRM_WARNING,("\'*** ScheduleTimer (RUN) ***\n"));
                KeSetTimerEx(
                    pStrmExt->Timer,
                    DueTime,
                    DVFormatInfoTable[pDevExt->VideoFormatIndex].ulAvgTimePerFrame/20000,  // Repeat every 40 MilliSecond
                    pStrmExt->DPCTimer
                    );
                pStrmExt->bTimerEnabled = TRUE;
            }

            if(pStrmExt->pStrmInfo->DataFlow == KSPIN_DATAFLOW_OUT) {

                // Start isoch listen; isoch talk will be start in the dispatch thread in either PAUSE or RUN state.
                // VfW application may use only one buffer!  61883 is attaching the descriptor list 
                // not this subunit driver so so it is ok to start streaming immediately without checking 
                // number of buffers attached.
                Status = 
                    DVStreamingStart(
                        pStrmExt->pStrmInfo->DataFlow,
                        pStrmExt,
                        pDevExt
                        );         
            }
        }

        break;
                    
    default:
                    
        TRACE(TL_STRM_ERROR,("\'SetStreamState:  unknown state = %x\n",StreamState));
        Status = STATUS_NOT_SUPPORTED;
        break;
    }

    // Be sure to save the state of the stream.
    TRACE(TL_STRM_WARNING,("\'DVSetStreamState: (%x)  from %d -> %d, Status %x\n", pStrmExt, pStrmExt->StreamState, StreamState, Status));

    if(Status == STATUS_SUCCESS) {
        pStrmExt->StreamStatePrevious = pStrmExt->StreamState;  // Cache previous stream state.
        pStrmExt->StreamState = StreamState;
    }

    return Status;
}



NTSTATUS 
DVStreamGetConnectionProperty (
    PDVCR_EXTENSION pDevExt,
    PSTREAMEX pStrmExt,
    PSTREAM_PROPERTY_DESCRIPTOR pSPD,
    PULONG pulActualBytesTransferred
    )
/*++

Routine Description:

    Handles KS_PROPERTY_CONNECTION* request.  For now, only ALLOCATORFRAMING and
    CONNECTION_STATE are supported.

--*/
{
    NTSTATUS Status = STATUS_SUCCESS;

    PAGED_CODE();


    TRACE(TL_STRM_TRACE,("\'DVStreamGetConnectionProperty:  entered ...\n"));

    switch (pSPD->Property->Id) {

    case KSPROPERTY_CONNECTION_ALLOCATORFRAMING:
        if (pDevExt != NULL && pDevExt->cndStrmOpen)  {
            PKSALLOCATOR_FRAMING pFraming = (PKSALLOCATOR_FRAMING) pSPD->PropertyInfo;
            
#ifdef SUPPORT_NEW_AVC 
            if(pStrmExt->bDV2DVConnect) {
                // No framing required.
                pFraming->RequirementsFlags = 0;
                pFraming->PoolType = DontUseThisType;
                pFraming->Frames = 0;
                pFraming->FrameSize = 0;
                pFraming->FileAlignment = 0; 
                pFraming->Reserved = 0;
            } else {
#endif
            pFraming->RequirementsFlags =
                KSALLOCATOR_REQUIREMENTF_SYSTEM_MEMORY |
                KSALLOCATOR_REQUIREMENTF_INPLACE_MODIFIER |
                KSALLOCATOR_REQUIREMENTF_PREFERENCES_ONLY;
            pFraming->PoolType = NonPagedPool;

            pFraming->Frames = \
                (pDevExt->paStrmExt[pDevExt->idxStreamNumber]->pStrmInfo->DataFlow == KSPIN_DATAFLOW_OUT ? \
                DVFormatInfoTable[pDevExt->VideoFormatIndex].ulNumOfRcvBuffers : \
                 DVFormatInfoTable[pDevExt->VideoFormatIndex].ulNumOfXmtBuffers);

            // Note:  we'll allocate the biggest frame.  We need to make sure when we're
            // passing the frame back up we also set the number of bytes in the frame.
            pFraming->FrameSize = DVFormatInfoTable[pDevExt->VideoFormatIndex].ulFrameSize;
            pFraming->FileAlignment = 0; // FILE_LONG_ALIGNMENT;
            pFraming->Reserved = 0;
#ifdef SUPPORT_NEW_AVC 
            }
#endif
            *pulActualBytesTransferred = sizeof (KSALLOCATOR_FRAMING);

            TRACE(TL_STRM_TRACE,("\'AllocFraming: cntStrmOpen:%d; VdoFmtIdx:%d; Frames %d; size:%d\n", \
                pDevExt->cndStrmOpen, pDevExt->VideoFormatIndex, pFraming->Frames, pFraming->FrameSize));
        } else {
            TRACE(TL_STRM_WARNING,("\'AllocFraming: pDevExt:%x; cntStrmOpen:%d\n", pDevExt, pDevExt->cndStrmOpen));
            Status = STATUS_INVALID_PARAMETER;
        }
        break;
        
    default:
        *pulActualBytesTransferred = 0;
        Status = STATUS_NOT_SUPPORTED;
        break;
    }

    TRACE(TL_STRM_TRACE,("\'DVStreamGetConnectionProperty:  exit.\n"));
    return Status;
}


NTSTATUS
DVGetDroppedFramesProperty(  
    PDVCR_EXTENSION pDevExt,
    PSTREAMEX       pStrmExt,
    PSTREAM_PROPERTY_DESCRIPTOR pSPD,
    PULONG pulBytesTransferred
    )
/*++

Routine Description:

    Return the dropped frame information while captureing.

--*/
{
    NTSTATUS Status = STATUS_SUCCESS;
  
    PAGED_CODE();

    switch (pSPD->Property->Id) {

    case KSPROPERTY_DROPPEDFRAMES_CURRENT:
         {

         PKSPROPERTY_DROPPEDFRAMES_CURRENT_S pDroppedFrames = 
                     (PKSPROPERTY_DROPPEDFRAMES_CURRENT_S) pSPD->PropertyInfo;
         
         pDroppedFrames->AverageFrameSize = DVFormatInfoTable[pStrmExt->pDevExt->VideoFormatIndex].ulFrameSize;

         if(pStrmExt->pStrmInfo->DataFlow == KSPIN_DATAFLOW_IN) {     
             // This is the picture number that MSDV is actually sending, and in a slow harddisk case,
             // it will be greater than (FramesProcessed + FramesDropped) considering repeat frame.
             pDroppedFrames->PictureNumber = pStrmExt->PictureNumber;
             pDroppedFrames->DropCount     = pStrmExt->FramesDropped; // pStrmExt->PictureNumber - pStrmExt->FramesProcessed;    // For transmit, this value includes both dropped and repeated.

         } else {
             pDroppedFrames->PictureNumber = pStrmExt->PictureNumber;         
             pDroppedFrames->DropCount     = pStrmExt->FramesDropped;    // For transmit, this value includes both dropped and repeated.
         }

         TRACE(TL_STRM_TRACE,("\'hMasClk:%x; *DroppedFP: Pic#(%d), Drp(%d); tmCurStream:%d\n", 
             pStrmExt->hMasterClock, 
             (LONG) pDroppedFrames->PictureNumber, (LONG) pDroppedFrames->DropCount,
             (DWORD) (pStrmExt->CurrentStreamTime/10000)
             ));
               
         *pulBytesTransferred = sizeof (KSPROPERTY_DROPPEDFRAMES_CURRENT_S);
         Status = STATUS_SUCCESS;

         }
         break;

    default:
        *pulBytesTransferred = 0;
        Status = STATUS_NOT_SUPPORTED;
        break;
    }

    return Status;
}

#ifdef SUPPORT_QUALITY_CONTROL
NTSTATUS
DVGetQualityControlProperty(  
    PDVCR_EXTENSION pDevExt,
    PSTREAMEX       pStrmExt,
    PSTREAM_PROPERTY_DESCRIPTOR pSPD,
    PULONG pulBytesTransferred
    )
/*++

Routine Description:

    Return the dropped frame information while captureing.

--*/
{
    NTSTATUS Status = STATUS_SUCCESS;
  
    PAGED_CODE();

    switch (pSPD->Property->Id) {

    case KSPROPERTY_STREAM_QUALITY:
        if(pStrmExt->pStrmInfo->DataFlow == KSPIN_DATAFLOW_IN) {     

            PKSQUALITY pKSQuality = (PKSQUALITY) pSPD->PropertyInfo;

            // Quality control only 
            if(pStrmExt->StreamState == KSSTATE_STOP || pStrmExt->StreamState == KSSTATE_ACQUIRE) {
                *pulBytesTransferred = 0;
                Status = STATUS_UNSUCCESSFUL;  // Data is not ready
                ASSERT(pSPD->Property->Id == KSPROPERTY_STREAM_QUALITY);
                break;                
            }
            /*
            log.Init_Quality(KSPROPERTY_QUALITY_REPORT, fSuccess);
            log.LogInt("Proportion", ksQuality.Proportion,
                "Indicates the percentage of frames currently being received which are actually being used. "
                " This is expressed in units of 0.1 of a percent, where 1000 is optimal.");
            log.LogLONGLONG("DeltaTime", ksQuality.DeltaTime,
                "Indicates the delta in native units (as indicated by the Interface) from optimal time at which "
                "the frames are being delivered, where a positive number means too late, and a negative number means too early. "
                "Zero indicate a correct delta.");
            log.LogPVOID("pvContext", ksQuality.Context,
                "Context parameter which could be a pointer to the filter pin interface used to "
                "locate the source of the complaint in the graph topology.");
            */
            pKSQuality->DeltaTime  = pStrmExt->KSQuality.DeltaTime;
            pKSQuality->Proportion = pStrmExt->KSQuality.Proportion;
            pKSQuality->Context    = 0;  // Not used!
            TRACE(TL_STRM_WARNING,("\'Get QualityControl: Context:%x; DeltaTime:%d; Proportion:%d\n", 
                pKSQuality->Context, (DWORD) pKSQuality->DeltaTime, pKSQuality->Proportion));
            Status = STATUS_SUCCESS;
            *pulBytesTransferred = sizeof(KSQUALITY);
         
         } else {
            *pulBytesTransferred = 0;
            Status = STATUS_NOT_SUPPORTED;       
         }
         break;
    default:
        *pulBytesTransferred = 0;
        Status = STATUS_NOT_SUPPORTED;
        break;
    }

    return Status;
}
#endif // SUPPORT_QUALITY_CONTROL


#ifdef SUPPORT_NEW_AVC
NTSTATUS
DVGetPinProperty(  
    PDVCR_EXTENSION pDevExt,
    PSTREAMEX       pStrmExt,
    PSTREAM_PROPERTY_DESCRIPTOR pSPD,
    PULONG pulBytesTransferred
    )
/*++

Routine Description:

    Return the dropped frame information while captureing.

--*/
{
    NTSTATUS Status = STATUS_SUCCESS;
    PKSPIN_MEDIUM pPinMediums;
    KSMULTIPLE_ITEM * pMultipleItem;
    ULONG idxStreamNumber;
    ULONG ulMediumsSize;
  
    PAGED_CODE();

    switch (pSPD->Property->Id) {

    case KSPROPERTY_PIN_MEDIUMS:
        if(!pStrmExt->pStrmObject) {         
            *pulBytesTransferred = 0;
            return STATUS_UNSUCCESSFUL;
        }

        idxStreamNumber = pStrmExt->pStrmObject->StreamNumber;
        ulMediumsSize = DVStreams[idxStreamNumber].hwStreamInfo.MediumsCount * sizeof(KSPIN_MEDIUM);

        TRACE(TL_STRM_WARNING,("\'KSPROPERTY_PIN_MEDIUMS: idx:%d; MediumSize:%d\n", idxStreamNumber, ulMediumsSize));

        // Its is KSMULTIPLE_ITEM so it is a two step process to return the data:
        // (1) return size in pActualBytesTransferred with STATUS_BUFFER_OVERFLOW
        // (2) 2nd time to get its actual data.
        if(pSPD->PropertyOutputSize == 0) {
            *pulBytesTransferred = sizeof(KSMULTIPLE_ITEM) + ulMediumsSize;
            Status = STATUS_BUFFER_OVERFLOW;          
        } else if(pSPD->PropertyOutputSize >= (sizeof(KSMULTIPLE_ITEM) + ulMediumsSize)) {
            pMultipleItem = (KSMULTIPLE_ITEM *) pSPD->PropertyInfo;    // pointer to the data
            pMultipleItem->Count = DVStreams[idxStreamNumber].hwStreamInfo.MediumsCount;
            pMultipleItem->Size  = sizeof(KSMULTIPLE_ITEM) + ulMediumsSize;
            pPinMediums = (PKSPIN_MEDIUM) (pMultipleItem + 1);    // pointer to the data
            memcpy(pPinMediums, DVStreams[idxStreamNumber].hwStreamInfo.Mediums, ulMediumsSize);
            *pulBytesTransferred = sizeof(KSMULTIPLE_ITEM) + ulMediumsSize;
            Status = STATUS_SUCCESS;         

        } else {
            TRACE(TL_STRM_ERROR,("DVCRMediaSeekingProperty: KSPROPERTY_MEDIASEEKING_FORMAT; STATUS_INVALID_PARAMETER\n"));
            Status = STATUS_INVALID_PARAMETER;
        }  
        break;

    default:
        *pulBytesTransferred = 0;
        Status = STATUS_NOT_SUPPORTED;
        break;
    }

    return Status;
}
#endif 

NTSTATUS
DVGetStreamProperty(
    PHW_STREAM_REQUEST_BLOCK pSrb
    )
/*++

Routine Description:

    Routine to process property request

--*/

{
    NTSTATUS Status = STATUS_SUCCESS;
    PSTREAM_PROPERTY_DESCRIPTOR pSPD = pSrb->CommandData.PropertyInfo;

    PAGED_CODE();

    TRACE(TL_STRM_TRACE,("\'DVGetStreamProperty:  entered ...\n"));

    if(IsEqualGUID (&KSPROPSETID_Connection, &pSPD->Property->Set)) {

        Status = 
            DVStreamGetConnectionProperty (
                pSrb->HwDeviceExtension,
                (PSTREAMEX) pSrb->StreamObject->HwStreamExtension,
                pSrb->CommandData.PropertyInfo,
                &pSrb->ActualBytesTransferred
                );
    } 
    else if (IsEqualGUID (&PROPSETID_VIDCAP_DROPPEDFRAMES, &pSPD->Property->Set)) {

        Status = 
            DVGetDroppedFramesProperty (
                pSrb->HwDeviceExtension,
                (PSTREAMEX) pSrb->StreamObject->HwStreamExtension,
                pSrb->CommandData.PropertyInfo,
                &pSrb->ActualBytesTransferred
                );
    } 
#ifdef SUPPORT_QUALITY_CONTROL
    else if (IsEqualGUID (&KSPROPSETID_Stream, &pSPD->Property->Set)) {

        Status = 
            DVGetQualityControlProperty (
                pSrb->HwDeviceExtension,
                (PSTREAMEX) pSrb->StreamObject->HwStreamExtension,
                pSrb->CommandData.PropertyInfo,
                &pSrb->ActualBytesTransferred
                );
    } 
#endif
#ifdef SUPPORT_NEW_AVC
    else if (IsEqualGUID (&KSPROPSETID_Pin, &pSPD->Property->Set)) {

        Status = 
            DVGetPinProperty (
                pSrb->HwDeviceExtension,
                (PSTREAMEX) pSrb->StreamObject->HwStreamExtension,
                pSrb->CommandData.PropertyInfo,
                &pSrb->ActualBytesTransferred
                );
    } 
#endif    
    else {
        Status = STATUS_NOT_SUPPORTED;
    }

    return Status;
}


NTSTATUS 
DVSetStreamProperty(
    PHW_STREAM_REQUEST_BLOCK pSrb
    )
/*++

Routine Description:

    Routine to process set property request

--*/

{
    PSTREAM_PROPERTY_DESCRIPTOR pSPD = pSrb->CommandData.PropertyInfo;

    PAGED_CODE();

    TRACE(TL_STRM_WARNING,("\'DVSetStreamProperty:  entered ...\n"));

    return STATUS_NOT_SUPPORTED;

}



NTSTATUS
DVCancelOnePacketCR(
    IN PDEVICE_OBJECT DeviceObject,
    IN PIRP pIrp,
    IN PSRB_DATA_PACKET pSrbDataPacket    
    )
/*++

Routine Description:

    Completion routine for detach an isoch descriptor associate with a pending read SRB.
    Will cancel the pending SRB here if detaching descriptor has suceeded.

--*/
{
    PSTREAMEX        pStrmExt;
    PLONG            plSrbUseCount;
    PHW_STREAM_REQUEST_BLOCK pSrbToCancel;
    KIRQL oldIrql;



    if(!NT_SUCCESS(pIrp->IoStatus.Status)) {
        TRACE(TL_STRM_ERROR,("CancelOnePacketCR: Srb:%x failed pIrp->Status %x\n", pSrbDataPacket->pSrb, pIrp->IoStatus.Status));
        IoFreeIrp(pIrp);  // Allocated locally 
        return STATUS_MORE_PROCESSING_REQUIRED;        
    }


    pStrmExt = pSrbDataPacket->pStrmExt;


    //
    // Add this to the attached list
    //
    KeAcquireSpinLock(pStrmExt->DataListLock, &oldIrql);

    // while it is being cancelled, it was completed ?
    if(pStrmExt->cntDataAttached <= 0) {
        TRACE(TL_STRM_WARNING|TL_CIP_WARNING,("\'DVCancelOnePacketCR:pStrmExt:%x, pSrbDataPacket:%x, AQD[%d:%d:%d]\n", \
            pStrmExt, pSrbDataPacket, 
            pStrmExt->cntDataAttached,
            pStrmExt->cntSRBQueued,
            pStrmExt->cntDataDetached
            ));
        ASSERT(pStrmExt->cntDataAttached > 0);
        KeReleaseSpinLock(pStrmExt->DataListLock, oldIrql); 
        IoFreeIrp(pIrp);  // Allocated locally        
        return STATUS_MORE_PROCESSING_REQUIRED;
    }


    pSrbToCancel = pSrbDataPacket->pSrb;  // Offload pSrb so this list entry can be inserted to available list.
    plSrbUseCount = (PLONG) pSrbDataPacket->pSrb->SRBExtension;
  
    // Remove from attached and add it to the detach list
    RemoveEntryList(&pSrbDataPacket->ListEntry); pStrmExt->cntDataAttached--; (*plSrbUseCount)--;

#if DBG
    // Detect if 61883 is starve.  This cause discontinuity.
    // This can happen for many valid reasons (slow system).
    // An assert is added to detect other unknown reason.
    if(pStrmExt->cntDataAttached == 0 && pStrmExt->StreamState == KSSTATE_RUN) {
        TRACE(TL_STRM_WARNING|TL_CIP_WARNING,("\n**** 61883 starve in RUN state (cancel); AQD[%d:%d:%d]\n\n", 
            pStrmExt->cntDataAttached, pStrmExt->cntSRBQueued, pStrmExt->cntDataDetached
        ));
        // ASSERT(pStrmExt->cntDataAttached > 0 && "61883 is starve at RUN state!!");
    }
#endif

    ASSERT(pStrmExt->cntDataAttached >= 0);
    ASSERT(*plSrbUseCount >= 0);
    
    InsertTailList(&pStrmExt->DataDetachedListHead, &pSrbDataPacket->ListEntry); pStrmExt->cntDataDetached++;
    pSrbDataPacket->State |= DE_IRP_CANCELLED;


    // 
    // Complete this Srb if its refCount is 0.
    // 
    if(*plSrbUseCount == 0) {
        PDVCR_EXTENSION  pDevExt;

        pDevExt = pStrmExt->pDevExt;
        pSrbToCancel->Status = (pDevExt->bDevRemoved ? STATUS_DEVICE_REMOVED : STATUS_CANCELLED);
        pSrbToCancel->CommandData.DataBufferArray->DataUsed = 0;
        pSrbToCancel->ActualBytesTransferred                = 0;
        pStrmExt->cntSRBCancelled++;  // RefCnt is 0, and cancelled.
        TRACE(TL_CIP_TRACE,("\'DVCancelOnePacketCR: Srb:%x cancelled; St:%x; cntCancel:%d\n", pSrbToCancel, pSrbToCancel->Status, pStrmExt->cntSRBCancelled));        

        StreamClassStreamNotification(StreamRequestComplete, pSrbToCancel->StreamObject, pSrbToCancel);  
        pSrbDataPacket->State |= DE_IRP_SRB_COMPLETED;  pSrbDataPacket->pSrb = NULL;
#if DBG
        pStrmExt->cntSRBPending--;
#endif
       
    }
    else {
        TRACE(TL_STRM_WARNING|TL_CIP_WARNING,("\'DVCancelOnePacketCR: Srb:%x; RefCnt:%d; not completed!\n", pSrbDataPacket->pSrb, *plSrbUseCount));
    }

    KeReleaseSpinLock(pStrmExt->DataListLock, oldIrql);
    IoFreeIrp(pIrp);  // Allocated locally 

    return STATUS_MORE_PROCESSING_REQUIRED;
}

NTSTATUS
DVStopCancelDisconnect(
    PSTREAMEX  pStrmExt
)
/*++

Routine Description:

   Stop a stream, cacel all pening data requests, terminate system thread, and disconnect.

--*/
{
    AV_61883_REQUEST * pAVReq;
    
    if(!(pAVReq = (AV_61883_REQUEST *) ExAllocatePool(NonPagedPool, sizeof(AV_61883_REQUEST)) )) 
        return STATUS_INSUFFICIENT_RESOURCES;              

    //
    // Set stream state and the work item thread can both call this routine.
    // Use a mutex to synchronize them.
    //
    KeWaitForSingleObject( pStrmExt->hStreamMutex, Executive, KernelMode, FALSE, 0 );

    //
    // Stop the 1394 isoch data transfer; Stream state is unchanged.
    //
    DVStreamingStop(
        pStrmExt,
        pStrmExt->pDevExt,
        pAVReq
        );

    ExFreePool(pAVReq);  pAVReq = NULL;

    //
    // Cancel all packets
    //
    DVCancelAllPackets(
        pStrmExt,
        pStrmExt->pDevExt
        );

    //
    // If the device is removed, terminate the system thread for attach frame.
    // 
    if(   pStrmExt->pDevExt->bDevRemoved
       && KSPIN_DATAFLOW_IN == pStrmExt->pStrmInfo->DataFlow
       && !pStrmExt->bTerminateThread
       && pStrmExt->pAttachFrameThreadObject
      ) {
        DVTerminateAttachFrameThread(pStrmExt);
        pStrmExt->pAttachFrameThreadObject = NULL;
        TRACE(TL_STRM_WARNING|TL_CIP_WARNING,("** DVStopCancelDisconnect: AttachFrameThread terminated;\n"));
    }


    //
    // Break the connection so 61883 will free isoch resource   
    //
    DVDisconnect(
        pStrmExt->pStrmInfo->DataFlow,
        pStrmExt->pDevExt,
        pStrmExt
        );

    
    KeReleaseMutex(pStrmExt->hStreamMutex, FALSE);

    return STATUS_SUCCESS;
}


void
DVCancelSrbWorkItemRoutine(
#ifdef USE_WDM110  // Win2000 code base
    // Extra parameter if using WDM10
    PDEVICE_OBJECT DeviceObject,
#endif
    PSTREAMEX  pStrmExt
    )
/*++

Routine Description:

   This work item routine will stop streaming and cancel all SRBs.   

--*/
{
    PAGED_CODE();

    TRACE(TL_STRM_WARNING,("\'CancelWorkItem: StreamState:%d; lCancel:%d\n", 
        pStrmExt->StreamState, pStrmExt->lCancelStateWorkItem));

    ASSERT(pStrmExt->lCancelStateWorkItem == 1);
#ifdef USE_WDM110  // Win2000 code base
    ASSERT(pStrmExt->pIoWorkItem);
#endif
   
    //
    // Stop the stream and cancel all pending requests.
    //
    if(!NT_SUCCESS(DVStopCancelDisconnect(pStrmExt))) {
        // Canceling is in theory done!
        InterlockedExchange(&pStrmExt->lCancelStateWorkItem, 0);
        KeSetEvent(&pStrmExt->hCancelDoneEvent, 0, FALSE);  pStrmExt->bAbortPending = FALSE;
        goto DVAbortWorkItemRoutine;           
    } 


    //
    // Canceling is in theory done!
    //
    InterlockedExchange(&pStrmExt->lCancelStateWorkItem, 0); 
    KeSetEvent(&pStrmExt->hCancelDoneEvent, 0, FALSE);  pStrmExt->bAbortPending = FALSE;


    // If the device is removed, terminate the system thread that is used 
    // for attaching frame for transmit to DV
    if(   pStrmExt->pDevExt->bDevRemoved
       && KSPIN_DATAFLOW_IN == pStrmExt->pStrmInfo->DataFlow
       && !pStrmExt->bTerminateThread
       && pStrmExt->pAttachFrameThreadObject
      ) {

        DVTerminateAttachFrameThread(pStrmExt);
        pStrmExt->pAttachFrameThreadObject = NULL;
        TRACE(TL_STRM_WARNING|TL_CIP_WARNING,("** WortItemRoutine: thread terminated;\n"));
    }

DVAbortWorkItemRoutine:
;
#ifdef USE_WDM110  // Win2000 code base
    // Release work item and release the cancel token
    IoFreeWorkItem(pStrmExt->pIoWorkItem);  pStrmExt->pIoWorkItem = NULL; 
#endif
}


BOOL
DVAbortStream(
    PDVCR_EXTENSION pDevExt,
    PSTREAMEX pStrmExt
    )
/*++

Routine Description:

   Start a work item to abort streaming.

--*/
{
    //
    // Claim this token; only one abort streaming per STOP->PAUSE transition.
    //
    if(InterlockedExchange(&pStrmExt->lCancelStateWorkItem, 1) == 1) {
        TRACE(TL_STRM_TRACE,("\'Cancel work item is already issued.\n"));
        return FALSE;
    }  

    TRACE(TL_STRM_WARNING,("\'DVAbortStream is issued; lCancelStateWorkItem:%d\n", pStrmExt->lCancelStateWorkItem));

    //
    // Non-signal this event so other thread depending on the completion will wait.
    //
    KeClearEvent(&pStrmExt->hCancelDoneEvent);  pStrmExt->bAbortPending = TRUE;

    //
    // If we are not running at DISPATFCH level or higher, we abort the stream without scheduleing
    // a work item; else schedule a work item is necessary.
    //
    if (KeGetCurrentIrql() <= APC_LEVEL) { 
        DVStopCancelDisconnect(pStrmExt);
        InterlockedExchange(&pStrmExt->lCancelStateWorkItem, 0); 
        KeSetEvent(&pStrmExt->hCancelDoneEvent, 0, FALSE);   pStrmExt->bAbortPending = FALSE;
        return TRUE;
    }


#ifdef USE_WDM110  // Win2000 code base
    ASSERT(pStrmExt->pIoWorkItem == NULL);  // Have not yet queued work item.

    // We will queue work item to stop and cancel all SRBs
    if(pStrmExt->pIoWorkItem = IoAllocateWorkItem(pDevExt->pBusDeviceObject)) { 

        IoQueueWorkItem(
            pStrmExt->pIoWorkItem,
            DVCancelSrbWorkItemRoutine,
            DelayedWorkQueue, // CriticalWorkQueue 
            pStrmExt
            );

#else  // Win9x code base
    ExInitializeWorkItem( &pStrmExt->IoWorkItem, DVCancelSrbWorkItemRoutine, pStrmExt);
    if(TRUE) {

        ExQueueWorkItem( 
            &pStrmExt->IoWorkItem,
            DelayedWorkQueue // CriticalWorkQueue 
            ); 
#endif

        TRACE(TL_STRM_WARNING,("\'CancelWorkItm queued; SrbRcv:%d;Pic#:%d;Prc:%d;;Drop:%d;Cncl:%d; AQD [%d:%d:%d]\n",
            (DWORD) pStrmExt->cntSRBReceived,
            (DWORD) pStrmExt->PictureNumber,
            (DWORD) pStrmExt->FramesProcessed, 
            (DWORD) pStrmExt->FramesDropped,
            (DWORD) pStrmExt->cntSRBCancelled,
            pStrmExt->cntDataAttached,
            pStrmExt->cntSRBQueued,
            pStrmExt->cntDataDetached
            ));

    } 
#ifdef USE_WDM110  // Win2000 code base
    else {
        InterlockedExchange(&pStrmExt->lCancelStateWorkItem, 0); 
        KeSetEvent(&pStrmExt->hCancelDoneEvent, 0, FALSE);   pStrmExt->bAbortPending = FALSE;
        ASSERT(pStrmExt->pIoWorkItem && "IoAllocateWorkItem failed.\n");
        return FALSE;
    }
#endif

    return TRUE;
}


VOID
DVCancelOnePacket(
    IN PHW_STREAM_REQUEST_BLOCK pSrbToCancel
    )
/*++

Routine Description:

   Search pending read lists for the SRB to be cancel.  If found cancel it.   

--*/
{
    PDVCR_EXTENSION pDevExt;
    PSTREAMEX pStrmExt;
    KIRQL OldIrql;


                                                                                                              
    pDevExt = (PDVCR_EXTENSION) pSrbToCancel->HwDeviceExtension; 
               
    // Cannot cancel device Srb.
    if ((pSrbToCancel->Flags & SRB_HW_FLAGS_STREAM_REQUEST) != SRB_HW_FLAGS_STREAM_REQUEST) {
        TRACE(TL_CIP_ERROR|TL_STRM_ERROR,("\'DVCancelOnePacket: Device SRB %x; cannot cancel!\n", pSrbToCancel));
        ASSERT((pSrbToCancel->Flags & SRB_HW_FLAGS_STREAM_REQUEST) == SRB_HW_FLAGS_STREAM_REQUEST );
        return;
    }         
        
    // Can try to cancel a stream Srb and only if the stream extension still around.
    pStrmExt = (PSTREAMEX) pSrbToCancel->StreamObject->HwStreamExtension;

    if(pStrmExt == NULL) {
        TRACE(TL_CIP_ERROR|TL_STRM_ERROR,("DVCancelOnePacket: pSrbTocancel %x but pStrmExt %x\n", pSrbToCancel, pStrmExt));
        ASSERT(pStrmExt && "Stream SRB but stream extension is NULL\n");
        return;
    }

    // We can only cancel SRB_READ/WRITE_DATA SRB
    if((pSrbToCancel->Command != SRB_READ_DATA) && (pSrbToCancel->Command != SRB_WRITE_DATA)) {
        TRACE(TL_CIP_ERROR|TL_STRM_ERROR,("DVCancelOnePacket: pSrbTocancel %x; Command:%d not SRB_READ,WRITE_DATA\n", pSrbToCancel, pSrbToCancel->Command));
        return;
    }

    TRACE(TL_STRM_TRACE|TL_CIP_TRACE,("\'DVCancelOnePacket: KSSt %d; Srb:%x; AQD[%d:%d:%d]\n",
        pStrmExt->StreamState, pSrbToCancel, pStrmExt->cntDataAttached, pStrmExt->cntSRBQueued, pStrmExt->cntDataDetached));

   
    KeAcquireSpinLock(&pDevExt->AVCCmdLock, &OldIrql);
    //
    // If device is removed, the surprise removal routine will do the cancelling.
    //
    if(!pDevExt->bDevRemoved) {
        KeReleaseSpinLock(&pDevExt->AVCCmdLock, OldIrql);
        // We will start an work item to stop streaming if we ever get an cancel Srb.
        if(!DVAbortStream(pDevExt, pStrmExt)) {
            TRACE(TL_STRM_WARNING,("\'CancelOnePacket: pSrb:%x; AbortStream not taken!\n", pSrbToCancel));
        }
    } else {
        TRACE(TL_STRM_WARNING,("\'CancelOnePacket: DevRemoved; pSrb:%x; AbortStream not taken!\n", pSrbToCancel));
        KeReleaseSpinLock(&pDevExt->AVCCmdLock, OldIrql);
    }
}



VOID
DVCancelAllPackets(
    PSTREAMEX        pStrmExt,
    PDVCR_EXTENSION  pDevExt
    )
/*++

Routine Description:

    Cancel all packet when This is where most of the interesting Stream requests come to us

--*/
{
    PHW_STREAM_REQUEST_BLOCK pSrb;
    PSRB_DATA_PACKET pSrbDataPacket;
    PAV_61883_REQUEST   pAVReq;
    PSRB_ENTRY       pSrbEntry;
    NTSTATUS         Status;

    PIRP               pIrp;
    PLIST_ENTRY        pEntry;    
    PIO_STACK_LOCATION NextIrpStack;
    KIRQL oldIrql;



    PAGED_CODE();

#if DBG
    if(pStrmExt->StreamState != KSSTATE_STOP) {
        TRACE(TL_STRM_WARNING|TL_CIP_WARNING,("DVCancelAllPackets: Enter; pStrmExt:%x; StrmSt:%d; IsochActive:%d\n", 
            pStrmExt, pStrmExt->StreamState, pStrmExt->bIsochIsActive));
    }
#endif

    //
    // Detached request only if not streaming
    //

    // Note: no need to spin lock this if isoch has stopped.
    if(!pStrmExt->bIsochIsActive) {

        PLONG plSrbUseCount;

        TRACE(TL_STRM_WARNING,("\'CancelAll: AQD: [%d:%d:%d]; DataAttachedListHead:%x\n",  
            pStrmExt->cntDataAttached, 
            pStrmExt->cntSRBQueued,
            pStrmExt->cntDataDetached,
            pStrmExt->DataAttachedListHead
            )); 


        //
        // Cancel buffer(s) that are still attached.
        //

        KeAcquireSpinLock(pStrmExt->DataListLock, &oldIrql);

        pEntry = pStrmExt->DataAttachedListHead.Flink;
        while(pEntry != &pStrmExt->DataAttachedListHead) {        

            ASSERT(pStrmExt->cntDataAttached > 0 && "List and cntAttached out of sync!");

            // Get an irp and detached the buffer        
            if(!(pIrp = IoAllocateIrp(pDevExt->pBusDeviceObject->StackSize, FALSE)))  {
                KeReleaseSpinLock(pStrmExt->DataListLock, oldIrql);
                return;            
            }

            pSrbDataPacket = CONTAINING_RECORD(pEntry, SRB_DATA_PACKET, ListEntry);

#if DBG
            if(!IsStateSet(pSrbDataPacket->State, DE_IRP_ATTACHED_COMPLETED)) {
                TRACE(TL_STRM_ERROR,("Cancel (unattached) entry; pStrmExt:%x; pSrbDataPacket:%x\n", pStrmExt, pSrbDataPacket)); 
                ASSERT(IsStateSet(pSrbDataPacket->State, DE_IRP_ATTACHED_COMPLETED));
            }
#endif

 
            pEntry = pEntry->Flink;  // Next since this may get changed in the completion routine

            KeReleaseSpinLock(pStrmExt->DataListLock, oldIrql);

            pSrb = pSrbDataPacket->pSrb;
            ASSERT(pSrbDataPacket->pSrb);
            plSrbUseCount = (PLONG) pSrb->SRBExtension;
            pAVReq = &pSrbDataPacket->AVReq;
            RtlZeroMemory(pAVReq, sizeof(AV_61883_REQUEST));
            INIT_61883_HEADER(pAVReq, Av61883_CancelFrame);

            pAVReq->CancelFrame.hConnect     = pStrmExt->hConnect;
            pAVReq->CancelFrame.Frame        = pSrbDataPacket->Frame;
            TRACE(TL_CIP_TRACE,("\'Canceling AttachList: pSrb %x, AvReq %x; UseCount %d\n", pSrb, pAVReq, *plSrbUseCount));
            ASSERT(pSrbDataPacket->Frame);

            NextIrpStack = IoGetNextIrpStackLocation(pIrp);
            NextIrpStack->MajorFunction = IRP_MJ_INTERNAL_DEVICE_CONTROL;
            NextIrpStack->Parameters.DeviceIoControl.IoControlCode = IOCTL_61883_CLASS;
            NextIrpStack->Parameters.Others.Argument1 = pAVReq;

            IoSetCompletionRoutine( 
                pIrp,
                DVCancelOnePacketCR,
                pSrbDataPacket,
                TRUE,
                TRUE,
                TRUE
                );

            Status = 
                IoCallDriver(
                    pDevExt->pBusDeviceObject,
                    pIrp
                    );


            ASSERT(Status == STATUS_PENDING || Status == STATUS_SUCCESS); 

            KeAcquireSpinLock(pStrmExt->DataListLock, &oldIrql);
        }

        KeReleaseSpinLock(pStrmExt->DataListLock, oldIrql);

#if DBG
        if(pStrmExt->cntDataAttached != 0) {
            TRACE(TL_STRM_WARNING|TL_CIP_WARNING,("\'DVCancelAllPackets: cntDataAttached:%d !!\n", pStrmExt->cntDataAttached));
            ASSERT(pStrmExt->cntDataAttached == 0);
        }
#endif
         
        //
        // Cancel SRB that are still the SrbQ; this applies only to SRB_WRITE_DATA
        //
        pEntry = pStrmExt->SRBQueuedListHead.Flink;
        while(pEntry != &pStrmExt->SRBQueuedListHead) {  

            pSrbEntry = CONTAINING_RECORD(pEntry, SRB_ENTRY, ListEntry);
            plSrbUseCount = (PLONG) pSrbEntry->pSrb->SRBExtension;

            pEntry = pEntry->Flink;  // Next since this may get changed if removed

            TRACE(TL_CIP_TRACE,("\'DVCnclAllPkts (SrbQ): cntQ:%d; pSrb:%x; UseCnt:%d (=? 1)\n", pStrmExt->cntSRBQueued, pSrbEntry->pSrb, *plSrbUseCount));
            if(*plSrbUseCount == 1) {
                RemoveEntryList(&pSrbEntry->ListEntry); pStrmExt->cntSRBQueued--; (*plSrbUseCount)--;  // Remove from queueed.
                pStrmExt->cntSRBCancelled++;
                pSrbEntry->pSrb->Status = (pDevExt->bDevRemoved ? STATUS_DEVICE_REMOVED : STATUS_CANCELLED);
                pSrbEntry->pSrb->CommandData.DataBufferArray->DataUsed = 0;
                pSrbEntry->pSrb->ActualBytesTransferred                = 0;
                TRACE(TL_STRM_WARNING,("\'Cancel queued SRB: pSRB:%x, Status:%x; cntSrbCancelled:%d\n", pSrbEntry->pSrb, pSrbEntry->pSrb->Status, pStrmExt->cntSRBCancelled));
                StreamClassStreamNotification(StreamRequestComplete, pSrbEntry->pSrb->StreamObject, pSrbEntry->pSrb);
#if DBG
                pStrmExt->cntSRBPending--;
#endif
                ExFreePool(pSrbEntry);
            } else {
                TRACE(TL_STRM_ERROR|TL_CIP_ERROR,("\'NOT Cancel queued SRB: pSRB:%x, Status:%x; *plSrbUseCount:%d, cntSrbCancelled:%d\n", pSrbEntry->pSrb, pSrbEntry->pSrb->Status, *plSrbUseCount, pStrmExt->cntSRBCancelled));
                ASSERT(*plSrbUseCount == 0 && "Still in use ?");
                break;  // Still in used.  Perhaps, free it in TimeoutHandler() or CancelOnePacket()
            }
        }
#if DBG
        if(pStrmExt->cntSRBQueued != 0 || !IsListEmpty(&pStrmExt->SRBQueuedListHead)) {
            TRACE(TL_STRM_ERROR|TL_CIP_ERROR,("\'DVCancelAllPackets: cntSRBQueued:%d !! Empty?%d\n", pStrmExt->cntSRBQueued, IsListEmpty(&pStrmExt->SRBQueuedListHead)));
            ASSERT(pStrmExt->cntSRBQueued == 0);
        }
#endif
    } 
    else {
        TRACE(TL_STRM_ERROR,("\'IsochActive; cannot cancel! cntSrbQ:%d; cntAttached:%d.\n", pStrmExt->cntSRBQueued, pStrmExt->cntDataAttached));
        ASSERT(pStrmExt->bIsochIsActive);
    }   



    TRACE(TL_STRM_WARNING|TL_CIP_WARNING,("\'DVCancelAllPackets: ************************ Exit!\n"));
}


VOID
DVTimeoutHandler(
    IN PHW_STREAM_REQUEST_BLOCK pSrb
    )

/*++

Routine Description:

    This routine is called when a packet has been in the minidriver too long.
    It can only valid if we are it wa a streaming packet and in PAUSE state;
    else we have a problem!

Arguments:

    pSrb - Pointer to Stream request block

Return Value:

    Nothing

--*/

{
    //
    // Note:
    //    Called from StreamClass at DisptchLevel
    //    

    //
    // We only expect stream SRB, but not device SRB.  
    //

    if ( (pSrb->Flags & SRB_HW_FLAGS_STREAM_REQUEST) != SRB_HW_FLAGS_STREAM_REQUEST) {
        TRACE(TL_PNP_ERROR,("TimeoutHandler: Device SRB %x (cmd:%x) timed out!\n", pSrb, pSrb->Command));
        return;
    } else {

        //
        // pSrb->StreamObject (and pStrmExt) only valid if it is a stream SRB
        //
        PSTREAMEX pStrmExt;

        pStrmExt = (PSTREAMEX) pSrb->StreamObject->HwStreamExtension;

        if(!pStrmExt) {
            TRACE(TL_PNP_ERROR,("TimeoutHandler: Stream SRB %x timeout with pStrmExt %x\n", pSrb, pStrmExt));
            ASSERT(pStrmExt);
            return;
        }

        TRACE(TL_STRM_WARNING,("\'TimeoutHandler: KSSt %d; Srb:%x (cmd:%x); AQD[%d:%d:%d]\n",
            pStrmExt->StreamState, pSrb, pSrb->Command, pStrmExt->cntDataAttached, pStrmExt->cntSRBQueued, pStrmExt->cntDataDetached));

 
        //
        // Stream SRB (esp the data SRB) can time out if there is not 
        // data on the bus; however, it can only happen while in PAUSE 
        // or RUN state when attaching data SRB is valid.
        //
        if(pStrmExt->StreamState != KSSTATE_PAUSE &&
           pStrmExt->StreamState != KSSTATE_RUN) {
            TRACE(TL_PNP_ERROR|TL_STRM_ERROR,("\'TmOutHndlr:(Irql:%d) Srb %x (cmd:%x); %s, pStrmExt %x, AQD [%d:%d:%d]\n", 
                KeGetCurrentIrql(),
                pSrb, pSrb->Command, 
                pStrmExt->StreamState == KSSTATE_RUN   ? "RUN" : 
                pStrmExt->StreamState == KSSTATE_PAUSE ? "PAUSE":
                pStrmExt->StreamState == KSSTATE_STOP  ? "STOP": "Unknown",
                pStrmExt,
                pStrmExt->cntDataAttached,
                pStrmExt->cntSRBQueued,
                pStrmExt->cntDataDetached
                ));   
        }

        //
        // Reset Timeout counter, or we are going to get this call immediately.
        //

        pSrb->TimeoutCounter = pSrb->TimeoutOriginal;
    }
}

NTSTATUS 
DVEventHandler(
    IN PHW_EVENT_DESCRIPTOR pEventDescriptor
    )
/*++

Routine Description:

    This routine is called to process events.

--*/
{

    PSTREAMEX  pStrmExt;

    if(IsEqualGUID (&KSEVENTSETID_Clock, pEventDescriptor->EventEntry->EventSet->Set)) {
        if(pEventDescriptor->EventEntry->EventItem->EventId == KSEVENT_CLOCK_POSITION_MARK) {
            if(pEventDescriptor->Enable) {
                // Note: According to the DDK, StreamClass queues pEventDescriptor->EventEntry, and dellaocate
                // every other structures, including the pEventDescriptor->EventData.
                if(pEventDescriptor->StreamObject) { 
                    PKSEVENT_TIME_MARK  pEventTime;

                    pStrmExt = (PSTREAMEX) pEventDescriptor->StreamObject->HwStreamExtension;
                    pEventTime = (PKSEVENT_TIME_MARK) pEventDescriptor->EventData;
                    // Cache the event data (Specified in the ExtraEntryData of KSEVENT_ITEM)
                    RtlCopyMemory((pEventDescriptor->EventEntry+1), pEventDescriptor->EventData, sizeof(KSEVENT_TIME_MARK));
                    TRACE(TL_STRM_TRACE,("\'CurrentStreamTime:%d, MarkTime:%d\n", (DWORD) pStrmExt->CurrentStreamTime, (DWORD) pEventTime->MarkTime));
                }
            } else {
               // Disabled!
                TRACE(TL_STRM_TRACE,("\'KSEVENT_CLOCK_POSITION_MARK disabled!\n"));            
            }
            return STATUS_SUCCESS;
        }
    } else if(IsEqualGUID (&KSEVENTSETID_Connection, pEventDescriptor->EventEntry->EventSet->Set)) {
        TRACE(TL_STRM_WARNING,("\'Connection event: pEventDescriptor:%x; id:%d\n", pEventDescriptor, pEventDescriptor->EventEntry->EventItem->EventId));

        pStrmExt = (PSTREAMEX) pEventDescriptor->StreamObject->HwStreamExtension;
        if(pStrmExt->pStrmInfo->DataFlow == KSPIN_DATAFLOW_IN) {
            if(pEventDescriptor->EventEntry->EventItem->EventId == KSEVENT_CONNECTION_ENDOFSTREAM) {
                if(pEventDescriptor->Enable) {
                    TRACE(TL_STRM_TRACE,("\'KSEVENT_CONNECTION_ENDOFSTREAM enabled!\n"));
                } else {
                    TRACE(TL_STRM_TRACE,("\'KSEVENT_CONNECTION_ENDOFSTREAM disabled!\n"));            
                }
                return STATUS_SUCCESS;
            }
        }
    }

    TRACE(TL_STRM_ERROR,("\'NOT_SUPPORTED event: pEventDescriptor:%x\n", pEventDescriptor));
    ASSERT(FALSE && "Event not advertised and not supported!");

    return STATUS_NOT_SUPPORTED;
}

VOID
DVSignalClockEvent(
    IN PKDPC Dpc,
    IN PSTREAMEX  pStrmExt,
    IN PVOID SystemArgument1,
    IN PVOID SystemArgument2 
)
/*++

Routine Description:

    This routine is called when we are the clock provider and when our clock "tick".  
    Find a pending clock event, signal it if it has expired.

--*/
{
    PKSEVENT_ENTRY pEvent, pLast;
    ULONGLONG tmStreamTime;
#if DBG
    ULONG EventPendings = 0;
#endif

    pEvent = NULL;
    pLast = NULL;


    //
    // A clock tick for DV is one frame time.  For better precision, 
    // we calculate current stream time with an offset from the last system time being queried.
    // We also add a max latency of one frame for decoding a DV frame.
    //
    tmStreamTime = 
        pStrmExt->CurrentStreamTime + 
        (GetSystemTime() - pStrmExt->LastSystemTime) + 
        DVFormatInfoTable[pStrmExt->pDevExt->VideoFormatIndex].ulAvgTimePerFrame;  // Allow one frame of latency

    while(( 
        pEvent = StreamClassGetNextEvent(
            pStrmExt->pDevExt,
            pStrmExt->pStrmObject,
            (GUID *)&KSEVENTSETID_Clock,
            KSEVENT_CLOCK_POSITION_MARK,
            pLast )) 
        != NULL ) {

#if DBG
        EventPendings++;
#endif

        if (
            // For real time capture (DV->PC), signal every frame. 
            // No frame that is produce can be "early" and requires AdviseTime().
            pStrmExt->pStrmInfo->DataFlow == KSPIN_DATAFLOW_OUT ||
                pStrmExt->bEOStream 
            || (pStrmExt->StreamState != KSSTATE_RUN)            // If not in RUN state, Data should be completed.
            || pStrmExt->pDevExt->PowerState != PowerDeviceD0    // If not power ON, data should be completed.
            || ((PKSEVENT_TIME_MARK)(pEvent +1))->MarkTime <= (LONGLONG) tmStreamTime ) {
            TRACE(TL_STRM_TRACE,("\'PowerSt:%d (ON:1?); StrmSt:%d; Clock event %x with id %d; Data:%x; \ttmMark\t%d \ttmCurrentStream \t%d; Notify!\n", 
                pStrmExt->pDevExt->PowerState, pStrmExt->StreamState,
                pEvent, KSEVENT_CLOCK_POSITION_MARK, (PKSEVENT_TIME_MARK)(pEvent +1),
                (DWORD) (((PKSEVENT_TIME_MARK)(pEvent +1))->MarkTime), (DWORD) tmStreamTime));
            ASSERT( ((PKSEVENT_TIME_MARK)(pEvent +1))->MarkTime > 0 );

            //
            // signal the event here
            //
            StreamClassStreamNotification(
                SignalStreamEvent,
                pStrmExt->pStrmObject,
                pEvent
                );
#if DBG
            if(pStrmExt->bEOStream) {
                TRACE(TL_STRM_WARNING,("\'bEOStream: Clock event %x with id %d; Data:%x; \ttmMark \t%d \ttmCurStream \t%d\n", 
                    pEvent, KSEVENT_CLOCK_POSITION_MARK, (PKSEVENT_TIME_MARK)(pEvent +1),
                    (DWORD) (((PKSEVENT_TIME_MARK)(pEvent +1))->MarkTime), (DWORD) tmStreamTime));
            }
#endif
        } else {
            TRACE(TL_STRM_WARNING,("\'PowerST:%d; StrmST:%d; AQD[%d:%d:%d]; Still early! ClockEvent: \tMarkTime \t%d \ttmStream \t%d \tdetla \t%d\n",
                pStrmExt->pDevExt->PowerState, pStrmExt->StreamState,
                pStrmExt->cntDataAttached, pStrmExt->cntSRBQueued, pStrmExt->cntDataDetached,
                (DWORD) (((PKSEVENT_TIME_MARK)(pEvent +1))->MarkTime), (DWORD) tmStreamTime,
                (DWORD) ((((PKSEVENT_TIME_MARK)(pEvent +1))->MarkTime) - tmStreamTime)
                ));

        }
        pLast = pEvent;
    }

#if DBG
    if(EventPendings == 0) {
        TRACE(TL_STRM_TRACE,("\'No event pending; PowerSt:%d (ON:1?); StrmSt:%d; AQD[%d:%d:%d]\n", 
            pStrmExt->pDevExt->PowerState, pStrmExt->StreamState, 
            pStrmExt->cntDataAttached, pStrmExt->cntSRBQueued, pStrmExt->cntDataDetached
        ));
    }
#endif

}


VOID 
StreamClockRtn(
    IN PHW_TIME_CONTEXT TimeContext
    )
/*++

Routine Description:

    This routine is called whenever someone in the graph wants to know what time it is, and we are the Master Clock.

--*/
{
    PDVCR_EXTENSION    pDevExt;
    PHW_STREAM_OBJECT  pStrmObj;
    PSTREAMEX          pStrmExt;
    
    // Call at dispatch level

    pDevExt  = (PDVCR_EXTENSION) TimeContext->HwDeviceExtension;
    pStrmObj = TimeContext->HwStreamObject;
    if(pStrmObj)
        pStrmExt = pStrmObj->HwStreamExtension;
    else 
        pStrmExt = 0;

    if(!pDevExt || !pStrmExt) {
        ASSERT(pDevExt && pStrmExt);
        return;
    }


    switch (TimeContext->Function) {
    
    case TIME_GET_STREAM_TIME:

        //
        // How long since the stream was first set into the run state?
        //
        ASSERT(pStrmExt->hMasterClock && "We are not master clock but we were qureied?");

        TimeContext->SystemTime = GetSystemTime();

        if(pStrmExt->pStrmInfo->DataFlow == KSPIN_DATAFLOW_IN) {
            if(pStrmExt->StreamState == KSSTATE_RUN)  { // Stream time is only meaningful in RUN state
                if(TimeContext->SystemTime >= pStrmExt->LastSystemTime)
                    TimeContext->Time = 
                        pStrmExt->CurrentStreamTime + (TimeContext->SystemTime - pStrmExt->LastSystemTime); 
                else {
                    TimeContext->Time = pStrmExt->CurrentStreamTime;
                    TRACE(TL_STRM_WARNING,("\'Clock went backward? %d -> %d\n", (DWORD) (TimeContext->SystemTime/10000), (DWORD) (pStrmExt->LastSystemTime/10000) ));
                    // ASSERT(TimeContext->SystemTime >= pStrmExt->LastSystemTime);
                }
        
                // Make current stream time one frame behind
                if(TimeContext->Time > DVFormatInfoTable[pDevExt->VideoFormatIndex].ulAvgTimePerFrame)
                    TimeContext->Time = TimeContext->Time - DVFormatInfoTable[pDevExt->VideoFormatIndex].ulAvgTimePerFrame;
                else 
                    TimeContext->Time = 0;
            } else  {
                if(pStrmExt->FramesProcessed > 0)
                    TimeContext->Time = pStrmExt->CurrentStreamTime;
                else
                    TimeContext->Time = 0;  // if get queried at the PAUSE state.
            }
           
        } else {

            if(pStrmExt->StreamState == KSSTATE_RUN) {
#ifdef NT51_61883
                // Can advance at most MAX_CYCLES_TIME (supported by 1394 OHCI).
                if((TimeContext->SystemTime - pStrmExt->LastSystemTime) > MAX_CYCLES_TIME)
                    TimeContext->Time = pStrmExt->CurrentStreamTime + MAX_CYCLES_TIME;
#else
                // Cannot advance more than one frame time.
                if((TimeContext->SystemTime - pStrmExt->LastSystemTime) >= DVFormatInfoTable[pDevExt->VideoFormatIndex].ulAvgTimePerFrame)
                    TimeContext->Time = pStrmExt->CurrentStreamTime + DVFormatInfoTable[pDevExt->VideoFormatIndex].ulAvgTimePerFrame;
#endif  // NT51_61883
                else 
                    TimeContext->Time = 
                        pStrmExt->CurrentStreamTime + (TimeContext->SystemTime - pStrmExt->LastSystemTime); 

                // Necessary tuning ?
                //     Make current stream time one frame behind so that the downstream filter 
                //     can render the data promptly instead of discarding it if it is late.
                if(TimeContext->Time > DVFormatInfoTable[pDevExt->VideoFormatIndex].ulAvgTimePerFrame)
                    TimeContext->Time = TimeContext->Time - DVFormatInfoTable[pDevExt->VideoFormatIndex].ulAvgTimePerFrame;
                else 
                    TimeContext->Time = 0;                

            } else {
                if(pStrmExt->FramesProcessed > 0)
                    TimeContext->Time = pStrmExt->CurrentStreamTime;
                else
                    TimeContext->Time = 0;
            }
        }
        TRACE(TL_STRM_TRACE,("\'TIME_GET_STREAM_TIME: ST:%d; Frame:%d; tmSys:%d; tmStream:%d msec\n", 
            pStrmExt->StreamState,
            (DWORD) pStrmExt->PictureNumber,
            (DWORD)(TimeContext->SystemTime/10000), (DWORD)(TimeContext->Time/10000)));  
        break;
   
    default:
        ASSERT(TimeContext->Function == TIME_GET_STREAM_TIME && "Unsupport clock func");
        break;
    } // switch TimeContext->Function
}



NTSTATUS 
DVOpenCloseMasterClock (
    PSTREAMEX  pStrmExt,
    HANDLE  hMasterClockHandle
    )
/*++

Routine Description:

    We can be a clock provider.

--*/
{

    PAGED_CODE();

    // Make sure the stream exist.
    if(pStrmExt == NULL) {
        TRACE(TL_STRM_ERROR,("\'DVOpenCloseMasterClock: stream is not yet running.\n"));
        ASSERT(pStrmExt);
        return  STATUS_UNSUCCESSFUL;
    } 

    TRACE(TL_STRM_TRACE,("\'DVOpenCloseMasterClock: pStrmExt %x; hMyClock:%x->%x\n", 
        pStrmExt, pStrmExt->hMyClock, hMasterClockHandle));

    if(hMasterClockHandle) {
        // Open master clock
        ASSERT(pStrmExt->hMyClock == NULL && "OpenMasterClk while hMyClock is not NULL!");
        pStrmExt->hMyClock = hMasterClockHandle;
    } else {
        // Close master clock
        ASSERT(pStrmExt->hMyClock && "CloseMasterClk while hMyClock is NULL!");
        pStrmExt->hMyClock = NULL;
    }
    return STATUS_SUCCESS;
}


NTSTATUS 
DVIndicateMasterClock (
    PSTREAMEX  pStrmExt,
    HANDLE  hIndicateClockHandle
    )
/*++

Routine Description:

    Compare the indicate clock handle with my clock handle.
    If the same, we are the master clock; else, other device is 
    the master clock.

    Note: either hMasterClock or hClock can be set.

--*/
{
    PAGED_CODE();

    // Make sure the stream exist.
    if (pStrmExt == NULL) {
        TRACE(TL_STRM_ERROR,("DVIndicateMasterClock: stream is not yet running.\n"));
        ASSERT(pStrmExt);
        return STATUS_UNSUCCESSFUL;
    }

    TRACE(TL_STRM_TRACE,("\'*>IndicateMasterClk[Enter]: pStrmExt:%x; hMyClk:%x; IndMClk:%x; pClk:%x, pMClk:%x\n",
        pStrmExt, pStrmExt->hMyClock, hIndicateClockHandle, pStrmExt->hClock, pStrmExt->hMasterClock));

    // it not null, set master clock accordingly.    
    if(hIndicateClockHandle == pStrmExt->hMyClock) {
        pStrmExt->hMasterClock = hIndicateClockHandle;
        pStrmExt->hClock       = NULL;
    } else {
        pStrmExt->hMasterClock = NULL;
        pStrmExt->hClock       = hIndicateClockHandle;
    }

    TRACE(TL_STRM_TRACE,("\'<*IndicateMasterClk[Exit]: hMyClk:%x; IndMClk:%x; pClk:%x; pMClk:%x\n",
        pStrmExt->hMyClock, hIndicateClockHandle, pStrmExt->hClock, pStrmExt->hMasterClock));

    return STATUS_SUCCESS;
}
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\drivers\wdm\capture\mini\msdv\msdvguts.h ===
/*++

Copyright (C) Microsoft Corporation, 1999 - 2000  

Module Name:

    MsdvGuts.h

Abstract:

    Header file MsdvGuts.c

Last changed by:
    
    Author:      Yee J. Wu

Environment:

    Kernel mode only

Revision History:

    $Revision::                    $
    $Date::                        $

--*/


//
// Device SRB
//

NTSTATUS
DVInitializeDevice(
    IN PDVCR_EXTENSION  pDevExt,
    IN PPORT_CONFIGURATION_INFORMATION pConfigInfo,
    IN PAV_61883_REQUEST pAVReq
    );

NTSTATUS
DVInitializeCompleted(
    IN PDVCR_EXTENSION  pDevExt
    );

NTSTATUS
DVGetStreamInfo(
    IN PDVCR_EXTENSION        pDevExt,
    IN ULONG                  ulBytesToTransfer, 
    IN PHW_STREAM_HEADER      pStreamHeader,       
    IN PHW_STREAM_INFORMATION pStreamInfo
    );

BOOL 
DVVerifyDataFormat(
    PKSDATAFORMAT  pKSDataFormatToVerify, 
    ULONG          StreamNumber,
    ULONG          ulSupportedFrameSize,
    HW_STREAM_INFORMATION * paCurrentStrmInfo	
    );

NTSTATUS
DVGetDataIntersection(
    IN  ULONG          ulStreamNumber,
    IN  PKSDATARANGE   pDataRange,
    OUT PVOID          pDataFormatBuffer,
    IN  ULONG          ulSizeOfDataFormatBuffer,
    IN  ULONG          ulSupportedFrameSize,
    OUT ULONG          *pulActualBytesTransferred,
    HW_STREAM_INFORMATION * paCurrentStrmInfo
#ifdef SUPPORT_NEW_AVC            
    ,IN HANDLE hPlug
#endif
    );

NTSTATUS
DVOpenStream(
    IN PHW_STREAM_OBJECT pStrmObject,
    IN PKSDATAFORMAT     pOpenFormat,
    IN PAV_61883_REQUEST    pAVReq
    );

NTSTATUS
DVCloseStream(
    IN PHW_STREAM_OBJECT pStrmObject,
    IN PKSDATAFORMAT     pOpenFormat,
    IN PAV_61883_REQUEST    pAVReq
    );

NTSTATUS
DVChangePower(
    PDVCR_EXTENSION  pDevExt,
    PAV_61883_REQUEST pAVReq,
    DEVICE_POWER_STATE NewPowerState
    );

NTSTATUS
DVSurpriseRemoval(
    PDVCR_EXTENSION pDevExt,
    PAV_61883_REQUEST  pAVReq
    );

NTSTATUS
DVProcessPnPBusReset(
    PDVCR_EXTENSION pDevExt
    );

NTSTATUS
DVUninitializeDevice(
    IN PDVCR_EXTENSION  pDevExt
    );

//
// Stream SRB
//

NTSTATUS
DVGetStreamState(
    PSTREAMEX  pStrmExt,
    PKSSTATE   pStreamState,
    PULONG     pulActualBytesTransferred
    );

NTSTATUS
DVStreamingStop( 
    PSTREAMEX        pStrmExt,
    PDVCR_EXTENSION  pDevExt,
    PAV_61883_REQUEST   pAVReq
    );

NTSTATUS
DVStreamingStart( 
    KSPIN_DATAFLOW   ulDataFlow,
    PSTREAMEX        pStrmExt,
    PDVCR_EXTENSION  pDevExt
    );

NTSTATUS
DVSetStreamState(
    PSTREAMEX        pStrmExt,
    PDVCR_EXTENSION  pDevExt,
    PAV_61883_REQUEST   pAVReq,
    KSSTATE          StreamState
    );

NTSTATUS 
DVGetStreamProperty(
    PHW_STREAM_REQUEST_BLOCK pSrb
    );

NTSTATUS
DVSetStreamProperty(
    PHW_STREAM_REQUEST_BLOCK pSrb
    );

BOOL
DVAbortStream(
    PDVCR_EXTENSION pDevExt,
    PSTREAMEX pStrmExt
    );

NTSTATUS
DVStopCancelDisconnect(
    PSTREAMEX  pStrmExt
);

VOID
DVCancelOnePacket(
    IN PHW_STREAM_REQUEST_BLOCK pSrbToCancel
    );

VOID
DVCancelAllPackets(
    IN PSTREAMEX        pStrmExt,
    IN PDVCR_EXTENSION  pDevExt
    );

VOID
DVTimeoutHandler(
    IN PHW_STREAM_REQUEST_BLOCK pSrb
    );

NTSTATUS 
DVOpenCloseMasterClock (
    PSTREAMEX  pStrmExt,
    HANDLE  hMasterClockHandle
    );

NTSTATUS 
DVIndicateMasterClock (
    PSTREAMEX  pStrmExt,
    HANDLE  hMasterClockHandle
    );

VOID
DVRcvDataPacket(
    IN PHW_STREAM_REQUEST_BLOCK pSrb
    );

VOID
DVRcvControlPacket(
    IN PHW_STREAM_REQUEST_BLOCK pSrb
    );

VOID 
StreamClockRtn(
    IN PHW_TIME_CONTEXT TimeContext
    );

VOID
DVSignalClockEvent(
    IN PKDPC Dpc,
    IN PSTREAMEX  pStrmExt,
    IN PVOID SystemArgument1,
    IN PVOID SystemArgument2    
    );

NTSTATUS 
DVEventHandler(
    IN PHW_EVENT_DESCRIPTOR pEventDescriptor
    );
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\drivers\wdm\capture\mini\mstape\mstpavc.h ===
/*++

Module Name:

    MsTpAvc.h

Abstract:

    Header file for MsTpAvc.c.

Author:   

    Yee J. Wu 27-July-99

Environment:

    Kernel mode only

Revision History:


--*/

#ifndef _MSTPAVC_INC
#define _MSTPAVC_INC

#include "XPrtDefs.h"  // WdmCap directory; derived from DShow's edevdefs.h
#include "EDevCtrl.h"  // External Device COM interface structures


#ifdef SUPPORT_NEW_AVC_CMD
//
// Define an AVC command constant and strcutures
//

typedef enum {
    OPC_UNIT_CONNECT_AV_20      = 0x20,
    OPC_UNIT_UNIT_INFO_30       = 0x30,
    OPC_UNIT_SUBUNIT_INFO_31    = 0x31,

    OPC_TAPE_PLAY_C3            = 0xC3,
    OPC_TAPE_TRANSPORT_STATE_D0 = 0xD0,

    // More...
} AVC_COMMAND_OP_CODE;


#define MAX_FCP_DATA_LEN      512
#define AVC_CMD_HEADER_LEN      3
#define MAX_OPERAND_LEN         (MAX_FCP_DATA_LEN - AVC_CMD_HEADER_LEN)

typedef struct _SUBUNIT_TYPE_ID {
    UCHAR   SubunitID:3;   // 1-4 instance number; 7: unit/ignoerd
    UCHAR   SubunitType:5; // 4:Tape; 5:Tuner; 7:VideoCamera;
} SUBUNIT_TYPE_ID, *PSUBUNIT_TYPE_ID;

typedef struct _AVC_CMD_FRAME_HEADER {
    union {
        UCHAR CmdType:4;   // 0:Control;1:Status;2:SpecInq;3:Notify;4:Geninq;other:reserved.
        UCHAR RespCode:4;  // 8:Not_IMPL;9:Accept;A:Rejected;B:InTransition;C:Imple/Stable;D:Changed;E:Reserved;F:Interim
    };
    UCHAR   CTS:4;         // 0000 for AVC

    SUBUNIT_TYPE_ID  SubunitTypeID;

    UCHAR   Opcode;
} AVC_CMD_FRAME_HEADER, *PAVC_CMD_FRAME_HEADER;

typedef struct _AVC_CMD_FRAME {
    AVC_CMD_FRAME_HEADER CmdHeader;
    UCHAR   Operand[MAX_OPERAND_LEN];
} AVC_CMD_FRAME, *PAVC_CMD_FRAME;

typedef struct _UNIT_CONNECT_AV_20 {
    AVC_CMD_FRAME_HEADER CmdHeader;
    UCHAR  AudDstType:2;
    UCHAR  VidDstType:2;
    UCHAR  AudSrcType:2;
    UCHAR  VidSrvType:2;
    UCHAR  VideoSource;
    UCHAR  AudSrc;
    UCHAR  VidSrc;
    UCHAR  AudDst;
    UCHAR  VidDst;
} UNIT_CONNECT_AV_20, *PUNIT_CONNECT_AV_20;

typedef struct _UNIT_UNIT_INFO_30 {
    AVC_CMD_FRAME_HEADER CmdHeader;
    UCHAR  Opcode;  // 0x30
    UCHAR  Operand; // 0x07
    ULONG  Unit:3;
    ULONG  UnitType:5;
    ULONG  CompanyID:24;
} UNIT_UNIT_INFO_30, *PUNIT_UNIT_INFO_30;



typedef struct _UNIT_SUBUNIT_INFO_31 {
    AVC_CMD_FRAME_HEADER CmdHeader;

    UCHAR  ExtCode:3;
    UCHAR  Rsv0:1;
    UCHAR  Page:3;  // 0..7
    UCHAR  Rsv1:1;

    UCHAR  Operand; // 0x07
    // Exclude extension_code, there are max of 8 pages.
    SUBUNIT_TYPE_ID  SubunitTypeID0[4];
    SUBUNIT_TYPE_ID  SubunitTypeID1[4];
    SUBUNIT_TYPE_ID  SubunitTypeID2[4];
    SUBUNIT_TYPE_ID  SubunitTypeID3[4];
    SUBUNIT_TYPE_ID  SubunitTypeID4[4];
    SUBUNIT_TYPE_ID  SubunitTypeID5[4];
    SUBUNIT_TYPE_ID  SubunitTypeID6[4];
    SUBUNIT_TYPE_ID  SubunitTypeID7[4];

} UNIT_SUBUNIT_INFO_31, *PUNIT_SUBUNIT_INFO_31;

typedef enum {
    NEXT_FRAME = 0x30,  // R
    SLOWEST_FORWARD,    // R
    SLOW_FORWARD_6,
    SLOW_FORWARD_5,
    SLOW_FORWARD_4,
    SLOW_FORWARD_3,
    SLOW_FORWARD_2,
    SLOW_FORWARD_1,
    X1,
    FAST_FORWARD_1,
    FAST_FORWARD_2,
    FAST_FORWARD_3,
    FAST_FORWARD_4,
    FAST_FORWARD_5,
    FAST_FORWARD_6,
    FASTEST_FORWARD,    // M
    //.... more...
} PlaybackMode;

typedef struct _TAPE_PLAY_C3 {
    AVC_CMD_FRAME_HEADER CmdHeader;
    PlaybackMode PlaybackMode;
} TAPE_PLAY_C3, *PTAPE_PLAY_C3;

typedef struct _TAPE_TRANSPORT_STATE_D0 {
    AVC_CMD_FRAME_HEADER CmdHeader;
    UCHAR  Operand;  // 7F
    UCHAR  TransportMode;
    UCHAR  TransportState;
} TAPE_TRANSPORT_STATE_D0, *PTAPE_TRANSPORT_STATE_D0;


//
// "Super" AVC command frame structure
//
typedef struct _AVC_CMD {
    ULONG   DataLen;  // 4..512; at least 4 (header+opcode+operand) to be valid.
    union {
        // Generic
        UCHAR                    FCP_DATA[MAX_FCP_DATA_LEN];
        AVC_CMD_FRAME            CmdFrame;

        // Unit commands
        UNIT_CONNECT_AV_20       ConnectAV;
        UNIT_UNIT_INFO_30        UnitInfo;
        UNIT_SUBUNIT_INFO_31     SubunitInfo;

        // Tape subunit commands
        TAPE_TRANSPORT_STATE_D0  TapeTransportState;
        TAPE_PLAY_C3             TapePlay;
    };
} AVC_CMD, *PAVC_CMD;

#endif // SUPPORT_NEW_AVC_CMD

// 
// The index MUST match DVcrAVCCmdTable[]
//
typedef enum {

    DV_UNIT_INFO = 0
    ,DV_SUBUNIT_INFO
    ,DV_CONNECT_AV_MODE

    ,DV_VEN_DEP_CANON_MODE    // Vendor denpendent mode of operation for Canon DV that does not support ConnectDV
    ,DV_VEN_DEP_DVCPRO        // Vendor depend cmd to detect DVC PRO tape format

    ,DV_IN_PLUG_SIGNAL_FMT
    ,DV_OUT_PLUG_SIGNAL_FMT   // to determine if it is a PAL or NTSC

    ,DV_GET_POWER_STATE         // Get current power state
    ,DV_SET_POWER_STATE_ON      // Get power state to ON
    ,DV_SET_POWER_STATE_OFF     // Get power state to OFF

    ,VCR_TIMECODE_SEARCH 
    ,VCR_TIMECODE_READ

    ,VCR_ATN_SEARCH 
    ,VCR_ATN_READ

    ,VCR_RTC_SEARCH 
    ,VCR_RTC_READ

    ,VCR_OPEN_MIC_CLOSE
    ,VCR_OPEN_MIC_READ
    ,VCR_OPEN_MIC_WRITE
    ,VCR_OPEN_MIC_STATUS

    ,VCR_READ_MIC

    ,VCR_WRITE_MIC

    ,VCR_OUTPUT_SIGNAL_MODE
    ,VCR_INPUT_SIGNAL_MODE

    ,VCR_LOAD_MEDIUM_EJECT

    ,VCR_RECORD
    ,VCR_RECORD_PAUSE

    ,VCR_PLAY_FORWARD_STEP
    ,VCR_PLAY_FORWARD_SLOWEST
    ,VCR_PLAY_FORWARD_SLOWEST2
    ,VCR_PLAY_FORWARD_FASTEST

    ,VCR_PLAY_REVERSE_STEP
    ,VCR_PLAY_REVERSE_SLOWEST
    ,VCR_PLAY_REVERSE_SLOWEST2
    ,VCR_PLAY_REVERSE_FASTEST

    ,VCR_PLAY_FORWARD
    ,VCR_PLAY_FORWARD_PAUSE

    ,VCR_WIND_STOP
    ,VCR_WIND_REWIND
    ,VCR_WIND_FAST_FORWARD

    ,VCR_TRANSPORT_STATE
    ,VCR_TRANSPORT_STATE_NOTIFY

    ,VCR_MEDIUM_INFO

    ,VCR_RAW_AVC
    
} DVCR_AVC_COMMAND, *PDVCR_AVC_COMMAND;



#define MAX_FCP_PAYLOAD_SIZE 512

//
// CTYPE definitions (in bit-map form... should correlate with AvcCommandType from avc.h)
//
typedef enum {
    CMD_CONTROL  = 0x01
   ,CMD_STATUS   = 0x02
   ,CMD_SPEC_INQ = 0x04
   ,CMD_NOTIFY   = 0x08
   ,CMD_GEN_INQ  = 0x10
} BITMAP_CTYPE;

typedef enum {
    CMD_STATE_UNDEFINED   
   ,CMD_STATE_ISSUED 
   ,CMD_STATE_RESP_ACCEPTED
   ,CMD_STATE_RESP_REJECTED
   ,CMD_STATE_RESP_NOT_IMPL           
   ,CMD_STATE_RESP_INTERIM
   ,CMD_STATE_ABORTED
} AVC_CMD_STATE, *PAVC_CMD_STATE;


// An AVC command entry 
typedef struct _AVC_CMD_ENTRY {
    LIST_ENTRY      ListEntry;
    PDVCR_EXTENSION pDevExt;        
    PIRP            pIrp;           // The Irp associated with this command
    PAVC_COMMAND_IRB pAvcIrb;       // points to the AVC command information
    PVOID           pProperty;      // Data from/to COM interface
    DVCR_AVC_COMMAND idxDVCRCmd;    // Used to check for RAW AVC command, which requires special processing
    AVC_CMD_STATE   cmdState;       // Issuing, interim, completed
    NTSTATUS        Status;         // To save the results of response parsing
    AvcCommandType  cmdType;        // Type of command: Control, Status. Notify, Gen or Spec Inquery
    BYTE            OpCode;         // Since the opcode in response frame of TRANSITION and STABLE can be different from the COMMAND frame
    BYTE            Reserved[3];    // Pack to DWORD
} AVCCmdEntry, *PAVCCmdEntry;



#define CMD_IMPLEMENTED       1
#define CMD_NOT_IMPLEMENTED   0
#define CMD_UNDETERMINED      0xffffffff   // -1


typedef struct {    
    DVCR_AVC_COMMAND command; // VCR_PLAY_FORWARD
    LONG   lCmdImplemented;   // 1:Implemented, 0:NotImpelemnted; -1:UnDetermined

    ULONG  ulRespFlags;       // DVCR_AVC_SEND

    ULONG  ulCmdSupported;    // one or more of constants defined in BITMAP_CTYPE

    LONG   OperandLength;      // -1 = variable length

    BYTE   CType;
    BYTE   SubunitAddr;
    BYTE   Opcode;

    BYTE   Operands[MAX_AVC_OPERAND_BYTES];

} KSFCP_PACKET, *PKSFCP_PACKET;



#define OPC_TIMECODE          0x51
#define OPC_OPEN_MIC          0x60
#define OPC_READ_MIC          0x61
#define OPC_WRITE_MIC         0x62
#define OPC_INPUT_SIGNAL_MODE 0x79
#define OPC_LOAD_MEDIUM       0xc1
#define OPC_RECORD            0xc2
#define OPC_PLAY              0xc3
#define OPC_WIND              0xc4
#define OPC_TRANSPORT_STATE   0xd0
#define OPC_MEDIUM_INFO       0xda




#define UNIT_TYPE_ID_VCR      0x20  // VCR    00100:000; 00100 == 4 == VCR,    000 == instancve number
#define UNIT_TYPE_ID_CAMERA   0x38  // Camera 00111:000; 00111 == 7 == Camera, 000 == instancve number
#define UNIT_TYPE_ID_DV       0xff  // DV UNIT as a whole


// Vendor IDs that require special treatments
#define VENDOR_ID_MASK        0x00ffffff
#define VENDORID_CANON        0x85     //  VEN_85   : Vendor Dependent command for ModeOfOperation
#define VENDORID_PANASONIC    0x8045   //  VEN_8045 : DVCPRO?


#define AVC_POWER_STATE_ON    0x70
#define AVC_POWER_STATE_OFF   0x60

#endif


NTSTATUS  
DVIssueAVCCommand (
    IN PDVCR_EXTENSION pDevExt, 
    IN AvcCommandType cType,
    IN DVCR_AVC_COMMAND idxAVCCmd,
    IN PVOID pProperty
    );


void
DVAVCCmdResetAfterBusReset(
    PDVCR_EXTENSION pDevExt
    );


NTSTATUS
AVCTapeGetDeviceProperty(
    IN PDVCR_EXTENSION     pDevExt,
    IN PSTREAM_PROPERTY_DESCRIPTOR pSPDesc,
    OUT PULONG pulActualBytetransferred
    );


NTSTATUS
AVCTapeSetDeviceProperty(
    IN PDVCR_EXTENSION     pDevExt,  
    IN PSTREAM_PROPERTY_DESCRIPTOR pSPD,
    IN PULONG pulActualBytetransferred
    );
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\drivers\wdm\capture\mini\mstape\mstpavc.c ===
/*++

Copyright (C) Microsoft Corporation, 1999 - 2000  

Module Name:

    MsTpAvc.c

Abstract:

    Interface code with for issuing external device control commands.

Last changed by:
    
    Author:      Yee J. Wu

Environment:

    Kernel mode only

Revision History:

    $Revision::                    $
    $Date::                        $

--*/

#include "strmini.h"
#include "ksmedia.h"
#include "1394.h"
#include "61883.h"
#include "avc.h"
#include "dbg.h"
#include "MsTpFmt.h"
#include "MsTpDef.h"
#include "MsTpUtil.h"
#include "MsTpAvc.h"

#include "EDevCtrl.h"


PAVCCmdEntry
DVCRFindCmdEntryCompleted(
    PDVCR_EXTENSION pDevExt,
    DVCR_AVC_COMMAND idxDVCRCmd,
    BYTE OpCodeToMatch,
    AvcCommandType cmdTypeToMatch
    );
NTSTATUS 
DVGetExtDeviceProperty(
    IN PDVCR_EXTENSION pDevExt,
    IN PSTREAM_PROPERTY_DESCRIPTOR pSPD,
    OUT PULONG pulActualBytesTransferred
    );
NTSTATUS 
DVSetExtDeviceProperty(
    IN PDVCR_EXTENSION pDevExt,
    IN PSTREAM_PROPERTY_DESCRIPTOR pSPD,
    OUT ULONG *pulActualBytesTransferred
    );
NTSTATUS 
DVGetExtTransportProperty(    
    IN PDVCR_EXTENSION pDevExt,
    IN PSTREAM_PROPERTY_DESCRIPTOR pSPD,
    OUT ULONG *pulActualBytesTransferred
    );
NTSTATUS 
DVSetExtTransportProperty( 
    IN PDVCR_EXTENSION pDevExt,
    IN PSTREAM_PROPERTY_DESCRIPTOR pSPD,
    OUT ULONG *pulActualBytesTransferred
    );
NTSTATUS 
DVGetTimecodeReaderProperty(
    IN PDVCR_EXTENSION pDevExt,
    IN PSTREAM_PROPERTY_DESCRIPTOR pSPD,
    OUT PULONG pulActualBytesTransferred
    );
NTSTATUS 
DVMediaSeekingProperty(
    IN PDVCR_EXTENSION pDevExt,
    IN PSTREAM_PROPERTY_DESCRIPTOR pSPD,
    OUT PULONG pulActualBytesTransferred
    );

#if 0  // Enable later
#ifdef ALLOC_PRAGMA   
     #pragma alloc_text(PAGE, DVCRFindCmdEntryCompleted)
     // #pragma alloc_text(PAGE, DVIssueAVCCommand)
     #pragma alloc_text(PAGE, DVGetExtDeviceProperty)
     #pragma alloc_text(PAGE, DVSetExtDeviceProperty)
     #pragma alloc_text(PAGE, DVGetExtTransportProperty)
     #pragma alloc_text(PAGE, DVSetExtTransportProperty)
     #pragma alloc_text(PAGE, DVGetTimecodeReaderProperty)
     #pragma alloc_text(PAGE, DVMediaSeekingProperty)
     #pragma alloc_text(PAGE, AVCTapeGetDeviceProperty)
     #pragma alloc_text(PAGE, AVCTapeSetDeviceProperty)
#endif
#endif

KSFCP_PACKET  DVcrAVCCmdTable[] = {
//                                                      ctype             subunitaddr       opcode    operands
  {  DV_UNIT_INFO,              -1, 0, CMD_STATUS,   5, AVC_CTYPE_STATUS, UNIT_TYPE_ID_DV,  0x30, 0xff, 0xff, 0xff, 0xff, 0xff}
 ,{  DV_SUBUNIT_INFO,           -1, 0, CMD_STATUS,   5, AVC_CTYPE_STATUS, UNIT_TYPE_ID_DV,  0x31, 0x07, 0xff, 0xff, 0xff, 0xff}
 ,{  DV_CONNECT_AV_MODE,        -1, 0, CMD_STATUS,   5, AVC_CTYPE_STATUS, UNIT_TYPE_ID_DV,  0x20, 0xf0, 0xff, 0xff, 0x20, 0x20}
 ,{  DV_VEN_DEP_CANON_MODE,     -1, 0, CMD_STATUS,   7, AVC_CTYPE_STATUS, UNIT_TYPE_ID_VCR, 0x00, 0x00, 0x00, 0x85, 0x00, 0x10, 0x08, 0xff}
 ,{  DV_VEN_DEP_DVCPRO,         -1, 0, CMD_STATUS,   7, AVC_CTYPE_STATUS, UNIT_TYPE_ID_DV,  0x00, 0x00, 0x80, 0x45, 0x82, 0x48, 0xff, 0xff}
 ,{  DV_IN_PLUG_SIGNAL_FMT,     -1, 0, CMD_STATUS,   5, AVC_CTYPE_STATUS, UNIT_TYPE_ID_DV,  0x19, 0x00, 0xff, 0xff, 0xff, 0xff}
 ,{  DV_OUT_PLUG_SIGNAL_FMT,    -1, 0, CMD_STATUS,   5, AVC_CTYPE_STATUS, UNIT_TYPE_ID_DV,  0x18, 0x00, 0xff, 0xff, 0xff, 0xff}

 ,{  DV_GET_POWER_STATE,        -1, 0, CMD_STATUS,   1, AVC_CTYPE_STATUS, UNIT_TYPE_ID_DV, 0xb2, 0x7f}
 ,{  DV_SET_POWER_STATE_ON,     -1, 0, CMD_CONTROL,  1, AVC_CTYPE_CONTROL,UNIT_TYPE_ID_DV, 0xb2, 0x70}
 ,{  DV_SET_POWER_STATE_OFF,    -1, 0, CMD_CONTROL,  1, AVC_CTYPE_CONTROL,UNIT_TYPE_ID_DV, 0xb2, 0x60}


 ,{ VCR_TIMECODE_SEARCH,        -1, 0, CMD_CONTROL,  5, AVC_CTYPE_CONTROL,UNIT_TYPE_ID_VCR, 0x51, 0x20, 0x00, 0x00, 0x00, 0x00}
 ,{ VCR_TIMECODE_READ,          -1, 0, CMD_STATUS,   5, AVC_CTYPE_STATUS, UNIT_TYPE_ID_VCR, 0x51, 0x71, 0xff, 0xff, 0xff, 0xff}

 ,{ VCR_ATN_SEARCH,             -1, 0, CMD_CONTROL,  5, AVC_CTYPE_CONTROL,UNIT_TYPE_ID_VCR, 0x52, 0x20, 0x00, 0x00, 0x00, 0x00}
 ,{ VCR_ATN_READ,               -1, 0, CMD_STATUS,   5, AVC_CTYPE_STATUS, UNIT_TYPE_ID_VCR, 0x52, 0x71, 0xff, 0xff, 0xff, 0xff}

 ,{ VCR_RTC_SEARCH,             -1, 0, CMD_CONTROL,  5, AVC_CTYPE_CONTROL,UNIT_TYPE_ID_VCR, 0x57, 0x20, 0x00, 0x00, 0x00, 0x00}
 ,{ VCR_RTC_READ,               -1, 0, CMD_STATUS,   5, AVC_CTYPE_STATUS, UNIT_TYPE_ID_VCR, 0x57, 0x71, 0xff, 0xff, 0xff, 0xff}

 ,{ VCR_OPEN_MIC_CLOSE,         -1, 0, CMD_CONTROL,  1, AVC_CTYPE_CONTROL,UNIT_TYPE_ID_VCR, 0x60, 0x00}
 ,{ VCR_OPEN_MIC_READ,          -1, 0, CMD_CONTROL,  1, AVC_CTYPE_CONTROL,UNIT_TYPE_ID_VCR, 0x60, 0x01}
 ,{ VCR_OPEN_MIC_WRITE,         -1, 0, CMD_CONTROL,  1, AVC_CTYPE_CONTROL,UNIT_TYPE_ID_VCR, 0x60, 0x03}
 ,{ VCR_OPEN_MIC_STATUS,        -1, 0, CMD_STATUS,   1, AVC_CTYPE_STATUS, UNIT_TYPE_ID_VCR, 0x60, 0xff}

 ,{ VCR_READ_MIC,               -1, 0, CMD_CONTROL, -1, AVC_CTYPE_CONTROL,UNIT_TYPE_ID_VCR, 0x61}

 ,{ VCR_WRITE_MIC,              -1, 0, CMD_CONTROL, -1, AVC_CTYPE_CONTROL,UNIT_TYPE_ID_VCR, 0x62}

 ,{ VCR_OUTPUT_SIGNAL_MODE,     -1, 0, CMD_STATUS,   1, AVC_CTYPE_STATUS, UNIT_TYPE_ID_VCR, 0x78, 0xff}
 ,{ VCR_INPUT_SIGNAL_MODE,      -1, 0, CMD_STATUS,   1, AVC_CTYPE_STATUS, UNIT_TYPE_ID_VCR, 0x79, 0xff}

 ,{ VCR_LOAD_MEDIUM_EJECT,      -1, 0, CMD_CONTROL,  1, AVC_CTYPE_CONTROL,UNIT_TYPE_ID_VCR, 0xc1, 0x60}

 ,{ VCR_RECORD,                 -1, 0, CMD_CONTROL,  1, AVC_CTYPE_CONTROL,UNIT_TYPE_ID_VCR, 0xc2, 0x75}
 ,{ VCR_RECORD_PAUSE,           -1, 0, CMD_CONTROL,  1, AVC_CTYPE_CONTROL,UNIT_TYPE_ID_VCR, 0xc2, 0x7d}

 ,{ VCR_PLAY_FORWARD_STEP,      -1, 0, CMD_CONTROL,  1, AVC_CTYPE_CONTROL,UNIT_TYPE_ID_VCR, 0xc3, 0x30}  // 00=AVC, 20=VCR, c3=Opcode, 30=Operand[0]
 ,{ VCR_PLAY_FORWARD_SLOWEST,   -1, 0, CMD_CONTROL,  1, AVC_CTYPE_CONTROL,UNIT_TYPE_ID_VCR, 0xc3, 0x31}  
 ,{ VCR_PLAY_FORWARD_SLOWEST2,  -1, 0, CMD_CONTROL,  1, AVC_CTYPE_CONTROL,UNIT_TYPE_ID_VCR, 0xc3, 0x33}  
 ,{ VCR_PLAY_FORWARD_FASTEST,   -1, 0, CMD_CONTROL,  1, AVC_CTYPE_CONTROL,UNIT_TYPE_ID_VCR, 0xc3, 0x3f}

 ,{ VCR_PLAY_REVERSE_STEP,      -1, 0, CMD_CONTROL,  1, AVC_CTYPE_CONTROL,UNIT_TYPE_ID_VCR, 0xc3, 0x40} 
 ,{ VCR_PLAY_REVERSE_SLOWEST,   -1, 0, CMD_CONTROL,  1, AVC_CTYPE_CONTROL,UNIT_TYPE_ID_VCR, 0xc3, 0x41}
 ,{ VCR_PLAY_REVERSE_SLOWEST2,  -1, 0, CMD_CONTROL,  1, AVC_CTYPE_CONTROL,UNIT_TYPE_ID_VCR, 0xc3, 0x43}
 ,{ VCR_PLAY_REVERSE_FASTEST,   -1, 0, CMD_CONTROL,  1, AVC_CTYPE_CONTROL,UNIT_TYPE_ID_VCR, 0xc3, 0x4f}
 
 ,{ VCR_PLAY_FORWARD,           -1, 0, CMD_CONTROL,  1, AVC_CTYPE_CONTROL,UNIT_TYPE_ID_VCR, 0xc3, 0x75}  
 ,{ VCR_PLAY_FORWARD_PAUSE,     -1, 0, CMD_CONTROL,  1, AVC_CTYPE_CONTROL,UNIT_TYPE_ID_VCR, 0xc3, 0x7d}

 ,{ VCR_WIND_STOP,              -1, 0, CMD_CONTROL,  1, AVC_CTYPE_CONTROL,UNIT_TYPE_ID_VCR, 0xc4, 0x60}
 ,{ VCR_WIND_REWIND,            -1, 0, CMD_CONTROL,  1, AVC_CTYPE_CONTROL,UNIT_TYPE_ID_VCR, 0xc4, 0x65}
 ,{ VCR_WIND_FAST_FORWARD,      -1, 0, CMD_CONTROL,  1, AVC_CTYPE_CONTROL,UNIT_TYPE_ID_VCR, 0xc4, 0x75}

 ,{ VCR_TRANSPORT_STATE,        -1, 0, CMD_STATUS,   1, AVC_CTYPE_STATUS, UNIT_TYPE_ID_VCR, 0xd0, 0x7f}
 ,{ VCR_TRANSPORT_STATE_NOTIFY, -1, 0, CMD_NOTIFY,   1, AVC_CTYPE_NOTIFY, UNIT_TYPE_ID_VCR, 0xd0, 0x7f}


 ,{ VCR_MEDIUM_INFO,            -1, 0, CMD_STATUS,   2, AVC_CTYPE_STATUS, UNIT_TYPE_ID_VCR, 0xda, 0x7f,0x7f}

 ,{ VCR_RAW_AVC,                 1, 0, CMD_CONTROL | CMD_STATUS | CMD_NOTIFY | CMD_SPEC_INQ | CMD_GEN_INQ, 0}

};



void
DVCRXlateGetMediumInfo(
    PMEDIUM_INFO pMediumInfo,
    PBYTE pbOperand0,
    PBYTE pbOperand1
    )
{

    TRACE(TL_FCP_TRACE,("GetMediumInfo: Type:%x; WriteProtect:%x\n", *pbOperand0, *pbOperand1));

    switch(*pbOperand0) {

    // Support for DigitalHi8; if we get this query, we treat DHi8 as a mini DV tape.
    case 0x12:  // DHi8

    case 0x31:// DVCR standard cassette
    case 0x32:// DVCR small cassette
    case 0x33:// DVCR medium cassette
        pMediumInfo->MediaPresent  = TRUE;
        pMediumInfo->MediaType     = ED_MEDIA_DVC;
        pMediumInfo->RecordInhibit = (*pbOperand1 & 0x01) == 0x01;
        break;
    case 0x22: // VHS cassette
        pMediumInfo->MediaPresent  = TRUE;
        pMediumInfo->MediaType     = ED_MEDIA_VHS;
        pMediumInfo->RecordInhibit = (*pbOperand1 & 0x01) == 0x01;
        break;
    case 0x23:
        pMediumInfo->MediaPresent  = TRUE;
        pMediumInfo->MediaType     = ED_MEDIA_VHSC;
        pMediumInfo->RecordInhibit = (*pbOperand1 & 0x01) == 0x01;
        break;
    case 0x60:
        pMediumInfo->MediaPresent  = FALSE;
        pMediumInfo->MediaType     = ED_MEDIA_NOT_PRESENT;
        pMediumInfo->RecordInhibit = TRUE;  // Cannot record if there is no tape.
        break;
    case 0x7e:
        pMediumInfo->MediaPresent  = TRUE;
        pMediumInfo->MediaType     = ED_MEDIA_UNKNOWN;
        pMediumInfo->RecordInhibit = TRUE;  // Actually cannot be determined
        break;
    // Sony's NEO device
    case 0x41:
        pMediumInfo->MediaPresent  = TRUE;
        pMediumInfo->MediaType     = ED_MEDIA_NEO;
        pMediumInfo->RecordInhibit = (*pbOperand1 & 0x01) == 0x01;
        break;
    default:
        pMediumInfo->MediaPresent  = TRUE;
        pMediumInfo->MediaType     = ED_MEDIA_UNKNOWN;
        pMediumInfo->RecordInhibit = TRUE;
        break;
    }

    // Reset command opcode/operands
    *pbOperand0 = 0x7f;
    *pbOperand1 = 0x7f;
}

void
DVCRXlateGetTransportState(
    PTRANSPORT_STATE pXPrtState,
    PBYTE pbOpcode,
    PBYTE pbOperand0
    )
{

    TRACE(TL_FCP_TRACE,("XlateGetTransportState: OpCode %x, Operand %x\n", *pbOpcode, *pbOperand0));

    switch(*pbOpcode) {

    case OPC_LOAD_MEDIUM:
        pXPrtState->Mode = ED_MEDIA_UNLOAD;
        ASSERT(*pbOperand0 == 0x60);
        break;

    case OPC_RECORD:
        pXPrtState->Mode = ED_MODE_RECORD;
        switch(*pbOperand0) {
        case 0x75: // RECORD
            pXPrtState->State = ED_MODE_RECORD;
            break;
        case 0x7d: // RECORD_FREEZE
            pXPrtState->State = ED_MODE_RECORD_FREEZE;
            break;
        default:
            ASSERT(FALSE && "OPC_RECORD: Operand0 undefined!");
            break;
        }
        break;

    case OPC_PLAY:
        pXPrtState->Mode = ED_MODE_PLAY;
        switch(*pbOperand0) {
        case 0x30:  // NEXT FRAME
            pXPrtState->State = ED_MODE_STEP_FWD;
            break;
        case 0x31:  // SLOWEST FORWARD
        case 0x32:  // SLOW FORWARD 6        
        case 0x33:  // SLOW FORWARD 5
        case 0x34:  // SLOW FORWARD 4
        case 0x35:  // SLOW FORWARD 3
        case 0x36:  // SLOW FORWARD 2
        case 0x37:  // SLOW FORWARD 1
            pXPrtState->State = ED_MODE_PLAY_SLOWEST_FWD;
            break;
        case 0x38:  // PLAY FORWARD 1
            pXPrtState->State = ED_MODE_PLAY;
            break;
        case 0x39:  // FAST FORWARD 1
        case 0x3a:  // FAST FORWARD 2
        case 0x3b:  // FAST FORWARD 3
        case 0x3c:  // FAST FORWARD 4
        case 0x3d:  // FAST FORWARD 5
        case 0x3e:  // FAST FORWARD 6
        case 0x3f:  // FASTEST FORWARD
            pXPrtState->State = ED_MODE_PLAY_FASTEST_FWD;
            break;
        case 0x40:  // PREVIOUS FRAME
            pXPrtState->State = ED_MODE_STEP_REV;
            break;
        case 0x41:  // SLOWEST REVERSE
        case 0x42:  // SLOW REVERSE 6
        case 0x43:  // SLOW REVERSE 5 
        case 0x44:  // SLOW REVERSE 4 
        case 0x45:  // SLOW REVERSE 3
        case 0x46:  // SLOW REVERSE 2 
        case 0x47:  // SLOW REVERSE 1 
            pXPrtState->State = ED_MODE_PLAY_SLOWEST_REV;
            break;
        case 0x48:  // X1 REVERSE
        case 0x65:  // REVERSE 
            pXPrtState->State = ED_MODE_REV_PLAY;
            break;
        case 0x49:  // FAST REVERSE 1
        case 0x4a:  // FAST REVERSE 2
        case 0x4b:  // FAST REVERSE 3
        case 0x4c:  // FAST REVERSE 4
        case 0x4d:  // FAST REVERSE 5
        case 0x4e:  // FAST REVERSE 6
        case 0x4f:  // FASTEST REVERSE
            pXPrtState->State = ED_MODE_PLAY_FASTEST_REV;
            break;
        case 0x75:  // FORWARD
            pXPrtState->State = ED_MODE_PLAY;
            break;
        case 0x6d:  // REVERSE PAUSE
        case 0x7d:  // FORWARD PAUSE
            pXPrtState->State = ED_MODE_FREEZE;
            break;
        default:
            pXPrtState->State = 0;
            ASSERT(FALSE && "OPC_PLAY: Operand0 undefined!");
            break;
        }
        break;

    case OPC_WIND:
        //pXPrtState->Mode = ED_MODE_WIND;
        switch(*pbOperand0) {
        case 0x45:  // HIGH SPEED REWIND
            pXPrtState->State = ED_MODE_REW_FASTEST;
            break;
        case 0x60:  // STOP
            pXPrtState->State = ED_MODE_STOP;
            break;
        case 0x65:  // REWIND
            pXPrtState->State = ED_MODE_REW;
            break;
        case 0x75:  // FAST FORWARD
            pXPrtState->State = ED_MODE_FF;
            break;
        default:
            TRACE(TL_FCP_ERROR,("XlateGetTransportState:  OPC_WIND with unknown operand0 %x\n", *pbOperand0));            
            break;
        }
        // Thre is not a state defined for WIND
        pXPrtState->Mode = pXPrtState->State;
        break;

    case OPC_TRANSPORT_STATE:  // As a result of the notify command
        break;

    default:
        ASSERT(FALSE && "OpCode undefined!");
        break;
    }

    // Reset command opcode/operands
    *pbOpcode   = 0xd0;
    *pbOperand0 = 0x7f;
}


void
DVCRXlateGetIOSignalMode(
    PULONG pIOSignalMode,
    PBYTE pbOperand0
    )
{

    TRACE(TL_FCP_WARNING,("IOSignalMode: IoSignal:%x\n", *pbOperand0));

    switch(*pbOperand0) {
    case 0x00:  // SD 525-60
    case 0x06:  // Analog 8mm NTSC
    case 0x0e:  // Analog Hi8 NTSC
        *pIOSignalMode = ED_TRANSBASIC_SIGNAL_525_60_SD;
        break;
    case 0x04:  // SDL 525-60
        *pIOSignalMode = ED_TRANSBASIC_SIGNAL_525_60_SDL;
        break;
    case 0x80:  // SD 625-50
    case 0x86:  // Analog 8mm NTSC
    case 0x8e:  // Analog Hi8 NTSC
        *pIOSignalMode = ED_TRANSBASIC_SIGNAL_625_50_SD;
        break;
    case 0x84:  // SDL 625-50
        *pIOSignalMode = ED_TRANSBASIC_SIGNAL_625_50_SDL;
        break;
  
    // Various MPEG2 format
    case 0x05:  // Analog VHS NTSC 525/60
    case 0x25:  // Analog VHS M-NTSC 525/60
    case 0xA5:  // Analog VHS PAL 625/50
    case 0xB5:  // Analog VHS M-PAL 625/50
    case 0xC5:  // Analog VHS SECAM 625/50
    case 0xD5:  // Analog VHS ME-SECAM 625/50
    case 0x01:  // D-VHS
    case 0x0d:  // Analob S-VHS 525/60
    case 0xed:  // Analog S-VHS 625/50
        *pIOSignalMode = ED_TRANSBASIC_SIGNAL_MPEG2TS;
        break;
    
    case 0x10:  // MPEG 25    Mbps-60
        *pIOSignalMode = ED_TRANSBASIC_SIGNAL_2500_60_MPEG;
        break;
    case 0x14:  // MPEG 12.5 Mbps-60
    case 0x24:  // MPEG 12.5 Mbps-60 (NEO)
        *pIOSignalMode = ED_TRANSBASIC_SIGNAL_1250_60_MPEG;
        break;
    case 0x18:  // MPEG  6.25Mbps-60
    case 0x28:  // MPEG  6.25Mbps-60 (NEO)
        *pIOSignalMode = ED_TRANSBASIC_SIGNAL_0625_60_MPEG;
        break;
    case 0x90:  // MPEG 25Mbps-50
        *pIOSignalMode = ED_TRANSBASIC_SIGNAL_2500_50_MPEG;
        break;
    case 0x94:  // MPEG 12.5Mbps-50
    case 0xa4:  // MPEG 12.5Mbps-50 (NEO)
        *pIOSignalMode = ED_TRANSBASIC_SIGNAL_1250_50_MPEG;
        break;
    case 0x98:  // MPEG  6.25Mbps-50
    case 0xa8:  // MPEG  6.25Mbps-50 (NEO)
        *pIOSignalMode = ED_TRANSBASIC_SIGNAL_0625_50_MPEG;
        break;

    case 0x0f:  // Unknown data 
        *pIOSignalMode = ED_TRANSBASIC_SIGNAL_UNKNOWN;
        break;

    default:
        // This driver does not understand other format;
        TRACE(TL_FCP_ERROR,("Unknown IoSignal:%x\n", *pbOperand0));
        ASSERT(FALSE && "Unknown IoSignal!");
        break;
    }

    // Reset command opcode/operands
    *pbOperand0 = 0xff;
}

NTSTATUS
DVCRXlateRAwAVC(
    PAVCCmdEntry pCmdEntry,
    PVOID     pProperty
    )
{
    PAVC_COMMAND_IRB pAvcIrb = pCmdEntry->pAvcIrb;
    UCHAR ucRespCode = pAvcIrb->ResponseCode;   
    NTSTATUS  Status;
    PUCHAR   pbRtnBuf;
    PKSPROPERTY_EXTDEVICE_S pXDevProperty;
    PKSPROPERTY_EXTXPORT_S pXPrtProperty;
    PKSPROPERTY_TIMECODE_S pTmCdReaderProperty;

    if(STATUS_SUCCESS != pCmdEntry->Status) {
        TRACE(TL_FCP_ERROR,("XlateRAwAVC: Status:%x\n", pCmdEntry->Status));
        return pCmdEntry->Status;
    }


    switch (pCmdEntry->idxDVCRCmd) {
    case DV_UNIT_INFO:       
        pbRtnBuf = (PBYTE) pProperty;        
        memcpy(pbRtnBuf, pAvcIrb->Operands+1, 4);
        break;
    case DV_SUBUNIT_INFO:
    case DV_IN_PLUG_SIGNAL_FMT:
    case DV_OUT_PLUG_SIGNAL_FMT:
        pbRtnBuf = (PBYTE) pProperty;
        memcpy(pbRtnBuf, pAvcIrb->Operands+1, 4);
        break;
     // special case, return the response code in the first byte
    case DV_CONNECT_AV_MODE:
        pbRtnBuf = (PBYTE) pProperty;
        pbRtnBuf[0] = ucRespCode;
        memcpy(&pbRtnBuf[1], pAvcIrb->Operands, 5);        
        break;
     // special case, return the response code in the first byte
    case DV_VEN_DEP_CANON_MODE:
        pbRtnBuf = (PBYTE) pProperty;
        pbRtnBuf[0] = ucRespCode;
        memcpy(&pbRtnBuf[1], pAvcIrb->Operands, 7);        
        break;
    case DV_GET_POWER_STATE:
        pXDevProperty = (PKSPROPERTY_EXTDEVICE_S) pProperty;
        TRACE(TL_FCP_WARNING,("GET_POWER_STATE: OperandsStatus:%x\n", pAvcIrb->Operands[0]));
        switch(pAvcIrb->Operands[0]) {
        case AVC_POWER_STATE_OFF: // 0x60
            // If the device is OFF, it cannot give us this response so it must be in standby mode.
            pXDevProperty->u.PowerState = ED_POWER_OFF;
            break;
        case AVC_POWER_STATE_ON:      // 0x70
            pXDevProperty->u.PowerState = ED_POWER_ON;
            break;
        default:
            // If it is not ON or OFF, we "guess" it is a new power state of "Standby".
            pXDevProperty->u.PowerState = ED_POWER_STANDBY;
            break;
        }
        break;

    case VCR_TIMECODE_READ:
        pTmCdReaderProperty = (PKSPROPERTY_TIMECODE_S) pProperty;
        if(pAvcIrb->Operands[1] == 0xff || 
           pAvcIrb->Operands[2] == 0xff || 
           pAvcIrb->Operands[3] == 0xff || 
           pAvcIrb->Operands[4] == 0xff )  {
            TRACE(TL_FCP_ERROR,("TimeCodeRead: %.2x:%.2x:%.2x,%.2x\n", pAvcIrb->Operands[4], pAvcIrb->Operands[3], pAvcIrb->Operands[2], pAvcIrb->Operands[1]));
            // Even though command succeded, but the data is not valid!
            Status = STATUS_UNSUCCESSFUL;
        } else {
            // bswap them.
            pTmCdReaderProperty->TimecodeSamp.timecode.dwFrames  = 
                (((DWORD) pAvcIrb->Operands[4]) << 24) |
                (((DWORD) pAvcIrb->Operands[3]) << 16) |
                (((DWORD) pAvcIrb->Operands[2]) <<  8) |
                 ((DWORD) pAvcIrb->Operands[1]);
             TRACE(TL_FCP_TRACE,("TimeCodeRead: %.2x:%.2x:%.2x,%.2x\n", pAvcIrb->Operands[4], pAvcIrb->Operands[3], pAvcIrb->Operands[2], pAvcIrb->Operands[1]));
        }
        break;
    case VCR_RTC_READ:
        pTmCdReaderProperty = (PKSPROPERTY_TIMECODE_S) pProperty;
        if(// 0xFF is valid for RTC: pAvcIrb->Operands[1] == 0xff || 
           pAvcIrb->Operands[2] == 0xff || 
           pAvcIrb->Operands[3] == 0xff || 
           pAvcIrb->Operands[4] == 0xff )  {
           TRACE(TL_FCP_ERROR,("RTC_Read: %.2x:%.2x:%.2x,%.2x\n", pAvcIrb->Operands[4], pAvcIrb->Operands[3], pAvcIrb->Operands[2], pAvcIrb->Operands[1]));
            // Even though command succeded, but the data is not valid!
            Status = STATUS_UNSUCCESSFUL;
        } else {
            // bswap them.
            pTmCdReaderProperty->TimecodeSamp.timecode.dwFrames  = 
                (((DWORD) pAvcIrb->Operands[4]) << 24) |
                (((DWORD) pAvcIrb->Operands[3]) << 16) |
                (((DWORD) pAvcIrb->Operands[2]) <<  8) |
                 ((DWORD) pAvcIrb->Operands[1]);
            TRACE(TL_FCP_TRACE,("RTC_Read: %.2x:%.2x:%.2x,%.2x\n", pAvcIrb->Operands[4], pAvcIrb->Operands[3], pAvcIrb->Operands[2], pAvcIrb->Operands[1]));
        }
        break;
    case VCR_ATN_READ:
        pTmCdReaderProperty = (PKSPROPERTY_TIMECODE_S) pProperty;
        if(pAvcIrb->Operands[1] == 0x00 && 
           pAvcIrb->Operands[2] == 0x00 && 
           pAvcIrb->Operands[3] == 0x00 )  {
            // Even though command succeded, but the data is not valid!
            Status = STATUS_UNSUCCESSFUL;
        } else {

#define MEDIUM_TYPE_MASK  0xf8 // 11111000b
#define MEDIUM_TYPE_DVHS  0x08 // 00001000b
#define MEDIUM_TYPE_DVCR  0xf8 // 11111000b
#define MEDIUM_TYPE_NEO   0x10 // 00010000b

            switch(pAvcIrb->Operands[4] & MEDIUM_TYPE_MASK) {
            case MEDIUM_TYPE_DVCR:            
                pTmCdReaderProperty->TimecodeSamp.dwUser = 
                    pAvcIrb->Operands[1] & 0x01;  // Get the Blank flag
                 // bswap them.
                pTmCdReaderProperty->TimecodeSamp.timecode.dwFrames  = 
                    ( (((DWORD) pAvcIrb->Operands[3]) << 16) |
                      (((DWORD) pAvcIrb->Operands[2]) <<  8) |
                      (((DWORD) pAvcIrb->Operands[1]))
                    ) >> 1;
                break;
            case MEDIUM_TYPE_DVHS:            
                pTmCdReaderProperty->TimecodeSamp.dwUser = 
                    (pAvcIrb->Operands[1] >> 6) & 0x03;  // Get the SF
                 // bswap them.
                pTmCdReaderProperty->TimecodeSamp.timecode.dwFrames  = 
                    ( (((DWORD) (pAvcIrb->Operands[1] & 0x3f)) << 16) |
                      (((DWORD) pAvcIrb->Operands[2]) <<  8) |
                      (((DWORD) pAvcIrb->Operands[3]))
                    );
                break;            
            case MEDIUM_TYPE_NEO:            
                pTmCdReaderProperty->TimecodeSamp.dwUser = 
                    (pAvcIrb->Operands[3] >> 7) & 0x01;  // Get the Blank flag
                 // bswap them.
                pTmCdReaderProperty->TimecodeSamp.timecode.dwFrames  = 
                    ( (((DWORD) (pAvcIrb->Operands[3] & 0x7f)) << 16) |
                      (((DWORD) pAvcIrb->Operands[2]) <<  8) |
                      (((DWORD) pAvcIrb->Operands[1]))
                    );

                TRACE(TL_FCP_TRACE, ("ATN (NEO):bf:%d ATN:%d\n",
                    pTmCdReaderProperty->TimecodeSamp.dwUser,
                    pTmCdReaderProperty->TimecodeSamp.timecode.dwFrames
                    ));
                break;
            default:
                // Unknown medium type
                Status = STATUS_UNSUCCESSFUL;
                TRACE(TL_FCP_ERROR, ("Operand4:%x; Unknown Medium type for ATN: %x\n",
                        pAvcIrb->Operands[4], pAvcIrb->Operands[4] & MEDIUM_TYPE_MASK));
                break;
            }
        }
        break;
    case VCR_INPUT_SIGNAL_MODE:
    case VCR_OUTPUT_SIGNAL_MODE:
        pXPrtProperty = (PKSPROPERTY_EXTXPORT_S) pProperty;
        DVCRXlateGetIOSignalMode(&pXPrtProperty->u.SignalMode, &pAvcIrb->Operands[0]);
        break;
    case VCR_TRANSPORT_STATE:
    case VCR_TRANSPORT_STATE_NOTIFY:
        pXPrtProperty = (PKSPROPERTY_EXTXPORT_S) pProperty;
        DVCRXlateGetTransportState(&pXPrtProperty->u.XPrtState, &pAvcIrb->Opcode, &pAvcIrb->Operands[0]);
        break;
    case VCR_MEDIUM_INFO:
        pXPrtProperty = (PKSPROPERTY_EXTXPORT_S) pProperty;
        DVCRXlateGetMediumInfo(&pXPrtProperty->u.MediumInfo, &pAvcIrb->Operands[0], &pAvcIrb->Operands[1]);
        break;
    case VCR_RAW_AVC:
        // Do nothing.
        break;
     default:
        // No translation necessary
         TRACE(TL_FCP_TRACE,("No tranlsation: pCmdEntry:%x; idx:%d\n", pCmdEntry, pCmdEntry->idxDVCRCmd));
        break;
    }

    return pCmdEntry->Status;
}



PAVCCmdEntry
DVCRFindCmdEntryCompleted(
    PDVCR_EXTENSION pDevExt,
    DVCR_AVC_COMMAND idxDVCRCmd,
    BYTE OpCodeToMatch,
    AvcCommandType cmdTypeToMatch
    )
/*++

Routine Description:

Arguments:

Return Value:

    PLIST_ENTRY

--*/
{
    LIST_ENTRY   *pEntry;
    KIRQL         OldIrql;

    PAGED_CODE();

    //
    // Special case:
    //
    //     ATN:       Status 01 20 52; Control 00 20 52
    //     (resp)            0c 20 52          0f 20 52   (CtrlInterim)
    //
    //     XPrtState: Status 01 20 d0;  Notify 03 20 d0
    //     (resp)            0c 20 xx          0f 20 xx xx (NotifyInterim)      
    //
    // Summary: if we keep cmdType and OpCode, it is unique.
    //
    KeAcquireSpinLock(&pDevExt->AVCCmdLock, &OldIrql);
    pEntry = pDevExt->AVCCmdList.Flink;
    while(pEntry != &pDevExt->AVCCmdList) {       
        PAVCCmdEntry pCmdEntry = (PAVCCmdEntry)pEntry;

        if (pCmdEntry->idxDVCRCmd == idxDVCRCmd) {
            //
            //  We only fetch if it is completed!       
            //
            if(pCmdEntry->cmdState != CMD_STATE_ISSUED) {
                if (pCmdEntry->cmdType == cmdTypeToMatch) {
                    // Control/GenInq/SpecInq: OpCode and Operand[n] remina unchanged.
                    if (pCmdEntry->OpCode == OpCodeToMatch) {
                        TRACE(TL_FCP_TRACE,("FindCmdEntryCompleted: (1) Found pCmdEntry:%x (%x, %x, %x)\n", 
                            pCmdEntry, pCmdEntry->pAvcIrb, cmdTypeToMatch, OpCodeToMatch));

                        RemoveEntryList(&pCmdEntry->ListEntry);  pDevExt->cntCommandQueued--;
                        InitializeListHead(&pCmdEntry->ListEntry);  // used as a flag for ownership
#if DBG
                        // pIrp should be NULL (completed).
                        if(pCmdEntry->pIrp) {
                            TRACE(TL_FCP_ERROR,("Error: FindCmdEntry: pCmdEntry:%x; pIrp:%x not completed\n", pCmdEntry, pCmdEntry->pIrp));
                        } 
#endif
                        KeReleaseSpinLock(&pDevExt->AVCCmdLock, OldIrql);

                        return pCmdEntry;  // Found
                    } 

                } else {
                    TRACE(TL_FCP_WARNING,("FindCmdEntryCompleted: cmdType %x != %x\n", pCmdEntry->cmdType, cmdTypeToMatch));
                }
            }
            else {
                TRACE(TL_FCP_TRACE,("FindCmdEntryCompleted: (0) Skip %x not completed (%x, %x) match entry %x\n", 
                        pCmdEntry, cmdTypeToMatch, OpCodeToMatch));                
            }
        }

        pEntry = pEntry->Flink;
    }

    KeReleaseSpinLock(&pDevExt->AVCCmdLock, OldIrql);

    TRACE(TL_FCP_TRACE,("FindCmdEntryCompleted: (a) No match\n"));                
    return NULL; // No match
}


void
DVAVCCmdResetAfterBusReset(
    PDVCR_EXTENSION pDevExt
    )
/*++

Routine Description:

Arguments:

Return Value:

    Nothing

--*/
{
    KIRQL        OldIrql;

    KeAcquireSpinLock(&pDevExt->AVCCmdLock, &OldIrql);
    TRACE(TL_FCP_TRACE,("BusReset: <enter> AVCCmd [completed %d]; CmdList:%x\n", pDevExt->cntCommandQueued, pDevExt->AVCCmdList));

    // Clear the command list
    while (!IsListEmpty(&pDevExt->AVCCmdList)) {

        PAVCCmdEntry pCmdEntry = (PAVCCmdEntry)RemoveHeadList(&pDevExt->AVCCmdList); pDevExt->cntCommandQueued--;
        InitializeListHead(&pCmdEntry->ListEntry);
        TRACE(TL_FCP_TRACE,("BusReset: AbortAVC: Completed:%d; pCmdEntry:%x; cmdState:%d; cmdSt:%x\n", 
            pDevExt->cntCommandQueued, pCmdEntry, pCmdEntry->cmdState, pCmdEntry->Status));

        switch(pCmdEntry->cmdState) {
        case CMD_STATE_ISSUED:
        case CMD_STATE_RESP_INTERIM:  // AVC.sys may still has it!
            TRACE(TL_FCP_WARNING,("BusReset: AbortAVC: IoCancelIrp(%x)!\n", pCmdEntry->pIrp));
            ASSERT(pCmdEntry->pIrp != NULL);
            IoCancelIrp(pCmdEntry->pIrp);    // Calls DVIssueAVCCommandCR() with pIrp->Cancel
            break;

        // Completed command
        case CMD_STATE_UNDEFINED:
            TRACE(TL_FCP_ERROR,("AVCCmdResetAfterBusReset: Unexpected CMD state %d; pCmdEntry %x\n", pCmdEntry->cmdState, pCmdEntry));
        case CMD_STATE_RESP_ACCEPTED:
        case CMD_STATE_RESP_REJECTED:
        case CMD_STATE_RESP_NOT_IMPL:
        case CMD_STATE_ABORTED:
            break;      

        default:
            TRACE(TL_FCP_ERROR,("AVCCmdResetAfterBusReset: Unknown CMD state %d; pCmdEntry %x\n", pCmdEntry->cmdState, pCmdEntry));
            ASSERT(FALSE && "Unknown cmdState\n");
            break;
        }

        // We are guaranteed at this point that no one needs the
        // results anymore so we will free the resources.
        ExFreePool(pCmdEntry->pAvcIrb);
        ExFreePool(pCmdEntry);
    }

#if DBG
    //
    // Should have no more entry !
    // 
    if(pDevExt->cntCommandQueued != 0) {
        TRACE(TL_FCP_ERROR,("BusReset: <exit> AVCCmd [completed %d]; CmdList:%x\n", pDevExt->cntCommandQueued, pDevExt->AVCCmdList));
        ASSERT(pDevExt->cntCommandQueued == 0);
    }
#endif

    KeReleaseSpinLock(&pDevExt->AVCCmdLock, OldIrql);

}

NTSTATUS
DVIssueAVCCommandCR(
    IN PDEVICE_OBJECT DeviceObject,
    IN PIRP pIrp,
    IN PAVCCmdEntry pCmdEntry
    )
/*++

Routine Description:

    This is the completion routine for the AVC command when it is completed which imply that 
    the interim response will not be called here.

Arguments:
    Note: pCmdEntry cannot be used if pIrp->Cancel.

Return Value:

    Always STATUS_MORE_PROCESSING_REQUIRED.
    Note: the real return is in pCmdEntry->Status.

--*/
{
    KIRQL oldIrql;

    if (!pIrp->Cancel) {

        PDVCR_EXTENSION pDevExt = pCmdEntry->pDevExt;
        BOOL bSignalInterimCotrolCompleted = FALSE;
        BOOL bSignalInterimNotifyCompleted = FALSE;
        PKSEVENT_ENTRY   pEvent;


        // Serialize AVC command response processing
        KeAcquireSpinLock(&pDevExt->AVCCmdLock, &oldIrql);

        ASSERT(pCmdEntry->pIrp == pIrp);
        pCmdEntry->pIrp = NULL; // don't need this anymore

        // Check if it's worthwhile to examine the response buffer
        if (STATUS_SUCCESS == pIrp->IoStatus.Status) {

            PAVC_COMMAND_IRB pAvcIrb = pCmdEntry->pAvcIrb;

            // Check Opcode for return state
            switch(pAvcIrb->ResponseCode) {
            case AVC_RESPONSE_NOTIMPL:
                pCmdEntry->cmdState = CMD_STATE_RESP_NOT_IMPL;
                pCmdEntry->Status   = STATUS_NOT_SUPPORTED;  // -> ERROR_NOT_SUPPORTED
                break;

            case AVC_RESPONSE_ACCEPTED:
                if(pCmdEntry->cmdState == CMD_STATE_RESP_INTERIM) {
                    if(pCmdEntry->cmdType == AVC_CTYPE_CONTROL) {
                        bSignalInterimCotrolCompleted = TRUE;
                        TRACE(TL_FCP_TRACE,("--> Accept: for control interim\n"));
                    } else {
                        TRACE(TL_FCP_ERROR,("pCmdExtry %x\n", pCmdEntry));
                        ASSERT(pCmdEntry->cmdType == AVC_CTYPE_CONTROL && "Accept+Interim but not control cmd");
                    }
                } 
                pCmdEntry->cmdState = CMD_STATE_RESP_ACCEPTED;
                pCmdEntry->Status   = STATUS_SUCCESS;       // -> NOERROR
                break;

            case AVC_RESPONSE_REJECTED:
                if(pCmdEntry->cmdState == CMD_STATE_RESP_INTERIM) {
                    if(pCmdEntry->cmdType == AVC_CTYPE_CONTROL) {
                        TRACE(TL_FCP_TRACE,("--> Reject: for control interim\n"));
                        bSignalInterimCotrolCompleted = TRUE;
                    } else if(pCmdEntry->cmdType == AVC_CTYPE_NOTIFY) {
                        TRACE(TL_FCP_TRACE,("--> Reject: for notify interim\n"));
                        bSignalInterimNotifyCompleted = TRUE;                  
                    } else {
                        TRACE(TL_FCP_ERROR,("pCmdExtry %x\n", pCmdEntry));
                        ASSERT((pCmdEntry->cmdType == AVC_CTYPE_CONTROL || pCmdEntry->cmdType == AVC_CTYPE_NOTIFY) && "Reject+Interim but not control or notify cmd");
                    }
                }
                pCmdEntry->cmdState = CMD_STATE_RESP_REJECTED;
                pCmdEntry->Status   = STATUS_REQUEST_NOT_ACCEPTED;  // ERROR_REQ_NOT_ACCEPTED
                break;

            case AVC_RESPONSE_IN_TRANSITION:
                pCmdEntry->cmdState = CMD_STATE_RESP_ACCEPTED;
                pCmdEntry->Status   = STATUS_SUCCESS;       // -> NOERROR
                break;

            case AVC_RESPONSE_STABLE: // == AVC_RESPONSE_IMPLEMENTED:
                pCmdEntry->cmdState = CMD_STATE_RESP_ACCEPTED;
                pCmdEntry->Status   = STATUS_SUCCESS;       // ->  NOERROR
                break;

            case AVC_RESPONSE_CHANGED:
#if DBG
                if(pCmdEntry->cmdState != CMD_STATE_RESP_INTERIM) {
                   TRACE(TL_FCP_ERROR,("Err: Changed; pCmdExtry:%x; cmdState:%d\n", pCmdEntry, pCmdEntry->cmdState));
                   ASSERT(pCmdEntry->cmdState == CMD_STATE_RESP_INTERIM);
                }
#endif
                if(pCmdEntry->cmdType == AVC_CTYPE_NOTIFY) {
                    TRACE(TL_FCP_TRACE,("--> Changed: for notify interim\n"));
                     bSignalInterimNotifyCompleted = TRUE;                  
                } else {
                    TRACE(TL_FCP_ERROR,("pCmdExtry %x\n", pCmdEntry));
                    ASSERT(pCmdEntry->cmdType == AVC_CTYPE_NOTIFY && "Changed but not notify cmd!");
                }
 
                pCmdEntry->cmdState = CMD_STATE_RESP_ACCEPTED;
                pCmdEntry->Status   = STATUS_SUCCESS;       // ->  NOERROR
                break;

            // AVC.sys should never return this response !!
            case AVC_RESPONSE_INTERIM:              
                ASSERT( pAvcIrb->ResponseCode != AVC_RESPONSE_INTERIM && "CmpRoutine should not has this response!");
                pCmdEntry->cmdState = CMD_STATE_RESP_INTERIM;
                pCmdEntry->Status   = STATUS_MORE_ENTRIES;   // ov.Internal 
                break;
        
            default:
                TRACE(TL_FCP_ERROR,("pCmdEntry%x; State:%d; pAvcIrb:%x; RespCode:%x\n", pCmdEntry, pCmdEntry->cmdState, pAvcIrb, pAvcIrb->ResponseCode));
                ASSERT(FALSE && "Undefined cmdState");
                pCmdEntry->cmdState = CMD_STATE_UNDEFINED;
                pCmdEntry->Status   = STATUS_NOT_SUPPORTED;   // ov.Internal 
                break;
            }

#if DBG
            if(pCmdEntry->cmdState != CMD_STATE_UNDEFINED) {
                TRACE(TL_FCP_WARNING,("<<<< AVCResp: pCmdEntry:%x; pAvcIrb:%x, cmdSt:%d; St:%x; %d:[%.2x %.2x %.2x %.2x]:[%.2x %.2x %.2x %.2x]\n",                  
                    pCmdEntry, pCmdEntry->pAvcIrb,
                    pCmdEntry->cmdState,
                    pCmdEntry->Status,
                    pAvcIrb->OperandLength+3,  // Resp+SuID+OpCd+Opr[]
                    pAvcIrb->ResponseCode,
                    pAvcIrb->SubunitAddr[0],
                    pAvcIrb->Opcode,
                    pAvcIrb->Operands[0],
                    pAvcIrb->Operands[1],
                    pAvcIrb->Operands[2],
                    pAvcIrb->Operands[3],
                    pAvcIrb->Operands[4]
                ));
            }
#endif
        } else {
            TRACE(TL_FCP_ERROR,("AVCCmdCR: pIrp->IoStatus.Status return error:%x\n", pIrp->IoStatus.Status));
            // Irp returns ERROR !!
            if (STATUS_BUS_RESET == pIrp->IoStatus.Status || STATUS_REQUEST_ABORTED == pIrp->IoStatus.Status) {
                TRACE(TL_FCP_ERROR,("Bus-Reset or abort (IoStatus.St:%x); pCmdEntry:%x; OpC:%x\n", pIrp->IoStatus.Status, pCmdEntry, pCmdEntry->OpCode));

                // Busreset while there is an interim pending, signal its client to wake up 
                // and get the "final" (busreset) result.
                if(pCmdEntry->cmdState == CMD_STATE_RESP_INTERIM) {
                    if(pCmdEntry->cmdType == AVC_CTYPE_CONTROL) {
                        TRACE(TL_FCP_TRACE,("--> BusRest: for control interim\n"));
                        bSignalInterimCotrolCompleted = TRUE;
                    } else if(pCmdEntry->cmdType == AVC_CTYPE_NOTIFY) {
                        TRACE(TL_FCP_TRACE,("--> BusRest: for notify interim\n"));
                        bSignalInterimNotifyCompleted = TRUE;                  
                    } else {
                        //
                        // Unexpected command state for a interim response
                        //
                        ASSERT(FALSE && "Unknow command state");
                    }
                }
            }
            else {
                TRACE(TL_FCP_ERROR,("IOCTL_AVC_CLASS Failed 0x%x\n", pIrp->IoStatus.Status));
            }

            pCmdEntry->cmdState = CMD_STATE_ABORTED;
            pCmdEntry->Status   = STATUS_REQUEST_ABORTED;  // -> ERROR_REQUERT_ABORT
        }

        //
        // If suceeded, translate the AVC response to COM property. if not 
        //    interim's final reponse.
        //    raw AVC command response
        //
        if(STATUS_SUCCESS == pCmdEntry->Status &&
           !bSignalInterimNotifyCompleted &&
           !bSignalInterimCotrolCompleted &&
           pCmdEntry->idxDVCRCmd != VCR_RAW_AVC
            )
            DVCRXlateRAwAVC(
                pCmdEntry, 
                pCmdEntry->pProperty
                );


        // Signal a KS event to inform its client that the final response 
        // has returned and come and get it.
        if(bSignalInterimNotifyCompleted) {
            pEvent = NULL;
            if(pEvent = StreamClassGetNextEvent((PVOID) pDevExt, 0, \
                (GUID *)&KSEVENTSETID_EXTDEV_Command, KSEVENT_EXTDEV_COMMAND_NOTIFY_INTERIM_READY, pEvent)) {            
                // Make sure the right event and then signal it
                if(pEvent->EventItem->EventId == KSEVENT_EXTDEV_COMMAND_NOTIFY_INTERIM_READY) {
                    StreamClassDeviceNotification(SignalDeviceEvent, pDevExt, pEvent);
                    TRACE(TL_FCP_TRACE,("->Signal NOTIFY_INTERIM ready; EventId %d.\n", pEvent->EventItem->EventId));
                }          
            }            
        } else if(bSignalInterimCotrolCompleted) {
            pEvent = NULL;
            if(pEvent = StreamClassGetNextEvent((PVOID) pDevExt, 0, \
                    (GUID *)&KSEVENTSETID_EXTDEV_Command, KSEVENT_EXTDEV_COMMAND_CONTROL_INTERIM_READY, pEvent)) {
                // Make sure the right event and then signal it
                if(pEvent->EventItem->EventId == KSEVENT_EXTDEV_COMMAND_CONTROL_INTERIM_READY) {
                    StreamClassDeviceNotification(SignalDeviceEvent, pDevExt, pEvent);
                    TRACE(TL_FCP_TRACE,("->Signal CONTROL_INTERIM ready; EventId %d.\n", pEvent->EventItem->EventId));
                }          
            }            
        }

        // Check that the command entry is ours only to process 
        // When a command is completed, it will be added to the list and therefore not empty.
        // It is designed to be added to the list in this completino routine.
        if (!IsListEmpty(&pCmdEntry->ListEntry)) {
            if(bSignalInterimNotifyCompleted || bSignalInterimCotrolCompleted) {
                // If final reponse is returned, we need to keep them in the list.
                TRACE(TL_FCP_TRACE,("Final response is completed; stay in the list\n"));
                KeReleaseSpinLock(&pDevExt->AVCCmdLock, oldIrql);
            }
            else {
                // This is a undefined path!!!
                // The command entry can only be in the list if it is interim of anykind.
                // If it is an interim, it will not be removed in the completion routine.
                ASSERT(FALSE && "Cannot complete an interim in CR\n");
            }
        }
        else {
            // This means that we have completed, but the code that issued the
            // command is still executing, and hasn't had a chance to look at
            // the results yet. Put this in the command list as a signal that
            // we have completed and updated the command state, but are not
            // planning to free the command resources.
            InsertTailList(&pDevExt->AVCCmdList, &pCmdEntry->ListEntry); pDevExt->cntCommandQueued++;
            TRACE(TL_FCP_TRACE,("Command completed and Queued(%d); pCmdEntry:%x.\n", pDevExt->cntCommandQueued, pCmdEntry));
            KeReleaseSpinLock(&pDevExt->AVCCmdLock, oldIrql);    
        }
    }
    else {
        TRACE(TL_FCP_WARNING,("IssueAVCCommandCR: pCmdEntry:%x; pIrp:%x cancelled\n", pCmdEntry, pIrp));
    }

    IoFreeIrp(pIrp);

    return STATUS_MORE_PROCESSING_REQUIRED;
} // DVIssueAVCCommandCR

NTSTATUS  
DVIssueAVCCommand (
    IN PDVCR_EXTENSION pDevExt, 
    IN AvcCommandType cType,
    IN DVCR_AVC_COMMAND idxAVCCmd,
    IN PVOID pProperty
    )
/*++

Routine Description:

    Issue a FCP/AVC command.

Arguments:
    

Return Value:

    NTSTATUS

--*/
{
    NTSTATUS      Status; 
    PAVCCmdEntry pCmdEntry;
    PAVC_COMMAND_IRB  pAvcIrb; 
    PIRP pIrp;
    PIO_STACK_LOCATION NextIrpStack;
#if DBG
    ULONGLONG tmStart;
    DWORD dwElapsed;
#endif
    PAGED_CODE();   
 

    if(pDevExt->bDevRemoved)
        return STATUS_DEVICE_NOT_CONNECTED;

    //
    // Validate Command type; the command type that each entry of the command table support.
    //
    switch(cType) {
    case AVC_CTYPE_CONTROL:
        if((DVcrAVCCmdTable[idxAVCCmd].ulCmdSupported & CMD_CONTROL) != CMD_CONTROL)
           return STATUS_NOT_SUPPORTED;
        break;
    case AVC_CTYPE_STATUS:
        if((DVcrAVCCmdTable[idxAVCCmd].ulCmdSupported & CMD_STATUS) != CMD_STATUS)
           return STATUS_NOT_SUPPORTED;
        break;
    case AVC_CTYPE_SPEC_INQ:
        if((DVcrAVCCmdTable[idxAVCCmd].ulCmdSupported & CMD_SPEC_INQ) != CMD_SPEC_INQ) 
           return STATUS_NOT_SUPPORTED;
        break;
    case AVC_CTYPE_GEN_INQ:
        if((DVcrAVCCmdTable[idxAVCCmd].ulCmdSupported & CMD_GEN_INQ) != CMD_GEN_INQ)
           return STATUS_NOT_SUPPORTED;
        break;
    case AVC_CTYPE_NOTIFY:
        if((DVcrAVCCmdTable[idxAVCCmd].ulCmdSupported & CMD_NOTIFY) != CMD_NOTIFY)
           return STATUS_NOT_SUPPORTED;
        break;
    default:
        TRACE(TL_FCP_ERROR,("IssueAVCCommand: idx %d, ctype (%02x) not supported; (%02x %02x %02x) %d:[%.8x]\n",
            idxAVCCmd,
            cType,
            DVcrAVCCmdTable[idxAVCCmd].CType,
            DVcrAVCCmdTable[idxAVCCmd].SubunitAddr,
            DVcrAVCCmdTable[idxAVCCmd].Opcode,
            DVcrAVCCmdTable[idxAVCCmd].OperandLength,
            (DWORD) *(&DVcrAVCCmdTable[idxAVCCmd].Operands[0])
            ));
        return STATUS_NOT_SUPPORTED;
    }

    // Create an AVC IRB and initialize it -
    pAvcIrb = ExAllocatePool(NonPagedPool, sizeof(AVC_COMMAND_IRB));
    if(!pAvcIrb) {
        TRACE(TL_FCP_ERROR,("IssueAVCCommand: Allocate Irb (%d bytes) failed\n", sizeof(AVC_COMMAND_IRB)));
        return STATUS_INSUFFICIENT_RESOURCES;
    }

    RtlZeroMemory(pAvcIrb, sizeof(AVC_COMMAND_IRB));
    pAvcIrb->Function = AVC_FUNCTION_COMMAND;

    // - set the AVC command type (Control, Status, Notify, General Inquiry, Specific Inquiry)
    pAvcIrb->CommandType = cType;

    // - override the subunit address in the avc unit driver (if it even has one for us)
    pAvcIrb->SubunitAddrFlag = 1;
    pAvcIrb->SubunitAddr = &DVcrAVCCmdTable[idxAVCCmd].SubunitAddr;
    pAvcIrb->Opcode = DVcrAVCCmdTable[idxAVCCmd].Opcode;

    // - include alternate opcodes for the transport state opcode
    if (pAvcIrb->Opcode == OPC_TRANSPORT_STATE) {
        pAvcIrb->AlternateOpcodesFlag = 1;
        pAvcIrb->AlternateOpcodes = pDevExt->TransportModes;
    }

    // - set up the operand list
    pAvcIrb->OperandLength = DVcrAVCCmdTable[idxAVCCmd].OperandLength;
    ASSERT(pAvcIrb->OperandLength <= MAX_AVC_OPERAND_BYTES);
    RtlCopyMemory(pAvcIrb->Operands, DVcrAVCCmdTable[idxAVCCmd].Operands, pAvcIrb->OperandLength);

    // Create an Irp and initialize it
    pIrp = IoAllocateIrp(pDevExt->pBusDeviceObject->StackSize, FALSE);
    if(!pIrp) {
        TRACE(TL_FCP_ERROR,("IssueAVCCommand: Allocate Irb (%d bytes) failed\n", sizeof(AVC_COMMAND_IRB)));
        ExFreePool(pAvcIrb);
        return STATUS_INSUFFICIENT_RESOURCES;
    }

    // Create an AVC Command entry and initialize it
    pCmdEntry = (AVCCmdEntry *) ExAllocatePool(NonPagedPool, sizeof(AVCCmdEntry));
    if(!pCmdEntry) {
        TRACE(TL_FCP_ERROR,("IssueAVCCommand: Allocate CmdEntry (%d bytes) failed\n", sizeof(AVCCmdEntry)));
        ExFreePool(pAvcIrb);
        IoFreeIrp(pIrp);
        return STATUS_INSUFFICIENT_RESOURCES;
    }

    RtlZeroMemory(pCmdEntry, sizeof(AVCCmdEntry));
    pCmdEntry->pDevExt      = pDevExt;  // So we can access pDevExt->AVCCmdList;
    pCmdEntry->pProperty    = pProperty;
    pCmdEntry->cmdState     = CMD_STATE_ISSUED;
    pCmdEntry->Status       = STATUS_UNSUCCESSFUL;
    pCmdEntry->cmdType      = cType;
    pCmdEntry->OpCode       = DVcrAVCCmdTable[idxAVCCmd].Opcode;
    pCmdEntry->idxDVCRCmd   = idxAVCCmd;
    pCmdEntry->pAvcIrb      = pAvcIrb;
    pCmdEntry->pIrp         = pIrp;
    InitializeListHead(&pCmdEntry->ListEntry);  // used as a flag for ownership

    TRACE(TL_FCP_WARNING,(">>>> AVCCmd: %d:[%.2x %.2x %.2x %.2x]:[%.2x %.2x %.2x %.2x]\n",                  
        pAvcIrb->OperandLength+3,  // Resp+SuID+OpCd+Opr[]
        cType,
        pAvcIrb->SubunitAddr[0],
        pAvcIrb->Opcode,
        pAvcIrb->Operands[0],
        pAvcIrb->Operands[1],
        pAvcIrb->Operands[2],
        pAvcIrb->Operands[3],
        pAvcIrb->Operands[4]
        ));

    // Finish initializing the Irp
    NextIrpStack = IoGetNextIrpStackLocation(pIrp);
    NextIrpStack->MajorFunction = IRP_MJ_INTERNAL_DEVICE_CONTROL;
    NextIrpStack->Parameters.DeviceIoControl.IoControlCode = IOCTL_AVC_CLASS;
    NextIrpStack->Parameters.Others.Argument1 = pAvcIrb;

    IoSetCompletionRoutine(pIrp, DVIssueAVCCommandCR, pCmdEntry, TRUE, TRUE, TRUE);

    pIrp->IoStatus.Status = STATUS_NOT_SUPPORTED;

#if DBG
    tmStart = GetSystemTime();
#endif

    // Now make the call
    // If encounter an interim response, STATUS_PENDING will be returned.    
    Status = 
        IoCallDriver(
            pDevExt->pBusDeviceObject, 
            pIrp
            );

#if DBG
#define MAX_RESPONSE_TIME_FOR_ALERT  500 // msec
    dwElapsed = (DWORD) ((GetSystemTime() - tmStart)/10000); // Convert 100nsec unit to msec
    if(dwElapsed > MAX_RESPONSE_TIME_FOR_ALERT) {    
        TRACE(TL_FCP_ERROR,("ST:%x; AVC Cmd took %d msec to response; CmdType:%d; OpCd:%x\n", Status, dwElapsed, cType, DVcrAVCCmdTable[idxAVCCmd].Opcode));
        ASSERT(dwElapsed < MAX_RESPONSE_TIME_FOR_ALERT * 8 && "Exceeded max response time!");  // It should be 100, but let's detect the really slow one.
    }
#endif
   

    // Interim response...
    if (STATUS_PENDING == Status) {
        
        KIRQL OldIrql;

#if 1   // WORKITEM: control command can be in interim for a while!!!
        // Some DV will return interim but it will completed it with a change quickly.
        if(cType == AVC_CTYPE_CONTROL) {
#define MSDV_WAIT_CONTROL_CMD_INTERIM   300
            TRACE(TL_FCP_WARNING,("!!!!!!!!!!!  Control Interim-- Wait %d msec !!!!!!!!\n", MSDV_WAIT_CONTROL_CMD_INTERIM));
            DVDelayExecutionThread(MSDV_WAIT_CONTROL_CMD_INTERIM);
            ASSERT(!IsListEmpty(&pCmdEntry->ListEntry) && "Control Cmd was interim after wait.");
        }
#endif

        KeAcquireSpinLock(&pDevExt->AVCCmdLock, &OldIrql);

        // Check that the Irp didn't complete between the return of IoCallDriver and now
        if (IsListEmpty(&pCmdEntry->ListEntry)) {
            // Enter INTERIM state
            pCmdEntry->cmdState = CMD_STATE_RESP_INTERIM;
            // Return STATUS_MORE_ENTRIES to inform caller that the command is pending.
            pCmdEntry->Status   = STATUS_MORE_ENTRIES;   // xlate to ERROR_MORE_DATA; No yet done with this command so keep the entry in the list

            // We have submitted a control or notify command, and have gotten
            // an Interim response. Put the command in the list so it can be
            // tracked for possible cancellation, and as an indication to the
            // completion routine that we won't be releasing any resources here.
            InsertTailList(&pDevExt->AVCCmdList, &pCmdEntry->ListEntry); pDevExt->cntCommandQueued++;
            pCmdEntry->pProperty = NULL;    // won't be using this, so get rid of it
            TRACE(TL_FCP_TRACE,("->AVC command Irp is pending!\n"));
            KeReleaseSpinLock(&pDevExt->AVCCmdLock, OldIrql);
            return pCmdEntry->Status;

        } else {
            // Although IoCallDriver indicated that the command was pending,
            // it has since been completed. The completion routine saw that
            // the command entry had not yet been added to the command list,
            // so put it there to let us know that we need to retain control
            // and free the resources.
            //
            // Temporarily change the status so the cleanup code path will
            // be followed.
            TRACE(TL_FCP_TRACE,("-> Cmd Rtns Pending but completed; treat as non-pending! ST:%x\n", pCmdEntry->Status));
            Status = STATUS_SUCCESS;
        }

        KeReleaseSpinLock(&pDevExt->AVCCmdLock, OldIrql);
    } 

    // Status from IoCallDriver can return:
    //    STATUS_PENDING (process above)  // If control, we wait and see if it get completed (risky!!)
    //    STATUS_TIMEOUT 
    //    STATUS_SUCCESS

    if(STATUS_PENDING != Status) {
        // The completion routine is usually the only one that frees the Irp. Is
        // it possible that the completion routine never got called? This will let
        // us know, since the completion routine will always make sure that the
        // command entry's Irp pointer is cleared.
        if(pCmdEntry->pIrp) {
            // If for some reason the completion routine never got called, free the Irp
            if(pCmdEntry->pIrp)
                IoFreeIrp(pCmdEntry->pIrp);
            pCmdEntry->pIrp = NULL;
        }
    }

    //
    // pCmdEntry->Status is the command response Status set in the completion routine, which can be
    //    STATUS_SUCCESS
    //    STATUS_REQ_NOT_ACCEP
    //    STATUS_NOT_SUPPORTED
    //    STATUS_MORE_ENTRIES    // Should not happen!!
    //    STATUS_REQUEST_ABORTED
    //

    // One possible valid command from IoCallDriver is STATUS_TIMEOUT, and
    // this shoull be returned, anything else we will get the status from pCmdEntry->Status
    // which was set in the completion routine.
    if (Status != STATUS_TIMEOUT) 
        Status = pCmdEntry->Status;  // This Status is being returned from this functino

    // Desiding if leaving the command response (entry) in the command list
    // Not if it is an (1) interim (all STATUS_MORE_ENTRIES); or (2) any RAW AVC response regardless of its status.
    if(STATUS_MORE_ENTRIES == Status ||
       VCR_RAW_AVC == pCmdEntry->idxDVCRCmd) {
        TRACE(TL_FCP_TRACE,("Status:%x; Do not remove (1) interim response or (2) a raw AVC response\n", Status));
    } 
    // Else we are done!
    else {
        KIRQL OldIrql;
        // It's time to clean up the command
        KeAcquireSpinLock(&pDevExt->AVCCmdLock, &OldIrql);
        if (!IsListEmpty(&pCmdEntry->ListEntry)) {
            RemoveEntryList(&pCmdEntry->ListEntry); pDevExt->cntCommandQueued--;
            InitializeListHead(&pCmdEntry->ListEntry);  // used as a flag for ownership
        }
        KeReleaseSpinLock(&pDevExt->AVCCmdLock, OldIrql);

        // Free the resources
        ExFreePool(pCmdEntry);
        ExFreePool(pAvcIrb);
    }  // else

    TRACE(TL_FCP_TRACE,("**** DVIssueAVCCmd (exit): St:%x; pCmdEntry:%x; cmdQueued:%d\n", Status, pCmdEntry, pDevExt->cntCommandQueued));                

    return Status;
}



#ifndef OATRUE
#define OATRUE (-1)
#endif
#ifndef OAFALSE
#define OAFALSE (0)
#endif

NTSTATUS 
DVGetExtDeviceProperty(
    IN PDVCR_EXTENSION pDevExt,
    IN PSTREAM_PROPERTY_DESCRIPTOR pSPD,
    OUT PULONG pulActualBytesTransferred
    )
/*++

Routine Description:

    Handle Get external device property.

Arguments:

    pDevExt - Device's extension
    pSPD - Stream property descriptor
    pulActualBytesTransferred - Number of byte transferred.

Return Value:

    NTSTATUS

--*/
{
    NTSTATUS Status = STATUS_SUCCESS;
    PKSPROPERTY_EXTDEVICE_S pExtDeviceProperty;
    DVCR_AVC_COMMAND idxDVCRCmd;
    AvcCommandType cType = AVC_CTYPE_STATUS;


    PAGED_CODE();

    ASSERT(pDevExt);    
    ASSERT(pSPD);
    ASSERT (pSPD->PropertyOutputSize >= sizeof (KSPROPERTY_EXTDEVICE_S)); 

    pExtDeviceProperty = (PKSPROPERTY_EXTDEVICE_S) pSPD->PropertyInfo;    // pointer to the data

  
    switch (pSPD->Property->Id) {

    case KSPROPERTY_EXTDEVICE_ID:
        if(pDevExt->ulVendorID) {
            // It was not bswap in the monolithic version so for competibility,
            // we will bswap this.
            pExtDeviceProperty->u.NodeUniqueID[0] = pDevExt->UniqueID.LowPart; 
            pExtDeviceProperty->u.NodeUniqueID[1] = pDevExt->UniqueID.HighPart;
            TRACE(TL_FCP_WARNING,("Low:%x; High:%x of UniqueID\n", pDevExt->UniqueID.LowPart, pDevExt->UniqueID.HighPart ));
            Status = STATUS_SUCCESS;
        } else {
            TRACE(TL_FCP_ERROR,("Failed: Vid:%x; Mid:%x\n", bswap(pDevExt->ulVendorID) >> 8, pDevExt->ulModelID ));
            Status = STATUS_UNSUCCESSFUL;
        }
        goto ExitGetDeviceProperty;                
        break;

    case KSPROPERTY_EXTDEVICE_VERSION:
        // AV/C VCR Subunit Specification 2.1.0 
        // Change from 2.0.1:
        //     Add Hi8 support
        wcscpy(pExtDeviceProperty->u.pawchString, L"2.1.0");  
        Status = STATUS_SUCCESS;
        goto ExitGetDeviceProperty;        
        break;

    case KSPROPERTY_EXTDEVICE_POWER_STATE:       
        idxDVCRCmd = DV_GET_POWER_STATE;
        break;       

    case KSPROPERTY_EXTDEVICE_PORT:
        pExtDeviceProperty->u.DevPort  = DEV_PORT_1394; 
        Status = STATUS_SUCCESS;        
        goto ExitGetDeviceProperty;                
        break;

    case KSPROPERTY_EXTDEVICE_CAPABILITIES:

        // Refresh mode of operation whenever capabilities is queried
        // since the mode of operation might have changed and is returned..
        DVGetDevModeOfOperation(pDevExt);

        // Can record only in VCR mode and has input plug(s).
        pExtDeviceProperty->u.Capabilities.CanRecord  = pDevExt->ulDevType == ED_DEVTYPE_VCR ? (pDevExt->pDevInPlugs->NumPlugs > 0 ? OATRUE : OAFALSE): OAFALSE;
        pExtDeviceProperty->u.Capabilities.CanRecordStrobe  = OAFALSE;        
        pExtDeviceProperty->u.Capabilities.HasAudio   = OATRUE;         
        pExtDeviceProperty->u.Capabilities.HasVideo   = OATRUE;        
        pExtDeviceProperty->u.Capabilities.UsesFiles  = OAFALSE;        
        pExtDeviceProperty->u.Capabilities.CanSave    = OAFALSE;
        pExtDeviceProperty->u.Capabilities.DeviceType = pDevExt->ulDevType;        
        pExtDeviceProperty->u.Capabilities.TCRead     = OATRUE;        
        pExtDeviceProperty->u.Capabilities.TCWrite    = OAFALSE; // DV decided        
        pExtDeviceProperty->u.Capabilities.CTLRead    = OAFALSE;  
        pExtDeviceProperty->u.Capabilities.IndexRead  = OAFALSE;        
        pExtDeviceProperty->u.Capabilities.Preroll    = 0L;      // NOT implemented, supposely can reg in INF and then read from registry       
        pExtDeviceProperty->u.Capabilities.Postroll   = 0L;      // NOT implemented, supposely can reg in INF and then read from registry 
        pExtDeviceProperty->u.Capabilities.SyncAcc    = ED_CAPABILITY_UNKNOWN;       
        pExtDeviceProperty->u.Capabilities.NormRate   = pDevExt->VideoFormatIndex == AVCSTRM_FORMAT_SDDV_NTSC ? ED_RATE_2997 : ED_RATE_25;
        pExtDeviceProperty->u.Capabilities.CanPreview = OAFALSE;    // View what is in the bus or tape
        pExtDeviceProperty->u.Capabilities.CanMonitorSrc = OATRUE;  // ViewFinder
        pExtDeviceProperty->u.Capabilities.CanTest    = OAFALSE;    // To see if a function is iplemented
        pExtDeviceProperty->u.Capabilities.VideoIn    = OAFALSE;  
        pExtDeviceProperty->u.Capabilities.AudioIn    = OAFALSE;  
        pExtDeviceProperty->u.Capabilities.Calibrate  = OAFALSE;  
        pExtDeviceProperty->u.Capabilities.SeekType   = ED_CAPABILITY_UNKNOWN;  

        TRACE(TL_FCP_TRACE,("GetExtDeviceProperty: DeviceType %x\n", pExtDeviceProperty->u.Capabilities.DeviceType));

        Status = STATUS_SUCCESS;               
        goto ExitGetDeviceProperty;        
        break;
       
    default:
        Status = STATUS_NOT_SUPPORTED;        
        goto ExitGetDeviceProperty;        
        break;
    }

    Status = DVIssueAVCCommand(pDevExt, cType, idxDVCRCmd, (PVOID) pExtDeviceProperty);
    TRACE(TL_FCP_TRACE,("GetExtDevice: idxDVCRCmd %d, cmdType %d, Status %x\n", idxDVCRCmd, cType, Status)); 

ExitGetDeviceProperty:

    *pulActualBytesTransferred = (Status == STATUS_SUCCESS ? sizeof (KSPROPERTY_EXTDEVICE_S) : 0);

    return Status;
}




NTSTATUS 
DVSetExtDeviceProperty(
    IN PDVCR_EXTENSION pDevExt,
    IN PSTREAM_PROPERTY_DESCRIPTOR pSPD,
    OUT ULONG *pulActualBytesTransferred
    )
/*++

Routine Description:

    Handle Set external device property.

Arguments:

    pDevExt - Device's extension
    pSPD - Stream property descriptor
    pulActualBytesTransferred - Number of byte transferred.

Return Value:

    NTSTATUS

--*/
{
    NTSTATUS Status = STATUS_SUCCESS;
    PKSPROPERTY_EXTDEVICE_S pExtDeviceProperty;
    DVCR_AVC_COMMAND idxDVCRCmd;
    AvcCommandType cType = AVC_CTYPE_CONTROL;



    PAGED_CODE();

    ASSERT(pDevExt);    
    ASSERT(pSPD);
    ASSERT (pSPD->PropertyOutputSize >= sizeof (KSPROPERTY_EXTDEVICE_S)); 

    pExtDeviceProperty = (PKSPROPERTY_EXTDEVICE_S) pSPD->PropertyInfo;    // pointer to the data

  
    switch (pSPD->Property->Id) {
    case KSPROPERTY_EXTDEVICE_POWER_STATE:
        switch(pExtDeviceProperty->u.PowerState) {
        case ED_POWER_ON:
            idxDVCRCmd = DV_SET_POWER_STATE_ON;
            break;
        case ED_POWER_STANDBY:
            Status = STATUS_NOT_SUPPORTED;  // AVC spec does not have a stanby power mode
            goto ExitSetDeviceProperty;
            break;
        case ED_POWER_OFF:
            idxDVCRCmd = DV_SET_POWER_STATE_OFF;
            break;
        default:
            Status = STATUS_INVALID_PARAMETER;
            goto ExitSetDeviceProperty;
        }
        break;  
    default:   
        Status = STATUS_NOT_SUPPORTED;                ;
        goto ExitSetDeviceProperty;
    }

    Status = DVIssueAVCCommand(pDevExt, cType, idxDVCRCmd, (PVOID) pExtDeviceProperty);
    TRACE(TL_FCP_TRACE,("SetExtDevice: idxDVCRCmd %d, cmdType %d, Status %x\n", idxDVCRCmd, cType, Status)); 

ExitSetDeviceProperty:

    *pulActualBytesTransferred = (Status == STATUS_SUCCESS ? sizeof (KSPROPERTY_EXTDEVICE_S) : 0);
 
    return Status;
}

NTSTATUS 
DVGetExtTransportProperty(    
    IN PDVCR_EXTENSION pDevExt,
    IN PSTREAM_PROPERTY_DESCRIPTOR pSPD,
    OUT ULONG *pulActualBytesTransferred
    )
/*++

Routine Description:

    Handle Get external transport property.

Arguments:

    pDevExt - Device's extension
    pSPD - Stream property descriptor
    pulActualBytesTransferred - Number of byte transferred.

Return Value:

    NTSTATUS 

--*/
{
    NTSTATUS Status = STATUS_NOT_SUPPORTED;
    PKSPROPERTY_EXTXPORT_S pXPrtProperty;
    DVCR_AVC_COMMAND idxDVCRCmd;
    AvcCommandType cType = AVC_CTYPE_STATUS;
    BOOL bHasTape = pDevExt->bHasTape;

    PAVCCmdEntry  pCmdEntry;


    PAGED_CODE();

    ASSERT(pDevExt);    
    ASSERT(pSPD);
    ASSERT (pSPD->PropertyOutputSize >= sizeof (KSPROPERTY_EXTXPORT_S)); 

    pXPrtProperty = (PKSPROPERTY_EXTXPORT_S) pSPD->PropertyInfo;    // pointer to the data
    *pulActualBytesTransferred = 0;


    switch (pSPD->Property->Id) {
    case KSPROPERTY_EXTXPORT_CAPABILITIES:
        return STATUS_NOT_IMPLEMENTED;

    case KSPROPERTY_RAW_AVC_CMD:
        pCmdEntry = DVCRFindCmdEntryCompleted( 
            pDevExt, 
            VCR_RAW_AVC,
            DVcrAVCCmdTable[VCR_RAW_AVC].Opcode,
            DVcrAVCCmdTable[VCR_RAW_AVC].CType
            );

        if(pCmdEntry) {
            PAVC_COMMAND_IRB pAvcIrb;

            pAvcIrb = pCmdEntry->pAvcIrb;
            ASSERT(pAvcIrb);

            if (pCmdEntry->cmdState == CMD_STATE_RESP_ACCEPTED ||
                pCmdEntry->cmdState == CMD_STATE_RESP_REJECTED ||
                pCmdEntry->cmdState == CMD_STATE_RESP_NOT_IMPL ||
                pCmdEntry->cmdState == CMD_STATE_RESP_INTERIM
                ) {
                // bytes for operands plus response, subunit addr, and opcode
                pXPrtProperty->u.RawAVC.PayloadSize = pAvcIrb->OperandLength + 3;
                pXPrtProperty->u.RawAVC.Payload[0] = pAvcIrb->ResponseCode;
                pXPrtProperty->u.RawAVC.Payload[1] = pAvcIrb->SubunitAddr[0];
                pXPrtProperty->u.RawAVC.Payload[2] = pAvcIrb->Opcode;                
                RtlCopyMemory(&pXPrtProperty->u.RawAVC.Payload[3], pAvcIrb->Operands, pAvcIrb->OperandLength);

                TRACE(TL_FCP_WARNING,("RawAVCResp: pEntry:%x; State:%x; Status:%x; Sz:%d; Rsp:%x;SuId:%x;OpCd:%x; Opr:[%x %x %x %x]\n",
                    pCmdEntry, pCmdEntry->cmdState, pCmdEntry->Status,
                    pXPrtProperty->u.RawAVC.PayloadSize,
                    pXPrtProperty->u.RawAVC.Payload[0],
                    pXPrtProperty->u.RawAVC.Payload[1],
                    pXPrtProperty->u.RawAVC.Payload[2],
                    pXPrtProperty->u.RawAVC.Payload[3],
                    pXPrtProperty->u.RawAVC.Payload[4],
                    pXPrtProperty->u.RawAVC.Payload[5],
                    pXPrtProperty->u.RawAVC.Payload[6]
                    )); 

                // If not success, bytes transferred and data will not returned!
                Status = STATUS_SUCCESS;  

                *pulActualBytesTransferred = sizeof (KSPROPERTY_EXTXPORT_S);
            } else {
                TRACE(TL_FCP_ERROR,("RawAVCResp: Found; but pCmdEntry:%x, unexpected cmdState:%d; ST:%x\n", pCmdEntry, pCmdEntry->cmdState, pCmdEntry->Status));
                ASSERT(pCmdEntry->cmdState == CMD_STATE_RESP_ACCEPTED && "Unexpected command state\n");
                Status = STATUS_REQUEST_ABORTED;
                *pulActualBytesTransferred = 0;
            }

            // pIrp is NULL if it has been completed.
            if(pCmdEntry->pIrp) {
                TRACE(TL_FCP_ERROR,("RawAVCResp: pCmdEntry %x; ->pIrp:%x not completd yet!\n", pCmdEntry, pCmdEntry->pIrp));
                ASSERT(pCmdEntry->pIrp == NULL && "pIrp is not completed!");
                IoCancelIrp(pCmdEntry->pIrp);
            }
            // Not used in the completion routine if pIrp->Cancel
            ExFreePool(pCmdEntry);
            ExFreePool(pAvcIrb);
        }
        else {
            TRACE(TL_FCP_ERROR,("KSPROPERTY_RAW_AVC_CMD, did not find a match[%x]!\n", 
                *((DWORD *) &DVcrAVCCmdTable[VCR_RAW_AVC].CType) )); 
            *pulActualBytesTransferred = 0;
            Status = STATUS_NOT_FOUND;  // ERROR_MR_MID_NOT_FOUND
        }
        return Status;

    case KSPROPERTY_EXTXPORT_INPUT_SIGNAL_MODE: // MPEG, D-VHS, Analog VHS etc.
        idxDVCRCmd = VCR_INPUT_SIGNAL_MODE;
        break;
    case KSPROPERTY_EXTXPORT_OUTPUT_SIGNAL_MODE: // MPEG, D-VHS, Analog VHS etc.
        idxDVCRCmd = VCR_OUTPUT_SIGNAL_MODE;
        break;
    case KSPROPERTY_EXTXPORT_MEDIUM_INFO:       // cassettte_type and tape_grade_and_write_protect
        idxDVCRCmd = VCR_MEDIUM_INFO;
        break;  
    case KSPROPERTY_EXTXPORT_STATE: 
        idxDVCRCmd = VCR_TRANSPORT_STATE;        
        break; 

    case KSPROPERTY_EXTXPORT_STATE_NOTIFY: 
        // Get final result from previous set command
        pCmdEntry = DVCRFindCmdEntryCompleted( 
            pDevExt, 
            VCR_TRANSPORT_STATE_NOTIFY,
            DVcrAVCCmdTable[VCR_TRANSPORT_STATE_NOTIFY].Opcode,
            DVcrAVCCmdTable[VCR_TRANSPORT_STATE_NOTIFY].CType
            );

        if(pCmdEntry) {
            PAVC_COMMAND_IRB pAvcIrb;

            pAvcIrb = pCmdEntry->pAvcIrb;
            ASSERT(pCmdEntry->pAvcIrb);

            TRACE(TL_FCP_WARNING,("->Notify Resp: pCmdEntry:%x; pIrb:%x; %d:[%.2x %.2x %.2x %.2x]\n",
                pCmdEntry, pAvcIrb,
                pAvcIrb->OperandLength + 3,
                pAvcIrb->ResponseCode,
                pAvcIrb->SubunitAddr[0],
                pAvcIrb->Opcode,
                pAvcIrb->Operands[0]
                )); 

            if(pCmdEntry->cmdState == CMD_STATE_RESP_ACCEPTED)
                Status = 
                    DVCRXlateRAwAVC(
                        pCmdEntry, 
                        pXPrtProperty
                        );

            // pIrp is NULL if it has been completed.
            if(pCmdEntry->pIrp) {
                TRACE(TL_FCP_ERROR,("XPrtNotifyResp: pCmdEntry %x; ->pIrp:%x not completed; IoCancelIrp(pIrp)\n", pCmdEntry, pCmdEntry->pIrp));
                IoCancelIrp(pCmdEntry->pIrp);
            }
            // These two are not touched in the CompletionRoutine if pIrp->Cancel
            ExFreePool(pCmdEntry);
            ExFreePool(pAvcIrb);

            *pulActualBytesTransferred = STATUS_SUCCESS == Status ? sizeof (KSPROPERTY_EXTXPORT_S) : 0;
        }
        else {
            TRACE(TL_FCP_ERROR,("EXTXPORT_STATE_NOTIFY: no match!\n"));
            *pulActualBytesTransferred = 0;
            Status = STATUS_NOT_FOUND;  // ERROR_MR_MID_NOT_FOUND
        }
        return Status;

    default:
        TRACE(TL_FCP_ERROR,("GetExtTransportProperty: NOT_IMPLEMENTED Property->Id %d\n", pSPD->Property->Id));        
        return STATUS_NOT_SUPPORTED;                
    }


    Status = DVIssueAVCCommand(pDevExt, cType, idxDVCRCmd, (PVOID) pXPrtProperty);
    TRACE(TL_FCP_TRACE,("GetExtTransportProperty: idxDVCRCmd %d, cmdType %d, Status %x\n", idxDVCRCmd, cType, Status)); 
    *pulActualBytesTransferred = (Status == STATUS_SUCCESS ? sizeof (KSPROPERTY_EXTXPORT_S) : 0);


    if(STATUS_SUCCESS == Status &&
       idxDVCRCmd == VCR_MEDIUM_INFO) {

        // Update Media info
        pDevExt->bHasTape        = pXPrtProperty->u.MediumInfo.MediaPresent;
        pDevExt->bWriteProtected = pXPrtProperty->u.MediumInfo.RecordInhibit;

        TRACE(TL_FCP_TRACE,("bHasTape: IN(%d):OUT(%d), ulDevType %d\n", bHasTape, pDevExt->bHasTape, pDevExt->ulDevType));        
    }
 
    return Status;
}




NTSTATUS 
DVSetExtTransportProperty( 
    IN PDVCR_EXTENSION pDevExt,
    IN PSTREAM_PROPERTY_DESCRIPTOR pSPD,
    OUT ULONG *pulActualBytesTransferred
    )
/*++

Routine Description:

    Handle Set external transport property.

Arguments:

    pDevExt - Device's extension
    pSPD - Stream property descriptor
    pulActualBytesTransferred - Number of byte transferr

Return Value:

    NTSTATUS

--*/
{
    NTSTATUS Status = STATUS_SUCCESS;
    PKSPROPERTY_EXTXPORT_S pXPrtProperty;
    DVCR_AVC_COMMAND idxDVCRCmd;
    AvcCommandType cType = AVC_CTYPE_CONTROL;


    PAGED_CODE();

    ASSERT(pDevExt);    
    ASSERT(pSPD);
    ASSERT (pSPD->PropertyOutputSize >= sizeof (KSPROPERTY_EXTXPORT_S)); 

    pXPrtProperty = (PKSPROPERTY_EXTXPORT_S) pSPD->PropertyInfo;    // pointer to the data    
    *pulActualBytesTransferred = 0;

    switch (pSPD->Property->Id) {

    case KSPROPERTY_EXTXPORT_STATE: 
     
         switch (pXPrtProperty->u.XPrtState.Mode) {
// RECORD
         case ED_MODE_RECORD:
             idxDVCRCmd = VCR_RECORD;
             break;
         case ED_MODE_RECORD_FREEZE:
             idxDVCRCmd = VCR_RECORD_PAUSE;
             break;

// PLAY
         case ED_MODE_STEP_FWD:
             idxDVCRCmd = VCR_PLAY_FORWARD_STEP;
             break;
         case ED_MODE_PLAY_SLOWEST_FWD:
             // DVCPRO does not seem to support the standard play slow fwd so this is an alternate
             if(pDevExt->bDVCPro)
                 idxDVCRCmd = VCR_PLAY_FORWARD_SLOWEST2;
             else
                 idxDVCRCmd = VCR_PLAY_FORWARD_SLOWEST;
             break;
         case ED_MODE_PLAY_FASTEST_FWD:
             idxDVCRCmd = VCR_PLAY_FORWARD_FASTEST;
             break;

         case ED_MODE_STEP_REV:
             idxDVCRCmd = VCR_PLAY_REVERSE_STEP;
             break;
         case ED_MODE_PLAY_SLOWEST_REV:
             // DVCPRO does not seem to support the standard play slow rev so this is an alternate
             if(pDevExt->bDVCPro)
                 idxDVCRCmd = VCR_PLAY_REVERSE_SLOWEST2;
             else
                 idxDVCRCmd = VCR_PLAY_REVERSE_SLOWEST;
             break;
         case ED_MODE_PLAY_FASTEST_REV:
             idxDVCRCmd = VCR_PLAY_REVERSE_FASTEST;
             break;

         case ED_MODE_PLAY:
             idxDVCRCmd = VCR_PLAY_FORWARD;
             break;
         case ED_MODE_FREEZE:
             idxDVCRCmd = VCR_PLAY_FORWARD_PAUSE;
             break;


// WIND
         case ED_MODE_STOP:
             idxDVCRCmd = VCR_WIND_STOP;
             break;
         case ED_MODE_FF:
             idxDVCRCmd = VCR_WIND_FAST_FORWARD;
             break;
         case ED_MODE_REW:
             idxDVCRCmd = VCR_WIND_REWIND;
             break;


         default:
             TRACE(TL_FCP_ERROR,("SetExtTransportProperty: NOT_IMPLEMENTED XPrtState.Mode %d\n", pXPrtProperty->u.XPrtState.Mode));        
             return STATUS_NOT_SUPPORTED; 
         }
         break;

    case KSPROPERTY_EXTXPORT_STATE_NOTIFY: 
        idxDVCRCmd = VCR_TRANSPORT_STATE_NOTIFY;
        cType = AVC_CTYPE_NOTIFY;        
        TRACE(TL_FCP_TRACE,("->Notify XPrt State Cmd issued.\n"));
        break; 

    case KSPROPERTY_EXTXPORT_LOAD_MEDIUM:  
        idxDVCRCmd = VCR_LOAD_MEDIUM_EJECT;
        break;

    case KSPROPERTY_EXTXPORT_TIMECODE_SEARCH: 
        idxDVCRCmd = VCR_TIMECODE_SEARCH;
        TRACE(TL_FCP_ERROR,("SetExtTransportProperty: KSPROPERTY_EXTXPORT_TIMECODE_SEARCH NOT_SUPPORTED\n"));        
        *pulActualBytesTransferred = 0;
        return STATUS_NOT_SUPPORTED; 
        
    case KSPROPERTY_EXTXPORT_ATN_SEARCH: 
        idxDVCRCmd = VCR_ATN_SEARCH;
        TRACE(TL_FCP_ERROR,("SetExtTransportProperty: KSPROPERTY_EXTXPORT_ATN_SEARCH NOT_SUPPORTED\n"));        
        *pulActualBytesTransferred = 0;
        return STATUS_NOT_SUPPORTED; 
        
    case KSPROPERTY_EXTXPORT_RTC_SEARCH: 
        idxDVCRCmd = VCR_RTC_SEARCH;
        TRACE(TL_FCP_ERROR,("SetExtTransportProperty: KSPROPERTY_EXTXPORT_RTC_SEARCH NOT_SUPPORTED\n"));        
        *pulActualBytesTransferred = 0;
        return STATUS_NOT_SUPPORTED;         

    case KSPROPERTY_RAW_AVC_CMD:
        idxDVCRCmd = VCR_RAW_AVC;   
        if(pXPrtProperty->u.RawAVC.PayloadSize <= MAX_FCP_PAYLOAD_SIZE) { 

            DVcrAVCCmdTable[idxDVCRCmd].CType = pXPrtProperty->u.RawAVC.Payload[0];
            DVcrAVCCmdTable[idxDVCRCmd].SubunitAddr = pXPrtProperty->u.RawAVC.Payload[1];
            DVcrAVCCmdTable[idxDVCRCmd].Opcode = pXPrtProperty->u.RawAVC.Payload[2];
            DVcrAVCCmdTable[idxDVCRCmd].OperandLength = pXPrtProperty->u.RawAVC.PayloadSize - 3;
            RtlCopyMemory(DVcrAVCCmdTable[idxDVCRCmd].Operands, pXPrtProperty->u.RawAVC.Payload + 3, DVcrAVCCmdTable[idxDVCRCmd].OperandLength);

            // extract command type; for RAW AVC, it can be anything.
            cType = pXPrtProperty->u.RawAVC.Payload[0];

            TRACE(TL_FCP_WARNING,("RawAVC cmd: cType %x, PayLoadSize %d, PayLoad %x %x %x %x\n",
                cType,
                pXPrtProperty->u.RawAVC.PayloadSize,
                pXPrtProperty->u.RawAVC.Payload[0],
                pXPrtProperty->u.RawAVC.Payload[1],
                pXPrtProperty->u.RawAVC.Payload[2],
                pXPrtProperty->u.RawAVC.Payload[3]
                )); 

        } else {
            Status = STATUS_INVALID_PARAMETER;
            *pulActualBytesTransferred = 0;
            return Status;
        }
        break;

    default:
        TRACE(TL_FCP_ERROR,("SetExtTransportProperty: NOT_IMPLEMENTED Property->Id %d\n", pSPD->Property->Id));        
        return STATUS_NOT_SUPPORTED; 
    }

    Status = DVIssueAVCCommand(pDevExt, cType, idxDVCRCmd, (PVOID) pXPrtProperty);

    TRACE(TL_FCP_TRACE,("SetExtTransportProperty: idxDVCRCmd %d, Status %x\n", idxDVCRCmd, Status));
    *pulActualBytesTransferred = (Status == STATUS_SUCCESS ? sizeof (PKSPROPERTY_EXTXPORT_S) : 0);

    return Status;
}

NTSTATUS 
DVGetTimecodeReaderProperty(
    IN PDVCR_EXTENSION pDevExt,
    IN PSTREAM_PROPERTY_DESCRIPTOR pSPD,
    OUT PULONG pulActualBytesTransferred
    )
/*++

Routine Description:

Arguments:

Return Value:

    NTSTATUS

--*/
{
    NTSTATUS Status = STATUS_SUCCESS;
    PKSPROPERTY_TIMECODE_S pTmCdReaderProperty;
    DVCR_AVC_COMMAND idxDVCRCmd;


    PAGED_CODE();

    ASSERT (pSPD->PropertyOutputSize >= sizeof (KSPROPERTY_TIMECODE_S)); 

    pTmCdReaderProperty = (PKSPROPERTY_TIMECODE_S) pSPD->PropertyInfo;    // pointer to the data
    *pulActualBytesTransferred = 0;
  
    switch (pSPD->Property->Id) {

    case KSPROPERTY_TIMECODE_READER:
        idxDVCRCmd = VCR_TIMECODE_READ;
#ifdef MSDV_SUPPORT_EXTRACT_SUBCODE_DATA
        // There can only be one active stream.
        if(pDevExt->cndStrmOpen == 1 &&            
           pDevExt->paStrmExt[pDevExt->idxStreamNumber]->StreamState == KSSTATE_RUN) {

            if(pDevExt->paStrmExt[pDevExt->idxStreamNumber]->bTimecodeUpdated) {
                // Once it is read, it is stale.
                pDevExt->paStrmExt[pDevExt->idxStreamNumber]->bTimecodeUpdated = FALSE;

                pTmCdReaderProperty->TimecodeSamp.timecode.dwFrames = 
                    (((DWORD) pDevExt->paStrmExt[pDevExt->idxStreamNumber]->Timecode[0]) << 24) |
                    (((DWORD) pDevExt->paStrmExt[pDevExt->idxStreamNumber]->Timecode[1]) << 16) |
                    (((DWORD) pDevExt->paStrmExt[pDevExt->idxStreamNumber]->Timecode[2]) <<  8) |
                     ((DWORD) pDevExt->paStrmExt[pDevExt->idxStreamNumber]->Timecode[3]);

                *pulActualBytesTransferred = (Status == STATUS_SUCCESS ? sizeof (KSPROPERTY_TIMECODE_S) : 0);
                return STATUS_SUCCESS;
            }
            else {
                TRACE(TL_FCP_TRACE,("bTimecode stale, issue AVC command to read it.\n"));
            }
        }
#endif
        break;

    case KSPROPERTY_ATN_READER:
        idxDVCRCmd = VCR_ATN_READ;
#ifdef MSDV_SUPPORT_EXTRACT_SUBCODE_DATA

        // There can only be one active stream.
        if(pDevExt->cndStrmOpen == 1 && 
           pDevExt->paStrmExt[pDevExt->idxStreamNumber]->StreamState == KSSTATE_RUN) {

            if(pDevExt->paStrmExt[pDevExt->idxStreamNumber]->bATNUpdated) {
                // Once it is read, it is stale.
                pDevExt->paStrmExt[pDevExt->idxStreamNumber]->bATNUpdated = FALSE;

                pTmCdReaderProperty->TimecodeSamp.timecode.dwFrames = 
                    pDevExt->paStrmExt[pDevExt->idxStreamNumber]->AbsTrackNumber >> 1;
                pTmCdReaderProperty->TimecodeSamp.dwUser = 
                    pDevExt->paStrmExt[pDevExt->idxStreamNumber]->AbsTrackNumber & 0x00000001;

                *pulActualBytesTransferred = (Status == STATUS_SUCCESS ? sizeof (KSPROPERTY_TIMECODE_S) : 0);            
                return STATUS_SUCCESS;
            }
            else {
                TRACE(TL_FCP_WARNING,("bATN stale, issue AVC command to read it.\n"));
            }
        }
#endif
        break;

    case KSPROPERTY_RTC_READER:
        idxDVCRCmd = VCR_RTC_READ;
        break;

    default:
        TRACE(TL_FCP_ERROR,("GetTimecodeReaderProperty: NOT_IMPLEMENTED Property->Id %d\n", pSPD->Property->Id));        
        return STATUS_NOT_SUPPORTED; 
    }

    Status = 
        DVIssueAVCCommand(
            pDevExt, 
            AVC_CTYPE_STATUS, 
            idxDVCRCmd, 
            (PVOID) pTmCdReaderProperty
            );  

    TRACE(TL_FCP_TRACE,("GetTimecodeReaderProperty: idxDVCRCmd %d, Status %x\n", idxDVCRCmd, Status));     

    *pulActualBytesTransferred = (Status == STATUS_SUCCESS ? sizeof (KSPROPERTY_TIMECODE_S) : 0);
 
    return Status;
}

NTSTATUS 
DVMediaSeekingProperty(
    IN PDVCR_EXTENSION pDevExt,
    IN PSTREAM_PROPERTY_DESCRIPTOR pSPD,
    OUT PULONG pulActualBytesTransferred
    )
/*++

Routine Description:

Arguments:

Return Value:

    NTSTATUS

--*/
{
    NTSTATUS Status = STATUS_SUCCESS;
    GUID * pTimeFormatGuid;
    KSMULTIPLE_ITEM * pMultipleItem;

    PAGED_CODE();


    *pulActualBytesTransferred = 0;
  
    switch (pSPD->Property->Id) {

    case KSPROPERTY_MEDIASEEKING_FORMATS:
        // Its is KSMULTIPLE_ITEM so it is a two step process to return the data:
        // (1) return size in pActualBytesTransferred with STATUS_BUFFER_OVERFLOW
        // (2) 2nd time to get its actual data.
        if(pSPD->PropertyOutputSize == 0) {
            *pulActualBytesTransferred = sizeof(KSMULTIPLE_ITEM) + sizeof(GUID);
            Status = STATUS_BUFFER_OVERFLOW;
        
        } else if(pSPD->PropertyOutputSize >= (sizeof(KSMULTIPLE_ITEM) + sizeof(GUID))) {
            pMultipleItem = (KSMULTIPLE_ITEM *) pSPD->PropertyInfo;    // pointer to the data
            pMultipleItem->Count = 1;
            pMultipleItem->Size  = sizeof(KSMULTIPLE_ITEM) + sizeof(GUID);
            pTimeFormatGuid = (GUID *) (pMultipleItem + 1);    // pointer to the data
            memcpy(pTimeFormatGuid, &KSTIME_FORMAT_MEDIA_TIME, sizeof(GUID));
            *pulActualBytesTransferred = sizeof(KSMULTIPLE_ITEM) + sizeof(GUID);
            Status = STATUS_SUCCESS;         

        } else {
            TRACE(TL_FCP_ERROR,("MediaSeekingProperty: KSPROPERTY_MEDIASEEKING_FORMAT; STATUS_INVALID_PARAMETER\n"));
            Status = STATUS_INVALID_PARAMETER;
        }  
        break;

    default:
        TRACE(TL_FCP_ERROR,("MediaSeekingProperty:Not supported ID %d\n", pSPD->Property->Id));
        return STATUS_NOT_SUPPORTED;         
    }

    return Status;
}



NTSTATUS
AVCTapeGetDeviceProperty(
    IN PDVCR_EXTENSION     pDevExt,
    IN PSTREAM_PROPERTY_DESCRIPTOR pSPD,
    IN PULONG pulActualBytesTransferred
    )
/*++

Routine Description:

    Handles Get operations for all adapter properties.

Arguments:   

Return Value:

    NTSTATUS

--*/
{
    NTSTATUS Status;

    PAGED_CODE();


    if (IsEqualGUID (&PROPSETID_EXT_DEVICE, &pSPD->Property->Set)) {
        Status = 
            DVGetExtDeviceProperty(              
                pDevExt,
                pSPD,
                pulActualBytesTransferred
                );
    } 
    else 
    if (IsEqualGUID (&PROPSETID_EXT_TRANSPORT, &pSPD->Property->Set)) {
        Status = 
            DVGetExtTransportProperty(
                pDevExt,
                pSPD,
                pulActualBytesTransferred
                );
    } 
    else 
    if (IsEqualGUID (&PROPSETID_TIMECODE_READER, &pSPD->Property->Set)) {
        Status = 
            DVGetTimecodeReaderProperty(
                pDevExt,
                pSPD,
                pulActualBytesTransferred
                );
    } 
    else 
    if (IsEqualGUID (&KSPROPSETID_MediaSeeking, &pSPD->Property->Set)) {

        Status = 
            DVMediaSeekingProperty(                
                pDevExt,
                pSPD, 
                pulActualBytesTransferred
                ); 
        
    } else {
        //
        // We should never get here
        //
        Status = STATUS_NOT_SUPPORTED;
        TRACE(TL_FCP_ERROR,("get unknown property\n"));
        ASSERT(FALSE);
    }

    return Status;
}



NTSTATUS
AVCTapeSetDeviceProperty(
    IN PDVCR_EXTENSION     pDevExt,  
    IN PSTREAM_PROPERTY_DESCRIPTOR pSPD,
    IN PULONG pulActualBytetransferred
    )
/*++

Routine Description:

    Handles Set operations for all adapter properties.

Arguments:

Return Value:

    NTSTATUS

--*/

{
    NTSTATUS Status;
    PAGED_CODE();


    if (IsEqualGUID (&PROPSETID_EXT_DEVICE, &pSPD->Property->Set)) {
        Status = 
            DVSetExtDeviceProperty(
                pDevExt,
                pSPD,
                pulActualBytetransferred
                );
    } 
    else 
    if (IsEqualGUID (&PROPSETID_EXT_TRANSPORT, &pSPD->Property->Set)) {
        Status = 
            DVSetExtTransportProperty(
                pDevExt,
                pSPD,
                pulActualBytetransferred
                );
    } 
    else {
        Status = STATUS_NOT_SUPPORTED;

        //
        // We should never get here
        //
        TRACE(TL_FCP_ERROR,("set unknown property\n"));
        ASSERT(FALSE);
    }

    return Status;
}
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\drivers\wdm\capture\mini\msdv\msdvlowr.c ===
/*++

Copyright (C) Microsoft Corporation, 1999 - 2000  

Module Name:

    MSDVLowr.c

Abstract:

    Interface code with 61883 or 1394 class driver.

Last changed by:
    
    Author:      Yee J. Wu

Environment:

    Kernel mode only

Revision History:

    $Revision::                    $
    $Date::                        $

--*/

#include "strmini.h"
#include "ksmedia.h"
#include "1394.h"
#include "61883.h"
#include "dbg.h"
#include "msdvfmt.h"
#include "msdvdef.h"
#include "MSDVUtil.h"
#include "MSDVGuts.h"
#include "XPrtDefs.h"
#include "EDevCtrl.h"


extern DV_FORMAT_INFO  DVFormatInfoTable[];
extern const GUID KSEVENTSETID_Connection_Local;


//
// Simple function prototype
//
VOID
DVSRBRead(
    IN PKSSTREAM_HEADER pStrmHeader,
    IN ULONG            ulFrameSize,
    IN PDVCR_EXTENSION  pDevExt,
    IN PSTREAMEX        pStrmExt,
    IN PHW_STREAM_REQUEST_BLOCK pSrb        // needs Srb->Status 
    );
NTSTATUS
DVAttachWriteFrame(
    IN PSTREAMEX  pStrmExt
    );
VOID
DVFormatAttachFrame(
    IN KSPIN_DATAFLOW   DataFlow,
    IN PSTREAMEX        pStrmExt,    
    IN PAV_61883_REQUEST   pAVReq,
    IN PHW_STREAM_REQUEST_BLOCK       pSrb,
    IN PSRB_DATA_PACKET pSrbDataPacket,
    IN ULONG            ulSourceLength,    // Packet length in bytes
    IN ULONG            ulFrameSize,
    IN PVOID            pFrameBuffer
    );
VOID
DVAttachFrameThread(
    IN PSTREAMEX pStrmExt
    );
VOID
DVTerminateAttachFrameThread(
    IN PSTREAMEX  pStrmExt
    );

#if DBG
ULONG cntInvSrcPkt = 0;
#endif
#if 0  // Enable later
#ifdef ALLOC_PRAGMA   
     #pragma alloc_text(PAGE, DVSRBRead)
     #pragma alloc_text(PAGE, DVFormatAttachFrame)
     #pragma alloc_text(PAGE, DVAttachFrameThread)
     #pragma alloc_text(PAGE, DVTerminateAttachFrameThread)
     #pragma alloc_text(PAGE, DVAttachWriteFrame)
     #pragma alloc_text(PAGE, DVFormatAttachFrame)
#endif
#endif

ULONG
DVReadFrameValidate(           
    IN PCIP_VALIDATE_INFO     pInfo
    )
/*++

Routine Description:

   Used to detect the start of a DV frame.  A DV frame is started with a header section.

Return

    0  verified
    1: invallid

--*/
{
    if(pInfo->Packet) {        

        //
        // Detect header 0 signature.
        //
        if(
             (pInfo->Packet[0] & DIF_BLK_ID0_SCT_MASK)  == 0 
          && (pInfo->Packet[1] & DIF_BLK_ID1_DSEQ_MASK) == 0 
          && (pInfo->Packet[2] & DIF_BLK_ID2_DBN_MASK)  == 0 
          ) {

// 
// This can be used to detect dynamic format change if this function is called 
// to check for data packets always.  This may require setting this flag:
//     CIP_VALIDATE_ALL_SOURCE instead of CIP_VALIDATE_FIRST_SOURCE
//
#if 0 // DBG


            PSRB_DATA_PACKET pSrbDataPacket = pInfo->Context;
            PSTREAMEX        pStrmExt       = pSrbDataPacket->pStrmExt;          
            PDVCR_EXTENSION  pDevExt        = pStrmExt->pDevExt;

            if((pInfo->Packet[0] & DIF_HEADER_DSF) == 0) {
                // Indicate a 10 DIF sequences include in a video frame (525-60)/NTSC.
                if(
                     pDevExt->VideoFormatIndex == FMT_IDX_SD_DVCR_PAL 
                  || pDevExt->VideoFormatIndex == FMT_IDX_SDL_DVCR_PAL
                  ) { 
                    // Dynamic format changes!!
                    TRACE(TL_STRM_ERROR|TL_CIP_WARNING,("Detect dynamic format change PAL -> NTSC!\n"));
                }
            } else {
                // Indicate a 12 DIF sequences include in a video frame (625-50)/PAL.
                if(
                     pDevExt->VideoFormatIndex == FMT_IDX_SD_DVCR_NTSC 
                  || pDevExt->VideoFormatIndex == FMT_IDX_SDL_DVCR_NTSC
                  ) { 
                    // Dynamic format changes!!
                    TRACE(TL_STRM_ERROR|TL_CIP_WARNING,("Detect dynamic format change NTSC -> PAL!\n"));
                }
            }
#endif
            
            // Check TF1, TF2, and  TF3:  1: not transmitted; 0:transmitted
            // TF1:Audio; TF2:Video; TF3:Subcode; they all need to be 0 to be valid.
            if(
                 (pInfo->Packet[5] & DIF_HEADER_TFn) 
              || (pInfo->Packet[6] & DIF_HEADER_TFn) 
              || (pInfo->Packet[7] & DIF_HEADER_TFn) 
              ) {
                TRACE(TL_STRM_ERROR|TL_CIP_WARNING,("\'%d inv src pkts; [%x %x %d %x], [%x   %x %x %x]\n", 
                    cntInvSrcPkt,
                    pInfo->Packet[0],
                    pInfo->Packet[1],
                    pInfo->Packet[2],
                    pInfo->Packet[3],
                    pInfo->Packet[4],
                    pInfo->Packet[5],
                    pInfo->Packet[6],
                    pInfo->Packet[7]
                    ));
                // Valid header but DIF block for this area is not transmitted.
                // Some DV (such as DVCPro) may wait untill its "mecha and servo" to be stable to make these valid.
                // This should happen if a graph is in run state before a tape is played (and stablized).
                return 1;
            }

#if DBG
            if(cntInvSrcPkt > 0) {
                TRACE(TL_CIP_TRACE,("\'%d inv src pkts; [%x %x %d %x] [%x %x %x %x]\n", 
                    cntInvSrcPkt,
                    pInfo->Packet[0],
                    pInfo->Packet[1],
                    pInfo->Packet[2],
                    pInfo->Packet[3],
                    pInfo->Packet[4],
                    pInfo->Packet[5],
                    pInfo->Packet[6],
                    pInfo->Packet[7]
                    )); 
                cntInvSrcPkt = 0;  // Reset
            }
#endif
            return 0;
        }
        else {
#if DBG

            //
            // To detect invalid src pkt sequence;
            // If it exceeded the number of source packet per frame, we need to know about it.
            //

            PSRB_DATA_PACKET pSrbDataPacket = pInfo->Context;
            PSTREAMEX        pStrmExt       = pSrbDataPacket->pStrmExt;          
            PDVCR_EXTENSION  pDevExt        = pStrmExt->pDevExt;

            if(++cntInvSrcPkt >= DVFormatInfoTable[pDevExt->VideoFormatIndex].ulSrcPackets) {            
                TRACE(TL_CIP_TRACE,("(%d) Invalid SrcPkt >= max inv src pkt %d; ID0,1,2 = [%x %x %x]\n",
                    cntInvSrcPkt,
                    DVFormatInfoTable[pDevExt->VideoFormatIndex].ulSrcPackets,
                    pInfo->Packet[0], pInfo->Packet[1], pInfo->Packet[2]
                    )); 

                if(DVTraceMask & TL_CIP_TRACE) {
                    ASSERT(cntInvSrcPkt < DVFormatInfoTable[pDevExt->VideoFormatIndex].ulSrcPackets);
                }
                cntInvSrcPkt = 0;  // Reset
            }
            else {
                TRACE(TL_CIP_INFO,("(%d) Invalid SrcPktSeq; ID0,1,2 = [%x,%x,%x]\n", 
                    cntInvSrcPkt, pInfo->Packet[0], pInfo->Packet[1], pInfo->Packet[2] )); 
            }
#endif
            return 1;
        }
    }
    else {
        TRACE(TL_CIP_WARNING, ("\'Validate: invalid SrcPktSeq; Packet %x\n", pInfo->Packet)); 
        return 1;
    }
} // DVReadFrameValidate


#if DBG
LONGLONG    PreviousPictureNumber;
LONGLONG    PreviousTime;
CYCLE_TIME  PreviousTimestamp;
#endif


ULONG
DVCompleteSrbRead(
    PCIP_NOTIFY_INFO     pInfo
    )
/*++

Routine Description:

    61883 has completed receiving data and callback to us to complete.   

--*/
{
    PSRB_DATA_PACKET            pSrbDataPacket;
    PHW_STREAM_REQUEST_BLOCK    pSrb; 
    PKSSTREAM_HEADER            pStrmHeader;
    PDVCR_EXTENSION             pDevExt;
    PSTREAMEX                   pStrmExt;  
    LONGLONG                    LastPictureNumber;
    PUCHAR                      pFrameBuffer;
    KIRQL oldIrql;
    PKS_FRAME_INFO  pFrameInfo; // For VidOnly pin only 
#if DBG
    PXMT_FRAME_STAT pXmtStat;
#endif


    // Callback and might be at the DISPATCH_LEVEL
    // The caller might have acquired spinlock as well!

    pSrbDataPacket = pInfo->Context;

    if(!pSrbDataPacket) {     
        ASSERT(pSrbDataPacket && "Context is NULL!");
        return 1;
    }

    pStrmExt = pSrbDataPacket->pStrmExt; 
    
    KeAcquireSpinLock(pStrmExt->DataListLock, &oldIrql);

#if DBG
    // Once it is completed by 61883, it becomes non-cancellable.
    if(!pStrmExt->bIsochIsActive) {   
        TRACE(TL_CIP_WARNING,("CompleteSrbRead: bIsochActive:%d; pSrbDataPacket:%x\n", pStrmExt->bIsochIsActive, pSrbDataPacket));        
    }
#endif

    pSrb     = pSrbDataPacket->pSrb;  ASSERT(pSrbDataPacket->pSrb);
    pDevExt  = pStrmExt->pDevExt;
    pFrameBuffer = (PUCHAR) pSrbDataPacket->FrameBuffer;
    pStrmHeader = pSrb->CommandData.DataBufferArray;  ASSERT(pStrmHeader->Size >= sizeof(KSSTREAM_HEADER));

    //
    // Check CIP_STATUS_* from 61883
    //    
    // CIP_STATUS_CORRUPT_FRAME (0x00000001)  // isoch header or cip header was incorrect
    if(pSrbDataPacket->Frame->Status & CIP_STATUS_CORRUPT_FRAME) {
        TRACE(TL_STRM_WARNING|TL_CIP_TRACE,("\'CIP_STATUS_CORRUPT_FRAME\n"));
        pStrmHeader->OptionsFlags = 0;
        pSrb->Status = STATUS_SUCCESS;  // Success but no data !
        pStrmHeader->DataUsed = 0;
        pStrmExt->PictureNumber++;  pStrmExt->FramesProcessed++;
    }
    else
    // CIP_STATUS_SUCCESS       (0x00000000)  // 0 so cannot do bitwise operation!!
    // CIP_STATUS_FIRST_FRAME   (0x00000002)  // First attached frame to 61883
    if(pSrbDataPacket->Frame->Status == CIP_STATUS_SUCCESS ||
       (pSrbDataPacket->Frame->Status & CIP_STATUS_FIRST_FRAME))   {

        // Only increment FramesProcessed if it is a valid frame;
        pStrmExt->FramesProcessed++;

        pSrb->Status              = STATUS_SUCCESS;
        pStrmHeader->OptionsFlags = KSSTREAM_HEADER_OPTIONSF_SPLICEPOINT;
        pStrmHeader->DataUsed     = DVFormatInfoTable[pDevExt->VideoFormatIndex].ulFrameSize;


        // Put in Timestamp info depending on clock provider            
        pStrmHeader->PresentationTime.Numerator   = 1;
        pStrmHeader->PresentationTime.Denominator = 1;

        if(pStrmExt->hMasterClock || pStrmExt->hClock) {

            pStrmHeader->Duration = 
                DVFormatInfoTable[pDevExt->VideoFormatIndex].ulAvgTimePerFrame;

            pStrmHeader->OptionsFlags |= 
                (KSSTREAM_HEADER_OPTIONSF_TIMEVALID |     // pStrmHeader->PresentationTime.Time is valid
                 KSSTREAM_HEADER_OPTIONSF_DURATIONVALID); 
        }
        //
        // Only if there is a clock, presentation time and drop frames information are set.
        //  Acoording to DDK:
        //  The PictureNumber member count represents the idealized count of the current picture, 
        //  which is calculated in one of two ways: 
        // ("Other" clock) Measure the time since the stream was started and divide by the frame duration. 
        // (MasterClock) Add together the count of frames captured and the count of frame dropped. 
        //

        // Other device (audio?) is the clock provider
        if(pStrmExt->hClock) {

            pStrmExt->TimeContext.HwDeviceExtension = (struct _HW_DEVICE_EXTENSION *) pDevExt; 
            pStrmExt->TimeContext.HwStreamObject    = pStrmExt->pStrmObject;
            pStrmExt->TimeContext.Function          = TIME_GET_STREAM_TIME;
            pStrmExt->TimeContext.Time              = 0;
            pStrmExt->TimeContext.SystemTime        = 0;

            StreamClassQueryMasterClockSync(
                pStrmExt->hClock,
                &(pStrmExt->TimeContext) 
                );

            pStrmHeader->PresentationTime.Time = pStrmExt->CurrentStreamTime = pStrmExt->TimeContext.Time;

            // Calculate picture number and dropped frame;
            // For NTSC, it could be 267 or 266 packet time per frame. Since integer calculation will round, 
            // we will add a packet time (TIME_PER_CYCLE = 125 us = 1250 100nsec) to that.This is only used for calculation.
            LastPictureNumber = pStrmExt->PictureNumber;  
            pStrmExt->PictureNumber = 
                1 +   // Picture number start with 1.
                (pStrmHeader->PresentationTime.Time + TIME_PER_CYCLE)
                * (LONGLONG) GET_AVG_TIME_PER_FRAME_DENOM(pStrmExt->pDevExt->VideoFormatIndex) 
                / (LONGLONG) GET_AVG_TIME_PER_FRAME_NUM(pStrmExt->pDevExt->VideoFormatIndex);

            // Detect discontinuity
            if(pStrmExt->PictureNumber > LastPictureNumber+1) {
                pStrmHeader->OptionsFlags |= KSSTREAM_HEADER_OPTIONSF_DATADISCONTINUITY;  // If there is a skipped frame, set the discontinuity flag
                TRACE(TL_CIP_WARNING,("\'Discontinuity: LastPic#:%d; Pic#%d; PresTime:%d;\n", (DWORD) LastPictureNumber, (DWORD) pStrmExt->PictureNumber, (DWORD) pStrmHeader->PresentationTime.Time));
            }

            // Detect if picture number did not progress.
            // This could be due to two frame being completely very close to each other.
            if(pStrmExt->PictureNumber <= LastPictureNumber) {
                TRACE(TL_CIP_WARNING,("\'hClock:Same pic #:(%d->%d); tmPres:(%d->%d); (%d:%d:%d) -> (%d:%d:%d); AQD[%d:%d:%d]\n", 
                    (DWORD) PreviousPictureNumber,
                    (DWORD) pStrmExt->PictureNumber, 
                    (DWORD) PreviousTime,
                    (DWORD) pStrmHeader->PresentationTime.Time,
                    PreviousTimestamp.CL_SecondCount, PreviousTimestamp.CL_CycleCount, PreviousTimestamp.CL_CycleOffset,
                    pSrbDataPacket->Frame->Timestamp.CL_SecondCount,
                    pSrbDataPacket->Frame->Timestamp.CL_CycleCount,
                    pSrbDataPacket->Frame->Timestamp.CL_CycleOffset,
                    pStrmExt->cntDataAttached,
                    pStrmExt->cntSRBQueued,
                    pStrmExt->cntDataDetached
                    ));

                pStrmExt->PictureNumber = LastPictureNumber + 1;  // Picture number must progress !!!!
            }
#if DBG
            PreviousPictureNumber = pStrmExt->PictureNumber;
            PreviousTime          = pStrmHeader->PresentationTime.Time;
            PreviousTimestamp = pSrbDataPacket->Frame->Timestamp;
#endif
            pStrmExt->FramesDropped = pStrmExt->PictureNumber - pStrmExt->FramesProcessed;

        // This subunit driver is a Master clock
        } else if (pStrmExt->hMasterClock) {
#ifdef NT51_61883
            ULONG  ulDeltaCycleCounts;

            // No drop frame for PAUSE->RUN transition
            if(pStrmExt->b1stNewFrameFromPauseState) { 

                pStrmHeader->OptionsFlags |= KSSTREAM_HEADER_OPTIONSF_DATADISCONTINUITY;            
                pStrmExt->b1stNewFrameFromPauseState = FALSE;                  

            } else {           
                ULONG ulCycleCount16bits;

                // Calculate skipped 1394 cycle from the returned CycleTime
                VALIDATE_CYCLE_COUNTS(pSrbDataPacket->Frame->Timestamp);
                ulCycleCount16bits = CALCULATE_CYCLE_COUNTS(pSrbDataPacket->Frame->Timestamp);
                ulDeltaCycleCounts = CALCULATE_DELTA_CYCLE_COUNT(pStrmExt->CycleCount16bits, ulCycleCount16bits); 

                // Adjust to max allowable gap to the max elapsed time of the CycleTime returned by OHCI 1394.
                if(ulDeltaCycleCounts > MAX_CYCLES)  
                    ulDeltaCycleCounts = MAX_CYCLES;  // Wrap around
    
                //
                // There are two cases for drop frames: 
                //    (1) Starve of buffer; or,
                //    (2) no data (blank tape or tape is not playing)
                //

                // For case (1), 61883 returns CIP_STATUS_FIRST_FRAME.  
                if(pSrbDataPacket->Frame->Status & CIP_STATUS_FIRST_FRAME)   {
                    // Use cycle count to calculate drop frame.  We substract 1 from the MaxSrcPacket on purpose to avoid truncating. 
                    // The max range is MAX_CYCLE (8 * 8000 = 64000 cycles)
                    //    64000 * 125 * 3 / 100100 = 239.76
                    //    64000 / 266 = 240
                    //    64000 / 267 = 239
                    if(ulDeltaCycleCounts >= (DVFormatInfoTable[pDevExt->VideoFormatIndex].ulMaxSrcPackets - 1)) {
                        ULONG ulFrameElapsed = ulDeltaCycleCounts / (DVFormatInfoTable[pDevExt->VideoFormatIndex].ulMaxSrcPackets - 1);
                        pStrmExt->FramesDropped += (ulFrameElapsed - 1);  // There is a valid frame that is not dropped.
                     } 
                    
                    TRACE(TL_STRM_WARNING|TL_CIP_WARNING,("CIP_STATUS_FIRST_FRAME: Drop:%d; Processed:%d\n", (DWORD) pStrmExt->FramesDropped, pStrmExt->FramesProcessed )); 
                    pStrmHeader->OptionsFlags |= KSSTREAM_HEADER_OPTIONSF_DATADISCONTINUITY;            

                } else {
                    // Ignore all "drop frames" in the "no data" case
                    // pStrmExt->FramesDropped += 0;
                }            
            }

            // If we are the clock provider, the stream time is based on sample number * AvgTimePerFrame
            pStrmExt->PictureNumber = pStrmExt->FramesProcessed + pStrmExt->FramesDropped;

            pStrmHeader->PresentationTime.Time = pStrmExt->CurrentStreamTime = 
                pStrmExt->PictureNumber 
                * (LONGLONG) GET_AVG_TIME_PER_FRAME_NUM(pStrmExt->pDevExt->VideoFormatIndex)
                / (LONGLONG) GET_AVG_TIME_PER_FRAME_DENOM(pStrmExt->pDevExt->VideoFormatIndex); 

            // Use to adjust the queried stream time
            pStrmExt->LastSystemTime = GetSystemTime();

            // Cache current CycleCount
            pStrmExt->CycleCount16bits = CALCULATE_CYCLE_COUNTS(pSrbDataPacket->Frame->Timestamp);

#if DBG
            // First frame or skipped frame
            if(pStrmExt->PictureNumber <= 1 ||
               pStrmExt->PictureNumber <= PreviousPictureNumber ||
               ulDeltaCycleCounts > DVFormatInfoTable[pDevExt->VideoFormatIndex].ulMaxSrcPackets
               )
                TRACE(TL_CIP_WARNING,("\'hMasterClock: Same pic #:(%d->%d); tmPres:(%d->%d); (%d:%d:%d) -> (%d:%d:%d); AQD[%d:%d:%d]\n", 
                    (DWORD) PreviousPictureNumber,
                    (DWORD) pStrmExt->PictureNumber, 
                    (DWORD) PreviousTime,
                    (DWORD) pStrmHeader->PresentationTime.Time,
                    PreviousTimestamp.CL_SecondCount, PreviousTimestamp.CL_CycleCount, PreviousTimestamp.CL_CycleOffset,
                    pSrbDataPacket->Frame->Timestamp.CL_SecondCount,
                    pSrbDataPacket->Frame->Timestamp.CL_CycleCount,
                    pSrbDataPacket->Frame->Timestamp.CL_CycleOffset,
                    pStrmExt->cntDataAttached,
                    pStrmExt->cntSRBQueued,
                    pStrmExt->cntDataDetached
                    ));

            PreviousPictureNumber = pStrmExt->PictureNumber;
            PreviousTime          = pStrmHeader->PresentationTime.Time;
            PreviousTimestamp = pSrbDataPacket->Frame->Timestamp;
#endif


#else   // NT51_61883
            // This is the old way when 61883 was not returning the correct CycleTime.
            pStrmHeader->PresentationTime.Time = pStrmExt->CurrentStreamTime;            
            pStrmExt->LastSystemTime = GetSystemTime();  // Use to adjust the queried stream time
            pStrmExt->CurrentStreamTime += DVFormatInfoTable[pDevExt->VideoFormatIndex].ulAvgTimePerFrame;
#endif  // NT51_61883

        // no Clock so "free flowing!"
        } else {
            pStrmHeader->PresentationTime.Time = 0;
            pStrmHeader->Duration = 0;  // No clock so not valid.
            pStrmExt->PictureNumber++;
            TRACE(TL_CIP_TRACE,("\'No clock: PicNum:%d\n", (DWORD) pStrmExt->PictureNumber));
        }
    }
    else {
        // 61883 has not defined this new status at this time!
        // Do not know what to do so we will complete it with 0 length for now.
        pStrmHeader->OptionsFlags = 0;
        pSrb->Status = STATUS_SUCCESS;
        pStrmHeader->DataUsed = 0;
        pStrmExt->PictureNumber++;  pStrmExt->FramesProcessed++;
        TRACE(TL_STRM_WARNING|TL_CIP_ERROR,("pSrbDataPacket:%x; unexpected Frame->Status %x\n", pSrbDataPacket, pSrbDataPacket->Frame->Status));
        ASSERT(FALSE && "Unknown pSrbDataPacket->Frame->Status");
    }

    // For VidOnly which uses VideoInfoHeader and has 
    // an extended frame information (KS_FRAME_INFO) appended to KSSTREAM_HEADER
    if( pDevExt->idxStreamNumber == 0 &&
        (pStrmHeader->Size >= (sizeof(KSSTREAM_HEADER) + sizeof(PKS_FRAME_INFO)))
        ) {
        pFrameInfo = (PKS_FRAME_INFO) (pStrmHeader + 1);
        pFrameInfo->ExtendedHeaderSize = sizeof(KS_FRAME_INFO);
        pFrameInfo->PictureNumber = pStrmExt->PictureNumber;
        pFrameInfo->DropCount     = pStrmExt->FramesDropped;
        pFrameInfo->dwFrameFlags  = 
            KS_VIDEO_FLAG_FRAME |     // Complete frame
            KS_VIDEO_FLAG_I_FRAME;    // Every DV frame is an I frame
    }

#if DBG
    // Validate that the data is return in the right sequence
    if(pSrbDataPacket->FrameNumber != pStrmExt->FramesProcessed) {
        TRACE(TL_STRM_WARNING|TL_CIP_ERROR,("\'pSrbDataPacket:%x; Status:%x; Out of Sequence %d != %d; (Dropped:%x)\n", 
                pSrbDataPacket, pSrbDataPacket->Frame->Status, 
                (DWORD) pSrbDataPacket->FrameNumber, (DWORD) pStrmExt->FramesProcessed,
                (DWORD) pStrmExt->FramesDropped
                ));
    };
#endif


#if DBG
    // Collect transmit buffer statistics    
    if(pStrmExt->ulStatEntries < MAX_XMT_FRAMES_TRACED) {
        pXmtStat = pStrmExt->paXmtStat + pStrmExt->ulStatEntries;
    
        pXmtStat->StreamState    = pStrmExt->StreamState;

        pXmtStat->cntSRBReceived = (LONG) pStrmExt->cntSRBReceived;
        pXmtStat->cntSRBPending  = (LONG) pStrmExt->cntSRBPending;
        pXmtStat->cntSRBQueued   = (LONG) pStrmExt->cntSRBQueued;
        pXmtStat->cntDataAttached= pStrmExt->cntDataAttached;

        pXmtStat->FrameSlot      = (DWORD) pStrmExt->PictureNumber;
        pXmtStat->tmStreamTime   = pStrmExt->CurrentStreamTime;

        pXmtStat->DropCount      = (DWORD) pStrmExt->FramesDropped;

        pXmtStat->FrameNumber    = (DWORD) pSrbDataPacket->FrameNumber;
        pXmtStat->OptionsFlags   = pSrb->CommandData.DataBufferArray->OptionsFlags;
        pXmtStat->tmPresentation = pSrb->CommandData.DataBufferArray->PresentationTime.Time;

        pXmtStat->tsTransmitted= pSrbDataPacket->Frame->Timestamp;

        pStrmExt->ulStatEntries++;
    }
    
#endif


    //
    // Mark completion is called.
    //
    pSrbDataPacket->State |= DE_IRP_CALLBACK_COMPLETED;

    //
    // Attached->Completed or Completed->Attached.
    //
    if(IsStateSet(pSrbDataPacket->State, DE_IRP_ATTACHED_COMPLETED)) {

        //
        // Recycle it back to the detach list
        //
        RemoveEntryList(&pSrbDataPacket->ListEntry); pStrmExt->cntDataAttached--;  ASSERT(pStrmExt->cntDataAttached >= 0);
        InsertTailList(&pStrmExt->DataDetachedListHead, &pSrbDataPacket->ListEntry); pStrmExt->cntDataDetached++;

#if DBG
        // Detect if 61883 is starve.  This cause discontinuity.
        // This can happen for many valid reasons (slow system).
        // An assert is added to detect other unknown reason.
        if(pStrmExt->cntDataAttached == 0 && pStrmExt->StreamState == KSSTATE_RUN) {
            TRACE(TL_STRM_WARNING|TL_CIP_WARNING,("\n**** 61883 starved in RUN state (read); AQD[%d:%d:%d]\n\n", 
                pStrmExt->cntDataAttached, pStrmExt->cntSRBQueued, pStrmExt->cntDataDetached
            ));
            // ASSERT(pStrmExt->cntDataAttached > 0 && "61883 is starve at RUN state!!");
        }
#endif

        //
        // Complete this Srb
        //

        StreamClassStreamNotification(StreamRequestComplete, pStrmExt->pStrmObject, pSrbDataPacket->pSrb );  
        pSrbDataPacket->State |= DE_IRP_SRB_COMPLETED;  pSrbDataPacket->pSrb = NULL;

#if DBG
        pStrmExt->cntSRBPending--;
#endif

    } else {

        TRACE(TL_STRM_WARNING,("CompleteSrbRead: pSrbDataPacket:%x; Completed before attach.\n", pSrbDataPacket));

    }

    KeReleaseSpinLock(pStrmExt->DataListLock, oldIrql); 

    return 0;
} // DVCompleteSrbRead


NTSTATUS
DVAttachFrameCR(
    IN PDEVICE_OBJECT DeviceObject,
    IN PIRP pIrp,
    IN PSRB_DATA_PACKET pSrbDataPacket    
    )
/*++

Routine Description:

    Completion routine for attaching a frame for transmitting.
    Apply to attaching listen and talk frame.

--*/
{
    PHW_STREAM_REQUEST_BLOCK pSrb;
    PSTREAMEX       pStrmExt;
    PLONG plSrbUseCount; // When this count is 0, it can be completed.
    KIRQL oldIrql;


    pStrmExt = pSrbDataPacket->pStrmExt;
    KeAcquireSpinLock(pStrmExt->DataListLock, &oldIrql);

    pSrb = pSrbDataPacket->pSrb;

    // This entry is be already attached before IoCallDriver.
    // This is done this way because this buffer could be filled and 
    // completed before the attach completion routine (here) is called.
    // If it is completed and callback is called, 
    // pSrbDataPacket->pSrb has been set to NULL.
    // In the error case, pSrbDataPacket->pSrb should not be NULL.
    if(!NT_SUCCESS(pIrp->IoStatus.Status)) {
        if(pSrbDataPacket->pSrb == NULL) {
            // PBinder told me that this cannot happen.
            // A buffer is completed (pSRb set to NULL), and still return with an error!
            ASSERT(pSrbDataPacket->pSrb);
            KeReleaseSpinLock(pStrmExt->DataListLock, oldIrql);   
            return STATUS_MORE_PROCESSING_REQUIRED;      
        }
        pSrbDataPacket->State |= DE_IRP_ERROR;

        plSrbUseCount = (PLONG) (pSrb->SRBExtension);
        (*plSrbUseCount) --;  // -- for being remove from queue
        ASSERT(*plSrbUseCount >= 0);

        TRACE(TL_CIP_ERROR,("DVAttachFrameCR: pSrb:%x; pSrb->Status:%x; failed pIrp->Status %x; UseCnt:%d\n", pSrb, pSrb->Status, pIrp->IoStatus.Status, *plSrbUseCount));   
        ASSERT(NT_SUCCESS(pIrp->IoStatus.Status) && "DVAttachFrameCR");
        // Complete this SRB only if the count is 0.
        if(*plSrbUseCount == 0 && pSrb->Status != STATUS_CANCELLED) {
            pSrb->Status = pIrp->IoStatus.Status;
            pSrb->CommandData.DataBufferArray->DataUsed = 0;

            // Complete SRB
            StreamClassStreamNotification(StreamRequestComplete, pSrb->StreamObject, pSrbDataPacket->pSrb);
            pSrbDataPacket->State |= DE_IRP_SRB_COMPLETED;  pSrbDataPacket->pSrb = NULL;
#if DBG
            pStrmExt->cntSRBPending--;
#endif            
        }

        // Recycle list
        RemoveEntryList(&pSrbDataPacket->ListEntry); pStrmExt->cntDataAttached--; ASSERT(pStrmExt->cntDataAttached >= 0);
        InsertTailList(&pStrmExt->DataDetachedListHead, &pSrbDataPacket->ListEntry); pStrmExt->cntDataDetached++;

#if DBG
        // Detect if 61883 is starve.  This cause discontinuity.
        // This can happen for many valid reasons (slow system).
        // An assert is added to detect other unknown reason.
        if(!pStrmExt->bEOStream && pStrmExt->cntDataAttached == 0 && pStrmExt->StreamState == KSSTATE_RUN) {
            TRACE(TL_STRM_WARNING|TL_CIP_WARNING,("\n**** 61883 starve in RUN state (AttachCR); AQD[%d:%d:%d]\n\n", 
                pStrmExt->cntDataAttached, pStrmExt->cntSRBQueued, pStrmExt->cntDataDetached
            ));
            if (pStrmExt->pStrmInfo->DataFlow == KSPIN_DATAFLOW_IN) {
                // ASSERT(pStrmExt->cntDataAttached > 0 && "61883 is starve at RUN state!!");
            }
        }
#endif

        KeReleaseSpinLock(pStrmExt->DataListLock, oldIrql);   
        return STATUS_MORE_PROCESSING_REQUIRED;        
    }


    //
    // Mark attached buffer completed.
    //
    pSrbDataPacket->State |= DE_IRP_ATTACHED_COMPLETED;


    //
    // Special case: Completed and then Attached.
    //
    if(IsStateSet(pSrbDataPacket->State, DE_IRP_CALLBACK_COMPLETED)) {

        //
        // Recycle it back to the detach list
        //
        RemoveEntryList(&pSrbDataPacket->ListEntry); pStrmExt->cntDataAttached--;  ASSERT(pStrmExt->cntDataAttached >= 0);
        InsertTailList(&pStrmExt->DataDetachedListHead, &pSrbDataPacket->ListEntry); pStrmExt->cntDataDetached++;

#if DBG
        // Detect if 61883 is starve.  This cause discontinuity.
        // This can happen for many valid reasons (slow system).
        // An assert is added to detect other unknown reason.
        if(!pStrmExt->bEOStream && pStrmExt->cntDataAttached == 0 && pStrmExt->StreamState == KSSTATE_RUN) {
            TRACE(TL_STRM_WARNING|TL_CIP_WARNING,("\n**** 61883 starve in RUN state (AttachCR); AQD[%d:%d:%d]\n\n", 
                pStrmExt->cntDataAttached, pStrmExt->cntSRBQueued, pStrmExt->cntDataDetached
            ));
            if (pStrmExt->pStrmInfo->DataFlow == KSPIN_DATAFLOW_IN) {
                // ASSERT(pStrmExt->cntDataAttached > 0 && "61883 is starve at RUN state!!");
            }
        }
#endif

        //
        // Complete this Srb
        //
        StreamClassStreamNotification(StreamRequestComplete, pStrmExt->pStrmObject, pSrbDataPacket->pSrb); 
        pSrbDataPacket->State |= DE_IRP_SRB_COMPLETED;  pSrbDataPacket->pSrb = NULL;

#if DBG
        pStrmExt->cntSRBPending--;
#endif

        TRACE(TL_STRM_WARNING,("AttachFrameCR: pSrbDataPacket:%x; completed before DttachFrameCR.\n", pSrbDataPacket));
    }


    KeReleaseSpinLock(pStrmExt->DataListLock, oldIrql);

    TRACE(TL_CIP_INFO,("\'DVAttachFrameCR: pSrb:%x; AttachCnt:%d\n", pSrb, pStrmExt->cntDataAttached));  

    return STATUS_MORE_PROCESSING_REQUIRED;
}


VOID
DVSRBRead(
    IN PKSSTREAM_HEADER pStrmHeader,
    IN ULONG            ulFrameSize,
    IN PDVCR_EXTENSION  pDevExt,
    IN PSTREAMEX        pStrmExt,
    IN PHW_STREAM_REQUEST_BLOCK pSrb        // needs Srb->Status 
    )
/*++

Routine Description:

    Called when an Read Data Srb request is received

--*/
{
    KIRQL             oldIrql;
    NTSTATUS          Status;
    PSRB_DATA_PACKET  pSrbDataPacket;
    PAV_61883_REQUEST   pAVReq;
    PLONG               plSrbUseCount;
    PIO_STACK_LOCATION  NextIrpStack;
    ULONG               ulSrcPktLen;    // Packet length in bytes
    PVOID               pFrameBuffer;



    PAGED_CODE();


    //
    // Some validation
    //
    if(pStrmHeader->FrameExtent < ulFrameSize) {
        TRACE(TL_CIP_WARNING,("\'SRBRead: FrmExt %d < FrmSz %d\n", pStrmHeader->FrameExtent, ulFrameSize));
#ifdef SUPPORT_NEW_AVC
        if(pStrmExt->bDV2DVConnect) {
            pSrb->Status = STATUS_SUCCESS;  // Testing...
        } else {
#endif
        ASSERT(pStrmHeader->FrameExtent >= ulFrameSize);
        pSrb->Status = STATUS_INVALID_PARAMETER;  
#ifdef SUPPORT_NEW_AVC
        }
#endif
        goto ExitReadStreamError;
    }


    //
    // Make sure that there is enough entry
    //
    KeAcquireSpinLock(pStrmExt->DataListLock, &oldIrql);
    if(IsListEmpty(&pStrmExt->DataDetachedListHead)) {
        //
        // This can happen only if the upper layer send down more than what we preallocated.        
        // In this case, we will expand the list.
        //
        if(!(pSrbDataPacket = ExAllocatePool(NonPagedPool, sizeof(SRB_DATA_PACKET)))) {
            KeReleaseSpinLock(pStrmExt->DataListLock, oldIrql);        
            pSrb->Status = STATUS_INSUFFICIENT_RESOURCES;
            goto ExitReadStreamError;
        }
        RtlZeroMemory(pSrbDataPacket, sizeof(SRB_DATA_PACKET));
        if(!(pSrbDataPacket->Frame = ExAllocatePool(NonPagedPool, sizeof(CIP_FRAME)))) {
            KeReleaseSpinLock(pStrmExt->DataListLock, oldIrql);        
            ExFreePool(pSrbDataPacket);
            pSrb->Status = STATUS_INSUFFICIENT_RESOURCES;
            goto ExitReadStreamError;            
        }
        if(!(pSrbDataPacket->pIrp = IoAllocateIrp(pDevExt->pBusDeviceObject->StackSize, FALSE))) {
            KeReleaseSpinLock(pStrmExt->DataListLock, oldIrql);        
            ExFreePool(pSrbDataPacket->Frame);  pSrbDataPacket->Frame = 0;
            ExFreePool(pSrbDataPacket); pSrbDataPacket = 0;
            pSrb->Status = STATUS_INSUFFICIENT_RESOURCES;
            goto ExitReadStreamError; 
        }
        InsertTailList(&pStrmExt->DataDetachedListHead, &pSrbDataPacket->ListEntry); pStrmExt->cntDataDetached++;
        TRACE(TL_CIP_WARNING,("\'Add one node to DetachList\n"));     
    }

    // Get a a nonpaged system-space virtual address for the buffer
    // This could fail it there is not enough system resource (MDL).
#ifdef USE_WDM110   // Win2000
    //
    // Driver verifier flag to use this but if this is used, this driver will not load for Millen!!!
    //
    pFrameBuffer = MmGetSystemAddressForMdlSafe(pSrb->Irp->MdlAddress, NormalPagePriority);
#else    // Win9x
    pFrameBuffer = MmGetSystemAddressForMdl    (pSrb->Irp->MdlAddress);
#endif
    if(pFrameBuffer == NULL) {
        KeReleaseSpinLock(pStrmExt->DataListLock, oldIrql);        

        pSrb->Status = STATUS_INSUFFICIENT_RESOURCES;
        ASSERT(FALSE && "DVFormatAttachFrame() insufficient resource!");
        goto ExitReadStreamError;
    }

    pSrbDataPacket = (PSRB_DATA_PACKET) RemoveHeadList(&pStrmExt->DataDetachedListHead); pStrmExt->cntDataDetached--;
    plSrbUseCount = (PLONG) (pSrb->SRBExtension); (*plSrbUseCount) = 0; // Not in a queue so 0.  
    pAVReq = &pSrbDataPacket->AVReq;


    ulSrcPktLen = \
        (DVFormatInfoTable[pDevExt->VideoFormatIndex].DataBlockSize << 2) * \
            (1 << DVFormatInfoTable[pDevExt->VideoFormatIndex].FractionNumber);  

    //
    // Format an attach frame request
    //
    DVFormatAttachFrame(
        pStrmExt->pStrmInfo->DataFlow,
        pStrmExt,
        pAVReq,
        pSrb,
        pSrbDataPacket,
        ulSrcPktLen,
        ulFrameSize,
        pFrameBuffer
        );

    // Completion callback can be called before the attach frame completion routine;
    // Add this to the attached list now; if it ever failed, it will be removed in the completion routine.
    InsertTailList(&pStrmExt->DataAttachedListHead, &pSrbDataPacket->ListEntry); pStrmExt->cntDataAttached++;
    (*plSrbUseCount) ++;  // ++ for being in queue
    ASSERT(*plSrbUseCount > 0);

    KeReleaseSpinLock(pStrmExt->DataListLock, oldIrql);        


    NextIrpStack = IoGetNextIrpStackLocation(pSrbDataPacket->pIrp);
    NextIrpStack->MajorFunction = IRP_MJ_INTERNAL_DEVICE_CONTROL;
    NextIrpStack->Parameters.DeviceIoControl.IoControlCode = IOCTL_61883_CLASS;
    NextIrpStack->Parameters.Others.Argument1 = &pSrbDataPacket->AVReq;

    IoSetCompletionRoutine(
        pSrbDataPacket->pIrp, 
        DVAttachFrameCR, 
        pSrbDataPacket, 
        TRUE, 
        TRUE, 
        TRUE
        );

    // Must set to _PENDING or MediaSample will return empty KSSTREAM_HEADER    
    pSrb->Status = STATUS_PENDING;
    pSrbDataPacket->pIrp->IoStatus.Status = STATUS_SUCCESS;  // Initialize it 

    Status = IoCallDriver( pStrmExt->pDevExt->pBusDeviceObject, pSrbDataPacket->pIrp);

    ASSERT(Status == STATUS_PENDING || Status == STATUS_SUCCESS);

    return;

ExitReadStreamError:

    StreamClassStreamNotification(          
        StreamRequestComplete,
        pSrb->StreamObject,
        pSrb 
        );
#if DBG
    pStrmExt->cntSRBPending--;
#endif
}


ULONG
DVCompleteSrbWrite(
    PCIP_NOTIFY_INFO     pInfo
    )
/*++

Routine Description:

    This fucntion is called when 61883 has completed transmitting a frame.

--*/
{
    PSRB_DATA_PACKET          pSrbDataPacket ;
    PHW_STREAM_REQUEST_BLOCK  pSrb; 
    NTSTATUS                  Status = STATUS_SUCCESS; 
    PDVCR_EXTENSION           pDevExt;
    PSTREAMEX                 pStrmExt;  
    PLONG plSrbUseCount; // When this count is 0, it can be completed.
    KIRQL oldIrql;
#if DBG
    LONG lCycleCountElapsed;
    PXMT_FRAME_STAT pXmtStat;
#endif



    // Callback and in DISPATCH_LEVEL
    // Caller might have acquired SpinLock as well!
    pSrbDataPacket = pInfo->Context;

    if(!pSrbDataPacket) {
        ASSERT(pSrbDataPacket);
        return 1;
    }


    pStrmExt = pSrbDataPacket->pStrmExt;
    ASSERT(pStrmExt);

    KeAcquireSpinLock(pStrmExt->DataListLock, &oldIrql);

    ASSERT(pSrbDataPacket->pSrb);

    pSrb     = pSrbDataPacket->pSrb;

    pDevExt  = pStrmExt->pDevExt;
    plSrbUseCount = (PLONG) pSrb->SRBExtension;

    // Check return Status
    if(!NT_SUCCESS(pSrbDataPacket->Frame->Status)) {        
        TRACE(TL_CIP_ERROR,("\'DVCompleteSrbWrite: %d: Frame->Status %x\n", (DWORD) pSrbDataPacket->FrameNumber, pSrbDataPacket->Frame->Status));
        ASSERT(NT_SUCCESS(pSrbDataPacket->Frame->Status));
        pSrb->Status = STATUS_UNSUCCESSFUL;            
    }
    else {
        pSrb->Status = STATUS_SUCCESS;
    }

    (*plSrbUseCount) --;          // This count need to be 0 before the SRB is completed.
    ASSERT(*plSrbUseCount >= 0);

#if DBG
    if(pSrbDataPacket->StreamState == KSSTATE_PAUSE) {
        pStrmExt->lPrevCycleCount = pSrbDataPacket->Frame->Timestamp.CL_CycleCount;
        pStrmExt->lTotalCycleCount = 0;
        pStrmExt->lFramesAccumulatedRun = 0;
        pStrmExt->lFramesAccumulatedPaused++;

    } else if(pSrbDataPacket->StreamState == KSSTATE_RUN) {

        if((LONG) pSrbDataPacket->Frame->Timestamp.CL_CycleCount > pStrmExt->lPrevCycleCount) 
            lCycleCountElapsed = pSrbDataPacket->Frame->Timestamp.CL_CycleCount - pStrmExt->lPrevCycleCount;
        else
            lCycleCountElapsed = pSrbDataPacket->Frame->Timestamp.CL_CycleCount + 8000 - pStrmExt->lPrevCycleCount;

        if(lCycleCountElapsed <= (LONG) DVFormatInfoTable[pDevExt->VideoFormatIndex].ulSrcPackets) {
            TRACE(TL_CIP_WARNING, ("\'#### CycleCounts between frames %d <= expected %d + empty pkt?\n", 
                lCycleCountElapsed,
                DVFormatInfoTable[pDevExt->VideoFormatIndex].ulSrcPackets
                ));
        }

        pStrmExt->lTotalCycleCount += lCycleCountElapsed;
        pStrmExt->lFramesAccumulatedRun++;

        TRACE(TL_CIP_TRACE,("\'%d) Attached:%d; pSrb:%x; FmSt:%x; CyTm:[SC:%d:CC:%d]; CyclElaps:%d; fps:%d/%d\n",
            (DWORD) pSrbDataPacket->FrameNumber,
            pStrmExt->cntDataAttached,
            pSrb,
            pSrbDataPacket->Frame->Status,
            pSrbDataPacket->Frame->Timestamp.CL_SecondCount,
            pSrbDataPacket->Frame->Timestamp.CL_CycleCount,
            lCycleCountElapsed,
            pStrmExt->lTotalCycleCount,
            (DWORD) pStrmExt->lFramesAccumulatedRun
            ));

        pStrmExt->lPrevCycleCount = pSrbDataPacket->Frame->Timestamp.CL_CycleCount;
    } else {
        TRACE(TL_CIP_ERROR,("\'This data was attached at %d state ?????\n", pSrbDataPacket->StreamState));
    }


#endif

    TRACE(TL_CIP_INFO,("\'%d) FmSt %x; Cnt %d; CyTm:[%d:%d:%d]; PrevCyclCnt:%d\n", 
        (DWORD) pSrbDataPacket->FrameNumber,
        pSrbDataPacket->Frame->Status,
        *plSrbUseCount,
        pSrbDataPacket->Frame->Timestamp.CL_SecondCount,
        pSrbDataPacket->Frame->Timestamp.CL_CycleCount,
        pSrbDataPacket->Frame->Timestamp.CL_CycleOffset,
        pStrmExt->lPrevCycleCount
        ));    

    TRACE(TL_CIP_INFO,("\'DVCompleteSrbWrite: Frm:%d; Attached:%d; cntUse:%d, Srb:%x; FrmSt:%x; CyclElaps:%d\n",
        (DWORD) pSrbDataPacket->FrameNumber,
        pStrmExt->cntDataAttached,
        *plSrbUseCount,
        pSrb,
        pSrbDataPacket->Frame->Status,
        lCycleCountElapsed
        ));


    //
    // Mark completion is called.
    //
    pSrbDataPacket->State |= DE_IRP_CALLBACK_COMPLETED;


    //
    // Attached->Completed or Completed->Attached.
    //
    if(IsStateSet(pSrbDataPacket->State, DE_IRP_ATTACHED_COMPLETED)) {

        //
        // Recycle it back to the detach list
        //
        RemoveEntryList(&pSrbDataPacket->ListEntry); pStrmExt->cntDataAttached--;  ASSERT(pStrmExt->cntDataAttached >= 0);
        InsertTailList(&pStrmExt->DataDetachedListHead, &pSrbDataPacket->ListEntry); pStrmExt->cntDataDetached++;

#if DBG
        // Detect if 61883 is starve.  This cause discontinuity.
        // This can happen for many valid reasons (slow system).
        // An assert is added to detect other unknown reason.
        if(!pStrmExt->bEOStream && pStrmExt->cntDataAttached == 0 && pStrmExt->StreamState == KSSTATE_RUN) {
            TRACE(TL_STRM_WARNING|TL_CIP_WARNING,("\n**** 61883 starve in RUN state (write);AQD[%d:%d:%d]\n\n", 
                pStrmExt->cntDataAttached, pStrmExt->cntSRBQueued, pStrmExt->cntDataDetached
            ));
            if (pStrmExt->pStrmInfo->DataFlow == KSPIN_DATAFLOW_IN) {
                // ASSERT(pStrmExt->cntDataAttached > 0 && "61883 is starve at RUN state!!");
            }
        }
#endif

        // Complete this SRB only if the count is 0.
        if(*plSrbUseCount == 0) {

            TRACE(TL_CIP_TRACE,("\'------------ Srb:%x completing..----------------\n", pSrb));
            // Frame that possibly made it to the device
            pStrmExt->FramesProcessed++;
            pSrb->CommandData.DataBufferArray->DataUsed = DVFormatInfoTable[pDevExt->VideoFormatIndex].ulFrameSize;

            StreamClassStreamNotification(StreamRequestComplete, pStrmExt->pStrmObject, pSrbDataPacket->pSrb );  
            pSrbDataPacket->State |= DE_IRP_SRB_COMPLETED;  pSrbDataPacket->pSrb = NULL;
#if DBG
            pStrmExt->cntSRBPending--;
#endif
        }

    } else {

        TRACE(TL_STRM_WARNING,("CompleteSrbWrite: pSrbDataPacket:%x; Completed before attach.\n", pSrbDataPacket));

    }


#if DBG
    // Collect transmit buffer statistics
    if((pStrmExt->lFramesAccumulatedPaused + pStrmExt->lFramesAccumulatedRun) <= MAX_XMT_FRAMES_TRACED) {
        pXmtStat = pStrmExt->paXmtStat + (pStrmExt->lFramesAccumulatedPaused + pStrmExt->lFramesAccumulatedRun - 1);
        pXmtStat->tsTransmitted  = pSrbDataPacket->Frame->Timestamp;
        if(pSrbDataPacket->Frame->Timestamp.CL_CycleCount == 0) {
            TRACE(TL_CIP_WARNING,("\'PAUSE:%d; RUN:%d; %d:%d\n", pStrmExt->lFramesAccumulatedPaused, pStrmExt->lFramesAccumulatedRun,
                pSrbDataPacket->Frame->Timestamp.CL_SecondCount, pSrbDataPacket->Frame->Timestamp.CL_CycleCount));
        }        
    }
#endif


    // Signal that all SRBs have been attached and transmitted.
    if(pStrmExt->bEOStream) {
        if(pStrmExt->cntDataAttached == 0 && pStrmExt->cntSRBQueued == 0) {

            //
            // Signal any pending clock events
            //
            DVSignalClockEvent(0, pStrmExt, 0, 0);

            //
            // No data request queued or pending; it is time to signal EOStream to 
            // trigger EC_COMPLETE.
            //
            StreamClassStreamNotification(
                SignalMultipleStreamEvents,
                pStrmExt->pStrmObject,
                (GUID *)&KSEVENTSETID_Connection_Local,
                KSEVENT_CONNECTION_ENDOFSTREAM
                ); 

            TRACE(TL_CIP_WARNING,("\'*-*-* EOStream Signalled: pSrb:%x completed; AQD [%d:%d:%d]; Took %d msec;\n", 
                pSrb, pStrmExt->cntDataAttached, pStrmExt->cntSRBQueued, pStrmExt->cntDataDetached,
                (DWORD) ((GetSystemTime() - pStrmExt->tmStreamStart)/(ULONGLONG) 10000)));
        }
        else {
            TRACE(TL_CIP_TRACE,("\'   *EOStream: pSrb:%x completed; cntAttached:%d; cntSRBQ:%d\n", pSrb, (DWORD) pStrmExt->cntDataAttached, (DWORD) pStrmExt->cntSRBQueued));
        }
    } 


    //
    // If we are not in the ending situtation (EOS pr Stop state) and number of
    // attach data request is below a threashold, we singal an event to the
    // code that does "throttle" to quickly attach another frame.
    //

    if(!pStrmExt->bEOStream || 
       (pStrmExt->bEOStream && pStrmExt->cntSRBQueued > 0)) {

        if(pStrmExt->StreamState != KSSTATE_STOP && 
           pStrmExt->cntDataAttached < NUM_BUF_ATTACHED_THEN_ISOCH) {
            KeSetEvent(&pStrmExt->hSrbArriveEvent, 0, FALSE);
            TRACE(TL_CIP_WARNING,("Threadshold:.AQD:[%d %d %d] < %d\n",
                pStrmExt->cntDataAttached,
                pStrmExt->cntSRBQueued,
                pStrmExt->cntDataDetached,
                NUM_BUF_ATTACHED_THEN_ISOCH
                ));
        }
    }

    KeReleaseSpinLock(pStrmExt->DataListLock, oldIrql); 

    return 0;
} // DVCompleteSrbWrite



NTSTATUS
DVAttachWriteFrame(
    IN PSTREAMEX  pStrmExt
    )
/*++

Routine Description:

    Prepare and submit a frame to 61883 for transmit.   

--*/
{
    KIRQL   oldIrql;
    PSRB_DATA_PACKET pSrbDataPacket;
    PSRB_ENTRY  pSrbEntry;
#if DBG
    ULONG  SrbNumCache;  // Cache the SRB number of tracking purpose
    PXMT_FRAME_STAT pXmtStat;
#endif
    PHW_STREAM_REQUEST_BLOCK pSrb;
    PHW_STREAM_REQUEST_BLOCK pSrbNext; 
    PVOID               pFrameBuffer;
    PIO_STACK_LOCATION  NextIrpStack;
    NTSTATUS Status;
    PLONG plSrbUseCount; // When this count is 0, it can be completed.
    ULONG  ulSrcPktLen;
    LARGE_INTEGER Timeout;  


    PAGED_CODE();


    // Serialize setting state to STOP
    if(pStrmExt->StreamState != KSSTATE_PAUSE && 
       pStrmExt->StreamState != KSSTATE_RUN) {

        TRACE(TL_CIP_WARNING,("\'DVAttachWriteFrame: StreamState:%d; no attach! Wait!\n", pStrmExt->StreamState));              
        Timeout.HighPart = -1;
        Timeout.LowPart  = (ULONG)(-1 * DVFormatInfoTable[pStrmExt->pDevExt->VideoFormatIndex].ulAvgTimePerFrame); 
        KeDelayExecutionThread(KernelMode, FALSE, &Timeout);
        return STATUS_SUCCESS; 
    }


    KeAcquireSpinLock(pStrmExt->DataListLock, &oldIrql);

    if(IsListEmpty(&pStrmExt->SRBQueuedListHead) ||
       IsListEmpty(&pStrmExt->DataDetachedListHead) ) {              
        KeReleaseSpinLock(pStrmExt->DataListLock, oldIrql);
#if DBG        
        if(!pStrmExt->bEOStream) {
            TRACE(TL_CIP_WARNING,("\'StrmSt:%d; DetachList or SrbQ empty: EOStream:%d; AQD [%d:%d:%d]; Wait one frame time.\n", 
                pStrmExt->StreamState,
                pStrmExt->bEOStream,
                pStrmExt->cntDataAttached,
                pStrmExt->cntSRBQueued,
                pStrmExt->cntDataDetached
                ));
        }
#endif
        Timeout.HighPart = -1;
        Timeout.LowPart  = (ULONG)(-1 * DVFormatInfoTable[pStrmExt->pDevExt->VideoFormatIndex].ulAvgTimePerFrame); 
        KeDelayExecutionThread(KernelMode, FALSE, &Timeout);
        // SRB is queued so it is OK. We will process that later.
        // This is usually cause by receiving more than what we pre-allocate.
        return STATUS_SUCCESS; 
    }


    // KSSTATE_PAUSE: "reuse" head of the SrbQ.
    // KSSTATE_RUN:   "remove" a Srb from the queue.

      
    // Get NEXT(SrbQ) and determine if it needs to be removed.
    pSrbEntry = (PSRB_ENTRY) pStrmExt->SRBQueuedListHead.Flink; pSrb = pSrbEntry->pSrb; plSrbUseCount = (PLONG) pSrb->SRBExtension;
    ASSERT(*plSrbUseCount >= 0);
#if DBG
    SrbNumCache = pSrbEntry->SrbNum;
#endif

    // Get a a nonpaged system-space virtual address for the buffer
    // This could fail it there is not enough system resource (MDL).
#ifdef USE_WDM110 // Win2000
    //
    // Driver verifier flag to use this but if this is used, this driver will not load for Millen!!!
    //
    pFrameBuffer = MmGetSystemAddressForMdlSafe(pSrb->Irp->MdlAddress, NormalPagePriority);
#else
    pFrameBuffer = MmGetSystemAddressForMdl    (pSrb->Irp->MdlAddress);
#endif
    if(pFrameBuffer == NULL) {      
        KeReleaseSpinLock(pStrmExt->DataListLock, oldIrql);
        ASSERT(FALSE && "Insufficient MDL\n");
        return STATUS_INSUFFICIENT_RESOURCES; 
    }

    // Only in RUN state, the stream time in the Srb is considered and Srbs in the SrbQ will be dequeued.
    if(pStrmExt->StreamState == KSSTATE_RUN) {

#define ALLOWABLE_TIMING_LATENCY TIME_PER_CYCLE

        // Presentation time is honor only if we are the master clock.
        if(pStrmExt->hMasterClock) {

            LONGLONG tmExpectedFrame;


            if(   pStrmExt->pDevExt->VideoFormatIndex == FMT_IDX_SD_DVCR_PAL 
               || pStrmExt->pDevExt->VideoFormatIndex == FMT_IDX_SDL_DVCR_PAL
               )
                tmExpectedFrame = pStrmExt->PictureNumber * (LONGLONG) FRAME_TIME_PAL;
            else {
                tmExpectedFrame = (pStrmExt->PictureNumber * (LONGLONG) 1000 * (LONGLONG) 1001 ) / (LONGLONG) 3;  // trouble NTSC!
                // Adjustment for rounding
                if((pStrmExt->PictureNumber % 3) == 1)
                    tmExpectedFrame++;
            }

            // Use to adjust the querued stream time.
            pStrmExt->LastSystemTime = GetSystemTime();

            // There are three situations about the NEXT(SrbQ) comparing with tmExpectedFrame:            
            //    1. Early; 2. OnTime; 3.Late
            //
            //                  tmExpectedFrame
            //                        |
            // 3>------------2>-----------------1>---------------
            //    3.Late     |   2.On  Time     |  1.Early
            //               |    x   |   x     |
            //  where "x" is the allowable latency (for calculation rounding)
            //
            // Note: allow TIME_PER_CYCLE latency                 
/*Early*/   
/*N+1/++*/  if((tmExpectedFrame + ALLOWABLE_TIMING_LATENCY) <= pSrb->CommandData.DataBufferArray->PresentationTime.Time) { 
            // FUTURE: if a frame arrive sooner than expected, do not remove SrbQ; 
            // instead, repeat until passing its "scheduled departure".

                // Remove NEXT(SrbQ) only if bEOStream
                if(pStrmExt->bEOStream) {
                    TRACE(TL_CIP_TRACE,("\'EOStream=== Srb:%x; (SrbNum:%d ?= PicNum:%d) cntSrbQ:%d; Attach:%d ===\n", 
                        pSrb, pSrbEntry->SrbNum, (DWORD) pStrmExt->PictureNumber, (DWORD) pStrmExt->cntSRBQueued, (DWORD) pStrmExt->cntDataAttached));
                    RemoveEntryList(&pSrbEntry->ListEntry); pStrmExt->cntSRBQueued--; (*plSrbUseCount)--;
                    ExFreePool(pSrbEntry);  pSrbEntry = NULL;  // Removed so free it! 
                }                         
                TRACE(TL_CIP_TRACE,("\'** Repeat: pSrb:%x; RefCnt:%d; cntSrbQ:%d; PicNum:%d; Drp:%d; PresTime:%d >= CurTime:%d\n", 
                    pSrb, *plSrbUseCount, pStrmExt->cntSRBQueued, (DWORD) pStrmExt->PictureNumber, (DWORD) pStrmExt->FramesDropped, 
                    (DWORD) (pSrb->CommandData.DataBufferArray->PresentationTime.Time/10000), (DWORD) tmExpectedFrame/10000));                

/*OnTime*/  } else 
/* N */     if((tmExpectedFrame - ALLOWABLE_TIMING_LATENCY) <= pSrb->CommandData.DataBufferArray->PresentationTime.Time) {
            // ON-TIME: may exactly matching or due to integer calculation, within one frame time.
            // Dequeue if there are more than one Srb in the queue. 
#if DBG
                // Detect if a pSrb is used more than once
                if((*plSrbUseCount) > 1) {                   
                    TRACE(TL_CIP_TRACE,("\'* Go: pSrb:%x; RefCnt:%d; cntSrbQ:%d; PicNum:%d; Drp:%d; PresTime:%d >= CurTime:%d\n", 
                        pSrb, *plSrbUseCount, pStrmExt->cntSRBQueued, (DWORD) pStrmExt->PictureNumber, (DWORD) pStrmExt->FramesDropped, 
                        (DWORD) (pSrb->CommandData.DataBufferArray->PresentationTime.Time/10000), (DWORD) tmExpectedFrame/10000)); 
                }
#endif
                if(pStrmExt->bEOStream) {
                // Remove NEXT(SrbQ) only if there are more than one SRB or bEOStream
                    TRACE(TL_CIP_TRACE,("\'EOStream=== Srb:%x; (SrbNum:%d ?= PicNum:%d) cntSrbQ:%d; Attach:%d ===\n", 
                        pSrb, pSrbEntry->SrbNum, (DWORD) pStrmExt->PictureNumber, (DWORD) pStrmExt->cntSRBQueued, (DWORD) pStrmExt->cntDataAttached));
                    RemoveEntryList(&pSrbEntry->ListEntry); pStrmExt->cntSRBQueued--; (*plSrbUseCount)--;
                    ExFreePool(pSrbEntry);  pSrbEntry = NULL;  // Removed so free it! 
                // Remove SRB if more than one SRBs in Q and there is not a discontinuity, or end of stream.
                } else if(pStrmExt->cntSRBQueued > 1) {
                    LONGLONG tmExpectedNextFrame = tmExpectedFrame + DVFormatInfoTable[pStrmExt->pDevExt->VideoFormatIndex].ulAvgTimePerFrame;

                    pSrbNext = ((SRB_ENTRY *) (pSrbEntry->ListEntry.Flink))->pSrb;                        

                    // Next SRB has the next presentation time
                    // May add this check as well: (but check Presentation time is more reliable)
                    //    pSrb->CommandData.DataBufferArray->OptionsFlags & KSSTREAM_HEADER_OPTIONSF_DATADISCONTINUITY
/* N,N+1 */         if((tmExpectedNextFrame + ALLOWABLE_TIMING_LATENCY) > pSrbNext->CommandData.DataBufferArray->PresentationTime.Time) { 

                        TRACE(TL_CIP_TRACE,("\'=== Srb:%x; (SrbNum:%d ?= PicNum:%d) cntSrbQ:%d; Attach:%d ===\n", 
                           pSrb, pSrbEntry->SrbNum, (DWORD) pStrmExt->PictureNumber, (DWORD) pStrmExt->cntSRBQueued, (DWORD) pStrmExt->cntDataAttached));
                        RemoveEntryList(&pSrbEntry->ListEntry); pStrmExt->cntSRBQueued--; (*plSrbUseCount)--;
                        ExFreePool(pSrbEntry);  pSrbEntry = NULL;  // Removed so free it! 

/* N, N+2/++ */     } else {
                        TRACE(TL_CIP_TRACE,("\'=== GO(Stale=TRUE) Srb:%x; (SrbNum:%d ?= PicNum:%d) Attach:%d ==\n", 
                            pSrb, pSrbEntry->SrbNum, (DWORD) pStrmExt->PictureNumber, (DWORD) pStrmExt->cntDataAttached));
                        // Mark this stale and be remove as soon as another is attached.
                    }                       
                } 
                else {
                    TRACE(TL_CIP_TRACE,("\'=== GO(Stale=TRUE) Srb:%x; (SrbNum:%d ?= PicNum:%d) Attach:%d ==\n", 
                        pSrb, pSrbEntry->SrbNum, (DWORD) pStrmExt->PictureNumber, (DWORD) pStrmExt->cntDataAttached));
                    // Mark this stale and be remove as soon as another is attached.
                    pSrbEntry->bStale = TRUE;
                }

                 // CLOCK: tick when a frame is transmitted.   
        
            // LATE: this is dropped until there is only one Srb in the SrbQ.
            // WORKITEM: we may need to implement IQualityManagement to inform application to read ahead.
/*Late*/    } 
/*N-1*/     else {

                if(pStrmExt->cntSRBQueued > 1) {

                    pSrbNext = ((SRB_ENTRY *) (pSrbEntry->ListEntry.Flink))->pSrb;                        

                    // Next SRB has the next presentation time; it can be:
                    // Current time is N
                    // Current frame is late (N-1 or N-2..) and we have more than one Srb in the queue; 
                    // check next frame:
                    //     (N?)
                    // N-2, N-1, N  late more than one frame; (Next frame is also late; dequeu and not transmit; "catch up" case.)
                    // N-1, N       late one frame; (Next frame is on time; dequeu this frame) <-- Normal case
                    // N-1, N+1     late one frame, but next frame is not N+1; (Next frame is early; *current frame will be repeated*) 
                    // 
                    // May add this check this as well: (but check Presentation time is more reliable)
                    //    pSrb->CommandData.DataBufferArray->OptionsFlags & KSSTREAM_HEADER_OPTIONSF_DATADISCONTINUITY
                    //
                    // ******************************************************************************************************
                    // If next frame is earlier than current stream time, "repeat" current stale frame; else we need to "catch up"!
                    // ******************************************************************************************************     
/* N-1++, N */      if((tmExpectedFrame + ALLOWABLE_TIMING_LATENCY) > pSrbNext->CommandData.DataBufferArray->PresentationTime.Time) {

                        TRACE(TL_CIP_TRACE,("\'*** Stale(not Sent): pSrb:%x; RefCnt:%d; cntSrbQ:%d; cntAtt:%d; PicNum:%d; Drp:%d; PTm:%d < ExpTm:%d\n", 
                            pSrb, *plSrbUseCount, pStrmExt->cntSRBQueued, pStrmExt->cntDataAttached, (DWORD) pStrmExt->PictureNumber, (DWORD) pStrmExt->FramesDropped, 
                            (DWORD) (pSrb->CommandData.DataBufferArray->PresentationTime.Time/10000), (DWORD) (tmExpectedFrame/10000) )); 

                        // Never been attached; remove late entry
                        RemoveEntryList(&pSrbEntry->ListEntry); pStrmExt->cntSRBQueued--; (*plSrbUseCount)--;
                        ExFreePool(pSrbEntry);  pSrbEntry = NULL;  // Removed so free it!

                        if(*plSrbUseCount == 0) {
                            // If no reference to is, complete this.
                            pSrb->Status = STATUS_SUCCESS;  // It is not a failure but late; maybe other status to indicate "non-fatal" late status..
                            pSrb->CommandData.DataBufferArray->DataUsed = 0;
                            StreamClassStreamNotification(StreamRequestComplete, pSrb->StreamObject, pSrb);
#if DBG
                            pStrmExt->cntSRBPending--;
#endif
                        }
                       
                        KeReleaseSpinLock(pStrmExt->DataListLock, oldIrql);

                        // Since SrbQ is not empty and this is a stale frame, call recursively to get to next frame.
                        // Only possible error is if there is not sufficient resource (esp MDL)
                        // then, we bail out by self terminating this thread.
                        if(STATUS_INSUFFICIENT_RESOURCES == 
                           DVAttachWriteFrame(pStrmExt)) {
                            TRACE(TL_CIP_ERROR,("DVAttachWriteFrame: STATUS_INSUFFICIENT_RESOURCES\n")); 
                            return STATUS_INSUFFICIENT_RESOURCES;
                        } else {
                            return STATUS_SUCCESS;  // SUCESS unless there is another status to indicate "non-fatal" late.
                        }
/*N-2++, N-1++*/    } else {
                        pSrbEntry->bStale = TRUE;
                    }
                }
                else {
                    // EOStream and is a stale stream, it is the last element in SrbQ.
                    // Remove it.
                    if(pStrmExt->bEOStream) {
                        TRACE(TL_CIP_TRACE,("\'*** Stale(bEOStream): pSrb:%x; RefCnt:%d; cntSrbQ:%d; cntAtt:%d; PicNum:%d; Drp:%d; PTm:%d < ExpTm:%d\n", 
                            pSrb, *plSrbUseCount, pStrmExt->cntSRBQueued, pStrmExt->cntDataAttached, (DWORD) pStrmExt->PictureNumber, (DWORD) pStrmExt->FramesDropped, 
                            (DWORD) (pSrb->CommandData.DataBufferArray->PresentationTime.Time/10000), (DWORD) (tmExpectedFrame/10000) )); 

                        RemoveEntryList(&pSrbEntry->ListEntry); pStrmExt->cntSRBQueued--; (*plSrbUseCount)--;
                        ExFreePool(pSrbEntry);  pSrbEntry = NULL;  // Removed so free it!
                        if(*plSrbUseCount == 0) {
                            // If no reference to is, complete this.
                            pSrb->Status = STATUS_SUCCESS;  // It is not a failure but late; maybe other status to indicate "non-fatal" late status..
                            pSrb->CommandData.DataBufferArray->DataUsed = 0;
                            StreamClassStreamNotification(StreamRequestComplete, pSrb->StreamObject, pSrb);
#if DBG
                            pStrmExt->cntSRBPending--;
#endif
                        }
                       
                        KeReleaseSpinLock(pStrmExt->DataListLock, oldIrql);

                        // Update current stream time
                        pStrmExt->CurrentStreamTime = tmExpectedFrame;

                        return STATUS_SUCCESS;  // SUCESS unless there is another status to indicate "non-fatal" late.
                    }

                    TRACE(TL_CIP_TRACE,("\'*** Stale(Sent): pSrb:%x; RefCnt:%d; cntSrbQ:%d; cntAtt:%d; PicNum:%d; Drp:%d; PTm:%d < ExpTm:%d\n", 
                        pSrb, *plSrbUseCount, pStrmExt->cntSRBQueued, pStrmExt->cntDataAttached, (DWORD) pStrmExt->PictureNumber, (DWORD) pStrmExt->FramesDropped, 
                        (DWORD) (pSrb->CommandData.DataBufferArray->PresentationTime.Time/10000), (DWORD) (tmExpectedFrame/10000) )); 

                    // If this is stale and this is the only frame in SrbQ, Xmt it
                }

                // If late, this frame is always drop.
                pStrmExt->FramesDropped++;
            } 

            // Update current stream time
            pStrmExt->CurrentStreamTime = tmExpectedFrame;

        } // if(pStrmExt->hMasterClock)
        else {
            // Not the master clock, no "pacing" so always dequeu (SrbQ) and transmit 
            // as long as there is one Srb in the queue.
            if(pStrmExt->cntSRBQueued > 1 || pStrmExt->bEOStream) {
                RemoveEntryList(&pSrbEntry->ListEntry); pStrmExt->cntSRBQueued--; (*plSrbUseCount)--;
                ExFreePool(pSrbEntry);  pSrbEntry = NULL;  // Removed so free it!
            }
            TRACE(TL_CIP_TRACE,("\'* GO: (NoClock) pSrb:%x; RefCnt:%d; cntSrbQ:%d; PicNum:%d;\n", pSrb, *plSrbUseCount, pStrmExt->cntSRBQueued, (DWORD) pStrmExt->PictureNumber));
        } // if(pStrmExt->hMasterClock)


        // pStrmExt->FramesProcessed is updated when a frame has been transmitted in the notify routine.
        // **** THIS IS THE CLOCK TICK ****
        pStrmExt->PictureNumber++;  // After tmExpectedFrame is calculated; Another frame to be attached
        if(pStrmExt->hMasterClock) {
#ifdef SUPPORT_QUALITY_CONTROL
            // +: late; -: early
            pStrmExt->KSQuality.DeltaTime = pStrmExt->CurrentStreamTime - pSrb->CommandData.DataBufferArray->PresentationTime.Time;
            // Percentage * 10 of frame transmitted
            pStrmExt->KSQuality.Proportion = (ULONG) 
                ((pStrmExt->PictureNumber - pStrmExt->FramesDropped) * 1000 / pStrmExt->PictureNumber);
            pStrmExt->KSQuality.Context = /* NOT USED */ 0; 
#define MIN_ATTACH_BUFFER  3
            // This is where we may want to signal that we are near Famine!!
            if (pStrmExt->KSQuality.DeltaTime > 
                (DV_NUM_OF_XMT_BUFFERS - MIN_ATTACH_BUFFER) * DVFormatInfoTable[pStrmExt->pDevExt->VideoFormatIndex].ulAvgTimePerFrame) {
                TRACE(TL_CIP_TRACE,("\'QualityControl: pic#%d; drop:%d; Prop:%d; DeltaTime:%d (Srb.tmPres:%d, tmStream:%d)\n",
                    (DWORD) pStrmExt->PictureNumber, 
                    (DWORD) pStrmExt->FramesDropped,
                    pStrmExt->KSQuality.Proportion,
                    (DWORD) pStrmExt->KSQuality.DeltaTime/10000,
                    (DWORD) pSrb->CommandData.DataBufferArray->PresentationTime.Time/10000,
                    (DWORD) pStrmExt->CurrentStreamTime/10000                    
                    ));
            }
#endif
        }
    }  // KSSTATE_RUN

#if DBG
    // Collect transmit buffer statistics    
    if(pStrmExt->ulStatEntries < MAX_XMT_FRAMES_TRACED) {
        pXmtStat = pStrmExt->paXmtStat + pStrmExt->ulStatEntries;
    
        pXmtStat->StreamState    = pStrmExt->StreamState;

        pXmtStat->cntSRBReceived = (LONG) pStrmExt->cntSRBReceived;
        pXmtStat->cntSRBPending  = (LONG) pStrmExt->cntSRBPending;
        pXmtStat->cntSRBQueued   = (LONG) pStrmExt->cntSRBQueued;
        pXmtStat->cntDataAttached= pStrmExt->cntDataAttached;

        pXmtStat->FrameSlot      = (DWORD) pStrmExt->PictureNumber;
        pXmtStat->tmStreamTime   = pStrmExt->CurrentStreamTime;

        pXmtStat->DropCount      = (DWORD) pStrmExt->FramesDropped;

        pXmtStat->FrameNumber    = SrbNumCache;
        pXmtStat->OptionsFlags   = pSrb->CommandData.DataBufferArray->OptionsFlags;
        pXmtStat->tmPresentation = pSrb->CommandData.DataBufferArray->PresentationTime.Time;

        // get the actual CyclTime when the frame is transmitted in the completion routine.

        pStrmExt->ulStatEntries++;
    }
    
#endif

#ifdef MSDV_SUPPORT_MUTE_AUDIO
    // pSrbEntry could have been freed; if it has not and useCnt>1, then it could be a repeat frame.
    if(pSrbEntry && (*plSrbUseCount) > 1) {  
        // Set it only once
        if(!pSrbEntry->bAudioMute)
            pSrbEntry->bAudioMute = 
                DVMuteDVFrame(pStrmExt->pDevExt, pFrameBuffer, TRUE);
    }
#endif
 


    // Get a data packet node as the context and list node

    pSrbDataPacket = (PSRB_DATA_PACKET) RemoveHeadList(&pStrmExt->DataDetachedListHead); pStrmExt->cntDataDetached--;
    
    ulSrcPktLen = \
        (DVFormatInfoTable[pStrmExt->pDevExt->VideoFormatIndex].DataBlockSize << 2) * \
            (1 << DVFormatInfoTable[pStrmExt->pDevExt->VideoFormatIndex].FractionNumber);  

    // Format an attach frame request
    DVFormatAttachFrame(
        pStrmExt->pStrmInfo->DataFlow,
        pStrmExt,
        &pSrbDataPacket->AVReq,
        pSrb,
        pSrbDataPacket,
        ulSrcPktLen,
        DVFormatInfoTable[pStrmExt->pDevExt->VideoFormatIndex].ulFrameSize,
        pFrameBuffer
        );

    TRACE(TL_CIP_INFO,("\'------ New>> UseCnt:%d; pAVReq:%x; Srb:%x; DtaPkt:%x; AQD [%d:%d:%d]\n",
        *plSrbUseCount,
        &pSrbDataPacket->AVReq, 
        pSrb, 
        pSrbDataPacket,
        pStrmExt->cntDataAttached,
        pStrmExt->cntSRBQueued,
        pStrmExt->cntDataDetached
        ));
 
    // Add this to the attached list
    InsertTailList(&pStrmExt->DataAttachedListHead, &pSrbDataPacket->ListEntry); pStrmExt->cntDataAttached++;
    (*plSrbUseCount) ++;  // ++ for being in queue
    ASSERT(*plSrbUseCount > 0);        

    KeReleaseSpinLock(pStrmExt->DataListLock, oldIrql); 

    NextIrpStack = IoGetNextIrpStackLocation(pSrbDataPacket->pIrp);
    NextIrpStack->MajorFunction = IRP_MJ_INTERNAL_DEVICE_CONTROL;
    NextIrpStack->Parameters.DeviceIoControl.IoControlCode = IOCTL_61883_CLASS;
    NextIrpStack->Parameters.Others.Argument1 = &pSrbDataPacket->AVReq;

    IoSetCompletionRoutine(
        pSrbDataPacket->pIrp, 
        DVAttachFrameCR, 
        pSrbDataPacket, 
        TRUE, 
        TRUE, 
        TRUE
        );

    pSrbDataPacket->pIrp->IoStatus.Status = STATUS_SUCCESS;  // Initialize it to something

    Status = IoCallDriver( pStrmExt->pDevExt->pBusDeviceObject, pSrbDataPacket->pIrp);

    ASSERT(Status == STATUS_PENDING || Status == STATUS_SUCCESS);

    if(!NT_SUCCESS(Status)) {
        // put the resource back!
        TRACE(TL_CIP_ERROR,("DVAttachWriteFrame: Failed to attach; St:%x\n", Status));
        ASSERT(FALSE && "Failed to attach a Xmt frame.");
    }


    //
    // This is our throttle that regulate data attach to DV:
    //
    // This function is called by the attach thread which is running in an infinite loop.
    // This function need to utilize the buffer that it receive and its repeat mechanism to 
    // regulate the incoming buffer from client and outgoing buffer attach to 1394 stadck for transmit.
    // One way is to wait while there is certain number of frame already attach.

    KeAcquireSpinLock(pStrmExt->DataListLock, &oldIrql);
    if(!pStrmExt->bEOStream &&
        // Need to keep NUM_BUF_ATTACHED_THEN_ISOCH buffer attached at all time to keep 61883 isoch xmt going.
       (pStrmExt->StreamState == KSSTATE_RUN   && pStrmExt->cntDataAttached >  NUM_BUF_ATTACHED_THEN_ISOCH || 
        pStrmExt->StreamState == KSSTATE_PAUSE && pStrmExt->cntDataAttached >= NUM_BUF_ATTACHED_THEN_ISOCH )
        ) {
        NTSTATUS StatusDelay = STATUS_SUCCESS;
#if DBG
        ULONGLONG tmStart = GetSystemTime();
        TRACE(TL_CIP_TRACE,("\'[Pic# %d]; SrbNum:%d; Dropped:%d; pSrb:%x; StrmSt:%d; EOS:%d; AQD:[%d;%d;%d]; ",  
            (DWORD) pStrmExt->PictureNumber, SrbNumCache, (DWORD) pStrmExt->FramesDropped, pSrb, pStrmExt->StreamState, pStrmExt->bEOStream,
            pStrmExt->cntDataAttached, pStrmExt->cntSRBQueued, pStrmExt->cntDataDetached));
#endif
        Timeout.HighPart = -1;
        Timeout.LowPart  = (ULONG)(-1 * DVFormatInfoTable[pStrmExt->pDevExt->VideoFormatIndex].ulAvgTimePerFrame * \
            (pStrmExt->StreamState == KSSTATE_PAUSE ? 1 : (pStrmExt->cntDataAttached - NUM_BUF_ATTACHED_THEN_ISOCH))) ; 

        // Wait the full time until we are very low in SrbQ or Attached buffers.
        if(pStrmExt->cntSRBQueued <= 1 && pStrmExt->cntDataAttached <= NUM_BUF_ATTACHED_THEN_ISOCH) {

            KeReleaseSpinLock(pStrmExt->DataListLock, oldIrql); // Guard against pStrmExt->cntSRBQueued
            // Down to one frame so we will wait for an event and will be signalled 
            // when a new frame has arrived, or
            // when number of attach buffer is below the minimum.
            StatusDelay = 
                KeWaitForSingleObject(
                    &pStrmExt->hSrbArriveEvent, 
                    Executive, 
                    KernelMode, 
                    FALSE, 
                    &Timeout
                    );

            // Important:  If signalled, reset it else (timeout), 
            // we are still behind so next time we will not wait!
            if(StatusDelay == STATUS_SUCCESS)
                KeClearEvent(&pStrmExt->hSrbArriveEvent);
        } 
        else {
            KeReleaseSpinLock(pStrmExt->DataListLock, oldIrql); 
            // Wait for frame(s) to be delivered; this is our throttle..
            // The timeout period can be one or up to 
            // (pStrmExt->cntDataAttached - NUM_BUF_ATTACHED_THEN_ISOCH) frames
            KeDelayExecutionThread(KernelMode, FALSE, &Timeout);
        }

#if DBG
        TRACE(TL_CIP_TRACE,("\'Wait(ST:%x) %d nsec!\n", StatusDelay, (DWORD) ((GetSystemTime() - tmStart)/10)));
#endif
    } else {
        KeReleaseSpinLock(pStrmExt->DataListLock, oldIrql); 
    }

    return Status;
}


VOID
DVFormatAttachFrame(
    IN KSPIN_DATAFLOW   DataFlow,
    IN PSTREAMEX        pStrmExt,    
    IN PAV_61883_REQUEST   pAVReq,
    IN PHW_STREAM_REQUEST_BLOCK       pSrb,
    IN PSRB_DATA_PACKET pSrbDataPacket,
    IN ULONG            ulSourceLength,    // Packet length in bytes
    IN ULONG            ulFrameSize,        // Buffer size; may contain one or multiple source packets
    IN PVOID            pFrameBuffer
    )
/*++

Routine Description:

    Format an attach frame request.

--*/
{

    ASSERT(pSrb);


    //
    // Setup PSRB_DATA_PACKET, except its Frame structure (PCIP_APP_FRAME)
    //

    InitializeListHead(&pSrbDataPacket->ListEntry);

    pSrbDataPacket->State       = DE_PREPARED;   // Initial state of a resued DataEntry (start over!)

    pSrbDataPacket->pSrb        = pSrb;
    pSrbDataPacket->StreamState = pStrmExt->StreamState;    // StreamState when this buffer is attached.
    pSrbDataPacket->pStrmExt    = pStrmExt;
    pSrbDataPacket->FrameBuffer = pFrameBuffer;

    ASSERT(pSrbDataPacket->FrameBuffer != NULL);

    pSrbDataPacket->Frame->pNext           = NULL;
    pSrbDataPacket->Frame->Status          = 0;
    pSrbDataPacket->Frame->Packet          = (PUCHAR) pFrameBuffer;

    if(DataFlow == KSPIN_DATAFLOW_OUT) {
        pSrbDataPacket->FrameNumber            = pStrmExt->cntSRBReceived;
#ifdef NT51_61883

        // This is needed since we have an old 61883.h in Lab06 (according to include path, anyway).
        // Remove this when 61883.h is updated.
#ifndef CIP_RESET_FRAME_ON_DISCONTINUITY
#define CIP_RESET_FRAME_ON_DISCONTINUITY    0x00000040
#endif

        //
        // Set CIP_USE_SOURCE_HEADER_TIMESTAMP to get 25 bit CycleTime from source packet header (13CycleCount:12CycleOffset)
        // Do not set this to get 16 bit CycleTime from isoch packet (3 SecondCount:13CycleCount)
        // 
        pSrbDataPacket->Frame->Flags           =   CIP_VALIDATE_FIRST_SOURCE         // Verify the start of a DV frame
                                                 | CIP_RESET_FRAME_ON_DISCONTINUITY; // No partial frame
#else
        pSrbDataPacket->Frame->Flags           = 0;
#endif
        pSrbDataPacket->Frame->pfnValidate     = DVReadFrameValidate;                // use to validate the 1st source packet
        pSrbDataPacket->Frame->ValidateContext = pSrbDataPacket;
        pSrbDataPacket->Frame->pfnNotify       = DVCompleteSrbRead;
    } 
    else {
        pSrbDataPacket->FrameNumber            = pStrmExt->FramesProcessed;
        pSrbDataPacket->Frame->Flags           = CIP_DV_STYLE_SYT;
        pSrbDataPacket->Frame->pfnValidate     = NULL;
        pSrbDataPacket->Frame->ValidateContext = NULL;
        pSrbDataPacket->Frame->pfnNotify       = DVCompleteSrbWrite;
    }
    pSrbDataPacket->Frame->NotifyContext       = pSrbDataPacket;

    //
    // Av61883_AttachFrames
    //
    RtlZeroMemory(pAVReq, sizeof(AV_61883_REQUEST));
    INIT_61883_HEADER(pAVReq, Av61883_AttachFrame);
    pAVReq->AttachFrame.hConnect     = pStrmExt->hConnect;
    pAVReq->AttachFrame.FrameLength  = ulFrameSize;
    pAVReq->AttachFrame.SourceLength = ulSourceLength;
    pAVReq->AttachFrame.Frame        = pSrbDataPacket->Frame;

    ASSERT(pStrmExt->hConnect);
    ASSERT(pSrbDataPacket->Frame);
}



VOID
DVAttachFrameThread(
    IN PSTREAMEX pStrmExt
    )  
/*++

Routine Description:

    This is a system thread to attach frame for transmit.

--*/    
{
    NTSTATUS  Status;   
    PDVCR_EXTENSION pDevExt;
    KIRQL OldIrql;



    PAGED_CODE();

    pDevExt = pStrmExt->pDevExt;

    //
    // Pump up the priority since we are dealing with real time data
    //
    KeSetPriorityThread(KeGetCurrentThread(), 
#if 1
            LOW_REALTIME_PRIORITY
#else
            HIGH_PRIORITY
#endif
            );

    while (!pStrmExt->bTerminateThread) {

        //
        // Halt this thread operation if other critical service 
        // is requested.
        //

        if(
              !pStrmExt->bTerminateThread 
           && (pStrmExt->lNeedService > 0)
          ) {  // not fullly awake/powered.
            NTSTATUS StatusWait;

            TRACE(TL_CIP_WARNING,("\'Request stop thread for other service: lNeedService:%d; pStrmExt:%x; AQD[%d,%d,%d]\n", 
                pStrmExt->lNeedService, pStrmExt, 
                pStrmExt->cntDataAttached,
                pStrmExt->cntSRBQueued,
                pStrmExt->cntDataDetached
                ));

            InterlockedDecrement(&pStrmExt->lNeedService);           // One reuqest serviced.

            //
            // Indicate that thread is about to stop.  Signal it so other operation can begin.
            //
            KeSetEvent(&pStrmExt->hStopThreadEvent, 0 ,FALSE);

            TRACE(TL_CIP_WARNING,("\'>>>> Enter WFSO(hRunThreadEvent)\n"));
            StatusWait = 
                KeWaitForSingleObject(
                    &pStrmExt->hRunThreadEvent, 
                    Executive, 
                    KernelMode, 
                    FALSE, 
                    0  
                    );
            TRACE(TL_CIP_WARNING,("\'<<<< Exit WFSO(hRunThreadEvent); lNeedService:%d\n", pStrmExt->lNeedService));
            ASSERT(pStrmExt->lNeedService == 0);
        }

        // Halt attach operation if
        //   not in either PAUSE or RUN state ( i.e. in STOP state)
        //   Device is removed
        //   in the process of being cancelled.

        if(
              !pStrmExt->bTerminateThread 
           && pStrmExt->StreamState != KSSTATE_PAUSE
           && pStrmExt->StreamState != KSSTATE_RUN 
           || pStrmExt->pDevExt->bDevRemoved       
           || pStrmExt->lCancelStateWorkItem > 0
           ) {
            NTSTATUS StatusWait;

            TRACE(TL_CIP_WARNING,("\'Enter WFSO(hSrbArriveEvent): StrmState:%d; bDevRemoved:%d\n", pStrmExt->StreamState, pStrmExt->pDevExt->bDevRemoved));

            StatusWait =  // Can only return STATUS_SUCCESS (signal) or STATUS_TIMEOUT
                KeWaitForSingleObject( 
                    &pStrmExt->hSrbArriveEvent,    // Signal with arrival of the first frame
                    Executive,
                    KernelMode,          // Cannot return STATUS_USER_APC
                    FALSE,               // Cannot be alerted STATUS_ALERTED
                    0                    // INFINITE!!
                    );

            // Reset notification event (or it will stay signalled).
            KeClearEvent(&pStrmExt->hSrbArriveEvent);
            TRACE(TL_CIP_WARNING,("\'Exit WFSO(hSrbArriveEvent): StrmState:%d; bDevRemoved:%d\n", pStrmExt->StreamState, pStrmExt->pDevExt->bDevRemoved));


#ifdef SUPPORT_PREROLL_AT_RUN_STATE

            // Simulate preroll at the RUN state
            // We do this only when we are the clock provider to avoid dropping frame
            // This timed WFSO is necessary if application send us only one frame while in RUN state.
#define PREROLL_WAITTIME 2000000
            if(
                !pStrmExt->bTerminateThread &&
                pStrmExt->hMasterClock
              ) {
                LARGE_INTEGER DueTime; 
                DueTime = RtlConvertLongToLargeInteger(-((LONG) PREROLL_WAITTIME));

                TRACE(TL_CIP_WARNING,("\'Enter WFSO(hPreRollEvent)\n"));
                StatusWait =  // Can only return STATUS_SUCCESS (signal) or STATUS_TIMEOUT
                    KeWaitForSingleObject( 
                        &pStrmExt->hPreRollEvent,
                        Executive,
                        KernelMode,          // Cannot return STATUS_USER_APC
                        FALSE,               // Cannot be alerted STATUS_ALERTED
                        &DueTime
                        );
                // hPreRollEvent is a ont shot event; no need to reset it; let it stay signalled.
                TRACE(TL_CIP_WARNING,("\'Exit WFSO(hPreRollEvent); waited %d msec; waitStatus:%x\n", (DWORD) ((GetSystemTime() - pStrmExt->tmStreamStart)/10000), StatusWait ));
            }
#endif
        }

#if DBG
        if(
              !pStrmExt->bTerminateThread
           && !pStrmExt->bEOStream
           && pStrmExt->FramesProcessed > 0 
           && pStrmExt->cntDataAttached < NUM_BUF_ATTACHED_THEN_ISOCH
          ) {

            TRACE(TL_CIP_TRACE,("\'AttachBuf is low!! SrbRcv:%d;Pic#:%d;Prc:%d;;Drop:%d;Cncl:%d; AQD [%d:%d:%d]\n",
                (DWORD) pStrmExt->cntSRBReceived,
                (DWORD) pStrmExt->PictureNumber,
                (DWORD) pStrmExt->FramesProcessed, 
                (DWORD) pStrmExt->FramesDropped,
                (DWORD) pStrmExt->cntSRBCancelled,
                pStrmExt->cntDataAttached,
                pStrmExt->cntSRBQueued,
                pStrmExt->cntDataDetached
                ));
        }
#endif
        // Attach another frame for transmit
        // Only possible error is if there is not sufficient resource (esp MDL)
        // Then, we bail out by self terminating this thread.
        if(
              !pStrmExt->pDevExt->bDevRemoved
           && !pStrmExt->bTerminateThread
          ) {
            if(STATUS_INSUFFICIENT_RESOURCES == \
                DVAttachWriteFrame(pStrmExt)) {
                TRACE(TL_CIP_ERROR,("STATUS_INSUFFICIENT_RESOURCES while attaching write frame.\n")); 
                  pStrmExt->bTerminateThread = TRUE;
            }
        }

        //
        // Start Isoch_Talk once we have enough buffers attached.
        // It is possible that streaming state is set to RUN before we have enough attach buffer 
        // start streaming.  So we need to kick start here.
        //
        if( 
              !pStrmExt->bTerminateThread             
           && !pStrmExt->pDevExt->bDevRemoved 
           && pStrmExt->pDevExt->PowerState == PowerDeviceD0   // Need to be PoweredON
           && pStrmExt->lCancelStateWorkItem == 0              // No pending cancel work item
           && !pStrmExt->bIsochIsActive  
           && (pStrmExt->StreamState == KSSTATE_PAUSE || pStrmExt->StreamState == KSSTATE_RUN) 
           && pStrmExt->cntDataAttached >= NUM_BUF_ATTACHED_THEN_ISOCH
          ) { 

            Status = 
                DVStreamingStart(
                    pStrmExt->pStrmInfo->DataFlow,
                    pStrmExt,
                    pStrmExt->pDevExt
                    );
        }
    }

    TRACE(TL_STRM_WARNING,("\'*** ThreadTerminating... AQD [%d:%d:%d]\n", 
        pStrmExt->cntDataAttached, 
        pStrmExt->cntSRBQueued,
        pStrmExt->cntDataDetached
        ));

    KeAcquireSpinLock(&pStrmExt->pDevExt->AVCCmdLock, &OldIrql);
    if(pStrmExt->lNeedService) {
        TRACE(TL_STRM_WARNING,("Thread is exiting but lNeedService:%x != 0!\n", pStrmExt->lNeedService));
        KeSetEvent(&pStrmExt->hStopThreadEvent, 0 ,FALSE); 
        InterlockedDecrement(&pStrmExt->lNeedService);  
        ASSERT(pStrmExt->lNeedService == 0);
    }
    KeReleaseSpinLock(&pStrmExt->pDevExt->AVCCmdLock, OldIrql);

    KeSetEvent(&pStrmExt->hThreadEndEvent, 0, FALSE);  // Signal it
    Status = PsTerminateSystemThread(STATUS_SUCCESS);  // Must be called at PASSIVE_LEVEL
    // End of this thread!
}



VOID
DVTerminateAttachFrameThread(
    IN PSTREAMEX  pStrmExt
    )
/*++

Routine Description:

    To terminate the system thread.  It waits for an event that is triggered
    right before PsTerminateSystemThread() is called.

--*/ 
{

    PAGED_CODE();

    TRACE(TL_CIP_WARNING,("\'DVTerminateAttachFrameThread enter\n"));

    //
    // Wake up the DataReady thread and terminate it if not already done so.
    //
    ASSERT(pStrmExt->bIsochIsActive == FALSE && "Terminate therad while IsochActive!");


    //
    // This function can be called from either CloseStrean or SurpriseRemoval;
    // When a DV is surprise removal, this function may get called from both functions.
    // Assuming StreamClass is serializing these two functions, no need to serialize it locally.
    //
    if(pStrmExt->bTerminateThread) {
        TRACE(TL_CIP_ERROR,("DVTerminateAttachFrameThread: Thread already terminated. Was surprise removed?\n"));
        return;
    }

    // ****** Terminate thread ******
    pStrmExt->bTerminateThread = TRUE;
    // ******

    // With bTerminate thread set, let the thread run and terminate.
    KeSetEvent(&pStrmExt->hRunThreadEvent, 0 ,FALSE);


    // WFSO while in STOP state; signal so it can be terminated.
    KeSetEvent(&pStrmExt->hSrbArriveEvent, 0, FALSE);
#ifdef SUPPORT_PREROLL_AT_RUN_STATE
    // Signal it in case that it is still in WFSO.
    KeSetEvent(&pStrmExt->hPreRollEvent, 0, FALSE);
#endif


    KeWaitForSingleObject(               
        &pStrmExt->hThreadEndEvent,
         Executive,
         KernelMode,
         FALSE,
         NULL
         );

    TRACE(TL_CIP_WARNING,("\'Thread terminated!\n"));

    ObDereferenceObject(
         &pStrmExt->pAttachFrameThreadObject
             );

    TRACE(TL_CIP_WARNING,("\'ObDereferenceObject done!\n"));
}
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\drivers\wdm\capture\mini\msdv\msdvuppr.c ===
/*++

Copyright (C) Microsoft Corporation, 1999 - 2000  

Module Name:

    MSDVUppr.c

Abstract:

    Interface code with stream class driver.

Last changed by:
    
    Author:      Yee J. Wu

Environment:

    Kernel mode only

Revision History:

    $Revision::                    $
    $Date::                        $

--*/

#include "strmini.h"
#include "ksmedia.h"
#include "1394.h"
#include "61883.h"
#include "avc.h"
#include "dbg.h"
#include "msdvfmt.h"
#include "msdvdef.h"
#include "MsdvGuts.h"  // Function prototypes
#include "MsdvAvc.h"
#include "MsdvUtil.h"

#include "EDevCtrl.h"

#ifdef TIME_BOMB
#include "..\..\inc\timebomb.c"
#endif

// global flag for debugging.  Inlines are defined in dbg.h.  The debug level is set for
// minimal amount of messages.
#if DBG

#define DVTraceMaskCheckIn  TL_PNP_ERROR | TL_STRM_ERROR | TL_61883_ERROR

#define DVTraceMaskDefault  TL_PNP_ERROR   | TL_PNP_WARNING \
                          | TL_61883_ERROR | TL_61883_WARNING \
                          | TL_CIP_ERROR  \
                          | TL_FCP_ERROR  \
                          | TL_STRM_ERROR  | TL_STRM_WARNING \
                          | TL_CLK_ERROR

#define DVTraceMaskDebug  TL_PNP_ERROR  | TL_PNP_WARNING \
                          | TL_61883_ERROR| TL_61883_WARNING \
                          | TL_CIP_ERROR  \
                          | TL_FCP_ERROR  | TL_FCP_WARNING \
                          | TL_STRM_ERROR | TL_STRM_WARNING \
                          | TL_CLK_ERROR


#ifdef USE_WDM110   // Win2000 code base
ULONG  DVTraceMask    = DVTraceMaskCheckIn | TL_FCP_ERROR;
#else
ULONG  DVTraceMask    = DVTraceMaskCheckIn;
#endif

ULONG  DVAssertLevel  = 1;  // Turn on assert (>0)
ULONG  DVDebugXmt     = 0;  // Debug data transfer flag; (> 0) to turn it on.

#endif


extern DV_FORMAT_INFO        DVFormatInfoTable[];

//
// Function prototypes
//
VOID
DVRcvStreamDevicePacket(
    IN PHW_STREAM_REQUEST_BLOCK pSrb
    );
VOID
DVSRBRead(
    IN PKSSTREAM_HEADER pStrmHeader,
    IN ULONG            ulFrameSize,
    IN PDVCR_EXTENSION  pDevExt,
    IN PSTREAMEX        pStrmExt,
    IN PHW_STREAM_REQUEST_BLOCK pSrb        // needs Srb->Status 
    );
NTSTATUS
DVAttachWriteFrame(
    IN PSTREAMEX  pStrmExt
    );
NTSTATUS
DriverEntry(
    IN PDRIVER_OBJECT DriverObject,
    IN PUNICODE_STRING RegistryPath
    ); 

#if 0  // Enable later
#ifdef ALLOC_PRAGMA   
     #pragma alloc_text(PAGE, DVRcvStreamDevicePacket)
     #pragma alloc_text(PAGE, DVRcvControlPacket)
     #pragma alloc_text(PAGE, DVRcvDataPacket)
     // #pragma alloc_text(INIT, DriverEntry)
#endif
#endif


VOID
DVRcvStreamDevicePacket(
    IN PHW_STREAM_REQUEST_BLOCK pSrb
    )
/*++

Routine Description:

    This is where most of the interesting Stream requests come to us

--*/
{
    PDVCR_EXTENSION     pDevExt;  
    PAV_61883_REQUEST      pAVReq;
    PIO_STACK_LOCATION  pIrpStack;


    PAGED_CODE();


    //
    // Get these extensions from a SRB
    //
    pDevExt = (PDVCR_EXTENSION) pSrb->HwDeviceExtension; 
    pAVReq  = (PAV_61883_REQUEST) pSrb->SRBExtension;       // Use in IrpSync is OK, 
                             
#if DBG
    if(pSrb->Command != SRB_INITIALIZE_DEVICE && // PowerState is initialize in this SRB so ignore it.
       pDevExt->PowerState != PowerDeviceD0) {
        TRACE(TL_PNP_WARNING,("RcvDevPkt; pSrb:%x; Cmd:%x; Dev is OFF state\n", pSrb, pSrb->Command));
    }
#endif

    TRACE(TL_PNP_TRACE,("\'DVRcvStreamDevicePacket: pSrb %x, Cmd %d, pdevExt %x\n", pSrb, pSrb->Command, pDevExt));

    //
    // Assume success
    //
    pSrb->Status = STATUS_SUCCESS;

    switch (pSrb->Command) {

    case SRB_INITIALIZE_DEVICE:

        ASSERT(((PPORT_CONFIGURATION_INFORMATION) pSrb->CommandData.ConfigInfo)->HwDeviceExtension == pDevExt);
        pSrb->Status = 
            DVInitializeDevice(
                (PDVCR_EXTENSION) ((PPORT_CONFIGURATION_INFORMATION)pSrb->CommandData.ConfigInfo)->HwDeviceExtension,
                pSrb->CommandData.ConfigInfo,
                pAVReq
                );
        break;



    case SRB_INITIALIZATION_COMPLETE:

        //
        // Stream class has finished initialization.  Get device interface registry value/
        //
        DVInitializeCompleted(
            (PDVCR_EXTENSION) pSrb->HwDeviceExtension); 
        break;


    case SRB_GET_STREAM_INFO:

        //
        // this is a request for the driver to enumerate requested streams
        //
        pSrb->Status = 
            DVGetStreamInfo(
                pDevExt,
                pSrb->NumberOfBytesToTransfer,
                &pSrb->CommandData.StreamBuffer->StreamHeader,
                &pSrb->CommandData.StreamBuffer->StreamInfo
                );
        break;



    case SRB_GET_DATA_INTERSECTION:

        // Since format can dynamically change, we will query new format here.
        // Note: during data intersection, we compare FrameSize and that is 
        // format related.

        if((GetSystemTime() - pDevExt->tmLastFormatUpdate) > FORMAT_UPDATE_INTERVAL) {

            // Get mode of operation (Camera or VCR)
            DVGetDevModeOfOperation(pDevExt);

            if(!DVGetDevSignalFormat(pDevExt, KSPIN_DATAFLOW_OUT,0)) {
                // If querying its format has failed, we cannot open this stream.
                TRACE(TL_STRM_WARNING,("SRB_GET_DATA_INTERSECTION:Failed getting signal format.\n"));
            }
        
            // Update system time to reflect last update
            pDevExt->tmLastFormatUpdate = GetSystemTime();              
        }

        pSrb->Status = 
            DVGetDataIntersection(
                pSrb->CommandData.IntersectInfo->StreamNumber,
                pSrb->CommandData.IntersectInfo->DataRange,
                pSrb->CommandData.IntersectInfo->DataFormatBuffer,
                pSrb->CommandData.IntersectInfo->SizeOfDataFormatBuffer,
                DVFormatInfoTable[pDevExt->VideoFormatIndex].ulFrameSize,
                &pSrb->ActualBytesTransferred,
                pDevExt->paCurrentStrmInfo
#ifdef SUPPORT_NEW_AVC            
                ,pDevExt->paCurrentStrmInfo[pSrb->CommandData.IntersectInfo->StreamNumber].DataFlow == KSPIN_DATAFLOW_OUT ? pDevExt->hOPcrDV : pDevExt->hIPcrDV
#endif
                );          
        break;



    case SRB_OPEN_STREAM:

        //
        // Serialize SRB_OPEN/CLOSE_STREAMs
        //
        KeWaitForSingleObject( &pDevExt->hMutex, Executive, KernelMode, FALSE, 0 );

        pSrb->Status = 
            DVOpenStream(
                pSrb->StreamObject,
                pSrb->CommandData.OpenFormat,
                pAVReq
                );

        KeReleaseMutex(&pDevExt->hMutex, FALSE);
        break;



    case SRB_CLOSE_STREAM:

        //
        // Serialize SRB_OPEN/CLOSE_STREAMs
        //
        KeWaitForSingleObject( &pDevExt->hMutex, Executive, KernelMode, FALSE, 0 );

        pSrb->Status = 
            DVCloseStream(
                pSrb->StreamObject,
                pSrb->CommandData.OpenFormat,
                pAVReq
                );
        KeReleaseMutex(&pDevExt->hMutex, FALSE);
        break;



    case SRB_GET_DEVICE_PROPERTY:

        pSrb->Status = 
            DVGetDeviceProperty(
                pDevExt,
                pSrb->CommandData.PropertyInfo,
                &pSrb->ActualBytesTransferred
                );
        break;

        
    case SRB_SET_DEVICE_PROPERTY:

        pSrb->Status = 
            DVSetDeviceProperty(
                pDevExt,
                pSrb->CommandData.PropertyInfo,
                &pSrb->ActualBytesTransferred
                );
        break;



    case SRB_CHANGE_POWER_STATE:
            
        pIrpStack = IoGetCurrentIrpStackLocation(pSrb->Irp);

        if(pIrpStack->MinorFunction == IRP_MN_SET_POWER) {
            pSrb->Status = 
                DVChangePower(
                    (PDVCR_EXTENSION) pSrb->HwDeviceExtension,
                    pAVReq,
                    pSrb->CommandData.DeviceState
                    );
        } else 
        if(pIrpStack->MinorFunction == IRP_MN_QUERY_POWER) {
            TRACE(TL_PNP_WARNING,("IRP_MN_QUERY_POWER: PwrSt:%d\n", pDevExt->PowerState)); 
            pSrb->Status = STATUS_SUCCESS;
        }
        else {
            TRACE(TL_PNP_WARNING,("NOT_IMPL POWER_STATE MinorFunc:%d\n", pIrpStack->MinorFunction)); 
            pSrb->Status = STATUS_NOT_IMPLEMENTED; 
        }

        break;


    case SRB_UNKNOWN_DEVICE_COMMAND:

        //
        // We might be interested in unknown commands if they pertain
        // to bus resets.  Bus resets are important cuz we need to know
        // what the current generation count is.
        //
        pIrpStack = IoGetCurrentIrpStackLocation(pSrb->Irp);

        if(pIrpStack->MajorFunction == IRP_MJ_PNP) {
            if(pIrpStack->MinorFunction == IRP_MN_BUS_RESET) {
            
                DVProcessPnPBusReset(
                    pDevExt
                    );
                
                //  Always success                
                pSrb->Status = STATUS_SUCCESS;
            }        
            else  {
                /* Known: IRP_MN_QUERY_PNP_DEVICE_STATE */
                TRACE(TL_PNP_WARNING,("\'DVRcvStreamDevicePacket: NOT_IMPL; IRP_MJ_PNP IRP_MN_:%x\n",
                    pIrpStack->MinorFunction
                    )); 
                // Canot return STATUS_NOT_SUPPORTED for PNP irp or device will not load.
                pSrb->Status = STATUS_NOT_IMPLEMENTED; 
            } 
        }
        else {
            TRACE(TL_PNP_WARNING,("\'DVRcvStreamDevicePacket: NOT_IMPL; IRP_MJ_ %x; IRP_MN_:%x\n",
                pIrpStack->MajorFunction,
                pIrpStack->MinorFunction
                ));
            // Canot return STATUS_NOT_SUPPORTED for PNP irp or device will not load.
            pSrb->Status = STATUS_NOT_IMPLEMENTED;
        }
        break;


    case SRB_SURPRISE_REMOVAL:

        TRACE(TL_PNP_WARNING,("\' #SURPRISE_REMOVAL# pSrb %x, pDevExt %x\n", pSrb, pDevExt));
        pSrb->Status = 
             DVSurpriseRemoval(
                 pDevExt,
                 pAVReq
                 );
        break;            


        
    case SRB_UNINITIALIZE_DEVICE:

        TRACE(TL_PNP_WARNING,("\' #UNINITIALIZE_DEVICE# pSrb %x, pDevExt %x\n", pSrb, pDevExt));                   
        pSrb->Status = 
            DVUninitializeDevice(
                (PDVCR_EXTENSION) pSrb->HwDeviceExtension
                );          
        break;           


    default:
            
        TRACE(TL_PNP_WARNING,("\'DVRcvStreamDevicePacket: Unknown or unprocessed SRB cmd 0x%x\n", pSrb->Command));

        //
        // this is a request that we do not understand.  Indicate invalid
        // command and complete the request
        //

        pSrb->Status = STATUS_NOT_IMPLEMENTED; // SUPPORTED;
    }

    //
    // NOTE:
    //
    // all of the commands that we do, or do not understand can all be completed
    // synchronously at this point, so we can use a common callback routine here.
    // If any of the above commands require asynchronous processing, this will
    // have to change
    //
#if DBG
    if (pSrb->Status != STATUS_SUCCESS && 
        pSrb->Status != STATUS_NOT_SUPPORTED &&
        pSrb->Status != STATUS_NOT_IMPLEMENTED &&
        pSrb->Status != STATUS_BUFFER_TOO_SMALL &&
        pSrb->Status != STATUS_BUFFER_OVERFLOW &&
        pSrb->Status != STATUS_NO_MATCH
        && pSrb->Status != STATUS_TIMEOUT
        ) {
        TRACE(TL_PNP_WARNING,("\'pSrb->Command (%x) ->Status:%x\n", pSrb->Command, pSrb->Status));
    }
#endif

    if(STATUS_PENDING != pSrb->Status) {

        StreamClassDeviceNotification(
            DeviceRequestComplete,
            pSrb->HwDeviceExtension,
           pSrb
           );
    } 
    else {

        // Pending pSrb which will be completed asynchronously
        // Does StreamClass allow device SRB to be in the pending state?
        TRACE(TL_PNP_WARNING,("\'DVReceiveDevicePacket:Pending pSrb %x\n", pSrb));
    }
}


VOID
DVRcvControlPacket(
    IN PHW_STREAM_REQUEST_BLOCK pSrb
    )
/*++

Routine Description:

    Called with packet commands that control the video stream

--*/
{
    PAV_61883_REQUEST   pAVReq;
    PSTREAMEX        pStrmExt;
    PDVCR_EXTENSION  pDevExt;


    PAGED_CODE();

    //
    // Get these three extension from SRB
    //
    pAVReq   = (PAV_61883_REQUEST) pSrb->SRBExtension;  // This is OK to be used us IrpSync operation
    pDevExt  = (PDVCR_EXTENSION) pSrb->HwDeviceExtension;
    pStrmExt = (PSTREAMEX) pSrb->StreamObject->HwStreamExtension;      // Only valid in SRB_OPEN/CLOSE_STREAM

    ASSERT(pStrmExt && pDevExt && pAVReq);

    //
    // Default to success
    //
    pSrb->Status = STATUS_SUCCESS;

    switch (pSrb->Command) {

    case SRB_GET_STREAM_STATE:

        pSrb->Status =
            DVGetStreamState( 
                pStrmExt,
                &(pSrb->CommandData.StreamState),
                &(pSrb->ActualBytesTransferred)
                );
        break;
            
    case SRB_SET_STREAM_STATE:
            
        pSrb->Status =
            DVSetStreamState(
                pStrmExt,
                pDevExt,
                pAVReq,
                pSrb->CommandData.StreamState   // Target KSSTATE
               );       
        break;

        
    case SRB_GET_STREAM_PROPERTY:

        pSrb->Status =
            DVGetStreamProperty( 
                pSrb 
                );
        break;


    case SRB_SET_STREAM_PROPERTY:

        pSrb->Status =        
            DVSetStreamProperty( 
                pSrb 
                );
        break;

    case SRB_OPEN_MASTER_CLOCK:
    case SRB_CLOSE_MASTER_CLOCK:

        //
        // This stream is being selected to provide a Master clock.
        //
        pSrb->Status =
            DVOpenCloseMasterClock(                 
                pStrmExt, 
                pSrb->Command == SRB_OPEN_MASTER_CLOCK ? pSrb->CommandData.MasterClockHandle: NULL);
        break;

    case SRB_INDICATE_MASTER_CLOCK:

        //
        // Assigns a clock to a stream.
        //
        pSrb->Status = 
            DVIndicateMasterClock(
                pStrmExt, 
                pSrb->CommandData.MasterClockHandle);
        break;

    case SRB_PROPOSE_DATA_FORMAT:
    
        //
        // The SRB_PROPOSE_DATA_FORMAT command queries the minidriver
        // to determine if the minidriver can change the format of a 
        // particular stream. If the minidriver is able to switch the 
        // stream to the specified format, STATUS_SUCCESS is returned. 
        // Note that this function only proposes a new format, but does
        // not change it. 
        //
        // The CommandData.OpenFormat passes the format to validate.
        // If the minidriver is able to accept the new format, at some 
        // later time the class driver may send the minidriver a format 
        // change, which is indicated by an OptionsFlags flag in a 
        // KSSTREAM_HEADER structure. 
        //
 
        TRACE(TL_STRM_INFO,("\'DVRcvControlPacket: SRB_PROPOSE_DATA_FORMAT\n"));
        if(!DVVerifyDataFormat(
            pSrb->CommandData.OpenFormat, 
            pSrb->StreamObject->StreamNumber,
            DVFormatInfoTable[pDevExt->VideoFormatIndex].ulFrameSize,
            pDevExt->paCurrentStrmInfo
            ))  {
            TRACE(TL_STRM_WARNING,("\'DVRcvControlPacket: AdapterVerifyFormat failed.\n"));
            pSrb->Status = STATUS_NO_MATCH;
        }
        break;

    case SRB_PROPOSE_STREAM_RATE:
        pSrb->Status = STATUS_NOT_IMPLEMENTED; // if returned STATUS_NOT_SUPPORTED, it will send EOStream.
        TRACE(TL_STRM_TRACE,("\'SRB_PROPOSE_STREAM_RATE: NOT_IMPLEMENTED!\n"));
        break;
    case SRB_BEGIN_FLUSH:
        pSrb->Status = STATUS_NOT_SUPPORTED;
        TRACE(TL_STRM_TRACE,("\'SRB_BEGIN_FLUSH: NOT_SUPPORTED!\n"));
        break;
    case SRB_END_FLUSH:
        pSrb->Status = STATUS_NOT_SUPPORTED;
        TRACE(TL_STRM_TRACE,("\'SRB_END_FLUSH: NOT_SUPPORTED!\n"));
        break;
    default:

        //
        // invalid / unsupported command. Fail it as such
        //
        TRACE(TL_STRM_WARNING,("\'DVRcvControlPacket: unknown cmd = %x\n",pSrb->Command));
            pSrb->Status = STATUS_NOT_IMPLEMENTED; // SUPPORTED;
    }

    TRACE(TL_STRM_TRACE,("\'DVRcvControlPacket: Command %x, ->Status %x, ->CommandData %x\n",
         pSrb->Command, pSrb->Status, &(pSrb->CommandData.StreamState) ));

    StreamClassStreamNotification(          
        StreamRequestComplete,
        pSrb->StreamObject,
        pSrb);
}




VOID
DVRcvDataPacket(
    IN PHW_STREAM_REQUEST_BLOCK pSrb
    )

/*++

Routine Description:

    Called with video data packet commands

--*/

{
    PSTREAMEX       pStrmExt;
    PDVCR_EXTENSION pDevExt;

    
    PAGED_CODE();

    pStrmExt = (PSTREAMEX) pSrb->StreamObject->HwStreamExtension;  
    pDevExt  = (PDVCR_EXTENSION) pSrb->HwDeviceExtension;

#if DBG
    if(pDevExt->PowerState != PowerDeviceD0) {
        TRACE(TL_STRM_WARNING|TL_PNP_WARNING,("\'SRB_READ/WRITE; PowerSt:OFF; pSrb:%x\n", pSrb));
    }
#endif

    // The stream has to be open before we can do anything.
    if (pStrmExt == NULL) {
        TRACE(TL_STRM_ERROR|TL_CIP_ERROR,("DVRcvDataPacket: stream not opened for SRB %x. kicking out...\n", pSrb->Command));
        pSrb->Status = STATUS_UNSUCCESSFUL;
        pSrb->CommandData.DataBufferArray->DataUsed = 0;
        StreamClassStreamNotification(StreamRequestComplete, pSrb->StreamObject, pSrb);
        return;        
    }


    //
    // Serialize attach, cancel and state change
    //
    KeWaitForSingleObject( pStrmExt->hStreamMutex, Executive, KernelMode, FALSE, 0 );


    TRACE(TL_CIP_TRACE,("\'XXX_DATA(%d, %d);Srb:%x;Flg:%x;FExt:%d:%d\n", 
        (DWORD) pStrmExt->cntSRBReceived, 
        (DWORD) pSrb->CommandData.DataBufferArray->PresentationTime.Time/10000,
        pSrb, 
        pSrb->CommandData.DataBufferArray->OptionsFlags,
        pSrb->CommandData.DataBufferArray->FrameExtent,
        DVFormatInfoTable[pDevExt->VideoFormatIndex].ulFrameSize
        ));

    //
    // determine the type of packet.
    //
    pSrb->Status = STATUS_SUCCESS;

#if DBG
    pStrmExt->cntSRBPending++;
#endif

    switch (pSrb->Command) {

    case SRB_READ_DATA:

        // Rule: 
        // Only accept read requests when in either the Pause or Run
        // States.  If Stopped, immediately return the SRB.

        if (pStrmExt->lCancelStateWorkItem) {
            // TRACE(TL_STRM_ERROR|TL_CIP_ERROR,("\'SRB_READ_DATA: Abort while getting SRB_READ_DATA!\n"));                        
            // ASSERT(pStrmExt->lCancelStateWorkItem == 0 && "Encounter SRB_READ_DATA while aborting or aborted.\n");
            pSrb->Status = (pDevExt->bDevRemoved ? STATUS_DEVICE_REMOVED : STATUS_CANCELLED);
            pSrb->CommandData.DataBufferArray->DataUsed = 0;
            break; 

        } else if( pStrmExt->StreamState == KSSTATE_STOP       ||
            pStrmExt->StreamState == KSSTATE_ACQUIRE    ||
            pStrmExt->hConnect == NULL                  ||    
            pDevExt->bDevRemoved 
            ) {
            TRACE(TL_STRM_ERROR|TL_CIP_ERROR,("\'SRB_READ_DATA: (DV->) State %d, bDevRemoved %d\n", pStrmExt->StreamState, pDevExt->bDevRemoved));            
            pSrb->Status = (pDevExt->bDevRemoved ? STATUS_DEVICE_REMOVED : STATUS_CANCELLED);
            pSrb->CommandData.DataBufferArray->DataUsed = 0;

            break;
  
        } else {

            TRACE(TL_STRM_INFO|TL_CIP_INFO,("\'SRB_READ_DATA pSrb %x, pStrmExt %x\n", pSrb, pStrmExt));
            pStrmExt->cntSRBReceived++;

            // Set state thread in halt while while Read/Write SRB is being processed
            DVSRBRead(
                pSrb->CommandData.DataBufferArray,
                DVFormatInfoTable[pDevExt->VideoFormatIndex].ulFrameSize,
                pDevExt,
                pStrmExt,
                pSrb
                );

            KeReleaseMutex(pStrmExt->hStreamMutex, FALSE); 
            
            // Note: This SRB will be completed asynchronously.

            return;
        }
            
        break;
            
    case SRB_WRITE_DATA:

        if( pStrmExt->StreamState == KSSTATE_STOP       ||
            pStrmExt->StreamState == KSSTATE_ACQUIRE    ||
#ifdef SUPPORT_NEW_AVC
            (pStrmExt->hConnect == NULL && !pStrmExt->bDV2DVConnect) ||
#else
            pStrmExt->hConnect == NULL                  ||
#endif
            pDevExt->bDevRemoved     
            ) {
            pSrb->Status = (pDevExt->bDevRemoved ? STATUS_DEVICE_REMOVED : STATUS_CANCELLED);
            pSrb->CommandData.DataBufferArray->DataUsed = 0;
            TRACE(TL_STRM_WARNING|TL_CIP_WARNING,("\'SRB_WRITE_DATA: (DV->) State %d, bDevRemoved %d; Status:%x\n", pStrmExt->StreamState, pDevExt->bDevRemoved, pSrb->Status));
            break;  // Complete SRB with error status
            
        } else {

            KIRQL  oldIrql;
            PLONG plSrbUseCount; // When this count is 0, it can be completed.

            TRACE(TL_STRM_INFO|TL_CIP_INFO,("\'SRB_WRITE_DATA pSrb %x, pStrmExt %x\n", pSrb, pStrmExt));

            //
            // Process EOSream frame separately
            //
            if(pSrb->CommandData.DataBufferArray->OptionsFlags & KSSTREAM_HEADER_OPTIONSF_ENDOFSTREAM) {
                KeAcquireSpinLock(pStrmExt->DataListLock, &oldIrql);
                TRACE(TL_STRM_WARNING|TL_CIP_WARNING,("\'*** EOStream: ST:%d; bIsochIsActive:%d; Wait (cndAttached:%d+cndSRQ:%d) to complete......\n", \
                    pStrmExt->StreamState, pStrmExt->bIsochIsActive, pStrmExt->cntDataAttached, pStrmExt->cntSRBQueued));        
                pStrmExt->bEOStream = TRUE;
                KeReleaseSpinLock(pStrmExt->DataListLock, oldIrql); 
                pSrb->Status = STATUS_SUCCESS;
                break;

            } else if(pSrb->CommandData.DataBufferArray->OptionsFlags & KSSTREAM_HEADER_OPTIONSF_TYPECHANGED) {
                TRACE(TL_STRM_WARNING|TL_CIP_WARNING,("\'DVRcvDataPacket:KSSTREAM_HEADER_OPTIONSF_TYPECHANGED.\n"));
                pSrb->CommandData.DataBufferArray->DataUsed = 0;
                // May need to compare the data format; instead of return STATUS_SUCCESS??
                pSrb->Status = STATUS_SUCCESS; // May need to check the format when dynamic format change is allowed.
                break;  

#ifdef SUPPORT_NEW_AVC
            } else if(pStrmExt->bDV2DVConnect) {
                pSrb->Status = STATUS_SUCCESS;
                pSrb->CommandData.DataBufferArray->DataUsed = 0;
                TRACE(TL_STRM_WARNING|TL_CIP_WARNING,("\'SRB_WRITE_DATA: [DV2DV] (pStrmExt:%x), pSrb:%x, FrameExt:%d\n", 
                    pStrmExt, pSrb, pSrb->CommandData.DataBufferArray->FrameExtent));
                break;              
#endif                
            } else {

                PSRB_ENTRY  pSrbEntry;

                //
                // Validation
                //
                if(pSrb->CommandData.DataBufferArray->FrameExtent < DVFormatInfoTable[pDevExt->VideoFormatIndex].ulFrameSize) {
                    TRACE(TL_STRM_ERROR|TL_CIP_ERROR,("\' FrameExt %d < FrameSize %d\n", pSrb->CommandData.DataBufferArray->FrameExtent, DVFormatInfoTable[pDevExt->VideoFormatIndex].ulFrameSize));
                    ASSERT(pSrb->CommandData.DataBufferArray->FrameExtent >= DVFormatInfoTable[pDevExt->VideoFormatIndex].ulFrameSize);
                    pSrb->Status = STATUS_INVALID_PARAMETER;  
                    break;  // Complete SRB with error status                 
                }

                //
                // Dynamically allocate a SRB_ENTRY and append it to SRBQueue
                //
                if(!(pSrbEntry = ExAllocatePool(NonPagedPool, sizeof(SRB_ENTRY)))) {
                    pSrb->Status = STATUS_INSUFFICIENT_RESOURCES;
                    pSrb->CommandData.DataBufferArray->DataUsed = 0;
                    break;  // Complete SRB with error status
                }

#if DBG
                if(pStrmExt->bEOStream) {
                    TRACE(TL_STRM_WARNING|TL_CIP_WARNING,("\'SRB_WRITE_DATA: pSrb:%x after EOStream!\n", pSrb));
                }
#endif

                //
                // For statistics
                //
                pStrmExt->cntSRBReceived++;

                //
                // Save SRB and add it to SRB queue
                // No need for spin lock since StreamClass will serialize it for us.
                //
                pSrb->Status = STATUS_PENDING;
                pSrbEntry->pSrb = pSrb; pSrbEntry->bStale = FALSE; pSrbEntry->bAudioMute  = FALSE;
#if DBG
                pSrbEntry->SrbNum = (ULONG) pStrmExt->cntSRBReceived -1;
#endif
                //
                // Note: plSrbUseCount is initialize to 1
                // When it is insert: ++
                // When it is removed: --
                // when this count is 0; it can be completed.
                //
                plSrbUseCount = (PLONG) pSrb->SRBExtension; *plSrbUseCount = 1;  // Can be completed if this is 0

                KeAcquireSpinLock(pStrmExt->DataListLock, &oldIrql); 
                InsertTailList(&pStrmExt->SRBQueuedListHead, &pSrbEntry->ListEntry); pStrmExt->cntSRBQueued++;
                TRACE(TL_CIP_INFO,("\'%d) Fresh Srb:%x; RefCnt:%d; cntSrbQ:%d\n", (DWORD) pStrmExt->cntSRBReceived, pSrb, *plSrbUseCount, pStrmExt->cntSRBQueued));
                KeReleaseSpinLock(pStrmExt->DataListLock, oldIrql);


#ifdef SUPPORT_PREROLL_AT_RUN_STATE
                // We can operate "smoothly" if we hace N number of media sample.
                if(pStrmExt->cntSRBReceived == NUM_BUFFER_BEFORE_TRANSMIT_BEGIN) {
                    KeSetEvent(&pStrmExt->hPreRollEvent, 0, FALSE);
                }
#endif
                if(pStrmExt->pAttachFrameThreadObject) {
                    // Signal that a new frame has arrived.
                    KeSetEvent(&pStrmExt->hSrbArriveEvent, 0, FALSE);
                }
                else {
                    TRACE(TL_STRM_ERROR|TL_CIP_ERROR,("\'No thread to attach frame ?\n"));
                }
            }            

            KeReleaseMutex(pStrmExt->hStreamMutex, FALSE); 

            return;  // Note: This SRB will be completed asynchronously.
        }

        break;  // Complete SRB with error status 

    default:
        //
        // invalid / unsupported command. Fail it as such
        //
        pSrb->Status = STATUS_NOT_SUPPORTED;
        break;
    }   

    KeReleaseMutex(pStrmExt->hStreamMutex, FALSE); 


    ASSERT(pSrb->Status != STATUS_PENDING);

    // Finally, send the srb back up ...
    StreamClassStreamNotification( 
        StreamRequestComplete,
        pSrb->StreamObject,
        pSrb );
#if DBG
    pStrmExt->cntSRBPending--;
#endif
}

NTSTATUS
DriverEntry(
    IN PDRIVER_OBJECT DriverObject,
    IN PUNICODE_STRING RegistryPath
    )

/*++

Routine Description:

    This where life begins for a driver.  The stream class takes care
    of alot of stuff for us, but we still need to fill in an initialization
    structure for the stream class and call it.

Arguments:

    Context1 - DriverObject
    Context2 - RegistryPath

Return Value:

    The function value is the final status from the initialization operation.

--*/
{

    HW_INITIALIZATION_DATA HwInitData;


    TRACE(TL_PNP_ERROR,("<<<<<<< MSDV.sys: %s; %s; %x %x >>>>>>>>\n", 
        __DATE__, __TIME__, DriverObject, RegistryPath));

#ifdef TIME_BOMB
    if (HasEvaluationTimeExpired()) {
        TRACE(TL_PNP_ERROR, ("Evaluation period expired!") );
        return STATUS_EVALUATION_EXPIRATION;
    }
#endif

    TRACE(TL_PNP_ERROR,("===================================================================\n"));
    TRACE(TL_PNP_ERROR,("DVTraceMask=0x%.8x = 0x[7][6][5][4][3][2][1][0] where\n", DVTraceMask));
    TRACE(TL_PNP_ERROR,("\n"));
    TRACE(TL_PNP_ERROR,("PNP:   [0]:Loading, power state, surprise removal, device SRB..etc.\n"));
    TRACE(TL_PNP_ERROR,("61883: [1]:Plugs, connection, CMP info and call to 61883.\n"));
    TRACE(TL_PNP_ERROR,("CIP:   [2]:Isoch data transfer.\n"));
    TRACE(TL_PNP_ERROR,("AVC:   [3]:AVC commands.\n"));
    TRACE(TL_PNP_ERROR,("Stream:[4]:Data intersec, open/close,.state, property etc.\n"));
    TRACE(TL_PNP_ERROR,("Clock: [5]:Clock (event and signal)etc.\n"));
    TRACE(TL_PNP_ERROR,("===================================================================\n"));
    TRACE(TL_PNP_ERROR,("dd msdv!DVTraceMask L1\n"));
    TRACE(TL_PNP_ERROR,("e msdv!DVTraceMask <new value> <enter>\n"));
    TRACE(TL_PNP_ERROR,("<for each nibble: ERROR:8, WARNING:4, TRACE:2, INFO:1, MASK:f>\n"));
    TRACE(TL_PNP_ERROR,("===================================================================\n\n"));


    //
    // Fill in the HwInitData structure    
    //
    RtlZeroMemory( &HwInitData, sizeof(HW_INITIALIZATION_DATA) );

    HwInitData.HwInitializationDataSize = sizeof(HwInitData);
    HwInitData.HwInterrupt              = NULL;

    HwInitData.HwReceivePacket          = DVRcvStreamDevicePacket;
    HwInitData.HwRequestTimeoutHandler  = DVTimeoutHandler; 
    HwInitData.HwCancelPacket           = DVCancelOnePacket;
    HwInitData.DeviceExtensionSize      = sizeof(DVCR_EXTENSION);   // Per device

    //
    // The ULONG is used in SRB_WRITE_DATA to keep track of 
    // number of times the same SRB was attached for transmit.
    // 
    // Data SRB: ULONG is used (< sizeof(AV_61883_REQ)
    // DeviceControl or StreamControl Srb: AV_61883_REQ is used.
    HwInitData.PerRequestExtensionSize  = sizeof(AV_61883_REQUEST);    // Per SRB
    HwInitData.PerStreamExtensionSize   = sizeof(STREAMEX);         // Per pin/stream
    HwInitData.FilterInstanceExtensionSize = 0;

    HwInitData.BusMasterDMA             = FALSE;
    HwInitData.Dma24BitAddresses        = FALSE;
    HwInitData.BufferAlignment          = sizeof(ULONG) - 1;
    HwInitData.TurnOffSynchronization   = TRUE;
    HwInitData.DmaBufferSize            = 0;

    return StreamClassRegisterAdapter(DriverObject, RegistryPath, &HwInitData); 
}
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\drivers\wdm\capture\mini\msdv\msdvutil.h ===
//
// Copyright (C) Microsoft Corporation, 1999 - 2000  
//
// MsdvUtil.h
//


VOID
DVDelayExecutionThread(
    ULONG ulDelayMSec
    );

NTSTATUS
DVSubmitIrpSynchWithTimeout(
    IN PDVCR_EXTENSION   pDevExt,
    IN PIRP              pIrp,
    IN PAV_61883_REQUEST pAVReq,
    IN ULONG             ulTimeoutMSec
    );

NTSTATUS
DVSubmitIrpSynch(
    IN PDVCR_EXTENSION   pDevExt,
    IN PIRP              pIrp,
    IN PAV_61883_REQUEST pAVReq
    );

//
// Related to DeviceControl
//

NTSTATUS
DVGetUnitCapabilities(
    IN OUT PDVCR_EXTENSION   pDevExt
    );

BOOL
DVGetDevModeOfOperation(   
    IN OUT PDVCR_EXTENSION  pDevExt
    );

BOOL
DVGetDevIsItDVCPro(   
    IN OUT PDVCR_EXTENSION  pDevExt
    );

BOOL
DVGetDevSignalFormat(
    IN PDVCR_EXTENSION  pDevExt,
    IN KSPIN_DATAFLOW   DataFlow,
    IN PSTREAMEX        pStrmExt
    );

BOOL 
DVCmpGUIDsAndFormatSize(
    IN PKSDATARANGE pDataRange1,
    IN PKSDATARANGE pDataRange2,
    IN BOOL fCompareSubformat,
    IN BOOL fCompareFormatSize
    );

NTSTATUS
DvAllocatePCResource(
    IN KSPIN_DATAFLOW   DataFlow,
    IN PSTREAMEX        pStrmExt
    );

NTSTATUS
DvFreePCResource(
    IN PSTREAMEX        pStrmExt
    );

NTSTATUS
DVGetDVPlug( 
    IN PDVCR_EXTENSION  pDevExt,
    IN CMP_PLUG_TYPE PlugType,
    IN ULONG  PlugNum,
    OUT HANDLE  *pPlugHandle
   );

#ifdef NT51_61883
NTSTATUS
DVSetAddressRangeExclusive( 
    IN PDVCR_EXTENSION  pDevExt
   );

NTSTATUS
DVGetUnitIsochParam( 
    IN PDVCR_EXTENSION  pDevExt,
    OUT UNIT_ISOCH_PARAMS  * pUnitIoschParams
    );

NTSTATUS
DVCreateLocalPlug( 
    IN PDVCR_EXTENSION  pDevExt,
    IN CMP_PLUG_TYPE PlugType,
    IN ULONG  PlugNum,
    OUT HANDLE  *pPlugHandle
    );

NTSTATUS
DVDeleteLocalPlug( 
    IN PDVCR_EXTENSION  pDevExt,
    IN HANDLE PlugHandle
    );
#endif

NTSTATUS
DVGetPlugState(
    IN PDVCR_EXTENSION   pDevExt,
    IN PSTREAMEX         pStrmExt,
    IN PAV_61883_REQUEST pAVReq
    );

VOID
DVAttachFrameThread(
    IN PSTREAMEX pStrmExt
    );

NTSTATUS
DVCreateAttachFrameThread(
    PSTREAMEX  pStrmExt
    );

NTSTATUS
DVConnect(
    IN KSPIN_DATAFLOW    ulDataFlow,
    IN PDVCR_EXTENSION   pDevExt,
    IN PSTREAMEX         pStrmExt,
    IN PAV_61883_REQUEST pAVReq
    );

NTSTATUS
DVDisconnect(
    IN KSPIN_DATAFLOW   ulDataFlow,
    IN PDVCR_EXTENSION  pDevExt,
    IN PSTREAMEX        pStrmExt
    );

ULONGLONG 
GetSystemTime(
    );


#ifdef MSDV_SUPPORT_EXTRACT_SUBCODE_DATA
VOID
DVCRExtractTimecodeFromFrame(
    IN PDVCR_EXTENSION pDevExt,
    IN PSTREAMEX       pStrmExt,
    IN PUCHAR          pFrameBuffer
    );
#endif

#ifdef MSDV_SUPPORT_EXTRACT_DV_DATE_TIME
VOID
DVCRExtractRecDateAndTimeFromFrame(
    IN PDVCR_EXTENSION pDevExt,
    IN PSTREAMEX       pStrmExt,
    IN PUCHAR          pFrameBuffer
    );
#endif

#ifdef MSDV_SUPPORT_MUTE_AUDIO
BOOL
DVMuteDVFrame(
    IN PDVCR_EXTENSION pDevExt,
    IN OUT PUCHAR      pFrameBuffer,
    IN BOOL            bMute     // TRUE to mute; FALSE to un-Mute
    );
#endif

BOOL
DVGetPropertyValuesFromRegistry(
    IN PDVCR_EXTENSION  pDevExt
    );

BOOL
DVSetPropertyValuesToRegistry(	
    PDVCR_EXTENSION  pDevExt
    );
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\drivers\wdm\capture\mini\msdv\msdvutil.c ===
/*++

Copyright (C) Microsoft Corporation, 1999 - 2000  

Module Name:

    MSDVUtil.c

Abstract:

    Provide utility functions for MSDV.

Last changed by:
    
    Author:      Yee J. Wu

Environment:

    Kernel mode only

Revision History:

    $Revision::                    $
    $Date::                        $

--*/

#include "strmini.h"
#include "ksmedia.h"
#include "1394.h"
#include "61883.h"
#include "avc.h"
#include "dbg.h"
#include "msdvfmt.h"
#include "msdvdef.h"
#include "MsdvAvc.h"
#include "MsdvUtil.h"  

#include "XPrtDefs.h"

#if 0  // Enable later
#ifdef ALLOC_PRAGMA
     #pragma alloc_text(PAGE, DVDelayExecutionThread)
     #pragma alloc_text(PAGE, DVGetUnitCapabilities)
     // Local variables might paged out but the called might use it in DISPATCH level!
     // #pragma alloc_text(PAGE, DVGetDevModeOfOperation)
     // #pragma alloc_text(PAGE, DVGetDevIsItDVCPro)
     // #pragma alloc_text(PAGE, DVGetDevSignalFormat)
     #pragma alloc_text(PAGE, DvAllocatePCResource)
     #pragma alloc_text(PAGE, DvFreePCResource)
     #pragma alloc_text(PAGE, DVGetPlugState)
     #pragma alloc_text(PAGE, DVConnect)
     #pragma alloc_text(PAGE, DVDisconnect)
#endif
#endif

extern DV_FORMAT_INFO DVFormatInfoTable[];

VOID
DVDelayExecutionThread(
    ULONG ulDelayMSec
    )
/*
    Device might need a "wait" in between AV/C commands.
*/
{
    PAGED_CODE();

    if (ulDelayMSec)
    {
        LARGE_INTEGER tmDelay;   

        TRACE(TL_PNP_TRACE,("\'DelayExeThrd: %d MSec\n",  ulDelayMSec));
    
        tmDelay.LowPart  =  (ULONG) (-1 * ulDelayMSec * 10000);
        tmDelay.HighPart = -1;
        KeDelayExecutionThread(KernelMode, FALSE, &tmDelay);
    }
}


NTSTATUS
DVIrpSynchCR(
    IN PDEVICE_OBJECT   DeviceObject,
    IN PIRP             pIrp,
    IN PKEVENT          Event
    )
{
    KeSetEvent(Event, 0, FALSE);
    return STATUS_MORE_PROCESSING_REQUIRED;
} // DVIrpSynchCR


NTSTATUS
DVSubmitIrpSynch(
    IN PDVCR_EXTENSION   pDevExt,
    IN PIRP              pIrp,
    IN PAV_61883_REQUEST pAVReq
    )
{
    NTSTATUS            Status;
    KEVENT              Event;
    PIO_STACK_LOCATION  NextIrpStack;
  

    Status = STATUS_SUCCESS;;

    NextIrpStack = IoGetNextIrpStackLocation(pIrp);
    NextIrpStack->MajorFunction = IRP_MJ_INTERNAL_DEVICE_CONTROL;
    NextIrpStack->Parameters.DeviceIoControl.IoControlCode = IOCTL_61883_CLASS;
    NextIrpStack->Parameters.Others.Argument1 = pAVReq;

    KeInitializeEvent(&Event, NotificationEvent, FALSE);

    IoSetCompletionRoutine( 
        pIrp,
        DVIrpSynchCR,
        &Event,
        TRUE,
        TRUE,
        TRUE
        );

    Status = 
        IoCallDriver(
            pDevExt->pBusDeviceObject,
            pIrp
            );

    if (Status == STATUS_PENDING) {
        
        TRACE(TL_PNP_TRACE,("\'Irp is pending...\n"));
                
        if(KeGetCurrentIrql() < DISPATCH_LEVEL) {
            KeWaitForSingleObject( 
                &Event,
                Executive,
                KernelMode,
                FALSE,
                NULL
                );
            TRACE(TL_PNP_TRACE,("\'Irp has returned; IoStatus==Status %x\n", pIrp->IoStatus.Status));
            Status = pIrp->IoStatus.Status;  // Final status
  
        }
        else {
            ASSERT(FALSE && "Pending but in DISPATCH_LEVEL!");
            return Status;
        }
    }

    return Status;
} // DVSubmitIrpSynchAV



BOOL
DVGetDevModeOfOperation(   
    IN PDVCR_EXTENSION pDevExt
    )
{
    NTSTATUS Status;
    BYTE    bAvcBuf[MAX_FCP_PAYLOAD_SIZE];

    PAGED_CODE();
   
    //
    // Use ConnectAV STATUS cmd to determine mode of operation,
    // except for some Canon DVs that it requires its vendor specific command
    //    
    
    Status = 
        DVIssueAVCCommand(
            pDevExt, 
            AVC_CTYPE_STATUS, 
            DV_CONNECT_AV_MODE, 
            (PVOID) bAvcBuf
            ); 

    TRACE(TL_FCP_TRACE,("\'DV_CONNECT_AV_MODE: St:%x,  %x %x %x %x : %x %x %x %x\n",
        Status, bAvcBuf[0], bAvcBuf[1], bAvcBuf[2], bAvcBuf[3], bAvcBuf[4], bAvcBuf[5], bAvcBuf[6], bAvcBuf[7]));

    if(Status == STATUS_SUCCESS) {
        if(bAvcBuf[0] == 0x0c) {
            if(bAvcBuf[1] == 0x00 &&
               bAvcBuf[2] == 0x38 &&
               bAvcBuf[3] == 0x38) {
                pDevExt->ulDevType = ED_DEVTYPE_CAMERA;  
            } else {
                pDevExt->ulDevType = ED_DEVTYPE_VCR;  
            } 
        } 
    } else if(pDevExt->ulVendorID == VENDORID_CANON) {
        // Try a vendor dependent command if it is a Canon AV device.
        Status = 
            DVIssueAVCCommand(
                pDevExt, 
                AVC_CTYPE_STATUS, 
                DV_VEN_DEP_CANON_MODE, 
                (PVOID) bAvcBuf
                ); 

        TRACE(TL_FCP_WARNING,("\'DV_VEN_DEP_CANON_MODE: Status %x,  %x %x %x %x : %x %x %x %x  %x %x\n",
            Status, bAvcBuf[0], bAvcBuf[1], bAvcBuf[2], bAvcBuf[3], bAvcBuf[4], bAvcBuf[5], bAvcBuf[6], bAvcBuf[7], bAvcBuf[8], bAvcBuf[9]));

        if(Status == STATUS_SUCCESS) {
            if(bAvcBuf[0] == 0x0c) {
                if(bAvcBuf[7] == 0x38) {
                    pDevExt->ulDevType = ED_DEVTYPE_CAMERA;  
                } else 
                if(bAvcBuf[7] == 0x20) {
                    pDevExt->ulDevType = ED_DEVTYPE_VCR;  
                } 
            }
        }
    }

    if(Status != STATUS_SUCCESS) {
        pDevExt->ulDevType = ED_DEVTYPE_UNKNOWN;
        TRACE(TL_FCP_ERROR,("\'DV_CONNECT_AV_MODE: Status %x, DevType %x,  %x %x %x %x : %x %x %x %x : %x %x\n",
             Status, pDevExt->ulDevType, bAvcBuf[0], bAvcBuf[1], bAvcBuf[2], bAvcBuf[3], bAvcBuf[4], bAvcBuf[5], bAvcBuf[6], bAvcBuf[7], bAvcBuf[8], bAvcBuf[9]));
    }

    TRACE(TL_FCP_WARNING,("\'%s; NumOPlg:%d; NumIPlg:%d\n", 
        pDevExt->ulDevType == ED_DEVTYPE_CAMERA ? "Camera" : pDevExt->ulDevType == ED_DEVTYPE_VCR ? "VTR" : "Unknown",
        pDevExt->NumOutputPlugs, pDevExt->NumInputPlugs));
              
    return TRUE;
}


BOOL
DVGetDevIsItDVCPro(   
    IN PDVCR_EXTENSION pDevExt
    )
{
    NTSTATUS Status;
    BYTE    bAvcBuf[MAX_FCP_PAYLOAD_SIZE];

    PAGED_CODE();    

    //
    // Use Panasnoic's vendor dependent command to determine if the system support DVCPro
    //    
    
    Status = 
        DVIssueAVCCommand(
            pDevExt, 
            AVC_CTYPE_STATUS, 
            DV_VEN_DEP_DVCPRO, 
            (PVOID) bAvcBuf
            );

    pDevExt->bDVCPro = Status == STATUS_SUCCESS;
    
    TRACE(TL_FCP_WARNING,("\'DVGetDevIsItDVCPro? %s; Status %x,  %x %x %x %x : %x %x %x %x\n",
        pDevExt->bDVCPro ? "Yes":"No",
        Status, bAvcBuf[0], bAvcBuf[1], bAvcBuf[2], bAvcBuf[3], bAvcBuf[4], bAvcBuf[5], bAvcBuf[6], bAvcBuf[7]));

    return pDevExt->bDVCPro;
}


// The retries might be redundant since AVC.sys and 1394.sys retries.
// For device that TIMEOUT an AVC command, we will only try it once.
#define GET_MEDIA_FMT_MAX_RETRIES 10  

BOOL
DVGetDevSignalFormat(
    IN PDVCR_EXTENSION pDevExt,
    IN KSPIN_DATAFLOW  DataFlow,
    IN PSTREAMEX       pStrmExt
    )
{
    NTSTATUS Status;
    BYTE    bAvcBuf[MAX_FCP_PAYLOAD_SIZE];
    LONG lRetries = GET_MEDIA_FMT_MAX_RETRIES;

    PAGED_CODE();

    //
    // Respone of Input/output signal mode is used to determine plug signal format:
    //
    //     FMT: 
    //         DVCR 10:00 0000 = 0x80; Canon returns 00:100000 (0x20)
    //             50/60: 0:NTSC/60; 1:PAL/50
    //             STYPE:
    //                 SD: 00000  (DVCPRO:11110)
    //                 HD: 00010
    //                 SDL:00001
    //             00:
    //             SYT:
    //         MPEG 10:10 0000 = 0xa0
    //             TSF:0:NotTimeShifted; 1:Time shifted
    //             000 0000 0000 0000 0000 0000
    //
    // If this command failed, we can use Input/Output Signal Mode subunit command
    // to determine signal format.
    // 

    do {
        RtlZeroMemory(bAvcBuf, sizeof(bAvcBuf));
        Status = 
            DVIssueAVCCommand(
                pDevExt, 
                AVC_CTYPE_STATUS, 
                pStrmExt == NULL ? DV_OUT_PLUG_SIGNAL_FMT : (DataFlow == KSPIN_DATAFLOW_OUT ? DV_OUT_PLUG_SIGNAL_FMT : DV_IN_PLUG_SIGNAL_FMT),
                (PVOID) bAvcBuf
                );  
        
        // 
        // Camcorders that has problem with this command:
        //
        // Panasonic's DVCPRO: if power on while connected to PC, it will 
        // reject this command with (STATUS_REQUEST_NOT_ACCEPTED)
        // so we will retry up to 10 time with .5 second wait between tries.
        //
        // JVC: returns STATUS_NOT_SUPPORTED.
        //
        // SONY DV Decoder Box: return STATUS_TIMEOUT or STATUS_REQUEST_ABORTED 
        //
        
        if(STATUS_REQUEST_ABORTED == Status)
            return FALSE;
        else if(STATUS_SUCCESS == Status)
            break;  // Normal case.
        else if(STATUS_NOT_SUPPORTED == Status || STATUS_TIMEOUT == Status) {
            TRACE(TL_FCP_WARNING | TL_PNP_WARNING,("SignalFormat: Encountered a known failed status:%x; no more retry\n", Status));
            break;  // No need to retry
        } else {
            if(Status == STATUS_REQUEST_NOT_ACCEPTED) {
                // If device is not accepting command and return this status, retry.
                if(lRetries > 0) {
                    TRACE(TL_FCP_WARNING | TL_PNP_WARNING,("\'ST:%x; Retry getting signal mode; wait...\n", Status));
                    DVDelayExecutionThread(DV_AVC_CMD_DELAY_DVCPRO);        
                }
            }
        }       

    } while (--lRetries >= 0); 



    if(NT_SUCCESS(Status)) {

        switch(bAvcBuf[0]) {

        case FMT_DVCR:
        case FMT_DVCR_CANON:  // Workaround for buggy Canon Camcorders
            switch(bAvcBuf[1] & FDF0_STYPE_MASK) {
            case FDF0_STYPE_SD_DVCR:
            case FDF0_STYPE_SD_DVCPRO:                
                pDevExt->VideoFormatIndex = ((bAvcBuf[1] & FDF0_50_60_MASK) ? FMT_IDX_SD_DVCR_PAL : FMT_IDX_SD_DVCR_NTSC);
                if(pStrmExt)
                    RtlCopyMemory(&pStrmExt->cipQuad2[0], &bAvcBuf[0], 4);
                break;
#ifdef MSDV_SUPPORT_HD_DVCR
            case FDF0_STYPE_HD_DVCR:
                pDevExt->VideoFormatIndex = ((bAvcBuf[1] & FDF0_50_60_MASK) ? FMT_IDX_HD_DVCR_PAL : FMT_IDX_HD_DVCR_NTSC);
                if(pStrmExt)
                    RtlCopyMemory(&pStrmExt->cipQuad2[0], &bAvcBuf[0], 4);
                break;
#endif
#ifdef MSDV_SUPPORT_SDL_DVCR
            case FDF0_STYPE_SDL_DVCR:
                pDevExt->VideoFormatIndex = ((bAvcBuf[1] & FDF0_50_60_MASK) ? FMT_IDX_SDL_DVCR_PAL : FMT_IDX_SDL_DVCR_NTSC);
                if(pStrmExt)
                    RtlCopyMemory(&pStrmExt->cipQuad2[0], &bAvcBuf[0], 4);
                break;     
#endif                
            default:  // Unknown format
                Status = STATUS_UNSUCCESSFUL;              
                break;
            }   
            break;
#ifdef MSDV_SUPPORT_MPEG2TS
        case FMT_MPEG:
            pDevExt->VideoFormatIndex = FMT_IDX_MPEG2TS;
            if(pStrmExt)
                RtlCopyMemory(&pStrmExt->cipQuad2[0], &bAvcBuf[0], 4);
            break;
#endif
        default:
            Status = STATUS_UNSUCCESSFUL;
        }  

        if(NT_SUCCESS(Status)) {
            TRACE(TL_FCP_WARNING,("\'ST:%x; PlugSignal:FMT[%x %x %x %x]; VideoFormatIndex;%d\n", Status, bAvcBuf[0], bAvcBuf[1], bAvcBuf[2] , bAvcBuf[3], pDevExt->VideoFormatIndex)); 
            return TRUE;  // Success
        }
    }
    TRACE(TL_FCP_WARNING,("\'ST:%x; PlugSignal:FMT[%x %x %x %x]\n", Status, bAvcBuf[0], bAvcBuf[1], bAvcBuf[2] , bAvcBuf[3], pDevExt->VideoFormatIndex)); 

    //
    // If "recommended" unit input/output plug signal status command fails,
    // try "manadatory" input/output signal mode status command.
    // This command may failed some device if its tape is not playing for
    // output signal mode command.
    //

    Status = 
        DVIssueAVCCommand(
            pDevExt, 
            AVC_CTYPE_STATUS, 
            DataFlow == KSPIN_DATAFLOW_OUT ? VCR_OUTPUT_SIGNAL_MODE : VCR_INPUT_SIGNAL_MODE,
            (PVOID) bAvcBuf
            );             

    if(STATUS_SUCCESS == Status) {

        PKSPROPERTY_EXTXPORT_S pXPrtProperty;

        pXPrtProperty = (PKSPROPERTY_EXTXPORT_S) bAvcBuf;
        TRACE(TL_FCP_WARNING,("\'** MediaFormat: Retry %d mSec; ST:%x; SignalMode:%dL\n", 
            (GET_MEDIA_FMT_MAX_RETRIES - lRetries) * DV_AVC_CMD_DELAY_DVCPRO, Status, pXPrtProperty->u.SignalMode - ED_BASE));

        switch(pXPrtProperty->u.SignalMode) {
        case ED_TRANSBASIC_SIGNAL_525_60_SD:
            pDevExt->VideoFormatIndex = FMT_IDX_SD_DVCR_NTSC;
            if(pStrmExt) {
                pStrmExt->cipQuad2[0] = FMT_DVCR; // 0x80 
                if(pDevExt->bDVCPro)
                    pStrmExt->cipQuad2[1] = FDF0_50_60_NTSC | FDF0_STYPE_SD_DVCPRO; // 0x78 = NTSC(0):STYPE(11110):RSV(00)
                else
                    pStrmExt->cipQuad2[1] = FDF0_50_60_NTSC | FDF0_STYPE_SD_DVCR;   // 0x00 = NTSC(0):STYPE(00000):RSV(00)            
            }
            break;
        case ED_TRANSBASIC_SIGNAL_625_50_SD:
            pDevExt->VideoFormatIndex = FMT_IDX_SD_DVCR_PAL;
            if(pStrmExt) {
                pStrmExt->cipQuad2[0] = FMT_DVCR;  // 0x80
                if(pDevExt->bDVCPro)
                    pStrmExt->cipQuad2[1] = FDF0_50_60_PAL | FDF0_STYPE_SD_DVCPRO; // 0xf8 = PAL(1):STYPE(11110):RSV(00)
                else
                    pStrmExt->cipQuad2[1] = FDF0_50_60_PAL | FDF0_STYPE_SD_DVCR;   // 0x80 = PAL(1):STYPE(00000):RSV(00)             
            }
            break;
#ifdef MSDV_SUPPORT_SDL_DVCR
        case ED_TRANSBASIC_SIGNAL_525_60_SDL:
            pDevExt->VideoFormatIndex = FMT_IDX_SDL_DVCR_NTSC;
            if(pStrmExt) {
                pStrmExt->cipQuad2[0] = FMT_DVCR; // 0x80 
                pStrmExt->cipQuad2[1] = FDF0_50_60_NTSC | FDF0_STYPE_SDL_DVCR;   
            }
            break;
        case ED_TRANSBASIC_SIGNAL_625_50_SDL:
            pDevExt->VideoFormatIndex = FMT_IDX_SDL_DVCR_PAL;
            if(pStrmExt) {
                pStrmExt->cipQuad2[0] = FMT_DVCR;  // 0x80
                pStrmExt->cipQuad2[1] = FDF0_50_60_PAL | FDF0_STYPE_SDL_DVCR;  
            }
            break;
#endif
        default:
            TRACE(TL_FCP_ERROR,("\'Unsupported SignalMode:%dL", pXPrtProperty->u.SignalMode - ED_BASE));
            ASSERT(FALSE && "Unsupported IoSignal! Refuse to load.");
            return FALSE;
            break;
        }
    } 

    // WORKITEM Sony HW CODEC does not response to any AVC command.
    // We are making an exception here to load it.
    if(Status == STATUS_TIMEOUT) {
        Status = STATUS_SUCCESS;
    }

    // We must know the signal format!!  If this failed, the driver will either:
    //    fail to load, or fail to open an stream
    ASSERT(Status == STATUS_SUCCESS && "Failed to get media signal format!\n");

#if DBG
    if(pStrmExt)  {
        // Note: bAvcBuf[0] is operand[1] == 10:fmt
        TRACE(TL_FCP_WARNING,("\'** MediaFormat: St:%x; idx:%d; CIP:[FMT:%.2x(%s); FDF:[%.2x(%s,%s):SYT]\n",
            Status,
            pDevExt->VideoFormatIndex,
            pStrmExt->cipQuad2[0],
            pStrmExt->cipQuad2[0] == FMT_DVCR ? "DVCR" : pStrmExt->cipQuad2[0] == FMT_MPEG ? "MPEG" : "Fmt:???",
            pStrmExt->cipQuad2[1],
            (pStrmExt->cipQuad2[1] & FDF0_50_60_MASK) == FDF0_50_60_PAL ? "PAL" : "NTSC",
            (pStrmExt->cipQuad2[1] & FDF0_STYPE_MASK) == FDF0_STYPE_SD_DVCR ?   "SD" : \
            (pStrmExt->cipQuad2[1] & FDF0_STYPE_MASK) == FDF0_STYPE_SDL_DVCR ?  "SDL" : \
            (pStrmExt->cipQuad2[1] & FDF0_STYPE_MASK) == FDF0_STYPE_HD_DVCR ?   "HD" : \
            (pStrmExt->cipQuad2[1] & FDF0_STYPE_MASK) == FDF0_STYPE_SD_DVCPRO ? "DVCPRO" : "DV:????"
            ));
    } else
        TRACE(TL_FCP_WARNING|TL_CIP_WARNING,("\'** MediaFormat: St:%x; use idx:%d\n", Status, pDevExt->VideoFormatIndex));

#endif

    return STATUS_SUCCESS == Status;
}



BOOL 
DVCmpGUIDsAndFormatSize(
    IN PKSDATARANGE pDataRange1,
    IN PKSDATARANGE pDataRange2,
    IN BOOL fCompareSubformat,
    IN BOOL fCompareFormatSize
    )
/*++

Routine Description:

    Checks for a match on the three GUIDs and FormatSize

Arguments:

    IN pDataRange1
    IN pDataRange2

Return Value:

    TRUE if all elements match
    FALSE if any are different

--*/

{
    return (
        IsEqualGUID (
            &pDataRange1->MajorFormat, 
            &pDataRange2->MajorFormat) &&
        (fCompareSubformat ?
        IsEqualGUID (
            &pDataRange1->SubFormat, 
            &pDataRange2->SubFormat) : TRUE) &&
        IsEqualGUID (
            &pDataRange1->Specifier, 
            &pDataRange2->Specifier) &&
        (fCompareFormatSize ? 
                (pDataRange1->FormatSize == pDataRange2->FormatSize) : TRUE ));
}


NTSTATUS
DvAllocatePCResource(
    IN KSPIN_DATAFLOW   DataFlow,
    IN PSTREAMEX        pStrmExt  // Note that pStrmExt can be NULL!
    )
{

    PSRB_DATA_PACKET pSrbDataPacket;
    PDVCR_EXTENSION  pDevExt;
    ULONG             i, j;

    PAGED_CODE();


    //
    // Pre-allcoate PC resource
    //
    pDevExt = pStrmExt->pDevExt;
    for(i=0; i < (DataFlow == KSPIN_DATAFLOW_OUT ? \
        DVFormatInfoTable[pDevExt->VideoFormatIndex].ulNumOfRcvBuffers : \
        DVFormatInfoTable[pDevExt->VideoFormatIndex].ulNumOfXmtBuffers); i++) {

        if(!(pSrbDataPacket = ExAllocatePool(NonPagedPool, sizeof(SRB_DATA_PACKET)))) {

            for(j = 0; j < i; j++) {
                pSrbDataPacket = (PSRB_DATA_PACKET) \
                    RemoveHeadList(&pStrmExt->DataDetachedListHead); pStrmExt->cntDataDetached--;
                ExFreePool(pSrbDataPacket->Frame);  pSrbDataPacket->Frame = NULL;
                IoFreeIrp(pSrbDataPacket->pIrp);  pSrbDataPacket->pIrp = NULL;
                ExFreePool(pSrbDataPacket);   pSrbDataPacket = NULL;               
                ASSERT(pStrmExt->cntDataDetached >= 0);
                return STATUS_NO_MEMORY;
            }
        }

        RtlZeroMemory(pSrbDataPacket, sizeof(SRB_DATA_PACKET));
        pSrbDataPacket->State = DE_IRP_SRB_COMPLETED;  // Initial state.

        if(!(pSrbDataPacket->Frame = ExAllocatePool(NonPagedPool, sizeof(CIP_FRAME)))) {
            ExFreePool(pSrbDataPacket);  pSrbDataPacket = NULL;

            for(j = 0; j < i; j++) {
                pSrbDataPacket = (PSRB_DATA_PACKET) \
                    RemoveHeadList(&pStrmExt->DataDetachedListHead); pStrmExt->cntDataDetached--;
                ExFreePool(pSrbDataPacket->Frame);  pSrbDataPacket->Frame = NULL;
                IoFreeIrp(pSrbDataPacket->pIrp);  pSrbDataPacket->pIrp = NULL;
                ExFreePool(pSrbDataPacket);  pSrbDataPacket = NULL;  
                return STATUS_NO_MEMORY;
            }
        }

        if(!(pSrbDataPacket->pIrp = IoAllocateIrp(pDevExt->pBusDeviceObject->StackSize, FALSE))) {
            ExFreePool(pSrbDataPacket->Frame); pSrbDataPacket->Frame = NULL;
            ExFreePool(pSrbDataPacket);  pSrbDataPacket = NULL;

            for(j = 0; j < i; j++) {
                pSrbDataPacket = (PSRB_DATA_PACKET) \
                    RemoveHeadList(&pStrmExt->DataDetachedListHead); pStrmExt->cntDataDetached--;
                ExFreePool(pSrbDataPacket->Frame);  pSrbDataPacket->Frame = NULL;
                IoFreeIrp(pSrbDataPacket->pIrp);  pSrbDataPacket->pIrp = NULL;
                ExFreePool(pSrbDataPacket);  pSrbDataPacket = NULL;                
                return STATUS_INSUFFICIENT_RESOURCES;  
            }
        }

        InsertTailList(&pStrmExt->DataDetachedListHead, &pSrbDataPacket->ListEntry); pStrmExt->cntDataDetached++;
    }

    return STATUS_SUCCESS;
}


NTSTATUS
DvFreePCResource(
    IN PSTREAMEX        pStrmExt
    )
{
    PSRB_DATA_PACKET pSrbDataPacket;
    KIRQL oldIrql;

    PAGED_CODE();

    KeAcquireSpinLock(pStrmExt->DataListLock, &oldIrql);
    while(!IsListEmpty(&pStrmExt->DataDetachedListHead)) {
        pSrbDataPacket = (PSRB_DATA_PACKET)
            RemoveHeadList(
                &pStrmExt->DataDetachedListHead
                );

        ExFreePool(pSrbDataPacket->Frame);
        pSrbDataPacket->Frame = NULL;
        IoFreeIrp(pSrbDataPacket->pIrp);
        pSrbDataPacket->pIrp = NULL;
        ExFreePool(pSrbDataPacket);

        pStrmExt->cntDataDetached--;

        ASSERT(pStrmExt->cntDataDetached >= 0);
    }
    ASSERT(pStrmExt->cntDataDetached == 0);
    KeReleaseSpinLock(pStrmExt->DataListLock, oldIrql);

    return STATUS_SUCCESS;
}

NTSTATUS
DVGetUnitCapabilities(
    IN PDVCR_EXTENSION  pDevExt
    )
/*++

Routine Description:

    Get the targe device's unit capabilities
 
Arguments:

Return Value:

    STATUS_SUCCESS 
    STATUS_INSUFFICIENT_RESOURCES
    status return from 61883.

--*/
{
    PIRP pIrp;
    PAV_61883_REQUEST  pAVReq;
    NTSTATUS Status = STATUS_SUCCESS;
    GET_UNIT_IDS * pUnitIds;
    GET_UNIT_CAPABILITIES * pUnitCaps;

    PAGED_CODE();

    if(!(pIrp = IoAllocateIrp(pDevExt->pBusDeviceObject->StackSize, FALSE)))
        return STATUS_INSUFFICIENT_RESOURCES;

    if(!(pAVReq = (AV_61883_REQUEST *) ExAllocatePool(NonPagedPool, sizeof(AV_61883_REQUEST)))) { 
        IoFreeIrp(pIrp); pIrp = NULL;
        return STATUS_INSUFFICIENT_RESOURCES;
    }

    //
    // Query device's capability
    //
    if(!(pUnitIds = (GET_UNIT_IDS *) ExAllocatePool(NonPagedPool, sizeof(GET_UNIT_IDS)))) {
        IoFreeIrp(pIrp); pIrp = NULL;
        ExFreePool(pAVReq); pAVReq = NULL;
        return STATUS_INSUFFICIENT_RESOURCES;
    }
    
    //
    // Query device's capability
    //
    if(!(pUnitCaps = (GET_UNIT_CAPABILITIES *) ExAllocatePool(NonPagedPool, sizeof(GET_UNIT_CAPABILITIES)))) {
        IoFreeIrp(pIrp); pIrp = NULL;
        ExFreePool(pAVReq); pAVReq = NULL;
        ExFreePool(pUnitIds);  pUnitIds = NULL;
        return STATUS_INSUFFICIENT_RESOURCES;
    }

    RtlZeroMemory(pAVReq, sizeof(AV_61883_REQUEST));
    INIT_61883_HEADER(pAVReq, Av61883_GetUnitInfo);
    pAVReq->GetUnitInfo.nLevel   = GET_UNIT_INFO_IDS;

    RtlZeroMemory(pUnitIds, sizeof(GET_UNIT_IDS));
    pAVReq->GetUnitInfo.Information = (PVOID) pUnitIds;

    Status = 
        DVSubmitIrpSynch( 
            pDevExt,
            pIrp,
            pAVReq
            );

    if(!NT_SUCCESS(Status)) {
        TRACE(TL_61883_ERROR,("\'Av61883_GetUnitInfo (IDS) Failed = 0x%x\n", Status));
        pDevExt->UniqueID.QuadPart = 0;
        pDevExt->ulVendorID = 0;
        pDevExt->ulModelID  = 0;
    }
    else {
        pDevExt->UniqueID   = pUnitIds->UniqueID;
        pDevExt->ulVendorID = pUnitIds->VendorID;
        pDevExt->ulModelID  = pUnitIds->ModelID;

        TRACE(TL_61883_WARNING,("\'UniqueId:(%x:%x); VID:%x; MID:%x\n", 
            pDevExt->UniqueID.LowPart, pDevExt->UniqueID.HighPart, 
            pUnitIds->VendorID,
            pUnitIds->ModelID
            ));
    }


    RtlZeroMemory(pAVReq, sizeof(AV_61883_REQUEST));
    INIT_61883_HEADER(pAVReq, Av61883_GetUnitInfo);
    pAVReq->GetUnitInfo.nLevel = GET_UNIT_INFO_CAPABILITIES; 

    RtlZeroMemory(pUnitCaps, sizeof(GET_UNIT_CAPABILITIES));
    pAVReq->GetUnitInfo.Information = (PVOID) pUnitCaps;

    Status = 
        DVSubmitIrpSynch( 
            pDevExt,
            pIrp,
            pAVReq
            );

    if(!NT_SUCCESS(Status)) {
        TRACE(TL_61883_ERROR,("Av61883_GetUnitInfo (CAPABILITIES) Failed = 0x%x\n", Status));
        pDevExt->MaxDataRate    = 0;
        pDevExt->NumOutputPlugs = 0;
        pDevExt->NumInputPlugs  = 0;
        pDevExt->HardwareFlags  = 0;
    }
    else {
        pDevExt->MaxDataRate     = pUnitCaps->MaxDataRate;
        pDevExt->NumOutputPlugs = pUnitCaps->NumOutputPlugs;
        pDevExt->NumInputPlugs  = pUnitCaps->NumInputPlugs;
        pDevExt->HardwareFlags  = pUnitCaps->HardwareFlags;
    }

#if DBG
    if(   pDevExt->NumOutputPlugs == 0
       || pDevExt->NumInputPlugs == 0)
    {
        TRACE(TL_PNP_WARNING|TL_61883_WARNING,("\'Watch out! NumOPlug:%d; NumIPlug:%d\n", pDevExt->NumOutputPlugs, pDevExt->NumInputPlugs));
    }
#endif

    TRACE(TL_61883_WARNING,("\'UnitCaps:%s OutP:%d; InP:%d; MDRt:%s; HWFlg:%x; CtsF:%x; HwF:%x\n", 
         (pUnitCaps->HardwareFlags & AV_HOST_DMA_DOUBLE_BUFFERING_ENABLED) ? "*PAE*;":"",
         pUnitCaps->NumOutputPlugs,
         pUnitCaps->NumInputPlugs,
         pUnitCaps->MaxDataRate == 0 ? "S100": pUnitCaps->MaxDataRate == 1? "S200" : "S400 or +",   
         pUnitCaps->HardwareFlags,
         pUnitCaps->CTSFlags,
         pUnitCaps->HardwareFlags
         ));      

    ExFreePool(pUnitIds);   pUnitIds = NULL;
    ExFreePool(pUnitCaps);  pUnitCaps = NULL;
    IoFreeIrp(pIrp); pIrp = NULL;
    ExFreePool(pAVReq); pAVReq = NULL;

    return Status;
}


NTSTATUS
DVGetDVPlug( 
    IN PDVCR_EXTENSION  pDevExt,
    IN CMP_PLUG_TYPE PlugType,
    IN ULONG  PlugNum,
    OUT HANDLE  *pPlugHandle
   )
/*++

Routine Description:

    Get the targe device's plug handle
 
Arguments:

Return Value:

    STATUS_SUCCESS 
    STATUS_INSUFFICIENT_RESOURCES
    status return from 61883.

--*/
{
    PIRP pIrp;
    PAV_61883_REQUEST  pAVReq;
    NTSTATUS Status = STATUS_SUCCESS;

    PAGED_CODE();

    if(!(pIrp = IoAllocateIrp(pDevExt->pBusDeviceObject->StackSize, FALSE)))
        return STATUS_INSUFFICIENT_RESOURCES;

    if(!(pAVReq = (AV_61883_REQUEST *) ExAllocatePool(NonPagedPool, sizeof(AV_61883_REQUEST)))) { 
        IoFreeIrp(pIrp); pIrp = NULL;
        return STATUS_INSUFFICIENT_RESOURCES;
    }

    RtlZeroMemory(pAVReq, sizeof(AV_61883_REQUEST));
    INIT_61883_HEADER(pAVReq, Av61883_GetPlugHandle);
    pAVReq->GetPlugHandle.PlugNum = PlugNum;
    pAVReq->GetPlugHandle.hPlug   = 0;
    pAVReq->GetPlugHandle.Type    = PlugType;

    if(NT_SUCCESS(
        Status = DVSubmitIrpSynch( 
            pDevExt,
            pIrp,
            pAVReq
            ))) {
        *pPlugHandle = pAVReq->GetPlugHandle.hPlug;
        TRACE(TL_61883_WARNING,("\'Created h%sPlugDV[%d]=%x\n", PlugType == CMP_PlugIn ? "I" : "O", PlugNum, *pPlugHandle));
    } else {
        TRACE(TL_61883_ERROR,("\'Created h%sPlugDV[%d] failed; Status:%x\n", PlugType == CMP_PlugIn ? "I" : "O", PlugNum, Status));
        Status = STATUS_INSUFFICIENT_RESOURCES;
    }

    IoFreeIrp(pIrp); pIrp = NULL;
    ExFreePool(pAVReq); pAVReq = NULL;

    return Status;
}


#ifdef NT51_61883

NTSTATUS
DVSetAddressRangeExclusive( 
    IN PDVCR_EXTENSION  pDevExt
   )
/*++

Routine Description:

    Set this mode so that our local plug will be created in address exclusive mode.
 
Arguments:

Return Value:

    STATUS_SUCCESS 
    STATUS_INSUFFICIENT_RESOURCES

--*/
{
    PIRP pIrp;
    PAV_61883_REQUEST  pAVReq;
    NTSTATUS Status = STATUS_SUCCESS;
    SET_CMP_ADDRESS_TYPE SetCmpAddress;

    PAGED_CODE();

    if(!(pIrp = IoAllocateIrp(pDevExt->pBusDeviceObject->StackSize, FALSE)))
        return STATUS_INSUFFICIENT_RESOURCES;

    if(!(pAVReq = (AV_61883_REQUEST *) ExAllocatePool(NonPagedPool, sizeof(AV_61883_REQUEST)))) { 
        IoFreeIrp(pIrp); pIrp = NULL;
        return STATUS_INSUFFICIENT_RESOURCES;
    }

    RtlZeroMemory(pAVReq, sizeof(AV_61883_REQUEST));
    INIT_61883_HEADER(pAVReq, Av61883_SetUnitInfo);
    pAVReq->SetUnitInfo.nLevel   = SET_CMP_ADDRESS_RANGE_TYPE;
    SetCmpAddress.Type = CMP_ADDRESS_TYPE_EXCLUSIVE;
    pAVReq->SetUnitInfo.Information = (PVOID) &SetCmpAddress;

    if(!NT_SUCCESS(
        Status = DVSubmitIrpSynch( 
            pDevExt,
            pIrp,
            pAVReq
            ))) {
        TRACE(TL_61883_ERROR,("\'SET_CMP_ADDRESS_RANGE_TYPE Failed:%x\n", Status));
    } else {
        TRACE(TL_61883_TRACE,("\'SET_CMP_ADDRESS_RANGE_TYPE suceeded.\n"));
    }

    IoFreeIrp(pIrp); pIrp = NULL;
    ExFreePool(pAVReq); pAVReq = NULL;

    return Status;
}


NTSTATUS
DVGetUnitIsochParam( 
    IN PDVCR_EXTENSION  pDevExt,
    OUT UNIT_ISOCH_PARAMS  * pUnitIoschParams
   )
/*++

Routine Description:

    Create an enumated local PC PCR
 
Arguments:

Return Value:

    STATUS_SUCCESS 
    STATUS_INSUFFICIENT_RESOURCES

--*/
{
    PIRP pIrp;
    PAV_61883_REQUEST  pAVReq;
    NTSTATUS Status = STATUS_SUCCESS;

    PAGED_CODE();

    if(!(pIrp = IoAllocateIrp(pDevExt->pBusDeviceObject->StackSize, FALSE)))
        return STATUS_INSUFFICIENT_RESOURCES;

    if(!(pAVReq = (AV_61883_REQUEST *) ExAllocatePool(NonPagedPool, sizeof(AV_61883_REQUEST)))) { 
        IoFreeIrp(pIrp); pIrp = NULL;
        return STATUS_INSUFFICIENT_RESOURCES;
    }
    //
    // Get Unit isoch parameters
    //
    RtlZeroMemory(pAVReq, sizeof(AV_61883_REQUEST));
    INIT_61883_HEADER(pAVReq, Av61883_GetUnitInfo);
    pAVReq->GetUnitInfo.nLevel   = GET_UNIT_INFO_ISOCH_PARAMS;

    RtlZeroMemory(pUnitIoschParams, sizeof(UNIT_ISOCH_PARAMS));
    pAVReq->GetUnitInfo.Information = (PVOID) pUnitIoschParams;

    Status = 
        DVSubmitIrpSynch( 
            pDevExt,
            pIrp,
            pAVReq
            );

    if(!NT_SUCCESS(Status)) {
        TRACE(TL_61883_ERROR,("Av61883_GetUnitInfo Failed:%x\n", Status));
        Status = STATUS_UNSUCCESSFUL;  // Cannot stream without this!
    }

    TRACE(TL_61883_WARNING,("\'IsochParam: RxPkt:%d, RxDesc:%d; XmPkt:%d, XmDesc:%d\n", 
        pUnitIoschParams->RX_NumPackets,
        pUnitIoschParams->RX_NumDescriptors,
        pUnitIoschParams->TX_NumPackets,
        pUnitIoschParams->TX_NumDescriptors
        ));

    IoFreeIrp(pIrp); pIrp = NULL;
    ExFreePool(pAVReq); pAVReq = NULL;

    return Status;
}


NTSTATUS
DVSetUnitIsochParams( 
    IN PDVCR_EXTENSION  pDevExt,
    IN UNIT_ISOCH_PARAMS  *pUnitIoschParams
   )
/*++

Routine Description:

    Set AV unit's isoch parameters via 61883.
 
Arguments:

Return Value:

    STATUS_SUCCESS 
    STATUS_INSUFFICIENT_RESOURCES

--*/
{
    PIRP pIrp;
    PAV_61883_REQUEST  pAVReq;
    NTSTATUS Status = STATUS_SUCCESS;

    PAGED_CODE();

    if(!(pIrp = IoAllocateIrp(pDevExt->pBusDeviceObject->StackSize, FALSE)))
        return STATUS_INSUFFICIENT_RESOURCES;

    if(!(pAVReq = (AV_61883_REQUEST *) ExAllocatePool(NonPagedPool, sizeof(AV_61883_REQUEST)))) { 
        IoFreeIrp(pIrp); pIrp = NULL;
        return STATUS_INSUFFICIENT_RESOURCES;
    }

    RtlZeroMemory(pAVReq, sizeof(AV_61883_REQUEST));
    INIT_61883_HEADER(pAVReq, Av61883_SetUnitInfo);
    pAVReq->SetUnitInfo.nLevel   = SET_UNIT_INFO_ISOCH_PARAMS;
    pAVReq->SetUnitInfo.Information = (PVOID) pUnitIoschParams;
    if(!NT_SUCCESS(
        Status = DVSubmitIrpSynch( 
            pDevExt,
            pIrp,
            pAVReq
            ))) {
        TRACE(TL_61883_ERROR,("DVSetUnitIsochParams: Av61883_SetUnitInfo Failed:%x\n", Status));
    }

    TRACE(TL_61883_WARNING,("\'UnitIsochParams: Set: RxPkt:%d, RxDesc:%d; XmPkt:%d, XmDesc:%d\n", 
        pUnitIoschParams->RX_NumPackets,
        pUnitIoschParams->RX_NumDescriptors,
        pUnitIoschParams->TX_NumPackets,
        pUnitIoschParams->TX_NumDescriptors
        ));

    IoFreeIrp(pIrp); pIrp = NULL;
    ExFreePool(pAVReq); pAVReq = NULL;

    return Status;
}


NTSTATUS
DVMakeP2PConnection( 
    IN PDVCR_EXTENSION  pDevExt,
    IN KSPIN_DATAFLOW   DataFlow,
    IN PSTREAMEX  pStrmExt
   )
/*++

Routine Description:

    Make a point to point connection .
 
Arguments:

Return Value:

    STATUS_SUCCESS 
    STATUS_INSUFFICIENT_RESOURCES

--*/
{
    PIRP pIrp;
    PAV_61883_REQUEST  pAVReq;
    NTSTATUS Status = STATUS_SUCCESS;

    PAGED_CODE();

    if(!(pIrp = IoAllocateIrp(pDevExt->pBusDeviceObject->StackSize, FALSE)))
        return STATUS_INSUFFICIENT_RESOURCES;

    if(!(pAVReq = (AV_61883_REQUEST *) ExAllocatePool(NonPagedPool, sizeof(AV_61883_REQUEST)))) { 
        IoFreeIrp(pIrp); pIrp = NULL;
        return STATUS_INSUFFICIENT_RESOURCES;
    }

    RtlZeroMemory(pAVReq, sizeof(AV_61883_REQUEST));
    INIT_61883_HEADER(pAVReq, Av61883_Connect);
    pAVReq->Connect.Type = CMP_PointToPoint;  // !!

    pAVReq->Connect.hOutputPlug      = pStrmExt->hOutputPcr;
    pAVReq->Connect.hInputPlug       = pStrmExt->hInputPcr;

    // see which way we the data will flow...
    if(DataFlow == KSPIN_DATAFLOW_OUT) {

        // Other parameters !!

    } else {

        pAVReq->Connect.Format.FMT       = pStrmExt->cipQuad2[0];  // From AV/C in/outpug plug signal format status cmd
        // 00 for NTSC, 80 for PAL; set the 50/60 bit       
        pAVReq->Connect.Format.FDF_hi    = pStrmExt->cipQuad2[1];  // From AV/C in/outpug plug signal format status cmd   

        //
        // 16bit SYT field = 4BitCycleCount:12BitCycleOffset;
        // Will be set by 61883
        //
        pAVReq->Connect.Format.FDF_mid   = 0;  
        pAVReq->Connect.Format.FDF_lo    = 0;

        //
        // Constants depend on the A/V data format (in or out plug format)
        //
        pAVReq->Connect.Format.bHeader   = (BOOL) DVFormatInfoTable[pDevExt->VideoFormatIndex].SrcPktHeader;
        pAVReq->Connect.Format.Padding   = (UCHAR) DVFormatInfoTable[pDevExt->VideoFormatIndex].QuadPadCount;
        pAVReq->Connect.Format.BlockSize = (UCHAR) DVFormatInfoTable[pDevExt->VideoFormatIndex].DataBlockSize; 
        pAVReq->Connect.Format.Fraction  = (UCHAR) DVFormatInfoTable[pDevExt->VideoFormatIndex].FractionNumber;
    }

    // Set this so that 61883 can know it is NTSC or PAL;
    // For read: It is needed so 61883 can preallocate just-enough packets
    //           so that data can return in a much regular interval.
    if(   pDevExt->VideoFormatIndex == FMT_IDX_SD_DVCR_NTSC 
       || pDevExt->VideoFormatIndex == FMT_IDX_SDL_DVCR_NTSC)
        pAVReq->Connect.Format.BlockPeriod = 133466800; // nano-sec
    else
        pAVReq->Connect.Format.BlockPeriod = 133333333; // nano-sec

    TRACE(TL_61883_WARNING,("\'cipQuad2[0]:%x, cipQuad2[1]:%x, cipQuad2[2]:%x, cipQuad2[3]:%x\n", 
        pStrmExt->cipQuad2[0],
        pStrmExt->cipQuad2[1],
        pStrmExt->cipQuad2[2],
        pStrmExt->cipQuad2[3]
        ));


    TRACE(TL_61883_WARNING,("\'Connect:oPcr:%x->iPcr:%x; cipQuad2[%.2x:%.2x:%.2x:%.2x]\n", 
        pAVReq->Connect.hOutputPlug,
        pAVReq->Connect.hInputPlug,
        pAVReq->Connect.Format.FMT,
        pAVReq->Connect.Format.FDF_hi,
        pAVReq->Connect.Format.FDF_mid,
        pAVReq->Connect.Format.FDF_lo
        ));

    TRACE(TL_61883_WARNING,("\'        BlkSz %d; SrcPkt %d; AvgTm %d, BlkPrd %d\n", 
        pAVReq->Connect.Format.BlockSize,
        DVFormatInfoTable[pDevExt->VideoFormatIndex].ulSrcPackets,
        DVFormatInfoTable[pDevExt->VideoFormatIndex].ulAvgTimePerFrame,
        (DWORD) pAVReq->Connect.Format.BlockPeriod
        ));

    if(NT_SUCCESS(
        Status = DVSubmitIrpSynch( 
            pDevExt,
            pIrp,
            pAVReq
            ))) {
        TRACE(TL_61883_WARNING,("\'hConnect:%x\n", pAVReq->Connect.hConnect));
        ASSERT(pAVReq->Connect.hConnect != NULL);
        pStrmExt->hConnect = pAVReq->Connect.hConnect;
    } 
    else {
        TRACE(TL_61883_ERROR,("Av61883_Connect Failed; Status:%x\n", Status));
        ASSERT(!NT_SUCCESS(Status) && "DisConnect failed");        
        pStrmExt->hConnect = NULL;
    }

    IoFreeIrp(pIrp); pIrp = NULL;
    ExFreePool(pAVReq); pAVReq = NULL;

    return Status;
}

NTSTATUS
DVCreateLocalPlug( 
    IN PDVCR_EXTENSION  pDevExt,
    IN CMP_PLUG_TYPE PlugType,
    IN ULONG  PlugNum,
    OUT HANDLE  *pPlugHandle
   )
/*++

Routine Description:

    Create an enumated local PC PCR
 
Arguments:

Return Value:

    STATUS_SUCCESS 
    STATUS_INSUFFICIENT_RESOURCES

--*/
{
    PIRP pIrp;
    PAV_61883_REQUEST  pAVReq;
    NTSTATUS Status = STATUS_SUCCESS;

    PAGED_CODE();

    if(!(pIrp = IoAllocateIrp(pDevExt->pBusDeviceObject->StackSize, FALSE)))
        return STATUS_INSUFFICIENT_RESOURCES;

    if(!(pAVReq = (AV_61883_REQUEST *) ExAllocatePool(NonPagedPool, sizeof(AV_61883_REQUEST)))) { 
        IoFreeIrp(pIrp); pIrp = NULL;
        return STATUS_INSUFFICIENT_RESOURCES;
    }

    // Need to correctly update Overhead_ID and payload fields of PC's own oPCR
    RtlZeroMemory(pAVReq, sizeof(AV_61883_REQUEST));
    INIT_61883_HEADER(pAVReq, Av61883_CreatePlug);

    pAVReq->CreatePlug.PlugNum   = PlugNum;
    pAVReq->CreatePlug.hPlug     = NULL;

    pAVReq->CreatePlug.Context   = NULL;
    pAVReq->CreatePlug.pfnNotify = NULL;
    pAVReq->CreatePlug.PlugType  = PlugType;

    //
    // Initialize oPCR values to default values using SDDV signal mode 
    // with speed of 100Mbps data rate
    //

    pAVReq->CreatePlug.Pcr.oPCR.OnLine     = 0;  // We are not online so we cannot be programmed.
    pAVReq->CreatePlug.Pcr.oPCR.BCCCounter = 0;
    pAVReq->CreatePlug.Pcr.oPCR.PPCCounter = 0;
    pAVReq->CreatePlug.Pcr.oPCR.Channel    = 0;

    pAVReq->CreatePlug.Pcr.oPCR.DataRate   = CMP_SPEED_S100;
    pAVReq->CreatePlug.Pcr.oPCR.OverheadID = PCR_OVERHEAD_ID_SDDV;
    pAVReq->CreatePlug.Pcr.oPCR.Payload    = PCR_PAYLOAD_SDDV;

    if(NT_SUCCESS(
        Status = DVSubmitIrpSynch( 
            pDevExt,
            pIrp,
            pAVReq
            ))) {
        *pPlugHandle    = pAVReq->CreatePlug.hPlug;
        TRACE(TL_61883_WARNING,("\'Created h%sPlugPC[%d]=%x\n", PlugType == CMP_PlugIn ? "I" : "O", PlugNum, *pPlugHandle));
    } else {
        TRACE(TL_61883_ERROR,("\'Created h%sPlugPC[%d] failed; Status:%x\n", pAVReq->CreatePlug.PlugType == CMP_PlugIn ? "I" : "O", PlugNum, Status));
        Status = STATUS_INSUFFICIENT_RESOURCES;  // No plug!
    }

    IoFreeIrp(pIrp); pIrp = NULL;
    ExFreePool(pAVReq); pAVReq = NULL;

    return Status;
}


NTSTATUS
DVDeleteLocalPlug( 
    IN PDVCR_EXTENSION  pDevExt,
    IN HANDLE PlugHandle
   )
/*++

Routine Description:

    Delete an enumated local PC PCR
 
Arguments:

Return Value:

    Nothing

--*/
{
    PIRP pIrp;
    PAV_61883_REQUEST  pAVReq;
    NTSTATUS Status = STATUS_SUCCESS;

    PAGED_CODE();


    if(!(pIrp = IoAllocateIrp(pDevExt->pBusDeviceObject->StackSize, FALSE)))
        return STATUS_INSUFFICIENT_RESOURCES;

    if(!(pAVReq = (AV_61883_REQUEST *) ExAllocatePool(NonPagedPool, sizeof(AV_61883_REQUEST)))) {  
        IoFreeIrp(pIrp); pIrp = NULL;
        return STATUS_INSUFFICIENT_RESOURCES;
    }

    // Delete our local oPCR 
    RtlZeroMemory(pAVReq, sizeof(AV_61883_REQUEST));
    INIT_61883_HEADER(pAVReq, Av61883_DeletePlug);
    pAVReq->DeletePlug.hPlug = PlugHandle;

    Status = 
        DVSubmitIrpSynch( 
            pDevExt,
            pIrp,
            pAVReq
            );

    if(!NT_SUCCESS(Status)) {
        TRACE(TL_61883_ERROR,("Av61883_DeletePlug Failed = 0x%x\n", Status));        
        // Do not care if this result in error.
    } else {
        TRACE(TL_61883_WARNING,("\'Av61883_DeletePlug: Deleted!\n", pDevExt->hOPcrPC)); 
    }

    IoFreeIrp(pIrp); pIrp = NULL;
    ExFreePool(pAVReq); pAVReq = NULL;

    return Status;
}
#endif

NTSTATUS
DVGetPlugState(
    IN PDVCR_EXTENSION  pDevExt,
    IN PSTREAMEX        pStrmExt,
    IN PAV_61883_REQUEST   pAVReq
    )
/*++

Routine Description:

    Ask 61883.sys for the plug state.
 
Arguments:

Return Value:

    Nothing

--*/
{
    PIRP      pIrp;
    NTSTATUS  Status = STATUS_SUCCESS;
   
    PAGED_CODE();

    if(!(pIrp = IoAllocateIrp(pDevExt->pBusDeviceObject->StackSize, FALSE)))
        return STATUS_INSUFFICIENT_RESOURCES;    

    //
    // Query oPCR plug state
    //
    if(pStrmExt->hOutputPcr) {
        RtlZeroMemory(pAVReq, sizeof(AV_61883_REQUEST));
        INIT_61883_HEADER(pAVReq, Av61883_GetPlugState);
        pAVReq->GetPlugState.hPlug = pStrmExt->hOutputPcr;

        Status = 
            DVSubmitIrpSynch( 
                pDevExt,
                pIrp,
                pAVReq
                );

        if(!NT_SUCCESS(Status)) {
            TRACE(TL_61883_ERROR,("Av61883_GetPlugState Failed %x\n", Status));
            goto ExitGetState;
        }
        else {

            TRACE(TL_61883_WARNING,("\'PlgState:(oPCR:%x): State %x; DRate %d; Payld %d; BCCnt %d; PPCnt %d\n", 
                pAVReq->GetPlugState.hPlug,
                pAVReq->GetPlugState.State,
                pAVReq->GetPlugState.DataRate,
                pAVReq->GetPlugState.Payload,
                pAVReq->GetPlugState.BC_Connections,
                pAVReq->GetPlugState.PP_Connections
                ));
        }
    }

    //
    // Query iPCR plug state
    //
    if(pStrmExt->hInputPcr) {
        RtlZeroMemory(pAVReq, sizeof(AV_61883_REQUEST));
        INIT_61883_HEADER(pAVReq, Av61883_GetPlugState);
        pAVReq->GetPlugState.hPlug = pStrmExt->hInputPcr;

        Status = 
            DVSubmitIrpSynch( 
                pDevExt,
                pIrp,
                pAVReq
                );

        if(!NT_SUCCESS(Status)) {

            TRACE(TL_61883_ERROR,("Av61883_GetPlugState Failed %x\n", Status));
            goto ExitGetState;
        }
        else {

            TRACE(TL_61883_WARNING,("\'PlugState(iPCR:%x): State %x; DRate %d; Payld %d; BCCnt %d; PPCnt %d\n", 
                pAVReq->GetPlugState.hPlug,
                pAVReq->GetPlugState.State,
                pAVReq->GetPlugState.DataRate,
                pAVReq->GetPlugState.Payload,
                pAVReq->GetPlugState.BC_Connections,
                pAVReq->GetPlugState.PP_Connections
                ));
        }
    }

ExitGetState:
    IoFreeIrp(pIrp);
    return Status;
}


NTSTATUS
DVCreateAttachFrameThread(
    PSTREAMEX  pStrmExt
    )
/*++

Routine Description:

    Create a system thread for attaching data (for transmiut to DV only).
 
Arguments:

Return Value:

    STATUS_SUCCESS or
    return status from PsCreateSystemThread

--*/
{
    NTSTATUS Status = STATUS_SUCCESS;
    HANDLE hAttachFrameThread;

    Status =  
        PsCreateSystemThread(
            &hAttachFrameThread,
            (ACCESS_MASK) 0,
            NULL,
            (HANDLE) 0,
            NULL,
            DVAttachFrameThread,
            pStrmExt
            );

    if(!NT_SUCCESS(Status)) {
        pStrmExt->bTerminateThread = TRUE;
        TRACE(TL_CIP_ERROR|TL_FCP_ERROR,("\'PsCreateSystemThread() failed %x\n", Status));
        ASSERT(NT_SUCCESS(Status));

    }
    else {
        pStrmExt->bTerminateThread = FALSE;  // Just started!
        Status = 
            ObReferenceObjectByHandle(
            hAttachFrameThread,
            THREAD_ALL_ACCESS,
            NULL,
            KernelMode,
            &pStrmExt->pAttachFrameThreadObject,
            NULL
            );

         TRACE(TL_CIP_WARNING|TL_PNP_WARNING,("\'ObReferenceObjectByHandle() St %x; Obj %x\n", Status, pStrmExt->pAttachFrameThreadObject));
         ZwClose(hAttachFrameThread);

         // To signl end of an event
         KeInitializeEvent(&pStrmExt->hThreadEndEvent, NotificationEvent, FALSE);  // Non-signal
    }

    return Status;
}

NTSTATUS
DVConnect(
    IN KSPIN_DATAFLOW   ulDataFlow,
    IN PDVCR_EXTENSION  pDevExt,
    IN PSTREAMEX        pStrmExt,
    IN PAV_61883_REQUEST   pAVReq
    )
/*++

Routine Description:

    Ask 61883.sys to allocate isoch bandwidth and program PCR.
 
Arguments:

Return Value:

    STATUS_SUCCESS
    other Status from calling other routine.

--*/
{
    NTSTATUS  Status;
  

    PAGED_CODE();

    ASSERT(pStrmExt->hConnect == NULL);

    //
    // Do not reconnect.  61883 should handle all the necessary CMP reconnect.
    //
    if(pStrmExt->hConnect) {
        return STATUS_SUCCESS;
    }


#ifdef SUPPORT_NEW_AVC
    //
    // For Device to device connection, we only connect if we are the data producer (oPCR)
    //

    TRACE(TL_61883_WARNING,("\'[pStrmExt:%x]: %s PC (oPCR:%x, iPCR:%x); DV (oPCR:%x;  iPCR:%x)\n",
        pStrmExt, 
        ulDataFlow == KSPIN_DATAFLOW_OUT ? "OutPin" : "InPin",
        pDevExt->hOPcrPC, 0,
        pDevExt->hOPcrDV, pDevExt->hIPcrDV       
        ));

    if(
       pStrmExt->bDV2DVConnect &&
       (pStrmExt->hOutputPcr != pDevExt->hOPcrDV)) {
        TRACE(TL_61883_WARNING,("\'** pStrmExt:%x not data producer!\n\n", pStrmExt));

        return STATUS_SUCCESS;
    }
#endif


#ifdef NT51_61883
    //
    // Set Unit isoch parameters:
    // The number of packets is depending on two factors:
    // For a PAE system, number of packets cannnot be bigger than 64k/480 = 133
    // For capture, number of packets should not be bigger than max packets to construct a DV buffer.
    // This is needed to avoid completing two buffers in the same descriptor and can cause glitched
    // in the "real time" playback of the data, esp the audio.
    //
    if(pDevExt->HardwareFlags & AV_HOST_DMA_DOUBLE_BUFFERING_ENABLED) {  
        // PAE system
        pDevExt->UnitIoschParams.RX_NumPackets = 
        // pDevExt->UnitIoschParams.TX_NumPackets = // Use the default set by 61883
            ((pDevExt->VideoFormatIndex == FMT_IDX_SD_DVCR_NTSC || pDevExt->VideoFormatIndex == FMT_IDX_SDL_DVCR_NTSC) ? 
             MAX_SRC_PACKETS_PER_NTSC_FRAME_PAE : MAX_SRC_PACKETS_PER_PAL_FRAME_PAE);
    } else {
        pDevExt->UnitIoschParams.RX_NumPackets = 
        // pDevExt->UnitIoschParams.TX_NumPackets = // Use the default set by 61883
            ((pDevExt->VideoFormatIndex == FMT_IDX_SD_DVCR_NTSC || pDevExt->VideoFormatIndex == FMT_IDX_SDL_DVCR_NTSC) ? 
             MAX_SRC_PACKETS_PER_NTSC_FRAME     : MAX_SRC_PACKETS_PER_PAL_FRAME);
    }

    if(!NT_SUCCESS(
        Status = DVSetUnitIsochParams(
            pDevExt,
            &pDevExt->UnitIoschParams
            ))) {
        return Status;
    }

#endif  // NT51_61883

    //
    // Make a point to point connection
    //
    Status = 
        DVMakeP2PConnection(
            pDevExt,
            ulDataFlow,
            pStrmExt
            );

    return Status;
}




NTSTATUS
DVDisconnect(
    IN KSPIN_DATAFLOW   ulDataFlow,
    IN PDVCR_EXTENSION  pDevExt,
    IN PSTREAMEX        pStrmExt
    )
/*++

Routine Description:

    Ask 61883.sys to free isoch bandwidth and program PCR.
    
Arguments:

Return Value:

    Nothing

--*/
{
    PIRP     pIrp;
    NTSTATUS Status = STATUS_SUCCESS;
    PAV_61883_REQUEST   pAVReq;

    PAGED_CODE();

    //
    // Use the hPlug to disconnect
    //
    if(pStrmExt->hConnect) {

        if(!(pAVReq = (AV_61883_REQUEST *) ExAllocatePool(NonPagedPool, sizeof(AV_61883_REQUEST))))
            return STATUS_INSUFFICIENT_RESOURCES;                    

        if(!(pIrp = IoAllocateIrp(pDevExt->pBusDeviceObject->StackSize, FALSE))) {
            ExFreePool(pAVReq);  pAVReq = NULL;
            return STATUS_INSUFFICIENT_RESOURCES;
        }

        RtlZeroMemory(pAVReq, sizeof(AV_61883_REQUEST));
        INIT_61883_HEADER(pAVReq, Av61883_Disconnect);
        pAVReq->Disconnect.hConnect = pStrmExt->hConnect;
        ASSERT(pStrmExt->hConnect);
        
        if(!NT_SUCCESS(
            Status = DVSubmitIrpSynch( 
                pDevExt,
                pIrp,
                pAVReq
                ))) {
            // This could be caused that the connection was not P2P, and 
            // it tried to disconnect.
            TRACE(TL_61883_ERROR,("\'Disconnect hConnect:%x failed; ST %x; AvReq->ST %x\n", pStrmExt->hConnect, Status, pAVReq->Flags  ));
            // ASSERT(NT_SUCCESS(Status) && "DisConnect failed");
        } else {
            TRACE(TL_61883_TRACE,("\'Disconnect suceeded; ST %x; AvReq->ST %x\n", Status, pAVReq->Flags  ));
        }

        IoFreeIrp(pIrp);  pIrp = NULL;
        ExFreePool(pAVReq); pAVReq = NULL;

        TRACE(TL_61883_WARNING,("\'DisConn %s St:%x; Stat: SRBCnt:%d; [Pic# =? Prcs:Drp:Cncl:Rpt] [%d ?=%d+%d+%d+%d]\n", 
            ulDataFlow  == KSPIN_DATAFLOW_OUT ? "[OutPin]" : "[InPin]",
            Status, 
            (DWORD) pStrmExt->cntSRBReceived,
            (DWORD) pStrmExt->PictureNumber,
            (DWORD) pStrmExt->FramesProcessed, 
            (DWORD) pStrmExt->FramesDropped,
            (DWORD) pStrmExt->cntSRBCancelled,  // number of SRB_READ/WRITE_DATA cancelled
            (DWORD) (pStrmExt->PictureNumber - pStrmExt->FramesProcessed - pStrmExt->FramesDropped - pStrmExt->cntSRBCancelled)
            ));
#if DBG
    if(DVFormatInfoTable[pDevExt->VideoFormatIndex].SrcPktHeader) {
        ULONG ulElapsed = (DWORD) ((GetSystemTime() - pStrmExt->tmStreamStart)/(ULONGLONG) 10000);
        TRACE(TL_61883_WARNING,("\'****-* TotalSrcPkt:%d; DisCont:%d; Elapse:%d msec; DataRate:%d bps *-****\n", \
            pStrmExt->lTotalCycleCount, pStrmExt->lDiscontinuityCount,
            ulElapsed,
            pStrmExt->lTotalCycleCount * 188 * 1000 / ulElapsed * 8
            )); 
    }
#endif

        // We will not have another chance to reconnect it so we assume it is disconnected.
        pStrmExt->hConnect = NULL; 
    }  

    return Status;
}


//
// GetSystemTime in 100 nS units
//

ULONGLONG GetSystemTime()
{

    LARGE_INTEGER rate, ticks;

    ticks = KeQueryPerformanceCounter(&rate);

    return (KSCONVERT_PERFORMANCE_TIME(rate.QuadPart, ticks));
}




#define DIFBLK_SIZE 12000

#define PACK_NO_INFO            0xff

// Subcode header identifier
#define SC_HDR_TIMECODE         0x13
#define SC_HDR_BINARYGROUP      0x14

// header identifier

#define AAUX_HDR_SOURCE         0x50
#define AAUX_HDR_SOURCE_CONTROL 0x51
#define AAUX_HDR_REC_DATE       0x52
#define AAUX_HDR_REC_TIME       0x53
#define AAUX_HDR_BINARY_GROUP   0x54
#define AAUX_HDR_CC             0x55
#define AAUX_HDR_TR             0x56

#define VAUX_HDR_SOURCE         0x60
#define VAUX_HDR_SOURCE_CONTROL 0x61
#define VAUX_HDR_REC_DATE       0x62
#define VAUX_HDR_REC_TIME       0x63
#define VAUX_HDR_BINARY_GROUP   0x64
#define VAUX_HDR_CC             0x65
#define VAUX_HDR_TR             0x66

// Determine section type (MS 3 bits); Fig.66; Table 36.
#define ID0_SCT_MASK            0xe0
#define ID0_SCT_HEADER          0x00
#define ID0_SCT_SUBCODE         0x20
#define ID0_SCT_VAUX            0x40
#define ID0_SCT_AUDIO           0x60
#define ID0_SCT_VIDEO           0x80

// A pack is consisted of one byte of header identifier and 4 bytes of data; Part2, annex D.
typedef struct _DV_PACK {
    UCHAR Header;
    UCHAR Data[4];
} DV_PACK, *PDV_PACK;

typedef struct _DV_H0 {
    UCHAR ID0;
    UCHAR ID1;
    UCHAR ID2;

    UCHAR DSF;
    UCHAR DFTIA;
    UCHAR TF1;
    UCHAR TF2;
    UCHAR TF3;

    UCHAR Reserved[72];
} DV_H0, *PDV_H0;

typedef struct _DV_SC {
    UCHAR ID0;
    UCHAR ID1;
    UCHAR ID2;

    struct {
        UCHAR SID0;
        UCHAR SID1;
        UCHAR Reserved;
        DV_PACK Pack;
    } SSyb0;
    struct {
        UCHAR SID0;
        UCHAR SID1;
        UCHAR Reserved;
        DV_PACK Pack;
    } SSyb1;
    struct {
        UCHAR SID0;
        UCHAR SID1;
        UCHAR Reserved;
        DV_PACK Pack;
    } SSyb2;
    struct {
        UCHAR SID0;
        UCHAR SID1;
        UCHAR Reserved;
        DV_PACK Pack;
    } SSyb3;
    struct {
        UCHAR SID0;
        UCHAR SID1;
        UCHAR Reserved;
        DV_PACK Pack;
    } SSyb4;
    struct {
        UCHAR SID0;
        UCHAR SID1;
        UCHAR Reserved;
        DV_PACK Pack;
    } SSyb5;

    UCHAR Reserved[29];
} DV_SC, *PDV_SC;

#define MAX_VAUX_PACK 15

typedef struct _DV_VAUX {
    UCHAR ID0;
    UCHAR ID1;
    UCHAR ID2;

    DV_PACK Pack[MAX_VAUX_PACK];

    UCHAR Reserved[2];
} DV_VAUX, *PDV_VAUX;

typedef struct _DV_A {
    UCHAR ID0;
    UCHAR ID1;
    UCHAR ID2;
    DV_PACK Pack;
    UCHAR Data[72];
} DV_A, *PDV_A;

typedef struct _DV_V {
    UCHAR ID0;
    UCHAR ID1;
    UCHAR ID2;    
    UCHAR Data[77]; // 3..79
} DV_V, *PDV_V;

// Two source packets
#define V_BLOCKS 15
typedef struct _DV_AV {
    DV_A  A;
    DV_V  V[V_BLOCKS];
} DV_AV, *PDV_AV; 


#define SC_SECTIONS     2
#define VAUX_SECTIONS   3
#define AV_SECTIONS     9

typedef struct _DV_DIF_SEQ {
    DV_H0   H0;
    DV_SC   SC[SC_SECTIONS];
    DV_VAUX VAux[VAUX_SECTIONS];
    DV_AV   AV[AV_SECTIONS];
} DV_DIF_SEQ, *PDV_DIF_SEQ;


typedef struct _DV_FRAME_NTSC {
    DV_DIF_SEQ DifSeq[10];
} DV_FRAME_NTSC, *PDV_FRAME_NTSC;

typedef struct _DV_FRAME_PAL {
    DV_DIF_SEQ DifSeq[12];
} DV_FRAME_PAL, *PDV_FRAME_PAL;

// By setting REC MODE to 111b (invalid recording) can
// cause DV to mute the audio
#define AAUX_REC_MODE_INVALID_MASK 0x38   // xx11:1xxx
#define AAUX_REC_MODE_ORIGINAL     0x08   // xx00:1xxx


#ifdef MSDV_SUPPORT_MUTE_AUDIO
// #define SHOW_ONE_FIELD_TWICE

BOOL
DVMuteDVFrame(
    IN PDVCR_EXTENSION pDevExt,
    IN OUT PUCHAR      pFrameBuffer,
    IN BOOL            bMuteAudio
    )
{
    PDV_DIF_SEQ pDifSeq;
#ifdef SHOW_ONE_FIELD_TWICE  
    PDV_VAUX    pVAux;
    ULONG k;
#endif
    ULONG i, j;
#ifdef SHOW_ONE_FIELD_TWICE  
    BOOL bFound1 = FALSE;
#endif
    BOOL bFound2 = FALSE;

    pDifSeq = (PDV_DIF_SEQ) pFrameBuffer;

    // find the VVAX Source pack
    for (i=0; i < DVFormatInfoTable[pDevExt->VideoFormatIndex].ulNumOfDIFSequences; i++) {

#ifdef SHOW_ONE_FIELD_TWICE  // Advise by Adobe that we may want to show bothj field but mute audio
        // Make the field2 output twice, FrameChange to 0 (same as previous frame)
        for (j=0; j < VAUX_SECTIONS; j++) {
            pVAux = &pDifSeq->VAux[j];
            if((pVAux->ID0 & ID0_SCT_MASK) != ID0_SCT_VAUX) {
                TRACE(TL_CIP_WARNING,("\'Invalid ID0:%.2x for pVAUX:%x (Dif:%d;V%d;S%d)\n", pVAux->ID0, pVAux, i, j, k)); 
                continue;
            }

            for (k=0; k< MAX_VAUX_PACK; k++) {
                if(pVAux->Pack[k].Header == VAUX_HDR_SOURCE_CONTROL) {
                    if(bMuteAudio) {
                        TRACE(TL_CIP_WARNING,("\'Mute Audio; pDifSeq:%x; pVAux:%x; (Dif:%d,V%d,S%d); %.2x,[%.2x,%.2x,%.2x,%.2x]; pack[2]->%.2x\n", \
                            pDifSeq, pVAux, i, j, k, \
                            pVAux->Pack[k].Header, pVAux->Pack[k].Data[0], pVAux->Pack[k].Data[1], pVAux->Pack[k].Data[2], pVAux->Pack[k].Data[3], \
                            (pVAux->Pack[k].Data[2] & 0x1F) ));
                        pVAux->Pack[k].Data[2] &= 0x1f; // 0x1F; // set FF, FS and FC to 0
                        TRACE(TL_CIP_TRACE,("\'pVAux->Pack[k].Data[2] = %.2x\n", pVAux->Pack[k].Data[2])); 
                    } else {
                        TRACE(TL_CIP_TRACE,("\'un-Mute Audio; pack[2]: %.2x ->%.2x\n", pVAux->Pack[k].Data[2], (pVAux->Pack[k].Data[2] | 0xc0) ));  
                        pVAux->Pack[k].Data[2] |= 0xe0; // set FF, FS and FCto 1; Show both fields in field 1,2 order
                    }
                    bFound1 = TRUE;
                    break;   // Set only the 1st occurrence
                }
            }
        }
#endif

        for (j=0; j < AV_SECTIONS; j++) {
            if(pDifSeq->AV[j].A.Pack.Header == AAUX_HDR_SOURCE_CONTROL) {
                TRACE(TL_CIP_TRACE,("\'A0Aux %.2x,[%.2x,%.2x,%.2x,%.2x] %.2x->%.2x\n", \
                    pDifSeq->AV[j].A.Pack.Header,  pDifSeq->AV[j].A.Pack.Data[0], \
                    pDifSeq->AV[j].A.Pack.Data[1], pDifSeq->AV[j].A.Pack.Data[2], pDifSeq->AV[j].A.Pack.Data[3], \
                    pDifSeq->AV[j].A.Pack.Data[1], pDifSeq->AV[j].A.Pack.Data[1] | AAUX_REC_MODE_INVALID_MASK
                    ));
                if(bMuteAudio) 
                    pDifSeq->AV[j].A.Pack.Data[1] |= AAUX_REC_MODE_INVALID_MASK;  // Cause DV to mute this.
                else 
                    pDifSeq->AV[j].A.Pack.Data[1] = \
                        (pDifSeq->AV[j].A.Pack.Data[1] & ~AAUX_REC_MODE_INVALID_MASK) | AAUX_REC_MODE_ORIGINAL;
                bFound2 = TRUE;
                break;  // Set only the 1st occurrence
            }
        }

        // Must do the 1st occurance of all Dif sequences;
        pDifSeq++;  // Next DIF sequence
    }
#ifdef SHOW_ONE_FIELD_TWICE  
    return (bFound1 && bFound2);  
#else
    return bFound2;
#endif
}
#endif

#ifdef MSDV_SUPPORT_EXTRACT_SUBCODE_DATA

VOID
DVCRExtractTimecodeFromFrame(
    IN PDVCR_EXTENSION pDevExt,
    IN PSTREAMEX       pStrmExt,
    IN PUCHAR          pFrameBuffer
    )
{
    PUCHAR pDIFBlk;
    PUCHAR pS0, pS1, pSID0;
    ULONG i, j;
    BYTE LastTimecode[4], Timecode[4]; // hh:mm:ss,ff
    DWORD LastAbsTrackNumber, AbsTrackNumber;
    PUCHAR pSID1;
    BYTE  Timecode2[4]; // hh:mm:ss,ff
    DWORD AbsTrackNumber2;
    BOOL bGetAbsT = TRUE, bGetTimecode = TRUE;


    // Can be called at DISPATCH_LEVEL

    pDIFBlk = (PUCHAR) pFrameBuffer;

    // Save the last timecode so we will now if it has 

    LastTimecode[0] = pStrmExt->Timecode[0];
    LastTimecode[1] = pStrmExt->Timecode[1];
    LastTimecode[2] = pStrmExt->Timecode[2];
    LastTimecode[3] = pStrmExt->Timecode[3];

    LastAbsTrackNumber = pStrmExt->AbsTrackNumber;

    //
    // Traverse thru every DIF BLOCK looking for VA0,1 and 2
    for(i=0; i < DVFormatInfoTable[pDevExt->VideoFormatIndex].ulNumOfDIFSequences; i++) {

        pS0 = pDIFBlk + 80;
        pS1 = pS0     + 80;


        //
        // Is this Subcode source packet? See Table 36 (P.111) of the Blue Book
        //
        if ((pS0[0] & 0xe0) == 0x20 && (pS1[0] & 0xe0) == 0x20) {

            if(bGetAbsT) {
                //
                // See Figure 42 (p. 94) of the Blue book
                // SID0(Low nibble),1 (high nibble) of every three subcode sync block can form the ATN
                //
                pSID0 = &pS0[3];              
                AbsTrackNumber = 0;
                for (j = 0 ; j < 3; j++) {
                    AbsTrackNumber = (( ( (pSID0[0] & 0x0f) << 4) | (pSID0[1] >> 4) ) << (j * 8)) | AbsTrackNumber;
                    pSID0 += 8;
                    bGetAbsT = FALSE;
                }

                pSID1 = &pS1[3];
                AbsTrackNumber2 = 0;
                for (j = 0 ; j < 3; j++) {
                    AbsTrackNumber2 = (( ( (pSID1[0] & 0x0f) << 4) | (pSID1[1] >> 4) ) << (j * 8)) | AbsTrackNumber2;
                    pSID1 += 8;
                }
            
                // Verify that the track number is the same!
                if(AbsTrackNumber == AbsTrackNumber2) {

                    bGetAbsT = FALSE;
                } else {
                   bGetAbsT = TRUE;
                   TRACE(TL_CIP_TRACE,("\'%d Sequence;  AbsT (%d,%d) != AbsT2 (%d,%d)\n",
                       i,
                       AbsTrackNumber / 2, AbsTrackNumber & 0x01,                       
                       AbsTrackNumber2 / 2, AbsTrackNumber2 & 0x01
                       ));
                }
            }


            if(bGetTimecode) {
                // See Figure 68 (p. 114) of the Blue Book
                // Subcode sync block number 3, 4 and 5
                for(j = 3; j <= 5; j++) {
                    // 3 bytes of IDs and follow by sequence of 8 bytes SyncBlock (3:5); 
                    // 0x13 == TIMECODE
                    if(pS0[3+3+j*8] == 0x13 
                       && pS0[3+3+j*8+4] != 0xff
                       && pS0[3+3+j*8+3] != 0xff
                       && pS0[3+3+j*8+2] != 0xff
                       && pS0[3+3+j*8+1] != 0xff) {

                        Timecode[0] = pS0[3+3+j*8+4]&0x3f;  // hh
                        Timecode[1] = pS0[3+3+j*8+3]&0x7f;  // mm
                        Timecode[2] = pS0[3+3+j*8+2]&0x7f;  // ss
                        Timecode[3] = pS0[3+3+j*8+1]&0x3f;  // ff
                                        
                        bGetTimecode = FALSE;
                        break;                  
                   }
                }

                // Subcode sync block number 9, 10 and 11
                for(j = 3; j <= 5; j++) {
                    // 3 bytes of IDs and follow by sequence of 8 bytes SyncBlock (3:5); 
                    // 0x13 == TIMECODE
                    if(pS1[3+3+j*8] == 0x13
                       && pS1[3+3+j*8+4] != 0xff
                       && pS1[3+3+j*8+3] != 0xff
                       && pS1[3+3+j*8+2] != 0xff
                       && pS1[3+3+j*8+1] != 0xff) {

                       Timecode2[0] = pS1[3+3+j*8+4]&0x3f;  // hh
                       Timecode2[1] = pS1[3+3+j*8+3]&0x7f;  // mm
                       Timecode2[2] = pS1[3+3+j*8+2]&0x7f;  // ss
                       Timecode2[3] = pS1[3+3+j*8+1]&0x3f;  // ff
            
                       bGetTimecode = FALSE;
                       break;                   
                    }
                }

                //
                // Verify
                //
                if(!bGetTimecode) {

                    if( Timecode[0] == Timecode2[0] 
                     && Timecode[1] == Timecode2[1] 
                     && Timecode[2] == Timecode2[2] 
                     && Timecode[3] == Timecode2[3]) {

                       } else {
                        bGetTimecode = TRUE;
                        TRACE(TL_CIP_TRACE,("\'%d Sequence;  %.2x:%.2x:%.2x,%.2x != %.2x:%.2x:%.2x,%.2x\n",
                            i,
                            Timecode[0],  Timecode[1],  Timecode[2],  Timecode[3],
                            Timecode2[0], Timecode2[1], Timecode2[2], Timecode2[3]
                            ));
                    }       
                }
            }
        }
        
        if(!bGetAbsT && !bGetTimecode) 
            break;

        pDIFBlk += DIFBLK_SIZE;  // Get to next block    
                
    }

    if(!bGetAbsT && pStrmExt->AbsTrackNumber != AbsTrackNumber) {
        pStrmExt->AbsTrackNumber = AbsTrackNumber;  // BF is the LSB  
        pStrmExt->bATNUpdated = TRUE;
        TRACE(TL_CIP_TRACE,("\'Extracted TrackNum:%d; DicontBit:%d\n", AbsTrackNumber / 2, AbsTrackNumber & 0x01));
    }

    if(!bGetTimecode &&
        (
         Timecode[0] != LastTimecode[0] ||
         Timecode[1] != LastTimecode[1] ||
         Timecode[2] != LastTimecode[2] ||
         Timecode[3] != LastTimecode[3]
        ) 
      )  { 
        pStrmExt->Timecode[0] = Timecode[0];  // hh
        pStrmExt->Timecode[1] = Timecode[1];  // mm
        pStrmExt->Timecode[2] = Timecode[2];  // mm
        pStrmExt->Timecode[3] = Timecode[3];  // ff
        pStrmExt->bTimecodeUpdated = TRUE;

        TRACE(TL_CIP_TRACE,("\'Extracted Timecode %.2x:%.2x:%.2x,%.2x\n", Timecode[0], Timecode[1], Timecode[2], Timecode[3]));
    }    
}

#endif // MSDV_SUPPORT_EXTRACT_SUBCODE_DATA


#ifdef MSDV_SUPPORT_EXTRACT_DV_DATE_TIME

VOID
DVCRExtractRecDateAndTimeFromFrame(
    IN PDVCR_EXTENSION pDevExt,
    IN PSTREAMEX       pStrmExt,
    IN PUCHAR          pFrameBuffer
    )
{
    PUCHAR pDIFBlk;
    PUCHAR pS0, pS1;
    ULONG i, j;
    BOOL bGetRecDate = TRUE, bGetRecTime = TRUE;

    // Can be called at DISPATCH_LEVEL


    pDIFBlk = (PUCHAR) pFrameBuffer + DIFBLK_SIZE * DVFormatInfoTable[pDevExt->VideoFormatIndex].ulNumOfDIFSequences/2;


    //
    // REC Data (VRD) and Time (VRT) on in the 2nd half oa a video frame
    // 
    for(i=DVFormatInfoTable[pDevExt->VideoFormatIndex].ulNumOfDIFSequences/2; i < DVFormatInfoTable[pDevExt->VideoFormatIndex].ulNumOfDIFSequences; i++) {

        pS0 = pDIFBlk + 80;
        pS1 = pS0     + 80;


        //
        // Find SC0 and SC1. See Table 36 (P.111) of the Blue Book
        //
        // SC0/1: ID(0,1,2), Data (3,50), Reserved(51-79)
        //     SC0:Data: SSYB0(3..10), SSYB1(11..18), SSYB2(19..26), SSYB3(27..34), SSYB4(35..42),   SSYB5(43..50)
        //     SC1:Data: SSYB6(3..10), SSYB7(11..18), SSYB8(19..26), SSYB9(27..34), SSYB10(35..42), SSYB11(43..50)
        //         SSYBx(SubCodeId0, SubcodeID1, Reserved, Pack(3,4,5,6,7))
        //
        //  TTC are in the 1st half: SSYB0..11 (every)
        //  TTC are in the 2nd half: SSYB0,3,6,9
        //  VRD are in the 2nd half of a video frame, SSYB1,4,7,10
        //  VRT are in the 2nd half of a video frame, SSYB2,5,8,11
        //

        // Subcode data ?
        if ((pS0[0] & 0xe0) == 0x20 && (pS1[0] & 0xe0) == 0x20) {

            //
            // RecDate: VRD
            //
            if(bGetRecDate) {
                // go thru 6 sync blocks (8 bytes per block) per Subcode; idx 1(SSYB1),4(SSYB4) for SC0
                for(j=0; j <= 5 ; j++) {
                    if(j == 1 || j == 4) {
                        // 0x62== RecDate
                        if(pS0[3+3+j*8] == 0x62) {
                            pStrmExt->RecDate[0] = pS0[3+3+j*8+4];        // Year
                            pStrmExt->RecDate[1] = pS0[3+3+j*8+3]&0x1f;   // Month
                            pStrmExt->RecDate[2] = pS0[3+3+j*8+2]&0x3f;   // Day
                            pStrmExt->RecDate[3] = pS0[3+3+j*8+1]&0x3f;   // TimeZone
                            bGetRecDate = FALSE;
                            break;
                        }
                    }
                }
            }

            if(bGetRecDate) {
                // go thru 6 sync blocks (8 bytes per block) per Subcode; idx 1 (SSYB7),4(SSYB10) for SC1
                for(j=0; j <= 5; j++) {
                    if(j == 1 || j == 4) {
                        // 0x62== RecDate
                        if(pS1[3+3+j*8] == 0x62) {
                            pStrmExt->RecDate[0] = pS1[3+3+j*8+4];         // Year
                            pStrmExt->RecDate[1] = pS1[3+3+j*8+3]&0x1f;    // Month
                            pStrmExt->RecDate[2] = pS1[3+3+j*8+2]&0x3f;    // Day
                            pStrmExt->RecDate[3] = pS1[3+3+j*8+1]&0x3f;    // TimeZone
                            bGetRecDate = FALSE;
                            break;
                        }
                    }
               }
            }

            //
            // RecTime: VRT
            //
            if(bGetRecTime) {
                // go thru 6 sync blocks (8 bytes per block) per Subcode; idx 2(SSYB2),5(SSYB5) for SC0
                for(j=0; j <= 5 ; j++) {
                    if(j == 2 || j == 5) {
                        // 0x63== RecTime
                        if(pS0[3+3+j*8] == 0x63) {
                            pStrmExt->RecTime[0] = pS0[3+3+j*8+4]&0x3f;
                            pStrmExt->RecTime[1] = pS0[3+3+j*8+3]&0x7f;
                            pStrmExt->RecTime[2] = pS0[3+3+j*8+2]&0x7f;
                            pStrmExt->RecTime[3] = pS0[3+3+j*8+1]&0x3f;
                            bGetRecTime = FALSE;
                            break;
                        }
                    }
                }
            }

            if(bGetRecTime) {
                // go thru 6 sync blocks (8 bytes per block) per Subcode; idx 2 (SSYB8),5(SSYB11) for SC1
                for(j=0; j <= 5; j++) {
                    if(j == 2 || j == 5) {
                        // 0x63== RecTime
                        if(pS1[3+3+j*8] == 0x63) {
                            pStrmExt->RecTime[0] = pS1[3+3+j*8+4]&0x3f;
                            pStrmExt->RecTime[1] = pS1[3+3+j*8+3]&0x7f;
                            pStrmExt->RecTime[2] = pS1[3+3+j*8+2]&0x7f;
                            pStrmExt->RecTime[3] = pS1[3+3+j*8+1]&0x3f;
                            bGetRecTime = FALSE;
                            break;
                        }
                    }
                }
            }

        }
        
        if(!bGetRecDate && !bGetRecTime)
            break;

        pDIFBlk += DIFBLK_SIZE;  // Next sequence    
                
    }

    TRACE(TL_CIP_TRACE,("\'Frame# %.5d, Date %s %x-%.2x-%.2x,  Time %s %.2x:%.2x:%.2x,%.2x\n", 
        (ULONG) pStrmExt->FramesProcessed,
        bGetRecDate ? "NF:" : "Found:", pStrmExt->RecDate[0], pStrmExt->RecDate[1] & 0x1f, pStrmExt->RecDate[2] & 0x3f,                 
        bGetRecTime ? "NF:" : "Found:",pStrmExt->RecTime[0], pStrmExt->RecTime[1], pStrmExt->RecTime[2], pStrmExt->RecTime[3]
       ));
}

#endif //  MSDV_SUPPORT_EXTRACT_DV_DATE_TIME

#ifdef READ_CUTOMIZE_REG_VALUES

NTSTATUS 
CreateRegistryKeySingle(
    IN HANDLE hKey,
    IN ACCESS_MASK desiredAccess,
    PWCHAR pwszSection,
    OUT PHANDLE phKeySection
    )
{
    NTSTATUS status;
    UNICODE_STRING ustr;
    OBJECT_ATTRIBUTES objectAttributes;

    RtlInitUnicodeString(&ustr, pwszSection);
       InitializeObjectAttributes(
              &objectAttributes,
              &ustr,
              OBJ_CASE_INSENSITIVE,
              hKey,
              NULL
              );

    status = 
           ZwCreateKey(
                  phKeySection,
                  desiredAccess,
                  &objectAttributes,
                  0,
                  NULL,                            /* optional*/
                  REG_OPTION_NON_VOLATILE,
                  NULL
                  );         

    return status;
}


NTSTATUS 
CreateRegistrySubKey(
    IN HANDLE hKey,
    IN ACCESS_MASK desiredAccess,
    PWCHAR pwszSection,
    OUT PHANDLE phKeySection
    )
{
    UNICODE_STRING ustr;
    USHORT usPos = 1;             // Skip first backslash
    static WCHAR wSep = '\\';
    NTSTATUS status = STATUS_SUCCESS;

    RtlInitUnicodeString(&ustr, pwszSection);

    while(usPos < ustr.Length) {
        if(ustr.Buffer[usPos] == wSep) {

            // NULL terminate our partial string
            ustr.Buffer[usPos] = UNICODE_NULL;
            status = 
                CreateRegistryKeySingle(
                    hKey,
                    desiredAccess,
                    ustr.Buffer,
                    phKeySection
                    );
            ustr.Buffer[usPos] = wSep;

            if(NT_SUCCESS(status)) {
                ZwClose(*phKeySection);
            } else {
                break;
            }
        }
        usPos++;
    }

    // Create the full key
    if(NT_SUCCESS(status)) {
        status = 
            CreateRegistryKeySingle(
                 hKey,
                 desiredAccess,
                 ustr.Buffer,
                 phKeySection
                 );
    }

    return status;
}


NTSTATUS 
GetRegistryKeyValue (
    IN HANDLE Handle,
    IN PWCHAR KeyNameString,
    IN ULONG KeyNameStringLength,
    IN PVOID Data,
    IN PULONG DataLength
    )

/*++

Routine Description:
    
    This routine gets the specified value out of the registry

Arguments:

    Handle - Handle to location in registry

    KeyNameString - registry key we're looking for

    KeyNameStringLength - length of registry key we're looking for

    Data - where to return the data

    DataLength - how big the data is

Return Value:

    status is returned from ZwQueryValueKey

--*/

{
    NTSTATUS status = STATUS_INSUFFICIENT_RESOURCES;
    UNICODE_STRING keyName;
    ULONG length;
    PKEY_VALUE_FULL_INFORMATION fullInfo;


    RtlInitUnicodeString(&keyName, KeyNameString);
    
    length = sizeof(KEY_VALUE_FULL_INFORMATION) + 
            KeyNameStringLength + *DataLength;
            
    fullInfo = ExAllocatePool(PagedPool, length); 
     
    if (fullInfo) { 
       
        status = ZwQueryValueKey(
                    Handle,
                   &keyName,
                    KeyValueFullInformation,
                    fullInfo,
                    length,
                   &length
                    );
                        
        if (NT_SUCCESS(status)){

            ASSERT(fullInfo->DataLength <= *DataLength); 

            RtlCopyMemory(
                Data,
                ((PUCHAR) fullInfo) + fullInfo->DataOffset,
                fullInfo->DataLength
                );

        }            

        *DataLength = fullInfo->DataLength;
        ExFreePool(fullInfo);

    }        
    
    return (status);

}


#if 0 // Not used
NTSTATUS
SetRegistryKeyValue(
   HANDLE hKey,
   PWCHAR pwszEntry, 
   LONG nValue
   )
{
    NTSTATUS status;
    UNICODE_STRING ustr;

    RtlInitUnicodeString(&ustr, pwszEntry);

    status =          
        ZwSetValueKey(
                  hKey,
                  &ustr,
                  0,            /* optional */
                  REG_DWORD,
                  &nValue,
                  sizeof(nValue)
                  );         

   return status;
}
#endif  // Not used

//
// Registry subky and values wide character strings.
//
WCHAR wszSettings[]      = L"Settings";

WCHAR wszATNSearch[]     = L"bSupportATNSearch";
WCHAR wszSyncRecording[] = L"bSyncRecording";
WCHAR wszMaxDataSync[]   = L"tmMaxDataSync";
WCHAR wszPlayPs2RecPs[]  = L"fmPlayPause2RecPause";
WCHAR wszStop2RecPs[]    = L"fmStop2RecPause";
WCHAR wszRecPs2Rec[]     = L"tmRecPause2Rec";
WCHAR wszXprtStateChangeWait[] = L"tmXprtStateChangeWait";

BOOL
DVGetPropertyValuesFromRegistry(
    IN PDVCR_EXTENSION  pDevExt
    )
{
    NTSTATUS Status;
    HANDLE hPDOKey, hKeySettings;
    ULONG ulLength; 


    //
    // Registry key: 
    //   Windows 2000:
    //   HKEY_LOCAL_MACHINE\SYSTEM\CurrentControlSet\Control\Class\
    //   {6BDD1FC6-810F-11D0-BEC7-08002BE2092F\000x
    //
    // Win98:
    //    HKEY_LOCAL_MACHINE\SYSTEM\CurrentControlSet\Services\Class\Image\000x
    // 
    Status = 
        IoOpenDeviceRegistryKey(
            pDevExt->pPhysicalDeviceObject, 
            PLUGPLAY_REGKEY_DRIVER,
            STANDARD_RIGHTS_READ, 
            &hPDOKey
            );

    // PDO might be deleted when it was removed.    
    if(! pDevExt->bDevRemoved) {
        ASSERT(Status == STATUS_SUCCESS);
    }

    //
    // loop through our table of strings,
    // reading the registry for each.
    //
    if(NT_SUCCESS(Status)) {

        // Create or open the settings key
        Status =         
            CreateRegistrySubKey(
                hPDOKey,
                KEY_ALL_ACCESS,
                wszSettings,
                &hKeySettings
                );

        if(NT_SUCCESS(Status)) {

            // Note: we can be more selective by checking
            //   pDevExt->ulDevType
#if 0  // Not supported yet!
            // ATNSearch
            ulLength = sizeof(LONG);
            Status = GetRegistryKeyValue(
                hKeySettings, 
                wszATNSearch, 
                sizeof(wszATNSearch), 
                (PVOID) &pDevExt->bATNSearch, 
                &ulLength);
            TRACE(TL_PNP_WARNING,("\'GetRegVal: St:%x, Len:%d, bATNSearch:%d (1:Yes)\n", Status, ulLength, pDevExt->bATNSearch));
            if(!NT_SUCCESS(Status)) pDevExt->bATNSearch = FALSE;

            // bSyncRecording
            ulLength = sizeof(LONG);
            Status = GetRegistryKeyValue(
                hKeySettings, 
                wszSyncRecording, 
                sizeof(wszSyncRecording), 
                (PVOID) &pDevExt->bSyncRecording, 
                &ulLength);
            TRACE(TL_PNP_WARNING,("\'GetRegVal: St:%x, Len:%d, bSyncRecording:%d (1:Yes)\n", Status, ulLength, pDevExt->bSyncRecording));
            if(!NT_SUCCESS(Status)) pDevExt->bSyncRecording = FALSE;

            // tmMaxDataSync
            ulLength = sizeof(LONG);
            Status = GetRegistryKeyValue(
                hKeySettings, 
                wszMaxDataSync, 
                sizeof(wszMaxDataSync), 
                (PVOID) &pDevExt->tmMaxDataSync, 
                &ulLength);
            TRACE(TL_PNP_WARNING,("\'GetRegVal: St:%x, Len:%d, tmMaxDataSync:%d (msec)\n", Status, ulLength, pDevExt->tmMaxDataSync));

            // fmPlayPs2RecPs
            ulLength = sizeof(LONG);
            Status = GetRegistryKeyValue(
                hKeySettings, 
                wszPlayPs2RecPs, 
                sizeof(wszPlayPs2RecPs), 
                (PVOID) &pDevExt->fmPlayPs2RecPs, 
                &ulLength);
            TRACE(TL_PNP_WARNING,("\'GetRegVal: St:%x, Len:%d, fmPlayPs2RecPs:%d (frames)\n", Status, ulLength, pDevExt->fmPlayPs2RecPs));

            // fmStop2RecPs
            ulLength = sizeof(LONG);
            Status = GetRegistryKeyValue(
                hKeySettings, 
                wszStop2RecPs, 
                sizeof(wszStop2RecPs), 
                (PVOID) &pDevExt->fmStop2RecPs, 
                &ulLength);
            TRACE(TL_PNP_WARNING,("\'GetRegVal: St:%x, Len:%d, fmStop2RecPs:%d (frames)\n", Status, ulLength, pDevExt->fmStop2RecPs));

            // tmRecPs2Rec
            ulLength = sizeof(LONG);
            Status = GetRegistryKeyValue(
                hKeySettings, 
                wszRecPs2Rec, 
                sizeof(wszRecPs2Rec), 
                (PVOID) &pDevExt->tmRecPs2Rec, 
                &ulLength);
            TRACE(TL_PNP_WARNING,("\'GetRegVal: St:%x, Len:%d, tmRecPs2Rec:%d (msec)\n", Status, ulLength, pDevExt->tmRecPs2Rec));
#endif
            ulLength = sizeof(LONG);
            Status = GetRegistryKeyValue(
                hKeySettings, 
                wszXprtStateChangeWait, 
                sizeof(wszXprtStateChangeWait), 
                (PVOID) &pDevExt->XprtStateChangeWait, // in msec
                &ulLength);
            TRACE(TL_PNP_WARNING,("\'GetRegVal: St:%x, Len:%d, XprtStateChangeWait:%d msec\n", Status, ulLength, pDevExt->XprtStateChangeWait));
            if(!NT_SUCCESS(Status)) pDevExt->XprtStateChangeWait = 0;

            ZwClose(hKeySettings);
            ZwClose(hPDOKey);

            return TRUE;

        } else {

            TRACE(TL_PNP_ERROR,("\'GetPropertyValuesFromRegistry: CreateRegistrySubKey failed with Status=%x\n", Status));

        }

        ZwClose(hPDOKey);

    } else {

        TRACE(TL_PNP_ERROR,("\'GetPropertyValuesFromRegistry: IoOpenDeviceRegistryKey failed with Status=%x\n", Status));

    }

    // Not implemented so always return FALSE to use the defaults.
    return FALSE;
}

#if 0  // Not used
BOOL
DVSetPropertyValuesToRegistry(    
    PDVCR_EXTENSION  pDevExt
    )
{
    // Set the default to :
    //        HLM\Software\DeviceExtension->pchVendorName\1394DCam

    NTSTATUS Status;
    HANDLE hPDOKey, hKeySettings;

    TRACE(TL_PNP_TRACE,("\'SetPropertyValuesToRegistry: pDevExt=%x; pDevExt->pBusDeviceObject=%x\n", pDevExt, pDevExt->pBusDeviceObject));


    //
    // Registry key: 
    //   HKEY_LOCAL_MACHINE\SYSTEM\CurrentControlSet\Control\Class\
    //   {6BDD1FC6-810F-11D0-BEC7-08002BE2092F\000x
    //
    Status = 
        IoOpenDeviceRegistryKey(
            pDevExt->pPhysicalDeviceObject, 
            PLUGPLAY_REGKEY_DRIVER,
            STANDARD_RIGHTS_WRITE, 
            &hPDOKey);

    // PDO might be deleted when it was removed.    
    if(! pDevExt->bDevRemoved) {
        ASSERT(Status == STATUS_SUCCESS);
    }

    //
    // loop through our table of strings,
    // reading the registry for each.
    //
    if(NT_SUCCESS(Status)) {

        // Create or open the settings key
        Status =         
            CreateRegistrySubKey(
                hPDOKey,
                KEY_ALL_ACCESS,
                wszSettings,
                &hKeySettings
                );

        if(NT_SUCCESS(Status)) {

#if 0       // Note used, just an example:
            // Brightness
            Status = SetRegistryKeyValue(
                hKeySettings,
                wszBrightness,
                pDevExt->XXXX);
            TRACE(TL_PNP_TRACE,("\'SetPropertyValuesToRegistry: Status %x, Brightness %d\n", Status, pDevExt->Brightness));

#endif
            ZwClose(hKeySettings);
            ZwClose(hPDOKey);

            return TRUE;

        } else {

            TRACE(TL_PNP_ERROR,("\'GetPropertyValuesToRegistry: CreateRegistrySubKey failed with Status=%x\n", Status));

        }

        ZwClose(hPDOKey);

    } else {

        TRACE(TL_PNP_TRACE,("\'GetPropertyValuesToRegistry: IoOpenDeviceRegistryKey failed with Status=%x\n", Status));

    }

    return FALSE;
}
#endif  // Not used
#endif  // READ_CUTOMIZE_REG_VALUES
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\drivers\wdm\capture\mini\mstape\dbg.h ===
/*++

Copyright (C) Microsoft Corporation, 2000 - 2001 

Module Name:

    dbg.h

Abstract:

    Debug Code for 1394 drivers.

Environment:

    kernel mode only

Notes:

Revision History:

    03-02-2001 Switch to use TraceMask instead of DebugLevel   

--*/
#ifndef _DBG_INC
#define _DBG_INC


//
// Various definitions
//

#if 1
extern LONG MSDVCRMutextUseCount;
#endif

#if DBG

    #define _DRIVERNAME_        "MSTape"

    // PnP: loading, power state, surprise removal, device SRB
    #define TL_PNP_MASK         0x0000000F
    #define TL_PNP_INFO         0x00000001
    #define TL_PNP_TRACE        0x00000002
    #define TL_PNP_WARNING      0x00000004
    #define TL_PNP_ERROR        0x00000008

    // Connection, plug and 61883 info (get/set)
    #define TL_61883_MASK       0x000000F0
    #define TL_61883_INFO       0x00000010
    #define TL_61883_TRACE      0x00000020
    #define TL_61883_WARNING    0x00000040
    #define TL_61883_ERROR      0x00000080

    // Data
    #define TL_CIP_MASK         0x00000F00
    #define TL_CIP_INFO         0x00000100
    #define TL_CIP_TRACE        0x00000200
    #define TL_CIP_WARNING      0x00000400
    #define TL_CIP_ERROR        0x00000800

    // AVC commands
    #define TL_FCP_MASK         0x0000F000
    #define TL_FCP_INFO         0x00001000
    #define TL_FCP_TRACE        0x00002000
    #define TL_FCP_WARNING      0x00004000
    #define TL_FCP_ERROR        0x00008000

    // Stream (data intersection, open/close, stream state (get/set))
    #define TL_STRM_MASK        0x000F0000
    #define TL_STRM_INFO        0x00010000
    #define TL_STRM_TRACE       0x00020000
    #define TL_STRM_WARNING     0x00040000
    #define TL_STRM_ERROR       0x00080000

    // clock and clock event
    #define TL_CLK_MASK         0x00F00000
    #define TL_CLK_INFO         0x00100000
    #define TL_CLK_TRACE        0x00200000
    #define TL_CLK_WARNING      0x00400000
    #define TL_CLK_ERROR        0x00800000


    extern ULONG TapeTraceMask;
    extern ULONG TapeAssertLevel;


    #define TRAP DbgBreakPoint();

    #define TRACE( l, x )                       \
        if( (l) & TapeTraceMask ) {              \
            KdPrint( (_DRIVERNAME_ ": ") );     \
            KdPrint( x );                       \
        }

    #ifdef ASSERT
    #undef ASSERT
    #endif
    #define ASSERT( exp ) \
        if (TapeAssertLevel && !(exp)) \
            RtlAssert( #exp, __FILE__, __LINE__, NULL )


#else  // #if DBG

    #define TRACE( l, x ) 

#endif // #if DBG


#endif
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\drivers\wdm\capture\mini\msdv\strmdata.h ===
/*++

Copyright (C) Microsoft Corporation, 1999 - 2001  

Module Name:

    StrmData.h

Abstract:

    Header file for supporting SD DV over 1394;

Last changed by:
    
    Author:      Yee J. Wu

--*/

#ifndef _DVSTRM_INC
#define _DVSTRM_INC

#define STATIC_KSCATEGORY_RENDER_EXTERNAL \
    0xcc7bfb41L, 0xf175, 0x11d1, 0xa3, 0x92, 0x00, 0xe0, 0x29, 0x1f, 0x39, 0x59
DEFINE_GUIDSTRUCT("cc7bfb41-f175-11d1-a392-00e0291f3959", KSCATEGORY_RENDER_EXTERNAL);
#define KSCATEGORY_RENDER_EXTERNAL DEFINE_GUIDNAMED(KSCATEGORY_RENDER_EXTERNAL)

// stream topology stuff
static GUID Categories[] = {
    STATIC_KSCATEGORY_VIDEO,             // Output pin
    STATIC_KSCATEGORY_CAPTURE,           // Output pin
    STATIC_KSCATEGORY_RENDER,            // Input pin
    STATIC_KSCATEGORY_RENDER_EXTERNAL,   // Input pin
};

#define NUMBER_OF_CATEGORIES  SIZEOF_ARRAY (Categories)

static KSTOPOLOGY Topology = {
    NUMBER_OF_CATEGORIES,        // CategoriesCount
    Categories,                  // Categories
    0,                           // TopologyNodesCount
    NULL,                        // TopologyNodes
    0,                           // TopologyConnectionsCount
    NULL,                        // TopologyConnections
    NULL,                        // TopologyNodesNames
    0,                           // Reserved
};
    
#ifndef mmioFOURCC    
#define mmioFOURCC( ch0, ch1, ch2, ch3 )                \
        ( (DWORD)(BYTE)(ch0) | ( (DWORD)(BYTE)(ch1) << 8 ) |    \
        ( (DWORD)(BYTE)(ch2) << 16 ) | ( (DWORD)(BYTE)(ch3) << 24 ) )
#endif  
#define FOURCC_DVSD        mmioFOURCC('d', 'v', 's', 'd')
#define FOURCC_DVSL        mmioFOURCC('d', 'v', 's', 'l')
#define FOURCC_DVHD        mmioFOURCC('d', 'v', 'h', 'd')


#undef D_X_NTSC
#undef D_Y_NTSC
#undef D_X_NTSC_MIN
#undef D_Y_NTSC_MIN
#undef D_X_PAL
#undef D_Y_PAL
#undef D_X_PAL_MIN
#undef D_Y_PAL_MIN

#define D_X_NTSC            720
#define D_Y_NTSC            480
#define D_X_NTSC_MIN        360
#define D_Y_NTSC_MIN        240

#define D_X_PAL                720
#define D_Y_PAL                576
#define D_X_PAL_MIN            360
#define D_Y_PAL_MIN            288


// ------------------------------------------------------------------------
// External Device PROPERTY
// ------------------------------------------------------------------------

DEFINE_KSPROPERTY_TABLE(ExternalDeviceProperties)
{
    DEFINE_KSPROPERTY_ITEM
    (
        KSPROPERTY_EXTDEVICE_CAPABILITIES,
        TRUE,                                   // GetSupported or Handler
        sizeof(KSPROPERTY),                     // MinProperty
        sizeof(KSPROPERTY_EXTDEVICE_S),         // MinData
        FALSE,                                  // SetSupported or Handler
        NULL,                                   // Values
        0,                                      // RelationsCount
        NULL,                                   // Relations
        NULL,                                   // SupportHandler
        sizeof(ULONG)                           // SerializedSize
    ),

    DEFINE_KSPROPERTY_ITEM
    (
        KSPROPERTY_EXTDEVICE_PORT,
        TRUE,                                   // GetSupported or Handler
        sizeof(KSPROPERTY),                     // MinProperty
        sizeof(KSPROPERTY_EXTDEVICE_S),         // MinData
        FALSE,                                  // SetSupported or Handler
        NULL,                                   // Values
        0,                                      // RelationsCount
        NULL,                                   // Relations
        NULL,                                   // SupportHandler
        sizeof(ULONG)                           // SerializedSize
    ), 
    
    DEFINE_KSPROPERTY_ITEM
    (
        KSPROPERTY_EXTDEVICE_POWER_STATE,
        TRUE,                                   // GetSupported or Handler
        sizeof(KSPROPERTY),                     // MinProperty
        sizeof(KSPROPERTY_EXTDEVICE_S),         // MinData
        FALSE,                                  // SetSupported or Handler
        NULL,                                   // Values
        0,                                      // RelationsCount
        NULL,                                   // Relations
        NULL,                                   // SupportHandler
        sizeof(ULONG)                           // SerializedSize
    ),    

    DEFINE_KSPROPERTY_ITEM
    (
        KSPROPERTY_EXTDEVICE_ID,
        TRUE,                                   // GetSupported or Handler
        sizeof(KSPROPERTY),                     // MinProperty
        sizeof(KSPROPERTY_EXTDEVICE_S),         // MinData
        FALSE,                                  // SetSupported or Handler
        NULL,                                   // Values
        0,                                      // RelationsCount
        NULL,                                   // Relations
        NULL,                                   // SupportHandler
        sizeof(ULONG)                           // SerializedSize
    ),

    DEFINE_KSPROPERTY_ITEM
    (
        KSPROPERTY_EXTDEVICE_VERSION,
        TRUE,                                   // GetSupported or Handler
        sizeof(KSPROPERTY),                     // MinProperty
        sizeof(KSPROPERTY_EXTDEVICE_S),         // MinData
        FALSE,                                  // SetSupported or Handler
        NULL,                                   // Values
        0,                                      // RelationsCount
        NULL,                                   // Relations
        NULL,                                   // SupportHandler
        sizeof(ULONG)                           // SerializedSize
    ),

};



DEFINE_KSPROPERTY_TABLE(ExternalTransportProperties)
{
    DEFINE_KSPROPERTY_ITEM
    (
        KSPROPERTY_EXTXPORT_CAPABILITIES,
        TRUE,                                   // GetSupported or Handler
        sizeof(KSPROPERTY),                     // MinProperty
        sizeof(KSPROPERTY_EXTXPORT_S),          // MinData
        FALSE,                                  // SetSupported or Handler
        NULL,                                   // Values
        0,                                      // RelationsCount
        NULL,                                   // Relations
        NULL,                                   // SupportHandler
        sizeof(ULONG)                           // SerializedSize
    ),

    DEFINE_KSPROPERTY_ITEM
    (
        KSPROPERTY_EXTXPORT_INPUT_SIGNAL_MODE,
        TRUE,                                   // GetSupported or Handler
        sizeof(KSPROPERTY),                     // MinProperty
        sizeof(KSPROPERTY_EXTXPORT_S),          // MinData
        FALSE,                                  // SetSupported or Handler
        NULL,                                   // Values
        0,                                      // RelationsCount
        NULL,                                   // Relations
        NULL,                                   // SupportHandler
        sizeof(ULONG)                           // SerializedSize
    ),

    DEFINE_KSPROPERTY_ITEM
    (
        KSPROPERTY_EXTXPORT_OUTPUT_SIGNAL_MODE,
        TRUE,                                   // GetSupported or Handler
        sizeof(KSPROPERTY),                     // MinProperty
        sizeof(KSPROPERTY_EXTXPORT_S),          // MinData
        FALSE,                                  // SetSupported or Handler
        NULL,                                   // Values
        0,                                      // RelationsCount
        NULL,                                   // Relations
        NULL,                                   // SupportHandler
        sizeof(ULONG)                           // SerializedSize
    ),

    DEFINE_KSPROPERTY_ITEM
    (
        KSPROPERTY_EXTXPORT_LOAD_MEDIUM,
        FALSE,                                  // GetSupported or Handler
        sizeof(KSPROPERTY),                     // MinProperty
        sizeof(KSPROPERTY_EXTXPORT_S),          // MinData
        TRUE,                                   // SetSupported or Handler
        NULL,                                   // Values
        0,                                      // RelationsCount
        NULL,                                   // Relations
        NULL,                                   // SupportHandler
        sizeof(ULONG)                           // SerializedSize
    ),

    DEFINE_KSPROPERTY_ITEM
    (
        KSPROPERTY_EXTXPORT_MEDIUM_INFO,
        TRUE,                                   // GetSupported or Handler
        sizeof(KSPROPERTY),                     // MinProperty
        sizeof(KSPROPERTY_EXTXPORT_S),          // MinData
        FALSE,                                  // SetSupported or Handler
        NULL,                                   // Values
        0,                                      // RelationsCount
        NULL,                                   // Relations
        NULL,                                   // SupportHandler
        sizeof(ULONG)                           // SerializedSize
    ),

    DEFINE_KSPROPERTY_ITEM
    (
        KSPROPERTY_EXTXPORT_STATE,
        TRUE,                                   // GetSupported or Handler
        sizeof(KSPROPERTY),                     // MinProperty
        sizeof(KSPROPERTY_EXTXPORT_S),          // MinData
        TRUE,                                   // SetSupported or Handler
        NULL,                                   // Values
        0,                                      // RelationsCount
        NULL,                                   // Relations
        NULL,                                   // SupportHandler
        sizeof(ULONG)                           // SerializedSize
    ),

    DEFINE_KSPROPERTY_ITEM
    (
        // If this is an asychronous operation, we need to set and then get in separate calls.
        KSPROPERTY_EXTXPORT_STATE_NOTIFY,
        TRUE,                                   // GetSupported or Handler
        sizeof(KSPROPERTY),                     // MinProperty
        sizeof(KSPROPERTY_EXTXPORT_S),          // MinData
        TRUE,                                   // SetSupported or Handler
        NULL,                                   // Values
        0,                                      // RelationsCount
        NULL,                                   // Relations
        NULL,                                   // SupportHandler
        sizeof(ULONG)                           // SerializedSize
    ),


    DEFINE_KSPROPERTY_ITEM
    (
        KSPROPERTY_EXTXPORT_TIMECODE_SEARCH,
        FALSE,                                  // GetSupported or Handler
        sizeof(KSPROPERTY),                     // MinProperty
        sizeof(KSPROPERTY_EXTXPORT_S),          // MinData
        TRUE,                                   // SetSupported or Handler
        NULL,                                   // Values
        0,                                      // RelationsCount
        NULL,                                   // Relations
        NULL,                                   // SupportHandler
        sizeof(ULONG)                           // SerializedSize
    ),

    DEFINE_KSPROPERTY_ITEM
    (
        KSPROPERTY_EXTXPORT_ATN_SEARCH,
        FALSE,                                  // GetSupported or Handler
        sizeof(KSPROPERTY),                     // MinProperty
        sizeof(KSPROPERTY_EXTXPORT_S),          // MinData
        TRUE,                                   // SetSupported or Handler
        NULL,                                   // Values
        0,                                      // RelationsCount
        NULL,                                   // Relations
        NULL,                                   // SupportHandler
        sizeof(ULONG)                           // SerializedSize
    ),

    DEFINE_KSPROPERTY_ITEM
    (
        KSPROPERTY_EXTXPORT_RTC_SEARCH,
        FALSE,                                  // GetSupported or Handler
        sizeof(KSPROPERTY),                     // MinProperty
        sizeof(KSPROPERTY_EXTXPORT_S),          // MinData
        TRUE,                                   // SetSupported or Handler
        NULL,                                   // Values
        0,                                      // RelationsCount
        NULL,                                   // Relations
        NULL,                                   // SupportHandler
        sizeof(ULONG)                           // SerializedSize
    ),

    //
    // Allow any RAW AVC to go through including Vendor dependent
    //
    DEFINE_KSPROPERTY_ITEM
    (
        KSPROPERTY_RAW_AVC_CMD,
        TRUE,                                   // GetSupported or Handler
        sizeof(KSPROPERTY),                     // MinProperty
        sizeof(KSPROPERTY_EXTXPORT_S),          // MinData
        TRUE,                                   // SetSupported or Handler
        NULL,                                   // Values
        0,                                      // RelationsCount
        NULL,                                   // Relations
        NULL,                                   // SupportHandler
        sizeof(ULONG)                           // SerializedSize
    ),

};


DEFINE_KSPROPERTY_TABLE(TimeCodeReaderProperties)
{
    DEFINE_KSPROPERTY_ITEM
    (
        KSPROPERTY_TIMECODE_READER,
        TRUE,                                   // GetSupported or Handler
        sizeof(KSPROPERTY),                     // MinProperty
        sizeof(KSPROPERTY_TIMECODE_S),          // MinData
        FALSE,                                  // SetSupported or Handler
        NULL,                                   // Values
        0,                                      // RelationsCount
        NULL,                                   // Relations
        NULL,                                   // SupportHandler
        sizeof(ULONG)                           // SerializedSize
    ),

    DEFINE_KSPROPERTY_ITEM
    (
        KSPROPERTY_ATN_READER,
        TRUE,                                   // GetSupported or Handler
        sizeof(KSPROPERTY),                     // MinProperty
        sizeof(KSPROPERTY_TIMECODE_S),          // MinData
        FALSE,                                  // SetSupported or Handler
        NULL,                                   // Values
        0,                                      // RelationsCount
        NULL,                                   // Relations
        NULL,                                   // SupportHandler
        sizeof(ULONG)                           // SerializedSize
    ),

    DEFINE_KSPROPERTY_ITEM
    (
        KSPROPERTY_RTC_READER,
        TRUE,                                   // GetSupported or Handler
        sizeof(KSPROPERTY),                     // MinProperty
        sizeof(KSPROPERTY_TIMECODE_S),          // MinData
        FALSE,                                  // SetSupported or Handler
        NULL,                                   // Values
        0,                                      // RelationsCount
        NULL,                                   // Relations
        NULL,                                   // SupportHandler
        sizeof(ULONG)                           // SerializedSize
    ),
};


DEFINE_KSPROPERTY_TABLE(MediaSeekingProperties)
{
    DEFINE_KSPROPERTY_ITEM
    (
        // Corresponding to IMediaSeeking::IsFormatSupported()
        KSPROPERTY_MEDIASEEKING_FORMATS,
        TRUE,                                   // GetSupported or Handler
        sizeof(KSPROPERTY),                     // MinProperty
        0,                                      // MinData; MULTIPLE_ITEM, 2 step process to get data
        FALSE,                                  // SetSupported or Handler
        NULL,                                   // Values
        0,                                      // RelationsCount
        NULL,                                   // Relations
        NULL,                                   // SupportHandler
        sizeof(ULONG)                           // SerializedSize
   ),
};

KSPROPERTY_SET    VideoDeviceProperties[] =
{
    DEFINE_KSPROPERTY_SET
    ( 
        &PROPSETID_EXT_DEVICE,                   // Set
        SIZEOF_ARRAY(ExternalDeviceProperties),         // PropertiesCount
        ExternalDeviceProperties,                       // PropertyItem
        0,                                              // FastIoCount
        NULL                                            // FastIoTable
    ),

    DEFINE_KSPROPERTY_SET
    ( 
        &PROPSETID_EXT_TRANSPORT,                // Set
        SIZEOF_ARRAY(ExternalTransportProperties),      // PropertiesCount
        ExternalTransportProperties,                    // PropertyItem
        0,                                              // FastIoCount
        NULL                                            // FastIoTable
    ),

    DEFINE_KSPROPERTY_SET
    ( 
        &PROPSETID_TIMECODE_READER,              // Set
        SIZEOF_ARRAY(TimeCodeReaderProperties),         // PropertiesCount
        TimeCodeReaderProperties,                       // PropertyItem
        0,                                              // FastIoCount
        NULL                                            // FastIoTable
    ),

    DEFINE_KSPROPERTY_SET
    ( 
        &KSPROPSETID_MediaSeeking,                    // Set
        SIZEOF_ARRAY(MediaSeekingProperties),         // PropertiesCount
        MediaSeekingProperties,                       // PropertyItem
        0,                                            // FastIoCount
        NULL                                          // FastIoTable
    ),
};

#define NUMBER_VIDEO_DEVICE_PROPERTIES (SIZEOF_ARRAY(VideoDeviceProperties))


// ------------------------------------------------------------------------
// External Device Events
// ------------------------------------------------------------------------

KSEVENT_ITEM ExtDevCommandItm[] = 
{
    {
        KSEVENT_EXTDEV_COMMAND_NOTIFY_INTERIM_READY,
        0, // sizeof(KSEVENT_ITEM),
        0,
        NULL,
        NULL,
        NULL
    },    

    {
        KSEVENT_EXTDEV_COMMAND_CONTROL_INTERIM_READY,
        0, // sizeof(KSEVENT_ITEM),
        0,
        NULL,
        NULL,
        NULL
    },

#ifdef MSDVDV_SUPPORT_BUSRESET_EVENT    
    // Application cares about this since AVC command will be ABORTED!
    {
        KSEVENT_EXTDEV_COMMAND_BUSRESET,
        0, // sizeof(KSEVENT_ITEM),
        0,
        NULL,
        NULL,
        NULL
    },
#endif

    // Tell client this device is being removed.
    {
        KSEVENT_EXTDEV_NOTIFY_REMOVAL,
        0, // sizeof(KSEVENT_ITEM),
        0,
        NULL,
        NULL,
        NULL
    },
};

// define event set related with streams
KSEVENT_SET VideoDeviceEvents[] =
{
    {
        &KSEVENTSETID_EXTDEV_Command,
        SIZEOF_ARRAY(ExtDevCommandItm),
        ExtDevCommandItm,
    },
};

#define NUMBER_VIDEO_DEVICE_EVENTS (SIZEOF_ARRAY(VideoDeviceEvents))


// ------------------------------------------------------------------------
// Stream Property sets for all video capture streams
// ------------------------------------------------------------------------

DEFINE_KSPROPERTY_TABLE(VideoStreamConnectionProperties)
{
    DEFINE_KSPROPERTY_ITEM
    (
        KSPROPERTY_CONNECTION_ALLOCATORFRAMING,
        TRUE,                                   // GetSupported or Handler
        sizeof(KSPROPERTY),                     // MinProperty
        sizeof(KSALLOCATOR_FRAMING),            // MinData
        FALSE,                                  // SetSupported or Handler
        NULL,                                   // Values
        0,                                      // RelationsCount
        NULL,                                   // Relations
        NULL,                                   // SupportHandler
        sizeof(ULONG)                           // SerializedSize
    ),
};

DEFINE_KSPROPERTY_TABLE(VideoStreamDroppedFramesProperties)
{
    DEFINE_KSPROPERTY_ITEM
    (
        KSPROPERTY_DROPPEDFRAMES_CURRENT,
        TRUE,                                   // GetSupported or Handler
        sizeof(KSPROPERTY_DROPPEDFRAMES_CURRENT_S),// MinProperty
        sizeof(KSPROPERTY_DROPPEDFRAMES_CURRENT_S),// MinData
        FALSE,                                  // SetSupported or Handler
        NULL,                                   // Values
        0,                                      // RelationsCount
        NULL,                                   // Relations
        NULL,                                   // SupportHandler
        0                                       // SerializedSize
    ),
};

#ifdef SUPPORT_QUALITY_CONTROL
DEFINE_KSPROPERTY_TABLE(VideoStreamQualityControlProperties)
{
    DEFINE_KSPROPERTY_ITEM
    (
        KSPROPERTY_STREAM_QUALITY,
        TRUE,                                   // GetSupported or Handler
        sizeof(KSPROPERTY),                     // MinProperty
        sizeof(KSQUALITY),                      // MinData
        FALSE,                                  // SetSupported or Handler
        NULL,                                   // Values
        0,                                      // RelationsCount
        NULL,                                   // Relations
        NULL,                                   // SupportHandler
        0,                                      // SerializedSize
    ),
};
#endif

#ifdef SUPPORT_NEW_AVC
DEFINE_KSPROPERTY_TABLE(VideoStreamStreamAllocatorStatusProperties)
{
    DEFINE_KSPROPERTY_ITEM
    (
        KSPROPERTY_STREAMALLOCATOR_STATUS,
        TRUE,                                   // GetSupported or Handler
        sizeof(KSPROPERTY),                     // MinProperty
        sizeof(KSSTREAMALLOCATOR_STATUS),       // MinData
        FALSE,                                  // SetSupported or Handler
        NULL,                                   // Values
        0,                                      // RelationsCount
        NULL,                                   // Relations
        NULL,                                   // SupportHandler
        0,                                      // SerializedSize
    ),
};


DEFINE_KSPROPERTY_TABLE(VideoStreamMediumsProperties)
{
    DEFINE_KSPROPERTY_ITEM
    (
        KSPROPERTY_PIN_MEDIUMS,
        TRUE,                                   // GetSupported or Handler
        sizeof(KSPROPERTY),                     // MinProperty
        0,                                      // MinData; MULTIPLE_ITEM, 2 step process to get data
        FALSE,                                  // SetSupported or Handler
        NULL,                                   // Values
        0,                                      // RelationsCount
        NULL,                                   // Relations
        NULL,                                   // SupportHandler
        0,                                      // SerializedSize
    ),
};
#endif

KSPROPERTY_SET    VideoStreamProperties[] =
{
    DEFINE_KSPROPERTY_SET
    ( 
        &KSPROPSETID_Connection,                        // Set
        SIZEOF_ARRAY(VideoStreamConnectionProperties),  // PropertiesCount
        VideoStreamConnectionProperties,                // PropertyItem
        0,                                              // FastIoCount
        NULL                                            // FastIoTable
    ),

    DEFINE_KSPROPERTY_SET
    ( 
        &PROPSETID_VIDCAP_DROPPEDFRAMES,                // Set
        SIZEOF_ARRAY(VideoStreamDroppedFramesProperties),  // PropertiesCount
        VideoStreamDroppedFramesProperties,                // PropertyItem
        0,                                              // FastIoCount
        NULL                                            // FastIoTable
    ),
#ifdef SUPPORT_NEW_AVC 
    // Apply only to INPIN????
    DEFINE_KSPROPERTY_SET
    ( 
        &KSPROPSETID_StreamAllocator,                   // Set
        SIZEOF_ARRAY(VideoStreamStreamAllocatorStatusProperties),     // PropertiesCount
        VideoStreamStreamAllocatorStatusProperties,     // PropertyItem
        0,                                              // FastIoCount
        NULL                                            // FastIoTable
    ),
    
    DEFINE_KSPROPERTY_SET
    ( 
        &KSPROPSETID_Pin,                               // Set
        SIZEOF_ARRAY(VideoStreamMediumsProperties),     // PropertiesCount
        VideoStreamMediumsProperties,                   // PropertyItem
        0,                                              // FastIoCount
        NULL                                            // FastIoTable
    ),
#endif
};

#define NUMBER_VIDEO_STREAM_PROPERTIES (SIZEOF_ARRAY(VideoStreamProperties))

KSPROPERTY_SET    VideoStreamPropertiesInPin[] =
{
    DEFINE_KSPROPERTY_SET
    ( 
        &KSPROPSETID_Connection,                        // Set
        SIZEOF_ARRAY(VideoStreamConnectionProperties),  // PropertiesCount
        VideoStreamConnectionProperties,                // PropertyItem
        0,                                              // FastIoCount
        NULL                                            // FastIoTable
    ),

    DEFINE_KSPROPERTY_SET
    ( 
        &PROPSETID_VIDCAP_DROPPEDFRAMES,                // Set
        SIZEOF_ARRAY(VideoStreamDroppedFramesProperties),  // PropertiesCount
        VideoStreamDroppedFramesProperties,                // PropertyItem
        0,                                              // FastIoCount
        NULL                                            // FastIoTable
    ),
#ifdef SUPPORT_QUALITY_CONTROL
    // Apply only to INPIN
    DEFINE_KSPROPERTY_SET
    ( 
        &KSPROPSETID_Stream,                            // Set
        SIZEOF_ARRAY(VideoStreamQualityControlProperties),  // PropertiesCount
        VideoStreamQualityControlProperties,                // PropertyItem
        0,                                              // FastIoCount
        NULL                                            // FastIoTable
    ),
#endif
#ifdef SUPPORT_NEW_AVC 
    // Apply only to INPIN
    DEFINE_KSPROPERTY_SET
    ( 
        &KSPROPSETID_StreamAllocator,                   // Set
        SIZEOF_ARRAY(VideoStreamStreamAllocatorStatusProperties),     // PropertiesCount
        VideoStreamStreamAllocatorStatusProperties,     // PropertyItem
        0,                                              // FastIoCount
        NULL                                            // FastIoTable
    ), 
    
    DEFINE_KSPROPERTY_SET
    ( 
        &KSPROPSETID_Pin,                               // Set
        SIZEOF_ARRAY(VideoStreamMediumsProperties),     // PropertiesCount
        VideoStreamMediumsProperties,                   // PropertyItem
        0,                                              // FastIoCount
        NULL                                            // FastIoTable
    ),
#endif
};

#define NUMBER_VIDEO_STREAM_PROPERTIES_INPIN (SIZEOF_ARRAY(VideoStreamPropertiesInPin))
// ----------------------------------------------------------------------
// Stream events
// ------------------------------------------------------------------------


// FORMAT_DVInfo
//
// Create a local copy of this GUID and make sure that it is not in the PAGED segment
//
const
GUID
KSEVENTSETID_Connection_Local = {STATICGUIDOF(KSEVENTSETID_Connection)};

const
GUID
KSEVENTSETID_Clock_Local = {STATICGUIDOF(KSEVENTSETID_Clock)};

// Isoch transmit End of stream event item
KSEVENT_ITEM EndOfStreamEventItm[] = 
{
    {
        KSEVENT_CONNECTION_ENDOFSTREAM,
        0,
        0,
        NULL,
        NULL,
        NULL
    }
};

// Clock event item
KSEVENT_ITEM ClockEventItm[] =
{
    {
        KSEVENT_CLOCK_POSITION_MARK,        // position mark event supported
        sizeof (KSEVENT_TIME_MARK),         // requires this data as input
        sizeof (KSEVENT_TIME_MARK),         // allocate space to copy the data
        NULL,
        NULL,
        NULL
    },
};

KSEVENT_SET ClockEventSet[] =
{
    {
        &KSEVENTSETID_Clock,
        SIZEOF_ARRAY(ClockEventItm),
        ClockEventItm,
    }
};


// define event set related with streams

// Output pin event set
KSEVENT_SET StreamEventsOutPin[] =
{
    {
        &KSEVENTSETID_Clock_Local,
        SIZEOF_ARRAY(ClockEventItm),
        ClockEventItm,
    },
};

// Input pin events set
KSEVENT_SET StreamEventsInPin[] =
{
    {
        &KSEVENTSETID_Connection_Local, 
        SIZEOF_ARRAY(EndOfStreamEventItm),
        EndOfStreamEventItm,
    },
    {
        &KSEVENTSETID_Clock_Local,
        SIZEOF_ARRAY(ClockEventItm),
        ClockEventItm,
    },
};

#define NUMBER_STREAM_EVENTS_OUT_PIN (SIZEOF_ARRAY(StreamEventsOutPin))
#define NUMBER_STREAM_EVENTS_IN_PIN (SIZEOF_ARRAY(StreamEventsInPin))




// ----------------------------------------------------------------------
// Stream data ranges
// ------------------------------------------------------------------------

//
// AAUX Source Pack:
// (SDDV_NTSC)
// PC4: d1 1101 0001 [EF:1:On];[TC:1:50/15us];[SMP:010:32KHz];[QU:001:12bit-nonlinear];
//*PC3: c0 1100 0000 [ML:1:NotMulti-language];[50/60:0:NTSC];[STYPE:0000:SD]
// PC2: 30 0011 0000 [SM:0:Multiple-Stereo];[CHN:01:two channels per an audio block];[PA:1:independent channel];[AudMode:0000:...]
// PC1: cf 1100 1111 [LF:1:Unlocked];[AFSize:1111:???]
//
// (SDDV_PAL)
//*PC3: c0 1110 0000 [ML:1:NotMulti-language];[50/60:1:PAL];[STYPE:0000:SD]
//

#define AAUXSRC_DEFAULT         0xd1c030cf   // ox PC4:PC3:PC2:PC1

#define AAUXSRC_AMODE_F         0x00000f00   // Set the AUDIO MODE of the 2nd AAUXSRC to 1111


#define AUXSRC_NTSC             0x00000000
#define AUXSRC_PAL              0x00200000
#define AUXSRC_STYPE_SD         0x00000000
#define AUXSRC_STYPE_SD_DVCPRO  0x000e0000
#define AUXSRC_STYPE_SDL        0x00010000
#define AUXSRC_STYPE_HD         0x00020000




#define AAUXSRC_SD_NTSC         AAUXSRC_DEFAULT | AUXSRC_NTSC | AUXSRC_STYPE_SD        // 0xd1c030cf 
#define AAUXSRC_SD_PAL          AAUXSRC_DEFAULT | AUXSRC_PAL  | AUXSRC_STYPE_SD        // 0xd1e030d0

#define AAUXSRC_SD_NTSC_DVCPRO  AAUXSRC_DEFAULT | AUXSRC_NTSC | AUXSRC_STYPE_SD_DVCPRO // 0xd1de30cf 
#define AAUXSRC_SD_PAL_DVCPRO   AAUXSRC_DEFAULT | AUXSRC_PAL  | AUXSRC_STYPE_SD_DVCPRO // 0xd1fe30d0 

#define AAUXSRC_SDL_NTSC        AAUXSRC_DEFAULT | AUXSRC_NTSC | AUXSRC_STYPE_SDL       // 0xd1c130cf 
#define AAUXSRC_SDL_PAL         AAUXSRC_DEFAULT | AUXSRC_PAL  | AUXSRC_STYPE_SDL       // 0xd1e130d0

#define AAUXSRC_HD_NTSC         AAUXSRC_DEFAULT | AUXSRC_NTSC | AUXSRC_STYPE_HD        // 0xd1c230cf 
#define AAUXSRC_HD_PAL          AAUXSRC_DEFAULT | AUXSRC_PAL  | AUXSRC_STYPE_HD        // 0xd1e230d0
 

//
// AAUX Source Control
//
// PC4:ff:1111 1111 [1];[Genere:111 1111:NoInfo]
// PC3:a0:1010 0000 [DRF:1:Forward direction];[Speed:010 0000:normal recording]
// PC2:cf:1100 1111 [RecSt:1:NoRecStPt];[RedEd:1:NoRecEdPt];[RecMode:001:Original];[InsCh:111:NoInfo]
// PC1:3f:0011 1111 [CMGS:00:CopyGMS];[ISR:11:NoInfo];[CMP:11:NoInfo];[SS:11:NoInfo]

#define AAUXSRCCTL_DEFAULT      0xffa0cf3f    // ox PC4:PC3:PC2:PC1

//
// VAUX Source
//
// PC4:ff [TunderCat:1111 1111:NoInfo]
// PC3:00 [SrcCode:00:Camera];[50/60:0:NTSC];[STYPE:0000:SD]
// PC2:ff [BW:1:Color];[EN:ColorFrameEnable:1:Invalid];[CLF:11:"Invalid"];[TV Ch:1111:NoInfo]
// PC1:ff:[TCChannel:1111 1111:NoInfo]

#define VAUXSRC_DEFAULT         0xff00ffff    // ox PC4:PC3:PC2:PC1

//
// VAUX Source Control
//
// PC4:ff 1111 1111 [1];[Genere:111 1111:NoInfo]
// PC3:fc 1111 1100 [FF:1:BothFields];[FS:1:Field1];[FC:1:DiffPic];[IL:1:Interlaced];
//                  [ST:1:1001/60 or 1/50];[SC:1:NotStillPic];[BCSYS:00:type0]
// PC2:c8 1100 1000 [RecSt:1:NoRecStPt];[1];[RecMode:001:Original];[1];[DISP:000:(4:3) full fmt]
// PC1:3f:0011 1111 [CMGS:00:CopyGMS];[ISR:11:NoInfo];[CMP:11:NoInfo];[SS:11:NoInfo]

#define VAUXSRCCTL_DEFAULT_EIA  0xfffcc83f    // for NTSC(?) 
#define VAUXSRCCTL_DEFAULT_ETS  0xfffdc83f    // for PAL (?) 


// SD DV VidOnly NTSC Stream
KS_DATARANGE_VIDEO SDDV_VidOnlyNTSCStream =
{
    // KSDATARANGE
    {
        sizeof (KS_DATARANGE_VIDEO),    // FormatSize
        0,                              // Flags
        FRAME_SIZE_SD_DVCR_NTSC,        // SampleSize
        0,                              // Reserved
        STATIC_KSDATAFORMAT_TYPE_VIDEO, 
        STATIC_KSDATAFORMAT_SUBTYPE_DVSD,
        STATIC_KSDATAFORMAT_SPECIFIER_VIDEOINFO, 
    },

    TRUE,               // BOOL,  bFixedSizeSamples (all samples same size?)
    FALSE,              // BOOL,  bTemporalCompression (all I frames?)
    KS_VIDEOSTREAM_CAPTURE, // StreamDescriptionFlags  (KS_VIDEO_DESC_*)
    0,                  // MemoryAllocationFlags   (KS_VIDEO_ALLOC_*)

    // KS_VIDEO_STREAM_CONFIG_CAPS  
    {
        STATIC_KSDATAFORMAT_SPECIFIER_VIDEOINFO, //MEDIATYPE_Video
        KS_AnalogVideo_NTSC_M,      // AnalogVideoStandard
        D_X_NTSC, D_Y_NTSC,         // InputSize, (the inherent size of the incoming signal
                                    //             with every digitized pixel unique)
        D_X_NTSC_MIN, D_Y_NTSC_MIN, // MinCroppingSize, smallest rcSrc cropping rect allowed
        D_X_NTSC, D_Y_NTSC,         // MaxCroppingSize, largest  rcSrc cropping rect allowed
        1,              // CropGranularityX, granularity of cropping size
        1,              // CropGranularityY    
        1,              // CropAlignX, alignment of cropping rect 
        1,              // CropAlignY;
        D_X_NTSC_MIN, D_Y_NTSC_MIN,     // MinOutputSize, smallest bitmap stream can produce
        D_X_NTSC, D_Y_NTSC,                // MaxOutputSize, largest  bitmap stream can produce
        1,              // OutputGranularityX, granularity of output bitmap size
        1,              // OutputGranularityY;
        0,              // StretchTapsX  (0 no stretch, 1 pix dup, 2 interp...)
        0,              // StretchTapsY
        0,              // ShrinkTapsX 
        0,              // ShrinkTapsY
        333667,         // MinFrameInterval, 100 nS units// MinFrameInterval, 100 nS units
        333667,         // MaxFrameInterval, 100 nS units
        (FRAME_SIZE_SD_DVCR_NTSC * 8)*30,  // MinBitsPerSecond;
        (FRAME_SIZE_SD_DVCR_NTSC * 8)*30,  // MaxBitsPerSecond;
    }, 
        
    // KS_VIDEOINFOHEADER (default format)
    {
        0,0,0,0, //D_X_NTSC,D_Y_NTSC,    // 0,0,720,480
        0,0,0,0,        //    RECT            rcTarget;          // Where the video should go
        (FRAME_SIZE_SD_DVCR_NTSC * 8 * 30),    //    DWORD           dwBitRate;         // Approximate bit data rate
        0L,             //    DWORD           dwBitErrorRate;    // Bit error rate for this stream
        333667,         //    REFERENCE_TIME  AvgTimePerFrame;   // Average time per frame (100ns units)

        sizeof (KS_BITMAPINFOHEADER),   //    DWORD      biSize;
        D_X_NTSC,                       //    LONG       biWidth;
        D_Y_NTSC,                       //    LONG       biHeight;
        1,                          //    WORD       biPlanes;
        24,                         //    WORD       biBitCount;
        FOURCC_DVSD,                //    DWORD      biCompression;
        FRAME_SIZE_SD_DVCR_NTSC,    //    DWORD      biSizeImage;
        0,                          //    LONG       biXPelsPerMeter;
        0,                          //    LONG       biYPelsPerMeter;
        0,                          //    DWORD      biClrUsed;
        0,                          //    DWORD      biClrImportant;
    },
};

// SD DV VidOnly PAL Stream
KS_DATARANGE_VIDEO SDDV_VidOnlyPALStream =
{
    // KSDATARANGE
    {
        sizeof (KS_DATARANGE_VIDEO),   // FormatSize
        0,                             // Flags
        FRAME_SIZE_SD_DVCR_PAL,        // SampleSize
        0,                             // Reserved
        STATIC_KSDATAFORMAT_TYPE_VIDEO, 
        STATIC_KSDATAFORMAT_SUBTYPE_DVSD,
        STATIC_KSDATAFORMAT_SPECIFIER_VIDEOINFO, 
    },

    TRUE,               // BOOL,  bFixedSizeSamples (all samples same size?)
    FALSE,              // BOOL,  bTemporalCompression (all I frames?)
    KS_VIDEOSTREAM_CAPTURE,    // StreamDescriptionFlags  (KS_VIDEO_DESC_*)
    0,                  // MemoryAllocationFlags   (KS_VIDEO_ALLOC_*)

    // _KS_VIDEO_STREAM_CONFIG_CAPS  
    {
        STATIC_KSDATAFORMAT_SPECIFIER_VIDEOINFO, //MEDIATYPE_Video
        KS_AnalogVideo_PAL_B,        // AnalogVideoStandard
        D_X_PAL, D_Y_PAL,            // InputSize, (the inherent size of the incoming signal
                        //             with every digitized pixel unique)
        D_X_PAL_MIN, D_Y_PAL_MIN,   // MinCroppingSize, smallest rcSrc cropping rect allowed
        D_X_PAL, D_Y_PAL,           // MaxCroppingSize, largest  rcSrc cropping rect allowed
        1,              // CropGranularityX, granularity of cropping size
        1,              // CropGranularityY    
        1,              // CropAlignX, alignment of cropping rect 
        1,              // CropAlignY;
        D_X_PAL_MIN, D_Y_PAL_MIN,   // MinOutputSize, smallest bitmap stream can produce
        D_X_PAL, D_Y_PAL,            // MaxOutputSize, largest  bitmap stream can produce
        1,              // OutputGranularityX, granularity of output bitmap size
        1,              // OutputGranularityY;
        0,              // StretchTapsX  (0 no stretch, 1 pix dup, 2 interp...)
        0,              // StretchTapsY
        0,              // ShrinkTapsX 
        0,              // ShrinkTapsY
        400000,         // MinFrameInterval, 100 nS units
        400000,         // MaxFrameInterval, 100 nS units
        (FRAME_SIZE_SD_DVCR_PAL * 8)*25,  // MinBitsPerSecond;
        (FRAME_SIZE_SD_DVCR_PAL * 8)*25,  // MaxBitsPerSecond;
    }, 
        
    // KS_VIDEOINFOHEADER (default format)
    {
        0,0,0,0, // D_X_PAL,D_Y_PAL,    // 0,0,720,480
        0,0,0,0,        //    RECT            rcTarget;          // Where the video should go
        (FRAME_SIZE_SD_DVCR_PAL * 8 * 25),  //    DWORD   dwBitRate;         // Approximate bit data rate
        0L,             //    DWORD           dwBitErrorRate;    // Bit error rate for this stream
        400000,         //    REFERENCE_TIME  AvgTimePerFrame;   // Average time per frame (100ns units)

        sizeof (KS_BITMAPINFOHEADER),   //    DWORD      biSize;
        D_X_PAL,                        //    LONG       biWidth;
        D_Y_PAL,                        //    LONG       biHeight;
        1,                          //    WORD       biPlanes;
        24,                         //    WORD       biBitCount;
        FOURCC_DVSD,                //    DWORD      biCompression;
        FRAME_SIZE_SD_DVCR_PAL,     //    DWORD      biSizeImage;
        0,                          //    LONG       biXPelsPerMeter;
        0,                          //    LONG       biYPelsPerMeter;
        0,                          //    DWORD      biClrUsed;
        0,                          //    DWORD      biClrImportant;
    },
};

#ifdef MSDV_SUPPORT_SDL_DVCR
// SDL DV VidOnly NTSC Stream
KS_DATARANGE_VIDEO SDLDV_VidOnlyNTSCStream =
{
    // KSDATARANGE
    {
        sizeof (KS_DATARANGE_VIDEO),    // FormatSize
        0,                              // Flags
        FRAME_SIZE_SDL_DVCR_NTSC,       // SampleSize
        0,                              // Reserved
        STATIC_KSDATAFORMAT_TYPE_VIDEO, 
        STATIC_KSDATAFORMAT_SUBTYPE_DVSL,
        STATIC_KSDATAFORMAT_SPECIFIER_VIDEOINFO, 
    },

    TRUE,               // BOOL,  bFixedSizeSamples (all samples same size?)
    FALSE,              // BOOL,  bTemporalCompression (all I frames?)
    KS_VIDEOSTREAM_CAPTURE, // StreamDescriptionFlags  (KS_VIDEO_DESC_*)
    0,                  // MemoryAllocationFlags   (KS_VIDEO_ALLOC_*)

    // KS_VIDEO_STREAM_CONFIG_CAPS  
    {
        STATIC_KSDATAFORMAT_SPECIFIER_VIDEOINFO, //MEDIATYPE_Video
        KS_AnalogVideo_NTSC_M,      // AnalogVideoStandard
        D_X_NTSC, D_Y_NTSC,         // InputSize, (the inherent size of the incoming signal
                                    //             with every digitized pixel unique)
        D_X_NTSC_MIN, D_Y_NTSC_MIN, // MinCroppingSize, smallest rcSrc cropping rect allowed
        D_X_NTSC, D_Y_NTSC,         // MaxCroppingSize, largest  rcSrc cropping rect allowed
        1,              // CropGranularityX, granularity of cropping size
        1,              // CropGranularityY    
        1,              // CropAlignX, alignment of cropping rect 
        1,              // CropAlignY;
        D_X_NTSC_MIN, D_Y_NTSC_MIN,     // MinOutputSize, smallest bitmap stream can produce
        D_X_NTSC, D_Y_NTSC,                // MaxOutputSize, largest  bitmap stream can produce
        1,              // OutputGranularityX, granularity of output bitmap size
        1,              // OutputGranularityY;
        0,              // StretchTapsX  (0 no stretch, 1 pix dup, 2 interp...)
        0,              // StretchTapsY
        0,              // ShrinkTapsX 
        0,              // ShrinkTapsY
        333667,         // MinFrameInterval, 100 nS units// MinFrameInterval, 100 nS units
        333667,         // MaxFrameInterval, 100 nS units
        (FRAME_SIZE_SDL_DVCR_NTSC * 8)*30,  // MinBitsPerSecond;
        (FRAME_SIZE_SDL_DVCR_NTSC * 8)*30,  // MaxBitsPerSecond;
    }, 
        
    // KS_VIDEOINFOHEADER (default format)
    {
        0,0,0,0, //D_X_NTSC,D_Y_NTSC,    // 0,0,720,480
        0,0,0,0,        //    RECT            rcTarget;          // Where the video should go
        (FRAME_SIZE_SDL_DVCR_NTSC * 8 * 30),    //    DWORD           dwBitRate;         // Approximate bit data rate
        0L,             //    DWORD           dwBitErrorRate;    // Bit error rate for this stream
        333667,         //    REFERENCE_TIME  AvgTimePerFrame;   // Average time per frame (100ns units)

        sizeof (KS_BITMAPINFOHEADER),   //    DWORD      biSize;
        D_X_NTSC,                       //    LONG       biWidth;
        D_Y_NTSC,                       //    LONG       biHeight;
        1,                          //    WORD       biPlanes;
        24,                         //    WORD       biBitCount;
        FOURCC_DVSL,                //    DWORD      biCompression;
        FRAME_SIZE_SDL_DVCR_NTSC,   //    DWORD      biSizeImage;
        0,                          //    LONG       biXPelsPerMeter;
        0,                          //    LONG       biYPelsPerMeter;
        0,                          //    DWORD      biClrUsed;
        0,                          //    DWORD      biClrImportant;
    },
};

// SDL DV VidOnly PAL Stream
KS_DATARANGE_VIDEO SDLDV_VidOnlyPALStream =
{
    // KSDATARANGE
    {
        sizeof (KS_DATARANGE_VIDEO),   // FormatSize
        0,                             // Flags
        FRAME_SIZE_SDL_DVCR_PAL,        // SampleSize
        0,                             // Reserved
        STATIC_KSDATAFORMAT_TYPE_VIDEO, 
        STATIC_KSDATAFORMAT_SUBTYPE_DVSL,
        STATIC_KSDATAFORMAT_SPECIFIER_VIDEOINFO, 
    },

    TRUE,               // BOOL,  bFixedSizeSamples (all samples same size?)
    FALSE,              // BOOL,  bTemporalCompression (all I frames?)
    KS_VIDEOSTREAM_CAPTURE,    // StreamDescriptionFlags  (KS_VIDEO_DESC_*)
    0,                  // MemoryAllocationFlags   (KS_VIDEO_ALLOC_*)

    // _KS_VIDEO_STREAM_CONFIG_CAPS  
    {
        STATIC_KSDATAFORMAT_SPECIFIER_VIDEOINFO, //MEDIATYPE_Video
        KS_AnalogVideo_PAL_B,        // AnalogVideoStandard
        D_X_PAL, D_Y_PAL,            // InputSize, (the inherent size of the incoming signal
                        //             with every digitized pixel unique)
        D_X_PAL_MIN, D_Y_PAL_MIN,   // MinCroppingSize, smallest rcSrc cropping rect allowed
        D_X_PAL, D_Y_PAL,           // MaxCroppingSize, largest  rcSrc cropping rect allowed
        1,              // CropGranularityX, granularity of cropping size
        1,              // CropGranularityY    
        1,              // CropAlignX, alignment of cropping rect 
        1,              // CropAlignY;
        D_X_PAL_MIN, D_Y_PAL_MIN,   // MinOutputSize, smallest bitmap stream can produce
        D_X_PAL, D_Y_PAL,            // MaxOutputSize, largest  bitmap stream can produce
        1,              // OutputGranularityX, granularity of output bitmap size
        1,              // OutputGranularityY;
        0,              // StretchTapsX  (0 no stretch, 1 pix dup, 2 interp...)
        0,              // StretchTapsY
        0,              // ShrinkTapsX 
        0,              // ShrinkTapsY
        400000,         // MinFrameInterval, 100 nS units
        400000,         // MaxFrameInterval, 100 nS units
        (FRAME_SIZE_SDL_DVCR_PAL * 8)*25,  // MinBitsPerSecond;
        (FRAME_SIZE_SDL_DVCR_PAL * 8)*25,  // MaxBitsPerSecond;
    }, 
        
    // KS_VIDEOINFOHEADER (default format)
    {
        0,0,0,0, // D_X_PAL,D_Y_PAL,    // 0,0,720,480
        0,0,0,0,        //    RECT            rcTarget;          // Where the video should go
        (FRAME_SIZE_SDL_DVCR_PAL * 8 * 25),  //    DWORD   dwBitRate;         // Approximate bit data rate
        0L,             //    DWORD           dwBitErrorRate;    // Bit error rate for this stream
        400000,         //    REFERENCE_TIME  AvgTimePerFrame;   // Average time per frame (100ns units)

        sizeof (KS_BITMAPINFOHEADER),   //    DWORD      biSize;
        D_X_PAL,                        //    LONG       biWidth;
        D_Y_PAL,                        //    LONG       biHeight;
        1,                          //    WORD       biPlanes;
        24,                         //    WORD       biBitCount;
        FOURCC_DVSL,                //    DWORD      biCompression;
        FRAME_SIZE_SDL_DVCR_PAL,    //    DWORD      biSizeImage;
        0,                          //    LONG       biXPelsPerMeter;
        0,                          //    LONG       biYPelsPerMeter;
        0,                          //    DWORD      biClrUsed;
        0,                          //    DWORD      biClrImportant;
    },
};

#endif // MSDV_SUPPORT_SDL_DVCR


// SD DV IAV NTSC Stream
#ifdef SUPPORT_NEW_AVC
KS_DATARANGE_DV_AVC
SDDV_IavNtscStreamAVC =
{
    // KSDATARANGE
    {
        sizeof (KS_DATARANGE_DV_AVC),  // FormatSize
        0,                             // Flags
        FRAME_SIZE_SD_DVCR_NTSC,       // SampleSize
        0,                             // Reserved
        STATIC_KSDATAFORMAT_TYPE_INTERLEAVED,
        STATIC_KSDATAFORMAT_SUBTYPE_DVSD,       
        // Indicate that an AVC structure is included and this is used for direct DV to DV connection. 
        STATIC_KSDATAFORMAT_SPECIFIER_DV_AVC,  // STATIC_KSDATAFORMAT_SPECIFIER_DVINFO,
    },

    // DVINFO
    // Note: audio is set for 32khz
    {
        //for 1st 5/6 DIF seq.
        AAUXSRC_SD_NTSC,               // DWORD dwDVAAuxSrc;
        AAUXSRCCTL_DEFAULT,            // DWORD dwDVAAuxCtl;
        // for 2nd  5/6 DIF seq.
        AAUXSRC_SD_NTSC | AAUXSRC_AMODE_F, // DWORD dwDVAAuxSrc1;
        AAUXSRCCTL_DEFAULT,            // DWORD dwDVAAuxCtl1;
        //for video information
        VAUXSRC_DEFAULT | AUXSRC_NTSC | AUXSRC_STYPE_SD, // DWORD dwDVVAuxSrc;
        VAUXSRCCTL_DEFAULT_EIA,        // DWORD dwDVVAuxCtl;
        0,                             // DWORD dwDVReserved[2];
        0,                             //
    },
    // AVCPRECONNECTINFO
    {
     0,   // Device ID
     0,   // Subunit address
     0,   // Subunit Plug number
     0,   // Data Flow
     0,   // Flag/Plug Handle
     0,   // UnitPlugNumber
    },
};

// SDL DV IAV PAL Stream
KS_DATARANGE_DV_AVC 
SDDV_IavPalStreamAVC =
{
    // KSDATARANGE
    {
        sizeof (KS_DATARANGE_DV_AVC), // FormatSize
        0,                             // Flags
        FRAME_SIZE_SD_DVCR_PAL,        // SampleSize
        0,                             // Reserved
        STATIC_KSDATAFORMAT_TYPE_INTERLEAVED, 
        STATIC_KSDATAFORMAT_SUBTYPE_DVSD,
        // Indicate that an AVC structure is included and this is used for direct DV to DV connection.
        STATIC_KSDATAFORMAT_SPECIFIER_DV_AVC,  // STATIC_KSDATAFORMAT_SPECIFIER_DVINFO,
    },
    
    // DVINFO
    // Note: Audio is set for 32khz.
    {
        //for 1st 5/6 DIF seq.
        AAUXSRC_SD_PAL,                // DWORD dwDVAAuxSrc;
        AAUXSRCCTL_DEFAULT,            // DWORD dwDVAAuxCtl;
        // for 2nd  5/6 DIF seq.
        AAUXSRC_SD_PAL | AAUXSRC_AMODE_F, // DWORD dwDVAAuxSrc1;
        AAUXSRCCTL_DEFAULT,            // DWORD dwDVAAuxCtl1;
        //for video information
        VAUXSRC_DEFAULT | AUXSRC_PAL | AUXSRC_STYPE_SD,  // DWORD dwDVVAuxSrc;
        VAUXSRCCTL_DEFAULT_ETS,        // DWORD dwDVVAuxCtl;
        0,                             // DWORD dwDVReserved[2];
        0,                             //
    },
    // AVCPRECONNECTINFO
    {
     0,   // Device ID
     0,   // Subunit address
     0,   // Subunit Plug number
     0,   // Data Flow
     0,   // Flag/Plug Handle
     0,   // UnitPlugNumber
    },
};

#endif

// SD DV IAV NTSC Stream
KS_DATARANGE_DVVIDEO 
SDDV_IavNtscStream =
{
    // KSDATARANGE
    {
        sizeof (KS_DATARANGE_DVVIDEO), // FormatSize
        0,                             // Flags
        FRAME_SIZE_SD_DVCR_NTSC,       // SampleSize
        0,                             // Reserved
        STATIC_KSDATAFORMAT_TYPE_INTERLEAVED,
        STATIC_KSDATAFORMAT_SUBTYPE_DVSD,
        STATIC_KSDATAFORMAT_SPECIFIER_DVINFO, // DV to DShow filter connection
    },

    // DVINFO
    // Note: audio is set for 32khz
    {
        //for 1st 5/6 DIF seq.
        AAUXSRC_SD_NTSC,               // DWORD dwDVAAuxSrc;
        AAUXSRCCTL_DEFAULT,            // DWORD dwDVAAuxCtl;
        // for 2nd  5/6 DIF seq.
        AAUXSRC_SD_NTSC | AAUXSRC_AMODE_F, // DWORD dwDVAAuxSrc1;
        AAUXSRCCTL_DEFAULT,            // DWORD dwDVAAuxCtl1;
        //for video information
        VAUXSRC_DEFAULT | AUXSRC_NTSC | AUXSRC_STYPE_SD, // DWORD dwDVVAuxSrc;
        VAUXSRCCTL_DEFAULT_EIA,        // DWORD dwDVVAuxCtl;
        0,                             // DWORD dwDVReserved[2];
        0,                             //
    },
};

// SDL DV IAV PAL Stream
KS_DATARANGE_DVVIDEO 
SDDV_IavPalStream =
{
    // KSDATARANGE
    {
        sizeof (KS_DATARANGE_DVVIDEO), // FormatSize
        0,                             // Flags
        FRAME_SIZE_SD_DVCR_PAL,        // SampleSize
        0,                             // Reserved
        STATIC_KSDATAFORMAT_TYPE_INTERLEAVED, 
        STATIC_KSDATAFORMAT_SUBTYPE_DVSD,
        STATIC_KSDATAFORMAT_SPECIFIER_DVINFO, // DV to DShow filter connection
    },
    
    // DVINFO
    // Note: Audio is set for 32khz.
    {
        //for 1st 5/6 DIF seq.
        AAUXSRC_SD_PAL,                // DWORD dwDVAAuxSrc;
        AAUXSRCCTL_DEFAULT,            // DWORD dwDVAAuxCtl;
        // for 2nd  5/6 DIF seq.
        AAUXSRC_SD_PAL | AAUXSRC_AMODE_F, // DWORD dwDVAAuxSrc1;
        AAUXSRCCTL_DEFAULT,            // DWORD dwDVAAuxCtl1;
        //for video information
        VAUXSRC_DEFAULT | AUXSRC_PAL | AUXSRC_STYPE_SD,  // DWORD dwDVVAuxSrc;
        VAUXSRCCTL_DEFAULT_ETS,        // DWORD dwDVVAuxCtl;
        0,                             // DWORD dwDVReserved[2];
        0,                             //
    },
};


#ifdef MSDV_SUPPORT_SDL_DVCR

// SDL DV IAV NTSC Stream
KS_DATARANGE_DVVIDEO SDLDV_IavNtscStream =
{
    // KSDATARANGE
    {
        sizeof (KS_DATARANGE_DVVIDEO), // FormatSize
        0,                             // Flags
        FRAME_SIZE_SDL_DVCR_NTSC,      // SampleSize
        0,                             // Reserved
        STATIC_KSDATAFORMAT_TYPE_INTERLEAVED,
        STATIC_KSDATAFORMAT_SUBTYPE_DVSL,
        STATIC_KSDATAFORMAT_SPECIFIER_DVINFO, 
    },

    // DVINFO
    // Note: audio is set for 32khz
    {
        //for 1st 5/6 DIF seq.
        AAUXSRC_SDL_NTSC,              // DWORD dwDVAAuxSrc;
        AAUXSRCCTL_DEFAULT,            // DWORD dwDVAAuxCtl;
        // for 2nd  5/6 DIF seq; SDL only have 5 dif seqs..
        0x0,                           // DWORD dwDVAAuxSrc1; 
        0x0,                           // DWORD dwDVAAuxCtl1;
        //for video information
        VAUXSRC_DEFAULT | AUXSRC_NTSC | AUXSRC_STYPE_SDL,  // DWORD dwDVVAuxSrc;
        VAUXSRCCTL_DEFAULT_EIA,        // DWORD dwDVVAuxCtl;
        0,                             // DWORD dwDVReserved[2];
        0,                             //
    },
};


// SDL DV VidOnly NTSC Stream
KS_DATARANGE_DVVIDEO SDLDV_IavPalStream =
{
    // KSDATARANGE
    {
        sizeof (KS_DATARANGE_DVVIDEO), // FormatSize
        0,                             // Flags
        FRAME_SIZE_SDL_DVCR_PAL,       // SampleSize
        0,                             // Reserved
        STATIC_KSDATAFORMAT_TYPE_INTERLEAVED, 
        STATIC_KSDATAFORMAT_SUBTYPE_DVSL,
        STATIC_KSDATAFORMAT_SPECIFIER_DVINFO, 
    },
    
    // DVINFO
    // Note: Audio is set for 32khz.
    {
        //for 1st 5/6 DIF seq.
        AAUXSRC_SDL_PAL,               // DWORD dwDVAAuxSrc;
        AAUXSRCCTL_DEFAULT,            // DWORD dwDVAAuxCtl;
        // for 2nd  5/6 DIF seq; SDL only have 5 dif seqs..
        0x0,                           // DWORD dwDVAAuxSrc1; 
        0x0,                           // DWORD dwDVAAuxCtl1;
        //for video information
        VAUXSRC_DEFAULT | AUXSRC_PAL | AUXSRC_STYPE_SDL,  // DWORD dwDVVAuxSrc;
        VAUXSRCCTL_DEFAULT_ETS,        // DWORD dwDVVAuxCtl;
        0,                             // DWORD dwDVReserved[2];
        0,                             //
    },
};
#endif // MSDV_SUPPORT_SDL_DVCR


//
// A device cannot support all these formats at the same time.  All 
// formats are advertise since the "current format" of the device can 
// dynamically changing (NTSC/PAL or SD/SDL); however, duraing data 
// intersection and stram opening, only the currently support format 
// will be accepted.
//

PKSDATAFORMAT DVCRStream0Formats[] = 
{
    (PKSDATAFORMAT) &SDDV_VidOnlyNTSCStream,
    (PKSDATAFORMAT) &SDDV_VidOnlyPALStream,
#ifdef MSDV_SUPPORT_SDL_DVCR
    (PKSDATAFORMAT) &SDLDV_VidOnlyNTSCStream,
    (PKSDATAFORMAT) &SDLDV_VidOnlyPALStream,
#endif
};

#define NUM_DVCR_STREAM0_FORMATS  (SIZEOF_ARRAY(DVCRStream0Formats))

PKSDATAFORMAT DVCRStream1Formats[] = 
{
#ifdef SUPPORT_NEW_AVC
    (PKSDATAFORMAT) &SDDV_IavNtscStreamAVC,   // DV to DV connection
    (PKSDATAFORMAT) &SDDV_IavPalStreamAVC,    // DV to DV connection
#endif
    (PKSDATAFORMAT) &SDDV_IavNtscStream,
    (PKSDATAFORMAT) &SDDV_IavPalStream,
#ifdef MSDV_SUPPORT_SDL_DVCR
    (PKSDATAFORMAT) &SDLDV_IavNtscStream,
    (PKSDATAFORMAT) &SDLDV_IavPalStream,
#endif
};

#define NUM_DVCR_STREAM1_FORMATS  (SIZEOF_ARRAY(DVCRStream1Formats))


//---------------------------------------------------------------------------
// Create an array that holds the list of all of the streams supported
//---------------------------------------------------------------------------

// If the minidriver does not specify a medium, 
// the class driver uses the KSMEDIUMSETID_Standard, 
// KSMEDIUM_TYPE_ANYINSTANCE medium as the default. 

KSPIN_MEDIUM DVVidonlyMediums[] =
{
    { STATIC_KSMEDIUMSETID_Standard,     0, 0 },  
};
#define NUM_VIDONLY_MEDIUMS (SIZEOF_ARRAY(DVVidonlyMediums))

KSPIN_MEDIUM DVIavMediums[] =
{
#ifdef SUPPORT_NEW_AVC
    { STATIC_KSMEDIUMSETID_1394SerialBus, 1394, 0 },  // ID=1394 (?); Flag=?
#endif
    { STATIC_KSMEDIUMSETID_Standard,      0, 0 },
};
#define NUM_IAV_MEDIUMS (SIZEOF_ARRAY(DVIavMediums))


static GUID guidPinCategoryCapture  = {STATIC_PINNAME_VIDEO_CAPTURE};

static GUID guidPinNameDVVidOutput  = {STATIC_PINNAME_DV_VID_OUTPUT};
static GUID guidPinNameDVAVOutput   = {STATIC_PINNAME_DV_AV_OUTPUT};
static GUID guidPinNameDVAVInput    = {STATIC_PINNAME_DV_AV_INPUT};


ALL_STREAM_INFO DVStreams [] = 
{
    // -----------------------------------------------------------------
    // Stream 0, DV coming from the camcorder
    // -----------------------------------------------------------------
    {
        // HW_STREAM_INFORMATION -------------------------------------------
        {
        1,                                              // NumberOfPossibleInstances
        KSPIN_DATAFLOW_OUT,                             // DataFlow
        TRUE,                                           // DataAccessible
        NUM_DVCR_STREAM0_FORMATS,                       // NumberOfFormatArrayEntries
        DVCRStream0Formats,                             // StreamFormatsArray
        0,                                              // ClassReserved[0]
        0,                                              // ClassReserved[1]
        0,                                              // ClassReserved[2]
        0,                                              // ClassReserved[3]
        NUMBER_VIDEO_STREAM_PROPERTIES,                 // NumStreamPropArrayEntries
        VideoStreamProperties,                          // StreamPropertiesArray
        NUMBER_STREAM_EVENTS_OUT_PIN,                   // NumStreamEventArrayEntries
        StreamEventsOutPin,                             // StreamEventsArray
        &guidPinCategoryCapture,                        // Category
        &guidPinNameDVVidOutput,                        // Name
        NUM_VIDONLY_MEDIUMS,                            // Mediums count
        DVVidonlyMediums,                               // Mediums
        FALSE,                                          // BridgeStream
        0,                                              // Reserved[0]
        0,                                              // Reserved[1]
        },

        // HW_STREAM_OBJECT ------------------------------------------------
        {
        sizeof(HW_STREAM_OBJECT),
        0,                                              // StreamNumber
        0,                                              // HwStreamExtension
        DVRcvDataPacket,                                // ReceiveDataPacket
        DVRcvControlPacket,                             // ReceiveControlPacket
        {
            (PHW_CLOCK_FUNCTION) StreamClockRtn,        // HW_CLOCK_OBJECT.HWClockFunction
            CLOCK_SUPPORT_CAN_RETURN_STREAM_TIME,       // HW_CLOCK_OBJECT.ClockSupportFlags
            0,                                          // HW_CLOCK_OBJECT.Reserved[0]
            0,                                          // HW_CLOCK_OBJECT.Reserved[1]
        },
        FALSE,                                          // Dma
        FALSE,                                          // Pio
        0,                                              // HwDeviceExtension
        sizeof(KS_FRAME_INFO),                          // StreamHeaderMediaSpecific
        0,                                              // StreamHeaderWorkspace 
        FALSE,                                          // Allocator 
        DVEventHandler,                                 // HwEventRoutine
        0,                                              // Reserved[0]
        0,                                              // Reserved[1]
        },
    },

    // -----------------------------------------------------------------
    // Stream 1, DV coming from the camcorder (interleaved format)
    // -----------------------------------------------------------------
    {
        // HW_STREAM_INFORMATION -------------------------------------------
        {
        1,                                              // NumberOfPossibleInstances
        KSPIN_DATAFLOW_OUT,                             // DataFlow
        TRUE,                                           // DataAccessible
        NUM_DVCR_STREAM1_FORMATS,                       // NumberOfFormatArrayEntries
        DVCRStream1Formats,                             // StreamFormatsArrayf
        0,                                              // ClassReserved[0]
        0,                                              // ClassReserved[1]
        0,                                              // ClassReserved[2]
        0,                                              // ClassReserved[3]
        NUMBER_VIDEO_STREAM_PROPERTIES,                 // NumStreamPropArrayEntries
        VideoStreamProperties,                          // StreamPropertiesArray
        NUMBER_STREAM_EVENTS_OUT_PIN,                   // NumStreamEventArrayEntries
        StreamEventsOutPin,                             // StreamEventsArray
        &guidPinCategoryCapture,                        // Category
        &guidPinNameDVAVOutput,                         // Name
        NUM_IAV_MEDIUMS,                                // Mediums count
        DVIavMediums,                                   // Mediums
        FALSE,                                          // BridgeStream
        0,                                              // Reserved[0]
        0,                                              // Reserved[1]
        },

        // HW_STREAM_OBJECT ------------------------------------------------
        {
        sizeof(HW_STREAM_OBJECT),
        1,                                              // StreamNumber
        0,                                              // HwStreamExtension
        DVRcvDataPacket,                                // ReceiveDataPacket
        DVRcvControlPacket,                             // ReceiveControlPacket
        {
            (PHW_CLOCK_FUNCTION) StreamClockRtn,        // HW_CLOCK_OBJECT.HWClockFunction
            CLOCK_SUPPORT_CAN_RETURN_STREAM_TIME,       // HW_CLOCK_OBJECT.ClockSupportFlags
            0,                                          // HW_CLOCK_OBJECT.Reserved[0]
            0,                                          // HW_CLOCK_OBJECT.Reserved[1]
        },
        FALSE,                                          // Dma
        FALSE,                                          // Pio
        0,                                              // HwDeviceExtension
        0,                                              // StreamHeaderMediaSpecific
        0,                                              // StreamHeaderWorkspace 
        FALSE,                                          // Allocator 
        DVEventHandler,                                 // HwEventRoutine
        0,                                              // Reserved[0]
        0,                                              // Reserved[1]
        },    
    },
 

    // -----------------------------------------------------------------
    // Stream 2, DV flows out of the adapter (interleaved)
    // -----------------------------------------------------------------
    {
        // HW_STREAM_INFORMATION -------------------------------------------
        {
        1,                                              // NumberOfPossibleInstances
        KSPIN_DATAFLOW_IN,                              // DataFlow
        TRUE,                                           // DataAccessible
        NUM_DVCR_STREAM1_FORMATS,                       // NumberOfFormatArrayEntries
        DVCRStream1Formats,                             // StreamFormatsArray
        0,                                              // ClassReserved[0]
        0,                                              // ClassReserved[1]
        0,                                              // ClassReserved[2]
        0,                                              // ClassReserved[3]
        NUMBER_VIDEO_STREAM_PROPERTIES_INPIN,           // NumStreamPropArrayEntries
        VideoStreamPropertiesInPin,                     // StreamPropertiesArray
        NUMBER_STREAM_EVENTS_IN_PIN,                    // NumStreamEventArrayEntries
        StreamEventsInPin,                              // StreamEventsArray
        NULL,                                           // Category
        &guidPinNameDVAVInput,                          // Name
        NUM_IAV_MEDIUMS,                                // Mediums count
        DVIavMediums,                                   // Mediums
        FALSE,                                          // BridgeStream
        0,                                              // Reserved[0]
        0,                                              // Reserved[1]
        },

        // HW_STREAM_OBJECT ------------------------------------------------
        {
        sizeof( HW_STREAM_OBJECT ),
        2,                                              // StreamNumber
        0,                                              // HwStreamExtension
        DVRcvDataPacket,                                // ReceiveDataPacket
        DVRcvControlPacket,                             // ReceiveControlPacket
        {
            (PHW_CLOCK_FUNCTION) StreamClockRtn,        // HW_CLOCK_OBJECT.HWClockFunction
            CLOCK_SUPPORT_CAN_RETURN_STREAM_TIME,       // HW_CLOCK_OBJECT.ClockSupportFlags
            0,                                          // HW_CLOCK_OBJECT.Reserved[0]
            0,                                          // HW_CLOCK_OBJECT.Reserved[1]
        },
        FALSE,                                          // Dma
        FALSE,                                          // Pio
        0,                                              // HwDeviceExtension
        0,                                              // StreamHeaderMediaSpecific
        0,                                              // StreamHeaderWorkspace 
#ifdef SUPPORT_NEW_AVC
        // Testing: Input pin as the allocator.
        TRUE,                                           // Allocator
#else
        FALSE,                                          // Allocator  
#endif
        DVEventHandler,                                 // HwEventRoutine
        0,                                              // Reserved[0]
        0,                                              // Reserved[1]
        }
    }
};

#define DV_STREAM_COUNT        (SIZEOF_ARRAY(DVStreams))


#endif  // _DVSTRM_INC
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\drivers\wdm\capture\mini\mstape\mstpguts.c ===
/*++

Copyright (C) Microsoft Corporation, 1999 - 2000  

Module Name:

    MSTpGuts.c

Abstract:

    Main service functions.

Last changed by:
    
    Author:      Yee J. Wu

Environment:

    Kernel mode only

Revision History:

    $Revision::                    $
    $Date::                        $

--*/

#include "strmini.h"
#include "ksmedia.h"

#include "1394.h"
#include "61883.h"
#include "avc.h"

#include "dbg.h"
#include "ksguid.h"

#include "MsTpFmt.h"  // Before MsTpDefs.h
#include "MsTpDef.h"

#include "MsTpGuts.h"
#include "MsTpUtil.h"
#include "MsTpAvc.h"

#include "XPrtDefs.h"
#include "EDevCtrl.h"

// Support MPEG2TS stride data format MPEG2_TRANSPORT_STRIDE
#include "BdaTypes.h" 

//
// Define formats supported
//
#include "strmdata.h"


NTSTATUS
AVCTapeGetDevInfo(
    IN PDVCR_EXTENSION  pDevExt,
    IN PAV_61883_REQUEST  pAVReq
    );
VOID 
AVCTapeIniStrmExt(
    PHW_STREAM_OBJECT  pStrmObject,
    PSTREAMEX          pStrmExt,
    PDVCR_EXTENSION    pDevExt,
    PSTREAM_INFO_AND_OBJ   pStream
    );
NTSTATUS 
DVStreamGetConnectionProperty (
    PDVCR_EXTENSION pDevExt,
    PSTREAM_PROPERTY_DESCRIPTOR pSPD,
    PULONG pulActualBytesTransferred
    );
NTSTATUS
DVGetDroppedFramesProperty(  
    PDVCR_EXTENSION pDevExt,
    PSTREAMEX       pStrmExt,
    PSTREAM_PROPERTY_DESCRIPTOR pSPD,
    PULONG pulBytesTransferred
    );

#if 0  // Enable later
#ifdef ALLOC_PRAGMA   
     #pragma alloc_text(PAGE, AVCTapeGetDevInfo)
     #pragma alloc_text(PAGE, AVCTapeInitialize)
     #pragma alloc_text(PAGE, AVCTapeGetStreamInfo)
     #pragma alloc_text(PAGE, AVCTapeVerifyDataFormat)
     #pragma alloc_text(PAGE, AVCTapeGetDataIntersection)
     #pragma alloc_text(PAGE, AVCTapeIniStrmExt)
     #pragma alloc_text(PAGE, AVCTapeOpenStream)
     #pragma alloc_text(PAGE, AVCTapeCloseStream)
     #pragma alloc_text(PAGE, DVChangePower)
     #pragma alloc_text(PAGE, AVCTapeSurpriseRemoval)
     #pragma alloc_text(PAGE, AVCTapeProcessPnPBusReset)
     #pragma alloc_text(PAGE, AVCTapeUninitialize)

     #pragma alloc_text(PAGE, DVStreamGetConnectionProperty)
     #pragma alloc_text(PAGE, DVGetDroppedFramesProperty)
     #pragma alloc_text(PAGE, DVGetStreamProperty)
     #pragma alloc_text(PAGE, DVSetStreamProperty)
     #pragma alloc_text(PAGE, AVCTapeOpenCloseMasterClock)
     #pragma alloc_text(PAGE, AVCTapeIndicateMasterClock)
#endif
#endif



NTSTATUS
AVCStrmReqIrpSynchCR(
    IN PDEVICE_OBJECT   DeviceObject,
    IN PIRP             pIrp,
    IN PKEVENT          Event
    )
{
#if DBG
    if(!NT_SUCCESS(pIrp->IoStatus.Status)) {
        TRACE(TL_FCP_WARNING,("AVCStrmReqIrpSynchCR: pIrp->IoStatus.Status:%x\n", pIrp->IoStatus.Status));
    }
#endif
    KeSetEvent(Event, 0, FALSE);
    return STATUS_MORE_PROCESSING_REQUIRED;
} // AVCStrmReqIrpSynchCR


NTSTATUS
AVCStrmReqSubmitIrpSynch(
    IN PDEVICE_OBJECT DeviceObject,
    IN PIRP  pIrp,
    IN PAVC_STREAM_REQUEST_BLOCK  pAVCStrmReq
    )
{
    NTSTATUS            Status;
    KEVENT              Event;
    PIO_STACK_LOCATION  NextIrpStack;
  

    Status = STATUS_SUCCESS;;

    NextIrpStack = IoGetNextIrpStackLocation(pIrp);
    NextIrpStack->MajorFunction = IRP_MJ_INTERNAL_DEVICE_CONTROL;
    NextIrpStack->Parameters.DeviceIoControl.IoControlCode = IOCTL_AVCSTRM_CLASS;
    NextIrpStack->Parameters.Others.Argument1 = pAVCStrmReq;

    KeInitializeEvent(&Event, NotificationEvent, FALSE);

    IoSetCompletionRoutine( 
        pIrp,
        AVCStrmReqIrpSynchCR,
        &Event,
        TRUE,
        TRUE,
        TRUE
        );

    Status = 
        IoCallDriver(
            DeviceObject,
            pIrp
            );

    if (Status == STATUS_PENDING) {
        
        TRACE(TL_PNP_TRACE,("(AVCStrm) Irp is pending...\n"));
                
        if(KeGetCurrentIrql() < DISPATCH_LEVEL) {
            KeWaitForSingleObject( 
                &Event,
                Executive,
                KernelMode,
                FALSE,
                NULL
                );
            TRACE(TL_PNP_TRACE,("Irp has completed; IoStatus.Status %x\n", pIrp->IoStatus.Status));
            Status = pIrp->IoStatus.Status;  // Final status
  
        }
        else {
            ASSERT(FALSE && "Pending but in DISPATCH_LEVEL!");
            return Status;
        }
    }

    TRACE(TL_PNP_TRACE,("AVCStrmReqSubmitIrpSynch: IoCallDriver, Status:%x\n", Status));

    return Status;
} // AVCStrmReqSubmitIrpSynch


NTSTATUS
AVCReqIrpSynchCR(
    IN PDEVICE_OBJECT   DeviceObject,
    IN PIRP             pIrp,
    IN PKEVENT          Event
    )
{
#if DBG
    if(!NT_SUCCESS(pIrp->IoStatus.Status)) {
        TRACE(TL_PNP_WARNING,("AVCReqIrpSynchCR: pIrp->IoStatus.Status:%x\n", pIrp->IoStatus.Status));
    }
#endif
    KeSetEvent(Event, 0, FALSE);
    return STATUS_MORE_PROCESSING_REQUIRED;
} // AVCReqIrpSynchCR


NTSTATUS
AVCReqSubmitIrpSynch(
    IN PDEVICE_OBJECT DeviceObject,
    IN PIRP  pIrp,
    IN PAVC_MULTIFUNC_IRB  pAvcIrbReq
    )
{
    NTSTATUS            Status;
    KEVENT              Event;
    PIO_STACK_LOCATION  NextIrpStack;
  

    Status = STATUS_SUCCESS;;

    NextIrpStack = IoGetNextIrpStackLocation(pIrp);
    NextIrpStack->MajorFunction = IRP_MJ_INTERNAL_DEVICE_CONTROL;
    NextIrpStack->Parameters.DeviceIoControl.IoControlCode = IOCTL_AVC_CLASS;
    NextIrpStack->Parameters.Others.Argument1 = pAvcIrbReq;

    KeInitializeEvent(&Event, NotificationEvent, FALSE);

    IoSetCompletionRoutine( 
        pIrp,
        AVCReqIrpSynchCR,
        &Event,
        TRUE,
        TRUE,
        TRUE
        );

    Status = 
        IoCallDriver(
            DeviceObject,
            pIrp
            );

    if (Status == STATUS_PENDING) {
        
        TRACE(TL_PNP_TRACE,("(AVC) Irp is pending...\n"));
                
        if(KeGetCurrentIrql() < DISPATCH_LEVEL) {
            KeWaitForSingleObject( 
                &Event,
                Executive,
                KernelMode,
                FALSE,
                NULL
                );
            TRACE(TL_PNP_TRACE,("Irp has completed; IoStatus.Status %x\n", pIrp->IoStatus.Status));
            Status = pIrp->IoStatus.Status;  // Final status
  
        }
        else {
            ASSERT(FALSE && "Pending but in DISPATCH_LEVEL!");
            return Status;
        }
    }

    TRACE(TL_PNP_TRACE,("AVCReqSubmitIrpSynch: IoCallDriver, Status:%x\n", Status));

    return Status;
} // AVCReqSubmitIrpSynch

VOID
DVIniDevExtStruct(
    IN PDVCR_EXTENSION  pDevExt,
    IN PPORT_CONFIGURATION_INFORMATION pConfigInfo    
    )
/*++

Routine Description:

    Initialiaze the device extension structure.

--*/
{
    ULONG            i;


    RtlZeroMemory( pDevExt, sizeof(DVCR_EXTENSION) );

    //
    // Cache what are in ConfigInfo in device extension
    //
    pDevExt->pBusDeviceObject      = pConfigInfo->PhysicalDeviceObject;      // IoCallDriver()
    pDevExt->pPhysicalDeviceObject = pConfigInfo->RealPhysicalDeviceObject;  // Used in PnP API

    //
    // Allow only one stream open at a time to avoid cyclic format
    //
    pDevExt->cndStrmOpen = 0;

    //
    // Serialize in the event of getting two consecutive SRB_OPEN_STREAMs
    //
    KeInitializeMutex( &pDevExt->hMutex, 0);  // Level 0 and in Signal state


    //
    // Initialize our pointer to stream extension
    //
    for (i=0; i<pDevExt->NumOfPins; i++) {
        pDevExt->paStrmExt[i] = NULL;  
    }

    //
    // Bus reset, surprise removal 
    //
    pDevExt->bDevRemoved = FALSE;

    pDevExt->PowerState = PowerDeviceD0;

    //
    // External device control (AV/C commands)
    // 
    KeInitializeSpinLock( &pDevExt->AVCCmdLock );  // To guard the count  

    pDevExt->cntCommandQueued   = 0; // Cmd that is completed its life cycle waiting to be read (most for RAW_AVC's Set/Read model)

    InitializeListHead(&pDevExt->AVCCmdList);      

    // Initialize the list of possible opcode values of the response
    // from a Transport State status or notify command. The first item
    // is the number of values that follow.
    ASSERT(sizeof(pDevExt->TransportModes) == 5);
    pDevExt->TransportModes[0] = 4;
    pDevExt->TransportModes[1] = 0xC1;
    pDevExt->TransportModes[2] = 0xC2;
    pDevExt->TransportModes[3] = 0xC3;
    pDevExt->TransportModes[4] = 0xC4;
}


NTSTATUS
AVCTapeGetDevInfo(
    IN PDVCR_EXTENSION  pDevExt,
    IN PAV_61883_REQUEST  pAVReq
    )
/*++

Routine Description:

    Issue AVC command to determine basic device information and cache them in the device extension.

--*/
{
    NTSTATUS    Status;
    PIRP        pIrp;
    BYTE                   bAvcBuf[MAX_FCP_PAYLOAD_SIZE];  // For issue AV/C command within this module
    PKSPROPERTY_EXTXPORT_S pXPrtProperty;                  // Point to bAvcBuf;
    KSPROPERTY_EXTDEVICE_S XDevProperty;   // External device property

    PAGED_CODE();


    pIrp = IoAllocateIrp(pDevExt->pBusDeviceObject->StackSize, FALSE);
    if(!pIrp) {    
        ASSERT(pIrp && "IoAllocateIrp() failed!");
        return STATUS_INSUFFICIENT_RESOURCES;       
    }


    //
    // The input and output plug arrays are at the end of the device extension
    //
    pDevExt->pDevOutPlugs = (PAVC_DEV_PLUGS) ((PBYTE) pDevExt + sizeof(DVCR_EXTENSION));
    pDevExt->pDevInPlugs  = (PAVC_DEV_PLUGS) ((PBYTE) pDevExt + sizeof(DVCR_EXTENSION) + sizeof(AVC_DEV_PLUGS));


    //
    // Get unit's capabilities indirectly from 61883.sys
    //    Speed
    //

    Status = DVGetUnitCapabilities(pDevExt, pIrp, pAVReq);
    if(!NT_SUCCESS(Status)) {
         TRACE(TL_61883_ERROR,("Av61883_GetUnitCapabilities Failed %x\n", Status));
         IoFreeIrp(pIrp);
         return Status;
    }

    IoFreeIrp(pIrp);

    //
    //  Get current power state.  Turn it on if it's off.
    // 
    Status = DVIssueAVCCommand(pDevExt, AVC_CTYPE_STATUS, DV_GET_POWER_STATE, (PVOID) &XDevProperty);
    TRACE(TL_PNP_WARNING,("GET_POWER_STATE: Status:%x; %s\n", Status, XDevProperty.u.PowerState == ED_POWER_ON ? "PowerON" : "PowerStandby"));

    if(STATUS_SUCCESS == Status) {
  
#define WAIT_SET_POWER         100 // Wait time when set power state; (msec)
#define MAX_SET_POWER_RETRIES    3

        if(    XDevProperty.u.PowerState == ED_POWER_STANDBY
            || XDevProperty.u.PowerState == ED_POWER_OFF
          ) {
            NTSTATUS StatusSetPower;
            LONG lRetries = 0;

            do {
                //
                // Some AVC device, such as D-VHS will return STATUS_DEVICE_DATA_ERROR when
                // this command is issue right after get power state command.  Such device
                // might be slow in response to the AVC command.  Even though wait is not
                // desirable, but it is the only way.
                //
                DVDelayExecutionThread(WAIT_SET_POWER);  // Wait a little
                StatusSetPower = DVIssueAVCCommand(pDevExt, AVC_CTYPE_CONTROL, DV_SET_POWER_STATE_ON, (PVOID) &XDevProperty);
                lRetries++;
                TRACE(TL_PNP_WARNING,("SET_POWER_STATE_ON: (%d) StatusSetPower:%x; Waited (%d msec).\n", lRetries, StatusSetPower, WAIT_SET_POWER));

            } while ( lRetries < MAX_SET_POWER_RETRIES
                   && (   StatusSetPower == STATUS_REQUEST_ABORTED 
                       || StatusSetPower == STATUS_DEVICE_DATA_ERROR
                       || StatusSetPower == STATUS_IO_TIMEOUT
                      ));

            TRACE(TL_PNP_WARNING,("SET_POWER_STATE_ON: StatusSetPower:%x; Retries:%d times\n\n", StatusSetPower, lRetries));
        } 
    } 

    //
    // Subunit_Info : VCR or camera
    //
    DVDelayExecutionThread(DV_AVC_CMD_DELAY_INTER_CMD);
    Status = DVIssueAVCCommand(pDevExt, AVC_CTYPE_STATUS, DV_SUBUNIT_INFO, (PVOID) bAvcBuf);

    if(STATUS_SUCCESS == Status) {
        TRACE(TL_PNP_TRACE,("GetDevInfo: Status %x DV_SUBUNIT_INFO (%x %x %x %x)\n", 
            Status, bAvcBuf[0], bAvcBuf[1], bAvcBuf[2], bAvcBuf[3]));
        //
        // Cache it. We assume max_subunit_ID is 0 and there is a max of 4 entries.
        //
        pDevExt->Subunit_Type[0] = bAvcBuf[0] & AVC_SUBTYPE_MASK;  
        pDevExt->Subunit_Type[1] = bAvcBuf[1] & AVC_SUBTYPE_MASK;
        pDevExt->Subunit_Type[2] = bAvcBuf[2] & AVC_SUBTYPE_MASK;
        pDevExt->Subunit_Type[3] = bAvcBuf[3] & AVC_SUBTYPE_MASK;

        // This is a tape subunit driver so one of the subunit must be a tape subunit.
        if(pDevExt->Subunit_Type[0] != AVC_DEVICE_TAPE_REC && pDevExt->Subunit_Type[1]) {                       
            TRACE(TL_PNP_ERROR,("GetDevInfo:Device not supported: %x, %x; (VCR %x, Camera %x)\n",
                pDevExt->Subunit_Type[0], pDevExt->Subunit_Type[1], AVC_DEVICE_TAPE_REC, AVC_DEVICE_CAMERA));            
            return STATUS_NOT_SUPPORTED;
        }
    } else {
        TRACE(TL_PNP_ERROR,("GetDevInfo: DV_SUBUNIT_INFO failed, Status %x\n", Status));

        if(STATUS_TIMEOUT == Status) {
            TRACE(TL_PNP_WARNING, ("GetDevInfo: Query DV_SUBUNIT_INFO failed. This could be the MediaDecoder box.\n"));
            // Do not fail this.  Making an exception.
        }

        // Has our device gone away?
        if (STATUS_IO_DEVICE_ERROR == Status || STATUS_REQUEST_ABORTED == Status)
            return Status;       

        pDevExt->Subunit_Type[0] = AVC_DEVICE_UNKNOWN;  
        pDevExt->Subunit_Type[1] = AVC_DEVICE_UNKNOWN;
        pDevExt->Subunit_Type[2] = AVC_DEVICE_UNKNOWN;
        pDevExt->Subunit_Type[3] = AVC_DEVICE_UNKNOWN;
    }


    //
    // Medium_Info: MediaPresent, MediaType, RecordInhibit
    //
    pXPrtProperty = (PKSPROPERTY_EXTXPORT_S) bAvcBuf;
    DVDelayExecutionThread(DV_AVC_CMD_DELAY_INTER_CMD);
    Status = DVIssueAVCCommand(pDevExt, AVC_CTYPE_STATUS, VCR_MEDIUM_INFO, (PVOID) pXPrtProperty);

    if(STATUS_SUCCESS == Status) {
        pDevExt->bHasTape  = pXPrtProperty->u.MediumInfo.MediaPresent;
        pDevExt->MediaType = pXPrtProperty->u.MediumInfo.MediaType;
        TRACE(TL_PNP_TRACE,("GetDevInfo: Status %x HasTape %s, VCR_MEDIUM_INFO (%x %x %x %x)\n", 
            Status, pDevExt->bHasTape ? "Yes" : "No", bAvcBuf[0], bAvcBuf[1], bAvcBuf[2], bAvcBuf[3]));
    } else {
        pDevExt->bHasTape = FALSE;
        TRACE(TL_PNP_ERROR,("GetDevInfo: VCR_MEDIUM_INFO failed, Status %x\n", Status));
        // Has our device gone away?
        if (STATUS_IO_DEVICE_ERROR == Status || STATUS_REQUEST_ABORTED == Status)
            return Status;
    }


    //
    // If this is a Panasonic AVC device, we will detect if it is a DVCPro format; 
    // This needs to be called before MediaFormat
    //
    if(pDevExt->ulVendorID == VENDORID_PANASONIC) {
        DVDelayExecutionThread(DV_AVC_CMD_DELAY_INTER_CMD);
        DVGetDevIsItDVCPro(pDevExt);
    }


    //
    // Medium format: NTSC or PAL
    //
    pDevExt->VideoFormatIndex = AVCSTRM_FORMAT_SDDV_NTSC;  // Default
    DVDelayExecutionThread(DV_AVC_CMD_DELAY_INTER_CMD);
    if(!DVGetDevSignalFormat(
        pDevExt,
        KSPIN_DATAFLOW_OUT,
        0)) {
        ASSERT(FALSE && "IN/OUTPUT SIGNAL MODE is not supported; driver abort.");
        return STATUS_NOT_SUPPORTED;
    } else {
        if(pDevExt->VideoFormatIndex != AVCSTRM_FORMAT_SDDV_NTSC && 
           pDevExt->VideoFormatIndex != AVCSTRM_FORMAT_SDDV_PAL  &&
           pDevExt->VideoFormatIndex != AVCSTRM_FORMAT_MPEG2TS
           ) {
            TRACE(TL_PNP_ERROR,("**** Format idx %d not supported by this driver ***\n", pDevExt->VideoFormatIndex));
            ASSERT(pDevExt->VideoFormatIndex == AVCSTRM_FORMAT_SDDV_NTSC || pDevExt->VideoFormatIndex == AVCSTRM_FORMAT_SDDV_PAL);
            return STATUS_NOT_SUPPORTED;
        }
    }

    //
    // Mode of Operation: 0(Undetermined), Camera or VCR
    //
    DVDelayExecutionThread(DV_AVC_CMD_DELAY_INTER_CMD);
    DVGetDevModeOfOperation(
        pDevExt
        );

         
    return STATUS_SUCCESS; // Status;
}

#ifdef SUPPORT_NEW_AVC


HANDLE
AVCTapeGetPlugHandle(
    IN PDVCR_EXTENSION  pDevExt,
    IN ULONG  PlugNum,
    IN KSPIN_DATAFLOW DataFlow
    )
{
    NTSTATUS Status;
    PAV_61883_REQUEST  pAVReq;

    PAGED_CODE();

    Status = STATUS_SUCCESS;

    pAVReq = &pDevExt->AVReq;
    RtlZeroMemory(pAVReq, sizeof(AV_61883_REQUEST));
    INIT_61883_HEADER(pAVReq, Av61883_GetPlugHandle);
    pAVReq->GetPlugHandle.PlugNum = PlugNum;
    pAVReq->GetPlugHandle.hPlug   = 0;
    pAVReq->GetPlugHandle.Type    = DataFlow == KSPIN_DATAFLOW_OUT ? CMP_PlugOut : CMP_PlugIn;

    Status = DVSubmitIrpSynch(pDevExt, pDevExt->pIrpSyncCall, pAVReq);

    if(!NT_SUCCESS(Status)) {
        TRACE(TL_61883_ERROR,("GetPlugHandle: Failed:%x\n", Status));
        ASSERT(NT_SUCCESS(Status));
        pAVReq->GetPlugHandle.hPlug = NULL;
        return NULL;
    }
    else {
        TRACE(TL_61883_TRACE,("hPlug=%x\n", pAVReq->GetPlugHandle.hPlug));
    }

    return pAVReq->GetPlugHandle.hPlug;
}


NTSTATUS
AVCTapeGetPinInfo(
    IN PDVCR_EXTENSION  pDevExt
    )
/*++

Routine Description:

    Acquire pin information from avc.sys.  These information will be used to define data range and 
    then for doing data interssection.

--*/
{
    NTSTATUS Status;
    ULONG  i;
    ULONG PinId;  // Pin number

    Status = STATUS_SUCCESS;

    // Get pin count
    RtlZeroMemory(&pDevExt->AvcMultIrb, sizeof(AVC_MULTIFUNC_IRB));
    pDevExt->AvcMultIrb.Function = AVC_FUNCTION_GET_PIN_COUNT;
    Status = AVCReqSubmitIrpSynch(pDevExt->pBusDeviceObject, pDevExt->pIrpSyncCall, &pDevExt->AvcMultIrb);
    if(!NT_SUCCESS(Status)) {
        TRACE(TL_STRM_ERROR,("GetPinCount Failed:%x\n", Status));
        goto GetPinInfoDone;
    } else {
        TRACE(TL_STRM_TRACE,("There are %d pins\n", pDevExt->AvcMultIrb.PinCount.PinCount));
        if(pDevExt->VideoFormatIndex == AVCSTRM_FORMAT_MPEG2TS) {
            if(pDevExt->AvcMultIrb.PinCount.PinCount > 1) {
                goto GetPinInfoDone;
            }
        } else {
            if(pDevExt->AvcMultIrb.PinCount.PinCount > 3) {
                goto GetPinInfoDone;
            }
        }
        pDevExt->PinCount = pDevExt->AvcMultIrb.PinCount.PinCount;  // <<<
    }

    // Get all pin descriptors
    for(i=0; i<pDevExt->PinCount; i++) {

        // Get a pin descriptor
        RtlZeroMemory(&pDevExt->AvcMultIrb, sizeof(AVC_MULTIFUNC_IRB));
        pDevExt->AvcMultIrb.Function = AVC_FUNCTION_GET_PIN_DESCRIPTOR;
        pDevExt->AvcMultIrb.PinDescriptor.PinId = i; 
        Status = AVCReqSubmitIrpSynch(pDevExt->pBusDeviceObject, pDevExt->pIrpSyncCall, &pDevExt->AvcMultIrb);
        if(!NT_SUCCESS(Status)) {
            TRACE(TL_PNP_ERROR,("GetPinDescriptor Failed:%x\n", Status));
            goto GetPinInfoDone;
        } else {
            // Copy the pDevExt->AvcMultIrb.PinDescriptor.PinDescriptor
            PinId = pDevExt->AvcMultIrb.PinDescriptor.PinId;
            // Anything else ?
        }

        // Get pre connection info
        RtlZeroMemory(&pDevExt->AvcMultIrb, sizeof(AVC_MULTIFUNC_IRB));
        pDevExt->AvcMultIrb.Function = AVC_FUNCTION_GET_CONNECTINFO;
        pDevExt->AvcMultIrb.PinDescriptor.PinId = PinId;
        Status = AVCReqSubmitIrpSynch(pDevExt->pBusDeviceObject, pDevExt->pIrpSyncCall, &pDevExt->AvcMultIrb);
        if(!NT_SUCCESS(Status)) {
            TRACE(TL_PNP_ERROR,("GetPinDescriptor Failed:%x\n", Status));
            goto GetPinInfoDone;
        } else {
            // Cache connectInfo
            if(pDevExt->VideoFormatIndex == AVCSTRM_FORMAT_MPEG2TS) {
                // Check 
                if(pDevExt->AvcMultIrb.PreConnectInfo.ConnectInfo.DataFlow == KSPIN_DATAFLOW_OUT) {
                    MPEG2TStreamOut.ConnectInfo = pDevExt->AvcMultIrb.PreConnectInfo.ConnectInfo;
                } else {
                    MPEG2TStreamIn.ConnectInfo  = pDevExt->AvcMultIrb.PreConnectInfo.ConnectInfo;
                }
            }
            else {
 
                if(pDevExt->AvcMultIrb.PreConnectInfo.ConnectInfo.DataFlow == KSPIN_DATAFLOW_OUT) {
                    DvcrNTSCiavStream.ConnectInfo = pDevExt->AvcMultIrb.PreConnectInfo.ConnectInfo;
                    DvcrPALiavStream.ConnectInfo  = pDevExt->AvcMultIrb.PreConnectInfo.ConnectInfo;
                } else if(pDevExt->AvcMultIrb.PreConnectInfo.ConnectInfo.DataFlow == KSPIN_DATAFLOW_IN) {
                    DvcrNTSCiavStreamIn.ConnectInfo = pDevExt->AvcMultIrb.PreConnectInfo.ConnectInfo;
                    DvcrPALiavStreamIn.ConnectInfo  = pDevExt->AvcMultIrb.PreConnectInfo.ConnectInfo;
                } else {
                    // Error; unexpected;
                    TRACE(TL_PNP_ERROR,("Unexpected index:%d for format:%d\n", i, pDevExt->VideoFormatIndex));
                    // goto GetPinInfoDone;
                }
            }
        }
    }


GetPinInfoDone:

    TRACE(TL_STRM_TRACE,("GetPinInfo exited with ST:%x\n", Status));

    return Status;
}

#endif // SUPPORT_NEW_AVC


NTSTATUS
AVCTapeInitialize(
    IN PDVCR_EXTENSION  pDevExt,
    IN PPORT_CONFIGURATION_INFORMATION pConfigInfo,
    IN PAV_61883_REQUEST  pAVReq
    )
/*++

Routine Description:

    This where we perform the necessary initialization tasks.

--*/

{
    ULONG i;
    NTSTATUS         Status = STATUS_SUCCESS;

    PAGED_CODE();

    //
    // Initialize the device extension structure
    //
    DVIniDevExtStruct(
        pDevExt,
        pConfigInfo
        );

#ifdef READ_CUTOMIZE_REG_VALUES
    //
    // Get values from this device's own registry 
    //
    DVGetPropertyValuesFromRegistry(
        pDevExt
        );
#endif

    // Allocate an Irp for synchronize call
    pDevExt->pIrpSyncCall = IoAllocateIrp(pDevExt->pBusDeviceObject->StackSize, FALSE);
    if(!pDevExt->pIrpSyncCall) {
        ASSERT(pDevExt->pIrpSyncCall && "Allocate Irp failed.\n");
        return STATUS_INSUFFICIENT_RESOURCES;
    }

    //
    // Query device information at the laod time:
    //    Subunit
    //    Unit Info
    //    Mode of operation
    //    NTSC or PAL
    //    Speed
    //
    Status = 
        AVCTapeGetDevInfo(
            pDevExt,
            pAVReq
            );

    if(!NT_SUCCESS(Status)) {
        TRACE(TL_PNP_ERROR,("GetDevInfo failed %x\n", Status));
        ASSERT(NT_SUCCESS(Status) && "AVCTapeGetDevInfo failed");
        goto AbortLoading;
    }


    //
    // Get device's output plug handles and states
    //

    if(pDevExt->pDevOutPlugs->NumPlugs) {
        NTSTATUS StatusPlug;

        TRACE(TL_61883_WARNING,("%d oPCR(s); MaxDataRate:%d (%s)\n", 
            pDevExt->pDevOutPlugs->NumPlugs, 
            pDevExt->pDevOutPlugs->MaxDataRate,
            (pDevExt->pDevOutPlugs->MaxDataRate == CMP_SPEED_S100) ? "S100" :
            (pDevExt->pDevOutPlugs->MaxDataRate == CMP_SPEED_S200) ? "S200" :
            (pDevExt->pDevOutPlugs->MaxDataRate == CMP_SPEED_S400) ? "S400" : "Sxxx"
            ));

        for (i = 0; i < pDevExt->pDevOutPlugs->NumPlugs; i++) {
            if(NT_SUCCESS(
                StatusPlug = AVCDevGetDevPlug( 
                    pDevExt,
                    CMP_PlugOut,
                    i,
                    &pDevExt->pDevOutPlugs->DevPlug[i].hPlug
                    ))) {

                if(NT_SUCCESS(
                    AVCDevGetPlugState(
                    pDevExt,
                    pDevExt->pDevOutPlugs->DevPlug[i].hPlug,
                    &pDevExt->pDevOutPlugs->DevPlug[i].PlugState
                    ))) {
                } else {
                    // 
                    // This is an error if we were told to this many number of plugs;
                    // Set default plug states.
                    //   
                    pDevExt->pDevOutPlugs->DevPlug[i].PlugState.DataRate       = CMP_SPEED_S100;
                    pDevExt->pDevOutPlugs->DevPlug[i].PlugState.Payload        = PCR_PAYLOAD_MPEG2TS_DEF;
                    pDevExt->pDevOutPlugs->DevPlug[i].PlugState.BC_Connections = 0;
                    pDevExt->pDevOutPlugs->DevPlug[i].PlugState.PP_Connections = 0;
                }
            }
            else {
                //
                // If there is a plug, we should be able to get its handle!
                //
                TRACE(TL_61883_ERROR,("GetDevPlug oPlug[%d] failed %x\n", i, StatusPlug));
                ASSERT(NT_SUCCESS(StatusPlug) && "Failed to get oPCR handle from 61883!");
                break;
            }
        }
    }
    else {
        TRACE(TL_61883_WARNING,("Has no oPCR\n"));
    }

    //
    // Get device's input plug handles and states
    //
    if(pDevExt->pDevInPlugs->NumPlugs) {
        NTSTATUS StatusPlug;

        TRACE(TL_61883_WARNING,("%d iPCR(s); MaxDataRate:%d (%s)\n", 
            pDevExt->pDevInPlugs->NumPlugs, 
            pDevExt->pDevInPlugs->MaxDataRate,
            (pDevExt->pDevInPlugs->MaxDataRate == CMP_SPEED_S100) ? "S100" :
            (pDevExt->pDevInPlugs->MaxDataRate == CMP_SPEED_S200) ? "S200" :
            (pDevExt->pDevInPlugs->MaxDataRate == CMP_SPEED_S400) ? "S400" : "Sxxx"
            ));

        for (i = 0; i < pDevExt->pDevInPlugs->NumPlugs; i++) {
            if(NT_SUCCESS(
                StatusPlug = AVCDevGetDevPlug( 
                    pDevExt,
                    CMP_PlugIn,
                    i,
                    &pDevExt->pDevInPlugs->DevPlug[i].hPlug
                    ))) {

                if(NT_SUCCESS(
                    AVCDevGetPlugState(
                    pDevExt,
                    pDevExt->pDevInPlugs->DevPlug[i].hPlug,
                    &pDevExt->pDevInPlugs->DevPlug[i].PlugState
                    ))) {
                } else {
                    // 
                    // This is an error if we were told to this many number of plugs;
                    // Set default plug states.
                    //   
                    pDevExt->pDevInPlugs->DevPlug[i].PlugState.DataRate       = CMP_SPEED_S200;
                    pDevExt->pDevInPlugs->DevPlug[i].PlugState.Payload        = PCR_PAYLOAD_MPEG2TS_DEF;
                    pDevExt->pDevInPlugs->DevPlug[i].PlugState.BC_Connections = 0;
                    pDevExt->pDevInPlugs->DevPlug[i].PlugState.PP_Connections = 0;
                }
            }
            else {
                //
                // If there is a plug, we should be able to get its handle!
                //
                TRACE(TL_61883_ERROR,("GetDevPlug iPlug[%d] failed %x\n", i, StatusPlug));
                ASSERT(NT_SUCCESS(StatusPlug) && "Failed to get iPCR handle from 61883!");
                break;
            }
        }
    }
    else {
        TRACE(TL_61883_WARNING,("Has no iPCR\n"));
    }


#ifdef SUPPORT_LOCAL_PLUGS
    // Create a local output plug.
    pDevExt->OPCR.oPCR.OnLine     = 0;  // We are not online so we cannot be programmed.
    pDevExt->OPCR.oPCR.BCCCounter = 0;
    pDevExt->OPCR.oPCR.PPCCounter = 0;
    pDevExt->OPCR.oPCR.Channel    = 0;

    // Default to MPEG2TS data since MPEg2TS device, like D-VHS,  can initialize connection.
    if(pDevExt->pDevOutPlugs->NumPlugs) {
        //
        // Set PC's oPCR to match device's oPCR[0]
        //
        pDevExt->OPCR.oPCR.DataRate   = 
#if 0
            // Be conservative and use this to match its oPCR[0]'s setting..
            pDevExt->pDevOutPlugs->DevPlug[0].PlugState.DataRate;  // oPCR's data rate <= MPR's MaxDataRate
#else
            // Be aggreessive in conserving BWU, use MaxDataRate.
            pDevExt->pDevOutPlugs->MaxDataRate;                    // Use MPR's MaxDataRate?
#endif
        pDevExt->OPCR.oPCR.OverheadID = PCR_OVERHEAD_ID_MPEG2TS_DEF;  // Default since we do not get this as a plug state
        pDevExt->OPCR.oPCR.Payload    = pDevExt->pDevOutPlugs->DevPlug[0].PlugState.Payload;

    } else {
        pDevExt->OPCR.oPCR.DataRate   = CMP_SPEED_S200;               // Default of D-VHS
        pDevExt->OPCR.oPCR.OverheadID = PCR_OVERHEAD_ID_MPEG2TS_DEF;  // This is just default
        pDevExt->OPCR.oPCR.Payload    = PCR_PAYLOAD_MPEG2TS_DEF;      // Default
    }

    if(!AVCTapeCreateLocalPlug(
        pDevExt,
        &pDevExt->AVReq,
        CMP_PlugOut,
        &pDevExt->OPCR,
        &pDevExt->OutputPCRLocalNum,
        &pDevExt->hOutputPCRLocal)) {
        TRACE(TL_PNP_ERROR,("Create PC oPCR failed!\n"));
        Status = STATUS_INSUFFICIENT_RESOURCES;
        goto AbortLoading;
    }       
    
    // Create a local input plug.
    pDevExt->IPCR.iPCR.OnLine     = 0;  // We are not online so we cannot be programmed.
    pDevExt->IPCR.iPCR.BCCCounter = 0;
    pDevExt->IPCR.iPCR.PPCCounter = 0;
    pDevExt->IPCR.iPCR.Channel    = 0;

    if(!AVCTapeCreateLocalPlug(
        pDevExt,
        &pDevExt->AVReq,
        CMP_PlugIn,
        &pDevExt->IPCR,
        &pDevExt->InputPCRLocalNum,
        &pDevExt->hInputPCRLocal)) {

        TRACE(TL_PNP_ERROR,("Create PC iPCR failed!\n"));

        // Delete oPCR created
        if(!AVCTapeDeleteLocalPlug(
            pDevExt,
            &pDevExt->AVReq,
            &pDevExt->OutputPCRLocalNum,
            &pDevExt->hOutputPCRLocal)) {
            TRACE(TL_PNP_ERROR,("Delete PC oPCR failed!\n"));        
        } 

        Status = STATUS_INSUFFICIENT_RESOURCES;
        goto AbortLoading;
    } 
#endif

#ifdef SUPPORT_NEW_AVC  // Initialize device

    //
    // Get plug handle of this device;
    // BUGBUG: For now, assume there is one pair of input and output plugs
    //
    pDevExt->hPlugLocalIn  = AVCTapeGetPlugHandle(pDevExt, 0, KSPIN_DATAFLOW_IN);
    pDevExt->hPlugLocalOut = AVCTapeGetPlugHandle(pDevExt, 0, KSPIN_DATAFLOW_OUT);


    //
    // Get Pin information for connection purpose
    //
    Status = AVCTapeGetPinInfo(pDevExt);
    if(!NT_SUCCESS(Status)) {
        TRACE(TL_PNP_ERROR,("GetPinInfo failed %x\n", Status));
        ASSERT(NT_SUCCESS(Status) && "AVCTapeGetPinInfo failed");
        goto AbortLoading;
    }
#endif
    //
    // Can customize the FormatInfoTable here!
    //
    switch(pDevExt->VideoFormatIndex) {
    case AVCSTRM_FORMAT_SDDV_NTSC:
    case AVCSTRM_FORMAT_SDDV_PAL:
    case AVCSTRM_FORMAT_HDDV_NTSC:
    case AVCSTRM_FORMAT_HDDV_PAL:
    case AVCSTRM_FORMAT_SDLDV_NTSC:
    case AVCSTRM_FORMAT_SDLDV_PAL:
        pDevExt->NumOfPins = DV_STREAM_COUNT;

        AVCStrmFormatInfoTable[pDevExt->VideoFormatIndex].cipHdr1.DBS = CIP_DBS_SDDV;
        AVCStrmFormatInfoTable[pDevExt->VideoFormatIndex].cipHdr1.FN  = CIP_FN_DV;
        AVCStrmFormatInfoTable[pDevExt->VideoFormatIndex].cipHdr1.QPC = CIP_QPC_DV;
        AVCStrmFormatInfoTable[pDevExt->VideoFormatIndex].cipHdr1.SPH = CIP_SPH_DV;

        AVCStrmFormatInfoTable[pDevExt->VideoFormatIndex].cipHdr2.FMT    = CIP_FMT_DV;
        AVCStrmFormatInfoTable[pDevExt->VideoFormatIndex].cipHdr2.STYPE  = CIP_STYPE_DV;
        break;

    case AVCSTRM_FORMAT_MPEG2TS:
        pDevExt->NumOfPins = MPEG_STREAM_COUNT;

        AVCStrmFormatInfoTable[pDevExt->VideoFormatIndex].cipHdr1.DBS = CIP_DBS_MPEG;
        AVCStrmFormatInfoTable[pDevExt->VideoFormatIndex].cipHdr1.FN  = CIP_FN_MPEG;
        AVCStrmFormatInfoTable[pDevExt->VideoFormatIndex].cipHdr1.QPC = CIP_QPC_MPEG;
        AVCStrmFormatInfoTable[pDevExt->VideoFormatIndex].cipHdr1.SPH = CIP_SPH_MPEG;

        AVCStrmFormatInfoTable[pDevExt->VideoFormatIndex].cipHdr2.FMT   = CIP_FMT_MPEG;
        // AVCStrmFormatInfoTable[pDevExt->VideoFormatIndex].cipHdr2.F5060_OR_TSF = CIP_60_FIELDS;
        break;
    default:
        Status = STATUS_NOT_SUPPORTED;
        goto AbortLoading;
        break;
    }

    switch(pDevExt->VideoFormatIndex) {
    case AVCSTRM_FORMAT_SDDV_NTSC:
    case AVCSTRM_FORMAT_HDDV_NTSC:
    case AVCSTRM_FORMAT_SDLDV_NTSC:
        AVCStrmFormatInfoTable[pDevExt->VideoFormatIndex].cipHdr2.F5060_OR_TSF = CIP_60_FIELDS;
        break;
    case AVCSTRM_FORMAT_SDDV_PAL:
    case AVCSTRM_FORMAT_HDDV_PAL:
    case AVCSTRM_FORMAT_SDLDV_PAL:
        AVCStrmFormatInfoTable[pDevExt->VideoFormatIndex].cipHdr2.F5060_OR_TSF = CIP_50_FIELDS;
        break;
    }


    //
    // Note: Must do ExAllocatePool after DVIniDevExtStruct() since ->pStreamInfoObject is initialized.
    // Since the format that this driver support is known when this driver is known,'
    // the stream information table need to be custonmized.  Make a copy and customized it.
    //

    //
    // Set the size of the stream inforamtion structure that we returned in SRB_GET_STREAM_INFO
    //
        
    pDevExt->pStreamInfoObject = (STREAM_INFO_AND_OBJ *) 
        ExAllocatePool(NonPagedPool, sizeof(STREAM_INFO_AND_OBJ) * pDevExt->NumOfPins);

    if(!pDevExt->pStreamInfoObject) {
        ASSERT(pDevExt->pStreamInfoObject && "STATUS_INSUFFICIENT_RESOURCES");
        Status = STATUS_INSUFFICIENT_RESOURCES;
        goto AbortLoading;
    }
        
    pConfigInfo->StreamDescriptorSize = 
        (pDevExt->NumOfPins * sizeof(HW_STREAM_INFORMATION)) +      // number of stream descriptors
        sizeof(HW_STREAM_HEADER);                                   // and 1 stream header

    TRACE(TL_PNP_TRACE,("pStreamInfoObject:%x; StreamDescriptorSize:%d\n", pDevExt->pStreamInfoObject, pConfigInfo->StreamDescriptorSize ));

    // Make a copy of the default stream information
    for(i = 0; i < pDevExt->NumOfPins; i++ ) {
        if(pDevExt->VideoFormatIndex == AVCSTRM_FORMAT_MPEG2TS)
           pDevExt->pStreamInfoObject[i] = MPEGStreams[i];
        else
           pDevExt->pStreamInfoObject[i] = DVStreams[i];
    }

    switch(pDevExt->VideoFormatIndex) {
    case AVCSTRM_FORMAT_SDDV_NTSC:
    case AVCSTRM_FORMAT_SDDV_PAL:
        // Set AUDIO AUX to reflect: NTSC/PAL, consumer DV or DVCPRO
        if(pDevExt->bDVCPro) {
            // Note: there is no DVInfo in VideoInfoHeader but there is for the iAV streams.
            DvcrPALiavStream.DVVideoInfo.dwDVAAuxSrc  = PAL_DVAAuxSrc_DVCPRO;
            DvcrNTSCiavStream.DVVideoInfo.dwDVAAuxSrc = NTSC_DVAAuxSrc_DVCPRO;
        } else {
            DvcrPALiavStream.DVVideoInfo.dwDVAAuxSrc  = PAL_DVAAuxSrc;
            DvcrNTSCiavStream.DVVideoInfo.dwDVAAuxSrc = NTSC_DVAAuxSrc;
        }
    }

    TRACE(TL_PNP_WARNING,("#### %s:%s:%s PhyDO %x, BusDO %x, DevExt %x, FrmSz %d; StrmIf %d\n", 
        pDevExt->ulDevType == ED_DEVTYPE_VCR ? "DVCR" : pDevExt->ulDevType == ED_DEVTYPE_CAMERA ? "Camera" : "Tuner?",
        pDevExt->VideoFormatIndex == AVCSTRM_FORMAT_SDDV_NTSC ? "SD:NTSC" : pDevExt->VideoFormatIndex == AVCSTRM_FORMAT_SDDV_PAL ? "PAL" : "MPEG_TS?",
        (pDevExt->ulDevType == ED_DEVTYPE_VCR && pDevExt->pDevInPlugs->NumPlugs > 0) ? "CanRec" : "NotRec",
        pDevExt->pPhysicalDeviceObject, 
        pDevExt->pBusDeviceObject, 
        pDevExt,  
        AVCStrmFormatInfoTable[pDevExt->VideoFormatIndex].FrameSize,
        pConfigInfo->StreamDescriptorSize
        ));
    
    return STATUS_SUCCESS;

AbortLoading:

    DvFreeTextualString(pDevExt, &pDevExt->UnitIDs);
    return Status;
}


NTSTATUS
AVCTapeInitializeCompleted(
    IN PDVCR_EXTENSION  pDevExt
    )
/*++

Routine Description:

    This where we perform the necessary initialization tasks.

--*/

{
    PAGED_CODE();


#ifdef SUPPORT_ACCESS_DEVICE_INTERFACE
    //
    // Access to the device's interface section
    //
    DVAccessDeviceInterface(pDevExt, NUMBER_OF_DV_CATEGORIES, DVCategories);
#endif

    return STATUS_SUCCESS;
}

NTSTATUS
AVCTapeGetStreamInfo(
    IN PDVCR_EXTENSION        pDevExt,
    IN ULONG                  ulBytesToTransfer, 
    IN PHW_STREAM_HEADER      pStreamHeader,       
    IN PHW_STREAM_INFORMATION pStreamInfo
    )

/*++

Routine Description:

    Returns the information of all streams that are supported by the driver

--*/

{
    ULONG i;

    PAGED_CODE();


    //
    // Make sure we have enough space to return our stream informations
    //
    if(ulBytesToTransfer < sizeof (HW_STREAM_HEADER) + sizeof(HW_STREAM_INFORMATION) * pDevExt->NumOfPins ) {
        TRACE(TL_PNP_ERROR,("GetStrmInfo: ulBytesToTransfer %d ?= %d\n",  
            ulBytesToTransfer, sizeof(HW_STREAM_HEADER) + sizeof(HW_STREAM_INFORMATION) * pDevExt->NumOfPins ));
        ASSERT(ulBytesToTransfer >= sizeof(HW_STREAM_HEADER) + sizeof(HW_STREAM_INFORMATION) * pDevExt->NumOfPins );

        return STATUS_INVALID_PARAMETER;
    }

    //
    // Initialize stream header:
    //   Device properties
    //   Streams
    //

    RtlZeroMemory(pStreamHeader, sizeof(HW_STREAM_HEADER));

    pStreamHeader->NumberOfStreams           = pDevExt->NumOfPins;
    pStreamHeader->SizeOfHwStreamInformation = sizeof(HW_STREAM_INFORMATION);

    pStreamHeader->NumDevPropArrayEntries    = NUMBER_VIDEO_DEVICE_PROPERTIES;
    pStreamHeader->DevicePropertiesArray     = (PKSPROPERTY_SET) VideoDeviceProperties;

    pStreamHeader->NumDevEventArrayEntries   = NUMBER_VIDEO_DEVICE_EVENTS;
    pStreamHeader->DeviceEventsArray         = (PKSEVENT_SET) VideoDeviceEvents;


    TRACE(TL_PNP_TRACE,("GetStreamInfo: StreamPropEntries %d, DevicePropEntries %d\n",
        pStreamHeader->NumberOfStreams, pStreamHeader->NumDevPropArrayEntries));


    //
    // Initialize the stream structure.
    //
    ASSERT(pDevExt->pStreamInfoObject);
    for( i = 0; i < pDevExt->NumOfPins; i++ )
        *pStreamInfo++ = pDevExt->pStreamInfoObject[i].hwStreamInfo;

    //
    //
    // store a pointer to the topology for the device
    //        
    if(pDevExt->VideoFormatIndex == AVCSTRM_FORMAT_MPEG2TS)
        pStreamHeader->Topology = &MPEG2TSTopology;
    else
        pStreamHeader->Topology = &DVTopology;



    return STATUS_SUCCESS;
}


BOOL 
AVCTapeVerifyDataFormat(
    IN  ULONG  NumOfPins,
    PKSDATAFORMAT  pKSDataFormatToVerify, 
    ULONG          StreamNumber,
    ULONG          ulSupportedFrameSize,
    STREAM_INFO_AND_OBJ * pStreamInfoObject 
    )
/*++

Routine Description:

    Checks the validity of a format request by walking through the array of 
    supported KSDATA_RANGEs for a given stream.

Arguments:

     pKSDataFormat - pointer of a KS_DATAFORMAT_VIDEOINFOHEADER structure.
     StreamNumber - index of the stream being queried / opened.

Return Value:

     TRUE if the format is supported
     FALSE if the format cannot be suppored

--*/
{
    PKSDATAFORMAT  *pAvailableFormats;
    int            NumberOfFormatArrayEntries;
    int            j;
     
    PAGED_CODE();

    //
    // Make sure the stream index is valid
    //
    if(StreamNumber >= NumOfPins) {
        return FALSE;
    }

    //
    // How many formats does this data range support?
    //
    NumberOfFormatArrayEntries = pStreamInfoObject[StreamNumber].hwStreamInfo.NumberOfFormatArrayEntries;

    //
    // Get the pointer to the array of available formats
    //
    pAvailableFormats = pStreamInfoObject[StreamNumber].hwStreamInfo.StreamFormatsArray;
    
    
    //
    // Walk the array, searching for a match
    //
    for (j = 0; j < NumberOfFormatArrayEntries; j++, pAvailableFormats++) {
        
        if (!DVCmpGUIDsAndFormatSize(
                 pKSDataFormatToVerify, 
                 *pAvailableFormats,
                 FALSE /* CompareFormatSize */ )) {
            continue;
        }

        //
        // Additional verification test
        //
        if(IsEqualGUID (&pKSDataFormatToVerify->Specifier, &KSDATAFORMAT_SPECIFIER_VIDEOINFO)) {
            // Make sure 
            if( ((PKS_DATAFORMAT_VIDEOINFOHEADER)pKSDataFormatToVerify)->VideoInfoHeader.bmiHeader.biSizeImage !=
                ulSupportedFrameSize) {
                TRACE(TL_STRM_TRACE,("VIDEOINFO: biSizeToVerify %d != Supported %d\n",
                    ((PKS_DATAFORMAT_VIDEOINFOHEADER)pKSDataFormatToVerify)->VideoInfoHeader.bmiHeader.biSizeImage,
                    ulSupportedFrameSize
                    ));
                continue;
            } else {
                TRACE(TL_STRM_TRACE,("VIDOINFO: **** biSizeToVerify %d == Supported %d\n",
                    ((PKS_DATAFORMAT_VIDEOINFOHEADER)pKSDataFormatToVerify)->VideoInfoHeader.bmiHeader.biSizeImage,
                    ulSupportedFrameSize
                    ));
            }
        } else if (IsEqualGUID (&pKSDataFormatToVerify->Specifier, &KSDATAFORMAT_SPECIFIER_DVINFO)) {

            // Test 50/60 bit
            if((((PKS_DATARANGE_DVVIDEO) pKSDataFormatToVerify)->DVVideoInfo.dwDVAAuxSrc & MASK_AUX_50_60_BIT) != 
               (((PKS_DATARANGE_DVVIDEO) *pAvailableFormats)->DVVideoInfo.dwDVAAuxSrc    & MASK_AUX_50_60_BIT)  ||
               (((PKS_DATARANGE_DVVIDEO) pKSDataFormatToVerify)->DVVideoInfo.dwDVVAuxSrc & MASK_AUX_50_60_BIT) != 
               (((PKS_DATARANGE_DVVIDEO) *pAvailableFormats)->DVVideoInfo.dwDVVAuxSrc    & MASK_AUX_50_60_BIT) ) {

                TRACE(TL_STRM_TRACE,("DVINFO VerifyFormat failed: ASrc: %x!=%x (MSDV);or VSrc: %x!=%x\n",                    
                 ((PKS_DATARANGE_DVVIDEO) pKSDataFormatToVerify)->DVVideoInfo.dwDVAAuxSrc, 
                    ((PKS_DATARANGE_DVVIDEO) *pAvailableFormats)->DVVideoInfo.dwDVAAuxSrc,
                 ((PKS_DATARANGE_DVVIDEO) pKSDataFormatToVerify)->DVVideoInfo.dwDVVAuxSrc,
                    ((PKS_DATARANGE_DVVIDEO) *pAvailableFormats)->DVVideoInfo.dwDVVAuxSrc
                     ));

                continue;
            }

            TRACE(TL_STRM_TRACE,("DVINFO: dwDVAAuxCtl %x, Supported %x\n", 
                ((PKS_DATARANGE_DVVIDEO) pKSDataFormatToVerify)->DVVideoInfo.dwDVAAuxSrc,
                ((PKS_DATARANGE_DVVIDEO) *pAvailableFormats)->DVVideoInfo.dwDVAAuxSrc
                ));

            TRACE(TL_STRM_TRACE,("DVINFO: dwDVVAuxSrc %x, Supported %x\n", 
                ((PKS_DATARANGE_DVVIDEO) pKSDataFormatToVerify)->DVVideoInfo.dwDVVAuxSrc,
                ((PKS_DATARANGE_DVVIDEO) *pAvailableFormats)->DVVideoInfo.dwDVVAuxSrc
                ));

        }
        else if (IsEqualGUID (&pKSDataFormatToVerify->SubFormat, &KSDATAFORMAT_TYPE_MPEG2_TRANSPORT)  ) {
            TRACE(TL_STRM_TRACE,("VerifyFormat: MPEG2 subformat\n"));
        }
        else if (IsEqualGUID (&pKSDataFormatToVerify->SubFormat, &KSDATAFORMAT_TYPE_MPEG2_TRANSPORT_STRIDE) 
            && pKSDataFormatToVerify->FormatSize >= (sizeof(KSDATARANGE)+sizeof(MPEG2_TRANSPORT_STRIDE)) ) {
            //
            // Verify the STRIDE structure
            //
            if(  ((KS_DATARANGE_MPEG2TS_STRIDE_AVC *) pKSDataFormatToVerify)->Stride.dwOffset       != MPEG2TS_STRIDE_OFFSET 
              || ((KS_DATARANGE_MPEG2TS_STRIDE_AVC *) pKSDataFormatToVerify)->Stride.dwPacketLength != MPEG2TS_STRIDE_PACKET_LEN 
              || ((KS_DATARANGE_MPEG2TS_STRIDE_AVC *) pKSDataFormatToVerify)->Stride.dwStride       != MPEG2TS_STRIDE_STRIDE_LEN 
              ) {
                TRACE(TL_STRM_ERROR,("VerifyDataFormat: Invalid STRIDE parameters: dwOffset:%d; dwPacketLength:%d; dwStride:%d\n",
                    ((KS_DATARANGE_MPEG2TS_STRIDE_AVC *) pKSDataFormatToVerify)->Stride.dwOffset,
                    ((KS_DATARANGE_MPEG2TS_STRIDE_AVC *) pKSDataFormatToVerify)->Stride.dwPacketLength,
                    ((KS_DATARANGE_MPEG2TS_STRIDE_AVC *) pKSDataFormatToVerify)->Stride.dwStride
                    ));
                    continue;
            }
            TRACE(TL_STRM_TRACE,("VerifyFormat: MPEG2 stride subformat\n"));
        }
        else {
            continue;
        }


        return TRUE;
    }

    return FALSE;
} 




NTSTATUS
AVCTapeGetDataIntersection(
    IN  ULONG  NumOfPins,
    IN  ULONG          ulStreamNumber,
    IN  PKSDATARANGE   pDataRange,
    OUT PVOID          pDataFormatBuffer,
    IN  ULONG          ulSizeOfDataFormatBuffer,
    IN  ULONG          ulSupportedFrameSize,
    OUT ULONG          *pulActualBytesTransferred,
    STREAM_INFO_AND_OBJ * pStreamInfoObject
#ifdef SUPPORT_NEW_AVC
    ,
    HANDLE  hPlugLocalOut,
    HANDLE  hPlugLocalIn
#endif
    )
/*++

Routine Description:

    Called to get a DATAFORMAT from a DATARANGE.

--*/
{
    BOOL                        bMatchFound = FALSE;
    ULONG                       ulFormatSize;
    ULONG                       j;
    ULONG                       ulNumberOfFormatArrayEntries;
    PKSDATAFORMAT               *pAvailableFormats;
#ifdef SUPPORT_NEW_AVC
    AVCPRECONNECTINFO * pPreConnectInfo;
    AVCCONNECTINFO * pConnectInfo;
#endif

    PAGED_CODE();

    
    //
    // Check that the stream number is valid
    //
    if(ulStreamNumber >= NumOfPins) {
        TRACE(TL_STRM_ERROR,("FormatFromRange: ulStreamNumber %d >= NumOfPins %d\n", ulStreamNumber, NumOfPins)); 
        ASSERT(ulStreamNumber < NumOfPins && "Invalid stream index");
        return STATUS_NOT_SUPPORTED;
    }


    // Number of format this stream supports
    ulNumberOfFormatArrayEntries = pStreamInfoObject[ulStreamNumber].hwStreamInfo.NumberOfFormatArrayEntries;

    //
    // Get the pointer to the array of available formats
    //
    pAvailableFormats = pStreamInfoObject[ulStreamNumber].hwStreamInfo.StreamFormatsArray;


    //
    // Walk the formats supported by the stream searching for a match
    // Note: DataIntersection is really enumerating supported MediaType only!
    //       SO matter compare format is NTSC or PAL, we need suceeded both;
    //       however, we will copy back only the format is currently supported (NTSC or PAL).
    //
    for(j = 0; j < ulNumberOfFormatArrayEntries; j++, pAvailableFormats++) {

        if(!DVCmpGUIDsAndFormatSize(pDataRange, *pAvailableFormats, TRUE)) {
            TRACE(TL_STRM_TRACE,("CmpGUIDsAndFormatSize failed! FormatSize:%d?=%d\n", pDataRange->FormatSize, (*pAvailableFormats)->FormatSize));
            continue;
        }

        //
        // SUBTYPE_DVSD has a fix sample size; 
        //
        if(   IsEqualGUID (&pDataRange->SubFormat, &KSDATAFORMAT_SUBTYPE_DVSD)  
           && (*pAvailableFormats)->SampleSize != ulSupportedFrameSize) {
            TRACE(TL_STRM_TRACE,("_SUBTYPE_DVSD: StrmNum %d, %d of %d formats, SizeToVerify %d *!=* SupportedSampleSize %d\n", 
                ulStreamNumber,
                j+1, ulNumberOfFormatArrayEntries, 
                (*pAvailableFormats)->SampleSize,  
                ulSupportedFrameSize));
            continue;
        }

         
        // -------------------------------------------------------------------
        // Specifier FORMAT_VideoInfo for VIDEOINFOHEADER
        // -------------------------------------------------------------------

        if(IsEqualGUID (&pDataRange->Specifier, &KSDATAFORMAT_SPECIFIER_VIDEOINFO)) {
         
            PKS_DATARANGE_VIDEO pDataRangeVideoToVerify = (PKS_DATARANGE_VIDEO) pDataRange;
            PKS_DATARANGE_VIDEO pDataRangeVideo         = (PKS_DATARANGE_VIDEO) *pAvailableFormats;

#if 0
            //
            // Check that the other fields match
            //
            if ((pDataRangeVideoToVerify->bFixedSizeSamples      != pDataRangeVideo->bFixedSizeSamples)
                || (pDataRangeVideoToVerify->bTemporalCompression   != pDataRangeVideo->bTemporalCompression) 
                || (pDataRangeVideoToVerify->StreamDescriptionFlags != pDataRangeVideo->StreamDescriptionFlags) 
                || (pDataRangeVideoToVerify->MemoryAllocationFlags  != pDataRangeVideo->MemoryAllocationFlags) 
#ifdef COMPARE_CONFIG_CAP
                || (RtlCompareMemory (&pDataRangeVideoToVerify->ConfigCaps,
                    &pDataRangeVideo->ConfigCaps,
                    sizeof (KS_VIDEO_STREAM_CONFIG_CAPS)) != 
                    sizeof (KS_VIDEO_STREAM_CONFIG_CAPS))
#endif
                    )   {

                TRACE(TL_STRM_TRACE,("FormatFromRange: *!=* bFixSizeSample (%d %d) (%d %d) (%d %d) (%x %x)\n",
                    pDataRangeVideoToVerify->bFixedSizeSamples,      pDataRangeVideo->bFixedSizeSamples,
                    pDataRangeVideoToVerify->bTemporalCompression ,  pDataRangeVideo->bTemporalCompression,
                    pDataRangeVideoToVerify->StreamDescriptionFlags, pDataRangeVideo->StreamDescriptionFlags,
                    pDataRangeVideoToVerify->ConfigCaps.VideoStandard, pDataRangeVideo->ConfigCaps.VideoStandard 
                    ));
                    
                continue;
            } else {
                TRACE(TL_STRM_TRACE,("FormatFromRange: == bFixSizeSample (%d %d) (%d %d) (%d %d) (%x %x)\n",
                    pDataRangeVideoToVerify->bFixedSizeSamples,      pDataRangeVideo->bFixedSizeSamples,
                    pDataRangeVideoToVerify->bTemporalCompression ,  pDataRangeVideo->bTemporalCompression,
                    pDataRangeVideoToVerify->StreamDescriptionFlags, pDataRangeVideo->StreamDescriptionFlags,
                    pDataRangeVideoToVerify->ConfigCaps.VideoStandard, pDataRangeVideo->ConfigCaps.VideoStandard 
                    ));
            }
           
#endif
            bMatchFound = TRUE;            
            ulFormatSize = sizeof (KSDATAFORMAT) + 
                KS_SIZE_VIDEOHEADER (&pDataRangeVideo->VideoInfoHeader);
            
            if(ulSizeOfDataFormatBuffer == 0) {

                // We actually have not returned this much data,
                // this "size" will be used by Ksproxy to send down 
                // a buffer of that size in next query.
                *pulActualBytesTransferred = ulFormatSize;

                return STATUS_BUFFER_OVERFLOW;
            }


            // Caller wants the full data format
            if(ulSizeOfDataFormatBuffer < ulFormatSize) {
                TRACE(TL_STRM_TRACE,("VIDEOINFO: StreamNum %d, SizeOfDataFormatBuffer %d < ulFormatSize %d\n",ulStreamNumber, ulSizeOfDataFormatBuffer, ulFormatSize));
                return STATUS_BUFFER_TOO_SMALL;
            }

            // KS_DATAFORMAT_VIDEOINFOHEADER
            //    KSDATAFORMAT            DataFormat;
            //    KS_VIDEOINFOHEADER      VideoInfoHeader;                
            RtlCopyMemory(
                &((PKS_DATAFORMAT_VIDEOINFOHEADER)pDataFormatBuffer)->DataFormat,
                &pDataRangeVideo->DataRange, 
                sizeof (KSDATAFORMAT));

            // This size is differnt from our data range size which also contains ConfigCap
            ((PKSDATAFORMAT)pDataFormatBuffer)->FormatSize = ulFormatSize;
            *pulActualBytesTransferred = ulFormatSize;

            RtlCopyMemory(
                &((PKS_DATAFORMAT_VIDEOINFOHEADER) pDataFormatBuffer)->VideoInfoHeader,
                &pDataRangeVideo->VideoInfoHeader,  
                KS_SIZE_VIDEOHEADER (&pDataRangeVideo->VideoInfoHeader));

            TRACE(TL_STRM_TRACE,("FormatFromRange: Matched, StrmNum %d, FormatSize %d, CopySize %d; FormatBufferSize %d, biSizeImage.\n", 
                ulStreamNumber, (*pAvailableFormats)->FormatSize, ulFormatSize, ulSizeOfDataFormatBuffer,
                ((PKS_DATAFORMAT_VIDEOINFOHEADER) pDataFormatBuffer)->VideoInfoHeader.bmiHeader.biSizeImage));

            return STATUS_SUCCESS;

        } else if (IsEqualGUID (&pDataRange->Specifier, &KSDATAFORMAT_SPECIFIER_DVINFO)) {
            // -------------------------------------------------------------------
            // Specifier FORMAT_DVInfo for KS_DATARANGE_DVVIDEO
            // -------------------------------------------------------------------

            // MATCH FOUND!
            bMatchFound = TRUE;            

            ulFormatSize = sizeof(KS_DATARANGE_DVVIDEO);

            if(ulSizeOfDataFormatBuffer == 0) {
                // We actually have not returned this much data,
                // this "size" will be used by Ksproxy to send down 
                // a buffer of that size in next query.
                *pulActualBytesTransferred = ulFormatSize;
                return STATUS_BUFFER_OVERFLOW;
            }
            
            // Caller wants the full data format
            if (ulSizeOfDataFormatBuffer < ulFormatSize) {
                TRACE(TL_STRM_ERROR,("DVINFO: StreamNum %d, SizeOfDataFormatBuffer %d < ulFormatSize %d\n", ulStreamNumber, ulSizeOfDataFormatBuffer, ulFormatSize));
                return STATUS_BUFFER_TOO_SMALL;
            }

            RtlCopyMemory(
                pDataFormatBuffer,
                *pAvailableFormats, 
                (*pAvailableFormats)->FormatSize); 
            
            ((PKSDATAFORMAT)pDataFormatBuffer)->FormatSize = ulFormatSize;
            *pulActualBytesTransferred = ulFormatSize;

#ifdef SUPPORT_NEW_AVC  // Data intersection; return hPlug if flag is set
            pPreConnectInfo = &(((KS_DATARANGE_DV_AVC *) *pAvailableFormats)->ConnectInfo);
            pConnectInfo    = &(((KS_DATAFORMAT_DV_AVC *) pDataFormatBuffer)->ConnectInfo);

            if(pPreConnectInfo->Flags & (KSPIN_FLAG_AVC_PCRONLY | KSPIN_FLAG_AVC_FIXEDPCR)) {
                // Need to return the plug handle
                pConnectInfo->hPlug = \
                    (pPreConnectInfo->DataFlow == KSPIN_DATAFLOW_OUT) ? hPlugLocalOut : hPlugLocalIn;        
            } else {
                // Choose any that is available
                // Set to 0 for now.
                pConnectInfo->hPlug = NULL;
            }

#if DBG
            TRACE(TL_STRM_TRACE,("DVINFO: pPreConnectInfo:%x; pConnectInfo:%x\n", pPreConnectInfo, pConnectInfo));
            if(TapeDebugLevel >= 2) {
                ASSERT(FALSE && "Check ConnectInfo!");
            }
#endif
#endif
            TRACE(TL_STRM_TRACE,("FormatFromRange: Matched, StrmNum %d, FormatSize %d, CopySize %d; FormatBufferSize %d.\n", 
                ulStreamNumber, (*pAvailableFormats)->FormatSize, ulFormatSize, ulSizeOfDataFormatBuffer));

            return STATUS_SUCCESS;

        } else if (IsEqualGUID (&pDataRange->SubFormat, &KSDATAFORMAT_TYPE_MPEG2_TRANSPORT_STRIDE) ){


            // -------------------------------------------------------------------
            // Compare subformat since it is unique
            // Subformat STATIC_KSDATAFORMAT_TYPE_MPEG2_TRANSPORT_STRIDE
            // -------------------------------------------------------------------

#if 0       // Not enforced.     
            // Only for a certain specifier
            if(!IsEqualGUID (&pDataRange->Specifier, &KSDATAFORMAT_SPECIFIER_61883_4)) {
                TRACE(TL_STRM_TRACE,("SubFormat KSDATAFORMAT_TYPE_MPEG2_TRANSPORT_STRIDE but Specifier is not STATIC_KSDATAFORMAT_SPECIFIER_61883_4\n"));
                continue;
            }
#endif

            // Sample size must match!
            if((*pAvailableFormats)->SampleSize != pDataRange->SampleSize) {
                TRACE(TL_STRM_TRACE,("SampleSize(MPEG2_TRANSPORT_STRIDE): Availabel:%d != Range:%d\n", (*pAvailableFormats)->SampleSize, pDataRange->SampleSize));
                continue;
            }

            // MATCH FOUND!
            bMatchFound = TRUE;            

#ifdef SUPPORT_NEW_AVC
            ulFormatSize = sizeof(KS_DATARANGE_MPEG2TS_STRIDE_AVC);                               
#else
            ulFormatSize = sizeof(KS_DATARANGE_MPEG2TS_STRIDE_AVC) - sizeof(AVCPRECONNECTINFO);     // FormatSize; exclude AVCPRECONNECTINFO
#endif
            if(ulSizeOfDataFormatBuffer == 0) {
                // We actually have not returned this much data,
                // this "size" will be used by Ksproxy to send down 
                // a buffer of that size in next query.
                *pulActualBytesTransferred = ulFormatSize;
                return STATUS_BUFFER_OVERFLOW;
            }
            
            // Caller wants the full data format
            if (ulSizeOfDataFormatBuffer < ulFormatSize) {
                TRACE(TL_STRM_ERROR,("MPEG2_TRANSPORT_STRIDE: StreamNum %d, SizeOfDataFormatBuffer %d < ulFormatSize %d\n", ulStreamNumber, ulSizeOfDataFormatBuffer, ulFormatSize));
                return STATUS_BUFFER_TOO_SMALL;
            }

            //
            // Verify the STRIDE structure
            //
            if(  ((KS_DATARANGE_MPEG2TS_STRIDE_AVC *) pDataRange)->Stride.dwOffset       != MPEG2TS_STRIDE_OFFSET 
              || ((KS_DATARANGE_MPEG2TS_STRIDE_AVC *) pDataRange)->Stride.dwPacketLength != MPEG2TS_STRIDE_PACKET_LEN 
              || ((KS_DATARANGE_MPEG2TS_STRIDE_AVC *) pDataRange)->Stride.dwStride       != MPEG2TS_STRIDE_STRIDE_LEN 
              ) {
                TRACE(TL_PNP_ERROR,("AVCTapeGetDataIntersection:Invalid STRIDE parameters: dwOffset:%d; dwPacketLength:%d; dwStride:%d\n",
                    ((KS_DATARANGE_MPEG2TS_STRIDE_AVC *) pDataRange)->Stride.dwOffset,
                    ((KS_DATARANGE_MPEG2TS_STRIDE_AVC *) pDataRange)->Stride.dwPacketLength,
                    ((KS_DATARANGE_MPEG2TS_STRIDE_AVC *) pDataRange)->Stride.dwStride
                    ));
                    return STATUS_INVALID_PARAMETER;
            }


            RtlCopyMemory(pDataFormatBuffer, *pAvailableFormats, (*pAvailableFormats)->FormatSize);             
            ((PKSDATAFORMAT)pDataFormatBuffer)->FormatSize = ulFormatSize;
            *pulActualBytesTransferred = ulFormatSize;

#ifdef SUPPORT_NEW_AVC  // Data intersection; return hPlug if flag is set

            pPreConnectInfo = &(((KS_DATARANGE_MPEG2TS_AVC *) *pAvailableFormats)->ConnectInfo);
            pConnectInfo    = &(((KS_DATAFORMAT_MPEG2TS_AVC *) pDataFormatBuffer)->ConnectInfo);


            if(pPreConnectInfo->Flags & (KSPIN_FLAG_AVC_PCRONLY | KSPIN_FLAG_AVC_FIXEDPCR)) {
                // Need to return the plug handle
                pConnectInfo->hPlug = \
                    (pPreConnectInfo->DataFlow == KSPIN_DATAFLOW_OUT) ? hPlugLocalOut : hPlugLocalIn;        
            } else {
                // Choose any that is available
                // Set to 0 for now.
                pConnectInfo->hPlug = NULL;
            }
#if DBG
            TRACE(TL_STRM_TRACE,("MPEG2TS: pPreConnectInfo:%x; pConnectInfo:%x\n", pPreConnectInfo, pConnectInfo));
            ASSERT(FALSE && "Check ConnectInfo!");            
#endif
#endif

            TRACE(TL_STRM_TRACE,("FormatFromRange:(MPEG2TS_STRIDE) Matched, StrmNum %d, FormatSize %d, CopySize %d; FormatBufferSize %d.\n", 
                ulStreamNumber, (*pAvailableFormats)->FormatSize, ulFormatSize, ulSizeOfDataFormatBuffer));

            return STATUS_SUCCESS;

        } else if (IsEqualGUID (&pDataRange->SubFormat, &KSDATAFORMAT_TYPE_MPEG2_TRANSPORT)) {

            // -------------------------------------------------------------------
            // Compare subformat since it is unique
            // Subformat STATIC_KSDATAFORMAT_TYPE_MPEG2_TRANSPORT
            // -------------------------------------------------------------------

            // Sample size must match!
            if((*pAvailableFormats)->SampleSize != pDataRange->SampleSize) {
                TRACE(TL_STRM_TRACE,("SampleSize(MPEG2_TRANSPORT): Availabel:%d != Range:%d\n", (*pAvailableFormats)->SampleSize, pDataRange->SampleSize));
                continue;
            }

            // MATCH FOUND!
            bMatchFound = TRUE;            

#ifdef SUPPORT_NEW_AVC
            ulFormatSize = sizeof(KS_DATARANGE_MPEG2TS_AVC);                               
#else
            ulFormatSize = sizeof(KS_DATARANGE_MPEG2TS_AVC) - sizeof(AVCPRECONNECTINFO);     // FormatSize; exclude AVCPRECONNECTINFO
#endif
            if(ulSizeOfDataFormatBuffer == 0) {
                // We actually have not returned this much data,
                // this "size" will be used by Ksproxy to send down 
                // a buffer of that size in next query.
                *pulActualBytesTransferred = ulFormatSize;
                return STATUS_BUFFER_OVERFLOW;
            }
            
            // Caller wants the full data format
            if (ulSizeOfDataFormatBuffer < ulFormatSize) {
                TRACE(TL_STRM_ERROR,("MPEG2_TRANSPORT: StreamNum %d, SizeOfDataFormatBuffer %d < ulFormatSize %d\n", ulStreamNumber, ulSizeOfDataFormatBuffer, ulFormatSize));
                return STATUS_BUFFER_TOO_SMALL;
            }

            RtlCopyMemory(pDataFormatBuffer, *pAvailableFormats, (*pAvailableFormats)->FormatSize);             
            ((PKSDATAFORMAT)pDataFormatBuffer)->FormatSize = ulFormatSize;
            *pulActualBytesTransferred = ulFormatSize;

#ifdef SUPPORT_NEW_AVC  // Data intersection; return hPlug if flag is set

            pPreConnectInfo = &(((KS_DATARANGE_MPEG2TS_AVC *) *pAvailableFormats)->ConnectInfo);
            pConnectInfo    = &(((KS_DATAFORMAT_MPEG2TS_AVC *) pDataFormatBuffer)->ConnectInfo);


            if(pPreConnectInfo->Flags & (KSPIN_FLAG_AVC_PCRONLY | KSPIN_FLAG_AVC_FIXEDPCR)) {
                // Need to return the plug handle
                pConnectInfo->hPlug = \
                    (pPreConnectInfo->DataFlow == KSPIN_DATAFLOW_OUT) ? hPlugLocalOut : hPlugLocalIn;        
            } else {
                // Choose any that is available
                // Set to 0 for now.
                pConnectInfo->hPlug = NULL;
            }
#if DBG
            TRACE(TL_STRM_TRACE,("MPEG2TS: pPreConnectInfo:%x; pConnectInfo:%x\n", pPreConnectInfo, pConnectInfo));
            ASSERT(FALSE && "Check ConnectInfo!");            
#endif
#endif

            TRACE(TL_STRM_TRACE,("FormatFromRange: (MPEG2TS) Matched, StrmNum %d, FormatSize %d, CopySize %d; FormatBufferSize %d.\n", 
                ulStreamNumber, (*pAvailableFormats)->FormatSize, ulFormatSize, ulSizeOfDataFormatBuffer));

            return STATUS_SUCCESS;

        } 

    } // End of loop on all formats for this stream
    
    if(!bMatchFound) {

        TRACE(TL_STRM_TRACE,("FormatFromRange: No Match! StrmNum %d, pDataRange %x\n", ulStreamNumber, pDataRange));
    }

    return STATUS_NO_MATCH;         
}



VOID 
AVCTapeIniStrmExt(
    PHW_STREAM_OBJECT  pStrmObject,
    PSTREAMEX          pStrmExt,
    PDVCR_EXTENSION    pDevExt,
    PSTREAM_INFO_AND_OBJ   pStream
    )
/*++

Routine Description:

    Initialize stream extension strcuture.

--*/
{

    PAGED_CODE();

    RtlZeroMemory( pStrmExt, sizeof(STREAMEX) );

    pStrmExt->bEOStream     = TRUE;       // Stream has not started yet!

    pStrmExt->pStrmObject   = pStrmObject;
    pStrmExt->StreamState   = KSSTATE_STOP;
    pStrmExt->pDevExt       = pDevExt;

    pStrmExt->hMyClock      = 0;
    pStrmExt->hMasterClock  = 0;
    pStrmExt->hClock        = 0;


//
// Aplly to both IN/OUT data flow
//
    //
    // Init isoch resources
    //
    pStrmExt->CurrentStreamTime = 0;  

    pStrmExt->cntSRBReceived    = 0;  // Total number of SRB_READ/WRITE_DATA
    pStrmExt->cntDataSubmitted  = 0;  // Number of pending data buffer

    pStrmExt->cntSRBCancelled   = 0;  // number of SRB_READ/WRITE_DATA cancelled
    

    pStrmExt->FramesProcessed = 0;
    pStrmExt->PictureNumber   = 0;
    pStrmExt->FramesDropped   = 0;   

    //
    // Subcode data that can be extract from a DV frame
    //

    pStrmExt->AbsTrackNumber = 0;
    pStrmExt->bATNUpdated    = FALSE;

    pStrmExt->Timecode[0] = 0;
    pStrmExt->Timecode[1] = 0;
    pStrmExt->Timecode[2] = 0;
    pStrmExt->Timecode[3] = 0;
    pStrmExt->bTimecodeUpdated = FALSE;


    //
    // Work item variables use to cancel all SRBs
    //
    pStrmExt->lCancelStateWorkItem = 0;
    pStrmExt->AbortInProgress = FALSE;

#ifdef USE_WDM110
    pStrmExt->pIoWorkItem = NULL;
#endif
   
    //
    // Cache the pointer
    // What in DVStreams[] are READONLY
    //
    pStrmExt->pStrmInfo = &pStream->hwStreamInfo;

    pStrmObject->ReceiveDataPacket    = (PVOID) pStream->hwStreamObject.ReceiveDataPacket;
    pStrmObject->ReceiveControlPacket = (PVOID) pStream->hwStreamObject.ReceiveControlPacket;
    pStrmObject->Dma                          = pStream->hwStreamObject.Dma;
    pStrmObject->Pio                          = pStream->hwStreamObject.Pio;
    pStrmObject->StreamHeaderWorkspace        = pStream->hwStreamObject.StreamHeaderWorkspace;
    pStrmObject->StreamHeaderMediaSpecific    = pStream->hwStreamObject.StreamHeaderMediaSpecific;
    pStrmObject->HwClockObject                = pStream->hwStreamObject.HwClockObject;
    pStrmObject->Allocator                    = pStream->hwStreamObject.Allocator;
    pStrmObject->HwEventRoutine               = pStream->hwStreamObject.HwEventRoutine;

}



NTSTATUS
AVCTapeOpenStream(
    IN PHW_STREAM_OBJECT pStrmObject,
    IN PKSDATAFORMAT     pOpenFormat,
    IN PAV_61883_REQUEST    pAVReq
    )

/*++

Routine Description:

    Verify the OpenFormat and then allocate PC resource needed for this stream.
    The isoch resource, if needed, is allocated when streaming is transition to PAUSE state.

--*/

{
    NTSTATUS         Status = STATUS_SUCCESS;
    PSTREAMEX        pStrmExt;
    PDVCR_EXTENSION  pDevExt;
    ULONG            idxStreamNumber;
    KSPIN_DATAFLOW   DataFlow;
    PIRP             pIrp = NULL;
    FMT_INDEX        VideoFormatIndexLast;  // Last format index; used to detect change.
    PAVC_STREAM_REQUEST_BLOCK  pAVCStrmReq;
    ULONG  i, j;

    PAGED_CODE();

    
    pDevExt  = (PDVCR_EXTENSION) pStrmObject->HwDeviceExtension;
    pStrmExt = (PSTREAMEX)       pStrmObject->HwStreamExtension;
    idxStreamNumber =            pStrmObject->StreamNumber;

    TRACE(TL_STRM_TRACE,("OpenStream: pStrmObject %x, pOpenFormat %x, cntOpen %d, idxStream %d\n", pStrmObject, pOpenFormat, pDevExt->cndStrmOpen, idxStreamNumber));

    //
    // When nonone else has open a stream (or is opening ?)
    //
    if(pDevExt->cndStrmOpen > 0) {

        Status = STATUS_UNSUCCESSFUL; 
        TRACE(TL_STRM_WARNING,("OpenStream: %d stream open already; failed hr %x\n", pDevExt->cndStrmOpen, Status));
        return Status;
    }

    pIrp = IoAllocateIrp(pDevExt->pBusDeviceObject->StackSize, FALSE);
    if(!pIrp) {
        ASSERT(pIrp && "IoAllocateIrp() failed!");
        return STATUS_INSUFFICIENT_RESOURCES;
    }

    //
    // If a user switch from Camera to VCR mode very quickly (passing the OFF position), 
    // the driver may not be relaoded to detect correct mode of operation.
    // It is safe to redetect here.
    // Note: MSDV does return all the stream info for both input and output pin format.
    //
    DVGetDevModeOfOperation(pDevExt);


    //
    // WARNING: !! we advertise both input and output pin regardless of its mode of operation,
    // but Camera does not support input pin so open should failed!
    // If a VCR does not have input pin should fail as well.
    //
    // Ignore checking for ED_DEVTYOPE_UNKNOWN (most likely a hardware decoder box)
    //
    if((pDevExt->ulDevType == ED_DEVTYPE_CAMERA || 
        (pDevExt->ulDevType == ED_DEVTYPE_VCR && pDevExt->pDevInPlugs->NumPlugs == 0))
        && idxStreamNumber == 2) {

        IoFreeIrp(pIrp);
        TRACE(TL_STRM_WARNING,("OpenStream:Camera mode or VCR with 0 input pin cannot take external in.\n"));
        return STATUS_UNSUCCESSFUL;
    }

    ASSERT(idxStreamNumber < pDevExt->NumOfPins);
    ASSERT(pDevExt->paStrmExt[idxStreamNumber] == NULL);  // Not yet open!

    //
    // Data flow
    //
    DataFlow= pDevExt->pStreamInfoObject[idxStreamNumber].hwStreamInfo.DataFlow;

           
    //
    // Initialize the stream extension structure
    //
    AVCTapeIniStrmExt(
         pStrmObject, 
         pStrmExt,
         pDevExt,
         &pDevExt->pStreamInfoObject[idxStreamNumber]
         );

    //
    // Sony's NTSC can play PAL tape and its plug will change its supported format accordingly.
    //
    // Query video format (NTSC/PAL) supported.
    // Compare with its default (set at load time or last opensteam),
    // if difference, change our internal video format table.
    //
    if(pDevExt->ulDevType != ED_DEVTYPE_CAMERA) {
        VideoFormatIndexLast = pDevExt->VideoFormatIndex;
        if(!DVGetDevSignalFormat(
            pDevExt,
            DataFlow,
            pStrmExt
            )) {
            IoFreeIrp(pIrp);
            // If querying its format has failed, we cannot open this stream.
            TRACE(TL_STRM_WARNING,("OpenStream:Camera mode cannot take external in.\n"));
            Status = STATUS_UNSUCCESSFUL;
            goto AbortOpenStream;
        }
    }


    //
    // Check the video data format is okay.
    //
    if(!AVCTapeVerifyDataFormat(
            pDevExt->NumOfPins,
            pOpenFormat, 
            idxStreamNumber,
            AVCStrmFormatInfoTable[pDevExt->VideoFormatIndex].FrameSize,
            pDevExt->pStreamInfoObject
            ) ) {
        IoFreeIrp(pIrp);
        TRACE(TL_STRM_ERROR,("OpenStream: AdapterVerifyFormat failed.\n"));        
        return STATUS_INVALID_PARAMETER;
    }


    //
    // This event guard againt work item completion
    // 

    KeInitializeEvent(&pStrmExt->hCancelDoneEvent, NotificationEvent, TRUE);


    //
    // Alloccate synchronization structures for flow control and queue management
    //

    pStrmExt->hMutexFlow = (KMUTEX *) ExAllocatePool(NonPagedPool, sizeof(KMUTEX));
    if(!pStrmExt->hMutexFlow) {
        Status = STATUS_INSUFFICIENT_RESOURCES;
        goto AbortOpenStream;
    }
    KeInitializeMutex( pStrmExt->hMutexFlow, 0);      // Level 0 and in Signal state

    pStrmExt->hMutexReq = (KMUTEX *) ExAllocatePool(NonPagedPool, sizeof(KMUTEX));
    if(!pStrmExt->hMutexReq) {
        Status = STATUS_INSUFFICIENT_RESOURCES;
        goto AbortOpenStream;
    }
    KeInitializeMutex(pStrmExt->hMutexReq, 0);

    pStrmExt->DataListLock = (KSPIN_LOCK *) ExAllocatePool(NonPagedPool, sizeof(KSPIN_LOCK));
    if(!pStrmExt->DataListLock) {
        Status = STATUS_INSUFFICIENT_RESOURCES;
        goto AbortOpenStream;
    }
    KeInitializeSpinLock(pStrmExt->DataListLock);


    // 
    // Request AVCStrm to open a stream
    //

    pStrmExt->pIrpReq = IoAllocateIrp(pDevExt->pBusDeviceObject->StackSize, FALSE);
    if(!pStrmExt->pIrpReq) {
        Status = STATUS_INSUFFICIENT_RESOURCES;
        goto AbortOpenStream;
    }

    pStrmExt->pIrpAbort = IoAllocateIrp(pDevExt->pBusDeviceObject->StackSize, FALSE);
    if(!pStrmExt->pIrpAbort) {
        IoFreeIrp(pStrmExt->pIrpReq);   pStrmExt->pIrpReq = NULL;
        Status = STATUS_INSUFFICIENT_RESOURCES;
        goto AbortOpenStream;
    }


    //
    // Pre-allocate list of detached (free) and attached (busy) list for tracking
    // data request sending down to lower driver for processing.
    // 
    InitializeListHead(&pStrmExt->DataDetachedListHead); pStrmExt->cntDataDetached = 0;
    InitializeListHead(&pStrmExt->DataAttachedListHead); pStrmExt->cntDataAttached = 0;

    for (i=0; i < MAX_DATA_REQUESTS; i++) {
        pStrmExt->AsyncReq[i].pIrp = IoAllocateIrp(pDevExt->pBusDeviceObject->StackSize, FALSE);
        if(!pStrmExt->AsyncReq[i].pIrp) {
            // Free resource allocated so far.
            for (j=0; j < i; j++) {
                if(pStrmExt->AsyncReq[j].pIrp) {
                    IoFreeIrp(pStrmExt->AsyncReq[j].pIrp); pStrmExt->AsyncReq[j].pIrp = NULL;
                }
                RemoveEntryList(&pStrmExt->AsyncReq[j].ListEntry);  pStrmExt->cntDataDetached--;            
            }
            IoFreeIrp(pStrmExt->pIrpAbort); pStrmExt->pIrpAbort = NULL;
            IoFreeIrp(pStrmExt->pIrpReq);   pStrmExt->pIrpReq = NULL;
            Status = STATUS_INSUFFICIENT_RESOURCES;
            goto AbortOpenStream;
        }

        InsertTailList(&pStrmExt->DataDetachedListHead, &pStrmExt->AsyncReq[i].ListEntry); pStrmExt->cntDataDetached++;
    }

    // Synchronous calls share the same AV request packet in the stream extension..
    EnterAVCStrm(pStrmExt->hMutexReq);

    pAVCStrmReq = &pStrmExt->AVCStrmReq;
    RtlZeroMemory(pAVCStrmReq, sizeof(AVC_STREAM_REQUEST_BLOCK));
    INIT_AVCSTRM_HEADER(pAVCStrmReq, AVCSTRM_OPEN);
#if 1
    if(pDevExt->VideoFormatIndex == AVCSTRM_FORMAT_MPEG2TS) {
        // Data Rate
        // AVCStrmFormatInfoTable[pDevExt->VideoFormatIndex].AvgTimePerFrame = ?
        if(DataFlow == KSPIN_DATAFLOW_IN) {
            AVCStrmFormatInfoTable[pDevExt->VideoFormatIndex].OptionFlags = 0;
            AVCStrmFormatInfoTable[pDevExt->VideoFormatIndex].FrameSize = BUFFER_SIZE_MPEG2TS_SPH;
        } else {
            if(IsEqualGUID (&pOpenFormat->SubFormat, &KSDATAFORMAT_TYPE_MPEG2_TRANSPORT_STRIDE)) {
                AVCStrmFormatInfoTable[pDevExt->VideoFormatIndex].OptionFlags = 0;
                AVCStrmFormatInfoTable[pDevExt->VideoFormatIndex].FrameSize = BUFFER_SIZE_MPEG2TS_SPH; 
            } else {
                AVCStrmFormatInfoTable[pDevExt->VideoFormatIndex].OptionFlags = AVCSTRM_FORMAT_OPTION_STRIP_SPH;
                AVCStrmFormatInfoTable[pDevExt->VideoFormatIndex].FrameSize = BUFFER_SIZE_MPEG2TS; 
            }
        }
    }
#endif
    pAVCStrmReq->CommandData.OpenStruct.AVCFormatInfo    = &AVCStrmFormatInfoTable[pDevExt->VideoFormatIndex]; 
    pAVCStrmReq->CommandData.OpenStruct.AVCStreamContext = 0;   // will return the AV stream context
    pAVCStrmReq->CommandData.OpenStruct.DataFlow         = DataFlow;
#ifdef SUPPORT_LOCAL_PLUGS
    if(DataFlow == KSPIN_DATAFLOW_OUT)
        pAVCStrmReq->CommandData.OpenStruct.hPlugLocal   = pDevExt->hInputPCRLocal;  // Remote(oPCR)->Local(iPCR)
    else
        pAVCStrmReq->CommandData.OpenStruct.hPlugLocal   = pDevExt->hOutputPCRLocal; // Remote(iPCR)<-Local(oPCR)
#else
    pAVCStrmReq->CommandData.OpenStruct.hPlugLocal   = 0; // Not supported; use whatever 61883 supply.
#endif

    Status = 
        AVCStrmReqSubmitIrpSynch( 
            pDevExt->pBusDeviceObject,
            pStrmExt->pIrpReq,
            pAVCStrmReq
            );

    // Expect SUCCESS or anything else is failure! (including _PENDING) since this is a Sync call.
    if(STATUS_SUCCESS != Status) {
        TRACE(TL_STRM_ERROR,("AVCSTRM_OPEN: failed %x; pAVCStrmReq:%x\n", Status, pAVCStrmReq));
        ASSERT(NT_SUCCESS(Status) && "AVCSTGRM_OPEN failed!\n");
        IoFreeIrp(pStrmExt->pIrpReq); pStrmExt->pIrpReq = NULL;
        LeaveAVCStrm(pStrmExt->hMutexReq);
        goto OpenStreamDone;  // Failed to open!
    }

    //
    // Save the context, which is used for subsequent call to AVCStrm filter driver
    //
    pStrmExt->AVCStreamContext = pAVCStrmReq->CommandData.OpenStruct.AVCStreamContext;
    TRACE(TL_STRM_TRACE,("AVCSTRM_OPEN: suceeded %x; pAVCStrmReq:%x; AVCStreamContext:%x\n", Status, pAVCStrmReq, pStrmExt->AVCStreamContext));


    //
    // Format specific tasks
    //
    switch(pDevExt->VideoFormatIndex) {
    // For DV input pin, setup a timer DPC to periodically fired to singal clock event.
    case AVCSTRM_FORMAT_MPEG2TS:
        break;

    case AVCSTRM_FORMAT_SDDV_NTSC:      // 61883-2
    case AVCSTRM_FORMAT_SDDV_PAL:       // 61883-2
    case AVCSTRM_FORMAT_HDDV_NTSC:      // 61883-3
    case AVCSTRM_FORMAT_HDDV_PAL:       // 61883-3
    case AVCSTRM_FORMAT_SDLDV_NTSC:     // 61883-5
    case AVCSTRM_FORMAT_SDLDV_PAL:      // 61883-5
#ifdef SUPPORT_LOCAL_PLUGS
        if(DataFlow == KSPIN_DATAFLOW_IN) {
            // Remote(iPCR)<-Local(oPCR)
            // The default was S200 for MPEG2TS data; set it to DV.
            pDevExt->OPCR.oPCR.DataRate   = CMP_SPEED_S100; 
            pDevExt->OPCR.oPCR.OverheadID = PCR_OVERHEAD_ID_SDDV_DEF;
            pDevExt->OPCR.oPCR.Payload    = PCR_PAYLOAD_SDDV_DEF;
            if(AVCTapeSetLocalPlug(
                pDevExt,
                &pDevExt->AVReq,
                &pDevExt->hOutputPCRLocal,
                &pDevExt->OPCR)) {
                TRACE(TL_STRM_ERROR|TL_61883_ERROR,("Failed to set oPCR\n"));
            }
        } 
#endif

        KeInitializeDpc(
            &pStrmExt->DPCTimer,
            AVCTapeSignalClockEvent,
            pStrmExt
            );
        KeInitializeTimer(
            &pStrmExt->Timer
            );
        break;
    default:
        // Not supported!
        break;
    }


    LeaveAVCStrm(pStrmExt->hMutexReq);

    //
    //  Cache it and reference when pDevExt is all we have, such as BusReset and SurprieseRemoval
    //
    pDevExt->idxStreamNumber = idxStreamNumber;  // index of current active stream; work only if there is only one active stream at any time.
    pDevExt->paStrmExt[idxStreamNumber] = pStrmExt;

    //
    // In the future, a DV can be unplug and plug back in, 
    // and restore its state if the application is not yet closed.
    //
    pDevExt->bDevRemoved    = FALSE;

    //
    // No one else can open another stream (inout or output) unitil this is release.
    // This is done to avoid cyclic graph.
    //
    pDevExt->cndStrmOpen++;    
    ASSERT(pDevExt->cndStrmOpen == 1);

OpenStreamDone:

    TRACE(TL_STRM_WARNING,("OpenStream: %d stream open, idx %d, Status %x, pStrmExt %x, Context:%x; pDevExt %x\n", 
        pDevExt->cndStrmOpen, pDevExt->idxStreamNumber, Status, pStrmExt, pStrmExt->AVCStreamContext, pDevExt));     
    TRACE(TL_STRM_TRACE,("OpenStream: Status %x, idxStream %d, pDevExt %x, pStrmExt %x, Contextg:%x\n", 
        Status, idxStreamNumber, pDevExt, pStrmExt, pStrmExt->AVCStreamContext));

    return Status;

AbortOpenStream:

    if(pStrmExt->DataListLock) {
        ExFreePool(pStrmExt->DataListLock); pStrmExt->DataListLock = NULL;
    }

    if(pStrmExt->hMutexFlow) {
        ExFreePool(pStrmExt->hMutexFlow); pStrmExt->hMutexFlow = NULL;
    }

    if(pStrmExt->hMutexReq) {
        ExFreePool(pStrmExt->hMutexReq); pStrmExt->hMutexReq = NULL;
    }

    TRACE(TL_STRM_ERROR,("OpenStream failed %x, idxStream %d, pDevExt %x, pStrmExt %x\n", 
        Status, idxStreamNumber, pDevExt, pStrmExt));

    return Status;
}


NTSTATUS
AVCTapeCloseStream(
    IN PHW_STREAM_OBJECT pStrmObject,
    IN PKSDATAFORMAT     pOpenFormat,
    IN PAV_61883_REQUEST    pAVReq
    )

/*++

Routine Description:

    Called when an CloseStream Srb request is received

--*/

{
    PSTREAMEX         pStrmExt;
    PDVCR_EXTENSION   pDevExt;
    ULONG             idxStreamNumber;  
    NTSTATUS  Status;
    PAVC_STREAM_REQUEST_BLOCK  pAVCStrmReq;
    ULONG  i;
    PDRIVER_REQUEST pDriverReq;


    PAGED_CODE();

    
    pDevExt  = (PDVCR_EXTENSION) pStrmObject->HwDeviceExtension;
    pStrmExt = (PSTREAMEX)       pStrmObject->HwStreamExtension;
    idxStreamNumber =            pStrmObject->StreamNumber;


    TRACE(TL_STRM_TRACE,("CloseStream: >> pStrmExt %x, pDevExt %x\n", pStrmExt, pDevExt));    


    //
    // If the stream isn't open, just return
    //
    if(pStrmExt == NULL) {
        ASSERT(pStrmExt && "CloseStream but pStrmExt is NULL!");   
        return STATUS_SUCCESS;  // ????
    }

    //
    // Wait until the pending work item is completed.  
    //
    KeWaitForSingleObject( &pStrmExt->hCancelDoneEvent, Executive, KernelMode, FALSE, 0 );

    // 
    // Request AVCStrm to close a stream
    //
    EnterAVCStrm(pStrmExt->hMutexReq);

#if 0
    // For DV input pin, setup a timer DPC to periodically fired to singal clock event.
    if(pDevExt->VideoFormatIndex != AVCSTRM_FORMAT_MPEG2TS) {
        // Cancel timer
        TRACE(TL_STRM_TRACE,("*** CancelTimer *********************************************...\n"));
        KeCancelTimer(
            &pStrmExt->Timer
            );
    }
#endif

    pAVCStrmReq = &pStrmExt->AVCStrmReq;
    RtlZeroMemory(pAVCStrmReq, sizeof(AVC_STREAM_REQUEST_BLOCK));
    INIT_AVCSTRM_HEADER(pAVCStrmReq, AVCSTRM_CLOSE);

    pAVCStrmReq->AVCStreamContext = pStrmExt->AVCStreamContext;

    Status = 
        AVCStrmReqSubmitIrpSynch( 
            pDevExt->pBusDeviceObject,
            pStrmExt->pIrpReq,
            pAVCStrmReq
            );

    if(!NT_SUCCESS(Status)) {
        TRACE(TL_STRM_ERROR,("AVCSTRM_CLOSE: failed %x; pAVCStrmReq:%x\n", Status, pAVCStrmReq));
        ASSERT(NT_SUCCESS(Status) && "AVCSTGRM_CLOSE failed!\n");
    }
    else {
        // Save the context, which is used for subsequent call to AVCStrm.sys
        TRACE(TL_STRM_TRACE,("AVCSTRM_CLOSE: suceeded %x; pAVCStrmReq:%x\n", Status, pAVCStrmReq));
        pStrmExt->AVCStreamContext = 0;
    }

    // Free system resources
    if(pStrmExt->pIrpReq) {
        IoFreeIrp(pStrmExt->pIrpReq); pStrmExt->pIrpReq = NULL;
    }

    if(pStrmExt->pIrpAbort) {
        IoFreeIrp(pStrmExt->pIrpAbort); pStrmExt->pIrpAbort = NULL;
    }

#if 0
    for (i=0; i < MAX_DATA_REQUESTS; i++) {
        if(pStrmExt->AsyncReq[i].pIrp) {
            IoFreeIrp(pStrmExt->AsyncReq[i].pIrp); pStrmExt->AsyncReq[i].pIrp = NULL;
        }
    }
#else
    //
    // Free IRPs preallocated.  The entire data structure is part of the stream extension so
    // it will be freed by the StreamClass.
    //
    ASSERT(pStrmExt->cntDataAttached == 0);
    ASSERT(pStrmExt->cntDataDetached >= MAX_DATA_REQUESTS);
    while (!IsListEmpty(&pStrmExt->DataDetachedListHead)) {
        pDriverReq = (PDRIVER_REQUEST) RemoveHeadList(&pStrmExt->DataDetachedListHead); pStrmExt->cntDataDetached--;
        IoFreeIrp(pDriverReq->pIrp); pDriverReq->pIrp = NULL;
    }
#endif

    LeaveAVCStrm(pStrmExt->hMutexReq);

    //
    //  Not valid after this call.
    //
    for (i=0; i<pDevExt->NumOfPins; i++) {
        //
        // Find what we cache and remove it.
        //
        if(pStrmExt == pDevExt->paStrmExt[i]) {
            pDevExt->paStrmExt[i] = NULL;
            break;
        }
    }

    //
    // Free synchronization structures
    //

    if(pStrmExt->DataListLock) {
        ExFreePool(pStrmExt->DataListLock); pStrmExt->DataListLock = NULL;
    }

    if(pStrmExt->hMutexFlow) {
        ExFreePool(pStrmExt->hMutexFlow); pStrmExt->hMutexFlow = NULL;
    }

    if(pStrmExt->hMutexReq) {
        ExFreePool(pStrmExt->hMutexReq); pStrmExt->hMutexReq = NULL;
    }

    // Release this count so other can open.   
    pDevExt->cndStrmOpen--;
    ASSERT(pDevExt->cndStrmOpen == 0);

    TRACE(TL_STRM_TRACE,("CloseStream: completed; %d stream;\n", pDevExt->cndStrmOpen));

    return STATUS_SUCCESS;
}


NTSTATUS
DVChangePower(
    PDVCR_EXTENSION  pDevExt,
    PAV_61883_REQUEST pAVReq,
    DEVICE_POWER_STATE NewPowerState
    )
/*++

Routine Description:

    Process changing this device's power state.  

--*/
{
    ULONG i;   
    NTSTATUS Status;

    PAGED_CODE();


    // 
    //    D0: Device is on and can be streaming.
    //    D1,D2: not supported.
    //    D3: Device is off and can not streaming. The context is lost.  
    //        Power can be removed from the device.
    //        When power is back on, we will get a bus reset.
    //

    TRACE(TL_PNP_TRACE,("ChangePower: PowrSt: %d->%d; (d0:[1:On],D3[4:off])\n", pDevExt->PowerState, NewPowerState));

    Status = STATUS_SUCCESS;

    if(pDevExt->PowerState == NewPowerState) {
        TRACE(TL_STRM_WARNING,("ChangePower: no change; do nothing!\n"));
        return STATUS_SUCCESS;
    }

    switch (NewPowerState) {
    case PowerDeviceD3:  // Power OFF   
        // We are at D0 and ask to go to D3: save state, stop streaming and Sleep
        if( pDevExt->PowerState == PowerDeviceD0)  {
            // For a supported power state change
            for (i=0; i<pDevExt->NumOfPins; i++) {
                if(pDevExt->paStrmExt[i]) {
                    if(pDevExt->paStrmExt[i]->bIsochIsActive) {
                        // Stop isoch but do not change the streaming state
                        TRACE(TL_PNP_WARNING,("ChangePower: Stop isoch but not change stream state:%d\n", pDevExt->paStrmExt[i]->StreamState)); 
                    }
                }
            }
        }
        else {
            TRACE(TL_PNP_WARNING,("pDevExt->paStrmExt[i].StreamState:Intermieate power state; do nothing;\n"));
        }
        break;

    case PowerDeviceD0:  // Powering ON (waking up)
        if( pDevExt->PowerState == PowerDeviceD3) {
            // For a supported power state change
            for (i=0; i<pDevExt->NumOfPins; i++) {
                if(pDevExt->paStrmExt[i]) {
                    if(!pDevExt->paStrmExt[i]->bIsochIsActive) {
                        TRACE(TL_PNP_ERROR,("ChangePower: StrmSt:%d; Start isoch\n", pDevExt->paStrmExt[i]->StreamState)); 
                        // Start isoch depending on streaming state for DATAFLOW_IN/OUT
                        if(pDevExt->paStrmExt[i]->pStrmInfo->DataFlow == KSPIN_DATAFLOW_IN) {
                            if(pDevExt->paStrmExt[i]->StreamState == KSSTATE_PAUSE ||
                                pDevExt->paStrmExt[i]->StreamState == KSSTATE_RUN) {   
                            }
                        }
                        else if(pDevExt->paStrmExt[i]->pStrmInfo->DataFlow == KSPIN_DATAFLOW_OUT) {
                            if(pDevExt->paStrmExt[i]->StreamState == KSSTATE_RUN) {                             
                            }
                        }                    
                    }  // IsochActive
                }
            }
        }
        else {
            TRACE(TL_PNP_WARNING,("Intermieate power state; do nothing;\n"));
        }
        break;

    // These state are not supported.
    case PowerDeviceD1:
    case PowerDeviceD2:               
    default:
        TRACE(TL_PNP_WARNING,("ChangePower: Not supported PowerState %d\n", DevicePowerState));                  
        Status = STATUS_SUCCESS; // STATUS_INVALID_PARAMETER;
        break;
    }
           

    if(Status == STATUS_SUCCESS) 
        pDevExt->PowerState = NewPowerState;         
    else 
        Status = STATUS_NOT_IMPLEMENTED;

    return STATUS_SUCCESS;     
}


NTSTATUS
AVCTapeSurpriseRemoval(
    PDVCR_EXTENSION pDevExt,
    PAV_61883_REQUEST  pAVReq
    )

/*++

Routine Description:

    Response to SRB_SURPRISE_REMOVAL.

--*/

{
    ULONG  i;
    PKSEVENT_ENTRY  pEvent = NULL;

    PAGED_CODE();

    //
    // ONLY place this flag is set to TRUE.
    // Block incoming read although there might still in the process of being attached
    //
    pDevExt->bDevRemoved    = TRUE;

    // Signal
    if(pDevExt->PowerState != PowerDeviceD3) {
        pDevExt->PowerState = PowerDeviceD3;  // It is as good as power is off.
    }

    //
    // Now Stop the stream and clean up
    //

    for(i=0; i < pDevExt->NumOfPins; i++) {
        
        if(pDevExt->paStrmExt[i] != NULL) {

            TRACE(TL_PNP_WARNING,("#SURPRISE_REMOVAL# StrmNum %d, pStrmExt %x\n", i, pDevExt->paStrmExt[i]));

            // Signal this event so SRB can complete.
            if(pDevExt->paStrmExt[i]->pStrmInfo->DataFlow == KSPIN_DATAFLOW_IN ) {
                //
                // Imply EOStream!
                //

                if(!pDevExt->paStrmExt[i]->bEOStream)
                    pDevExt->paStrmExt[i]->bEOStream = TRUE;
                //
                // Signal EOStream
                //
                StreamClassStreamNotification(
                    SignalMultipleStreamEvents,
                    pDevExt->paStrmExt[i]->pStrmObject,
                    (GUID *)&KSEVENTSETID_Connection_Local,
                    KSEVENT_CONNECTION_ENDOFSTREAM
                    );
            }

            //
            // Start a work item to abort streaming
            //
            AVCTapeCreateAbortWorkItem(pDevExt, pDevExt->paStrmExt[i]);

            //
            // Wait until the pending work item is completed.  
            //
            TRACE(TL_PNP_WARNING,("SupriseRemoval: Wait for CancelDoneEvent <entering>; lCancelStateWorkItem:%d\n", pDevExt->paStrmExt[i]->lCancelStateWorkItem));
            KeWaitForSingleObject( &pDevExt->paStrmExt[i]->hCancelDoneEvent, Executive, KernelMode, FALSE, 0 );
            TRACE(TL_PNP_WARNING,("SupriseRemoval: Wait for CancelDoneEvent; Attached:%d <exited>...\n", pDevExt->paStrmExt[i]->cntDataAttached));
            ASSERT(pDevExt->paStrmExt[i]->cntDataAttached == 0);  // No more attach after abort stream!
        }
    }


    // Signal KSEvent that device is removed.
    // After this SRb, there will be no more Set/Get property Srb into this driver.
    // By notifying the COM I/F, it will wither signal application that device is removed and
    // return ERROR_DEVICE_REMOVED error code for subsequent calls.

    pEvent = 
        StreamClassGetNextEvent(
            (PVOID) pDevExt,
            0,
            (GUID *)&KSEVENTSETID_EXTDEV_Command,
            KSEVENT_EXTDEV_NOTIFY_REMOVAL,
            pEvent);

    if(pEvent) {
        //
        // signal the event here
        //     
        if(pEvent->EventItem->EventId == KSEVENT_EXTDEV_NOTIFY_REMOVAL) {
            StreamClassDeviceNotification(
                SignalDeviceEvent,
                pDevExt,
                pEvent
                );        
             TRACE(TL_PNP_WARNING,("SurpriseRemoval: signal KSEVENT_EXTDEV_NOTIFY_REMOVAL, id %x.\n", pEvent->EventItem->EventId));
        } else {
            TRACE(TL_PNP_TRACE,("SurpriseRemoval: pEvent:%x; Id:%d not matched!\n", pEvent, pEvent->EventItem->EventId)); 
        }
    } else {
        TRACE(TL_PNP_TRACE,("SurpriseRemoval: KSEVENT_EXTDEV_NOTIFY_REMOVAL event not enabled\n")); 
    }
   
    return STATUS_SUCCESS;
}


// Return code is basically return in pSrb->Status.
NTSTATUS
AVCTapeProcessPnPBusReset(
    PDVCR_EXTENSION  pDevExt
    )
/*++

Routine Description:

    Process a bus reset.

Arguments:

    Srb - Pointer to stream request block

Return Value:

    Nothing

--*/
{   
#ifdef MSDVDV_SUPPORT_BUSRESET_EVENT
    PKSEVENT_ENTRY   pEvent;
#endif

    PAGED_CODE();


    TRACE(TL_PNP_TRACE,("ProcessPnPBusReset: >>\n"));
    
#ifdef MSDVDV_SUPPORT_BUSRESET_EVENT
    //
    // Signal (if enabled) busreset event to let upper layer know that a busreset has occurred.
    //
    pEvent = NULL;
    pEvent = 
        StreamClassGetNextEvent(
            (PVOID) pDevExt,
            0, 
            (GUID *)&KSEVENTSETID_EXTDEV_Command,
            KSEVENT_EXTDEV_COMMAND_BUSRESET,
            pEvent
            );

    if(pEvent) {
        //
        // signal the event here
        //    
        if(pEvent->EventItem->EventId == KSEVENT_EXTDEV_COMMAND_BUSRESET) {
            StreamClassDeviceNotification(
                SignalDeviceEvent,
                pDevExt,
                pEvent
                );        

            TRACE(TL_PNP_TRACE,("ProcessPnPBusReset: Signal BUSRESET; EventId %d.\n", pEvent->EventItem->EventId));
        }
    }
#endif   

    //
    // Reset pending count and AVC command that is in Interim
    //
    DVAVCCmdResetAfterBusReset(pDevExt);


    //
    // Can we return anything other than SUCCESS ?
    //
    return STATUS_SUCCESS;
}   


NTSTATUS
AVCTapeUninitialize(
    IN PDVCR_EXTENSION  pDevExt
    )
/*++

Routine Description:

    This where we perform the necessary initialization tasks.

Arguments:

    Srb - Pointer to stream request block

Return Value:

    Nothing

--*/
{
    PAGED_CODE();

    TRACE(TL_PNP_TRACE,("UnInitialize: pDevExt=%x\n", pDevExt));

    //
    // Clear all pending AVC command entries.
    //
    DVAVCCmdResetAfterBusReset(pDevExt);

    
    //
    // Free textual string
    //
    DvFreeTextualString(pDevExt, &pDevExt->UnitIDs);


#ifdef SUPPORT_LOCAL_PLUGS

    // Delete the local output plug.
    if(pDevExt->hOutputPCRLocal) {
        if(!AVCTapeDeleteLocalPlug(
            pDevExt,
            &pDevExt->AVReq,
            &pDevExt->OutputPCRLocalNum,
            &pDevExt->hOutputPCRLocal)) {
            TRACE(TL_PNP_ERROR,("Failed to delete a local oPCR!\n"));        
        }
    }

    // Delete the local input plug.
    if(pDevExt->hInputPCRLocal) {
        if(!AVCTapeDeleteLocalPlug(
            pDevExt,
            &pDevExt->AVReq,
            &pDevExt->InputPCRLocalNum,
            &pDevExt->hInputPCRLocal)) {
            TRACE(TL_PNP_ERROR,("Failed to delete a local iPCR!\n"));        
        }
    }

#endif

    // Free preallocate resource
    if(pDevExt->pIrpSyncCall) {
        IoFreeIrp(pDevExt->pIrpSyncCall); pDevExt->pIrpSyncCall = NULL;
    }

    // Free stream information allocated
    if(pDevExt->pStreamInfoObject) {
        ExFreePool(pDevExt->pStreamInfoObject);
        pDevExt->pStreamInfoObject = NULL;
    }

    TRACE(TL_PNP_TRACE,("UnInitialize: done!\n"));

    return STATUS_SUCCESS;
}


//*****************************************************************************
//*****************************************************************************
// S T R E A M    S R B
//*****************************************************************************
//*****************************************************************************
#if DBG
ULONG DbgLastIdx = 0;
#endif

NTSTATUS
AVCTapeReqReadDataCR(
    IN PDEVICE_OBJECT  DeviceObject,
    IN PIRP  pIrpReq,
    IN PDRIVER_REQUEST  pDriverReq
    )
{
    PHW_STREAM_REQUEST_BLOCK  pSrb;
    PSTREAMEX  pStrmExt;
    KIRQL  oldIrql;

    ASSERT(pDriverReq);
    pSrb     = pDriverReq->Context1;
    pStrmExt = pDriverReq->Context2;

    if(pSrb == NULL || pStrmExt == NULL) {
        TRACE(TL_STRM_ERROR|TL_CIP_ERROR,("ReqReadDataCR: Context are all NULL!\n"));
        return STATUS_MORE_PROCESSING_REQUIRED;  // Will reuse this irp
    }



    KeAcquireSpinLock(pStrmExt->DataListLock, &oldIrql);
    
    // Count frame procesed
    pStrmExt->FramesProcessed++;
    pStrmExt->cntDataSubmitted--;

#if 1
    // Retrieve current stream time
    if(pStrmExt->hMasterClock) {
        pStrmExt->CurrentStreamTime = pSrb->CommandData.DataBufferArray->PresentationTime.Time;
#if 0
        AVCTapeSignalClockEvent(pStrmExt);
#endif
    }
#endif

#if DBG
    //
    // Check data request completion is in sequence
    //
    if(pStrmExt->FramesProcessed != pDriverReq->cntDataRequestReceived) {
        TRACE(TL_STRM_WARNING,("** OOSeq: Next:%d != Actual:%d **\n", 
            (DWORD) pStrmExt->FramesProcessed, (DWORD) pDriverReq->cntDataRequestReceived));
        // ASSERT(pStrmExt->FramesProcessed == pDriverReq->cntDataRequestReceived);
    }
#endif

    if(!NT_SUCCESS(pIrpReq->IoStatus.Status)) {
        TRACE(TL_STRM_TRACE|TL_CIP_TRACE,("ReadDataReq failed; St:%x; DataUsed:%d\n", pIrpReq->IoStatus.Status,
            pSrb->CommandData.DataBufferArray->DataUsed));
        // Only acceptable status is cancel.
        ASSERT(pIrpReq->IoStatus.Status == STATUS_CANCELLED && "ReadDataReq failed\n");
    } else {
        TRACE(TL_STRM_INFO,("ReadDataReq pSrb:%x; St:%x; DataUsed:%d; Flag:%x\n", pIrpReq->IoStatus.Status, 
            pSrb->CommandData.DataBufferArray->DataUsed, pSrb->CommandData.DataBufferArray->OptionsFlags));
    }

    ASSERT(pIrpReq->IoStatus.Status != STATUS_PENDING);

    pSrb->Status = pIrpReq->IoStatus.Status;

    // Reset them so if this is completed here before the IRP's IoCallDriver is returned,
    // it will not try to complete again.
    pDriverReq->Context1 = NULL;
    pDriverReq->Context2 = NULL;

    // Done; recycle.
    RemoveEntryList(&pDriverReq->ListEntry);  pStrmExt->cntDataAttached--;
    InsertTailList(&pStrmExt->DataDetachedListHead, &pDriverReq->ListEntry); pStrmExt->cntDataDetached++;

    KeReleaseSpinLock(pStrmExt->DataListLock, oldIrql);

    //
    // Signal the graph manager that we are completed.
    //
    if(pSrb->CommandData.DataBufferArray->OptionsFlags & KSSTREAM_HEADER_OPTIONSF_ENDOFSTREAM) {

        StreamClassStreamNotification(
            SignalMultipleStreamEvents,
            pStrmExt->pStrmObject,
            &KSEVENTSETID_Connection,
            KSEVENT_CONNECTION_ENDOFSTREAM
            );
    }

    // Finally, send the srb back up ...
    StreamClassStreamNotification( 
        StreamRequestComplete,
        pSrb->StreamObject,
        pSrb 
        );



    return STATUS_MORE_PROCESSING_REQUIRED;  // Will reuse this irp
} // AVCStrmReqIrpSynchCR


NTSTATUS
AVCTapeGetStreamState(
    PSTREAMEX  pStrmExt,
    IN PDEVICE_OBJECT DeviceObject,
    PKSSTATE   pStreamState,
    PULONG     pulActualBytesTransferred
    )
/*++

Routine Description:

    Gets the current state of the requested stream

--*/
{
    NTSTATUS Status;
    PAVC_STREAM_REQUEST_BLOCK  pAVCStrmReq;

    PAGED_CODE();

    if(!pStrmExt) {
        TRACE(TL_STRM_ERROR,("GetStreamState: pStrmExt:%x; STATUS_UNSUCCESSFUL\n", pStrmExt));
        return STATUS_UNSUCCESSFUL;        
    }

    // 
    // Request AVCStrm to get current stream state
    //
    EnterAVCStrm(pStrmExt->hMutexReq);

    pAVCStrmReq = &pStrmExt->AVCStrmReq;
    RtlZeroMemory(pAVCStrmReq, sizeof(AVC_STREAM_REQUEST_BLOCK));
    INIT_AVCSTRM_HEADER(pAVCStrmReq, AVCSTRM_GET_STATE);
    pAVCStrmReq->AVCStreamContext = pStrmExt->AVCStreamContext;

    Status = 
        AVCStrmReqSubmitIrpSynch( 
            DeviceObject,
            pStrmExt->pIrpReq,
            pAVCStrmReq
            );

    if(!NT_SUCCESS(Status)) {
        TRACE(TL_STRM_ERROR,("AVCSTRM_GET_STATE: failed %x; pAVCStrmReq:%x\n", Status, pAVCStrmReq));
        ASSERT(NT_SUCCESS(Status) && "AVCSTRM_GET_STATE failed!\n");
    }
    else {
        // Save the context, which is used for subsequent call to AVCStrm.sys
        TRACE(TL_STRM_WARNING,("AVCSTRM_GET_STATE: Status:%x; pAVCStrmReq:%x; KSSTATE:%d\n", Status, pAVCStrmReq, pAVCStrmReq->CommandData.StreamState));
        *pStreamState = pAVCStrmReq->CommandData.StreamState;
        *pulActualBytesTransferred = sizeof (KSSTATE);

        // A very odd rule:
        // When transitioning from stop to pause, DShow tries to preroll
        // the graph.  Capture sources can't preroll, and indicate this
        // by returning VFW_S_CANT_CUE in user mode.  To indicate this
        // condition from drivers, they must return ERROR_NO_DATA_DETECTED
        if(   *pStreamState == KSSTATE_PAUSE 
           && pStrmExt->pStrmInfo->DataFlow == KSPIN_DATAFLOW_OUT
          ) 
           Status = STATUS_NO_DATA_DETECTED;
        else 
           Status = STATUS_SUCCESS;
    }

    LeaveAVCStrm(pStrmExt->hMutexReq);

    return Status;
}



NTSTATUS
AVCTapeSetStreamState(
    PSTREAMEX        pStrmExt,
    PDVCR_EXTENSION  pDevExt,
    PAV_61883_REQUEST   pAVReq,
    KSSTATE          StreamState
    )
/*++

Routine Description:

    Sets the stream state via the SRB.

--*/

{
    PAVC_STREAM_REQUEST_BLOCK  pAVCStrmReq;
    NTSTATUS Status;

   
    PAGED_CODE();


    ASSERT(pStrmExt);
    if(pStrmExt == NULL)  {
        return STATUS_UNSUCCESSFUL;      
    }

    Status = STATUS_SUCCESS;

    TRACE(TL_STRM_TRACE,("Set State %d -> %d; PowerSt:%d (1/On;4/Off]); AD [%d,%d]\n", \
        pStrmExt->StreamState, StreamState, pDevExt->PowerState,
        pStrmExt->cntDataAttached,
        pStrmExt->cntDataDetached
        ));

#if DBG
    if(StreamState == KSSTATE_RUN) {
        ASSERT(pDevExt->PowerState == PowerDeviceD0 && "Cannot set to RUN while power is off!");
    }
#endif

    // 
    // Request AVCStrm to set to a new stream state
    //
    EnterAVCStrm(pStrmExt->hMutexReq);

    pAVCStrmReq = &pStrmExt->AVCStrmReq;
    RtlZeroMemory(pAVCStrmReq, sizeof(AVC_STREAM_REQUEST_BLOCK));
    INIT_AVCSTRM_HEADER(pAVCStrmReq, AVCSTRM_SET_STATE);
    pAVCStrmReq->AVCStreamContext = pStrmExt->AVCStreamContext;
    pAVCStrmReq->CommandData.StreamState = StreamState;

    Status = 
        AVCStrmReqSubmitIrpSynch( 
            pDevExt->pBusDeviceObject,
            pStrmExt->pIrpReq,
            pAVCStrmReq
            );

    if(!NT_SUCCESS(Status)) {
        TRACE(TL_STRM_ERROR,("AVCSTRM_SET_STATE: failed %x; pAVCStrmReq:%x\n", Status, pAVCStrmReq));
        ASSERT(NT_SUCCESS(Status) && "AVCSTRM_SET_STATE failed!\n");
    }
    else {
        // Save the context, which is used for subsequent call to AVCStrm.sys
        TRACE(TL_STRM_TRACE,("AVCSTRM_SET_STATE: Status:%x; pAVCStrmReq:%x, new KSSTATE:%d\n", Status, pAVCStrmReq, pAVCStrmReq->CommandData.StreamState));

        // Reset the abort state
        if(pStrmExt->StreamState == KSSTATE_STOP && StreamState == KSSTATE_ACQUIRE)
            pStrmExt->AbortInProgress  = FALSE;


        // Reaction due to state change
        switch(StreamState) {
        case KSSTATE_STOP:
            TRACE(TL_STRM_TRACE,("SrbRcv:%d, Processed:%d; Pending:%d\n", (DWORD) pStrmExt->cntSRBReceived, (DWORD) pStrmExt->FramesProcessed, (DWORD) pStrmExt->cntDataSubmitted));
            // Reset it
            pStrmExt->cntSRBReceived = pStrmExt->FramesProcessed = pStrmExt->cntDataSubmitted = 0;
            pStrmExt->CurrentStreamTime = 0;  
            break;

        case KSSTATE_PAUSE:
            // For DV input pin, setup a timer DPC to periodically fired to singal clock event.
            if(pStrmExt->hMasterClock && pDevExt->VideoFormatIndex != AVCSTRM_FORMAT_MPEG2TS && pStrmExt->StreamState == KSSTATE_RUN) {
               // Cancel timer
#if 1
                TRACE(TL_STRM_TRACE,("*** (RUN->PAUSE) CancelTimer *********************************************...\n"));
                KeCancelTimer(
                    &pStrmExt->Timer
                    );
#endif
            }
            break;

        case KSSTATE_RUN:
            // For DV input pin, setup a timer DPC to periodically fired to singal clock event.
            if(pStrmExt->hMasterClock &&
               pDevExt->VideoFormatIndex != AVCSTRM_FORMAT_MPEG2TS) {
                LARGE_INTEGER DueTime;
#define CLOCK_INTERVAL 20 // Unit=MilliSeconds

#if 0
                // For DV input pin, setup a timer DPC to periodically fired to singal clock event.
                KeInitializeDpc(
                    &pStrmExt->DPCTimer,
                    AVCTapeSignalClockEvent,
                    pStrmExt
                    );
                KeInitializeTimer(
                    &pStrmExt->Timer              
                    );    
#endif

                DueTime = RtlConvertLongToLargeInteger(-CLOCK_INTERVAL * 10000);
                TRACE(TL_STRM_TRACE,("*** ScheduleTimer (RUN) *****************************************...\n"));
                KeSetTimerEx(
                    &pStrmExt->Timer,
                    DueTime,
                    CLOCK_INTERVAL,  // Repeat every 40 MilliSecond
                    &pStrmExt->DPCTimer
                    );
            }
            break;
        default:
            break;
        }

            // Cache the current state
        pStrmExt->StreamState = StreamState;
    }

    LeaveAVCStrm(pStrmExt->hMutexReq);

    return Status;
}



NTSTATUS 
DVStreamGetConnectionProperty (
    PDVCR_EXTENSION pDevExt,
    PSTREAM_PROPERTY_DESCRIPTOR pSPD,
    PULONG pulActualBytesTransferred
    )
/*++

Routine Description:

    Handles KS_PROPERTY_CONNECTION* request.  For now, only ALLOCATORFRAMING and
    CONNECTION_STATE are supported.

--*/
{
    NTSTATUS Status = STATUS_SUCCESS;

    PAGED_CODE();

    switch (pSPD->Property->Id) {

    case KSPROPERTY_CONNECTION_ALLOCATORFRAMING:
        if (pDevExt != NULL && pDevExt->cndStrmOpen)  {
            PKSALLOCATOR_FRAMING pFraming = (PKSALLOCATOR_FRAMING) pSPD->PropertyInfo;
            
            pFraming->RequirementsFlags =
                KSALLOCATOR_REQUIREMENTF_SYSTEM_MEMORY |
                KSALLOCATOR_REQUIREMENTF_INPLACE_MODIFIER |
                KSALLOCATOR_REQUIREMENTF_PREFERENCES_ONLY;
            pFraming->PoolType = NonPagedPool;

            pFraming->Frames = \
                pDevExt->paStrmExt[pDevExt->idxStreamNumber]->pStrmInfo->DataFlow == KSPIN_DATAFLOW_OUT ? \
                AVCStrmFormatInfoTable[pDevExt->VideoFormatIndex].NumOfRcvBuffers : \
                 AVCStrmFormatInfoTable[pDevExt->VideoFormatIndex].NumOfXmtBuffers;

            // Note:  we'll allocate the biggest frame.  We need to make sure when we're
            // passing the frame back up we also set the number of bytes in the frame.
            pFraming->FrameSize = AVCStrmFormatInfoTable[pDevExt->VideoFormatIndex].FrameSize;
            pFraming->FileAlignment = 0; // FILE_LONG_ALIGNMENT;
            pFraming->Reserved = 0;
            *pulActualBytesTransferred = sizeof (KSALLOCATOR_FRAMING);

            TRACE(TL_STRM_TRACE,("*** AllocFraming: cntStrmOpen:%d; VdoFmtIdx:%d; Frames %d; size:%d\n", \
                pDevExt->cndStrmOpen, pDevExt->VideoFormatIndex, pFraming->Frames, pFraming->FrameSize));
        } else {
            Status = STATUS_INVALID_PARAMETER;
        }
        break;
        
    default:
        *pulActualBytesTransferred = 0;
        Status = STATUS_NOT_SUPPORTED;
        ASSERT(pSPD->Property->Id == KSPROPERTY_CONNECTION_ALLOCATORFRAMING);
        break;
    }

    return Status;
}


NTSTATUS
DVGetDroppedFramesProperty(  
    PDVCR_EXTENSION pDevExt,
    PSTREAMEX       pStrmExt,
    PSTREAM_PROPERTY_DESCRIPTOR pSPD,
    PULONG pulBytesTransferred
    )
/*++

Routine Description:

    Return the dropped frame information while captureing.

--*/
{
    NTSTATUS Status = STATUS_SUCCESS;
  
    PAGED_CODE();

    switch (pSPD->Property->Id) {

    case KSPROPERTY_DROPPEDFRAMES_CURRENT:
         {

         PKSPROPERTY_DROPPEDFRAMES_CURRENT_S pDroppedFrames = 
                     (PKSPROPERTY_DROPPEDFRAMES_CURRENT_S) pSPD->PropertyInfo;
         
         pDroppedFrames->AverageFrameSize = AVCStrmFormatInfoTable[pStrmExt->pDevExt->VideoFormatIndex].FrameSize;

         if(pStrmExt->pStrmInfo->DataFlow == KSPIN_DATAFLOW_IN) {     
#if 0
             // pStrmExt->PictureNumber is not returned since it might be greater than number of SRBs returned.
             // pStrmExt->CurrentStreamTime >= pDroppedFrames->PictureNumber * (ulAvgTimePerFrame)
             // CurrentStreamTime will be ahead if there is repeat frame and the data source
             // cannot keep up with the constant data transfer of 29.97 (or 25) FPS; therefore,
             // repeat frame might have inserted and the last data in the last SRB is transferred.
             // To resolve this, an application can query PictureNumber and CurrentStreamTime and
             // does a read ahead of their delta to "catch up".
             pDroppedFrames->PictureNumber = pStrmExt->FramesProcessed + pStrmExt->FramesDropped;   
#else
             // This is the picture number that MSDV is actually sending, and in a slow harddisk case,
             // it will be greater than (FramesProcessed + FramesDropped) considering repeat frame.
             pDroppedFrames->PictureNumber = pStrmExt->PictureNumber;
#endif
         } else {
             pDroppedFrames->PictureNumber = pStrmExt->PictureNumber;
         }
         pDroppedFrames->DropCount        = pStrmExt->FramesDropped;    // For transmit, this value includes both dropped and repeated.

         TRACE(TL_STRM_TRACE,("*DroppedFP: Pic#(%d), Drp(%d)\n", (LONG) pDroppedFrames->PictureNumber, (LONG) pDroppedFrames->DropCount));
               
         *pulBytesTransferred = sizeof (KSPROPERTY_DROPPEDFRAMES_CURRENT_S);
         Status = STATUS_SUCCESS;

         }
         break;

    default:
        *pulBytesTransferred = 0;
        Status = STATUS_NOT_SUPPORTED;
        ASSERT(pSPD->Property->Id == KSPROPERTY_DROPPEDFRAMES_CURRENT);
        break;
    }

    return Status;
}


NTSTATUS
DVGetStreamProperty(
    PHW_STREAM_REQUEST_BLOCK pSrb
    )
/*++

Routine Description:

    Routine to process property request

--*/

{
    NTSTATUS Status = STATUS_SUCCESS;
    PSTREAM_PROPERTY_DESCRIPTOR pSPD = pSrb->CommandData.PropertyInfo;

    PAGED_CODE();

    if(IsEqualGUID (&KSPROPSETID_Connection, &pSPD->Property->Set)) {

        Status = 
            DVStreamGetConnectionProperty (
                pSrb->HwDeviceExtension,
                pSrb->CommandData.PropertyInfo,
                &pSrb->ActualBytesTransferred
                );
    } 
    else if (IsEqualGUID (&PROPSETID_VIDCAP_DROPPEDFRAMES, &pSPD->Property->Set)) {

        Status = 
            DVGetDroppedFramesProperty (
                pSrb->HwDeviceExtension,
                (PSTREAMEX) pSrb->StreamObject->HwStreamExtension,
                pSrb->CommandData.PropertyInfo,
                &pSrb->ActualBytesTransferred
                );
    } 
    else {
        Status = STATUS_NOT_SUPPORTED;
    }

    return Status;
}


NTSTATUS 
DVSetStreamProperty(
    PHW_STREAM_REQUEST_BLOCK pSrb
    )
/*++

Routine Description:

    Routine to process set property request

--*/

{
    PSTREAM_PROPERTY_DESCRIPTOR pSPD = pSrb->CommandData.PropertyInfo;

    PAGED_CODE();

    TRACE(TL_STRM_TRACE,("SetStreamProperty:  entered ...\n"));

    return STATUS_NOT_SUPPORTED;

}


void
DVCancelSrbWorkItemRoutine(
#ifdef USE_WDM110  // Win2000 code base
    // Extra parameter if using WDM10
    PDEVICE_OBJECT DeviceObject,
#endif
    PSTREAMEX  pStrmExt
    )
/*++

Routine Description:

   This work item routine will stop streaming and cancel all SRBs.   

--*/
{
    PAVC_STREAM_REQUEST_BLOCK  pAVCStrmReq;
    NTSTATUS Status;
    NTSTATUS StatusWait;

    PAGED_CODE();

    TRACE(TL_STRM_WARNING,("CancelWorkItem: StreamState:%d; lCancel:%d\n", pStrmExt->StreamState, pStrmExt->lCancelStateWorkItem));
    ASSERT(pStrmExt->lCancelStateWorkItem == 1);
#ifdef USE_WDM110  // Win2000 code base
    ASSERT(pStrmExt->pIoWorkItem);
#endif

    // Synchronize 
    //    streaming state, and 
    //    incoming streaming data SRBs
    StatusWait = 
        KeWaitForMutexObject(pStrmExt->hMutexFlow, Executive, KernelMode, FALSE, NULL);
    ASSERT(StatusWait == STATUS_SUCCESS);

    // 
    // We get here usually as a result of a thread was terminated and it needs to cancel irps.
    // We therefore abort streaming.
    //
    pAVCStrmReq = &pStrmExt->AVCStrmReqAbort;

    RtlZeroMemory(pAVCStrmReq, sizeof(AVC_STREAM_REQUEST_BLOCK));
    INIT_AVCSTRM_HEADER(pAVCStrmReq, AVCSTRM_ABORT_STREAMING);
    pAVCStrmReq->AVCStreamContext = pStrmExt->AVCStreamContext;

    Status = 
        AVCStrmReqSubmitIrpSynch( 
            pStrmExt->pDevExt->pBusDeviceObject,
            pStrmExt->pIrpAbort,
            pAVCStrmReq
            );

#if DBG
    if(Status != STATUS_SUCCESS) {
        TRACE(TL_STRM_ERROR,("Abort streaming status:%x\n", Status));
        ASSERT(Status == STATUS_SUCCESS && "Abort streaming failed\n");
    }
#endif

    KeReleaseMutex(pStrmExt->hMutexFlow, FALSE);  

#ifdef USE_WDM110  // Win2000 code base
    // Release work item and release the cancel token
    IoFreeWorkItem(pStrmExt->pIoWorkItem);  pStrmExt->pIoWorkItem = NULL; 
#endif
    pStrmExt->AbortInProgress = TRUE;
    InterlockedExchange(&pStrmExt->lCancelStateWorkItem, 0);
    KeSetEvent(&pStrmExt->hCancelDoneEvent, 0, FALSE);
}

VOID
AVCTapeCreateAbortWorkItem(
    PDVCR_EXTENSION pDevExt,
    PSTREAMEX pStrmExt
    )
{    
    // Claim this token
    if(InterlockedExchange(&pStrmExt->lCancelStateWorkItem, 1) == 1) {
        TRACE(TL_STRM_WARNING,("Cancel work item is already issued.\n"));
        return;
    }
    // Cancel is already in progress
    if(pStrmExt->AbortInProgress) {
        TRACE(TL_STRM_WARNING,("Cancel work item is already in progress.\n"));
        return;
    }

#ifdef USE_WDM110  // Win2000 code base
    ASSERT(pStrmExt->pIoWorkItem == NULL);  // Have not yet queued work item.

    // We will queue work item to stop and cancel all SRBs
    if(pStrmExt->pIoWorkItem = IoAllocateWorkItem(pDevExt->pBusDeviceObject)) { 

        // Set to non-signal
        KeClearEvent(&pStrmExt->hCancelDoneEvent);  // Before queuing; just in case it return the work item is completed.

        IoQueueWorkItem(
            pStrmExt->pIoWorkItem,
            DVCancelSrbWorkItemRoutine,
            DelayedWorkQueue, // CriticalWorkQueue 
            pStrmExt
            );

#else  // Win9x code base
    ExInitializeWorkItem( &pStrmExt->IoWorkItem, DVCancelSrbWorkItemRoutine, pStrmExt);
    if(TRUE) {

        // Set to non-signal
        KeClearEvent(&pStrmExt->hCancelDoneEvent);  // Before queuing; just in case it return the work item is completed.

        ExQueueWorkItem( 
            &pStrmExt->IoWorkItem,
            DelayedWorkQueue // CriticalWorkQueue 
            ); 
#endif

        TRACE(TL_STRM_WARNING,("CancelWorkItm queued\n"));
    } 
#ifdef USE_WDM110  // Win2000 code base
    else {
        InterlockedExchange(&pStrmExt->lCancelStateWorkItem, 0);
        ASSERT(pStrmExt->pIoWorkItem && "IoAllocateWorkItem failed.\n");
    }
#endif
}


VOID
DVCRCancelOnePacket(
    IN PHW_STREAM_REQUEST_BLOCK pSrbToCancel
    )
/*++

Routine Description:

   Search pending read lists for the SRB to be cancel.  If found cancel it.   

--*/
{
    PDVCR_EXTENSION pDevExt;
    PSTREAMEX pStrmExt;

                                                                                                              
    pDevExt = (PDVCR_EXTENSION) pSrbToCancel->HwDeviceExtension; 
               
    // Cannot cancel device Srb.
    if ((pSrbToCancel->Flags & SRB_HW_FLAGS_STREAM_REQUEST) != SRB_HW_FLAGS_STREAM_REQUEST) {
        TRACE(TL_PNP_WARNING,("CancelOnePacket: Device SRB %x; cannot cancel!\n", pSrbToCancel));
        ASSERT((pSrbToCancel->Flags & SRB_HW_FLAGS_STREAM_REQUEST) == SRB_HW_FLAGS_STREAM_REQUEST );
        return;
    }         
        
    // Can try to cancel a stream Srb and only if the stream extension still around.
    pStrmExt = (PSTREAMEX) pSrbToCancel->StreamObject->HwStreamExtension;
    if(pStrmExt == NULL) {
        TRACE(TL_PNP_ERROR,("CancelOnePacket: pSrbTocancel %x but pStrmExt %x\n", pSrbToCancel, pStrmExt));
        ASSERT(pStrmExt && "Stream SRB but stream extension is NULL\n");
        return;
    }

    // We can only cancel SRB_READ/WRITE_DATA SRB
    if((pSrbToCancel->Command != SRB_READ_DATA) && (pSrbToCancel->Command != SRB_WRITE_DATA)) {
        TRACE(TL_PNP_ERROR,("CancelOnePacket: pSrbTocancel %x; Command:%d not SRB_READ,WRITE_DATA\n", pSrbToCancel, pSrbToCancel->Command));
        ASSERT(pSrbToCancel->Command == SRB_READ_DATA || pSrbToCancel->Command == SRB_WRITE_DATA);
        return;
    }

    TRACE(TL_STRM_TRACE,("CancelOnePacket: KSSt %d; Srb:%x;\n", pStrmExt->StreamState, pSrbToCancel));


    // This is called at DispatchLevel.
    // We will create a work item to do the cancelling (detaching buffers) at the passive level.
    AVCTapeCreateAbortWorkItem(pDevExt, pStrmExt);
}



VOID
DVTimeoutHandler(
    IN PHW_STREAM_REQUEST_BLOCK pSrb
    )

/*++

Routine Description:

    This routine is called when a packet has been in the minidriver too long.
    It can only valid if we are it wa a streaming packet and in PAUSE state;
    else we have a problem!

Arguments:

    pSrb - Pointer to Stream request block

Return Value:

    Nothing

--*/

{
    //
    // Note:
    //    Called from StreamClass at DisptchLevel
    //    

    //
    // We only expect stream SRB, but not device SRB.  
    //

    if ( (pSrb->Flags & SRB_HW_FLAGS_STREAM_REQUEST) != SRB_HW_FLAGS_STREAM_REQUEST) {
        TRACE(TL_PNP_WARNING,("TimeoutHandler: Device SRB %x timed out!\n", pSrb));
        ASSERT((pSrb->Flags & SRB_HW_FLAGS_STREAM_REQUEST) == SRB_HW_FLAGS_STREAM_REQUEST );
        return;
    } else {

        //
        // pSrb->StreamObject (and pStrmExt) only valid if it is a stream SRB
        //
        PSTREAMEX pStrmExt;

        pStrmExt = (PSTREAMEX) pSrb->StreamObject->HwStreamExtension;
        ASSERT(pStrmExt);

        if(!pStrmExt) {
            TRACE(TL_PNP_ERROR,("TimeoutHandler: Stream SRB %x timeout with ppStrmExt %x\n", pSrb, pStrmExt));
            ASSERT(pStrmExt);
            return;
        }

        //
        // Reset Timeout counter, or we are going to get this call immediately.
        //

        pSrb->TimeoutCounter = pSrb->TimeoutOriginal;
    }
}



NTSTATUS 
AVCTapeEventHandler(
    IN PHW_EVENT_DESCRIPTOR pEventDescriptor
    )
/*++

Routine Description:

    This routine is called to enable/disable and possibly process events.

--*/
{
    PKSEVENT_TIME_MARK  pEventTime;
    PSTREAMEX  pStrmExt;

    if(IsEqualGUID (&KSEVENTSETID_Clock, pEventDescriptor->EventEntry->EventSet->Set)) {
        if(pEventDescriptor->EventEntry->EventItem->EventId == KSEVENT_CLOCK_POSITION_MARK) {
            if(pEventDescriptor->Enable) {
                // Note: According to the DDK, StreamClass queues pEventDescriptor->EventEntry, and dellaocate
                // every other structures, including the pEventDescriptor->EventData.
                if(pEventDescriptor->StreamObject) { 
                    pStrmExt = (PSTREAMEX) pEventDescriptor->StreamObject->HwStreamExtension;
                    pEventTime = (PKSEVENT_TIME_MARK) pEventDescriptor->EventData;
                    // Cache the event data (Specified in the ExtraEntryData of KSEVENT_ITEM)
                    RtlCopyMemory((pEventDescriptor->EventEntry+1), pEventDescriptor->EventData, sizeof(KSEVENT_TIME_MARK));
                    TRACE(TL_CLK_TRACE,("CurrentStreamTime:%d, MarkTime:%d\n", (DWORD) pStrmExt->CurrentStreamTime, (DWORD) pEventTime->MarkTime));
                }
            } else {
               // Disabled!
                TRACE(TL_CLK_TRACE,("KSEVENT_CLOCK_POSITION_MARK disabled!\n"));            
            }
            return STATUS_SUCCESS;
        }
    } else if(IsEqualGUID (&KSEVENTSETID_Connection, pEventDescriptor->EventEntry->EventSet->Set)) {
        TRACE(TL_STRM_TRACE,("Connecytion event: pEventDescriptor:%x; id:%d\n", pEventDescriptor, pEventDescriptor->EventEntry->EventItem->EventId));
        if(pEventDescriptor->EventEntry->EventItem->EventId == KSEVENT_CONNECTION_ENDOFSTREAM) {
            if(pEventDescriptor->Enable) {
                TRACE(TL_STRM_TRACE,("KSEVENT_CONNECTION_ENDOFSTREAM enabled!\n"));
            } else {
                TRACE(TL_STRM_TRACE,("KSEVENT_CONNECTION_ENDOFSTREAM disabled!\n"));            
            }
            return STATUS_SUCCESS;
        }
    }

    TRACE(TL_PNP_ERROR|TL_CLK_ERROR,("NOT_SUPPORTED event: pEventDescriptor:%x\n", pEventDescriptor));
    ASSERT(FALSE);

    return STATUS_NOT_SUPPORTED;
}

VOID
AVCTapeSignalClockEvent(
    IN PKDPC Dpc,
    
    IN PSTREAMEX  pStrmExt,

    IN PVOID SystemArgument1,
    IN PVOID SystemArgument2    
)
/*++

Routine Description:

    This routine is called when we are the clock provider and when our clock "tick".  
    Find a pending clock event, signal it if it has expired.

--*/
{
    PKSEVENT_ENTRY pEvent, pLast;

    pEvent = NULL;
    pLast = NULL;

    while(( 
        pEvent = StreamClassGetNextEvent(
            pStrmExt->pDevExt,
            pStrmExt->pStrmObject,
            (GUID *)&KSEVENTSETID_Clock,
            KSEVENT_CLOCK_POSITION_MARK,
            pLast )) 
        != NULL ) {

#if 1
#define CLOCK_ADJUSTMENT  400000
        if (((PKSEVENT_TIME_MARK)(pEvent +1))->MarkTime <= pStrmExt->CurrentStreamTime + CLOCK_ADJUSTMENT) {
#else
        if (((PKSEVENT_TIME_MARK)(pEvent +1))->MarkTime <= pStrmExt->CurrentStreamTime) {
#endif
            TRACE(TL_CLK_TRACE,("Clock event %x with id %d; Data:%x; tmMark:%d; tmCurrentStream:%d; Notify!\n", 
                pEvent, KSEVENT_CLOCK_POSITION_MARK, (PKSEVENT_TIME_MARK)(pEvent +1),
                (DWORD) (((PKSEVENT_TIME_MARK)(pEvent +1))->MarkTime), (DWORD) pStrmExt->CurrentStreamTime));
            ASSERT( ((PKSEVENT_TIME_MARK)(pEvent +1))->MarkTime != 0 );

            //
            // signal the event here
            //
            StreamClassStreamNotification(
                SignalStreamEvent,
                pStrmExt->pStrmObject,
                pEvent
                );
        } else {
            TRACE(TL_CLK_WARNING,("Still early! ClockEvent: MarkTime:%d, tmStream%d\n",
                (DWORD) (((PKSEVENT_TIME_MARK)(pEvent +1))->MarkTime), (DWORD) pStrmExt->CurrentStreamTime));

        }
        pLast = pEvent;
    }

#if DBG
    if(pLast == NULL) {
        TRACE(TL_CLK_WARNING,("No clock event in the queued! State:%d; tmCurrentStream:%d\n", pStrmExt->StreamState, (DWORD) pStrmExt->CurrentStreamTime));
    }
#endif

}

VOID 
AVCTapeStreamClockRtn(
    IN PHW_TIME_CONTEXT TimeContext
    )
/*++

Routine Description:

    This routine is called whenever someone in the graph wants to know what time it is, and we are the Master Clock.

--*/
{
    PDVCR_EXTENSION    pDevExt;
    PHW_STREAM_OBJECT  pStrmObj;
    PSTREAMEX          pStrmExt;
    
    // Call at dispatch level

    pDevExt  = (PDVCR_EXTENSION) TimeContext->HwDeviceExtension;
    pStrmObj = TimeContext->HwStreamObject;
    if(pStrmObj)
        pStrmExt = pStrmObj->HwStreamExtension;
    else 
        pStrmExt = 0;

    if(!pDevExt || !pStrmExt) {
        ASSERT(pDevExt && pStrmExt);
        return;
    }


    switch (TimeContext->Function) {
    
    case TIME_GET_STREAM_TIME:

        //
        // How long since the stream was first set into the run state?
        //
        ASSERT(pStrmExt->hMasterClock && "We are not master clock but we were qureied?");
        TimeContext->Time = pStrmExt->CurrentStreamTime;
        TimeContext->SystemTime = GetSystemTime();

        TRACE(TL_STRM_WARNING|TL_CLK_TRACE,("State:%d; tmStream:%d tmSys:%d\n", pStrmExt->StreamState, (DWORD) TimeContext->Time, (DWORD) TimeContext->SystemTime ));  
        break;
   
    default:
        ASSERT(TimeContext->Function == TIME_GET_STREAM_TIME && "Unsupport clock func");
        break;
    } // switch TimeContext->Function
}


NTSTATUS 
AVCTapeOpenCloseMasterClock (
    PSTREAMEX  pStrmExt,
    HANDLE  hMasterClockHandle
    )
/*++

Routine Description:

    We can be a clock provider.

--*/
{

    PAGED_CODE();

    // Make sure the stream exist.
    if(pStrmExt == NULL) {
        TRACE(TL_STRM_ERROR|TL_CLK_ERROR,("OpenCloseMasterClock: stream is not yet running.\n"));
        ASSERT(pStrmExt);
        return  STATUS_UNSUCCESSFUL;
    } 

    TRACE(TL_CLK_WARNING,("OpenCloseMasterClock: pStrmExt %x; hMyClock:%x->%x\n", 
        pStrmExt, pStrmExt->hMyClock, hMasterClockHandle));

    if(hMasterClockHandle) {
        // Open master clock
        ASSERT(pStrmExt->hMyClock == NULL && "OpenMasterClk while hMyClock is not NULL!");
        pStrmExt->hMyClock = hMasterClockHandle;
    } else {
        // Close master clock
        ASSERT(pStrmExt->hMyClock && "CloseMasterClk while hMyClock is NULL!");
        pStrmExt->hMyClock = NULL;
    }
    return STATUS_SUCCESS;
}


NTSTATUS 
AVCTapeIndicateMasterClock (
    PSTREAMEX  pStrmExt,
    HANDLE  hIndicateClockHandle
    )
/*++

Routine Description:

    Compare the indicate clock handle with my clock handle.
    If the same, we are the master clock; else, other device is 
    the master clock.

    Note: either hMasterClock or hClock can be set.

--*/
{
    PAGED_CODE();

    // Make sure the stream exist.
    if (pStrmExt == NULL) {
        TRACE(TL_STRM_ERROR|TL_CLK_ERROR,("AVCTapeIndicateMasterClock: stream is not yet running.\n"));
        ASSERT(pStrmExt);
        return STATUS_UNSUCCESSFUL;
    }

    TRACE(TL_STRM_TRACE|TL_CLK_WARNING,("IndicateMasterClock[Enter]: pStrmExt:%x; hMyClk:%x; IndMClk:%x; pClk:%x, pMClk:%x\n",
        pStrmExt, pStrmExt->hMyClock, hIndicateClockHandle, pStrmExt->hClock, pStrmExt->hMasterClock));

    // it not null, set master clock accordingly.    
    if(hIndicateClockHandle == pStrmExt->hMyClock) {
        pStrmExt->hMasterClock = hIndicateClockHandle;
        pStrmExt->hClock       = NULL;
    } else {
        pStrmExt->hMasterClock = NULL;
        pStrmExt->hClock       = hIndicateClockHandle;
    }

    TRACE(TL_STRM_TRACE|TL_CLK_TRACE,("IndicateMasterClk[Exit]: hMyClk:%x; IndMClk:%x; pClk:%x; pMClk:%x\n",
        pStrmExt->hMyClock, hIndicateClockHandle, pStrmExt->hClock, pStrmExt->hMasterClock));

    return STATUS_SUCCESS;
}
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\drivers\wdm\capture\mini\mstape\sources.inc ===
#############################################################################
#
#       Confidential Microsoft
#       Copyright (C) Microsoft Corporation 2000-2001
#       All Rights Reserved.
#                                                                          
#       Sources for 1394 Tape subunit driver
#
##########################################################################

TARGETNAME=mstape
TARGETPATH=obj
TARGETTYPE=DRIVER
DRIVERTYPE=WDM

USE_MAPSYM      = 1

INCLUDES=$(MULTIMEDIA_INC_PATH);$(SDK_PATH)\amovie\inc;

TARGETLIBS= \
    $(DDK_LIB_PATH)\stream.lib \
    $(DDK_LIB_PATH)\ksguid.lib

SOURCES= \
    MsTpUtil.c\
    MsTpUppr.c\
    MsTpGuts.c\
    MsTpAvc.c\
    MsTape.rc
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\drivers\wdm\capture\mini\mstape\mstpdef.h ===
/*++

Copyright (C) Microsoft Corporation, 2000 - 2001

Module Name:

    MsTpDef.h

Abstract:

    Header file for all of AV/C tape subunit

Last changed by:
    
    $Author::                $

Environment:

    Kernel mode only

Revision History:

    $Revision::                    $
    $Date::                        $

--*/

#ifndef _DVCRDEF_INC
#define _DVCRDEF_INC


#include "AVCStrm.h"

#define DRIVER_TAG (ULONG)'USpT'  // Tape SubUnit

#undef ExAllocatePool
#define ExAllocatePool(type, size) \
            ExAllocatePoolWithTag (type, size, DRIVER_TAG)


//
// In order to send a request to lower driver, we need an irp and the request block.
// 
typedef struct _DRIVER_REQUEST {

    //
    // Link with other request (in attach or detach list)
    //
    LIST_ENTRY ListEntry;

    //
    // Some context and reserved
    //
    PVOID Context1;
    PVOID Context2;

#if DBG
    //
    // Unique id of this data request
    //
    LONGLONG cntDataRequestReceived;
#endif

    //
    // Irp used to send down a reqest
    //
    PIRP pIrp;

    //
    // Request block
    //
    AVC_STREAM_REQUEST_BLOCK AVCStrmReq;

} DRIVER_REQUEST, *PDRIVER_REQUEST;

//
// Need to reference this in PSTRMEX
//
typedef struct _DVCR_EXTENSION;



// 
// The index MUST match 
//
typedef enum {

    FMT_IDX_SD_DVCR_NTSC = 0,
    FMT_IDX_SD_DVCR_PAL,

#ifdef MSDV_SUPPORT_HD_DVCR
    FMT_IDX_HD_DVCR_NTSC,
    FMT_IDX_HD_DVCR_PAL,
#endif

#ifdef MSDV_SUPPORT_SDL_DVCR
    FMT_IDX_SDL_DVCR_NTSC,
    FMT_IDX_SDL_DVCR_PAL,
#endif

} FMT_INDEX, *PFMT_INDEX;


#define MAX_DATA_BUFFERS  32                    // Max data buffer (allocator framing)
#define MAX_DATA_REQUESTS (MAX_DATA_BUFFERS+2)  // 2 extra for optional flags "data request", such as EndOfStream.

//
// this structure is our per stream extension structure.  This stores
// information that is relevant on a per stream basis.  Whenever a new stream
// is opened, the stream class driver will allocate whatever extension size
// is specified in the HwInitData.PerStreamExtensionSize.
//
 
typedef struct _STREAMEX {

    // return stream exension (a context) if a stream is open successfully
    // This context is used for subsequent call after a stream is opened.
    PVOID  AVCStreamContext;

    //
    // Point to pSrb->HwDeviceExtension
    // 
    struct _DVCR_EXTENSION * pDevExt;

    //
    // Cache pSrb->StreamObject:
    //     ->HwStreamExtension  (pStrmExt)
    //     ->StreamNumber
    //     ->HwDeviceExtension  (pDevExt)
    //
    PHW_STREAM_OBJECT  pStrmObject;      


    //
    //  ->NumberOfPossibleInstances;
    //  ->DataFlow;
    //
    PHW_STREAM_INFORMATION pStrmInfo;
    
    //
    // Holds state
    //
    KSSTATE StreamState;

    //
    // Holds whether or not the dvcr is listening or receiving
    //
    // TRUE:  successful REQUEST_ISOCH_LISTEN and REQUEST_ISOCH_TALK
    // FALSE: successful INIT and REQUEST_ISOCH_STOP
    //
    BOOLEAN bIsochIsActive;  // Close associated with StreamState

    //
    // Set to TRUE when receiving KSSTREAM_HEADER_OPTIONSF_ENDOFSTREAM for SRB_WRITE_DATA
    // For SRB_WRITE_DATA only since then this driver servers as a renderer.
    //
    BOOL      bEOStream;  

    //
    // Count number of SRB_READ/WRITE_DATA received since last transiting to PAUSE state from STOP
    //
    LONGLONG  cntSRBReceived;


    //
    // Count number of Data buffer has submitted for receiving or transmitting.
    //
    LONGLONG  cntDataSubmitted;

    //
    // Statistic of the frame information since last start stream
    // PictureNumber = FramesProcessed + FramesDropped + cndSRBCancelled.
    //    
    LONGLONG  FramesProcessed;   // Frame sent (including repeated)
    LONGLONG  FramesDropped;     // SRB not sent
    LONGLONG  PictureNumber;     // Number of SRB_XXX_DATA made it to or from 1394 bus

    //
    // Count number of SRB_READ/WRITE_DATA that was incompleted and cancelled
    //
    LONGLONG  cntSRBCancelled;


    //
    // The stream time (master clock or not) is "almost" or near 0 
    // when setting to RUN state and start increment.
    //
    LONGLONG CurrentStreamTime;

    //
    // Holds the master clock
    //
    HANDLE hMyClock;       // If set, we can be a clock provider.
    HANDLE hMasterClock;   // If set, we are the master clock.
    HANDLE hClock;         // If set, other device on the same graph is the master clock.



    //
    // 2nd CIP Quadlet: 01:Fmt, 50/60:STYPE:RSv, SYT
    //
    BYTE cipQuad2[4];

    //
    // Timecode, RecDate and RecTime are all in pack format (4 bytes)
    //
    BOOL bATNUpdated;
    DWORD AbsTrackNumber; // LSB:BlankField   

    BOOL bTimecodeUpdated;
    BYTE Timecode[4];     // hh:mm:ss,ff

    //
    // Regulate flow between between setting to STOP state and SRB_XXX_DATA
    //
    KMUTEX * hMutexFlow;


    //
    // Counter used to indicate starting of an work item to cancel 
    //
    LONG  lCancelStateWorkItem;
    BOOL  AbortInProgress;

    //
    // Hold the work item
    //
#ifdef USE_WDM110  // Win2000 code base
    PIO_WORKITEM       pIoWorkItem;
#else
    WORK_QUEUE_ITEM    IoWorkItem;
#endif

    //
    // TO singal that an work item is completed.
    //
    KEVENT hCancelDoneEvent;

    //
    // Stream open format
    //
    AVCSTRM_FORMAT_INFO  AVCFormatInfo;

    //
    // AVCStrm request for issuing synchronous request
    
    KMUTEX * hMutexReq;

    PIRP pIrpReq;
    AVC_STREAM_REQUEST_BLOCK AVCStrmReq;

    //
    // free list
    //
    LONG       cntDataDetached;
    LIST_ENTRY DataDetachedListHead;

    //
    // busy list
    //
    LONG       cntDataAttached;
    LIST_ENTRY DataAttachedListHead;

    //
    // AVCStrem request for asynchronous request, such as read and write data
    //
    DRIVER_REQUEST  AsyncReq[MAX_DATA_REQUESTS];  

    //
    // AVCStrm request for issuing synchronous request to abort at DISPATCH_LEVEL
    //
    PIRP pIrpAbort;
    AVC_STREAM_REQUEST_BLOCK AVCStrmReqAbort;

    //
    // Data list lock
    // 
    KSPIN_LOCK * DataListLock;

    // 
    // DPC and TIMER objects; this is used for the signal clock events.
    //
    KDPC   DPCTimer;

    KTIMER Timer;


} STREAMEX, *PSTREAMEX;


//
// Max number of input and output PCR an AVC can support
//
#define MAX_NUM_PCR  31  

#define MAX_PAYLOAD 1024 

//
// Structure for a plug control register
//
typedef struct _AVC_DEV_PLUG {
    //
    // Plug handle of a PCR returned from 61883.sys
    //
    HANDLE hPlug;

    //
    // PCR's state; this is dynamic and is consider as a snap shot.
    //
    CMP_GET_PLUG_STATE PlugState;

} AVC_DEV_PLUG, *PAVC_DEV_PLUG;


//
// Structure for a max (31) plug control registers 
//
typedef struct _AVC_DEV_PLUGS {

    //
    // data rate of the device
    //
    ULONG  MaxDataRate;

    //
    // Number of input or output plugs (as in i/oMPR)
    //
    ULONG  NumPlugs;

    //
    // Array of plug handles and states;
    //
    AVC_DEV_PLUG  DevPlug[MAX_NUM_PCR];

} AVC_DEV_PLUGS, *PAVC_DEV_PLUGS;

    
//
// Device Extension for our  Desktop Camera Driver
//
typedef struct _DVCR_EXTENSION {  

    //
    // Holds video format supported by this device (presentaly allow only one format per device)
    //
    AVCSTRM_FORMAT VideoFormatIndex;

    //
    // Number of pin supported by this device; this usually equal to number of data range supported.
    //
    ULONG NumOfPins;

    //
    // Contain a table for the support formats (HW_STREAM_INFORMATION && HW_STREAM_OBJECT)
    //
    STREAM_INFO_AND_OBJ  * pStreamInfoObject;

    //
    // Keep track of number of stream that is openned; in this driver, only one stream can be open at any time.
    //
    LONG  cndStrmOpen;  // [0..1]

    //
    // Count the stream index (pin index) that has been opened.
    //
    ULONG idxStreamNumber;  // Index of current stream

    //
    // Can have only 1 Stream active at any time.
    // (Stream Class will allocate the stream extension at SRB_OPENSTREAM)    
    //
    PSTREAMEX  paStrmExt[3];    

    // 
    // Current Device Power State
    //
    DEVICE_POWER_STATE  PowerState;

    // 
    // TRUE only after SRB_SURPRISE_REMOVAL; 
    //
    BOOL  bDevRemoved;  

    // The list of AVC commands that have been issued
    LIST_ENTRY  AVCCmdList;

    // Number of completed commands waiting to be removed from the list
    // This includes:
    //     Command response has returned and processed in the completion routine
    //     Interim response awaiting final response
    LONG  cntCommandQueued;

    // Protection for command processing
    KSPIN_LOCK  AVCCmdLock;

    // The counted list of possible opcode values on response from Transport State status or notify
    UCHAR  TransportModes[5]; // 0x4, [0xC1, 0xC2, 0xC3, 0xC4]
    UCHAR  Reserved0[3];

    // Subunit type
    UCHAR  Subunit_Type[4];   // There are only two subunits

    //
    // The device type (and its capabilities) cannot be determined until a tape is in    
    //
    ULONG  MediaType;         // DVCR standard, small, medium; VHS; VHS-C; unknown
    ULONG  ulDevType;         // 0: undetermined, ED_DEVTYPE_CAMERA or ED_DEVTYPE_VCR
    BOOL  bHasTape;
    BOOL  bWriteProtected;
    BOOL  bDVCPro;

    //
    // Save Unit capabilities:
    //    Vendor and Model IDs
    //

    ULONG      ulVendorID;
    ULONG      ulModelID;

    LARGE_INTEGER  UniqueID;


    //
    // AVC Device's output plugs
    //
    PAVC_DEV_PLUGS pDevOutPlugs;

    //
    // AVC Device's input plugs
    //
    PAVC_DEV_PLUGS pDevInPlugs;


#ifdef SUPPORT_LOCAL_PLUGS
    //
    // Support local oPCR
    //
    AV_PCR  OPCR;
    ULONG  OutputPCRLocalNum;
    HANDLE  hOutputPCRLocal;

    //
    // Support local iPCR
    //
    AV_PCR  IPCR;
    ULONG  InputPCRLocalNum;
    HANDLE  hInputPCRLocal;
#endif

    //
    // Holds the Device Object of our parent (1394 bus driver)
    //
    PDEVICE_OBJECT pBusDeviceObject;  // IoCallDriver()

    //
    // Holds my Physical Device Object
    // pass it in PnP API, such as IoOpenDeviceRegistryKey()
    //
    PDEVICE_OBJECT pPhysicalDeviceObject;


    // 
    // Cache device's Unit capa
    //
    GET_UNIT_IDS  UnitIDs;

#ifndef NT51_61883
//
// Add support for unit model text that 61883 does not support for its 1st version
//
    //
    // 1394 generation count; used in 1394 asych operation.
    //
    ULONG GenerationCount;

    //
    // RootModelString
    //
    UNICODE_STRING  UniRootModelString;

    //
    // UnitModelString
    //
    UNICODE_STRING  UniUnitModelString;

#endif


    //
    // Serialize in the event of getting two consecutive SRB_OPEN_STREAMs
    //
    KMUTEX hMutex;


    //
    // Irp for sychnonize call
    //
    PIRP  pIrpSyncCall;

#ifdef SUPPORT_NEW_AVC
    //
    // 61883 request
    //
    HANDLE  hPlugLocalIn;        // Generic i/oPLUG handle
    HANDLE  hPlugLocalOut;       // Generic i/oPLUG handle
#endif

    AV_61883_REQUEST  AVReq;

    // Pin and connection 
    ULONG  PinCount;
    AVC_MULTIFUNC_IRB  AvcMultIrb;

} DVCR_EXTENSION, *PDVCR_EXTENSION;



//
// Used to queue a SRB
//

typedef struct _SRB_ENTRY {
    LIST_ENTRY                ListEntry;
    PHW_STREAM_REQUEST_BLOCK  pSrb; 
    BOOL                      bStale;  // TRUE if it is marked stale but is the only Srb in the SrbQ
    // Audio Mute ?
    BOOL                      bAudioMute;
#if DBG
    ULONG SrbNum;
#endif
} SRB_ENTRY, *PSRB_ENTRY;



//
// This is the context used to attach a frame 
//

typedef struct _SRB_DATA_PACKET {
    // Build list
    LIST_ENTRY                  ListEntry;

    PHW_STREAM_REQUEST_BLOCK    pSrb;  
    PSTREAMEX                   pStrmExt;  // Can get this from pSrb, here for convenience only!

#if DBG
    BOOL                        bAttached;  // TRUE if attached to 61883.
#endif

    // Used to send 61883 request
    PIRP                        pIrp;     // Use to attach and release.

    PCIP_FRAME                  Frame;
    PVOID                       FrameBuffer;

    //
    // Add debug related info here
    //
    LONGLONG                    FrameNumber;

    // Use to send 61883 AV data request
    AV_61883_REQUEST            AVReq;

} SRB_DATA_PACKET, *PSRB_DATA_PACKET;


//
// Wait time constants
//
#define DV_AVC_CMD_DELAY_STARTUP                       500   // MSec
#define DV_AVC_CMD_DELAY_INTER_CMD                      20   // MSec
#define DV_AVC_CMD_DELAY_DVCPRO                        500   // MSec                          
 
#endif
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\drivers\wdm\capture\mini\mstape\mstpguts.h ===
/*++

Copyright (C) Microsoft Corporation, 1999 - 2000  

Module Name:

    MsTpGuts.h

Abstract:

    Header file MsTpGuts.c

Last changed by:
    
    Author:      Yee J. Wu

Environment:

    Kernel mode only

Revision History:

    $Revision::                    $
    $Date::                        $

--*/


//
// Device SRB
//

NTSTATUS
AVCTapeInitialize(
    IN PDVCR_EXTENSION  pDevExt,
    IN PPORT_CONFIGURATION_INFORMATION pConfigInfo,
    IN PAV_61883_REQUEST pAVReq
    );

NTSTATUS
AVCTapeInitializeCompleted(
    IN PDVCR_EXTENSION  pDevExt
    );

NTSTATUS
AVCTapeGetStreamInfo(
    IN PDVCR_EXTENSION        pDevExt,
    IN ULONG                  ulBytesToTransfer, 
    IN PHW_STREAM_HEADER      pStreamHeader,       
    IN PHW_STREAM_INFORMATION pStreamInfo
    );

BOOL 
AVCTapeVerifyDataFormat(
    IN  ULONG  NumOfPins,
    PKSDATAFORMAT  pKSDataFormatToVerify, 
    ULONG          StreamNumber,
    ULONG          ulSupportedFrameSize,
    STREAM_INFO_AND_OBJ * paCurrentStrmInfo	
    );

NTSTATUS
AVCTapeGetDataIntersection(
    IN  ULONG  NumOfPins,
    IN  ULONG          ulStreamNumber,
    IN  PKSDATARANGE   pDataRange,
    OUT PVOID          pDataFormatBuffer,
    IN  ULONG          ulSizeOfDataFormatBuffer,
    IN  ULONG          ulSupportedFrameSize,
    OUT ULONG          *pulActualBytesTransferred,
    STREAM_INFO_AND_OBJ * paCurrentStrmInfo
#ifdef SUPPORT_NEW_AVC
    ,
    IN HANDLE  hPlugLocalOut,
    IN HANDLE  hPlugLocalIn
#endif
    );

NTSTATUS
AVCTapeOpenStream(
    IN PHW_STREAM_OBJECT pStrmObject,
    IN PKSDATAFORMAT     pOpenFormat,
    IN PAV_61883_REQUEST    pAVReq
    );

NTSTATUS
AVCTapeCloseStream(
    IN PHW_STREAM_OBJECT pStrmObject,
    IN PKSDATAFORMAT     pOpenFormat,
    IN PAV_61883_REQUEST    pAVReq
    );

NTSTATUS
DVChangePower(
    PDVCR_EXTENSION  pDevExt,
    PAV_61883_REQUEST pAVReq,
    DEVICE_POWER_STATE NewPowerState
    );

NTSTATUS
AVCTapeSurpriseRemoval(
    PDVCR_EXTENSION pDevExt,
    PAV_61883_REQUEST  pAVReq
    );

NTSTATUS
AVCTapeProcessPnPBusReset(
    PDVCR_EXTENSION pDevExt
    );

NTSTATUS
AVCTapeUninitialize(
    IN PDVCR_EXTENSION  pDevExt
    );

//
// Stream SRB
//

NTSTATUS
AVCTapeReqReadDataCR(
    IN PDEVICE_OBJECT  DeviceObject,
    IN PIRP  pIrp,
    IN PDRIVER_REQUEST  pDriverReq
    );

NTSTATUS
AVCTapeGetStreamState(
    PSTREAMEX  pStrmExt,
    IN PDEVICE_OBJECT DeviceObject,
    PKSSTATE   pStreamState,
    PULONG     pulActualBytesTransferred
    );

NTSTATUS
AVCTapeSetStreamState(
    PSTREAMEX        pStrmExt,
    PDVCR_EXTENSION  pDevExt,
    PAV_61883_REQUEST   pAVReq,
    KSSTATE          StreamState
    );

NTSTATUS 
DVGetStreamProperty(
    PHW_STREAM_REQUEST_BLOCK pSrb
    );

NTSTATUS
DVSetStreamProperty(
    PHW_STREAM_REQUEST_BLOCK pSrb
    );

VOID
AVCTapeCreateAbortWorkItem(
    PDVCR_EXTENSION pDevExt,
    PSTREAMEX pStrmExt
    );

VOID
DVCRCancelOnePacket(
    IN PHW_STREAM_REQUEST_BLOCK pSrbToCancel
    );

VOID
DVCRCancelAllPackets(
    IN PSTREAMEX        pStrmExt,
    IN PDVCR_EXTENSION  pDevExt
    );

VOID
DVTimeoutHandler(
    IN PHW_STREAM_REQUEST_BLOCK pSrb
    );

NTSTATUS 
AVCTapeOpenCloseMasterClock (
    PSTREAMEX  pStrmExt,
    HANDLE  hMasterClockHandle
    );

NTSTATUS 
AVCTapeIndicateMasterClock (
    PSTREAMEX  pStrmExt,
    HANDLE  hMasterClockHandle
    );

VOID
AVCTapeRcvDataPacket(
    IN PHW_STREAM_REQUEST_BLOCK pSrb
    );

VOID
AVCTapeRcvControlPacket(
    IN PHW_STREAM_REQUEST_BLOCK pSrb
    );
NTSTATUS 
AVCTapeEventHandler(
    IN PHW_EVENT_DESCRIPTOR pEventDescriptor
    );
VOID
AVCTapeSignalClockEvent(
    IN PKDPC Dpc,
    
    IN PSTREAMEX  pStrmExt,

    IN PVOID SystemArgument1,
    IN PVOID SystemArgument2    
    );
VOID 
AVCTapeStreamClockRtn(
    IN PHW_TIME_CONTEXT TimeContext
    );
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\drivers\wdm\capture\mini\mstape\mstpfmt.h ===
/*++

Copyright (C) Microsoft Corporation, 2000 - 2001

Module Name:

    MsTpFmt.h

Abstract:

    Header file for AV/C Tape format data.

Last changed by:
    
$Author::                $

Environment:

    Kernel mode only

Revision History:

$Revision::                    $
$Date::                        $

--*/




#ifndef _DVFORMAT_INC
#define _DVFORMAT_INC


// ****************
// Support switches
// ****************

//
// Differnt level of WDM supports may use different API
//
// e.g. MmGetSystemAddressForMdl (win9x) 
//          Return NULL for Win9x; bugcheck for Win2000 if NULL would have returned.
//
//      MmGetSystemAddressForMdlSafe (win2000)
//          Not supported in Win9x or Millen
//
// #define USE_WDM110  // Define this if WDM1.10 is used; e.g. Win2000 code base; Set this in SOURCES file.


//
// Turn this on to support HD DVCR 
//#define MSDV_SUPPORT_HD_DVCR

//
// Turn this on to support SDL DVCR 
//#define SUPPORT_SDL_DVCR




//
// Turn on this switch to support bus reset KS event
// #define MSDVDV_SUPPORT_BUSRESET_EVENT


//
// Turn this define to extract timecode from a video frame
// Advantage: faster turn around compare to an AVC status command
// #define MSDV_SUPPORT_EXTRACT_SUBCODE_DATA


//
// To get recorded date and time
// #define MSDV_SUPPORT_EXTRACT_DV_DATE_TIME

//
// Mute audio when in pause state while transmitting to DV
#define MSDV_SUPPORT_MUTE_AUDIO

//
// Support getting regitry value for this device
//
// #define READ_CUTOMIZE_REG_VALUES


//
// Suuport accessing to the device's interface section
//
#define SUPPORT_ACCESS_DEVICE_INTERFACE

//
// Support new AVC - plug connection ..etc.
//
// #define SUPPORT_NEW_AVC


//
// Support local plug.
//
#define SUPPORT_LOCAL_PLUG

//
// Testing
//
#if DBG
    #define EnterAVCStrm(pMutex)  \
        { \
        KeWaitForMutexObject(pMutex, Executive, KernelMode, FALSE, NULL);\
        InterlockedIncrement(&MSDVCRMutextUseCount);\
        }
    #define LeaveAVCStrm(pMutex)  \
        { \
        KeReleaseMutex(pMutex, FALSE);\
        InterlockedDecrement(&MSDVCRMutextUseCount);\
        }
#else
    #define EnterAVCStrm(pMutex) KeWaitForMutexObject(pMutex, Executive, KernelMode, FALSE, NULL);
    #define LeaveAVCStrm(pMutex) KeReleaseMutex(pMutex, FALSE);
#endif

//
// DV format tables
//


typedef struct _STREAM_INFO_AND_OBJ {
    HW_STREAM_INFORMATION   hwStreamInfo;
    HW_STREAM_OBJECT        hwStreamObject;
} STREAM_INFO_AND_OBJ, *PSTREAM_INFO_AND_OBJ;



// All CIP sizes are in quads. The upper third byte is the size.
#define CIP_HDR_FMT_DV                   0x00
#define CIP_HDR_FMT_DVCPRO               0x1e


//
// 1394 stuff
//
#define SPEED_100_INDEX                     0
#define SPEED_200_INDEX                     1
#define SPEED_400_INDEX                     2


#define CIP_DBS_SD_DVCR                   120       // quadlets in a data block of the SD DVCR; BlueBook Part 2
#define CIP_DBS_HD_DVCR                   240       // quadlets in a data block of the HD DVCR; BlueBook Part 3
#define CIP_DBS_SDL_DVCR                  108       // quadlets in a data block of the SDL DVCR; BlueBook Part 5

#define CIP_FN_SD_DVCR                      0       // Data blocks in a source pacaket of SD DVCR; BlueBook Part 2
#define CIP_FN_HD_DVCR                      0       // Data blocks in a source pacaket of HD DVCR; BlueBook Part 3
#define CIP_FN_SDL_DVCR                     0       // Data blocks in a source pacaket of SDL DVCR; BlueBook Part 5


#define MAX_FCP_PAYLOAD_SIZE              512


// CIP header definition:

// FMT: "Blue book" Part 1, page 25, Table 3; DVCR:000000
#define FMT_DVCR             0x80  // 10:FMT(00:0000)
#define FMT_DVCR_CANON       0x20  // 10:FMT(00:0000); but Canon return 00:FMT(10:0000)
#define FMT_MPEG             0xa0  // 10:FMT(10:0000)


// FDF
#define FDF0_50_60_MASK      0x80
#define FDF0_50_60_PAL       0x80
#define FDF0_50_60_NTSC      0x00

#define FDF0_STYPE_MASK      0x7c
#define FDF0_STYPE_SD_DVCR   0x00  // STYPE: 000:00
#define FDF0_STYPE_SDL_DVCR  0x04  // STYPE: 000:01
#define FDF0_STYPE_HD_DVCR   0x08  // STYPE: 000:10
#define FDF0_STYPE_SD_DVCPRO 0x78  // STYPE: 111:10


// PCR constants
#define PCR_OVERHEAD_ID_SDDV_DEF        0xf      // 480; delays caused by IEEE 1394 bus parmeters
#define PCR_PAYLOAD_SDDV_DEF            122      // Fixed: 122 * 4 = 480 + 8

#define PCR_OVERHEAD_ID_MPEG2TS_DEF     0xf      // 480; delays caused by IEEE 1394 bus parmeters
#define PCR_PAYLOAD_MPEG2TS_DEF         146      // Variable but this is based on oPCR of a Panasonic's D-VHS


//
// FCP and AVCC stuff.  Used in conjunction with defs in 1394.h
//

// DVCR:
#define SUBUNIT_TYPE_CAMCORDER           4
#define SUBUNIT_ID_CAMCORDER             0

#define DIF_SEQS_PER_NTSC_FRAME         10
#define DIF_SEQS_PER_PAL_FRAME          12

#define SRC_PACKETS_PER_NTSC_FRAME     250
#define SRC_PACKETS_PER_PAL_FRAME      300


#define NUM_OF_RCV_BUFFERS_DV           8
#define NUM_OF_XMT_BUFFERS_DV           8


// MPEG2TS
#define MPEG2TS_STRIDE_OFFSET           4   // 4 byte of SPH
#define MPEG2TS_STRIDE_PACKET_LEN     188   // standard 188-byte packet
#define MPEG2TS_STRIDE_STRIDE_LEN     (MPEG2TS_STRIDE_OFFSET+MPEG2TS_STRIDE_PACKET_LEN)   // Stride packet length


//
// Data buffers
//

#define NUM_BUF_ATTACHED_THEN_ISOCH         4   // number of buffers attached before streaming and also as the water mark.
#define DV_NUM_EXTRA_USER_XMT_BUFFERS      12   // Extra user buffers that the data source can send to us as a read ahead.
#define DV_NUM_OF_XMT_BUFFERS               (NUM_BUF_ATTACHED_THEN_ISOCH + DV_NUM_EXTRA_USER_XMT_BUFFERS)




//
// The "signature" of the header section of Seq0 of incoming source packets:
//
// "Blue" book, Part2, 11.4 (page 50); Figure 66, table 36 (page 111)
//
// ID0 = {SCT2,SCT1,SCT0,RSV,Seq3,Seq2,Seq1,Seq0} = {0,0,0,1, 1,1,1,1} = 0x1f
//
//     SCT2-0 = {0,0,0}
//     RSV    = {1}
//     Seq3-0 = {1,1,1,1} for NoInfo or {0,0,0,} for Sequence 0
//
// ID1 = {DSeq3-0, 0, RSV, RSV, RSV} = {0,0,0,0, 0,1,1,1} = 0x07
//     DSeq3-0 = {0, 0, 0, 0}  // Start from seq 0
//
#define ID0_SEQ0_HEADER_MASK    0xf0 // 11110000  Seq3-0 = xxxx Don't care!; check only SCT2-0:000 and RSV:1
#define ID0_SEQ0_HEADER_NO_INFO 0x1f // 00011111  Seq3-0 = 1111 no data     (Most of Consumer DV)
#define ID0_SEQ0_HEADER_0000    0x10 // 00010000  Seq3-0 = 0000 sequence 0  (DVCPRO)
#define ID1_SEQ0_HEADER         0x07 // 00000111 


//
// AV/C command response data definition
//
#define AVC_SUBTYPE_MASK    0xf8
#define AVC_DEVICE_TAPE_REC 0x20  // 00100:000
#define AVC_DEVICE_CAMERA   0x38  // 00111:000
#define AVC_DEVICE_TUNER    0x28  // 00101:000
#define AVC_DEVICE_UNKNOWN  0xff  // 11111:111



//
// GUID definitions for pins and DV format types.
//

// DV vid only output pin
#define STATIC_PINNAME_DV_VID_OUTPUT \
    0x5b21c540L, 0x7aee, 0x11d1, 0x88, 0x3b, 0x00, 0x60, 0x97, 0xf0, 0x5c, 0x70
DEFINE_GUIDSTRUCT("5b21c540-7aee-11d1-883b-006097f05c70", PINNAME_DV_VID_OUTPUT);
#define PINNAME_DV_VID_OUTPUT DEFINE_GUIDNAMED(PINNAME_DV_VID_OUTPUT)
#define PINNAME_VID_OUT PINNAME_DV_VID_OUTPUT

// DV A/V output pin
#define STATIC_PINNAME_DV_AV_OUTPUT \
    0x5b21c541L, 0x7aee, 0x11d1, 0x88, 0x3b, 0x00, 0x60, 0x97, 0xf0, 0x5c, 0x70
DEFINE_GUIDSTRUCT("5b21c540-7aee-11d1-883b-006097f05c70", PINNAME_DV_AV_OUTPUT);
#define PINNAME_DV_AV_OUTPUT DEFINE_GUIDNAMED(PINNAME_DV_AV_OUTPUT)
#define PINNAME_AV_OUTPUT PINNAME_DV_AV_OUTPUT

// DV A/V input pin
#define STATIC_PINNAME_DV_AV_INPUT \
    0x5b21c543L, 0x7aee, 0x11d1, 0x88, 0x3b, 0x00, 0x60, 0x97, 0xf0, 0x5c, 0x70
DEFINE_GUIDSTRUCT("5b21c543-7aee-11d1-883b-006097f05c70", PINNAME_DV_AV_INPUT);
#define PINNAME_DV_AV_INPUT DEFINE_GUIDNAMED(PINNAME_DV_AV_INPUT)
#define PINNAME_AV_INPUT PINNAME_DV_AV_INPUT


// MPEG2TS Output pin
#define STATIC_PINNAME_MPEG2TS_OUTPUT \
    0x2CFF7B83L, 0x96F1, 0x47e3, 0x98, 0xEC, 0x57, 0xBD, 0x8A, 0x99, 0x72, 0x15
    DEFINE_GUIDSTRUCT("2CFF7B83-96F1-47e3-98EC-57BD8A997215", PINNAME_MPEG2TS_OUTPUT);
#define PINNAME_MPEG2TS_OUTPUT DEFINE_GUIDNAMED(PINNAME_MPEG2TS_OUTPUT)
#define PINNAME_AV_MPEG2TS_OUTPUT PINNAME_MPEG2TS_OUTPUT

// MPEG2TS Input pin
#define STATIC_PINNAME_MPEG2TS_INPUT \
    0xCF4C59A3L, 0xACE3, 0x444B, 0x8C, 0x37, 0xB, 0x22, 0x66, 0x1A, 0x4A, 0x29
    DEFINE_GUIDSTRUCT("CF4C59A3-ACE3-444b-8C37-0B22661A4A29", PINNAME_MPEG2TS_INPUT);
#define PINNAME_MPEG2TS_INPUT DEFINE_GUIDNAMED(PINNAME_MPEG2TS_INPUT)
#define PINNAME_AV_MPEG2TS_INPUT PINNAME_MPEG2TS_INPUT

#endif
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\drivers\wdm\capture\mini\mstape\mstpuppr.c ===
/*++

Copyright (C) Microsoft Corporation, 1999 - 2000  

Module Name:

    MSTpUppr.c

Abstract:

    Interface code with stream class driver.

Last changed by:
    
    Author:      Yee J. Wu

Environment:

    Kernel mode only

Revision History:

    $Revision::                    $
    $Date::                        $

--*/

#include "strmini.h"
#include "ksmedia.h"
#include "1394.h"
#include "61883.h"
#include "avc.h"
#include "dbg.h"
#include "MsTpFmt.h"
#include "MsTpDef.h"
#include "MsTpGuts.h"  // Function prototypes
#include "MsTpAvc.h"

#include "EDevCtrl.h"

#ifdef TIME_BOMB
#include "..\..\inc\timebomb.c"
#endif

#if DBG
LONG MSDVCRMutextUseCount = 0;
#endif


// global flag for debugging.  Inlines are defined in dbg.h.  The debug level is set for
// minimal amount of messages.
#if DBG

#define TraceMaskCheckIn  TL_PNP_ERROR | TL_STRM_ERROR

#define TraceMaskDefault  TL_PNP_ERROR   | TL_PNP_WARNING \
                          | TL_61883_ERROR | TL_61883_WARNING \
                          | TL_CIP_ERROR  \
                          | TL_FCP_ERROR  \
                          | TL_STRM_ERROR  | TL_STRM_WARNING \
                          | TL_CLK_ERROR

#define TraceMaskDebug    TL_PNP_ERROR  | TL_PNP_WARNING \
                          | TL_61883_ERROR| TL_61883_WARNING \
                          | TL_CIP_ERROR  \
                          | TL_FCP_ERROR  | TL_FCP_WARNING \
                          | TL_STRM_ERROR | TL_STRM_WARNING \
                          | TL_CLK_ERROR


ULONG TapeTraceMask   = TraceMaskCheckIn;
ULONG TapeAssertLevel = 1;

#endif


extern AVCSTRM_FORMAT_INFO  AVCStrmFormatInfoTable[];

//
// Function prototypes
//
VOID
DVRcvStreamDevicePacket(
    IN PHW_STREAM_REQUEST_BLOCK pSrb
    );
VOID
DVSRBRead(
    IN PKSSTREAM_HEADER pStrmHeader,
    IN ULONG            ulFrameSize,
    IN PDVCR_EXTENSION  pDevExt,
    IN PSTREAMEX        pStrmExt,
    IN PHW_STREAM_REQUEST_BLOCK pSrb        // needs Srb->Status 
    );
BOOL
DVSignalEOStream(    
    IN PHW_STREAM_REQUEST_BLOCK pSrb,
    IN PSTREAMEX                pStrmExt,
    IN FMT_INDEX                ulVideoFormatIndex,
    IN ULONG                    ulOptionFlags
    );
NTSTATUS
DVAttachWriteFrame(
    IN PSTREAMEX  pStrmExt
    );
NTSTATUS
DriverEntry(
    IN PDRIVER_OBJECT DriverObject,
    IN PUNICODE_STRING RegistryPath
    ); 

#if 0  // Enable later
#ifdef ALLOC_PRAGMA   
     #pragma alloc_text(PAGE, DVRcvStreamDevicePacket)
     #pragma alloc_text(PAGE, AVCTapeRcvControlPacket)
     #pragma alloc_text(PAGE, AVCTapeRcvDataPacket)
     // #pragma alloc_text(INIT, DriverEntry)
#endif
#endif


VOID
DVRcvStreamDevicePacket(
    IN PHW_STREAM_REQUEST_BLOCK pSrb
    )
/*++

Routine Description:

    This is where most of the interesting Stream requests come to us

--*/
{
    PDVCR_EXTENSION  pDevExt;  
    PAV_61883_REQUEST  pAVReq;
    PIO_STACK_LOCATION  pIrpStack;


    PAGED_CODE();


    //
    // Get these extensions from a SRB
    //
    pDevExt = (PDVCR_EXTENSION) pSrb->HwDeviceExtension; 
    pAVReq  = (PAV_61883_REQUEST) pSrb->SRBExtension;       // Use in IrpSync is OK, 
                             
#if DBG
    if(pSrb->Command != SRB_INITIALIZE_DEVICE && // PowerState is initialize in this SRB so ignore it.
       pDevExt->PowerState != PowerDeviceD0) {
        TRACE(TL_PNP_WARNING,("RcvDevPkt; pSrb:%x; Cmd:%x; Dev is OFF state\n", pSrb, pSrb->Command));
    }
#endif

    TRACE(TL_PNP_TRACE,("StreamDevicePacket: pSrb %x, Cmd %d, pdevExt %x\n", pSrb, pSrb->Command, pDevExt));

    //
    // Assume success
    //
    pSrb->Status = STATUS_SUCCESS;

    switch (pSrb->Command) {

    case SRB_INITIALIZE_DEVICE:

        ASSERT(((PPORT_CONFIGURATION_INFORMATION) pSrb->CommandData.ConfigInfo)->HwDeviceExtension == pDevExt);
        pSrb->Status = 
            AVCTapeInitialize(
                (PDVCR_EXTENSION) ((PPORT_CONFIGURATION_INFORMATION)pSrb->CommandData.ConfigInfo)->HwDeviceExtension,
                pSrb->CommandData.ConfigInfo,
                pAVReq
                );
        break;



    case SRB_INITIALIZATION_COMPLETE:

        //
        // Stream class has finished initialization.
        // Now create DShow Medium interface BLOBs.
        // This needs to be done at low priority since it uses the registry, so use a callback
        //
        pSrb->Status = 
            AVCTapeInitializeCompleted(
                pDevExt
                );
        break;


    case SRB_GET_STREAM_INFO:

        //
        // this is a request for the driver to enumerate requested streams
        //
        pSrb->Status = 
            AVCTapeGetStreamInfo(
                pDevExt,
                pSrb->NumberOfBytesToTransfer,
                &pSrb->CommandData.StreamBuffer->StreamHeader,
                &pSrb->CommandData.StreamBuffer->StreamInfo
                );
        break;



    case SRB_GET_DATA_INTERSECTION:

        pSrb->Status = 
            AVCTapeGetDataIntersection(
                pDevExt->NumOfPins,
                pSrb->CommandData.IntersectInfo->StreamNumber,
                pSrb->CommandData.IntersectInfo->DataRange,
                pSrb->CommandData.IntersectInfo->DataFormatBuffer,
                pSrb->CommandData.IntersectInfo->SizeOfDataFormatBuffer,
                AVCStrmFormatInfoTable[pDevExt->VideoFormatIndex].FrameSize,
                &pSrb->ActualBytesTransferred,
                pDevExt->pStreamInfoObject
#ifdef SUPPORT_NEW_AVC
                ,
                pDevExt->hPlugLocalOut,
                pDevExt->hPlugLocalIn
#endif
                );
        break;



    case SRB_OPEN_STREAM:

        //
        // Serialize SRB_OPEN_STREAMs
        //

        KeWaitForMutexObject(&pDevExt->hMutex, Executive, KernelMode, FALSE, NULL);

        pSrb->Status = 
            AVCTapeOpenStream(
                pSrb->StreamObject,
                pSrb->CommandData.OpenFormat,
                pAVReq
                );

        KeReleaseMutex(&pDevExt->hMutex, FALSE); 

        break;



    case SRB_CLOSE_STREAM:

        KeWaitForMutexObject(&pDevExt->hMutex, Executive, KernelMode, FALSE, NULL);
        pSrb->Status = 
            AVCTapeCloseStream(
                pSrb->StreamObject,
                pSrb->CommandData.OpenFormat,
                pAVReq
                );
        KeReleaseMutex(&pDevExt->hMutex, FALSE); 
        break;



    case SRB_GET_DEVICE_PROPERTY:

        pSrb->Status = 
            AVCTapeGetDeviceProperty(
                pDevExt,
                pSrb->CommandData.PropertyInfo,
                &pSrb->ActualBytesTransferred
                );
        break;

        
    case SRB_SET_DEVICE_PROPERTY:

        pSrb->Status = 
            AVCTapeSetDeviceProperty(
                pDevExt,
                pSrb->CommandData.PropertyInfo,
                &pSrb->ActualBytesTransferred
                );
        break;



    case SRB_CHANGE_POWER_STATE:
            
        pIrpStack = IoGetCurrentIrpStackLocation(pSrb->Irp);

        if(pIrpStack->MinorFunction == IRP_MN_SET_POWER) {
            pSrb->Status = 
                DVChangePower(
                    (PDVCR_EXTENSION) pSrb->HwDeviceExtension,
                    pAVReq,
                    pSrb->CommandData.DeviceState
                    );
        } else 
        if(pIrpStack->MinorFunction == IRP_MN_QUERY_POWER) {
            TRACE(TL_PNP_WARNING,("IRP_MN_QUERY_POWER: PwrSt:%d\n", pDevExt->PowerState)); 
            pSrb->Status = STATUS_SUCCESS;
        }
        else {
            TRACE(TL_PNP_WARNING,("Not Supported POWER_STATE MinorFunc:%d\n", pIrpStack->MinorFunction)); 
            pSrb->Status = STATUS_NOT_IMPLEMENTED; // STATUS_NOT_SUPPORTED;
        }

        break;


    case SRB_UNKNOWN_DEVICE_COMMAND:

        //
        // We might be interested in unknown commands if they pertain
        // to bus resets.  Bus resets are important cuz we need to know
        // what the current generation count is.
        //
        pIrpStack = IoGetCurrentIrpStackLocation(pSrb->Irp);

        if(pIrpStack->MajorFunction == IRP_MJ_PNP) {
            if(pIrpStack->MinorFunction == IRP_MN_BUS_RESET) {
            
                AVCTapeProcessPnPBusReset(
                    pDevExt
                    );
                
                //  Always success                
                pSrb->Status = STATUS_SUCCESS;
            }        
            else  {
                TRACE(TL_PNP_TRACE,("StreamDevicePacket: NOT_IMPL; IRP_MJ_PNP Min:%x\n",                  
                    pIrpStack->MinorFunction
                    )); 
                pSrb->Status = STATUS_NOT_IMPLEMENTED; // SUPPORTED;
            } 
        }
        else 
            pSrb->Status = STATUS_NOT_IMPLEMENTED; // SUPPORTED;
        break;


    case SRB_SURPRISE_REMOVAL:

        TRACE(TL_PNP_WARNING,("#SURPRISE_REMOVAL# pSrb %x, pDevExt %x\n", pSrb, pDevExt));
        pSrb->Status = 
             AVCTapeSurpriseRemoval(
                 pDevExt,
                 pAVReq
                 );
        break;            


        
    case SRB_UNINITIALIZE_DEVICE:

        TRACE(TL_PNP_WARNING,("#UNINITIALIZE_DEVICE# pSrb %x, pDevExt %x\n", pSrb, pDevExt));                   
        pSrb->Status = 
            AVCTapeUninitialize(
                (PDVCR_EXTENSION) pSrb->HwDeviceExtension
                );          
        break;           


    default:
            
        TRACE(TL_PNP_WARNING,("StreamDevicePacket: Unknown or unprocessed SRB cmd %x\n", pSrb->Command));

        //
        // this is a request that we do not understand.  Indicate invalid
        // command and complete the request
        //

        pSrb->Status = STATUS_NOT_IMPLEMENTED; 
    }

    //
    // NOTE:
    //
    // all of the commands that we do, or do not understand can all be completed
    // synchronously at this point, so we can use a common callback routine here.
    // If any of the above commands require asynchronous processing, this will
    // have to change
    //
#if DBG
    if (pSrb->Status != STATUS_SUCCESS && 
        pSrb->Status != STATUS_NOT_SUPPORTED &&
        pSrb->Status != STATUS_NOT_IMPLEMENTED &&
        pSrb->Status != STATUS_BUFFER_TOO_SMALL &&
        pSrb->Status != STATUS_BUFFER_OVERFLOW &&
        pSrb->Status != STATUS_NO_MATCH
        ) {
        TRACE(TL_PNP_WARNING,("StreamDevicePacket:pSrb->Command(0x%x) does not return STATUS_SUCCESS or NOT_IMPLEMENTED but 0x%x\n", pSrb->Command, pSrb->Status));
    }
#endif

    if(STATUS_PENDING != pSrb->Status) {

        StreamClassDeviceNotification(
            DeviceRequestComplete,
            pSrb->HwDeviceExtension,
           pSrb
           );
    } 
    else {

        // Pending pSrb which will be completed asynchronously
        TRACE(TL_PNP_WARNING,("ReceiveDevicePacket:Pending pSrb %x\n", pSrb));
    }
}



VOID
AVCTapeRcvControlPacket(
    IN PHW_STREAM_REQUEST_BLOCK pSrb
    )
/*++

Routine Description:

    Called with packet commands that control the video stream

--*/
{
    PAV_61883_REQUEST   pAVReq;
    PSTREAMEX        pStrmExt;
    PDVCR_EXTENSION  pDevExt;


    PAGED_CODE();

    //
    // Get these three extension from SRB
    //
    pAVReq   = (PAV_61883_REQUEST) pSrb->SRBExtension;  // This is OK to be used us IrpSync operation
    pDevExt  = (PDVCR_EXTENSION) pSrb->HwDeviceExtension;
    pStrmExt = (PSTREAMEX) pSrb->StreamObject->HwStreamExtension;      // Only valid in SRB_OPEN/CLOSE_STREAM
    ASSERT(pStrmExt && pDevExt && pAVReq);

    //
    // Default to success
    //
    pSrb->Status = STATUS_SUCCESS;

    switch (pSrb->Command) {

    case SRB_GET_STREAM_STATE:

        pSrb->Status =
            AVCTapeGetStreamState( 
                pStrmExt,
                pDevExt->pBusDeviceObject,
                &(pSrb->CommandData.StreamState),
                &(pSrb->ActualBytesTransferred)
                );
        break;
            
    case SRB_SET_STREAM_STATE:
            
        pSrb->Status =
            AVCTapeSetStreamState(
                pStrmExt,
                pDevExt,
                pAVReq,
                pSrb->CommandData.StreamState   // Target KSSTATE
               );       
        break;

        
    case SRB_GET_STREAM_PROPERTY:

        pSrb->Status =
            DVGetStreamProperty( 
                pSrb 
                );
        break;


    case SRB_SET_STREAM_PROPERTY:

        pSrb->Status =        
            DVSetStreamProperty( 
                pSrb 
                );
        break;

    case SRB_OPEN_MASTER_CLOCK:
    case SRB_CLOSE_MASTER_CLOCK:

        //
        // This stream is being selected to provide a Master clock.
        //
        pSrb->Status =
            AVCTapeOpenCloseMasterClock(                 
                pStrmExt, 
                pSrb->Command == SRB_OPEN_MASTER_CLOCK ? pSrb->CommandData.MasterClockHandle: NULL);
        break;

    case SRB_INDICATE_MASTER_CLOCK:

        //
        // Assigns a clock to a stream.
        //
        pSrb->Status = 
            AVCTapeIndicateMasterClock(
                pStrmExt, 
                pSrb->CommandData.MasterClockHandle);
        break;

    case SRB_PROPOSE_DATA_FORMAT:
    
        //
        // The SRB_PROPOSE_DATA_FORMAT command queries the minidriver
        // to determine if the minidriver can change the format of a 
        // particular stream. If the minidriver is able to switch the 
        // stream to the specified format, STATUS_SUCCESS is returned. 
        // Note that this function only proposes a new format, but does
        // not change it. 
        //
        // The CommandData.OpenFormat passes the format to validate.
        // If the minidriver is able to accept the new format, at some 
        // later time the class driver may send the minidriver a format 
        // change, which is indicated by an OptionsFlags flag in a 
        // KSSTREAM_HEADER structure. 
        //
 
        if(!AVCTapeVerifyDataFormat(
            pDevExt->NumOfPins,
            pSrb->CommandData.OpenFormat, 
            pSrb->StreamObject->StreamNumber,
            AVCStrmFormatInfoTable[pDevExt->VideoFormatIndex].FrameSize,
            pDevExt->pStreamInfoObject
            ))  {
            TRACE(TL_PNP_WARNING,("RcvControlPacket: AdapterVerifyFormat failed.\n"));
            pSrb->Status = STATUS_NO_MATCH;
        }
        break;
 
    default:

        //
        // invalid / unsupported command. Fail it as such
        //
        TRACE(TL_PNP_WARNING,("RcvControlPacket: unknown cmd = %x\n",pSrb->Command));
        pSrb->Status = STATUS_NOT_IMPLEMENTED;
    }

    TRACE(TL_PNP_TRACE,("RcvControlPacket: pSrb:%x, Command %x, ->Status %x, ->CommandData %x\n",
         pSrb, pSrb->Command, pSrb->Status, &(pSrb->CommandData.StreamState) ));

    StreamClassStreamNotification(          
        StreamRequestComplete,
        pSrb->StreamObject,
        pSrb);
}




VOID
AVCTapeRcvDataPacket(
    IN PHW_STREAM_REQUEST_BLOCK pSrb
    )

/*++

Routine Description:

    Called with video data packet commands

--*/

{
    PSTREAMEX       pStrmExt;
    PDVCR_EXTENSION pDevExt;
    PAVC_STREAM_REQUEST_BLOCK  pAVCStrmReq;
    PIRP  pIrpReq;
    PIO_STACK_LOCATION  NextIrpStack;
    NTSTATUS Status;
    PDRIVER_REQUEST pDriverReq;
    KIRQL oldIrql;


    
    PAGED_CODE();

    pStrmExt = (PSTREAMEX) pSrb->StreamObject->HwStreamExtension;  
    pDevExt  = (PDVCR_EXTENSION) pSrb->HwDeviceExtension;

#if DBG
    if(pDevExt->PowerState != PowerDeviceD0) {
        TRACE(TL_PNP_WARNING,("SRB_READ/WRITE; PowerSt:OFF; pSrb:%x\n", pSrb));
    }
#endif

    // The stream has to be open before we can do anything.
    if (pStrmExt == NULL) {
        TRACE(TL_STRM_TRACE,("RcvDataPacket: stream not opened for SRB %x. kicking out...\n", pSrb->Command));
        pSrb->Status = STATUS_UNSUCCESSFUL;
        pSrb->CommandData.DataBufferArray->DataUsed = 0;
        StreamClassStreamNotification(StreamRequestComplete, pSrb->StreamObject, pSrb);
        return;        
    }


    TRACE(TL_PNP_TRACE,("XXX_DATA(%d, %d);Srb:%x;Flg:%x;FExt:%d:%d\n", 
        (DWORD) pStrmExt->cntSRBReceived, 
        (DWORD) pSrb->CommandData.DataBufferArray->PresentationTime.Time/10000,
        pSrb, 
        pSrb->CommandData.DataBufferArray->OptionsFlags,
        pSrb->CommandData.DataBufferArray->FrameExtent,
        AVCStrmFormatInfoTable[pDevExt->VideoFormatIndex].FrameSize
        ));

    // If we has asked to stopped, we should not receive data request.
    ASSERT(pStrmExt->StreamState != KSSTATE_STOP);

    //
    // determine the type of packet.
    //
    pSrb->Status = STATUS_SUCCESS;

    switch (pSrb->Command) {


    case SRB_WRITE_DATA:

        // ********************************
        // Take care of some special cases:
        // ********************************

        // Can signal this when the last is transmitted or sigal it immediately like 
        // what is done here.
        if(pSrb->CommandData.DataBufferArray->OptionsFlags & KSSTREAM_HEADER_OPTIONSF_ENDOFSTREAM) {
            // Optional, wait a fix time and can be signalled when the last one has returned.
            // And then signal the completion.

            TRACE(TL_STRM_WARNING,("RcvDataPacket: EndOfStream is signalled!\n"));
            pSrb->CommandData.DataBufferArray->DataUsed = 0;
            pSrb->Status = STATUS_SUCCESS;

            //
            // Send this flag down to AVCStrm.sys so it will wait until 
            // all attach buffers are completed.
            //

        } else if (pSrb->CommandData.DataBufferArray->OptionsFlags & KSSTREAM_HEADER_OPTIONSF_TYPECHANGED) {
            TRACE(TL_PNP_WARNING,("RcvDataPacket:KSSTREAM_HEADER_OPTIONSF_TYPECHANGED.\n"));
            pSrb->CommandData.DataBufferArray->DataUsed = 0;
            // May need to compare the data format; instead of return STATUS_SUCCESS??
            pSrb->Status = STATUS_SUCCESS; // May need to check the format when dynamic format change is allowed.
            break; 
        }

    case SRB_READ_DATA:

        //
        // If removed, cancel the request with STATUS_DEVICE_REMOVED. 
        // (apply to both SRB_READ_DATA and SRB_WRITE_DATA)
        //
        if(pDevExt->bDevRemoved) {
            TRACE(TL_STRM_WARNING,("SRB_READ/WRITE; DevRemoved!\n", pSrb));
            pSrb->Status = STATUS_DEVICE_REMOVED;
            pSrb->CommandData.DataBufferArray->DataUsed = 0;
            break;
        }

        //
        // A true data request must has a MdlAddress unless it is a know 
        // optional flag.
        //
        if(pSrb->Irp->MdlAddress == NULL) {
            if((pSrb->CommandData.DataBufferArray->OptionsFlags & 
                (KSSTREAM_HEADER_OPTIONSF_ENDOFSTREAM | KSSTREAM_HEADER_OPTIONSF_TYPECHANGED) )) {
                //
                // Known optional flags
                //
            } else {
                TRACE(TL_STRM_ERROR,("pSrb:%x, unknown OptionsFlags:%x\n",pSrb, pSrb->CommandData.DataBufferArray->OptionsFlags));
                ASSERT(pSrb->Irp->MdlAddress);
                break;
                
                //
                // We do not know how to handle this option flag so we will quit on this data request.
                //
            }
        }

        // 
        // Serialize with setting state
        //
        EnterAVCStrm(pStrmExt->hMutexReq);

        //
        // Get a context to send this request down
        //
        KeAcquireSpinLock(pStrmExt->DataListLock, &oldIrql); 

        pStrmExt->cntSRBReceived++;

        if(IsListEmpty(&pStrmExt->DataDetachedListHead)) {
            TRACE(TL_STRM_ERROR,("**** DataDetachList is empty! ****\n"));
            ASSERT(!IsListEmpty(&pStrmExt->DataDetachedListHead));

            //
            // Note: The alternative to the failure is to expand the pre-allocated list.
            //

            KeReleaseSpinLock(pStrmExt->DataListLock, oldIrql);
            LeaveAVCStrm(pStrmExt->hMutexReq);
            pSrb->Status = STATUS_INSUFFICIENT_RESOURCES;
            pSrb->CommandData.DataBufferArray->DataUsed = 0;
            break;
        } else {

            pDriverReq = (PDRIVER_REQUEST) RemoveHeadList(&pStrmExt->DataDetachedListHead); pStrmExt->cntDataDetached--;          
#if DBG
            pDriverReq->cntDataRequestReceived = pStrmExt->cntSRBReceived;  // For verification
#endif
            InsertTailList(&pStrmExt->DataAttachedListHead, &pDriverReq->ListEntry); pStrmExt->cntDataAttached++;

            pAVCStrmReq = &pDriverReq->AVCStrmReq;
            pIrpReq     = pDriverReq->pIrp;
            KeReleaseSpinLock(pStrmExt->DataListLock, oldIrql);
        }

        RtlZeroMemory(pAVCStrmReq, sizeof(AVC_STREAM_REQUEST_BLOCK));
        INIT_AVCSTRM_HEADER(pAVCStrmReq, (pSrb->Command == SRB_READ_DATA) ? AVCSTRM_READ : AVCSTRM_WRITE);
        pAVCStrmReq->AVCStreamContext = pStrmExt->AVCStreamContext;
        // Need these context when this IRP is completed.
        pDriverReq->Context1 = (PVOID) pSrb;
        pDriverReq->Context2 = (PVOID) pStrmExt;

        // We are the clock provide if hMasterClock is not NULL.
        pAVCStrmReq->CommandData.BufferStruct.ClockProvider = (pStrmExt->hMasterClock != NULL);
        pAVCStrmReq->CommandData.BufferStruct.ClockHandle   =  pStrmExt->hClock;  // Used only if !ClockProvider

        pAVCStrmReq->CommandData.BufferStruct.StreamHeader = pSrb->CommandData.DataBufferArray;

        //
        // This could be a data or just flag that need to be processed.
        // Get its system address only if there is an MdlAddress.
        //
        if(pSrb->Irp->MdlAddress) {

            pAVCStrmReq->CommandData.BufferStruct.FrameBuffer =             
#ifdef USE_WDM110   // Win2000, XP
                MmGetSystemAddressForMdlSafe(pSrb->Irp->MdlAddress, NormalPagePriority);
            if(!pAVCStrmReq->CommandData.BufferStruct.FrameBuffer) {
                
                //
                // Reclaim the data entry from attach (busy) to detach (free)
                //
                KeAcquireSpinLock(pStrmExt->DataListLock, &oldIrql); 
                RemoveEntryList(&pDriverReq->ListEntry);  pStrmExt->cntDataAttached--;
                InsertHeadList(&pStrmExt->DataAttachedListHead, &pDriverReq->ListEntry); pStrmExt->cntDataAttached++;
                KeReleaseSpinLock(pStrmExt->DataListLock, oldIrql);

                pSrb->Status = STATUS_INSUFFICIENT_RESOURCES;
                pSrb->CommandData.DataBufferArray->DataUsed = 0;
                ASSERT(pAVCStrmReq->CommandData.BufferStruct.FrameBuffer);
                break;
            }
#else               // Win9x
                MmGetSystemAddressForMdl    (pSrb->Irp->MdlAddress);
#endif        
        }

        // This is a Async command
        NextIrpStack = IoGetNextIrpStackLocation(pIrpReq);
        NextIrpStack->MajorFunction = IRP_MJ_INTERNAL_DEVICE_CONTROL;
        NextIrpStack->Parameters.DeviceIoControl.IoControlCode = IOCTL_AVCSTRM_CLASS;
        NextIrpStack->Parameters.Others.Argument1 = pAVCStrmReq;

        // Not cancellable!
        IoSetCancelRoutine(
            pIrpReq,
            NULL
            );

        IoSetCompletionRoutine( 
            pIrpReq,
            AVCTapeReqReadDataCR,
            pDriverReq,
            TRUE,  // Success
            TRUE,  // Error
            TRUE   // or Cancel
            );

        pSrb->Status = STATUS_PENDING;
        pStrmExt->cntDataSubmitted++;

        Status = 
            IoCallDriver(
                pDevExt->pBusDeviceObject,
                pIrpReq
                );

        LeaveAVCStrm(pStrmExt->hMutexReq);

        if(Status == STATUS_PENDING) {
            // Normal case.
            return;  // Will complete asychronousely (Success, Error, or Cancel)
        } else {
            //
            // Complete the data request synchronousely (no pending)
            //
            if(pDriverReq->Context1 == NULL || pDriverReq->Context2 == NULL) {
                TRACE(TL_STRM_WARNING|TL_CIP_WARNING,("pSrb:%x; SRB_READ_DATA/WRITE IRP completed with Status;%x\n", pSrb, Status));
                return;
            } else {
                TRACE(TL_STRM_WARNING,("AVCSTRM_READ/WRITE: pSrb %x; failed or completed with ST:%x; pAVCStrmReq:%x\n", pSrb, Status, pAVCStrmReq));
                ASSERT(FALSE);
                // Complete the SRB if not pending
                pSrb->Status = pDevExt->bDevRemoved ? STATUS_DEVICE_REMOVED : STATUS_UNSUCCESSFUL;
                pSrb->CommandData.DataBufferArray->DataUsed = 0;
            }
        }

        break;
            
    default:
        //
        // invalid / unsupported command. Fail it as such
        //
        pSrb->Status = STATUS_NOT_SUPPORTED;
        break;
    }   


    ASSERT(pSrb->Status != STATUS_PENDING);

    // Finally, send the srb back up ...
    StreamClassStreamNotification( 
        StreamRequestComplete,
        pSrb->StreamObject,
        pSrb );
}


NTSTATUS
DriverEntry(
    IN PDRIVER_OBJECT DriverObject,
    IN PUNICODE_STRING RegistryPath
    )

/*++

Routine Description:

    This where life begins for a driver.  The stream class takes care
    of alot of stuff for us, but we still need to fill in an initialization
    structure for the stream class and call it.

Arguments:

    Context1 - DriverObject
    Context2 - RegistryPath

Return Value:

    The function value is the final status from the initialization operation.

--*/
{

    HW_INITIALIZATION_DATA HwInitData;


    TRACE(TL_PNP_ERROR,("<<<<<<< MSTape.sys: %s; %s; %x %x >>>>>>>>\n", 
        __DATE__, __TIME__, DriverObject, RegistryPath));

#ifdef TIME_BOMB
    if (HasEvaluationTimeExpired()) {
        TRACE(TL_PNP_ERROR, ("Evaluation period expired!") );
        return STATUS_EVALUATION_EXPIRATION;
    }
#endif

    TRACE(TL_PNP_ERROR,("===================================================================\n"));
    TRACE(TL_PNP_ERROR,("TapeTraceMask=0x%.8x = 0x[7][6][5][4][3][2][1][0] where\n", TapeTraceMask));
    TRACE(TL_PNP_ERROR,("\n"));
    TRACE(TL_PNP_ERROR,("PNP:   [0]:Loading, power state, surprise removal, device SRB..etc.\n"));
    TRACE(TL_PNP_ERROR,("61883: [1]:Plugs, connection, CMP info and call to 61883.\n"));
    TRACE(TL_PNP_ERROR,("CIP:   [2]:Isoch data transfer.\n"));
    TRACE(TL_PNP_ERROR,("AVC:   [3]:AVC commands.\n"));
    TRACE(TL_PNP_ERROR,("Stream:[4]:Data intersec, open/close,.state, property etc.\n"));
    TRACE(TL_PNP_ERROR,("Clock: [5]:Clock (event and signal)etc.\n"));
    TRACE(TL_PNP_ERROR,("===================================================================\n"));
    TRACE(TL_PNP_ERROR,("dd mstape!TapeTraceMask L1\n"));
    TRACE(TL_PNP_ERROR,("e mstape!TapeTraceMask <new value> <enter>\n"));
    TRACE(TL_PNP_ERROR,("<for each nibble: ERROR:8, WARNING:4, TRACE:2, INFO:1, MASK:f>\n"));
    TRACE(TL_PNP_ERROR,("===================================================================\n\n"));


    //
    // Fill in the HwInitData structure    
    //
    RtlZeroMemory( &HwInitData, sizeof(HW_INITIALIZATION_DATA) );

    HwInitData.HwInitializationDataSize = sizeof(HwInitData);
    HwInitData.HwInterrupt              = NULL;

    HwInitData.HwReceivePacket          = DVRcvStreamDevicePacket;
    HwInitData.HwRequestTimeoutHandler  = DVTimeoutHandler; 
    HwInitData.HwCancelPacket           = DVCRCancelOnePacket;
    HwInitData.DeviceExtensionSize      = sizeof(DVCR_EXTENSION) +     
                                          sizeof(AVC_DEV_PLUGS) * 2;

    //
    // The ULONG is used in SRB_WRITE_DATA to keep track of 
    // number of times the same SRB was attached for transmit.
    // 
    // Data SRB: ULONG is used (< sizeof(AV_61883_REQ)
    // DeviceControl or StreamControl Srb: AV_61883_REQ is used.
    HwInitData.PerRequestExtensionSize  = sizeof(AV_61883_REQUEST);    // Per SRB
    HwInitData.PerStreamExtensionSize   = sizeof(STREAMEX);         // Per pin/stream
    HwInitData.FilterInstanceExtensionSize = 0;

    HwInitData.BusMasterDMA             = FALSE;
    HwInitData.Dma24BitAddresses        = FALSE;
    HwInitData.BufferAlignment          = sizeof(ULONG) - 1;
    HwInitData.TurnOffSynchronization   = TRUE;
    HwInitData.DmaBufferSize            = 0;

    return StreamClassRegisterAdapter(DriverObject, RegistryPath, &HwInitData); 
}
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\drivers\wdm\capture\mini\mstape\mstputil.h ===
//
// Copyright (C) Microsoft Corporation, 1999 - 2000  
//
// MsTpUtil.h
//


VOID
DVDelayExecutionThread(
    ULONG ulDelayMSec
    );

NTSTATUS
DVSubmitIrpSynch(
    IN PDVCR_EXTENSION   pDevExt,
    IN PIRP              pIrp,
    IN PAV_61883_REQUEST pAVReq
    );

//
// Related to DeviceControl
//
#ifdef SUPPORT_LOCAL_PLUGS
BOOL
AVCTapeCreateLocalPlug(
    IN PDVCR_EXTENSION  pDevExt,
    IN AV_61883_REQUEST * pAVReq,
    IN CMP_PLUG_TYPE PlugType,
    IN AV_PCR *pPCR,
    OUT ULONG *pPlugNumber,
    OUT HANDLE *pPlugHandle
    );

BOOL
AVCTapeDeleteLocalPlug(
    IN PDVCR_EXTENSION  pDevExt,
    IN AV_61883_REQUEST * pAVReq,
    OUT ULONG *pPlugNumber,
    OUT HANDLE *pPlugHandle
    );
BOOL
AVCTapeSetLocalPlug(
    IN PDVCR_EXTENSION  pDevExt,
    IN AV_61883_REQUEST * pAVReq,
    IN HANDLE *pPlugHandle,
    IN AV_PCR *pPCR
    );
#endif

NTSTATUS
AVCDevGetDevPlug( 
    IN PDVCR_EXTENSION  pDevExt,
    IN CMP_PLUG_TYPE PlugType,
    IN ULONG  PlugNum,
    OUT HANDLE  *pPlugHandle
   );

NTSTATUS
AVCDevGetPlugState(
    IN PDVCR_EXTENSION  pDevExt,
    IN HANDLE  hPlug,
    OUT CMP_GET_PLUG_STATE *pPlugState
    );

NTSTATUS
DVGetUnitCapabilities(
    IN PDVCR_EXTENSION   pDevExt,
    IN PIRP              pIrp,
    IN PAV_61883_REQUEST pAVReq
    );

BOOL
DVGetDevModeOfOperation(   
    PDVCR_EXTENSION  pDevExt
    );

BOOL
DVGetDevIsItDVCPro(   
    IN PDVCR_EXTENSION  pDevExt
    );

BOOL
DVGetDevSignalFormat(
    IN PDVCR_EXTENSION  pDevExt,
    IN KSPIN_DATAFLOW   DataFlow,
    IN PSTREAMEX        pStrmExt
    );

BOOL 
DVCmpGUIDsAndFormatSize(
    IN PKSDATARANGE pDataRange1,
    IN PKSDATARANGE pDataRange2,
    IN BOOL fCompareFormatSize
    );

ULONGLONG 
GetSystemTime(
    );

VOID
DvFreeTextualString(
  PDVCR_EXTENSION pDevExt,
  GET_UNIT_IDS  * pUnitIds
  );


#ifdef MSDV_SUPPORT_EXTRACT_SUBCODE_DATA
VOID
DVCRExtractTimecodeFromFrame(
    IN PDVCR_EXTENSION pDevExt,
    IN PSTREAMEX       pStrmExt,
    IN PUCHAR          pFrameBuffer
    );
#endif

#ifdef MSDV_SUPPORT_EXTRACT_DV_DATE_TIME
VOID
DVCRExtractRecDateAndTimeFromFrame(
    IN PDVCR_EXTENSION pDevExt,
    IN PSTREAMEX       pStrmExt,
    IN PUCHAR          pFrameBuffer
    );
#endif

#ifdef MSDV_SUPPORT_MUTE_AUDIO
BOOL
DVMuteDVFrame(
    IN PDVCR_EXTENSION pDevExt,
    IN OUT PUCHAR      pFrameBuffer,
    IN BOOL            bMute     // TRUE to mute; FALSE to un-Mute
    );
#endif

BOOL
DVGetPropertyValuesFromRegistry(
    IN PDVCR_EXTENSION  pDevExt
    );

BOOL
DVSetPropertyValuesToRegistry(	
    PDVCR_EXTENSION  pDevExt
    );

BOOL
DVAccessDeviceInterface(
    IN PDVCR_EXTENSION  pDevExt,
    IN const ULONG ulNumCategories,
    IN GUID DVCategories[]
    );
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\drivers\wdm\capture\mini\mstape\mstputil.c ===
/*++

Copyright (C) Microsoft Corporation, 1999 - 2000  

Module Name:

    MsTpUtil.c

Abstract:

    Provide utility functions for MSTAPE.

Last changed by:
    
    Author:      Yee J. Wu

Environment:

    Kernel mode only

Revision History:

    $Revision::                    $
    $Date::                        $

--*/

#include "strmini.h"
#include "ksmedia.h"
#include "1394.h"
#include "61883.h"
#include "avc.h"
#include "dbg.h"
#include "MsTpFmt.h"
#include "MsTpDef.h"
#include "MsTpAvc.h"
#include "MsTpUtil.h"  

#include "XPrtDefs.h"

#if 0  // Enable later
#ifdef ALLOC_PRAGMA
     #pragma alloc_text(PAGE, DVDelayExecutionThread)
     #pragma alloc_text(PAGE, DVGetUnitCapabilities)
     // Local variables might paged out but the called might use it in DISPATCH level!
     // #pragma alloc_text(PAGE, DVGetDevModeOfOperation)
     // #pragma alloc_text(PAGE, DVGetDevIsItDVCPro)
     // #pragma alloc_text(PAGE, DVGetDevSignalFormat)
     #pragma alloc_text(PAGE, DvAllocatePCResource)
     #pragma alloc_text(PAGE, DvFreePCResource)
     #pragma alloc_text(PAGE, DVGetPlugState)
#endif
#endif

extern AVCSTRM_FORMAT_INFO  AVCStrmFormatInfoTable[];

VOID
DVDelayExecutionThread(
    ULONG ulDelayMSec
    )
/*
    Device might need a "wait" in between AV/C commands.
*/
{
    PAGED_CODE();

    if (ulDelayMSec)
    {
        LARGE_INTEGER tmDelay;   

        TRACE(TL_PNP_TRACE,("DelayExeThrd: %d MSec\n",  ulDelayMSec));
    
        tmDelay.LowPart  =  (ULONG) (-1 * ulDelayMSec * 10000);
        tmDelay.HighPart = -1;
        KeDelayExecutionThread(KernelMode, FALSE, &tmDelay);
    }
}


NTSTATUS
DVIrpSynchCR(
    IN PDEVICE_OBJECT   DeviceObject,
    IN PIRP             pIrp,
    IN PKEVENT          Event
    )
{
    KeSetEvent(Event, 0, FALSE);
    return STATUS_MORE_PROCESSING_REQUIRED;
} // DVIrpSynchCR


NTSTATUS
DVSubmitIrpSynch(
    IN PDVCR_EXTENSION   pDevExt,
    IN PIRP              pIrp,
    IN PAV_61883_REQUEST pAVReq
    )
{
    NTSTATUS            Status;
    KEVENT              Event;
    PIO_STACK_LOCATION  NextIrpStack;
  

    Status = STATUS_SUCCESS;;

    NextIrpStack = IoGetNextIrpStackLocation(pIrp);
    NextIrpStack->MajorFunction = IRP_MJ_INTERNAL_DEVICE_CONTROL;
    NextIrpStack->Parameters.DeviceIoControl.IoControlCode = IOCTL_61883_CLASS;
    NextIrpStack->Parameters.Others.Argument1 = pAVReq;

    KeInitializeEvent(&Event, NotificationEvent, FALSE);

    IoSetCompletionRoutine( 
        pIrp,
        DVIrpSynchCR,
        &Event,
        TRUE,
        TRUE,
        TRUE
        );

    Status = 
        IoCallDriver(
            pDevExt->pBusDeviceObject,
            pIrp
            );

    if (Status == STATUS_PENDING) {
        
        TRACE(TL_PNP_TRACE,("Irp is pending...\n"));
                
        if(KeGetCurrentIrql() < DISPATCH_LEVEL) {
            KeWaitForSingleObject( 
                &Event,
                Executive,
                KernelMode,
                FALSE,
                NULL
                );
            TRACE(TL_PNP_TRACE,("Irp has completed; IoStatus.Status %x\n", pIrp->IoStatus.Status));
            Status = pIrp->IoStatus.Status;  // Final status
  
        }
        else {
            ASSERT(FALSE && "Pending but in DISPATCH_LEVEL!");
            return Status;
        }
    }

    return Status;
} // DVSubmitIrpSynchAV

#ifdef SUPPORT_LOCAL_PLUGS

BOOL
AVCTapeCreateLocalPlug(
    IN PDVCR_EXTENSION  pDevExt,
    IN AV_61883_REQUEST * pAVReq,
    IN CMP_PLUG_TYPE PlugType,
    IN AV_PCR *pPCR,
    OUT ULONG *pPlugNumber,
    OUT HANDLE *pPlugHandle
    )
/* 
    To be a compliant device, we need to have both input and output 
    plugs in order to do isoch streaming. These plug is belong to 
    the device and is part of the device extension.  In theory, the
    lugs belong to the unit (ei.e. avc.sys) and not this subunit 
    Driver; however, in this case, we create directly from 61883.sys.
*/  
{   
    NTSTATUS Status = STATUS_SUCCESS;
    PIRP pIrp;

    pIrp = IoAllocateIrp(pDevExt->pBusDeviceObject->StackSize, FALSE);
    if(!pIrp) 
        return FALSE;
    
    // Create a local oPCR
    // Need to correctly update Overhead_ID and payload fields of PC's own oPCR
    RtlZeroMemory(pAVReq, sizeof(AV_61883_REQUEST));
    INIT_61883_HEADER(pAVReq, Av61883_CreatePlug);

    pAVReq->CreatePlug.Context   = NULL;
    pAVReq->CreatePlug.pfnNotify = NULL; 
    pAVReq->CreatePlug.PlugType  = PlugType;

    if(PlugType == CMP_PlugOut) 
        pAVReq->CreatePlug.Pcr.oPCR = pPCR->oPCR;
    else 
        pAVReq->CreatePlug.Pcr.iPCR = pPCR->iPCR;

    Status = DVSubmitIrpSynch(pDevExt, pIrp, pAVReq);

    if(!NT_SUCCESS(Status)) {
        *pPlugNumber = 0xffffffff;
        *pPlugHandle = 0;
        TRACE(TL_61883_ERROR,("Av61883_CreatePlug (%s) Failed:%x\n", 
            PlugType == CMP_PlugOut ? "oPCR":"iPCR", Status));
    } else {
        *pPlugNumber = pAVReq->CreatePlug.PlugNum;
        *pPlugHandle = pAVReq->CreatePlug.hPlug;
        TRACE(TL_61883_TRACE,("Av61883_CreatePlug (%s): PlugNum:%d, hPlug:%x\n", 
            PlugType == CMP_PlugOut ? "oPCR":"iPCR", *pPlugNumber, *pPlugHandle));
#if DBG
        if(PlugType == CMP_PlugOut) {
            TRACE(TL_61883_WARNING,("Av61883_CreatePlug: oPCR DataRate:%d (%s); Payload:%d, Overhead_ID:0x%x\n",
                pPCR->oPCR.DataRate,
                (pPCR->oPCR.DataRate == CMP_SPEED_S100) ? "S100" :
                (pPCR->oPCR.DataRate == CMP_SPEED_S200) ? "S200" :
                (pPCR->oPCR.DataRate == CMP_SPEED_S400) ? "S400" : "Sxxx",
                pPCR->oPCR.Payload,
                pPCR->oPCR.OverheadID
                ));
        }
#endif        
    }

    IoFreeIrp(pIrp);
    pIrp = NULL;

    return NT_SUCCESS(Status);
}

BOOL
AVCTapeDeleteLocalPlug(
    IN PDVCR_EXTENSION  pDevExt,
    IN AV_61883_REQUEST * pAVReq,
    OUT ULONG *pPlugNumber,
    OUT HANDLE *pPlugHandle
    )
/* 
    Delete a local plug.
*/  
{   
    NTSTATUS Status = STATUS_SUCCESS;
    PIRP pIrp;

    TRACE(TL_61883_TRACE,("Deleting hPlug[%d]:%x\n", *pPlugNumber, *pPlugHandle));

    pIrp = IoAllocateIrp(pDevExt->pBusDeviceObject->StackSize, FALSE);
    if(!pIrp) 
        return FALSE;

    RtlZeroMemory(pAVReq, sizeof(AV_61883_REQUEST));
    INIT_61883_HEADER(pAVReq, Av61883_DeletePlug);
    pAVReq->DeletePlug.hPlug = *pPlugHandle;

    Status = DVSubmitIrpSynch(pDevExt, pIrp, pAVReq);

    if(!NT_SUCCESS(Status)) {
        TRACE(TL_61883_ERROR,("Av61883_DeletePlug Failed; ST:%x\n", Status));        
        // Do not care if this result in error.
    } else {
        *pPlugNumber = 0xffffffff;
        *pPlugHandle = 0;
        TRACE(TL_61883_TRACE,("Av61883_DeltePlug suceeded.\n"));
    }

    IoFreeIrp(pIrp);
    pIrp = NULL;

    return NT_SUCCESS(Status);

}


BOOL
AVCTapeSetLocalPlug(
    IN PDVCR_EXTENSION  pDevExt,
    IN AV_61883_REQUEST * pAVReq,
    IN HANDLE *pPlugHandle,
    IN AV_PCR *pPCR
    )
/* 
    Set the content of a local plug.
*/  
{   
    NTSTATUS Status = STATUS_SUCCESS;
    PIRP pIrp;

    pIrp = IoAllocateIrp(pDevExt->pBusDeviceObject->StackSize, FALSE);
    if(!pIrp) 
        return FALSE;

    RtlZeroMemory(pAVReq, sizeof(AV_61883_REQUEST));
    INIT_61883_HEADER(pAVReq, Av61883_SetPlug);
    pAVReq->SetPlug.hPlug = *pPlugHandle;
    pAVReq->SetPlug.Pcr   = *pPCR;

     TRACE(TL_61883_TRACE,("Av61883_SetPlug hPlug:%x to %x.\n", *pPlugHandle, pPCR->ulongData));

    Status = DVSubmitIrpSynch(pDevExt, pIrp, pAVReq);

#if DBG
    if(!NT_SUCCESS(Status)) {
        TRACE(TL_61883_ERROR,("Av61883_SetPlug to %x Failed; ST:%x\n", pPCR->ulongData, Status));        
    } 
#endif

    IoFreeIrp(pIrp);
    pIrp = NULL;

    return NT_SUCCESS(Status);
}

#endif // SUPPORT_LOCAL_PLUGS


//
// Get device plug and query its state
//
NTSTATUS
AVCDevGetDevPlug( 
    IN PDVCR_EXTENSION  pDevExt,
    IN CMP_PLUG_TYPE PlugType,
    IN ULONG  PlugNum,
    OUT HANDLE  *pPlugHandle
   )
/*++

Routine Description:

    Get the targe device's plug handle
 
Arguments:

Return Value:

    STATUS_SUCCESS 
    STATUS_INSUFFICIENT_RESOURCES
    status return from 61883.

--*/
{
    PIRP pIrp;
    PAV_61883_REQUEST  pAVReq;
    NTSTATUS Status = STATUS_SUCCESS;

    PAGED_CODE();

    if(!(pIrp = IoAllocateIrp(pDevExt->pBusDeviceObject->StackSize, FALSE)))
        return STATUS_INSUFFICIENT_RESOURCES;

    if(!(pAVReq = (AV_61883_REQUEST *) ExAllocatePool(NonPagedPool, sizeof(AV_61883_REQUEST)))) { 
        IoFreeIrp(pIrp); pIrp = NULL;
        return STATUS_INSUFFICIENT_RESOURCES;
    }

    RtlZeroMemory(pAVReq, sizeof(AV_61883_REQUEST));
    INIT_61883_HEADER(pAVReq, Av61883_GetPlugHandle);
    pAVReq->GetPlugHandle.PlugNum = PlugNum;
    pAVReq->GetPlugHandle.hPlug   = 0;
    pAVReq->GetPlugHandle.Type    = PlugType;

    if(NT_SUCCESS(        
        Status = DVSubmitIrpSynch( 
            pDevExt,
            pIrp,
            pAVReq
            ))) {
        *pPlugHandle = pAVReq->GetPlugHandle.hPlug;
        TRACE(TL_61883_WARNING,("Created h%sPlugDV[%d]=%x\n", PlugType == CMP_PlugIn ? "I" : "O", PlugNum, *pPlugHandle));
    } else {
        TRACE(TL_61883_ERROR,("Created h%sPlugDV[%d] failed; Status:%x\n", PlugType == CMP_PlugIn ? "I" : "O", PlugNum, Status));
        Status = STATUS_INSUFFICIENT_RESOURCES;
    }

    IoFreeIrp(pIrp); pIrp = NULL;
    ExFreePool(pAVReq); pAVReq = NULL;

    return Status;
}


NTSTATUS
AVCDevGetPlugState(
    IN PDVCR_EXTENSION  pDevExt,
    IN HANDLE  hPlug,
    OUT CMP_GET_PLUG_STATE *pPlugState
    )
/*++

Routine Description:

    Ask 61883.sys for the plug state.
 
Arguments:

Return Value:

    Nothing

--*/
{
    PIRP pIrp;
    PAV_61883_REQUEST  pAVReq;
    NTSTATUS Status = STATUS_SUCCESS;

    PAGED_CODE();

    if(!hPlug || !pPlugState) 
        return STATUS_INVALID_PARAMETER;    

    if(!(pIrp = IoAllocateIrp(pDevExt->pBusDeviceObject->StackSize, FALSE)))
        return STATUS_INSUFFICIENT_RESOURCES;

    if(!(pAVReq = (AV_61883_REQUEST *) ExAllocatePool(NonPagedPool, sizeof(AV_61883_REQUEST)))) { 
        IoFreeIrp(pIrp); pIrp = NULL;
        return STATUS_INSUFFICIENT_RESOURCES;
    }

    RtlZeroMemory(pAVReq, sizeof(AV_61883_REQUEST));
    INIT_61883_HEADER(pAVReq, Av61883_GetPlugState);
    pAVReq->GetPlugState.hPlug = hPlug;

    if(NT_SUCCESS(
        Status = DVSubmitIrpSynch( 
            pDevExt,
            pIrp,
            pAVReq
            ))) {
        //
        // Transfer plug state (note: these are dynamic values)
        //
        *pPlugState = pAVReq->GetPlugState;

        TRACE(TL_61883_WARNING,("GetPlugState: ST %x; State %x; DRate %d (%s); Payld %d; BCCnt %d; PPCnt %d\n", 
            pAVReq->Flags ,
            pAVReq->GetPlugState.State,
            pAVReq->GetPlugState.DataRate,
            (pAVReq->GetPlugState.DataRate == CMP_SPEED_S100) ? "S100" : 
            (pAVReq->GetPlugState.DataRate == CMP_SPEED_S200) ? "S200" :
            (pAVReq->GetPlugState.DataRate == CMP_SPEED_S400) ? "S400" : "Sxxx",
            pAVReq->GetPlugState.Payload,
            pAVReq->GetPlugState.BC_Connections,
            pAVReq->GetPlugState.PP_Connections
            ));
    }
    else {
        TRACE(TL_61883_ERROR,("GetPlugState Failed %x\n", Status));
    }

    IoFreeIrp(pIrp); pIrp = NULL;
    ExFreePool(pAVReq); pAVReq = NULL;

    return Status;
}

#ifndef NT51_61883

NTSTATUS
AVCDevSubmitIrpSynch1394(
    IN PDEVICE_OBJECT pDevObj,
    IN PIRP pIrp,
    IN PIRB pIrb
    )
{
    NTSTATUS            Status;
    KEVENT              Event;
    PIO_STACK_LOCATION  NextIrpStack;
  

    Status = STATUS_SUCCESS;;

    NextIrpStack = IoGetNextIrpStackLocation(pIrp);
    NextIrpStack->MajorFunction = IRP_MJ_INTERNAL_DEVICE_CONTROL;
    NextIrpStack->Parameters.DeviceIoControl.IoControlCode = IOCTL_1394_CLASS;
    NextIrpStack->Parameters.Others.Argument1 = pIrb;

    KeInitializeEvent(&Event, NotificationEvent, FALSE);

    IoSetCompletionRoutine( 
        pIrp,
        DVIrpSynchCR,
        &Event,
        TRUE,
        TRUE,
        TRUE
        );

    Status = 
        IoCallDriver(
            pDevObj,
            pIrp
            );

    if (Status == STATUS_PENDING) {
        
        TRACE(TL_PNP_TRACE,("Irp is pending...\n"));
                
        if(KeGetCurrentIrql() < DISPATCH_LEVEL) {
            KeWaitForSingleObject( 
                &Event,
                Executive,
                KernelMode,
                FALSE,
                NULL
                );
            TRACE(TL_PNP_TRACE,("Irp has completed; IoStatus.Status %x\n", pIrp->IoStatus.Status));
            Status = pIrp->IoStatus.Status;  // Final status
  
        }
        else {
            ASSERT(FALSE && "Pending but in DISPATCH_LEVEL!");
            return Status;
        }
    }

    return Status;
} // AVCDevSubmitIrpSynch1394

NTSTATUS
Av1394_GetGenerationCount(
    IN PDVCR_EXTENSION  pDevExt,
    OUT PULONG pGenerationCount
    )
{
    NTSTATUS    ntStatus = STATUS_SUCCESS;
    PIRP        pIrp = NULL;
    PIRB        p1394Irb = NULL;
    CCHAR       StackSize;


    PAGED_CODE();

    StackSize = pDevExt->pBusDeviceObject->StackSize;

    pIrp = IoAllocateIrp(StackSize, FALSE);
    p1394Irb = ExAllocatePool(NonPagedPool, sizeof(IRB));

    if ((pIrp == NULL) || (p1394Irb == NULL)) {

        TRACE(TL_PNP_ERROR, ("Failed to allocate pIrp (%x) or p1394Irb (%x)", pIrp, p1394Irb));
        ntStatus = STATUS_INSUFFICIENT_RESOURCES;
        goto Exit_GetGenerationCount;
    }

    //
    // Get the current generation count first
    //
    p1394Irb->FunctionNumber = REQUEST_GET_GENERATION_COUNT;
    p1394Irb->Flags = 0;

    ntStatus = AVCDevSubmitIrpSynch1394(pDevExt->pBusDeviceObject, pIrp, p1394Irb);
    if (!NT_SUCCESS(ntStatus)) {
        TRACE(TL_PNP_ERROR, ("REQUEST_GET_GENERATION_COUNT Failed %x", ntStatus));
        goto Exit_GetGenerationCount;
    }

    *pGenerationCount = p1394Irb->u.GetGenerationCount.GenerationCount;

Exit_GetGenerationCount:

    if(pIrp) {
        IoFreeIrp(pIrp);  pIrp = NULL;
    }

    if(p1394Irb) {
        ExFreePool(p1394Irb);  p1394Irb = NULL;
    }

    return(ntStatus);
} // Av1394_GetGenerationCount

#define RETRY_COUNT     4

//
// IEEE 1212 Directory definition
//
typedef struct _DIRECTORY_INFO {
    union {
        USHORT          DI_CRC;
        USHORT          DI_Saved_Length;
    } u;
    USHORT              DI_Length;
} DIRECTORY_INFO, *PDIRECTORY_INFO;


//
// IEEE 1212 Immediate entry definition
//
typedef struct _IMMEDIATE_ENTRY {
    ULONG               IE_Value:24;
    ULONG               IE_Key:8;
} IMMEDIATE_ENTRY, *PIMMEDIATE_ENTRY;


NTSTATUS
Av1394_QuadletRead(
    IN PDVCR_EXTENSION  pDevExt,
    IN OUT PULONG  pData,
    IN ULONG  Address
    )
{
    NTSTATUS    ntStatus = STATUS_SUCCESS;
    PIRP        pIrp;
    PIRB        p1394Irb;
    PMDL        Mdl = NULL;
    ULONG       Retries = RETRY_COUNT;
    CCHAR       StackSize;


    PAGED_CODE();

    StackSize = pDevExt->pBusDeviceObject->StackSize;

    pIrp = IoAllocateIrp(StackSize, FALSE);
    p1394Irb = ExAllocatePool(NonPagedPool, sizeof(IRB));

    if ((pIrp == NULL) || (p1394Irb == NULL)) {

        TRACE(TL_PNP_ERROR, ("Failed to allocate Irp (0x%x) or Irb (0x%x)", pIrp, p1394Irb));
        ntStatus = STATUS_INSUFFICIENT_RESOURCES;
        goto Exit_Av1394_QuadletRead;
    }

    Mdl = IoAllocateMdl(pData, sizeof(ULONG), FALSE, FALSE, NULL);

    if (!Mdl) {

        TRACE(TL_PNP_ERROR, ("Failed to allocate Mdl!"));
        ntStatus = STATUS_INSUFFICIENT_RESOURCES;
        goto Exit_Av1394_QuadletRead;
    }

    MmBuildMdlForNonPagedPool(Mdl);

    do {

        p1394Irb->FunctionNumber = REQUEST_ASYNC_READ;
        p1394Irb->Flags = 0;
        p1394Irb->u.AsyncRead.DestinationAddress.IA_Destination_Offset.Off_High = (USHORT)0xffff;
        p1394Irb->u.AsyncRead.DestinationAddress.IA_Destination_Offset.Off_Low = Address;
        p1394Irb->u.AsyncRead.nNumberOfBytesToRead = 4;
        p1394Irb->u.AsyncRead.nBlockSize = 0;
        p1394Irb->u.AsyncRead.fulFlags = 0;
        p1394Irb->u.AsyncRead.Mdl = Mdl;
        p1394Irb->u.AsyncRead.ulGeneration = pDevExt->GenerationCount;
        p1394Irb->u.AsyncRead.chPriority = 0;
        p1394Irb->u.AsyncRead.nSpeed = 0;
        p1394Irb->u.AsyncRead.tCode = 0;
        p1394Irb->u.AsyncRead.Reserved = 0;

        ntStatus = AVCDevSubmitIrpSynch1394(pDevExt->pBusDeviceObject, pIrp, p1394Irb);

        if (ntStatus == STATUS_INVALID_GENERATION) {

            TRACE(TL_PNP_WARNING, ("QuadletRead: Invalid GenerationCount = %d", pDevExt->GenerationCount));

            Av1394_GetGenerationCount(pDevExt, &pDevExt->GenerationCount);
        }
        else if (!NT_SUCCESS(ntStatus)) {

            TRACE(TL_PNP_ERROR, ("Av1394_QuadletRead Failed = 0x%x  Address = 0x%x", ntStatus, Address));
        }
        else {

            goto Exit_Av1394_QuadletRead;
        }

    } while ((ntStatus == STATUS_INVALID_GENERATION) || (Retries--));

Exit_Av1394_QuadletRead:

    if(pIrp) {
        IoFreeIrp(pIrp);  pIrp = NULL;
    }
    if(p1394Irb) {
        ExFreePool(p1394Irb); p1394Irb = NULL;
    }

    if(Mdl) {
        IoFreeMdl(Mdl); Mdl = NULL;
    }

    return(ntStatus);
} // Av1394_QuadletRead


#define KEY_ModuleVendorId      (0x03)
#define KEY_ModuleHwVersion     (0x04)
#define KEY_UnitSwVersion       (0x13)
#define KEY_ModelId             (0x17)

#define DEVICE_NAME_MAX_CHARS   100*sizeof(WCHAR)

NTSTATUS
Av1394_ReadTextualDescriptor(
    IN PDVCR_EXTENSION  pDevExt,
    IN OUT PUNICODE_STRING uniString,
    IN ULONG Address
    )
{
    NTSTATUS ntStatus = STATUS_SUCCESS;
    PULONG pData = NULL;
    ULONG DataLength, i, n;
    ULONG ulUnicode;

    ULONG ulQuadlet;

    union {
        ULONG            asUlong;
        UCHAR            asUchar[4];
        DIRECTORY_INFO   DirectoryHeader;
    } u;


    PAGED_CODE();

    TRACE(TL_PNP_TRACE, ("Address = 0x%x", Address));

    // read the first quadlet of leaf, this is the header
    ntStatus = Av1394_QuadletRead(pDevExt, &ulQuadlet, Address);

    if (!NT_SUCCESS(ntStatus)) {

        TRACE(TL_PNP_ERROR, ("GetUnitInfo: QuadletRead Error = 0x%x", ntStatus));
        goto Exit_Av1394_ReadTextualDescriptor;
    }

    // number of entries
    u.asUlong = bswap(ulQuadlet);
    DataLength = u.DirectoryHeader.DI_Length-2; // one extra for the header

    // read the second quadlet of leaf to determine unicode
    Address += 4;

    ntStatus = Av1394_QuadletRead(pDevExt, &ulQuadlet, Address);

    if (!NT_SUCCESS(ntStatus)) {

        TRACE(TL_PNP_ERROR, ("GetUnitInfo: QuadletRead Error = 0x%x", ntStatus));
        goto Exit_Av1394_ReadTextualDescriptor;
    }

    // save spec type
    ulUnicode = bswap(ulQuadlet);

    pData = ExAllocatePool(NonPagedPool, DataLength*sizeof(ULONG)+2);

    if (pData == NULL) {
        TRACE(TL_PNP_ERROR, ("Failed to allocate pData"));
        ntStatus = STATUS_INSUFFICIENT_RESOURCES;
        goto Exit_Av1394_ReadTextualDescriptor;
    }

    RtlZeroMemory(pData, DataLength*sizeof(ULONG)+2);

    // lets read in each quad
    Address += 8;

    for (i=0; i<DataLength; i++) {

        ntStatus = Av1394_QuadletRead(pDevExt, &u.asUlong, Address+(sizeof(ULONG)*i));

        if (!NT_SUCCESS(ntStatus)) {

            TRACE(TL_PNP_ERROR, ("GetUnitInfo: QuadletRead Error = 0x%x", ntStatus));
            goto Exit_Av1394_ReadTextualDescriptor;
        }

        // need to make sure we have valid characters...
        for (n=0; n<4; n++) {

            // we should be done if the char equals 0x00
            if (u.asUchar[n] == 0x00)
                break;

            if ((u.asUchar[n] == 0x2C) || (u.asUchar[n] < 0x20) || (u.asUchar[n] > 0x7F)) {

                TRACE(TL_PNP_WARNING, ("Invalid Character = 0x%x", u.asUchar[n]));

                // set it to space
                u.asUchar[n] = 0x20;
            }

            if (ulUnicode & 0x80000000)
                n++;
        }

        RtlCopyMemory((PULONG)pData+i, &u.asUlong, sizeof(ULONG));
    }

    // if there's a vendor leaf, then convert it to unicode
    {
        ANSI_STRING     ansiString;

        uniString->Length = 0;
        uniString->MaximumLength = DEVICE_NAME_MAX_CHARS;
        uniString->Buffer = ExAllocatePool(NonPagedPool, uniString->MaximumLength);

        if (!uniString->Buffer) {

            TRACE(TL_PNP_ERROR, ("Failed to allocate uniString.Buffer!"));
            ntStatus = STATUS_INSUFFICIENT_RESOURCES;
            goto Exit_Av1394_ReadTextualDescriptor;
        }
        RtlZeroMemory(uniString->Buffer, uniString->MaximumLength);

        // unicode??
        if (ulUnicode & 0x80000000) {

            RtlAppendUnicodeToString(uniString, ((PWSTR)pData));
        }
        else {

            RtlInitAnsiString(&ansiString, (PUCHAR)pData);
            RtlAnsiStringToUnicodeString(uniString, &ansiString, FALSE);
        }
    }

Exit_Av1394_ReadTextualDescriptor:

    if (pData)
        ExFreePool(pData);

    return(ntStatus);
} // ReadTextualLeaf




NTSTATUS
AVCDevGetModelText(
    IN PDVCR_EXTENSION  pDevExt,
    PUNICODE_STRING  pUniRootModelString,
    PUNICODE_STRING  pUniUnitModelString
    )
{
    CCHAR StackSize;
    PIRP pIrp = NULL;
    PIRB p1394Irb = NULL;
    NTSTATUS ntStatus = STATUS_SUCCESS;
    CONFIG_ROM ConfigRom;
    ULONG ulQuadlet = 0;
    ULONG CurrAddress;
    PULONG UnitDir = NULL, UnitDirToFree = NULL;
    ULONG i;
    ULONG LastKey;

    union {
        ULONG           asUlong;
        DIRECTORY_INFO  DirInfo;
        IMMEDIATE_ENTRY Entry;
    } u, u2; //, u3;


    PAGED_CODE();

    StackSize = pDevExt->pBusDeviceObject->StackSize;
    pIrp = IoAllocateIrp(StackSize, FALSE);
    p1394Irb = ExAllocatePool(NonPagedPool, sizeof(IRB));

    if ((pIrp == NULL) || (p1394Irb == NULL)) {
        TRACE(TL_PNP_ERROR, ("Failed to allocate pIrp (%x) or p1394Irb (%x)", pIrp, p1394Irb));
        return STATUS_INSUFFICIENT_RESOURCES;
    }

    //
    // Get the current generation count (used to read config rom)
    //
    Av1394_GetGenerationCount(pDevExt, &pDevExt->GenerationCount);


    //
    // Get Model Text from the Root directory
    //
    CurrAddress = 0xF0000414;

    // root directory
    ntStatus = Av1394_QuadletRead(pDevExt, &ulQuadlet, CurrAddress);

    if (!NT_SUCCESS(ntStatus)) {

        TRACE(TL_PNP_ERROR, ("GetUnitInfo: QuadletRead Error = 0x%x", ntStatus));
        goto Exit_GetUnitInfo;
    }

    u.asUlong = bswap(ulQuadlet);
    TRACE(TL_PNP_TRACE, ("RootDir: Length = %d", u.DirInfo.DI_Length));

    // process the root directory
    for (i=0; i<u.DirInfo.DI_Length; i++) {

        CurrAddress += sizeof(ULONG);

        ntStatus = Av1394_QuadletRead(pDevExt, &ulQuadlet, CurrAddress);

        if (!NT_SUCCESS(ntStatus)) {

            TRACE(TL_PNP_ERROR, ("GetUnitInfo: QuadletRead Error = 0x%x", ntStatus));
            goto Exit_GetUnitInfo;
        }

        u2.asUlong = bswap(ulQuadlet);

        TRACE(TL_PNP_TRACE, ("CurrAddress = 0x%x  Key = 0x%x  Value = 0x%x",
	        CurrAddress, u2.Entry.IE_Key, u2.Entry.IE_Value));

        // ModelId Textual Descriptor
        if ((u2.Entry.IE_Key == 0x81) && (LastKey == KEY_ModelId)) {

            // get the first entry of the textual descriptor
            Av1394_ReadTextualDescriptor( pDevExt, 
                                          pUniRootModelString,
                                          CurrAddress+(u2.Entry.IE_Value*sizeof(ULONG))
                                          );            
        }
#if 0
        // ModelId Textual Descriptor Layer
        if ((u2.Entry.IE_Key == 0xC1) && (LastKey == KEY_ModelId)) {

            ULONG   DescAddress;

            DescAddress = CurrAddress+(u2.Entry.IE_Value*sizeof(ULONG));

            Av1394_QuadletRead(pDevExt, &ulQuadlet, DescAddress);

            u3.asUlong = bswap(ulQuadlet);

            // get the first entry of the textual descriptor
            Av1394_ReadTextualDescriptor( pDevExt, 
                                          pUniRootModelString,
                                          DescAddress+(u3.Entry.IE_Value*sizeof(ULONG))
                                          );
        }
#endif
        LastKey = u2.Entry.IE_Key;
    }


    //
    // Get Configuration Info
    //
    p1394Irb->FunctionNumber = REQUEST_GET_CONFIGURATION_INFO;
    p1394Irb->Flags = 0;

    p1394Irb->u.GetConfigurationInformation.ConfigRom = NULL;
    p1394Irb->u.GetConfigurationInformation.UnitDirectoryBufferSize = 0;
    p1394Irb->u.GetConfigurationInformation.UnitDirectory = NULL;
    p1394Irb->u.GetConfigurationInformation.UnitDependentDirectoryBufferSize = 0;
    p1394Irb->u.GetConfigurationInformation.UnitDependentDirectory = NULL;
    p1394Irb->u.GetConfigurationInformation.VendorLeafBufferSize = 0;
    p1394Irb->u.GetConfigurationInformation.VendorLeaf = NULL;
    p1394Irb->u.GetConfigurationInformation.ModelLeafBufferSize = 0;
    p1394Irb->u.GetConfigurationInformation.ModelLeaf = NULL;

    ntStatus = AVCDevSubmitIrpSynch1394(pDevExt->pBusDeviceObject, pIrp, p1394Irb);
    if (!NT_SUCCESS(ntStatus)) {

        TRACE(TL_PNP_ERROR, ("REQUEST_GET_CONFIGURATION_INFO Failed %x", ntStatus));
        goto Exit_GetUnitInfo;
    }


    //
    // Allocate buffer in order retrieve unit directory of a config rom
    //
    if (p1394Irb->u.GetConfigurationInformation.UnitDirectoryBufferSize) {

        UnitDir = UnitDirToFree = 
        p1394Irb->u.GetConfigurationInformation.UnitDirectory =
            ExAllocatePool(NonPagedPool, p1394Irb->u.GetConfigurationInformation.UnitDirectoryBufferSize);

        if (!p1394Irb->u.GetConfigurationInformation.UnitDirectory) {
            TRACE(TL_PNP_ERROR, ("Couldn't allocate memory for the UnitDirectory"));
            ntStatus = STATUS_INSUFFICIENT_RESOURCES;
            goto Exit_GetUnitInfo;
        }
    }
    else {
         TRACE(TL_PNP_ERROR, ("No Unit directory. Bad Device."));
         ntStatus = STATUS_BAD_DEVICE_TYPE;
         goto Exit_GetUnitInfo;
    }

    p1394Irb->u.GetConfigurationInformation.ConfigRom = &ConfigRom;
    p1394Irb->u.GetConfigurationInformation.UnitDependentDirectoryBufferSize = 0;
    p1394Irb->u.GetConfigurationInformation.VendorLeafBufferSize = 0;
    p1394Irb->u.GetConfigurationInformation.ModelLeafBufferSize = 0;
    ntStatus = AVCDevSubmitIrpSynch1394(pDevExt->pBusDeviceObject, pIrp, p1394Irb);
    if (!NT_SUCCESS(ntStatus)) {
        TRACE(TL_PNP_ERROR, ("2nd REQUEST_GET_CONFIGURATION_INFO Failed = 0x%x", ntStatus));
        goto Exit_GetUnitInfo;
    }

    //
    // Process unit directory; see this doc for detail:
    //    1394TA specification: Configuration ROM for AV/C device 1.0 (AVWG)
    //
    u.asUlong = bswap(*UnitDir++);  // Get length, and dkip first quadlet
    TRACE(TL_PNP_TRACE, ("UnitDir: Length = %d", u.DirInfo.DI_Length));

    CurrAddress = p1394Irb->u.GetConfigurationInformation.UnitDirectoryLocation.IA_Destination_Offset.Off_Low;
    for (i=0; i<u.DirInfo.DI_Length; i++) {
        TRACE(TL_PNP_TRACE, ("i = %d  UnitDir = 0x%x  *UnitDir = 0x%x", i, UnitDir, *UnitDir));
        u2.asUlong = bswap(*UnitDir++);
        CurrAddress += sizeof(ULONG);
        TRACE(TL_PNP_TRACE, ("UnitDir Quadlet = 0x%x", u2.asUlong));

        //
        // ModelId Textual Descriptor
        //
        if ((u2.Entry.IE_Key == 0x81) && (LastKey == KEY_ModelId)) {

            // get the first entry of the textual descriptor
            Av1394_ReadTextualDescriptor( 
                pDevExt, 
                pUniUnitModelString,
                CurrAddress+(u2.Entry.IE_Value*sizeof(ULONG))
                );
        }
#if 0
        //
        // UnitModelId Textual Descriptor Layer
        //
        if ((u2.Entry.IE_Key == 0xC1) && (LastKey == KEY_ModelId)) {
            ULONG   DescAddress;
            DescAddress = CurrAddress+(u2.Entry.IE_Value*sizeof(ULONG));
            Av1394_QuadletRead(pDevExt, &ulQuadlet, DescAddress);
            u3.asUlong = bswap(ulQuadlet);

            // get the first entry of the textual descriptor
            Av1394_ReadTextualDescriptor( 
                pDevExt,
                pUniUnitModelString,
                DescAddress+(u3.Entry.IE_Value*sizeof(ULONG))
                );
        }
#endif

        LastKey = u2.Entry.IE_Key;
    }


Exit_GetUnitInfo:

    if (UnitDirToFree) {
        ExFreePool(UnitDirToFree);  UnitDirToFree = NULL;
    }
    if(pIrp) {
        IoFreeIrp(pIrp);  pIrp = NULL;
    }
    if(p1394Irb) {
        ExFreePool(p1394Irb);  p1394Irb = NULL;
    }

    return ntStatus;
}
#endif


NTSTATUS
DVGetUnitCapabilities(
    IN PDVCR_EXTENSION  pDevExt,
    IN PIRP            pIrp,
    IN PAV_61883_REQUEST  pAVReq
    )
{
    NTSTATUS Status;
    GET_UNIT_IDS * pUnitIds;
    GET_UNIT_CAPABILITIES * pUnitCaps;

    PAGED_CODE();


    //
    // Query device's capability
    //
    pUnitCaps = (GET_UNIT_CAPABILITIES *) ExAllocatePool(NonPagedPool, sizeof(GET_UNIT_CAPABILITIES));
    if(!pUnitCaps) {
        TRACE(TL_61883_ERROR,("DVGetUnitCapabilities: Allocate pUnitCaps (%d bytes) failed\n", sizeof(GET_UNIT_CAPABILITIES)));
        return STATUS_INSUFFICIENT_RESOURCES;
    }

    // UnitIDS is cached in DevExt.
    pUnitIds = &pDevExt->UnitIDs;

    RtlZeroMemory(pAVReq, sizeof(AV_61883_REQUEST));
    INIT_61883_HEADER(pAVReq, Av61883_GetUnitInfo);
    pAVReq->GetUnitInfo.nLevel   = GET_UNIT_INFO_IDS;
    RtlZeroMemory(pUnitIds, sizeof(GET_UNIT_IDS));  // Initialize pointers.    
    pAVReq->GetUnitInfo.Information = (PVOID) pUnitIds;

    Status = 
        DVSubmitIrpSynch( 
            pDevExt,
            pIrp,
            pAVReq
            );

    if(!NT_SUCCESS(Status)) {
        TRACE(TL_61883_ERROR,("Av61883_GetUnitCapabilities Failed = 0x%x\n", Status));
        pDevExt->UniqueID.QuadPart = 0;
        pDevExt->ulVendorID = 0;
        pDevExt->ulModelID  = 0;
    }
    else {
        pDevExt->UniqueID   = pUnitIds->UniqueID;
        pDevExt->ulVendorID = pUnitIds->VendorID;
        pDevExt->ulModelID  = pUnitIds->ModelID;

         TRACE(TL_61883_TRACE,("UniqueId:(Low)%x:(High)%x; VendorID:%x; ModelID:%x\n", 
            pDevExt->UniqueID.LowPart, pDevExt->UniqueID.HighPart, pDevExt->ulVendorID, pDevExt->ulModelID));
  
        //
        // Allocate memory needed for the text string for VendorText, 
        // ModelText and UntiModelText.
        //
        if(pUnitIds->ulVendorLength) {
            pUnitIds->VendorText = (PWSTR) ExAllocatePool(NonPagedPool, pUnitIds->ulVendorLength);
            if(!pUnitIds->VendorText)
                goto AbortGetUnitCapabilities;
        }

        if(pUnitIds->ulModelLength) {
            pUnitIds->ModelText = (PWSTR) ExAllocatePool(NonPagedPool, pUnitIds->ulModelLength);
            if(!pUnitIds->ModelText)
                goto AbortGetUnitCapabilities;
        }


#ifdef NT51_61883
        if(pUnitIds->ulUnitModelLength) {
            pUnitIds->UnitModelText = (PWSTR) ExAllocatePool(NonPagedPool, pUnitIds->ulUnitModelLength);
            if(!pUnitIds->UnitModelText)
                goto AbortGetUnitCapabilities;
        }
#else
        // 
        // 1st version of 61883.sys does not retrieve Root and Unit model text 
        // the same way as in WinXP; so we retieve them directly using 1394 API
        //
        if(!NT_SUCCESS(AVCDevGetModelText(
                pDevExt,
                &pDevExt->UniRootModelString,
                &pDevExt->UniUnitModelString
                ))) {
                goto AbortGetUnitCapabilities;
        } 
#endif

        Status = 
            DVSubmitIrpSynch( 
                pDevExt,
                pIrp,
                pAVReq
                );
    }


    RtlZeroMemory(pAVReq, sizeof(AV_61883_REQUEST));
    INIT_61883_HEADER(pAVReq, Av61883_GetUnitInfo);
    pAVReq->GetUnitInfo.nLevel = GET_UNIT_INFO_CAPABILITIES;
    RtlZeroMemory(pUnitCaps, sizeof(GET_UNIT_CAPABILITIES));  // Initialize pointers.    
    pAVReq->GetUnitInfo.Information = (PVOID) pUnitCaps;

    Status = 
        DVSubmitIrpSynch( 
            pDevExt,
            pIrp,
            pAVReq
            );

    if(!NT_SUCCESS(Status)) {
        TRACE(TL_61883_ERROR,("Av61883_GetUnitCapabilities Failed = 0x%x\n", Status));
        pDevExt->pDevOutPlugs->MaxDataRate = 0;
        pDevExt->pDevOutPlugs->NumPlugs    = 0; 

        pDevExt->pDevInPlugs->MaxDataRate  = 0;
        pDevExt->pDevInPlugs->NumPlugs     = 0;
    }
    else {
        //
        // There can never be more than MAX_NUM_PCR (= 31) of plugs
        //
        ASSERT(pUnitCaps->NumOutputPlugs <= MAX_NUM_PCR);
        ASSERT(pUnitCaps->NumInputPlugs  <= MAX_NUM_PCR);

        pDevExt->pDevOutPlugs->MaxDataRate = pUnitCaps->MaxDataRate;  
        pDevExt->pDevOutPlugs->NumPlugs = (pUnitCaps->NumOutputPlugs > MAX_NUM_PCR ? MAX_NUM_PCR : pUnitCaps->NumOutputPlugs);

        pDevExt->pDevInPlugs->MaxDataRate = pUnitCaps->MaxDataRate;  
        pDevExt->pDevInPlugs->NumPlugs = (pUnitCaps->NumInputPlugs > MAX_NUM_PCR ? MAX_NUM_PCR : pUnitCaps->NumInputPlugs);
    }

    TRACE(TL_61883_TRACE,("** UnitCaps: OutP:%d; InP:%d; MDRate:%s; CtsF:%x; HwF:%x; VID:%x; MID:%x\n", 
         pUnitCaps->NumOutputPlugs,
         pUnitCaps->NumInputPlugs,
         pUnitCaps->MaxDataRate == 0 ? "S100": pUnitCaps->MaxDataRate == 1? "S200" : "S400 or +",   
         pUnitCaps->CTSFlags,
         pUnitCaps->HardwareFlags,
         pUnitIds->VendorID,
         pUnitIds->ModelID
         ));      

AbortGetUnitCapabilities:

    if(pUnitIds->ulVendorLength && pUnitIds->VendorText) {
         TRACE(TL_61883_TRACE,("Vendor:    Len:%d; \"%S\"\n", pUnitIds->ulVendorLength, pUnitIds->VendorText)); 
        if(!NT_SUCCESS(Status)) {
            ExFreePool(pUnitIds->VendorText);  pUnitIds->VendorText = NULL;
        }
    }
    
    if(pUnitIds->ulModelLength && pUnitIds->ModelText) {
         TRACE(TL_61883_TRACE,("Model:     Len:%d; \"%S\"\n", pUnitIds->ulModelLength, pUnitIds->ModelText)); 
        if(!NT_SUCCESS(Status)) {
            ExFreePool(pUnitIds->ModelText);  pUnitIds->ModelText = NULL;
        }
    }

#ifdef NT51_61883
    if(pUnitIds->ulUnitModelLength && pUnitIds->UnitModelText) {
        TRACE(TL_61883_TRACE,("UnitModel (61883): Len:%d; \"%S\"\n", pUnitIds->ulUnitModelLength, pUnitIds->UnitModelText));
        if(!NT_SUCCESS(Status)) {
            ExFreePool(pUnitIds->UnitModelText);  pUnitIds->UnitModelText = NULL;
        }
    }
#else
    if(pDevExt->UniRootModelString.Length && pDevExt->UniRootModelString.Buffer) {
        TRACE(TL_61883_TRACE,("RootModel (MSTape): Len:%d; \"%S\"\n", pDevExt->UniRootModelString.Length, pDevExt->UniRootModelString.Buffer));
        if(!NT_SUCCESS(Status)) {
            ExFreePool(pDevExt->UniRootModelString.Buffer);  pDevExt->UniRootModelString.Buffer = NULL;
        }
    }

    if(pDevExt->UniUnitModelString.Length && pDevExt->UniUnitModelString.Buffer) {
        TRACE(TL_61883_TRACE,("UnitModel (MSTape): Len:%d; \"%S\"\n", pDevExt->UniUnitModelString.Length, pDevExt->UniUnitModelString.Buffer));
        if(!NT_SUCCESS(Status)) {
            ExFreePool(pDevExt->UniUnitModelString.Buffer);  pDevExt->UniUnitModelString.Buffer = NULL;
        }
    }
#endif

    ExFreePool(pUnitCaps);  pUnitCaps = NULL;

    return Status;
}

#ifdef SUPPORT_NEW_AVC_CMD
BOOL
InitializeAVCCommand (
    PAVC_CMD pAVCCmd,
    AvcCommandType  CmdType,
    AvcSubunitType  SubunitType,
    UCHAR  SubunitID,  
    AVC_COMMAND_OP_CODE  Opcode
    )
{
    switch(Opcode) {
    case OPC_UNIT_CONNECT_AV_20:
        pAVCCmd->DataLen = 8;

        pAVCCmd->ConnectAV.AudSrc = 3;
        pAVCCmd->ConnectAV.VidSrc = 3;
        pAVCCmd->ConnectAV.AudDst = 0;  // subunit
        pAVCCmd->ConnectAV.VidDst = 0;  // subunit

        pAVCCmd->ConnectAV.VidSrc = 0xff;
        pAVCCmd->ConnectAV.AudSrc = 0xff;
        pAVCCmd->ConnectAV.VidDst = 0x20;
        pAVCCmd->ConnectAV.AudDst = 0x20;
        break;

    case OPC_TAPE_PLAY_C3:
        pAVCCmd->DataLen = 4;
        // pAVCCmd->TapePlay.PlaybackMode = 
        break;

    default:
        return FALSE;
    }

    pAVCCmd->CmdFrame.CmdHeader.CTS = 0;
    pAVCCmd->CmdFrame.CmdHeader.CmdType = CmdType;
    pAVCCmd->CmdFrame.CmdHeader.SubunitTypeID.SubunitType = SubunitType;
    pAVCCmd->CmdFrame.CmdHeader.SubunitTypeID.SubunitID = SubunitID;
    pAVCCmd->CmdFrame.CmdHeader.Opcode = Opcode;

    return TRUE;
}
#endif // SUPPORT_NEW_AVC_CMD

BOOL
DVGetDevModeOfOperation(   
    IN PDVCR_EXTENSION pDevExt
    )
{
    NTSTATUS Status;
    BYTE    bAvcBuf[MAX_FCP_PAYLOAD_SIZE];

#ifdef SUPPORT_NEW_AVC_CMD
    AVC_CMD  AVCCmd;
#endif

    PAGED_CODE();

#ifdef SUPPORT_NEW_AVC_CMD
    InitializeAVCCommand(&AVCCmd, AVC_CTYPE_STATUS, AVC_SUBUNITTYPE_UNIT, 0, OPC_UNIT_CONNECT_AV_20);
    InitializeAVCCommand(&AVCCmd, AVC_CTYPE_CONTROL, AVC_SUBUNITTYPE_TAPE_PLAYER, 0, OPC_TAPE_PLAY_C3);
    AVCCmd.TapePlay.PlaybackMode = NEXT_FRAME;   // Testing...
#endif
    
    //
    // Use ConnectAV STATUS cmd to determine mode of operation,
    // except for some Canon DVs that it requires its vendor specific command
    //    
   
    Status = DVIssueAVCCommand(pDevExt, AVC_CTYPE_STATUS, DV_CONNECT_AV_MODE, (PVOID) bAvcBuf); 

     TRACE(TL_61883_TRACE,("GetDevModeOfOperation(DV_CONNECT_AV_MODE): Status %x,  %x %x %x %x : %x %x %x %x\n",
        Status, bAvcBuf[0], bAvcBuf[1], bAvcBuf[2], bAvcBuf[3], bAvcBuf[4], bAvcBuf[5], bAvcBuf[6], bAvcBuf[7]));

    if(Status == STATUS_SUCCESS) {
        if(bAvcBuf[0] == 0x0c) {
            if(bAvcBuf[1] == 0x00 &&
               bAvcBuf[2] == 0x38 &&
               bAvcBuf[3] == 0x38) {
                pDevExt->ulDevType = ED_DEVTYPE_CAMERA;  
            } else 
            if(bAvcBuf[1] == 0xa0 &&
               bAvcBuf[2] == 0x00 &&
               bAvcBuf[3] == 0x00) {
                pDevExt->ulDevType = ED_DEVTYPE_VCR;  
            } 
        }    
    } else if(pDevExt->ulVendorID == VENDORID_CANON) {
        // If this is a Canon, we can try this:
        Status = DVIssueAVCCommand(pDevExt, AVC_CTYPE_STATUS, DV_VEN_DEP_CANON_MODE, (PVOID) bAvcBuf); 
         TRACE(TL_61883_TRACE,("GetDevModeOfOperation(DV_VEN_DEP_CANON_MODE): Status %x,  %x %x %x %x : %x %x %x %x\n",
            Status, bAvcBuf[0], bAvcBuf[1], bAvcBuf[2], bAvcBuf[3], bAvcBuf[4], bAvcBuf[5], bAvcBuf[6], bAvcBuf[7]));

        if(Status == STATUS_SUCCESS) {
            if(bAvcBuf[0] == 0x0c) {
                if(bAvcBuf[7] == 0x38) {
                    pDevExt->ulDevType = ED_DEVTYPE_CAMERA;  
                } else 
                if(bAvcBuf[7] == 0x20) {
                    pDevExt->ulDevType = ED_DEVTYPE_VCR;  
                } 
            }
        }
    }

    //
    // Connect AV is an optional command, a device may not support it.
    // If this device support a tape subunit, we will assume we are in that device type.
    //
    if(Status != STATUS_SUCCESS) {
        // We are the subunit driver so if any of the device type is a 
        // tape subunit, we are in that device type.
        if(   pDevExt->Subunit_Type[0] == AVC_DEVICE_TAPE_REC 
           || pDevExt->Subunit_Type[1] == AVC_DEVICE_TAPE_REC
           || pDevExt->Subunit_Type[2] == AVC_DEVICE_TAPE_REC
           || pDevExt->Subunit_Type[3] == AVC_DEVICE_TAPE_REC) {
            pDevExt->ulDevType = ED_DEVTYPE_VCR;
        } else {
            pDevExt->ulDevType = ED_DEVTYPE_UNKNOWN;  // Such as MediaConverter box.
        }

        TRACE(TL_PNP_ERROR|TL_FCP_ERROR,("GetDevModeOfOperation: failed but we choose DevType:%x\n", pDevExt->ulDevType));
    }

     TRACE(TL_61883_TRACE,("** Mode of operation: %s (%x); NumOPlg:%d; NumIPlg:%d\n", 
        pDevExt->ulDevType == ED_DEVTYPE_CAMERA ? "Camera" : pDevExt->ulDevType == ED_DEVTYPE_VCR ? "Tape" : "Unknown",
        pDevExt->ulDevType, pDevExt->pDevOutPlugs->NumPlugs, pDevExt->pDevInPlugs->NumPlugs));
             
    return TRUE;
}


BOOL
DVGetDevIsItDVCPro(   
    IN PDVCR_EXTENSION pDevExt
    )
{
    NTSTATUS Status;
    BYTE    bAvcBuf[MAX_FCP_PAYLOAD_SIZE];

    PAGED_CODE();    

    //
    // Use Panasnoic's vendor dependent command to determine if the system support DVCPro
    //        
    Status = DVIssueAVCCommand(pDevExt, AVC_CTYPE_STATUS, DV_VEN_DEP_DVCPRO, (PVOID) bAvcBuf);
    pDevExt->bDVCPro = (Status == STATUS_SUCCESS);
    
     TRACE(TL_61883_TRACE,("GetDevIsItDVCPro? %s; Status %x,  %x %x %x %x : %x %x %x %x\n",
        pDevExt->bDVCPro ? "Yes":"No",
        Status, bAvcBuf[0], bAvcBuf[1], bAvcBuf[2], bAvcBuf[3], bAvcBuf[4], bAvcBuf[5], bAvcBuf[6], bAvcBuf[7]));

    return pDevExt->bDVCPro;
}


#define GET_MEDIA_FMT_MAX_RETRIES 10  // AVC.sys will retry so we may rey just once.

BOOL
DVGetDevSignalFormat(
    IN PDVCR_EXTENSION pDevExt,
    IN KSPIN_DATAFLOW  DataFlow,
    IN PSTREAMEX       pStrmExt
    )
{
    NTSTATUS Status;
    BYTE    bAvcBuf[MAX_FCP_PAYLOAD_SIZE];
    LONG lRetries = GET_MEDIA_FMT_MAX_RETRIES;

    PAGED_CODE();


    //
    // Respone of Input/output signal mode is used to determine plug signal format:
    //
    //     FMT: 
    //         DVCR 10:00 0000 = 0x80; Canon returns 00:100000 (0x20)
    //             50/60: 0:NTSC/60; 1:PAL/50
    //             STYPE:
    //                 SD: 00000  (DVCPRO:11110)
    //                 HD: 00010
    //                 SDL:00001
    //             00:
    //             SYT:
    //         MPEG 10:10 0000 = 0xa0
    //             TSF:0:NotTimeShifted; 1:Time shifted
    //             000 0000 0000 0000 0000 0000
    //
    // If this command failed, we can use Input/Output Signal Mode subunit command
    // to determine signal format.
    // 

    do {
        RtlZeroMemory(bAvcBuf, sizeof(bAvcBuf));

        Status = 
            DVIssueAVCCommand(
                pDevExt, 
                AVC_CTYPE_STATUS, 
                pStrmExt == NULL ? DV_OUT_PLUG_SIGNAL_FMT : pStrmExt->pStrmInfo->DataFlow == KSPIN_DATAFLOW_OUT ? DV_OUT_PLUG_SIGNAL_FMT : DV_IN_PLUG_SIGNAL_FMT,
                (PVOID) bAvcBuf
                );  

        --lRetries;

        // 
        // Camcorders that has problem with this command:
        //
        // Panasonic's DVCPRO: if power on while connected to PC, it will 
        // reject this command with (STATUS_REQUEST_NOT_ACCEPTED)
        // so we will retry up to 10 time with .5 second wait between tries.
        //
        // JVC: returns STATUS_NOT_SUPPORTED.
        //
        // SONY DV Decoder Box: return STATUS_TIMEOUT
        //

        if(Status == STATUS_SUCCESS ||
           Status == STATUS_NOT_SUPPORTED ||
           Status == STATUS_TIMEOUT) {
            break;  // No need to retry
        } else 
        if(Status == STATUS_REQUEST_NOT_ACCEPTED) {
            if(lRetries >= 0) 
                DVDelayExecutionThread(DV_AVC_CMD_DELAY_DVCPRO);        
        }
        // else retry.
    } while (lRetries >= 0); 


    if(NT_SUCCESS(Status)) {

        switch(bAvcBuf[0]) {

        case FMT_DVCR:
        case FMT_DVCR_CANON:  // Workaround for buggy Canon Camcorders
            switch(bAvcBuf[1] & FDF0_STYPE_MASK) {
            case FDF0_STYPE_SD_DVCR:
            case FDF0_STYPE_SD_DVCPRO:                
                pDevExt->VideoFormatIndex = ((bAvcBuf[1] & FDF0_50_60_MASK) ? AVCSTRM_FORMAT_SDDV_PAL : AVCSTRM_FORMAT_SDDV_NTSC);
                break;
            case FDF0_STYPE_HD_DVCR:
                pDevExt->VideoFormatIndex = ((bAvcBuf[1] & FDF0_50_60_MASK) ? AVCSTRM_FORMAT_HDDV_PAL : AVCSTRM_FORMAT_HDDV_NTSC);
                break;
            case FDF0_STYPE_SDL_DVCR:
                pDevExt->VideoFormatIndex = ((bAvcBuf[1] & FDF0_50_60_MASK) ? AVCSTRM_FORMAT_SDLDV_PAL : AVCSTRM_FORMAT_SDLDV_NTSC);
                break;                
            default:  // Unknown format
                Status = STATUS_UNSUCCESSFUL;              
                break;
            }   
            break;

        case FMT_MPEG:
            pDevExt->VideoFormatIndex = AVCSTRM_FORMAT_MPEG2TS;
            break;

        default:
            Status = STATUS_UNSUCCESSFUL;
        }  

        if(NT_SUCCESS(Status)) {
             TRACE(TL_PNP_ERROR|TL_FCP_ERROR,("ST:%x; PlugSignal:FMT[%x %x %x %x]; VideoFormatIndex;%d\n", Status, bAvcBuf[0], bAvcBuf[1], bAvcBuf[2] , bAvcBuf[3], pDevExt->VideoFormatIndex)); 
            return TRUE;  // Success
        }        
    }

     TRACE(TL_FCP_TRACE,("ST:%x; PlugSignal:FMT[%x %x %x %x]\n", Status, bAvcBuf[0], bAvcBuf[1], bAvcBuf[2] , bAvcBuf[3], pDevExt->VideoFormatIndex)); 


    //
    // If "recommended" unit input/output plug signal status command fails,
    // try "manadatory" input/output signal mode status command.
    // This command may failed some device if its tape is not playing for
    // output signal mode command.
    //

    RtlZeroMemory(bAvcBuf, sizeof(bAvcBuf));
    Status = 
        DVIssueAVCCommand(
            pDevExt, 
            AVC_CTYPE_STATUS, 
            DataFlow == KSPIN_DATAFLOW_OUT ? VCR_OUTPUT_SIGNAL_MODE : VCR_INPUT_SIGNAL_MODE,
            (PVOID) bAvcBuf
            );             

    if(STATUS_SUCCESS == Status) {

        PKSPROPERTY_EXTXPORT_S pXPrtProperty;

        pXPrtProperty = (PKSPROPERTY_EXTXPORT_S) bAvcBuf;
         TRACE(TL_STRM_TRACE|TL_FCP_TRACE,("** MediaFormat: Retry %d mSec; ST:%x; SignalMode:%dL\n", 
            (GET_MEDIA_FMT_MAX_RETRIES - lRetries) * DV_AVC_CMD_DELAY_DVCPRO, Status, pXPrtProperty->u.SignalMode - ED_BASE));

        switch(pXPrtProperty->u.SignalMode) {
        case ED_TRANSBASIC_SIGNAL_525_60_SD:
            pDevExt->VideoFormatIndex = AVCSTRM_FORMAT_SDDV_NTSC;
            if(pStrmExt) {
                pStrmExt->cipQuad2[0] = FMT_DVCR; // 0x80 
                if(pDevExt->bDVCPro)
                    pStrmExt->cipQuad2[1] = FDF0_50_60_NTSC | FDF0_STYPE_SD_DVCPRO; // 0x78 = NTSC(0):STYPE(11110):RSV(00)
                else
                    pStrmExt->cipQuad2[1] = FDF0_50_60_NTSC | FDF0_STYPE_SD_DVCR;   // 0x00 = NTSC(0):STYPE(00000):RSV(00)            
            }
            break;
        case ED_TRANSBASIC_SIGNAL_625_50_SD:
            pDevExt->VideoFormatIndex = AVCSTRM_FORMAT_SDDV_PAL;
            if(pStrmExt) {
                pStrmExt->cipQuad2[0] = FMT_DVCR;  // 0x80
                if(pDevExt->bDVCPro)
                    pStrmExt->cipQuad2[1] = FDF0_50_60_PAL | FDF0_STYPE_SD_DVCPRO; // 0xf8 = PAL(1):STYPE(11110):RSV(00)
                else
                    pStrmExt->cipQuad2[1] = FDF0_50_60_PAL | FDF0_STYPE_SD_DVCR;   // 0x80 = PAL(1):STYPE(00000):RSV(00)             
            }
            break;

        case ED_TRANSBASIC_SIGNAL_MPEG2TS:
            pDevExt->VideoFormatIndex = AVCSTRM_FORMAT_MPEG2TS;
            break;

        default:
            TRACE(TL_PNP_ERROR|TL_FCP_ERROR,("Unsupported SignalMode:%dL", pXPrtProperty->u.SignalMode - ED_BASE));
            ASSERT(FALSE && "Unsupported IoSignal! Refuse to load.");
            return FALSE;
            break;
        }
    } 

    // WORKITEM Sony HW CODEC does not response to any AVC command.
    // We are making an exception here to load it.
    if(Status == STATUS_TIMEOUT) {
        Status = STATUS_SUCCESS;
    }

    // We must know the signal format!!  If this failed, the driver will either:
    //    fail to load, or fail to open an stream
    ASSERT(Status == STATUS_SUCCESS && "Failed to get media signal format!\n");

#if DBG
    if(pStrmExt)  {
        // Note: bAvcBuf[0] is operand[1] == 10:fmt
         TRACE(TL_STRM_TRACE|TL_CIP_TRACE,("** MediaFormat: St:%x; idx:%d; CIP:[FMT:%.2x(%s); FDF:[%.2x(%s,%s):SYT]\n",
            Status,
            pDevExt->VideoFormatIndex,
            pStrmExt->cipQuad2[0],
            pStrmExt->cipQuad2[0] == FMT_DVCR ? "DVCR" : pStrmExt->cipQuad2[0] == FMT_MPEG ? "MPEG" : "Fmt:???",
            pStrmExt->cipQuad2[1],
            (pStrmExt->cipQuad2[1] & FDF0_50_60_MASK) == FDF0_50_60_PAL ? "PAL" : "NTSC",
            (pStrmExt->cipQuad2[1] & FDF0_STYPE_MASK) == FDF0_STYPE_SD_DVCR ?   "SD" : \
            (pStrmExt->cipQuad2[1] & FDF0_STYPE_MASK) == FDF0_STYPE_SDL_DVCR ?  "SDL" : \
            (pStrmExt->cipQuad2[1] & FDF0_STYPE_MASK) == FDF0_STYPE_HD_DVCR ?   "HD" : \
            (pStrmExt->cipQuad2[1] & FDF0_STYPE_MASK) == FDF0_STYPE_SD_DVCPRO ? "DVCPRO" : "DV:????"
            ));
    } else
         TRACE(TL_STRM_TRACE|TL_CIP_TRACE,("** MediaFormat: St:%x; use idx:%d\n", Status, pDevExt->VideoFormatIndex));

#endif

    return STATUS_SUCCESS == Status;
}



BOOL 
DVCmpGUIDsAndFormatSize(
    IN PKSDATARANGE pDataRange1,
    IN PKSDATARANGE pDataRange2,
    IN BOOL fCompareFormatSize
    )
/*++

Routine Description:

    Checks for a match on the three GUIDs and FormatSize

Arguments:

    IN pDataRange1
    IN pDataRange2

Return Value:

    TRUE if all elements match
    FALSE if any are different

--*/

{
    return (
        IsEqualGUID (
            &pDataRange1->MajorFormat, 
            &pDataRange2->MajorFormat) &&
        IsEqualGUID (
            &pDataRange1->SubFormat, 
            &pDataRange2->SubFormat) &&
        IsEqualGUID (
            &pDataRange1->Specifier, 
            &pDataRange2->Specifier) &&
        (fCompareFormatSize ? 
                (pDataRange1->FormatSize == pDataRange2->FormatSize) : TRUE ));
}


//
// GetSystemTime in 100 nS units
//

ULONGLONG GetSystemTime()
{

    LARGE_INTEGER rate, ticks;

    ticks = KeQueryPerformanceCounter(&rate);

    return (KSCONVERT_PERFORMANCE_TIME(rate.QuadPart, ticks));
}


VOID
DvFreeTextualString(
    PDVCR_EXTENSION pDevExt,
    GET_UNIT_IDS  * pUnitIds
  )
{
    if(pUnitIds->ulVendorLength && pUnitIds->VendorText) {
        ExFreePool(pUnitIds->VendorText);  pUnitIds->VendorText = NULL;
    }
    
    if(pUnitIds->ulModelLength && pUnitIds->ModelText) {
        ExFreePool(pUnitIds->ModelText);  pUnitIds->ModelText = NULL;
    }

#ifdef NT51_61883
    if(pUnitIds->ulUnitModelLength && pUnitIds->UnitModelText) {
        ExFreePool(pUnitIds->UnitModelText);  pUnitIds->UnitModelText = NULL;
    }
#else
    if(pDevExt->UniRootModelString.Length && pDevExt->UniRootModelString.Buffer) {
        ExFreePool(pDevExt->UniRootModelString.Buffer);  pDevExt->UniRootModelString.Buffer = NULL;
    }
    if(pDevExt->UniUnitModelString.Length && pDevExt->UniUnitModelString.Buffer) {
        ExFreePool(pDevExt->UniUnitModelString.Buffer);  pDevExt->UniUnitModelString.Buffer = NULL;
    }
#endif
}



#define DIFBLK_SIZE 12000

#define PACK_NO_INFO            0xff

// Subcode header identifier
#define SC_HDR_TIMECODE         0x13
#define SC_HDR_BINARYGROUP      0x14

// header identifier

#define AAUX_HDR_SOURCE         0x50
#define AAUX_HDR_SOURCE_CONTROL 0x51
#define AAUX_HDR_REC_DATE       0x52
#define AAUX_HDR_REC_TIME       0x53
#define AAUX_HDR_BINARY_GROUP   0x54
#define AAUX_HDR_CC             0x55
#define AAUX_HDR_TR             0x56

#define VAUX_HDR_SOURCE         0x60
#define VAUX_HDR_SOURCE_CONTROL 0x61
#define VAUX_HDR_REC_DATE       0x62
#define VAUX_HDR_REC_TIME       0x63
#define VAUX_HDR_BINARY_GROUP   0x64
#define VAUX_HDR_CC             0x65
#define VAUX_HDR_TR             0x66

// Determine section type (MS 3 bits); Fig.66; Table 36.
#define ID0_SCT_MASK            0xe0
#define ID0_SCT_HEADER          0x00
#define ID0_SCT_SUBCODE         0x20
#define ID0_SCT_VAUX            0x40
#define ID0_SCT_AUDIO           0x60
#define ID0_SCT_VIDEO           0x80

// A pack is consisted of one byte of header identifier and 4 bytes of data; Part2, annex D.
typedef struct _DV_PACK {
    UCHAR Header;
    UCHAR Data[4];
} DV_PACK, *PDV_PACK;

typedef struct _DV_H0 {
    UCHAR ID0;
    UCHAR ID1;
    UCHAR ID2;

    UCHAR DSF;
    UCHAR DFTIA;
    UCHAR TF1;
    UCHAR TF2;
    UCHAR TF3;

    UCHAR Reserved[72];
} DV_H0, *PDV_H0;

typedef struct _DV_SC {
    UCHAR ID0;
    UCHAR ID1;
    UCHAR ID2;

    struct {
        UCHAR SID0;
        UCHAR SID1;
        UCHAR Reserved;
        DV_PACK Pack;
    } SSyb0;
    struct {
        UCHAR SID0;
        UCHAR SID1;
        UCHAR Reserved;
        DV_PACK Pack;
    } SSyb1;
    struct {
        UCHAR SID0;
        UCHAR SID1;
        UCHAR Reserved;
        DV_PACK Pack;
    } SSyb2;
    struct {
        UCHAR SID0;
        UCHAR SID1;
        UCHAR Reserved;
        DV_PACK Pack;
    } SSyb3;
    struct {
        UCHAR SID0;
        UCHAR SID1;
        UCHAR Reserved;
        DV_PACK Pack;
    } SSyb4;
    struct {
        UCHAR SID0;
        UCHAR SID1;
        UCHAR Reserved;
        DV_PACK Pack;
    } SSyb5;

    UCHAR Reserved[29];
} DV_SC, *PDV_SC;

#define MAX_VAUX_PACK 15

typedef struct _DV_VAUX {
    UCHAR ID0;
    UCHAR ID1;
    UCHAR ID2;

    DV_PACK Pack[MAX_VAUX_PACK];

    UCHAR Reserved[2];
} DV_VAUX, *PDV_VAUX;

typedef struct _DV_A {
    UCHAR ID0;
    UCHAR ID1;
    UCHAR ID2;
    DV_PACK Pack;
    UCHAR Data[72];
} DV_A, *PDV_A;

typedef struct _DV_V {
    UCHAR ID0;
    UCHAR ID1;
    UCHAR ID2;    
    UCHAR Data[77]; // 3..79
} DV_V, *PDV_V;

// Two source packets
#define V_BLOCKS 15
typedef struct _DV_AV {
    DV_A  A;
    DV_V  V[V_BLOCKS];
} DV_AV, *PDV_AV; 


#define SC_SECTIONS     2
#define VAUX_SECTIONS   3
#define AV_SECTIONS     9

typedef struct _DV_DIF_SEQ {
    DV_H0   H0;
    DV_SC   SC[SC_SECTIONS];
    DV_VAUX VAux[VAUX_SECTIONS];
    DV_AV   AV[AV_SECTIONS];
} DV_DIF_SEQ, *PDV_DIF_SEQ;


typedef struct _DV_FRAME_NTSC {
    DV_DIF_SEQ DifSeq[10];
} DV_FRAME_NTSC, *PDV_FRAME_NTSC;

typedef struct _DV_FRAME_PAL {
    DV_DIF_SEQ DifSeq[12];
} DV_FRAME_PAL, *PDV_FRAME_PAL;

// By setting REC MODE to 111b (invalid recording) can
// cause DV to mute the audio
#define AAUX_REC_MODE_INVALID_MASK 0x38   // xx11:1xxx
#define AAUX_REC_MODE_ORIGINAL     0x08   // xx00:1xxx


#ifdef MSDV_SUPPORT_MUTE_AUDIO
BOOL
DVMuteDVFrame(
    IN PDVCR_EXTENSION pDevExt,
    IN OUT PUCHAR      pFrameBuffer,
    IN BOOL            bMuteAudio
    )
{
    PDV_DIF_SEQ pDifSeq;
#if 0
    PDV_VAUX    pVAux;
    ULONG k;
#endif
    ULONG i, j;
#if 0
    BOOL bFound1 = FALSE;
#endif
    BOOL bFound2 = FALSE;

    pDifSeq = (PDV_DIF_SEQ) pFrameBuffer;

    // find the VVAX Source pack
    for (i=0; i < AVCStrmFormatInfoTable[pDevExt->VideoFormatIndex].FrameSize/DIFBLK_SIZE; i++) {

// #define SHOW_ONE_FIELD_TWICE
#ifdef SHOW_ONE_FIELD_TWICE  // Advise by Adobe that we may want to show bothj field but mute audio
        // Make the field2 output twice, FrameChange to 0 (same as previous frame)
        for (j=0; j < VAUX_SECTIONS; j++) {
            pVAux = &pDifSeq->VAux[j];
            if((pVAux->ID0 & ID0_SCT_MASK) != ID0_SCT_VAUX) {
                 TRACE(TL_CIP_TRACE,("Invalid ID0:%.2x for pVAUX:%x (Dif:%d;V%d;S%d)\n", pVAux->ID0, pVAux, i, j, k)); 
                continue;
            }

            for (k=0; k< MAX_VAUX_PACK; k++) {
                if(pVAux->Pack[k].Header == VAUX_HDR_SOURCE_CONTROL) {
                    if(bMuteAudio) {
                        TRACE(TL_CIP_TRACE,("Mute Audio; pDifSeq:%x; pVAux:%x; (Dif:%d,V%d,S%d); %.2x,[%.2x,%.2x,%.2x,%.2x]; pack[2]->%.2x\n", \
                            pDifSeq, pVAux, i, j, k, \
                            pVAux->Pack[k].Header, pVAux->Pack[k].Data[0], pVAux->Pack[k].Data[1], pVAux->Pack[k].Data[2], pVAux->Pack[k].Data[3], \
                            (pVAux->Pack[k].Data[2] & 0x1F) ));
                        pVAux->Pack[k].Data[2] &= 0x1f; // 0x1F; // set FF, FS and FC to 0
                        TRACE(TL_CIP_INFO,("pVAux->Pack[k].Data[2] = %.2x\n", pVAux->Pack[k].Data[2])); 
                    } else {
                        TRACE(TL_CIP_INFO,("un-Mute Audio; pack[2]: %.2x ->%.2x\n", pVAux->Pack[k].Data[2], (pVAux->Pack[k].Data[2] | 0xc0) ));  
                        pVAux->Pack[k].Data[2] |= 0xe0; // set FF, FS and FCto 1; Show both fields in field 1,2 order
                    }
                    bFound1 = TRUE;
                    break;   // Set only the 1st occurrence
                }
            }
        }
#endif

        for (j=0; j < AV_SECTIONS; j++) {
            if(pDifSeq->AV[j].A.Pack.Header == AAUX_HDR_SOURCE_CONTROL) {
                TRACE(TL_CIP_INFO,("A0Aux %.2x,[%.2x,%.2x,%.2x,%.2x] %.2x->%.2x\n", \
                    pDifSeq->AV[j].A.Pack.Header,  pDifSeq->AV[j].A.Pack.Data[0], \
                    pDifSeq->AV[j].A.Pack.Data[1], pDifSeq->AV[j].A.Pack.Data[2], pDifSeq->AV[j].A.Pack.Data[3], \
                    pDifSeq->AV[j].A.Pack.Data[1], pDifSeq->AV[j].A.Pack.Data[1] | AAUX_REC_MODE_INVALID_MASK
                    ));
                if(bMuteAudio) 
                    pDifSeq->AV[j].A.Pack.Data[1] |= AAUX_REC_MODE_INVALID_MASK;  // Cause DV to mute this.
                else 
                    pDifSeq->AV[j].A.Pack.Data[1] = \
                        (pDifSeq->AV[j].A.Pack.Data[1] & ~AAUX_REC_MODE_INVALID_MASK) | AAUX_REC_MODE_ORIGINAL;
                bFound2 = TRUE;
                break;  // Set only the 1st occurrence
            }
        }

        // Must do the 1st occurance of all Dif sequences;
        pDifSeq++;  // Next DIF sequence
    }
#if 0
    return (bFound1 && bFound2);  
#else
    return bFound2;
#endif
}
#endif

#ifdef MSDV_SUPPORT_EXTRACT_SUBCODE_DATA

VOID
DVCRExtractTimecodeFromFrame(
    IN PDVCR_EXTENSION pDevExt,
    IN PSTREAMEX       pStrmExt,
    IN PUCHAR          pFrameBuffer
    )
{
    PUCHAR pDIFBlk;
    PUCHAR pS0, pS1, pSID0;
    ULONG i, j;
    BYTE LastTimecode[4], Timecode[4]; // hh:mm:ss,ff
    DWORD LastAbsTrackNumber, AbsTrackNumber;
    PUCHAR pSID1;
    BYTE  Timecode2[4]; // hh:mm:ss,ff
    DWORD AbsTrackNumber2;
    BOOL bGetAbsT = TRUE, bGetTimecode = TRUE;


    // Can be called at DISPATCH_LEVEL

    pDIFBlk = (PUCHAR) pFrameBuffer;

    // Save the last timecode so we will now if it has 

    LastTimecode[0] = pStrmExt->Timecode[0];
    LastTimecode[1] = pStrmExt->Timecode[1];
    LastTimecode[2] = pStrmExt->Timecode[2];
    LastTimecode[3] = pStrmExt->Timecode[3];

    LastAbsTrackNumber = pStrmExt->AbsTrackNumber;

    //
    // Traverse thru every DIF BLOCK looking for VA0,1 and 2
    for(i=0; i < AVCStrmFormatInfoTable[pDevExt->VideoFormatIndex].ulNumOfDIFSequences; i++) {

        pS0 = pDIFBlk + 80;
        pS1 = pS0     + 80;


        //
        // Is this Subcode source packet? See Table 36 (P.111) of the Blue Book
        //
        if ((pS0[0] & 0xe0) == 0x20 && (pS1[0] & 0xe0) == 0x20) {

            if(bGetAbsT) {
                //
                // See Figure 42 (p. 94) of the Blue book
                // SID0(Low nibble),1 (high nibble) of every three subcode sync block can form the ATN
                //
                pSID0 = &pS0[3];              
                AbsTrackNumber = 0;
                for (j = 0 ; j < 3; j++) {
                    AbsTrackNumber = (( ( (pSID0[0] & 0x0f) << 4) | (pSID0[1] >> 4) ) << (j * 8)) | AbsTrackNumber;
                    pSID0 += 8;
                    bGetAbsT = FALSE;
                }

                pSID1 = &pS1[3];
                AbsTrackNumber2 = 0;
                for (j = 0 ; j < 3; j++) {
                    AbsTrackNumber2 = (( ( (pSID1[0] & 0x0f) << 4) | (pSID1[1] >> 4) ) << (j * 8)) | AbsTrackNumber2;
                    pSID1 += 8;
                }
            
                // Verify that the track number is the same!
                if(AbsTrackNumber == AbsTrackNumber2) {

                    bGetAbsT = FALSE;
                } else {
                   bGetAbsT = TRUE;
                   TRACE(TL_CIP_TRACE,("%d Sequence;  AbsT (%d,%d) != AbsT2 (%d,%d)\n",
                       i,
                       AbsTrackNumber / 2, AbsTrackNumber & 0x01,                       
                       AbsTrackNumber2 / 2, AbsTrackNumber2 & 0x01
                       ));
                }
            }


            if(bGetTimecode) {
                // See Figure 68 (p. 114) of the Blue Book
                // Subcode sync block number 3, 4 and 5
                for(j = 3; j <= 5; j++) {
                    // 3 bytes of IDs and follow by sequence of 8 bytes SyncBlock (3:5); 
                    // 0x13 == TIMECODE
                    if(pS0[3+3+j*8] == 0x13 
                       && pS0[3+3+j*8+4] != 0xff
                       && pS0[3+3+j*8+3] != 0xff
                       && pS0[3+3+j*8+2] != 0xff
                       && pS0[3+3+j*8+1] != 0xff) {

                        Timecode[0] = pS0[3+3+j*8+4]&0x3f;  // hh
                        Timecode[1] = pS0[3+3+j*8+3]&0x7f;  // mm
                        Timecode[2] = pS0[3+3+j*8+2]&0x7f;  // ss
                        Timecode[3] = pS0[3+3+j*8+1]&0x3f;  // ff
                                        
                        bGetTimecode = FALSE;
                        break;                  
                   }
                }

                // Subcode sync block number 9, 10 and 11
                for(j = 3; j <= 5; j++) {
                    // 3 bytes of IDs and follow by sequence of 8 bytes SyncBlock (3:5); 
                    // 0x13 == TIMECODE
                    if(pS1[3+3+j*8] == 0x13
                       && pS1[3+3+j*8+4] != 0xff
                       && pS1[3+3+j*8+3] != 0xff
                       && pS1[3+3+j*8+2] != 0xff
                       && pS1[3+3+j*8+1] != 0xff) {

                       Timecode2[0] = pS1[3+3+j*8+4]&0x3f;  // hh
                       Timecode2[1] = pS1[3+3+j*8+3]&0x7f;  // mm
                       Timecode2[2] = pS1[3+3+j*8+2]&0x7f;  // ss
                       Timecode2[3] = pS1[3+3+j*8+1]&0x3f;  // ff
            
                       bGetTimecode = FALSE;
                       break;                   
                    }
                }

                //
                // Verify
                //
                if(!bGetTimecode) {

                    if( Timecode[0] == Timecode2[0] 
                     && Timecode[1] == Timecode2[1] 
                     && Timecode[2] == Timecode2[2] 
                     && Timecode[3] == Timecode2[3]) {

                       } else {
                        bGetTimecode = TRUE;
                        TRACE(TL_CIP_TRACE,("%d Sequence;  %.2x:%.2x:%.2x,%.2x != %.2x:%.2x:%.2x,%.2x\n",
                            i,
                            Timecode[0],  Timecode[1],  Timecode[2],  Timecode[3],
                            Timecode2[0], Timecode2[1], Timecode2[2], Timecode2[3]
                            ));
                    }       
                }
            }
        }
        
        if(!bGetAbsT && !bGetTimecode) 
            break;

        pDIFBlk += DIFBLK_SIZE;  // Get to next block    
                
    }

    if(!bGetAbsT && pStrmExt->AbsTrackNumber != AbsTrackNumber) {
        pStrmExt->AbsTrackNumber = AbsTrackNumber;  // BF is the LSB  
        pStrmExt->bATNUpdated = TRUE;
        TRACE(TL_CIP_INFO,("Extracted TrackNum:%d; DicontBit:%d\n", AbsTrackNumber / 2, AbsTrackNumber & 0x01));
    }

    if(!bGetTimecode &&
        (
         Timecode[0] != LastTimecode[0] ||
         Timecode[1] != LastTimecode[1] ||
         Timecode[2] != LastTimecode[2] ||
         Timecode[3] != LastTimecode[3]
        ) 
      )  { 
        pStrmExt->Timecode[0] = Timecode[0];  // hh
        pStrmExt->Timecode[1] = Timecode[1];  // mm
        pStrmExt->Timecode[2] = Timecode[2];  // mm
        pStrmExt->Timecode[3] = Timecode[3];  // ff
        pStrmExt->bTimecodeUpdated = TRUE;

        TRACE(TL_CIP_INFO,("Extracted Timecode %.2x:%.2x:%.2x,%.2x\n", Timecode[0], Timecode[1], Timecode[2], Timecode[3]));
    }    
}

#endif // MSDV_SUPPORT_EXTRACT_SUBCODE_DATA


#ifdef MSDV_SUPPORT_EXTRACT_DV_DATE_TIME

VOID
DVCRExtractRecDateAndTimeFromFrame(
    IN PDVCR_EXTENSION pDevExt,
    IN PSTREAMEX       pStrmExt,
    IN PUCHAR          pFrameBuffer
    )
{
    PUCHAR pDIFBlk;
    PUCHAR pS0, pS1;
    ULONG i, j;
    BOOL bGetRecDate = TRUE, bGetRecTime = TRUE;

    // Can be called at DISPATCH_LEVEL


    pDIFBlk = (PUCHAR) pFrameBuffer + DIFBLK_SIZE * AVCStrmFormatInfoTable[pDevExt->VideoFormatIndex].ulNumOfDIFSequences/2;


    //
    // REC Data (VRD) and Time (VRT) on in the 2nd half oa a video frame
    // 
    for(i=AVCStrmFormatInfoTable[pDevExt->VideoFormatIndex].ulNumOfDIFSequences/2; i < AVCStrmFormatInfoTable[pDevExt->VideoFormatIndex].ulNumOfDIFSequences; i++) {

        pS0 = pDIFBlk + 80;
        pS1 = pS0     + 80;


        //
        // Find SC0 and SC1. See Table 36 (P.111) of the Blue Book
        //
        // SC0/1: ID(0,1,2), Data (3,50), Reserved(51-79)
        //     SC0:Data: SSYB0(3..10), SSYB1(11..18), SSYB2(19..26), SSYB3(27..34), SSYB4(35..42),   SSYB5(43..50)
        //     SC1:Data: SSYB6(3..10), SSYB7(11..18), SSYB8(19..26), SSYB9(27..34), SSYB10(35..42), SSYB11(43..50)
        //         SSYBx(SubCodeId0, SubcodeID1, Reserved, Pack(3,4,5,6,7))
        //
        //  TTC are in the 1st half: SSYB0..11 (every)
        //  TTC are in the 2nd half: SSYB0,3,6,9
        //  VRD are in the 2nd half of a video frame, SSYB1,4,7,10
        //  VRT are in the 2nd half of a video frame, SSYB2,5,8,11
        //

        // Subcode data ?
        if ((pS0[0] & 0xe0) == 0x20 && (pS1[0] & 0xe0) == 0x20) {

            //
            // RecDate: VRD
            //
            if(bGetRecDate) {
                // go thru 6 sync blocks (8 bytes per block) per Subcode; idx 1(SSYB1),4(SSYB4) for SC0
                for(j=0; j <= 5 ; j++) {
                    if(j == 1 || j == 4) {
                        // 0x62== RecDate
                        if(pS0[3+3+j*8] == 0x62) {
                            pStrmExt->RecDate[0] = pS0[3+3+j*8+4];        // Year
                            pStrmExt->RecDate[1] = pS0[3+3+j*8+3]&0x1f;   // Month
                            pStrmExt->RecDate[2] = pS0[3+3+j*8+2]&0x3f;   // Day
                            pStrmExt->RecDate[3] = pS0[3+3+j*8+1]&0x3f;   // TimeZone
                            bGetRecDate = FALSE;
                            break;
                        }
                    }
                }
            }

            if(bGetRecDate) {
                // go thru 6 sync blocks (8 bytes per block) per Subcode; idx 1 (SSYB7),4(SSYB10) for SC1
                for(j=0; j <= 5; j++) {
                    if(j == 1 || j == 4) {
                        // 0x62== RecDate
                        if(pS1[3+3+j*8] == 0x62) {
                            pStrmExt->RecDate[0] = pS1[3+3+j*8+4];         // Year
                            pStrmExt->RecDate[1] = pS1[3+3+j*8+3]&0x1f;    // Month
                            pStrmExt->RecDate[2] = pS1[3+3+j*8+2]&0x3f;    // Day
                            pStrmExt->RecDate[3] = pS1[3+3+j*8+1]&0x3f;    // TimeZone
                            bGetRecDate = FALSE;
                            break;
                        }
                    }
               }
            }

            //
            // RecTime: VRT
            //
            if(bGetRecTime) {
                // go thru 6 sync blocks (8 bytes per block) per Subcode; idx 2(SSYB2),5(SSYB5) for SC0
                for(j=0; j <= 5 ; j++) {
                    if(j == 2 || j == 5) {
                        // 0x63== RecTime
                        if(pS0[3+3+j*8] == 0x63) {
                            pStrmExt->RecTime[0] = pS0[3+3+j*8+4]&0x3f;
                            pStrmExt->RecTime[1] = pS0[3+3+j*8+3]&0x7f;
                            pStrmExt->RecTime[2] = pS0[3+3+j*8+2]&0x7f;
                            pStrmExt->RecTime[3] = pS0[3+3+j*8+1]&0x3f;
                            bGetRecTime = FALSE;
                            break;
                        }
                    }
                }
            }

            if(bGetRecTime) {
                // go thru 6 sync blocks (8 bytes per block) per Subcode; idx 2 (SSYB8),5(SSYB11) for SC1
                for(j=0; j <= 5; j++) {
                    if(j == 2 || j == 5) {
                        // 0x63== RecTime
                        if(pS1[3+3+j*8] == 0x63) {
                            pStrmExt->RecTime[0] = pS1[3+3+j*8+4]&0x3f;
                            pStrmExt->RecTime[1] = pS1[3+3+j*8+3]&0x7f;
                            pStrmExt->RecTime[2] = pS1[3+3+j*8+2]&0x7f;
                            pStrmExt->RecTime[3] = pS1[3+3+j*8+1]&0x3f;
                            bGetRecTime = FALSE;
                            break;
                        }
                    }
                }
            }

        }
        
        if(!bGetRecDate && !bGetRecTime)
            break;

        pDIFBlk += DIFBLK_SIZE;  // Next sequence    
                
    }

    TRACE(TL_PNP_TRACE,("Frame# %.5d, Date %s %x-%.2x-%.2x,  Time %s %.2x:%.2x:%.2x,%.2x\n", 
        (ULONG) pStrmExt->FramesProcessed,
        bGetRecDate ? "NF:" : "Found:", pStrmExt->RecDate[0], pStrmExt->RecDate[1] & 0x1f, pStrmExt->RecDate[2] & 0x3f,                 
        bGetRecTime ? "NF:" : "Found:",pStrmExt->RecTime[0], pStrmExt->RecTime[1], pStrmExt->RecTime[2], pStrmExt->RecTime[3]
       ));
}

#endif //  MSDV_SUPPORT_EXTRACT_DV_DATE_TIME

#ifdef READ_CUTOMIZE_REG_VALUES

NTSTATUS 
CreateRegistryKeySingle(
    IN HANDLE hKey,
    IN ACCESS_MASK desiredAccess,
    PWCHAR pwszSection,
    OUT PHANDLE phKeySection
    )
{
    NTSTATUS status;
    UNICODE_STRING ustr;
    OBJECT_ATTRIBUTES objectAttributes;

    RtlInitUnicodeString(&ustr, pwszSection);
       InitializeObjectAttributes(
              &objectAttributes,
              &ustr,
              OBJ_CASE_INSENSITIVE,
              hKey,
              NULL
              );

    status = 
           ZwCreateKey(
                  phKeySection,
                  desiredAccess,
                  &objectAttributes,
                  0,
                  NULL,                            /* optional*/
                  REG_OPTION_NON_VOLATILE,
                  NULL
                  );         

    return status;
}



NTSTATUS 
CreateRegistrySubKey(
    IN HANDLE hKey,
    IN ACCESS_MASK desiredAccess,
    PWCHAR pwszSection,
    OUT PHANDLE phKeySection
    )
{
    UNICODE_STRING ustr;
    USHORT usPos = 1;             // Skip first backslash
    static WCHAR wSep = '\\';
    NTSTATUS status = STATUS_SUCCESS;

    RtlInitUnicodeString(&ustr, pwszSection);

    while(usPos < ustr.Length) {
        if(ustr.Buffer[usPos] == wSep) {

            // NULL terminate our partial string
            ustr.Buffer[usPos] = UNICODE_NULL;
            status = 
                CreateRegistryKeySingle(
                    hKey,
                    desiredAccess,
                    ustr.Buffer,
                    phKeySection
                    );
            ustr.Buffer[usPos] = wSep;

            if(NT_SUCCESS(status)) {
                ZwClose(*phKeySection);
            } else {
                break;
            }
        }
        usPos++;
    }

    // Create the full key
    if(NT_SUCCESS(status)) {
        status = 
            CreateRegistryKeySingle(
                 hKey,
                 desiredAccess,
                 ustr.Buffer,
                 phKeySection
                 );
    }

    return status;
}



NTSTATUS 
GetRegistryKeyValue (
    IN HANDLE Handle,
    IN PWCHAR KeyNameString,
    IN ULONG KeyNameStringLength,
    IN PVOID Data,
    IN PULONG DataLength
    )

/*++

Routine Description:
    
    This routine gets the specified value out of the registry

Arguments:

    Handle - Handle to location in registry

    KeyNameString - registry key we're looking for

    KeyNameStringLength - length of registry key we're looking for

    Data - where to return the data

    DataLength - how big the data is

Return Value:

    status is returned from ZwQueryValueKey

--*/

{
    NTSTATUS status = STATUS_INSUFFICIENT_RESOURCES;
    UNICODE_STRING keyName;
    ULONG length;
    PKEY_VALUE_FULL_INFORMATION fullInfo;


    RtlInitUnicodeString(&keyName, KeyNameString);
    
    length = sizeof(KEY_VALUE_FULL_INFORMATION) + 
            KeyNameStringLength + *DataLength;
            
    fullInfo = ExAllocatePool(PagedPool, length); 
     
    if (fullInfo) { 
       
        status = ZwQueryValueKey(
                    Handle,
                   &keyName,
                    KeyValueFullInformation,
                    fullInfo,
                    length,
                   &length
                    );
                        
        if (NT_SUCCESS(status)){

            ASSERT(fullInfo->DataLength <= *DataLength); 

            RtlCopyMemory(
                Data,
                ((PUCHAR) fullInfo) + fullInfo->DataOffset,
                fullInfo->DataLength
                );

        }            

        *DataLength = fullInfo->DataLength;
        ExFreePool(fullInfo);

    }        
    
    return (status);

}



NTSTATUS
SetRegistryKeyValue(
   HANDLE hKey,
   PWCHAR pwszEntry, 
   LONG nValue
   )
{
    NTSTATUS status;
    UNICODE_STRING ustr;

    RtlInitUnicodeString(&ustr, pwszEntry);

    status =          
        ZwSetValueKey(
                  hKey,
                  &ustr,
                  0,            /* optional */
                  REG_DWORD,
                  &nValue,
                  sizeof(nValue)
                  );         

   return status;
}

//
// Registry subky and values wide character strings.
//
WCHAR wszSettings[]      = L"Settings";

WCHAR wszATNSearch[]     = L"bSupportATNSearch";
WCHAR wszSyncRecording[] = L"bSyncRecording";
WCHAR wszMaxDataSync[]   = L"tmMaxDataSync";
WCHAR wszPlayPs2RecPs[]  = L"fmPlayPause2RecPause";
WCHAR wszStop2RecPs[]    = L"fmStop2RecPause";
WCHAR wszRecPs2Rec[]     = L"tmRecPause2Rec";

BOOL
DVGetPropertyValuesFromRegistry(
    IN PDVCR_EXTENSION  pDevExt
    )
{
    NTSTATUS Status;
    HANDLE hPDOKey, hKeySettings;
    ULONG ulLength; 


    //
    // Registry key: 
    //   Windows 2000:
    //   HKEY_LOCAL_MACHINE\SYSTEM\CurrentControlSet\Control\Class\
    //   {6BDD1FC6-810F-11D0-BEC7-08002BE2092F\000x
    //
    // Win98:
    //    HKEY_LOCAL_MACHINE\SYSTEM\CurrentControlSet\Services\Class\Image\000x
    // 
    Status = 
        IoOpenDeviceRegistryKey(
            pDevExt->pPhysicalDeviceObject, 
            PLUGPLAY_REGKEY_DRIVER,
            STANDARD_RIGHTS_READ, 
            &hPDOKey
            );

    // PDO might be deleted when it was removed.    
    if(! pDevExt->bDevRemoved) {
        ASSERT(Status == STATUS_SUCCESS);
    }

    //
    // loop through our table of strings,
    // reading the registry for each.
    //
    if(NT_SUCCESS(Status)) {

        // Create or open the settings key
        Status =         
            CreateRegistrySubKey(
                hPDOKey,
                KEY_ALL_ACCESS,
                wszSettings,
                &hKeySettings
                );

        if(NT_SUCCESS(Status)) {

            // Note: we can be more selective by checking
            //   pDevExt->ulDevType

            // ATNSearch
            ulLength = sizeof(LONG);
            Status = GetRegistryKeyValue(
                hKeySettings, 
                wszATNSearch, 
                sizeof(wszATNSearch), 
                (PVOID) &pDevExt->bATNSearch, 
                &ulLength);
            TRACE(TL_PNP_TRACE,("GetRegVal: St:%x, Len:%d, bATNSearch:%d (1:Yes)\n", Status, ulLength, pDevExt->bATNSearch));
            if(!NT_SUCCESS(Status)) pDevExt->bATNSearch = FALSE;

            // bSyncRecording
            ulLength = sizeof(LONG);
            Status = GetRegistryKeyValue(
                hKeySettings, 
                wszSyncRecording, 
                sizeof(wszSyncRecording), 
                (PVOID) &pDevExt->bSyncRecording, 
                &ulLength);
            TRACE(TL_PNP_TRACE,("GetRegVal: St:%x, Len:%d, bSyncRecording:%d (1:Yes)\n", Status, ulLength, pDevExt->bSyncRecording));
            if(!NT_SUCCESS(Status)) pDevExt->bSyncRecording = FALSE;

            // tmMaxDataSync
            ulLength = sizeof(LONG);
            Status = GetRegistryKeyValue(
                hKeySettings, 
                wszMaxDataSync, 
                sizeof(wszMaxDataSync), 
                (PVOID) &pDevExt->tmMaxDataSync, 
                &ulLength);
            TRACE(TL_PNP_TRACE,("GetRegVal: St:%x, Len:%d, tmMaxDataSync:%d (msec)\n", Status, ulLength, pDevExt->tmMaxDataSync));

            // fmPlayPs2RecPs
            ulLength = sizeof(LONG);
            Status = GetRegistryKeyValue(
                hKeySettings, 
                wszPlayPs2RecPs, 
                sizeof(wszPlayPs2RecPs), 
                (PVOID) &pDevExt->fmPlayPs2RecPs, 
                &ulLength);
            TRACE(TL_PNP_TRACE,("GetRegVal: St:%x, Len:%d, fmPlayPs2RecPs:%d (frames)\n", Status, ulLength, pDevExt->fmPlayPs2RecPs));

            // fmStop2RecPs
            ulLength = sizeof(LONG);
            Status = GetRegistryKeyValue(
                hKeySettings, 
                wszStop2RecPs, 
                sizeof(wszStop2RecPs), 
                (PVOID) &pDevExt->fmStop2RecPs, 
                &ulLength);
            TRACE(TL_PNP_TRACE,("GetRegVal: St:%x, Len:%d, fmStop2RecPs:%d (frames)\n", Status, ulLength, pDevExt->fmStop2RecPs));

            // tmRecPs2Rec
            ulLength = sizeof(LONG);
            Status = GetRegistryKeyValue(
                hKeySettings, 
                wszRecPs2Rec, 
                sizeof(wszRecPs2Rec), 
                (PVOID) &pDevExt->tmRecPs2Rec, 
                &ulLength);
            TRACE(TL_PNP_TRACE,("GetRegVal: St:%x, Len:%d, tmRecPs2Rec:%d (msec)\n", Status, ulLength, pDevExt->tmRecPs2Rec));


            ZwClose(hKeySettings);
            ZwClose(hPDOKey);

            return TRUE;

        } else {

            TRACE(TL_PNP_ERROR,("GetPropertyValuesFromRegistry: CreateRegistrySubKey failed with Status=%x\n", Status));

        }

        ZwClose(hPDOKey);

    } else {

        TRACE(TL_PNP_ERROR,("GetPropertyValuesFromRegistry: IoOpenDeviceRegistryKey failed with Status=%x\n", Status));

    }

    // Not implemented so always return FALSE to use the defaults.
    return FALSE;
}


BOOL
DVSetPropertyValuesToRegistry(    
    PDVCR_EXTENSION  pDevExt
    )
{
    // Set the default to :
    //        HLM\Software\DeviceExtension->pchVendorName\1394DCam

    NTSTATUS Status;
    HANDLE hPDOKey, hKeySettings;

    TRACE(TL_PNP_TRACE,("SetPropertyValuesToRegistry: pDevExt=%x; pDevExt->pBusDeviceObject=%x\n", pDevExt, pDevExt->pBusDeviceObject));


    //
    // Registry key: 
    //   HKEY_LOCAL_MACHINE\SYSTEM\CurrentControlSet\Control\Class\
    //   {6BDD1FC6-810F-11D0-BEC7-08002BE2092F\000x
    //
    Status = 
        IoOpenDeviceRegistryKey(
            pDevExt->pPhysicalDeviceObject, 
            PLUGPLAY_REGKEY_DRIVER,
            STANDARD_RIGHTS_WRITE, 
            &hPDOKey);

    // PDO might be deleted when it was removed.    
    if(! pDevExt->bDevRemoved) {
        ASSERT(Status == STATUS_SUCCESS);
    }

    //
    // loop through our table of strings,
    // reading the registry for each.
    //
    if(NT_SUCCESS(Status)) {

        // Create or open the settings key
        Status =         
            CreateRegistrySubKey(
                hPDOKey,
                KEY_ALL_ACCESS,
                wszSettings,
                &hKeySettings
                );

        if(NT_SUCCESS(Status)) {

#if 0       // Note used, just an example:
            // Brightness
            Status = SetRegistryKeyValue(
                hKeySettings,
                wszBrightness,
                pDevExt->XXXX);
            TRACE(TL_PNP_TRACE,("SetPropertyValuesToRegistry: Status %x, Brightness %d\n", Status, pDevExt->Brightness));

#endif
            ZwClose(hKeySettings);
            ZwClose(hPDOKey);

            return TRUE;

        } else {

            TRACE(TL_PNP_ERROR,("GetPropertyValuesToRegistry: CreateRegistrySubKey failed with Status=%x\n", Status));

        }

        ZwClose(hPDOKey);

    } else {

        TRACE(TL_PNP_TRACE,("GetPropertyValuesToRegistry: IoOpenDeviceRegistryKey failed with Status=%x\n", Status));

    }

    return FALSE;
}

#endif  // READ_CUTOMIZE_REG_VALUES


#ifdef SUPPORT_ACCESS_DEVICE_INTERFACE

#if DBG

NTSTATUS
DVGetRegistryValue(
                   IN HANDLE Handle,
                   IN PWCHAR KeyNameString,
                   IN ULONG KeyNameStringLength,
                   IN PVOID Data,
                   IN ULONG DataLength
)
/*++

Routine Description:

    Reads the specified registry value

Arguments:

    Handle - handle to the registry key
    KeyNameString - value to read
    KeyNameStringLength - length of string
    Data - buffer to read data into
    DataLength - length of data buffer

Return Value:

    NTSTATUS returned as appropriate

--*/
{
    NTSTATUS        Status = STATUS_INSUFFICIENT_RESOURCES;
    UNICODE_STRING  KeyName;
    ULONG           Length;
    PKEY_VALUE_FULL_INFORMATION FullInfo;

    PAGED_CODE();

    RtlInitUnicodeString(&KeyName, KeyNameString);

    Length = sizeof(KEY_VALUE_FULL_INFORMATION) +
        KeyNameStringLength + DataLength;

    FullInfo = ExAllocatePool(PagedPool, Length);

    if (FullInfo) {
        Status = ZwQueryValueKey(Handle,
                                 &KeyName,
                                 KeyValueFullInformation,
                                 FullInfo,
                                 Length,
                                 &Length);

        if (NT_SUCCESS(Status)) {

            if (DataLength >= FullInfo->DataLength) {
                RtlCopyMemory(Data, ((PUCHAR) FullInfo) + FullInfo->DataOffset, FullInfo->DataLength);

            } else {

                Status = STATUS_BUFFER_TOO_SMALL;
            }                   // buffer right length

        }                      // if success
        else {
            TRACE(TL_PNP_ERROR,("ReadRegValue failed; ST:%x\n", Status));
        }
        ExFreePool(FullInfo);

    }                           // if fullinfo
    return Status;

}

#endif


#ifdef NT51_61883 
static const WCHAR DeviceTypeName[] = L"GLOBAL";
#endif

static const WCHAR UniqueID_Low[]   = L"UniqueID_Low";
static const WCHAR UniqueID_High[]  = L"UniqueID_High";

static const WCHAR VendorID[]       = L"VendorID";
static const WCHAR ModelID[]        = L"ModelID";

static const WCHAR VendorText[]     = L"VendorText";
static const WCHAR ModelText[]      = L"ModelText";
static const WCHAR UnitModelText[]  = L"UnitModelText";

static const WCHAR DeviceOPcr0Payload[]     = L"DeviceOPcr0Payload";
static const WCHAR DeviceOPcr0DataRate[]    = L"DeviceOPcr0DataRate";


#if DBG
static const WCHAR FriendlyName[]   = L"FriendlyName";
#endif

BOOL
DVAccessDeviceInterface(
    IN PDVCR_EXTENSION  pDevExt,
    IN const ULONG ulNumCategories,
    IN GUID DVCategories[]
    )
/*++

Routine Description:

    Access to the device's interface section and update the VendorText, 
    ModelText and UnitModelText.

--*/
{
    NTSTATUS ntStatus = STATUS_SUCCESS;
    HANDLE hDevIntfKey;
    UNICODE_STRING *aSymbolicLinkNames, 
#ifdef NT51_61883 
                   RefString,
#endif
                   TempUnicodeString;
    ULONG i;
#ifdef NT51_61883 
#if DBG
    WCHAR DataBuffer[MAX_PATH];
#endif
#endif


    //
    // allocate space for the array of catagory names
    //

    if (!(aSymbolicLinkNames = ExAllocatePool(PagedPool,
                                              sizeof(UNICODE_STRING) * ulNumCategories))) {
        return FALSE;
    }
    //
    // zero the array in case we're unable to fill it in below.  the Destroy
    // routine below will then correctly handle this case.
    //

    RtlZeroMemory(aSymbolicLinkNames, sizeof(UNICODE_STRING) * ulNumCategories);

#ifdef NT51_61883 
    //
    // loop through each of the catagory GUID's for each of the pins,
    // creating a symbolic link for each one.
    //

    RtlInitUnicodeString(&RefString, DeviceTypeName);
#endif

    for (i = 0; i < ulNumCategories; i++) {

        // Register our Device Interface
        ntStatus = IoRegisterDeviceInterface(
            pDevExt->pPhysicalDeviceObject,
            &DVCategories[i],  
#ifdef NT51_61883 
            &RefString, 
#else
            NULL,
#endif
            &aSymbolicLinkNames[i]
            );

        if(!NT_SUCCESS(ntStatus)) {
            //
            //  Can't register device interface
            //
            TRACE(TL_PNP_WARNING,("Cannot register device interface! ST:%x\n", ntStatus));          
            goto Exit;
        }

        TRACE(TL_PNP_TRACE,("AccessDeviceInterface:%d) Cateogory (Len:%d; MaxLen:%d); Name:\n%S\n", i, 
            aSymbolicLinkNames[i].Length, aSymbolicLinkNames[i].MaximumLength, aSymbolicLinkNames[i].Buffer));

        //
        // Get deice interface 
        //
        hDevIntfKey = 0;            
        ntStatus = IoOpenDeviceInterfaceRegistryKey(&aSymbolicLinkNames[i],
                                                     STANDARD_RIGHTS_ALL, 
                                                     &hDevIntfKey);
        if (NT_SUCCESS(ntStatus)) {

#ifdef NT51_61883 
#if DBG
            // Get DeviceInstance
            ntStatus = DVGetRegistryValue(hDevIntfKey, 
                                          (PWCHAR) FriendlyName, 
                                          sizeof(FriendlyName), 
                                          &DataBuffer, 
                                          MAX_PATH);
            if(NT_SUCCESS(ntStatus)) {
               TRACE(TL_PNP_TRACE,("AccessDeviceInterface:%S:%S\n", FriendlyName, DataBuffer));
            } else {
                TRACE(TL_PNP_WARNING,("Get %S failed; ST:%x\n", FriendlyName, ntStatus));
            }
#endif
#endif

            //
            // Update ConfigROM info read from an AV/C device: 
            // UniqueID, VendorID, ModelID,
            // VendorText, ModelText and UnitModelText             
            //

            if(pDevExt->UniqueID.LowPart || pDevExt->UniqueID.HighPart) {

                RtlInitUnicodeString(&TempUnicodeString, UniqueID_High);
                ZwSetValueKey(hDevIntfKey,
                              &TempUnicodeString,
                              0,
                              REG_DWORD,
                              &pDevExt->UniqueID.HighPart,  
                              sizeof(pDevExt->UniqueID.HighPart));

                RtlInitUnicodeString(&TempUnicodeString, UniqueID_Low);
                ZwSetValueKey(hDevIntfKey,
                              &TempUnicodeString,
                              0,
                              REG_DWORD,
                              &pDevExt->UniqueID.LowPart,  
                              sizeof(pDevExt->UniqueID.LowPart));

               TRACE(TL_PNP_TRACE,("Reg: %S = (Low)%x:(High)%x\n", TempUnicodeString.Buffer, pDevExt->UniqueID.LowPart, pDevExt->UniqueID.HighPart));
            }

            if(pDevExt->ulVendorID) {
                RtlInitUnicodeString(&TempUnicodeString, VendorID);
                ZwSetValueKey(hDevIntfKey,
                              &TempUnicodeString,
                              0,
                              REG_DWORD,
                              &pDevExt->ulVendorID,
                              sizeof(pDevExt->ulVendorID));
               TRACE(TL_PNP_TRACE,("Reg: %S = %x\n", TempUnicodeString.Buffer, pDevExt->ulVendorID));
            }

            if(pDevExt->ulModelID) {
                RtlInitUnicodeString(&TempUnicodeString, ModelID);
                ZwSetValueKey(hDevIntfKey,
                              &TempUnicodeString,
                              0,
                              REG_DWORD,
                              &pDevExt->ulModelID,
                              sizeof(pDevExt->ulModelID));
               TRACE(TL_PNP_TRACE,("Reg: %S = %x\n", TempUnicodeString.Buffer, pDevExt->ulModelID));
            }

            if(pDevExt->UnitIDs.ulVendorLength && pDevExt->UnitIDs.VendorText) {
                RtlInitUnicodeString(&TempUnicodeString, VendorText);
                ZwSetValueKey(hDevIntfKey,
                              &TempUnicodeString,
                              0,
                              REG_SZ,
                              pDevExt->UnitIDs.VendorText,
                              pDevExt->UnitIDs.ulVendorLength);
               TRACE(TL_PNP_TRACE,("Reg: %S = %S\n", TempUnicodeString.Buffer, pDevExt->UnitIDs.VendorText));
            }

#ifdef NT51_61883
            if(pDevExt->UnitIDs.ulModelLength && pDevExt->UnitIDs.ModelText) {
                RtlInitUnicodeString(&TempUnicodeString, ModelText);
                ZwSetValueKey(hDevIntfKey,
                              &TempUnicodeString,
                              0,
                              REG_SZ,
                              pDevExt->UnitIDs.ModelText,
                              pDevExt->UnitIDs.ulModelLength);
               TRACE(TL_PNP_WARNING,("Reg: %S = %S\n", TempUnicodeString.Buffer, pDevExt->UnitIDs.ModelText));
            }
#else
            if(pDevExt->UniRootModelString.Length && pDevExt->UniRootModelString.Buffer) {
                RtlInitUnicodeString(&TempUnicodeString, ModelText);
                ZwSetValueKey(hDevIntfKey,
                              &TempUnicodeString,
                              0,
                              REG_SZ,
                              pDevExt->UniRootModelString.Buffer,
                              pDevExt->UniRootModelString.Length);
               TRACE(TL_PNP_WARNING,("Reg: %S = %S\n", TempUnicodeString.Buffer, pDevExt->UniRootModelString.Buffer));
            }
#endif

#ifdef NT51_61883
            if(pDevExt->UnitIDs.ulUnitModelLength && pDevExt->UnitIDs.UnitModelText) {
                RtlInitUnicodeString(&TempUnicodeString, UnitModelText);
                ZwSetValueKey(hDevIntfKey,
                              &TempUnicodeString,
                              0,
                              REG_SZ,
                              pDevExt->UnitIDs.UnitModelText,
                              pDevExt->UnitIDs.ulUnitModelLength);
               TRACE(TL_PNP_WARNING,("Reg: %S = %S\n", TempUnicodeString.Buffer, pDevExt->UnitIDs.UnitModelText));
            }
#else
            if(pDevExt->UniUnitModelString.Length && pDevExt->UniUnitModelString.Buffer) {
                RtlInitUnicodeString(&TempUnicodeString, UnitModelText);
                ZwSetValueKey(hDevIntfKey,
                              &TempUnicodeString,
                              0,
                              REG_SZ,
                              pDevExt->UniUnitModelString.Buffer,
                              pDevExt->UniUnitModelString.Length);
               TRACE(TL_PNP_WARNING,("Reg: %S = %S\n", TempUnicodeString.Buffer, pDevExt->UniUnitModelString.Buffer));
            }
#endif

            //
            // Cache cache device's payload field of the oPCR[0]; 
            // The valid range is 0 to 1023 where 0 is 1024.
            // This value is needed for an application figure out 
            // max data rate.  However, if this payload is 
            // dynamically changing, it will not be accurate.
            //

            if(pDevExt->pDevOutPlugs->NumPlugs) {
                //
                // 98 and 146 are two known valid payloads
                //
                ASSERT(pDevExt->pDevOutPlugs->DevPlug[0].PlugState.Payload <= MAX_PAYLOAD-1);  // 0..MAX_PAYLOAD-1 is the valid range; "0" is MAX_PAYLOAD (1024) quadlets.
                RtlInitUnicodeString(&TempUnicodeString, DeviceOPcr0Payload);
                ZwSetValueKey(hDevIntfKey,
                              &TempUnicodeString,
                              0,
                              REG_DWORD,
                              &pDevExt->pDevOutPlugs->DevPlug[0].PlugState.Payload, 
                              sizeof(pDevExt->pDevOutPlugs->DevPlug[0].PlugState.Payload));
                TRACE(TL_PNP_TRACE,("Reg: %S = %d quadlets\n", TempUnicodeString.Buffer, pDevExt->pDevOutPlugs->DevPlug[0].PlugState.Payload));

                //
                // 0 (S100), 1(S200) and 2(S400) are the only three valid data rates.
                //
                ASSERT(pDevExt->pDevOutPlugs->DevPlug[0].PlugState.DataRate <= CMP_SPEED_S400);
                RtlInitUnicodeString(&TempUnicodeString, DeviceOPcr0DataRate);
                ZwSetValueKey(hDevIntfKey,
                              &TempUnicodeString,
                              0,
                              REG_DWORD,
                              &pDevExt->pDevOutPlugs->DevPlug[0].PlugState.DataRate,  
                              sizeof(pDevExt->pDevOutPlugs->DevPlug[0].PlugState.DataRate));
                TRACE(TL_PNP_TRACE,("Reg: %S = %d (0:S100,1:S200,2:S400)\n", TempUnicodeString.Buffer, 
                    pDevExt->pDevOutPlugs->DevPlug[0].PlugState.DataRate));
            }

            ZwClose(hDevIntfKey);

        } else {
            TRACE(TL_PNP_ERROR,("IoOpenDeviceInterfaceRegistryKey failed; ST:%x\n", ntStatus));
        }


        RtlFreeUnicodeString(&aSymbolicLinkNames[i]);    
    }

Exit:

    ExFreePool(aSymbolicLinkNames);  aSymbolicLinkNames = NULL;

    return ntStatus == STATUS_SUCCESS;
}
#endif
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\drivers\wdm\capture\mini\tecra750\bert.h ===
//
//              INTEL CORPORATION PROPRIETARY INFORMATION
//     This software is supplied under the terms of a license agreement or
//     nondisclosure agreement with Intel Corporation and may not be copied
//     or disclosed except in accordance with the terms of that agreement.
//           Copyright (c) 1996 Intel Corporation. All Rights Reserved.
//
//  Workfile: BERT.H
//
//  Purpose:
//     This header contains the defines for the Bert Gate Array Asic
//     registers and functions
//
//  Contents:
//

#ifndef  _BERT_H_
#define _BERT_H_

// Bert register offsets

#define BERT_CAPSTAT_REG        0x00
#define BERT_VINSTAT_REG        0x04
#define BERT_INTSTAT_REG        0x08
#define BERT_INTRST_REG         0x0c
#define BERT_IIC_REG            0x10
#define BERT_FIFOCFG_REG        0x14
#define BERT_RPSADR_REG         0x18

#define BERT_UALIMIT_REG        0x20
#define BERT_LALIMIT_REG        0x24
#define BERT_RPSPAGE_REG        0x28

#define BERT_YPTR_REG           0x30
#define BERT_UPTR_REG           0x34
#define BERT_VPTR_REG           0x38

#define BERT_YSTRIDE_REG        0x40
#define BERT_USTRIDE_REG        0x44
#define BERT_VSTRIDE_REG        0x48

#define BERT_DALI_REG           0x50
#define BERT_EEPROM_REG         0x60

#define BERT_DMASTAT_REG        0x70
#define BERT_TEST_REG           0x74

// for Pistachio's Register 97-03-21(Fri)
#define BERT_P_SKIP_REG                 0x80
#define BERT_P_ISIZ_REG                 0x84
#define BERT_P_OSIZ_REG                 0x88
#define BERT_P_LUMI_REG                 0x8c
#define BERT_P_COL_REG                  0x90
#define BERT_P_FILT_REG                 0x94
#define BERT_P_SUP1_REG                 0x98
#define BERT_P_SUP2_REG                 0x9c
#define BERT_P_SUP3_REG                 0xa0

#define BERT_BURST_LEN                  0x9c    // Insert 97-03-17(Mon)

#define BERT_FER_REG                    0xf0
#define BERT_FEMR_REG                   0xf4
#define BERT_FPSR_REG                   0xf8
#define BERT_FECREG                     0xfc

// I2C status byte bits
#define I2C_OFFSET                      0x40

#define I2CSTATUS_ALTD          0x02
#define I2CSTATUS_FIDT          0x20
#define I2CSTATUS_HLCK          0x40

// INTSTAT Interrupt status register bit defines

#define FIELD_INT             0x00000001
#define RPS_INT               0x00000002
#define SYNC_LOCK_INT         0x00000004
#define SPARE_INT             0x00000008
#define FIFO_OVERFLOW_INT     0x00000010
#define LINE_TIMEOUT_INT      0x00000020
#define RPS_OOB_INT           0x00000040
#define REG_UNDEF_INT         0x00000080

#define CODEC_INT             0x00000100
#define SLOW_CLOCK_INT        0x00000200
#define OVER_RUN_INT          0x00000400
#define REG_LOAD_INT          0x00000800
#define LINE_SYNC_INT         0x00001000
#define IIC_ERROR_INT         0x00002000
#define PCI_PARITY_ERROR_INT  0x00004000
#define PCI_ACCESS_ERROR_INT  0x00008000

// INSTAT Interrupt enable OR mask bits

#define FIELD_INT_MASK            0x00010000
#define RPS_INT_MASK              0x00020000
#define SYNC_LOCK_INT_MASK        0x00040000
#define SPARE_INT_MASK            0x00080000
#define FIFO_OVERFLOW_INT_MASK    0x00100000
#define LINE_TIMEOUT_INT_MASK     0x00200000
#define RPS_OOB_INT_MASK          0x00400000
#define REG_UNDEF_INT_MASK        0x00800000

#define CODEC_INT_MASK            0x01000000
#define SLOW_CLOCK_INT_MASK       0x02000000
#define OVER_RUN_INT_MASK         0x04000000
#define REG_LOAD_INT_MASK         0x08000000
#define LINE_SYNC_INT_MASK        0x10000000
#define IIC_ERROR_INT_MASK        0x20000000
#define PCI_PARITY_ERROR_INT_MASK 0x40000000
#define PCI_ACCESS_ERROR_INT_MASK 0x80000000


// INTRST Interrupt ReSeT Register bits
// reset bits
#define FIELD_INT_RESET             0x00000001
#define RPS_INT_RESET               0x00000002
#define SYNC_LOCK_INT_RESET         0x00000004
#define SPARE_INT_RESET             0x00000008
#define FIFO_OVERFLOW_INT_RESET     0x00000010
#define LINE_TIMEOUT_INT_RESET      0x00000020
#define RPS_OOB_INT_RESET           0x00000040
#define REG_UNDEF_INT_RESET         0x00000080

#define SLOW_CLOCK_INT_RESET        0x00000200
#define OVER_RUN_INT_RESET          0x00000400
#define REG_LOAD_INT_RESET          0x00000800
#define LINE_SYNC_INT_RESET         0x00001000
#define IIC_ERROR_INT_RESET         0x00002000
#define PCI_PARITY_ERROR_INT_RESET  0x00004000
#define PCI_ACCESS_ERROR_INT_RESET  0x00008000

// set bits
#define FIELD_INT_SET               0x00010000
#define RPS_INT_SET                 0x00020000
#define SYNC_LOCK_INT_SET           0x00040000
#define SPARE_INT_SET               0x00080000
#define FIFO_OVERFLOW_INT_SET       0x00100000
#define LINE_TIMEOUT_INT_SET        0x00200000
#define RPS_OOB_INT_SET             0x00400000
#define REG_UNDEF_INT_SET           0x00800000

#define SLOW_CLOCK_INT_SET          0x02000000
#define OVER_RUN_INT_SET            0x04000000
#define REG_LOAD_INT_SET            0x08000000
#define LINE_SYNC_INT_SET           0x10000000
#define IIC_ERROR_INT_SET           0x20000000
#define PCI_PARITY_ERROR_INT_SET    0x40000000
#define PCI_ACCESS_ERROR_INT_SET    0x80000000

#define TEST_MAKE_VORLON1           0x10000000

//
// The following values for the FIFO trip points and giving unlimited
// PCI bus master access is reasonable for all platforms.
//

#define BERT_DEF_TRIP_POINTS    16
#define BERT_DEF_PCI_BURST_LEN  3


typedef struct _RPS_COMMAND
{
   union
   {
      struct
      {
         ULONG  RegisterOffset:8;
         ULONG  Reserved:19;
         ULONG  FWait:1;
         ULONG  Edge:1;
         ULONG  Int:1;
         ULONG  ReadWrite:1;
         ULONG  Continue:1;
      } bits;
      ULONG  AsULONG;
   } u;

   ULONG Argument;

} RPS_COMMAND, *PRPS_COMMAND;

#define RPS_COMMAND_CONT          0x80000000
#define RPS_COMMAND_STOP          0x00000000
#define RPS_COMMAND_READ          0x40000000
#define RPS_COMMAND_WRITE         0x00000000
#define RPS_COMMAND_INT           0x20000000
#define RPS_COMMAND_NOINT         0x00000000
#define RPS_COMMAND_RISE_EDGE     0x10000000
#define RPS_COMMAND_FALL_EDGE     0x00000000
#define RPS_COMMAND_FWAIT         0x00000000


#define RPS_COMMAND_DEFAULT   (RPS_COMMAND_STOP | RPS_COMMAND_WRITE |      \
                               RPS_COMMAND_RISE_EDGE | RPS_COMMAND_FWAIT | \
                               RPS_COMMAND_NOINT)

// RPS COMMAND
#define RPS_CONTINUE_CMD        0x80000000
#define RPS_READ_CMD            0x40000000
#define RPS_INT_CMD             0x20000000



// Enable bits for the CAPSTAT register
#define RST             0x80000000              // Reset front end.
#define EBMV            0x10000000              // Enable Bus Master Video (i.e. DMA)
#define EREO            0x04000000              // Enable RPS Even
#define EROO            0x02000000              // Enable RPS Odd
#define LOCK            0x00002000              // Sync Lock
#define RPSS            0x00001000              // RPS Status
#define GO0             0x00000010              // Power to camara
#define CKRE            0x00000008              // Clock Run Enable             // Add 97-05-08
#define CKMD            0x00000004              // Clock Request Mode   // Add 97-05-08
#define ERPS            0x08000000              // Enable RPS
#define FEMR_ENABLE     0x00008000
#define CAMARA_OFF      RST

//#define PASSIVE_ENABLE        (ERPS | GO0)
//#define CAPTURE_EVEN          (ERPS | EREO | GO0 | EBMV)
//#define CAPTURE_ODD           (ERPS | EROO | GO0 | EBMV)
//#define SKIP_EVEN             (ERPS | EREO | GO0)
//#define SKIP_ODD              (ERPS | EROO | GO0)

#define PASSIVE_ENABLE  ERPS            // DEL GO0 97-04-07(Mon) BUN
#define CAPTURE_EVEN    (ERPS | EBMV)   // DEL EREO ZGO0 97-04-07(Mon) BUN
#define CAPTURE_ODD     (ERPS | EBMV)   // mode 97-03-29(Sat) BUN
#define SKIP_EVEN       ERPS            // DEL EREO ZGO0 97-04-07(Mon) BUN
#define SKIP_ODD        ERPS            // DEL EROO ZGO0 97-04-07(Mon) BUN


// Bit positions for the INTSTAT register's ENABLE flags.
#define FIE     0x10000         // Field Interrupt Enable
#define RIE     0x20000         // RPS Interrupt Enable
#define SLIE    0x40000         // Sync Lock Interrupt Enable
#define EXIE    0x80000         // External interrupt Enable(Dilbert)
#define SPIE    0x80000         // Spare Interrupt Enable(Bert).
#define FOIE    0x100000        // FIFO Overflow Interrupt Enable.
#define LTIE    0x200000        // LINE Timeout Interrupt Enable.
#define ROIE    0x400000        // RPS Out of Bounds Interrupt Enable.
#define RUIE    0x800000        // Register Undefined Interrupt Enable.
#define SCIE    0x2000000       // Slock Clock Interrupt Enable.
#define ORIE    0x4000000       // Over Run Interrupt Enable.
#define RLIE    0x8000000       // Register Load Interrupt Enable.
#define DEIE    0x10000000      // DCI Error Interrupt Enable(Dilbert).
#define LSIE    0x10000000      // Line Sync Interrupt Enable(Bert).
#define IEIE    0x20000000      // IIC Error Interrupt Enable.
#define PPIE    0x40000000      // PCI Parity Error Interrupt Enable.
#define PEIE    0x80000000      // PCI Access Error Interrupt Enable.

// The active video capture interrupts mask
//#define ACTIVE_CAPTURE_IRQS (RIE | SLIE | FOIE | ROIE | RUIE |\
//                             ORIE | RLIE | IEIE | PPIE | PEIE)

// delete PPIE & IEIE & ORIE 97-03-15(Sat)
// Pistachi not support to PPIE and ORIE. Santaclara does not use I2c bus.
#define ACTIVE_CAPTURE_IRQS (RIE | SLIE | FOIE | LTIE | ROIE | RUIE | RLIE | PEIE)

// for Pistachio's flags 97-03-21(Fri)
#define CHGCOL          0x00010000      // P_LUMI Change Color
#define VFL             0x00010000      // P_FIL Vertical Filter
#define EI_H            0x00000001      // P_SUP1 EI Level H
#define EI_L            0x00000000      // P_SUP1 EI Level L
#define EICH_2          0x00000000      // P_SUP1 EICH 2ms
#define EICH_10         0x00000010      // P_SUP1 EICH 10ms
#define EICH_50         0x00000020      // P_SUP1 EICH 50ms
#define EICH_NONE       0x00000030      // P_SUP1 EICH None
#define MSTOPI          0x00000002      // P_SUP3 IIC Stop Not Auto
#define HSIIC           0x00000001      // P_SUP3 IIC HighSpeed Mode
#define VSNC            0x00000008      // VINSTAT VSNC




//
// define the video standard constants
//
#define NTSC_MAX_PIXELS_PER_LINE        640
#define NTSC_MAX_LINES_PER_FIELD        240

#define PAL_MAX_PIXELS_PER_LINE         768
#define PAL_MAX_LINES_PER_FIELD         288

#define NTSC_HORIZONTAL_START           3
#define NTSC_VERTICAL_START             14
#define PAL_HORIZONTAL_START            NTSC_HORIZONTAL_START   // Same as NTSC
#define PAL_VERTICAL_START              19

#define MAX_CAPTURE_BUFFER_SIZE         ((640*480*12)/8)
#define DEFAULT_CAPTURE_BUFFER_SIZE     ((320*240*12)/8)

//
// frame timing, time between vsync interrupts
//
#define PAL_MICROSPERFRAME      (1000L/25)
#define NTSC_MICROSPERFRAME     (1000L/30)

//#define EBMV_TIMEOUT        200000      // 20 millisec
#define EBMV_TIMEOUT        500000      // 20 millisec

#define DEF_RPS_FRAMES      30          // 30 default fps

#define CAMERA_OFF_TIME         5000    // StreamFini -> CameraOFF      Add 97-05-03(Sat)
#define CAMERA_FLAG_ON          0x01    // Add 97-05-10(Sat)
#define CAMERA_FLAG_OFF         0x00    // Add 97-05-10(Sat)
#define CAVCE_ON                        0x01    // Add 97-05-10(Sat)
#define CAVCE_OFF                       0x00    // Add 97-05-10(Sat)

#define ZV_ENABLE                       0x01l   // Add 97-05-10(Sat)
#define ZV_DISABLE                      0x00l   // Add 97-05-10(Sat)
#define ZV_GETSTATUS            0xffl   // Add 97-05-10(Sat)
#define ZV_ERROR                        0xffl   // Add 97-05-10(Sat)

#define MODE_VFW                        0x01    // Add 97-05-10(Sat)
#define MODE_ZV                         0x02    // Add 97-05-10(Sat)


#define MAX_HUE         0xff
#define DEFAULT_HUE     0x80
#define MAX_HUE          0xff
#define MAX_BRIGHTNESS   0xff
#define MAX_CONTRAST     0xff
#define MAX_SATURATION   0xff


#define IGNORE100msec   0x200000l
#define PCI_CFGCCR              0x08    /* offset of Pistachio Configration/Revision */
#define PCI_Wake_Up             0x40    /* offset of Pistachio Wake up  */
#define PCI_CFGWAK              0x40    /* offset of Pistachio Wake up  */
#define PCI_DATA_PATH   0x44    /* offset of Pistachio Data path */
#define PCI_CFGPAT              0x44    /* offset of Pistachio Data path */

#define SELIZV_CFGPAT   0x2l
#define ZVEN_CFGPAT             0x1l
#define CAVCE_CFGPAT    0x10l
#define CADTE_CFGPAT    0x20l
#define PXCCE_CFGPAT    0x100l
#define PXCSE_CFGPAT    0x200l
#define PCIFE_CFGPAT    0x400l
#define PCIME_CFGPAT    0x800l
#define PCIDS_CFGPAT    0x1000l
#define GPB_CFGPAT      0x30000l

#define CASL_CFGWAK             0x00010000l





VOID    HW_ApmResume(PHW_DEVICE_EXTENSION);
VOID    HW_ApmSuspend(PHW_DEVICE_EXTENSION);
VOID    HW_SetFilter(PHW_DEVICE_EXTENSION, BOOL);
ULONG   HW_ReadFilter(PHW_DEVICE_EXTENSION, BOOL);
BOOL
SetupPCILT(PHW_DEVICE_EXTENSION pHwDevExt);

VOID
InitializeConfigDefaults(PHW_DEVICE_EXTENSION pHwDevExt);

BOOL
CameraChkandON(PHW_DEVICE_EXTENSION pHwDevExt, ULONG ulMode);

BOOL
CameraChkandOFF(PHW_DEVICE_EXTENSION pHwDevExt, ULONG ulMode);

BOOL
CheckCameraStatus(PHW_DEVICE_EXTENSION pHwDevExt);     // Add 97-05-05(Mon)

BOOL
SetZVControl(PHW_DEVICE_EXTENSION pHwDevExt, ULONG ulZVStatus);     // Add 97-05-02(Fri)

VOID
WriteRegUlong(PHW_DEVICE_EXTENSION pHwDevExt,
                          ULONG,
                          ULONG);

VOID
ReadModifyWriteRegUlong(PHW_DEVICE_EXTENSION pHwDevExt,
                                                ULONG,
                                                ULONG,
                                                ULONG);

ULONG
ReadRegUlong(PHW_DEVICE_EXTENSION pHwDevExt, ULONG);

BOOL
HWInit(
  IN PHW_DEVICE_EXTENSION pHwDevExt
);

VOID
BertInterruptEnable(
  IN PHW_DEVICE_EXTENSION pHwDevExt,
  IN BOOL bStatus
);

VOID
BertDMAEnable(
  IN PHW_DEVICE_EXTENSION pHwDevExt,
  IN BOOL bStatus
);

BOOL
BertIsLocked(
  IN PHW_DEVICE_EXTENSION pHwDevExt
);

BOOL
BertFifoConfig(
  IN PHW_DEVICE_EXTENSION pHwDevExt,
  IN ULONG dwFormat
);

BOOL
BertInitializeHardware(
  IN PHW_DEVICE_EXTENSION pHwDevExt
);

VOID
BertEnableRps(
  IN PHW_DEVICE_EXTENSION pHwDevExt
);

VOID
BertDisableRps(
  IN PHW_DEVICE_EXTENSION pHwDevExt
);

BOOL
BertIsCAPSTATReady(
  IN PHW_DEVICE_EXTENSION pHwDevExt
);

VOID
BertVsncSignalWait(
  IN PHW_DEVICE_EXTENSION pHwDevExt
);

VOID
BertDMARestart(
  IN PHW_DEVICE_EXTENSION pHwDevExt
);

BOOL
BertBuildNodes(
  IN PHW_DEVICE_EXTENSION pHwDevExt
);

BOOL
BertTriBuildNodes(
  IN PHW_DEVICE_EXTENSION pHwDevExt
);

BOOL
BertIsCardIn(
  IN PHW_DEVICE_EXTENSION pHwDevExt
);

VOID
BertSetDMCHE(
  IN PHW_DEVICE_EXTENSION pHwDevExt
);

BOOL
ImageSetInputImageSize(
  IN PHW_DEVICE_EXTENSION pHwDevExt,
  IN PRECT pRect
);

BOOL
ImageSetOutputImageSize(
  IN PHW_DEVICE_EXTENSION pHwDevExt,
  IN ULONG ulWidth,
  IN ULONG ulHeight
);

BOOL
ImageSetChangeColorAvail(
  IN PHW_DEVICE_EXTENSION pHwDevExt,
  IN ULONG ulChgCol
);

BOOL
ImageSetHueBrightnessContrastSat(
  IN PHW_DEVICE_EXTENSION pHwDevExt
);

BOOL
ImageSetFilterInfo(
  IN PHW_DEVICE_EXTENSION pHwDevExt,
  IN ULONG ulVFL,
  IN ULONG ulFL1,
  IN ULONG ulFL2,
  IN ULONG ulFL3,
  IN ULONG ulFL4
);

BOOL
ImageFilterON(
  IN PHW_DEVICE_EXTENSION pHwDevExt
);

BOOL
ImageFilterOFF(
  IN PHW_DEVICE_EXTENSION pHwDevExt
);

BOOL
ImageGetFilterInfo(
  IN PHW_DEVICE_EXTENSION pHwDevExt
);

BOOL
ImageGetFilteringAvailable(
  IN PHW_DEVICE_EXTENSION pHwDevExt
);

BOOL
Alloc_TriBuffer(
  IN PHW_DEVICE_EXTENSION pHwDevExt
);

BOOL
Free_TriBuffer(
  IN PHW_DEVICE_EXTENSION pHwDevExt
);

BOOL
SetASICRev(
  IN PHW_DEVICE_EXTENSION pHwDevExt
);

BOOL
VC_GetPCIRegister(
    PHW_DEVICE_EXTENSION pHwDevExt,
    ULONG ulOffset,
    PVOID pData,
    ULONG ulLength);

BOOL
VC_SetPCIRegister(
    PHW_DEVICE_EXTENSION pHwDevExt,
    ULONG ulOffset,
    PVOID pData,
    ULONG ulLength);

VOID VC_Delay(int nMillisecs);

#if DBG
void DbgDumpPciRegister( PHW_DEVICE_EXTENSION pHwDevExt );
void DbgDumpCaptureRegister( PHW_DEVICE_EXTENSION pHwDevExt );
#endif

#endif   // _BERT_H_


=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\drivers\wdm\capture\mini\tecra750\capirq.c ===
//==========================================================================;
//
//  THIS CODE AND INFORMATION IS PROVIDED "AS IS" WITHOUT WARRANTY OF ANY
//  KIND, EITHER EXPRESSED OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE
//  IMPLIED WARRANTIES OF MERCHANTABILITY AND/OR FITNESS FOR A PARTICULAR
//  PURPOSE.
//
//  Copyright (c) 1992 - 1997  Microsoft Corporation.  All Rights Reserved.
//
//==========================================================================;

#include "strmini.h"
#include "ksmedia.h"
#include "capmain.h"
#ifdef  TOSHIBA
#include "bert.h"

#ifdef  _FPS_COUNT_
extern  ULONG    FrameCounter;
extern  ULONG    InterruptCounter;
#endif//_FPS_COUNT_
#endif//TOSHIBA

#ifdef  TOSHIBA
BOOLEAN InterruptAcknowledge( PHW_DEVICE_EXTENSION );
#endif//TOSHIBA

#ifdef  TOSHIBA
void ImageSynthXXX (
    IN OUT PHW_STREAM_REQUEST_BLOCK pSrb
    )
{
    PSTREAMEX               pStrmEx = (PSTREAMEX)pSrb->StreamObject->HwStreamExtension;
    PHW_DEVICE_EXTENSION    pHwDevExt = ((PHW_DEVICE_EXTENSION)pSrb->HwDeviceExtension);
    int                     StreamNumber = pSrb->StreamObject->StreamNumber;
    KS_VIDEOINFOHEADER      *pVideoInfoHdr = pStrmEx->pVideoInfoHeader;

    UINT biWidth        =   pVideoInfoHdr->bmiHeader.biWidth;
    UINT biHeight       =   pVideoInfoHdr->bmiHeader.biHeight;
    UINT biSizeImage    =   pVideoInfoHdr->bmiHeader.biSizeImage;
    UINT biWidthBytes   =   KS_DIBWIDTHBYTES (pVideoInfoHdr->bmiHeader);
    UINT biBitCount     =   pVideoInfoHdr->bmiHeader.biBitCount;
    UINT LinesToCopy    =   abs (biHeight);
    DWORD biCompression =   pVideoInfoHdr->bmiHeader.biCompression;

    UINT                    Line;
    PUCHAR                  pLineBuffer;

    PKSSTREAM_HEADER        pDataPacket = pSrb->CommandData.DataBufferArray;
    PUCHAR                  pImage =  pDataPacket->Data;
    ULONG                   InRPSflag;
    ULONG                   ImageSizeY;
    ULONG                   ImageSizeU;
    ULONG                   ImageSizeV;


    DEBUG_ASSERT (pSrb->NumberOfBuffers == 1);

#if 0
    // Note:  set "ulInDebug = 1" in a debugger to view this output with .ntkern
    KdPrint(("\'TsbVcap: ImageSynthBegin\n"));
    KdPrint(("\'TsbVcap: biSizeImage=%d, DataPacketLength=%d\n",
            biSizeImage, pDataPacket->DataPacketLength));
    KdPrint(("\'TsbVcap: biWidth=%d biHeight=%d WidthBytes=%d bpp=%d\n",
            biWidth, biHeight, biWidthBytes, biBitCount));
    KdPrint(("\'TsbVcap: pImage=%x\n", pImage));
#endif

    if (pHwDevExt->Format == FmtYUV12) {
        ImageSizeY = biWidth * biHeight;
        ImageSizeU = ImageSizeY / 4;
        ImageSizeV = ImageSizeY / 4;
    } else if (pHwDevExt->Format == FmtYUV9) {
        ImageSizeY = biWidth * biHeight;
        ImageSizeU = ImageSizeY / 16;
        ImageSizeV = ImageSizeY / 16;
    } else {
        biSizeImage = 0;
        return;
    }

    if (pHwDevExt->dblBufflag) {
        InRPSflag = ReadRegUlong(pHwDevExt, BERT_YPTR_REG);
        if (InRPSflag == pHwDevExt->pPhysCaptureBufferY.LowPart) {
            if (pHwDevExt->Format == FmtYUV12) {
                RtlCopyMemory( pImage, pHwDevExt->pCaptureBufferY, ImageSizeY );
                pImage += ImageSizeY;
                RtlCopyMemory( pImage, pHwDevExt->pCaptureBufferU, ImageSizeU );
                pImage += ImageSizeU;
                RtlCopyMemory( pImage, pHwDevExt->pCaptureBufferV, ImageSizeV );
            } else {
                RtlCopyMemory( pImage, pHwDevExt->pCaptureBufferY, ImageSizeY );
                pImage += ImageSizeY;
                RtlCopyMemory( pImage, pHwDevExt->pCaptureBufferV, ImageSizeV );
                pImage += ImageSizeV;
                RtlCopyMemory( pImage, pHwDevExt->pCaptureBufferU, ImageSizeU );
            }
        } else if (InRPSflag == pHwDevExt->pPhysCapBuf2Y.LowPart) {
            if (pHwDevExt->Format == FmtYUV12) {
                RtlCopyMemory( pImage, pHwDevExt->pCapBuf2Y, ImageSizeY );
                pImage += ImageSizeY;
                RtlCopyMemory( pImage, pHwDevExt->pCapBuf2U, ImageSizeU );
                pImage += ImageSizeU;
                RtlCopyMemory( pImage, pHwDevExt->pCapBuf2V, ImageSizeV );
            } else {
                RtlCopyMemory( pImage, pHwDevExt->pCapBuf2Y, ImageSizeY );
                pImage += ImageSizeY;
                RtlCopyMemory( pImage, pHwDevExt->pCapBuf2V, ImageSizeV );
                pImage += ImageSizeV;
                RtlCopyMemory( pImage, pHwDevExt->pCapBuf2U, ImageSizeU );
            }
        } else {
            biSizeImage = 0;
        }
    } else {
        if (pHwDevExt->Format == FmtYUV12) {
            RtlCopyMemory( pImage, pHwDevExt->pCaptureBufferY, ImageSizeY );
            pImage += ImageSizeY;
            RtlCopyMemory( pImage, pHwDevExt->pCaptureBufferU, ImageSizeU );
            pImage += ImageSizeU;
            RtlCopyMemory( pImage, pHwDevExt->pCaptureBufferV, ImageSizeV );
        } else {
            RtlCopyMemory( pImage, pHwDevExt->pCaptureBufferY, ImageSizeY );
            pImage += ImageSizeY;
            RtlCopyMemory( pImage, pHwDevExt->pCaptureBufferV, ImageSizeV );
            pImage += ImageSizeV;
            RtlCopyMemory( pImage, pHwDevExt->pCaptureBufferU, ImageSizeU );
        }
    }
    pDataPacket->DataUsed = biSizeImage;
#ifdef  _FPS_COUNT_
    FrameCounter++;
#endif//_FPS_COUNT_
}

VOID
TransferRoutine(
    PHW_DEVICE_EXTENSION        pHwDevExt,
    int                         StreamNumber
    )
{
    PHW_STREAM_REQUEST_BLOCK    pSrb;
    PSTREAMEX                   pStrmEx;
    PKSSTREAM_HEADER            pDataPacket;
    PKS_FRAME_INFO              pFrameInfo;

    pStrmEx = (PSTREAMEX)pHwDevExt->pStrmEx[StreamNumber];

    // If we're stopped and the timer is still running, just return.
    // This will stop the timer.

    if (pStrmEx->KSState == KSSTATE_STOP) {
        return;
    }

    // Find out what time it is, if we're using a clock

    if (pStrmEx->hMasterClock ) {
        HW_TIME_CONTEXT TimeContext;

        TimeContext.HwDeviceExtension = pHwDevExt;
        TimeContext.HwStreamObject = pStrmEx->pStreamObject;
        TimeContext.Function = TIME_GET_STREAM_TIME;

        StreamClassQueryMasterClockSync (
                pStrmEx->hMasterClock,
                &TimeContext);

        pStrmEx->QST_StreamTime = TimeContext.Time;
        pStrmEx->QST_Now = TimeContext.SystemTime;

        if (pStrmEx->QST_NextFrame == 0) {
            pStrmEx->QST_NextFrame = pStrmEx->QST_StreamTime + pStrmEx->pVideoInfoHeader->AvgTimePerFrame;
        }

#ifdef CREATE_A_FLURRY_OF_TIMING_SPEW
        KdPrint(("TsbVcap:    Time=%16lx\n", TimeContext.Time));
        KdPrint(("TsbVcap: SysTime=%16lx\n", TimeContext.SystemTime));
#endif
    }

    // Only capture in the RUN state

    if (pStrmEx->KSState == KSSTATE_RUN) {

        //
        // Determine if it is time to capture a frame based on
        // how much time has elapsed since capture started.
        // If there isn't a clock available, then capture immediately.
        //

        if ((!pStrmEx->hMasterClock) ||
             (pStrmEx->QST_StreamTime >= pStrmEx->QST_NextFrame)) {
            // Increment the picture count (usually this is VSYNC count)

            pStrmEx->FrameInfo.PictureNumber++;

            //
            // Get the next queue SRB (if any)
            //

            pSrb = VideoQueueRemoveSRB (
                            pHwDevExt,
                            StreamNumber);

            if (pSrb) {

                pDataPacket = pSrb->CommandData.DataBufferArray;
                pFrameInfo = (PKS_FRAME_INFO) (pDataPacket + 1);

                //
                // Call the routine which synthesizes images
                //

                ImageSynthXXX (pSrb);

                // Set additional info fields about the data captured such as:
                //   Frames Captured
                //   Frames Dropped
                //   Field Polarity

                pStrmEx->FrameInfo.ExtendedHeaderSize = pFrameInfo->ExtendedHeaderSize;

                *pFrameInfo = pStrmEx->FrameInfo;

                // Init the flags to zero
                pDataPacket->OptionsFlags = 0;

                // Set the discontinuity flag if frames have been previously
                // dropped, and then reset our internal flag

                if (pStrmEx->fDiscontinuity) {
                    pDataPacket->OptionsFlags |= KSSTREAM_HEADER_OPTIONSF_DATADISCONTINUITY;
                    pStrmEx->fDiscontinuity = FALSE;
                }

                //
                // Return the timestamp for the frame
                //
                pDataPacket->PresentationTime.Numerator = 1;
                pDataPacket->PresentationTime.Denominator = 1;
                pDataPacket->Duration = pStrmEx->pVideoInfoHeader->AvgTimePerFrame;

                //
                // if we have a master clock AND this is the capture stream
                //
                if (pStrmEx->hMasterClock && (StreamNumber == 0)) {

                    pDataPacket->PresentationTime.Time = pStrmEx->QST_StreamTime;
                    pDataPacket->OptionsFlags |=
                        KSSTREAM_HEADER_OPTIONSF_TIMEVALID |
                        KSSTREAM_HEADER_OPTIONSF_DURATIONVALID;
                }
                else {
                    //
                    // no clock or the preview stream, so just mark the time as unknown
                    //
                    pDataPacket->PresentationTime.Time = 0;
                    // clear the timestamp valid flags
                    pDataPacket->OptionsFlags &=
                        ~(KSSTREAM_HEADER_OPTIONSF_TIMEVALID |
                          KSSTREAM_HEADER_OPTIONSF_DURATIONVALID);
                }

                // Every frame we generate is a key frame (aka SplicePoint)
                // Delta frames (B or P) should not set this flag

                pDataPacket->OptionsFlags |= KSSTREAM_HEADER_OPTIONSF_SPLICEPOINT;

                CompleteStreamSRB (pSrb);

            } // if we have an SRB

            else {

                //
                // No buffer was available when we should have captured one

                // Increment the counter which keeps track of
                // dropped frames

                pStrmEx->FrameInfo.DropCount++;

                // Set the (local) discontinuity flag
                // This will cause the next packet processed to have the
                //   KSSTREAM_HEADER_OPTIONSF_DATADISCONTINUITY flag set.

                pStrmEx->fDiscontinuity = TRUE;

            }

            // Figure out when to capture the next frame
            pStrmEx->QST_NextFrame += pStrmEx->pVideoInfoHeader->AvgTimePerFrame;

        } // endif time to capture a frame
    } // endif we're running

}

VOID
DeferredRoutine(
    PKDPC          pDpc,
    PDEVICE_OBJECT pDeviceObject,
    PIRP           pIrpNotUsed,
    PVOID          Context
    )
{
    PHW_DEVICE_EXTENSION        pHwDevExt = (PHW_DEVICE_EXTENSION)Context;
    PHW_STREAM_REQUEST_BLOCK    pSrb;
    PSTREAMEX                   pStrmEx;
    PKSSTREAM_HEADER            pDataPacket;
    PKS_FRAME_INFO              pFrameInfo;
    int                         StreamNumber;

    pHwDevExt->DpcRequested = FALSE;

    if (pHwDevExt->NeedCameraON == TRUE) {
        CameraChkandON(pHwDevExt, MODE_VFW);
        KeStallExecutionProcessor(100000);    // Wait 100 msec
        BertDMARestart(pHwDevExt);
        pHwDevExt->bVideoIn = TRUE;
        pHwDevExt->NeedCameraON = FALSE;
    }

    if (pHwDevExt->NeedCameraOFF == TRUE) {
        BertDMAEnable(pHwDevExt, FALSE);
        pHwDevExt->NeedCameraOFF = FALSE;
    }

    if (pHwDevExt->bRequestDpc == FALSE) {
        return;
    }

    for (StreamNumber = 0; StreamNumber < MAX_TSBVCAP_STREAMS; StreamNumber++) {
        if ( pHwDevExt->pStrmEx[StreamNumber] ) {
            TransferRoutine(pHwDevExt, StreamNumber);
        }
    }
}
#endif//TOSHIBA

/*
** HwInterrupt()
**
**   Routine is called when an interrupt at the IRQ level specified by the
**   ConfigInfo structure passed to the HwInitialize routine is received.
**
**   Note: IRQs may be shared, so the device should ensure the IRQ received
**         was expected
**
** Arguments:
**
**  pHwDevEx - the device extension for the hardware interrupt
**
** Returns:
**
** Side Effects:  none
*/

BOOLEAN
HwInterrupt(
    IN PHW_DEVICE_EXTENSION  pHwDevEx
    )
{

#ifdef  TOSHIBA
    pHwDevEx->bRequestDpc = FALSE;
    /*
     * call the acknowledge. this will not do any service, but will
     * return TRUE if the service routine is to be called.
     */
    if (!InterruptAcknowledge(pHwDevEx)) {
        return(FALSE);
    }

    /* the isr reckons that it is time to schedule the service
     * routine. This is done on a DPC.
     */

    if( pHwDevEx->bRequestDpc )
    {
        if (pHwDevEx->DpcRequested) {
            KdPrint(("dpc overrun.\n"));
        } else {
//          KdPrint(("dpc requested.\n"));
            pHwDevEx->DpcRequested = TRUE;
            IoRequestDpc(pHwDevEx->PDO, NULL, pHwDevEx);
        }
    }
    else
    {
        KdPrint(("bRequestDpc Flag is False.\n"));
        if (pHwDevEx->DpcRequested) {
            KdPrint(("dpc overrun.\n"));
        } else {
//          KdPrint(("dpc requested.\n"));
            pHwDevEx->DpcRequested = TRUE;
            IoRequestDpc(pHwDevEx->PDO, NULL, pHwDevEx);
        }
    }

    /* everything else is done in dpc routine */

    return(TRUE);
#else //TOSHIBA
    BOOL fMyIRQ = FALSE;

    if (pHwDevEx->IRQExpected)
    {
        pHwDevEx->IRQExpected = FALSE;

        //
        // call the routine to handle the IRQ here
        //

        fMyIRQ = TRUE;
    }


    //
    // returning FALSE indicates that this was not an IRQ for this device, and
    // the IRQ dispatcher will pass the IRQ down the chain to the next handler
    // for this IRQ level
    //

    return(fMyIRQ);
#endif//TOSHIBA
}

#ifdef  TOSHIBA
/*
 * interrupt acknowledge routine. This is called to ack the interrupt
 * and re-enable it for next time. It should return TRUE if it is time
 * to capture a frame.
 */
BOOLEAN
InterruptAcknowledge(PHW_DEVICE_EXTENSION pHwDevExt)
{
    LARGE_INTEGER CurrentTime;
    ULONG istat;
    ULONG intrst;
    BOOLEAN bret;
    BOOL bSLI;

    istat = ReadRegUlong(pHwDevExt, BERT_INTSTAT_REG);

    if (0xFFFFFFFF == istat)
        return FALSE;

    if (!((istat >> 16) & (istat & 0xffff)))
    {
        return FALSE;
    }

    intrst = 0x0;
    bret = FALSE;
    bSLI = FALSE;

    if ((istat & RPS_INT_MASK) && (istat & RPS_INT))
    {
        intrst |= RPS_INT_RESET;

        bret = TRUE;

        if (pHwDevExt->bVideoIn)
        {
            pHwDevExt->bRequestDpc = TRUE;
        }
#ifdef  _FPS_COUNT_
        InterruptCounter++;
#endif//_FPS_COUNT_
    }

    if ((istat & FIELD_INT_MASK) && (istat & FIELD_INT))
    {
        intrst |= FIELD_INT_RESET;
        bret = TRUE;
    }

    if ((istat & SYNC_LOCK_INT_MASK) && (istat & SYNC_LOCK_INT))
    {
        intrst |= SYNC_LOCK_INT_RESET;
        bret = TRUE;
        bSLI = TRUE;
    }

    if ((istat & FIFO_OVERFLOW_INT_MASK) && (istat & FIFO_OVERFLOW_INT))
    {
        intrst |= FIFO_OVERFLOW_INT_RESET;
        bret = TRUE;
    }

    if ((istat & LINE_TIMEOUT_INT_MASK) && (istat & LINE_TIMEOUT_INT))
    {
        intrst |= LINE_TIMEOUT_INT_RESET;
        bret = TRUE;
    }

    if ((istat & RPS_OOB_INT_MASK) && (istat & RPS_OOB_INT))
    {
        intrst |= RPS_OOB_INT_RESET;
        bret = TRUE;
    }

    if ((istat & REG_UNDEF_INT_MASK) && (istat & REG_UNDEF_INT))
    {
        intrst |= REG_UNDEF_INT_RESET;
        bret = TRUE;
    }

    if ((istat & SLOW_CLOCK_INT_MASK) && (istat & SLOW_CLOCK_INT))
    {
        intrst |= SLOW_CLOCK_INT_RESET;
        bret = TRUE;

        if (pHwDevExt->bVideoIn)
        {
            if ((ReadRegUlong(pHwDevExt, BERT_CAPSTAT_REG) & ERPS) == 0x0)
            {
                WriteRegUlong(pHwDevExt, BERT_CAPSTAT_REG, (ERPS | CKRE | CKMD));
            }
        }
    }

    if ((istat & OVER_RUN_INT_MASK) && (istat & OVER_RUN_INT))
    {
        intrst |= OVER_RUN_INT_RESET;
        bret = TRUE;

        if (pHwDevExt->bVideoIn)
        {
            if ((ReadRegUlong(pHwDevExt, BERT_CAPSTAT_REG) & ERPS) == 0x0)
            {
                WriteRegUlong(pHwDevExt, BERT_CAPSTAT_REG, (ERPS | CKRE | CKMD));
            }
        }
    }

    if ((istat & REG_LOAD_INT_MASK) && (istat & REG_LOAD_INT))
    {
        intrst |= REG_LOAD_INT_RESET;
        bret = TRUE;

        if (pHwDevExt->bVideoIn)
        {
            if ((ReadRegUlong(pHwDevExt, BERT_CAPSTAT_REG) & ERPS) == 0x0)
            {
                WriteRegUlong(pHwDevExt, BERT_CAPSTAT_REG, (ERPS | CKRE | CKMD));
            }
        }
    }

    if ((istat & LINE_SYNC_INT_MASK) && (istat & LINE_SYNC_INT))
    {
        intrst |= LINE_SYNC_INT_RESET;
        bret = TRUE;
    }

    if ((istat & IIC_ERROR_INT_MASK) && (istat & IIC_ERROR_INT))
    {
        intrst |= IIC_ERROR_INT_RESET;
        bret = TRUE;

        if (pHwDevExt->bVideoIn)
        {
            if ((ReadRegUlong(pHwDevExt, BERT_CAPSTAT_REG) & ERPS) == 0x0)
            {
                WriteRegUlong(pHwDevExt, BERT_CAPSTAT_REG, (ERPS | CKRE | CKMD));
            }
        }
    }

    if ((istat & PCI_PARITY_ERROR_INT_MASK) && (istat & PCI_PARITY_ERROR_INT))
    {
        intrst |= PCI_PARITY_ERROR_INT_RESET;
        bret = TRUE;
    }

    if ((istat & PCI_ACCESS_ERROR_INT_MASK) && (istat & PCI_ACCESS_ERROR_INT))
    {
        intrst |= PCI_ACCESS_ERROR_INT_RESET;
        bret = TRUE;
    }

    if ((istat & SPARE_INT_MASK) && (istat & SPARE_INT))
    {
        intrst |= SPARE_INT_RESET;
        bret = TRUE;
    }

    if (bret)
    {
        WriteRegUlong(pHwDevExt, BERT_INTRST_REG, intrst);
    }

    if (bSLI)
    {
        if (BertIsLocked(pHwDevExt))    // Mount Camera
        {
            pHwDevExt->NeedCameraON = TRUE;
            KdPrint(("Mount Camera\n"));
        }
        else                            // Remove Camera
        {
            pHwDevExt->NeedCameraOFF = TRUE;
            pHwDevExt->bVideoIn = FALSE;
            KdPrint(("Remove Camera\n"));
        }
    }
    return bret;
}
#endif//TOSHIBA
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\drivers\wdm\capture\mini\mstape\strmdata.h ===
/*++

Copyright (C) Microsoft Corporation, 1999 - 2001  

Module Name:

    StrmData.h

Abstract:

    Header file for supporting SD DV over 1394;

Last changed by:
    
    Author:      Yee J. Wu

--*/

#ifndef _DVSTRM_INC
#define _DVSTRM_INC



#define STATIC_KSCATEGORY_RENDER_EXTERNAL \
    0xcc7bfb41L, 0xf175, 0x11d1, 0xa3, 0x92, 0x00, 0xe0, 0x29, 0x1f, 0x39, 0x59
DEFINE_GUIDSTRUCT("cc7bfb41-f175-11d1-a392-00e0291f3959", KSCATEGORY_RENDER_EXTERNAL);
#define KSCATEGORY_RENDER_EXTERNAL DEFINE_GUIDNAMED(KSCATEGORY_RENDER_EXTERNAL)

// stream topology stuff for DV
static GUID DVCategories[] = {
    STATIC_KSCATEGORY_VIDEO,             // Output pin
    STATIC_KSCATEGORY_CAPTURE,           // Output pin
    STATIC_KSCATEGORY_RENDER,            // Input pin
    STATIC_KSCATEGORY_RENDER_EXTERNAL,   // Input pin
};

#define NUMBER_OF_DV_CATEGORIES  SIZEOF_ARRAY (DVCategories)

static KSTOPOLOGY DVTopology = {
    NUMBER_OF_DV_CATEGORIES,     // CategoriesCount
    DVCategories,                // Categories
    0,                           // TopologyNodesCount
    NULL,                        // TopologyNodes
    0,                           // TopologyConnectionsCount
    NULL,                        // TopologyConnections
    NULL,                        // TopologyNodesNames
    0,                           // Reserved
};

// stream topology stuff for MPEG2TS 
static GUID MPEG2TSCategories[] = {
    STATIC_KSCATEGORY_VIDEO,             // Output pin
    STATIC_KSCATEGORY_CAPTURE,           // Output pin
};

#define NUMBER_OF_MPEG2TS_CATEGORIES  SIZEOF_ARRAY (MPEG2TSCategories)

static KSTOPOLOGY MPEG2TSTopology = {
    NUMBER_OF_MPEG2TS_CATEGORIES, // CategoriesCount
    MPEG2TSCategories,           // Categories
    0,                           // TopologyNodesCount
    NULL,                        // TopologyNodes
    0,                           // TopologyConnectionsCount
    NULL,                        // TopologyConnections
    NULL,                        // TopologyNodesNames
    0,                           // Reserved
};
    
#ifndef mmioFOURCC    
#define mmioFOURCC( ch0, ch1, ch2, ch3 )                \
        ( (DWORD)(BYTE)(ch0) | ( (DWORD)(BYTE)(ch1) << 8 ) |    \
        ( (DWORD)(BYTE)(ch2) << 16 ) | ( (DWORD)(BYTE)(ch3) << 24 ) )
#endif  
#define FOURCC_DVSD        mmioFOURCC('d', 'v', 's', 'd')

#undef D_X_NTSC
#undef D_Y_NTSC
#undef D_X_NTSC_MIN
#undef D_Y_NTSC_MIN
#undef D_X_PAL
#undef D_Y_PAL
#undef D_X_PAL_MIN
#undef D_Y_PAL_MIN

#define D_X_NTSC            720
#define D_Y_NTSC            480
#define D_X_NTSC_MIN        360
#define D_Y_NTSC_MIN        240

#define D_X_PAL                720
#define D_Y_PAL                576
#define D_X_PAL_MIN            360
#define D_Y_PAL_MIN            288


// ------------------------------------------------------------------------
// External Device PROPERTY
// ------------------------------------------------------------------------

DEFINE_KSPROPERTY_TABLE(ExternalDeviceProperties)
{
    DEFINE_KSPROPERTY_ITEM
    (
        KSPROPERTY_EXTDEVICE_CAPABILITIES,
        TRUE,                                   // GetSupported or Handler
        sizeof(KSPROPERTY),                     // MinProperty
        sizeof(KSPROPERTY_EXTDEVICE_S),         // MinData
        FALSE,                                  // SetSupported or Handler
        NULL,                                   // Values
        0,                                      // RelationsCount
        NULL,                                   // Relations
        NULL,                                   // SupportHandler
        sizeof(ULONG)                           // SerializedSize
    ),

    DEFINE_KSPROPERTY_ITEM
    (
        KSPROPERTY_EXTDEVICE_PORT,
        TRUE,                                   // GetSupported or Handler
        sizeof(KSPROPERTY),                     // MinProperty
        sizeof(KSPROPERTY_EXTDEVICE_S),         // MinData
        FALSE,                                  // SetSupported or Handler
        NULL,                                   // Values
        0,                                      // RelationsCount
        NULL,                                   // Relations
        NULL,                                   // SupportHandler
        sizeof(ULONG)                           // SerializedSize
    ), 
    
    DEFINE_KSPROPERTY_ITEM
    (
        KSPROPERTY_EXTDEVICE_POWER_STATE,
        TRUE,                                   // GetSupported or Handler
        sizeof(KSPROPERTY),                     // MinProperty
        sizeof(KSPROPERTY_EXTDEVICE_S),         // MinData
        TRUE,                                   // SetSupported or Handler
        NULL,                                   // Values
        0,                                      // RelationsCount
        NULL,                                   // Relations
        NULL,                                   // SupportHandler
        sizeof(ULONG)                           // SerializedSize
    ),    

    DEFINE_KSPROPERTY_ITEM
    (
        KSPROPERTY_EXTDEVICE_ID,
        TRUE,                                   // GetSupported or Handler
        sizeof(KSPROPERTY),                     // MinProperty
        sizeof(KSPROPERTY_EXTDEVICE_S),         // MinData
        FALSE,                                  // SetSupported or Handler
        NULL,                                   // Values
        0,                                      // RelationsCount
        NULL,                                   // Relations
        NULL,                                   // SupportHandler
        sizeof(ULONG)                           // SerializedSize
    ),

    DEFINE_KSPROPERTY_ITEM
    (
        KSPROPERTY_EXTDEVICE_VERSION,
        TRUE,                                   // GetSupported or Handler
        sizeof(KSPROPERTY),                     // MinProperty
        sizeof(KSPROPERTY_EXTDEVICE_S),         // MinData
        FALSE,                                  // SetSupported or Handler
        NULL,                                   // Values
        0,                                      // RelationsCount
        NULL,                                   // Relations
        NULL,                                   // SupportHandler
        sizeof(ULONG)                           // SerializedSize
    ),

};



DEFINE_KSPROPERTY_TABLE(ExternalTransportProperties)
{
    DEFINE_KSPROPERTY_ITEM
    (
        KSPROPERTY_EXTXPORT_CAPABILITIES,
        TRUE,                                   // GetSupported or Handler
        sizeof(KSPROPERTY),                     // MinProperty
        sizeof(KSPROPERTY_EXTXPORT_S),          // MinData
        FALSE,                                  // SetSupported or Handler
        NULL,                                   // Values
        0,                                      // RelationsCount
        NULL,                                   // Relations
        NULL,                                   // SupportHandler
        sizeof(ULONG)                           // SerializedSize
    ),

    DEFINE_KSPROPERTY_ITEM
    (
        KSPROPERTY_EXTXPORT_INPUT_SIGNAL_MODE,
        TRUE,                                   // GetSupported or Handler
        sizeof(KSPROPERTY),                     // MinProperty
        sizeof(KSPROPERTY_EXTXPORT_S),          // MinData
        FALSE,                                  // SetSupported or Handler
        NULL,                                   // Values
        0,                                      // RelationsCount
        NULL,                                   // Relations
        NULL,                                   // SupportHandler
        sizeof(ULONG)                           // SerializedSize
    ),

    DEFINE_KSPROPERTY_ITEM
    (
        KSPROPERTY_EXTXPORT_OUTPUT_SIGNAL_MODE,
        TRUE,                                   // GetSupported or Handler
        sizeof(KSPROPERTY),                     // MinProperty
        sizeof(KSPROPERTY_EXTXPORT_S),          // MinData
        FALSE,                                  // SetSupported or Handler
        NULL,                                   // Values
        0,                                      // RelationsCount
        NULL,                                   // Relations
        NULL,                                   // SupportHandler
        sizeof(ULONG)                           // SerializedSize
    ),

    DEFINE_KSPROPERTY_ITEM
    (
        KSPROPERTY_EXTXPORT_LOAD_MEDIUM,
        FALSE,                                  // GetSupported or Handler
        sizeof(KSPROPERTY),                     // MinProperty
        sizeof(KSPROPERTY_EXTXPORT_S),          // MinData
        TRUE,                                   // SetSupported or Handler
        NULL,                                   // Values
        0,                                      // RelationsCount
        NULL,                                   // Relations
        NULL,                                   // SupportHandler
        sizeof(ULONG)                           // SerializedSize
    ),

    DEFINE_KSPROPERTY_ITEM
    (
        KSPROPERTY_EXTXPORT_MEDIUM_INFO,
        TRUE,                                   // GetSupported or Handler
        sizeof(KSPROPERTY),                     // MinProperty
        sizeof(KSPROPERTY_EXTXPORT_S),          // MinData
        FALSE,                                  // SetSupported or Handler
        NULL,                                   // Values
        0,                                      // RelationsCount
        NULL,                                   // Relations
        NULL,                                   // SupportHandler
        sizeof(ULONG)                           // SerializedSize
    ),

    DEFINE_KSPROPERTY_ITEM
    (
        KSPROPERTY_EXTXPORT_STATE,
        TRUE,                                   // GetSupported or Handler
        sizeof(KSPROPERTY),                     // MinProperty
        sizeof(KSPROPERTY_EXTXPORT_S),          // MinData
        TRUE,                                   // SetSupported or Handler
        NULL,                                   // Values
        0,                                      // RelationsCount
        NULL,                                   // Relations
        NULL,                                   // SupportHandler
        sizeof(ULONG)                           // SerializedSize
    ),

    DEFINE_KSPROPERTY_ITEM
    (
        // If this is an asychronous operation, we need to set and then get in separate calls.
        KSPROPERTY_EXTXPORT_STATE_NOTIFY,
        TRUE,                                   // GetSupported or Handler
        sizeof(KSPROPERTY),                     // MinProperty
        sizeof(KSPROPERTY_EXTXPORT_S),          // MinData
        TRUE,                                   // SetSupported or Handler
        NULL,                                   // Values
        0,                                      // RelationsCount
        NULL,                                   // Relations
        NULL,                                   // SupportHandler
        sizeof(ULONG)                           // SerializedSize
    ),


    DEFINE_KSPROPERTY_ITEM
    (
        KSPROPERTY_EXTXPORT_TIMECODE_SEARCH,
        FALSE,                                  // GetSupported or Handler
        sizeof(KSPROPERTY),                     // MinProperty
        sizeof(KSPROPERTY_EXTXPORT_S),          // MinData
        TRUE,                                   // SetSupported or Handler
        NULL,                                   // Values
        0,                                      // RelationsCount
        NULL,                                   // Relations
        NULL,                                   // SupportHandler
        sizeof(ULONG)                           // SerializedSize
    ),

    DEFINE_KSPROPERTY_ITEM
    (
        KSPROPERTY_EXTXPORT_ATN_SEARCH,
        FALSE,                                  // GetSupported or Handler
        sizeof(KSPROPERTY),                     // MinProperty
        sizeof(KSPROPERTY_EXTXPORT_S),          // MinData
        TRUE,                                   // SetSupported or Handler
        NULL,                                   // Values
        0,                                      // RelationsCount
        NULL,                                   // Relations
        NULL,                                   // SupportHandler
        sizeof(ULONG)                           // SerializedSize
    ),

    DEFINE_KSPROPERTY_ITEM
    (
        KSPROPERTY_EXTXPORT_RTC_SEARCH,
        FALSE,                                  // GetSupported or Handler
        sizeof(KSPROPERTY),                     // MinProperty
        sizeof(KSPROPERTY_EXTXPORT_S),          // MinData
        TRUE,                                   // SetSupported or Handler
        NULL,                                   // Values
        0,                                      // RelationsCount
        NULL,                                   // Relations
        NULL,                                   // SupportHandler
        sizeof(ULONG)                           // SerializedSize
    ),

    //
    // Allow any RAW AVC to go through including Vendor dependent
    //
    DEFINE_KSPROPERTY_ITEM
    (
        KSPROPERTY_RAW_AVC_CMD,
        TRUE,                                   // GetSupported or Handler
        sizeof(KSPROPERTY),                     // MinProperty
        sizeof(KSPROPERTY_EXTXPORT_S),          // MinData
        TRUE,                                   // SetSupported or Handler
        NULL,                                   // Values
        0,                                      // RelationsCount
        NULL,                                   // Relations
        NULL,                                   // SupportHandler
        sizeof(ULONG)                           // SerializedSize
    ),

};


DEFINE_KSPROPERTY_TABLE(TimeCodeReaderProperties)
{
    DEFINE_KSPROPERTY_ITEM
    (
        KSPROPERTY_TIMECODE_READER,
        TRUE,                                   // GetSupported or Handler
        sizeof(KSPROPERTY),                     // MinProperty
        sizeof(KSPROPERTY_TIMECODE_S),          // MinData
        FALSE,                                  // SetSupported or Handler
        NULL,                                   // Values
        0,                                      // RelationsCount
        NULL,                                   // Relations
        NULL,                                   // SupportHandler
        sizeof(ULONG)                           // SerializedSize
    ),

    DEFINE_KSPROPERTY_ITEM
    (
        KSPROPERTY_ATN_READER,
        TRUE,                                   // GetSupported or Handler
        sizeof(KSPROPERTY),                     // MinProperty
        sizeof(KSPROPERTY_TIMECODE_S),          // MinData
        FALSE,                                  // SetSupported or Handler
        NULL,                                   // Values
        0,                                      // RelationsCount
        NULL,                                   // Relations
        NULL,                                   // SupportHandler
        sizeof(ULONG)                           // SerializedSize
    ),

    DEFINE_KSPROPERTY_ITEM
    (
        KSPROPERTY_RTC_READER,
        TRUE,                                   // GetSupported or Handler
        sizeof(KSPROPERTY),                     // MinProperty
        sizeof(KSPROPERTY_TIMECODE_S),          // MinData
        FALSE,                                  // SetSupported or Handler
        NULL,                                   // Values
        0,                                      // RelationsCount
        NULL,                                   // Relations
        NULL,                                   // SupportHandler
        sizeof(ULONG)                           // SerializedSize
    ),
};


DEFINE_KSPROPERTY_TABLE(MediaSeekingProperties)
{
    DEFINE_KSPROPERTY_ITEM
    (
        // Corresponding to IMediaSeeking::IsFormatSupported()
        KSPROPERTY_MEDIASEEKING_FORMATS,
        TRUE,                                   // GetSupported or Handler
        sizeof(KSPROPERTY),                     // MinProperty
        0,                                      // MinData; MULTIPLE_ITEM, 2 step process to get data
        FALSE,                                  // SetSupported or Handler
        NULL,                                   // Values
        0,                                      // RelationsCount
        NULL,                                   // Relations
        NULL,                                   // SupportHandler
        sizeof(ULONG)                           // SerializedSize
   ),
};

KSPROPERTY_SET    VideoDeviceProperties[] =
{
    DEFINE_KSPROPERTY_SET
    ( 
        &PROPSETID_EXT_DEVICE,                   // Set
        SIZEOF_ARRAY(ExternalDeviceProperties),         // PropertiesCount
        ExternalDeviceProperties,                       // PropertyItem
        0,                                              // FastIoCount
        NULL                                            // FastIoTable
    ),

    DEFINE_KSPROPERTY_SET
    ( 
        &PROPSETID_EXT_TRANSPORT,                // Set
        SIZEOF_ARRAY(ExternalTransportProperties),      // PropertiesCount
        ExternalTransportProperties,                    // PropertyItem
        0,                                              // FastIoCount
        NULL                                            // FastIoTable
    ),

    DEFINE_KSPROPERTY_SET
    ( 
        &PROPSETID_TIMECODE_READER,              // Set
        SIZEOF_ARRAY(TimeCodeReaderProperties),         // PropertiesCount
        TimeCodeReaderProperties,                       // PropertyItem
        0,                                              // FastIoCount
        NULL                                            // FastIoTable
    ),

    DEFINE_KSPROPERTY_SET
    ( 
        &KSPROPSETID_MediaSeeking,                    // Set
        SIZEOF_ARRAY(MediaSeekingProperties),         // PropertiesCount
        MediaSeekingProperties,                       // PropertyItem
        0,                                            // FastIoCount
        NULL                                          // FastIoTable
    ),
};

#define NUMBER_VIDEO_DEVICE_PROPERTIES (SIZEOF_ARRAY(VideoDeviceProperties))


// ------------------------------------------------------------------------
// External Device Events
// ------------------------------------------------------------------------

KSEVENT_ITEM ExtDevCommandItm[] = 
{
    {
        KSEVENT_EXTDEV_COMMAND_NOTIFY_INTERIM_READY,
        0, // sizeof(KSEVENT_ITEM),
        0,
        NULL,
        NULL,
        NULL
    },    

    {
        KSEVENT_EXTDEV_COMMAND_CONTROL_INTERIM_READY,
        0, // sizeof(KSEVENT_ITEM),
        0,
        NULL,
        NULL,
        NULL
    },

#ifdef MSDVDV_SUPPORT_BUSRESET_EVENT    
    // Application cares about this since AVC command will be ABORTED!
    {
        KSEVENT_EXTDEV_COMMAND_BUSRESET,
        0, // sizeof(KSEVENT_ITEM),
        0,
        NULL,
        NULL,
        NULL
    },
#endif

    // Tell client this device is being removed.
    {
        KSEVENT_EXTDEV_NOTIFY_REMOVAL,
        0, // sizeof(KSEVENT_ITEM),
        0,
        NULL,
        NULL,
        NULL
    },
};

// define event set related with streams
KSEVENT_SET VideoDeviceEvents[] =
{
    {
        &KSEVENTSETID_EXTDEV_Command,
        SIZEOF_ARRAY(ExtDevCommandItm),
        ExtDevCommandItm,
    },
};

#define NUMBER_VIDEO_DEVICE_EVENTS (SIZEOF_ARRAY(VideoDeviceEvents))


// ------------------------------------------------------------------------
// Stream Property sets for all video capture streams
// ------------------------------------------------------------------------

DEFINE_KSPROPERTY_TABLE(VideoStreamConnectionProperties)
{
    DEFINE_KSPROPERTY_ITEM
    (
        KSPROPERTY_CONNECTION_ALLOCATORFRAMING,
        TRUE,                                   // GetSupported or Handler
        sizeof(KSPROPERTY),                     // MinProperty
        sizeof(KSALLOCATOR_FRAMING),            // MinData
        FALSE,                                  // SetSupported or Handler
        NULL,                                   // Values
        0,                                      // RelationsCount
        NULL,                                   // Relations
        NULL,                                   // SupportHandler
        sizeof(ULONG)                           // SerializedSize
    ),
};

DEFINE_KSPROPERTY_TABLE(VideoStreamDroppedFramesProperties)
{
    DEFINE_KSPROPERTY_ITEM
    (
        KSPROPERTY_DROPPEDFRAMES_CURRENT,
        TRUE,                                   // GetSupported or Handler
        sizeof(KSPROPERTY_DROPPEDFRAMES_CURRENT_S),// MinProperty
        sizeof(KSPROPERTY_DROPPEDFRAMES_CURRENT_S),// MinData
        FALSE,                                  // SetSupported or Handler
        NULL,                                   // Values
        0,                                      // RelationsCount
        NULL,                                   // Relations
        NULL,                                   // SupportHandler
        0                                       // SerializedSize
    ),
};


KSPROPERTY_SET    VideoStreamProperties[] =
{
    DEFINE_KSPROPERTY_SET
    ( 
        &KSPROPSETID_Connection,                        // Set
        SIZEOF_ARRAY(VideoStreamConnectionProperties),  // PropertiesCount
        VideoStreamConnectionProperties,                // PropertyItem
        0,                                              // FastIoCount
        NULL                                            // FastIoTable
    ),

    DEFINE_KSPROPERTY_SET
    ( 
        &PROPSETID_VIDCAP_DROPPEDFRAMES,                // Set
        SIZEOF_ARRAY(VideoStreamDroppedFramesProperties),  // PropertiesCount
        VideoStreamDroppedFramesProperties,                // PropertyItem
        0,                                              // FastIoCount
        NULL                                            // FastIoTable
    ),
};

#define NUMBER_VIDEO_STREAM_PROPERTIES (SIZEOF_ARRAY(VideoStreamProperties))


// ----------------------------------------------------------------------
// Stream events
// ------------------------------------------------------------------------


// FORMAT_DVInfo
//
// Create a local copy of this GUID and make sure that it is not in the PAGED segment
//
const
GUID
KSEVENTSETID_Connection_Local = {STATICGUIDOF(KSEVENTSETID_Connection)};

const
GUID
KSEVENTSETID_Clock_Local = {STATICGUIDOF(KSEVENTSETID_Clock)};

// Isoch transmit End of stream event item
KSEVENT_ITEM EndOfStreamEventItm[] = 
{
    {
        KSEVENT_CONNECTION_ENDOFSTREAM,
        0,
        0,
        NULL,
        NULL,
        NULL
    }
};

// Clock event item
KSEVENT_ITEM ClockEventItm[] =
{
    {
        KSEVENT_CLOCK_POSITION_MARK,        // position mark event supported
        sizeof (KSEVENT_TIME_MARK),         // requires this data as input
        sizeof (KSEVENT_TIME_MARK),         // allocate space to copy the data
        NULL,
        NULL,
        NULL
    },
#if 0
    {
        KSEVENT_CLOCK_INTERVAL_MARK,        // interval mark event supported
        sizeof (KSEVENT_TIME_INTERVAL),     // requires interval data as input
        sizeof (MYTIME),                    // we use an additional workspace of
                                            // size longlong for processing
                                            // this event
        NULL,
        NULL,
        NULL
    }
#endif
};

KSEVENT_SET ClockEventSet[] =
{
    {
        &KSEVENTSETID_Clock,
        SIZEOF_ARRAY(ClockEventItm),
        ClockEventItm,
    }
};


// define event set related with streams

// Output pin event set
KSEVENT_SET StreamEventsOutPin[] =
{
    {
        &KSEVENTSETID_Clock_Local,
        SIZEOF_ARRAY(ClockEventItm),
        ClockEventItm,
    },
};

// Input pin events set
KSEVENT_SET StreamEventsInPin[] =
{
    {
        &KSEVENTSETID_Connection_Local, 
        SIZEOF_ARRAY(EndOfStreamEventItm),
        EndOfStreamEventItm,
    },
    {
        &KSEVENTSETID_Clock_Local,
        SIZEOF_ARRAY(ClockEventItm),
        ClockEventItm,
    },
};

// Input pin events set for MPEG2TS (has EOS but no clock event)
KSEVENT_SET StreamEventsInPinMPEG2TS[] =
{
    {
        &KSEVENTSETID_Connection_Local, 
        SIZEOF_ARRAY(EndOfStreamEventItm),
        EndOfStreamEventItm,
    },
};

#define NUMBER_STREAM_EVENTS_OUT_PIN (SIZEOF_ARRAY(StreamEventsOutPin))
#define NUMBER_STREAM_EVENTS_IN_PIN (SIZEOF_ARRAY(StreamEventsInPin))

#define NUMBER_STREAM_EVENTS_IN_PIN_MPEG2TS (SIZEOF_ARRAY(StreamEventsInPinMPEG2TS))




// ----------------------------------------------------------------------
// Stream data ranges
// ------------------------------------------------------------------------



/**********************************************************************
 SDDV data range
 **********************************************************************/

// NTSC stream
KS_DATARANGE_VIDEO DvcrNTSCVideoStream =
{
    // KSDATARANGE
    {
        sizeof (KS_DATARANGE_VIDEO),    // FormatSize
        0,                              // Flags
        FRAME_SIZE_SDDV_NTSC,           // SampleSize
        0,                              // Reserved
        STATIC_KSDATAFORMAT_TYPE_VIDEO,
        STATIC_KSDATAFORMAT_SUBTYPE_DVSD,
        STATIC_KSDATAFORMAT_SPECIFIER_VIDEOINFO,
    },

    TRUE,               // BOOL,  bFixedSizeSamples (all samples same size?)
    FALSE,              // BOOL,  bTemporalCompression (all I frames?)
    KS_VIDEOSTREAM_CAPTURE, // StreamDescriptionFlags  (KS_VIDEO_DESC_*)
    0,                  // MemoryAllocationFlags   (KS_VIDEO_ALLOC_*)

    // _KS_VIDEO_STREAM_CONFIG_CAPS  
    {
        STATIC_KSDATAFORMAT_SPECIFIER_VIDEOINFO, //MEDIATYPE_Video
        KS_AnalogVideo_NTSC_M,        // AnalogVideoStandard
        D_X_NTSC, D_Y_NTSC,         // InputSize, (the inherent size of the incoming signal
                                    //             with every digitized pixel unique)
        D_X_NTSC_MIN, D_Y_NTSC_MIN, // MinCroppingSize, smallest rcSrc cropping rect allowed
        D_X_NTSC, D_Y_NTSC,         // MaxCroppingSize, largest  rcSrc cropping rect allowed
        1,              // CropGranularityX, granularity of cropping size
        1,              // CropGranularityY    
        1,              // CropAlignX, alignment of cropping rect 
        1,              // CropAlignY;
        D_X_NTSC_MIN, D_Y_NTSC_MIN,     // MinOutputSize, smallest bitmap stream can produce
        D_X_NTSC, D_Y_NTSC,                // MaxOutputSize, largest  bitmap stream can produce
        1,              // OutputGranularityX, granularity of output bitmap size
        1,              // OutputGranularityY;
        0,              // StretchTapsX  (0 no stretch, 1 pix dup, 2 interp...)
        0,              // StretchTapsY
        0,              // ShrinkTapsX 
        0,              // ShrinkTapsY
        333667,         // MinFrameInterval, 100 nS units// MinFrameInterval, 100 nS units
        333667,         // MaxFrameInterval, 100 nS units
        (FRAME_SIZE_SDDV_NTSC * 8)*30,     // MinBitsPerSecond;
        (FRAME_SIZE_SDDV_NTSC * 8)*30,     // MaxBitsPerSecond;
    }, 
        
    // KS_VIDEOINFOHEADER (default format)
    {
        0,0,0,0, //D_X_NTSC,D_Y_NTSC,    // 0,0,720,480
        0,0,0,0,        //    RECT            rcTarget;          // Where the video should go
        (FRAME_SIZE_SDDV_NTSC * 8 * 30),    //    DWORD           dwBitRate;         // Approximate bit data rate
        0L,             //    DWORD           dwBitErrorRate;    // Bit error rate for this stream
        333667,         //    REFERENCE_TIME  AvgTimePerFrame;   // Average time per frame (100ns units)

        sizeof (KS_BITMAPINFOHEADER),   //    DWORD      biSize;
        D_X_NTSC,                       //    LONG       biWidth;
        D_Y_NTSC,                       //    LONG       biHeight;
        1,                          //    WORD       biPlanes;
        24,                         //    WORD       biBitCount;
        FOURCC_DVSD,                //    DWORD      biCompression;
        FRAME_SIZE_SDDV_NTSC,       //    DWORD      biSizeImage;
        0,                          //    LONG       biXPelsPerMeter;
        0,                          //    LONG       biYPelsPerMeter;
        0,                          //    DWORD      biClrUsed;
        0,                          //    DWORD      biClrImportant;
    },
};

// PAL stream format
KS_DATARANGE_VIDEO DvcrPALVideoStream =
{
    // KSDATARANGE
    {
        sizeof (KS_DATARANGE_VIDEO),
        0,                                // Flags
        FRAME_SIZE_SDDV_PAL,              // SampleSize
        0,                                // Reserved
        STATIC_KSDATAFORMAT_TYPE_VIDEO,
        STATIC_KSDATAFORMAT_SUBTYPE_DVSD,
        STATIC_KSDATAFORMAT_SPECIFIER_VIDEOINFO,
    },

    TRUE,               // BOOL,  bFixedSizeSamples (all samples same size?)
    FALSE,              // BOOL,  bTemporalCompression (all I frames?)
    KS_VIDEOSTREAM_CAPTURE,    // StreamDescriptionFlags  (KS_VIDEO_DESC_*)
    0,                  // MemoryAllocationFlags   (KS_VIDEO_ALLOC_*)

    // _KS_VIDEO_STREAM_CONFIG_CAPS  
    {
        STATIC_KSDATAFORMAT_SPECIFIER_VIDEOINFO, //MEDIATYPE_Video
        KS_AnalogVideo_PAL_B,        // AnalogVideoStandard
        D_X_PAL, D_Y_PAL,            // InputSize, (the inherent size of the incoming signal
                        //             with every digitized pixel unique)
        D_X_PAL_MIN, D_Y_PAL_MIN,   // MinCroppingSize, smallest rcSrc cropping rect allowed
        D_X_PAL, D_Y_PAL,           // MaxCroppingSize, largest  rcSrc cropping rect allowed
        1,              // CropGranularityX, granularity of cropping size
        1,              // CropGranularityY    
        1,              // CropAlignX, alignment of cropping rect 
        1,              // CropAlignY;
        D_X_PAL_MIN, D_Y_PAL_MIN,   // MinOutputSize, smallest bitmap stream can produce
        D_X_PAL, D_Y_PAL,            // MaxOutputSize, largest  bitmap stream can produce
        1,              // OutputGranularityX, granularity of output bitmap size
        1,              // OutputGranularityY;
        0,              // StretchTapsX  (0 no stretch, 1 pix dup, 2 interp...)
        0,              // StretchTapsY
        0,              // ShrinkTapsX 
        0,              // ShrinkTapsY
        400000,         // MinFrameInterval, 100 nS units
        400000,         // MaxFrameInterval, 100 nS units
        (FRAME_SIZE_SDDV_PAL * 8)*25,  // MinBitsPerSecond;
        (FRAME_SIZE_SDDV_PAL * 8)*25,  // MaxBitsPerSecond;
    }, 
        
    // KS_VIDEOINFOHEADER (default format)
    {
        0,0,0,0, // D_X_PAL,D_Y_PAL,    // 0,0,720,480
        0,0,0,0,        //    RECT            rcTarget;          // Where the video should go
        (FRAME_SIZE_SDDV_PAL * 8 * 25),  //    DWORD   dwBitRate;         // Approximate bit data rate
        0L,             //    DWORD           dwBitErrorRate;    // Bit error rate for this stream
        400000,         //    REFERENCE_TIME  AvgTimePerFrame;   // Average time per frame (100ns units)

        sizeof (KS_BITMAPINFOHEADER),   //    DWORD      biSize;
        D_X_PAL,                        //    LONG       biWidth;
        D_Y_PAL,                        //    LONG       biHeight;
        1,                          //    WORD       biPlanes;
        24,                         //    WORD       biBitCount;
        FOURCC_DVSD,                //    DWORD      biCompression;
        FRAME_SIZE_SDDV_PAL,     //    DWORD      biSizeImage;
        0,                          //    LONG       biXPelsPerMeter;
        0,                          //    LONG       biYPelsPerMeter;
        0,                          //    DWORD      biClrUsed;
        0,                          //    DWORD      biClrImportant;
    },
};



#define NTSC_DVAAuxSrc         0xd1c030cf 
#define PAL_DVAAuxSrc          0xd1e030d0
 
#define NTSC_DVAAuxSrc_DVCPRO  0xd1de30cf 
#define PAL_DVAAuxSrc_DVCPRO   0xd1fe30d0 

// NTSC stream (for iavs connections)
#ifdef SUPPORT_NEW_AVC
KS_DATARANGE_DV_AVC
#else
KS_DATARANGE_DVVIDEO 
#endif
    DvcrNTSCiavStream =
{
    // KSDATARANGE
    {
#ifdef SUPPORT_NEW_AVC
        sizeof (KS_DATARANGE_DV_AVC),     // FormatSize
#else
        sizeof (KS_DATARANGE_DVVIDEO),     // FormatSize
#endif
        0,                                 // Flags
        FRAME_SIZE_SDDV_NTSC,              // SampleSize
        0,                                 // Reserved
        STATIC_KSDATAFORMAT_TYPE_INTERLEAVED,
        STATIC_KSDATAFORMAT_SUBTYPE_DVSD,
        STATIC_KSDATAFORMAT_SPECIFIER_DVINFO,
    },

    // DVINFO
    // Note: audio is set for 32khz
    {
        //for 1st 5/6 DIF seq.
        NTSC_DVAAuxSrc, // 0xd1c030cf,                    // DWORD dwDVAAuxSrc;
        0xffa0c733,                    // DWORD dwDVAAuxCtl;
        // for 2nd  5/6 DIF seq.
        0xd1c03fcf,                    // DWORD dwDVAAuxSrc1; 32K, 12bit
        0xffa0ff3f,                    // DWORD dwDVAAuxCtl1;
        //for video information
        0xff00ffff,                    // DWORD dwDVVAuxSrc;
        0xfffcc833,                    // DWORD dwDVVAuxCtl;
        0,                             // DWORD dwDVReserved[2];
        0,                             //
    },
#ifdef SUPPORT_NEW_AVC
    // AVCPRECONNECTINFO
    {
     0,   // Device ID
     0,   // Subunit address
     0,   // Subunit Plug number
     0,   // Data Flow
     0,   // Flag/Plug Handle
     0,   // UnitPlugNumber
    },
#endif
};


// PAL stream (for iavs connections)
#ifdef SUPPORT_NEW_AVC
KS_DATARANGE_DV_AVC
#else
KS_DATARANGE_DVVIDEO 
#endif
    DvcrPALiavStream =
{
    // KSDATARANGE
    {
#ifdef SUPPORT_NEW_AVC
        sizeof (KS_DATARANGE_DV_AVC),     // FormatSize
#else
        sizeof (KS_DATARANGE_DVVIDEO),    // FormatSize
#endif
        0,                                // Flags
        FRAME_SIZE_SDDV_PAL,              // SampleSize
        0,                                // Reserved
        STATIC_KSDATAFORMAT_TYPE_INTERLEAVED,
        STATIC_KSDATAFORMAT_SUBTYPE_DVSD,
        STATIC_KSDATAFORMAT_SPECIFIER_DVINFO,
    },
    
    // DVINFO
    // Note: Audio is set for 32khz.
    {
        //for 1st 5/6 DIF seq.
        PAL_DVAAuxSrc, // 0xd1e030d0,                    // DWORD dwDVAAuxSrc;
        0xffa0cf3f,                    // DWORD dwDVAAuxCtl;
        // for 2nd  5/6 DIF seq.
        0xd1e03fd0,                    // DWORD dwDVAAuxSrc1; 32k, 12bit
        0xffa0cf3f,                    // DWORD dwDVAAuxCtl1;
        //for video information
        0xff20ffff,                    // DWORD dwDVVAuxSrc;
        0xfffdc83f,                    // DWORD dwDVVAuxCtl;
        0,                             // DWORD dwDVReserved[2];
        0,                             //
    },
#ifdef SUPPORT_NEW_AVC
    // AVCPRECONNECTINFO
    {
     0,   // Device ID
     0,   // Subunit address
     0,   // Subunit Plug number
     0,   // Data Flow
     0,   // Flag/Plug Handle
     0,   // UnitPlugNumber
    },
#endif
};


// NTSC stream (for iavs connections)
#ifdef SUPPORT_NEW_AVC
KS_DATARANGE_DV_AVC
#else
KS_DATARANGE_DVVIDEO 
#endif
    DvcrNTSCiavStreamIn =
{
    // KSDATARANGE
    {
#ifdef SUPPORT_NEW_AVC
        sizeof (KS_DATARANGE_DV_AVC),     // FormatSize
#else
        sizeof (KS_DATARANGE_DVVIDEO),     // FormatSize
#endif
        0,                                 // Flags
        FRAME_SIZE_SDDV_NTSC,              // SampleSize
        0,                                 // Reserved
        STATIC_KSDATAFORMAT_TYPE_INTERLEAVED,
        STATIC_KSDATAFORMAT_SUBTYPE_DVSD,
        STATIC_KSDATAFORMAT_SPECIFIER_DVINFO,
    },

    // DVINFO
    // Note: audio is set for 32khz
    {
        //for 1st 5/6 DIF seq.
        NTSC_DVAAuxSrc, // 0xd1c030cf,                    // DWORD dwDVAAuxSrc;
        0xffa0c733,                    // DWORD dwDVAAuxCtl;
        // for 2nd  5/6 DIF seq.
        0xd1c03fcf,                    // DWORD dwDVAAuxSrc1; 32K, 12bit
        0xffa0ff3f,                    // DWORD dwDVAAuxCtl1;
        //for video information
        0xff00ffff,                    // DWORD dwDVVAuxSrc;
        0xfffcc833,                    // DWORD dwDVVAuxCtl;
        0,                             // DWORD dwDVReserved[2];
        0,                             //
    },
#ifdef SUPPORT_NEW_AVC
    // AVCPRECONNECTINFO
    {
     0,   // Device ID
     0,   // Subunit address
     0,   // Subunit Plug number
     0,   // Data Flow
     0,   // Flag/Plug Handle
     0,   // UnitPlugNumber
    },
#endif
};


// PAL stream (for iavs connections)
#ifdef SUPPORT_NEW_AVC
KS_DATARANGE_DV_AVC
#else
KS_DATARANGE_DVVIDEO 
#endif
    DvcrPALiavStreamIn =
{
    // KSDATARANGE
    {
#ifdef SUPPORT_NEW_AVC
        sizeof (KS_DATARANGE_DV_AVC),     // FormatSize
#else
        sizeof (KS_DATARANGE_DVVIDEO),    // FormatSize
#endif
        0,                                // Flags
        FRAME_SIZE_SDDV_PAL,              // SampleSize
        0,                                // Reserved
        STATIC_KSDATAFORMAT_TYPE_INTERLEAVED,
        STATIC_KSDATAFORMAT_SUBTYPE_DVSD,
        STATIC_KSDATAFORMAT_SPECIFIER_DVINFO,
    },
    
    // DVINFO
    // Note: Audio is set for 32khz.
    {
        //for 1st 5/6 DIF seq.
        PAL_DVAAuxSrc, // 0xd1e030d0,                    // DWORD dwDVAAuxSrc;
        0xffa0cf3f,                    // DWORD dwDVAAuxCtl;
        // for 2nd  5/6 DIF seq.
        0xd1e03fd0,                    // DWORD dwDVAAuxSrc1; 32k, 12bit
        0xffa0cf3f,                    // DWORD dwDVAAuxCtl1;
        //for video information
        0xff20ffff,                    // DWORD dwDVVAuxSrc;
        0xfffdc83f,                    // DWORD dwDVVAuxCtl;
        0,                             // DWORD dwDVReserved[2];
        0,                             //
    },
#ifdef SUPPORT_NEW_AVC
    // AVCPRECONNECTINFO
    {
     0,   // Device ID
     0,   // Subunit address
     0,   // Subunit Plug number
     0,   // Data Flow
     0,   // Flag/Plug Handle
     0,   // UnitPlugNumber
    },
#endif
};





//
// A driver does not support both format at the same time,
// the MediaType (NTSC or PAL) is determined at the load time.
//

PKSDATAFORMAT DVCRStream0Formats[] = 
{
    (PKSDATAFORMAT) &DvcrNTSCVideoStream,
    (PKSDATAFORMAT) &DvcrPALVideoStream,
};

PKSDATAFORMAT DVCRStream1Formats[] = 
{
    (PKSDATAFORMAT) &DvcrNTSCiavStream,
    (PKSDATAFORMAT) &DvcrPALiavStream,
};

PKSDATAFORMAT DVCRStream2Formats[] = 
{
    (PKSDATAFORMAT) &DvcrNTSCiavStreamIn,
    (PKSDATAFORMAT) &DvcrPALiavStreamIn,
};


static KSPIN_MEDIUM NULLMedium = {STATIC_GUID_NULL, 0, 0};


#define NUM_DVCR_STREAM0_FORMATS        (SIZEOF_ARRAY(DVCRStream0Formats))
#define NUM_DVCR_STREAM1_FORMATS        (SIZEOF_ARRAY(DVCRStream1Formats))
#define NUM_DVCR_STREAM2_FORMATS        (SIZEOF_ARRAY(DVCRStream2Formats))

static GUID guidPinCategoryCapture  = {STATIC_PINNAME_VIDEO_CAPTURE};

static GUID guidPinNameDVVidOutput  = {STATIC_PINNAME_DV_VID_OUTPUT};
static GUID guidPinNameDVAVOutput   = {STATIC_PINNAME_DV_AV_OUTPUT};
static GUID guidPinNameDVAVInput    = {STATIC_PINNAME_DV_AV_INPUT};

//---------------------------------------------------------------------------
// Create an array that holds the list of all of the streams supported
//---------------------------------------------------------------------------

STREAM_INFO_AND_OBJ DVStreams [] = 
{
    // -----------------------------------------------------------------
    // Stream 0, DV coming from the camcorder
    // -----------------------------------------------------------------
    {
        // HW_STREAM_INFORMATION -------------------------------------------
        {
        1,                                              // NumberOfPossibleInstances
        KSPIN_DATAFLOW_OUT,                             // DataFlow
        TRUE,                                           // DataAccessible
        NUM_DVCR_STREAM0_FORMATS,                       // NumberOfFormatArrayEntries
        DVCRStream0Formats,                             // StreamFormatsArray
        0,                                              // ClassReserved[0]
        0,                                              // ClassReserved[1]
        0,                                              // ClassReserved[2]
        0,                                              // ClassReserved[3]
        NUMBER_VIDEO_STREAM_PROPERTIES,                 // NumStreamPropArrayEntries
        (PKSPROPERTY_SET) VideoStreamProperties,        // StreamPropertiesArray
        NUMBER_STREAM_EVENTS_OUT_PIN,                   // NumStreamEventArrayEntries
        StreamEventsOutPin,                             // StreamEventsArray
        &guidPinCategoryCapture,                        // Category
        &guidPinNameDVVidOutput,                        // Name
        0,                                              // Mediums count
        &NULLMedium,                                    // Mediums
        FALSE,                                          // BridgeStream
        0,                                              // Reserved[0]
        0,                                              // Reserved[1]
        },

        // HW_STREAM_OBJECT ------------------------------------------------
        {
        sizeof(HW_STREAM_OBJECT),
        0,                                              // StreamNumber
        0,                                              // HwStreamExtension
        AVCTapeRcvDataPacket,                           // ReceiveDataPacket
        AVCTapeRcvControlPacket,                        // ReceiveControlPacket
        {
            (PHW_CLOCK_FUNCTION) AVCTapeStreamClockRtn, // HW_CLOCK_OBJECT.HWClockFunction
            CLOCK_SUPPORT_CAN_RETURN_STREAM_TIME,       // HW_CLOCK_OBJECT.ClockSupportFlags
            0,                                          // HW_CLOCK_OBJECT.Reserved[0]
            0,                                          // HW_CLOCK_OBJECT.Reserved[1]
        },
        FALSE,                                          // Dma
        FALSE,                                          // Pio
        0,                                              // HwDeviceExtension
        sizeof(KS_FRAME_INFO),                          // StreamHeaderMediaSpecific
        0,                                              // StreamHeaderWorkspace 
        FALSE,                                          // Allocator 
        AVCTapeEventHandler,                            // HwEventRoutine
        0,                                              // Reserved[0]
        0,                                              // Reserved[1]
        },
    },

    // -----------------------------------------------------------------
    // Stream 1, DV coming from the camcorder (interleaved format)
    // -----------------------------------------------------------------
    {
        // HW_STREAM_INFORMATION -------------------------------------------
        {
        1,                                              // NumberOfPossibleInstances
        KSPIN_DATAFLOW_OUT,                             // DataFlow
        TRUE,                                           // DataAccessible
        NUM_DVCR_STREAM1_FORMATS,                       // NumberOfFormatArrayEntries
        DVCRStream1Formats,                             // StreamFormatsArrayf
        0,                                              // ClassReserved[0]
        0,                                              // ClassReserved[1]
        0,                                              // ClassReserved[2]
        0,                                              // ClassReserved[3]
        NUMBER_VIDEO_STREAM_PROPERTIES,                 // NumStreamPropArrayEntries
        (PKSPROPERTY_SET) VideoStreamProperties,        // StreamPropertiesArray
        NUMBER_STREAM_EVENTS_OUT_PIN,                   // NumStreamEventArrayEntries
        StreamEventsOutPin,                             // StreamEventsArray
        &guidPinCategoryCapture,                        // Category
        &guidPinNameDVAVOutput,                         // Name
        0,                                              // Mediums count
        &NULLMedium,                                    // Mediums
        FALSE,                                          // BridgeStream
        0,                                              // Reserved[0]
        0,                                              // Reserved[1]
        },

        // HW_STREAM_OBJECT ------------------------------------------------
        {
        sizeof(HW_STREAM_OBJECT),
        1,                                              // StreamNumber
        0,                                              // HwStreamExtension
        AVCTapeRcvDataPacket,                           // ReceiveDataPacket
        AVCTapeRcvControlPacket,                        // ReceiveControlPacket
        {
            (PHW_CLOCK_FUNCTION) AVCTapeStreamClockRtn, // HW_CLOCK_OBJECT.HWClockFunction
            CLOCK_SUPPORT_CAN_RETURN_STREAM_TIME,       // HW_CLOCK_OBJECT.ClockSupportFlags
            0,                                          // HW_CLOCK_OBJECT.Reserved[0]
            0,                                          // HW_CLOCK_OBJECT.Reserved[1]
        },
        FALSE,                                          // Dma
        FALSE,                                          // Pio
        0,                                              // HwDeviceExtension
        0,                                              // StreamHeaderMediaSpecific
        0,                                              // StreamHeaderWorkspace 
        FALSE,                                          // Allocator 
        AVCTapeEventHandler,                            // HwEventRoutine
        0,                                              // Reserved[0]
        0,                                              // Reserved[1]
        },    
    },
 

    // -----------------------------------------------------------------
    // Stream 2, DV flows out of the adapter (interleaved)
    // -----------------------------------------------------------------
    {
        // HW_STREAM_INFORMATION -------------------------------------------
        {
        1,                                              // NumberOfPossibleInstances
        KSPIN_DATAFLOW_IN,                              // DataFlow
        TRUE,                                           // DataAccessible
        NUM_DVCR_STREAM2_FORMATS,                       // NumberOfFormatArrayEntries
        DVCRStream2Formats,                             // StreamFormatsArray
        0,                                              // ClassReserved[0]
        0,                                              // ClassReserved[1]
        0,                                              // ClassReserved[2]
        0,                                              // ClassReserved[3]
        NUMBER_VIDEO_STREAM_PROPERTIES,                 // NumStreamPropArrayEntries
        (PKSPROPERTY_SET) VideoStreamProperties,        // StreamPropertiesArray
        NUMBER_STREAM_EVENTS_IN_PIN,                    // NumStreamEventArrayEntries
        StreamEventsInPin,                              // StreamEventsArray
        NULL,                                           // Category
        &guidPinNameDVAVInput,                          // Name
        0,                                              // Mediums count
        &NULLMedium,                                    // Mediums
        FALSE,                                          // BridgeStream
        0,                                              // Reserved[0]
        0,                                              // Reserved[1]
        },

        // HW_STREAM_OBJECT ------------------------------------------------
        {
        sizeof(HW_STREAM_OBJECT),
        2,                                              // StreamNumber
        0,                                              // HwStreamExtension
        AVCTapeRcvDataPacket,                           // ReceiveDataPacket
        AVCTapeRcvControlPacket,                        // ReceiveControlPacket
        {
            (PHW_CLOCK_FUNCTION) AVCTapeStreamClockRtn, // HW_CLOCK_OBJECT.HWClockFunction
            CLOCK_SUPPORT_CAN_RETURN_STREAM_TIME,       // HW_CLOCK_OBJECT.ClockSupportFlags
            0,                                          // HW_CLOCK_OBJECT.Reserved[0]
            0,                                          // HW_CLOCK_OBJECT.Reserved[1]
        },
        FALSE,                                          // Dma
        FALSE,                                          // Pio
        0,                                              // HwDeviceExtension
        0,                                              // StreamHeaderMediaSpecific
        0,                                              // StreamHeaderWorkspace 
        FALSE,                                          // Allocator 
        AVCTapeEventHandler,                            // HwEventRoutine
        0,                                              // Reserved[0]
        0,                                              // Reserved[1]
        }
    }
};

#define DV_STREAM_COUNT        (SIZEOF_ARRAY(DVStreams))




/**********************************************************************
 MPEG2TS data range
 **********************************************************************/

 
static GUID guidPinNameMPEG2TSOutput  = {STATIC_PINNAME_MPEG2TS_OUTPUT};
static GUID guidPinNameMPEG2TSInput   = {STATIC_PINNAME_MPEG2TS_INPUT};

//
// Default buffer setting for MPEG2TS
//

#define SRC_PACKETS_PER_MPEG2TS_FRAME   256 // Variable length

#define BUFFER_SIZE_MPEG2TS      (((CIP_DBS_MPEG << 2) * (1 << CIP_FN_MPEG) - 4) * SRC_PACKETS_PER_MPEG2TS_FRAME)
#define BUFFER_SIZE_MPEG2TS_SPH  (((CIP_DBS_MPEG << 2) * (1 << CIP_FN_MPEG)    ) * SRC_PACKETS_PER_MPEG2TS_FRAME)

#define NUM_OF_RCV_BUFFERS_MPEG2TS      MAX_DATA_BUFFERS
#define NUM_OF_XMT_BUFFERS_MPEG2TS      MAX_DATA_BUFFERS


// These values are from the "Blue book" Part 4 P. 9-10
// transmission rate:
//     Src Pkt/cycle
//         1/8       : 188/8 bytes * 8000 cycles * 8 bits/byte =  1,504,000 bits/sec 
//         ...
//         1/2       : 188/2 bytes * 8000 cycles * 8 bits/byte =  6,015,000 bits/sec 
//          1        : 188   bytes * 8000 cycles * 8 bits/byte = 12,032,000 bits/sec
//          5        : 188*5 bytes * 8000 cycles * 8 bits/byte = 60,160,000 bits/sec
//          


// this structure reuqires inclusion of "bdatypes.h" for MPEG2_TRANSPORT_STRIDE
typedef struct tagKS_DATARANGE_MPEG2TS_STRIDE_AVC {
   KSDATARANGE             DataRange;
   MPEG2_TRANSPORT_STRIDE  Stride;
   AVCPRECONNECTINFO       ConnectInfo;
} KS_DATARANGE_MPEG2TS_STRIDE_AVC, *PKS_DATARANGE_MPEG2TS_STRIDE_AVC;

KS_DATARANGE_MPEG2TS_STRIDE_AVC
MPEG2TStreamOutStride =      
{
    // KSDATARANGE
    {
#ifdef SUPPORT_NEW_AVC
     sizeof(KS_DATARANGE_MPEG2TS_STRIDE_AVC),                                 // FormatSize
#else
     sizeof(KS_DATARANGE_MPEG2TS_STRIDE_AVC) - sizeof(AVCPRECONNECTINFO),     // FormatSize; exclude AVCPRECONNECTINFO
#endif
     0,                                 // Flags
     BUFFER_SIZE_MPEG2TS_SPH,           // SampleSize with SPH:192*N
     0,                                 // Reserved
     STATIC_KSDATAFORMAT_TYPE_STREAM,
     STATIC_KSDATAFORMAT_TYPE_MPEG2_TRANSPORT_STRIDE, 
     // If there is a format block (like MPEG2_TRANSPORT_STRIDE), 
     // the specifier cannot use STATIC_KSDATAFORMAT_SPECIFIER_NONE or _WILDCARD    
     STATIC_KSDATAFORMAT_SPECIFIER_61883_4,  
    },
    // MPEG2_TRANSPORT_STRIDE 
    {
    MPEG2TS_STRIDE_OFFSET,     // 4
    MPEG2TS_STRIDE_PACKET_LEN, // 188
    MPEG2TS_STRIDE_STRIDE_LEN, // 192
    },
#ifdef SUPPORT_NEW_AVC
    // AVCPRECONNECTINFO
    {
     0,   // Device ID
     0,   // Subunit address
     0,   // Subunit Plug number
     0,   // Data Flow
     0,   // Flag/Plug handle
     0,   // UnitPlugNumber
    },
#endif
};

KS_DATARANGE_MPEG2TS_AVC
MPEG2TStreamOut =      
{
    // KSDATARANGE
    {
#ifdef SUPPORT_NEW_AVC
     sizeof(KS_DATARANGE_MPEG2TS_AVC),                                 // FormatSize
#else
     sizeof(KS_DATARANGE_MPEG2TS_AVC) - sizeof(AVCPRECONNECTINFO),     // FormatSize; exclude AVCPRECONNECTINFO
#endif
     0,                                 // Flags
     BUFFER_SIZE_MPEG2TS,               // SampleSize:188*N
     0,                                 // Reserved
     STATIC_KSDATAFORMAT_TYPE_STREAM,
     STATIC_KSDATAFORMAT_TYPE_MPEG2_TRANSPORT,
     STATIC_KSDATAFORMAT_SPECIFIER_NONE,
    },
#ifdef SUPPORT_NEW_AVC
    // AVCPRECONNECTINFO
    {
     0,   // Device ID
     0,   // Subunit address
     0,   // Subunit Plug number
     0,   // Data Flow
     0,   // Flag/Plug handle
     0,   // UnitPlugNumber
    },
#endif
};



KS_DATARANGE_MPEG2TS_STRIDE_AVC
MPEG2TStreamInStride =      
{
    // KSDATARANGE
    {
#ifdef SUPPORT_NEW_AVC
     sizeof(KS_DATARANGE_MPEG2TS_STRIDE_AVC),                                 // FormatSize
#else
     sizeof(KS_DATARANGE_MPEG2TS_STRIDE_AVC) - sizeof(AVCPRECONNECTINFO),     // FormatSize; exclude AVCPRECONNECTINFO
#endif
     0,                                 // Flags
     BUFFER_SIZE_MPEG2TS_SPH,           // SampleSize with SPH:192*N
     0,                                 // Reserved
     STATIC_KSDATAFORMAT_TYPE_STREAM,
     STATIC_KSDATAFORMAT_TYPE_MPEG2_TRANSPORT_STRIDE,
     // If there is a format block (like MPEG2_TRANSPORT_STRIDE), 
     // the specifier cannot use STATIC_KSDATAFORMAT_SPECIFIER_NONE or _WILDCARD 
     STATIC_KSDATAFORMAT_SPECIFIER_61883_4,
    },
    // MPEG2_TRANSPORT_STRIDE 
    {
    MPEG2TS_STRIDE_OFFSET,     // 4
    MPEG2TS_STRIDE_PACKET_LEN, // 188
    MPEG2TS_STRIDE_STRIDE_LEN, // 192
    },
#ifdef SUPPORT_NEW_AVC
    // AVCPRECONNECTINFO
    {
     0,   // Device ID
     0,   // Subunit address
     0,   // Subunit Plug number
     0,   // Data Flow
     0,   // Flag/Plug handle
     0,   // UnitPlugNumber
    },
#endif
};


PKSDATAFORMAT MPEG2TStream0Formats[] = 
{

    (PKSDATAFORMAT) &MPEG2TStreamOutStride,
    (PKSDATAFORMAT) &MPEG2TStreamOut,
};

#define NUM_MPEG_STREAM0_FORMATS  (SIZEOF_ARRAY(MPEG2TStream0Formats))

PKSDATAFORMAT MPEG2TStream1Formats[] = 
{
    (PKSDATAFORMAT) &MPEG2TStreamInStride,
};

#define NUM_MPEG_STREAM1_FORMATS  (SIZEOF_ARRAY(MPEG2TStream1Formats))


STREAM_INFO_AND_OBJ MPEGStreams [] = 
{
    // -----------------------------------------------------------------
    // Stream 0, MPEG2 TS coming from the AV device
    // -----------------------------------------------------------------
    {
        // HW_STREAM_INFORMATION -------------------------------------------        
        {
        1,                                      // NumberOfPossibleInstances
        KSPIN_DATAFLOW_OUT,                     // DataFlow
        TRUE,                                   // DataAccessible
        NUM_MPEG_STREAM0_FORMATS,               // NumberOfFormatArrayEntries
        MPEG2TStream0Formats,                   // StreamFormatsArray
        0,                                      // ClassReserved[0]
        0,                                      // ClassReserved[1]
        0,                                      // ClassReserved[2]
        0,                                      // ClassReserved[3]
        NUMBER_VIDEO_STREAM_PROPERTIES,         // NumStreamPropArrayEntries
        (PKSPROPERTY_SET) VideoStreamProperties, // StreamPropertiesArray
        0,                                      // NUMBER_STREAM_EVENTS,                           // NumStreamEventArrayEntries
        NULL,                                   // StreamEvents,
        &guidPinCategoryCapture,                // Category
        &guidPinNameMPEG2TSOutput,              // Name
        0,                                      // MediumsCount
        NULL,                                   // Mediums
        FALSE,                                  // BridgeStream
        0,
        0
        },


        // HW_STREAM_OBJECT ------------------------------------------------
        {
        sizeof(HW_STREAM_OBJECT),
        0,                                              // StreamNumber
        0,                                              // HwStreamExtension
        AVCTapeRcvDataPacket,                           // ReceiveDataPacket
        AVCTapeRcvControlPacket,                        // ReceiveControlPacket
        {
#if 0
            (PHW_CLOCK_FUNCTION) AVCTapeStreamClockRtn, // HW_CLOCK_OBJECT.HWClockFunction
            CLOCK_SUPPORT_CAN_RETURN_STREAM_TIME,       // HW_CLOCK_OBJECT.ClockSupportFlags
#else
            (PHW_CLOCK_FUNCTION) NULL,                  // HW_CLOCK_OBJECT.HWClockFunction
            0,                                          // HW_CLOCK_OBJECT.ClockSupportFlags
#endif
            0,                                          // HW_CLOCK_OBJECT.Reserved[0]
            0,                                          // HW_CLOCK_OBJECT.Reserved[1]
        },
        FALSE,                                          // Dma
        FALSE,                                          // Pio
        0,                                              // HwDeviceExtension
        0,                                              // StreamHeaderMediaSpecific
        0,                                              // StreamHeaderWorkspace 
        FALSE,                                          // Allocator 
        NULL,                                           // EventRoutine
        0,                                              // Reserved[0]
        0,                                              // Reserved[1]
        },
    },
    // -----------------------------------------------------------------
    // Stream 1, MPEG2 TS from adapter to the AV device
    // -----------------------------------------------------------------
    {
        // HW_STREAM_INFORMATION -------------------------------------------        
        {
        1,                                      // NumberOfPossibleInstances
        KSPIN_DATAFLOW_IN,                      // DataFlow
        TRUE,                                   // DataAccessible
        NUM_MPEG_STREAM1_FORMATS,               // NumberOfFormatArrayEntries
        MPEG2TStream1Formats,                   // StreamFormatsArray
        0,                                      // ClassReserved[0]
        0,                                      // ClassReserved[1]
        0,                                      // ClassReserved[2]
        0,                                      // ClassReserved[3]
        NUMBER_VIDEO_STREAM_PROPERTIES,         // NumStreamPropArrayEntries
        (PKSPROPERTY_SET) VideoStreamProperties, // StreamPropertiesArray
        NUMBER_STREAM_EVENTS_IN_PIN_MPEG2TS,    // NumStreamEventArrayEntries
        StreamEventsInPinMPEG2TS,               // StreamEventsArray
        &guidPinCategoryCapture,                // Category
        &guidPinNameMPEG2TSInput,               // Name
        0,                                      // MediumsCount
        NULL,                                   // Mediums
        FALSE,                                  // BridgeStream
        0,
        0
        },


        // HW_STREAM_OBJECT ------------------------------------------------
        {
        sizeof(HW_STREAM_OBJECT),
        1,                                              // StreamNumber
        0,                                              // HwStreamExtension
        AVCTapeRcvDataPacket,                           // ReceiveDataPacket
        AVCTapeRcvControlPacket,                        // ReceiveControlPacket
        {
#if 0
            (PHW_CLOCK_FUNCTION) AVCTapeStreamClockRtn, // HW_CLOCK_OBJECT.HWClockFunction
            CLOCK_SUPPORT_CAN_RETURN_STREAM_TIME,       // HW_CLOCK_OBJECT.ClockSupportFlags
#else
            (PHW_CLOCK_FUNCTION) NULL,                  // HW_CLOCK_OBJECT.HWClockFunction
            0,                                          // HW_CLOCK_OBJECT.ClockSupportFlags
#endif
            0,                                          // HW_CLOCK_OBJECT.Reserved[0]
            0,                                          // HW_CLOCK_OBJECT.Reserved[1]
        },
        FALSE,                                          // Dma
        FALSE,                                          // Pio
        0,                                              // HwDeviceExtension
        0,                                              // StreamHeaderMediaSpecific
        0,                                              // StreamHeaderWorkspace 
        FALSE,                                          // Allocator 
        NULL,                                           // EventRoutine
        0,                                              // Reserved[0]
        0,                                              // Reserved[1]
        },
    }
};


#define MPEG_STREAM_COUNT        (SIZEOF_ARRAY(MPEGStreams))



/**********************************************************************
 Supported AVC Stream format information table
 **********************************************************************/

#define BLOCK_PERIOD_MPEG2TS  192   // number of 1394 cycle offset to send one block

AVCSTRM_FORMAT_INFO AVCStrmFormatInfoTable[] = {
//
// SDDV_NTSC
//
    {
        sizeof(AVCSTRM_FORMAT_INFO),
        AVCSTRM_FORMAT_SDDV_NTSC,
        {
            0,0,
            CIP_DBS_SDDV,
            CIP_FN_DV,
            CIP_QPC_DV,
            CIP_SPH_DV,0,
            0
        },  // CIP header[0]
        { 
            0x2, 
            CIP_FMT_DV,
            CIP_60_FIELDS, 
            CIP_STYPE_DV, 0,
            0
        },  // CIP header[1]
        SRC_PACKETS_PER_NTSC_FRAME,
        FRAME_SIZE_SDDV_NTSC,
        NUM_OF_RCV_BUFFERS_DV,
        NUM_OF_XMT_BUFFERS_DV,
        FALSE,  // No source header
        FRAME_TIME_NTSC,
        BLOCK_PERIOD_2997,
        0,0,0,0,
    },
//
// SDDV_PAL
//
    { 
        sizeof(AVCSTRM_FORMAT_INFO),
        AVCSTRM_FORMAT_SDDV_PAL,
        {
            0,0,
            CIP_DBS_SDDV,
            CIP_FN_DV,
            CIP_QPC_DV,
            CIP_SPH_DV,0,
            0
        },  // CIP header[0]
        { 
            0x2, 
            CIP_FMT_DV,
            CIP_50_FIELDS, 
            CIP_STYPE_DV, 0,
            0
        },  // CIP header[1]
        SRC_PACKETS_PER_PAL_FRAME,
        FRAME_SIZE_SDDV_PAL, 
        NUM_OF_RCV_BUFFERS_DV,
        NUM_OF_XMT_BUFFERS_DV,
        FALSE,  // No source header
        FRAME_TIME_PAL,
        BLOCK_PERIOD_25,
        0,0,0,0,
    },
//
// MPEG2TS
//
    { 
        sizeof(AVCSTRM_FORMAT_INFO),
        AVCSTRM_FORMAT_MPEG2TS,
        {
            0,0,
            CIP_DBS_MPEG,
            CIP_FN_MPEG,
            CIP_QPC_MPEG,
            CIP_SPH_MPEG,0,
            0
        },  // CIP header[0]
        { 
            0x2, 
            CIP_FMT_MPEG,
            CIP_TSF_OFF,\
            0, 0,
            0
        },  // CIP header[1]
        SRC_PACKETS_PER_MPEG2TS_FRAME,  // Default
        BUFFER_SIZE_MPEG2TS_SPH,        // Default
        NUM_OF_RCV_BUFFERS_MPEG2TS,
        NUM_OF_XMT_BUFFERS_MPEG2TS,
        FALSE,  // Strip source packet header
        FRAME_TIME_NTSC,
        BLOCK_PERIOD_MPEG2TS,  
        0,0,0,0,
    },
//
// HDDV_NTSC
// ...

//
// HDDV_PAL
// ...

//
// SDLDV_NTSC
// ...

//
// SDLDV_PAL
// ...
};



#endif  // _DVSTRM_INC
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\drivers\wdm\capture\mini\tecra750\capdebug.h ===
//==========================================================================;
//
//  THIS CODE AND INFORMATION IS PROVIDED "AS IS" WITHOUT WARRANTY OF ANY
//  KIND, EITHER EXPRESSED OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE
//  IMPLIED WARRANTIES OF MERCHANTABILITY AND/OR FITNESS FOR A PARTICULAR
//  PURPOSE.
//
//  Copyright (c) 1992 - 1996  Microsoft Corporation.  All Rights Reserved.
//
//==========================================================================;


#ifndef __CAPDEBUG_H
#define __CAPDEBUG_H

#define TRAP   KdBreakPoint();

#endif // #ifndef __CAPDEBUG_H
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\drivers\wdm\capture\mini\tecra750\bert.c ===
//
//              TOSHIBA CORPORATION PROPRIETARY INFORMATION
//     This software is supplied under the terms of a license agreement or
//     nondisclosure agreement with TOSHIBA Corporation and may not be copied
//     or disclosed except in accordance with the terms of that agreement.
//           Copyright (c) 1997 TOSHIBA Corporation. All Rights Reserved.
//
//  Workfile: BERT.C
//
//  Purpose:
//
//  Contents:
//


#include "strmini.h"
#include "ksmedia.h"
#include "capmain.h"
#include "capdebug.h"
#include "bert.h"
#include "image.h"

#ifdef  TOSHIBA // '99-01-20 Added
extern  ULONG   CurrentOSType;
ULONG           ulConfigAddress;
#endif//TOSHIBA

//--------------------------------------------------------------------
//  ReadRegUlong
//--------------------------------------------------------------------

ULONG
ReadRegUlong(PHW_DEVICE_EXTENSION pHwDevExt, ULONG offset)
{
    PUCHAR  pBase = (PUCHAR)(pHwDevExt->ioBaseLocal);

#ifndef TOSHIBA
    if (!pHwDevExt->IsCardIn) return 0L;
#endif//TOSHIBA
    return *(PULONG)(pBase + offset);
}

//--------------------------------------------------------------------
//  WriteRegUlong
//--------------------------------------------------------------------

VOID
WriteRegUlong(PHW_DEVICE_EXTENSION pHwDevExt, ULONG offset, ULONG data)
{
    ULONG volatile *temp;
    PUCHAR  pBase = (PUCHAR)(pHwDevExt->ioBaseLocal);

#ifndef TOSHIBA
    if (!pHwDevExt->IsCardIn) return;
#endif//TOSHIBA
    temp = (PULONG)(pBase + offset);
    *temp = data;
}

//--------------------------------------------------------------------
//  ReadModifyWriteRegUlong
//--------------------------------------------------------------------

VOID
ReadModifyWriteRegUlong(PHW_DEVICE_EXTENSION pHwDevExt,
                                       ULONG offset,
                                       ULONG a_mask,
                                       ULONG o_mask)
{
    ULONG tdata;
    ULONG volatile *temp;
    PUCHAR  pBase = (PUCHAR)(pHwDevExt->ioBaseLocal);

#ifndef TOSHIBA
    if (!pHwDevExt->IsCardIn) return;
#endif//TOSHIBA
    temp = (PULONG)(pBase + offset);
    tdata = *temp;
    tdata = (tdata & a_mask) | o_mask;
    *temp = tdata;
}

BOOL
BertIsCardIn(
  IN PHW_DEVICE_EXTENSION pHwDevExt
)
{
    DWORD value;
    value = ReadRegUlong(pHwDevExt, BERT_CAPSTAT_REG);
    if ((value == 0) || (value == 0xffffffff))
        return FALSE;
    else
        return TRUE;
}


//--------------------------------------------------------------------
//  BertInterruptEnable
//--------------------------------------------------------------------

VOID
BertInterruptEnable(
  IN PHW_DEVICE_EXTENSION pHwDevExt,
  IN BOOL bStatus
)
{
    WriteRegUlong(pHwDevExt, BERT_INTRST_REG , 0xFFFF);

    if (!bStatus)
    {
        ReadModifyWriteRegUlong(pHwDevExt, BERT_INTSTAT_REG, (ULONG)~ACTIVE_CAPTURE_IRQS, 0);
    }
    else
    {
        ReadModifyWriteRegUlong(pHwDevExt, BERT_INTSTAT_REG, ~0UL, (ULONG)ACTIVE_CAPTURE_IRQS);
    }
}

//--------------------------------------------------------------------
//  BertDMAEnable
//--------------------------------------------------------------------

VOID
BertDMAEnable(
  IN PHW_DEVICE_EXTENSION pHwDevExt,
  IN BOOL bStatus
)
{
    DWORD   dwAddr;

    if (bStatus)    // Turn On Video Transfer.
    {
        dwAddr = (DWORD)pHwDevExt->pPhysRpsDMABuf.LowPart;
#if 0
        dwAddr = (dwAddr + 0x1FFF) & 0xFFFFE000;
#endif
        WriteRegUlong(pHwDevExt, BERT_RPSADR_REG, dwAddr);
        WriteRegUlong(pHwDevExt, BERT_RPSPAGE_REG, dwAddr);
        BertVsncSignalWait(pHwDevExt);
        // Let the RPS turn on/off EBMV
        WriteRegUlong(pHwDevExt, BERT_CAPSTAT_REG, (ERPS | CKRE | CKMD)); // mod passive_enable -> ERPS 97-03-15(Sat) Mod 97-05-08(Thu)
    }
    else    // Turn Off Video Transfer.
    {
        if (ReadRegUlong(pHwDevExt, BERT_CAPSTAT_REG) & ERPS)
        {
            ReadModifyWriteRegUlong(pHwDevExt, BERT_CAPSTAT_REG, (ULONG)~ERPS, 0UL);
        }

        if (!BertIsCAPSTATReady(pHwDevExt))
        {
            ReadModifyWriteRegUlong(pHwDevExt, BERT_CAPSTAT_REG, (ULONG)~EBMV, 0UL);
        }

        if (ReadRegUlong(pHwDevExt, BERT_CAPSTAT_REG) & RPSS)
        {
            pHwDevExt->NeedHWInit = TRUE;
        }
    }
}

//--------------------------------------------------------------------
//  BertIsLocked
//--------------------------------------------------------------------

BOOL
BertIsLocked(
  IN PHW_DEVICE_EXTENSION pHwDevExt
)
/*++

Routine Description :

    Check if the decoder has been locked or not.

Arguments :

    pDevInfo - Device Info for the driver

Return Value :

    TRUE - configuration success

--*/
{
    return ((ReadRegUlong(pHwDevExt, BERT_CAPSTAT_REG) & LOCK) != 0);
}

//--------------------------------------------------------------------
//  BertFifoConfig
//--------------------------------------------------------------------

BOOL
BertFifoConfig(
  IN PHW_DEVICE_EXTENSION pHwDevExt,
  IN ULONG ulFormat
)
/*++

Routine Description :

    Configure the BERT fifo for the format choosen.

Arguments :

    pDevInfo - Device Info for the driver
    dwFormat - format index as defined in wally.h

Return Value :

    TRUE - configuration success

--*/
{
    DWORD dwFifo;

    switch (ulFormat)
    {
        case FmtYUV12:
                dwFifo = 0xe;
                break;
        case FmtYUV9:
                dwFifo = 0xd;
                break;
        default:
                return FALSE;
    }

    dwFifo=(dwFifo<<24)| 0x100000l;     // Modify 97-04-02

    WriteRegUlong(pHwDevExt, BERT_FIFOCFG_REG, dwFifo);
    WriteRegUlong(pHwDevExt, BERT_BURST_LEN, 0x00000002);
    // DATA=8 DWORD, RPS=2DWORD
    WriteRegUlong(pHwDevExt, BERT_YSTRIDE_REG, pHwDevExt->Ystride);
    WriteRegUlong(pHwDevExt, BERT_USTRIDE_REG, pHwDevExt->Ustride);
    WriteRegUlong(pHwDevExt, BERT_VSTRIDE_REG, pHwDevExt->Vstride);
    return TRUE;
}

//--------------------------------------------------------------------
//  BertInitializeHardware
//--------------------------------------------------------------------

BOOL
BertInitializeHardware(
  IN PHW_DEVICE_EXTENSION pHwDevExt
)
/*++

Routine Description :

    This function initializes the bert asic to the default values.

Arguments :

    pDevInfo - Device Info for the driver
    pHw - pointer to hardware info data structure

Return Value :

    TRUE - initialization success

--*/
{
    WriteRegUlong(pHwDevExt, BERT_CAPSTAT_REG, (CAMARA_OFF | CKRE | CKMD));      // Mod 97-05-08(Thu)
    return TRUE;
}


//--------------------------------------------------------------------
//  BertEnableRps
//--------------------------------------------------------------------

VOID
BertEnableRps(
  IN PHW_DEVICE_EXTENSION pHwDevExt
)
/*++

Routine Description :

    enable the rps execution by setting ERPS and EROO bits
    in the CAPSTAT reg

Arguments :

    pDevInfo - Device Info for the driver

Return Value :

    None

--*/
{
    ReadModifyWriteRegUlong(pHwDevExt, BERT_CAPSTAT_REG, 0xf0ffffff, 0x08000000); // MOD 97-03-17(Mon)
}

//--------------------------------------------------------------------
//  BertDisableRps
//--------------------------------------------------------------------

VOID
BertDisableRps(
  IN PHW_DEVICE_EXTENSION pHwDevExt
)
/*++

Routine Description :

    disable the rps execution by reseting the ERPS bit
    in the CAPSTAT reg

Arguments :

    pDevInfo - Device Info for the driver

Return Value :

    None

--*/
{
    ReadModifyWriteRegUlong(pHwDevExt, BERT_CAPSTAT_REG, (ULONG)~ERPS, 0L);
}


BOOL
BertIsCAPSTATReady(PHW_DEVICE_EXTENSION pHwDevExt)
{
    LARGE_INTEGER CurrentTime;
    LARGE_INTEGER StartTime;

    KeQuerySystemTime( &StartTime );
    // Wait until EBMV is cleared by the RPS
    while (ReadRegUlong(pHwDevExt, BERT_CAPSTAT_REG) & EBMV)
    {
        KeQuerySystemTime( &CurrentTime );
        if ((CurrentTime.QuadPart - StartTime.QuadPart) > EBMV_TIMEOUT)
        {
            return FALSE;
        }
    }
    return TRUE;
}

VOID
BertVsncSignalWait(PHW_DEVICE_EXTENSION pHwDevExt)
{
    ULONG ulCount;

    // Wait until VSNC is low
    for (ulCount = 0; ulCount < 500; ulCount++ )
    {
        if (!(ReadRegUlong(pHwDevExt, BERT_VINSTAT_REG) & VSNC)) break;
        VC_Delay(2);
    }
}

VOID
BertDMARestart(
  IN PHW_DEVICE_EXTENSION pHwDevExt
)
{
    DWORD   dwAddr;

    dwAddr = (DWORD)pHwDevExt->pPhysRpsDMABuf.LowPart;
#if 0
    dwAddr = (dwAddr + 0x1FFF) & 0xFFFFE000;
#endif
    WriteRegUlong(pHwDevExt, BERT_RPSADR_REG, dwAddr);
    WriteRegUlong(pHwDevExt, BERT_RPSPAGE_REG, dwAddr);
    WriteRegUlong(pHwDevExt, BERT_CAPSTAT_REG, (ERPS | CKRE | CKMD));
}


void
ActiveField(
  IN PHW_DEVICE_EXTENSION pHwDevExt,
  IN DWORD *addr,
  IN DWORD *PhysAddr,   /* Insert BUN 97-03-25(Tue) */
  IN DWORD bNoCopy,
  IN DWORD *y_DMA_addr,
  IN DWORD *v_DMA_addr,
  IN DWORD *u_DMA_addr,
  IN DWORD *nextRPSaddr,
  IN DWORD *readRegAddr,
  IN BOOL genIRQ /* = FALSE */,
  IN DWORD fieldsToCapture /* = CAPTURE_BOTH */ )
{
    // Set DmaActive flag right away since this is the indicator register for whether DMA is pending.
    // If the DmaActive flag is zero, it is safe to copy the DMA frame buffer.  The YPTR register is
    // used as a scratch register to be read into the DmaActive flag.

    *addr++ = RPS_CONTINUE_CMD | BERT_YPTR_REG;
    *addr++ = (DWORD)y_DMA_addr;                            // Address of y DMA buffer.

    *addr++ = RPS_CONTINUE_CMD | ((genIRQ) ? RPS_INT_CMD : 0) | BERT_RPSPAGE_REG;
    *addr++ = (pHwDevExt->s_physDmaActiveFlag-0x1860);      // Page s_DmaActiveFlag is on mod BUN

    *addr++ = RPS_CONTINUE_CMD | BERT_VPTR_REG;
    *addr++ = (DWORD)v_DMA_addr;                            // Address of v DMA buffer.

    *addr++ = RPS_CONTINUE_CMD | BERT_UPTR_REG;
    *addr++ = (DWORD)u_DMA_addr;                            // Address of u DMA buffer.

    *addr++ = BERT_CAPSTAT_REG;                             // LAST RPS command this VSYNC
    *addr++ = fieldsToCapture;                              // Switch on bus master bit.

    *addr++ = RPS_CONTINUE_CMD | BERT_RPSADR_REG;
    *addr   = (DWORD)nextRPSaddr;                           // Address of next RPS.
}

//
// SKIP_FIELD_RPS is the size of a RPS node that skips a field.
// Skip frame is programmed as follows:
//      DWORD                                   -- RPS command register
//      DWORD                                   -- Value of register programming.
//---------------- Actual RPS for Skip Frame ------------------------
// RPS_CONTINUE_CMD | CAPSTAT   - RPS, read next RPS, select CAPSTAT
//  ERPS | EROO | GO0           - Enable RPS & Power to camara (off bus master)
// INTSTAT                                      - Don't continue & select INITSTAT register.
// m_passive_cap_IRQs           - Don't interrupt end of field.
// RPS_CONTINUE_CMD | RPSADDR   - Set up address
// Address field                        - Program at init for next field.
//-------------------------------------------------------------------
//
VOID
SkipField(
  IN PHW_DEVICE_EXTENSION pHwDevExt,
  IN DWORD *addr,
  IN DWORD *PhysAddr,   /* Insert BUN 97-03-25(Tue) */
  IN DWORD *nextRPSaddr,
  IN DWORD *readRegAddr,
  IN BOOL genIRQ /* = FALSE */,
  IN DWORD fieldToSkip /* = SKIP_BOTH */ )
{
    // Set YPTR right away since this is the indicator register for whether DMA is pending.
    // If DmaActive flag is zero, it is safe to copy the DMA frame buffer.

    *addr++ = RPS_CONTINUE_CMD | BERT_YPTR_REG;
    *addr++ = (DWORD)PhysAddr;

    *addr++ = RPS_CONTINUE_CMD | ((genIRQ) ? RPS_INT_CMD : 0) | BERT_RPSPAGE_REG;
    *addr++ = (pHwDevExt->s_physDmaActiveFlag-0x1860);      // Page s_physDmaActiveFlag is on MOD bun

    *addr++ = BERT_CAPSTAT_REG;  /* mod BUN 97-04-16(Wed) */
    *addr++ = fieldToSkip;                                  // Switch off bus master bit.
    *addr++ = RPS_CONTINUE_CMD | BERT_RPSADR_REG;
    *addr   = (DWORD)nextRPSaddr;                           // Address of next RPS.
}


BOOL
BertBuildNodes(
  IN PHW_DEVICE_EXTENSION pHwDevExt
)
{
    DWORD*          addr;
    DWORD*          physAddr;
    DWORD*          physBase;
    ULONG           ulTemp;
    unsigned        framesPerSecond;
    unsigned        f;
    unsigned        max_rps;
    BOOL            lastOneActive = FALSE;

    framesPerSecond = pHwDevExt->uiFramePerSecond;
    max_rps = DEF_RPS_FRAMES;

    ulTemp = (ULONG)pHwDevExt->pRpsDMABuf;
#if 0
    ulTemp = (ulTemp + 0x1FFF) & 0xFFFFE000;
#endif
    addr   = (DWORD *)ulTemp;
    ulTemp = (ULONG)pHwDevExt->pPhysRpsDMABuf.LowPart;
#if 0
    ulTemp = (ulTemp + 0x1FFF) & 0xFFFFE000;
#endif
    physAddr = (DWORD *)ulTemp;
    physBase = physAddr;

    if (addr == NULL) return FALSE;

    // Build an RPS per frame.
    // Building 2 nodes per iteration when capturing both fields, so always
    // go thru only DEF_RPS_FRAMES iterations.

    for (f = max_rps ; f >= 1 ; f-- )
    {
        if (((framesPerSecond * f) % DEF_RPS_FRAMES) < framesPerSecond)
        {
            ActiveField(pHwDevExt,addr,(DWORD *)0,
                        TRUE,       // No buffer copying during the processing of this node
                        (DWORD *)((BYTE *)pHwDevExt->pPhysCaptureBufferY.LowPart + pHwDevExt->YoffsetOdd),    // Position Y data.
                        (DWORD *)((BYTE *)pHwDevExt->pPhysCaptureBufferV.LowPart + pHwDevExt->VoffsetOdd),    // Position V data.
                        (DWORD *)((BYTE *)pHwDevExt->pPhysCaptureBufferU.LowPart + pHwDevExt->UoffsetOdd),    // Position U data.
                        ((f == 1 )
                            ? physBase
                            : physAddr + 0x1A),
                        physAddr + 0x19,    // Put the read value at the end of the list.
                        lastOneActive,
                        (CAPTURE_ODD | CKRE | CKMD));       // Mod 97-05-08(Thu)
            lastOneActive = TRUE;
        }
        else
        {
            // Don't generate interrupts for skipped frames
            SkipField(pHwDevExt,addr,
                      (DWORD *)((BYTE *)pHwDevExt->pPhysCapBuf2Y.LowPart + pHwDevExt->YoffsetOdd),
                      ((f == 1 )
                          ? physBase
                          : physAddr + 0x1A),
                      physAddr + 0x19,    // Put the read value at the end of the list.
                      lastOneActive,
                      (SKIP_ODD | CKRE | CKMD));  // Mod 97-05-08(Thu)

            lastOneActive = FALSE;
        }
        addr += 0x1A;
        physAddr += 0x1A;
    }
    return TRUE;
}

BOOL
BertTriBuildNodes(
  IN PHW_DEVICE_EXTENSION pHwDevExt
)
{
    DWORD*          addr;
    DWORD*          physAddr;
    DWORD*          physBase;
    ULONG           ulTemp;
    unsigned        framesPerSecond;
    unsigned        f;
    unsigned        max_rps;
    BOOL            lastOneActive = FALSE;
    DWORD*          CapphysAddrY;
    DWORD*          CapphysAddrV;
    DWORD*          CapphysAddrU;

    framesPerSecond = pHwDevExt->uiFramePerSecond;
    max_rps = DEF_RPS_FRAMES;

    ulTemp      = (ULONG)pHwDevExt->pRpsDMABuf;
#if 0
    ulTemp      = (ulTemp + 0x1FFF) & 0xFFFFE000;
#endif
    addr        = (DWORD *)ulTemp;
    ulTemp      = (ULONG)pHwDevExt->pPhysRpsDMABuf.LowPart;
#if 0
    ulTemp      = (ulTemp + 0x1FFF) & 0xFFFFE000;
#endif
    physAddr    = (DWORD *)ulTemp;
    physBase    = physAddr;

    if (addr == NULL) return FALSE;

    // Build an RPS per frame.
    // Building 2 nodes per iteration when capturing both fields, so always
    // go thru only DEF_RPS_FRAMES iterations.

    lastOneActive = ( ((framesPerSecond*1)%DEF_RPS_FRAMES) < framesPerSecond ) ? TRUE : FALSE ;

    for (f = max_rps ; f >= 1 ; f-- )
    {
        if( f%2 ){
            CapphysAddrY=(DWORD *)pHwDevExt->pPhysCapBuf2Y.LowPart;
            CapphysAddrV=(DWORD *)pHwDevExt->pPhysCapBuf2V.LowPart;
            CapphysAddrU=(DWORD *)pHwDevExt->pPhysCapBuf2U.LowPart;
        }
        else{
            CapphysAddrY=(DWORD *)pHwDevExt->pPhysCaptureBufferY.LowPart;
            CapphysAddrV=(DWORD *)pHwDevExt->pPhysCaptureBufferV.LowPart;
            CapphysAddrU=(DWORD *)pHwDevExt->pPhysCaptureBufferU.LowPart;
        }

        if (((framesPerSecond * f) % DEF_RPS_FRAMES) < framesPerSecond)
        {
            ActiveField(pHwDevExt,addr,(DWORD *)0,
                        TRUE,       // No buffer copying during the processing of this node
                        (DWORD *)((BYTE *)CapphysAddrY + pHwDevExt->YoffsetOdd),   // Position Y data.
                        (DWORD *)((BYTE *)CapphysAddrV + pHwDevExt->VoffsetOdd),   // Position V data.
                        (DWORD *)((BYTE *)CapphysAddrU + pHwDevExt->UoffsetOdd),   // Position U data.
                        ((f == 1 )
                            ? physBase
                            : physAddr + 0x1A),
                        physAddr + 0x19,    // Put the read value at the end of the list.
                        lastOneActive,
                        (CAPTURE_ODD | CKRE | CKMD));       // Mod 97-05-08(Thu)

            lastOneActive = TRUE;
        }
        else
        {
            // Don't generate interrupts for skipped frames
            SkipField(pHwDevExt,addr,(DWORD *)((BYTE *)CapphysAddrY + pHwDevExt->YoffsetOdd),
                      ((f == 1 )
                          ? physBase
                          : physAddr + 0x1A),
                      physAddr + 0x19,    // Put the read value at the end of the list.
                      lastOneActive,
                      (SKIP_ODD | CKRE | CKMD));  // Mod 97-05-08(Thu)

            lastOneActive = FALSE;
        }
        addr += 0x1A;
        physAddr += 0x1A;
    }
    return TRUE;
}


//--------------------------------------------------------------------
//  BertSetDMCHE
//--------------------------------------------------------------------

VOID
BertSetDMCHE(IN PHW_DEVICE_EXTENSION pHwDevExt)
{
    switch(pHwDevExt->dwAsicRev){
        case 0:         // Pistachio #1
        case 1:         // Pistachio #2
        case 2:         // Pistachio #3
            WriteRegUlong(pHwDevExt, BERT_P_SUP3_REG, 0x00);
            break;
        default:        // Pistachio #4~
            WriteRegUlong(pHwDevExt, BERT_P_SUP3_REG, 0x0100);
            break;
    }
}

VOID
HW_ApmResume(PHW_DEVICE_EXTENSION pHwDevExt)
{
    BertSetDMCHE(pHwDevExt);
    CameraChkandON(pHwDevExt, MODE_VFW);
    BertInitializeHardware(pHwDevExt);
    pHwDevExt->NeedHWInit = TRUE;
    pHwDevExt->IsRPSReady = FALSE;
}

VOID
HW_ApmSuspend(PHW_DEVICE_EXTENSION pHwDevExt)
{
    BertInterruptEnable(pHwDevExt, FALSE);
    BertDMAEnable(pHwDevExt, FALSE);
    pHwDevExt->bRequestDpc = FALSE;
    CameraChkandOFF(pHwDevExt, MODE_VFW);
}

VOID
HW_SetFilter(PHW_DEVICE_EXTENSION pHwDevExt, BOOL bFlag)
{
    if( bFlag )
    {
        ImageFilterON(pHwDevExt);
    }
    else
    {
        ImageFilterOFF(pHwDevExt);
    }
}

ULONG
HW_ReadFilter(PHW_DEVICE_EXTENSION pHwDevExt, BOOL bFlag)
{
    ULONG ulRet;

    if( bFlag )
    {
        ulRet = ImageGetFilteringAvailable(pHwDevExt);
    }
    else
    {
        ulRet = ImageGetFilterInfo(pHwDevExt);
    }
    return ulRet;
}

BOOL
HWInit(PHW_DEVICE_EXTENSION pHwDevExt)
{
    if (pHwDevExt->NeedHWInit == FALSE) return TRUE;

    // reset hardware to power up state
    if ( !BertInitializeHardware(pHwDevExt) )        // MOD 97-03-31(Fri)
    {
        return FALSE;
    }
    else
    {
        pHwDevExt->NeedHWInit = FALSE;
    }
    return TRUE;
}

#ifdef  TOSHIBA // '99-01-20 Added
//--------------------------------------------------------------------
//  InitConfigAddress
//--------------------------------------------------------------------
VOID
InitConfigAddress( PHW_DEVICE_EXTENSION pHwDevExt )
{
    ULONG OldPort;
    ULONG Id;
    ULONG Data;
    ULONG i, j;

    ulConfigAddress = 0xFFFFFFFF;
#ifdef  TOSHIBA // '99-02-05 Modified
    return;
#else //TOSHIBA
    if ( CurrentOSType ) return;    // NT5.0

    if ( !StreamClassReadWriteConfig(
                    pHwDevExt,
                    TRUE,           // indicates a READ
                    (PVOID)&Id,
                    0,              // this is the offset into the PCI space
                    4               // this is the # of bytes to read.
            )) {
        return;
    }
    if ( Id == 0 || Id == 0xFFFFFFFF ) return;

    OldPort = READ_PORT_ULONG( (PULONG)0xCF8 );
    for ( i = 0 ; i < 256; i++ ) {   // PCI_MAX_BRIDGE_NUMBER
        for ( j = 0 ; j < 32; j++ ) {// PCI_MAX_DEVICE
            WRITE_PORT_ULONG( (PULONG)0xCF8, (i << 16) | (j << 11) | 0x80000000 );
            Data = READ_PORT_ULONG( (PULONG)0xCFC );
            if ( Data == Id ) {
                ulConfigAddress = (i << 16) | (j << 11) | 0x80000000;
                break;
            }
        }
        if ( Data == Id ) break;
    }
    WRITE_PORT_ULONG( (PULONG)0xCF8, OldPort );
#endif//TOSHIBA
}
#endif//TOSHIBA

//--------------------------------------------------------------------
//  InitializeConfigDefaults
//--------------------------------------------------------------------

VOID
InitializeConfigDefaults(PHW_DEVICE_EXTENSION pHwDevExt)
{
    ULONG ImageSize;

#ifdef  TOSHIBA // '99-01-20 Added
    InitConfigAddress( pHwDevExt );
#endif//TOSHIBA

#ifndef TOSHIBA
    pHwDevExt->VideoStd = NTSC;
#endif//TOSHIBA
    pHwDevExt->Format = FmtYUV9;
    pHwDevExt->ulWidth = 320;
    pHwDevExt->ulHeight = 240;
    pHwDevExt->MaxRect.right = NTSC_MAX_PIXELS_PER_LINE;
    pHwDevExt->MaxRect.bottom = NTSC_MAX_LINES_PER_FIELD * 2; // Mod 97-04-08(Tue)
    pHwDevExt->SrcRect = pHwDevExt->MaxRect;

#ifdef  TOSHIBA
    pHwDevExt->Hue = 0x80;
    pHwDevExt->Contrast = 0x80;
    pHwDevExt->Brightness = 0x80;
    pHwDevExt->Saturation = 0x80;

    ImageSetChangeColorAvail(pHwDevExt, IMAGE_CHGCOL_AVAIL);
#else //TOSHIBA
    pHwDevExt->ulHue = 0x80;
    pHwDevExt->ulContrast = 0x80;
    pHwDevExt->ulBrightness = 0x80;
    pHwDevExt->ulSaturation = 0x80;

    ImageSetChangeColorAvail(pHwDevExt, IMAGE_CHGCOL_NOTAVAIL);
#endif//TOSHIBA
}

BOOL SetupPCILT( PHW_DEVICE_EXTENSION pHwDevExt )
{
    BYTE   byte_buffer;
    ULONG  ulCommand;

#define PCI_LTIME_OFFSET        0x0d    /* offset of Latency timer from PCI base */
#define PCI_CACHELINE_OFFSET    0x0c    /* offset of cache line size from PCI base */
#define PCI_STATUSorCOMMAND     0x04    /* offset of Pistachio Status and Command regster */


        byte_buffer = 255;
        VC_SetPCIRegister(pHwDevExt,
                          PCI_LTIME_OFFSET,
                          &byte_buffer,
                          0x01);

        byte_buffer=(BYTE) 0;
        VC_SetPCIRegister(pHwDevExt,
                          PCI_CACHELINE_OFFSET,
                          &byte_buffer,
                          0x01);

        ulCommand = 0x02000006;
        VC_SetPCIRegister(pHwDevExt,
                          PCI_STATUSorCOMMAND,
                          &ulCommand,
                          0x04);

        ulCommand = IGNORE100msec ; // Set ignore time for chattering
        VC_SetPCIRegister(pHwDevExt,
                          PCI_Wake_Up,
                          &ulCommand,
                          0x04);

        return TRUE;
}


BOOL CameraChkandON( PHW_DEVICE_EXTENSION pHwDevExt, ULONG ulMode )
{

        ULONG  dd_buffer;

        if (!VC_GetPCIRegister(pHwDevExt,
                               PCI_Wake_Up,
                               &dd_buffer,
                               0x04) )
        {
            return FALSE;
        }

        if( (dd_buffer&0x10000l) == 0)
        {
            return TRUE;
        }

        dd_buffer = IGNORE100msec | 0x101l; // Set Wake Up enable
        if (!VC_SetPCIRegister(pHwDevExt,
                               PCI_Wake_Up,
                               &dd_buffer,
                               0x04) )
        {
            return FALSE;
        }

        switch(ulMode){
                case MODE_VFW:
                        dd_buffer = CAVCE_CFGPAT | CADTE_CFGPAT | PXCCE_CFGPAT | PXCSE_CFGPAT
                                | PCIFE_CFGPAT | PCIME_CFGPAT | PCIDS_CFGPAT | GPB_CFGPAT;      // Mod 97-05-06(Tue)
                        break;
                case MODE_ZV:
                        dd_buffer = CAVCE_CFGPAT | CADTE_CFGPAT | PXCCE_CFGPAT | PCIFE_CFGPAT
                                | PCIME_CFGPAT | PCIDS_CFGPAT | GPB_CFGPAT;                                     // Add 97-05-06(Tue)
                        break;
        }

        // Power ON to camera.
        if (!VC_SetPCIRegister(pHwDevExt,
                               PCI_DATA_PATH,
                               &dd_buffer,
                               0x04) )
        {
            return FALSE;
        }

        return TRUE;
}


BOOL CameraChkandOFF( PHW_DEVICE_EXTENSION pHwDevExt, ULONG ulMode )
{
        DWORD   dwBuffer;
        DWORD   dwSystemWait;   // Add 97-05-06(Tue)

        switch(ulMode){
                case MODE_VFW:
                        break;
                case MODE_ZV:
                        SetZVControl(pHwDevExt, ZV_DISABLE);
                        break;
        }

        dwBuffer = GPB_CFGPAT;  // Camera Power Off

        if (!VC_SetPCIRegister(pHwDevExt,
                               PCI_CFGPAT,
                               &dwBuffer,
                               0x04) )
        {
            return FALSE;
        }

        return TRUE;
}


BOOL CheckCameraStatus(PHW_DEVICE_EXTENSION pHwDevExt)    // Add 97-05-06(Tue)
{
        DWORD   dwBuffer;
        BOOL    crStatus;

        if (!VC_GetPCIRegister(pHwDevExt,
                               PCI_CFGPAT,
                               &dwBuffer,
                               0x04) )
        {
            return FALSE;
        }

        if(dwBuffer & CAVCE_CFGPAT){
                crStatus = TRUE;
        }
        else{
                crStatus = FALSE;
        }

        return crStatus;
}


BOOL SetZVControl(PHW_DEVICE_EXTENSION pHwDevExt, ULONG ulZVStatus) // Add 97-05-02(Fri)
{
        DWORD   dwBuffer, dwBuffer2;
        BOOL    crStatus = TRUE;

        if (!VC_GetPCIRegister(pHwDevExt,
                               PCI_CFGPAT,
                               &dwBuffer,
                               0x04) )
        {
            return FALSE;
        }

        if (!VC_GetPCIRegister(pHwDevExt,
                               PCI_CFGWAK,
                               &dwBuffer2,
                               0x04) )
        {
            return FALSE;
        }

        if(!(dwBuffer2 & CASL_CFGWAK))  // Camera Not Connect
        {
            return FALSE;
        }

        switch(ulZVStatus){
                case ZV_ENABLE:
                        if(!(dwBuffer & CAVCE_CFGPAT)){         // Check CAVCE Status
                                crStatus = CameraChkandON(pHwDevExt, MODE_ZV);
                                if(!crStatus){
                                        return FALSE;
                                }
                        }
                case ZV_DISABLE:
                        dwBuffer = (dwBuffer & 0xfffffffe) | ulZVStatus;
                        if (!VC_SetPCIRegister(pHwDevExt,
                                               PCI_CFGPAT,
                                               &dwBuffer,
                                               0x04) )
                        {
                                return FALSE;
                        }
                        crStatus = TRUE;
                        break;
                case ZV_GETSTATUS:
                        if(dwBuffer & ZV_ENABLE){
                                crStatus = TRUE;
                        }
                        else{
                                crStatus = FALSE;
                        }
                        break;
        }

        return crStatus;
}


BOOL SetASICRev(PHW_DEVICE_EXTENSION pHwDevExt)   // Add 97-05-12(Mon)
{
    DWORD   dwBuffer;
    DWORD   dwAsicRev;

        if (!VC_GetPCIRegister(pHwDevExt,
                               PCI_CFGCCR,
                               &dwBuffer,
                               0x04) )
        {
                return FALSE;
        }

        dwAsicRev = dwBuffer & 0x0f;

        pHwDevExt->dwAsicRev = dwAsicRev;

        return TRUE;
}

BOOL
Alloc_TriBuffer(PHW_DEVICE_EXTENSION pHwDevExt)
{
    ULONG            ulSize;
    PUCHAR           puTemp;

    ulSize = pHwDevExt->BufferSize;
    puTemp = (PUCHAR)pHwDevExt->pCaptureBufferY;
    pHwDevExt->pCapBuf2Y = puTemp + ulSize;
    puTemp = (PUCHAR)pHwDevExt->pCaptureBufferU;
    pHwDevExt->pCapBuf2U = puTemp + ulSize;
    puTemp = (PUCHAR)pHwDevExt->pCaptureBufferV;
    pHwDevExt->pCapBuf2V = puTemp + ulSize;
    pHwDevExt->pPhysCapBuf2Y.LowPart = pHwDevExt->pPhysCaptureBufferY.LowPart + ulSize;
    pHwDevExt->pPhysCapBuf2U.LowPart = pHwDevExt->pPhysCaptureBufferU.LowPart + ulSize;
    pHwDevExt->pPhysCapBuf2V.LowPart = pHwDevExt->pPhysCaptureBufferV.LowPart + ulSize;
    return TRUE;
}

BOOL
Free_TriBuffer(PHW_DEVICE_EXTENSION pHwDevExt)
{
    pHwDevExt->pCapBuf2Y = NULL;
    pHwDevExt->pCapBuf2U = NULL;
    pHwDevExt->pCapBuf2V = NULL;
    pHwDevExt->pPhysCapBuf2Y.LowPart = 0;
    pHwDevExt->pPhysCapBuf2U.LowPart = 0;
    pHwDevExt->pPhysCapBuf2V.LowPart = 0;
    return TRUE;
}


BOOL
VC_GetPCIRegister(
    PHW_DEVICE_EXTENSION pHwDevExt,
    ULONG ulOffset,
    PVOID pData,
    ULONG ulLength)
{
#ifdef  TOSHIBA // '99-01-20 Added
    if( ulConfigAddress != 0xFFFFFFFF ) {
        ULONG OldPort;
        ULONG DataPort;

        OldPort = READ_PORT_ULONG( (PULONG)0xCF8 );
        WRITE_PORT_ULONG( (PULONG)0xCF8, ( ulConfigAddress | ulOffset) & 0xFFFFFFFC );
        DataPort = 0xCFC + (ulOffset % 4);
        switch ( ulLength ) {
            case 1:
                *((PUCHAR)pData) = READ_PORT_UCHAR( (PUCHAR)DataPort );
                break;
            case 2:
                *((PUSHORT)pData) = READ_PORT_USHORT( (PUSHORT)DataPort );
                break;
            case 4:
                *((PULONG)pData) = READ_PORT_ULONG( (PULONG)DataPort );
                break;
        }
        WRITE_PORT_ULONG( (PULONG)0xCF8, OldPort );
        return TRUE;
    }
#endif//TOSHIBA
    if( StreamClassReadWriteConfig(
                    pHwDevExt,
                    TRUE,           // indicates a READ
                    pData,
                    ulOffset,       // this is the offset into the PCI space
                    ulLength        // this is the # of bytes to read.
            )) {
        return TRUE;
    } else {
        return FALSE;
    }
}

BOOL
VC_SetPCIRegister(
    PHW_DEVICE_EXTENSION pHwDevExt,
    ULONG ulOffset,
    PVOID pData,
    ULONG ulLength)
{
#ifdef  TOSHIBA // '99-01-20 Added
    if( ulConfigAddress != 0xFFFFFFFF ) {
        ULONG OldPort;
        ULONG DataPort;

        OldPort = READ_PORT_ULONG( (PULONG)0xCF8 );
        WRITE_PORT_ULONG( (PULONG)0xCF8, ( ulConfigAddress | ulOffset) & 0xFFFFFFFC );
        DataPort = 0xCFC + (ulOffset % 4);
        switch ( ulLength ) {
            case 1:
                WRITE_PORT_UCHAR( (PUCHAR)DataPort, *((PUCHAR)pData) );
                break;
            case 2:
                WRITE_PORT_USHORT( (PUSHORT)DataPort, *((PUSHORT)pData) );
                break;
            case 4:
                WRITE_PORT_ULONG( (PULONG)DataPort, *((PULONG)pData) );
                break;
        }
        WRITE_PORT_ULONG( (PULONG)0xCF8, OldPort );
        return TRUE;
    }
#endif//TOSHIBA
    if( StreamClassReadWriteConfig(
                    pHwDevExt,
                    FALSE,          // indicates a WRITE
                    pData,
                    ulOffset,       // this is the offset into the PCI space
                    ulLength        // this is the # of bytes to read.
            )) {
        return TRUE;
    } else {
        return FALSE;
    }
}

/*
 * delay for a number of milliseconds. This is accurate only to
 * +- 15msecs at best.
 */
VOID
VC_Delay(int nMillisecs)
{
    LARGE_INTEGER Delay;

    /*
     * relative times are negative, in units of 100 nanosecs
     */

    // first wait for the minimum length of time - this ensures that
    // our wait is never less than nMillisecs.
    Delay = RtlConvertLongToLargeInteger(-1);
    KeDelayExecutionThread(KernelMode,
                           FALSE,               //non-alertable
                           &Delay);


    // now wait for the requested time.

    Delay = RtlConvertLongToLargeInteger(-(nMillisecs * 10000));

    KeDelayExecutionThread(KernelMode,
                           FALSE,               //non-alertable
                           &Delay);
}


#if DBG
void
DbgDumpPciRegister( PHW_DEVICE_EXTENSION pHwDevExt )
{
    ULONG  i;
    ULONG  data;

    DbgPrint("\n+++++ PCI Config Register +++++\n");
    for( i=0; i<0x48; i+=4 )
    {
        if (VC_GetPCIRegister(pHwDevExt,
                              i,
                              &data,
                              0x04) )
        {
            DbgPrint("0x%02X: 0x%08X\n", i, data);
        }
        else
        {
            DbgPrint("0x%02X: Read Error.\n", i);
        }
    }
}

void
DbgDumpCaptureRegister( PHW_DEVICE_EXTENSION pHwDevExt )
{
    ULONG  i;
    ULONG  data;

    DbgPrint("\n+++++ Capture Register +++++\n");
    for( i=0; i<0xA4; i+=4 )
    {
        data = ReadRegUlong(pHwDevExt, i);
        DbgPrint("0x%02X: 0x%08X\n", i, data);
    }
}
#endif



=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\drivers\wdm\capture\mini\tecra750\capmain.c ===
//==========================================================================;
//
//  THIS CODE AND INFORMATION IS PROVIDED "AS IS" WITHOUT WARRANTY OF ANY
//  KIND, EITHER EXPRESSED OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE
//  IMPLIED WARRANTIES OF MERCHANTABILITY AND/OR FITNESS FOR A PARTICULAR
//  PURPOSE.
//
//  Copyright (c) 1992 - 1997  Microsoft Corporation.  All Rights Reserved.
//
//==========================================================================;

#include "strmini.h"
#include "ksmedia.h"
#include "capmain.h"
#include "mediums.h"
#include "capstrm.h"
#include "capprop.h"
#include "capdebug.h"
#ifdef  TOSHIBA
#include "bert.h"

ULONG   CurrentOSType;  // 0:Win98 1:NT5.0
#endif//TOSHIBA

#ifdef  TOSHIBA
VOID
DevicePowerON (
    IN OUT PHW_STREAM_REQUEST_BLOCK pSrb
    )
{
    PHW_DEVICE_EXTENSION pHwDevExt = ((PHW_DEVICE_EXTENSION)pSrb->HwDeviceExtension);
    DWORD                   dwAddr;

    CameraChkandON(pHwDevExt, MODE_VFW);
    VC_Delay(100);
    ImageSetInputImageSize(pHwDevExt, &(pHwDevExt->SrcRect));
    ImageSetOutputImageSize(pHwDevExt, pHwDevExt->ulWidth, pHwDevExt->ulHeight);
    BertFifoConfig(pHwDevExt, pHwDevExt->Format);
    ImageSetHueBrightnessContrastSat(pHwDevExt);
    if ( pHwDevExt->ColorEnable ) {
        if ( get_AblFilter( pHwDevExt ) ) {
            set_filtering( pHwDevExt, TRUE );
        } else {
            set_filtering( pHwDevExt, FALSE );
            pHwDevExt->ColorEnable = 0;
        }
    } else {
        set_filtering( pHwDevExt, FALSE );
    }
    dwAddr = (DWORD)pHwDevExt->pPhysRpsDMABuf.LowPart;
#if 0
    dwAddr = (dwAddr + 0x1FFF) & 0xFFFFE000;
#endif
    pHwDevExt->s_physDmaActiveFlag = dwAddr + 0X1860;

    if( pHwDevExt->dblBufflag ){
        BertTriBuildNodes(pHwDevExt); // Add 97-04-08(Tue)
    }
    else{
        BertBuildNodes(pHwDevExt);  // Add 97-04-08(Tue)
    }
    pHwDevExt->IsRPSReady = TRUE;
    BertInterruptEnable(pHwDevExt, TRUE);
    BertDMARestart(pHwDevExt);
}

VOID
CameraPowerON (
    IN OUT PHW_STREAM_REQUEST_BLOCK pSrb
    )
{
    PHW_DEVICE_EXTENSION pHwDevExt = ((PHW_DEVICE_EXTENSION)pSrb->HwDeviceExtension);

    CameraChkandON(pHwDevExt, MODE_VFW);
    VC_Delay(100);
}

VOID
CameraPowerOFF (
    IN OUT PHW_STREAM_REQUEST_BLOCK pSrb
    )
{
    PHW_DEVICE_EXTENSION pHwDevExt = ((PHW_DEVICE_EXTENSION)pSrb->HwDeviceExtension);

    CameraChkandOFF(pHwDevExt, MODE_VFW);
}

VOID
QueryOSTypeFromRegistry()
{
    NTSTATUS ntStatus = STATUS_SUCCESS;
    LONG     RegVals[2];
    PLONG    pRegVal;
    WCHAR    BasePath[] = L"\\Registry\\MACHINE\\SOFTWARE\\Toshiba\\Tsbvcap";
    RTL_QUERY_REGISTRY_TABLE Table[2];
    UNICODE_STRING RegPath;

    //
    // Get the actual values for the controls
    //

    RtlZeroMemory (Table, sizeof(Table));

    CurrentOSType = 1;  // Assume NT5.0
    RegVals[0] = CurrentOSType;

    pRegVal = RegVals;  // for convenience sake
    RegPath.Buffer = BasePath;
#ifdef  TOSHIBA // '99-01-08 Modified
    RegPath.MaximumLength = sizeof(BasePath) + (32 * sizeof(WCHAR)); //32 chars for keys
#else //TOSHIBA
    RegPath.MaximumLength = sizeof(BasePath + 32); //32 chars for keys
#endif//TOSHIBA
    RegPath.Length = 0;

    Table[0].Name = L"CurrentOSType";
    Table[0].Flags = RTL_QUERY_REGISTRY_DIRECT;
    Table[0].EntryContext = pRegVal++;

    ntStatus = RtlQueryRegistryValues(
                       RTL_REGISTRY_ABSOLUTE,
                       RegPath.Buffer,
                       Table,
                       NULL,
                       NULL );

    if( NT_SUCCESS(ntStatus))
    {
        CurrentOSType = RegVals[0];
    }
}

VOID
QueryControlsFromRegistry(
    PHW_DEVICE_EXTENSION pHwDevExt
    )
{
    NTSTATUS ntStatus = STATUS_SUCCESS;
    LONG     RegVals[6];
    PLONG    pRegVal;
    WCHAR    BasePath[] = L"\\Registry\\MACHINE\\SOFTWARE\\Toshiba\\Tsbvcap";
    RTL_QUERY_REGISTRY_TABLE Table[6];
    UNICODE_STRING RegPath;

    //
    // Get the actual values for the controls
    //

    RtlZeroMemory (Table, sizeof(Table));

    RegVals[0] = pHwDevExt->Brightness;
    RegVals[1] = pHwDevExt->Contrast;
    RegVals[2] = pHwDevExt->Hue;
    RegVals[3] = pHwDevExt->Saturation;
    RegVals[4] = pHwDevExt->ColorEnable;

    pRegVal = RegVals;   // for convenience sake
    RegPath.Buffer = BasePath;
#ifdef  TOSHIBA // '99-01-08 Modified
    RegPath.MaximumLength = sizeof(BasePath) + (32 * sizeof(WCHAR)); //32 chars for keys
#else //TOSHIBA
    RegPath.MaximumLength = sizeof(BasePath + 32); //32 chars for keys
#endif//TOSHIBA
    RegPath.Length = 0;

    Table[0].Name = L"Brightness";
    Table[0].Flags = RTL_QUERY_REGISTRY_DIRECT;
    Table[0].EntryContext = pRegVal++;

    Table[1].Name = L"Contrast";
    Table[1].Flags = RTL_QUERY_REGISTRY_DIRECT;
    Table[1].EntryContext = pRegVal++;

    Table[2].Name = L"Hue";
    Table[2].Flags = RTL_QUERY_REGISTRY_DIRECT;
    Table[2].EntryContext = pRegVal++;

    Table[3].Name = L"Saturation";
    Table[3].Flags = RTL_QUERY_REGISTRY_DIRECT;
    Table[3].EntryContext = pRegVal++;

    Table[4].Name = L"FilterEnable";
    Table[4].Flags = RTL_QUERY_REGISTRY_DIRECT;
    Table[4].EntryContext = pRegVal++;

    ntStatus = RtlQueryRegistryValues(
                       RTL_REGISTRY_ABSOLUTE,
                       RegPath.Buffer,
                       Table,
                       NULL,
                       NULL );

    if( NT_SUCCESS(ntStatus))
    {
        pHwDevExt->Brightness  = RegVals[0];
        pHwDevExt->Contrast    = RegVals[1];
        pHwDevExt->Hue         = RegVals[2];
        pHwDevExt->Saturation  = RegVals[3];
        pHwDevExt->ColorEnable = RegVals[4];
    }
}

VOID
SaveControlsToRegistry(
    PHW_DEVICE_EXTENSION pHwDevExt
    )
{
    LONG Value;
    WCHAR BasePath[] = L"\\Registry\\MACHINE\\SOFTWARE\\Toshiba\\Tsbvcap";
    UNICODE_STRING RegPath;


    RegPath.Buffer = BasePath;
#ifdef  TOSHIBA // '99-01-08 Modified
    RegPath.MaximumLength = sizeof(BasePath) + (32 * sizeof(WCHAR)); //32 chars for keys
#else //TOSHIBA
    RegPath.MaximumLength = sizeof(BasePath + 32); //32 chars for keys
#endif//TOSHIBA
    RegPath.Length = 0;

    Value = pHwDevExt->Brightness;
    RtlWriteRegistryValue(
                          RTL_REGISTRY_ABSOLUTE,
                          RegPath.Buffer,
                          L"Brightness",
                          REG_DWORD,
                          &Value,
                          sizeof (ULONG));

    Value = pHwDevExt->Contrast;
    RtlWriteRegistryValue(
                          RTL_REGISTRY_ABSOLUTE,
                          RegPath.Buffer,
                          L"Contrast",
                          REG_DWORD,
                          &Value,
                          sizeof (ULONG));

    Value = pHwDevExt->Hue;
    RtlWriteRegistryValue(
                          RTL_REGISTRY_ABSOLUTE,
                          RegPath.Buffer,
                          L"Hue",
                          REG_DWORD,
                          &Value,
                          sizeof (ULONG));

    Value = pHwDevExt->Saturation;
    RtlWriteRegistryValue(
                          RTL_REGISTRY_ABSOLUTE,
                          RegPath.Buffer,
                          L"Saturation",
                          REG_DWORD,
                          &Value,
                          sizeof (ULONG));

    Value = pHwDevExt->ColorEnable;
    RtlWriteRegistryValue(
                          RTL_REGISTRY_ABSOLUTE,
                          RegPath.Buffer,
                          L"FilterEnable",
                          REG_DWORD,
                          &Value,
                          sizeof (ULONG));
}
#endif//TOSHIBA

/*
** DriverEntry()
**
**   This routine is called when the driver is first loaded by PnP.
**   It in turn, calls upon the stream class to perform registration services.
**
** Arguments:
**
**   DriverObject -
**          Driver object for this driver
**
**   RegistryPath -
**          Registry path string for this driver's key
**
** Returns:
**
**   Results of StreamClassRegisterAdapter()
**
** Side Effects:  none
*/

ULONG
DriverEntry (
    IN PDRIVER_OBJECT DriverObject,
    IN PUNICODE_STRING RegistryPath
    )
{

    HW_INITIALIZATION_DATA      HwInitData;
    ULONG                       ReturnValue;


    KdPrint(("TsbVcap: DriverEntry\n"));

    RtlZeroMemory(&HwInitData, sizeof(HwInitData));

    HwInitData.HwInitializationDataSize = sizeof(HwInitData);

    //
    // Set the Adapter entry points for the driver
    //

#ifdef  TOSHIBA
    QueryOSTypeFromRegistry();

    HwInitData.HwInterrupt              = HwInterrupt;
#else //TOSHIBA
    HwInitData.HwInterrupt              = NULL; // HwInterrupt;
#endif//TOSHIBA

    HwInitData.HwReceivePacket          = AdapterReceivePacket;
    HwInitData.HwCancelPacket           = AdapterCancelPacket;
    HwInitData.HwRequestTimeoutHandler  = AdapterTimeoutPacket;

    HwInitData.DeviceExtensionSize      = sizeof(HW_DEVICE_EXTENSION);
    HwInitData.PerRequestExtensionSize  = sizeof(SRB_EXTENSION);
    HwInitData.FilterInstanceExtensionSize = 0;
    HwInitData.PerStreamExtensionSize   = sizeof(STREAMEX);
    HwInitData.BusMasterDMA             = FALSE;
    HwInitData.Dma24BitAddresses        = FALSE;
    HwInitData.BufferAlignment          = 3;
#ifdef  TOSHIBA
    if ( CurrentOSType ) {  // NT5.0
        HwInitData.DmaBufferSize = 8192 * 2;
    } else {
        HwInitData.DmaBufferSize = 8192 * 2 + MAX_CAPTURE_BUFFER_SIZE;
    }
#else //TOSHIBA
    HwInitData.DmaBufferSize            = 0;
#endif//TOSHIBA

    // Don't rely on the stream class using raised IRQL to synchronize
    // execution.  This single paramter most affects the overall structure
    // of the driver.

    HwInitData.TurnOffSynchronization   = TRUE;

    ReturnValue = StreamClassRegisterAdapter(DriverObject, RegistryPath, &HwInitData);

    KdPrint(("TsbVcap: StreamClassRegisterAdapter = %x\n", ReturnValue));

    return ReturnValue;
}

//==========================================================================;
//                   Adapter Based Request Handling Routines
//==========================================================================;

/*
** HwInitialize()
**
**   This routine is called when an SRB_INITIALIZE_DEVICE request is received
**
** Arguments:
**
**   pSrb - pointer to stream request block for the Initialize command
**
** Returns:
**
** Side Effects:  none
*/

BOOL
STREAMAPI
HwInitialize (
    IN OUT PHW_STREAM_REQUEST_BLOCK pSrb
    )
{
    STREAM_PHYSICAL_ADDRESS     adr;
    ULONG                       Size;
    PUCHAR                      pDmaBuf;
    int                         j;

    PPORT_CONFIGURATION_INFORMATION ConfigInfo = pSrb->CommandData.ConfigInfo;

    PHW_DEVICE_EXTENSION pHwDevExt =
        (PHW_DEVICE_EXTENSION)ConfigInfo->HwDeviceExtension;

    KdPrint(("TsbVcap: HwInitialize()\n"));

#ifdef  TOSHIBA
    if (ConfigInfo->NumberOfAccessRanges == 0) {
#else //TOSHIBA
    if (ConfigInfo->NumberOfAccessRanges != 0) {
#endif//TOSHIBA
        KdPrint(("TsbVcap: illegal config info\n"));

        pSrb->Status = STATUS_NO_SUCH_DEVICE;
        return (FALSE);
    }

    KdPrint(("TsbVcap: Number of access ranges = %lx\n", ConfigInfo->NumberOfAccessRanges));
    KdPrint(("TsbVcap: Memory Range = %lx\n", pHwDevExt->ioBaseLocal));
    KdPrint(("TsbVcap: IRQ = %lx\n", ConfigInfo->BusInterruptLevel));

    if (ConfigInfo->NumberOfAccessRanges != 0) {
        pHwDevExt->ioBaseLocal
                = (PULONG)(ConfigInfo->AccessRanges[0].RangeStart.LowPart);
    }

    pHwDevExt->Irq  = (USHORT)(ConfigInfo->BusInterruptLevel);

    ConfigInfo->StreamDescriptorSize = sizeof (HW_STREAM_HEADER) +
                DRIVER_STREAM_COUNT * sizeof (HW_STREAM_INFORMATION);

    pDmaBuf = StreamClassGetDmaBuffer(pHwDevExt);

    adr = StreamClassGetPhysicalAddress(pHwDevExt,
            NULL, pDmaBuf, DmaBuffer, &Size);

#ifdef  TOSHIBA
    if ( CurrentOSType ) {  // NT5.0
        pHwDevExt->pRpsDMABuf = pDmaBuf;
        pHwDevExt->pPhysRpsDMABuf = adr;
        pHwDevExt->pCaptureBufferY = NULL;
        pHwDevExt->pCaptureBufferU = NULL;
        pHwDevExt->pCaptureBufferV = NULL;
        pHwDevExt->pPhysCaptureBufferY.LowPart = 0;
        pHwDevExt->pPhysCaptureBufferY.HighPart = 0;
        pHwDevExt->pPhysCaptureBufferU.LowPart = 0;
        pHwDevExt->pPhysCaptureBufferU.HighPart = 0;
        pHwDevExt->pPhysCaptureBufferV.LowPart = 0;
        pHwDevExt->pPhysCaptureBufferV.HighPart = 0;
        pHwDevExt->BufferSize = 0;
    } else {
        pHwDevExt->pRpsDMABuf = pDmaBuf;
        pHwDevExt->pCaptureBufferY = pDmaBuf + (8192 * 2);
        pHwDevExt->pPhysRpsDMABuf = adr;
        adr.LowPart += 8192 * 2;
        pHwDevExt->pPhysCaptureBufferY = adr;
        pHwDevExt->BufferSize = 0;
    }

    InitializeConfigDefaults(pHwDevExt);
    pHwDevExt->NeedHWInit = TRUE;
    if(!SetupPCILT(pHwDevExt))
    {
        pSrb->Status = STATUS_NO_SUCH_DEVICE;
        return (FALSE);
    }
    pHwDevExt->dblBufflag=FALSE;
    BertInitializeHardware(pHwDevExt);
    if(SetASICRev(pHwDevExt) != TRUE )
    {
        pSrb->Status = STATUS_NO_SUCH_DEVICE;
        return (FALSE);
    }
    BertSetDMCHE(pHwDevExt);
#if 0   // move to CameraPowerON()
    if( !CameraChkandON(pHwDevExt, MODE_VFW) )
    {
        pSrb->Status = STATUS_NO_SUCH_DEVICE;
        return (FALSE);
    }
#endif
    HWInit(pHwDevExt);
#endif//TOSHIBA

#ifdef  TOSHIBA
    // Init VideoProcAmp properties
    pHwDevExt->Brightness = 0x80;
    pHwDevExt->BrightnessFlags = KSPROPERTY_VIDEOPROCAMP_FLAGS_MANUAL;
    pHwDevExt->Contrast = 0x80;
    pHwDevExt->ContrastFlags = KSPROPERTY_VIDEOPROCAMP_FLAGS_MANUAL;
    pHwDevExt->Hue = 0x80;
    pHwDevExt->HueFlags = KSPROPERTY_VIDEOPROCAMP_FLAGS_MANUAL;
    pHwDevExt->Saturation = 0x80;
    pHwDevExt->SaturationFlags = KSPROPERTY_VIDEOPROCAMP_FLAGS_MANUAL;
    pHwDevExt->ColorEnable = ColorEnableDefault;
    pHwDevExt->ColorEnableFlags = KSPROPERTY_VIDEOPROCAMP_FLAGS_MANUAL;

#ifdef  TOSHIBA // '98-12-09 Added, for Bug-Report 253529
    pHwDevExt->BrightnessRange = BrightnessRangeAndStep[0].Bounds;
    pHwDevExt->ContrastRange   = ContrastRangeAndStep[0].Bounds;
    pHwDevExt->HueRange        = HueRangeAndStep[0].Bounds;
    pHwDevExt->SaturationRange = SaturationRangeAndStep[0].Bounds;
#endif//TOSHIBA

    // Init VideoControl properties
    pHwDevExt->VideoControlMode = 0;
#else //TOSHIBA
    // Init Crossbar properties
    pHwDevExt->VideoInputConnected = 0;     // TvTuner video is the default
    pHwDevExt->AudioInputConnected = 5;     // TvTuner audio is the default

    // Init VideoProcAmp properties
    pHwDevExt->Brightness = BrightnessDefault;
    pHwDevExt->BrightnessFlags = KSPROPERTY_VIDEOPROCAMP_FLAGS_AUTO;
    pHwDevExt->Contrast = ContrastDefault;
    pHwDevExt->ContrastFlags = KSPROPERTY_VIDEOPROCAMP_FLAGS_AUTO;
    pHwDevExt->ColorEnable = ColorEnableDefault;
    pHwDevExt->ColorEnableFlags = KSPROPERTY_VIDEOPROCAMP_FLAGS_MANUAL;

    // Init CameraControl properties
    pHwDevExt->Focus = FocusDefault;
    pHwDevExt->FocusFlags = KSPROPERTY_CAMERACONTROL_FLAGS_AUTO;
    pHwDevExt->Zoom = ZoomDefault;
    pHwDevExt->ZoomFlags = KSPROPERTY_CAMERACONTROL_FLAGS_AUTO;

    // Init TvTuner properties
    pHwDevExt->TunerInput = 0;
    pHwDevExt->Busy = 0;

    // Init TvAudio properties
    pHwDevExt->TVAudioMode = KS_TVAUDIO_MODE_MONO   |
                             KS_TVAUDIO_MODE_LANG_A ;

    // Init AnalogVideoDecoder properties
    pHwDevExt->VideoDecoderVideoStandard = KS_AnalogVideo_NTSC_M;
    pHwDevExt->VideoDecoderOutputEnable = FALSE;
    pHwDevExt->VideoDecoderVCRTiming = FALSE;

    // Init VideoControl properties
    pHwDevExt->VideoControlMode = 0;
#endif//TOSHIBA

    // Init VideoCompression properties
    pHwDevExt->CompressionSettings.CompressionKeyFrameRate = 15;
    pHwDevExt->CompressionSettings.CompressionPFramesPerKeyFrame = 3;
    pHwDevExt->CompressionSettings.CompressionQuality = 5000;

    pHwDevExt->PDO = ConfigInfo->PhysicalDeviceObject;
    KdPrint(("TsbVcap: Physical Device Object = %lx\n", pHwDevExt->PDO));

#ifdef  TOSHIBA
    IoInitializeDpcRequest(pHwDevExt->PDO, DeferredRoutine);
#endif//TOSHIBA

    for (j = 0; j < MAX_TSBVCAP_STREAMS; j++){

        // For each stream, maintain a separate queue for data and control
        InitializeListHead (&pHwDevExt->StreamSRBList[j]);
        InitializeListHead (&pHwDevExt->StreamControlSRBList[j]);
        KeInitializeSpinLock (&pHwDevExt->StreamSRBSpinLock[j]);
        pHwDevExt->StreamSRBListSize[j] = 0;
    }


    KdPrint(("TsbVcap: Exit, HwInitialize()\n"));

    pSrb->Status = STATUS_SUCCESS;

    return (TRUE);

}

/*
** HwUnInitialize()
**
**   This routine is called when an SRB_UNINITIALIZE_DEVICE request is received
**
** Arguments:
**
**   pSrb - pointer to stream request block for the UnInitialize command
**
** Returns:
**
** Side Effects:  none
*/

BOOL
STREAMAPI
HwUnInitialize (
    PHW_STREAM_REQUEST_BLOCK pSrb
    )
{
#ifdef  TOSHIBA
    PHW_DEVICE_EXTENSION    pHwDevExt = ((PHW_DEVICE_EXTENSION)pSrb->HwDeviceExtension);

    if ( CurrentOSType ) {  // NT5.0
        if ( pHwDevExt->pCaptureBufferY )
        {
            // free frame buffer
            MmFreeContiguousMemory(pHwDevExt->pCaptureBufferY);
            pHwDevExt->pCaptureBufferY = NULL;
            pHwDevExt->pPhysCaptureBufferY.LowPart = 0;
            pHwDevExt->pPhysCaptureBufferY.HighPart = 0;
        }
        if ( pHwDevExt->pCaptureBufferU )
        {
            // free frame buffer
            MmFreeContiguousMemory(pHwDevExt->pCaptureBufferU);
            pHwDevExt->pCaptureBufferU = NULL;
            pHwDevExt->pPhysCaptureBufferU.LowPart = 0;
            pHwDevExt->pPhysCaptureBufferU.HighPart = 0;
        }
        if ( pHwDevExt->pCaptureBufferV )
        {
            // free frame buffer
            MmFreeContiguousMemory(pHwDevExt->pCaptureBufferV);
            pHwDevExt->pCaptureBufferV = NULL;
            pHwDevExt->pPhysCaptureBufferV.LowPart = 0;
            pHwDevExt->pPhysCaptureBufferV.HighPart = 0;
        }
    }
#endif//TOSHIBA

    pSrb->Status = STATUS_SUCCESS;

    return TRUE;
}

/*
** AdapterPowerState()
**
**   This routine is called when an SRB_CHANGE_POWER_STATE request is received
**
** Arguments:
**
**   pSrb - pointer to stream request block for the Change Power state command
**
** Returns:
**
** Side Effects:  none
*/

BOOLEAN
STREAMAPI
AdapterPowerState (
    PHW_STREAM_REQUEST_BLOCK pSrb
    )
{
    PHW_DEVICE_EXTENSION    pHwDevExt = ((PHW_DEVICE_EXTENSION)pSrb->HwDeviceExtension);
#ifdef  TOSHIBA
    int                     Counter;
    PSTREAMEX               pStrmEx;
#endif//TOSHIBA

    pHwDevExt->DeviceState = pSrb->CommandData.DeviceState;

#ifdef  TOSHIBA
    for (Counter = 0; Counter < DRIVER_STREAM_COUNT; Counter++) {
        if ( pStrmEx = (PSTREAMEX)pHwDevExt->pStrmEx[Counter] ) {
            //
            // Only when it is not streaming, its power state can be changed.
            // We have "DontSuspendIfStreamsAreRunning" turn on in the INF.
            //
            if (pStrmEx->KSState == KSSTATE_PAUSE ||
                pStrmEx->KSState == KSSTATE_RUN) {
                if (pHwDevExt->DeviceState == PowerDeviceD3) {
                    if (pHwDevExt->bVideoIn == TRUE) {
                      // disable the RPS_INT and field interrupts
                      BertInterruptEnable(pHwDevExt, FALSE);
                      BertDMAEnable(pHwDevExt, FALSE);
                      // wait for the current data xfer to complete
                      pHwDevExt->bVideoIn = FALSE;
                    }
                    VideoQueueCancelAllSRBs (pStrmEx);
                    break;
                } else if (pHwDevExt->DeviceState == PowerDeviceD0) {
                    pHwDevExt->bVideoIn = TRUE;
#ifdef  TOSHIBA // '99-01-20 Modified
                    DevicePowerON( pSrb );
#else //TOSHIBA
                    StreamClassCallAtNewPriority(
                            NULL,
                            pSrb->HwDeviceExtension,
                            Low,
                            (PHW_PRIORITY_ROUTINE) DevicePowerON,
                            pSrb
                    );
#endif//TOSHIBA
                }
            }
        }
    }
#endif//TOSHIBA

    return TRUE;
}

/*
** AdapterSetInstance()
**
**   This routine is called to set all of the Medium instance fields
**
** Arguments:
**
**   pSrb - pointer to stream request block
**
** Returns:
**
** Side Effects:  none
*/

VOID
STREAMAPI
AdapterSetInstance (
    PHW_STREAM_REQUEST_BLOCK pSrb
    )
{
    int j;
    PHW_DEVICE_EXTENSION    pHwDevExt = ((PHW_DEVICE_EXTENSION)pSrb->HwDeviceExtension);

    // Use our HwDevExt as the instance data on the Mediums
    // This allows multiple instances to be uniquely identified and
    // connected.  The value used in .Id is not important, only that
    // it is unique for each hardware connection

#ifdef  TOSHIBA
    for (j = 0; j < SIZEOF_ARRAY (CaptureMediums); j++) {
        CaptureMediums[j].Id = 0; //(ULONG) pHwDevExt;
    }
#else //TOSHIBA
    for (j = 0; j < SIZEOF_ARRAY (TVTunerMediums); j++) {
        TVTunerMediums[j].Id = 0; //(ULONG) pHwDevExt;
    }
    for (j = 0; j < SIZEOF_ARRAY (TVAudioMediums); j++) {
        TVAudioMediums[j].Id = 0; //(ULONG) pHwDevExt;
    }
    for (j = 0; j < SIZEOF_ARRAY (CrossbarMediums); j++) {
        CrossbarMediums[j].Id = 0; //(ULONG) pHwDevExt;
    }
    for (j = 0; j < SIZEOF_ARRAY (CaptureMediums); j++) {
        CaptureMediums[j].Id = 0; //(ULONG) pHwDevExt;
    }

    pHwDevExt->AnalogVideoInputMedium = CaptureMediums[2];
#endif//TOSHIBA
}

/*
** AdapterCompleteInitialization()
**
**   This routine is called when an SRB_COMPLETE_INITIALIZATION request is received
**
** Arguments:
**
**   pSrb - pointer to stream request block
**
** Returns:
**
** Side Effects:  none
*/

VOID
STREAMAPI
AdapterCompleteInitialization (
    PHW_STREAM_REQUEST_BLOCK pSrb
    )
{
    NTSTATUS                Status;
    PHW_DEVICE_EXTENSION    pHwDevExt = ((PHW_DEVICE_EXTENSION)pSrb->HwDeviceExtension);
    KIRQL                   KIrql;

    KIrql = KeGetCurrentIrql();

    // The following allows multiple instance of identical hardware
    // to be installed
    AdapterSetInstance (pSrb);

    // Create the Registry blobs that DShow uses to create
    // graphs via Mediums

#ifndef TOSHIBA
    // Register the TVTuner
    Status = StreamClassRegisterFilterWithNoKSPins (
                    pHwDevExt->PDO,                 // IN PDEVICE_OBJECT   DeviceObject,
                    &KSCATEGORY_TVTUNER,            // IN GUID           * InterfaceClassGUID,
                    SIZEOF_ARRAY (TVTunerMediums),  // IN ULONG            PinCount,
                    TVTunerPinDirection,            // IN ULONG          * Flags,
                    TVTunerMediums,                 // IN KSPIN_MEDIUM   * MediumList,
                    NULL                            // IN GUID           * CategoryList
            );

    // Register the Crossbar
    Status = StreamClassRegisterFilterWithNoKSPins (
                    pHwDevExt->PDO,                 // IN PDEVICE_OBJECT   DeviceObject,
                    &KSCATEGORY_CROSSBAR,           // IN GUID           * InterfaceClassGUID,
                    SIZEOF_ARRAY (CrossbarMediums), // IN ULONG            PinCount,
                    CrossbarPinDirection,           // IN ULONG          * Flags,
                    CrossbarMediums,                // IN KSPIN_MEDIUM   * MediumList,
                    NULL                            // IN GUID           * CategoryList
            );

    // Register the TVAudio decoder
    Status = StreamClassRegisterFilterWithNoKSPins (
                    pHwDevExt->PDO,                 // IN PDEVICE_OBJECT   DeviceObject,
                    &KSCATEGORY_TVAUDIO,            // IN GUID           * InterfaceClassGUID,
                    SIZEOF_ARRAY (TVAudioMediums),  // IN ULONG            PinCount,
                    TVAudioPinDirection,            // IN ULONG          * Flags,
                    TVAudioMediums,                 // IN KSPIN_MEDIUM   * MediumList,
                    NULL                            // IN GUID           * CategoryList
            );

    // Register the Capture filter
    // Note:  This should be done automatically be MSKsSrv.sys,
    // when that component comes on line (if ever) ...
    Status = StreamClassRegisterFilterWithNoKSPins (
                    pHwDevExt->PDO,                 // IN PDEVICE_OBJECT   DeviceObject,
                    &KSCATEGORY_CAPTURE,            // IN GUID           * InterfaceClassGUID,
                    SIZEOF_ARRAY (CaptureMediums),  // IN ULONG            PinCount,
                    CapturePinDirection,            // IN ULONG          * Flags,
                    CaptureMediums,                 // IN KSPIN_MEDIUM   * MediumList,
                    NULL                            // IN GUID           * CategoryList
            );
#endif//TOSHIBA

}


/*
** AdapterOpenStream()
**
**   This routine is called when an OpenStream SRB request is received.
**   A stream is identified by a stream number, which indexes an array
**   of KSDATARANGE structures.  The particular KSDATAFORMAT format to
**   be used is also passed in, which should be verified for validity.
**
** Arguments:
**
**   pSrb - pointer to stream request block for the Open command
**
** Returns:
**
** Side Effects:  none
*/

VOID
STREAMAPI
AdapterOpenStream (
    PHW_STREAM_REQUEST_BLOCK pSrb
    )
{
    //
    // the stream extension structure is allocated by the stream class driver
    //

    PSTREAMEX               pStrmEx = (PSTREAMEX)pSrb->StreamObject->HwStreamExtension;
    PHW_DEVICE_EXTENSION    pHwDevExt = ((PHW_DEVICE_EXTENSION)pSrb->HwDeviceExtension);
    int                     StreamNumber = pSrb->StreamObject->StreamNumber;
    PKSDATAFORMAT           pKSDataFormat = pSrb->CommandData.OpenFormat;
#ifdef  TOSHIBA
    int                     Counter;
    BOOL                    First = TRUE;
#endif//TOSHIBA


    RtlZeroMemory(pStrmEx, sizeof(STREAMEX));

    KdPrint(("TsbVcap: ------- ADAPTEROPENSTREAM ------- StreamNumber=%d\n", StreamNumber));

    //
    // check that the stream index requested isn't too high
    // or that the maximum number of instances hasn't been exceeded
    //

    if (StreamNumber >= DRIVER_STREAM_COUNT || StreamNumber < 0) {

        pSrb->Status = STATUS_INVALID_PARAMETER;

        return;
    }

    //
    // Check that we haven't exceeded the instance count for this stream
    //

    if (pHwDevExt->ActualInstances[StreamNumber] >=
        Streams[StreamNumber].hwStreamInfo.NumberOfPossibleInstances) {

        pSrb->Status = STATUS_INVALID_PARAMETER;

        return;
    }

    //
    // Check the validity of the format being requested
    //

    if (!AdapterVerifyFormat (pKSDataFormat, StreamNumber)) {

        pSrb->Status = STATUS_INVALID_PARAMETER;

        return;
    }

#ifdef  TOSHIBA
    QueryControlsFromRegistry(pHwDevExt);
#endif//TOSHIBA

    //
    // And set the format for the stream
    //

    if (!VideoSetFormat (pSrb)) {

        return;
    }

    ASSERT (pHwDevExt->pStrmEx [StreamNumber] == NULL);

#ifdef  TOSHIBA
    for (Counter = 0; Counter < DRIVER_STREAM_COUNT; Counter++) {
        if ( pHwDevExt->pStrmEx[Counter] ) {
            First = FALSE;
            break;
        }
    } // for all streams
#endif//TOSHIBA

    // Maintain an array of all the StreamEx structures in the HwDevExt
    // so that we can cancel IRPs from any stream

    pHwDevExt->pStrmEx [StreamNumber] = (PSTREAMX) pStrmEx;

    // Set up pointers to the handlers for the stream data and control handlers

    pSrb->StreamObject->ReceiveDataPacket =
            (PVOID) Streams[StreamNumber].hwStreamObject.ReceiveDataPacket;
    pSrb->StreamObject->ReceiveControlPacket =
            (PVOID) Streams[StreamNumber].hwStreamObject.ReceiveControlPacket;

    //
    // The DMA flag must be set when the device will be performing DMA directly
    // to the data buffer addresses passed in to the ReceiceDataPacket routines.
    //

    pSrb->StreamObject->Dma = Streams[StreamNumber].hwStreamObject.Dma;

    //
    // The PIO flag must be set when the mini driver will be accessing the data
    // buffers passed in using logical addressing
    //

    pSrb->StreamObject->Pio = Streams[StreamNumber].hwStreamObject.Pio;

    //
    // How many extra bytes will be passed up from the driver for each frame?
    //

    pSrb->StreamObject->StreamHeaderMediaSpecific =
                Streams[StreamNumber].hwStreamObject.StreamHeaderMediaSpecific;

    pSrb->StreamObject->StreamHeaderWorkspace =
                Streams[StreamNumber].hwStreamObject.StreamHeaderWorkspace;

    //
    // Indicate the clock support available on this stream
    //

    pSrb->StreamObject->HwClockObject =
                Streams[StreamNumber].hwStreamObject.HwClockObject;

    //
    // Increment the instance count on this stream
    //
    pHwDevExt->ActualInstances[StreamNumber]++;


    // Retain a private copy of the HwDevExt and StreamObject in the stream extension
    // so we can use a timer

    pStrmEx->pHwDevExt = pHwDevExt;                     // For timer use
    pStrmEx->pStreamObject = pSrb->StreamObject;        // For timer use

    // Initialize the compression settings
    // These may have been changed from the default values in the HwDevExt
    // before the stream was opened
    pStrmEx->CompressionSettings.CompressionKeyFrameRate =
        pHwDevExt->CompressionSettings.CompressionKeyFrameRate;
    pStrmEx->CompressionSettings.CompressionPFramesPerKeyFrame =
        pHwDevExt->CompressionSettings.CompressionPFramesPerKeyFrame;
    pStrmEx->CompressionSettings.CompressionQuality =
        pHwDevExt->CompressionSettings.CompressionQuality;

    // Init VideoControl properties
    pStrmEx->VideoControlMode = pHwDevExt->VideoControlMode;

#ifdef  TOSHIBA
    if ( First ) {
#ifdef  TOSHIBA // '99-01-20 Modified
        CameraPowerON( pSrb );
#else //TOSHIBA
        StreamClassCallAtNewPriority(
                NULL,
                pSrb->HwDeviceExtension,
                Low,
                (PHW_PRIORITY_ROUTINE) CameraPowerON,
                pSrb
        );
#endif//TOSHIBA
    }
#endif//TOSHIBA

    KdPrint(("TsbVcap: AdapterOpenStream Exit\n"));

}

/*
** AdapterCloseStream()
**
**   Close the requested data stream.
**
**   Note that a stream could be closed arbitrarily in the midst of streaming
**   if a user mode app crashes.  Therefore, you must release all outstanding
**   resources, disable interrupts, complete all pending SRBs, and put the
**   stream back into a quiescent condition.
**
** Arguments:
**
**   pSrb the request block requesting to close the stream
**
** Returns:
**
** Side Effects:  none
*/

VOID
STREAMAPI
AdapterCloseStream (
    PHW_STREAM_REQUEST_BLOCK pSrb
    )
{
    PSTREAMEX               pStrmEx = (PSTREAMEX)pSrb->StreamObject->HwStreamExtension;
    PHW_DEVICE_EXTENSION    pHwDevExt = ((PHW_DEVICE_EXTENSION)pSrb->HwDeviceExtension);
    int                     StreamNumber = pSrb->StreamObject->StreamNumber;
    PKSDATAFORMAT           pKSDataFormat = pSrb->CommandData.OpenFormat;
    KS_VIDEOINFOHEADER      *pVideoInfoHdr = pStrmEx->pVideoInfoHeader;
#ifdef  TOSHIBA
    int                     Counter;
    BOOL                    ClosedAll = TRUE;
#endif//TOSHIBA


    KdPrint(("TsbVcap: -------- ADAPTERCLOSESTREAM ------ StreamNumber=%d\n", StreamNumber));

    if (pHwDevExt->StreamSRBListSize > 0) {
        VideoQueueCancelAllSRBs (pStrmEx);
        KdPrint(("TsbVcap: Outstanding SRBs at stream close!!!\n"));
    }

    pHwDevExt->ActualInstances[StreamNumber]--;

    ASSERT (pHwDevExt->pStrmEx [StreamNumber] != 0);

    pHwDevExt->pStrmEx [StreamNumber] = 0;

    //
    // the minidriver should free any resources that were allocate at
    // open stream time etc.
    //

    // Free the variable length VIDEOINFOHEADER

    if (pVideoInfoHdr) {
        ExFreePool(pVideoInfoHdr);
        pStrmEx->pVideoInfoHeader = NULL;
    }

    // Make sure we no longer reference the clock
    pStrmEx->hMasterClock = NULL;

    // Make sure the state is reset to stopped,
    pStrmEx->KSState = KSSTATE_STOP;

#ifdef  TOSHIBA
    for (Counter = 0; Counter < DRIVER_STREAM_COUNT; Counter++) {
        if ( pHwDevExt->pStrmEx[Counter] ) {
            ClosedAll = FALSE;
            break;
        }
    } // for all streams
    if ( ClosedAll ) {
        if( pHwDevExt->dblBufflag ){
                Free_TriBuffer(pHwDevExt);
                pHwDevExt->IsRPSReady = FALSE;
                pHwDevExt->dblBufflag = FALSE;
        }
#ifdef  TOSHIBA // '99-01-20 Modified
        CameraPowerOFF( pSrb );
#else //TOSHIBA
        StreamClassCallAtNewPriority(
                NULL,
                pSrb->HwDeviceExtension,
                Low,
                (PHW_PRIORITY_ROUTINE) CameraPowerOFF,
                pSrb
        );
#endif//TOSHIBA
        SaveControlsToRegistry(pHwDevExt);
    }
#endif//TOSHIBA

}


/*
** AdapterStreamInfo()
**
**   Returns the information of all streams that are supported by the
**   mini-driver
**
** Arguments:
**
**   pSrb - Pointer to the STREAM_REQUEST_BLOCK
**        pSrb->HwDeviceExtension - will be the hardware device extension for
**                                  as initialised in HwInitialise
**
** Returns:
**
** Side Effects:  none
*/

VOID
STREAMAPI
AdapterStreamInfo (
    PHW_STREAM_REQUEST_BLOCK pSrb
    )
{
    int j;

    PHW_DEVICE_EXTENSION pHwDevExt =
        ((PHW_DEVICE_EXTENSION)pSrb->HwDeviceExtension);

    //
    // pick up the pointer to header which preceeds the stream info structs
    //

    PHW_STREAM_HEADER pstrhdr =
            (PHW_STREAM_HEADER)&(pSrb->CommandData.StreamBuffer->StreamHeader);

     //
     // pick up the pointer to the array of stream information data structures
     //

     PHW_STREAM_INFORMATION pstrinfo =
            (PHW_STREAM_INFORMATION)&(pSrb->CommandData.StreamBuffer->StreamInfo);


    //
    // verify that the buffer is large enough to hold our return data
    //

    DEBUG_ASSERT (pSrb->NumberOfBytesToTransfer >=
            sizeof (HW_STREAM_HEADER) +
            sizeof (HW_STREAM_INFORMATION) * DRIVER_STREAM_COUNT);

#ifndef TOSHIBA
    // Ugliness.  To allow mulitple instances, modify the pointer to the
    // AnalogVideoMedium and save it in our device extension

    Streams[STREAM_AnalogVideoInput].hwStreamInfo.Mediums =
           &pHwDevExt->AnalogVideoInputMedium;
    pHwDevExt->AnalogVideoInputMedium = CrossbarMediums[9];
    pHwDevExt->AnalogVideoInputMedium.Id = 0; //(ULONG) pHwDevExt;
#endif//TOSHIBA

     //
     // Set the header
     //

     StreamHeader.NumDevPropArrayEntries = NUMBER_OF_ADAPTER_PROPERTY_SETS;
     StreamHeader.DevicePropertiesArray = (PKSPROPERTY_SET) AdapterPropertyTable;
     *pstrhdr = StreamHeader;

     //
     // stuff the contents of each HW_STREAM_INFORMATION struct
     //

     for (j = 0; j < DRIVER_STREAM_COUNT; j++) {
        *pstrinfo++ = Streams[j].hwStreamInfo;
     }

}


/*
** AdapterReceivePacket()
**
**   Main entry point for receiving adapter based request SRBs.  This routine
**   will always be called at Passive level.
**
**   Note: This is an asyncronous entry point.  The request does not necessarily
**         complete on return from this function, the request only completes when a
**         StreamClassDeviceNotification on this request block, of type
**         DeviceRequestComplete, is issued.
**
** Arguments:
**
**   pSrb - Pointer to the STREAM_REQUEST_BLOCK
**        pSrb->HwDeviceExtension - will be the hardware device extension for
**                                  as initialised in HwInitialise
**
** Returns:
**
** Side Effects:  none
*/

VOID
STREAMAPI
AdapterReceivePacket(
    IN PHW_STREAM_REQUEST_BLOCK pSrb
    )
{
    PHW_DEVICE_EXTENSION    pHwDevExt = ((PHW_DEVICE_EXTENSION)pSrb->HwDeviceExtension);
    BOOL                    Busy;

    DEBUG_ASSERT(KeGetCurrentIrql() == PASSIVE_LEVEL);

    KdPrint(("TsbVcap: Receiving Adapter  SRB %8x, %x\n", pSrb, pSrb->Command));

    // The very first time through, we need to initialize the adapter spinlock
    // and queue
    if (!pHwDevExt->AdapterQueueInitialized) {
        InitializeListHead (&pHwDevExt->AdapterSRBList);
        KeInitializeSpinLock (&pHwDevExt->AdapterSpinLock);
        pHwDevExt->AdapterQueueInitialized = TRUE;
        pHwDevExt->ProcessingAdapterSRB = FALSE;
    }

    //
    // If we're already processing an SRB, add it to the queue
    //
    Busy = AddToListIfBusy (
                    pSrb,
                    &pHwDevExt->AdapterSpinLock,
                    &pHwDevExt->ProcessingAdapterSRB,
                    &pHwDevExt->AdapterSRBList);

    if (Busy) {
        return;
    }

    //
    // This will run until the queue is empty
    //
    while (TRUE) {
        //
        // Assume success
        //
        pSrb->Status = STATUS_SUCCESS;

        //
        // determine the type of packet.
        //

        switch (pSrb->Command)
        {

        case SRB_INITIALIZE_DEVICE:

            // open the device

            HwInitialize(pSrb);

            break;

        case SRB_UNINITIALIZE_DEVICE:

            // close the device.

            HwUnInitialize(pSrb);

            break;

        case SRB_OPEN_STREAM:

            // open a stream

            AdapterOpenStream(pSrb);

            break;

        case SRB_CLOSE_STREAM:

            // close a stream

            AdapterCloseStream(pSrb);

            break;

        case SRB_GET_STREAM_INFO:

            //
            // return a block describing all the streams
            //

            AdapterStreamInfo(pSrb);

            break;

        case SRB_GET_DATA_INTERSECTION:

            //
            // Return a format, given a range
            //

            AdapterFormatFromRange(pSrb);

            break;

        case SRB_OPEN_DEVICE_INSTANCE:
        case SRB_CLOSE_DEVICE_INSTANCE:

            //
            // We should never get these since this is a single instance device
            //

            TRAP
            pSrb->Status = STATUS_NOT_IMPLEMENTED;
            break;

        case SRB_GET_DEVICE_PROPERTY:

            //
            // Get adapter wide properties
            //

            AdapterGetProperty (pSrb);
            break;

        case SRB_SET_DEVICE_PROPERTY:

            //
            // Set adapter wide properties
            //

            AdapterSetProperty (pSrb);
            break;

        case SRB_PAGING_OUT_DRIVER:

            //
            // The driver is being paged out
            // Disable Interrupts if you have them!
            //
            KdPrint(("'TsbVcap: Receiving SRB_PAGING_OUT_DRIVER -- SRB=%x\n", pSrb));
            break;

        case SRB_CHANGE_POWER_STATE:

            //
            // Changing the device power state, D0 ... D3
            //
            KdPrint(("'TsbVcap: Receiving SRB_CHANGE_POWER_STATE ------ SRB=%x\n", pSrb));
            AdapterPowerState(pSrb);
            break;

        case SRB_INITIALIZATION_COMPLETE:

            //
            // Stream class has finished initialization.
            // Now create DShow Medium interface BLOBs.
            // This needs to be done at low priority since it uses the registry
            //
            KdPrint(("'TsbVcap: Receiving SRB_INITIALIZATION_COMPLETE-- SRB=%x\n", pSrb));

            AdapterCompleteInitialization (pSrb);
            break;


        case SRB_UNKNOWN_DEVICE_COMMAND:
        default:

            //
            // this is a request that we do not understand.  Indicate invalid
            // command and complete the request
            //
            pSrb->Status = STATUS_NOT_IMPLEMENTED;

        }

        //
        // Indicate back to the Stream Class that we're done with this SRB
        //
        CompleteDeviceSRB (pSrb);

        //
        // See if there's anything else on the queue
        //
        Busy = RemoveFromListIfAvailable (
                &pSrb,
                &pHwDevExt->AdapterSpinLock,
                &pHwDevExt->ProcessingAdapterSRB,
                &pHwDevExt->AdapterSRBList);

        if (!Busy) {
            break;
        }
    } // end of while there's anything in the queue
}

/*
** AdapterCancelPacket ()
**
**   Request to cancel a packet that is currently in process in the minidriver
**
** Arguments:
**
**   pSrb - pointer to request packet to cancel
**
** Returns:
**
** Side Effects:  none
*/

VOID
STREAMAPI
AdapterCancelPacket(
    PHW_STREAM_REQUEST_BLOCK pSrb
    )
{
    PHW_DEVICE_EXTENSION        pHwDevExt = (PHW_DEVICE_EXTENSION)pSrb->HwDeviceExtension;
    PSTREAMEX                   pStrmEx;
    int                         StreamNumber;
    BOOL                        Found = FALSE;

    //
    // Run through all the streams the driver has available
    //

    for (StreamNumber = 0; !Found && (StreamNumber < DRIVER_STREAM_COUNT); StreamNumber++) {

        //
        // Check to see if the stream is in use
        //

        if (pStrmEx = (PSTREAMEX) pHwDevExt->pStrmEx[StreamNumber]) {

            Found = VideoQueueCancelOneSRB (
                pStrmEx,
                pSrb
                );

        } // if the stream is open
    } // for all streams

    KdPrint(("TsbVcap: Cancelling SRB %8x Succeeded=%d\n", pSrb, Found));
}

/*
** AdapterTimeoutPacket()
**
**   This routine is called when a packet has been in the minidriver for
**   too long.  The adapter must decide what to do with the packet
**
** Arguments:
**
**   pSrb - pointer to the request packet that timed out
**
** Returns:
**
** Side Effects:  none
*/

VOID
STREAMAPI
AdapterTimeoutPacket(
    PHW_STREAM_REQUEST_BLOCK pSrb
    )
{
    //
    // Unlike most devices, we need to hold onto data SRBs indefinitely,
    // since the graph could be in a pause state indefinitely
    //

    KdPrint(("TsbVcap: Timeout    Adapter SRB %8x\n", pSrb));

    pSrb->TimeoutCounter = pSrb->TimeoutOriginal;

}

/*
** CompleteDeviceSRB ()
**
**   This routine is called when a packet is being completed.
**   The optional second notification type is used to indicate ReadyForNext
**
** Arguments:
**
**   pSrb - pointer to the request packet that timed out
**
** Returns:
**
** Side Effects:
**
*/

VOID
STREAMAPI
CompleteDeviceSRB (
     IN PHW_STREAM_REQUEST_BLOCK pSrb
    )
{
    KdPrint(("TsbVcap: Completing Adapter SRB %8x\n", pSrb));

    StreamClassDeviceNotification( DeviceRequestComplete, pSrb->HwDeviceExtension, pSrb);
}

/*
** AdapterCompareGUIDsAndFormatSize()
**
**   Checks for a match on the three GUIDs and FormatSize
**
** Arguments:
**
**         IN DataRange1
**         IN DataRange2
**         BOOL fCompareFormatSize - TRUE when comparing ranges
**                                 - FALSE when comparing formats
**
** Returns:
**
**   TRUE if all elements match
**   FALSE if any are different
**
** Side Effects:  none
*/

BOOL
STREAMAPI
AdapterCompareGUIDsAndFormatSize(
    IN PKSDATARANGE DataRange1,
    IN PKSDATARANGE DataRange2,
    BOOL fCompareFormatSize
    )
{
    return (
        IsEqualGUID (
            &DataRange1->MajorFormat,
            &DataRange2->MajorFormat) &&
        IsEqualGUID (
            &DataRange1->SubFormat,
            &DataRange2->SubFormat) &&
        IsEqualGUID (
            &DataRange1->Specifier,
            &DataRange2->Specifier) &&
        (fCompareFormatSize ?
                (DataRange1->FormatSize == DataRange2->FormatSize) : TRUE ));
}


/*
** AdapterVerifyFormat()
**
**   Checks the validity of a format request by walking through the
**       array of supported KSDATA_RANGEs for a given stream.
**
** Arguments:
**
**   pKSDataFormat - pointer of a KSDATAFORMAT structure.
**   StreamNumber - index of the stream being queried / opened.
**
** Returns:
**
**   TRUE if the format is supported
**   FALSE if the format cannot be suppored
**
** Side Effects:  none
*/

BOOL
STREAMAPI
AdapterVerifyFormat(
    PKSDATAFORMAT pKSDataFormatToVerify,
    int StreamNumber
    )
{
    BOOL                        fOK = FALSE;
    ULONG                       j;
    ULONG                       NumberOfFormatArrayEntries;
    PKSDATAFORMAT               *pAvailableFormats;


    //
    // Check that the stream number is valid
    //

    if (StreamNumber >= DRIVER_STREAM_COUNT) {
        TRAP;
        return FALSE;
    }

    NumberOfFormatArrayEntries =
            Streams[StreamNumber].hwStreamInfo.NumberOfFormatArrayEntries;

    //
    // Get the pointer to the array of available formats
    //

    pAvailableFormats = Streams[StreamNumber].hwStreamInfo.StreamFormatsArray;


    KdPrint(("TsbVcap: AdapterVerifyFormat, Stream=%d\n", StreamNumber));
    KdPrint(("TsbVcap: FormatSize=%d\n",  pKSDataFormatToVerify->FormatSize));
    KdPrint(("TsbVcap: MajorFormat=%x\n", pKSDataFormatToVerify->MajorFormat));

    //
    // Walk the formats supported by the stream
    //

    for (j = 0; j < NumberOfFormatArrayEntries; j++, pAvailableFormats++) {

        // Check for a match on the three GUIDs and format size

        if (!AdapterCompareGUIDsAndFormatSize(
                        pKSDataFormatToVerify,
                        *pAvailableFormats,
                        FALSE /* CompareFormatSize */ )) {
            continue;
        }

        //
        // Now that the three GUIDs match, switch on the Specifier
        // to do a further type-specific check
        //

        // -------------------------------------------------------------------
        // Specifier FORMAT_VideoInfo for VIDEOINFOHEADER
        // -------------------------------------------------------------------

        if (IsEqualGUID (&pKSDataFormatToVerify->Specifier,
                &KSDATAFORMAT_SPECIFIER_VIDEOINFO)) {

            PKS_DATAFORMAT_VIDEOINFOHEADER  pDataFormatVideoInfoHeader =
                    (PKS_DATAFORMAT_VIDEOINFOHEADER) pKSDataFormatToVerify;
            PKS_VIDEOINFOHEADER  pVideoInfoHdrToVerify =
                     (PKS_VIDEOINFOHEADER) &pDataFormatVideoInfoHeader->VideoInfoHeader;
            PKS_DATARANGE_VIDEO             pKSDataRangeVideo = (PKS_DATARANGE_VIDEO) *pAvailableFormats;
            KS_VIDEO_STREAM_CONFIG_CAPS    *pConfigCaps = &pKSDataRangeVideo->ConfigCaps;
            RECT                            rcImage;

            KdPrint(("TsbVcap: AdapterVerifyFormat\n"));
            KdPrint(("TsbVcap: pVideoInfoHdrToVerify=%x\n", pVideoInfoHdrToVerify));
            KdPrint(("TsbVcap: KS_VIDEOINFOHEADER size=%d\n",
                    KS_SIZE_VIDEOHEADER (pVideoInfoHdrToVerify)));
            KdPrint(("TsbVcap: Width=%d  Height=%d  BitCount=%d\n",
            pVideoInfoHdrToVerify->bmiHeader.biWidth,
            pVideoInfoHdrToVerify->bmiHeader.biHeight,
            pVideoInfoHdrToVerify->bmiHeader.biBitCount));
            KdPrint(("TsbVcap: biSizeImage=%d\n",
                pVideoInfoHdrToVerify->bmiHeader.biSizeImage));

            /*
            **  HOW BIG IS THE IMAGE REQUESTED (pseudocode follows)
            **
            **  if (IsRectEmpty (&rcTarget) {
            **      SetRect (&rcImage, 0, 0,
            **              BITMAPINFOHEADER.biWidth,
                            BITMAPINFOHEADER.biHeight);
            **  }
            **  else {
            **      // Probably rendering to a DirectDraw surface,
            **      // where biWidth is used to expressed the "stride"
            **      // in units of pixels (not bytes) of the destination surface.
            **      // Therefore, use rcTarget to get the actual image size
            **
            **      rcImage = rcTarget;
            **  }
            */

            if ((pVideoInfoHdrToVerify->rcTarget.right -
                 pVideoInfoHdrToVerify->rcTarget.left <= 0) ||
                (pVideoInfoHdrToVerify->rcTarget.bottom -
                 pVideoInfoHdrToVerify->rcTarget.top <= 0)) {

                 rcImage.left = rcImage.top = 0;
                 rcImage.right = pVideoInfoHdrToVerify->bmiHeader.biWidth;
                 rcImage.bottom = pVideoInfoHdrToVerify->bmiHeader.biHeight;
            }
            else {
                 rcImage = pVideoInfoHdrToVerify->rcTarget;
            }

            //
            // TODO, perform all other verification tests here!!!
            //

            //
            // HOORAY, the format passed all of the tests, so we support it
            //

            fOK = TRUE;
            break;

        } // End of VIDEOINFOHEADER specifier

#ifndef TOSHIBA
        // -------------------------------------------------------------------
        // Specifier FORMAT_AnalogVideo for KS_ANALOGVIDEOINFO
        // -------------------------------------------------------------------

        else if (IsEqualGUID (&pKSDataFormatToVerify->Specifier,
                &KSDATAFORMAT_SPECIFIER_ANALOGVIDEO)) {

            //
            // For analog video, the DataRange and DataFormat
            // are identical, so just copy the whole structure
            //

            PKS_DATARANGE_ANALOGVIDEO DataRangeVideo =
                    (PKS_DATARANGE_ANALOGVIDEO) *pAvailableFormats;

            //
            // TODO, perform all other verification tests here!!!
            //

            fOK = TRUE;
            break;

        } // End of KS_ANALOGVIDEOINFO specifier
#endif//TOSHIBA

    } // End of loop on all formats for this stream

    return fOK;
}

/*
** AdapterFormatFromRange()
**
**   Produces a DATAFORMAT given a DATARANGE.
**
**   Think of a DATARANGE as a multidimensional space of all of the possible image
**       sizes, cropping, scaling, and framerate possibilities.  Here, the caller
**       is saying "Out of this set of possibilities, could you verify that my
**       request is acceptable?".  The resulting singular output is a DATAFORMAT.
**       Note that each different colorspace (YUV vs RGB8 vs RGB24)
**       must be represented as a separate DATARANGE.
**
**   Generally, the resulting DATAFORMAT will be immediately used to open a stream
**       in that format.
**
** Arguments:
**
**         IN PHW_STREAM_REQUEST_BLOCK pSrb
**
** Returns:
**
**   TRUE if the format is supported
**   FALSE if the format cannot be suppored
**
** Side Effects:  none
*/

BOOL
STREAMAPI
AdapterFormatFromRange(
    IN PHW_STREAM_REQUEST_BLOCK pSrb
    )
{
    PSTREAM_DATA_INTERSECT_INFO IntersectInfo;
    PKSDATARANGE                DataRange;
    BOOL                        OnlyWantsSize;
    BOOL                        MatchFound = FALSE;
    ULONG                       FormatSize;
    ULONG                       StreamNumber;
    ULONG                       j;
    ULONG                       NumberOfFormatArrayEntries;
    PKSDATAFORMAT               *pAvailableFormats;

    IntersectInfo = pSrb->CommandData.IntersectInfo;
    StreamNumber = IntersectInfo->StreamNumber;
    DataRange = IntersectInfo->DataRange;

    //
    // Check that the stream number is valid
    //

    if (StreamNumber >= DRIVER_STREAM_COUNT) {
        pSrb->Status = STATUS_NOT_IMPLEMENTED;
        TRAP;
        return FALSE;
    }

    NumberOfFormatArrayEntries =
            Streams[StreamNumber].hwStreamInfo.NumberOfFormatArrayEntries;

    //
    // Get the pointer to the array of available formats
    //

    pAvailableFormats = Streams[StreamNumber].hwStreamInfo.StreamFormatsArray;

    //
    // Is the caller trying to get the format, or the size of the format?
    //

    OnlyWantsSize = (IntersectInfo->SizeOfDataFormatBuffer == sizeof(ULONG));

    //
    // Walk the formats supported by the stream searching for a match
    // of the three GUIDs which together define a DATARANGE
    //

    for (j = 0; j < NumberOfFormatArrayEntries; j++, pAvailableFormats++) {

        if (!AdapterCompareGUIDsAndFormatSize(
                        DataRange,
                        *pAvailableFormats,
                        TRUE /* CompareFormatSize */)) {
            continue;
        }

        //
        // Now that the three GUIDs match, switch on the Specifier
        // to do a further type-specific check
        //

        // -------------------------------------------------------------------
        // Specifier FORMAT_VideoInfo for VIDEOINFOHEADER
        // -------------------------------------------------------------------

        if (IsEqualGUID (&DataRange->Specifier,
                &KSDATAFORMAT_SPECIFIER_VIDEOINFO)) {

            PKS_DATARANGE_VIDEO DataRangeVideoToVerify =
                    (PKS_DATARANGE_VIDEO) DataRange;
            PKS_DATARANGE_VIDEO DataRangeVideo =
                    (PKS_DATARANGE_VIDEO) *pAvailableFormats;
            PKS_DATAFORMAT_VIDEOINFOHEADER DataFormatVideoInfoHeaderOut;

            //
            // Check that the other fields match
            //
            if ((DataRangeVideoToVerify->bFixedSizeSamples != DataRangeVideo->bFixedSizeSamples) ||
                (DataRangeVideoToVerify->bTemporalCompression != DataRangeVideo->bTemporalCompression) ||
                (DataRangeVideoToVerify->StreamDescriptionFlags != DataRangeVideo->StreamDescriptionFlags) ||
                (DataRangeVideoToVerify->MemoryAllocationFlags != DataRangeVideo->MemoryAllocationFlags) ||
                (RtlCompareMemory (&DataRangeVideoToVerify->ConfigCaps,
                        &DataRangeVideo->ConfigCaps,
                        sizeof (KS_VIDEO_STREAM_CONFIG_CAPS)) !=
                        sizeof (KS_VIDEO_STREAM_CONFIG_CAPS))) {
                continue;
            }

            // MATCH FOUND!
            MatchFound = TRUE;
            FormatSize = sizeof (KSDATAFORMAT) +
                KS_SIZE_VIDEOHEADER (&DataRangeVideoToVerify->VideoInfoHeader);

            if (OnlyWantsSize) {
                break;
            }

            // Caller wants the full data format
            if (IntersectInfo->SizeOfDataFormatBuffer < FormatSize) {
                pSrb->Status = STATUS_BUFFER_TOO_SMALL;
                return FALSE;
            }

            // Copy over the KSDATAFORMAT, followed by the
            // actual VideoInfoHeader

            DataFormatVideoInfoHeaderOut = (PKS_DATAFORMAT_VIDEOINFOHEADER) IntersectInfo->DataFormatBuffer;

            // Copy over the KSDATAFORMAT
            RtlCopyMemory(
                &DataFormatVideoInfoHeaderOut->DataFormat,
                &DataRangeVideoToVerify->DataRange,
                sizeof (KSDATARANGE));

            DataFormatVideoInfoHeaderOut->DataFormat.FormatSize = FormatSize;

            // Copy over the callers requested VIDEOINFOHEADER

            RtlCopyMemory(
                &DataFormatVideoInfoHeaderOut->VideoInfoHeader,
                &DataRangeVideoToVerify->VideoInfoHeader,
                KS_SIZE_VIDEOHEADER (&DataRangeVideoToVerify->VideoInfoHeader));

            // Calculate biSizeImage for this request, and put the result in both
            // the biSizeImage field of the bmiHeader AND in the SampleSize field
            // of the DataFormat.
            //
            // Note that for compressed sizes, this calculation will probably not
            // be just width * height * bitdepth

            DataFormatVideoInfoHeaderOut->VideoInfoHeader.bmiHeader.biSizeImage =
                DataFormatVideoInfoHeaderOut->DataFormat.SampleSize =
                KS_DIBSIZE(DataFormatVideoInfoHeaderOut->VideoInfoHeader.bmiHeader);

            //
            // TODO Perform other validation such as cropping and scaling checks
            //

            break;

        } // End of VIDEOINFOHEADER specifier

#ifndef TOSHIBA
        // -------------------------------------------------------------------
        // Specifier FORMAT_AnalogVideo for KS_ANALOGVIDEOINFO
        // -------------------------------------------------------------------

        else if (IsEqualGUID (&DataRange->Specifier,
                &KSDATAFORMAT_SPECIFIER_ANALOGVIDEO)) {

            //
            // For analog video, the DataRange and DataFormat
            // are identical, so just copy the whole structure
            //

            PKS_DATARANGE_ANALOGVIDEO DataRangeVideo =
                    (PKS_DATARANGE_ANALOGVIDEO) *pAvailableFormats;

            // MATCH FOUND!
            MatchFound = TRUE;
            FormatSize = sizeof (KS_DATARANGE_ANALOGVIDEO);

            if (OnlyWantsSize) {
                break;
            }

            // Caller wants the full data format
            if (IntersectInfo->SizeOfDataFormatBuffer < FormatSize) {
                pSrb->Status = STATUS_BUFFER_TOO_SMALL;
                return FALSE;
            }

            RtlCopyMemory(
                IntersectInfo->DataFormatBuffer,
                DataRangeVideo,
                sizeof (KS_DATARANGE_ANALOGVIDEO));

            ((PKSDATAFORMAT)IntersectInfo->DataFormatBuffer)->FormatSize = FormatSize;

            break;

        } // End of KS_ANALOGVIDEOINFO specifier
#endif//TOSHIBA

        else {
            pSrb->Status = STATUS_NO_MATCH;
            return FALSE;
        }

    } // End of loop on all formats for this stream

    if (OnlyWantsSize) {
        *(PULONG) IntersectInfo->DataFormatBuffer = FormatSize;
        pSrb->ActualBytesTransferred = sizeof(ULONG);
        return TRUE;
    }
    pSrb->ActualBytesTransferred = FormatSize;
    return TRUE;
}























=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\drivers\wdm\capture\mini\tecra750\capmain.h ===
//==========================================================================;
//
//  THIS CODE AND INFORMATION IS PROVIDED "AS IS" WITHOUT WARRANTY OF ANY
//  KIND, EITHER EXPRESSED OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE
//  IMPLIED WARRANTIES OF MERCHANTABILITY AND/OR FITNESS FOR A PARTICULAR
//  PURPOSE.
//
//  Copyright (c) 1992 - 1996  Microsoft Corporation.  All Rights Reserved.
//
//==========================================================================;

#ifndef __CAPMAIN_H__
#define __CAPMAIN_H__

#ifdef __cplusplus
extern "C" {
#endif // __cplusplus

#ifdef  TOSHIBA
//#define _FPS_COUNT_     // For FPS confirm
#endif//TOSHIBA

#ifndef FIELDOFFSET
#define FIELDOFFSET(type, field)        (int)((INT_PTR)(&((type *)1)->field)-1)
#endif

#ifndef mmioFOURCC
#define mmioFOURCC( ch0, ch1, ch2, ch3 )                                \
                ( (DWORD)(BYTE)(ch0) | ( (DWORD)(BYTE)(ch1) << 8 ) |    \
                ( (DWORD)(BYTE)(ch2) << 16 ) | ( (DWORD)(BYTE)(ch3) << 24 ) )
#endif

#ifdef  TOSHIBA
#define FOURCC_YVU9             mmioFOURCC('Y', 'V', 'U', '9')
#define FOURCC_YUV12            mmioFOURCC('I', '4', '2', '0')
#else //TOSHIBA
#define FOURCC_YUV422           mmioFOURCC('U', 'Y', 'V', 'Y')
#endif//TOSHIBA

typedef struct _STREAMX;
typedef struct _STREAMX *PSTREAMX;

#ifdef  TOSHIBA
#define MAX_TSBVCAP_STREAMS 2
#else //TOSHIBA
#define MAX_TSBVCAP_STREAMS 4
#endif//TOSHIBA

#ifdef  TOSHIBA
/* possible capture formats */
typedef enum _CAPTUREFORMAT {
    FmtInvalid = 0,             // default fmt is 'not set yet'
    FmtYUV12,                   // yuv12 planar
    FmtYUV9,                    // yuv9 planar
    MaxCaptureFormat
} CAPTUREFORMAT;
#endif//TOSHIBA

typedef struct _COMPRESSION_SETTINGS {
    LONG                     CompressionKeyFrameRate;
    LONG                     CompressionPFramesPerKeyFrame;
    LONG                     CompressionQuality;
} COMPRESSION_SETTINGS, *PCOMPRESSION_SETTINGS;

//
// definition of the full HW device extension structure This is the structure
// that will be allocated in HW_INITIALIZATION by the stream class driver
// Any information that is used in processing a device request (as opposed to
// a STREAM based request) should be in this structure.  A pointer to this
// structure will be passed in all requests to the minidriver. (See
// HW_STREAM_REQUEST_BLOCK in STRMINI.H)
//

typedef struct _HW_DEVICE_EXTENSION {
    PULONG                   ioBaseLocal;                           // board base address
    USHORT                   Irq;                                   // IRQ level
    BOOLEAN                  IRQExpected;                           // IRQ expected
    PSTREAMX                 pStrmEx [MAX_TSBVCAP_STREAMS];         // Pointers to each stream
    UINT                     ActualInstances [MAX_TSBVCAP_STREAMS]; // Counter of instances per stream
    PDEVICE_OBJECT           PDO;                                   // Physical Device Object
    DEVICE_POWER_STATE       DeviceState;                           // D0 ... D3

    // Spinlock and Queue for the Adapter
    BOOL                     AdapterQueueInitialized;               // Stays TRUE after first init
    KSPIN_LOCK               AdapterSpinLock;                       // Multiprocessor safe access to AdapterSRBList
    LIST_ENTRY               AdapterSRBList;                        // List of pending adapter commands
    BOOL                     ProcessingAdapterSRB;                  // Master flag which prevents reentry

    // Spinlocks and Queues for each data stream
    LIST_ENTRY               StreamSRBList[MAX_TSBVCAP_STREAMS];    // List of pending read requests
    KSPIN_LOCK               StreamSRBSpinLock[MAX_TSBVCAP_STREAMS];// Multiprocessor safe access to StreamSRBList
    int                      StreamSRBListSize[MAX_TSBVCAP_STREAMS];// Number of entries in the list

    // Control Queues for each data stream
    LIST_ENTRY               StreamControlSRBList[MAX_TSBVCAP_STREAMS];
    BOOL                     ProcessingControlSRB[MAX_TSBVCAP_STREAMS];

#ifdef  TOSHIBA
    // VideoProcAmp settings
    LONG                     Brightness;
    LONG                     BrightnessFlags;
    LONG                     Contrast;
    LONG                     ContrastFlags;
    LONG                     Hue;
    LONG                     HueFlags;
    LONG                     Saturation;
    LONG                     SaturationFlags;
    LONG                     ColorEnable;
    LONG                     ColorEnableFlags;

    // VideoControl settings (these are set if a pin is not opened,
    // otherwise, the STREAMEX values are used.
    LONG                     VideoControlMode;

    // Compressor settings (these are set if a pin is not opened,
    // otherwise, the STREAMEX values are used.
    COMPRESSION_SETTINGS     CompressionSettings;

#ifdef  TOSHIBA // '98-12-09 Added, for Bug-Report 253529
    KSPROPERTY_BOUNDS_LONG   BrightnessRange;
    KSPROPERTY_BOUNDS_LONG   ContrastRange;
    KSPROPERTY_BOUNDS_LONG   HueRange;
    KSPROPERTY_BOUNDS_LONG   SaturationRange;
#endif//TOSHIBA

    // Misc
    volatile BOOL            bVideoIn;  // are we actually doing video in ?
    CAPTUREFORMAT            Format;    // format of destination DIB
    DWORD                    dwAsicRev;
    // source rectangle data
    RECT                     SrcRect;
    RECT                     MaxRect;
    // driver DMA structures for direct io
    PVOID                    pRpsDMABuf;    // pointer to the RPS DMA buffer
    STREAM_PHYSICAL_ADDRESS  pPhysRpsDMABuf;// physical address of RPS DMA buffer
    // driver capture buffer information
    PVOID                    pCaptureBufferY;
    PVOID                    pCaptureBufferU;
    PVOID                    pCaptureBufferV;
    STREAM_PHYSICAL_ADDRESS  pPhysCaptureBufferY;
    STREAM_PHYSICAL_ADDRESS  pPhysCaptureBufferU;
    STREAM_PHYSICAL_ADDRESS  pPhysCaptureBufferV;
    PVOID                    pCapBuf2Y;
    PVOID                    pCapBuf2U;
    PVOID                    pCapBuf2V;
    STREAM_PHYSICAL_ADDRESS  pPhysCapBuf2Y;
    STREAM_PHYSICAL_ADDRESS  pPhysCapBuf2U;
    STREAM_PHYSICAL_ADDRESS  pPhysCapBuf2V;
    BOOL                     dblBufflag;
    //  configuration parameters for the video source and the format
    ULONG                    ulWidth;
    ULONG                    ulHeight;
    ULONG                    BufferSize;
    // RequestDpc flag for CaptureService
    BOOL                     bRequestDpc;
    volatile BOOLEAN         DpcRequested;

    unsigned                 uiFramePerSecond;
    volatile DWORD           s_physDmaActiveFlag;

    DWORD                    YoffsetOdd;
    DWORD                    UoffsetOdd;
    DWORD                    VoffsetOdd;

    DWORD                    YoffsetEven;
    DWORD                    UoffsetEven;
    DWORD                    VoffsetEven;

    DWORD                    Ystride;
    DWORD                    Ustride;
    DWORD                    Vstride;

    BOOL                     NeedCameraON;
    BOOL                     NeedCameraOFF;
    BOOL                     NeedHWInit;
    BOOL                     IsRPSReady;
#else //TOSHIBA
    // Unique identifier for the analog video input pin
    KSPIN_MEDIUM             AnalogVideoInputMedium;

    // Crossbar settings
    LONG                     VideoInputConnected;                   // which input is the video out connected to?
    LONG                     AudioInputConnected;                   // which input is the audio out connected to?

    // TV Tuner settings
    ULONG                    Frequency;
    ULONG                    VideoStandard;
    ULONG                    TuningQuality;
    ULONG                    TunerInput;
    ULONG                    Busy;

    // TV Audio settings
    ULONG                    TVAudioMode;

    // VideoProcAmp settings
    LONG                     Brightness;
    LONG                     BrightnessFlags;
    LONG                     Contrast;
    LONG                     ContrastFlags;
    LONG                     ColorEnable;
    LONG                     ColorEnableFlags;

    // CameraControl settings
    LONG                     Focus;
    LONG                     FocusFlags;
    LONG                     Zoom;
    LONG                     ZoomFlags;

    // AnalogVideoDecoder settings
    LONG                     VideoDecoderVideoStandard;
    LONG                     VideoDecoderOutputEnable;
    LONG                     VideoDecoderVCRTiming;

    // VideoControl settings (these are set if a pin is not opened,
    // otherwise, the STREAMEX values are used.
    LONG                     VideoControlMode;

    // Compressor settings (these are set if a pin is not opened,
    // otherwise, the STREAMEX values are used.
    COMPRESSION_SETTINGS     CompressionSettings;

    // Channel Change information
    KS_TVTUNER_CHANGE_INFO   TVTunerChangeInfo;
#endif//TOSHIBA

} HW_DEVICE_EXTENSION, *PHW_DEVICE_EXTENSION;

//
// this structure is our per stream extension structure.  This stores
// information that is relevant on a per stream basis.  Whenever a new stream
// is opened, the stream class driver will allocate whatever extension size
// is specified in the HwInitData.PerStreamExtensionSize.
//

typedef struct _STREAMEX {
    PHW_DEVICE_EXTENSION        pHwDevExt;          // For timer use
    PHW_STREAM_OBJECT           pStreamObject;      // For timer use
    KS_VIDEOINFOHEADER         *pVideoInfoHeader;   // format (variable size!)
    KS_FRAME_INFO               FrameInfo;          // PictureNumber, etc.
    ULONG                       fDiscontinuity;     // Discontinuity since last valid
    KSSTATE                     KSState;            // Run, Stop, Pause
    UCHAR                       LineBuffer[720 * 3];// working buffer (RGB24)

    // Clock
    HANDLE                      hMasterClock;       // Master clock to use
    REFERENCE_TIME              QST_Now;            // KeQuerySystemTime currently
    REFERENCE_TIME              QST_NextFrame;      // When to capture the next frame
    REFERENCE_TIME              QST_StreamTime;     // Stream time reported by master clock

    // Compressor settings (note these are duplicated in the
    // HW_DEVICE_EXTENSION to allow setting these before a pin is created)
    COMPRESSION_SETTINGS        CompressionSettings;

    // VideoControl settings (note these are duplicated in the
    // HW_DEVICE_EXTENSION to allow setting these before a pin is created)
    LONG                        VideoControlMode;

    // Kernel DDraw interface
    BOOL                        KernelDirectDrawRegistered;
    HANDLE                      UserDirectDrawHandle;       // DD itself
    HANDLE                      KernelDirectDrawHandle;
    BOOL                        PreEventOccurred;
    BOOL                        PostEventOccurred;
} STREAMEX, *PSTREAMEX;

//
// this structure defines the per request extension.  It defines any storage
// space that the mini driver may need in each request packet.
//

typedef struct _SRB_EXTENSION {
    LIST_ENTRY                  ListEntry;
    PHW_STREAM_REQUEST_BLOCK    pSrb;
    HANDLE                      UserSurfaceHandle;      // DDraw
    HANDLE                      KernelSurfaceHandle;    // DDraw
} SRB_EXTENSION, * PSRB_EXTENSION;

// -------------------------------------------------------------------
//
// Adapter level prototypes
//
// These functions affect the device as a whole, as opposed to
// affecting individual streams.
//
// -------------------------------------------------------------------

//
// DriverEntry:
//
// This routine is called when the mini driver is first loaded.  The driver
// should then call the StreamClassRegisterAdapter function to register with
// the stream class driver
//

ULONG DriverEntry (PVOID Context1, PVOID Context2);

#ifdef  TOSHIBA
VOID GetPCIConfigSpace(PHW_STREAM_REQUEST_BLOCK pSrb);
#endif//TOSHIBA

//
// This routine is called by the stream class driver with configuration
// information for an adapter that the mini driver should load on.  The mini
// driver should still perform a small verification to determine that the
// adapter is present at the specified addresses, but should not attempt to
// find an adapter as it would have with previous NT miniports.
//
// All initialization of the adapter should also be performed at this time.
//

BOOL STREAMAPI HwInitialize (IN OUT PHW_STREAM_REQUEST_BLOCK pSrb);

//
// This routine is called when the system is going to remove or disable the
// device.
//
// The mini-driver should free any system resources that it allocated at this
// time.  Note that system resources allocated for the mini-driver by the
// stream class driver will be free'd by the stream driver, and should not be
// free'd in this routine.  (Such as the HW_DEVICE_EXTENSION)
//

BOOL STREAMAPI HwUnInitialize ( PHW_STREAM_REQUEST_BLOCK pSrb);

//
// This is the prototype for the Hardware Interrupt Handler.  This routine
// will be called whenever the minidriver receives an interrupt
//

BOOLEAN HwInterrupt ( IN PHW_DEVICE_EXTENSION pDeviceExtension );

//
// This is the prototype for the stream enumeration function.  This routine
// provides the stream class driver with the information on data stream types
// supported
//

VOID STREAMAPI AdapterStreamInfo(PHW_STREAM_REQUEST_BLOCK pSrb);

//
// This is the prototype for the stream open function
//

VOID STREAMAPI AdapterOpenStream(PHW_STREAM_REQUEST_BLOCK pSrb);

//
// This is the prototype for the stream close function
//

VOID STREAMAPI AdapterCloseStream(PHW_STREAM_REQUEST_BLOCK pSrb);

//
// This is the prototype for the AdapterReceivePacket routine.  This is the
// entry point for command packets that are sent to the adapter (not to a
// specific open stream)
//

VOID STREAMAPI AdapterReceivePacket(IN PHW_STREAM_REQUEST_BLOCK Srb);

//
// This is the protoype for the cancel packet routine.  This routine enables
// the stream class driver to cancel an outstanding packet.
//

VOID STREAMAPI AdapterCancelPacket(IN PHW_STREAM_REQUEST_BLOCK Srb);

//
// This is the packet timeout function.  The adapter may choose to ignore a
// packet timeout, or rest the adapter and cancel the requests, as required.
//

VOID STREAMAPI AdapterTimeoutPacket(IN PHW_STREAM_REQUEST_BLOCK Srb);

//
// Adapter level property set handling
//

VOID STREAMAPI AdapterGetCrossbarProperty(IN PHW_STREAM_REQUEST_BLOCK pSrb);
VOID STREAMAPI AdapterSetCrossbarProperty(IN PHW_STREAM_REQUEST_BLOCK pSrb);
VOID STREAMAPI AdapterSetTunerProperty(IN PHW_STREAM_REQUEST_BLOCK pSrb);
VOID STREAMAPI AdapterGetTunerProperty(IN PHW_STREAM_REQUEST_BLOCK pSrb);
VOID STREAMAPI AdapterSetVideoProcAmpProperty(IN PHW_STREAM_REQUEST_BLOCK pSrb);
VOID STREAMAPI AdapterGetVideoProcAmpProperty(IN PHW_STREAM_REQUEST_BLOCK pSrb);
VOID STREAMAPI AdapterSetCameraControlProperty(IN PHW_STREAM_REQUEST_BLOCK pSrb);
VOID STREAMAPI AdapterGetCameraControlProperty(IN PHW_STREAM_REQUEST_BLOCK pSrb);
VOID STREAMAPI AdapterSetTVAudioProperty(IN PHW_STREAM_REQUEST_BLOCK pSrb);
VOID STREAMAPI AdapterGetTVAudioProperty(IN PHW_STREAM_REQUEST_BLOCK pSrb);
VOID STREAMAPI AdapterSetAnalogVideoDecoderProperty(IN PHW_STREAM_REQUEST_BLOCK pSrb);
VOID STREAMAPI AdapterGetAnalogVideoDecoderProperty(IN PHW_STREAM_REQUEST_BLOCK pSrb);
VOID STREAMAPI AdapterSetVideoControlProperty(IN PHW_STREAM_REQUEST_BLOCK pSrb);
VOID STREAMAPI AdapterGetVideoControlProperty(IN PHW_STREAM_REQUEST_BLOCK pSrb);
VOID STREAMAPI AdapterGetVideoCompressionProperty(IN PHW_STREAM_REQUEST_BLOCK pSrb);
VOID STREAMAPI AdapterSetVideoCompressionProperty(IN PHW_STREAM_REQUEST_BLOCK pSrb);
VOID STREAMAPI AdapterSetProperty(IN PHW_STREAM_REQUEST_BLOCK pSrb);
VOID STREAMAPI AdapterGetProperty(IN PHW_STREAM_REQUEST_BLOCK pSrb);

BOOL
STREAMAPI
AdapterVerifyFormat(
        PKSDATAFORMAT pKSDataFormatToVerify,
        int StreamNumber);

BOOL
STREAMAPI
AdapterFormatFromRange(
        IN PHW_STREAM_REQUEST_BLOCK pSrb);

VOID
STREAMAPI
CompleteDeviceSRB (
         IN PHW_STREAM_REQUEST_BLOCK pSrb
        );

VOID
STREAMAPI
AdapterSetInstance (
    PHW_STREAM_REQUEST_BLOCK pSrb
    );


//
// prototypes for general queue management using a busy flag
//

BOOL
STREAMAPI
AddToListIfBusy (
    IN PHW_STREAM_REQUEST_BLOCK pSrb,
    IN KSPIN_LOCK              *SpinLock,
    IN OUT BOOL                *BusyFlag,
    IN LIST_ENTRY              *ListHead
    );

BOOL
STREAMAPI
RemoveFromListIfAvailable (
    IN OUT PHW_STREAM_REQUEST_BLOCK *pSrb,
    IN KSPIN_LOCK                   *SpinLock,
    IN OUT BOOL                     *BusyFlag,
    IN LIST_ENTRY                   *ListHead
    );


// -------------------------------------------------------------------
//
// Stream level prototypes
//
// These functions affect individual streams, as opposed to
// affecting the device as a whole.
//
// -------------------------------------------------------------------

//
// Routines to manage the SRB queue on a per stream basis
//

VOID
STREAMAPI
VideoQueueAddSRB (
    IN PHW_STREAM_REQUEST_BLOCK pSrb
    );

PHW_STREAM_REQUEST_BLOCK
STREAMAPI
VideoQueueRemoveSRB (
    PHW_DEVICE_EXTENSION pHwDevExt,
    int StreamNumber
    );

VOID
STREAMAPI
VideoQueueCancelAllSRBs (
    PSTREAMEX pStrmEx
    );

BOOL
STREAMAPI
VideoQueueCancelOneSRB (
    PSTREAMEX pStrmEx,
    PHW_STREAM_REQUEST_BLOCK pSrbToCancel
    );

//
// Data packet handlers
//
//
// prototypes for data handling routines
//
VOID STREAMAPI CompleteStreamSRB (IN PHW_STREAM_REQUEST_BLOCK pSrb);
BOOL STREAMAPI VideoSetFormat(IN PHW_STREAM_REQUEST_BLOCK pSrb);
VOID STREAMAPI VideoReceiveDataPacket(IN PHW_STREAM_REQUEST_BLOCK pSrb);
VOID STREAMAPI VideoReceiveCtrlPacket(IN PHW_STREAM_REQUEST_BLOCK pSrb);
VOID STREAMAPI AnalogVideoReceiveDataPacket(IN PHW_STREAM_REQUEST_BLOCK pSrb);
VOID STREAMAPI AnalogVideoReceiveCtrlPacket(IN PHW_STREAM_REQUEST_BLOCK pSrb);

VOID STREAMAPI EnableIRQ(PHW_STREAM_OBJECT pstrm);
VOID STREAMAPI DisableIRQ(PHW_STREAM_OBJECT pstrm);

//
// prototypes for properties and states
//

VOID STREAMAPI VideoSetState(PHW_STREAM_REQUEST_BLOCK pSrb);
VOID STREAMAPI VideoGetState(PHW_STREAM_REQUEST_BLOCK pSrb);
VOID STREAMAPI VideoSetProperty(PHW_STREAM_REQUEST_BLOCK pSrb);
VOID STREAMAPI VideoGetProperty(PHW_STREAM_REQUEST_BLOCK pSrb);
VOID STREAMAPI VideoStreamGetConnectionProperty (PHW_STREAM_REQUEST_BLOCK pSrb);
VOID STREAMAPI VideoStreamGetDroppedFramesProperty(PHW_STREAM_REQUEST_BLOCK pSrb);

//
// stream clock functions
//
VOID
STREAMAPI
VideoIndicateMasterClock (PHW_STREAM_REQUEST_BLOCK pSrb);

ULONGLONG
STREAMAPI
VideoGetSystemTime();

//
// The point of it all
//
VOID
STREAMAPI
VideoCaptureRoutine(
    IN PSTREAMEX pStrmEx
    );

#ifdef  TOSHIBA
VOID
DeferredRoutine(
    PKDPC          pDpc,
    PDEVICE_OBJECT pDeviceObject,
    PIRP           pIrpNotUsed,
    PVOID          Context
    );

ULONG
get_AblFilter (
    PHW_DEVICE_EXTENSION pHwDevExt
    );

ULONG
get_filtering (
    PHW_DEVICE_EXTENSION pHwDevExt
    );

VOID
set_filtering (
    PHW_DEVICE_EXTENSION pHwDevExt,
    BOOL bFlag
    );

NTKERNELAPI
PHYSICAL_ADDRESS
MmGetPhysicalAddress (
    IN PVOID BaseAddress
    );

NTKERNELAPI
PVOID
MmAllocateContiguousMemory (
    IN ULONG NumberOfBytes,
    IN PHYSICAL_ADDRESS HighestAcceptableAddress
    );

NTKERNELAPI
VOID
MmFreeContiguousMemory (
    IN PVOID BaseAddress
    );
#endif//TOSHIBA

#ifdef    __cplusplus
}
#endif // __cplusplus

#endif //__CAPMAIN_H__
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\drivers\wdm\capture\mini\tecra750\capprop.c ===
//==========================================================================;
//
//  THIS CODE AND INFORMATION IS PROVIDED "AS IS" WITHOUT WARRANTY OF ANY
//  KIND, EITHER EXPRESSED OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE
//  IMPLIED WARRANTIES OF MERCHANTABILITY AND/OR FITNESS FOR A PARTICULAR
//  PURPOSE.
//
//  Copyright (c) 1992 - 1996  Microsoft Corporation.  All Rights Reserved.
//
//==========================================================================;

//
// This file handles all adapter property sets
//


#include "strmini.h"
#include "ksmedia.h"
#include "capmain.h"
#include "capdebug.h"
#ifdef  TOSHIBA
#include "bert.h"
#endif//TOSHIBA
#define DEFINE_MEDIUMS
#include "mediums.h"

#ifdef  TOSHIBA
ULONG
get_AblFilter (
    PHW_DEVICE_EXTENSION pHwDevExt
    )
{
    return( HW_ReadFilter( pHwDevExt, TRUE ) );
}

ULONG
get_filtering (
    PHW_DEVICE_EXTENSION pHwDevExt
    )
{
    return( HW_ReadFilter( pHwDevExt, FALSE ) );
}

VOID
set_filtering (
    PHW_DEVICE_EXTENSION pHwDevExt, BOOL bFlag
    )
{
    HW_SetFilter( pHwDevExt, bFlag );
}
#endif//TOSHIBA

// -------------------------------------------------------------------
// A few notes about property set handling
//
// Property sets used in TsbVcap are of two varieties, those that have
// default values, ranges, and stepping, such as VideoProcAmp and CameraControl,
// and those which don't have defaults and ranges, such as TVTuner and
// Crossbar.
//
// Default values and stepping are established by tables in capprop.h,
// no code is required to implement this other than initally creating the tables.
//
// Many of the property sets require the ability to modify a number
// of input parameters.  Since KS doesn't allow this inherently, you'll
// note that some property sets require copying the provided input parameters
// to the ouput parameter list, effectively creating a "read, modify, write"
// capability.  For this reason, the input and output parameter lists
// use identical structures.
//
// On an SRB_GET_DEVICE_PROPERTY, read-only input data to the driver is provided as:
//      pSrb->CommandData.PropertyInfo
//
// ... while the output data pointer is:
//      pSrb->CommandData.PropertyInfo.PropertyInfo
//
// -------------------------------------------------------------------


#ifndef TOSHIBA
// -------------------------------------------------------------------
// XBar pin definitions
// -------------------------------------------------------------------

typedef struct _XBAR_PIN_DESCRIPTION {
    ULONG       PinType;
    ULONG       SynthImageCommand;    // This driver simulates different inputs by synthesizing images
    ULONG       RelatedPinIndex;
    const KSPIN_MEDIUM *Medium;               // Describes hardware connectivity
} XBAR_PIN_DESCRIPTION, *PXBAR_PIN_DESCRIPTION;


XBAR_PIN_DESCRIPTION XBarInputPins[] = {

    // First list the video input pins, then the audio inputs, then the output pins
    // Note that audio pin index 6 is shared between two video inputs (index 1 and index 2)


    //    PinType                       SynthImageCommand                     RelatedPinIndex   Medium
    /*0*/ KS_PhysConn_Video_Tuner,         IMAGE_XFER_NTSC_EIA_100AMP_100SAT,    5,             &CrossbarMediums[0],
    /*1*/ KS_PhysConn_Video_Composite,     IMAGE_XFER_NTSC_EIA_75AMP_100SAT,     6,             &CrossbarMediums[1],
    /*2*/ KS_PhysConn_Video_SVideo,        IMAGE_XFER_BLACK,                     6,             &CrossbarMediums[2],
    /*3*/ KS_PhysConn_Video_Tuner,         IMAGE_XFER_WHITE,                     7,             &CrossbarMediums[3],
    /*4*/ KS_PhysConn_Video_Composite,     IMAGE_XFER_GRAY_INCREASING,           8,             &CrossbarMediums[4],

    /*5*/ KS_PhysConn_Audio_Tuner,         0,                                    0,             &CrossbarMediums[5],
    /*6*/ KS_PhysConn_Audio_Line,          0,                                    1,             &CrossbarMediums[6],
    /*7*/ KS_PhysConn_Audio_Tuner,         0,                                    3,             &CrossbarMediums[7],
    /*8*/ KS_PhysConn_Audio_Line,          0,                                    4,             &CrossbarMediums[8],

};
#define NUMBER_OF_XBAR_INPUTS       (SIZEOF_ARRAY (XBarInputPins))


XBAR_PIN_DESCRIPTION XBarOutputPins[] = {

    //    PinType                       SynthImageCommand                     RelatedPinIndex

    /*0*/ KS_PhysConn_Video_VideoDecoder,  0,                                    1,             &CrossbarMediums[9],
    /*1*/ KS_PhysConn_Audio_AudioDecoder,  0,                                    0,             &CrossbarMediums[10],
};
#define NUMBER_OF_XBAR_OUTPUTS      (SIZEOF_ARRAY (XBarOutputPins))

#define NUMBER_OF_XBAR_PINS_TOTAL   (NUMBER_OF_XBAR_INPUTS + NUMBER_OF_XBAR_OUTPUTS)


// -------------------------------------------------------------------
// XBar Property Set functions
// -------------------------------------------------------------------

/*
** AdapterSetCrossbarProperty ()
**
**    Handles Set operations on the Crossbar property set.
**      TsbVcap uses this to select an image to synthesize.
**
** Arguments:
**
**      pSRB -
**          Pointer to the HW_STREAM_REQUEST_BLOCK
**
** Returns:
**
** Side Effects:  none
*/

VOID
STREAMAPI
AdapterSetCrossbarProperty(
    PHW_STREAM_REQUEST_BLOCK pSrb
    )
{
    PHW_DEVICE_EXTENSION pHwDevExt = ((PHW_DEVICE_EXTENSION)pSrb->HwDeviceExtension);
    PSTREAM_PROPERTY_DESCRIPTOR pSPD = pSrb->CommandData.PropertyInfo;
    ULONG Id  = pSPD->Property->Id;              // index of the property
    ULONG nS  = pSPD->PropertyOutputSize;        // size of data supplied

    switch (Id) {
    case KSPROPERTY_CROSSBAR_ROUTE:                       //  W
    {
        PKSPROPERTY_CROSSBAR_ROUTE_S  pRoute =
            (PKSPROPERTY_CROSSBAR_ROUTE_S)pSPD->PropertyInfo;

        ASSERT (nS >= sizeof (KSPROPERTY_CROSSBAR_ROUTE_S));

        // Copy the input property info to the output property info
        RtlCopyMemory(  pRoute,
                        pSPD->Property,
                        sizeof (KSPROPERTY_CROSSBAR_ROUTE_S));


        // Default to failure
        pRoute->CanRoute = 0;

        // if video
        if (pRoute->IndexOutputPin == 0) {
            if (pRoute->IndexInputPin <= 4) {
                pHwDevExt->VideoInputConnected = pRoute->IndexInputPin;
                pRoute->CanRoute = 1;
            }
        }
        // if audio
        else if (pRoute->IndexOutputPin == 1) {
            // Special case!  Audio Routing of (-1) means mute!!!
            if (pRoute->IndexInputPin == -1) {
                pHwDevExt->AudioInputConnected = pRoute->IndexInputPin;
                pRoute->CanRoute = 1;
            }
            else if (pRoute->IndexInputPin > 4 && pRoute->IndexInputPin <= 8) {
                pHwDevExt->AudioInputConnected = pRoute->IndexInputPin;
                pRoute->CanRoute = 1;
            }
        }

        // Somebody passed bogus data
        if (pRoute->CanRoute == 0) {
            pSrb->Status = STATUS_INVALID_PARAMETER;
        }
    }
    break;


    default:
        TRAP
        break;
    }
}

/*
** AdapterGetCrossbarProperty ()
**
**    Handles Get operations on the Crossbar property set.
**      TsbVcap uses this to select an image to synthesize.
**
** Arguments:
**
**      pSRB -
**          Pointer to the HW_STREAM_REQUEST_BLOCK
**
** Returns:
**
** Side Effects:  none
*/

VOID
STREAMAPI
AdapterGetCrossbarProperty(
    PHW_STREAM_REQUEST_BLOCK pSrb
    )
{
    PHW_DEVICE_EXTENSION pHwDevExt = ((PHW_DEVICE_EXTENSION)pSrb->HwDeviceExtension);
    PSTREAM_PROPERTY_DESCRIPTOR pSPD = pSrb->CommandData.PropertyInfo;
    ULONG Id  = pSPD->Property->Id;              // index of the property
    ULONG nS  = pSPD->PropertyOutputSize;        // size of data supplied

    switch (Id) {

    case KSPROPERTY_CROSSBAR_CAPS:                  // R
    {
        PKSPROPERTY_CROSSBAR_CAPS_S  pCaps =
            (PKSPROPERTY_CROSSBAR_CAPS_S)pSPD->PropertyInfo;

        if (nS < sizeof (KSPROPERTY_CROSSBAR_CAPS_S))
            break;

        // Copy the input property info to the output property info
        RtlCopyMemory(  pCaps,
                        pSPD->Property,
                        sizeof (KSPROPERTY_CROSSBAR_CAPS_S));

        pCaps->NumberOfInputs  = NUMBER_OF_XBAR_INPUTS;
        pCaps->NumberOfOutputs = NUMBER_OF_XBAR_OUTPUTS;

        pSrb->ActualBytesTransferred = sizeof (KSPROPERTY_CROSSBAR_CAPS_S);
    }
    break;


    case KSPROPERTY_CROSSBAR_CAN_ROUTE:                   // R
    {
        PKSPROPERTY_CROSSBAR_ROUTE_S  pRoute =
            (PKSPROPERTY_CROSSBAR_ROUTE_S)pSPD->PropertyInfo;

        if (nS < sizeof (KSPROPERTY_CROSSBAR_ROUTE_S))
            break;

        // Copy the input property info to the output property info
        RtlCopyMemory(  pRoute,
                        pSPD->Property,
                        sizeof (KSPROPERTY_CROSSBAR_ROUTE_S));

        // Special case, audio output routed to (-1) means mute
        if (pRoute->IndexOutputPin == 1 && pRoute->IndexInputPin == -1) {
            pRoute->CanRoute = TRUE;
        }
        else if ((pRoute->IndexInputPin  >= NUMBER_OF_XBAR_INPUTS) ||
            (pRoute->IndexOutputPin >= NUMBER_OF_XBAR_OUTPUTS)) {

            pRoute->CanRoute = FALSE;
        }
        else if ((pRoute->IndexInputPin <= 4) &&
            (pRoute->IndexOutputPin == 0) ||
            (pRoute->IndexInputPin >= 5) &&
            (pRoute->IndexOutputPin == 1)) {

            // This driver allows any video input to connect to any video output
            // and any audio input to connect to any audio output
            pRoute->CanRoute = TRUE;
        }
        else {
            pRoute->CanRoute = FALSE;
        }
        pSrb->ActualBytesTransferred = sizeof (KSPROPERTY_CROSSBAR_ROUTE_S);
    }
    break;


    case KSPROPERTY_CROSSBAR_PININFO:                     // R
    {
        PKSPROPERTY_CROSSBAR_PININFO_S  pPinInfo =
            (PKSPROPERTY_CROSSBAR_PININFO_S)pSPD->PropertyInfo;

        if (nS < sizeof (KSPROPERTY_CROSSBAR_PININFO_S))
            break;

        // Copy the input property info to the output property info
        RtlCopyMemory(  pPinInfo,
                        pSPD->Property,
                        sizeof (KSPROPERTY_CROSSBAR_PININFO_S));

        if (pPinInfo->Direction == KSPIN_DATAFLOW_IN) {

            ASSERT (pPinInfo->Index < NUMBER_OF_XBAR_INPUTS);

            pPinInfo->PinType          = XBarInputPins[pPinInfo->Index].PinType;
            pPinInfo->RelatedPinIndex  = XBarInputPins[pPinInfo->Index].RelatedPinIndex;
            pPinInfo->Medium           = *XBarInputPins[pPinInfo->Index].Medium;
        }
        else {

            ASSERT (pPinInfo->Index < NUMBER_OF_XBAR_OUTPUTS);

            pPinInfo->PinType          = XBarOutputPins[pPinInfo->Index].PinType;
            pPinInfo->RelatedPinIndex  = XBarOutputPins[pPinInfo->Index].RelatedPinIndex;
            pPinInfo->Medium           = *XBarOutputPins[pPinInfo->Index].Medium;
        }

        pPinInfo->Medium.Id = 0; // (ULONG) pHwDevExt;  // Multiple instance support

        pSrb->ActualBytesTransferred = sizeof (KSPROPERTY_CROSSBAR_PININFO_S);
    }
    break;


    case KSPROPERTY_CROSSBAR_ROUTE:                   // R
    {
        PKSPROPERTY_CROSSBAR_ROUTE_S  pRoute =
            (PKSPROPERTY_CROSSBAR_ROUTE_S)pSPD->PropertyInfo;

        if (nS < sizeof (KSPROPERTY_CROSSBAR_ROUTE_S))
            break;

        // Copy the input property info to the output property info
        RtlCopyMemory(  pRoute,
                        pSPD->Property,
                        sizeof (KSPROPERTY_CROSSBAR_ROUTE_S));

        // Sanity check
        if (pRoute->IndexOutputPin >= NUMBER_OF_XBAR_OUTPUTS) {
            pRoute->CanRoute = FALSE;
        }
        // querying the the video output pin
        else if (pRoute->IndexOutputPin == 0) {
            pRoute->IndexInputPin = pHwDevExt->VideoInputConnected;
            pRoute->CanRoute = TRUE;
        }
        // querying the the audio output pin
        else if (pRoute->IndexOutputPin == 1) {
            pRoute->IndexInputPin = pHwDevExt->AudioInputConnected;
            pRoute->CanRoute = TRUE;
        }
        pSrb->ActualBytesTransferred = sizeof (KSPROPERTY_CROSSBAR_ROUTE_S);
    }
    break;


    default:
        TRAP
        break;
    }
}

// -------------------------------------------------------------------
// TVTuner Property Set functions
// -------------------------------------------------------------------

/*
** AdapterSetTunerProperty ()
**
**    Handles Set operations on the TvTuner property set.
**      TsbVcap uses this for demo purposes only.
**
** Arguments:
**
**      pSRB -
**          Pointer to the HW_STREAM_REQUEST_BLOCK
**
** Returns:
**
** Side Effects:  none
*/

VOID
STREAMAPI
AdapterSetTunerProperty(
    PHW_STREAM_REQUEST_BLOCK pSrb
    )
{
    PHW_DEVICE_EXTENSION pHwDevExt = ((PHW_DEVICE_EXTENSION)pSrb->HwDeviceExtension);
    PSTREAM_PROPERTY_DESCRIPTOR pSPD = pSrb->CommandData.PropertyInfo;
    ULONG Id = pSPD->Property->Id;              // index of the property
    ULONG nS = pSPD->PropertyOutputSize;        // size of data supplied

    switch (Id) {

    case KSPROPERTY_TUNER_MODE:
    {
         PKSPROPERTY_TUNER_MODE_S pMode =
            (PKSPROPERTY_TUNER_MODE_S)pSPD->Property;
         ASSERT (pMode->Mode == KSPROPERTY_TUNER_MODE_TV);
    }
    break;

    case KSPROPERTY_TUNER_STANDARD:
    {
        PKSPROPERTY_TUNER_STANDARD_S pStandard_S =
            (PKSPROPERTY_TUNER_STANDARD_S) pSPD->Property;
        pHwDevExt->VideoStandard = pStandard_S->Standard;
    }
    break;

    case KSPROPERTY_TUNER_FREQUENCY:
    {
        PKSPROPERTY_TUNER_FREQUENCY_S pFreq_S =
            (PKSPROPERTY_TUNER_FREQUENCY_S) pSPD->Property;
        pHwDevExt->Frequency = pFreq_S->Frequency;
    }
    break;

    case KSPROPERTY_TUNER_INPUT:
    {
        PKSPROPERTY_TUNER_INPUT_S pInput_S =
            (PKSPROPERTY_TUNER_INPUT_S) pSPD->Property;
        pHwDevExt->TunerInput = pInput_S->InputIndex;
    }
    break;

    default:
        TRAP
        break;
    }
}

/*
** AdapterGetTunerProperty ()
**
**    Handles Get operations on the TvTuner property set.
**      TsbVcap uses this for demo purposes only.
**
** Arguments:
**
**      pSRB -
**          Pointer to the HW_STREAM_REQUEST_BLOCK
**
** Returns:
**
** Side Effects:  none
*/

VOID
STREAMAPI
AdapterGetTunerProperty(
    PHW_STREAM_REQUEST_BLOCK pSrb
    )
{
    PHW_DEVICE_EXTENSION pHwDevExt = ((PHW_DEVICE_EXTENSION)pSrb->HwDeviceExtension);
    PSTREAM_PROPERTY_DESCRIPTOR pSPD = pSrb->CommandData.PropertyInfo;
    ULONG Id = pSPD->Property->Id;              // index of the property
    ULONG nS = pSPD->PropertyOutputSize;        // size of data supplied
    PVOID pV = pSPD->PropertyInfo;              // pointer to the output data

    ASSERT (nS >= sizeof (LONG));

    switch (Id) {

    case KSPROPERTY_TUNER_CAPS:
    {
         PKSPROPERTY_TUNER_CAPS_S pCaps =
            (PKSPROPERTY_TUNER_CAPS_S)pSPD->Property;
         ASSERT (nS >= sizeof( KSPROPERTY_TUNER_CAPS_S ) );

         // now work with the output buffer
         pCaps =(PKSPROPERTY_TUNER_CAPS_S)pV;

         pCaps->ModesSupported = KSPROPERTY_TUNER_MODE_TV;

         pCaps->VideoMedium = TVTunerMediums[0];
         pCaps->VideoMedium.Id = 0; //(ULONG) pHwDevExt;  // Multiple instance support

         pCaps->TVAudioMedium = TVTunerMediums[1];
         pCaps->TVAudioMedium.Id = 0; //(ULONG) pHwDevExt;  // Multiple instance support

         pCaps->RadioAudioMedium = TVTunerMediums[2];   // No separate radio audio pin?
         pCaps->RadioAudioMedium.Id = 0; //(ULONG) pHwDevExt;  // Multiple instance support

         pSrb->ActualBytesTransferred = sizeof( KSPROPERTY_TUNER_CAPS_S );
    }
    break;

    case KSPROPERTY_TUNER_MODE:
    {
        PKSPROPERTY_TUNER_MODE_S pMode =
            (PKSPROPERTY_TUNER_MODE_S)pSPD->Property;
        ASSERT (nS >= sizeof( KSPROPERTY_TUNER_MODE_S ) );

        // now work with the output buffer
        pMode =(PKSPROPERTY_TUNER_MODE_S)pV;

        pMode->Mode = KSPROPERTY_TUNER_MODE_TV;

        pSrb->ActualBytesTransferred = sizeof( KSPROPERTY_TUNER_MODE_S);
    }
    break;

    case KSPROPERTY_TUNER_MODE_CAPS:
    {
        PKSPROPERTY_TUNER_MODE_CAPS_S pCaps =
                (PKSPROPERTY_TUNER_MODE_CAPS_S) pSPD->Property;

        ASSERT (nS >= sizeof (KSPROPERTY_TUNER_MODE_CAPS_S));
        ASSERT (pCaps->Mode == KSPROPERTY_TUNER_MODE_TV);

        // now work with the output buffer
        pCaps = (PKSPROPERTY_TUNER_MODE_CAPS_S) pV;

        //
        // List the formats actually supported by this tuner
        //

        pCaps->StandardsSupported =

                   KS_AnalogVideo_NTSC_M

                |  KS_AnalogVideo_PAL_B
                |  KS_AnalogVideo_PAL_D
            //  |  KS_AnalogVideo_PAL_H
            //  |  KS_AnalogVideo_PAL_I
                |  KS_AnalogVideo_PAL_M
                |  KS_AnalogVideo_PAL_N

            //  |  KS_AnalogVideo_SECAM_B
            //  |  KS_AnalogVideo_SECAM_D
            //  |  KS_AnalogVideo_SECAM_G
            //  |  KS_AnalogVideo_SECAM_H
            //  |  KS_AnalogVideo_SECAM_K
            //  |  KS_AnalogVideo_SECAM_K1
            //  |  KS_AnalogVideo_SECAM_L
                ;

            //
            // Get the min and max frequencies supported
            //

        pCaps->MinFrequency =  55250000L;
        pCaps->MaxFrequency = 997250000L;

        //
        // What is the frequency step size?
        //

        pCaps->TuningGranularity =  62500L;

        //
        // How many inputs are on the tuner?
        //

        pCaps->NumberOfInputs = 1;

        //
        // What is the maximum settling time in milliseconds?
        //

        pCaps->SettlingTime = 100;

        //
        // Strategy defines how the tuner knows when it is in tune:
        //
        // KS_TUNER_STRATEGY_PLL (Has PLL offset information)
        // KS_TUNER_STRATEGY_SIGNAL_STRENGTH (has signal strength info)
        // KS_TUNER_STRATEGY_DRIVER_TUNES (driver handles all fine tuning)
        //

        pCaps->Strategy = KS_TUNER_STRATEGY_DRIVER_TUNES;

        pSrb->ActualBytesTransferred = sizeof (KSPROPERTY_TUNER_MODE_CAPS_S);
    }
    break;

    case KSPROPERTY_TUNER_STANDARD:
    {
        // What is the currently selected video standard?

        ((PKSPROPERTY_TUNER_STANDARD_S) pSPD->PropertyInfo)->Standard =
                pHwDevExt->VideoStandard;

        pSrb->ActualBytesTransferred = sizeof (KSPROPERTY_TUNER_STANDARD_S);
    }
    break;

    case KSPROPERTY_TUNER_INPUT:
    {
        // What is the currently selected input?

        ((PKSPROPERTY_TUNER_INPUT_S) pSPD->PropertyInfo)->InputIndex =
                pHwDevExt->TunerInput;

        pSrb->ActualBytesTransferred = sizeof (PKSPROPERTY_TUNER_INPUT_S);
    }
    break;


    case KSPROPERTY_TUNER_STATUS:

        // Return the status of the tuner

        // PLLOffset is in units of TuningGranularity
        // SignalStrength is 0 to 100
        // Set Busy to 1 if tuning is still in process

        {
            PKSPROPERTY_TUNER_STATUS_S pStatus =
                        (PKSPROPERTY_TUNER_STATUS_S) pSPD->PropertyInfo;

            ASSERT (nS >= sizeof (KSPROPERTY_TUNER_STATUS_S));
            pStatus->CurrentFrequency = pHwDevExt->Frequency;
            pStatus->PLLOffset = 0;
            pStatus->SignalStrength = 100;
            pStatus->Busy = pHwDevExt->Busy;

            pSrb->ActualBytesTransferred = sizeof (KSPROPERTY_TUNER_STATUS_S);
        }
        break;

    default:
        TRAP
        break;
    }
}
#endif//TOSHIBA

// -------------------------------------------------------------------
// VideoProcAmp functions
// -------------------------------------------------------------------

/*
** AdapterSetVideoProcAmpProperty ()
**
**    Handles Set operations on the VideoProcAmp property set.
**      TsbVcap uses this for demo purposes only.
**
** Arguments:
**
**      pSRB -
**          Pointer to the HW_STREAM_REQUEST_BLOCK
**
** Returns:
**
** Side Effects:  none
*/

VOID
STREAMAPI
AdapterSetVideoProcAmpProperty(
    PHW_STREAM_REQUEST_BLOCK pSrb
    )
{
    PHW_DEVICE_EXTENSION pHwDevExt = ((PHW_DEVICE_EXTENSION)pSrb->HwDeviceExtension);
    PSTREAM_PROPERTY_DESCRIPTOR pSPD = pSrb->CommandData.PropertyInfo;
    ULONG Id = pSPD->Property->Id;              // index of the property
    PKSPROPERTY_VIDEOPROCAMP_S pS = (PKSPROPERTY_VIDEOPROCAMP_S) pSPD->PropertyInfo;
#ifdef  TOSHIBA // '98-12-09 Added, for Bug-Report 253529
    LONG MaxRange;
    LONG MinRange;
#endif//TOSHIBA

    ASSERT (pSPD->PropertyInputSize >= sizeof (KSPROPERTY_VIDEOPROCAMP_S));

    switch (Id) {

    case KSPROPERTY_VIDEOPROCAMP_BRIGHTNESS:
#ifdef  TOSHIBA // '98-12-09 Modified, for Bug-Report 253529
        MaxRange = pHwDevExt->BrightnessRange.SignedMaximum;
        MinRange = pHwDevExt->BrightnessRange.SignedMinimum;
          if (   pS->Value < MinRange || pS->Value > MaxRange ) {
            pSrb->Status = STATUS_INVALID_PARAMETER;
            return;
        }
#endif//TOSHIBA
        pHwDevExt->Brightness = pS->Value;
        pHwDevExt->BrightnessFlags = pS->Flags;
        break;

    case KSPROPERTY_VIDEOPROCAMP_CONTRAST:
#ifdef  TOSHIBA // '98-12-09 Modified, for Bug-Report 253529
        MaxRange = pHwDevExt->ContrastRange.SignedMaximum;
        MinRange = pHwDevExt->ContrastRange.SignedMinimum;
        if ( pS->Value < MinRange || pS->Value > MaxRange ) {
            pSrb->Status = STATUS_INVALID_PARAMETER;
            return;
        }
#endif//TOSHIBA
        pHwDevExt->Contrast = pS->Value;
        pHwDevExt->ContrastFlags = pS->Flags;
        break;

#ifdef  TOSHIBA
    case KSPROPERTY_VIDEOPROCAMP_HUE:
#ifdef  TOSHIBA // '98-12-09 Modified, for Bug-Report 253529
        MaxRange = pHwDevExt->HueRange.SignedMaximum;
        MinRange = pHwDevExt->HueRange.SignedMinimum;
        if ( pS->Value < MinRange || pS->Value > MaxRange ) {
            pSrb->Status = STATUS_INVALID_PARAMETER;
            return;
        }
#endif//TOSHIBA
        pHwDevExt->Hue = pS->Value;
        pHwDevExt->HueFlags = pS->Flags;
        break;

    case KSPROPERTY_VIDEOPROCAMP_SATURATION:
#ifdef  TOSHIBA // '98-12-09 Modified, for Bug-Report 253529
        MaxRange = pHwDevExt->SaturationRange.SignedMaximum;
        MinRange = pHwDevExt->SaturationRange.SignedMinimum;
        if ( pS->Value < MinRange || pS->Value > MaxRange ) {
            pSrb->Status = STATUS_INVALID_PARAMETER;
            return;
        }
#endif//TOSHIBA
        pHwDevExt->Saturation = pS->Value;
        pHwDevExt->SaturationFlags = pS->Flags;
        break;

    case KSPROPERTY_VIDEOPROCAMP_COLORENABLE:
        pHwDevExt->ColorEnable = pS->Value;
        pHwDevExt->ColorEnableFlags = pS->Flags;
        if ( pS->Value ) {
            if ( get_AblFilter( pHwDevExt ) ) {
                set_filtering( pHwDevExt, TRUE );
            } else {
                set_filtering( pHwDevExt, FALSE );
                pHwDevExt->ColorEnable = 0;
            }
        } else {
            set_filtering( pHwDevExt, FALSE );
        }
        return;
#else //TOSHIBA

    case KSPROPERTY_VIDEOPROCAMP_COLORENABLE:
        pHwDevExt->ColorEnable = pS->Value;
        pHwDevExt->ColorEnableFlags = pS->Flags;
        break;
#endif//TOSHIBA

#ifdef  TOSHIBA
    default:
        return;
    }
    ImageSetHueBrightnessContrastSat(pHwDevExt);
#else //TOSHIBA
    default:
        break;
    }
#endif//TOSHIBA
}

/*
** AdapterGetVideoProcAmpProperty ()
**
**    Handles Get operations on the VideoProcAmp property set.
**      TsbVcap uses this for demo purposes only.
**
** Arguments:
**
**      pSRB -
**          Pointer to the HW_STREAM_REQUEST_BLOCK
**
** Returns:
**
** Side Effects:  none
*/

VOID
STREAMAPI
AdapterGetVideoProcAmpProperty(
    PHW_STREAM_REQUEST_BLOCK pSrb
    )
{
    PHW_DEVICE_EXTENSION pHwDevExt = ((PHW_DEVICE_EXTENSION)pSrb->HwDeviceExtension);
    PSTREAM_PROPERTY_DESCRIPTOR pSPD = pSrb->CommandData.PropertyInfo;
    ULONG Id = pSPD->Property->Id;              // index of the property
    PKSPROPERTY_VIDEOPROCAMP_S pS = (PKSPROPERTY_VIDEOPROCAMP_S) pSPD->PropertyInfo;

    ASSERT (pSPD->PropertyOutputSize >= sizeof (KSPROPERTY_VIDEOPROCAMP_S));

    switch (Id) {

#ifdef  TOSHIBA
    case KSPROPERTY_VIDEOPROCAMP_BRIGHTNESS:
        pS->Value = pHwDevExt->Brightness;
        pS->Flags = pHwDevExt->BrightnessFlags;
        pS->Capabilities = KSPROPERTY_VIDEOPROCAMP_FLAGS_MANUAL;
        break;

    case KSPROPERTY_VIDEOPROCAMP_CONTRAST:
        pS->Value = pHwDevExt->Contrast;
        pS->Flags = pHwDevExt->ContrastFlags;
        pS->Capabilities = KSPROPERTY_VIDEOPROCAMP_FLAGS_MANUAL;
        break;

    case KSPROPERTY_VIDEOPROCAMP_HUE:
        pS->Value = pHwDevExt->Hue;
        pS->Flags = pHwDevExt->HueFlags;
        pS->Capabilities = KSPROPERTY_VIDEOPROCAMP_FLAGS_MANUAL;
        break;

    case KSPROPERTY_VIDEOPROCAMP_SATURATION:
        pS->Value = pHwDevExt->Saturation;
        pS->Flags = pHwDevExt->SaturationFlags;
        pS->Capabilities = KSPROPERTY_VIDEOPROCAMP_FLAGS_MANUAL;
        break;

    case KSPROPERTY_VIDEOPROCAMP_COLORENABLE:
        if ( get_AblFilter( pHwDevExt ) ) {
            if ( get_filtering( pHwDevExt ) ) {
                pHwDevExt->ColorEnable = 1;
            } else {
                pHwDevExt->ColorEnable = 0;
            }
            pHwDevExt->ColorEnableFlags = KSPROPERTY_VIDEOPROCAMP_FLAGS_MANUAL;
            pS->Value = pHwDevExt->ColorEnable;
            pS->Flags = pHwDevExt->ColorEnableFlags;
            pS->Capabilities = KSPROPERTY_VIDEOPROCAMP_FLAGS_MANUAL;
        } else {
            if ( pHwDevExt->ColorEnable ) {
                set_filtering( pHwDevExt, FALSE );
                pHwDevExt->ColorEnable = 0;
            }
            pHwDevExt->ColorEnableFlags = KSPROPERTY_VIDEOPROCAMP_FLAGS_AUTO;
            pS->Value = pHwDevExt->ColorEnable;
            pS->Flags = pHwDevExt->ColorEnableFlags;
            pS->Capabilities = KSPROPERTY_VIDEOPROCAMP_FLAGS_AUTO;
        }
        break;
#else //TOSHIBA
    case KSPROPERTY_VIDEOPROCAMP_BRIGHTNESS:
        pS->Value = pHwDevExt->Brightness;
        pS->Flags = pHwDevExt->BrightnessFlags;
        pS->Capabilities = KSPROPERTY_VIDEOPROCAMP_FLAGS_MANUAL |
                           KSPROPERTY_VIDEOPROCAMP_FLAGS_AUTO;
        break;

    case KSPROPERTY_VIDEOPROCAMP_CONTRAST:
        pS->Value = pHwDevExt->Contrast;
        pS->Flags = pHwDevExt->ContrastFlags;
        pS->Capabilities = KSPROPERTY_VIDEOPROCAMP_FLAGS_MANUAL |
                           KSPROPERTY_VIDEOPROCAMP_FLAGS_AUTO;
        break;

    case KSPROPERTY_VIDEOPROCAMP_COLORENABLE:
        pS->Value = pHwDevExt->ColorEnable;
        pS->Flags = pHwDevExt->ColorEnableFlags;
        pS->Capabilities = KSPROPERTY_VIDEOPROCAMP_FLAGS_MANUAL;
        break;
#endif//TOSHIBA

    default:
        break;
    }
    pSrb->ActualBytesTransferred = sizeof (KSPROPERTY_VIDEOPROCAMP_S);
}

#ifndef TOSHIBA
// -------------------------------------------------------------------
// CameraControl functions
// -------------------------------------------------------------------

/*
** AdapterSetCameraControlProperty ()
**
**    Handles Set operations on the CameraControl property set.
**      TsbVcap uses this for demo purposes only.
**
** Arguments:
**
**      pSRB -
**          Pointer to the HW_STREAM_REQUEST_BLOCK
**
** Returns:
**
** Side Effects:  none
*/

VOID
STREAMAPI
AdapterSetCameraControlProperty(
    PHW_STREAM_REQUEST_BLOCK pSrb
    )
{
    PHW_DEVICE_EXTENSION pHwDevExt = ((PHW_DEVICE_EXTENSION)pSrb->HwDeviceExtension);
    PSTREAM_PROPERTY_DESCRIPTOR pSPD = pSrb->CommandData.PropertyInfo;
    ULONG Id = pSPD->Property->Id;              // index of the property
    PKSPROPERTY_CAMERACONTROL_S pS = (PKSPROPERTY_CAMERACONTROL_S) pSPD->PropertyInfo;

    ASSERT (pSPD->PropertyInputSize >= sizeof (KSPROPERTY_CAMERACONTROL_S));

    switch (Id) {

    case KSPROPERTY_CAMERACONTROL_ZOOM:
        pHwDevExt->Zoom = pS->Value;
        pHwDevExt->ZoomFlags = pS->Flags;
        break;

    case KSPROPERTY_CAMERACONTROL_FOCUS:
        pHwDevExt->Focus = pS->Value;
        pHwDevExt->FocusFlags = pS->Flags;
        break;

    default:
        break;
    }
}

/*
** AdapterGetCameraControlProperty ()
**
**    Handles Get operations on the CameraControl property set.
**      TsbVcap uses this for demo purposes only.
**
** Arguments:
**
**      pSRB -
**          Pointer to the HW_STREAM_REQUEST_BLOCK
**
** Returns:
**
** Side Effects:  none
*/

VOID
STREAMAPI
AdapterGetCameraControlProperty(
    PHW_STREAM_REQUEST_BLOCK pSrb
    )
{
    PHW_DEVICE_EXTENSION pHwDevExt = ((PHW_DEVICE_EXTENSION)pSrb->HwDeviceExtension);
    PSTREAM_PROPERTY_DESCRIPTOR pSPD = pSrb->CommandData.PropertyInfo;
    ULONG Id = pSPD->Property->Id;              // index of the property
    PKSPROPERTY_CAMERACONTROL_S pS = (PKSPROPERTY_CAMERACONTROL_S) pSPD->PropertyInfo;    // pointer to the output data

    ASSERT (pSPD->PropertyOutputSize >= sizeof (KSPROPERTY_CAMERACONTROL_S));

    switch (Id) {

    case KSPROPERTY_CAMERACONTROL_ZOOM:
        pS->Value = pHwDevExt->Zoom;
        pS->Flags = pHwDevExt->ZoomFlags;
        pS->Capabilities = KSPROPERTY_CAMERACONTROL_FLAGS_MANUAL |
                           KSPROPERTY_CAMERACONTROL_FLAGS_AUTO;
        break;

    case KSPROPERTY_CAMERACONTROL_FOCUS:
        pS->Value = pHwDevExt->Focus;
        pS->Flags = pHwDevExt->FocusFlags;
        pS->Capabilities = KSPROPERTY_CAMERACONTROL_FLAGS_MANUAL |
                           KSPROPERTY_CAMERACONTROL_FLAGS_AUTO;
        break;

    default:
        break;
    }
    pSrb->ActualBytesTransferred = sizeof (KSPROPERTY_CAMERACONTROL_S);
}

// -------------------------------------------------------------------
// TVAudio functions
// -------------------------------------------------------------------

/*
** AdapterSetTVAudioProperty ()
**
**    Handles Set operations on the TVAudio property set.
**      TsbVcap uses this for demo purposes only.
**
** Arguments:
**
**      pSRB -
**          Pointer to the HW_STREAM_REQUEST_BLOCK
**
** Returns:
**
** Side Effects:  none
*/

VOID
STREAMAPI
AdapterSetTVAudioProperty(
    PHW_STREAM_REQUEST_BLOCK pSrb
    )
{
    PHW_DEVICE_EXTENSION pHwDevExt = ((PHW_DEVICE_EXTENSION)pSrb->HwDeviceExtension);
    PSTREAM_PROPERTY_DESCRIPTOR pSPD = pSrb->CommandData.PropertyInfo;
    ULONG Id = pSPD->Property->Id;              // index of the property


    switch (Id) {

    case KSPROPERTY_TVAUDIO_MODE:
    {
        PKSPROPERTY_TVAUDIO_S pS = (PKSPROPERTY_TVAUDIO_S) pSPD->PropertyInfo;

        pHwDevExt->TVAudioMode = pS->Mode;
    }
    break;

    default:
        break;
    }
}

/*
** AdapterGetTVAudioProperty ()
**
**    Handles Get operations on the TVAudio property set.
**      TsbVcap uses this for demo purposes only.
**
** Arguments:
**
**      pSRB -
**          Pointer to the HW_STREAM_REQUEST_BLOCK
**
** Returns:
**
** Side Effects:  none
*/

VOID
STREAMAPI
AdapterGetTVAudioProperty(
    PHW_STREAM_REQUEST_BLOCK pSrb
    )
{
    PHW_DEVICE_EXTENSION pHwDevExt = ((PHW_DEVICE_EXTENSION)pSrb->HwDeviceExtension);
    PSTREAM_PROPERTY_DESCRIPTOR pSPD = pSrb->CommandData.PropertyInfo;
    ULONG Id = pSPD->Property->Id;              // index of the property

    switch (Id) {

    case KSPROPERTY_TVAUDIO_CAPS:
    {
        PKSPROPERTY_TVAUDIO_CAPS_S pS = (PKSPROPERTY_TVAUDIO_CAPS_S) pSPD->PropertyInfo;    // pointer to the data

        ASSERT (pSPD->PropertyOutputSize >= sizeof (KSPROPERTY_TVAUDIO_CAPS_S));

        pS->InputMedium  = TVAudioMediums[0];
        pS->InputMedium.Id = 0; //(ULONG) pHwDevExt;  // Multiple instance support
        pS->OutputMedium = TVAudioMediums[1];
        pS->OutputMedium.Id = 0; //(ULONG) pHwDevExt;  // Multiple instance support

        // Report all of the possible audio decoding modes the hardware is capabable of
        pS->Capabilities = KS_TVAUDIO_MODE_MONO   |
                           KS_TVAUDIO_MODE_STEREO |
                           KS_TVAUDIO_MODE_LANG_A |
                           KS_TVAUDIO_MODE_LANG_B ;

        pSrb->ActualBytesTransferred = sizeof (KSPROPERTY_TVAUDIO_CAPS_S);
    }
    break;

    case KSPROPERTY_TVAUDIO_MODE:
    {
        PKSPROPERTY_TVAUDIO_S pS = (PKSPROPERTY_TVAUDIO_S) pSPD->PropertyInfo;    // pointer to the data

        ASSERT (pSPD->PropertyOutputSize >= sizeof (KSPROPERTY_TVAUDIO_S));
        // Report the currently selected mode
        pS->Mode = pHwDevExt->TVAudioMode;

        pSrb->ActualBytesTransferred = sizeof (KSPROPERTY_TVAUDIO_S);
    }
    break;

    case KSPROPERTY_TVAUDIO_CURRENTLY_AVAILABLE_MODES:
    {
        PKSPROPERTY_TVAUDIO_S pS = (PKSPROPERTY_TVAUDIO_S) pSPD->PropertyInfo;    // pointer to the data

        ASSERT (pSPD->PropertyOutputSize >= sizeof (KSPROPERTY_TVAUDIO_S));
        // Report which audio modes could potentially be selected right now
        pS->Mode = KS_TVAUDIO_MODE_MONO   |
                   KS_TVAUDIO_MODE_STEREO |
                   KS_TVAUDIO_MODE_LANG_A ;

        pSrb->ActualBytesTransferred = sizeof (KSPROPERTY_TVAUDIO_S);
    }
    break;

    default:
        break;
    }
}

// -------------------------------------------------------------------
// AnalogVideoDecoder functions
// -------------------------------------------------------------------

/*
** AdapterSetAnalogVideoDecoderProperty ()
**
**    Handles Set operations on the AnalogVideoDecoder property set.
**      TsbVcap uses this for demo purposes only.
**
** Arguments:
**
**      pSRB -
**          Pointer to the HW_STREAM_REQUEST_BLOCK
**
** Returns:
**
** Side Effects:  none
*/

VOID
STREAMAPI
AdapterSetAnalogVideoDecoderProperty(
    PHW_STREAM_REQUEST_BLOCK pSrb
    )
{
    PHW_DEVICE_EXTENSION pHwDevExt = ((PHW_DEVICE_EXTENSION)pSrb->HwDeviceExtension);
    PSTREAM_PROPERTY_DESCRIPTOR pSPD = pSrb->CommandData.PropertyInfo;
    ULONG Id = pSPD->Property->Id;              // index of the property
    PKSPROPERTY_VIDEODECODER_S pS = (PKSPROPERTY_VIDEODECODER_S) pSPD->PropertyInfo;

    ASSERT (pSPD->PropertyInputSize >= sizeof (KSPROPERTY_VIDEODECODER_S));

    switch (Id) {

    case KSPROPERTY_VIDEODECODER_STANDARD:
    {
        pHwDevExt->VideoDecoderVideoStandard = pS->Value;
    }
    break;

    case KSPROPERTY_VIDEODECODER_OUTPUT_ENABLE:
    {
        pHwDevExt->VideoDecoderOutputEnable = pS->Value;
    }
    break;

    case KSPROPERTY_VIDEODECODER_VCR_TIMING:
    {
        pHwDevExt->VideoDecoderVCRTiming = pS->Value;
    }
    break;

    default:
        break;
    }
}

/*
** AdapterGetAnalogVideoDecoderProperty ()
**
**    Handles Get operations on the AnalogVideoDecoder property set.
**      TsbVcap uses this for demo purposes only.
**
** Arguments:
**
**      pSRB -
**          Pointer to the HW_STREAM_REQUEST_BLOCK
**
** Returns:
**
** Side Effects:  none
*/

VOID
STREAMAPI
AdapterGetAnalogVideoDecoderProperty(
    PHW_STREAM_REQUEST_BLOCK pSrb
    )
{
    PHW_DEVICE_EXTENSION pHwDevExt = ((PHW_DEVICE_EXTENSION)pSrb->HwDeviceExtension);
    PSTREAM_PROPERTY_DESCRIPTOR pSPD = pSrb->CommandData.PropertyInfo;
    ULONG Id = pSPD->Property->Id;              // index of the property

    switch (Id) {

    case KSPROPERTY_VIDEODECODER_CAPS:
    {
        PKSPROPERTY_VIDEODECODER_CAPS_S pS = (PKSPROPERTY_VIDEODECODER_CAPS_S) pSPD->PropertyInfo;    // pointer to the data

        ASSERT (pSPD->PropertyOutputSize >= sizeof (KSPROPERTY_VIDEODECODER_CAPS_S));

        pS->StandardsSupported =
                   KS_AnalogVideo_NTSC_M

                |  KS_AnalogVideo_PAL_B
                |  KS_AnalogVideo_PAL_D
            //  |  KS_AnalogVideo_PAL_H
            //  |  KS_AnalogVideo_PAL_I
                |  KS_AnalogVideo_PAL_M
                |  KS_AnalogVideo_PAL_N

            //  |  KS_AnalogVideo_SECAM_B
            //  |  KS_AnalogVideo_SECAM_D
            //  |  KS_AnalogVideo_SECAM_G
            //  |  KS_AnalogVideo_SECAM_H
            //  |  KS_AnalogVideo_SECAM_K
            //  |  KS_AnalogVideo_SECAM_K1
            //  |  KS_AnalogVideo_SECAM_L
                   ;

        pS->Capabilities = KS_VIDEODECODER_FLAGS_CAN_DISABLE_OUTPUT  |
                           KS_VIDEODECODER_FLAGS_CAN_USE_VCR_LOCKING |
                           KS_VIDEODECODER_FLAGS_CAN_INDICATE_LOCKED ;


        pS->SettlingTime = 10;          // How long to delay after tuning before
                                        // Locked indicator is valid

        pS->HSyncPerVSync = 6;          // HSync per VSync

        pSrb->ActualBytesTransferred = sizeof (KSPROPERTY_VIDEODECODER_CAPS_S);
    }
    break;

    case KSPROPERTY_VIDEODECODER_STANDARD:
    {
        PKSPROPERTY_VIDEODECODER_S pS = (PKSPROPERTY_VIDEODECODER_S) pSPD->PropertyInfo;    // pointer to the data

        ASSERT (pSPD->PropertyOutputSize >= sizeof (KSPROPERTY_VIDEODECODER_S));

        pS->Value = pHwDevExt->VideoDecoderVideoStandard;

        pSrb->ActualBytesTransferred = sizeof (KSPROPERTY_VIDEODECODER_S);
    }
    break;

    case KSPROPERTY_VIDEODECODER_STATUS:
    {
        PKSPROPERTY_VIDEODECODER_STATUS_S pS = (PKSPROPERTY_VIDEODECODER_STATUS_S) pSPD->PropertyInfo;    // pointer to the data

        ASSERT (pSPD->PropertyOutputSize >= sizeof (KSPROPERTY_VIDEODECODER_STATUS_S));

        pS->NumberOfLines = (pHwDevExt->VideoDecoderVideoStandard & KS_AnalogVideo_NTSC_Mask)
                             ? 525 : 625;

        // Just to make things interesting, simulate that some channels aren't locked
        // In the US, these are channels 54 through 70
        pS->SignalLocked = (pHwDevExt->Frequency < 400000000 || pHwDevExt->Frequency > 500000000);

        pSrb->ActualBytesTransferred = sizeof (KSPROPERTY_VIDEODECODER_S);
    }
    break;

    case KSPROPERTY_VIDEODECODER_OUTPUT_ENABLE:
    {
        PKSPROPERTY_VIDEODECODER_S pS = (PKSPROPERTY_VIDEODECODER_S) pSPD->PropertyInfo;    // pointer to the data

        ASSERT (pSPD->PropertyOutputSize >= sizeof (KSPROPERTY_VIDEODECODER_S));

        pS->Value = pHwDevExt->VideoDecoderOutputEnable;

        pSrb->ActualBytesTransferred = sizeof (KSPROPERTY_VIDEODECODER_S);
    }
    break;

    case KSPROPERTY_VIDEODECODER_VCR_TIMING:
    {
        PKSPROPERTY_VIDEODECODER_S pS = (PKSPROPERTY_VIDEODECODER_S) pSPD->PropertyInfo;    // pointer to the data

        ASSERT (pSPD->PropertyOutputSize >= sizeof (KSPROPERTY_VIDEODECODER_S));

        pS->Value = pHwDevExt->VideoDecoderVCRTiming;

        pSrb->ActualBytesTransferred = sizeof (KSPROPERTY_VIDEODECODER_S);
    }
    break;

    default:
        break;
    }
}
#endif//TOSHIBA

#ifndef TOSHIBA // '98-12-10 Deleted, for Bug-Report 253534
// -------------------------------------------------------------------
// VideoControl functions
// -------------------------------------------------------------------

/*
** AdapterSetVideoControlProperty ()
**
**    Handles Set operations on the VideoControl property set.
**      TsbVcap uses this for demo purposes only.
**
** Arguments:
**
**      pSRB -
**          Pointer to the HW_STREAM_REQUEST_BLOCK
**
** Returns:
**
** Side Effects:  none
*/

VOID
STREAMAPI
AdapterSetVideoControlProperty(
    PHW_STREAM_REQUEST_BLOCK pSrb
    )
{
    PHW_DEVICE_EXTENSION pHwDevExt = ((PHW_DEVICE_EXTENSION)pSrb->HwDeviceExtension);
    PSTREAM_PROPERTY_DESCRIPTOR pSPD = pSrb->CommandData.PropertyInfo;
    ULONG Id = pSPD->Property->Id;              // index of the property
    PKSPROPERTY_VIDEOCONTROL_MODE_S pS = (PKSPROPERTY_VIDEOCONTROL_MODE_S) pSPD->PropertyInfo;
    PSTREAMEX pStrmEx;
    ULONG StreamIndex;
    ULONG *pVideoControlMode;

    // For this property set, the StreamIndex is always in the same place
    // for each property
    StreamIndex = ((PKSPROPERTY_VIDEOCONTROL_CAPS_S) pSPD->Property)->StreamIndex;

    ASSERT (StreamIndex >= 0 && StreamIndex < MAX_TSBVCAP_STREAMS);

    // Verify the stream index is valid
    if (StreamIndex < 0 || StreamIndex >= MAX_TSBVCAP_STREAMS) {
        pSrb->Status = STATUS_INVALID_PARAMETER;
        return;
    }

    pStrmEx = (PSTREAMEX) pHwDevExt->pStrmEx[StreamIndex];

    // If the stream is not opened when this property set is used,
    // store the values in the HwDevExt

    if (pStrmEx) {
        pVideoControlMode = &pStrmEx->VideoControlMode;
    }
    else {
        pVideoControlMode = &pHwDevExt->VideoControlMode;
    }

    ASSERT (pSPD->PropertyInputSize >= sizeof (KSPROPERTY_VIDEOCONTROL_MODE_S));

    switch (Id) {

    case KSPROPERTY_VIDEOCONTROL_MODE:
    {
        *pVideoControlMode = pS->Mode;
    }
    break;

    default:
        break;
    }
}

/*
** AdapterGetVideoControlProperty ()
**
**    Handles Get operations on the VideoControl property set.
**      TsbVcap uses this for demo purposes only.
**
** Arguments:
**
**      pSRB -
**          Pointer to the HW_STREAM_REQUEST_BLOCK
**
** Returns:
**
** Side Effects:  none
*/

VOID
STREAMAPI
AdapterGetVideoControlProperty(
    PHW_STREAM_REQUEST_BLOCK pSrb
    )
{
    PHW_DEVICE_EXTENSION pHwDevExt = ((PHW_DEVICE_EXTENSION)pSrb->HwDeviceExtension);
    PSTREAM_PROPERTY_DESCRIPTOR pSPD = pSrb->CommandData.PropertyInfo;
    ULONG Id = pSPD->Property->Id;              // index of the property
    PSTREAMEX pStrmEx;
    ULONG StreamIndex;
    ULONG *pVideoControlMode;

    // For this property set, the StreamIndex is always in the same place
    // for each property
    StreamIndex = ((PKSPROPERTY_VIDEOCONTROL_CAPS_S) pSPD->Property)->StreamIndex;

    ASSERT (StreamIndex >= 0 && StreamIndex < MAX_TSBVCAP_STREAMS);

    // Verify the stream index is valid
    if (StreamIndex < 0 || StreamIndex >= MAX_TSBVCAP_STREAMS) {
        pSrb->Status = STATUS_INVALID_PARAMETER;
        return;
    }

    pStrmEx = (PSTREAMEX) pHwDevExt->pStrmEx[StreamIndex];

    // If the stream is not opened when this property set is used,
    // store the values in the HwDevExt

    if (pStrmEx) {
        pVideoControlMode = &pStrmEx->VideoControlMode;
    }
    else {
        pVideoControlMode = &pHwDevExt->VideoControlMode;
    }

    switch (Id) {

    case KSPROPERTY_VIDEOCONTROL_CAPS:
    {
        PKSPROPERTY_VIDEOCONTROL_CAPS_S pS = (PKSPROPERTY_VIDEOCONTROL_CAPS_S) pSPD->PropertyInfo;    // pointer to the data

        ASSERT (pSPD->PropertyOutputSize >= sizeof (KSPROPERTY_VIDEOCONTROL_CAPS_S));

        pS->VideoControlCaps =
              KS_VideoControlFlag_FlipHorizontal
//            | KS_VideoControlFlag_FlipVertical
//            | KS_VideoControlFlag_ExternalTriggerEnable
//            | KS_VideoControlFlag_Trigger
            ;

        pSrb->ActualBytesTransferred = sizeof (KSPROPERTY_VIDEOCONTROL_CAPS_S);
    }
    break;

    case KSPROPERTY_VIDEOCONTROL_ACTUAL_FRAME_RATE:
    {
        PKSPROPERTY_VIDEOCONTROL_ACTUAL_FRAME_RATE_S pS =
            (PKSPROPERTY_VIDEOCONTROL_ACTUAL_FRAME_RATE_S) pSPD->PropertyInfo;    // pointer to the data

        ASSERT (pSPD->PropertyOutputSize >= sizeof (KSPROPERTY_VIDEOCONTROL_ACTUAL_FRAME_RATE_S));

        pS->CurrentActualFrameRate = 15;        // TODO: Why is this a fixed value?  Is it not reprogrammable?
        pS->CurrentMaxAvailableFrameRate = 15;  // TODO: Why is this a fixed value?  Is it not reprogrammable?


        pSrb->ActualBytesTransferred = sizeof (KSPROPERTY_VIDEOCONTROL_ACTUAL_FRAME_RATE_S);
    }
    break;

    case KSPROPERTY_VIDEOCONTROL_FRAME_RATES:
    {
        // todo
    }
    break;

    case KSPROPERTY_VIDEOCONTROL_MODE:
    {
        PKSPROPERTY_VIDEOCONTROL_MODE_S pS = (PKSPROPERTY_VIDEOCONTROL_MODE_S) pSPD->PropertyInfo;    // pointer to the data

        ASSERT (pSPD->PropertyOutputSize >= sizeof (KSPROPERTY_VIDEOCONTROL_MODE_S));

        pS->Mode = *pVideoControlMode;

        pSrb->ActualBytesTransferred = sizeof (KSPROPERTY_VIDEOCONTROL_MODE_S);
    }
    break;

    default:
        break;
    }
}

/*
** AdapterGetVideoCompressionProperty()
**
**    Gets compressor settings
**
** Arguments:
**
**    pSrb - pointer to the stream request block for properties
**
** Returns:
**
** Side Effects:  none
*/

VOID
STREAMAPI
AdapterGetVideoCompressionProperty(
    PHW_STREAM_REQUEST_BLOCK pSrb
    )
{
    PHW_DEVICE_EXTENSION pHwDevExt = ((PHW_DEVICE_EXTENSION)pSrb->HwDeviceExtension);
    PSTREAMEX pStrmEx;
    PSTREAM_PROPERTY_DESCRIPTOR pSPD = pSrb->CommandData.PropertyInfo;
    ULONG Id = pSPD->Property->Id;              // index of the property
    ULONG StreamIndex;
    PCOMPRESSION_SETTINGS pCompressionSettings;

    // For this property set, the StreamIndex is always in the same place
    // for each property
    StreamIndex = ((PKSPROPERTY_VIDEOCOMPRESSION_S) pSPD->Property)->StreamIndex;

    ASSERT (StreamIndex >= 0 && StreamIndex < MAX_TSBVCAP_STREAMS);

    // Verify the stream index is valid
    if (StreamIndex < 0 || StreamIndex >= MAX_TSBVCAP_STREAMS) {
        pSrb->Status = STATUS_INVALID_PARAMETER;
        return;
    }

    pStrmEx = (PSTREAMEX) pHwDevExt->pStrmEx[StreamIndex];

    // If the stream is not opened when this property set is used,
    // store the values in the HwDevExt

    if (pStrmEx) {
        pCompressionSettings = &pStrmEx->CompressionSettings;
    }
    else {
        pCompressionSettings = &pHwDevExt->CompressionSettings;
    }


    switch (Id) {

    case KSPROPERTY_VIDEOCOMPRESSION_GETINFO:
        {
            PKSPROPERTY_VIDEOCOMPRESSION_GETINFO_S pS =
                (PKSPROPERTY_VIDEOCOMPRESSION_GETINFO_S) pSPD->PropertyInfo;

            pS->DefaultKeyFrameRate = 15;    // Key frame rate
            pS->DefaultPFrameRate = 3;       // Predeicted frames per Key frame
            pS->DefaultQuality = 5000;       // 0 to 10000
            pS->Capabilities =
                       KS_CompressionCaps_CanQuality  |
                       KS_CompressionCaps_CanKeyFrame |
                       KS_CompressionCaps_CanBFrame   ;

            pSrb->ActualBytesTransferred = sizeof (KSPROPERTY_VIDEOCOMPRESSION_GETINFO_S);
        }
        break;

    case KSPROPERTY_VIDEOCOMPRESSION_KEYFRAME_RATE:
        {
            PKSPROPERTY_VIDEOCOMPRESSION_S pS =
                (PKSPROPERTY_VIDEOCOMPRESSION_S) pSPD->PropertyInfo;

            pS->Value = pCompressionSettings->CompressionKeyFrameRate;

            pSrb->ActualBytesTransferred = sizeof (KSPROPERTY_VIDEOCOMPRESSION_S);
        }
        break;

    case KSPROPERTY_VIDEOCOMPRESSION_PFRAMES_PER_KEYFRAME:
        {
            PKSPROPERTY_VIDEOCOMPRESSION_S pS =
                (PKSPROPERTY_VIDEOCOMPRESSION_S) pSPD->PropertyInfo;

            pS->Value = pCompressionSettings->CompressionPFramesPerKeyFrame;

            pSrb->ActualBytesTransferred = sizeof (KSPROPERTY_VIDEOCOMPRESSION_S);
        }
        break;

    case KSPROPERTY_VIDEOCOMPRESSION_QUALITY:
        {
            PKSPROPERTY_VIDEOCOMPRESSION_S pS =
                (PKSPROPERTY_VIDEOCOMPRESSION_S) pSPD->PropertyInfo;

            pS->Value = pCompressionSettings->CompressionQuality;

            pSrb->ActualBytesTransferred = sizeof (KSPROPERTY_VIDEOCOMPRESSION_S);
        }
        break;

    default:
        break;
    }
}

/*
** AdapterSetVideoCompressionProperty()
**
**    Sets compressor settings
**
** Arguments:
**
**    pSrb - pointer to the stream request block for properties
**
** Returns:
**
** Side Effects:  none
*/

VOID
STREAMAPI
AdapterSetVideoCompressionProperty(
    PHW_STREAM_REQUEST_BLOCK pSrb
    )
{
    PHW_DEVICE_EXTENSION pHwDevExt = ((PHW_DEVICE_EXTENSION)pSrb->HwDeviceExtension);
    PSTREAMEX pStrmEx;
    PSTREAM_PROPERTY_DESCRIPTOR pSPD = pSrb->CommandData.PropertyInfo;
    PKSPROPERTY_VIDEOCOMPRESSION_S pS = (PKSPROPERTY_VIDEOCOMPRESSION_S) pSPD->Property;
    ULONG Id = pSPD->Property->Id;              // index of the property
    ULONG StreamIndex;
    PCOMPRESSION_SETTINGS pCompressionSettings;

    // For this property set, the StreamIndex is always in the same place
    // for each property
    StreamIndex = ((PKSPROPERTY_VIDEOCOMPRESSION_S) pSPD->Property)->StreamIndex;

    ASSERT (StreamIndex >= 0 && StreamIndex < MAX_TSBVCAP_STREAMS);

    // Verify the stream index is valid
    if (StreamIndex < 0 || StreamIndex >= MAX_TSBVCAP_STREAMS) {
        pSrb->Status = STATUS_INVALID_PARAMETER;
        return;
    }

    pStrmEx = (PSTREAMEX) pHwDevExt->pStrmEx[StreamIndex];

    // If the stream is not opened when this property set is used,
    // store the values in the HwDevExt

    if (pStrmEx) {
        pCompressionSettings = &pStrmEx->CompressionSettings;
    }
    else {
        pCompressionSettings = &pHwDevExt->CompressionSettings;
    }

    switch (Id) {

    case KSPROPERTY_VIDEOCOMPRESSION_KEYFRAME_RATE:
        {
            pCompressionSettings->CompressionKeyFrameRate = pS->Value;
        }
        break;

    case KSPROPERTY_VIDEOCOMPRESSION_PFRAMES_PER_KEYFRAME:
        {
            pCompressionSettings->CompressionPFramesPerKeyFrame = pS->Value;
        }
        break;

    case KSPROPERTY_VIDEOCOMPRESSION_QUALITY:
        {
            pCompressionSettings->CompressionQuality = pS->Value;
        }
        break;

    default:
        break;
    }
}
#endif//TOSHIBA


// -------------------------------------------------------------------
// General entry point for all get/set adapter properties
// -------------------------------------------------------------------

/*
** AdapterSetProperty ()
**
**    Handles Set operations for all adapter properties.
**
** Arguments:
**
**      pSRB -
**          Pointer to the HW_STREAM_REQUEST_BLOCK
**
** Returns:
**
** Side Effects:  none
*/

VOID
STREAMAPI
AdapterSetProperty(
    PHW_STREAM_REQUEST_BLOCK pSrb
    )

{
    PSTREAM_PROPERTY_DESCRIPTOR pSPD = pSrb->CommandData.PropertyInfo;

#ifdef  TOSHIBA
    if (IsEqualGUID(&PROPSETID_VIDCAP_VIDEOPROCAMP, &pSPD->Property->Set)) {
        AdapterSetVideoProcAmpProperty (pSrb);
    }
#else //TOSHIBA // '98-12-10 Moved, for Bug-Report 253534
    else if (IsEqualGUID(&PROPSETID_VIDCAP_VIDEOCONTROL, &pSPD->Property->Set)) {
        AdapterSetVideoControlProperty (pSrb);
    }
    else if (IsEqualGUID (&PROPSETID_VIDCAP_VIDEOCOMPRESSION, &pSPD->Property->Set)) {
        AdapterSetVideoCompressionProperty (pSrb);
    }
//#else //TOSHIBA  '98-12-10 Moved, for Bug-Report 253534
    if (IsEqualGUID(&PROPSETID_VIDCAP_CROSSBAR, &pSPD->Property->Set)) {
        AdapterSetCrossbarProperty (pSrb);
    }
    else if (IsEqualGUID(&PROPSETID_TUNER, &pSPD->Property->Set)) {
        AdapterSetTunerProperty (pSrb);
    }
    else if (IsEqualGUID(&PROPSETID_VIDCAP_VIDEOPROCAMP, &pSPD->Property->Set)) {
        AdapterSetVideoProcAmpProperty (pSrb);
    }
    else if (IsEqualGUID(&PROPSETID_VIDCAP_CAMERACONTROL, &pSPD->Property->Set)) {
        AdapterSetCameraControlProperty (pSrb);
    }
    else if (IsEqualGUID(&PROPSETID_VIDCAP_TVAUDIO, &pSPD->Property->Set)) {
        AdapterSetTVAudioProperty (pSrb);
    }
    else if (IsEqualGUID(&PROPSETID_VIDCAP_VIDEODECODER, &pSPD->Property->Set)) {
        AdapterSetAnalogVideoDecoderProperty (pSrb);
    }
    else if (IsEqualGUID(&PROPSETID_VIDCAP_VIDEOCONTROL, &pSPD->Property->Set)) {
        AdapterSetVideoControlProperty (pSrb);
    }
    else if (IsEqualGUID (&PROPSETID_VIDCAP_VIDEOCOMPRESSION, &pSPD->Property->Set)) {
        AdapterSetVideoCompressionProperty (pSrb);
    }
#endif//TOSHIBA
    else {
        //
        // We should never get here
        //

        pSrb->Status = STATUS_NOT_IMPLEMENTED;
    }
}

/*
** AdapterGetProperty ()
**
**    Handles Get operations for all adapter properties.
**
** Arguments:
**
**      pSRB -
**          Pointer to the HW_STREAM_REQUEST_BLOCK
**
** Returns:
**
** Side Effects:  none
*/

VOID
STREAMAPI
AdapterGetProperty(
    PHW_STREAM_REQUEST_BLOCK pSrb
    )

{
    PSTREAM_PROPERTY_DESCRIPTOR pSPD = pSrb->CommandData.PropertyInfo;

#ifdef  TOSHIBA
    if (IsEqualGUID(&PROPSETID_VIDCAP_VIDEOPROCAMP, &pSPD->Property->Set)) {
        AdapterGetVideoProcAmpProperty (pSrb);
    }
#else //TOSHIBA // '98-12-10 Moved, for Bug-Report 253534
    else if (IsEqualGUID(&PROPSETID_VIDCAP_VIDEOCONTROL, &pSPD->Property->Set)) {
        AdapterGetVideoControlProperty (pSrb);
    }
    else if (IsEqualGUID (&PROPSETID_VIDCAP_VIDEOCOMPRESSION, &pSPD->Property->Set)) {
        AdapterGetVideoCompressionProperty (pSrb);
    }
//#else //TOSHIBA  '98-12-10 Moved, for Bug-Report 253534
    if (IsEqualGUID (&PROPSETID_VIDCAP_CROSSBAR, &pSPD->Property->Set)) {
        AdapterGetCrossbarProperty (pSrb);
    }
    else if (IsEqualGUID (&PROPSETID_TUNER, &pSPD->Property->Set)) {
        AdapterGetTunerProperty (pSrb);
    }
    else if (IsEqualGUID(&PROPSETID_VIDCAP_VIDEOPROCAMP, &pSPD->Property->Set)) {
        AdapterGetVideoProcAmpProperty (pSrb);
    }
    else if (IsEqualGUID(&PROPSETID_VIDCAP_CAMERACONTROL, &pSPD->Property->Set)) {
        AdapterGetCameraControlProperty (pSrb);
    }
    else if (IsEqualGUID(&PROPSETID_VIDCAP_TVAUDIO, &pSPD->Property->Set)) {
        AdapterGetTVAudioProperty (pSrb);
    }
    else if (IsEqualGUID(&PROPSETID_VIDCAP_VIDEODECODER, &pSPD->Property->Set)) {
        AdapterGetAnalogVideoDecoderProperty (pSrb);
    }
    else if (IsEqualGUID(&PROPSETID_VIDCAP_VIDEOCONTROL, &pSPD->Property->Set)) {
        AdapterGetVideoControlProperty (pSrb);
    }
    else if (IsEqualGUID (&PROPSETID_VIDCAP_VIDEOCOMPRESSION, &pSPD->Property->Set)) {
        AdapterGetVideoCompressionProperty (pSrb);
    }
#endif//TOSHIBA
    else {
        //
        // We should never get here
        //

        pSrb->Status = STATUS_NOT_IMPLEMENTED;
    }
}




=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\drivers\wdm\capture\mini\tecra750\image.c ===
//
//              TOSHIBA CORPORATION PROPRIETARY INFORMATION
//     This software is supplied under the terms of a license agreement or
//     nondisclosure agreement with TOSHIBA Corporation and may not be copied
//     or disclosed except in accordance with the terms of that agreement.
//           Copyright (c) 1997 TOSHIBA Corporation. All Rights Reserved.
//
//  Workfile: IMAGE.C
//
//  Purpose:
//
//  Contents:
//

#include "strmini.h"
#include "ksmedia.h"
#include "capmain.h"
#include "capdebug.h"
#include "bert.h"
#include "Image.h"


//
// SetInputImageSize
//      Set Input Image Size
//      Set P_SKIP_REG, P_ISIZ_REG
//

BOOL SetInputImageSize(PHW_DEVICE_EXTENSION pHwDevExt, PRECT pRect)
{
        ULONG ulSkipLine;
        ULONG ulSkipPix;
        ULONG ulSrcHeight;
        ULONG ulSrcWidth;

        if((pHwDevExt->MaxRect.bottom < pRect->bottom) || (pHwDevExt->MaxRect.right < pRect->right)) { // Mod 97-04-09(Wed)
            return FALSE;
        }

        ulSkipLine = pRect->left & 0x000003ff;
        ulSkipPix = pRect->top & 0x000003ff;
        ulSrcHeight = (pRect->bottom - pRect->top) & 0x000003ff;
        ulSrcWidth = (pRect->right - pRect->left) & 0x000003ff;

        ReadModifyWriteRegUlong(pHwDevExt, BERT_P_SKIP_REG, 0xfc00ffff, ulSkipLine << 16);
        ReadModifyWriteRegUlong(pHwDevExt, BERT_P_SKIP_REG, 0xfffffc00, ulSkipPix);

        ReadModifyWriteRegUlong(pHwDevExt, BERT_P_ISIZ_REG, 0xfc00ffff, ulSrcHeight << 16);
        ReadModifyWriteRegUlong(pHwDevExt, BERT_P_ISIZ_REG, 0xfffffc00, ulSrcWidth);

        return TRUE;
}


//
// SetOutputImageSize
//      Set Output Image Size
//      Set P_OSIZ_REG
//

BOOL SetOutputImageSize(PHW_DEVICE_EXTENSION pHwDevExt,
                                       ULONG ulWidth,
                                       ULONG ulHeight
                                                )
{
        ULONG ulMaxWidth = pHwDevExt->MaxRect.right - pHwDevExt->MaxRect.left;
        ULONG ulMaxHeight = pHwDevExt->MaxRect.bottom - pHwDevExt->MaxRect.top;

        if((ulWidth <= ulMaxWidth) && (ulHeight <= ulMaxHeight)){       // Mod 97-04-09(Wed)
                ulWidth &= 0x000003ff;
                ulHeight &= 0x000003ff;
                ulHeight <<= 16;
                ReadModifyWriteRegUlong(pHwDevExt, BERT_P_OSIZ_REG, 0xfffffc00, ulWidth);
                ReadModifyWriteRegUlong(pHwDevExt, BERT_P_OSIZ_REG, 0xfc00ffff, ulHeight);
        }
        else{
                return FALSE;
        }
        return TRUE;
}


//
// SetLumiInfo
//      Set Luminance Info
//      Set P_LUMI_REG
//

BOOL SetLumiInfo(PHW_DEVICE_EXTENSION pHwDevExt,
                                ULONG ulContrast,
                                ULONG ulBrightness
                                 )
{
        if(ulContrast > 0xff){
                return FALSE;
        }
        if(ulBrightness > 0xff){
                return FALSE;
        }

        ulContrast >>= 1;       // 1/2
        ulContrast <<= 8;
        ReadModifyWriteRegUlong(pHwDevExt, BERT_P_LUMI_REG, 0xffff80ff, ulContrast);
        ReadModifyWriteRegUlong(pHwDevExt, BERT_P_LUMI_REG, 0xffffff00, ulBrightness);
        return TRUE;
}


//
// SetColorInfo
//      Set Color Info
//      Set P_COL_REG
//

BOOL SetColorInfo(PHW_DEVICE_EXTENSION pHwDevExt,   // Mod 97-04-12(Sat)
                                 ULONG ulHue,
                                 ULONG ulSaturation
                                  )
{
        ULONG   ulUFU, ulVFU, ulUFV, ulVFV;
        ULONG   ulUFUVFU, ulUFVVFV;
        long    lSatu;

        long sindata[256] = {
                -1, -1, -1, -1, -1, -1, -1, -1, -1,                             // 1/sin(-128~-120)     0~8
                -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,                 // 1/sin(-119~-110)     9~18
                -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,                 // 1/sin(-109~-100)     19~28
                -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,                 // 1/sin(-99~-90)       29~38
                -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,                 // 1/sin(-89~-80)       39~48
                -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,                 // 1/sin(-79~-70)       49~58
                -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,                 // 1/sin(-69~-60)       59~68
                -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,                 // 1/sin(-59~-50)       69~78
                -1, -1, -1, -1, -1, -1, -1, -1, -2, -2,                 // 1/sin(-49~-40)       79~88
                -2, -2, -2, -2, -2, -2, -2, -2, -2, -2,                 // 1/sin(-39~-30)       89~98
                -2, -2, -2, -2, -2, -2, -3, -3, -3, -3,                 // 1/sin(-29~-20)       99~108
                -3, -3, -3, -4, -4, -4, -4, -5, -5, -6,                 // 1/sin(-19~-10)       109~118
                -6, -7, -8, -10, -11, -14, -19, -29, -57,               // 1/sin(-9~-1)         119~127
                0,                                                                                              // 1/sin(0)                     128
                57, 29, 19, 14, 11, 10, 8, 7, 6, 6,                             // 1/sin(1~10)          129~138
                5, 5, 4, 4, 4, 4, 3, 3, 3, 3,                                   // 1/sin(11~20)         139~148
                3, 3, 3, 2, 2, 2, 2, 2, 2, 2,                                   // 1/sin(21~30)         149~158
                2, 2, 2, 2, 2, 2, 2, 2, 2, 2,                                   // 1/sin(31~40)         159~168
                2, 1, 1, 1, 1, 1, 1, 1, 1, 1,                                   // 1/sin(41~50)         169~178
                1, 1, 1, 1, 1, 1, 1, 1, 1, 1,                                   // 1/sin(51~60)         179~188
                1, 1, 1, 1, 1, 1, 1, 1, 1, 1,                                   // 1/sin(61~70)         189~198
                1, 1, 1, 1, 1, 1, 1, 1, 1, 1,                                   // 1/sin(71~80)         199~208
                1, 1, 1, 1, 1, 1, 1, 1, 1, 1,                                   // 1/sin(81~90)         209~218
                1, 1, 1, 1, 1, 1, 1, 1, 1, 1,                                   // 1/sin(91~100)        219~228
                1, 1, 1, 1, 1, 1, 1, 1, 1, 1,                                   // 1/sin(101~110)       229~238
                1, 1, 1, 1, 1, 1, 1, 1, 1, 1,                                   // 1/sin(111~120)       239~248
                1, 1, 1, 1, 1, 1, 1                                                             // 1/sin(121~127)       249~255
        };
        long cosdata[256] = {
                -2, -2, -2, -2, -2, -2, -2, -2, -2,                             // 1/cos(-128~-120)     0~8
                -2, -2, -2, -2, -2, -2, -3, -3, -3, -3,                 // 1/cos(-119~-110)     9~18
                -3, -3, -3, -4, -4, -4, -4, -5, -5, -6,                 // 1/cos(-109~-100)     19~28
                -6, -7, -8, -10, -11, -14, -19, -29, -57,               // 1/cos(-99~-91)       29~37
                0,                                                                                              // 1/cos(-90)           38
                57, 29, 19, 14, 11, 10, 8, 7, 6, 6,                             // 1/cos(-89~-80)       39~48
                5, 5, 4, 4, 4, 4, 3, 3, 3, 3,                                   // 1/cos(-79~-70)       49~58
                3, 3, 3, 2, 2, 2, 2, 2, 2, 2,                                   // 1/cos(-69~-60)       59~68
                2, 2, 2, 2, 2, 2, 2, 2, 2, 2,                                   // 1/cos(-59~-50)       69~78
                2, 1, 1, 1, 1, 1, 1, 1, 1, 1,                                   // 1/cos(-49~-40)       79~88
                1, 1, 1, 1, 1, 1, 1, 1, 1, 1,                                   // 1/cos(-39~-30)       89~98
                1, 1, 1, 1, 1, 1, 1, 1, 1, 1,                                   // 1/cos(-29~-20)       99~108
                1, 1, 1, 1, 1, 1, 1, 1, 1, 1,                                   // 1/cos(-19~-10)       109~118
                1, 1, 1, 1, 1, 1, 1, 1, 1, 1,                                   // 1/cos(-9~0)          119~128
                1, 1, 1, 1, 1, 1, 1, 1, 1, 1,                                   // 1/cos(1~10)          129~138
                1, 1, 1, 1, 1, 1, 1, 1, 1, 1,                                   // 1/cos(11~20)         139~148
                1, 1, 1, 1, 1, 1, 1, 1, 1, 1,                                   // 1/cos(21~30)         149~158
                1, 1, 1, 1, 1, 1, 1, 1, 1, 1,                                   // 1/cos(31~40)         159~168
                1, 1, 1, 1, 1, 1, 1, 1, 2, 2,                                   // 1/cos(41~50)         169~178
                2, 2, 2, 2, 2, 2, 2, 2, 2, 2,                                   // 1/cos(51~60)         179~188
                2, 2, 2, 2, 2, 2, 3, 3, 3, 3,                                   // 1/cos(61~70)         189~198
                3, 3, 3, 4, 4, 4, 4, 5, 5, 6,                                   // 1/cos(71~80)         199~208
                6, 7, 8, 10, 11, 14, 19, 29, 57,                                // 1/cos(81~89)         209~217
                0,                                                                                              // 1/cos(90)            218
                -57, -29, -19, -14, -11, -10, -8, -7, -6, -6,   // 1/cos(91~100)        219~228
                -5, -5, -4, -4, -4, -4, -3, -3, -3, -3,                 // 1/cos(101~110)       229~238
                -3, -3, -3, -2, -2, -2, -2, -2, -2, -2,                 // 1/cos(111~120)       239~248
                -2, -2, -2, -2, -2, -2, -2                                              // 1/cos(121~127)       249~255
        };

        if(ulHue > 0xff){
                return FALSE;
        }
        if(ulSaturation > 0xff){
                return FALSE;
        }
        lSatu = ulSaturation / 2;       // Mod 97-05-10(Sat)

        switch(ulHue){
                case 38:        // -90
                        ulUFU = 128;
                        ulVFU = lSatu + 128;
                        ulUFV = -lSatu + 127;
                        ulVFV = 128;
                        break;
                case 128:       // 0
                        ulUFU = lSatu + 128;
                        ulVFU = 128;
                        ulUFV = 128;
                        ulVFV = lSatu + 128;
                        break;
                case 218:       // 90
                        ulUFU = 128;
                        ulVFU = -lSatu + 127;
                        ulUFV = lSatu + 128;
                        ulVFV = 128;
                        break;
                default:
                        ulUFU = lSatu / cosdata[ulHue] + 128;
                        ulVFU = -lSatu / sindata[ulHue] + 128;
                        ulUFV = lSatu / sindata[ulHue] + 128;
                        ulVFV = lSatu / cosdata[ulHue] + 128;
                        break;
        }

        ulUFU &= 0xff;  // Add 97-04-19(Sat)
        ulVFU &= 0xff;
        ulUFV &= 0xff;
        ulVFV &= 0xff;

        ulUFUVFU = ulUFU << 24 | ulVFU << 16;
        ulUFVVFV = ulUFV << 8 | ulVFV;

        ReadModifyWriteRegUlong(pHwDevExt, BERT_P_COL_REG, 0x0000ffff, ulUFUVFU);
        ReadModifyWriteRegUlong(pHwDevExt, BERT_P_COL_REG, 0xffff0000, ulUFVVFV);

        return TRUE;
}


//
// SetChgColInfo
//      Set ChangeColor Info
//      Set P_LUMI_REG
//

BOOL SetChgColInfo(PHW_DEVICE_EXTENSION pHwDevExt,
                                  ULONG ulChgCol
                                 )
{
        switch(ulChgCol){
                case IMAGE_CHGCOL_AVAIL:
                case IMAGE_CHGCOL_NOTAVAIL:
                        ReadModifyWriteRegUlong(pHwDevExt, BERT_P_LUMI_REG, 0xfffeffff, ulChgCol);
                        break;
                default:
                        ReadModifyWriteRegUlong(pHwDevExt, BERT_P_LUMI_REG, 0xfffeffff, 0UL);
                        break;
        }

        return TRUE;
}


//
// SetVerticalFilterInfo
//      Set Vertical Filter Info
//      Set P_FILT_REG
//

BOOL SetVerticalFilterInfo(PHW_DEVICE_EXTENSION pHwDevExt,
                                          ULONG ulVFL
                                                   )
{
        switch(ulVFL){
                case IMAGE_VFL:
                        ReadModifyWriteRegUlong(pHwDevExt, BERT_P_FILT_REG, 0xfffeffff, ulVFL);  // Mod 97-04-14(Mon)
                        break;
                default:
                        ReadModifyWriteRegUlong(pHwDevExt, BERT_P_FILT_REG, 0xfffeffff, 0UL);
                        break;
        }

        return TRUE;
}


//
// SetHorizontalFilterInfo
//      Set Horizontal Filter Info
//      Set P_FILT_REG
//

BOOL SetHorizontalFilterInfo(PHW_DEVICE_EXTENSION pHwDevExt,
                                            ULONG ulFL1,
                                            ULONG ulFL2,
                                            ULONG ulFL3,
                                            ULONG ulFL4
                                                         )
{
        switch(ulFL1){
                case IMAGE_FL_0:
                case IMAGE_FL_1:
                        ReadModifyWriteRegUlong(pHwDevExt, BERT_P_FILT_REG, 0xfffffff8, ulFL1);
                        break;
                default:
                        ReadModifyWriteRegUlong(pHwDevExt, BERT_P_FILT_REG, 0xfffffff8, 0UL);
                        break;
        }
        switch(ulFL2){
                case IMAGE_FL_0:
                case IMAGE_FL_1:
                        ReadModifyWriteRegUlong(pHwDevExt, BERT_P_FILT_REG, 0xffffff8f, ulFL2 << 4);
                        break;
                case IMAGE_FL_2:
                case IMAGE_FL_3:
                case IMAGE_FL_4:
                default:
                        ReadModifyWriteRegUlong(pHwDevExt, BERT_P_FILT_REG, 0xffffff8f, 0UL);
                        break;
        }
        switch(ulFL3){
                case IMAGE_FL_0:
                case IMAGE_FL_1:
                case IMAGE_FL_2:
                case IMAGE_FL_4:
                        ReadModifyWriteRegUlong(pHwDevExt, BERT_P_FILT_REG, 0xfffff8ff, ulFL3 << 8);
                        break;
                case IMAGE_FL_3:
                default:
                        ReadModifyWriteRegUlong(pHwDevExt, BERT_P_FILT_REG, 0xfffff8ff, 0UL);
                        break;
        }
        switch(ulFL4){
                case IMAGE_FL_0:
                case IMAGE_FL_2:
                case IMAGE_FL_4:
                        ReadModifyWriteRegUlong(pHwDevExt, BERT_P_FILT_REG, 0xffff8fff, ulFL4 << 12);
                        break;
                case IMAGE_FL_1:
                case IMAGE_FL_3:
                default:
                        ReadModifyWriteRegUlong(pHwDevExt, BERT_P_FILT_REG, 0xffff8fff, 0UL);
                        break;
        }

        return TRUE;
}


//
// ImageSetInputImageSize
//      Set Input Image Size
//      Set P_SKIP_REG, P_ISIZ_REG
//

BOOL ImageSetInputImageSize(PHW_DEVICE_EXTENSION pHwDevExt,
                                           PRECT pRect
                                                        )
{
        if(!SetInputImageSize(pHwDevExt, pRect)){
                return FALSE;
        }
        return TRUE;
}


//
// ImageSetOutputImageSize
//      Set Output Image Size
//      Set P_OSIZ_REG
//

BOOL ImageSetOutputImageSize(PHW_DEVICE_EXTENSION pHwDevExt,
                                            ULONG ulWidth,
                                            ULONG ulHeight
                                                         )
{
        if(!SetOutputImageSize(pHwDevExt, ulWidth, ulHeight)){
                return FALSE;
        }

        if(!ImageGetFilteringAvailable(pHwDevExt)){
                ImageFilterOFF(pHwDevExt);
        }
        else if(ImageGetFilterInfo(pHwDevExt)){          // Add 97-05-13(Tue)
                ImageFilterON(pHwDevExt);
        }

        return TRUE;
}


//
// ImageSetChangeColorAvail
//      Set/Reset CHGCOL Bit
//      Set P_LUMI_REG
//

BOOL ImageSetChangeColorAvail(PHW_DEVICE_EXTENSION pHwDevExt,
                                             ULONG ulChgCol
                                                          )
{
        if(!SetChgColInfo(pHwDevExt, ulChgCol)){
                return FALSE;
        }
        return TRUE;
}


//
// ImageSetHueBrightnessContrastSat
//      Set Color Info
//      Call SetLumiImfo, SetColorInfo
//

BOOL ImageSetHueBrightnessContrastSat(PHW_DEVICE_EXTENSION pHwDevExt) // Mod 97-04-08(Tue)
{
#ifdef  TOSHIBA
        if(!SetLumiInfo(pHwDevExt, pHwDevExt->Contrast, pHwDevExt->Brightness)){
                return FALSE;
        }
        if(!SetColorInfo(pHwDevExt, pHwDevExt->Hue, pHwDevExt->Saturation)){
                return FALSE;
        }
#else //TOSHIBA
        if(!SetLumiInfo(pHwDevExt, pHwDevExt->ulContrast, pHwDevExt->ulBrightness)){
                return FALSE;
        }
        if(!SetColorInfo(pHwDevExt, pHwDevExt->ulHue, pHwDevExt->ulSaturation)){
                return FALSE;
        }
#endif//TOSHIBA
        return TRUE;
}


//
// ImageSetFilterInfo
//      Set Filter Info
//      Set P_FILT_REG
//

BOOL ImageSetFilterInfo(PHW_DEVICE_EXTENSION pHwDevExt,
                                       ULONG                   ulVFL,
                                       ULONG                   ulFL1,
                                       ULONG                   ulFL2,
                                       ULONG                   ulFL3,
                                       ULONG                   ulFL4
                                                )
{
        if(!SetHorizontalFilterInfo(pHwDevExt, ulFL1, ulFL2, ulFL3, ulFL4)){
                return FALSE;
        }
        if(!SetVerticalFilterInfo(pHwDevExt, ulVFL)){
                return FALSE;
        }
        return TRUE;
}


//
// ImageFilterON
//
//      Set P_FILT_REG
//

BOOL ImageFilterON(PHW_DEVICE_EXTENSION pHwDevExt)
{
        ULONG   ulFL1, ulFL2, ulFL3, ulFL4;

        if(pHwDevExt->ulWidth <= 80){         // 0 < Width <= 80
                ulFL1 = IMAGE_FL_1;
                ulFL2 = IMAGE_FL_1;
                ulFL3 = IMAGE_FL_2;
                ulFL4 = IMAGE_FL_4;
        }
        else if((pHwDevExt->ulWidth > 80) && (pHwDevExt->ulWidth <= 160)){  // 80 < Width <= 160
                ulFL1 = IMAGE_FL_1;
                ulFL2 = IMAGE_FL_1;
                ulFL3 = IMAGE_FL_2;
                ulFL4 = IMAGE_FL_0;
        }
        else{                                           // 160 < Width
                ulFL1 = IMAGE_FL_1;
                ulFL2 = IMAGE_FL_1;
                ulFL3 = IMAGE_FL_0;
                ulFL4 = IMAGE_FL_0;
        }

        if(!SetHorizontalFilterInfo(pHwDevExt, ulFL1, ulFL2, ulFL3, ulFL4)){
                return FALSE;
        }
        if(!SetVerticalFilterInfo(pHwDevExt, IMAGE_VFL)){
                return FALSE;
        }
        return TRUE;
}


//
// ImageFilterOFF
//
//      Set P_FILT_REG
//

BOOL ImageFilterOFF(PHW_DEVICE_EXTENSION pHwDevExt)
{
        ReadModifyWriteRegUlong(pHwDevExt, BERT_P_FILT_REG, 0xfffe0000, 0UL);
        return TRUE;
}


//
// ImageGetFilterInfo
//      Get Filter Info
//

BOOL ImageGetFilterInfo(PHW_DEVICE_EXTENSION pHwDevExt)
{
        if(!ReadRegUlong(pHwDevExt, BERT_P_FILT_REG)){
                return FALSE;
        }
        return TRUE;
}


//
// ImageGetFilteringAvailable
//

BOOL ImageGetFilteringAvailable(PHW_DEVICE_EXTENSION pHwDevExt)
{
        ULONG ulISIZ, ulOSIZ;
        ULONG ulFL, ulFL1, ulFL2, ulFL3, ulFL4;

        ulISIZ = ReadRegUlong(pHwDevExt, BERT_P_ISIZ_REG);
        ulISIZ &= 0x3ff;
        ulOSIZ = ReadRegUlong(pHwDevExt, BERT_P_OSIZ_REG);
        ulOSIZ &= 0x3ff;
        ulFL = ReadRegUlong(pHwDevExt, BERT_P_FILT_REG);
        ulFL1 = ulFL & 0x7;
        ulFL2 = (ulFL >> 4) & 0x7;
        ulFL3 = (ulFL >> 8) & 0x7;
        ulFL4 = (ulFL >> 12) & 0x7;

        if((ulOSIZ > 400) || (ulOSIZ == 640)){
                return FALSE;
        }
        if((ulISIZ - ulOSIZ) < ((ulFL1 + ulFL2 + ulFL3 + ulFL4) * 2)){
                return FALSE;
        }
        return TRUE;
}



=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\drivers\wdm\capture\mini\tecra750\capstrm.h ===
//==========================================================================;
//
//  THIS CODE AND INFORMATION IS PROVIDED "AS IS" WITHOUT WARRANTY OF ANY
//  KIND, EITHER EXPRESSED OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE
//  IMPLIED WARRANTIES OF MERCHANTABILITY AND/OR FITNESS FOR A PARTICULAR
//  PURPOSE.
//
//  Copyright (c) 1992 - 1996  Microsoft Corporation.  All Rights Reserved.
//
//==========================================================================;

#ifndef __CAPSTRM_H__
#define __CAPSTRM_H__

#ifdef __cplusplus
extern "C" {
#endif // __cplusplus


KSPIN_MEDIUM StandardMedium = {
    STATIC_KSMEDIUMSETID_Standard,
    0, 0
};

// ------------------------------------------------------------------------
// The master list of all streams supported by this driver
// ------------------------------------------------------------------------

typedef enum {
    STREAM_Capture,
#ifndef TOSHIBA
    STREAM_Preview,
    STREAM_AnalogVideoInput
#endif//TOSHIBA
};

// ------------------------------------------------------------------------
// Property sets for all video capture streams
// ------------------------------------------------------------------------

DEFINE_KSPROPERTY_TABLE(VideoStreamConnectionProperties)
{
    DEFINE_KSPROPERTY_ITEM
    (
        KSPROPERTY_CONNECTION_ALLOCATORFRAMING,
        TRUE,                                   // GetSupported or Handler
        sizeof(KSPROPERTY),                     // MinProperty
        sizeof(KSALLOCATOR_FRAMING),            // MinData
        FALSE,                                  // SetSupported or Handler
        NULL,                                   // Values
        0,                                      // RelationsCount
        NULL,                                   // Relations
        NULL,                                   // SupportHandler
        0                                       // SerializedSize
    ),
};

DEFINE_KSPROPERTY_TABLE(VideoStreamDroppedFramesProperties)
{
    DEFINE_KSPROPERTY_ITEM
    (
        KSPROPERTY_DROPPEDFRAMES_CURRENT,
        TRUE,                                   // GetSupported or Handler
        sizeof(KSPROPERTY_DROPPEDFRAMES_CURRENT_S),// MinProperty
        sizeof(KSPROPERTY_DROPPEDFRAMES_CURRENT_S),// MinData
        FALSE,                                  // SetSupported or Handler
        NULL,                                   // Values
        0,                                      // RelationsCount
        NULL,                                   // Relations
        NULL,                                   // SupportHandler
        0                                       // SerializedSize
    ),
};


// ------------------------------------------------------------------------
// Array of all of the property sets supported by video streams
// ------------------------------------------------------------------------

DEFINE_KSPROPERTY_SET_TABLE(VideoStreamProperties)
{
    DEFINE_KSPROPERTY_SET
    (
        &KSPROPSETID_Connection,                        // Set
        SIZEOF_ARRAY(VideoStreamConnectionProperties),  // PropertiesCount
        VideoStreamConnectionProperties,                // PropertyItem
        0,                                              // FastIoCount
        NULL                                            // FastIoTable
    ),
    DEFINE_KSPROPERTY_SET
    (
        &PROPSETID_VIDCAP_DROPPEDFRAMES,                // Set
        SIZEOF_ARRAY(VideoStreamDroppedFramesProperties),  // PropertiesCount
        VideoStreamDroppedFramesProperties,             // PropertyItem
        0,                                              // FastIoCount
        NULL                                            // FastIoTable
    ),
};

#define NUMBER_VIDEO_STREAM_PROPERTIES (SIZEOF_ARRAY(VideoStreamProperties))

//---------------------------------------------------------------------------
// All of the video and vbi data formats we might use
//---------------------------------------------------------------------------

#define D_X 320
#define D_Y 240

#ifdef  TOSHIBA
static  KS_DATARANGE_VIDEO StreamFormatYVU9_Capture =
{
    // KSDATARANGE
    {
        sizeof (KS_DATARANGE_VIDEO),            // FormatSize
        0,                                      // Flags
        (D_X * D_Y * 9)/8,                      // SampleSize
        0,                                      // Reserved

        STATIC_KSDATAFORMAT_TYPE_VIDEO,         // aka. MEDIATYPE_Video
        FOURCC_YVU9, 0x0000, 0x0010, 0x80, 0x00, 0x00, 0xaa, 0x00, 0x38, 0x9b, 0x71,  //MEDIASUBTYPE_YVU9
        STATIC_KSDATAFORMAT_SPECIFIER_VIDEOINFO // aka. FORMAT_VideoInfo
    },

    TRUE,               // BOOL,  bFixedSizeSamples (all samples same size?)
    TRUE,               // BOOL,  bTemporalCompression (all I frames?)
    0,                  // Reserved (was StreamDescriptionFlags)
    0,                  // Reserved (was MemoryAllocationFlags   (KS_VIDEO_ALLOC_*))

    // _KS_VIDEO_STREAM_CONFIG_CAPS
    {
        STATIC_KSDATAFORMAT_SPECIFIER_VIDEOINFO, // GUID
#if 1
        KS_AnalogVideo_None,    // VideoStandard
#else
        KS_AnalogVideo_NTSC_M |
        KS_AnalogVideo_PAL_B,                    // AnalogVideoStandard
#endif
        640,480,        // InputSize, (the inherent size of the incoming signal
                        //             with every digitized pixel unique)
        160,120,        // MinCroppingSize, smallest rcSrc cropping rect allowed
        640,480,        // MaxCroppingSize, largest  rcSrc cropping rect allowed
        2,              // CropGranularityX, granularity of cropping size
        2,              // CropGranularityY
        2,              // CropAlignX, alignment of cropping rect
        2,              // CropAlignY;
        160, 120,       // MinOutputSize, smallest bitmap stream can produce
        640, 480,       // MaxOutputSize, largest  bitmap stream can produce
        16,             // OutputGranularityX, granularity of output bitmap size
        4,              // OutputGranularityY;
        0,              // StretchTapsX  (0 no stretch, 1 pix dup, 2 interp...)
        0,              // StretchTapsY
        2,              // ShrinkTapsX
        2,              // ShrinkTapsY
        333667,         // MinFrameInterval, 100 nS units
        640000000,      // MaxFrameInterval, 100 nS units
        30 * 160 * 120 * 9,  // MinBitsPerSecond;
        30 * 640 * 480 * 9   // MaxBitsPerSecond;
    },

    // KS_VIDEOINFOHEADER (default format)
    {
        0,0,0,0,                            // RECT  rcSource;
        0,0,0,0,                            // RECT  rcTarget;
        D_X * D_Y * 9 / 8 * 30,             // DWORD dwBitRate;
        0L,                                 // DWORD dwBitErrorRate;
        333667,                             // REFERENCE_TIME  AvgTimePerFrame;

        sizeof (KS_BITMAPINFOHEADER),       // DWORD biSize;
        D_X,                                // LONG  biWidth;
        D_Y,                                // LONG  biHeight;
        1,                                  // WORD  biPlanes;
        9,                                  // WORD  biBitCount;
        FOURCC_YVU9,                        // DWORD biCompression;
        D_X * D_Y * 9 / 8,                  // DWORD biSizeImage;
        0,                                  // LONG  biXPelsPerMeter;
        0,                                  // LONG  biYPelsPerMeter;
        0,                                  // DWORD biClrUsed;
        0                                   // DWORD biClrImportant;
    }
};

static  KS_DATARANGE_VIDEO StreamFormatYUV12_Capture =
{
    // KSDATARANGE
    {
        sizeof (KS_DATARANGE_VIDEO),            // FormatSize
        0,                                      // Flags
        (D_X * D_Y * 12)/8,                     // SampleSize
        0,                                      // Reserved

        STATIC_KSDATAFORMAT_TYPE_VIDEO,         // aka. MEDIATYPE_Video
        FOURCC_YUV12, 0x0000, 0x0010, 0x80, 0x00, 0x00, 0xaa, 0x00, 0x38, 0x9b, 0x71, //MEDIASUBTYPE_YUV12
        STATIC_KSDATAFORMAT_SPECIFIER_VIDEOINFO // aka. FORMAT_VideoInfo
    },

    TRUE,               // BOOL,  bFixedSizeSamples (all samples same size?)
    TRUE,               // BOOL,  bTemporalCompression (all I frames?)
    0,                  // Reserved (was StreamDescriptionFlags)
    0,                  // Reserved (was MemoryAllocationFlags   (KS_VIDEO_ALLOC_*))

    // _KS_VIDEO_STREAM_CONFIG_CAPS
    {
        STATIC_KSDATAFORMAT_SPECIFIER_VIDEOINFO, // GUID
#if 1
        KS_AnalogVideo_None,    // VideoStandard
#else
        KS_AnalogVideo_NTSC_M |
        KS_AnalogVideo_PAL_B,                    // AnalogVideoStandard
#endif
        640,480,        // InputSize, (the inherent size of the incoming signal
                        //             with every digitized pixel unique)
        160,120,        // MinCroppingSize, smallest rcSrc cropping rect allowed
        640,480,        // MaxCroppingSize, largest  rcSrc cropping rect allowed
        2,              // CropGranularityX, granularity of cropping size
        2,              // CropGranularityY
        2,              // CropAlignX, alignment of cropping rect
        2,              // CropAlignY;
        160, 120,       // MinOutputSize, smallest bitmap stream can produce
        640, 480,       // MaxOutputSize, largest  bitmap stream can produce
        16,             // OutputGranularityX, granularity of output bitmap size
        4,              // OutputGranularityY;
        0,              // StretchTapsX  (0 no stretch, 1 pix dup, 2 interp...)
        0,              // StretchTapsY
        2,              // ShrinkTapsX
        2,              // ShrinkTapsY
        333667,         // MinFrameInterval, 100 nS units
        640000000,      // MaxFrameInterval, 100 nS units
        30 * 160 * 120 * 12, // MinBitsPerSecond;
        30 * 640 * 480 * 12  // MaxBitsPerSecond;
    },

    // KS_VIDEOINFOHEADER (default format)
    {
        0,0,0,0,                            // RECT  rcSource;
        0,0,0,0,                            // RECT  rcTarget;
        D_X * D_Y * 12 / 8 * 30,            // DWORD dwBitRate;
        0L,                                 // DWORD dwBitErrorRate;
        333667,                             // REFERENCE_TIME  AvgTimePerFrame;

        sizeof (KS_BITMAPINFOHEADER),       // DWORD biSize;
        D_X,                                // LONG  biWidth;
        D_Y,                                // LONG  biHeight;
        1,                                  // WORD  biPlanes;
        12,                                 // WORD  biBitCount;
        FOURCC_YUV12,                       // DWORD biCompression;
        D_X * D_Y * 12 / 8,                 // DWORD biSizeImage;
        0,                                  // LONG  biXPelsPerMeter;
        0,                                  // LONG  biYPelsPerMeter;
        0,                                  // DWORD biClrUsed;
        0                                   // DWORD biClrImportant;
    }
};
#else //TOSHIBA
static  KS_DATARANGE_VIDEO StreamFormatRGB24Bpp_Capture =
{
    // KSDATARANGE
    {
        sizeof (KS_DATARANGE_VIDEO),            // FormatSize
        0,                                      // Flags
        D_X * D_Y * 3,                          // SampleSize
        0,                                      // Reserved

        STATIC_KSDATAFORMAT_TYPE_VIDEO,         // aka. MEDIATYPE_Video
        0xe436eb7d, 0x524f, 0x11ce, 0x9f, 0x53, 0x00, 0x20, 0xaf, 0x0b, 0xa7, 0x70, //MEDIASUBTYPE_RGB24,
        STATIC_KSDATAFORMAT_SPECIFIER_VIDEOINFO // aka. FORMAT_VideoInfo
    },

    TRUE,               // BOOL,  bFixedSizeSamples (all samples same size?)
    TRUE,               // BOOL,  bTemporalCompression (all I frames?)
    0,                  // Reserved (was StreamDescriptionFlags)
    0,                  // Reserved (was MemoryAllocationFlags   (KS_VIDEO_ALLOC_*))

    // _KS_VIDEO_STREAM_CONFIG_CAPS
    {
        STATIC_KSDATAFORMAT_SPECIFIER_VIDEOINFO, // GUID
        KS_AnalogVideo_NTSC_M |
        KS_AnalogVideo_PAL_B,                    // AnalogVideoStandard
        720,480,        // InputSize, (the inherent size of the incoming signal
                        //             with every digitized pixel unique)
        160,120,        // MinCroppingSize, smallest rcSrc cropping rect allowed
        720,480,        // MaxCroppingSize, largest  rcSrc cropping rect allowed
        8,              // CropGranularityX, granularity of cropping size
        1,              // CropGranularityY
        8,              // CropAlignX, alignment of cropping rect
        1,              // CropAlignY;
        160, 120,       // MinOutputSize, smallest bitmap stream can produce
        720, 480,       // MaxOutputSize, largest  bitmap stream can produce
        8,              // OutputGranularityX, granularity of output bitmap size
        1,              // OutputGranularityY;
        0,              // StretchTapsX  (0 no stretch, 1 pix dup, 2 interp...)
        0,              // StretchTapsY
        0,              // ShrinkTapsX
        0,              // ShrinkTapsY
        333667,         // MinFrameInterval, 100 nS units
        640000000,      // MaxFrameInterval, 100 nS units
        8 * 3 * 30 * 160 * 120,  // MinBitsPerSecond;
        8 * 3 * 30 * 720 * 480   // MaxBitsPerSecond;
    },

    // KS_VIDEOINFOHEADER (default format)
    {
        0,0,0,0,                            // RECT  rcSource;
        0,0,0,0,                            // RECT  rcTarget;
        D_X * D_Y * 3 * 30,                 // DWORD dwBitRate;
        0L,                                 // DWORD dwBitErrorRate;
        333667,                             // REFERENCE_TIME  AvgTimePerFrame;

        sizeof (KS_BITMAPINFOHEADER),       // DWORD biSize;
        D_X,                                // LONG  biWidth;
        D_Y,                                // LONG  biHeight;
        1,                                  // WORD  biPlanes;
        24,                                 // WORD  biBitCount;
        KS_BI_RGB,                          // DWORD biCompression;
        D_X * D_Y * 3,                      // DWORD biSizeImage;
        0,                                  // LONG  biXPelsPerMeter;
        0,                                  // LONG  biYPelsPerMeter;
        0,                                  // DWORD biClrUsed;
        0                                   // DWORD biClrImportant;
    }
};

#undef D_X
#undef D_Y

#define D_X 320
#define D_Y 240


static  KS_DATARANGE_VIDEO StreamFormatUYU2_Capture =
{
    // KSDATARANGE
    {
        sizeof (KS_DATARANGE_VIDEO),            // FormatSize
        0,                                      // Flags
        D_X * D_Y * 2,                          // SampleSize
        0,                                      // Reserved

        STATIC_KSDATAFORMAT_TYPE_VIDEO,         // aka. MEDIATYPE_Video
        0x59565955, 0x0000, 0x0010, 0x80, 0x00, 0x00, 0xaa, 0x00, 0x38, 0x9b, 0x71, //MEDIASUBTYPE_UYVY,
        STATIC_KSDATAFORMAT_SPECIFIER_VIDEOINFO // aka. FORMAT_VideoInfo
    },

    TRUE,               // BOOL,  bFixedSizeSamples (all samples same size?)
    TRUE,               // BOOL,  bTemporalCompression (all I frames?)
    0,                  // Reserved (was StreamDescriptionFlags)
    0,                  // Reserved (was MemoryAllocationFlags   (KS_VIDEO_ALLOC_*))

    // _KS_VIDEO_STREAM_CONFIG_CAPS
    {
        STATIC_KSDATAFORMAT_SPECIFIER_VIDEOINFO, // GUID
        KS_AnalogVideo_NTSC_M |
        KS_AnalogVideo_PAL_B,                    // AnalogVideoStandard
        720,480,        // InputSize, (the inherent size of the incoming signal
                        //             with every digitized pixel unique)
        160,120,        // MinCroppingSize, smallest rcSrc cropping rect allowed
        720,480,        // MaxCroppingSize, largest  rcSrc cropping rect allowed
        8,              // CropGranularityX, granularity of cropping size
        1,              // CropGranularityY
        8,              // CropAlignX, alignment of cropping rect
        1,              // CropAlignY;
        160, 120,       // MinOutputSize, smallest bitmap stream can produce
        720, 480,       // MaxOutputSize, largest  bitmap stream can produce
        8,              // OutputGranularityX, granularity of output bitmap size
        1,              // OutputGranularityY;
        0,              // StretchTapsX  (0 no stretch, 1 pix dup, 2 interp...)
        0,              // StretchTapsY
        0,              // ShrinkTapsX
        0,              // ShrinkTapsY
        333667,         // MinFrameInterval, 100 nS units
        640000000,      // MaxFrameInterval, 100 nS units
        8 * 2 * 30 * 160 * 120,  // MinBitsPerSecond;
        8 * 2 * 30 * 720 * 480   // MaxBitsPerSecond;
    },

    // KS_VIDEOINFOHEADER (default format)
    {
        0,0,0,0,                            // RECT  rcSource;
        0,0,0,0,                            // RECT  rcTarget;
        D_X * D_Y * 2 * 30,                 // DWORD dwBitRate;
        0L,                                 // DWORD dwBitErrorRate;
        333667,                             // REFERENCE_TIME  AvgTimePerFrame;

        sizeof (KS_BITMAPINFOHEADER),       // DWORD biSize;
        D_X,                                // LONG  biWidth;
        D_Y,                                // LONG  biHeight;
        1,                                  // WORD  biPlanes;
        16,                                 // WORD  biBitCount;
        FOURCC_YUV422,                      // DWORD biCompression;
        D_X * D_Y * 2,                      // DWORD biSizeImage;
        0,                                  // LONG  biXPelsPerMeter;
        0,                                  // LONG  biYPelsPerMeter;
        0,                                  // DWORD biClrUsed;
        0                                   // DWORD biClrImportant;
    }
};
#endif//TOSHIBA

#undef D_X
#undef D_Y

#ifndef TOSHIBA
static  KS_DATARANGE_ANALOGVIDEO StreamFormatAnalogVideo =
{
    // KS_DATARANGE_ANALOGVIDEO
    {
        sizeof (KS_DATARANGE_ANALOGVIDEO),      // FormatSize
        0,                                      // Flags
        sizeof (KS_TVTUNER_CHANGE_INFO),        // SampleSize
        0,                                      // Reserved

        STATIC_KSDATAFORMAT_TYPE_ANALOGVIDEO,   // aka MEDIATYPE_AnalogVideo
        STATIC_KSDATAFORMAT_SUBTYPE_NONE,
        STATIC_KSDATAFORMAT_SPECIFIER_ANALOGVIDEO, // aka FORMAT_AnalogVideo
    },
    // KS_ANALOGVIDEOINFO
    {
        0, 0, 720, 480,         // rcSource;
        0, 0, 720, 480,         // rcTarget;
        720,                    // dwActiveWidth;
        480,                    // dwActiveHeight;
        0,                      // REFERENCE_TIME  AvgTimePerFrame;
    }
};
#endif//TOSHIBA


//---------------------------------------------------------------------------
//  STREAM_Capture Formats
//---------------------------------------------------------------------------

static  PKSDATAFORMAT Stream0Formats[] =
{
#ifdef  TOSHIBA
    (PKSDATAFORMAT) &StreamFormatYUV12_Capture,
    (PKSDATAFORMAT) &StreamFormatYVU9_Capture,
#else //TOSHIBA
    (PKSDATAFORMAT) &StreamFormatRGB24Bpp_Capture,
    (PKSDATAFORMAT) &StreamFormatUYU2_Capture,
#endif//TOSHIBA
};
#define NUM_STREAM_0_FORMATS (SIZEOF_ARRAY(Stream0Formats))

#ifndef TOSHIBA
//---------------------------------------------------------------------------
//  STREAM_Preview Formats
//---------------------------------------------------------------------------

static  PKSDATAFORMAT Stream1Formats[] =
{
#ifdef  TOSHIBA
    (PKSDATAFORMAT) &StreamFormatYUV12_Capture,
    (PKSDATAFORMAT) &StreamFormatYVU9_Capture,
#else //TOSHIBA
    (PKSDATAFORMAT) &StreamFormatRGB24Bpp_Capture,
    (PKSDATAFORMAT) &StreamFormatUYU2_Capture,
#endif//TOSHIBA
};
#define NUM_STREAM_1_FORMATS (SIZEOF_ARRAY (Stream1Formats))

//---------------------------------------------------------------------------
//  STREAM_AnalogVideoInput Formats
//---------------------------------------------------------------------------

static  PKSDATAFORMAT Stream2Formats[] =
{
    (PKSDATAFORMAT) &StreamFormatAnalogVideo,
};
#define NUM_STREAM_2_FORMATS (SIZEOF_ARRAY (Stream2Formats))
#endif//TOSHIBA

//---------------------------------------------------------------------------
// Create an array that holds the list of all of the streams supported
//---------------------------------------------------------------------------

typedef struct _ALL_STREAM_INFO {
    HW_STREAM_INFORMATION   hwStreamInfo;
    HW_STREAM_OBJECT        hwStreamObject;
} ALL_STREAM_INFO, *PALL_STREAM_INFO;

static  ALL_STREAM_INFO Streams [] =
{
  // -----------------------------------------------------------------
  // STREAM_Capture
  // -----------------------------------------------------------------
  {
    // HW_STREAM_INFORMATION -------------------------------------------
    {
    1,                                      // NumberOfPossibleInstances
    KSPIN_DATAFLOW_OUT,                     // DataFlow
    TRUE,                                   // DataAccessible
    NUM_STREAM_0_FORMATS,                   // NumberOfFormatArrayEntries
    Stream0Formats,                         // StreamFormatsArray
    0,                                      // ClassReserved[0]
    0,                                      // ClassReserved[1]
    0,                                      // ClassReserved[2]
    0,                                      // ClassReserved[3]
    NUMBER_VIDEO_STREAM_PROPERTIES,         // NumStreamPropArrayEntries
    (PKSPROPERTY_SET) VideoStreamProperties,// StreamPropertiesArray
    0,                                      // NumStreamEventArrayEntries;
    0,                                      // StreamEventsArray;
    (GUID *) &PINNAME_VIDEO_CAPTURE,        // Category
    (GUID *) &PINNAME_VIDEO_CAPTURE,        // Name
    1,                                      // MediumsCount
    &StandardMedium,                        // Mediums
        FALSE,                                                                  // BridgeStream
    },

    // HW_STREAM_OBJECT ------------------------------------------------
    {
    sizeof (HW_STREAM_OBJECT),              // SizeOfThisPacket
    0,                                      // StreamNumber
    0,                                      // HwStreamExtension
    VideoReceiveDataPacket,                 // HwReceiveDataPacket
    VideoReceiveCtrlPacket,                 // HwReceiveControlPacket
    { NULL, 0 },                            // HW_CLOCK_OBJECT
    FALSE,                                  // Dma
    TRUE,                                   // Pio
    NULL,                                   // HwDeviceExtension
    sizeof (KS_FRAME_INFO),                 // StreamHeaderMediaSpecific
    0,                                      // StreamHeaderWorkspace
    FALSE,                                  // Allocator
    NULL,                                   // HwEventRoutine
    { 0, 0 },                               // Reserved[2]
    },
#ifndef TOSHIBA
 },
 // -----------------------------------------------------------------
 // STREAM_Preview
 // -----------------------------------------------------------------
 {
    // HW_STREAM_INFORMATION -------------------------------------------
    {
    1,                                      // NumberOfPossibleInstances
    KSPIN_DATAFLOW_OUT,                     // DataFlow
    TRUE,                                   // DataAccessible
    NUM_STREAM_1_FORMATS,                   // NumberOfFormatArrayEntries
    Stream1Formats,                         // StreamFormatsArray
    0,                                      // ClassReserved[0]
    0,                                      // ClassReserved[1]
    0,                                      // ClassReserved[2]
    0,                                      // ClassReserved[3]
    NUMBER_VIDEO_STREAM_PROPERTIES,         // NumStreamPropArrayEntries
    (PKSPROPERTY_SET) VideoStreamProperties,// StreamPropertiesArray
    0,                                      // NumStreamEventArrayEntries;
    0,                                      // StreamEventsArray;
    (GUID *) &PINNAME_VIDEO_PREVIEW,        // Category
    (GUID *) &PINNAME_VIDEO_PREVIEW,        // Name
    1,                                      // MediumsCount
    &StandardMedium,                        // Mediums
        FALSE,                                                                  // BridgeStream
    },

    // HW_STREAM_OBJECT ------------------------------------------------
    {
    sizeof (HW_STREAM_OBJECT),              // SizeOfThisPacket
    1,                                      // StreamNumber
    0,                                      // HwStreamExtension
    VideoReceiveDataPacket,                 // HwReceiveDataPacket
    VideoReceiveCtrlPacket,                 // HwReceiveControlPacket
    { NULL, 0 },                            // HW_CLOCK_OBJECT
    FALSE,                                  // Dma
    TRUE,                                   // Pio
    0,                                      // HwDeviceExtension
    sizeof (KS_FRAME_INFO),                 // StreamHeaderMediaSpecific
    0,                                      // StreamHeaderWorkspace
    FALSE,                                  // Allocator
    NULL,                                   // HwEventRoutine
    { 0, 0 },                               // Reserved[2]
    },
 },
 // -----------------------------------------------------------------
 // STREAM_AnalogVideoInput
 // -----------------------------------------------------------------
 {
    // HW_STREAM_INFORMATION -------------------------------------------
    {
    1,                                      // NumberOfPossibleInstances
    KSPIN_DATAFLOW_IN,                      // DataFlow
    TRUE,                                   // DataAccessible
    NUM_STREAM_2_FORMATS,                   // NumberOfFormatArrayEntries
    Stream2Formats,                         // StreamFormatsArray
    0,                                      // ClassReserved[0]
    0,                                      // ClassReserved[1]
    0,                                      // ClassReserved[2]
    0,                                      // ClassReserved[3]
    0,                                      // NumStreamPropArrayEntries
    0,                                      // StreamPropertiesArray
    0,                                      // NumStreamEventArrayEntries;
    0,                                      // StreamEventsArray;
    (GUID *) &PINNAME_VIDEO_ANALOGVIDEOIN,  // Category
    (GUID *) &PINNAME_VIDEO_ANALOGVIDEOIN,  // Name
    1,                                      // MediumsCount
    &CrossbarMediums[9],                    // Mediums
        FALSE,                                                                  // BridgeStream
    },

    // HW_STREAM_OBJECT ------------------------------------------------
    {
    sizeof (HW_STREAM_OBJECT),              // SizeOfThisPacket
    2,                                      // StreamNumber
    0,                                      // HwStreamExtension
    AnalogVideoReceiveDataPacket,           // HwReceiveDataPacket
    AnalogVideoReceiveCtrlPacket,           // HwReceiveControlPacket
    { NULL, 0 },                            // HW_CLOCK_OBJECT
    FALSE,                                  // Dma
    TRUE,                                   // Pio
    0,                                      // HwDeviceExtension
    0,                                      // StreamHeaderMediaSpecific
    0,                                      // StreamHeaderWorkspace
    FALSE,                                  // Allocator
    NULL,                                   // HwEventRoutine
    { 0, 0 },                               // Reserved[2]
    }
#endif//TOSHIBA
  }
};

#define DRIVER_STREAM_COUNT (SIZEOF_ARRAY (Streams))


//---------------------------------------------------------------------------
// Topology
//---------------------------------------------------------------------------

// Categories define what the device does.

static const GUID Categories[] = {
#ifdef  TOSHIBA
    STATIC_KSCATEGORY_VIDEO,
    STATIC_KSCATEGORY_CAPTURE,
#else //TOSHIBA
    STATIC_KSCATEGORY_VIDEO,
    STATIC_KSCATEGORY_CAPTURE,
    STATIC_KSCATEGORY_TVTUNER,
    STATIC_KSCATEGORY_CROSSBAR,
    STATIC_KSCATEGORY_TVAUDIO
#endif//TOSHIBA
};

#define NUMBER_OF_CATEGORIES  SIZEOF_ARRAY (Categories)


static KSTOPOLOGY Topology = {
    NUMBER_OF_CATEGORIES,               // CategoriesCount
    (GUID*) &Categories,                // Categories
    0,                                  // TopologyNodesCount
    NULL,                               // TopologyNodes
    0,                                  // TopologyConnectionsCount
    NULL,                               // TopologyConnections
    NULL,                               // TopologyNodesNames
    0,                                  // Reserved
};


//---------------------------------------------------------------------------
// The Main stream header
//---------------------------------------------------------------------------

static HW_STREAM_HEADER StreamHeader =
{
    DRIVER_STREAM_COUNT,                // NumberOfStreams
    sizeof (HW_STREAM_INFORMATION),     // Future proofing
    0,                                  // NumDevPropArrayEntries set at init time
    NULL,                               // DevicePropertiesArray  set at init time
    0,                                  // NumDevEventArrayEntries;
    NULL,                               // DeviceEventsArray;
    &Topology                           // Pointer to Device Topology
};

#ifdef    __cplusplus
}
#endif // __cplusplus

#endif // __CAPSTRM_H__

=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\drivers\wdm\capture\mini\tecra750\capprop.h ===
//==========================================================================;
//
//  THIS CODE AND INFORMATION IS PROVIDED "AS IS" WITHOUT WARRANTY OF ANY
//  KIND, EITHER EXPRESSED OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE
//  IMPLIED WARRANTIES OF MERCHANTABILITY AND/OR FITNESS FOR A PARTICULAR
//  PURPOSE.
//
//  Copyright (c) 1992 - 1996  Microsoft Corporation.  All Rights Reserved.
//
//==========================================================================;

#ifndef TOSHIBA
// ------------------------------------------------------------------------
// Property set for the Video Crossbar
// ------------------------------------------------------------------------

DEFINE_KSPROPERTY_TABLE(XBarProperties)
{
    DEFINE_KSPROPERTY_ITEM
    (
        KSPROPERTY_CROSSBAR_CAPS,
        TRUE,                                   // GetSupported or Handler
        sizeof(KSPROPERTY_CROSSBAR_CAPS_S),     // MinProperty
        sizeof(KSPROPERTY_CROSSBAR_CAPS_S),     // MinData
        FALSE,                                  // SetSupported or Handler
        NULL,                                   // Values
        0,                                      // RelationsCount
        NULL,                                   // Relations
        NULL,                                   // SupportHandler
        0                                       // SerializedSize
    ),
    DEFINE_KSPROPERTY_ITEM
    (
        KSPROPERTY_CROSSBAR_CAN_ROUTE,
        TRUE,                                   // GetSupported or Handler
        sizeof(KSPROPERTY_CROSSBAR_ROUTE_S),    // MinProperty
        sizeof(KSPROPERTY_CROSSBAR_ROUTE_S),    // MinData
        FALSE,                                  // SetSupported or Handler
        NULL,                                   // Values
        0,                                      // RelationsCount
        NULL,                                   // Relations
        NULL,                                   // SupportHandler
        0                                       // SerializedSize
    ),
    DEFINE_KSPROPERTY_ITEM
    (
        KSPROPERTY_CROSSBAR_ROUTE,
        TRUE,                                   // GetSupported or Handler
        sizeof(KSPROPERTY_CROSSBAR_ROUTE_S),    // MinProperty
        sizeof(KSPROPERTY_CROSSBAR_ROUTE_S),    // MinData
        TRUE,                                   // SetSupported or Handler
        NULL,                                   // Values
        0,                                      // RelationsCount
        NULL,                                   // Relations
        NULL,                                   // SupportHandler
        0                                       // SerializedSize
    ),
    DEFINE_KSPROPERTY_ITEM
    (
        KSPROPERTY_CROSSBAR_PININFO,
        TRUE,                                   // GetSupported or Handler
        sizeof(KSPROPERTY_CROSSBAR_PININFO_S),  // MinProperty
        sizeof(KSPROPERTY_CROSSBAR_PININFO_S),  // MinData
        FALSE,                                  // SetSupported or Handler
        NULL,                                   // Values
        0,                                      // RelationsCount
        NULL,                                   // Relations
        NULL,                                   // SupportHandler
        0                                       // SerializedSize
    ),

};

// ------------------------------------------------------------------------
// Property set for the TVTuner
// ------------------------------------------------------------------------

DEFINE_KSPROPERTY_TABLE(TVTunerProperties)
{
    DEFINE_KSPROPERTY_ITEM
    (
        KSPROPERTY_TUNER_CAPS,
        TRUE,                                   // GetSupported or Handler
        sizeof(KSPROPERTY_TUNER_CAPS_S),        // MinProperty
        sizeof(KSPROPERTY_TUNER_CAPS_S),        // MinData
        FALSE,                                  // SetSupported or Handler
        NULL,                                   // Values
        0,                                      // RelationsCount
        NULL,                                   // Relations
        NULL,                                   // SupportHandler
        0                                       // SerializedSize
    ),
    DEFINE_KSPROPERTY_ITEM
    (
        KSPROPERTY_TUNER_MODE,
        TRUE,                                   // GetSupported or Handler
        sizeof(KSPROPERTY_TUNER_MODE_S),        // MinProperty
        sizeof(KSPROPERTY_TUNER_MODE_S),        // MinData
        TRUE,                                   // SetSupported or Handler
        NULL,                                   // Values
        0,                                      // RelationsCount
        NULL,                                   // Relations
        NULL,                                   // SupportHandler
        0                                       // SerializedSize
    ),
    DEFINE_KSPROPERTY_ITEM
    (
        KSPROPERTY_TUNER_MODE_CAPS,
        TRUE,                                   // GetSupported or Handler
        sizeof(KSPROPERTY_TUNER_MODE_CAPS_S),   // MinProperty
        sizeof(KSPROPERTY_TUNER_MODE_CAPS_S),   // MinData
        FALSE,                                  // SetSupported or Handler
        NULL,                                   // Values
        0,                                      // RelationsCount
        NULL,                                   // Relations
        NULL,                                   // SupportHandler
        0                                       // SerializedSize
    ),
    DEFINE_KSPROPERTY_ITEM
    (
        KSPROPERTY_TUNER_STANDARD,
        TRUE,                                   // GetSupported or Handler
        sizeof(KSPROPERTY_TUNER_STANDARD_S),    // MinProperty
        sizeof(KSPROPERTY_TUNER_STANDARD_S),    // MinData
        FALSE,                                  // SetSupported or Handler
        NULL,                                   // Values
        0,                                      // RelationsCount
        NULL,                                   // Relations
        NULL,                                   // SupportHandler
        0                                       // SerializedSize
    ),
    DEFINE_KSPROPERTY_ITEM
    (
        KSPROPERTY_TUNER_FREQUENCY,
        FALSE,                                  // GetSupported or Handler
        sizeof(KSPROPERTY_TUNER_FREQUENCY_S),   // MinProperty
        sizeof(KSPROPERTY_TUNER_FREQUENCY_S),   // MinData
        TRUE,                                   // SetSupported or Handler
        NULL,                                   // Values
        0,                                      // RelationsCount
        NULL,                                   // Relations
        NULL,                                   // SupportHandler
        0                                       // SerializedSize
    ),
    DEFINE_KSPROPERTY_ITEM
    (
        KSPROPERTY_TUNER_INPUT,
        TRUE,                                   // GetSupported or Handler
        sizeof(KSPROPERTY_TUNER_INPUT_S),       // MinProperty
        sizeof(KSPROPERTY_TUNER_INPUT_S),       // MinData
        TRUE,                                   // SetSupported or Handler
        NULL,                                   // Values
        0,                                      // RelationsCount
        NULL,                                   // Relations
        NULL,                                   // SupportHandler
        0                                       // SerializedSize
    ),
    DEFINE_KSPROPERTY_ITEM
    (
        KSPROPERTY_TUNER_STATUS,
        TRUE,                                   // GetSupported or Handler
        sizeof(KSPROPERTY_TUNER_STATUS_S),      // MinProperty
        sizeof(KSPROPERTY_TUNER_STATUS_S),      // MinData
        FALSE,                                  // SetSupported or Handler
        NULL,                                   // Values
        0,                                      // RelationsCount
        NULL,                                   // Relations
        NULL,                                   // SupportHandler
        0                                       // SerializedSize
    )
};


// ------------------------------------------------------------------------
// Property set for the TVAudio
// ------------------------------------------------------------------------

DEFINE_KSPROPERTY_TABLE(TVAudioProperties)
{
    DEFINE_KSPROPERTY_ITEM
    (
        KSPROPERTY_TVAUDIO_CAPS,
        TRUE,                                   // GetSupported or Handler
        sizeof(KSPROPERTY_TVAUDIO_CAPS_S),      // MinProperty
        sizeof(KSPROPERTY_TVAUDIO_CAPS_S),      // MinData
        FALSE,                                  // SetSupported or Handler
        NULL,                                   // Values
        0,                                      // RelationsCount
        NULL,                                   // Relations
        NULL,                                   // SupportHandler
        0                                       // SerializedSize
    ),
    DEFINE_KSPROPERTY_ITEM
    (
        KSPROPERTY_TVAUDIO_MODE,
        TRUE,                                   // GetSupported or Handler
        sizeof(KSPROPERTY_TVAUDIO_S),           // MinProperty
        sizeof(KSPROPERTY_TVAUDIO_S),           // MinData
        TRUE,                                   // SetSupported or Handler
        NULL,                                   // Values
        0,                                      // RelationsCount
        NULL,                                   // Relations
        NULL,                                   // SupportHandler
        0                                       // SerializedSize
    ),
    DEFINE_KSPROPERTY_ITEM
    (
        KSPROPERTY_TVAUDIO_CURRENTLY_AVAILABLE_MODES,
        TRUE,                                   // GetSupported or Handler
        sizeof(KSPROPERTY_TVAUDIO_S),           // MinProperty
        sizeof(KSPROPERTY_TVAUDIO_S),           // MinData
        FALSE,                                   // SetSupported or Handler
        NULL,                                   // Values
        0,                                      // RelationsCount
        NULL,                                   // Relations
        NULL,                                   // SupportHandler
        0                                       // SerializedSize
    ),
};
#endif//TOSHIBA

// ------------------------------------------------------------------------
// Property set for VideoProcAmp
// ------------------------------------------------------------------------

//
// First define all of the ranges and stepping values
//

// ------------------------------------------------------------------------
#ifdef  TOSHIBA
static KSPROPERTY_STEPPING_LONG BrightnessRangeAndStep [] =
{
    {
        256 / 1,            // SteppingDelta (range / steps)
        0,                  // Reserved
        0,                  // Minimum in (IRE * 100) units
        255                 // Maximum in (IRE * 100) units
    }
};

static const ULONG BrightnessDefault = 128;
#else //TOSHIBA
static KSPROPERTY_STEPPING_LONG BrightnessRangeAndStep [] =
{
    {
        10000 / 10,         // SteppingDelta (range / steps)
        0,                  // Reserved
        0,                  // Minimum in (IRE * 100) units
        10000               // Maximum in (IRE * 100) units
    }
};

static const ULONG BrightnessDefault = 5000;
#endif//TOSHIBA

static KSPROPERTY_MEMBERSLIST BrightnessMembersList [] =
{
    {
        {
            KSPROPERTY_MEMBER_RANGES,
            sizeof (BrightnessRangeAndStep),
            SIZEOF_ARRAY (BrightnessRangeAndStep),
            0
        },
        (PVOID) BrightnessRangeAndStep,
     },
     {
        {
            KSPROPERTY_MEMBER_VALUES,
            sizeof (BrightnessDefault),
            sizeof (BrightnessDefault),
            KSPROPERTY_MEMBER_FLAG_DEFAULT
        },
        (PVOID) &BrightnessDefault,
    }
};

static KSPROPERTY_VALUES BrightnessValues =
{
    {
        STATICGUIDOF (KSPROPTYPESETID_General),
        VT_I4,
        0
    },
    SIZEOF_ARRAY (BrightnessMembersList),
    BrightnessMembersList
};

// ------------------------------------------------------------------------
#ifdef  TOSHIBA
static KSPROPERTY_STEPPING_LONG ContrastRangeAndStep [] =
{
    {
        256 / 1,            // SteppingDelta (range / steps)
        0,                  // Reserved
        0,                  // Minimum in (gain * 100) units
        255                 // Maximum in (gain * 100) units
    }
};

static const ULONG ContrastDefault = 128;
#else //TOSHIBA
static KSPROPERTY_STEPPING_LONG ContrastRangeAndStep [] =
{
    {
        10000 / 256,        // SteppingDelta (range / steps)
        0,                  // Reserved
        0,                  // Minimum in (gain * 100) units
        10000               // Maximum in (gain * 100) units
    }
};

static const ULONG ContrastDefault = 5000;
#endif//TOSHIBA

static KSPROPERTY_MEMBERSLIST ContrastMembersList [] =
{
    {
        {
            KSPROPERTY_MEMBER_RANGES,
            sizeof (ContrastRangeAndStep),
            SIZEOF_ARRAY (ContrastRangeAndStep),
            0
        },
        (PVOID) ContrastRangeAndStep
     },
     {
        {
            KSPROPERTY_MEMBER_VALUES,
            sizeof (ContrastDefault),
            sizeof (ContrastDefault),
            KSPROPERTY_MEMBER_FLAG_DEFAULT
        },
        (PVOID) &ContrastDefault,
    }
};

static KSPROPERTY_VALUES ContrastValues =
{
    {
        STATICGUIDOF (KSPROPTYPESETID_General),
        VT_I4,
        0
    },
    SIZEOF_ARRAY (ContrastMembersList),
    ContrastMembersList
};

#ifdef  TOSHIBA
// ------------------------------------------------------------------------
static KSPROPERTY_STEPPING_LONG HueRangeAndStep [] =
{
    {
        256 / 1,            // SteppingDelta (range / steps)
        0,                  // Reserved
        0,                  // Minimum in (IRE * 100) units
        255                 // Maximum in (IRE * 100) units
    }
};

static const ULONG HueDefault = 128;

static KSPROPERTY_MEMBERSLIST HueMembersList [] =
{
    {
        {
            KSPROPERTY_MEMBER_RANGES,
            sizeof (HueRangeAndStep),
            SIZEOF_ARRAY (HueRangeAndStep),
            0
        },
        (PVOID) HueRangeAndStep,
     },
     {
        {
            KSPROPERTY_MEMBER_VALUES,
            sizeof (HueDefault),
            sizeof (HueDefault),
            KSPROPERTY_MEMBER_FLAG_DEFAULT
        },
        (PVOID) &HueDefault,
    }
};

static KSPROPERTY_VALUES HueValues =
{
    {
        STATICGUIDOF (KSPROPTYPESETID_General),
        VT_I4,
        0
    },
    SIZEOF_ARRAY (HueMembersList),
    HueMembersList
};

// ------------------------------------------------------------------------
static KSPROPERTY_STEPPING_LONG SaturationRangeAndStep [] =
{
    {
        256 / 1,            // SteppingDelta (range / steps)
        0,                  // Reserved
        0,                  // Minimum in (gain * 100) units
        255                 // Maximum in (gain * 100) units
    }
};

static const ULONG SaturationDefault = 128;

static KSPROPERTY_MEMBERSLIST SaturationMembersList [] =
{
    {
        {
            KSPROPERTY_MEMBER_RANGES,
            sizeof (SaturationRangeAndStep),
            SIZEOF_ARRAY (SaturationRangeAndStep),
            0
        },
        (PVOID) SaturationRangeAndStep
     },
     {
        {
            KSPROPERTY_MEMBER_VALUES,
            sizeof (SaturationDefault),
            sizeof (SaturationDefault),
            KSPROPERTY_MEMBER_FLAG_DEFAULT
        },
        (PVOID) &SaturationDefault,
    }
};

static KSPROPERTY_VALUES SaturationValues =
{
    {
        STATICGUIDOF (KSPROPTYPESETID_General),
        VT_I4,
        0
    },
    SIZEOF_ARRAY (SaturationMembersList),
    SaturationMembersList
};
#endif//TOSHIBA

// ------------------------------------------------------------------------
static KSPROPERTY_STEPPING_LONG ColorEnableRangeAndStep [] =
{
    {
        1,                  // SteppingDelta (this is a BOOL)
        0,                  // Reserved
        0,                  // Minimum
        1                   // Maximum
    }
};

#ifdef  TOSHIBA
static const ULONG ColorEnableDefault = 0;
#else //TOSHIBA
static const ULONG ColorEnableDefault = 1;
#endif//TOSHIBA

static KSPROPERTY_MEMBERSLIST ColorEnableMembersList [] =
{
    {
        {
            KSPROPERTY_MEMBER_RANGES,
            sizeof (ColorEnableRangeAndStep),
            SIZEOF_ARRAY (ColorEnableRangeAndStep),
            0
        },
        (PVOID) ColorEnableRangeAndStep
     },
     {
        {
            KSPROPERTY_MEMBER_VALUES,
            sizeof (ColorEnableDefault),
            sizeof (ColorEnableDefault),
            KSPROPERTY_MEMBER_FLAG_DEFAULT
        },
        (PVOID) &ColorEnableDefault,
    }
};

static KSPROPERTY_VALUES ColorEnableValues =
{
    {
        STATICGUIDOF (KSPROPTYPESETID_General),
        VT_I4,
        0
    },
    SIZEOF_ARRAY (ColorEnableMembersList),
    ColorEnableMembersList
};

// ------------------------------------------------------------------------
DEFINE_KSPROPERTY_TABLE(VideoProcAmpProperties)
{
    DEFINE_KSPROPERTY_ITEM
    (
        KSPROPERTY_VIDEOPROCAMP_CONTRAST,
        TRUE,                                   // GetSupported or Handler
        sizeof(KSPROPERTY_VIDEOPROCAMP_S),      // MinProperty
        sizeof(KSPROPERTY_VIDEOPROCAMP_S),      // MinData
        TRUE,                                   // SetSupported or Handler
        &ContrastValues,                        // Values
        0,                                      // RelationsCount
        NULL,                                   // Relations
        NULL,                                   // SupportHandler
        sizeof(ULONG)                           // SerializedSize
    ),
    DEFINE_KSPROPERTY_ITEM
    (
        KSPROPERTY_VIDEOPROCAMP_BRIGHTNESS,
        TRUE,                                   // GetSupported or Handler
        sizeof(KSPROPERTY_VIDEOPROCAMP_S),      // MinProperty
        sizeof(KSPROPERTY_VIDEOPROCAMP_S),      // MinData
        TRUE,                                   // SetSupported or Handler
        &BrightnessValues,                      // Values
        0,                                      // RelationsCount
        NULL,                                   // Relations
        NULL,                                   // SupportHandler
        sizeof(ULONG)                           // SerializedSize
    ),
#ifdef  TOSHIBA
    DEFINE_KSPROPERTY_ITEM
    (
        KSPROPERTY_VIDEOPROCAMP_HUE,
        TRUE,                                   // GetSupported or Handler
        sizeof(KSPROPERTY_VIDEOPROCAMP_S),      // MinProperty
        sizeof(KSPROPERTY_VIDEOPROCAMP_S),      // MinData
        TRUE,                                   // SetSupported or Handler
        &HueValues,                             // Values
        0,                                      // RelationsCount
        NULL,                                   // Relations
        NULL,                                   // SupportHandler
        sizeof(ULONG)                           // SerializedSize
    ),
    DEFINE_KSPROPERTY_ITEM
    (
        KSPROPERTY_VIDEOPROCAMP_SATURATION,
        TRUE,                                   // GetSupported or Handler
        sizeof(KSPROPERTY_VIDEOPROCAMP_S),      // MinProperty
        sizeof(KSPROPERTY_VIDEOPROCAMP_S),      // MinData
        TRUE,                                   // SetSupported or Handler
        &SaturationValues,                      // Values
        0,                                      // RelationsCount
        NULL,                                   // Relations
        NULL,                                   // SupportHandler
        sizeof(ULONG)                           // SerializedSize
    ),
#endif//TOSHIBA
    DEFINE_KSPROPERTY_ITEM
    (
        KSPROPERTY_VIDEOPROCAMP_COLORENABLE,
        TRUE,                                   // GetSupported or Handler
        sizeof(KSPROPERTY_VIDEOPROCAMP_S),      // MinProperty
        sizeof(KSPROPERTY_VIDEOPROCAMP_S),      // MinData
        TRUE,                                   // SetSupported or Handler
        &ColorEnableValues,                     // Values
        0,                                      // RelationsCount
        NULL,                                   // Relations
        NULL,                                   // SupportHandler
        sizeof(ULONG)                           // SerializedSize
    ),
};

#ifndef TOSHIBA
// ------------------------------------------------------------------------
// Property set for CameraControl
// ------------------------------------------------------------------------

//
// First define all of the ranges and stepping values
//

// ------------------------------------------------------------------------
static KSPROPERTY_STEPPING_LONG ZoomRangeAndStep [] =
{
    {
        10000 / 10,         // SteppingDelta (range / steps)
        0,                  // Reserved
        0,                  // Minimum
        10000               // Maximum
    }
};

static const ULONG ZoomDefault = 5000;

static KSPROPERTY_MEMBERSLIST ZoomMembersList [] =
{
    {
        {
            KSPROPERTY_MEMBER_RANGES,
            sizeof (ZoomRangeAndStep),
            SIZEOF_ARRAY (ZoomRangeAndStep),
            0
        },
        (PVOID) ZoomRangeAndStep,
     },
     {
        {
            KSPROPERTY_MEMBER_VALUES,
            sizeof (ZoomDefault),
            sizeof (ZoomDefault),
            KSPROPERTY_MEMBER_FLAG_DEFAULT
        },
        (PVOID) &ZoomDefault,
    }
};

static KSPROPERTY_VALUES ZoomValues =
{
    {
        STATICGUIDOF (KSPROPTYPESETID_General),
        VT_I4,
        0
    },
    SIZEOF_ARRAY (ZoomMembersList),
    ZoomMembersList
};

// ------------------------------------------------------------------------
static KSPROPERTY_STEPPING_LONG FocusRangeAndStep [] =
{
    {
        10000 / 256,        // SteppingDelta (range / steps)
        0,                  // Reserved
        0,                  // Minimum
        10000               // Maximum
    }
};

static const ULONG FocusDefault = 5000;

static KSPROPERTY_MEMBERSLIST FocusMembersList [] =
{
    {
        {
            KSPROPERTY_MEMBER_RANGES,
            sizeof (FocusRangeAndStep),
            SIZEOF_ARRAY (FocusRangeAndStep),
            0
        },
        (PVOID) FocusRangeAndStep
     },
     {
        {
            KSPROPERTY_MEMBER_VALUES,
            sizeof (FocusDefault),
            sizeof (FocusDefault),
            KSPROPERTY_MEMBER_FLAG_DEFAULT
        },
        (PVOID) &FocusDefault,
    }
};

static KSPROPERTY_VALUES FocusValues =
{
    {
        STATICGUIDOF (KSPROPTYPESETID_General),
        VT_I4,
        0
    },
    SIZEOF_ARRAY (FocusMembersList),
    FocusMembersList
};

// ------------------------------------------------------------------------
DEFINE_KSPROPERTY_TABLE(CameraControlProperties)
{
    DEFINE_KSPROPERTY_ITEM
    (
        KSPROPERTY_CAMERACONTROL_ZOOM,
        TRUE,                                   // GetSupported or Handler
        sizeof(KSPROPERTY_CAMERACONTROL_S),     // MinProperty
        sizeof(KSPROPERTY_CAMERACONTROL_S),     // MinData
        TRUE,                                   // SetSupported or Handler
        &ZoomValues,                            // Values
        0,                                      // RelationsCount
        NULL,                                   // Relations
        NULL,                                   // SupportHandler
        sizeof(ULONG)                           // SerializedSize
    ),
    DEFINE_KSPROPERTY_ITEM
    (
        KSPROPERTY_CAMERACONTROL_FOCUS,
        TRUE,                                   // GetSupported or Handler
        sizeof(KSPROPERTY_CAMERACONTROL_S),     // MinProperty
        sizeof(KSPROPERTY_CAMERACONTROL_S),     // MinData
        TRUE,                                   // SetSupported or Handler
        &FocusValues,                           // Values
        0,                                      // RelationsCount
        NULL,                                   // Relations
        NULL,                                   // SupportHandler
        sizeof(ULONG)                           // SerializedSize
    ),
};

// ------------------------------------------------------------------------
// Property set for AnalogVideoDecoder
// ------------------------------------------------------------------------

DEFINE_KSPROPERTY_TABLE(AnalogVideoDecoder)
{
    DEFINE_KSPROPERTY_ITEM
    (
        KSPROPERTY_VIDEODECODER_CAPS,
        TRUE,                                   // GetSupported or Handler
        sizeof(KSPROPERTY_VIDEODECODER_CAPS_S), // MinProperty
        sizeof(KSPROPERTY_VIDEODECODER_CAPS_S), // MinData
        FALSE,                                  // SetSupported or Handler
        NULL,                                   // Values
        0,                                      // RelationsCount
        NULL,                                   // Relations
        NULL,                                   // SupportHandler
        0                                       // SerializedSize
    ),
    DEFINE_KSPROPERTY_ITEM
    (
        KSPROPERTY_VIDEODECODER_STANDARD,
        TRUE,                                   // GetSupported or Handler
        sizeof(KSPROPERTY_VIDEODECODER_S),      // MinProperty
        sizeof(KSPROPERTY_VIDEODECODER_S),      // MinData
        TRUE,                                   // SetSupported or Handler
        NULL,                                   // Values
        0,                                      // RelationsCount
        NULL,                                   // Relations
        NULL,                                   // SupportHandler
        0                                       // SerializedSize
    ),
    DEFINE_KSPROPERTY_ITEM
    (
        KSPROPERTY_VIDEODECODER_STATUS,
        TRUE,                                   // GetSupported or Handler
        sizeof(KSPROPERTY_VIDEODECODER_STATUS_S),// MinProperty
        sizeof(KSPROPERTY_VIDEODECODER_STATUS_S),// MinData
        FALSE,                                  // SetSupported or Handler
        NULL,                                   // Values
        0,                                      // RelationsCount
        NULL,                                   // Relations
        NULL,                                   // SupportHandler
        0                                       // SerializedSize
    ),
    DEFINE_KSPROPERTY_ITEM
    (
        KSPROPERTY_VIDEODECODER_OUTPUT_ENABLE,
        TRUE,                                   // GetSupported or Handler
        sizeof(KSPROPERTY_VIDEODECODER_S),      // MinProperty
        sizeof(KSPROPERTY_VIDEODECODER_S),      // MinData
        TRUE,                                   // SetSupported or Handler
        NULL,                                   // Values
        0,                                      // RelationsCount
        NULL,                                   // Relations
        NULL,                                   // SupportHandler
        0                                       // SerializedSize
    ),
    DEFINE_KSPROPERTY_ITEM
    (
        KSPROPERTY_VIDEODECODER_VCR_TIMING,
        TRUE,                                   // GetSupported or Handler
        sizeof(KSPROPERTY_VIDEODECODER_S),      // MinProperty
        sizeof(KSPROPERTY_VIDEODECODER_S),      // MinData
        TRUE,                                   // SetSupported or Handler
        NULL,                                   // Values
        0,                                      // RelationsCount
        NULL,                                   // Relations
        NULL,                                   // SupportHandler
        0                                       // SerializedSize
    ),
};
#endif//TOSHIBA

#ifndef TOSHIBA // '98-12-10 Deleted, for Bug-Report 253534
// ------------------------------------------------------------------------
// Property set for VideoControl
// ------------------------------------------------------------------------

DEFINE_KSPROPERTY_TABLE(VideoControlProperties)
{
    DEFINE_KSPROPERTY_ITEM
    (
        KSPROPERTY_VIDEOCONTROL_CAPS,
        TRUE,                                   // GetSupported or Handler
        sizeof(KSPROPERTY_VIDEOCONTROL_CAPS_S), // MinProperty
        sizeof(KSPROPERTY_VIDEOCONTROL_CAPS_S), // MinData
        FALSE,                                  // SetSupported or Handler
        NULL,                                   // Values
        0,                                      // RelationsCount
        NULL,                                   // Relations
        NULL,                                   // SupportHandler
        0                                       // SerializedSize
    ),
    DEFINE_KSPROPERTY_ITEM
    (
        KSPROPERTY_VIDEOCONTROL_ACTUAL_FRAME_RATE,
        TRUE,                                   // GetSupported or Handler
        sizeof(KSPROPERTY_VIDEOCONTROL_ACTUAL_FRAME_RATE_S),      // MinProperty
        sizeof(KSPROPERTY_VIDEOCONTROL_ACTUAL_FRAME_RATE_S),      // MinData
        FALSE,                                  // SetSupported or Handler
        NULL,                                   // Values
        0,                                      // RelationsCount
        NULL,                                   // Relations
        NULL,                                   // SupportHandler
        0                                       // SerializedSize
    ),
    DEFINE_KSPROPERTY_ITEM
    (
        KSPROPERTY_VIDEOCONTROL_FRAME_RATES,
        TRUE,                                   // GetSupported or Handler
        sizeof(KSPROPERTY),                     // MinProperty
        sizeof(KSMULTIPLE_ITEM),                // MinData
        FALSE,                                  // SetSupported or Handler
        NULL,                                   // Values
        0,                                      // RelationsCount
        NULL,                                   // Relations
        NULL,                                   // SupportHandler
        0                                       // SerializedSize
    ),
    DEFINE_KSPROPERTY_ITEM
    (
        KSPROPERTY_VIDEOCONTROL_MODE,
        TRUE,                                   // GetSupported or Handler
        sizeof(KSPROPERTY_VIDEOCONTROL_MODE_S), // MinProperty
        sizeof(KSPROPERTY_VIDEOCONTROL_MODE_S), // MinData
        TRUE,                                   // SetSupported or Handler
        NULL,                                   // Values
        0,                                      // RelationsCount
        NULL,                                   // Relations
        NULL,                                   // SupportHandler
        0                                       // SerializedSize
    ),
};

// ------------------------------------------------------------------------
// Property set for VideoCompression
// ------------------------------------------------------------------------

DEFINE_KSPROPERTY_TABLE(VideoStreamCompressionProperties)
{
    DEFINE_KSPROPERTY_ITEM
    (
        KSPROPERTY_VIDEOCOMPRESSION_GETINFO,
        TRUE,                                   // GetSupported or Handler
        sizeof(KSPROPERTY_VIDEOCOMPRESSION_GETINFO_S),// MinProperty
        sizeof(KSPROPERTY_VIDEOCOMPRESSION_GETINFO_S),// MinData
        FALSE,                                  // SetSupported or Handler
        NULL,                                   // Values
        0,                                      // RelationsCount
        NULL,                                   // Relations
        NULL,                                   // SupportHandler
        0                                       // SerializedSize
    ),
    DEFINE_KSPROPERTY_ITEM
    (
        KSPROPERTY_VIDEOCOMPRESSION_KEYFRAME_RATE,
        TRUE,                                   // GetSupported or Handler
        sizeof(KSPROPERTY_VIDEOCOMPRESSION_S),  // MinProperty
        sizeof(KSPROPERTY_VIDEOCOMPRESSION_S),  // MinData
        TRUE,                                   // SetSupported or Handler
        NULL,                                   // Values
        0,                                      // RelationsCount
        NULL,                                   // Relations
        NULL,                                   // SupportHandler
        0                                       // SerializedSize
    ),
    DEFINE_KSPROPERTY_ITEM
    (
        KSPROPERTY_VIDEOCOMPRESSION_PFRAMES_PER_KEYFRAME,
        TRUE,                                   // GetSupported or Handler
        sizeof(KSPROPERTY_VIDEOCOMPRESSION_S),  // MinProperty
        sizeof(KSPROPERTY_VIDEOCOMPRESSION_S),  // MinData
        TRUE,                                   // SetSupported or Handler
        NULL,                                   // Values
        0,                                      // RelationsCount
        NULL,                                   // Relations
        NULL,                                   // SupportHandler
        0                                       // SerializedSize
    ),
    DEFINE_KSPROPERTY_ITEM
    (
        KSPROPERTY_VIDEOCOMPRESSION_QUALITY,
        TRUE,                                   // GetSupported or Handler
        sizeof(KSPROPERTY_VIDEOCOMPRESSION_S),  // MinProperty
        sizeof(KSPROPERTY_VIDEOCOMPRESSION_S),  // MinData
        TRUE,                                   // SetSupported or Handler
        NULL,                                   // Values
        0,                                      // RelationsCount
        NULL,                                   // Relations
        NULL,                                   // SupportHandler
        0                                       // SerializedSize
    ),
};
#endif//TOSHIBA

// ------------------------------------------------------------------------
// Array of all of the property sets supported by the adapter
// ------------------------------------------------------------------------

DEFINE_KSPROPERTY_SET_TABLE(AdapterPropertyTable)
{
#ifdef  TOSHIBA
    DEFINE_KSPROPERTY_SET
    (
        &PROPSETID_VIDCAP_VIDEOPROCAMP,
        SIZEOF_ARRAY(VideoProcAmpProperties),
        VideoProcAmpProperties,
        0,
        NULL,
    ),
#else //TOSHIBA // '98-12-10 Moved, for Bug-Report 253534
    DEFINE_KSPROPERTY_SET
    (
        &PROPSETID_VIDCAP_VIDEOCONTROL,
        SIZEOF_ARRAY(VideoControlProperties),
        VideoControlProperties,
        0,
        NULL,
    ),
    DEFINE_KSPROPERTY_SET
    (
        &PROPSETID_VIDCAP_VIDEOCOMPRESSION,             // Set
        SIZEOF_ARRAY(VideoStreamCompressionProperties), // PropertiesCount
        VideoStreamCompressionProperties,               // PropertyItem
        0,                                              // FastIoCount
        NULL                                            // FastIoTable
    ),
//#else //TOSHIBA  '98-12-10 Moved, for Bug-Report 253534
    DEFINE_KSPROPERTY_SET
    (
        &PROPSETID_VIDCAP_CROSSBAR,             // Set
        SIZEOF_ARRAY(XBarProperties),           // PropertiesCount
        XBarProperties,                         // PropertyItem
        0,                                      // FastIoCount
        NULL                                    // FastIoTable
    ),
    DEFINE_KSPROPERTY_SET
    (
        &PROPSETID_TUNER,
        SIZEOF_ARRAY(TVTunerProperties),
        TVTunerProperties,
        0,
        NULL,
    ),
    DEFINE_KSPROPERTY_SET
    (
        &PROPSETID_VIDCAP_TVAUDIO,
        SIZEOF_ARRAY(TVAudioProperties),
        TVAudioProperties,
        0,
        NULL,
    ),
    DEFINE_KSPROPERTY_SET
    (
        &PROPSETID_VIDCAP_VIDEOPROCAMP,
        SIZEOF_ARRAY(VideoProcAmpProperties),
        VideoProcAmpProperties,
        0,
        NULL,
    ),
    DEFINE_KSPROPERTY_SET
    (
        &PROPSETID_VIDCAP_CAMERACONTROL,
        SIZEOF_ARRAY(CameraControlProperties),
        CameraControlProperties,
        0,
        NULL,
    ),
    DEFINE_KSPROPERTY_SET
    (
        &PROPSETID_VIDCAP_VIDEOCONTROL,
        SIZEOF_ARRAY(VideoControlProperties),
        VideoControlProperties,
        0,
        NULL,
    ),
    DEFINE_KSPROPERTY_SET
    (
        &PROPSETID_VIDCAP_VIDEODECODER,
        SIZEOF_ARRAY(AnalogVideoDecoder),
        AnalogVideoDecoder,
        0,
        NULL,
    ),
    DEFINE_KSPROPERTY_SET
    (
        &PROPSETID_VIDCAP_VIDEOCOMPRESSION,             // Set
        SIZEOF_ARRAY(VideoStreamCompressionProperties), // PropertiesCount
        VideoStreamCompressionProperties,               // PropertyItem
        0,                                              // FastIoCount
        NULL                                            // FastIoTable
    ),
#endif//TOSHIBA

};

#define NUMBER_OF_ADAPTER_PROPERTY_SETS (SIZEOF_ARRAY (AdapterPropertyTable))

=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\drivers\wdm\capture\mini\tecra750\capvideo.c ===
//==========================================================================;
//
//  THIS CODE AND INFORMATION IS PROVIDED "AS IS" WITHOUT WARRANTY OF ANY
//  KIND, EITHER EXPRESSED OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE
//  IMPLIED WARRANTIES OF MERCHANTABILITY AND/OR FITNESS FOR A PARTICULAR
//  PURPOSE.
//
//  Copyright (c) 1992 - 1996  Microsoft Corporation.  All Rights Reserved.
//
//==========================================================================;

#include "strmini.h"
#include "ksmedia.h"
#include "capmain.h"
#include "capdebug.h"
#include "ntstatus.h"
#ifdef  TOSHIBA
#include "bert.h"

extern  ULONG   CurrentOSType;
#ifdef  _FPS_COUNT_
ULONG   InterruptCounter = 0;
ULONG   FrameCounter = 0;
#endif//_FPS_COUNT_
#endif//TOSHIBA

//==========================================================================;
// General queue management routines
//==========================================================================;

/*
** AddToListIfBusy ()
**
**   Grabs a spinlock, checks the busy flag, and if set adds an SRB to a queue
**
** Arguments:
**
**   pSrb - Stream request block
**
**   SpinLock - The spinlock to use when checking the flag
**
**   BusyFlag - The flag to check
**
**   ListHead - The list onto which the Srb will be added if the busy flag is set
**
** Returns:
**
**   The state of the busy flag on entry.  This will be TRUE if we're already
**   processing an SRB, and FALSE if no SRB is already in progress.
**
** Side Effects:  none
*/

BOOL
STREAMAPI
AddToListIfBusy (
    IN PHW_STREAM_REQUEST_BLOCK pSrb,
    IN KSPIN_LOCK              *SpinLock,
    IN OUT BOOL                *BusyFlag,
    IN LIST_ENTRY              *ListHead
    )
{
    KIRQL                       Irql;
    PSRB_EXTENSION              pSrbExt = (PSRB_EXTENSION)pSrb->SRBExtension;

    KeAcquireSpinLock (SpinLock, &Irql);

    // If we're already processing another SRB, add this current request
    // to the queue and return TRUE

    if (*BusyFlag == TRUE) {
        // Save the SRB pointer away in the SRB Extension
        pSrbExt->pSrb = pSrb;
        InsertTailList(ListHead, &pSrbExt->ListEntry);
        KeReleaseSpinLock(SpinLock, Irql);
        return TRUE;
    }

    // Otherwise, set the busy flag, release the spinlock, and return FALSE

    *BusyFlag = TRUE;
    KeReleaseSpinLock(SpinLock, Irql);

    return FALSE;
}

/*
** RemoveFromListIfAvailable ()
**
**   Grabs a spinlock, checks for an available SRB, and removes it from the list
**
** Arguments:
**
**   &pSrb - where to return the Stream request block if available
**
**   SpinLock - The spinlock to use
**
**   BusyFlag - The flag to clear if the list is empty
**
**   ListHead - The list from which an SRB will be removed if available
**
** Returns:
**
**   TRUE if an SRB was removed from the list
**   FALSE if the list is empty
**
** Side Effects:  none
*/

BOOL
STREAMAPI
RemoveFromListIfAvailable (
    IN OUT PHW_STREAM_REQUEST_BLOCK *pSrb,
    IN KSPIN_LOCK                   *SpinLock,
    IN OUT BOOL                     *BusyFlag,
    IN LIST_ENTRY                   *ListHead
    )
{
    KIRQL                       Irql;

    KeAcquireSpinLock (SpinLock, &Irql);

    //
    // If the queue is now empty, clear the busy flag, and return
    //
    if (IsListEmpty(ListHead)) {
        *BusyFlag = FALSE;
        KeReleaseSpinLock(SpinLock, Irql);
        return FALSE;
    }
    //
    // otherwise extract the SRB
    //
    else {
        PUCHAR          ptr;
        PSRB_EXTENSION  pSrbExt;

        ptr = (PUCHAR)RemoveHeadList(ListHead);
        *BusyFlag = TRUE;
        KeReleaseSpinLock(SpinLock, Irql);
        // Get the SRB out of the SRB extension and return it
        pSrbExt = (PSRB_EXTENSION) (((PUCHAR) ptr) -
                     FIELDOFFSET(SRB_EXTENSION, ListEntry));
        *pSrb = pSrbExt->pSrb;
    }
    return TRUE;
}

//==========================================================================;
// Routines for managing the SRB queue on a per stream basis
//==========================================================================;

/*
** VideoQueueAddSRB ()
**
**   Adds a stream data SRB to a stream queue.  The queue is maintained in a
**   first in, first out order.
**
** Arguments:
**
**   pSrb - Stream request block for the Video stream
**
** Returns: nothing
**
** Side Effects:  none
*/

VOID
STREAMAPI
VideoQueueAddSRB (
    IN PHW_STREAM_REQUEST_BLOCK pSrb
    )
{
    PHW_DEVICE_EXTENSION    pHwDevExt = ((PHW_DEVICE_EXTENSION)pSrb->HwDeviceExtension);
    PSTREAMEX               pStrmEx = (PSTREAMEX)pSrb->StreamObject->HwStreamExtension;
    int                     StreamNumber = pSrb->StreamObject->StreamNumber;
    KIRQL                   oldIrql;

    KeAcquireSpinLock (&pHwDevExt->StreamSRBSpinLock[StreamNumber], &oldIrql);

    // Save the SRB pointer in the IRP so we can use the IRPs
    // ListEntry to maintain a doubly linked list of pending
    // requests

    pSrb->Irp->Tail.Overlay.DriverContext[0] = pSrb;

    InsertTailList (
                &pHwDevExt->StreamSRBList[StreamNumber],
                &pSrb->Irp->Tail.Overlay.ListEntry);

    // Increment the count of outstanding SRBs in this queue
    pHwDevExt->StreamSRBListSize[StreamNumber]++;

    KeReleaseSpinLock (&pHwDevExt->StreamSRBSpinLock[StreamNumber], oldIrql);

}

/*
** VideoQueueRemoveSRB ()
**
**   Removes a stream data SRB from a stream queue
**
** Arguments:
**
**   pHwDevExt - Device Extension
**
**   StreamNumber - Index of the stream
**
** Returns: SRB or NULL
**
** Side Effects:  none
*/

PHW_STREAM_REQUEST_BLOCK
STREAMAPI
VideoQueueRemoveSRB (
    PHW_DEVICE_EXTENSION pHwDevExt,
    int StreamNumber
    )
{
    PUCHAR ptr;
    PIRP pIrp;
    PHW_STREAM_REQUEST_BLOCK pSrb = NULL;
    KIRQL oldIrql;

    KeAcquireSpinLock (&pHwDevExt->StreamSRBSpinLock[StreamNumber], &oldIrql);

    //
    // Get the SRB out of the IRP out of the pending list
    //
    if (!IsListEmpty (&pHwDevExt->StreamSRBList[StreamNumber])) {

        ptr = (PUCHAR) RemoveHeadList(
                         &pHwDevExt->StreamSRBList[StreamNumber]);

        pIrp = (PIRP) (((PUCHAR) ptr) -
                     FIELDOFFSET(IRP, Tail.Overlay.ListEntry));

        pSrb = (PHW_STREAM_REQUEST_BLOCK) pIrp->Tail.Overlay.DriverContext[0];

        // Decrement the count of SRBs in this queue
        pHwDevExt->StreamSRBListSize[StreamNumber]--;

    }

    KeReleaseSpinLock (&pHwDevExt->StreamSRBSpinLock[StreamNumber], oldIrql);

    return pSrb;
}

/*
** VideoQueueCancelAllSRBs()
**
**    In case of a client crash, this empties the stream queue when the stream closes
**
** Arguments:
**
**    pStrmEx - pointer to the stream extension
**
** Returns:
**
** Side Effects:  none
*/

VOID
STREAMAPI
VideoQueueCancelAllSRBs (
    PSTREAMEX pStrmEx
    )
{
    PHW_DEVICE_EXTENSION        pHwDevExt = (PHW_DEVICE_EXTENSION)pStrmEx->pHwDevExt;
    int                         StreamNumber = pStrmEx->pStreamObject->StreamNumber;
    PUCHAR                      ptr;
    PIRP                        pIrp;
    PHW_STREAM_REQUEST_BLOCK    pSrb;
    KIRQL                       oldIrql;

    if (pStrmEx->KSState != KSSTATE_STOP) {

        KdPrint(("TsbVcap: ERROR Cleanup without being in the stopped state\n"));
        // May need to force the device to a stopped state here
        // may need to disable interrupts here !
    }

    //
    // The stream class will cancel all outstanding IRPs for us
    // (but only if we've set TurnOffSynchronization = FALSE)
    //

    KeAcquireSpinLock (&pHwDevExt->StreamSRBSpinLock[StreamNumber], &oldIrql);

    //
    // Get the SRB out of the IRP out of the pending list
    //
    while (!IsListEmpty (&pHwDevExt->StreamSRBList[StreamNumber])) {

        ptr = (PUCHAR) RemoveHeadList(
                         &pHwDevExt->StreamSRBList[StreamNumber]);

        pIrp = (PIRP) (((PUCHAR) ptr) -
                     FIELDOFFSET(IRP, Tail.Overlay.ListEntry));

        pSrb = (PHW_STREAM_REQUEST_BLOCK) pIrp->Tail.Overlay.DriverContext[0];

        // Decrement the count of SRBs in this queue
        pHwDevExt->StreamSRBListSize[StreamNumber]--;

        //
        // Make the length zero, and status cancelled
        //

        pSrb->CommandData.DataBufferArray->DataUsed = 0;
        pSrb->Status = STATUS_CANCELLED;

        KdPrint(("TsbVcap: VideoQueueCancelALLSRBs FOUND Srb=%x\n", pSrb));

        CompleteStreamSRB (pSrb);

    }

    KeReleaseSpinLock (&pHwDevExt->StreamSRBSpinLock[StreamNumber], oldIrql);

    KdPrint(("TsbVcap: VideoQueueCancelAll\n"));

}

/*
** VideoQueueCancelOneSRB()
**
**    Called when cancelling a particular SRB
**
** Arguments:
**
**    pStrmEx - pointer to the stream extension
**
**    pSRBToCancel - pointer to the SRB
**
** Returns:
**
**    TRUE if the SRB was found in this queue
**
** Side Effects:  none
*/

BOOL
STREAMAPI
VideoQueueCancelOneSRB (
    PSTREAMEX pStrmEx,
    PHW_STREAM_REQUEST_BLOCK pSrbToCancel
    )
{
    PHW_DEVICE_EXTENSION        pHwDevExt = (PHW_DEVICE_EXTENSION)pStrmEx->pHwDevExt;
    int                         StreamNumber = pStrmEx->pStreamObject->StreamNumber;
    KIRQL                       oldIrql;
    BOOL                        Found = FALSE;
    PIRP                        pIrp;
    PHW_STREAM_REQUEST_BLOCK    pSrb;
    PLIST_ENTRY                 Entry;

    KeAcquireSpinLock (&pHwDevExt->StreamSRBSpinLock[StreamNumber], &oldIrql);

    Entry = pHwDevExt->StreamSRBList[StreamNumber].Flink;

    //
    // Loop through the linked list from the beginning to end,
    // trying to find the SRB to cancel
    //

    while (Entry != &pHwDevExt->StreamSRBList[StreamNumber]) {

        pIrp = (PIRP) (((PUCHAR) Entry) -
                     FIELDOFFSET(IRP, Tail.Overlay.ListEntry));

        pSrb = (PHW_STREAM_REQUEST_BLOCK) pIrp->Tail.Overlay.DriverContext[0];

        if (pSrb == pSrbToCancel) {
            RemoveEntryList(Entry);
            Found = TRUE;
            break;
        }

        Entry = Entry->Flink;
    }

    KeReleaseSpinLock (&pHwDevExt->StreamSRBSpinLock[StreamNumber], oldIrql);

    if (Found) {

        pHwDevExt->StreamSRBListSize[StreamNumber]--;

        //
        // Make the length zero, and status cancelled
        //

        pSrbToCancel->CommandData.DataBufferArray->DataUsed = 0;
        pSrbToCancel->Status = STATUS_CANCELLED;

        CompleteStreamSRB (pSrbToCancel);

        KdPrint(("TsbVcap: VideoQueueCancelOneSRB FOUND Srb=%x\n", pSrb));

    }

    KdPrint(("TsbVcap: VideoQueueCancelOneSRB\n"));

    return Found;
}

/*
** VideoSetFormat()
**
**   Sets the format for a video stream.  This happens both when the
**   stream is first opened, and also when dynamically switching formats
**   on the preview pin.
**
**   It is assumed that the format has been verified for correctness before
**   this call is made.
**
** Arguments:
**
**   pSrb - Stream request block for the Video stream
**
** Returns:
**
**   TRUE if the format could be set, else FALSE
**
** Side Effects:  none
*/

BOOL
STREAMAPI
VideoSetFormat(
    IN PHW_STREAM_REQUEST_BLOCK pSrb
    )
{
    PSTREAMEX               pStrmEx = (PSTREAMEX)pSrb->StreamObject->HwStreamExtension;
    PHW_DEVICE_EXTENSION    pHwDevExt = ((PHW_DEVICE_EXTENSION)pSrb->HwDeviceExtension);
    int                     StreamNumber = pSrb->StreamObject->StreamNumber;
    UINT                    nSize;
    PKSDATAFORMAT           pKSDataFormat = pSrb->CommandData.OpenFormat;
#ifdef  TOSHIBA
    ULONG                   ImageSize;
    ULONG                   ImageSizeY;
    ULONG                   ImageSizeU;
    ULONG                   ImageSizeV;
    ULONG                   ulFrameRate;
    DWORD                   dwAddr;
    UINT                    biWidth;
    UINT                    biHeight;
    int                     Counter;
    PSTREAMEX               pStrmExTmp;
#endif//TOSHIBA

    // -------------------------------------------------------------------
    // Specifier FORMAT_VideoInfo for VIDEOINFOHEADER
    // -------------------------------------------------------------------

    if (IsEqualGUID (&pKSDataFormat->Specifier,
                &KSDATAFORMAT_SPECIFIER_VIDEOINFO)) {

        PKS_DATAFORMAT_VIDEOINFOHEADER  pVideoInfoHeader =
                    (PKS_DATAFORMAT_VIDEOINFOHEADER) pSrb->CommandData.OpenFormat;
        PKS_VIDEOINFOHEADER     pVideoInfoHdrRequested =
                    &pVideoInfoHeader->VideoInfoHeader;

        nSize = KS_SIZE_VIDEOHEADER (pVideoInfoHdrRequested);

        KdPrint(("TsbVcap: New Format\n"));
        KdPrint(("TsbVcap: pVideoInfoHdrRequested=%x\n", pVideoInfoHdrRequested));
        KdPrint(("TsbVcap: KS_VIDEOINFOHEADER size=%d\n", nSize));
        KdPrint(("TsbVcap: Width=%d  Height=%d  BitCount=%d\n",
                    pVideoInfoHdrRequested->bmiHeader.biWidth,
                    pVideoInfoHdrRequested->bmiHeader.biHeight,
                    pVideoInfoHdrRequested->bmiHeader.biBitCount));
        KdPrint(("TsbVcap: biSizeImage=%d\n",
                    pVideoInfoHdrRequested->bmiHeader.biSizeImage));

#ifdef  TOSHIBA // '98-12-10 Added, for Bug-Report 253563
        if ( (pVideoInfoHdrRequested->bmiHeader.biWidth  & 0x03) ||
             (pVideoInfoHdrRequested->bmiHeader.biHeight & 0x03) ) {
            pSrb->Status = STATUS_INVALID_PARAMETER;
            return FALSE;
        }
#endif//TOSHIBA

#ifdef  TOSHIBA
        for (Counter = 0; Counter < MAX_TSBVCAP_STREAMS; Counter++) {
            if ( pStrmExTmp = (PSTREAMEX)pHwDevExt->pStrmEx[Counter] ) {
                // Check other opened stream format
                if ( pStrmExTmp->pVideoInfoHeader ) {
                    if ( (pStrmExTmp->pVideoInfoHeader->bmiHeader.biWidth !=
                          pVideoInfoHdrRequested->bmiHeader.biWidth) ||
                         (pStrmExTmp->pVideoInfoHeader->bmiHeader.biHeight !=
                          pVideoInfoHdrRequested->bmiHeader.biHeight) ||
                         (pStrmExTmp->pVideoInfoHeader->bmiHeader.biBitCount !=
                          pVideoInfoHdrRequested->bmiHeader.biBitCount) ) {
                        pSrb->Status = STATUS_INVALID_PARAMETER;
                        return FALSE;
                    }
                }
            }
        }
#endif//TOSHIBA

        //
        // If a previous format was in use, release the memory
        //
        if (pStrmEx->pVideoInfoHeader) {
            ExFreePool(pStrmEx->pVideoInfoHeader);
            pStrmEx->pVideoInfoHeader = NULL;
        }

        // Since the VIDEOINFOHEADER is of potentially variable size
        // allocate memory for it

        pStrmEx->pVideoInfoHeader = ExAllocatePool(NonPagedPool, nSize);

        if (pStrmEx->pVideoInfoHeader == NULL) {
            KdPrint(("TsbVcap: ExAllocatePool failed\n"));
            pSrb->Status = STATUS_INSUFFICIENT_RESOURCES;
            return FALSE;
        }

        // Copy the VIDEOINFOHEADER requested to our storage
        RtlCopyMemory(
                pStrmEx->pVideoInfoHeader,
                pVideoInfoHdrRequested,
                nSize);

#ifdef  TOSHIBA
        if (pHwDevExt->NeedHWInit) HWInit(pHwDevExt);
        biWidth = pVideoInfoHdrRequested->bmiHeader.biWidth,
        biHeight = pVideoInfoHdrRequested->bmiHeader.biHeight,
        pHwDevExt->ulWidth = biWidth;
        pHwDevExt->ulHeight = biHeight;
        ImageSize = biWidth * biHeight;
        switch (pVideoInfoHdrRequested->bmiHeader.biCompression)
        {
            case FOURCC_YUV12:  // I420
                pHwDevExt->Format = FmtYUV12;
                pHwDevExt->YoffsetEven = 0;
                pHwDevExt->UoffsetEven = 0;
                pHwDevExt->VoffsetEven = 0;
                pHwDevExt->YoffsetOdd = 0;
                pHwDevExt->UoffsetOdd = 0;
                pHwDevExt->VoffsetOdd = 0;
                pHwDevExt->Ystride = 0;
                pHwDevExt->Ustride = 0;
                pHwDevExt->Vstride = 0;
                if ( CurrentOSType ) {  // NT5.0
                    ImageSizeY = ImageSize;
                    ImageSizeU = ImageSize / 4;
                    ImageSizeV = ImageSize / 4;
                } else {  // Win98
                    pHwDevExt->pCaptureBufferU = (PUCHAR)pHwDevExt->pCaptureBufferY + ImageSize;
                    pHwDevExt->pCaptureBufferV = (PUCHAR)pHwDevExt->pCaptureBufferU + ImageSize/4;
                    pHwDevExt->pPhysCaptureBufferU.LowPart = pHwDevExt->pPhysCaptureBufferY.LowPart + ImageSize;
                    pHwDevExt->pPhysCaptureBufferV.LowPart = pHwDevExt->pPhysCaptureBufferU.LowPart + ImageSize/4;
                }
                ImageSize = ImageSize * 12 / 8;
                break;
            case FOURCC_YVU9:   // YVU9
                pHwDevExt->Format = FmtYUV9;
                pHwDevExt->YoffsetEven = 0;
                pHwDevExt->UoffsetEven = 0;
                pHwDevExt->VoffsetEven = 0;
                pHwDevExt->YoffsetOdd = 0;
                pHwDevExt->UoffsetOdd = 0;
                pHwDevExt->VoffsetOdd = 0;
                pHwDevExt->Ystride = 0;
                pHwDevExt->Ustride = 0;
                pHwDevExt->Vstride = 0;
                if ( CurrentOSType ) {  // NT5.0
                    ImageSizeY = ImageSize;
                    ImageSizeU = ImageSize / 16;
                    ImageSizeV = ImageSize / 16;
                } else {  // Win98
                    pHwDevExt->pCaptureBufferV = (PUCHAR)pHwDevExt->pCaptureBufferY + ImageSize;
                    pHwDevExt->pCaptureBufferU = (PUCHAR)pHwDevExt->pCaptureBufferV + ImageSize/16;
                    pHwDevExt->pPhysCaptureBufferV.LowPart = pHwDevExt->pPhysCaptureBufferY.LowPart + ImageSize;
                    pHwDevExt->pPhysCaptureBufferU.LowPart = pHwDevExt->pPhysCaptureBufferV.LowPart + ImageSize/16;
                }
                ImageSize = ImageSize * 9 / 8;
                break;
            default:
                pSrb->Status = STATUS_INVALID_PARAMETER;
                return FALSE;
        }

        if (ImageSize > MAX_CAPTURE_BUFFER_SIZE) {
            if (pStrmEx->pVideoInfoHeader) {
                ExFreePool(pStrmEx->pVideoInfoHeader);
                pStrmEx->pVideoInfoHeader = NULL;
            }
            pSrb->Status = STATUS_INVALID_PARAMETER;
            return FALSE;
        }

        ulFrameRate = pHwDevExt->uiFramePerSecond;
        if (pHwDevExt->BufferSize != ImageSize) {
            if ( CurrentOSType ) {  // NT5.0
                ULONG            ulSize;
                PVOID            VirtualAddress;
                PHYSICAL_ADDRESS LimitAddress;
                PHYSICAL_ADDRESS PhysicalAddress;

                pHwDevExt->IsRPSReady = FALSE;

                if ( pHwDevExt->pCaptureBufferY )
                {
                    // free frame buffer
                    MmFreeContiguousMemory(pHwDevExt->pCaptureBufferY);
                    pHwDevExt->pCaptureBufferY = NULL;
                }
                if ( pHwDevExt->pCaptureBufferU )
                {
                    // free frame buffer
                    MmFreeContiguousMemory(pHwDevExt->pCaptureBufferU);
                    pHwDevExt->pCaptureBufferU = NULL;
                }
                if ( pHwDevExt->pCaptureBufferV )
                {
                    // free frame buffer
                    MmFreeContiguousMemory(pHwDevExt->pCaptureBufferV);
                    pHwDevExt->pCaptureBufferV = NULL;
                }

                // Allocate frame buffer

                LimitAddress.LowPart = 0xFFFFFFFF;
                LimitAddress.HighPart = 0;
                pHwDevExt->BufferSize = ImageSize;

                VirtualAddress = MmAllocateContiguousMemory(ImageSizeY, LimitAddress);
                if (VirtualAddress == 0)
                {
                    pHwDevExt->pPhysCaptureBufferY.LowPart = 0;
                    pHwDevExt->pPhysCaptureBufferY.HighPart = 0;
                    pHwDevExt->pPhysCaptureBufferU.LowPart = 0;
                    pHwDevExt->pPhysCaptureBufferU.HighPart = 0;
                    pHwDevExt->pPhysCaptureBufferV.LowPart = 0;
                    pHwDevExt->pPhysCaptureBufferV.HighPart = 0;
                    pHwDevExt->BufferSize = 0;
                    pSrb->Status = STATUS_INVALID_PARAMETER;
                    return FALSE;
                }
                RtlZeroMemory(VirtualAddress, ImageSizeY);
                pHwDevExt->pCaptureBufferY = VirtualAddress;
                PhysicalAddress = MmGetPhysicalAddress(pHwDevExt->pCaptureBufferY);
                pHwDevExt->pPhysCaptureBufferY = PhysicalAddress;

                VirtualAddress = MmAllocateContiguousMemory(ImageSizeU, LimitAddress);
                if (VirtualAddress == 0)
                {
                    MmFreeContiguousMemory(pHwDevExt->pCaptureBufferY);
                    pHwDevExt->pCaptureBufferY = NULL;
                    pHwDevExt->pPhysCaptureBufferY.LowPart = 0;
                    pHwDevExt->pPhysCaptureBufferY.HighPart = 0;
                    pHwDevExt->pPhysCaptureBufferU.LowPart = 0;
                    pHwDevExt->pPhysCaptureBufferU.HighPart = 0;
                    pHwDevExt->pPhysCaptureBufferV.LowPart = 0;
                    pHwDevExt->pPhysCaptureBufferV.HighPart = 0;
                    pHwDevExt->BufferSize = 0;
                    pSrb->Status = STATUS_INVALID_PARAMETER;
                    return FALSE;
                }
                RtlZeroMemory(VirtualAddress, ImageSizeU);
                pHwDevExt->pCaptureBufferU = VirtualAddress;
                PhysicalAddress = MmGetPhysicalAddress(pHwDevExt->pCaptureBufferU);
                pHwDevExt->pPhysCaptureBufferU = PhysicalAddress;

                VirtualAddress = MmAllocateContiguousMemory(ImageSizeV, LimitAddress);
                if (VirtualAddress == 0)
                {
                    MmFreeContiguousMemory(pHwDevExt->pCaptureBufferY);
                    pHwDevExt->pCaptureBufferY = NULL;
                    MmFreeContiguousMemory(pHwDevExt->pCaptureBufferU);
                    pHwDevExt->pCaptureBufferU = NULL;
                    pHwDevExt->pPhysCaptureBufferY.LowPart = 0;
                    pHwDevExt->pPhysCaptureBufferY.HighPart = 0;
                    pHwDevExt->pPhysCaptureBufferU.LowPart = 0;
                    pHwDevExt->pPhysCaptureBufferU.HighPart = 0;
                    pHwDevExt->pPhysCaptureBufferV.LowPart = 0;
                    pHwDevExt->pPhysCaptureBufferV.HighPart = 0;
                    pHwDevExt->BufferSize = 0;
                    pSrb->Status = STATUS_INVALID_PARAMETER;
                    return FALSE;
                }
                RtlZeroMemory(VirtualAddress, ImageSizeV);
                pHwDevExt->pCaptureBufferV = VirtualAddress;
                PhysicalAddress = MmGetPhysicalAddress(pHwDevExt->pCaptureBufferV);
                pHwDevExt->pPhysCaptureBufferV = PhysicalAddress;


                ulFrameRate = 15;
                pHwDevExt->dblBufflag = FALSE;
            } else {
                pHwDevExt->IsRPSReady = FALSE;
                pHwDevExt->BufferSize = ImageSize;
                if ((ImageSize * 2) > MAX_CAPTURE_BUFFER_SIZE) {
                    ulFrameRate = 15;
                    pHwDevExt->dblBufflag = FALSE;
                } else {
                    ulFrameRate = 30;
                    Alloc_TriBuffer(pHwDevExt);
                    pHwDevExt->dblBufflag = TRUE;
                }
            }
        }

        if(!ImageSetInputImageSize(pHwDevExt, &(pHwDevExt->SrcRect)))  // Insert 97-04-08(Tue)
        {
            pSrb->Status = STATUS_INVALID_PARAMETER;
            return FALSE;
        }

        if(!ImageSetOutputImageSize(pHwDevExt, pHwDevExt->ulWidth, pHwDevExt->ulHeight))     // Insert 97-04-08(Tue)
        {
            pSrb->Status = STATUS_INVALID_PARAMETER;
            return FALSE;
        }

        if (!BertFifoConfig(pHwDevExt, pHwDevExt->Format))
        {
            pSrb->Status = STATUS_INVALID_PARAMETER;
            return FALSE;
        }
        if(!ImageSetHueBrightnessContrastSat(pHwDevExt)){                                // Insert 97-04-08(Tue)
            return FALSE;
        }

        if ( pHwDevExt->ColorEnable ) {
            if ( get_AblFilter( pHwDevExt ) ) {
                set_filtering( pHwDevExt, TRUE );
            } else {
                set_filtering( pHwDevExt, FALSE );
                pHwDevExt->